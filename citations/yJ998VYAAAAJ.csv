Reconstruction and simulation of neocortical microcircuitry,Henry Markram; Eilif Muller; Srikanth Ramaswamy; Michael W Reimann; Marwan Abdellah; Carlos Aguado Sanchez; Anastasia Ailamaki; Lidia Alonso-Nanclares; Nicolas Antille; Selim Arsever; Guy Antoine Atenekeng Kahou; Thomas K Berger; Ahmet Bilgili; Nenad Buncic; Athanassia Chalimourda; Giuseppe Chindemi; Jean-Denis Courcol; Fabien Delalondre; Vincent Delattre; Shaul Druckmann; Raphael Dumusc; James Dynes; Stefan Eilemann; Eyal Gal; Michael Emiel Gevaert; Jean-Pierre Ghobril; Albert Gidon; Joe W Graham; Anirudh Gupta; Valentin Haenel; Etay Hay; Thomas Heinis; Juan B Hernando; Michael Hines; Lida Kanari; Daniel Keller; John Kenyon; Georges Khazen; Yihwa Kim; James G King; Zoltan Kisvarday; Pramod Kumbhar; Sébastien Lasserre; Jean-Vincent Le Bé; Bruno RC Magalhães; Angel Merchán-Pérez; Julie Meystre; Benjamin Roy Morrice; Jeffrey Muller; Alberto Muñoz-Céspedes; Shruti Muralidhar; Keerthan Muthurasa; Daniel Nachbaur; Taylor H Newton; Max Nolte; Aleksandr Ovcharenko; Juan Palacios; Luis Pastor; Rodrigo Perin; Rajnish Ranjan; Imad Riachi; José-Rodrigo Rodríguez; Juan Luis Riquelme; Christian Rössert; Konstantinos Sfyrakis; Ying Shi; Julian C Shillcock; Gilad Silberberg; Ricardo Silva; Farhan Tauheed; Martin Telefont; Maria Toledo-Rodriguez; Thomas Tränkler; Werner Van Geit; Jafet Villafranca Díaz; Richard Walker; Yun Wang; Stefano M Zaninetta; Javier DeFelipe; Sean L Hill; Idan Segev; Felix Schürmann,Summary We present a first-draft digital reconstruction of the microcircuitry of somatosensorycortex of juvenile rat. The reconstruction uses cellular and synaptic organizing principles toalgorithmically reconstruct detailed anatomy and physiology from sparse experimental data.An objective anatomical method defines a neocortical volume of 0.29±0.01 mm 3containing∼ 31;000 neurons; and patch-clamp studies identify 55 layer-specificmorphological and 207 morpho-electrical neuron subtypes. When digitally reconstructedneurons are positioned in the volume and synapse formation is restricted to biologicalbouton densities and numbers of synapses per connection; their overlapping arbors form∼8 million connections with∼ 37 million synapses. Simulations reproduce an array of in vitroand in vivo experiments without parameter tuning. Additionally; we find a spectrum of …,Cell,2015,291
Efficient lineage tracking for scientific workflows,Thomas Heinis; Gustavo Alonso,Abstract Data lineage and data provenance are key to the management of scientific data.Not knowing the exact provenance and processing pipeline used to produce a derived dataset often renders the data set useless from a scientific point of view. On the positive side;capturing provenance information is facilitated by the widespread use of workflow tools forprocessing scientific data. The workflow process describes all the steps involved inproducing a given data set and; hence; captures its lineage. On the negative side; efficientlystoring and querying workflow based data lineage is not trivial. All existing solutions userecursive queries and even recursive tables to represent the workflows. Such solutions donot scale and are rather inefficient. In this paper we propose an alternative approach tostoring lineage information captured as a workflow process. We use a space and query …,Proceedings of the 2008 ACM SIGMOD international conference on Management of data,2008,126
Design and evaluation of an autonomic workflow engine,Thomas Heinis; Cesare Pautasso; Gustavo Alonso,In this paper we present the design and evaluate the performance of an autonomic workflowexecution engine. Although there exist many distributed workflow engines; in practice; itremains a difficult problem to deploy such systems in an optimal configuration. Furthermore;when facing an unpredictable workload with high variability; manual reconfiguration is notan option. Thanks to its autonomic controller; the engine features self-configuration; self-tuning and self-healing properties. The engine runs on a cluster of computers using a tuplespace to coordinate its various components. Its autonomic controller monitors itsperformance and responds to workload variations by altering the configuration. In casefailures occur; the controller can recover the workflow execution state from persistent storageand migrate it to a different node of the cluster. Such interventions are carried out without …,Autonomic Computing; 2005. ICAC 2005. Proceedings. Second International Conference on,2005,90
Developing scientific workflows from heterogeneous services,Aphrodite Tsalgatidou; George Athanasopoulos; Michael Pantazoglou; Cesare Pautasso; Thomas Heinis; Roy Grønmo; Hjørdis Hoff; Arne-Jørgen Berre; Magne Glittum; Simela Topouzidou,Abstract Scientific WorkFlows (SWFs) need to utilize components and applications in orderto satisfy the requirements of specific workflow tasks. Technology trends in softwaredevelopment signify a move from component-based to service-oriented approach; thereforeSWF will inevitably need appropriate tools to discover and integrate heterogeneousservices. In this paper we present the SODIUM platform consisting of a set of languages andtools as well as related middleware; for the development and execution of scientificworkflows composed of heterogeneous services.,ACM Sigmod Record,2006,66
Autonomic execution of web service compositions,Cesare Pautasso; Thomas Heinis; Gustavo Alonso,An increasing amount of Web services are being implemented using process managementtools and languages (BPML; BPEL; etc.). The main advantage of processes is that designerscan express complex business conversations at a high level of abstraction; even reusingstandardized business protocols. The downside is that the infrastructure behind the Webservice becomes more complex. This is particularly critical for Web services that may besubjected to high variability in demand and suffer from unpredictable peaks of heavy load. Inthis paper we present a flexible architecture for process execution that has been designed tosupport autonomic scalability. The system runs on a cluster of computers and reacts toworkload variations by altering its configuration in order to optimally use the availableresources. Such changes happen automatically and without any human intervention. This …,Web Services; 2005. ICWS 2005. Proceedings. 2005 IEEE International Conference on,2005,55
Overview of autonomic computing: Origins; evolution; direction,Alan Ganek,*,Autonomic Computing: Concepts; Infrastructure; and Applications.; by Salim Hariri Manish Parashar,2004,44
Autonomic resource provisioning for software business processes,Cesare Pautasso; Thomas Heinis; Gustavo Alonso,Abstract Software development nowadays involves several levels of abstraction: startingfrom the programming of single objects; to their combination into components; to theirpublication as services and the overall architecture linking elements at each level. As aresult; software engineering is dealing with a wider range of artifacts and concepts (ie; in thecontext of this paper: services and business processes) than ever before. In this paper weexplore the importance of having an adequate engine for executing business processeswritten as compositions of Web services. The paper shows that; independently of thecomposition language used; the overall scalability of the system is determined by how therun-time engine treats the process execution. This is particularly relevant at the service levelbecause publishing a process through a Web service interface makes it accessible to an …,Information and Software Technology,2007,41
TOUCH: in-memory spatial join by hierarchical data-oriented partitioning,Sadegh Nobari; Farhan Tauheed; Thomas Heinis; Panagiotis Karras; Stéphane Bressan; Anastasia Ailamaki,Abstract Efficient spatial joins are pivotal for many applications and particularly important forgeographical information systems or for the simulation sciences where scientists work withspatial models. Past research has primarily focused on disk-based spatial joins; efficient in-memory approaches; however; are important for two reasons: a) main memory has grown solarge that many datasets fit in it and b) the in-memory join is a very time-consuming part of alldisk-based spatial joins. In this paper we develop TOUCH; a novel in-memory spatial joinalgorithm that uses hierarchical data-oriented space partitioning; thereby keeping both itsmemory footprint and the number of comparisons low. Our results show that TOUCHoutperforms known in-memory spatial-join algorithms as well as in-memory implementationsof disk-based join approaches. In particular; it has a one order of magnitude advantage …,Proceedings of the 2013 ACM SIGMOD International Conference on Management of Data,2013,35
JOpera: Autonomic Service Orchestration.,Cesare Pautasso; Thomas Heinis; Gustavo Alonso,The increasing interest in new software engineering technologies for application integrationsuch as Service Oriented Computing and Service Orchestration has resulted in aproliferation of workflow management systems as the underlying representation andexecution platform for service composition [7]. Workflow management system are also beingapplied to new domains (eg; virtual scientific laboratories [1]; Grid computing [12]; servicedelivery and provisioning [6]). For these new applications; workflows are seen as themodeling metaphor behind the notion of straight through processing and virtualorganizations where a collection of existing heterogeneous systems are composed into anintegrated solution. In all these settings workflow engines are at the core of a complexcombination of applications and clustered computers. As such; they have become rather …,IEEE Data Eng. Bull.,2006,30
Just-in-time data virtualization: Lightweight data management with ViDa,Manos Karpathiotakis; Ioannis Alagiannis; Thomas Heinis; Miguel Branco; Anastasia Ailamaki,ABSTRACT As the size of data and its heterogeneity increase; traditional database systemarchitecture becomes an obstacle to data analysis. Integrating and ingesting (loading) datainto databases is quickly becoming a bottleneck in face of massive data as well asincreasingly heterogeneous data formats. Still; state-of-the-art approaches typically rely oncopying and transforming data into one (or few) repositories. Queries; on the other hand; areoften ad-hoc and supported by pre-cooked operators which are not adaptive enough tooptimize access to data. As data formats and queries increasingly vary; there is a need todepart from the current status quo of static query processing primitives and build dynamic;fully adaptive architectures. We build ViDa; a system which reads data in its raw format andprocesses queries using adaptive; just-in-time operators. Our key insight is use of …,Proceedings of the 7th Biennial Conference on Innovative Data Systems Research (CIDR),2015,27
Accelerating range queries for brain simulations,Farhan Tauheed; Laurynas Biveinis; Thomas Heinis; Felix Schurmann; Henry Markram; Anastasia Ailamaki,Neuroscientists increasingly use computational tools in building and simulating models ofthe brain. The amounts of data involved in these simulations are immense and efficientlymanaging this data is key. One particular problem in analyzing this data is the scalableexecution of range queries on spatial models of the brain. Known indexing approaches donot perform well even on today's small models which represent a small fraction of the brain;containing only few millions of densely packed spatial elements. The problem of currentapproaches is that with the increasing level of detail in the models; also the overlap in thetree structure increases; ultimately slowing down query execution. The neuroscientists' needto work with bigger and more detailed (denser) models thus motivates us to develop a newindexing approach. To this end we develop FLAT; a scalable indexing approach for …,Data Engineering (ICDE); 2012 IEEE 28th International Conference on,2012,25
Parinda: an interactive physical designer for postgresql,Cristina Maier; Debabrata Dash; Ioannis Alagiannis; Anastasia Ailamaki; Thomas Heinis,Abstract One of the most challenging tasks for the database administrator is to physicallydesign the database to attain optimal performance for a given workload. Physical design ishard because it requires the selection of an optimal set of design features from a vast searchspace. There have been many commercial tools available to automatically suggest thephysical design; for a given a set of queries. These tools are; however; based on greedyheuristic pruning; which reduces their usefulness. Furthermore; they are not interactive; asthe APIs to simulate the indexes and tables are product specific and hidden from thedatabase administrators. Finally; all these tools are built specifically for commercial systemsand there is lack of automated physical designers for open source DBMSs. In thisdemonstration we introduce-PARINDA-an interactive physical designer for an open …,Proceedings of the 13th International Conference on Extending Database Technology,2010,24
Automatic configuration of an autonomic controller: An experimental study with zero-configuration policies,Thomas Heinis; Cesare Pautasso,Autonomic control managers can remove the need for manual system configuration in orderto achieve good performance and efficient resource utilization. However; simple controllersbased on reconfiguration actions tied to thresholds; or'if-then'rules; themselves need to beconfigured and tuned in order to adapt the controller behavior to the expected workloadcharacteristic. In this paper we present an experimental study of zero-configuration policiesthat can be automatically tuned based on analytical models of the system under control. Inparticular; we have designed and implemented a threshold-free self-configuration policy fora distributed workflow execution engine and compared it with a standard PID controller. Theexperimental results included in the paper show that using such apolicy the controller cantune itself in addition to reconfiguring the distributed engine and the proposed policy out …,Autonomic Computing; 2008. ICAC'08. International Conference on,2008,16
Publishing persistent grid computations as WS resources,Thomas Heinis; Cesare Pautasso; Oliver Deak; Gustavo Alonso,Grid services can be composed into processes; providing a high level definition of thecomputations involved in terms of their data exchanges and control flow dependencies. Inthis paper we show how processes themselves can be efficiently published as grid servicesby mapping the persistent state of the process executions to standard compliant interfacesas defined by the Web Services Resource Framework (WS-RF). Mapping processes toresources is a fundamental step to enable recursive Grid service composition; wherecomposite grid services are themselves published as services. This gives processes astandardized and well-understood interface that enables their management; monitoring;steering and adaptation. Additionally it eases their reusability and simplifies integration intoexisting grid applications and portals. In order to determine the mapping's overhead; we …,e-Science and Grid Computing; 2005. First International Conference on,2005,16
SCOUT: prefetching for latent structure following queries,Farhan Tauheed; Thomas Heinis; Felix Schürmann; Henry Markram; Anastasia Ailamaki,Abstract Today's scientists are quickly moving from in vitro to in silico experimentation: theyno longer analyze natural phenomena in a petri dish; but instead they build models andsimulate them. Managing and analyzing the massive amounts of data involved insimulations is a major task. Yet; they lack the tools to efficiently work with data of this size.One problem many scientists share is the analysis of the massive spatial models they build.For several types of analysis they need to interactively follow the structures in the spatialmodel; eg; the arterial tree; neuron fibers; etc.; and issue range queries along the way. Eachquery takes long to execute; and the total time for executing a sequence of queriessignificantly delays data analysis. Prefetching the spatial data reduces the response timeconsiderably; but known approaches do not prefetch with high accuracy.,Proceedings of the VLDB Endowment,2012,14
Data analysis: Approximation aids handling of big data,Thomas Heinis,Abstract We need a radical shift in our approach to data analysis towards approximation.Our technical capacity is being overtaken by the unprecedented rate of data generation bytoday's powerful instruments and computers (see H. Esmaeilzadehet al. Commun. ACM56;93,Nature,2014,9
THERMAL-JOIN: A scalable spatial join for dynamic workloads,Farhan Tauheed; Thomas Heinis; Anastasia Ailamaki,Abstract Simulations have become ubiquitous in many domains of science. Today scientistsstudy natural phenomena by first building massive three-dimensional spatial models andthen by simulating the models at discrete intervals of time to mimic the behavior of naturalphenomena. One frequently occurring challenge during simulations is the repeatedcomputation of spatial self-joins of the model at each simulation time step. The join isperformed to access a group of neighboring spatial objects (groups of particles; moleculesor cosmological objects) so that scientists can calculate the cumulative effect (likegravitational force) on an object. Computing a self-join even in memory; soon becomes aperformance bottleneck in simulation applications. The problem becomes even worse asscientists continue to improve the precision of simulations by increasing the number as …,Proceedings of the 2015 ACM SIGMOD International Conference on Management of Data,2015,8
Challenges and opportunities in self-managing scientific databases,Thomas Heinis; Miguel Branco; Ioannis Alagiannis; Renata Borovica; Farhan Tauheed; Anastasia Ailamaki,Abstract Advances in observation instruments and abundance of computational power forsimulations encourage scientists to gather and produce unprecedented amounts ofincreasingly complex data. Organizing data automatically to enable efficient andunobstructed access is pivotal for the scientists. Organizing these vast amounts of complexdata; however; is particularly difficult for scientists who have little experience in datamanagement; hence they spend considerable amounts of time dealing with data analysisand computing problems rather than answering scientific questions or developing newhypotheses. Therefore scientific experiments are in many ways ideal targets for research inself-managing database systems. In this paper; we describe challenges and opportunitiesfor research in automating scientific data management. We first discuss the problems …,Data Engineering Bulletin,2011,7
Mirroring resources or mapping requests: implementing WS-RF for Grid workflows,Thomas Heinis; Cesare Pautasso; Gustavo Alonso,The Web services resource framework (WS-RF) and the Web services notification (WS-N)specifications are a crucial component of grid infrastructures. They provide a standardizedinterface to stateful services so that they can be managed remotely. There are alreadyseveral implementations of these specifications and initial performance studies havecompared them in terms of the overhead observed by a single client. In this paper; weaddress the problem of implementing the WS-RF and WS-N specifications for large scalesystems. In particular; we discuss how to implement WS-RF and WS-N as the managementinterfaces to a grid workflow engine. In the paper we describe and compare two differentarchitectures for mapping resources to processes. The first one mirrors the state of theprocess as a resource. The second one maps the client requests to access the state of a …,Cluster Computing and the Grid; 2006. CCGRID 06. Sixth IEEE International Symposium on,2006,6
OCTOPUS: Efficient query execution on dynamic mesh datasets,Farhan Tauheed; Thomas Heinis; Felix Schurmann; Henry Markram; Anastasia Ailamaki,Scientists in many disciplines use spatial mesh models to study physical phenomena.Simulating natural phenomena by changing meshes over time helps to better understandthe phenomena. The higher the precision of the mesh models; the more insight do thescientists gain and they thus continuously increase the detail of the meshes and build themas detailed as their instruments and the simulation hardware allow. In the process; the datavolume also increases; slowing down the execution of spatial range queries needed tomonitor the simulation considerably. Indexing speeds up range query execution; but theoverhead to maintain the indexes is considerable because almost the entire mesh changesunpredictably at every simulation step. Using a simple linear scan; on the other hand;requires accessing the entire mesh and the performance deteriorates as the size of the …,Data Engineering (ICDE); 2014 IEEE 30th International Conference on,2014,5
BLOCK: Efficient Execution of Spatial Range Queries in Main-Memory,Matthaios Alexandros Olma; Farhan Tauheed; Thomas Heinis; Anastasia Ailamaki,ABSTRACT The execution of spatial range queries is at the core of many applications;particularly in the simulation sciences but also in many other domains. Although mainmemory in desktop and supercomputers alike has grown considerably in recent years; mostspatial indexes supporting the efficient execution of range queries are still only optimized fordisk access (minimizing disk page reads). Recent research has primarily focused on theoptimization of known disk-based approaches for memory (through cache alignment etc.)but has not fundamentally revisited index structures for memory. In this paper we developBLOCK; a novel approach to execute range queries on spatial data featuring volumetricobjects in main memory. Our approach is built on the key insight that in-memory approachesneed to be optimized to reduce the number of intersection tests (between objects and …,*,2017,4
GIPSY: joining spatial datasets with contrasting density,Mirjana Pavlovic; Farhan Tauheed; Thomas Heinis; Anastasia Ailamakit,Abstract Many scientific and geographical applications rely on the efficient execution ofspatial joins. Past research has produced several efficient spatial join approaches and whileeach of them can join two datasets; the problem of efficiently joining two datasets withcontrasting density; ie; with the same spatial extent but with a wildly different number ofspatial elements; has so far been overlooked. State-of-the-art data-oriented spatial joinapproaches (eg; based on the R-Tree) suffer from degraded performance due to overlap;whereas space-oriented approaches excessively read data from disk. In this paper wedevelop GIPSY; a novel approach for the spatial join of two datasets with contrasting density.GIPSY uses fine-grained data-oriented partitioning and thus only retrieves the data neededfor the join. At the same time it avoids the overlap related problems associated with data …,Proceedings of the 25th International Conference on Scientific and Statistical Database Management,2013,4
Data-driven neuroscience: enabling breakthroughs via innovative data management,Alexandros Stougiannis; Mirjana Pavlovic; Farhan Tauheed; Thomas Heinis; Anastasia Ailamaki,Abstract Scientists in all disciplines increasingly rely on simulations to develop a betterunderstanding of the subject they are studying. For example the neuroscientists wecollaborate with in the Blue Brain project have started to simulate the brain on asupercomputer. The level of detail of their models is unprecedented as they model details onthe subcellular level (eg; the neurotransmitter). This level of detail; however; also leads to atrue data deluge and the neuroscientists have only few tools to efficiently analyze the data.This demonstration showcases three innovative spatial management techniques that havesubstantial impact on computational neuroscience and other disciplines in that they allow tobuild; analyze and simulate bigger and more detailed models. More particularly; wedemonstrate a tool that integrates three spatial data management techniques that have …,Proceedings of the 2013 ACM SIGMOD International Conference on Management of Data,2013,4
Towards the identification of disease signatures,Tassos Venetis; Anastasia Ailamaki; Thomas Heinis; Manos Karpathiotakis; Ferath Kherif; Alexis Mitelpunkt; Vasilis Vassalos,Abstract The identification of biological signatures of diseases will enable the developmentof new biologically grounded classifications of brain diseases; leading to a new systematicunderstanding of their causes; and new diagnostic tools. In this paper we present thechallenges and steps taken towards the identification of disease signatures; through theMedical Informatics Platform of the Human Brain Project; that will expedite diagnosis andlead to more accurate prognosis and objective diagnosis.,International Conference on Brain Informatics and Health,2015,3
Spatial data management challenges in the simulation sciences,Thomas Heinis; Farhan Tauheed; Anastasia Ailamaki,ABSTRACT Scientists in many disciplines have progressively been using simulations tobetter understand the natural systems they study. Faster hardware; as well as increasinglyprecise instruments; allow the construction and simulation of progressively advancedmodels of various systems. Governed by algorithms and equations; the spatial models at thecore of simulations are changed and updated at every simulation step through spatialqueries; implementing massive updates. Therefore; the efficient execution of thesenumerous spatial queries is essential. Two reasons render current spatial indexesinadequate for simulation applications. First; to ensure quick access to data; most of thespatial models in simulations are stored in memory. Most spatial access methods; however;have been optimized for use on disk and are not efficient in memory. Second; in every …,Proceedings of the International Conference on Extending Database Technology,2014,3
Spatial data management challenges in the simulation sciences,Thomas Heinis; Farhan Tauheed; Anastasia Ailamaki,ABSTRACT Scientists in many disciplines have progressively been using simulations tobetter understand the natural systems they study. Faster hardware; as well as increasinglyprecise instruments; allow the construction and simulation of progressively advancedmodels of various systems. Governed by algorithms and equations; the spatial models at thecore of simulations are changed and updated at every simulation step through spatialqueries; implementing massive updates. Therefore; the efficient execution of thesenumerous spatial queries is essential. Two reasons render current spatial indexesinadequate for simulation applications. First; to ensure quick access to data; most of thespatial models in simulations are stored in memory. Most spatial access methods; however;have been optimized for use on disk and are not efficient in memory. Second; in every …,Proceedings of the International Conference on Extending Database Technology,2014,3
Computational neuroscience breakthroughs through innovative data management,Farhan Tauheed; Sadegh Nobari; Laurynas Biveinis; Thomas Heinis; Anastasia Ailamaki,Abstract Simulations have become key in many scientific disciplines to better understandnatural phenomena. Neuroscientists; for example; build and simulate increasingly fine-grained models (including subcellular details; eg; neurotransmitter) of the neocortex tounderstand the mechanisms causing brain diseases and to test new treatments in-silico. Thesheer size and; more importantly; the level of detail of their models challenges today'sspatial data management techniques. In collaboration with the Blue Brain project (BBP) wedevelop new approaches that efficiently enable analysis; navigation and discovery in spatialmodels of the brain. More precisely; we develop an index for the scalable and efficientexecution of spatial range queries supporting model building and analysis. Furthermore; weenable navigational access to the brain models; ie; the execution of of series of range …,East European Conference on Advances in Databases and Information Systems,2013,3
Computational neuroscience breakthroughs through innovative data management,Farhan Tauheed; Sadegh Nobari; Laurynas Biveinis; Thomas Heinis; Anastasia Ailamaki,Abstract Simulations have become key in many scientific disciplines to better understandnatural phenomena. Neuroscientists; for example; build and simulate increasingly fine-grained models (including subcellular details; eg; neurotransmitter) of the neocortex tounderstand the mechanisms causing brain diseases and to test new treatments in-silico. Thesheer size and; more importantly; the level of detail of their models challenges today'sspatial data management techniques. In collaboration with the Blue Brain project (BBP) wedevelop new approaches that efficiently enable analysis; navigation and discovery in spatialmodels of the brain. More precisely; we develop an index for the scalable and efficientexecution of spatial range queries supporting model building and analysis. Furthermore; weenable navigational access to the brain models; ie; the execution of of series of range …,East European Conference on Advances in Databases and Information Systems,2013,3
TRANSFORMERS: Robust spatial joins on non-uniform data distributions,Mirjana Pavlovic; Thomas Heinis; Farhan Tauheed; Panagiotis Karras; Anastasia Ailamaki,Spatial joins are becoming increasingly ubiquitous in many applications; particularly in thescientific domain. While several approaches have been proposed for joining spatialdatasets; each of them has a strength for a particular type of density ratio among the joineddatasets. More generally; no single proposed method can efficiently join two spatial datasetsin a robust manner with respect to their data distributions. Some approaches do well fordatasets with contrasting densities while others do better with similar densities. None ofthem does well when the datasets have locally divergent data distributions. In this paper wedevelop TRANSFORMERS; an efficient and robust spatial join approach that is indifferent tosuch variations of distribution among the joined data. TRANSFORMERS achieves this featby departing from the state-of-the-art through adapting the join strategy and data layout to …,Data Engineering (ICDE); 2016 IEEE 32nd International Conference on,2016,2
Configuring Spatial Grids for Efficient Main Memory Joins,Farhan Tauheed; Thomas Heinis; Anastasia Ailamaki,Abstract The performance of spatial joins is becoming increasingly important in manyapplications; particularly in the scientific domain. Several approaches have been proposedfor joining spatial datasets on disk and few in main memory. Recent results show that inmain memory; grids are more efficient than the traditional tree based methods primarilydeveloped for disk. The question how to configure the grid; however; has so far not beendiscussed. In this paper we study how to configure a spatial grid for joining spatial data inmain memory. We discuss the trade-offs involved; develop an analytical model predictingthe performance of a configuration and finally validate the model with experiments.,British International Conference on Databases,2015,2
A Self-Configuring Service Composition Engine,Thomas Heinis; Cesare Pautasso; Gustavo Alonso,Accessibility; Homepage; Navigation within EPFL sites; Navigation within this site; Jump to searchfield; Jump to page content; Technical contact. You are: Prospective students portal. Bachelor;Master; PhD; Exchange student. Students portal. Student services; Academic calendar. Researchersportal. Research funding; Prizes and Awards. Staff portal. Human resources; Polylex: laws; directives.Business portal. Innovation & Tech Transfer; EPFL Innovation Park. Mediacorner. Press releases;EPFL Magazine; Image library. Teaching portal. Courses management; Students management.EPFL Alumni Portal. Join the community; Alumni events. Science and Society. Science Outreach;Culture/Art/Science - ArtLab. By school: Architecture; Civil and Environmental Engineering ENAC.Architecture; Civil Engineering; Environmental Engineering. Basic Sciences SB. Chemistry andChemical Engineering; Mathematics; Physics …,*,2006,2
Efficient mining of regional movement patterns in semantic trajectories,Dong-Wan Choi; Jian Pei; Thomas Heinis,Abstract Semantic trajectory pattern mining is becoming more and more important with therapidly growing volumes of semantically rich trajectory data. Extracting sequential patterns insemantic trajectories plays a key role in understanding semantic behaviour of humanmovement; which can widely be used in many applications such as location-basedadvertising; road capacity optimisation; and urban planning. However; most of existingworks on semantic trajectory pattern mining focus on the entire spatial area; leading tomissing some locally significant patterns within a region. Based on this motivation; this paperstudies a regional semantic trajectory pattern mining problem; aiming at identifying all theregional sequential patterns in semantic trajectories. Specifically; we propose a new densityscheme to quantify the frequency of a particular pattern in space; and thereby formulate a …,Proceedings of the VLDB Endowment,2017,1
Hashing-based approximate DBSCAN,Tianrun Li; Thomas Heinis; Wayne Luk,Abstract Analyzing massive amounts of data and extracting value from it has become keyacross different disciplines. As the amounts of data grow rapidly; however; currentapproaches for data analysis struggle. This is particularly true for clustering algorithmswhere distance calculations between pairs of points dominate overall time. Crucial to thedata analysis and clustering process; however; is that it is rarely straightforward. Instead;parameters need to be determined through several iterations. Entirely accurate results arethus rarely needed and instead we can sacrifice precision of the final result to accelerate thecomputation. In this paper we develop ADvaNCE; a new approach to approximatingDBSCAN. ADvaNCE uses two measures to reduce distance calculation overhead:(1) localitysensitive hashing to approximate and speed up distance calculations and (2) …,East European Conference on Advances in Databases and Information Systems,2016,1
An Efficient Parallel Load-Balancing Framework for Orthogonal Decomposition of Geometrical Data,Bruno RC Magalhães; Farhan Tauheed; Thomas Heinis; Anastasia Ailamaki; Felix Schürmann,Abstract The accurate subdivision of spatially organized datasets is a complex problem incomputer science but specifically important for load balancing in parallel environments. Theproblem is to (a) find a partitioning where each partition has the same number of elementsand (b) the communication between partitions (duplicate members) is minimized. Wepresent a novel parallel load-balancing framework—Sort Balance Split (SBS)—the first toour knowledge to perform accurate parallel partitioning of multidimensional data; whilerequiring a fixed number of communication steps independent of network size or input datadistribution. When compared to the state of the art sampling and parallel partitioningmethods adopted by HPC problems; it delivers better load balancing on a shorter time tosolution. We analyse four partitioning schemes that SBS can be applied to; and evaluated …,International Conference on High Performance Computing,2016,1
Uncertainty Quantification of Epidemic Phenomena and the Parallel Simulator Tool,Alina Draganescu; William Knottenbelt; Thomas Heinis,Abstract Technological and industrial advances allows for biological and non-biologicalepidemics to spread faster than the world has ever seen. The analysis of epidemiologicalmodels and uncertainty quantification represents one of the best strategies for the controland management of infectious diseases. The main contributions of this project are acomparison between simulated and analytically derived measures (mean; variance;skewness) regarding the infected counts of an epidemic and a parallelised tool that canprovide the user with a quick visualisations of the particularities of their chosencompartmental model. The report will detail the approach taken in deriving both analyticaland simulated measures along with a discussion regarding the implementation of theParallel Simulator Tool. This project provides valuable insight regarding the potential of …,*,2015,1
Reconsolidating data structures,Thomas Heinis; Anastasia Ailamaki,ABSTRACT For decades forgetting has been treated as an abnormality; a malfunction of thebrain that leads humans to lose stored information. Recent results; however; suggest thatforgetting is not only a malfunction of the human storage system; but also a useful feature. Inorder to guarantee a quick response in the face of the limited processing power of the brain;acting quickly on less or reduced information is key. With storage becoming ever cheaperand continually growing it has become standard practice today to store each and everysingle data item. However; even increasingly powerful processors cannot deal with this datadeluge. In this paper we consequently argue that forgetting and its mechanisms should be apart of today's data management; particularly for techniques requiring fast and/orapproximate query answers. While forgetting or shedding information may have far …,*,2015,1
Workflow-based services: infrastructure for scientific applications,Thomas Heinis,Abstract The way scientists work in traditional sciences has changed dramatically in recentyears. Computer science is increasingly supporting them in performing and analyzing theirexperiments. Today; obtaining the raw data from instruments is merely the first step. Nolonger is the data analyzed on paper or with simple computational tools. Instead; massiveamounts of data obtained raw from instruments are processed in complex and long-runningcomputational pipelines. This trend of supporting traditional sciences with computationaltools has lead to a significant speedup in executing experiments and has also enabledexperiments which would not have been possible before. Scientists increasingly depend onadequate infrastructure to process experiment data using computational pipelines and tomanage the plethora of data used and produced by them. Such computational pipelines …,*,2010,1
Workflow-based services: infrastructure for scientific applications,Thomas Heinis,Abstract The way scientists work in traditional sciences has changed drastically in recentyears. Computer science is increasingly supporting them in performing and analyzing theirexperiments. Today; obtaining the raw data from instruments is merely the first step. Nolonger is the data analyzed on paper or with simple computational tools. Instead; massiveamounts of data obtained raw from instruments are processed in complex and long-runningcomputational pipelines. This trend of supporting traditional sciences with computationaltools has lead to a significant speedup in executing experiments and has also enabledexperiments which would not have been possible before. Scientists increasingly depend onadequate infrastructure to process experiment data using complex computational pipelinesand to manage the plethora of data used and produced by them. Such computational …,*,2009,1
Data Infrastructure for Medical Research,Thomas Heinis; Anastasia Ailamaki,Abstract While we are witnessing rapid growth in data across the sciences and in manyapplications; this growth is particularly remarkable in the medical domain; be it because ofhigher resolution instruments and diagnostic tools (eg MRI); new sources of structured datalike activity trackers; the wide-spread use of electronic health records and many others. Thesheer volume of the data is not; however; the only challenge to be faced when using medicaldata for research. Other crucial challenges include data heterogeneity; data quality; dataprivacy and so on. In this article; we review solutions addressing these challenges bydiscussing the current state of the art in the areas of data integration; data cleaning; dataprivacy; scalable data access and processing in the context of medical data. The techniquesand tools we present will give practitioners—computer scientists and medical researchers …,Foundations and Trends® in Databases,2017,*
STATS-A Point Access Method for Multidimensional Clusters,Giannis Evagorou; Thomas Heinis,Abstract The ubiquity of high-dimensional data in machine learning and data miningapplications makes its efficient indexing and retrieval from main memory crucial. Frequently;these machine learning algorithms need to query specific characteristics of singlemultidimensional points. For example; given a clustered dataset; the cluster membership(CM) query retrieves the cluster to which an object belongs. To efficiently answer this type ofquery we have developed STATS; a novel main-memory index which scales to answer CMqueries on increasingly big datasets. Current indexing methods are oblivious to the structureof clusters in the data; and we thus; develop STATS around the key insight that exploiting thecluster information when indexing and preserving it in the index will accelerate look up. Weshow experimentally that STATS outperforms known methods in regards to retrieval time …,International Conference on Database and Expert Systems Applications,2017,*
ADvaNCE–Efficient and Scalable Approximate Density-Based Clustering Based on Hashing,Tianrun Li; Thomas Heinis; Wayne Luk,Abstract Analysing massive amounts of data and extracting value from it has become keyacross different disciplines. As the amounts of data grow rapidly; current approaches for dataanalysis are no longer efficient. This is particularly true for clustering algorithms wheredistance calculations between pairs of points dominate overall time: the more data pointsare in the dataset; the bigger the share of time needed for distance calculations.,Informatica,2017,*
Space odyssey: efficient exploration of scientific data,Mirjana Pavlovic; Eleni Tzirita Zacharatou; Darius Sidlauskas; Thomas Heinis; Anastasia Ailamaki,Abstract Advances in data acquisition---through more powerful supercomputers forsimulation or sensors with better resolution---help scientists tremendously to understandnatural phenomena. At the same time; however; it leaves them with a plethora of data andthe challenge of analysing it. Ingesting all the data in a database or indexing it for an efficientanalysis is unlikely to pay off because scientists rarely need to analyse all data. Not knowinga priori what parts of the datasets need to be analysed makes the problem challenging.Tools and methods to analyse only subsets of this data are rather rare. In this paper wetherefore present Space Odyssey; a novel approach enabling scientists to efficiently exploremultiple spatial datasets of massive size. Without any prior information; Space Odysseyincrementally indexes the datasets and optimizes the access to datasets frequently …,Proceedings of the Third International Workshop on Exploratory Search in Databases and the Web,2016,*
On-the-Fly Data Synopses: Efficient Data Exploration in the Simulation Sciences,Thomas Heinis; David A Ham,Abstract As a consequence of ever more powerful computing hardware and increasinglyprecise instruments; our capacity to produce scientific data by far outpaces our ability toefficiently store and analyse it. Few of today's tools to analyse scientific data are able tohandle the deluge captured by instruments or generated by supercomputers. In manyscenarios; however; it suffices to analyse a small subset of the data in detail. What scientistsanalysing the data consequently need are efficient means to explore the full dataset usingapproximate query results and to identify the subsets of interest. Once found; interestingareas can still be scrutinised using a precise; but also more time-consuming analysis. Datasynopses fit the bill as they provide fast (but approximate) query execution on massiveamounts of data. Generating data synopses after the data is stored; however; requires us …,ACM SIGMOD Record,2015,*
RUBIK: efficient threshold queries on massive time series,Eleni Tzirita Zacharatou; Farhan Tauheedz; Thomas Heinis; Anastasia Ailamaki,Abstract An increasing number of applications from finance; meteorology; science andothers are producing time series as output. The analysis of the vast amount of time series iskey to understand the phenomena studied; particularly in the simulation sciences; where theanalysis of time series resulting from simulation allows scientists to refine the modelsimulated. Existing approaches to query time series typically keep a compact representationin main memory; use it to answer queries approximately and then access the exact timeseries data on disk to validate the result. The more precise the in-memory representation;the fewer disk accesses are needed to validate the result. With the massive sizes of today'sdatasets; however; current in-memory representations oftentimes no longer fit into mainmemory. To make them fit; their precision has to be reduced considerably resulting in …,Proceedings of the 27th International Conference on Scientific and Statistical Database Management,2015,*
EDBT Vision Papers: EDBT Vision Track,Thomas Heinis; Farhan Tauheed; Anastasia Ailamaki; Michael Johnson; Jorge Perez; James Terwillinger; David Bronseke; Sebastian Bress; Max Heimel; Gunter Saake,T. Heinis; F. Tauheed; A. Ailamaki; M. Johnson; J. Perez; J. Terwillinger; D. Bronseke; S.Bress; M. Heimel; and G. Saake; “EDBT Vision Papers: EDBT Vision Track;” presented at the17th International Conference on Extending Database Technology; Εθνικό Κέντρο Τεκμηρίωσης(ΕΚΤ); 26-Mar-2014.,10442/13867,2014,*
Accelerating spatial range queries,Alexandros Stougiannis; Farhan Tauheed; Thomas Heinis; Anastasia Ailamaki,Abstract It is increasingly common for domain scientists to use computational tools to buildand simulate spatial models of the phenomena they are studying. The spatial models theybuild are more and more detailed as well as dense and are consequently difficult to managewith today's tools. A crucial problem when analyzing spatial models of increasing detail isthe scalable execution of range queries. State-of-the-art approaches like the R-Tree performsuboptimally on today's models and do not scale for more dense; future models. Theproblem is that the amount of overlap in the tree structure increases as a function of the levelof detail/density in the model. In this demonstration we showcase ZOOM; a new tool toefficiently execute spatial range queries on increasingly detailed (denser) models. ZOOM isbased on FLAT; a novel range query execution approach that effectively decouples the …,Proceedings of the 16th International Conference on Extending Database Technology,2013,*
Enabling Scientific Discovery Via Innovative Spatial Data Management,Thomas Heinis; Farhan Tauheed; Mirjana Pavlovic; Anastasia Ailamaki,Abstract Researchers in several scientific disciplines are struggling to cope with the massesof data resulting from either increasingly precise instruments or from simulation runs on evermore powerful supercomputers. Efficiently managing this deluge of data has become key tounderstand the phenomena they are studying. Scientists in the simulation sciences; forexample; build increasingly big and detailed models; as detailed as the hardware allows;but they lack the efficient technology to update and analyze them. In this paper we discusshow innovative data management techniques we have developed; enable scientists to buildand analyze bigger and more detailed spatial models and how these techniques ultimatelyaccelerate discovery in the simulation sciences. These include spatial join methods (inmemory and on disk); techniques for the efficient navigation in detailed meshes; an index …,Data Engineering Bulletin,2013,*
Workflow-based Services,Thomas Heinis,Abstract The way scientists work in traditional sciences has changed drastically in recentyears. Computer science is increasingly supporting them in performing and analyzing theirexperiments. Today; obtaining the raw data from instruments is merely the first step. Nolonger is the data analyzed on paper or with simple computational tools. Instead; massiveamounts of data obtained raw from instruments are processed in complex and long-runningcomputational pipelines. This trend of supporting traditional sciences with computationaltools has lead to a significant speedup in executing experiments and has also enabledexperiments which would not have been possible before. Scientists increasingly depend onadequate infrastructure to process experiment data using complex computational pipelinesand to manage the plethora of data used and produced by them. Such computational …,*,2009,*
Automatic Configuration of an Autonomic,Thomas Heinis; Cesare Pautasso,▪ Autonomic controllers are added to systems to … ▪ Configuring an autonomic system is verydifficult … ▪ Monitors performance ▪ Calculates new configuration ▪ Applies changes to configuration▪ Waits for changes to take effect ▪ Acts upon … ▪ Selection policy: Which nodes arereconfigured? ▪ Information policy: What parameters should be monitored? ▪ Optimizationpolicy: How should the system be reconfigured … ▪ QProcess + QEvent = QTask ▪ Control Error= (QProcess + QEvent ) / QTask … ▪ If QProcess + QEvent < QTask => more dispatchers needto be added and vice versa … ▪ Control error [-∞; ∞] is mapped to the number of required dispatchers[0; a]; with a the size of the cluster … ▪ Formally express growth in each of the queues … GrowthQEvent= #Dsps * #Msgs * Production Rate – #Navs * 1 * Consumption Rate Growth QTask =#Navs * #Msgs * Production Rate – #Dsps * 1 * Consumption Rate #Dsps = Size of …,*,2008,*
D10: Detailed Specification of SODIUM Runtime Environment,C Pautasso; T Heinis; G Alonso; M Pantazoglou; G Athanasopoulos; A Tsalgatidou,Executive Summary The purpose of this deliverable (D10) is to provide a detailedspecification of the SODIUM Runtime environment. The Runtime environment forms part ofthe overall SODIUM platform and is composed of the following components:• the SODIUMComposition Repository;• the USQL Query Engine and• the USCL Execution Engine.,*,2006,*
Modeling and Executing Heterogeneous Grid Workflows with JOpera for Eclipse,Cesare Pautasso; Thomas Heinis,Page 1. 5 October 2005 Modeling and Executing Heterogeneous Grid Workflows with JOperafor Eclipse Cesare Pautasso; Thomas Heinis Department of Computer Science; ETH Zurich;Switzerland {pautasso; heinis}@inf.ethz.ch – www.jopera.org © Cesare Pautasso |www.jopera.org Page 2. 2 5 October 2005 Cesare Pautasso | www.jopera.org Goal:Heterogeneous Grid Service Composition 1. Design a simple workflow language for rapidcomposition of Grid services 2. Build a user-friendly; efficient and autonomic system to supportit 3. Ensure their independence from the actual mechanisms and protocols involved (there arelots of standards and they change all the time) Page 3. 3 5 October 2005 Cesare Pautasso |www.jopera.org About JOpera for Eclipse 1. Modeling service composition as workflow •Graph-based; functional workflow modeling language (Visual syntax; XML under the hood) …,*,2005,*
D6: Specification of Unified Service Composition Language (USCL),Cesare Pautasso; Thomas Heinis; Gustavo Alonso,Executive Summary The purpose of this deliverable is to specify the SODIUM UnifiedService Composition Language (USCL). USCL documents are written using the XML syntax;in order to facilitate the development of the related SODIUM tools. The main feature of thelanguage consists of providing support for composing an open set of services; includingWeb; Grid and P2P services. The description of the compositions is kept separate from thedescription of the components; in order to enhance the reusability of both. Compositions aremodelled as processes; whose structure defines the data and control flow dependenciesbetween the service invocations; as well as the required exception handling behaviour.Components are modelled as services; an abstraction that makes the mechanism used toaccess the corresponding implementation transparent.,*,2005,*
Towards Batch-Processing on Cold Storage Devices,A Hadian; T Heinis,*,*,*,*
THERMAL-JOIN: A Scalable Spatial Join for Dynamic Workloads,T Heinis; A Ailamaki; F Tauheed,Simulations have become ubiquitous in many domains of science. Today scientists studynatural phenomena by first building massive three-dimensional spatial models and then bysimulating the models at discrete intervals of time to mimic the behavior of naturalphenomena. One frequently occurring challenge during simulations is the repeatedcomputation of spatial self-joins of the model at each simulation time step. The join isperformed to access a group of neighboring spatial objects (groups of particles; moleculesor cosmological objects) so that scientists can calculate the cumulative effect (likegravitational force) on an object. Computing a self-join even in memory; soon becomes aperformance bottleneck in simulation applications. The problem becomes even worse asscientists continue to improve the precision of simulations by increasing the number as …,*,*,*
Enhancing Facebook’s RocketSpeed Publish/Subscribe System,Dan Danaila; Thomas Heinis,Abstract The growth in the number of people that use social networks and the number offeatures that they offer requires a scalable and robust publish/subscribe system.RocketSpeed is a new publish/subscribe system developed by Facebook targeted to beused by multiple applications such as Facebook Messenger; GraphQL-cache; WhatsApp;etc.. RocketSpeed developers claim that the system can scale up to a trillion topics.However; the open source implementation lacks this ability as it uses an internallydeveloped log storage. One of the main contributions of the project is to overcome this majordrawback of the open-source implementation by extending RocketSpeed to use ApacheKafka for message storage. Thus; the project provides a working solution for real-worlddeployments. The report will further explain the approach taken to integrate Apache Kafka …,*,*,*
Data Management Challenges in the Simulation Sciences,Thomas Heinis; Farhan Tauheed; Anastasia Ailamaki,*,*,*,*
Speeding Up Range Queries For Brain Simulations,Farhan Tauheed; Laurynas Biveinis; Thomas Heinis; Felix Schürmann; Henry Markram; Anastasia Ailamaki,Abstract—Neuroscientists increasingly use computational tools to build and simulate modelsof the brain. The amounts of data involved in these simulations are immense and efcient lymanaging this data is key. One particular problem in analyzing this data is the scalableexecution of range queries on spatial models of the brain. Known indexing approaches donot perform well; even on today's small models containing only few million densely packedspatial elements. The problem of current approaches is that with the increasing level ofdetail in the models; the overlap in the tree structure also increases; ultimately slowing downquery execution. The neuroscientists' need to work with bigger and more importantly; withincreasingly detailed (denser) models; motivates us to develop a new indexing approach. Tothis end we developed FLAT; a scalable indexing approach for dense data sets. We …,*,*,*
Data Engineering,Thomas Heinis; Farhan Tauheed; Mirjana Pavlovic; Anastasia Ailamaki; Jacob Vanderplas; Emad Soroush; Simon Krughoff; Magdalena Balazinska; Michael Stonebraker; Jennie Duggan; Leilani Battle; Olga Papaemmanouil; Colin Talbert; Marian Talbert; Jeff Morisette; David Koop; Fernando Chirigati; Matthias Troyer; Dennis Shasha; Juliana Freire,Abstract Researchers in several scientific disciplines are struggling to cope with the massesof data resulting from either increasingly precise instruments or from simulation runs on evermore powerful supercomputers. Efficiently managing this deluge of data has become key tounderstand the phenomena they are studying. Scientists in the simulation sciences; forexample; build increasingly big and detailed models; as detailed as the hardware allows;but they lack the efficient technology to update and analyze them. In this paper we discusshow innovative data management techniques we have developed; enable scientists to buildand analyze bigger and more detailed spatial models and how these techniques ultimatelyaccelerate discovery in the simulation sciences. These include spatial join methods (inmemory and on disk); techniques for the efficient navigation in detailed meshes; an index …,*,*,*
