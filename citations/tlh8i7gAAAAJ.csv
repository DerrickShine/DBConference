A volumetric method for building complex models from range images,Brian Curless; Marc Levoy,Abstract A number of techniques have been developed for reconstructing surfaces byintegrating groups of aligned range images. A desirable set of properties for such algorithmsincludes: incremental updating; representation of directional uncertainty; the ability to fillgaps in the reconstruction; and robustness in the presence of outliers. Prior algorithmspossess subsets of these properties. In this paper; we present a volumetric method forintegrating range images that possesses all of these properties. Our volumetricrepresentation consists of a cumulative weighted signed distance function. Working with onerange image at a time; we first scan-convert it to a distance function; then combine this withthe data already acquired using a simple additive scheme. To achieve space efficiency; weemploy a run-length encoding of the volume. To achieve time efficiency; we resample the …,Proceedings of the 23rd annual conference on Computer graphics and interactive techniques,1996,2608
The digital Michelangelo project: 3D scanning of large statues,Marc Levoy; Kari Pulli; Brian Curless; Szymon Rusinkiewicz; David Koller; Lucas Pereira; Matt Ginzton; Sean Anderson; James Davis; Jeremy Ginsberg; Jonathan Shade; Duane Fulk,Abstract We describe a hardware and software system for digitizing the shape and color oflarge fragile objects under non-laboratory conditions. Our system employs lasertriangulation rangefinders; laser time-of-flight rangefinders; digital still cameras; and a suiteof software for acquiring; aligning; merging; and viewing scanned data. As a demonstrationof this system; we digitized 10 statues by Michelangelo; including the well-known figure ofDavid; two building interiors; and all 1;163 extant fragments of the Forma Urbis Romae; agiant marble map of ancient Rome. Our largest single dataset is of the David-2 billionpolygons and 7;000 color images. In this paper; we discuss the challenges we faced inbuilding this system; the solutions we employed; and the lessons we learned. We focus inparticular on the unusual design of our laser triangulation scanner and on the algorithms …,Proceedings of the 27th annual conference on Computer graphics and interactive techniques,2000,2196
A comparison and evaluation of multi-view stereo reconstruction algorithms,Steven M Seitz; Brian Curless; James Diebel; Daniel Scharstein; Richard Szeliski,This paper presents a quantitative comparison of several multi-view stereo reconstructionalgorithms. Until now; the lack of suitable calibrated multi-view image datasets with knownground truth (3D shape models) has prevented such direct comparisons. In this paper; wefirst survey multi-view stereo algorithms and compare them qualitatively using a taxonomythat differentiates their key properties. We then describe our process for acquiring andcalibrating multiview image datasets with high-accuracy ground truth and introduce ourevaluation methodology. Finally; we present the results of our quantitative comparison ofstate-of-the-art multi-view stereo reconstruction algorithms on six benchmark datasets. Thedatasets; evaluation details; and instructions for submitting new models are available onlineat http://vision. middlebury. edu/mview.,Computer vision and pattern recognition; 2006 IEEE Computer Society Conference on,2006,1971
Image analogies,Aaron Hertzmann; Charles E Jacobs; Nuria Oliver; Brian Curless; David H Salesin,Abstract This paper describes a new framework for processing images by example; called“image analogies.” The framework involves two stages: a design phase; in which a pair ofimages; with one image purported to be a “filtered” version of the other; is presented as“training data”; and an application phase; in which the learned filter is applied to some newtarget image in order to create an “analogous” filtered result. Image analogies are based ona simple multi-scale autoregression; inspired primarily by recent results in texture synthesis.By choosing different types of source image pairs as input; the framework supports a widevariety of “image filter” effects; including traditional image filters; such as blurring orembossing; improved texture synthesis; in which some textures are synthesized with higherquality than by previous approaches; super-resolution; in which a higher-resolution …,Proceedings of the 28th annual conference on Computer graphics and interactive techniques,2001,1485
Building rome in a day,Sameer Agarwal; Yasutaka Furukawa; Noah Snavely; Ian Simon; Brian Curless; Steven M Seitz; Richard Szeliski,Abstract We present a system that can reconstruct 3D geometry from large; unorganizedcollections of photographs such as those found by searching for a given city (eg; Rome) onInternet photo-sharing sites. Our system is built on a set of new; distributed computer visionalgorithms for image matching and 3D reconstruction; designed to maximize parallelism ateach stage of the pipeline and to scale gracefully with both the size of the problem and theamount of available computation. Our experimental results demonstrate that it is nowpossible to reconstruct city-scale image collections with more than a hundred thousandimages in less than a day.,Communications of the ACM,2011,1430
The space of human body shapes: reconstruction and parameterization from range scans,Brett Allen; Brian Curless; Zoran Popović,Abstract We develop a novel method for fitting high-resolution template meshes to detailedhuman body range scans with sparse 3D markers. We formulate an optimization problem inwhich the degrees of freedom are an affine transformation at each template vertex. Theobjective function is a weighted combination of three measures: proximity of transformedvertices to the range data; similarity between neighboring transformations; and proximity ofsparse markers at corresponding locations on the template and target surface. We solve forthe transformations with a non-linear optimizer; run at two resolutions to speed convergence.We demonstrate reconstruction and consistent parameterization of 250 human body models.With this parameterized set; we explore a variety of applications for human body modeling;including: morphing; texture transfer; statistical analysis of shape; model fitting from …,ACM transactions on graphics (TOG),2003,1064
Interactive digital photomontage,Aseem Agarwala; Mira Dontcheva; Maneesh Agrawala; Steven Drucker; Alex Colburn; Brian Curless; David Salesin; Michael Cohen,Abstract We describe an interactive; computer-assisted framework for combining parts of aset of photographs into a single composite picture; a process we call" digital photomontage."Our framework makes use of two techniques primarily: graph-cut optimization; to choosegood seams within the constituent images so that they can be combined as seamlessly aspossible; and gradient-domain fusion; a process based on Poisson equations; to furtherreduce any remaining visible artifacts in the composite. Also central to the framework is asuite of interactive tools that allow the user to specify a variety of high-level image objectives;either globally across the image; or locally through a painting-style interface. Imageobjectives are applied independently at each pixel location and generally involve a functionof the pixel values (such as" maximum contrast") drawn from that same location in the set …,ACM Transactions on Graphics (ToG),2004,1047
A bayesian approach to digital matting,Yung-Yu Chuang; Brian Curless; David H Salesin; Richard Szeliski,This paper proposes a new Bayesian framework for solving the matting problem; ieextracting a foreground element from a background image by estimating an opacity for eachpixel of the foreground element. Our approach models both the foreground and backgroundcolor distributions with spatially-varying sets of Gaussians; and assumes a fractionalblending of the foreground and background colors to produce the final output. It then uses amaximum-likelihood criterion to estimate the optimal opacity; foreground and backgroundsimultaneously. In addition to providing a principled approach to the matting problem; ouralgorithm effectively handles objects with intricate boundaries; such as hair strands and fur;and provides an improvement over existing techniques for these difficult cases.,Computer Vision and Pattern Recognition; 2001. CVPR 2001. Proceedings of the 2001 IEEE Computer Society Conference on,2001,924
Rapid shape acquisition using color structured light and multi-pass dynamic programming,Li Zhang; Brian Curless; Steven M Seitz,This paper presents a color structured light technique for recovering object shape from oneor more images. The technique works by projecting a pattern of stripes of alternating colorsand matching the projected color transitions with observed edges in the image. Thecorrespondence problem is solved using a novel; multi-pass dynamic programmingalgorithm that eliminates global smoothness assumptions and strict ordering constraintspresent in previous formulations. The resulting approach is suitable for generating both high-speed scans of moving objects when projecting a single stripe pattern and high-resolutionscans of static scenes using a short sequence of time-shifted stripe patterns. In the lattercase; space-time analysis is used at each sensor pixel to obtain inter-frame depthlocalization. Results are demonstrated for a variety of complex scenes.,3D Data Processing Visualization and Transmission; 2002. Proceedings. First International Symposium on,2002,609
Towards internet-scale multi-view stereo,Yasutaka Furukawa; Brian Curless; Steven M Seitz; Richard Szeliski,This paper introduces an approach for enabling existing multi-view stereo methods tooperate on extremely large unstructured photo collections. The main idea is to decomposethe collection into a set of overlapping sets of photos that can be processed in parallel; andto merge the resulting reconstructions. This overlapping clustering problem is formulated asa constrained optimization and solved iteratively. The merging algorithm; designed to beparallel and out-of-core; incorporates robust filtering steps to eliminate low-qualityreconstructions and enforce global visibility constraints. The approach has been tested onseveral large datasets downloaded from Flickr. com; including one with over ten thousandimages; yielding a 3D reconstruction with nearly thirty million points.,Computer Vision and Pattern Recognition (CVPR); 2010 IEEE Conference on,2010,608
Spacetime faces: High-resolution capture for~ modeling and animation,Li Zhang; Noah Snavely; Brian Curless; Steven M Seitz,Creating face models that look and move realistically is an important problem in computergraphics. 1 It is also one of the most difficult; as even the most minute changes in facialexpression can reveal complex moods and emotions. Yet; the presence of very convincingsynthetic characters in recent films makes a strong case that these difficulties can beovercome with the aid of highly skilled animators. Because of the sheer amount of workrequired to create such models; however; there is a clear need for more automatedtechniques. Our objective is to create models that accurately reflect the shape andtimevarying behavior of a real person's face from videos. For those models; we seek real-time; intuitive controls to edit expressions and create animations. For instance; dragging thecorner of the mouth up should result in a realistic expression; such as a smiling face …,*,2008,600
Multi-view stereo for community photo collections,Michael Goesele; Noah Snavely; Brian Curless; Hugues Hoppe; Steven M Seitz,We present a multi-view stereo algorithm that addresses the extreme changes in lighting;scale; clutter; and other effects in large online community photo collections. Our idea is tointelligently choose images to match; both at a per-view and per-pixel level. We show thatsuch adaptive view selection enables robust performance even with dramatic appearancevariability. The stereo matching technique takes as input sparse 3D points reconstructedfrom structure-from-motion methods and iteratively grows surfaces from these points.Optimizing for surface normals within a photoconsistency measure significantly improves thematching results. While the focus of our approach is to estimate high-quality depth maps; wealso show examples of merging the resulting depth maps into compelling scenereconstructions. We demonstrate our algorithm on standard multi-view stereo datasets …,Computer Vision; 2007. ICCV 2007. IEEE 11th International Conference on,2007,564
Multicore bundle adjustment,Changchang Wu; Sameer Agarwal; Brian Curless; Steven M Seitz,We present the design and implementation of new inexact Newton type Bundle Adjustmentalgorithms that exploit hardware parallelism for efficiently solving large scale 3D scenereconstruction problems. We explore the use of multicore CPU as well as multicore GPUs forthis purpose. We show that overcoming the severe memory and bandwidth limitations ofcurrent generation GPUs not only leads to more space efficient algorithms; but also tosurprising savings in runtime. Our CPU based system is up to ten times and our GPU basedsystem is up to thirty times faster than the current state of the art methods; while maintainingcomparable convergence behavior. The code and additional results are available athttp://grail. cs. washington. edu/projects/mcba.,Computer Vision and Pattern Recognition (CVPR); 2011 IEEE Conference on,2011,561
Surface light fields for 3D photography,Daniel N Wood; Daniel I Azuma; Ken Aldinger; Brian Curless; Tom Duchamp; David H Salesin; Werner Stuetzle,Abstract A surface light field is a function that assigns a color to each ray originating on asurface. Surface light fields are well suited to constructing virtual images of shiny objectsunder complex lighting conditions. This paper presents a framework for construction;compression; interactive rendering; and rudimentary editing of surface light fields of realobjects. Generalization of vector quantization and principal component analysis are used toconstruct a compressed representation of an object's surface light field from photographsand range scans. A new rendering algorithm achieves interactive rendering of images fromthe compressed representation; incorporating view-dependent geometric level-of-detailcontrol. The surface light field representation can also be directly edited to yield plausiblesurface light fields for small changes in surface geometry and reflectance properties.,Proceedings of the 27th annual conference on Computer graphics and interactive techniques,2000,461
Video matting of complex scenes,Yung-Yu Chuang; Aseem Agarwala; Brian Curless; David H Salesin; Richard Szeliski,Abstract This paper describes a new framework for video matting; the process of pulling ahigh-quality alpha matte and foreground from a video sequence. The framework builds upontechniques in natural image matting; optical flow computation; and background estimation.User interaction is comprised of garbage matte specification if background estimation isneeded; and hand-drawn keyframe segmentations into" foreground;"" background" and"unknown". The segmentations; called trimaps; are interpolated across the video volumeusing forward and backward optical flow. Competing flow estimates are combined based oninformation about where flow is likely to be accurate. A Bayesian matting technique uses theflowed trimaps to yield high-quality mattes of moving foreground elements with complexboundaries filmed by a moving camera. A novel technique for smoke matte extraction is …,ACM Transactions on Graphics (ToG),2002,388
Spacetime stereo: Shape recovery for dynamic scenes,Li Zhang; Brian Curless; Steven M Seitz,This paper extends the traditional binocular stereo problem into the spacetime domain; inwhich a pair of video streams is matched simultaneously instead of matching pairs of imagesframe by frame. Almost any existing stereo algorithm may be extended in this manner simplyby replacing the image matching term with a spacetime term. By utilizing both spatial andtemporal appearance variation; this modification reduces ambiguity and increases accuracy.Three major applications for spacetime stereo are proposed in this paper. First; spacetimestereo serves as a general framework for structured light scanning and generates highquality depth maps for static scenes. Second; spacetime stereo is effective for a class ofnatural scenes; such as waving trees and flowing water; which have repetitive textures andchaotic behaviors and are challenging for existing stereo algorithms. Third; the approach …,Computer Vision and Pattern Recognition; 2003. Proceedings. 2003 IEEE Computer Society Conference on,2003,370
Articulated body deformation from range scan data,Brett Allen; Brian Curless; Zoran Popović,Abstract This paper presents an example-based method for calculating skeleton-driven bodydeformations. Our example data consists of range scans of a human body in a variety ofposes. Using markers captured during range scanning; we construct a kinematic skeletonand identify the pose of each scan. We then construct a mutually consistent parameterizationof all the scans using a posable subdivision surface template. The detail deformations arerepresented as displacements from this surface; and holes are filled smoothly within thedisplacement maps. Finally; we combine the range scans using k-nearest neighborinterpolation in pose space. We demonstrate results for a human upper body withcontrollable pose; kinematics; and underlying surface shape.,ACM Transactions on Graphics (TOG),2002,364
Shape and spatially-varying brdfs from photometric stereo,Dan B Goldman; Brian Curless; Aaron Hertzmann; Steven M Seitz,This paper describes a photometric stereo method designed for surfaces with spatially-varying BRDFs; including surfaces with both varying diffuse and specular properties. Ouroptimization-based method builds on the observation that most objects are composed of asmall number of fundamental materials by constraining each pixel to be representable by acombination of at most two such materials. This approach recovers not only the shape butalso material BRDFs and weight maps; yielding accurate rerenderings under novel lightingconditions for a wide variety of objects. We demonstrate examples of interactive editingoperations made possible by our approach.,IEEE Transactions on Pattern Analysis and Machine Intelligence,2010,326
Multi-view stereo revisited,Michael Goesele; Brian Curless; Steven M Seitz,We present an extremely simple yet robust multi-view stereo algorithm and analyze itsproperties. The algorithm first computes individual depth maps using a window-based votingapproach that returns only good matches. The depth maps are then merged into a singlemesh using a straightforward volumetric approach. We show results for several datasets;showing accuracy comparable to the best of the current state of the art techniques andrivaling more complex algorithms.,Computer Vision and Pattern Recognition; 2006 IEEE Computer Society Conference on,2006,322
Interactive skeleton-driven dynamic deformations,Steve Capell; Seth Green; Brian Curless; Tom Duchamp; Zoran Popović,Abstract This paper presents a framework for the skeleton-driven animation of elasticallydeformable characters. A character is embedded in a coarse volumetric control lattice; whichprovides the structure needed to apply the finite element method. To incorporate skeletalcontrols; we introduce line constraints along the bones of simple skeletons. The bones aremade to coincide with edges of the control lattice; which enables us to apply the constraintsefficiently using algebraic methods. To accelerate computation; we associate regions of thevolumetric mesh with particular bones and perform locally linearized simulations; which areblended at each time step. We define a hierarchical basis on the control lattice; so fordetailed interactions the simulation can adapt the level of detail. We demonstrate the abilityto animate complex models using simple skeletons and coarse volumetric meshes in a …,ACM Transactions on Graphics (TOG),2002,313
Manhattan-world stereo,Yasutaka Furukawa; Brian Curless; Steven M Seitz; Richard Szeliski,Multi-view stereo (MVS) algorithms now produce reconstructions that rival laser rangescanner accuracy. However; stereo algorithms require textured surfaces; and therefore workpoorly for many architectural scenes (eg; building interiors with textureless; painted walls).This paper presents a novel MVS approach to overcome these limitations for ManhattanWorld scenes; ie; scenes that consists of piece-wise planar surfaces with dominantdirections. Given a set of calibrated photographs; we first reconstruct textured regions usingan existing MVS algorithm; then extract dominant plane directions; generate planehypotheses; and recover per-view depth maps using Markov random fields. We have testedour algorithm on several datasets ranging from office interiors to outdoor buildings; anddemonstrate results that outperform the current state of the art for such texture-poor …,Computer Vision and Pattern Recognition; 2009. CVPR 2009. IEEE Conference on,2009,305
Spatio-angular resolution tradeoffs in integral photography.,Todor Georgiev; Ke Colin Zheng; Brian Curless; David Salesin; Shree K Nayar; Chintan Intwala,Abstract An integral camera samples the 4D light field of a scene within a single photograph.This paper explores the fundamental tradeoff between spatial resolution and angularresolution that is inherent to integral photography. Based on our analysis we divide previousintegral camera designs into two classes depending on how the 4D light field is distributed(multiplexed) over the 2D sensor. Our optical treatment is mathematically rigorous andextensible to the broader area of light field research. We argue that for many real-worldscenes it is beneficial to sacrifice angular resolution for higher spatial resolution. Themissing angular resolution is then interpolated using techniques from computer vision. Wehave developed a prototype integral camera that uses a system of lenses and prisms as anexternal attachment to a conventional camera. We have used this prototype to capture the …,Rendering Techniques,2006,304
Reconstructing building interiors from images,Yasutaka Furukawa; Brian Curless; Steven M Seitz; Richard Szeliski,This paper proposes a fully automated 3D reconstruction and visualization system forarchitectural scenes (interiors and exteriors). The reconstruction of indoor environments fromphotographs is particularly challenging due to texture-poor planar surfaces such asuniformly-painted walls. Our system first uses structure-from-motion; multi-view stereo; and astereo algorithm specifically designed for Manhattan-world scenes (scenes consistingpredominantly of piece-wise planar surfaces with dominant directions) to calibrate thecameras and to recover initial 3D geometry in the form of oriented points and depth maps.Next; the initial geometry is fused into a 3D model with a novel depth-map integrationalgorithm that; again; makes use of Manhattan-world assumptions and produces simplified3D models. Finally; the system enables the exploration of reconstructed environments …,Computer Vision; 2009 IEEE 12th International Conference on,2009,290
Better optical triangulation through spacetime analysis,Brian Curless; Marc Levoy,The standard methods for extracting range data from optical triangulation scanners areaccurate only for planar objects of uniform reflectance illuminated by an incoherent source.Using these methods; curved surfaces; discontinuous surfaces; and surfaces of varyingreflectance cause systematic distortions of the range data. Coherent light sources such aslasers introduce speckle artifacts that further degrade the data. We present a new rangingmethod based on analyzing the time evolution of the structured light reflections. Using ourspacetime analysis; we can correct for each of these artifacts; thereby attaining significantlyhigher accuracy using existing technology. We present results that demonstrate the validityof our method using a commercial laser stripe triangulation scanner.,Computer Vision; 1995. Proceedings.; Fifth International Conference on,1995,276
Environment matting and compositing,Douglas E Zongker; Dawn M Werner; Brian Curless; David H Salesin,Abstract This paper introduces a new process; environment matting; which captures not justa foreground object and its traditional opacity matte from a real-world scene; but also adescription of how that object refracts and reflects light; which we call an environment matte.The foreground object can then be placed in a new environment; using environmentcompositing; where it will refract and reflect light from that scene. Objects captured in thisway exhibit not only specular but glossy and translucent effects; as well as selectiveattenuation and scattering of light according to wavelength. Moreover; the environmentcompositing process; which can be performed largely with texture mapping operations; isfast enough to run at interactive speeds on a desktop PC. We compare our results to photosof the same objects in real scenes. Applications of this work include the relighting of …,Proceedings of the 26th annual conference on Computer graphics and interactive techniques,1999,249
Single image deblurring using motion density functions,Ankit Gupta; Neel Joshi; C Lawrence Zitnick; Michael Cohen; Brian Curless,Abstract We present a novel single image deblurring method to estimate spatially non-uniform blur that results from camera shake. We use existing spatially invariantdeconvolution methods in a local and robust way to compute initial estimates of the latentimage. The camera motion is represented as a Motion Density Function (MDF) whichrecords the fraction of time spent in each discretized portion of the space of all possiblecamera poses. Spatially varying blur kernels are derived directly from the MDF. We showthat 6D camera motion is well approximated by 3 degrees of motion (in-plane translationand rotation) and analyze the scope of this approximation. We present results on bothsynthetic and captured data. Our system out-performs current approaches which make theassumption of spatially invariant blur.,European Conference on Computer Vision,2010,247
Panoramic video textures,Aseem Agarwala; Ke Colin Zheng; Chris Pal; Maneesh Agrawala; Michael Cohen; Brian Curless; David Salesin; Richard Szeliski,Abstract This paper describes a mostly automatic method for taking the output of a singlepanning video camera and creating a panoramic video texture (PVT): a video that has beenstitched into a single; wide field of view and that appears to play continuously andindefinitely. The key problem in creating a PVT is that although only a portion of the scenehas been imaged at any given time; the output must simultaneously portray motionthroughout the scene. Like previous work in video textures; our method employs min-cutoptimization to select fragments of video that can be stitched together both spatially andtemporally. However; it differs from earlier work in that the optimization must take place overa much larger set of data. Thus; to create PVTs; we introduce a dynamic programming step;followed by a novel hierarchical min-cut optimization algorithm. We also use gradient …,ACM Transactions on Graphics (TOG),2005,209
Gradientshop: A gradient-domain optimization framework for image and video filtering,Pravin Bhat; C Lawrence Zitnick; Michael Cohen; Brian Curless,Abstract We present an optimization framework for exploring gradient-domain solutions forimage and video processing. The proposed framework unifies many of the key ideas in thegradient-domain literature under a single optimization formulation. Our hope is that thisgeneralized framework will allow the reader to quickly gain a general understanding of thefield and contribute new ideas of their own. We propose a novel metric for measuring localgradient saliency that identifies salient gradients that give rise to long; coherent edges; evenwhen the individual gradients are faint. We present a general weighting scheme for gradientconstraints that improves the visual appearance of results. We also provide a solution forapplying gradient-domain filters to videos and video streams in a coherent manner.,ACM Transactions on Graphics (TOG),2010,195
Schematic storyboarding for video visualization and editing,Dan B Goldman; Brian Curless; David Salesin; Steven M Seitz,Abstract We present a method for visualizing short video clips in a single static image; usingthe visual language of storyboards. These schematic storyboards are composed frommultiple input frames and annotated using outlines; arrows; and text describing the motion inthe scene. The principal advantage of this storyboard representation over standardrepresentations of video--generally either a static thumbnail image or a playback of thevideo clip in its entirety--is that it requires only a moment to observe and comprehend but atthe same time retains much of the detail of the source video. Our system renders aschematic storyboard layout based on a small amount of user interaction. We alsodemonstrate an interaction technique to scrub through time using the natural spatialdimensions of the storyboard. Potential applications include video editing; surveillance …,ACM Transactions on Graphics (TOG),2006,183
Shape and motion under varying illumination: Unifying structure from motion; photometric stereo; and multiview stereo,Li Zhang,We present an algorithm for computing optical flow; shape; motion; lighting; and albedo froman image sequence of a rigidly-moving Lambertian object under distant illumination. Theproblem is formulated in a manner that subsumes structure from motion; multiview stereo;and photometric stereo as special cases. The algorithm utilizes both spatial and temporalintensity variation as cues: the former constrains flow and the latter constrains surfaceorientation; combining both cues enables dense reconstruction of both textured andtextureless surfaces. The algorithm works by iteratively estimating affine camera parameters;illumination; shape; and albedo in an alternating fashion. Results are demonstrated onvideos of hand-held objects moving in front of a fixed light and camera.,Computer Vision; 2003. Proceedings. Ninth IEEE International Conference on,2003,177
A multiresolution framework for dynamic deformations,Steve Capell; Seth Green; Brian Curless; Tom Duchamp; Zoran Popović,Abstract We present a novel framework for the dynamic simulation of elastic deformablesolids. Our approach combines classical finite element methodology with a multiresolutionsubdivision framework in order to produce fast; easy to use; and realistic animations. Werepresent deformations using a hierarchical basis constructed using volumetric subdivision.The subdivision framework provides topological flexibility and the hierarchical basis allowsthe simulation to add detail where it is needed. Since volumetric parameterization is difficultfor complex models; we support the embedding of objects in domains that are easier toparameterize.,Proceedings of the 2002 ACM SIGGRAPH/Eurographics symposium on Computer animation,2002,161
New methods for surface reconstruction from range images,Brian Curless,Abstract The digitization and reconstruction of 3D shapes has numerous applications inareas that include manufacturing; virtual simulation; science; medicine; and consumermarketing. In this thesis; we address the problem of acquiring accurate range data throughoptical triangulation; and we present a method for reconstructing surfaces from sets of dataknown as range images. The standard methods for extracting range data from opticaltriangulation scanners are accurate only for planar objects of uniform reflectance. Usingthese methods; curved surfaces; discontinuous surfaces; and surfaces of varying reflectancecause systematic distortions of the range data. We present a new ranging method based onanalysis of the time evolution of the structured light reflections. Using this spacetimeanalysis; we can correct for each of these artifacts; thereby attaining significantly higher …,*,1997,159
Curve Analogies.,Aaron Hertzmann; Nuria Oliver; Brian Curless; Steven M Seitz,Abstract This paper describes a method for learning statistical models of 2D curves; andshows how these models can be used to design line art rendering styles by example. A usercan create a new style by providing an example of the style; eg by sketching a curve in adrawing program. Our method can then synthesize random new curves in this style; andmodify existing curves to have the same style as the example. This method can incorporateposition constraints on the resulting curves.,Rendering Techniques,2002,157
Environment matting extensions: Towards higher accuracy and real-time capture,Yung-Yu Chuang; Douglas E Zongker; Joel Hindorff; Brian Curless; David H Salesin; Richard Szeliski,Abstract Environment matting is a generalization of traditional bluescreen matting. Byphotographing an object in front of a sequence of structured light backdrops; a set ofapproximate light-transport paths through the object can be computed. The originalenvironment matting research chose a middle ground—using a moderate number ofphotographs to produce results that were reasonably accurate for many objects. In this work;we extend the technique in two opposite directions: recovering a more accurate model at theexpense of using additional structured light backdrops; and obtaining a simplified matteusing just a single backdrop. The first extension allows for the capture of complex and subtleinteractions of light with objects; while the second allows for video capture of colorlessobjects in motion.,Proceedings of the 27th annual conference on Computer graphics and interactive techniques,2000,153
From range scans to 3D models,Brian Curless,Abstract Each year; we see a growing number of 3D range scanning products on theSIGGRAPH exhibition floor. You may find yourself asking" how do these technologieswork?" and" how can I make use of the shape data they produce?" In this article; I willdescribe a few of the more common range scanning technologies. Then; I will step through apipeline that takes the range data into a single geometric model and will conclude with adiscussion of the future of range scanning.,ACM SIGGRAPH Computer Graphics,1999,143
Animating pictures with stochastic motion textures,Yung-Yu Chuang; Dan B Goldman; Ke Colin Zheng; Brian Curless; David H Salesin; Richard Szeliski,Abstract In this paper; we explore the problem of enhancing still pictures with subtlyanimated motions. We limit our domain to scenes containing passive elements that respondto natural forces in some fashion. We use a semi-automatic approach; in which a humanuser segments the scene into a series of layers to be individually animated. Then; a"stochastic motion texture" is automatically synthesized using a spectral method; ie; theinverse Fourier transform of a filtered noise spectrum. The motion texture is a time-varying2D displacement map; which is applied to each layer. The resulting warped layers are thenrecomposited to form the animated frames. The result is a looping video texture created froma single still image; which has the advantages of being more controllable and of generallyhigher image quality and resolution than a video texture created from a video source. We …,ACM Transactions on Graphics (TOG),2005,136
Automated generation of interactive 3D exploded view diagrams,Wilmot Li; Maneesh Agrawala; Brian Curless; David Salesin,Abstract We present a system for creating and viewing interactive exploded views ofcomplex 3D models. In our approach; a 3D input model is organized into an explosion graphthat encodes how parts explode with respect to each other. We present an automatic methodfor computing explosion graphs that takes into account part hierarchies in the input modelsand handles common classes of interlocking parts. Our system also includes an interfacethat allows users to interactively explore our exploded views using both direct controls andhigher-level interaction modes.,ACM Transactions on Graphics (TOG),2008,118
Using photographs to enhance videos of a static scene,Pravin Bhat; C Lawrence Zitnick; Noah Snavely; Aseem Agarwala; Maneesh Agrawala; Michael Cohen; Brian Curless; Sing Bing Kang,Abstract We present a framework for automatically enhancing videos of a static scene usinga few photographs of the same scene. For example; our system can transfer photographicqualities such as high resolution; high dynamic range and better lighting from thephotographs to the video. Additionally; the user can quickly modify the video by editing onlya few still images of the scene. Finally; our system allows a user to remove unwanted objectsand camera shake from the video. These capabilities are enabled by two technicalcontributions presented in this paper. First; we make several improvements to a state-of-the-art multiview stereo algorithm in order to compute view-dependent depths using video;photographs; and structure-from-motion data. Second; we present a novel image-basedrendering algorithm that can re-render the input video using the appearance of the …,Proceedings of the 18th Eurographics conference on Rendering Techniques,2007,118
Video object annotation; navigation; and composition,Dan B Goldman; Chris Gonterman; Brian Curless; David Salesin; Steven M Seitz,Abstract We explore the use of tracked 2D object motion to enable novel approaches tointeracting with video. These include moving annotations; video navigation by directmanipulation of objects; and creating an image composite from multiple video frames.Features in the video are automatically tracked and grouped in an off-line preprocess thatenables later interactive manipulation. Examples of annotations include speech and thoughtballoons; video graffiti; path arrows; video hyperlinks; and schematic storyboards. We alsodemonstrate a direct-manipulation interface for random frame access using spatialconstraints; and a drag-and-drop interface for assembling still images from videos. Takentogether; our tools can be employed in a variety of applications including film and videoediting; visual tagging; and authoring rich media such as hyperlinked video.,Proceedings of the 21st annual ACM symposium on User interface software and technology,2008,117
Interactive cutaway illustrations of complex 3D models,Wilmot Li; Lincoln Ritter; Maneesh Agrawala; Brian Curless; David Salesin,Abstract We present a system for authoring and viewing interactive cutaway illustrations ofcomplex 3D models using conventions of traditional scientific and technical illustration. Ourapproach is based on the two key ideas that 1) cuts should respect the geometry of the partsbeing cut; and 2) cutaway illustrations should support interactive exploration. In ourapproach; an author instruments a 3D model with auxiliary parameters; which we call"rigging;" that define how cutaways of that structure are formed. We provide an authoringinterface that automates most of the rigging process. We also provide a viewing interfacethat allows viewers to explore rigged models using high-level interactions. In particular; theviewer can just select a set of target structures; and the system will automatically generate acutaway illustration that exposes those parts. We have tested our system on a variety of …,ACM Transactions on Graphics (TOG),2007,109
Fourier analysis of the 2D screened Poisson equation for gradient domain problems,Pravin Bhat; Brian Curless; Michael Cohen; C Lawrence Zitnick,Abstract We analyze the problem of reconstructing a 2D function that approximates a set ofdesired gradients and a data term. The combined data and gradient terms enableoperations like modifying the gradients of an image while staying close to the original image.Starting with a variational formulation; we arrive at the “screened Poisson equation” knownin physics. Analysis of this equation in the Fourier domain leads to a direct; exact; andefficient solution to the problem. Further analysis reveals the structure of the spatial filtersthat solve the 2D screened Poisson equation and shows gradient scaling to be a well-defined sharpen filter that generalizes Laplacian sharpening; which itself can be mapped togradient domain filtering. Results using a DCT-based screened Poisson solver aredemonstrated on several applications including image blending for panoramas; image …,European Conference on Computer Vision,2008,100
Shadow matting and compositing,Yung-Yu Chuang; Dan B Goldman; Brian Curless; David H Salesin; Richard Szeliski,Abstract In this paper; we describe a method for extracting shadows from one natural sceneand inserting them into another. We develop physically-based shadow matting andcompositing equations and use these to pull a shadow matte from a source scene in whichthe shadow is cast onto an arbitrary planar background. We then acquire the photometricand geometric properties of the target scene by sweeping oriented linear shadows (cast by astraight object) across it. From these shadow scans; we can construct a shadowdisplacement map without requiring camera or light source calibration. This map can thenbe used to deform the original shadow matte. We demonstrate our approach for both indoorscenes with controlled lighting and for outdoor scenes using natural lighting.,ACM Transactions on Graphics (TOG),2003,100
Autonomous generation of complete 3D object models using next best view manipulation planning,Michael Krainin; Brian Curless; Dieter Fox,Recognizing and manipulating objects is an important task for mobile robots performinguseful services in everyday environments. In this paper; we develop a system that enables arobot to grasp an object and to move it in front of its depth camera so as to build a 3D surfacemodel of the object. We derive an information gain based variant of the next best viewalgorithm in order to determine how the manipulator should move the object in front of thecamera. By considering occlusions caused by the robot manipulator; our technique alsodetermines when and how the robot should re-grasp the object in order to build a completemodel.,Robotics and Automation (ICRA); 2011 IEEE International Conference on,2011,93
Reconstructing rome,Sameer Agarwal; Yasutaka Furukawa; Noah Snavely; Brian Curless; Steven M Seitz; Richard Szeliski,Community photo collections like Flickr offer a rich; ever-growing record of the world aroundus. New computer vision techniques can use photographs from these collections to rapidly builddetailed 3D models … Sameer Agarwal and Yasutaka Furukawa; Google Noah Snavely; CornellUniversity Brian Curless; University of Washington Steven M. Seitz; Google and University ofWashington Richard Szeliski; Microsoft Research … Creating accurate 3D city models is a problemwith broad applications. In the government sector; city models are vital for urban planning andvisualization. They're equally important in a wide range of academic disciplines; includinghistory; archaeology; geography; and computer graphics research. And digital city models arecentral to popular consumer mapping and visualization applications such as Google Earth andBing Maps as well as GPS- enabled navigation systems. In the near future; these models …,Computer,2010,93
3D puppetry: a kinect-based interface for 3D animation.,Robert Held; Ankit Gupta; Brian Curless; Maneesh Agrawala,ABSTRACT We present a system for producing 3D animations using physical objects (ie;puppets) as input. Puppeteers can load 3D models of familiar rigid objects; including toys;into our system and use them as puppets for an animation. During a performance; thepuppeteer physically manipulates these puppets in front of a Kinect depth sensor. Oursystem uses a combination of image-feature matching and 3D shape matching to identifyand track the physical puppets. It then renders the corresponding 3D models into a virtualset. Our system operates in real time so that the puppeteer can immediately see the resultinganimation and make adjustments on the fly. It also provides 6D virtual camera and lightingcontrols; which the puppeteer can adjust before; during; or after a performance. Finally oursystem supports layered animations to help puppeteers produce animations in which …,UIST,2012,89
Physically based rigging for deformable characters,Steve Capell; Matthew Burkhart; Brian Curless; Tom Duchamp; Zoran Popović,Abstract In this paper we introduce a framework for instrumenting (" rigging") characters thatare modeled as dynamic elastic bodies; so that their shapes can be controlled by ananimator. Because the shape of such a character is determined by physical dynamics; therigging system cannot simply dictate the shape as in traditional animation. For this reason;we introduce forces as the building blocks of rigging. Rigging forces guide the shape of thecharacter; but are combined with other forces during simulation. Forces have other desirablefeatures: they can be combined easily and simulated at any resolution; and since they arenot tightly coupled with the surface geometry; they can be more easily transferred from onemodel to another. Our framework includes a new pose-dependent linearization scheme forelastic dynamics; which ensures a correspondence between forces and deformations …,Proceedings of the 2005 ACM SIGGRAPH/Eurographics symposium on Computer animation,2005,85
Learning a correlated model of identity and pose-dependent body shape variation for real-time synthesis,Brett Allen; Brian Curless; Zoran Popović; Aaron Hertzmann,Abstract We present a method for learning a model of human body shape variation from acorpus of 3D range scans. Our model is the first to capture both identity-dependent and pose-dependent shape variation in a correlated fashion; enabling creation of a variety of virtualhuman characters with realistic and non-linear body deformations that are customized to theindividual. Our learning method is robust to irregular sampling in pose-space and identity-space; and also to missing surface data in the examples. Our synthesized character modelsare based on standard skinning techniques and can be rendered in real time.,Proceedings of the 2006 ACM SIGGRAPH/Eurographics symposium on Computer animation,2006,73
DuploTrack: a real-time system for authoring and guiding duplo block assembly,Ankit Gupta; Dieter Fox; Brian Curless; Michael Cohen,Abstract We demonstrate a realtime system which infers and tracks the assembly process ofa snap-together block model using a Kinect® sensor. The inference enables us to build avirtual replica of the model at every step. Tracking enables us to provide context specificvisual feedback on a screen by augmenting the rendered virtual model aligned with thephysical model. The system allows users to author a new model and uses the inferredassembly process to guide its recreation by others. We propose a novel way of assemblyguidance where the next block to be added is rendered in blinking mode with the trackedvirtual model on screen. The system is also able to detect any mistakes made and helpscorrect them by providing appropriate feedback. We focus on assemblies of Duplo® blocks.We discuss the shortcomings of existing methods of guidance-static figures or recorded …,Proceedings of the 25th annual ACM symposium on User interface software and technology,2012,69
Vacuum-assisted socket suspension compared with pin suspension for lower extremity amputees: effect on fit; activity; and limb volume,Glenn K Klute; Jocelyn S Berge; Wayne Biggs; Suporn Pongnumkul; Zoran Popovic; Brian Curless,Abstract Klute GK; Berge JS; Biggs W; Pongnumkul S; Popovic Z; Curless B. Vacuum-assisted socket suspension compared with pin suspension for lower extremity amputees:effect on fit; activity; and limb volume. Objective To investigate the effect of a vacuum-assisted socket suspension system as compared with pin suspension on lower extremityamputees. Design Randomized crossover with 3-week acclimation. Setting Household;community; and laboratory environments. Participants Unilateral; transtibial amputees (N=20 enrolled; N= 5 completed). Interventions (1) Total surface–bearing socket with a vacuum-assisted suspension system (VASS); and (2) modified patellar tendon–bearing socket with apin lock suspension system. Main Outcome Measures Activity level; residual limb volumebefore and after a 30-minute treadmill walk; residual limb pistoning; and Prosthesis …,Archives of physical medicine and rehabilitation,2011,67
The visual turing test for scene reconstruction,Qi Shan; Riley Adams; Brian Curless; Yasutaka Furukawa; Steven M Seitz,We present the first large scale system for capturing and rendering relight able scenereconstructions from massive unstructured photo collections taken under differentillumination conditions and viewpoints. We combine photos taken from many sources; Flickr-Based ground-level imagery; oblique aerial views; and street view; to recover models thatare significantly more complete and detailed than previously demonstrated. We demonstratethe ability to match both the viewpoint and illumination of arbitrary input photos; enabling aVisual Turing Test in which photo and rendering are viewed side-by-side and the observerhas to guess which is which. While we cannot yet fool human perception; the gap is closing.,3D Vision-3DV 2013; 2013 International Conference on,2013,60
Overview of active vision techniques,Brian Curless,Smallest change in depth that sensor can report? Quantization? Spacing of samples … Statisticalvariations among repeated measurements of known value. Repeatability … Does temperatureor wind speed influence measurements … • Can only acquire visible portions of the surface• Sensitivity to surface properties > transparency; shininess; rapid color variations; darkness(no reflected light); subsurface scatter • Confused by interreflections … • Compact • Low power• Single wavelength is easy to isolate • No chromatic aberration • Tight focus over long distances… • Eye safety concerns • Laser speckle adds noise > Narrowing the aperture increases thenoise … A pulse of light is emitted; and the time of the reflected pulse is recorded … The currentto a laser diode is driven at frequency … The phase difference between incoming and outgoingsignals gives the range … 2 2 AM AM r n ϕ λ λ π … The ambiguity can be overcome …,Proc. SIGGRAPH,2000,54
Piecewise image registration in the presence of multiple large motions,Pravin Bhat; Ke Colin Zheng; Noah Snavely; Aseem Agarwala; Maneesh Agrawala; Michael F Cohen; Brian Curless,We present a technique for computing a dense pixel correspondence between two imagesof a scene containing multiple large; rigid motions. We model each motion with either ahomography (for planar objects) or a fundamental matrix. The various motions in the sceneare first extracted by clustering an initial sparse set of correspondences between featurepoints; we then perform a multi-label graph cut optimization which assigns each pixel to anindependent motion and computes its disparity with respect to that motion. We demonstrateour technique on several example scenes and compare our results with previousapproaches.,Computer Vision and Pattern Recognition; 2006 IEEE Computer Society Conference on,2006,51
Exploring the space of human body shapes: Data-driven synthesis under anthropometric control,Brett Allen; Brian Curless; Zoran Popović,Abstract: In this paper; we demonstrate a system for synthesizing high-resolution; realistic3D human body shapes according to user-specified anthropometric parameters. We beginwith a corpus of whole-body 3D laser range scans of 250 different people. For each scan;we warp a common template mesh to fit each scanned shape; thereby creating a one-to-onevertex correspondence between each of the example body shapes. Once we have acommon surface representation for each example; we then use principal componentanalysis to reduce the data storage requirements. The final step is to relate the variation ofbody shape with concrete parameters; such as body circumferences; point-to-pointmeasurements; etc. These parameters can then be used as “sliders” to synthesize newindividuals with the required attributes; or to edit the attributes of scanned individuals.,*,2004,50
Schematic surface reconstruction,Changchang Wu; Sameer Agarwal; Brian Curless; Steven M Seitz,This paper introduces a schematic representation for architectural scenes together withrobust algorithms for reconstruction from sparse 3D point cloud data. The schematic modelsarchitecture as a network of transport curves; approximating a floorplan; with associatedprofile curves; together comprising an interconnected set of swept surfaces. Therepresentation is extremely concise; composed of a handful of planar curves; and easilyinterpretable by humans. The approach also provides a principled mechanism forinterpolating a dense surface; and enables filling in holes in the data; by means of a pipelinethat employs a global optimization over all parameters. By incorporating a displacementmap on top of the schematic surface; it is possible to recover fine details. Experiments showthe ability to reconstruct extremely clean and simple models from sparse structure-from …,Computer Vision and Pattern Recognition (CVPR); 2012 IEEE Conference on,2012,48
3D Photography,Brian Curless; Steven Seitz,3D photography is the process of using cameras and light to capture the shape andappearance of real objects. This process provides a simple way of acquiring graphicalmodels of unparalleled detail and realism by scanning them in from the real world. Thiscourse provides an introduction to the emerging area of 3D photography; focusing on thecurrent state of the art and the principles underlying several leading approaches. Afterintroducing fundamental concepts; the course surveys a variety of techniques and providesan in-depth analysis of a few successful approaches at the forefront of 3D photography;presented by leading researchers in the field. The focus is on passive and active opticalmethods; including stereo vision; photogrammetry; structured light; imaging radar;interferometry; and optical triangulation. The course concludes with a field study …,Course Notes for SIGGRAPH 2000,2000,46
Enhancing and experiencing spacetime resolution with videos and stills,Ankit Gupta; Pravin Bhat; Mira Dontcheva; Oliver Deussen; Brian Curless; Michael Cohen,We present solutions for enhancing the spatial and/or temporal resolution of videos. Ouralgorithm targets the emerging consumer-level hybrid cameras that can simultaneouslycapture video and high-resolution stills. Our technique produces a high spacetime resolutionvideo using the high-resolution stills for rendering and the low-resolution video to guide thereconstruction and the rendering process. Our framework integrates and extends twoexisting algorithms; namely a high-quality optical flow algorithm and a high-quality image-based-rendering algorithm. The framework enables a variety of applications that werepreviously unavailable to the amateur user; such as the ability to (1) automatically createvideos with high spatiotemporal resolution; and (2) shift a high-resolution still to nearbypoints in time to better capture a missed event.,Computational Photography (ICCP); 2009 IEEE International Conference on,2009,38
A theory of frequency domain invariants: Spherical harmonic identities for BRDF/lighting transfer and image consistency,Dhruv Mahajan; Ravi Ramamoorthi; Brian Curless,This paper develops a theory of frequency domain invariants in computer vision. We derivenovel identities using spherical harmonics; which are the angular frequency domain analogto common spatial domain invariants such as reflectance ratios. These invariants arederived from the spherical harmonic convolution framework for reflection from a curvedsurface. Our identities apply in a number of canonical cases; including single and multipleimages of objects under the same and different lighting conditions. One important case weconsider is two different glossy objects in two different lighting environments. For this case;we derive a novel identity; independent of the specific lighting configurations or BRDFs; thatallows us to directly estimate the fourth image if the other three are available. The identitycan also be used as an invariant to detect tampering in the images. Although this paper is …,IEEE transactions on pattern analysis and machine intelligence,2008,34
Accurate geo-registration by ground-to-aerial image matching,Qi Shan; Changchang Wu; Brian Curless; Yasutaka Furukawa; Carlos Hernandez; Steven M Seitz,We address the problem of geo-registering ground-based multi-view stereo models byground-to-aerial image matching. The main contribution is a fully automated geo-registrationpipeline with a novel viewpoint-dependent matching method that handles ground to aerialviewpoint variation. We conduct large-scale experiments which consist of many popularoutdoor landmarks in Rome. The proposed approach demonstrates a high success rate forthe task; and dramatically outperforms state-of-the-art techniques; yielding geo-registrationat pixel-level accuracy.,3D Vision (3DV); 2014 2nd International Conference on,2014,33
Occluding contours for multi-view stereo,Qi Shan; Brian Curless; Yasutaka Furukawa; Carlos Hernandez; Steven M Seitz,Abstract This paper leverages occluding contours (aka “internal silhouettes”) to improve theperformance of multi-view stereo methods. The contributions are 1) a new technique toidentify free-space regions arising from occluding contours; and 2) a new approach forincorporating the resulting free-space constraints into Poisson surface reconstruction [14].The proposed approach outperforms state of the art MVS techniques for challenging Internetdatasets; yielding dramatic quality improvements both around object contours and in surfacedetail.,Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition,2014,33
Candid portrait selection from video,Juliet Fiss; Aseem Agarwala; Brian Curless,Abstract In this paper; we train a computer to select still frames from video that work well ascandid portraits. Because of the subjective nature of this task; we conduct a human subjectsstudy to collect ratings of video frames across multiple videos. Then; we compute a numberof features and train a model to predict the average rating of a video frame. We evaluate ourmodel with cross-validation; and show that it is better able to select quality still frames thanprevious techniques; such as simply omitting frames that contain blinking or motion blur; orselecting only smiles. We also evaluate our technique qualitatively on videos that were notpart of our validation set; and were taken outdoors and under different lighting conditions.,ACM Transactions on Graphics (TOG),2011,30
Painting With Texture.,Lincoln Ritter; Wilmot Li; Brian Curless; Maneesh Agrawala; David Salesin,Abstract We present an interactive texture painting system that allows the user to authordigital images by painting with a palette of input textures. At the core of our system is aninteractive texture synthesis algorithm that generates textures with natural-looking boundaryeffects and alpha information as the user paints. Furthermore; we describe an intuitivelayered painting model that allows strokes of texture to be merged; intersected andoverlapped while maintaining the appropriate boundaries between texture regions. Wedemonstrate the utility and expressiveness of our system by painting several images usingtextures that exhibit a range of different boundary effects.,Rendering Techniques,2006,27
Refocusing plenoptic images using depth-adaptive splatting,Juliet Fiss; Brian Curless; Richard Szeliski,In this paper; we propose a simple; novel plane sweep technique for refocusing plenopticimages. Rays are projected directly from the raw plenoptic image captured on the sensorinto the output image plane; without computing intermediate representations such assubaperture views or epipolar images. Interpolation is performed in the output image planeusing splatting. The splat kernel for each ray is adjusted adaptively; based on the refocusdepth and an estimate of the depth at which that ray intersects the scene. This adaptiveinterpolation method antialiases out-of-focus regions; while keeping in-focus regions sharp.We test the proposed method on images from a Lytro camera and compare our results withthose from the Lytro SDK. Additionally; we provide a thorough discussion of our calibrationand preprocessing pipeline for this camera.,Computational Photography (ICCP); 2014 IEEE International Conference on,2014,26
View-dependent refinement of multiresolution meshes with subdivision connectivity,Daniel I Azuma; Daniel N Wood; Brian Curless; Tom Duchamp; David H Salesin; Werner Stuetzle,Abstract We present a view-dependent level-of-detail algorithm for triangle meshes withsubdivision connectivity. The algorithm is more suitable for textured meshes of arbitrarytopology than existing progressive mesh-based schemes. It begins with a waveletdecomposition of the mesh; and; per frame; finds a partial sum of wavelets necessary forhigh-quality renderings from that frame's viewpoint. We present a screen-space error metricthat measures both geometric and texture deviation and tends to outperform prior errormetrics developed for progressive meshes. In addition; wavelets that lie outside the viewfrustum or in backfacing areas are eliminated. The algorithm takes advantage of frame-to-frame coherence for improved performance and supports geomorphs for smooth transitionsbetween levels of detail.,Proceedings of the 2nd international conference on Computer graphics; virtual Reality; visualisation and interaction in Africa,2003,25
Parallax photography: creating 3d cinematic effects from stills,Ke Colin Zheng; Alex Colburn; Aseem Agarwala; Maneesh Agrawala; David Salesin; Brian Curless; Michael F Cohen,Abstract We present an approach to convert a small portion of a light field with extracteddepth information into a cinematic effect with simulated; smooth camera motion that exhibitsa sense of 3D parallax. We develop a taxonomy of the cinematic conventions of theseeffects; distilled from observations of documentary film footage and organized by the numberof subjects of interest in the scene. We present an automatic; content-aware approach toapply these cinematic conventions to an input light field. A face detector identifies subjects ofinterest. We then optimize for a camera path that conforms to a cinematic convention;maximizes apparent parallax; and avoids missing information in the input. We describe aGPU-accelerated; temporally coherent rendering algorithm that allows users to create morecomplex camera moves interactively; while experimenting with effects such as focal …,Proceedings of Graphics Interface 2009,2009,24
Photo tours,Avanish Kushal; Ben Self; Yasutaka Furukawa; David Gallup; Carlos Hernandez; Brian Curless; Steven M Seitz,This paper describes an effort to automatically create``tours''of thousands of the world'slandmarks from geo-tagged user-contributed photos on the Internet. These photo tours takeyou through each site's most popular viewpoints on a tour that maximizes visual quality andtraversal efficiency. This planning problem is framed as a form of the Traveling SalesmanProblem on a graph with photos as nodes and transition costs on edges and pairs of edges;permitting efficient solution even for large graphs containing thousands of photos. Ourapproach is highly scalable and is the basis for the Photo Tours feature in Google Maps;which can be viewed at http://maps. google. com/phototours.,3D Imaging; Modeling; Processing; Visualization and Transmission (3DIMPVT); 2012 Second International Conference on,2012,20
Frequency-space decomposition and acquisition of light transport under spatially varying illumination,Dikpal Reddy; Ravi Ramamoorthi; Brian Curless,Abstract We show that; under spatially varying illumination; the light transport of diffusescenes can be decomposed into direct; near-range (subsurface scattering and local inter-reflections) and far-range transports (diffuse inter-reflections). We show that these threecomponent transports are redundant either in the spatial or the frequency domain and canbe separated using appropriate illumination patterns. We propose a novel; efficient methodto sequentially separate and acquire the component transports. First; we acquire the directtransport by extending the direct-global separation technique from floodlit images to fulltransport matrices. Next; we separate and acquire the near-range transport by illuminatingpatterns sampled uniformly in the frequency domain. Finally; we acquire the far-rangetransport by illuminating low-frequency patterns. We show that theoretically; our …,European Conference on Computer Vision,2012,20
Image-based remodeling,Alex Colburn; Aseem Agarwala; Aaron Hertzmann; Brian Curless; Michael F Cohen,Imagining what a proposed home remodel might look like without actually performing it ischallenging. We present an image-based remodeling methodology that allows real-timephotorealistic visualization during both the modeling and remodeling process of a homeinterior. Large-scale edits; like removing a wall or enlarging a window; are performed easilyand in real time; with realistic results. Our interface supports the creation of concise;parameterized; and constrained geometry; as well as remodeling directly from within thephotographs. Real-time texturing of modified geometry is made possible by precomputingview-dependent textures for all faces that are potentially visible to each original cameraviewpoint; blending multiple viewpoints and hole-filling when necessary. The resultingtextures are stored and accessed efficiently enabling intuitive real-time realistic …,IEEE transactions on visualization and computer graphics,2013,15
Refractive height fields from single and multiple images,Qi Shan; Sameer Agarwal; Brian Curless,We propose a novel framework for reconstructing homogenous; transparent; refractiveheight-fields from a single viewpoint. The height-field is imaged against a known planarbackground; or sequence of backgrounds. Unlike existing approaches that do a point-by-point reconstruction-which is known to have intractable ambiguities-our method estimatesand optimizes for the entire height-field at the same time. The formulation supports shaperecovery from measured distortions (deflections) or directly from the images themselves;including from a single image. We report results for a variety of refractive height-fieldsshowing significant improvement over prior art.,Computer Vision and Pattern Recognition (CVPR); 2012 IEEE Conference on,2012,14
Emptying; refurnishing; and relighting indoor spaces,Edward Zhang; Michael F Cohen; Brian Curless,Abstract Visualizing changes to indoor scenes is important for many applications. Whenlooking for a new place to live; we want to see how the interior looks not with the currentinhabitant's belongings; but with our own furniture. Before purchasing a new sofa; we wantto visualize how it would look in our living room. In this paper; we present a system that takesan RGBD scan of an indoor scene and produces a scene model of the empty room;including light emitters; materials; and the geometry of the non-cluttered room. Our systemenables realistic rendering not only of the empty room under the original lighting conditions;but also with various scene edits; including adding furniture; changing the materialproperties of the walls; and relighting. These types of scene edits enable many mixed realityapplications in areas such as real estate; furniture retail; and interior design. Our system …,ACM Transactions on Graphics (TOG),2016,13
New models and methods for matting and compositing,Yung-Yu Chuang; Brian Curless; David H Salesin,Matting and compositing are fundamental operations in graphics. In the matting process; aforeground element of arbitrary shape is extracted from an image. In the compositingprocess; the extracted foreground element is placed over a novel background image.Matting and compositing were originally developed for film production. Today; matting andcompositing have become crucial and frequently used operations in visual effectsproduction. They enable directors to insert new elements seamlessly into a scene or totransport an actor into a completely new location. Nearly all modern movies utilize digitalmatting and compositing in their production; notable examples include “Jurassic Park;”“TheMatrix;” and “The Lord of the Rings.” The potential importance of matting and compositingcan perhaps be best indicated by observing how lucrative visual effects movies have …,*,2004,13
Surface light fields for 3D photography,N Wood Daniel,CiNii 国立情報学研究所 学術情報ナビゲータ[サイニィ]. メニュー 検索 …,SIGGRAPH2000,2000,12
Light field layer matting,Juliet Fiss; Brian Curless; Richard Szeliski,Abstract In this paper; we use matting to separate foreground layers from light fieldscaptured with a plenoptic camera. We represent the input 4D light field as a 4D backgroundlight field; plus a 2D spatially varying foreground color layer with alpha. Our method can beused to both pull a foreground matte and estimate an occluded background light field. Ourmethod assumes that the foreground layer is thin and fronto-parallel; and is composed of alimited set of colors that are distinct from the background layer colors. Our method works wellfor thin; translucent; and blurred foreground occluders. Our representation can be used torender the light field from novel views; handling disocclusions while avoiding commonartifacts.,Computer Vision and Pattern Recognition (CVPR); 2015 IEEE Conference on,2015,10
Image analogies,Hertzmann Aaron; EJ Charles; Oliver Nuria; Curless Brian; HS David,*,Proceedings of ACM SIGGRAPH. ACM Press; New York,2001,9
A real-time; multichannel system with parallel digital signal processors,William A Weeks; Brian L Curless,A high-performance parallel signal processing system for use in a real-time environment isdescribed. The system includes analog input and output conditioners and data converters;digital signal processing (DSP) elements; and a system control computer. Expandingrequirements and advances in DSP technology have resulted in the evolution of severalgenerations of the system; each more powerful than the previous one. The hallmark of thenewest system is an ensemble of DSP boards; each containing eight AT&T DSP32Cprocessors. Custom architectures and algorithms were developed to allow the DSP chips toexecute filters with more taps per second than processor cycles.,Acoustics; Speech; and Signal Processing; 1990. ICASSP-90.; 1990 International Conference on,1990,8
Photo uncrop,Qi Shan; Brian Curless; Yasutaka Furukawa; Carlos Hernandez; Steven M Seitz,Abstract We address the problem of extending the field of view of a photo—an operation wecall uncrop. Given a reference photograph to be uncropped; our approach selects;reprojects; and composites a subset of Internet imagery taken near the reference into alarger image around the reference using the underlying scene geometry. The proposedMarkov Random Field based approach is capable of handling large Internet photocollections with arbitrary viewpoints; dramatic appearance variation; and complicated scenelayout. We show results that are visually compelling on a wide range of real-worldlandmarks.,European Conference on Computer Vision,2014,7
Seeing through obscure glass,Qi Shan; Brian Curless; Tadayoshi Kohno,Abstract Obscure glass is textured glass designed to separate spaces and “obscure”visibility between the spaces. Such glass is used to provide privacy while still allowing lightto flow into a space; and is often found in homes and offices. We propose and explore thechallenge of “seeing through” obscure glass; using both optical and digital techniques. Insome cases–such as when the textured surface is on the side of the observer–we find thatsimple household substances and cameras with small apertures enable a surprising level ofvisibility through the obscure glass. In other cases; where optical techniques are not usable;we find that we can model the action of obscure glass as convolution of spatially varyingkernels and reconstruct an image of the scene on the opposite side of the obscure glass withsurprising detail.,European Conference on Computer Vision,2010,7
Interactive video object annotation,Dan B Goldman; Brian Curless; David Salesin; Steven M Seitz,Abstract We present interactive techniques for visually annotating independently movingobjects in a video stream. Features in the video are automatically tracked and grouped in anoff-line preprocess that enables later interactive manipulation and annotation. Examples ofsuch annotations include speech and thought balloons; video graffiti; hyperlinks; and patharrows. Our system also employs a directmanipulation interface for random frame accessusing spatial constraints. This annotation interface can be employed in a variety ofapplications including surveillance; film and video editing; visual tagging; and authoring richmedia such as hyperlinked video.,ACM Computing Surveys,2007,6
Department of Computer Science and Engineering,Li Zhang; Brian Curless; Steven M Seitz,*,University of Washington,2004,6
Motionmontage: A system to annotate and combine motion takes for 3d animations,Ankit Gupta; Maneesh Agrawala; Brian Curless; Michael Cohen,Abstract We present MotionMontage; a system for recording multiple motion takes of a rigidvirtual object and compositing them together into a montage. Our system incorporates aKinect-based performance capture setup that allows animators to create 3D animations bytracking the motion of a rigid physical object and mapping it in realtime onto a virtual object.The animator then temporally annotates the best parts of each take. MotionMontage mergesthe annotated motions into a single composite montage using a combination of dynamictime warping and optimization of a Semi-Markov Conditional Random Field. Our system alsosupports the creation of layered animations in which multiple objects are moving at the sametime. To aid the animator in coordinating the motions of the objects we provide spatialmarkers which indicate the positions of previously recorded objects at user-specified …,Proceedings of the SIGCHI Conference on Human Factors in Computing Systems,2014,5
VripPack User’s Guide,Brian Curless,Before you get started; you will need to set up some environment variables. Theseenvironment variables are typically set in the. cshrc or. bash profile file in your homedirectory. We'll use the “setenv” command to describe how to set the environment variables;but bash users will instead use the “export” command. Note: The Vrip commands areexecuted as shell scripts using/bin/csh. You must set the environment variables in whicheverfile gets sourced when executing these scripts. If we call the place where you unpackvrippack the your root/vrippack directory; then you will need to set: setenv VRIP_DIRyour_root/vrippack/src/vrip,*,2006,5
A consistent segmentation approach to image-based rendering,Ke Colin Zheng; Alex Colburn; Aseem Agarwala; Maneesh Agrawala; B Curless; D Salesin; M Cohen,Abstract This paper presents an approach to render novel views from input photographs; atask which is commonly referred to as image based rendering. We first compute dense viewdependent depthmaps using consistent segmentation. This method jointly computesmultiview stereo and segments input photographs while accounting for mixed pixels(matting). We take the images with depth as our input and then propose two renderingalgorithms to render novel views using the segmentation; both realtime and off-line. Wedemonstrate the results of our approach on a wide variety of scenes.,*,2009,3
Project to build a 3D fax machine,Brian Curless; M Levoy,There is a growing interest in the graphics; vision; and manufacturing communities inbuilding an inexpensive device capable of digitizing the shape and external appearance ofobjects for transmission; display; and numerically controlled fabrication. Applications forsuch a device include product design; fast prototyping; reverse engineering; and digitizing ofshapes for the visual simulation; animation; and entertainment industries.Toward this end;we have been developing a laser-based scanning system capable of generating anocclusion-free low-level geometric description of the externally visible surfaces of an object.Here is a flow chart of the process.(This flow chart is somewhat out of date.) The crucial stepin this process is the merging of multiple range images; each of which captures only oneside of the object; in order to produce a seamless description of the entire object. The …,Website–http://graphics. stanford. edu/projects/faxing,1996,2
The Authors Respond: Vacuum-Assisted Socket Suspension Systems for Lower Extremity Amputees: Effect on Fit; Activity; and Limb Volume,Glenn K Klute; Jocelyn S Berge; Wayne Biggs; Suporn Pongnumkul; Zoran Popovic; Brian Curless,*,Archives of physical medicine and rehabilitation,2012,1
Non-photorealistic rendering,Aaron Hertzmann; Jianbo Peng; Ken Perlin; Denis Zorin; A Hertzmann; C Jacobs; N Oliver; B Curless; D Salesin; Paint by Relaxation; A Hertzmann; D Zorin,Over the centuries; visual artists developed a wide variety of valuable techniques for makingexpressive; pleasing; and communicative imagery--this includes ways of painting; drawing;sculpting; and so forth. However; 3D computer graphics tools are typically designed asapproximations to a realistic photographic model. Our goal is to expand the range ofrendering styles available to artists and designers for creating images; animations; andinteractive environments; in effect; to combine the expressivity of natural media with theflexibility of computer graphics. Furthermore; digital tools can make possible animated artforms that would be impossible with traditional media.,Los Angeles; California; USA: ACM SIGGRAPH,2006,1
Acquiring Images,Brian Curless,Page 1. 1 Acquiring Images Brian Curless University of Washington SIGGRAPH 99 Courseon 3D Photography The Imaging Pipeline Page 2. 2 Overview Pinhole camera Lenses •Principles of operation • Limitations Charge-coupled devices • Principles of operation •Limitations The pinhole camera The first camera - “camera obscura” - known to Aristotle. Smallaperture = high fidelity but requires long exposure or bright illumination Page 3. 3 Pinhole cameraIf aperture is too small; then diffraction causes blur. [Figure from Hecht87] Lenses Lenses focusa bundle of rays to one point. => can have larger aperture. [Figure from Hecht87] Page 4. 4Lenses A lens images a bundle of parallel rays to a focal point at a distance; f; beyond the planeof the lens. Note: f is a function of the index of refraction of the lens. An aperture of diameter;D; restricts the extent of the bundle of refracted rays. Lenses …,Siggraph [25],*,1
Ask not what your postdoc can do for you...,Chitta Baral; Shih-Fu Chang; Brian Curless; Partha Dasgupta; Julia Hirschberg; Anita Jones,JANUARY 2018| VOL. 61| NO. 1| COMMUNICATIONS OF THE ACM 43 viewpoints that fundundergraduates to work on the postdoc's independent research. The award process offers akind of academic; on-the-job training. In this program; postdocs define an independentproject; write a short NSF-style proposal to fund an undergraduate to perform the research;receive critical reviews from a committee of faculty and past postdoc awardees; receivefunding (if accepted) to perform the research; recruit an undergraduate; and mentor theundergraduate through the project. All of this is done independently of the postdoc's facultyadviser.,Communications of the ACM,2017,*
A Visual Cloud for Virtual Reality Applications.,Magdalena Balazinska; Luis Ceze; Alvin Cheung; Brian Curless; Steven M Seitz,Our ability to collect images of the world en masse can revolutionize how we interact with theworld by enabling powerful virtual reality (VR) applications in education; tourism; gaming;and others. These new applications; however; require a dramatic improvement intechnology to manage the massive-scale visual and audio data necessary for trulyimmersive experiences. In the Computer Science & Engineering Department at theUniversity of Washington; we are building a Visual Cloud that will provide seamless accessto a new stack of hardware and software components that; together; will enable the efficientmanagement of massive-scale image and audio data and VR applications.,CIDR,2017,*
Bilateral Filtering: Theory and Applications: Series: Foundations and Trends® in Computer Graphics and Vision,S Paris; P Kornprobst; J Tumblin; F Durand; Brian Curless; Luc Van Gool; Richard Szeliski,Paris; S.; Kornprobst; P.; Tumblin; J.; Durand; F.; Curless; B. (Ed.); Gool; LV (Ed.); & Szeliski;R. (Ed.) (2009). Bilateral Filtering: Theory and Applications: Series: Foundations and Trends®in Computer Graphics and Vision. Unknown Publisher … Bilateral Filtering: Theory and Applications: Series: Foundations and Trends® in Computer Graphics and Vision. / Paris; S.; Kornprobst;P.; Tumblin; J.; Durand; F.; Curless; Brian (Editor); Gool; Luc Van (Editor); Szeliski; Richard(Editor) … Paris; S; Kornprobst; P; Tumblin; J; Durand; F; Curless; B (ed.); Gool; LV (ed.) &Szeliski; R (ed.) 2009; Bilateral Filtering: Theory and Applications: Series: Foundations andTrends® in Computer Graphics and Vision. Unknown Publisher … Paris S; Kornprobst P; TumblinJ; Durand F; Curless B; (ed.); Gool LV; (ed.) et al. Bilateral Filtering: Theory and Applications:Series: Foundations and Trends® in Computer Graphics and Vision. Unknown Publisher …,*,2009,*
Capturing Visual Experiences.,Brian Curless,Abstract Why do we take pictures and videos? Often; the answer is that we hope to capturemoments in time; so that we can later recall and savor them once again. Digital cameras andcamcorders are making it ever easier to record these moments; but often; something is lost.Photographs freeze time and space; losing the sense of motion in a scene and losing thefreedom of motion available to the original viewer; and video is usually of lower resolutionand finite duration; and still gives up viewpoint freedom. Furthermore; the task of sortingthrough the reams of image and video data that an individual records is becoming simplyburdensome. In this talk; I will describe research aimed at helping the user to better captureand re-experience the moment. One approach is to build complex hardware to acquire animmersive representation of the scene; allowing virtual flythroughs and the like. The work …,BMVC,2006,*
The Space of Human Shapes.,Brian Curless,Abstract The human form has been the dominant subject of painters and sculptors formillennia. It is the shape we are most attuned to; the one most important to recognize and tobuild our environments around. Modeling this shape and the way it moves has been a grandchallenge in computer science. This task is one of the main components of the graphicsTuring test: can a machine fool an observer into thinking the synthetic projection of a moving;talking person is real. In this talk; I present strides taken in the direction of modeling realistic;time-varying human shape. These strides are formed around the premise that realismdepends on samples from reality. The capacity to sample the shape of the real world hasgrown dramatically in recent years with the advent of fast; reliable imaging sensors andcontrollable illumination sources. Using existing shape scanners; I will describe how my …,ICVGIP,2004,*
Shape analogies,Aaron Hertzmann; Nuria Oliver; Brian Curless; Steven M Seitz,Abstract This sketch presents" Shape Analogies;" a method for learning line styles fromexamples. With this approach; an artist or end-user simply draws in the desired style; thesystem analyzes the drawings and generates new imagery in the same style. For example;to design an outline style for a nervous character; one may draw a jittery stroke; to design anoutline style for a robot; one may draw a very rigid style with many sharp angles.,ACM SIGGRAPH 2002 conference abstracts and applications,2002,*
ICCV 2003 Author Index,Photometric Stereo Stereo; Li Zhang; Brian Curless; Aaron Hertzmann; Steven M Seitz Pages; Kannan Achan; Unsupervised Image Translation; Romer Rosales; Kannan Achan; Brendan Frey Pages; Meirav Galun; Eitan Sharon; Ronen Basri; Achi Brandt Pages; Adrian Barbu Graph Partition by Swendsen; Wang Cuts; Adrian Barbu; Song-Chun Zhu Pages; Adrien Bartoli; Peter Sturm Pages; Gauge Dependent Damping; Adrien Bartoli Pages; Motilal Agrawal; Larry Davis Pages; Maneesh Singh; Narendra Ahuja Pages; Hongcheng Wang; Alessandro Busti; Globally Convergent Autocalibration; Arrigo Benedetti; Michela Farenzena; Andrea Fusiello Pages; Paolo Favaro; Alessandro Duci; Yi Ma; Stefano Soatto Pages; Anthony Yezzi; Sanjoy Mitter,All authors of each paper are indexed; both by their surnames (ignoring prefixes like 'van';'de') and by their first name if given … Aaron Hertzmann Shape and Motion under VaryingIllumination: Unifying Multiview Stereo; Photometric Stereo; and Structure from Motion LiZhang; Brian Curless; Aaron Hertzmann; Steven M. Seitz. Pages 618–625 … Aaron P. ShonProbabilistic Bilinear Models for Appearance-Based Vision David B. Grimes; Aaron P. Shon;Rajesh PN Rao. Pages 1478–1485 … Achan; Kannan Unsupervised Image Translation RomerRosales; Kannan Achan; Brendan Frey. Pages 472–478 … Achi Brandt Texture Segmentationby Multiscale Aggregation of Filter Responses and Shape Elements Meirav Galun; EitanSharon; Ronen Basri; Achi Brandt. Pages 716–723. See the CD-ROM for a color version. AdrianBarbu Graph Partition by Swendsen-Wang Cuts Adrian Barbu; Song-Chun Zhu. Pages …,Learning,*,*
Additional Reviewer,Marc Alexa; Nina Amenta; Helder Araujo; Anup Basu; Peter Belhumeur; Alexander Belyaev; Fausto Bernardini; Jean-Daniel Boissonat; Vladimir Brajovic; Pere Brunet; Daniel Cohen-Or; David Cooper; Guido Cortelazzo; Daniel Cremers; Brian Curless; Kostas Daniilidis; Larry Davis; Leila De Floriani; Tamal Dey; Jan-Olof Eklundh; Davi Geiger; Craig Gotsman; Markus Gross; Concettina Guerra; Martial Hebert; David Jacobs; Avi Kak; Myung-Soo Kim; Leif Kobbelt; Jan Koenderink; Jana Kosecka; Kyros Kutulakos; Frederic Leymarie; Yi Ma; Nadia Magnenat-Thalmann; Roberto Manduchi; Dinesh Manocha; Ioana Martin; Ralph Martin; Takashi Matsuyama; Leonard McMillan; Dimitris Metaxas; Randal Nelson; Ko Nishino; Nikos Paragios; Valerio Pascucci; Yannis Pitas; Marc Pollefeys; Jean Ponce; Martin Rumpf; Holly Rushmeier; Szymon Rusinkiewicz; Dimitris Samaras; Francis Schmitt; Peter Schröder; Hans-Peter Seidel; Yoshihisa Shinagawa; Harry Shum; Claudio Silva; Stefano Soatto; Carlo Tomasi; Luc Van Gool; Luiz Velho; Naokazu Yokoya; Denis Zorin,Marc Alexa Nina Amenta Helder Araujo Anup Basu Peter Belhumeur Alexander Belyaev FaustoBernardini Jean-Daniel Boissonat Vladimir Brajovic Pere Brunet Daniel Cohen-Or David CooperGuido Cortelazzo Daniel Cremers Brian Curless Kostas Daniilidis Larry Davis Leila De FlorianiTamal Dey Jan-Olof Eklundh Davi Geiger Craig Gotsman Markus Gross Concettina Guerra MartialHebert David Jacobs Avi Kak Myung-Soo Kim Leif Kobbelt Jan Koenderink Jana Kosecka KyrosKutulakos Frederic Leymarie … Yi Ma Nadia Magnenat-Thalmann Roberto Manduchi DineshManocha Ioana Martin Ralph Martin Takashi Matsuyama Leonard McMillan Dimitris MetaxasRandal Nelson Ko Nishino Nikos Paragios Valerio Pascucci Yannis Pitas Marc Pollefeys JeanPonce Martin Rumpf Holly Rushmeier Szymon Rusinkiewicz Dimitris Samaras Francis SchmittPeter Schröder Hans-Peter Seidel Yoshihisa Shinagawa Harry Shum Claudio Silva …,*,*,*
CVPR Program Committee,Gene Alexander; Peter Allen; Elli Angeloupoulo; Greg Arnold; Patrick Bouthemy; Simon Baker; Eamon Barrett; Peter Belhumeur; Aaron Bobick; Jean-Yves Bouguet; Terry Boult; Kevin Bowyer; Christoph Bregler; Emanuela Bricolo; Mike Brooks; Alfred Bruckstein; Rama Chellappa; Isaac Cohen; Dorin Comaniciu; Luigi Cordella; James Crowley; Brian Curless; Ross Cutler; Kristin Dana; Kostas Daniilidis; James Davis; Jeremy De Bonet; Zachary Dodds; Dov Dori; Irfan Essa; David Fleet; Myron Flickner; Patrick Flynn; David Forsyth; William Freeman; Pascal Fua; Davi Geiger; Guido Gerig; Joshua Gluckman; Dmitry Goldgof; Venu Govindaraju; Richard Hall; Edwin Hancock; Richard Hartley; Anders Heyden; Horace Ip; Michal Irani; Michael Isard; Andrew Johnson; Ioannis Kakadiaris; Sing Bing Kang; Daniel Kersten; Benjamin Kimia; Josef Kittler; Rick Kjeldsen; Jana Kosecka; John Krumm; Kiriakos Kutulakos; Yann LeCun; Mi-Suen Lee; Tai Sing Lee; Ales Leonardis; James Little; Yi Ma; Bogdan Matei; Rudolf Mester; Baback Moghaddam; Javier Movellan; Randal Nelson; Clark Olson; Stelios Orphanoudakis; Theodore Papadopoulo; Eric Pauwels; Shmuel Peleg; John Platt; Jean Ponce; Jerry Prince,*,*,*,*
3DV 2013,Brian Curless; Yasutaka Furukawa; Ioannis Stamos; Camillo J Taylor; Sudipta Sinha; Bryan Russell; Austin Reiter; Guy Godin; Marc Pollefeys; Steve Seitz; Rick Szeliski; Ankit Gupta,A not-for-profit organization; IEEE is the world's largest technical professional organization dedicatedto advancing technology for the benefit of humanity. © Copyright 2017 IEEE - All rightsreserved. Use of this web site signifies your agreement to the terms and conditions.,*,*,*
From range scanners to surfaces,Brian Curless,*,*,*,*
Shape and Appearance from Images and Range Data,Brian Curless,Page 1. 1 Shape and Appearance from Images and Range Data Brian Curless Universityof Washington SIGGRAPH 2000 Course on 3D Photography Overview Range images vs.point clouds Registration Reconstruction from point clouds Reconstruction from range imagesModeling appearance Page 2. 2 Range images For many structured light scanners; the rangedata forms a highly regular pattern known as a range image. The sampling pattern isdetermined by the specific scanner. Examples of sampling patterns Page 3. 3 Examplesof sampling patterns Examples of sampling patterns Page 4. 4 Range images and rangesurfaces Given a range image; we can perform a preliminary reconstruction known as a rangesurface. Tessellation threshold To avoid “prematurely aggressive” reconstruction; atessellation threshold is employed: Page 5. 5 Registration …,*,*,*
