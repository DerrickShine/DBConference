Provably-efficient job scheduling for energy and fairness in geographically distributed data centers,Shaolei Ren; Yuxiong He; Fei Xu,Decreasing the soaring energy cost is imperative in large data centers. Meanwhile; limitedcomputational resources need to be fairly allocated among different organizations. Latencyis another major concern for resource management. Nevertheless; energy cost; resourceallocation fairness; and latency are important but often contradicting metrics on schedulingdata center workloads. In this paper; we explore the benefit of electricity price variationsacross time and locations. We study the problem of scheduling batch jobs; which originatefrom multiple organizations/users and are scheduled to multiple geographically-distributeddata centers. We propose a provably-efficient online scheduling algorithm--Gre Far--whichoptimizes the energy cost and fairness among different organizations subject to queueingdelay constraints. Gre Far does not require any statistical information of workload arrivals …,Distributed Computing Systems (ICDCS); 2012 IEEE 32nd International Conference on,2012,103
The Cilkview scalability analyzer,Yuxiong He; Charles E Leiserson; William M Leiserson,Abstract The Cilkview scalability analyzer is a software tool for profiling; estimatingscalability; and benchmarking multithreaded Cilk++ applications. Cilkview monitors logicalparallelism during an instrumented execution of the Cilk++ application on a singleprocessing core. As Cilkview executes; it analyzes logical dependencies within thecomputation to determine its work and span (critical-path length). These metrics allowCilkview to estimate parallelism and predict how the application will scale with the number ofprocessing cores. In addition; Cilkview analyzes cheduling overhead using the concept of a"burdened dag;" which allows it to diagnose performance problems in the application due toan insufficient grain size of parallel subcomputations. Cilkview employs the Pin dynamic-instrumentation framework to collect metrics during a serial execution of the application …,Proceedings of the twenty-second annual ACM symposium on Parallelism in algorithms and architectures,2010,86
Adaptive scheduling with parallelism feedback,Kunal Agrawal; Yuxiong He; Wen Jing Hsu; Charles E Leiserson,Abstract Multiprocessor scheduling in a shared multiprogramming environment is oftenstructured as two-level scheduling; where a kernel-level job scheduler allots processors tojobs and a user-level task scheduler schedules the work of a job on the allotted processors.In this context; the number of processors allotted to a particular job may vary during the job'sexecution; and the task scheduler must adapt to these changes in processor resources. Foroverall system efficiency; the task scheduler should also provide parallelism feedback to thejob scheduler to avoid the situation where a job is allotted processors that it cannot useproductively. We present an adaptive task scheduler for multitasked jobs with dependenciesthat provides continual parallelism feedback to the job scheduler in the form of requests forprocessors. Our scheduler guarantees that a job completes near optimally while utilizing …,Proceedings of the eleventh ACM SIGPLAN symposium on Principles and practice of parallel programming,2006,67
Adaptive work-stealing with parallelism feedback,Kunal Agrawal; Charles E Leiserson; Yuxiong He; Wen Jing Hsu,Abstract Multiprocessor scheduling in a shared multiprogramming environment can bestructured as two-level scheduling; where a kernel-level job scheduler allots processors tojobs and a user-level thread scheduler schedules the work of a job on its allottedprocessors. We present a randomized work-stealing thread scheduler for fork-joinmultithreaded jobs that provides continual parallelism feedback to the job scheduler in theform of requests for processors. Our A-STEAL algorithm is appropriate for large parallelservers where many jobs share a common multiprocessor resource and in which thenumber of processors available to a particular job may vary during the job's execution.Assuming that the job scheduler never allots a job more processors than requested by thejob's thread scheduler; A-STEAL guarantees that the job completes in near-optimal time …,ACM Transactions on Computer Systems (TOCS),2008,61
Graph query processing using plurality of engines,*,Graph queries are processed using a plurality of independent query execution engines. Agraph query submitted to a graph database which is modeled by an attributed graph isreceived. The graph query is decomposed into a plurality of query components. For each ofthe query components; a one of the query execution engines that is available to process thequery component is identified; a sub-query representing the query component is generated;the sub-query is sent to the identified query execution engine for processing; and results forthe sub-query are received from the identified query execution engine. The results receivedare then combined to generate a response to the graph query.,*,2015,60
Adaptive work stealing with parallelism feedback,Kunal Agrawal; Yuxiong He; Charles E Leiserson,Abstract We present an adaptive work-stealing thread scheduler; AS teal; for fork-joinmultithreaded jobs; like those written using the Cilk multithreaded language or the Hoodwork-stealing library. The AS teal algorithm is appropriate for large parallel servers wheremany jobs share a common multiprocessor resource and in which the number of processorsavailable to a particular job may vary during the job's execution. AS teal provides continualparallelism feedback to a job scheduler in the form of processor requests; and the job mustadaptits execution to the processors allotted to it. Assuming that the job scheduler neverallots any job more processors than requested by thejob's thread scheduler; AS tealguarantees that the job completes in near-optimal time while utilizing at least a constantfraction of the allotted processors. Our analysis models the job scheduler as the thread …,Proceedings of the 12th ACM SIGPLAN symposium on Principles and practice of parallel programming,2007,55
Zeta: Scheduling interactive services with partial execution,Yuxiong He; Sameh Elnikety; James Larus; Chenyu Yan,Abstract This paper presents a scheduling model for a class of interactive services in whichrequests are time bounded and lower result quality can be traded for shorter execution time.These applications include web search engines; finance servers; and other interactive; on-line services. We develop an efficient scheduling algorithm; Zeta; that allocates processortime among service requests to maximize the quality and minimize the variance of theresponse. Zeta exploits the concavity of the request quality profile to distribute processingtime among outstanding requests. By executing some requests partially (and obtainingmuch or most benefit of a full execution); Zeta frees resources for other requests; whichmight have timed out and produced no results. Compared to scheduling algorithms thatconsider only deadline or quality profile information; Zeta improves overall response …,Proceedings of the Third ACM Symposium on Cloud Computing,2012,53
G-SPARQL: a hybrid engine for querying large attributed graphs,Sherif Sakr; Sameh Elnikety; Yuxiong He,Abstract We propose a SPARQL-like language; G-SPARQL; for querying attributed graphs.The language expresses types of queries which of large interest for applications whichmodel their data as large graphs such as: pattern matching; reachability and shortest pathqueries. Each query can combine both of structural predicates and value-based predicates(on the attributes of the graph nodes and edges). We describe an algebraic compilationmechanism for our proposed query language which is extended from the relational algebraand based on the basic construct of building SPARQL queries; the Triple Pattern. Wedescribe a hybrid Memory/Disk representation of large attributed graphs where only thetopology of the graph is maintained in memory while the data of the graph is stored in arelational database. The execution engine of our proposed query language splits parts of …,Proceedings of the 21st ACM international conference on Information and knowledge management,2012,46
Provably efficient online nonclairvoyant adaptive scheduling,Yuxiong He; Wen-Jing Hsu; Charles E Leiserson,Multiprocessor scheduling in a shared multiprogramming environment can be structured intwo levels; where a kernel-level job scheduler allots processors to jobs and a user-levelthread scheduler maps the ready threads of a job onto the allotted processors. We presenttwo provably-efficient two-level scheduling schemes called G-RAD and S-RAD respectively.Both schemes use the same job scheduler RAD for the processor allotments that ensuresfair allocation under all levels of workload. In G-RAD; RAD is combined with a greedy threadscheduler suitable for centralized scheduling; in S-RAD; RAD is combined with a work-stealing thread scheduler more suitable for distributed settings. Both G-RAD and S-RAD arenon-clairvoyant. Moreover; they provide effective control over the scheduling overhead andensure efficient utilization of processors. We also analyze the competitiveness of both G …,IEEE Transactions on Parallel and Distributed Systems,2008,44
Horton: Online query execution engine for large distributed graphs,Mohamed Sarwat; Sameh Elnikety; Yuxiong He; Gabriel Kliot,Graphs are used in many large-scale applications; such as social networking. Themanagement of these graphs poses new challenges as such graphs are too large for asingle server to manage efficiently. Current distributed techniques such as map-reduce andPregel are not well-suited to processing interactive ad-hoc queries against large graphs. Inthis paper we demonstrate Horton; a distributed interactive query execution engine for largegraphs. Horton defines a query language that allows the expression of regular languagereach ability queries and provides a query execution engine with a query optimizer thatallows interactive execution of queries on large distributed graphs in parallel. In the demo;we show the functionality of Horton managing a large graph for a social networkingapplication called Codebook; whose graph represents data on software components …,Data Engineering (ICDE); 2012 IEEE 28th International Conference on,2012,43
Predictive parallelization: Taming tail latencies in web search,Myeongjae Jeon; Saehoon Kim; Seung-won Hwang; Yuxiong He; Sameh Elnikety; Alan L Cox; Scott Rixner,Abstract Web search engines are optimized to reduce the high-percentile response time toconsistently provide fast responses to almost all user queries. This is a challenging taskbecause the query workload exhibits large variability; consisting of many short-runningqueries and a few long-running queries that significantly impact the high-percentileresponse time. With modern multicore servers; parallelizing the processing of an individualquery is a promising solution to reduce query execution time; but it gives limited benefitscompared to sequential execution since most queries see little or no speedup whenparallelized. The root of this problem is that short-running queries; which dominate theworkload; do not benefit from parallelization. They incur a large parallelization overhead;taking scarce resources from long-running queries. On the other hand; parallelization …,Proceedings of the 37th international ACM SIGIR conference on Research & development in information retrieval,2014,41
Few-to-many: Incremental parallelism for reducing tail latency in interactive services,Md E Haque; Yuxiong He; Sameh Elnikety; Ricardo Bianchini; Kathryn S McKinley,Abstract Interactive services; such as Web search; recommendations; games; and finance;must respond quickly to satisfy customers. Achieving this goal requires optimizing tail (eg;99th+ percentile) latency. Although every server is multicore; parallelizing individualrequests to reduce tail latency is challenging because (1) service demand is unknown whenrequests arrive;(2) blindly parallelizing all requests quickly oversubscribes hardwareresources; and (3) parallelizing the numerous short requests will not improve tail latency.This paper introduces Few-to-Many (FM) incremental parallelization; which dynamicallyincreases parallelism to reduce tail latency. FM uses request service demand profiles andhardware parallelism in an offline phase to compute a policy; represented as an intervaltable; which specifies when and how much software parallelism to add. At runtime; FM …,ACM SIGPLAN Notices,2015,38
Exploiting processor heterogeneity in interactive services,Shaolei Ren; Yuxiong He; Sameh Elnikety; Kathryn S McKinley,Abstract To add processing power under power constraints; emerging heterogeneousprocessors include fast and slow cores on the same chip. This paper demonstrates that thisheterogeneity is well suited to interactive data center workloads (eg; web search; onlinegaming; and financial trading) by observing and exploiting two workload properties.(1)These workloads may trade response quality for responsiveness.(2) The request servicedemand is unknown and varies widely with both short and long requests. Subject to per-server power constraints; traditional homogeneous processors either include a few high-power fast cores that deliver high quality responses or many low-power slow cores thatdeliver high throughput; but not both. This paper shows heterogeneous processors deliverboth high quality and throughput by executing short requests on slow cores and long …,*,2013,38
Mercury: A memory-constrained spatio-temporal real-time search on microblogs,Amr Magdy; Mohamed F Mokbel; Sameh Elnikety; Suman Nath; Yuxiong He,This paper presents Mercury; a system for real-time support of top-k spatio-temporal querieson microblogs; where users are able to browse recent microblogs near their locations. Withhigh arrival rates of microblogs; Mercury ensures real-time query response within a tightmemory-constrained environment. Mercury bounds its search space to include only thosemicroblogs that have arrived within certain spatial and temporal boundaries; in which onlythe top-k microblogs; according to a spatio-temporal ranking function; are returned in thesearch results. Mercury employs:(a) a scalable dynamic in-memory index structure that iscapable of digesting all incoming microblogs;(b) an efficient query processor that exploitsthe in-memory index through spatio-temporal pruning techniques that reduce the number ofvisited microblogs to return the final answer;(c) an index size tuning module that …,Data Engineering (ICDE); 2014 IEEE 30th International Conference on,2014,34
Horton+: a distributed system for processing declarative reachability queries over partitioned graphs,Mohamed Sarwat; Sameh Elnikety; Yuxiong He; Mohamed F Mokbel,Abstract Horton+ is a graph query processing system that executes declarative reachabilityqueries on a partitioned attributed multi-graph. It employs a query language; queryoptimizer; and a distributed execution engine. The query language expresses declarativereachability queries; and supports closures and predicates on node and edge attributes tomatch graph paths. We introduce three algebraic operators; select; traverse; and join; and aquery is compiled into an execution plan containing these operators. As reachability queriesaccess the graph elements in a random access pattern; the graph is therefore maintained inthe main memory of a cluster of servers to reduce query execution time. We develop adistributed execution engine that processes a query plan in parallel on the graph servers.Since the query language is declarative; we build a query optimizer that uses graph …,Proceedings of the VLDB Endowment,2013,34
Provably efficient two-level adaptive scheduling,Yuxiong He; Wen-Jing Hsu; Charles E Leiserson,Abstract Multiprocessor scheduling in a shared multiprogramming environment can bestructured in two levels; where a kernel-level job scheduler allots processors to jobs and auser-level thread scheduler maps the ready threads of a job onto the allotted processors.This paper presents two-level scheduling schemes for scheduling “adaptive” multithreadedjobs whose parallelism can change during execution. The AGDEQ algorithm uses dynamic-equipartioning (DEQ) as a job-scheduling policy and an adaptive greedy algorithm (A-Greedy) as the thread scheduler. The ASDEQ algorithm uses DEQ for job scheduling and anadaptive work-stealing algorithm (A-Steal) as the thread scheduler. AGDEQ is suitable forscheduling in centralized scheduling environments; and ASDEQ is suitable for moredecentralized settings. Both two-level schedulers achieve O (1)-competitiveness with …,Workshop on Job Scheduling Strategies for Parallel Processing,2006,32
Adaptive parallelism for web search,Myeongjae Jeon; Yuxiong He; Sameh Elnikety; Alan L Cox; Scott Rixner,Abstract A web search query made to Microsoft Bing is currently parallelized by distributingthe query processing across many servers. Within each of these servers; the query is;however; processed sequentially. Although each server may be processing multiple queriesconcurrently; with modern multicore servers; parallelizing the processing of an individualquery within the server may nonetheless improve the user's experience by reducing theresponse time. In this paper; we describe the issues that make the parallelization of anindividual query within a server challenging; and we present a parallelization approach thateffectively addresses these challenges. Since each server may be processing multiplequeries concurrently; we also present a adaptive resource management algorithm thatchooses the degree of parallelism at run-time for each query; taking into account system …,Proceedings of the 8th ACM European Conference on Computer Systems,2013,31
An empirical evaluation of work stealing with parallelism feedback,Kunal Agrawal; Yuxiong He; Charles E Leiserson,A-STEAL is a provably good adaptive work-stealing thread scheduler that providesparallelism feedback to a multiprocessor job scheduler. A-STEAL uses a simplemultiplicative-increase; multiplicative-decrease algorithm to provide continual parallelismfeedback to the job scheduler in the form of processor requests. Although jobs scheduled byA-STEAL can be shown theoretically to complete in near-optimal time asymptotically whileutilizing at least a constant fraction of the allotted processors; the constants in the analysisleave it open on whether A-STEAL works well in practice. This paper confirms withsimulation studies that A-STEAL performs well when scheduling adaptively parallel work-stealing jobs on large-scale multiprocessors. Our studies monitored the behavior of A-STEAL on a simulated multiprocessor system using synthetic workloads. We measured …,Distributed Computing Systems; 2006. ICDCS 2006. 26th IEEE International Conference on,2006,31
Delayed-Dynamic-Selective (DDS) prediction for reducing extreme tail latency in web search,Saehoon Kim; Yuxiong He; Seung-won Hwang; Sameh Elnikety; Seungjin Choi,Abstract A commercial web search engine shards its index among many servers; andtherefore the response time of a search query is dominated by the slowest server thatprocesses the query. Prior approaches target improving responsiveness by reducing the taillatency of an individual search server. They predict query execution time; and if a query ispredicted to be long-running; it runs in parallel; otherwise it runs sequentially. Theseapproaches are; however; not accurate enough for reducing a high tail latency whenresponses are aggregated from many servers because this requires each server to reduce asubstantially higher tail latency (eg; the 99.99 th-percentile); which we call extreme taillatency. We propose a prediction framework to reduce the extreme tail latency of searchservers. The framework has a unique set of characteristics to predict long-running queries …,Proceedings of the Eighth ACM International Conference on Web Search and Data Mining,2015,26
Computing the processor desires of jobs in an adaptively parallel scheduling environment,*,The present invention describes a system and method for scheduling jobs on amultiprocessor system. The invention includes schedulers for use in both work-sharing andwork-stealing environments. Each system utilizes a task scheduler using historical usageinformation; in conjunction with a job scheduler to achieve its results. In one embodiment;the task scheduler measures the time spent on various activities; in conjunction with itsprevious processor allocation or previous desire; to determine an indication of its currentprocessor desire. In another embodiment of the present invention; the task schedulermeasures the resources used by the job on various activities. Based on thesemeasurements; the task scheduler determines the efficiency of the job and an indication ofits current processor desire. In another embodiment; the task scheduler measures the …,*,2013,26
Computing the processor desires of jobs in an adaptively parallel scheduling environment,*,The present invention describes a system and method for scheduling jobs on amultiprocessor system. The invention includes schedulers for use in both work-sharing andwork-stealing environments. Each system utilizes a task scheduler using historical usageinformation; in conjunction with a job scheduler to achieve its results. In one embodiment;the task scheduler measures the time spent on various activities; in conjunction with itsprevious processor allocation or previous desire; to determine an indication of its currentprocessor desire. In another embodiment of the present invention; the task schedulermeasures the resources used by the job on various activities. Based on thesemeasurements; the task scheduler determines the efficiency of the job and an indication ofits current processor desire. In another embodiment; the task scheduler measures the …,*,2013,26
Tians scheduling: Using partial processing in best-effort applications,Yuxiong He; Sameh Elnikety; Hongyang Sun,To service requests with high quality; interactive services such as web search; on-demandvideo and online gaming keep average server utilization low. As servers become busy;queuing delays increase; and requests miss their deadlines; resulting in degraded quality ofservice with poor user experience and potential revenue loss. In this paper; we proposeTians scheduling; a group of scheduling algorithms for interactive services that can producepartial answers during overload. A Tians scheduler allocates processing time to eachrequest based on system load with the objective of maximizing overall quality of responses.We propose three Tians scheduling algorithms-offline; online clairvoyant and onlinenonclairvoyant. For interactive applications with concave quality profile; we prove that the offline algorithm is optimal. We show the effectiveness of the online algorithms by …,Distributed Computing Systems (ICDCS); 2011 31st International Conference on,2011,25
Coca: Online distributed resource management for cost minimization and carbon neutrality in data centers,Shaolei Ren; Yuxiong He,Abstract Due to the enormous energy consumption and associated environmental concerns;data centers have been increasingly pressured to reduce long-term net carbon footprint tozero; ie; carbon neutrality. In this paper; we propose an online algorithm; called COCA(optimizing for COst minimization and CArbon neutrality); for minimizing data centeroperational cost while satisfying carbon neutrality without long-term future information.Unlike the existing research; COCA enables distributed server-level resource management:each server autonomously adjusts its processing speed and optimally decides the amount ofworkloads to process. We prove that COCA achieves a close-to-minimum operational cost(incorporating both electricity and delay costs) compared to the optimal algorithm with futureinformation; while bounding the potential violation of carbon neutrality. We also perform …,Proceedings of the International Conference on High Performance Computing; Networking; Storage and Analysis,2013,21
Stochastic modeling and optimization of stragglers,Farshid Farhat; Diman Tootaghaj; Yuxiong He; Anand Sivasubramaniam; Mahmut Kandemir; Chita Das,MapReduce framework is widely used to parallelize batch jobs since it exploits a highdegree of multi-tasking to process them. However; it has been observed that when thenumber of servers increases; the map phase can take much longer than expected. Thispaper analytically shows that the stochastic behavior of the servers has a negative effect onthe completion time of a MapReduce job; and continuously increasing the number of serverswithout accurate scheduling can degrade the overall performance. We analytically modelthe map phase in terms of hardware; system; and application parameters to capture theeffects of stragglers on the performance. Mean sojourn time (MST); the time needed to syncthe completed tasks at a reducer; is introduced as a performance metric and mathematicallyformulated. Following that; we stochastically investigate the optimal task scheduling …,IEEE Transactions on Cloud Computing,2016,17
Measuring and managing answer quality for online data-intensive services,Jaimie Kelley; Christopher Stewart; Nathaniel Morris; Devesh Tiwari; Yuxiong He; Sameh Elnikety,Online data-intensive services parallelize query execution across distributed softwarecomponents. Interactive response time is a priority; so online query executions returnanswers without waiting for slow running components to finish. However; data from theseslow components could lead to better answers. We propose Ubora; an approach to measurethe effect of slow running components on the quality of answers. Ubora randomly samplesonline queries and executes them twice. The first execution elides data from slowcomponents and provides fast online answers; the second execution waits for allcomponents to complete. Ubora uses memoization to speed up mature executions byreplaying network messages exchanged between components. Our systems-levelimplementation works for a wide range of platforms; including Hadoop/Yarn; Apache …,Autonomic Computing (ICAC); 2015 IEEE International Conference on,2015,17
Scheduling functionally heterogeneous systems with utilization balancing,Yuxiong He; Jie Liu; Hongyang Sun,Heterogeneous systems become popular in both client and cloud. A parallel program canincur operations on multiple processing resources such as CPU; GPU; and vector processorunits. This paper investigates scheduling problems on functionally heterogeneous systemswith the objective of minimizing the completion time of parallel jobs. We first presentperformance bounds of online scheduling and show that any online algorithm is at bestaround (K+ 1)-competitive with respect to job completion time; where K is the total number ofresource types. There exist" bad" jobs that prevent any online algorithms from obtaininggood interleaving of heterogeneous tasks. This lower bound suggests that the relativeperformance of online algorithms versus an offline optimal could degrade linearly as types ofheterogeneous resources increase. The limitation of online scheduling motivates our …,Parallel & Distributed Processing Symposium (IPDPS); 2011 IEEE International,2011,17
Budget-based control for interactive services with adaptive execution,Yuxiong He; Zihao Ye; Qiang Fu; Sameh Elnikety,Abstract We study the problem of managing a class of interactive services to meet aresponse time target while achieving high service quality. We focus here on interactiveservices that support adaptive execution; such as web search engines and finance servers.With adaptive execution; when a request receives more processing time; its result improves;posing new challenges and opportunities for resource management. We propose a newbudget-based control model for interactive services with adaptive execution. The budgetrepresents the amount of resources assigned to all pending requests. The budget-basedcontrol model consists of two components:(1) a hybrid control mechanism; which combinesadaptive and integral controllers and controls the budget in order to meet the response timetarget with small steady-state error; fast settling time and little runtime overhead; and (2) …,Proceedings of the 9th international conference on Autonomic computing,2012,16
Assessing capacity and improving utilization of anchorages,Shell Ying Huang; Wen Jing Hsu; Yuxiong He,Abstract Anchorages are important resources for certain hub ports; and they are increasinglyin demand during peak periods. We evaluate the capacity of multiple anchorages byreproducing realistic mix of arriving vessels; dwelling time and the current practices inchoosing anchoring spots within an anchorage. The model is validated by using historicaldata. We also propose methods for improving space utilization of anchorages. Ourexperiments with four real anchorages show that the space utilization is improved by 6–10%with MHDF and WALLPACK_MHDF algorithms. This finding opens up possibilities ofdesignating vessel anchoring spots for improved utilizations in the future.,Transportation Research Part E: Logistics and Transportation Review,2011,16
Energy-efficient scheduling for best-effort interactive services to achieve high response quality,Zhihui Du; Hongyang Sun; Yuxiong He; Yu He; David A Bader; Huazhe Zhang,High response quality is critical for many best-effort interactive services; and at the sametime; reducing energy consumption can directly reduce the operational cost of serviceproviders. In this paper; we study the quality-energy tradeoff for such services by using acomposite performance metric that captures their relative importance in practice: Serviceproviders usually grant top priority to quality guarantee and explore energy saving secondly.We consider scheduling on multicore systems with core-level DVFS support and a powerbudget. Our solution consists of two steps. First; we employ an equal sharing principle forboth job and power distribution. Specifically; we present a “Cumulative Round-Robin” policyto distribute the jobs onto the cores; and a “Water-Filling” policy to distribute the powerdynamically among the cores. Second; we exploit the concave quality function of many …,Parallel & Distributed Processing (IPDPS); 2013 IEEE 27th International Symposium on,2013,13
Secure communications between bandwidth brokers,Bu-Sung Lee; Wing-Keong Woo; Chai-Kiat Yeo; Teck-Meng Lim; Bee-Hwa Lim; Yuxiong He; Jie Song,Abstract In the Differentiated Services (DiffServ) architecture; each domain has a BandwidthBroker to provide the resources management; primarily bandwidth reservation. In a multi-domain environment; Simple Inter-domain Bandwidth Broker Signaling (SIBBS) protocol isproposed for the inter-domain communication protocol proposed for bandwidth brokercommunication. Since the information exchanged between BBs are sensitive in sense ofService Level Agreement (SLA); the communications between the inter-domain bandwidthbrokers should be protected from attacks. This paper presents the incorporation of the PublicKey Infrastructure (PKI) security model for SIBBS. A prototype system with the securityelements as well as the implementation of the SIBBS was successfully developed andtested.,ACM SIGOPS Operating Systems Review,2004,12
Optimal aggregation policy for reducing tail latency of web search,Jeong-Min Yun; Yuxiong He; Sameh Elnikety; Shaolei Ren,Abstract A web search engine often employs partition-aggregate architecture; where anaggregator propagates a user query to all index serving nodes (ISNs) and collects theresponses from them. An aggregation policy determines how long the aggregators wait forthe ISNs before returning aggregated results to users; crucially affecting both query latencyand quality. Designing an aggregation policy is; however; challenging: Response latencyamong queries and among ISNs varies significantly; and aggregators lack of knowledgeabout when ISNs will respond. In this paper; we propose aggregation policies that minimizetail latency of search queries subject to search quality service level agreements (SLAs);combining data-driven offline analysis with online processing. Beginning with a singleaggregator; we formally prove the optimality of our policy: It achieves the offline optimal …,Proceedings of the 38th International ACM SIGIR Conference on Research and Development in Information Retrieval,2015,11
Assigning jobs to heterogeneous processing modules,*,A processing system is described which assigns jobs to heterogeneous processingmodules. The processing system assigns jobs to the processing modules in a manner thatattempts to accommodate the service demands of the jobs; but without advance knowledgeof the service demands. In one case; the processing system implements the processingmodules as computing units that have different physical characteristics. Alternatively; or inaddition; the processing system may implement the processing modules as threads that areexecuted by computing units. Each thread which runs on a computing unit offers a level ofperformance that depends on a number of other threads that are simultaneously beingexecuted by the same computing unit.,*,2016,10
Processing and optimizing main memory spatial-keyword queries,Taesung Lee; Jin-woo Park; Sanghoon Lee; Seung-won Hwang; Sameh Elnikety; Yuxiong He,Abstract Important cloud services rely on spatial-keyword queries; containing a spatialpredicate and arbitrary boolean keyword queries. In particular; we study the processing ofsuch queries in main memory to support short response times. In contrast; current state-of-the-art spatial-keyword indexes and relational engines are designed for differentassumptions. Rather than building a new spatial-keyword index; we employ a cost-basedoptimizer to process these queries using a spatial index and a keyword index. We addressseveral technical challenges to achieve this goal. We introduce three operators as thebuilding blocks to construct plans for main memory query processing. We then develop acost model for the operators and query plans. We introduce five optimization techniques thatefficiently reduce the search space and produce a query plan with low cost. The …,Proceedings of the VLDB Endowment,2015,10
Performance modeling and scalability optimization of distributed deep learning systems,Feng Yan; Olatunji Ruwase; Yuxiong He; Trishul Chilimbi,Abstract Big deep neural network (DNN) models trained on large amounts of data haverecently achieved the best accuracy on hard tasks; such as image and speech recognition.Training these DNNs using a cluster of commodity machines is a promising approach sincetraining is time consuming and compute-intensive. To enable training of extremely largeDNNs; models are partitioned across machines. To expedite training on very large data sets;multiple model replicas are trained in parallel on different subsets of the training exampleswith a global parameter server maintaining shared weights across these replicas. Thecorrect choice for model and data partitioning and overall system provisioning is highlydependent on the DNN and distributed system hardware characteristics. These decisionscurrently require significant domain expertise and time consuming empirical state space …,Proceedings of the 21th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining,2015,10
Mars: Real-time spatio-temporal queries on microblogs,Amr Magdy; Ahmed M Aly; Mohamed F Mokbel; Sameh Elnikety; Yuxiong He; Suman Nath,Mars demonstration exploits the microblogs location information to support a wide variety ofimportant spatio-temporal queries on microblogs. Supported queries include range; nearest-neighbor; and aggregate queries. Mars works under a challenging environment wherestreams of microblogs are arriving with high arrival rates. Mars distinguishes itself with threenovel contributions:(1) Efficient in-memory digestion/expiration techniques that can handlemicroblogs of high arrival rates up to 64;000 microblog/sec. This also includes highlyaccurate and efficient hopping-window based aggregation for incoming microblogskeywords.(2) Smart memory optimization and load shedding techniques that adjust in-memory contents based on the expected query load to trade off a significant storage savingswith a slight and bounded accuracy loss.(3) Scalable real-time query processing …,Data Engineering (ICDE); 2014 IEEE 30th International Conference on,2014,10
Venus: Scalable real-time spatial queries on microblogs with adaptive load shedding,Amr Magdy; Mohamed F Mokbel; Sameh Elnikety; Suman Nath; Yuxiong He,Microblogging services have become among the most popular services on the web in thelast few years. This led to significant increase in data size; speed; and applications. Thispaper presents Venus; a system that supports real-time spatial queries on microblogs.Venus supports its queries on a spatial boundary $ R $ and a temporal boundary $ T $; fromwhich only the top-$ k $ microblogs are returned in the query answer based on a spatio-temporal ranking function. Supporting such queries requires Venus to digest hundreds ofmillions of real-time microblogs in main-memory with high rates; yet; it provides low queryresponses and efficient memory utilization. To this end; Venus employs:(1) an efficient in-memory spatio-temporal index that digests high rates of incoming microblogs in real time;(2)a scalable query processor that prune the search space; $ R $ and $ T $; effectively to …,IEEE Transactions on Knowledge and Data Engineering,2016,9
BATS: budget-constrained autoscaling for cloud performance optimization,A Hasan Mahmud; Yuxiong He; Shaolei Ren,Autoscaling has become an integral feature of cloud computing services; allowing users todynamically scale the cloud resources on demand for both performance and cost. Moreover;recent survey shows the importance of satisfying long-term budget constraints (eg; monthlyor yearly) for cloud users. However; meeting such constraints while optimizing delayperformance is challenging: it requires the knowledge of complete offline information suchas workload demand over the entire budgeting period; which is difficult to predict accurately.This paper proposes a new autoscaling system; BATS; which optimizes delay performancewhile meeting long-term budget constraints using only past and instantaneous workloadinformation. Analytically; we prove that; for arbitrary workload arrival; the autoscalingalgorithm of BATS achieves close-to-optimal performance even compared to the optimal …,Modeling; Analysis and Simulation of Computer and Telecommunication Systems (MASCOTS); 2015 IEEE 23rd International Symposium on,2015,8
Qaco: Exploiting partial execution in web servers,Jinhan Kim; Sameh Elnikety; Yuxiong He; Seung-won Hwang; Shaolei Ren,Abstract Web servers provide content to users; with the requirement of providing highresponse quality within a short response time. Meeting these requirements is challenging;especially in the event of load spikes. Meanwhile; we observe that a response to a requestcan be adapted or partially executed depending on current resource availability at theserver. For example; a web server can choose to send a low or medium resolution imageinstead of sending the original high resolution image under resource contention. In thispaper; we exploit partial execution to expose a trade off between resource consumption andservice quality. We show how to manage server resources to improve service quality andresponsiveness. Specifically; we develop a framework; called Quota-based ControlOptimization (QACO). The quota represents the total amount of resources available for all …,Proceedings of the 2013 ACM Cloud and Autonomic Computing Conference,2013,8
Prediction and predictability for search query acceleration,Seung-Won Hwang; Saehoon Kim; Yuxiong He; Sameh Elnikety; Seungjin Choi,Abstract A commercial web search engine shards its index among many servers; andtherefore the response time of a search query is dominated by the slowest server thatprocesses the query. Prior approaches target improving responsiveness by reducing the taillatency; or high-percentile response time; of an individual search server. They predict queryexecution time; and if a query is predicted to be long-running; it runs in parallel; otherwise; itruns sequentially. These approaches are; however; not accurate enough for reducing a hightail latency when responses are aggregated from many servers because this requires eachserver to reduce a substantially higher tail latency (eg; the 99.99 th percentile); which we callextreme tail latency. To address tighter requirements of extreme tail latency; we propose anew design space for the problem; subsuming existing work and also proposing a new …,ACM Transactions on the Web (TWEB),2016,7
TPC: Target-driven parallelism combining prediction and correction to reduce tail latency in interactive services,Myeongjae Jeon; Yuxiong He; Hwanju Kim; Sameh Elnikety; Scott Rixner; Alan L Cox,Abstract In interactive services such as web search; recommendations; games and finance;reducing the tail latency is crucial to provide fast response to every user. Using web searchas a driving example; we systematically characterize interactive workload to identify theopportunities and challenges for reducing tail latency. We find that the workload consists ofmainly short requests that do not benefit from parallelism; and a few long requests whichsignificantly impact the tail but exhibit high parallelism speedup. This motivates estimatingrequest execution time; using a predictor; to identify long requests and to parallelize them.Prediction; however; is not perfect; a long request mispredicted as short is likely to contributeto the server tail latency; setting a ceiling on the achievable tail latency. We propose TPC; anapproach that combines prediction information judiciously with dynamic correction for …,ACM SIGPLAN Notices,2016,7
A theoretical foundation for scheduling and designing heterogeneous processors for interactive applications,Shaolei Ren; Yuxiong He; Kathryn S McKinley,Abstract To improve performance and meet power constraints; vendors are introducingheterogeneous multicores that combine high performance and low power cores. However;choosing which cores and scheduling applications on them remain open problems. Thispaper presents a scheduling algorithmthat provably minimizes energy onheterogeneousmulticores and meets latency constraints for interactive applications; such assearch; recommendations; advertisements; and games. Because interactive applicationsmust respond quickly to satisfy users; they impose multiple constraints; including average;tail; and maximumlatency. We introduce SEM (Slow-to-fast; Energy optimization for Multipleconstraints); which minimizes energy by choosing core speeds and how long to executejobs on each core. We prove SEM minimizes energy without a priori knowledge of job …,International Symposium on Distributed Computing,2014,7
Solving graph isomorphism using parameterized matching,Juan Mendivelso; Sunghwan Kim; Sameh Elnikety; Yuxiong He; Seung-won Hwang; Yoan Pinzón,Abstract We propose a new approach to solve graph isomorphism using parameterizedmatching. To find isomorphism between two graphs; one graph is linearized; ie; representedas a graph walk that covers all nodes and edges such that each element is represented by aparameter. Next; we match the graph linearization on the second graph; searching for abijective function that maps each element of the first graph to an element of the secondgraph. We develop an efficient linearization algorithm that generates short linearization withan approximation guarantee; and develop a graph matching algorithm. We evaluate ourapproach experimentally on graphs of different types and sizes; and compare to theperformance of VF2; which is a prominent algorithm for graph isomorphism. Our empiricalmeasurements show that graph linearization finds a matching graph faster than VF2 in …,International Symposium on String Processing and Information Retrieval,2013,7
Hybrid query execution engine for large attributed graphs,Sherif Sakr; Sameh Elnikety; Yuxiong He,Abstract Graphs are widely used for modeling complicated data such as social networks;bibliographical networks and knowledge bases. The growing sizes of graph databasesmotivate the crucial need for developing powerful and scalable graph-based query engines.We propose a SPARQL-like language; G-SPARQL; for querying attributed graphs. Thelanguage enables the expression of different types of graph queries that are of large interestin the databases that are modeled as large graph such as pattern matching; reachability andshortest path queries. Each query can combine both structural predicates and value-basedpredicates (on the attributes of the graph nodes/edges). We describe an algebraiccompilation mechanism for our proposed query language which is extended from therelational algebra and based on the basic construct of building SPARQL queries; the …,Information Systems,2014,6
Adaptive scheduling of parallel jobs on functionally heterogeneous resources,Yuxiong He; Hongyang Sun; Wen-Jing Hsu,A parallel program usually incurs operations on multiple processing resources; interleavingcomputations; I/Os; and communications; where each task can only be executed on aprocessor of a matching category. Many parallel systems also embed special-purposeprocessors like vector units; floating-point co-processors; and various I/O processors.Presently; there is no provably good scheduling algorithm that ensures efficient use ofmultiple resources with functional heterogeneity. This paper presents K-RAD; an algorithmthat adoptively schedules parallel jobs on multiple processing resources without requiringprior information about the jobs; such as their release times and parallelism profiles. Let Kdenote the number of categories of heterogenous resources and P max denote themaximum number of processors among all categories. We show that; for any set of jobs …,Parallel Processing; 2007. ICPP 2007. International Conference on,2007,6
BitFunnel: Revisiting signatures for search,Bob Goodwin; Michael Hopcroft; Dan Luu; Alex Clemmer; Mihaela Curmei; Sameh Elnikety; Yuxiong He,Abstract Since the mid-90s there has been a widely-held belief that signature files areinferior to inverted files for text indexing. In recent years the Bing search engine hasdeveloped and deployed an index based on bit-sliced signatures. This index; known asBitFunnel; replaced an existing production system based on an inverted index. The drivingfactor behind the shift away from the inverted index was operational cost savings. This paperdescribes algorithmic innovations and changes in the cloud computing landscape that ledus to reconsider and eventually field a technology that was once considered unusable. TheBitFunnel algorithm directly addresses four fundamental limitations in bit-sliced blocksignatures. At the same time; our mapping of the algorithm onto a cluster offers opportunitiesto avoid other costs associated with signatures. We show these innovations yield a …,Proceedings of the 40th International ACM SIGIR Conference on Research and Development in Information Retrieval,2017,5
Work stealing for interactive services to meet target latency,Jing Li; Kunal Agrawal; Sameh Elnikety; Yuxiong He; I Lee; Chenyang Lu; Kathryn S McKinley,Abstract Interactive web services increasingly drive critical business workloads such assearch; advertising; games; shopping; and finance. Whereas optimizing parallel programsand distributed server systems have historically focused on average latency and throughput;the primary metric for interactive applications is instead consistent responsiveness; ie;minimizing the number of requests that miss a target latency. This paper is the first to showhow to generalize work-stealing; which is traditionally used to minimize the makespan of asingle parallel job; to optimize for a target latency in interactive services with multiple parallelrequests. We design a new adaptive work stealing policy; called tail-control; that reduces thenumber of requests that miss a target latency. It uses instantaneous request progress;system load; and a target latency to choose when to parallelize requests with stealing …,ACM SIGPLAN Notices,2016,5
Energy-efficient multiprocessor scheduling for flow time and makespan,Hongyang Sun; Yuxiong He; Wen-Jing Hsu; Rui Fan,Abstract We consider energy-efficient scheduling on multiprocessors; where the speed ofeach processor can be individually scaled; and a processor consumes power s α whenrunning at speed s; for α> 1. A scheduling algorithm needs to decide at any time bothprocessor allocations and processor speeds for a set of parallel jobs with time-varyingparallelism. The objective is to minimize the sum of the total energy consumption and certainperformance metric; which in this paper includes total flow time and makespan. For bothobjectives; we present instantaneous parallelism-clairvoyant (IP-clairvoyant) algorithms thatare aware of the instantaneous parallelism of the jobs at any time but not their futurecharacteristics; such as remaining parallelism and work. For total flow time plus energy; wepresent an O (1)-competitive algorithm; which significantly improves upon the best known …,Theoretical Computer Science,2014,5
Cache provisioning for interactive NLP services,Jaimie Kelley; Christopher Stewart; S Elnikety; Y He,Abstract Search engines and question-answer systems support interactive queries againstnatural language corpora. As their corpora grows; these interactive natural languageprocessing (NLP) services use large portions of their IT budget to cache data in costly mainmemory. These caches ensure fast access to existing and recently added data. However;recently added data often overlaps with existing data in terms of informative content. Userswill not perceive a loss in quality if such redundant data is excluded from cache. For thispaper; we quantified cost savings when caches are rightly provisioned so that they are justlarge enough to avoid quality loss. We set up two NLP services; a search engine and aquestion-answering system; that supported growing corpora from Wikipedia and the NewYork Times (up to 88MB and 30GB per month; respectively). First; we studied the effect of …,Workshop on Large-Scale Distributed Systems and Middleware,2013,5
GeoTrend: spatial trending queries on real-time microblogs,Amr Magdy; Ahmed M Aly; Mohamed F Mokbel; Sameh Elnikety; Yuxiong He; Suman Nath; Walid G Aref,Abstract This paper presents GeoTrend; a system for scalable support of spatial trenddiscovery on recent microblogs; eg; tweets and online reviews; that come in real time.GeoTrend is distinguished from existing techniques in three aspects:(1) It discovers trends inarbitrary spatial regions; eg; city blocks.(2) It supports trending measures that effectivelycapture trending items under a variety of definitions that suit different applications.(3) Itpromotes recent microblogs as first-class citizens and optimizes its system components todigest a continuous flow of fast data in main-memory while removing old data efficiently.GeoTrend queries are top-k queries that discover the most trending k keywords that areposted within an arbitrary spatial region and during the last T time units. To support itsqueries efficiently; GeoTrend employs an in-memory spatial index that is able to efficiently …,Proceedings of the 24th ACM SIGSPATIAL International Conference on Advances in Geographic Information Systems,2016,4
Power-effiicent resource allocation in MapReduce clusters,Kaiqi Xiong; Yuxiong He,MapReduce has recently evolved in data-intensive parallel computing. It is a programmingmodel for processing large data sets. The implementation of MapReduce typically runs on alarge scale of cluster computing systems consisting of thousands of commodity machines.Such cluster computing systems are called MapReduce clusters. The high powerconsumption of MapReduce clusters has become a major concern since hundreds ofMapReduce programs are implemented and thousands of MapReduce jobs are executed insuch clusters like Amazon's Elastic MapReduce Clusters every day. Power managementbecomes one of the most important problems in MapReduce clusters. Furthermore; theavailability of MapReduce clusters plays an essential role in the delivery of quality ofservices (QoS) for customer services. In this paper; we investigate the problem of …,Integrated Network Management (IM 2013); 2013 IFIP/IEEE International Symposium on,2013,4
Speed scaling for energy and performance with instantaneous parallelism,Hongyang Sun; Yuxiong He; Wen-Jing Hsu,Abstract We consider energy-performance tradeoff for scheduling parallel jobs onmultiprocessors using dynamic speed scaling. The objective is to minimize the sum ofenergy consumption and certain performance metric; including makespan and total flowtime. We focus on designing algorithms that are aware of the jobs' instantaneous parallelismbut not their characteristics in the future. For total flow time plus energy; it is known that anyalgorithm that does not rely on instantaneous parallelism is Ω (ln 1/α P)-competitive; where Pis the total number of processors. In this paper; we demonstrate the benefits of knowinginstantaneous parallelism by presenting an O (1)-competitive algorithm. In the case ofmakespan plus energy; which is considered in the literature for the first time; we present anO (ln 1− 1/α P)-competitive algorithm for batched jobs consisting of fully-parallel and …,*,2011,4
Improved results for scheduling batched parallel jobs by using a generalized analysis framework,Yuxiong He; Hongyang Sun; Wen-Jing Hsu,Abstract We present two improved results for scheduling batched parallel jobs onmultiprocessors with mean response time as the performance metric. These results areobtained by using a generalized analysis framework where the response time of the jobs isexpressed in two contributing factors that directly impact a scheduler's competitive ratio.Specifically; we show that the scheduler IGDEQ is 3-competitive against the optimal whileAGDEQ is 5.24-competitive. These results improve the known competitive ratios of 4 and 10;obtained by Deng et al. and by He et al.; respectively. For the common case where nofractional allotments are allowed; we show that slightly larger competitive ratios can beobtained by augmenting the schedulers with the round-robin strategy.,Journal of Parallel and Distributed Computing,2010,4
Provably efficient adaptive scheduling for parallel jobs,Yuxiong He; Wen Jing Hsu; Charles E Leiserson,Scheduling competing jobs on multiprocessors has always been an important issue forparallel and distributed systems. The challenge is to ensure global; system-wide efficiencywhile offering a level of fairness to user jobs. Various degrees of successes have beenachieved over the years. However; few existing schemes address both efficiency andfairness over a wide range of work loads. Moreover; in order to obtain analytical results;most of them require prior information about jobs; which may be difficult to obtain in realapplications. This paper presents two novel adaptive scheduling algorithms--GRAD forcentralized scheduling; and WRAD for distributed scheduling. Both GRAD and WRADensure fair allocation under all levels of workload; and they offer provable efficiency withoutrequiring prior information of job's parallelism. Moreover; they provide effective control …,*,2007,4
Hyperdrive: Exploring hyperparameters with POP scheduling,Jeff Rasley; Yuxiong He; Feng Yan; Olatunji Ruwase; Rodrigo Fonseca,Abstract The quality of machine learning (ML) and deep learning (DL) models are verysensitive to many different adjustable parameters that are set before training even begins;commonly called hyperparameters. Efficient hyperparameter exploration is of greatimportance to practitioners in order to find high-quality models with affordable time and cost.This is however a challenging process due to a huge search space; expensive trainingruntime; sparsity of good configurations; and scarcity of time and resources. We develop ascheduling algorithm POP that quickly identifies among promising; opportunistic and poorconfigurations of hyperparameters. It infuses probabilistic model-based classification withdynamic scheduling and early termination to jointly optimize quality and cost. We also builda comprehensive hyperparameter exploration infrastructure; HyperDrive; to support …,Proceedings of the 18th ACM/IFIP/USENIX Middleware Conference,2017,3
Work stealing with parallelism feedback,Kunal Agrawal; Yuxiong He; Charles E Leiserson,Abstract ASteal is a randomized work-stealing thread scheduler for fork-join multithreadedjobs which provides continual parallelism feedback to a job scheduler in the form ofprocessor requests. The ASteal algorithm is appropriate for large parallel servers wheremany jobs share a common multiprocessor resource and in which the number of processorsavailable to a particular job may vary during the job's execution. Assuming that the jobscheduler never allots the job more processors than requested by the job's threadscheduler; ASteal guarantees that the job completes in near-optimal time while utilizing atleast a constant fraction of the allotted processors. Our analysis models the job scheduler asthe thread scheduler's adversary; challenging the thread scheduler to be robust to thesystem environment and the job scheduler's administrative policies. We analyze the …,Unpublished manuscripts,2006,3
Learning Intrinsic Sparse Structures within Long Short-term Memory,Wei Wen; Yuxiong He; Samyam Rajbhandari; Wenhan Wang; Fang Liu; Bin Hu; Yiran Chen; Hai Li,Abstract: Model compression is significant for wide adoption of Recurrent Neural Networks(RNNs) in both user devices possessing limited resources and in business clusters requiringquick responses to large-scale service requests. In this work; we focus on reducing the sizesof basic structures (including input updates; gates; hidden states; cell states and outputs)within Long Short-term Memory (LSTM) units; so as to learn homogeneously-sparse LSTMs.Independently reducing the sizes of those basic structures can result in unmatcheddimensions among them; and consequently; end up with illegal LSTM units. To overcomethis; we propose Intrinsic Sparse Structures (ISS) in LSTMs. By reducing one component ofISS; the sizes of basic structures are simultaneously reduced by one such that theconsistency of dimensions is maintained. By learning ISS within LSTM units; the eventual …,arXiv preprint arXiv:1709.05027,2017,2
Tool for Investigating the Performance of a Distributed Processing System,*,A performance investigation tool (PIT) is described herein for investigating the performanceof a distributed processing system (DPS). The PIT operates by first receiving inputinformation that describes a graph processing task to be executed using a plurality ofcomputing units. The PIT then determines; based on the input information; at least one time-based performance measure that describes the performance of a DPS that is capable ofperforming the graphical task. More specifically; the PIT can operate in a manual mode toexplore the behavior of a specified DPS; or in an automatic mode to find an optimal DPSfrom within a search space of candidate DPSs. A configuration system may then be used toconstruct a selected DPS; using the plurality of computing units. In one case; the graphprocessing task involves training a deep neural network model having a plurality of layers.,*,2016,2
System support for managing large graphs in the cloud,Sameh Elnikety; Yuxiong He,Large graphs are at the heart of online social networks and many other applicationsincluding routing in road networks and online collaboration systems. In this paper; we arguethat a novel distributed infrastructure is needed to manage and query large graphs to meetthe demands of these applications. In a public social network; a node represents an entitysuch as a person; event; or photo. An edge represents a binary relationship between twonodes indicating for example friendship; participation at an event or appearance in a photo.Both nodes and edges may have a set of attributes because they model real world entitiesand interactions. The resulting social graph is challenging to manage: It is too large tomanage on a single server; there are frequent updates and users want to pose ad-hocqueries. For example; a user may ask “which photos include me and my friends X and Y”;“ …,Proceedings of the NSF Workshop on Social Networks and Mobility in the Cloud,2012,2
Position Paper: Embracing Heterogeneity-Improving Energy Efficiency for Interactive Services on Heterogeneous Data Center Hardware.,Yuxiong He; Sameh Elnikety,Abstract Data centers today are heterogeneous: they have servers from multiple generationsand multiple vendors; server machines have multiple cores that are capable of running atdifference speeds; and some have general purpose graphics processing units (GPGPU).Hardware trends indicate that future processors will have heterogeneous cores with differentspeeds and capabilities. This environment enables new advances in power saving andapplication optimization. It also poses new challenges; as current systems software is ill-suited for heterogeneity. In this position paper; we focus on interactive applications andoutline some of the techniques to embrace heterogeneity. We show that heterogeneity canbe exploited to deliver interactive services in an energy-efficient manner. For example; ourinitial study suggests that neither high-end nor low-end servers alone are very effective in …,AI for Data Center Management and Cloud Computing,2011,2
Anchorage Capacity analysis using simulation,Shell Ying Huang; Wen Jing Hsu; Yuxiong He; Tiancheng Song; Charles De Souza; Rong Ye; Chuanyu Chen; Stuti Nautiyal,With the substantial growth in marine traffic; anchorage space is now in high demand incertain hub ports. To provide decision support for port authorities; we have analyzed theusage of anchorages in recent years. The demands on the anchorages arise from thedynamically changing vessel mix and similarly complex service patterns. The utilization andthe capacity of an anchorage space also depend heavily on the dispatching and allocationrules as well as the shape and areas of the anchorage. The complexity of the system studiedis therefore beyond the current analytical tools; and hence simulation provides an effectivemeans for the study. In this paper; we present a simulation-based capacity analysis onanchorages. The simulation model built is able to match the current scenarios well; and theanalysis by simulation proves very useful in assessing anchorage utilization and capacity …,*,2009,2
Exploiting heterogeneity for tail latency and energy efficiency,Md E Haque; Yuxiong He; Sameh Elnikety; Thu D Nguyen; Ricardo Bianchini; Kathryn S McKinley,Abstract Interactive service providers have strict requirements on high-percentile (tail)latency to meet user expectations. If providers meet tail latency targets with less energy; theyincrease profits; because energy is a significant operating expense. Unfortunately;optimizing tail latency and energy are typically conflicting goals. Our work resolves thisconflict by exploiting servers with per-core Dynamic Voltage and Frequency Scaling (DVFS)and Asymmetric Multicore Processors (AMPs). We introduce the Adaptive Slow-to-Fastscheduling framework; which matches the heterogeneity of the workload---a mix of short andlong requests---to the heterogeneity of the hardware---cores running at different speeds. Thescheduler prioritizes long requests to faster cores by exploiting the insight that long requestsreveal themselves. We use control theory to design threshold-based scheduling policies …,Proceedings of the 50th Annual IEEE/ACM International Symposium on Microarchitecture,2017,1
Optimizing CNNs on Multicores for Scalability; Performance and Goodput,Samyam Rajbhandari; Yuxiong He; Olatunji Ruwase; Michael Carbin; Trishul Chilimbi,Abstract Convolutional Neural Networks (CNN) are a class of Ar-tificial Neural Networks(ANN) that are highly efficient at the pattern recognition tasks that underlie difficult AI prob-lems in a variety of domains; such as speech recognition; object recognition; and naturallanguage processing. CNNs are; however; computationally intensive to train. This paperpresents the first characterization of the per-formance optimization opportunities for trainingCNNs on CPUs. Our characterization includes insights based on the structure of the networkitself (ie; intrinsic arithmetic inten-sity of the convolution and its scalability under parallelism)as well as dynamic properties of its execution (ie; sparsity of the computation). Given thischaracterization; we present an automatic framework called spg-CNN for optimizing CNNtraining on CPUs. It comprises of a computation scheduler for efficient parallel execution …,Proceedings of the Twenty-Second International Conference on Architectural Support for Programming Languages and Operating Systems,2017,1
SERF: efficient scheduling for fast deep neural network serving via judicious parallelism,Feng Yan; Olatunji Ruwase; Yuxiong He; Evgenia Smirni,Deep neural networks (DNNs) has enabled a variety of artificial intelligence applications.These applications are backed by large DNN models running in serving mode on a cloudcomputing infrastructure. Given the compute-intensive nature of large DNN models; a keychallenge for DNN serving systems is to minimize the request response latencies. Thispaper characterizes the behavior of different parallelism techniques for supporting scalableand responsive serving systems for large DNNs. We identify and model two importantproperties of DNN workloads: homogeneous request service demand; and interferenceamong requests running concurrently due to cache/memory contention. These propertiesmotivate the design of SERF; a dynamic scheduling framework that is powered by aninterference-aware queueing-based analytical model. We evaluate SERF in the context of …,High Performance Computing; Networking; Storage and Analysis; SC16: International Conference for,2016,1
Assigning jobs to heterogeneous processing modules,*,A processing system is described which assigns jobs to heterogeneous processingmodules. The processing system assigns jobs to the processing modules in a manner thatattempts to accommodate the service demands of the jobs; but without advance knowledgeof the service demands. In one case; the processing system implements the processingmodules as computing units that have different physical characteristics. Alternatively; or inaddition; the processing system may implement the processing modules as threads that areexecuted by computing units. Each thread which runs on a computing unit offers a level ofperformance that depends on a number of other threads that are simultaneously beingexecuted by the same computing unit.,*,2016,1
Exploiting Processor Heterogeneity for Interactive Systems,Shaolei Ren; Yuxiong He; Sameh Elnikety; Kathryn S McKinley,Abstract To add processing power under power constraints; emerging heterogeneousprocessors include fast and slow cores on the same chip. This paper demonstrates that thisheterogeneity is well suited to interactive data center workloads (eg; web search; onlinegaming; and financial trading) by observing and exploiting two workload properties.(1)These workloads may trade response quality for responsiveness.(2) The request servicedemand is unknown and varies widely with both short and long requests. Subject to per-server power constraints; traditional homogeneous processors either include a few high-power fast cores that deliver high quality responses or many low-power slow cores thatdeliver high throughput; but not both.,*,2013,1
Efficient Deep Neural Network Serving: Fast and Furious,Feng Yan; Yuxiong He; Olatunji Ruwase; Evgenia Smirni,The emergence of deep neural networks (DNNs) as a state-of-the-art machine learningtechnique has enabled a variety of artificial intelligence applications for image recognition;speech recognition and translation; drug discovery; and machine vision. These applicationsare backed by large DNN models running in serving mode on a cloud computinginfrastructure to process client inputs such as images; speech segments; and text segments.Given the compute-intensive nature of large DNN models; a key challenge for DNN servingsystems is to minimize the request response latencies. This work characterizes the behaviorof different parallelism techniques for supporting scalable and responsive serving systemsfor large DNNs. We identify and model two important properties of DNN workloads:homogeneous request service demand; and interference among requests running …,IEEE Transactions on Network and Service Management,2018,*
Swayam: distributed autoscaling to meet SLAs of machine learning inference services with resource efficiency,Arpan Gujarati; Sameh Elnikety; Yuxiong He; Kathryn S McKinley; Björn B Brandenburg,Abstract Developers use Machine Learning (ML) platforms to train ML models and thendeploy these ML models as web services for inference (prediction). A key challenge forplatform providers is to guarantee response-time Service Level Agreements (SLAs) forinference workloads while maximizing resource efficiency. Swayam is a fully distributedautoscaling framework that exploits characteristics of production ML inference workloads todeliver on the dual challenge of resource efficiency and SLA compliance. Our keycontributions are (1) model-based autoscaling that takes into account SLAs and MLinference workload characteristics;(2) a distributed protocol that uses partial load informationand prediction at frontends to provision new service instances; and (3) a backend self-decommissioning protocol for service instances. We evaluate Swayam on 15 popular …,Proceedings of the 18th ACM/IFIP/USENIX Middleware Conference,2017,*
Scheduling execution requests to allow partial results,*,The subject disclosure is directed towards scheduling requests using quality values that aredefined for partial responses to the requests. For each request in a queue; an associatedprocessing time is determined using a system load and/or the quality values. The associatedprocessing time is less than or equal to a service demand; which represents an amount oftime to produce a complete response.,*,2017,*
Workload analysis and caching strategies for search advertising systems,Conglong Li; David G Andersen; Qiang Fu; Sameh Elnikety; Yuxiong He,Abstract Search advertising depends on accurate predictions of user behavior and interest;accomplished today using complex and computationally expensive machine learningalgorithms that estimate the potential revenue gain of thousands of candidateadvertisements per search query. The accuracy of this estimation is important for revenue;but the cost of these computations represents a substantial expense; eg; 10% to 30% of thetotal gross revenue. Caching the results of previous computations is a potential path toreducing this expense; but traditional domain-agnostic and revenue-agnostic approaches todo so result in substantial revenue loss. This paper presents three domain-specific cachingmechanisms that successfully optimize for both factors. Simulations on a trace from the Bingadvertising system show that a traditional cache can reduce cost by up to 27.7% but has …,Proceedings of the 2017 Symposium on Cloud Computing,2017,*
Optimal Reissue Policies for Reducing Tail Latency,Tim Kaler; Yuxiong He; Sameh Elnikety,Abstract Interactive services send redundant requests to multiple different replicas to meetstringent tail latency requirements. These additional (reissue) requests mitigate the impact ofnon-deterministic delays within the system and thus increase the probability of receiving anon-time response. There are two existing approaches of using reissue requests to reducetail latency.(1) Reissue requests immediately to one or more replicas; which multiplies theload and runs the risk of overloading the system.(2) Reissue requests if not completed aftera fixed delay. The delay helps to bound the number of extra reissue requests; but it alsoreduces the chance for those requests to respond before a tail latency target.,Proceedings of the 29th ACM Symposium on Parallelism in Algorithms and Architectures,2017,*
Neural network training performance optimization framework,*,A neural network training tool selects from a plurality of parallelizing techniques and selectsfrom a plurality of forward-propagation computation techniques. The neural network trainingtool performs a forward-propagation phase to train a neural network using the selectedparallelizing technique and the selected forward-propagation computation technique basedon one or more inputs. Additionally; the neural network training tool selects from a pluralitycomputation techniques and from a plurality of parallelizing techniques for a backward-propagation phase. The neural network training tool performs a backward-propagationphase of training the neural network using the selected backward-propagation parallelizingtechnique and the selected backward-propagation computation technique to generate errorgradients and weight deltas and to update weights associated with one or more layers of …,*,2017,*
When Good Enough Is Better: Energy-Aware Scheduling for Multicore Servers,Xinning Hui; Zhihui Du; Jason Liu; Hongyang Sun; Yuxiong He; David A Bader,Power is a primary concern for mobile; cloud; and high-performance computing applications.Approximate computing refers to running applications to obtain results with tolerable errorsunder resource constraints; and it can be applied to balance energy consumption withservice quality. In this paper; we propose a" Good Enough (GE)" scheduling algorithm thatuses approximate computing to provide satisfactory QoS (Quality of Service) for interactiveapplications with significant energy savings. Given a user-specified quality level; the GEalgorithm works in the AES (Aggressive Energy Saving) mode for the majority of the time;neglecting the low-quality portions of the workload. When the perceived quality falls belowthe required level; the algorithm switches to the BQ (Best Quality) mode with a compensationpolicy. To avoid core speed thrashing between the two modes; GE employs a hybrid …,Parallel and Distributed Processing Symposium Workshops (IPDPSW); 2017 IEEE International,2017,*
Obtaining and Managing Answer Quality for Online Data-Intensive Services,Jaimie Kelley; Christopher Stewart; Nathaniel Morris; Devesh Tiwari; Yuxiong He; Sameh Elnikety,Abstract Online data-intensive (OLDI) services use anytime algorithms to compute over largeamounts of data and respond quickly. Interactive response times are a priority; so OLDIservices parallelize query execution across distributed software components and return besteffort answers based on the data so far processed. Omitted data from slow componentscould lead to better answers; but tracing online how much better the answers could be isdifficult. We propose Ubora; a design approach to measure the effect of slow-runningcomponents on the quality of answers. Ubora randomly samples online queries andexecutes them a second time. The first online execution omits data from slow componentsand provides interactive answers. The second execution uses mature results fromintermediate components completed after the online execution finishes. Ubora uses …,ACM Transactions on Modeling and Performance Evaluation of Computing Systems (TOMPECS),2017,*
Optimal Aggregation Policy for Reducing Tail Latency of Web Search (Tech-Report Version),Jeong-Min Yun; Yuxiong He; Sameh Elnikety; Shaolei Ren,Abstract A web search engine often employs partition-aggregate architecture; where anaggregator propagates a user query to all index serving nodes (ISNs) and collects theresponses from them. An aggregation policy determines how long the aggregators wait forthe ISNs before returning aggregated results to users; crucially affecting both query latencyand quality. Designing an aggregation policy is; however; challenging: Response latencyamong queries and among ISNs varies significantly; and aggregators lack of knowledgeabout when ISNs will respond. In this paper; we propose aggregation policies that minimizetail latency of search queries subject to search quality service level agreements (SLAs);combining data-driven offline analysis with online processing. Beginning with a singleaggregator; we formally prove the optimality of our policy: It achieves the offline optimal …,*,2015,*
Online Resource Management for Carbon-Neutral Cloud Computing,Kishwar Ahmed; Shaolei Ren; Yuxiong He; Athanasios V Vasilakos,Abstract The explosive growth of cloud computing services in recent years has led tosignificant expansion of data centers around the world and dramatically increased theoverall electricity consumption; thereby resulting in a huge carbon footprint and severelyimpacting environment. As a consequence; data center operators have been increasinglyurged to find effective solutions to achieve an overall net zero carbon footprint ie; carbonneutrality. The state-of-the-art research addresses carbon neutrality based on accurateprediction of long-term future information that is typically unavailable in practice. In thischapter; we propose a provably-efficient online algorithm; called COCA (optimizing for COstminimization and CArbon neutrality); which minimizes the operational cost while satisfyingthe carbon neutrality without long-term future information a priori and in the presence of …,*,2015,*
Topic 3: Scheduling and Load Balancing,Zhihui Du; Ramin Yahyapour; Yuxiong He; Nectarios Koziris; Bilha Mendelson; Veronika Sonigo; Achim Streit; Andrei Tchernykh,Abstract Despite significant effort parallel and distributed systems available today are still notfully utilized and exploited. Scheduling and load balancing techniques remain crucial forimplementing efficient parallel and distributed applications and for making best use ofexisting parallel and distributed systems. The need for such techniques intensifies with theforeseen advent of exa-scale computer systems with many core and acceleratorarchitectures. Similarly; cloud computing became a viable paradigm for some applications.Scheduling includes planning and optimization of the resource allocation as well as copingwith the dynamics of the systems. These topics have been subject for research for manydecades but remain one of the core topics in parallel and distributed computing.,European Conference on Parallel Processing,2013,*
A Novel Approach to Graph Isomorphism Based on Parameterized Matching,Juan Mendivelso; Sunghwan Kim; Sameh Elnikety; Yuxiong He; Yoan Pinzon,Abstract We propose a new approach to solve graph isomorphism using parameterizedmatching. To find isomorphism between two graphs; one graph is linearized; ie; representedas a graph walk that covers all nodes and edges such that each element is represented by aparameter. Next; we match the graph linearization on the second graph; searching for abijective function that maps each element of the first graph to an element of the secondgraph. We develop an efficient linearization algorithm that generates short linearization withan approximation guarantee; and develop a graph matching algorithm. We evaluate ourapproach experimentally on graphs of different types and sizes; and compare to theperformance of VF2; which is a prominent algorithm for graph isomorphism. Our empiricalmeasurements show that graph linearization finds a matching graph faster than VF2 in …,*,2013,*
Performance Inconsistency in Large Scale Data Processing Clusters,Mingyuan Xia; Nan Zhu; Yuxiong He; Sameh Elnikety; Xue Liu,Abstract A large shared computing platform is usually divided into several virtual clusters offixed sizes; and each virtual cluster is used by a team. A cluster scheduler dynamicallyallocates physical servers to the virtual clusters depending on their sizes and current jobdemands. In this paper; we show that current cluster schedulers; which optimize forinstantaneous fairness; cause performance inconsistency among the virtual clusters: Virtualclusters with similar loads see very different performance characteristics. We identify thisproblem by studying a production trace obtained from a large cluster and performing asimulation study. Our results demonstrate that when using an instantaneous-fairnessscheduler; a large VC that contributes more resources during underload periods can not beproperly rewarded during its overload periods. These results suggest that not using …,*,2013,*
Zeta: Scheduling Interactive Services with Partial Execution,Sameh Elnikety; James Larus; Chenyu Yan; Yuxiong He; Jim Larus,Abstract This paper presents a scheduling model for a class of interactive services in whichrequests are time bounded and lower result quality can be traded for shorter execution time.These applications include web search engines; finance servers; and other interactive; on-line services. We develop an efficient scheduling algorithm; Zeta; which allocates processortime among service requests to maximize the quality and minimize the variance of theresponse.,*,2012,*
Horton: Online Query Execution Engine for Large Distributed Graphs (Demo Track),Mohamed Sarwat; Sameh Elnikety; Yuxiong He; Gabriel Kliot,Abstract Large graphs are used in many applications; such as social networking. Themanagement of these graphs poses new challenges because such graphs are too large tofit on a single server. Current distributed techniques such as map-reduce and Pregel are notwell-suited for processing interactive adhoc queries against large graphs. In this paper wedemonstrate Horton; a distributed interactive query execution engine for large graphs.Horton defines a query language that allows expressing regular language reachabilityqueries and provides a query execution engine with a query optimizer that allows interactiveexecution of queries on large distributed graphs in parallel. In the demo; we show thefunctionality of Horton managing a large graph for a social networking application calledCodebook; in which a graph models data on software components; developers …,*,2012,*
Scheduling for data center interactive services,Yuxiong He; Sameh Elnikety,To service requests with high quality; web search servers keep average server utilizationlow. As servers become busy; queuing delays increase; and requests miss their deadlines;resulting in degraded quality of service with poor user experience and potential revenueloss. In this paper; we propose a group of scheduling algorithms that can produce partialanswers during overload. One of their key features is assigning processing time to eachrequest based on system load with the objective of maximizing overall quality of responses.We propose three scheduling algorithms-offline; online clairvoyant and onlinenonclairvoyant. For applications with concave quality profile; we prove that the offlinealgorithm is optimal. We show the effectiveness of the online algorithms by conducting asimulation study modeling a web search engine. Simulation results show a significant …,Communication; Control; and Computing (Allerton); 2011 49th Annual Allerton Conference on,2011,*
Computing the processor desires of jobs in an adaptively parallel scheduling environment,*,*,*,2008,*
Provably efficient adaptive scheduling of parallel jobs on multiprocessors,Yuxiong He,This thesis presents feedback-driven adaptive algorithms for efficient scheduling of paralleljobs on multiprogrammed multiprocessors.,*,2008,*
Provably-Efficient Online Adaptive Scheduling of Parallel Jobs Based on Simple Greedy Rules,Yuxiong He; Wen-Jing Hsu,Scheduling competing jobs on multiprocessors has always been an important issue forparallel and distributed systems. The challenge is to ensure overall system efficiency whileoffering a level of fairness to user jobs. Although various degrees of successes have beenachieved over the past decades; few existing schemes address both efficiency and fairnessover a wide range of work loads. Moreover; in order to obtain analytical results; many knownresults [22; 24; 7; 8; 17; 20; 23; 25; 33] require prior information about jobs such as jobs'release time; amount of work; parallelism profile; etc; which may be difficult to obtain in realapplications. This chapter describes a scheduling algorithm-GRAD; which offers provableefficiency in terms of makespan and mean response time by allotting each job a fair share ofprocessor resources. Our algorithm is non-clairvoyant [10; 6; 18; 12]; ie it assumes …,*,2008,*
On-the-fly Race Detection for Programs with Recursive Spawn-Sync Parallelism,Yuxiong He; Junqing Wang,Detecting data race is very important for debugging shared-memory parallel programs;because data races result in unintended nondeterministic execution of the program. Wepropose a dynamic on-the-fly race detection mechanism called Parallel Nondeterminator tocheck for determinacy races during the parallel execution of a program with recursive spawn-sync parallelism. A modified version of Nested Region Labeling scheme is developed for theconcurrency relationship test in the spawn-sync parallel structure. Through the identificationof Least Common Ancestor in the spawn tree; the Parallel Nondeterminator only needs tokeep two read access records and one write access record for each shared location. Thework and critical path in the instrumented codes are analyzed as well as time complexity andspace requirements. Let N denote the maximum depth of the recursion in the parallel …,*,2004,*
2015 IEEE 23rd International Symposium on Modeling; Analysis and Simulation of Computer and Telecommunication Systems (MASCOTS),Anshul Gandhi; Xi Zhang; Naman Mittal,Load Balancers (LBs) play a critical role in managing the performance and resourceutilization of distributed systems. However; developing efficient LBs for large; distributedclusters is challenging for several reasons:(i) large clusters require numerous schedulingdecisions per second;(ii) such clusters typically consist of heterogeneous servers that widelydiffer in their computing power; and...,*,*,*
Research Abstracts-2007,Kunal Agrawal; Yu Xiong He NUS; Wen Jing Hsu NTU; Charles E Leiserson; Jim Sukha; N Alon; Alexandr Andoni; Tali Kaufman; Kevin Matulef; Ronitt Rubinfeld; Ning Xie; Nadia M Benbernou; Erik D Demaine; Martin L Demaine,In this research; we address the problem of adaptive scheduling and resource allocation inthe domain of dynamic multithreading. Most existing parallel programming systems arenonadaptive; where each job is assigned a fixed number of processors. This policy placesthe burden of estimating the parallelism of the job on the programmer. In addition;nonadaptive scheduling may lead to a poor use of available resources. For example; if thejob's parallelism changes while the job is executing; or if the resources available in thesystem change; the job is still forced to run with the same number of processors as it wasallotted when it started executing. Nonadaptive allocation schemes may also lead to thestarvation of some jobs if other jobs are using all the processors in the system. A moreattractive model would be an adaptive model; where processors allotted to a job change …,*,*,*
Energy-Efficient Scheduling of Interactive Services on Heterogeneous Multicore Processors,Shaolei Ren; Yuxiong He; Sameh Elnikety,Abstract—A heterogeneous multicore processor has several cores that share the sameinstruction set architecture but run at different speeds and power consumption rates; offeringboth energy efficient cores and high-performance cores to applications. We show how toexploit such processors to make significant energy reduction to serve large interactiveworkloads such as web search by carefully scheduling requests. Scheduling is achallenging task. Intuitively; we want to run short requests on slow cores for energyefficiency and long requests on fast cores for timely responses. However; there are two keychallenges:(1) request service demands are unknown; and (2) the most appropriate core torun a request may be busy. We propose an online algorithm; Fast-Preempt-Slow (FPS);which improves response quality subject to deadline and total power constraints. We …,*,*,*
Non-clairvoyant Scheduling of Batched Parallel Jobs to Minimize Mean Response Time,Yuxiong He; Hongyang Sun; Wen-Jing Hsu,Abstract This paper presents a new scheduling algorithm RAD; and shows that RADefficiently schedules batched parallel jobs on multiprocessors. An early result by Deng et al.shows that Dynamic Equi-partitioning is 4-competitive for mean response time when thenumber of jobs is not more than the number of processors. Then; in STOC 97; Edmonds etal. show that the mean response time obtained by Equi-partitioning is 2+,*,*,*
Dynamic Processor Allocation for Adaptively Parallel Jobs,Kunal Agrawal; Yu Xiong He; Charles E Leiserson,In this research we address the problem of scheduling many adaptively parallel jobs on amultiprocessor system [4; 5; 6]. An adaptively parallel job is a job that can change itsparallelism in the course of its execution. Today; most multiprocessor systems use staticallocation; where a fixed number of processors is allocated to the job for its lifetime. Thispolicy places the burden of estimating the parallelism of the job on the programmer. Inaddition; since the parallelism of the job may change during execution; there are programsfor which any static allocation will lead to either inefficiency or unnecessary slowdown. Staticallocation schemes may also lead to the starvation of some jobs if other jobs are using allthe processors in the system. Ideally; we would like to adaptively change the number ofprocessors allotted to a particular job as the job's parallelism and the state of the system …,*,*,*
