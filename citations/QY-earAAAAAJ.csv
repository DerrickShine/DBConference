Probabilistic Inductive Logic Programming,Luc De Raedt; Kristian Kersting,Abstract Probabilistic inductive logic programming aka. statistical relational learningaddresses one of the central questions of artificial intelligence: the integration of probabilisticreasoning with machine learning and first order and relational logic representations. A richvariety of different formalisms and learning techniques have been developed. A unifyingcharacterization of the underlying learning settings; however; is missing so far. In thischapter; we start from inductive logic programming and sketch how the inductive logicprogramming formalisms; settings and techniques can be extended to the statistical case.More precisely; we outline three classical settings for inductive logic programming; namelylearning from entailment; learning from interpretations; and learning from proofs or traces;and show how they can be adapted to cover state-of-the-art statistical relational learning …,*,2008,382
Interpreting Bayesian logic programs,Kristian Kersting; Luc De Raedt; Stefan Kramer,Abstract Various proposals for combining first order logic with Bayesian nets exist. Weintroduce the formalism of Bayesian logic programs; which is basically a simplification andreformulation of Ngo and Haddawys probabilistic logic programs. However; Bayesian logicprograms are sufficiently powerful to represent essentially the same knowledge in a moreelegant manner. The elegance is illustrated by the fact that they can represent bothBayesian nets and definite clause programs (as in" pure" Prolog) and that their kernel inProlog is actually an adaptation of an usual Prolog meta-interpreter.,Proceedings of the AAAI-2000 workshop on learning statistical models from relational data,2000,335
Most likely heteroscedastic Gaussian process regression,Kristian Kersting; Christian Plagemann; Patrick Pfaff; Wolfram Burgard,Abstract This paper presents a novel Gaussian process (GP) approach to regression withinput-dependent noise rates. We follow Goldberg et al.'s approach and model the noisevariance using a second GP in addition to the GP governing the noise-free output value. Incontrast to Goldberg et al.; however; we do not use a Markov chain Monte Carlo method toapproximate the posterior noise variance but a most likely noise approach. The resultingmodel is easy to implement and can directly be used in combination with various existingextensions of the standard GPs such as sparse approximations. Extensive experiments onboth synthetic and real-world data; including a challenging perception problem in robotics;show the effectiveness of most likely heteroscedastic GP regression.,Proceedings of the 24th international conference on Machine learning,2007,191
Probabilistic logic learning,Luc De Raedt; Kristian Kersting,Abstract The past few years have witnessed an significant interest in probabilistic logiclearning; ie in research lying at the intersection of probabilistic reasoning; logicalrepresentations; and machine learning. A rich variety of different formalisms and learningtechniques have been developed. This paper provides an introductory survey and overviewof the state-of-the-art in probabilistic logic learning through the identification of a number ofimportant probabilistic; logical and learning concepts.,ACM SIGKDD Explorations Newsletter,2003,191
Lifted Probabilistic Inference with Counting Formulas.,Brian Milch; Luke S Zettlemoyer; Kristian Kersting; Michael Haimes; Leslie Pack Kaelbling,*,Aaai,2008,187
Bayesian Logic Programming: Theory and Tool,Kristian Kersting; Luc De Raedt,Bayesian networks provide an elegant formalism for representing and reasoning aboutuncertainty. They are a probabilistic extension of propositional logic and; hence; inheritsome of the limitations of propositional logic; such as the diﬃculties with representingobjects and relations. In this chapter; we introduce Bayesian logic programs; which are anextension of Bayesian networks to overcome these limitations. Bayesian logic programstightly integrate deﬁnite logic programs with Bayesian networks. The key idea underlyingBayesian logic programs is to establish a one-to-one mapping between ground atoms andrandom variables; and between the immediate consequence operator and the dependencyrelation. In doing so; Bayesian logic programs combine the advantages of both deﬁniteclause logic and Bayesian networks: notions of objects and relations; a separation of …,*,2007,165
Towards combining inductive logic programming with Bayesian networks,Kristian Kersting; Luc De Raedt,Abstract Recently; new representation languages that integrate first order logic withBayesian networks have been developed. Bayesian logic programs are one of theselanguages. In this paper; we present results on combining Inductive Logic Programming(ILP) with Bayesian networks to learn both the qualitative and the quantitative components ofBayesian logic programs. More precisely; we show how to combine the ILP setting learningfrom interpretations with score-based techniques for learning Bayesian networks. Thus; thepaper positively answers Koller and Pfeffer's question; whether techniques from ILP couldhelp to learn the logical component of first order probabilistic models.,International Conference on Inductive Logic Programming,2001,162
Counting belief propagation,Kristian Kersting; Babak Ahmadi; Sriraam Natarajan,Abstract A major benefit of graphical models is that most knowledge is captured in the modelstructure. Many models; however; produce inference problems with a lot of symmetries notreflected in the graphical structure and hence not exploitable by efficient inferencetechniques such as belief propagation (BP). In this paper; we present a new and simple BPalgorithm; called counting BP; that exploits such additional symmetries. Starting from a givenfactor graph; counting BP first constructs a compressed factor graph of clusternodes andclusterfactors; corresponding to sets of nodes and factors that are indistinguishable giventhe evidence. Then it runs a modified BP algorithm on the compressed graph that isequivalent to running BP on the original factor graph. Our experiments show that countingBP is applicable to a variety of important AI tasks such as (dynamic) relational models and …,Proceedings of the Twenty-Fifth Conference on Uncertainty in Artificial Intelligence,2009,140
Bellman goes relational,Kristian Kersting; Martijn Van Otterlo; Luc De Raedt,Abstract Motivated by the interest in relational reinforcement learning; we introduce a novelrelational Bellman update operator called REBEL. It employs a constraint logic programminglanguage to compactly represent Markov decision processes over relational domains. UsingREBEL; a novel value iteration algorithm is developed in which abstraction (over states andactions) plays a major role. This framework provides new insights into relationalreinforcement learning. Convergence results as well as experiments are presented.,Proceedings of the twenty-first international conference on Machine learning,2004,139
Logical hidden markov models,Kristian Kersting; Luc De Raedt; Tapani Raiko,Hidden Markov models (HMMs) (Rabiner & Juang; 1986) are extremely popular for an- alyzingsequential data. Application areas include computational biology; user modelling; speechrecognition; empirical natural language processing; and robotics. Despite their suc- cesses; HMMshave a major weakness: they handle only sequences of flat; ie; unstruc- tured symbols. Yet; inmany applications the symbols occurring in sequences are struc- tured. Consider; eg; sequencesof UNIX commands; which may have parameters such as emacs lohmms.tex;ls; latexlohmms.tex;...Thus; commands are essentially structured. Tasks that have been considered forUNIX command sequences include the prediction of the next command in the sequence (Davison& Hirsh; 1998); the classification of a command sequence in a user category (Korvemaker &Greiner; 2000; Jacobs & Blockeel; 2001); and anomaly detection (Lane; 1999) …,Journal of Artificial Intelligence Research,2006,107
Gradient-based boosting for statistical relational learning: The relational dependency network case,Sriraam Natarajan; Tushar Khot; Kristian Kersting; Bernd Gutmann; Jude Shavlik,Abstract Dependency networks approximate a joint probability distribution over multiplerandom variables as a product of conditional distributions. Relational Dependency Networks(RDNs) are graphical models that extend dependency networks to relational domains. Thishigher expressivity; however; comes at the expense of a more complex model-selectionproblem: an unbounded number of relational abstraction levels might need to be explored.Whereas current learning approaches for RDNs learn a single probability tree per randomvariable; we propose to turn the problem into a series of relational function-approximationproblems using gradient-based boosting. In doing so; one can easily induce highly complexfeatures over several iterations and in turn estimate quickly a very expressive model. Ourexperimental results in several different data sets show that this boosting method results …,Machine Learning,2012,102
Robust 3D scan point classification using associative Markov networks,Rudolph Triebel; Kristian Kersting; Wolfram Burgard,In this paper we present an efficient technique to learn associative Markov networks (AMNs)for the segmentation of 3D scan data. Our technique is an extension of the work recentlypresented by Anguelov et al.(2005); in which AMNs are applied and the learning is doneusing max-margin optimization. In this paper we show that by adaptively reducing thetraining data; the training process can be performed much more efficiently while stillachieving good classification results. The reduction is obtained by utilizing kd-trees andpruning them appropriately. Our algorithm does not require any additional parameters andyields an abstraction of the training data. In experiments with real data collected from amobile outdoor robot we demonstrate that our approach yields accurate segmentations,Robotics and Automation; 2006. ICRA 2006. Proceedings 2006 IEEE International Conference on,2006,98
nFOIL: integrating Naïve Bayes and FOIL,Niels Landwehr; Kristian Kersting; Luc De Raedt,Abstract We present the system nFOIL. It tightly integrates the naıve Bayes learning schemewith the inductive logic programming rule-learner FOIL. In contrast to previous combinations;which have employed naıve Bayes only for post-processing the rule sets; nFOIL employs thenaıve Bayes criterion to directly guide its search. Experimental evidence shows that nFOILperforms better than both its base line algorithm FOIL or the post-processing approach; andis at the same time competitive with more sophisticated approaches.,Proceedings of the twentieth national conference on artificial intelligence (AAAI-05),2005,90
Adaptive Bayesian logic programs,Kristian Kersting; Luc De Raedt,Abstract First order probabilistic logics combine a first order logic with a probabilisticknowledge representation. In this context; we introduce continuous Bayesian logicprograms; which extend the recently introduced Bayesian logic programs to deal withcontinuous random variables. Bayesian logic programs tightly integrate definite logicprograms with Bayesian networks. The resulting framework nicely seperates the qualitative(ie logical) component from the quantitative (ie the probabilistic) one. We also show how thequantitative component can be learned using a gradient-based maximum likelihood method.,International Conference on Inductive Logic Programming,2001,88
Lifted Probabilistic Inference.,Kristian Kersting,Abstract. Many AI problems arising in a wide variety of fields such as machine learning;semantic web; network communication; computer vision; and robotics can elegantly beencoded and solved using probabilistic graphical models. Often; however; we are facinginference problems with symmetries and redundancies only implicitly captured in the graphstructure and; hence; not exploitable by efficient inference approaches. A prominentexample are probabilistic logical models that tackle a long standing goal of AI; namelyunifying first-order logic—capturing regularities and symmetries—and probability—capturinguncertainty. Although they often encode large; complex models using few rules only and;hence; symmetries and redundancies abound; inference in them was originally still at thepropositional representation level and did not exploit symmetries. This paper is intended …,ECAI,2012,78
Integrating naive bayes and foil,Niels Landwehr; Kristian Kersting; Luc De Raedt,Abstract A novel relational learning approach that tightly integrates the naïve Bayes learningscheme with the inductive logic programming rule-learner FOIL is presented. In contrast toprevious combinations that have employed naïve Bayes only for post-processing the rulesets; the presented approach employs the naïve Bayes criterion to guide its search directly.The proposed technique is implemented in the NFOIL and TFOIL systems; which employstandard naïve Bayes and tree augmented naïve Bayes models respectively. We show thatthese integrated approaches to probabilistic model and rule learning outp erform post-processing approaches. They also yield significantly more accurate models than si mple rulelearning and are competitive with more sophisticated ILP systems.,Journal of Machine Learning Research,2007,77
Early drought stress detection in cereals: simplex volume maximisation for hyperspectral image analysis,Christoph Römer; Mirwaes Wahabzada; Agim Ballvora; Francisco Pinto; Micol Rossini; Cinzia Panigada; Jan Behmann; Jens Léon; Christian Thurau; Christian Bauckhage; Kristian Kersting; Uwe Rascher; Lutz Plümer,Early water stress recognition is of great relevance in precision plant breeding andproduction. Hyperspectral imaging sensors can be a valuable tool for early stress detectionwith high spatio-temporal resolution. They gather large; high dimensional data cubes posinga significant challenge to data analysis. Classical supervised learning algorithms often fail inapplied plant sciences due to their need of labelled datasets; which are difficult to obtain.Therefore; new approaches for unsupervised learning of relevant patterns are needed. Weapply for the first time a recent matrix factorisation technique; simplex volume maximisation(SiVM); to hyperspectral data. It is an unsupervised classification approach; optimised forfast computation of massive datasets. It allows calculation of how similar each spectrum is toobserved typical spectra. This provides the means to express how likely it is that one plant …,Functional Plant Biology,2012,72
Non-parametric policy gradients: A unified treatment of propositional and relational domains,Kristian Kersting; Kurt Driessens,Abstract Policy gradient approaches are a powerful instrument for learning how to interactwith the environment. Existing approaches have focused on propositional and continuousdomains only. Without extensive feature engineering; it is difficult-if not impossible-to applythem within structured domains; in which eg there is a varying number of objects andrelations among them. In this paper; we describe a non-parametric policy gradient approach-called NPPG-that overcomes this limitation. The key idea is to apply Friedmann's gradientboosting: policies are represented as a weighted sum of regression models grown in anstage-wise optimization. Employing off-the-shelf regression learners; NPPG can deal withpropositional; continuous; and relational domains in a unified way. Our experimental resultsshow that it can even improve on established results.,Proceedings of the 25th international conference on Machine learning,2008,68
Symbolic dynamic programming for first-order POMDPs,Scott Sanner; Kristian Kersting,Abstract Partially-observable Markov decision processes (POMDPs) provide a powerfulmodel for sequential decision-making problems with partially-observed state and are knownto have (approximately) optimal dynamic programming solutions. Much work in recent yearshas focused on improving the efficiency of these dynamic programming algorithms byexploiting symmetries and factored or relational representations. In this work; we show that itis also possible to exploit the full expressive power of first-order quantification to achievestate; action; and observation abstraction in a dynamic programming solution to relationallyspecified POMDPs. Among the advantages of this approach are the ability to maintaincompact value function representations; abstract over the space of potentially optimalactions; and automatically derive compact conditional policy trees that minimally partition …,*,2010,66
Parameter learning in probabilistic databases: A least squares approach,Bernd Gutmann; Angelika Kimmig; Kristian Kersting; Luc De Raedt,Abstract We introduce the problem of learning the parameters of the probabilistic databaseProbLog. Given the observed success probabilities of a set of queries; we compute theprobabilities attached to facts that have a low approximation error on the training examplesas well as on unseen examples. Assuming Gaussian error terms on the observed successprobabilities; this naturally leads to a least squares optimization problem. Our approach;called LeProbLog; is able to learn both from queries and from proofs and even from bothsimultaneously. This makes it flexible and allows faster training in domains where the proofsare available. Experiments on real world data show the usefulness and effectiveness of thisleast squares calibration of probabilistic databases.,Joint European Conference on Machine Learning and Knowledge Discovery in Databases,2008,64
How players lose interest in playing a game: An empirical study based on distributions of total playing times,Christian Bauckhage; Kristian Kersting; Rafet Sifa; Christian Thurau; Anders Drachen; Alessandro Canossa,Analyzing telemetry data of player behavior in computer games is a topic of increasinginterest for industry and research; alike. When applied to game telemetry data; patternrecognition and statistical analysis provide valuable business intelligence tools for gamedevelopment. An important problem in this area is to characterize how player engagement ina game evolves over time. Reliable models are of pivotal interest since they allow forassessing the long-term success of game products and can provide estimates of how longplayers may be expected to keep actively playing a game. In this paper; we introducemethods from random process theory into game data mining in order to draw inferencesabout player engagement. Given large samples (over 250;000 players) of behavioraltelemetry data from five different action-adventure and shooter games; we extract …,Computational Intelligence and Games (CIG); 2012 IEEE conference on,2012,62
Learning predictive terrain models for legged robot locomotion,Christian Plagemann; Sebastian Mischke; Sam Prentice; Kristian Kersting; Nicholas Roy; Wolfram Burgard,Legged robots require accurate models of their environment in order to plan and executepaths. We present a probabilistic technique based on Gaussian processes that allowsterrain models to be learned and updated efficiently using sparse approximation techniques.The major benefit of our terrain model is its ability to predict elevations at unseen locationsmore reliably than alternative approaches; while it also yields estimates of the uncertainty inthe prediction. In particular; our nonstationary Gaussian process model adapts itscovariance to the situation at hand; allowing more accurate inference of terrain height atpoints that have not been observed directly. We show how a conventional motion plannercan use the learned terrain model to plan a path to a goal location; using a terrain-specificcost model to accept or reject candidate footholds. In experiments with a real quadruped …,Intelligent Robots and Systems; 2008. IROS 2008. IEEE/RSJ International Conference on,2008,62
TildeCRF: Conditional random fields for logical sequences,Bernd Gutmann; Kristian Kersting,Abstract Conditional Random Fields (CRFs) provide a powerful instrument for labelingsequences. So far; however; CRFs have only been considered for labeling sequences overflat alphabets. In this paper; we describe TildeCRF; the first method for training CRFs onlogical sequences; ie; sequences over an alphabet of logical atoms. TildeCRF's key idea isto use relational regression trees in Dietterich et al.'s gradient tree boosting approach. Thus;the CRF potential functions are represented as weighted sums of relational regression trees.Experiments show a significant improvement over established results achieved with hiddenMarkov models and Fisher kernels for logical sequences.,European Conference on Machine Learning,2006,62
Descriptive matrix factorization for sustainability adopting the principle of opposites,Christian Thurau; Kristian Kersting; Mirwaes Wahabzada; Christian Bauckhage,Abstract Climate change; the global energy footprint; and strategies for sustainabledevelopment have become topics of considerable political and public interest. The publicdebate is informed by an exponentially growing amount of data and there are diversepartisan interest when it comes to interpretation. We therefore believe that data analysismethods are called for that provide results which are intuitively understandable even to non-experts. Moreover; such methods should be efficient so that non-experts users can performtheir own analysis at low expense in order to understand the effects of different parametersand influential factors. In this paper; we discuss a new technique for factorizing data matricesthat meets both these requirements. The basic idea is to represent a set of data by means ofconvex combinations of extreme data points. This often accommodates human cognition …,Data Mining and Knowledge Discovery,2012,60
Learning markov logic networks via functional gradient boosting,Tushar Khot; Sriraam Natarajan; Kristian Kersting; Jude Shavlik,Recent years have seen a surge of interest in Statistical Relational Learning (SRL) modelsthat combine logic with probabilities. One prominent example is Markov Logic Networks(MLNs). While MLNs are indeed highly expressive; this expressiveness comes at a cost.Learning MLNs is a hard problem and therefore has attracted much interest in the SRLcommunity. Current methods for learning MLNs follow a two-step approach: first; perform asearch through the space of possible clauses and then learn appropriate weights for theseclauses. We propose to take a different approach; namely to learn both the weights and thestructure of the MLN simultaneously. Our approach is based on functional gradient boostingwhere the problem of learning MLNs is turned into a series of relational functionalapproximation problems. We use two kinds of representations for the gradients: clause …,Data Mining (ICDM); 2011 IEEE 11th International Conference on,2011,57
Convex non-negative matrix factorization in the wild,Christian Thurau; Kristian Kersting; Christian Bauckhage,Non-negative matrix factorization (NMF) has recently received a lot of attention in datamining; information retrieval; and computer vision. It factorizes a non-negative input matrix Vinto two non-negative matrix factors V= WH such that W describes" clusters" of the datasets.Analyzing genotypes; social networks; or images; it can be beneficial to ensure V to containmeaningful``cluster centroids''; ie; to restrict W to be convex combinations of data points. Buthow can we run this convex NMF in the wild; ie; given millions of data points? Triggered bythe simple observation that each data point is a convex combination of vertices of the dataconvex hull; we propose to restrict W further to be vertices of the convex hull. The benefits ofthis convex-hull NMF approach are twofold. First; the expected size of the convex hull of thecandidate set typically grows much slower than the data set. Second; distance preserving …,Data Mining; 2009. ICDM'09. Ninth IEEE International Conference on,2009,54
Multi-Relational Learning with Gaussian Processes.,Zhao Xu; Kristian Kersting; Volker Tresp,Abstract Due to their flexible nonparametric nature; Gaussian process models are veryeffective at solving hard machine learning problems. While existing Gaussian processmodels focus on modeling one single relation; we present a generalized GP model; namedmulti-relational Gaussian process model; that is able to deal with an arbitrary number ofrelations in a domain of interest. The proposed model is analyzed in the context of bipartite;directed; and undirected univariate relations. Experimental results on real-world datasetsshow that exploiting the correlations among different entity types and relations can indeedimprove prediction performance.,IJCAI,2009,54
Nonstationary Gaussian process regression using point estimates of local smoothness,Christian Plagemann; Kristian Kersting; Wolfram Burgard,Abstract Gaussian processes using nonstationary covariance functions are a powerful toolfor Bayesian regression with input-dependent smoothness. A common approach is to modelthe local smoothness by a latent process that is integrated over using Markov chain MonteCarlo approaches. In this paper; we demonstrate that an approximation that uses theestimated mean of the local smoothness yields good results and allows one to employefficient gradient-based optimization techniques for jointly learning the parameters of thelatent and the observed processes. Extensive experiments on both synthetic and real-worlddata; including challenging problems in robotics; show the relevance and feasibility of ourapproach.,Joint European Conference on Machine Learning and Knowledge Discovery in Databases,2008,54
Gaussian Beam Processes: A Nonparametric Bayesian Measurement Model for Range Finders.,Christian Plagemann; Kristian Kersting; Patrick Pfaff; Wolfram Burgard,Abstract—In probabilistic mobile robotics; the development of measurement models plays acrucial role as it directly influences the efficiency and the robustness of the robot'sperformance in a great variety of tasks including localization; tracking; and map building. Inthis paper; we present a novel probabilistic measurement model for range finders; calledGaussian beam processes; which treats the measurement modeling task as anonparametric Bayesian regression problem and solves it using Gaussian processes. Themajor benefit of our approach is its ability to generalize over entire range scans directly. Thisway; we can learn the distributions of range measurements for whole regions of the robot'sconfiguration space from only few recorded or simulated range scans. Especially inapproximative approaches to state estimation like particle filtering or histogram filtering …,Robotics: Science and Systems,2007,54
Yes we can: simplex volume maximization for descriptive web-scale matrix factorization,Christian Thurau; Kristian Kersting; Christian Bauckhage,Abstract Matrix factorization methods are among the most common techniques for detectinglatent components in data. Popular examples include the Singular Value Decomposition orNon-negative Matrix Factorization. Unfortunately; most methods suffer from highcomputational complexity and therefore do not scale to massive data. In this paper; wepresent a linear time algorithm for the factorization of gigantic matrices that iteratively yieldslatent components. We consider a constrained matrix factorization st~ the latent componentsform a simplex that encloses most of the remaining data. The algorithm maximizes thevolume of that simplex and thereby reduces the displacement of data from the spacespanned by the latent components. Hence; it also lowers the Frobenius norm; a commoncriterion for matrix factorization quality. Our algorithm is efficient; well-grounded in …,Proceedings of the 19th ACM international conference on Information and knowledge management,2010,51
Predicting player churn in the wild,Fabian Hadiji; Rafet Sifa; Anders Drachen; Christian Thurau; Kristian Kersting; Christian Bauckhage,Free-to-Play or “freemium” games represent a fundamental shift in the business models ofthe game industry; facilitated by the increasing use of online distribution platforms and theintroduction of increasingly powerful mobile platforms. The ability of a game developmentcompany to analyze and derive insights from behavioral telemetry is crucial to the success ofthese games which rely on in-game purchases and in-game advertising to generaterevenue; and for the company to remain competitive in a global marketplace. The ability tomodel; understand and predict future player behavior has a crucial value; allowingdevelopers to obtain data-driven insights to inform design; development and marketingstrategies. One of the key challenges is modeling and predicting player churn. This paperpresents the first cross-game study of churn prediction in Free-to-Play games. Churn in …,Computational intelligence and games (CIG); 2014 IEEE conference on,2014,49
Imitation learning in relational domains: A functional-gradient boosting approach,Sriraam Natarajan; Saket Joshi; Prasad Tadepalli; Kristian Kersting; Jude Shavlik,Abstract Imitation learning refers to the problem of learning how to behave by observing ateacher in action. We consider imitation learning in relational domains; in which there is avarying number of objects and relations among them. In prior work; simple relational policiesare learned by viewing imitation learning as supervised learning of a function from states toactions. For propositional worlds; functional gradient methods have been proved to bebeneficial. They are simpler to implement than most existing methods; more efficient; morenaturally satisfy common constraints on the cost function; and better represent our priorbeliefs about the form of the function. Building on recent generalizations of functionalgradient boosting to relational representations; we implement a functional gradient boostingapproach to imitation learning in relational domains. In particular; given a set of traces …,IJCAI Proceedings-International Joint Conference on Artificial Intelligence,2011,49
Basic principles of learning Bayesian logic programs,Kristian Kersting; Luc De Raedt,Abstract Bayesian logic programs tightly integrate definite logic programs with Bayesiannetworks in order to incorporate the notions of objects and relations into Bayesian networks.They establish a one-to-one mapping between ground atoms and random variables; andbetween the immediate consequence operator and the directly influenced by relation. Indoing so; they nicely separate the qualitative (ie logical) component from the quantitative (iethe probabilistic) one providing a natural framework to describe general; probabilisticdependencies among sets of random variables. In this chapter; we present results oncombining Inductive Logic Programming with Bayesian networks to learn both the qualitativeand the quantitative components of Bayesian logic programs from data. More precisely; weshow how the qualitative components can be learned by combining the inductive logic …,*,2008,48
Basic principles of learning Bayesian logic programs,Kristian Kersting; Luc De Raedt,Abstract Bayesian logic programs tightly integrate definite logic programs with Bayesiannetworks in order to... In this paper; we present results on combining Inductive LogicProgramming with Bayesian networks to learn both the qualitative and the quantitativecomponents of Bayesian logic programs from data. More precisely; we show how thequalitative components can be learned by combining the inductive logic programmingsetting learning from interpretations with score-based techniques for learning Bayesiannetworks. The estimation of the quantitative components is reduced to the correspondingproblem of (dynamic) Bayesian networks,Institute for Computer Science; University of Freiburg,2002,48
Towards discovering structural signatures of protein folds based on logical hidden markov models,Kristian Kersting; Tapani Raiko; Stefan Kramer; Luc De Raedt,Abstract With the growing number of determined protein structures and the availability ofclassification schemes; it becomes increasingly important to develop computer methods thatautomatically extract structural signatures for classes of proteins. In this paper; we introduceand apply a new Machine Learning technique; Logical Hidden Markov Models (LOHMMs);to the task of finding structural signatures of folds according to the classification schemeSCOP. Our results indicate that LOHMMs are applicable to this task and possess severaladvantages over other approaches.,*,2002,45
Mathematical Models of Fads Explain the Temporal Dynamics of Internet Memes.,Christian Bauckhage; Kristian Kersting; Fabian Hadiji,Abstract Internet memes are a pervasive phenomenon on the social Web. They typicallyconsist of viral catch phrases; images; or videos that spread through instantmessaging;(micro) blogs; forums; and social networking sites. Due to their popularity andproliferation; Internet memes attract interest in areas as diverse as marketing; sociology; orcomputer science and have been dubbed a new form of communication or artisticexpression. In this paper; we examine the merits of such claims and analyze how collectiveattention into Internet memes evolves over time. We introduce and discuss statistical modelsof the dynamics of fads and fit them to meme related time series obtained from GoogleTrends. Given data as to more than 200 memes; we find that our models provide moreaccurate descriptions of the dynamics of growth and decline of collective attention to …,ICWSM,2013,44
Logical hierarchical hidden markov models for modeling user activities,Sriraam Natarajan; Hung H Bui; Prasad Tadepalli; Kristian Kersting; Weng-Keen Wong,Abstract Hidden Markov Models (HMM) have been successfully used in applications such asspeech recognition; activity recognition; bioinformatics etc. There have been previousattempts such as Hierarchical HMMs and Abstract HMMs to elegantly extend HMMs atmultiple levels of temporal abstraction (for example to represent the user's activities).Similarly; there has been previous work such as Logical HMMs on extending HMMs todomains with relational structure. In this work we develop a representation that naturallycombines the power of both relational and hierarchical models in the form of LogicalHierarchical Hidden Markov Models (LoHiHMMs). LoHiHMMs inherit the compactness ofrepresentation from Logical HMMs and the tractability of inference from Hierarchical HMMs.We outline two inference algorithms: one based on grounding the LoHiHMM to a …,International Conference on Inductive Logic Programming,2008,44
Logical Markov decision programs and the convergence of logical TD (λ),Kristian Kersting; Luc De Raedt,Abstract Recent developments in the area of relational reinforcement learning (RRL) haveresulted in a number of new algorithms. A theory; however; that explains why RRL works;seems to be lacking. In this paper; we provide some initial results on a theory of RRL. Torealize this; we introduce a novel representation formalism; called logical Markov decisionprograms (LOMDPs); that integrates Markov Decision Processes (MDPs) with LogicPrograms. Using LOMDPs one can compactly and declaratively represent complex MDPs.Within this framework we then devise a relational upgrade of TD (λ) called logical TD (λ) andprove convergence. Experiments validate our approach.,International Conference on Inductive Logic Programming,2004,44
Exploiting symmetries for scaling loopy belief propagation and relational training,Babak Ahmadi; Kristian Kersting; Martin Mladenov; Sriraam Natarajan,Abstract Judging by the increasing impact of machine learning on large-scale data analysisin the last decade; one can anticipate a substantial growth in diversity of the machinelearning applications for “big data” over the next decade. This exciting new opportunity;however; also raises many challenges. One of them is scaling inference within and trainingof graphical models. Typical ways to address this scaling issue are inference byapproximate message passing; stochastic gradients; and MapReduce; among others. Often;we encounter inference and training problems with symmetries and redundancies in thegraph structure. A prominent example are relational models that capture complexity.Exploiting these symmetries; however; has not been considered for scaling yet. In this paper;we show that inference and training can indeed benefit from exploiting symmetries …,Machine learning,2013,42
Analysis of respiratory pressure–volume curves in intensive care medicine using inductive machine learning,Steven Ganzert; Josef Guttmann; Kristian Kersting; Ralf Kuhlen; Christian Putensen; Michael Sydow; Stefan Kramer,Abstract We present a case study of machine learning and data mining in intensive caremedicine. In the study; we compared different methods of measuring pressure–volumecurves in artificially ventilated patients suffering from the adult respiratory distress syndrome(ARDS). Our aim was to show that inductive machine learning can be used to gain insightsinto differences and similarities among these methods. We defined two tasks: the first onewas to recognize the measurement method producing a given pressure–volume curve. Thiswas defined as the task of classifying pressure–volume curves (the classes being themeasurement methods). The second was to model the curves themselves; that is; to predictthe volume given the pressure; the measurement method and the patient data. Clearly; thiscan be defined as a regression task. For these two tasks; we applied C5. 0 and CUBIST …,Artificial intelligence in medicine,2002,40
Statistical relational artificial intelligence: Logic; probability; and computation,Luc De Raedt; Kristian Kersting; Sriraam Natarajan; David Poole,Abstract An intelligent agent interacting with the real world will encounter individual people;courses; test results; drugs prescriptions; chairs; boxes; etc.; and needs to reason aboutproperties of these individuals and relations among them as well as cope with uncertainty.Uncertainty has been studied in probability theory and graphical models; and relations havebeen studied in logic; in particular in the predicate calculus and its extensions. This bookexamines the foundations of combining logic and probability into what are called relationalprobabilistic models. It introduces representations; inference; and learning techniques forprobability; logic; and their combinations. The book focuses on two representations in detail:Markov logic networks; a relational extension of undirected graphical models and weightedfirst-order predicate calculus formula; and Problog; a probabilistic extension of logic …,Synthesis Lectures on Artificial Intelligence and Machine Learning,2016,37
Hyperspectral phenotyping on the microscopic scale: towards automated characterization of plant-pathogen interactions,Matheus Kuska; Mirwaes Wahabzada; Marlene Leucker; Heinz-Wilhelm Dehne; Kristian Kersting; Erich-Christian Oerke; Ulrike Steiner; Anne-Katrin Mahlein,The detection and characterization of resistance reactions of crop plants against fungalpathogens are essential to select resistant genotypes. In breeding practice phenotyping ofplant genotypes is realized by time consuming and expensive visual rating. In this contexthyperspectral imaging (HSI) is a promising non-invasive sensor technique in order toaccelerate and to automate classical phenotyping methods. A hyperspectral microscopewas established to determine spectral changes on the leaf and cellular level of barley(Hordeum vulgare) during resistance reactions against powdery mildew (Blumeria graminisf. sp. hordei; isolate K1). Experiments were conducted with near isogenic barley lines of cv.Ingrid; including the susceptible wild type (WT); mildew locus a 12 (Mla12 based resistance)and the resistant mildew locus o 3 (mlo3 based resistance); respectively. The reflection of …,Plant Methods,2015,37
Lifted Linear Programming,Martin Mladenov; Babak Ahmadi; Kristian Kersting,Abstract Lifted inference approaches have rendered large; previously intractableprobabilistic inference problems quickly solvable by handling whole sets ofindistinguishable objects together. Triggered by this success; we show that anotherimportant AI technique is liftable; too; namely linear programming. Intuitively; given a linearprogram (LP); we employ a lifted variant of Gaussian belief propagation (GaBP) to solve thesystems of linear equations arising when running an interiorpoint method to solve the LP.However; this naıve solution cannot make use of standard solvers for linear equations and isdoomed to construct lifted networks in each iteration of the interior-point method again; anoperation that can itself be quite costly. To address both issues; we show how to read off anequivalent LP from the lifted GaBP computations that can be solved using any off-the …,JMLR: W&CP,2012,37
Multi-evidence lifted message passing; with application to pagerank and the kalman filter,Babak Ahmadi; Kristian Kersting; Scott Sanner,Abstract Lifted message passing algorithms exploit repeated structure within a givengraphical model to answer queries efficiently. Given evidence; they construct a lifted networkof supernodes and superpotentials corresponding to sets of nodes and potentials that areindistinguishable given the evidence. Recently; efficient algorithms were presented forupdating the structure of an existing lifted network with incremental changes to the evidence.In the inference stage; however; current algorithms need to construct a separate liftednetwork for each evidence case and run a modified message passing algorithm on eachlifted network separately. Consequently; symmetries across the inference tasks are notexploited. In this paper; we present a novel lifted message passing technique that exploitssymmetries across multiple evidence cases. The benefits of this multi-evidence lifted …,IJCAI Proceedings-International Joint Conference on Artificial Intelligence,2011,37
Compressing probabilistic Prolog programs,Luc De Raedt; Kristian Kersting; Angelika Kimmig; Kate Revoredo; Hannu Toivonen,Abstract ProbLog is a recently introduced probabilistic extension of Prolog (De Raedt; et al.in Proceedings of the 20th international joint conference on artificial intelligence; pp. 2468–2473; 2007). A ProbLog program defines a distribution over logic programs by specifying foreach clause the probability that it belongs to a randomly sampled program; and theseprobabilities are mutually independent. The semantics of ProbLog is then defined by thesuccess probability of a query in a randomly sampled program. This paper introduces thetheory compression task for ProbLog; which consists of selecting that subset of clauses of agiven ProbLog program that maximizes the likelihood wrt a set of positive and negativeexamples. Experiments in the context of discovering links in real biological networksdemonstrate the practical applicability of the approach.,Machine Learning,2008,37
Learning relational navigation policies,Alexandru Cocora; Kristian Kersting; Christian Plagemann; Wolfram Burgard; Luc De Raedt,Navigation is one of the fundamental tasks for a mobile robot. The majority of path planningapproaches has been designed to entirely solve the given problem from scratch given thecurrent and goal configurations of the robot. Although these approaches yield highly efficientplans; the computed policies typically do not transfer to other; similar tasks. We propose tolearn relational decision trees as abstract navigation strategies from example paths.Relational abstraction has several interesting and important properties. First; it allows amobile robot to generalize navigation plans from specific examples provided by users orexploration. Second; the navigation policy learned in one environment can be transferred tounknown environments. In several experiments with real robots in a real environment and insimulated runs; we demonstrate the usefulness of our approach,Intelligent Robots and Systems; 2006 IEEE/RSJ International Conference on,2006,36
Efficient graph kernels by randomization,Marion Neumann; Novi Patricia; Roman Garnett; Kristian Kersting,Abstract Learning from complex data is becoming increasingly important; and graph kernelshave recently evolved into a rapidly developing branch of learning on structured data.However; previously proposed kernels rely on having discrete node label information. In thispaper; we explore the power of continuous node-level features for propagation-based graphkernels. Specifically; propagation kernels exploit node label distributions from propagationschemes like label propagation; which naturally enables the construction of graph kernelsfor partially labeled graphs. In order to efficiently extract graph features from continuousnode label distributions; and in general from continuous vector-valued node attributes; weutilize randomized techniques; which easily allow for deriving similarity measures based onpropagated information. We show that propagation kernels utilizing locality-sensitive …,Joint European Conference on Machine Learning and Knowledge Discovery in Databases,2012,34
Convex non-negative matrix factorization for massive datasets,Christian Thurau; Kristian Kersting; Mirwaes Wahabzada; Christian Bauckhage,Abstract Non-negative matrix factorization (NMF) has become a standard tool in data mining;information retrieval; and signal processing. It is used to factorize a non-negative data matrixinto two non-negative matrix factors that contain basis elements and linear coefficients;respectively. Often; the columns of the first resulting factor are interpreted as “clustercentroids” of the input data; and the columns of the second factor are understood to containcluster membership indicators. When analyzing data such as collections of geneexpressions; documents; or images; it is often beneficial to ensure that the resulting clustercentroids are meaningful; for instance; by restricting them to be convex combinations of datapoints. However; known approaches to convex-NMF suffer from high computational costsand therefore hardly apply to large-scale data analysis problems. This paper presents a …,Knowledge and information systems,2011,34
Probabilistic Inductive Logic Programming-Theory and Applications,LD Raedt; Paolo Frasconi; Kristian Kersting; Stephen Muggleton,*,Lecture Notes in Computer Science,2008,34
Exploration in relational domains for model-based reinforcement learning,Tobias Lang; Marc Toussaint; Kristian Kersting,Abstract A fundamental problem in reinforcement learning is balancing exploration andexploitation. We address this problem in the context of model-based reinforcement learningin large stochastic relational domains by developing relational extensions of the concepts ofthe E 3 and R-MAX algorithms. Efficient exploration in exponentially large state spacesneeds to exploit the generalization of the learned model: what in a propositional settingwould be considered a novel situation and worth exploration may in the relational setting bea well-known context in which exploitation is promising. To address this we introducerelational count functions which generalize the classical notion of state and action visitationcounts. We provide guarantees on the exploration efficiency of our framework using countfunctions under the assumption that we had a relational KWIK learner and a near-optimal …,Journal of Machine Learning Research,2012,33
Metro maps of plant disease dynamics—automated mining of differences using hyperspectral images,Mirwaes Wahabzada; Anne-Katrin Mahlein; Christian Bauckhage; Ulrike Steiner; Erich-Christian Oerke; Kristian Kersting,Understanding the response dynamics of plants to biotic stress is essential to improvemanagement practices and breeding strategies of crops and thus to proceed towards a moresustainable agriculture in the coming decades. In this context; hyperspectral imaging offers aparticularly promising approach since it provides non-destructive measurements of plantscorrelated with internal structure and biochemical compounds. In this paper; we present acascade of data mining techniques for fast and reliable data-driven sketching of complexhyperspectral dynamics in plant science and plant phenotyping. To achieve this; we build ontop of a recent linear time matrix factorization technique; called Simplex VolumeMaximization; in order to automatically discover archetypal hyperspectral signatures that arecharacteristic for particular diseases. The methods were applied on a data set of barley …,PLoS One,2015,32
An Inductive Logic programming Approach to Statistical Relational Learning,Kristian Kersting,Abstract It has been a great pleasure to be asked to write the preface for the book based onKristian Kersting's thesis. There is no doubt in my mind that this is a remarkable andoutstanding piece of work. In his thesis Kristian has made an assault on one of the hardestintegration problems at the heart of Artificial Intelligence research. This involves taking threedisparate major areas of research and attempting a fusion among them. The three areas are:Logic Programming; Uncertainty Reasoning and Machine Learning. Every one of these is amajor sub-area of research with its own associated international research conferences.Having taken on such a Herculean task; Kristian has produced a series of widely publishedresults which are now at the core of a newly emerging area: Probabilistic Inductive LogicProgramming. The new area is closely tied to; though strictly subsumes; a new field …,*,2006,32
Logical markov decision programs,Kristian Kersting; Luc De Raedt,Abstract Motivated by the interest in relational reinforcement learning; we introduce a novelrepresentation formalism; called logical Markov decision programs (LOMDPs); thatintegrates Markov Decision Processes with Logic Programs. Using LOMDPs one cancompactly and declaratively represent complex relational Markov decision processes. Withinthis framework we then develop a theory of reinforcement learning in which abstraction (ofstates and actions) plays a major role. Various convergence results are presented; as wellas some experiments that validate the approach. The theory presented should provide asound basis for further developments in relational reinforcement learning.,Proceedings of the IJCAI’03 Workshop on Learning Statistical Models of Relational Data,2003,32
A Bayesian regression approach to terrain mapping and an application to legged robot locomotion,Christian Plagemann; Sebastian Mischke; Sam Prentice; Kristian Kersting; Nicholas Roy; Wolfram Burgard,Abstract We deal with the problem of learning probabilistic models of terrain surfaces fromsparse and noisy elevation measurements. The key idea is to formalize this as a regressionproblem and to derive a solution based on nonstationary Gaussian processes. We describehow to achieve a sparse approximation of the model; which makes the model applicable toreal-world data sets. The main benefits of our model are that (1) it does not require adiscretization of space;(2) it also provides the uncertainty for its predictions; and (3) it adaptsits covariance function to the observed data; allowing more accurate inference of terrainelevation at points that have not been observed directly. As a second contribution; wedescribe how a legged robot equipped with a laser range finder can utilize the developedterrain model to plan and execute a path over rough terrain. We show how a motion …,Journal of Field Robotics,2009,29
'Say EM'for selecting probabilistic models for logical sequences,Kristian Kersting; Tapani Raiko,Abstract: Many real world sequences such as protein secondary structures or shell logsexhibit a rich internal structures. Traditional probabilistic models of sequences; however;consider sequences of flat symbols only. Logical hidden Markov models have beenproposed as one solution. They deal with logical sequences; ie; sequences over analphabet of logical atoms. This comes at the expense of a more complex model selectionproblem. Indeed; different abstraction levels have to be explored. In this paper; we proposea novel method for selecting logical hidden Markov models from data called SAGEM.SAGEM combines generalized expectation maximization; which optimizes parameters; withstructure search for model selection using inductive logic programming refinementoperators. We provide convergence and experimental results that show SAGEM's …,arXiv preprint arXiv:1207.1353,2012,27
Kernel conditional quantile estimation via reduction revisited,Novi Quadrianto; Kristian Kersting; Mark D Reid; Tibério S Caetano; Wray L Buntine,Quantile regression refers to the process of estimating the quantiles of a conditionaldistribution and has many important applications within econometrics and data mining;among other domains. In this paper; we show how to estimate these conditional quantilefunctions within a Bayes risk minimization framework using a Gaussian process prior. Theresulting non-parametric probabilistic model is easy to implement and allows non-crossingquantile functions to be enforced. Moreover; it can directly be used in combination with toolsand extensions of standard Gaussian Processes such as principled hyperparameterestimation; sparsification; and quantile regression with input-dependent noise rates. Noexisting approach enjoys all of these desirable properties. Experiments on benchmarkdatasets show that our method is competitive with state-of-the-art approaches.",Data Mining; 2009. ICDM'09. Ninth IEEE International Conference on,2009,27
Automated interpretation of 3D laserscanned point clouds for plant organ segmentation,Mirwaes Wahabzada; Stefan Paulus; Kristian Kersting; Anne-Katrin Mahlein,Plant organ segmentation from 3D point clouds is a relevant task for plant phenotyping andplant growth observation. Automated solutions are required to increase the efficiency ofrecent high-throughput plant phenotyping pipelines. However; plant geometrical propertiesvary with time; among observation scales and different plant types. The main objective of thepresent research is to develop a fully automated; fast and reliable data driven approach forplant organ segmentation. The automated segmentation of plant organs usingunsupervised; clustering methods is crucial in cases where the goal is to get fast insightsinto the data or no labeled data is available or costly to achieve. For this we propose andcompare data driven approaches that are easy-to-realize and make the use of standardalgorithms possible. Since normalized histograms; acquired from 3D point clouds; can be …,BMC bioinformatics,2015,26
Predicting purchase decisions in mobile free-to-play games,Rafet Sifa; Fabian Hadiji; Julian Runge; Anders Drachen; Kristian Kersting; Christian Bauckhage,Abstract Mobile digital games are dominantly released under the freemium business model;but only a small fraction of the players makes any purchases. The ability to predict who willmake a purchase enables optimization of marketing efforts; and tailoring customerrelationship management to the specific user's profile. Here this challenge is addressed viatwo models for predicting purchasing players; using a 100;000 player dataset: 1) Aclassification model focused on predicting whether a purchase will occur or not. 2) aregression model focused on predicting the number of purchases a user will make. Bothmodels are presented within a decision and regression tree framework for building rules thatare actionable by companies. To the best of our knowledge; this is the first studyinvestigating purchase decisions in freemium mobile products from a user behavior …,Proc. of AAAI AIIDE,2015,26
Boosting relational sequence alignments,Andreas Karwath; Kristian Kersting; Niels Landwehr,The task of aligning sequences arises in many applications. Classical dynamicprogramming approaches require the explicit state enumeration in the reward model. This isoften impractical: the number of states grows very quickly with the number of domain objectsand relations among these objects. Relational sequence alignment aims at exploitingsymbolic structure to avoid the full enumeration. This comes at the expense of a morecomplex reward model selection problem: virtually infinitely many abstraction levels have tobe explored. In this paper; we apply gradient-based boosting to leverage this problem.Specifically; we show how to reduce the learning problem to a series of relationalregressions problems. The main benefit of this is that interactions between states variablesare introduced only as needed; so that the potentially infinite search space is not explicitly …,Data Mining; 2008. ICDM'08. Eighth IEEE International Conference on,2008,26
Modeling semantic cognition as logical dimensionality reduction,Yarden Katz; Noah D Goodman; Kristian Kersting; Charles Kemp; Joshua B Tenenbaum,Abstract Semantic knowledge is often expressed in the form of intuitive theories; whichorganize; predict and explain our observations of the world. How are these powerfulknowledge structures represented and acquired? We present a framework; logicaldimensionality reduction; that treats theories as compressive probabilistic models;attempting to express observed data as a sample from the logical consequences of thetheory's underlying laws and a small number of core facts. By performing Bayesian learningand inference on these models we combine important features of more familiar connectionistand symbolic approaches to semantic cognition: an ability to handle graded; uncertaininferences; together with systematicity and compositionality that support appropriateinferences from sparse observations in novel contexts.,Proceedings of the Annual Meeting of the Cognitive Science Society,2008,26
Dimension reduction via colour refinement,Martin Grohe; Kristian Kersting; Martin Mladenov; Erkal Selman,Abstract Colour refinement is a basic algorithmic routine for graph isomorphism testing;appearing as a subroutine in almost all practical isomorphism solvers. It partitions thevertices of a graph into “colour classes” in such a way that all vertices in the same colourclass have the same number of neighbours in every colour class. There is a tightcorrespondence between colour refinement and fractional isomorphisms of graphs; whichare solutions to the LP relaxation of a natural ILP formulation of graph isomorphism. Weintroduce a version of colour refinement for matrices and extend existing quasilinearalgorithms for computing the colour classes. Then we generalise the correspondencebetween colour refinement and fractional automorphisms and develop a theory of fractionalautomorphisms and isomorphisms of matrices. We apply our results to reduce the …,European Symposium on Algorithms,2014,25
Informed Lifting for Message-Passing.,Kristian Kersting; Youssef El Massaoudi; Fabian Hadiji; Babak Ahmadi,Abstract Lifted inference; handling whole sets of indistinguishable objects together; is criticalto the effective application of probabilistic relational models to realistic real world tasks.Recently; lifted belief propagation (LBP) has been proposed as an efficient approximatesolution of this inference problem. It runs a modified BP on a lifted network where nodeshave been grouped together if they have—roughly speaking—identical computation trees;the tree-structured unrolling of the underlying graph rooted at the nodes. In many situations;this purely syntactic criterion is too pessimistic: message errors decay along paths.Intuitively; for a long chain graph with weak edge potentials; distant nodes will send andreceive identical messages yet their computation trees are quite different. To overcome this;we propose iLBP; a novel; easy-to-implement; informed LBP approach that interleaves …,AAAI,2010,24
Fisher kernels for logical sequences,Kristian Kersting; Thomas Gärtner,Abstract One approach to improve the accuracy of classifications based on generativemodels is to combine them with successful discriminative algorithms. Fisher kernels weredeveloped to combine generative models with a currently very popular class of learningalgorithms; kernel methods. Empirically; the combination of hidden Markov models withsupport vector machines has shown promising results. So far; however; Fisher kernels haveonly been considered for sequences over flat alphabets. This is mostly due to the lack of amethod for computing the gradient of a generative model over structured sequences. In thispaper; we show how to compute the gradient of logical hidden Markov models; which allowfor the modelling of logical sequences; ie; sequences over an alphabet of logical atoms.Experiments show a considerable improvement over results achieved without Fisher …,European Conference on Machine Learning,2004,24
Mind the nuisance: Gaussian process classification using privileged noise,Daniel Hernández-Lobato; Viktoriia Sharmanska; Kristian Kersting; Christoph H Lampert; Novi Quadrianto,Abstract The learning with privileged information setting has recently attracted a lot ofattention within the machine learning community; as it allows the integration of additionalknowledge into the training process of a classifier; even when this comes in the form of adata modality that is not available at test time. Here; we show that privileged information cannaturally be treated as noise in the latent function of a Gaussian process classifier (GPC).That is; in contrast to the standard GPC setting; the latent function is not just a nuisance but afeature: it becomes a natural measure of confidence about the training data by modulatingthe slope of the GPC probit likelihood function. Extensive experiments on public datasetsshow that the proposed GPC method using privileged noise; called GPC+; improves over astandard GPC without privileged knowledge; and also over the current state-of-the-art …,Advances in Neural Information Processing Systems,2014,23
Lifted Online Training of Relational Models with Stochastic Gradients,B Ahmadi; K Kersting; S Natarajan,*,Proceedings of the European Conference on Machine Learning  and Principles and Practice of Knowledge Discovery in Databases (ECML PKDD);,2012,23
Hierarchical convex NMF for clustering massive data,Kristian Kersting; Mirwaes Wahabzada; Christian Thurau; Christian Bauckhage,Abstract We present an extension of convex-hull non-negative matrix factorization (CH-NMF)which was recently proposed as a large scale variant of convex non-negative matrixfactorization or Archetypal Analysis. CHNMF factorizes a non-negative data matrix V into twonon-negative matrix factors V= WH such that the columns of W are convex combinations ofcertain data points so that they are readily interpretable to data analysts. There is; however;no free lunch: imposing convexity constraints on W typically prevents adaptation to intrinsic;low dimensional structures in the data. Alas; in cases where the data is distributed in a non-convex manner or consists of mixtures of lower dimensional convex distributions; the clusterrepresentatives obtained from CH-NMF will be less meaningful. In this paper; we present ahierarchical CH-NMF that automatically adapts to internal structures of a dataset; hence it …,Proceedings of 2nd Asian Conference on Machine Learning,2010,23
Fast active exploration for link-based preference learning using gaussian processes,Zhao Xu; Kristian Kersting; Thorsten Joachims,Abstract In preference learning; the algorithm observes pairwise relative judgments(preference) between items as training data for learning an ordering of all items. This is animportant learning problem for applications where absolute feedback is difficult to elicit; butpairwise judgments are readily available (eg; via implicit feedback [13]). While it was alreadyshown that active learning can effectively reduce the number of training pairs needed; themost successful existing algorithms cannot generalize over items or queries. Consideringweb search as an example; they would need to learn a separate relevance score for eachdocument-query pair from scratch. To overcome this inefficiency; we propose a link-basedactive preference learning method based on Gaussian Processes (GPs) that incorporatesdependency information from both feature-vector representations as well as relations …,Joint European Conference on Machine Learning and Knowledge Discovery in Databases,2010,23
Self-Taught Decision Theoretic Planning with First Order Decision Diagrams.,Saket Joshi; Kristian Kersting; Roni Khardon,Abstract We present a new paradigm for planning by learning; where the planner is given amodel of the world and a small set of states of interest; but no indication of optimal actions inthese states. The additional information can help focus the planner on regions of the statespace that are of interest and lead to improved performance. We demonstrate this idea byintroducing novel model-checking reduction operations for First Order Decision Diagrams(FODD); a representation that has been used to implement decision-theoretic planning withRelational Markov Decision Processes (RMDP). Intuitively; these reductions modify theconstruction of the value function by removing any complex specifications that are irrelevantto the set of training examples; thereby focusing on the region of interest. We show that suchtraining examples can be constructed on the fly from a description of the planning …,ICAPS,2010,23
Stacked Gaussian process learning,Marion Neumann; Kristian Kersting; Zhao Xu; Daniel Schulz,Triggered by a market relevant application that involves making joint predictions ofpedestrian and public transit flows in urban areas; we address the question of how to utilizehidden common cause relations among variables of interest in order to improveperformance in the two related regression tasks. Specifically; we propose stacked Gaussianprocess learning; a meta-learning scheme in which a base Gaussian process is enhancedby adding the posterior covariance functions of other related tasks to its covariance functionin a stage-wise optimization. The idea is that the stacked posterior covariances encode thehidden common causes among variables of interest that are shared across the relatedregression tasks. Stacked Gaussian process learning is efficient; capable of capturingshared common causes; and can be implemented with any kind of standard Gaussian …,Data Mining; 2009. ICDM'09. Ninth IEEE International Conference on,2009,23
Generalized First Order Decision Diagrams for First Order Markov Decision Processes.,Saket Joshi; Kristian Kersting; Roni Khardon,Abstract First order decision diagrams (FODD) were recently introduced as a compactknowledge representation expressing functions over relational structures. FODDs representnumerical functions that; when constrained to the Boolean range; use only existentialquantification. Previous work developed a set of operations over FODDs; showed how theycan be used to solve relational Markov decision processes (RMDP) using dynamicprogramming algorithms; and demonstrated their success in solving stochastic planningproblems from the International Planning Competition in the system FODD-Planner. Acrucial ingredient of this scheme is a set of operations to remove redundancy in decisiondiagrams; thus keeping them compact. This paper makes three contributions. First; weintroduce Generalized FODDs (GFODD) and combination algorithms for them …,IJCAI,2009,23
Power Iterated Color Refinement.,Kristian Kersting; Martin Mladenov; Roman Garnett; Martin Grohe,Abstract Color refinement is a basic algorithmic routine for graph isomorphism testing andhas recently been used for computing graph kernels as well as for lifting belief propagationand linear programming. So far; color refinement has been treated as a combinatorialproblem. Instead; we treat it as a nonlinear continuous optimization problem and prove that itimplements a conditional gradient optimizer that can be turned into graph clusteringapproaches using hashing and truncated power iterations. This shows that color refinementis easy to understand in terms of random walks; easy to implement (matrix-matrix/vectormultiplications) and readily parallelizable. We support our theoretical results withexperiments on real-world graphs with millions of edges.,AAAI,2014,22
Relational Logistic Regression.,Seyed Mehran Kazemi; David Buchman; Kristian Kersting; Sriraam Natarajan; David Poole,Abstract Logistic regression is a commonly used representation for aggregators in Bayesianbelief networks when a child has multiple parents. In this paper we consider extendinglogistic regression to relational models; where we want to model varying populations andinteractions among parents. In this paper; we first examine the representational problemscaused by population variation. We show how these problems arise even in simple caseswith a single parametrized parent; and propose a linear relational logistic regression whichwe show can represent arbitrary linear (in population size) decision thresholds; whereas thetraditional logistic regression cannot. Then we examine representing interactions among theparents of a child node; and representing non-linear dependency on population size. Wepropose a multi-parent relational logistic regression which can represent interactions …,KR,2014,21
Propagation kernels: efficient graph kernels from propagated information,Marion Neumann; Roman Garnett; Christian Bauckhage; Kristian Kersting,Abstract We introduce propagation kernels; a general graph-kernel framework for efficientlymeasuring the similarity of structured data. Propagation kernels are based on monitoringhow information spreads through a set of given graphs. They leverage early-stagedistributions from propagation schemes such as random walks to capture structuralinformation encoded in node labels; attributes; and edge information. This has two benefits.First; off-the-shelf propagation schemes can be used to naturally construct kernels for manygraph types; including labeled; partially labeled; unlabeled; directed; and attributed graphs.Second; by leveraging existing efficient and informative propagation schemes; propagationkernels can be considerably faster than state-of-the-art approaches without sacrificingpredictive performance. We will also show that if the graphs at hand have a regular …,Machine Learning,2016,20
Collective attention to social media evolves according to diffusion models,Christian Bauckhage; Kristian Kersting; Bashir Rastegarpanah,Abstract We investigate patterns of adoption of 175 social media services and Webbusinesses using data from Google Trends. For each service; we collect aggregated searchfrequencies from 45 countries as well as global averages. This results in more than 8.000time series which we analyze using economic diffusion models. The models are found toprovide accurate and statistically significant fits to the data and show that collective attentionto social media grows and subsides in a highly regular manner. Regularities persist acrossregions; cultures; and topics and thus hint at general mechanisms that govern the adoptionof Web-based services.,Proceedings of the 23rd International Conference on World Wide Web,2014,20
Perception beyond the Here and Now,Albrecht Schmidt; Marc Langheinrich; Kristian Kersting,Page 1. COMPUTER 86 INVISIBLE COMPUTING Published by the IEEE Computer Society0018-9162/11/$26.00 © 2011 IEEE Perception beyond the Here and Now A multitude ofsenses pro- vide us with information about the here and now. What we see; hear; and feelin turn shape how we perceive our surroundings and understand the world. Our sensesare extremely limited; however; and ever since humans began creating and using technology;they have tried to enhance their nat- ural perception in various ways. For example; hilltopcastles and watch towers were early means to look farther into the distance; while opticalinstruments such as telescopes and microscopes enable us to see objects that are too faraway or too small to be seen with the naked eye …,IEEE Computer,2011,20
Plant phenotyping using probabilistic topic models: uncovering the hyperspectral language of plants,Mirwaes Wahabzada; Anne-Katrin Mahlein; Christian Bauckhage; Ulrike Steiner; Erich-Christian Oerke; Kristian Kersting,Abstract Modern phenotyping and plant disease detection methods; based on opticalsensors and information technology; provide promising approaches to plant research andprecision farming. In particular; hyperspectral imaging have been found to revealphysiological and structural characteristics in plants and to allow for tracking physiologicaldynamics due to environmental effects. In this work; we present an approach to plantphenotyping that integrates non-invasive sensors; computer vision; as well as data miningtechniques and allows for monitoring how plants respond to stress. To uncover latenthyperspectral characteristics of diseased plants reliably and in an easy-to-understand way;we “wordify” the hyperspectral images; ie; we turn the images into a corpus of textdocuments. Then; we apply probabilistic topic models; a well-established natural …,Scientific reports,2016,19
Larger residuals; less work: Active document scheduling for latent Dirichlet allocation,Mirwaes Wahabzada; Kristian Kersting,Abstract Recently; there have been considerable advances in fast inference for latentDirichlet allocation (LDA). In particular; stochastic optimization of the variational Bayes (VB)objective function with a natural gradient step was proved to converge and able to processmassive document collections. To reduce noise in the gradient estimation; it considersmultiple documents chosen uniformly at random. While it is widely recognized that thescheduling of documents in stochastic optimization may have significant consequences; thisissue remains largely unexplored. In this work; we address this issue. Specifically; wepropose residual LDA; a novel; easy-to-implement; LDA approach that schedulesdocuments in an informed way. Intuitively; in each iteration; residual LDA actively selectsdocuments that exert a disproportionately large influence on the current residual to …,Joint European Conference on Machine Learning and Knowledge Discovery in Databases,2011,19
Relational sequence learning,Kristian Kersting; Luc De Raedt; Bernd Gutmann; Andreas Karwath; Niels Landwehr,Abstract Sequential behavior and sequence learning are essential to intelligence. Often theelements of sequences exhibit an internal structure that can elegantly be represented usingrelational atoms. Applying traditional sequential learning techniques to such relationalsequences requires one either to ignore the internal structure or to live with a combinatorialexplosion of the model complexity. This chapter briefly reviews relational sequence learningand describes several techniques tailored towards realizing this; such as local patternmining techniques;(hidden) Markov models; conditional random fields; dynamicprogramming and reinforcement learning.,*,2008,19
Poisson dependency networks: Gradient boosted models for multivariate count data,Fabian Hadiji; Alejandro Molina; Sriraam Natarajan; Kristian Kersting,Abstract Although count data are increasingly ubiquitous; surprisingly little work hasemployed probabilistic graphical models for modeling count data. Indeed the univariatecase has been well studied; however; in many situations counts influence each other andshould not be considered independently. Standard graphical models such as multinomial orGaussian ones are also often ill-suited; too; since they disregard either the infinite rangeover the natural numbers or the potentially asymmetric shape of the distribution of countvariables. Existing classes of Poisson graphical models can only model negative conditionaldependencies or neglect the prediction of counts or do not scale well. To ease the modelingof multivariate count data; we therefore introduce a novel family of Poisson graphicalmodels; called Poisson Dependency Networks (PDNs). A PDN consists of a set of local …,Machine Learning,2015,18
Statistical relational learning,Luc De Raedt; Kristian Kersting,Samuel's Checkers Player is the first machine learning system that received publicrecognition. It pioneered many important ideas in game playing and machine learning. Tetwo main papers describing his research (Samuel;;) became landmark papers in ArtificialIntelligence. In one game; the resulting program was able to beat one of America's bestplayers of the time.,*,2011,18
Multi-agent inverse reinforcement learning,Sriraam Natarajan; Gautam Kunapuli; Kshitij Judah; Prasad Tadepalli; Kristian Kersting; Jude Shavlik,Learning the reward function of an agent by observing its behavior is termed inversereinforcement learning and has applications in learning from demonstration orapprenticeship learning. We introduce the problem of multi-agent inverse reinforcementlearning; where reward functions of multiple agents are learned by observing theiruncoordinated behavior. A centralized controller then learns to coordinate their behavior byoptimizing a weighted sum of reward functions of all the agents. We evaluate our approachon a traffic-routing domain; in which a controller coordinates actions of multiple traffic signalsto regulate traffic density. We show that the learner is not only able to match but evensignificantly outperform the expert.,Machine Learning and Applications (ICMLA); 2010 Ninth International Conference on,2010,18
Exploiting causal independence in Markov logic networks: Combining undirected and directed models,Sriraam Natarajan; Tushar Khot; Daniel Lowd; Prasad Tadepalli; Kristian Kersting; Jude Shavlik,Abstract A new method is proposed for compiling causal independencies into Markov logicnetworks (MLNs). An MLN can be viewed as compactly representing a factorization of a jointprobability into the product of a set of factors guided by logical formulas. We present a notionof causal independence that enables one to further factorize the factors into a combination ofeven smaller factors and consequently obtain a finer-grain factorization of the jointprobability. The causal independence lets us specify the factor in terms of weighted; directedclauses and operators; such as “or”;“sum” or “max”; on the contribution of the variablesinvolved in the factors; hence combining both undirected and directed knowledge. Ourexperimental evaluations shows that making use of the finer-grain factorization provided bycausal independence can improve quality of parameter learning in MLNs.,Joint European Conference on Machine Learning and Knowledge Discovery in Databases,2010,18
Beyond 2D-grids: a dependence maximization view on image browsing,Novi Quadrianto; Kristian Kersting; Tinne Tuytelaars; Wray L Buntine,Abstract Ideally; one would like to perform image search using an intuitive and friendlyapproach. Many existing image search engines; however; present users with sets of imagesarranged in some default order on the screen; typically the relevance to a query; only. Whilethis certainly has its advantages; arguably; a more flexible and intuitive way would be to sortimages into arbitrary structures such as grids; hierarchies; or spheres so that images that arevisually or semantically alike are placed together. This paper focuses on designing such anavigation system for image browsers. This is a challenging task because arbitrary layoutstructure makes it difficult--if not impossible--to compute cross-similarities between imagesand structure coordinates; the main ingredient of traditional layouting approaches. For thisreason; we resort to a recently developed machine learning technique: kernelized sorting …,Proceedings of the international conference on Multimedia information retrieval,2010,18
Learning preferences with hidden common cause relations,Kristian Kersting; Zhao Xu,Abstract Gaussian processes have successfully been used to learn preferences amongentities as they provide nonparametric Bayesian approaches for model selection andprobabilistic inference. For many entities encountered in real-world applications; however;there are complex relations between them. In this paper; we present a preference modelwhich incorporates information on relations among entities. Specifically; we propose aprobabilistic relational kernel model for preference learning based on Silva et al.'s mixedgraph Gaussian processes: a new prior distribution; enhanced with relational graph kernels;is proposed to capture the correlations between preferences. Empirical analysis on theLETOR datasets demonstrates that relational information can improve the performance ofpreference learning.,Joint European Conference on Machine Learning and Knowledge Discovery in Databases,2009,18
Fisher kernels for relational data,Uwe Dick; Kristian Kersting,Abstract Combining statistical and relational learning receives currently a lot of attention.The majority of statistical relational learning approaches focus on density estimation. Forclassification; however; it is well-known that the performance of such generative models isoften lower than that of discriminative classifiers. One approach to improve the performanceof generative models is to combine them with discriminative algorithms. Fisher kernels weredeveloped to combine them with kernel methods; and have shown promising results for thecombinations of support vector machines with (logical) hidden Markov models and Bayesiannetworks. So far; however; Fisher kernels have not been considered for relational data; ie;data consisting of a collection of objects and relational among these objects. In this paper;we develop Fisher kernels for relational data and empirically show that they can …,European Conference on Machine Learning,2006,18
Data mining and pattern recognition in agriculture,Christian Bauckhage; Kristian Kersting,Abstract Modern communication; sensing; and actuator technologies as well as methodsfrom signal processing; pattern recognition; and data mining are increasingly applied inagriculture. Developments such as increased mobility; wireless networks; newenvironmental sensors; robots; and the computational cloud put the vision of a sustainableagriculture for anybody; anytime; and anywhere within reach. Yet; precision farming is afundamentally new domain for computational intelligence and constitutes a trulyinterdisciplinary venture. Accordingly; researchers and experts of complementary skills haveto cooperate in order to develop models and tools for data intensive discovery that allow foroperation through users that are not necessarily trained computer scientists. We presentapproaches and applications that address these challenges and underline the potential …,KI-Künstliche Intelligenz,2013,17
Exploration in relational worlds,Tobias Lang; Marc Toussaint; Kristian Kersting,Abstract One of the key problems in model-based reinforcement learning is balancingexploration and exploitation. Another is learning and acting in large relational domains; inwhich there is a varying number of objects and relations between them. We provide one ofthe first solutions to exploring large relational Markov decision processes by developingrelational extensions of the concepts of the Explicit Explore or Exploit (E 3) algorithm. A keyinsight is that the inherent generalization of learnt knowledge in the relational representationhas profound implications also on the exploration strategy: what in a propositional settingwould be considered a novel situation and worth exploration may in the relational setting bean instance of a well-known context in which exploitation is promising. Our experimentalevaluation shows the effectiveness and benefit of relational exploration over several …,European Conference on Machine Learning and Knowledge Discovery in Databases (ECML PKDD),2010,17
Social network mining with nonparametric relational models,Zhao Xu; Volker Tresp; Achim Rettinger; Kristian Kersting,Abstract Statistical relational learning (SRL) provides effective techniques to analyze socialnetwork data with rich collections of objects and complex networks. Infinite hidden relationalmodels (IHRMs) introduce nonparametric mixture models into relational learning and havebeen successful in many relational applications. In this paper we explore the modeling andanalysis of complex social networks with IHRMs for community detection; link prediction andproduct recommendation. In an IHRM-based social network model; each edge is associatedwith a random variable and the probabilistic dependencies between these random variablesare specified by the model; based on the relational structure. The hidden variables; one foreach object; are able to transport information such that non-local probabilistic dependenciescan be obtained. The model can be used to predict entity attributes; to predict …,*,2010,17
Gradient-based boosting for statistical relational learning: the Markov logic network and missing data cases,Tushar Khot; Sriraam Natarajan; Kristian Kersting; Jude Shavlik,Abstract Recent years have seen a surge of interest in Statistical Relational Learning (SRL)models that combine logic with probabilities. One prominent and highly expressive SRLmodel is Markov Logic Networks (MLNs); but the expressivity comes at the cost of learningcomplexity. Most of the current methods for learning MLN structure follow a two-stepapproach where first they search through the space of possible clauses (ie structures) andthen learn weights via gradient descent for these clauses. We present a functional-gradientboosting algorithm to learn both the weights (in closed form) and the structure of the MLNsimultaneously. Moreover most of the learning approaches for SRL apply the closed-worldassumption; ie; whatever is not observed is assumed to be false in the world. We attempt toopen this assumption. We extend our algorithm for MLN structure learning to handle …,Machine Learning,2015,16
Learning to hash logistic regression for fast 3D scan point classification,Jens Behley; Kristian Kersting; Dirk Schulz; Volker Steinhage; Armin B Cremers,Segmenting range data into semantic categories has become a more and more active fieldof research in robotics. In this paper; we advocate to view this task as a problem of fast; large-scale retrieval. Intuitively; given a dataset of millions of labeled scan points and theirneighborhoods; we simply search for similar points in the datasets and use the labels of theretrieved ones to predict the labels of a novel point using some local prediction model suchas majority vote or logistic regression. However; actually carrying this out requires highlyefficient ways of (1) storing millions of scan points in memory and (2) quickly finding similarscan points to a target scan point. In this paper; we propose to address both issues byemploying Weiss et al.'s recent spectral hashing. It represents each item in a database by acompact binary code that is constructed so that similar items will have similar binary code …,Intelligent Robots and Systems (IROS); 2010 IEEE/RSJ International Conference on,2010,16
Parameter estimation in ProbLog from annotated queries,Bernd Gutmann; Angelika Kimmig; Kristian Kersting; Luc De Raedt,Abstract: We introduce the problem of learning the parameters of the probabilistic databaseProbLog. Given the observed success probabilities of a set of queries; we compute theunobserved probabilities attached to facts that have a low approximation error on thetraining examples as well as on unseen examples. The objective function to be minimized isthe squared-error between the measured and computed values of the queries. As we willshow; our approach is able to learn both from queries and from proofs and even from bothsimultaneously. This makes it flexible and allows faster training in domains where proofs areavailable. Experiments on real world data show the usefulness and effectiveness of thisleast squares calibration of probabilistic databases.,*,2010,16
Towards learning stochastic logic programs from proof-banks,Luc De Raedt; Kristian Kersting; Sunna Torge,Abstract Stochastic logic programs combine ideas from probabilistic grammars with theexpressive power of definite clause logic; as such they can be considered as an extension ofprobabilistic context-free grammars. Motivated by an analogy with learning tree-bankgrammars; we study how to learn stochastic logic programs from proof-trees. Using proof-trees as examples imposes strong logical constraints on the structure of the target stochasticlogic program. These constraints can be integrated in the least general generalization (lgg)operator; which is employed to traverse the search space. Our implementation employs agreedy search guided by the maximum likelihood principle and failure-adjustedmaximization. We also report on a number of simple experiments that show the promise ofthe approach.,PROCEEDINGS OF THE NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE,2005,16
Balios–the engine for Bayesian logic programs,Kristian Kersting; Uwe Dick,Abstract Inductive Logic Programming (ILP)[4] combines techniques from machine learningwith the representation of logic programming. It aims at inducing logical clauses; ie; generalrules from specific observations and background knowledge. Because of focusing on logicalclauses; traditional ILP systems do not model uncertainty explicitly. On the other hand; state-of-the-art probabilistic models such as Bayesian networks (BN)[5]; hidden Markov models;and stochastic context-free grammars have a rigid structure and therefore have problemsrepresenting a variable number of objects and relations among these objects. Recently;various relational extensions of traditional probabilistic models have been proposed; see [1]for an overview. The newly emerging field of stochastic relational learning (SRL) studieslearning such rich probabilistic models.,European Conference on Principles of Data Mining and Knowledge Discovery,2004,16
The Weibull as a model of shortest path distributions in random networks,Christian Bauckhage; Kristian Kersting; Bashir Rastegarpanah,ABSTRACT We address the problem of characterizing shortest path histograms of networksin terms of continuous; analytically tractable distributions. Based on a recent model for theexpected number of paths between arbitrary vertices in random networks; we establish theWeibull distribution as the corresponding distribution of minimal path lengths. Empirical testswith different graph topologies confirm our theoretical prediction. Our methodology allows forcomputing non-linear low dimensional embeddings of path histograms for visual analytics.,Proc. Int. Workshop on Mining and Learning with Graphs; Chicago; IL; USA,2013,15
Boosting relational dependency networks,Sriraam Natarajan; Tushar Khot; Kristian Kersting; Bernd Gutmann; Jude Shavlik,Abstract: Relational Dependency Networks (RDNs) are graphical models that extenddependency networks to relational domains where the joint probability distribution over thevariables is approximated as a product of conditional distributions. The current learningalgorithms for RDNs use pseudolikelihood techniques to learn probability trees for eachvariable in order to represent the conditional distribution. We propose the use of gradienttree boosting as applied by Dietterich et al.(2004) to approximate the gradient for eachvariable. The use of several regression trees; instead of just one; results in an expressivemodel. Our results in 3 different data sets show that this training method results in efficientlearning of RDNs when compared to state-of-the-art approaches to Statistical RelationalLearning.,Online Proceedings of the International Conference on Inductive Logic Programming 2010,2010,15
Efficient Lifting of MAP LP Relaxations Using k-Locality,Martin Mladenov; Kristian Kersting; Amir Globerson,Abstract Inference in large scale graphical models is an important task in many domains;and in particular for probabilistic relational models (eg;. Markov logic networks). Suchmodels often exhibit considerable symmetry; and it is a challenge to devise algorithms thatexploit this symmetry to speed up inference. Here we address this task in the context of theMAP inference problem and its linear programming relaxations. We show that symmetry inthese problems can be discovered using an elegant algorithm known as the k-dimensionalWeisfeiler-Lehman (k-WL) algorithm. We run k-WL on the original graphical model; and noton the far larger graph of the linear program (LP) as proposed in earlier work in the field.Furthermore; the algorithm is polynomial and thus far more practical than other previousapproaches which rely on orbit partitions that are GI complete to find. The fact that k-WL …,Proceedings of the Seventeenth International Conference on Artificial Intelligence and Statistics,2014,14
Challenges for relational reinforcement learning,Martijn Otterlo; Kristian Kersting,*,Working Notes of the ICML-2004 Workshop on Relational Reinforcement Learning,2004,14
Learning from imbalanced data in relational domains: A soft margin approach,Shuo Yang; Tushar Khot; Kristian Kersting; Gautam Kunapuli; Kris Hauser; Sriraam Natarajan,We consider the problem of learning probabilistic models from relational data. One of thekey issues with relational data is class imbalance where the number of negative examplesfar outnumbers the number of positive examples. The common approach for dealing withthis problem is the use of sub-sampling of negative examples. We; on the other hand;consider a soft margin approach that explicitly trades off between the false positives andfalse negatives. We apply this approach to the recently successful formalism of relationalfunctional gradient boosting. Specifically; we modify the objective function of the learningproblem to explicitly include the trade-off between false positives and negatives. We showempirically that this approach is more successful in handling the class imbalance problemthan the original framework that weighed all the examples equally.,Data Mining (ICDM); 2014 IEEE International Conference on,2014,13
Learning to transfer optimal navigation policies,Kristian Kersting; Christian Plagemann; Alexandru Cocora; Wolfram Burgard; Luc De Raedt,Autonomous agents that act in the real world utilizing sensory input greatly rely on the abilityto plan their actions and to transfer these skills across tasks. The majority of path-planningapproaches for mobile robots; however; solve the current navigation problem from scratch;given the current and goal configuration of the robot. Consequently; these approaches yieldhighly efficient plans for the specific situation; but the computed policies typically do nottransfer to other; similar tasks. In this paper; we propose to apply techniques from statisticalrelational learning to the path-planning problem. More precisely; we propose to learnrelational decision trees as abstract navigation strategies from example paths. Relationalabstraction has several interesting and important properties. First; it allows a mobile robot toimitate navigation behavior shown by users or by optimal policies. Second; it yields …,Advanced Robotics,2007,13
Scaled cgem: A fast accelerated em,Jörg Fischer; Kristian Kersting,Abstract The EM algorithm is a popular method for maximum likelihood estimation ofBayesian networks in the presence of missing data. Its simplicity and general convergenceproperties make it very attractive. However; it sometimes converges slowly. Severalaccelerated EM methods based on gradient-based optimization techniques have beenproposed. In principle; they all employ a line search involving several NP-hard likelihoodevaluations. We propose a novel acceleration called SCGEM based on scaled conjugategradients (SCGs) well-known from learning neural networks. SCGEM avoids the line searchby adopting the scaling mechanism of SCGs applied to the expected information matrix. Thisguarantees a single likelihood evaluation per iteration. We empirically compare SCGEMwith EM and conventional conjugate gradient accelerated EM. The experiments show that …,European Conference on Machine Learning,2003,13
Boosted statistical relational learners: From benchmarks to data-driven medicine,Sriraam Natarajan; Kristian Kersting; Tushar Khot; Jude Shavlik,This SpringerBrief addresses the challenges of analyzing multi-relational and noisy data byproposing several Statistical Relational Learning (SRL) methods. These methods combinethe expressiveness of first-order logic and the ability of probability theory to handleuncertainty. It provides an overview of the methods and the key assumptions that allow foradaptation to different models and real world applications. The models are highly attractivedue to their compactness and comprehensibility but learning their structure iscomputationally intensive. To combat this problem; the authors review the use of functionalgradients for boosting the structure and the parameters of statistical relational models. Thealgorithms have been applied successfully in several SRL settings and have been adaptedto several real problems from Information extraction in text to medical problems. Including …,*,2015,12
Explicit versus implicit graph feature maps: A computational phase transition for walk kernels,Nils Kriege; Marion Neumann; Kristian Kersting; Petra Mutzel,As many real-world data can elegantly be represented as graphs; various graph kernels andmethods for computing them have been proposed. Surprisingly; many of the recent graphkernels do not employ the kernel trick anymore but rather compute an explicit feature mapand report higher efficiency. So; is there really no benefit of the kernel trick when it comes tographs? Triggered by this question; we investigate under which conditions it is possible tocompute a graph kernel explicitly and for which graph properties this computation is actuallymore efficient. We give a sufficient condition for R-convolution kernels that enables kernelcomputation by explicit mapping. We theoretically and experimentally analyze efficiency andflexibility of implicit kernel functions and dot products of explicitly computed feature maps forwidely used graph kernels such as random walk kernels; sub graph matching kernels …,Data Mining (ICDM); 2014 IEEE International Conference on,2014,12
Non-negative factor analysis supporting the interpretation of elemental distribution images acquired by XRF,Matthias Alfeld; Mirwaes Wahabzada; Christian Bauckhage; Kristian Kersting; Gerd Wellenreuther; Gerald Falkenberg,Abstract Stacks of elemental distribution images acquired by XRF can be difficult to interpret;if they contain high degrees of redundancy and components differing in their quantitative butnot qualitative elemental composition. Factor analysis; mainly in the form of PrincipalComponent Analysis (PCA); has been used to reduce the level of redundancy and highlightcorrelations. PCA; however; does not yield physically meaningful representations as theyoften contain negative values. This limitation can be overcome; by employing factor analysisthat is restricted to non-negativity. In this paper we present the first application of the PythonMatrix Factorization Module (pymf) on XRF data. This is done in a case study on the paintingSaul and David from the studio of Rembrandt van Rijn. We show how the discriminationbetween two different Co containing compounds with minimum user intervention and a …,Journal of Physics: Conference Series,2014,12
Pre-Symptomatic Prediction of Plant Drought Stress Using Dirichlet-Aggregation Regression on Hyperspectral Images.,Kristian Kersting; Zhao Xu; Mirwaes Wahabzada; Christian Bauckhage; Christian Thurau; Christoph Roemer; Agim Ballvora; Uwe Rascher; Jens Leon; Lutz Pluemer,Abstract Pre-symptomatic drought stress prediction is of great relevance in precision plantprotection; ultimately helping to meet the challenge of “How to feed a hungry world?”.Unfortunately; it also presents unique computational problems in scale and interpretability: itis a temporal; large-scale prediction task; eg; when monitoring plants over time usinghyperspectral imaging; and features are 'things' with a 'biological'meaning and interpretationand not just mathematical abstractions computable for any data. In this paper we proposeDirichletaggregation regression (DAR) to meet the challenge. DAR represents all data bymeans of convex combinations of only few extreme ones computable in linear time and easyto interpret. Then; it puts a Gaussian process prior on the Dirichlet distributions induced onthe simplex spanned by the extremes. The prior can be a function of any observed meta …,AAAI,2012,12
Deterministic CUR for improved large-scale data analysis: An empirical study,Christian Thurau; Kristian Kersting; Christian Bauckhage,Abstract Low-rank approximations which are computed from selected rows and columns of agiven data matrix have attracted considerable attention lately. They have been proposed asan alternative to the SVD because they naturally lead to interpretable decompositions whichwas shown to be successful in application such as fraud detection; fMRI segmentation; andcollaborative filtering. The CUR decomposition of large matrices; for example; samples rowsand columns according to a probability distribution that depends on the Euclidean norm ofrows or columns or on other measures of statistical leverage. At the same time; there arevarious deterministic approaches that do not resort to sampling and were found to often yieldfactorization of superior quality with respect to reconstruction accuracy. However; these arehardly applicable to large matrices as they typically suffer from high computational costs …,*,2012,12
Simplex distributions for embedding data matrices over time,Kristian Kersting; Mirwaes Wahabzada; Christoph Römer; Christian Thurau; Agim Ballvora; Uwe Rascher; Jens Léon; Christian Bauckhage; Lutz Plümer,Abstract Early stress recognition is of great relevance in precision plant protection. Pre-symptomatic water stress detection is of particular interest; ultimately helping to meet thechallenge of “How to feed a hungry world?”. Due to the climate change; this is ofconsiderable political and public interest. Due to its large-scale and temporal nature; eg;when monitoring plants using hyper-spectral imaging; and the demand of physical meaningof the results; it presents unique computational problems in scale and interpretability.However; big data matrices over time also arise in several other real-life applications suchas stock market monitoring where a business sector is characterized by the ups and downsof each of its companies per year or topic monitoring of document collections. Therefore; weconsider the general problem of embedding data matrices into Euclidean space over time …,*,2012,12
Lifted belief propagation: Pairwise marginals and beyond,Babak Ahmadi; Kristian Kersting; Fabian Hadiji,Abstract Lifted belief propagation (LBP) can be extremely fast at computing approximatemarginal probability distributions over single variables and neighboring ones in theunderlying graphical model. It does; however; not prescribe a way to compute jointdistributions over pairs; triples or k-tuples of distant random variables. In this paper; wepresent an algorithm; called conditioned LBP; for approximating these distributions.Essentially; we select variables one at a time for conditioning; running lifted beliefpropagation after each selection. This naive solution; however; recomputes the liftednetwork in each step from scratch; therefore often canceling the benefits of lifted inference.We show how to avoid this by efficiently computing the lifted network for each conditioningdirectly from the one already known for the single node marginals. Our experimental …,on Probabilistic Graphical Models,2010,12
Probabilistic inductive querying using ProbLog,Luc De Raedt; Angelika Kimmig; Bernd Gutmann; Kristian Kersting; Vítor Santos Costa; Hannu Toivonen,Abstract We study how probabilistic reasoning and inductive querying can be combinedwithin ProbLog; a recent probabilistic extension of Prolog. ProbLog can be regarded as adatabase system that supports both probabilistic and inductive reasoning through a varietyof querying mechanisms. After a short introduction to ProbLog; we provide a survey of thedifferent types of inductive queries that ProbLog supports; and show how it can be applied tothe mining of large biological networks.,*,2010,12
How Viral Are Viral Videos?,Christian Bauckhage; Fabian Hadiji; Kristian Kersting,Abstract Within only a few years after the launch of video sharing platforms; viral videos havebecome a pervasive Internet phenomenon. Yet; notwithstanding growing scholarly interest;the suitability of the viral metaphor seems not to have been studied so far. In this paper; wetherefore investigate the attention dynamics of viral videos from the point of view ofmathematical epidemiology. We introduce a novel probabilistic model of the progression ofinfective diseases and use it to analyze time series of YouTube view counts and Googlesearches. Our results on a data set of almost 800 videos show that their attention dynamicsare indeed well accounted for by our epidemic model. In particular; we find that the vastmajority of videos considered in this study show very high infection rates.,ICWSM,2015,11
Erosion band features for cell phone image based plant disease classification,Marion Neumann; Lisa Hallau; Benjamin Klatt; Kristian Kersting; Christian Bauckhage,We introduce a novel set of features for a challenging image analysis task in agriculturewhere cell phone camera images of beet leaves are analyzed as to the presence of plantdiseases. Aiming at minimal computational costs on the cellular device and highly accurateprediction results; we present an efficient detector of potential disease regions and a robustclassification method based on texture features. We evaluate several first-and second-orderstatistical features for classifying textures of leaf spots and we find that a combination ofdescriptors derived on multiple erosion bands of the RGB color channels; as well as; thelocal binary patterns of gradient magnitudes of the extracted regions accurately distinguishbetween symptoms caused by five diseases; including infections of the fungi Cercosporabeticola; Ramularia beticola; Uromyces betae; and Phoma betae; and the bacterium …,Pattern Recognition (ICPR); 2014 22nd International Conference on,2014,11
Strong regularities in growth and decline of popularity of social media services,Christian Bauckhage; Kristian Kersting,Abstract: We analyze general trends and pattern in time series that characterize thedynamics of collective attention to social media services and Web-based businesses. Ourstudy is based on search frequency data available from Google Trends and considers 175different services. For each service; we collect data from 45 different countries as well asglobal averages. This way; we obtain more than 8;000 time series which we analyze usingdiffusion models from the economic sciences. We find that these models accuratelycharacterize the empirical data and our analysis reveals that collective attention to socialmedia grows and subsides in a highly regular and predictable manner. Regularities persistacross regions; cultures; and topics and thus hint at general mechanisms that govern theadoption of Web-based services. We discuss several cases in detail to highlight …,arXiv preprint arXiv:1406.6529,2014,11
Kernelized map matching,Ahmed Jawad; Kristian Kersting,Abstract Map matching is a fundamental operation in many applications such as trafficanalysis and location-aware services; the killer apps for ubiquitous computing. In past;several map matching approaches have been proposed. Roughly; they can be categorizedinto four groups: geometric; topological; probabilistic; and other advanced techniques.Surprisingly; kernel methods have not received attention yet although they are very popularin the machine learning community due to their solid mathematical foundation; tendencytoward easy geometric interpretation; and strong empirical performance in a wide variety ofdomains. In this paper; we show how to employ kernels for map matching. Specifically;ignoring map constraints; we first maximize the consistency between the similarity measurescaptured by the kernel matrices of the trajectory and relevant part of the street map. The …,Proceedings of the 18th SIGSPATIAL International conference on advances in geographic information systems,2010,11
Lifting Relational MAP-LPs Using Cluster Signatures.,Udi Apsel; Kristian Kersting; Martin Mladenov,Abstract Inference in large scale graphical models is an important task in many domains;and in particular probabilistic relational models (eg Markov logic networks). Such modelsoften exhibit considerable symmetry; and it is a challenge to devise algorithms that exploitthis symmetry to speed up inference. Recently; the automorphism group has been proposedto formalize mathematically what” exploiting symmetry” means. However; obtainingsymmetry derived from automorphism is GI-hard; and consequently only a small fraction ofthe symmetry is easily available for effective employment. In this paper; we improve uponefficiency in two ways. First; we introduce the Cluster Signature Graph (CSG); a platform onwhich greater portions of the symmetries can be revealed and exploited. CSGs classifyclusters of variables by projecting relations between cluster members onto a graph …,AAAI Workshop: Statistical Relational Artificial Intelligence,2014,10
Lifted Message Passing as Reparametrization of Graphical Models.,Martin Mladenov; Amir Globerson; Kristian Kersting,Abstract Lifted inference approaches can considerably speed up probabilistic inference inMarkov random fields (MRFs) with symmetries. Given evidence; they essentially form a lifted;ie; reduced factor graph by grouping together indistinguishable variables and factors.Typically; however; lifted factor graphs are not amenable to offthe-shelf message passing(MP) approaches; and hence requires one to use either generic optimization tools; whichwould be slow for these problems; or design modified MP algorithms. Here; we demonstratethat the reliance on modified MP can be eliminated for the class of MP algorithms arisingfrom MAP-LP relaxations of pairwise MRFs. Specifically; we show that a given MRF inducesa whole family of MRFs of different sizes sharing essentially the same MAPLP solution. Inturn; we give an efficient algorithm to compute from them the smallest one that can be …,UAI,2014,10
Reduce and Re-Lift: Bootstrapped Lifted Likelihood Maximization for MAP.,Fabian Hadiji; Kristian Kersting,Abstract By handling whole sets of indistinguishable objects together; lifted beliefpropagation approaches have rendered large; previously intractable; probabilistic inferenceproblems quickly solvable. In this paper; we show that Kumar and Zilberstein's likelihoodmaximization (LM) approach to MAP inference is liftable; too; and actually providesadditional structure for optimization. Specifically; it has been recognized that some pseudomarginals may converge quickly; turning intuitively into pseudo evidence. This additionalevidence typically changes the structure of the lifted network: it may expand or reduce it. Thecurrent lifted network; however; can be viewed as an upper bound on the size of the liftednetwork required to finish likelihood maximization. Consequently; we re-lift the network onlyif the pseudo evidence yields a reduced network; which can efficiently be computed on …,AAAI Workshop: Statistical Relational Artificial Intelligence,2013,10
Symbolic dynamic programming for continuous state and observation POMDPs,Zahra Zamani; Scott Sanner; Pascal Poupart; Kristian Kersting,Abstract Partially-observable Markov decision processes (POMDPs) provide a powerfulmodel for real-world sequential decision-making problems. In recent years; point-basedvalue iteration methods have proven to be extremely effective techniques for ﬁnding(approximately) optimal dynamic programming solutions to POMDPs when an initial set ofbelief states is known. However; no point-based work has provided exact point-basedbackups for both continuous state and observation spaces; which we tackle in this paper.Our key insight is that while there may be an inﬁnite number of possible observations; thereare only a ﬁnite number of observation partitionings that are relevant for optimal decision-making when a ﬁnite; ﬁxed set of reachable belief states is known. To this end; we make twoimportant contributions:(1) we show how previous exact symbolic dynamic pro-gramming …,Advances in Neural Information Processing Systems,2012,10
Agriculture´s Technological Makeover,Christian Bauckhage; Kristian Kersting; Albrecht Schmidt,Mobile Devices and Sensors Pervasive computing is taking over the fields; as smartphones;portable computers; GPS sensors; RFID tags; and other environmental sensor net- works continuallygather and exchange information. Companies such as Ag Leader (www.agleader.com); FarmWorks (www.farmworks.com); and SST (www.sstsoftware.com) sell hand- helds with enhancedfeatures—including more powerful processors; GPS sensors; high-resolution cameras; andbuilt-in wireless and cellular interfaces—that are robust enough for deployment in the fields andthat sim- plify tasks such as yield control or soil sampling. Increasingly; farm equipment and fieldshave smart sensors that can read everything from plants' health and water needs to the soil'snitro- gen levels; thereby helping farmers optimize the irrigation process and avoid cropfailure. New optical sens- ing technologies for monitoring crop health include Trimble's …,IEEE Pervasive Computing,2012,10
More influence means less work: fast latent Dirichlet allocation by influence scheduling,Mirwaes Wahabzada; Kristian Kersting; Anja Pilz; Christian Bauckhage,Abstract There have recently been considerable advances in fast inference for (online) latentDirichlet allocation (LDA). While it is widely recognized that the scheduling of documents instochastic optimization and in turn in LDA may have significant consequences; this issueremains largely unexplored. Instead; practitioners schedule documents essentially uniformlyat random; due perhaps to ease of implementation; and to the lack of clear guidelines onscheduling the documents. In this work; we address this issue and propose to scheduledocuments for an update that exert a disproportionately large influence on the topics of thecorpus before less influential ones. More precisely; we justify to sample documentsrandomly biased towards those ones with higher norms to form mini-batches. On severalreal-world datasets; including 3M articles from Wikipedia and 8M from PubMed; we …,Proceedings of the 20th ACM international conference on Information and knowledge management,2011,10
Markov Logic Sets: Towards Lifted Information Retrieval Using PageRank and Label Propagation.,Marion Neumann; Babak Ahmadi; Kristian Kersting,Abstract Inspired by “GoogleTM Sets” and Bayesian sets; we consider the problem ofretrieving complex objects and relations among them; ie; ground atoms from a logicalconcept; given a query consisting of a few atoms from that concept. We formulate this as awithin-network relational learning problem using few labels only and describe an algorithmthat ranks atoms using a score based on random walks with restart (RWR): the probabilitythat a random surfer hits an atom starting from the query atoms. Specifically; we compute aninitial ranking using personalized PageRank. Then; we find paths of atoms that areconnected via their arguments; variablize the ground atoms in each path; in order to createfeatures for the query. These features are used to re-personalize the original RWR and tofinally compute the set completion; based on Label Propagation. Moreover; we exploit …,AAAI,2011,10
Topic models conditioned on relations,Mirwaes Wahabzada; Zhao Xu; Kristian Kersting,Abstract Latent Dirichlet allocation is a fully generative statistical language model that hasbeen proven to be successful in capturing both the content and the topics of a corpus ofdocuments. Recently; it was even shown that relations among documents such as hyper-links or citations allow one to share information between documents and in turn to improvetopic generation. Although fully generative; in many situations we are actually not interestedin predicting relations among documents. In this paper; we therefore present a Dirichlet-multinomial nonparametric regression topic model that includes a Gaussian process prior onjoint document and topic distributions that is a function of document relations. On networks ofscientific abstracts and of Wikipedia documents we show that this approach meets orexceeds the performance of several baseline topic models.,Joint European Conference on Machine Learning and Knowledge Discovery in Databases,2010,10
Relational sequence alignments and logos,Andreas Karwath; Kristian Kersting,Abstract The need to measure sequence similarity arises in many applicitation domains andoften coincides with sequence alignment: the more similar two sequences are; the betterthey can be aligned. Aligning sequences not only shows how similar sequences are; it alsoshows where there are differences and correspondences between the sequences.Traditionally; the alignment has been considered for sequences of flat symbols only. Manyreal world sequences such as natural language sentences and protein secondarystructures; however; exhibit rich internal structures. This is akin to the problem of dealingwith structured examples studied in the field of inductive logic programming (ILP). In thispaper; we introduce Real; which is a powerful; yet simple approach to align sequence ofstructured symbols using well-established ILP distance measures within traditional …,International Conference on Inductive Logic Programming,2006,10
Efficient sequential clamping for lifted message passing,Fabian Hadiji; Babak Ahmadi; Kristian Kersting,Abstract Lifted message passing approaches can be extremely fast at computingapproximate marginal probability distributions over single variables and neighboring ones inthe underlying graphical model. They do; however; not prescribe a way to solve morecomplex inference tasks such as computing joint marginals for k-tuples of distant randomvariables or satisfying assignments of CNFs. A popular solution in these cases is the idea ofturning the complex inference task into a sequence of simpler ones by selecting andclamping variables one at a time and running lifted message passing again after eachselection. This naive solution; however; recomputes the lifted network in each step fromscratch; therefore often canceling the benefits of lifted inference. We show how to avoid thisby efficiently computing the lifted network for each conditioning directly from the one …,Annual Conference on Artificial Intelligence,2011,9
Symbolic dynamic programming,Scott Sanner; Kristian Kersting,Samuel's Checkers Player is the first machine learning system that received publicrecognition. It pioneered many important ideas in game playing and machine learning. Tetwo main papers describing his research (Samuel;;) became landmark papers in ArtificialIntelligence. In one game; the resulting program was able to beat one of America's bestplayers of the time.,*,2011,9
Hyperspectral imaging reveals the effect of sugar beet quantitative trait loci on Cercospora leaf spot resistance,Marlene Leucker; Mirwaes Wahabzada; Kristian Kersting; Madlaina Peter; Werner Beyer; Ulrike Steiner; Anne-Katrin Mahlein; Erich-Christian Oerke,The quantitative resistance of sugar beet (Beta vulgaris L.) against Cercospora leaf spot(CLS) caused by Cercospora beticola (Sacc.) was characterised by hyperspectral imaging.Two closely related inbred lines; differing in two quantitative trait loci (QTL); which made adifference in disease severity of 1.1–1.7 on the standard scoring scale (1–9); wereinvestigated under controlled conditions. The temporal and spatial development of CLSlesions on the two genotypes were monitored using a hyperspectral microscope. The lesiondevelopment on the QTL-carrying; resistant genotype was characterised by a fast and abruptchange in spectral reflectance; whereas it was slower and ultimately more severe on thegenotype lacking the QTL. An efficient approach for clustering of hyperspectral signatureswas adapted in order to reveal resistance characteristics automatically. The presented …,Functional Plant Biology,2017,8
Effectively creating weakly labeled training examples via approximate domain knowledge,Sriraam Natarajan; Jose Picado; Tushar Khot; Kristian Kersting; Christopher Re; Jude Shavlik,Abstract One of the challenges to information extraction is the requirement of humanannotated examples; commonly called gold-standard examples. Many successfulapproaches alleviate this problem by employing some form of distant supervision; ie; lookinto knowledge bases such as Freebase as a source of supervision to create moreexamples. While this is perfectly reasonable; most distant supervision methods rely on ahand-coded background knowledge that explicitly looks for patterns in text. For example;they assume all sentences containing Person X and Person Y are positive examples of therelation married (X; Y). In this work; we take a different approach–we infer weakly supervisedexamples for relations from models learned by using knowledge outside the naturallanguage task. We argue that this method creates more robust examples that are …,*,2015,8
Relational learning helps in three-way classification of Alzheimer patients from structural magnetic resonance images of the brain,Sriraam Natarajan; Baidya Saha; Saket Joshi; Adam Edwards; Tushar Khot; Elizabeth M Davenport; Kristian Kersting; Christopher T Whitlow; Joseph A Maldjian,Abstract Magnetic resonance imaging (MRI) has emerged as an important tool to identifyintermediate biomarkers of Alzheimer's disease (AD) due to its ability to measure regionalchanges in the brain that are thought to reflect disease severity and progression. In thispaper; we set out a novel pipeline that uses volumetric MRI data collected from differentsubjects as input and classifies them into one of three classes: AD; mild cognitiveimpairment (MCI) and cognitively normal (CN). Our pipeline consists of three stages—(1) asegmentation layer where brain MRI data is divided into clinically relevant regions;(2) aclassification layer that uses relational learning algorithms to make pairwise predictionsbetween the three classes; and (3) a combination layer that combines the results of thedifferent classes to obtain the final classification. One of the key features of our proposed …,International Journal of Machine Learning and Cybernetics,2014,8
Propagation kernels for partially labeled graphs,Marion Neumann; Roman Garnett; Plinio Moreno; Novi Patricia; Kristian Kersting,Abstract Learning from complex data is becoming increasingly important; and graph kernelshave recently evolved into a rapidly developing branch of learning on structured data.However; previously proposed kernels rely on having discrete node label information.Propagation kernels leverage the power of continuous node label distributions as graphfeatures and hence; enhance traditional graph kernels to efficiently handle partially labeledgraphs in a principled manner. Utilizing localitysensitive hashing; propagation kernels areable to outperform state-of-the-art graph kernels in terms of runtime without loss in predictionaccuracy. This paper investigates the power of propagation kernels to classify partiallylabeled images and to tackle the challenging problem of retrieving similar object views inrobotic grasping.,ICML–2012 Workshop on Mining and Learning with Graphs (MLG–2012); Edinburgh; UK,2012,8
Decision-theoretic planning with generalized first-order decision diagrams,Saket Joshi; Kristian Kersting; Roni Khardon,Abstract Many tasks in AI require representation and manipulation of complex functions. First-Order Decision Diagrams (FODD) are a compact knowledge representation expressingfunctions over relational structures. They represent numerical functions that; whenconstrained to the Boolean range; use only existential quantification. Previous work hasdeveloped a set of operations for composition and for removing redundancies in FODDs;thus keeping them compact; and showed how to successfully employ FODDs for solvinglarge-scale stochastic planning problems through the formalism of relational Markovdecision processes (RMDP). In this paper; we introduce several new ideas enhancing theapplicability of FODDs. More specifically; we first introduce Generalized FODDs (GFODD)and composition operations for them; generalizing FODDs to arbitrary quantification …,Artificial Intelligence,2011,8
Heteroscedastic gaussian process regression for modeling range sensors in mobile robotics,Christian Plagemann; Kristian Kersting; Patrick Pfaff; Wolfram Burgard,In probabilistic approaches to mobile robot navigation; the development of measurementmodels plays a crucial role as it directly influences the efficiency and the robustness of therobot's performance in a great variety of tasks including localization; tracking; and mapbuilding [1]. Among the most popular types of sensors used are range finders; whichmeasure distances to nearby obstacles relative to certain (possibly multivariate) bearingangles. Probabilistic measurement models for this kind of sensor; such as beam models(aka. ray-casting models) and likelihood fields (aka. end point models); typically assumeindependency between individual range measurements. This leads to a series of practicallimitations such as overly peaked observation likelihood functions for high density rangescans or degrading performance in highly cluttered environments. To overcome this; we …,Snowbird learning workshop,2007,8
Scaled conjugate gradients for maximum likelihood: An empirical comparison with the EM algorithm,Kristian Kersting; Niels Landwehr,Abstract To learn Bayesian networks; one must estimate the parameters of the network fromthe data. EM (Expectation-Maximization) and gradient-based algorithms are the two bestknown techniques to estimate these parameters. Although the theoretical properties of thesetwo frameworks are well-studied; it remains an open question as to when and whether EM isto be preferred over gradients. We will answer this question empirically. More specifically;we first adapt scaled conjugate gradients well-known from neural network learning. Thisaccelerated conjugate gradient avoids the time consuming line search of more traditionalmethods. Secondly; we empirically compare scaled conjugate gradients with EM. Theexperiments show that accelerated conjugate gradients are competitive with EM. Although;in general EM is the domain independent method of choice; gradient-based methods can …,*,2004,8
A structural gem for learning logical hidden markov models,K Kersting; Tapani Raiko; L De Raedt,Abstract. Traditional hidden Markov models (HMMs) specify probability distributions oversequences of flat symbols. Recently; logical hidden Markov models (LOHMMs) have beenintroduced to deal with sequences of structured symbols. Within LOHMMs; logical atoms areused to represent output and state symbols. Together with unification; this kind of abstractioncan lead to LOHMMs that have a much smaller number of parameters equivalent HMMs(typically an order of magnitude). However; the compactness of LOHMMs comes at theexpense of a more complex structure learning problem. Indeed; different abstraction levelshave to be explored. In this paper; we propose for the first time a method for learning thestructure of LOHMMs from data. The method essentially adapts Friedman's structural EM(SEM) algorithm. More precisely; it combines generalized expectation maximization (GEM …,Working Notes of the Second KDD-Workshop on Multi-Relational Data Mining (MRDM-03),2003,8
Relational linear programming,Kristian Kersting; Martin Mladenov; Pavel Tokmakov,Abstract We propose relational linear programming; a simple framework for combining linearprograms (LPs) and logic programs. A relational linear program (RLP) is a declarative LPtemplate defining the objective and the constraints through the logical concepts of objects;relations; and quantified variables. This allows one to express the LP objective andconstraints relationally for a varying number of individuals and relations among them withoutenumerating them. Together with a logical knowledge base; effectively a logic programconsisting of logical facts and rules; it induces a ground LP. This ground LP is solved usinglifted linear programming. That is; symmetries within the ground LP are employed to reduceits dimensionality; if possible; and the reduced program is solved using any off-the-shelf LPsolver. In contrast to mainstream LP template languages such as AMPL; which features a …,Artificial Intelligence,2017,7
Statistical relational learning of grammar rules for 3D building reconstruction,Youness Dehbi; Fabian Hadiji; Gerhard Gröger; Kristian Kersting; Lutz Plümer,Abstract The automatic interpretation of 3D point clouds for building reconstruction is achallenging task. The interpretation process requires highly structured models representingsemantics. Formal grammars can describe structures as well as the parameters of buildingsand their parts. We propose a novel approach for the automatic learning of weightedattributed context-free grammar rules for 3D building reconstruction; supporting thelaborious manual design of rules. We separate structure from parameter learning. SpecificSupport Vector Machines (SVMs) are used to generate a weighted context-free grammarand predict structured outputs such as parse trees. The grammar is extended by parametersand constraints; which are learned based on a statistical relational learning method usingMarkov Logic Networks (MLNs). MLNs enforce the topological and geometric constraints …,Transactions in GIS,2017,7
Poisson Sum-Product Networks: A Deep Architecture for Tractable Multivariate Poisson Distributions.,Alejandro Molina; Sriraam Natarajan; Kristian Kersting,Abstract Multivariate count data are pervasive in science in the form of histograms;contingency tables and others. Previous work on modeling this type of distributions do notallow for fast and tractable inference. In this paper we present a novel Poisson graphicalmodel; the first based on sum product networks; called PSPN; allowing for positive as wellas negative dependencies. We present algorithms for learning tree PSPNs from data as wellas for tractable inference via symbolic evaluation. With these; information-theoreticmeasures such as entropy; mutual information; and distances among count variables can becomputed without resorting to approximations. Additionally; we show a connection betweenPSPNs and LDA; linking the structure of tree PSPNs to a hierarchy of topics. Theexperimental results on several synthetic and real world datasets demonstrate that PSPN …,AAAI,2017,7
Faster kernels for graphs with continuous attributes via hashing,Christopher Morris; Nils M Kriege; Kristian Kersting; Petra Mutzel,While state-of-the-art kernels for graphs with discrete labels scale well to graphs withthousands of nodes; the few existing kernels for graphs with continuous attributes;unfortunately; do not scale well. To overcome this limitation; we present hash graph kernels;a general framework to derive kernels for graphs with continuous attributes from discreteones. The idea is to iteratively turn continuous attributes into discrete labels usingrandomized hash functions. We illustrate hash graph kernels for the Weisfeiler-Lehmansubtree kernel and for the shortest-path kernel. The resulting novel graph kernels are shownto be; both; able to handle graphs with continuous attributes and scalable to large graphsand data sets. This is supported by our theoretical analysis and demonstrated by anextensive experimental evaluation.,Data Mining (ICDM); 2016 IEEE 16th International Conference on,2016,7
Scaling lifted probabilistic inference and learning via graph databases,Mayukh Das; Yuqing Wu; Tushar Khot; Kristian Kersting; Sriraam Natarajan,Abstract Over the past decade; exploiting relations and symmetries within probabilisticmodels has been proven to be surprisingly effective at solving large scale data miningproblems. One of the key operations inside these lifted approaches is counting-be it forparameter/structure learning or for efficient inference. Typically; however; they just countexploiting the logical structure using adhoc operators. This paper investigates whether'Compilation to Graph Databases' could be a practical technique for scaling liftedprobabilistic inference and learning methods. We demonstrate that the proposed approachachieves reasonable speed-ups for both inference and learning; without sacrificingperformance.,*,2016,7
Parameterizing the Distance Distribution of Undirected Networks.,Christian Bauckhage; Kristian Kersting; Fabian Hadiji,Abstract Network statistics such as node degree distributions; average path lengths;diameters; or clustering coefficients are widely used to characterize networks. One statisticthat received considerable attention is the distance distribution—the number of pairs ofnodes for each shortest-path distance—in undirected networks. It captures importantproperties of the network; reflecting on the dynamics of network spreading processes; andincorporates parameters such as node centrality and (effective) diameter. So far; however;no parameterization of the distance distribution is known that applies to a large class ofnetworks. Here we develop such a closed-form distribution by applying maximum entropyarguments to derive a general; physically plausible model of path length histograms. Basedon the model; we then establish the generalized Gamma as a threeparameter distribution …,UAI,2015,7
Early Prediction of Coronary Artery Calcification Levels Using Machine Learning.,Sriraam Natarajan; Kristian Kersting; Edward Ip; David R Jacobs; Jeffrey Carr,Abstract Coronary heart disease (CHD) is a major cause of death worldwide. In the US CHDis responsible for approximated 1 in every 6 deaths with a coronary event occurring every 25seconds and about 1 death every minute based on data current to 2007. Although amultitude of cardiovascular risks factors have been identified; CHD actually reflects complexinteractions of these factors over time. Today's datasets from longitudinal studies offer greatpromise to uncover these interactions but also pose enormous analytical problems due totypically large amount of both discrete and continuous measurements and risk factors withpotential long-range interactions over time. Our investigation demonstrates that a statisticalrelational analysis of longitudinal data can easily uncover complex interactions of risksfactors and actually predict future coronary artery calcification (CAC) levels—an indicator …,IAAI,2013,7
Aggregation and population growth: The relational logistic regression and Markov logic cases,David Poole; David Buchman; Sriraam Natarajan; Kristian Kersting,Abstract This paper considers how relational probabilistic models adapt to population size.First we show that what are arbitrary choices for nonrelational domains become acommitment to how a relational model adapts to population change. We show how thismanifests in a directed model where the conditional probabilities are represented using thelogistic function; and show why it needs to be extended to a relational logistic function.Second we prove that directed aggregation models cannot be represented by Markov Logicwithout clauses that involve multiple individuals. Third we show how these models changeas a function of population size.,Proc. UAI-2012 Workshop on Statistical Relational AI,2012,7
Bellman goes relational,Martijn Otterlo; Kristian Kersting; Luc De Raedt,*,16th Belgian-Dutch Conference on Artificial Intelligence (BNAIC),2004,7
How is a data-driven approach better than random choice in label space division for multi-label classification?,Piotr Szymański; Tomasz Kajdanowicz; Kristian Kersting,Abstract We propose using five data-driven community detection approaches from socialnetworks to partition the label space in the task of multi-label classification as an alternativeto random partitioning into equal subsets as performed by RAkELd. We evaluate modularity-maximizing using fast greedy and leading eigenvector approximations; infomap; walktrapand label propagation algorithms. For this purpose; we propose to construct a label co-occurrence graph (both weighted and unweighted versions) based on training data andperform community detection to partition the label set. Then; each partition constitutes alabel space for separate multi-label classification sub-problems. As a result; we obtain anensemble of multi-label classifiers that jointly covers the whole label space. Based on thebinary relevance and label powerset classification methods; we compare community …,Entropy,2016,6
Transfer learning via relational type matching,Raksha Kumaraswamy; Phillip Odom; Kristian Kersting; David Leake; Sriraam Natarajan,Transfer learning is typically performed between problem instances within the same domain.We consider the problem of transferring across domains. To this effect; we adopt aprobabilistic logic approach. First; our approach automatically identifies predicates in thetarget domain that are similar in their relational structure to predicates in the source domain.Second; it transfers the logic rules and learns the parameters of the transferred rules usingtarget data. Finally; it refines the rules as necessary using theory refinement. Ourexperimental evidence supports that this transfer method finds models as good or betterthan those found with state-of-the-art methods; with and without transfer; and in a fraction ofthe time.,Data Mining (ICDM); 2015 IEEE International Conference on,2015,6
Population size extrapolation in relational probabilistic modelling,David Poole; David Buchman; Seyed Mehran Kazemi; Kristian Kersting; Sriraam Natarajan,Abstract When building probabilistic relational models it is often difficult to determine whatformulae or factors to include in a model. Different models make quite different predictionsabout how probabilities are affected by population size. We show some general patterns thathold in some classes of models for all numerical parametrizations. Given a data set; it isoften easy to plot the dependence of probabilities on population size; which; together withprior knowledge; can be used to rule out classes of models; where just assessing or fittingnumerical parameters will be misleading. In this paper we analyze the dependence onpopulation for relational undirected models (in particular Markov logic networks) andrelational directed models (for relational logistic regression). Finally we show howprobabilities for real data sets depend on the population size.,International Conference on Scalable Uncertainty Management,2014,6
Markov logic mixtures of Gaussian processes: Towards machines reading regression data,Martin Schiegg; Marion Neumann; Kristian Kersting,Abstract We propose a novel mixtures of Gaussian processes model in which the gatingfunction is interconnected with a probabilistic logical model; in our case Markov logicnetworks. In this way; the resulting mixed graphical model; called Markov logic mixtures ofGaussian processes (MLxGP); solves joint Bayesian non-parametric regression andprobabilistic relational inference tasks. In turn; MLxGP facilitates novel; interesting taskssuch as regression based on logical constraints or drawing probabilistic logical conclusionsabout regression data; thus putting “machines reading regression data” in reach.,Artificial Intelligence and Statistics,2012,6
Where traffic meets dna: mobility mining using biological sequence analysis revisited,Ahmed Jawad; Kristian Kersting; Natalia Andrienko,Abstract Traffic and mobility mining are fascinating and fast growing areas of data miningand geographical information systems that impact the lives of billions of people every day.Another well-known scientific field that impacts lives of billions is biological sequenceanalysis. It has experienced an incredible evolution in the recent decade; especially sincethe Human Genome project. Although; a very first link between both fields has beenestablished already in the early 90ies; many recent papers on mobility mining seem to beunaware of it. We therefore revisit the link and show that many unexplored and novelmobility mining methods fall naturally out of it. Specifically; using advanced discretizationtechniques for stay-point detection and map matching; we turn traffic sequences into a"biological" ones. Then; we introduce a novel distance function that enables us to directly …,Proceedings of the 19th ACM SIGSPATIAL International Conference on Advances in Geographic Information Systems,2011,6
Stratified gradient boosting for fast training of conditional random fields,Bernd Gutmann; Kristian Kersting,Abstract: Boosting has recently been shown to be a promising approach for trainingconditional random fields (CRFs) as it allows to efficiently induce conjunctive (evenrelational) features. The potentials are represented as weighted sums of regression treesthat are induced using gradient tree boosting. Its large scale application such as in relationaldomains; however; suffers from two drawbacks: induced trees can spoil previousmaximizations and the number of generated regression examples can become quite large.In this paper; we propose to tackle the latter problem by injecting randomness into theregression estimation procedure by subsampling regression examples. Experiments on areal-world data set show that this sampling approach is comparable with more sophisticatedboosting algorithms in early iterations and; hence; provides an interesting alternative as it …,Proceedings of the 6th international workshop on multi-relational data mining,2007,6
Unbiased conjugate direction boosting for conditional random fields,Kristian Kersting; Bernd Gutmann,Abstract: Conditional Random Fields (CRFs) currently receive a lot of attention for labelingsequences. To train CRFs; Dietterich et al. proposed a functional gradient optimizationapproach: the potential functions are represented as weighted sums of regression trees thatare induced using Friedman's gradient tree boosting method. In this paper; we improve uponthis approach in two ways. First; we identify an expectation selection bias implicitly imposedand compensate for it. Second; we employ a more sophisticated boosting algorithm basedon conjugate gradients in function space. Initial experiments show performance gains overthe basic functional gradient approach.,Proceedings of the International Workshop on Mining and Learning with Graphs (MLG 2006),2006,6
Expressivity analysis for pl-languages,Manfred Jaeger; Kristian Kersting; Luc De Raedt,Many different languages for representing probabilisticlogical (pl) models have beenproposed over the last decade. Among them are Prism models [9]; Stochastic LogicPrograms (SLPs)[6]; Relational Bayesian networks (RBNs)[3]; Probabilistic Relation Models(PRMs)[1]; Bayesian Logic Programs (BLPs)[5]; Markov Logic Networks (MLNs)[8]; andmany others. There now is considerable interest in gaining a better understanding of therelationships between these languages; and translations between them have beeninvestigated [7; 10; 4; 2]. These works focus on pairwise comparisons between languagesand do not establish a general; robust framework for comparing pl-languages. In this paperwe propose the outlines of a general conceptual framework for analysing expressivity of pl-languages.,*,2006,6
Logical Hidden Markov Models,Kristian Kersting; Tapani Raiko; Luc De Raedt,Hidden Markov models (Rabiner & Juang; 1986) (HMMs) are extremely popular for an- alyzingsequential data. Application areas include computational biology; user modelling; speechrecognition; empirical natural language processing; and robotics. Despite their suc- cesses; HMMshave a major weakness: they handle only sequences of flat; ie; unstruc- tured symbols. Yet; inmany applications the symbols occurring in sequences are struc- tured. Consider; eg; sequencesof UNIX commands; which may have parameters such as emacs lohmms.tex;ls; latexlohmms.tex;...Thus; commands are essentially structured. Tasks that have been considered forUNIX command sequences include the prediction of the next command in the sequence (Davison& Hirsh; 1998); the classification of a command sequence in a user category (Korvemaker &Greiner; 2000; Jacobs & Blockeel; 2001); and anomaly detection (Lane; 1999) …,Proceedings of the First European Workshop on Probabilistic Graphical Models (PGM-02),2002,6
Learning Continuous-Time Bayesian Networks in Relational Domains: A Non-Parametric Approach,Shuo Yang; Tushar Khot; Kristian Kersting; Sriraam Natarajan,Abstract Many real world applications in medicine; biology; communication networks; webmining; and economics; among others; involve modeling and learning structured stochasticprocesses that evolve over continuous time. Existing approaches; however; have focused onpropositional domains only. Without extensive feature engineering; it is difficult—if notimpossible—to apply them within relational domains where we may have varying number ofobjects and relations among them. We therefore develop the first relational representationcalled Relational Continuous-Time Bayesian Networks (RCTBNs) that can address thischallenge. It features a nonparametric learning method that allows for efficiently learning thecomplex dependencies and their strengths simultaneously from sequence data. Ourexperimental results demonstrate that RCTBNs can learn as effectively as stateof-the-art …,AAAI,2016,5
LTE connectivity and vehicular traffic prediction based on machine learning approaches,Christoph Ide; Fabian Hadiji; Lars Habel; Alejandro Molina; Thomas Zaksek; Michael Schreckenberg; Kristian Kersting; Christian Wietfeld,The prediction of both; vehicular traffic and communication connectivity are importantresearch topics. In this paper; we propose the usage of innovative machine learningapproaches for these objectives. For this purpose; Poisson Dependency Networks (PDNs)are introduced to enhance the prediction quality of vehicular traffic flows. The machinelearning model is fitted based on empirical vehicular traffic data. The results show that PDNsenable a significantly better short-term prediction in comparison to a prediction based on thephysics of traffic. To combine vehicular traffic with cellular communication networks; acorrelation between connectivity indicators and vehicular traffic flow is shown based onmeasurement results. This relationship is leveraged by means of Poisson regression trees inboth directions; and hence; enabling the prediction of both types of network utilization.,Vehicular Technology Conference (VTC Fall); 2015 IEEE 82nd,2015,5
Computer Science on the Move: Inferring Migration Regularities from the Web via Compressed Label Propagation.,Fabian Hadiji; Martin Mladenov; Christian Bauckhage; Kristian Kersting,Abstract Many collective human activities have been shown to exhibit universal patterns.However; the possibility of regularities underlying researcher migration in computer science(CS) has barely been explored at global scale. To a large extend; this is due to official andcommercial records being restricted; incompatible between countries; and especially notregistered across researchers. We overcome these limitations by building our own;transnational; large-scale dataset inferred from publicly available information on the Web.Essentially; we use Label Propagation (LP) to infer missing geo-tags of author-paper-pairsretrieved from online bibliographies. On this dataset; we then find statistical regularities thatexplain how researchers in CS move from one place to another. However; although vanillaLP is simple and has been remarkably successful; its run time can suffer from unexploited …,IJCAI,2015,5
Coinciding walk kernels: Parallel absorbing random walks for learning with graphs and few labels,Marion Neumann; Roman Garnett; Kristian Kersting,Abstract Exploiting autocorrelation for node-label prediction in networked data has led togreat success. However; when dealing with sparsely labeled networks; common in present-day tasks; the autocorrelation assumption is difficult to exploit. Taking a step beyond; wepropose the coinciding walk kernel (cwk); a novel kernel leveraging label-structure similarity–the idea that nodes with similarly arranged labels in their local neighbourhoods are likely tohave the same label–for learning problems on partially labeled graphs. Inspired by thesuccess of random walk based schemes for the construction of graph kernels; cwk is definedin terms of the probability that the labels encountered during parallel random walks coincide.In addition to its intuitive probabilistic interpretation; coinciding walk kernels outperformexisting kernel-and walk-based methods on the task of node-label prediction in sparsely …,Asian conference on machine learning,2013,5
Probabilistic path-disruption games,K Kersting; M Toussaint,Abstract. Path-disruption games; recently introduced by Bachrach and Porat [1]; arecoalitional games played on graphs where one or multiple adversaries each seek to reach agiven target vertex from a given source vertex and a coalition of agents seeks to prevent thatfrom happening by blocking every path from the source to the target; for each adversary. Weexpand their model by allowing uncertainty about the targets. In probabilistic path-disruptiongames; we assign to each vertex the probability that an adversary wants to reach it. Westudy the complexity of various problems related to such games.,STAIRS 2012: Proceedings of the Sixth Starting AI Researchers’ Symposium,2012,5
Multi-task learning with task relations,Zhao Xu; Kristian Kersting,Multi-task and relational learning with Gaussian processes are two active but alsoorthogonal areas of research. So far; there has been few attempt at exploring relationalinformation within multi-task Gaussian processes. While existing relational Gaussianprocess methods have focused on relations among entities and in turn could be employedwithin an individual task; we develop a class of Gaussian process models whichincorporates relational information across multiple tasks. As we will show; inference andlearning within the resulting class of models; called relational multi-task Gaussianprocesses; can be realized via a variational EM algorithm. Experimental results on syntheticand real-world datasets verify the usefulness of this approach: The observed relationalknowledge at the level of tasks can indeed reveal additional pair wise correlations …,Data Mining (ICDM); 2011 IEEE 11th International Conference on,2011,5
Gaussian process,Novi Quadrianto; Kristian Kersting; Zhao Xu,where√ π ensures the normalization; ie;∫ R p (x) dx=. Tis distribution centers around x=and the rate of decay or “width” of the curve is. More generally; we can apply translation andscaling to obtain a Gaussian distribution that centers on arbitrary µ∈ R and with arbitrarywidth σ>. Te pdf is: p (x)= σ x− µ σ,Encyclopedia of Machine Learning,2010,5
Lifted Message Passing for Satisfiability.,Fabian Hadiji; Kristian Kersting; Babak Ahmadi,Abstract Unifying logical and probabilistic reasoning is a longstanding goal of AI. Whilerecent work in lifted belief propagation; handling whole sets of indistinguishable objectstogether; are promising steps towards achieving this goal that even scale to realisticdomains; they are not tailored towards solving combinatorial problems such as determiningthe satisfiability of Boolean formulas. Recent results; however; show that certain othermessage passing algorithms; namely; survey propagation; are remarkably successful atsolving such problems. In this paper; we propose the first lifted variants of surveypropagation and its simpler version warning propagation. Our initial experimental resultsindicate that they are faster than using lifted belief propagation to determine the satisfiabilityof Boolean formulas.,Statistical Relational Artificial Intelligence,2010,5
Archetypal analysis as an autoencoder,C Bauckhage; HF Kersting; C Thurau,Abstract. We present an efficient approach to archetypal analysis where we use sub-gradient algorithms for optimization over the simplex to determine archetypes andreconstruction coefficients. Runtime evaluations reveal our approach to be notably moreefficient than previous techniques. As an practical application; we consider archetypalanalysis for autoencoding.,Workshop New Challenges in Neural Computation,2015,4
pyGPs: a Python library for Gaussian process regression and classification,Marion Neumann; Shan Huang; Daniel E Marthaler; Kristian Kersting,Abstract We introduce pyGPs; an object-oriented implementation of Gaussian processes(gps) for machine learning. The library provides a wide range of functionalities reaching fromsimple gp specification via mean and covariance and gp inference to more compleximplementations of hyperparameter optimization; sparse approximations; and graph basedlearning. Using Python we focus on usability for both “users” and “researchers”. Our maingoal is to offer a user-friendly and flexible implementation of gps for machine learning.,The Journal of Machine Learning Research,2015,4
Graph kernels for object category prediction in task-dependent robot grasping,Marion Neumann; Plinio Moreno; Laura Antanas; Roman Garnett; Kristian Kersting,ABSTRACT Robot grasping is a critical and difficult problem in robotics. The problem ofsimply finding a stable grasp is difficult enough; but to perform a useful grasp; we must alsoconsider other aspects of the task: the object; its properties; and any task-related constraints.The choice of grasping region is highly dependent on the category of object; and theautomated prediction of object category is the problem we focus on here. In this paper; weconsider manifold information and semantic object parts in a graph kernel to predictcategories of a large variety of household objects such as cups; pots; pans; bottles; andvarious tools. The similarity based category prediction is achieved by employingpropagation kernels; a recently introduced graph kernel for partially labeled graphs; ongraph representations of 3D point clouds of objects. Our work highlights the importance of …,Online Proceedings of the Eleventh Workshop on Mining and Learning with Graphs,2013,4
Learning relational probabilistic models from partially observed data-opening the closed-world assumption,Tushar Khot; Sriraam Natarajan; Kristian Kersting; Jude Shavlik,Abstract. Recent years have seen a surge of interest in learning the structure of StatisticalRelational Learning (SRL) models that combine logic with probabilities. Most of thesemodels apply the closed-world assumption ie; whatever is not observed is false in the world.In this work; we consider the problem of learning the structure of SRL models in thepresence of hidden data ie we open the closed-world assumption. We develop a functional-gradient boosting algorithm based on EM to learn the structure and parameters of themodels simultaneously and apply it to learn different kinds of models–RelationalDependency Networks; Markov Logic Networks and relational policies. Our results in avariety of domains demonstrate that the algorithms can effectively learn with missing data.,Proceedings of the 23rd International Conference on Inductive Logic Programming (ILP-13),2013,4
Geodblp: Geo-tagging dblp for mining the sociology of computer science,Fabian Hadiji; Kristian Kersting; Christian Bauckhage; Babak Ahmadi,Abstract: Many collective human activities have been shown to exhibit universal patterns.However; the possibility of universal patterns across timing events of researcher migrationhas barely been explored at global scale. Here; we show that timing events of migrationwithin different countries exhibit remarkable similarities. Specifically; we look at thedistribution governing the data of researcher migration inferred from the web. Compiling thedata in itself represents a significant advance in the field of quantitative analysis of migrationpatterns. Official and commercial records are often access restricted; incompatible betweencountries; and especially not registered across researchers. Instead; we introduce GeoDBLPwhere we propagate geographical seed locations retrieved from the web across the DBLPdatabase of 1;080;958 authors and 1;894;758 papers. But perhaps more important is that …,arXiv preprint arXiv:1304.7984,2013,4
“Deep Phenotyping” of Early Plant Response to Abiotic Stress Using Non-invasive Approaches in Barley,Agim Ballvora; Christoph Römer; Mirwaes Wahabzada; Uwe Rascher; Christian Thurau; Christian Bauckhage; Kristian Kersting; Lutz Plümer; Jens Léon,Abstract The basic mechanisms of yield maintenance under drought conditions are far frombeing understood. Pre-symptomatic water stress recognition would help to get insides intocomplex plant mechanistic basis of plant response when confronted to water shortageconditions and is of great relevance in precision plant breeding and production. The plantreactions to drought stress result in spatial; temporal and tissue-specific pattern changeswhich can be detected using non-invasive sensor techniques; such as hyperspectralimaging. The “response turning time-point” in the temporal curve of plant response to stressrather than the maxima is the most relevant time-point for guided sampling to get insightsinto mechanistic basis of plant response to drought stress. Comparative hyperspectral imageanalysis was performed on barley (Hordeum vulgare) plants grown under well-watered …,*,2013,4
Efficient learning for hashing proportional data,Zhao Xu; Kristian Kersting; Christian Bauckhage,Spectral hashing (SH) seeks compact binary codes of data points so that Hammingdistances between codes correlate with data similarity. Quickly learning such codes typicallyboils down to principle component analysis (PCA). However; this is only justified for normallydistributed data. For proportional data (normalized histograms); this is not the case. Due tothe sum-to-unity constraint; features that are as independent as possible will not all beuncorrelated. In this paper; we show that a linear-time transformation efficiently copes withsum-to-unity constraints: first; we select a small number K of diverse data points bymaximizing the volume of the simplex spanned by these prototypes; second; we representeach data point by means of its cosine similarities to the K selected prototypes. Thismaximum volume hashing is sensible since each dimension in the transformed space is …,Data Mining (ICDM); 2012 IEEE 12th International Conference on,2012,4
Matrix factorization as search,Kristian Kersting; Christian Bauckhage; Christian Thurau; Mirwaes Wahabzada,Abstract Simplex Volume Maximization (SiVM) exploits distance geometry for efficientlyfactorizing gigantic matrices. It was proven successful in game; social media; and plantmining. Here; we review the distance geometry approach and argue that it generallysuggests to factorize gigantic matrices using search-based instead of optimizationtechniques.,Joint European Conference on Machine Learning and Knowledge Discovery in Databases,2012,4
Pairwise markov logic,Daan Fierens; Kristian Kersting; Jesse Davis; Jian Chen; Martin Mladenov,Abstract For many tasks in fields like computer vision; computational biology and informationextraction; popular probabilistic inference methods have been devised mainly forpropositional models that contain only unary and pairwise clique potentials. In contrast;statistical relational approaches typically do not restrict a model's representational powerand use high-order potentials to capture the rich structure of relational domains. This paperaims to bring both worlds closer together. We introduce pairwise Markov Logic; a subset ofMarkov Logic where each formula contains at most two atoms. We show that every non-pairwise Markov Logic Network (MLN) can be transformed or 'reduced'to a pairwise MLN.Thus; existing; highly efficient probabilistic inference methods can be employed for pairwiseMLNs without the overhead of devising or implementing high-order variants. Experiments …,International Conference on Inductive Logic Programming,2012,4
Reasoning about large populations with lifted probabilistic inference,Kristian Kersting; Brian Milch; Luke S Zettlemoyer; Michael Haimes; Leslie Pack Kaelbling,Abstract We use a concrete problem in the context of planning meetings to show how liftedprobabilistic inference can dramatically speed up reasoning. We also extend lifted inferenceto deal with cardinality potentials; and examine how to deal with background knowledgeabout a social network. Lifted inference: An example. Suppose that n people (say; n= 100)have been invited to a NIPS workshop; and we are wondering whether the attendees willoverflow the 40-seat room we have reserved. A graphical model for this scenario is shown inFig. 1 (a). In this simple model; the attendance variables attend (pi) for each person pi areconditionally independent given the workshop's popularity. We get noisy information abouteach person's attendance based on the reply they have sent us:“yes”;“no”; or “no reply”.,Working Notes of the NIPS-07 Workshop on Statistical Model of Networks,2007,4
Relational Sequence Alignment,Andreas Karwath; Kristian Kersting,Abstract. The need to measure sequence similarity arises in information extraction; musicmining; biological sequence analysis; and other domains; and often coincides withsequence alignment: the more similar two sequences are; the better they can be aligned.Aligning sequences not only shows how similar sequences are; it also shows where thereare differences and correspondences between the sequences. Traditionally; the alignmenthas been considered for sequences of flat symbols only. Many real world sequences suchas protein secondary structures; however; exhibit a rich internal structures. This is akin to theproblem of dealing with structured examples studied in the field of inductive logicprogramming (ILP). In this paper; we propose to use wellestablished ILP distance measureswithin alignment methods. Although straight-forward; our initial experimental results show …,MLG 2006,2006,4
On the trade-off between iterative classification and collective classification: First experimental results,Tayfun Gürel; Kristian Kersting,Abstract. There have been two major approaches for classification of networked (linked)data. Local approaches (iterative classification) learn a model locally without consideringunlabeled data and apply the model iteratively to classify unlabeled data. Globalapproaches (collective classification); on the other hand; exploit unlabeled data and thelinks occurring between labeled and unlabeled data for learning. Naturally; globalapproaches are computationally more demanding than local ones. Moreover; for large datasets; approximate inference has to be performed to make computations feasible. In thepresent work; we investigate the benefits of collective classification based on globalprobabilistic models over local approaches. Our experimental results show that globalapproaches do not always outperform local approaches with respect to the classification …,Working Notes of the 3rd International ECML/PKDD Workshop on Mining Graphs; Trees; and Sequences,2005,4
Bayesian learning of logical hidden markov models,Tapani Raiko; Kristian Kersting; Juha Karhunen; Luc De Raedt,Abstract Logical hidden Markov models (LOHMMs) are a generalisation of hidden Markovmodels to analyze sequences of logical atoms. Transitions are factorized into two steps;selecting an atom and instantiating the variables. Uni cation is used to share informationamong states; and between states and observations. In this paper; we show how LOHMMscan be learned using Bayesian methods. Some estimators are compared and parameterestimation is tested with synthetic data.,*,2002,4
Equitable Partitions of Concave Free Energies.,Martin Mladenov; Kristian Kersting,Abstract Significant progress has recently been made towards formalizing symmetry-awarevariational inference approaches into a coherent framework. With the exception of TRW formarginal inference; however; this framework resulted in approximate MAP algorithms only;based on equitable and orbit partitions of the graphical model. Here; we deepen ourunderstanding of it for marginal inference. We show that a large class of concave freeenergies admits equitable partitions; of which orbit partitions are a special case; that can beexploited for lifting. Although already interesting on its own; we go one step further. Wedemonstrate that concave free energies of pairwise models can be reparametrized so thatexisting convergent algorithms for lifted marginal inference can be used withoutmodification.,UAI,2015,3
A Deeper Empirical Analysis of CBP Algorithm: Grounding Is the Bottleneck.,Shrutika Poyrekar; Sriraam Natarajan; Kristian Kersting,Abstract In this work-in-progress; we consider a lifted inference algorithm and analyze itsscaling properties. We compare two versions of this algorithm–the original implementationand a newer implementation built on a database. Our preliminary results show thatconstructing the factor graph from the relational model rather than the construction of thecompressed model is the key bottleneck for the application of lifted inference in largedomains.,AAAI Workshop: Statistical Relational Artificial Intelligence,2014,3
Accelerating imitation learning in relational domains via transfer by initialization,Sriraam Natarajan; Phillip Odom; Saket Joshi; Tushar Khot; Kristian Kersting; Prasad Tadepalli,Abstract The problem of learning to mimic a human expert/teacher from training trajectoriesis called imitation learning. To make the process of teaching easier in this setting; wepropose to employ transfer learning (where one learns on a source problem and transfersthe knowledge to potentially more complex target problems). We consider multi-relationalenvironments such as real-time strategy games and use functional-gradient boosting tocapture and transfer the models learned in these environments. Our experimentsdemonstrate that our learner learns a very good initial model from the simple scenario andeffectively transfers the knowledge to the more complex scenario thus achieving a jumpstart; a steeper learning curve and a higher convergence in performance.,International Conference on Inductive Logic Programming,2013,3
Can Computers Learn from the Aesthetic Wisdom of the Crowd?,Christian Bauckhage; Kristian Kersting,Abstract The social media revolution has led to an abundance of image and video data onthe Internet. Since this data is typically annotated; rated; or commented upon by largecommunities; it provides new opportunities and challenges for computer vision. Socialnetworking and content sharing sites seem to hold the key to the integration of context andsemantics into image analysis. In this paper; we explore the use of social media in thisregard. We present empirical results obtained on a set of 127;593 images with 3;741;176 tagassignments that were harvested from Flickr; a photo sharing site. We report on how userstag and rate photos and present an approach towards automatically recognizing theaesthetic appeal of images using confidence-based classifiers to alleviate effects due toambiguously labeled data. Our results indicate that user generated content allows for …,KI-Künstliche Intelligenz,2013,3
Lifted Inference via k-Locality.,Martin Mladenov; Kristian Kersting,Abstract Lifted inference approaches exploit symmetries of a graphical model. So far; onlythe automorphism group of the graphical model has been proposed to formalize thesymmetries used. We show that this is only the GI-complete tip of a hierarchy and that theamount of lifting depends on how local the inference algorithm is: if the LP relaxationintroduces constraints involving features over at most k variables; then the amount of liftingdecreases monotonically with k. This induces a hierarchy of lifted inference algorithms; withlifted BP and MPLP at the bottom and exact inference methods at the top. In between; thereare relaxations whose liftings are equitable partitions of intermediate coarseness; which allcan be computed in polynomial time.,AAAI Workshop: Statistical Relational Artificial Intelligence,2013,3
Representational power of probabilistic-logical models: From upgrading to downgrading,Kristian Kersting,*,In IJCAI-2003 Workshop on Learning Statistical Models from Relational Data,2003,3
Bayes’ sche-logische Programme,Kristian Kersting,*,Master's thesis; Albert-Ludwigs-University; Freiburg; Germany,2000,3
Spectral patterns reveal early resistance reactions of barley against Blumeria graminis f. sp. hordei,Matheus Thomas Kuska; Anna Brugger; Stefan Thomas; Mirwaes Wahabzada; Kristian Kersting; Erich-Christian Oerke; Ulrike Steiner; Anne-Katrin Mahlein,Differences in early plant–pathogen interactions are mainly characterized by usingdestructive methods. Optical sensors are advanced techniques for phenotyping host–pathogen interactions on different scales and for detecting subtle plant resistance responsesagainst pathogens. A microscope with a hyperspectral camera was used to studyinteractions between Blumeria graminis f. sp. hordei and barley (Hordeum vulgare)genotypes with high susceptibility or resistance due to hypersensitive response (HR) andpapilla formation. Qualitative and quantitative assessment of pathogen development wasused to explain changes in hyperspectral signatures. Within 48 h after inoculation; genotype-specific changes in the green and red range (500 to 690 nm) and a blue shift of the red-edgeinflection point were observed. Manual analysis indicated resistance-specific reflectance …,Phytopathology,2017,2
Plant disease detection by hyperspectral imaging: from the lab to the field,AK Mahlein; MT Kuska; S Thomas; D Bohnenkamp; E Alisaac; J Behmann; M Wahabzada; K Kersting,Abstract The detection and identification of plant diseases is a fundamental task insustainable crop production. An accurate estimate of disease incidence; disease severityand negative effects on yield quality and quantity is important for precision crop production;horticulture; plant breeding or fungicide screening as well as in basic and applied plantresearch. Particularly hyperspectral imaging of diseased plants offers insight into processesduring pathogenesis. By hyperspectral imaging and subsequent data analysis routines; itwas possible to realize an early detection; identification and quantification of differentrelevant plant diseases. Depending on the measuring scale; even subtle processes ofdefence and resistance mechanism of plants could be evaluated. Within this scope; recentresults from studies in barley; wheat and sugar beet and their relevant foliar diseases will …,Advances in Animal Biosciences,2017,2
Simplex Volume Maximization (SiVM): A matrix factorization algorithm with non-negative constrains and low computing demands for the interpretation of full spectral...,Matthias Alfeld; Mirwaes Wahabzada; Christian Bauckhage; Kristian Kersting; Geert van der Snickt; Petria Noble; Koen Janssens; Gerd Wellenreuther; Gerald Falkenberg,Abstract Technological progress allows for an ever-faster acquisition of hyperspectral data;challenging the users to keep up with interpreting the recorded data. Matrix factorization; therepresentation of data sets by bases (or loads) and coefficient (or score) images is long usedto support the interpretation of complex data sets. We propose in this publication SimplexVolume Maximization (SiVM) for the analysis of X-ray fluorescence (XRF) imaging data sets.SiVM selects archetypical data points that represents the data set and thus provides easilyunderstandable bases; preserves the non-negative character of XRF data sets and has lowdemands concerning computing resources. We apply SiVM on an XRF data set of HansMemling's Portrait of a man from the Lespinette family from the collection of the Mauritshuis(The Hague; NL) and discuss capabilities and shortcomings of SiVM.,Microchemical Journal,2017,2
A unifying view of explicit and implicit feature maps for structured data: systematic studies of graph kernels,Nils M Kriege; Marion Neumann; Christopher Morris; Kristian Kersting; Petra Mutzel,Abstract: Non-linear kernel methods can be approximated by fast linear ones using suitableexplicit feature maps allowing their application to large scale problems. To this end; explicitfeature maps of kernels for vectorial data have been extensively studied. As many real-worlddata is structured; various kernels for complex data like graphs have been proposed.Indeed; many of them directly compute feature maps. However; the kernel trick is employedwhen the number of features is very large or the individual vertices of graphs are annotatedby real-valued attributes. Can we still compute explicit feature maps efficiently under thesecircumstances? Triggered by this question; we investigate how general convolution kernelsare composed from base kernels and construct corresponding feature maps. We apply ourresults to widely used graph kernels and analyze for which kernels and graph properties …,arXiv preprint arXiv:1703.00676,2017,2
Non-negative matrix factorization for the near real-time interpretation of absorption effects in elemental distribution images acquired by X-ray fluorescence imaging,Matthias Alfeld; Mirwaes Wahabzada; Christian Bauckhage; Kristian Kersting; Gerd Wellenreuther; Pere Barriobero-Vila; Guillermo Requena; Ulrike Boesenberg; Gerald Falkenberg,Elemental distribution images acquired by imaging X-ray fluorescence analysis can containhigh degrees of redundancy and weakly discernible correlations. In this article near real-time non-negative matrix factorization (NMF) is described for the analysis of a number ofdata sets acquired from samples of a bi-modal α+ β Ti-6Al-6V-2Sn alloy. NMF was used forthe first time to reveal absorption artefacts in the elemental distribution images of thesamples; where two phases of the alloy; namely α and β; were in superposition. The findingsand interpretation of the NMF results were confirmed by Monte Carlo simulation of thelayered alloy system. Furthermore; it is shown how the simultaneous factorization of severalstacks of elemental distribution images provides uniform basis vectors and consequentlysimplifies the interpretation of the representation.,Journal of synchrotron radiation,2016,2
High-level reasoning and low-level learning for grasping: A probabilistic logic pipeline,Laura Antanas; Plinio Moreno; Marion Neumann; Rui Pimentel de Figueiredo; Kristian Kersting; José Santos-Victor; Luc De Raedt,Abstract: While grasps must satisfy the grasping stability criteria; good grasps depend on thespecific manipulation scenario: the object; its properties and functionalities; as well as thetask and grasp constraints. In this paper; we consider such information for robot grasping byleveraging manifolds and symbolic object parts. Specifically; we introduce a newprobabilistic logic module to first semantically reason about pre-grasp configurations withrespect to the intended tasks. Further; a mapping is learned from part-related visual featuresto good grasping points. The probabilistic logic module makes use of object-taskaffordances and object/task ontologies to encode rules that generalize over similar objectparts and object/task categories. The use of probabilistic logic for task-dependent graspingcontrasts with current approaches that usually learn direct mappings from visual …,arXiv preprint arXiv:1411.1108,2014,2
Relational linear programs,Kristian Kersting; Martin Mladenov; Pavel Tokmakov,Abstract: We propose relational linear programming; a simple framework for combing linearprograms (LPs) and logic programs. A relational linear program (RLP) is a declarative LPtemplate defining the objective and the constraints through the logical concepts of objects;relations; and quantified variables. This allows one to express the LP objective andconstraints relationally for a varying number of individuals and relations among them withoutenumerating them. Together with a logical knowledge base; effectively a logical programconsisting of logical facts and rules; it induces a ground LP. This ground LP is solved usinglifted linear programming. That is; symmetries within the ground LP are employed to reduceits dimensionality; if possible; and the reduced program is solved using any off-the-shelf LPsolver. In contrast to mainstream LP template languages like AMPL; which features a …,arXiv preprint arXiv:1410.3125,2014,2
Efficient information theoretic clustering on discrete lattices,Christian Bauckhage; Kristian Kersting,Abstract: We consider the problem of clustering data that reside on discrete; low dimensionallattices. Canonical examples for this setting are found in image segmentation and key pointextraction. Our solution is based on a recent approach to information theoretic clusteringwhere clusters result from an iterative procedure that minimizes a divergence measure. Wereplace costly processing steps in the original algorithm by means of convolutions. Theseallow for highly efficient implementations and thus significantly reduce runtime. This papertherefore bridges a gap between machine learning and signal processing.,arXiv preprint arXiv:1310.7114,2013,2
Latent dirichlet allocation uncovers spectral characteristics of drought stressed plants,Mirwaes Wahabzada; Kristian Kersting; Christian Bauckhage; Christoph Römer; Agim Ballvora; Francisco Pinto; Uwe Rascher; Jens Léon; Lutz Ploemer,Abstract: Understanding the adaptation process of plants to drought stress is essential inimproving management practices; breeding strategies as well as engineering viable cropsfor a sustainable agriculture in the coming decades. Hyper-spectral imaging provides aparticularly promising approach to gain such understanding since it allows to discover non-destructively spectral characteristics of plants governed primarily by scattering andabsorption characteristics of the leaf internal structure and biochemical constituents. Severaldrought stress indices have been derived using hyper-spectral imaging. However; they aretypically based on few hyper-spectral images only; rely on interpretations of experts; andconsider few wavelengths only. In this study; we present the first data-driven approach todiscovering spectral drought stress indices; treating it as an unsupervised labeling …,arXiv preprint arXiv:1210.4919,2012,2
Early Prediction of Coronary Artery Calcification Levels Using Statistical Relational Learning,Sriraam Natarajan; Kristian Kersting; Saket Joshi; Santiago Saldana; Edward Ip; D Jacobs; Jeffrey Carr,Abstract Coronary heart disease (CHD) is a major cause of death worldwide. Although amultitude of cardiovascular risks factors have been identified; CHD most likely reflectsactually complex interactions of these factors even over time. Today's datasets fromlongitudinal studies offer great promise to uncover these interactions but also poseenormous analytical problems due to typically large amount of both discrete and continuousmeasurements and risk factors with potential long-range interactions over time. Ourinvestigation demonstrates that a statistical relational analysis of longitudinal data can easilyuncover complex interactions of risks factors and actually predict future coronary arterycalcified (CAC) plaque levels—an indicator of the amount of CHD present in an individual—significantly better than traditional non-relational machine learning approaches. The …,Workshop on Machine Learning for Clinical Data Analysis. Edinburgh; Scotland,2012,2
Combining video and sequential statistical relational techniques to monitor card games,Laura Antanas; Bernd Gutmann; Ingo Thon; Kristian Kersting; Luc De Raedt,Abstract: The key to make computer games more compelling and interesting is to createintelligent artificial game agents. A first step is teaching them the protocols to play a game.To the best of our knowledge; most systems which train AI agents are used in virtualenvironments. In this work we train a computer system in a real world environment by videostreams. First; we demonstrate a way to bridge the gap between low-level video data andhigh-level symbolic data. Second; using the high-level; yet noisy data; we show that state-of-the-art statistical relational learning systems are able to capture underlying concepts invideo streams. We evaluate the selected methods on the task of detecting fraudulentbehavior in card games.,Proceedings of the Annual Belgian-Dutch Conference on Machine Learning,2010,2
ILP; the blind; and the elephant: Euclidean embedding of co-proven queries,Hannes Schulz; Kristian Kersting; Andreas Karwath,Abstract Relational data is complex. This complexity makes one of the basic steps of ILPdifficult: understanding the data and results. If the user cannot easily understand it; he drawsincomplete conclusions. The situation is very much as in the parable of the blind men andthe elephant that appears in many cultures. In this tale the blind work independently andwith quite different pieces of information; thereby drawing very different conclusions aboutthe nature of the beast. In contrast; visual representations make it easy to shift from oneperspective to another while exploring and analyzing data. This paper describes a methodfor embedding interpretations and queries into a single; common Euclidean space based ontheir co-proven statistics. We demonstrate our method on real-world datasets showing thatILP results can indeed be captured at a glance.,International Conference on Inductive Logic Programming,2009,2
Identifying mathematical models of the mechanically ventilated lung using equation discovery,Steven Ganzert; Knut Möller; Stefan Kramer; Kristian Kersting; Josef Guttmann,Abstract Mechanical ventilation is the live-saving therapy in intensive care medicine by allmeans. Nevertheless; it can induce severe mechanical stress to the lung; which generallyimpairs the outcome of the therapy. To reduce the risk of a ventilator induced lung injury(VILI); lung protective ventilation is essential; especially for patients with a previous medicalhistory like the adult respiratory distress syndrome (ARDS). The prerequisite for lungprotective ventilation approaches is the knowledge about the physical behavior of thehuman lung under the condition of mechanical ventilation. This knowledge is commonlydescribed by mathematical models. Diverse models have been introduced to representparticular aspects of mechanical characteristics of the lung. A commonly accepted generalmodel is the equation of motion; which relates the airway pressure to the airflow and the …,*,2009,2
Mach Learn,L De; Raedt K Kersting; A Kimmig; K Revoredo; H Toivonen; Raedt A Kimmig; L De Raedt; K Kersting,Abstract ProbLog is a recently introduced probabilistic extension of Prolog (De Raedt; et al.in Proceedings of the 20th international joint conference on artificial intelligence; pp. 2468–2473; 2007). A ProbLog program defines a distribution over logic programs by specifying foreach clause the probability that it belongs to a randomly sampled program; and theseprobabilities are mutually independent. The semantics of ProbLog is then defined by thesuccess probability of a query in a randomly sampled program. This paper introduces thetheory compression task for ProbLog; which consists of selecting that subset of clauses of agiven ProbLog program that maximizes the likelihood wrt a set of positive and negativeexamples. Experiments in the context of discovering links in real biological networksdemonstrate the practical applicability of the approach.,*,2007,2
Revising probabilistic prolog programs,Luc De Raedt; Kristian Kersting; Angelika Kimmig; Kate Revoredo; Hannu Toivonen,A ProbLog program consists – as Prolog – of a set of definite clauses. However; in ProbLog everyclause ci is labeled with the probability pi that it is true. Example 1. Within bibliographic dataanalysis; the similarity structure among items can improve information retrieval results. Considera collection of papers {a; b; c; d} and some pairwise similarities similar(a; b); eg; based on keyword analysis. Two items X and Y are related(X; Y) if they are similar (such as a and c) or if Xis similar to some item Z which is related to Y. Uncertainty in the data and in the inference canelegantly be represented by the attached probabilities … 1.0 : related(X; Y) : −similar(X; Y).0.8 : related(X; Y) : −similar(X; Z); related(Z; Y). 0.9 : similar(a; c). 0.9 : similar(c; b). 0.6 :similar(c; d). 0.7 : similar(d; b) … A ProbLog program T = {p1 : c1; ··· ;pn : cn} now defines a probabilitydistri- bution over logic programs L ⊆ LT = {c1; ··· ;cn} in the following way:,International Conference on Inductive Logic Programming,2006,2
Core dependency networks,Alejandro Molina; Alexander Munteanu; Kristian Kersting,Abstract Many applications infer the structure of a probabilistic graphical model from data toelucidate the relationships between variables. But how can we train graphical models on amassive data set? In this paper; we show how to construct coresets—compressed data setswhich can be used as proxy for the original data and have provably bounded worst caseerror—for Gaussian dependency networks (DNs); ie; cyclic directed graphical models overGaussians; where the parents of each variable are its Markov blanket. Specifically; we provethat Gaussian DNs admit coresets of size independent of the size of the data set.Unfortunately; this does not extend to DNs over members of the exponential family ingeneral. As we will prove; Poisson DNs do not admit small coresets. Despite this worst-caseresult; we will provide an argument why our coreset construction for DNs can still work …,Proceedings of the 32nd AAAI Conference on Artificial Intelligence (AAAI). AAAI Press Google Scholar,2018,1
Mixed Sum-Product Networks: A Deep Architecture for Hybrid Domains,Alejandro Molina; Antonio Vergari; Nicola Di Mauro; Sriraam Natarajan; Floriana Esposito; Kristian Kersting,Abstract While all kinds of mixed data—from personal data; over panel and scientific data; topublic and commercial data—are collected and stored; building probabilistic graphicalmodels for these hybrid domains becomes more difficult. Users spend significant amounts oftime in identifying the parametric form of the random variables (Gaussian; Poisson; Logit;etc.) involved and learning the mixed models. To make this difficult task easier; we proposethe first trainable probabilistic deep architecture for hybrid domains that features tractablequeries. It is based on Sum-Product Networks (SPNs) with piecewise polynomial leafdistributions together with novel nonparametric decomposition and conditioning steps usingthe Hirschfeld-Gebelein-Rényi Maximum Correlation Coefficient. This relieves the user fromdeciding a-priori the parametric form of the random variables but is still expressive …,*,2018,1
Global Weisfeiler-Lehman Graph Kernels,Christopher Morris; Kristian Kersting; Petra Mutzel,Abstract: Most state-of-the-art graph kernels only take local graph properties into account; ie;the kernel is computed with regard to properties of the neighborhood of vertices or othersmall substructures only. On the other hand; kernels that do take global graph properties intoaccount may not scale well to large graph databases. Here we propose to start exploring thespace between local and global graph kernels; striking the balance between both worlds.Specifically; we introduce a novel graph kernel based on the $ k $-dimensional Weisfeiler-Lehman algorithm; and show that it takes local as well as global properties into account.Unfortunately; the $ k $-dimensional Weisfeiler-Lehman scales exponentially in $ k $.Consequently; we devise a stochastic version of the kernel with provable approximationguarantees using conditional Rademacher averages. On bounded-degree graphs; it can …,arXiv preprint arXiv:1703.02379,2017,1
Relational restricted boltzmann machines: A probabilistic logic learning approach,Navdeep Kaur; Gautam Kunapuli; Tushar Khot; Kristian Kersting; William Cohen; Sriraam Natarajan,Abstract. We consider the problem of learning Boltzmann machine classifiers from relationaldata. Our goal is to extend the deep belief framework of RBMs to statistical relationalmodels. This allows one to exploit the feature hierarchies and the non-linearity inherent inRBMs over the rich representations used in statistical relational learning (SRL). Specifically;we use lifted random walks to generate features for predicates that are then used toconstruct the observed features in the RBM in a manner similar to Markov Logic Networks.We show empirically that this method of constructing an RBM is comparable or better thanthe state-of-theart probabilistic relational learning algorithms on four relational domains.,*,2017,1
Lifted Inference for Convex Quadratic Programs.,Martin Mladenov; Leonard Kleinhans; Kristian Kersting,Abstract Symmetry is the essential element of lifted inference that has recently demonstratedthe possibility to perform very efficient inference in highly-connected; but symmetricprobabilistic models. This raises the question; whether this holds for optimization problemsin general. Here we show that for a large class of optimization methods this is actually thecase. Specifically; we introduce the concept of fractional symmetries of convex quadraticprograms (QPs); which lie at the heart of many AI and machine learning approaches; andexploit it to lift; ie; to compress QPs. These lifted QPs can then be tackled with the usualoptimization toolbox (off-the-shelf solvers; cutting plane algorithms; stochastic gradientsetc.). If the original QP exhibits symmetry; then the lifted one will generally be more compact;and hence more efficient to solve.,AAAI,2017,1
The Symbolic Interior Point Method.,Martin Mladenov; Vaishak Belle; Kristian Kersting,Abstract Numerical optimization is arguably the most prominent computational framework inmachine learning and AI. It can be seen as an assembly language for hard combinatorialproblems ranging from classification and regression in learning; to computing optimalpolicies and equilibria in decision theory; to entropy minimization in information sciences.Unfortunately; specifying such problems in complex domains involving relations; objects andother logical dependencies is cumbersome at best; requiring considerable expertknowledge; and solvers require models to be painstakingly reduced to standard forms. Toovercome this; we introduce a rich modeling framework for optimization problems that allowsconvenient codification of symbolic structure. Rather than reducing this symbolic structure toa sparse or dense matrix; we represent and exploit it directly using algebraic decision …,AAAI,2017,1
Collective attention on the Web,Christian Bauckhage; Kristian Kersting,Abstract Understanding the dynamics of collective human attention has been called a keyscientific challenge for the information age. Tackling this challenge; this monographexplores the dynamics of collective attention related to Internet phenomena such as Internetmemes; viral videos; or social media platforms and Web-based businesses. To this end; weanalyze time series data that directly or indirectly represent how the interest of largepopulations of Web users in content or services develops over time. Regardless of regionalor cultural contexts; we generally observe strong regularities in time series that reflectattention dynamics and we discuss mathematical models that provide plausibleexplanations as to what drives the apparently dominant dynamics of rapid initial growth andprolonged decline.,Foundations and Trends® in Web Science,2016,1
Computational Sustainability,Jörg Lässig; Kristian Kersting; Katharina Morik,The series “Studies in Computational Intelligence”(SCI) publishes new developments andadvances in the various areas of computational intelligence—quickly and with a high quality.The intent is to cover the theory; applications; and design methods of computationalintelligence; as embedded in the fields of engineering; computer science; physics and lifesciences; as well as the methodologies behind them. The series contains monographs;lecture notes and edited volumes in computational intelligence spanning the areas of neuralnetworks; connectionist systems; genetic algorithms; evolutionary computation; artificialintelligence; cellular automata; self-organizing systems; soft computing; fuzzy systems; andhybrid intelligent systems. Of particular value to both the contributors and the readership arethe short publication timeframe and the worldwide distribution; which enable both wide …,*,2016,1
Adaptive streaming anomaly analysis,Zhao Xu; Lorenzo von Ritter; Kristian Kersting,Abstract Detecting anomalous activities from time series data is critical for enhancingavailability and security of systems in many domains. Streaming data usually containscomplex dynamic patterns; which complicates the learning process. In this paper; wepresent a nonparametric Bayesian method AOTS to help automating the model learning foranomaly detection in streaming time series. The method learns the dynamics of anomaly-contaminated time series with submodular optimization based kernel selection to effectivelyadapt to the data and identify potential anomalous events. Experiments on real data showencouraging results.,Proceedings of NIPS 2016 Workshop on Artificial Intelligence for Data Science,2016,1
Traffic Simulations with Empirical Data: How to Replace Missing Traffic Flows?,Lars Habel; Alejandro Molina; Thomas Zaksek; Kristian Kersting; Michael Schreckenberg,Abstract For the real-time microscopic simulation of traffic on a real-world road network; acontinuous input stream of empirical data from different locations is usually needed toachieve good results. Traffic flows for example are needed to properly simulate the influenceof slip roads and motorway exits. However; quality and reliability of empirical traffic data issometimes a problem for example because of damaged detectors; transmission errors orsimply lane diversions at road works. In this contribution; we attempt to close those datagaps of missing traffic flows with processed historical traffic data. Therefore; we compare atemporal approach based on exponential smoothing with a data-driven approach based onPoisson Dependency Networks.,*,2016,1
Deep distant supervision: Learning statistical relational models for weak supervision in natural language extraction,Sriraam Natarajan; Ameet Soni; Anurag Wazalwar; Dileep Viswanathan; Kristian Kersting,Abstract One of the challenges to information extraction is the requirement of humanannotated examples; commonly called gold-standard examples. Many successfulapproaches alleviate this problem by employing some form of distant supervision ie; lookinto knowledge bases such as Freebase as a source of supervision to create moreexamples. While this is perfectly reasonable; most distant supervision methods rely on agiven set of propositions as a source of supervision. We propose a different approach: weinfer weakly supervised examples for relations from statistical relational models learned byusing knowledge outside the natural language task. We argue that this deep distantsupervision creates more robust examples that are particularly useful when learning theentire model (the structure and parameters). We demonstrate on several domains that this …,*,2016,1
Modeling coronary artery calcification levels from behavioral data in a clinical study,Shuo Yang; Kristian Kersting; Greg Terry; Jefferey Carr; Sriraam Natarajan,Abstract Cardiovascular disease (CVD) is one of the key causes for death worldwide. Weconsider the problem of modeling an imaging biomarker; Coronary Artery Calcification(CAC) measured by computed tomography; based on behavioral data. We employ theformalism of Dynamic Bayesian Network (DBN) and learn a DBN from these data. Ourlearned DBN provides insights about the associations of specific risk factors with CAClevels. Exhaustive empirical results demonstrate that the proposed learning method yieldsreasonable performance during cross-validation.,Conference on Artificial Intelligence in Medicine in Europe,2015,1
Reports of the AAAI 2014 Conference Workshops,Stefano V Albrecht; André MS Barreto; Darius Braziunas; David L Buckeridge; Heriberto Cuayáhuitl; Nina Dethlefs; Markus Endres; Amir-massoud Farahmand; Mark Fox; Lutz Frommberger; Sam Ganzfried; Yolanda Gil; Sébastien Guillet; Lawrence E Hunter; Arnav Jhala; Kristian Kersting; George Konidaris; Freddy Lecue; Sheila McIlraith; Sriraam Natarajan; Zeinab Noorian; David Poole; Rémi Ronfard; Alessandro Saffiotti; Arash Shaban-Nejad; Biplav Srivastava; Gerald Tesauro; Rosario Uceda-Sosa; Guy Van den Broeck; Martijn Van Otterlo; Byron C Wallace; Paul Weng; Jenna Wiens; Jie Zhang,Abstract The AAAI-14 Workshop program was held Sunday and Monday; July 27–28; 2012;at the Québec City Convention Centre in Québec; Canada. Canada. The AAAI-14 workshopprogram included fifteen workshops covering a wide range of topics in artificial intelligence.The titles of the workshops were AI and Robotics; Artificial Intelligence Applied to AssistiveTechnologies and Smart Environments; Cognitive Computing for Augmented HumanIntelligence; Computer Poker and Imperfect Information; Discovery Informatics; Incentivesand Trust in Electronic Communities; Intelligent Cinematography and Editing; MachineLearning for Interactive Systems: Bridging the Gap between Perception; Action andCommunication; Modern Artificial Intelligence for Health Analytics; Multiagent Interactionwithout Prior Coordination; Multidisciplinary Workshop on Advances in Preference …,AI Magazine,2015,1
Maximum Entropy Models of Shortest Path and Outbreak Distributions in Networks,Christian Bauckhage; Kristian Kersting; Fabian Hadiji,Abstract: Properties of networks are often characterized in terms of features such as nodedegree distributions; average path lengths; diameters; or clustering coefficients. Here; westudy shortest path length distributions. On the one hand; average as well as maximumdistances can be determined therefrom; on the other hand; they are closely related to thedynamics of network spreading processes. Because of the combinatorial nature of networks;we apply maximum entropy arguments to derive a general; physically plausible model. Inparticular; we establish the generalized Gamma distribution as a continuouscharacterization of shortest path length histograms of networks or arbitrary topology.Experimental evaluations corroborate our theoretical results. Subjects: Social andInformation Networks (cs. SI); Physics and Society (physics. soc-ph) Cite as: arXiv …,arXiv preprint arXiv:1501.04232,2015,1
Graph-based Approximate Counting for Relational Probabilistic Models,Mayukh Das; Yuqing Wu; Tushar Khot; Kristian Kersting; Sriraam Natarajan,*,Working Notes of the 5th International Workshop on Statistical Relational AI (StarAI@ UAI-15),2015,1
Boosting in the presence of missing data,Sriraam Natarajan; Kristian Kersting; Tushar Khot; Jude Shavlik,Abstract The learning approaches presented in the last two chapters employed the closed-world assumption ie; whatever that is not observed in the data is assumed to be false. In thischapter; we relax this assumption and derive a boosting algorithm that can effectively workwith missing data. The derivation is independent of the model and hence we will discussabout adapting it for RDNs and MLNs. As with other chapters; we will conclude withempirical evaluation on the SRL data sets.,*,2014,1
Using Commonsense Knowledge to Automatically Create (Noisy) Training Examples from Text.,Sriraam Natarajan; Jose Picado; Tushar Khot; Kristian Kersting; Christopher Re; Jude W Shavlik,Abstract One of the challenges to information extraction is the requirement of humanannotated examples. Current successful approaches alleviate this problem by employingsome form of distant supervision ie; look into knowledge bases such as Freebase as asource of supervision to create more examples. While this is perfectly reasonable; mostdistant supervision methods rely on a hand coded background knowledge that explicitlylooks for patterns in text. In this work; we take a different approach–we create weaklysupervised examples for relations by using commonsense knowledge. The key innovation isthat this commonsense knowledge is completely independent of the natural language text.This helps when learning the full model for information extraction as against simply learningthe parameters of a known CRF or MLN. We demonstrate on two domains that this form of …,AAAI Workshop: Statistical Relational Artificial Intelligence,2013,1
MapReduce Lifting for Belief Propagation.,Babak Ahmadi; Kristian Kersting; Sriraam Natarajan,Abstract Judging by the increasing impact of machine learning on large-scale data analysisin the last decade; one can anticipate a substantial growth in diversity of the machinelearning applications for “big data” over the next decade. This exciting new opportunity;however; also raises many challenges. One of them is scaling inference within and trainingof graphical models. Typical ways to address this scaling issue are inference byapproximate message passing; stochastic gradients; and MapReduce; among others. Often;we encounter inference and training problems with symmetries and redundancies in thegraph structure. It has been shown that inference and training can indeed benefit fromexploiting symmetries; for example by lifting loopy belief propagation (LBP). That is; a modelis compressed by grouping nodes together that send and receive identical messages so …,AAAI Workshop: Statistical Relational Artificial Intelligence,2013,1
Coinciding Walk Kernels,Marion Neumann; Roman Garnett; Kristian Kersting,ABSTRACT Exploiting autocorrelation for node-label prediction in networked data has led togreat success. However; when dealing with sparsely labeled networks; common in present-day tasks; the autocorrelation assumption is difficult to exploit. Taking a step beyond; wepropose the coinciding walk kernel (cwk); a novel kernel leveraging label-structure similarity–the idea that nodes with similarly arranged labels in their local neighbourhoods are likely tohave the same label–for learning problems on partially labeled graphs. Inspired by thesuccess of random walk based schemes for the construction of graph kernels; cwk is definedin terms of the probability that the labels encountered during parallel random walks coincide.In addition to its intuitive probabilistic interpretation; coinciding walk kernels outperform state-ofthe-art kernel-and walk-based methods on the task of nodelabel prediction in sparsely …,Eleventh Workshop on Mining and Learning with Graphs (MLG-13),2013,1
A machine learning pipeline for three-way classification of alzheimer patients from structural magnetic resonance images of the brain,Sriraam Natarajan; Saket Joshi; Baidya Nath Saha; Adam Edwards; Tushar Khot; Elizabeth Moody; Kristian Kersting; Christopher T Whitlow; Joseph A Maldjian,Magnetic resonance imaging (MRI) has emerged as an important tool to identifyintermediate biomarkers of Alzheimer's disease (AD) due to its ability to measure regionalchanges in the brain that are thought to reflect disease severity and progression. In thispaper; we set out a novel pipeline that uses volumetric MRI data collected from differentsubjects as input and classifies them into one of three classes: AD; mild cognitiveimpairment (MCI) and cognitively normal (CN). Our pipeline consists of three stages-(1) asegmentation layer where brain MRI data is divided into clinically relevant regions;(2) aclassification layer that uses relational learning algorithms to make pair wise predictionsbetween the three classes; and (3) a combination layer that combines the results of thedifferent classes to obtain the final classification. One of the key features of our proposed …,Machine Learning and Applications (ICMLA); 2012 11th International Conference on,2012,1
From lifted inference to lifted models,Daan Fierens; Kristian Kersting,Abstract: In this position paper we raise the question whether lifted inference can beperformed by'lifting'the probabilistic model rather than the inference algorithm. We show thatthis is indeed possible using so-called count models; at least for the common examplesused within the exact lifting literature. The challenge is to turn this into a general approach.,*,2012,1
Statistical relational AI: logic; probability and computation,Kristian Kersting; Sriraam Natarajan; David Poole,Abstract One of the key challenges in building intelligent agents is closing the gap betweenlogical and statistical AI; so that we can have rich representations including objects; relationsand uncertainty; that we can effectively learn and carry out inference with. Over the last 25years there has been a considerable body of research into combinations of predicate logicand probability forming what has become known as statistical relational artificial intelligence(StaR-AI). We overview the foundations of the area; give some research problems; proposedsolutions; outstanding issues; and clear up some misconceptions that have arisen. Wediscuss representations; semantics; inference; learning and applications; and providereferences to the literature.,Proceedings of the 11th International Conference on Logic Programming and Nonmonotonic Reasoning (LPNMR’11),2011,1
Reports of the AAAI 2010 conference workshops,David W Aha; Mark Boddy; Vadim Bulitko; Artur S d'Avila Garcez; Prashant Doshi; Stefan Edelkamp; Christopher Geib; Piotr Gmytrasiewicz; Robert P Goldman; Pascal Hitzler; Charles Isbell; Darsana Josyula; Leslie Pack Kaelbling; Kristian Kersting; Maithilee Kunda; Luis C Lamb; Bhaskara Marthi; Keith McGreggor; Vivi Nastase; Gregory Provan; Anita Raja; Ashwin Ram; Mark Riedl; Stuart Russell; Ashish Sabharwal; Jan-Georg Smaus; Gita Sukthankar; Karl Tuyls; Ron van der Meyden; Alon Halevy; Lilyana Mihalkova; Sriraam Natarajan,Abstract The AAAI-10 Workshop program was held Sunday and Monday; July 11–12; 2010at the Westin Peachtree Plaza in Atlanta; Georgia. The AAAI-10 workshop program included13 workshops covering a wide range of topics in artificial intelligence. The titles of theworkshops were AI and Fun; Bridging the Gap between Task and Motion Planning;Collaboratively-Built Knowledge Sources and Artificial Intelligence; Goal-DirectedAutonomy; Intelligent Security; Interactive Decision Theory and Game Theory; Metacognitionfor Robust Social Systems; Model Checking and Artificial Intelligence; Neural-SymbolicLearning and Reasoning; Plan; Activity; and Intent Recognition; Statistical Relational AI;Visual Representations and Reasoning; and Abstraction; Reformulation; and Approximation.This article presents short summaries of those events.,AI Magazine,2010,1
SRL without Tears: An ILP Perspective,Kristian Kersting,Abstract Statistical relational learning addresses one of the central questions of artificialintelligence: the integration of probabilistic reasoning with first order logic representationsand machine learning. A rich variety of different formalisms and learning techniques havebeen developed. This tutorial provides an gentle introduction to and an overview of the state-of-the-art in statistical relational learning. It starts from classical settings for inductive logicprogramming and shows how they can be extended with probabilistic methods. It touchesupon lifted inference and recent developments in nonparametric approaches to statisticalrelational learning. While doing so; it reviews state-of-the-art statistical relational learningapproaches.,International Conference on Inductive Logic Programming,2008,1
Estimating the parameters of probabilistic databases from probabilistically weighted queries and proofs,Bernd Gutmann; Angelika Kimmig; Kristian Kersting; Luc De Raedt,Abstract. We introduce the problem of learning the parameters of the probabilistic databaseProbLog. Given the observed success probabilities of a set of queries; we compute theprobabilities attached to facts that have a low approximation error on the training examplesas well as on unseen examples. Assuming Gaussian error terms on the observed successprobabilities; this naturally leads to a least squares optimization problem. Our approach;called LeProbLog; is able to learn both from queries and from proofs and even from bothsimultaneously. This makes it flexible and allows faster training in domains where the proofsare available. Experiments on real world data show the usefulness and effectiveness of thisleast squares calibration of probabilistic databases. 3,Inductive Logic Programming; Late Breaking Papers,2008,1
Distributed relational state representations for complex stochastic processes,Ingo Thon; Kristian Kersting,Abstract. Several promising variants of hidden Markov models (HMMs) have recently beendeveloped to efficiently deal with large state and observation spaces and relationalstructure. Many application domains; however; have an apriori componential structure suchas parts in musical scores. In this case; exact inference within relational HMMs still growsexponentially in the number of components. In this paper; we propose to approximate thecomplex joint relational HMM with a simpler; distributed one: k relational hidden chains overn states; one for each component. Then; we iteratively perform inference for each chaingiven fixed values for the other chains until convergence. Due to this structured mean fieldapproximation; the effective size of the hidden state space collapses from O (nk) to O (n).,Proceedings of the 6th International Workshop on Mulit-Relational Data Mining,2007,1
Fisher Kernels and Logical Sequences with an Application to Protein Fold Recognition,Kristian Kersting; Thomas Gärtner,Generative models in general and hidden Markov models (HMM)[10] in particular are widelyused in computational biology. One of their application areas there is protein fold recognition[2] where one tries to understand how proteins fold up in nature. Despite of their successHMMs have some weaknesses:(1) their predictive accuracy is usually lower than that ofdiscriminative classifiers; and (2) they are able to handle sequences of flat; ie; unstructured;symbols only. Fisher Kernels [6; 5] were developed to improve the classification accuracy ofgenerative models. The key idea is to use the gradient of the log likelihood with respect tothe parameters of a generative Model as the features in a discriminative classifiers. Usually;for the generative model a HMM is used and for the discriminative classifier a support vectormachine [1] is used. This has led to improved classification results in several domains …,Working Notes of the NIPS-2002 Workshop on Machine Learning Techniques for Bioinformatics; Vancouver; Canada; December (Friday),2002,1
From Big Data to Big Artificial Intelligence?,Kristian Kersting; Ulrich Meyer,Abstract Big Data is no fad. The world is growing at an exponential rate; and so is the size ofdata collected across the globe. The data is becoming more meaningful and contextuallyrelevant; breaks new ground for machine learning and artificial intelligence (AI); and evenmoves them from research labs to production. That is; the problem has shifted fromcollecting massive amounts of data to understanding it; ie; turning data into knowledge;conclusions; and actions. This Big AI; however; often faces poor scale-up behaviour fromalgorithms that have been designed based on models of computation that are no longerrealistic for Big Data. This special issue constitutes an attempt to highlight the algorithmicchallenges and opportunities but also the social and ethical issues of Big Data. Of specificinterest and focus have been computation-and resource-efficient algorithms when …,*,2018,*
Lifted Filtering via Exchangeable Decomposition,Stefan Lüdtke; Max Schröder; Sebastian Bader; Kristian Kersting; Thomas Kirste,Abstract: We present a model for recursive Bayesian filtering based on lifted multiset states.Combining multisets with lifting makes it possible to simultaneously exploit multiplestrategies for reducing inference complexity when compared to list-based grounded staterepresentations. The core idea is to borrow the concept of Maximally Parallel MultisetRewriting Systems and to enhance it by concepts from Rao-Blackwellisation and LiftedInference; giving a representation of state distributions that enables efficient inference. Inworlds where the random variables that define the system state are exchangeable-wherethe identity of entities does not matter-it automatically uses a representation that abstractsfrom ordering (achieving an exponential reduction in complexity) and it automatically adaptswhen observations or system dynamics destroy exchangeability by breaking symmetry …,arXiv preprint arXiv:1801.10495,2018,*
DeepVizdom: Deep Interactive Data Exploration,Carsten Binnig; Kristian Kersting; Alejandro Molina; Emanuel Zgraggen,ABSTRACT We make a case for a new generation of interactive data exploration systemsthat seamlessly integrate deep models as first-class citizens into the data exploration stack.Based on three case studies; we argue that this not only enables users to gain much deeperinsights into a broader range of data sets but also helps to improve the performance andquality of existing data exploration systems.,*,2018,*
Sum-Product Autoencoding: Encoding and Decoding Representations using Sum-Product Networks,Antonio Vergari; Robert Peharz; Nicola Di Mauro; Alejandro Molina; Kristian Kersting; Floriana Esposito,Abstract Sum-Product Networks (SPNs) are a deep probabilistic architecture that up to nowhas been successfully employed for tractable inference. Here; we extend their scopetowards unsupervised representation learning: we encode samples into continuous andcategorical embeddings and show that they can also be decoded back into the original inputspace by leveraging MPE inference. We characterize when this Sum-Product Autoencoding(SPAE) leads to equivalent reconstructions and extend it towards dealing with missingembedding information. Our experimental results on several multilabel classificationproblems demonstrate that SPAE is competitive with state-of-the-art autoencoderarchitectures; even if the SPNs were never trained to reconstruct their inputs.,*,2018,*
Monitoring wound healing in a 3D wound model by hyperspectral imaging and efficient clustering,Mirwaes Wahabzada; Manuela Besser; Milad Khosravani; Matheus Thomas Kuska; Kristian Kersting; Anne-Katrin Mahlein; Ewa Stürmer,Wound healing is a complex and dynamic process with different distinct and overlappingphases from homeostasis; inflammation and proliferation to remodelling. Monitoring thehealing response of injured tissue is of high importance for basic research and clinicalpractice. In traditional application; biological markers characterize normal and abnormalwound healing. Understanding functional relationships of these biological processes isessential for developing new treatment strategies. However; most of the present techniques(in vitro or in vivo) include invasive microscopic or analytical tissue sampling. In the presentstudy; a non-invasive alternative for monitoring processes during wound healing isintroduced. Within this context; hyperspectral imaging (HSI) is an emerging and innovativenon-invasive imaging technique with different opportunities in medical applications. HSI …,PloS one,2017,*
Glocalized Weisfeiler-Lehman Graph Kernels: Global-Local Feature Maps of Graphs,Christopher Morris; Kristian Kersting; Petra Mutzel,Most state-of-the-art graph kernels only take local graph properties into account; ie; thekernel is computed with regard to properties of the neighborhood of vertices or other smallsubstructures. On the other hand; kernels that do take global graph properties into accountmay not scale well to large graph databases. Here we propose to start exploring the spacebetween local and global graph kernels; so called glocalized graph kernels; striking thebalance between both worlds. Specifically; we introduce a novel graph kernel based on thek-dimensional Weisfeiler-Lehman algorithm. Unfortunately; the k-dimensional Weisfeiler-Lehman algorithm scales exponentially in k. Consequently; we devise a stochastic versionof the kernel with provable approximation guarantees using conditional Rademacheraverages. On bounded-degree graphs; it can even be computed in constant time. We …,Data Mining (ICDM); 2017 IEEE International Conference on,2017,*
Modeling Heart Procedures from EHRs: An Application of Exponential Families,Shuo Yang; Fabian Hadiji; Kristian Kersting; Shaun Grannis; Sriraam Natarajan,Abstract—In order to facilitate better estimations on coronary artery disease conditions of apatient; we aim to predict the number of Angioplasty (a coronary artery procedure) by takinginto account all the information from his/her Electronic Health Record (EHR) data. For thispurpose; two exponential family members—multinomial distribution and Poisson distributionmodels—are considered; which treat the target variable as categorical-valued and count-valued respectively. From the perspective of exponential family; we derive the functionalgradient boosting approach for these two distributions and analyze their assumptions withreal EHR data. Our empirical results show that Poisson models appear to be more faithful formodeling the number of this procedure.,2017 IEEE International Conference on Bioinformatics and Biomedicine (BIBM),2017,*
Semantic Interpretation of Multi-Modal Human-Behaviour Data,Mehul Bhatt; Kristian Kersting,Abstract This special issue presents interdisciplinary research—at the interface of artificialintelligence; cognitive science; and human-computer interaction—focussing on the semanticinterpretation of human behaviour. The special issue constitutes an attempt to highlight andsteer foundational methods research in artificial intelligence; in particular knowledgerepresentation and reasoning; for the development of human-centred cognitive assistivetechnologies. Of specific interest and focus have been application outlets for basic researchin knowledge representation and reasoning and computer vision for the cognitive;behavioural; and social sciences.,*,2017,*
Coreset based Dependency Networks,Alejandro Molina; Alexander Munteanu; Kristian Kersting,Abstract: Many applications infer the structure of a probabilistic graphical model from data toelucidate the relationships between variables. But how can we train graphical models on amassive data set? In this paper; we show how to construct coresets-compressed data setswhich can be used as proxy for the original data and have provably bounded worst caseerror-for Gaussian dependency networks (DNs); ie; cyclic directed graphical models overGaussians; where the parents of each variable are its Markov blanket. Specifically; we provethat Gaussian DNs admit coresets of size independent of the size of the data set.Unfortunately; this does not extend to DNs over members of the exponential family ingeneral. As we will prove; Poisson DNs do not admit small coresets. Despite this worst-caseresult; we will provide an argument why our coreset construction for DNs can still work …,arXiv preprint arXiv:1710.03285,2017,*
Sum-Product Networks for Hybrid Domains,Alejandro Molina; Antonio Vergari; Nicola Di Mauro; Sriraam Natarajan; Floriana Esposito; Kristian Kersting,Abstract: While all kinds of mixed data-from personal data; over panel and scientific data; topublic and commercial data-are collected and stored; building probabilistic graphicalmodels for these hybrid domains becomes more difficult. Users spend significant amounts oftime in identifying the parametric form of the random variables (Gaussian; Poisson; Logit;etc.) involved and learning the mixed models. To make this difficult task easier; we proposethe first trainable probabilistic deep architecture for hybrid domains that features tractablequeries. It is based on Sum-Product Networks (SPNs) with piecewise polynomial leavedistributions together with novel nonparametric decomposition and conditioning steps usingthe Hirschfeld-Gebelein-R\'enyi Maximum Correlation Coefficient. This relieves the user fromdeciding a-priori the parametric form of the random variables but is still expressive …,arXiv preprint arXiv:1710.03297,2017,*
Graph Enhanced Memory Networks for Sentiment Analysis,Zhao Xu; Romain Vial; Kristian Kersting,Abstract Memory networks model information and knowledge as memories that can bemanipulated for prediction and reasoning about questions of interest. In many cases; thereexists complicated relational structure in the data; by which the memories can be linkedtogether into graphs to propagate information. Typical examples include tree structure of asentence and knowledge graph in a dialogue system. In this paper; we present a novelgraph enhanced memory network GEMN to integrate relational information betweenmemories for prediction and reasoning. Our approach introduces graph attentions to modelthe relations; and couples them with content-based attentions via an additional neuralnetwork layer. It thus can better identify and manipulate the memories related to a givenquestion; and provides more accurate prediction about the final response. We …,Joint European Conference on Machine Learning and Knowledge Discovery in Databases,2017,*
Towards Argumentation-based Classification,Matthias Thimm; Kristian Kersting,Classification is the problem of categorizing new observations by using a classifier learntfrom already categorized examples. In general; the area of machine learning [Mitchell; 1997]has brought forth a series of different approaches to deal with this problem; from decisiontrees to support vector machines and others. Recently; approaches to statistical relationallearning [De Raedt et al.; 2016] even take the perspective of knowledge representation andreasoning into account by developing models on more formal logical and statistical grounds.In this position paper; we envisage to significantly generalize this reasoning aspect ofmachine learning towards the use of computational models of argumentation [Baroni et al.;2011]; a popular approach to commonsense reasoning; for reasoning within machinelearning. More concretely; we consider the following two-step classification approach. In …,LFU-2017,2017,*
Stochastic online anomaly analysis for streaming time series,Zhao Xu; Kristian Kersting; Lorenzo von Ritter,Abstract Identifying patterns in time series that exhibit anomalous behavior is of increasingimportance in many domains; such as financial and Web data analysis. In real applications;time series data often arrive continuously; and usually only a single scan is allowed throughthe data. Batch learning and retrospective segmentation methods would not be wellapplicable to such scenarios. In this paper; we present an online nonparametric Bayesianmethod OLAD for anomaly analysis in streaming time series. Moreover; we develop a noveland efficient online learning approach for the OLAD model based on stochastic gradientdescent. The proposed method can effectively learn the underlying dynamics of anomaly-contaminated heavy-tailed time series and identify potential anomalous events. Empiricalanalysis on real-world datasets demonstrates the effectiveness of our method.,Proceedings of the 26th International Joint Conference on Artificial Intelligence,2017,*
Automated identification of sugar beet diseases using smartphones,L Hallau; M Neumann; B Klatt; B Kleinhenz; T Klein; C Kuhn; M Röhrig; C Bauckhage; K Kersting; A‐K Mahlein; U Steiner; E‐C Oerke,Abstract Cercospora leaf spot (CLS) poses a high economic risk to sugar beet productiondue to its potential to greatly reduce yield and quality. For successful integratedmanagement of CLS rapid and accurate identification of the disease is essential. Diagnosison the basis of typical visual symptoms is often compromised by the inability to differentiateCLS symptoms from similar symptoms caused by other foliar pathogens of varyingsignificance; or from abiotic stress. An automated detection and classification of CLS andother leaf diseases; enabling a reliable basis for decisions in disease control; would be analternative to visual as well as molecular and serological methods. This paper presents analgorithm based on a RGB-image database captured with smartphone cameras for theidentification of sugar beet leaf diseases. This tool combines image acquisition and …,Plant Pathology,2017,*
Öffentlichkeitsorientierung von Wissenschaftsinstitutionen und Wissenschaftsdisziplinen,Julia Serong; Lars Koppers; Edith Luschmann; Alejandro Molina Ramirez; Kristian Kersting; Jörg Rahnenführer; Holger Wormer,Zusammenfassung Die Qualität der Wissenschaftskommunikation in Deutschland istGegenstand intensiver Debatten. Empirische Daten zu Inhalt und Umfang insbesondere derinstitutionellen Wissenschaftskommunikation und-PR sind jedoch rar. Ausgehend von derMedialisierungsthese präsentiert dieser Beitrag Befunde einer deskriptivenLängsschnittstudie zu Pressemitteilungen von Forschungseinrichtungen; die vom„Informationsdienst Wissenschaft “(idw) im Zeitraum von 1995 bis 2015 verbreitet wurden.Die quantitative Analyse der mehr als 300.000 Pressemitteilungen erfolgte ininterdisziplinärer Kooperation mit Methoden aus der Informatik; Statistik undKommunikationswissenschaft. Dabei wurde neben dem zeitlichen Verlauf nachverschiedenen Typen von Forschungseinrichtungen und wissenschaftlichen Disziplinen …,Publizistik,2017,*
Learning Through Advice-Seeking via Transfer,Phillip Odom; Raksha Kumaraswamy; Kristian Kersting; Sriraam Natarajan,Abstract Experts possess vast knowledge that is typically ignored by standard machinelearning methods. This rich; relational knowledge can be utilized to learn more robustmodels especially in the presence of noisy and incomplete training data. Such experts areoften domain but not machine learning experts. Thus; deciding what knowledge to provide isa difficult problem. Our goal is to improve the human-machine interaction by providing theexpert with a machine-generated bias that can be refined by the expert as necessary. To thiseffect; we propose using transfer learning; leveraging knowledge in alternative domains; toguide the expert to give useful advice. This knowledge is captured in the form of first-orderlogic horn clauses. We demonstrate empirically the value of the transferred knowledge; aswell as the contribution of the expert in providing initial knowledge; plus revising and …,International Conference on Inductive Logic Programming,2016,*
Machine Learning meets Data-Driven Journalism: Boosting International Understanding and Transparency in News Coverage,Elena Erdmann; Karin Boczek; Lars Koppers; Gerret von Nordheim; Christian Pölitz; Alejandro Molina; Katharina Morik; Henrik Müller; Jörg Rahnenführer; Kristian Kersting,Abstract: Migration crisis; climate change or tax havens: Global challenges need globalsolutions. But agreeing on a joint approach is difficult without a common ground fordiscussion. Public spheres are highly segmented because news are mainly produced andreceived on a national level. Gain-ing a global view on international debates aboutimportant issues is hindered by the enormous quantity of news and by language barriers.Media analysis usually focuses only on qualitative re-search. In this position statement; weargue that it is imperative to pool methods from machine learning; journalism studies andstatistics to help bridging the segmented data of the international public sphere; using theTransatlantic Trade and Investment Partnership (TTIP) as a case study.,arXiv preprint arXiv:1606.05110,2016,*
Lifted Convex Quadratic Programming,Martin Mladenov; Leonard Kleinhans; Kristian Kersting,Abstract: Symmetry is the essential element of lifted inference that has recently demon-strated the possibility to perform very efficient inference in highly-connected; but symmetricprobabilistic models models. This raises the question; whether this holds for optimisationproblems in general. Here we show that for a large class of optimisation methods this isactually the case. More precisely; we introduce the concept of fractional symmetries ofconvex quadratic programs (QPs); which lie at the heart of many machine learningapproaches; and exploit it to lift; ie; to compress QPs. These lifted QPs can then be tackledwith the usual optimization toolbox (off-the-shelf solvers; cutting plane algorithms; stochasticgradients etc.). If the original QP exhibits symmetry; then the lifted one will generally be morecompact; and hence their optimization is likely to be more efficient. Subjects: Artificial …,arXiv preprint arXiv:1606.04486,2016,*
RELOOP: A Python-Embedded Declarative Language for Relational Optimization,Martin Mladenov; Danny Heinrich; Leonard Kleinhans; Felix Gonsior; Kristian Kersting,Abstract We present RELOOP; a domain-specific language for relational optimizationembedded in Python. It allows the user to express relational optimization problems in anatural syntax that follows logic and linear algebra; rather than in the restrictive standardform required by solvers; and can automatically compile the model to a lower-order butequivalent model. Moreover; RELOOP makes it easy to combine relational optimization withhigh-level features of Python such as loops; parallelism and interfaces to relationaldatabases.,Workshops at the Thirtieth AAAI Conference on Artificial Intelligence,2016,*
Learning using unselected features (LUFe),Joseph G Taylor; Viktoriia Sharmanska; Kristian Kersting; David Weir; Novi Quadrianto,Feature selection has been studied in machine learning and data mining for many years;and is a valuable way to improve classification accuracy while reducing model complexity.Two main classes of feature selection methods-filter and wrapper-discard those featureswhich are not selected; and do not consider them in the predictive model. We propose thatthese unselected features may instead be used as an additional source of information attrain time. We describe a strategy called Learning using Unselected Features (LUFe) thatallows selected and unselected features to serve different functions in classification. In thisframework; selected features are used directly to set the decision boundary; and unselectedfeatures are utilised in a secondary role; with no additional cost at test time. Our empiricalresults on 49 textual datasets show that LUFe can improve classification performance in …,Proceedings of the 25th International Joint Conference on Artificial Intelligence; New York; 9–15 July 2016,2016,*
Feeding the World with Big Data: Uncovering Spectral Characteristics and Dynamics of Stressed Plants,Kristian Kersting; Christian Bauckhage; Mirwaes Wahabzada; Anne-Kathrin Mahlein; Ulrike Steiner; Erich-Christian Oerke; Christoph Römer; Lutz Plümer,Abstract Modern communication; sensing; and actuator technologies as well as methodsfrom signal processing; pattern recognition; and data mining are increasingly applied inagriculture; ultimately helping to meet the challenge of “How to feed a hungry world?”Developments such as increased mobility; wireless networks; new environmental sensors;robots; and the computational cloud put the vision of a sustainable agriculture for anybody;anytime; and anywhere within reach. Unfortunately; data-driven agriculture also presentsunique computational problems in scale and interpretability:(1) Data is gathered often atmassive scale; and (2) researchers and experts of complementary skills have to cooperatein order to develop models and tools for data intensive discovery that yield easy-to-interpretinsights for users that are not necessarily trained computer scientists. On the problem of …,*,2016,*
Statistical Relational Artificial Intelligence: From Distributions through Actions to Optimization,Kristian Kersting; Sriraam Natarajan,Abstract Statistical Relational AI—the science and engineering of making intelligentmachines acting in noisy worlds composed of objects and relations among the objects—iscurrently motivating a lot of new AI research and has tremendous theoretical and practicalimplications. Theoretically; combining logic and probability in a unified representation andbuilding general-purpose reasoning tools for it has been the dream of AI; dating back to thelate 1980s. Practically; successful statistical relational AI tools enable new applications inseveral large; complex real-world domains including those involving big data; natural text;social networks; the web; medicine and robotics; among others. Such domains are oftencharacterized by rich relational structure and large amounts of uncertainty. Logic helps tofaithfully model the former while probability helps to effectively manage the latter. Our …,KI-Künstliche Intelligenz,2015,*
Cell Phone Image-Based Plant Disease Classification,Christian Bauckhage; Marion Neumann; Lisa Hallau; Kristian Kersting,ABSTRACT Modern communication and sensor technology coupled with powerful patternrecognition algorithms for information extraction and classification allow the developmentand use of integrated systems to tackle environmental problems. This integration isparticularly promising for applications in crop farming; where such systems can help tocontrol growth and improve yields while harmful environmental impacts are minimized.Thus; the vision of sustainable agriculture for anybody; anytime; and anywhere in the worldcan be put into reach. This chapter reviews and presents approaches to plant diseaseclassification based on cellphone images; a novel way to supply farmers with personalizedinformation and processing recommendations in real time. Several statistical image featuresand a novel scheme of measuring local textures of leaf spots are introduced. The …,Computer Vision and Pattern Recognition in Environmental Informatics,2015,*
Künstliche Intelligenz für Computerspiele,Christian Bauckhage; Kristian Kersting; Christian Thurau,Zusammenfassung Die technische Entwicklung von Computerspielen und die Entwicklungvon Methoden der Künstlichen Intelligenz (KI) gehen seit Jahrzehnten Hand in Hand.Spektakuläre Erfolge der KI in Spieleszenarien sind etwa der Sieg des SchachcomputersDeep Blue über den damaligen Weltmeister Gary Kasparow im Jahr 1997 oder der Gewinnder Quizshow Jeopardy durch das Programm Watson im Jahr 2010. Standen lange ZeitFragen zur Implementierung möglichst intelligenter und glaubwürdiger künstlicher Spielerim Vordergrund; ergeben sich durch aktuelle Entwicklungen in den Bereichen mobile-undsocial gaming neue Problemstellungen für die KI. Dieser Artikel beleuchtet die historischeEntwicklung der KI in Computerspielen und diskutiert die Herausforderungen; die sich inmodernen Spieleszenarien ergeben.,Informatik-Spektrum,2014,*
Propagation Kernels,Marion Neumann; Roman Garnett; Christian Bauckhage; Kristian Kersting,Abstract: We introduce propagation kernels; a general graph-kernel framework for efficientlymeasuring the similarity of structured data. Propagation kernels are based on monitoringhow information spreads through a set of given graphs. They leverage early-stagedistributions from propagation schemes such as random walks to capture structuralinformation encoded in node labels; attributes; and edge information. This has two benefits.First; off-the-shelf propagation schemes can be used to naturally construct kernels for manygraph types; including labeled; partially labeled; unlabeled; directed; and attributed graphs.Second; by leveraging existing efficient and informative propagation schemes; propagationkernels can be considerably faster than state-of-the-art approaches without sacrificingpredictive performance. We will also show that if the graphs at hand have a regular …,arXiv preprint arXiv:1410.3314,2014,*
Non-negative factor analysis supporting the interpretation of XRF imaging data,Matthias Alfeld; Christian Bauckhage; Kristian Kersting; Gerald Falkenberg; Gerd Wellenreuther; Mirwaes Wahabzada,Alfeld; Matthias; Wahabzada; Mirwaes; Bauckhage; Christian; Kersting;Kristian; Wellenreuther; Gerd; Falkenberg; Gerald.,*,2014,*
Statistical Relational Learning,Sriraam Natarajan; Kristian Kersting; Tushar Khot; Jude Shavlik,Abstract This chapter presents background on SRL models on which our work is based on.We start with a brief technical background on first-order logic and graphical models. In Sect.2.2; we present an overview of SRL models followed by details on two popular SRL models.We then present the learning challenges in these models and the approaches taken to solvethem in literature. In Sect. 2.3. 3; we present functional-gradient boosting; an ensembleapproach; which forms the basis of our learning approaches. Finally; We present detailsabout the evaluation metrics and datasets we used.,*,2014,*
Boosting Undirected Relational Models,Sriraam Natarajan; Kristian Kersting; Tushar Khot; Jude Shavlik,Abstract Having presented the outline of functional gradient based learning of RelationalDependency Networks in the previous chapter; we turn our focus to learning undirected SRLmodels. More precisely; we adapt the algorithm for learning the popular formalism of MarkovLogic Networks. We derive the gradients in this case and present empirical evidence todemonstrate the efficacy of this approach.,*,2014,*
Boosting Statistical Relational Learning in Action,Sriraam Natarajan; Kristian Kersting; Tushar Khot; Jude Shavlik,Abstract In the previous chapters; we discussed the structure learning algorithms for twoSRL models and extended them to learn with missing data. In this chapter; we discuss howthis algorithm can be adapted to learn to act in sequential domains. We then present three ofour most successful applications in real health care data—two cardiovascular predictionproblems and the third is prediction of onset of Alzheimer's disease. We then conclude thechapter with a few NLP applications.,*,2014,*
Relational Logistic Regression: The Directed Analog of Markov Logic Networks.,Seyed Mehran Kazemi; David Buchman; Kristian Kersting; Sriraam Natarajan; David Poole,Abstract Relational logistic regression (RLR) was presented at the 14th InternationalConference on Principles of Knowledge Representation and Reasoning (KR-2014). RLR isthe directed analogue of Markov logic networks. Whereas Markov logic networks definedistributions in terms of weighted formulae; RLR defines conditional probabilities in terms ofweighted formulae. They agree for the supervised learning case when all variables except aquery leaf variable are observed. However; they are quite different in representingdistributions. The KR-2014 paper defined the RLR formalism; defined canonical forms forRLR in terms of positive conjunctive (or disjunctive) formulae; indicated the class ofconditional probability distributions that can and cannot be represented by RLR; and definedmany other aggregators in terms of RLR. In this paper; we summarize these results and …,AAAI Workshop: Statistical Relational Artificial Intelligence,2014,*
Guest editor’s introduction: special issue of the ECML PKDD 2013 journal track,Hendrik Blockeel; Kristian Kersting; Siegfried Nijssen; Filip Železný,The 2013 European Conference on Machine Learning and Principles and Practice ofKnowledge Discovery in Databases (ECMLPKDD) was held in Prague; September 2013.Following the long-standing tradition of the series; it brought together researchers inMachine Learning and Data Mining for an exciting program of cuttingedge research results;aiming in particular at a cross-fertilization between these two areas. The 2013 editionfeatured a record-breaking 138 full presentations of novel research results; selected througha careful peer review process from 629 submissions.,Data Mining and Knowledge Discovery,2013,*
The AAAI-13 Conference Workshops,Vikas Agrawal; Christopher Archibald; Mehul Bhatt; Hung Bui; Diane J Cook; Juan Cortés; Christopher Geib; Vibhav Gogate; Hans W Guesgen; Dietmar Jannach; Michael Johanson; Kristian Kersting; George Konidaris; Lars Kotthoff; Martin Michalowski; Sriraam Natarajan; Barry O'Sullivan; Marc Pickett; Vedran Podobnik; David Poole; Lokendra Shastri; Amarda Shehu; Gita Sukthankar,Abstract The AAAI-13 Workshop Program; a part of the 27th AAAI Conference on ArtificialIntelligence; was held Sunday and Monday; July 14 ‚Äì15; 2013 at the Hyatt RegencyBellevue Hotel in Bellevue; Washington; USA. The program included 12 workshopscovering a wide range of topics in artificial intelligence; including Activity Context-AwareSystem Architectures (WS-13-05); Artificial Intelligence and Robotics Methods inComputational Biology (WS-13-06); Combining Constraint Solving with Mining and Learning(WS-13-07); Computer Poker and Imperfect Information (WS-13-08); Expanding theBoundaries of Health Informatics Using Artificial Intelligence (WS-13-09); Intelligent RoboticSystems (WS-13-10); Intelligent Techniques for Web Personalization and Recommendation(WS-13-11); Learning Rich Representations from Low-Level Sensors (WS-13-12); Plan …,Ai magazine,2013,*
Csaba Szepesvári University of Alberta,Alborz Geramifard; Alessandro Lazaric; Amir-massoud Farahmand; Andre Damotta Salles; Andrew McHutchon Barreto; Bert Kappen; Bradley Knox; Byron Boots; Carlos Diuk; Christian Daniel Wasser; Christian Igel; Damien Ernst; David Silver; Doina Precup; Dvijotham Krishnamurthy; Emma Brunskill; Evangelos Theodorou; Fernand Fernandez; Francisco Melo; Gerhard Neumann; Hado van Hasselt; Jan Peters; Jens Kober; Jose Antonio; H Martin; Jun Morimoto; Katharina Mülling; Kristian Kersting; Manuel Lopes; Marco Wiering; Martijn van Otterlo; Martin Riedmiller; Masashi Sugiyama; Matthew Hoffman; Matthew Robards; Matthieu Geist; Michal Valko; Mohammad Ghavamzadeh; Nikos Vlassis; Odalric-Ambrym Maillard; Oliver Kroemer; Olivier Pietquin; Pedro Ortega; Peter Auer; Peter Dayan; Peter Sunehag; Philipp Hennig; Philippe Preux; Remi Munos; Ronald Ortner; Shivaram Kalyanakrishnan; Stephane Ross; Teodor Moldovan; Thomas Furmston; Thomas J Walsh; Thomas Rückstieß; Tobias Jung; Tobias Lang; Todd Hester; Tom Erez; Tom Schaul; Verena Heidrich-Meisner; Yuri Grinberg; Zhikun Wang; Zico Kolter; Marc Deisenroth,The 10th European Workshop on Reinforcement Learning (EWRL); held June 30–July 1;2012 in Edinburgh; Scotland; served as a forum to discuss the current state-of-the-art andfuture research directions in the continuously growing field of reinforcement learning (RL).We made EWRL an exciting and well-received event for the international RL community.Therefore; we appreciate that we could attract a wide spectrum of researchers by co-locatingEWRL 2012 with the International Conference on Machine Learning. We were very excitedabout our outstanding invited speakers Martin Riedmiller (University of Freiburg); DrewBagnell (Carnegie Mellon University); Shie Mannor (Technion); and Richard Sutton(University of Alberta); who gave great overviews of current research and diverse applicationareas of reinforcement learning. EWRL 2012 had 63 submissions from which 43 (68%) …,*,2012,*
STAIRS 2012: Proceedings of the Sixth Starting AI Researchers’ Symposium,Kristian Kersting; Marc Toussaint,The field of Artificial Intelligence is one in which novel ideas and new and originalperspectives are of more than usual importance. The Starting AI Researchers' Symposium(STAIRS) is an international meeting which supports AI researchers from all countries at thebeginning of their career; PhD students and those who have held a PhD for less than oneyear. It offers doctoral students and young post-doctoral AI fellows a unique and valuableopportunity to gain experience in presenting their work in a supportive scientificenvironment; where they can obtain constructive feedback on the technical content of theirwork; as well as advice on how to present it; and where they can also establish contacts withthe broader European AI research community. This book presents revised versions of peer-reviewed papers presented at the Sixth STAIRS; which took place in Montpellier; France …,*,2012,*
A revised publication model for ECML PKDD,Hendrik Blockeel; Kristian Kersting; Siegfried Nijssen; Filip Zelezny,Abstract: ECML PKDD is the main European conference on machine learning and datamining. Since its foundation it implemented the publication model common in computerscience: there was one conference deadline; conference submissions were reviewed by aprogram committee; papers were accepted with a low acceptance rate. Proceedings werepublished in several Springer Lecture Notes in Artificial (LNAI) volumes; while selectedpapers were invited to special issues of the Machine Learning and Data Mining andKnowledge Discovery journals. In recent years; this model has however come under stress.Problems include: reviews are of highly variable quality; the purpose of bringing thecommunity together is lost; reviewing workloads are high; the information content ofconferences and journals decreases; there is confusion among scientists in …,arXiv preprint arXiv:1207.6324,2012,*
Lifted Parameter Learning in Relational Models,Babak Ahmadi; Kristian Kersting; Sriraam Natarajan,Abstract Lifted inference approaches have rendered large; previously intractableprobabilistic inference problems quickly solvable by employing symmetries to handle wholesets of indistinguishable random variables. Still; in many if not most situations trainingrelational models will not benefit from lifting: symmetries within models easily break sincevariables become correlated by virtue of depending asymmetrically on evidence. Anappealing idea for such situations is to train and recombine local models. This breakslongrange dependencies and allows to exploit lifting within and across the local trainingtasks. Moreover; it naturally paves the way for online training for relational models.Specifically; we develop the first lifted stochastic gradient optimization method with gainvector adaptation; processing each lifted piece one after the other.,Working Notes of the ICML-2012 Workshop on Statistical Relational Learning; Edinburg; UK,2012,*
Structure Learning with Hidden Data in Relational Domains,Tushar Khot; Sriraam Natarajan; Kristian Kersting; Jude Shavlik,Abstract Recent years have seen a surge of interest in learning the structure of StatisticalRelational Learning (SRL) models; which combine logic with probabilities. Most of thesemodels apply the closed-world assumption ie; whatever is not observed is false in the world.We consider the problem of learning the structure of SRL models in the presence of hiddendata; ie we open the closedworld assumption. We develop a functionalgradient boostingalgorithm based on EM to learn the structure and parameters of the models simultaneouslyand apply it to learn two kinds of models–Relational Dependency Networks (RDNs) andMarkov Logic Networks (MLNs). Our results in two testbeds demonstrate that the algorithmscan effectively learn with missing data.,Working Notes of the ICML-2012 Workshop on Statistical Relational Learning; Edinburg; UK,2012,*
Invited talk: increasing representational power and scaling inference in reinforcement learning,Kristian Kersting,Abstract As robots are starting to perform everyday manipulation tasks; such as cleaning up;setting a table or preparing simple meals; they must become much more knowledgeablethan they are today. Natural environments are composed of objects; and the possibilities tomanipulate them are highly structured due to the general laws governing our relationalworld. All these need to be acknowledged when we want to realize thinking robots thatefficiently learn how to accomplish tasks in our relational world. Triggered by this grandvision; this talk discusses the very promising perspective on the application of StatisticalRelational AI techniques to reinforcement learning. Specifically; it reviews existing symbolicdynamic programming and relational RL approaches that exploit the symbolic structure inthe solution of relational and first-order logical Markov decision processes. They illustrate …,Proceedings of the 9th European conference on Recent Advances in Reinforcement Learning,2011,*
Guest editorial to the special issue on inductive logic programming; mining and learning in graphs and statistical relational learning,Hendrik Blockeel; Karsten Borgwardt; Luc De Raedt; Pedro Domingos; Kristian Kersting; Xifeng Yan,In 2009; three international conferences/workshops on learning from relational; graph-basedand probabilistic data were co-located: ILP-2009; the 19th International Conference onInductive Logic Programming; MLG-2009; the 7th International Workshop on Mining andLearning with Graphs; and SRL-2009; the International Workshop on Statistical RelationalLearning. These events were organized in Leuven; Belgium; on July 2–4; 2009. The ILPconference series has been the premier forum for work on logic-based approaches tolearning for almost two decades and has recently reached out to other forms of relationallearning and to probabilistic approaches. The MLG workshop series focuses on graph-based approaches to machine learning and data mining while the SRL workshop seriesfocuses on statistical inference and learning with relational and first-order logical,Machine Learning,2011,*
Multi-evidence Lifted Message Passing,Babak Ahmadi; Kristian Kersting; Scott Sanner,Any staff member (including those holding honorary status; such as Emeriti and Visitors) andHigher Degree by Research students of the University can submit material to ANU OpenResearch repository. Undergraduate and Postgraduate by Coursework students can depositresearch outputs (such as journal article; theses).,*,2011,*
On Lifted PageRank; Kalman Filter and Towards Lifted Linear Program Solving.,Babak Ahmadi; Martin Mladenov; Kristian Kersting; Scott Sanner,Abstract Lifted message passing algorithms exploit repeated structure within a givengraphical model to answer queries efficiently. Given evidence; they construct a lifted networkof supernodes and superpotentials corresponding to sets of nodes and potentials that areindistinguishable given the evidence. Recently; efficient algorithms were presented forupdating the structure of an existing lifted network with incremental changes to the evidence.In the inference stage; however; current algorithms need to construct a separate liftednetwork for each evidence case and run a modified message passing algorithm on eachlifted network separately. Consequently; symmetries across the inference tasks are notexploited. In this paper; we present a novel lifted message passing technique that exploitssymmetries across multiple evidence cases. The benefits of this multi-evidence lifted …,LWA,2011,*
O Scientist; Where Art Thou? Affiliation Propagation for Geo-Referencing Scientific Publications.,Babak Ahmadi; Salah Zayakh; Fabian Hadiji; Kristian Kersting,Abstract Today; electronic scholarly articles are available freely at the point of use.Moreover; bibliographic systems such as DBLP; ACM's Digital Libraries; Google's Scholar;and Microsoft's AcademicSearch provide means to search and analyze bibliographicinformation. However; one important information is typically incomplete; wrong; or evenmissing: the affiliation of authors. This type of information can be valuable not only for findingand tracking scientists using map interfaces but also for automatic detection of conflict ofinterests and; in aggregate form; for helping to understand topics and trends in science atglobal scale. In this work-in-progress report; we consider the problem of retrieving affiliationsfrom few observed affiliations only. Specifically; we crawl ACM's Digital Libraries foraffiliations of authors listed in DBLP. Then; we employ multi-label propagation to …,LWA,2011,*
Convex NMF on Non-Convex Massiv Data.,Kristian Kersting; Mirwaes Wahabzada; Christian Thurau; Christian Bauckhage,Abstract We present an extension of convex-hull nonnegative matrix factorization (CH-NMF)which was recently proposed as a large scale variant of convex non-negative matrixfactorization (CNMF) or Archetypal Analysis (AA). CH-NMF factorizes a non-negative datamatrix V into two non-negative matrix factors V≈ WH such that the columns of W are convexcombinations of certain data points so that they are readily interpretable to data analysts.There is; however; no free lunch: imposing convexity constraints on W typically preventsadaptation to intrinsic; low dimensional structures in the data. Alas; in cases where the datais distributed in a nonconvex manner or consists of mixtures of lower dimensional convexdistributions; the cluster representatives obtained from CH-NMF will be less meaningful. Inthis paper; we present a hierarchical CH-NMF that automatically adapts to internal …,LWA,2010,*
Lifted Conditioning for Pairwise Marginals and Beyond.,Babak Ahmadi; Kristian Kersting; Fabian Hadiji,Abstract Lifted belief propagation (LBP) can be extremely fast at computing approximatemarginal probability distributions over single variables and neighboring ones in theunderlying graphical model. It does; however; not prescribe a way to compute jointdistributions over pairs; triples or k-tuples of distant random variables. In this paper; wepresent an algorithm; called conditioned LBP; for approximating these distributions.Essentially; we select variables one at a time for conditioning; running lifted beliefpropagation after each selection. This naive solution; however; recomputes the liftednetwork in each step from scratch; therefore often canceling the benefits of lifted inference.We show how to avoid this by efficiently computing the lifted network for each conditioningdirectly from the one already known for the single node marginals. This contribution …,LWA,2010,*
Towards Engaging MDPs,Olana Missura; Kristian Kersting; Thomas Gärtner,Abstract. One of the challenges that a computer game developer meets when creating a newgame is setting the difficulty “right”. Not only is it a complicated task to balance all the gameparameters; but the developer also needs to cater for players with very different skill levels.Providing a game with an ability to automatically scale the difficulty depending on the currentplayer would make the games more engaging over longer time. While a few commercialgames boast about having such a system; to the best of our knowledge it was notresearched as a learning problem. In this paper we first give a problem definition of theautomatic difficulty scaling problem we call Engagement Problem. Then; we also outline aframework based on nested Markov Decision Processes; called Engaging Markov DecisionProcess for solving it. Preliminary experiments in a small grid world show the …,Workshop on Artificial Intelligence in Games,2008,*
07161 Abstracts collection--Probabilistic; logical and relational learning-A further synthesis,Luc De Raedt; Thomas Dietterich; Lise Getoor; Kristian Kersting; Stephen Muggleton,HUITI e str ts golle tion ro ilisti D vogi l nd el tion l ve rning E e purther ynthesis" h gstuhlemin r" vF he edt1D F hietteri h2D vF qetoor3 nd F rF wuggleton4 1 nivF prei urgD hi lu Fderedtd sFkuleuvenF e 2 yregon t te nivFD tgdd sForstFedu 3 nivF of w ryl nd E gollege rkDgetoord sFumdFedu 4 smperi l gollege vondonD u shmddo Fi F Fuk e str tF prom FF to FFDthe h gstuhl emin r HUITI ro ilisti D vogE il nd el tion l ve rning E e purther ynthesis ws held inthe sntern tion l gonferen e nd ese rh genter@ sfpsAD hloss h gstuhlF huring the semin rDsever lp rti ip nts presented their urrent rese r hD nd ongoing work nd open pro lems weredis ussedF e str ts of the present tions given during the semin rs well s str ts of semin r reEsults nd ide s re put together in this p perF he first se tion des ri es the semin r topi s nd go lsin gener lF vinks to extended str ts or full p pers re providedD if v il leF ueywordsF oe …,Probabilistic; Logical and Relational Learning-A Further Synthesis,2008,*
Towards Engaging Games.,Olana Missura; Kristian Kersting; Thomas Gärtner; J Baumeister,Abstract One of the challenges that a computer game developer meets when creating a newgame is setting the difficulty “right”. Not only is it a complicated task to balance all the gameparameters; but the developer also needs to cater for players with very different skill levels.Providing a game with an ability to automatically scale the difficulty depending on the currentplayer would make the games more engaging over longer time. While a few commercialgames boast about having such a system; to the best of our knowledge treating it as amachine learning problem has received surprisingly low attention. In this paper; weinvestigate the automatic difficulty scaling problem from a more general perspective: Howcan agents learn to keep agents engaged. After introducing the learning problem; calledEngagement Problem; we outline a framework based on nested Markov Decision …,LWA,2008,*
Gaussian Process Models for Colored Graphs,Zhao Xu; Kristian Kersting; Volker Tresp,Abstract Many real-world domains can naturally be represented as complex graphs; ie; interms of entities (nodes) and relations (edges) among them. In domains with multiplerelations; represented as colored graphs; we may improve the quality of a model byexploiting the correlations among relations of different types. To this end; we develop a multi-relational Gaussian process (MRGP) model. The MRGP model introduces multiple GPs foreach type of entities. Each random variable drawn from a GP represents profile/preferenceof an entity in some aspect; which is the function value of entity features at the aspect. TheseGPs are then coupled together via relations between entities. The MRGP model can be usedfor relation prediction and (semi-) supervised learning. We give an analysis of the MRGPmodel for bipartite; directed and undirected univariate relations.,Working Notes of the NIPS-08 Workshop on Analyzing Graphs,2008,*
Stratified Gradient Boosting for Fast Training of CRFs,Bernd Gutmann; Kristian Kersting,Abstract Boosting has recently been shown to be a promising approach for trainingconditional random fields (CRFs) as it allows to efficiently induce conjunctive (evenrelational) features. The potentials are represented as weighted sums of regression treesthat are induced using gradient tree boosting. Its large scale application; however; suffersfrom two drawbacks: induced trees can spoil previous maximizations and the number ofgenerated regression examples can become quite large. In this paper; we propose to tacklethe latter problem by injecting randomness in the regression estimation procedure due tosubsampling regression examples.,Working Notes of the 6th Workshop on Multi-Relational Data Mining (MRDM-07) at ECML/PKDD-07; Warsaw; Poland,2007,*
Stratified conjugate gradient boosting for fast training of conditional random fields,Bernd Gutmann; Kristian Kersting,Abstract: Boosting has recently been shown to be a promising approach for trainingconditional random fields (CRFs) as it allows to efficiently induce conjunctive (evenrelational) features. The potentials are represented as weighted sums of regression treesthat are induced using gradient tree boosting. Its large scale application; however; suffersfrom two drawbacks: induced trees can spoil previous maximizations and the number ofgenerated regression examples can become quite large. In this paper; we propose to tacklethe latter problem by injecting randomness in the regression estimation procedure due tosubsampling regression examples.,Proceedings of the 5th International Workshop on Mining and Learning with Graphs,2007,*
Equation discovery for model identification in respiratory mechanics under conditions of mechanical ventilation,Steven Ganzert; Knut Möller; Kristian Kersting; Luc De Raedt; Josef Guttmann,Abstract Lung protective ventilation considerably improves the outcome of mechanicallyventilated and critically ill patients as it avoids extensive mechanical stress of the lung tissueand hence its irreversible damage. A valid analysis of respiratory mechanics is aprerequisite for lung protective ventilation. This analysis is always based on mathematicalmodels. The equation of motion defines a generally accepted model of the respiratorysystem. It relates the airway pressure to the ventilator induced airflow and volumeapplication influenced by distensibility and resistance of the respiratory system. We presenta novel equation discovery system which combines the technique of using declarative biasfor the reduction of the vast search space known from the LAGRAMGE-system with a greedy;randomized search strategy according to GSAT. We experimentally validate the …,working notes of the ICML-07 workshop on the Induction of Process Models (IPM-07). Corvallis; OR; USA,2007,*
Learning the structure of directed probabilistic logical models,Daan Fierens,NbQ post-prune error no no no BIC no HIV (N= 41768) 51.9 74.7 63.2/70.1 66.6 72.1 67.1Sirs-Shock (N= 9467) 81.1 86.9 85.7 87.7 87.8 88.2 Sirs (N= 3527) 64.0 63.0 66.5 66.6 66.466.4 ICU-death (N= 1548) 68.2 70.3 72.3 71.2 70.3 75.6 ASM (N= 999) 58.9 58.4 66.8 65.665.2 66.8 Trains (N= 700) 84.5 82.7 80.5 83.9 84.0 81.7 Biodegrad.(N= 328) 77.8 79.1 60.876.8 78.5 67.8 Financial (N= 232) 50.2 66.2 35.7 47.8 62.1 49.4 Mutagenesis (N= 230) 69.974.0 64.9 70.5 70.1 64.9 (probabilities estimated using Laplace-correction)(significance: two-tailed paired t-tests p= 0.05),*,2007,*
Conditional Random Fields for Logical Sequences,Bernd Gutmann; Kristian Kersting,*,*,2006,*
Learning the functional connectivity in neuronal cultures,Tayfun Gürel; Kristian Kersting; Steffen Kandler; Ulrich Egert; Stefan Rotter; Luc De Raedt,Taakbalk. taskbar; subnavigation; contents. Contact; Who's who; Organisational chart; Libraries;Toledo; Intranet; KU Leuven Nederlands. logo zoekterm: Navigation. Education: Internationalprogrammes; Faculties; ECTS; Vision and policy. Research: Research at KU Leuven; Supportand funding; Industry and society; PhD; Postdoc researchers; Output and impact; Networking;Vision and policy. Admissions: How to apply; Scholarships; Degree-seeking students;Non-degree-seeking students; Doctoral students; Reseachers; Short-term study visits; Prepareyour stay. Living in Leuven: Welcome activities; News and agenda; Student services; Housing;Insurance; Sports and culture; Student organisations. About KU Leuven: Mission statement; Factsand figures; International networks; Development co-operation; Academic calendar; Alumni;Fundraising; Services and support; Boards and councils; News and press; Job opportunities …,*,2006,*
Logical Hidden Markov Models,Luc De Raedt; Kristian Kersting; Tapani Raiko,Hidden Markov models (HMMs) (Rabiner & Juang; 1986) are extremely popular for an- alyzingsequential data. Application areas include computational biology; user modelling; speechrecognition; empirical natural language processing; and robotics. Despite their suc- cesses; HMMshave a major weakness: they handle only sequences of flat; ie; unstruc- tured symbols. Yet; inmany applications the symbols occurring in sequences are struc- tured. Consider; eg; sequencesof UNIX commands; which may have parameters such as emacs lohmms.tex;ls; latexlohmms.tex;...Thus; commands are essentially structured. Tasks that have been considered forUNIX command sequences include the prediction of the next command in the sequence (Davison& Hirsh; 1998); the classification of a command sequence in a user category (Korvemaker &Greiner; 2000; Jacobs & Blockeel; 2001); and anomaly detection (Lane; 1999) …,Journal Of Artificial Intelligence Research,2006,*
Challenges for Relational Reinforcement Learning,Kristian Kersting; P Tadepalli; R Givan; K Driessens,*,*,2004,*
Inducing Probabilistic Context-Free Grammars for the Sequencing of Robot Movement Primitives,Rudolf Lioutikov; Guilherme Maeda; Filipe Veiga; Kristian Kersting; Jan Peters,Abstract—Movement Primitives are a well studied and widely applied concept in modernrobotics. Composing primitives out of an existing library; however; has shown to be achallenging problem. We propose the use of probabilistic context-free grammars tosequence a series of primitives to generate complex robot policies from a given library ofprimitives. The rule-based nature of formal grammars allows an intuitive encoding ofhierarchically and recursively structured tasks. This hierarchical concept strongly connectswith the way robot policies can be learned; organized; and re-used. However; the inductionof context-free grammars has proven to be a complicated and yet unsolved challenge. In thiswork; we exploit the physical nature of robot movement primitives to restrict and efficientlysearch the grammar space. The grammar is learned with Markov Chain Monte Carlo …,*,*,*
Sensors; autonomous tractors; and computing: Pervasive computingtakes over the fields,Christian Bauckhage; Kristian Kersting; Albrecht Schmidt,Facing a rapidly growing world population; answers to the daunting question of “How to feeda hungry world?''are becoming ever more urgent. A recent Nature editorial states that"producing enough food for the world's population in 2050 will be easy. But doing it at anacceptable cost to the planet will depend on research into everything from high-tech seedsto low-tech farming practices"[Nature; 7306 (466): 531-532; 2010]. Obviously; the challengesare manifold: climate change; water shortages; labor shortage due to aging urbanizedpopulations; and increased concerns about issues such as animal welfare; food safety; andenvironmental impact. Integrating pervasive computing; sensing and human-computerinteraction with communication technologies and methods from data mining; computervision; or robotics provides new solutions in this regard. Social and technological …,IEEE Pervasive Computing,*,*
Principles of Robot Motion: Theory; Algorithms; and Implementations Principles of Robot Motion: Theory; Algorithms; and Implementations; 2005,KRISTIAN KERSTING; CHRISTIAN PLAGEMANN; ALEXANDRU COCORA; WOLFRAM BURGARD; LUC DE RAEDT,CiNii 国立情報学研究所 学術情報ナビゲータ[サイニィ]. メニュー 検索 …,*,*,*
Collective Attention on the Web,Kristian Kersting,Its one of the most popular YouTube videos ever produced; having been viewed more than840 million times. Its hard to understand why this clip is so famous and actually went viral;since nothing much happens. Two little boys; Charlie and Harry; are sitting in a chair whenCharlie; the younger brother; mischievously bites Harrys finger. Theres a shriek and then alaugh. The clip is called “Charlie Bit My Finger–Again!” Generally; understanding thedynamics of collective attention is central to an information age where millions of peopleleave digital footprints everyday. So; can we capture the dynamics of collective attentionmathematically? Can we even gain insights into the underlying physical resp. socialprocesses? Is it for instance fair to call the video “viral” in an epidemiological sense? In thistalk I shall argue that computational methods of collective attention are not …,*,*,*
GloCal: Global-local Graph Kernels,Christopher Morris; Kristian Kersting; Petra Mutzel,Abstract—Most state-of-the-art graph kernels only take local graph properties into account;ie; the kernel is computed with regard to properties of the neighborhood of vertices or othersmall substructures only. On the other hand; kernels that do take global graph properties intoaccount may not scale well to large graph databases. Here we propose to start exploring thespace between local and global graph kernels; striking the balance between both worlds.Specifically; we introduce a novel graph kernel based on the k-dimensional Weisfeiler-Lehman algorithm; and show that it takes local as well as global properties into account.Unfortunately; the k-dimensional Weisfeiler-Lehman algorithm scales exponentially in k.Consequently; we devise a stochastic version of the kernel with provable approximationguarantees using conditional Rademacher averages. On boundeddegree graphs; it can …,*,*,*
Global Weisfeiler-Lehman Kernels,Christopher Morris; Kristian Kersting; Petra Mutzel,Abstract—Most state-of-the-art graph kernels only take local graph properties into account;ie; the kernel is computed with regard to properties of the neighborhood of vertices or othersmall substructures. On the other hand; kernels that do take global graph properties intoaccount may not scale well to large graph databases. Here we propose to start exploring thespace between local and global graph kernels; striking the balance between both worlds.Specifically; we introduce a novel graph kernel based on the k-dimensional Weisfeiler-Lehman algorithm. Unfortunately; the k-dimensional Weisfeiler-Lehman algorithm scalesexponentially in k. Consequently; we devise a stochastic version of the kernel with provableapproximation guarantees using conditional Rademacher averages. On bounded-degreegraphs; it can even be computed in constant time. We support our theoretical results with …,*,*,*
Bellman goes Relational (extended abstract),M van Otterlo; K Kersting; L de Raedt,*,Proceedings of the 16th Belgium-Netherlands Artificial Intelligence Conference (BNAIC'04),*,*
Bayesian Logic Programs,Luc de Raedt; Kristian Kersting,Abstract [en]: Bayesian networks provide an elegant formalism for representing andreasoning about uncertainty. They are a probabilistic extension of propositional logic and;hence; inherit some of the limitations of propositional logic; such as the difficulties torepresent objects and relations. The main contribution of this extended abstract is tointroduce a new approach; called Bayesian logic programs; to overcome the limitations. Itcombines Bayesian networks with definite clause logic; ie" pure" Prolog; by establishing aone-to-one mapping between ground atoms and random variables. Thus; Bayesian logicprograms combine the advantages of definite clause logic and Bayesian networks. Thisincludes the separation of quantitative and qualitative aspects of the world. Furthermore;Bayesian logic programs generalize both Bayesian networks as well as logic programs …,*,*,*
Interactive Data Analytics for the Humanities,Iryna Gurevych; Christian M Meyer; Carsten Binnig; Johannes Fürnkranz; Kristian Kersting; Stefan Roth; Edwin Simpson,Abstract. In this vision paper; we argue that current solutions to data analytics are notsuitable for complex tasks from the humanities; as they are agnostic of the user and focusedon static; predefined tasks with large-scale benchmarks. Instead; we believe that the humanmust be put into the loop to address small data scenarios that require expert domainknowledge and fluid; incrementally defined tasks; which are common for many humanitiesuse cases. Besides the main challenges; we discuss existing and urgently requiredsolutions to interactive data acquisition; model development; model interpretation; andsystem support for interactive data analytics. In the envisioned interactive systems; humanusers not only provide annotations to a machine learner; but train a model by using thesystem and demonstrating the task. The learning system will actively query the user for …,*,*,*
Combining Logic and Probability,Kristian Kersting; Pedro Domingos,Page 1. Languages; Algorithms and Applications Combining Logic and Probability KristianKersting Fraunhofer IAIS & Univ. of Bonn; Germany Pedro Domingos University of Washington;USA Search IR … Robotics CV KR Planning SAT Probability Statistics Logic Graphs TreesLearning Page 2. Acknowledgements ▪ Statistical Relational Learning (SRL) and AI (StarAI) area synthesis of ideas of many individuals who have participated in various SRL/StarAI events;workshops and classes. ▪ Thanks to all of you! 2 Pedro Domingos; Kristian Kersting CombiningProbability and Logic: Languages; Algorithms and Applications Page 3. General Take-AwayMessage ▪ Graphs are not enough ▪ We need logic 3 Pedro Domingos; Kristian KerstingCombining Logic and Probability: Languages; Algorithms and Applications Page 4. Roadmap1. Motivation 2. Statistical Relational Learning / AI: a short overview …,*,*,*
Factorizing Gigantic Matrices: Tutorial at ECML-PKDD 2011,Christian Bauckhage; Kristian Kersting; Christian Thurau,Low-rank approximations of data matrices have become an important tool in machinelearning and data mining. They allow for embedding high dimensional data in lowerdimensional spaces and can therefore mitigate effects due to noise; uncover latent relations;or facilitate further processing. These properties have been proven successful in manyapplications areas such as bio-informatics; computer vision; text process ing; recommendersystems; social network analysis; among others. Present day technologies are characterizedby exponentially growing amounts of data. Recent advances in sensor technology; Internetapplications; and communication networks call for methods that scale to very large and/orgrowing data matrices. In this tutorial; we discuss basic characteristics of matrix factorizationand introduce several recent approaches that scale to modern massive data analysis …,*,*,*
Learning with Privileged Information: Decision-Trees and Boosting,Rahul Pasunuri; Phillip Odom; Tushar Khot; Kristian Kersting; Sriraam Natarajan,Abstract We consider the problem of learning with privileged information where the goal is tolearn a classifier that uses features not available at test time to learn a better model attraining time. While the earlier approaches under this formalism focused mainly on SVMs;we extend the setting to treebased learners—decision trees and boosting for learning withprivileged information. Our methods use privileged features to create additional labels foreach example and use these privileged labels to guide the learning algorithms. We derivethe theory and empirically validate the effectiveness of our learning approach both in thecase of decision-trees and boosting. Our methods outperform the SVM based learner withprivileged information.,*,*,*
AAAI 2012 Conference Committees,Dieter Fox; Jörg Hoffmann; Bart Selman; Markus Fromherz; Hector Munoz‐Avila; David Kauchak; Denny Vrandecic; Chris Welty; Matthias Scheutz; James Allen; Carla P Gomes; Brian C Williams; Kurt Konolige; Siddhartha Srinivasa; Toby Walsh; Carmel Domshlak; Patrick Pantel; Michael Beetz; Holger Hoos; Elizabeth Sklar; Peter McBurney; Rudolph Triebel; Kristian Kersting,Chairs and Cochairs AAAI Conference Committee Chair Dieter Fox (University ofWashington; USA) AAAI12 Program Cochairs Jörg Hoffmann (Saarland University;Germany) Bart Selman (Cornell University; USA) IAAI12 Conference Chair and Cochair MarkusFromherz (ACS; a Xerox Company; USA) Hector Munoz‐Avila (Lehigh University; USA) EAAI12Symposium Chair David Kauchak (Middlebury College; USA) Special Track on Artificial Intelligenceand the Web Cochairs Denny Vrandecic (Institute of Applied Informatics and Formal DescriptionMethods; Germany) Chris Welty (IBM Research; USA) Special Track on Cognitive Systems CochairsMatthias Scheutz (Tufts University; USA) James Allen (University of Rochester; USA) SpecialTrack on Computational Sustainability and Artificial Intelligence Cochairs Carla P. Gomes (CornellUniversity; USA) Brian C. Williams (Massachusetts Institute of Technology; USA) Special …,*,*,*
A Bayesian Regression Approach to Terrain Modeling,C Plagemann; S Mischke; K Kersting; S Prentice; N Roy; W Burgard,Surface models that represent the distribution of elevations at given points in the plane areimportant in many areas such as outdoor robotics or the geo-sciences. We introduce anonparametric; probabilistic regression framework based on locally-adaptive Gaussianprocesses for learning such models from sets of elevation samples. Our approach does notrequire a discretization of the space; it can be learned efficiently by making justified modelapproximations; and it is fully predictive in the sense that; for every point in the plane; apredictive distribution of elevation values can be estimated.,*,*,*
Lifted Online Training of Relational Models with,B Ahmadi; K Kersting; S Natarajan,Flexible Skill Acquisition and Intuitive Robot Tasking for Mobile Manipulation in the Real World.Show All; Search Everywhere. Today; Last Week; Last Month. Search for a specific document.Lifted online training of re lational models with stochastic gradient methods B. Ahmadi; K. Kersting;and S. Natarajan In Proceedings of the European Conference on Machine Learning andPrinciples and Practice of Knowledge Discovery in Databases (ECML PKDD) 2012ahmadi12ecmlpkdd.pdf BibTeX: @inproceedings {ahmadi12ecmlpkdd; author = {B. Ahmadiand K. Kersting and S. Natarajan}; title = {Lifted Online Training of Relational Models withStochastic Gradient Methods}; year = {2012}; booktitle = {Proceedings …,Proceedings of the European Conference on,*,*
Appears in ICDM 2011,Tushar Khot; Sriraam Natarajan; Kristian Kersting; Jude Shavlik; IAIS Fraunhofer,Abstract—Recent years have seen a surge of interest in Statistical Relational Learning(SRL) models that combine logic with probabilities. One prominent example is Markov LogicNetworks (MLNs). While MLNs are indeed highly expressive; this expressiveness comes ata cost. Learning MLNs is a hard problem and therefore has attracted much interest in theSRL community. Current methods for learning MLNs follow a twostep approach: first;perform a search through the space of possible clauses and then learn appropriate weightsfor these clauses. We propose to take a different approach; namely to learn both the weightsand the structure of the MLN simultaneously. Our approach is based on functional gradientboosting where the problem of learning MLNs is turned into a series of relational functionalapproximation problems. We use two kinds of representations for the gradients …,*,*,*
Artificial Intelligence on the Web (AIW),Sebastian Rudolph; Heiner Stuckenschmidt; Matthias Thimm; Chris Biemann; Claudia D’Amato; Gerd Gröner; Barbara Hammer; Andreas Hotho; Yevgeny Kazakov; Pavel Klinov; Kristian Kersting; Mathias Niepert; Rafael Penaloza Nyssen; Ansgar Scherp; Michael Strube; Ingo J Timm; Stefan Woltran,The World Wide Web has become a unique source of knowledge on virtually anyimaginable topic. It is continuously fed by companies; academia; and common people with avariety of information in numerous formats. By today; the Web has become an invaluableasset for research; learning; commerce; socializing; communication; and entertainment. Still;making full use of the knowledge contained on the Web is an ongoing challenge due to thespecial properties of the Web as an information source:,*,*,*
Statistical Relational Artificial Intelligence,Kristian Kersting; Sriraam Natarajan,Abstract Statistical Relational AI—the science and engineering of making intelligentmachines acting in noisy worlds composed of objects and relations among the objects—iscurrently motivating a lot of new AI research and has tremendous theoretical and practicalimplications. Theoretically; combining logic and probability in a unified representation andbuilding general-purpose reasoning tools for it has been the dream of AI; dating back to thelate 1980s. Practically; successful statistical relational AI tools enable new applications inseveral large; complex real-world domains including those involving big data; natural text;social networks; the web; medicine and robotics; among others. Such domains are oftencharacterized by rich relational structure and large amounts of uncertainty. Logic helps tofaithfully model the former while probability helps to effectively manage the latter. Our …,*,*,*
Transfer Learning Across Relational and Uncertain Domains: A Language-Bias Approach,Raksha Kumaraswamy; Phillip Odom; Kristian Kersting; David Leake; Sriraam Natarajan,Abstract Transfer learning is typically performed between problem instances within the samedomain. We consider the problem of transferring across domains. To this effect; we adopt aprobabilistic logic approach. First; our approach automatically identifies predicates in thetarget domain that are similar in their relational structure to predicates in the source domain.Second; it transfers the logic rules and learns the parameters of the transferred rules usingtarget data. Finally; it refines the rules as necessary using theory refinement. Ourexperimental evidence supports that this transfer finds models as good or better than thosefound with state-of-the-art; and in a fraction of the time.,*,*,*
Interpreting Bayesian Logic Programs Kristian Kersting and Luc De Raedt and Stefan Kramer Institute for Computer Science; Machine Learning Lab University Freib...,Kristian Kersting,*,*,*,*
Machine Learning Journal manuscript No.(will be inserted by the editor) Compressing Probabilistic Prolog Programs,L De Raedt; K Kersting; A Kimmig; K Revoredo; H Toivonen,Abstract ProbLog is a recently introduced probabilistic extension of Prolog [4]. A ProbLogprogram defines a distribution over logic programs by specifying for each clause theprobability that it belongs to a randomly sampled program; and these probabilities aremutually independent. The semantics of ProbLog is then defined by the success probabilityof a query in a randomly sampled program. This paper introduces the theory compressiontask for ProbLog; which consists of selecting that subset of clauses of a given ProbLogprogram that maximizes the likelihood wrt a set of positive and negative examples.Experiments in the context of discovering links in real biological networks demonstrate thepractical applicability of the approach. 1,*,*,*
Propagation Kernels for Partially Labeled Graphs 击,Marion Neumann; Roman Garnett; Plinio Moreno; Novi Patricia; Kristian Kersting,Abstract Learning from complex data is becoming increasingly important; and graph kernelshave recently evolved into a rapidly developing branch of learning on structured data.However; previously proposed kernels rely on having discrete node label information.Propagation kernels leverage the power of continuous node label distributions as graphfeatures and hence; enhance traditional graph kernels to efficiently handle partially labeledgraphs in a principled manner. Utilizing localitysensitive hashing; propagation kernels areable to outperform state-of-the-art graph kernels in terms of runtime without loss in predictionaccuracy. This paper investigates the power of propagation kernels to classify partiallylabeled images and to tackle the challenging problem of retrieving similar object views inrobotic grasping.,*,*,*
Efficient Sequential Clamping for Lifted Message,F Hadiji; B Ahmadi; K Kersting,Flexible Skill Acquisition and Intuitive Robot Tasking for Mobile Manipulation in the Real World.Show All; Search Everywhere. Today; Last Week; Last Month. Search for a specific document.Efficient Sequential Clamping for Lifted Message Passing F. Hadiji and B. Ahmadi and K. KerstingIn Proceedings of the 34th Annual German Conference on Artificial Intelligence (K-11) 2011hadiji11ki.pdf BibTeX: @inproceedings { hadiji11ki; author = {F. Hadiji and B. Ahmadi and K.Kersting}; title = {Efficient Sequential Clamping for Lifted Message Passing}; year = {2011}; booktitle= {In Proceedings of the 34th Annual German Conference on Artificial Intelligence (K{--}11)};publisher = {Springer}; volume = {7006}; series = {Lecture Notes in Computer Science}; pages ={122{--}133}; month = {October 4{--}7}; address = {Berlin} } …,Proceedings of the 34th Annual German,*,*
Characterization of Shortest Path Distributions,Christian Bauckhage; Kristian Kersting; Fabian Hadiji; Bashir Rastegarpanah,Because of their combinatorial nature; networks are peculiar objects of study. In practice;they are often characterized by means of abstract measures such as node degreedistributions; clustering coefficients; or assortativity. With the work reported here; we arguethat shortest path distributions; too; provide viable characteristics of networks that can beuseful in various practical settings.,*,*,*
International Workshop on Learning and Data Mining for Robots,Shin Ando; Jose L Balcázar; Aude Billard; Ivan Bratko; Nicolas Bredeche; João Gama; Peter Grünwald; Hitoshi Iba; Kristian Kersting; Jan Peters; Takashi Washio,Robotics has motivated many advances in Machine Learning; ranging from InverseReinforcement Learning to Robust Control. Symmetrically; Machine Learning acknowlegdlyis a major factor behind some of the recent achievements in Robotics; dating back to the2005 DARPA Grand Challenge. Along these lines; researchers from both communitiesgradually become more knowledgeable in the strengths or requirements of the othercommunity.,*,*,*
Logical Hidden Markov Models Logical Hidden Markov Models,Kristian Kersting; Luc De Raedt; Tapani Raiko,Abstract Logical hidden Markov models (LOHMMs) upgrade traditional hidden Markovmodels (HMMs) to deal with sequences of structured symbols in the form of logical atoms;rather than flat characters. This note formally introduces LOHMMs and presents solutions tothe three central inference problems for LOHMMs: evaluation; most likely hidden statesequence and parameter estimation. The resulting representation and algorithms areexperimentally evaluated on problems from the domain of bioinformatics. 1.,*,*,*
Imitation Learning in Relational Domains Using Functional Gradient Boosting,Sriraam Natarajan; Saket Joshi; Prasad Tadepalli; Kristian Kersting; Jude Shavlik,It is common knowledge that both humans and animals learn new skills by observing others.This problem; which is called imitation learning; can be formulated as learning arepresentation of a policy–a mapping from states to actions–from examples of that policy.Our focus is on relational domains where states are naturally described by relations amongan indefinite number of objects. Examples include real time strategy games such asWarcraft; regulation of traffic lights; logistics; and a variety of planning domains. In this work;we employ two ideas. First; instead of learning a deterministic policy to imitate the expert; welearn a stochastic policy where the probability of an action given a state is represented by asum of potential functions. Second; we leverage the recently developed functional-gradientboosting approach to learn a set of regression trees; each of which represents a potential …,*,*,*
Submission and Formatting Instructions for the Twenty-second,Pat Langley; Claude-Nicolas Fiechter; Mehmet Göker; Cynthia Thompson; Andrea Danyluk; Claude Sammut; Terran Lane; Jennifer Dy; Dale Schuurmans; Kristian Kersting; Codrina Lauth,Page 1. Submission and Formatting Instructions for the Twenty-second International Conferenceon Machine Learning (ICML-2005) Pat Langley langley@isle.org Institute for the Study of Learningand Expertise; 2164 Staunton Court; Palo Alto; CA 94306 USA Claude-Nicolas Fiechterfiechter@rtna.daimlerchrysler.com Mehmet Göker goker@rtna.daimlerchrysler.comDaimlerChrysler Research and Technology Center; 1510 Page Mill Road; Palo Alto; CA 94304USA Cynthia Thompson cthomp@csli.stanford.edu Computational Learning Laboratory; Centerfor the Study of Language and Information; Stanford University; Stanford; CA 94305 USA AndreaDanyluk andrea@cs.williams.edu Department of Computer Science; Williams College;Williamstown; MA 01267 USA Claude Sammut claude@cse.unsw.edu.au School of ComputerScience and Engineering; University of New South Wales; Sydney NSW 2052; Australia …,*,*,*
Probabilistic Logic Learning and Reasoning,Kristian Kersting,Probabilistic logic learning which is sometimes also called statistical relational learningaddresses one of the central questions of artificial intelligence: the integration of probabilisticreasoning with first order logic representations and machine Learning. In the past few years;this question has received a lot of attention. Various different approaches have beendeveloped in several related; but different areas (including machine learning; statistics;inductive logic programming; databases; and reasoning under uncertainty). Mostresearchers only have exposure to one or two of the constituents underlying ProbabilisticLogic Learning; cf. Figure 1. In this talk; I shall start from a Bayesian network perspective andsketch how to incorporate logical concepts of objects and relations among these objects. Astime and actions are not just other relations; I shall afterwards outline probabilistic logic …,Benelearn 2005 Annual Machine Learning Conference of Belgium and the Netherlands,*,*
AAAI Tutorial: Decision-Theoretic Planning and Learning in Relational Domains,Prasad Tadepalli; Alan Fern; Kristian Kersting,*,*,*,*
Machine Learning Laboratory University of Freiburg Georges-Koehler-Allee 079; 79112 Freiburg; Germany,Kristian Kersting,Abstract Many real world sequences such as protein secondary structures or shell logsexhibit a rich internal structures. Traditional probabilistic models of sequences; however;consider sequences of flat symbols only. Logical hidden Markov models have beenproposed as one solution. They deal with logical sequences; ie; sequences over analphabet of logical atoms. This comes at the expense of a more complex model selectionproblem. Indeed; different abstraction levels have to be explored. In this paper; we proposea novel method for selecting logical hidden Markov models from data called SAGEM.SAGEM combines generalized expectation maximization; which optimizes parameters; withstructure search for model selection using inductive logic programming refinementoperators. We provide convergence and experimental results that show SAGEM's …,*,*,*
Relational Gaussian Processes for Learning Preference Relations,Kristian Kersting; Zhao Xu,Preference learning has received increasing attention in both machine learning andinformation retrieval. The goal of preference learning is to automatically learn a model torank entities (eg; documents; webpages; products; music; etc.) according to their degrees ofrelevance. The particularity of preference learning might be that the training data is a set ofpairwise preferences between entities; instead of explicit entity-wise values. For example;we may only know that a user prefers an item to another one ei≻ ej; but we do not know theexact preference degrees of items. Gaussian processes have successfully been used tolearn preferences among entities (Chu & Ghahramani; 2005); as they provide nonparametricBayesian approaches for model selection and probabilistic inference. Basically; GP basedpreference learning models introduce for each entity a latent variable; which is a function …,*,*,*
Software Tools for Probabilistic Inductive Logic Programming,Kristian Kersting; Luc De Raedt,Inductive Logic Programming [6] combines techniques from machine learning with therepresentation of logic programming. It aims at inducing general rules from specificobservations and background knowledge. Few ILP systems are capable of representing orprocessing probabilities. Consequently; they have problems to handle uncertainty explicitly.On the other hand; traditional probabilistic models such as Bayesian networks; hiddenMarkov models; stochastic context-free grammars; etc. have a rigid structure and thereforehave problems representing a variable number of objects and general relations amongobjects. Recently; various first-order logical extensions of traditional probabilistic modelshave been proposed. More over; first approaches for learning such probabilistic-logicalmodels (PLMs) have been developed. For more information we refer to the PLMs …,*,*,*
Fallstudie zur Bilddatenkompression in der Medizin,Kristian Kersting,Seit einigen Jahren l auft auch am Universit atsklinikum der Stadt Freiburg i. Br. ein Projektzur Verwendung des DICOM Standards. Der Standard unterst uzt in der vorhandenenVersion keine Art der Datenkompression. Das hat seinen Grund ua darin; da nachgeltendem Recht auch zehn Jahre nach Erstellung einer Diagnose ihre Rekonstruktion moglich sein mu; sowie in der Tatsache; da es bis vor kurzem nicht erlaubt war; die Datenallein digital zu archivieren. Ohne Komprimierung fallen im Universit atsklinikum t aglich biszu 2 GB an Bilddaten an; obwohl das System noch nicht auf allen Stationen eingesetzt wird.So soll zB in n achster Zeit die neurologische Radiologie angeschlossen werden. Insofernist mit einem Anstieg der Daten ut zu rechnen. Rechnet man diese Zahlen hoch; so ergibtsich; da jedes Jahr mindestens 730 GB alleine an Bildaten anfallen. Das ergibt in zehn …,*,*,*
