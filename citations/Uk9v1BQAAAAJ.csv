Indexing and querying XML data for regular path expressions,Quanzhong Li; Bongki Moon,Abstract With the advent of XML as a standard for data representation and exchange on theInternet; storing and querying XML data becomes more and more important. Several XMLquery languages have been proposed; and the common feature of the languages is the useof regular path expressions to query XML data. This poses a new challenge concerningindexing and searching XML data; because conventional approaches based on treetraversals may not meet the processing requirements under heavy access requests. In thispaper; we propose a new system for indexing and storing XML data based on a numberingscheme for elements. This numbering scheme quickly determines the ancestor-descendantrelationship between elements in the hierarchy of XML data. We also propose severalalgorithms for processing regular path expressions; namely;(1)-Join for searching paths …,VLDB,2001,1282
Analysis of the clustering properties of the Hilbert space-filling curve,Bongki Moon; Hosagrahar V Jagadish; Christos Faloutsos; Joel H.  Saltz,Several schemes for the linear mapping of a multidimensional space have been proposedfor various applications; such as access methods for spatio-temporal databases and imagecompression. In these applications; one of the most desired properties from such linearmappings is clustering; which means the locality between objects in the multidimensionalspace being preserved in the linear space. It is widely believed that the Hilbert space-fillingcurve achieves the best clustering (Abel and Mark; 1990; Jagadish; 1990). We analyze theclustering property of the Hilbert space-filling curve by deriving closed-form formulas for thenumber of clusters in a given query region of an arbitrary shape (eg; polygons andpolyhedra). Both the asymptotic solution for the general case and the exact solution for aspecial case generalize previous work. They agree with the empirical results that the …,IEEE Transactions on knowledge and data engineering,2001,711
Parallel data processing with MapReduce: a survey,Kyong-Ha Lee; Yoon-Joon Lee; Hyunsik Choi; Yon Dohn Chung; Bongki Moon,Abstract A prominent parallel data processing tool MapReduce is gaining significantmomentum from both industry and academia as the volume of data to analyze grows rapidly.While MapReduce is used in many areas where massive data analysis is required; there arestill debates on its performance; efficiency per node; and simple abstraction. This surveyintends to assist the database and open source communities in understanding varioustechnical aspects of the MapReduce framework. In this survey; we characterize theMapReduce framework and discuss its inherent pros and cons. We then introduce itsoptimization strategies reported in the recent literature. We also discuss the open issues andchallenges raised on parallel data analysis with MapReduce.,AcM sIGMoD Record,2012,546
Design of flash-based DBMS: an in-page logging approach,Sang-Won Lee; Bongki Moon,Abstract The popularity of high-density flash memory as data storage media has increasedsteadily for a wide spectrum of computing devices such as PDA's; MP3 players; mobilephones and digital cameras. More recently; computer manufacturers started launching newlines of mobile or portable computers that did away with magnetic disk drives altogether;replacing them with tens of gigabytes of NAND flash memory. Like EEPROM and magneticdisk drives; flash memory is non-volatile and retains its contents even when the power isturned off. As its capacity increases and price drops; flash memory will compete moresuccessfully with lower-end; lower-capacity disk drives. It is thus not inconceivable toconsider running a full database system on the flash-only computing platforms or running anembedded database system on the lightweight computing devices. In this paper; we …,Proceedings of the 2007 ACM SIGMOD international conference on Management of data,2007,427
A case for flash memory ssd in enterprise database applications,Sang-Won Lee; Bongki Moon; Chanik Park; Jae-Myung Kim; Sang-Woo Kim,Abstract Due to its superiority such as low access latency; low energy consumption; lightweight; and shock resistance; the success of flash memory as a storage alternative formobile computing devices has been steadily expanded into personal computer andenterprise server markets with ever increasing capacity of its storage. However; since flashmemory exhibits poor performance for small-to-moderate sized writes requested in arandom order; existing database systems may not be able to take full advantage of flashmemory without elaborate flash-aware data structures and algorithms. The objective of thiswork is to understand the applicability and potential impact that flash memory SSD (SolidState Drive) has for certain type of storage spaces of a database server where sequentialwrites and random reads are prevalent. We show empirically that up to more than an …,Proceedings of the 2008 ACM SIGMOD international conference on Management of data,2008,354
PRIX: Indexing and querying XML using prufer sequences,Praveen Rao; Bongki Moon,We propose a new way of indexing XML documents and processing twig patterns in an XMLdatabase. Every XML document in the database can be transformed into a sequence oflabels by Prufer's method that constructs a one-to-one correspondence between trees andsequences. During query processing; a twig pattern is also transformed into its Prufersequence. By performing subsequence matching on the set of sequences in the database;and performing a series of refinement phases that we have developed; we can find all theoccurrences of a twig pattern in the database. Our approach allows holistic processing of atwig pattern without breaking the twig into root-to-leaf paths and processing these pathsindividually. Furthermore; we show that all correct answers are found without any falsedismissals or false alarms. Experimental results demonstrate the performance benefits of …,Data Engineering; 2004. Proceedings. 20th International Conference on,2004,317
Adaptive multi-stage distance join processing,Hyoseop Shin; Bongki Moon; Sukho Lee,Abstract A spatial distance join is a relatively new type of operation introduced for spatialand multimedia database applications. Additional requirements for ranking and stoppingcardinality are often combined with the spatial distance join in on-line query processing orinternet search environments. These requirements pose new challenges as well asopportunities for more efficient processing of spatial distance join queries. In this paper; wefirst present an efficient k-distance join algorithm that uses spatial indexes such as R-trees.Bi-directional node expansion and plane-sweeping techniques are used for fast pruning ofdistant pairs; and the plane-sweeping is further optimized by novel strategies for selecting asweeping axis and direction. Furthermore; we propose adaptive multi-stage algorithms for k-distance join and incremental distance join operations. Our performance study shows that …,ACM SIGMOD Record,2000,187
The virtual microscope.,Renato Ferreira; Bongki Moon; Jim Humphries; Alan Sussman; Joel Saltz; Robert Miller; Angelo Demarzo,Abstract We present the design of the Virtual Microscope; a software system employing aclient/server architecture to provide a realistic emulation of a high power light microscope.We discuss several technical challenges related to providing the performance necessary toachieve rapid response time; mainly in dealing with the enormous amounts of data (tens tohundreds of gigabytes per slide) that must be retrieved from secondary storage andprocessed. To effectively implement the data server; the system design relies on thecomputational power and high I/O throughput available from an appropriately configuredparallel computer.,Proceedings of the AMIA Annual Fall Symposium,1997,175
Spatiotemporal aggregate computation: A survey,IF Vega Lopez; Richard T Snodgrass; Bongki Moon,Spatiotemporal databases are becoming increasingly more common. Typically; applicationsmodeling spatiotemporal objects need to process vast amounts of data. In such cases;generating aggregate information from the data set is more useful than individuallyanalyzing every entry. In this paper; we study the most relevant techniques for the evaluationof aggregate queries on spatial; temporal; and spatiotemporal data. We also present amodel that reduces the evaluation of aggregate queries to the problem of selectingqualifying tuples and the grouping of these tuples into collections on which an aggregatefunction is to be applied. This model gives us a framework that allows us to analyze andcompare the different existing techniques for the evaluation of aggregate queries. At thesame time; it allows us to identify opportunities for research on types of aggregate queries …,IEEE Transactions on Knowledge and Data Engineering,2005,170
Titan: a high-performance remote-sensing database,Chialin Chang; Bongki Moon; Anurag Acharya; Carter Shock; Alan Sussman; Joel Saltz,There are two major challenges for a high performance remote sensing database. First; itmust provide low latency retrieval of very large volumes of spatio temporal data. Thisrequires effective declustering and placement of a multidimensional dataset onto a largedisk farm. Second; the order of magnitude reduction in data size due to post processingmakes it imperative; from a performance perspective; that the post processing be done onthe machine that holds the data. This requires careful coordination of computation and dataretrieval. The paper describes the design; implementation and evaluation of Titan; a parallelshared nothing database designed for handling remote sensing data. The computationalplatform for Titan is a 16 processor IBM SP-2 with four fast disks attached to each processor.Titan is currently operational and contains about 24 GB of AVHRR data from the NOAA-7 …,Data Engineering; 1997. Proceedings. 13th International Conference on,1997,170
Advances in flash memory SSD technology for enterprise database applications,Sang-Won Lee; Bongki Moon; Chanik Park,Abstract The past few decades have witnessed a chronic and widening imbalance amongprocessor bandwidth; disk capacity; and access speed of disk. According to Amdhal's law;the performance enhancement possible with a given improvement is limited by the amountthat the improved feature is used. This implies that the performance enhancement of anOLTP system would be seriously limited without a considerable improvement in I/Othroughput. Since the market debut of flash memory SSD a few years ago; we have made acontinued effort to overcome its poor random write performance and to provide stable andsufficient I/O bandwidth. In this paper; we present three different flash memory SSD modelsprototyped recently by Samsung Electronics. We then show how the flash memory SSDtechnology has advanced to reverse the widening trend of performance gap between …,Proceedings of the 2009 ACM SIGMOD International Conference on Management of data,2009,160
FiST: scalable XML document filtering by sequencing twig patterns,Joonho Kwon; Praveen Rao; Bongki Moon; Sukho Lee,Abstract In recent years; publish-subscribe (pub-sub) systems based on XML documentfiltering have received much attention. In a typical pub-sub system; subscribed users specifytheir interest in profiles expressed in the XPath language; and each new content is matchedagainst the user profiles so that the content is delivered to only the interested subscribers. Asthe number of subscribed users and their profiles can grow very large; the scalability of thesystem is critical to the success of pub-sub services. In this paper; we propose a novelscalable filtering system called FiST (Filtering by Sequencing Twigs) that transforms twigpatterns expressed in XPath and XML documents into sequences using Prüfer's method. Asa consequence; instead of matching linear paths of twig patterns individually and mergingthe matches during post-processing; FiST performs holistic matching of twig patterns with …,Proceedings of the 31st international conference on Very large data bases,2005,151
Run-time and compile-time support for adaptive irregular problems,Shamik D Sharma; Ravi Ponnusamy; Bongki Moon; Yuan Shin Hwang; Raja Das; Joel Saltz,Abstract In adaptive irregular problems; data arrays are accessed via indirection arrays; anddata access patterns change during computation. Parallelizing such problems on distributedmemory machines requires support for dynamic data partitioning; efficient preprocessingand fast data migration. This paper describes CHAOS; a library of efficient runtime primitivesthat provides such support. To demonstrate the effectiveness of the runtime support; twoadaptive irregular applications have been parallelized using CHAOS primitives: a moleculardynamics code (CHARMM) and a code for simulating gas flows (DSMC). We have alsoproposed minor extensions to Fortran D which would enable compilers to parallelizeirregular forall loops in such adaptive applications by embedding calls to primitives providedby a runtime library. We have implemented our proposed extensions in the Syracuse …,Proceedings of the 1994 ACM/IEEE conference on Supercomputing,1994,119
A manual for the CHAOS runtime library,Joel Saltz; Ravi Ponnusamy; Shamik D Sharma; Bongki Moon; Yuan-Shin Hwang; Mustafa Uysal; Raja Das,Procedures are presented that are designed to help users efficiently program irregularproblems (eg unstructured mesh sweeps; sparse matrix codes; adaptive mesh partial dif-ferential equations solvers) on distributed memory machines. These procedures are alsodesigned for use in compilers for distributed memory multiprocessors. The portable CHAOSpro-cedures are designed to support dynamic data distributions and to automaticallygenerate send and receive messsage by capturing communications patterns atruntime.(Also cross-referenced as UMIACS-TR-95-34),*,1998,89
Runtime and language support for compiling adaptive irregular programs on distributed‐memory machines,Yuan‐Shin Hwang; Bongki Moon; Shamik D Sharma; Ravi Ponnusamy; Raja Das; Joel H Saltz,Page 1. SOFTWARGPRACTICE AND EXPERIENCE; VOL. 25(6); 597-621 (JUNE 1995)Runtime and Language Support for Compiling Adaptive Irregular Programs onDistributed-memory Machines YUAN-SHIN HWANG; BONGKI MOON; SHAMIK D. SHARMADepartment of Computer Science; University of Maryland; College Park; MD 20742; USARAW PONNUSAMY Northeast Parallel Architectures Center; Syracuse University; Syracuse;NY 13244; USA AND RAJA DAS AND JOEL H. SALTZ UMIACS and Department of ComputerScience; University of Maryland; Coiiege Park; MD 20742; USA . SUMMARY In many scientificapplications; arrays containing data are indirectly indexed through indirection arrays. Suchscientific applications are called irregular programs and are a distinct class of applicationsthat require special techniques for parallelization …,Software: Practice and Experience,1995,86
A case for parallelism in data warehousing and OLAP,Anindya Datta; Bongki Moon; Helen Thomas,In recent years the database community has experienced a tremendous increase in theavailability of new technologies to support efficient storage and retrieval of large volumes ofdata; namely data warehousing and On-Line Analytical Processing (OLAP) products.Efficient query processing is critical in such an environment; yet achieving quick responsetimes with OLAP queries is still largely an open issue. We propose a solution approach tothis problem by applying parallel processing techniques to a warehouse environment. Wesuggest an efficient partitioning strategy based on the relational representation of a datawarehouse (ie; star schema). Furthermore; we incorporate a particular indexing strategy;DataIndexes; to further improve query processing times and parallel resource utilization; andpropose a preliminary parallel star-join strategy.,Database and Expert Systems Applications; 1998. Proceedings. Ninth International Workshop on,1998,77
Distributed cooperative Web servers1,Scott M Baker; Bongki Moon,Abstract Traditional techniques for a distributed web server design rely on manipulation ofcentral resources; such as routers or DNS services; to distribute requests designated for asingle IP address to multiple web servers. The goal of the distributed cooperative Webserver (DCWS) system development is to explore application-level techniques fordistributing web content. We achieve this by dynamically manipulating the hyperlinks storedwithin the web documents themselves. The DCWS system effectively eliminates thebottleneck of centralized resources; while balancing the load among distributed webservers. DCWS servers may be located in different networks; or even different continentsand still balance load effectively. DCWS system design is fully compatible with existingHTTP protocol semantics and existing web client software products.,Computer Networks,1999,76
Distributed cooperative Apache web server,Quanzhong Li; Bongki Moon,ABSTRACT Given explosive data traffic in the world-wide web (WWW); it is crucial toachieve the scalable performance of web servers. The overall performance and resourceutilization can be improved by spreading document requests among a group of web servers.This leads to the design and implementation of Distributed Cooperative Apache (VC-Apache) web server. In this paper; we describe the unique features of the VC-Apachesystem (1) to migrate and replicate documents among cooperating servers;(2) usingdynamic hyperlink generation to distribute requests for documents to balance the load; and(3) to maintain replicated copies in a consistent state. We also address the issue of storagemanagement for more effective document replication under limited capacity. In theexperiments; the VC-Apache system demonstrated its ability to achieve high performance …,Proceedings of the 10th international conference on World Wide Web,2001,70
Efficient algorithms for large-scale temporal aggregation,Bongki Moon; I Fernando Vega Lopez; Vijaykumar Immanuel,The ability to model time-varying natures is essential to many database applications such asdata warehousing and mining. However; the temporal aspects provide many uniquecharacteristics and challenges for query processing and optimization. Among the challengesis computing temporal aggregates; which is complicated by having to compute temporalgrouping. We introduce a variety of temporal aggregation algorithms that overcome majordrawbacks of previous work. First; for small-scale aggregations; both the worst-case andaverage-case processing time have been improved significantly. Second; for large-scaleaggregations; the proposed algorithms can deal with a database that is substantially largerthan the size of available memory. Third; the parallel algorithm designed on a shared-nothing architecture achieves scalable performance by delivering nearly linear scale-up …,IEEE Transactions on Knowledge and Data Engineering,2003,60
Adaptive runtime support for direct simulation Monte Carlo methods on distributed memory architectures,Bongki Moon; Joel Saltz,In highly adaptive irregular problems such as many particle-in-cell (PIC) codes and directsimulation Monte Carlo (DSMC) codes; data access patterns may vary from time step to timestep. This fluctuation may hinder efficient utilization of distributed memory parallel computersbecause of the resulting overhead for data redistribution and dynamic load balancing. Toefficiently parallelize such adaptive irregular problems on distributed memory parallelcomputers; several issues such as effective methods for domain partitioning and fast datatransportation must be addressed. This paper presents efficient runtime support methods forsuch problems. A simple one-dimensional domain partitioning method is implemented andcompared with unstructured mesh partitioners such as recursive coordinate bisection andrecursive inertial bisection. A remapping decision policy has been investigated for …,Scalable High-Performance Computing Conference; 1994.; Proceedings of the,1994,60
Skyline index for time series data,Quanzhong Li; Bongki Moon; IFV Lopez,We have developed a new indexing strategy that helps overcome the curse ofdimensionality for time series data. Our proposed approach; called skyline index; adoptsnew skyline bounding regions (SBR) to approximate and represent a group of time seriesdata according to their collective shape. Skyline bounding regions allow us to define adistance function that tightly lower bounds the distance between a query and a group of timeseries data. In an extensive performance study; we investigate the impact of differentdistance functions by various dimensionality reduction and indexing techniques on theperformance of similarity search; including index pages accessed; data objects fetched; andoverall query processing time. In addition; we show that; for k-nearest neighbor queries; theproposed skyline index approach can be coupled with the state of the art dimensionality …,IEEE Transactions on Knowledge and Data Engineering,2004,56
X-FTL: transactional FTL for SQLite databases,Woon-Hak Kang; Sang-Won Lee; Bongki Moon; Gi-Hwan Oh; Changwoo Min,Abstract In the era of smartphones and mobile computing; many popular applications suchas Facebook; twitter; Gmail; and even Angry birds game manage their data using SQLite.This is mainly due to the development productivity and solid transactional support. Fortransactional atomicity; however; SQLite relies on less sophisticated but costlier page-oriented journaling mechanisms. Hence; this is often cited as the main cause of tardyresponses in mobile applications. Flash memory does not allow data to be updated in place;and the copy-on-write strategy is adopted by most flash storage devices. In this paper; wepropose X-FTL; a transactional flash translation layer (FTL) for SQLite databases. Byoffloading the burden of guaranteeing the transactional atomicity from a host system to flashstorage and by taking advantage of the copy-on-write strategy used in modern FTLs; X …,Proceedings of the 2013 ACM SIGMOD International Conference on Management of Data,2013,54
Scalability analysis of declustering methods for multidimensional range queries,Bongki Moon; Joel H Saltz,Efficient storage and retrieval of multi-attribute data sets has become one of the essentialrequirements for many data-intensive applications. The Cartesian product file has beenknown as an effective multi-attribute file structure for partial-match and best-match queries.Several heuristic methods have been developed to decluster Cartesian product files acrossmultiple disks to obtain high performance for disk accesses. Although the scalability of thedeclustering methods becomes increasingly important for systems equipped with a largenumber of disks; no analytic studies have been done so far. The authors derive formulasdescribing the scalability of two popular declustering methods-Disk Module and FieldwiseXor-for range queries; which are the most common type of queries. These formulas disclosethe limited scalability of the declustering methods; and this is corroborated by extensive …,IEEE Transactions on Knowledge and Data Engineering,1998,52
Study of scalable declustering algorithms for parallel grid files,Bongki Moon; Anurag Acharya; Joel Saltz,The efficient storage and retrieval of large multidimensional datasets is an important concernfor large-scale scientific computations; such as long-running time-dependent simulationswhich periodically generate snapshots of the state. The main challenge for efficientlyhandling such datasets is to minimize response time for multidimensional range queries.The grid file is one of the well known access methods for multidimensional and spatial data.We investigate effective and scalable declustering techniques for grid files with the primarygoal of minimizing response time and the secondary goal of maximizing the fairness of datadistribution. The main contributions of this paper are (1) the analytic and experimentalevaluation of existing index-based declustering techniques and their extensions for gridfiles; and (2) the development of a proximity-based declustering algorithm called'minimax' …,Parallel Processing Symposium; 1996.; Proceedings of IPPS'96; The 10th International,1996,50
Scalable algorithms for large temporal aggregation,Bongki Moon; Inés Fernando Vega López; Vijaykumar Immanuel,The ability to model time-varying nature is essential to many database applications such asdata warehousing and mining. However; the temporal aspects provide many uniquecharacteristics and challenges for query processing and optimization. Among the challengesis computing temporal aggregates; which is complicated by having to compute temporalgrouping. In this paper; we introduce a variety of temporal aggregation algorithms thatovercome major drawbacks of previous work. First; for small-scale aggregations; both theworst-case and average-case processing time have been improved significantly. Second; forlarge-scale aggregations; the proposed algorithms can deal with a database that issubstantially larger than the size of available memory.,Data Engineering; 2000. Proceedings. 16th International Conference on,2000,45
-XISS/R: XML Indexing and Storage System Using RDBMS** This work was sponsored in part by National Science Foundation CAREER Award (IIS-9876037); NSF...,Philip J Harding; Quanzhong Li; Bongki Moon,This chapter demonstrates the XISS/R system; an implementation of the XML indexing andstorage system (XISS) on top of a relational database. The system is based on the XISSextended preorder numbering scheme; which captures the nesting structure of XML dataand provides the opportunity for storage and query processing independent of the particularstructure of the data. The system includes a web-based user interface; which enables storeddocuments to be queried via XPath. The user interface utilizes the XPath Query Engine;which automatically translates XPath queries into efficient SQL statements. XML is quicklybecoming the new standard for data representation and exchange in the internet. Anemerging issue is how to provide efficient storage and manipulation of XML data. Sincerelational technology is mature and well-developed; using relational databases to store …,*,2003,44
Flash-based extended cache for higher throughput and faster recovery,Woon-Hak Kang; Sang-Won Lee; Bongki Moon,Abstract Considering the current price gap between disk and flash memory drives; forapplications dealing with large scale data; it will be economically more sensible to use flashmemory drives to supplement disk drives rather than to replace them. This paper presentsFaCE; which is a new low-overhead caching strategy that uses flash memory as anextension to the DRAM buffer. FaCE aims at improving the transaction throughput as well asshortening the recovery time from a system failure. To achieve the goals; we propose twonovel algorithms for flash cache management; namely; Multi-Version FIFO replacement andGroup Second Chance. One striking result from FaCE is that using a small flash memorydrive as a caching device could deliver even higher throughput than using a large flashmemory drive to store the entire database tables. This was possible due to flash write …,Proceedings of the VLDB Endowment,2012,42
FASTer FTL for enterprise-class flash memory SSDs,Sang-Phil Lim; Sang-Won Lee; Bongki Moon,For the past decade; numerous methods have been proposed for the design of a flashtranslation layer (FTL); which is the core engine of flash memory drives that criticallydetermines the performance of the drives. In this paper; we revisit one of the popular FTLschemes called FAST; and augment it with new optimization techniques aiming particularlyat online transaction processing (OLTP) workloads. As flash memory solid state drives(SSDs) are increasingly adopted for large-scale enterprise-class storage systems; it isimportant to develop an FTL that can deal with OLTP workloads in a scalable manner; whichare characterized by a large number of small; random and skewed IO operations. With theproposed optimization methods such as giving a second chance to valid pages and isolatingcold ones; the enhanced FTL; called FASTer; outperforms FAST considerably. In our …,Storage Network Architecture and Parallel I/Os (SNAPI); 2010 International Workshop on,2010,42
HadoopXML: a suite for parallel processing of massive XML data with multiple twig pattern queries,Hyebong Choi; Kyong-Ha Lee; Soo-Hyong Kim; Yoon-Joon Lee; Bongki Moon,Abstract The volume of XML data is tremendous in many areas; but especially in datalogging and scientific areas. XML data in the areas are accumulated over time as new dataare continuously collected. It is a challenge to process massive XML data with multiple twigpattern queries given by multiple users in a timely manner. We showcase HadoopXML; asystem that simultaneously processes many twig pattern queries for a massive volume ofXML data with Hadoop. Specifically; HadoopXML provides an efficient way to process asingle large XML file in parallel. It processes multiple twig pattern queries simultaneouslywith a shared input scan. Users do not need to iterate M/R jobs for each query. HadoopXMLalso reduces many I/Os by enabling twig pattern queries to share their path solutions eachother. Moreover; HadoopXML provides a sophisticated runtime load balancing scheme …,Proceedings of the 21st ACM international conference on Information and knowledge management,2012,41
Sequencing XML data and query twigs for fast pattern matching,Praveen Rao; Bongki Moon,Abstract We propose a new way of indexing XML documents and processing twig patterns inan XML database. Every XML document in the database can be transformed into asequence of labels by prüfer's method that constructs a one-to-one correspondencebetween trees and sequences. During query processing; a twig pattern is also transformedinto its Prüfer sequence. By performing subsequence matching on the set of sequences inthe database and performing a series of refinement phases that we have developed; we canfind all the occurrences of a twig pattern in the database. Our approach allows holisticprocessing of a twig pattern without breaking the twig into root-to-leaf paths and processingthese paths individually. Furthermore; we show in the article that all correct answers arefound without any false dismissals or false alarms. Experimental results demonstrate the …,ACM Transactions on Database Systems (TODS),2006,40
The design and evaluation of a high-performance earth science database,Carter T Shock; Chialin Chang; Bongki Moon; Anurag Acharya; Larry Davis; Joel Saltz; Alan Sussman,Abstract Earth scientists have encountered two major obstacles in their attempts to useremotely sensed imagery to analyze the earth's land cover dynamics. First; the volume ofdata involved is very large and second; significant preprocessing is needed before the datacan be used. This is particularly so for studies that analyze global trends using data sets thatcover multiple years. In this paper; we present the design of an earth science database aswell as our early experiences with it. The primary design goal of this database is to facilitateefficient access to and preprocessing of large volumes of satellite data. Our initial designassumed that the main bottleneck in the system would be retrieving data from the disks.However; experimental results show that precise identification of all the data valuescorresponding to a query can take a significant amount of time. The problem is even more …,Parallel Computing,1998,36
Parallel algorithms for computing temporal aggregates,Jose Alvin G Gendrano; Bruce C Huang; Jim M Rodrigue; Bongki Moon; Richard T Snodgrass,The ability to model the temporal dimension is essential to many applications. Furthermore;the rate of increase in database size and response time requirements has out-pacedadvancements in processor and mass storage technology; leading to the need for paralleltemporal database management systems. In this paper; we introduce a variety of paralleltemporal aggregation algorithms for a shared-nothing architecture based on the sequential"aggregation tree algorithm". Via an empirical study; we found that the number of processingnodes; the partitioning of the data; the placement of results and the degree of data reductioneffected by the aggregation impacted on the performance of the algorithms. For distributedresults placement; we discovered that time-division merging was the obvious choice. Forcentralized results and high data reduction; pairwise merging was preferred; regardless …,Data Engineering; 1999. Proceedings.; 15th International Conference on,1999,34
Durable write cache in flash memory SSD for relational and NoSQL databases,Woon-Hak Kang; Sang-Won Lee; Bongki Moon; Yang-Suk Kee; Moonwook Oh,Abstract In order to meet the stringent requirements of low latency as well as highthroughput; web service providers with large data centers have been replacing magneticdisk drives with flash memory solid-state drives (SSDs). They commonly use relational andNoSQL database engines to manage OLTP workloads in the warehouse-scale computingenvironments. These modern database engines rely heavily on redundant writes andfrequent cache flushes to guarantee the atomicity and durability of transactional updates.This has become a serious bottleneck of performance in both relational and NoSQLdatabase engines. This paper presents a new SSD prototype called DuraSSD equippedwith tantalum capacitors. The tantalum capacitors make the device cache inside DuraSSDdurable; and additional firmware features of DuraSSD take advantage of the durable …,Proceedings of the 2014 ACM SIGMOD international conference on Management of data,2014,33
Locating XML documents in a peer-to-peer network using distributed hash tables,Praveen R Rao; Bongki Moon,One of the key challenges in a peer-to-peer (P2P) network is to efficiently locate relevantdata sources across a large number of participating peers. With the increasing popularity ofthe extensible markup language (XML) as a standard for information interchange on theInternet; XML is commonly used as an underlying data model for P2P applications to dealwith the heterogeneity of data and enhance the expressiveness of queries. In this paper; weaddress the problem of efficiently locating relevant XML documents in a P2P network; wherea user poses queries in a language such as XPath. We have developed a new systemcalled psiX that runs on top of an existing distributed hashing framework. Under the psiXsystem; each XML document is mapped into an algebraic signature that captures thestructural summary of the document. An XML query pattern is also mapped into a …,IEEE Transactions on Knowledge and Data Engineering,2009,32
A clustering method based on path similarities of XML data,Ilhwan Choi; Bongki Moon; Hyoung-Joo Kim,Abstract Current studies on the storage of XML data are focused on either the efficientmapping of XML data onto an existing RDBMS or the development of a native XML storage.Some native XML storages store each XML node in a parsed object form. Clustering; whichmeans the physical arrangement of objects; can be an important factor in improving theperformance in this storage model. In this paper; we propose a clustering method that storesdata nodes in an XML document into the native XML storage. The proposed clusteringmethod uses path similarities between data nodes; which can reduce page I/Os required forquery processing. In addition; we propose a query processing method using signatures thatfacilitate the cluster-level access on the stored data to benefit from the proposed clusteringmethod. This method can process a path query by accessing only a small number of …,Data & Knowledge Engineering,2007,30
Value-based predicate filtering of XML documents,Joonho Kwon; Praveen Rao; Bongki Moon; Sukho Lee,Abstract In recent years; publish–subscribe systems based on XML filtering have receivedmuch attention in ubiquitous computing environments and Internet applications. The mainchallenge is to process a large number of content against millions of user subscriptions.Several XML filtering systems focus on the efficient processing of structural matching of usersubscriptions represented as XPath twig patterns. However; existing techniques providelimited or no support for twig patterns that contain various operators in the value-basedpredicates. In this paper; we present the pFiST system that filters XML documents bytransforming twig patterns into sequences based on Prüfer's method. This sequencing ideafor XML filtering was first demonstrated by FiST [J. Kwon; P. Rao; B. Moon; S. Lee; FiST:scalable XML document filtering by sequencing twig patterns; in: Proceedings of the 31st …,Data & Knowledge Engineering,2008,29
Efficient execution of range top-k queries in aggregate r-trees,Seokjin Hong; Bongki Moon; Sukho Lee,A range top-k query returns the topmost k records in the order set by a measure attributewithin a specified region of multi-dimensional data. The range top-k query is a powerful toolfor analysis in spatial databases and data warehouse environments. In this paper; wepropose an algorithm to answer the query by selectively traversing an aggregate R-treehaving MAX as the aggregate values. The algorithm can execute the query by accessingonly a small part of the leaf nodes within a query region. Therefore; it shows good queryperformance regardless of the size of the query region. We suggest an efficient pruningtechnique for the priority queue; which reduces the cost of handling the priority queue; andalso propose an efficient technique for leaf node organization to reduce the number of nodeaccesses to execute the range top-k queries.,IEICE TRANSACTIONS on Information and Systems,2005,27
Adaptive and incremental processing for distance join queries,Hyoseop Shin; Bongki Moon; Sukho Lee,A spatial distance join is a relatively new type of operation introduced for spatial andmultimedia database applications. Additional requirements for ranking and stoppingcardinality are often combined with the spatial distance join in online query processing orInternet search environments. These requirements pose new challenges as well asopportunities for more efficient processing of spatial distance join queries. In this paper; wefirst present an efficient k-distance join algorithm that uses spatial indexes such as R-trees.Bidirectional node expansion and plane-sweeping techniques are used for fast pruning ofdistant pairs; and the plane-sweeping is further optimized by novel strategies for selecting asweeping axis and direction. Furthermore; we propose adaptive multistage algorithms for k-distance join and incremental distance join operations. Our performance study shows that …,IEEE Transactions on Knowledge and Data Engineering,2003,25
Programming irregular applications: Runtime support; compilation and tools,Joel Saltz; Chialin Chang; Guy Edjlali; Yuan-Shin Hwang; Bongki Moon; Ravi Ponnusamy; Shamik Sharma; Alan Sussman; Mustafa Uysal; Gagan Agrawal; Raja Das; Paul Havlak,Abstract In this chapter; we present a summary of the runtime support; compiler and toolsdevelopment efforts in the CHAOS group at the University of Maryland. The principal focus ofthe CHAOS group's research has been to develop tools; compiler runtime support andcompilation techniques to help scientists and engineers develop high-speed parallelimplementations of codes for irregular scientific problems (ie problems that are unstructured;sparse; adaptive or block structured). We have developed a series of runtime supportlibraries (CHAOS; CHAOS++) that carry out the preprocessing and data movement neededto efficiently implement irregular and block structured scientific algorithms on distributedmemory machines and networks of workstations. Our compilation research has played amajor role in demonstrating that it is possible to develop data parallel compilers able to …,*,1997,24
Sqlite optimization with phase change memory for mobile applications,Gihwan Oh; Sangchul Kim; Sang-Won Lee; Bongki Moon,Abstract Given its pervasive use in smart mobile platforms; there is a compelling need tooptimize the performance of sluggish SQLite databases. Popular mobile applications suchas messenger; email and social network services rely on SQLite for their data managementneed. Those mobile applications tend to execute relatively short transactions in theautocommit mode for transactional consistency in databases. This often has adverse effecton the flash memory storage in mobile devices because the small random updates causehigh write amplification and high write latency. In order to address this problem; we proposea new optimization strategy; called per-page logging (PPL); for mobile data management;and have implemented the key functions in SQLite/PPL. The hardware component ofSQLite/PPL includes phase change memory (PCM) with a byte-addressable; persistent …,Proceedings of the VLDB Endowment,2015,23
Scalable web server design for distributed data management,Scott M Baker; Bongki Moon,Abstract Traditional techniques for a distributed web server design rely on manipulation ofcentral resources; such as routers or DNS services; to distribute requests designated for asingle IP address to multiple web servers. The goal of the Distributed Cooperative WebServer (DCWS) system development is to explore application-level techniques fordistributing web content. We achieve this by dynamically manipulating the hyperlinks storedwithin the web documents themselves. The DCWS system e ectively eliminates thebottleneck of centralized resources; while balancing the load among distributed webservers. DCWS servers may be located in di erent networks; or even di erent continents andstill balance load e ectively. DCWS system design is fully compatible with existing HTTPprotocol semantics and existing web client software products.,icde,1999,23
An internet-scale service for publishing and locating XML documents,Praveen Rao; Bongki Moon,In recent years; there has been a growing interest for peer-to-peer (P2P) based computingand applications. One of the most important challenges in P2P environments is to quicklylocate relevant data across many participating peers. In this demonstration; we present psiX;which is an Internet-scale service for publishing and locating XML documents. This serviceruns on several PlanetLab nodes geographically spread across the globe. The psiX systemadopts a suite of new techniques for XML indexing and pattern matching in a P2P network;namely;(a) representing XML documents and XPath queries compactly via algebraicsignatures;(b) searching signatures of documents and value summaries indexed usingdistributed hierarchical indexesbuilt over a Distributed Hash Table (DHT); and (c) gracefullyadapting to failures while running on the Internet; where failures are a norm rather than …,Data Engineering; 2009. ICDE'09. IEEE 25th International Conference on,2009,22
Parallel Monte Carlo simulation of three-dimensional flow over a flat plate,Robert P Nance; Richard G Wilmoth; Bongki Moon; HA Hassan; Joel Saltz,M.; _= freestream Mach number Re= freestream Reynolds number pw= surface pressure;Pa/?()= stagnation pressure; bar qw= surface heat flux; W/m2 Tw= surface temperature; KT()= stagnation temperature; K t= time required to compute 1 time step W (n)= systemdegradation function Z;= rotational relaxation number,Journal of Thermophysics and Heat Transfer,1995,21
Parallel DSMC solution of three-dimensional flow over a finite flat plate,Robert P Nance; Richard G Wilmoth; Bongki Moon; HA Hassan; Joel Saltz,Abstract: This paper describes a parallel implementation of the direct simulation Monte Carlo(DSMC) method. Runtime library support is used for scheduling and execution ofcommunication between nodes; and domain decomposition is performed dynamically tomaintain a good load balance. Performance tests are conducted using the code to evaluatevarious remapping and remapping-interval policies; and it is shown that a one-dimensionalchain-partitioning method works best for the problems considered. The parallel code is thenused to simulate the Mach 20 nitrogen flow over a finite-thickness flat plate. It is shown thatthe parallel algorithm produces results which compare well with experimental data.Moreover; it yields significantly faster execution times than the scalar code; as well as verygood load-balance characteristics.,*,1994,21
A data parallel algorithm for XML DOM parsing,Bhavik Shah; Praveen R Rao; Bongki Moon; Mohan Rajagopalan,Abstract The extensible markup language XML has become the de facto standard forinformation representation and interchange on the Internet. XML parsing is a core operationperformed on an XML document for it to be accessed and manipulated. This operation isknown to cause performance bottlenecks in applications and systems that process largevolumes of XML data. We believe that parallelism is a natural way to boost performance.Leveraging multicore processors can offer a cost-effective solution; because future multicoreprocessors will support hundreds of cores; and will offer a high degree of parallelism inhardware. We propose a data parallel algorithm called ParDOM for XML DOM parsing; thatbuilds an in-memory tree structure for an XML document. ParDOM has two phases. In thefirst phase; an XML document is partitioned into chunks and parsed in parallel. In the …,International XML Database Symposium,2009,20
Main memory-based algorithms for efficient parallel aggregation for temporal databases,Dengfeng Gao; Jose Alvin G Gendrano; Bongki Moon; Richard T Snodgrass; Minseok Park; Bruce C Huang; Jim M Rodrigue,Abstract The ability to model the temporal dimension is essential to many applications.Furthermore; the rate of increase in database size and stringency of response timerequirements has out-paced advancements in processor and mass storage technology;leading to the need for parallel temporal database management systems. In this paper; weintroduce a variety of parallel temporal aggregation algorithms for the shared-nothingarchitecture; these algorithms are based on the sequential Aggregation Tree algorithm. Weare particularly interested in developing parallel algorithms that can maximally exploitavailable memory to quickly compute large-scale temporal aggregates without intermediatedisk writes and reads. Via an empirical study; we found that the number of processingnodes; the partitioning of the data; the placement of results; and the degree of data …,Distributed and Parallel Databases,2004,20
Runtime Support Dynamic Load Balancing Strategies for Structured Adaptive Applications.,Bongki Moon; Gopal Patnaik; Robert Bennett; David Fyfe; Alan Sussman; Craig Douglas; Joel H Saltz; K Kailasanath,Abstract One class of scienti c and engineering applications involves structured meshes.One example of a code in this class is a ame modelling code developed at the NavalResearch Laboratory (NRL). The numerical model used in the NRL ame code ispredominantly based on structured nite volume methods. The chemistry process of thereactive ow is modeled by a system of ordinary di erential equations which is solvedindependently at each grid point. Thus; though the model uses a mesh structure; theworkload at each grid point can vary considerably. It is this feature that requires the use ofboth structured and unstructured methods in the same code. We have applied the MultiblockPARTI and CHAOS runtime support libraries to parallelize the NRL ame code with minimalchanges to the sequential code. We have also developed parallel algorithms to carry out …,PPSC,1995,20
Adaptive cell-based index for moving objects,Wonik Choi; Bongki Moon; Sukho Lee,Abstract R-tree based access methods for moving objects are hardly applicable in practice;due mainly to excessive space requirements and high management costs. To overcome thelimitations of such R-tree based access methods; we propose a new index structure calledAIM (Adaptive cell-based Index for Moving objects). The AIM is a cell-based multiversionaccess structure adopting an overlapping technique. The AIM refines cells adaptively tohandle regional data skew; which may change its locations over time. Through the extensiveperformance studies; we observed that The AIM consumed at most 30% of the spacerequired by R-tree based methods; and achieved higher query performance compared withR-tree based methods.,Data & Knowledge Engineering,2004,19
R3F: RDF triple filtering method for efficient SPARQL query processing,Kisung Kim; Bongki Moon; Hyoung-Joo Kim,Abstract With the rapid growth in the amount of graph-structured Resource DescriptionFramework (RDF) data; SPARQL query processing has received significant attention. Themost important part of SPARQL query processing is its method of subgraph patternmatching. For this; most RDF stores use relation-based approaches; which can produce avast number of redundant intermediate results during query evaluation. In order to addressthis problem; we propose an RDF Triple Filtering (R3F) method that exploits the graph-structural information of RDF data. We design a path-based index called the RDF Path index(RP-index) to efficiently provide filter data for the triple filtering. We also propose a relationaloperator called the RDF Filter (RFLT) that can conduct the triple filtering with little overheadcompared to the original query processing. Through comprehensive experiments on …,World Wide Web,2015,16
Fast XML document filtering by sequencing twig patterns,Joonho Kwon; Praveen Rao; Bongki Moon; Sukho Lee,Abstract XML-enabled publish-subscribe (pub-sub) systems have emerged as anincreasingly important tool for e-commerce and Internet applications. In a typical pub-subsystem; subscribed users specify their interests in a profile expressed in the XPathlanguage. Each new data content is then matched against the user profiles so that thecontent is delivered only to the interested subscribers. As the number of subscribed usersand their profiles can grow very large; the scalability of the service is critical to the success ofpub-sub systems. In this article; we propose a novel scalable filtering system called iFiSTthat transforms user profiles of a twig pattern expressed in XPath into sequences using thePrüfer's method. Consequently; instead of breaking a twig pattern into multiple linear pathsand matching them separately; FiST performs holistic matching of twig patterns with each …,ACM Transactions on Internet Technology (TOIT),2009,16
Partition based path join algorithms for XML data,Quanzhong Li; Bongki Moon,Abstract Path expression is an important component in querying XML data. The extendedpreorder numbering scheme enables us to quickly determine the ancestor-descendantrelationship between elements in the hierarchy of XML data. Using the numbering scheme;a path expression can be evaluated by join operations to avoid potentially high cost of treetraversals. In this paper; we first formulate XML path queries as range-point join queries.Then we discuss the partition based algorithms that can utilize the range containmentproperty to efficiently process the range-point join queries. Under the partition basedframework; we propose three algorithms; namely Descendant partition join; Segment-treepartition join and Ancestor Link partition join; which can be chosen by a query optimizer fordifferent input data characteristics. The experimental results show that the partition based …,International Conference on Database and Expert Systems Applications,2003,15
Bulk insertion for R-tree by seeded clustering,Taewon Lee; Bongki Moon; Sukho Lee,Abstract In many scientific and commercial applications such as Earth Observation System(EOSDIS) and mobile phone services tracking a large number of clients; it is a daunting taskto archive and index ever increasing volume of complex data that are continuously added todatabases. To efficiently manage multidimensional data in scientific and data warehousingenvironments; R-tree based index structures have been widely used. In this paper; wepropose a scalable technique called Seeded Clustering that allows us to maintain R-treeindexes by bulk insertion while keeping pace with high data arrival rates. Our approach usesa seed tree; which is copied from the top k levels of a target R-tree; to classify input dataobjects into clusters. We then build an R-tree for each of the clusters and insert the input R-trees into the target R-tree in bulk one at a time. We present detailed algorithms for the …,International Conference on Database and Expert Systems Applications,2003,15
Accelerating In-Page Logging with Non-Volatile Memory.,Sang-Won Lee; Bongki Moon; Chanik Park; Joo Young Hwang; Kangnyeon Kim,Abstract A great deal of research has been done on solid-state storage media such as flashmemory and non-volatile memory in the past few years. While NAND-type flash memory isnow being considered a top alternative to magnetic disk drives; non-volatile memory (alsoknown as storage class memory) has begun to appear in the market recently. Althoughsome advocates of non-volatile memory predict that flash memory will give way to non-volatile memory soon; we believe that they will co-exist; complementing each other; for awhile until the hurdles in its manufacturing process are lifted and non-volatile memorybecomes commercially competitive in both capacity and price. In this paper; we present animproved design of In-Page Logging (IPL) by augmenting it with phase change RAM(PCRAM) in its log area. IPL is a buffer and storage management strategy that has been …,IEEE Data Eng. Bull.,2010,14
Dynamic in-page logging for flash-aware B-tree index,Gap-Joo Na; Sang-Won Lee; Bongki Moon,Abstract This paper presents Dynamic IPL B+-tree (d-IPL in short) as a B+-tree index variantfor flash-based storage systems. The d-IPL B+-tree adopts a dynamic In-Page Logging (IPL)scheme in order to address a few new problems that are caused by the uniquecharacteristics of B+-tree indexes The d-IPL B+-tree avoids the frequent log overflowproblem by allocating a log area in a flash block dynamically. It also addresses elegantly theproblem of page evaporation; imposed by the contemporary NAND flash chips; byintroducing ghost nodes within the context of the dynamic IPL scheme. This simple butelegant design of the d-IPL B+-tree improves the performance significantly. For a randominsertion workload; the d-IPL B+-tree index outperformed a B+-tree with a plain IPL schemeby more than a factor of two in terms of page write and block erase operations.,Proceedings of the 18th ACM conference on Information and knowledge management,2009,14
Bulk insertion for R-trees by seeded clustering,Taewon Lee; Bongki Moon; Sukho Lee,Abstract We propose a scalable technique called Seeded Clustering that allows us tomaintain R-tree indices by bulk insertion while keeping pace with high data arrival rates. Ourapproach uses a seed tree; which is copied from the top k levels of a target R-tree; to classifyinput data objects into clusters. We then build an R-tree for each of the clusters and insertthe input R-trees into the target R-tree in bulk one at a time. We present detailed algorithmsfor the seeded clustering and bulk insertion. The experimental results show that the bulkinsertion by seeded clustering outperforms the previously known methods.,Data & Knowledge Engineering,2006,14
Bitmap indexes for relational XML twig query processing,Kyong-Ha Lee; Bongki Moon,Abstract Due to an increasing volume of XML data; it is considered prudent to store XMLdata on an industry-strength database system instead of relying on a domain specificapplication or a file system. For shredded XML data stored in the relational tables; however;it may not be straightforward to apply existing algorithms for twig query processing; becausemost of the algorithms require XML data to be accessed in a form of streams of elementsgrouped by their tags and sorted in a particular order. In order to support XML queryprocessing within the common framework of relational database systems; we first proposeseveral bitmap indexes for supporting holistic twig joins on XML data stored in the relationaltables. Since bitmap indexes are well supported in most of the commercial and open-sourcedatabase systems; the proposed bitmap indexes and twig query processing algorithms …,Proceedings of the 18th ACM conference on Information and knowledge management,2009,13
In-page logging b-tree for flash memory,Gap-Joo Na; Bongki Moon; Sang-Won Lee,Abstract We demonstrate the IPL B+-tree prototype; which has been designed as a flash-aware index structure by adopting the in-page logging (IPL) scheme. The IPL scheme hasbeen proposed to improve the overall write performance of flash memory database systemsby avoiding costly erase operations that would be caused by small random write requestscommon in database workloads. The goal of this demonstration is to provide a proof-of-concept for IPL scheme as a viable and effective solution to flash memory database systems.,International Conference on Database Systems for Advanced Applications,2009,11
Sketchtree: Approximate tree pattern counts over streaming labeled trees,Praveen Rao; Bongki Moon,In recent years; there has been a rising interest in developing online approximationalgorithms for data streams. Some of the key challenges are posed by the fact that streamingdata can be read only once in a fixed order of arrival and only a limited amount of memory isavailable for storage. In this paper; we address the problem of approximately counting treepatterns over a stream of labeled trees (eg; XML documents). We propose a newapproximation algorithm called SketchTree that computes a synopsis of the stream in asingle pass by processing each tree only once. Using a limited amount of memory;SketchTree provides approximate answers for both ordered and unordered tree patterncounts. Furthermore; we discuss a class of count queries that can be handled by SketchTreeand their utility. We provide theoretical analyses to show that our algorithm has provably …,Data Engineering; 2006. ICDE'06. Proceedings of the 22nd International Conference on,2006,11
Dynamic In-Page Logging for B⁺-tree Index,Gap-Joo Na; Sang-Won Lee; Bongki Moon,Unlike database tables; B+-tree indexes are hierarchical and their structures change overtime by node splitting operations; which may propagate changes from one node to another.The node splitting operation is difficult for the basic In-Page Logging (IPL) scheme to dealwith; because it involves more than one node that may be stored separately in different flashblocks. In this paper; we propose Dynamic IPL B+-tree (d-IPL B+-tree in short) as a variant ofthe IPL scheme tailored for flash-based B+-tree indexes. The d-IPL B+-tree addresses theproblem of frequent log overflow by allocating a log area in a flash block dynamically. It alsoavoids a page evaporation problem; imposed by the contemporary NAND flash chips; byintroducing ghost nodes to d-IPL B+-tree. This simple but elegant design of the d-IPL B+-treeprovides significant performance improvement over existing approaches. For a random …,IEEE Transactions on Knowledge and Data Engineering,2012,10
IPL-P: In-page logging with PCRAM,Kangnyeon Kim; Sang-Won Lee; Bongki Moon; Chanik Park; Joo-Young Hwang,ABSTRACT A great deal of research has been done on solid-state storage media such asflash memory and non-volatile memory in the past few years. While NAND-type flashmemory is now considered a top alternative to magnetic disk drives; different types of non-volatile memory have also begun to appear in the market recently. Although someadvocates of storage class memory (SCM) predicted that flash memory would give way toSCM in the very near future; we believe that they will co-exist; complementing each other; fora while until the hurdles in its manufacturing process are lifted and storage class memorybecomes commercially competitive in both capacity and price. This demo presents animproved design of In-Page Logging (IPL) by augmenting it with Phase Change RAM(PCRAM) in its log area. IPL is a buffer and storage management strategy that has been …,Proceedings of the VLDB Endowment,2011,10
'Advocacy makes you feel brave': advocacy support for children and young people in Scotland,Susan Elsley,This report presents the findings from a scoping study into advocacy support for children andyoung people. The research was commissioned by the Scottish Government in order to findwhat advocacy services are available in Scotland; where they are and the circumstances inwhich they are available and to which groups of children and young people. A total of 39face to face or telephone interviews were undertaken with representatives of voluntaryorganisations and local authorities which directly provide advocacy services or haveexpertise in the needs of particular groups of children and young people. In addition;interviews were undertaken with representatives of national agencies. A range of otherorganisations provided information or informal contributions.,*,2010,10
Net-χ: unified data-centric internet services,Praveen Rao; Justin Cappos; Varun Khare; Bongki Moon; Beichuan Zhang,Abstract Databases and networks currently have different service models. Databaseservices are data-centric in that users typically describe the content of data and the systemfinds and returns matching data. However; traditional Internet services are server-centric inthat users have to know the location of data (eg; a URL) in order to retrieve it. We envision afuture in which Internet services are data-centric. Users specify their interests and publishersdescribe their data. Based on the matching between user interests and data contents; userscan pull data from publishers; and publishers can push data to interested users. We proposea unified system design called Net-χ to support data-centric Internet services seamlesslyunder a common framework. In Net-χ; user interests and data contents are characterized bypolynomial signatures. These signatures are stored in a distributed hash table; on which …,Proceedings of the 3rd USENIX international workshop on Networking meets databases,2007,10
Transactional In-Page Logging for multiversion read consistency and recovery,Sang-Won Lee; Bongki Moon,Recently; a new buffer and storage management strategy called In-Page Logging (IPL) hasbeen proposed for database systems based on flash memory. Its main objective is toovercome the limitations of flash memory such as erase-before-write and asymmetricread/write speeds by storing changes made to a data page in a form of log records withoutoverwriting the data page itself. Since it maintains a series of changes made to a data pageseparately from the original data page until they are merged; the IPL scheme providesunique opportunities to design light-weight transactional support for database systems. Inthis paper; we propose the transactional IPL (TIPL) scheme that takes advantage of the IPLlog records to support multiversion read consistency and light-weight database recovery.Due to the dual use of IPL log records; namely; for snapshot isolation and fast recovery as …,Data Engineering (ICDE); 2011 IEEE 27th International Conference on,2011,9
Index translation schemes for adaptive computations on distributed memory multicomputers,Bongki Moon; Mustafa Uysal; Joel Saltz,Current research in parallel programming is focused on closing the gap between globallyindexed algorithms and the separate address spaces of processors on distributed memorymulticomputers. A set of index translation schemes have been implemented as a part ofCHAOS runtime support library; so that the library functions can be used for implementing aglobal index space across a collection of separate local index spaces. These schemesinclude two software-cached translation schemes aimed at adaptive irregular problems aswell as a distributed translation table technique for statically irregular problems. To evaluateand demonstrate the efficiency of the software-cached translation schemes; experimentshave been performed with an adaptively irregular loop kernel and a full-fledged 3D DSMCcode from NASA Langley on the Intel Paragon and Gray T3D. This paper also discusses …,Parallel Processing Symposium; 1995. Proceedings.; 9th International,1995,9
IPLB+-tree for Flash Memory Database Systems.,Gap-Joo Na; Bongki Moon; Sang-Won Lee,Recently; the in-page logging (IPL) scheme has been proposed to improve the overall writeperformance of flash memory by avoiding costly erase operations that would be caused bysmall random write requests common in database applications. In this paper; we identify theproblems inherent in the existing design of disk-based B+-tree index; and present the designand implementation of the IPL B+-tree. In this paper; in order to prove the concept of IPL tobe a viable and effective solution for flash memory; we show the superior performance of theIPL B+-tree index by running it on a real hardware prototype. We then show the IPL B+-treeindex outperforms traditional B+-tree index running on top of an FTL by a factor of two tofifteen. In addition; we introduce the concept of FTL dependency: many existing B+ treeschemes for flash memory could not control FTL so that their performance might be …,J. Inf. Sci. Eng.,2011,8
Scalable algorithms for large-scale temporal aggregation,Bongki Moon; Ines Fernando Vega Lopez; Vijaykumar Immanuel,Abstract The ability to model time-varying natures is essential to many database applicationssuch as data warehousing and mining. However; the temporal aspects provide many uniquecharacteristics and challenges for query processing and optimization. Among the challengesis computing temporal aggregates; which is complicated by having to compute temporalgrouping. In this paper; we introduce a variety of temporal aggregation algorithms thatovercome major drawbacks of previous work. First; for small-scale aggregations; both theworst-case and average-case processing time have been improved signi cantly. Second; forlarge-scale aggregations; the proposed algorithms can deal with a database that issubstantially larger than the size of available memory. Third; the parallel algorithm designedon a shared-nothing architecture achieves scalable performance by delivering nearly …,Marketing,1998,8
Applying parallel processing techniques in data warehousing and OLAP,Anindya Datta; Debra VanderMeer; Krithi Ramamritham; Bongki Moon,Abstract We explore the applicability of parallel processing techniques for OLAP queryprocessing. In particular; we exploit the natural partitionability of a star schema and render iteven more e cient by applying a storage and access structure that serves both as an indexas well as data and lends itself naturally to vertical partitioning of the data. We propose adeclustering strategy which incorporates both task and data partitioning and present theParallel Star Join (PSJ) algorithm; which provides a means to perform a star join in parallelusing e cient operations involving only rowsets and projection columns. We compare theperformance of this algorithm with two parallel query processing strategies. The rst strategyis a parallel join strategy utilizing the Bitmap Join Index (BJI); arguably the state of the artOLAP join structure in use today. For the second strategy we choose a well known …,submitted for publication,1998,8
" Have your Data and Index it; too". Efficient Storage and Indexing for Data Warehouses,Anindya Datta; Bongki Moon; Krithi Ramamritham; Helen Thomas; Igor Viguier,Abstract Two possible strategies may be utilized to enhance the efficiency of processingOLAP queries:(a) precomputation strategies (eg; view materialization; realizing data cubes);and (b) ad-hoc strategies. While a significant amount of work has been done in developingprecomputation strategies; it is generally recognized that it is difficult to materialize theanswers to all possible queries. Thus; ad-hoc querying must be supported in datawarehouses. This realization has sparked an interest in exploring indexing strategiessuitable for OLAP queries. There appears to have been relatively little work done in ad-hocquery support for data warehouses [45; 46; 55; 39]. In this paper we propose DataIndexes asa new paradigm for storing the base data. An attractive feature of DataIndexes is that theyserve as indexes as well as the store of base data. Thus; DataIndexes actually define a …,*,1998,8
Runtime support to parallelize adaptive irregular programs,Yuan-Shin Hwang; Bongki Moon; Shamik Sharma; Raja Das; Joel Saltz,Abstract This paper describes how a runtime support library can be used as compilerruntime support in irregular applications. The CHAOS runtime support library carries outoptimizations designed to reduce communication costs by performing software caching;communication coalescing and inspector/executor preprocessing. CHAOS also suppliesspecial purpose routines to support specific types of irregular reduction and runtime supportfor partitioning data and work between processors. A number of adaptive irregular codeshave been parallelized using the CHAOS library and performance results from these codesare also presented in this paper.,Proceedings of the Workshop on Environments and Tools for Parallel Scientific Computing,1994,7
In-storage processing of database scans and joins,Sungchan Kim; Hyunok Oh; Chanik Park; Sangyeun Cho; Sang-Won Lee; Bongki Moon,Abstract Flash memory-based SSD is becoming popular because of its outstandingperformance compared to conventional magnetic disk drives. Today; SSDs are essentially ablock device attached to a legacy host interface. As a result; the system I/O bus remains abottleneck; and the abundant flash memory bandwidth and the computing capabilities ofSSD are largely untapped. In this paper; we propose to accelerate key database operations;scan and join; for large-scale data analysis by moving data-intensive processing from thehost CPU to inside flash SSDs (“in-storage processing”); close to the data source itself. Torealize the idea of in-storage processing in a cost-effective manner; we deploy special-purpose compute modules using the System-on-Chip technology. While data from flashmemory are transferred; a target database operation is applied to the data stream on the …,Information Sciences,2016,6
Quantizing time series for efficient similarity search under time warping,Inés F Vega-López; Bongki Moon,QUANTIZING TIME SERIES FOR EFFICIENT SIMILARITY SEARCH UNDER TIME WARPINGIn´es F. Vega-L´opez School of Informatics Autonomous University of Sinaloa Culiac´an;Sinaloa; M´exico email: ifvega@uas.uasnet.mx Bongki Moon Department of Computer ScienceUniversity of Arizona Tucson; AZ; USA email: bkmoon@cs.arizona.edu ABSTRACT IndexingTime Series Data is an interesting problem that has attracted much interest in the research communityfor the last decade. Traditional indexing methods organize the data space using differentmetrics. For time series; how- ever; there are some cases when a metric is not suited for properlyassessing the similarity between sequences. For instance; to detect similarities between sequencesthat are locally out of phase Dynamic Time Warping (DTW) must be used. DTW is not a metricas it does not satisfy the trian- gular inequality. Therefore; traditional spatial access meth …,ACST,2006,6
Extent mapping scheme for flash memory devices,Young-Kyoon Suh; Bongki Moon; Alon Efrat; Jin-Soo Kim; Sang-Won Lee,Flash memory devices commonly rely on traditional address mapping schemes such aspage mapping; block mapping or a hybrid of the two. Page mapping is more flexible thanblock mapping or hybrid mapping without being restricted by block boundaries. However; itsmapping table tends to grow large quickly as the capacity of flash memory devices does. Toovercome this limitation; we propose a novel mapping scheme that is fundamentally differentfrom the existing mapping strategies. We call this new scheme Virtual Extent Trie (VET); as itmanages mapping information by treating each I/O request as an extent and by usingextents as basic mapping units rather than pages or blocks. By storing extents instead ofindividual addresses; VET consumes much less memory to store mapping information andstill remains as flexible as page mapping. We observed in our experiments that VET …,Modeling; Analysis & Simulation of Computer and Telecommunication Systems (MASCOTS); 2012 IEEE 20th International Symposium on,2012,5
RG-index: An RDF graph index for efficient SPARQL query processing,Kisung Kim; Bongki Moon; Hyoung-Joo Kim,Abstract As the size of Resource Description Framework (RDF) graphs has grown rapidly;SPARQL query processing on the large-scale RDF graph has become a more challengingproblem. For efficient SPARQL query processing; the handling of the intermediate results isthe most crucial element because it generally involves many join operators. Recently; atriple filtering method; called the RP-filter; which uses a path-based index; was proposed. Itcan reduce the intermediate results effectively by filtering out irrelevant triples in advance.However; its filtering power is limited; because it uses only the path information of the RDFgraph. In this paper; we extend the triple filtering method to exploit the graph-structuralinformation; and propose the RDF graph index (RG-index). We address the problem of theRG-index; which is caused by the indexing of the graph patterns; by indexing only …,Expert Systems with Applications,2014,4
Value-Based predicate filtering of streaming XML data,Joonho Kwon; Praveen Rao; Bongki Moon; Sukho Lee,In recent years; publish-subscribe systems based on XML document filtering have receivedmuch intention in ubiquitous computing environments and Internet applications. Theircommon need is to process a large number of content against millions of user subscriptions.In this paper; we present the design of the FiST-P system for XML filtering system based onthe sequence approach. The FiST-P system can process the structure matching and alsohandle value-based predicates in the twig patterns. The value-based predicates arehandled differently according to their operators. We also described the cost for processing atwig pattern which includes value-based predicates.,Multimedia and Ubiquitous Engineering; 2007. MUE'07. International Conference on,2007,4
A clustering method based on path similarities of XML data,Il-Hwan Choi; Bong-Ki Moon; Hyoung-Joo Kim,Abstract Current studies on storing XML data are focused on either mapping XML data toexisting RDBMS efficiently or developing a native XML storage. Some native XML storagesstore each XML node with parsed object form. Clustering; the physical arrangement of eachobject; can be an important factor to increase the performance with this storing method. Inthis paper; we propose re-clustering techniques that can store an XML document efficiently.Proposed clustering technique uses path similarities among data nodes; which can reducepage I/Os when returning query results. And proposed technique can process a path queryonly using small number of clusters as possible instead of using all clusters. This enablesefficient processing of path query because we can reduce search space by skippingunnecessary data. Finally; we apply existing clustering techniques to store XML data and …,Journal of KIISE: Databases,2006,4
psiX: Hierarchical distributed index for efficiently locating xml data in peer-to-peer networks,Praveen Rao; Bongki Moon,*,Technical Report,2005,4
Flash as cache extension for online transactional workloads,Woon-Hak Kang; Sang-Won Lee; Bongki Moon,Abstract Considering the current price gap between hard disk and flash memory SSDstorages; for applications dealing with large-scale data; it will be economically moresensible to use flash memory drives to supplement disk drives rather than to replace them.This paper presents FaCE; which is a new low-overhead caching strategy that uses flashmemory as an extension to the RAM buffer of database systems. FaCE aims at improving thetransaction throughput as well as shortening the recovery time from a system failure. Toachieve the goals; we propose two novel algorithms for flash cache management; namelymulti-version FIFO replacement and group second chance. This was possible due to flashwrite optimization as well as disk access reduction obtained by the FaCE caching methods.In addition; FaCE takes advantage of the nonvolatility of flash memory to fully support …,The VLDB Journal,2016,3
InnoDB DoubleWrite Buffer as Read Cache using SSDs,Woon-Hak Kang; Gi-Tae Yun; Sang-Phil Lim; Dong-In Shin; Yang-Hun Park; Sang-Won Lee; Bongki Moon,As the technology of flash memory solid state drives (SSD hereafter for short) continues toadvance; they are increasingly adopted in a wide spectrum of storage systems.Nevertheless; it is still true that the price per unit capacity of flash memory SSDs is higherthan that of disk drives; and the market trend is likely to continue for the foreseeable future.Therefore; for applications dealing with large scale data; it may be economically moresensible to use flash memory SSDs to supplement disk drives rather than to replace them.Along this vein; a few studies have been recently proposed to use SSD as a cache betweenthe RAM buffer and harddisk [2]; and they are very promising in terms of performance andprice. Meanwhile; a recent empirical study showed that; due to low latency of SSDs;significant performance improvement can be achieved in OLTP databases just by …,10th USENIX Conference on File and Storage Technologies,2012,3
RP-Filter: a path-based triple filtering method for efficient SPARQL query processing,Kisung Kim; Bongki Moon; Hyoung-Joo Kim,Abstract With the rapid increase of RDF data; the SPARQL query processing has receivedmuch attention. Currently; most RDF databases store RDF data in a relational table calledtriple table and carry out several join operations on the triple tables for SPARQL queryprocessing. However; the execution plans with many joins might be inefficient due to a largeamount of intermediate data being passed between join operations. In this paper; wepropose a triple filtering method called RP-Filter to reduce the amount of intermediate data.RP-Filter exploits the path information in the query graphs and filters the triples which wouldnot be included in final results in advance of joins. We also suggest an efficient relationaloperator RFLT which filters triples by means of RP-Filter. Experimental results on syntheticand real-life RDF data show that RP-Filter can reduce the intermediate results effectively …,Joint International Semantic Technology Conference,2011,3
Scalability analysis of declustering methods for Cartesian product files,Bongki Moon; Joel Saltz,Efficient storage and retrieval of multi-attribute datasets has become one of the essentialrequirements for many data-intensive applications. The Cartesian product file has beenknown as an effective multi-attribute file structure for partial-match and best-match queries.Several heuristic methods have been developed to decluster Cartesian product files overmultiple disks to obtain high performance for disk accesses. Though the scalability of thedeclustering methods becomes increasingly important for systems equipped with a largenumber of disks; no analytic studies have been done so far. In this paper we derive formulasdescribing the scalability of two popular declustering methods Disk Modulo and FieldwiseXor for range queries; which are the most common type of queries. These formulas disclosethe limited scalability of the declustering methods and are corroborated by extensive …,*,1998,3
SBH: Super byte-aligned hybrid bitmap compression,Sangchul Kim; Junhee Lee; Srinivasa Rao Satti; Bongki Moon,Abstract Bitmap indexes are commonly used in data warehousing applications such as on-line analytic processing (OLAP). Storing the bitmaps in compressed form has been shown tobe effective not only for low cardinality attributes; as conventional wisdom would suggest;but also for high cardinality attributes. Compressed bitmap indexes; such as Byte-alignedBitmap Compression (BBC); Word-Aligned Hybrid (WAH) and several of their variants havebeen shown to be efficient in terms of both time and space; compared to traditional databaseindexes. In this paper; we propose a new technique for compressed bitmap indexing; calledSuper Byte-aligned Hybrid (SBH) bitmap compression; which improves upon the currentstate-of-the-art compression schemes. In our empirical evaluation; the query processing timeof SBH was about five times faster than that of WAH; while the size of its compressed …,Information Systems,2016,2
Memory efficient and scalable address mapping for flash storage devices,Young-Kyoon Suh; Bongki Moon; Alon Efrat; Jin-Soo Kim; Sang-Won Lee,Abstract Flash memory devices commonly rely upon traditional address mapping schemessuch as page mapping; block mapping or a hybrid of the two. Page mapping is more flexiblethan block or hybrid mapping without being restricted by block boundaries. However; itsmapping table tends to grow large quickly as the capacity of flash memory devices does. Toovercome this limitation; we propose novel mapping schemes that are fundamentallydifferent from the existing mapping strategies. We call these new schemes Virtual Extent Trie(VET) and Extent Mapping Tree (EMT); as they manage mapping information by treatingeach I/O request as an extent and by using extents as basic mapping units rather than pagesor blocks. By storing extents instead of individual addresses; our extent mapping schemesconsume much less memory to store mapping information and still remain as flexible as …,Journal of Systems Architecture,2014,2
Extended Buffer Management with Flash Memory SSDs,Do-Yoon Sim; Jang-Woo Park; Sung-Tan Kim; Sang-Won Lee; Bong-Ki Moon,Abstract As the price of flash memory continues to drop and the technology of flash SSDcontroller innovates; high performance flash SSDs with affordable prices flourish in thestorage market. Nevertheless; it is hard to expect that flash SSDs will replace harddiskscompletely as database storage. Instead; the approach to use flash SSD as a cache forharddisks would be more practical; and; in fact; several hybrid storage architectures for flashmemory and harddisk have been suggested in the literature. In this paper; we propose anew approach to use flash SSD as an extended buffer for main buffer in database systems;which stores the pages replaced out from main buffer and returns the pages which are re-referenced in the upper buffer layer; improving the system performance drastically. Incontrast to the existing approaches to use flash SSD as a cache in the lower storage layer …,Journal of KIISE: Databases,2010,2
XML Document Filtering based on Segments,Joon-Ho Kwon; Praveen Rao; Bong-Ki Moon; Suk-Ho Lee,Abstract In recent years; publish-subscribe (pub-sub) systems based on XML documentfiltering have received much attention. In a typical pub-sub system; subscribed users specifytheir interest in profiles expressed in the XPath language; and each new content is matchedagainst the user profiles so that the content is delivered to only the interested subscribers. Asthe number of subscribed users and their profiles can grow very large; the scalability of thesystem is critical to the success of pub-sub services. In this paper; we propose a fast andscalable XML filtering system called SFiST which is an extension of the FiST system.Sharable segments are extracted from twig patterns and stored into the hash-basedSegment Table in SFiST system. Segments are used to represent user profiles as TerseSequences and stored in the Compact Segment Index during filtering. Our experimental …,Journal of KIISE: Databases,2008,2
Locating XML Documents in Peer-to-Peer Networks using DHTs,Praveen Rao; Bongki Moon,Abstract One of key challenges in a peer-to-peer (P2P) network is to efficiently locaterelevant data sources across a large number of participating peers. With the increasingpopularity of the extensible markup language (XML) as a standard for informationinterchange on the Internet; XML is commonly used as an underlying data model for P2Papplications to deal with the heterogeneity of data and to enhance the expressiveness ofqueries. In this paper; we address the problem of efficiently locating relevant XMLdocuments in a P2P network; where a user poses queries in a language such as XPath. Wehave developed a new system called psiX that runs on top of an existing distributed hashingframework. Under the psiX system; each XML document is mapped into an algebraicsignature that captures the structural summary of the document. An XML query pattern is …,*,2008,2
Efficiently Tracking Moving Sources in the LSST,J Kubica; T Axelrod; K Barnard; A Connolly; L Denneau; A Efrat; J Heasley; R Jedicke; B Moon; A Moore; S Morris; P Rao,Abstract The LSST will survey the sky with a cadence of several visits per month spaced byapproximately a week. This time sampling enables a detailed census of Solar Systemobjects ranging from over a million Main Belt Asteroids; to 20;000 Trans Neptunian Objectsand even potentially hazardous asteroids. The challenge in identifying all potential asteroidassociations is that it can be very computationally expensive (due to the many potentialtracks that must be tested in order to isolate true orbits).,Bulletin of the American Astronomical Society,2005,2
Partition-based similarity join in high dimensional data spaces,Hyoseop Shin; Bongki Moon; Sukho Lee,Abstract It is not desirable in the performance perspective of search algorithms to partition ahigh dimensional data space by dividing all the dimensions. This is because the number ofcells resulted from partitioning explodes as the number of partitioning dimensions increases;thus making any search method based on space partitioning impractical. To address thisproblem; we propose an algorithm to dynamically select partitioning dimensions based on adata sampling method for efficient similarity join processing. Futhermore; a disk-based planesweeping method is proposed to minimize the cost of joins between the partitioned cells.The experimental results show that the proposed schemes substantially improve theperformance of the partition-based similarity joins in high dimensional data spaces.,International Conference on Database and Expert Systems Applications,2002,2
A Quantization Approach for Efficient Similarity Search on Time Series Data,Ines F Vega Lopez; Bongki Moon,Abstract In recent years; we have observed a growing interest in similarity search on largecollections of time series data. The research community has provided ingenious approachesfor solving this problem. Most of the proposals advocate transforming a time series data to asmaller object that can be indexed by a spatial access method. Unfortunately; thesetechniques are not always effective and; in some cases; they can be outperformed by asimple linear scan on the data set. The major problems affecting the performance of thesetechniques are accessing a large portion of the index structure; retrieving a large number ofdata objects to guarantee the correctness of the result; or the combination of both. Asuccessful mechanism for efficient similarity search must therefore minimize both index anddata accesses during search. In this paper; we propose a new encoding strategy for time …,Proceedings of the International Conference on Internet Information Retrieval,*,2
Selective Scan for Filter Operator of SciDB,Sangchul Kim; Seoung Gook Sohn; Taehoon Kim; Jinseon Yu; Bogyeong Kim; Bongki Moon,Abstract Recently there has been an increasing interest in analyzing scientific datagenerated by observations and scientific experiments. For managing these data efficiently;SciDB; a multi-dimensional array-based DBMS; is suggested. When SciDB processes aquery with where predicates; it uses filter operator internally to produce a result array thatmatches the predicates. Most queries for scientific data analysis utilize spatial information.However; filter operator of SciDB reads all data without considering features of array-basedDBMSs and spatial information. In this demo; we present an efficient query processingscheme utilizing characteristics of array-based data; implemented by employingcoordinates. It uses a selective scan that retrieves data corresponding to a range thatsatisfies specific conditions. In our experiments; the selective scan is up to 30x faster than …,Proceedings of the 28th International Conference on Scientific and Statistical Database Management,2016,1
The LSST moving object processing pipeline,Kobus Barnard; Andrew Connolly; Larry Denneau; Alon Efrat; Tommy Grav; Jim Heasley; Robert Jedicke; Jeremy Kubica; Bongki Moon; Scott H Morris; Praveen R Rao,We describe a proposed architecture for the Large Synoptic Survey Telescope (LSST)moving object processing pipeline based on a similar system under development for thePan-STARRS project. This pipeline is responsible for identifying and discovering fastmoving objects such as asteroids; updating information about them; generating appropriatealerts; and supporting queries about moving objects. Of particular interest are potentiallyhazardous asteroids (PHA's). We consider the system as being composed of two interactingcomponents. First; candidate linkages corresponding to moving objects are found bytracking detections (" tracklets"). To achieve this in reasonable time we have developedspecialized data structures and algorithms that efficiently evaluate the possibilities usingquadratic fits of the detections on a modest time scale. For the second component we take …,Observatory Operations: Strategies; Processes; and Systems,2006,1
Quantizing time series for efficient subsequence matching,Inés F Vega-López; Bongki Moon,QUANTIZING TIME SERIES FOR EFFICIENT SUBSEQUENCE MATCHING In´es F. Vega-L´opezSchool of Informatics Autonomous University of Sinaloa Culiac´an; Sinaloa; M´exico email:ifvega@uas.uasnet.mx Bongki Moon Department of Computer Science University of ArizonaTucson; AZ; USA email: bkmoon@cs.arizona.edu ABSTRACT Indexing time series data is aninteresting problem that has attracted much interest in the research community for the lastdecade. Traditional indexing methods organize the data space using different metrics.However; searching high-dimensional spaces using a hierarchical index is not always efﬁcientbecause a large portion of the index might need to be accessed during search. We have revisitedthis problem of matching subsequences in light of new techno- logical advances. Inparticular; we have paid close attention to the increasing ratio of CPU to disk …,Proceedings of the 24th IASTED international conference on Database and applications,2006,1
Approximate tree pattern counts over streaming labeled trees,Praveen Rao; Bongki Moon,Abstract In recent years; there has been a rising interest in developing online approximationalgorithms for data streams. Some of the key challenges are posed by the fact that streamingdata can be read only once in a fixed order of arrival and only a limited amount of memory isavailable for storage. In this paper; we address the problem of approximately counting treepatterns over a stream of labeled trees (eg; XML documents). We propose a newapproximation algorithm called SketchTree that computes a synopsis of the stream in asingle pass by processing each tree only once. Using a limited amount of memory;SketchTree provides approximate answers for both ordered and unordered tree patterncounts.,Technical Report,2004,1
Tie-breaking strategies for fast distance join processing,Hyoseop Shin; Bongki Moon; Sukho Lee,Abstract The distance join is a spatial join that finds pairs of closest objects in the order ofdistance by associating two spatial data sets. The distance join stores node pairs in a priorityqueue; from which node pairs are retrieved while traversing R-trees in top-down manners inthe order of distance. This paper first shows that a priority strategy for the tied pairs in thepriority queue during distance join processing greatly affects its performance. Then itproposes a probabilistic tie-breaking priority method. The experiments show that theproposed method is always better than alternative methods in the performance perspectives.,Data & Knowledge Engineering,2002,1
A Parallel Implementation of a Time-Dependent; Two-Dimensional Flame Model With Detailed Chemistry,G Patnaik; D Fyfe; K Kailasanath; B Moon,*,CHEMICAL AND PHYSICAL PROCESSES IN COMBUSTION,1994,1
Scalable parallel data loading in SciDB,Sangchul Kim; Junhee Lee; Taehoon Kim; Bongki Moon,SciDB is an array-based DBMS popularly used for scientific data analysis. One major hurdlein processing large-scale scientific data is pre-processing before loading data; whichincludes extraneous file conversion from a raw data format to a software-specific format;which causes a significant I/O overhead. Moreover; data loading is typically followed byarray transformation; which requires data to be sorted and redistributed by hashing. In orderto reduce the overhead; we streamline the conversion process and modify the distributionmethod in loading stages. In addition; we eliminate two heavy-duty steps; namely sort andredistribution; which account for a dominant portion of the redimensioning cost. Ourexperiments show that the data loading time can be reduced up to 65% compared with thevanilla loader of SciDB.,Big Data (Big Data); 2017 IEEE International Conference on,2017,*
Memory storage apparatus; method of supporting transaction function for database; and memory system,*,A memory storage apparatus interworking with a database management system and a filesystem includes a flash translation layer (FTL) configured to guarantee atomicity of atransaction for the database management system by utilizing a copy-on-write (CoW)mechanism.,*,2017,*
Supporting Transactional Atomicity in Flash Storage Devices.,Woon-Hak Kang; Sang-Won Lee; Bongki Moon; Gi-Hwan Oh; Changwoo Min,Abstract Flash memory does not allow data to be updated in place; and the copy-on-writestrategy is adopted by most flash storage devices. The copy-on-write strategy in modernFTLs provides an excellent opportunity for offloading the burden of guaranteeing thetransactional atomicity from a host system to flash storage and for supporting atomic updatepropagation. This paper presents X-FTL as a model case of exploiting the opportunity inflash storage to achieve the transactional atomicity in a simple and efficient way. X-FTLdrastically improves the transactional throughput almost for free without resorting to costlyjournaling schemes. We have implemented X-FTL on an SSD development board calledOpenSSD; and modified SQLite and ext4 file system minimally to make them compatiblewith the extended abstractions provided by X-FTL. We demonstrate the effectiveness of X …,IEEE Data Eng. Bull.,2014,*
Bitmap Indexes and Query Processing Strategies for Relational XML Twig Queries,Kyong-Ha Lee; Bong-Ki Moon; Kyu-Chul Lee,Abstract Due to an increasing volume of XML data; it is considered prudent to store XMLdata on an industry-strength database system instead of relying on a domain specificapplication or a file system. For shredded XML data stored in relational tables; however; itmay not be straightforward to apply existing algorithms for twig query processing; since mostof the algorithms require XML data to be accessed in a form of streams of elements groupedby their tags and sorted in a particular order. In order to support XML query processingwithin the common framework of relational database systems; we first propose severalbitmap indexes and their strategies for supporting holistic twig joining on XML data stored inrelational tables. Since bitmap indexes are well supported in most of the commercial andopen-source database systems; the proposed bitmapped indexes and twig query …,Journal of KIISE: Databases,2010,*
FiST: XML Document Filtering by Sequencing Twig Patterns,Joon-Ho Kwon; Praveen Rao; Bong-Ki Moon; Suk-Ho Lee,Abstract In recent years; publish-subscribe (pub-sub) systems based on XML documentfiltering have received much attention. In a typical pub-sub system; subscribing users specifytheir interest in profiles expressed in the XPath language; and each new content is matchedagainst the user profiles so that the content is delivered only to the interested subscribers. Asthe number of subscribed users and their profiles can grow very large; the scalability of thesystem is critical to the success of pub-sub services. In this paper; we propose a novelscalable filtering system called FiST (Filtering by Sequencing Twigs) that transforms twigpatterns expressed in XPath and XML documents into sequences using Prufer's method. Asa consequence; instead of matching linear paths of twig patterns individually and mergingthe matches during post-processing; FiST performs holistic matching of twig patterns with …,Journal of KIISE: Databases,2006,*
XML Indexing and Pattern Matching,Bongki Moon; Praveen R Rao,This book introduces issues and challenges in XML indexing and pattern matching. Sinceextensible markup language XML emerged as a new standard for informationrepresentation and exchange on the Internet; the problem of storing; indexing and queryingXML documents has been among the major issues of database research. The book reviewsstate of the art techniques in indexing; and offers solutions to problems that arise in real-world applications.,*,2006,*
CSc 560: Database Systems Implementation,Bongki Moon,Term project: Students are required to complete a term project in small groups throughoutthe semester. The goal of the project is to build a working but simplified relational databasesystem called MINIREL. The implementation of the MINIREL will be composed of four layersand a transaction manager. Among the four layers; the paged file (PF) layer will be provided;the other layers (heap file (HF); access method (AM); and front-end (FE)) and the transactionmanager (TM) will be implemented by each project team. For each part of the MINIRELproject; students are required to submit an archive of source files that will produce a functionlibrary and/or an executable program; and a short report that will explain the implementationapproach such as overall techniques; important data structures; tricky design decisions; andso on. Reading assignments and Class participation: You are expected to read every …,*,2004,*
Adaptive and Incremental Processing for Distance Join Queries,Bongki Moon; Hyoseop Shin; Sukho Lee,Abstract A spatial distance join is a relatively new type of operation introduced for spatialand multimedia database applications. Additional requirements for ranking and stoppingcardinality are often combined with the spatial distance join in on-line query processing orinternet search environments. These requirements pose new challenges as well asopportunities for more efficient processing of spatial distance join queries. In this paper; wefirst present an efficient k-distance join algorithm that uses spatial indexes such as R-trees.Bi-directional node expansion and plane-sweeping techniques are used for fast pruning ofdistant pairs; and the plane-sweeping is further optimized by novel strategies for selecting asweeping axis and direction. Furthermore; we propose adaptive multi-stage algorithms for k-distance join and incremental distance join operations. Our performance study shows that …,*,2002,*
Proceedings of the ACM SIGMOD International Conference on Management of Data: Madison; Wisconsin; June 3-6; 2002,Michael Franklin; Bongki Moon; Anastassia Ailamaki,*,*,2002,*
Analysis of the Clustering Properties of,Bongki Moon; HV Jagadish; Christos Faloutsos; Joel H Saltz,*,*,1999,*
Parallel Aggregation for Temporal Databases,Bongki Moon; Jose Alvin; Jose Alvin G Gendrano; Minseok Park; Richard T Snodgrass; Bruce C Huang; Jim M Rodrigue,Abstract The ability to model the temporal dimension is essential to many applications.Furthermore; the rate of increase in database size and stringency of response timerequirements has out-paced advancements in processor and mass storage technology;leading to the need for parallel temporal database management systems. In this paper; weintroduce a variety of parallel temporal aggregation algorithms for shared-nothingarchitectures; these algorithms are based on the sequential Aggregation Tree algorithm. Viaan empirical study; we found that the number of processing nodes; the partitioning of thedata; the placement of results; and the degree of data reduction effected by the aggregationimpacted the performance of the algorithms. For distributed result placement; we discoveredthat Greedy Time Division Merge was the obvious choice. For centralized results and high …,*,1999,*
Data placement for high performance spatio-temporal databases,Bongki Moon,Abstract Data clustering and declustering play a role in achieving high performance for large-scale spatio-temporal database applications. The main challenge for efficiently handlingsuch databases is to minimize response time for multidimensional range queries. Forclustering; we have focused on the Hilbert space-filling curve; which provides a locality-preserving mapping from a multidimensional space into a linear space. We present theclustering property of the Hilbert curve in simple closed-form formulas. The second part ofthis research deals with the problem of declustering Cartesian product files over multipledisks. Using the response time of hypercubic range queries as a metric; we have derivedformulas which state the limited scalability and the optimal conditions of two populardeclustering methods.,*,1996,*
AIA A,Robert P Nance; Richard G Wilmoth; Bongki Moon; HA Hassan; Joel Saltz,Abstract This paper describes a parallel implementation of the direct simulation Monte Carlo(DSMC) method. Runtime library support is used for scheduling and execution ofcommunication between nodes; and domain decomposition is performed dynamically tomaintain a good load balance. Performance tests are conducted using the code to evaluatevarious remapping and remapping-interval policies; and it is shown that aone dimensionalchain-partitioning method works best for the problems considered. The parallel code is thenused to simulate the Mach 7.0 nitrogen flow over a finitethickness flat plate. It is shown thatthe parallel algo-rithm produces results which compare well with experi-mental data.Moreover; it yields significantly faster v execution times than the scalar code; as well as verygood load-balance characteristics.,*,1994,*
Skyline Index for Time Series Data,Inés Fernando Vega; Bongki Moon,*,*,*,*
Data Engineering,Hongchan Roh; Sanghyun Park; Mincheol Shin; Sang-Won Lee; Yulei Fan; Wenyu Lai; Xiaofeng Meng; Kwanghyun Park; Yang-Suk Kee; Jignesh M Patel; Jaeyoung Do; Chanik Park; David J DeWitt; Woon-Hak Kang; Bongki Moon; Gi-Hwan Oh; Changwoo Min,Bulletin of the Technical Committee on Data Engineering June 2014 Vol. 37 No. 2 IEEE ComputerSociety Letters Letter from the Editor-in-Chief...................................................... David Lomet 1 Letterfrom the Special Issue Editor................................................ Per-Ake Larson 2 Special Issue on AdaptingDatabase Systems to Flash Storage Search: Multi-Path Search for Tree-based Indexes to ExploitInternal Parallelism of Flash SSDs … Editorial Board Editor-in-Chief DavidB. Lomet Microsoft Research One Microsoft Way Redmond; WA 98052; USA lomet@microsoft. com Associate Editors Juliana Freire Polytechnic Institute of New York University 2MetroTech Center; 10th floor Brooklyn NY 11201-3840 Paul Larson Microsoft Research OneMicrosoft Way Redmond; WA 98052 Sharad Mehrotra Department of Computer Science Universityof California; Irvine Irvine; CA 92697 S. Sudarshan Computer Science and Engineering …,*,*,*
NASA-TM-III? 54,G Patnaik; D Fyfe; K Kailasanath; B Moon; R Bennett; A Sussman; J Saltz,Physical processes in hydrocarbon flames are highly complex and interact in a strongly non-lin-ear fashion. Numerical experimentation is an excellent way to isolate physical processes;study their interactions; or predict important properties such as flammability limits. Onlyhighly detailed models that include complex chemistry and diffusive processes can obtainthe correct flammability limits. To date; sufficiently detailed calculations for hydrocarbonflames have only been carried out for steady-state flames. However; the extinction ofhydrocarbon flames is a multidimensional; transient process. Numerous two-dimensionalcalculations of detailed hydrogen flames[1-3] and some preliminary calculations of transientmethane flames with moderately detailed chemistry have been carried out at the NavalResearch Laboratory[4]. For heavier hydrocarbon fuels; which are of more practical …,*,*,*
A Quantization Approach for Efficient Similarity Search on Time Series Data,Inés Fernando Vega LópezÝ; Bongki Moon,Abstract In recent years; we have observed a growing interest in similarity search on largecollections of time series data. The research community has provided ingenious approachesfor solving this problem. Most of the proposals advocate transforming a time series data to asmaller object that can be indexed by a spatial access method. Unfortunately; thesetechniques are not always effective and; in some cases; they can be outperformed by asimple linear scan on the data set. The major problems affecting the performance of thesetechniques are accessing a large portion of the index structure; retrieving a large number ofdata objects to guarantee the correctness of the result; or the combination of both. Asuccessful mechanism for efficient similarity search must therefore minimize both index anddata accesses during search. In this paper; we propose a new encoding strategy for time …,*,*,*
Main Memory-Based Algorithms for Efficient Parallel Aggregation for Temporal Databases,Dengfeng Gao Jose Alvin G Gendrano; Bongki Moon; Richard T Snodgrass Minseok Park; Bruce C Huang; Jim M Rodrigue,Abstract The ability to model the temporal dimension is essential to many applications.Furthermore; the rate of increase in database size and stringency of response timerequirements has out-paced advancements in processor and mass storage technology;leading to the need for parallel temporal database management systems. In this paper; weintroduce a variety of parallel temporal aggregation algorithms for the sharednothingarchitecture; these algorithms are based on the sequential Aggregation Tree algorithm. Weare particularly interested in developing parallel algorithms that can maximally exploitavailable memory to quickly compute large-scale temporal aggregates without intermediatedisk writes and reads. Via an empirical study; we found that the number of processingnodes; the partitioning of the data; the placement of results; and the degree of data …,*,*,*
