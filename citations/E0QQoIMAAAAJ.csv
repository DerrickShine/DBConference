Querying data under access limitations,Andrea Calì; Davide Martinenghi,Data sources on the web are often accessible through web interfaces that present them asrelational tables; but require certain attributes to be mandatorily selected; eg; via a web form.In a scenario where we integrate a set of such sources; and we pose queries over them; thevalues needed to access a source may have to be retrieved from other sources that arepossibly not even mentioned in the query: answering queries at best can then be done onlywith a potentially recursive query plan that gets all obtainable answers to the query. Sincedata sources are typically distributed over a network; a major cost indicator for the executionof a query plan is the number of accesses to remote sources. In this paper we present anoptimization technique for conjunctive queries that produces a query plan that:(1) minimizesthe number of accesses according to a strong notion of minimality;(2) excludes all …,Data Engineering; 2008. ICDE 2008. IEEE 24th International Conference on,2008,83
Optimization of multi-domain queries on the web,Daniele Braga; Stefano Ceri; Florian Daniel; Davide Martinenghi,Abstract Where can I attend an interesting database workshop close to a sunny beach? Whoare the strongest experts on service computing based upon their recent publication recordand accepted European projects? Can I spend an April weekend in a city served by a low-cost direct flight from Milano offering a Mahler's symphony? We regard the above queries asmulti-domain queries; ie; queries that can be answered by combining knowledge from two ormore domains (such as: seaside locations; flights; publications; accepted projects;conference offerings; and so on). This information is available on the Web; but no general-purpose software system can accept the above queries nor compute the answer. At themost; dedicated systems support specific multi-domain compositions (eg; Google-locallocates information such as restaurants and hotels upon geographic maps). This paper …,Proceedings of the VLDB Endowment,2008,67
On simplification of database integrity constraints,Henning Christiansen; Davide Martinenghi,Abstract Without proper simplification techniques; database integrity checking can beprohibitively time consuming. Several methods have been developed for producingsimplified incremental checks for each update but none until now of sufficient quality andgenerality for providing a true practical impact; and the present paper is an attempt to fill thisgap. On the theoretical side; a general characterization is introduced of the problem ofsimplification of integrity constraints and a natural definition is given of what it means for asimplification procedure to be ideal. We prove that ideality of simplification is strictly relatedto query containment; in fact; an ideal simplification pro-cedure can only exist in databaselanguages for which query containment is decidable. However; simplifications that do notqualify as ideal may also be relevant for practical purposes. We present a concrete …,Fundamenta Informaticae,2006,66
Mashing up search services,Daniele Braga; Stefano Ceri; Florian Daniel; Davide Martinenghi,Mashup languages offer new graphic interfaces for service composition. Normally;composition is limited to simple services; such as RSS or Atom feeds; but users canpotentially use visual mashup languages for complex service compositions; with typedparameters and well-defined I/O interfaces. Composing search services introduces newissues; however; such as determining the optimal sequence of search invocations andseparately composing ranked entries into a globally ranked result. Enabling end users tomash up services through suitable abstractions and tools is a viable option for improvingservice-based computations.,IEEE Internet Computing,2008,62
Top-k bounded diversification,Piero Fraternali; Davide Martinenghi; Marco Tagliasacchi,Abstract This paper investigates diversity queries over objects embedded in a low-dimensional vector space. An interesting case is provided by spatial Web objects; which areproduced in great quantity by location-based services that let users attach content to places;and arise also in trip planning; news analysis; and real estate scenarios. The targetedqueries aim at retrieving the best set of objects relevant to given user criteria and welldistributed over a region of interest. Such queries are a particular case of diversified top-kqueries; for which existing methods are too costly; as they evaluate diversity by accessingand scanning all relevant objects; even if only a small subset is needed. We thereforeintroduce Space Partitioning and Probing (SPP); an algorithm that minimizes the number ofaccessed objects while finding exactly the same result as MMR; the most popular …,Proceedings of the 2012 ACM SIGMOD International Conference on Management of Data,2012,51
Ranking with uncertain scoring functions: semantics and sensitivity measures,Mohamed A Soliman; Ihab F Ilyas; Davide Martinenghi; Marco Tagliasacchi,Abstract Ranking queries report the top-K results according to a user-defined scoringfunction. A widely used scoring function is the weighted summation of multiple scores. Oftentimes; users cannot precisely specify the weights in such functions in order to produce thepreferred order of results. Adopting uncertain/incomplete scoring functions (eg; using weightranges and partially-specified weight preferences) can better capture user's preferences inthis scenario. In this paper; we study two aspects in uncertain scoring functions. The firstaspect is the semantics of ranking queries; and the second aspect is the sensitivity ofcomputed results to refinements made by the user. We formalize and solve multipleproblems under both aspects; and present novel techniques that compute query resultsefficiently to comply with the interactive nature of these problems.,Proceedings of the 2011 ACM SIGMOD International Conference on Management of data,2011,51
Inconsistency-tolerant integrity checking,Hendrik Decker; Davide Martinenghi,All methods for efficient integrity checking require all integrity constraints to be totallysatisfied; before any update is executed. However; a certain amount of inconsistency is therule; rather than the exception in databases. In this paper; we close the gap between theoryand practice of integrity checking; ie; between the unrealistic theoretical requirement of totalintegrity and the practical need for inconsistency tolerance; which we define for integritychecking methods. We show that most of them can still be used to check whether updatespreserve integrity; even if the current state is inconsistent. Inconsistency-tolerant integritychecking proves beneficial both for integrity preservation and query answering. Also; weshow that it is useful for view updating; repairs; schema evolution; and other applications.,IEEE Transactions on Knowledge and Data Engineering,2011,48
Method for extracting; merging and ranking search engine results,*,A method and a computer program product for identifying the domains; selecting for eachdomain one domain-specific search engine and data source to be involved; generating thedomain-specific subqueries for each selected search engine; defining a strategy for sendingrequests to each search engine and data source; and receiving; merging and rankingresults. The result of the multi-domain query is a list of combinations; where everycombination consists of a tuple of data; each relative to one of the domains of the query;such data is present in the results returned either by search engines or by data sources. Themethod provides the combinations having the highest combination score; as computed by amonotone aggregation function over the combinations.,*,2012,38
Integrity checking and maintenance in relational and deductive databases and beyond,Davide Martinenghi; Henning Christiansen; Hendrik Decker,Abstract Integrity constraints are a key tool for characterizing the well-formedness andsemantics of the information contained in databases. In this regard; it is essential thatintelligent database management systems provide their users with automatic support toeffectively and efficiently maintain the semantic correctness of data with respect to the givenintegrity constraints. This chapter gives an overview of the field of efficient integrity checkingand maintenance for relational as well as deductive databases. It covers both theoreticaland practical aspects of integrity control; including integrity maintenance via active rules.New lines of research are outlined;,Intelligent Databases: Technologies and Applications,2006,36
Proximity rank join,Davide Martinenghi; Marco Tagliasacchi,Abstract We introduce the proximity rank join problem; where we are given a set of relationswhose tuples are equipped with a score and a real-valued feature vector. Given a targetfeature vector; the goal is to return the K combinations of tuples with high scores that are asclose as possible to the target and to each other; according to some notion of distance. Thesetting closely resembles that of traditional rank join; but the geometry of the vector spaceplays a distinctive role in the computation of the overall score of a combination. Also; theinput relations typically return their results either by distance from the target or by score.Because of these aspects; it turns out that traditional rank join algorithms; such as the well-known HRJN; have shortcomings in solving the proximity rank join problem; as they mayread more input than needed. To overcome this weakness; we define a tight bound (used …,Proceedings of the VLDB Endowment,2010,32
Querying the deep web,Andrea Calì; Davide Martinenghi,Abstract Data stored outside Web pages and accessible from the Web; typically throughHTML forms; consitute the so-called Deep Web. Such data are of great value; but difficult toquery and search. We survey techniques to optimize query processing on the Deep Web; ina setting where data are represented in the relational model. We illustrate optimizations bothat query plan generation time and at runtime; highlighting the role of integrity constraints. Wediscuss several prototype systems that address the query processing problem.,Proceedings of the 13th International Conference on Extending Database Technology,2010,30
Modeling; measuring and monitoring the quality of information,Hendrik Decker; Davide Martinenghi,Abstract Semantic properties that reflect quality criteria can be modeled by integrityconstraints. Violated instances of constraints may serve as a basis for measuring quality.Such measures also serve for monitoring and controlling quality impairment acrosschanges.,International Conference on Conceptual Modeling,2009,29
Advanced techniques for efficient data integrity checking,Davide Martinenghi,Abstract Integrity constraint checking; understood as the verification of data correctness andwellformedness conditions that must be satisfied in any state of a database; is not fullysupported by current database technology. In a typical scenario; a database is required tocomply with given semantic criteria (the integrity constraints) and to maintain the complianceeach time data are updated. Since the introduction of the SQL2 standard; the SQL languagestarted supporting assertions; which allow one to define general data consistencyrequirements expressing arbitrarily complex “business rules” that may go beyond predefinedconstraints such as primary keys and foreign keys. General integrity constraints are;however; far from being widely available in commercial systems; in fact; their usage iscommonly not encouraged; since the database management system would not be able to …,*,2005,29
Classifying integrity checking methods with regard to inconsistency tolerance,Hendrik Decker; Davide Martinenghi,Abstract We define and examine six classes of methods for integrity checking: case-based;compositional; relevance-based; simplification-based; total-integrity-dependent; andmeasure-based ones. Each; except the penultimate; corresponds to a particular form ofinconsistency tolerance. Inconsistency measures provide a new approach to integritychecking and inconsistency tolerance. For many methods; proofs or disproofs of theirinconsistency tolerance become easier and more transparent by our classification. Ingeneral; a better understanding of inconsistency-tolerant integrity checking is achieved,Proceedings of the 10th international ACM SIGPLAN conference on Principles and practice of declarative programming,2008,27
A relaxed approach to integrity and inconsistency in databases,Hendrik Decker; Davide Martinenghi,Abstract We demonstrate that many; though not all integrity checking methods are able totolerate inconsistency; without having been aware of it. We show that it is possible to usethem to beneficial effect and without further ado; not only for preserving integrity in consistentdatabases; but also in databases that violate their constraints. This apparently relaxedattitude toward integrity and inconsistency stands in contrast to approaches that are muchmore cautious wrt the prevention; identification; removal; repair and tolerance of inconsistentdata that violate integrity. We assess several well-known methods in terms of inconsistencytolerance and give examples and counter-examples thereof.,International Conference on Logic for Programming Artificial Intelligence and Reasoning,2006,26
Dynamic query optimization under access limitations and dependencies,Andrea Calı; Diego Calvanese; Davide Martinenghi,Abstract: Unlike relational tables in a database; data sources on the Web typically can onlybe accessed in limited ways. In particular; some of the source fields may be required asinput and thus need to be mandatorily filled in order to access the source. Answeringqueries over sources with access limitations is a complex task that requires a possiblyrecursive evaluation even when the query is non-recursive. After reviewing the maintechniques for query answering in this context; in this article we consider the impact offunctional and inclusion dependencies on dynamic query optimization under accesslimitations. In particular; we address the implication problem for functional dependenciesand simple full-width inclusion dependencies; and prove that it can be decided inpolynomial time. Then we provide necessary and sufficient conditions; based on the …,Journal of Universal Computer Science,2009,24
Conjunctive query containment under access limitations,Andrea Calì; Davide Martinenghi,Abstract Access limitations may occur when querying data sources over the web orheterogeneous data sources presented as relational tables: this happens; for instance; inData Exchange and Integration; Data Warehousing; and Web Information Systems. Accesslimitations force certain attributes to be selected in order to access the tables. It is known thatevaluating a conjunctive query under such access restrictions amounts to evaluating apossibly recursive Datalog program. We address the problem of checking containment ofconjunctive queries under access limitations; which is highly relevant in query optimization.Checking containment in such a setting would amount to checking containment of recursiveDatalog programs of a certain class; while; for general Datalog programs; this problem isundecidable. We propose a decision procedure for query containment based on the …,International Conference on Conceptual Modeling,2008,22
Crowdsourcing for top-k query processing over uncertain data,Eleonora Ciceri; Piero Fraternali; Davide Martinenghi; Marco Tagliasacchi,Querying uncertain data has become a prominent application due to the proliferation of user-generated content from social media and of data streams from sensors. When dataambiguity cannot be reduced algorithmically; crowdsourcing proves a viable approach;which consists of posting tasks to humans and harnessing their judgment for improving theconfidence about data values or relationships. This paper tackles the problem of processingtop-K queries over uncertain data with the help of crowdsourcing for quickly converging tothe realordering of relevant results. Several offline and online approaches for addressingquestions to a crowd are defined and contrasted on both synthetic and real data sets; withthe aim of minimizing the crowd interactions necessary to find the realordering of the resultset.,IEEE Transactions on Knowledge and Data Engineering,2016,21
Cost-aware rank join with random and sorted access,Davide Martinenghi; Marco Tagliasacchi,In this paper; we address the problem of joining ranked results produced by two or moreservices on the web. We consider services endowed with two kinds of access that are oftenavailable: 1) sorted access; which returns tuples sorted by score; 2) random access; whichreturns tuples matching a given join attribute value. Rank join operators combine objects oftwo or more relations and output the k combinations with the highest aggregate score. Whilethe past literature has studied suitable bounding schemes for this setting; in this paper wefocus on the definition of a pulling strategy; which determines the order of invocation of thejoined services. We propose the Cost-Aware with Random and Sorted access (CARS)pulling strategy; which is derived at compile-time and is oblivious of the query-dependentscore distributions. We cast CARS as the solution of an optimization problem based on a …,IEEE transactions on knowledge and data engineering,2012,21
Top-k diversity queries over bounded regions,Ilio Catallo; Eleonora Ciceri; Piero Fraternali; Davide Martinenghi; Marco Tagliasacchi,Abstract Top-k diversity queries over objects embedded in a low-dimensional vector spaceaim to retrieve the best k objects that are both relevant to given user's criteria and welldistributed over a designated region. An interesting case is provided by spatial Web objects;which are produced in great quantity by location-based services that let users attach contentto places and are found also in domains like trip planning; news analysis; and real estate. Inthis article we present a technique for addressing such queries that; unlike existing methodsfor diversified top-k queries; does not require accessing and scanning all relevant objects inorder to find the best k results. Our Space Partitioning and Probing (SPP) algorithm works byprogressively exploring the vector space; while keeping track of the already seen objectsand of their relevance and position. The goal is to provide a good quality result set in …,ACM Transactions on Database Systems (TODS),2013,19
Querying context-aware databases,Davide Martinenghi; Riccardo Torlone,Abstract In this paper; we propose a logical model and an abstract query language as afoundation of context-aware database management systems. The model is a naturalextension of the relational model in which contexts are first class citizens and can bedescribed at different levels of granularity. This guarantees a smooth implementation of theapproach with current database technology. The query language is an extension ofrelational algebra where special operators allow the specification of queries over contexts.As it happens in practice; contexts in queries and contexts associated with data can be atdifferent granularities: this is made possible by a partial order relationship defined overcontexts. We also study equivalence and rewriting properties of the query language that canbe used for the optimization of context-aware queries.,International Conference on Flexible Query Answering Systems,2009,19
Simplification of integrity constraints with aggregates and arithmetic built-ins,Davide Martinenghi,Abstract In the context of relational as well as deductive databases; correct and efficientintegrity checking is a crucial issue; as; without any guarantee of data consistency; theanswers to queries cannot be trusted. To be of any practical use; any method for integritychecking must support aggregates and arithmetic constraints; which are among the mostwidespread constructs in current database technology. In this paper we propose a method ofpractical relevance that can be used to simplify integrity constraints possibly containingaggregates and arithmetic expressions. Simplified versions of the integrity constraints arederived at database design time and can be tested before the execution of any update. Inthis way; virtually no time is spent for optimization or rollbacks at run time. Both set and bagsemantics are considered.,International Conference on Flexible Query Answering Systems,2004,19
Simplification of integrity constraints for data integration,Henning Christiansen; Davide Martinenghi,Abstract When two or more databases are combined into a global one; integrity may beviolated even when each database is consistent with its own local integrity constraints.Efficient methods for checking global integrity in data integration systems are called for:answers to queries can then be trusted; because either the global database is known to beconsistent or suitable actions have been taken to provide consistent views. The present workgeneralizes simplification techniques for integrity checking in traditional databases to thecombined case. Knowledge of local consistency is employed; perhaps together with given apriori constraints on the combination; so that only a minimal number of tuples needs to beconsidered. Combination from scratch; integration of a new source; and absorption of localupdates are dealt with for both the local-as-view and global-as-view approaches to data …,International Symposium on Foundations of Information and Knowledge Systems,2004,19
Symbolic constraints for meta-logic programming,Henning Christiansen; Davide Martinenghi,Logic programming; with its declarative bias as well as unification and the directrepresentation of linguistic structures; is well qualified for meta-programming; ie; programsworking with representations of other programs as their data. However; constrainttechniques seem necessary in order to fully exploit this paradigm. In the DEMOII system; thelanguage of constraint handling rules (CHRs) has been used in order to provide afunctionality that appears difficult to obtain without such means. For example; reversibility ofa meta-interpreter; which can be obtained by means of constraints; turns it into a powerfulprogram generator; in the same way; negation-as-failure implemented by means ofconstraints provides an incremental evaluation of integrity constraints. This paper focuses onthe design of such constraints and their implementation by means of CHR.,Applied Artificial Intelligence,2000,19
A draw-and-guess game to segment images,Luca Galli; Piero Fraternali; Davide Martinenghi; Marco Tagliasacchi; Jasminko Novak,Human Computation is defined as the integration of human tasks and automated algorithmsto achieve superior quality in complex tasks like multimedia content analysis. This paperdiscusses a scenario in which human computation is used to segment time stamped fashionimages for mining trends based on visual features of garments (eg; color and texture) andattributes of portrayed subjects (eg; gender and age). State-of-the-art algorithms for bodypart detection and feature extraction can produce low quality results when parts of the bodyare occluded and when dealing with complex human poses. In such cases; these algorithmscould benefit from the assistance of human agents. In order to jointly leverage the potentialof crowds and image analysis algorithms; a game with a purpose (GWAP) is proposed;whereby players can help segment images for which specialized algorithms have failed …,Privacy; Security; Risk and Trust (PASSAT); 2012 International Conference on and 2012 International Confernece on Social Computing (SocialCom),2012,18
Fashion-focused creative commons social dataset,Babak Loni; Maria Menendez; Mihai Georgescu; Luca Galli; Claudio Massari; Ismail Sengor Altingovde; Davide Martinenghi; Mark Melenhorst; Raynor Vliegendhart; Martha Larson,Abstract In this work; we present a fashion-focused Creative Commons dataset; which isdesigned to contain a mix of general images as well as a large component of images thatare focused on fashion (ie; relevant to particular clothing items or fashion accessories). Thedataset contains 4810 images and related metadata. Furthermore; a ground truth on image'stags is presented. Ground truth generation for large-scale datasets is a necessary butexpensive task. Traditional expert based approaches have become an expensive and non-scalable solution. For this reason; we turn to crowdsourcing techniques in order to collectground truth labels; in particular we make use of the commercial crowdsourcing platform;Amazon Mechanical Turk (AMT). Two different groups of annotators (ie; trusted annotatorsknown to the authors and crowdsourcing workers on AMT) participated in the ground truth …,Proceedings of the 4th ACM Multimedia Systems Conference,2013,17
A Framework for Crowdsourced Multimedia Processing and Querying.,Alessandro Bozzon; Ilio Catallo; Eleonora Ciceri; Piero Fraternali; Davide Martinenghi; Marco Tagliasacchi; M Tagliasacchi,ABSTRACT This paper introduces a conceptual and architectural framework for addressingthe design; execution and verification of tasks by a crowd of performers. The proposedframework is substantiated by an ongoing application to a problem of trademark logodetection in video collections. Preliminary results show that the contribution of crowds canimprove the recall of state-of-the-art traditional algorithms; with no loss in terms of precision.However; task-to-executor matching; as expected; has an important influence on the taskperformance.,CrowdSearch,2012,17
Querying incomplete data over extended er schemata,Andrea CalÌ; Davide Martinenghi,Abstract Since Chen's Entity-Relationship (ER) model; conceptual modeling has beenplaying a fundamental role in relational data design. In this paper we consider an extendedER (EER) model enriched with cardinality constraints; disjointness assertions; and is arelations among both entities and relationships. In this setting; we consider the case ofincomplete data; which is likely to occur; for instance; when data from different sources areintegrated. In such a context; we address the problem of providing correct answers toconjunctive queries by reasoning on the schema. Based on previous results aboutdecidability of the problem; we provide a query answering algorithm that performs rewritingof the initial query into a recursive Datalog query encoding the information about theschema. We finally show extensions to more general settings.,Theory and Practice of Logic Programming,2010,17
Avenues to flexible data integrity checking,Hendrik Decker; Davide Martinenghi,Traditional methods for integrity checking in relational or deductive databases heavily relyon the assumption that data have integrity before the execution of updates. In this way; ashas always been claimed; one can automatically derive strategies to check; in anincremental way; whether data preserve their integrity after the update. On the other hand;this consistency assumption greatly reduces applicability of such methods; since it is mostoften the case that small parts of a database do not comply with the integrity constraints;especially when the data are distributed or have been integrated from different sources. Inthis paper; we revisit integrity checking from an inconsistency-tolerant viewpoint. We showthat most methods for integrity checking (though not all) are still applicable in the presenceof inconsistencies and may be used to guarantee that the satisfied instances of the …,Database and Expert Systems Applications; 2006. DEXA'06. 17th International Workshop on,2006,14
Transaction management with integrity checking,Davide Martinenghi; Henning Christiansen,Abstract Database integrity constraints; understood as logical conditions that must hold forany database state; are not fully supported by current database technology. It is typically upto the database designer and application programmer to enforce integrity via triggers or testsat the application level; which are difficult to maintain and error prone. Two importantaspects must be taken care of. 1. It is too time consuming to check integrity constraints fromscratch after each update; so simplified checks before each update should be used relyingon the assumption that the current state is consistent. 2. In concurrent database systems;besides the traditional correctness criterion; the execution schedule must ensure that thedifferent transactions can overlap in time without destroying the consistency requirementstested by other; concurrent transactions. We show in this paper how to apply a method for …,International Conference on Database and Expert Systems Applications,2005,14
Getting rid of straitjackets for flexible integrity checking,Hendrik Decker; Davide Martinenghi,Various requirements that usually are imposed on data; constraints; updates and methodsfor checking the integrity of databases can be perceived as inflexible straitjackets. We showthat such restrictions can be notably relaxed or even completely abandoned withoutforfeiting any major advantage. On the contrary; a significant amount of flexibility is gainedby relaxing or abandoning several established prerequisites for integrity checking.,Database and Expert Systems Applications; 2007. DEXA'07. 18th International Workshop on,2007,13
Taxonomy-based relaxation of query answering in relational databases,Davide Martinenghi; Riccardo Torlone,Abstract Traditional information search in which queries are posed against a known andrigid schema over a structured database is shifting toward a Web scenario in which exposedschemas are vague or absent and data come from heterogeneous sources. In thisframework; query answering cannot be precise and needs to be relaxed; with the goal ofmatching user requests with accessible data. In this paper; we propose a logical model anda class of abstract query languages as a foundation for querying relational data sets withvague schemas. Our approach relies on the availability of taxonomies; that is; simpleclassifications of terms arranged in a hierarchical structure. The model is a natural extensionof the relational model in which data domains are organized in hierarchies; according todifferent levels of generalization between terms. We first propose a conservative …,The VLDB Journal,2014,12
A simplification procedure for integrity constraints,D Martinenghi,*,World Wide Web; http://www. dat. ruc. dk/dm/spic/index. html,2003,11
Querying databases with taxonomies,Davide Martinenghi; Riccardo Torlone,Abstract Traditional information search in which queries are posed against a known andrigid schema over a structured database is shifting towards a Web scenario in whichexposed schemas are vague or absent and data comes from heterogeneous sources. In thisframework; query answering cannot be precise and needs to be relaxed; with the goal ofmatching user requests with accessible data. In this paper; we propose a logical model andan abstract query language as a foundation for querying data sets with vague schemas. Ourapproach takes advantages of the availability of taxonomies; that is; simple classifications ofterms arranged in a hierarchical structure. The model is a natural extension of the relationalmodel in which data domains are organized in hierarchies; according to different levels ofgeneralization. The query language is a conservative extension of relational algebra …,International Conference on Conceptual Modeling,2010,10
A logical approach to context-aware databases,Davide Martinenghi; Riccardo Torlone,Abstract Context awareness is an enabling technology of ubiquitous computing aimed atutilizing the location; the time; and other properties that characterize the context of use toselect the information that is most appropriate to final users. Although it is widely considereda fundamental ability of modern applications; current database technology does not provideany support to context awareness yet. In this paper; we propose a logical model and anabstract query language as a foundation for context-aware database management systems.The model is a natural extension of the relational model in which contexts are first classcitizens and can be described at different levels of granularity. This guarantees a smoothimplementation of the approach with current database technology. The query language is aconservative extension of relational algebra where special operators allow the …,*,2010,10
Rank-join algorithms for search computing,Ihab F Ilyas; Davide Martinenghi; Marco Tagliasacchi,Abstract Joins represent the basic functional operations of complex query plans in a SearchComputing system; as discussed in the previous chapter. In this chapter we provide furtherinsight on this matter; by focusing on algorithms that deal with joining ranked resultsproduced by search services. We cast this problem as a generalization of the traditional rankaggregation problem; ie; combining several ranked lists of objects to produce a singleconsensus ranking. Rank-join algorithms; also called top-k join algorithms; aim atdetermining the best overall results without accessing all the objects. The rank-join problemhas been dealt with in the literature by extending rank aggregation algorithms to the case ofjoin in the setting of relational databases. However; previous approaches to top-k queriesdid not consider some of the distinctive features of search engines on the Web. Indeed; as …,*,2010,10
The CUBRIK project: human-enhanced time-aware multimedia search,Piero Fraternali; Marco Tagliasacchi; Davide Martinenghi; Alessandro Bozzon; Ilio Catallo; Eleonora Ciceri; Francesco Nucci; Vincenzo Croce; Ismail Sengor Altingovde; Wolf Siberski; Fausto Giunchiglia; Wolfgang Nejdl; Martha Larson; Ebroul Izquierdo; Petros Daras; Otto Chrons; Ralph Traphoener; Bjoern Decker; John Lomas; Patrick Aichroth; Jasminko Novak; Ghislain Sillaume; F Sanchez Figueroa; Carolina Salas-Parra,Abstract The Cubrik Project is an Integrated Project of the 7th Framework Programme thataims at contributing to the multimedia search domain by opening the architecture ofmultimedia search engines to the integration of open source and third party contentannotation and query processing components; and by exploiting the contribution of humansand communities in all the phases of multimedia search; from content processing to queryprocessing and relevance feedback processing. The CUBRIK presentation will showcasethe architectural concept and scientific background of the project and demonstrate an initialscenario of human-enhanced content and query processing pipeline.,Proceedings of the 21st International Conference on World Wide Web,2012,9
Proximity measures for rank join,Davide Martinenghi; Marco Tagliasacchi,Abstract We introduce the proximity rank join problem; where we are given a set of relationswhose tuples are equipped with a score and a real-valued feature vector. Given a targetfeature vector; the goal is to return the K combinations of tuples with high scores that are asclose as possible to the target and to each other; according to some notion of distance ordissimilarity. The setting closely resembles that of traditional rank join; but the geometry ofthe vector space plays a distinctive role in the computation of the overall score of acombination. Also; the input relations typically return their results either by distance from thetarget or by score. Because of these aspects; it turns out that traditional rank join algorithms;such as the well-known HRJN; have shortcomings in solving the proximity rank join problem;as they may read more input than needed. To overcome this weakness; we define a tight …,ACM Transactions on Database Systems (TODS),2012,9
Search Computing: Managing complex search queries,Stefano Ceri; Adnan Abid; Mamoun Abu Helou; Davide Barbieri; Alessandro Bozzon; Daniele Braga; Marco Brambilla; Alessandro Campi; Francesco Corcoglioniti; Emanuele Della Valle; Davide Eynard; Piero Fraternali; Michael Grossniklaus; Davide Martinenghi; Stefania Ronchi; Marco Tagliasacchi; Salvatore Vadacca,Search computing focuses on building answers to complex search queries (for example;"Where can I attend an interesting conference in my field near a sunny beach?") byinteracting with a constellation of cooperating search services; and using result ranking andjoining as the dominant factors for service composition. The service computing paradigmhas so far been neutral to the specific features of search applications and services. Toaddress this weakness; search computing advocates a new approach in which search; join;and ranking are the central aspects for service composition.,IEEE Internet Computing,2010,9
NGS: a framework for multi-domain query answering,Daniele Braga; Diego Calvanese; Alessandro Campi; Stefano Ceri; Florian Daniel; Davide Martinenghi; Paolo Merialdo; Riccardo Torlone,If we consider a query involving multiple domains; such as" find all database conferencesheld within six months in locations whose seasonal average temperature is 28degC and forwhich a cheap travel solution exists"; we note that (i) general-purpose search engines fail toanswer multi-domain queries and (ii) specific search services may cover one of suchdomains; but no general integration framework is readily available. Currently; the only wayto treat such cases is to separately query dedicated services and feed the result of onesearch as input to another; or to pairwise compare them by hand. This paper presents NGS;a framework providing fully automated support for cross-domain queries. In particular; NGS(a) integrates different kinds of services (search engines; web services; and wrapped webpages) into a global ontology; ie; a unified view of the concepts supported by the …,Data Engineering Workshop; 2008. ICDEW 2008. IEEE 24th International Conference on,2008,9
Building social graphs from images through expert-based crowdsourcing,Marcello Dionisio; Piero Fraternali; Erik Harloff; Davide Martinenghi; Isabel Micheel; Jasminko Novak; Chiara Pasini; M Tagliasacchi; S Zagorac,Human computation is an approach to problem solving that integrates the computationalpower of machines with the perceptual; rational or social contribution of humans (Quinn andBederson 2011). It can be applied to the resolution of distributed problems where neither thecapability of machines nor that of humans alone suffice. One such problem is the detectionof objects in images; for which machine algorithms still fail to provide a generalpurposesolution with high accuracy. Even the detection of faces and the recognition of face similarity;two of the tasks for which automated solutions grant good precision and recall; leave spaceto further improvement; because common algorithms typically work well under rathercontrolled conditions; most notably frontal face images and constraints on the minimum andmaximum resolution.,Proceedings of the International Workshop on Social Media for Crowdsourcing and Human Computation; Paris,2013,8
Top-k pipe join,Davide Martinenghi; Marco Tagliasacchi,In the context of service composition and orchestration; service invocation is typicallyscheduled according to execution plans; whose topology establishes whether differentservices are to be invoked in parallel or in a sequence. In the latter case; we may have aconfiguration; called pipe join; in which the output of a service is used as input for anotherservice. When the services involved in a pipe join output results sorted by score; the problemarises of efficiently determining the join tuples (aka combinations) with the highest combinedscores. In this paper we study different execution strategies related to the pipe joinconfiguration. First; we consider a strategy that minimizes the access costs to achieve atarget number of combinations. Then; we propose a strategy that explicitly considers thescores of the output tuples in order to provide deterministic guarantees that the top-k …,Data Engineering Workshops (ICDEW); 2010 IEEE 26th International Conference on,2010,8
Optimization of query plans in the presence of access limitations,Andrea Calı; Diego Calvanese; Davide Martinenghi,Abstract. We consider the problem of querying data sources that have limited capabilitiesand can thus only be accessed by complying with certain binding patterns for their attributes.This is often the case; eg; in the context of data on the web queryable via web forms as wellas in legacy data wrapped in relational tables. In such contexts; computing the answer to auser query cannot be done as in a traditional database; instead; a query plan is needed thattakes the access limitations into account. In this paper; we develop a technique forproducing a (possibly recursive) Datalog program that retrieves all obtainable answers for aquery with limited source capabilities. In particular; we improve with respect to a previouslypublished algorithm for optimizing query answering for conjunctive queries. Furthermore; weextend it to the context of unions of conjunctive queries. The algorithm exploits the …,EROW,2007,8
Incremental integrity checking: Limitations and possibilities,Henning Christiansen; Davide Martinenghi,Abstract Integrity checking is an essential means for the preservation of the intendedsemantics of a deductive database. Incrementality is the only feasible approach to checkingand can be obtained with respect to given update patterns by exploiting query optimizationtechniques. By reducing the problem to query containment; we show that no procedureexists that always returns the best incremental test (aka simplification of integrity constraints);and this according to any reasonable criterion measuring the checking effort. In spite of thistheoretical limitation; we develop an effective procedure allowing general parametricupdates that; for given database classes; returns ideal simplifications and also applies torecursive databases. Finally; we point out the improvements with respect to previousmethods based on an experimental evaluation.,International Conference on Logic for Programming Artificial Intelligence and Reasoning,2005,8
Efficient integrity checking for databases with recursive views,Davide Martinenghi; Henning Christiansen,Abstract Efficient and incremental maintenance of integrity constraints involving recursiveviews is a difficult issue that has received some attention in the past years; but for which nowidely accepted solution exists yet. In this paper a technique is proposed for compiling suchintegrity constraints into incremental and optimized tests specialized for given updatepatterns. These tests may involve the introduction of new views; but for relevant cases ofrecursion; simplified integrity constraints are obtained that can be checked more efficientlythan the original ones and without auxiliary views. Notably; these simplified tests are derivedat design time and can be executed before the particular database update is made andwithout simulating the updated state. In this way all overhead due to optimization orexecution of compensative actions at run time is avoided. It is argued that; in the recursive …,East European Conference on Advances in Databases and Information Systems,2005,8
Database integrity checking,Hendrik Decker; Davide Martinenghi,Integrity constraints (or simply “constraints”) are formal representations of invariantconditions for the semantic correctness of database records. Constraints can be expressedin declarative languages such as datalog; predicate logic; or SQL. This article highlights thehistorical background of integrity constraints and the essential features of their simplifiedincremental evaluation. It concludes with an outlook on future trends.,Database Technologies: Concepts; Methodologies; Tools; and Applications: Concepts; Methodologies; Tools; and Applications,2009,7
Monitoring the Quality of Information,Hendrik Decker; Davide Martinenghi,*,Proceedings of the ER,2009,6
On using simplification and correction tables for integrity maintenance in integrated databases,Henning Christiansen; Davide Martinenghi,When a database is defined as views over autonomous sources; inconsistencies withrespect to global integrity constraints are to be expected. This paper investigates thepossibility of using simplification techniques for integrity constraints in order to maintain; inan incremental way; a correction table of virtual updates which; if executed; would restoreconsistency; access can be made through auxiliary views that take the table into account.The approach employs assumptions about local source consistency as well as cross-sourceconstraints whenever possible,Database and Expert Systems Applications; 2006. DEXA'06. 17th International Workshop on,2006,6
Common framework for representing ontologies,Diego Calvanese; B Cuenca Grau; Giuseppe De Giacomo; Enrico Franconi; Ian Horrocks; Alissa Kaplunova; Domenico Lembo; Maurizio Lenzerini; Carsten Lutz; Davide Martinenghi; Ralf Möller; Riccardo Rosati; Sergio Tessaris; Anni-Yasmin Turhan,Abstract In this document; we present the general framework for the representation ofontologies that has been designed within tones as a semantic infrastructure capturing thedifferent formalizations of ontologies as well as their services and the different contexts inwhich ontologies are used. Then; we illustrate several meaningful instantiations of theframework through ontology based formalisms that have been proposed recently in theliterature. Some of these instantiations constitute themselves significant contributions interms of logic-based ontology formalisms that have been developed within the tonesconsortium; and that have been presented recently at high quality scientific venues. c2006/TONES–August. 25; 2006 1/68 TONES-D08–v. 2.1,Deliverable TONES-DO8,2006,6
Integrity Checking for Uncertain Data.,Hendrik Decker; Davide Martinenghi,ABSTRACT The uncertainty associated to stored information can be put in directcorrespondence to the extent to which these data violate conditions expressed as semanticintegrity constraints. Thus; imposing and checking such constraints provides a better controlover uncertain data. We present and discuss a condition which ensures the violationtolerance of methods for integrity checking. Usually; such methods are supposed to workcorrectly only if all constraints are satisfied before each update. Applied to express andcheck conditions about uncertain data; violation tolerance means that stored data theuncertainty of which violates integrity can be tolerated while updates can be safely checkedfor introducing violations of constraints about uncertainty. We also discuss the soundnessand completeness of violation-tolerant integrity checking and assert it for several methods.,TDM,2006,6
Exploiting user generated content for mountain peak detection,Fedorov Roman; Martinenghi Davide; Tagliasacchi Marco; Castelletti Andrea,Recently the Web has become a publishing platform of massive user personal mediacontent; mostly photographs and videos. User generated content has been exploited as aform of “passive human computation”; in which the collective intelligence of a large group ofusers is harnessed for the resolution of complex tasks (Quinn and Bederson 2011). In thisarticle we present a collective intelligence application from user-generated photographs;which relies on the fact that nowadays many photographs are geo-tagged to predictenvironmental variables. The availability of geo-tags in photos results from two currenttrends: first; the widespread habit of using the smartphone as a photo camera; second; theincreasing number of digital cameras with an integrated GPS locator and Wi-Fi module. Theimpact of these two factors is that more and more personal photographs are being …,2nd International Workshop on Social Media for Crowdsourcing and Human Computation (SoHuman 2013),2013,5
Access pattern,Davide Martinenghi,Background Limitations in the way in which relations can be accessed were originallystudied in the mid-1980s in the context of logic programs with (input or output) accessmodes [4]. A more thorough analysis of query processing issues involving relations withaccess patterns has emerged within the field of information integration during the 1990s [6;7; 14; 16].,*,2011,5
Optimal Database Locks for Efficient Integrity Checking.,Davide Martinenghi,Abstract. In concurrent database systems; correctness of update transactions refers to theequivalent effects of the execution schedule and some serial schedule over the same set oftransactions. Integrity constraints add further semantic requirements to the correctness of thedatabase states reached upon the execution of update transactions. Several methods forefficient integrity checking and enforcing exist. We show in this paper how to apply one suchmethod to automatically extend update transactions with locks and simplified consistencytests on the locked entities. All schedules produced in this way are conflict serializable andpreserve consistency. For certain classes of databases we also guarantee that the amount oflocked database entities is minimal.,ADBIS (Local Proceedings),2004,5
Context-aware data tailoring through answer set programming,Angelo Rauseo; Davide Martinenghi; Letizia Tanca,Abstract. In this paper we describe a technique for context-aware data tailoring by means ofAnswer Set Programming (ASP). We use ASP techniques to describe and generate thefeasible contexts compatible with a context specification structure called Context DimensionTree. We define suitable context-dependent views that; as soon as a specific feasiblecontext is selected; retain only those data that are meaningful with respect to the context.,SEBD,2011,4
Context through answer set programming,Angelo Rauseo; Davide Martinenghi; Letizia Tanca,Abstract In a world of global networking; the variety and abundance of information generatesthe need for effectively and efficiently gathering; synthesizing; and querying the availabledata while removing information noise. The concept of context has been developed andrefined since the first approaches to ubiquitous computing [3]; the research area ofeverywhere computing systems; which has the objective to provide help and information tousers in an almost imperceptible way. At first; the idea of context was limited to time andlocation; later it was extended also to the other external environmental factors; current trendsand phenomena that may change or influence the information and services available to auser. In this work; we refer to context primarily in relation with the effects that this notion hasover data. A system where context awareness is integrated with--yet orthogonal to--data …,Proceedings of the 4th International Workshop on Logic in Databases,2011,4
A model and a language for context-aware databases,Davide Martinenghi; Riccardo Torlone,ABSTRACT Context awareness is an enabling technology of ubiquitous computing aimed atutilizing the location; the time; and other properties that characterize the context of use toselect the information that is most appropriate to final users. Although it is widely considereda fundamental ability of modern applications; current database technology does not providea support to context awareness yet. In this paper; we propose a logical model and anabstract query language as a foundation for context-aware database management systems.The model is a natural extension of the relational model in which contexts are first classcitizens and can be described at different levels of granularity. This guarantees a smoothimplementation of the approach with current database technology. The query language is aconservative extension of relational algebra where special operators allow the …,Dip. di Elettronica e Informazione; Politecnico di Milano; Italy; Tech. Rep,2009,4
Query optimisation for web data sources: minimisation of the number of accesses,Andrea Calı; Davide Martinenghi; Domenico Carbotta,Abstract. When relational data have access constraints that require certain attributes to beselected in queries; as in the case of (wrapped) Web sources accessible via forms; arecursive query plan is needed to answer queries at best. We present a query planoptimisation technique for several classes of queries that minimises the number of accessesaccording to a novel; strong notion of minimality. We provide experimental evidence of theeffectiveness of our technique.,Proceedings of the Fifteenth Italian Symposium on Advanced Database Systems; SEBD,2007,4
Checking violation tolerance of approaches to database integrity,Hendrik Decker; Davide Martinenghi,Abstract A hitherto unquestioned assumption made by all methods for integrity checking hasbeen that the database satisfies its constraints before each update. This consistencyassumption has been exploited for improving the efficiency of determining whether integrityis satisfied or violated after the update. Based on a notion of violation tolerance; we presentand discuss an abstract property which; for any given approach to integrity checking; is aneasy; sufficient condition to check whether the consistency assumption can be abandonedwithout sacrificing usability and efficiency of the approach. We demonstrate the usefulnessof our definitions by showing that the theorem-proving approach to database integrity bySadri and Kowalski; as well as several other well-known methods; can indeed afford toabandon the consistency assumption without losing their efficiency; while their …,International Conference on Advances in Information Systems,2006,4
Efficient integrity checking over XML documents,Daniele Braga; Alessandro Campi; Davide Martinenghi,Abstract The need for incremental constraint maintenance within collections of semi-structured documents has been ever increasing in the last years due to the widespreaddiffusion of XML. This problem is addressed here by adapting to the XML data model someconstraint verification techniques known in the context of deductive databases. Ourapproach allows the declarative specification of constraints as well as their optimization wrtgiven update patterns. Such optimized constraints are automatically translated intoequivalent XQuery expressions in order to avoid illegal updates. This automatic processguarantees an efficient integrity checking that combines the advantages of declarativity withincrementality and early detection of inconsistencies.,International Conference on Extending Database Technology,2006,4
Keyword queries over the deep web,Andrea Calì; Davide Martinenghi; Riccardo Torlone,Abstract The Deep Web is constituted by data that are accessible through Web pages; butnot indexable by search engines as they are returned in dynamic pages. In this paper wepropose a conceptual framework for answering keyword queries on Deep Web sourcesrepresented as relational tables with so-called access limitations. We formalize the notion ofoptimal answer and characterize queries for which an answer can be found.,International Conference on Conceptual Modeling,2016,3
Champagne: a web tool for the execution of crowdsourcing campaigns,Carlo Bernaschina; Ilio Catallo; Piero Fraternali; Davide Martinenghi; Marco Tagliasacchi,Abstract We present Champagne; a web tool for the execution of crowdsourcing campaigns.Through Champagne; task requesters can model crowdsourcing campaigns as a sequenceof choices regarding different; independent crowdsourcing design decisions. Such decisionsinclude; eg; the possibility of qualifying some workers as expert reviewers; or of combiningdifferent quality assurance techniques to be used during campaign execution. In this regard;a walkthrough example showcasing the capabilities of the platform is reported. Moreover;we show that our modular approach in the design of campaigns overcomes many of thelimitations exposed by the major platforms available in the market.,Proceedings of the 24th International Conference on World Wide Web,2015,3
On the difference between checking integrity constraints before or after updates,Davide Martinenghi,Abstract: Integrity checking is a crucial issue; as databases change their instance all the timeand therefore need to be checked continuously and rapidly. Decades of research haveproduced a plethora of methods for checking integrity constraints of a database in anincremental manner. However; not much has been said about when to check integrity. In thispaper; we study the differences and similarities between checking integrity before an update(aka pre-test) or after (aka post-test) in order to assess the respective convenience andproperties.,arXiv preprint arXiv:1312.2353,2013,3
Dealing with the Deep Web and all its Quirks.,Meghyn Bienvenu; Daniel Deutch; Davide Martinenghi; Pierre Senellart; Fabian M Suchanek,ABSTRACT Several approaches harvest; query; or combine Deep Web sources. Yet; inaddition to well-studied aspects of the problem such as query answering using views;access limitations; or top-k querying; the Deep Web exhibits a number of peculiarities thatare often neglected. First; the services usually deliver not all results; but only the top-nresults according to some ranking function. This function may not be compatible with theordering specified in a user's query. Subsequent results have to be obtained by paging; ormay not even be accessible. Second; the services may deliver results in a granularity that isincompatible with the query or joinable services (eg; months vs. exact dates). Moreover; theservices may perform selections or ranking over attributes that are not exposed in theresults: this poses an incompleteness problem. Additional challenges come from …,VLDS,2012,3
Efficient Diversification of Top-k Queries over Bounded Regions.,Piero Fraternali; Davide Martinenghi; Marco Tagliasacchi,Abstract. This paper reports on recent findings regarding diversity queries over objectsembedded in a low-dimensional vector space. Among the many contexts of interest; wemention spatial Web objects; which are abundant in location-based services that let usersattach content to places. Typical queries aim at retrieving the best set of relevant objects thatare well distributed over a region of interest. Existing methods for answering diversified top-kqueries are too costly; as they evaluate diversity by accessing and scanning all relevantobjects; even if only a small subset thereof is needed. Our proposal; named SPP; is analgorithm that; while finding exactly the same result as MMR (one of the most populardiversification algorithms); does not require retrieving all the relevant objects and; indeed;minimizes the number of accessed objects. Experiments confirm that SPP saves a …,SEBD,2012,3
Search computing systems,Stefano Ceri; Marco Brambilla,Abstract Search Computing defines a new class of applications; which enable end users toperform exploratory search processes over multi-domain data sources available on the Web.These applications exploit suitable software frameworks and models that make it possiblefor expert users to configure the data sources to be searched and the interfaces for querysubmission and result visualization. We describe some usage scenarios and the referencearchitecture for Search Computing systems.,International Conference on Advanced Information Systems Engineering,2010,3
Activexqbe: A visual paradigm for triggers over xml data,Daniele Braga; Alessandro Campi; Davide Martinenghi; Alessandro Raffio,Abstract While XQuery is becoming a standard; the W3C is currently discussing the featuresof an update language for XML; and its requirements. Therefore; time is ripe for designingand defining the language features and extensions that are usually needed when updatesare supported: reaction policies to constraint violations; business rules; and more. In the pastyears; several languages have been proposed for updates as well as for triggers in XML;such as XUpdate and Active XQuery. In this paper; we propose a visual approach to theformulation of active rules building on XQBE; a graphical query language for XML data. Ourapproach is motivated by the need to provide unskilled users with the ability to expressbusiness rules in an intuitive fashion. Visual triggers are then translated into statements thatcan be interpreted by query engines.,International Conference on Extending Database Technology,2006,3
Can Integrity Tolerate Inconsistency?,Hendrik Decker; Davide Martinenghi,Abstract. An unconditional and hitherto unquestioned basic requirement for integritychecking is that the data need to be consistent before the update; such that the success of asimplified test can guarantee the invariance of integrity after the update. We answer thequestion whether this consistency requirement can be relaxed with” Yes; at least sometimes;and to some extent.”,SEBD,2006,3
A workload-dependent task assignment policy for crowdsourcing,Ilio Catallo; Stefano Coniglio; Piero Fraternali; Davide Martinenghi,Abstract Crowdsourcing marketplaces have emerged as an effective tool for high-speed; low-cost labeling of massive data sets. Since the labeling accuracy can greatly vary from workerto worker; we are faced with the problem of assigning labeling tasks to workers so as tomaximize the accuracy associated with their answers. In this work; we study the problem ofassigning workers to tasks under the assumption that workers' reliability could changedepending on their workload; as a result of; eg; fatigue and learning. We offer empiricalevidence of the existence of a workload-dependent accuracy variation among workers; andpropose solution procedures for our Crowdsourced Labeling Task Assignment Problem;which we validate on both synthetic and real data sets.,World Wide Web,2017,2
Keyword search in the deep web,Andrea Calì; Davide Martinenghi; Riccardo Torlone,The Deep Web is constituted by data accessible through Web pages; but not readilyindexable by search engines; as they are returned in dynamic pages. In this paper wepropose a framework for accessing Deep Web sources; represented as relational tables withso-called ac-cess limitations; with keyword-based queries. We formalize the notion ofoptimal answer and investigate methods for query processing. To our knowledge; thisproblem has never been studied in a systematic way.,CEUR Workshop Proceedings,2015,2
Robust aggregation of GWAP tracks for local image annotation,Carlo Bernaschina; Piero Fraternali; Luca Galli; Davide Martinenghi; Marco Tagliasacchi,Abstract The possibility of assigning labels to localized regions in an image enables flexibleimage retrieval paradigms. However; the process of automatically segmenting and taggingimages is notoriously hard; due to the presence of occlusions; noise; challengingillumination conditions; background clutter; etc. For this reason; human computation hasrecently emerged as a viable alternative when computer vision algorithms fail to provide asatisfactory answer. For example; Games with a purpose (GWAP) represent a powerfulcrowdsourcing mechanism to collect implicit annotations from human players. In this paperwe consider the problem of aggregating the gaming tracks collected by a GWAP wedeveloped to solve challenging instances of image segmentation problems. In particular weconsider the existence of malicious players; who might try to fool the rules of the game to …,Proceedings of International Conference on Multimedia Retrieval,2014,2
Logic in databases: report on the LID 2008 workshop,Andrea Calì; Laks VS Lakshmanan; Davide Martinenghi,Andrea Calì Oxford-Man Institute of Quantitative Finance University of Oxford WolfsonBuilding; Parks Road Oxford OX1 3QD United Kingdom andrea.cali@comlab.ox.ac.uk … LaksVS Lakshmanan Dept. of Computer Science University of British Columbia 2366 Main MallVancouver; BC Canada V6T 1Z4 laks@cs.ubc.ca … Davide Martinenghi Dip. di Elettr. e InformazionePolitecnico di Milano Via Ponzio; 34/5 I-20133 Milano Italy martinen@elet.polimi.it … 1. INTRODUCTIONThe Logic in Databases (LID'08) workshop was held at the DIS department of “La Sapienza”university; Rome; Italy; between May 19-20; 2008 … LID'08 was established as a forum for bringingtogether re- searchers and practitioners; from the academia and the in- dustry; who are focusingon all logical aspects of data man- agement … LID'08 was a confluence of three successfulpast events … • LID'96; an international workshop on Logic in Databases; which LID'08 …,ACM SIGMOD Record,2010,2
Selected papers from the Logic in Databases Workshop 2008,Andrea Calì; Laks VS Lakshmanan; Davide Martinenghi,*,*,2010,2
Querying the Deep Web: Back to the Foundations,Andrea Calı; Davide Martinenghi; Igor Razgon; Martın Ugarte,Abstract. The Deep Web is the large corpus of data accessible on the Web through formsand presented in dynamically-generated pages; but not indexable as static pages; andtherefore invisible to search engines. Deep Web data are usually modelled as relations withso-called access limitations; that is; they can be queried only by selecting certain attributes.In this paper we give some fundamental complexity results on the problem of processingconjunctive (select-project-join) queries on relational data with access limitations.,Proc. of AMW,2017,1
On the role of task design in crowdsourcing campaigns,Carlo Bernaschina; Ilio Catallo; Piero Fraternali; Davide Martinenghi,Abstract Despite the success of crowdsourcing marketplaces; fully harnessing their massiveworkforce remains challenging. In this work we study the effect on crowdsourcing campaignsof different feedback and payment strategies. Our results reveal the joint effect of feedbackand payment on the quality and quantity of the outcome.,Third AAAI Conference on Human Computation and Crowdsourcing,2015,1
On the dependency on the size of the data when chasing under conceptual dependencies,Davide Martinenghi,Abstract: Conceptual dependencies (CDs) are particular kinds of key dependencies (KDs)and inclusion dependencies (IDs) that precisely characterize relational schemata modeledaccording to the main features of the Entity-Relationship (ER) model. An instance for such aschema may be inconsistent (data violate the dependencies) and incomplete (dataconstitute a piece of correct information; but not necessarily all the relevant information).While undecidable under general KDs and IDs; query answering under incomplete data isknown to be decidable for CDs. The known techniques are based on the chase--a specialinstance; organized in levels of depth; that is a representative of all the instances that satisfythe dependencies and that include the initial instance. Although the chase generally hasinfinite size; query answering can be addressed by posing the query (or a rewriting …,arXiv preprint arXiv:1312.2355,2013,1
Contextual data tailoring using ASP,Angelo Rauseo; Davide Martinenghi; Letizia Tanca,Abstract In a world of global networking; the variety and abundance of available datagenerates the need for effectively and efficiently gathering; synthesizing; and querying suchdata; while reducing information noise. A system where context awareness is integrated with–yet orthogonal to–data management allows the knowledge of the context in which the dataare used to better focus on currently useful information (represented as a view); keepingnoise at bay. This activity is called context-aware data tailoring. In this paper; after a briefreview of the literature on context awareness; we describe a technique for context-awaredata tailoring by means of Answer Set Programming (ASP). We use ASP techniques to i)validate the context values against the feasible contexts compatible with a contextspecification structure called Context Dimension Tree; and ii) convey to the user the …,International Workshop on Semantics in Data and Knowledge Bases,2011,1
Trends in rank join,Ihab Ilyas; Davide Martinenghi; Neoklis Polyzotis; Marco Tagliasacchi,Abstract This chapter reports the main findings of a panel that was moderated by DavideMartinenghi in which Ihab Ilyas; Neoklis Polyzotis; and Marco Tagliasacchi shared theirthoughts with the attendees of the Second SeCo Workshop regarding current and futureissues related to what was presented during the session on rank join. The topics touchedupon during the discussion regarded relevance for Search Computing; pertinence ofoptimization; multi-way joins; approximate answers; and uncertainty.,*,2011,1
Optimizing query processing for the hidden web,Andrea Calı Davide Martinenghi,Page 1. Optimizing Query Processing for the Hidden Web Optimizing Query Processing forthe Hidden Web Andrea Cal`ı Davide Martinenghi Oxford-Man Institute; University of OxfordDepartment of Information Systems and Computing; Brunel University Dipartimento diElettronica e Informazione; Politecnico di Milano APWeb 2010 Busan; 6 April 2010 Page2. Optimizing Query Processing for the Hidden Web Outline 1 Introduction 2 Surfacing 3 Queryanswering under access limitations 4 Optimization 5 Views and constraints 6 Containment7 Dynamic optimization 8 Conclusions Page 3. Optimizing Query Processing for the HiddenWeb Introduction The deep Web The deep Web Page 4. Optimizing Query Processing forthe Hidden Web Introduction What is the Deep Web …,*,2010,1
Data-driven optimization of search service composition for answering multi-domain queries,Davide Francesco Barbieri; Alessandro Bozzon; Daniele Braga; Marco Brambilla; Alessandro Campi; Stefano Ceri; Emanuele Della Valle; Piero Fraternali; Michael Grossniklaus; Davide Martinenghi,Answering multi-domain queries requires the combination of knowledge from variousdomains. Such queries are inadequately answered by general-purpose search engines;because domain-specific systems typically exhibit sophisticated knowledge about their ownfields of expertise. Moreover; multi-domain queries typically require combining in the resultdomain knowledge possibly coming from multiple web resources; therefore conventionalcrawling and indexing techniques; based on individual pages; are not adequate. In thispaper we present a conceptual framework for addressing the composition of search servicesfor solving multi-domain queries. The approach consists in building an infrastructure forsearch service composition that leaves within each search system the responsibility ofmaintaining and improving its domain knowledge; and whose main challenge is to …,VLDB Workshop on Using Search Engine Technology for Information Management (USETIM),2009,1
XQBE: the Swiss Army Knife for Semi-structured Data.,Daniele Braga; Alessandro Campi; Davide Martinenghi; Alessandro Raffio; Damiano Salvi,Abstract. The growing importance of XML calls for easier access to data managementtechnologies; in order to provide domain experts who are inexperienced in databasetechnologies with the possibility to directly query and transform domain specific data.Intuitiveness and simplicity are gained with the use of a graphical representation. The formeris obtained by depicting the hierarchical XML data model as tree structures; the latterconsists in considering only elements; attributes; and un-typed textual data. In this regard;the graphical framework of XQBE is a suitable tool for querying; transforming; and updatingXML data as well as for specifying integrity constraints.,SEBD,2005,1
Advanced Techniques for Efficient Data Integrity Checking: Ph. d. Dissertation,Davide Martinenghi,*,*,2005,1
Implementing the Event Calculus in the DemoII System,Davide Martinenghi,Abstract This report is about the practical uses of the Event Calculus and the problems thatmight arise when implementing the axioms that define it. It is assumed that the reader isfamiliar with a meta-logical system such as the DemoII System; which represents the contextof this paper.,*,1999,1
A Short Account of Techniques for Assisting Users in Mastering Big Data,Davide Martinenghi; Elisa Quintarelli; Fabio A Schreiber; Letizia Tanca,Abstract One of the most challenging problems faced by the database community is to assistinexperienced or casual users; who need the support of a sophisticated system that guidesthem in making sense of the data. This problem becomes especially relevant in the case ofBig Data; where the amount of data may quickly overwhelm users and discourage them fromleveraging the richness of the data patrimony. In the last years; often in collaboration withother members of the Italian database community; we have developed several differenttechniques whose aim is both to reduce the size of the problem and to focus on theinformation that is most relevant to the user. To this end; most of these techniques fruitfullyextract and exploit data semantics; for example by succinctly characterizing data viaintensional properties such as integrity constraints or by tailoring the answer to the user …,*,2018,*
Reconciling skyline and ranking queries,Paolo Ciaccia; Davide Martinenghi,Abstract Traditionally; skyline and ranking queries have been treated separately asalternative ways of discovering interesting data in potentially large datasets. While rankingqueries adopt a specific scoring function to rank tuples; skyline queries return the set of non-dominated tuples and are independent of attribute scales and scoring functions. Rankingqueries are thus less general; but usually cheaper to compute and widely used in datamanagement systems. We propose a framework to seamlessly integrate these twoapproaches by introducing the notion of restricted skyline queries (R-skylines). We proposeR-skyline operators that generalize both skyline and ranking queries by applying the notionof dominance to a set of scoring functions of interest. Such sets can be characterized; eg; byimposing constraints on the function's parameters; such as the weights in a linear scoring …,Proceedings of the VLDB Endowment,2017,*
The Dimensions of Crowdsourcing Task Design,Ilio Catallo; Davide Martinenghi,Abstract Crowdsourcing; ie; the provision of micro-tasks to be executed by a large pool ofpossibly anonymous workers; is attracting an increasing research attention; because itpromises to help solving many scientific and practical problems where the harmoniccooperation of humans and machines delivers superior results. This paper proposes asystematic view of the crowdsourcing task design space and categorizes the dimensionsthat qualify the design decisions in crowdsourcing applications. For each dimension; wediscuss the main open research problems and the most significant contributions; therebyoffering guidelines for a principled understanding of current crowdsourcing marketplaces.,International Conference on Web Engineering,2017,*
Humans Fighting Uncertainty: Crowdsourcing for Top-K Query Processing,Eleonora Ciceri; Piero Fraternali; Davide Martinenghi; Marco Tagliasacchi,Abstract. Querying uncertain data has become a prominent application due to theproliferation of user-generated content from social media and of data streams from sensors.When data ambiguity cannot be reduced algorithmically; crowdsourcing proves a viableapproach; which consists in posting tasks to humans and harnessing their judgment forimproving the confidence about data values or relationships. This paper tackles the problemof processing top-K queries over uncertain data with the help of crowdsourcing for quicklyconverging to the real ordering of relevant results. Several o✏ ine and online approaches foraddressing questions to a crowd are defined and contrasted on both synthetic and real datasets; with the aim of minimizing the crowd interactions necessary to find the real ordering ofthe result set.,24th Italian Symposium on Advanced Database Systems; SEBD 2016,2016,*
Processing keyword queries under access limitations,Andrea Calì; Thomas W Lynch; Davide Martinenghi; Riccardo Torlone,Abstract The Deep Web is constituted by data accessible through web pages; but not readilyindexable by search engines; as they are returned in dynamic pages. In this paper wepropose a framework for accessing Deep Web sources; represented as relational tables withso-called access limitations; with keyword-based queries. We formalize the notion of optimalanswer and investigate methods for query processing. We also outline the main ideas of ourimplementation of a prototype system for Deep Web keyword search.,Semanitic Keyword-based Search on Structured Data Sources,2015,*
When food matters: identifying food-related events on Twitter,Ciceri Eleonora; Catallo Ilio; Martinenghi Davide; Fraternali Piero,Abstract. Food communities in Twitter are growing every year; and food-related contentpermeates everyday conversations. Users meet on Twitter to share recipes; give cookingadvices or simply inform others about what they are eating. While some of these food-relatedconversations are not associated with any special occurrence; many conversations takeplace instead during specific events. The detection of food-related events gives interestinginsights: people do not talk only about Halloween and Easter; but they also create their ownfood-related events; such as the promotion of products (eg; an online petition to propose theproduction of bacon-flavored chips) or themed home-made recipes (eg; a day of recipesdedicated to chocolate). In this paper; we propose an approach that accurately capturesfood-related content from the tweet live stream; and analyze the detected conversations to …,CEUR WORKSHOP PROCEEDINGS,2015,*
When Food Matters: Identifying Food-related Events on Twitter.,Eleonora Ciceri; Ilio Catallo; Davide Martinenghi; Piero Fraternali,*,KDWeb,2015,*
Determining Relevant Relations for Datalog Queries under Access Limitations is Undecidable,Davide Martinenghi,Abstract: Access limitations are restrictions in the way in which the tuples of a relation can beaccessed. Under access limitations; query answering becomes more complex than in thetraditional case; with no guarantee that the answer tuples that can be extracted (akamaximal answer) are all those that would be found without access limitations (aka completeanswer). The field of query answering under access limitations has been broadlyinvestigated in the past. Attention has been devoted to the problem of determining relationsthat are relevant for a query; ie; those (possibly off-query) relations that might need to beaccessed in order to find all tuples in the maximal answer. In this short paper; we show thatrelevance is undecidable for Datalog queries.,arXiv preprint arXiv:1401.0069,2013,*
Answering Queries in a Relaxed Way.,Davide Martinenghi; Riccardo Torlone,Abstract. Traditional information search in which queries are posed against a known andrigid schema over a structured database is shifting towards a Web scenario in whichschemas are vague or absent. In this framework; query answering needs to be relaxed withthe goal of matching user requests with accessible data. In this paper; we propose a logicalmodel and an abstract query language as a foundation for querying data sets with vagueschemas. The model is a natural extension of the relational model in which data domainsare organized in taxonomies; simple classifications of values arranged in a hierarchicalstructure. The query language is a conservative extension of relational algebra wherespecial operators allow the specification of relaxed queries over vaguely structuredinformation.,SEBD,2011,*
Proximity rank join in search computing,Davide Martinenghi; Marco Tagliasacchi,Abstract Rank join can be generalized to sets of relations whose objects are equipped with ascore and a real-valued feature vector. Such vectors can be used to compare the objects toone another so as to join them based on a notion of “proximity”. The problem becomes thenthat of retrieving combinations of objects that have high scores; whose feature vectors areclose to one another and possibly to a given feature vector (the query). Traditional rank joinalgorithms may read more input than needed when solving proximity rank join. Suchweakness can be overcome by designing new algorithms for which; as in classical rank join;bounding scheme (and a tight version thereof) and pulling strategy play a crucial role toefficiently compute the solution.,*,2011,*
Cost-aware top-k join algorithms,Stefano Ceri; Davide Martinenghi; Marco Tagliasacchi,Abstract In this paper we consider the problem of joining ranked results produced by searchservices on the Web. We consider services that output data tuples sorted by score. We castthis problem as a generalization of the traditional rank aggregation problem; ie; combiningseveral ranked lists of objects to produce a single consensus ranking. The ranked lists maycontain a high number of objects; typically presented in pages; and accessing such pages iscostly. Therefore; algorithms should determine the best overall results without accessing allthe objects. Besides pagination of results; additional difficulties with respect to rankaggregation include the fact that the ranked lists do not; in general; rank the same set ofobjects; but rather heterogeneous sets of objects that may match on given join attributes toform a join tuple (here called combination). Each combination is assigned a combined …,*,2009,*
XQBE: a Visual Language for XML Data Management,Alessandro Campi,Abstract This Chapter describes a visual framework; called XQBE; that covers the mostimportant aspects of XML data management; spanning the visualization of XML documents;the formulation of queries; the representation and specification of document schemata; thedefinition of integrity constraints; the formulation of updates; and the expression of reactivebehaviors in response to data modifications. All these features are strongly unified by acommon visual abstraction and a few recurrent paradigms; so as to provide a homogeneousand comprehensive environment that allows even users without advanced programmingskills to deal with nontrivial XML data management and transformation tasks. The intrinsicambiguity inherent in any visual representation of richly expressive languages required aconsiderable effort of formalization in the semantics of XQBE that eventually lead to a …,*,2008,*
NGS: A New Generation Search Engine Supporting Cross Domain Queries,Daniele Braga; Diego Calvanese; Alessandro Campi; Stefano Ceri; Florian Daniel; Davide Martinenghi; Paolo Merialdo; Riccardo Torlone,Abstract. This paper presents NGS; a framework providing fully automated support for cross-domain queries. In particular; NGS (a) integrates different kinds of services (search engines;web services; and wrapped web pages) into a global ontology; ie; a unified view of theconcepts supported by the available services;(b) covers query formulation aspects over theglobal ontology; and query rewriting in terms of the actual services; and (c) offers severaloptimization opportunities leveraging the characteristics of the different services at hand;based on several different cost metrics.,Proc. of the 16th Italian Conf. on Database Systems (SEBD 2008),2008,*
Second International Workshop on Database Technologies for Handling XML Information on the Web (DataX'06)-Efficient Integrity Checking over XML Documents,Daniele Braga; Alessandro Campi; Davide Martinenghi,*,Lecture Notes in Computer Science,2006,*
Constraints-Simplification of Database Integrity Constraints Revisited: A Transformational Approach,Henning Christiansen; Davide Martinenghi,*,Lecture Notes in Computer Science,2004,*
Integrity checking for combined databases,Davide Martinenghi,CoLogNET Workshop on Logic-Based Methods for Information Integration - 23 August 2003… Computer Science; building 42.1 Roskilde University Universitetsvej 1 PO Box 260 DK-4000Roskilde Denmark Phone: +45 4674 2000 Fax: +45 4674 3072 www.dat.ruc.dk … CoLogNETWorkshop on Logic-Based Methods for Information Integration - 23 August 2003 … CoLogNETWorkshop on Logic-Based Methods for Information Integration - 23 August 2003 … • ICs areproperties of the DB that must … • The integrity must be checked wrt the ICs … • In a data integrationsystem; it's the same … CoLogNET Workshop on Logic-Based Methods for Information Integration- 23 August 2003 … 2. Use the fact that ϕ was known to hold … CoLogNET Workshop onLogic-Based Methods for Information Integration - 23 August 2003 … CoLogNET Workshopon Logic-Based Methods for Information Integration - 23 August 2003,Integration,2003,*
Googling the Deep Web,Andrea Calı; Davide Martinenghi; Riccardo Torlone,Abstract. The Deep Web is constituted by data that are accessible through Web pages; butnot indexable by search engines as they are returned in dynamic pages. In this paper wepropose a conceptual framework for answering keyword queries on Deep Web sourcesrepresented as relational tables with so-called access limitations. We formalize the notion ofoptimal answer and characterize queries for which an answer can be found.,*,*,*
Workshop Organization,Hendrik Decker; Leticia Pascual Miret; Deepthi Akkoorath; Ofer Arieli; Enrique Armendáriz-Íñigo; Laurence Cholvy; Alfredo Cuzzocrea; Karen C Davis; Carlos F Enguix; Edward Hermann Haeusler; Weiru Liu; James Lu; Davide Martinenghi; Francesc Muñoz-Escoí; Hitoshi Omori; Valeria de Paiva; Nuno Preguiça; Maarten van Stehen; Alejandro Toselli; Jørgen Villadsen; Toshiharu Waragai; Xiaowang Zhang,Organization Hendrik Decker; PROS Research Center; Universidad Politécnica de Valencia;Spain Leticia Pascual Miret; Instituto Tecnológica de Informática; Universidad Politécnica deValencia; Spain … Program Committee Deepthi Akkoorath; Technische UniversitätKaiserslautern; Germany Ofer Arieli; Academic College of Tel Aviv; Israel EnriqueArmendáriz-Íñigo; Universidad Pública de Navarra; Pamplona; Spain Vicent Cholvi UniversitatJaume I; Castelló; Spain Laurence Cholvy; ONERA Toulouse; France Alfredo Cuzzocrea; Universityof Trieste; Italy Karen C. Davis; University of Cincinnati; USA Carlos F. Enguix; SydneyUniversity; Australia Sergio Greco Universitá della Calabria; Rende; Italy Edward HermannHaeusler; Pontifícia Universidade Catolica do Rio de Janeiro; Brazil Weiru Liu; Queen'sUniversity; Belfast; Northern Ireland James Lu; Emory University; Atlanta GA; USA …,*,*,*
Seventeenth International Conference on Database and Expert Systems Applications,E Palomar; JM Estevez-Tapiador; JC Hernandez-Castro; A Ribagorda,A significant challenge for peer-to-peer (P2P) systems is maintaining the correctness andconsistency of their global data structures and shared contents as peers independently andunpredictably join and leave the system. In such networks; it is necessary that some securitymechanisms will be applied with the aim of avoiding attacks based on non-authorizedcontent modifications. In this paper; we...,*,*,*
Query Optimization in the Deep Web,Andrea Calı Davide Martinenghi,Page 1. Query Optimization in the Deep Web Query Optimization in the Deep Web AndreaCal`ı Davide Martinenghi Oxford-Man Institute; University of Oxford Department of InformationSystems and Computing; Brunel University Dipartimento di Elettronica e Informazione; Politecnicodi Milano Roma Tre University Rome; 10 June 2010 Page 2. Query Optimization in the DeepWeb Outline 1 Introduction 2 Surfacing 3 Query answering under access limitations 4 Optimization5 Views and constraints 6 Containment 7 Dynamic optimization 8 Conclusions Page 3. QueryOptimization in the Deep Web Introduction The deep Web The deep Web Page 4. QueryOptimization in the Deep Web Introduction The deep Web The deep Web Page 5. QueryOptimization in the Deep Web Introduction What is the Deep Web …,*,*,*
2nd International Workshop on Logical Aspects and Applications of Integrity Constraints,Henning Christiansen; Davide Martinenghi; Marcelo Arenas; Andrea Calì; Stefano Ceri,Integrity constraints are commonly recognized as the tool for characterizing data semanticsand well-formedness in databases and information systems in general. As such; integrityconstraints apply to different contexts; such as relational and deductive databases; activedatabase systems; and XML document collections; and are relevant for several applications;including integrity control; data integration and semantic query optimization. LAAIC'06 is the2nd International Workshop on Logical Aspects and Applications of Integrity Constraints;and its goal is to gather experts in the field and to stimulate a constructive dialogue amongresearchers. It provides an international forum for the presentation of the most recent trends;and a common starting point to address the most pressing research problems. We haveselected eight high-quality; full papers for discussion and presentation in the workshop …,*,*,*
Workshop DALI 2011,Philippe Besnard; Hendrik Decker; Andreas Herzig; Ofer Arieli; Bráulio Coelho Ávila; Diderik Batens; Leopoldo Bertossi; Meghyn Bienvenu; Joaquín Borrego-Díaz; Walter Carnielli; Diego Calvanese; Jeremy Carroll; Jan Chomicki; Marie-Odile Cordier; Timothy Hinrichs; Anthony Hunter; Sébastien Konieczny; Weiru Liu; João Marcos; Davide Martinenghi; Joke Meheus; Guilin Qi; Torsten Schaub; Settimo Termini; Hans Tompits; Kewen Wang; Toshiharu Waragai; Gregory Wheeler; Stefan Woltran; Guo-Qiang Zhang,Workshop Organizers Philippe Besnard; IRIT-CNRS; Université Paul Sabatier; Toulouse; FranceHendrik Decker; Instituto Tecnológico de Informática; UPV; Valencia; Spain Andreas Herzig;IRIT-CNRS; Université Paul Sabatier; Toulouse; France … Program Committee Ofer Arieli; AcademicCollege Tel-Aviv; Israel Bráulio Coelho Ávila; University Paraná; Brazil Diderik Batens; GhentUniversity; Belgium Leopoldo Bertossi; Carleton University; Ottawa; Canada PhilippeBesnard; University Paul Sabatier; Toulouse; France Meghyn Bienvenu; University ParisSud; France Joaquín Borrego-Díaz; University Sevilla; Spain Walter Carnielli; UniversityCampinas; Brazil Diego Calvanese; University Bolzano; Italy Jeremy Carroll; TopQuadrant; MountainView; CA; USA Laurence Cholvy; ONERA; Toulouse; France Jan Chomicki; UniversityBuffalo; USA Marie-Odile Cordier; University Rennes1/IRISA; Rennes; France Hendrik …,*,*,*
Preserving Integrity in Inconsistent Databases,Hendrik Decker; Davide Martinenghi,*,*,*,*
J.-M. Andreoli; UM Borghoff; R. Pareschi; JH Schlichter,A Calì; D Calvanese; D Martinenghi; N Carvalho; A Correia Jr; J Pereira; L Rodrigues; R Oliveira; S Guedes; S Kell; I Navas-Delgado; JF Aldana-Montes,J.-M. Andreoli; UM Borghoff; R. Pareschi; JH Schlichter: Constraint Agents for the InformationAge We propose constraints as the appropriate computational constructs for the design of agentswith the task of selecting; merging and managing electronic information coming from such servicesas Internet access; digital libraries; E-mail; or on-line … A. Calì; D. Calvanese; D.Martinenghi: Dynamic Query Optimization under Access Limitations and Dependencies Unlikerelational tables in a database; data sources on the Web typically can only be accessed in limitedways. In particular; some of the source fields may be required as input and thus need to be mandatorilyfilled in order to access the … N. Carvalho; A. Correia Jr.; J. Pereira; L. Rodrigues; R.Oliveira; S. Guedes: On the Use of a Reflective Architecture to Augment Database ManagementSystems The Database Management System (DBMS) used to be a commodity software …,*,*,*
G. Kolaczek; K. Juszczyszyn,J Sánchez-Hernández; K Svozil; E Börger; A Calì; D Calvanese; D Martinenghi,G. Kolaczek; K. Juszczyszyn: Deontic Logic-based Framework for Ontology Aligment in AgentCommunities In this paper we consider a multiagent system with multiple ontologies. The agentsmaintain the ontologies individually which leads to frequent changes and possible knowledgeinconsistencies. We propose a general framework for decision making … J.Sánchez-Hernández: Constructive Failure in Functional-Logic Programming: From Theory toImplementation Functional-logic programming amalgamates some of the main features of bothfunctional and logic styles into a single paradigm. Nevertheless; negation is a widely investigatedfeature in logic programming that has not received much attention in … K. Svozil: QuantumAlgorithmic Information Theory The agenda of quantum algorithmic information theory; ordered`top-down; is the quantum halting amplitude; followed by the quantum algorithmic …,*,*,*
We investigate properties of coincidence ideals in subattribute lattices that occur in complex value datamodels; ie sets of subattributes; on which two complex values...,H Köhler; KD Schewe; H Ma; A Calì; D Calvanese; D Martinenghi,A. Sali; K.-D. Schewe: A Characterisation of Coincidence Ideals for Complex Values We investigateproperties of coincidence ideals in subattribute lattices that occur in complex valuedatamodels; ie sets of subattributes; on which two complex values coincide. We let complex valuesbe defined by constructors for records … H. Köhler: Global Database Design based on StorageSpace and Update Time Minimization A common approach in designing relational databasesis to start with a universal relation schema; which is then decomposed into multiplesubschemas. A good choice of subschemas can be determined using integrity constraints definedon the schema … K.-D. Schewe: Functional Dependencies with Counting on Trees The paperpresents an axiomatisation for functional dependencies on trees that are defined using constructorsfor records; lists; sets and multisets. A simple form of restructuring permitting lists to be …,*,*,*
We investigate properties of coincidence ideals in subattribute lattices that occur in complex value datamodels; ie sets of subattributes; on which two complex values...,S Hartmann; S Link; H Ma; A Calì; D Calvanese; D Martinenghi; HJ Lenz; B Thalheim,A. Sali; K.-D. Schewe: A Characterisation of Coincidence Ideals for Complex Values We investigateproperties of coincidence ideals in subattribute lattices that occur in complex valuedatamodels; ie sets of subattributes; on which two complex values coincide. We let complex valuesbe defined by constructors for records … S. Hartmann; S. Link: Weak FunctionalDependencies: Full Propositional Expressiveness for the Database Practitioner We study inferencesystems of weak functional dependencies in relational and complex-value databases. Functionaldependencies form a very common class of database constraints. Designers and administratorsproficiently utilise them in everyday … H. Ma: A Geometrically Enhanced Conceptual Modeland Query Language Motivated by our experiences with spatial modelling for the sustainableland use initiative we present a geometrically enhanced ER model (GERM); which …,*,*,*
Accessing Data through Ontologies under Access Limitations: State of the Art,Andrea Calı; Diego Calvanese; Davide Martinenghi,Search engines operating on the web; as well as web information systems [FLM98]; mayneed to access data that are somehow “hidden” behind web pages; these data are onlyaccessible through forms; and they are not immediately accessible on the web. Such hiddenpages are dynamically generated; and they are the response to a user query. Typically;certain fields are required to be filled in by the user in order to obtain a result. For example;an online shop would forbid a request posed by a user who leaves all fields of the formempty; while searching for products. Analogously; in legacy systems where data arescattered over several files; data may be wrapped and masked as relational tables that havesimilar access limitations; due to the way the data are organized in the files. It is easy to seethat; usually; accessing information through a web form amounts to querying a relational …,*,*,*
R. Wastl,S Hartmann; S Link; H Köhler; R Bergmann; M Schaaf; A Calì; D Calvanese; D Martinenghi,R. Wastl: Linear Derivations for Keys of a Database Relation Schema In [Wastl 1998] we haveintroduced the Hilbert style inference system K for deriving all keys of a database relationschema. In this paper we investigate formal K-derivations more closely using the concept oftableaux. The analysis gives insight … S. Hartmann; S. Link: Weak FunctionalDependencies: Full Propositional Expressiveness for the Database Practitioner We study inferencesystems of weak functional dependencies in relational and complex-value databases. Functionaldependencies form a very common class of database constraints. Designers and administratorsproficiently utilise them in everyday … H. Köhler: Global Database Design based on StorageSpace and Update Time Minimization A common approach in designing relational databasesis to start with a universal relation schema; which is then decomposed into multiple …,*,*,*
4th International Workshop on Ranking in Databases (DBRank’10),Thomas Bernecker; Tobias Emrich; Franz Graf; Hans-Peter Kriegel; Peer Kröger; Matthias Renz; Erich Schubert; Arthur Zimek; Christian Beecks; Merih Seran Uysal; Thomas Seidl; Davide Martinenghi; Marco Tagliasacchi; Dimitris Souravlias; Marina Drosou; Kostas Stefanidis; Evaggelia Pitoura,4th International Workshop on Ranking in Databases (DBRank'10) … 4 Subspace SimilaritySearch Using the Ideas of Ranking and Top-k Retrieval Thomas Bernecker; Tobias Emrich; FranzGraf; Hans-Peter Kriegel; Peer Kröger; Matthias Renz; Erich Schubert; Arthur Zimek; LMUMünchen; Germany … 10 Efficient k-Nearest Neighbor Queries with the Signature QuadraticForm Distance Christian Beecks; Merih Seran Uysal; Thomas Seidl; RWTH AachenUniversity; Germany … 16 Top-k Pipe Join Davide Martinenghi; Marco Tagliasacchi; Politecnicodi Milano; Italy … 20 On Novelty in Publish/Subscribe Delivery Dimitris Souravlias; MarinaDrosou; Kostas Stefanidis; Evaggelia Pitoura; University of Ioannina; Greece … 23 Rankingfor Data Repairs Mohamed Yakout; Ahmed K. Elmagarmid; Jennifer Neville; PurdueUniversity; USA … 2nd International Workshop on Information & Software as Services,*,*,*
