Reasoning on UML class diagrams,Daniela Berardi; Andrea Calı; Diego Calvanese; Giuseppe De Giacomo,Abstract UML is the de-facto standard formalism for software design and analysis. Tosupport the design of large-scale industrial applications; sophisticated CASE tools areavailable on the market; that provide a user-friendly environment for editing; storing; andaccessing multiple UML diagrams. It would be highly desirable to equip such CASE toolswith automated reasoning capabilities; such as those studied in Artificial Intelligence and; inparticular; in Knowledge Representation and Reasoning. Such capabilities would allow toautomatically detect relevant formal properties of UML diagrams; such as inconsistencies orredundancies. With regard to this issue; we consider UML class diagrams; which are one ofthe most important components of UML; and we address the problem of reasoning on suchdiagrams. We resort to several results developed in the field of Knowledge …,Artificial Intelligence,2003,582
A general datalog-based framework for tractable query answering over ontologies,Andrea Calì; Georg Gottlob; Thomas Lukasiewicz,Abstract Ontologies and rules play a central role in the development of the Semantic Web.Recent research in this context focuses especially on highly scalable formalisms for the Webof Data; which may highly benefit from exploiting database technologies. In this paper; as afirst step towards closing the gap between the Semantic Web and databases; we introduce afamily of expressive extensions of Datalog; called Datalog±; as a new paradigm for queryanswering over ontologies. The Datalog±family admits existentially quantified variables inrule heads; and has suitable restrictions to ensure highly efficient ontology querying. Weshow in particular that Datalog±encompasses and generalizes the tractable descriptionlogic EL and the DL-Lite family of tractable description logics; which are the most commontractable ontology languages in the context of the Semantic Web and databases. We also …,Web Semantics: Science; Services and Agents on the World Wide Web,2012,417
Data integration under integrity constraints,Andrea Calı; Diego Calvanese; Giuseppe De Giacomo; Maurizio Lenzerini,Abstract Data integration systems provide access to a set of heterogeneous; autonomousdata sources through a so-called global schema. There are basically two approaches fordesigning a data integration system. In the global-centric approach; one defines theelements of the global schema as views over the sources; whereas in the local-centricapproach; one characterizes the sources as views over the global schema. It is well knownthat processing queries in the latter approach is similar to query answering with incompleteinformation; and; therefore; is a complex task. On the other hand; it is a common opinion thatquery processing is much easier in the former approach. In this paper we show thesurprising result that; when the global schema is expressed in the relational model withintegrity constraints; even of simple types; the problem of incomplete information implicitly …,Information Systems,2004,353
On the decidability and complexity of query answering over inconsistent and incomplete databases,Andrea Calì; Domenico Lembo; Riccardo Rosati,Abstract In databases with integrity constraints; data may not satisfy the constraints. In thispaper; we address the problem of obtaining consistent answers in such a setting; when keyand inclusion dependencies are expressed on the database schema. We establishdecidability and complexity results for query answering under different assumptions on data(soundness and/or completeness). In particular; after showing that the problem is in generalundecidable; we identify the maximal class of inclusion dependencies under which queryanswering is decidable in the presence of key dependencies. Although obtained in a singledatabase context; such results are directly applicable to data integration; where multipleinformation sources may provide data that are inconsistent with respect to the global view ofthe sources.,Proceedings of the twenty-second ACM SIGMOD-SIGACT-SIGART symposium on Principles of database systems,2003,305
Taming the infinite chase: Query answering under expressive relational constraints,Andrea Calı; Georg Gottlob; Michael Kifer,*,Proc. of KR,2008,286
Query rewriting and answering under constraints in data integration systems,Andrea Calı; Domenico Lembo; Riccardo Rosati,Abstract In this paper we address the problem of query answering and rewriting in global-as-view data integration systems; when key and inclusion dependencies are expressed on theglobal integration schema. In the case of sound views; we provide sound and completerewriting techniques for a maximal class of constraints for which decidability holds. Then; weintroduce a semantics which is able to cope with violations of constraints; and present asound and complete rewriting technique for the same decidable class of constraints. Finally;we consider the decision problem of query answering and give decidability and complexityresults.,Proc. of the 18th Int. Joint Conf. on Artificial Intelligence (IJCAI 2003),2003,167
Towards more expressive ontology languages: The query answering problem,Andrea Cali; Georg Gottlob; Andreas Pieris,Abstract Ontology reasoning finds a relevant application in the so-called ontology-baseddata access; where a classical extensional database (EDB) is enhanced by an ontology; inthe form of logical assertions; that generates new intensional knowledge which contributesto answering queries. In this setting; queries are therefore answered against a logical theoryconstituted by the EDB and the ontology; more specifically; query answering amounts tocomputing the answers to the query that are entailed by the EDB and the ontology. In thispaper; we study novel relevant classes of ontological theories for which query answering isboth decidable and of tractable data complexity; that is; the complexity with respect to thesize of the data only. In particular; our new classes belong to the recently introduced familyof Datalog-based languages; called Datalog±. The basic Datalog±rules are (function-free …,Artificial Intelligence,2012,127
On the expressive power of data integration systems,Andrea Calì; Diego Calvanese; Giuseppe De Giacomo; Maurizio Lenzerini,Abstract There are basically two approaches for designing a data integration system. In theglobal-as-view (GAV) approach; one maps the concepts in the global schema to views overthe sources; whereas in the local-as-view (LAV) approach; one maps the sources into viewsover the global schema. The goal of this paper is to relate the two approaches with respectto their expressive power. The analysis is carried out in a relational database setting; whereboth the queries on the global schema; and the views in the mapping are conjunctivequeries. We introduce the notion of query-preserving transformation; and query-reducibilitybetween data integration systems; and we show that; when no integrity constraints areallowed in global schema; the LAV and the GAV approaches are incomparable. We thenconsider the addition of integrity constraints in the global schema; and present techniques …,International Conference on Conceptual Modeling,2002,120
Datalog+/-: A family of logical knowledge representation and query languages for new applications,Andrea Cali; Georg Gottlob; Thomas Lukasiewicz; Bruno Marnette; Andreas Pieris,This paper summarizes results on a recently introduced family of Datalog-based languages;called Datalog+/-; which is a new framework for tractable ontology querying; and for a varietyof other applications. Datalog+/-extends plain Datalog by features such as existentiallyquantified rule heads and; at the same time; restricts the rule syntax so as to achievedecidability and tractability. In particular; we discuss three paradigms ensuring decidability:chase termination; guardedness; and stickiness.,Logic in Computer Science (LICS); 2010 25th Annual IEEE Symposium on,2010,118
Datalog±: a unified approach to ontologies and integrity constraints,Andrea Calì; Georg Gottlob; Thomas Lukasiewicz,Abstract We report on a recently introduced family of expressive extensions of Datalog;called Datalog±; which is a new framework for representing ontological axioms in form ofintegrity constraints; and for query answering under such constraints. Datalog±is derivedfrom Datalog by allowing existentially quantified variables in rule heads; and by enforcingsuitable properties in rule bodies; to ensure decidable and efficient query answering. Wefirst present different languages in the Datalog±family; providing tight complexity bounds forall cases but one (where we have a low complexity AC 0 upper bound). We then show thatsuch languages are general enough to capture the most common tractable ontologylanguages. In particular; we show that the DL-Lite family of description logics and F-LogicLite are expressible in Datalog±. We finally show how stratified negation can be added to …,Proceedings of the 12th International Conference on Database Theory,2009,118
Advanced processing for ontological queries,Andrea Calì; Georg Gottlob; Andreas Pieris,Abstract Ontology-based data access is a powerful form of extending database technology;where a classical extensional database (EDB) is enhanced by an ontology that generatesnew intensional knowledge which may contribute to answer a query. The ontologicalintegrity constraints for generating this intensional knowledge can be specified in descriptionlogics such as DL-Lite. It was recently shown that these formalisms allow for very efficientquery-answering. They are; however; too weak to express simple and useful integrityconstraints that involve joins. In this paper we introduce a more expressive formalism thattakes joins into account; while still enjoying the same low query-answering complexity. Inour framework; ontological constraints are expressed by sets of rules that are so-called tuple-generating dependencies (TGDs). We propose the language of sticky sets of TGDs; which …,Proceedings of the VLDB Endowment,2010,106
Query answering under non-guarded rules in datalog+/-,Andrea Calì; Georg Gottlob; Andreas Pieris,Abstract In ontology-based data access; an extensional database is enhanced by anontology that generates new intensional knowledge which has to be considered whenanswering queries. In this setting; tractable data complexity (ie; complexity wrt the data only)of query answering is crucial; given the need to deal with large data sets. A well-known classof tractable ontology languages is the DL-lite family; however; in DL-lite it is impossible toexpress simple and useful integrity constraints that involve joins. To overcome this limitation;the Datalog+/-class of decidable languages uses tuple-generating dependencies (TGDs) asrules; thus allowing for conjunctions of atoms in the rule bodies; with suitable limitations toensure decidability. In particular; sticky sets of TGDs allow for joins and variable repetition inrule bodies under certain conditions. In this paper we extend the notion of stickiness by …,International Conference on Web Reasoning and Rule Systems,2010,87
Querying data under access limitations,Andrea Cali; Davide Martinenghi,Data sources on the web are often accessible through web interfaces that present them asrelational tables; but require certain attributes to be mandatorily selected; eg; via a web form.In a scenario where we integrate a set of such sources; and we pose queries over them; thevalues needed to access a source may have to be retrieved from other sources that arepossibly not even mentioned in the query: answering queries at best can then be done onlywith a potentially recursive query plan that gets all obtainable answers to the query. Sincedata sources are typically distributed over a network; a major cost indicator for the executionof a query plan is the number of accesses to remote sources. In this paper we present anoptimization technique for conjunctive queries that produces a query plan that:(1) minimizesthe number of accesses according to a strong notion of minimality;(2) excludes all …,Data Engineering; 2008. ICDE 2008. IEEE 24th International Conference on,2008,83
Accessing data integration systems through conceptual schemas,Andrea Calì; Diego Calvanese; Giuseppe De Giacomo; Maurizio Lenzerini,Abstract Data integration systems provide access to a set of heterogeneous; autonomousdata sources through a so-called global; or mediated view. There is a general consensusthat the best way to describe the global view is through a conceptual data model; and thatthere are basically two approaches for designing a data integration system. In the global-as-view approach; one defines the concepts in the global schema as views over the sources;whereas in the local-as-view approach; one characterizes the sources as views over theglobal schema. It is well known that processing queries in the latter approach is similar toquery answering with incomplete information; and; therefore; is a complex task. On the otherhand; it is a common opinion that query processing is much easier in the former approach. Inthis paper we show the surprising result that; when the global schema is expressed in …,International conference on conceptual modeling,2001,81
A formal framework for reasoning on UML class diagrams,Andrea Calì; Diego Calvanese; Giuseppe De Giacomo; Maurizio Lenzerini,Abstract In this paper we formalize UML class diagrams in terms of a logic belonging toDescription Logics; which are subsets of First-Order Logic that have been thoroughlyinvestigated in Knowledge Representation. The logic we have devised is specificallytailored towards the high expressiveness of UML information structuring mechanisms; andallows one to formally model important properties which typically can only be specified bymeans of qualifiers. The logic is equipped with decidable reasoning procedures which canbe profitably exploited in reasoning on UML class diagrams. This makes it possible toprovide computer aided support during the application design phase in order toautomatically detect relevant properties; such as inconsistencies and redundancies.,International Symposium on Methodologies for Intelligent Systems,2002,79
A description logic based approach for matching user profiles,Andrea Calı; Diego Calvanese; Simona Colucci; Tommaso Di Noia3 Francesco M Donini,Abstract Several applications require the matching of user profiles; eg; job recruitment ordating systems. In this paper we present a logical framework for specifying user profiles thatallows profile description to be incomplete in the parts that are unavailable or areconsidered irrelevant by the user. We present an algorithm for matching demands andsupplies of profiles; taking into account incompleteness of profiles and incompatibilitybetween demand and supply. We specialize our framework to dating services; however; thesame techniques can be directly applied to several other contexts.,2004 International Workshop on Description Logics,2004,52
Models for information integration: Turning local-as-view into global-as-view,Andrea Cali; Giuseppe De Giacomo; Maurizio Lenzerini,Abstract. There are basically two approaches for designing a data inte grat; ion system. Inthe global-as-view approach; one defines t. he concepts in the global schema as views overthe sources; whereas in the local-as view approach; one characterizes the sources as viewsover the global schema. The goal of this paper is to verify whether we can transform a dataintegration system built with the local-as-viev.-approach into a system following the global-as-view approach.\Vc study the problem in a setting where the global schema is expressedin the relational model with inclusion dependencies; and the queries used in the integrationsys tems (both the queries on the global schema; and the views in the map ping) areexpressed in the language of conjunctive queries. The result we present is that such atransformation exists: we can always transform a local-as-view system into a global-as …,Proc. of Int. Workshop on Foundations of Models for Information Integration,2001,44
IBIS: Semantic data integration at work,Andrea Calì; Diego Calvanese; Giuseppe De Giacomo; Maurizio Lenzerini; Paolo Naggar; Fabio Vernacotola,Abstract In this paper we present IBIS (Internet-Based Information System); a system for thesemantic integration of heterogeneous data sources; which adopts innovative and state-of-the-art solutions to deal with all aspects of a complex data-integration environment;including query answering under integrity constraints and limitations on source access. IBISis based on the global-as-view approach; using a relational mediated schema to query thedata at the sources. Sources are wrapped so as to provide a relational view on them. A keyissue is that the system allows the specification of integrity constraints (modeling constraintsin the domain of interest) in the global schema. Since sources are autonomous; theextracted data in general do not satisfy the constraints. IBIS adapts and integrates the dataextracted from the sources making use of the constraints in the global schema; so as to …,International Conference on Advanced Information Systems Engineering,2003,38
A logic-based approach for matching user profiles,Andrea Calì; Diego Calvanese; Simona Colucci; Tommaso Di Noia; Francesco M Donini,Abstract Several applications require the matching of user profiles; eg; job recruitment ordating systems. In this paper we present a logical framework for specifying user profiles thatallows profile description to be incomplete in the parts that are unavailable or areconsidered irrelevant by the user. We present an algorithm for matching demands andsupplies of profiles; taking into account incompleteness of profiles and incompatibilitybetween demand and supply. We specialize our framework to dating services; however; thesame techniques can be directly applied to several other contexts.,International Conference on Knowledge-Based and Intelligent Information and Engineering Systems,2004,36
New expressive languages for ontological query answering,Andrea Calı; Georg Gottlob; Andreas Pieris,Abstract Ontology-based data access is a powerful form of extending database technology;where a classical extensional database (EDB) is enhanced by an ontology that generatesnew intensional knowledge which may contribute to answer a query. Recently; theDatalog±family of ontology languages was introduced; in Datalog±; rules are tuple-generating dependencies (TGDs); ie; Datalog rules with the possibility of having existentially-quantified variables in the head. In this paper we introduce a novel Datalog±language;namely sticky sets of TGDs; which allows for a wide class of joins in the body; while enjoyingat the same time a low query-answering complexity. We establish complexity results foranswering conjunctive queries under sticky sets of TGDs; showing; in particular; thatontological conjunctive queries can be compiled into first-order and thus SQL queries …,Proc. of AAAI,2011,33
Reasoning in data integration systems: why lav and gav are siblings,Andrea Calì,Abstract Data integration consists in providing a uniform access to a set of data sources;through a unified representation of the data called global schema; a mapping specifies therelationship between the global schema and the sources. Integrity constraints (ICs) areexpressed on the global schema to better represent the domain of interest; in general; ICsare not satisfied by the data at the sources. In this paper we address the problem of queryanswering in GLAV data integration systems; where tuple-generating dependencies areexpressed on the global schema. We solve the problem in an intensional fashion; bypresenting a rewriting technique that; taking into account both the ICs and the mapping;allows us to compute the answers to a query; expressed over the global schema; byevaluating the rewritten query directly over the sources. Since the GLAV approach is a …,International Symposium on Methodologies for Intelligent Systems,2003,33
Containment of conjunctive object meta-queries,Andrea Cali; Michael Kifer,Abstract We consider the problem of query containment over an object data model derivedfrom F-logic. F-logic has generated considerable interest commercially; in the academia;and within various standardization efforts as a means for building ontologies and forreasoning on the Semantic Web. Solution to the containment problem for F-logic queries canhelp with query optimization as well as the classification problem in information integrationsystems. An important property of F-logic queries; which sets them apart from databasequeries; is that they can mix the data-level and the meta-level in simple and useful ways.This means that such queries may refer not only to data but also schema information. To thebest of our knowledge; the containment problem for such queries has not been consideredin the literature. We show that; even for queries over meta-information together with data …,Proceedings of the 32nd international conference on Very large data bases,2006,32
Reasoning on UML class diagrams in description logics,Andrea Calı; Diego Calvanese; Giuseppe De Giacomo; Maurizio Lenzerini,Abstract. In this paper1 we formalize UML class diagrams in terms of a logic belonging toDescription Logics; which are subsets of First-Order Logic that have been thoroughlyinvestigated in Knowledge Representation. The logic we have devised is specificallytailored towards the high expressiveness of UML information structuring mechanisms; andallows one to formally model important properties which typically can only be specified bymeans of qualifiers. The logic is equipped with decidable reasoning procedures which canbe profitably exploited in reasoning on UML class diagrams. This makes it possible toprovide computer aided support during the application design phase in order toautomatically detect relevant properties; such as inconsistencies and redundancies.,Proc. of IJCAR Workshop on Precise Modelling and Deduction for Object-oriented Software Development (PMD 2001),2001,32
Querying the deep web,Andrea Calì; Davide Martinenghi,Abstract Data stored outside Web pages and accessible from the Web; typically throughHTML forms; consitute the so-called Deep Web. Such data are of great value; but difficult toquery and search. We survey techniques to optimize query processing on the Deep Web; ina setting where data are represented in the relational model. We illustrate optimizations bothat query plan generation time and at runtime; highlighting the role of integrity constraints. Wediscuss several prototype systems that address the query processing problem.,Proceedings of the 13th International Conference on Extending Database Technology,2010,30
Tractable query answering over conceptual schemata,Andrea Calì; Georg Gottlob; Andreas Pieris,Abstract We address the problem of answering conjunctive queries over extended Entity-Relationship schemata; which we call EER (Extended ER) schemata; with is-a amongentities and relationships; and cardinality constraints. This is a common setting in conceptualdata modelling; where reasoning over incomplete data with respect to a knowledge base isrequired. We adopt a semantics for EER schemata based on their relational representation.We identify a wide class of EER schemata for which query answering is tractable in datacomplexity; the crucial condition for tractability is the separability between maximum-cardinality constraints (represented as key constraints in relational form) and the otherconstraints. We provide; by means of a graph-based representation; a syntactic condition forseparability: we show that our conditions is not only sufficient; but also necessary; thus …,International Conference on Conceptual Modeling,2009,30
Tightly integrated probabilistic description logic programs for representing ontology mappings,Andrea Calì; Thomas Lukasiewicz; Livia Predoiu; Heiner Stuckenschmidt,Abstract Creating mappings between ontologies is a common way of approaching thesemantic heterogeneity problem on the Semantic Web. To fit into the landscape of semanticweb languages; a suitable; logic-based representation formalism for mappings is needed.We argue that such a formalism has to be able to deal with uncertainty and inconsistenciesin automatically created mappings. We analyze the requirements for such a formalism; andwe propose a novel approach to probabilistic description logic programs as such aformalism; which tightly combines disjunctive logic programs under the answer setsemantics with both description logics and Bayesian probabilities. We define the language;and we show that it can be used to resolve inconsistencies and merge mappings fromdifferent matchers based on the level of confidence assigned to different rules …,International Symposium on Foundations of Information and Knowledge Systems,2008,28
On the role of integrity constraints in data integration,Andrea Calı; Diego Calvanese; Giuseppe De Giacomo; Maurizio Lenzerini,Abstract We discuss the issue of dealing with integrity constraints over the global schema indata integration. On the one hand; integrity constraints can be used to extract moreinformation from incomplete sources; similarly to the case of databases with incompleteinformation. On the other hand; integrity constraints raise the problem of dealing with theinconsistency of the whole system; due to contradictory data at the sources. We also presenta data integration system developed by taking into account such issues.,Bull. of the IEEE Computer Society Technical Committee on Data Engineering,2002,28
Ontological query answering under expressive Entity–Relationship schemata,Andrea Calí; Georg Gottlob; Andreas Pieris,Abstract The Entity–Relationship (ER) model is a fundamental tool for database design;recently extended and employed in knowledge representation and reasoning due to itsexpressiveness and comprehensibility. We address the problem of answering conjunctivequeries under constraints representing schemata expressed in an extended version of theEntity–Relationship model. This extended model; called ER+; comprises is-a constraintsamong entities and relationships; plus functional and mandatory participation constraints. Inparticular; it allows for arbitrary permutations of the roles in is-a among relationships. A keynotion that ensures high tractability in ER+ schemata is separability; ie; the absence ofinteraction between the functional participation constraints and the other constructs of ER+.We provide a precise syntactic characterization of separable ER+ schemata by means of …,Information Systems,2012,26
Dynamic query optimization under access limitations and dependencies,Andrea Calı; Diego Calvanese; Davide Martinenghi,Abstract: Unlike relational tables in a database; data sources on the Web typically can onlybe accessed in limited ways. In particular; some of the source fields may be required asinput and thus need to be mandatorily filled in order to access the source. Answeringqueries over sources with access limitations is a complex task that requires a possiblyrecursive evaluation even when the query is non-recursive. After reviewing the maintechniques for query answering in this context; in this article we consider the impact offunctional and inclusion dependencies on dynamic query optimization under accesslimitations. In particular; we address the implication problem for functional dependenciesand simple full-width inclusion dependencies; and prove that it can be decided inpolynomial time. Then we provide necessary and sufficient conditions; based on the …,Journal of Universal Computer Science,2009,24
Tightly integrated probabilistic description logic programs for the Semantic Web,Andrea Calì; Thomas Lukasiewicz,Abstract We present a novel approach to probabilistic description logic programs for theSemantic Web; where a tight integration of disjunctive logic programs under the answer setsemantics with description logics is generalized by probabilistic uncertainty. The approachhas a number of nice features. In particular; it allows for a natural probabilistic dataintegration and for a natural representation of ontology mappings under probabilisticuncertainty and inconsistency. It also provides a natural integration of a situation-calculusbased language for reasoning about actions with both description logics and probabilisticuncertainty.,International Conference on Logic Programming,2007,23
Conjunctive query containment under access limitations,Andrea Calì; Davide Martinenghi,Abstract Access limitations may occur when querying data sources over the web orheterogeneous data sources presented as relational tables: this happens; for instance; inData Exchange and Integration; Data Warehousing; and Web Information Systems. Accesslimitations force certain attributes to be selected in order to access the tables. It is known thatevaluating a conjunctive query under such access restrictions amounts to evaluating apossibly recursive Datalog program. We address the problem of checking containment ofconjunctive queries under access limitations; which is highly relevant in query optimization.Checking containment in such a setting would amount to checking containment of recursiveDatalog programs of a certain class; while; for general Datalog programs; this problem isundecidable. We propose a decision procedure for query containment based on the …,International Conference on Conceptual Modeling,2008,22
Query answering under expressive entity-relationship schemata,Andrea Calì; Georg Gottlob; Andreas Pieris,Abstract We address the problem of answering conjunctive queries under constraintsrepresenting schemata expressed in an extended version of the Entity-Relationship model.This extended model; called ER+ model; comprises is-a constraints among entities andrelationships; plus functional and mandatory participation constraints. In particular; it allowsarbitrary permutations of the roles in is-a among relationships. A key notion that ensureshigh tractability in ER+ schemata is separability; ie; the absence of interaction between thefunctional participation constraints and the other constructs of ER+. We provide a precisesyntactic characterization of separable ER+ schemata; called ER±schemata; by means of anecessary and sufficient condition. We present a complete complexity analysis of theconjunctive query answering problem under ER±schemata. We show that the addition of …,International Conference on Conceptual Modeling,2010,21
Query rewriting under non-guarded rules,Andrea Calı; Georg Gottlob; Andreas Pieris,Abstract. We address the problem of answering conjunctive queries over knowledge bases;specified by sets of first-order sentences called tuple-generating dependencies (TGDs). Thisproblem is highly relevant to query optimization; information integration; and ontologicalreasoning. We present a rewriting algorithm; inspired by resolution in Logic Programming;which is capable of dealing with an expressive class of TGDs; called sticky TGDs. Given aset of sticky TGDs and a conjunctive query; the algorithm produces a first-order query thatcan be then evaluated over the data; providing the correct answers. In this way; we establishthat conjunctive query answering under sticky TGDs is in the highly tractable class ac0 in thedata complexity.,Proc. AMW,2010,21
Tightly coupled probabilistic description logic programs for the Semantic Web,Andrea Calì; Thomas Lukasiewicz; Livia Predoiu; Heiner Stuckenschmidt,Abstract We present a novel approach to probabilistic description logic programs for theSemantic Web in which disjunctive logic programs under the answer set semantics aretightly coupled with description logics and Bayesian probabilities. The approach has severalnice features. In particular; it is a logic-based representation formalism that naturally fits intothe landscape of Semantic Web languages. Tightly coupled probabilistic description logicprograms can especially be used for representing mappings between ontologies; which area common way of approaching the semantic heterogeneity problem on the Semantic Web. Inthis application; they allow in particular for resolving inconsistencies and for mergingmappings from different matchers based on the level of confidence assigned to differentrules. Furthermore; tightly coupled probabilistic description logic programs also provide a …,*,2009,19
Querying incomplete data over extended er schemata,Andrea CalÌ; Davide Martinenghi,Abstract Since Chen's Entity-Relationship (ER) model; conceptual modeling has beenplaying a fundamental role in relational data design. In this paper we consider an extendedER (EER) model enriched with cardinality constraints; disjointness assertions; and is arelations among both entities and relationships. In this setting; we consider the case ofincomplete data; which is likely to occur; for instance; when data from different sources areintegrated. In such a context; we address the problem of providing correct answers toconjunctive queries by reasoning on the schema. Based on previous results aboutdecidability of the problem; we provide a query answering algorithm that performs rewritingof the initial query into a recursive Datalog query encoding the information about theschema. We finally show extensions to more general settings.,Theory and Practice of Logic Programming,2010,17
Tractable Query Answering over Ontologies with Datalog+⁄−,Andrea Calì; Georg Gottlob; Thomas Lukasiewicz,Abstract: We present a family of expressive extensions of Datalog; called Datalog±; as a newparadigm for query answering over ontologies. The Datalog±family admits existentiallyquantified variables in rule heads; and has suitable restrictions to ensure highly efficientontology querying. In particular; we show that query answering under so-called guardedDatalog±is PTIME-complete in data complexity; and that query answering under so-calledlinear Datalog±is in AC0 in data complexity. We also show how negative constraints and ageneral class of key constraints can be added to Datalog while keeping ontology queryingtractable. We then show that linear Datalog±; enriched with a special class of keyconstraints; generalizes the well-known DL-Lite family of tractable description logics.Furthermore; the Datalog±family is of interest in its own right and can; moreover; be used …,Proceedings of the 22nd International Workshop on Description Logics ‚DL 2009 ‚Oxford ‚UK ‚July 27− 30 ‚2009,2009,16
Rule-based approaches for representing probabilistic ontology mappings,Andrea Calì; Thomas Lukasiewicz; Livia Predoiu; Heiner Stuckenschmidt,Abstract Using mappings between ontologies is a common way of approaching the semanticheterogeneity problem on the Semantic Web. To fit into the landscape of Semantic Weblanguages; a suitable logic-based representation formalism for mappings is needed; whichallows to reason with ontologies and mappings in an integrated manner; and to deal withuncertainty and inconsistencies in automatically created mappings. We analyze therequirements for such a formalism; and propose to use frameworks that integrate descriptionlogic ontologies with probabilistic rules. We compare two such frameworks and show theadvantages of using the probabilistic extensions of their deterministic counterparts. The twoframeworks that we compare are tightly coupled probabilistic dl-programs; which tightlycombine the description logics behind OWL DL resp. OWL Lite; disjunctive logic …,*,2008,15
A framework for representing ontology mappings under probabilities and inconsistency,Andrea Calı; Thomas Lukasiewicz; Livia Predoiu; Heiner Stuckenschmidt,Abstract Creating mappings between ontologies is a common way of approaching thesemantic heterogeneity problem on the SemanticWeb. To fit into the landscape of semanticweb languages; a suitable; logic-based representation formalism for mappings is needed.We argue that such a formalism has to be able to deal with uncertainty and inconsistenciesin automatically created mappings. We analyze the requirements for such a mappinglanguage and present a formalism that combines tightly integrated description logicprograms with independent choice logic for representing probabilistic information. We definethe language; show that it can be used to resolve inconsistencies and merge mappings fromdifferent matchers based on the level of confidence assigned to different rules. We alsoanalyze the computational aspects of consistency checking and query processing in …,Proceedings URSW-2007. CEUR Workshop Proceedings,2007,15
Flexible querying for SPARQL,Andrea Calì; Riccardo Frosini; Alexandra Poulovassilis; Peter T Wood,Abstract Flexible querying techniques can be used to enhance users' access toheterogeneous data sets; such as Linked Open Data. This paper extends SPARQL 1.1 withapproximation and relaxation operators that can be applied to regular expressions forquerying property paths in order to find more answers than would be returned by the exactform of a user query. We specify the semantics of the extended language and we considerthe complexity of query answering with the new operators; showing that both data and querycomplexity are not impacted by our extensions. We present a query evaluation algorithm thatreturns results incrementally according to their “distance” from the original query. We haveimplemented this algorithm and have conducted preliminary trials over the YAGO SPARQLendpoint and the Lehigh University Benchmark; showing promising performance for the …,OTM Confederated International Conferences" On the Move to Meaningful Internet Systems",2014,14
Datalog+/-: A family of languages for ontology querying,Andrea Calì; Georg Gottlob; Thomas Lukasiewicz; Andreas Pieris,Abstract In ontology-based data access; an extensional database is enhanced by anontology that generates new intensional knowledge which has to be considered whenanswering queries. In this setting; tractable data complexity (ie; complexity wrt the data only)of query answering is crucial; given the need to deal with large data sets. This papersummarizes results on a recently introduced family of Datalog-based languages; calledDatalog+/-; which is a new framework for tractable ontology querying. Plain Datalog isextended by allowing existential quantifiers; the equality predicate; and the truth constantfalse to appear in rule heads. At the same time; the resulting language is syntacticallyrestricted; so as to achieve decidability and even tractability.,*,2011,14
Interaction-based adaptation for small screen devices,Enrico Bertini; Andrea Calì; Tiziana Catarci; Silvia Gabrielli; Stephen Kimani,Abstract This paper explores an original approach to overcome current issues in the use ofmobile devices; such as limited screen space and interaction modalities; based onexploiting interface adaptation and adaptive techniques. Specifically; the paper describesthe application of this approach to a web searching prototype; which collects usage data tomodel interaction and provide a personalized version of the web facility visited by the user.,International Conference on User Modeling,2005,14
Flexible query processing for SPARQL,Riccardo Frosini; Andrea Calì; Alexandra Poulovassilis; Peter T Wood,Abstract Flexible querying techniques can enhance users' access to complex;heterogeneous datasets in settings such as Linked Data; where the user may not alwaysknow how a query should be formulated in order to retrieve the desired answers. This paperpresents query processing algorithms for a fragment of SPARQL 1.1 incorporating regularpath queries (property path queries); extended with query approximation and relaxationoperators. Our flexible query processing approach is based on query rewriting and returnsanswers incrementally according to their “distance” from the exact form of the query. Weformally show the soundness; completeness and termination properties of our queryrewriting algorithm. We also present empirical results that show promising query processingperformance for the extended language.,Semantic Web,2017,12
Querying UML class diagrams,Andrea Calì; Georg Gottlob; Giorgio Orsi; Andreas Pieris,Abstract UML Class Diagrams (UCDs) are the best known class-based formalism forconceptual modeling. They are used by software engineers to model the intensionalstructure of a system in terms of classes; attributes and operations; and to expressconstraints that must hold for every instance of the system. Reasoning over UCDs is ofparamount importance in design; validation; maintenance and system analysis; however; formedium and large software projects; reasoning over UCDs may be impractical. Queryanswering; in particular; can be used to verify whether a (possibly incomplete) instance ofthe system modeled by the UCD; ie; a snapshot; enjoys a certain property. In this work; westudy the problem of querying UCD instances; and we relate it to query answering underguarded Datalog±; that is; a powerful Datalog-based language for ontological modeling …,International Conference on Foundations of Software Science and Computational Structures,2012,12
An approach to probabilistic data integration for the semantic web,Andrea Calì; Thomas Lukasiewicz,Abstract Probabilistic description logic programs are a powerful tool for knowledgerepresentation in the Semantic Web; which combine description logics; normal programsunder the answer set or well-founded semantics; and probabilistic uncertainty. The task ofdata integration amounts to providing the user with access to a set of heterogeneous datasources in the same fashion as when querying a single database; that is; through a globalschema; which is a common representation of all the underlying data sources. In this paper;we make use of probabilistic description logic programs to model expressive dataintegration systems for the Semantic Web; where constraints are expressed both over thedata sources and the global schema. We describe different types of probabilistic dataintegration; which aim especially at applications in the Semantic Web.,*,2008,12
Source integration for data warehousing,Andrea Cal; Domenico Lembo; Maurizio Lenzerini; Riccardo Rosati,ABSTRACT While the main goal of a data warehouse is to provide support for data analysisand management's decisions; a fundamental aspect in design of a data warehouse systemis the process of acquiring the raw data from a set of relevant information sources. We willcall source integration system the component of a data warehouse system dealing with thisprocess. The main goal of a source integration system is to deal with the transfer of data fromthe set of sources constituting the application-oriented operational environment; to the datawarehouse. Since sources are typically autonomous; distributed; and heterogeneous; thistask has to deal with the problem of cleaning; reconciling;,Multidimensional Databases: Problems and Solutions: Problems and Solutions,2002,12
Querying incomplete data with logic programs: ER strikes back,Andrea Calì,Abstract Since Chen's Entity-Relationship (ER) model; conceptual modelling has beenplaying a fundamental role in relational data design. In this paper we consider an extendedER model enriched with cardinality constraints; disjunction assertions; and is-a relationsamong both entities and relationships; we present a framework in which the data underlyingan ER schema can be directly queried through the schema by using suitable predicates. Inthis setting; we consider the case of incomplete data; which is likely to happen; for instance;when data from different sources are integrated. We address the problem of providingcorrect answers to conjunctive queries by reasoning on the schema. Based on previousresults about decidability of the problem; we provide a query answering algorithm based onrewriting the initial query into a recursive Datalog query; in which the information about …,International Conference on Conceptual Modeling,2007,10
IBIS: Data integration at work,Andrea Calı; Diego Calvanese; Giuseppe De Giacomo; Maurizio Lenzerini; Paolo Naggar; Fabio Vernacotola,Abstract. We present IBIS (Internet-Based Information System); a system for the semanticintegration of heterogeneous data sources. IBIS adopts innovative and state-of-the-artsolutions to deal with all aspects of a complex data-integration environment; includingsource wrapping; limitations on source access; and query answering under integrityconstraints.,Proc. of SEBD,2002,10
Optimized querying of integrated data over the Web,Andrea Calì; Diego Calvanese,Abstract Information Integration is the problem of providing a uniform access to multiple andheterogeneous data sources. The most common approach to this task; called global-as-view; consists in providing a global schema of the data; in which each relation is defined asa view over a set of data sources. Recent works deal with this problem in the case of limitedsource capabilities; where; in general; sources can only be accessed respecting certainbinding patterns for their attributes. In this case; computing the answer to a user query overthe global schema cannot be done by simply substituting the concepts appearing in thequery with their definitions. Instead; it may require the evaluation of a suitable recursiveDatalog program. In this paper we study the evaluation of conjunctive queries in the global-as-view approach with limited source capabilities. We first present an algorithm for …,*,2002,10
On the interaction of existential rules and equality constraints in ontology querying,Andrea Calì; Georg Gottlob; Giorgio Orsi; Andreas Pieris,Abstract Ontological query processing is an exciting research topic in database theory;knowledge representation; and logic programming. In many cases; ontological constraintsare expressed over an extensional database by extending traditional Datalog rules to allowexistential quantification and equality atoms in the head. The unrestricted use of thesefeatures causes undecidability of query answering and; therefore; their interaction must becontrolled. This work provides a tutorial-like introduction to the problem of query answeringunder existential and equality constraints. We survey the most notable (semantic andsyntactic) restrictions to such constraints ensuring decidability of query answering; and wediscuss their practical application to conceptual modelling.,*,2012,9
A logical toolbox for ontological reasoning,Andrea Calì; Georg Gottlob; Thomas Lukasiewicz; Andreas Pieris,Abstract In ontology-enhanced database systems; an ontology on top of the extensionaldatabase expresses intensional knowledge that enhances the database schema. Queriesposed to such systems are to be evaluated considering all the knowledge inferred from thedata by means of the ontology; in other words; queries are to be evaluated against thelogical theory constituted by the data and the ontology. In this context; tractability of queryanswering is a central issue; given that the data size is normally very large. This papersurveys results on a recently introduced family of Datalog-based languages; calledDatalog+/-; which is a useful logical toolbox for ontology modeling and for ontology-basedquery answering. We present different Datalog+/-languages and related complexity results;showing that Datalog+/-can be successfully adopted due to its clarity; expressiveness and …,ACM Sigmod Record,2011,9
Querying conceptual schemata with expressive equality constraints,Andrea Calì; Georg Gottlob; Andreas Pieris,Abstract When querying data through a conceptual schema or ontology; we computeanswers entailed by the logical theory constituted by the data plus the conceptual schema.Traditional database constraints like tuple-generating dependencies (TGDs) and equality-generating dependencies (EGDs) are a useful tool for ontology specification. However; theirinteraction leads to undecidability of query answering even in simple cases. In this paper weexhibit a novel and general class of EGDs that; together with a relevant class of TGDs;ensures decidability of query answering. Our results capture well-known ontologylanguages as special cases; in particular; they allow us to deal with extended Entity-Relationship schemata enriched with expressive equality constraints.,International Conference on Conceptual Modeling,2011,9
Containment of conjunctive queries over conceptual schemata,Andrea Calì,Abstract Conceptual Modelling plays a fundamental role in database design since Chen'sEntity-Relationship (ER) model. In this paper we consider a conceptual model capable ofcapturing classes of objects with their attributes; relationships among classes; cardinalityconstraints in the participation of entities to relationships; and is-a relations among bothclasses and relationships. We provide a formal semantics for such model in terms ofpredicates and constraints over their extensions. We address the problem of containment ofconjunctive queries over a conceptual schema; and we show an algorithm for solving theproblem; that achieves better computational complexity than the techniques found in theliterature. The results presented here are directly applicable in query answering onincomplete databases; and in data integration under constraints.,International Conference on Database Systems for Advanced Applications,2006,9
A comprehensive semantic framework for data integration systems,Andrea Calì; Domenico Lembo; Riccardo Rosati,Abstract A data integration system provides the user with a unified view; called globalschema; of the data residing at different sources. Users issue their queries against the globalschema; and the system computes answers to queries by suitably accessing the sources;through the mapping; ie; the specification of the relationship between the global schema andthe sources. Since sources are in general autonomous subsystems; the informationprovided by the data at the sources and the mapping is likely not to be consistent with theknowledge expressed by the global schema. Therefore; the question arises of how tointerpret user queries in such a situation; ie; in the presence of data contradicting the globalschema and the mapping. In this paper; we provide an in-depth analysis of the problem ofdealing with inconsistencies in data integration systems. In this respect; we highlight the …,Journal of Applied Logic,2005,9
Experimenting data integration with DIS@ DIS,Andrea Calì; Domenico Lembo; Riccardo Rosati; Marco Ruzzi,Abstract Data integration consists in providing a uniform access to a set of heterogeneoussources through a common representation called global schema. In this paper we presentDIS@ DIS; a data integration system that adopts innovative techniques for query answeringin a complex integration environment. In particular; DIS@ DIS is able to deal with integrityconstraints; which are used to enhance the expressiveness of the global schema. Since dataat the sources may not satisfy the constraints; DIS@ DIS is capable of reasoning in thepresence of incomplete and inconsistent information; so as to provide consistent answers touser queries. Moreover; DIS@ DIS is able to deal with both local-as-view and global-as-viewapproaches for the specification of the mapping between the global schema and thesources. DIS@ DIS incorporates novel optimization techniques for query processing …,International Conference on Advanced Information Systems Engineering,2004,9
A Hybrid Approach to Query Answering Under Expressive Datalog $ $^\pm $ $,Mostafa Milani; Andrea Calì; Leopoldo Bertossi,Abstract Datalog^ ± is a family of ontology languages that combine good computationalproperties with high expressive power. Datalog^ ± languages are provably able to capturemany relevant Semantic Web languages. In this paper we consider the class of weakly-sticky (WS) Datalog^ ± programs; which allow for certain useful forms of joins in rule bodiesas well as extending the well-known class of weakly-acyclic TGDs. So far; onlynondeterministic algorithms were known for answering queries on WS Datalog^ ± programs.We present novel deterministic query answering algorithms under WS Datalog^ ±. Inparticular; we propose:(1) a bottom-up grounding algorithm based on a query-driven chase;and (2) a hybrid approach based on transforming a WS program into a so-called sticky one;for which query rewriting techniques are known. We discuss how our algorithms can be …,International Conference on Web Reasoning and Rule Systems,2016,8
On separability of ontological constraints,Andrea Calı; Marco Console; Riccardo Frosini,Abstract. When data schemata are enriched with expressive constraints that aim atrepresenting the domain of interest; in order to answer queries one needs to consider thelogical theory consisting of both the data and the constraints. Query answering in such acontext is called ontological query answering. Commonly adopted database constraints inthis field are tuple-generating dependencies (TGDs) and equalitygenerating dependencies(EGDs). It is well known that their interaction leads to intractability or undecidability of queryanswering even in the case of simple subclasses. Several conditions have been found toguarantee separability; that is lack of interaction; between TGDs and EGDs. Separabilitymakes EGDs (mostly) irrelevant for query answering and therefore often guaranteestractability; as long as the theory is satisfiable. In this paper we review the two notions of …,*,2013,8
Optimization of query plans in the presence of access limitations,Andrea Calı; Diego Calvanese; Davide Martinenghi,Abstract. We consider the problem of querying data sources that have limited capabilitiesand can thus only be accessed by complying with certain binding patterns for their attributes.This is often the case; eg; in the context of data on the web queryable via web forms as wellas in legacy data wrapped in relational tables. In such contexts; computing the answer to auser query cannot be done as in a traditional database; instead; a query plan is needed thattakes the access limitations into account. In this paper; we develop a technique forproducing a (possibly recursive) Datalog program that retrieves all obtainable answers for aquery with limited source capabilities. In particular; we improve with respect to a previouslypublished algorithm for optimizing query answering for conjunctive queries. Furthermore; weextend it to the context of unions of conjunctive queries. The algorithm exploits the …,EROW,2007,8
Semistructured data schemas with expressive constraints,Andrea Calı; Diego Calvanese; Maurizio Lenzerini,Abstract Recently; there have been several proposals of formalisms for modelingsemistructured data; which is data that is neither raw; nor strictly typed as in conventionaldatabase systems. Semistructured data models are graph-based models; where graphs areused to represent both databases and schemas. We study the basic problem of schemasubsumption; which amounts to check whether all databases conforming to a schema alsoconform to another schema; in the presence of constraints; which are used to enforceadditional conditions on databases. In particular; we study the relationship between variousconstraint languages and the basic property of locality; which allows one to checksubsumption between schemas in polynomial time in the number of nodes of the schemas.We show that locality holds when both numeric constraints and disjunction are added to a …,*,2000,8
Datalog extensions for tractable query answering over ontologies,Andrea Calì; Georg Gottlob; Thomas Lukasiewicz,Abstract We survey a recently introduced family of expressive extensions of Datalog; calledDatalog±; which is a new framework for representing ontologies in the form of integrityconstraints; and for query answering under such constraints. Datalog±is derived fromDatalog by allowing existentially quantified variables in rule heads; and by enforcingsuitable properties in rule bodies; to ensure decidable and efficient query answering. Wefirst present different languages in the Datalog±family; providing tight complexity bounds fornearly all cases. We then show that such languages are general enough to capture the mostcommon tractable ontology languages. In particular; Datalog±can express the DL-Lite familyof description logics and F-Logic Lite. Datalog±is a natural and very general framework thatcan be employed in different contexts such as data integration and exchange.,*,2010,7
Query answering by rewriting in GLAV data integration systems under constraints,Andrea Calì,Abstract In the Semantic Web; the goal is offering access to information that is distributedover the Internet. Data integration is highly relevant in this context; since it consists inproviding a uniform access to a set of data sources; through a unified representation of thedata called global schema. Integrity constraints (ICs) are expressed on the global schema inorder to better represent the domain of interest; yet such constraints may not be satisfied bythe data at the sources. In this paper we address the problem of answering queries posed toa data integration system where the mapping is specified in the so-called GLAV approach;and when tuple-generating dependencies (TGDs) and functional dependencies (FDs) areexpressed over the global schema. We extend previous results by first showing that; in thecase of TGDs without FDs; known query rewriting techniques can be applied in a more …,International Workshop on Semantic Web and Databases,2004,7
Ontological reasoning with F-Logic Lite and its extensions,Andrea Calı; Georg Gottlob; Michael Kifer; Thomas Lukasiewicz; Andreas Pieris,Answering queries posed over knowledge bases is a central problem in knowledgerepresentation and database theory. In the database area; checking query containment is animportant query optimization and schema integration technique (Aho; Sagiv; and Ullman1979; Johnson and Klug 1984). In knowledge representation it has been used for objectclassification; schema integration; service discovery; and more. In the presence of aknowledge base; the problem of query containment is strictly related to that of queryanswering; indeed; the two are reducible to each other (Calı; Gottlob; and Kifer 2008b); wefocus on the latter; and our results immediately extend to the former. A practically relevantinstance of the query containment problem was first studied in (Johnson and Klug 1984) forfunctional and inclusion dependencies; and later; for instance; in (Calvanese; Giacomo …,Proc. of AAAI (to appear; 2010),2010,6
On equality-generating dependencies in ontology querying–Preliminary report,Andrea Calı; Andreas Pieris,Abstract. In ontology-based data access; data are queried through an ontology that offers arepresentation of the domain of interest. In this context; correct answers are those entailedby the logical theory constituted by the data and the ontology. Traditional databaseconstraints like tuple-generating dependencies (TGDs) and equality-generatingdependencies (EGDs) are a useful tool for ontology specification. However; their interactionusually leads to intractability or undecidability of query answering; separability is the notionthat captures the lack of interaction between TGDs and EGDs. In this paper we exhibit anovel and general sufficient condition for separability; in the case where the ontology isexpressed with inclusion dependencies (a subclass of TGDs) and EGDs.,Proc. of AMW,2011,5
An ontology-based approach to information retrieval,Ana Meštrović; Andrea Calì,Abstract We define a general framework for ontology-based information retrieval (IR). In ourapproach; document and query expansion rely on a base taxonomy that is extracted from alexical database or a Linked Data set (eg WordNet; Wiktionary etc.). Each term from adocument or query is modelled as a vector of base concepts from the base taxonomy. Wedefine a set of mapping functions which map multiple ontological layers (dimensions) ontothe base taxonomy. This way; each concept from the included ontologies can also berepresented as a vector of base concepts from the base taxonomy. We propose a generalweighting schema which is used for the vector space model. Our framework can thereforetake into account various lexical and semantic relations between terms and concepts (egsynonymy; hierarchy; meronymy; antonymy; geo-proximity; etc.). This allows us to avoid …,Semanitic Keyword-based Search on Structured Data Sources,2016,4
Peer-to-peer semantic integration of linked data,Mirko Michele Dimartino; Andrea Calì; Alexandra Poulovassilis; Peter T Wood,We propose a framework for peer-based integration of linked data sets; where the semanticrelationships between data at different peers are expressed through mappings. We providethe theoretical foundations for such a setting and we devise an algorithm for processinggraph pattern queries; discussing its complexity and scalability.,CEUR Workshop Proceedings,2015,4
Recommendation of text tags in social applications using linked data,Andrea Calì; Stefano Capuzzi; Mirko Michele Dimartino; Riccardo Frosini,Abstract We present a recommender system that suggests geo-located text tags by usinglinguistic information extracted from Linked Data sets available on the Web. Therecommender system performs tag matching by measuring the semantic similarity of naturallanguage texts. Our approach evaluates similarity using a technique that comparessentences taking into account their grammatical structure.,International Conference on Web Engineering,2013,4
Tightly integrated probabilistic description logic programs,Andrea Cali; Thomas Lukasiewicz,Abstract. We present a novel approach to probabilistic description logic programs for theSemantic Web; which constitutes a tight combination of disjunctive logic programs under theanswer set semantics with both description logics and Bayesian probabilities. The approachhas a number of nice features. In particular; it allows for a natural probabilistic dataintegration; where probabilities over possible worlds may be used as trust; error; or mappingprobabilities. Furthermore; it also provides a natural integration of a situation-calculus basedlanguage for reasoning about actions with both description logics and Bayesianprobabilities. We show that consistency checking and query processing are decidable resp.computable; and that they can be reduced to consistency checking resp. cautious/bravereasoning in tightly integrated disjunctive description logic programs. We also analyze the …,Report INFSYS RR-1843-07-05; Institut für Informationssysteme; TU Wien (March 2007),2007,4
Techniques for ontology design and maintenance,F Baader; R Bernardi; D Calvanese; A Calı; B Cuenca Grau; M Garcia; G De Giacomo; A Kaplunova; O Kutz; D Lembo; M Lenzerini; L Lubyte; C Lutz; M Milicic; R Möller; B Parsia; R Rosati; U Sattler; B Sertkaya; S Tessaris; C Thorne; AY Turhan,Workpackage 3 of the TONES project is concerned with automated reasoning support ofontology design and maintenance. As discussed in much more detail in the previousdeliverable [LLS06]; such support is needed to assist the ontology designer in carrying out aprincipled and systematic design-process; and to ensure that the resulting ontology is well-structured and useful for the intended application. To maintain the high-quality structurethroughout the whole ontology life-cycle; it is additionally necessary to carry outmaintenance and evolution in a structured and systematic way. Also here; support providedby automated reasoning tools can be of tremendous benefit. In the deliverable [LLS06]; wehave identified and described the tasks that play a crucial role during ontology design andmaintenance. We have also identified services that should be offered by ontology design …,Project Report of Ontology Design and Maintenance at Technische Universit at Dresden,2007,4
Query optimisation for web data sources: minimisation of the number of accesses,Andrea Calı; Davide Martinenghi; Domenico Carbotta,Abstract. When relational data have access constraints that require certain attributes to beselected in queries; as in the case of (wrapped) Web sources accessible via forms; arecursive query plan is needed to answer queries at best. We present a query planoptimisation technique for several classes of queries that minimises the number of accessesaccording to a novel; strong notion of minimality. We provide experimental evidence of theeffectiveness of our technique.,Proceedings of the Fifteenth Italian Symposium on Advanced Database Systems; SEBD,2007,4
Reference architecture and framework,M Adorni; F Arcelli; S Bandini; L Baresi; C Batini; A Bianchi; D Bianchini; M Brioschi; A Caforio; A Cali; P Cappellari; C Cappiello; T Catarci; A Corallo; V De Antonellis; C Franza; G Giunta; A Limonta; G Lorenzo; P Losi; A Maurino; M Melideo; D Micucci; S Modafferi; E Mussi; L Negri; C Pandolfo; B Pernici; P Plebani; D Ragazzi; C Raibulet; M Riva; N Simeoni; C Simone; G Solazzo; F Tisato; R Torlone; G Vizzari; A Zilli,The goal of the MAIS system is to provide support for flexible and adaptive execution ofapplications in a distributed; multichannel; mobile information system. In such a system; afundamental requirement is an ability to describe the continuously evolving executionenvironment and user characteristics. Service requests are therefore satisfied byconsidering both the request itself and its provisioning environment. The first part of thischapter presents the general architecture of the MAIS system. The MAIS architecture allowsus to define a set of “pluggable” modules which can be composed to provide adaptivity atdifferent levels in the MAIS system. The main architectural components are introduced inSect. 2.2; more details of the components are provided in the rest of the book. The MAISreference framework; illustrated in the second part of this chapter; provides the essential …,*,2006,4
IM3: A system for matchmaking in mobile environments,Andrea Calì,Abstract In this paper we present IM3 (Intelligent Mobile MatchMaker); a system thatrecommends tourist events to users. The system; based on a centralised server andaccessible through mobile devices; matches user preferences (demand) with descriptions oftourist events (supply); in order to provide the user with information about the events thathe/she is likely to be interested in. User and event descriptions in IM3 are represented with aformalism borrowed from AI and based on Description Logics; such descriptions are allowedto be incomplete in the parts that are considered irrelevant by the demander/supplier. Thealgorithms implemented in IM3 are able to deal with both conflicting and missing informationbetween user and event profiles. Motivated by the nature of its application domain; IM3 canoperate in a location-based fashion: it can provide the user with information related to …,International Conference on Knowledge-Based and Intelligent Information and Engineering Systems,2005,4
DIS@ DIS: A system for semantic data integration under integrity constraints,Andrea Calì; Saverio De Nigris; Domenico Lembo; Gabriele Messineo; Riccardo Rosati; Marco Ruzzi,The recent developments of computer and telecommunication technology; such as theexpansion of the Internet and the World Wide Web; have made available to users a hugenumber of information sources; generally autonomous; heterogeneous and widelydistributed. As a consequence; information integration has emerged as a crucial issue inmany application domains; eg; distributed databases; cooperative information systems; datawarehousing; as well as in accessing distributed data over the Web.,Web Information Systems Engineering; 2003. WISE 2003. Proceedings of the Fourth International Conference on,2003,4
Non-FPT lower bounds for structural restrictions of decision DNNF,Andrea Calì; Florent Capelli; Igor Razgon,Abstract: We give a non-FPT lower bound on the size of structured decision DNNF andOBDD with decomposable AND-nodes representing CNF-formulas of bounded incidencetreewidth. Both models are known to be of FPT size for CNFs of bounded primal treewidth.To the best of our knowledge this is the first parameterized separation of primal treewidthand incidence treewidth for knowledge compilation models. Subjects: Artificial Intelligence(cs. AI); Computational Complexity (cs. CC) Cite as: arXiv: 1708.07767 [cs. AI](or arXiv:1708.07767 v1 [cs. AI] for this version) Submission history From: Florent Capelli [viewemail][v1] Fri; 25 Aug 2017 15: 05: 22 GMT (19kb),arXiv preprint arXiv:1708.07767,2017,3
Keyword queries over the deep web,Andrea Calì; Davide Martinenghi; Riccardo Torlone,Abstract The Deep Web is constituted by data that are accessible through Web pages; butnot indexable by search engines as they are returned in dynamic pages. In this paper wepropose a conceptual framework for answering keyword queries on Deep Web sourcesrepresented as relational tables with so-called access limitations. We formalize the notion ofoptimal answer and characterize queries for which an answer can be found.,International Conference on Conceptual Modeling,2016,3
Exposing open street map in the linked data cloud,Vito Walter Anelli; Andrea Calì; Tommaso Di Noia; Matteo Palmonari; Azzurra Ragone,Abstract After the mobile revolution; geographical knowledge has getting more and moreimportance in many location-aware application scenarios. Its popularity influenced also theproduction and publication of dedicated datasets in the Linked Data (LD) cloud. In fact; itsmost recent representation shows Geonames competing with DBpedia as the largest andmost linked knowledge graph available in the Web. Among the various projects related tothe collection and publication of geographical information; as of today; Open Street Map(OSM) is for sure one of the most complete and mature one exposing a huge amount of datawhich is continually updated in a crowdsourced fashion. In order to make all this knowledgeavailable as Linked Data; we developed LOSM: a SPARQL endpoint able to query the dataavailable in OSM by an on-line translation form syntax to a sequence of calls to the OSM …,International Conference on Industrial; Engineering and Other Applications of Applied Intelligent Systems,2016,3
Methods and tools for the development of adaptive applications,Riccardo Torlone; T Barbieri; E Bertini; A Bianchi; M Billi; D Bolchini; S Bruna; L Burzagli; A Calì; T Catarci; S Ceri; F Daniel; R De Virgilio; F Facca; F Gabbanini; S Gabrielli; G Giunta; P Graziani; S Kimani; M Legnani; L Mainetti; M Matera; E Palchetti; D Presenza; G Santucci; L Sbattella; N Simeoni,The number and the spread of nontraditional devices able to provide access to the Webeverywhere and anytime are increasing day by day. These devices include not only cellularphones; PDAs; and terminals for disabled people; but also new kinds of devices; possiblyembedded into objects such as household appliances or vehicle dashboards. Thecharacteristics of the various devices are so different that the issues related to deliveringinformation and services on the Web involve not only presentational aspects; but alsostructural and navigational aspects. As an example consider a cellular phone: its limitedcomputing capabilities require that information be filtered and organized as a collection ofatomic units whose dimensions depend closely on specific features of the device. It turns outthat a novel and fundamental requirement in this scenario is the system's ability to adapt …,*,2006,3
Smartdate: User Adaptation in Location-based Mobile matchmaking,M Berghell; Andrea Capata; Tiziana Catarci; Paolo Cerrocchi; Paolo Masi; Marco Oppedisano; Amiliano Trevisani; Andrea Vitaletti; Andrea Calì,Abstract. The problem of matching user profiles arises in several applications wheredemand and supply profiles need to be matched; eg; in information systems for recruitment;real estate; or dating agencies. In this paper we present SmartDate; a system that matchesprofiles of users that need to be matched for dating. The system runs on mobile devices andoperates in multichannel mode; the matches take into account the location of the user at thetime he/she issues a query. The matchmaking technique implemented in our system usesrigorous logic formalisms and is based on formal reasoning tasks. Since the best results arepresented to the user at each query issued to the system; the technique allows for a user-based adaptation of the interface offered by the system; thus making possible anoptimization of the small screen space available in mobile devices.,International Workshop on Plastic Services for Mobile Devices; Rome; Italy,2005,3
Designing adaptable multidevice applications,Giorgio Ausiello; Enrico Bertini; A Calı; Tiziana Catarci; Stephen Kimani; Giuseppe Santucci,*,MAIS project report,2003,3
Query Rewriting under Linear $ $\mathcal {EL} $ $ Knowledge Bases,Mirko M Dimartino; Andrea Calì; Alexandra Poulovassilis; Peter T Wood,Abstract With the adoption of the recent SPARQL 1.1 standard; RDF databases are capableof directly answering more expressive queries than simple conjunctive queries. In this paperwe exploit such capabilities to answer conjunctive queries (CQs) under ontologiesexpressed in the description logic called linear EL^ ℓ in; a restricted form of EL. In particular;we show a query answering algorithm that rewrites a given CQ into a conjunctive regularpath query (CRPQ) which; evaluated on the given instance; returns the correct answer. Ourtechnique is based on the representation of infinite unions of CQs by non-deterministic finite-state automata. Our results achieve optimal data complexity; as well as producing rewritingsstraightforwardly implementable in SPARQL 1.1.,International Conference on Web Reasoning and Rule Systems,2016,2
Keyword search in the deep web,Andrea Calì; Davide Martinenghi; Riccardo Torlone,The Deep Web is constituted by data accessible through Web pages; but not readilyindexable by search engines; as they are returned in dynamic pages. In this paper wepropose a framework for accessing Deep Web sources; represented as relational tables withso-called ac-cess limitations; with keyword-based queries. We formalize the notion ofoptimal answer and investigate methods for query processing. To our knowledge; thisproblem has never been studied in a systematic way.,CEUR Workshop Proceedings,2015,2
Deep separability of ontological constraints,Andrea Calì; Marco Console; Riccardo Frosini,Abstract: When data schemata are enriched with expressive constraints that aim atrepresenting the domain of interest; in order to answer queries one needs to consider thelogical theory consisting of both the data and the constraints. Query answering in such acontext is called ontological query answering. Commonly adopted database constraints inthis field are tuple-generating dependencies (TGDs) and equality-generating dependencies(EGDs). It is well known that their interaction leads to intractability or undecidability of queryanswering even in the case of simple subclasses. Several conditions have been found toguarantee separability; that is lack of interaction; between TGDs and EGDs. Separabilitymakes EGDs (mostly) irrelevant for query answering and therefore often guaranteestractability; as long as the theory is satisfiable. In this paper we review the two notions of …,arXiv preprint arXiv:1312.5914,2013,2
The Return of the Entity-Relationship Model: Ontological Query Answering,Andrea Calì; Georg Gottlob; Andreas Pieris,Abstract The Entity-Relationship (ER) model is a fundamental tool for database design;recently extended and employed in knowledge representation and reasoning due to itsexpressiveness and comprehensibility. We present an extension of the ER model; calledER+; which is particularly suitable for ontology modeling; as well as being flexible andcomprehensible. Our model comprises is-a constraints among entities and relationships;plus functional and mandatory participation constraints. In particular; it allows for arbitrarypermutations of the roles in is-a among relationships. We argue that ER-based languagescan be profitably used in ontology-enhanced database systems; where queries areevaluated against the union of a database instance and an ontology; which constitute alogical theory. In such systems; the instance has usually large size; therefore ensuring …,*,2012,2
Generating preview Instances for the face validation of entity-relationship schemata: the acyclic case,Maria Amalfi; Alessandro Artale; Andrea Calì; Alessandro Provetti,Abstract We describe a mapping of Extended Entity-Relationship schemata to Answer SetProgramming that allows us to generate informative example instances of the relationaldatabase that is implied by the conceptual schema. Such instances may be submitted topeople involved in the requirements phase as a glimpse of what instances are allowed bythe ER schema at hand; thus enhancing database comprehension and so-called facevalidation.,International Conference on Database Systems for Advanced Applications,2011,2
Logic in databases: report on the LID 2008 workshop,Andrea Calì; Laks VS Lakshmanan; Davide Martinenghi,Andrea Calì Oxford-Man Institute of Quantitative Finance University of Oxford WolfsonBuilding; Parks Road Oxford OX1 3QD United Kingdom andrea.cali@comlab.ox.ac.uk … LaksVS Lakshmanan Dept. of Computer Science University of British Columbia 2366 Main MallVancouver; BC Canada V6T 1Z4 laks@cs.ubc.ca … Davide Martinenghi Dip. di Elettr. e InformazionePolitecnico di Milano Via Ponzio; 34/5 I-20133 Milano Italy martinen@elet.polimi.it … 1. INTRODUCTIONThe Logic in Databases (LID'08) workshop was held at the DIS department of “La Sapienza”university; Rome; Italy; between May 19-20; 2008 … LID'08 was established as a forum for bringingtogether re- searchers and practitioners; from the academia and the in- dustry; who are focusingon all logical aspects of data man- agement … LID'08 was a confluence of three successfulpast events … • LID'96; an international workshop on Logic in Databases; which LID'08 …,ACM SIGMOD Record,2010,2
Selected papers from the Logic in Databases Workshop 2008,Andrea Calì; Laks VS Lakshmanan; Davide Martinenghi,*,*,2010,2
Checking Containment of Schema Mappings (Preliminary Report),Andrea Calì; Riccardo Torlone,Abstract. In data exchange; data are materialised from a source schema to a target schema;according to suitable source-to-target constraints. Constraints are also expressed on thetarget schema to represent the domain of interest. A schema mapping is the union of thesource-to-target and of the target constraints. In this paper; we address the problem ofcontainment of schema mappings for data exchange; which has been recently proposed inthis framework as a step towards the optimization of data exchange settings. We refer to anatural notion of containment that relies on the behaviour of schema mappings with respectto conjunctive query answering; in the presence of so-called LAV TGDs as target constraints.Our contribution is a practical technique for testing the containment based on the existenceof a homomorphism between special “dummy” instances; which can be easily built from …,*,2009,2
On the containment of schema mappings,Andrea Calì; Riccardo Torlone,Birkbeck; University of London logo. BIROn - Birkbeck Institutional Research Online …,*,2008,2
Optimising query answering in the presence of access limitations (position paper),Andrea Cali; Diego Calvanese,Relational data may have access limitations; ie; relations may require certain attributes to beselected when they are accessed; this happens; for instance; while querying Web datasources (wrapped in relational form) or legacy databases. It is known that the evaluation of aconjunctive query under access limitations requires a recursive algorithm that is encodedinto a Datalog program. In this paper we consider the problem of optimising queryanswering in this setting; where the query language is that of conjunctive queries. We reviewsome optimisation techniques for this problem; that aim to reduce the number of accesses tothe data in the query plan. Then we argue that checking query containment is necessary inthis case for achieving effective query optimisation. Checking containment in the presence ofaccess limitations would amount to check containment of recursive DATALOG programs …,Database and Expert Systems Applications; 2006. DEXA'06. 17th International Workshop on,2006,2
Containment of conjunctive queries under access limitations,Andrea Calı; Diego Calvanese,Abstract. Relational data may have access limitations; ie; relations may require certainattributes to be selected when they are accessed; this happens; for instance; while queryingweb data sources (wrapped in relational form) or legacy databases. It is known that theevaluation of a conjunctive query under access limitations requires a recursive algorithmthat is encoded into a Datalog program. In this paper we address the problem ofcontainment of conjunctive queries under access limitations; which is highly relevant inquery optimization. Checking containment in this case would amount to check containmentof recursive Datalog programs; which is undecidable in general. We show however; that dueto the specific form of the Datalog programs resulting from encoding access limitations; thecontainment problem is in fact decidable. We provide a decision procedure based on …,Proc. of SEBD,2006,2
State of the art survey,A Calı; D Calvanese; B Cuenca Grau; G De Giacomo; D Lembo; M Lenzerini; C Lutz; D Milano; R Möller; A Poggi; U Sattler,Abstract Ontologies are formalism whose purpose is to support humans or machines toshare some common knowledge in a structured way. They allow the concepts and termsrelevant to a given domain to be identified and defined in an unambiguous way. As such;ontologies are seen as the key technology used to describe the semantics of information atvarious sites; overcoming the problem of implicit and hidden knowledge and thus enablingexchange of semantic contents. In this report we survey the work on ontologies that hasbeen carried out in recent years. In particular; we first overview the languages that havebeen proposed for representing ontologies; and present the work on reasoning overontologies. We then overview the work on ontologies from four different points of view:(i) Wesurvey methodologies for designing and maintaining ontologies; presenting automated …,*,2005,2
Intensional query processing in data integration systems under integrity constraints.,Andrea Calì; Domenico Lembo; Riccardo Rosati,*,SEBD,2003,2
Integration of deep web sources: a distributed information retrieval approach,Andrea Calì; Umberto Straccia,Abstract The Deep Web consists of those structured data that are available as dynamicallygenerated pages; typically requested through HTML forms. Deep Web pages cannot beindexed by search engines; and are notoriously difficult to query and integrate due to thelimited access that they offer. We propose a novel framework for integrating Deep Websources by means of a mediated schema that represent the underlying; distributed sources.Our goal is to compute answers to queries posed on the mediated schema. To this aim; wepropose the use of techniques from the area of Distributed Information Retrieval. We discussa novel approach to automated sampling; size estimation and selection of Deep Websources; as well as a technique for merging result lists.,Proceedings of the 7th International Conference on Web Intelligence; Mining and Semantics,2017,1
Querying the Deep Web: Back to the Foundations,Andrea Calı; Davide Martinenghi; Igor Razgon; Martın Ugarte,Abstract. The Deep Web is the large corpus of data accessible on the Web through formsand presented in dynamically-generated pages; but not indexable as static pages; andtherefore invisible to search engines. Deep Web data are usually modelled as relations withso-called access limitations; that is; they can be queried only by selecting certain attributes.In this paper we give some fundamental complexity results on the problem of processingconjunctive (select-project-join) queries on relational data with access limitations.,Proc. of AMW,2017,1
Implementing eer-to-eer Semantic Integration of Linked Data,Mirko M Dimartino; Andrea Calì; Alexandra Poulovassilis; Peter T Wood,Abstract The World Wide Web has expanded from a network of hyper-linked documents to amore complex structure where both documents and data are easily published; consumedand reused. Ideally; users should be able to access this information as a single; global dataspace. However; Linked Data on the Web is highly heterogeneous: different datasets maydescribe overlapping domains; using different approaches to data modelling and naming. Asingle global ontological conceptualisation is impracticable; and instead a more extensibleapproach is needed for semantic integration of heterogeneous Linked Data sets into aglobal data space.,British International Conference on Databases,2015,1
Data integration with many heterogeneous sources and dynamic target schemas,Luigi Bellomarini; Paolo Atzeni; Luca Cabibbo; A Cali; ME Vidal,Information integration is the general problem that arises in applications that need toconsolidate (in a virtual or materialized way) data coming from different sources [9; Ch. 21].In this paper; we consider a scenario for data integration; very common in practice; for whichexisting solutions are not effective. We refer to those applications where there are many(dozens or hundreds or even more) sources; in the same domain; that have to contribute toone; single global (“target”) system. A common case is that of “central” organizations thatreceive data from a large set of “local” companies or administrations; a specific case is thatof a national central bank that receives data from all the banks in the country. This scenariois often handled by imposing to all local sources an exchange format; so that data aretransferred to the central institution in a standardized form. In some cases; this solution is …,Alberto Mendelzon International Workshop on Foundations of Data Management,2015,1
A Framework for Conjunctive Query Answering over Distributed Deep Web Information Resources.,Andrea Calì; Umberto Straccia,Abstract. Deep Web Information Resources (DWIRs) are data that are accessible throughweb forms but are not indexable by search engines. We propose a novel framework to tacklethe problem of conjunctive query (CQ) answering over a mediated schema in which the localresources are DWIR. To this aim; we propose to use techniques from the field of DistributedInformation Retrieval (DIR). We discuss a novel approach to automated DWIR sampling;size estimation and selection; as well as an approach to result list merging.,SEBD,2015,1
Complexity of Conjunctive Query Answering under Access Limitations (Preliminary Report).,Andrea Calì; Igor Razgon,Abstract. The Deep Web consists of data accessible through HTML forms but not as webpages; usually such data are modelled as relations that can be queried only by operating aselection on certain attributes—such restrictions are called access limitations. In this paperwe illustrate the problem of Boolean conjunctive query answering under access limitations;we define and motivate the problem's two main cases; we provide some preliminary resultson its computational complexity and we suggest some research directions.,SEBD,2014,1
Taming the infinite chase: Query answering under expressive relational constraints,Andrea Calì; Georg Gottlob; Michael Kifer,*,Journal of Artificial Intelligence Research,2013,1
Tractable Reasoning in Description Logics with Functionality Constraints,Andrea Calì; Georg Gottlob; Andreas Pieris,Abstract Ontological query answering amounts to returning the answers to a query; that arelogically entailed by the union of a set of membership assertions and an ontology; where thelatter is a set of logical assertions. Ontological query answering has applications; forinstance; in the Semantic Web and in semantic data integration. We propose as ontologylanguage a new description logic; called DLR±; allowing for roles of arbitrary arity and roleinclusion assertions with permutation; as well as functionality assertions; which generalizesthe most widely-adopted tractable ontology languages. The interaction between functionalityassertions and other constructs in ontology languages has been shown to lead easily tointractability and even undecidability. The absence of such interaction is characterized byseparability; a semantic property which has been studied in different contexts. With the …,*,2013,1
Rewrite and Conquer: Dealing with Integrity Constraints in Data Integration,Andrea Calì; Diego Calvanese; Giuseppe De Giacomo; Maurizio Lenzerini,Abstract The work “Data Integration under Integrity Constraints”; published at the CAiSE2002 Conference; proposes a rewriting technique for answering queries in data integrationsystems; when the global schema contains the classical key and foreign key constraints; andthe mapping between the data sources and the global schema is of the global-as-view type.In this addendum; we explain why this research was important and how it gave raise toseveral results in the following years.,*,2013,1
Taming the Infinite Chase: Query Answering under Expressive Integrity Constraints,Andrea Cali; Georg Gottlob; Michael Kifer,Abstract The chase algorithm is a fundamental tool for query evaluation and querycontainment under constraints; where the constraints are (sub-classes of) tuple-generatingdependencies (TGDs) and equality generating depencies (EGDs). So far; most of theresearch on this topic has focused on cases where the chase procedure terminates; withsome notable exceptions. In this paper we take a general approach; and we propose largeclasses of TGDs under which the chase does not always terminate. Our languages; inparticular; are inspired by guarded logic: we show that by enforcing syntactic properties onthe form of the TGDs; we are able to ensure decidability of the problem of answeringconjunctive queries despite the non-terminating chase. We provide tight complexity boundsfor the problem of conjunctive query evaluation for several classes of TGDs. We then …,arXiv preprint arXiv:1212.3357,2012,1
On Equality-Generating Dependencies in Ontology Querying,Andrea Calı; Andreas Pieris,Abstract. In ontology-based data access; data are queried through an ontology that offers arepresentation of the domain of interest. In this context; correct answers are those entailedby the logical theory constituted by the data and the ontology. Traditional databaseconstraints like tuple-generating dependencies (TGDs) and equality-generatingdependencies (EGDs) are a useful tool for ontology specification. However; their interactionusually leads to intractability or undecidability of query answering. Separability is the notionthat captures the lack of interaction between TGDs and EGDs. In this paper we exhibit anovel and general sufficient condition for separability; in the case where the ontology isexpressed with inclusion dependencies (a subclass of TGDs) and EGDs.,SEBD 2011,2011,1
Optimizing query processing for the hidden web,Andrea Calı Davide Martinenghi,Page 1. Optimizing Query Processing for the Hidden Web Optimizing Query Processing forthe Hidden Web Andrea Cal`ı Davide Martinenghi Oxford-Man Institute; University of OxfordDepartment of Information Systems and Computing; Brunel University Dipartimento diElettronica e Informazione; Politecnico di Milano APWeb 2010 Busan; 6 April 2010 Page2. Optimizing Query Processing for the Hidden Web Outline 1 Introduction 2 Surfacing 3 Queryanswering under access limitations 4 Optimization 5 Views and constraints 6 Containment7 Dynamic optimization 8 Conclusions Page 3. Optimizing Query Processing for the HiddenWeb Introduction The deep Web The deep Web Page 4. Optimizing Query Processing forthe Hidden Web Introduction What is the Deep Web …,*,2010,1
Ontological query answering under non-guarded rules,Andrea Calì; Georg Gottlob; Andreas Pieris,*,*,2010,1
Automatic interface generation through interaction; users; and devices modeling,Enrico Bertini; Giuseppe Santucci; Andrea Calì,Abstract We present a system for designing Internet based applications that automaticallyadapt to different devices. We define a model that describes the user interaction in terms ofelementary input/output actions. Then; we model devices to implements the user interactionin a multi-device context. Finally; we model users; to further adapt the interface,*,2007,1
Optimizing Query Planning with Limited Source Capabilities in the Presence of Inclusion and Functional Dependencies.,Andrea Calì; Diego Calvanese,Abstract. Information Integration is the problem of providing a uniform access to multiple andheterogeneous data sources. The most common approach to this problem; called Globalas-View; consists in providing a global schema of data in which each relation of such a schemais defined as a view over a set of data sources. Recent works deal with this problem in thecase of limited source capabilities; where in general sources can only be accessedrespecting certain binding patterns for their attributes. In this case; computing the answer toa query over the global schema cannot be done by simply unfolding the global relations withtheir definitions. Instead; it may require the evaluation of a suitable recursive datalogprogram. In this paper we study query evaluation in the Global-as-View approach withlimited source capabilities in the presence of full inclusion and functional dependencies …,SEBD,2001,1
Accessing the Deep Web with Keywords: A Foundational Approach,Andrea Calì; Martín Ugarte,Abstract The Deep Web is constituted by data that are generated dynamically as the result ofinteractions with Web pages. The problem of accessing Deep Web data presents manychallenges: it has been shown that answering even simple queries on such data requiresthe execution of recursive query plans. There is a gap between the theoreticalunderstanding of this problem and the practical approaches to it. The main reason behindthis is that the problem is to be studied by considering the database as part of the input; butqueries can be processed by accessing data according to limitations; expressed as so-called access patterns. In this paper we embark on the task of closing the above gap bygiving a precise definition that reflects the practical nature of accessing Deep Web datasources. In particular; we define the problem of querying Deep Web sources with …,International KEYSTONE Conference on Semantic Keyword-Based Search on Structured Data Sources,2017,*
Ontology querying: datalog strikes back,Andrea Calì,Abstract In this tutorial we address the problem of ontology querying; that is; the problem ofanswering queries against a theory constituted by facts (the data) and inference rules (theontology). A varied landscape of ontology languages exists in the scientific literature; withseveral degrees of complexity of query processing. We argue that Datalog^ ±; a family oflanguages derived from Datalog; is a powerful tool for ontology querying. To illustrate theimpact of this comeback of Datalog; we present the basic paradigms behind the mainDatalog^ ± as well as some recent extensions. We also present some efficient queryprocessing techniques for some cases.,Reasoning Web International Summer School,2017,*
Data Analytics: 31st British International Conference on Databases; BICOD 2017; London; UK; July 10–12; 2017; Proceedings,Andrea Calì; Peter Wood; Nigel Martin; Alexandra Poulovassilis,This book constitutes the refereed conference proceedings of the 31st British InternationalConference on Databases; BICOD 2017-formerly known as BNCOD (British NationalConference on Databases)-held in London; UK; in July 2017. The 17 revised full paperswere carefully reviewed and selected from numerous submissions. The papers cover a widerange of topics such as data cleansing; data integration; data wrangling; data mining andknowledge discovery; graph data and knowledge graphs; intelligent data analysis;approximate and flexible querying; data provenance and ontology-based data access. Theyare organized in the following topical sections: data wrangling and data integration; dataanalysis and data mining; graph data querying and analysis; multidimensional data anddata quality; and distributed and multimedia data management.,*,2017,*
Querying deep web data sources as linked data,Vito W Anelli; Vito Bellini; Andrea Calí; Giuseppe De Santis; Tommaso di Noia; Eugenio di Sciascio,Abstract The Deep Web is constituted by dynamically generated pages; usually requestedthrough HTML forms; it is notoriously difficult to query and to search; as its pages areobviously non-indexable. Recently; Deep Web data have been made accessible throughRESTful services that return information usually structured in JSON or XML format. Wepropose techniques to make the Deep Web available in the Linked Data Cloud; and westudy algorithms for processing queries posed in a transparent way on the Linked Data;providing answers based on the underlying Deep Web sources. We present a softwareprototype that exposes RESTful services as Linked Data datasets thus allowing a smoothersemantic integration of different structured information sources in a global data andknowledge space.,Proceedings of the 7th International Conference on Web Intelligence; Mining and Semantics,2017,*
Querying and searching the deep web,Andrea Calí,Abstract The term Deep Web (sometimes also called Hidden Web)[2; 5; 8] refers to the datacontent that is accessible through Web pages; typically via HTML forms; but is not availableon static pages for indexing by search engines. Deep Web data reside in databases and aremade available dynamically; as Web pages; upon a specific search or query. An example iswhen we query a Yellow Pages website: the generated output is the result of a query posedon an underlying database; and is not stored as static pages; such output can normally berepresented in relational form.,Proceedings of the 7th International Conference on Web Intelligence; Mining and Semantics,2017,*
Semantic Keyword-Based Search on Structured Data Sources: COST Action IC1302 Second International KEYSTONE Conference; IKC 2016; Cluj-Napoca; Romani...,Andrea Calì; Dorian Gorgan; Martín Ugarte,This book constitutes the thoroughly refereed post-conference proceedings of the SecondCOST Action IC1302 International KEYSTONE Conference on Semantic Keyword-BasedSearch on Structured Data Sources; IKC 2016; held in Cluj-Napoca; Romania; in September2016. The 15 revised full papers and 2 invited papers are reviewed and selected from 18initial submissions and cover the areas of keyword extraction; natural language searches;graph databases; information retrieval techniques for keyword search and documentretrieval.,*,2017,*
Query answering on expressive Datalog+/-ontologies,L Bertossi; Andrea Calì; Mostafa Milani,The Datalog±family of ontology languages [1]; which extends Datalog with existentialquantification; has been gaining importance in the area of Ontology Querying due to itscapability of capturing several prominent Semantic Web languages as well as offeringefficient query answering services in many variants relevant for applications. The corefeature of Datalog±languages are so-called tuple-generating dependencies (TGDs); whichare the main form of rules. Such rules allow the inference of new atoms from an initial set (adatabase); which is captured by the notion of chase procedure. For example; consider theTGD r (X; Y)→∃ Z s (X; Z) and a database D constituted by a single atom r (a; b). A chasestep will generate the atom s (a; ζ); where ζ is a labelled null; that is; a placeholder for anunknown value; notice that the constant b is lost in this step as it doesn't appear in the …,CEUR Workshop Proceedings,2016,*
Processing keyword queries under access limitations,Andrea Calì; Thomas W Lynch; Davide Martinenghi; Riccardo Torlone,Abstract The Deep Web is constituted by data accessible through web pages; but not readilyindexable by search engines; as they are returned in dynamic pages. In this paper wepropose a framework for accessing Deep Web sources; represented as relational tables withso-called access limitations; with keyword-based queries. We formalize the notion of optimalanswer and investigate methods for query processing. We also outline the main ideas of ourimplementation of a prototype system for Deep Web keyword search.,Semanitic Keyword-based Search on Structured Data Sources,2015,*
Scalable Uncertainty Management: 8th International Conference; SUM 2014; Oxford; UK; September 15-17; 2014; Proceedings,Umberto Straccia; Andrea Calì,This book constitutes the refereed proceedings of the 8th International Conference onScalable Uncertainty Management; SUM 2014; held in Oxford; UK; in September 2014. The20 revised full papers and 6 revised short papers were carefully reviewed and selected from47 submissions. The papers cover topics in all areas of managing and reasoning withsubstantial and complex kinds of uncertain; incomplete or inconsistent information includingapplications in decision support systems; machine learning; negotiation technologies;semantic web applications; search engines; ontology systems; information retrieval; naturallanguage processing; information extraction; image recognition; vision systems; data andtext mining; and the consideration of issues such as provenance; trust; heterogeneity; andcomplexity of data and knowledge.,*,2014,*
Semantic search in RealFoodTrade,Andrea Calì; Roberto De Virgilio; Tommaso Di Noia; Luca Menichetti; Roberto Mirizzi; LM Nardini; Vito Claudio Ostuni; Fabrizio Rebecca; Marco Ungania,We present RealFoodTrade (RFT); a system that allows farmers and fisher-men to sell theirproducts directly to the end-buyer. RFT mak es use of Linked Data sets; together with adomain ontology designed by expert s; to perform semantic search over products on sale.RFT employs geo-locat ion technology on mobile devices to match demand and supplyaccording to the l ocation. We sketch the semantic search techniques in RFT and illustrat eaprototype tailored to the fishing industry.,CEUR Workshop Proceedings,2014,*
How to find the best fish market in Sorrento?,Andrea Calì; R De Virgilio; Tommaso Di Noia,Birkbeck; University of London logo. BIROn - Birkbeck Institutional Research Online …,*,2014,*
Containment of Schema Mappings for Data Exchange (Preliminary Report),Andrea Calì; Riccardo Torlone,Abstract: In data exchange; data are materialised from a source schema to a target schema;according to suitable source-to-target constraints. Constraints are also expressed on thetarget schema to represent the domain of interest. A schema mapping is the union of thesource-to-target and of the target constraints. In this paper; we address the problem ofcontainment of schema mappings for data exchange; which has been recently proposed inthis framework as a step towards the optimization of data exchange settings. We refer to anatural notion of containment that relies on the behaviour of schema mappings with respectto conjunctive query answering; in the presence of so-called LAV TGDs as target constraints.Our contribution is a practical technique for testing the containment based on the existenceof a homomorphism between special" dummy" instances; which can be easily built from …,arXiv preprint arXiv:1312.5912,2013,*
Recommendation of text tags using linked data,Andrea Calì; Stefano Capuzzi; Mirko Michele Dimartino; Riccardo Frosini,Abstract We illustrate our approach to recommending short texts according to their semanticsimilarity to a given one. We make use of Linked Data on the Web to discover similaritybetween words; and then we analyze the syntax of sentences to compute a degree ofsimilarity between them. We show some preliminary experimental results as well as somedirections for future research.,Proceedings of the 3rd International Workshop on Semantic Search Over the Web,2013,*
Representing ontology mappings with probabilistic description logics programs,Andrea Calì; Thomas Lukasiewicz; Livia Predoiu; Heiner Stuckenschmidt,The problem of aligning heterogeneous ontologies via semantic mappings has beenidentified as one of the major challenges of semantic web technologies. In order to addressthis problem; a number of languages for representing semantic relations between elementsin different ontologies as a basis for reasoning and query answering across multipleontologies have been proposed [28]. In the presence of real world ontologies; it is unrealisticto assume that mappings between ontologies are created manually by domain experts; dueto the large size of existing ontologies. Recently; a number of heuristic methods; relying onlinguistic and structural criteria; for matching elements from different ontologies have beenproposed that support the creation of mappings between different languages by suggestingcandidate mappings (eg;[11]). Such methods often trade off precision and recall; as …,Proceedings of the 16th Italian Symposium on Advanced Database Systems ‚SEBD 2008 ‚Mondello ‚Italy ‚June 22− 25 ‚2008,2008,*
Inconsistency and Incompleteness in Databases (IIDB),J Chomicki; J Wijsen; M Arenas; O Arieli; L Bertossi; P Bosc; A Cali; N Dalvi; T Eiter; W Fan; E Franconi; A Fuxman; G Grahne; S Greco; M Lenzerini; J Marcinkowski; VS Subrahmanian,*,*,2006,*
Data integration under integrity constraints,Andrea Calì; Diego Calvanese; Giuseppe De Giacomo; Maurizio Lenzerini,*,Information Systems,2004,*
Publications in Journals,Andrea Calì; Diego Calvanese FUB; Giuseppe de Giacomo; Alessandro Artale FUB; Clare Dixon; Michael Fisher; Enrico Franconi; Stefan Brass; Jürgen Dix FUB; Teodor C Przymusinski; Super Logic; Giuseppe De Giacomo; Maurizio Lenzerini; Martin Peim; Enrico Franconi FUB; Norman Paton,We expect that most presentations at conferences and workshops will be submitted in acomplete version to Journals as well. However; the process of getting a paper published at ajournal usually takes 1-3 years; so the first publications appeared in the second year of theproject.,Information Systems,2004,*
Description Logic Formalization of CIM,Andrea Calı; Diego Calvanese; Giuseppe De Giacomo; Maurizio Lenzerini; Daniele Nardi,Abstract Common Information Model (CIM) has the goal of providing a suitable approach formodeling systems and networks using the object-oriented paradigm. In this document weillustrate how to map CIM onto an expressive Description Logics; called DLRifd; so as toobtain a rigorous logical framework for representing and reasoning on managed systems.The document is organized as follows. We first give an overview of both CIM and theDescription Logic DLRifd. We then illustrate the formalization of CIM in terms of DLRifd.Finally; we present an example of how such a formalization works; by showing how the CIMCore model and the CIM Common model is expressed in DLRifd.,*,2001,*
Local constraints in semistructured data schemas,Andrea Calì; Diego Calvanese; Maurizio Lenzerini,Abstract. Recently; therehavebeenseveralproposalsofformalis… data; which is data that isneither raw; nor strictly typed as in conventional database systems. Semistructured datamodels are graph-based models; where graphs are used to represent both databases andschemas. We study the basic problem of schema subsumption; which amounts to checkwhether all databases conforming to a schema also conform to another schema; in thepresence of constraints; which are used to enforce additional conditions on databases. Inparticular; we study the relationship between various constraint languages and the basicproperty of locality; which allows one to check subsumption between schemas in polynomialtime in the number of nodes of the schemas. We show that locality holds when both numericconstraints and disjunction are added to a simple constraint language. On the other hand …,Proc. of the 8th Italian Conf. on Database Systems (SEBD,2000,*
Dai biosegnali agli stati emotivi: un approccio semantico,Michele Ruta; Floriano Scioscia; Annarita Cinquepalmi; Silvia Cipriani; Eugenio Di,Abstract Obiettivo dell'Affective Computing è permettere il riconoscimento di stati emotiviumani attraverso procedure automatiche. Gli scenari applicativi spaziano dalperfezionamento dell'interazione uomo-macchina alla generazione di biofeedback al fine dimigliorare lo stato cognitivo e il benessere dei soggetti e; al contempo; ridurre potenzialisituazioni di rischio alle quali essi sono esposti. Sebbene la letteratura sottolinei l'utilitàdell'analisi dei biosegnali per il rilevamento e la classificazione delle emozioni; gli approcciesistenti risultano generalmente invasivi per il soggetto e caratterizzati da elaborazionionerose. Si tratta infatti di architetture di calcolo convenzionali che supportano il processingdi segnali biologici estratti mediante interfacce sensoriali particolarmente sofisticate. Inparticolare poi il processing punta all'estrazione di tratti caratteristici (o feature) dai …,*,*,*
Exposing the Deep Web in the Linked Data Cloud,Andrea Calı; Giuseppe De Santis; Tommaso Di Noia; Nicola Mincuzzi,Abstract. The Deep Web is constituted by dynamically generated pages; usually requestedthrough a HTML form; it is notoriously difficult to query and to search; as its pages areobviously non-indexable. More recently; Deep Web data have been made accessiblethrough RESTful services that return information usually structured in JSON or XML format.We propose techniques to make the Deep Web available in the Linked Data Cloud; and westudy algorithms for processing queries; posed in a transparent way on the Linked Data; onthe underlying Deep Web sources. The tool we developed mainly focuses on exposingRESTful services as Linked Data datasets thus allowing a smoother semantic integration ofdifferent structured information sources in a global dataand knowledge-space.,*,*,*
Googling the Deep Web,Andrea Calı; Davide Martinenghi; Riccardo Torlone,Abstract. The Deep Web is constituted by data that are accessible through Web pages; butnot indexable by search engines as they are returned in dynamic pages. In this paper wepropose a conceptual framework for answering keyword queries on Deep Web sourcesrepresented as relational tables with so-called access limitations. We formalize the notion ofoptimal answer and characterize queries for which an answer can be found.,*,*,*
Data Analytics,Andrea Calì; Peter Wood; Nigel Martin; Alexandra Poulovassilis,This volume contains research papers presented at BICOD 2017: the 31st BritishInternational Conference on Databases held July 10–12; 2017; at Birkbeck; University ofLondon. The BICOD Conference is an international venue with a long tradition ofpresentation and discussion of research in the broad area of data management. The themeof BICOD 2017 was “Data Analytics;” that is; the process of deriving higher-level informationfrom large sets of raw data.,*,*,*
Semantic Keyword-Based Search on Structured Data Sources,Andrea Calì; Dorian Gorgan; Martín Ugarte,In data management we face the problem of handling and querying very large datasets withlarge and partially unknown schemas; possibly containing billions of instances. An importantissue in this context is to efficiently perform keyword searches. The size of the datasetsposes challenges related to both scalability and semantic analysis. Another challenge is thediscovery of suitable data sources for keyword search; given that one would want to processqueries on relevant sources. The Second International KEYSTONE Conference (IKC 2016);organized within the Cost Action IC1302 (Semantic Keyword-Based Search on StructuredData Sources); attracted several contributions in the area of keyword and semantic searchon large structured data. In all; 14 papers were selected; the topics covered; among others;the areas of keyword extraction; natural language searches; graph databases …,*,*,*
Workshop Organization,Alberto HF Laender; Juliana Freire; Dan Suciu; Mirella M Moro; Vanessa Braganholo; Clodoveu Davis Jr; Marcos André Gonçalves; Francesco Bonchi; Angela Bonifati; Andrea Calì; Sara Cohen; Isabel Cruz; Wolfgang Gatterbauer; Boris Glavic; Claudio Gutierrez; Solmaz Kolahi; Dongwon Lee; Domenico Lembo; Marta Mattoso; Regina Motz; Frank Neven; Rachel Pottinger; Vibhor Rastogi; Altigran S da Silva; Cristina Sirangelo; Divesh Srivastava; Julia Stoyanovich; David Toman; Alejandro Vaisman; Stijn Vansummeren; Ke Yi; Daniel Oliveira,The Alberto Mendelzon International Workshop on Foundations of Data Management (AMW2012) held in Ouro Preto; Brazil; on June 27-30; 2012; is the sixth workshop of a serieswhich started in 2006; as part on an initiative of the Latin American community ofresearchers in data management to honor the memory of our friend; colleague and mentorAlberto Mendelzon. The AMW series has been a venue for high-quality research onfoundational aspects of data management and it has helped foster and solidify the researchin this area throughout Latin America. This event; as the previous ones; has encouraged theparticipation of Latin American graduate students and includes activities specially designedfor them. In addition; with sponsorship from the VLDB Endowment; travel grants have beenprovided for students to attend the event. The proceedings of the workshop consist of 14 …,*,*,*
We are also looking forward to the next editions of the Alberto Mendelzon Workshop; which has become an established and high-quality venue in the area of data m...,Andrea Calı; Maria-Esther Vidal,The Alberto Mendelzon Workshop (AMW) is a Latin American initiative started in 2006 tohonor the memory of Alberto Mendelzon; who gave a significant contribution to the field ofdata management. The AMW is a discussion venue for top-quality research in foundations ofdata management; while focused especially on Latin American students and scholars; theworkshop is open to submissions from anywhere and it has so far gathered some of theworld's best researchers in the field. This volume contains papers accepted at the 9th editionof the AMW; held in Lima; Peru; from the 6th to the 8th of May; 2015. The call for papers ofthis edition solicited two types of submissions: regular and short papers; where the latterwere intended to present ongoing research; results published elsewhere or applications.With 40 submissions we could put up an exciting program; which gave raise to …,*,*,*
Datalog+/-: A Family of Logical Knowledge Representation and Query Languages for New Applications Keynote Lecture,Andrea Calı; Georg Gottlob; Thomas Lukasiewicz; Bruno Marnette; Andreas Pieris,*,*,*,*
Semantic Keyword Search in Linked Data,Andrea Calı; Leonardo Coaccioli; Mirko Michele Dimartino; Riccardo Frosini; Federico Pastori,Linked Data sets available on the web constitute now a large corpus of (semi) structuredinformation that is generally highly valuable. Though data in Linked Data sets arerepresented in in a flat data structure (usually RDF); from the semantic point of view thereare several levels of abstractions: for instance; we can find information about classes ofobjects and inclusion (or subset; or is-a) relationship between classes. We therefore arguethat semantic search is particularly suited to Linked Data sets. In this short paper we outlineour approach to semantic search in Linked Data. In particular; we focus on keyword search;the goal is to return results (in the form of concepts) that are semantically close to thekeyword (s) entered by the user. We have applied our techniques to the system Real FoodTrade (RFT); which provides a marketplace for producers to sell their produce directly to …,*,*,*
2nd International Workshop on Logical Aspects and Applications of Integrity Constraints,Henning Christiansen; Davide Martinenghi; Marcelo Arenas; Andrea Calì; Stefano Ceri,Integrity constraints are commonly recognized as the tool for characterizing data semanticsand well-formedness in databases and information systems in general. As such; integrityconstraints apply to different contexts; such as relational and deductive databases; activedatabase systems; and XML document collections; and are relevant for several applications;including integrity control; data integration and semantic query optimization. LAAIC'06 is the2nd International Workshop on Logical Aspects and Applications of Integrity Constraints;and its goal is to gather experts in the field and to stimulate a constructive dialogue amongresearchers. It provides an international forum for the presentation of the most recent trends;and a common starting point to address the most pressing research problems. We haveselected eight high-quality; full papers for discussion and presentation in the workshop …,*,*,*
STSM Report,Andrea Calı,Abstract. This is a brief report of the research activities carried out under theCOSTKEYSTONE grant during the Short-Term Scientific Mission to the Universita Roma Tre.In particular; I worked with Prof. Riccardo Torlone. The topic of the visit was keywordsearches on Deep Web (aka Hidden Web) data sources. The Deep Web is constituted bydata that are accessible through Web pages; but are not indexable by search engines; beingreturned in dynamic pages. We notion of keyword search in the context of web data sourcesaccessible through HTML forms; and propose a preliminary framework for it.,*,*,*
Scalable Uncertainty Management,Umberto Straccia; Andrea Calì,Information systems are becoming increasingly complex; involving massive amounts of datacoming from different sources. Information is often inconsistent; incomplete; heterogeneous;and pervaded with uncertainty. The International Conference on Scalable UncertaintyManagement (SUM) conferences series provides an international forum about themanagement of uncertain; incomplete; or inconsistent information. This volume contains thepapers presented at the 8th International Conference on Scalable Uncertainty Management(SUM 2014); which was held at St Anne's College; Oxford; UK; from the 15th to the 17th ofSeptember; 2014. The call for papers solicited submissions in two categories: regularresearch papers and short papers; where the latter report on interesting work in progress orprovide system descriptions. The call for papers resulted in 47 submissions. Based on the …,*,*,*
Research Program Committee,Yanif Ahmad; Aris Anagnostopoulos; Walid Aref; Ismail Ari; Shivnath Babu; Zohra Bellahsene; II Elisa Bertino; Claudio Bettini; Michael Bohlen; Paolo Boldi; Francesco Bonchi; Peter Boncz; CWI Angela Bonifati; Vinayak Borkar; Christof Bornhoevd; SAP Randal Burns; Andrea Cali; Selcuk Candan; Barbara Carminati; Deepayan Chakrabarti; Chee Yong Chan; Shimin Chen; Pittsburgh Su Chen; Yi Chen; Reynold Cheng; Sarah Cohen-Boulakia; LRI Orsay; Gao Cong; Mariano Consens; Isabel Cruz; Bin Cui; Colazzo Dario; Gautam Das; Anish Das Sarma; Khuzaima Daudjee; Antonios Deligiannakis; Stefan Dessloch; Anhai Doan; Eduard Dragut,Yanif Ahmad; Johns Hopkins University Aris Anagnostopoulos; Sapienza University of RomeWalid Aref; Purdue University Ismail Ari; Ozyegin University Soeren Auer; Leipzig School of MediaShivnath Babu; Duke University Roger Barga; Microsoft Zohra Bellahsene; University of MontpellierII Elisa Bertino; Purdue University Claudio Bettini; University of Milan Michael Bohlen; Universityof Zurich Paolo Boldi; University of Milan Francesco Bonchi; Yahoo! Research Peter Boncz; CWIAngela Bonifati; ICAR-CNR; Italy Vinayak Borkar; University of California; Irvine ChristofBornhoevd; SAP Randal Burns; Johns Hopkins University Andrea Cali; University of Oxford SelcukCandan; Arizona State University Barbara Carminati; University of Insubria; Italy DeepayanChakrabarti; Yahoo! Research Chee Yong Chan; National University of Singapore BadrishChandramouli; Microsoft Gang Chen; Zhejing University; China Shimin Chen; Intel Labs …,*,*,*
Querying Incomplete Data: Towards Practical Cases (position paper),Andrea Calı,When integrity constraints are expressed on a database schema; it is possible that suchconstraints are not satisfied by the data represented by the schema. This may happen; forexample; in a data warehouse where data are retrieved from different sources; or in a dataintegration system where the schema is a representation of several independent datasources. In such cases the constraints are not representing some property of the data;instead; they are used to enhance the database schema in order to better represent thedomain of interest. In case of inconsistencies; the goal is to provide consistent answers;according to a suitable semantics. In this paper we present some results about queryinginconsistent databases; analysing decidability and complexity of query answering underdifferent classes of integrity constraints. In particular; data complexity; ie complexity wrt …,Inconsistency and Incompleteness in Databases,*,*
Datalog+/-: A New Family of Languages for Ontology Querying,Andrea Calı; Georg Gottlob; Thomas Lukasiewicz; Andreas Pieris,We briefly report on Datalog±; a family of recently introduced variants of Datalog. InDatalog±languages; Datalog is extended by allowing features such as existentialquantifiers; the equality predicate; and the truth constant false to appear in rule heads. At thesame time; the resulting language is syntactically restricted; so as to achieve decidabilityand in some relevant cases even tractability. Datalog (see; eg;[1]) has been used as aparadigmatic database programming and query language for over three decades. Rules inDatalog±are so-called tuple-generating dependencies (TGDs); ie; Datalog (Horn) rules withthe possibility of having existentially quantified variables in the head. For example; the ruleperson (X)→∃ Y father (X; Y)(with the universal quantifiers omitted) expresses the fact thatevery person has a father. Existential quantification in Datalog±rules allows us to …,*,*,*
Accessing Data through Ontologies under Access Limitations: State of the Art,Andrea Calı; Diego Calvanese; Davide Martinenghi,Search engines operating on the web; as well as web information systems [FLM98]; mayneed to access data that are somehow “hidden” behind web pages; these data are onlyaccessible through forms; and they are not immediately accessible on the web. Such hiddenpages are dynamically generated; and they are the response to a user query. Typically;certain fields are required to be filled in by the user in order to obtain a result. For example;an online shop would forbid a request posed by a user who leaves all fields of the formempty; while searching for products. Analogously; in legacy systems where data arescattered over several files; data may be wrapped and masked as relational tables that havesimilar access limitations; due to the way the data are organized in the files. It is easy to seethat; usually; accessing information through a web form amounts to querying a relational …,*,*,*
Data Engineering,Ronald Fagin; Ariel Fuxman; Laura M Haas; Mauricio A Hernández; Howard Ho; Anastasios Kementsietsidis; Renée J Miller; Felix Nauman; Lucian Popa; Yannis Velegrakis; Charlotte Vilarem; Ling-Ling Yan; Andrea Calı; Diego Calvanese; Giuseppe De Giacomo; Maurizio Lenzerini,Bulletin of the Technical Committee on Data Engineering September 2002 Vol. 25 No. 3 IEEEComputer Society Letters Letter from the Editor-in-Chief...................................................... DavidLomet 1 Letter from the Special Issue Editor.................................................. Renée J. Miller 2 SpecialIssue on Integration Management Data Integration: Where Does the Time Go?...... LenSeligman; Arnon Rosenthal; Paul Lehner; Angela Smith 3 Integration Through a Practitioner'sEye.... Srinivasa Narayanan; Subbu N. Subramanian and the Tavant Team 11 Data … EditorialBoard Editor-in-Chief David B. Lomet Microsoft Research One Microsoft Way; Bldg. 9 RedmondWA 98052-6399 lomet@ microsoft. com Associate Editors Umeshwar Dayal Hewlett-PackardLaboratories 1501 Page Mill Road; MS 1142 Palo Alto; CA 94304 Johannes Gehrke Departmentof Computer Science Cornell University Ithaca; NY 14853 Christian S. Jensen …,Urbana,*,*
DIS@ DIS: un Sistema per l’Integrazione Semantica dei Dati in Presenza di Vincoli di Integrit,Andrea Calı; Saverio De Nigris; Domenico Lembo; Gabriele Messineo; Riccardo Rosati; Marco Ruzzi,*,*,*,*
Local Constraints in Semistructured Data Schemas,Andrea Calı; Diego Calvanese; Maurizio Lenzerini,Abstract. Recently; there have been several proposals of formalisms for modelingsemistructured data; which is data that is neither raw; nor strictly typed as in conventionaldatabase systems. Semistructured data models are graph-based models; where graphs areused to represent both databases and schemas. We study the basic problem of schemasubsumption; which amounts to check whether all databases conforming to a schema alsoconform to another schema; in the presence of constraints; which are used to enforceadditional conditions on databases. In particular; we study the relationship between variousconstraint languages and the basic property of locality; which allows one to checksubsumption between schemas in polynomial time in the number of nodes of the schemas.We show that locality holds when both numeric constraints and disjunction are added to a …,*,*,*
Report 7.3. 4 Specifiche del Prototipo per la Generazione di Interfacce Utente Parte A: Architettura generale del sistema,E Bertini; A Calì; T Catarci; G Santucci,*,*,*,*
Specifiche dei tre dimostratori (parte 1),A Calì; A Corallo; M Matera; D Presenza; G Santucci; N Simeoni; S Fragola; A Maurino; M Mecella; F De Rosa; M Adorni; A Limonta; P Losi; F Tisato; L Mainetti; L Sbattella; T Barbieri; A Bianchi; B Pernici,*,*,*,*
We investigate properties of coincidence ideals in subattribute lattices that occur in complex value datamodels; ie sets of subattributes; on which two complex values...,H Köhler; KD Schewe; H Ma; A Calì; D Calvanese; D Martinenghi,A. Sali; K.-D. Schewe: A Characterisation of Coincidence Ideals for Complex Values We investigateproperties of coincidence ideals in subattribute lattices that occur in complex valuedatamodels; ie sets of subattributes; on which two complex values coincide. We let complex valuesbe defined by constructors for records … H. Köhler: Global Database Design based on StorageSpace and Update Time Minimization A common approach in designing relational databasesis to start with a universal relation schema; which is then decomposed into multiplesubschemas. A good choice of subschemas can be determined using integrity constraints definedon the schema … K.-D. Schewe: Functional Dependencies with Counting on Trees The paperpresents an axiomatisation for functional dependencies on trees that are defined using constructorsfor records; lists; sets and multisets. A simple form of restructuring permitting lists to be …,*,*,*
A USER-ADAPTIVE SMALL-SCREEN OPTIMIZATION APPROACH FOR SEARCHING BOOKS,Enrico Bertini; Andrea Calì; Silvia Gabrielli; Tiziana Catarci,ABSTRACT In this paper; we describe a user-adaptive system designed to access arepository of books with small screen devices. The purpose is to investigate the idea ofemploying usage data as a source for user interface adaptations; to overcome the lack ofscreen space and limit the need for explicit user input. We present an overview of potentialadaptations; describe the user model and the design of an application for an handhehelddevice; and report on a preliminary expert-based usability study.,*,*,*
