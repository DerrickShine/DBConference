A Formal Approach for RDF/S Ontology Evolution.,George Konstantinidis; Giorgos Flouris; Grigoris Antoniou; Vassilis Christophides,Abstract. In this paper; we consider the problem of ontology evolution in the face of a changeoperation. We devise a general-purpose algorithm for determining the effects and side-effects of a requested elementary or complex change operation. Our work is inspired bybelief revision principles (ie; validity; success and minimal change) and allows us to handleany change operation in a provably rational and consistent manner. To the best of ourknowledge; this is the first approach overcoming the limitations of existing solutions; whichdeal with each change operation on a per-case basis. Additionally; we rely on our generalchange handling algorithm to implement specialized versions of it; one per desired changeoperation; in order to compute the equivalent set of effects and side-effects. 2,ECAI,2008,44
Evaluation of Query Rewriting Approaches for OWL 2,Héctor Pérez-Urbina; Edgar Rodrıguez-Dıaz; Michael Grove; George Konstantinidis; Evren Sirin,*,Joint Workshop on Scalable and High-Performance Semantic Web Systems (SSWS+ HPCSW 2012),*,36
Scalable query rewriting: a graph-based approach,George Konstantinidis; José Luis Ambite,Abstract In this paper we consider the problem of answering queries using views; which isimportant for data integration; query optimization; and data warehouses. We consider itssimplest form; conjunctive queries and views; which already is NP-complete. Our context isdata integration; so we search for maximally-contained rewritings. By looking at the problemfrom a graph perspective we are able to gain a better insight and develop an algorithmwhich compactly represents common patterns in the source descriptions; and (optionally)pushes some computation offline. This together with other optimizations result in anexperimental performance about two orders of magnitude faster than current state-of-the-artalgorithms; rewriting queries using over 10000 views within seconds.,Proceedings of the 2011 ACM SIGMOD International Conference on Management of data,2011,25
Formal Foundations for RDF/S KB Evolution,Giorgos Flouris; George Konstantinidis; Grigoris Antoniou; Vassilis Christophides,Abstract There are ongoing efforts to provide declarative formalisms of integrity constraintsover RDF/S data. In this context; addressing the evolution of RDF/S knowledge bases whilerespecting associated constraints is a challenging issue; yet to receive a formal treatment.We provide a theoretical framework for dealing with both schema and data change requests.We define the notion of a rational change operator as one that satisfies the belief revisionprinciples of Success; Validity and Minimal Change. The semantics of such an operator aresubject to customization; by tuning the properties that a rational change should adhere to.We prove some interesting theoretical results and propose a general-purpose algorithm forimplementing rational change operators in knowledge bases with integrity constraints; whichallows us to handle uniformly any possible change request in a provably rational and …,Knowledge and information systems,2012,20
Ontology evolution: A framework and its application to rdf,George Konstantinidis; Giorgos Flouris; Grigoris Antoniou; Vassilis Christophides,ABSTRACT The algorithms dealing with the incorporation of new knowledge in an ontologyoften share a rather standard process of dealing with changes. This process consists of thedetermination of the allowed change operations; the identification of the inconsistencies thatcould be caused by each such operation as well as the various alternatives to deal witheach such inconsistency; and; finally; some (manual or automatic) selection mechanism thatallows the determination of the “best” of these alternatives. Unfortunately; most ontologyevolution algorithms implement these steps using a case-based; ad-hoc methodology;which is cumbersome and error-prone. In this paper we propose a general framework forontology change management that generalizes the methodology employed by existing tools.The introduction of this framework allows us to devise a whole class of ontology evolution …,Proceedings of the Joint ODBIS & SWDB Workshop on Semantic Web; Ontologies; Databases (SWDB-ODBIS-07),2007,16
On RDF/S ontology evolution,George Konstantinidis; Giorgos Flouris; Grigoris Antoniou; Vassilis Christophides,Abstract The algorithms dealing with the incorporation of new knowledge in an ontology(ontology evolution) often share a rather standard process of dealing with changes. Thisprocess consists of the specification of the language; the determination of the allowedupdate operations; the identification of the invalidities that could be caused by each suchoperation; the determination of the various alternatives to deal with each such invalidity; and;finally; some selection mechanism for singling out the “best” of these alternatives.Unfortunately; most ontology evolution algorithms implement these steps using a case-based; ad-hoc methodology; which is cumbersome and error-prone. The first goal of thispaper is to present; justify and make explicit the five steps of the process. The second goal isto propose a general framework for ontology change management that captures this …,*,2008,13
Benchmarking the chase,Michael Benedikt; George Konstantinidis; Giansalvatore Mecca; Boris Motik; Paolo Papotti; Donatello Santoro; Efthymia Tsamoura,Abstract The chase is a family of algorithms used in a number of data management tasks;such as data exchange; answering queries under dependencies; query reformulation withconstraints; and data cleaning. It is well established as a theoretical tool for understandingthese tasks; and in addition a number of prototype systems have been developed. Whileindividual chase-based systems and particular optimizations of the chase have beenexperimentally evaluated in the past; we provide the first comprehensive and publiclyavailable benchmark---test infrastructure and a set of test scenarios---for evaluating chaseimplementations across a wide range of assumptions about the dependencies and the data.We used our benchmark to compare chase-based systems on data exchange and queryanswering tasks with one another; as well as with systems that can solve similar tasks …,Proceedings of the 36th ACM SIGMOD-SIGACT-SIGAI Symposium on Principles of Database Systems,2017,6
Optimizing query rewriting for multiple queries,George Konstantinidis; José Luis Ambite,Abstract We present an scalable algorithm for answering multiple conjunctive queries usingviews. This is an important problem in query optimization; data integration and ontology-based data access. Since rewriting one conjunctive query using views is an NP-hardproblem; we develop an approach where answering n queries takes less than n times thecost of answering one query; by compactly representing and indexing common patterns inthe input queries and the views. Our initial experimental results show a promising speed up.,Proceedings of the Ninth International Workshop on Information Integration on the Web,2012,4
SchizConnect: virtual data integration in neuroimaging,Jose Luis Ambite; Marcelo Tallis; Kathryn Alpert; David B Keator; Margaret King; Drew Landis; George Konstantinidis; Vince D Calhoun; Steven G Potkin; Jessica A Turner; Lei Wang,Abstract In many scientific domains; including neuroimaging studies; there is a need toobtain increasingly larger cohorts to achieve the desired statistical power for discovery.However; the economics of imaging studies make it unlikely that any single study orconsortia can achieve the desired sample sizes. What is needed is an architecture that caneasily incorporate additional studies as they become available. We present sucharchitecture based on a virtual data integration approach; where data remains at the originalsources; and is retrieved and harmonized in response to user queries. This is in contrast toapproaches that move the data to a central warehouse. We implemented our approach inthe SchizConnect system that integrates data from three neuroimaging consortia onSchizophrenia: FBIRN's Human Imaging Database (HID); MRN's Collaborative Imaging …,International Conference on Data Integration in the Life Sciences,2015,3
Optimizing the chase: Scalable data integration under constraints,George Konstantinidis; José Luis Ambite,Abstract We are interested in scalable data integration and data exchange underconstraints/dependencies. In data exchange the problem is how to materialize a targetdatabase instance; satisfying the source-to-target and target dependencies; that providesthe certain answers. In data integration; the problem is how to rewrite a query over the targetschema into a query over the source schemas that provides the certain answers. In boththese problems we make use of the chase algorithm; the main tool to reason withdependencies. Our first contribution is to introduce the frugal chase; which produces smalleruniversal solutions than the standard chase; still remaining polynomial in data complexity.Our second contribution is to use the frugal chase to scale up query answering using viewsunder LAV weakly acyclic target constraints; a useful language capturing RDF/S. The …,Proceedings of the VLDB Endowment,2014,2
Belief change in semantic web environments,George Konstantinidis,Abstract Towards the realization of the vision of the Semantic Web; one of the mostsignificant tasks to be performed is the transformation of current human-oriented Webinformation into machine-processable Web information. In this direction; standards havebeen adopted in order to structure the data (XML) and to describe the semantics of the data(meta-data expressed in RDF). RDF is a data model and along with the RDF Schema; whichdefines the vocabulary of this model; they form a mechanism which provides a formal;machine processable representation of knowledge. However the nature of world is dynamicand as the world changes; the knowledge itself; or our view of it; is subject to changes.Consequently; modeling a dynamic world means encapsulating a mechanism for updatingknowledge. The algorithms dealing with the incorporation of new knowledge in an …,*,2008,2
Scalable containment for unions of conjunctive queries under constraints,George Konstantinidis; Jose Luis Ambite,Abstract We consider the problem of query containment under ontological constraints; suchas those of RDFS. Query containment; ie; deciding whether the answers of a given query arealways contained in the answers of another query; is an important problem to areas such asdatabase theory and knowledge representation; with applications to data integration; queryoptimization and minimization. We consider unions of conjunctive queries; which constitutethe core of structured query languages; such as SPARQL and SQL. We also considerontological constraints or axioms; expressed in the language of Tuple-GeneratingDependencies. TGDs capture RDF/S and fragments of Description Logics. We considerclasses of TGDs for which the chase is known to terminate. Query containment under chase-terminating axioms can be decided by first running the chase on one of the two queries …,Proceedings of the Fifth Workshop on Semantic Web Information Management,2013,1
Towards Scalable Data Integration under Constraints,George Konstantinidis,Abstract In this paper we consider the problem of answering queries using views; with orwithout ontological constraints; which is important for data integration; query optimization;and data warehouses. Our context is data integration; so we search for maximally-containedrewritings. We have produced a very scalable and efficient solution for its simplest form;conjunctive queries and views; and we are working towards the full relational case. Whenconsidering constraints; the problem is usually divided in two phases:(1) query expansion;which rewrites queries wrt the intentional knowledge and (2) expanded query reformulationusing the views. Relevant algorithms have given little attention to the second phase andhave studied a limited form of view definition languages overall (namely; only GAV). Bylooking at the problem from a graph perspective we are able to gain a better insight and …,*,2012,1
The bag semantics of ontology-based data access,Charalampos Nikolaou; Egor V Kostylev; George Konstantinidis; Mark Kaminski; Bernardo Cuenca Grau; Ian Horrocks,Abstract: Ontology-based data access (OBDA) is a popular approach for integrating andquerying multiple data sources by means of a shared ontology. The ontology is linked to thesources using mappings; which assign views over the data to ontology predicates. Motivatedby the need for OBDA systems supporting database-style aggregate queries; we propose abag semantics for OBDA; where duplicate tuples in the views defined by the mappings areretained; as is the case in standard databases. We show that bag semantics makesconjunctive query answering in OBDA coNP-hard in data complexity. To regain tractability;we consider a rather general class of queries and show its rewritability to a generalisation ofthe relational calculus to bags. Subjects: Artificial Intelligence (cs. AI) Cite as: arXiv:1705.07105 [cs. AI](or arXiv: 1705.07105 v1 [cs. AI] for this version) Submission history …,arXiv preprint arXiv:1705.07105,2017,*
Scalable Data Integration Under Constraints,George Konstantinidis,*,*,2015,*
Data Integration Technologies,Casey L Overby; Alejandro Flores; Guillermo Palma; Maria-Esther Vidal; Elena Zotkina; Louiqa Raschid; Naveen Ashish; Peehoo Dewan; Jose-Luis Ambite; Arthur W Toga; Tassos Venetis; Vasilis Vassalos; Jose Luis Ambite; Marcelo Tallis; Kathryn Alpert; David B Keator; Margaret King; Drew Landis; George Konstantinidis; Vince D Calhoun; Steven G Potkin; Jessica A Turner; Lei Wang; Victor Christen; Anika Groß; Julian Varghese; Martin Dugas; Erhard Rahm; Ignacio Traverso-Ribón; Danielle Pasquerello; Matthew D Turner; Shima Dastgheib; Daniel Ian McSkimming; Natarajan Kannan; Krys Kochut,Combining Multiple Knowledge Sources: A Case Study of Drug Induced Liver Injury . . . . . . . .… Casey L. Overby; Alejandro Flores; GuillermoPalma; Maria-Esther Vidal; Elena Zotkina; and Louiqa Raschid … Naveen Ashish; PeehooDewan; Jose-Luis Ambite; and Arthur W. Toga … Data Integration in the Human Brain Project… Jose Luis Ambite; Marcelo Tallis; Kathryn Alpert; David B.Keator; Margaret King; Drew Landis; George Konstantinidis; Vince D. Calhoun; Steven G.Potkin; Jessica A. Turner; and Lei Wang … Ontology and Knowledge Engineering for Data Integration… Victor Christen; Anika Groß; Julian Varghese; Martin Dugas; and Erhard Rahm …OnSim: A Similarity Measure for Determining Relatedness Between Ontology Terms . . . . . . .… Ignacio Traverso-Ribón; Maria-Esther Vidal …,*,*,*
The Bag Semantics of Ontology-Based Data Access (Extended Abstract)⋆,Charalampos Nikolaou; Egor V Kostylev; George Konstantinidis; Mark Kaminski; Bernardo Cuenca Grau; Ian Horrocks,Ontology-based data access (OBDA) is an increasingly popular approach to enable uniformaccess to multiple data sources with diverging schemas. In OBDA; an ontology provides aunifying conceptual model for the data sources together with domain knowledge. Theontology is linked to each source by globalas-view (GAV) mappings; which assign viewsover the data to ontology predicates. Users access the data by means of queries formulatedusing the vocabulary of the ontology; query answering amounts to computing the certainanswers of the query over the union of ontology and the materialisation of the views definedby the mappings. The formalism of choice for representing ontologies in OBDA is thedescription logic DL-LiteR which underpins OWL 2 QL. DL-LiteR was designed to ensurethat queries against the ontology are first-order rewritable; that is; they can be …,*,*,*
Formalizing the Evolution Process,Giorgos Flouris; George Konstantinidis,Abstract. This work focuses on identifying and formalizing the process underlying thedevelopment of an evolution algorithm. The main argument elaborated in this work is thatthe development of an algorithm dealing with the incorporation of new knowledge in alogical structure (such as an ontology) is based on a pattern consisting of discrete and well-defined steps which can be formalized; described and studied independently. After a shortliterature review on the current state-of-the-art in the field of ontology evolution; we describethe aforementioned pattern and propose a formalization of it; this allows us to develop ageneric “algorithmic pattern” which can be made specific and be applied to differentrepresentation languages or application scenarios; and lead to specific ontology evolutionalgorithms applicable to specific contexts. We then apply our formalization to the problem …,*,*,*
