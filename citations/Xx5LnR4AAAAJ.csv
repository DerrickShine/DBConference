Improving in-memory database index performance with Intel® Transactional Synchronization Extensions,Tomas Karnagel; Roman Dementiev; Ravi Rajwar; Konrad Lai; Thomas Legler; Benjamin Schlegel; Wolfgang Lehner,The increasing number of cores every generation poses challenges for high-performance in-memory database systems. While these systems use sophisticated high-level algorithms topartition a query or run multiple queries in parallel; they also utilize low-levelsynchronization mechanisms to synchronize access to internal database data structures.Developers often spend significant development and verification effort to improveconcurrency in the presence of such synchronization. The Intel® TransactionalSynchronization Extensions (Intel® TSX) in the 4th Generation Core™ Processors enablehardware to dynamically determine whether threads actually need to synchronize even inthe presence of conservatively used synchronization. This paper evaluates the effectivenessof such hardware support in a commercial database. We focus on two index …,High Performance Computer Architecture (HPCA); 2014 IEEE 20th International Symposium on,2014,43
Fast integer compression using SIMD instructions,Benjamin Schlegel; Rainer Gemulla; Wolfgang Lehner,Abstract We study algorithms for efficient compression and decompression of a sequence ofintegers on modern hardware. Our focus is on universal codes in which the codeword lengthis a monotonically non-decreasing function of the uncompressed integer value; such codesare widely used for compressing" small integers". In contrast to traditional integercompression; our algorithms make use of the SIMD capabilities of modern processors byencoding multiple integer values at once. More specifically; we provide SIMD versions ofboth null suppression and Elias gamma encoding. Our experiments show that theseversions provide a speedup from 1.5 x up to 6.7 x for decompression; while maintaining asimilar compression performance.,Proceedings of the Sixth International Workshop on Data Management on New Hardware,2010,38
Fast Sorted-Set Intersection using SIMD Instructions.,Benjamin Schlegel; Thomas Willhalm; Wolfgang Lehner,ABSTRACT In this paper; we focus on sorted-set intersection which is an important part inmany algorithms; eg; RID-list intersection; inverted indexes; and others. In contrast totraditional scalar sorted-set intersection algorithms that try to reduce the number ofcomparisons; we propose a parallel algorithm that relies on speculative execution ofcomparisons. In general; our algorithm requires more comparisons but less instructions thanscalar algorithms that translates into a better overall speed. We achieve this by utilizingefficient single-instruction-multiple-data (SIMD) instructions that are available in manyprocessors. We provide different sorted-set intersection algorithms for different integer datatypes. We propose versions that use uncompressed integer values as input and output aswell as a version that uses a tailor-made data layout for even faster intersections. In our …,ADMS@ VLDB,2011,37
Efficient In-Memory Indexing with Generalized Prefix Trees.,Matthias Boehm; Benjamin Schlegel; Peter Benjamin Volk; Ulrike Fischer; Dirk Habich; Wolfgang Lehner,Abstract: Efficient data structures for in-memory indexing gain in importance due to (1) theexponentially increasing amount of data;(2) the growing main-memory capacity; and (3) thegap between main-memory and CPU speed. In consequence; there are high performancedemands for in-memory data structures. Such index structures are used—with minorchanges—as primary or secondary indices in almost every DBMS. Typically; tree-based orhash-based structures are used; while structures based on prefix-trees (tries) are neglectedin this context. For tree-based and hash-based structures; the major disadvantages areinherently caused by the need for reorganization and key comparisons. In contrast; themajor disadvantage of trie-based structures in terms of high memory consumption (createdand accessed nodes) could be improved. In this paper; we argue for reconsidering prefix …,BTW,2011,37
Memory-efficient frequent-itemset mining,Benjamin Schlegel; Rainer Gemulla; Wolfgang Lehner,Abstract Efficient discovery of frequent itemsets in large datasets is a key component ofmany data mining tasks. In-core algorithms---which operate entirely in main memory andavoid expensive disk accesses---and in particular the prefix tree-based algorithm FP-growthare generally among the most efficient of the available algorithms. Unfortunately; theirexcessive memory requirements render them inapplicable for large datasets with manydistinct items and/or itemsets of high cardinality. To overcome this limitation; we propose twonovel data structures---the CFP-tree and the CFP-array---; which reduce memoryconsumption by about an order of magnitude. This allows us to process significantly largerdatasets in main memory than previously possible. Our data structures are based onstructural modifications of the prefix tree that increase compressability; an optimized …,Proceedings of the 14th International Conference on Extending Database Technology,2011,32
Eris: A NUMA-aware in-memory storage engine for analytical workloads,Thomas Kissinger; Tim Kiefer; Benjamin Schlegel; Dirk Habich; Daniel Molka; Wolfgang Lehner,*,Proceedings of the VLDB Endowment,2014,29
KISS-Tree: smart latch-free in-memory indexing on modern architectures,Thomas Kissinger; Benjamin Schlegel; Dirk Habich; Wolfgang Lehner,Abstract Growing main memory capacities and an increasing number of hardware threads inmodern server systems led to fundamental changes in database architectures. Mostimportantly; query processing is nowadays performed on data that is often completely storedin main memory. Despite of a high main memory scan performance; index structures are stillimportant components; but they have to be designed from scratch to cope with the specificcharacteristics of main memory and to exploit the high degree of parallelism. Currentresearch mainly focused on adapting block-optimized B+-Trees; but these data structureswere designed for secondary memory and involve comprehensive structural maintenancefor updates. In this paper; we present the KISS-Tree; a latch-free in-memory index that isoptimized for a minimum number of memory accesses and a high number of concurrent …,Proceedings of the Eighth International Workshop on Data Management on New Hardware,2012,29
Scalable frequent itemset mining on many-core processors,Benjamin Schlegel; Tomas Karnagel; Tim Kiefer; Wolfgang Lehner,Abstract Frequent-itemset mining is an essential part of the association rule mining process;which has many application areas. It is a computation and memory intensive task with manyopportunities for optimization. Many efficient sequential and parallel algorithms wereproposed in the recent years. Most of the parallel algorithms; however; cannot cope with thehuge number of threads that are provided by large multiprocessor or many-core systems. Inthis paper; we provide a highly parallel version of the well-known Eclat algorithm. It runs onboth; multiprocessor systems and many-core coprocessors; and scales well up to a verylarge number of threads---244 in our experiments. To evaluate mcEclat's performance; weconducted many experiments on realistic datasets. mcEclat achieves high speedups of up to11.5 x and 100x on a 12-core multiprocessor system and a 61-core Xeon Phi many-core …,Proceedings of the Ninth International Workshop on Data Management on New Hardware,2013,22
Experimental Evaluation of NUMA Effects on Database Management Systems.,Tim Kiefer; Benjamin Schlegel; Wolfgang Lehner,Abstract: NUMA systems with multiple CPUs and large main memories are common today.Consequently; database management systems (DBMSs) in data centers are deployed onNUMA systems. They serve a wide range of database use-cases; single large applicationshaving high performance needs as well as many small applications that are consolidated onone machine to save resources and increase utilization. Database servers often show anatural partitioning in the data that is accessed; eg; caused by multiple applicationsaccessing only their data. Knowledge about these partitions can be used to allocate adatabase's memory on the different nodes accordingly: a strategy that increases memorylocality and reduces expensive communication between CPUs. In this work; we show thatpartitioning a database's memory with respect to the data's access patterns can improve …,BTW,2013,21
K-ary search on modern processors,Benjamin Schlegel; Rainer Gemulla; Wolfgang Lehner,Abstract This paper presents novel tree-based search algorithms that exploit the SIMDinstructions found in virtually all modern processors. The algorithms are a natural extensionof binary search: While binary search performs one comparison at each iteration; therebycutting the search space in two halves; our algorithms perform k comparisons at a time andthus cut the search space into k pieces. On traditional processors; this so-called k-ary searchprocedure is not beneficial because the cost increase per iteration offsets the cost reductiondue to the reduced number of iterations. On modern processors; however; multiple scalaroperations can be executed simultaneously; which makes k-ary search attractive. In thispaper; we provide two different search algorithms that differ in terms of efficiency andmemory access patterns. Both algorithms are first described in a platform independent …,Proceedings of the Fifth International Workshop on Data Management on New Hardware,2009,20
An application-specific instruction set for accelerating set-oriented database primitives,Oliver Arnold; Sebastian Haas; Gerhard Fettweis; Benjamin Schlegel; Thomas Kissinger; Wolfgang Lehner,Abstract The key task of database systems is to efficiently manage large amounts of data. Ahigh query throughput and a low query latency are essential for the success of a databasesystem. Lately; research focused on exploiting hardware features like superscalar executionunits; SIMD; or multiple cores to speed up processing. Apart from these softwareoptimizations for given hardware; even tailor-made processing circuits running on FPGAsare built to run mostly stateless query plans with incredibly high throughput. A similar idea;which was already considered three decades ago; is to build tailor-made hardware like adatabase processor. Despite their superior performance; such application-specificprocessors were not considered to be beneficial because general-purpose processorseventually always caught up so that the high development costs did not pay off. In this …,Proceedings of the 2014 ACM SIGMOD International Conference on Management of Data,2014,16
The HELLS-join: a heterogeneous stream join for extremely large windows,Tomas Karnagel; Dirk Habich; Benjamin Schlegel; Wolfgang Lehner,Abstract Upcoming processors are combining different computing units in a tightly-coupledapproach using a unified shared memory hierarchy. This tightly-coupled combination leadsto novel properties with regard to cooperation and interaction. This paper demonstrates theadvantages of those processors for a stream-join operator as an important data-intensiveexample. In detail; we propose our HELLS-Join approach employing all heterogeneousdevices by outsourcing parts of the algorithm on the appropriate device. Our HELLS-Joinperforms better than CPU stream joins; allowing wider time windows; higher streamfrequencies; and more streams to be joined as before.,Proceedings of the Ninth International Workshop on Data Management on New Hardware,2013,14
Qppt: Query processing on prefix trees,Thomas Kissinger; Benjamin Schlegel; Dirk Habich; Wolfgang Lehner,ABSTRACT Modern database systems have to process huge amounts of data and shouldprovide results with low latency at the same time. To achieve this; data is nowadays typicallyhold completely in main memory; to benefit of its high bandwidth and low access latency thatcould never be reached with disks. Current in-memory databases are usually columnstoresthat exchange columns or vectors between operators and suffer from a high tuplereconstruction overhead. In this paper; we present the indexed table-at-a-time processingmodel that makes indexes the first-class citizen of the database system. The processingmodel comprises the concepts of intermediate indexed tables and cooperative operators;which make indexes the common data exchange format between plan operators. To keepthe intermediate index materialization costs low; we employ optimized prefix trees that …,*,2013,11
Heterogeneity-aware operator placement in column-store DBMS,Tomas Karnagel; Dirk Habich; Benjamin Schlegel; Wolfgang Lehner,Abstract Due to the tremendous increase in the amount of data efficiently managed bycurrent database systems; optimization is still one of the most challenging issues indatabase research. Today's query optimizer determine the most efficient composition ofphysical operators to execute a given SQL query; whereas the underlying hardware consistsof a multi-core CPU. However; hardware systems are more and more shifting towardsheterogeneity; combining a multi-core CPU with various computing units; eg; GPU or FPGAcores. In order to efficiently utilize the provided performance capability of suchheterogeneous hardware; the assignment of physical operators to computing units gainsimportance. In this paper; we propose a heterogeneity-aware physical operator placementstrategy (HOP) for in-memory columnar database systems in a heterogeneous …,Datenbank-Spektrum,2014,10
MulTe: a multi-tenancy database benchmark framework,Tim Kiefer; Benjamin Schlegel; Wolfgang Lehner,Abstract Multi-tenancy in relational databases has been a topic of interest for a couple ofyears. On the one hand; ever increasing capabilities and capacities of modern hardwareeasily allow for multiple database applications to share one system. On the other hand;cloud computing leads to outsourcing of many applications to service architectures; which inturn leads to offerings for relational databases in the cloud; as well. The ability to benchmarkmulti-tenancy database systems (MT-DBMSs) is imperative to evaluate and comparesystems and helps to reveal otherwise unnoticed shortcomings. With several tenants sharinga MT-DBMS; a benchmark is considerably different compared to classic databasebenchmarks and calls for new benchmarking methods and performance metrics.Unfortunately; there is no single; well-accepted multi-tenancy benchmark for MT-DBMSs …,Technology Conference on Performance Evaluation and Benchmarking,2012,10
HASHI: An Application Specific Instruction Set Extension for Hashing.,Oliver Arnold; Sebastian Haas; Gerhard Fettweis; Benjamin Schlegel; Thomas Kissinger; Tomas Karnagel; Wolfgang Lehner,ABSTRACT Hashing is one of the most relevant operations within query processing. Almostall core database operators like groupby; selections; or different join implementations rely onhighly efficient hash implementations. In this paper; we present a way to significantlyimprove performance and energy efficiency of hash operations using specialized instructionset extensions for the Tensilica Xtensa LX5 core. To show the applicability of instruction setextensions; we implemented a bit extraction hashing scheme for 32-bit integer keys as wellas the CityHash function for string values. We identify the individual parts of the algorithmsrequired to be optimized; we describe our hashing-specific instruction set; and finally give acomprehensive experimental evaluation. We observed that the hash implementation usingthe hashing-specific instruction set (1) is up to two orders of magnitudes faster than the …,ADMS@ VLDB,2014,8
A high-throughput in-memory index; durable on flash-based SSD: insights into the winning solution of the SIGMOD programming contest 2011,Thomas Kissinger; Benjamin Schlegel; Matthias Boehm; Dirk Habich; Wolfgang Lehner,Abstract Growing memory capacities and the increasing number of cores on modernhardware enforces the design of new in-memory indexing structures that reduce the numberof memory transfers and minimizes the need for locking to allow massive parallel access.However; most applications depend on hard durability constraints requiring a persistentmedium like SSDs; which shorten the latency and throughput gap between main memoryand hard disks. In this paper; we present our winning solution of the SIGMOD ProgrammingContest 2011. It consists of an in-memory indexing structure that provides a balancedread/write performance as well as non-blocking reads and single-lock writes.Complementary to this index; we describe an SSD-optimized logging approach to fit harddurability requirements at a high throughput rate.,ACM SIGMOD Record,2012,8
Stream Join Processing on Heterogeneous Processors.,Tomas Karnagel; Benjamin Schlegel; Dirk Habich; Wolfgang Lehner,Abstract: The window-based stream join is an important operator in all data streamingsystems. It has often high resource requirements so that many efficient sequential as well asparallel versions of it were proposed in the literature. The parallel stream join operatorsrecently gain increasing interest because hardware is getting more and more parallel. Mostof these operators; however; are only optimized for processors with homogeneous executionunits (eg; multi-core processors). Newly available processors with heterogeneous executionunits cannot be exploited whereas such processors provide typically a very high peakperformance. In this paper; we propose an initial variant of a window-based stream joinoperator that is optimized for processors with heterogeneous execution units. We provide anefficient load balancing approach to utilize all available execution units of a processor …,BTW Workshops,2013,7
Frequent itemset mining on multiprocessor systems,Benjamin Schlegel,Abstract Frequent itemset mining is an important building block in many data miningapplications like market basket analysis; recommendation; web-mining; fraud detection; andgene expression analysis. In many of them; the datasets being mined can easily grow up tohundreds of gigabytes or even terabytes of data. Hence; efficient algorithms are required toprocess such large amounts of data. In recent years; there have been many frequent-itemsetmining algorithms proposed; which however (1) often have high memory requirements and(2) do not exploit the large degrees of parallelism provided by modern multiprocessorsystems. The high memory requirements arise mainly from inefficient data structures thathave only been shown to be sufficient for small datasets. For large datasets; however; theuse of these data structures force the algorithms to go out-of-core; ie; they have to access …,*,2013,5
HW/SW-database-codesign for compressed bitmap index processing,Sebastian Haas; Tomas Karnagel; Oliver Arnold; Erik Laux; Benjamin Schlegel; Gerhard Fettweis; Wolfgang Lehner,Compressed bitmap indices are heavily used in scientific and commercial database systemsbecause they largely improve query performance for various workloads. Early researchfocused on finding tailor-made index compression schemes that are amenable for modernprocessors. Improving performance further typically comes at the expense of a lowercompression rate; which is in many applications not acceptable because of memorylimitations. Alternatively; tailor-made hardware allows to achieve a performance that canonly hardly be reached with software running on general-purpose CPUs. In this paper; wewill show how to create a custom instruction set framework for compressed bitmapprocessing that is generic enough to implement most of the major compressed bitmapindices. For evaluation; we implemented WAH; PLWAH; and COMPAX operations using …,Application-specific Systems; Architectures and Processors (ASAP); 2016 IEEE 27th International Conference on,2016,4
Online bit flip detection for in-memory b-trees on unreliable hardware,Till Kolditz; Thomas Kissinger; Benjamin Schlegel; Dirk Habich; Wolfgang Lehner,Abstract Hardware vendors constantly decrease the feature sizes of integrated circuits toobtain better performance and energy efficiency. Due to cosmic rays; low voltage or heatdissipation; hardware--both processors and memory--becomes more and more unreliableas the error rate increases. From a database perspective bit flip errors in main memory willbecome a major challenge for modern in-memory database systems; which keep all theirenterprise data in volatile; unreliable main memory. Although existing hardware error controltechniques like ECC-DRAM are able to detect and correct memory errors; their detectionand correction capabilities are limited. Moreover; hardware error correction faces majordrawbacks in terms of acquisition costs; additional memory utilization; and latency. In thispaper; we argue that slightly increasing data redundancy at the right places by …,Proceedings of the Tenth International Workshop on Data Management on New Hardware,2014,4
ERIS live: a NUMA-aware in-memory storage engine for tera-scale multiprocessor systems,Tim Kiefer; Thomas Kissinger; Benjamin Schlegel; Dirk Habich; Daniel Molka; Wolfgang Lehner,Abstract The ever-growing demand for more computing power forces hardware vendors toput an increasing number of multiprocessors into a single server system; which usuallyexhibits a non-uniform memory access (NUMA). In-memory database systems running onNUMA platforms face several issues such as the increased latency and the decreasedbandwidth when accessing remote main memory. To cope with these NUMA-related issues;a DBMS has to allow flexible data partitioning and data placement at runtime. In thisdemonstration; we present ERIS; our NUMA-aware in-memory storage engine. ERIS usesan adaptive partitioning approach that exploits the topology of the underlying NUMAplatform and significantly reduces NUMA-related issues. We demonstrate throughputnumbers and hardware performance counter evaluations of ERIS and a NUMA-unaware …,Proceedings of the 2014 ACM SIGMOD International Conference on Management of Data,2014,4
PcApriori: scalable Apriori for multiprocessor systems,Benjamin Schlegel; Tim Kiefer; Thomas Kissinger; Wolfgang Lehner,Abstract Frequent-itemset mining is an important part of data mining. It is a computationaland memory intensive task and has a large number of scientific and statistical applicationareas. In many of them; the datasets can easily grow up to tens or even several hundredgigabytes of data. Hence; efficient algorithms are required to process such amounts of data.In the recent years; there have been proposed many efficient sequential mining algorithms;which however cannot exploit current and future systems providing large degrees ofparallelism. Contrary; the number of parallel frequent-itemset mining algorithms is rathersmall and most of them do not scale well as the number of threads is largely increased. Inthis paper; we present a highly-scalable mining algorithm that is based on the well-knownApriori algorithm; it is optimized for processing very large datasets on multiprocessor …,Proceedings of the 25th International Conference on Scientific and Statistical Database Management,2013,4
Forecasting in hierarchical environments,Robert Lorenz; Lars Dannecker; Philipp Rösch; Wolfgang Lehner; Gregor Hackenbroich; Benjamin Schlegel,Abstract Forecasting is an important data analysis technique and serves as the basis forbusiness planning in many application areas such as energy; sales and traffic management.The currently employed statistical models already provide very accurate predictions; but theforecasting calculation process is very time consuming. This is especially true since manyapplication domains deal with hierarchically organized data. Forecasting in theseenvironments is especially challenging due to ensuring forecasting consistency betweenhierarchy levels; which leads to an increased data processing and communication effort. Forthis purpose; we introduce our novel hierarchical forecasting approach; where we proposeto push forecast models to the entities on the lowest hierarch level and reuse these modelsto efficiently create forecast models on higher hierarchical levels. With that we avoid the …,Proceedings of the 25th International Conference on Scientific and Statistical Database Management,2013,4
QDM: A Generic QoS-Aware Data Model for Real-Time Data Stream Processing,Sven Schmidt; Benjamin Schlegel; Wolfgang Lehner,Data stream processing addresses a huge variety of application; ranging from processingcomplex-structured business events to high-volume RFID tag info streams. Some applicationareas; especially in telecommunication or manufacturing; require guarantees with regard topre-defined service constraints. In this paper; we outline the cornerstones of a QoS-awaredata model comprising functional as well as non-functional properties to describe qualityconstraints. We will look at the model from a structural point of view as well as from theoperational perspective. Since the proposed model is specific with regard to QoS constraintand generic with regard to specific operators; it may serve as a blue-print for a broadspectrum of data stream systems.,Digital Telecommunications; 2007. ICDT'07. Second International Conference on,2007,4
Next Generation Database Programming and Execution Environment.,Dirk Habich; Matthias Boehm; Maik Thiele; Benjamin Schlegel; Ulrike Fischer; Hannes Voigt; Wolfgang Lehner,ABSTRACT The database research is always on the move. In order to integrate novelconcepts; the significance of the database programmability aspect more and moreincreases. The programmability aspect focuses on internal components as well as onprinciple to push-down application logic to the database system. In this paper; we propose anovel database programming model and a corresponding database architecture frameworkenabling extensibility and a better integration of application code into DBMS. In detail; wepresent a scripting language pyDBL which is unified utilizable to implement physicaldatabase operators; query plans and even complete applications. We demonstrate theapplicability of our approach in terms of a moderate performance overhead.,DBPL,2011,3
Online bit flip detection for in-memory B-trees live!,Till Kolditz; Benjamin Schlegel; Dirk Habich; Wolfgang Lehner,Hardware vendors constantly decrease the feature sizes of integrated circuits to obtainhigher performance and energy efficiency. As a side-effect; integrated circuits-like CPUs andmain memory-become more and more vulnerable to external influences and thus unreliable;which results in increasing numbers of (multi-) bit flips. From a database perspective bit fliperrors in main memory will become a major challenge for modern in-memory databasesystems; which keep all their enterprise data in volatile; unreliable main memory. Existinghardware error control techniques like ECC-DRAM are able to detect and correct memoryerrors; but their detection and correction capabilities are limited and come along with severaldownsides. To underline this we heat up RAM live on-site to show possible error rates offuture hardware. We previously presented various techniques for the B-Tree-as a wide …,Datenbanksysteme für Business; Technologie und Web (BTW 2015),2015,*
Query processing on prefix trees live,Thomas Kissinger; Benjamin Schlegel; Dirk Habich; Wolfgang Lehner,Abstract Modern database systems have to process huge amounts of data and shouldprovide results with low latency at the same time. To achieve this; data is nowadays typicallyhold completely in main memory; to benefit of its high bandwidth and low access latency thatcould never be reached with disks. Current in-memory databases are usually column-storesthat exchange columns or vectors between operators and suffer from a high tuplereconstruction overhead. In this demonstration proposal; we present DexterDB; whichimplements our novel prefix tree-based processing model that makes indexes the first-classcitizen of the database system. The core idea is that each operator takes a set of indexes asinput and builds a new index as output that is indexed on the attribute requested by thesuccessive operator. With that; we are able to build composed operators; like the multi …,Proceedings of the 2013 ACM SIGMOD International Conference on Management of Data,2013,*
Multi-GPU Approximation for Silent Data Corruption of AN Codes,Matthias Werner; Till Kolditz; Tomas Karnagel; Dirk Habich; Wolfgang Lehner,Background The key objective of database systems is to reliably manage data; while highquery throughput and low query latency are core requirements [1]. To satisfy theserequirements for a constantly increasing amount of data; database systems constantly adaptto new hardware features [2; 3; 4; 5; 6; 7]; for instance: new instruction sets; increasing corecounts; changing core/cache topologies; increasing DRAM bandwidths; or new persistencetechnologies (nvRAM)[8; 9; 10]. These advances come with a backdraw; though: for a longtime it has been known that hardware is subject to soft and hard errors [11; 12; 13]. Softerrors are also called bit flips; which may occur due to cosmic rays; heat; hardware aging; orelectrical crosstalk; which; in turn; is due to the ongoing miniaturization of integrated curcuits[11; 14]. Hardware aging even leads to increasing error rates during a system's run-time …,Further Improvements in the Boolean Domain,*,*
BOOK-CHAPTERS,HaHL11 Martin Hahmann; Dirk Habich; Wolfgang Lehner; KHSL13 Tomas Karnagel; Benjamin Schlegel; MKHL13 Lukas M Maas; Thomas Kissinger,Hab08 Dirk Habich: Komplexe Datenanalyseprozesse in serviceorientierten Umgebungen.(PhD-Thesis); Technische Universität Dresden; Fakultät Informatik; Institut fürSystemarchitektur; Lehrstuhl Datenbanken … ThHa07 Maik Thiele; Dirk Habich: Orchestrierungdatenintensiver Prozes- se - Einsatz von BPEL in der Genexpressionsanalyse.; VDM Ver- lagDr. Müller; Saarbrücken; Germany ISBN: 978-3-8364-0239-2; 2007 … HaHL11 MartinHahmann; Dirk Habich; Wolfgang Lehner: Large-Scale Data Analytics using EnsembleClustering; In: Handbook of Data Intensive Computing; Editors: Borko Furht and ArmandoEscalante; ISBN 978-1- 4614-1415-5; pages 285-322; 2011 … KHSL13 Tomas Karnagel; DirkHabich; Benjamin Schlegel; Wolfgang Lehner: The HELLS-join: a heterogeneous stream joinfor extremely large win- dows; In: Proceedings of the Ninth International Workshop on …,*,*,*
ERIS: A NUMA-AWARE IN-MEMORY STORAGE ENGINE FOR TERA-SCALE ANALYTICAL WORKLOAD,Benjamin Schlegel; Dirk Habich; Daniel Molka; Wolfgang Lehner,Page 1. © Prof. Dr.-Ing. Wolfgang Lehner | Thomas Kissinger 2014/09/01 Tim Kiefer ADMS 2014Benjamin Schlegel Hangzhou; China Dirk Habich Daniel Molka Wolfgang Lehner ERIS: ANUMA-AWARE IN-MEMORY STORAGE ENGINE FOR TERA-SCALE ANALYTICAL WORKLOADPage 2. | 2 Motivation ERIS: A NUMA-Aware In-Memory Storage Engine for Tera-Scale AnalyticalWorkload Databases in the many-core era 0 0.5 1 1.5 2 0 0.5 1 1.5 2 2.5 3 3.5 0 64 128 192256 320 384 448 Scan Th rough p u t [TiB/s] Loo ku p Thro u gh p u t [Billio n /s] #Cores SharedLookup ERIS Lookup Shared Scan ERIS Scan Page 3. | 3 NUMA Systems ERIS: A NUMA-AwareIn-Memory Storage Engine for Tera-Scale Analytical Workload 85 196 16.4 1.8 0 50 100 150200 250 local remote 0 5 10 15 20 latency (ns) bandwidth (GB/s) AMD 8 nodes 64 cores 64GBs max 2 hops Page 4. | 4 NUMA Systems …,*,*,*
