Flexible Information Management; Exploration and Analysis in SAP HANA.,Christof Bornhövd; Robert Kubis; Wolfgang Lehner; Hannes Voigt; Horst Werner,Abstract: Data management is not limited anymore to towering data silos full of perfectlystructured; well integrated data. Today; we need to process and make sense of data fromdiverse sources (public and on-premise); in different application contexts; with differentschemas; and with varying degrees of structure and quality. Because of the necessity todefine a rigid data schema upfront; fixed-schema database systems are not a good fit forthese new scenarios. However; schema is still essential to give data meaning and toprocess data purposefully. In this paper; we describe a schema-flexible database systemthat combines a flexible data model with a powerful data query; analysis; and manipulationlanguage that provides both required schema information and the flexibility required formodern information processing and decision support.,DATA,2012,14
CoDEL–a relationally complete language for database evolution,Kai Herrmann; Hannes Voigt; Andreas Behrend; Wolfgang Lehner,Abstract Software developers adapt to the fast-moving nature of software systems with agiledevelopment techniques. However; database developers lack the tools and concepts tokeep pace. Data; already existing in a running product; needs to be evolved accordingly;usually by manually written SQL scripts. A promising approach in database research is touse a declarative database evolution language; which couples both schema and dataevolution into intuitive operations. Existing database evolution languages focus on usabilitybut did not aim for completeness. However; this is an inevitable prerequisite for reasonabledatabase evolution to avoid complex and error-prone workarounds. We argue that relationalcompleteness is the feasible expressiveness for a database evolution language. Buildingupon an existing language; we introduce CoDEL. We define its semantic using relational …,East European Conference on Advances in Databases and Information Systems,2015,11
Rsql-a query language for dynamic data types,Tobias Jäkel; Thomas Kühn; Hannes Voigt; Wolfgang Lehner,Abstract Database Management Systems (DBMS) are used by software applications; tostore; manipulate; and retrieve large sets of data. However; the requirements of currentsoftware systems pose various challenges to established DBMS. First; most softwaresystems organize their data by means of objects rather than relations leading to increasedmaintenance; redundancy; and transformation overhead when persisting objects torelational databases. Second; complex objects are separated into several objects resultingin Object Schizophrenia and hard to persist Distributed State. Last but not least; currentsoftware systems have to cope with increased complexity and changes. These challengeshave lead to a general paradigm shift in the development of software systems. Unfortunately;classical DBMS will become intractable; if they are not adapted to the new requirements …,Proceedings of the 18th International Database Engineering & Applications Symposium,2014,10
Relationships for dynamic data types in RSQL,Tobias Jäkel; Thomas Kühn; Stefan Hinkel; Hannes Voigt; Wolfgang Lehner,Currently; there is a mismatch between the conceptual model of an information system andits implementation in a database management system (DBMS). Most of the conceptualmodeling languages relate their conceptual entities with relationships; but relationaldatabase management systems solely rely on the notion of relations to model both; entitiesand relationships. To make things worse; real world objects are not static as assumed insuch modeling languages; but change over time. Thus; modeling languages were enrichedto model those scenarios; as well. However; mapping these models onto relationaldatabases requires the use of object-relational mapping engines; which in turn hide thesemantics of the conceptual model from the DBMS. Consequently; traditional relationaldatabase systems cannot directly ensure specific consistency constraints and thus lose …,Datenbanksysteme für Business; Technologie und Web (BTW 2015),2015,8
Smix: Self-managing indexes for dynamic workloads,Hannes Voigt; Thomas Kissinger; Wolfgang Lehner,Abstract As databases accumulate growing amounts of data at an increasing rate; adaptiveindexing becomes more and more important. At the same time; applications and their useget more agile and flexible; resulting in less steady and less predictable workloadcharacteristics. Being inert and coarse-grained; state-of-the-art index tuning techniquesbecome less useful in such environments. Especially the full-column indexing paradigmresults in many indexed but never queried records and prohibitively high storage andmaintenance costs. In this paper; we present Self-Managing Indexes; a novel; adaptive; fine-grained; autonomous indexing infrastructure. In its core; our approach builds on a novelaccess path that automatically collects useful index information; discards useless indexinformation; and competes with its kind for resources to host its index information …,Proceedings of the 25th International Conference on Scientific and Statistical Database Management,2013,6
Towards a role-based contextual database,Tobias Jäkel; Thomas Kühn; Hannes Voigt; Wolfgang Lehner,Abstract Traditional modeling approaches and information systems assume static entitiesthat represent all information and attributes at once. However; due to the evolution ofinformation systems to increasingly context-aware and self-adaptive systems; thisassumption no longer holds. To cope with the required flexibility; the role concept wasintroduced. Although researchers have proposed several role modeling approaches; theyusually neglect the contextual characteristics of roles and their representation in databasemanagement systems. Unfortunately; these systems do not rely on a conceptual model of aninformation system; rather they model this information by their own means leading totransformation and maintenance overhead. So far; the challenges posed by dynamiccomplex entities; their first class implementation; and their contextual characteristics lack …,East European Conference on Advances in Databases and Information Systems,2016,5
SynopSys: foundations for multidimensional graph analytics,Michael Rudolf; Hannes Voigt; Christof Bornhövd; Wolfgang Lehner,Abstract The past few years have seen a tremendous increase in often irregularly structureddata that can be represented most naturally and efficiently in the form of graphs. Makingsense of incessantly growing graphs is not only a key requirement in applications like socialmedia analysis or fraud detection but also a necessity in many traditional enterprisescenarios. Thus; a flexible approach for multidimensional analysis of graph data is needed.Whereas many existing technologies require up-front modelling of analytical scenarios andare difficult to adapt to changes; our approach allows for ad-hoc analytical queries of graphdata. Extending our previous work on graph summarization; in this position paper we lay thefoundation for large graph analytics to enable business intelligence on graph-structureddata.,*,2015,5
Flexs–a logical model for physical data layout,Hannes Voigt; Alfred Hanisch; Wolfgang Lehner,Abstract Driven by novel application domains and hardware trends database research anddevelopment set off to many novel and specialized architectures. Particularly in the area ofphysical data layout; specialized solutions have shown exceptional performance for specificapplications. This trend is great for research and development and for those in need of top-level performance first and foremost. For those with moderate performance needs; however;a universal but flexible database system has the benefit of lower TCO. Regarding physicaldata layout; the more general systems are fairly inflexible compared to the variety of physicaldata layouts available in specialized systems. Particularly; the macroscopic characteristics;ie; how the data is grouped and clustered; are generally hard-coded and cannot be changedby configuration. We present Flexs; a declarative storage description language for the …,*,2015,5
Living in parallel realities: Co-existing schema versions with a bidirectional database evolution language,Kai Herrmann; Hannes Voigt; Andreas Behrend; Jonas Rausch; Wolfgang Lehner,Abstract We introduce end-to-end support of co-existing schema versions within onedatabase. While it is state of the art to run multiple versions of a continuously developedapplication concurrently; it is hard to do the same for databases. In order to keep multiple co-existing schema versions alive--which are all accessing the same data set--developersusually employ handwritten delta code (eg views and triggers in SQL). This delta code ishard to write and hard to maintain: if a database administrator decides to adapt the physicaltable schema; all handwritten delta code needs to be adapted as well; which is expensiveand error-prone in practice. In this paper; we present InVerDa: developers use the simplebidirectional database evolution language BiDEL; which carries enough information togenerate all delta code automatically. Without additional effort; new schema versions …,Proceedings of the 2017 ACM International Conference on Management of Data,2017,4
Stream-Based Web Service Invocation.,Steffen Preißler; Hannes Voigt; Dirk Habich; Wolfgang Lehner,Abstract: Service-oriented architectures (SOA) based on Web service technology play anincreasingly important role in many different application areas. The current serviceinvocation methodology suffers from performance problems and heavy resourceconsumption when services are used to process large amounts of data. A number ofsolutions to this problem have been proposed. Unfortunately; these modified invocationmethodologies are applicable only to a limited number of business scenarios; because theydo not provide all features of the traditional methodology. In this paper; we introduce a newservice invocation methodology that allows large volume data processing and does not limitapplicability. Our approach macerates the existing request–response paradigm andincorporates stream semantics into the Web service invocation methodology without …,BTW,2009,4
Constrained dynamic physical database design,Hannes Voigt; Wolfgang Lehner; Kenneth Salem,Abstract Physical design has always been an important part of database administration.Today's commercial database management systems offer physical design tools; whichrecommend a physical design for a given workload. However; these tools work only withstatic workloads and ignore the fact that workloads; and physical designs; may change overtime. Research has now begun to focus on dynamic physical design; which can account fortime-varying workloads. In this paper; we consider a dynamic but constrained approach tophysical design. The goal is to recommend dynamic physical designs that reflect majorworkload trends but that are not tailored too closely to the details of the input workloads. Toachieve this; we constrain the number of changes that are permitted in the recommendeddesign. In this paper we present our definition of the constrained dynamic physical design …,SMDB’08,2008,4
Online horizontal partitioning of heterogeneous data,Kai Herrmann; Hannes Voigt; Wolfgang Lehner,Abstract In an increasing number of use cases; databases face the challenge of managingheterogeneous data. Heterogeneous data is characterized by a quickly evolving variety ofentities without a common set of attributes. These entities do not show enough regularity tobe captured in a traditional database schema. A common solution is to centralize the diverseentities in a universal table. Usually; this leads to a very sparse table. Although today'stechniques allow efficient storage of sparse universal tables; query efficiency is still aproblem. Queries that address only a subset of attributes have to read the whole universaltable including many irrelevant entities. A solution is to use a partitioning of the table; whichallows pruning partitions of irrelevant entities before they are touched. Creating andmaintaining such a partitioning manually is very laborious or even infeasible; due to the …,it–Information Technology,2014,3
Adaptive index buffer,Hannes Voigt; Tobias Jaekel; Thomas Kissinger; Wolfgang Lehner,With rapidly increasing datasets and more dynamic workloads; adaptive partial indexingbecomes an important way to keep indexing efficiently. During times of changing workloads;the query performance suffers from inefficient tables scans while the index tuningmechanism adapts the partial index. In this paper we present the Adaptive Index Buffer. TheAdaptive Index Buffer reduces the cost of table scans by quickly indexing tuples in memoryuntil the partial index has adapted to the workload again. We explain the basic operatingmode of an Index Buffer and discuss how it adapts to changing workload situations. Further;we present three experiments that show the Index Buffer at work.,Data Engineering Workshops (ICDEW); 2012 IEEE 28th International Conference on,2012,3
MOAW: An Agile Visual Modeling and Exploration Tool for Irregularly Structured Data.,Horst Werner; Christof Bornhoevd; Robert Kubis; Hannes Voigt,Abstract: The Mother of all Whiteboards (MOAW) is an innovative visual modeling andexploration tool for semi-structured information. It combines gesture-based user interactionwith deep zooming; particle dynamics and the powerful data processing capabilities ofSAP's newly developed Active Information Store. This application has been designed toconvey complex information by easily created visual models which are backed by a formalrepresentation and thus allow the fluid navigation to unlimited levels of detail and creation ofdifferent angles of view.,BTW,2011,3
Next Generation Database Programming and Execution Environment.,Dirk Habich; Matthias Boehm; Maik Thiele; Benjamin Schlegel; Ulrike Fischer; Hannes Voigt; Wolfgang Lehner,ABSTRACT The database research is always on the move. In order to integrate novelconcepts; the significance of the database programmability aspect more and moreincreases. The programmability aspect focuses on internal components as well as onprinciple to push-down application logic to the database system. In this paper; we propose anovel database programming model and a corresponding database architecture frameworkenabling extensibility and a better integration of application code into DBMS. In detail; wepresent a scripting language pyDBL which is unified utilizable to implement physicaldatabase operators; query plans and even complete applications. We demonstrate theapplicability of our approach in terms of a moderate performance overhead.,DBPL,2011,3
Innovative Process Execution in Service-oriented Environments.,Dirk Habich; Steffen Preissler; Hannes Voigt; Wolfgang Lehner,Abstract: Today's information systems are often built on the foundation of service-orientedenvironments. Although the fundamental purpose of an information system is the processingof data and information; the service-oriented architecture (SOA) does not treat data as a corefirst class citizen. Current SOA technologies support neither the explicit modeling of dataflows in common business process modeling languages (such as BPMN) nor the usage ofspecialized data transformation and propagation technologies (for instance ETL-tools) onthe process execution layer (BPEL). In this paper; we introduce our data-aware approach onthe execution perspective as well as on the modeling perspective of business processes.,ICEIS (1),2009,3
Robust and simple database evolution,Kai Herrmann; Hannes Voigt; Jonas Rausch; Andreas Behrend; Wolfgang Lehner,Abstract Software developers adapt to the fast-moving nature of software systems with agiledevelopment techniques. However; database developers lack the tools and concepts tokeep the pace. Whenever the current database schema is evolved; the already existing dataneeds to be evolved as well. This is usually realized with manually written SQL scripts;which is error-prone and explains significant costs in software projects. A promising solutionare declarative database evolution languages; which couple both schema and dataevolution into intuitive operations. Existing database evolution languages focus on usabilitybut do not strive for completeness. However; this is an inevitable prerequisite to avoidcomplex and error-prone workarounds. We present CoDEL which is based on an existinglanguage but is relationally complete. We precisely define its semantic using relational …,Information Systems Frontiers,2018,2
Declarative Graph Querying in Practice and Theory.,George HL Fletcher; Hannes Voigt; Nikolay Yakovets,ABSTRACT With the recent resurgence of interest in graph data management; there hasbeen a flurry of research on the design and engineering of graph query languages. On thedesign side; there is a large body of theoretical results that have been obtained regardinggraph languages. On the engineering side; many sophisticated scalable solutions for graphquery processing have been developed and put into practice. While both areas are focusingon the study of graph query languages; there has been relatively little work bridging theresults on both sides. This tutorial will survey the state of the art in this landscape with aparticular focus on uncovering and highlighting indicative research issues that are ripe forcollaboration and cross-fertilization between the engineering and theoretical studies ofgraph database systems.,EDBT,2017,2
InVerDa-co-existing schema versions made foolproof,Kai Herrmann; Hannes Voigt; Thorsten Seyschab; Wolfgang Lehner,In modern software landscapes multiple applications usually share one database as theirsingle point of truth. All these applications will evolve over time by their very nature. Oftenformer versions need to stay available; so database developers find themselves maintainingco-existing schema version of multiple applications in multiple versions. This is highly error-prone and accounts for significant costs in software projects; as developers realize thetranslation of data accesses between schema versions with hand-written delta code. In thisdemo; we showcase INVERDA; a tool for integrated; robust; and easy to use databaseversioning. We rethink the way of specifying the evolution to new schema versions. Usingthe richer semantics of a descriptive database evolution language; we generate all requiredartifacts automatically and make database versioning foolproof.,Data Engineering (ICDE); 2016 IEEE 32nd International Conference on,2016,2
Optimizing continuous queries using update propagation with varying granularities,Andreas Behrend; Ulrike Griefahn; Hannes Voigt; Philip Schmiegelt,Abstract We investigate the possibility to use update propagation methods for optimizing theevaluation of continuous queries. Update propagation allows for the efficient determinationof induced changes to derived relations resulting from an explicitly performed base tableupdate. In order to simplify the computation process; we propose the propagation of updateswith different degrees of granularity which corresponds to an incremental query evaluationwith different levels of accuracy. We show how propagation rules for different updategranularities can be systematically derived; combined and further optimized by using MagicSets. This way; the costly evaluation of certain subqueries within a continuous query can besystematically circumvented allowing for cutting down on the number of pipelined tuplesconsiderably.,Proceedings of the 27th International Conference on Scientific and Statistical Database Management,2015,2
Flexible relational data model–a common ground for schema-flexible database systems,Hannes Voigt; Wolfgang Lehner,Abstract An increasing number of application fields represent dynamic and open discoursescharacterized by high mutability; variety; and pluralism in data. Data in dynamic and opendiscourses typically exhibits an irregular schema. Such data cannot be directly representedin the traditional relational data model. Mapping strategies allow representation but increasedevelopment and maintenance costs. Likewise; NoSQL systems offer the required schemaflexibility but introduce new costs by not being directly compatible with relational systemsthat still dominate enterprise information systems. With the Flexible Relational Data Model(FRDM) we propose a third way. It allows the direct representation of data with irregularschemas. It combines tuple-oriented data representation with relation-oriented dataprocessing. So that; FRDM is still relational; in contrast to other flexible data models …,East European Conference on Advances in Databases and Information Systems,2014,2
Cinderella—Adaptive online partitioning of irregularly structured data,Kai Herrmann; Hannes Voigt; Wolfgang Lehner,In an increasing number of use cases; databases face the challenge of managing irregularlystructured data. Irregularly structured data is characterized by a quickly evolving variety ofentities without a common set of attributes. These entities do not show enough regularity tobe captured in a traditional database schema. A common solution is to centralize the diverseentities in a universal table. Usually; this leads to a very sparse table. Although today'stechniques allow efficient storage of sparse universal tables; query efficiency is still aproblem. Queries that reference only a subset of attributes have to read the whole universaltable including many irrelevant entities. One possible solution is to use a partitioning of thetable; which allows pruning partitions of irrelevant entities before they are touched. Creatingand maintaining such a partitioning manually is very laborious or even infeasible; due to …,Data Engineering Workshops (ICDEW); 2014 IEEE 30th International Conference on,2014,2
Pack Indexing for Time-Constrained In-Memory Query Processing.,Tobias Jaekel; Hannes Voigt; Thomas Kissinger; Wolfgang Lehner,Abstract: Main memory databases management systems are used more often and in a widespread of application scenarios. To take significant advantage of the main memory readperformance; most techniques known from traditional disk-centric database systems have tobe adapted and re-designed. In the field of indexing; many mainmemory-optimized indexstructures have been proposed. Most of these works aim at primary indexing. Secondaryindexes are rarely considered in the context of main memory databases. Either queryperformance is sufficiently good without secondary indexing or main memory is a resourcetoo scarce to invest in huge secondary indexes. A more subtle trade between benefit andcosts of secondary indexing has not been considered so far. In this paper we present PackIndexing; a secondary indexing technique for main memory databases that allows a …,BTW,2013,2
SMIX Live--A Self-Managing Index Infrastructure for Dynamic Workloads,Thomas Kissinger; Hannes Voigt; Wolfgang Lehner,As databases accumulate growing amounts of data at an increasing rate; adaptive indexingbecomes more and more important. At the same time; applications and their use get moreagile and flexible; resulting in less steady and less predictable workload characteristics.Being inert and coarse-grained; state-of-the-art index tuning techniques become less usefulin such environments. Especially the full-column indexing paradigm results in lot of indexedbut never queried data and prohibitively high memory and maintenance costs. In ourdemonstration; we present Self-Managing Indexes; a novel; adaptive; fine-grained;autonomous indexing infrastructure. In its core; our approach builds on a novel access paththat automatically collects useful index information; discards useless index information; andcompetes with its kind for resources to host its index information. Compared to existing …,Data Engineering (ICDE); 2012 IEEE 28th International Conference on,2012,2
Poster session: Constrained dynamic physical database design,Hannes Voigt; Wolfgang Lehner; Kenneth Salem,Physical design has always been an important part of database administration. Today'scommercial database management systems offer physical design tools; which recommend aphysical design for a given workload. However; these tools work only with static workloadsand ignore the fact that workloads; and physical designs; may change over time. Researchhas now begun to focus on dynamic physical design; which can account for time-varyingworkloads. In this paper; we consider a dynamic but constrained approach to physicaldesign. The goal is to recommend dynamic physical designs that reflect major workloadtrends but that are not tailored too closely to the details of the input workloads. To achievethis; we constrain the number of changes that are permitted in the recommended design. Inthis paper we present our definition of the constrained dynamic physical design problem …,Data Engineering Workshop; 2008. ICDEW 2008. IEEE 24th International Conference on,2008,2
Partitioning Strategy Selection for In-Memory Graph Pattern Matching on Multiprocessor Systems,Alexander Krause; Thomas Kissinger; Dirk Habich; Hannes Voigt; Wolfgang Lehner,Abstract Pattern matching on large graphs is the foundation for a variety of applicationdomains. The continuously increasing size of the underlying graphs requires highly parallelin-memory graph processing engines that need to consider non-uniform memory access(NUMA) and concurrency issues to scale up on modern multiprocessor systems. To tacklethese aspects; a fine-grained graph partitioning becomes increasingly important. Hence; wepresent a classification of graph partitioning strategies and evaluate representativealgorithms on medium and large-scale NUMA systems in this paper. As a scalable patternmatching processing infrastructure; we leverage a data-oriented architecture that preservesdata locality and minimizes concurrency-related bottlenecks on NUMA systems. Our in-depth evaluation reveals that the optimal partitioning strategy depends on a variety of …,European Conference on Parallel Processing,2017,1
SPARQLytics: multidimensional analytics for RDF,Michael Rudolf; Hannes Voigt; Wolfgang Lehner,With the rapid growth of open RDF data in recent years; being able to performmultidimensional analytics with it has become more and more important; in particular for thedata analyst performing explorative business intelligence tasks. Existing analyticapproaches are often not flexible enough to address the needs of data analysts andenthusiasts with iterative exploratory workflows. In this paper we propose SPARQLytics; atool that exposes the concepts of multidimensional graph analytics by offering standardOLAP cube operations and generating SPARQL queries. Our evaluation shows thatSPARQLytics unburdens data analysts from writing many lines of SPARQL code in iterativedata explorations and at the same time it does not impose any overhead to query execution.SPARQLytics fits well with interactive computing tools; such as Jupyter; providing data …,Datenbanksysteme für Business; Technologie und Web (BTW 2017),2017,1
Position Paper: Runtime Model for Role-Based Software Systems,Tobias Jäkel; Martin Weißbach; Kai Herrmann; Hannes Voigt; Max Leuthäuser,In the increasingly dynamic realities of today's software systems; it is no longer feasible toalways expect human developers to react to changing environments and changingconditions immediately. Instead; software systems need to be self-aware and autonomouslyadapt their behavior according to their experiences gathered from their environment. Currentresearch provides role-based modeling as a promising approach to handle the adaptivityand self-awareness within a software system. There are established role-based systems eg;for application development; persistence; and so on. However; these are isolatedapproaches using the role-based model on their specific layer and mapping to existing non-role-based layers. We present a global runtime model covering the whole stack of a softwaresystem to maintain a global view of the current system state and model the …,Autonomic Computing (ICAC); 2016 IEEE International Conference on,2016,1
Declarative multidimensional graph queries,Hannes Voigt,Abstract Graphs have become an ubiquitous type of data; increasing the desire and need toperform analytics on graph data. In this article; we review the fundamental concepts that formthe common basis of most declarative graph querying languages. The article conveys ageneral understanding of these concepts which will help the reader to learn a specific graphquery language; rotate between graph query language; and work with graph databasesystem in general. We also provide examples in query languages such as Cypher andSPARQL that illustrate how the discussed concept manifest in specific graph querylanguages. Further; we take a look at how these concepts of declarative graph querylanguages can be extended towards declarative multidimensional queries; to facilitate themost fundamental form of analytics on graphs in graph database systems. This helps the …,European Business Intelligence Summer School,2016,1
Multidimensional graph analytics,*,Disclosed herein are system; method; and computer program product embodiments forperforming ad-hoc analytical queries of graph data. An embodiment operates by receiving agraph pattern for a subgraph of interest. The facts of interest are then selected from graphdata based on the received graph pattern. Dimensions are then defined based on adimension seed pattern and a set of level expressions; and measures are defined based ona computation function and an aggregation function. A graph cube is formed based on theselected facts and the defined dimensions and measures. Because the facts; dimensions;and measures of interest are defined at the time of an analytical query; a user does not haveto define such facts; dimensions; and measures; or know which analytical queries will be ofinterest; at the time of data collection.,*,2016,1
Database Evolution for Software Product Lines,Kai Herrmann; Jan Reimann; Hannes Voigt; Birgit Demuth; Stefan Fromm; Robert Stelzmann; Wolfgang Lehner,Google; Inc. (search). SIGN IN SIGN UP. Database Evolution for Software ProductLines. Authors: Kai Herrmann; Technische Universität Dresden. Jan Reimann;Technische Universität Dresden. Hannes Voigt; Technische Universität Dresden. BirgitDemuth; Technische Universität Dresden. Stefan Fromm; Dresden-Informatik GmbH.Robert Stelzmann; iSAX GmbH & Co. KG. Wolfgang Lehner.,Proceedings of 4th International Conference on Data Management Technologies and Applications,2015,1
Ein begriffsbasierter Ansatz zur semantischen Extraktion von Datenbankschemata.,Henri Mühle; Hannes Voigt; Wolfgang Lehner,Abstract: Die durch das rasante Anwachsen digitaler Datenbestände in Volumen und Vielfaltnotwendig gewordene effiziente Verwaltung der erhobenen Datenbestände; bringtherkömmliche Datenbankmethoden an ihre Grenzen. Ein modelliertes Datenbankschemazur Grundstrukturierung der Datenbank kann längst nicht mehr statisch rigide modelliertwerden. Vielmehr werden schemaflexible Datenbanken benötigt; die ihr Schemaentsprechend an Anderungen im Datenbestand anpassen können. Da dasDatenbankschema basierend auf einer konzeptuellen Datenbanksicht modelliert wird;präsentieren wir einen Ansatz; der die Formale Begriffsanalyse als Modellierungsmethodeeinsetzt. Die Formale Begriffsanalyse greift genau diese begriffsorientierte Weltsicht auf.Damit können wir Schemaextraktion und weiterführende Problemstellungen mit wohl …,Software Engineering (Workshops),2010,1
Streaming Web Services and Standing Processes.,Steffen Preißler; Hannes Voigt; Dirk Habich; Wolfgang Lehner,Abstract: Today; service orientation is a well established concept in modern ITinfrastructures. Web services and WS-BPEL as the two key technologies handle largestructured data sets very inefficiently because they process the whole data set at once. Inthis demo; we present a framework to build standing business processes. Standing businessprocesses rely on item-wise data set processing; exploit pipeline parallelism and show asignificantly higher throughput than the traditional WS-BPEL approach.,BTW,2009,1
G-CORE: A Core for Future Graph Query Languages,Renzo Angles; Marcelo Arenas; George HL Fletcher; Claudio Gutierrez; Tobias Lindaaker; Marcus Paradies; Stefan Plantikow; Juan Sequeda; Oskar van Rest; Hannes Voigt,Abstract: We report on a community effort between industry and academia to shape thefuture of graph query languages. We argue that existing graph database managementsystems should consider supporting a query language with two key characteristics. First; itshould be composable; meaning; that graphs are the input and the output of queries.Second; the graph query language should treat paths as first-class citizens. Our result is G-CORE; a powerful graph query language design that fulfills these goals; and strikes a carefulbalance between path query expressivity and evaluation complexity. Subjects: Databases(cs. DB) Cite as: arXiv: 1712.01550 [cs. DB](or arXiv: 1712.01550 v1 [cs. DB] for this version)Submission history From: Hannes Voigt [view email][v1] Tue; 5 Dec 2017 09: 59: 47 GMT(329kb; D),arXiv preprint arXiv:1712.01550,2017,*
Big Graph Data Analytics on Single Machines–An Overview,Marcus Paradies; Hannes Voigt,Abstract Driven by a multitude of use cases; graph data analytics has become a hot topic inresearch and industry. Particularly on big graphs; performing complex analytical queriesefficiently to derive new insights is a challenging task. Systems that aim at solving thetechnical part of this challenge are often referred to as graph processing systems. Theyallow expressing and executing analytic algorithms and queries; while hiding most of thetechnical details related to efficiently storing and processing graph data. Since 2010; workon graph processing systems for distributed systems as well as shared memory systems hasvirtually exploded. In this article; we give an overview of this work with the particular focus ongraph processing systems for large multiprocessor machines. We describe the state of theart established in recent years and outline trends and challenges in research and …,Datenbank-Spektrum,2017,*
An Analysis of the Feasibility of Graph Compression Techniques for Indexing Regular Path Queries,Frank Tetzel; Hannes Voigt; Marcus Paradies; Wolfgang Lehner,Abstract Regular path queries (RPQs) are a fundamental part of recent graph querylanguages like SPARQL and PGQL. They allow the definition of recursive path structuresthrough regular expressions in a declarative pattern matching environment. We study theuse of the K2-tree graph compression technique to materialize RPQ results with low memoryconsumption for indexing. Compact index representations enable the efficient storage ofmultiple indexes for varying RPQs.,Proceedings of the Fifth International Workshop on Graph Data-management Experiences & Systems,2017,*
InVerDa–The Liquid Database,Kai Herrmann; Hannes Voigt; Thorsten Seyschab; Wolfgang Lehner,Multiple applications; which share one common database; will evolve over time by their verynature. Often; former versions need to stay available; so database developers findthemselves maintaining co-existing schema versions of multiple applications in multipleversions—usually with handwritten delta code—which is highly error-prone and explainssignificant costs in software projects. We showcase IVD; a tool using the richer semantics ofa bidirectional database evolution language to generate all the delta code automatically;easily providing co-existing schema versions within one database. IVD automaticallydecides on an optimized physical database schema serving all schema versions totransparently optimize the performance for the current workload.,Datenbanksysteme für Business; Technologie und Web (BTW 2017),2017,*
Logical Data Independence in the 21st Century--Co-Existing Schema Versions with InVerDa,Kai Herrmann; Hannes Voigt; Andreas Behrend; Jonas Rausch; Wolfgang Lehner,Abstract: We present InVerDa; a tool for end-to-end support of co-existing schema versionswithin one database. While it is state of the art to run multiple versions of a continuouslydeveloped application concurrently; the same is hard for databases. In order to keepmultiple co-existing schema versions alive; that all access the same data set; developersusually employ handwritten delta code (eg views and triggers in SQL). This delta code ishard to write and hard to maintain: if a database administrator decides to adapt the physicaltable schema; all handwritten delta code needs to be adapted as well; which is expensiveand error-prone in practice. With InVerDa; developers use a simple bidirectional databaseevolution language in the first place that carries enough information to generate all the deltacode automatically. Without additional effort; new schema versions become immediately …,arXiv preprint arXiv:1608.05564,2016,*
HUGS-A Lightweight Graph Partitioning Approach.,Alexander Krause; Hannes Voigt; Wolfgang Lehner,ABSTRACT The growing interest in graph data lead to increasingly more research in thefield of graph data management and graph analytics. Nowadays; even large graphs of uptoa size of billions of vertices and edges fit into main memory of big modern multisocketmachines; making them a first-grade platform for graph management and graph analytics.High performance data management solutions have to be aware of the NUMA properties ofsuch big machines. A dataoriented architecture (DORA) is a particular solution to that.However; it requires partitioning the data in a way such that inter-partition communicationcan be avoided. Graph partitioning is a long studied problem and stateof-the-art solutions;such as multilevel k-way partitioning and recursive bisection achieve good results in feasibletime. Integrating such solution is a rather difficult task; though. In this paper; we present a …,GvD,2016,*
Enjoy FRDM-play with a schema-flexible RDBMS,Hannes Voigt; Patrick Damme; Wolfgang Lehner,Relational database management systems build on the closed world assumption requiringupfront modeling of a usually stable schema. However; a growing number of today'sdatabase applications are characterized by self-descriptive data. The schema of self-descriptive data is very dynamic and prone to frequent changes; a situation which is alwaystroublesome to handle in relational systems. This demo presents the relational databasemanagement system FRDM. With flexible relational tables FRDM greatly simplifies themanagement of self-descriptive data in a relational database system. Self-descriptive datacan reside directly next to traditionally modeled data and both can be queried together usingSQL. This demo presents the various features of FRDM and provides first-hand experienceof the newly gained freedom in relational database systems.,Data Engineering (ICDE); 2015 IEEE 31st International Conference on,2015,*
Flexibility in Data Management,Hannes Voigt,Abstract With the ongoing expansion of information technology; new fields of applicationrequiring data management emerge virtually every day. In our knowledge culture increasingamounts of data and work force organized in more creativity-oriented ways also radicallychange traditional fields of application and question established assumptions about datamanagement. For instance; investigative analytics and agile software development movetowards a very agile and flexible handling of data. As the primary facilitators of datamanagement; database systems have to reflect and support these developments. However;traditional database management technology; in particular relational database systems; isbuilt on assumptions of relatively stable application domains. The need to model all data upfront in a prescriptive database schema earned relational database management systems …,*,2013,*
Listen to the customer: model-driven database design,Hannes Voigt; Kai Herrmann; Tim Kiefer; Wolfgang Lehner,Abstract In modern IT landscapes; databases are subject to a major role change. Especiallyin Service-Oriented Architectures; databases are more and more frequently dedicated to asingle application. Therefore; it is even more important to reflect the applicationrequirements in their design. Software developers and application experts formulateapplication requirements in software models. Hence; we obviously need to bridge the gap tothe software world and directly derive a database design from the software models used inapplication development and maintenance. We introduce this concept as model-drivendatabase design. In this paper; we present the architecture principles of a model-drivendatabase design tool and details on the enumeration and evaluation of logical databasedesigns.,Proceedings of the Fourteenth International Database Engineering & Applications Symposium,2010,*
Anfragegetriebene Indizierung räumlicher Daten.,Hannes Voigt; Steffen Preißler; Matthias Böhm; Wolfgang Lehner,Abstract: Mit der zunehmenden Verbreitung von GPS-und internetfähigen Smartphoneswerden ortsbezogene Informationsdienste immer beliebter. Zur Sicherung einer hohenDienstqualität werden die zugrundeliegenden Ortsinformationen indiziert. BekannteIndexstrukturen für räumliche Daten teilen diese gemäß ihrer Verteilung auf; wodurch alleAnfragen gleich behandelt werden. Möchte man häufige Anfrage durch eine genauereIndizierung besonders unterstützen; so muss sich die Aufteilung der Daten nicht an derDatenverteilung; sondern an der Anfrageverteilung orientieren. In diesem Papier stellen wirdas QD-Grid vor; eine räumliche Indexstruktur; deren Indizierung sich inkrementell mit dengestellten Anfragen aufbaut. Zusätzlich präsentieren wir Evaluationsergebnisse.,GI Jahrestagung,2009,*
Modellierung komplexer Workflows in jExam.,Christoph Hartwig; Hannes Voigt; Sebastian Richly; Dirk Habich,Abstract: jExam ist ein Online Informationssystem zur Unterstützung von Studium und Lehre.In einem solchen Informationssystem werden üblicherweise mehrere Arbeitsabläufe(Workflows) abgebildet. Verschiedene Mitarbeiter bearbeiten nacheinander oder parallelbestimmte Daten. So besteht normalerweise die Lehrveranstaltungsplanung aus derLehrangebotsplanung und der Raum-und Zeitplanung. Um die vielen komplexenuniversitären Workflows effizient abbilden zu können; ist eine generischeWorkflowunterstützung wünschenswert. Ein Problem dabei ist; das üblicherweise ein Objektwie beispielsweise die Lehrveranstaltung aus verschiedenen Aspekten besteht und dieseunterschiedlichen Bearbeitungsschritte unterliegen. Existierende Workflowenginesbetrachten immer ein einzelnes Objekt als feinste Einheit; was aber in diesem Umfeld …,Informatiktage,2006,*
