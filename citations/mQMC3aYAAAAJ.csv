Improved parallel I/O via a two-phase run-time access strategy,Juan Miguel Del Rosario; Rajesh Bordawekar; Alok Choudhary,Abstract As scientists expand their models to describe physical phenomena of increasinglylarge extent; I/O becomes crucial and a system with limited I/O capacity can severelyconstrain the performance of the entire program. We provide experimental results;performed on an lntel Touchtone Delta and nCUBE 2 I/O system; to show that theperformance of existing parallel I/O systems can vary by several orders of magnitude as afunction of the data access pattern of the parallel program. We then propose a two-phaseaccess strategy; to be implemented in a runtime system; in which the data distribution oncomputational nodes is decoupled from storage distribution. Our experimental results showthat performance improvements of several orders of magnitude over direct access baseddata distribution methods can be obtained; and that performance for most data access …,ACM SIGARCH Computer Architecture News,1993,331
Optimizing sparse matrix-vector multiplication on GPUs using compile-time and run-time strategies,Muthu Manikandan Baskaran; Rajesh Bordawekar,Abstract We are witnessing the emergence of Graphics Processor units (GPUs) as powerfulmassively parallel systems. Furthermore; the introduction of new APIs for general-purposecomputations on GPUs; namely CUDA from NVIDIA; Stream SDK from AMD; and OpenCL;makes GPUs an attractive choice for high-performance numerical and scientific computing.Sparse Matrix-Vector multiplication (SpMV) is one of the most important and heavily usedkernels in scientific computing. However with indirect and irregular memory accessesresulting in more memory accesses per floating point operation; optimization of SpMV kernelis a significant challenge in any architecture. In this paper; we evaluate the variouschallenges in developing a high-performance SpMV kernel on NVIDIA GPUs using theCUDA programming model and propose a framework that employs both compile-time …,IBM Reserach Report; RC24704 (W0812-047),2008,254
Semantics of ranking queries for probabilistic data and expected ranks,Graham Cormode; Feifei Li; Ke Yi,When dealing with massive quantities of data; top-k queries are a powerful technique forreturning only the k most relevant tuples for inspection; based on a scoring function. Theproblem of efficiently answering such ranking queries has been studied and analyzedextensively within traditional database settings. The importance of the top-k is perhaps evengreater in probabilistic databases; where a relation can encode exponentially many possibleworlds. There have been several recent attempts to propose definitions and algorithms forranking queries over probabilistic data. However; these all lack many of the intuitiveproperties of a top-k over deterministic data. Specifically; we define a number of fundamentalproperties; including exact-k; containment; unique-rank; value-invariance; and stability;which are all satisfied by ranking queries on certain data. We argue that all these …,Data Engineering; 2009. ICDE'09. IEEE 25th International Conference on,2009,212
Design and evaluation of primitives for parallel I/O,Rajesh Bordawekar; Juan Miguel del Rosario; Alok Choudhary,Abstract In this paper; we show that the performance of parallel file systems can vary greatlyas a function of the selected data distm” butions; and that some data distributions can not besupported. We have devised an alternative scheme for conduci-ng parallel 1/0-the Two-Phase Access Strategy-which guarantees higher and more consistent performance over awider spectrum of data distributions. We have designed and implemented runtime primitivesthat make use of the two-phase access strategy to conduct parallel I/O; and facilitate theprogramming of parallel I/O operations. We describe these primitives in detail and provideperformance results which show that I/O access rates are improved by up to several ordersof magnitude. Further; we show that the variation in performance over various datadistributions is restricted to within a factor of 2 of the best access rate.,Proceedings of the 1993 ACM/IEEE conference on Supercomputing,1993,173
Passion: Optimized I/O for parallel applications,Rajeev Thakur; Alok Choudhary; Rajesh Bordawekar; Sachin More; Sivaramakrishna Kuditipudi,Abstract We have implemented Passion on Intel's Paragon; Touchstone Delta; andiPSC/860 systems; and on the IBM SP system. We have also made it publicly availablethrough the World Wide Web (http://www. cat. syr. edu/passion. html). We are in the processof porting the library to other machines and extending its functionality.,Computer,1996,162
CellSort: high performance sorting on the cell processor,Buǧra Gedik; Rajesh R Bordawekar; Philip S Yu,Abstract In this paper we describe the design and implementation of CellSort-a highperformance distributed sort algorithm for the Cell processor. We design CellSort as adistributed bitonic merge with a data-parallel bitonic sorting kernel. In order to best exploitthe architecture of the Cell processor and make use of all available forms of parallelism toachieve good scalability; we structure CellSort as a three-tiered sort. The first tier is a SIMD(single-instruction multiple data) optimized bitonic sort; which sorts up to 128KB of items thatcat fit into one SPE's (a co-processor on Cell) local store. We design a comprehensiveSIMDization scheme that employs data parallelism even for the most fine-grained steps ofthe bitonic sorting kernel. Our results show that; SIMDized bitonic sorting kernel is vastlysuperior to other alternatives on the SPE and performs up to 1.7 times faster compared to …,Proceedings of the 33rd international conference on Very large data bases,2007,134
PASSION: parallel and scalable software for input-output,Alok Choudhary; Rajesh Bordawekar; Michael Harry; Rakesh Krishnaiyer,Description/Abstract We are developing a software system called PASSION: Parallel AndScalable Software for Input-Output which provides software support for high performanceparallel I/O. PASSION provides support at the language; compiler; runtime as well as filesystem level. PASSION provides runtime procedures for parallel access to files (read/write);as well as for out-of-core computations. These routines can either be used together with acompiler to translate out-of-core data parallel programs written in a language like HPF; orused directly by application programmers. A number of optimizations such as Two-PhaseAccess; Data Sieving; Data Prefetching and Data Reuse have been incorporated in thePASSION Runtime Library for improved performance. PASSION also provides an initialframework for runtime support for out-of-core irregular problems. The goal of the …,*,1994,133
A model and compilation strategy for out-of-core data parallel programs,Rajesh Bordawekar; Alok Choudhary; Ken Kennedy; Charles Koelbel; Michael Paleczny,Abstract It is widely acknowledged in high-performance computing circles that parallelinput/output needs substantial improvement in order to make scalable computers trulyusable. We present a data storage model that allows processors independent access to theirown data and a corresponding compilation strategy that integrates data-parallel computationwith data distribution for out-of-core problems. Our results compare several communicationmethods and I/O optimizations using two out-of-core problems; Jacobi iteration and LUfactorization.,ACM SIGPLAN Notices,1995,96
PASSION runtime library for parallel I/O,Rajeev Thakur; Rajesh Bordawekar; Alok Choudhary; Ravi Ponnusamy; Tarvinder Singh,We are developing a compiler and runtime support system called PASSION: Parallel andScalable Software for Input-Output. PASSION provides software support for I/O intensive out-of-core loosely synchronous problems. This paper gives an overview of the PASSIONRuntime Library and describes two of the optimizations incorporated in it; namely dataprefetching and data sieving. Performance improvements provided by these optimizationson the Intel Touchstone Delta are discussed together with an out-of-core median filteringapplication.,Scalable Parallel Libraries Conference; 1994.; Proceedings of the 1994,1994,91
Exploiting prolific types for memory management and optimizations,Yefim Shuf; Manish Gupta; Rajesh Bordawekar; Jaswinder Pal Singh,Abstract In this paper; we introduce the notion of prolific and non-prolific types; based on thenumber of instantiated objects of those types. We demonstrate that distinguishing betweenthese types enables a new class of techniques for memory management and data locality;and facilitates the deployment of known techniques. Specifically; we first present a new type-based approach to garbage collection that has similar attributes but lower cost thangenerational collection. Then we describe the short type pointer technique for reducingmemory requirements of objects (data) used by the program. We also discuss techniques tofacilitate the recycling of prolific objects and to simplify object co-allocation decisions. Weevaluate the first two techniques on a standard set of Java benchmarks (SPECjvm98 andSPECjbb2000). An implementation of the type-based collector in the Jalapeño VM shows …,ACM SIGPLAN Notices,2002,89
Quicksilver: a quasi-static compiler for Java,Mauricio Serrano; Rajesh Bordawekar; Sam Midkiff; Manish Gupta,Abstract This paper presents the design and implementation of the Quicksilver 1 quasi-staticcompiler for Java. Quasi-static compilation is a new approach that combines the benefits ofstatic and dynamic compilation; while maintaining compliance with the Java standard;including support of its dynamic features. A quasi-static compiler relies on the generationand reuse of persistent code images to reduce the overhead of compilation during programexecution; and to provide identical; testable and reliable binaries over different programexecutions. At runtime; the quasi-static compiler adapts pre-compiled binaries to the currentJVM instance; and uses dynamic compilation of the code when necessary to supportdynamic Java features. Our system allows interprocedural program optimizations to beperformed while maintaining binary compatibility. Experimental data obtained using a …,ACM SIGPLAN Notices,2000,82
Building a Java virtual machine for server applications: The JVM on OS/390,Donna Dillenberger; Rajesh Bordawekar; Clarence W Clark III; Donald Durand; David Emmes; Osamu Gohda; Sally Howard; Michael F Oliver; Frank Samuel; RW St John,As the use of the Java™ language and virtual machines proliferates beyond the sphere ofapplets into the space of server programs; developers are requiring better performance;availability; and transactional and scalability features. This paper describes the work donefor the Operating System/390 (OS/390®) Java virtual machine to improve performance andserviceability; to introduce security and performance enhancements; and to redesign parts ofthe virtual machine to enable it to run server programs efficiently and safely. AlthoughOS/390 was the motivating platform for these changes; Java server programs on anyplatform can benefit from these features.,IBM Systems Journal,2000,73
XJ: facilitating XML processing in Java,Matthew Harren; Mukund Raghavachari; Oded Shmueli; Michael G Burke; Rajesh Bordawekar; Igor Pechtchanski; Vivek Sarkar,Abstract The increased importance of XML as a data representation format has led toseveral proposals for facilitating the development of applications that operate on XML data.These proposals range from runtime API-based interfaces to XML-based programminglanguages. The subject of this paper is XJ; a research language that proposes novelmechanisms for the integration of XML as a first-class construct into Java™. The designgoals of XJ distinguish it from past work on integrating XML support into programminglanguages---specifically; the XJ design adheres to the XML Schema and XPath standards.Moreover; it supports in-place updates of XML data thereby keeping with the imperativenature of Java. We have built a prototype compiler for XJ; and our preliminary experimentsdemonstrate that the performance of XJ programs can approach that of traditional low …,Proceedings of the 14th international conference on World Wide Web,2005,72
GPU programming in a high level language: compiling X10 to CUDA,Dave Cunningham; Rajesh Bordawekar; Vijay Saraswat,Abstract GPU architectures have emerged as a viable way of considerably improvingperformance for appropriate applications. Program fragments (kernels) appropriate for GPUexecution can be implemented in CUDA or OpenCL and glued into an application via anAPI. While there is plenty of evidence of performance improvements using this approach;there are many issues with productivity. Programmers must understand an additionalprogramming model and API to program the accelerator; concurrency and synchronizationin this programming model is typically expressed differently from the programming model forthe host. On top of this; the languages used to write kernels are very low level and thusprone to the kinds of errors that one does not encounter in higher level languages.Programmers must explicitly deal with moving data back-and-forth between the host and …,Proceedings of the 2011 ACM SIGPLAN X10 Workshop,2011,70
Methods and systems for analyzing XML documents,*,Methods and systems for analyzing XML documents. The system scans an XML document;identifies different dimensions that span the XML document and detects scopingrelationships amongst them. The system uses the dimensional information to create a logicalhierarchical scoped dimension analysis model; maps the logical XML tree to this model; andthen implements the analytical method over the logical model. The logical model allows bothstructural features and numeric/non-numeric data to be used for analysis. The analyticalmethod allows users to query irregular structural properties of the XML documents using theXPath navigational API.,*,2006,68
Long running; reusable; extendible; virtual machine,*,In a virtual machine environment; the invention enables creation of a long running; reusable;virtual machine are disclosed. The environment includes a shared heap where requisiteruntime code to bring the virtual machine into a 'ready'mode are loaded; linked; verified;initialized and compiled. Subsequent virtual machines are started and jointly use the sharedheap. Applications create their objects in 'private heaps' that are exclusively reserved for therespective applications. At the end of execution of an application; each private heap isreinitialized. Static initializers are run in a persistent area of each private heap. Thispersistent area is reset to its initial values in between execution of applications. Thisobviates the need to terminate the virtual machine.,*,2004,62
Automatic optimization of communication in compiling out-of-core stencil codes,Rajesh Bordawekar; Alok Choudhary; J Ramanujam,Abstract In this paper. we describe a technique for optimizing communication for out-of-coredistributed memory stencil problems. In these problems; communication may require bothinter-processor communication and file 1/0. We show that in certain cases; extra file 1/0incurred in communication can be completely eliminated by reordering in-corecomputations. The in-core computation pattern is decided by:(1) how the out-of-core datadistributed into in-core slabs (tiling) and (2) how the slabs are accessed. We show that acompiler using the stencil and processor information can choose the tiling parameters andschedule the tile accesses so that theextra file I/O is eliminated and overall performance isimproved.,Proceedings of the 10th international conference on Supercomputing,1996,60
Modeling optimistic concurrency using quantitative dependence analysis,Christoph von Praun; Rajesh Bordawekar; Calin Cascaval,Abstract This work presents a quantitative approach to analyze parallelization opportunitiesin programs with irregular memory access where potential data dependencies maskavailable parallelism. The model captures data and causal dependencies among criticalsections as algorithmic properties and quantifies them as a density computed over thenumber of executed instructions. The model abstracts from runtime aspects such asscheduling; the number of threads; and concurrency control used in a particularparallelization. We illustrate the model on several applications requiring ordered andunordered execution of critical sections. We describe a run-time tool that computes thedependence densities from a deterministic single-threaded program execution. This densitymetric provides insights into the potential for optimistic parallelization; opportunities for …,Proceedings of the 13th ACM SIGPLAN Symposium on Principles and practice of parallel programming,2008,58
Method; system and recording medium for maintaining the order of nodes in a heirarchical document,*,A method; a system and recording medium for maintaining the order of nodes in ahierarchical document. The method may select the maximum and the minimum number ofchildren for each node; build an auxiliary ordered tree having at least as many leaves asatoms within the hierarchical document based upon the selected maximum and minimumnumber of children for each node; attach the atoms to the leaves of the auxiliary orderedtree; and label each of the nodes in the auxiliary ordered tree.,*,2007,58
Method for compiling program components in a mixed static and dynamic environment,*,This invention describes a method and several variants for compiling programs orcomponents of programs in a mixed static and dynamic environment; so as to reduce theamount of time and memory spent in run-time compilation; or to exercise greater control overtesting of the executable code for the program; or both. The invention involves generatingpersistent code images prior to program execution based on static compilation or dynamiccompilation from a previous run; and then; adapting those images during programexecution. We describe a method for generating auxiliary information in addition to theexecutable code that is recorded in the persistent code image. Further; we describe amethod for checking the validity of those code images; adapting those images to the newexecution context; and generating new executable code to respond to dynamic events …,*,2005,56
Method for efficient garbage collection based on object type,*,A computing apparatus and method classify data objects into at least a first type andalternatively a second type; and allocate a first portion of computer memory to objects of thefirst type and a second portion of computer memory to objects of the second type. Then themethod performs garbage collection of data objects within at least one portion of computermemory while retaining surviving objects within the computer memory. Objects of the firsttype occur in a computer memory with a frequency that exceeds a selected threshold; andare designated “prolific.” Objects of the second type occur in the computer memory with afrequency that does not exceed the selected threshold; and are designated “non-prolific”.,*,2005,56
An experimental performance evaluation of Touchstone Delta Concurrent File System,Rajesh R Bordawekar; Alok N Choudhary; Juan Miguel Del Rosario,ABSTRACT For a high-performance parallel machine to be a scalable system; it must afsohave a scalable parallel 1/0 system. This paper presents an experimental evaluation of theIntel Touchstone Delta's Concurrent File System (CFS). The main objective of the study is todetermine the maximum file read/write rates for various configurations of 1/0 and computenodes. In addition; we study the effects of file access modes; buffer sizes and file sizes onthe system performance. In most cases; the result shows that performance of CFS scales asthe number of disks is increased; but the sustained performance improvements are muchlower than the system's peak capacity. If'e observe that the performance of CFS scales withthe number of processors in the beginning; however; a plateu a quickly reached due to the1/0 system bottleneck and enormous software overhead; especially that of …,Proceedings of the 7th international conference on Supercomputing,1993,55
A comparison of parallel graph coloring algorithms,JR Allwright; R Bordawekar; PD Coddington; K Dincer; CL Martin,Abstract Dynamic irregular triangulated meshes are used in adaptive grid partial di erentialequation (PDE) solvers; and in simulations of random surface models of quantum gravity inphysics and cell membranes in biology. Parallel algorithms for random surface simulationsand adaptive grid PDE solvers require coloring of the triangulated mesh; so that neighboringvertices are not updated simultaneously. Graph coloring is also used in iterative parallelalgorithms for solving large irregular sparse matrix equations. Here we introduce someparallel graph coloring algorithms based on well-known sequential heuristic algorithms; andcompare them with some existing parallel algorithms. These algorithms are implemented onboth SIMD and MIMD parallel architectures and tested for speed; e ciency; and quality (theaverage number of colors required) for coloring random triangulated meshes and graphs …,SCCS-666,1995,52
Compiler and runtime support for out-of-core HPF programs,Rajeev Thakur; Rajesh Bordawekar; Alok Choudhary,Abstract This paper describes the design of a compiler which can translate out-of-coreprograms written in a data parallel language like HPF. Such a compiler is required forcompiling large scale scientific applications; such as the Grand Challenge applications;which deal with enormous quantities of data. We propose a framework by which a compilertogether with appropriate runtime support can translate an out-of-core HPF program to amessage passing node program with explicit parallel I/O. We describe the basic model of thecompiler and the various transformations made by the compiler. We also discuss the runtimeroutines used by the compiler for I/O and communication. In order to minimize I/O; theruntime support system can reuse data already fetched into memory. The working of thecompiler is illustrated using two out-of-core applications; namely a Laplace equation …,Proceedings of the 8th international conference on Supercomputing,1994,51
Single pass workload directed clustering of XML documents,*,A method and system for clustering of XML documents is disclosed. The method operatesunder specified memory-use constraints. The system implements the method and scans anXML document; assigns edge-weights according to the application workload; and mapsclusters of XML nodes to disk pages; all in a single parser-controlled pass over the XMLdata. Application workload information is used to generate XML clustering solutions thatlead to substantial reduction in page faults for the workload under consideration. Severalapproaches for representing workload information are disclosed. For example; the workloadmay list the XPath operators invoked during the application along with their invocationfrequencies. The application workload can be further refined by incorporating additionalfeatures such as query importance or query compilation costs. XML access patterns could …,*,2009,45
Parallelization of XPath queries using multi-core processors: challenges and experiences,Rajesh Bordawekar; Lipyeow Lim; Oded Shmueli,Abstract In this study; we present experiences of parallelizing XPath queries using the XalanXPath engine on shared-address space multi-core systems. For our evaluation; we considera scenario where an XPath processor uses multiple threads to concurrently navigate andexecute individual XPath queries on a shared XML document. Given the constraints of theXML execution and data models; we propose three strategies for parallelizing individualXPath queries: Data partitioning; Query partitioning; and Hybrid (query and data)partitioning. We experimentally evaluated these strategies on an x86 Linux multi-coresystem using a set of XPath queries; invoked on a variety of XML documents using the XalanXPath APIs. Experimental results demonstrate that the proposed parallelization strategieswork very effectively in practice; for a majority of XPath queries under evaluation; the …,Proceedings of the 12th International Conference on Extending Database Technology: Advances in Database Technology,2009,43
Executing stream joins on the cell processor,Buǧra Gedik; Philip S Yu; Rajesh R Bordawekar,Abstract Low-latency and high-throughput processing are key requirements of data streammanagement systems (DSMSs). Hence; multi-core processors that provide high aggregateprocessing capacity are ideal matches for executing costly DSMS operators. The recentlydeveloped Cell processor is a good example of a heterogeneous multi-core architecture andprovides a powerful platform for executing data stream operators with high-performance. Onthe down side; exploiting the full potential of a multi-core processor like Cell is oftenchallenging; mainly due to the heterogeneous nature of the processing elements; thesoftware managed local memory at the co-processor side; and the unconventionalprogramming model in general. In this paper; we study the problem of scalable execution ofwindowed stream join operators on multi-core processors; and specifically on the Cell …,Proceedings of the 33rd international conference on Very large data bases,2007,42
Analytical processing of XML documents: opportunities and challenges,Rajesh R Bordawekar; Christian A Lang,Abstract Online Analytical Processing (OLAP) has been a valuable tool for analyzing trendsin business information. While the multi-dimensional cube model used by OLAP is ideal foranalyzing structured business data; it is not suitable for representing and analyzing complexsemi-structured data; such as; XML documents. Need for analyzing XML documents isgaining urgency as XML has become the language of choice for data representation acrossa wide range of application domains. This paper describes a proposal for analyzing XMLdocuments using the abstract XML tree model. We argue that OLAP's multi-dimensionalaggregation operators can not express structurally complex analytical operations on XMLdocuments. Hence; we outline new extensions to XQuery for supporting such complexanalytical operations. Finally; we discuss various challenges in implementing XML …,ACM Sigmod Record,2005,42
Believe it or not! multi-core cpus can match gpu performance for a flop-intensive application!,Rajesh Bordawekar; Uday Bondhugula; Ravi Rao,In this paper; we evaluate performance of a real-world image processing application thatuses a cross-correlation algorithm to compare a given image with a reference one. Weimplement this algorithm on a nVidia GTX 285 GPU using CUDA; and also parallelize it forthe Intel Xeon (Nehalem) and IBM Power7 processors; using both manual and automatictechniques. Pthreads and OpenMP with SSE and VSX vector intrinsics are used for themanually parallelized version; while a state-of-the-art optimization framework based on thepolyhedral model is used for automatic compiler parallelization and optimization. The bestperforming versions on the Power7; Nehalem; and GTX 285 run in 1.02 s; 1.82 s; and 1.22 s;respectively. The performance of this algorithm on the nVidia GPU suffers from:(1) a smallershared memory;(2) unaligned device memory access patterns;(3) expensive atomic …,Parallel Architectures and Compilation Techniques (PACT); 2010 19th International Conference on,2010,37
XJ: Integration of XML processing into Java,Matthew Harren; Mukund Raghavachari; Oded Shmueli; Michael G Burke; Vivek Sarkar; Rajesh Bordawekar,Abstract The increased importance of XML as a universal data representation format has ledto several proposals for enabling the development of applications that operate on XML data.These proposals range from runtime API-based interfaces to XML-based programminglanguages. The subject of this paper is XJ; a research language that proposes novelmechanisms for the integration of XML as a first-class construct into Java TM. The designgoals of XJ distinguish it from pastwork on integrating XML support into programminglanguages---specifically; the XJ design adheres to the XML Schema and XPathstandards;and supports in-place updates of XML data thereby keeping with the imperative nature ofJava. We have also built a prototype compiler for XJ; and our preliminary experimentalresults demonstrate that the performance of XJ programs can approach that of tradition …,Proceedings of the 13th International World Wide Web conference on Alternate track papers & posters,2004,35
Compilation techniques for out-of-core parallel computations,Mahmut Kandemir; Alok Choudhary; J Ramanujam; Rajesh Bordawekar,Abstract The difficulty of handling out-of-core data limits the performance of supercomputersas well as the potential of the parallel machines. Since writing an efficient out-of-core versionof a program is a difficult task and virtual memory systems do not perform well on scientificcomputations; we believe that there is a clear need for compiler directed explicit I/Oapproach for out-of-core computations. In this paper; we first present an out-of-corecompilation strategy based on a disk storage abstraction. Then; we offer a compileralgorithm to optimize locality of disk accesses in out-of-core codes by choosing a goodcombination of file layouts on disks and loop transformations. We introduce memorycoefficient and processor coefficient concepts to characterize the behavior of out-of-coreprograms under different memory constraints. We also enhance our algorithm to handle …,Parallel Computing,1998,35
Detecting an integrity constraint violation in a database by analyzing database schema; application and mapping and inserting a check into the database and applic...,*,A system (and method) of detecting an error in a database interaction; includes providinginformation about at least one of at least first and second software systems; and a mappingbetween at least a portion of said at least first and second software systems; and examiningsaid at least one of said first and second software systems and said mapping to determinean error in an interaction between said at least first and second software systems.,*,2009,34
CellJoin: a parallel stream join operator for the cell processor,Buğra Gedik; Rajesh R Bordawekar; Philip S Yu,Abstract Low-latency and high-throughput processing are key requirements of data streammanagement systems (DSMSs). Hence; multi-core processors that provide high aggregateprocessing capacity are ideal matches for executing costly DSMS operators. The recentlydeveloped Cell processor is a good example of a heterogeneous multi-core architecture andprovides a powerful platform for executing data stream operators with high-performance. Onthe down side; exploiting the full potential of a multi-core processor like Cell is oftenchallenging; mainly due to the heterogeneous nature of the processing elements; thesoftware managed local memory at the co-processor side; and the unconventionalprogramming model in general. In this paper; we study the problem of scalable execution ofwindowed stream join operators on multi-core processors; and specifically on the Cell …,The VLDB Journal—The International Journal on Very Large Data Bases,2009,34
L-Tree: a dynamic labeling structure for ordered XML data,Yi Chen; George Mihaila; Rajesh Bordawekar; Sriram Padmanabhan,Abstract With the ever growing use of XML as a data representation format; we see anincreasing need for robust; high performance XML database systems. While most of therecent work focuses on efficient XML query processing; XML databases also need to supportefficient updates. To speed up query processing; various labeling schemes have beenproposed. However; the vast majority of these schemes have poor update performance. Inthis paper; we introduce a dynamic labeling structure for XML data: L-Tree and its order-preserving labeling scheme with O (log n) amortized update cost and O (log n) bits per label.L-Tree has good performance on updates without compromising the performance of queryprocessing. We present the update algorithm for L-Tree and analyze its complexity.,International Conference on Extending Database Technology,2004,34
Serially; reusable virtual machine,*,In a virtual machine environment; a method and apparatus for the use of multiple heaps toretain persistent data and transient data wherein the multiple heaps enables a single virtualmachine to be easily resettable; thus avoiding the need to terminate and start a new VirtualMachine as well as enabling a single virtual machine to retain data and objects acrossmultiple applications; thus avoiding the computing resource overhead of relinking;reloading; reverifying; and recompiling classes. The memory hierarchy includes a SystemHeap; a Middleware Heap and a Transient Heap. The use of three heaps enables garbagecollection to be selectively targeted to one heap at a time in between applications; thusavoiding this overhead during the life of an application.,*,2007,30
Implementation of collective I/O in the Intel Paragon parallel file system: Initial experiences,Rajesh Bordawekar,Abstract A majority of parallel applications achieve parallelism by partitioning data overmultiple processors. Accessing distributed data structures such as arrays from files oftenrequires each processor to make a large number of small noncontiguous data requests. Thisproblem can be addressed by replacing small non-contiguous requests by large collec-tiverequests. This approach; known as collective I/O; has been found to work extremely well inpractice. This paper describes implementation and evaluation of a collective I/O prototype inthe Parallel File System (PFS) of the Intel Paragon Operating System (Paragon OS). Weevaluate the collective I/O performance using its comparison with the PFS MRECORD andKUNIX I/O modes. It is observed that collective I/O provides significant performanceimprovement over accesses in the H-UNIX mode. However; in many cases; various …,Proceedings of the 11th international conference on Supercomputing,1997,30
Compilation of out-of-core data parallel programs for distributed memory machines,Rajeev Thakur; Rajesh Bordawekar; Alok Choudhary,Abstract We are developing a compiler and runtime support system called PASSION(Parallel And Scalable Software for Input-Output); to translate out-of-core programs written ina data parallel language like HPF to message passing node programs with explicit parallelI/O. This paper describes the basic model of the compiler and the various steps involved inthe compilation. We also discuss the runtime routines used by the compiler for I/O andcommunication. The working of the compiler is illustrated using the example of an out-of-core Laplace equation solver; with performance results on the Intel Touchstone Delta.,ACM SIGARCH Computer Architecture News,1994,30
System and method for analyzing streams and counting stream items on multi-core processors,*,Systems and methods for parallel stream item counting are disclosed. A data stream ispartitioned into portions and the portions are assigned to a plurality of processing cores. Asequential kernel is executed at each processing core to compute a local count for items inan assigned portion of the data stream for that processing core. The counts are aggregatedfor all the processing cores to determine a final count for the items in the data stream. Afrequency-aware counting method (FCM) for data streams includes dynamically capturingrelative frequency phases of items from a data stream and placing the items in a sketchstructure using a plurality of hash functions where a number of hash functions is based onthe frequency phase of the item. A zero-frequency table is provided to reduce errors due toabsent items.,*,2012,29
Compiler and runtime techniques for software transactional memory optimization,Peng Wu; Maged M Michael; Christoph von Praun; Takuya Nakaike; Rajesh Bordawekar; Harold W Cain; Calin Cascaval; Siddhartha Chatterjee; Stefanie Chiras; Rui Hou; Mark Mergen; Xiaowei Shen; Michael F Spear; Hua Yong Wang; Kun Wang,Abstract Software transactional memory (STM) systems are an attractive environment toevaluate optimistic concurrency. We describe our experience of supporting and optimizingan STM system at both the managed runtime and compiler levels. We describe the designpolicies of our STM system and the statistics collected by the runtime to identify performancebottlenecks and guide tuning decisions. We present an initial work on supporting automaticinstrumentation of the STM primitives for C/C++ and Java programs in the IBM XL compilerand J9 Java virtual machine. We evaluate and discuss the performance of severaltransactional programs running on our system. Copyright© 2008 John Wiley & Sons; Ltd.,Concurrency and Computation: Practice and Experience,2009,28
Techniques for compiling i/o intensive parallel programs,Rajesh R Bordawekar,Abstract This dissertation investigates several issues in providing compiler support for I/Ointensive parallel programs. In this dissertation; we focus on satisfying two I/O requirements;namely; support for accessing multidimensional arrays and support for out-of-corecomputations. We analyze working spaces in I/O intensive programs and propose threeexecution models to be used by users or compilers for developing efficient I/O intensiveparallel programs. Different phases in compiling out-of-core parallel programs are thendescribed. Three different methods for performing communication are presented andvalidated using representative application templates.,*,1996,28
Can CPUs match GPUs on performance with productivity?: experiences with optimizing a FLOP-intensive application on CPUs and GPU,Rajesh Bordawekar; Uday Bondhugula; Ravi Rao,Abstract In this work; we evaluate performance of a real-world image processing applicationthat uses a cross-correlation algorithm to compare a given image with a reference one. Thealgorithm processes individual images represented as 2-dimensional matrices of single-precision floating-point values using Θ (n4) operations involving dot-products and additions.We implement this algorithm on a NVIDIA Fermi GPU (Tesla 2050) using CUDA; and alsomanually parallelize it for the Intel Xeon X5680 (Westmere) and IBM Power7 multi-coreprocessors. Pthreads and OpenMP with SSE and VSX vector intrinsics are used for themanually parallelized version on the multi-core CPUs. A number of optimizations wereperformed for the GPU implementation on the Fermi; including blocking for Fermi'sconfigurable on-chip memory architecture. Experimental results illustrate that on a single …,*,2010,24
XIST: An XML index selection tool,Kanda Runapongsa; Jignesh M Patel; Rajesh Bordawekar; Sriram Padmanabhan,Abstract XML indices are essential for efficiently processing XML queries which typicallyhave predicates on both structures and values. Since the number of all possible structuraland value indices is large even for a small XML document with a simple structure; XMLDBMSs must carefully choose which indices to build. In this paper; we propose a tool; calledXIST; that can be used by an XML DBMS as an index selection tool. XIST exploits XMLstructural information; data statistics; and query workload to select the most beneficialindices. XIST employs a technique that organizes paths that evaluate to the same result intostructure equivalence groups and uses this concept to reduce the number of pathsconsidered as candidates for indexing. XIST selects a set of candidate paths and evaluatesthe benefit of an index for each candidate path on the basis of performance gains for non …,International XML Database Symposium,2004,23
Method for reducing write barrier overhead,*,A computer system and method for compiling a program; where the program executespointer assignments from a source object to a destination object; each source object beingaddressable through a first pointer and each destination object being addressable through asecond pointer. The system and method eliminate write barrier code from association withcompiled program code when the first pointer points to a source object whose type is prolific;eliminate write barrier code from association with compiled program code when the secondpointer points to a destination object whose type is non-prolific; and associate write barriercode with compiled program code when the source object is non-prolific and the destinationobject is prolific. Additionally; the system and method can determine not to associate writebarrier code with a compiled program code if the second pointer points to a destination …,*,2007,22
Statistics-based parallelization of XPath queries in shared memory systems,Rajesh Bordawekar; Lipyeow Lim; Anastasios Kementsietsidis; Bryant Wei-Lun Kok,Abstract The wide availability of commodity multi-core systems presents an opportunity toaddress the latency issues that have plaqued XML query processing. However; simplyexecuting multiple XML queries over multiple cores merely addresses the throughput issue:intra-query parallelization is needed to exploit multiple processing cores for better latency.Toward this effort; this paper investigates the parallelization of individual XPath queries overshared-address space multi-core processors. Much previous work on parallelizing XPath ina distributed setting failed to exploit the shared memory parallelism of multi-core systems.We propose a novel; end-to-end parallelization framework that determines the optimal wayof parallelizing an XML query. This decision is based on a statistics-based approach thatrelies both on the query specifics and the data statistics. At each stage of the …,Proceedings of the 13th International Conference on Extending Database Technology,2010,21
On efficient query processing of stream counts on the cell processor,Dina Thomas; Rajesh Bordawekar; Charu C Aggarwal; S Yu Philip,In recent years; the sketch-based technique has been presented as an effective method forcounting stream items on processors with limited storage and processing capabilities; suchas the network processors. In this paper; we examine the implementation of a sketch-basedcounting algorithm on the heterogeneous multi-core Cell processor. Like the networkprocessors; the Cell also contains on-chip special processors with limited local memories.These special processors enable parallel processing of stream items using short-vector data-parallel (SIMD) operations. We demonstrate that the inaccuracies of the estimates computedby straightforward adaptations of current sketch-based counting approaches areexacerbated by increased inaccuracies in approximating counts of low frequency items; andby the inherent space limitations of the Cell processor. To address these concerns; we …,Data Engineering; 2009. ICDE'09. IEEE 25th International Conference on,2009,21
Experimental evaluation of the Hewlett-Parkard exemplar file system,Rajesh Bordawekar; Steven Landherr; Don Capps; Mark Davis,Abstract This article presents results from an experimental evaluation study of the HPExemplar file system. Our experiments consist of simple micro-benchmarks that study theimpact of various factors on the file system performance. These factors include I/Orequest/buffer sizes; vectored/non-vectored access patterns; read-ahead policies; multi-threaded (temporally irregular) requests; and architectural issues (cache parameters; NUMAbehavior; etc.). Experimental results indicate that the Exemplar file system provides high I/Obandwidth; both for single-and multi-threaded applications. The buffer cache; with prioritizedbuffer management and large buffer sizes; is effective in exploiting temporal and spatialaccess localities. The performance of non-contiguous accesses can be improved by eitherusing vectored I/O interfaces or tuning the read-ahead facilities. The file system …,ACM SIGMETRICS Performance Evaluation Review,1997,21
E cient compilation of out-of-core data parallel programs,Rajesh Bordawekar; Rajeev Thakur; Alok Choudhary,Abstract Large scale scienti c applications; such as the Grand Challenge applications; dealwith very large quantities of data. The amount of main memory in distributed memorymachines is usually not large enough to solve problems of realistic size. This limitationresults in the need for system and application software support to provide e cient parallel I/Ofor out-of-core programs. This paper describes techniques for translating out-of-coreprograms written in a data parallel language like HPF to message passing node programswith explicit parallel I/O. We describe the basic compilation model and various stepsinvolved in the compilation. The compilation process is explained with the help of an out-of-core matrix multiplication program. We rst discuss how an out-of-core program can betranslated by extending the method used for translating in-core programs. We then …,*,1994,20
Language and compiler support for parallel I/O,Rajesh Bordawekar; Alok Choudhary,Abstract This paper addresses the problem of performing parallel input-output in dataparallel computations. Specifically; we present language support (as extensions to HPF);and initial compiler implementation in the Fortran90D/HPF compiler for distributed memorymachines. In this paper we only address the problem of reading and writing data in parallel.We suggest a set of compiler directives for parallel I/O which can be used in addition tostandard HPF directives. The runtime primitives along with the compiler directives provide acommon I/O platform for parallel languages like HPF.,*,1994,20
Data access reorganizations in compiling out-of-core data parallel programs on distributed memory machines,Mahmut Kandemir; Rajesh Bordawekar; Alok Choudhary,This paper describes optimization techniques for translating out-of-core programs written ina data parallel language to message passing node programs with explicit parallel I/O. Wedemonstrate that straightforward extension of in-core compilation techniques does not workwell for out-of-core programs. We then describe how the compiler can optimize the code by(1) determining appropriate file layouts for out-of-core arrays;(2) permuting the loops in thenest (s) to allow efficient file access; and (3) partitioning the available node memory amongreferences based on I/O cost estimation. Our experimental results indicate that theseoptimizations can reduce the amount of time spent in I/O by as much as an order ofmagnitude.,Parallel Processing Symposium; 1997. Proceedings.; 11th International,1997,19
Compilation and communication strategies for out-of-core programs on distributed memory machines,Rajesh Bordawekar; Alok Choudhary; J Ramanujam,Abstract It is widely acknowledged that improving parallel I/O performance is critical forwidespread adoption of high performance computing. In this paper; we show thatcommunication in out-of-core distributed memory problems may require both interprocessorcommunication and file I/O. Thus; in order to improve I/O performance; it is necessary tominimize the I/O costs associated with a communication step. We present three methods forperforming communication in out-of-core distributed memory problems. The first method;called thegeneralized collective communicationmethod; follows a loosely synchronousmodel; computation and communication phases are clearly separated; and communicationrequires permutation of data in files. The second method; called thereceiver-driven in-corecommunication; communicates only the in-core data. The third method; called theowner …,Journal of Parallel and Distributed Computing,1996,19
Flexible workload-aware clustering of XML documents,Rajesh Bordawekar; Oded Shmueli,Abstract We investigate workload-directed physical data clustering in native XML databaseand repository systems. We present a practical algorithm for clustering XML documents;called XC; which is based on Lukes' tree partitioning algorithm. XC carefully approximatescertain aspects of Lukes' algorithm so as to substantially reduce memory and time usage.XC can operate with varying degrees of precision; even in memory constrainedenvironments. Experimental results indicate that XC is a superior clustering algorithm interms of partition quality; with only a slight overhead in performance when compared to aworkload-directed depth-first scan and store scheme. We demonstrate that XC issubstantially faster than the exact Lukes' algorithm; with only a minimal loss in clusteringquality. Results also indicate that XC can exploit application workload information to …,International XML Database Symposium,2004,18
PASSION runtime library for the Intel Paragon,Alok Choudhary; Rajesh Bordawekar; Sachin More,Abstract We are developing a runtime library which pro-vides a number of routines toperform the 1/0 required in parallel applications in an eficient and convenient manner. Thisis part of a project called PASSION; which aims to provide software support for high-performance parallel 1/0 at the compiler; runtime and file system levels. The PASSIONRuntime Library uses a high-level interface which makes it easy for the user to specify the1/0 required in the program. The user only needs to specify what portion of the data struclureneeds to read from or written to the file; and the. PASSION routines will perform all thenecessa y I/O efficiently. This paper gives an overview of the PASSION Runtime Library anddescribes in detail its high-level interface.,*,1995,18
Communication strategies for out-of-core programs on distributed memory machines,Rajesh Bordawekar; Alok Choudhary,Abstract In this paper; we show that communication in the outof-core distributed memoryproblems requires both interprocessor communication and file 1/0. Thus; in order to improve1/0 performance; it is necessary to optimize the I/O costs associated with a communicationstep. We present three methods for performing communicationin out-of-core distributedmemory problems. The first method; termed a. sthe” out-of-core” communication method;follows aloosely synchronous model. Computation and Cornmunication phases in this caseare clearly separated; and communication requires permutation of data in files. The secondmethod; termed aa “demand-driven-in-core communication” considers only communicationrequired of each in-core data slab individually. The third method; termed as “producer-driven-in-core communication” goes even one step further and tries to identify the potential …,Proceedings of the 9th international conference on Supercomputing,1995,18
Optimizing queries to hierarchically structured data,*,Techniques are disclosed for optimizing queries to hierarchically structured data. Forexample; a method for processing a query directed to data having a hierarchical structurewith a plurality of data nodes comprises the following steps. One or more structural attributesdescribing the hierarchical structure of the data are identified. The query is partitioned intotwo or more query partitions using at least one of the one or more identified structuralattributes. A parallel execution plan is determined for the query by splitting into componentsone or more of: the query into at least two of the query partitions; and the hierarchicalstructure of the data. The split components are executed in parallel on different computerprocesses according to the parallel execution plan.,*,2012,17
Implementation and scalability of Fortran 90D intrinsic functions on distributed memory machines,Ishfaq Ahmad; Rajesh Bordawekar; Zeki Bozkus; Alok Choudhary; Geoffrey Fox; Kanchana Parasuram; Ravi Ponnusamy; Sanjay Ranka; Rajeev Thakur,Abstract We are developing a Fortran 90D compiler; which converts Fortran 90D code intoFortran 77 node programs for distributed memory machines. This paper presents theperformance results of Fortran 90D intrinsic functions on Intel iPSC/860 and iPSC/2hypercubes. We discuss the implementation of these intrinsic functions and show that ourimplementations are scalable. This work was sponsored by DARPA under contract#DABT63-91-C-0028. The content of the information does not necessarily reflect the positionor the policy of the Government and no official endorsement should be inferred. 1Introduction It is widely recognized that massively parallel MIMD distributed memorymachines can provide enormous computing power. But this power has not yet been fullyharnessed because of the difficulty in programming these machines and the lack of …,*,1993,17
Quantitative Characterization and Analysis of the I/O behavior of a Commercial Distributed-shared-memory Machine,Rajesh R Bordawekar,This paper presents a unified evaluation of the I/O behavior of a commercial clustered DSMmachine; the HP Exemplar. Our study has the following objectives: 1) To evaluate the impactof different interacting system components; namely; architecture; operating system; andprogramming model; on the overall I/O behavior and identify possible performancebottlenecks; and 2) To provide hints to the users for achieving high out-of-box I/O throughput.We find that for the DSM machines that are built as a cluster of SMP nodes; integratedclustering of computing and I/O resources; both hardware and software; is not advantageousfor two reasons. First; within an SMP node; the I/O bandwidth is often restricted by theperformance of the peripheral components and cannot match the memory bandwidth.Second; since the I/O resources are shared as a global resource; the file-access costs …,IEEE transactions on parallel and distributed systems,2000,16
Data access reorganizations in compiling out-of-core data parallel programs on distributed memory machines,Rajesh Bordawekar; Alok Choudhary; Rajeev Thakur,Description/Abstract This paper describes techniques for translating out-of-core programswritten in a data parallel language like HPF to message passing node programs with explicitparallel I/O. We describe the basic compilation model and various steps involved in thecompilation. The compilation process is explained with the help of an out-of-core matrixmultiplication program. We first discuss how an out-of-core program can be translated byextending the method used for translating in-core programs. We demonstrate thatstraightforward extension of in-core compiler does not work for out-of-core programs. Wethen describe how the compiler can optimize the code by (1) estimating the I/O costsassociated with different array access patterns;(2) reorganizing array accesses;(3) selectingthe method with the least I/O cost; and (4) allocating memory according to access cost for …,*,1994,14
PARADIS: an efficient parallel algorithm for in-place radix sort,Minsik Cho; Daniel Brand; Rajesh Bordawekar; Ulrich Finkler; Vincent Kulandaisamy; Ruchir Puri,Abstract In-place radix sort is a popular distribution-based sorting algorithm for short numericor string keys due to its linear run-time and constant memory complexity. However; efficientparallelization of in-place radix sort is very challenging for two reasons. First; the initialphase of permuting elements into buckets suffers read-write dependency inherent in its in-place nature. Secondly; load balancing of the recursive application of the algorithm to theresulting buckets is difficult when the buckets are of very different sizes; which happens forskewed distributions of the input data. In this paper; we present a novel parallel in-placeradix sort algorithm; PARADIS; which addresses both problems: a)" speculative permutation"solves the first problem by assigning multiple non-continuous array stripes to eachprocessor. The resulting shared-nothing scheme achieves full parallelization. Since our …,Proceedings of the VLDB Endowment,2015,11
Issues in Software Support for Parallel I/O,Rajesh Bordawekar,Abstract This thesis looks at various issues in providing application-level software supportfor parallel I/O. We show that the performance of the parallel I/O system varies greatly as afunction of data distributions. We present runtime I/O primitives for parallel languages whichallow the user to obtain a consistent performance over a wide range of data distributions. Inorder to design these primitives; we study various parameters used in the design of aparallel le system. We evaluate the performance of Touchstone Delta Concurrent FileSystem and study the e ect of parameters like number of processors; number of disks; le sizeon the system performance. We compute the I/O costs for common data distributions. Wepropose an alternative strategy-two phase data access strategy-to optimize the I/O costsconnected with data distributions. We implement runtime primitives using the two-phase …,*,1993,11
A User's Guide for the PASSION Runtime Library Version 1.0,Alok Choudhary; R Bordawekar; S More; K Sivaram; R Thakur,The PASSION Runtime Library provides software support for high-performance parallel I/Oon distributed memory parallel computers. PASSION runtime routines can be used to eciently perform the I/O required in out-of-core programs. PASSION assumes a looselysynchronous Single Program Multiple Data (SPMD) model of parallel computation. Itprovides the user with a simple high-level interface; which is a level higher than any of theexisting parallel file system interfaces or even the proposed MPI-IO interface CFH+94]. Forexample; the user only needs to specify what section of the array needs to be read in termsof its lowerbound; upper-bound and stride in each dimension; and the PASSION RuntimeLibrary will fetch it in an e cient manner. A number of optimizations; such as Data Sieving;Data Prefetching; Data Reuse; and the Extended Two-Phase Method; have been …,Syracuse University; October,1995,10
Disk-based management of interaction graphs,Buğra Gedik; Rajesh Bordawekar,In our increasingly connected and instrumented world; live data recording the interactionsbetween people; systems; and the environment is available in various domains; such astelecommunications and social media. This data often takes the form of a temporallyevolving graph; where entities are the vertices and the interactions between them are theedges. An important feature of this graph is that the number of edges it has growscontinuously; as new interactions take place. We call such graphs interaction graphs. In thispaper we study the problem of storing interaction graphs such that temporal queries on themcan be answered efficiently. Since interaction graphs are append-only and edges are addedcontinuously; traditional graph layout and storage algorithms that are batch based cannot beapplied directly. We present the design and implementation of a system that caches …,IEEE Transactions on Knowledge and Data Engineering,2014,9
Fortran 90D Intrinsic Functions on Distributed Memory Machines: Implementation and Scalability,Ishfaq Ahmad; Rajesh Bordawekar; Zeki Bozkus; Alok Choudhary; Geoffrey Fox; Kanchana Parasuram; Ravi Ponnusamy; Sanjay Ranka; Rajeev Thakur,The authors are developing a Fortran 90D compiler; which converts Fortran 90D code intoFortran 77 plus message passing node programs for distributed memory machines. Theauthors present the implementation and performance results of Fortran 90D intrinsicfunctions on the Intel iPSC/860 hypercube. They have implemented several Fortran 90Dintrinsic functions so that they can be called from the node programs of a distributed memorymachine. The implementations are scalable; portable and architecture independent.,System Sciences; 1993; Proceeding of the Twenty-Sixth Hawaii International Conference on,1993,9
Analyzing analytics,Rajesh Bordawekar; Bob Blainey; Ruchir Puri,Abstract This book aims to achieve the following goals:(1) to provide a high-level survey ofkey analytics models and algorithms without going into mathematical details;(2) to analyzethe usage patterns of these models; and (3) to discuss opportunities for acceleratinganalytics workloads using software; hardware; and system approaches. The book firstdescribes 14 key analytics models (exemplars) that span data mining; machine learning;and data management domains. For each analytics exemplar; we summarize itscomputational and runtime patterns and apply the information to evaluate parallelization andacceleration alternatives for that exemplar. Using case studies from important applicationdomains such as deep learning; text analytics; and business intelligence (BI); wedemonstrate how various software and hardware acceleration strategies are …,Synthesis Lectures on Computer Architecture,2015,8
An algorithm for partitioning trees augmented with sibling edges,Rajesh Bordawekar; Oded Shmueli,Abstract We investigate a special case of the graph partitioning problem: the partitioning of asibling graph which is an ordered tree augmented with edges connecting consecutive nodesthat share a common parent. We describe the algorithm; XS; and present a proof of itscorrectness.,Information Processing Letters,2008,8
Issues in compiling I/O intensive problems,Rajesh Bordawekar; Alok Choudhary,Abstract It has been widely acknowledged in high-performance computing circles thatinput/output (I/O) needs substantial improvement in order to make scalable computers trulyusable. Many users see parallelism in I/O as the best way to improve the I/O performance.Recent surveys [12] of I/O needs of parallel applications have determined that their I/Orequirements fall into following categories:(1) Initial/intermediate/final I/O;(2) Out-of-coreComputations;(2) Checkpointing and Restart and (4) Real-time I/O. In order to improve theoverall I/O performance; one or more of these requirements need tobe addressed.,*,1996,8
Method and system for detection of integrity constraint violations,*,A system (and method) of detecting an error in a database interaction; includes providinginformation about at least one of at least first and second software systems; and a mappingbetween at least a portion of the at least first and second software systems; and examiningthe at least one of the first and second software systems and the mapping to determine anerror in an interaction between the at least first and second software systems.,*,2012,7
Method for providing maximal concurrency in a tree structure,*,The emergence of commodity parallelism makes concurrent B-trees of interest for a variety ofother software. Concurrent use of a B-tree requires that one control access to nodes; typicallyusing locks. One proceeds from the root of the tree toward the leaves; locking individual nodesalong the way. To gain a more stable view of the tree and stronger invariants; one can use alocking protocol such as lock coupling. In such a protocol; to move from an already locked nodeA to a child node B; one first locks B and only then releases the lock on A. This has the effectof preserving operation order along any given path in the tree and is deadlock-free becauseit always locks a parent before a child. However; one cannot implement lock coupling using atomicblocks because the periods of time A and B that are locked are neither independent nor properlynested … A concern that highly concurrent implementations face is how long a given …,*,2010,7
Optimizing out-of-core computations in uniprocessors,Mahmut Kandemir; Alok Choudhary; J Ramanujam; Rajesh Bordawekar,Abstract Programs accessing disk-resident arrays perform poorly in general due toexcessive number of I/O calls and insufficient help from compilers. In this paper; in order toalleviate this problem; we propose a series of compiler optimizations. Both the analyticalapproach we use and the experimental results provide strong evidence that our method isvery effective on uniprocessors for out-of-core nests whose data sizes far exceed the size ofavailable memory.,Proceedings of the Workshop on Interaction between Compilers and Computer Architectures,1997,7
A Uni ed Tiling Approach for Out-Of-Core Computations,M Kandemir; R Bordawekar; A Choudharyy; J Ramanujam,Abstract This paper describes a framework by which an out-of-core stencil program written ina data-parallel language can be translated into node programs in a distributed-memorymessage-passing machine with explicit I/O and communication. We focus on a techniquecalled Data Space Tiling to group data elements into slabs that can t into memories ofprocessors. Methods to choose legal tile shapes under several constraints and deadlock-free scheduling of tiles are investigated. Our approach is uni ed in the sense that it can beapplied to both FORALL loops and the loops that involve ow-dependences.,*,1996,7
Analyzing analytics,Rajesh Bordawekar; Bob Blainey; Chidanand Apte,Abstract Many organizations today are faced with the challenge of processing and distillinginformation from huge and growing collections of data. Such organizations are increasinglydeploying sophisticated mathematical algorithms to model the behavior of their businessprocesses to discover correlations in the data; to predict trends and ultimately drivedecisions to optimize their operations. These techniques; are known collectively asanalytics; and draw upon multiple disciplines; including statistics; quantitative analysis; datamining; and machine learning. In this survey paper; we identify some of the key techniquesemployed in analytics both to serve as an introduction for the non-specialist and to explorethe opportunity for greater optimizations for parallelization and acceleration usingcommodity and specialized multi-core processors. We are interested in isolating and …,ACM SIGMOD Record,2014,6
Implementation and evaluation of collective i/o in the intel paragon parallel file system,Rajesh Bordawekar,ABSTRACT A majority of parallel applications obtain parallelism by partitioning data overmultiple processors. Accessing distributed data structures like arrays from les often requireseach processor to make a large number of small non-contiguous data requests. Thisproblem can be addressed by replacing small noncontiguous requests by large collectiverequests. This approach; known as Collective I/O; has been found to work extremely well inpractice BdC93; Kot96; SCJ+95]. In this paper; we describe implementation and evaluationof a collective I/O prototype in a production parallel le system on the Intel Paragon. Theprototype is implemented in the PFS subsystem of the Intel Paragon Operating System. Weevaluate the collective I/O performance using its comparison with the PFS M RECORD andM UNIX I/O modes. It is observed that collective I/O provides signi cant performance …,*,1996,6
Identifying communities in an information network,*,Techniques for identifying one or more communities in an information network are provided.The techniques include collecting one or more nodes and one or more edges from aninformation network; performing a random walk on the one or more nodes to produce asequence of one or more nodes; creating a sequence database from one or moresequences produced via random walk; and mining the sequence database to determine oneor more patterns in the network; wherein the one or more patterns identify one or morecommunities in the information network.,*,2013,5
Observations on tuning a Java enterprise application for performance and scalability,E Altman; Matthew Arnold; Rajesh Bordawekar; Robert M Delmonico; Nick Mitchell; Peter F Sweeney,Enterprise software shows increasing levels of concurrency and complexity and decreasingthink times between user interactions. Such trends are evident in both emerging workloads;such as social networking; and traditional applications; such as banking; for which bothquery counts and complexity are increasing. Similarly; in today's multicore-processor era;processor core counts double every processor generation. However; not all hardwarecapacity (eg; cache; disk; and network capacity) is growing at this core rate. As a result;processor dies will have more cores sharing resources. Personnel associated with ourproject Multicore Applications Restructured for Scaling started with a well-tuned baselineversion of a large multitier commercial workload and worked to efficiently identify a small setof software changes that; together; would lead to improved scaling and performance. This …,IBM Journal of Research and Development,2010,5
Searching multi-dimensional data using a parallelization framework comprising data partitioning and short-cutting via early out,*,Techniques for searching multi-dimensional data are provided. The techniques includeproviding a parallelization framework for a search algorithm; wherein the search algorithmexposes one or more architecture-sensitive tunable optimization parameters; and using theone or more architecture-sensitive tunable optimization parameters to tune the searchalgorithm to search multi-dimensional data in any underlying architecture.,*,2013,4
Concept Analysis Operations Utilizing Accelerators,*,Mechanisms; in a system comprising a host system and at least one accelerator device; forperforming a concept analysis operation are provided. The host system extracts a set of oneor more concepts from an information source and provides the set of one or more conceptsto the accelerator device. The host system also provides at least one matrix representationdata structure representing a graph of concepts and relationships between concepts in acorpus. The accelerator device executes the concept analysis operation internal to theaccelerator device to generate an output vector identifying concepts in the corpus; identifiedin the at least one matrix representation data structure; related to the set of one or moreconcepts extracted from the information source. The accelerator device outputs the outputvector to the host system which utilizes the output vector to respond to a request …,*,2016,3
Running native code across single or multi-core hybrid processor achitecture,*,Provided is a method that enables an interpretive engine to execute in a non-homogeneous;multiple processor architecture. Am interpretive engine is modified to identify code native toa target processor that is executing an ISA different than the ISA of the processor executingthe interpretive engine. An intermediate function is called to correlate the native code with aprocessor type and a target processor is identified. A context is created for the native codeand the context is either transmitted to the target processor or stored in a memory locationsuch that the target processor may retrieve the context. Once the context is transmitted; thetarget processor executes the task. Results are either transmitted to the originatingprocessor or placed in memory such that the originating processor can access the result andthe originating processor is signaled of the completion of the task.,*,2014,3
Evaluation of parallel hashing techniques,Rajesh Bordawekar,• Overall space utilization similar to that of cuckoo hashing; with higher load factor• Onlyuses fast single-precision atomic CAS operations• Number of CAS operations in the order ofinput data items (N)• Multiple levels enable bounded probing and reduce the size ofbounded probe region• Probe region sizes:(4; 256) for two levels;(4; 8; 8) for three levels•Probe region size enables hardware coalescing and exploits locality during insertion andquerying• No restrictions on the number of threads in the thread block• Enables data-parallelimplementation of querying functions,GTC,2014,3
Analyzing analytics; part 1: A survey of business analytics models and algorithms,Rajesh Bordawekar; Bob Blainey; Chidanand Apte; Michael McRoberts,Abstract Many organizations today are faced with the challenge of processing and distillinginformation from huge and growing collections of data. We see examples of retailers trying tobetter serve their customers; telecommunications providers trying to more effectivelymanage their growing networks; cities trying to provide smarter infrastructure and servicesfor their rapidly growing populations; and many more similar instances across multipleindustries. These organizations are facing a deluge of information and are increasinglydeploying sophisticated mathematical algorithms to model the behavior of their businessprocesses to discover correlations in the data; to predict trends and ultimately drivedecisions to optimize their operations. These techniques; are known collectively as”analytics”; and draw upon multiple disciplines; including statistics; quantitative analysis …,*,2011,3
Believe it or Not! Multicore CPUs can Match GPUs for FLOP-intensive Applications,Rajesh Bordawekar; Ravi Rao; Uday Bondhugula,In this work; we evaluate performance of a real-world image processing application thatuses a cross-correlation algorithm to compare a given image with a reference one. Thealgorithm processes individual images represented as 2-dimensional matrices of single-precision floating-point values using O (n4) operations involving dot-products and additions.We implement this algorithm on a nVidia GTX 285 GPU using CUDA; and also parallelize itfor the Intel Xeon (Nehalem) and IBM Power7 processors; using both manual and automatictechniques. Pthreads and OpenMP with SSE and VSX vector intrinsics are used for themanually parallelized version; while a state-of-the-art optimization framework based on thepolyhedral model is used for automatic compiler parallelization and optimization. Theperformance of this algorithm on the nVidia GPU suffers from:(1) a smaller shared …,*,2010,3
PASSIONate Approach to High-Performance Parallel I/O,Rajeev Thakur; Alok Choudhary; Rajesh Bordawekar; Sach-in More; K Sivaramkrishna,Abstract Parallel computers with peak performance of more than 100 Gﬂops are alreadyavailable. However; the I/O (input/output) performance of these machines is just a paleshadow of their computational power. This problem is compounded by the fact that parallelcomputers are increasingly being used for large scientiﬁc and other applications havinghuge data requirements; which perform a considerable amount of I/O. It is widely recognizedthat in order to have a bal-anced system; the I/O performance needs to improve signiﬁcantly.This requires improvements in hardware as well as software support for parallel I/O.'; Wehave developed a runtime system; called PASSION (Parallel and Scalable Software for Input-Output); that provides software support for high-performance parallel 1/O ondistributedmemory parallel computers. PASSION provides a library of optimized routines …,IEEE Computer,1996,3
Using Word Embedding to Enable Semantic Queries in Relational Databases,Rajesh Bordawekar; Oded Shmueli,Abstract We investigate opportunities for exploiting Artificial Intelligence (AI) techniques forenhancing capabilities of relational databases. In particular; we explore applications ofNatural Language Processing (NLP) techniques to endow relational databases withcapabilities that were very hard to realize in practice. We apply an unsupervised neural-network based NLP idea; Distributed Representation via Word Embedding; to extract latentinformation from a relational table. The word embedding model is based on meaningfultextual view of a relational database and captures inter-/intra-attribute relationships betweendatabase tokens. For each database token; the model includes a vector that encodes thesecontextual semantic relationships. These vectors enable processing a new class of SQL-based business intelligence queries called cognitive intelligence (CI) queries that use the …,Proceedings of the 1st Workshop on Data Management for End-to-End Machine Learning,2017,2
Parallelized Hybrid Sparse Matrix Representations for Performing Personalized Content Ranking,*,Mechanisms are provided for performing a matrix operation. A processor is configured toperform hybrid compressed representation matrix operations on an input matrix thatcomprises zero value and non-zero value entries. A first compressed representation datastructure corresponding to the input matrix; and a second compressed representation datastructure are obtained; each utilizing a different format for representing the non-zero valueentries of the input matrix. A matrix operation is iteratively executed on the input matrix usingthe first compressed representation data structure and the second compressedrepresentation data structure. The first compressed representation data structure is utilizedfor a first subset of iterations of the matrix operation and the second compressedrepresentation data structure is utilized for a second subset of iterations of the matrix …,*,2016,2
Accelerating database workloads by software-hardware-system co-design,Rajesh R Bordawekar; Mohammad Sadoghi,The key objective of this tutorial is to provide a broad; yet an in-depth survey of the emergingfield of co-designing software; hardware; and systems components for acceleratingenterprise data management workloads. The overall goal of this tutorial is two-fold. First; weprovide a concise system-level characterization of different types of data managementtechnologies; namely; the relational and NoSQL databases and data stream managementsystems from the perspective of analytical workloads. Using the characterization; we discussopportunities for accelerating key data management workloads using software andhardware approaches. Second; we dive deeper into the hardware acceleration opportunitiesusing Graphics Processing Units (GPUs) and Field-Programmable Gate Arrays (FPGAs) forthe query execution pipeline. Furthermore; we explore other hardware acceleration …,Data Engineering (ICDE); 2016 IEEE 32nd International Conference on,2016,2
Method and system for processing queries over datasets stored using hierarchical data structures,*,Systems and methods for processing a query are provided. A method for processing a queryof a tree-based dataset; comprises receiving the query; and analyzing the query and thedataset to create an execution plan for the query; wherein creating the execution plancomprises partitioning traversals over the dataset into sequential and parallel components;and distributing the components across a plurality of processing threads that independentlytraverse their portion of the dataset and compute local results. The method further comprisesmerging the local results to compute a final result.,*,2015,2
Fast computation of functional networks from fMRI activity: a multi-platform comparison,A Ravishankar Rao; Rajesh Bordawekar; Guillermo Cecchi,The recent deployment of functional networks to analyze fMRI images has been verypromising. In this method; the spatio-temporal fMRI data is converted to a graph-basedrepresentation; where the nodes are voxels and edges indicate the relationship between thenodes; such as the strength of correlation or causality. Graph-theoretic measures can thenbe used to compare different fMRI scans. However; there is a significant computationalbottleneck; as the computation of functional networks with directed links takes several hourson conventional machines with single CPUs. The study in this paper shows that a GPU canbe advantageously used to accelerate the computation; such that the network computationtakes a few minutes. Though GPUs have been used for the purposes of displaying fMRIimages; their use in computing functional networks is novel. We describe specific …,Medical Imaging 2011: Image Processing,2011,2
To Parallelize or Not to Parallelize: XPath Queries on Multi-core Systems,Rajesh Bordawekar; Lipyeow Lim; Anastasios Kementsietsidis; B Kok,ABSTRACT With wide availability of commodity multi-core systems; it is imperative tounderstand what; if any; changes are needed to existing software systems to harness thenewly available computational power. In this context; this work explores acceleration of XMLprocessing systems. Specifically; we investigate parallelization of individual XPath queriesover shared-address space multi-core processors. Unlike past approaches that haveconsidered a distributed setting or ad hoc parallel solutions; ours is the first methodicalendto-end proposal. Our solution first identifies if a particular XPath query should beparallelized and then determines the optimal way of parallelizing that query. This decision isbased on a cost-base approach that relies both on the query specifics and data statistics. Ateach stage of the parallelization process; we evaluate three alternative approaches …,*,2009,2
Pixsar: Incremental reclustering of augmented xml trees,Lila Shnaiderman; Oded Shmueli; Rajesh Bordawekar,Abstract XML is one of the primary encoding schemes for data and knowledge. Weinvestigate incremental physical data clustering in systems that store XML documents usinga native format. We formulate the XML clustering problem as an augmented (with siblingedges) tree partitioning problem and propose the PIXSAR (Practical Incremental XMLSibling Augmented Reclustering) algorithm for incrementally clustering XML documents. Weshow the fundamental importance of workload-driven dynamically rearranging storage.PIXSAR incrementally executes reclustering operations on selected subgraphs of the globalaugmented document tree. The subgraphs are implied by significant changes in theworkload. As the workload changes; PIXSAR incrementally djusts the XML data layout so asto better fit the workload. PIXSAR's main parameters are the radius; in pages; of the …,Proceedings of the 10th ACM workshop on Web information and data management,2008,2
AXIL: An XPath Intermediate Language,Christoph Reichenbach; Michael Burke; Igor Peshansky; Mukund Raghavachari; Rajesh Bordawekar,Abstract XPath is a central component of many XML-processing languages; therefore; it isimportant to process XPath queries efficiently. We describe AXIL; a functional intermediatelanguage; which allows us to simplify the task of optimising and compiling XPath for efficientexecution. We describe interesting parts of the syntax and semantics of AXIL and particulardesign issues which shaped this language; sketch the translation from XPath into AXIL; anddiscuss our experience with using AXIL for an optimising XPath compiler backend.,*,2006,2
Extending I/O capabilities of High Performance Fortran: Initial experiences,Rajesh Bordawekar; Alok Choudhary,*,*,1995,2
Cognitive Database: A Step towards Endowing Relational Databases with Artificial Intelligence Capabilities,Rajesh Bordawekar; Bortik Bandyopadhyay; Oded Shmueli,Abstract: We propose Cognitive Databases; an approach for transparently enabling ArtificialIntelligence (AI) capabilities in relational databases. A novel aspect of our design is to firstview the structured data source as meaningful unstructured text; and then use the text tobuild an unsupervised neural network model using a Natural Language Processing (NLP)technique called word embedding. This model captures the hidden inter-/intra-columnrelationships between database tokens of different types. For each database token; themodel includes a vector that encodes contextual semantic relationships. We seamlesslyintegrate the word embedding model into existing SQL query infrastructure and use it toenable a new class of SQL-based analytics queries called cognitive intelligence (CI)queries. CI queries use the model vectors to enable complex queries such as semantic …,arXiv preprint arXiv:1712.07199,2017,1
Matrix ordering for cache efficiency in performing large sparse matrix operations,*,Mechanisms are provided for performing a matrix operation. A processor of a dataprocessing system is configured to perform cluster-based matrix reordering of an inputmatrix. An input matrix; which comprises nodes associated with elements of the matrix; isreceived. The nodes are clustered into clusters based on numbers of connections with othernodes within and between the clusters; and the clusters are ordered by minimizing a totallength of cross cluster connections between nodes of the clusters; to thereby generate areordered matrix. A lookup table is generated identifying new locations of nodes of the inputmatrix; in the reordered matrix. A matrix operation is then performed based on the reorderedmatrix and the lookup table.,*,2017,1
Provisioning service requests in a computer system,*,Disclosed is a system; computer program product; and method for provisioning a newservice request. The computer-implemented method begins with receiving a new servicerequest for computational resources in a computing system. The required computationalresources are memory usage; storage usage; processor usage; or a combination thereof tofulfill the new service request. Next a sandbox computing environment is used to operate thenew service request. The sandbox computing environment is used to isolate the computingsystem. The sandbox computing environment produces a current computational resourcesusage data to fulfill the new service request in the sandbox computing environment. Thecurrent sandbox computational resources usage data and historical computationalresources usage data are both used by a machine learning module to create a prediction …,*,2016,1
Enabling cognitive intelligence queries in relational databases using low-dimensional word embeddings,Rajesh Bordawekar; Oded Shmueli,Abstract: We apply distributed language embedding methods from Natural LanguageProcessing to assign a vector to each database entity associated token (for example; a tokenmay be a word occurring in a table row; or the name of a column). These vectors; of typicaldimension 200; capture the meaning of tokens based on the contexts in which the tokensappear together. To form vectors; we apply a learning method to a token sequence derivedfrom the database. We describe various techniques for extracting token sequences from adatabase. The techniques differ in complexity; in the token sequences they output and in thedatabase information used (eg; foreign keys). The vectors can be used to algebraicallyquantify semantic relationships between the tokens such as similarities and analogies.Vectors enable a dual view of the data: relational and (meaningful rather than purely …,arXiv preprint arXiv:1603.07185,2016,1
Building and querying hash tables on processors,*,A plurality of memory maps may be allocated that represents the hash table on a memorydevice to store keys and values. The memory maps may comprise at least a primary mapand a secondary map. A hash table operation may be performed on the primary map basedon a first position computed using a first hash function; and if not successful; a boundedlinear probing that probes a defined primary probe region in the primary map. Responsive todetermining that the hash table operation on the primary map is not successful; the hashtable operation may be performed on the secondary map based on a second positioncomputed using a second hash function; and if not successful; a bounded linear probing thatprobes a defined secondary probe region in the secondary map.,*,2015,1
Computer system performance markers,*,Identifying computer system markers to understand computer system performance; in oneaspect; may comprise identifying a set of executions of applications indicative of computerperformance based on first values associated with a first set of artifacts in the set ofexecutions. Two subsets of executions from said identified set of executions are selectedbased on second values associated with a second set of artifacts in the set of executions.One or more markers are identified by determining one or more third set of artifacts from thetwo subsets of executions that have an associated third value that is different in a first of thetwo subsets from a second of the two subsets of executions according to a criterion.,*,2014,1
Project trident: An investigation into integrating databases; analytics; and high-performane computing,Rajesh Bordawekar,This paper describes Project Trident; an effort at IBM Research that aims to explore theinteractions between the HPC; analytics; and enterprise systems. The key goals of theproject are to identify common computational patterns across the three domains and todetermine key system and library components that can be used to optimize performance ofall the three different workloads. We first summarize key similarities and differences betweendifferent workload domain and then outline various design issues for building an unifiedsystem.,High Performance Computing; Networking; Storage and Analysis (SCC); 2012 SC Companion:,2012,1
XJ: robust XML processing in Java™,Rajesh Bordawekar; Michael Burke; Igor Peshansky; Mukund Raghavachari,XML has emerged as an important standard for data integration. Despite the importance ofXML; the development of XML processing applications in object-oriented programminglanguages such as Java can be tedious. Programmers use low-level APIs such as DOM;which provide minimal support for ensuring that programs that process XML are correct withrespect to the XML Schemas governing the XML data. Furthermore; the runtime performanceof XML processing is a limitation of XML. Runtime libraries do not take advantage of staticanalysis of programs or XML Schema information to optimize accesses to XML data. XJ [2] isa research language that integrates XML as a first-class construct into Java (a prototype isavailable for download from http://www. alphaworks. ibm. com/tech/xj). Salient features of XJinclude:,Companion to the 20th annual ACM SIGPLAN conference on Object-oriented programming; systems; languages; and applications,2005,1
Integrating database and programming language constraints,Oded Shmueli; Mukund Raghavachari; Vivek Sarkar; Rajesh Bordawekar; Michael G Burke,Abstract We examine the maintenance of data consistency in the presence of application-database interactions. Currently; a programmer must insert explicit checks to ensure thatdata are consistent with respect to the application's and the database's requirements. Thisexplicit hand-coding of integrity constraint checks is error-prone and results in lessmaintainable code when the integrity constraints on the application or the database change.We describe an architecture for automatically generating application-level checks fromapplication and database integrity constraint specifications. We focus on EJB-databaseinteractions as a concrete context for our work; but our results are applicable to otherprogramming language-database interactions.,International Workshop on Database Programming Languages,2003,1
Distinguishing between prolific and non-prolific types for efficient memory management,Yefim Shuf; Manish Gupta; Rajesh Bordawekar; Jaswinder Pal Singh,ABSTRACT In this paper we introduce the notion of prolific and non-prolific types; based onthe number of instantiated objects of those types. We propose and empirically validate anew hypothesis; the prolific generational hypothesis; which states that the objects of prolifictypes have short lifetimes. We use this hypothesis to develop a new garbage collectionscheme; which is similar in spirit to generational collection; but uses types rather than age todistinguish between different regions of the heap. It looks for garbage first among objects ofprolific types. Our approach lets the compiler eliminate redundant write barriers by simplychecking the type of objects involved in a pointer assignment. We describe techniques thatenable this test to be done effectively at compile time; in spite of the complications due topolymorphism and dynamic class loading in Java. A preliminary implementation of this …,*,2001,1
A case for compositional file systems,Rajesh Bordawekar,Abstract This article presents a case for compositional le systems (CFSs). The CFS isdesigned using the endto-end argument; the basic le system attributes; therefore; areindependent of the user requirements. The CFS is designed as a functionally compositional;structurally distributed; and dynamically extendible le system. The article also discusses theadvantages and implementation alternatives for such le systems; and outlines possibleapplications.,SIGOPS Operating Systems Review,1998,1
A framework for integrated communication and I/O placement,Rajesh Bordawekar; Alok Choudhary; J Ramanujam,Abstract This paper describes a framework for analyzing dataflow within an out-of-coreparallel program. Dataflow properties of FORALL statement are analyzed and a unified I/Oand communication placement framework is presented. This placement framework can beapplied to many problems; which include eliminating redudant I/O incurred incommunication. The framework is validated by applying it for optimizing I/O andcommunication in out-of-core stencil problems. Experimental performance results on an IntelParagon show significant reduction in I/O and communication overhead.,European Conference on Parallel Processing,1996,1
Runtime Support for Parallel I/O in PASSION,Rajesh Bordawekar; Rajeev Thakur; Ravi Ponnusamy; Alok Choudhary,Abstract We are developing a compiler and runtime support system called PASSION:Parallel And Scalable Software for Input-Output; to translate out-of-core data-parallelprograms to message passing node programs with explicit parallel I/O. This paper describesthe design and implementation of the runtime system used in PASSION. We explain thebasic model used by the compiler and runtime system. We describe the runtime routines forregular problems and provide an initial framework for runtime support for out-of-coreirregular problems. Preliminary performance results are presented for 2D FFT and Laplaceequation solver; and a kernel from a molecular dynamics code. This work was supported inpart by NSF Young Investigator Award CCR-9357840; a grant from Intel SSD; and IBM; andin part by USRA CESDIS Contract# 5555-26. This work was performed in part using the …,*,1995,1
Parallelized in-place radix sorting,*,Abstract Methods for sorting a data set. A data storage is divided into a plurality of bucketsthat is each associated with a respective key value. A plurality of stripes is identified in eachbucket. At least one data stripe set is defined that has one stripe within each respectivebucket. An in-place partial bucket radix sort is performed on data items contained within onedata stripe set with a first processor using an initial radix. Incorrectly sorted data items arethen grouped in each bucket into a respective incorrect data item group within each bucket.A radix sort is then performed using the initial radix on the items within the respectiveincorrect data item group. A first level sorted output is produced.,*,2018,*
USING WORD EMBEDDING TO SELECTIVELY DISCLOSE DATABASE INFORMATION,Rajesh Bordawekar; Oded Shmueli,Abstract: Database information may be disclosed in a variety of ways depending on thesensitivity of the stored information and the recipient's need to know. Traditionally;researchers have been concerned with preventing a recipient of the information fromassociating sensitive information (eg; a disease) with specific individuals. However; otherconcerns may apply. For example; within an enterprise (Domingo-Ferrer et al.; 2016); certaintest results may be considered sensitive and should be only be openly disclosed to divisionsconcerned with these results. On the other hand; disclosing as much information as possiblemay also be in the enterprise's interest as it is not always clear what information may actuallybe useful to a division. We propose a mechanism that allows a discloser to exercise finecontrol over what is being disclosed and allowing disclosing information indirectly rather …,*,2018,*
EXPLOITING LATENT INFORMATION IN RELATIONAL DATABASES VIA WORD EMBEDDING,Rajesh Bordawekar; Oded Shmueli; Bortik Bandyopadhyay,Abstract: We propose Cognitive Databases; an approach for transparently enabling ArtificialIntelligence (AI) capabilities in relational databases. A novel aspect of our design is to firstview the structured data source as meaningful unstructured text; and then use the text tobuild a word embedding model. This model captures the hidden inter-/intra-columnrelationships between database tokens of different types such as numeric values; SQLDates; and even images. For each database token; the model includes a vector thatencodes contextual semantic relationships. We seamlessly integrate the word embeddingmodel into existing SQL query infrastructure and use it to enable a new class of SQL-basedanalytics queries called cognitive intelligence (CI) queries. CI queries use the model vectorsto enable complex queries such as semantic similarity/dissimilarity; inductive reasoning …,*,2018,*
Parallelized in-place radix sorting,*,Abstract Methods for sorting a data set. Data items each having a first portion and a secondportion is stored. The first and second portions are stored separately and each has aseparate set of keys. The first portion has a pointer indicating the second portion. At leastsome of the first set of keys for each data item is stored in a local memory of a first processor.At least one data stripe set is defined with one stripe within each bucket. An in-place partialbucket radix sort is performed on data items within one data stripe set with a first processorusing an initial key. Incorrectly sorted data items are grouped into respective incorrect dataitem groups within each bucket. A radix sort is then performed using the initial radix on theincorrect data item groups. A first level sorted output is produced.,*,2018,*
Parallelized in-place radix sorting,*,Abstract Systems and methods for sorting a data set. A data storage is divided into a pluralityof buckets that is each associated with a respective key value. A plurality of stripes isidentified in each bucket. At least one data stripe set is defined that has one stripe withineach respective bucket. An in-place partial bucket radix sort is performed on data itemscontained within one data stripe set with a first processor using an initial radix. Incorrectlysorted data items are then grouped in each bucket into a respective incorrect data itemgroup within each bucket. A radix sort is then performed using the initial radix on the itemswithin the respective incorrect data item group. A first level sorted output is produced.,*,2017,*
Parallelized in-place radix sorting,*,Abstract Systems and methods for sorting a data set. Data items each having a first portionand a second portion is stored. The first and second portions are stored separately and eachhas a separate set of keys. The first portion has a pointer indicating the second portion. Atleast some of the first set of keys for each data item is stored in a local memory of a firstprocessor. At least one data stripe set is defined with one stripe within each bucket. An in-place partial bucket radix sort is performed on data items within one data stripe set with afirst processor using an initial key. Incorrectly sorted data items are grouped into respectiveincorrect data item groups within each bucket. A radix sort is then performed using the initialradix on the incorrect data item groups. A first level sorted output is produced.,*,2017,*
Method and system for hybrid sort and hash-based query execution,*,A database system; computer program product; and a method for evaluating aggregates indatabase systems includes hashing of aggregation keys on a per bucket basis; anddepending on a number of hashed tuples per bucket; sorting said tuples. Additionally;depending on the number of hashed tuples per bucket; the bucket is kept without change.Moreover; depending on the number of hashed tuples per bucket; maintaining a secondaryhash table for a particular bucket; map tuples to it; aggregate as you map.,*,2017,*
Method And System For Semantic-Based Queries Using Word Vector Representation,*,A method; apparatus; and computer program product are provided for generating a set oftoken sequences for at least a portion of a database; wherein each token in a sequencerepresents a respective database entity of the database; assigning; for each token in the setof token sequences; at least one corresponding vector from a set of vectors of a samedimension; wherein the at least one corresponding vector encodes relationships betweenthe database entity of a token and other database entities of other tokens of the set of tokensequences; and extracting; using a query language; information from the database based atleast in part on the relationships encoded by the assigned vectors.,*,2017,*
Data Management on New Hardware,Spyros Blanas; Rajesh Bordawekar; Tirthankar Lahiri; Justin Levandoski; Andrew Pavlo,The International Workshop on Accelerating Analytics and Data Management SystemsUsing Modern Processor and Storage Architectures (ADMS) and the International Workshopon In-Memory Data Management (IMDM) were held jointly this year. The objective of thisworkshop is to investigate opportunities in accelerating analytics/data management systemsand workloads (which include traditional OLTP; data warehousing/OLAP; ETL;streaming/real-time; business analytics; and XML/RDF processing) running in memory-onlyenvironments; using processors (eg; commodity and specialized multi-core; GPUs; andFPGAs); storage systems (eg; storage-class memories like SSDs and phase-changememory); and hybrid programming models such as CUDA; OpenCL; and OpenACC. Theworkshop hopes to explore the interplay between overall system design; core algorithms …,*,2017,*
Detecting denial-of-service attacks on graph databases,*,Detecting a denial-of-service attack on a graph database is provided. In response toreceiving a request to process a graph query on the graph database from a client device viaa network; a graph query pattern of the graph query is determined. In response todetermining that the graph query pattern of the graph query matches a stored graph querypattern that lead to a previous denial-of-service attack on the graph database; the graphquery is identified as the denial-of-service attack on the graph database. Then; the requestto process the graph query is denied by dropping the graph query.,*,2017,*
System and method for natural language processing using synthetic text,*,A method for performing natural language processing includes receiving a primary text file.The received primary text file is scanned to determine a set of statistics related to afrequency at which various words of the primary text file follow other words of the primary textfile. A probabilistic word generator is created based on the determined set of statistics. Theprobabilistic word generator generates synthetic text exhibiting the determined set ofstatistics. Synthetic text exhibiting the determined set of statistics is generated using thecreated probabilistic word generator. Word vectorization is performed on the synthetic text.Results of the performed vectorization are used to perform machine learning tasks.,*,2017,*
HPBDC Introduction and Committees,Dhabaleswar K Panda; Jianfeng Zhan; Xiaoyi Lu,Managing and processing large volumes of data; or “Big Data”; and gaining meaningfulinsights is a significant challenge facing the distributed computing community. This hassignificant impact on a wide range of domains including health care; bio-medical research;Internet search; finance and business informatics; and scientific computing. As data-gathering technologies and data-sources witness an explosion in the amount of input data; itis expected that in the future massive quantities of data in the order of hundreds orthousands of petabytes will need to be processed. Thus; it is critical that data-intensivecomputing middleware (such as Hadoop; HBase and Spark) to process such data arediligently designed; with high performance and scalability; in order to meet the growingdemands of such Big Data applications. The explosive growth of Big Data has caused …,Parallel and Distributed Processing Symposium Workshops; 2016 IEEE International,2016,*
Radix sort acceleration using custom asic,*,An information processing system; computer readable storage medium; and method foraccelerated radix sort processing of data elements in an array in memory. The informationprocessing system stores an array of data elements in a buffer memory in an applicationspecific integrated circuit radix sort accelerator. The array has a head end and a tail end.The system radix sort processing; with a head processor; data elements starting at the headend of the array and progressively advancing radix sort processing data elements towardthe tail end of the array. The system radix sort processing; with a tail processor; dataelements starting at the tail end of the array and progressively advancing radix sortprocessing data elements toward the head end of the array; the tail processor radix sortprocessing data elements in the array contemporaneously with the head processor radix …,*,2015,*
Program Committee for International Workshop on High-Performance Big Data Computing (HPBDC 2015),Dhabaleswar K DK Panda; Jianfeng Zhan; Xiaoyi Lu; Chaitanya Baru; Rajesh Bordawekar; Yanpei Chen; Bingsheng He; Lizy John; Jian Li; Xu Liu; Raghunath Nambiar; Manoj Nambiar; Ren Wu; Li Zha; Yunquan Zhang,In conjunction with ICDCS 2015 June 29; 2015 … • Dhabaleswar K. (DK) Panda; The Ohio StateUniversity • Jianfeng Zhan; Institute of Computing Technology; Chinese Academy ofSciences; China • Xiaoyi Lu; The Ohio State University … • Chaitanya Baru; San Diego SupercomputerCenter; National Science Foundation • Rajesh Bordawekar; IBM Thomas J. Watson ResearchCenter • Yanpei Chen; Cloudera • Bingsheng He; Nanyang Technological University; Singapore• Lizy John; The University of Texas at Austin • Jian Li; Huawei • Xu Liu; The College of Williamand Mary • Raghunath Nambiar; Cisco • Manoj Nambiar; Tata Consultancy Services Ltd.; India• Ren Wu; Baidu • Li Zha; Institute of Computing Technology; Chinese Academy of Sciences;China • Yunquan Zhang; Institute of Computing Technology; Chinese Academy of Sciences;China,*,2015,*
Efficient GPU implementation of convolutional neural networks for speech recognition.,Ewout van den Berg; Daniel Brand; Rajesh Bordawekar; Leonid Rachevsky; Bhuvana Ramabhadran,*,INTERSPEECH,2015,*
Efficient GPU implementation of convolutional neural networks for speech recognition,Ewout van den Berg; Daniel Brand; Rajesh Bordawekar; Leonid Rachevsky; Bhuvana Ramabhadran,Abstract Deep learning has enjoyed tremendous success in speech recognition in recentyears. Despite their widespread use; training large and complex architectures remains verytime consuming. A prime example of this are convolutional neural networks (CNNs); whichhave provided state-of-the-art results; but are also among the most computationally intensivenetworks to train. In this paper; we study four different methods for GPU acceleration ofCNNs: a native implementation using cuBLAS; two implementations based on NVIDIA'srecently released deep-learning cuDNN library; and an implementation based on cuFFT. Weanalyze the performance of each of these approaches on the forward operation; the gradientcomputation; and the backward propagation. The overall best performance is obtained usingthe custom native implementation; which was found to be up to 6.9 times faster than …,Sixteenth Annual Conference of the International Speech Communication Association,2015,*
2014 Index IEEE Transactions on Knowledge and Data Engineering Vol. 26,A Abboud; S Abraham; CC Aggarwal; A Ahmad; H Aksu; M Al Hasan; Alessia Albanese; Massimiliano Albanese; A Allue; K Amaral; Mehmet Fatih Amasyali; S Amer-Yahia; A An; W Aref; WG Aref; Ana Arruarte; A Arvanitis; N Asadi; L Atzori; Man Ho Au; U Avci; C Aykanat; Javad Azimi; A Badia; B Baesens; He Bai; Sumeet Bajaj; A Bannur; Alberto Bartoli; G Barua; S Barua; Sukarna Barua; D Ben-David; K Benabdeslem; F Benites; PA Bernstein; E Bertino; D Bhattacharjya; SS Bhowmick; MA Bhuiyan; Y Bi; C Bielza; B Biggio; F Bonchi; R Bordawekar; G Brown; J Bu; A Bulut; L Cagliero; Yi Cai; Yilun Cai; Z Cai; Inaki Calvo; M Canim; L Cao; Longbing Cao; V Carlan; P Carlin; J Carmona; C Castillo; Federico Cavalieri,This index covers all technical items-papers; correspondence; reviews; etc.-that appeared inthis periodical during the year; and items from previous years that were commented upon orcorrected in this year. Departments and other items may also be covered if they have beenjudged to have archival value. The Author Index contains the primary entry for each item;listed under the first author's name. The primary entry includes the co-authors' names; thetitle of the paper or other item; and its location; specified by the publication abbreviation;year; month; and inclusive pagination. The Subject Index contains entries describing theitem under all appropriate subject headings; plus the first author's name; the publicationabbreviation; month; and year; and inclusive pages. Note that the item title is found onlyunder the primary entry in the Author Index.,IEEE Transactions on Knowledge and Data Engineering,2015,*
Analyzing analytics,Rajesh Bordawekar; Bob Blainey; Chidanand Apte,*,SIGMOD RECORD,2013,*
Method and apparatus for computing massive spatio-temporal correlations using a hybrid CPU-GPU approach,*,A CPU may select a variable from a variable set as a dependent variable. The variable setmay be part of the data structure that includes a plurality of vector values; a vector valueassociated with a variable set of n number of variables; and each variable of the variable sethaving a variable value. The number of dependent variable steps for the dependent variablemay be determined. The number of the vector values in a dependent variable step isdetermined as being number of independent variables. A function is mapped to a plurality ofthread processors; and each thread processor is assigned for the function to be performedon each one of the independent variables for each of the dependent variable steps.,*,2013,*
MULTI-RESOLUTION MODELING OF BIOLOGICAL MACROMOLECULES–Session Introduction,Samuel Flores; Julie Bernauer; Xuhui Huang; Ruhong Zhou; Seokmin Shin,The field of molecular modeling has long recognized modeling the folding; assembly; andlong-time dynamics of large macromolecules as its biggest challenge; since it is precisely atlarge size and long time scales that computational methods are most taxed. In response; manymethods have been developed to reduce the computational cost by coarsening the granularityof the problem. Inevitably accuracy remains limited for these methods and so in recent yearsa consensus has emerged that we should work at more than one level of resolution; oftensimultaneously; in an approach known as multi-resolution modeling. We propose to organizea session on multi-resolution approaches to predict and analyze macromolecular structure; assemblyand dynamics. This session will focus on state-of-the-art methodological developments and applicationsat different levels of molecular organization. Research directions are based on …,*,2010,*
Can CPUs Match GPUs on Performance with Productivity?: Experiences with Optimizing a FLOP-intensive Application on CPUs and GPU,Ravi Rao; Rajesh Bordawekar; Uday Bondhugula,Abstract In this work; we evaluate performance of a real-world image processing applicationthat uses a cross-correlation algorithm to compare a given image with a reference one. Thealgorithm processes individual images represented as 2-dimensional matrices of single-precision floating-point values using Θ (n4) operations involving dot-products and additions.We implement this algorithm on a NVIDIA Fermi GPU (Tesla 2050) using CUDA; and alsomanually parallelize it for the Intel Xeon X5680 (Westmere) and IBM Power7 multi-coreprocessors. Pthreads and OpenMP with SSE and VSX vector intrinsics are used for themanually parallelized version on the multi-core CPUs. A number of optimizations wereperformed for the GPU implementation on the Fermi; including blocking for Fermi'sconfigurable on-chip memory architecture. Experimental results illustrate that on a single …,*,2010,*
Database Technologies for Handling-XML-Information on the Web (DataX)-Indexing XML Documents-L-Tree: A Dynamic Labeling Structure for Ordered XML Data,Yi Chen; George Mihaila; Rajesh Bordawekar; Sriram Padmanabhan,*,Lecture Notes in Computer Science,2004,*
A Unified Tiling Approach for Out-Of-Core Computations,Rajesh Bordawekar; Alok Choudhary; J Ramanujam; Mahmut Kandemir,Description/Abstract This paper describes a framework by which an out-of-core stencilprogram written in a data-parallel language can be translated into node programs in adistributed-memory message-passing machine with explicit I/O and communication. Wefocus on a technique called Data Space Tiling to group data elements into slabs that can fitinto memories of processors. Methods to choose legal tile shapes under several constraintsand deadlock-free scheduling of tiles are investigated. Our approach is unified in the sensethat it can be applied to both FORALL loops and the loops that involve flow-dependences.,*,1996,*
Agrawal; Dharma P.; 107,Corinne Ancourt; Seungjo Bae; Prithviraj Banerjee; Rajesh Bordawekar; BC Bromley; Martin C Carlisle; Siddhartha Chatterjee; Alok Choudhary; Fabien Coelho; Michele Dion; Didier El Baz; Li-Xin Gao; Didier Gazen; John R Gilbert; Manuel Ujaldón; Rob F Van der Wijngaart; Feng-Jian Wang; Pei-Chi Wu; Yong Yan; Qing Yang; Katherine Yelick; Emilio L Zapata; Xiaodong Zhang; Taegeun Park; Tai-Ming Parng; J Ramanujam; Shankar Ramaswamy; Cyril Randriamaro; Sanjay Ranka; Sibabrata Ray; Yves Robert; Anne Rogers; Arnold L Rosenberg; P Sadayappan; Joel Saltz; Sekhar R Sarukkai; Robert Schreiber; Shamik D Sharma; Thomas J Sheffler; Barbara Simons; Yongsheng Song; Pierre Spiteri; VS Sunderam; Eugene W Hodges IV; CH Huang; Kuo-Chan Huang; Hong Jiang; SD Kaushik; Ken Kennedy; Arvind Krishnamurthy; Chiung-San Lee; Pankaj Mehra; Jean Claude Miellou; Steven A Moyer; Leonid Oliker,*,Journal of Parallel and Distributed Computing,1996,*
A Framework for Representing Data Parallel Programs and its Application in Program Reordering,Rajesh Bordawekar; Alok Choudhary,Abstract In this paper; we present a framework for describing the data ow and dependenceinformation of a data parallel program. Our framework initially represents the program usinga directed Intermediate Program Locality Graph (IPLG). Using Dependence AccessRelations (DARs); the IPLG is reduced to a Program Locality Graph (PLG). The informationprovided by PLG is used by the compiler to reorder the program to improve program locality.We view the program reordering problem as an optimization problem. To solve this problem;we present a polynomial time heuristic; called the Range Reduction Heuristic. The best casetime complexity of the heuristic is O (m2n2); where m is the number of statements and n isthe number of arrays used in the program. The average case running time of the heuristicapproaches the best case performance. This framework will be implemented as a part of …,*,1995,*
CRPC-TR94483-S September 1994,Alok Choudhary; Rajesh Bordawekar; Rakesh Krishnaiyer; Ravi Ponnusamy; Tarvinder Singh; Rajeev Thakur,Abstract We are developing a software system called PASSION: Parallel And ScalableSoftware for Input-Output which provides software support for high performance parallel I/O.PASSION provides support at the language; compiler; runtime as well as file system level.PASSION provides runtime procedures for parallel access to files (read/write); as well as forout-of-core computations. These routines can either be used together with a compiler totranslate out-of-core data parallel programs written in a language like HPF; or used directlyby application programmers. A number of optimizations such as Two-Phase Access; DataSieving; Data Prefetching and Data Reuse have been incorporated in the PASSIONRuntime Library for improved performance. PASSION also provides an initial framework forruntime support for out-of-core irregular problems. The goal of the PASSION compiler is to …,*,1994,*
Flexible Workload-directed Clustering of XML Documents,Rajesh Bordawekar; Oded Shmueli,Abstract We investigate workload-directed physical data clustering in native XML databaseand repository systems. We present a practical algorithm for clustering XML documents;called XC; which is based on Lukes' tree partitioning algorithm. XC carefully approximatescertain aspects of Lukes' algorithm so as to substantially reduce memory and time usage.XC can operate with varying degrees of precision; even in memory constrainedenvironments. Experimental results indicate that XC is a superior clustering algorithm interms of partition quality; with only a slight overhead in performance when compared toWDFS; a workload-directed depth-first scan and store scheme. We demonstrate that XC issubstantially faster than the exact Lukes' algorithm; with only a minimal loss in clusteringquality. Results also indicate that XC can exploit application workload information to …,*,*,*
A Frequency-aware Parallel Algorithm for Counting Stream Items on Multicore Processors,Dina Thomas; Rajesh Bordawekar; Charu Aggarwal; Philip S Yu,ABSTRACT We present a parallel counting algorithm for estimating frequencies of itemsfrom data streams where a stream is ingested and queried in parallel by partitioning dataover multiple processing cores of a multi-core processor. We demonstrate that currentprobabilistic counting algorithms are illsuited to be used as the sequential kernel in theparallel algorithm due to space limitations; inaccuracies in approximating counts of lowfrequency items; and inability to identify the absent items in a stream. To address theseconcerns; we have devised a new sequential counting algorithm; called the Frequency-aware Counting Algorithm (FCM). FCM is related to the Cormode-Muthukrishnan Count-Minalgorithm and incorporates novel capabilities for improving accuracy in estimating low-frequency items by dynamically capturing frequency changes of items in the stream; and …,*,*,*
HPF with Parallel I/O Extensions,Rajesh Bordawekar; Alok Choudhary,High Performance Fortran (HPF) has been designed to be an informal standardprogramming language for a variety of high-performance computers; such as vectormachines and massively parallel MIMD and SIMD multiprocessors 10; 8]. HPF uses datadistribution and alignment for mapping and decomposing the computational domain onprocessors. HPF provides data distribution directives which can be used by the user to eectively declare and map distributed arrays. Important directives include PROCESSORS;TEMPLATE; DISTRIBUTE and ALIGN. Arrays can be distributed in either in BLOCK orCYCLIC form in each dimension. A large number of scientific problems including manygrand challenge problems are I/O intensive 1]. Therefore; in order to achieve goodscalability in speed and problem size; support for high performance I/O to perform reads …,*,*,*
Passion: Optimized I/O for Parallel Applications,Rajesh Bordawekar; Sivaramakrishna Kuditipudi,*,*,*,*
Parallel Prgﬁ “’ll ‘/Tttdel and Compilation Strategy,Rajesh Bordawekar,Abstract It is widely acknowledged in high-performance computing circles that parallelinput/output needs substantial improvement in order to make scalable computers trulyusable. We present'a data storage model that allows processors independent access to theirown data and a corresponding compilation strategy that integrates data-parallel computationwith data distribution for out-of-core problems. Our results compare several communicationmethods and If O optimizations using two out-of-core problems; Jacobi iteration and LUfactorization.,*,*,*
Commercial Software for Multicore Systems,B Blainey; H Franke; M Hind; RA Sciampacone; V Sundaresan; D Maier; T Gray-Donald; E Altman; M Arnold; R Bordawekar; RM Delmonico; N Mitchell; PF Sweeney; R Agarwal; S Bensalem; E Farchi; K Havelund; Y Nir-Buchbinder; SD Stoller; S Ur; L Wang; QM Teng; HC Wang; Z Xiao; E Duesterwald; C Cazcaval; S Chatterjee; KJ Gildea; P Pattnaik; J Jann; N Dubey; RS Burugula; SM Cho; DW Im; OY Jang; HJ Song; BD Paulovicks; V Sheinin; H Yeo,Microprocessor and computing-system designs are making increasing use of parallelism;which includes homogeneous and heterogeneous chip multiprocessors; or multicores; as ameans of providing continuing improvement in performance and efficiency. This issuepresents key aspects of software for parallel computing and multicore systems in thecommercial domain. This issue concludes with two nontopical papers. Topics include asubsystem for enhancing operating system health in the cloud computing era and the OpenComputing Language (OpenCL) for use in digital TV applications.,*,*,*
Highly Concurrent B-Trees Using Atomic Blocks,Rajesh Bordawekar; J Eliot B Moss,Abstract—We present a new highly-concurrent B link-tree algorithm and discuss ourimplementation of it. Our design is novel in that it supports high concurrency while usingatomic blocks in the implementation. Atomic blocks impose a discipline of static declarationof regions in which the system enforces atomicity of accesses. However; their static structureprecludes lock coupling down through the levels of the tree; the usual method for traversingconcurrent B-trees. We consider atomic blocks because of their software engineeringadvantages over unstructured use of locks. For example; it is easy to see that our design isdeadlock-free. In our approach; structure modifying operations (SMOs); such as B-tree nodesplits; occur as separate deferred; even asynchronous; operations at each affected level.This increases concurrency and leads to interesting data structure invariants and …,*,*,*
