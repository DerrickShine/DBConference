Structural joins: A primitive for efficient XML query pattern matching,Shurug Al-Khalifa; HV Jagadish; Nick Koudas; Jignesh M Patel; Divesh Srivastava; Yuqing Wu,XML queries typically specify patterns of selection predicates on multiple elements that havesome specified tree structured relationships. The primitive tree structured relationships areparent-child and ancestor-descendant; and finding all occurrences of these relationships inan XML database is a core operation for XML query processing. We develop two families ofstructural join algorithms for this task: tree-merge and stack-tree. The tree-merge algorithmsare a natural extension of traditional merge joins and the multi-predicate merge joins; whilethe stack-tree algorithms have no counterpart in traditional relational join processing. Wepresent experimental results on a range of data and queries using the TIMBER native XMLquery engine built on top of SHORE. We show that while; in some cases; tree-mergealgorithms can have performance comparable to stack-tree algorithms; in many cases …,Data Engineering; 2002. Proceedings. 18th International Conference on,2002,1206
Timber: A native xml database,Hosagrahar V Jagadish; Shurug Al-Khalifa; Adriane Chapman; Laks VS Lakshmanan; Andrew Nierman; Stelios Paparizos; Jignesh M Patel; Divesh Srivastava; Nuwee Wiwatwattana; Yuqing Wu; Cong Yu,Abstract This paper describes the overall design and architecture of the Timber XMLdatabase system currently being implemented at the University of Michigan. The system isbased upon a bulk algebra for manipulating trees; and natively stores XML. New accessmethods have been developed to evaluate queries in the XML context; and new costestimation and query optimization techniques have also been developed. We presentperformance numbers to support some of our design decisions. We believe that the keyintellectual contribution of this system is a comprehensive set-at-a-time query processingability in a native XML store; with all the standard components of relational queryprocessing; including algebraic rewriting and a cost-based optimizer.,The VLDB Journal—The International Journal on Very Large Data Bases,2002,568
Partition based spatial-merge join,Jignesh M Patel; David J DeWitt,Abstract This paper describes PBSM (Partition Based Spatial-Merge); a new algorithm forperforming spatial join operation. This algorithm is especially effective when neither of theinputs to the join have an index on the joining attribute. Such a situation could arise if bothinputs to the join are intermediate results in a complex query; or in a parallel environmentwhere the inputs must be dynamically redistributed. The PBSM algorithm partitions theinputs into manageable chunks; and joins them using a computational geometry basedplane-sweeping technique. This paper also presents a performance study comparing the thetraditional indexed nested loops join algorithm; a spatial join algorithm based on joiningspatial indices; and the PBSM algorithm. These comparisons are based on completeimplementations of these algorithms in Paradise; a database system for handling GIS …,ACM Sigmod Record,1996,476
A comparison of join algorithms for log processing in mapreduce,Spyros Blanas; Jignesh M Patel; Vuk Ercegovac; Jun Rao; Eugene J Shekita; Yuanyuan Tian,Abstract The MapReduce framework is increasingly being used to analyze large volumes ofdata. One important type of data analysis done with MapReduce is log processing; in whicha click-stream or an event log is filtered; aggregated; or mined for patterns. As part of thisanalysis; the log often needs to be joined with reference data such as information aboutusers. Although there have been many studies examining join algorithms in parallel anddistributed DBMSs; the MapReduce framework is cumbersome for joins. MapReduceprogrammers often use simple but inefficient algorithms to perform joins. In this paper; wedescribe crucial implementation details of a number of well-known join strategies inMapReduce; and present a comprehensive experimental comparison of these jointechniques on a 100-node Hadoop cluster. Our results provide insights that are unique to …,Proceedings of the 2010 ACM SIGMOD International Conference on Management of data,2010,465
Storm@ twitter,Ankit Toshniwal; Siddarth Taneja; Amit Shukla; Karthik Ramasamy; Jignesh M Patel; Sanjeev Kulkarni; Jason Jackson; Krishna Gade; Maosong Fu; Jake Donham; Nikunj Bhagat; Sailesh Mittal; Dmitriy Ryaboy,Abstract This paper describes the use of Storm at Twitter. Storm is a real-time fault-tolerantand distributed stream data processing system. Storm is currently being used to run variouscritical computations in Twitter at scale; and in real-time. This paper describes thearchitecture of Storm and its methods for distributed scale-out and fault-tolerance. This paperalso describes how queries (aka. topologies) are executed in Storm; and presents someoperational stories based on running Storm at Twitter. We also present results from anempirical evaluation demonstrating the resilience of Storm in dealing with machine failures.Storm is under active development at Twitter and we also present some potential directionsfor future work.,Proceedings of the 2014 ACM SIGMOD international conference on Management of data,2014,446
Big data and its technical challenges,HV Jagadish; Johannes Gehrke; Alexandros Labrinidis; Yannis Papakonstantinou; Jignesh M Patel; Raghu Ramakrishnan; Cyrus Shahabi,The growth rate of the output of current NGS methods in terms of the raw sequence data producedby a single NGS machine is shown in Figure 1; along with the performance increase for the SPECintCPU benchmark. Clearly; the NGS sequence data growth far outstrips the performance gainsoffered by Moore's Law for single-threaded applications (here; SPECint). Note the sequencedata size in Figure 1 is the output of analyzing the raw images that are actually produced by theNGS instruments. The size of these raw image datasets themselves is so large (many TBs perlab per day) that it is impractical today to even consider storing them. Rather; these images areanalyzed on the fly to produce sequence data; which is then retained … Big Data has the potentialto revolutionize much more than just research. Google's work on Google File System andMapReduce; and subsequent open source work on systems like Hadoop; have led to …,Communications of the ACM,2014,409
Efficient aggregation for graph summarization,Yuanyuan Tian; Richard A Hankins; Jignesh M Patel,Abstract Graphs are widely used to model real world objects and their relationships; andlarge graph datasets are common in many application domains. To understand theunderlying characteristics of large graphs; graph summarization techniques are critical.However; existing graph summarization methods are mostly statistical (studying statisticssuch as degree distributions; hop-plots and clustering coefficients). These statisticalmethods are very useful; but the resolutions of the summaries are hard to control. In thispaper; we introduce two database-style operations to summarize graphs. Like the OLAP-style aggregation methods that allow users to drill-down or roll-up to control the resolution ofsummarization; our methods provide an analogous functionality for large graph datasets.The first operation; called SNAP; produces a summary graph by grouping nodes based …,Proceedings of the 2008 ACM SIGMOD international conference on Management of data,2008,375
Indexing large trajectory data sets with SETI,V Prasad Chakka; Adam C Everspaugh; Jignesh M Patel,Abstract With the rapid increase in the use of inexpensive; location-aware sensors in avariety of new applications; large amounts of time-sequenced location data will soon beaccumulated. Efficient indexing techniques for managing these large volumes of trajectorydata sets are urgently needed. The key requirements for a good trajectory indexingtechnique is that it must support both searches and inserts efficiently.,Ann Arbor,2003,291
Overview of SciDB: large scale array storage; processing and analysis,Paul G Brown,Abstract SciDB [4; 3] is a new open-source data management system intended primarily foruse in application domains that involve very large (petabyte) scale array data; for example;scientific applications such as astronomy; remote sensing and climate modeling; bio-scienceinformation management; risk management systems in financial applications; and theanalysis of web log data. In this talk we will describe our set of motivating examples and usethem to explain the features of SciDB. We then briefly give an overview of the project'inflight'; explaining our novel storage manager; array data model; query language; andextensibility frameworks.,Proceedings of the 2010 ACM SIGMOD International Conference on Management of data,2010,280
Tale: A tool for approximate large graph matching,Yuanyuan Tian; Jignesh M Patel,Large graph datasets are common in many emerging database applications; and mostnotably in large-scale scientific applications. To fully exploit the wealth of informationencoded in graphs; effective and efficient graph matching tools are critical. Due to the noisyand incomplete nature of real graph datasets; approximate; rather than exact; graphmatching is required. Furthermore; many modern applications need to query large graphs;each of which has hundreds to thousands of nodes and edges. This paper presents a noveltechnique for approximate matching of large graph queries. We propose a novel indexingmethod that incorporates graph structural information in a hybrid index structure. Thisindexing technique achieves high pruning power and the index size scales linearly with thedatabase size. In addition; we propose an innovative matching paradigm to query large …,Data Engineering; 2008. ICDE 2008. IEEE 24th International Conference on,2008,265
STRIPES: an efficient index for predicted trajectories,Jignesh M Patel; Yun Chen; V Prasad Chakka,Abstract Moving object databases are required to support queries on a large number ofcontinuously moving objects. A key requirement for indexing methods in this domain is toefficiently support both update and query operations. Previous work on indexing suchdatabases can be broadly divided into categories: indexing the past positions and indexingthe future predicted positions. In this paper we focus on an efficient indexing method forindexing the future positions of moving objects. In this paper we propose an indexingmethod; called STRIPES; which indexes predicted trajectories in a dual transformed space.Trajectories for objects in d-dimensional space become points in a higher-dimensional 2d-space. This dual transformed space is then indexed using a regular hierarchical griddecomposition indexing structure. STRIPES can evaluate a range of queries including …,Proceedings of the 2004 ACM SIGMOD international conference on Management of data,2004,244
Energy management for mapreduce clusters,Willis Lang; Jignesh M Patel,Abstract The area of cluster-level energy management has attracted significant researchattention over the past few years. One class of techniques to reduce the energy consumptionof clusters is to selectively power down nodes during periods of low utilization to increaseenergy efficiency. One can think of a number of ways of selectively powering down nodes;each with varying impact on the workload response time and overall energy consumption.Since the MapReduce framework is becoming" ubiquitous"; the focus of this paper is ondeveloping a framework for systematically considering various MapReduce node powerdown strategies; and their impact on the overall energy consumption and workloadresponse time. We closely examine two extreme techniques that can be accommodated inthis framework. The first is based on a recently proposed technique called" Covering Set" …,Proceedings of the VLDB Endowment,2010,230
Structural join order selection for XML query optimization,Yuqing Wu; Jignesh M Patel; HV Jagadish,Structural join operations are central to evaluating queries against XML data; and aretypically responsible for consuming a lion's share of the query processing time. Thus;structural join order selection is at the heart of query optimization in an XML database; justas (value-based) join order selection is central to relational query optimization. We introducefive algorithms for structural join order optimization for XML tree pattern matching andpresent an extensive experimental evaluation. Our experiments demonstrate that manyrelational rules of thumb are no longer appropriate: for instance; using dynamicprogramming style optimization is not efficient; limiting consideration to left-deep plansusually misses the best solution. Our experiments also show that a dynamic programmingoptimization with pruning (DPP) algorithm can find the optimal solution; with low cost …,Data Engineering; 2003. Proceedings. 19th International Conference on,2003,228
SAGA: a subgraph matching tool for biological graphs,Yuanyuan Tian; Richard C Mceachin; Carlos Santos; David J States; Jignesh M Patel,Abstract Motivation: With the rapid increase in the availability of biological graph datasets;there is a growing need for effective and efficient graph querying methods. Due to the noisyand incomplete characteristics of these datasets; exact graph matching methods havelimited use and approximate graph matching methods are required. Unfortunately; existinggraph matching methods are too restrictive as they only allow exact or near exact graphmatching. This paper presents a novel approximate graph matching technique called SAGA.This technique employs a flexible model for computing graph similarity; which allows fornode gaps; node mismatches and graph structural differences. SAGA employs an indexingtechnique that allows it to efficiently evaluate queries even against large graph datasets.Results: SAGA has been used to query biological pathways and literature datasets; which …,Bioinformatics,2006,205
Client-server paradise,David J DeWitt; Navin Kabra; Jun Luo; Jignesh M Patel; Jie-Bing Yu,Abstract This paper describes the design and implementation of Paradise; a databasesystem designed for handling GIS type of applications. The current version of Paradise; usesa client {server architecture and provides an extended {relational data model for modelingGIS applications. Paradise supports an extended version of SQL and provides a graphicaluser interface for querying and browsing the database. We also describe the results ofbenchmarking Paradise using the Sequoia 2000 storage benchmark.,VLDB,1994,194
Twitter heron: Stream processing at scale,Sanjeev Kulkarni; Nikunj Bhagat; Maosong Fu; Vikas Kedigehalli; Christopher Kellogg; Sailesh Mittal; Jignesh M Patel; Karthik Ramasamy; Siddarth Taneja,Abstract Storm has long served as the main platform for real-time analytics at Twitter.However; as the scale of data being processed in real-time at Twitter has increased; alongwith an increase in the diversity and the number of use cases; many limitations of Stormhave become apparent. We need a system that scales better; has better debug-ability; hasbetter performance; and is easier to manage--all while working in a shared clusterinfrastructure. We considered various alternatives to meet these needs; and in the endconcluded that we needed to build a new real-time stream data processing system. Thispaper presents the design and implementation of this new system; called Heron. Heron isnow the de facto stream data processing engine inside Twitter; and in this paper we alsoshare our experiences from running Heron in production. In this paper; we also provide …,Proceedings of the 2015 ACM SIGMOD International Conference on Management of Data,2015,190
Data prefetching by dependence graph precomputation,Murali Annavaram; Jignesh M Patel; Edward S Davidson,Data cache misses reduce the performance of wide-issue processors by stalling the datasupply to the processor. Prefetching data by predicting the miss address is one way totolerate the cache miss latencies. But current applications with irregular access patternsmake it difficult to accurately predict the address sufficiently early to mask large cache misslatencies. This paper explores an alternative to predicting prefetch addresses; namelyprecomputing them. The Dependence Graph Precomputation scheme (DGP) introduced inthis paper is a novel approach for dynamically identifying and precomputing the instructionsthat determine the addresses accessed by those load/store instructions marked as beingresponsible for most data cache misses. DGP's dependence graph generator efficientlygenerates the required dependence graphs at run time. A separate precomputation …,Computer Architecture; 2001. Proceedings. 28th Annual International Symposium on,2001,182
Design and evaluation of main memory hash join algorithms for multi-core CPUs,Spyros Blanas; Yinan Li; Jignesh M Patel,Abstract The focus of this paper is on investigating efficient hash join algorithms for modernmulti-core processors in main memory environments. This paper dissects each internalphase of a typical hash join algorithm and considers different alternatives for implementingeach phase; producing a family of hash join algorithms. Then; we implement these mainmemory algorithms on two radically different modern multi-processor systems; and carefullyexamine the factors that impact the performance of each method. Our analysis reveals someinteresting results--a very simple hash join algorithm is very competitive to the other morecomplex methods. This simple join algorithm builds a shared hash table and does notpartition the input relations. Its simplicity implies that it requires fewer parameter settings;thereby making it far easier for query optimizers and execution engines to use it in …,Proceedings of the 2011 ACM SIGMOD International Conference on Management of data,2011,176
Estimating answer sizes for XML queries,Yuqing Wu; Jignesh M Patel; HV Jagadish,Abstract Estimating the sizes of query results; and intermediate results; is crucial to manyaspects of query processing. In particular; it is necessary for effective query optimization.Even at the user level; predictions of the total result size can be valuable in “next-step”decisions; such as query refinement. This paper proposes a technique to obtain query resultsize estimates effectively in an XML database. Queries in XML frequently specify structuralpatterns; requiring specific relationships between selected elements. Whereas traditionaltechniques can estimate the number of nodes (XML elements) that will satisfy a node-specific predicate in the query pattern; such estimates cannot easily be combined to provideestimates for the entire query pattern; since element occurrences are expected to have highcorrelation. We propose a solution based on a novel histogram encoding of element …,International Conference on Extending Database Technology,2002,170
An efficient and accurate method for evaluating time series similarity,Michael D Morse; Jignesh M Patel,Abstract A variety of techniques currently exist for measuring the similarity between timeseries datasets. Of these techniques; the methods whose matching criteria is bounded by aspecified ε threshold value; such as the LCSS and the EDR techniques; have been shown tobe robust in the presence of noise; time shifts; and data scaling. Our work proposes a newalgorithm; called the Fast Time Series Evaluation (FTSE) method; which can be used toevaluate such threshold value techniques; including LCSS and EDR. Using FTSE; we showthat these techniques can be evaluated faster than using either traditional dynamicprogramming or even warp-restricting methods such as the Sakoe-Chiba band and theItakura Parallelogram. We also show that FTSE can be used in a framework that canevaluate a richer range of ε threshold-based scoring techniques; of which EDR and LCSS …,Proceedings of the 2007 ACM SIGMOD international conference on Management of data,2007,168
Method and apparatus for parallel execution of SQL-from within user defined functions,*,A method; apparatus; and an article of manufacture for parallel execution of SQL operationsfrom within user defined functions. One or more embodiments of the invention provide theuser defined function (UDF) with a C++ class (hereinafter referred to as “dispatcher”) thatcan take an SQL query and start parallel execution of the query. The query is optimized andparallelized. The dispatcher executes the query; sets up the communication links betweenthe various operators in the query; and ensures that all the results are sent back to the data-server that originated the query request. Further; the dispatcher merges the results of theparallel execution and produces a single stream of tuples that is fed to the calling UDF. Toprovide the single stream to the calling UDF; one or more embodiments of the inventionutilize a class that provides the UDF with a simple and easy-to-use interface to access the …,*,2003,165
High-performance concurrency control mechanisms for main-memory databases,Per-Åke Larson; Spyros Blanas; Cristian Diaconu; Craig Freedman; Jignesh M Patel; Mike Zwilling,Abstract A database system optimized for in-memory storage can support much highertransaction rates than current systems. However; standard concurrency control methodsused today do not scale to the high transaction rates achievable by such systems. In thispaper we introduce two efficient concurrency control methods specifically designed for main-memory databases. Both use multiversioning to isolate read-only transactions from updatesbut differ in how atomicity is ensured: one is optimistic and one is pessimistic. To avoidexpensive context switching; transactions never block during normal processing but theymay have to wait before commit to ensure correct serialization ordering. We alsoimplemented a main-memory optimized version of single-version locking. Experimentalresults show that while single-version locking works well when transactions are short and …,Proceedings of the VLDB Endowment,2011,159
Efficient skyline computation over low-cardinality domains,Michael Morse; Jignesh M Patel; Hosagrahar V Jagadish,Abstract Current skyline evaluation techniques follow a common paradigm that eliminatesdata elements from skyline consideration by finding other elements in the dataset thatdominate them. The performance of such techniques is heavily influenced by the underlyingdata distribution (ie whether the dataset attributes are correlated; independent; or anti-correlated). In this paper; we propose the Lattice Skyline Algorithm (LS) that is built around anew paradigm for skyline evaluation on datasets with attributes that are drawn from low-cardinality domains. LS continues to apply even if one attribute has high cardinality. Manyskyline applications naturally have such data characteristics; and previous skyline methodshave not exploited this property. We show that for typical dimensionalities; the complexity ofLS is linear in the number of input tuples. Furthermore; we show that the performance of …,Proceedings of the 33rd international conference on Very large data bases,2007,155
A demonstration of SciDB: a science-oriented DBMS,Philippe Cudré-Mauroux; Hideaki Kimura; K-T Lim; Jennie Rogers; Roman Simakov; Emad Soroush; Pavel Velikhov; Daniel L Wang; Magdalena Balazinska; Jacek Becla; D DeWitt; Bobbi Heath; David Maier; Samuel Madden; J Patel; Michael Stonebraker; S Zdonik,Abstract In CIDR 2009; we presented a collection of requirements for SciDB; a DBMS thatwould meet the needs of scientific users. These included a nested-array data model; science-specific operations such as regrid; and support for uncertainty; lineage; and named versions.In this paper; we present an overview of SciDB's key features and outline a demonstration ofthe first version of SciDB on data and operations from one of our lighthouse users; the LargeSynoptic Survey Telescope (LSST).,Proceedings of the VLDB Endowment,2009,153
Column-oriented storage techniques for MapReduce,Avrilia Floratou; Jignesh M Patel; Eugene J Shekita; Sandeep Tata,Abstract Users of MapReduce often run into performance problems when they scale up theirworkloads. Many of the problems they encounter can be overcome by applying techniqueslearned from over three decades of research on parallel DBMSs. However; translating thesetechniques to a Map-Reduce implementation such as Hadoop presents unique challengesthat can lead to new design choices. This paper describes how column-oriented storagetechniques can be incorporated in Hadoop in a way that preserves its popular programmingAPIs. We show that simply using binary storage formats in Hadoop can provide a 3xperformance boost over the naive use of text files. We then introduce a column-orientedstorage format that is compatible with the replication and scheduling constraints of Hadoopand show that it can speed up MapReduce jobs on real workloads by an order of …,Proceedings of the VLDB Endowment,2011,152
Building a scaleable geo-spatial DBMS: technology; implementation; and evaluation,Jignesh Patel; JieBing Yu; Navin Kabra; Kristin Tufte; Biswadeep Nag; Josef Burger; Nancy Hall; Karthikeyan Ramasamy; Roger Lueder; Curt Ellmann; Jim Kupsch; Shelly Guo; Johan Larson; David De Witt; Jeffrey Naughton,Abstract This paper presents a number of new techniques for parallelizing geo-spatialdatabase systems and discusses their implementation in the Paradise object-relationaldatabase system. The effectiveness of these techniques is demonstrated using a variety ofcomplex geo-spatial queries over a 120 GB global geo-spatial data set.,ACM SIGMOD Record,1997,145
Method and apparatus for parallel execution of SQL from stored procedures,*,A method; apparatus; and an article of manufacture for parallel execution of SQL operationsfrom stored procedures. One or more embodiments of the invention provide the storedprocedure (stored procedure) with a C++ class (hereinafter referred to as “dispatcher”) thatcan take an SQL query and start parallel execution of the query. The query is optimized andparallelized. The dispatcher executes the query; sets up the communication links betweenthe various operators in the query; and ensures that all the results are sent back to the data-server that originated the query request. Further; the dispatcher merges the results of theparallel execution and produces a single stream of tuples that is fed to the calling storedprocedure. To provide the single stream to the calling stored procedure; one or moreembodiments of the invention utilize a class that provides the stored procedure with a …,*,2003,141
Efficient continuous skyline computation,Michael Morse; Jignesh M Patel; William I Grosky,Abstract In a number of emerging streaming applications; the data values that are producedhave an associated time interval for which they are valid. A useful computation over suchstreaming data is to produce a continuous and valid skyline summary. Previous work onskyline algorithms have only focused on evaluating skylines over static data sets; and thereare no known algorithms for skyline computation in the continuous setting. In this paper; weintroduce the continuous time-interval skyline operator; which continuously computes thecurrent skyline over a data stream. We present a new algorithm called LookOut forevaluating such queries efficiently; and empirically demonstrate the scalability of thisalgorithm. In addition; we also examine the effect of the underlying spatial index structurewhen evaluating skylines. Whereas previous work on skyline computations have only …,Information Sciences,2007,135
-OASIS: An Online and Accurate Technique for Local-alignment Searches on Biological Sequences,Colin Meek; Jignesh M Patel; Shruti Kasetty,This chapter introduces a new algorithm called online and accurate search technique forInferring local-alignments on sequences (OASIS); which improves upon the performance ofthe existing state-of-the-art for accurate local sequence alignment. The existing accuratelocal-alignment algorithm; the Smith-Waterman (SW) algorithm; is rarely used since it is verycomputationally expensive. The chapter shows that the OASIS algorithm is often an order-of-magnitude or faster than the SW algorithm when the query is a short sequence. Such shortsequences are often used in querying biological sequence data sets; and OASIS is veryeffective in these cases. OASIS; also has the property of returning result tuples in decreasingorder of the matching scores. Consequently; OASIS can also be used in an online mode;where the scientist may want to abort the query after seeing the top few results. The …,*,2003,127
Discovery-driven graph summarization,Ning Zhang; Yuanyuan Tian; Jignesh M Patel,Large graph datasets are ubiquitous in many domains; including social networking andbiology. Graph summarization techniques are crucial in such domains as they can assist inuncovering useful insights about the patterns hidden in the underlying data. One importanttype of graph summarization is to produce small and informative summaries based on user-selected node attributes and relationships; and allowing users to interactively drill-down orroll-up to navigate through summaries with different resolutions. However; two keycomponents are missing from the previous work in this area that limit the use of this methodin practice. First; the previous work only deals with categorical node attributes.Consequently; users have to manually bucketize numerical attributes based on domainknowledge; which is not always possible. Moreover; users often have to manually iterate …,Data Engineering (ICDE); 2010 IEEE 26th International Conference on,2010,119
-Data Morphing: An Adaptive; Cache-Conscious Storage Technique,Richard A Hankins; Jignesh M Patel,This chapter proposes a flexible data storage technique called Data Morphing. Using DataMorphing; a cache-efficient attribute layout; called a partition; is first determined through ananalysis of the query workload. This partition is then used as a template for storing data in acache efficient way. This chapter presents two algorithms for computing partitions; andpresents a versatile storage model that accommodates the dynamic reorganization of theattributes in a file. It experimentally demonstrates that the Data Morphing technique providesa significant performance improvement over both the traditional N-ary storage model and thePAX model. The number of processor cache misses has a critical impact on the performanceof database management systems (DBMSs) running on servers with large main-memoryconfigurations. In turn; the cache utilization of database systems is highly dependent on …,*,2003,111
Practical suffix tree construction,Sandeep Tata; Richard A Hankins; Jignesh M Patel,Abstract Large string datasets are common in a number of emerging text and biologicaldatabase applications. Common queries over such datasets include both exact andapproximate string matches. These queries can be evaluated very efficiently by using asuffix tree index on the string dataset. Although suffix trees can be constructed quickly inmemory for small input datasets; constructing persistent trees for large datasets has beenchallenging. In this paper; we explore suffix tree construction algorithms over a widespectrum of data sources and sizes. First; we show that on modern processors; a cache-efficient algorithm with O (n 2) complexity outperforms the popular O (n) Ukkonen algorithm;even for in-memory construction. For larger datasets; the disk I/O requirement quicklybecomes the bottleneck in each algorithm's performance. To address this problem; we …,Proceedings of the Thirtieth international conference on Very large data bases-Volume 30,2004,110
Estimating the selectivity of tf-idf based cosine similarity predicates,Sandeep Tata; Jignesh M Patel,Abstract An increasing number of database applications today require sophisticatedapproximate string matching capabilities. Examples of such application areas include dataintegration and data cleaning. Cosine similarity has proven to be a robust metric for scoringthe similarity between two strings; and it is increasingly being used in complex queries. Animmediate challenge faced by current database optimizers is to find accurate and efficientmethods for estimating the selectivity of cosine similarity predicates. To the best of ourknowledge; there are no known methods for this problem. In this paper; we present the firstapproach for estimating the selectivity of tf. idf based cosine similarity predicates. Weevaluate our approach on three different real datasets and show that our method oftenproduces estimates that are within 40% of the actual selectivity.,ACM Sigmod Record,2007,109
Challenges and Opportunities with big data 2011-1,Divyakant Agrawal; Philip Bernstein; Elisa Bertino; Susan Davidson; Umeshwas Dayal; Michael Franklin; Johannes Gehrke; Laura Haas; Alon Halevy; Jiawei Han; HV Jagadish; Alexandros Labrinidis; Sam Madden; Yannis Papakonstantinou; Jignesh Patel; Raghu Ramakrishnan; Kenneth Ross; Cyrus Shahabi; Dan Suciu; Shiv Vaithyanathan; Jennifer Widom,Abstract The promise of data-driven decision-making is now being recognized broadly; andthere is growing enthusiasm for the notion of``Big Data.''While the promise of Big Data is real--for example; it is estimated that Google alone contributed 54 billion dollars to the USeconomy in 2009--there is currently a wide gap between its potential and its realization.,*,2011,107
Practical methods for constructing suffix trees,Yuanyuan Tian; Sandeep Tata; Richard A Hankins; Jignesh M Patel,Abstract Sequence datasets are ubiquitous in modern life-science applications; andquerying sequences is a common and critical operation in many of these applications. Thesuffix tree is a versatile data structure that can be used to evaluate a wide variety of querieson sequence datasets; including evaluating exact and approximate string matches; andfinding repeat patterns. However; methods for constructing suffix trees are often very time-consuming; especially for suffix trees that are large and do not fit in the available mainmemory. Even when the suffix tree fits in memory; it turns out that the processor cachebehavior of theoretically optimal suffix tree construction methods is poor; resulting in poorperformance. Currently; there are a large number of algorithms for constructing suffix trees;but the practical tradeoffs in using these algorithms for different scenarios are not well …,The VLDB Journal,2005,105
Can the elephants handle the nosql onslaught?,Avrilia Floratou; Nikhil Teletia; David J DeWitt; Jignesh M Patel; Donghui Zhang,Abstract In this new era of" big data"; traditional DBMSs are under attack from two sides. Atone end of the spectrum; the use of document store NoSQL systems (eg MongoDB)threatens to move modern Web 2.0 applications away from traditional RDBMSs. At the otherend of the spectrum; big data DSS analytics that used to be the domain of parallel RDBMSsis now under attack by another class of NoSQL data analytics systems; such as Hive onHadoop. So; are the traditional RDBMSs; aka" big elephants"; doomed as they arechallenged from both ends of this" big data" spectrum? In this paper; we compare onerepresentative NoSQL system from each end of this spectrum with SQL Server; and analyzethe performance and scalability aspects of each of these approaches (NoSQL vs. SQL) ontwo workloads (decision support analysis and interactive data-serving) that represent the …,Proceedings of the VLDB Endowment,2012,99
Michigan molecular interactions r2: from interacting proteins to pathways,V Glenn Tarcea; Terry Weymouth; Alex Ade; Aaron Bookvich; Jing Gao; Vasudeva Mahavisno; Zach Wright; Adriane Chapman; Magesh Jayapandian; Arzucan Özgür; Yuanyuan Tian; Jim Cavalcoli; Barbara Mirel; Jignesh Patel; Dragomir Radev; Brian Athey; David States; HV Jagadish,Abstract Molecular interaction data exists in a number of repositories; each with its own dataformat; molecule identifier and information coverage. Michigan molecular interactions (MiMI)assists scientists searching through this profusion of molecular interaction data. The originalrelease of MiMI gathered data from well-known protein interaction databases; and deepmerged this information while keeping track of provenance. Based on the feedback receivedfrom users; MiMI has been completely redesigned. This article describes the resulting MiMIRelease 2 (MiMIr2). New functionality includes extension from proteins to genes and topathways; identification of highlighted sentences in source publications; seamless two-waylinkage with Cytoscape; query facilities based on MeSH/GO terms and other concepts;approximate graph matching to find relevant pathways; support for querying in bulk; and a …,Nucleic acids research,2008,99
Sedna: A BPEL-based environment for visual scientific workflow modeling,Bruno Wassermann; Wolfgang Emmerich; Ben Butchart; Nick Cameron; Liang Chen; Jignesh Patel,Abstract Scientific Grid computing environments are increasingly adopting the Open GridServices Architecture (OGSA); which is a service-oriented architecture for Grids. With theproliferation of OGSA; Grids effectively consist of a collection of Grid services; Web serviceswith certain extensions providing additional support for state and life cycle management.Hence; the need arises for some means of composing these basic services into largerworkflows in order to; for example; express a scientific experiment.,*,2007,99
The Michigan benchmark: towards XML query performance diagnostics,Kanda Runapongsa; Jignesh M Patel; HV Jagadish; Yun Chen; Shurug Al-Khalifa,Abstract We propose a micro-benchmark for XML data management to aid engineers indesigning improved XML processing engines. This benchmark is inherently different fromapplication-level benchmarks; which are designed to help users choose between alternativeproducts. We primarily attempt to capture the rich variety of data structures and distributionspossible in XML; and to isolate their effects; without imitating any particular application. Thebenchmark specifies a single data set against which carefully specified queries can be usedto evaluate system performance for XML data with various characteristics. We have used thebenchmark to analyze the performance of three database systems: two native XML DBMSs;and a commercial ORDBMS. The benchmark reveals key strengths and weaknesses ofthese systems. We find that commercial relational techniques are effective for XML query …,Information Systems,2006,98
Towards eco-friendly database management systems,Willis Lang; Jignesh Patel,Abstract: Database management systems (DBMSs) have largely ignored the task ofmanaging the energy consumed during query processing. Both economical andenvironmental factors now require that DBMSs pay close attention to energy consumption. Inthis paper we approach this issue by considering energy consumption as a first-classperformance goal for query processing in a DBMS. We present two concrete techniques thatcan be used by a DBMS to directly manage the energy consumption. Both techniques tradeenergy consumption for performance. The first technique; called PVC; leverages the abilityof modern processors to execute at lower processor voltage and frequency. The secondtechnique; called QED; uses query aggregation to leverage common components of queriesin a workload. Using experiments run on a commercial DBMS and MySQL; we show that …,arXiv preprint arXiv:0909.1767,2009,92
Efficient evaluation of all-nearest-neighbor queries,Yun Chen; Jignesh M Patel,The All Nearest Neighbor (ANN) operation is a commonly used primitive for analyzing largemulti-dimensional datasets. Since computing ANN is very expensive; in previous works R*-tree based methods have been proposed to speed up this computation. These traditionalindex-based methods use a pruning metric called MAXMAXDIST; which allows thealgorithms to prune out nodes in the index that need not be traversed during the ANNcomputation. In this paper we introduce a new pruning metric called the NXNDIST; andshow that this metric is far more effective than the traditional MAXMAXDIST metric. In thispaper; we also challenge the common practice of using R*-tree index for speeding up theANN computation. We propose an enhanced bucket quadtree index structure; called theMBRQT; and using extensive experimental evaluation show that the MBRQT index can …,Data Engineering; 2007. ICDE 2007. IEEE 23rd International Conference on,2007,91
Fast regular expression matching using small TCAMs for network intrusion detection and prevention systems,Chad R Meiners; Jignesh Patel; Eric Norige; Eric Torng; Alex X Liu,Abstract Regular expression (RE) matching is a core component of deep packet inspectionin modern networking and security devices. In this paper; we propose the first hardware-based RE matching approach that uses Ternary Content Addressable Memories (TCAMs);which are off-the-shelf chips and have been widely deployed in modern networking devicesfor packet classification. We propose three novel techniques to reduce TCAM space andimprove RE matching speed: transition sharing; table consolidation; and variable striding.We tested our techniques on 8 real-world RE sets; and our results show that small TCAMscan be used to store large DFAs and achieve potentially high RE matching throughtput. Forspace; we were able to store each of the corresponding 8 DFAs with as many as 25;000states in a 0.59 Mb TCAM chip where the number of TCAM bits required per DFA state …,Proceedings of the 19th USENIX conference on Security,2010,90
Towards multi-tenant performance SLOs,Willis Lang; Srinath Shankar; Jignesh M Patel; Ajay Kalhan,As traditional and mission-critical relational database workloads migrate to the cloud in theform of Database-as-a-Service (DaaS); there is an increasing motivation to provideperformance goals in Service Level Objectives (SLOs). Providing such performance goals ischallenging for DaaS providers as they must balance the performance that they can deliverto tenants and the data center's operating costs. In general; aggressively aggregatingtenants on each server reduces the operating costs but degrades performance for thetenants; and vice versa. In this paper; we present a framework that takes as input the tenantworkloads; their performance SLOs; and the server hardware that is available to the DaaSprovider; and outputs a cost-effective recipe that specifies how much hardware to provisionand how to schedule the tenants on each hardware resource. We evaluate our method …,IEEE Transactions on Knowledge and Data Engineering,2014,83
Set containment joins: The good; the bad and the ugly,Karthikeyan Ramasamy; Jignesh M Patel; Jeffrey F Naughton; Raghav Kaushik,Abstract Efficient support for set-valued attributes is likely to grow in importance as object-relational database systems; which either support set-valued attributes or propose to do sosoon; begin to replace their purely relational predecessors. One of the most interesting andchallenging operations on set-valued attributes is the set containment join; because itprovides a concise and elegant way to express otherwise complex queries. Unfortunately;evaluating these joins is difficult; and naive approaches lead to algorithms that are veryexpensive. In this paper; we develop a new partition based algorithm for set containmentjoins: the Partitioning Set Join Algorithm (PSJ); which uses a replicating multilevelpartitioning scheme based on a combination of set elements and signatures. We present adetailed performance study with a complete implementation in the Paradise object …,VLDB,2000,82
Turbocharging DBMS buffer pool using SSDs,Jaeyoung Do; Donghui Zhang; Jignesh M Patel; David J DeWitt; Jeffrey F Naughton; Alan Halverson,Abstract Flash solid-state drives (SSDs) are changing the I/O landscape; which has largelybeen dominated by traditional hard disk drives (HDDs) for the last 50 years. In this paper wepropose and systematically explore designs for using an SSD to improve the performance ofa DBMS buffer manager. We propose three alternatives that differ mainly in the way that theydeal with the dirty pages evicted from the buffer pool. We implemented these alternatives; aswell another recently proposed algorithm for this task (TAC); in SQL Server; and ranexperiments using a variety of benchmarks (TPC-C; E and H) at multiple scale factors. Ourempirical evaluation shows significant performance improvements of our methods over thedefault HDD configuration (up to 9.4 X); and up to a 6.8 X speedup over TAC.,Proceedings of the 2011 ACM SIGMOD International Conference on Management of data,2011,78
Wimpy node clusters: What about non-wimpy workloads?,Willis Lang; Jignesh M Patel; Srinath Shankar,Abstract The high cost associated with powering servers has introduced new challenges inimproving the energy efficiency of clusters running data processing jobs. Traditional high-performance servers are largely energy inefficient due to various factors such as the over-provisioning of resources. The increasing trend to replace traditional high-performanceserver nodes with low-power low-end nodes in clusters has recently been touted as asolution to the cluster energy problem. However; the key tacit assumption that drives such asolution is that the proportional scale-out of such low-power cluster nodes results in constantscaleup in performance. This paper studies the validity of such an assumption usingmeasured price and performance results from a low-power Atom-based node and atraditional Xeon-based server and a number of published parallel scaleup results. Our …,Proceedings of the Sixth International Workshop on Data Management on New Hardware,2010,77
Effect of node size on the performance of cache-conscious B+-trees,Richard A Hankins; Jignesh M Patel,Abstract In main-memory databases; the number of processor cache misses has a criticalimpact on the performance of the system. Cache-conscious indices are designed to improveperformance by reducing the number of processor cache misses that are incurred during asearch operation. Conventional wisdom suggests that the index's node size should be equalto the cache line size in order to minimize the number of cache misses and improveperformance. As we show in this paper; this design choice ignores additional effects; suchas the number of instructions executed and the number of TLB misses; which play asignificant role in determining the overall performance. To capture the impact of node sizeon the performance of a cache-conscious B+ tree (CSB+-tree); we first develop an analyticalmodel based on the fundamental components of the search process. This model is then …,ACM SIGMETRICS Performance Evaluation Review,2003,76
Storing and querying XML data in object-relational DBMSs,Kanda Runapongsa; Jignesh M Patel,Abstract As the popularity of eXtensible Markup Language (XML) continues to increase at anastonishing pace; data management systems for storing and querying large repositories ofXML data are urgently needed. In this paper; we investigate an Object-Relational DBMS(ORDBMS) for storing and querying XML data. We present an algorithm; called XORator; formapping XML documents to tables in an ORDBMS. An important part of this mapping isassigning a fragment of an XML document to a new XML data type. We demonstrate thatusing the XORator algorithm; an ORDBMS is usually more efficient than a Relational DBMS(RDBMS). Based on an actual implementation in DB2 V. 7.2; we compare the performanceof the XORator algorithm with a well-known algorithm for mapping XML data to an RDBMS.Our experiments show that the XORator algorithm requires less storage space; has much …,International Conference on Extending Database Technology,2002,73
Query processing on smart SSDs: opportunities and challenges,Jaeyoung Do; Yang-Suk Kee; Jignesh M Patel; Chanik Park; Kwanghyun Park; David J DeWitt,Abstract Data storage devices are getting" smarter." Smart Flash storage devices (aka"Smart SSD") are on the horizon and will package CPU processing and DRAM storage insidea Smart SSD; and make that available to run user programs inside a Smart SSD. The focusof this paper is on exploring the opportunities and challenges associated with exploiting thisfunctionality of Smart SSDs for relational analytic query processing. We have implementedan initial prototype of Microsoft SQL Server running on a Samsung Smart SSD. Our resultsdemonstrate that significant performance and energy gains can be achieved by pushingselected query processing components inside the Smart SSDs. We also identify variouschanges that SSD device manufacturers can make to increase the benefits of using SmartSSDs for data processing applications; and also suggest possible research opportunities …,Proceedings of the 2013 ACM SIGMOD International Conference on Management of Data,2013,69
Efficient and accurate discovery of patterns in sequence data sets,Avrilia Floratou; Sandeep Tata; Jignesh M Patel,Existing sequence mining algorithms mostly focus on mining for subsequences. However; alarge class of applications; such as biological DNA and protein motif mining; require efficientmining of “approximate” patterns that are contiguous. The few existing algorithms that can beapplied to find such contiguous approximate pattern mining have drawbacks like poorscalability; lack of guarantees in finding the pattern; and difficulty in adapting to otherapplications. In this paper; we present a new algorithm called FLexible and Accurate MotifDEtector (FLAME). FLAME is a flexible suffix-tree-based algorithm that can be used to findfrequent patterns with a variety of definitions of motif (pattern) models. It is also accurate; as italways finds the pattern if it exists. Using both real and synthetic data sets; we demonstratethat FLAME is fast; scalable; and outperforms existing algorithms on a variety of …,IEEE Transactions on Knowledge and Data Engineering,2011,69
Identification of cross-species shared transcriptional networks of diabetic nephropathy in human and mouse glomeruli,Jeffrey B Hodgin; Viji Nair; Hongyu Zhang; Ann Randolph; Raymond C Harris; Robert G Nelson; E Jennifer Weil; James D Cavalcoli; Jignesh M Patel; Frank C Brosius; Matthias Kretzler,Murine models are valuable instruments in defining the pathogenesis of diabeticnephropathy (DN); but they only partially recapitulate disease manifestations of human DN;limiting their utility. To define the molecular similarities and differences between human andmurine DN; we performed a cross-species comparison of glomerular transcriptionalnetworks. Glomerular gene expression was profiled in patients with early type 2 DN and inthree mouse models (streptozotocin DBA/2; C57BLKS db/db; and eNOS-deficient C57BLKSdb/db mice). Species-specific transcriptional networks were generated and compared with anovel network-matching algorithm. Three shared human–mouse cross-species glomerulartranscriptional networks containing 143 (Human-DBA STZ); 97 (Human-BKS db/db); and162 (Human-BKS eNOS−/− db/db) gene nodes were generated. Shared nodes across all …,Diabetes,2013,66
On energy management; load balancing and replication,Willis Lang; Jignesh M Patel; Jeffrey F Naughton,Abstract In this paper we investigate some opportunities and challenges that arise in energy-aware computing in a cluster of servers running data-intensive workloads. We leverage theinsight that servers in a cluster are often underutilized; which makes it attractive to considerpowering down some servers and redistributing their load to others. Of course; poweringdown servers naively will render data stored only on powered down servers inaccessible.While data replication can be exploited to power down servers without losing access to data;unfortunately; care must be taken in the design of the replication and server power downschemes to avoid creating load imbalances on the remaining" live" servers. Accordingly; inthis paper we study the interaction between energy management; load balancing; andreplication strategies for data-intensive cluster computing. In particular; we show that …,ACM SIGMOD Record,2010,61
BitWeaving: fast scans for main memory data processing,Yinan Li; Jignesh M Patel,Abstract This paper focuses on running scans in a main memory data processing system at"bare metal" speed. Essentially; this means that the system must aim to process data at ornear the speed of the processor (the fastest component in most system configurations).Scans are common in main memory data processing environments; and with the state-of-the-art techniques it still takes many cycles per input tuple to apply simple predicates on a singlecolumn of a table. In this paper; we propose a technique called BitWeaving that exploits theparallelism available at the bit level in modern processors. BitWeaving operates on multiplebits of data in a single cycle; processing bits from different columns in each cycle. Thus; bitsfrom a batch of tuples are processed in each cycle; allowing BitWeaving to drop the cyclesper column to below one in some case. BitWeaving comes in two flavors: BitWeaving/V …,Proceedings of the 2013 ACM SIGMOD International Conference on Management of Data,2013,60
Location tracking optimizations,*,Location based services are services that require knowledge of and usually provide featuresrelating to the location of something. The objects of interest may be alive or inanimate. Forexample; location based services may be provided in relation to a vehicle; a nonmoving location(eg when a person moves into that location); a person such as a teenager or elder; a pet; or avaluable farm animal. A fleet of trucks may be tracked and nearby features of interest to theirdrivers; such as the near presence of a refueling station; may be presented to a driver. Anotherexample is informing a person entering an airport that a shop within the airport has a sale. Thissecond example not only illustrates a location based service but the information transferred alsohas a time component as it may only be sent when a sale is occurring and at a time when thestore is open. Some location based services might be presented to anyone at the correct …,*,2012,58
Wham: a high-throughput sequence alignment method,Yinan Li; Jignesh M Patel; Allison Terrell,Abstract Over the last decade; the cost of producing genomic sequences has droppeddramatically due to the current so-called next-generation sequencing methods. However;these next-generation sequencing methods are critically dependent on fast andsophisticated data processing methods for aligning a set of query sequences to a referencegenome using rich string matching models. The focus of this work is on the design;development and evaluation of a data processing system for this crucial “short readalignment” problem. Our system; called WHAM; employs hash-based indexing methods andbitwise operations for sequence alignments. It allows rich match models and it is significantlyfaster than the existing state-of-the-art methods. In addition; its relative speedup over theexisting method is poised to increase in the future in which read sequence lengths will …,ACM Transactions on Database Systems (TODS),2012,53
Call graph prefetching for database applications,Murali Annavaram; Jignesh M Patel; Edward S Davidson,Abstract With the continuing technological trend of ever cheaper and larger memory; mostdata sets in database servers will soon be able to reside in main memory. In thisconfiguration; the performance bottleneck is likely to be the gap between the processingspeed of the CPU and the memory access latency. Previous work has shown that databaseapplications have large instruction and data footprints and hence do not use processorcaches effectively. In this paper; we propose Call Graph Prefetching (CGP); an N instructionprefetching technique that analyzes the call graph of a database system and prefetchesinstructions from the function that is deemed likely to be called next. CGP capitalizes on thehighly predictable function call sequences that are typical of database systems. CGP can beimplemented either in software or in hardware. The software-based CGP (CGP_S) uses …,ACM Transactions on Computer Systems (TOCS),2003,52
DNA damage enhancement from gold nanoparticles for clinical MV photon beams,Ross I Berbeco; Houari Korideck; Wilfred Ngwa; Rajiv Kumar; Janki Patel; Srinivas Sridhar; Sarah Johnson; Brendan D Price; Alec Kimmelman; G Mike Makrigiorgos,In this study; we quantify the relative damage enhancement due to the presence of goldnanoparticles (GNP) in vitro in a clinical 6 MV beam for various delivery parameters anddepths. It is expected that depths and delivery modes that produce a larger proportions oflow-energy photons will have a larger effect on the cell samples containing GNP. HeLa cellswith and without 50 nm GNP were irradiated at depths of 1.5; 5; 10; 15 and 20 cm.Conventional beams with square aperture sizes 5; 10 and 15 cm at isocenter; and flatteningfilter free (FFF) beams were used. Relative DNA damage enhancement with GNP wasevaluated by γ-H2AX staining. Statistically significant increases in DNA damage with GNP;compared to the absence of GNP; were observed for all depths and delivery modes.Relative to the shallowest depth; damage enhancement was observed to increase as a …,Radiation research,2012,48
Rethinking query processing for energy efficiency: Slowing down to win the race.,Willis Lang; Ramakrishnan Kandhan; Jignesh M Patel,Abstract The biggest change in the TPC benchmarks in over two decades is now wellunderway–namely the addition of an energy efficiency metric along with traditionalperformance metrics. This change is fueled by the growing; real; and urgent demand forenergy-efficient database processing. Database query processing engines must nowconsider becoming energy-aware; else they risk missing many opportunities for significantenergy savings. While other recent work has focused on solely optimizing for energyefficiency; we recognize that such methods are only practical if they also considerperformance requirements specified in SLAs. The focus of this paper is on the design andevaluation of a general framework for query optimization that considers both performanceconstraints and energy consumption as first-class optimization criteria. Our method …,IEEE Data Eng. Bull.,2011,48
Clone join and shadow join: two parallel spatial join algorithms,Jignesh M Patel; David J DeWitt,Abstract Spatial applications frequently need to join two data sets based on some spatialrelationship between objects in the two data sets. This operation; called a spatial join; is anexpensive operation and in the past many algorithms have been proposed for evaluating thespatial join operation on a single processor system. However; the use of parallelism forhandling queries involving large volumes of spatial data has received little attention. In thispaper; we explore the use of parallelism for evaluating the spatial join operation. We firstpropose two strategies for storing spatial data in a parallel database system. We propose anumber of spatial join algorithms based on these declustering strategies. Two algorithms areidentified as the key algorithms in this design space. We analyze these two algorithms bothanalytically and experimentally. The experimental evaluation uses real data sets and is …,Proceedings of the 8th ACM international symposium on Advances in geographic information systems,2000,48
Learning generalized linear models over normalized data,Arun Kumar; Jeffrey Naughton; Jignesh M Patel,Abstract Enterprise data analytics is a booming area in the data management industry. Manycompanies are racing to develop toolkits that closely integrate statistical and machinelearning techniques with data management systems. Almost all such toolkits assume that theinput to a learning algorithm is a single table. However; most relational datasets are notstored as single tables due to normalization. Thus; analysts often perform key-foreign keyjoins before learning on the join output. This strategy of learning after joins introducesredundancy avoided by normalization; which could lead to poorer end-to-end performanceand maintenance overheads due to data duplication. In this work; we take a step towardsenabling and optimizing learning over joins for a common class of machine learningtechniques called generalized linear models that are solved using gradient descent …,Proceedings of the 2015 ACM SIGMOD International Conference on Management of Data,2015,46
The Case Against Specialized Graph Analytics Engines.,Jing Fan; Adalbert Gerald Soosai Raj; Jignesh M Patel,ABSTRACT Graph analytic processing has started to become a nearly ubiquitouscomponent in the enterprise data analytics ecosystem. In response to this growing need;various specialized graph processing engines have been created in recent years. Sadly; theuse of relational database management systems (RDBMSs) for graph processing is largelyignored in most enterprise settings. This oversight is surprising since in most enterprisesettings; RDBMSs are already present and used for a variety of other analytic tasks. Thissituation then begs the question of whether the use of RDBMS for graph processing isfundamentally lacking in some respect compared to the specialized graph processingengines. In this paper; we aim to address this question both from the programmerproductivity perspective and from the performance perspective. We present Grail–a …,CIDR,2015,45
Accurate modeling of the hybrid hash join algorithm,Jignesh M Patel; Michael J Carey; Mary K Vernon,Abstract The join of two relations is an important operation in database systems. It occursfrequently in relational queries; and join performance is a significant factor in overall systemperformance. Cost models for join algorithms are used by query optimizers to chooseefficient query execution strategies. This paper presents an efficient analytical model of animportant join method; the hybrid hash join algorithm; that captures several key features ofthe algorithm's performance—including its intra-operator parallelism; interference betweendisk reads and writes; caching of disk pages; and placement of data on disk (s). Validation ofthe model against a detailed simulation of a database system shows that the response timeestimates produced by the model are quite accurate.,ACM SIGMETRICS Performance Evaluation Review,1994,45
Method and apparatus for using Java as a stored procedure language and as an embedded language on a client,*,One or more embodiments of the invention provide the ability to utilize the Javaprogramming language as a stored procedure language. One or more embodiments of theinvention provide for Java abstract data types (ADT) that map to ADT attributes from adatabase. The Java ADT can then be manipulated in an application written in the Javaprogramming language such as a stored procedure. Each ADT attribute from a database ismapped to a Java class by wrapping the ADT definition (which is commonly written in C++)in a Java wrapper. The wrapping process enables a user to write any client side Javaapplication. Once the ADTs are wrapped and a stored procedure is created; the storedprocedure must be able to execute. Enhancements permit a stored procedure written in theJava programming language to execute. Such enhancements include a server side …,*,2002,44
Rethinking Choices for Multi-dimensional Point Indexing: Making the Case for the Often Ignored Quadtree.,You Jung Kim; Jignesh M Patel,ABSTRACT Multi-dimensional point indexing methods play a critical role in a variety of data-centric applications; ranging from image retrieval; sequence matching; and protein structurecomparison. Many of these applications require manipulating point data in low to mediumdimensional space; either because of the inherent nature of the problem; or due to the use ofdimensionality reduction techniques such as PCA. A common choice of indexing method forthese applications is often the" ubiquitous" R*-tree. In this paper; we challenge this popularchoice of indexing for low and medium dimensional point data and investigate the use ofQuadtree as an alternative index structure. Our paper shows that the regular and disjointdecomposition method used by Quadtrees provides a significant structural advantage overthe R*-tree; which suffers from high overlap amongst MBRs even for low dimensional …,CIDR,2007,43
TIMBER: A native system for querying XML,Stelios Paparizos; Shurug Al-Khalifa; Adriane Chapman; HV Jagadish; Laks VS Lakshmanan; Andrew Nierman; Jignesh M Patel; Divesh Srivastava; Nuwee Wiwatwattana; Yuqing Wu; Cong Yu,Abstract XML has become ubiquitous; and XML data has to be managed in databases. Thecurrent industry standard is to map XML data into relational tables and store this informationin a relational database. Such mappings create both expressive power problems andperformance problems. In the T IMBER [7] project we are exploring the issues involved instoring XML in native format. We believe that the key intellectual contribution of this system isa comprehensive set-at-a-time query processing ability in a native XML store; with all thestandard components of relational query processing; including algebraic rewriting and acost-based optimizer.,Proceedings of the 2003 ACM SIGMOD international conference on Management of data,2003,43
Towards energy-efficient database cluster design,Willis Lang; Stavros Harizopoulos; Jignesh M Patel; Mehul A Shah; Dimitris Tsirogiannis,Abstract Energy is a growing component of the operational cost for many" big data"deployments; and hence has become increasingly important for practitioners of large-scaledata analysis who require scale-out clusters or parallel DBMS appliances. Although anumber of recent studies have investigated the energy efficiency of DBMSs; none of thesestudies have looked at the architectural design space of energy-efficient parallel DBMSclusters. There are many challenges to increasing the energy efficiency of a DBMS cluster;including dealing with the inherent scaling inefficiency of parallel data processing; andchoosing the appropriate energy-efficient hardware. In this paper; we experimentallyexamine and analyze a number of key parameters related to these challenges for designingenergy-efficient database clusters. We explore the cluster design space using empirical …,Proceedings of the VLDB Endowment,2012,42
Method and apparatus for parallel execution of trigger actions,*,A method and apparatus for parallel execution of trigger actions. One or more embodimentsof the invention comprise providing a C++ class (hereinafter referred to as “dispatcher”) thatcan take an SQL query or trigger action and start parallel execution of the trigger action. Thetrigger action is optimized and parallelized. The dispatcher executes the trigger action; setsup the communication links between the various operators in the trigger action; and ensuresthat all the results are sent back to the trigger.,*,2004,42
Join processing for flash SSDs: remembering past lessons,Jaeyoung Do; Jignesh M Patel,Abstract Flash solid state drives (SSDs) provide an attractive alternative to traditionalmagnetic hard disk drives (HDDs) for DBMS applications. Naturally there is substantialinterest in redesigning critical database internals; such as join algorithms; for flash SSDs.However; we must carefully consider the lessons that we have learnt from over threedecades of designing and tuning algorithms for magnetic HDD-based systems; so that wecontinue to reuse techniques that worked for magnetic HDDs and also work with flash SSDs.The focus of this paper is on recalling some of these lessons in the context of ad hoc joinalgorithms. Based on an actual implementation of four common ad hoc join algorithms onboth a magnetic HDD and a flash SSD; we show that many of the" surprising" results frommagnetic HDD-based join methods also hold for flash SSDs. These results include the …,Proceedings of the Fifth International Workshop on Data Management on New Hardware,2009,41
Wind: Workload-aware intrusion detection,Sushant Sinha; Farnam Jahanian; Jignesh M Patel,Abstract Intrusion detection and prevention systems have become essential to the protectionof critical networks across the Internet. Widely deployed IDS and IPS systems are basedaround a database of known malicious signatures. This database is growing quickly while atthe same time the signatures are getting more complex. These trends place additionalperformance requirements on the rule-matching engine inside IDSs and IPSs; which checkeach signature against an incoming packet. Existing approaches to signature evaluationapply statically-defined optimizations that do not take into account the network in which theIDS or IPS is deployed or the characteristics of the signature database. We argue that forhigher performance; IDS and IPS systems should adapt according to the workload; whichincludes the set of input signatures and the network traffic characteristics. To demonstrate …,International Workshop on Recent Advances in Intrusion Detection,2006,39
The Michigan Benchmark: A microbenchmark for XML query processing systems,Kanda Runapongsa; Jignesh M Patel; HV Jagadish; Shurug Al-Khalifa,With the continuing increasing popularity of the eXtensible Markup Language (XML) as arepresentation format for a wide variety of data; and it is clear that large repositories of XMLdata sets will soon emerge. The effective management of XML in a database thus becomesa pressing issue. Several methods for managing XML databases have emerged; rangingfrom retrofitting commercial RDBMSs to building native XML database systems. There hasnaturally been an interest in benchmarking the performance of these systems; and a numberof benchmarks have been proposed [?;?;?]. The focus of currently proposed benchmarks isto assess the performance of a given XML database in performing a variety of representativetasks. Such benchmarks are valuable to potential users of a database system in providingan indication of the performance that the user can expect on their specific application. The …,EEXTT,2002,37
Declarative querying for biological sequences,Sandeep Tata; James S Friedman; Anand Swaroop,The ongoing revolution in life sciences research is producing vast amounts of genetic andproteomic sequence data. Scientists want to pose increasingly complex queries on this data;but current methods for querying biological sequences are primitive and largely procedural.This limits the ease with which complex queries can be posed; and often results in veryinefficient query plans. There is a growing and urgent need for declarative and efficientmethods for querying biological sequence data. In this paper; we introduce a system calledPeriscope/SQ which addresses this need. Queries in our system are based on a well-defined extension of relational algebra. We introduce new physical operators and supportfor novel indexes in the database. As part of the optimization framework; we describe a newtechnique for selectivity estimation of string pattern matching predicates that is more …,Data Engineering; 2006. ICDE'06. Proceedings of the 22nd International Conference on,2006,35
Performance Comparison of the {\rm R}^{\ast}-Tree and the Quadtree for kNN and Distance Join Queries,You Jung Kim; Jignesh Patel,Multidimensional point indexing plays a critical role in a variety of data-centric applications;including image retrieval; sequence matching; and moving object database search. Acommon choice of indexing method for these applications is often the" ubiquitous” R*-tree.Choosing the right indexing method requires careful consideration of various factors such asquery operations and index construction methods. In this work; we present an experimentalstudy comparing the R*-tree and Quadtree using various criteria including the queryoperations and index construction methods. Although a variety of query operations can beperformed using these index structures; previous work has largely focused only on the rangesearch operation. We go beyond this previous work and compare the performance of theseindex structures using k-nearest neighbor (kNN) and distance join queries. In addition; we …,IEEE Transactions on Knowledge and Data Engineering,2010,34
Intelligent ship arrangements: a new approach to general arrangement,Michael G Parsons; Hyun Chung; Eleanor Nick; Anthony Daniels; Su Liu; Jignesh Patel,Abstract A new surface ship general arrangement optimization system developed at theUniversity of Michigan is described. The Intelligent Ship Arrangements system is a nativeC++; Leading Edge Architecture for Prototyping Systems–compatible software system thatwill assist the designer in developing rationally based arrangements that satisfy designspecific needs as well as general Navy requirements and standard practices to themaximum extent practicable. This software system is intended to be used following or as alatter part of ASSET synthesis. The arrangement process is approached as two essentiallytwo-dimensional tasks. First; the spaces are allocated to Zone-decks; one deck in onevertical zone; on the ship's inboard profile. Then the assigned spaces are arranged in detailon the deck plan of each Zone-deck in succession. Consideration is given to overall …,Naval Engineers Journal,2008,33
miBLAST: scalable evaluation of a batch of nucleotide sequence queries with BLAST,You Jung Kim; Andrew Boyd; Brian D Athey; Jignesh M Patel,Abstract A common task in many modern bioinformatics applications is to match a set ofnucleotide query sequences against a large sequence dataset. Exis-ting tools; such asBLAST; are designed to evaluate a single query at a time and can be unacceptably slowwhen the number of sequences in the query set is large. In this paper; we present a newalgorithm; called miBLAST; that evaluates such batch workloads efficiently. At the core;miBLAST employs aq-gram filtering and an index join for efficiently detecting similaritybetween the query sequences and database sequences. This set-oriented technique; whichindexes both the query and the database sets; results in substantial performanceimprovements over existing methods. Our results show that miBLAST is significantly fasterthan BLAST in many cases. For example; miBLAST aligned 247 965 oligonucleotide …,Nucleic acids research,2005,32
Enabling JSON Document Stores in Relational Systems.,Craig Chasseur; Yinan Li; Jignesh M Patel,ABSTRACT In recent years;“document store” NoSQL systems have exploded in popularity. Alarge part of this popularity has been driven by the adoption of the JSON data model in theseNoSQL systems. JSON is a simple but expressive data model that is used in many Web 2.0applications; and maps naturally to the native data types of many modern programminglanguages (eg Javascript). The advantages of these NoSQL document store systems (likeMongoDB and CouchDB) are tempered by a lack of traditional RDBMS features; notably asophisticated declarative query language; rich native query processing constructs (eg joins);and transaction management providing ACID safety guarantees. In this paper; weinvestigate whether the advantages of the JSON data model can be added to RDBMSs;gaining some of the traditional benefits of relational systems in the bargain. We present …,WebDB,2013,31
Using histograms to estimate answer sizes for XML queries,Yuqing Wu; Jignesh M Patel; HV Jagadish,Abstract Estimating the sizes of query results; and intermediate results; is crucial to manyaspects of query processing. In particular; it is necessary for effective query optimization.Even at the user level; predictions of the total result size can be valuable in “next-step”decisions; such as query refinement. This paper proposes a technique to obtain query resultsize estimates effectively in an XML database. Queries in XML frequently specify structuralpatterns; requiring specific relationships between selected elements. Whereas traditionaltechniques can estimate the number of nodes (XML elements) that will satisfy a node-specific predicate in the query pattern; such estimates cannot easily be combined to provideestimates for the entire query pattern; since element occurrences are expected to have highcorrelation. We propose a solution based on a novel histogram encoding of element …,Information Systems,2003,31
Model selection management systems: The next frontier of advanced analytics,Arun Kumar; Robert McCann; Jeffrey Naughton; Jignesh M Patel,Abstract John Boyd recognized in the 1960's the importance of situation awareness formilitary operations and introduced the notion of the OODA loop (Observe; Orient; Decide;and Act). Today we realize that many applications have to deal with situation awareness:Customer Relationship Management; Human Capital Management; Supply ChainManagement; patient care; power grid management; and cloud services management; aswell as any IoT (Internet of Things) related application; the list seems to be endless. Situationawareness requires applications to support the management of data; knowledge; processes;and other services such as social networking in an integrated way. These applicationsadditionally require high personalization as well as rapid and continuous evolution. Theymust provide a wide variety of operational and functional requirements; including real …,ACM SIGMOD Record,2016,30
Evaluating skylines in the presence of equijoins,Wen Jin; Michael D Morse; Jignesh M Patel; Martin Ester; Zengjian Hu,When a database system is extended with the skyline operator; it is important to determinethe most efficient way to execute a skyline query across tables with join operations. Thispaper describes a framework for evaluating skylines in the presence of equijoins;including:(1) the development of algorithms to answer such queries over large input tablesin a non-blocking; pipeline fashion; which significantly speeds up the entire query evaluationtime. These algorithms are built on top of the traditional relational Nested-Loop and the Sort-Merge join algorithms; which allows easy implementation of these methods in existingrelational systems;(2) a novel method for estimating the skyline selectivity of the joinedtable;(3) evaluation of skyline computation based on the estimation method and theproposed evaluation techniques; and (4) a systematic experimental evaluation to validate …,Data Engineering (ICDE); 2010 IEEE 26th International Conference on,2010,30
Searching on the secondary structure of protein sequences,Laurie Hammel; Jignesh M Patel,This chapter addresses the problem of efficient and declarative querying of the secondarystructure of protein data sets. The secondary structure of proteins plays an important role indetermining their function. Consequently; tools for querying the secondary structure ofproteins are invaluable in the study of proteomics. The recent conclusion of the HumanGenome Project has served to fuel an already explosive area of research in bioinformaticsthat is involved in deriving meaningful knowledge from proteins and DNA sequences. Evenwith the full human genome sequence now in hand; scientists still face the challenges ofdetermining exact gene locations and functions; observing interactions between proteins incomplex molecular machines; and learning the structure and function of proteins throughprotein conservation; just to name a few. The progress of this scientific research in the …,*,2002,28
Widetable: An accelerator for analytical data processing,Yinan Li; Jignesh M Patel,Abstract This paper presents a technique called WideTable that aims to improve the speedof analytical data processing systems. A WideTable is built by denormalizing the database;and then converting complex queries into simple scans on the underlying (wide) table. Toavoid the pitfalls associated with denormalization; eg space overheads; WideTable uses acombination of techniques including dictionary encoding and columnar storage. Whendenormalizing the data; WideTable uses outer joins to ensure that queries on tables in theschema graph; which are now nested as embedded tables in the WideTable; are processedcorrectly. Then; using a packed code scan technique; even complex queries on the originaldatabase can be answered by using simple scans on the WideTable (s). We experimentallyevaluate our methods in a main memory setting using the queries in TPC-H; and …,Proceedings of the VLDB Endowment,2014,27
SigMatch: fast and scalable multi-pattern matching,Ramakrishnan Kandhan; Nikhil Teletia; Jignesh M Patel,Abstract Multi-pattern matching involves matching a data item against a large database of"signature" patterns. Existing algorithms for multi-pattern matching do not scale well as thesize of the signature database increases. In this paper; we present sigMatch--a fast;versatile; and scalable technique for multi-pattern signature matching. At its heart; sigMatchorganizes the signature database into a (processor) cache-efficient q-gram index structure;called the sigTree. The sigTree groups patterns based on common sub-patterns; such thatsignatures that don't match can be quickly eliminated from the matching process. ThesigTree also uses parallel Bloom filters and a technique to reduce imbalances acrossgroups; for improved performance. Using extensive empirical evaluation across threediverse domains; we show that sigMatch often outperforms existing methods by an order …,Proceedings of the VLDB Endowment,2010,27
Identifying subgroups of patients with depression who are at high risk for suicide,Mark A Ilgen; Karen Downing; Kara Zivin; Katherine J Hoggatt; H Myra Kim; Dara Ganoczy; Karen L Austin; John McCarthy; Jignesh M Patel; Marcia Valenstein,Objective Although prior research has identified a number of separate risk factors for suicideamong patients with depression; little is known about how these factors may interact tomodify suicide risks. Using an empirically-based decision tree analysis for a large nationalsample of Veterans Affairs (VA) health system patients treated for depression; we identifysubgroups with particularly high or low rates of suicide. Method We identified 887;859 VApatients treated for depression between April 1; 1999 and September 30; 2004. Randomlysplitting the data into two samples (primary and replication samples); we developed adecision tree for the primary sample using recursive partitioning. We then tested whether thegroups developed within the primary sample were associated with increased suicide risk inthe replication sample. Results The exploratory data analysis produced a decision tree …,The Journal of clinical psychiatry,2009,27
Fast regular expression matching using small TCAM,Chad R Meiners; Jignesh Patel; Eric Norige; Alex X Liu; Eric Torng,Regular expression (RE) matching is a core component of deep packet inspection inmodern networking and security devices. In this paper; we propose the first hardware-basedRE matching approach that uses ternary content addressable memory (TCAM); which isavailable as off-the-shelf chips and has been widely deployed in modern networkingdevices for tasks such as packet classification. We propose three novel techniques to reduceTCAM space and improve RE matching speed: transition sharing; table consolidation; andvariable striding. We tested our techniques on eight real-world RE sets; and our results showthat small TCAMs can be used to store large deterministic finite automata (DFAs) andachieve potentially high RE matching throughput. For space; we can store each of thecorresponding eight DFAs with 25 000 states in a 0.59-Mb TCAM chip. Using a different …,IEEE/Acm Transactions On Networking,2014,26
Dictionary-based compression for long time-series similarity,Willis Lang; Michael Morse; Jignesh M Patel,Long time-series data sets are common in many domains; especially scientific domains.Applications in these fields often require comparing trajectories using similarity measures.Existing methods perform well for short time series but their evaluation cost degrades rapidlyfor longer time series. In this work; we develop a new time-series similarity measure calledthe Dictionary Compression Score (DCS) for determining time-series similarity. We alsoshow that this method allows us to accurately and quickly calculate similarity for both shortand long time series. We use the well-known Kolmogorov Complexity in information theoryand the Lempel-Ziv compression framework as a basis to calculate similarity scores. Weshow that off-the-shelf compressors do not fair well for computing time-series similarity. Toaddress this problem; we developed a novel dictionary-based compression technique to …,IEEE transactions on knowledge and data engineering,2010,24
ProbeMatch: rapid alignment of oligonucleotides to genome allowing both gaps and mismatches,You Jung Kim; Nikhil Teletia; Victor Ruotti; Christopher A Maher; Arul M Chinnaiyan; Ron Stewart; James A Thomson; Jignesh M Patel,Summary: We have developed a tool; called ProbeMatch; for matching a large set ofoligonucleotide sequences against a genome database using gapped alignments. Unlikemost of the existing tools such as ELAND which only perform ungapped alignments allowingat most two mismatches; ProbeMatch generates both ungapped and gapped alignmentsallowing up to three errors including insertion; deletion and mismatch. To speedupsequence alignment; ProbeMatch uses gapped q-grams and q-grams of various patterns toidentify target hits to a query sequence. This approach results in fewer initial sequences toexamine with no loss in sensitivity. ProbeMatch has been used to align 169 095 IlluminaGAII reads against the human genome; which could not be mapped by ELAND; and foundalignments for 28 625 reads of the 169 095 reads in less than 3 h.,Bioinformatics,2009,24
A framework for protein structure classification and identification of novel protein structures,You Jung Kim; Jignesh M Patel,Protein structure classification plays a central role in understanding the function of a proteinmolecule with respect to all known proteins in a structure database. With the rapid increasein the number of new protein structures; the need for automated and accurate methods forprotein classification is increasingly important. In this paper we present a unified frameworkfor protein structure classification and identification of novel protein structures. Theframework consists of a set of components for comparing; classifying; and clustering proteinstructures. These components allow us to accurately classify proteins into known folds; todetect new protein folds; and to provide a way of clustering the new folds. In our evaluationwith SCOP 1.69; our method correctly classifies 86.0%; 87.7%; and 90.5% of new domainsat family; superfamily; and fold levels. Furthermore; for protein domains that belong to …,BMC bioinformatics,2006,24
XIST: An XML index selection tool,Kanda Runapongsa; Jignesh M Patel; Rajesh Bordawekar; Sriram Padmanabhan,Abstract XML indices are essential for efficiently processing XML queries which typicallyhave predicates on both structures and values. Since the number of all possible structuraland value indices is large even for a small XML document with a simple structure; XMLDBMSs must carefully choose which indices to build. In this paper; we propose a tool; calledXIST; that can be used by an XML DBMS as an index selection tool. XIST exploits XMLstructural information; data statistics; and query workload to select the most beneficialindices. XIST employs a technique that organizes paths that evaluate to the same result intostructure equivalence groups and uses this concept to reduce the number of pathsconsidered as candidates for indexing. XIST selects a set of candidate paths and evaluatesthe benefit of an index for each candidate path on the basis of performance gains for non …,International XML Database Symposium,2004,23
To join or not to join?: Thinking twice about joins before feature selection,Arun Kumar; Jeffrey Naughton; Jignesh M Patel; Xiaojin Zhu,Abstract Closer integration of machine learning (ML) with data processing is a booming areain both the data management industry and academia. Almost all ML toolkits assume that theinput is a single table; but many datasets are not stored as single tables due tonormalization. Thus; analysts often perform key-foreign key joins to obtain features from allbase tables and apply a feature selection method; either explicitly or implicitly; with the aimof improving accuracy. In this work; we show that the features brought in by such joins canoften be ignored without affecting ML accuracy significantly; ie; we can" avoid joins safely."We identify the core technical issue that could cause accuracy to decrease in some casesand analyze this issue theoretically. Using simulations; we validate our analysis andmeasure the effects of various properties of normalized data on accuracy. We apply our …,Proceedings of the 2016 International Conference on Management of Data,2016,21
Towards cost-effective storage provisioning for DBMSs,Ning Zhang; Junichi Tatemura; Jignesh M Patel; Hakan Hacigümüş,Abstract Data center operators face a bewildering set of choices when considering how toprovision resources on machines with complex I/O subsystems. Modern I/O subsystemsoften have a rich mix of fast; high performing; but expensive SSDs sitting alongside withcheaper but relatively slower (for random accesses) traditional hard disk drives. The datacenter operators need to determine how to provision the I/O resources for specific workloadsso as to abide by existing Service Level Agreements (SLAs); while minimizing the totaloperating cost (TOC) of running the workload; where the TOC includes the amortizedhardware costs and the run time energy costs. The focus of this paper is on introducing thisnew problem of TOC-based storage allocation; cast in a framework that is compatible withtraditional DBMS query optimization and query processing architecture. We also present …,Proceedings of the VLDB Endowment,2011,21
Challenges and Opportunities with Big Data,Elisa Bertino; Philip Bernstein; Divyakant Agrawal; Susan Davidson; Umeshwas Dayal; Michael Franklin; Johannes Gehrke; Laura Haas; Alon Halevy; Jiawei Han; HV Jadadish; Alexandros Labrinidis; Sam Madden; Yannis Papokonstantinou; Jignesh Patel; Raghu Ramakrishnan; Kenneth Ross; Cyrus Shahabi; Dan Suciu; Shiv Vaithyanathan; Jennifer Widom,Abstract The promise of data-driven decision-making is now being recognized broadly; andthere is growing enthusiasm for the notion of" Big Data". While the promise of Bid Data isreal-for example; it is estimated that Google alone contributed 54 billion dollars to the USeconomy in 2009-there is currently a wide gap between its potential and its realization.,*,2011,21
The role of declarative querying in bioinformatics,Jignesh M Patel,THE RECENT PUBLICATION of a draft of the entire human genome (McPherson et al.;2001; Venter et al.; 2001) has served to fuel an already explosive area of research inbioinformatics that is involved in deriving meaningful knowledge from proteins and DNAsequences (Alberts et al.; 2002). Even with the full human genome sequence now in hand;scientists still face the challenges of determining exact gene locations and functions;observing interactions between proteins in complex molecular machines; and learning thestructure and function of proteins; just to name a few. The progress of this scientific researchis closely connected to the research in the database community in that analyzing largevolumes of biological data sets involves being able to maintain and query large databases(Moussouni et al.; 1999; Davidson; 2002). Database management systems (DBMSs) …,OMICS A Journal of Integrative Biology,2003,21
When free is not really free: What does it cost to run a database workload in the cloud?,Avrilia Floratou; Jignesh M Patel; Willis Lang; Alan Halverson,Abstract The current computing trend towards cloud-based Database-as-a-Service (DaaS)as an alternative to traditional on-site relational database management systems (RDBMSs)has largely been driven by the perceived simplicity and cost-effectiveness of migrating to aDaaS. However; customers that are attracted to these DaaS alternatives may find that therange of different services and pricing options available to them add an unexpected level ofcomplexity to their decision making. Cloud service pricing models are typically 'pay-as-you-go'in which the customer is charged based on resource usage such as CPU and memoryutilization. Thus; customers considering different DaaS options must take into account howthe performance and efficiency of the DaaS will ultimately impact their monthly bill. In thispaper; we show that the current DaaS model can produce unpleasant surprises–for …,Technology Conference on Performance Evaluation and Benchmarking,2011,20
Method and apparatus for evaluating index predicates on complex data types using virtual indexed streams,*,A method; apparatus; article of manufacture; and a memory structure for providing access toabstract data types using an index providing a tuple. The method comprises the steps ofaccepting a database query; generating an index predicate from the database query; anddetermining a tuple from an index using the index predicate. The tuple is associated with anabstract or complex data type responsive to the database query. A data stream is initializedwith the index predicate; and the tuple is returned in the data stream. The apparatuscomprises means for performing the above method steps; and the article of manufacturecomprises a medium tangibly embodying computer instructions for performing these methodsteps.,*,2004,20
PiQA: An algebra for querying protein data sets,Sandeep Tata; Jignesh M Patel,Life science researchers frequently need to query large protein data sets in a variety ofdifferent ways. Protein data sets have a rich structure that includes its primary structure;which is described as a sequence of amino acids; and its secondary structure; which isdescribed as a sequence of folding patterns of the protein. Both these structures areimportant as the amino acid sequence is often used to find homologous proteins; and thesecondary structure can produce important hints about the functionality of proteins. Whilethere are tools for querying each of these structures independently; there are no tools fordeclarative querying on both these structures. Even the tools that allow querying on eitherone of these structures are not based on any formal algebra; and as a result require complexrewriting of the tools programming logic when the" query evaluation plan" changes. This …,Scientific and Statistical Database Management; 2003. 15th International Conference on,2003,20
Method and apparatus for fetching array based objects by direct delivery and batching,*,A method; apparatus; article of manufacture; and a memory structure for providing access toan array-based data object to a client is disclosed. The method comprises the steps ofreceiving a database query from a client; generating a first execution plan from the databasequery; transmitting at least a portion of the first execution plan to a data server; compiling aquery result from the execution of the first execution plan; and transmitting the query result tothe client on a first communication path wherein the query result comprises an identificationfor a master data object responsive to the database query and the master data objectcomprises an identification for a plurality of array-based objects associated with the masterdata object. Further; the method comprises the establishment of a second communicationpath between the data server and the client and the transmission of the master data …,*,2003,19
Method of pattern searching,*,Structural join mechanisms provide efficient query pattern matching.In one embodiment; tree-merge mechanisms are provided. In anotherembodiment; stack-tree mechanisms are provided.,*,2008,18
Quickfoil: Scalable inductive logic programming,Qiang Zeng; Jignesh M Patel; David Page,Abstract Inductive Logic Programming (ILP) is a classic machine learning technique thatlearns first-order rules from relational-structured data. However; to-date most ILP systemscan only be applied to small datasets (tens of thousands of examples). A long-standingchallenge in the field is to scale ILP methods to larger data sets. This paper presents amethod called QuickFOIL that addresses this limitation. QuickFOIL employs a new scoringfunction and a novel pruning strategy that enables the algorithm to find high-quality rules.QuickFOIL can also be implemented as an in-RDBMS algorithm. Such an implementationpresents a host of query processing and optimization challenges that we address in thispaper. Our empirical evaluation shows that QuickFOIL can scale to large datasets consistingof hundreds of millions tuples; and is often more than order of magnitude more efficient …,Proceedings of the VLDB Endowment,2014,16
Design and evaluation of storage organizations for read-optimized main memory databases,Craig Chasseur; Jignesh M Patel,Abstract Existing main memory data processing systems employ a variety of storageorganizations and make a number of storage-related design choices. The focus of this paperis on systematically evaluating a number of these key storage design choices for mainmemory analytical (ie read-optimized) database settings. Our evaluation produces a numberof key insights: First; it is always beneficial to organize data into self-contained memoryblocks rather than large files. Second; both column-stores and row-stores displayperformance advantages for different types of queries; and for high performance both shouldbe implemented as options for the tuple-storage layout. Third; cache-sensitive B+-treeindices can play a major role in accelerating query performance; especially when used in ablock-oriented organization. Finally; compression can also play a role in accelerating …,Proceedings of the VLDB Endowment,2013,16
Periscope/gq: a graph querying toolkit,Yuanyuan Tian; Jignesh M Patel; Viji Nair; Sebastian Martini; Matthias Kretzler,Abstract Real life data can often be modeled as graphs; in which nodes represent objectsand edges between nodes indicate their relationships. Large graph datasets are common inmany emerging applications. Examples span from social networks; biological networks tocomputer networks. To fully exploit the wealth of information encoded in graphs; systems formanaging and analyzing graph data are critical. To address this need; we have designedand developed a graph querying toolkit; called Periscope/GQ. This toolkit is built on top of atraditional RDBMS. It provides a uniform schema for storing graphs in the database andsupports various graph query operations; especially sophisticated operations; such asapproximate graph matching; large graph alignment and graph summarization. Users caneasily combine several operations to perform complex analysis on graphs. In addition …,Proceedings of the VLDB Endowment,2008,16
SIGOPT: Using schema to optimize XML query processing,Stelios Paparizos; Jignesh M Patel; HV Jagadish,There has been a great deal of work in recent years on processing and optimizing queriesagainst XML data. Typically in these previous works; schema information is not considered;so that evaluation techniques can continue to be used even in the absence of one. However;schema information is often available and; in this paper; we show that when available it canbe exploited to great advantage in ways that complement" traditional" XML queryoptimization. To be usable in practice; we require that aspects of schema; essential for ourpurposes; be captured in a schema information graph (SIG). We exploit such meta-dataknowledge with a preprocessing enumeration phase that detects potentiallyinterchangeable evaluation units-we call such units alternate paths. We show; within analgebraic framework; methods that can break down a pattern tree into elementary paths …,Data Engineering; 2007. ICDE 2007. IEEE 23rd International Conference on,2007,15
Implications of emerging 3D GPU architecture on the scan primitive,Jason Power; Yinan Li; Mark D Hill; Jignesh M Patel; David A Wood,Abstract Analytic database workloads are growing in data size and query complexity. At thesame time; computer architects are struggling to continue the meteoric increase inperformance enabled by Moore's Law. We explore the impact of two emerging architecturaltrends which may help continue the Moore's Law performance trend for analytic databaseworkloads; namely 3D die-stacking and tight accelerator-CPU integration; specifically GPUs.GPUs have evolved from fixed-function units; to programmable discrete chips; and now areintegrated with CPUs in most manufactured chips. Past efforts to use GPUs for analytic queryprocessing have not had widespread practical impact; but it is time to re-examine and re-optimize database algorithms for massively data-parallel architectures. We argue that high-throughput data-parallel accelerators are likely to play a big role in future systems as they …,ACM SIGMOD Record,2015,14
Daq: a new paradigm for approximate query processing,Navneet Potti; Jignesh M Patel,Abstract Many modern applications deal with exponentially increasing data volumes and aidbusiness-critical decisions in near real-time. Particularly in exploratory data analysis; thefocus is on interactive querying and some degree of error in estimated results is tolerable. Acommon response to this challenge is approximate query processing; where the user ispresented with a quick confidence interval estimate based on a sample of the data. In thiswork; we highlight some of the problems that are associated with this probabilistic approachwhen extended to more complex queries; both in semantic interpretation and the lack of aformal algebra. As an alternative; we propose deterministic approximate querying (DAQ)schemes; formalize a closed deterministic approximation algebra; and outline some designprinciples for DAQ schemes. We also illustrate the utility of this approach with an example …,Proceedings of the VLDB Endowment,2015,14
Profiling R on a contemporary processor,Shriram Sridharan; Jignesh M Patel,Abstract R is a popular data analysis language; but there is scant experimental datacharacterizing the run-time profile of R programs. This paper addresses this limitation bysystematically cataloging where time is spent when running R programs. Our evaluationusing four different workloads shows that when analyzing large datasets; R programs a)spend more than 85% of their time in processor stalls; which leads to slower executiontimes; b) trigger the garbage collector frequently; which leads to higher memory stalls; and c)create a large number of unnecessary temporary objects that causes R to swap to diskquickly even for datasets that are far smaller than the available main memory. Addressingthese issues should allow R programs to run faster than they do today; and allow R to beused for analyzing even larger datasets. As outlined in this paper; the results presented in …,Proceedings of the VLDB Endowment,2014,14
Fuzzy inference based edge detection system using Sobel and Laplacian of Gaussian operators,J Patel; J Patwardhan; K Sankhe; R Kumbhare,Abstract This paper presents a new edge detection algorithm based on fuzzy system andfuzzy rules. Different approaches used before for detecting edges have some advantagesand disadvantages like false edges are detected; some important edges are missed; noisearound the corners etc. So; in order to reduce these types of effect special fuzzy system areused with inputs which are the computed values of two different methods. The output of fuzzysystem will decide whether that particular pixel is a part of edge or not. The two methodsused are gradient based ie first order derivative method and detection of zero crossing usinglaplacian operator applied to gaussian-smoothed image which is second order derivativemethod. Using these two approaches first values are computed and applied to fuzzy system.Then fuzzy system will decide for each pixel using different sets of fuzzy rules. Finally the …,Proceedings of the International Conference & Workshop on Emerging Trends in Technology,2011,14
Scalable rule-based gene expression data classification,Mark A Iwen; Willis Lang; Jignesh M Patel,Current state-of-the-art association rule-based classifiers for gene expression data operatein two phases:(i) Association rule mining from training data followed by (ii) Classification ofquery data using the mined rules. In the worst case; these methods require an exponentialsearch over the subset space of the training data set's samples and/or genes during at leastone of these two phases. Hence; existing association rule-based techniques areprohibitively computationally expensive on large gene expression datasets. Our main resultis the development of a heuristic rule-based gene expression data classifier called BooleanStructure Table Classification (BSTC). BSTC is explicitly related to association rule-basedmethods; but is guaranteed to be polynomial space/time. Extensive cross validation studieson several real gene expression datasets demonstrate that BSTC retains the …,Data Engineering; 2008. ICDE 2008. IEEE 24th International Conference on,2008,14
Toward GPUs being mainstream in analytic processing: An initial argument using simple scan-aggregate queries,Jason Power; Yinan Li; Mark D Hill; Jignesh M Patel; David A Wood,Abstract There have been a number of research proposals to use discrete graphicsprocessing units (GPUs) to accelerate database operations. Although many of these worksshow up to an order of magnitude performance improvement; discrete GPUs are notcommonly used in modern database systems. However; there is now a proliferation ofintegrated GPUs which are on the same silicon die as the conventional CPU. With theadvent of new programming models like heterogeneous system architecture; theseintegrated GPUs are considered first-class compute units; with transparent access to CPUvirtual addresses and very low overhead for computation offloading. We show thatintegrated GPUs significantly reduce the overheads of using GPUs in a databaseenvironment. Specifically; an integrated GPU is 3x faster than a discrete GPU even …,Proceedings of the 11th International Workshop on Data Management on New Hardware,2015,13
Memory footprint matters: efficient equi-join algorithms for main memory data processing,Spyros Blanas; Jignesh M Patel,Abstract High-performance analytical data processing systems often run on servers withlarge amounts of main memory. A common operation in such environments is combiningdata from two or more sources using some" join" algorithm. The focus of this paper is onstudying hash-based and sort-based equi-join algorithms when the data sets being joinedfully reside in main memory. We only consider a single node setting; which is an importantbuilding block for larger high-performance distributed data processing systems. A criticalcontribution of this work is in pointing out that in addition to query response time; one mustalso consider the memory footprint of each join algorithm; as it impacts the number ofconcurrent queries that can be serviced. Memory footprint becomes an importantdeployment consideration when running analytical data processing services on hardware …,Proceedings of the 4th annual Symposium on Cloud Computing,2013,13
Bypassing space explosion in regular expression matching for network intrusion detection and prevention systems,Jignesh Patel; Alex X Liu; Eric Torng,CiteSeerX - Document Details (Isaac Councill; Lee Giles; Pradeep Teregowda): 1.,In Proceedings of the 19th Annual Network and Distributed System Security Symposium,2012,13
Periscope/SQ: interactive exploration of biological sequence databases,Sandeep Tata; Willis Lang; Jignesh M Patel,Abstract Life science laboratories today have to rely on procedural techniques to store andmanage large sequence datasets. Procedural techniques are cumbersome to use and areoften very inefficient compared to optimized declarative techniques. We have designed andimplemented a system called Periscope/SQ that makes it possible to rapidly expresscomplex queries within a declarative framework and take advantage of database-style queryoptimization. As a result; queries in Periscope/SQ run orders of magnitude faster than typicalprocedural implementations. We demonstrate the power of Persicope/SQ through anapplication called Gene-Locator which allows biologists to rapidly explore large genomicsequence databases.,Proceedings of the 33rd international conference on Very large data bases,2007,13
Set containment join operation in an object/relational database management system,*,A novel partition-based set containment join algorithm; known as Set Partitioning Algorithm(SPA); is performed by a relational database management system to aggressively partitionset-valued attributes into a very large number of partitions; in order to minimize the impact ofexcessive replication and improve performance.,*,2004,13
Bacterial small RNAs in the genus Rickettsia,Casey LC Schroeder; Hema P Narra; Mark Rojas; Abha Sahni; Jignesh Patel; Kamil Khanipov; Thomas G Wood; Yuriy Fofanov; Sanjeev K Sahni,Rickettsia species are obligate intracellular Gram-negative pathogenic bacteria and theetiologic agents of diseases such as Rocky Mountain spotted fever (RMSF); Mediterraneanspotted fever; epidemic typhus; and murine typhus. Genome sequencing revealed that R.prowazekii has~ 25% non-coding DNA; the majority of which is thought to be either “junkDNA” or pseudogenes resulting from genomic reduction. These characteristics also defineother Rickettsia genomes. Bacterial small RNAs; whose biogenesis is predominantlyattributed to either the intergenic regions (trans-acting) or to the antisense strand of an openreading frame (cis-acting); are now appreciated to be among the most important post-transcriptional regulators of bacterial virulence and growth. We hypothesize that intergenicregions in rickettsial species encode for small; non-coding RNAs (sRNAs) involved in the …,BMC genomics,2015,12
Indexing HDFS data in PDW: splitting the data from the index,Vinitha Reddy Gankidi; Nikhil Teletia; Jignesh M Patel; Alan Halverson; David J DeWitt,Abstract There is a growing interest in making relational DBMSs work synergistically withMapReduce systems. However; there are interesting technical challenges associated withfiguring out the right balance between the use and co-deployment of these systems. Thispaper focuses on one specific aspect of this balance; namely how to leverage the superiorindexing and query processing power of a relational DBMS for data that is often more cost-effectively stored in Hadoop/HDFS. We present a method to use conventional B+-treeindices in an RDBMS for data stored in HDFS and demonstrate that our approach isespecially effective for highly selective queries.,Proceedings of the VLDB Endowment,2014,12
Design and evaluation of trajectory join algorithms,Yun Chen; Jignesh M Patel,Abstract Both spatial and temporal join algorithms have been widely studied in the past; butthere is very little work on the more complex problem of trajectory joins; which have manyuses in emerging location-based applications. In this paper; we present a generalframework; called JiST; that introduces a broad class of trajectory join operations; includingtrajectory distance join and trajectory k Nearest Neighbors join. Within the JiST framework;we present a set of algorithms to evaluate the trajectory join operations. Finally we presentresults from detailed experiments that demonstrate the efficiency and scalability of the JiSTjoin algorithms. To the best of our knowledge; JiST is the first comprehensive framework forcomplex trajectory join operations and lays the foundation for building a complex queryingplatform for emerging trajectory-based applications.,Proceedings of the 17th ACM SIGSPATIAL International Conference on Advances in Geographic Information Systems,2009,12
Bypassing space explosion in high-speed regular expression matching,Jignesh Patel; Alex X Liu; Eric Torng,Network intrusion detection and prevention systems commonly use regular expression (RE)signatures to represent individual security threats. While the corresponding deterministicfinite state automata (DFA) for any one RE is typically small; the DFA that corresponds to theentire set of REs is usually too large to be constructed or deployed. To address this issue; avariety of alternative automata implementations that compress the size of the final automatonhave been proposed such as extended finite automata (XFA) and delayed input DFA (D 2FA). The resulting final automata are typically much smaller than the corresponding DFA.However; the previously proposed automata construction algorithms do suffer from somedrawbacks. First; most employ a “Union then Minimize” framework where the automata foreach RE are first joined before minimization occurs. This leads to an expensive …,IEEE/ACM Transactions on Networking,2014,11
Fast peak-to-peak behavior with SSD buffer pool,Jaeyoung Do; Donghui Zhang; Jignesh M Patel; David J DeWitt,A promising use of flash SSDs in a DBMS is to extend the main memory buffer pool bycaching selected pages that have been evicted from the buffer pool. Such a use has beenshown to produce significant gains in the steady state performance of the DBMS. Onestrategy for using the SSD buffer pool is to throw away the data in the SSD when the systemis restarted (either when recovering from a crash or restarting after a shutdown); andconsequently a long “ramp-up” period to regain peak performance is needed. One approachto eliminate this limitation is to use a memory-mapped file to store the SSD buffer table inorder to be able to restore its contents on restart. However; this design can result in lowersustained performance; because every update to the SSD buffer table may incur an I/Ooperation to the memory-mapped file. In this paper we propose two new alternative …,Data Engineering (ICDE); 2013 IEEE 29th International Conference on,2013,11
Efficient and generic evaluation of ranked queries,Wen Jin; Jignesh M Patel,Abstract An important feature of the existing methods for ranked top-k processing is to avoidsearching all the objects in the underlying dataset; and limiting the number of randomaccesses to the data. However; the performance of these methods degrades rapidly as thenumber of random accesses increases. In this paper; we propose a novel and generalsequential access scheme for top-k query evaluation; which outperforms existing methods.We extend this scheme to efficiently answer top-k queries in subspace and on dynamic data.We also study the" dual" form of top-k queries called" ranking" queries; which returns therank of a specified record/object; and propose an exact as well as two approximatesolutions. An extensive empirical evaluation validates the robustness and efficiency of ourtechniques.,Proceedings of the 2011 ACM SIGMOD International Conference on Management of data,2011,11
TIMBER: A native XML database,Stelios Paparizos; Shurug Al-Khalifa; Y Wu; N Wiwatwattana; HV Jagadish; Andrew Nierman; C Yu; LVS Lakshmanan; D Srivastava; A Chapman; Jignesh M Patel,This paper describes the overall design and architecture of the Timber XML databasesystem currently being implemented at the University of Michigan. The system is based upona bulk algebra for manipulating trees; and natively stores XML. New access methods havebeen developed to evaluate queries in the XML context; and new cost estimation and queryoptimization techniques have also been developed. We present performance numbers tosupport some of our design decisions. We believe that the key intellectual contribution of thissystem is a comprehensive set-at-a-time query processing ability in a native XML store; withall the standard components of relational query processing; including algebraic rewritingand a cost-based optimizer.,*,2002,10
Demonstration of Santoku: optimizing machine learning over normalized data,Arun Kumar; Mona Jalal; Boqun Yan; Jeffrey Naughton; Jignesh M Patel,Abstract Advanced analytics is a booming area in the data management industry and a hotresearch topic. Almost all toolkits that implement machine learning (ML) algorithms assumethat the input is a single table; but most relational datasets are not stored as single tablesdue to normalization. Thus; analysts often join tables to obtain a denormalized table. Also;analysts typically ignore any functional dependencies among features because ML toolkitsdo not support them. In both cases; time is wasted in learning over data with redundancy.We demonstrate Santoku; a toolkit to help analysts improve the performance of ML overnormalized data. Santoku applies the idea of factorized learning and automatically decideswhether to denormalize or push ML computations through joins. Santoku also exploitsdatabase dependencies to provide automatic insights that could help analysts with …,Proceedings of the VLDB Endowment,2015,7
Cloud databases: what's new?,Daniel J Abadi; Michael Carey; Surajit Chaudhuri; Hector Garcia-Molina; Jignesh M Patel; Raghu Ramakrishnan,Abstract The panelists will discuss what characterizes data management in the cloud; andhow this differs from the broad range of applications that conventional databasemanagement systems have supported over the past few decades. They will examinewhether we need to develop new technologies to address demonstrably new challenges; orwhether we can largely re-position existing systems and approaches. The discussion willcover data analysis in the cloud using Map-Reduce based systems such as Hadoop; andcloud data serving (and so-called" No SQL" systems).,Proceedings of the VLDB Endowment,2010,7
Interactive graph summarization,Yuanyuan Tian; Jignesh M Patel,Abstract Graphs are widely used to model real-world objects and their relationships; andlarge graph data sets are common in many application domains. To understand theunderlying characteristics of large graphs; graph summarization techniques are critical.Existing graph summarization methods are mostly statistical (studying statistics such asdegree distributions; hop-plots; and clustering coefficients). These statistical methods arevery useful; but the resolutions of the summaries are hard to control. In this chapter; weintroduce database-style operations to summarize graphs. Like the OLAP-style aggregationmethods that allow users to interactively drill-down or roll-up to control the resolution ofsummarization; the methods described in this chapter provide an analogous functionality forlarge graph data sets.,*,2010,7
CASMIL: a comprehensive software/toolkit for image‐guided neurosurgeries,Gulsheen Kaur; Jun Tan; Mohammed Alam; Vipin Chaudhary; Dingguo Chen; Ming Dong; Hazem Eltahawy; Farshad Fotouhi; Christopher Gammage; Jason Gong; William Grosky; Murali Guthikonda; Jingwen Hu; Devkanak Jeyaraj; Xin Jin; Albert King; Joseph Landman; Jong Lee; Qing Hang Li; Hanping Lufei; Michael Morse; Jignesh Patel; Ishwar Sethi; Weisong Shi; King Yang; Zhiming Zhang,Background CASMIL aims to develop a cost-effective and efficient approach to monitor andpredict deformation during surgery; allowing accurate; and real-time intra-operativeinformation to be provided reliably to the surgeon. Method CASMIL is a comprehensiveImage-guided Neurosurgery System with extensive novel features. It is an integration ofvarious modules including rigid and non-rigid body co-registration (image-image; image-atlas; and image-patient); automated 3D segmentation; brain shift predictor; knowledgebased query tools; intelligent planning; and augmented reality. One of the vital and uniquemodules is the Intelligent Planning module; which displays the best surgical corridor on thecomputer screen based on tumor location; captured surgeon knowledge; and predictedbrain shift using patient specific Finite Element Model. Also; it has multi-level parallel …,*,2006,7
Efficient database support for spatial applications,Jignesh M Patel; David J Dewitt; James Goodman,This thesis concerns efficient support of geo-spatial applications on large volumes of spatialdata. This thesis examines efficient algorithms for evaluating two important spatialoperations: the spatial join and the spatial aggregate. A spatial join combines two spatialdata sets based on some spatial relationship between the elements in the two data sets. Forexample; map overlap; which requires combining two maps to produce a third; is a spatialjoin. A spatial aggregate summarizes the input by applying a spatial aggregate function. Anexample of spatial aggregation is locating the closest airport to a point on the map. Both thespatial join and the spatial aggregate operations are very expensive to compute.Consequently; efficient algorithms for both these operations are critical to the overallperformance of a spatial database system. The first part of this thesis presents a new …,*,1998,7
Re-evaluating designs for multi-tenant OLTP workloads on SSD-basedI/O subsystems,Ning Zhang; Junichi Tatemura; Jignesh Patel; Hakan Hacigumus,Abstract Multi-tenancy is a common practice that is employed to maximize server resourcesand reduce the total cloud operation costs. The focus of this work is on multi-tenancy forOLTP workloads. Several designs for OLTP multi-tenancy have been proposed that vary thetrade-offs made between performance and isolation. However; existing studies have notconsidered the impact of OLTP multi-tenancy designs when using an SSD-based I/Osubsystem. In this paper; we compare three designs using both open-source and proprietaryDBMSs on SSD-based I/O subsystems. Our study reveals that in contrast to the case of anHDD-based I/O subsystem; VM-based designs have fairly competitive performancecompared to the non-virtualized designs (generally within 1.3-2X of the best performingcase) on SSD-based I/O subsystems. Whereas previous studies were based on …,Proceedings of the 2014 ACM SIGMOD International Conference on Management of Data,2014,6
Method of pattern searching,*,The present application is a continuation of US patent application Ser. No. 10/748;832 filedDec. 30; 2003; now US Pat. No. 7;451;144 now pending; which claims the benefit of US ProvisionalPatent Application No. 60/450;222; filed on Feb. 25; 2003; where each of the above cited applicationsis incorporated herein by reference … The government may have certain rights in the inventionpursuant to a National Science Foundation grant under Grant Numbers IIS-9986030 andIIS-0208852 … The present invention relates generally to processing queries in a computersystem and; more particularly; to processing computer queries using pattern matching … Asis known in the art; the eXtensible Markup Language (XML) employs a tree-structured modelfor representing data. Queries in XML query languages typically specify patterns of selectionpredicates on multiple elements that have some specified tree structured relationships …,*,2012,6
How efficient is our radix join implementation,Spyros Blanas; Jignesh M Patel,We recently published a paper [2] that examines the design choices available to create ahigh-performance main-memory hash join algorithm. We experimentally evaluated four hashjoin variants on two different architectures; and we showed that an algorithm that does notdo any partitioning on the input tables often outperforms the other more complexpartitioningbased join alternatives. Our claim is that in an environment with a singleprocessor and multiple cores; the non-partitioning method has many advantages over themore complex methods that have been proposed before. If the memory access latencybetween different processors is non-uniform; partitioning will be more beneficial; the non-partitioning method could then be used as a building block for an efficient hash joinalgorithm for data that has been partitioned to each processor (NUMA node). A full …,*,2011,6
Replica placement in multi-tenant database environments,Avrilia Floratou; Jignesh M Patel,Database-as-a-service providers typically use replication to meet the performance andavailability guarantees demanded by their customers. A crucial problem in this context is thatof placing the replicas on machines in such a way as to meet these guarantees whileoptimally utilizing the available resources; despite having incomplete or erroneous a prioriknowledge of the workload characteristics. In contrast to previous work; we incorporate thisuncertainty by proposing online algorithms that make little or no assumptions aboutworkload characteristics. In this paper; we provide a formal definition of variants of thereplica placement problem; as well as a wide spectrum of criteria to evaluate proposedsolutions. We also designed and evaluated a number of new algorithms for the onlinereplica placement problem. We show that one of our algorithms; RkC; which is based on …,Big Data (BigData Congress); 2015 IEEE International Congress on,2015,5
A padded encoding scheme to accelerate scans by leveraging skew,Yinan Li; Craig Chasseur; Jignesh M Patel,Abstract In-memory data analytic systems that use vertical bit-parallel scan methodsgenerally use encoding techniques. We observe that in such environments; there is anopportunity to turn skew in both the data and predicate distributions (usually a problem forquery processing) into a benefit that can be leveraged to encode the column values. Thispaper proposes a padded encoding scheme to address this opportunity. The proposedscheme creates encodings that map common attribute values to codes that can easily bedistinguished from other codes by only examining a few bits in the full code. Consequently;scans on columns stored using the padded encoding scheme can safely prune thecomputation without examining all the bits in the code; thereby reducing the memorybandwidth and CPU cycles that are consumed when evaluating scan queries. Our …,Proceedings of the 2015 ACM SIGMOD International Conference on Management of Data,2015,5
Location tracking framework,*,A computer-implemented location tracking system includes an index comprising separateorganizations of a) entity information and location based notifications for the entities; and b)independent location based notifications; and the index further comprising a spatialorganization of references to the entity information; location based notifications for theentities; and independent location based notifications.,*,2013,5
An online framework for publishing privacy-sensitive location traces,Wen Jin; Kristen LeFevre; Jignesh M Patel,Abstract This paper studies the problem of protecting individual privacy when continuouslypublishing a stream of location trace data collected from a population of users.Fundamentally; this leads to the new challenge of anonymizing data that evolves inpredictable ways over time. Our main technical contribution is a novel formal framework forreasoning about privacy in this setting. We articulate a new privacy principle called temporalunlinkability. Then; by incorporating a probabilistic model of data change (in this case; usermotion); we are able to quantify the risk of privacy violations. Within this framework; wedevelop an initial set of algorithms for continuous privacy-preserving publishing. Finally; ourexperiments demonstrate the shortcomings of previous publishing techniques that do notaccount for inference based on predictable data change; and they demonstrate the …,Proceedings of the Ninth ACM International Workshop on Data engineering for wireless and Mobile Access,2010,5
Scientific data management: An orphan in the database community?,Randal C Burns; Susan B Davidson; Yannis E Ioannidis; Miron Livny; Jignesh M Patel,Increasingly; scientific discovery relies on querying vast amount of information forcorrelations and comparisons. Scientists in biology; astronomy; medicine; etc. areassembling databases thatare commonly hundreds of terabytes. Petascale databases willbe become the norm in the next ten years for disciplines as disparate as astronomy; biology;environmental engineering; geophysics; hydrology; oceanography; and medicine (just toname a few!). At the same time; interdisciplinary research between Computer Science andother science and engineering disciplines lies at the forefront of the National researchagenda; as evidenced by the National Academies Keck Futures Initiative and by the creationof the National Science Foundation's Office of Cyberinfrastructure. Despite these factors; thedatabase community has been slow to extend its research mission to include scientific …,ICDE,2008,5
Efficient evaluation of radial queries using the target tree,Michael Morse; Jignesh M Patel; William I Grosky,We propose a novel indexing structure; called the target tree; which is designed to answer anew type of spatial query; called the radial query. A radial query finds all objects in thespatial data set that intersect with line segments emanating from a single target point. Manybiomedical applications use radial queries; including neurosurgical planning. A target treeuses a regular hierarchical decomposition of space using wedge shapes that emanate fromthe target point. We compare the target tree with the R*-tree and quadtree; and show that thetarget tree is significantly faster than these methods.,International journal of bioinformatics research and applications,2006,5
Clone Join and Shadow Join: Two Parallel Algorithms for Executing Spatial Join Operations,Jignesh M Patel; David J DeWitt,Abstract VVith the growing popularity of spatial applications; there has been a signiﬁcantincrease in the use of database systems for storing and querying spatial data. Spatial data isnow readily available from a variety of sources including government mapping agencies;commercial sources; satellite images; and simulation outputs. As this trend continues;applications continue to execute increasingly complex queries on large and larger volumesof spatial data. As can be expected; these complex spatial queries frequently involve joiningtwo data sets based on some spatial relationship between objects in the two data sets. Thisoperation is called a spatial join; and like its relational counterpart; is an expensiveoperation. Consequently; spatial database systems must employ eflicient spatial joinalgorithms. In the past; many algorithms have been proposed for evaluating a spatial join …,Technical Report; University of Wisconsin; CS-TR-99-1403,1999,5
Towards linear algebra over normalized data,Lingjiao Chen; Arun Kumar; Jeffrey Naughton; Jignesh M Patel,Abstract Providing machine learning (ML) over relational data is a mainstream requirementfor data analytics systems. While almost all ML tools require the input data to be presentedas a single table; many datasets are multi-table. This forces data scientists to join thosetables first; which often leads to data redundancy and runtime waste. Recent works on"factorized" ML mitigate this issue for a few specific ML algorithms by pushing ML throughjoins. But their approaches require a manual rewrite of ML implementations. Suchpiecemeal methods create a massive development overhead when extending such ideas toother ML algorithms. In this paper; we show that it is possible to mitigate this overhead byleveraging a popular formal algebra to represent the computations of many ML algorithms:linear algebra. We introduce a new logical data type to represent normalized data and …,Proceedings of the VLDB Endowment,2017,4
Ava: From Data to Insights Through Conversations.,Rogers Jeffrey Leo John; Navneet Potti; Jignesh M Patel,ABSTRACT Enterprises increasingly employ a wide array of tools and processes to makedata-driven decisions. However; there are large inefficiencies in the enterprise-wideworkflow that stem from the fact that business workflows are expressed in natural languagebut the actual computational workflow has to be manually translated into computationalprograms. In this paper; we present an initial approach to bridge this gap by targeting thedata science component of enterprise workflows. In many cases; this component is theslowest part of the overall enterprise process; and focusing on it allows us to take an initialstep in solving the larger enterprise-wide productivity problem. In this initial approach; wepropose using a chatbot to allow a data scientist to assemble data analytics pipelines. Acrucial insight is that while precise interpretation of general natural language continues to …,CIDR,2017,4
Embedded multi-channel data acquisition system on FPGA for Aditya Tokamak,Rachana Rajpal; Hitesh Mandaliya; Jignesh Patel; Praveena Kumari; Pramila Gautam; Vismaysinh Raulji; Praveenlal Edappala; HD Pujara; R Jha,Abstract The 64 channel data acquisition board is designed to meet the future demand ofacquisition channels for plasma diagnostics. The inherent features of the board are 16 bitresolution; programmable sampling rate upto 200 kS/s/ch and simultaneous acquisition. Tomake system embedded and compact; 8 Analog Inputs ADC chip; 4M× 16 bit RAM memory;Field Programmable Gate Arrays; PC/104 platform and single board computer are used.High speed timing control signals for all ADCs and RAMs are generated by FPGA. Thesystem is standalone; portable and interface through Ethernet. The acquisition application isdeveloped in Qt. on Linux platform; in SBC. Due to ethernet connectivity and onboardprocessing; system can be integrated into Aditya and SST-1 data acquisition system. Theperformance of hardware is tested on Linux and Windows Embedded OS. The paper …,Fusion Engineering and Design,2016,4
Towards building wind tunnels for data center design,Avrilia Floratou; Frank Bertsch; Jignesh M Patel; Georgios Laskaris,Abstract Data center design is a tedious and expensive process. Recently; this process hasbecome even more challenging as users of cloud services expect to have guaranteed levelsof availability; durability and performance. A new challenge for the service providers is tofind the most cost-effective data center design and configuration that will accommodate theusers' expectations; on ever-changing workloads; and constantly evolving hardware andsoftware components. In this paper; we argue that data center design should become asystematic process. First; it should be done using an integrated approach that takes intoaccount both the hardware and the software interdependencies; and their impact on users'expectations. Second; it should be performed in a" wind tunnel"; which uses large-scalesimulation to systematically explore the impact of a data center configuration on both the …,Proceedings of the VLDB Endowment,2014,4
TU‐C‐BRB‐11: In Vitro Dose Enhancement from Gold Nanoparticles under Different Clinical MV Photon Beam Configurations,R Berbeco; H Korideck; W Ngwa; R Kumar; J Patel; S Sridhar; S Johnson; B Price; A Kimmelman; M Makrigiorgos,Purpose: To quantify the relative in vitro dose enhancement due to the presence of goldnanoparticles (GNPs) in a clinical 6 MV beam. It is expected that depths and delivery modesthat produce larger proportions of low energy photons will have a larger effect on cellsamples containing GNP. Methods: HeLa cells were combined with 50 nm GNPs at aconcentration of 0 or 0.05 mg/ml. The cells were irradiated in clinical solid water at depths of1.5; 5; 10; 15 and 20 cm (SAD setup). Conventional beams with square aperture sizes 5; 10and 15 cm at isocenter; IMRT and flattening filter free (FFF) beams were used. DNA doublestrand breaks (DSBs) were evaluated by H2AX staining. Results: Statistically significantdose enhancement was observed for all depths and delivery modes. Dose enhancementratios varied between 1.1 and 1.7. Relative to the shallowest depth; dose enhancement …,Medical Physics,2012,4
Declarative and efficient querying on protein secondary structures,Jignesh M Patel; Donald P Huddler; Laurie Hammel,Summary In spite of the many decades of progress in database research; surprisinglyscientists in the life sciences community still struggle with inefficient and awkward tools forquerying biological datasets. This work highlights a specific problem involving searchinglarge volumes of protein datasets based on their secondary structure. In this chapter wedefine an intuitive query language that can be used to express queries on secondarystructure and develop several algorithms for evaluating these queries. We haveimplemented these algorithms in Periscope; which is a native database managementsystem that we are building for declarative querying on biological datasets. Experimentsbased on our implementation show that the choice of algorithms can have a significantimpact on query performance. As part of the Periscope implementation; we have also …,*,2005,4
Towards Declarative Querying for Biological Sequences,Sandeep Tata; J Patel; J Friedman; Anand Swaroop,Abstract The ongoing revolution in life sciences research is producing vast amounts ofgenetic and proteomic sequence data. Scientists want to pose increasingly complex querieson this data; but current methods for querying biological sequences are primitive and largelyprocedural. This limits the ease with which complex queries can be posed; and often resultsin very inefficient query plans. There is a growing and urgent need for declarative andefficient methods for querying biological sequence data. In this paper we introduce a systemcalled Periscope/SQ which addresses this need. Queries in our system are based on awelldefined extension of relational algebra. We introduce new physical operators andsupport for novel indexes in the database. As part of the optimization framework; wedescribe a new technique for selectivity estimation of string pattern matching predicates …,*,2005,4
Query Processing in Mobile Environments,Jignesh M Patel,We are on the verge of a new revolution in computing in which a large number of devices;ranging from small personal digital assistants (PDAs) to—invisible “embedded devices willbe pervasive in our physical world. The hand-held computing devices and the mobilephones that are available today are precursors to the types of devices that we are likely tosee in the future. In addition to these computing devices that are currently available; we arealso likely to encounter computing devices embedded in every day articles like appliances;clothes; watches; environmental sensor devices; etc. Besides having computing and storageresources; these devices will also have some connectivity to a data network. In many casesas the device moves; it may change the form of network connectivity; for example within aroom a hand-held PDA might use a 802.11 b or Bluetooth wireless connection; and may …,NFS Wokshop on Context Aware Mobile Database Management (CAMM),2002,4
Toward cost-effective storage provisioning for DBMSs,Ning Zhang; Junichi Tatemura; Jignesh M Patel; Hakan Hacigumus,Abstract Data center operators face a bewildering set of choices when considering how toprovision resources on machines with complex I/O subsystems. Modern I/O subsystemsoften have a rich mix of fast; high performing; but expensive SSDs sitting alongside withcheaper but relatively slower (for random accesses) traditional hard disk drives. The datacenter operators need to determine how to provision the I/O resources for specific workloadsso as to abide by existing service level agreements; while minimizing the total operating cost(TOC) of running the workload; where the TOC includes the amortized hardware costs andthe run-time energy costs. The focus of this paper is on introducing this new problem of TOC-based storage allocation; cast in a framework that is compatible with traditional DBMS queryoptimization and query processing architecture. We also present a heuristic-based …,The VLDB Journal,2014,3
Query Processing on Smart SSDs.,Kwanghyun Park; Yang-Suk Kee; Jignesh M Patel; Jaeyoung Do; Chanik Park; David J Dewitt,Abstract Data storage devices are getting smarter. Smart flash storage devices (aka SmartSSDs) are on the horizon and package a small programmable computer inside the device.Thus; users can run code closer to the data right inside the SSD; on the “other” side of the I/Obus. The focus of this paper is on exploring the opportunities and challenges associated withexploiting this functionality of Smart SSDs for relational analytic query processing. We haveimplemented an initial prototype of Microsoft SQL Server running on a Samsung SmartSSDs. Our results demonstrate that significant performance and energy gains can beachieved by pushing selected query processing components inside the Smart SSD. We alsoidentify various changes that SSD manufacturers can make to increase the benefits of usingSmart SSDs for data processing applications; and suggest possible research …,IEEE Data Eng. Bull.,2014,3
Fast peak-to-peak restart for SSD buffer pool Extension,Jaeyoung Do; Donghui Zhang; Jignesh M Patel; David J DeWitt,Abstract—A promising usage of Flash SSDs in a DBMS is to use it to extend the mainmemory buffer pool by caching in the SSD selected pages that are evicted from the bufferpool. These schemes have been shown to produce big performance gains in the steadystate. Simple methods for using the SSD buffer pool throw away the data in the SSD whenthe system is restarted (either when recovering from a crash or restarting after a shutdown);and consequently need a long “ramp-up” period to regain peak performance. A recentmethod to address this limitation is to use a memory-mapped file to store the metadata(called the SSD buffer table) about the contents of the SSD buffer pool; and to recover themetadata at the beginning of recovery. However; this method can result in lower sustainedperformance; because every update to the SSD buffer table may incur a random I/O …,Proc. of ICDE,2013,3
Looking ahead makes query plans robust: Making the initial case with in-memory star schema data warehouse workloads,Jianqiao Zhu; Navneet Potti; Saket Saurabh; Jignesh M Patel,Abstract Query optimizers and query execution engines cooperate to deliver highperformance on complex analytic queries. Typically; the optimizer searches through the planspace and sends a selected plan to the execution engine. However; optimizers may at timesmiss the optimal plan; with sometimes disastrous impact on performance. In this paper; wedevelop the notion of robustness of a query evaluation strategy with respect to a space ofquery plans. We also propose a novel query execution strategy called LookaheadInformation Passing (LIP) that is robust with respect to the space of (fully pipeline-able) left-deep query plan trees for in-memory star schema data warehouses. LIP ensures thatexecution times for the best and the worst case plans are far closer than without LIP. In fact;under certain assumptions of independent and uniform distributions; any plan in that …,Proceedings of the VLDB Endowment,2017,2
Operational NoSQL Systems: What's New and What's Next?,Jignesh M Patel,Operational NoSQL systems are relatively new in the data-management ecosystem; andthere is much confusion about their capabilities and how they differ from traditional relationaldatabase systems. This summary of characteristics clearly distinguishes the two systemclasses and provides a glimpse into directions for future work.,Computer,2016,2
Note: Tesla based pulse generator for electrical breakdown study of liquid dielectrics,G Veda Prakash; R Kumar; J Patel; K Saurabh; A Shyam,In the process of studying charge holding capability and delay time for breakdown in liquidsunder nanosecond (ns) time scales; a Tesla based pulse generator has been developed.Pulse generator is a combination of Tesla transformer; pulse forming line; a fast closingswitch; and test chamber. Use of Tesla transformer over conventional Marx generatorsmakes the pulse generator very compact; cost effective; and requires less maintenance. Thesystem has been designed and developed to deliver maximum output voltage of 300 kV andrise time of the order of tens of nanoseconds. The paper deals with the system designparameters; breakdown test procedure; and various experimental results. To validate thepulse generator performance; experimental results have been compared with PSPICEsimulation software and are in good agreement with simulation results.,Review of Scientific Instruments,2013,2
Finding Hidden Patterns in Sequences,Avrilia Floratou; Sandeep Tata; Jignesh M Patel,*,Sciences-New York,2010,2
FLAME: Shedding Light on Hidden Frequent Patterns in Sequence Datasets,Sandeep Tata; Jignesh M Patel,Existing database sequence mining algorithms focus on mining for subsequences.However; for many emerging applications; the subsequence model is inadequate fordetecting interesting patterns. Often; an approximate substring model better accommodatesthe notion of a noisy pattern. In this paper; we present a powerful new model for approximatepattern mining. We show that this model can be used to capture the notion of anapproximate match for a variety of different applications. We also present a novel; suffix treebased pattern mining algorithm called FLAME and demonstrate that it is a fast; accurate; andscalable method for discovering hidden patterns in large sequence databases.,Data Engineering; 2008. ICDE 2008. IEEE 24th International Conference on,2008,2
Comparing OLTP Scaling Behavior on Intel® Xeon and Itanium® 2 Processors,Richard Hankins; Murali Annavaram; Brian Hirano¹; Jignesh Patel; John Shen,Abstract Analyzing On-Line Transaction Processing workloads can be quite challenging assmall configurations may not accurately represent realistic systems; while largeconfigurations are very complex to configure and cost prohibitive to build. This paperpresents a comparative study of the scaling behavior of an OLTP workload on Intel Xeonand Intel Itanium 2 processors. Using our “iron law” of database performance as aframework; we characterize the scaling behavior of two performance metrics that are criticalto the transaction throughput: the average instructions executed per transaction (IPX) andthe average cycles per instruction(CPI). This characterization is determined through anextensive empirical examination of an Oracle based commercial OLTP workload runningon both architectures. Our study shows that both systems' CPI trend show two distinct …,Red,2004,2
Effect of Node Size on the Performance of Cache-Conscious Indices,Richard A Hankins; Jignesh M Patel,Abstract In main-memory environments; the number of processor cache misses has a criticalimpact on the performance of the system. Cache-conscious indices are designed to improvethe performance of mainmemory indices by reducing the number of processor cache missesthat are incurred during a search operation. Conventional wisdom suggests that the index'snode size should be equal to the cache line size in order to minimize the number of cachemisses and improve performance. As we show in this paper; this design choice ignoresadditional effects; such as instruction count; which play a significant role in determining theoverall performance of the index. Using analytical models and a detailed experimentalevaluation; we investigate the effect of the index's node size on two common cache-conscious indices: a cache-conscious B+-tree (CSB+-tree); and a cache-conscious …,Extended Report; http://www. eecs. umich. edu/quickstep/publ/ccindices. pdf,2002,2
Partition Based Spatial-Merge Join,DJ DeWitt,*,Proc. of ACM SIGMOD,1996,2
Adaptive concurrent query execution framework for an analytical in-memory database system,Harshad Deshmukh; Hakan Memisoglu; Jignesh M Patel,There is a growing need for in-memory database analytic services; especially in cloudsettings. Concurrent query execution is common in such environments. A crucial deploymentrequirement is to employ a concurrent query execution scheduling framework that is flexible;precise; and adaptive to meet specified deployment goals. In addition; the framework mustalso aim to use all the underlying hardware resources effectively (for high performance andhigh cost efficiency). This paper focuses on the design and evaluation of such a schedulerframework. Our scheduler framework incorporates a design in which the scheduling policiesare cleanly separated from the scheduling mechanisms; allowing the scheduler to support avariety of policies; such as fair and priority scheduling. The scheduler also contains a novellearning component to monitor and quickly adapt to changing resource requirements of …,Big Data (BigData Congress); 2017 IEEE International Congress on,2017,1
What Do Students Feel about Learning Programming Using Both English and Their Native Language?,Adalbert Gerald Soosai Raj; Kasama Ketsuriyonk; Jignesh M Patel; Richard Halverson,Programming is taught in India using English as the medium of instruction to students whosenative language is not English. This places a high cognitive load on students who learnprogramming for the first time and who are not very proficient in English. Our study aims atfinding out what the students feel if their native language is used along with English forteaching programming. As a part of our study; we taught linked list; a basic concept inprogramming; to two groups of undergraduate students for a week in Tamil Nadu; India. Weused English to teach one group of students and English and Tamil (the native language inTamil Nadu) to teach the other group. Our intervention consisted of 3 lectures and 1 live-coding session. We collected qualitative data by means of an open-ended feedback from thestudents. The analysis of this feedback shows that students have expressed positive …,Learning and Teaching in Computing and Engineering (LaTICE); 2017 International Conference on,2017,1
Predictive Provisioning: Efficiently Anticipating Usage in Azure SQL Database,Lalitha Viswanathan; Bikash Chandra; Willis Lang; Karthik Ramachandra; Jignesh M Patel; Ajay Kalhan; David J DeWitt; Alan Halverson,Over-booking cloud resources is an effective way to increase the cost efficiency of a cluster;and is being studied within Microsoft for the Azure SQL Database service. A key challenge isto strike the right balance between the potentially conflicting goals of optimizing for resourceallocation efficiency and positive user experience. Understanding when cloud databasecustomers use their database instances and when they are idle can allow one tosuccessfully balance these two metrics. In our work; we formulate and evaluate production-feasible methods to develop idleness profiles for customer databases. Using one of thelargest data center telemetry datasets; namely Azure SQL Database telemetry acrossmultiple data centers; we show that our schemes are effective in predicting future patterns ofdatabase usage. Our methods are practical and improve the efficiency of clusters while …,Data Engineering (ICDE); 2017 IEEE 33rd International Conference on,2017,1
When Lempel-Ziv-Welch Meets Machine Learning: A Case Study of Accelerating Machine Learning using Coding,Fengan Li; Lingjiao Chen; Arun Kumar; Jeffrey F Naughton; Jignesh M Patel; Xi Wu,Abstract: In this paper we study the use of coding techniques to accelerate machine learning(ML). Coding techniques; such as prefix codes; have been extensively studied and used toaccelerate low-level data processing primitives such as scans in a relational databasesystem. However; there is little work on how to exploit them to accelerate ML algorithms. Infact; applying coding techniques for faster ML faces a unique challenge: one needs toconsider both how the codes fit into the optimization algorithm used to train a model; and theinterplay between the model sstructure and the coding scheme. Surprisingly andintriguingly; our study demonstrates that a slight variant of the classical Lempel-Ziv-Welch(LZW) coding scheme is a good fit for several popular ML algorithms; resulting in substantialruntime savings. Comprehensive experiments on several real-world datasets show that …,arXiv preprint arXiv:1702.06943,2017,1
Aggressive buffer pool warm-up after restart in SQL Server,Kwanghyun Park; Jaeyoung Do; Nikhil Teletia; Jignesh M Patel,In many settings; a database server has to be restarted either in response to a failure event;or in response to an operational decision such as moving a database service from onemachine to another. However; such restarts pose a potential performance problem as thenew database server starts off with a cold buffer pool. As a result; the database applicationexperiences a dramatic reduction in performance right after the restart; since just before therestart the database buffer pool was filled with hot pages and after the restart the databasebuffer pool is empty. To address these issues; traditional database systems use mechanismssuch as SQL Server's aggressive page expansion and MySQL's buffer pool preloading.However; these approaches have key limitations including long warm-up times; possibleearly hot page eviction; user query performance saturation; and failure restart. In this …,Data Engineering Workshops (ICDEW); 2016 IEEE 32nd International Conference on,2016,1
Database system with data organization providing improved bit parallel processing,*,A database system provides vertical or horizontal pre-packing of database data elementsaccording to a size of physical processor words in order to obtain improved parallelprocessing at the bit level. After processor words are populated with data from multiple dataelements of the database; query operations are used which may simultaneously process themultiple data elements in each data word simultaneously in the computer arithmetic logicunit.,*,2015,1
Toward GPUs being mainstream in analytic processing,Jason Power; Yinan Li; Mark D Hill; Jignesh M Patel; David A Wood,ABSTRACT There have been a number of research proposals to use discrete graphicsprocessing units (GPUs) to accelerate database operations. Although many of these worksshow up to an order of magnitude performance improvement; discrete GPUs are notcommonly used in modern database systems. However; there is now a proliferation ofintegrated GPUs which are on the same silicon die as the conventional CPU. With theadvent of new programming models like heterogeneous system architecture; theseintegrated GPUs are considered first-class compute units; with transparent access to CPUvirtual addresses and very low overhead for computation offloading. We show thatintegrated GPUs significantly reduce the overheads of using GPUs in a databaseenvironment. Specifically; an integrated GPU is 3× faster than a discrete GPU even …,*,2015,1
A Survey of the Existing Landscape of ML Systems,Arun Kumar; Robert McCann; Jeffrey Naughton; Jignesh M Patel,1. INTRODUCTION We present a detailed survey of the existing land- scape of ML systems. Wecategorize the existing and proposed ML systems into six major categories: (1) Packages of MLImplementations; (2) Systems with a Linear Algebra-based Language; (3) Model ManagementSystems; (4) Systems for Feature En- gineering; (5) Systems for Algorithm Selection; and (6)Systems for Parameter Tuning. For each cate- gory (or sub-category; wherever applicable); wedis- cuss a few prominent examples from both research and practice. Note that it is possible fora sys- tem to belong to more than one category; since it could potentially have multiple simultaneousgoals. Our categorization is not intended to be exhaustive. Rather; we aim to give a high-levelpicture of the kinds of functionalities that have been considered; and underscore the gaps thatexist to motivate our vision [26]. Table 1 summarizes the categories.,UW-Madison CS Tech. Rep. TR1827,2015,1
An Online Framework for Publishing Dynamic Privacy-Sensitive Location Traces,Wen Jin; Kristen LeFevre; Jignesh M Patel,ABSTRACT This paper considers the problem of protecting individual anonymity whencontinuously publishing a stream of location trace information collected from a population ofusers. Fundamentally; the key challenge that arises in this setting is the presence of evolvingdata; and in particular; data that evolves in semi-predictable ways. The main contribution ofthis paper is the first comprehensive formal framework for reasoning about privacy in thissetting. Through careful analysis of the expected threat; we articulate a new privacy principlecalled temporal unlinkability. Then; by incorporating a model of user motion; we are able toquantify the risk of privacy violations probabilistically. Within this framework; we develop asimple initial set of algorithms for continuous publishing; and we demonstrate the feasibilityof the approach using both real and synthetic location data.,*,2009,1
Architecture-conscious databases: sub-optimization or the next big leap?,Babak Falsafi; Jignesh Patel; Ken Ross,• What will computer architectures look like in 5 years? (Both desktop/server architecture asmobile/ubiquitous platforms. Encompassing CPU architectures (SMT and beyond?); platforms(new communication buses/paradigms?); memory technologies (nvram; end beyond?); and massstorage (mag- netic; mems; and beyond?)) … • To what extent are CPU manufacturers willingto listen to DBMS people? (If so; is there any evidence? If not; why not?) … • Do computer architecturetrends/changes force us to re-think the classical DBMS architecture (virtually unchanged sinceSystem R)? (Is this required for classical application areas (OLTP;OLAP)? Or just noise thereand only applicable for certain new areas (see next question)?) … • What architecture-consciousHYPEWORD data-management challenges/opportunities do you see in the next 5 years? (WhereHYPEWORD in XML; stream; mobile/ubiquitous; sensor; data mining; multimedia .. ),Proceedings of the 1st international workshop on Data management on new hardware,2005,1
The Michigan Benchmark: A Micro-Benchmark for XML Query Performance Diagnostics,Jignesh M Patel; HV Jagadish,With the increasing popularity of the eXtensible Markup Language (XML) as arepresentation format for a wide variety of data; and it is clear that large repositories of XMLdata sets will soon emerge. The effective management of XML in a database thus becomesa pressing issue. Several methods for managing XML databases have emerged; rangingfrom retrofitting commercial RDBMSs to building native XML database systems. There hasnaturally been an interest in benchmarking the performance of these systems; and a numberof benchmarks have been proposed [4; 10; 12]. The focus of currently proposed benchmarksis to assess the performance of a given XML database in performing a variety ofrepresentative tasks. Such benchmarks are valuable to potential users of a database systemin providing an indication of the performance that the user can expect on their specific …,XML Data Management: Native XML and XML-Enable Database systems,2003,1
Quickstep: A Data Platform Based on the Scaling-In Approach,Jignesh M Patel; Harshad Deshmukh; Jianqiao Zhu; Hakan Memisoglu; Navneet Potti; Saket Saurabh; Marc Spehlmann; Zuyu Zhang,Abstract Modern servers pack enough storage and computing power that just a decade agowas spread across a modestsized cluster. This paper presents a prototype system; calledQuickstep; to exploit the large amount of parallelism that is packed inside such modernservers. Quickstep builds on a vast body of previous work on methods for organizing data;optimizing; scheduling and executing queries; and brings them together in a single system.Quickstep also includes new query processing methods that go beyond previousapproaches. To keep the project focused; the project's initial target is read-mostly in-memorydata warehousing workloads in single-node settings. In this paper; we describe the designand implementation of Quickstep for this target application space. In this paper; we alsopresent experimental results comparing the performance of Quickstep to a number of …,Growth,*,1
Design and Evaluation of Storage Organizations for Read-Optimized Main Memory Databases (Supplementary Material),Craig Chasseur; Jignesh M Patel,ABSTRACT This document is a supplement to the authors' paper Design and Evaluation ofStorage Organizations for Read-Optimized Main Memory Databases [4]. It containsadditional experimental results which demonstrate the interaction between join processingand storage organization.,*,*,1
Does Native Language Play a Role in Learning a Programming Language?,Adalbert Gerald Soosai Raj; Kasama Ketsuriyonk; Jignesh M Patel; Richard Halverson,Abstract Computer Science (CS) is taught in India; using English as the medium ofinstruction; to students whose native language is not English. This places a high cognitiveload on students who learn programming for the first time and who are not very proficient inEnglish. The problems these students face become even harder since learning to programcan be an incredibly difficult task. Our study aims to find out if a student's native languagehas any effect on the student's ability to learn programming. We taught linked list; a basicconcept in CS; to two groups of undergraduate students for a week in Tamil Nadu; India. Weused English to teach one group of students and English and Tamil (the native language inTamil Nadu) to teach the other group. Our intervention consisted of three lectures and onelive-coding session. We collected quantitative and qualitative data using technical tests …,Proceedings of the 49th ACM Technical Symposium on Computer Science Education,2018,*
How to teach modern C++ to someone who already knows programming?,Adalbert Gerald Soosai Raj; Varun Naik; Jignesh M Patel; Richard Halverson,Abstract The C++ programming language has undergone major changes since theintroduction of C++ 11.'Modern C++;'defined here as C++ 11 and beyond; can be viewed asa new language compared to C++ 98 (the version of C++ introduced in 1998). Many newfeatures have been added to modern C++; including lambda expressions and automatictype deduction. The standard library has also been dramatically updated with constructssuch as std:: unordered_set and smart pointers. The traditional way of teaching C++ by firstteaching C's low-level features; such as raw pointers and char* strings; is potentiallyineffective when teaching modern C++. Based on this hypothesis; we updated the way inwhich we teach C++ at UW-Madison by teaching the most important high-level features(containers; iterators; and algorithms) first; and introducing the low-level features (raw …,Proceedings of the 20th Australasian Computing Education Conference,2018,*
Database system with highly denormalized database structure,*,Abstract A database system converts a multi-table relational database into a wide tableincorporating all of the information of the relational database tables and converts queries forthe relational database system into a form applicable to the wide table. Dictionarycompression and/or columnar store allow faster query processing despite a substantiallylarger size of the wide table.,*,2018,*
Automatic recovery of application cache warmth,*,The automated recovery of the warmth of cache of an application that has been subject to arunning state change that degraded the warmth of the cache. To prepare for a loss inwarmth; the cache portion identifiers are captured; and corresponding cache portions arestored in an external store. Thereafter; the application experiences changes in state. In orderto warm the application cache more quickly; cache portions identified by the captured cacheportion identifiers are retrieved from the external data store and placed in the applicationcache.,*,2017,*
Does Kinesio taping correct exaggerated dynamic knee valgus? A randomized double blinded sham-controlled trial,Sannasi Rajasekar; Ajay Kumar; Jignesh Patel; Muthukrishnan Ramprasad; Asir John Samuel,Abstract Background Deficiency in hip girdle neuromuscular control can cause exaggeratedDynamic Knee Valgus (DKV) which afflicts the knee joint and lead to knee injuries especiallyACL injury in sports. Though Kinesio taping (KT) is known to improve function; stability andproprioception; the evidence is inconclusive on its effectiveness in athletes. Wehypothesized that kinesio taping could enhance neuromuscular control of the hip girdlethere by causing a reduction in DKV. Aim/Objective To determine whether KT on Gluteusmedius can correct exaggerated dynamic knee valgus and improves hip abductor strengthwhen compared to sham KT. Method 40 collegiate level athletes; aged between 18 and 28years; of both genders with presence of dynamic knee valgus (> 8° for men and> 13° forwomen) were recruited in the study. Athletes were excluded if they had history of lower …,Journal of Bodywork and Movement Therapies,2017,*
Application cache replication to secondary application (s),*,Replicating a primary application cache that serves a primary application on one networknode into a secondary application cache that serves a secondary application on a secondnetwork node. Cache portions that are within the primary application cache are identified;and then identifiers (but not the cache portions) are transferred to the second network node.Once these identifiers are received; the cache portions that they identify may then beretrieved into the secondary application caches. This process may be repeatedly performedsuch that the secondary application cache moves towards the same state as the primaryapplication cache though the state of the primary application cache also changes as theprimary application operates by receiving read and write requests.,*,2017,*
External data access with split index,*,A split-index can be employed for access to external data. The index can be created on aprimary data storage system for data stored externally on a secondary data storage system.After creation; the index can be utilized to expedite at least query execution over theexternally stored data. The index can be updated upon detection of changes to data. Further;even when the index is not completely up to date; the index can be exploited for queryexecution. Furthermore; hybrid execution is enabled with the index and without the index.,*,2017,*
ROSA: R Optimizations with Static Analysis,Rathijit Sen; Jianqiao Zhu; Jignesh M Patel; Somesh Jha,Abstract: R is a popular language and programming environment for data scientists. It isincreasingly co-packaged with both relational and Hadoop-based data platforms and canoften be the most dominant computational component in data analytics pipelines. Recentwork has highlighted inefficiencies in executing R programs; both in terms of execution timeand memory requirements; which in practice limit the size of data that can be analyzed by R.This paper presents ROSA; a static analysis framework to improve the performance andspace efficiency of R programs. ROSA analyzes input programs to determine programproperties such as reaching definitions; live variables; aliased variables; and types ofvariables. These inferred properties enable program transformations such as C++ codetranslation; strength reduction; vectorization; code motion; in addition to interpretive …,arXiv preprint arXiv:1704.02996,2017,*
Determining data locality in a distributed system using aggregation of locality summaries,*,This specification describes methods; systems; and computer program products formaintaining data representing where each data block of multiple data blocks are storedamong multiple computing nodes. Each computing node generates a respective localitysummary based on locally stored data blocks; and submits the locality summary to acontrolling computing node.,*,2017,*
Development of electronics and data acquisition system for independent calibration of electron cyclotron emission radiometer,Praveena Kumari; Vismaysinh Raulji; Hitesh Mandaliya; Jignesh Patel; Varsha Siju; SK Pathak; Rachana Rajpal; R Jha,Abstract Signal conditioning units (SCU) along with Multichannel Data acquisition system(DAS) are developed and installed for automatization and frequent requirement of absolutecalibration of ECE radiometer system. The DAS is an indigenously developed economicalsystem which is based on Single Board Computer (SBC). The onboard RAM memory of 64 Kfor each channel enables the DAS for simultaneous and continuous acquisition. A Labviewbased graphical user interface provides commands locally or remotely to acquire; process;plot and finally save the data in binary format. The microscopic signals received fromradiometer are strengthened; filtered by SCU and acquired through DAS for the set time andat set sampling frequency. Stored data are processed and analyzed offline with Labviewutility. The calibration process has been performed for two hours continuously at different …,Fusion Engineering and Design,2016,*
A multidisciplinary team approach to efficient breast cancer diagnosis.,Mary E Cianfrocca; Melissa Shelby; Shefali Birdi; Stephanie Costa Byrum; Julie Annie Yee Billar; Kevin McCabe; Jignesh Patel; Vilert A Loving,88 Background: System inefficiencies result in delayed breast cancer diagnoses.Inefficiencies include any non-value added steps between symptom onset/imagingabnormality to cancer diagnosis and treatment. Diagnostic delays can lead to moreadvanced disease and may negatively impact survival. Further; optimizing the efficiency ofdiagnostic evaluation models can reduce barriers to care and improve patient satisfaction.To achieve these efficiency goals; Banner MD Anderson Cancer Center (BMDACC)instituted the Undiagnosed Breast Clinic (UBC). The UBC expedites patient evaluationthrough a multidisciplinary diagnostic team of internists; surgeons; pathologists andradiologists. Patients with an abnormality on physical exam or imaging are promptlyevaluated by the UBC team and any necessary diagnostic tests are performed. If …,*,2016,*
International Journal of Recent Scientific Research,Krishna Kumar; Prashant Mishra; Pranjali Dutt,ABSTRACT The present study is an attempt to find out the prevalence of anxiety; disruptivebehaviour and self absorbed problems of children with moderate intellectual disability (IQ:35-55). Sample comprised of 37 children randomly selected from 3 special schools formentally retarded children in Pondicherry.(Mean 11.5 years). Tools used were Binet Kamattest of intelligence (BKT) Vineland social maturity scale (VSMS) and Developmentalbehaviour checklist teacher version (DBC–T) Results reveal that gender difference wassignificant in influencing the anxiety and self absorbed problems of children with moderateintellectual disability; whereas age and area differences were not significant.,*,2015,*
Rethinking Benchmarking for Data,Jignesh M Patel,Benchmarking has been critical in making progress in the field of data; as it has provided a crucialmechanism to accelerate the progress in the data community. Early benchmarks have been responsiblefor spurring innovation and serving as a quantitative way to get past marketing salvos. Primeexamples of this observation are the Anon et al. benchmark and the Wisconsin benchmark thatspurred rapid advances in database transaction and analytic query processing. These dual technologiesare now crucial to running our “digital planet 1 ” today … However; data benchmarking haschanged considerably over the past four decades. In the early days; pioneers like Jim Gray andDavid DeWitt; were crucial in creating benchmarks that were genuinely designed to move thecommunity forward. Back then the data industry was in its “Wild West” days. A few good-meaningcowboys is all that it took to set the industry in the right direction … Sadly; those halcyon …,Technology Conference on Performance Evaluation and Benchmarking,2015,*
From Data to Insights@ Bare Metal Speed,Jignesh M Patel,Abstract Data analytics platforms today largely employ data processing kernels (egimplementation of selection and join operator algorithms) that were developed for a nowbygone hardware era. Hardware has made fundamental shifts in recent years; driven by theneed to consider energy as a first-class design parameter. Consequently; across theprocessor-IO hierarchy; the hardware paradigm today looks very different than it did just afew years ago. I argue that because of this shift; we are now building a'deficit'between thepace at which the hardware is evolving and the pace that is demanded of data processingkernels to keep up with the growth of big data. This deficit is unsustainable in the long run.One way to'pay off'this deficit is to have hardware and software co-evolve to exploit the fullpotential of the hardware. I will provide some examples of recent work from our Wisconsin …,Proceedings of the 2015 ACM SIGMOD International Conference on Management of Data,2015,*
Measurement and sweep-biasing circuit for langmuir probe diagnostic in SYMPLE,Pramila Gautam; Jignesh Patel; Rachana Rajpal; Chandresh Hanasalia; VP Anitha; Krishnamachari Sathyanarayana; Ratneshwar Jha,A device named SYMPLE is being developed at IPR to study high power microwave-plasmainteraction physics. The plasma that enables the proposed investigation needs to satisfycertain criteria in terms of its density ((1-10) X 10 18/m 3); uniform axial (∼ 1 m) and radial(∼ 10 cm) extends and a sharp gradient; with scale length of the order of the wavelength ofthe microwave; in the microwave-plasma interaction regime. In order to identify the rightparametric regime where the plasma meets with the required pre-requisites conditions;Langmuir Probe based measurements need to be routinely carried out to measure variousplasma parameters such as the electron density (ne); the electron temperature (T e); thefloating potential (V f); and the plasma potential (V p). The Langmuir Probe diagnosticselectronics along with biasing power supplies is installed in standard industrial racks with …,*,2015,*
Database query processing with reduce function configuration,*,A distributed system that includes multiple database compute nodes; each operating adatabase. A control node provides a database interface that offers a view on a singledatabase using parallel interaction with the multiple compute nodes. The control node helpsperform a map reduce operation using some or all of the compute nodes in response toreceiving a database query having an associated function that is identified as a reducefunction. The control node evaluates the target data of the database query to identify one ormore properties of the content of the target data. The reduce function is then configuredbased on these identified properties.,*,2014,*
Adapting Hash Joins For Modern Processors,Daniel Fabbri; Jignesh Patel; Thomas F Wenisch,ABSTRACT Hash join algorithms are crucial to the performance of modern databasesystems. Conventional hash joins exhibit poor memory system performance on modernprocessors because their key data structure; the bucket-chain hash table; is ill-suited for theperformance characteristics of out-of-order processors with large cache hierarchies.Whereas prior research has considered a variety of optimizations to reduce join latency;these studies fall short of asking whether the bucket-chain hash table is the right datastructure for modern systems. We propose a set of mechanisms that redesign the hash tableto better fit modern CPU architectures for primarykey/foreign-key hash joins. First; wepresent the collision cache; a data structure that densely packs hash join elements into anL1 cache line. Second; we examine the performance of the collision cache in partitioned …,University of Michigan. Accessed April,2014,*
VIRCATOR based on repetitive pulsed power generator,Rajesh Kumar; Jignesh Patel; Saurabh Kumar; A Shyam,A repetitive compact Tesla transformer and plasma-opening switch (POS) based VIRCATORsystem has been developed. This whole system generates electrical powers well in excessof 20 GW in a single shot and can be operated up-to 10 Hz. This electrical power isconverted into the microwave by using VIRCATOR with the efficiency around one percent.Plasma opening switch is being used as repetitive opening switch for enhancing the feedingvoltage to the axial VIRCATOR. Two power supplies 40 kV; 750 mA and 10 Hz are beingused for charging capacitors of Tesla and plasma guns of POS.,Pulsed Power Conference (PPC); 2013 19th IEEE,2013,*
Survey of School Psychologists' Actual and Preferred Roles; and Job Satisfaction in Wisconsin,Krystle A Kaifesh,*,*,2013,*
Comprehensive evaluation of PEGylated gold nanorods for two photon photoluminescence image guided radiation therapy enhancement,Rajiv Kumar; Janki Patel; Houari Korideck; Ross I Berbeco; Mike G Makrigiorgos; Srinivas Sridhar,Nanoparticle formulations of gold have shown a tremendous potential in various biomedicalapplications. The use of high atomic number (Z) materials presents an attractive approach inenhancing the therapeutic efficacy of the radiation therapy. The high Z number for gold (Z=79) makes them an ideal candidate for radiosensitization enhancement. The ability of theanisotropic gold nanorods to sustain the resonating surface plasmon with minimal dampingresults in highly efficient two-photon induced photoluminescence imaging. Here we presentthe synthesis and in vitro characterization of PEGylated gold nanorods as efficientradiosensitizing agents which can be imaged using inherent two-photon photoluminescencewithout a conjugated fluorophore. We have synthesized gold nanorods with an aspect ratioof 2.5 and functionalized the surface with different ratios of methoxy and amine PEG for …,*,2012,*
Algorithms for Deep Packet Inspection,Jignesh Patel,Deep Packet Inspection (DPI) is the core component of many networking devices on theInternet such as Network Intrusion Detection (or Prevention) Systems (NIDS/NIPS); rewalls;and layer 7 switches. In DPI; in addition to examining the packet headers; the entire contentsof each packet is compared against a set of signatures to check if any signature is found inthe packet or not. For instance; for security applications; each individual virus or attack threatis represented using one signature. The payload of each packet passing through thenetwork device is compared against the set of signatures; and a match indicates thecorresponding threat is found. Necessary action to neutralize the threat can then be taken.Application level signature analysis is also used for providing advanced QoS mechanisms;detecting peer-to-peer tra c; and in general application 1,*,2012,*
Special issue: best papers of VLDB 2009,Serge Abiteboul; Volker Markl; Tova Milo; Jignesh Patel,This issue contains journal versions of the six best papers accepted by the programcommittees of the Core Database Technology Track and the Infrastructure for InformationSystems Track. As usual for VLDB; the breadth of the papers mirrors the breadth of the VLDBConference; exemplifies the broad applicability of ideas from database systems; and is ashowcase for the activity of the field. All papers have been significantly revised; improved;and extended beyond their initial version that appeared at VLDB 2009 and went throughrounds of reviewing. We would like to thank the reviewers of these extended versions fortheir valuable comments. The paper “Preference Elicitation in Prioritized Skyline Queries”;by Denis Mindolin and Jan Chomicki; considers the evaluation of an important class ofpreference queries; called p-skyline. P-skyline queries generalize the standard notion of …,The VLDB Journal,2011,*
Proceedings of the VLDB Endowment Volume 2 Issue 2,Serge Abiteboul; Tova Milo; Jignesh Patel; Philippe Rigaux,*,*,2009,*
Query Languages and Evaluation Techniques for Biological Sequence Data,Sandeep Tata; Jignesh M Patel,In general; the term Quadtree refers to a class of representations of geometric entities (suchas points; line segments; polygons; regions) in a space of two (or more) dimensions; thatrecursively decompose the space containing these entities into blocks until the data in eachblock satisfy some condition (with respect; for example; to the block size; the number of blockentities; the characteristics of the block entities; etc.). In a more restricted sense; the termQuadtree (Octree) refers to a tree data-structure in which each internal node has four (eight)children and is used for the representation of geometric entities in a two (three) dimensionalspace. The root of the tree represents the whole space/region. Each child of a noderepresents a subregion of the subregion of its parent. The subregions of the siblingsconstitute a partition of the parent's regions. Several variations of quadtrees are possible …,*,2009,*
BatchGenAna: a batch platform for large-scale genomic analysis of mammalian small RNAs,Xiaomin Ying; You Jung Kim; Yiqing Mao; Ming Liu; Yanyan Hou; Hua Li; Xiaolei Wang; Yalin Zhao; Dongsheng Zhao; Jignesh M Patel; Wuju Li,Abstract An increasing number of small RNAs have been discovered in mammals. However;their primary transcripts and upstream regulatory networks remain largely to be determined.Genomic analysis of small RNAs facilitates identification of their primary transcripts; andhence contributes to researches of their upstream regulatory networks. We here report abatch platform; BatchGenAna; which is specifically designed for large-scale genomicanalysis of mammalian small RNAs. It can map and annotate for as many as 1000 smallRNAs or 10;000 genomic loci of small RNAs at a time. It provides genomic features includingRefSeq genes; mRNAs; ESTs and repeat elements in tabular and graphical results. It alsoallows extracting flanking sequences of submitted queries; specified genomic regions andhost transcripts; which facilitates subsequent analysis such as scanning transcription …,Bioinformation,2009,*
CASMIL: a comprehensive software/toolkit for image-guided neurosurgeries This research was supported in part by a research grant from Michigan Life Sciences C...,Gulsheen Kaur; Jun Tan; Mohammed Alam; Vipin Chaudhary; Dingguo Chen; Ming Dong; Hazem Eltahawy; Farshad Fotouhi; Christopher Gammage; Jason Gong; William Grosky; Murali Guthikonda; Jingwen Hu; Devkanak Jeyaraj; Xin Jin; Albert King; Joseph Landman; Jong Lee; Qing Hang Li; Hanping Lufei; Michael Morse; Jignesh Patel; Ishwar Sethi; Weisong Shi; King Yang; Zhiming Zhang,Background CASMIL aims to develop a cost-effective and efficient approach to monitor andpredict deformation during surgery; allowing accurate; and real-time intra-operativeinformation to be provided reliably to the surgeon. Method CASMIL is a comprehensiveImage-guided Neurosurgery System with extensive novel features. It is an integration ofvarious modules including rigid and non-rigid body co-registration (image-image; image-atlas; and image-patient); automated 3D segmentation; brain shift predictor; knowledgebased query tools; intelligent planning; and augmented reality. One of the vital and uniquemodules is the Intelligent Planning module; which displays the best surgical corridor on thecomputer screen based on tumor location; captured surgeon knowledge; and predictedbrain shift using patient specific Finite Element Model. Also; it has multi-level parallel …,*,2006,*
Practical methods for constructing suffix trees,Richard A Hankins; Sandeep Tata; Jignesh M Patel; Yuanyuan Tian,Sequence datasets are ubiquitous in modern life-science applications; and queryingsequences is a common and critical operation in many of these applications. The suffix treeis a versatile data structure that can be used to evaluate a wide variety of queries onsequence datasets; including evaluating exact and approximate string matches; and findingrepeat patterns. However; methods for constructing suffix trees are often very time-consuming; especially for suffix trees that are large and do not fit in the available mainmemory. Even when the suffix tree fits in memory; it turns out that the processor cachebehavior of theoretically optimal suffix tree construction methods is poor; resulting in poorperformance. Currently; there are a large number of algorithms for constructing suffix trees;but the practical tradeoffs in using these algorithms for different scenarios are not well …,*,2005,*
Storing and Querying XML Documents Without Using Schema Information,Kanda Runapongsa; Jignesh M Patel,Abstract As the popularity of eXtensible Markup Language (XML) continues to increase at anastonishing pace; data management systems for storing and querying large repositories ofXML data are urgently needed. In this paper; we investigate using a Relational DatabaseManagement System (RDBMS) for storing and querying XML data. We present a mappingscheme; called PAID; for mapping XML documents to relations in an RDBMS. Compared topreviously proposed mapping schemes; we demonstrate that the PAID mapping schemeresults in less response times by up to several orders of magnitude. The primary reason forthis performance improvement is that PAID includes information that the database can use toevaluate both direct and indirect containment queries efficiently.,The Second National Conference on Electronic Business,2003,*
Introduction to special issue with best papers from EDBT 2002,Christian S Jensen,*,*,2003,*
Efficiency and Effectiveness of XML Tools and Techniques (EEXTT)-Benchmarking XML-The Michigan Benchmark: A Microbenchmark for XML Query Processing Sy...,Kanda Runapongsa; Jignesh M Patel; HV Jagadish; Shurug Al-Khalifa,*,Lecture Notes in Computer Science,2003,*
The magazine archive includes every article published in Communications of the ACM for over the past 50 years.,Akhilesh Chandra; Thomas Calderon,Information systems (IS) are quickly emerging as critical resources to be leveraged fororganizational productivity in many business; social; and economic enterprises. Theexplosive growth in information technology (IT) can be broadly attributed to the emergingnovel linkages of IS/IT with several base disciplines; extending the reach of IS/IT toapplication domains never previously considered.In this article; we focus on certainimportant and promising IS/IT frontiers identified from the perspectives of academia; industry;and federal research funding agencies. Our objective is to focus the collective awareness ofthe IS community and those in related disciplines on some of the frontier developments inIS/IT with a vision of the road ahead and point to challenges and opportunities [1].,Communications of the ACM,2000,*
Clone Join and Shadow Join: TWO Parallel Algorithms for Executing Spatial Join Operatiuns Jignesh Patel David DeWitt Technical Report# 1399,Jignesh Patel,Abstract With the growing popularity of spatial applications; there has been a signiﬁcantincrease in the use of database systems for storing and querying spatial data. Spatial data isnow readily available from a variety of sources including government mapping agencies;commercial sources; satellite images; and simulation outputs. As this trend continues;applications continue to execute increasingly complex queries on large and larger volumesof spatial data. As can be expected; these complex spatial queries frequently involve joiningtwo data sets based on some spatial relationship between objects in the two data sets. Thisoperation is called a spatial join; and like its relational counterpart; is an expensiveoperation. Consequently; spatial database systems must employ efficient spatial joinalgorithms. In the past; many algorithms have been proposed for evaluating a spatial join …,*,1999,*
Building a Scalable Geo-Spatial DBMS: Technology; Implementation; and Evaluation,Jignesh Patel Jiebing; Jignesh Patel; Jiebing Yu; Navin Kabra; Kristin Tufte; Biswadeep Nag; Josef Burger; Nancy Hall; Karthikeyan Ramasamy; Roger Lueder; Curt Ellmann; Jim Kupsch; Shelly Guo; Johan Larson; David Dewitt; Jeffrey Naughton,Abstract This paper presents a number of new techniques for parallelizing geo-spatialdatabase systems and discusses their implementation in the Paradise object-relationaldatabase system. The effectiveness of these techniques is demonstrated using a variety ofcomplex geo-spatial queries over a 120 GB global geo-spatial data set. 1. Introduction andMotivation The past ten years have seen a great deal of research devoted to extendingrelational database systems to handle geo-spatial workloads; in fact; handling theseworkloads has been one of the driving forces for object-relational database technology.While researchers have always acknowledged the existence of very large data sets in thegeo-spatial domain; the vast majority of research to date has focused on language issues oruniprocessor query evaluation and indexing techniques. This is unfortunate; since the …,In Proceedings of the ACM SIGMOD Conference,1997,*
A survey of Midwest employee recreation programs conducted outdoors,Kevin A Falkenberg,*,*,1986,*
Survey of the attitudes of superintendents; school board presidents; and principals toward health education by school district size,Janice Lee Thornberg,*,*,1979,*
A survey of parental attitudes concerning the acceptance of death education in the curriculum at Cashton High School; Cashton; Wisconsin,Gary Hanson,*,*,1978,*
A Survey of Practicing Pharmacists in Wisconsin,David Stewart Forbes,*,*,1971,*
A survey of student lighting conditions at the University of Wisconsin,William Francis Cormack,*,*,1939,*
The clinical significance of high T waves in the electrocardiogram,Lester Paul Brillman,*,*,1938,*
A Clinical Survey of Cord Bladder,Henry Adolph Anderson,*,*,1937,*
LaTiCE 2017,Adalbert Gerald Soosai Raj; Kasama Ketsuriyonk; Jignesh M Patel; Richard Halverson,What Do Students Feel about Learning Programming Using Both English and Their NativeLanguage? ..................................................................................................................1 Adalbert GeraldSoosai Raj; Kasama Ketsuriyonk; Jignesh M. Patel; and Richard Halverson … Session 2: OnlineTools for Thinking and Assessment … Students' Types of Argumentative Knowledge ConstructionProcess in Social Collaborative Learning Environment ........................................................................................9 Siti Nur Khadijah Aishah Ibrahim and Jamalludin Harun … The Effect ofScenario-Epistemic Game on Higher Order Thinking Skills among High School Chemistry Studentsin Malaysia ...........................................................................16 Kho Pui Wun and Jamalludin Harun… A Perspective from Vietnamese Students on Teaching of Soft Skills ..................................................23 Huu-Phuc Vo; Anders Berglund; and Mats Daniels,*,*,*
What Do Students Feel About Learning Programming Using Both English And Their Native,Adalbert Gerald Soosai Raj; Kasama Ketsuriyonk; Jignesh M Patel; Richard Halverson,Abstract—Programming is taught in India using English as the medium of instruction tostudents whose native language is not English. This places a high cognitive load onstudents who learn programming for the first time and who are not very proficient in English.Our study aims at finding out what the students feel if their native language is used alongwith English for teaching programming. As a part of our study; we taught linked list; a basicconcept in programming; to two groups of undergraduate students for a week in Tamil Nadu;India. We used English to teach one group of students and English and Tamil (the nativelanguage in Tamil Nadu) to teach the other group. Our intervention consisted of 3 lecturesand 1 live-coding session. We collected qualitative data by means of an openendedfeedback from the students. The analysis of this feedback shows that students have …,*,*,*
Adaptive Concurrent Query Execution Framework for an Analytical In-Memory Database System-Supplemental Material,Harshad Deshmukh; Hakan Memisoglu; Jignesh M Patel,Work done for executing a query in Quickstep is split into multiple work orders. A work order containsall the information that is needed to process tuples in a given data block. A work order encapsulatesthe relational operator that is being applied; the relevant input relation(s); location of the inputdata block; any predicate(s) to be applied on the tuples in the input block; and descriptors toother run-time structures (such as hash tables). Consider the following full table scan query toillustrate the work order concept … SELECT name FROM Employee WHERE city='SanDiego' … The plan for this query has a simple selection operator. For the selection operator;the number of work orders is same as the number of input blocks in the Employee table. Eachselection work order contains the following information … • Relation: Employee; attribute: name• Predicate: city='San Diego' • The unique ID of an input block from the Employee table …,*,*,*
Molecular Re-Classification of renal disease through approximate graph matching; clustering and pattern mining.,Ramakrishna Varadarajan; Felix Eichinger; Jignesh Patel; Matthias Kretzler,Classification of patients with a chronic disease course; such as kidney diseases; usesmainly descriptive disease definitions. To develop molecular based disease stratification; weaimed to define patient subgroups by conserved transcriptional networks. Defining similarityof patients on a regulatory network level; rather than on an individual gene level; might yieldmore robust indicators of function. Network nodes for each patient were derived fromAffymetrix microarrays of kidney biopsies compared to healthy controls. Subsequently;relations between the nodes were established by natural language processing of PubMedabstracts and automated promoter analysis for transcription factor binding sites. Theresulting networks are typically noisy or incomplete in nature; therefore network similaritiesare determined through an approximate graph-matching tool; allowing a degree of …,*,*,*
Data Engineering,Hongchan Roh; Sanghyun Park; Mincheol Shin; Sang-Won Lee; Yulei Fan; Wenyu Lai; Xiaofeng Meng; Kwanghyun Park; Yang-Suk Kee; Jignesh M Patel; Jaeyoung Do; Chanik Park; David J DeWitt; Woon-Hak Kang; Bongki Moon; Gi-Hwan Oh; Changwoo Min,Bulletin of the Technical Committee on Data Engineering June 2014 Vol. 37 No. 2 IEEE ComputerSociety Letters Letter from the Editor-in-Chief...................................................... David Lomet 1 Letterfrom the Special Issue Editor................................................ Per-Ake Larson 2 Special Issue on AdaptingDatabase Systems to Flash Storage Search: Multi-Path Search for Tree-based Indexes to ExploitInternal Parallelism of Flash SSDs … Editorial Board Editor-in-Chief DavidB. Lomet Microsoft Research One Microsoft Way Redmond; WA 98052; USA lomet@microsoft. com Associate Editors Juliana Freire Polytechnic Institute of New York University 2MetroTech Center; 10th floor Brooklyn NY 11201-3840 Paul Larson Microsoft Research OneMicrosoft Way Redmond; WA 98052 Sharad Mehrotra Department of Computer Science Universityof California; Irvine Irvine; CA 92697 S. Sudarshan Computer Science and Engineering …,*,*,*
LECTURE SERIES,Jignesh Patel,Jignesh Patel is a Professor in Computer Sciences at the University of Wisconsin-Madison;which is where he also got his PhD. He has worked in the area of databases (now called“big data”) for over two decades. He is the recipient of an NSF Career Award; and multipleGoogle; IBM; Microsoft; and Oracle faculty awards. His papers have been selected as the“best papers in the conference” at VLDB (2012); SIGMOD (2011); and ICDE (2010; 2011).He also has a strong interest in seeing research ideas transition to actual products. Histhesis work was commercialized via an acquisition by NCR/Teradata. He also co-foundedLocomatix; a startup that built a platform to power real-time data-driven mobile services.Locomatix became part of Twitter in 2013. Jignesh is also an ACM Distinguished Scientist.He blogs at bigfastdata. blogspot. com.,*,*,*
2008 IEEE 24th International Conference on Data Engineering (ICDE'08),G Koloniari; E Pitoura,The use of atomic commit protocols in mobile ad-hoc networks involves difficulties in settingup reasonable time-outs for aborting a pending distributed transaction. This paper presentsthe non-blocking adjourn state; a concurrency control modification which makes time-outs inan atomic commit protocol for aborting a transaction unnecessary. Further; it enhancesconcurrency among transactions performing...,*,*,*
Event Extraction in The Twittersphere,Adel Ardalan; Qian Wan; Nikesh Garera; AnHai Doan; Jignesh Patel,Twitter is an online microblogging platform which allows its users to post messages of lengthup to 140 characters. Users share their opinions; and promote and discuss current events.An event in the Twittersphere happens when many users tweet about a subject (possibly; areal-world event) at a particular time. Table 1 shows some sample events and theirattributes. An emerging event is an event such that the number of Twitter users tweetingabout it rises to a significant number; over a certain period of time. That is; an event is anemerging one at a particular time if (1) a considerable number of people are discussing it (itis hot) and (2) there are considerably more people talking about the event than before (it isemerging).,*,*,*
Online Replica Placement in Cloud Environments,Avrilia Floratou; Navneet Potti; Jignesh M Patel,Database-as-a-Service (DaaS) providers need to provide performance and availabilityguarantees to their customers; typically in the form of Service Level Objectives (SLOs).Replication is a key mechanism that is used to meet availability targets. A critical challengeis to meet a target availability goal while minimizing the total operating cost. In multi-tenantenvironments where each tenant needs only a fraction of the resources of a single node (eg;in [1]); the degree of multi-tenant concurrency per node is high; which makes guaranteeingthe performance SLOs challenging. Another challenge is that the DaaS providers typicallyhave an estimate of the workloads that they expect to serve; but the actual workloadcharacteristics may deviate from this estimate. An online data placement algorithm (asopposed to offline techniques; such as [2])) tackles exactly this situation–it finds a …,*,*,*
Senior program committee members,Divy Agrawal; Francesco Bonchi; Lei Chen; Bruce Croft; Gautam Das; Lise Getoor; Dimitrios Gunopulos; Jiawei Han; Bingsheng He; Jimmy Huang; Panos Kalnis KAUST Saudi Arabia; George Karypis; Irwin King; Guoliang Li; Ee-Peng Lim; Xuemin Lin; Huan Liu; Raymond Ng; M Tamer Ozsu; Yannis Papakonstantinou; Jignesh M Patel; Kyuseok Shim; Vincent Tseng; Liqiang Wang; Ji-Rong Wen; Jianliang Xu; Ben Zhao,Page 1. Senior Program Committee Members Name Organization Country Karl Aberer EcolePolytechnique Federale de Lausanne (EPFL) Switzerland Divy Agrawal University of California;Santa Barbara USA Francesco Bonchi Yahoo! Research USA Lei Chen Hong Kong Universityof Science and Technology China Bruce Croft University of Massachusetts Amherst USA GautamDas University of Texas at Arlington USA Shirshanka Das LinkedIn USA Juliana Freire NYUPoly USA Rainer Gemulla Max-Planck-Institute für Informatik Germany Lise Getoor Universityof California; Santa Cruz USA Dimitrios Gunopulos University of Athens Greece Jiawei HanUniversity of Illinois at Urbana-Champaign USA Bingsheng He Nanyang TechnologicalUniversity Singapore Jimmy Huang York University Canada Panos Kalnis KAUST Saudi ArabiaGeorge Karypis University of Minnesota USA …,*,*,*
Hideaki SUGAWARA; National Institute of Genetics Anthony Kum Hoe TUNG; National University of Singapore,Klaus-Peter ADLASSNIG; Abdelghani BELLAACHIA; Noel BONNET; Young Moon CHAE; Jake CHEN; Yi-Ping Phoebe CHEN; Jin Wook CHOI; Susumu GOTO; Wynne HSU; Ela HUNT; Gon KHANG; Hajime KITAKAMI; Mong Li LEE; Hideo MATSUDA; Vasilis MEGALOOIKONOMOU; Kensaku MORI; Frank OLKEN; Z Meral OZSOYOGLU; Srinivasan PARTHASARATHY; Jignesh M PATEL; Isidore RIGOUTSOS; Ambuj K SINGH,Page 1. Program Committee Klaus-Peter ADLASSNIG; Medical University of ViennaAbdelghani BELLAACHIA; George Washington University Noel BONNET; University of ReimsYoung Moon CHAE; Yonsei University Jake CHEN; Indiana University Yi-Ping Phoebe CHEN;Deakin University Jin Wook CHOI; Seoul National University Terry GAASTERLAND; RockfellerUniversity Susumu GOTO; Kyoto University Wynne HSU; National University of SingaporeEla HUNT; University of Glasgow Shigehiko KANAYA; Nara Institute of Science andTechnology (NAIST) Gon KHANG; Kyung Hee University Hajime KITAKAMI; Hiroshima CityUniversity Mong Li LEE; National University of Singapore Hideo MATSUDA; Osaka UniversityVasilis MEGALOOIKONOMOU; Temple University Kensaku MORI; Nagoya University FrankOLKEN; Lawrence Berkeley National Laboratory …,*,*,*
Towards Integrated Data Center Design,Avrilia Floratou; Frank Bertsch; Jignesh M Patel; Georgios Laskaris,ABSTRACT Data center design is a tedious and expensive process. Recently; this processhas become even more challenging as users of cloud services expect to have guaranteedlevels of availability; durability and performance. A new challenge for the service providers isto find the most cost-effective data center design and configuration that will accommodatethe users' expectations; on ever-changing workloads; and constantly evolving hardware andsoftware components. In this paper; we argue that data center design should become asystematic process. First; it should be done using an integrated approach that takes intoaccount both the hardware and the software interdependencies; and their impact on users'expectations. Second; it should be performed in a “wind tunnel”; which uses large-scalesimulation to systematically explore the impact of a data center configuration on both the …,*,*,*
1EEE TRANSACTIONS ON COMPUTERS; VOL. C-33; NO. 11; NOVEMBER 1984,BW Arden; D DeWitt; K Irani; K Padmanabhan; KD Smith; CN Arnold; RJ Douglass; DR Jefferson; J Patel; SR Stemnberg; JL Baer; RA Finkel; HF Jordon; CV Ramamoorthy; H Stone; B Berra; D Gajski; HT Kung; TA Rice; D Towsley,Leah H. Jamieson (S'75-M'77) was born in Trenton; NJ; on August 27; 1949. She receivedthe SB degree in mathematics in 1972 from the Massachusetts Institute of Technology; f _Cambridge; MA; and the MA and MSE degrees in 1974; and the Ph. D. degree in 1977; all inelectrical engineering and computer science from Princeton University; Princeton; NJ. Since1976 she has been on the Faculty of the School of Electrical Engineering; Purdue University;West Lafayette; IN; where she is currently an Associate Professor. Her research interestsinclude the design and analysis of parallel processing algorithms; the modeling of parallelprocesses; and speech analysis and recognition.,*,*,*
Design and Evaluation of Online Replica Placement Algorithms,Avrilia Floratou; Jignesh M Patel; Willis Lang,*,*,*,*
Efficient Filtering and Routing in a Scalable XML-Based Publish-Subscribe System,Yuanyuan Tian; Jignesh M Patel; Farnam Jahanian,Abstract This paper introduces YAK–a scalable contentbased publish-subscribe system.YAK employs XML documents and expressive XPath queries as the publication andsubscription model. To achieve high scalability; it combines the advantages of contentrouting in existing publish-subscribe systems and the efficient query indexing technique inthe context of XML filtering. The filtering and routing strategy used in YAK exploits the localityof subscribers and therefore dramatically reduces the network communication overhead.Through performance tests; we conclude that our YAK publish-subscribe model is highlyscalable; especially when subscriptions exhibit high selectivity and regionalism.,*,*,*
Rethinking Designs for Managing Multi-Tenant OLTP Workloads on SSD-based I/O Subsystems,Ning Zhang; Junichi Tatemura; Jignesh M Patel; Hakan Hacıgümüs,ABSTRACT Multi-tenancy is a common practice that is employed to maximize server'sresources and reduce the total cloud operation costs. The focus of this work is on multi-tenancy for OLTP workloads. Several designs for OLTP multi-tenancy have been proposedthat vary the trade-offs made between between performance and isolation. However;existing studies have not considered the impact of OLTP multi-tenancy designs when usingan SSD-based I/O subsystem. The focus of this work is on examining and comparing arange of multi-tenancy designs for OLTP workloads on an SSD-based I/O subsystem. Wecompare three designs using both open-source and proprietary DBMSs. Our study revealsthat in contrast to the case of an HDD-based I/O subsystem; VM-based designs have fairlycompetitive performance to the non-virtualized designs (generally within 1.3–2X of the …,*,*,*
PROGRAM VICE-CHAIRS,Anastassia Ailamaki; Alfons Kemper; Kian-Lee Tan; Kyuseok Shim; Jayavel Shanmugasundaram; Gustavo Alonso; Wolfgang Nejdl; Sharad Mehrotra; Phillip Gibbons; Jayant R Haritsa; Jignesh M Patel; Evaggelia Pitoura; Takahiro Hara,Page 1. xxiv Program Committee PROGRAM VICE-CHAIRS Database System Internals andPerformance Anastassia Ailamaki; Carnegie Mellon University; USA Query Processing andOptimization Alfons Kemper; Technical University of Munich; Germany Data Warehouse; OLAP;and Statistical Databases Kian-Lee Tan; National University of Singapore; Singapore MiningData; Text and Web Kyuseok Shim; Seoul National University; Korea Semi-structured Dataand XML Jayavel Shanmugasundaram; Cornell University; USA Middleware; Web Services;and Workflow Gustavo Alonso; ETH Zürich; Switzerland Heterogeneity; Semantic Web; andMetadata Wolfgang Nejdl; University of Hannover; Germany Privacy and Security SharadMehrotra; University of California; Irvine; USA Stream Processing; Continuous Queries; andSensor Databases Phillip Gibbons; Intel Research; USA …,*,*,*
Towards Cost-Effective Storage Provisioning for DBMSs (Extended Version),Ning Zhang; Junichi Tatemura; Jignesh M Patel; Hakan Hacigumus,ABSTRACT Data center operators face a bewildering set of choices when considering howto provision resources on machines with complex I/O subsystems. Modern I/O subsystemsoften have a rich mix of fast; high performing; but expensive SSDs sitting alongside withcheaper but relatively slower (for random accesses) traditional hard disk drives. The datacenter operators need to determine how to provision the I/O resources for specific workloadsso as to abide by existing Service Level Agreements (SLAs); while minimizing the totaloperating cost (TOC) of running the workload; where the TOC includes the amortizedhardware costs and the run time energy costs. The focus of this paper is on introducing thisnew problem of TOC-based storage allocation; cast in a framework that is compatible withtraditional DBMS query optimization and query processing architecture. We also present …,*,*,*
Data Morphing: An Adaptive; Cache-Conscious Storage,Richard A Hankins; Jignesh M Patel,*,*,*,*
Structural Joins: A Primitive for Efficient XML Query Pattern Matching Shurug Al-Khalifa Univ of Michigan shurug@ eecs. umich. edu,Jignesh M Patel; Divesh Srivastava; Yuqing Wu,Abstract XML queries typically specify patterns of selection predicates on multiple elementsthat have some specified tree structured relationships. The primitive tree structuredrelationships are parent-child and ancestor-descendant; and finding all occurrences of thesestructural relationships in an XML database is a core operation for XML query processing. Inthis paper; we develop two families of structural join algorithms for this task: tree-merge andstack-tree. The tree-merge algorithms are a natural extension of traditional merge joins andthe recently proposed multi-predicate merge joins; while the stack-tree algorithms have nocounterpart in traditional relationaljoin processing. We present experimental results on arange of data and queries using (i) the TimbER native XML query engine built on top ofSHOR E; and (ii) a commercial relational database system. In all cases; our structural join …,*,*,*
