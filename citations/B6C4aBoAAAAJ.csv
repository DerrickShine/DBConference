Hexastore: sextuple indexing for semantic web data management,Cathrin Weiss; Panagiotis Karras; Abraham Bernstein,Abstract Despite the intense interest towards realizing the Semantic Web vision; mostexisting RDF data management schemes are constrained in terms of efficiency andscalability. Still; the growing popularity of the RDF format arguably calls for an effort to offsetthese drawbacks. Viewed from a relational-database perspective; these constraints arederived from the very nature of the RDF data model; which is based on a triple format.Recent research has attempted to address these constraints using a vertical-partitioningapproach; in which separate two-column tables are constructed for each property. However;as we show; this approach suffers from similar scalability drawbacks on queries that are notbound by RDF property value. In this paper; we propose an RDF storage scheme that usesthe triple nature of RDF as an asset. This scheme enhances the vertical partitioning idea …,Proceedings of the VLDB Endowment,2008,593
Fast data anonymization with low information loss,Gabriel Ghinita; Panagiotis Karras; Panos Kalnis; Nikos Mamoulis,Abstract Recent research studied the problem of publishing microdata without revealingsensitive information; leading to the privacy preserving paradigms of k-anonymity and l-diversity. k-anonymity protects against the identification of an individual's record. l-diversity;in addition; safeguards against the association of an individual with specific sensitiveinformation. However; existing approaches suffer from at least one of the followingdrawbacks:(i) The information loss metrics are counter-intuitive and fail to capture datainaccuracies inflicted for the sake of privacy.(ii) l-diversity is solved by techniques developedfor the simpler k-anonymity problem; which introduces unnecessary inaccuracies.(iii) Theanonymization process is inefficient in terms of computation and I/O cost. In this paper wepropose a framework for efficient privacy preservation that addresses these deficiencies …,Proceedings of the 33rd international conference on Very large data bases,2007,269
One-pass wavelet synopses for maximum-error metrics,Panagiotis Karras; Nikos Mamoulis,Abstract We study the problem of computing wavelet-based synopses for massive data setsin static and streaming environments. A compact representation of a data set is obtainedafter a thresholding process is applied on the coefficients of its wavelet decomposition.Existing polynomial-time thresholding schemes that minimize maximum error metrics aredisadvantaged by impracticable time and space complexities and are not applicable in adata stream context. This is a cardinal issue; as the problem at hand in its most practicallyinteresting form involves the time-efficient approximation of huge amounts of data;potentially in a streaming environment. In this paper we fill this gap by developing efficientand practicable wavelet thresholding algorithms for maximum-error metrics; for both a staticand a streaming case. Our algorithms achieve near-optimal accuracy and superior …,Proceedings of the 31st international conference on Very large data bases,2005,80
A framework for efficient data anonymization under privacy and accuracy constraints,Gabriel Ghinita; Panagiotis Karras; Panos Kalnis; Nikos Mamoulis,Abstract Recent research studied the problem of publishing microdata without revealingsensitive information; leading to the privacy-preserving paradigms of k-anonymity and l-diversity. k-anonymity protects against the identification of an individual's record. l-diversity;in addition; safeguards against the association of an individual with specific sensitiveinformation. However; existing approaches suffer from at least one of the followingdrawbacks:(i) l-diversification is solved by techniques developed for the simpler k-anonymization problem; causing unnecessary information loss.(ii) The anonymizationprocess is inefficient in terms of computational and I/O cost.(iii) Previous research focusedexclusively on the privacy-constrained problem and ignored the equally important accuracy-constrained (or dual) anonymization problem. In this article; we propose a framework for …,ACM Transactions on Database Systems (TODS),2009,77
ρ-uncertainty: inference-proof transaction anonymization,Jianneng Cao; Panagiotis Karras; Chedy Raïssi; Kian-Lee Tan,Abstract The publication of transaction data; such as market basket data; medical records;and query logs; serves the public benefit. Mining such data allows for the derivation ofassociation rules that connect certain items to others with measurable confidence. Still; thistype of data analysis poses a privacy threat; an adversary having partial information on aperson's behavior may confidently associate that person to an item deemed to be sensitive.Ideally; an anonymization of such data should lead to an inference-proof version thatprevents the association of individuals to sensitive items; while otherwise allowing for truthfulassociations to be derived. Original approaches to this problem were based on valueperturbation; damaging data integrity. Recently; value generalization has been proposed asan alternative; still; approaches based on it have assumed either that all items are equally …,Proceedings of the VLDB Endowment,2010,73
SABRE: a Sensitive Attribute Bucketization and REdistribution framework for t-closeness,Jianneng Cao; Panagiotis Karras; Panos Kalnis; Kian-Lee Tan,Abstract Today; the publication of microdata poses a privacy threat: anonymous personalrecords can be re-identified using third data sources. Past research has tried to develop aconcept of privacy guarantee that an anonymized data set should satisfy before publication;culminating in the notion of t-closeness. To satisfy t-closeness; the records in a data set needto be grouped into Equivalence Classes (ECs); such that each EC contains records ofindistinguishable quasi-identifier values; and its local distribution of sensitive attribute (SA)values conforms to the global table distribution of SA values. However; despite this progress;previous research has not offered an anonymization algorithm tailored for t-closeness. In thispaper; we cover this gap with SABRE; a SA Bucketization and REdistribution framework for t-closeness. SABRE first greedily partitions a table into buckets of similar SA values and …,The VLDB Journal—The International Journal on Very Large Data Bases,2011,65
Stochastic database cracking: Towards robust adaptive indexing in main-memory column-stores,Felix Halim; Stratos Idreos; Panagiotis Karras; Roland HC Yap,Abstract Modern business applications and scientific databases call for inherently dynamicdata storage environments. Such environments are characterized by two challengingfeatures:(a) they have little idle system time to devote on physical design; and (b) there islittle; if any; a priori workload knowledge; while the query and data workload keeps changingdynamically. In such environments; traditional approaches to index building andmaintenance cannot apply. Database cracking has been proposed as a solution that allowson-the-fly physical data reorganization; as a collateral effect of query processing. Crackingaims to continuously and automatically adapt indexes to the workload at hand; withouthuman intervention. Indexes are built incrementally; adaptively; and on demand.Nevertheless; as we show; existing adaptive indexing methods fail to deliver workload …,Proceedings of the VLDB Endowment,2012,64
H 2 RDF+: High-performance distributed joins over large-scale RDF graphs,Nikolaos Papailiou; Ioannis Konstantinou; Dimitrios Tsoumakos; Panagiotis Karras; Nectarios Koziris,The proliferation of data in RDF format calls for efficient and scalable solutions for theirmanagement. While scalability in the era of big data is a hard requirement; modern systemsfail to adapt based on the complexity of the query. Current approaches do not scale wellwhen faced with substantially complex; non-selective joins; resulting in exponential growthof execution times. In this work we present H 2 RDF+; an RDF store that efficiently performsdistributed Merge and Sort-Merge joins over a multiple index scheme. H 2 RDF+ is highlyscalable; utilizing distributed MapReduce processing and HBase indexes. Utilizingaggressive byte-level compression and result grouping over fast scans; it can process bothcomplex and selective join queries in a highly efficient manner. Furthermore; it adaptivelychooses for either single-or multi-machine execution based on join complexity estimated …,Big Data; 2013 IEEE International Conference on,2013,57
Publishing microdata with a robust privacy guarantee,Jianneng Cao; Panagiotis Karras,Abstract Today; the publication of microdata poses a privacy threat. Vast research hasstriven to define the privacy condition that microdata should satisfy before it is released; anddevise algorithms to anonymize the data so as to achieve this condition. Yet; no methodproposed to date explicitly bounds the percentage of information an adversary gains afterseeing the published data for each sensitive value therein. This paper introduces β-likeness;an appropriately robust privacy model for microdata anonymization; along with twoanonymization schemes designed therefore; the one based on generalization; and the otherbased on perturbation. Our model postulates that an adversary's confidence on thelikelihood of a certain sensitive-attribute (SA) value should not increase; in relativedifference terms; by more than a predefined threshold. Our techniques aim to satisfy a …,Proceedings of the VLDB Endowment,2012,49
Fast random graph generation,Sadegh Nobari; Xuesong Lu; Panagiotis Karras; Stéphane Bressan,Abstract Today; several database applications call for the generation of random graphs. Afundamental; versatile random graph model adopted for that purpose is the Erdős-Rényi Γ v;p model. This model can be used for directed; undirected; and multipartite graphs; with andwithout self-loops; it induces algorithms for both graph generation and sampling; hence isuseful not only in applications necessitating the generation of random structures but also forsimulation; sampling and in randomized algorithms. However; the commonly advocatedalgorithm for random graph generation under this model performs poorly when generatinglarge graphs; and fails to make use of the parallel processing capabilities of modernhardware. In this paper; we propose PPreZER; an alternative; data parallel algorithm forrandom graph generation under the Erdős-Rényi model; designed and implemented in a …,Proceedings of the 14th international conference on extending database technology,2011,48
Exploiting duality in summarization with deterministic guarantees,Panagiotis Karras; Dimitris Sacharidis; Nikos Mamoulis,Abstract Summarization is an important task in data mining. A major challenge over the pastyears has been the efficient construction of fixed-space synopses that provide adeterministic quality guarantee; often expressed in terms of a maximum-error metric.Histograms and several hierarchical techniques have been proposed for this problem.However; their time and/or space complexities remain impractically high and depend notonly on the data set size n; but also on the space budget B. These handicaps stem from arequirement to tabulate all allocations of synopsis space to different regions of the data. Inthis paper we develop an alternative methodology that dispels these deficiencies; thanks toa fruitful application of the solution to the dual problem: given a maximum allowed error;determine the minimum-space synopsis that achieves it. Compared to the state-of-the-art …,Proceedings of the 13th ACM SIGKDD international conference on Knowledge discovery and data mining,2007,42
Scalable parallel minimum spanning forest computation,Sadegh Nobari; Thanh-Tung Cao; Panagiotis Karras; Stéphane Bressan,Abstract The proliferation of data in graph form calls for the development of scalable graphalgorithms that exploit parallel processing environments. One such problem is thecomputation of a graph's minimum spanning forest (MSF). Past research has proposedseveral parallel algorithms for this problem; yet none of them scales to large; high-densitygraphs. In this paper we propose a novel; scalable; parallel MSF algorithm for undirectedweighted graphs. Our algorithm leverages Prim's algorithm in a parallel fashion;concurrently expanding several subsets of the computed MSF. Our effort focuses onminimizing the communication among different processors without constraining the localgrowth of a processor's computed subtree. In effect; we achieve a scalability that previousapproaches lacked. We implement our algorithm in CUDA; running on a GPU and study …,ACM SIGPLAN Notices,2012,37
TOUCH: in-memory spatial join by hierarchical data-oriented partitioning,Sadegh Nobari; Farhan Tauheed; Thomas Heinis; Panagiotis Karras; Stéphane Bressan; Anastasia Ailamaki,Abstract Efficient spatial joins are pivotal for many applications and particularly important forgeographical information systems or for the simulation sciences where scientists work withspatial models. Past research has primarily focused on disk-based spatial joins; efficient in-memory approaches; however; are important for two reasons: a) main memory has grown solarge that many datasets fit in it and b) the in-memory join is a very time-consuming part of alldisk-based spatial joins. In this paper we develop TOUCH; a novel in-memory spatial joinalgorithm that uses hierarchical data-oriented space partitioning; thereby keeping both itsmemory footprint and the number of comparisons low. Our results show that TOUCHoutperforms known in-memory spatial-join algorithms as well as in-memory implementationsof disk-based join approaches. In particular; it has a one order of magnitude advantage …,Proceedings of the 2013 ACM SIGMOD International Conference on Management of Data,2013,35
H 2 RDF+: an efficient data management system for big RDF graphs,Nikolaos Papailiou; Dimitrios Tsoumakos; Ioannis Konstantinou; Panagiotis Karras; Nectarios Koziris,Abstract The proliferation of data in RDF format has resulted in the emergence of a plethoraof specialized management systems. While the ability to adapt to the complexity of aSPARQL query--given their inherent diversity--is crucial; current approaches do not scalewell when faced with substantially complex; non-selective joins; resulting in exponentialgrowth of execution times. In this demonstration we present H2 RDF+; an RDF store thatefficiently performs distributed Merge and Sort-Merge joins using a multiple-index schemeover HBase indexes. Through a greedy planner that incorporates our cost-model; itadaptively commands for either single or multi-machine query execution based on joincomplexity. In this paper; we present its key scientific contributions and allow participants tointeract with an H2RDF+ deployment over a Cloud infrastructure. Using a web-based GUI …,Proceedings of the 2014 ACM SIGMOD international conference on Management of data,2014,31
Anonymizing set-valued data by nonreciprocal recoding,Mingqiang Xue; Panagiotis Karras; Chedy Raïssi; Jaideep Vaidya; Kian-Lee Tan,Abstract Today there is a strong interest in publishing set-valued data in a privacy-preserving manner. Such data associate individuals to sets of values (eg; preferences;shopping items; symptoms; query logs). In addition; an individual can be associated with asensitive label (eg; marital status; religious or political conviction). Anonymizing such dataimplies ensuring that an adversary should not be able to (1) identify an individual's record;and (2) infer a sensitive label; if such exists. Existing research on this problem eitherperturbs the data; publishes them in disjoint groups disassociated from their sensitive labels;or generalizes their values by assuming the availability of a generalization hierarchy. In thispaper; we propose a novel alternative. Our publication method also puts data in ageneralized form; but does not require that published records form disjoint groups and …,Proceedings of the 18th ACM SIGKDD international conference on Knowledge discovery and data mining,2012,31
Sensitive label privacy protection on social network data,Yi Song; Panagiotis Karras; Qian Xiao; Stéphane Bressan,Abstract This paper is motivated by the recognition of the need for a finer grain and morepersonalized privacy in data publication of social networks. We propose a privacy protectionscheme that not only prevents the disclosure of identity of users but also the disclosure ofselected features in users' profiles. An individual user can select which features of her profileshe wishes to conceal. The social networks are modeled as graphs in which users arenodes and features are labels. Labels are denoted either as sensitive or as non-sensitive.We treat node labels both as background knowledge an adversary may possess; and assensitive information that has to be protected. We present privacy protection algorithms thatallow for graph data to be published in a form such that an adversary who possessesinformation about a node's neighborhood cannot safely infer its identity and its sensitive …,International Conference on Scientific and Statistical Database Management,2012,30
Collaborative search log sanitization: Toward differential privacy and boosted utility,Yuan Hong; Jaideep Vaidya; Haibing Lu; Panagiotis Karras; Sanjay Goel,Severe privacy leakage in the AOL search log incident has attracted considerable worldwideattention. However; all the web users' daily search intents and behavior are collected in suchdata; which can be invaluable for researchers; data analysts and law enforcement personnelto conduct social behavior study [14]; criminal investigation [5] and epidemics detection [10].Thus; an important and challenging research problem is how to sanitize search logs withstrong privacy guarantee and sufficiently retained utility. Existing approaches in search logsanitization are capable of only protecting the privacy under a rigorous standard [24] ormaintaining good output utility [25]. To the best of our knowledge; there is little work that hasperfectly resolved such tradeoff in the context of search logs; meeting a high standard ofboth requirements. In this paper; we propose a sanitization framework to tackle the above …,IEEE Transactions on Dependable and Secure Computing,2015,27
The Haar+ tree: a refined synopsis data structure,Panagiotis Karras; Nikos Mamoulis,We introduce the Haar+ tree: a refined; wavelet-inspired data structure for synopsisconstruction. The advantages of this structure are twofold: First; it achieves higher synopsisquality at the task of summarizing data sets with sharp discontinuities than state-of-the-arthistogram and Haar wavelet techniques. Second; thanks to its search space delimitationcapacity; Haar+ synopsis construction operates in time linear to the size of the data set forany monotonic distributive error metric. Through experimentation; we demonstrate thesuperiority of Haar+ synopses over histogram and Haar wavelet methods in bothconstruction time and achieved quality for representative error metrics.,Data Engineering; 2007. ICDE 2007. IEEE 23rd International Conference on,2007,25
Graph-aware; workload-adaptive sparql query caching,Nikolaos Papailiou; Dimitrios Tsoumakos; Panagiotis Karras; Nectarios Koziris,Abstract The pace at which data is described; queried and exchanged using the RDFspecification has been ever increasing with the proliferation of Semantic Web. MinimizingSPARQL query response times has been an open issue for the plethora of RDF stores; yetSPARQL result caching techniques have not been extensively utilized. In this work wepresent a novel system that addresses graph-based; workload-adaptive indexing of largeRDF graphs by caching SPARQL query results. At the heart of the system lies a SPARQLquery canonical labelling algorithm that is used to uniquely index and reference SPARQLquery graphs as well as their isomorphic forms. We integrate our canonical labellingalgorithm with a dynamic programming planner in order to generate the optimal joinexecution plan; examining the utilization of both primitive triple indexes and cached query …,Proceedings of the 2015 ACM SIGMOD International Conference on Management of Data,2015,20
Delineating social network data anonymization via random edge perturbation,Mingqiang Xue; Panagiotis Karras; Raissi Chedy; Panos Kalnis; Hung Keng Pung,Abstract Social network data analysis raises concerns about the privacy of related entities orindividuals. To address this issue; organizations can publish data after simply replacing theidentities of individuals with pseudonyms; leaving the overall structure of the social networkunchanged. However; it has been shown that attacks based on structural identification (eg; awalk-based attack) enable an adversary to re-identify selected individuals in an anonymizednetwork. In this paper we explore the capacity of techniques based on random edgeperturbation to thwart such attacks. We theoretically establish that any kind of structuralidentification attack can effectively be prevented using random edge perturbation and showthat; surprisingly; important properties of the whole network; as well as of subgraphs thereof;can be accurately calculated and hence data analysis tasks performed on the perturbed …,Proceedings of the 21st ACM international conference on Information and knowledge management,2012,17
Scalable knn search on vertically stored time series,Shrikant Kashyap; Panagiotis Karras,Abstract Nearest-neighbor search over time series has received vast research attention as abasic data mining task. Still; none of the hitherto proposed methods scales well withincreasing time-series length. This is due to the fact that all methods provide an one-offpruning capacity only. In particular; traditional methods utilize an index to search in areduced-dimensionality feature space; however; for high time-series length; search withsuch an index yields many false hits that need to be eliminated by accessing the full records.An attempt to reduce false hits by indexing more features exacerbates the curse ofdimensionality; and vice versa. A recently proposed alternative; iSAX; uses symbolicapproximate representations accessed by a simple file-system directory as an index. Still;iSAX also encounters false hits; which are again eliminated by accessing records in full …,Proceedings of the 17th ACM SIGKDD international conference on Knowledge discovery and data mining,2011,17
Authenticated multistep nearest neighbor search,Stavros Papadopoulos; Lixing Wang; Yin Yang; Dimitris Papadias; Panagiotis Karras,Multistep processing is commonly used for nearest neighbor (NN) and similarity search inapplications involving high-dimensional data and/or costly distance computations. Today;many such applications require a proof of result correctness. In this setting; clients issue NNqueries to a server that maintains a database signed by a trusted authority. The serverreturns the NN set along with supplementary information that permits result verification usingthe data set signature. An adaptation of the multistep NN algorithm incurs prohibitivenetwork overhead due to the transmission of false hits; ie; records that are not in the NN set;but are nevertheless necessary for its verification. In order to alleviate this problem; wepresent a novel technique that reduces the size of each false hit. Moreover; we generalizeour solution for a distributed setting; where the database is horizontally partitioned over …,IEEE Transactions on Knowledge and Data Engineering,2011,17
Hierarchical synopses with optimal error guarantees,Panagiotis Karras; Nikos Mamoulis,Abstract Hierarchical synopsis structures offer a viable alternative in terms of efficiency andflexibility in relation to traditional summarization techniques such as histograms. Previousresearch on such structures has mostly focused on a single model; based on the Haarwavelet decomposition. In previous work; we have introduced a more refined; wavelet-inspired hierarchical index structure for synopsis construction: the Haar+ tree. The chiefadvantages of this structure are twofold. First; it achieves higher synopsis quality at the taskof summarizing data sets with sharp discontinuities than state-of-the-art histogram and Haarwavelet techniques. Second; thanks to its search space delimitation capacity; Haar+synopsis construction operates in time linear in the size of the data set for any monotonicdistributive error metric. Contemporaneous research has introduced another hierarchical …,ACM Transactions on Database Systems (TODS),2008,17
Common influence join: A natural join operation for spatial pointsets,Man Lung Yiu; Nikos Mamoulis; Panagiotis Karras,We identify and formalize a novel join operator for two spatial pointsets P and Q. Thecommon influence join (CIJ) returns the pairs of points (p; q); pP; qQ; such that there exists alocation in space; being closer to p than to any other point in P and at the same time closerto q than to any other point in Q. In contrast to existing join operators between pointsets (ie;-distance joins and k-closest pairs); CIJ is parameter-free; providing a natural join result thatfinds application in marketing and decision support. We propose algorithms for the efficientevaluation of CIJ; for pointsets indexed by hierarchical multi-dimensional indexes. Wevalidate the effectiveness and the efficiency of these methods via experimentation withsynthetic and real spatial datasets. The experimental results show that a non-blockingalgorithm; which computes intersecting pairs of Voronoi cells on-demand; is very efficient …,Data Engineering; 2008. ICDE 2008. IEEE 24th International Conference on,2008,17
On the privacy and utility of anonymized social networks,Yi Song; Sadegh Nobari; Xuesong Lu; Panagiotis Karras; Stéphane Bressan,Abstract You are on Facebook or you are out. Of course; this assessment is controversialand its rationale arguable. It is nevertheless not far; for many of us; from the reason behindour joining social media and publishing and sharing details of our professional and privatelives. Not only the personal details we may reveal but also the very structure of the networksthemselves are sources of invaluable information for any organization wanting tounderstand and learn about social groups; their dynamics and their members. Theseorganizations may or may not be benevolent. It is therefore important to devise; design andevaluate solutions that guarantee some privacy. One approach that attempts to reconcile thedifferent stakeholders' requirement is the publication of a modified graph. The perturbation ishoped to be sufficient to protect members' privacy while it maintains sufficient utility for …,Proceedings of the 13th International Conference on Information Integration and Web-based Applications and Services,2011,14
Adaptive indexing over encrypted numeric data,Panagiotis Karras; Artyom Nikitin; Muhammad Saad; Rudrika Bhatt; Denis Antyukhov; Stratos Idreos,Abstract Today; outsourcing query processing tasks to remote cloud servers becomes aviable option; such outsourcing calls for encrypting data stored at the server so as to renderit secure against eavesdropping adversaries and/or an honest-but-curious server itself. Atthe same time; to be efficiently managed; outsourced data should be indexed; and evenadaptively so; as a side-effect of query processing. Computationally heavy encryptionschemes render such outsourcing unattractive; an alternative; Order-Preserving EncryptionScheme (OPES); intentionally preserves and reveals the order in the data; hence isunattractive from the security viewpoint. In this paper; we propose and analyze a scheme forlightweight and indexable encryption; based on linear-algebra operations. Our schemeprovides higher security than OPES and allows for range and point queries to be …,Proceedings of the 2016 International Conference on Management of Data,2016,10
L-opacity: linkage-aware graph anonymization,Sadegh Nobari; Panagiotis Karras; Hwee Hwa PANG; Stéphane Bressan,Abstract The wealth of information contained in online social networks has created ademand for the publication of such data as graphs. Yet; publication; even after identitieshave been removed; poses a privacy threat. Past research has suggested ways to publishgraph data in a way that prevents the re-identification of nodes. However; even whenidentities are effectively hidden; an adversary may still be able to infer linkage betweenindividuals with sufficiently high confidence. In this paper; we focus on the privacy threatarising from such link disclosure. We suggest L-opacity; a sufficiently strong privacy modelthat aims to control an adversary's confidence on short multiedge linkages among nodes.We propose an algorithm with two variant heuristics; featuring a sophisticated look-aheadmechanism; which achieves the desired privacy guarantee after a few graph …,*,2014,10
Fast and effective histogram construction,Felix Halim; Panagiotis Karras; Roland HC Yap,Abstract Histogram construction or sequence segmentation is a basic task with applicationsin database systems; information retrieval; and knowledge management. Its aim is toapproximate a sequence by line segments. Unfortunately; the quadratic algorithm thatderives an optimal histogram for Euclidean error lacks the desired scalability. Therefore;sophisticated approximation algorithms have been recently proposed; while several simpleheuristics are used in practice. Still; these solutions fail to resolve the efficiency-qualitytradeoff in a satisfactory manner. In this paper we take a fresh view on the problem. Wepropose conceptually clear and scalable algorithms that efficiently derive high-qualityhistograms. We experimentally demonstrate that existing approximation schemes fail todeliver the desired efficiency and conventional heuristics do not fare well on the side of …,Proceedings of the 18th ACM conference on Information and knowledge management,2009,10
Optimality and scalability in lattice histogram construction,Panagiotis Karras,Abstract The Lattice Histogram is a recently proposed data summarization technique thatachieves approximation quality preferable to that of an optimal plain histogram. Like otherhierarchical synopsis methods; a lattice histogram (LH) aims to approximate data using ahierarchical structure. Still; this structure is not defined a priori; it consists an unknown; not agiven; of the problem. Past work has defined the properties that an LH needs to obey anddeveloped general-purpose approximation algorithms for the construction thereof. Still; twomajor issues remain unaddressed: First; the construction of an optimal LH for a given errormetric is a problem unsolved to date. Second; the proposed algorithms suffer from too highspace and time complexities that render their application in real-world settings problematic.In this paper; we address both these questions; focusing on the case that the target error …,Proceedings of the VLDB Endowment,2009,10
Lattice histograms: a resilient synopsis structure,Panagiotis Karras; Nikos Mamoulis,Despite the surge of interest in data reduction techniques over the past years; no methodhas been proposed to date that can always achieve approximation quality preferable to thatof the optimal plain histogram for a target error metric. In this paper; we introduce the LatticeHistogram: a novel data reduction method that discovers and exploits any arbitrary hierarchyin the data; and achieves approximation quality provably at least as high as an optimalhistogram for any data reduction problem. We formulate LH construction techniques withapproximation guarantees for general error metrics. We show that the case of minimizing amaximum-error metric can be solved by a specialized; memory-sparing approach; we exploitthis solution to design reduced-space heuristics for the general-error case. We develop amixed synopsis approach; applicable to the space-efficient high-quality summarization of …,Data Engineering; 2008. ICDE 2008. IEEE 24th International Conference on,2008,9
Detecting the direction of motion in a binary sensor network,Panagiotis Karras; Nikos Mamoulis,We examine the problem of detecting the direction of motion in a binary sensor network; insuch a network each sensor's value is supplied reliably in a single bit of information: whetherthe moving object is approaching towards or moving away from the sensor. We demonstratethat the geometric properties of the network itself can be exploited for the detection ofmovement direction; from a single instance of sensor reading only. Moreover the estimationis performed in a distributed processing fashion; with only a minimal data collection atsituation-dependent leading sensors and features a low computational burden on eachsensor. In addition; different detection instances drain the resources of different groups ofsensors; of a small size compared to the size of the whole network. Our experimentsdemonstrate high accuracy that increases with sensor density and/or sensing range …,Sensor Networks; Ubiquitous; and Trustworthy Computing; 2006. IEEE International Conference on,2006,8
How to Hack into Facebook without being a Hacker,Tarun Parwani; Ramin Kholoussi; Panagiotis Karras,Abstract The proliferation of online social networking services has aroused privacy concernsamong the general public. The focus of such concerns has typically revolved aroundproviding explicit privacy guarantees to users and letting users take control of the privacy-threatening aspects of their online behavior; so as to ensure that private personalinformation and materials are not made available to other parties and not used forunintended purposes without the user's consent. As such protective features are usually opt-in; users have to explicitly opt-in for them in order to avoid compromising their privacy.Besides; third-party applications may acquire a user's personal information; but only afterthey have been granted consent by the user. If we also consider potential network securityattacks that intercept or misdirect a user's online communication; it would appear that the …,Proceedings of the 22nd International Conference on World Wide Web,2013,7
Multiplicative synopses for relative-error metrics,Panagiotis Karras,Abstract Existing hierarchical summarization techniques fail to provide synopses good interms of relative-error metrics. This paper introduces multiplicative synopses: asummarization paradigm tailored for effective relative-error summarization. This paradigm isinspired from previous hierarchical index-based summarization schemes; but goes beyondthem by altering their underlying data representation mechanism. Existing schemes havedecomposed the summarized data based on sums and differences of values; resulting inwhat we call additive synopses. We argue that the incapacity of these models to handlerelative-error metrics stems exactly from this additive nature of their representationmechanism. We substitute this additive nature by a multiplicative one. We argue that this ismore appropriate for achieving low-relative-error data approximations. We develop an …,Proceedings of the 12th International Conference on Extending Database Technology: Advances in Database Technology,2009,7
An effective and efficient parallel approach for random graph generation over GPUs,Stéphane Bressan; Alfredo Cuzzocrea; Panagiotis Karras; Xuesong Lu; Sadegh Heyrani Nobari,Abstract The widespread usage of random graphs has been highlighted in the context ofdatabase applications for several years. This because such data structures turn out to bevery useful in a large family of database applications ranging from simulation to sampling;from analysis of complex networks to study of randomized algorithms; and so forth. Amongstothers; Erdős–Rényi Γ v; p is the most popular model to obtain and manipulate randomgraphs. Unfortunately; it has been demonstrated that classical algorithms for generatingErdős–Rényi based random graphs do not scale well in large instances and; in addition tothis; fail to make use of the parallel processing capabilities of modern hardware. Inspired bythis main motivation; in this paper we propose and experimentally assess a novel parallelalgorithm for generating random graphs under the Erdős–Rényi model that is designed …,Journal of Parallel and Distributed Computing,2013,6
Skyline query processing over encrypted data: An attribute-order-preserving-free approach,Suvarna Bothe; Alfredo Cuzzocrea; Panagiotis Karras; Akrivi Vlachou,Abstract Making co-existent and convergent the need for efficiency of relational queryprocessing over Clouds and the security of data themselves is figuring-out how one of themost challenging research problems in the Big Data era. Indeed; in actual analytics-orientedengines; such as Google Analytics and Amazon S3; where key-value storage-representationand efficient-management models are employed as to cope with the simultaneousprocessing of billions of transactions; querying encrypted data is becoming one of the mostannoying problem; which has also attracted a great deal of attention from the researchcommunity. While this issue has been applied to a large variety of data formats; egrelational; RDF and multidimensional data; very few initiatives have pointed-out skylinequery processing over encrypted data; which is; indeed; relevant for database analytics …,Proceedings of the First International Workshop on Privacy and Secuirty of Big Data,2014,5
eskyline: Processing skyline queries over encrypted data,Suvarna Bothe; Panagiotis Karras; Akrivi Vlachou,Abstract The advent of cloud computing redefines the traditional query processing paradigm.Whereas computational overhead and memory constraints become less prohibitive; dataprivacy; security; and confidentiality concerns become top priorities. In particular; as dataowners outsource the management of their data to service providers; query processing oversuch data has more resources to tap into; yet the data oftentimes has to be encrypted so asto prevent unauthorized access. The challenge that arises in such a setting is to devise anencryption scheme that still allows for query results to be efficiently computed using theencrypted data values. An important type of query that raises unconventional requirementsin terms of the operator that has to be evaluated is the skyline query; which returns a set ofobjects in a dataset whose values are not dominated by any other object therein. In this …,Proceedings of the VLDB Endowment,2013,5
Ring-constrained join: deriving fair middleman locations from pointsets via a geometric constraint,Man Lung Yiu; Panagiotis Karras; Nikos Mamoulis,Abstract We introduce a novel spatial join operator; the ring-constrained join (RCJ). Giventwo sets P and Q of spatial points; the result of RCJ consists of pairs (p; q)(where p ε P; q ε Q)satisfying an intuitive geometric constraint: the smallest circle enclosing p and q contains noother points in P; Q. This new operation has important applications in decision support; eg;placing recycling stations at fair locations between restaurants and residential complexes.Clearly; RCJ is defined based on a geometric constraint but not on distances betweenpoints. Thus; our operation is fundamentally different from the conventional distance joinsand closest pairs problems. We are not aware of efficient processing algorithms for RCJ inthe literature. A brute-force solution requires computational cost quadratic to input size and itdoes not scale well for large datasets. In view of this; we develop efficient R-tree based …,Proceedings of the 11th international conference on Extending database technology: Advances in database technology,2008,5
k-Anonymization by freeform generalization,Katerina Doka; Mingqiang Xue; Dimitrios Tsoumakos; Panagiotis Karras,Abstract Syntactic data anonymization strives to (i) ensure that an adversary cannot identifyan individual's record from published attributes with high probability; and (ii) provide highdata utility. These mutually conflicting goals can be expressed as an optimization problemwith privacy as the constraint and utility as the objective function. Conventional researchusing the k-anonymity model has resorted to publishing data in homogeneous generalizedgroups. A recently proposed alternative does not create such cliques; instead; it recasts datavalues in a heterogeneous manner; aiming for higher utility. Nevertheless; such works neverdefined the problem in the most general terms; thus; the utility gains they achieve are limited.In this paper; we propose a methodology that achieves the full potential of heterogeneity andgains higher utility while providing the same privacy guarantee. We formulate the problem …,Proceedings of the 10th ACM Symposium on Information; Computer and Communications Security,2015,4
Discretionary social network data revelation with a user-centric utility guarantee,Yi Song; Panagiotis Karras; Sadegh Nobari; Giorgos Cheliotis; Mingqiang Xue; Stéphane Bressan,Abstract The proliferation of online social networks has created intense interest in studyingtheir nature and revealing information of interest to the end user. At the same time; suchrevelation raises privacy concerns. Existing research addresses this problem following anapproach popular in the database community: a model of data privacy is defined; and thedata is rendered in a form that satisfies the constraints of that model while aiming tomaximize some utility measure. Still; these is no consensus on a clear and quantifiable utilitymeasure over graph data. In this paper; we take a different approach: we define a utilityguarantee; in terms of certain graph properties being preserved; that should be respectedwhen releasing data; while otherwise distorting the graph to an extend desired for the sakeof confidentiality. We propose a form of data release which builds on current practice in …,Proceedings of the 21st ACM international conference on Information and knowledge management,2012,4
Cooperative scalable moving continuous query processing,Xiaohui Li; Panagiotis Karras; Lei Shi; Kian-Lee Tan; Christian S Jensen,A range of applications call for a mobile client to continuously monitor others in closeproximity. Past research on such problems has covered two extremes: It has offered totallycentralized solutions; where a server takes care of all queries; and totally distributedsolutions; in which there is no central authority at all. Unfortunately; none of these twosolutions scales to intensive moving object tracking applications; where each client poses aquery. In this paper; we formulate the moving continuous query (MCQ) problem and proposea balanced model where servers cooperatively take care of the global view and handle themajority of the workload. Meanwhile; moving clients; having basic memory and computationresources; handle small portions of the workload. This model is further enhanced bydynamic region allocation and grid size adjustment mechanisms that reduce the …,Mobile Data Management (MDM); 2012 IEEE 13th International Conference on,2012,4
Utility-driven anonymization in data publishing,Mingqiang Xue; Panagiotis Karras; Chedy Raïssi; Hung Keng Pung,Abstract Privacy-preserving data publication has been studied intensely in the past years.Still; all existing approaches transform data values by random perturbation or generalization.In this paper; we introduce a radically different data anonymization methodology. Ourproposal aims to maintain a certain amount of patterns; defined in terms of a set of propertiesof interest that hold for the original data. Such properties are represented as linearrelationships among data points. We present an algorithm that generates a set ofanonymized data that strictly preserves these properties; thus maintaining specified patternsin the data. Extensive experiments with real and synthetic data show that our algorithm isefficient; and produces anonymized data that affords high utility in several data analysistasks while safeguarding privacy.,Proceedings of the 20th ACM international conference on Information and knowledge management,2011,4
Indoor localization accuracy estimation from fingerprint data,Artyom Nikitin; Christos Laoudias; Georgios Chatzimilioudis; Panagiotis Karras; Demetrios Zeinalipour-Yazti,The demand for indoor localization services has led to the development of techniques thatcreate a Fingerprint Map (FM) of sensor signals (eg; magnetic; Wi-Fi; bluetooth) atdesignated positions in an indoor space and then use FM as a reference for subsequentlocalization tasks. With such an approach; it is crucial to assess the quality of the FM beforedeployment; in a manner disregarding data origin and at any location of interest; so as toprovide deployment staff with the information on the quality of localization. Even though FM-based localization algorithms usually provide accuracy estimates during system operation(eg; visualized as uncertainty circle or ellipse around the user location); they do not provideany information about the expected accuracy before the actual deployment of thelocalization service. In this paper; we develop a novel frame-work for quality assessment …,Mobile Data Management (MDM); 2017 18th IEEE International Conference on,2017,3
An equitable solution to the stable marriage problem,Ioannis Giannakopoulos; Panagiotis Karras; Dimitrios Tsoumakos; Katerina Doka; Nectarios Koziris,A stable marriage problem (SMP) of size n involves n men and n women; each of whom hasordered members of the opposite gender by descending preferability. A solution is a perfectmatching among men and women; such that there exists no pair who prefer each other totheir current spouses. The problem was formulated in 1962 by Gale and Shapley; whoshowed that any instance can be solved in polynomial time; and has attracted interest due toits application to any two-sided market. Still; the solution obtained by the Gale-Shapleyalgorithm is favorable to one side. Gusfield and Irving introduced the equitable stablemarriage problem (ESMP); which calls for finding a stable matching that minimizes thedistance between men's and women's sum-of-rankings of their spouses. Unfortunately;ESMP is strongly NP-hard; approximation algorithms therefor are impractical; while even …,Tools with Artificial Intelligence (ICTAI); 2015 IEEE 27th International Conference on,2015,3
TRANSFORMERS: Robust spatial joins on non-uniform data distributions,Mirjana Pavlovic; Thomas Heinis; Farhan Tauheed; Panagiotis Karras; Anastasia Ailamaki,Spatial joins are becoming increasingly ubiquitous in many applications; particularly in thescientific domain. While several approaches have been proposed for joining spatialdatasets; each of them has a strength for a particular type of density ratio among the joineddatasets. More generally; no single proposed method can efficiently join two spatial datasetsin a robust manner with respect to their data distributions. Some approaches do well fordatasets with contrasting densities while others do better with similar densities. None ofthem does well when the datasets have locally divergent data distributions. In this paper wedevelop TRANSFORMERS; an efficient and robust spatial join approach that is indifferent tosuch variations of distribution among the joined data. TRANSFORMERS achieves this featby departing from the state-of-the-art through adapting the join strategy and data layout to …,Data Engineering (ICDE); 2016 IEEE 32nd International Conference on,2016,2
Local Search in Histogram Construction.,Felix Halim; Panagiotis Karras; Roland HC Yap,Abstract The problem of dividing a sequence of values into segments occurs in databasesystems; information retrieval; and knowledge management. The challenge is to select afinite number of boundaries for the segments so as to optimize an objective error functiondefined over those segments. Although this optimization problem can be solved inpolynomial time; the algorithm which achieves the minimum error does not scale well; henceit is not practical for applications with massive data sets. There is considerable research withnumerous approximation and heuristic algorithms. Still; none of those approaches hasresolved the quality-efficiency tradeoff in a satisfactory manner. In (Halim; Karras; and Yap2009); we obtain near linear time algorithms which achieve both the desired scalability andnear-optimal quality; thus dominating earlier approaches. In this paper; we show how two …,AAAI,2010,2
Content Recommendation for Viral Social Influence,Sergei Ivanov; Konstantinos Theocharidis; Manolis Terrovitis; Panagiotis Karras,Abstract How do we create content that will become viral in a whole network after we share itwith friends or followers' Significant research activity has been dedicated to the problem ofstrategically selecting a seed set of initial adopters so as to maximize a meme's spread in anetwork. This line of work assumes that the success of such a campaign depends solely onthe choice of a tunable seed set of adopters; while the way users perceive the propagatedmeme is fixed. Yet; in many real-world settings; the opposite holds: a meme's propagationdepends on users' perceptions of its tunable characteristics; while the set of initiators is fixed.In this paper; we address the natural problem that arises in such circumstances: Suggestcontent; expressed as a limited set of attributes; for a creative promotion campaign that startsout from a given seed set of initiators; so as to maximize its expected spread over a social …,Proceedings of the 40th International ACM SIGIR Conference on Research and Development in Information Retrieval,2017,1
Scalable Indexing and Adaptive Querying of RDF Data in the cloud,Nikolaos Papailiou; Dimitrios Tsoumakos; Ioannis Konstantinou; Panagiotis Karras; Nectarios Koziris,Abstract Efficient RDF data management systems are central to the vision of the SemanticWeb. The enormous increase in both user and machine generated content dictates forscalable solutions in triple data stores. Current systems manage to decentralize some or allthe stages of RDF data management; scaling to arbitrarily large numbers of triples. Yet;these systems prove highly inflexible in adjusting their behavior relative to the query in hand.Queries over triple data include multiple joins with varying degrees of selectivity and cost. Inmany cases; a join performed on a single centralized computer node is highly preferable.Thus; both informed query planning and adaptive join execution are necessary to gainoptimal performance in both selective and non selective queries. Towards that direction; wedescribe H2RDF+; an RDF store that efficiently performs distributed joins over a multiple …,Proceedings of Semantic Web Information Management on Semantic Web Information Management,2014,1
ACCES: Offline Accuracy Estimation for Fingerprint-based Localization,Artyom Nikitin; Christos Laoudias; Georgios Chatzimilioudis; Panagiotis Karras; Demetrios Zeinalipour-Yazti,In this demonstration we present ACCES; a novel framework that enables qualityassessment of arbitrary fingerprint maps and offline accuracy estimation for the task offingerprint-based indoor localization. Our framework considers collected fingerprintsdisregarding the physical origin of the data. First; it applies a widely used statisticalinstrument; namely Gaussian Process Regression (GPR); for interpolation of the fingerprints.Then; to estimate the best possibly achievable localization accuracy at any location; itutilizes the Cramer-Rao Lower Bound (CRLB) with interpolated data as an input. Ourdemonstration entails a standalone version of the popular and open-source AnyplaceInternet-based indoor navigation service in which the software modules of ACCES areintegrated. At the conference; we will present the utility of our method in two modes:(i) …,Mobile Data Management (MDM); 2017 18th IEEE International Conference on,2017,*
VERSE: Versatile Graph Embeddings from Similarity Measures,Anton Tsitsulin; Davide Mottin; Panagiotis Karras; Emmanuel Müller,ABSTRACT Embedding a web-scale information network into a low-dimensional vectorspace facilitates tasks such as link prediction; classification; and visualization. Past researchhas addressed the problem of extracting such embeddings by adopting methods from wordsto graphs; without defining a clearly comprehensible graph-related objective. Yet; as weshow; the objectives used in past works implicitly utilize similarity measures among graphnodes. In this paper; we carry the similarity orientation of previous works to its logicalconclusion; we propose VERtex Similarity Embeddings (VERSE); a simple; versatile; andmemory-efficient method that derives graph embeddings explicitly calibrated to preserve thedistributions of a selected vertex-to-vertex similarity measure. VERSE learns suchembeddings by training a single-layer neural network. While its default; scalable version …,*,2017,*
Harvester: Influence Optimization in Symmetric Interaction Networks,Sergei Ivanov; Panagiotis Karras,The problem of optimizing influence diffusion in a network has applications in areas such asmarketing; disease control; social media analytics; and more. In all cases; an initial set ofinfluencers are chosen so as to optimize influence propagation. While a lot of research hasbeen devoted to the influence maximization problem; most solutions proposed to date applyon directed networks; considering the undirected case to be solvable as a special case. Inthis paper; we propose a novel algorithm; Harvester; that achieves results of higher qualitythan the state of the art on symmetric interaction networks; leveraging the particularcharacteristics of such networks. Harvester is based on the aggregation of instances of live-edge graphs; from which we compute the influence potential of each node. We show thatthis technique can be applied for both influence maximization under a known seed size …,Data Science and Advanced Analytics (DSAA); 2016 IEEE International Conference on,2016,*
Fuzzy trajectory linking,Huayu Wu; Mingqiang Xue; Jianneng Cao; Panagiotis Karras; Wee Siong Ng; Kee Kiat Koo,Today; people can access various services with smart carry-on devices; eg; surf the webwith smart phones; make payments with credit cards; or ride a bus with commuting cards. Inaddition to the offered convenience; the access of such services can reveal their traveledtrajectory to service providers. Very often; a user who has signed up for multiple servicesmay expose her trajectory to more than one service providers. This state of affairs raises aprivacy concern; but also an opportunity. On one hand; several colluding service providers;or a government agency that collects information from such service providers; may identifyand reconstruct users' trajectories to an extent that can be threatening to personal privacy.On the other hand; the processing of such rich data may allow for the development of betterservices for the common good. In this paper; we take a neutral standpoint and investigate …,Data Engineering (ICDE); 2016 IEEE 32nd International Conference on,2016,*
Computing skylines over encrypted data in cloud environments,Suvarna Bothe; Alfredo Cuzzocrea; Panagiotis Karras; Akrivi Vlachou,Making co-existent and convergent the need for efficiency of relational query processingover Clouds and the security of data themselves is figuring-out how one of the mostchallenging research problems in the Big Data era. Indeed; in actual analytics-orientedengines; such as Google Analytics and Amazon S3; where key-value storage-representationand efficientmanagement models are employed as to cope with the simultaneousprocessing of billions of transactions; querying encrypted data is becoming one of the mostannoying problem; which has also attracted a great deal of attention from the researchcommunity. While this issue has been applied to a large variety of data formats; egrelational; RDF and multidimensional data; very few initiatives have pointed-out skylinequery processing over encrypted data; which is; indeed; relevant for database analytics …,24th Italian Symposium on Advanced Database Systems; SEBD 2016,2016,*
Heterogeneous k-anonymization with high utility,Katerina Doka; Mingqiang Xue; Dimitrios Tsoumakos; Panagiotis Karras; Alfredo Cuzzocrea; Nectarios Koziris,Among the privacy-preserving approaches that are known in the literature; h-anonymityremains the basis of more advanced models while still being useful as a stand-alonesolution. Applying h-anonymity in practice; though; incurs severe loss of data utility; thuslimiting its effectiveness and reliability in real-life applications and systems. However; suchloss in utility does not necessarily arise from an inherent drawback of the model itself; butrather from the deficiencies of the algorithms used to implement the model. Conventionalapproaches rely on a methodology that publishes data in homogeneous generalizedgroups. An alternative modern data publishing scheme focuses on publishing the data inheterogeneous groups and achieves higher utility; while ensuring the same privacyguarantees. As conventional approaches cannot anonymize data following this …,Big Data (Big Data); 2015 IEEE International Conference on,2015,*
CW2I: community data indexing for complex query processing,Mei Hui; Panagiotis Karras; Beng Chin Ooi,Abstract The increasing popularity of Community Web Management Systems (CWMSs) callsfor tailor-made data management approaches for them. Still; existing CWMSs have mostlyfocused on simple similarity-based queries; they do not provide a framework for the efficientprocessing of more complex queries over community web data. In this paper; we propose atwo-way indexing scheme that facilitates efficient and scalable retrieval and complex queryprocessing with community data. A thorough experimental comparison; based on real-worlddata and practical queries; illustrates the advantages of our scheme compared to otherapproaches for community web data management. Besides; our double-indexing schemeprovides an attractive solution to the storage problem as well.,International Conference on Web-Age Information Management,2010,*
Data structures and algorithms for data representation in constrained environments,Panagiotis Karras,每個DOI號前面加上 「 http://dx.doi.org/ 」 便成為永久網址。 如以DOI號為 10.5297/ser.1201.002的文獻為例，此文獻的永久連結便是： http://dx.doi.org/ 10.5297/ser.1201.002 。日後不論出版單位如何更動此文獻位置，永久連結所指向的位置皆會即時更新，不再錯失重要的研究… 有DOI的文獻在引用時皆應同時引用DOI。若使用APA、Chicago以外未規範DOI的引用格式，可引用DOI永久連結 …DOI可強化引用精確性、增強學術圈連結，並給予使用者跨平台的良好使用經驗，目前在全世界已有超過五千萬個物件申請DOI。 如想對DOI的使用與概念有進一步了解，請參考 華藝DOI註冊中心 （ doi.airiti.com ） …數據來源：Academic Citation Index，簡稱ACI臺灣地區最大的引用文獻資料庫，目前收錄臺灣地區所出版的人文學、社會學領域學術期刊，穩定出刊中的期刊總量約400種，若包含已收錄但後續停刊的期刊，總期刊量超過500種 …,香港大學學位論文,2007,*
Poster: A Secure and Verifiable Electronic Voting System,Francisco Kajatt-Vaccari; Tamara Finogina; Panagiotis Karras,Abstract—We propose an architecture for an electronic voting system that satisfies thefollowing three requirements: Integrity; Verifiability; and Anonymity. We keep informationabout user votes and user identity in different tables; encrypt them; and hide connectionsbetween those tables. Encryption techniques used in the system include oblivious RAM andfully (or partly) homomorphic encryption.,*,*,*
Algebra-based Encryption for Adaptive Indexing,Artyom Nikitin; Panagiotis Karras,Abstract. Today; outsourcing query processing tasks to remote cloud servers becomes aviable option for several financial applications; for example; a firm may deploy trading;analytics; and risk management modules to the cloud; while collecting financial data daily; oron a finer time scale [1]. At the same time; this model raises security and confidentialityconcerns; sensitive data and query results may be leaked to malicious adversaries and/oran honest-but-curious service provider itself. Such concerns have motivated research onquery answering over encrypted data [6]. Yet; to be efficiently managed; outsourcedencrypted data should be indexed; and even adaptively so; as a side-effect of queryprocessing [4]; extant encryption schemes suffer from one or more of the followingdrawbacks:(i) they are too computationally expensive; or (ii) leak too much information on …,*,*,*
