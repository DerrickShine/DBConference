A stemming algorithm for the portuguese language,Viviane Moreira Orengo; Christian Huyck,*,String Processing and Information Retrieval; 2001. SPIRE 2001. Proceedings. Eighth International Symposium on,2001,180
Measuring quality of similarity functions in approximate data matching,Roberto Da Silva; Raquel Stasiu; Viviane Moreira Orengo; Carlos A Heuser,Abstract This paper presents a method for assessing the quality of similarity functions. Thescenario taken into account is that of approximate data matching; in which it is necessary todetermine whether two data instances represent the same real world object. Our method isbased on the semi-automatic estimation of optimal threshold values. We propose twomethods for performing such estimation. The first method is an algorithm based on a rewardfunction; and the second is a statistical method. Experiments were carried out to validate thetechniques proposed. The results show that both methods for threshold estimation producesimilar results. The output of such methods was used to design a grading function forsimilarity functions. This grading function; called discernability; was used to compare anumber of similarity functions applied to an experimental data set.,Journal of Informetrics,2007,47
Multilingual schema matching for Wikipedia infoboxes,Thanh Nguyen; Viviane Moreira; Huong Nguyen; Hoa Nguyen; Juliana Freire,Abstract Recent research has taken advantage of Wikipedia's multi-lingualism as a resourcefor cross-language information retrieval and machine translation; as well as proposedtechniques for enriching its cross-language structure. The availability of documents inmultiple languages also opens up new opportunities for querying structured Wikipediacontent; and in particular; to enable answers that straddle different languages. As a steptowards supporting such queries; in this paper; we propose a method for identifyingmappings between attributes from infoboxes that come from pages in different languages.Our approach finds mappings in a completely automated fashion. Because it does notrequire training data; it is scalable: not only can it be used to find mappings between manylanguage pairs; but it is also effective for languages that are under-represented and lack …,Proceedings of the VLDB Endowment,2011,40
Identification and treatment of multiword expressions applied to information retrieval,Otavio Costa Acosta; Aline Villavicencio; Viviane P Moreira,Abstract The extensive use of Multiword Expressions (MWE) in natural language textsprompts more detailed studies that aim for a more adequate treatment of these expressions.A MWE typically expresses concepts and ideas that usually cannot be expressed by a singleword. Intuitively; with the appropriate treatment of MWEs; the results of an InformationRetrieval (IR) system could be improved. The aim of this paper is to apply techniques for theautomatic extraction of MWEs from corpora to index them as a single unit. Experimentalresults show improvements on the retrieval of relevant documents when identifying MWEsand treating them as a single indexing unit.,Proceedings of the Workshop on Multiword Expressions: from Parsing and Generation to the Real World,2011,36
A new approach for cross-language plagiarism analysis,Rafael Corezola Pereira; Viviane P Moreira; Renata Galante,Abstract This paper presents a new method for Cross-Language Plagiarism Analysis. Ourtask is to detect the plagiarized passages in the suspicious documents and theircorresponding fragments in the source documents. We propose a plagiarism detectionmethod composed by five main phases: language normalization; retrieval of candidatedocuments; classifier training; plagiarism analysis; and post-processing. To evaluate ourmethod; we created a corpus containing artificial plagiarism offenses. Two differentexperiments were conducted; the first one considers only monolingual plagiarism cases;while the second one considers only cross-language plagiarism cases. The results showedthat the cross-language experiment achieved 86% of the performance of the monolingualbaseline. We also analyzed how the plagiarized text length affects the overall …,International Conference of the Cross-Language Evaluation Forum for European Languages,2010,33
Examining multiple features for author profiling,Edson RD Weren; Anderson U Kauer; Lucas Mizusaki; Viviane P Moreira; J Palazzo M de Oliveira; Leandro K Wives,*,Journal of information and data management,2014,25
Automatic threshold estimation for data matching applications,Juliana B dos Santos; Carlos A Heuser; Viviane P Moreira; Leandro K Wives,Abstract Several advanced data management applications; such as data integration; datadeduplication; and similarity querying rely on the application of similarity functions. Asimilarity function requires the definition of a threshold value in order to decide whether twodifferent data instances match; ie; if they represent the same real world object. In this context;threshold definition is a central problem. This paper proposes a method for estimating thequality of a similarity function. Quality is measured in terms of recall and precision calculatedat several different thresholds. Based on the results of the proposed estimation process andthe requirements of a specific application; a user is able to choose a suitable thresholdvalue. The estimation process is based on a clustering phase performed over a datacollection (or a sample thereof) and requires no human intervention since the choice of …,Information Sciences,2011,21
Information retrieval and categorisation using a cell assembly network,Christian R Huyck; Viviane Orengo,Abstract Simulated networks of spiking leaky integrators are used to categorise and forInformation Retrieval (IR). Neurons in the network are sparsely connected; learn usingHebbian learning rules; and are simulated in discrete time steps. Our earlier work has usedthese models to simulate human concept formation and usage; but we were interested in themodel's applicability to real world problems; so we have done experiments on categorisationand IR. The results of the system show that congresspeople are correctly categorised 89% ofthe time. The IR systems have 40% average precision on the Time collection; and 28% onthe Cranfield 1;400. All scores are comparable to the state of the art results on these tasks.,Neural computing & applications,2005,18
Relevance feedback and cross-language information retrieval,Viviane Moreira Orengo; Christian Huyck,Abstract This paper presents a study of relevance feedback in a cross-language informationretrieval environment. We have performed an experiment in which Portuguese speakers areasked to judge the relevance of English documents; documents hand-translated toPortuguese and documents automatically translated to Portuguese. The goals of theexperiment were to answer two questions (i) how well can native Portuguese searchersrecognise relevant documents written in English; compared to documents that are handtranslated and automatically translated to Portuguese; and (ii) what is the impact ofmisjudged documents on the performance improvement that can be achieved by relevancefeedback. Surprisingly; the results show that machine translation is as effective as handtranslation in aiding users to assess relevance in the experiment. In addition; the impact …,Information processing & management,2006,17
A strategy for allowing meaningful and comparable scores in approximate matching,Carina F Dorneles; Marcos Freitas Nunes; Carlos A Heuser; Viviane P Moreira; Altigran S da Silva; Edleno S de Moura,Abstract Approximate data matching aims at assessing whether two distinct instances ofdata represent the same real-world object. The comparison between data values is usuallydone by applying a similarity function which returns a similarity score. If this score surpassesa given threshold; both data instances are considered as representing the same real-worldobject. These score values depend on the algorithm that implements the function and haveno meaning to the user. In addition; score values generated by different functions are notcomparable. This will potentially lead to problems when the scores returned by differentsimilarity functions need to be combined for computing the similarity between records. In thisarticle; we propose that thresholds should be defined in terms of the precision that isexpected from the matching process rather than in terms of the raw scores returned by the …,Information Systems,2009,16
A study on the use of stemming for monolingual ad-hoc Portuguese information retrieval,Viviane Moreira Orengo; Luciana S Buriol; Alexandre Ramos Coelho,Abstract For UFRGS's first participation in CLEF our goal was to compare the performance ofheavier and lighter stemming strategies using the Portuguese data collections formonolingual Ad-hoc retrieval. The results show that the safest strategy was to use the lighteralternative (reducing plural forms only). On a query-by-query analysis; full stemmingachieved the highest improvement but also the biggest decrease in performance whencompared to no stemming. In addition; statistical tests showed that the only significantimprovement in terms of mean average precision; precision at ten and number of relevantretrieved was achieved by our lighter stemmer.,Workshop of the Cross-Language Evaluation Forum for European Languages,2006,16
Prequery discovery of domain-specific query forms: A survey,Mauricio C Moraes; Carlos A Heuser; Viviane P Moreira; Denilson Barbosa,The discovery of HTML query forms is one of the main challenges in Deep Web crawling.Automatic solutions for this problem perform two main tasks. The first is locating HTML formson the Web; which is done through the use of traditional/focused crawlers. The second isidentifying which of these forms are indeed meant for querying; which also typically involvesdetermining a domain for the underlying data source (and thus for the form as well). Thisproblem has attracted a great deal of interest; resulting in a long list of algorithms andtechniques. Some methods submit requests through the forms and then analyze the dataretrieved in response; typically requiring a great deal of knowledge about the domain as wellas semantic processing. Others do not employ form submission; to avoid such difficulties;although some techniques rely to some extent on semantics and domain knowledge. This …,IEEE Transactions on Knowledge and Data Engineering,2013,12
SimEval: a tool for evaluating the quality of similarity functions,Carlos A Heuser; Francisco NA Krieser; Viviane Moreira Orengo,Abstract Approximate data matching applications typically use similarity functions to quantifythe degree of likeness between two data instances. There are several similarity functionsavailable; thus; it is often necessary to evaluate a number of them aiming at choosing thefunction that is more adequate to a specific application. This paper presents a tool that usesaverage precision and discernability to evaluate the quality of similarity functions over a dataset.,Tutorials; posters; panels and industrial contributions at the 26th international conference on Conceptual modeling-Volume 83,2007,12
Schema versioning: queries to the generalized temporal database system,V Pereira Moreira; Nina Edelweiss,Raw data and database structures are evolving entities that require adequate support forpast; present and even future versions. Temporal databases supporting schema versioningwere developed with the aim of satisfying this requirement. This paper considers ageneralized temporal database system; which provides support for time at both intensionaland extensional levels. The support for schema versioning raises two complex subjects: thestorage of the several schema versions and their associate data; and the processing ofqueries involving more than one schema version. The main goal of this paper is to analysethe second aspect in order to propose a strategy to answer multi-schema queries.,Database and Expert Systems Applications; 1999. Proceedings. Tenth International Workshop on,1999,12
Assessing the impact of Stemming Accuracy on Information Retrieval–A multilingual perspective,Felipe N Flores; Viviane P Moreira,Abstract The quality of stemming algorithms is typically measured in two different ways:(i)how accurately they map the variant forms of a word to the same stem; or (ii) how muchimprovement they bring to Information Retrieval systems. In this article; we evaluate variousstemming algorithms; in four languages; in terms of accuracy and in terms of their aid toInformation Retrieval. The aim is to assess whether the most accurate stemmers are also theones that bring the biggest gain in Information Retrieval. Experiments in English; French;Portuguese; and Spanish show that this is not always the case; as stemmers with highererror rates yield better retrieval quality. As a byproduct; we also identified the most accuratestemmers and the best for Information Retrieval purposes.,Information Processing & Management,2016,11
Assessing the impact of stemming accuracy on information retrieval,Felipe N Flores; Viviane P Moreira; Carlos A Heuser,Abstract The quality of stemming algorithms is typically measured in two different ways:(i)how accurately they map the variant forms of a word to the same stem; or (ii) how muchimprovement they bring to Information Retrieval. In this paper; we evaluate differentPortuguese stemming algorithms in terms of accuracy and in terms of their aid to InformationRetrieval. The aim is to assess whether the most accurate stemmers are also the ones thatbring the biggest gain in Information Retrieval. Our results show that some kind of correlationdoes exist; but it is not as strong as one might have expected.,International Conference on Computational Processing of the Portuguese Language,2010,10
Assessing relevance using automatically translated documents for cross-language information retrieval,Viviane Moreira Orengo,This thesis focuses on the Relevance Feedback (RF) process; and the scenario consideredis that of a Portuguese-English Cross-Language Information Retrieval (CUR) system. CURdeals with the retrieval of documents in one natural language in response to a queryexpressed in another language. RF is an automatic process for query reformulation. Theidea behind it is that users are unlikely to produce perfect queries; especially if given justone attempt. The process aims at improving the queryspecification; which will lead to morerelevant documents being retrieved. The method consists of asking the user to analyse aninitial sample of documents retrieved in response to a query and judge them for relevance.In that context; two main questions were posed. The first one relates to the user's ability inassessing the relevance of texts in a foreign language; texts hand translated into their …,*,2004,9
Comparing and combining Content‐and Citation‐based approaches for plagiarism detection,Solange de L Pertile; Viviane P Moreira; Paolo Rosso,Abstract The vast amount of scientific publications available online makes it easier forstudents and researchers to reuse text from other authors and makes it harder for checkingthe originality of a given text. Reusing text without crediting the original authors isconsidered plagiarism. A number of studies have reported the prevalence of plagiarism inacademia. As a consequence; numerous institutions and researchers are dedicated todevising systems to automate the process of checking for plagiarism. This work focuses onthe problem of detecting text reuse in scientific papers. The contributions of this paper aretwofold:(a) we survey the existing approaches for plagiarism detection based on content;based on content and structure; and based on citations and references; and (b) we comparecontent and citation-based approaches with the goal of evaluating whether they are …,Journal of the Association for Information Science and Technology,2016,8
Exploring Information Retrieval Features for Author Profiling.,Edson RD Weren; Viviane Pereira Moreira; José Palazzo M de Oliveira,Abstract This paper describes the methods we have employed to solve the author profilingtask at PAN-2014. Our goal was to rely mainly on features from Information Retrieval toidentify the age group and the gender of the author of a given text. We describe the features;the classification algorithms employed; and how the experiments were run. Also; we providean analysis of our results compared to other groups.,CLEF (Working Notes),2014,8
Using simple content features for the author profiling task,Edson RD Weren; Viviane P Moreira; J Oliveira,Abstract This paper describes the methods we have employed to solve the author profilingtask at PAN-2013. Our goal was to use simple features to identify the age group and thegender of the author of a given text. We introduce the features; detail how the classifierswere trained; and how the experiments were run.,Notebook for PAN at Cross-Language Evaluation Forum. Valencia; Spain,2013,8
UFRGS@ CLEF2008: Using Association Rules for Cross-Language Information Retrieval,André Pinto Geraldo; Viviane Moreira,Abstract For UFRGS's participation on the TEL task at CLEF2008; our aim was to assess thevalidity of using algorithms for mining association rules to find mappings between conceptson a Cross-Language Information Retrieval scenario. Our approach requires a sample ofparallel documents to serve as the basis for the generation of the association rules. Theresults of the experiments show that the performance of our approach is not statisticallydifferent from the monolingual baseline in terms of mean average precision. This is anindication that association rules can be effectively used to map concepts betweenlanguages. We have also tested a modification to BM25 that aims at increasing the weight ofrare terms. The results show that this modified version achieved better performance. Theimprovements were considered to be statistically significant in terms of MAP on our …,Evaluating Systems for Multilingual and Multimodal Information Access,2009,8
Portuguese-english experiments using latent semantic indexing,Viviane Moreira Orengo; Christian Huyck,Abstract This paper reports the work of Middlesex University in the CLEF bilingual task. Wehave carried out experiments using Portuguese queries to retrieve documents in English.The approach used was Latent Semantic Indexing; which is an automatic method notrequiring dictionaries or thesauri. We have also run a monolingual version of the system towork as a baseline. Here we describe in detail the methods used and give an analysis of theresults obtained.,Workshop of the Cross-Language Evaluation Forum for European Languages,2002,8
Exploring information retrieval features for author profiling—notebook for pan at clef 2014,Edson RD Weren; Viviane P Moreira; José PM de Oliveira,*,Cappellato et al.[6],*,7
Comparing the Quality of Focused Crawlers and of the Translation Resources Obtained from them.,Bruno Laranjeira; Viviane Pereira Moreira; Aline Villavicencio; Carlos Ramisch; Maria José Bocorny Finatto,Abstract Comparable corpora have been used as an alternative for parallel corpora asresources for computational tasks that involve domainspecific natural language processing.One way to gather documents related to a specific topic of interest is to traverse a portion ofthe web graph in a targeted way; using focused crawling algorithms. In this paper; wecompare several focused crawling algorithms using them to collect comparable corpora on aspecific domain. Then; we compare the evaluation of the focused crawling algorithms to theperformance of linguistic processes executed after training with the correspondinggenerated corpora. Also; we propose a novel approach for focused crawling; exploiting theexpressive power of multiword expressions.,LREC,2014,6
Statistics for ranking program committees and editorial boards,Roberto da Silva; José Palazzo de Oliveira; José Valdeni de Lima; Viviane Moreira,Abstract: Ranking groups of researchers is important in several contexts and can servemany purposes such as the fair distribution of grants based on the scientist's publicationoutput; concession of research projects; classification of journal editorial boards and manyother applications in a social context. In this paper; we propose a method for measuring theperformance of groups of researchers. The proposed method is called alpha-index and it isbased on two parameters:(i) the homogeneity of the h-indexes of the researchers in thegroup; and (ii) the h-group; which is an extension of the h-index for groups. Our methodintegrates the concepts of homogeneity and absolute value of the h-index into a singlemeasure which is appropriate for the evaluation of groups. We report on experiments thatassess computer science conferences based on the h-indexes of their program …,arXiv preprint arXiv:1002.1060,2010,6
Consultas a bancos de dados temporais que suportam versionamento de esquemas,Viviane Pereira Moreira,*,*,1999,6
Using information retrieval for sentiment polarity prediction,Anderson Uilian Kauer; Viviane P Moreira,Abstract Social networks such as Twitter are used by millions of people who express theiropinions on a variety of topics. Consequently; these media are constantly being examinedby sentiment analysis systems which aim at classifying the posts as positive or negative.Given the variety of topics discussed and the short length of the posts; the standardapproach of using the words as features for machine learning algorithms results in sparsevectors. In this work; we propose using features derived from the ranking generated by anInformation Retrieval System in response to a query consisting of the post that needs to beclassified. Our system can be fully automatic; has only 24 features; and does not depend onexpensive resources. Experiments on real datasets have shown that a classifier that reliessolely on these features outperforms established baselines and can reach accuracies …,Expert Systems with Applications,2016,5
UFRGS@ PAN2010: Detecting External Plagiarism-Lab Report for PAN at CLEF 2010.,Rafael Corezola Pereira; Viviane Pereira Moreira; Renata Galante,*,CLEF (Notebook Papers/LABs/Workshops),2010,5
An integer linear programming approach for approximate string comparison,Marcus Ritt; Alysson M Costa; Sergio Mergen; Viviane M Orengo,Abstract We introduce a problem called maximum common characters in blocks (MCCB);which arises in applications of approximate string comparison; particularly in the unificationof possibly erroneous textual data coming from different sources. We show that this problemis NP-complete; but can nevertheless be solved satisfactorily using integer linearprogramming for instances of practical interest. Two integer linear formulations are proposedand compared in terms of their linear relaxations. We also compare the results of theapproximate matching with other known measures such as the Levenshtein (edit) distance.,European Journal of Operational Research,2009,5
Ufrgs@ clef2008: Indexing multiword expressions for information retrieval,Otavio Acosta; Andre Geraldo; Viviane Moreira Orengo; Aline Villavicencio,Abstract For UFRGS's participation on CLEF's Robust task; our aim was to assess thebenefits of identifying and indexing Multiword Expressions (MWEs) for Information Retrieval.The approach used for MWE identification was totally statistical; based associationmeasures such as Mutual Information and Chi-square. Contradicting our results on thetraining topics; the results on the test topics did not show any significant improvements.However; for some queries; the identification of MWEs was very important. We have alsoperformed bilingual experiments which achieved 84% of their monolingual counterparts.,Aarhus; Denmark. Working Notes of the Workshop of the Cross-Language Evaluation Forum-CLEF,2008,5
Automatic filling of hidden web forms: a survey,Gustavo Zanini Kantorski; Viviane Pereira Moreira; Carlos Alberto Heuser,Abstract A significant part of the information available on the Web is stored in onlinedatabases which compose what is known as Hidden Web or Deep Web. In order to accessinformation from the Hidden Web; one must fill an HTML form that is submitted as a query tothe underlying database. In recent years; many works have focused on how to automate theprocess of form filling by creating methods for choosing values to fill the fields in the forms.This is a challenging task since forms may contain fields for which there are no predefinedvalues to choose from. This article presents a survey of methods for Web Form Filling;analyzing the existing solutions with respect to the type of forms that they handle and thefilling strategy adopted. We provide a comparative analysis of 15 key works in this area anddiscuss directions for future research.,ACM SIGMOD Record,2015,4
Um estudo de caso de mineração de emoções em textos multilíngues,AGL Santos; K Becker; V Moreira,*,Anais do Brasnam,2014,4
Counting Co-occurrences in Citations to Identify Plagiarised Text Fragments,Solange de L Pertile; Paolo Rosso; Viviane P Moreira,Abstract Research in external plagiarism detection is mainly concerned with the comparisonof the textual contents of a suspicious document against the contents of a collection oforiginal documents. More recently; methods that try to detect plagiarism based on citationpatterns have been proposed. These methods are particularly useful for detecting plagiarismin scientific publications. In this work; we assess the value of identifying co-occurrences incitations by checking whether this method can identify cases of plagiarism in a dataset ofscientific papers. Our results show that most the cases in which co-occurrences were foundindeed correspond to plagiarised passages.,International Conference of the Cross-Language Evaluation Forum for European Languages,2013,4
Finding missing cross-language links in wikipedia,Carlos Eduardo M Moreira; Viviane P Moreira,Abstract Wikipedia is a public encyclopedia composed of millions of articles written daily byvolunteer authors from different regions of the world. The articles contain links called cross-language links which relate corresponding articles across different languages. This featureis extremely useful for applications that work with automatic translation and multilingualinformation retrieval as it allows the assembly of comparable corpora. Thus; it is important tohave a mechanism that automatically creates such links. This has been motivating thedevelopment of techniques to identify missing cross-language links. In this article; wepresent CLLFinder; an approach for finding missing cross-language links. The approachmakes use of the links between categories and of the transitivity between existing cross-language links; as well as textual features extracted from the articles. Experiments using …,Journal of Information and Data Management,2013,4
On-demand associative cross-language information retrieval,André Pinto Geraldo; Viviane P Moreira; Marcos A Gonçalves,Abstract This paper proposes the use of algorithms for mining association rules as anapproach for Cross-Language Information Retrieval. These algorithms have been widelyused to analyse market basket data. The idea is to map the problem of finding associationsbetween sales items to the problem of finding term translations over a parallel corpus. Theproposal was validated by means of experiments using queries in two distinct languages:Portuguese and Finnish to retrieve documents in English. The results show that theperformance of our proposed approach is comparable to the performance of themonolingual baseline and to query translation via machine translation; even though thesesystems employ more complex Natural Language Processing techniques. The combinationbetween machine translation and our approach yielded the best results; even …,International Symposium on String Processing and Information Retrieval,2009,4
Multilingual emotion classification using supervised learning: Comparative experiments,Karin Becker; Viviane P Moreira; Aline GL dos Santos,Abstract The importance of emotion mining is acknowledged in a wide range of newapplications; thus broadening the potential market already proven for opinion mining.However; the lack of resources for languages other than English is even more critical foremotion mining. In this article; we investigate whether Multilingual Sentiment Analysisdelivers reliable and effective results when applied to emotions. For this purpose; wedeveloped experiments involving machine translations over corpora originally written in twolanguages. Our experimental framework for emotion classification assesses variations on (i)the language of the original text and its translations;(ii) strategies to combine multiplelanguages to overcome losses due to translation;(iii) options for data pre-processing(tokenization; feature representation and feature selection); and (iv) classification …,Information Processing & Management,2017,3
Choosing values for text fields in web forms,Gustavo Zanini Kantorski; Tiago Guimaraes Moraes; Viviane Pereira Moreira; Carlos Alberto Heuser,Abstract Since the only way to gain access to Hidden Web data is through form submission;one of the challenges is how to fill Web forms automatically. In this paper; we proposealgorithms which address this challenge. We describe an efficient method to select goodvalues for text fields and a technique which minimizes the number of form submissions andsimultaneously maximizes the number of rows retrieved from the underlying database.Experiments using real Web forms show the advantages of our proposed approaches.,*,2013,3
Queries to Temporal Databases Supporting Schema Versioning.,Viviane Pereira Moreira; Nina Edelweiss,Abstract The conceptual schema (intention) and raw data (extension) are evolving entitieswhich require adequate support for past; present and even future versions. TemporalDatabases supporting schema evolution were developed with the aim of satisfying thisneed. The support for schema versioning raises two complex subjects: the storage of theseveral schema versions and their associate data; and the processing of queries that involvemore than one schema version. The main objective of this work is to analyse the secondaspect in order to propose a strategy for answering those queries. In an environmentsupporting schema versioning the complete history of schema evolution is kept. In manyoccasions it can be necessary to query the database's structure; so this work proposes anextension to the temporal query language TSQL2 in order to support queries to …,SBBD,1999,3
ARCTIC: metadata extraction from scientific papers in pdf using two-layer CRF,Alan Souza; Viviane Moreira; Carlos Heuser,Abstract Most scientific articles are available in PDF format. The PDF standard allows thegeneration of metadata that is included within the document. However; many authors do notdefine this information; making this feature unreliable or incomplete. This fact has beenmotivating research which aims to extract metadata automatically. Automatic metadataextraction has been identified as one of the most challenging tasks in documentengineering. This work proposes Artic; a method for metadata extraction from scientificpapers which employs a two-layer probabilistic framework based on Conditional RandomFields. The first layer aims at identifying the main sections with metadata information; andthe second layer finds; for each section; the corresponding metadata. Given a PDF filecontaining a scientific paper; Artic extracts the title; author names; emails; affiliations; and …,Proceedings of the 2014 ACM symposium on Document engineering,2014,2
Um estudo de caso de mineração de emoções em textos multilíngues,Aline Graciela Lermen dos Santos; Karin Becker; Viviane Moreira,Abstract. Multilingual Opinion Mining deals with the analysis of opinions regardless of thelanguage in which they are written. The vast majority of the work in this area focuses solelyon classifying the polarity of the sentiment; overlooking the analysis of the emotions. In orderto fill this gap; this work presents a case study about the classification of emotions present inproduct reviews; evaluating an approach that combines lexicon-based emotion classificationand automatic translation. The case study aims at finding out if it is best to translate the textof the reviews or the dictionary. It also evaluates whether lemmatization can bring anybenefits. The results of our experiments on real data show that translating the reviews yieldsbetter results and that lemmatization does not bring significant changes. Resumo. O objetivoda Mineração de Opinião Multilíngue é extrair e analisar textos contendo opiniões …,*,2014,2
Using Simple Content Features for the Author Profiling Task Notebook for PAN at CLEF 2013,Edson RD Weren; Viviane P Moreira; José PM De Oliveira,Abstract This paper describes the methods we have employed to solve the au-thor profilingtask at PAN-2013. Our goal was to use simple features to identify the age group and thegender of the author of a given text. We introduce the fea-tures; detail how the classifierswere trained; and how the experiments were run. 1,*,2013,2
BBK-UFRGS@ CLEF2009: Query Expansion of Geographic Place Names.,Richard Flemmings; Joana Barros; André Pinto Geraldo; Viviane Pereira Moreira,Abstract For our first participation on CLEF; our aim was to compare plain informationretrieval strategies and query expansion and emphasis of geographic terms. ANNIE wasused to recognise geographic entities which were expanded using Google's HierarchicalList of Geographical Place Names. The idea was that the expansion would produce moreaccurate answers. The results have shown the opposite. Our best performing run was thebaseline. Future work will include further experiments and a deeper analysis of our results inorder to enable the design of a better performing strategy.,CLEF (Working Notes),2009,2
Automatically training form classifiers,Mauricio C Moraes; Carlos A Heuser; Viviane P Moreira; Denilson Barbosa,Abstract The state-of-the-art in domain-specific Web form discovery relies on supervisedmethods requiring substantial human effort in providing training examples; which limits theirapplicability in practice. This paper proposes an effective alternative to reduce the humaneffort: obtaining high-quality domain-specific training forms. In our approach; the only userinput is the domain of interest; we use a search engine and a focused crawler to locatequery forms which are fed as training data into supervised form classifiers. We tested thisapproach thoroughly; using thousands of real Web forms from six domains; including arepresentative subset of a publicly available form base to validate this approach. The resultsreported in this paper show that it is feasible to mitigate the demanding manual workrequired by some methods of the current state-of-the-art in form discovery; at the cost of a …,International Conference on Web Information Systems Engineering,2013,1
A test collection to evaluate plagiarism by missing or incorrect references,Solange de L Pertile; Viviane P Moreira,Abstract In recent years; several methods and tools been developed together with testcollections to aid in plagiarism detection. However; both methods and collections havefocused on content analysis; overlooking citation analysis. In this paper; we aim at filling thisgap and present a test collection with cases of plagiarism by missing and incorrectreferences. The collection contains automatically generated academic papers in whichpassages from other documents have been inserted. Such passages were either:adequately referenced (ie; not plagiarized); not referenced; or incorrectly referenced.Annotation files identifying each passage enable the evaluation of plagiarism detectionsystems.,International Conference of the Cross-Language Evaluation Forum for European Languages,2012,1
UFRGS@ PAN2010: Detecting External Plagiarism,Rafael Corezola Pereira; Viviane P Moreira; Renata Galante,Abstract. This paper presents our approach to detect plagiarism in the PAN'10 competition.To accomplish this task we applied a method which aims at detecting external plagiarismcases. The method is specially designed to detect crosslanguage plagiarism and iscomposed by five phases: language normalization; retrieval of candidate documents;classifier training; plagiarism analysis; and post-processing. Our group got the seventh placein the competition with an overall score of 0.5175. It is important to notice that the final scorewas affected by our low recall (0.4036) which arose as a result of not detecting intrinsicplagiarism cases; which were also present in the competition corpus.,LAB Report for PAN at CLEF,2010,1
UFRGS@ CLEF2009: retrieval by numbers,Thyago Bohrer Borges; Viviane P Moreira,Abstract For UFRGS's participation on CLEF's Robust task; our aim was to compare retrievalof plain documents to retrieval using information on word senses. The experimental runswhich used word-sense disambiguation (WSD) consisted in indexing the synset codes of thesenses which had scores higher than a predefined threshold. Several thresholds weretested. Our results have shown that the best WSD runs did not present a significantimprovement in relation to the baseline run in which plain documents were used. In addition;a comparison between two alternative disambiguation systems has shown that oneoutperforms the other in all experimental runs.,Workshop of the Cross-Language Evaluation Forum for European Languages,2009,1
Análise quantitativa e temporal do Wikigrafo-PT,Marcelo Zambiasi; Thiago A Presa; Luciana S Buriol; Viviane M Orengo,Abstract. The Wikipedia is an online encyclopedia available in about 200 languages. ItsPortuguese version currently contains over 200 thousand articles. If we consider eachWikipedia article as a vertex and each link as an arc; we have what we call a “Wikigraph”.This graph differs from other Web mainly graphs because it has temporal informationassociated to its nodes. The aim of this paper is to do a quantitative analysis of thePortuguese Wikigraph's (Wikigraph-PT) temporal data. The analysis of this graph revealedthat it presents features that are commonly found on other Webgraphs; which confirmsresults of prior studies on the English Wikigraph (Wikigraph-EN). Resumo. A Wikipédia éuma enciclopédia online disponıvel em cerca de 200 lınguas que possui mais de 200 milartigos na sua versao em português. Se considerarmos cada artigo da Wikipédia como …,*,2007,1
Exploration of User Groups in VEXUS,Sihem Amer-Yahia; Behrooz Omidvar-Tehrani; Joao Comba; Viviane Moreira; Fabian Colque Zegarra,Abstract: We introduce VEXUS; an interactive visualization framework for exploring userdata to fulfill tasks such as finding a set of experts; forming discussion groups and analyzingcollective behaviors. User data is characterized by a combination of demographics like ageand occupation; and actions such as rating a movie; writing a paper; following a medicaltreatment or buying groceries. The ubiquity of user data requires tools that help explorers; bethey specialists or novice users; acquire new insights. VEXUS lets explorers interact withuser data via visual primitives and builds an exploration profile to recommend the nextexploration steps. VEXUS combines state-of-the-art visualization techniques withappropriate indexing of user data to provide fast and relevant exploration. Subjects:Databases (cs. DB) Cite as: arXiv: 1712.03529 [cs. DB](or arXiv: 1712.03529 v1 [cs. DB] …,arXiv preprint arXiv:1712.03529,2017,*
Identifying sentiment-based contradictions,Danny Suarez Vargas; Viviane Moreira,Abstract. Contradiction Analysis is a relatively new multidisciplinary and complex area with themain goal of identifying contradictory pieces of text. It can be addressed from the perspectivesof different research areas such as Natural Language Processing; Opinion Mining; InformationRetrieval; and Information Extraction. This article focuses on the problem of detectingsentiment-based contradictions which occur in the sentences of a given review text. Unlike othertypes of contradictions; the detection of sentiment-based contradictions can be tackled as apost-processing step in the traditional sentiment analysis task. In this context; we adapted andextended an existing contradiction analysis framework by filtering its results to remove the reviewsthat are erroneously labeled as contradictory. The filtering method is based on two simple termsimilarity algorithms which relies on sets of known positive and negative words. An …,Journal of Information and Data Management,2017,*
Offensive Comments in the Brazilian Web: a dataset and baseline results,Rogers Prates de Pelle Pelle; Viviane P Moreira Moreira,Resumo Brazilian Web users are among the most active in social networks and very keenon interacting with others. Offensive comments; known as hate speech; have been plaguingonline media and originating a number of lawsuits against companies which publish Webcontent. Given the massive number of user generated text published on a daily basis;manually filtering offensive comments becomes infeasible. The identification of offensivecomments can be treated as a supervised classification task. In order to obtain a model toclassify comments; an annotated dataset containing positive and negative examples isnecessary. The lack of such a dataset in Portuguese; limits the development of detectionapproaches for this language. In this paper; we describe how we created annotated datasetsof offensive comments for Portuguese by collecting news comments on the Brazilian Web …,Congresso da Sociedade Brasileira de Computação-CSBC,2017,*
DuelMerge: Merging with Fewer Moves,Sergio LS Mergen; Viviane P Moreira,Abstract This work proposes duelmerge; a stable merging algorithm that is asymptoticallyoptimal in the number of comparisons and performs O (n log 2 (n)) moves. Unlike otherpartition-based algorithms; we only allow blocks of equal sizes to be swapped; whichreduces the number of moves required. We performed experiments comparing duelmergeagainst a number of baselines including recmerge; the standard merging solution forprogramming languages such as C; and some more recent approaches. The results showthat our proposed algorithm performs fewer moves than other stable solutions. Experimentsemploying duelmerge within MergeSort confirmed our positive results in terms of moves;comparisons and runtime.,*,2017,*
On the application of focused crawling for statistical machine translation domain adaptation,Bruno Rezende Laranjeira,Statistical Machine Translation (SMT) is highly dependent on the availability of parallelcorpora for training. However; these kinds of resource may be hard to be found; especiallywhen dealing with under-resourced languages or very specific domains; like thedermatology. For working this situation around; one possibility is the use of comparablecorpora; which are much more abundant resources. One way of acquiring comparablecorpora is to apply Focused Crawling (FC) algorithms. In this work we propose novelapproach for FC algorithms; some based on n-grams and other on the expressive power ofmultiword expressions. We also assess the viability of using FC for performing domainadaptations for generic SMT systems and whether there is a correlation between the qualityof the FC algorithms and of the SMT systems that can be built with its collected data …,*,2015,*
UFRGS: Identifying Categories and Targets in Customer Reviews,Anderson Kauer; Viviane Moreira,Abstract This paper reports on our participation in SemEval-2015 Task 12; which wasdevoted to Aspect-Based Sentiment Analysis. Participants were required to identify thecategory (entity and attribute); the opinion target; and the polarity of customer reviews. Thesystem we built relies on classification algorithms to identify aspect categories and on a setof rules to identify the opinion target. We propose a two-phase classification approach forcategory identification and use a simple method for polarity detection. Our results outperformthe baseline in many cases; which means our system could be used as an alternative foraspect classification.,Proceedings of the 9th International Workshop on Semantic Evaluation (SemEval 2015),2015,*
Atribuição de perfis de autoria,Edson Roberto Duarte Weren,A identificação de perfis de autoria visa classificar os textos com base nas escolhasestilísticas de seus autores. A ideia é descobrir as características dos autores dos textos.Esta tarefa tem uma importância crescente em análise forense; segurança e marketing.Neste trabalho; nos concentramos em descobrir a idade e o gênero dos autores de blogs.Com este objetivo em mente; analisamos um grande número de atributos-que variam derecuperação de informação até análise de sentimento. Esta dissertação relata a utilidadedesses atributos. Uma avaliação experimental em um corpus com mais de 236K posts deblogs mostrou que um classificador usando os atributos explorados aqui supera o estado-da arte. Mais importante ainda; as experiências mostram que os atributos oriundos derecuperação de informação propostos neste trabalho são os mais discriminativos e …,*,2014,*
Mineração de Emoções em Textos Multilíngues usando um Corpus Paralelo.,Aline Rode dos Santos; Karin Becker; Viviane Pereira Moreira,Abstract. Multilingual Opinion Mining deals with the analysis of opinions; regardless of thelanguage in which they are written. Works in this area focus on the classification of thepolarity of opinions extracted from texts; and less attention has been paid to the classificationof emotions. This work proposes the use of Multilingual Opinion Mining techniques foremotion mining using parallel corpora. We developed experiments with two goals: 1) tocompare two approaches for emotion classification: lexicon-based and machine learning-based; 2) to analyze whether a specific language produces better classification results. Wedeveloped experiments with a parallel corpus composed by lyrics in their original language(English) and their translations to Portuguese. The results show that machine learning issuperior to the use of sentiment lexicon; and that there is no statistical difference …,SBBD,2014,*
Clustering Wikipedia infoboxes to discover their types,Thanh Hoang Nguyen; Huong Dieu Nguyen; Viviane Moreira; Juliana Freire,Abstract Wikipedia has emerged as an important source of structured information on theWeb. But while the success of Wikipedia can be attributed in part to the simplicity of addingand modifying content; this has also created challenges when it comes to using; querying;and integrating the information. Even though authors are encouraged to select appropriatecategories and provide infoboxes that follow pre-defined templates; many do not follow theguidelines or follow them loosely. This leads to undesirable effects; such as templateduplication; heterogeneity; and schema drift. As a step towards addressing this problem; wepropose a new unsupervised approach for clustering Wikipedia infoboxes. Instead of relyingon manually assigned categories and template labels; we use the structured informationavailable in infoboxes to group them and infer their entity types. Experiments using over …,Proceedings of the 21st ACM international conference on Information and knowledge management,2012,*
Identifying Parallel Web Pages,Marcela Macedo Vieira; Viviane Pereira Moreira,Abstract Research on statistical machine translation and corpus-based approaches for cross-language information retrieval depend on the availability of multilingual data; particularly inthe form of parallel corpora (collections of equivalent texts in two or more languages).However; the scarcity of parallel corpora limits the development of these applications. TheWeb is a vast repository of multilingual information; which has motivated research aimed atmining corpora from it. In this article; we present PPLocator an approach for locating parallelWeb pages. PPLocator was designed to be effective while keeping a low processing cost;thus it avoids making exhaustive pairwise comparisons in order to identify the candidatepairs. In addition; it tries to minimize the number of pages that need to be downloadedduring the intra-site crawl. An important characteristic of our approach is that it does not …,Journal of Information and Data Management,2012,*
Cell assemblies for query expansion in Information Retrieval,Isabel Volpe; Viviane Moreira; Christian Huyck,One of the main tasks in Information Retrieval is to match a user query to the documents thatare relevant for it. This matching is challenging because in many cases the keywords theuser chooses will be different from the words the authors of the relevant documents haveused. Throughout the years; many approaches have been proposed to deal with thisproblem. One of the most popular consists in expanding the query with related terms with thegoal of retrieving more relevant documents. In this paper; we propose a new method inwhich a Cell Assembly model is applied for query expansion. Cell Assemblies arereverberating circuits of neurons that can persist long beyond the initial stimulus has ceased.They learn through Hebbian Learning rules and have been used to simulate the formationand the usage of human concepts. We adapted the Cell Assembly model to learn …,Neural Networks (IJCNN); The 2011 International Joint Conference on,2011,*
Sixteenth ACM Conference on Information Knowledge and Management (CIKM 2007),Carina F Dorneles; Marcos Freitas Nunes; Carlos A Heuser; Viviane P Moreira; Edleno S de Moura; Sara Cohen; Tali Brodianskiy; Alan Feuer; Stefan Savev; Javed A Aslam; Susan L Price; Marianne Lykke Nielsen; Lois ML Delcambre; Peter Vedsted; Jeremy Steinhauer; Dmitri Roussinov; Ozgur Turetken; Jonathan Yu; James A Thom; Audrey Tam; Nicola Fanizzi; Claudia d’Amato; Floriana Esposito,Read the latest articles of Information Systems at ScienceDirect.com; Elsevier'sleading platform of peer-reviewed scholarly literature.,*,2009,*
Aplicando algoritmos de mineração de regras de associação para recuperação de informações multilíngues.,André Pinto Geraldo,Este trabalho propõe a utilização de algoritmos de mineração de regras de associação paraa Recuperação de Informações Multilíngues. Esses algoritmos têm sido amplamenteutilizados para analisar transações de registro de vendas. A ideia é mapear o problema deencontrar associações entre itens vendidos para o problema de encontrar termosequivalentes entre idiomas diferentes em um corpus paralelo. A proposta foi validada pormeio de experimentos com diferentes idiomas; conjuntos de consultas e corpora. Osresultados mostram que a eficácia da abordagem proposta é comparável ao estado da arte;ao resultado monolíngue e à tradução automática de consultas; embora este utilize técnicasmais complexas de processamento de linguagem natural. Foi criado um protótipo que fazconsultas à Web utilizando o método proposto. O sistema recebe palavras-chave em …,*,2009,*
Indexing multiword expressions for information retrieval,Otavio Costa Acosta; André Pinto Geraldo; Viviane Pereira Moreira; Aline Villavicencio,Abstract For UFRGS's participation on CLEF's Robust task; our aim was to assess thebenefits of identifying and indexing Multiword Expressions (MWEs) for Information Retrieval.The approach used for MWE identification was totally statistical; based associationmeasures such as Mutual Information and Chi-square. Contradicting our results on thetraining topics; the results on the test topics did not show any significant improvements.However; for some queries; the identification of MWEs was very important. We have alsoperformed bilingual experiments which achieved 84% of their monolingual counterparts.,Workshop on Cross Language Evaluation Forum (9.: 2008 Sept.: Aarhus; Denmark). Working Notes for the CLEF 2008 Workshop; 17-19 September; Aarhus; Denmark [recurso eletrônico].[Sl: sn; 2008?],2008,*
Using association rules for cross-language information retrieval,André Pinto Geraldo; Viviane Pereira Moreira,Abstract For UFRGS's participation on the TEL task at CLEF2008; our aim was to assess thevalidity of using algorithms for mining association rules to find mappings between conceptson a Cross-Language Information Retrieval scenario. Our approach requires a sample ofparallel documents to serve as the basis for the generation of the association rules. Theresults of the experiments show that the performance of our approach is not statisticallydifferent from the monolingual baseline in terms of mean average precision. This is anindication that association rules can be effectively used to map concepts betweenlanguages. We have also tested a modification to BM25 that aims at increasing the weight ofrare terms. The results show that this modified version achieved better performance. Theimprovements were considered to be statistically significant in terms of MAP on our …,Workshop on Cross Language Evaluation Forum (9.: 2008 Sept.: Aarhus; Denmark). Working Notes for the CLEF 2008 Workshop; 17-19 September; Aarhus; Denmark [recurso eletrônico].[Sl: sn; 2008?],2008,*
Part I-Multilingual Textual Document Retrieval (Ad Hoc)-Monolingual-A Study on the Use of Stemming for Monolingual Ad-Hoc Portuguese Information Retrieval,Viviane Moreira Orengo; Luciana S Buriol; Alexandre Ramos Coelho,*,Lecture Notes in Computer Science,2007,*
Extraç ao de dados de conferências a partir da Web,Cássio Alan Garcia; Viviane P Moreira,Abstract. Choosing the most suitable conference to submit a paper is a task that depends ona number of factors including:(i) the topic of the paper needs to be among the topics ofinterest of the conference;(ii) submission deadlines need to be compatible with thenecessary time for paper writing; and (iii) the quality or impact of the conference. Thesefactors allied to the existence of thousands of conferences; make the search of the rightevent very time consuming; especially when researching in a new area. Intending to helpresearchers finding conferences; this paper presents a method developed to retrieve andextract data from conferences web sites. Our method combines the identification ofconference URL and deadline extraction. The retrieved data is stored in a database to besearched with an online tool. The paper also reports on experiments that evaluate the …,*,*,*
Visualizing Hotel Reviews: a Case Study using TripAdvisor Data,Fabian Colque; Joao LD Comba; Viviane Moreira,Abstract—Finding hotels that are suited to one's needs can be a time-consuming task. In thisprocess; people usually rely on customer reviews from travel websites. These websitestypically contain many reviews shown in a textual format and a chart that summarizes theoverall opinion about a given hotel. In order to compare a number of hotels; users will needto read many reviews and navigate through many web pages. With the goal of aiding usersin this process; in this paper; we propose a visual tool for hotel comparison. The toolsfocuses on the most important aspects that can be extracted from hotel reviews (location;cleanliness; rooms; etc.) and it allows ordering the hotels by one or more of these aspects.We display aspect information using stacked bar charts alongside their ranking; whichbecomes very useful for comparing hotels. Additionally; we provide a scatterplot matrix …,*,*,*
Coleta de Corpora Paralelos,Marcela Macedo Vieira; Viviane Moreira,Resumo. A pesquisa em Processamento de Linguagem Natural e Recuperação deInformações Multilíngues depende da disponibilidade de dados; sobretudo de corporaparalelos (coleções de textos equivalentes em dois ou mais idiomas); preferencialmentesobre domínios específicos. Entretanto; a escassez de corpora paralelos limita odesenvolvimento destas aplicações. A Web é um imenso repositório de informaçõesmultilíngues; o que tem motivado pesquisas que visam minerar corpora a partir dela. Estetrabalho visa desenvolver um coletor focado de corpora paralelos na Web que localize aspáginas relevantes de maneira automática e eficiente. Dado um tópico e uma lista deidiomas; o objetivo é que textos paralelos nos idiomas especificados sejam identificados ecoletados.,*,*,*
The Database Research Group at UFRGS,JPM de Oliveira; CA Heuser; C Iocphpe; JV de Lima; K Becker; LK Wives; M Abel; R Galante; VP Moreira,Abstract. This paper presents the database group at the Instituto de Informática of theUniversidade Federal do Rio Grande do Sul; in Porto Alegre; Brazil. It is one of the oldestdatabase groups in the country; being active for over 30 years. Research subjects cover abroad range of topics such as Data Integration; Conceptual Modeling and Ontology; Dataand Schema Matching; XML databases; Information Retrieval; Data Mining; Web Mining andRecommender Systems; Text Mining and Web Services. Our group also collaborates withseveral Database research groups in Brazil and abroad. The paper introduces the activeresearchers in the group; describes the main topics of research; details the main researchtopics and collaborations.,*,*,*
Using Structure to Discover Types and Relationships for Wikipedia Infoboxes,Thanh Nguyen; Huong Nguyen; Viviane Moreira; Juliana Freire,*,*,*,*
Cell Assemblies for Query Expansion,Isabel Volpe; Viviane Moreira,Abstract This paper applies the Cell Assemblies (CAs) model to Information Retrieval. CAsare reverberating circuits of neurons that can persist long beyond the initial stimulus hasceased. CAs are learned through Hebbian learning rules and have been used to simulatethe formation and the usage of human concepts. We adapted the CAs model to learnrelationships between the terms in a document collection. The method will be validated bymeans of experiments on standard IR test collections.,*,*,*
Cross-Language Information Retrieval using Algorithms for Min-ing Association Rules,André Pinto Geraldo; Viviane Pereira Moreira,Cross-Language Information Retrieval (CLIR) is the retrieval of documents in one naturallanguage; based on a query formulated in another natural language; eg retrieval ofdocuments written in English based on a set of keywords in Portuguese. The mainmotivation for CLIR is the growing need for exploring documents in foreign languages. Thisneed has increased dramatically with the explosive growth of the Internet. The Web hascontent in many languages and the distribution of this content by language is very differentfrom the distribution of Internet access. While English is still dominant in terms of content (~66%)[8]; the percentage of users that access the Internet in English is less than 30%[16].Despite being one of the languages with the largest number of native speakers; Portugueseis an extremely underrepresented language on the Web. It is estimated that only 1.4% of …,*,*,*
