The end of an architectural era:(it's time for a complete rewrite),Michael Stonebraker; Samuel Madden; Daniel J Abadi; Stavros Harizopoulos; Nabil Hachem; Pat Helland,Abstract In previous papers [SC05; SBC+ 07]; some of us predicted the end of" one size fitsall" as a commercial relational DBMS paradigm. These papers presented reasons andexperimental evidence that showed that the major RDBMS vendors can be outperformed by1--2 orders of magnitude by specialized engines in the data warehouse; stream processing;text; and scientific database markets. Assuming that specialized engines dominate thesemarkets over time; the current relational DBMS code lines will be left with the business dataprocessing (OLTP) market and hybrid markets where more than one kind of capability isrequired. In this paper we show that current RDBMSs can be beaten by nearly two orders ofmagnitude in the OLTP market as well. The experimental evidence comes from comparing anew OLTP prototype; H-Store; which we have built at MIT to a popular RDBMS on the …,Proceedings of the 33rd international conference on Very large data bases,2007,693
OLTP through the looking glass; and what we found there,Stavros Harizopoulos; Daniel J Abadi; Samuel Madden; Michael Stonebraker,Abstract Online Transaction Processing (OLTP) databases include a suite of features-disk-resident B-trees and heap files; locking-based concurrency control; support for multi-threading-that were optimized for computer technology of the late 1970's. Advances inmodern processors; memories; and networks mean that today's computers are vastlydifferent from those of 30 years ago; such that many OLTP databases will now fit in mainmemory; and most OLTP transactions can be processed in milliseconds or less. Yetdatabase architecture has changed little. Based on this observation; we look at someinteresting variants of conventional database systems that one might build that exploit recenthardware trends; and speculate on their performance through a detailed instruction-levelbreakdown of the major components involved in a transaction processing database …,Proceedings of the 2008 ACM SIGMOD international conference on Management of data,2008,283
Column-oriented database systems,Daniel J Abadi; Peter A Boncz; Stavros Harizopoulos,Abstract Column-oriented database systems (column-stores) have attracted a lot of attentionin the past few years. Column-stores; in a nutshell; store each database table columnseparately; with attribute values belonging to the same column stored contiguously;compressed; and densely packed; as opposed to traditional database systems that storeentire records (rows) one after the other. Reading a subset of a table's columns becomesfaster; at the potential expense of excessive disk-head seeking from column to column forscattered reads or updates. After several dozens of research papers and at least a dozen ofnew column-store start-ups; several questions remain. Are these a new breed of systems orsimply old wine in new bottles? How easily can a major row-based system achieve column-store performance? Are column-stores the answer to effortlessly support large-scale data …,Proceedings of the VLDB Endowment,2009,252
Analyzing the energy efficiency of a database server,Dimitris Tsirogiannis; Stavros Harizopoulos; Mehul A Shah,Abstract Rising energy costs in large data centers are driving an agenda for energy-efficientcomputing. In this paper; we focus on the role of database software in affecting; and;ultimately; improving the energy efficiency of a server. We first characterize the power-useprofiles of database operators under different configuration parameters. We find thatcommon database operations can exercise the full dynamic power range of a server; andthat the CPU power consumption of different operators; for the same CPU utilization; candiffer by as much as 60%. We also find that for these operations CPU power does not varylinearly with CPU utilization. We then experiment with several classes of database systemsand storage managers; varying parameters that span from different query plans tocompression algorithms and from physical layout to CPU frequency and operating system …,Proceedings of the 2010 ACM SIGMOD International Conference on Management of data,2010,223
Performance tradeoffs in read-optimized databases,Stavros Harizopoulos; Velen Liang; Daniel J Abadi; Samuel Madden,Abstract Database systems have traditionally optimized performance for write-intensiveworkloads. Recently; there has been renewed interest in architectures that optimize readperformance by using column-oriented data representation and light-weight compression.This previous work has shown that under certain broad classes of workloads; column-basedsystems can outperform row-based systems. Previous work; however; has not characterizedthe precise conditions under which a particular query workload can be expected to performbetter on a column-oriented database. In this paper we first identify the distinctivecomponents of a read-optimized DBMS and describe our implementation of a high-performance query engine that can operate on both row and column-oriented data. We thenuse our prototype to perform an in-depth analysis of the tradeoffs between column and …,Proceedings of the 32nd international conference on Very large data bases,2006,211
QPipe: a simultaneously pipelined relational query engine,Stavros Harizopoulos; Vladislav Shkapenyuk; Anastassia Ailamaki,Abstract Relational DBMS typically execute concurrent queries independently by invoking aset of operator instances for each query. To exploit common data retrievals and computationin concurrent queries; researchers have proposed a wealth of techniques; ranging frombuffering disk pages to constructing materialized views and optimizing multiple queries. Theideas proposed; however; are inherently limited by the query-centric philosophy of modernengine designs. Ideally; the query engine should proactively coordinate same-operatorexecution among concurrent queries; thereby exploiting common accesses to memory anddisks as well as common intermediate result computation. This paper introduces on-demandsimultaneous pipelining (OSP); a novel query evaluation paradigm for maximizing data andwork sharing across concurrent queries at execution time. OSP enables proactive …,Proceedings of the 2005 ACM SIGMOD international conference on Management of data,2005,174
Query processing techniques for solid state drives,Dimitris Tsirogiannis; Stavros Harizopoulos; Mehul A Shah; Janet L Wiener; Goetz Graefe,Abstract Solid state drives perform random reads more than 100x faster than traditionalmagnetic hard disks; while offering comparable sequential read and write bandwidth.Because of their potential to speed up applications; as well as their reduced powerconsumption; these new drives are expected to gradually replace hard disks as the primarypermanent storage media in large data centers. However; although they may benefitapplications that stress random reads immediately; they may not improve databaseapplications; especially those running long data analysis queries. Database queryprocessing engines have been designed around the speed mismatch between random andsequential I/O on hard disks and their algorithms currently emphasize sequential accessesfor disk-resident data. In this paper; we investigate data structures and algorithms that …,Proceedings of the 2009 ACM SIGMOD International Conference on Management of data,2009,155
Energy efficiency: The new holy grail of data management systems research,Stavros Harizopoulos; Mehul Shah; Justin Meza; Parthasarathy Ranganathan,Abstract: Energy costs are quickly rising in large-scale data centers and are soon projectedto overtake the cost of hardware. As a result; data center operators have recently startedturning into using more energy-friendly hardware. Despite the growing body of research inpower management techniques; there has been little work to date on energy efficiency froma data management software perspective. In this paper; we argue that hardware-onlyapproaches are only part of the solution; and that data management software will be key inoptimizing for energy efficiency. We discuss the problems arising from growing energy usein data centers and the trends that point to an increasing set of opportunities for software-level optimizations. Using two simple experiments; we illustrate the potential of suchoptimizations; and; motivated by these examples; we discuss general approaches for …,arXiv preprint arXiv:0909.1784,2009,142
The design and implementation of modern column-oriented database systems,Daniel Abadi; Peter Boncz; Stavros Harizopoulos; Stratos Idreos; Samuel Madden,Abstract In this article; we survey recent research on column-oriented database systems; orcolumn-stores; where each attribute of a table is stored in a separate file or region onstorage. Such databases have seen a resurgence in recent years with a rise in interest inanalytic queries that perform scans and aggregates over large portions of a few columns of atable. The main advantage of a column-store is that it can access just the columns needed toanswer such queries. We specifically focus on three influential research prototypes;MonetDB [46]; MonetDB/X100 [18]; and C-Store [86]. These systems have formed the basisfor several well-known commercial column-store implementations. We describe theirsimilarities and differences and discuss their specific architectural features for compression;late materialization; join processing; vectorization and adaptive indexing (database …,Foundations and Trends® in Databases,2013,124
One size fits all? Part 2: Benchmarking results,Michael Stonebraker; Chuck Bear; Uğur Çetintemel; Mitch Cherniack; Tingjian Ge; Nabil Hachem; Stavros Harizopoulos; John Lifter; Jennie Rogers; Stan Zdonik,ABSTRACT Two years ago; some of us wrote a paper predicting the demise of “One SizeFits All (OSFA)”[Sto05a]. In that paper; we examined the stream processing and datawarehouse markets and gave reasons for a substantial performance advantage tospecialized architectures in both markets. Herein; we make three additional contributions.First; we present reasons why the same performance advantage is enjoyed by specializedimplementations in the text processing market. Second; the major contribution of the paper isto show “apples to apples” performance numbers between commercial implementations ofspecialized architectures and relational DBMSs in both stream processing and datawarehouses. Finally; we also show comparison numbers between an academic prototype ofa specialized architecture for scientific and intelligence applications; a relational DBMS …,Conference on Innovative Data Systems Research (CIDR),2007,122
Fast scans and joins using flash drives,Mehul A Shah; Stavros Harizopoulos; Janet L Wiener; Goetz Graefe,Abstract As access times to main memory and disks continue to diverge; faster non-volatilestorage technologies become more attractive for speeding up data analysis applications.NAND flash is one such promising substitute for disks. Flash offers faster random reads thandisk; consumes less power than disk; and is cheaper than DRAM. In this paper; weinvestigate alternative data layouts and join algorithms suited for systems that use flashdrives as the non-volatile store. All of our techniques take advantage of the fast randomreads of flash. We convert traditional sequential I/O algorithms to ones that use a mixture ofsequential and random I/O to process less data in less time. Our measurements oncommodity flash drives show that a column-major layout of data pages is faster than atraditional row-based layout for simple scans. We present a new join algorithm; RARE …,Proceedings of the 4th international workshop on Data management on new hardware,2008,74
A case for staged database systems,Stavros Harizopoulos; Anastassia Ailamaki,Abstract Traditional database system architectures face a rapidly evolving operatingenvironment; where millions of users store and access terabytes of data. In order to copewith increasing demands for performance; high-end DBMS employ parallel processingtechniques coupled with a plethora of sophisticated features. However; the widely adopted;work-centric; thread-parallel execution model entails several shortcomings that limit serverperformance when executing workloads with changing requirements. Moreover; themonolithic approach in DBMS software has lead to complex and difficult to extend designs.This paper introduces a staged design for high-performance; evolvable DBMS that are easyto tune and maintain. We propose to break the database system into modules and toencapsulate them into self-contained stages connected to each other through queues …,*,2003,71
Scalable analysis platform for semi-structured data,*,A method of operating a query system includes retrieving objects from a data source;wherein each of the retrieved objects includes (i) data and (ii) metadata describing the data.The method includes dynamically creating a cumulative schema by inferring a schema fromeach of the retrieved objects and merging the inferred schema with the cumulative schema.The method includes storing the data of each of the retrieved objects in a storage service.The method includes receiving; from a user; a query; and responding to the query based ondata stored by the storage service.,*,2014,62
StagedDB: Designing Database Servers for Modern Hardware.,Stavros Harizopoulos; Anastassia Ailamaki,Abstract Advances in computer architecture research yield increasingly powerful processorswhich can execute code at a much faster pace than they can access data in the memoryhierarchy. Database management systems (DBMS); due to their intensive data processingnature; are in the front line of commercial applications which cannot harness the availablecomputing power. To prevent the CPU from idling; a multitude of hardware mechanisms andsoftware optimizations have been proposed. Their effectiveness; however; is limited by thesheer volume of data accessed and by the unpredictable sequence of memory requests. Inthis article we describe StagedDB; a new DBMS software architecture for optimizing dataand instruction locality at all levels of the memory hierarchy. The key idea is to breakdatabase request execution in stages and process a group of sub-requests at each stage …,IEEE Data Eng. Bull.,2005,52
To share or not to share?,Ryan Johnson; Stavros Harizopoulos; Nikos Hardavellas; Kivanc Sabirli; Ippokratis Pandis; Anastasia Ailamaki; Naju G Mancheril; Babak Falsafi,Abstract Intuitively; aggressive work sharing among concurrent queries in a databasesystem should always improve performance by eliminating redundant computation or dataaccesses. We show that; contrary to common intuition; this is not always the case in practice;especially in the highly parallel world of chip multiprocessors. As the number of cores in thesystem increases; a trade-off appears between exploiting work sharing opportunities and theavailable parallelism. To resolve the trade-off; we develop an analytical approach thatpredicts the effect of work sharing in multi-core systems. Database systems can use themodel to determine; statically or at runtime; whether work sharing is beneficial and apply itonly when appropriate. The contributions of this paper are as follows. First; we introduce andanalyze the effects of the trade-off between work sharing and parallelism on database …,Proceedings of the 33rd international conference on Very large data bases,2007,50
STEPS towards cache-resident transaction processing,Stavros Harizopoulos; Anastassia Ailamaki,Abstract Online transaction processing (OLTP) is a multibillion dollar industry with high-enddatabase servers employing state-of-the-art processors to maximize performance.Unfortunately; recent studies show that CPUs are far from realizing their maximum intendedthroughput because of delays in the processor caches. When running OLTP; instruction-related delays in the memory subsystem account for 25 to 40% of the total execution time. Incontrast to data; instruction misses cannot be overlapped with out-of-order execution; andinstruction caches cannot grow as the slower access time directly affects the processorspeed. The challenge is to alleviate the instruction-related delays without increasing thecache size. We propose Steps; a technique that minimizes instruction cache misses in OLTPworkloads by multiplexing concurrent transactions and exploiting common code paths …,Proceedings of the Thirtieth international conference on Very large data bases-Volume 30,2004,48
Towards energy-efficient database cluster design,Willis Lang; Stavros Harizopoulos; Jignesh M Patel; Mehul A Shah; Dimitris Tsirogiannis,Abstract Energy is a growing component of the operational cost for many" big data"deployments; and hence has become increasingly important for practitioners of large-scaledata analysis who require scale-out clusters or parallel DBMS appliances. Although anumber of recent studies have investigated the energy efficiency of DBMSs; none of thesestudies have looked at the architectural design space of energy-efficient parallel DBMSclusters. There are many challenges to increasing the energy efficiency of a DBMS cluster;including dealing with the inherent scaling inefficiency of parallel data processing; andchoosing the appropriate energy-efficient hardware. In this paper; we experimentallyexamine and analyze a number of key parameters related to these challenges for designingenergy-efficient database clusters. We explore the cluster design space using empirical …,Proceedings of the VLDB Endowment,2012,42
Improving instruction cache performance in OLTP,Stavros Harizopoulos; Anastassia Ailamaki,Instruction-cache misses account for up to 40% of execution time in Online TransactionProcessing (OLTP) database workloads. In contrast to data cache misses; instruction missescannot be overlapped with out-of-order execution. Chip design limitations do not allowincreases in the size or associativity of instruction caches that would help reduce misses. Onthe contrary; the effective instruction cache size is expected to further decrease with theadoption of Multicore and Multithreading chip designs (multiple onchip processor cores andmultiple simultaneous threads per core). Different concurrent database threads; however;execute similar instruction sequences over their lifetime; too long to be captured andexploited in hardware. The challenge; from a software designer's point of view; is to identifyand exploit common code paths across threads executing arbitrary operations; thereby …,ACM transactions on database systems,2006,33
Query co-processing on commodity processors,Anastassia Ailamaki; Naga K Govindaraju; Stavros Harizopoulos; Dinesh Manocha,Page 1. The UNIVERSITY of NORTH CAROLINA at CHAPEL HILL @Carnegie Mellon DatabasesQuery co-Processing on Commodity Processors Anastassia Ailamaki Carnegie Mellon UniversityNaga K. Govindaraju Dinesh Manocha University of North Carolina at Chapel Hill StavrosHarizopoulos MIT Page 2. The UNIVERSITY of NORTH CAROLINA at CHAPEL HILL @CarnegieMellon Databases © A. Ailamaki 2004-06 Technology shift towards multi-cores [Multipleprocessors on the same chip] Specint2000 1.00 10.00 100.00 1000.00 10000.00 85 86 87 8889 90 91 92 93 94 95 96 97 98 99 00 01 02 03 04 05 Intel Alpha Sparc Mips HP PA Pow er PCAMD Processor Performance over Time* Year of introduction Scalar Superscalar Out-of-orderSMT Performance *graph courtesy of Rakesh Kumar Page 3. The UNIVERSITY of NORTHCAROLINA at CHAPEL HILL @Carnegie Mellon Databases …,VLDB,2006,32
Affinity scheduling in staged server architectures,Stavros Harizopoulos; Anastassia Ailamaki,Abstract Modern servers typically process request streams by assigning a worker thread to arequest; and rely on a round robin policy for context-switching. Although this programmingparadigm is intuitive; it is oblivious to the execution state and ignores each softwaremodule's affinity to the processor caches. As a result; resumed threads of execution sufferadditional delays due to conflict and compulsory misses while populating the caches withtheir evicted working sets. Alternatively; the staged programming paradigm dividescomputation into stages and allows for stage-based (rather than request thread-based)cohort scheduling that improves module affinity. This technical report introduces (a) fournovel cohort scheduling techniques for staged software servers that follow a “production-line” model of operation; and (b) a mathematical framework to methodically quantify the …,*,2002,24
Database join optimized for flash storage,*,Computer-implemented systems and associated operating methods implement a fast join fordatabases which is adapted for usage with flash storage. A system comprises a processorthat performs a join of two tables stored in a storage in pages processed in a columnorientation wherein column values for all rows on a page are co-located in mini-pages withinthe page. The processor reduces input/output operations of the join by accessing only joincolumns and mini-pages containing join results.,*,2015,21
A case for micro-cellstores: energy-efficient data management on recycled smartphones,Stavros Harizopoulos; Spiros Papadimitriou,Abstract Increased energy costs and concerns for sustainability make the following questionmore relevant than ever: can we turn old or unused computing equipment into cost-andenergy-efficient modules that can be readily repurposed? We believe the answer is yes; andour proposal is to turn unused smartphones into micro-data center composable modules. Inthis paper; we introduce the concept of a Micro-Cellstore (MCS); a stand-alone data-appliance housing dozens of recycled smartphones. Through detailed power andperformance measurements on a Linux-based current-generation smartphone; we assessthe potential of MCSs as a data management platform. In this paper we focus on scan-basedpartitionable workloads. We show that smartphones are overall more energy efficient thanrecently proposed low-power alternatives; based on an initial evaluation over a wide …,Proceedings of the Seventh International Workshop on Data Management on New Hardware,2011,18
Repeatability & workability evaluation of SIGMOD 2009,Stefan Manegold; Ioana Manolescu; Loredana Afanasiev; Jianling Feng; Gang Gou; Marios Hadjieleftheriou; Stavros Harizopoulos; Panos Kalnis; Konstantinos Karanasos; Dominique Laurent; Mihai Lupu; Nicola Onose; Christopher Ré; Virginie Sans; Pierre Senellart; Tianyi Wu; Dennis Shasha,Abstract SIGMOD 2008 was the first database conference that offered to test submitters'programs against their data to verify the repeatability of the experiments published [1]. Giventhe positive feedback concerning the SIGMOD 2008 repeatability initiative; SIGMOD 2009modified and expanded the initiative with a workability assessment.,ACM SIGMOD Record,2010,17
Hathi: durable transactions for memory using flash,Mohit Saxena; Mehul A Shah; Stavros Harizopoulos; Michael M Swift; Arif Merchant,Abstract Recent architectural trends---cheap; fast solid-state storage; inexpensive DRAM;and multi-core CPUs---provide an opportunity to rethink the interface between applicationsand persistent storage. To leverage these advances; we propose a new system architecturecalled Hathi that provides an in-memory transactional heap made persistent using high-speed flash drives. With Hathi; programmers can make consistent concurrent updates to in-memory data structures that survive system failures. Hathi focuses on three major designgoals: ACID semantics; a simple programming interface; and fine-grained programmercontrol. Hathi relies on software transactional memory to provide a simple concurrentinterface to in-memory data structures; and extends it with persistent logs and checkpoints toadd durability.,Proceedings of the Eighth International Workshop on Data Management on New Hardware,2012,16
Column-oriented storage in a row-oriented database management system,*,Systems; methods; and computer-readable storage media are provided for column-orientedstorage in a row-oriented database management system. Data may be provided in one ormore columns; each datum associated with a position within a column. A list may be createdof one or more records per column; each record including a plurality of values stored in anorder of position within the column and a first positional indicator. An index may be createdto access a value stored in a record; wherein the index includes an index parameter derivedfrom each record in the list and the index parameters are ordered in accordance with anorder of records in the list.,*,2011,13
Simultaneous pipelining in QPipe: Exploiting work sharing opportunities across queries,Kun Gao; Stavros Harizopoulos; Ippokratis Pandis; Vladislav Shkapenyuk; Anastassia Ailamaki,Data warehousing and scientific database applications operate on massive datasets andare characterized by complex queries accessing large portions of the database. Concurrentqueries often exhibit high data and computation overlap; eg; they access the same relationson disk; compute similar aggregates; or share intermediate results. Unfortunately; run-timesharing in modern database engines is limited by the paradigm of invoking an independentset of operator instances per query; potentially missing sharing opportunities if the bufferpool evicts data early.,Data Engineering; 2006. ICDE'06. Proceedings of the 22nd International Conference on,2006,12
Prefetching into smart-disk caches for high performance media servers,Peter Triantafillou; Stavros Harizopoulos,The paper presents techniques which exploit recent magnetic disk-drive technologicaldevelopments (such as the existence of embedded drive-level caches and powerfulcontrollers; and the ever-increasing transfer rates). It contributes prefetching techniques intohost-and drive-level caches to improve the maximum number of continuous data streamsthat a drive can support. We show how our techniques can achieve significant performanceimprovements while guaranteeing the uninterrupted display of the continuous data. Inaddition; despite our techniques' utilization of drive-level caches; the performanceimprovements do not come at the expense of additional cache memory (at the host and/orthe drive). Given current technology trends; the benefits of our techniques are expected tobecome even greater.,Multimedia Computing and Systems; 1999. IEEE International Conference on,1999,12
Prefetching into smart-disk caches for high performance media servers,Peter Triantafillou; Stavros Harizopoulos,The paper presents techniques which exploit recent magnetic disk-drive technologicaldevelopments (such as the existence of embedded drive-level caches and powerfulcontrollers; and the ever-increasing transfer rates). It contributes prefetching techniques intohost-and drive-level caches to improve the maximum number of continuous data streamsthat a drive can support. We show how our techniques can achieve significant performanceimprovements while guaranteeing the uninterrupted display of the continuous data. Inaddition; despite our techniques' utilization of drive-level caches; the performanceimprovements do not come at the expense of additional cache memory (at the host and/orthe drive). Given current technology trends; the benefits of our techniques are expected tobecome even greater.,Multimedia Computing and Systems; 1999. IEEE International Conference on,1999,12
Transaction commitment and replication in a storage system,*,An embodiment provides a system and method for transaction commitment and replication.The method includes receiving a minitransaction from a client node at one or more memorynodes; wherein each memory node includes a number of replicas. The minitransaction is atype of transaction which atomically executes any combination of reading; comparing; andwriting to any of a number of memory locations. The method also includes determining; for aleader of the replicas within a memory node; whether the leader is able to commit theminitransaction and stabilizing state changes of the minitransaction within a transaction logusing a consensus procedure to update the replicas. The method further includescommitting the minitransaction if; at each memory node; a quorum of the replicas is able tostabilize the minitransaction; or aborting the minitransaction otherwise.,*,2017,11
Hierarchical caching and prefetching for continuous media servers with smart disks,Stavros Harizopoulos; Costas Harizakis; Peter Triantafillou,I/O controllers and SCSI controller as dif- ferent processing units; the data can flow between thedisk caches; the multiple disk controller buffer; and the host cache. We have developed severalalgorithms that exploit these coexisting elements in continuous media applications. Ouralgo- rithms work in parallel to retrieve; or “prefetch;” data from the disk surface to either the diskor the SCSI controller caches and concurrently transfer the data from the lower cache hierarchiesto the host cache. At the same time; the host streams the data from its RAM through the networkto the clients. As we will describe; this parallelism—which is mainly based on the intelligent controllersand the differ- ent caches—can significantly improve media server performance. We measureperformance in three ways: by the maximum number of continuous data streams that a drivecan support; the total RAM size requirements; and the start- up latency. Our caching and …,IEEE concurrency,2000,11
Fetching optimization in multi-way pipelined database joins,*,A method of performing a multi-way join of a plurality of database relations includesexecuting a plurality of pipelined two-way joins with the database relations. Each two-wayjoin has two sequential phases. In the first phase; missing attributes of the input relations thatare required to evaluate a joining criterion specific to said two-way join are fetched from anon-volatile memory device; and the input relations are joined according to the criterion. Inthe second phase; any additional missing attributes of the input relations are fetched fromthe non-volatile memory device as assigned by an optimization process executed prior tocommencing the multi-way join.,*,2013,10
Designing Database Operators for Flash-enabled Memory Hierarchies.,Goetz Graefe; Stavros Harizopoulos; Harumi A Kuno; Mehul A Shah; Dimitris Tsirogiannis; Janet L Wiener,Abstract Flash memory affects not only storage options but also query processing. In thispaper; we analyze the use of flash memory for database query processing; includingalgorithms that combine flash memory and traditional disk drives. We first focus on flash-resident databases and present data structures and algorithms that leverage the fast randomreads of flash to speed up selection; projection; and join operations. FlashScan andFlashJoin are two such algorithms that leverage a column-based layout to significantlyreduce memory and I/O requirements. Experiments with Postgres and an enterprise SSDdrive show improved query runtimes by up to 6x for queries ranging from simple relationalscans and joins to full TPC-H queries. In the second part of the paper; we use externalmerge sort as a prototypical query execution algorithm to demonstrate that the most …,IEEE Data Eng. Bull.,2010,10
Staged database systems,Stavros Harizopoulos,Abstract Advances in computer architecture research yield increasingly powerful processorswhich can execute code at a much faster pace than they can access data in the memoryhierarchy. Database management systems (DBMS); due to their intensive data processingnature; are in the front line of commercial applications which cannot harness the availablecomputing power. To prevent processors from idling; a multitude of hardware mechanismsand software optimizations have been proposed. Their effectiveness; however; is limited bythe sheer volume of data accessed and by the unpredictable sequence of memory requests.This Ph. D. dissertation introduces Staged Database Systems; a new software architecturefor optimizing data and instruction locality at all levels of the memory hierarchy. The key ideais to break database request execution in stages and process a group of subrequests at …,*,2005,5
Computer cluster with objective-based resource sharing,*,A computer cluster with objectives-based resource sharing. The cluster includes cloudnodes each with one or more resources; a terminal; data storage; and an allocation node tomonitor cloud node resources; provide information descriptive of the cloud node resourcesto a customer through the terminal; receive a reservation for cloud node resources from thecustomer; store the reservation in the data storage; determine assignments of the cloudnode resources for the reservation and any other pending reservations according to one ormore objectives; and allocate the cloud node resources to customers according to theresource assignments.,*,2016,3
CloudAlloc: a monitoring and reservation system for compute clusters,Enrico Iori; Alkis Simitsis; Themis Palpanas; Kevin Wilkinson; Stavros Harizopoulos,Abstract Cloud computing has emerged as a promising environment capable of providingflexibility; scalability; elasticity; fail-over mechanisms; high availability; and other importantfeatures to applications. Compute clusters are relatively easy to create and use; but tools toeffectively share cluster resources are lacking. CloudAlloc addresses this problem andschedules workloads to cluster resources using allocation algorithms that can be easilychanged according to the objectives of the enterprise. It also monitors resource utilizationand thus; provides accountability for actual usage. CloudAlloc is a lightweight; flexible; easy-to-use tool for cluster resource allocation that has also proved useful as a research platform.We demonstrate its features and also discuss its allocation algorithms that minimize powerusage. CloudAlloc was implemented and is in use at HP Labs.,Proceedings of the 2012 international conference on Management of Data,2012,3
Dark silicon accelerators for database indexing,Onur Kocberber; Babak Falsafi; Kevin Lim; Parthasarathy Ranganathan; Stavros Harizopoulos,The growing explosion of digital data motivates renewed emphasis on new architectures forfuture data-centric workloads. At the same time; the inability of power to scale withincreasing transistor counts has led to a recent focus on “dark silicon” designs wheretransistors are used to design specialized accelerators to improve energy efficiency andperformance. Combining these trends; in this paper; we examine the applicability ofaccelerators in future data-centric system architectures. Specifically; we focus on indexing; afundamental and time consuming component of databases; and propose a new “indexingwidget” to improve energy efficiency and performance. Through preliminary characterizationof a representative scale-out database; VoltDB; in conjunction with performance; power andarea models; we show that our proposed approach can achieve 1.24 X improvement in …,1st Dark Silicon Workshop (DaSi),2012,3
Sidestep: Co-designed shiftable memory and software,T Kelly; H Kuno; M Pickett; H Boehm; A Davis; W Golab; G Graefe; S Harizopoulos; P Joisha; A Karp; N Muralimanohar; F Perner; G Medeiros-Ribeiro; G Seroussi; A Simitsis; R Tarjan; S Williams,Abstract We have designed computer memories that can shift a long user-specifiedcontiguous region a short; fixed distance in constant time. Such memories make possiblecomplementary co-designed software that not only improves performance but also simplifiesand unifies solutions to fundamental computing problems including sorting; searching; anddata management.,Technical report; HP Labs,2012,3
Resource sharing in computer clusters according to objectives,*,A method of assigning resources of a computer duster with resource sharing according toobjectives. The method includes monitoring resources of each of a plurality of cloud nodes;providing information descriptive of the cloud node resources; receiving a reservation;determining whether resources are available to satisfy the reservation and any otherpending reservations; if resources are available; using a rapid search to determine resourceassignments for the reservation and any other pending reservations according to one ormore objectives; and allocating resources according to the resource assignments.,*,2015,2
vDrive: An Efficient and Consistent Virtual I/O System,Mohit Saxena; Pin Zhou; David A Pease,Abstract The most popular methods for managing storage and providing crash consistencyare I/O virtualization and journaled filesystems respectively. This popularity is due to theirwidespread use in production environments. However; both of these methods have evolvedseparately in different contexts in the past. This paper presents a first look on providing crashconsistency for virtual I/O caches through journaled filesystems. We find that nestedfilesystem journaling in guest and host operating systems has a significant performancecost. This cost is attributed to the use of traditional disk interfaces for cache flushes and lackof coordination between the two journaling levels. We present vDrive; a consistent virtual I/Osystem architecture; with a new virtual disk interface and semantic journaling mechanismdesigned to provide high performance. We have implemented vDrive interface extensions …,IBM Research Almaden; Datos IO,*,1
Shiftable memory supporting bimodal storage,*,A shiftable memory supporting bimodal data storage includes a memory having built-inshifting capability to shift a contiguous subset of data stored in the memory from a firstlocation to a second location within the memory. The shiftable memory further includes abimodal data storage operator to operate on a data structure comprising the contiguoussubset of data words and to provide in-place insertion of a data value using the built-inshifting capability.,*,2016,*
Imparting durability to a transactional memory system,*,A transactional memory system uses a volatile memory as primary storage for transactions.Data is selectively stored in a non-volatile memory to impart durability to the transactionalmemory system to allow the transactional memory system to be restored to a consistent statein the event of data loss to the volatile memory.,*,2014,*
Staged DBMS,Stavros Harizopoulos,The values in the relations of a relational database are elements of one or more underlyingsets called domains. In practical applications; a domain may be infinite; eg; the set of naturalnumbers. In this case; the value of a relational calculus query when applied to such adatabase may be infinite; eg;{njn! 10}. A query Q is called finite if the value of Q whenapplied to any database is finite. Even when the database domains are finite; all that isnormally known about them is that they are some finite superset of the values that occur inthe database. In this case; the value of a relational calculus query may depend on such anunknown domain; eg;{xj 8yR (x; y)}. A query Q is called domain independent if the value of Qwhen applied to any database is the same for any two domains containing the databasevalues or; equivalently; if the value of Q when applied to a database contains only values …,Encyclopedia of Database Systems,2009,*
Simultaneous Query Pipelines in QPipe,Kun Gao; Stavros Harizopoulos; Ippokratis Pandis; Anastassia Ailamaki; Vladislav Shkapenyuk,Data warehousing and scientific database applications operate on massive datasets andare characterized by complex queries accessing large portions of the database. Concurrentqueries often exhibit high data and computation overlap; eg; they access the same relationson disk; compute similar aggregates; or share intermediate results. Unfortunately; run-timesharing in modern database engines is limited by the paradigm of invoking an independentset of operator instances per query; potentially missing sharing opportunities if the bufferpool evicts data early. QPipe is a new; operator-centric; relational query engine that candetect and exploit overlap across concurrent queries; at run time [1]. In QPipe; eachrelational operator is promoted to an independent micro-engine (μEngine) with its ownresource management and runtime support. Incoming queries break up into as many …,*,*,*
Data Engineering,G Graefe; S Harizopoulos; H Kuno; MA Shah; D Tsirogiannis; JL Wiener; B Bhattacharjee; M Canim; CA Lang; GA Mihaila; KA Ross; M Bjørling; P Bonnet; L Bouganim; B Jònsson,The Data Engineering Bulletin The Bulletin of the Technical Committee on Data Engineeringis published quarterly and is distributed to all TC members. Its scope includes the design;implementation; modelling; theory and application of database systems and theirtechnology. Letters; conference information; and news should be sent to the Editor-in-Chief.Papers for each issue are solicited by and should be sent to the Associate Editorresponsible for the issue. Opinions expressed in contributions are those of the authors anddo not necessarily reflect the positions of the TC on Data Engineering; the IEEE ComputerSociety; or the authors' organizations. The Data Engineering Bulletin web site is at http://tab.computer. org/tcde/bull_about. html.,*,*,*
