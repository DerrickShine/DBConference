The importance of stop word removal on recall values in text categorization,Catarina Silva; Bernardete Ribeiro,Given a data set and a learning task such as classification; there are two prime motives forexecuting some kind of data set reduction. On one hand there is the possible algorithmperformance improvement. On the other hand the decrease in the overall size of the data setcan bring advantages in storage space used and time spent computing. Our purpose is todetermine the importance of several basic reduction techniques on Support VectorMachines; by comparing their relative performance improvement when applied on thestandard REUTERS-21578 benchmark.,Neural Networks; 2003. Proceedings of the International Joint Conference on,2003,113
A neural network for shortest path computation,Filipe Araujo; Bernardete Ribeiro; Luis Rodrigues,This paper presents a new neural network to solve the shortest path problem for inter-network routing. The proposed solution extends the traditional single-layer recurrentHopfield architecture introducing a two-layer architecture that automatically guarantees anentire set of constraints held by any valid solution to the shortest path problem. This newmethod addresses some of the limitations of previous solutions; in particular the lack ofreliability in what concerns successful and valid convergence. Experimental results showthat an improvement in successful convergence can be achieved in certain classes ofgraphs. Additionally; computation performance is also improved at the expense of slightlyworse results.,IEEE Transactions on Neural Networks,2001,98
Image complexity and feature mining for steganalysis of least significant bit matching steganography,Qingzhong Liu; Andrew H Sung; Bernardete Ribeiro; Mingzhen Wei; Zhongxue Chen; Jianyun Xu,Abstract The information-hiding ratio is a well-known metric for evaluating steganalysisperformance. In this paper; we introduce a new metric of image complexity to enhance theevaluation of steganalysis performance. In addition; we also present a scheme ofsteganalysis of least significant bit (LSB) matching steganography; based on feature miningand pattern recognition techniques. Compared to other well-known methods of steganalysisof LSB matching steganography; our method performs the best. Results also indicate thatthe significance of features and the detection performance depend not only on theinformation-hiding ratio; but also on the image complexity.,Information Sciences,2008,93
Home electrical signal disaggregation for non-intrusive load monitoring (NILM) systems,Marisa Figueiredo; Ana De Almeida; Bernardete Ribeiro,Abstract Electrical load disaggregation for end-use recognition in the smart home hasbecome an area of study of its own right. The most well-known examples are energymonitoring; health care applications; in-home activity modeling; and home automation. Real-time energy-use analysis for whole-home approaches needs to understand where andwhen the electrical loads are spent. Studies have shown that individual loads can bedetected (and disaggregated) from sampling the power at one single point (eg the electricservice entrance for the house) using a non-intrusive load monitoring (NILM) approach. Inthis paper; we focus on the feature extraction and pattern recognition tasks for non-intrusiveresidential electrical consumption traces. In particular; we develop an algorithm capable ofdetermining the step-changes in signals that occur whenever a device is turned on or off …,Neurocomputing,2012,92
Support vector machines for quality monitoring in a plastic injection molding process,Bernardete Ribeiro,Support vector machines (SVMs) are receiving increased attention in different applicationdomains for which neural networks (NNs) have had a prominent role. However; in qualitymonitoring little attention has been given to this more recent development encompassing atechnique with foundations in statistic learning theory. In this paper; we compare C-SVMand/spl nu/-SVM classifiers with radial basis function (RBF) NNs in data sets correspondingto product faults in an industrial environment concerning a plastics injection moldingmachine. The goal is to monitor in-process data as a means of indicating product quality andto be able to respond quickly to unexpected process disturbances. Our approach based onSVMs exploits the first part of this goal. Model selection which amounts to search inhyperparameter space is performed for study of suitable condition monitoring. In the …,IEEE Transactions on Systems; Man; and Cybernetics; Part C (Applications and Reviews),2005,78
An improved approach to steganalysis of JPEG images,Qingzhong Liu; Andrew H Sung; Mengyu Qiao; Zhongxue Chen; Bernardete Ribeiro,Abstract Steganography secretly embeds additional information in digital products; thepotential for covert dissemination of malicious software; mobile code; or information is great.To combat the threat posed by steganography; steganalysis aims at the exposure of thestealthy communication. In this paper; a new scheme is proposed for steganalysis of JPEGimages; which; being the most common image format; is believed to be widely used forsteganography purposes as there are many free or commercial tools for producingsteganography using JPEG covers. First; a recently proposed Markov approach [27] isexpanded to the inter-block of the discrete cosine transform (DCT) and to the discretewavelet transform (DWT). The features on the joint distributions of the transform coefficientsand the features on the polynomial fitting errors of the histogram of the DCT coefficients …,Information Sciences,2010,56
Clustering and visualization of bankruptcy trajectory using self-organizing map,Ning Chen; Bernardete Ribeiro; Armando Vieira; An Chen,Abstract Bankruptcy trajectory reflects the dynamic changes of financial situation ofcompanies; and hence make possible to keep track of the evolution of companies andrecognize the important trajectory patterns. This study aims at a compact visualization of thecomplex temporal behaviors in financial statements. We use self-organizing map (SOM) toanalyze and visualize the financial situation of companies over several years through a two-step clustering process. Initially; the bankruptcy risk is characterized by a feature self-organizing map (FSOM); and therefore the temporal sequence is converted to the trajectoryvector projected on the map. Afterwards; the trajectory self-organizing map (TSOM) clustersthe trajectory vectors to a number of trajectory patterns. The proposed approach is applied toa large database of French companies spanning over four years. The experimental …,Expert Systems with Applications,2013,54
Image complexity and feature extraction for steganalysis of LSB matching steganography,Qingzhong Liu; Andrew H Sung; Jianyun Xu; Bernardete M Ribeiro,In this paper; we present a scheme for steganalysis of LSB matching steganography basedon feature extraction and pattern recognition techniques. Shape parameter of generalizedGaussian distribution (GGD) in the wavelet domain is introduced to measure imagecomplexity. Several statistical pattern recognition algorithms are applied to train and classifythe feature sets. Comparison of our method and others indicates our method is highlycompetitive. It is highly efficient for color image steganalysis. It is also efficient for grayscalesteganalysis in the low image complexity domain,Pattern Recognition; 2006. ICPR 2006. 18th International Conference on,2006,52
An experimental study on electrical signature identification of non-intrusive load monitoring (nilm) systems,Marisa B Figueiredo; Ana De Almeida; Bernardete Ribeiro,Abstract Electrical load disambiguation for end-use recognition in the residential sector hasbecome an area of study of its own right. Several works have shown that individual loadscan be detected (and separated) from sampling of the power at a single point (eg theelectrical service entrance for the house) using a non-intrusive load monitoring (NILM)approach. This work presents the development of an algorithm for electrical featureextraction and pattern recognition; capable of determining the individual consumption ofeach device from the aggregate electric signal of the home. Namely; the idea consists ofanalyzing the electrical signal and identifying the unique patterns that occur whenever adevice is turned on or off by applying signal processing techniques. We further describe ourtechnique for distinguishing loads by matching different signal parameters (step-changes …,International Conference on Adaptive and Natural Computing Algorithms,2011,49
An efficient gradient-based learning algorithm applied to neural networks with selective actuation neurons,Noel Lopes; Bernardete Ribeiro,ABSTRACT A new class of Neural Networks (NN); designated the Multiple Feed-Forward(MFF) networks; and a new gradient-based learning algorithm; Multiple Back-Propagation(MBP); are proposed and analyzed. MFF are obtained by integrating two feed-forwardnetworks (a main network and a space network) in a novel manner. A major characteristic istheir ability to partition the input space by using selective neurons; whose actuation role iscaptured through the space localisation of input pattern data. In this sense; only thoseneurons fired by a particular data point turn out to be relevant; while they retain the capacityto approximate closely to more general; irregular; non-linear features in localized regions.Together; the MFF networks and the MBP algorithm embody a new neural architecture;ensuring; in most cases; a better design choice than the one provided by the Multi-Layer …,Neural; Parallel & Scientific Computations,2003,44
On text-based mining with active learning and background knowledge using svm,Catarina Silva; Bernardete Ribeiro,Abstract Text mining; intelligent text analysis; text data mining and knowledge-discovery intext are generally used aliases to the process of extracting relevant and non-trivialinformation from text. Some crucial issues arise when trying to solve this problem; such asdocument representation and deficit of labeled data. This paper addresses these problemsby introducing information from unlabeled documents in the training set; using the supportvector machine (SVM) separating margin as the differentiating factor. Besides studying theinfluence of several pre-processing methods and concluding on their relative significance;we also evaluate the benefits of introducing background knowledge in a SVM text classifier.We further evaluate the possibility of actively learning and propose a method for successfullycombining background knowledge and active learning. Experimental results show that …,Soft Computing,2007,41
A similarity measure for clustering and its applications,Guadalupe J Torres; Ram B Basnet; Andrew H Sung; Srinivas Mukkamala; Bernardete M Ribeiro,Abstract—This paper introduces a measure of similarity between two clusterings of the samedataset produced by two different algorithms; or even the same algorithm (K-means; forinstance; with different initializations usually produce different results in clustering the samedataset). We then apply the measure to calculate the similarity between pairs of clusterings;with special interest directed at comparing the similarity between various machineclusterings and human clustering of datasets. The similarity measure thus can be used toidentify the best (in terms of most similar to human) clustering algorithm for a specificproblem at hand. Experimental results pertaining to the text categorization problem of aPortuguese corpus (wherein a translation-into-English approach is used) are presented; aswell as results on the well-known benchmark IRIS dataset. The significance and other …,Int J Electr Comput Syst Eng,2009,40
A genetic algorithm-based approach to cost-sensitive bankruptcy prediction,Ning Chen; Bernardete Ribeiro; Armando S Vieira; João Duarte; João C Neves,Abstract The prediction of bankruptcy is of significant importance with the present-dayincrease of bankrupt companies. In the practical applications; the cost of misclassification isworthy of consideration in the modeling in order to make accurate and desirable decisions.An effective prediction system requires the integration of the cost preference into theconstruction and optimization of prediction models. This paper presents an evolutionaryapproach for optimizing simultaneously the complexity and the weights of learning vectorquantization network under the symmetric cost preference. Experimental evidences on areal-world data set demonstrate the proposed algorithm leads to significant reduction offeatures without the degradation of prediction capability.,Expert Systems with Applications,2011,39
GPUMLib: An efficient open-source GPU machine learning library,Noel Lopes; Bernardete Ribeiro,Abstract: Graphics Processing Units (GPUs) placed at our disposal an unprecedentedcomputational-power; largely surpassing the performance of cutting-edge CPUs (CentralProcessing Units). The high-parallelism inherent to the GPU makes this device especiallywell-suited to address Machine Learning (ML) problems with prohibitively computationalintensive tasks. Nevertheless; few ML algorithms have been implemented on the GPU andmost are not openly shared; posing difficulties for researchers and engineers aiming todevelop GPU-based systems. To mitigate this problem; we propose the creation of an opensource GPU Machine Learning Library (GPUMLib) that aims to provide the building blocksfor the development of efficient GPU ML software. Experimental results on benchmarkdatasets show that the algorithms already implemented yield significant time savings over …,International Journal of Computer Information Systems and Industrial Management Applications,2011,36
Learning from multiple annotators: distinguishing good from random labelers,Filipe Rodrigues; Francisco Pereira; Bernardete Ribeiro,Abstract With the increasing popularity of online crowdsourcing platforms such as AmazonMechanical Turk (AMT); building supervised learning models for datasets with multipleannotators is receiving an increasing attention from researchers. These platforms provide aninexpensive and accessible resource that can be used to obtain labeled data; and in manysituations the quality of the labels competes directly with those of experts. For such reasons;much attention has recently been given to annotator-aware models. In this paper; wepropose a new probabilistic model for supervised learning with multiple annotators wherethe reliability of the different annotators is treated as a latent variable. We empirically showthat this model is able to achieve state of the art performance; while reducing the number ofmodel parameters; thus avoiding a potential overfitting. Furthermore; the proposed model …,Pattern Recognition Letters,2013,35
Scaling text classification with relevance vector machines,Catarina Silva; Bernardete Ribeiro,Text classification (TC) is a complex ubiquitous task that handles a huge amount of data.Current research has recently proved that kernel learning based methods are quite effectivein this problem. As opposed to support vector machines (SVM); the relevance vectormachine (RVM) in particular yields a probabilistic output while preserving its accuracy.However; few research efforts have addressed the issue of scalability that arises whenapplying RVM to large scale problems like TC. We propose a new model which consists of atwo-step RVM classifier able to (i) be competitive regarding processing time;(ii) use allavailable training elements and (iii) improve RVM classification performance. The paperalso shows that a convenient similitude measure among documents can be defined on allthe collection data; which does not only make the process swifter but also parallelizable …,Systems; Man and Cybernetics; 2006. SMC'06. IEEE International Conference on,2006,35
On using crowdsourcing and active learning to improve classification performance,Joana Costa; Catarina Silva; Mário Antunes; Bernardete Ribeiro,Crowdsourcing is an emergent trend for general-purpose classification problem solving.Over the past decade; this notion has been embodied by enlisting a crowd of humans tohelp solve problems. There are a growing number of real-world problems that takeadvantage of this technique; such as Wikipedia; Linux or Amazon Mechanical Turk. In thispaper; we evaluate its suitability for classification; namely if it can outperform state-of-the-artmodels by combining it with active learning techniques. We propose two approaches basedon crowdsourcing and active learning and empirically evaluate the performance of abaseline Support Vector Machine when active learning examples are chosen and madeavailable for classification to a crowd in a web-based scenario. The proposedcrowdsourcing active learning approach was tested with Jester data set; a text humour …,Intelligent Systems Design and Applications (ISDA); 2011 11th International Conference on,2011,32
GPU implementation of the multiple back-propagation algorithm,Noel Lopes; Bernardete Ribeiro,Abstract Graphics Processing Units (GPUs) can provide remarkable performance gainswhen compared to CPUs for computationally-intensive applications. Thus they are muchattractive to be used as dedicated hardware in many fields such as in machine learning. Inparticular; the implementation of neural networks (NNs) in GPUs can decrease enormouslythe long training times during the learning process. In this paper; we describe a parallelimplementation of the Multiple Back-Propagation (MBP) algorithm and present the resultsobtained when running the algorithm on two well-known benchmarks. We show that for bothclassification and regression problems our implementation reduces the computational costwhen compared with the standalone CPU version.,International Conference on Intelligent Data Engineering and Automated Learning,2009,32
Enhanced default risk models with SVM+,Bernardete Ribeiro; Catarina Silva; Ning Chen; Armando Vieira; João Carvalho das Neves,Abstract Default risk models have lately raised a great interest due to the recent worldeconomic crisis. In spite of many advanced techniques that have extensively beenproposed; no comprehensive method incorporating a holistic perspective has hitherto beenconsidered. Thus; the existing models for bankruptcy prediction lack the whole coverage ofcontextual knowledge which may prevent the decision makers such as investors andfinancial analysts to take the right decisions. Recently; SVM+ provides a formal way toincorporate additional information (not only training data) onto the learning modelsimproving generalization. In financial settings examples of such non-financial (thoughrelevant) information are marketing reports; competitors landscape; economic environment;customers screening; industry trends; etc. By exploiting additional information able to …,Expert Systems with Applications,2012,31
Distributed text classification with an ensemble kernel-based learning approach,Catarina Silva; Uros Lotric; Bernardete Ribeiro; Andrej Dobnikar,Constructing a single text classifier that excels in any given application is a rather inviablegoal. As a result; ensemble systems are becoming an important resource; since they permitthe use of simpler classifiers and the integration of different knowledge in the learningprocess. However; many text-classification ensemble approaches have an extremely highcomputational burden; which poses limitations in applications in real environments.Moreover; state-of-the-art kernel-based classifiers; such as support vector machines andrelevance vector machines; demand large resources when applied to large databases.Therefore; we propose the use of a new systematic distributed ensemble framework to tacklethese challenges; based on a generic deployment strategy in a cluster distributedenvironment. We employ a combination of both task and data decomposition of the text …,IEEE Transactions on Systems; Man; and Cybernetics; Part C (Applications and Reviews),2010,31
Towards adaptive learning with improved convergence of deep belief networks on graphics processing units,Noel Lopes; Bernardete Ribeiro,Abstract In this paper we focus on two complementary approaches to significantly decreasepre-training time of a deep belief network (DBN). First; we propose an adaptive step sizetechnique to enhance the convergence of the contrastive divergence (CD) algorithm;thereby reducing the number of epochs to train the restricted Boltzmann machine (RBM) thatsupports the DBN infrastructure. Second; we present a highly scalable graphics processingunit (GPU) parallel implementation of the CD-k algorithm; which boosts notably the trainingspeed. Additionally; extensive experiments are conducted on the MNIST and the HHrecodatabases. The results suggest that the maximum useful depth of a DBN is related to thenumber and quality of the training samples. Moreover; it was found that the lower-level layerplays a fundamental role for building successful DBN models. Furthermore; the results …,Pattern recognition,2014,26
Extracting discriminative features using non-negative matrix factorization in financial distress data,Bernardete Ribeiro; Catarina Silva; Armando Vieira; João Neves,Abstract In the recent financial crisis the incidence of important cases of bankruptcy led to agrowing interest in corporate bankruptcy prediction models. In addition to buildingappropriate financial distress prediction models; it is also of extreme importance to devisedimensionality reduction methods able to extract the most discriminative features. Here weshow that Non-Negative Matrix Factorization (NMF) is a powerful technique for successfulextraction of features in this financial setting. NMF is a technique that decomposes financialmultivariate data into a few basis functions and encodings using non-negative constraints.We propose an approach that first performs proper initialization of NMF taking into accountoriginal data using K-means clustering. Second; builds a bankruptcy prediction model usingthe discriminative financial ratios extracted by NMF decomposition. Model predictive …,International Conference on Adaptive and Natural Computing Algorithms,2009,26
Model selection for kernel based intrusion detection systems,Srinvas Mukkamala; AH Sung; BM Ribeiro,Abstract This paper describes results concerning the robustness and generalizationcapabilities of a supervised machine learning method in detecting intrusions using networkaudit trails. We also evaluate the impact of kernel type and parameter values on theaccuracy with which a support vector machine (SVM) performs intrusion classification. Weshow that classification accuracy varies with the kernel type and the parameter values; thus;with appropriately chosen parameter values; intrusions can be detected by SVMs withhigher accuracy and lower rates of false alarms. Feature selection is as important forintrusion detection as it is for many other problems. We present support vector decisionfeature selection method for intrusion detection. It is demonstrated that; with appropriatelychosen features; intrusions can be detected in real time or near real time.,*,2005,24
Gaussian process classification and active learning with multiple annotators,Filipe Rodrigues; Francisco Pereira; Bernardete Ribeiro,Abstract Learning from multiple annotators took a valuable step towards modeling data thatdoes not fit the usual single annotator setting; since multiple annotators sometimes offervarying degrees of expertise. When disagreements occur; the establishment of the correctlabel through trivial solutions such as majority voting may not be adequate; since withoutconsidering heterogeneity in the annotators; we risk generating a flawed model. In thispaper; we generalize GP classification in order to account for multiple annotators withdifferent levels expertise. By explicitly handling uncertainty; Gaussian processes (GPs)provide a natural framework for building proper multiple-annotator models. We empiricallyshow that our model significantly outperforms other commonly used approaches; such asmajority voting; without a significant increase in the computational cost of approximate …,International Conference on Machine Learning,2014,23
Defining semantic meta-hashtags for twitter classification,Joana Costa; Catarina Silva; Mário Antunes; Bernardete Ribeiro,Abstract Given the wide spread of social networks; research efforts to retrieve informationusing tagging from social networks communications have increased. In particular; in Twittersocial network; hashtags are widely used to define a shared context for events or topics.While this is a common practice often the hashtags freely introduced by the user becomeeasily biased. In this paper; we propose to deal with this bias defining semantic meta-hashtags by clustering similar messages to improve the classification. First; we use the user-defined hashtags as the Twitter message class labels. Then; we apply the meta-hashtagapproach to boost the performance of the message classification. The meta-hashtagapproach is tested in a Twitter-based dataset constructed by requesting public tweets to theTwitter API. The experimental results yielded by comparing a baseline model based on …,International Conference on Adaptive and Natural Computing Algorithms,2013,23
Modeling epileptic brain states using EEG spectral analysis and topographic mapping,Bruno Direito; César Teixeira; Bernardete Ribeiro; Miguel Castelo-Branco; Francisco Sales; António Dourado,Abstract Changes in the spatio-temporal behavior of the brain electrical activity are believedto be associated to epileptic brain states. We propose a novel methodology to identify thedifferent states of the epileptic brain; based on the topographic mapping of the time varyingrelative power of delta; theta; alpha; beta and gamma frequency sub-bands; estimated fromEEG. Using normalized-cuts segmentation algorithm; points of interest are identified in thetopographic mappings and their trajectories over time are used for finding out relations withepileptogenic propagations in the brain. These trajectories are used to train a HiddenMarkov Model (HMM); which models the different epileptic brain states and the transitionamong them. Applied to 10 patients suffering from focal seizures; with a total of 30 seizuresover 497.3 h of data; the methodology shows good results (an average point-by-point …,Journal of neuroscience methods,2012,23
GPUMLib: a new library to combine machine learning algorithms with graphics processing units,Noel Lopes; Bernardete Ribeiro; Ricardo Quintas,The Graphics Processing Unit (GPU) is a highly parallel; many-core device with enormouscomputational power; especially well-suited to address Machine Learning (ML) problemsthat can be expressed as data-parallel computations. As problems become increasinglydemanding; parallel implementations of ML algorithms become critical for developing hybridintelligent real-world applications. The relative low cost of GPUs combined with theunprecedent computational power they offer; make them particularly well-positioned toautomatically analyze and capture relevant information from large amounts of data. In thispaper; we propose the creation of an open source GPU Machine Learning Library(GPUMLib) that aims to provide the building blocks for the scientific community to developGPU ML algorithms. Experimental results on benchmark datasets demonstrate that the …,Hybrid Intelligent Systems (HIS); 2010 10th International Conference on,2010,23
Restricted Boltzmann machines and deep belief networks on multi-core processors,Noel Lopes; Bernardete Ribeiro; Joao Goncalves,Deep learning architecture models by contrast with shallow models draw on the insights ofbiological inspiration which has been a challenge since the inception of the idea ofsimulating the brain. In particular their (many) hierarchical levels of composition track thedevelopment of parallel implementation in an attempt to become accessibly fast. When itcomes to performance enhancement Graphics Processing Units (GPU) have carved theirown strength in machine learning. In this paper; we present an approach that relies mainlyon three kernels for implementing both the Restricted Boltzmann Machines (RBM) and DeepBelief Networks (DBN) algorithms. Instead of considering the neuron as the smallest unit ofcomputation each thread represents the connection between two (one visible and onehidden) neurons. Although conceptually it may seem weird; the rationale behind is to …,Neural Networks (IJCNN); the 2012 International Joint Conference On,2012,22
Inductive inference for large scale text classification: kernel approaches and techniques,Catarina Silva; Bernadete Ribeiro,Text classification is becoming a crucial task to analysts in different areas. In the last fewdecades; the production of textual documents in digital form has increased exponentially.Their applications range from web pages to scientific documents; including emails; newsand books. Despite the widespread use of digital texts; handling them is inherently difficult-the large amount of data necessary to represent them and the subjectivity of classificationcomplicate matters. This book gives a concise view on how to use kernel approaches forinductive inference in large scale text classification; it presents a series of new techniques toenhance; scale and distribute text classification tasks. It is not intended to be acomprehensive survey of the state-of-the-art of the whole field of text classification. Itspurpose is less ambitious and more practical: to explain and illustrate some of the …,*,2009,22
Coastal erosion due to anthropogenic impacts on sediment transport in Douro river-Portugal,Carlos Coelho; Tony Conceição; Bruno Ribeiro,Abstract The coastal erosion causes and their relative importance are site specific; changingfrom place to place. In the Portuguese Northwest coast; namely between Douro River andNazaré; coastal erosion is mainly due to sediment supply reduction from Douro River. Thepresent study analyzed the anthropogenic impacts on the river; identifying the type and timehistory of Human actions; the flow changes and the impact on the sediment transport alongthe years. Numerical formulations of sediment transport estimation allow defining the relativeimportance of the different interventions on the Douro River and its basin. The majorimportance of the dams constructed in the Douro River basin led to laboratory works on ahydraulic flume; evidencing the sediment transport reduction related with the lower flowvelocities caused by the reservoirs of the dams on the upstream side.,*,2009,22
Kernelized based functions with Minkovsky's norm for SVM regression,B Ribeiro,Presents an empirical study for support vector machine (SVM) regression using Minkovsky'snorm in a Gaussian kernel function. Due to the encouraging results with RBF kernels; moregeneralized forms based on some distance measure are suitable to be investigated. TheEuclidean distance has a natural generalization in the form of the Minkovsky distancefunction. The results presented on the approximation of sincos functions as well as on a timeseries prediction function show that Gaussian kernels with Minkovsky's distance (/splalpha/= 3) and (/spl alpha/= 6) evaluated on a 10-k cross validation basis present bettergeneralization accuracy than RBF kernels (/spl alpha/= 2).,Neural Networks; 2002. IJCNN'02. Proceedings of the 2002 International Joint Conference on,2002,22
Hybrid learning in a multi-neural network architecture,N Lopes; B Ribeiro,This paper describes a new class of neural networks (multiple feedforward networks(MFFNs)) obtained by integrating two feedforward networks in a novel manner. A newmultiple backpropagation (MBP) algorithm that can be seen as a generalization of thebackpropagation (BP) algorithm is also presented. The MFFNs and MBP algorithm togetherform a new neural architecture that is in most cases preferable to the use of multilayerperceptron networks trained with the BP algorithm. Experimental results on benchmarksshow that the advantages offered by the new architecture are shorter training times foronline learning and better generalization and function approximation capabilities.,Neural Networks; 2001. Proceedings. IJCNN'01. International Joint Conference on,2001,21
Deep learning networks for off-line handwritten signature recognition,Bernardete Ribeiro; Ivo Gonçalves; Sérgio Santos; Alexander Kovacec,Abstract Reliable identification and verification of off-line handwritten signatures fromimages is a difficult problem with many practical applications. This task is a difficult visionproblem within the field of biometrics because a signature may change depending onpsychological factors of the individual. Motivated by advances in brain science whichdescribe how objects are represented in the visual cortex; advanced research on deepneural networks has been shown to work reliably on large image data sets. In this paper; wepresent a deep learning model for off-line handwritten signature recognition which is able toextract high-level representations. We also propose a two-step hybrid model for signatureidentification and verification improving the misclassification rate in the well-known GPDSdatabase.,Iberoamerican Congress on Pattern Recognition,2011,20
An evaluation of multiple feed-forward networks on GPUs,Noel Lopes; Bernardete Ribeiro,The Graphics Processing Unit (GPU) originally designed for rendering graphics and which isdifficult to program for other tasks; has since evolved into a device suitable for general-purpose computations. As a result graphics hardware has become progressively moreattractive yielding unprecedented performance at a relatively low cost. Thus; it is the idealcandidate to accelerate a wide variety of data parallel tasks in many fields such as inMachine Learning (ML). As problems become more and more demanding; parallelimplementations of learning algorithms are crucial for a useful application. In particular; theimplementation of Neural Networks (NNs) in GPUs can significantly reduce the long trainingtimes during the learning process. In this paper we present a GPU parallel implementation ofthe Back-Propagation (BP) and Multiple Back-Propagation (MBP) algorithms; and …,International journal of neural systems,2011,20
Control of a biped robot with support vector regression in sagittal plane,João P Ferreira; Manuel M Crisostomo; A Paulo Coimbra; Bernardete Ribeiro,This paper describes the control of an autonomous biped robot that uses the support vectorregression (SVR) method for its sagittal balance. This SVR uses the zero moment point(ZMP) position and its variation as input and the torso correction of the robot's body asoutput. As the robot model used segments the robot into eight parts; it is difficult to useonline. This is the main reason for using the artificial intelligence method. The SVR wastrained with simulation data that was previously tested with the real robot. The SVR wasfound to be faster (with similar accuracy) than a recurrent network and a neuro-fuzzy control.This method is more precise than the model based on an inverted pendulum. The design ofthe feet is considered in terms of accommodating the force sensors used to estimate thecenter of pressure (CoP). The SVR was tested in the real robot using joint trajectories that …,IEEE Transactions on Instrumentation and Measurement,2009,20
Steganalysis of multi-class JPEG images based on expanded Markov features and polynomial fitting,Qingzhong Liu; Andrew H Sung; Bernardete M Ribeiro; Rita Ferreira,In this article; based on the Markov approach proposed by shi et al.[1]; we expand it to theinter-blocks of the DCT domain; calculate the difference of the expanded Markov featuresbetween the testing image and the calibrated version; and combine these differencefeatures and the polynomial fitting features on the histogram of the DCT coefficients asdetectors. We reasonably improve the detection performance in multi-class JPEG images.We also compare the steganalysis performance among the feature reduction/selectionmethods based on principal component analysis; singular value decomposition; andFisher's linear discriminant.,Neural Networks; 2008. IJCNN 2008.(IEEE World Congress on Computational Intelligence). IEEE International Joint Conference on,2008,20
Lime kiln simulation and control by neural networks,B Ribeiro; A Dourado,*,Neural networks for chemical engineers,1995,20
Simulation control of a biped robot with support vector regression,Joao P Ferreira; Manuel Crisostomo; A Paulo Coimbra; Bernardete Ribeiro,This paper describes the control of an autonomous biped robot that uses the Support VectorRegression (SVR) method for its longitudinal balance. This SVR uses the Zero MomentPoint (ZMP) position and its variation as input and the longitudinal correction of the robot'sbody is obtained as the output. The SVR was trained based on simulation data that wasconfirmed with the real robot. This method showed to be faster (with similar accuracy) than arecurrent network or a neuro-fuzzy control of the biped balance.,Intelligent Signal Processing; 2007. WISP 2007. IEEE International Symposium on,2007,19
Financial distress model prediction using SVM+,Bernardete Ribeiro; Catarina Silva; Armando Vieira; António Gaspar-Cunha; Joao C das Neves,Financial distress prediction is of great importance to all stakeholders in order to enablebetter decision-making in evaluating firms. In recent years; the rate of bankruptcy has risenand it is becoming harder to estimate as companies become more complex and theasymmetric information between banks and firms increases. Although a great variety oftechniques have been applied along the years; no comprehensive method incorporating anholistic perspective had hitherto been considered. Recently; SVM+ a technique proposed byVapnik [17] provides a formal way to incorporate privileged information onto the learningmodels improving generalization. By exploiting additional information to improve traditionalinductive learning we propose a prediction model where data is naturally separated intoseveral groups according to the size of the firm. Experimental results in the setting of a …,Neural Networks (IJCNN); The 2010 International Joint Conference on,2010,18
Learning manifolds for bankruptcy analysis,Bernardete Ribeiro; Armando Vieira; João Duarte; Catarina Silva; João Carvalho Das Neves; Qingzhong Liu; Andrew H Sung,Abstract We apply manifold learning to a real data set of distressed and healthy companiesfor proper geometric tunning of similarity data points and visualization. While Isomapalgorithm is often used in unsupervised learning our approach combines this algorithm withinformation of class labels for bankruptcy prediction. We compare prediction results withclassifiers such as Support Vector Machines (SVM); Relevance Vector Machines (RVM) andthe simple k-Nearest Neighbor (KNN) in the same data set and we show comparableaccuracy of the proposed approach.,International conference on neural information processing,2008,18
Towards expanding relevance vector machines to large scale datasets,Catarina Silva; Bernardete Ribeiro,In this paper we develop and analyze methods for expanding automated learning ofRelevance Vector Machines (RVM) to large scale text sets. RVM rely on Bayesian inferencelearning and while maintaining state-of-the-art performance; offer sparse and probabilisticsolutions. However; efforts towards applying RVM to large scale sets have met with limitedsuccess in the past; due to computational constraints. We propose a diversified set of divide-and-conquer approaches where decomposition techniques promote the definition of smallerworking sets that permit the use of all training examples. The rationale is that by exploringincremental; ensemble and boosting strategies; it is possible to improve classificationperformance; taking advantage of the large training set available. Results on Reuters-21578and RCV1 are presented; showing performance gains and maintaining sparse solutions …,International journal of neural systems,2008,18
Financial credit risk assessment: a recent review,Ning Chen; Bernardete Ribeiro; An Chen,Abstract The assessment of financial credit risk is an important and challenging researchtopic in the area of accounting and finance. Numerous efforts have been devoted into thisfield since the first attempt last century. Today the study of financial credit risk assessmentattracts increasing attentions in the face of one of the most severe financial crisis everobserved in the world. The accurate assessment of financial credit risk and prediction ofbusiness failure play an essential role both on economics and society. For this reason; moreand more methods and algorithms were proposed in the past years. From this point; it is ofcrucial importance to review the nowadays methods applied to financial credit riskassessment. In this paper; we summarize the traditional statistical models and state-of-the-art intelligent methods for financial distress forecasting; with the emphasis on the most …,Artificial Intelligence Review,2016,17
Choosing real-time predictors for ventricular arrhythmia detection,Bernardete Ribeiro; AmANdio Marques; Jorge Henriques; Manuel Antunes,The risk of developing life-threatening ventricular arrhythmias in patients with structural heartdisease is higher with increased occurrence of premature ventricular complex (PVC).Therefore; reliable detection of these arrhythmias is a challenge for a cardiovasculardiagnosis system. While early diagnosis is critical; the task of its automatic detection andclassification becomes crucial. Therefore; the underlying models should be efficient; albeitensuring robustness. Although neural networks (NN) have proven successful in this setting;we show that kernel-based learning algorithms achieve superior performance. In particular;recently developed sparse Bayesian methods; such as; Relevance Vector Machines (RVM);present a parsimonious solution when compared with Support Vector Machines (SVM); yetrevealing competitive accuracy. This can lead to significant reduction in the computational …,International Journal of Pattern Recognition and Artificial Intelligence,2007,17
On the performance of learning machines for bankruptcy detection,AS Vieira; B Ribeiro; S Mukkamala; JC Neves; AH Sung,Predicting the financial health of companies is a problem of great importance to variousstakeholders in the increasingly globalized economy. We apply several learning machinesmethods to the problem of bankruptcy prediction of private companies. Financial dataobtained from Diana; a database containing 780;000 financial statements of Frenchcompanies; are used to perform experiments. Classification accuracy is evaluated withrespect to artificial neural networks; linear genetic programming and support vectormachines. We analyze both type I (bankrupted companies misclassified as healthy) and typeII (healthy companies misclassified as bankrupted) errors on three datasets containingbalanced and unbalanced class distribution. Linear genetic programming has the bestaccuracy in the balanced data while support vector machines is more stable for the …,Computational Cybernetics; 2004. ICCC 2004. Second IEEE International Conference on,2004,17
Concept drift awareness in twitter streams,Joana Costa; Catarina Silva; Mário Antunes; Bernardete Ribeiro,Learning in non-stationary environments is not an easy task and requires a distinctiveapproach. The learning model must not only have the ability to continuously learn; but alsothe ability to acquired new concepts and forget the old ones. Additionally; given thesignificant importance that social networks gained as information networks; there is an ever-growing interest in the extraction of complex information used for trend detection; promotingservices or market sensing. This dynamic nature tends to limit the performance of traditionalstatic learning models and dynamic learning strategies must be put forward. In this paper wepresent a learning strategy to learn with drift in the occurrence of concepts in Twitter. Wepropose three different models: a time-window model; an ensemble-based model and anincremental model. Since little is known about the types of drift that can occur in Twitter …,Machine Learning and Applications (ICMLA); 2014 13th International Conference on,2014,16
Electrical signal source separation via nonnegative tensor factorization using on site measurements in a smart home,Marisa Figueiredo; Bernardete Ribeiro; Ana de Almeida,Measuring the electrical consumption of individual appliances in a household has recentlyreceived renewed interest in the area of energy efficiency research and sustainabledevelopment. The unambiguous acquisition of information by a single monitoring point ofthe whole house's electrical signal is known as energy disaggregation or nonintrusive loadmonitoring. A novel way to look into the issue of energy disaggregation is to interpret it as asingle-channel source separation problem. To this end; we analyze the performance ofsource modeling based on multiway arrays and the corresponding decomposition or tensorfactorization. First; with the proviso that a tensor composed of the data for the severaldevices in the house is given; nonnegative tensor factorization is performed in order toextract the most relevant components. Second; the outcome is later embedded in the test …,IEEE Transactions on Instrumentation and Measurement,2014,15
A novel approach for detection of copy-move forgery,Mengyu Qiao; Andrew Sung; Qingzhong Liu; Bernardete Ribeiro,Abstract—With the increasing popularity of digital media and the ubiquitous availability ofmedia editing software; innocuous multimedia are easily tampered for malicious purposes.Copy-move forgery is one important category of image forgery; in which a part of an image isduplicated; and substitutes another part of the same image at a different location. Therefore;it is necessary to have reliable and efficient methods to detect copy-move forgery forapplications in law enforcement; forensics; etc. In this paper; based on multiresolution andmulti-orientation curvelet transform; we propose a blind forensics approach for the detectionof copymove forgery. In detail; the input image is segmented into overlapping blocks; andthen curvelet transform is applied to each block. Statistics of curvelet sub-bands areextracted and sorted. Finally; duplicated blocks are identified by comparing their similarity …,proceedings of Fifth International Conference on Advanced Engineering Computing and Applications in Sciences (ADVCOMP 2011),2011,15
Non-negative matrix factorization implementation using graphic processing units,Noel Lopes; Bernardete Ribeiro,Abstract Non-Negative Matrix Factorization (NMF) algorithms decompose a matrix;containing only non-negative coefficients; into the product of two matrices; usually withreduced ranks. The resulting matrices are constrained to have only non-negativecoefficients. NMF can be used to reduce the number of characteristics in a dataset; whilepreserving the relevant information that allows for the reconstruction of the original data.Since negative coefficients are not allowed; the original data is reconstructed throughadditive combinations of the parts-based factorized matrix representation. A GraphicsProcessing Unit (GPU) implementation of the NMF algorithms; using both the multiplicativeand the additive (gradient descent) update rules is presented for the Euclidean distance aswell as for the divergence cost function. The performance results on an image database …,International Conference on Intelligent Data Engineering and Automated Learning,2010,15
Sequence labeling with multiple annotators,Filipe Rodrigues; Francisco Pereira; Bernardete Ribeiro,Abstract The increasingly popular use of Crowdsourcing as a resource to obtain labeleddata has been contributing to the wide awareness of the machine learning community to theproblem of supervised learning from multiple annotators. Several approaches have beenproposed to deal with this issue; but they disregard sequence labeling problems. However;these are very common; for example; among the Natural Language Processing andBioinformatics communities. In this paper; we present a probabilistic approach for sequencelabeling using Conditional Random Fields (CRF) for situations where label sequences frommultiple annotators are available but there is no actual ground truth. The approach uses theExpectation-Maximization algorithm to jointly learn the CRF model parameters; the reliabilityof the annotators and the estimated ground truth. When it comes to performance; the …,Machine learning,2014,14
Extracting features from an electrical signal of a non-intrusive load monitoring system,Marisa B Figueiredo; Ana de Almeida; Bernardete Ribeiro; António Martins,Abstract Improving energy efficiency by monitoring household electrical consumption is ofsignificant importance with the present-day climate change concerns. A solution for theelectrical consumption management problem is the use of a non-intrusive load monitoringsystem (NILM). This system captures the signals from the aggregate consumption; extractsthe features from these signals and classifies the extracted features in order to identify theswitched on appliances. An effective device identification (ID) requires a signature to beassigned for each appliance. Moreover; to specify an ID for each device; signal processingtechniques are needed for extracting the relevant features. This paper describes a techniquefor the steady-states recognition in an electrical digital signal as the first stage for theimplementation of an innovative NILM. Furthermore; the final goal is to develop an …,International Conference on Intelligent Data Engineering and Automated Learning,2010,14
Cambada’2010: Team description paper,AJR Neves; JL Azevedo; MB Cunha; N Lau; A Pereira; G Corrente; F Santos; D Martins; N Figueiredo; J Silva; J Cunha; B Ribeiro; R Sequeira; L Almeida; LS Lopes; JM Rodrigues; AJ Pinho,Abstract. This paper describes the CAMBADA middle-size robotic soccer team for thepurpose of qualification to RoboCup'2010. During the last year; improvements have beenmade mostly in the vision system; in the high-level coordination and control; in the worldmodelling and robot control.,Proceedings Robocup 2010,2010,14
RVM ensemble for text classification,Catarina Silva; Bernardete Ribeiro,Abstract: Automated classification of texts by their likeness or affinity has greatly eased themanagement and processing of the massive volumes of information we face everyday.Although Support Vector Machines (SVM) provide a state-of-theart technique to tackle thisproblem; Relevance Vector Machines (RVM); which rely on Bayesian inference learning;offer advantages such as their capacity to find sparser and probabilistic solutions. A knownproblem with the Bayesian approaches; however; is their relative inability to scale to largerproblems where millions of documents are involved as well as real-time user's requests. Wepropose an ensemble strategy to circumvent RVMs scalability problem by applying a divide-and-conquer technique to handle the overload of available data; where the trainingdocuments are divided amongst small RVM classifiers; then the ensemble combines their …,International Journal of Computational Intelligence Research,2007,14
Margin-based active learning and background knowledge in text mining,Catarina Silva; Bernardete Ribeiro,Text mining; also known as intelligent text analysis; text data mining or knowledge-discoveryin text; refers generally to the process of extracting interesting and nontrivial information andknowledge from text. One of the main problems with text mining and classification systems isthe lack of labeled data; as well as the cost of labeling unlabeled data (Kiritchenko andMatwin 2001). Thus; there is a growing interest in exploring the use of unlabeled data as away to improve classification performance in text classification. The ready availability of thiskind of data in most applications makes it an appealing source of information. In this work weevaluate the benefits of introducing unlabeled data in a support vector machine automatictext classifier. We further evaluate the possibility of learning actively and propose a methodfor choosing the samples to be learned.,Hybrid Intelligent Systems; 2004. HIS'04. Fourth International Conference on,2004,14
Cost-sensitive learning vector quantization for financial distress prediction,Ning Chen; Armando S Vieira; João Duarte; Bernardete Ribeiro; João C Neves,Abstract Financial distress prediction is of crucial importance in credit risk analysis with theincreasing competition and complexity of credit industry. Although a variety of methods havebeen applied in this field; there are still some problems remained. The accurate andsensitive prediction in presence of unequal misclassification costs is an important one.Learning vector quantization (LVQ) is a powerful tool to solve financial distress predictionproblem as a classification task. In this paper; a cost-sensitive version of LVQ is proposedwhich incorporates the cost information in the model. Experiments on two real data setsshow the proposed approach is effective to improve the predictive capability in cost-sensitivesituation.,Portuguese Conference on Artificial Intelligence,2009,12
Accurate prediction of financial distress of companies with machine learning algorithms,Armando S Vieira; João Duarte; Bernardete Ribeiro; João C Neves,Abstract Prediction of financial distress of companies is analyzed with several machinelearning approaches. We used Diane; a large database containing financial records fromsmall and medium size French companies; from the year of 2002 up to 2007. It is shown thatinclusion of historical data; up to 3 years priori to the analysis; increases the predictionaccuracy and that Support Vector Machines are the most accurate predictor.,International Conference on Adaptive and Natural Computing Algorithms,2009,12
Two-level hierarchical hybrid SVM-RVM classification model,Catarina Silva; Bernardete Ribeiro,Support vector machines (SVM) and relevance vector machines (RVM) constitute two state-of-the-art learning machines that are currently focus of cutting-edge research. SVM presentaccuracy and complexity preponderance; but are surpassed by RVM when probabilisticoutputs or kernel selection come to discussion. We propose a two-level hierarchical hybridSVM-RVM model to combine the best of both learning machines. The proposed model firstlevel uses an RVM to determine the less confident classified examples and the second levelthen makes use of an SVM to learn and classify the tougher examples. We show the benefitsof the hierarchical approach on a text classification task; where the two-levels outperformboth learning machines,Machine Learning and Applications; 2006. ICMLA'06. 5th International Conference on,2006,12
Learning control of thermal systems,GM Dimirovski; A Dourado; E Ikonen; U Kortela; J Pico; B Ribeiro; MJ Stankovski; E Tulunay,Processes and plant constructions of thermal systems; and of industrial furnaces; kilns and ovensin particular; have been subject to both scien- tific and technological research for long time [Rhineand Thucker 1991]. Due to the process complexity of energy conversion and transfer intother- mal systems; however; their control and supervision have recently become topics of extensiveresearch. From this point of view and in the course of C08Y research; these thermal processeshave been summarized and op- erationally characterized as: operating regimes of low-load andstart-up; medium-load and full-load as well as start-up and shut-down; multi-input- multi-output(MIMO) convex; control or steady-state (88); input-output (I/O) characteristics at operatingpoints; slow and non-linear overall dy- namics; but locally linearizable; low-frequencybandwidth; time-delay and non-minimum phase phenomena; problematic sensor …,*,2001,12
On learning control in industrial furnaces and boilers,GM Dimirovski; A Dourado; NE Gough; B Ribeiro; MJ Stankovski; IH Ting; E Tulunay,Presents some contributions to the integrated learning control and supervision of industrialthermal systems such as furnaces and boilers. Three application case-studies have enabledus to demonstrate practical feasibility and efficiency of the learning control and supervisionapproach in thermal systems automation. This approach provides for a methodology forsolving the problem of process identification; control and supervision for complex; multi-variable; thermal plants within a time-domain setting and by using recorded; operating timeseries and/or rough; non-parametric process models.,Intelligent Control; 2000. Proceedings of the 2000 IEEE International Symposium on,2000,12
Deep belief networks for financial prediction,Bernardete Ribeiro; Noel Lopes,Abstract Financial business prediction has lately raised a great interest due to the recentworld crisis events. In spite of the many advanced shallow computational methods that haveextensively been proposed; most algorithms have not yet attained a desirable level ofapplicability. All show a good performance for a given financial setup but fail in general tocreate better and reliable models. The main focus of this paper is to present a deep learningmodel with strong ability to generate high level feature representations for accurate financialprediction. The proposed Deep Belief Network (DBN) approach tested in a real dataset ofFrench companies compares favorably to shallow architectures such as Support VectorMachines (SVM) and single Restricted Boltzmann Machine (RBM). We show that theunderlying financial model with deep machine technology has a strong potential thus …,International Conference on Neural Information Processing,2011,11
Combining active learning and relevance vector machines for text classification,Catarina Silva; Bernardete Ribeiro,Relevance vector machines (RVM) have proven successful in many learning tasks.However; in large applications; they scale poorly. In many settings there is a large amount ofunlabeled data which could be actively chosen by a learner and integrated in the learningprocedure. The idea is to improve performance meanwhile reducing costs from datacategorization. In this paper we propose an active learning RVM method based on thekernel trick. The underpinning idea is to define a working space between the relevancevectors (RV) initially obtained in a small labeled data set and the new unlabeled examples;where the most informative instances are chosen. By using kernel distance metrics; such aspace can be defined and more informative examples can be added to the training set;increasing performance even though the problem dimension is not significantly affected …,Machine Learning and Applications; 2007. ICMLA 2007. Sixth International Conference on,2007,11
A utilização do planejamento estratégico na gestão de pequenas e médias empresas,André Fortuna Costa; Bian Ribeiro; GM de ALMEIDA; Jacqueline de Oliveira Catta Preta; Vinicius Bernardes Silva,*,Trabalho de Conclusão de Curso. FEAD–Minas. Belo Horizonte,2005,11
Labeled and unlabeled data in text categorization,Catarina Silva; Bernardete Ribeiro,There is a growing interest in exploring the use of unlabeled data as a way to improveclassification performance in text categorization. The ready availability of this kind of data inmost applications makes it an appealing source of information. This work reports a studycarried out on the Reuters-21578 corpus to evaluate the performance of support vectormachines when unlabeled examples are introduced in the learning process. Theimprovement achieved; especially in false negative values and therefore in recall values;demonstrates that the use of unlabeled examples can be very important for small data sets.,Neural Networks; 2004. Proceedings. 2004 IEEE International Joint Conference on,2004,11
Parry-Romberg syndrome: findings in advanced magnetic resonance imaging sequences-case report,Rafael Alfenas de Paula; Bruno Niemeyer de Freitas Ribeiro; Paulo Roberto Valle Bahia; Renato Niemeyer de Freitas Ribeiro; Laís Balbi de Carvalho,RESUMO Síndrome de Parry-Romberg é uma doença rara caracterizada por atrofiahemifacial progressiva associada a outras alterações sistêmicas; dentre elas; neurológicas.Atualmente; são poucos os trabalhos que exploraram sequências avançadas emressonância magnética nesta enfermidade. Neste artigo; relatamos o caso de um pacientecom 45 anos e descrevemos os achados de ressonância magnética estrutural e emsequências avançadas; correlacionando com dados fisiopatológicos.,Radiologia brasileira,2014,10
Extreme learning classifier with deep concepts,Bernardete Ribeiro; Noel Lopes,Abstract The text below describes a short introduction to extreme learning machines (ELM)enlightened by new developed applications. It also includes an introduction to deep beliefnetworks (DBN); noticeably tuned into the pattern recognition problems. Essentially; thedeep belief networks learn to extract invariant characteristics of an object or; in other words;an DBN shows the ability to simulate how the brain recognizes patterns by the contrastivedivergence algorithm. Moreover; it contains a strategy based on both the kernel (and neural)extreme learning of the deep features. Finally; it shows that the DBN-ELM recognition rate iscompetitive (and often better) than other successful approaches in well-known benchmarks.The results also show that the method is extremely fast when the neural based ELM is used.,Iberoamerican Congress on Pattern Recognition,2013,10
On the regularization parameter selection for sparse code learning in electrical source separation,Marisa Figueiredo; Bernardete Ribeiro; Ana Maria de Almeida,Abstract Source separation of whole-home electrical consumption also known as energydisaggregation plays a crucial role in energy savings and sustainable development. Oneimportant approach towards accurate energy disaggregation is based on sparse codelearning. The sparsity-based source separation algorithms allow to build models thatexplicitly generalize across multiple different devices of the same category. While thismethod has recently been investigated; yet the importance of the degree of sparsenessgiven by the regularization parameter is rarely considered. In this paper we aim atinvestigating the performance of learning representations from the aggregated electricalload signal with sparse models for energy disaggregation. In particular we focus our studyon the influence of the regularization parameter in the overall approach. The …,International Conference on Adaptive and Natural Computing Algorithms,2013,10
Wavelet decomposition and singular spectrum analysis for electrical signal denoising,Marisa B Figueiredo; Ana de Almeida; Bernardete Ribeiro,The aggregated electrical load of a household network contains relevant information.Specifically; which loads are related to electrical appliances switched on. However; whenreal-world data is at stake; not only this specific data must be individually recognized; butalso there is other non-relevant information that can be thought as noise in the electricalsignal. Therefore; to extract the important information we need to use signal denoisingalgorithms. This work presents a comparison for the application of an algorithm based onWavelet Decomposition versus the Singular Spectrum Analysis to the denoise of aggregatedelectrical signal. These techniques were applied both in an artificially generated signal aswell as to the analysis of a signal obtained from an ordinary household. For the latter; theexperiments highlighted a small set of wavelet functions that are more suitable for the …,Systems; Man; and Cybernetics (SMC); 2011 IEEE International Conference on,2011,10
A hybrid ais-svm ensemble approach for text classification,Mário Antunes; Catarina Silva; Bernardete Ribeiro; Manuel Correia,Abstract In this paper we propose and analyse methods for expanding state-of-the-artperformance on text classification. We put forward an ensemble-based structure thatincludes Support Vector Machines (SVM) and Artificial Immune Systems (AIS). Theunderpinning idea is that SVM-like approaches can be enhanced with AIS approacheswhich can capture dynamics in models. While having radically different genesis; andprobably because of that; SVM and AIS can cooperate in a committee setting; using aheterogeneous ensemble to improve overall performance; including a confidence on eachsystem classification as the differentiating factor. Results on the well-known Reuters-21578benchmark are presented; showing promising classification performance gains; resulting ina classification that improves upon all baseline contributors of the ensemble committee.,International Conference on Adaptive and Natural Computing Algorithms,2011,10
Magnetic and transport properties of transition-metal implanted ZnO single crystals,RP Borges; B Ribeiro; ARG Costa; C Silva; RC da Silva; G Evans; AP Gonçalves; MM Cruz; M Godinho,Abstract. ZnO single crystals were implanted with Mn; Co and Ni with fluences between 1×10 16 cm-2 and 1× 10 17 cm-2 and energy of 200 keV. Results indicate that aggregation oftransition metal ions in the as implanted state occurs only in the case of Ni. After anannealing stage to recover the ZnO structure aggregation occurs for the higher fluences ofall implanted species. For lower concentrations paramagnetic behaviour with magneticmoments close to those of individual ions is observed. No polarised impurity band is formedas a result of the presence of transition metal ions and all samples show electricalconduction by carriers in extended states of ZnO. Significant values of magnetoresistanceare measured at low temperatures; where electrical transport is described by hoppingmechanisms between localized states. The sign of the magnetoresistance is dependent …,The European Physical Journal B,2011,10
A stable credit rating model based on learning vector quantization,Ning Chen; Armando Vieira; Bernardete Ribeiro; João Duarte; João Neves,Abstract Credit rating is involved in many financial applications to estimate thecreditworthiness of corporations or individuals. In addition to building accurate credit ratingmodels; the stability of models is of significant importance to economic performance. In thiswork we propose a methodology based on learning vector quantization (LVQ) to develop acredit rating model. This model is applied to a French database of private companies over aperiod of several years. LVQ is trained and calibrated in a supervised way using data from2006 and then applied to the remaining years. We analyze one year transition matrix andshow that the model is capable to create robust and stable classes to rank companies.,Intelligent Data Analysis,2011,10
High-performance bankruptcy prediction model using graphics processing units,Bernardete Ribeiro; Noel Lopes; Catarina Silva,In recent years the the potential and programmability of Graphics Processing Units (GPU)has raised a note-worthy interest in the research community for applications that demandhigh-computational power. In particular; in financial applications containing thousands ofhigh-dimensional samples; machine learning techniques such as neural networks are oftenused. One of their main limitations is that the learning phase can be extremely consumingdue to the long training times required which constitute a hard bottleneck for their use inpractice. Thus their implementation in graphics hardware is highly desirable as a way tospeed up the training process. In this paper we present a bankruptcy prediction modelbased on the parallel implementation of the Multiple BackPropagation (MBP) algorithmwhich is tested on a real data set of French companies (healthy and bankrupt). Results by …,Neural Networks (IJCNN); The 2010 International Joint Conference on,2010,10
Supervised Isomap with dissimilarity measures in embedding learning,Bernardete Ribeiro; Armando Vieira; Joao Carvalho das Neves,Abstract In this paper we propose a supervised version of the Isomap algorithm byincorporating class label information into a dissimilarity matrix in a financial analysis setting.On the credible assumption that corporates financial status lie on a low dimensionalmanifold; nonlinear dimensionality reduction based on manifold learning techniques hasstrong potential for bankruptcy analysis in financial applications. We apply the method to areal data set of distressed and healthy companies for proper geometric tunning of similaritycases. We show that the accuracy of the proposed approach is comparable to the state-of-the-art Support Vector Machines (SVM) and Relevance Vector Machines (RVM) despite thefewer dimensions used resulting from embedding learning.,Iberoamerican Congress on Pattern Recognition,2008,10
Sparse bayesian models: Bankruptcy-predictors of choice?,Bernardete Ribeiro; Armando Vieira; Joao Carvalho das Neves,Abstract—Making inferences and choosing appropriate re-sponses based on incomplete;uncertainty and noisy data is challenging in financial settings particularly in bankruptcydetection. In an increasingly globalized economy; bankruptcy results both in huge economiclosses and tremendous social impact. While early prediction for a bankruptcy; if doneappropriately; is of great importance to banks; insurance firms; creditors; and investors; theneed of substantially more accurately predicting models becomes crucial. This problem hasbeen approached by various methods ranging from statistics to machine learning; howeverthey find a class decision estimate rather than a probabilistic confidence of the classdistribution. In this paper we show that sparse Bayesian models also known as RelevanceVector Machine (RVMs) are superior to the stateof-the-art machine learning algorithms …,IJCNN,2006,10
Support vector machines and RBF neural networks for fault detection and diagnosis,B Ribeiro,*,Proceedings of the 8th international conference on neural information processing; paper,2001,10
MONODA: a neural modular architecture for obstacle avoidance without knowledge of the environment,Catarina Silva; Manuel Crisostomo; Bernardete Ribeiro,A technique is proposed to detect and avoid obstacles for a mobile robot in an unknownenvironment. The usual problem of having too much sensorial information is dealt with byusing several neural networks that cooperate in the guidance of the robot. Several unknownobstacle configurations were presented to the modular networks; proving that the MONODAarchitecture is very effective for obstacle avoidance when there is neither a priori nor aposteriori maps of the environment.,Neural Networks; 2000. IJCNN 2000; Proceedings of the IEEE-INNS-ENNS International Joint Conference on,2000,10
Automatic graphic logo detection via Fast Region-based Convolutional Networks,Gonçalo Oliveira; Xavier Frazão; André Pimentel; Bernardete Ribeiro,Brand recognition is a very challenging topic with many useful applications in localizationrecognition; advertisement and marketing. In this paper we present an automatic graphiclogo detection system that robustly handles unconstrained imaging conditions. Ourapproach is based on Fast Region-based Convolutional Networks (FRCN) proposed byRoss Girshick; which have shown state-of-the-art performance in several generic objectrecognition tasks (PASCAL Visual Object Classes challenges). In particular; we use twoCNN models pretrained with the ILSVRC ImageNet dataset and we look at the selectivesearch of windowsproposals' in the pre-processing stage and data augmentation toenhance the logo recognition rate. The novelty lies in the use of transfer learning to leveragepowerful Convolutional Neural Network models trained with large-scale datasets and …,Neural Networks (IJCNN); 2016 International Joint Conference on,2016,9
Mining the big data: The critical feature dimension problem,Qingzhong Liu; Bernardete Ribeiro; Andrew H Sung; Divya Suryakumar,In mining massive datasets; often two of the most important and immediate problems aresampling and feature selection. Proper sampling and feature selection contributes toreducing the size of the dataset while obtaining satisfactory results in model building.Theoretically; therefore; it is interesting to investigate whether a given dataset possesses acritical feature dimension; or the minimum number of features that is required for a givenlearning machine to achieve" satisfactory" performance.(Likewise; the critical sampling sizeproblem concerns whether; for a given dataset; there is a minimum number of data pointsthat must be included in any sample for a learning machine to achieve satisfactoryperformance.) Here the specific meaning of" satisfactory" performance is to be defined by theuser. This paper addresses the complexity of both problems in one general theoretical …,Advanced Applied Informatics (IIAIAAI); 2014 IIAI 3rd International Conference on,2014,9
Get your jokes right: ask the crowd,Joana Costa; Catarina Silva; Mário Antunes; Bernardete Ribeiro,Abstract Jokes classification is an intrinsically subjective and complex task; mainly due to thedifficulties related to cope with contextual constraints on classifying each joke. Nowadayspeople have less time to devote to search and enjoy humour and; as a consequence;people are usually interested on having a set of interesting filtered jokes that could be worthreading; that is with a high probability of make them laugh. In this paper we propose acrowdsourcing based collective intelligent mechanism to classify humour and to recommendthe most interesting jokes for further reading. Crowdsourcing is becoming a model forproblem solving; as it revolves around using groups of people to handle tasks traditionallyassociated with experts or machines. We put forward an active learning Support VectorMachine (SVM) approach that uses crowdsourcing to improve classification of user …,International Conference on Model and Data Engineering,2011,9
Graph weighted subspace learning models in bankruptcy,Bernardete Ribeiro; Ning Chen,Many dimensionality reduction algorithms have been proposed easing both tasks ofvisualization and classification in high dimension problems. Despite the different motivationsthey can be cast in a graph embedding framework. In this paper we address weighted graphsubspace learning methods for bankruptcy analysis. The rationale behind re-embedding thedata in a lower dimensional space that would be better filled is twofold: to get the mostcompact representation (visualization) and to make subsequent processing of data moreeasy (classification). The approaches used; Graph regularized Non-Negative MatrixFactorization (GNMF) and Spatially Smooth Subspace Learning (SSSL); construct an affinityweight graph matrix to encode geometrical information and to learn in the training set thesubspace models that enhance visualization and are able to ease the task of bankruptcy …,Neural Networks (IJCNN); The 2011 International Joint Conference on,2011,9
Fast pattern classification of ventricular arrhythmias using graphics processing units,Noel Lopes; Bernardete Ribeiro,Abstract Graphics Processing Units (GPUs) can provide remarkable performance gainswhen compared to CPUs for computationally-intensive applications. In the biomedical area;most of the previous studies are focused on using Neural Networks (NNs) for patternrecognition of biomedical signals. However; the long training times prevent them to be usedin real-time. This is critical for the fast detection of Ventricular Arrhythmias (VAs) which maycause cardiac arrest and sudden death. In this paper; we present a parallel implementationof the Back-Propagation (BP) and the Multiple Back-Propagation (MBP) algorithm whichallowed significant training speedups. In our proposal; we explicitly specify data parallelcomputations by defining special functions (kernels); therefore; we can use a fast evaluationstrategy for reducing the computational cost without wasting memory resources. The …,Iberoamerican Congress on Pattern Recognition,2009,9
Image Complexity and Feature Extraction for Steganalysis of LSB Matching,Qing zhong Liu; Andrew H Sung; X Jianyun; Bernardete M Ribeiro,*,The 18th International Conference on Pattern Recognition (ICPR'06) 0-7695-2521-0/06 $20.00,2006,9
Machine Learning for Adaptive Many-Core Machines-A Practical Approach,Noel Lopes; Bernardete Ribeiro,Today the increasing complexity; performance requirements and cost of current (and future)applications in society is transversal to a wide range of activities; from science to businessand industry. In particular; this is a fundamental issue in the Machine Learning (ML) area;which is becoming increasingly relevant in a wide diversity of domains. The scale of the datafrom Web growth and advances in sensor data collection technology have been rapidlyincreasing the magnitude and complexity of tasks that ML algorithms have to solve. Much ofthe data that we are generating and capturing will be available “indefinitely” since it isconsidered a strategic asset from which useful and valuable information can be extracted. Inthis context; Machine Learning (ML) algorithms play a vital role in providing new insightsfrom the abundant streams and increasingly large repositories of data. However; it is well …,*,2015,8
Hybrid genetic algorithm and learning vector quantization modeling for cost-sensitive bankruptcy prediction,Ning Chen; Bernardete Ribeiro; Armando S Vieira; João Duarte; João C Neves,Cost-sensitive classification algorithms that enable effective prediction; where the costs ofmisclassification can be very different; are crucial to creditors and auditors in credit riskanalysis. Learning vector quantization (LVQ) is a powerful tool to solve bankruptcyprediction problem as a classification task. The genetic algorithm (GA) is applied widely inconjunction with artificial intelligent methods. The hybridization of genetic algorithm withexisting classification algorithms is well illustrated in the field of bankruptcy prediction. In thispaper; a hybrid GA and LVQ approach is proposed to minimize the expected misclassifiedcost under the asymmetric cost preference. Experiments on real-life French private companydata show the proposed approach helps to improve the predictive performance inasymmetric cost setup.,Machine Learning and Computing (ICMLC); 2010 Second International Conference on,2010,8
Improving text classification performance with incremental background knowledge,Catarina Silva; Bernardete Ribeiro,Abstract Text classification is generally the process of extracting interesting and non-trivialinformation and knowledge from text. One of the main problems with text classificationsystems is the lack of labeled data; as well as the cost of labeling unlabeled data. Thus;there is a growing interest in exploring the use of unlabeled data as a way to improveclassification performance in text classification. The ready availability of this kind of data inmost applications makes it an appealing source of information. In this work we propose anIncremental Background Knowledge (IBK) technique to introduce unlabeled data into thetraining set by expanding it using initial classifiers to deliver oracle decisions. The definedincremental SVM margin-based method was tested in the Reuters-21578 benchmarkshowing promising results.,International Conference on Artificial Neural Networks,2009,8
An ECG compression approach based on a segment dictionary and bezier approximations,Mário Brito; Jorge Henriques; Paulo Carvalho; Bernardete Ribeiro; Manuel Antunes,This paper proposes a methodology for ECG (electrocardiograms) data compression basedon RR segmentation. An ECG can be seen as a quasi-periodic signal; where it is possible tofind many similarities between heart beats. These similarities are explored by the proposedcompression scheme through the use of a segment dictionary combined with an efficientform of progressive error codification. The dictionary is able to incorporate new patterns; inorder to assure the algorithm adapts to changes in signal morphology. Experimental resultsreveal that high compression ratios are possible for highly regular signals; with irregularsignals still achieving acceptable results.,Signal Processing Conference; 2007 15th European,2007,8
Adaptive and Natural Computing Algorithms: Proceedings of the International Conference in Coimbra; Portugal; 2005,Bernadete Ribeiro; Rudolf F Albrecht; Andrej Dobnikar; David W Pearson; Nigel C Steele,The ICANNGA series of Conferences has been organised since 1993 and has a long historyof promoting the principles and understanding of computational intelligence paradigmswithin the scientific community and is a reference for established workers in this area.Starting in Innsbruck; in Austria (1993); then to Ales in Prance (1995); Norwich in England(1997); Portoroz in Slovenia (1999); Prague in the Czech Republic (2001) and finallyRoanne; in France (2003); the ICANNGA series has established itself for experiencedworkers in the field. The series has also been of value to young researchers wishing both toextend their knowledge and experience and also to meet internationally renowned experts.The 2005 Conference; the seventh in the ICANNGA series; will take place at the Universityof Coimbra in Portugal; drawing on the experience of previous events; and following the …,*,2005,8
Navigating mobile robots with a modular neural architecture,Catarina Silva; Bernardete Ribeiro,Abstract Neural architectures have been proposed to navigate mobile robots within severalenvironment definitions. In this paper a new neural modular constructive approach tonavigate mobile robots in unknown environments is presented. The problem; in its basicform; consists of defining and executing a trajectory to a pre-defined goal while avoiding allobstacles; in an unknown environment. Some crucial issues arise when trying to solve thisproblem; such as an overflow of sensorial information and conflicting objectives. Most neuralnetwork (NN) approaches to this problem focus on a monolithic system; ie; a system withonly one neural network that receives and analyses all available information; resulting inconflicting training patterns; long training times and poor generalisation. The work presentedin this article circumvents these problems by the use of a constructive modular NN …,Neural computing & applications,2003,8
On data based learning using support vector clustering,B Ribeiro,This paper addresses the effect of applying clustering algorithms; based on a distancemetric rule; prior to support kernel learning in classification and regression problems. Self-Organising Maps (SOMs); which place emphasis in data domain description; and K-meansclustering algorithms have been selected before applying a support vector algorithm whichis based on a margin rule. Moreover; the recently developed support vector clusteringalgorithm; based on a cluster boundary rule; is applied in benchmark problems forcomparison.,Neural Information Processing; 2002. ICONIP'02. Proceedings of the 9th International Conference on,2002,8
Artificial neural networks for data modelling of a plastic injection moulding process,N Costa; B Ribeiro,Injection moulding is the most common manufacturing method for the production of high-volume plastic parts. Although theoretically simple; the existence of strong nonlinearities andthe unpredictability that is inherent in the raw material used transforms the method into aquite complex process. The development of a process model; based on the analysis of themathematical relationships between the variables; although possible; would be extremelydifficult. Artificial neural networks; due to their capabilities and simplicity; are an attractiveapproach. Several training algorithms are presented in this paper; from which resilientbackpropagation has been used to train a neural network that is capable of modelling theprocess behaviour. Because of the complexity involved; due to the large number of availablevariables; principal component analysis has been applied to reduce the dimensionality of …,Neural Information Processing; 1999. Proceedings. ICONIP'99. 6th International Conference on,1999,8
Learning supervised topic models from crowds,Filipe Rodrigues; Bernardete Ribeiro; Mariana Lourenço; Francisco Pereira,Abstract The growing need to analyze large collections of documents has led to greatdevelopments in topic modeling. Since documents are frequently associated with otherrelated variables; such as labels or ratings; much interest has been placed on supervisedtopic models. However; the nature of most annotation tasks; prone to ambiguity and noise;often with high volumes of documents; deem learning under a single-annotator assumptionunrealistic or unpractical for most real-world applications. In this paper; we propose asupervised topic model that accounts for the heterogeneity and biases among differentannotators that are encountered in practice when learning from crowds. We develop anefficient stochastic variational inference algorithm that is able to scale to very large datasets;and we empirically demonstrate the advantages of the proposed model over state of the …,Third AAAI Conference on Human Computation and Crowdsourcing,2015,7
MSP430 microcontrollers essentials-A new approach for the embedded systems courses: Part 1-Overview and tools,Pedro Dinis Gaspar; A Espirito Santo; Bruno Ribeiro,The embedded systems (ES) formation require a broader set of knowledge; abilities andskills including informatics and electronics concepts in order to develop highly creative andimaginative applications based in analytical studies. Moreover; in an effort to improve theeducation quality it needs to be followed with intense hands-on laboratories. This paperpresents a new approach for embedded systems courses appropriate for both high schooland undergraduate classrooms; that has been conceived and designed to accomplish thesegoals; while motivating and equipping this next generation of engineers to rise to futurechallenges. The course structure was defined in order to be easy to understand and providea logical flow along the topics; as it mostly progresses from simple topics to more advancedones. The developed materials include slides for class room teaching; explanatory …,Education and Research Conference (EDERC); 2010 4th European,2010,7
A strategy for dealing with missing values by using selective activation neurons in a multi-topology framework,Noel Lopes; Bernardete Ribeiro,Neural Networks (NN) have proven to be able to successfully solve problems in many areas.However; for large scale real problems; data is often incomplete. This is a serious problem;because NN cannot handle directly missing values. The usual approach to solve thisproblem consists of removing attributes and/or samples containing unknown values. Thisstrategy is very attractive since it is simple to implement and reduces the dimensionality ofdata; therefore potentially reducing the complexity of the problem. However removingfeatures or instances containing vital information; which can not be compensated by theremaining data; may result in the unattainability of accurate NN models. Another strategyconsists of estimating missing values. However; wrong estimations of crucial data can leadto unpredicted results. Moreover these techniques do not account for real situations (eg …,Neural Networks (IJCNN); The 2010 International Joint Conference on,2010,7
Text classification on embedded manifolds,Catarina Silva; Bernardete Ribeiro,Abstract The problem of overfitting arises frequently in text mining due to high dimensionalfeature spaces; making the task of the learning algorithms difficult. Moreover; in such spacesvisualization is not feasible. We focus on supervised text classification by presenting anapproach that uses prior information about training labels; manifold learning and SupportVector Machines (SVM). Manifold learning is herein used as a pre-processing step; whichperforms nonlinear dimension reduction in order to tackle the curse of dimensionality thatoccurs. We use Isomap (Isometric Mapping) which allows text to be embedded in a lowdimensional space; while enhancing the geometric characteristics of data by preserving thegeodesic distance within the manifold. Finally; kernel-based machines can be used withbenefits for final text classification in this reduced space. Results on a real-world …,Ibero-American Conference on Artificial Intelligence,2008,7
Evaluation system for e-learning with pattern mining tools,Bernardete Ribeiro; Alberto Cardoso,Learning in online open networking environments turned out possible by today'swidespread use of Internet technologies; has led to the development of a broad range ofproducts for web-based courses at University level. However; although elearning ineducation is well established; there are a few attempts to extract information during thecourse final evaluation phase. In other words; while evaluation of e-learning applicationshas boosted the need to design effective methodologies for better tools; little attention wasdevoted to extract information for discovery of student's behavior.,Systems; Man and Cybernetics; 2008. SMC 2008. IEEE International Conference on,2008,7
Part quality prediction in an injection moulding process using neural networks,Noel Lopes; Bernardete Ribeiro,Abstract Competition is nowadays growing in every industrial field and the plastic industry isno exception. The superior quality demands; impose the development of intelligent systemsable to cope with the defects on the parts produced; by avoiding them and correcting theprocess parameters. Fault detection and diagnosis is an essential component for theconstruction of such systems. This paper presents a first step to build a fault detection anddiagnosis system for an injection moulding process. The basis for the approach takes twoartificial neural networks; trained with the back-propagation algorithm for detecting partdefects and monitoring a quality variable. The data was collected from the work carried outin an industrial site. Results show that the neural networks are able to embed the non-linearrelationships between the process variables and the quality part variables. The strategy …,proceedings of WMC; ISM,1999,7
Fault detection in a thermoplastic injection molding process using neural networks,B Ribeiro,Injection molding technology should assure a high level of quality control of the moldedparts via automation. Inherent complexities of the process make mathematical modelingdifficult; hindering the control quality demands of the conventional methods. Neural networksadaptive data based technology has been successfully applied in industrial applications asthey rely on highly nonlinear models and are able to provide enough rich data for modellingthe required process relationships. Neural networks are used herein for fault detection in theinjection molding process. The next step is to develop a system for automatic tuning ofmachine setups.,Neural Networks; 1999. IJCNN'99. International Joint Conference on,1999,7
Customized crowds and active learning to improve classification,Joana Costa; Catarina Silva; Mário Antunes; Bernardete Ribeiro,Abstract Traditional classification algorithms can be limited in their performance when aspecific user is targeted. User preferences; eg in recommendation systems; constitute achallenge for learning algorithms. Additionally; in recent years user's interaction throughcrowdsourcing has drawn significant interest; although its use in learning settings is stillunderused. In this work we focus on an active strategy that uses crowd-based non-expertinformation to appropriately tackle the problem of capturing the drift between userpreferences in a recommendation system. The proposed method combines two main ideas:to apply active strategies for adaptation to each user; to implement crowdsourcing to avoidexcessive user feedback. A similitude technique is put forward to optimize the choice of themore appropriate similitude-wise crowd; under the guidance of basic user feedback. The …,Expert Systems with Applications,2013,6
Improving the generalization capacity of cascade classifiers,Oswaldo Ludwig; Urbano Nunes; Bernardete Ribeiro; Cristiano Premebida,The cascade classifier is a usual approach in object detection based on vision; since itsuccessively rejects negative occurrences; eg; background images; in a cascade structure;keeping the processing time suitable for on-the-fly applications. On the other hand; similar toother classifier ensembles; cascade classifiers are likely to have high Vapnik-Chervonenkis(VC) dimension; which may lead to overfitting the training data. Therefore; this work aims atimproving the generalization capacity of the cascade classifier by controlling its complexity;which depends on the model of their classifier stages; the number of stages; and the featurespace dimension of each stage; which can be controlled by integrating the parameter settingof the feature extractor (in our case an image descriptor) into the maximum-marginframework of support vector machine training; as will be shown in this paper. Moreover; to …,IEEE transactions on cybernetics,2013,6
Nanoparticles of Ni in ZnO single crystal matrix,RP Borges; B Ribeiro; MM Cruz; M Godinho; U Wahl; RC da Silva; AP Gonçalves; C Magén,Abstract Magnetic nanoparticles were produced in ZnO single crystals using ionimplantation of Ni along the [0001] channelling direction of ZnO. The particles wereidentified by X-ray diffraction and magnetization measurements as a distribution ofsuperparamagnetic nickel nanoparticles having diameters in the range 2− 3 nm. The depthdistribution and size of the particles were determined using Rutherford backscatteringspectrometry (RBS) and transmission electron microscopy (TEM). The obtained resultsagree with magnetization and X-ray diffraction (XRD) data. From the determined depthdistribution; the density change of implanted region of the material modified by theimplantation procedure was estimated.,The European Physical Journal B,2013,6
Influence of class distribution on cost-sensitive learning: A case study of bankruptcy analysis,Ning Chen; An Chen; Bernardete Ribeiro,Abstract Skewed class distribution and non-uniform misclassification cost are pervasive inmany real-world domains such as bankruptcy prediction; medical diagnosis; and intrusiondetection. Although class imbalance learning and cost-sensitive learning can bemanipulated in a unified framework as was illustrated in previous studies; the influence ofclass distribution on cost-sensitive learning still needs clarification. In this paper; weinvestigate the effect of cost ratio; imbalance ratio and sample size on classificationperformance using a real-world French bankruptcy database. The results show that the costratio and the level of class imbalance have strong effect on prediction performance. A near-balanced training data set is favorable when a relatively uniform cost ratio is used; whereasa near-natural class distribution is favorable when a highly uneven cost ratio is used.,Intelligent Data Analysis,2013,6
Multi-objective evolutionary algorithms for feature selection: application in bankruptcy prediction,António Gaspar-Cunha; Fernando Mendes; João Duarte; Armando Vieira; Bernardete Ribeiro; André Ribeiro; João Neves,Abstract A Multi-Objective Evolutionary Algorithm (MOEA) was adapted in order to deal withproblems of feature selection in data-mining. The aim is to maximize the accuracy of theclassifier and/or to minimize the errors produced while minimizing the number of featuresnecessary. A Support Vector Machines (SVM) classifier was adopted. Simultaneously; theparameters required by the classifier were also optimized. The validity of the methodologyproposed was tested in the problem of bankruptcy prediction using a database containingfinancial statements of 1200 medium sized private French companies. The results producedshown that MOEA is an efficient feature selection approach and the best results wereobtained when the accuracy; the errors and the classifiers parameters are optimized.,Asia-Pacific Conference on Simulated Evolution and Learning,2010,6
Weighted learning vector quantization to cost-sensitive learning,Ning Chen; Bernardete Ribeiro; Armando Vieira; João Duarte; João Neves,Abstract The importance of cost-sensitive learning becomes crucial when the costs ofmisclassifications are quite different. Many evidences have demonstrated that a cost-sensitive predictive model is more desirable in practical applications than a traditional onewithout taking the cost into consideration. In this paper; we propose two approaches whichincorporate the cost matrix into original learning vector quantization by means of instanceweighting. Empirical results show that the proposed algorithms are effective on both binary-class data and multi-class data.,International Conference on Artificial Neural Networks,2010,6
Manifold learning for premature ventricular contraction detection,BR Ribeiro; JH Henirques; AM Marques; MA Antunes,Prompt diagnosis of abnormally shaped wave forms in ECG signal is an importantcomponent in the early diagnosis of cardiac arrhythmias; improving the quality of life ofpatients. Meanwhile; detection models for Premature Ventricular Contractions (PVC) arewidely investigated; a less studied problem is data analysis and visualization. In this paper;we propose an approach for PVC detection and data visualization by exploiting the intrinsicgeometry of the high-dimensional data using manifold learning and Support VectorMachines (SVM). ISOMAP forms a neighborhood-preserving projection which allows touncover the low-dimensional manifold and is used here as a pre-processing step. Then byincorporating training labels the method is capable of recognizing PVC patterns withcomparable accuracy of kernel learning machines.,Computers in Cardiology; 2008,2008,6
Premature ventricular beat detection by using spectral clustering methods,BR Ribeiro; AM Marques; JH Henriques; MA Antunes,In this paper; we the look at the spectral properties of features extracted from segmentedECG signals containing Normal (N) and premature ventricular beats (V) prior to applyclassification methods for reliable PVC detection. In a first stage; feature extraction based onsignal basic analysis which computes not only intervals and amplitudes on each beat; butalso description of wave morphology was performed. Extracted parameters that describe thebasic shape of the beat such as: average wave amplitudes; durations and areas have beencomputed. In a second stage; the eigen decomposition of data allows finding structure inrecords which is optimal to attain high performance of classification. In a third stage; supportvector machines (SVM) which are benchmarked against several techniques have beenchosen for PVC detection. By applying SVM recursive feature elimination (SVM RFE) …,Computers in Cardiology; 2007,2007,6
Boosting rvm classifiers for large data sets,Catarina Silva; Bernardete Ribeiro; Andrew H Sung,Abstract Relevance Vector Machines (RVM) extend Support Vector Machines (SVM) to haveprobabilistic interpretations; to build sparse training models with fewer basis functions (ie;relevance vectors or prototypes); and to realize Bayesian learning by placing priors overparameters (ie; introducing hyperparameters). However; RVM algorithms do not scale up tolarge data sets. To overcome this problem; in this paper we propose a RVM boostingalgorithm and demonstrate its potential with a text mining application. The idea is to buildweaker classifiers; and then improve overall accuracy by using a boosting technique fordocument classification. The algorithm proposed is able to incorporate all the training dataavailable; when combined with sampling techniques for choosing the working set; theboosted learning machine is able to attain high accuracy. Experiments on REUTERS …,International Conference on Adaptive and Natural Computing Algorithms,2007,6
Statistical correlations and machine learning for steganalysis,Qingzhong Liu; Andrew H Sung; Bernardete M Ribeiro,Abstract In this paper; we present a scheme for steganalysis based on statistical correlationsand machine learning. In general; digital images are highly correlated in the spatial domainand the wavelet domain; hiding data in images will affect the correlations. Differentcorrelation features are chosen based on ANOVA (analysis of variance) in differentsteganographic systems. Several machine learning methods are applied to classify theextracted feature vectors. Experimental results indicate that our scheme in detecting thepresence of hidden messages in several steganographic systems is highly effective.,*,2005,6
Lime kiln fault detection and diagnosis by neural networks,B Ribeiro; E Costa; A Dourado,Abstract Artificial neural networks have recently been used successfully for fault detectionand diagnosis in chemical processes. In this paper; we present a study on fault detectionand diagnosis of an industrial lime kiln which is a complex highly nonlinear process withinthe pulp and paper industry. We show the capability of neural networks to learn faults whichcan occur during steady state kiln operation; their adaptation to different input distributionsinvolving nonlinear mappings and their capability to spontaneously generalize. We comparethe performance of two architectures; nameley BPNN (Back Propagation Neural Network)and RBFNN (Radial Basis Function Neural Network); and investigate several topologies.Through this study; it can be concluded that the RBFNN arquitecture learns faster; with lesserror and performs better at classifying kiln malfunctions.,*,1995,6
DOTS: drift oriented tool system,Joana Costa; Catarina Silva; Mário Antunes; Bernardete Ribeiro,Abstract Drift is a given in most machine learning applications. The idea that models mustaccommodate for changes; and thus be dynamic; is ubiquitous. Current challenges includetemporal data streams; drift and non-stationary scenarios; often with text data; whether insocial networks or in business systems. There are multiple drift patterns types: concepts thatappear and disappear suddenly; recurrently; or even gradually or incrementally.Researchers strive to propose and test algorithms and techniques to deal with drift in textclassification; but it is difficult to find adequate benchmarks in such dynamic environments. Inthis paper we present DOTS; Drift Oriented Tool System; a framework that allows for thedefinition and generation of text-based datasets where drift characteristics can be thoroughlydefined; implemented and tested. The usefulness of DOTS is presented using a Twitter …,International Conference on Neural Information Processing,2015,5
The impact of longstanding messages in micro-blogging classification,Joana Costa; Catarina Silva; Mário Antunes; Bernardete Ribeiro,Social networks are making part of the daily routine of millions of users. Twitter is amongFacebook and Instagram one of the most used; and can be seen as a relevant source ofinformation as users share not only daily status; but rapidly propagate news and events thatoccur worldwide. Considering the dynamic nature of social networks; and their potential ininformation spread; it is imperative to find learning strategies able to learn in theseenvironments and cope with their dynamic nature. Time plays an important role by easily out-dating information; being crucial to understand how informative can past events be to currentlearning models and for how long it is relevant to store previously seen information; to avoidthe computation burden associated with the amount of data produced. In this paper we studythe impact of longstanding messages in micro-blogging classification by using different …,Neural Networks (IJCNN); 2015 International Joint Conference on,2015,5
Development of a low power wireless network to support elderly people based on eZ430-Chronos and SimpliciTI,Bruno Ribeiro; António Espírito-Santo; Weber Calixto; Nuno Garcia,The welfare of elderly people living alone or in rest homes can be significantly improved withthe introduction of technological solutions. However; before start the development of a newcommercial product; new ideas and concepts must be quickly validated. The existence of aplatform to enable the rapid verification of a solution will be an asset to support thedevelopment of a commercial product. The eZ430-Chronos together with the SimpliciTI weremodified to build a wireless network that works as a test bench for new products andconcepts. After laboratorial validation; an experimental pilot was installed in a rest home;contributing this way to gather fundamental conclusions to be used in the development ofnew commercial solutions.,Education and Research Conference (EDERC); 2014 6th European Embedded Design in,2014,5
Multi-threaded support vector machines for pattern recognition,João Gonçalves; Noel Lopes; Bernardete Ribeiro,Abstract Support Vector Machines (SVM) have become indispensable tools in the area ofpattern recognition. They show powerful classification and regression performance in highlynon-linear problems by mapping the input vectors nonlinearly into a high-dimensionalfeature space through a kernel function. However; the optimization task is numericallyexpensive since single-threaded implementations are hardly able to cope up with thecomplex learning task. In this paper; we present a multi-threaded implementation of theSequential Minimal Optimization (SMO) which reduces the numerical complexity byparallelizing the KKT conditions update; the calculation of the hyperplane offset and theclassification task. Our preliminary results both in benchmark datasets and real-worldproblems show competitive performance to the state-of-the-art tools while the execution …,International Conference on Neural Information Processing,2012,5
Improving convergence of restricted Boltzmann machines via a learning adaptive step size,Noel Lopes; Bernardete Ribeiro,Abstract Restricted Boltzmann Machines (RBMs) have recently received much attention dueto their potential to integrate more complex and deeper architectures. Despite their success;in many applications; training an RBM remains a tricky task. In this paper we present alearning adaptive step size method which accelerates its convergence. The results for theMNIST database demonstrate that the proposed method can drastically reduce the timenecessary to achieve a good RBM reconstruction error. Moreover; the technique excels thefixed learning rate configurations; regardless of the momentum term used.,Iberoamerican Congress on Pattern Recognition,2012,5
An incremental hypersphere learning framework for protein membership prediction,Noel Lopes; Daniel Correia; Carlos Pereira; Bernardete Ribeiro; António Dourado,Abstract With the recent raise of fast-growing biological databases; it is essential to developefficient incremental learning algorithms able to extract information efficiently; in particularfor constructing protein prediction models. Traditional inference inductive learning modelssuch as SVM perform well when all the data is available. However; they are not suited tocope with the dynamic change of the databases. Recently; a new Incremental HypersphereClassifier (IHC) Algorithm which performs instance selection has been proved to haveimpact in online learning settings. In this paper we propose a two-step approach which firstlyuses IHC for selecting a reduced data set (and also for immediate prediction); and secondlyapplies Support Vector Machines (SVM) for protein detection. By retaining the samples thatplay the most significant role in the construction of the decision surface while removing …,International Conference on Hybrid Artificial Intelligence Systems,2012,5
An incremental class boundary preserving hypersphere classifier,Noel Lopes; Bernardete Ribeiro,Abstract Recent progress in sensing; networking and data management has led to a wealthof valuable information. The challenge is to extract meaningful knowledge from such dataproduced at an astonishing rate. Unlike batch learning algorithms designed under theassumptions that data is static and its volume is small (and manageable); incrementalalgorithms can rapidly update their models to incorporate new information (on a sample-by-sample basis). In this paper we propose a new incremental instance-based learningalgorithm which presents good properties in terms of multi-class support; complexity;scalability and interpretability. The Incremental Hypersphere Classifier (IHC) is tested in well-known benchmarks yielding good classification performance results. Additionally; it can beused as an instance selection method since it preserves class boundary samples.,International Conference on Neural Information Processing,2011,5
Efeito das barragens no transporte sedimentar fluvial,Bruno Miguel Gomes Ribeiro,Na dissertação apresentada procuram-se estudar os aspectos relacionados com adiminuição do transporte sedimentar fluvial; principalmente devido à construção debarragens. Este facto é importante no balanço sedimentar negativo e consequente erosãocosteira que se regista no litoral Português. Assim; analisa-se o transporte sólido antes eapós a construção de barragens em dois casos reais. No Rio Tejo; a construção deinúmeras barragens; provocou uma diminuição do transporte sólido em cerca de 70%; aopasso que; no Rio Saru (Japão); por aplicação de diferentes formulações numéricas; houveum decréscimo do transporte sedimentar fluvial em cerca de 50%; devido ao aumento dasecção de montante e consequente redução da velocidade de escoamento. Perante estefacto; foram efectuados ensaios laboratoriais com sedimentos; desenvolvidos no canal …,*,2009,5
Selecting examples in manifold reduced feature space for active learning,Catarina Silva; Bernardete Ribeiro,Nowadays machine learning are faced with an overload of data; both in terms of examplesand features. Although recent algorithms; like support vector machines; can handle highdimensionality; it remains valuable to find smaller and more fitted spaces to perform learningtasks. We propose a twofold approach to tackle these high dimensionality issues in a textclassification setting. First we use manifold learning as a pre-processing step to nonlinearlyreduce the feature space. Second we use support vector machines to implement an activelearning strategy; where the kernel trick is used to define the active examples. This approachdeals with the high dimensionality both reducing the features and the number of examplesneeded to reach a desired performance. Results on a real-world benchmark corpus fromReuters and also on a reduced realistic version of the corpus show first the visualization …,Machine Learning and Applications; 2008. ICMLA'08. Seventh International Conference on,2008,5
Building resilient classifiers for LSB matching steganography,Rita Ferreira; Bernardete Ribeiro; Catarina Silva; Qingzhong Liu; Andrew H Sung,One of the Internet's hallmark is the rapid spread of the use of information andcommunication technology. This has boosted methods for hiding stego information insidedigital cover content images which is a concerning issue in information security. On the otherhand; attack of steganographic schemes has leveraged methods for steganalysis which is achallenging problem. In this paper; first we look at the design of classifiers; such as; SupportVector Machines (SVM) and neural networks (RBF and MLP) which are able to detect thepresence of Least Significant Bit (LSB) matching steganography of gray scale images.Second; by combining with feature ranking methods (SVM-Recursive Feature Elimination;Kruskal Wallis) and reduction techniques (PCA) pattern classification of stego is successfullyachieved. It is of utmost importance to look at the large set of features extracted from …,Neural Networks; 2008. IJCNN 2008.(IEEE World Congress on Computational Intelligence). IEEE International Joint Conference on,2008,5
Biased Support Vector Machines and Kernel Methods for Intrusion Detection.,Krishna Yendrapalli; Srinivas Mukkamala; Andrew H Sung; Bernardete Ribeiro,Abstract–This paper describes results concerning the robustness and generalizationcapabilities of kernel methods in detecting intrusions using network audit trails. We usetraditional support vector machines (SVM); biased support vector machine (BSVM) andleave-one-out model selection for support vector machines (looms) for model selection. Wealso evaluate the impact of kernel type and parameter values on the accuracy of a supportvector machine (SVM) performing intrusion classification. Through a variety of comparativeexperiments; it is found that SVM performs the best for detecting Normal and User to SuperUser; BSVM performs the best for Denial of Service attacks; and looms based on BSVMperforms the best for Probe and Remote to Local. We show that classification accuracyvaries with the kernel type and the parameter values; thus; with appropriately chosen …,World Congress on Engineering,2007,5
Computational intelligent techniques for financial distress detection,S Mukkamala; DD Tilve; AH Sung; B Ribeiro; AS Vieira,Abstract: In this paper we apply several computational intelligence techniques to theproblem of bankruptcy prediction of medium-sized private companies. Financial data wasobtained from Diana; a large database containing financial statements of French companies.Classification accuracy is evaluated for Linear Genetic Programs (LGPs); Classification andRegression Tress (CART); TreeNet; and Random Forests; Multilayer Perceptron (using BackPropogation); Hidden Layer Learning Vector Quantization and several gradient descentmethods; conjugate gradient methods; the Levenberg-Marquardt algorithm (LM); theResilient Backpropogation Algorithm (Rprop); and One Step Secant Method. We analyze 2datasets; one is balanced and the other unbalanced. TreeNet has the best performanceaccuracy on unbalanced dataset and LGPs performs the best on balanced dataset …,International Journal of Computational Intelligence Research,2006,5
Bayes information criterion for Tikhonov regularization with linear constraints: application to spectral data estimation,Paulo Carvalho; Amâncio Santos; António Dourado; Bernardete Ribeiro,Spectral data estimation is an ill-posed problem; since it is difficult to collect sufficient linearindependent data and; due to the integral nature of solid-state light sensors; camera outputsdo not depend continuously on input signals. To solve these problems; most methods relyon exact a priori knowledge to reduce the problem's complexity (solution space). In thispaper a new algorithm is introduced which does not require a priori information. The methodis build upon a new extension of the Bayes information criterion for ill-posed estimationproblems; that is able to extract this information from the input data. The proposed solution isquite general and can readily be applied to other ill-posed problems; which are common incomputer vision and image processing.,Pattern Recognition; 2002. Proceedings. 16th International Conference on,2002,5
A neural prediction model for monitoring and fault diagnosis of a plastic injection moulding process,Nuno Costa; Bernardete Ribeiro,In engineering systems; early detection of the occurrence of faults is critical in avoidingproduct defects. This problematic is here discussed in the framework of an industrialprocess; namely; an injection moulding plastic machine. The relationships between theprocess state and the product quality are achieved through Principal Component Analysis.After having identified the main variables; two neural network architectures wereinvestigated; TDNN and Elman networks; with respect to one-step ahead prediction. Theresults show that TDNN exhibited lower training times with respect to a desired performancecriteria. However; for time series in which temporal dependency is large; the recurrentnetworks with time delayed inputs could lead to better results.,Control Conference (ECC); 1999 European,1999,5
Prediction of the lime availability on an industrial kiln by neural networks,B Ribeiro,Neural networks are used to predict the lime availability on an industrial kiln for qualitycontrol. For this purpose; a predictive empirical model of the highly nonlinear relationshipbetween important variables such as the kiln temperatures and the residual calciumcarbonate; at the discharge end; is constructed using neural networks. It allows us to predictand monitor lime properties from kiln operation simulated data. With the help of neuralnetworks the quality control of the industrial unit is achieved more quickly and is extremelycost effective. These capabilities further strengthen the kiln operator's decisions leading toenergy savings and increased production of first-quality materials in the pulp manufacturingprocess.,Neural Networks Proceedings; 1998. IEEE World Congress on Computational Intelligence. The 1998 IEEE International Joint Conference on,1998,5
Visualization of individual ensemble classifier contributions,Catarina Silva; Bernardete Ribeiro,Abstract Ensembles of classifiers are usually considered a valuable approach in differentscenarios. A broad range of methods to deal with the construction; diversity and combinationof multiple predictive models have been extensively studied. While the focus is often toobtain more accurate and robust predictions than single models seldom the individualcontribution of classifiers which could contribute to a better understanding of the uncertaintyassociated with ensembles' outputs is taken into account. In this work we look into this issueand focus on evaluating the individual ensemble classifier contributions using severalscenarios. We propose a visual web model that allows for the evaluation of both individualcontributions as well as their interactions. We apply the proposed approach on a benchmarkdataset and show how it can visually be used to better understand the uncertainty …,International Conference on Information Processing and Management of Uncertainty in Knowledge-Based Systems,2016,4
Understanding road network dynamics: link-based topological patterns,Susana Freiria; Bernardete Ribeiro; Alexandre O Tavares,Abstract Road network interruptions caused by natural disasters are becoming morefrequent and their consequences are becoming of a wider range. The main goal of this workis to identify the most important roads in a network. Herein; a new model is proposed toevaluate the most important roads in the network through the application of biclusteringtechnique; identifying patterns of attributes (road performance measures) and patterns ofroads (connectivity patterns). Thereafter the model presented here is compared with themean geodesic distance variation. Both methodologies are applied to a case study and thepros and cons are discussed as well. Results point out the alpha index as the topologicalmeasure more relevant in the normal network flow; moreover the interruption of the links withhighest values of connectivity will have larger consequences in the normal functioning of …,Journal of transport geography,2015,4
Comparative study of classifier ensembles for cost-sensitive credit risk assessment,Ning Chen; Bernardete Ribeiro; An Chen,Abstract Ensemble is a recently emerged computing technique to provide promisingdecisions by a consensus of multiple classifiers. The benefit of classifier ensembles hasbeen demonstrated in a vast number of studies in the scope of credit risk management. Yetthe performance of different ensemble models was rarely compared when the costs ofmisclassification errors are asymmetric. In this paper; we concentrate on the performance of6 ensemble techniques in the context of cost-sensitive credit scoring using 3 financial datasets. The ensemble models are built on the basis of a set of component classifiers derivedfrom different subsets of instances or features by a single learning algorithm. Theperformance of classifiers is evaluated in terms of expected misclassification cost andcompared by nonparametric significance test. The experimental results demonstrate that …,Intelligent Data Analysis,2015,4
Signature identification via efficient feature selection and GPU-based SVM classifier,Bernardete Ribeiro; Noel Lopes; Joao Goncalves,The problem of handwritten signature recognition is considered significant in biometrics; inparticular for determining the validity of official documents. The rationale consists of creatingan off-line classifier to discriminate between fake (forged) and genuine digitalizedsignatures. In such applications containing thousands of samples machine learningtechniques such as Support Vector Machines (SVM) play a preponderant role in overcomingthe challenges inherent to this problematic. However; to deal with the computational burdenof calculating the large Gram matrix; approaches such as Graphics Processing Units (GPU)computing are required for efficiently processing big image biometric data. In this paper; first;we present an empirical study for efficient feature selection concerning the signatureidentification problem. Second; an GPU-based SVM classifier that integrates a …,Neural Networks (IJCNN); 2014 International Joint Conference on,2014,4
On the optimization of appliance loads inferred by probabilistic models,Marisa Figueiredo; Bernardete Ribeiro; Ana de Almeida,Abstract—Recent Non-Intrusive Load Monitoring (NILM) approaches consider probabilisticgraphical models and statistical inference algorithms such as Hidden Markov Model (HMM).One interesting HMM based approach towards unsupervised energy disaggregationproposes prior models of general appliance types which are tuned to specific instancesusing only aggregated electrical consumption measurements. An essential step of thisapproach is the subtraction of the estimated usage from the aggregated load before thedisaggregation of a new load. Then wrongly-detected states of a given device lead to errorsthat are disseminated by the subsequent disaggregation. In this paper we aim atinvestigating an unsupervised HMM based approach that overcomes this limitation. First; thegeneral models are tuned for a selection of suitable periods of the signal in analysis …,Proceedings of the 2nd International Workshop on Non-Intrusive Load Monitoring,2014,4
A consensus approach for combining multiple classifiers in cost-sensitive bankruptcy prediction,Ning Chen; Bernardete Ribeiro,Abstract Bankruptcy prediction is an extremely important topic in the field of financialdecision making. There has been a raising interest in studying more accurate predictivemodels able to provide valuable early warning before the real business failure. Recentresearches suggested using the consensus of multiple classifiers for boosting the predictionperformance. Yet rarely the cost of misclassification errors is considered in the literature ofconsensus decision making. In this paper we investigate the performance of classifierensembles for cost-sensitive bankruptcy prediction. The selection of ensemble members isbased on individual performance and pairwise diversity of classifiers. The experimentalresults on a real world database of French companies show that by selecting appropriatebase classifiers the ensemble learning substantially improves the performance of cost …,International Conference on Adaptive and Natural Computing Algorithms,2013,4
Lethal midline granuloma syndrome: a diagnostic dilemma,Bruno Niemeyer de Freitas Ribeiro; Paulo Roberto Valle Bahia; Ana Luiza Vianna Sobral de Oliveira; João Luiz Marchon Júnior,RESUMO A rara síndrome do granuloma letal da linha média apresenta difícil diagnóstico;em razão da grande variedade de doenças que podem causá-la e um desconhecimentopela maioria da classe médica. No presente artigo relatamos caso de paciente com estadoença; provocada por carcinoma epidermoide; chamando a atenção para os diagnósticosdiferenciais e aspectos clínico-radiológicos que podem auxiliar no diagnóstico.,Radiologia Brasileira,2012,4
Biclustering and subspace learning with regularization for financial risk analysis,Bernardete Ribeiro; Ning Chen,Abstract Financial models draw on the need to turn critical (economical) information intobetter decision making models. When it comes to performance enhancement manyadvanced techniques have been used in bankruptcy detection with good results; yet rarelybiclustering has been considered. In this paper; we propose a two-step approach based firston biclustering and second on subspace learning with constant regularization. The rationalebehind biclustering is to discover patterns upholding instances and features that are highlycorrelated. Moreover; we placed great emphasis on building a weight affinity graph matrixand performing smooth subspace learning with regularization. In particular; the geometrictopology of biclusters is preserved during learning. Experimental results demonstrate thesuccess of the approach yielding excellent results in a real French data set of healthy and …,International Conference on Neural Information Processing,2012,4
Smart home: A novel model for denoising an electrical signal,Marisa B Figueiredo; Ana de Almeida; Bernardete Ribeiro,Emerging trends for energy monitoring as in Smart Energy Systems require intelligentsolutions for appliances identification. Non-intrusive load monitoring (NILM) systems areable to extract particular features from the aggregate consumption of the electrical network.However; the whole-consumption signal is contaminated with noise; which hinderssuccessful load disambiguation of individual appliances. In this work; we propose a novelapproach to denoise a signal based on the techniques of Embedding; Wavelet Shrinkageand Diagonal Averaging. The embedding stage transforms the one-dimensional signal intoa sequence of lagged vectors. These vectors are denoised using wavelet decomposition.Finally; the denoised signal is obtained by taking the diagonal averages of the resultantmatrix. Our approach is compared to Wavelet Decomposition and Singular Spectrum …,Intelligent Systems Design and Applications (ISDA); 2011 11th International Conference on,2011,4
The importance of precision in humour classification,Joana Costa; Catarina Silva; Mário Antunes; Bernardete Ribeiro,Abstract Humour classification is one of the most interesting and difficult tasks in textclassification. Humour is subjective by nature; yet humans are able to promptly define theirpreferences. Nowadays people often search for humour as a relaxing proxy to overcomestressful and demanding situations; having little or no time to search contents for suchactivities. Hence; we propose to aid the definition of personal models that allow the user toaccess humour with more confidence on the precision of his preferences. In this paper wefocus on a Support Vector Machine (SVM) active learning strategy that uses specific mostinformative examples to improve baseline performance. Experiments were carried out usingthe widely available Jester jokes dataset; with encouraging results on the proposedframework.,International Conference on Intelligent Data Engineering and Automated Learning,2011,4
Design of a learning environment for embedded system,Tiago Gonçalves; A Espírito-Santo; BJF Ribeiro; PD Gaspar,Abstract—Embedded systems have an everyday presence and direct impact in our lives.Therefore; Universities are continuously improving their courses in microprocessor andembedded programming. Although the diversity of curriculums; the availability of learningtools; where the student can practice and improve their skills; is a key factor to the success ofthe learning process. The platform developed and presented in this paper results fromauthor's experience in teaching embedded systems. From the analysis of teaching/learningneeds; a learning environment based on the MSP430 family was designed. This tool can beexpanded by modules and adjusted; at a specific time; to student's real needs. All modulescan be interconnected by an I2C bus; allowing to expand the capabilities of the platform. Thedeveloped modules allow the practice of subjects related with digital IO; analog interface …,Proceedings of the world congress on engineering,2010,4
Several enhancements to Hermite-based approximation of one-variable functions,Bartlomiej Beliczynski; Bernardete Ribeiro,Abstract Several enhancements and comments to Hermite-based one-variable functionapproximation are presented. First of all we prove that a constant bias extracted from thefunction contributes to the error decrease. We demonstrate how to choose that bias.Secondly we show how to select a basis among orthonormal functions to achieve minimumerror for a fixed dimension of an approximation space. Thirdly we prove that loss oforthonormality due to truncation of the argument range of the basis functions does not effectthe overall error of approximation and the expansion coefficients. We show how this featurecan be used. An application of the obtained results to ECG data compression is presented.,International Conference on Artificial Neural Networks,2008,4
Automated learning of RVM for large scale text sets: Divide to conquer,Catarina Silva; Bernardete Ribeiro,Abstract Three methods are investigated and presented for automated learning ofRelevance Vector Machines (RVM) in large scale text sets. RVM probabilistic Bayesiannature allows both predictive distributions on test instances and model-based selectionyielding a parsimonious solution. However; scaling up the algorithm is not workable in mostdigital information processing applications. We look at the properties of the baseline RVMalgorithm and propose new scaling approaches based on choosing appropriate workingsets which retain the most informative data. Incremental; ensemble and boosting algorithmsare deployed to improve classification performance by taking advantage of the large trainingset available. Results on Reuters-21578 are presented; showing performance gains andmaintaining sparse solutions that can be deployed in distributed environments.,International Conference on Intelligent Data Engineering and Automated Learning,2006,4
Rare class text categorization with SVM ensemble,C Silva; B Ribeiro,Kategoryzacja tekstu to przypisanie nowego tekstu do odpowiedniej kategorii zezdefiniowanego wcześniej zbioru. W praktycznych zastosowaniach liczba wzorców dlawiększości klas jest ograniczona; podczas gdy liczba wszystkich danych wejściowych jestogromna. Przy takich właściwościach problemu; zbudowanie klasyfikatora dobrzespełniającego swoje zadanie nie jest trywialne. Aby rozwiązać ten problem;zaproponowano zespól kilku struktur SVM; w których uczenie opiera się na maksymalizacjimarginesu separacji pomiędzy dwiema różnymi klasami. Metoda wprowadza odpornośćpoprzez korekcję wyjścia jednego z klasyfikatorów dzięki wykorzystaniu informacji z wyjśćpozostałych. Skuteczność metody zilustrowano na przykładzie symulacji dla zbioru danychReuters-21578.,Przegląd Elektrotechniczny,2006,4
Modeling execution times of data mining problems in grid environment,U Lotric; C Silva; B Ribeiro; A Dobnikar,*,Proc. 14th IEEE Int. ERK Conf,2005,4
Speeding-up text classification in a grid computing environment,C Silva; B Ribeiro; U Lotric,*,Proc. IEEE Int. Conf. Mach. Learning Appl,2005,4
Learning spectral calibration parameters for color inspection,Paulo Carvalho; Amancio Santos; Antonio Dourado; Bernardete Ribeiro,Light sensor spectral calibration is an ill-defined problem. For the identification problem oneneeds a priori knowledge of the characteristics of the sensor which is difficult to get in mostsituations. A new methodology is presented in this paper that does not rely on any a prioriknowledge of the sensor's characteristics. The method uses an extended generalized cross-validation function to measure predictability of the identified sensor's spectral behavior. Theprediction error is minimized with a hybrid genetic algorithm. Further an extended imageformation model is introduced to model changes in additive and multiplicative errors. Thecalibration problem is formulated to be independent of these changes by previouslyidentifying and removing them from the images.,Computer Vision; 2001. ICCV 2001. Proceedings. Eighth IEEE International Conference on,2001,4
Monitoring an Industrial Plastic Injection Moulding Machine Using Neural Networks,Nuno Costa; A Cunha; B Ribeiro,Abstract Plastics are nowadays one of the most used materials in several industries. Fromdomestic tools up to the automotive industry; there is an enormous number of possibleapplications. The pressures imposed by the market have led to the development of newstrategies capable of answering the required demands. Neural networks have revealed highpotential in a wide range of situations and have been successfully applied in fault detectionand diagnosis systems. In this paper we intend to clarify; in part; the different diagnosticmethodologies and; on the other hand; we suggest a neural network approach formonitoring the plastic injection moulding process. Future work will use the developed neuralmonitoring scheme for process fault diagnosis with the aim of industrial quality management.,*,1999,4
Lime ball quality inspection using a neural network and geometrical-based decision criteria,P d Carvalho; N Costa; B Ribeiro; A Dourado,*,Proceedings of the ICSE’97,1997,4
Industrial lime kiln computer dynamic simulation for improving efficiency,Bernardete Ribeiro; A Dourado Correia,Abstract The mathematical model of a pulp mill lime kiln and computer dynamic simulationare presented. The set of hyperbolic partial differential equations describing the chemicalreactions; the mass balance; energy balance and axial solids transport is described. In orderto obtain a model with an acceptable degree of complexity; the radial and angular variationsfor the solid and gas temperature equations are neglected. Since the wall represents animportant thermodynamical link between kiln environment and surroundings the radial kilnwall variation was considered in the model. The objective is the optimization of the kilnoperating conditions in industrial environment in order to increase product quality; decreaseenergy consumption and improve environmental conditions. The set of partial differentialequations is solved by a finite difference method and by a finite element orthogonal …,*,1993,4
Learning supervised topic models for classification and regression from crowds,Filipe Rodrigues; Mariana Lourenco; Bernardete Ribeiro; Francisco C Pereira,The growing need to analyze large collections of documents has led to great developmentsin topic modeling. Since documents are frequently associated with other related variables;such as labels or ratings; much interest has been placed on supervised topic models.However; the nature of most annotation tasks; prone to ambiguity and noise; often with highvolumes of documents; deem learning under a single-annotator assumption unrealistic orunpractical for most real-world applications. In this article; we propose two supervised topicmodels; one for classification and another for regression problems; which account for theheterogeneity and biases among different annotators that are encountered in practice whenlearning from crowds. We develop an efficient stochastic variational inference algorithm thatis able to scale to very large datasets; and we empirically demonstrate the advantages of …,IEEE transactions on pattern analysis and machine intelligence,2017,3
Choice of best samples for building ensembles in dynamic environments,Joana Costa; Catarina Silva; Mário Antunes; Bernardete Ribeiro,Abstract Machine learning approaches often focus on optimizing the algorithm rather thanassuring that the source data is as rich as possible. However; when it is possible to enhancethe input examples to construct models; one should consider it thoroughly. In this work; wepropose a technique to define the best set of training examples using dynamic ensembles intext classification scenarios. In dynamic environments; where new data is constantlyappearing; old data is usually disregarded; but sometimes some of those disregardedexamples may carry substantial information. We propose a method that determines the mostrelevant examples by analysing their behaviour when defining separating planes orthresholds between classes. Those examples; deemed better than others; are kept for alonger time-window than the rest. Results on a Twitter scenario show that keeping those …,International Conference on Engineering Applications of Neural Networks,2016,3
Sampling and evaluating the big data for knowledge discovery,A Sung; Bernardete Ribeiro; Qingzhong Liu,1School of Computing; The University of Southern Mississippi; Hattiesburg; MS 39406; USA2Department of Informatics Engineering; University of Coimbra; 3030-290 Coimbra; Portugal3Department of Computer Science; Sam Houston State University; Huntsville; TX 77341;USA andrew. sung@ usm. edu; bribeiro@ dei. uc. pt; liu@ shsu. edu,Proceedings of International Conference on Internet of Things and Big Data (IoTBD 2016); Science and Technology Publications,2016,3
Analysis of trends in seasonal electrical energy consumption via non-negative tensor factorization,Marisa Figueiredo; Bernardete Ribeiro; Ana de Almeida,Abstract This paper looks at the extraction of trends of household electrical seasonalconsumption via load disaggregation. With the proviso that data for several home devicescan be embedded in a tensor; non-negative multi-way array factorization is performed inorder to extract the most relevant components. In the initial decomposition step thedecomposed signals are incorporated in the test signal consisting of the whole-homemeasured consumption. After this the disaggregated data corresponding to each electricaldevice is obtained by factorizing the associated matrix through the learned model. Finally;we evaluate the performance of load disaggregation by the supervised method; and studythe trends along several years and across seasons. Towards this end; computationalexperiments were yielded using real-world data from household electrical consumption …,Neurocomputing,2015,3
On the impact of distance metrics in instance-based learning algorithms,Noel Lopes; Bernardete Ribeiro,Abstract In this paper we analyze the impact of distinct distance metrics in instance-basedlearning algorithms. In particular; we look at the well-known 1-Nearest Neighbor (NN)algorithm and the Incremental Hypersphere Classifier (IHC) algorithm; which proved to beefficient in large-scale recognition problems and online learning. We provide a detailedempirical evaluation on fifteen datasets with several sizes and dimensionality. We thenstatistically show that the Euclidean and Manhattan metrics significantly yield good results ina wide range of problems. However; grid-search like methods are often desirable todetermine the best matching metric depending on the problem and algorithm.,Iberian Conference on Pattern Recognition and Image Analysis,2015,3
Active manifold learning with twitter big data,Catarina Silva; Mário Antunes; Joana Costa; Bernardete Ribeiro,Abstract The data produced by Internet applications have increased substantially. Big data isa flaring field that deals with this deluge of data by using storage techniques; dedicatedinfrastructures and development frameworks for the parallelization of defined tasks and itsconsequent reduction. These solutions how-ever fall short in online and highly datademanding scenarios; since users expect swift feedback. Reduction techniques areefficiently used in big data online applications to improve classification problems. Reductionin big data usually falls in one of two main methods:(i) reduce the dimensionality by pruningor reformulating the feature set;(ii) reduce the sample size by choosing the most relevantexamples. Both approaches have benefits; not only of time consumed to build a model; buteventually also performance-wise; usually by reducing overfitting and improving …,Procedia Computer Science,2015,3
A fast optimized semi-supervised non-negative matrix factorization algorithm,Noel Lopes; Bernardete Ribeiro,Non-negative Matrix Factorization (NMF) is an unsupervised technique that projects datainto lower dimensional spaces; effectively reducing the number of features of a dataset whileretaining the basis information necessary to reconstruct the original data. In this paper wepresent a semi-supervised NMF approach that reduces the computational cost whileimproving the accuracy of NMF-based models. The advantages inherent to the proposedmethod are supported by the results obtained in two well-known face recognitionbenchmarks.,Neural Networks (IJCNN); The 2011 International Joint Conference on,2011,3
A robust learning model for dealing with missing values in many-core architectures,Noel Lopes; Bernardete Ribeiro,Abstract Most of the classification algorithms (eg support vector machines; neural networks)cannot directly handle Missing Values (MV). A common practice is to rely on data pre-processing techniques by using imputation or simply by removing instances and/or featurescontaining MV. This seems inadequate for various reasons: the resulting models do notpreserve the uncertainty; these techniques might inject inaccurate values into the learningprocess; the resulting models are unable to deal with faulty sensors and data in real-worldproblems is often incomplete. In this paper we look at the Missing Values Problem (MVP) byextending our recently proposed Neural Selective Input Model (NSIM) first; to a novel multi-core architecture implementation and; second; by validating our method in a real-worldfinancial application. The NSIM encompasses different transparent and bound …,International Conference on Adaptive and Natural Computing Algorithms,2011,3
MSP430 microcontrollers essentials-A new approach for the embedded systems courses: Part 2-System and peripherals,Pedro Dinis Gaspar; A Espírito Santo; Bruno Ribeiro,This paper presents the second part of a new approach for embedded systems coursesappropriate for both high school and undergraduate classrooms; that has been conceivedand designed to accomplish these goals; while motivating and equipping this nextgeneration of engineers to rise to future challenges.,Education and Research Conference (EDERC); 2010 4th European,2010,3
Feature selection for bankruptcy prediction: A multi-objective optimization approach,António Gaspar-Cunha; Fernando Mendes; João Duarte; Armando Vieira; Bernardete Ribeiro; André Ribeiro; J Neves,Abstract In this work a Multi-Objective Evolutionary Algorithm (MOEA) was applied forfeature selection in the problem of bankruptcy prediction. This algorithm maximizes theaccuracy of the classifier while keeping the number of features low. A two-objective problem;that is minimization of the number of features and accuracy maximization; was fully analyzedusing the Logistic Regression (LR) and Support Vector Machines (SVM) classifiers.Simultaneously; the parameters required by both classifiers were also optimized; and thevalidity of the methodology proposed was tested using a database containing financialstatements of 1200 medium sized private French companies. Based on extensive tests; it isshown that MOEA is an efficient feature selection approach. Best results were obtainedwhen both the accuracy and the classifiers parameters are optimized. The proposed …,International Journal of Natural Computing Research (IJNCR),2010,3
Background on text classification,Catarina Silva; Bernardete Ribeiro,Abstract In this chapter background material for studying text classification problems ispresented along with the notation used throughout the book. After describing the problem; asummary of typical applications is given and document representation issues are introducedfollowed by commonly used pre-processing steps; including dimensionality reduction. Next;state-of-the-art classifiers for text classification are briefly reviewed with currentachievements; followed by some widely accepted performance evaluation metrics andbenchmarks. To determine the influence and relative importance of pre-processing methodsin text classification performance an empirical study was carried out to comparedimensionality reduction techniques; using standard learning machines and benchmarks.Results and analysis of this study are reported and finally the conclusions on the relative …,*,2010,3
Knowledge extraction with non-negative matrix factorization for text classification,Catarina Silva; Bernardete Ribeiro,Abstract Text classification has received increasing interest over the past decades for itswide range of applications driven by the ubiquity of textual information. The highdimensionality of those applications led to pervasive use of dimensionality reductionmethods; often black-box feature extraction non-linear techniques. We show how Non-Negative Matrix Factorization (NMF); an algorithm able to learn a parts-based representationof data by imposing non-negativity constraints; can be used to represent and extractknowledge from a text classification problem. The resulting reduced set of features is testedwith kernel-based machines on Reuters-21578 benchmark showing the method'sperformance competitiveness.,International Conference on Intelligent Data Engineering and Automated Learning,2009,3
Some enhancements to approximation of one-variable functions by orthonormal basis,Bartlomiej Beliczynski; Bernardete Ribeiro,Abstract Some enhancements to the approximation of one-variable functions with respect toan orthogonal basis are considered. A two-step approximation scheme is presented here. Inthe first step; a constant bias is extracted from the approximated function; while in thesecond; the function with extracted bias is approximated in a usual way. Later; these twocomponents are added together. First of all we prove that a constant bias extracted from thefunction decreases the error. We demonstrate how to calculate that bias. Secondly; in aminor contribution; we show how to choose basis from a selected set of orthonormalfunctions to achieve minimum error. Finally we prove that loss of orthonormality due totruncation of the argument range of the basis functions does not effect the overall error ofapproximation and the expansion coefficients' correctness. We show how this feature can …,Neural Network World,2009,3
Improving visualization; scalability and performance of multiclass problems with SVM manifold learning,Catarina Silva; Bernardete Ribeiro,Abstract We propose a learning framework to address multiclass challenges; namelyvisualization; scalability and performance. We focus on supervised problems by presentingan approach that uses prior information about training labels; manifold learning and supportvector machines (SVMs). We employ manifold learning as a feature reduction step;nonlinearly embedding data in a low dimensional space using Isomap (Isometric Mapping);enhancing geometric characteristics and preserving the geodesic distance within themanifold. Structured SVMs are used in a multiclass setting with benefits for final multiclassclassification in this reduced space. Results on a text classification toy example and onISOLET; an isolated letter speech recognition problem; demonstrate the remarkablevisualization capabilities of the method for multiclass problems in the severely reduced …,International Conference on Adaptive and Natural Computing Algorithms,2009,3
Using Expanded Markov Process and Joint Distribution Features for JPEG Steganalysis.,Qingzhong Liu; Andrew H Sung; Mengyu Qiao; Bernardete Ribeiro,Abstract: In this paper; we propose a scheme for detecting the information-hiding in multi-class JPEG images by combining expanded Markov process and joint distribution features.First; the features of the condition and joint distributions in the transform domains areextracted (including the Discrete Cosine Transform or DCT; the Discrete Wavelet Transformor DWT); next; the same features from the calibrated version of the testing images areextracted. A Support Vector Machine (SVM) is applied to the differences of the featuresextracted from the testing image and from the calibrated version. Experimental results showthat this approach delivers good performance in identifying several hiding systems in JPEGimages.,ICAART,2009,3
Translation Based Arabic Text Categorization,MK Sankarapani; RB Basnet; S Mukkamala; Andrew H Sung; B Ribeiro; Coimbra Coimbra,Abstract This paper reports preliminary results of categorizing Arabic text into predefinedcategories by first translating the Arabic text into English using commercially availabletranslators and then categorizing the English text using support vector machines (SVMs). AnArabic corpus from Leeds University of UK is used in the experiments. Machine translation isprone to disfluencies and mistakes; even professional human translation often lacksprecision. Text categorization; however; is a much easier task than translation and machinelearning techniques have been utilized to obtain highly accurate automated categorization.This paper proposes that text categorization-especially the classification into a relativelysmall number of predefined categories such as Reuter‟ s collection-relies only on lexicalinformation and; therefore; it is feasible to categorize foreign-language texts using an …,Proceedings of Second International Conference on Information Systems Technology and Management; Dubai,2008,3
Bankruptcy Analysis for Credit Risk using Manifold Learning,B Ribeiro; A Vieira; J Duarte; C Silva; J Carvalho das Neves; Q Liu; AH Sung,In this work we apply manifold learning to a real data set of distressed and healthycompanies for proper geometric tunning of similarity data points and visualization. WhileIsomap [1] algorithm is often used in unsupervised learning; our approach combines thisalgorithm with information of class labels for bankruptcy prediction. We compare predictionresults with classifiers such as Support Vector Machines (SVM); Relevance Vector Machines(RVM) and the simple k-Nearest Neighbor (KNN) in the same data set; showing comparableaccuracy. Furthermore; the proposed approach is shown to have excellent visualizationcapabilities; as a result of the incorporation of prior knowledge of a variable (indicatingbankruptcy risk) into a dissimilarity matrix.,ICONIP. LNCS; Springer; Auckland,2008,3
Distributed Ensemble Learning in Text Classification.,Catarina Silva; Bernardete Ribeiro; Uros Lotric; Andrej Dobnikar,*,ICEIS (2),2008,3
Behavior pattern mining during the evaluation phase in an e-learning course,Bernardete Ribeiro; Alberto Cardoso,Abstract–There is a broad range of products available for e-learning which can be used incourse curriculum at University level. While e-learning in education is well established; thereare a few attempts to extract information in its evaluation phase. We look at a specific part ofan e-learning designed course favoring students' evaluation phase for extraction of behaviorpattern mining. Our approach uses neural networks (NN) and Support Vector Machines(SVM) to build prediction models able to track student's behavior. The data sets wereobtained from student's logs in a Moodle designed Course of Discrete Structures of theInformatics Engineering Bachelor at the University of Coimbra. The results show the modelis able to successfully predict students' final outcome while bringing useful feedback duringcourse learning.,Proceeings of International Conference on Engineering and Education,2007,3
On the Evaluation of Minkovsky Kernel for SVMs.,Bernardete Ribeiro,*,Neural Parallel & Scientific Comp.,2005,3
A method to improve generalization of neural networks: application to the problem of bankruptcy prediction,Armando Vieira; Joao C Neves; Bernardete Ribeiro,Abstract The Hidden Layer Learning Vector Quantization is used to correct the prediction ofmultilayer perceptrons in classification of high-dimensional data. Corrections are significantfor problems with insufficient training data to constrain learning. Our method; HLVQ-C;allows the inclusion of a large number of attributes without compromising the generalizationcapabilities of the network. The method is applied to the problem of bankruptcy predictionwith excellent results.,*,2005,3
On the Evaluation of Text Processing in Text Categorization.,Catarina Silva; Bernardete Ribeiro,*,ICMLA,2003,3
On the estimation of spectral data: a genetic algorithm approach,Paulo Carvalho; Amâncio Santos; A Dourado; B Ribeiro,Spectral data estimation from image data is an ill-posed problem since (i) due to the integralnature of solid-state light sensors; the same output can be obtained from an infinity of inputsignals and (ii) color signals are spectrally smooth in nature and therefore limit the numberof linear independent equations that can be formulated for the identification problem. Toenable the solution of these problems most methods rely on exact a priori knowledge; suchas smoothness and modality; to formulate hard constraints. A new method based on anextended generalized cross-validation measure is introduced for this type of problems. Thesolution is obtained with a genetic algorithm that maximizes its prediction ability. The methoddoes not require exact a priori knowledge on the solution; since it is able to extract thisinformation from the input data.,Image Processing; 2001. Proceedings. 2001 International Conference on,2001,3
On the use of neural networks and geometrical criteria for localisation of highly irregular elliptical shapes,Paulo Carvalho; N Costa; Bernardete Ribeiro; A Dourado,Abstract: Detection of elliptical shapes is of extreme importance in several computer visionapplications. In this paper a new method for irregular elliptical shapes localisation in multi-connected regions is described. This method first computes a set of elementary arcsegments; which is then aggregated using geometrical decision criteria and a posterioriaggregation probabilities obtained from a neural network for Bayes classification. To identifyand characterise the elementary arc segments; a cluster identification; a contour groupingstrategy and some extensions to Fitzgibbon's ellipse fitting method are introduced. Thesemethods are applied successfully in the set-up of an automatic lime granule inspectionsystem. The algorithm has proven to be very robust; since it is able to correctly detectelliptical shapes even when noisy data are present.,Pattern Analysis & Applications,1999,3
A data pre-processing tool for neural networks (dptnn) use in a moulding injection machine,Noel Lopes; Bernardete Ribeiro,Neural Networks (DPTNN) use in a fault diagnosis system in the plastics industry. Whenproperly understood and properly applied neural network technologies consistently buildeffective models from data. However; this task requires substantial investment in pre-processing and training. The developed tool allows to analyse and transform the data; topick train and test sets and to select the right inputs to be used on a neural network. On-linemeasurements of key processing variables from an injection moulding machine wereobtained from insite industry experiments. These were conducted to collect process data thatwas used to evaluate the ability of artificial neural networks to model the relationshipsamong process variables changes and the moulded part quality. The quality and quantity ofprocess data will have a significant impact on the performance of the diagnosis system …,Proceedings of the Second World Manufacturing Congress Durham,1999,3
Real time adaptive training of RBFNN using a selective forgetting algorithm,C Pereira; J Henriques; B Ribeiro; A Dourado,ABSTRACT In this work; we investigate the real-time identification problem of dynamic non-linear systems using a neural network approach. The neural network model structure ischosen to be the Gaussian Radial Basis Function (RBF) type; due to its universalapproximation property and also to the fact that the parameters are linearly related to theoutputs; allowing linear learning algorithms; with fast convergence speed and lowcomputational time; suitable for real-time applications. We propose a new hybrid learning;where we used first an adaptive learning rate with process monitoring. Secondly; takingadvantage of the locality property of this type of networks; we apply a selective forgettingalgorithm. Simulation examples are provided; applied to the identification of a theoreticalmodel and to a real laboratory process.,EANN96,1996,3
Lime kiln process identification and control: A neural network approach,B Ribeiro; A Dourado; E Costa,Abstract Complex systems exhibiting strong non linearities and time delays such aschemical processes are very demanding in control requirements. In this paper we present aneural network approach for multivariable non-linear kiln process identification and control.Neural networks; in control theory; are attractive because of their powerful capabilities tosuccessfully approximate nonlinear functions within a specified approximation error asrecent research has proven. They can be used to synthetize non-linear controllers for non-linear processes and it is expected that better results can be obtained as compared to moreconventional methods. The main objective of this work is to train the neural network kilncontroller to provide suitable control inputs that produce a desired kiln response. If theneural network plant model is capable of approximating well and with sufficient accuracy …,*,1993,3
A Bayesian additive model for understanding public transport usage in special events,Filipe Rodrigues; Stanislav S Borysov; Bernardete Ribeiro; Francisco C Pereira,Public special events; like sports games; concerts and festivals are well known to createdisruptions in transportation systems; often catching the operators by surprise. Althoughthese are usually planned well in advance; their impact is difficult to predict; even whenorganisers and transportation operators coordinate. The problem highly increases whenseveral events happen concurrently. To solve these problems; costly processes; heavilyreliant on manual search and personal experience; are usual practice in large cities likeSingapore; London or Tokyo. This paper presents a Bayesian additive model with Gaussianprocess components that combines smart card records from public transport with contextinformation about events that is continuously mined from the Web. We develop an efficientapproximate inference algorithm using expectation propagation; which allows us to …,IEEE transactions on pattern analysis and machine intelligence,2017,2
Towards the evolution of multi-layered neural networks: a dynamic structured grammatical evolution approach,Filipe Assunçao; Nuno Lourenço; Penousal Machado; Bernardete Ribeiro,Abstract Current grammar-based NeuroEvolution approaches have several shortcomings.On the one hand; they do not allow the generation of Artifi cial Neural Networks (ANNs)composed of more than one hidden-layer. On the other; there is no way to evolve networkswith more than one output neuron. To properly evolve ANNs with more than one hidden-layer and multiple output nodes there is the need to know the number of neurons availablein previous layers. In this paper we introduce Dynamic Structured Grammatical Evolution(DSGE): a new genotypic representation that overcomes the aforementioned limitations. Byenabling the creation of dynamic rules that specify the connection possibilities of eachneuron; the methodology enables the evolution of multi-layered ANNs with more than oneoutput neuron. Results in different classifi cation problems show that DSGE evolves …,Proceedings of the Genetic and Evolutionary Computation Conference,2017,2
Impact pad for use in tundish of continuous casting steel,*,An impact pad for use in tundish of continuous casting steel during pouring out of moltensteel (6) from the casting ladle into the tundish. The impact pad (1) has side walls (2)provided with barriers (3) distributed spaced apart and staggered in height and in length inthe whole extension of the walls (2) or part thereof; the impact pad (1) still comprises animpact bottom (5) provided with corrugations (4) uniformly distributed and staggered in itsentirety or part thereof.,*,2016,2
Chronic kernicterus: magnetic resonance imaging findings,Bruno Niemeyer de Freitas Ribeiro; Gabriela de Almeida Lima; Nina Ventura; Emerson Leandro Gasparetto; Edson Marchiori,Dear Editor; A 3-year-old male child who had developed bilirubin encephalopathy in theneonatal period; due to Rh incompatibility; presented with delayed neuromotor/psychomotordevelopment and involuntary movements. The prenatal and perinatal periods had been freeof complications. Serology for cytomegalovirus; toxoplasmosis; and HIV were negative; aswas the VDRL test. The results of a complete blood count; serum ceruloplasmin; electrolytes;and thyroid function were all within the limits of normality. Magnetic resonance imaging(MRI) of the brain showed bilateral; symmetrical hyperintense signals on FLAIR and T2-weighted sequences; affecting the globus pallidus and subthalamic nuclei; with no masseffect; with no diffusion restriction or evidence of gadolinium enhancement (Figure 1). Thoseimaging findings; together with the clinical and biochemical history; confirmed the …,Radiologia brasileira,2016,2
Convex hull calculations: a Matlab implementation and correctness proofs for the lrs-algorithm,Alexander Kovačec; Bernardete Ribeiro,Abstract: This paper provides full\Matlab-code and informal correctness proofs for thelexicographic reverse search algorithm for convex hull calculations. The implementation wastested on a 1993 486-PC for various small and some larger; partially highly degeneratecombinatorial polytopes; one of which (a certain 13-dimensional 24 vertex polyhedron)occurs naturally in the study of a well known problem posed by Professor Graciano deOliveira: see end of section 1.,arXiv preprint arXiv:1604.06112,2016,2
Credit Prediction Using Transfer of Learning via Self-Organizing Maps to Neural Networks,Ali AghaeiRad; Bernardete Ribeiro,Abstract For financial institutions; the ability to predict or forecast business failures is crucial;as incorrect decisions can have direct financial consequences. Credit prediction and creditscoring are the two major research problems in the accounting and finance domain. Avariety of pattern recognition techniques including neural networks; decision trees andsupport vector machines have been applied to predict whether borrowers are in danger ofbankruptcy and whether they should be considered a good or bad credit risk. In this paper aclustering and unsupervised method named Self Organizing Map (SOM) is used. Wepropose to label each cluster with voted method and improve labeling process by training afeedforward Neural Network (NN). The approach uses transfer of learning via SOM to theNN; is tested on the Australian Credit Approval financial data set. We compare both …,*,2015,2
Deep belief networks (DBNs),Noel Lopes; Bernardete Ribeiro,Abstract This chapter covers successful applications in deep learning with remarkablecapability to generate sophisticated and invariant features from raw input signal data. Newinsights of the visual cortex and studies in the relations between the connectivity found in thebrain and mechanisms for mind inference have enlightened the development of deep neuralnetworks. In this chapter the motivation for the design of these architectures points outtowards models with many layers exhibiting complex behavior enhanced by thousands ofneurons in each layer. By contrast; shallow neural networks have admittedly less capabilitywith respect to inference mechanisms since no feature detectors are found in their hiddenlayer. Then the chapter formalizes Restricted Boltzmann Machines (RBMs) and Deep BeliefNetworks (DBNs); which are generative models that along with an unsupervised greedy …,*,2015,2
Credit scoring for SME using a manifold supervised learning algorithm,Armando Vieira; Bernardete Ribeiro; Ning Chen,Abstract We propose a credit scoring algorithm based on the supervised ISOMAP to rateSME. By projecting the companies balance sheet data into a one dimensional componentwe obtain a smoother distribution of ratings while increasing the discriminatory capability ofeach rate in terms of the probability of default. The method is applied to a large dataset ofFrench SME.,International Conference on Intelligent Data Engineering and Automated Learning,2012,2
Síndrome do granuloma letal da linha média: um dilema diagnóstico,Bruno Niemeyer de Freitas Ribeiro; Paulo Roberto Valle Bahia; Ana Luiza Vianna Sobral de Magalhães; João Luiz Marchon Júnior,Abstract: The rare lethal midline granuloma syndrome is difficult to diagnose because of thewide array of related diseases and lack of knowledge by the majority of physicians. In thepresent report; the authors describe the case of a patient with this disease; caused bysquamous cell carcinoma; drawing attention to differential diagnoses and to clinical andradiological findings that may be useful to define the diagnosis. Resumo: A rara síndrome dogranuloma letal da linha média apresenta difícil diagnóstico; em razão da grande variedadede doenças que podem causá-la e um desconhecimento pela maioria da classe médica. Nopresente artigo relatamos caso de paciente com esta doença; provocada por carcinomaepidermoide; chamando a atenção para os diagnósticos diferenciais e aspectos clínico-radiológicos que podem auxiliar no diagnóstico.,Radiologia Brasileira,2012,2
Extension of learning vector quantization to cost-sensitive learning,Ning Chen; Bernardete Ribeiro; Armando Vieira; João Duarte; João C Neves,Abstract Learning vector quantization (LVQ) is an effectivenetwork model to solveclassification tasks in a wide variety ofreal world applications. The usage of LVQ has beenextended tohybrid data type. In this paper; we propose a weighted versionof BNCLVQ;which incorporates the cost matrix into prototypelearning and labeling by means of instanceweighting. Empirical results show the superiority of proposed algorithmover originalNBCLVQ and some variants on both binary-classdata and multi-class data.,International Journal of Computer Theory and Engineering,2011,2
Evaluation of a resource allocating network with long term memory using GPU,Bernardete Ribeiro; Ricardo Quintas; Noel Lopes,Abstract Incremental learning has recently received broad attention in many applications ofpattern recognition and data mining. With many typical incremental learning situations in thereal world where a fast response to changing data is necessary; developing a parallelimplementation (in fast processing units) will give great impact to many applications. Currentresearch on incremental learning methods employs a modified version of a resourceallocating network (RAN) which is one variation of a radial basis function network (RBFN).This paper evaluates the impact of a Graphics Processing Units (GPU) basedimplementation of a RAN network incorporating Long Term Memory (LTM)[4]. Theincremental learning algorithm is compared with the batch RBF approach in terms ofaccuracy and computational cost; both in sequential and GPU implementations. The UCI …,International Conference on Adaptive and Natural Computing Algorithms,2011,2
Non-intrusive residential electrical consumption traces,Marisa Figueiredo; Ana De Almeida; Bernardete Ribeiro,Abstract An active trend of research consists of understanding how electricity is used;namely for energy efficiency enforcement and in-home activity tracking. The obvious andcheapest solution is to use an inconspicuous monitoring system. Through the use of non-intrusive load monitoring systems; the signal from the aggregate consumption is captured;electrical significant features are extracted and classified and the appliances that wereconsuming are identified. In order to obtain a precise identification of the device; the mainrequirements are an electrical signature for each device and a proper classification method.The information thus obtained identifies appliance's usage and specific consumptions. Thispaper describes an on-going research aiming at the development and simplification oftechniques and algorithms for non-intrusive load monitoring systems (NILM). The first …,*,2011,2
Improving recall values in breast cancer diagnosis with Incremental Background Knowledge,Catarina Silva; Bernardete Ribeiro; Noel Lopes,Cancer diagnosis is generally the process of using some form of physical or genetic tests orexams; usually referred as patient data; to detect the disease. One of the main problems withcancer diagnosis systems is the lack of labeled data; as well as the difficulties of labeling pre-existing unlabeled data. Thus; there is a growing interest in exploring the use of unlabeleddata as a way to improve classification performance in cancer diagnosis. The possibleavailability of this kind of data for some applications makes it an appealing source ofinformation. In this work we explore an Incremental Background Knowledge (IBK) techniqueto introduce unlabeled data into the training set by expanding it using initial classifiers tobetter aid decisions; namely by improving recall values. The defined incremental SVMmargin-based method was tested in the Wisconsin-Madison breast cancer diagnosis …,Neural Networks (IJCNN); The 2010 International Joint Conference on,2010,2
Translation Based Foreign Language Text Categorization,Ram Basnet; G Torres; A Sung; B Ribeiro,Abstract—This paper reports results of translating foreign-language text into English utilizingmachine translation and then performing categorization of the English text by using supportvector machines (SVMs). Machine translation is prone to disfluencies and mistakes; evenhuman expert translation often lacks precision. Text categorization; however; is a mucheasier task than translation; and machine learning techniques have been utilized to obtainhighly accurate automated categorization. This paper proposes that text categorization-especially the classification into a relatively small number of predefined categories-reliesonly on lexical information and it is therefore feasible to categorize foreign-language textsusing an automated translator (to translate texts into English) and a trained classifier thatcategorizes texts in English language by exploiting the fact that English language has …,*,2009,2
Ventricular Arrhythmias Assessment,Jorge Henriques; Paulo Carvalho; Paulo Gil; Amandio Marques; Teresa Rocha; Bernardete Ribeiro; Manual Antunes; J Habetha,An integrated framework for ventricular arrhythmias (VA) assessment; composed of twolevels; is proposed in this work. The first level consists of four independent neural networks(NN); designed for specific detection tasks: signal quality; premature ventricular contractions(PVC); ventricular tachycardia (VT) and ventricular fibrillation (VF). Time and frequencydomain features; obtained from the electrocardiogram (ECG) and selected through acorrelation analysis procedure; form the inputs to the neural modules. The outputs feed thesecond layer; which consists of a global classifier (ANFIS structure); returns the global resultfor the VA assessment scheme. Sensitivity and specificity values; evaluated from public MIT-BIH databases; show the effectiveness of the proposed strategy.,Engineering in Medicine and Biology Society; 2007. EMBS 2007. 29th Annual International Conference of the IEEE,2007,2
Fast-decision SVM ensemble text classifier using cluster computing,Catarina Silva; Bernardete Ribeiro; Uroš Lotrič,*,International Conference on Neural; Parallel & Scientific Computations-ICNPSC,2006,2
Tuning parameters of the simple forecasting models,B Beliczyński; B Ribeiro,W artykule przedstawiono metody wyznaczania parametrów dla dwóch prostych modeliprognostycznych: modelu wygładzania wykładniczego i modelu Holta. Dla pierwszego znich zamiast metody poszukiwawczej proponowany jest prosty wzór. Dla drugiegoformułowana jest funkcja celu dla procedury optymalizacyjnej. Ta funkcja celu obejmuje nietylko błąd obliczony dla danych z przeszłości; lecz również zawiera składnik kary za zmianyzmiennej prognozowanej. Dołączony jest przykład ilustrujący.,Przegląd Elektrotechniczny,2006,2
Speeding-up text categorization in a grid computing environment,Catarina Silva; Bernardete Ribeiro; Uros Lotric,The amount of texts available in digital form has dramatically increased; giving rise to theneed of fast text classifiers. The tasks involved can be parallelized and distributed in a gridenvironment. This paper reports a study conducted on Reuters-21578 corpus; using a SVMlearning machine. The task of text categorization is distributed in several platforms. Theresults achieved are very promising for speeding-up text categorization tasks and are validindependently of the learning machine.,Machine Learning and Applications; 2005. Proceedings. Fourth International Conference on,2005,2
Text classification from partially labeled distributed data,Catarina Silva; Bemardete Ribeiro,Abstract One of the main problems with text classification systems is the lack of labeled data;as well as the cost of labeling unlabeled data [1]. Thus; there is a growing interest inexploring the combination of labeled and unlabeled data; ie; partially labeled data [2]; as away to improve classification performance in text classification. The ready availability of thiskind of data in most applications makes it an appealing source of information. Thedistributed nature of the data; usually available online; makes it a very interesting problemsuited to be solved with distributed computing tools; delivered by emerging GRID computingenvironments. We evaluate the advantages obtained by blending supervised andunsupervised learning in a support vector machine automatic text classifier. We furtherevaluate the possibility of learning actively and propose a method for choosing the …,*,2005,2
Angular memory and supervisory modules in a neural architecture for navigating NOMAD,Catarina Silva; Manuel Crisóstomo; Bernardete Ribeiro,Abstract This paper presents a neural modular architecture for navigating mobile robots. Theproposed architecture; based on functional task division; has been shown to be efficient inprevious work [1; 2]. The traditional difficulties associated with monolithic neural networksare circumvent by introducing a neural modular architecture; developed for the NOMADmobile robot. The modularity introduced retrieves all the available information; minimizingthe incoherence in the training sets; that arises from conflicting training patterns. Afterpresenting the modular architecture; two additional modules are introduced: Supervisoryand Angular Memory. The combination of all defined modules was first tested in simulationand then with the real robot; providing a solution to the problem of navigating NOMADmobile robot to an objective in an unknown environment.,*,2001,2
Industrial visual inspection of lime granules by neural networks,P d Carvalho; N Costa; B Ribeiro; A Dourado,Abstract Lime granule quality inspection is an important task in the pulp and paper industry.In this paper a new method; build-up on a neural network and a path search method; isintroduced for lime granule automatic visual inspection. Several correction steps to Landau'smethod are also introduced.,Computers & industrial engineering,1998,2
A Model-based Neural Network Controller for a Process Trainer Laboratory Equipment,B Ribeiro; A Cardoso,Abstract This paper presents an application of multilayered feedforward neural networks forcontrolling a PT326 process trainer laboratory equipment. Firstly; the process as well as itsinverse have been identified using the Levenberg-Marquardt algorithm for neural networktraining. Secondly an internal model control (IMC) strategy has been used for neurocontrol.Different architectures and learning methods have been investigated for modelapproximation. Control of the process has been implemented in real-time using theSimulink/Matlab environment. Experimental results regarding the performance of the controlscheme axe included in a comparative study.,*,1998,2
Industrial visual inspection of lime balls by neural networks,P d Carvalho; N Costa; B Ribeiro; A Dourado,ABSTRACT Lime ball quality inspection is an important task in the pulp and paper industry.In this paper a new method; build-up on a neural network and a path search method; isintroduced for lime ball automatic visual inspection. Several correction steps to Landau'smethod are also introduced.,CPj,1997,2
Neurocontroller synthesis of a scaled heating laboratory process,B Ribeiro; J Cordeiro; I Gomes; A Cardoso,*,Proceedings of the 2 Encontro Portugu^ es de Controlo Autom atico; CONTROLO96; Porto,1996,2
Integrated Process Supervision and Control by Neural Networks in an Industrial Lime Kiln,B Ribeiro; A Dourado; E Costa,ABSTRACT The focus of this paper is in the use of connectionist systems in the area of on-line process supervision and control. A survey of current literature [1] reveals that processsupervisison has the following functions:(i) detection of plant parameter deviations andinstability;(ii) guidance of controller tuning; adaptation and synthesis and (iii) identificationand diagnosis of process faults. A neural network approach is presented herein to performabove functions in an industrial lime kiln within pulp and paper industry. For economical andenvironmental reasons the process must be controlled in an efficient manner. An InternalModel Control (IMC) strategy is used to maintain fuel flow rate and draft flow rate atappropriate values in order to produce enough and high quality lime for the caustificationdepartment. The fault and diagnosis module observes deviations from operating …,World Congress on Neural Networks; San Diego; California,1996,2
Industrial kiln multivariable control: MNN and RBFNN approaches,B Ribeiro; A Dourado; E Costa,Abstract Artificial neural networks have been recognized as a valuable framework fornonlinear identification and control. In this paper we discuss and compare the use of twotypes of neural network arquitectures (1) MNN (Multilayer Neural Network) and (2) RBFNN(Radial Basis Function Neural Network) for modelling a second order nonlinear chemicalprocess—a lime kiln in the pulp and paper industry. The simulation results showed that MNNperforms better in this practical case. Therefore; it was used in an IMC (Internal ModelControl) strategy. The neurocontroller was analysed with regards to performance androbustness against disturbances.,*,1995,2
A Modular Neural Architecture for Navigating NOMAD Mobile Robot,Catarina Silva; Manuel Crisóstomo; Bernardete Ribeiro,*,8th International Conf. on Information Processing and Management of Uncertainty in Knowledge Based Systems.–Spain.–2000.–3-7 July,*,2
Importance Weighted Import Vector Machine for Unsupervised Domain Adaptation,Sirvan Khalighi; Bernardete Ribeiro; Urbano J Nunes,In real-world applications; the assumption of independent and identical distribution is nolonger consistent. To alleviate the significant mismatch between source and target domains;importance weighting import vector machine; which is an adaptive classifier; is proposed.This adaptive probabilistic classification method; which is sparse and computationallyefficient; can be used for unsupervised domain adaptation (DA). The effectiveness of theproposed approach is demonstrated via a toy problem; and a real-world cross-domainobject recognition task. Even though the sparseness; the proposed method outperforms thestate-of-the-art in both unsupervised and semisupervised DA scenarios. We also introduce areliable importance weighted cross validation (RIWCV); which is an improvement ofimportance weighted cross validation; for parameter and model selection. The RIWCV …,IEEE transactions on cybernetics,2017,1
Shaping graph pattern mining for financial risk,Bernardete Ribeiro; Ning Chen; Alexander Kovacec,Abstract In recent years graph pattern mining took a prominent role in knowledge discoveryin many scientific fields. From Web advertising to biology and finance; graph data isubiquitous making pattern-based graph tools increasingly important. When it comes tofinancial settings; data is very complex and although many successful approaches havebeen proposed often they neglect the intertwined economic risk factors; which seriouslyaffects the goodness of predictions. In this paper; we posit that financial risk analysis can beleveraged if structure can be taken into account by discovering financial motifs. We look atthis problem from a graph-based perspective in two ways; by considering the structure in theinputs; the graphs themselves; and by taking into account the graph embedded structure ofthe data. In the first; we use gBoost combined with a substructure mining algorithm. In the …,Neurocomputing,2017,1
Offline and online deep learning for image recognition,Nguyen Huu Phong; Bernardete Ribeiro,Image recognition using Deep Learning has been evolved for decades though advances inthe field through different settings is still a challenge. In this paper; we present our findings insearching for better image classifiers in offline and online environments. We resort toConvolutional Neural Network and its variations of fully connected Multi-layer Perceptron.Though still preliminary; these results are encouraging and may provide a betterunderstanding about the field and directions toward future works.,Experiment@ International Conference (exp. at'17); 2017 4th,2017,1
Automatic generation of neural networks with structured Grammatical Evolution,Filipe Assunçao; Nuno Lourenço; Penousal Machado; Bernardete Ribeiro,The effectiveness of Artificial Neural Networks (ANNs) depends on a non-trivial manualcrafting of their topology and parameters. Typically; practitioners resort to a time consumingmethodology of trial-and-error to find and/or adjust the models to solve specific tasks. Tominimise this burden one might resort to algorithms for the automatic selection of the mostappropriate properties of a given ANN. A remarkable example of such methodologies isGrammar-based Genetic Programming. This work analyses and compares the use of twogrammar-based methods; Grammatical Evolution (GE) and Structured GrammaticalEvolution (SGE); to automatically design and configure ANNs. The evolved networks areused to tackle several classification datasets. Experimental results show that SGE is able toautomatically build better models than GE; and that are competitive with the state of the …,Evolutionary Computation (CEC); 2017 IEEE Congress on,2017,1
Comparación de algoritmos para detección de intrusos en entornos estacionarios y de flujo de datos,Jorge Luis Rivero Pérez; Bernardete Ribeiro; Kadir Héctor Ortiz,RESUMEN La detección de intrusos en redes de computadoras a partir del enfoque deaprendizaje automático presenta algunas deficiencias dadas por la propia naturaleza de laaplicación. La principal viene dada por el modesto despliegue de sistemas de detecciónbasados en algoritmos de aprendizaje bajo las restricciones impuestas por los entornosreales. En este artículo se describen y proponen tres variantes de pre procesamiento sobreel conjunto de datos KDD99; incluye selección de atributos. Luego la experimentación serealiza primeramente a partir de evaluar algoritmos representativos en entornosestacionarios sobre las variantes obtenidas a partir de pre procesar KDD99. Por último;dado que el tráfico de red es un flujo constante de datos; en el cual pueden existirvariaciones de conceptos relacionadas con las tasas de falsos positivos; unido al hecho …,Revista Universidad y Sociedad,2016,1
How Deep Can We Rely on Emotion Recognition,Ana Laranjeira; Xavier Frazão; André Pimentel; Bernardete Ribeiro,Abstract The emerging success of digital social media has had an impact on several fieldsranging from science to economy and business. Therefore; there is an invested interest inemotion detection and recognition technology from facial expressions; in order to increasetheir market competitiveness. This area still presents many challenges; namely the difficultyin achieving real-time facial recognition. Herein we tackle this problem by crossing methodstargeting both static images and active images. In this work; we explore the recenttechnological breakthroughs in deep learning and develop a system based on automaticrecognition of human face expressions using Convolutional Neural Networks (CNN). Weuse the Cohn-Kanade Extended (CKP) dataset for testing our proposed CNN model alongwith an augmented version; which demonstrated effectiveness in seven basic …,Iberoamerican Congress on Pattern Recognition,2016,1
Attribute learning for network intrusion detection,Jorge Luis Rivero Pérez; Bernardete Ribeiro,Abstract Network intrusion detection is one of the most visible uses for Big Data analytics.One of the main problems in this application is the constant rise of new attacks. Thisscenario; characterized by the fact that not enough labeled examples are available for thenew classes of attacks is hardly addressed by traditional machine learning approaches.New findings on the capabilities of Zero-Shot learning (ZSL) approach makes it aninteresting solution for this problem because it has the ability to classify instances of unseenclasses. ZSL has inherently two stages: the attribute learning and the inference stage. In thispaper we propose a new algorithm for the attribute learning stage of ZSL. The idea is tolearn new values for the attributes based on decision trees (DT). Our results show that basedon the rules extracted from the DT a better distribution for the attribute values can be …,INNS Conference on Big Data,2016,1
Multiclass Ensemble of One-against-all SVM Classifiers,Catarina Silva; Bernardete Ribeiro,Abstract Ensembles of classifiers have recently received a resounding interest due to theirsuccessful application in different scenarios. In this paper; our main focus is on usingensembles of one-against-all classifiers in multiclass problems. Current approaches inmulticlass problems are often focused in dividing the problem but seldom focus oncooperating strategies between classifiers. We propose a framework based on SupportVector Machines (SVM) one-against-all baseline ensemble classifiers that includes aMulticlass Ensemble Function (MEF) to heuristically incorporate both the predictions ofindividual classifiers as well as the confidence margin associated with those predictions todetermine the final ensemble output. The results achieved with the renown Iris and Winedatasets show the performance improvement achieved by the proposed multiclass …,International Symposium on Neural Networks,2016,1
Towards tangible benefits of corporate failure prediction with business sector: A comparative study,Ning Chen; An Chen; Bernardete Ribeiro,Abstract It is well known that bankruptcy patterns are different across the industries; andconsequently most studies focused on a given business sector or sub-sector. However; insome real world applications the bankruptcy patterns are likely constructed based on thecompanies of various business sectors (eg construction; real estate; education; retail;transportation) due to the lack of default samples. This paper presents a comparative studyusing different classifiers and performance metrics to examine the role of the business sectorin corporate failure prediction based on the data from multiple business sectors. Theexperiments use a real-world French database of corporate companies diversified indifferent industries. The bankruptcy of companies is forecasted using 10 prediction modelsand evaluated by 8 performance metrics. The experimental results are analyzed by …,Intelligent Decision Technologies,2016,1
Bone involvement by Sporothrix schenckii in an immunocompetent child,Bruno Niemeyer de Freitas Ribeiro; Renato Niemeyer de Freitas Ribeiro; Claudia Renata Rezende Penna; Ana C Frota,Abstract Sporotrichosis in children is rare; and its osteoarticular form is very unusual.Disseminated forms are described mostly in immunocompromised patients. We report acase of a 5-year-old immunocompetent boy with multiple suppurated cutaneous lesions thatprogressed to polyarthritis of the hands and feet. Radiographic imaging demonstratedmultifocal lytic lesions. Sporotrichosis was diagnosed through biopsy and culture. Thisarticle describes the radiographic appearance of a rare manifestation of this disease. Inareas of high prevalence; the diagnosis of sporotrichosis should be taken into account; evenin immunocompetent patients; when dactylitis with lytic lesions is present.,Pediatric radiology,2015,1
Non-Negative Matrix Factorization (NMF),Noel Lopes; Bernardete Ribeiro,Abstract In this chapter we introduce the Non-Negative Matrix Factorization (NMF); which isan unsupervised algorithm that projects data into lower dimensional spaces; effectivelyreducing the number of features while retaining the basis information necessary toreconstruct the original data. Basically; it decomposes a matrix; containing only non-negative coefficients; into the product of two other non-negative matrices with reduced ranks.Since negative coefficients are not allowed; the original data is reconstructed throughadditive combinations of the parts-based factorized matrix representation. Following; wepresent the multiplicative and the additive GPU implementations of the NMF algorithm for theEuclidean distance as well as for the divergence cost function. In addition; a new semi-supervised approach that reduces the computational cost while improving the accuracy of …,*,2015,1
Support Vector Machines (SVMs),Noel Lopes; Bernardete Ribeiro,Abstract This Chapter details a class of learning mechanisms known as the Support VectorMachines (SVMs). We start by giving the machine learning framework; define and introducethe concepts of linear classifiers; and describe formally the SVMs as large margin classifiers.We focus on the convex optimization problem and in particular we deal with the SequentialMinimal Optimization (SMO) which is crucial to proceed to implement the algorithm. Finallywe detail issues of the SVMs implementation. Regarding the latter; several aspects relatedto CPU and GPU implementation are surveyed. Our aim is two fold: first; we implement themulti-thread CPU version; test it in benchmark data sets; then we proceed with the GPUversion. We intend to give a clear understanding of specific aspects related to theimplementation of basic SVM machines in a many-core perspective. Further …,*,2015,1
Adaptive many-core machines,Noel Lopes; Bernardete Ribeiro,Abstract The previous chapters presented a number of novel Machine Learning algorithmsand high-performance implementations of existing ones with data scalability in mind. Therationale is to increase their practical applicability to largescale ML problems. The commonunderlying thread has been the recent progress in usability; cost effectiveness and diversityof parallel computing platforms; specifically; Graphics Processing Units (GPUs); tailored for abroad set of data analysis and machine learning tasks. In this chapter; we provide the mainoutcomes of the book through a unified view of the rationale behind adaptive many-coremachines enlightened by the practical approach taken in this volume. The awareness thatbig data has sparked large-scale machine learning has put forward a new understandingand thinking into Big Learning. The machine learning community has to take on these …,*,2015,1
Incremental Hypersphere Classifier (IHC),Noel Lopes; Bernardete Ribeiro,Abstract In the previous chapters we have presented batch learning algorithms; which aredesigned under the assumptions that data is static and its volume is small (andmanageable). Faced with a myriad of high-throughput data usually presenting uncertainty;high dimensionality and large complexity; the batch methods are no longer useful. Using adifferent approach; incremental algorithms are designed to rapidly update their models toincorporate new information on a sampleby-sample basis. In this chapter we present a novelincremental instance-based learning algorithm; which presents good properties in terms ofmulti-class support; complexity; scalability and interpretability. The Incremental HypersphereClassifier (IHC) is tested in well-known benchmarks yielding good classificationperformance results. Additionally; it can be used as an instance selection method since it …,*,2015,1
Hashing for financial credit risk analysis,Bernardete Ribeiro; Ning Chen,Abstract Hashing techniques have recently become the trend for accessing complex contentover large data sets. With the overwhelming financial data produced today; binaryembeddings are efficient tools of indexing big datasets for financial credit risk analysis. Therationale is to find a good hash function such that similar data points in Euclidean spacepreserve their similarities in the Hamming space for fast data retrieval. In this paper; first weuse a semi-supervised hashing method to take into account the pairwise supervisedinformation for constructing the weight adjacency graph matrix needed to learn the binarisedLaplacian EigenMap. Second; we train a generalised regression neural network (GRNN) tolearn the k-bits hash code. Third; the k-bits code for the test data is efficiently found in therecall phase. The results of hashing financial data show the applicability and advantages …,International Conference on Neural Information Processing,2014,1
Exploring the performance of non-negative multi-way factorization for household electrical seasonal consumption disaggregation,Marisa Figueiredo; Bernardete Ribeiro; Ana Maria de Almeida,The performance of household electrical seasonal consumption disaggregation is exploredin this paper. Firstly; given a tensor composed by the data for the several devices in thehouse; non-negative tensor factorization is performed in order to extract the most relevantcomponents. Secondly; the outcome is embedded in the test step; where only the whole-home measured consumption is available. Lastly; the disaggregated data by device isobtained by factorizing the associated matrix regarding the learned model. This sourceseparation approach thus requires prior data; needed to learn the source models.Nevertheless; the consumer behaviors vary along time particularly from season to season;and hence also the electrical consumption. Consequently; the assessment of performance atlong-term and across different times of the year is essential. We evaluate the performance …,Neural Networks (IJCNN); 2014 International Joint Conference on,2014,1
Development of support vector machines (svms) in graphics processing units for pattern recognition,Joao Carlos Ferreira Gonçalves; Bernardete Ribeiro; Noel Lopes,*,*,2012,1
Space Time Frequency (STF) code tensor for the characterization of the epileptic preictal stage,Bruno Direito; César Teixeira; Bernardete Ribeiro; Miguel Castelo-Branco; António Dourado,We evaluate the ability of multiway models to characterize the epileptic preictal period. Theunderstanding of the characteristics of the period prior to the seizure onset is a decisive steptowards the development of seizure prediction frameworks. Multiway models of EEGsegments already demonstrated that hidden structures may be unveiled using tensordecomposition techniques. We propose a novel approach using a multiway model; ParallelFactor Analysis (PARAFAC); to identify spatial; temporal and spectral signatures of thepreictal period. The results obtained; from a dataset of 4 patients; with a total of 30 seizures;suggest that a common structure may be involved in seizure generation. Furthermore; thespatial signature may be related to the ictal onset region and that determined frequency sub-bands may be more relevant in preictal stages.,Engineering in Medicine and Biology Society (EMBC); 2012 Annual International Conference of the IEEE,2012,1
Handling missing values via a neural selective input model,Noel Lopes; Bernardete Ribeiro,Abstract Missing data represent an ubiquitous problem with numerous and diverse causes.Handling Missing Values (MVs) properly is a crucial issue; in particular in Machine Learning(ML) and pattern recognition. To date; the only option available for standard NeuralNetworks (NNs) to handle this problem has been to rely on pre-processing techniques suchas imputation for estimating the missing data values; which limited considerably the scope oftheir application. To circumvent this limitation we propose a Neural Selective Input Model(NSIM) that accommodates different transparent and bound models; while providing supportfor NNs to handle MVs directly. By embedding the mechanisms to support MVs we canobtain better models that reflect the uncertainty caused by unknown values. Experiments onseveral UCI datasets with both different distributions and proportion of MVs show that the …,Neural Network World,2012,1
Towards a hybrid NMF-based neural approach for face recognition on GPUs,Noel Lopes; Bernardete Ribeiro,We present a hybrid face recognition approach that relies on a high-performance graphicsprocessing unit (GPU) implementation of the non-negative matrix factorisation (NMF) andmultiple back-propagation (MBP) algorithms. NMF is a non-linear unsupervised algorithmwhich reduces the data dimensionality; while preserving the information of the most relevantfeatures allowing for the reconstruction of the original data. The projection of the data onlower dimensional spaces accounts for noise reduction and enables to remove worthlessinformation. By combining the strengths of both algorithms; we are able to take advantage ofthe high generalisation potential of MBP; while upholding the parts-based representationcapabilities provided by the NMF algorithm. The proposed approach is tested on the Yaleand AT&T (ORL) facial images databases; evidencing robustness with different lighting …,International Journal of Data Mining; Modelling and Management 11,2012,1
Bankruptcy trajectory analysis on french companies using self-organizing map,Ning Chen; Bernardete Ribeiro; Armando S Vieira,Abstract As one of the major business problems; corporate bankruptcy has been extensivelystudied using a large variety of statistical and machine learning approaches. However; thetrajectory of bankruptcy behavior is seldom explored in the literature. In this paper; we useself-organizing map neural networks to analyze the changes of financial situation ofcompanies in several consecutive years through a two-step clustering process. Firstly; thebankruptcy risk is characterized by a feature map; and therefore the temporal sequence isconverted to the trajectory vector projected on the map. Afterwards; the trajectory mapclusters the trajectory vectors to a number of evolution patterns. The approach is applied to alarge database of French companies which contains the financial ratios spawning over aperiod of four years. Typical behaviors such as the deterioration and amelioration …,Portuguese Conference on Artificial Intelligence,2011,1
SVR Controller for a Biped Robot with a Human-like Gait Subjected to External Sagittal Forces,João P Ferreira; Manuel Crisóstomo; A Paulo Coimbra; Bernardete Ribeiro,This paper describes the control of a biped robot that uses an SVR (Support VectorRegression) for its balance. The control system was tested subjected to external sagittalpulling and pushing forces. Biped robots have leg link structures similar to the human'sanatomy. To be able to maintain its stability under dynamic situations such robotic systemsrequire good mechanical designs and force sensors to acquire the zero moment point(ZMP). Research in biped robotics has recently had a great surge due to the challenges ofthe subject and the media impact of famous biped robots like Honda's.(Vukobratovic; 1990)developed a mathematical model of a biped robot and its method of control. Some researchworks (Zarrugh & Radcliffe; 1979);(Nakamura et al.; 2004);(Jang et al.; 2002) have reportedthe gait of biped robots based on human kinematics data; and a very good study of …,*,2011,1
A hybrid face recognition approach using GPUMLib,Noel Lopes; Bernardete Ribeiro,Abstract We present a hybrid face recognition approach which relies on a GraphicsProcessing Unit (GPU) Machine Learning (ML) Library (GPUMLib). The library includes ahigh-performance implementation of the Non-Negative Matrix Factorization (NMF) and theMultiple Back-Propagation (MBP) algorithms. Both algorithms are combined in order toobtain a reliable face recognition classifier. The proposed approach first applies anhistogram equalization to the original face images in order to reduce the influence from thesurrounding illumination. The NMF algorithm is then applied to reduce the datadimensionality; while preserving the information of the most relevant features. The obtaineddecomposition is further used to rebuild accurate approximations of the original data (byusing additive combinations of the parts-based matrix). Finally; the MBP algorithm is used …,Iberoamerican Congress on Pattern Recognition,2010,1
OPTIMIZATION OF 99MO MEASUREMENT IN 99MTC ELUATE SAMPLES USING A SCINTILLATION DETECTION SYSTEM,Ana Letícia A Dantas; Bianca S Ribeiro; Raphael Sancho S Souza; Eder A Lucena; Bernardo M Dantas,Abstract—During elution of 99Mo-99mTc generators used in nuclear medicine; 99Mo mightbe extracted becoming a radionuclidic impurity. According to the International Atomic EnergyAgency; the activity ratio between 99Mo and 99mTc in the eluate; at the moment ofadministration to the patient; should not exceed 0.015%. The aim of this work is to optimize amethodology to determine 99Mo activity in 99mTc eluates. Efficiency curves were obtainedusing a NaI (Tl) 8 4 scintillation detector. The methodology was validated by measuring astandard solution of 99Mo. It was concluded that the technique is sensitive to detect 99Mo in99mTc eluates at levels below international limits.,Health physics,2010,1
On using an ensemble approach of AIS and SVM for text classification,Catarina Silva; Mário Antunes; Bernardete Ribeiro; Manuel Correia,Abstract—Artificial Immune Systems (AIS) and Support Vec-tor Machines (SVM) aregrounded on two radically different conceptual paradigms; each one having intrinsicdistinctive features suitable to be successfully applied in dynamic real world applications.One of such applications is the classification of textual documents where each approachindividually has proved to obtain promising results. In this paper we aim to present an hybridsystem for text classification based on the ensemble of both AIS and SVM approaches. InAIS we explore a binary classification methodology derived from an immunological modelwhich stats that for activation thresholds for T-cells activation is based on the recent historyof their iterations with the environment. Regarding the SVM we take advantage of a non-evolutionary implementation that produced remarkable results with text classification. We …,Proceedings of 5th Workshop on Applications of Computational Intelligence (WACI 2010). IEEE (Portuguese Chapter),2010,1
Object detection in robotics using morphological information,Bruno Miguel Marques Ribeiro,Uma das componentes mais importantes em sistemas de processamento de imagem é adetecção de objectos de interesse. Contudo; a detecção de objectos é um desafio. Dadauma imagem arbitrária e assumindo que se está interessado em localizar um determinadoobjecto; o grande objectivo da detecção de objectos passa por determinar se existe ou nãoqualquer objecto de interesse. Esta tese encontra-se inserida no domínio do RoboCup efoca o desenvolvimento de algoritmos para a detecção de bolas oficiais da FIFA; um objectoimportante no futebol robótico. Para atingir o objectivo principal; foram desenvolvidos trêsalgoritmos para detectar bolas de futebol com cores arbitrárias; usando informaçãomorfológica obtida através do detector de cortornos Canny e da tranformada de Hough. Emprimeiro lugar; foi desenvolvida uma abordagem onde se implementou um algoritmo …,*,2009,1
Classification of Mass Spectrometry Data-Using Manifold and Supervised Distance Metric Learning.,Qingzhong Liu; Andrew H Sung; Bernardete Ribeiro; Mengyu Qiao,*,BIOSIGNALS,2009,1
Um sistema distribuído para a automação de espaços residencias e de serviços.,Bruno Jorge Ferreira Ribeiro,Apresenta-se a arquitectura e as tecnologias utilizadas numa plataforma modular parasuportar aplicações na área da automação de edifícios e de espaços residenciais. Aproposta visa colmatar lacunas existentes nos sistemas actualmente disponíveis e assim;poder vir a potenciar o relançamento do mercado da Domótica. É proposto um sistemadistribuído com elevada flexibilidade e alta capacidade para integrar numerososdispositivos; devidamente balizados em termos funcionais através de perfis; que; emconjunto e através de ligações lógicas entre os seus data points; garantem o funcionamentodas aplicações distribuídas; assim como a total integração da informação circulante narede. Um particular destaque merece a interface humana; que foi afastada da perspectivatradicional; com elevada afinidade com o detalhe dos sistemas; para o nível dos serviços …,*,2008,1
Determinação de 99Mo em eluatos de 99mTc utilizados em serviços de medicina nuclear do Rio de Janeiro,BS Ribeiro; ALA Dantas; EA Lucena; BM Dantas,Resumo. Os radiofármacos marcados com tecnécio-99m (99mTc) são os mais utilizadosnos serviços de medicina nuclear (SMN); em diagnósticos por imagens do tipo SPECT(Single Photon Emission Computed Tomography). O 99mTc é obtido a partir da eluição degeradores Molibdênio-99/Tecnécio-99m (99Mo/99mTc). O molibdênio-99 (99Mo) podeaparecer como uma impureza radionuclídica; quando se desprende da coluna de aluminado gerador dependendo da qualidade e integridade do mesmo; gerando assim uma dosedesnecessária ao paciente; além de degradar a imagem devido aos fótons de alta energiae emissão de partículas beta. Um dos parâmetros que indica a qualidade dos eluatos é apureza radionuclídica; o MBT (molybednum breakthrough); que define a proporção entre99Mo e 99mTc nos eluatos. A concentração máxima de 99Mo estabelecido pela …,I simpósio de dosimetria interna aplicada à medicina nuclear,2008,1
Support; Relevance and Spectral Learning for Time Series,Bernardete Ribeiro,Abstract This paper proposes the Spectral Clustering Kernel Machine (SCKM) for timesseries prediction. Support Vector Machine (SVM); Relevance Vector Machine (RVM) and theSpectral Clustering Kernel Machine (SCKM) are compared in terms of performanceaccuracy for a simple time series approximation problem. The three outlined algorithmseach of which with interesting features to perform automated learning are examined;analysed and empirically tested. In case of the SVM; our tests combine also a preprocessingstage including Kohonen Maps (SOM) as well as K-means clustering. In the case of RVM wealso implemented a constructive approach based on the fast marginal likelihoodmaximization described in [14]. Prediction results in two benchmark time series have beenaddressed using various performance metrics. The results demonstrate that whereas …,International Conference on Adaptive and Natural Computing Algorithms,2007,1
Nova Abordagem para o Ensino da Robótica baseada na Modificação do RoboSapien,Pedro Dinis Gaspar; António Espírito Santo; Humberto Santos; Bruno Ribeiro,Resumo—O ensino da robótica no ensino superior integra diversos conhecimentosadquiridos durante os cursos que apresentam esta área específica nos seus conteúdosprogramáticos. Estes conhecimentos prendem-se fundamentalmente com conceitosmecânicos e eléctricos/electrónicos. Adicionalmente; a experiência prática destes conceitosé parte importante do ensino na engenharia. Porém; a sua aplicação requer variadosrecursos laboratoriais por vezes reduzidos. Com o intuito de ultrapassar esta dificuldade; eatingir os objectivos pretendidos; com a apreensão de conhecimentos na área da robótica;é apresentada uma abordagem para o seu ensino baseada na modificação do robotRoboSapien. Para o propósito em causa; esta abordagem mostrou-se uma valiosaferramenta de ensino; permitindo o reforço de vários conceitos chave relacionados com a …,Proc. of Engenharia'2007-Inovação e Desenvolvimento,2007,1
Computational intelligence in manufacturing quality control,B Ribeiro,Abstrakty EN The field of Computational Intelligence (Cl) comprises well establishedtechnologies of neural networks; fuzzy systems. evolutionary computation and otheradaptive and biologically motivated computational paradigms. Support Vector Machines(SVMs) and Kernel Methods (KM) are emerging fields among others. We look at one ofthese technigues (SVMs); in the setting of a defects detection model of automobile plasticparts within the framework of a manufacturing quality control problem.,Przegląd Elektrotechniczny,2004,1
Learning Adaptive Kernels for Model Diagnosis.,Bernardete Ribeiro,Abstract. This paper looks into the tradeoff between model complexity and predictionaccuracy using data examples from the benchmark problem of breast cancer. In particular;we take into account several crucial aspects in model construction using learning kernelclassifiers. Given its importance; a more generalized form of the basis kernel functiondefinition is then applied. Moreover; model selection is performed in terms of kernel machinehyperparameters; and results are evaluated in terms of the model development cost time.,HIS,2003,1
Mercer's Kernel Based Learning for Fault Detection.,Bernardete Ribeiro; Paulo Carvalho,*,HIS,2002,1
Support vector machines in fault tolerance control,Bernardete Ribeiro,This paper presents a new approach for quality monitoring of on‐line molded parts in thecontext of an injection molding problem using Support Vector Machines (SVMs). While themain goal in the industrial framework is to automatically calculate the setpoints; a lessimportant task is to classify plastic molded parts defects efficiently in order to assess multiplequality characteristics. The paper presents a comparison of the performance assessment ofSVMs and RBF neural networks as part quality monitoring tools by analyzing complete datapatterns. Results show that the classification model using SVMs presents slightly betterperformance than RBF neural networks mainly due to the superior generalization of theSVMs in high‐dimensional spaces. Particularly; when RBF kernels are used; the accuracy ofthe task increases thus leading to smaller error rates. Besides; the optimization method is …,AIP Conference Proceedings,2002,1
Hybrid learning multi neural architecture',L Noel; R Bernardete,*,IEEE International Joint Conference on Neural Networks,2001,1
Artificial neural network for data modelling of a plastic injection moulding machine,N Costa; B Ribeiro,*,IEEE 6th International Conference on Neural Information Processing,1999,1
RBFNN for Real-Time Process Identification and Control with Selective Forgetting,C Pereira; J Henriques; B Ribeiro; A Dourado,Abstract This work is concerned with the problem of the real-time identification and control ofdynamic non-linear systems using a neural network approach. The chosen model was theGaussian Radial Basis Function Neural Network (RBFNN) type; due to its universalapproximation property and also to the fact that the parameters are linearly related to theoutputs allowing linear learning algorithms. A hybrid learning technique is developed; usingan adaptive learning rate with process monitoring; and taking advantage of the localityproperty of this type of networks; we apply a selective forgetting algorithm. This on-linelearning is used both for identification and control. A novel technique is proposed for the on-line adaptive control. The potential of the proposed method is demonstrated by a simulationexample applied to a theoretical model and to a real laboratory process.,Proceedings of the 2nd Portuguese Conference on Automatic Control-Controlo96; Porto,1996,1
Kolmogorov’s Theorem: From Algebraic Equations and Nomography to Neural Networks,Alexander Kovačec; Bernardete Ribeiro,Abstract We trace the developments around Hilbert's thirteenth problem back to questionsconcerning algebraic equations. Its solution; namely Kolmogorov's superposition theorem of1956; is stated in an elaborate form and its relation with neural nets is explained. A detailedproof allows to initiate discussions concerning implementability. We address individualsinterested to form an opinion about the hotly debated applicability of the superpositiontheorem but also the philosophically inclined readers that want to learn the background of amathematical problem with an eventful history; and who; by studying its proof will get asense of the difference between construction and existence in mathematics.,*,1993,1
Adaptive and Natural Computing Algorithms; Part 2,A Dzielinski Beliczynski; M Iwanowski; B Ribeiro,*,Lecture Notes in Computer Science,*,1
Dynamic modelling and simulation of a pulp mill lime kiln,B Ribeiro; A Dourado,*,Modelling Identification and Control,*,1
Sparse bayesian classifiers: Bankruptcy-predictors of choice,B Ribeiro; A Vieira; J Neves,*,World Congress On Computational Intelligence; IEEE Int Joint Conf on Neural Networks (IJCNN’06),*,1
Example of finding the architecture of a BPNN for a pulp and paper engineering application looking at the geometry of a given classification task,B Ribeiro; A Kovacec; A Dourado,*,Int Conf on Engineering Applications of Neural Networks (EANN’95),*,1
Comparison of gene selection and machine learning for tumor classification,Qingzhong Liu; Andrew H Sung; Bernardete M Ribeiro,Abstract. Class prediction and feature selection are two learning tasks that are strictly pairedin the search of molecular profiles from microarray data. In this paper; we apply the recursivegene selection proposed in our previous paper to six types of micaroarray gene expressiondata for tumor classification. In comparison with other two well-known gene selections; SVM-RFE (Support Vector Machine Recursive Feature Elimination) and T-test; our methodoutperforms best. The kernel type and kernel parameters are critical to the classificationperformances for the kernel classifiers. Our experiments indicate that RBF kernel classifiersare pretty good under low feature dimensions; their performances increase initially and thendecrease as the feature dimension increases.,3rd Int Conf on Informatics in Control; Automation and Robotics; Workshop on Signal Processing and Classification,*,1
DENSER: Deep Evolutionary Network Structured Representation,Filipe Assunção; Nuno Lourenço; Penousal Machado; Bernardete Ribeiro,Abstract: Deep Evolutionary Network Structured Representation (DENSER) is a novelapproach to automatically design Artificial Neural Networks (ANNs) using EvolutionaryComputation (EC). The algorithm not only searches for the best network topology (eg;number of layers; type of layers); but also tunes hyper-parameters; such as; learningparameters or data augmentation parameters. The automatic design is achieved using arepresentation with two distinct levels; where the outer level encodes the general structure ofthe network; ie; the sequence of layers; and the inner level encodes the parametersassociated with each layer. The allowed layers and hyper-parameter value ranges aredefined by means of a human-readable Context-Free Grammar. DENSER was used toevolve ANNs for two widely used image classification benchmarks obtaining an average …,arXiv preprint arXiv:1801.01563,2018,*
Epileptic Seizure Prediction with Stacked Auto-encoders: Lessons from the Evaluation on a Large and Collaborative Database,R Barata; B Ribeiro; A Dourado; CA Teixeira,Abstract The seizure prediction performance of algorithms based in stacked auto-encodersdeep-learning technique has been evaluated. The study is established on long-termelectroencephalography (EEG) recordings of 103 patients suffering from drug-resistantepilepsy. The proposed patient-specific methodology consists of feature extraction;classification by machine learning techniques; post-classification alarm generation; andperformance evaluation using long-term recordings in a quasi-prospective way. Multiplequantitative features were extracted from EEG recordings. The classifiers were trained todiscriminate preictal and non-preictal states. The first part of the feature time series wasconsidered for training; a second part for selection of the “optimal” predictors of each patient;while the remaining data was used for prospective out-of-sample validation. The …,*,2018,*
Active Learning Metamodels for Transportation Simulators,Francisco Antunes; Bernardete Ribeiro; Francisco Pereira; Rui Gomes,Abstract Simulation modeling is a well-known and recurrent approach to study theperformance of urban systems. Taking into account the recent and continuoustransformations within increasingly complex and multidimensional cities; the use ofsimulation tools is; in many cases; the only feasible and reliable approach to study suchdynamic systems. However; simulation models can become very time-consuming whendetailed input-space exploration is needed. To tackle this problem; simulation metamodelsare often used to approximate the simulator results. In this paper; we propose an activelearning algorithm based on the Gaussian Processes (GP) framework that gathers the mostinformative data points in batches; according to both their variances and to the relativedistance between them. This allows us to explore the simulator input space with fewer …,*,2017,*
A Grassmannian Approach to Zero-Shot Learning for Network Intrusion Detection,Jorge Rivero; Bernardete Ribeiro; Ning Chen; Fátima Silva Leite,Abstract One of the main problems in Network Intrusion Detection comes from constant riseof new attacks; so that not enough labeled examples are available for the new classes ofattacks. Traditional Machine Learning approaches hardly address such problem. This canbe overcome with Zero-Shot Learning; a new approach in the field of Computer Vision;which can be described in two stages: the Attribute Learning and the Inference Stage. Thegoal of this paper is to propose a new Inference Stage algorithm for Network IntrusionDetection. In order to attain this objective; we firstly put forward an experimental setup for theevaluation of the Zero-Shot Learning in Network Intrusion Detection related tasks. Secondly;a decision tree based algorithm is applied to extract rules for generating the attributes in theAL stage. Finally; using a representation of a Zero-Shot Class as a point in the …,International Conference on Neural Information Processing,2017,*
Probabilistic modeling and visualization for bankruptcy prediction,Francisco Antunes; Bernardete Ribeiro; Francisco Pereira,Abstract In accounting and finance domains; bankruptcy prediction is of great utility for all ofthe economic stakeholders. The challenge of accurate assessment of business failureprediction; specially under scenarios of financial crisis; is known to be complicated. Althoughthere have been many successful studies on bankruptcy detection; seldom probabilisticapproaches were carried out. In this paper we assume a probabilistic point-of-view byapplying Gaussian processes (GP) in the context of bankruptcy prediction; comparing itagainst the support vector machines (SVM) and the logistic regression (LR). Using real-world bankruptcy data; an in-depth analysis is conducted showing that; in addition to aprobabilistic interpretation; the GP can effectively improve the bankruptcy predictionperformance with high accuracy when compared to the other approaches. We …,Applied Soft Computing,2017,*
Adaptive learning for dynamic environments: A comparative approach,Joana Costa; Catarina Silva; Mário Antunes; Bernardete Ribeiro,Abstract Nowadays most learning problems demand adaptive solutions. Current challengesinclude temporal data streams; drift and non-stationary scenarios; often with text data;whether in social networks or in business systems. Various efforts have been pursued inmachine learning settings to learn in such environments; specially because of their non-trivial nature; since changes occur between the distribution data used to define the modeland the current environment. In this work we present the Drift Adaptive Retain Knowledge(DARK) framework to tackle adaptive learning in dynamic environments based on recentand retained knowledge. DARK handles an ensemble of multiple Support Vector Machine(SVM) models that are dynamically weighted and have distinct training window sizes. Acomparative study with benchmark solutions in the field; namely the Learn++. NSE …,Engineering Applications of Artificial Intelligence,2017,*
Low-power smart sensing in energy and water systems integration,António Espírito-Santo; Pedro Serra; Sérgio Albuquerque; Bruno Ribeiro; Fernando Santos; José Páscoa,The water energy nexus is a multidisciplinary topic that requires the interaction of differentareas of knowledge; with direct impact on the economy; society and ecosystems. Smartsensing concept allows us to develop new ways of monitoring and; consequently; contributeto simultaneously optimize the efficiency of energy and water processes. The integration ofenergy and water management systems requires the coverage of a wide geographic area.Therefore; the interconnection of smart sensors; over a wireless network; is a requirementthat can be assured with the adoption of standards such as the ISO/IEC/IEEE21451. Smartsensors operation and effectiveness depends on the availability of energy. Harvestingenergy in water systems allows to power smart sensors avoiding batteries. Microbial fuelcells allow the conversion of organic material found in wastewater into electrical energy …,Measurement and Networking (M&N); 2017 IEEE International Workshop on,2017,*
Adaptive Supervisory Framework for Cyber-Physical Systems,Joaquim Leitao; Paulo Gil; Bernardete Ribeiro; Alberto Cardoso,Abstract—Cyber-Physical Systems (CPS) result from the aggregation of the cyber andphysical worlds into a single spatially distributed macrosystem; relying on sensor andactuator networks to perform its optimised management. CPS must be capable of reacting toperceived and inferred knowledge about the systems they coordinate; demonstrating context-aware and selfadaptive characteristics. Popular solutions proposed in the literature areinspired by feedback-loop control theory; according to which a repeated analysis of the stateof the managed environment is performed; followed by a review and adjustment ofoperational objectives and constraints. Despite current advances CPS still face importantchallenges; among which the integration of heterogeneous entities (where human presencemust also be accounted for); high-order predictive models; lack of a holistic design …,*,2017,*
Performance Metrics for Model Fusion in Twitter Data Drifts,Joana Costa; Catarina Silva; Mário Antunes; Bernardete Ribeiro,Abstract Ensemble approaches have revealed remarkable abilities to tackle differentlearning challenges; namely in dynamic scenarios with concept drift; eg in social networks;as Twitter. Several efforts have been engaged in defining strategies to combine the modelsthat constitute an ensemble. In this work; we investigate the effect of using different metricsfor combining ensembles' models; specifically performance-based metrics. We propose fiveperformance combining metrics; having in mind that we may take advantage of diversity inclassifiers; as their individual performance takes a leading role in defining their contributionto the ensemble. Experimental results on a Twitter dataset; artificially timestamped; suggestthat using performance metrics to combine the models that constitute an ensemble canintroduce relevant improvements in the overall ensemble performance.,Iberian Conference on Pattern Recognition and Image Analysis,2017,*
Improve credit scoring using transfer of learned knowledge from self-organizing map,Ali AghaeiRad; Ning Chen; Bernardete Ribeiro,Abstract Credit scoring is important for credit risk evaluation and monitoring in theaccounting and finance domain. For financial institutions; the ability to predict the businessfailure is crucial; as incorrect decisions have direct financial consequences. A variety ofpattern recognition techniques including neural networks; decision trees; and support vectormachines have been applied to predict whether the borrowers should be considered a goodor bad credit risk. This paper presents a hybrid approach to building the credit scoring modeland illustrates how the unsupervised learning based on self-organizing map (SOM) canimprove the discriminant capability of feedforward neural network (FNN). Within thehybridization scheme; the knowledge (ie; prototypes of clusters) found by SOM is transferredas input to the subsequent FNN model. Four real-world data sets are used in the …,Neural Computing and Applications,2017,*
Finding the Critical Sampling of Big Datasets,José Silva; Bernardete Ribeiro; Andrew H Sung,Abstract Big Data allied to the Internet of Things nowadays provides a powerful resource thatvarious organizations are increasingly exploiting for applications ranging from decisionsupport; predictive and prescriptive analytics; to knowledge extraction and intelligencediscovery. In analytics and data mining processes; it is usually desirable to have as muchdata as possible; though it is often more important that the data is of high quality thereby twoof the most important problems are raised when handling large datasets: sampling andfeature selection. This paper addresses the sampling problem and presents a heuristicmethod to find the" critical sampling" of big datasets. The concept of the critical sampling sizeof a dataset D is that there is a minimum number of samples of D that is required for a givendata analytic task to achieve satisfactory performance. The problem is very important in …,Proceedings of the Computing Frontiers Conference,2017,*
Epileptic Seizure prediction based on Stacked Regularized Autoencoders: A Deep Machine Learning approach,Ricardo Barata; Bernardete Ribeiro; António Dourado; César Teixeira,ABSTRACT: Purpose: In this study; we test whether an invasive Electroencephalogram(iEEG)-based seizure pre-diction approach; based on regularized stacked auto-encoders; isable to achieve prediction performances above chance level. With this deepleaningalgorithm implementation we expect to overcome the adversities faced by classic shallowclassifiers. Data & Methods: Nineteen patients with invasive recordings were randomlyselected from the EPILEP-SIAE database [1]. Twenty-two univariate features were extractedfor each patient; and a neural network composed of four regularized autoencoders was usedas classifier. The first three seizures were considered for training; the fourth and fifth seizureswere used to optimize and select the best model. The remaining data containing the lastseizures were used for out-of-sample testing. Four different durations of the seizure …,Proceedings Book,2017,*
A Comparison of Algorithms for Intrusion Detection on Batch and Data Stream Environments,Jorge Luis Rivero Pérez; Bernardete Ribeiro; Kadir Hector Ortiz,Abstract: Intruders detection in computer networks has some deficiencies from machinelearning approach; given by the nature of the application. The principal problem is themodest display of detection systems based on learning algorithms under the constraintsimposed by real environments. This article focuses on the machine learning approach fornetwork intrusion detection in batch and data stream environments. First; we propose anddescribe three variants of KDD99 dataset preprocessing including attribute selection.Secondly; a thoroughly experimentation is performed from evaluating and comparingrepresentative batch learning algorithms on the variants obtained from KDD99 preprocessing. Finally; since network traffic is a constant data stream; which can presentconcept drifting with high rate of false positive; along with the fact that there are not many …,arXiv preprint arXiv:1701.00893,2017,*
Deep learning in digital marketing: brand detection and emotion recognition,Bernardete Ribeiro; Gonçalo Oliveira; Ana Laranjeira; Joel P Arrais,Deep learning has gained major popularity in automated feature extraction from images;audio and text. We present two case studies where deep learning can have a key impact.The first case study consists of a graphic logo detection based on a fast region-basedconvolutional networks (FRCN). This method tackles the issue of the logo different size andpositioning by looking for scale invariant regions. This avoids a full image search whileimproving the overall object detection. Furthermore; instead of building a convolutionalneural networks (CNN) from scratch; transfer learning and data augmentation techniqueswere applied excelling previous approaches. The second case study consists of a robustfacial emotions recognition based on an improved version of the classic CNN-LeNet-5.Despite the net simplicity; it was found to be better suited for the system constraints; such …,International Journal of Machine Intelligence and Sensory Signal Processing,2017,*
Financial credit risk assessment via learning-based hashing,Bernardete Ribeiro; Ning Chen,Abstract With the increasing amount of financial data produced today; the problem of findingthe k-nearest neighbors to the query point in high-dimensional space is itself of importanceto access the financial credit risk. Binary embeddings are efficient tools of indexing bigdatasets for financial credit risk analysis. The idea is to find a good hash function such thatsimilar data points in Euclidean space preserve their similarities in the Hamming space forfast data retrieval. By exploring out-of-sample extension to test data it is possible to set fortha go-forward strategy to establish a fast retrieval model of companies' status therebyrendering the stakeholders' evaluation task very efficiently. First; we use semi-supervisedlearning-based hashing to take into account the pairwise information for constructing theweight adjacency graph matrix needed or building the binarised Laplacian EigenMap …,Intelligent Decision Technologies,2017,*
Trading off Distance Metrics vs Accuracy in Incremental Learning Algorithms,Noel Lopes; Bernardete Ribeiro,Abstract With the growth and development of data; the empirical evidence supporting a linkbetween the distance metrics that are used in the instance-based algorithms andgeneralization has been mounting. In this paper; we look at distinct similarity measures tostudy its impact on the performance accuracy of incremental instance-based algorithms inpattern recognition problems. An in-depth analysis of the results of the proposed study for avariety of classification tasks (binary and multi-way) from various different domains shineslight on the trade off between the distance metrics and yielded accuracy.,Iberoamerican Congress on Pattern Recognition,2016,*
Wireless indoor low power tracking system for elderly people assistance in an urban environment,G Di Simone; Antonio Pietrosanto; A Espirito-Santo; B Ribeiro; Vincenzo Paciello,Smart cities and smart homes are driving economic growth and improving the quality ofpeople's life by enabling local development and harnessing technologies; especially theones leading to smart outcomes and connectivity. Application of smart solutions will enablehuman living environments to use technology; information and data to improveinfrastructures and services in the behalf of human beings. The welfare of elderly peopleliving alone; at their homes; or; in rest houses; can significantly be improved with theintroduction of these smart solutions. Wireless indoor tracking of elderly people is animportant feature together with the DLMS/COSEM protocol. Above all using low powerdevices to assist and monitoring them. The paper highlights implementation in the realworld; proposing a method that can be suited in a large range of cases thanks to the …,e-Health Networking; Applications and Services (Healthcom); 2016 IEEE 18th International Conference on,2016,*
A COMPARISON OF ALGORITHMS FOR INTRUDER DETECTION ON BATCH AND DATA STREAM ENVIRONMENTS,Jorge Luis Rivero Perez; Bernardete Ribeiro; Kadir Hector Ortiz,*,REVISTA UNIVERSIDAD Y SOCIEDAD,2016,*
Rosai-Dorfman disease affecting the nasal cavities and paranasal sinuses,Bruno Niemeyer de Freitas Ribeiro; Edson Marchiori,Radiol Bras. 2016 Jul/Ago; 49 (4): 267–276 276 lymphadenopathy (6–11); withspontaneous resolution in approximately half of all cases (7). The disease has a slightpredilection for males and primarily affects children; adolescents; and young adults; 80% ofcases occurring in individuals under 20 years of age (6). Extranodal involvement occurs in30–40% of al cases (6; 8; 9); being most common in immunocompromised individuals andpreferentially affecting the skin; respiratory tract; reticuloendothelial system; genitourinarytract; or bones (6; 8; 9). Although uncommon; enlargement of the mediastinal; hilar; axillary;and inguinal lymph nodes can occur. The etiology of Rosai-Dorfman disease is unclear;although it could be related to changes in the immune response or to infections caused byagents such as varicella-zoster virus and other herpes viruses; as well as Epstein-Barr …,Radiologia brasileira,2016,*
Mahalanobis distance metric learning algorithm for instance-based data stream classification,Jorge Luis Rivero Perez; Bernardete Ribeiro; Carlos Morell Perez,With the massive data challenges nowadays and the rapid growing of technology; streammining has recently received considerable attention. To address the large number ofscenarios in which this phenomenon manifests itself suitable tools are required in variousresearch fields. Instance-based data stream algorithms generally employ the Euclideandistance for the classification task underlying this problem. A novel way to look into this issueis to take advantage of a more flexible metric due to the increased requirements imposed bythe data stream scenario. In this paper we present a new algorithm that learns aMahalanobis metric using similarity and dissimilarity constraints in an online manner. Thisapproach hybridizes a Mahalanobis distance metric learning algorithm and a k-NN datastream classification algorithm with concept drift detection. First; some basic aspects of …,Neural Networks (IJCNN); 2016 International Joint Conference on,2016,*
Prevalence; risk factors and prognostic impact of bleeding complications in patients in cardiogenic shock in intensive care unit,Tatiana T Duarte; S Goncalves; B Ribeiro; G Domingos; I Goncalves; R Ribeiro; F Seixo; R Caria,Read 'Prevalence; risk factors and prognostic impact of bleeding complications in patientsin cardiogenic shock in intensive care unit' on Ovid Insights.,European Journal of Heart Failure,2016,*
Cognitive radio networks (CRNs) are networks of nodes equipped with cognitive radios that can optimize performance by adapting to network conditions. Although v...,Anandkumar Prakasam; Nickolas Savarimuthu; Ning Chen; Bernardete Ribeiro; An Chen,The application of metaheuristic algorithms to combinatorial optimization problems is on therise and is growing rapidly now than ever before. In this paper the historical context and theconducive environment that accelerated this particular trend of inspiring analogies ormetaphors from various natural phenomena are analysed. We have implemented the AntSystem Model and the other variants of ACO...,Artificial Intelligence Review,2016,*
Learning the hash code with generalised regression neural networks for handwritten signature biometric data retrieval,Bernardete Ribeiro; Noel Lopes; Catarina Silva,Handwritten signature recognition is one important component of biometric authentication.This is a central process in a broad range of areas requiring personal identification; such assecurity; legal contracts and bank transactions. Extensive efforts have been put into theresearch towards the verification of handwritten signatures; which contain biometricinformation. Although many successful methods have been used; they often disregard thesize of databases; which can be very large; posing scalability problems to their application inreal-world scenarios. To overcome this problem; in this paper; we use binary embeddings ofhigh-dimensional data which is an efficient tool for indexing big datasets of biometricimages. The rationale is to find a good hash function such that similar data points inEuclidean space preserve their similarities in the resulting Hamming space for fast data …,Neural Networks (IJCNN); 2015 International Joint Conference on,2015,*
A Structural Pattern Mining Approach for Credit Risk Assessment,Bernardete Ribeiro; Ning Chen; Alexander Kovačec,Abstract In recent years graph mining took a valuable step towards harnessing the problemof efficient discovery of substructures in complex input data that do not fit into the usual datamining models. A graph is a general and powerful data representation formalism; whichfound widespread application in many scientific fields. Finding subgraphs capable ofcompressing data by abstracting instances of the substructures and identifying interestingpatterns is thus crucial. When it comes to financial settings; data is very complex and inparticular when risk factors relationships are not taken into account it seriously affects thegoodness of predictions. In this paper; we posit that risk analysis can be leveraged ifstructure can be taken into account by discovering financial motifs in the input graphs. Weuse gBoost which learns from graph data using a mathematical linear programming …,International Conference on Hybrid Artificial Intelligence Systems,2015,*
Consensus-based Approach for Keyword Extraction from Urban Events Collections,Ana Oliveira Alves; Bernardete Ribeiro,Automatic keyword extraction (AKE) from textual sources took a valuable step towardsharnessing the problem of efficient scanning of large document collections. Particularly inthe context of urban mobility; where the most relevant events in the city are advertised on-line; it becomes difficult to know exactly what is happening in a place./nIn this paper wetackle this problem by extracting a set of keywords from different kinds of textual sources;focusing on the urban events context. We propose an ensemble of automatic keywordextraction systems KEA (Key-phrase Extraction Algorithm) and KUSCO (KnowledgeUnsupervised Search for instantiating Concepts on lightweight Ontologies) and ConditionalRandom Fields (CRF).,*,2015,*
GPUMLib Framework: Using the GPU to Empower Machine Learning Research,Noel Lopes; Bernardete Ribeiro,Resumo: The amount of information being produced by humans is continuously increasing;to the point that we are generating; capturing and sharing an unprecedented volume of datafrom which useful and valuable information can be extracted. However; obtaining theinformation represents only a fraction of the time and effort needed to analyze it. Hence; weneed scalable fast Machine Learning (ML) tools that can cope with large amounts of data ina realistic time frame. As problems become increasingly challenging and demanding; theybecome; in many cases; intractable by traditional CPU architectures. Accordingly; novel real-world ML applications will most likely demand tools that take advantage of new high-throughput parallel architectures. In this context; today GPUs (Graphics Processing Units)can be used as inexpensive highly-parallel programmable devices; providing remarkable …,*,2015,*
Generating datasets with drift,B. Costa; J. and Silva; C. and Antunes; M. and Ribeiro,*,Portuguese Conference on Pattern Recognition (RecPad); Faro; Portugal,2015,*
Glucose Level Prediction in Diabetic Patients,A. Frutuoso; D. and Ribeiro; B. and Pimentel,*,Portuguese Conference on Pattern Recognition - RecPad 2015; Faro; Portugal,2015,*
SABADO - SmArt BrAnd DetectiOn,X. Oliveira; G. and Ribeiro; B. and Pimentel; A. and Frazão,*,Portuguese Conference on Pattern Recognition; RecPad 2015; Faro; Portugal,2015,*
The Critical Feature Dimension and Critical Sampling Problems.,Bernardete Ribeiro; Andrew H Sung; Divya Suryakumar; Ram B Basnet,Abstract: Efficacious data mining methods are critical for knowledge discovery in variousapplications in the era of big data. Two issues of immediate concern in big data analytictasks are how to select a critical subset of features and how to select a critical subset of datapoints for sampling. This position paper presents ongoing research by the authors thatsuggests: 1. the critical feature dimension problem is theoretically intractable; but simpleheuristic methods may well be sufficient for practical purposes; 2. there are big data analyticproblems where the success of data mining depends more on the critical feature dimensionthan the specific features selected; thus a random selection of the features based on thedataset's critical feature dimension will prove sufficient; and 3. The problem of criticalsampling has the same intractable complexity as critical feature dimension; but again …,ICPRAM (1),2015,*
Aggregated local models via subspace clustering,Bernardete Ribeiro; Ning Chen,Abstract Decision models take a valuable step towards harnessing the problem of efficientrisk assessment in social and technological environments. In particular; in bankruptcyprediction models it becomes difficult to know exactly what happens when so many financialand external variables are at stake. To partly tackle this problem; a new approachencompassing aggregated local models obtained via subspace clustering and intelligentdecision technologies is proposed in this paper. The approach first takes co-clusters of firmsand financial ratios found by a biclustering algorithm; second the weight affinity graph matrixembedding data points is built for learning the subspace clustering model; finally; a largemargin binary classifier over the regularized model is used to make predictions on financialreal data. We empirically show that our model (by combining biclustering with subspace …,Intelligent Decision Technologies,2015,*
Dimensionality Reduction Using Graph Weighted Subspace Learning for Bankruptcy Prediction,Bernardete Ribeiro; Ning Chen,Abstract Bankruptcy prediction is an extremely actual and important topic in the world. In thiscomplex problem; dimensionality reduction becomes important easing both tasks ofvisualization and classification. Despite the different motivations; these algorithms can becast in a graph embedding framework. In this paper we address weighted graph subspacelearning methods for dimensionality reduction of bankruptcy data. The rationale behind re-embedding the data in a lower dimensional space that would be better filled is twofold: to getthe most compact representation (visualization) and to make subsequent processing of datamore easy (classification). To achieve this; two graph weighted subspace learning modelsare investigated; namely graph regularized non-negative matrix factorization (GNMF) andspatially smooth subspace learning (SSSL). Through an affinity weight graph matrix; the …,*,2015,*
GPU Machine Learning Library (GPUMLib),Noel Lopes; Bernardete Ribeiro,Abstract The previous chapter accentuated the need for the understanding of large;complex; and distributed data sets generated from digital sources coming from sensors orother physical instruments as well as simulations; crowd sourcing; social networks or otherinternet transactions. The focus was on the difficulties posed to ML algorithms to extractknowledge with prohibitive computational requirements. In this chapter we introduce theGPU; which represents a novel and compelling solution for this problem; due to its inherenthigh-parallelism. Seldom ML algorithms have been implemented on the GPU and most arenot openly shared. To mitigate this problem; this Chapter describes a new open-sourcelibrary (GPUMLib); that aims to provide the building blocks for the development of efficientGPU ML software. In the first part of the chapter we cast arguments for the need of an …,*,2015,*
Motivation and Preliminaries,Noel Lopes; Bernardete Ribeiro,Abstract In this Chapter the motivation for the setting of adaptive many-core machines ableto deal with big machine learning challenges is emphasized. A framework for inference inBig Data from real-time sources is presented as well as the reasons for developing high-throughput Machine Learning (ML) implementations. The chapter gives an overview of theresearch covered in the book spanning the topics of advanced ML methodologies; the GPUframework and a practical application perspective. The chapter describes the main MachineLearning (ML) paradigms; and formalizes the supervised and unsupervised ML problemsalong with the notation used throughout the book. Great relevance has been rightfully givento the learning problem setting bringing to solutions that need to be consistent; well-posedand robust. In the final of the chapter an approach to combine supervised and …,*,2015,*
Handling Missing Data,Noel Lopes; Bernardete Ribeiro,Abstract In this chapter we address the problematic of dealing with missing data in NeuralNetworks (NNs). Missing data is an ubiquitous problem with numerous and diverse causes.Therefore; handling Missing Values (MVs) properly is a crucial issue. Usually; pre-processing techniques; such as imputation; are used for estimating the missing data values.However; they limit considerably the scope of application of NNs. To circumvent thislimitation we introduce a novel Neural Selective Input Model (NSIM) that accommodatesdifferent transparent and bound models; while providing support for handling MVs directly.By embedding the mechanisms to supportMVs we can obtain better models that reflect theuncertainty caused by unknown values. Experiments on several datasets with both differentdistributions and proportion of MVs show that the NSIM approach is very robust and …,*,2015,*
Ensemble learning for keyword extraction from event descriptions,Pedro Geadas; Ana Alves; Bernardete Ribeiro,Automatic keyword extraction (AKE) from textual sources took a valuable step towardsharnessing the problem of efficient scanning of large document collections. Particularly inthe context of urban mobility; where the most relevant events in the city are advertised on-line; it becomes difficult to know exactly what is happening in a place. In this paper we tacklethis problem by extracting a set of keywords from different kinds of textual sources; focusingon the urban events context. We propose an ensemble of automatic keyword extractionsystems KEA (Keyphrase Extraction Algorithm) and KUSCO (Knowledge UnsupervisedSearch for instantiating Concepts on lightweight Ontologies) and Conditional RandomFields (CRF). Unlike KEA and KUSCO which are well-known tools for automatic keywordextraction; CRF needs further preprocessing. Therefore; a tool for handling AKE from the …,Neural Networks (IJCNN); 2014 International Joint Conference on,2014,*
This paper submits a comprehensive report of the use of order statistics (OS) for parametric pattern recognition (PR) for various distributions within the exponential fa...,Noel Lopes; Bernardete Ribeiro,In this paper we focus on two complementary approaches to significantly decrease pre-training time of a deep belief network (DBN). First; we propose an adaptive step sizetechnique to enhance the convergence of the contrastive divergence (CD) algorithm;thereby reducing the number of epochs to train the restricted Boltzmann machine (RBM) thatsupports the DBN infrastructure. Second; we present a highly...,Pattern Recognition,2014,*
On the Optimization of Appliance Loads Inferred by Probabilistic Models,Marisa Figueiredo Ana Maria Carvalho de Almeida Bernardete Ribeiro,*,NILM Workshop; USA,2014,*
Handwritten Signature Matching using GPUMLib,B. João Gonçalves and Noel Lopes and Ribeiro,*,Portuguese Conference on Pattern Recognition; RecPad; Covilhã; Portugal,2014,*
Learning with Drift in Twitter,B. Costa; J. and Silva; C. and Antunes; M. and Ribeiro,*,Portuguese Conference on Pattern Recognition; Covilhã; Portugal,2014,*
Authentication and Security; issues of modern banking services in Iranian banking sector,Ali AghaeiRad; Bernardete Ribeiro,Abstract: Interbank Network" SHETAB" has been working for several years in Iran; andprovides banking services such as withdrawals from ATM machines; buying from the POSmachines; and also recently the online shopping service for the clients of the member banks.In another paper we have shown that the interbank network in the present form canjeopardize users' privacy. In this paper; we show that users are not aware of security issuesin modern banking services by using a statistical study; and they usually do not considersuch issues. Therefore; we conclude that the methods used by interbank network “SHETAB”are not safe. Finally; for solving the mentioned problems; a banking system based on thecollaboration between the banks is offered; that will eliminate problems facing the currentsystem. The presented method is based on short-term passwords; which in author's …,Life Science Journal,2014,*
Spatial Dynamics of the Topographic Representation of Electroencephalogram Spectral Features during General Anesthesia,B Direito; C Teixeira; B Ribeiro; A Dourado; MP Santos; MC Loureiro,Abstract The goal of this study is to identify spatial distributions of the EEG recordings relatedto the anesthesia depth. Serious adverse effects may result from the inaccurate estimation ofanesthesia depth during surgery. We analyzed the spatio-temporal distribution of spectralelectroencephalogram (EEG) collected from patients subjected to general anesthesia. Theapproach is based on the topographic mapping of spectral features of the EEG recordings;and the analysis of the positions of the maxima and minima over the anesthesia cycle. Wefound different patterns depending on the analyzed feature and on the anesthesia phase.The maxima of the spectral edge frequency (SEF) feature are closer to the nasion (frontaland temporal areas) before anesthesia; shift to farther regions during the anesthetic period;and return to regions close to the nasion during the recovery period. The minima of …,*,2014,*
CrowdTargeting: Making Crowds More Personal,Joana Costa; Catarina Silva; Bernardete Ribeiro; Mario Antunes,Crowd sourcing is a bubbling research topic that has the potential to be applied in numerousonline and social scenarios. It consists on obtaining services or information by solicitingcontributions from a large group of people. However; the question of defining theappropriate scope of a crowd to tackle each scenario is still open. In this work we comparetwo approaches to define the scope of a crowd in a classification problem; casted as arecommendation system. We propose a similarity measure to determine the closeness of aspecific user to each crowd contributor and hence to define the appropriate crowd scope.We compare different levels of customization using crowd-based information; allowing non-experts classification by crowds to be tuned to substitute the user profile definition. Resultson a real recommendation data set show the potential of making crowds more personal …,Semantic and Social Media Adaptation and Personalization (SMAP); 2013 8th International Workshop on,2013,*
Crowdtargeting: Making crowds more personal,Mário João Antunes; J Costa; C Silva; B Ribeiro,*,*,2013,*
1692–Obsessive-compulsive-bipolar disorder comorbidity: a case report,JP Ribeiro; Â Ribeiro; B Ribeiro; JC Silva,Introduction Anxiety disorders have been historically described as a feature of BipolarDisorder (BD); and Obsessive-compulsive-bipolar disorder (OCBD) comorbidity has beenreferred in literature. A survey reports that 55; 8% of obsessive-compulsive patients maydevelop BD in their lifetime. Another survey estimates it at 21%. Mania in Obsessive-Compulsive Disorder (OCD) can occur either as an independent comorbidity or as a result ofan antidepressant-induced switch in a patient in anti-OCD drugs. Objectives/aims The aim ofthis poster is to describe and discuss some aspects of this psychiatric comorbidity; withemphasis on its diagnosis and management; based on a case report. Methods This casereport describes a 38-years-old married male with 5 years history of OCD treated with anantidepressant; admitted at our psychiatric ward due to a manic episode. Its management …,European Psychiatry,2013,*
1696–Postictal psychoses-the importance of seizures control a case report,Â Ribeiro; B Ribeiro; JP Ribeiro; O von Doellinger,Introduction Psychiatric symptoms occur quite often in epilepsy and are an importantprognostic factor in quality of life of patients with this neurological condition. The psychoticdisorders occurring in epilepsy are classified according to their chronological relationshipwith the seizures. The peri-ictal psychoses occur before (pre-ictal); during (ictal) or after(postictal) the emergence of a seizure. Inter-ictal psychoses occur independently of seizures.Postictal psychosis (PP) episodes are typically of short duration. Objectives/aims Our aim isto show the great importance of seizures control as a way to prevent the onset of psychoticsymptoms; thereby improving patient's prognosis and quality of life. Methods In this paperwe describe a case of a 44-year-old man; with post-traumatic epilepsy and postictalpsychotic symptoms. Results/conclusion The search and the recognition of psychiatric …,European Psychiatry,2013,*
1214–Emptiness in a life full of experiences: major depression in a 66-year-old man,B Ribeiro; Â Ribeiro; JP Ribeiro; O von Doellinger,Introduction Depression is a common; recurrent; often underdiagnosed and undertreateddisorder in older people. 10-15% of the elderly present depressive symptoms and 3% of thatsame population meet criteria for a major depressive episode. Several factors; such aspsychosocial changes; may be related to the onset of depressive episodes. Retirement(often accompanied with feelings of loss of status; both in the family and in the society); thedecrease of social contacts with a tendency to isolation; and the difficulties to adapt to newactivities and routines; all lead to feelings of inadequacy; worthlessness and a poor self-esteem. Objectives/aims The aim of this poster is to show and discuss the importance inrecognizing some psychosocial factors that can predict the onset of depressive symptoms inthe elderly. Methods We report a case of a 66-year-old man; without previous psychiatric …,European Psychiatry,2013,*
920–Diagnostic difficulties in post-stroke depression: a case report,B Ribeiro; JP Ribeiro; Â Ribeiro; O von Doellinger,Introduction The occurrence of a depressive disorder after a neurological disease is acondition classified in the International Classification of Diseases (ICD-10) as an Organicmood [affective] disorders [F06. 3]; and in the Diagnostic and Statistical Manual of MentalDisorders (DSM-IV-TR) as a Mood disorder due to a general medical condition [298.83].Cerebrovascular disease is associated with an increased risk for depression; with incidencerates of 30-40%. Frequency of post-stroke depression is highest during the first month afterthe ischemic event; but remains high for several years. Objectives/aims The aim of thisposter is to show and discuss some troublesome and complex issues on diagnosing andmanaging patients with post-stroke depression; based on a case report. Methods Herein wereport a case of a 46-year-old woman; without significant prior psychiatric history; who …,European Psychiatry,2013,*
Application Management in Low Power Distributed Embedded Systems,FM Castanheira; A Espírito-Santo; BJF Ribeiro,Embedded systems are nowadays widely found throughout the entire society. We can findthem across all kinds of activities. The application field is so wide that it goes from industry;passing by biomedical applications; or by home automation; without forgetting its use inpersonal assistance applications. This dissemination has required; at different levels; a highincrease of the structural complexity of these systems. In this context; we can forecast thatseveral processing units could cooperate jointly to perform one or more taskssimultaneously. These tasks have a distributed characteristic; demanding; at the same time;the availability of real-time processing capacities executed by a single processing unit; orshared by a pool of cooperating processing units. This scenario is possible only if aninfrastructure that supports this mode of operation is available. This chapter presents the …,Embedded Systems and Wireless Technology: Theory and Practical Applications,2012,*
Tumores marrons múltiplos em paciente com carcinoma de paratireoide,Bruno Niemeyer de Freitas Ribeiro; Renato Niemeyer de Freitas Ribeiro; Ana Luiza Vianna Sobral de Oliveira,Resumo Os tumores marrons são complicações que entram no amplo espectro clínico demanifestações do hiperparatireoidismo; geralmente surgindo como lesões líticas; únicas;frequentemente associadas; na forma primária; ao adenoma de paratireoide (principalcausa) e; na forma secundária; à insuficiência renal crônica. Porém; há relatos deapresentação múltipla. No presente artigo descreve-se um caso incomum de tumor marromassociado à carcinoma de paratireoide; apresentando outra peculiaridade rara; que é amanifestação como lesões múltiplas.,*,2012,*
Using Non-negative Matrix Factorization for Bankruptcy Analysis,Ning Chen; Bernardete Ribeiro; An Chen,Abstract Dimensionality reduction is demonstrated crucial to improve the predictivecapability of models by means of linear or nonlinear projections. Non-negative matrixfactorization (NMF) is a popular multivariate analysis technique for part-based datarepresentation. It attempts to find an approximation of a high dimensional matrix as theproduct of two low dimensional matrices under the non-negative constraint. Recently agraph regularized non-negative matrix factorization (GNMF) provides a formal way toincorporate the geometrical structure into the NMF decomposition; particularly applicable tothe data embedded in submanifolds of the Euclidean space. In this paper; the usage ofGNMF in financial analysis is discussed from the perspectives of unsupervised clusteringand supervised classification. Experimental results on a French bankruptcy data set show …,INFOCOMP,2011,*
Purging false negatives in cancer diagnosis using incremental active learning,Catarina Silva; Bernardete Ribeiro,Abstract Cancer is becoming a human plague; and decision-support tools to help physiciansbetter diagnosing are a fulsome research field. False negatives can be a huge problem forcancer diagnosticians; since while a false positive can result in time and money lost; a falsenegative can result in the lost of human lives; which puts an overwhelming burden ondiagnosis. In this framework; we propose a two-fold approach to purge false negatives incancer diagnosis without compromising precision performance. First; we use an incrementalbackground knowledge method and then; an active learning strategy completes theprocedure. The defined incremental active learning SVM method was tested in theWisconsin-Madison breast cancer diagnosis problem showing the effectiveness of suchtechniques in supporting cancer diagnosis.,International Conference on Intelligent Data Engineering and Automated Learning,2011,*
Incorporate Cost Matrix into Learning Vector Quantization Modeling: a Comparative Study of Genetic Algorithm; Simulated Annealing and Particle Swarm Optimization,Ning Chen; Bernardete Ribeiro; Armando Vieira; Joao Duarte; Joao C Neves,Abstract Cost-sensitive learning is an important topic inbankruptcy prediction concerning theunequal misclassificationcost of different classes. Learning vector quantization (LVQ) isapowerful tool to solve bankruptcy prediction problem as aclassification task. The heuristicalgorithms are applied widelyin conjunction with artificial intelligent methods forsolvingoptimization problems. The hybridization of heuristictechniques with existingclassification algorithms is wellillustrated in the field of bankruptcy prediction. In this paper;three hybrid heuristic-based LVQ approaches which combineLVQ with genetic algorithm;simulated annealing and particleswarm optimization respectively; are proposed to minimizethetotal misclassified cost under the asymmetric cost preference. The idea behind the hybridclassifier is the adoption of heuristicalgorithms for the determination of the connection …,International Journal of Computer Theory and Engineering,2011,*
A Scalable Hardware Environment for Embedded Systems Education,Tiago Gonçalves; A Espírito-Santo; BJF Ribeiro; PD Gaspar,Abstract This chapter presents a scalable platform designed from scratch to support teachinglaboratories of embedded systems. Platform's complexity can increase to offer morefunctionalities in conjunction with student's educational evolution. An I2C bus guaranteesthe continuity of functionalities among modules. The functionalities are supported by acommunication protocol presented in this chapter.,*,2011,*
Incremental Learning for Non-Stationary Patterns,B. Noel Lopes and Ribeiro,*,Portuguese Conference on Pattern Recognition - RECPAD; Lisbon; Portugal,2011,*
Impact of Temporal Window-size on Pattern Denoising of a Smart Home Electrical Signal,B. Figueiredo; M. and Ana Maria de Almeida and Ribeiro,*,Portuguese Conference on Pattern Recognition (RecPad); Lisbon; Portugal,2011,*
Feature Mining and Pattern Recognition in Multimedia Forensics—Detection of JPEG Image Based Steganography; Double-Compression; Interpolation and WAV A...,Qingzhong Liu; Andrew H Sung; Mengyu Qiao; Bernardete Ribeiro; Zhongxue Chen,Abstract Steganography; the ancient art for secretive communications; has revived on theInternet by way of hiding secret data; in completely imperceptible manners; into a digital file.Thus; the steganography has created a serious threat to cyber security due to the covertchannel it provides that can be readily exploited for various illegal purposes. Likewise;image tampering or forgery; which has been greatly facilitated and proliferated by photoprocessing tools; is increasingly causing problems concerning the authenticity of digitalimages. JPEG images constitute one of the most popular media on the Internet; yet they canbe easily used for the steganography as well as easily tampered by; eg; removing; adding;or splicing objects without leaving any clues. Therefore; there is a critical need to developreliable methods for steganalysis (analysis of multimedia for the steganography) and for …,*,2011,*
Computational Intelligence: Neural Networks and Kernel Methods,Bernardete Martins Ribeiro,*,Computational Intelligence: Neural Networks and Kernel Methods,2010,*
Programa; Conteúdos e Métodos de Ensino Teórico e Prático: Técnicas de Reconhecimento de Padrões,Bernardete Martins Ribeiro,*,Programa; Conteúdos e Métodos de Ensino Teórico e Prático: Técnicas de Reconhecimento de Padrões,2010,*
Enhancing SVMs for Text Classification,Catarina Silva; Bernardete Ribeiro,Abstract The previous chapter introduced kernel-based techniques and their baselineapplication to text classification. In this chapter we develop and explore learning techniquesthat integrate knowledge in the classification task to improve the performance of supportvector machines (SVMs) in text classification applications. The introduction of unlabeleddata in the learning stage is investigated. With the deluge of digital text data; unlabeled textsare ubiquitous. Whether it is the Internet; email servers; database files or plain file systems;the sources for digital texts are countless. However; such texts are usually unlabeled; andtheir labeling is mostly manual and costly. Therefore; a research field on the study and useof these unlabeled texts has been emerging. It is further exploited the potential of usingseveral learning machines organized in a committee. Knowing that there is no unique …,*,2010,*
Framework for Text Classification,Catarina Silva; Bernardete Ribeiro,Abstract The previous chapters presented a number of novel techniques to tackle a variety ofproblems encountered in real-world text classification settings. The common underlyingthread has been the integration of knowledge in the inference of inductive learning modelswithout penalizing processing time. This chapter unifies the main topics of this book into aframework. An inductive inference-based text classification framework will provide basicgeneric tools that are appropriate for a broad range of applications. New research trends intext classification are highlighted towards the end. We will focus on the particulardevelopments in kernel methods triggered by new problems in text mining and on how toextract useful knowledge by mining relationships between data. We include a few promisingresearch directions that are likely to expand in the future.,*,2010,*
Scaling RVMs for Text Classification,Catarina Silva; Bernardete Ribeiro,Abstract In the previous chapter we investigated learning techniques to improve supportvector machines'(SVMs) performance in text classification. We turn our attention in thischapter to relevance vector machines (RVMs) and their application to text classification.RVMs' probabilistic Bayesian nature allows both predictive distributions on testing instancesand model-based selection that yields a parsimonious solution. However; scaling up thealgorithm is not viable in most digital information processing applications.,*,2010,*
Kernel Machines for Text Classification,Catarina Silva; Bernardete Ribeiro,Abstract This chapter details the concept of kernel methods and presents the foundations oftwo paradigmatic techniques: support vector machines and relevance vector machines. Bothare introduced in a text classification perspective and then results and comparisons of theirapplication to benchmark corpora are presented.,*,2010,*
Distributing Text Classification in Grid Environments,Catarina Silva; Bernardete Ribeiro,Abstract The previous chapters looked at several ways to improve the performance ofsupport vector machines (SVMs) and relevance vector machines (RVMs) in textclassification applications. Most data mining problems are nowadays faced with two greatchallenges. First; the volume of digital data available is growing massively in almost allapplication areas. Second; state-of-the-art learning machines are becoming increasinglydemanding in terms of computing power. This chapter establishes a high-performancedistributed computing environment model where the learning techniques proposed in theprevious chapters are efficiently deployed and tested in large scale corpora.,*,2010,*
Stochastic GPU-based Multithread Implementation of Multiple Back-propagation.,Noel Lopes; Bernardete Ribeiro,*,ICAART (1),2010,*
Projecto de desenvolvimento de um sistema de planeamento de produção: o caso da Pecol 2,Bruno Miguel de Castro Ribeiro,O Projecto enquadrou-se numa reestruturação empresarial à empresa Pecol. Devido àsdeficiências do sistema de planeamento de produção; a empresa decidiu fazer odesenvolvimento de um sistema de planeamento de produção baseado em Tecnologias deInformação. Esse desenvolvimento podia ser feito internamente ou externamente. Noprojecto foi feita a decisão sobre o desenvolvimento interno ou externo. Optando-se pelodesenvolvimento interno foi incluído no projecto a criação de procedimentos e interfacespara o sistema de informação de apoio ao planeamento de produção. ABSTRACT: TheProject fits into a restructuring taken over on Pecol company; In regard to de deficiências inthe production planning system; it was decided to make a developmento of a new system.This system based on Information Technologies. This devolpement could be made …,*,2009,*
MBPGPU: A Supervised Pattern Classifier for Graphical Processing Units,B. Noel Lopes and Ribeiro,*,Portuguese Conference on Pattern Recognition - RECPAD; Porto; Portugal,2009,*
Improving Personal Credit Scoring with HLVQ-C,Armando Vieira; João Duarte; Bernardete Ribeiro; Joao Carvalho Neves,Abstract In this paper we study personal credit scoring using several machine learningalgorithms: Multilayer Perceptron; Logistic Regression; Support Vector Machines;AddaboostM1 and Hidden Layer Learning Vector Quantization. The scoring models weretested on a large dataset from a Portuguese bank. Results are benchmarked againsttraditional methods under consideration for commercial applications. A measure of theusefulness of a scoring model is presented and we show that HLVQ-C is the most accuratemodel.,International Conference on Neural Information Processing,2008,*
ECG Compression through segment matching and progressive error encoding,Mario Brito; Jorge Henriques; Paulo Carvalho; Bernardete Ribeiro; Manual Antunes,This work describes a lossy electrocardiogram (ECG) compression algorithm based on RRsegmentation and segment matching. An ECG can be thought of as a quasi-periodic signal;with many similarities existing between heartbeats acquired from the same source. Throughthe use of an adaptive dictionary; it is possible to explore the similarities between new andpreviously encountered patterns; incorporating new patterns when a significant change inmorphology has been observed. Algorithm simulation reveals very high compression ratiosare possible on very regular signals.,Engineering in Medicine and Biology Society; 2007. EMBS 2007. 29th Annual International Conference of the IEEE,2007,*
Adaptive and Natural Computing Algorithms,Bartłomiej Beliczyński; Andrzej Dzieliński; Marcin Iwanowski; Bernardete Ribeiro,Adaptive and Natural Computing Algorithms. Bartłomiej Beliczyński ; Andrzej Dzieliński ; MarcinIwanowski ; Bernardete Ribeiro. Abstract. n/a. Book type; Monograph. Editor; Bartłomiej BeliczyńskiISEP Bartłomiej Beliczyński;; - The Institute of Control and Industrial Electronics. ; AndrzejDzieliński ISEP Andrzej Dzieliński;; - The Institute of Control and Industrial Electronics. ; MarcinIwanowski ISEP Marcin Iwanowski;; - The Institute of Control and Industrial Electronics. ;Bernardete Ribeiro Bernardete Ribeiro;; -. Author; Publisher; Springer Berlin Heidelberg. ISBN;978-3-540-71590-0; 978-3-540-71629-7. Issue year; 2007. Book series /Journal (in case ofJournal special issue); Lecture Notes In Computer Science. No; 4432. Score (nominal); 0. Citationcount*; 0. Cite. Cite. Share Share. * presented citation count is obtained through Internetinformation analysis and it is close to the number calculated by the Publish or Perish …,*,2007,*
Computational intelligent techniques for financial distress detection Srinivas Mukkamala; Gourav D. Tilve; Andrew H. Sung Department of Computer Science; New M...,Bernardete M Ribeiro; Armando S Vieira,Abstract In this paper we apply several computational intelligence techniques to the problemof bankruptcy prediction of medium-sized private companies. Financial data was obtainedfrom Diana; a large database containing financial statements of French companies.Classification accuracy is evaluated for Linear Genetic Programs (LGPs); Classification andRegression Tress (CART); TreeNet; and Random Forests; Multilayer Perceptron (using BackPropogation); Hidden Layer Learning Vector Quantization and several gradient descentmethods; conjugate gradient methods; the Levenberg-Marquardt algorithm (LM); theResilient Backpropogation Algorithm (Rprop); and One Step Secant Method. We analyze 2datasets; one is balanced and the other unbalanced. TreeNet has the best performanceaccuracy on unbalanced dataset and LGPs performs the best on balanced dataset …,International Journal of Computational Intelligence Research (IJCIR),2006,*
Adaptive and Natural Computing Algorithms: Proceedings of the 7th International Conference in Coimbra; Portugal; March 21-23 2005,Bernadete Ribeiro; Rudolf F Albrecht; Andrej Dobnikar; David W Pearson; Nigel C Steele,*,*,2005,*
Adaptive and Natural Computing Algorithms: Proceedings of the International Conference in Coimbra; Portugal; March 21st to 23rd; 2005,Rudolf F Albrecht; Andrej Dobnikar; David W Pearson; Bernardete Ribeiro; Nigel C Steele,*,*,2005,*
Selective Classification and Regression Models Based on Support Vector Clustering,Bemardete Ribeiro,*,Neural; Parallel & Scientific Computations,2005,*
A framework for neural quality control systems design,N Costa; B Ribeiro,Abstract Stimulated by the growing demand for improving system performance andreliability; fault-tolerant system design has been receiving significant attention. This paperproposes a new framework for fault-tolerant and quality control design based on the learningcapabilities of neural networks. In highly nonlinear systems; with slow process variation; anda high degree of reactivity; quick changes (in the environment; for example) cause fastresponses. This class of systems is broad enough so that it is not only of theoretical interestbut also of practical applicability. Moreover; the fault-tolerance ability of the adaptivecontroller will be further improved by exploiting information estimated from a fault-detectionand diagnosis unit designed by a pattern-matching strategy in multiple faults modelsinterfaced with the overall system. Results of the approach are presented in a practical …,*,2003,*
An Inductive Inference Approach to Large Scale Text Categorisation,Catarina Silva; Bernardete Ribeiro,Abstract Automatic text categorisation of documents has received a resounding interest inlast years due to the increased availability of documents in digital form and the commandingneed to organize them. In this paper; our main focus is the development of tools that willenable very fast and accurate text classifiers in large scale databases. To pursue thisobjective; we start by introducing the main issues of text categorisation and present possibleways of handling them. Kernel based methods; such as; Support Vector Machines (SVMs);are learning methods with strong potential for solving the tasks involved in automatic textcategorisation. The first results achieved with Reuters-21578 collection are reported andsome points of possible improvements are identified.,*,2003,*
Radiometric image correction with automatic model selection,P Carvalho; A Santos; A Dourado; B Ribeiro,Abstract Computer vision is a powerful tool for intelligent sensor development. However;noise in CCD cameras leads to significant radiometric distortions. Therefore; radiometricimage correction is a critical operation; specially when physics-based models are applied forimage processing; as is the case in many industrial applications. All known radiometriccorrection methods assume that noise characteristics remain stable over time. In this paper;a new radiometric correction method is proposed to account for non static noise effects. Themethod decomposes radiometric distortion into multiplicative and additive errors; whoseoptimal models are computed with a new extension to the Generalized Cross-ValidationCriterion.,IFAC Proceedings Volumes,2002,*
Aplicação das Redes Neuronais no Encaminhamento em Redes de Dados,F Araújo; L Rodrigues; B Ribeiro,Skip navigation. Página principal; Percorrer: Comunidades & Colecções; Percorrer Itens por:Data de publicação; Autor; Orientador; Título; Assunto; Tipo de Documento; Tipo de Acesso.Ajuda. Idioma: português; english. Entrar: Área Pessoal; Serviço de alertas; Editar conta.Repositório da Universidade de Lisboa logo. Repositório da Universidade de Lisboa; Faculdadede Ciências (FC); Departamento de Informática / Department of Informatics (FC-DI); Lasige -Large-Scale Informatics Systems Laboratory (FC-DI-Lasige); FC-DI-Lasige - Articles inInternational Journals. Utilize este identificador para referenciar este registo: http://hdl.handle.net/10451/14376. Título: Aplicação das Redes Neuronais no Encaminhamento em Redes deDados. Autor: F. Araújo L. Rodrigues B. Ribeiro. Palavras-chave: Computer Science. Data: 20002000. Editora: Terceira Conferência sobre Redes de Computadores (CRC'00) …,*,2000,*
Monitoring an Industrial Plastic Injection Moulding Machine Using Neural,N Costa; A Cunha; B Ribeiro,Abstract Plastics are nowadays one of the most used materials in several industries. Fromdomestic tools up to the automotive industry; there is an enormous number of possibleapplications. The pressures imposed by the market have led to the development of newstrategies capable of answering the required demands. Neural networks have revealed highpotential in a wide range of situations and have been successfully applied in fault detectionand diagnosis systems. In this paper we intend to clarify; in part; the different diagnosticmethodologies and; on the other hand; we suggest a neural network approach formonitoring the plastic injection moulding process. Future work will use the developed neuralmonitoring scheme for process fault diagnosis with the aim of industrial quality management.,Artificial Neural Nets and Genetic Algorithms: Proceedings of the International Conference in Portorož; Slovenia; 1999,1999,*
Application of neural networks for diagnosing and predicting the condition of an industrial furnace,B Ribeiro,ABSTRACT Draft Paper This paper discusses an industrial application of a neural networkbased automatic scheme for fault detection and diagnosis. Faults in a lime kiln are isolatedand detected; using two multilayer feedforward networks. One is used to model the industrialprocess according to its nonlinear structure. The fault detection method is based on theoutput prediction error between the real simulated response and the neural network modelresponse. A second neural network is fed with the residual vector from the previous phasefor which each speci c output corresponds to each speci c fault. The good performanceobtained demonstrates the e ectivness of the strategy employed.,CESA'96 IMACS Multiconference: computational engineering in systems applications,1996,*
Contribuição para a modelização; supervisão e controlo de sistemas multivariáveis não lineares por redes neuronais com aplicação a um forno de cal,Bernardete Martins Ribeiro,Nesta Tese apresentamos um contributo para o estudo do comportamento dinâmico dumforno rotativo de cal; para a sua identificação e controlo; e para a monitorização ediagnóstico das condições de operação. Numa primeira fase; desenvolvemos um modelomatemático de parâmetros distribuídos do processo e; numa segunda fase; utilizamos umaabordagem por redes neuronais para a sua modelização; controlo multivariável ediagnóstico industrial. O forno rotativo de cal é essencial para o sistema de caustificação doprocesso kraft da indústria de pasta de papel; no caso particular; o centro fabril da Portucelde Viana do Castelo. É um processo multivariável; fortemente não linear; com tempos deatraso e está; muitas vezes; sob a influência de perturbações externas ou processuais. Querpor razões económicas e de qualidade do produto; quer por razões de protecção …,*,1995,*
Kolmogorov's Theorem: From Algebraic Equations and Nomography to Neural Networks.,Bernardete Ribeiro; Alexander Kovacec,*,Artificial Neural Nets and Genetic Algorithms: Proceedings of the International Conference in...,1993,*
DINTER: um simulador de processos de destilação,Bernardete Martins Ribeiro,Skip navigation …,DINTER: um simulador de processos de destilação,1986,*
Computational Concept Modeling for Student Centric Lifestyle Analysis: A Technical Report on SOCIALITE Case Study,Rahul Sharma; Bernardete Ribeiro; Alexandre Miguel Pinto; F Amılcar Cardoso; Marcelo Duarte Raposo; André Rodrigues; Jorge Sá Silva; Fernando Boavida,Abstract—Students are an important part of our society; and their way of life has a greateffect in their performance. There has been a remarkable contribution by psychologicalresearch in studying students' behavior and its impact over aspects like studies; and health.Nowadays Internet of Everything (IoE) sources (such as smart-phones; social networks;sensor networks etc.) are capturing person specific data which can contribute to studyhumans over various dimensions (for example behavior analysis; activity monitoring etc.);but it's challenging to handle such colossal data. Though; Computational modelingtechniques can play an essential role comprehending such data. In this work we used threedatasets obtained from IoE source; out of which two datasets (Sleep-Detection; Student-Activity) are from Smart-phone; and one data (Room) is from Sensor-boxes. Further; we …,*,*,*
Paper reviewers,A Augusto Sousa; Alberto Cardoso; Amélia Loja; Ana Sofia Guimarães; André Fidalgo; António Mendes Lopes; António Ruano; Bárbara Rangel; Bernardete Ribeiro; Celina Pinto Leão; César Teixeira; Fátima Chouzal; Fernando Gomes; PT de Almeida; Fernando Carneiro; Filomena Soares; Gustavo Alves; CA Hamadou Saliah-Hassane; Hélia Guerra; Horácio Fernandes; João Tavares; João Pedro Carneiro; Jorge Lobo; José Rodrigues; José Couto Marques; BR Juarez Silva; Luís Mendes Gomes; Manuel Romano Barbosa; Maria da Graça Ruano; Maria Teresa Restivo; SK Mikulas Huba; Mohammed Serrhini; Nadiia Basos; Paulo Abreu; Paulo Gil; Paulo Menezes; Paulo B Oliveira; Rafael Tavares; Ricardo Costa,› A. Augusto Sousa; PT › Alberto Cardoso; PT › Alberto Leva; IT › Alejandro López-Ruiz; ES ›Alexander Kist; AU › Alexander Zimin; RU › Amélia Loja; PT › Ana Sofia Guimarães; PT › AndréFidalgo; PT › Andreas Lauber; GE › Andreas Pester; AT › Andreja Rojko; SI › AndreyShumov; RU › Anna Friesel; DK › Anthony Rossiter; UK › António Mendes Lopes; PT › AntónioRuano; PT › Ari Saptawijaya; ID › Armando Preciado Babb; CA › Bárbara Rangel; PT › BernardeteRibeiro; PT › Bogdan Deaky; RO › Carlos Argueda Matarrita; CR › Celina Pinto Leão; PT › CesarOrtega-Sanchez; AU › César Teixeira; PT › Christian Guetl; AT › Christian Kreiter; AT › ChristianDominic Fehling; DE › Christos Dimopoulos; CY › Claudius Terkowsky; DE › DanielaJanßen; DE › Danilo Garbi Zutin; AT › David Boehringer; DE › David Lowe; AU › Denis Gillet;CH › Dominik May; DE … › Doru Ursutiu; RO › Ernesto Fabregas; ES › Euan Lindsay …,*,*,*
GAIT Analysis: Methods & Data Review,Alexandra Vieira; Bernardete Ribeiro; João P Ferreira,Abstract-The physiotherapists analyse gait patterns to recognize normal and pathologicalgait movements. The difficulty of the gait analysis can be high due to patterns' complexityand variability. The gait patterns are affected by the characteristics of the individual (gender;age; weight and height) and the walking speed. In this paper; it is proposed a MachineLearning (ML) algorithm to generate knee angle patterns in sagittal plane; which is one ofthe joints used during the walk. The ML algorithm can generate a specific reference ofnormal knee pattern depending on individual's characteristics and walking speed. Thisspecific reference provides a personalized gait analysis. To this end; three ML approachesare compared: an Artificial Neural Network (ANN); an Extreme Learning Machine (ELM) anda Multi-output Support Vector Regression (MSVR). Using the patterns of healthy people …,*,*,*
Evolving the Topology of Large Scale Deep Neural Networks,Filipe Assunçao; Nuno Lourenço; Penousal Machado; Bernardete Ribeiro,Abstract. In the recent years Deep Learning has attracted a lot of attention due to its successin difficult tasks such as image recognition and computer vision. Most of the success in thesetasks is merit of Convolutional Neural Networks (CNNs); which allow the automaticconstruction of features. However; designing such networks is not an easy task; whichrequires expertise and insight. In this paper we introduce DENSER; a novel representationfor the evolution of deep neural networks. In concrete we adapt ideas from GeneticAlgorithms (GAs) and Grammatical Evolution (GE) to enable the evolution of sequences oflayers and their parameters. We test our approach in the well-known image classificationCIFAR-10 dataset. The results show that our method:(i) outperforms previous evolutionaryapproaches to the generations of CNNs;(ii) is able to create CNNs that have state-of-the …,*,*,*
Generating datasets with drift,Joana Costa12; Catarina Silva12; Mário Antunes13; Bernardete Ribeiro,Abstract Modern challenges in machine learning include non-stationary environments. Dueto their dynamic nature; learning in these environments is not an easy task; as models haveto deal both with continuous learning process and also with the acquisition of new concepts.Different types of drift can occur; as concepts can appear and disappear with differentpatterns; namely sudden; reoccurring; incremental or gradual. Besides striving to proposenew techniques to learn in the presence of drift; researchers aim to find appropriatebenchmarks to non-stationary scenarios. In this paper we propose DOTS; a drift oriented toolsystem; whose main goals are to define and generate datasets with drift for text classificationproblems. DOTS tries to fill an existing gap in machine learning research for textapplications; by making possible to generate benchmark datasets with thoroughly …,*,*,*
CriticalSampleSizeforMiningData,José Silva; Bernardete Ribeiro; Andrew H Sung,Page 1. CriticalSampleSizeforMiningData José Silva; Bernardete Ribeiro; Andrew H. Sungjmpsilva@student.dei.uc.pt; bribeiro@dei.uc.pt; andrew.sung@usm.edu Problem Critical SampleSize (CSS) is the absolute minimal number of instances; of a given dataset; that are needed toallow a specific learning machine achieve a given performance threshold. This problem is veryimportant in data mining; as the size of data sets directly relates to the cost of executing the datamining task. Since the problem of determining the critical sampling size is intractable; in our workwe study heuristic methods to find the critical sampling. Basic Concepts There exists a Dv whichlets a learning machine M achieve a performance of at least T; where Dv is a sample of Dn withv instances and PM(Dv) is the performance of M when trained with Dv: (∃Dv ⊂ Dn)[PM(Dv) ≥T] (1) For all j<v; a sample of Dn with j instances …,*,*,*
On the Evaluation of Text Processing in Text Categorization,C Silva; B Ribeiro,*,*,*,*
CONTROLO 98; Coimbra; Portugal; 9-11 September 1998,A Dourado; F Silva Leite; T Pedroso de Lima; F Cardoso; J Dias; N Oliveira; B Ribeiro; J Afonso,The architecture herewith described is currently implemented in the first prototypes of theRESOLV project; two mobile robotic platforms: one autonomous (AEST) and the othermanually operated (EST). The project aims at the development of a system to enable theacquisition and reconstruction of realistic 3D models of large and complex indoorenvironments; based on range and video data.,*,*,*
Bayes Information Criterion for Tikhonov Problems with Linear Constraints: Application to Radiometric Image Correction,P Carvalho; A Santos; A Dourado; B Ribeiro,ABSTRACT Ill-conditioned or singular data modeling problems are commonly observed inimage processing. To solve these problems some constraints; such as smoothness andboundary conditions have to be formulated. Further; the optimal structure of the model is notalways self-evident. There are several criteria that can be applied for” optimal” regularizationgain or model selection. However; these measures (i) are not for problems with linearconstraints and; further (ii) are usually not simultaneously suitable for model andregularization gain selection. In this paper the Bayes Information Criterion is extended forTikhonov problems with linear constraints. Using this measure; a new radiometric imagecorrection method is introduced. All known radiometric correction algorithms assume thatradiometric distortions remain stable over time. Our algorithm enables image correction …,*,*,*
Determination of 99 Mo in eluates of 99m Tc used in nuclear medicine services in Rio de Janeiro; RJ; Brazil,BS Ribeiro; ALA Dantas; EA Lucena; BM Dantas,The objective of this study is to determine the presence of 99 Mo in the eluates used inNuclear Medicine Services (NMS). For the methodology of this work was provided using aNal scintillation detector (Tl) 8 x 4 installed in the shielded room of the IRD whole bodycounter. The eluates were counted in three distinct distances (10; 15 and 20 cm) weredetermined 99 Mo activity. The 99m Tc activity was measured in the NMS own where theeluates were collected; and by using suitable calculations was determined the ratio of 99Mo/99m Tc. Samples of eluates were provided voluntarily by NMS in Rio de Janeiro. Allmeasures indicated the presence of 99 Mo; it is concluded that this technique is sensitive forthe detection of 99 Mo in eluates of 99m Tc; and you can check the quality of generatorsused in SMN evaluated in this study,*,*,*
APPLICATION OF BIOASSAY TECHNIQUES TO EVALUATE 99Mo INCORPORATION IN NUCLEAR MEDICINE PATIENTS,Caroline de OA da Silva; Bianca S Ribeiro; Wanderson O Souza; Francisco de Araújo; Eder A Lucena; Ana Letícia A Dantas; Bernardo M Dantas,ABSTRACT 99mTc is the most widely used radionuclide in nuclear medicine. It is obtainedby elution of 99Mo/99mTc generators. Depending on the quality of the generator and itsintegrity; 99Mo might be extracted from the column during the elution process; becoming aradionuclidic impurity in the 99mTc eluate. This fact would impart an undesired dose to thepatients submitted to diagnostic procedures using 99mTc. The aim of this work is to estimatethe internal effective doses in nuclear medicine patients due to the incorporation of 99Mo asa radionuclidic impurity and provide additional information about the metabolic behavior ofmolybdenum in humans. Results of in vivo and in vitro measurements have been comparedwith values obtained through the use of a standard metabolic model of molybdenumestablished by the ICRP using the software AIDE. Experimental data obtained in this work …,*,*,*
Determination of 99 Mo in 99m Tc eluates used in nuclear medicine centers in Rio de Janeiro,Bianca da S Ribeiro; Raphael SS Souza; Eder A Lucena; Ana Letícia A Dantas; Bernardo M Dantas,ABSTRACT 99mTc is used in nuclear medicine for image diagnoses with SPECT. It isobtained from the elution of molybdenum-99/technetium-99m (99Mo/99mTc) generators.During the elution; 99Mo can detach from the column; passing through the filter and mixingin the solution of pertechnetate eluate and becoming a radionuclidic impurity. The presenceof molybdenum in the radiopharmaceutical solution imparts an unnecessary radiation doseto the patient; since its half-life is relatively long (66 hours) and it emits beta particles andhigh-energy photons of (740keV). A parameter that indicates the quality of the eluates is theradionuclidic purity; the MBT (molybdenum break through); defined as the ratio between99Mo and 99mTc activities in the eluate. The American and the European Pharmacopoeiasrestrict 99Mo content to respectively 0.015% and 0.1% activity ratio 99Mo/99mTc at the …,*,*,*
2010 4th European DSP Education and Research Conference (EDERC),Baranski Przemyslaw; Polanczyk Maciej; Strumillo Pawel,An electronic travel aid for the blind is presented in the paper. The built device features twomain functionalities: a mobile phone and a remote assistant module. The device is capableof receiving and dispatching text messages; handling phone calls and browsing a contactbook. Text messages; menu; contact book and so on are read by a speech synthesizerwhich was developed from scratch. The latter...,*,*,*
CALIBRATION OF A SCINTILATION DETECTION SYSTEM FOR 99Mo MEASUREMENTS IN 99mTc ELUATE SAMPLES,Bianca Ribeiro; Ana Letícia Dantas; Caroline Silva; Francisco Araújo; Eder Lucena; Bernardo Dantas,ABSTRACT Molybdenum-99 is the parent of 99mTc; a radionuclide widely used in nuclearmedicine for image diagnose. During elution of 99Mo-99mTc generators it should not beextracted from the column but it might occur depending on the quality and integrity of thegenerator and usage conditions in the radiopharmacy laboratory. 99Mo emits high-energybeta particles. Its presence as a radionuclidic impurity in the technetium eluate increasesunnecessarily the dose delivered to the patient. Furthermore; depending on its activity in theradiopharmaceutical solution; and considering its high-energy gamma of 740 keV andaffinity to the liver; it can also degrades the quality of the diagnose image. The objective ofthis work is to develop a methodology to identify and quantify 99Mo activity in 99mTceluates. A NaI (Tl) 8” x4” scintilation detector installed in the shielded room of the IRD …,*,*,*
Supplementary material for: Gaussian Process Classification and Active Learning with Multiple Annotators,Filipe Rodrigues; Francisco C Pereira; Bernardete Ribeiro,Page 1. Supplementary material for: Gaussian Process Classification and Active Learning withMultiple Annotators Filipe Rodrigues (fmpr@dei.uc.pt) Francisco C. Pereira (camara@smart.mit.edu) Bernardete Ribeiro (bribeiro@dei.uc.pt) In this extra material; we provide more detailson deriving the moments of the product of the cavity distribution with the exact likelihood term ∑zi∈{0;1} p(yi|zi)p(zi|fi); which constitutes the step 2 of EP referred in the paper. This derivationwas ommited from the main text due to lack of space. 1 Moments derivation Recall that theproduct of the cavity distribution with the exact likelihood term is given by: q(fi) ˆ ZiN(ˆµi; ˆσ2i ) ≃ q−i(fi) ∑ zi∈{0;1} p(yi|zi)p(zi|fi) which; by making of the definitions of the differentprobabilities; can be manipulated to give: q(fi) = biN(fi|µ−i;σ2 −i)+(ai − bi)Φ(fi)N(fi|µ−i;σ2 −i)(1) whose moments we wish to compute for moment matching …,*,*,*
New Approach for Robotics Education-RoboSapien Hacking,Pedro Dinis Gaspar; António Espírito Santo; Humberto Santos; Bruno Ribeiro,Abstract—The robotics education integrates several knowledge's acquired during theundergraduate course; namely mechanical and electronics concepts. Moreover; thepractical experience of these concepts is very important as part of engineering education;but it is resource intensive. It is presented a nouvelle approach for the robotics educationbased in the RoboSapien hacking. It has proven to be a valuable teaching tool for thispurpose; allowing the reinforcement of several key concepts concerning the integration oftopics related to kinematics; dynamics; control systems; embedded systems; data acquisitionand microprocessors programming. Furthermore; this approach for the robotics educationproved to be very motivating and stimulating for the students.,*,*,*
Bayes Information Criterion for Tikhonov Problems with Linear Constraints: Application to Spectral Data Estimation,P d Carvalho; A Santos; B Ribeiro; A Dourado,*,*,*,*
MBPGPU: A Supervised Pattern Classiﬁer for Graphical Processing Units,N Lopes; B Ribeiro,*,*,*,*
Intelligent Data Mining in the GRID Environment-Report 6/2005,C Silva; U Lotrič; B Ribeiro; A Dobnikar,*,*,*,*
Support Vector Machines in Fault Monitoring Control,B Ribeiro,*,*,*,*
Support Vector Machines for Quality Monitoring in a Plastic Injection Molding Machine,B Ribeiro,*,*,*,*
Mercer’s Kernel Based Learning,B Ribeiro; P d Carvalho,*,*,*,*
On Data Support Vector Clustering,B Ribeiro,*,*,*,*
Accurate Prediction of Financial Distress with Machine Learning Algorithms,AS Vieira; João Duarte; B Ribeiro; JC Neves,Abstract Prediction of financial distress of companies is analyzed with several machinelearning approaches. We used DIANE; a large database containing financial records ofsmall and medium size French companies from the year of 2002 up to 2007. It is shown thatinclusion of historical data; up to 3 years priori to the analysis; increase the predictionaccuracy. In particular; fluctuations of some financial ratios are found to be crucial. Due tothe inclusion of a large amount of inputs particular attention is given to feature selection. Anaccuracy of up to 94% is achieved with the best models.,*,*,*
A Modular Constructive Approach to Mobile Robot Navigation,C Silva; B Ribeiro,*,*,*,*
Expanding Working Set Approaches to RVM for Text Classification,C Silva; B Ribeiro,*,*,*,*
Industrial Lime Kiln Simulation and Control by Neural Networks,B Ribeiro; A Dourado,*,*,*,*
Aplicaçc ao das redes neuronais no,Filipe Araéujo; Luéis Rodrigues; Bernardete Ribeiro,*,*,*,*
A NEURAL MODULAR ARCHITECTURE FOR NAVIGATING MOBILE ROBOTS,Bernardete Ribeiro,*,*,*,*
Program Committees,Janos Abonyi; Jerzy W Grzymala-Busse; David Pelta; Jesús Aguilar; Saman Halgamuge; Sabri Pllana; Abo Al-Ola Atifi; Shuji Hashimoto; Radu-Emil Precup; Bruno Apolloni; Ilkka Havukkala; Steven Prestwich; Akira Asano; Enrique Herrera-Viedma; Günther Raidl; Youakim Badr; Cesar Hervas; Vitorino Ramos; Leonard Barolli; Silviu Ionita; Cesar Rego; Thomas Bartz-Beielstein; Pedro Isasi; Mauricio GC Resende; Rafael Bello; Hisao Ishibuchi; Bernardete Ribeiro; José Manuel Benítez; Yoshiteru Ishida; Jose Riquelme; Ester Bernado; Janina Jakubczyc; Ignacio Rojas; Maumita Bhattacharya; Yaochu Jin; Andrea Roli; Mauro Birattari; Angel Alejandro Juan; Dumitru Roman; Michael Blumenstein; Janusz Kacprzyk; Louis-Martin Rousseau,Janos Abonyi University of Veszprem; Hungary Jerzy W. Grzymala-Busse University ofKansas; USA David Pelta Universidad de Granada; Spain Jesús Aguilar Univ. PabloOlavide; Spain Saman Halgamuge University of Melbourne; Australia Sabri Pllana Universityof Vienna; Austria Abo Al-Ola Atifi CBA Kuweit University; Kuweit Shuji Hashimoto WasedaUniversity; Japan Radu-Emil Precup Politehnica Univ. of Timisoara; Romania Bruno ApolloniUniversita degli Studi di Milano; Italy Ilkka Havukkala IPONZ; New Zealand Steven Prestwich4C Cork; Ireland Akira Asano Hiroshima University; Japan Enrique Herrera-Viedma Universityof Granada; Spain Günther Raidl Technical Univ. Vienna; Austria Youakim Badr INSA Lyon;France Cesar Hervas University of Cordoba; Spain Vitorino Ramos Technical Univ. ofLisbon; Portugal Leonard Barolli FIT; Japan Silviu Ionita University of Pitesti; Romania …,*,*,*
Aplicação Multimédia para Treino e Aprendizagem em Controlo Automático,C Gonçalves; AJ Cardoso; A Dourado; B Ribeiro; C Pereira; JO Henriques,*,*,*,*
CISUC-Centro de Inform atica e Sistemas da Universidade de Coimbra Pinhal de Marrocos; Polo II; P-3030 Coimbra Tel No.+ 351-39-7000040; Fax No.+ 351-39-70...,B Ribeiro,*,*,*,*
Support Vector Machines For Medical Data Bases Classification,Bernardete Ribeiro,*,*,*,*
Classification of Mass Spectrometry Proteomics Data: Manifold and Supervised Distance Metric Learning,Qingzhong Liu; Andrew H Sung; Bernardete M Ribeiro; Mengyu Qiao,ABSTRACT Mass spectrometry has become a widely used measurement in proteomicsresearch. High dimensionality of features and small dataset are two major challenges inmass spectrum data analysis. To address the high dimensionality issue; we study featureextraction and feature selection. A wellknown approach is to detect peak values and applysupport vector machine recursive feature elimination (SVMRFE) to choose feature sets forclassification. In this paper; we successfully apply a distance metric learning to classifyproteomics mass spectrometry data. Experimental results show that distance metric learningcan successfully be applied to the classification of proteomics data and the results arecomparable to the best results by applying SVM to the feature sets chosen with the use ofSVMRFE. Our results also show the promising potential of manifold learning in feature …,*,*,*
Channel Equalization Using Neural Networks: A Review................. K. Burse; RN Yadav; and SC Shrivastava 352 Design of an Automatic Wood Types Classification...,C Silva; U Lotric; B Ribeiro; A Dobnikar; Y Ye; T Li; Q Jiang; Y Wang; EC Martins; FG Jota; A Rodriguez; WA Chaovalitwongse; L Zhe; H Singhal; H Pham; Z Li; M Yan; M Zhou; AN Tarau; B De Schutter; H Hellendoorn,REVIEWS Grid Resource Negotiation: Survey and New Directions . . . . . . . . . . . . . . . . . . . . . . .. . . . . . . . . . . . . . . . . . . . . . . . . . .KM Sim … PAPERS Burst Detection From Multiple DataStreams: A Network-Based Approach. . . . . . . . . . . .A. Sun; DD Zeng; and H. Chen … A MathematicalProgramming Solution to the Mars Express Memory Dumping Problem . . . . . G. Righini andE. Tresoldi … Geometric Distortion Insensitive Image Watermarking in Affine Covariant Regions. . . X. Gao; C. Deng; X. Li; and D. Tao … Distributed Text Classification With an EnsembleKernel-Based Learning Approach . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . C. Silva; U. Lotric; B. Ribeiro; and A. Dobnikar… CIMDS: Adapting Postprocessing Techniques of Associative Classification for Malware Detection…,*,*,*
A Neural Prediction Model for Monitoring and Fault Diagnosis of a Plastic Injection Moulding Machine,N Costa; B Ribeiro,*,*,*,*
A Neural Modular Learning Architecture for Navigating the NOMAD Mobile Robot Without Knowledge of the Environment,Catarina Silva; Bernardete Ribeiro,*,*,*,*
Controlo Multivariável de um Forno Industrial baseado em Redes Neuronais Artificiais MNN e RBFNN,B Ribeiro; A Dourado,*,*,*,*
Highly Irregular Elliptical Object Localisation In Multi-Connected Regions Using Neural Networks,P d Carvalho; N Costa; B Ribeiro; A Dourado,Abstract− Detection of elliptical shapes is of extreme importance in several computerapplications. In this paper we describe a new method for highly irregular elliptical objectlocalisation based on neural networks and some decision criteria. This method is applied toseveral inspection tasks; namely to lime granule visual inspection.,*,*,*
Application of Neural Networks for Diagnosing and Predicting the Condition of an Industrial Lime Kiln,B Ribeiro,*,*,*,*
A Neural Modular Architecture for Navigating Mobile Robots,C Silva; B Ribeiro,*,*,*,*
Sparse Bayesian Simplified Models for ECG Compression,B Ribeiro; M Brito; JO Henriques; M Antunes,*,*,*,*
