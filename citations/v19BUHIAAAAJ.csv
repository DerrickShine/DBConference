ORA-SS: An Object-Relationship-Attribute Model for Semi-Stractured Data,Gillian Dobbie; Wu Xiaoying; Tok Wang Ling; Mong Li Lee,Semi-structured data is becoming increasingly important with the introduction of XML andrelated languages and technologies. The recent shift from DTDs (document type definitions)to XML-Schema for XML data highlights the importance of a schema definition for semi-structured data applications. At the same time; there is a move to extend semi-structureddata models to express richer semantics. In this paper we propose a semantically rich datamodel for semi-structured data; ORA-SS (Object-Relationship-Attribute model for Semi-Structured data). ORA-SS not only reflects the nested structure of semi-structured data; but italso distinguishes between objects; relationships and attributes. It is possible to specify thedegree of n-ary relationships and indicate if an attribute is an attribute of a relationship or anattribute of an object. Such information is lacking in existing semi-structured data models …,*,2000,91
Research on particle swarm optimization based clustering: a systematic review of literature and techniques,Shafiq Alam; Gillian Dobbie; Yun Sing Koh; Patricia Riddle; Saeed Ur Rehman,Abstract Optimization based pattern discovery has emerged as an important field inknowledge discovery and data mining (KDD); and has been used to enhance the efficiencyand accuracy of clustering; classification; association rules and outlier detection. Clusteranalysis; which identifies groups of similar data items in large datasets; is one of its recentbeneficiaries. The increasing complexity and large amounts of data in the datasets haveseen data clustering emerge as a popular focus for the application of optimization basedtechniques. Different optimization techniques have been applied to investigate the optimalsolution for clustering problems. Swarm intelligence (SI) is one such optimization techniquewhose algorithms have successfully been demonstrated as solutions for different dataclustering domains. In this paper we investigate the growth of literature in SI and its …,*,2014,82
Extracting association rules from XML documents using XQuery,Jacky WW Wan; Gillian Dobbie,Abstract Data mining is generally considered the extraction and analysis of information fromdatabases. With the rapid growth of XML data available online; mining XML data from theweb is becoming important. In support of this trend; several encouraging attempts atdeveloping methods for mining XML data have been proposed. However; efficiency andsimplicity are still a barrier for further development In this paper; we show that any XMLdocument can be mined for association rules using only the query language XQuery withoutany pre-processing or post-processing.,Proceedings of the 5th ACM international workshop on Web information and data management,2003,77
XOO7: Applying OO7 Benchmark to XML Query Processing Tools,Stéphane Bressan; Gillian Dobbie; Zoé Lacroix; Mong Li Lee; Ying Guang Li; Ullas Nambiar; Bimlesh Wadhwa,If XML is to play the critical role of the lingua franca for Internet data interchange that manypredict; it is necessary to start designing and adopting benchmarks allowing the comparativeperformance analysis of the tools being developed and proposed. The effectiveness ofexisting XML query languages has been studied by many who focused on the comparison oflinguistic features; implicitly reflecting the fact that most XML tools exist only on paper. In thispaper; with a focus on efficiency and concreteness; we propose a pragmatic first step towardthe systematic benchmarking of XML query processing platforms with an initial focus on thedata (versus document) point of view. We propose XOO7; an XML version of the OO7benchmark. We discuss the applicability of XOO7; its strengths; limitations and theextensions we are considering. We illustrate its use by presenting and discussing the …,*,2001,63
An evolutionary particle swarm optimization algorithm for data clustering,Shafiq Alam; Gillian Dobbie; Patricia Riddle,Clustering is an important data mining task and has been explored extensively by a numberof researchers for different application areas such as finding similarities in images; text dataand bio-informatics data. Various optimization techniques have been proposed to improvethe performance of clustering algorithms. In this paper we propose a novel algorithm forclustering that we call Evolutionary Particle Swarm Optimization (EPSO)-clustering algorithmwhich is based on PSO. The proposed algorithm is based on the evolution of swarmgenerations where the particles are initially uniformly distributed in the input data space andafter a specified number of iterations; a new generation of the swarm evolves. The swarmtries to dynamically adjust itself after each generation to optimal positions. The paperdescribes the new algorithm the initial implementation and presents tests performed on …,Swarm Intelligence Symposium; 2008. SIS 2008. IEEE,2008,57
Research collaboration among university scientists,Philip S Morrison; Gill Dobbie; Fiona J McDonald,Despite the growing importance of collaboration in research there have been very fewinvestigations of the practice of research collaboration itself. The study we reportinvestigated this practice by analysing 444 collaborative projects undertaken by staff in theScience Faculty of a New Zealand university. While the results support the sociology ofscience model of vertical collaboration up and down the academic hierarchy; we also showthat significant collaboration now takes place across levels in the hierarchy; that is amongpeers; in what we call horizontal collaboration. This shift from vertical to horizontalcollaboration has not been readily apparent in bibliographic studies of co-authored papersin top journals. One of the questions this study raises is the often assumed positiveassociation between collaboration; research output and research quality; and the …,Higher Education Research & Development,2003,56
Designing semistructured databases using ORA-SS model,Xiaoying Wu; Tok Wang Ling; Mong Li Lee; Gillian Dobbie,Semistructured data has become prevalent with the growth of the Internet. The developmentof new web applications that require efficient design and maintenance of large amounts ofdata makes it increasingly important to design" good" semistructured databases to preventdata redundancy and updating anomalies. However; it is not easy; even impossible; forcurrent semistructured data models to capture the semantics traditionally needed fordesigning databases. In this paper; we show how an object-relationship-attribute model forsemistructured data (ORA-SS) can facilitate the design of" good" semistructured databases.This is accomplished via the normalization of ORA-SS. An XML DTD or Schema generatedfrom a normal form ORA-SS schema diagram has no undesirable redundancy; and thus noupdating anomalies for the complying semistructured databases. The general design …,Web Information Systems Engineering; 2001. Proceedings of the Second International Conference on,2001,54
Semistructured database design,Tok Wang Ling; Gillian Dobbie,Semistructured Database Design provides an essential reference for anyone interested inthe effective management of semsistructured data. Since many new and advanced webapplications consume a huge amount of such data; there is a growing need to properlydesign efficient databases. This volume responds to that need by describing a semanticallyrich data model for semistructured data; called Object-Relationship-Attribute model forSemistructured data (ORA-SS). Focusing on this new model; the book discuss problems andpresent solutions for a number of topics; including schema extraction; the design of non-redundant storage organizations for semistructured data; and physical semsitructureddatabase design; among others. Semistructured Database Design; presents researchersand professionals with the most complete and up-to-date research in this fast-growing …,*,2004,53
Mining association rules from XML data using XQuery,Jacky WW Wan; Gillian Dobbie,Abstract In recent years XML has became very popular for representing semistructured dataand a standard for data exchange over the web. Mining XML data from the web is becomingincreasingly important. Several encouraging attempts at developing methods for miningXML data have been proposed. However; efficiency and simplicity are still a barrier forfurther development. Normally; pre-processing or post-processing are required for miningXML data; such as transforming the data from XML format to relational format. In this paper;we show that extracting association rules from XML documents without any pre-processingor post-processing using XQuery is possible and analyze the XQuery implementation of thewell-known Apriori algorithm. In addition; we suggest features that need to be added intoXQuery in order to make the implementation of the Apriori algorithm more efficient.,Proceedings of the second workshop on Australasian information security; Data Mining and Web Intelligence; and Software Internationalisation-Volume 32,2004,53
Automated usability testing framework,Fiora TW Au; Simon Baker; Ian Warren; Gillian Dobbie,Abstract Handheld device applications with poor usability can reduce the productivity ofusers and incur costs for businesses; thus usability testing should play a vital role inapplication development. Conventional usability testing methodologies; such as formal usertesting; can be expensive; time consuming and labour intensive; less resource-demandingalternatives can yield unreliable results. Automating aspects of usability testing wouldimprove its efficiency and make it more practical to perform throughout development. Anautomated usability testing tool should capture as input the properties of an application'sgraphical user interface; the sequence of user actions as they use the application to achieveparticular tasks; their behaviour and comments; as well as a description of these tasks. Thetool should evaluate both the static and dynamic properties of the interface; examine …,Proceedings of the ninth conference on Australasian user interface-Volume 76,2008,49
On the declarative and procedural semantics of deductive object-oriented systems,Gillian Dobbie; Rodney Topor,Abstract We present declarative and procedural semantics for a deductive object-orientedlanguage; Gulog. The declarative semantics is based on preferred minimal models. Wedescribe both bottom-up and top-down query evaluation procedures and show that they aresound with respect to the declarative semantics. The results contribute to our understandingof the interaction of inheritance; overriding and deduction in the presence of both functionaland set-valued methods; and multiple inheritance.,Journal of Intelligent Information Systems,1995,48
Supporting and evaluating team dynamics in group projects,Judy Brown; Gillian Dobbie,Abstract Computer science students benefit from working in teams. But working in teams isdifficult and team skills are seldom taught. In this paper; we describe mechanisms we put inplace for supporting team processes in our group project course. We evaluate themechanisms and extract guidelines that are useful for supporting team dynamics.,ACM SIGCSE Bulletin,1999,43
Particle swarm optimization based clustering of web usage data,Shafiq Alam; Gillian Dobbie; Patricia Riddle,Abstract Web session clustering is one of the important web usage mining techniques whichaims to group usage sessions on the basis of some similarity measures. In this paper wedescribe a new web session clustering algorithm that uses particle swarm optimization. Wereview the existing web usage clustering techniques and propose a swarm intelligencebased PSO-clustering algorithm for the clustering of web user sessions. The proposedalgorithm works independently without hybridization with any other clustering algorithm. Theresults show that our approach performs better than the benchmark K-means clusteringalgorithm for clustering web usage sessions.,Proceedings of the 2008 IEEE/WIC/ACM International Conference on Web Intelligence and Intelligent Agent Technology-Volume 03,2008,42
XOO7: applying OO7 benchmark to XML query processing tool,Ying Guang Li; Stéphane Bressan; Gillian Dobbie; Zoé Lacroix; Mong Li Lee; Ullas Nambiar; Bimlesh Wadhwa,Abstract If XML is to play the critical role of the lingua franca for Internet data interchange thatmany predict; it is necessary to start designing and adopting benchmarks allowing thecomparative performance analysis of the tools being developed and proposed. Theeffectiveness of existing XML query languages has been studied by many; with a focus onthe comparison of linguistic features; implicitly reflecting the fact that most XML tools existonly on paper. In this paper; with a focus on efficiency and concreteness; we propose apragmatic first step toward the systematic benchmarking of XML query processing platformswith an initial focus on the data (versus document) point of view. We propose XOO7; an XMLversion of the OO7 benchmark. We discuss the applicability of XOO7; its strengths;limitations and the extensions we are considering. We illustrate its use by presenting and …,Proceedings of the tenth international conference on Information and knowledge management,2001,42
R-MESHJOIN for near-real-time data warehousing,M Asif Naeem; Gillian Dobbie; Gerald Weber; Shafiq Alam,Abstract To fulfill the increasing demand of business for the latest information; current dataintegration approaches are moving towards real-time updates. One important element inreal-time data integration is the join of a continuous incoming data stream with a disk-basedrelation. In this paper we investigate a stream-based join algorithm; called mesh join(MESHJOIN); and propose an improved version called reduced MESHJOIN (R-MESHJOIN).Both algorithms tune the memory; allocating parts of the memory to key components. InMESHJOIN there is a dependency between the size of partitions in an internal queue for thestream data and the number of iterations required to bring the disk-based relation intomemory. This dependency hampers the optimal distribution of memory among the joincomponents. In particular the size of the disk-buffer varies with the size of the disk-based …,Proceedings of the ACM 13th international workshop on Data warehousing and OLAP,2010,39
A logical foundation for deductive object-oriented databases,Mengchi Liu; Gillian Dobbie; Tok Wang Ling,Abstract Over the past decade; a large number of deductive object-oriented databaselanguages have been proposed. The earliest of these languages had few object-orientedfeatures; and more and more features have systematically been incorporated in successivelanguages. However; a language with a clean logical semantics that naturally accounts forall the key object-oriented features; is still missing from the literature. This article takes usanother step towards solving this problem. Two features that are currently missing are theencapsulation of rule-based methods in classes; and nonmonotonic structural andbehavioral inheritance with overriding; conflict resolution and blocking. This articleintroduces the syntax of a language with these features. The language is restricted in thesense that we have omitted other object-oriented and deductive features that are now …,ACM Transactions on Database Systems (TODS),2002,38
An event-based near real-time data integration architecture,M Asif Naeem; Gillian Dobbie; Gerald Webber,Extract-Transform-Load (ETL) tools feed data from operational databases into datawarehouses. Traditionally; these ETL tools use batch processing and operate offline atregular time intervals; for example on a nightly or weekly basis. Naturally; users prefer tohave up-to-date data to make their decisions; therefore there is a demand for real-time ETLtools. In this paper we investigate an event-based near real-time ETL layer for transferringand transforming data from the operational database to the data warehouse. One of ourmain concerns in this paper is master data management in the ETL layer. We present thearchitecture of a novel; general purpose; event-driven; and near real-time ETL layer thatuses a Database Queue (DBQ); works on a push technology principle and directly supportscontent enrichment. We also observe that the system architecture is consistent with the …,Enterprise Distributed Object Computing Conference Workshops; 2008 12th,2008,37
Particle swarm optimization based hierarchical agglomerative clustering,Shafiq Alam; Gillian Dobbie; Patricia Riddle; M Asif Naeem,Clustering-an important data mining task; which groups the data on the basis of similaritiesamong the data; can be divided into two broad categories; partitional clustering andhierarchal. We combine these two methods and propose a novel clustering algorithm calledHierarchical Particle Swarm Optimization (HPSO) data clustering. The proposed algorithmexploits the swarm intelligence of cooperating agents in a decentralized environment. Theexperimental results were compared with benchmark clustering techniques; which include K-means; PSO clustering; Hierarchical Agglomerative clustering (HAC) and Density-BasedSpatial Clustering of Applications with Noise (DBSCAN). The results are evidence of theeffectiveness of Swarm based clustering and the capability to perform clustering in ahierarchical agglomerative manner.,Web Intelligence and Intelligent Agent Technology (WI-IAT); 2010 IEEE/WIC/ACM International Conference on,2010,36
A maturity model for computing education,Christof Lutteroth; Andrew Luxton-Reilly; Gillian Dobbie; John Hamer,Abstract We propose a maturity model for computing education which is inspired by theCapability Maturity Model (CMM) used in software engineering. Similar to CMM; theComputing Education Maturity Model (CEMM) can be used to rate educational organisationsaccording to their capability to deliver high-quality education on a five level scale.Furthermore; CEMM can be used in order to improve an institution's capability byimplementing the best practises and organisational changes it describes.,Proceedings of the ninth Australasian conference on Computing education-Volume 66,2007,36
Weighted association rule mining via a graph based connectivity model,Russel Pears; Yun Sing Koh; Gillian Dobbie; Wai Yeap,Abstract Association rule mining is an important data mining task that discovers relationshipsamong items in a transaction database. Classical association rule mining approaches makethe implicit assumption that an item's importance is determined by its support. In contrast;Weighted Association Rule Mining (WARM) attempts to provide a notion of importance; orweight to individual items that are not based solely on item support. Previous approaches toWeighted Association Rule Mining assign item weights in a subjective manner; based on auser's specialized knowledge of the underlying domain that is involved. Such approachesare infeasible when millions of items are present in a dataset; or when domain knowledge isunavailable. Furthermore; even when such domain information is available; a weightassignment based on subjective information constrains the knowledge discovered to fit …,Information Sciences,2013,35
NF-SS: A normal form for semistructured schema,Xiaoying Wu; Tok Wang Ling; Lee Sin Yeung; Mong Li Lee; Gillian Dobbie,Abstract Semistructured data is becoming increasingly important for web applications withthe development of XML and related technologies. Designing a “good” semistructureddatabase is crucial to prevent data redundancy; inconsistency and undesirable updatinganomalies. However; unlike relational databases; there is no normalization theory tofacilitate the design of good semistructured databases. In this paper; we introduce the notionof a semistructured schema and identify the various anomalies that may occur in such aschema. A Normal Form for Semistructured Schemata; NF-SS; is proposed. A semistructuredschema in NF-SS guarantees minimal redundancy and hence no undesirable updatinganomalies for the associated semistructured databases. Furthermore; a semistructuredschema in NF-SS gives a more reasonable representation of real world semantics. We …,International Conference on Conceptual Modeling,2001,33
A model for sets and multiple inheritance in deductive object-oriented systems,Gillian Dobbie; Rodney Topor,Abstract We consider the addition of set-valued methods and multiple inheritance to asimple deductive object-oriented language we defined and studied previously. We showhow the previously defined declarative semantics can be extended to provide a naturalsemantics for inheritance and overriding in this more general setting; and similarly extendour previously defined evaluation procedures.,International Conference on Deductive and Object-Oriented Databases,1993,28
Evaluating domain-specific modelling solutions,Parastoo Mohagheghi; Øystein Haugen,Abstract This paper presents criteria and evaluation methods for evaluating domain-specificmodelling (DSM) solutions based on analysing state of the art and experiences ofdeveloping and evaluating DSM solutions in research projects. The state-of-the-art analysisreturned several requirements regarding the quality of domain-specific modelling languagesand tools developed based on them that are classified based on the identified stakeholders.The stakeholders are those who develop and those who use a DSM solution; the intendeddomain and purposes with developing a DSM solution as defined by domain experts;software engineering concerns; integration with other languages or tools; and the quality ofartefacts to be modelled or generated. Both quantitative and qualitative approaches may beapplied for evaluating DSM solutions based on the development stage and requirements …,International Conference on Conceptual Modeling,2010,24
RP-Tree: rare pattern tree mining,Sidney Tsang; Yun Sing Koh; Gillian Dobbie,Abstract Most association rule mining techniques concentrate on finding frequent rules.However; rare association rules are in some cases more interesting than frequentassociation rules since rare rules represent unexpected or unknown associations. All currentalgorithms for rare association rule mining use an Apriori level-wise approach which hascomputationally expensive candidate generation and pruning steps. We propose RP-Tree; amethod for mining a subset of rare association rules using a tree structure; and aninformation gain component that helps to identify the more interesting association rules.Empirical evaluation using a range of real world datasets shows that RP-Tree itemset andrule generation is more time efficient than modified versions of FP-Growth and ARIMA; anddiscovers 92-100% of all the interesting rare association rules.,International Conference on Data Warehousing and Knowledge Discovery,2011,23
Towards specification based testing for semantic web services,M Shaban Jokhio; Gillian Dobbie; Jing Sun,Web services have become popular in the modern infrastructure of the World Wide Web.They aim to provide automatic discovery; selection; and invocation of required applications(services) across the internet. However; the quality assurance aspects of web servicesremain a challenge. Recently; the semantic web has been introduced as an emergingtechnology which emphasizes presenting the meaning of the web content to achieve amachine processable automation. In this paper; we explore the synergy of applyingspecification based software testing techniques to semantic web services. Our approachinvestigates the possibility of deriving concrete test cases from the goal specification of asemantic web service in order to determine the correctness of a service implementation.Furthermore; we also propose coverage criteria to evaluate the generated test cases at …,Software Engineering Conference; 2009. ASWEC'09. Australian,2009,22
A model for inheritance and overriding in deductive object-oriented systems,Gillian Dobbie; Rodney Topor,Abstract We present a simple model for deductive objectoriented systems with inheritanceand overriding. In this model we de ne a declarative semantics based on preferred minimalmodels; we present bottom-up and top-down procedures for query evaluation; and we notethat these procedures are sound with respect to the declarative semantics.,Sixteen Australian Computer Science Conference,1988,21
Designing semistructured databases: A conceptual approach,Mong Li Lee; Sin Yeung Lee; Tok Wang Ling; Gillian Dobbie; Leonid A Kalinichenko,Abstract Semistructured data has become prevalent with the growth of the Internet. The datais usually stored in a database system or in a specialized repository. Many informationproviders have presented their databases on the web as semistructured data; while othersare developing repositories for new applications. Designing a “good” semistructureddatabase is important to prevent data redundancy and updating anomalies. In this paper; wepropose a conceptual approach to design semistructured databases. A conceptual layerbased on the Entity-Relationship model is used to remove redundancies at the semanticlevel. An algorithm to map an ER diagram involving composite attributes weak entity types;recursive; n-ary and ISA relationship sets; and aggregations to a semistructured schemagraph (S3-Graph) is also given.,International Conference on Database and Expert Systems Applications,2001,19
Exploiting swarm behaviour of simple agents for clustering web users’ session data,Shafiq Alam; Gillian Dobbie; Patricia Riddle,Abstract In recent years the integration and interaction of data mining and multi agent system(MAS) has become a popular approach for tackling the problem of distributed data mining.The use of intelligent optimization techniques in the form of MAS has been demonstrated tobe beneficial for the performance of complex; real time; and costly data mining processes.Web session clustering; a sub domain of Web mining is one such problem; tackling theinformation comprehension problem of the exponentially growing World Wide Web (WWW)by grouping usage sessions on the basis of some similarity measure. In this chapter wepresent a novel web session clustering approach based on swarm intelligence (SI); a simpleagent oriented approach based on communication and cooperation between agents. SIexploits the collective behaviour of simple agents; cooperation between the agents; and …,*,2009,18
Detecting volatility shift in data streams,David Tse Jung Huang; Yun Sing Koh; Gillian Dobbie; Russel Pears,Current drift detection techniques detect a change in distribution within a stream. However;there are no current techniques that analyze the change in the rate of these detectedchanges. We coin the term stream volatility; to describe the rate of changes in a stream. Astream has a high volatility if changes are detected frequently and has a low volatility ifchanges are detected infrequently. We are particularly interested in a volatility shift which isa change in the rate of change (eg From high volatility to low volatility). We introduce anddefine the concept of stream volatility; and propose a novel technique to detect volatility ondata streams in the presence of concept drifts. In the experiments we show our algorithm tobe both fast and efficient. We also propose a new algorithm for drift detection called SEEDthat is faster and more memory efficient than the existing state-of-the-art drift detection …,Data Mining (ICDM); 2014 IEEE International Conference on,2014,17
A swarm intelligence based clustering approach for outlier detection,Shafiq Alam; Gillian Dobbie; Patricia Riddle; M Asif Naeem,Outlier detection is an important field in data mining and knowledge discovery; which aims toidentify abnormal observations in a large dataset. Common application areas of outlierdetection are intrusion detection in computer networks; credit cards fraud detection;detecting abnormal changes in stock prices; and identifying abnormal health conditions. Wepropose the use of a novel swarm intelligence based clustering technique calledHierarchical Particle Swarm Optimization Based Clustering (HPSO-clustering) for outlierdetection. The proposed technique is able to perform Hierarchical Agglom-erative Clustering(HAC) as well as outlier detection. In the proposed approach a swarm of particles evolvesthrough different stages to identify outliers and normal clusters. The experimentation of theproposed approach is performed on benchmark datasets which show that the efficiency of …,Evolutionary Computation (CEC); 2010 IEEE Congress on,2010,17
Automated usability testing using HUI analyzer,Simon Baker; Fiora Au; Gillian Dobbie; Ian Warren,In this paper; we present an overview of HUI Analyzer; a tool intended for automatingusability testing. The tool allows a user interface's exepected and actual use to be capturedunobtrusively; with any mismatches indicating potential usability problems beinghighlighted. HUI Analyzer allows supports specification and checking of assertionsgoverning an interface's layout and actual user interaction. Assertions offer a low-costmeans of detecting usability defects and are intended to be checked iteratively during a userinterface's development. Hotspot analysis is a feature that highlights relative use of GUIcomponents in a form. This is useful in informing form layout; for example to collocateheavily used components thereby reducing unnecessary scrolling or movement. Based onevaluation; we have found HUI Analyzer's performance in detecting usability defects to be …,Software Engineering; 2008. ASWEC 2008. 19th Australian Conference on,2008,17
Applications of ora-ss: An object-relationship-attribute data model for semistructured data,Tok Wang Ling; Mong Li Lee; Gillian Dobbie,*,*,2001,17
Detecting online auction shilling frauds using supervised learning,Sidney Tsang; Yun Sing Koh; Gillian Dobbie; Shafiq Alam,Abstract Online auction sites are a target for fraud due to their anonymity; number ofpotential targets and low likelihood of identification. Researchers have developed methodsfor identifying fraud. However; these methods must be individually tailored for each type offraud; since each differs in the characteristics important for their identification. Usingsupervised learning methods; it is possible to produce classifiers for specific types of fraudby providing a dataset where instances with behaviours of interest are assigned to aseparate class. However this requires multiple labelled datasets: one for each fraud type ofinterest. It is difficult to use real-world datasets for this purpose since they are difficult tolabel; often limited in size; and contain zero or multiple suspicious behaviours that may ormay not be under investigation. The aims of this work are to:(1) demonstrate the approach …,Expert Systems with Applications,2014,16
X-HYBRIDJOIN for near-real-time data warehousing,Muhammad Asif Naeem; Gillian Dobbie; Gerald Weber,Abstract In order to make timely and effective decisions; businesses need the latestinformation from data warehouse repositories. To keep these repositories up-to-date withrespect to end user updates; near-real-time data integration is required. An important phasein near-real-time data integration is data transformation where the stream of updates isjoined with disk-based master data. The stream-based algorithm Mesh Join (MESHJOIN)has been proposed to amortize disk access over fast stream. MESHJOIN makes noassumptions about the data distribution. In real world applications; however; skeweddistributions can be found; eg; certain products are sold more frequently than the remainderof the products. The question arises; how much does MESHJOIN loose in terms ofperformance by not adapting to data skew. In this paper we perform a rigorous …,British National Conference on Databases,2011,16
Software engineers aren't born in teams: Supporting team processes in software engineering project courses,Judy Brown; Gill Dobbie,In the Computer Science programme at Victoria University of Wellington; we teach two 3rdyear software engineering courses. The first course teaches software engineering principles.The second course is a project course in which students are expected to work in teams. Thisyear; we provided more support for team processes in the project course. We describe themechanisms that we use to support the team process and summarize the results of a surveythat evaluated the mechanisms. The survey; which was administered at the mid-point of thecourse; indicates that at that time our mechanisms to support team processes appear to beworking well.,Software Engineering: Education & Practice; 1998. Proceedings. 1998 International Conference,1998,16
Foundations of deductive object-oriented database systems,Gillian Dobbie,Abstract The mathematical foundation of the relational data model has contributed to thewidespread use of relational database systems. This mathematical foundation gives a clearmeaning to the data; provides a basis for database design; allows the use of simpledeclarative query languages; and enables queries to be optimized automatically. However;the relational data model has limitations. These include the difficulty of representingcomplex; structured and procedural information that is required in many new databaseapplications; and the restriction to query languages that are not computationally complete.Two approaches that address some of these problems are deductive databases and object-oriented databases. Deductive databases extend the class of queries that can be expressed;and preserve the mathematical foundation of relational systems and object-oriented …,Informatica,1996,16
HYBRIDJOIN for Near-real-time Data Warehousing,M Asif Naeem; Gillian Dobbie; Gerald Weber,An important component of near-real-time data warehouses is the near-real-time integrationlayer. One important element in near-real-time data integration is the join of a continuousinput data stream with a diskbased relation. For high-throughput streams; stream-basedalgorithms; such as Mesh Join (MESHJOIN); can be used. However; in MESHJOIN theperformance of the algorithm is inversely proportional to the size of disk-based relation. TheIndex Nested Loop Join (INLJ) can be set up so that it processes stream input; and can dealwith intermittences in the update stream but it has low throughput. This paper introduces arobust stream-based join algorithm called Hybrid Join (HYBRIDJOIN); which combines thetwo approaches. A theoretical result shows that HYBRIDJOIN is asymptotically as fast as thefastest of both algorithms. The authors present performance measurements of the …,*,2011,15
Anomaly detection and identification scheme for VM live migration in cloud infrastructure,Tian Huang; Yongxin Zhu; Yafei Wu; Stéphane Bressan; Gillian Dobbie,Abstract Virtual machines (VM) offer simple and practical mechanisms to address many ofthe manageability problems of leveraging heterogeneous computing resources. VM livemigration is an important feature of virtualization in cloud computing: it allows administratorsto transparently tune the performance of the computing infrastructure. However; VM livemigration may open the door to security threats. Classic anomaly detection schemes such asLocal Outlier Factors (LOF) fail in detecting anomalies in the process of VM live migration. Totackle such critical security issues; we propose an adaptive scheme that mines data from thecloud infrastructure in order to detect abnormal statistics when VMs are migrated to newhosts. In our scheme; we extend classic Local Outlier Factors (LOF) approach by definingnovel dimension reasoning (DR) rules as DR-LOF to figure out the possible sources of …,Future Generation Computer Systems,2016,14
Detection of abnormal profiles on group attacks in recommender systems,Wei Zhou; Yun Sing Koh; Junhao Wen; Shafiq Alam; Gillian Dobbie,Abstract Recommender systems using Collaborative Filtering techniques are capable ofmake personalized predictions. However; these systems are highly vulnerable to profileinjection attacks. Group attacks are attacks that target a group of items instead of one; andthere are common attributes among these items. Such profiles will have a good probability ofbeing similar to a large number of user profiles; making them hard to detect. We propose anovel technique for identifying group attack profiles which uses an improved metric basedon Degree of Similarity with Top Neighbors (DegSim) and Rating Deviation from MeanAgreement (RDMA). We also extend our work with a detailed analysis of target item ratingpatterns. Experiments show that the combined methods can improve detection rates in user-based recommender systems.,Proceedings of the 37th international ACM SIGIR conference on Research & development in information retrieval,2014,14
Automatic item weight generation for pattern mining and its application,Yun Sing Koh; Russel Pears; Gillian Dobbie,ABSTRACT Association rule mining discovers relationships among items in a transactionaldatabase. Most approaches assume that all items within a dataset have a uniformdistribution with respect to support. However; this is not always the case; and weightedassociation rule mining (WARM) was introduced to provide importance to individual items.Previous approaches to the weighted association rule mining problem require users toassign weights to items. In certain cases; it is difficult to provide weights to all items within adataset. In this paper; the authors propose a method that is based on a novel Valency modelthat automatically infers item weights based on interactions between items. The authorsexperiment shows that the weighting scheme results in rules that better capture the naturalvariation that occurs in a dataset when compared with a miner that does not employ a …,Developments in Data Extraction; Management; and Analysis,2013,14
Hierarchical PSO clustering based recommender system,Shafiq Alam; Gillian Dobbie; Patricia Riddle; Yun Sing Koh,Due to a marked increase in the number of web users and their activities; many applicationareas that use patterns generated from their activities has been proposed. Web-basedimplicit recommender systems are one such application. An implicit recommender system isa tool that helps guide a user to a particular web resource based on implicit data. Implicitdata comes from the web users activities without their active participation. Building such asystem is a complex process due to two reasons; there is a huge amount of data and thequality of the data is poor. In this research; we tackle the first problem of generating patternsefficiently for recommender system by proposing Hierarchical Particle Swarm Optimizationbased clustering (HPSO-clustering). HPSO-clustering is a clustering approach based onParticle Swarm Optimization which combines both the properties of hierarchical and …,Evolutionary Computation (CEC); 2012 IEEE Congress on,2012,14
Representing inheritance and overriding in Datalog,Gillian Dobbie; Rodney Topor,Abstract We describe the relationship between inheritance with overriding in an object-oriented database language; Gulog; and negation. We present a translation from Gulogprograms to Datalog programs with negation and show that evaluating queries in thetranslation yields correct answers with respect to the original program.,*,1994,14
Clustering heterogeneous web usage data using hierarchical particle swarm optimization,Shafiq Alam; Gillian Dobbie; Yun Sing Koh; Patricia Riddle,Data clustering aims to group data based on similarities between the data elements.Recently; due to the increasing complexity and amount of heterogenous data; modeling ofsuch data for clustering has become a serious challenge. In this paper we tackle theproblem of modeling heterogeneous web usage data for clustering. The main contribution isa new similarity measure which we propose to cluster heterogeneous web usage data. Wethen use this similarity measure in our Particle Swarm Optimization (PSO) based clusteringalgorithm; Hierarchical Particle Swarm Optimization based clustering (HPSO-clustering).HPSO-clustering combines the qualities of hierarchical and partitional clustering to clusterdata in a hierarchical agglomerative manner. We present the clustering results and explainthe effects of the new similarity measure on inter-cluster and intra-cluster distances …,Swarm Intelligence (SIS); 2013 IEEE Symposium on,2013,13
A framework for testing semantic web services using model checking,Muhammad Shaban; Gill Dobbie; Jing Sun,Web Services (WS); which are based on standard XML protocols; such as; WSDL; SOAPand UDDI; are the building blocks of Service Oriented Architecture (SOA). The aim of SOA isto automate web service tasks; such as; web service discovery; selection; composition andexecution. Since XML is a syntax-based language; the automation of these tasks is still achallenge. To overcome this; web services can be described semantically using an ontologydescription language; eg; Web Ontology Language (OWL); giving rise to semantic webservices (SWS). Because semantic web services are relatively new; there has been littleresearch into testing and quality assurance aspects. In this paper; we propose a novelapproach for generating test cases based on user requirements for testing semantic webservices. In SWS frameworks; such as; Web Service Modelling Ontology (WSMO); the …,Formal Methods (SEEFM); 2009 Fourth South-East European Workshop on,2009,13
XTree for declarative XML querying,Zhuo Chen; Tok Wang Ling; Mengchi Liu; Gillian Dobbie,Abstract How to query XML documents to extract and restructure the information is animportant issue in XML research. Currently; XQuery based on XPath is the most promisingstandard of W3C. In this paper; we introduce a new set of syntax rules called XTree; which isa generalization of XPath. XTree has a tree structure; and a user can bind multiple variablesin one XTree expression. It explicitly identifies list-valued variables; and defines somenatural built-in functions to manipulate them. XTree expression can also be used in theresult construction part of a query; to make it easy to read and comprehend. With thesedifferences; XTree expressions are much more compact; and more convenient to write andunderstand than XPath expressions. We also give algorithms to convert queries based onXTree expressions to standard XQuery queries.,International Conference on Database Systems for Advanced Applications,2004,13
Analysis of particle swarm optimization based hierarchical data clustering approaches,Shafiq Alam; Gillian Dobbie; Saeed Ur Rehman,Abstract Data clustering is one of the most widely used data mining techniques; classifyingsimilar data items into groups on the basis of similarity among the data items. Differentissues have been observed while achieving the classification of data into the most suitablegrouping. Efficiency of the clustering techniques and accuracy of the resulting groups aretwo of the main issues. To tackle these issues; recently; optimization based techniques havebeen used; resulting in enhanced quality of the output and improved efficiency of theclustering process. Swarm Intelligence (SI) is one such technique whose different algorithmshave been found effective for this purpose. Particle Swarm Optimization (PSO) and AntColony Optimization (ACO) are the two most prominent SI based techniques. In this paperwe analyze the use of PSO for data clustering in particular for clustering in a hierarchical …,Swarm and Evolutionary Computation,2015,12
Spreadsheets as collaborative technologies in global requirements change management,Waqar Hussain; Tony Clear,Globally distributed stakeholders employ various collaborative technologies to managerequirements. While these technologies facilitate requirements collaboration; their perceivedpurpose; use and structure co-evolve over time. In this paper we report the results of a studyin two global software development settings involving client-vendor relationships. In bothcases we noted that the vendor and client sites appropriated spreadsheet technology inquite specific ways; for use locally and for bridging across sites. Yet these spreadsheet fileswere embedded within different collaborative technologies. Through close study we notehow team members practices co-evolved with the spreadsheet artefacts involved in theprocess of managing requirements change. We note how through a single spreadsheet cell;we may see a world as in William Blake's" grain of sand". Through the evolution of a …,Global Software Engineering (ICGSE); 2014 IEEE 9th International Conference on,2014,12
Attack detection in recommender systems based on target item analysis,Wei Zhou; Junhao Wen; Yun Sing Koh; Shafiq Alam; Gillian Dobbie,Recommender systems are highly vulnerable to attacks. Attackers who introduce biasedratings in order to affect recommendations; have been shown to be effective againstcollaborative filtering algorithms. In this paper; we study the use of statistical metrics to detectrating patterns of attackers. Two metrics; Rating Deviation from Mean Agreement (RDMA)and Degree of Similarity with Top Neighbors (DegSim); are used for analysing ratingpatterns between malicious profiles and genuine profiles in shilling attacks. Building uponthis; we propose and evaluate an algorithm for detecting shilling attacks in recommendersystems using a statistical approach. We look at two attack models: random attack andaverage attack. The experimental results show that our detection technique based on targetitem analysis is an effective approach in detecting shilling attacks for both the random and …,Neural Networks (IJCNN); 2014 International Joint Conference on,2014,12
SPO-tree: efficient single pass ordered incremental pattern mining,Yun Sing Koh; Gillian Dobbie,Abstract Since the introduction of FP-growth using FP-tree there has been a lot of researchinto extending its usage to data stream or incremental mining. Most incremental miningadapts the Apriori algorithm. However; we believe that using a tree based approach wouldincrease performance as compared to the candidate generation and testing mechanismused in Apriori. Despite this FP-tree still requires two scans through a dataset. In this paperwe present a novel tree structure called Single Pass Ordered Tree SPO-Tree that capturesinformation with a single scan for incremental mining. All items in a transaction areinserted/sorted based on their frequency. The tree is reorganized dynamically whennecessary. SPO-Tree allows for easy maintenance in an incremental or data streamenvironment.,International Conference on Data Warehousing and Knowledge Discovery,2011,12
Finding interesting rare association rules using rare pattern tree,Sidney Tsang; Yun Sing Koh; Gillian Dobbie,Abstract Most association rule mining techniques concentrate on finding frequent rules.However; rare association rules are in some cases more interesting than frequentassociation rules since rare rules represent unexpected or unknown associations. All currentalgorithms for rare association rule mining use an Apriori level-wise approach which hascomputationally expensive candidate generation and pruning steps. We propose RP-Tree; amethod for mining a subset of rare association rules using a tree structure; and aninformation gain component that helps to identify the more interesting association rules.Empirical evaluation using a range of real world datasets shows that RP-Tree itemset andrule generation is more time efficient than modified versions of FP-Growth and ARIMA; anddiscovers 92-100% of all the interesting rare association rules. Additional evaluation …,*,2013,11
Reducing graph matching to tree matching for XML queries with ID references,Huayu Wu; Tok Wang Ling; Gillian Dobbie; Zhifeng Bao; Liang Xu,Abstract ID/IDREF is an important and widely used feature in XML documents for eliminatingdata redundancy. Most existing algorithms consider an XML document with ID references asa graph and perform graph matching for queries involving ID references. Graph matchingnaturally brings higher complexity compared with original tree matching algorithms thatprocess XML queries. In this paper; we make use of semantics of ID/IDREF to reduce graphmatching to tree matching to process queries involving ID references. Using our approach;an XML document with ID/IDREF is not treated as a graph; and a general query with IDreferences will be decomposed and processed using tree pattern matching techniques;which are more efficient than graph matching. Furthermore; our approach is able to handlecomplex ID references; such as cyclic references and sequential references; which …,International Conference on Database and Expert Systems Applications,2010,11
Validating ORA-SS data models using Alloy,Lin Wang; Gillian Dobbie; Jing Sun; Lindsay Groves,Semistructured data is typically represented using XML. However; little semantic informationcan be captured using XML. Other data models; such as the object relationship attribute datamodel for semistructured data (ORA-SS); have been introduced to represent more detailedsemantic information. Automatic analysis of the data models would enable us to revealinconsistencies both at the schema and instance levels of the semistructured data. The aimof this paper is to encode the semantics of the ORA-SS data model in the Alloy formallanguage and automatically validate the semistructured data design using the Alloyanalyzer. It enables us to check the consistency of an ORA-SS schema and its instances.,Software Engineering Conference; 2006. Australian,2006,11
Resolving ambiguities caused by multiple inheritance,Gillian Dobbie; Rodney Topor,Abstract In object-oriented languages; multiple inheritance can cause ambiguities whenmethods of the same name are inherited from more than one superclass of a given class. InC++; qualifiers can be used to explicitly state which method should be inherited. Wedescribe a mathematical foundation for an object-oriented language that uses qualifiers orroles to resolve such ambiguity. Our theory also allows us to model the role “super”. Forlanguages with dynamic overriding [1]; it further allows us to model monotonic inheritance ofmulti-valued methods. Finally; we describe a possible implementation of query evaluation inour language. This work extends that presented in [5].,International Conference on Deductive and Object-Oriented Databases,1995,11
Rare pattern mining on data streams,David Huang; Yun Sing Koh; Gillian Dobbie,Abstract There has been some research in the area of rare pattern mining where theresearchers try to capture patterns involving events that are unusual in a dataset. Thesepatterns are considered more useful than frequent patterns in some domain; includingdetection of computer attacks; or fraudulent credit transactions. Until now; most of theresearch in this area concentrates only on finding rare rules in a static dataset. There is aproliferation of applications which generate data streams; such as network logs and bankingtransactions. Applying techniques for static datasets is not practical for data streams. In thispaper we propose a novel approach called Streaming Rare Pattern Tree (SRP-Tree); whichfinds rare rules in a data stream environment using a sliding window; and show that it isfaster than current approaches.,International Conference on Data Warehousing and Knowledge Discovery,2012,10
Drift detection using stream volatility,David Tse Jung Huang; Yun Sing Koh; Gillian Dobbie; Albert Bifet,Abstract Current methods in data streams that detect concept drifts in the underlyingdistribution of data look at the distribution difference using statistical measures based onmean and variance. Existing methods are unable to proactively approximate the probabilityof a concept drift occurring and predict future drift points. We extend the current driftdetection design by proposing the use of historical drift trends to estimate the probability ofexpecting a drift at different points across the stream; which we term the expected driftprobability. We offer empirical evidence that applying our expected drift probability with thestate-of-the-art drift detector; ADWIN; we can improve the detection performance of ADWINby significantly reducing the false positive rate. To the best of our knowledge; this is the firstwork that investigates this idea. We also show that our overall concept can be easily …,Joint European Conference on Machine Learning and Knowledge Discovery in Databases,2015,9
SPAN: Finding collaborative frauds in online auctions,Sidney Tsang; Yun Sing Koh; Gillian Dobbie; Shafiq Alam,Abstract Fraud is an ongoing concern for online auction websites. Current methods to detector prevent fraud have been limited in several ways; making them difficult to apply in realworld settings. Firstly; existing methods cannot adapt to changes in the behaviour offraudulent users over time: new models must be continuously constructed as they graduallylose accuracy. In addition; each method can only be used to detect a specific type of fraud.Secondly; existing methods are generally poor at identifying collaborative frauds. Andthirdly; method training and evaluation has been limited by the quality of available datasets.We propose an algorithm named SPAN (Score Propagation over an Auction Network); fordetecting users committing collaborative fraud that addresses these problems. SPAN is atwo phase method that first applies anomaly detection on multiple 2-dimensional feature …,Knowledge-Based Systems,2014,9
WeightTransmitter: weighted association rule mining using landmark weights,Yun Sing Koh; Russel Pears; Gillian Dobbie,Abstract Weighted Association Rule Mining (WARM) is a technique that is commonly used toovercome the well-known limitations of the classical Association Rule Mining approach. Theassignment of high weights to important items enables rules that express relationshipsbetween high weight items to be ranked ahead of rules that only feature less importantitems. Most previous research to weight assignment has used subjective measures to assignweights and are reliant on domain specific information. Whilst there have been a fewapproaches that automatically deduce weights from patterns of interaction between items;none of them take advantage of the situation where weights of only a subset of items areknown in advance. We propose a model; WeightTransmitter; that interpolates the unknownweights from a known subset of weights.,Pacific-Asia Conference on Knowledge Discovery and Data Mining,2012,9
An XML document generator for semantic query optimization experimentation,Ke Geng; Gillian Dobbie,Purpose–XML semantic query optimization (XSQO) is an important area in eXtensibleMarkup Language (XML) query processing. However; the experiments evaluating semanticoptimization methods often suffer because of the lack of suitable data sets. To evaluateXSQO methods it is necessary to be able to build datasets with specific characteristics. Inparticular; it is necessary to be able to set: selectivity of embedded elements; selectivity ofvalues of elements; depth; fan-out and size. The aim of this paper is to describe therequirements of such a generator; and the challenges of building the generator.Design/methodology/approach–The paper considers that there is currently no generator thatgives this flexibility; so the paper discusses the design and building of such a generator.Findings–The main characteristic of the generator is that it is possible to adapt existing …,International Journal of Web Information Systems,2007,9
Validating semistructured data using OWL,Yuan Fang Li; Jing Sun; Gillian Dobbie; Jun Sun; Hai H Wang,Abstract Semistructured data has become prevalent in both web applications and databasesystems. This rapid growth in use makes the design of good semistructured data essential.Formal semantics and automated reasoning tools enable us to reveal the inconsistencies ina semistructured data model and its instances. The Object Relationship Attribute model forSemistructured data (ORA-SS) is a graphical notation for designing and representingsemistructured data. This paper presents a methodology of encoding the semantics of ORA-SS in the Web Ontology Language (OWL) and automatically validating the semistructureddata design using the OWL reasoning tool–RACER. Our methodology provides automatedconsistency checking of an ORA-SS data model at both the schema and instance levels.,International Conference on Web-Age Information Management,2006,9
Finding maximal overlapping communities,Eileen H-C Wei; Yun Sing Koh; Gillian Dobbie,Abstract Social networks play an important role in everyday life. Nowadays there is variousresearch that concentrates on detecting communities within these networks. Traditionallymost of the community detection algorithms focus on detecting disjoint networks. Howeverthere is a need for overlapping community detection. In recent years there have been someattempts at detecting overlapping communities. Most of these techniques concentrate on justdetecting these communities; none of this research tries to detect the maximal set of thesecommunities which gives more stability. In this paper we propose a new method calledMaximal-DSHRINK that allows us to detect the maximal set of overlapping communitieswithin a social network. We show that the maximal set provides us with better quality in termsof modularity gain.,International Conference on Data Warehousing and Knowledge Discovery,2013,8
Evaluating fraud detection algorithms using an auction data generator,Sidney Tsang; Gillian Dobbie; Yun Sing Koh,Online auction sites are a target for fraud. Researchers have developed fraud detection andprevention methods. However; there are difficulties when using either commercial orsynthetic auction data to evaluate the effectiveness of these methods. When usingcommercial data; it is not possible to accurately identify cases of fraud. Using synthetic data;the conclusions drawn may not extend to the real world. The availability of realistic syntheticauction data; which models real auction data; will be invaluable for effective evaluation offraud detection algorithms. We present an agent-based simulator that is capable ofgenerating realistic English auction data. The agents and model are based on data collectedfrom the Trade Me online auction site. We evaluate the generated data in two ways to showthat it is similar to the Trade Me auction data we have collected. In addition; we …,Data Mining Workshops (ICDMW); 2012 IEEE 12th International Conference on,2012,8
A lightweight stream-based join with limited resource consumption,M Asif Naeem; Gillian Dobbie; Gerald Weber,Abstract Many stream-based applications have plenty of resources available to them; butthere are also applications where resource consumption must be limited. For one importantclass of stream-based joins; where a stream is joined with a non-stream master data set; thealgorithm called MESHJOIN was proposed. MESHJOIN uses limited memory and is acandidate for a resource-aware system setup. The problem that is considered in this paper isthat MESHJOIN is not very selective. In particular; the performance of the algorithm is alwaysinversely proportional to the size of the master data table. As a consequence; the resourceconsumption is in some scenarios sub-optimal. We present an algorithm CACHEJOIN;which performs asymptotically at least as well as MESHJOIN but performs better in realisticscenarios; particularly if parts of the master data are used with different frequencies. In …,International Conference on Data Warehousing and Knowledge Discovery,2012,8
Towards recommender system using particle swarm optimization based web usage clustering,Shafiq Alam; Gillian Dobbie; Patricia Riddle,Abstract Efficiency and quality of the product of data mining process is a challengingquestion for the researchers. Different methods have been proposed in the literature totackle these problems. Optimization based methods are a way to address this issue. Weaddressed the problem of data clustering by implementing swarm intelligence basedoptimization technique called Particle Swarm Optimization (PSO). We scaled the approachto implement it in a hierarchical way using Hierarchical Particle Swarm (HPSO) clustering.The paper also aims to outline our novel outlier detection technique. The research will leadus to provide a benchmark for web usage mining and propose a collective intelligencebased recommender system for the usage of Java API documentation.,Pacific-Asia Conference on Knowledge Discovery and Data Mining,2011,8
AZ Approach in Validating ORA-SS Data Models,Scott Uk-Jin Lee; Jing Sun; Gillian Dobbie; Yuan Fang Li,Abstract The rapid growth of the World Wide Web has resulted in more data being accessedover the Internet. In turn there is an increase in the use of semistructured data; which plays acrucial role in many web applications particularly with the introduction of XML and its relatedtechnologies. This increase in use makes the design of good semistructured data structuresessential. The Object Relationship Attribute model for Semistructured data (ORA-SS) is agraphical notation for designing and representing semistructured data. In this paper; wedemonstrate an approach to formally validate the ORA-SS data models in order to enhancethe correctness of semistructured data design. A mathematical semantics for the ORA-SSnotation is defined using the Z formal language; and further validation processes are carriedout to check the correctness of the semistructured data models at both the schema and …,Electronic Notes in Theoretical Computer Science,2006,8
Shilling attacks detection in recommender systems based on target item analysis,Wei Zhou; Junhao Wen; Yun Sing Koh; Qingyu Xiong; Min Gao; Gillian Dobbie; Shafiq Alam,Recommender systems are highly vulnerable to shilling attacks; both by individuals andgroups. Attackers who introduce biased ratings in order to affect recommendations; havebeen shown to negatively affect collaborative filtering (CF) algorithms. Previous researchfocuses only on the differences between genuine profiles and attack profiles; ignoring thegroup characteristics in attack profiles. In this paper; we study the use of statistical metrics todetect rating patterns of attackers and group characteristics in attack profiles. Anotherquestion is that most existing detecting methods are model specific. Two metrics; RatingDeviation from Mean Agreement (RDMA) and Degree of Similarity with Top Neighbors(DegSim); are used for analyzing rating patterns between malicious profiles and genuineprofiles in attack models. Building upon this; we also propose and evaluate a detection …,PloS one,2015,7
Towards unified ad-hoc data processing,Xiaogang Shi; Bin Cui; Gillian Dobbie; Beng Chin Ooi,Abstract It is important to provide efficient execution for ad-hoc data processing programs. Incontrast to constructing complex declarative queries; many users prefer to write theirprograms using procedural code with simple queries. As many users are not expertprogrammers; their programs usually exhibit poor performance in practice and it is achallenge to automatically optimize these programs and efficiently execute the programs. Inthis paper; we present UniAD; a system designed to simplify the programming of dataprocessing tasks and provide efficient execution for user programs. We propose a novelintermediate representation named UniQL which utilizes HOQs to describe the operationsperformed in programs. By combining both procedural and declarative logics; we canperform various optimizations across the boundary between procedural and declarative …,Proceedings of the 2014 ACM SIGMOD International Conference on Management of Data,2014,7
EWgen: automatic generation of item weights for weighted association rule mining,Russel Pears; Yun Sing Koh; Gillian Dobbie,Abstract Association Rule Mining is an important data mining technique that has beenwidely used as an automatic rule generation method. While having outstanding success inmany different application domains; it also has the potential to generate a vast number ofrules; many of which are of little interest to the user. Weighted Association Rule Mining(WARM) overcomes this problem by assigning weights to items thus enabling interestingrules to be ranked ahead of less interesting ones and making it easier for the user todetermine which rules are the most useful. Past research on WARM assumes that usershave the necessary knowledge to supply item weights. In this research we relax thisassumption by deriving item weights based on interactions between items. Ourexperimentation shows that the rule bases produced by our scheme produces more …,International Conference on Advanced Data Mining and Applications,2010,7
Xdo2: A deductive object-oriented query language for xml,Wei Zhang; Tok Wang Ling; Zhuo Chen; Gillian Dobbie,Abstract In the past decade; researchers have combined deductive and object-orientedfeatures to produce systems that are powerful and have excellent modeling capabilities.More recently; an XML query language XTree was proposed. Queries written in XTree aremore compact; more convenient to write and easier to understand than queries written inXPath. In this paper; we introduce a novel XML query language XDO2 that extends XTree;with deductive features such as deductive rules and negation; and object-oriented featuressuch as inheritance and methods. Our XDO2 language is more compact; and convenient touse than current query languages for XML such as XQuery and XPath because it is basedon XTree; supports (recursive) deductive rules and the not-predicate. An XDO2 databaseexample is given to motivate the usefulness of the language. The formal treatment of …,International Conference on Database Systems for Advanced Applications,2005,7
Experience teaching CS1 with Java,Peter Andreae; Robert Biddle; Gill Dobbie; Amy Gale; Linton Miller; Ewan Tempero,Abstract: We describe our experiences teaching our CS1 course with Java. Java has anumber of features that complicate using it to teach introductory programming. Although wedesigned our course to deal with these features; there were some surprises in how thecourse worked out. We discuss the underlying cause of these surprises.,Journal of Computer Science Education,2000,7
Optimised X-HYBRIDJOIN for near-real-time data warehousing,M Asif Naeem; Gillian Dobbie; Gerald Weber,Abstract Stream-based join algorithms are needed in modern near-real-time datawarehouses. A particular class of stream-based join algorithms; with MESHJOIN as a typicalexample; computes the join between a stream and a disk-based relation. Recently we havepresented a new algorithm X-HYBRIDJOIN (Extended Hybrid Join) in that class. X-HYBRIDJOIN achieves better performance compared to earlier algorithms by pinningfrequently accessed data from the disk-based relation in main memory. Apart from beingheld in main memory; X-HYBRIDJOIN treats this frequently accessed data no differently thanother data from the disk-based relation. In this paper we investigate whether performancecan be improved by treating the frequently accessed data differently. We present a newalgorithm called Optimised X-HYBRIDJOIN; which consists of two phases. One phase …,Proceedings of the Twenty-Third Australasian Database Conference-Volume 124,2012,6
Survey of XML semantic query optimization,Ke Geng; Gillian Dobbie; Yulong Meng,There has been a lot of research into XML query optimization. In this paper; we focus onseveral techniques for XML semantic query optimization; which improve the query executionbased on the information abstracted from the XML documents. The optimization methods willbe discussed in two groups: optimization based on structure and optimization based oncontent. The query optimization mechanisms of each optimization method are discussedand compared.,Internet Computing for Science and Engineering (ICICSE); 2009 Fourth International Conference on,2009,6
A semantic approach to query rewriting for integrated XML data,Xia Yang; Mong Li Lee; Tok Wang Ling; Gillian Dobbie,Abstract Query rewriting is a fundamental task in query optimization and data integration.With the advent of the web; there has been renewed interest in data integration; where datais dispersed among many sources and an integrated view over these sources is provided.Queries on the integrated view are rewritten to query the underlying source repositories. Inthis paper; we develop a novel algorithm for rewriting queries that considers the XMLhierarchy structure and the semantic relationship between the source schemas and theintegrated schema. Our approach is based on the semantically rich Object-Relationship-Attribute model for SemiStructured data (ORA-SS); and guarantees that the rewritten queriesgive the expected results; even where the integrated view is complex.,International Conference on Conceptual Modeling,2005,6
Object oriented database systems: A survey,G Dobbie,*,Department of Computer Science; The University of Melbourne; Melbourne,1990,6
SQL data profiling of foreign keys,Mozhgan Memari; Sebastian Link; Gillian Dobbie,Abstract Referential integrity is one of the three inherent integrity rules and can be enforcedin databases using foreign keys. However; in many real world applications referentialintegrity is not enforced since foreign keys remain disabled to ease data acquisition.Important applications such as anomaly detection; data integration; data modeling; indexing;reverse engineering; schema design; and query optimization all benefit from the discovery offoreign keys. Therefore; the profiling of foreign keys from dirty data is an important yetchallenging task. We raise the challenge further by diverting from previous research in whichnull markers have been ignored. We propose algorithms for profiling unary and multi-columnforeign keys in the real world; that is; under the different semantics for null markers of theSQL standard. While state of the art algorithms perform well in the absence of null …,International Conference on Conceptual Modeling,2015,5
Group-by and aggregate functions in XML keyword search,Thuy Ngoc Le; Zhifeng Bao; Tok Wang Ling; Gillian Dobbie,Abstract In this paper; we study how to support group-by and aggregate functions in XMLkeyword search. It goes beyond the simple keyword query; and raises several challengesincluding:(1) how to address the keyword ambiguity problem when interpreting a keywordquery;(2) how to identify duplicated objects and relationships in order to guarantee thecorrectness of the results of aggregation functions; and (3) how to compute a keyword querywith group-by and aggregate functions. We propose an approach to address the abovechallenges. As a result; our approach enables users to explore the data as much as possiblewith simple keyword queries. The experimental results on real datasets demonstrate that ourapproach can support keyword queries with group-by and aggregate functions which are notaddressed by the LCA-based approaches while achieving a similar response time to that …,International Conference on Database and Expert Systems Applications,2014,5
Theorem prover approach to semistructured data design,Scott Uk-Jin Lee; Gillian Dobbie; Jing Sun; Lindsay Groves,Abstract The wide adoption of semistructured data has created a growing need for effectiveways to ensure the correctness of its organization. One effective way to achieve this goal isthrough formal specification and automated verification. This paper presents a theoremproving approach towards verifying that a particular design or organization of semistructureddata is correct. We formally specify the semantics of the Object Relationship Attribute datamodel for Semistructured Data (ORA-SS) modeling notation and its correctness criteria forsemistructured data normalization using the Prototype Verification System (PVS). The resultis that effective verification on semistructured data models and their normalization can becarried out using the PVS theorem prover.,Formal Methods in System Design,2010,5
Comparing global optimization and default settings of stream-based joins,M Asif Naeem; Gillian Dobbie; Gerald Weber,Abstract One problem encountered in real-time data integration is the join of a continuousincoming data stream with a disk-based relation. In this paper we investigate a stream-based join algorithm; called mesh join (MESHJOIN); and focus on a critical component in thealgorithm; called the disk-buffer. In MESHJOIN the size of disk-buffer varies with a change intotal memory budget and tuning is required to get the maximum service rate within limitedavailable memory. Until now there was little data on the position of the optimum valuedepending on the memory size; and no performance comparison has been carried outbetween the optimum and reasonable default sizes for the disk-buffer. To avoid tuning; wepropose a reasonable default value for the disk-buffer size with a small and acceptableperformance loss. The experimental results validate our arguments.,International Workshop on Business Intelligence for the Real-Time Enterprise,2009,5
Web bots detection using particle swarm optimization based clustering,Shafiq Alam; Gillian Dobbie; Yun Sing Koh; Patricia Riddle,Optimization based techniques have emerged as important methods to tackle the problemsof efficiency and accuracy in data mining. One of the current application areas is outlierdetection that has not been fully explored yet but has enormous potential. Web bots are anexample of outliers; which can be found in the web usage analysis process. Web botrequests are different from a genuine web user as web bots crawl large numbers of pages ina very short time. If web bots remains undetected they can skew the analysis process whichcan result in incorrect patterns that can cause wrong decisions. In this paper we use one ofthe popular Swarm Intelligence (SI) based techniques called Particle Swarm Optimization(PSO) to detect web bots among genuine user requests. We use our Particle SwarmOptimization (PSO) based clustering algorithm; Hierarchical Particle Swarm Optimization …,Evolutionary Computation (CEC); 2014 IEEE Congress on,2014,4
SSCJ: A semi-stream cache join using a front-stage cache module,M Asif Naeem; Gerald Weber; Gillian Dobbie; Christof Lutteroth,Abstract Semi-stream processing has become an emerging area of research in the field ofdata stream management. One common operation in semi-stream processing is joining astream with disk-based master data using a join operator. This join operator typically worksunder limited main memory and this memory is generally not large enough to hold the wholedisk-based master data. Recently; a number of semi-stream join algorithms have beenproposed in the literature to achieve an optimal performance but still there is room toimprove the performance. In this paper we propose a novel Semi-Stream Cache Join (SSCJ)using a front-stage cache module. The algorithm takes advantage of skewed distributions;and we present results for Zipfian distributions of the type that appear in many applications.We analyze the performance of SSCJ with a well known related join algorithm …,International Conference on Data Warehousing and Knowledge Discovery,2013,4
Analysis of web usage data for clustering based recommender system,Shafiq Alam; Gillian Dobbie; Patricia Riddle; Yun Sing Koh,Abstract Implicit web usage data is sparse and noisy and cannot be used for usageclustering unless passed through a sophisticated pre-processing phase. In this paper wepropose a systematic way to analyze and preprocess the web usage data so that dataclustering can be applied effectively to extract similar groups of user. We split the entireprocess into analysis; preprocessing and outlier detection and show the effect of each phaseon Java Application Programming Interface (API) documentation usage data that is collectedfrom our server logs. We use the extracted clusters for web based recommender systemsand present the accuracy of the recommendations.,*,2013,4
Generating realistic online auction data,Sidney Tsang; Gillian Dobbie; Yun Sing Koh,Abstract To combat online auction fraud; researchers have developed fraud detection andprevention methods. However; it is difficult to effectively evaluate these methods usingcommercial or synthetic auction data. For commercial data; it is not possible to accuratelyidentify cases of fraud. For synthetic auction data; the conclusions drawn may not extend tothe real world. The availability of realistic synthetic auction data; which models real auctiondata; will be invaluable for effective evaluation of fraud detection algorithms. We present anagent-based simulator that is capable of generating realistic English auction data. Theagents and model are based on data collected from the TradeMe online auction site. Weevaluate the generated data in two ways to show that it is similar to the TradeMe data.Evaluation of individual features show that correlation is greater than 0.9 for 8 of the 10 …,Australasian Joint Conference on Artificial Intelligence,2012,4
Extrapolation prefix tree for data stream mining using a landmark model,Yun Sing Koh; Russel Pears; Gillian Dobbie,Abstract Since the introduction of FP-growth there has been extensive research intoextending its usage to data streams or incremental mining. This task is particularlychallenging in the data stream environment because of the unbounded nature of a datastream and the need for avoiding multiple scans of the data. In this paper; we propose analgorithm; Extrapolation Prefix Tree that extracts frequent itemsets using a landmarkwindowing scheme. The algorithm uses a prefix tree structure to store arriving transactions;but unlike previous approaches estimates the structure of the tree in the next block of databased on the arrival pattern of items appearing in transactions that arrive in the currentblock. Our experimentation shows that Extrapolation-Tree significantly outperforms the CP-Tree; both in terms of the number of updates and the execution time required to keep the …,International Conference on Data Warehousing and Knowledge Discovery,2012,4
Automatic assignment of item weights for pattern mining on data streams,Yun Sing Koh; Russel Pears; Gillian Dobbie,Abstract Research in Weighted Association Rule Mining (WARM) has largely concentratedon mining traditional static transactional datasets. Whilst there have been a few attempts atresearching WARM in a data stream environment; none have addressed the problem ofassigning and adapting weights in the presence of concept drift; which often occurs in a datastream environment. In this research we experiment with two methods of adapting weights;firstly; a simplistic method that recomputes the entire set of weights at fixed intervals; andsecondly a method that relies on a distance function that assesses the extent of change inthe stream and only updates those items that have had significant change in their patterns ofinteraction. We show that the latter method is able to maintain good accuracy whilst beingseveral times faster than the former.,Pacific-Asia Conference on Knowledge Discovery and Data Mining,2011,4
Element classification-based transformation of XML queries,Ke Geng; Gillian Dobbie,Purpose–Engines have been built that execute queries against XML data. The aim of thispaper is to describe a novel technique that can be used to improve the speed of execution ofthe queries based on semantics of the data in the XML document. Design/methodology/approach–The paper formally introduces algorithms for optimizing XML queries; implementthe algorithms; and through experimentation demonstrate the improvement in speed.Findings–Three possible semantic query optimizations based on the values of elementswere introduced and these demonstrate that two of the three optimizations improve queryperformance but the third does not. It is hypothesized why this is the case. Researchlimitations/implications–A limitation is obviously the query engine and how it works. Futurework includes; executing the experiments on a different engine and comparing results …,International Journal of Web Information Systems,2008,4
Teaching software engineering in a computer science department,Gillian Dobbie; Guszti Bartfai,This paper discusses four issues that are related to teaching software engineering; whichthe authors have found of particular relevance with respect to the computer scienceprogramme offered by the Department of Computer Science at Victoria University ofWellington; New Zealand. These issues are programming vs. software engineering;structured vs. object-oriented methods; textbook selection and assessment of project work.Underlying these issues is the question of how industrial experience can be taught orsimulated in software engineering courses. The aim of this paper is to share our experienceshoping to stimulate further discussion on how software engineering can best be taught.,Software Engineering: Education and Practice; 1996. Proceedings. International Conference,1996,4
From Design to Code: An Educational Approach.,Candice Eckert; Brian Cham; Jing Sun; Gillian Dobbie,Abstract—Model Driven Engineering (MDE); despite having many advantages; is oftenoverlooked by programmers due to lack of proper understanding and training in the matter.This paper investigates the advantages and disadvantages of MDE and looks at researchresults showing the adoption rates of design models. In light of the findings; an educationaltool; namely Lorini; was developed to provide automated code generation from the designmodels. The implemented tool consists in a plug-in for the Astah framework aimed atteaching Java programming to students through UML diagrams. It features instantaneouscode generation from three types of UML diagrams; code-diagram matching; a feedbackpanel for error displays and on-the-fly compilation and execution of the resulting program.Evaluation of the tool indicated it to be successful with unique educational features and …,SEKE,2016,3
Phishing Detection on Twitter Streams,Se Yeong Jeong; Yun Sing Koh; Gillian Dobbie,Abstract With the prevalence of cutting-edge technology; the social media network is gainingpopularity and is becoming a worldwide phenomenon. Twitter is one of the most widely usedsocial media sites; with over 500 million users all around the world. Along with its rapidlygrowing number of users; it has also attracted unwanted users such as scammers;spammers and phishers. Research has already been conducted to prevent such issuesusing network or contextual features with supervised learning. However; these methods arenot robust to changes; such as temporal changes or changes in phishing trends. Currenttechniques also use additional network information. However; these techniques cannot beused before spammers form a particular number of user relationships. We propose anunsupervised technique that detects phishing in Twitter using a 2-phase unsupervised …,Pacific-Asia Conference on Knowledge Discovery and Data Mining,2016,3
Detecting changes in rare patterns from data streams,David Tse Jung Huang; Yun Sing Koh; Gillian Dobbie; Russel Pears,Abstract Current drift detection techniques in data streams focus on finding changes instreams with labeled data intended for supervised machine learning methods. Up to nowthere has been no research that considers drift detection on item based data streams withunlabeled data intended for unsupervised association rule mining. In this paper we addressand discuss the current issues in performing drift detection of rare patterns in data streamsand present a working approach that enables the detection of rare pattern changes. Wepropose a novel measure; called the M measure; that facilitates pattern change detectionand through our experiments we show that this measure can be used to detect changes inrare patterns in data streams efficiently and accurately.,Pacific-Asia Conference on Knowledge Discovery and Data Mining,2014,3
TP+ Output: modeling complex output information in XML twig pattern query,Huayu Wu; Tok Wang Ling; Gillian Dobbie,Abstract Twig pattern is considered a core pattern for XML queries. However; due to thelimited expressivity of twig pattern expressions; many queries that aim to find complex outputinformation under one object cannot be expressed in a single twig pattern. Instead; theyhave to be expressed as XQuery expression; which is transformed into several twig patternslinked by joins. To process such an XQuery query; we need to match multiple twig patternsto the XML document; even though they are all centered on the same object. In this paperwe analyze the characteristics of each query node; ie the purpose; optionality andoccurrence; and define four types of nodes in a twig pattern query to express outputinformation; namely; output node; optional-output node; predicated-output node; andoptional-predicated-output node. Then we propose the TP+ Output expression to extend …,International XML Database Symposium,2010,3
Sketching ER diagrams,Paul Schmieder; Beryl Plimmer; Gillian Dobbie,Abstract Hand-drawn diagrams are frequently used as the first visualization of a model.Converting these preliminary diagrams into a specific formal format is time consuming.Computer based sketch-tools can offer support during the informal sketching stage andautomatic conversion to formal representations. Entity Relationship diagrams are particularlydifficult to convert because of their characteristics such as cardinality notations. We extendthe general diagram sketching tool InkKit with domain semantics to successfully recognizeand automatically convert Entity Relationship diagrams. This approach takes advantage ofsketching as the preferred initial design realization while minimizing the effort required totranslate the initial design to a functional prototype.,Proceedings of the Tenth Australasian Conference on User Interfaces-Volume 93,2009,3
Formal Verification of Semistructured Data Models in PVS.,Scott Uk-Jin Lee; Gillian Dobbie; Jing Sun; Lindsay Groves,Abstract: The rapid growth of the World Wide Web has resulted in a dramatic increase insemistructured data usage; creating a growing need for effective and efficient utilization ofsemistructured data. In order to verify the correctness of semistructured data design; precisedescriptions of the schemas and transformations on the schemas must be established. Oneeffective way to achieve this goal is through formal modeling and automated verification.This paper presents the first step towards this goal. In our approach; we have formallyspecified the semantics of the ORA-SS (Object-Relationship-Attribute data model forSemistructured data) data modeling language in PVS (Prototype Verification System) andprovided automated verification support for both ORA-SS schemas and XML (ExtensibleMarkup Language) data instances using the PVS theorem prover. This approach …,J. UCS,2009,3
Efficient parameter learning of Bayesian network classifiers,Nayyar A Zaidi; Geoffrey I Webb; Mark J Carman; François Petitjean; Wray Buntine; Mike Hynes; Hans De Sterck,Abstract Recent advances have demonstrated substantial benefits from learning with bothgenerative and discriminative parameters. On the one hand; generative approachesaddress the estimation of the parameters of the joint distribution—P (y; x) P (y; x); which formost network types is very computationally efficient (a notable exception to this are Markovnetworks) and on the other hand; discriminative approaches address the estimation of theparameters of the posterior distribution—and; are more effective for classification; since theyfit P (y| x) P (y| x) directly. However; discriminative approaches are less computationallyefficient as the normalization factor in the conditional log-likelihood precludes the derivationof closed-form estimation of parameters. This paper introduces a new discriminativeparameter learning method for Bayesian network classifiers that combines in an elegant …,Machine Learning,2017,2
Adventures of categories: Modelling the evolution of categories during scientific investigation,Prashant Gupta; Mark Gahegan; Gillian Dobbie,Categories are the fundamental components of scientific knowledge and are used in everyphase of the scientific process. However; they are often in a state of flux; with newobservations; discoveries and changes in our conceptual understanding leading to the birthand death of categories; drift in their identities; as well as merging or splitting. Contemporaryresearch tools rarely support such changes in operationalized categories; neglecting theproblem of capturing and utilizing the knowledge lurking behind the process of change. Thispaper presents a tool--AdvoCate1--that represents the dynamic nature of categories. Itallows category evolution to be modelled; while maintaining a category versioning systemthat captures all the different versions of a category; along with the process of its explorationand evolution through use. This helps us to better understand and communicate different …,e-Science (e-Science); 2015 IEEE 11th International Conference on,2015,2
Fast disjoint and overlapping community detection,Yi Song; Stéphane Bressan; Gillian Dobbie,Abstract We propose algorithms for the detection of disjoint and overlapping communities innetworks. The algorithms exploit both the degree and clustering coefficient of vertices asthese metrics characterize dense connections; which we hypothesize as being indicative ofcommunities. Each vertex independently seeks the community to which it belongs; byvisiting its neighboring vertices and choosing its peers on the basis of their degrees andclustering coefficients. The algorithms are intrinsically data parallel. We devise a version forGraphics Processing Unit (GPU). We empirically evaluate the performance of our methods.We measure and compare their efficiency and effectiveness to several state-of-the-artcommunity detection algorithms. Effectiveness is quantified by metrics; namely; modularity;conductance; internal density; cut ratio; weighted community clustering and normalized …,*,2015,2
Optimizing queue-based semi-stream joins with indexed master data,M Asif Naeem; Gerald Weber; Christof Lutteroth; Gillian Dobbie,Abstract In Data Stream Management Systems (DSMS) semi-stream processing hasbecome a popular area of research due to the high demand of applications for up-to-dateinformation (eg in real-time data warehousing). A common operation in stream processing isjoining an incoming stream with disk-based master data; also known as semi-stream join.This join typically works under the constraint of limited main memory; which is generally notlarge enough to hold the whole disk-based master data. Many semi-stream joins use aqueue of stream tuples to amortize the disk access to the master data; and use an index toallow directed access to master data; avoiding the loading of unnecessary master data. Insuch a situation the question arises which master data partitions should be accessed; as anystream tuple from the queue could serve as a lookup element for accessing the master …,International Conference on Data Warehousing and Knowledge Discovery,2014,2
Semantic path ranking scheme for relational keyword queries,Zhong Zeng; Zhifeng Bao; Gillian Dobbie; Mong Li Lee; Tok Wang Ling,Abstract Existing works on keyword search over relational databases typically do notconsider users' search intention for a query and return many answers which oftenoverwhelm users. We observe that a database is in fact a repository of real world objects thatinteract with each other via relationships. In this work; we identify four types of semanticpaths between objects and design an algorithm called pathRank to compute and rank theresults of keyword queries. The answers are grouped by the types of semantic paths whichreflect different query interpretations; and are annotated to facilitate user understanding.,International Conference on Database and Expert Systems Applications,2014,2
Biologically-inspired Techniques for Knowledge Discovery and Data Mining,Shafiq Alam,Biologically-inspired data mining has a wide variety of applications in areas such as dataclustering; classification; sequential pattern mining; and information extraction in healthcareand bioinformatics. Over the past decade; research materials in this area have dramaticallyincreased; providing clear evidence of the popularity of these techniques. Biologically-Inspired Techniques for Knowledge Discovery and Data Mining exemplifies prestigiousresearch and shares the practices that have allowed these areas to grow and flourish. Thisessential reference publication highlights contemporary findings in the area of biologically-inspired techniques in data mining domains and their implementation in real-life problems.Providing quality work from established researchers; this publication serves to extendexisting knowledge within the research communities of data mining and knowledge …,*,2014,2
Biologically Inspired Techniques for Data Mining: A Brief Overview of Particle,Shafiq Alam; Gillian Dobbie; Yun Sing Koh; Saeed ur Rehman,ABSTRACT Knowledge Discovery and Data (KDD) mining helps uncover hidden knowledgein huge amounts of data. However; recently; different researchers have questioned thecapability of traditional KDD techniques to tackle the information extraction problem in anefficient way while achieving accurate results when the amount of data grows. One of theways to overcome this problem is to treat data mining as an optimization problem. Recently;a huge increase in the use of Swarm Intelligence (SI)-based optimization techniques forKDD has been observed due to the flexibility; simplicity; and extendibility of thesetechniques to be used for different data mining tasks. In this chapter; the authors overviewthe use of Particle Swarm Optimization (PSO); one of the most cited SI-based techniques inthree different application areas of KDD; data clustering; outlier detection; and …,Biologically-Inspired Techniques for Knowledge Discovery and Data Mining,2014,2
Web usage mining based recommender systems using implicit heterogeneous data,Shafiq Alam; Gillian Dobbie; Yun Sing Koh; Patricia Riddle,Abstract Recommender systems have become one of the necessary tools to help a web userfind a potentially interesting resource based on their preferences. In implicit recommendersystems; the recommendations are made based on the implicit information of the web usersie data collected from web logs or cookies without knowing users preferences. Developingsuch a recommender system is complex due to the huge amount of anonymous noisy data.In this paper we present a Particle Swarm Optimization (PSO) based clustering approachcalled Hierarchical Particle Swarm Optimization based clustering (HPSO-clustering) forbuilding a recommender system based on implicit web usage data. The approach mimicsmulti-agent properties of the particles of a swarm and divide the problem space into smallersub-spaces ie clusters. Each cluster represents a particular group of user with similar …,Web Intelligence and Agent Systems: An International Journal,2014,2
Tracking drift types in changing data streams,David TJ Huang; Yun Sing Koh; Gillian Dobbie; Russel Pears,Abstract The rate of change of drift in a data stream can be of interest. It could show; forexample; that a strand of bacteria is becoming more resistant to a drug; or that a machine isbecoming unreliable and requires maintenance. While concept drift in data streams hasbeen widely studied; no one has studied the rate of change in concept drift. In this paper wedefine three new drift types: relative abrupt drift; relative moderate drift and relative gradualdrift. We propose a novel algorithm that tracks changes in drift intensity relative to previousdrift points within the stream. The algorithm is based on mapping drift patterns to a Gaussianfunction. Our experimental results show that the algorithm is robust and achieving accuracylevels above 90%.,International Conference on Advanced Data Mining and Applications,2013,2
Verb selection using semantic role labeling for citation classification,Mohammad Abdullatif; Yun Sing Koh; Gillian Dobbie; Shafiq Alam,Abstract Citation classification is the task of assigning a category to a reference or citation.The current sets of categories or classes proposed in the literature vary in size and they arebased on the analysis of a small sample of citation sentences. We are developing a processto automatically generate such categories and base them on the analysis of a large corpusof papers. Part of the generation process involves selecting the main verb relevant to thereference being cited in the sentence. In this paper we present our recently developedtechnique that automatically identifies the relevant verb in a citation sentence. The techniqueuses heuristic rules; which are dependent on the results of a semantic role labeler. Four testsets were collected; and the common annotations of the test sets annotated by three peoplewere used to assess the accuracy of the rules. Through experimentation we show that the …,Proceedings of the 2013 workshop on Computational scientometrics: theory & applications,2013,2
A generic front-stage for semi-stream processing,M Asif Naeem; Gerald Weber; Gillian Dobbie; Christof Lutteroth,Abstract Recently; a number of semi-stream join algorithms have been published. Thetypical system setup for these consists of one fast stream input that has to be joined with adisk-based relation R. These semi-stream join approaches typically perform the join with alimited main memory partition assigned to them; which is generally not large enough to holdthe whole relation R. We propose a caching approach that can be used as a front-stage fordifferent semi-stream join algorithms; resulting in significant performance gains for commonapplications. We analyze our approach in the context of a seminal semi-stream join;MESHJOIN (Mesh Join); and provide a cost model for the resulting semi-stream joinalgorithm; which we call CMESHJOIN (Cached Mesh Join). The algorithm takes advantageof skewed distributions; this article presents results for Zipfian distributions of the type that …,Proceedings of the 22nd ACM international conference on Information & Knowledge Management,2013,2
Web services testing via goal and mutation,M Shaban Jokhio; Gillian Dobbie; Jing Sun; Tianming Hu,Semantic Web Services (SWS) introduce a semantic layer to the current web infrastructure;enabling the automated processing of web tasks. Different frameworks have been proposedfor designing SWS; however; there has been little research in the area of testing SWS.Generating test cases for SWS is challenging due to its dynamic nature and abstract views;evaluating the test cases is equally essential in order to ensure the quality of the test suite. Inthis paper; we propose a goal oriented generation and mutation based evaluation approachtowards SWS testing. This way; the generation (model-based) and evaluation (code-based)procedures are totally independent to each other; which further provides a much accuratemeasurement on the results. In addition; a tool support has been developed to automate themajor steps in the proposed solution.,Engineering of Complex Computer Systems (ICECCS); 2013 18th International Conference on,2013,2
Efficient single pass ordered incremental pattern mining,Yun Sing Koh; Gillian Dobbie,Abstract Since the introduction of FP-growth using FP-tree there has been a lot of researchinto extending its usage to data stream or incremental mining. Most incremental miningadapts the Apriori algorithm. However; we believe that using a tree based approach wouldincrease performance as compared to the candidate generation and testing mechanismused in Apriori. Despite this; FP-tree still requires two scans through a dataset. In this paperwe present a novel tree structure called Single Pass Ordered Tree; SPO-Tree; that capturesinformation with a single scan for incremental mining. All items in a transaction areinserted/sorted based on their frequency. The tree is reorganized dynamically whennecessary. SPO-Tree allows for easy maintenance in an incremental or data streamenvironment.,*,2013,2
Indirect weighted association rules mining for academic network collaboration recommendations,Yun Sing Koh; Gillian Dobbie,Abstract Collaborative research is increasingly important and popular in academic circles.However for young researchers identifying new research collaborators to form joint researchand analyzing the level of cooperation of the current partners can be a very complex task.Thus recommendation of new collaborations would be important for young researchers. Thispaper presents a new approach to recommend collaborators in an academic social networkusing the co-authorship network. We propose a weighted indirect rule mining approachusing a novel weighting mechanism called sociability.,Proceedings of the Tenth Australasian Data Mining Conference-Volume 134,2012,2
Efficient usage of memory resources in near-real-time data warehousing,Muhammad Asif Naeem; Gillian Dobbie; Gerald Weber; Imran Sarwar Bajwa,Abstract In the context of near-real-time data warehousing the user's updates generated atdata source level need to be stored into warehouse as soon as they occur. Before loadingthese updates into the warehouse they need to be transformed; often using a join operatorbetween the stream of updates and disk-based master data. In this context a stream-basedalgorithm called X-HYBRIDJOIN (Extended Hybrid Join) has been proposed earlier; with afavourable asymptotic runtime behavior. However; the absolute performance was not asgood as hoped for. In this paper we present results showing that through properly tuning thealgorithm; the resulting “Tuned X-HYBRIDJOIN” performs significantly better than that of theprevious X-HYBRIDJOIN; and better as other applicable join operators found in literature.We present the tuning approach; based on measurement techniques and a revised cost …,International Multi Topic Conference,2012,2
XML,Huayu Wu; Tok Wang Ling; Gillian Dobbie; Zhifeng Bao; Liang Xu,Documents; Authors; Tables. Log in; Sign up; MetaCart; Donate. CiteSeerX logo. Documents:Advanced Search Include Citations. Authors: Advanced Search Include Citations | Disambiguate.Tables: XML. Cached. Download as a PDF. Download Links. [www.comp.nus.edu.sg];[www.comp.nus.edu.sg]. Save to List; Add to Collection; Correct Errors; Monitor Changes. byHuayu Wu ; Tok Wang Ling ; Gillian Dobbie ; Zhifeng Bao ; Liang Xu. Summary; Citations; ActiveBibliography; Co-citation; Clustered Documents; Version History. BibTeX. @MISC{Wu_xml; author= {Huayu Wu and Tok Wang Ling and Gillian Dobbie and Zhifeng Bao and Liang Xu}; title ={XML}; year = {} }. Share. Facebook; Twitter; Reddit; Bibsonomy. OpenURL. Abstract. graphmatching to tree matching for. Powered by: Apache Solr. About CiteSeerX; Submit and IndexDocuments; Privacy Policy; Help; Data; Source; Contact Us …,*,2009,2
Verifying semistructured data normalization using SWRL,Yuan Fang Li; Jing Sun; Gillian Dobbie; Scott Lee; Hai H Wang,Semistructured data has become more and more prominent in the fast growing areas of webinformation technology. XML has been used as a standard format for semistructured data inrepresenting and exchanging information in various applications. However; the lack offormality and verification support in the design of a good semistructured data model mayhinder its development. For example; redundant data in XML must be removed or minimizedto avoid inconsistent and inefficient information processing. Normalization algorithms havebeen developed to overcome these problems by transforming the schema of asemistructured document into a better form. Therefore; it is essential to ensure that atransformed schema model preserves the same information that its original form holds. Inthis paper; we present an approach to investigate and verify the no-data-loss property of …,Theoretical Aspects of Software Engineering; 2009. TASE 2009. Third IEEE International Symposium on,2009,2
A semantic approach to the design of valid and reversible semistructured views,Yabing Chen; Tok Wang Ling; Mong Li Lee; Masatake Nakanishi; Gillian Dobbie,Abstract Existing systems that support semistructured views do not maintain semanticsduring the process of designing the views. Thus; these systems do not guarantee the validityand reversibility of the views. In this paper; we propose an approach to address the issue ofvalid and reversible semistructured views; We design a set of view operators for designingsemistructured views. These operators are select; drop; join and swap. For each operator;we develop a complete set of rules to maintain the semantics of the views. In particular; wemaintain the evolution and integrity of relationships once an operator is applied. We alsoexamine the reversible view problem under our operators and develop rules to guaranteethat the designed views are reversible. Finally; we examine the changes in the participationconstraints of relationship types during the view design process; and develop rules to …,Journal of Computing Science and Engineering,2007,2
Using semantics in XML data management,Tok Wang Ling; Gillian Dobbie,Abstract XML is emerging as a de facto standard for information exchange over the Web;while businesses and enterprises generate and exchange large amounts of XML data daily.One of the major challenges is how to query this data efficiently. Queries typically can berepresented as twig patterns. Some researchers have developed algorithms that reduce theintermediate results that are generated during query processing; while others haveintroduced labeling schemes that encode the position of elements; enabling queries to beanswered by accessing the labels without traversing the original XML documents. In thispaper we outline optimizations that are based on semantics of the data being queried; andintroduce efficient algorithms for content and keyword searches in XML databases. If thesemantics are known we can further optimize the query processing; but if the semantics …,*,2007,2
A PVS Approach to Verifying ORA-SS Data Models.,Scott Uk-Jin Lee; Gillian Dobbie; Jing Sun; Lindsay Groves,Abstract The rapid growth of the World Wide Web has resulted in a dramatic increase insemistructured data usage. This creates a growing need for ensuring consistency of the dataespecially when applications or databases change the schema of semistructured data. Inthis paper; we demonstrate an approach to formally define and verify the ORA-SS datamodel for semistructured data design. A mathematical semantics for the ORA-SS notation isdefined using the PVS formal language. With this semantics; it is possible to performautomated verification via the PVS theorem prover to identify the inconsistencies indesigning ORA-SS data models. The verification is based on criteria for semistructured dataverification at both schema and data instance levels.,SEKE,2006,2
Join Operation over XML data.,Hong-Cheu Liu; Gillian Dobbie,JOIN OPERATION OVER XML DATA Hong-Cheu Liu Department of Information ManagementProvidence University Taichung; 433 Taiwan E-mail: hcliu@pu.edu.tw Gillian Dobbie Departmentof Computer Science University of Auckland Auckland; New Zealand E-mail:gill@cs.auckland.ac.nz Abstract We propose a novel approach of mapping XML documents tothe object-relational form and then to cor- responding nested tables; and explore the join problemon the XML data by applying a path join operator to the mapped nested tables. It is demonstratedin this paper that object-relational database systems need to augment their suite of physical joinalgorithms to include nested table join to be competitive on XML query process- ing. Our P-joinoperator turns out to be superior to traditional traverse-style algorithms. The results of this papercan be used as a basis to develop and conﬁgure more sophisticated object-relational …,ISDB,2002,2
Arithmetic and aggregate operators in deductive object-oriented databases,Gillian Dobbie; Rodney Topor,Abstract We extend our previous mathematical foundation for a deductive object-orientedlanguage called Gulog to include arithmetic and aggregate operators. We describe thesemantics of the extended language and present a corresponding query evaluationprocedure.,*,1996,2
Skewed distributions in semi-stream joins: How much can caching help?,M Asif Naeem; Gillian Dobbie; Christof Lutteroth; Gerald Weber,Abstract Semi-stream join algorithms join a fast data stream with a disk-based relation. Thisis important; for example; in real-time data warehousing where a stream of transactions isjoined with master data before loading it into a data warehouse. In many importantscenarios; the stream input has a skewed distribution; which makes certain performanceoptimizations possible. We propose two such optimization techniques:(1) a cachingtechnique for frequently used master data and (2) a technique for selective load shedding ofstream tuples. The caching technique is fine-grained; operating on a tuple-level.Furthermore; it is generic in the sense that it can be applied to different semi-stream joinalgorithms to deal with data skew. We analyze it by combining it with various well-knownsemi-stream joins; and show that it improves the service rate by more than 40% for typical …,Information Systems,2017,1
Parallel discord discovery,Tian Huang; Yongxin Zhu; Yishu Mao; Xinyang Li; Mengyun Liu; Yafei Wu; Yajun Ha; Gillian Dobbie,Abstract Discords are the most unusual subsequences of a time series. Sequential discoveryof discords is time consuming. As the scale of datasets increases unceasingly; datasetshave to be kept on hard disk; which degrades the utilization of computing resources.Furthermore; the results discovered from segmentations of a time series are non-combinable; which makes discord discovery hard to parallelize. In this paper; we proposeParallel Discord Discovery (PDD); which divides the discord discovery problem in acombinable manner and solves its sub-problems in parallel. PDD accelerates discorddiscovery with multiple computing nodes and guarantees the correctness of the results. PDDstores large time series in distributed memory and takes advantage of in-memory computingto improve the utilization of computing resources. Experiments show that given 10 …,Pacific-Asia Conference on Knowledge Discovery and Data Mining,2016,1
Advances in knowledge discovery and data mining,James Bailey; Latifur Khan; Takashi Washio; Gillian Dobbie; Joshua Zhexue Huang; Ruili Wang,Abstract. We present a denoising technique in the domain of time series data that presumesa model for the uncorrupted underlying signal rather than a model for noise. Specifically; weshow how the nonlinear reconstruction of the underlying dynamical system by way of timedelay embedding yields a new solution for denoising where the underlying dynamics isassumed to be highly non-linear yet low-dimensional. The model for the underlying data isrecovered using a non-parametric Bayesian approach and is therefore very flexible. Theproposed technique first clusters the reconstructed phase space through a Dirichlet ProcessMixture of Exponential density; an infinite mixture model. Phase Space Reconstruction isaccomplished by time delay embedding in the framework of Taken's Embedding Theoremwith the underlying dimension being determined by the False Neighborhood method …,*,2016,1
Unsupervised semantic and syntactic based classification of scientific citations,Mohammad Abdullatif; Yun Sing Koh; Gillian Dobbie,Abstract In the recent years; the number of scientific publications has increasedsubstantially. A way to measure the impact of a publication is to count the number of citationsto the paper. Thus; citations are being used as a proxy for a researcher's contribution andinfluence in a field. Citation classification can provide context to the citations. To performcitation classification; supervised techniques are normally used. To the best of ourknowledge there are no research that performs this task in a unsupervised manner. In thispaper we present two techniques to cluster citations automatically without humanintervention. This paper presents two novel techniques to cluster citations according to theircontents (semantic) and the citation sentence styles (syntactic). The techniques arevalidated using external test sets from existing supervised citation classification studies.,International Conference on Big Data Analytics and Knowledge Discovery,2015,1
An EScience Tool for Understanding Copyright in Data Driven Sciences,Richard Hosking; Mark Gahegan; Gillian Dobbie,Understanding the impacts of copyright is a challenge for the sharing and reuse of ourresearch data. There is growing recognition of the problem; but the legal knowledgerequired to navigate through the minefield of restrictions and risks is often too difficult touncover and understand. As of yet there are no appropriate tools to aid researchers;librarians and research policy makers. To address this gap we present Camden; anautomated copyright reasoning tool designed to integrate into existing research workflows.At its core; Camden uses dynamically generated defeasible rules to reason over the legalityof a situation of using; combining and publishing data; while additionally suggestingpotential licenses by which to safely share derived research outputs. This functionality hasbeen wrapped up into an embedded software library and offered as a web application. In …,e-Science (e-Science); 2014 IEEE 10th International Conference on,2014,1
Connecting and Synchronizing Scientific Artifacts through the Process of Conceptual Change,Prashant Gupta; Mark Gahegan; Gillian Dobbie,In this age of digital science; our scientific knowledge is fragmented into data; methods;schemas; ontology; code and workflows--each of them largely disconnected from the othersand manipulated within their own specialized tools. These tools have disaggregated ourscientific knowledge and analytic processes. As a result; it is becoming much harder todecipher scholarly outcomes; much information is lost within the broken connections amongvarious artifacts and processes; and the deeper knowledge required to model andcommunicate the conceptual underpinning of research is often not captured. This workproposes a model that attempts to provide a coordinated view of evolving scientificknowledge. The model connects various scientific artifacts--categories; database schemaand ontologies--through the'process of conceptual change'; allowing both connections …,e-Science (e-Science); 2014 IEEE 10th International Conference on,2014,1
Automated mutation-based test case evaluation for semantic web services,M Shaban Jokhio; Gillian Dobbie; Tianming Hu; Jing Sun,Semantic Web Services (SWS) introduce a semantic layer to the current web infrastructure;enabling the automated processing of web service tasks. In the past decade; variousframeworks have been proposed for designing SWS. However; few of them aimed at testingSWS. Generating test cases for SWS is challenging due to its dynamic nature and abstractviews; evaluating the test cases is equally essential in order to ensure the quality of the testsuite. In this paper; we propose a mutation based evaluation approach to measuring thequality of test cases for SWS. Furthermore; we develop a tool support to automate the stepsin the proposed solution. Finally; the approach is applied to the Amazon E-CommerceService as a real world case study.,Software Engineering Conference (ASWEC); 2014 23rd Australian,2014,1
Hermoso; Ramón 87 Hurtado; Marıa Visitación 67 Hurtado-Torres; Nuria 67 Koh; Yun Sing 171,Paulo Leitao; Ricardo Anacleto; Javier Bajo; Maria Bermudez-Edo; Hugues Bersini; Vicente Botón-Fernández; Philipp Brock; Enrique Romero Cadaval; Henrique Lopes Cardoso; Dolly Carrillo; José Carlos Castillo; Pablo Chamoso; Juan Manuel Corchado; Ângelo Costa; Angel P del Pobil; Juan F De Paz; Claudia Di Napoli; Gillian Dobbie; Johannes Fähndrich; Antonio Fernández-Caballero; Lino Figueiredo; Davinia Font; José Luis Garrido; Ana Belén Gil; Rui Pedro Lopes; Vivian F López; Adolfo Lozano-Tello; José Machado; Dani Martınez; Ester Martinez-Martin; Nils Masuch; Javier Moreno; Marıa N Moreno; Denis Mušic; José Neves; Manuel Noguera; Paulo Novais; Tiago Oliveira; Jordi Palacın; Tomas Palleja; Paolo Pisa; Gabriel Pontes; Filipe Carlos Portela; Abdul Mateen Rajput; Joao Ramos; Patricia Riddle; Rui Rodrigues,Author Index Abelha; António 139 Adam; Emmanuel 103 Ahrndt; Sebastian 147 Alam; Shafiq171 Albayrak; Sahin 147; 155 Almeida; Ana 59 Anacleto; Ricardo 59 Bajo; Javier 53Bermudez-Edo; Maria 67 Bersini; Hugues 1 Botón-Fernández; Vicente 113 Brock; Philipp 155Cadaval; Enrique Romero 113 Cardoso; Henrique Lopes 87 Carrillo; Dolly 181 Castillo; JoséCarlos 129 Chamoso; Pablo 41 Corchado; Juan Manuel 33 Costa; Ângelo 121 del Pobil; AngelP. 121 De Paz; Juan F. 53 Di Napoli; Claudia 9 Dobbie; Gillian 171 Fähndrich; Johannes 147Fernández-Caballero; Antonio 129 Figueiredo; Lino 59 Font; Davinia 25 Garrido; José Luis 67Gil; Ana Belén 201 Hermoso; Ramón 87 Hurtado; Marıa Visitación 67 Hurtado-Torres; Nuria67 Koh; Yun Sing 171 Leitao; Paulo 103 Lopes; Rui Pedro 17 López; Vivian F. 181Lozano-Tello; Adolfo 113 Machado; José 139 Martınez; Dani 25 Martinez-Martin; Ester …,Trends in Practical Applications of Agents and Multiagent Systems,2013,1
Kernel-tree: mining frequent patterns in a data stream based on forecast support,David Tse Jung Huang; Yun Sing Koh; Gillian Dobbie; Russel Pears,Abstract Although frequent pattern mining techniques have been extensively studied; theextension of their application onto data streams has been challenging. Due to data streamsbeing continuous and unbounded; an efficient algorithm that avoids multiple scans of data isneeded. In this paper we propose Kernel-Tree (KerTree); a single pass tree structuredtechnique that mines frequent patterns in a data stream based on forecasting the support ofcurrent items in the future state. Unlike previous techniques that build a tree based on thesupport of items in the previous block; KerTree performs an estimation of item support in thenext block and builds the tree based on the estimation. By building the tree on an estimatedfuture state; KerTree effectively reduces the need to restructure for every block and thusresults in a better performance and mines the complete set of frequent patterns from the …,Australasian Joint Conference on Artificial Intelligence,2012,1
Resource optimization for processing of stream data in data warehouse environment,M Asif Naeem; Gillian Dobbie; Imran Sarwar Bajwa; Gerald Weber,Abstract To fulfill the increasing demand of business for the latest information; current dataintegration approaches are moving towards real-time updates. In the case of real-time dataintegration the updates occurring on the source systems need to be reflected in the datawarehouse immediately. One important element in real-time data integration is the join of acontinuous incoming data stream with a disk-based master data. In this context a stream-based algorithm called X-HYBRIDJOIN (Extended Hybrid Join) has been proposed earlier;with a favorable asymptotic runtime behavior. However; the absolute performance was notas good as hoped for. In this paper we present results showing that through properly tuningthe algorithm; the resulting Tuned X-HYBRIDJOIN performs significantly better than that ofthe previous X-HYBRIDJOIN; and better as other applicable join operators found in …,Proceedings of the International Conference on Advances in Computing; Communications and Informatics,2012,1
Advances in Conceptual Modeling-Applications and Challenges,Juan Trujillo; Gillian Dobbie; Hannu Kangassalo; Sven Hartmann; Markus Kirchberg; Matti Rossi; Iris Reinhartz-Berger; Esteban Zimányi; Flavius Frasincar,*,Lecture Notes in Computer Science,2010,1
Normal form ORA-SS schema diagrams,Gillian Dobbie; Tok Wang Ling,The simplest way to incorporate unknown values into the relational model; is to allowvariables; in addition to constants; as entries in the columns of relations. Such constructs arecalled tables; instead of relations. A table is an incomplete database; and represents a set ofcomplete databases; each obtained by substituting all variables with constants. Differentoccurrences of the same variable (marked null) are substituted with the same constant. Thesubstitution is thus a function from the variables and constants; to the constants; such thatthe function is identity on the constants. A table T then represents the set of relations;denoted rep (T); defined as {v (T): v is a valuation}. Then the certain answer to a query q on atable T; denoted sure (q; T) is the set of tuples that occur in every answer obtained byapplying the query to every database in rep (T). In other words; the certain answer to q on …,*,2009,1
Verifying Semistructured Data Normalization using PVS,Scott Uk-Jin Lee; Jing Sun; Gillian Dobbie; Lindsay Groves,The dramatic expansion of semistructured data has led to the development of databasesystems for manipulating the data. Despite its huge potential; there is still a lack of formalityand verification support in the design of good semistructured databases. Like traditionaldatabase systems; developed semistructured database systems should contain minimalredundancies and update anomalies; in order to store and manage the data effectively.Several normalization algorithms have been proposed to satisfy these needs; bytransforming the schema of the semistructured data into a better form. It is essential toensure that the normalized schema remains semantically equivalent to its original form. Inthis paper; we present tool support for reasoning about the correctness of semistructureddata normalization. The proposed approach uses the ORA-SS data modeling notation …,Engineering of Complex Computer Systems; 2008. ICECCS 2008. 13th IEEE International Conference on,2008,1
Reasoning about ORA-SS data models using the semantic web,Yuan Fang Li; Jing Sun; Gillian Dobbie; Hai H Wang; Jun Sun,Abstract There has been a rapid growth in the use of semistructured data in both webapplications and database systems. Consequently; the design of a good semistructured datamodel is essential. In the relational database community; algorithms have been defined totransform a relational schema from one normal form to a more suitable normal form. Thesealgorithms have been shown to preserve certain semantics during the transformation. Thework presented in this paper is the first step towards representing such algorithms forsemistructured data; namely formally defining the semantics necessary for achieving thisgoal. Formal semantics and automated reasoning tools enable us to reveal theinconsistencies in a semistructured data model and its instances. The Object RelationshipAttribute model for Semistructured data (ORA-SS) is a graphical notation for designing …,*,2006,1
Normalization,Tok Wang Ling; Mong Li Lee; Gillian Dobbie,Example 5.1 Consider the XML document in Figure 5.1 that contains information aboutcourses in a department and the students who take the courses. In this document; there aretwo courses (with code CS1102 and CS2104) and two students (with stuNo stu123 andstu125). The details of the students; such as stuName; address and hobby; are repeated foreach course the student takes. This duplication of information causes a number of problems.For example; if a student changes their address; it must be updated everywhere the addressis stored; that is it must be updated in every course the student takes. If a new course isinserted and student stu125 enrolls in that course then the details of,Semistructured Database Design,2005,1
XTree: A Declarative Query Language for XML Documents,Zhuo Chen; Tok Wang Ling; Mengchi Liu; Gillian Dobbie,XML is becoming prevalent in data presentation and data exchange on the internet. Oneimportant issue in the XML research community is how to query XML documents to extractand restructure information. Currently; XQuery based on XPath is the most promisingstandard. In this paper; we discuss limitations of XPath and XQuery; and propose ageneralization of XPath called XTree that overcomes these limitations. Using XTree; multiplevariable bindings can be instantiated in one expression; and XTree expressions; whichrepresent a tree rather than a path; can be used in both the querying part and the resultconstruction part of a query. Based on XTree; we develop an XTree query language; whichis more compact and convenient to use than XQuery; and supports common queryoperations such as join; negation; grouping; and recursion in a direct way. We describe …,to appear,2005,1
On logical foundations of multilevel secure databases,Hasan M Jamil; Gillian Dobbie,Abstract It is envisaged that the application of the multilevel security (MLS) scheme willenhance flexibility and effectiveness of authorization policies in shared enterprise databasesand will replace cumbersome authorization enforcement practices through complicated viewdefinitions on a per user basis. However; the critical problem with the current model is thatthe belief at a higher security level is cluttered with irrelevant or inconsistent data as nomechanism for attenuation is supported. Critics also argue that it is imperative for MLSdatabase users to theorize about the belief of others; perhaps at different security levels; anapparatus that is currently missing and the absence of which is seriously felt. The impetus forour current research is the need to provide an adequate framework for belief reasoning inMLS databases. In this paper; we show that these concepts can be captured in a F-logic …,Journal of Intelligent Information Systems,2004,1
Practical approach to selecting data warehouse views using data dependencies,Gillian Dobbie; Tok Wang Ling,Abstract Materialized views in data warehouses are typically complicated; making themaintenance of such views difficult. However; they are also very important for improving thespeed of access to the information in the data warehouse. So; the selection of materializedviews is crucial to the operation of the data warehouse both with respect to maintenance andspeed of access. Most research to date has treated the selection of materialized views as anoptimization problem with respect to the cost of view maintenance and/or with respect to thecost of queries. In this paper; we consider practical aspects of data warehousing. We identifyproblems with the star and snow ake schema and suggest solutions. We also identifypractical problems that may arise during view selection and suggest heuristics based ondata dependencies and access patterns that can be used to measure if one set of views is …,International Conference on Conceptual Modeling,2000,1
Towards normalization in object-oriented databases,Gillian Dobbie,There are two common approaches to designing object-oriented database schemas. Thefirst is to follow an object-oriented analysis and design methodology; and the second is totranslate an extended entity relationship diagram to an object-oriented schema. Neither ofthese approaches provide a way of choosing between or evaluating alternative object-oriented designs.,*,1996,1
Supporting Team Work in a Computer Science Course,Gillian Dobbie,*,*,*,1
An Experience Report on a Boot-Camp Style Programming Course,Yu-Cheng Tu; Gillian Dobbie; Ian Warren; Andrew Meads; Cameron Grout,Abstract Recently; there has been a strong demand for talented ICT (Information andCommunication Technology) graduates in the software industry in New Zealand. To meetthis demand; in 2015; the government of New Zealand provided funding for three new ICTGraduate Schools. The challenge for the schools was twofold: to provide a qualification forstudents transitioning into ICT and to prepare those with an ICT education for the workforce.Each of the Schools offer different programmes. We offer two postgraduate programmes forgrowing talent and knowledge to support the New Zealand's ICT sector. In this paper; wedescribe our experience with delivering one of the postgraduate programmes; thePostgraduate Certificate in Information Technology. The programme consists of two courses;Programming for Industry and Programming with Web Technologies. The courses focus …,Proceedings of the 49th ACM Technical Symposium on Computer Science Education,2018,*
A Review of Privacy and Consent Management in Healthcare: A Focus on Emerging Data Sources,Muhammad Rizwan Asghar; TzeHowe Lee; Mirza Mansoor Baig; Ehsan Ullah; Giovanni Russello; Gillian Dobbie,Abstract: The emergence of New Data Sources (NDS) in healthcare is revolutionisingtraditional electronic health records in terms of data availability; storage; and access.Increasingly; clinicians are using NDS to build a virtual holistic image of a patient's healthcondition. This research is focused on a review and analysis of the current legislation andprivacy rules available for healthcare professionals. NDS in this project refers to andincludes patient-generated health data; consumer device data; wearable health and fitnessdata; and data from social media. This project reviewed legal and regulatory requirementsfor New Zealand; Australia; the European Union; and the United States to establish theground reality of existing mechanisms in place concerning the use of NDS. The outcome ofour research is to recommend changes and enhancements required to better prepare for …,arXiv preprint arXiv:1711.00546,2017,*
Precision Driven Health: A New Zealand Research Partnership,Gillian Dobbie; Kevin Ross,Abstract Future healthcare will be driven by individuals expecting personalized treatmentbased on their own biological; social and environmental profiles. We have launched anambitious project with an integrated partnership model across government; commercial;health care providers and researchers in New Zealand.,International Journal of Integrated Care,2017,*
Volatility Adaptive Classifier System,Ruolin Jia; Yun Sing Koh; Gillian Dobbie,Abstract A data stream's concept may evolve over time; which is known as the concept drift.Concept drifts affect the prediction accuracy of the learning model and are required to behandled to maintain the model quality. In most cases; there is a trade-off betweenmaintaining prediction quality and learning efficiency. We present a novel framework knownas the Volatility-Adaptive Classifier System (VACS) to balance the trade-off. The systemcontains an adaptive classifier and a non-adaptive classifier. The former can maintain ahigher prediction quality but requires additional computational overhead; and the latterrequires less computational overhead but its prediction quality may be susceptible toconcept drifts. VACS automatically applies the adaptive classifier when the concept drifts arefrequent; and switches to the non-adaptive classifier when drifts are infrequent. As a result …,Pacific-Asia Conference on Knowledge Discovery and Data Mining,2017,*
UniAD: A Unified Ad Hoc Data Processing System,Xiaogang Shi; Bin Cui; Gillian Dobbie; Beng Chin Ooi,Abstract Instead of constructing complex declarative queries; many users prefer to write theirprograms using procedural code embedded with simple queries. Since many users are notexpert programmers or the programs are written in a rush; these programs usually exhibitpoor performance in practice and it is a challenge to automatically and efficiently optimizethese programs. In this article; we present UniAD; which stands for Unified execution for Adhoc Data processing; a system designed to simplify the programming of data processingtasks and provide efficient execution for user programs. We provide the background ofprogram semantics and propose a novel intermediate representation; called UnifiedIntermediate Representation (UniIR); which utilizes a simple and expressive mechanismHOQ to describe the operations performed in programs. By combining both procedural …,ACM Transactions on Database Systems (TODS),2017,*
Goal-based testing of semantic web services,M Shaban Jokhio; Jing Sun; Gillian Dobbie; Tianming Hu,Abstract Context: Recent years have witnessed growing interests in semantic web and itsrelated technologies. While various frameworks have been proposed for designing semanticweb services (SWS); few of them aim at testing. Objective: This paper investigates into thetechnologies for automatically deriving test cases from semantic web service descriptionsbased on the Web Service Modeling Ontology (WSMO) framework. Method: WSMO goalspecifications were translated into B abstract machines. Test cases were generated viamodel checking with calculated trap properties from coverage criteria. Furthermore; weemployed mutation analysis to evaluate the test suite. In this approach; the model-based testcase generation and code-based evaluation techniques are independent of each other;which provides much more accurate measures of the testing results. Results: We applied …,Information and Software Technology,2017,*
Improving Imputation Accuracy in Ordinal Data Using Classification,Shafiq Alam; Gillian Dobbie; XiaoBin Sun,Abstract Tackling missing data is one of the fundamental data pre-processing steps. Dataanalysis and pattern extraction are affected due to the underlying differences betweeninstances with and without missing data. This is a particular problem with ordinal data;where for example a sample of a population may have all failed to answer a specificquestion in a questionnaire. The existing methods such as listwise deletion; mean attributesubstitution; and regression substitution; naively impute data. They do not impute plausiblevalues as they fail to take into account the relationships between the attributes; but insteadconsider the distribution of the attribute with missing values only. In this paper we introducethe use of Classification Based Imputation (CNI) to replace missing values with plausiblevalues in ordinal data. The results show that not only does the CNI based technique …,International Conference on Intelligent Systems Design and Applications,2016,*
CPF: Concept Profiling Framework for recurring drifts in data streams,Robert Anderson; Yun Sing Koh; Gillian Dobbie,Abstract We propose the Concept Profiling Framework (CPF); a meta-learner that uses aconcept drift detector and a collection of classification models to perform effectiveclassification on data streams with recurrent concept drifts; through relating models bysimilarity of their classifying behaviour. We introduce a memory-efficient version of ourframework and show that it can operate faster and with less memory than a naïveimplementation while achieving similar accuracy. We compare this memory-efficient versionof CPF to a state-of-the-art meta-learner made to handle recurrent drift and show that we canregularly achieve improved classification accuracy along with runtime and memory use. Weprovide results from testing on synthetic and real-world datasets to prove CPF's value inclassifying data streams with recurrent concepts.,Australasian Joint Conference on Artificial Intelligence,2016,*
Linking Design Model with Code,Candice Eckert; Brian Cham; Pengyi Li; Jing Sun; Gillian Dobbie,With the growing in size and complexity of modern computer systems; the need forimproving the quality at all stages of software development has become a critical issue. Thecurrent software production has been largely dependent on manual code development.Despite the slow development process; the errors introduced by the programmers contributeto a substantial portion of defects in the final software product. Model-driven engineering(MDE); despite having many advantages; is often overlooked by programmers due to lack ofproper understanding and training in the matter. This paper investigates the advantages anddisadvantages of MDE and looks at research results showing the adoption rates of designmodels. It analyzes different tools used for automated code generation and displays thereasons that led to technical decisions such as the programming language or design …,International Journal of Software Engineering and Knowledge Engineering,2016,*
A real-time distributed hardware health monitoring framework,Sai Santhan Kusam Venkata; Jahnavi Bharadwaj; Gillian Dobbie; Sathiamoorthy Manoharan,Health monitoring involves sensing; reporting; and sometimes adjusting the states of objectsor nodes remotely. This paper describes the design and implementation of a real-timedistributed hardware health monitoring framework; assuming a homogeneous set ofhardware nodes. The framework consists of sensor components operating at the nodes; andvisualization components operating at monitoring stations. A service-oriented softwarearchitecture naturally lends itself to fit such a framework. As the primary focus and casestudy; the paper presents the implementation of a system to monitor the status of a collectionof computers; where the sensors are hardware probes and counters such as CPU probesand performance counters.,Applied and Theoretical Computing and Communication Technology (iCATccT); 2016 2nd International Conference on,2016,*
Modeling Ice Storm Climatology,Ranjini Swaminathan; Mohan Sridharan; Gillian Dobbie; Katharine Hayhoe,Abstract Extreme weather events such as ice storms cause significant damage to life andproperty. Accurately forecasting ice storms sufficiently in advance to offset their impacts isvery challenging because they are driven by atmospheric processes that are complex andnot completely defined. Furthermore; such forecasting has to consider the influence of achanging climate on relevant atmospheric variables; but it is difficult to generalise existingexpertise in the absence of observed data; making the underlying computational challengeall the more formidable. This paper describes a novel computational framework to model icestorm climatology. The framework is based on an objective identification of ice storm eventsby key variables derived from vertical profiles of temperature; humidity; and geopotentialheight (a measure of pressure). Historical ice storm records are used to identify days with …,Australasian Joint Conference on Artificial Intelligence,2015,*
Special Issue on Advances in Conceptual Modeling (ER 2014),Matthias Jarke; Gillian Dobbie; Eric Yu,*,Data & Knowledge Engineering,2015,*
Rare Pattern Mining from Data Streams Using SRP-Tree and Its Variants,David Tse Jung Huang; Yun Sing Koh; Gillian Dobbie,Abstract There has been some research in the area of rare pattern mining where theresearchers try to capture patterns involving events that are unusual in a dataset. Thesepatterns are considered more useful than frequent patterns in some domains; includingdetection of computer attacks; or fraudulent credit transactions. Until now; most of theresearch in this area concentrates only on finding rare rules in a static dataset. There is aproliferation of applications which generate data streams; such as network logs and bankingtransactions; and applying techniques that mine static datasets is not practical for datastreams. We propose a novel approach called Streaming Rare Pattern Tree (SRP-Tree) andits variations; which finds rare rules in a data stream environment using a sliding window;and show that it both finds the complete set of itemsets and runs with fast execution time.,*,2015,*
Conceptual Modeling: 33rd International Conference; ER 2014; Atlanta; GA; USA; October 27-29; 2014. Proceedings,Eric Yu; Gillian Dobbie; Matthias Jarke; Sandeep Purao,This book constitutes the refereed proceedings of the 32nd International Conference onConceptual Modeling; ER 2014; held in Atlanta; GA; USA. The 23 full and 15 short paperspresented were carefully reviewed and selected from 80 submissions. Topics of interestpresented and discussed in the conference span the entire spectrum of conceptualmodeling including research and practice in areas such as: data on the web; unstructureddata; uncertain and incomplete data; big data; graphs and networks; privacy and safety;database design; new modeling languages and applications; software concepts andstrategies; patterns and narratives; data management for enterprise architecture; city andurban applications.,*,2014,*
Drift Detector for Memory-Constrained Environments,Timothy D Robinson; David Tse Jung Huang; Yun Sing Koh; Gillian Dobbie,Abstract Current approaches to drift detection assume that stable memory consumption withslight variations with each stream is suitable for all programs. This is not always the caseand there are situations where small variations in memory are undesirable such as driftdetectors on medical vital sign monitoring systems. Under these circumstances; it is notsufficient to have a memory use that is predictable on average; but instead memory use mustbe fixed. To detect drift using fixed memory in a stream; we propose DualWin: a techniquethat keeps two samples of controllable size; one is stored in a sliding window; whichrepresents the most recent stream elements; and the other is stored in a reservoir; whichuses reservoir sampling to maintain an image of the stream since the previous drift wasdetected. Through experimentation; we find that DualWin obtains a rate of true positive …,International Conference on Data Warehousing and Knowledge Discovery,2014,*
Efficient processing of streaming updates with archived master data in near-real-time data warehousing,M Asif Naeem; Gillian Dobbie; Gerald Weber,Abstract In order to make timely and effective decisions; businesses need the latestinformation from data warehouse repositories. To keep these repositories up-to-date withrespect to end user updates; near-real-time data integration is required. An important phasein near-real-time data integration is data transformation where the stream of updates isjoined with disk-based master data. The stream-based algorithm MESHJOIN (Mesh Join)has been proposed to amortize disk access over fast streams. MESHJOIN makes noassumptions about the data distribution. In real-world applications; however; skeweddistributions can be found; such as a stream of products sold; where certain products aresold more frequently than the remainder of the products. The question arises is how muchdoes MESHJOIN lose in terms of performance by not adapting to data skew. In this paper …,Knowledge and information systems,2014,*
Change Itemset Mining in Data Streams,Minmin Zhang; Gillian Dobbie; Yun Sing Koh,Abstract Data stream mining is becoming very important in many application areas; such asthe stock market. A data stream consists of an ordered sequence of instances and becausethere are usually a large number of instances along with limited computing and storagecapabilities; algorithms that read the data only once are preferred. There has been someresearch that focuses on finding when a concept has changed; given some knowledgeabout the previous instances in the data stream; but little on determining the characteristicsof that change. In this paper we concentrate on finding the characteristics of the changes thatoccur; using frequent itemset mining techniques. We propose an approach; which combinesboth heuristic and statistical approaches; that analyses changes that have occurred within astream at itemset level and identify three types of change: extension; reduction; and …,International Conference on Advanced Data Mining and Applications,2013,*
Efficient Processing of Stream Data over Persistent Data,M Asif Naeem; Gillian Dobbie; Gerald Weber,A data stream is a continuous sequence of items produced in real time. A stream can beconsidered to be a relational table of infinite size [1]. It is therefore considered impossible tomaintain an order of the items in the stream with respect to an arbitrary attribute. Likewise; itis impossible to store the entire stream in memory. However; results of operations areexpected to be produced as soon as possible. As a consequence; standard relational queryprocessing cannot be straightforwardly applied; and online stream processing has becomea new field of research in the area of data management. A number of common exampleswhere online stream processing is important are network traffic monitoring [2–6]; sensor data[7]; web log analysis [8; 9]; online auctions [10]; inventory and supply-chain analysis [11–13];as well as real-time data integration [14; 15].,Big Data Computing,2013,*
Big Data Management in the Context of Real-Time Data Warehousing,M Asif Naeem; Gillian Dobbie; Gerald Weber,ABSTRACT In order to make timely and effective decisions; businesses need the latestinformation from big data warehouse repositories. To keep these repositories up to date; real-time data integration is required. An important phase in real-time data integration is datatransformation where a stream of updates; which is huge in volume and infinite; is joinedwith large disk-based master data. Stream processing is an important concept in Big Data;since large volumes of data are often best processed immediately. A well-known algorithmcalled Mesh Join (MESHJOIN) was proposed to process stream data with disk-based masterdata; which uses limited memory. MESHJOIN is a candidate for a resource-aware systemsetup. The problem that the authors consider in this chapter is that MESHJOIN is not veryselective. In particular; the performance of the algorithm is always inversely proportional …,Big Data Management; Technologies; and Applications,2013,*
A Parametric Analysis of Stream Based Joins,Muhammad Asif Naeem; Gillian Dobbie; Gerald Weber; Imran Sarwar Bajwa,Abstract Online stream processing is an emerging research area in the field of computerscience. Common examples where online stream processing is important are network trafficmonitoring; web log analysis and real-time data integration. One kind of stream processingis used to relate the information from one data stream to other data stream or disk-baseddata. A stream-based join is required to perform such operations. A survey of the literatureshows a number of join operators which can process the stream in an online fashion; buteach approach has advantages and disadvantages. In this paper we address a number ofwell known join operators by grouping them into two categories. In first category we discussthose operators which take all their inputs in the form of stream while in the second categorywe consider operators in which one input resides on the disk. At the end of the paper we …,International Multi Topic Conference,2012,*
Discriminatory confidence analysis in pattern mining,Russel Pears; Yun Sing Koh; Gillian Dobbie,Abstract The field of association rule mining has long been dominated by algorithms thatsearch for patterns based on their frequency of occurrence in a given dataset. The birth ofweighted association rule mining caused a fundamental paradigm shift in the way thatpatterns are identified. Consideration was given to the “importance” of an item in addition toits frequency of occurrence. In this research we propose a novel measure which we termDiscriminatory Confidence that identifies the extent to which a given item can segment adataset in a meaningful manner. We devise an efficient algorithm which is driven by anInformation Scoring model that identifies items with high discriminatory power. We compareour results with the classical approach to association rule mining and show that theInformation Scoring model produces widely divergent results. Our research reveals that …,International Conference on Advanced Data Mining and Applications,2011,*
What have we learnt from deductive object-oriented database research?,Mengchi Liu; Gillian Dobbie; Tok Wang Ling,Abstract Deductive databases and object-oriented databases (DOOD) are two importantextensions of the traditional relational database technology. Deductive databases provide arule-based language called Datalog¬(Datalog with negation) that uses function-free Hornclauses with negation to express deductive rules [1]; and is a simplified version of the logicprogramming language Prolog [2]. A deductive database consists of an extensionaldatabase and an intensional database. The extensional database (EDB) consists of therelations stored in a relational database whereas the intensional database (IDB) consists ofa Datalog¬ program that is a set of deductive rules used to derive relations that are thelogical consequences of the program and the extensional database. Datalog¬ is moreexpressive than pure relational query languages such as relational algebra and relational …,International Conference on Database Systems for Advanced Applications,2011,*
XML Benchmark,Ke Geng; Gillian Dobbie,ABSTRACT Benchmarks are widely used in database-related research; helping userschoose suitable database management systems and helping researchers evaluate theirnew methods. Recently benchmarks for XML have been designed to support thedevelopment of XML tools and systems. In this chapter; XML benchmarks are categorizedinto four groups: application benchmark; micro benchmark; XML generator and real dataset.Characteristics of each benchmark are discussed and compared. Finally; the future directionof XML benchmarks are discussed.,Advanced Applications and Structures in XML Processing: Label Streams; Semantics Utilization and Data Query Technologies: Label Streams; Semantics Utilization and Data Query Technologies,2010,*
Semistructured Database Design Web Information Systems Engineering and Internet Technologies,Tok Wang Ling; Gillian Dobbie,*,*,2010,*
Advances in Conceptual Modeling-Applications and Challenges,Gillian Dobbie; Hannu Kangassalo; Sven Hartmann; Markus Kirchberg; Matti Rossi; Iris Reinhartz-Berger; Esteban Zimányi; Flavius Frasincar,Welcome to the workshops associated with the 29th International Conference onConceptual Modeling (ER 2010). As always; the aim of the workshops was to giveresearchers and participants a forum to discuss cutting edge research in conceptualmodeling; and to pose some of the challenges that arise when applying conceptualmodeling in less traditional areas. Workshops provided an intensive collaborative forum forexchanging late breaking ideas and theories in an evolutionary stage. Topics of interestspan the entire spectrum of conceptual modeling including research and practice in areassuch as theories of concepts and ontologies underlying conceptual modeling; methods andtools for developing and communicating conceptual models; and techniques fortransforming conceptual models into effective implementations. In order to provoke more …,*,2010,*
Semi-Structured Database Design,Gillian Dobbie; Tok Wang Ling,The values in the relations of a relational database are elements of one or more underlyingsets called domains. In practical applications; a domain may be infinite; eg; the set of naturalnumbers. In this case; the value of a relational calculus query when applied to such adatabase may be infinite; eg;{njn! 10}. A query Q is called finite if the value of Q whenapplied to any database is finite. Even when the database domains are finite; all that isnormally known about them is that they are some finite superset of the values that occur inthe database. In this case; the value of a relational calculus query may depend on such anunknown domain; eg;{xj 8yR (x; y)}. A query Q is called domain independent if the value of Qwhen applied to any database is the same for any two domains containing the databasevalues or; equivalently; if the value of Q when applied to a database contains only values …,*,2009,*
Object Relationship Attribute Data Model for Semi-structured Data,Gillian Dobbie; Tok Wang Ling,OASIS was founded in 1993 under the name ''SGML Open.''The initial goal of theorganization was to develop guidelines for interoperability among products using StandardGeneralized Markup Language (SGML). In 1998 it changed name to OASIS to reflect onchanging scope of its technical work. OASIS consists of an open group of memberorganizations whose representatives work in committees developing standards; promotingstandards adoption; product interoperability and standards conformance. In 2007 OASIShad 5;000 participants representing 600 organizations and individual members in 100countries. OASIS is governed by a member-elected Board in an annual election process.The board membership is based on the personal merits of Board nominees. OASIS processallows participants to influence standards that affect their business; contribute to …,*,2009,*
Functional Dependencies for Semi-Structured Data,Gillian Dobbie; Tok Wang Ling,Functional dependencies are used in relational database design to show that the value of a setof attributes depends on the value of another set of attributes. Theory has been developed tomanipulate a set of functional dependencies to describe equivalences of sets of functionaldependencies. Semi-structured data differs from relational data in two important ways: semi-structureddata is hierarchical and the structure of the data is less consistent. Traditional functional dependenciesdo not capture these differences so new functional dependencies with associated theory hasbeen defined for semi-structured data … Functional dependencies for semi-structured datahave been defined in the three recommended readings. While the syntax of functional dependenciesdefined over semi-structured data varies; the semantics is similar. In this article the syntax ofArenas and Libkin [1] is used but the notation differs a little since there is no distinction …,*,2009,*
Correctness criteria for normalization of semistructured data,Scott Uk-Jin Lee; Jing Sun; Gillian Dobbie; Lindsay Groves; Yuan Fang Li,The rapid increase in semistructured data usage has lead to the development of variousdatabase systems for semistructured data. Web services and applications that utilize largeamounts of semistructured data require data to remain consistent and be stored efficient.Several normalization algorithms for semistructured database systems have beendeveloped to satisfy these needs. However; these algorithms lack the verification that wouldensure that data and constraints among the data are not lost or corrupted duringnormalization. In this paper; we propose a set of correctness criteria for normalization ofsemistructured data; which require that functional dependencies are preserved; data is notlost; and spurious data is not created during normalization. We use the Z specificationlanguage to provide a precise and declarative definition of our criteria.,Software Engineering; 2008. ASWEC 2008. 19th Australian Conference on,2008,*
Using data in the transformation of xml queries,Ke Geng; Gillian Dobbie,ABSTRACT XML query transformation is a key part of XML query optimization. Howevermost research into transforming XML queries is schema-based rather than data-basedbecause of the highly flexible nature of XML documents. In this paper; we introduce anengine that we designed and built to test the effectiveness of different data-based querytransformation techniques. The information is extracted from the data or XML documents;and with this engine; queries can be automatically transformed if they fall into particularcategories which we have defined. Because this engine is developed independent of anyparticular XML database and different functions are realized by different modules; theengine is extensible and easy to adapt for different database systems.,Christchurch; New Zealand,2008,*
towards verifying semistructured data,Gillian Dobbie; Jing Sun; Yuan Fang Li; Scott UK-Jin Lee,Abstract Semistructured data is now widely used in both web applications and databasesystems. There are many research challenges in this area; such as data integration; changemanagement; view definition; and data normalization. Traditionally in these areas aformalism is defined for the database model; and properties of the algorithms can bereasoned about; such as the dependency preserving property of the normalization algorithmin the relational data model. Because research into semistructured data is still in its infancy;many algorithms have been defined in this area and a number of formalisms have beenproposed but there is no widely accepted formalism that is generally accepted to reasonabout the properties of the algorithms. Such a formalism must capture all the necessarysemantics required to model the algorithms; should not be too complex; and should be …,Proceedings of the fourth Asia-Pacific conference on Comceptual modelling-Volume 67,2007,*
Extended abstract: towards verifying semistructured data,Gillian Dobbie; Jing Sun; Yuan Fang Li; Scott Uk-Jin Lee,*,ACM International Conference Proceeding Series,2007,*
Research into verifying semistructured data,Gillian Dobbie; Jing Sun; Yuan Fang Li; UK Scott,Abstract Semistructured data is now widely used in both web applications and databasesystems. Much of the research into this area defines algorithms that transform the data andschema; such as data integration; change management; view definition; and datanormalization. While some researchers have defined a formalism for the work they haveundertaken; there is no widely accepted formalism that can be used for the comparison ofalgorithms within these areas. The requirements of a formalism that would be helpful inthese situations are that it must capture all the necessary semantics required to model thealgorithms; it should not be too complex and it should be easy to use. This paper describes afirst step in defining such a formalism. We have modelled the semantics expressed in theORA-SS (Object Relationship Attribute data model for SemiStructured data) data …,International Conference on Distributed Computing and Internet Technology,2006,*
A tool for visualizing schemas for semistructured data,John Hosking; Nodira Khoussainova; Gillian Dobbie,Copyright © 2006 by the Association for Computing Machinery; Inc. Permission to make digitalor hard copies of part or all of this work for personal or classroom use is granted without fee providedthat copies are not made or distributed for commercial advantage and that copies bear this noticeand the full citation on the first page. Copyrights for components of this work owned by othersthan ACM must be honored. Abstracting with credit is permitted. To copy otherwise; torepublish; to post on servers; or to redistribute to lists; requires prior specific permission and/ora fee. Request permissions from Permissions Dept; ACM Inc.; fax +1 (212) 869-0481 or e-mailpermissions@acm.org. SOFTVIS 2006; Brighton; United Kingdom; September 04–05; 2006.© 2006 ACM 1-59593-464-2/06/0009 $5.00 … A Tool for Visualizing Schemas for SemistructuredData … John Hosking Department of Computer Science; University of Auckland …,Proceedings of the 2006 ACM symposium on Software visualization,2006,*
XTree: A Declarative Query Language for XML Documents,CHEN Zhuo; Tok Wang LING; LIU Mengchi; Gillian DOBBIE,XML is becoming prevalent in data presentation and data exchange on the internet. Oneimportant issue in the XML research community is how to query XML documents to extractand restructure information. Currently; XQuery based on XPath is the most promisingstandard. In this paper; we discuss limitations of XPath and XQuery; and propose ageneralization of XPath called XTree that overcomes these limitations. Using XTree; multiplevariable bindings can be instantiated in one expression; and XTree expressions; whichrepresent a tree rather than a path; can be used in both the querying part and the resultconstruction part of a query. Based on XTree; we develop an XTree query language; whichis more compact and convenient to use than XQuery; and supports common queryoperations such as join; negation; grouping; and recursion in a direct way. We describe …,*,2005,*
ORA-SS,Tok Wang Ling; Mong Li Lee; Gillian Dobbie,The ORA-SS data model has three basic concepts: object classes; relationship types andattributes. Object classes model sets of real world entities. An object class is related to otherobject classes through relationship types. Attributes are properties; and may belong to anobject class or a relationship type. The ORA-SS data model consists of four diagrams: ORA-SS instance diagram; ORA-SS schema diagram; functional dependency diagram and ORA-SS inheritance diagram. The instance diagram provides a way to visualize an instance of thedata; the schema diagram represents the structure and constraints on an instance;additional functional dependencies can be represented in the functional dependencydiagram and specialization/generalization relationships among the object classes arerepresented in the inheritance diagram.,Semistructured Database Design,2005,*
Views,Tok Wang Ling; Mong Li Lee; Gillian Dobbie,Summary In this paper; we have proposed a systematic approach for valid XML view design.The approach is composed of three steps. The first step transforms an XML document intoan ORA-SS schema diagram. The second step enriches the ORA-SS schema diagram withnecessary semantics for valid XML views design. The final step uses the proposed a set ofrules to guide the design of valid XML views. We have also presented rules to validateviews.,Semistructured Database Design,2005,*
Physical Database Design,Tok Wang Ling; Mong Li Lee; Gillian Dobbie,Summary While the process of transforming an ORA-SS schema diagram to an NF ORA-SSschema diagram can lead to databases that have no replicated data which in turn leads to areduction in anomalies; the addition of references may adversely degrade the performanceof queries on the database. In this chapter; we have addressed how replication can beadded back into a schema in a controlled manner in order to improve the performance ofqueries that are frequently asked. We have reviewed how attributes that seldom change aredealt with in relational databases; and how pairings are maintained automatically inhierarchical IMS databases for answering symmetric queries efficiently. We have describedthe kinds of replication that can arise in semistructured databases; and how the replication ofrelatively stable attributes and relationship types can be added; and how pairings …,Semistructured Database Design,2005,*
Schema Extraction,Tok Wang Ling; Mong Li Lee; Gillian Dobbie,Unlike data stored in traditional relational or object-oriented databases; semistructured datadoes not have a fixed schema that is known in advance and that can be stored separatelyfrom the data. In fact; the structure of semistructured data is irregular; unknown; and changesoften [Suciu; 1998]. The lack of external schema information renders the storage; indexing;and querying of semistructured data inefficient; or even impossible. This leads to thedevelopment of methods such as DataGuide [Goldman and Widom; 1997] to extract theschema from semistructured data. The focus of these techniques is to extract the hierarchystructure of semistructured data. In contrast; ORASS is able to capture important semanticinformation such as objects classes; relationship types; attributes; degree of relationshiptypes; participation constraints of the object classes in the relationship types. Further …,Semistructured Database Design,2005,*
Data Models for Semistructured Data,Tok Wang Ling; Mong Li Lee; Gillian Dobbie,Traditionally; real world semantics are captured in a data model; and mapped to thedatabase schema. The real world semantics are modeled as constraints and used to ensureconsistency of the data in the resulting database. Similarly; in semistructured databases theconsistency of the data can be enforced through the use of constraints. There are twoapproaches to designing a schema for a semistructured database. The first follows thetraditional approach and captures the real world constraints in a data model. The secondapproach is used in the case where a semistructured document exists without a schema.Following this approach the constraints are extracted from the document and modeled usinga data model. A data model that is used in the design of schemas for semistructured datahas different requirements than those used in the design of schemas for relational …,Semistructured Database Design,2005,*
Special Issue on Database and Applications Security,Bhavani M Thuraisingham,*,*,2004,*
Databases; but not as we know them,Gillian Dobbie,Images and Information 2003). The information can either be gathered dynamically whenrequested or stored in some kind of repository. If it is stored in a repository; the question thatarises is" what kind of repository should be used". The obvious answer is a native XMLdatabase because XML databases have revolutionized how businesses operate. They arethe hottest topic in database research since entity relationship diagrams. Or are they? XMLitself is a very simple language that allows us to format documents; allowing us to describethem in a hierarchical manner; defining our own tags to describe the different parts of thedocuments. We can use either DTD or XMLSchema to define the structure of thesedocuments. Most of the early research was into how XML documents could be mapped torelational databases and vice versa. Since then companies like Oracle have included …,Proceedings of the 15th Australasian database conference-Volume 27,2004,*
Semantic Data Models for Semistructured Data,Tok Wang Ling; Mong Li Lee; Gillian Dobbie,[摘要]: 正Semistructured data has become more prevalent on the Web; and XML hasbecome the de facto standard for semistructured data; with much of the data stored in flatfiles. There is a growing concern for the effective management and efficient storage andretrieval of semistructured data. This paper provides an overview of the data models thathave been developed for capturing the semantics that are crucial for the effectivemanagement of semistructured data. These data models include DTD; DOM; OEM;DataGuide; and ORA-SS. The semantics include the representation of objects; relationships;attributes of objects; key attributes; functional dependencies; degrees of relationships;participation constraints in relationships; attributes of relationships; etc. We will alsodemonstrate the usefulness of these semantics in minimizing redundancy in the storage …,第二十一届中国数据库学术会议论文集 (技术报告篇),2004,*
An E-Commerce Framework for Small Businesses,Gillian Dobbie; Franziska Gelies; Daniel Blossey,*,*,2003,*
A model theoretic semantics for multi-level secure deductive databases,Hasan M Jamil; Gillian Dobbie,Abstract The impetus for our current research is the need to provide an adequate frameworkfor belief reasoning in multi-level secure (MLS) databases. We demonstrate that a prudentapplication of the concept of inheritance in a deductive database setting will help capture thenotion of declarative belief and belief reasoning in MLS databases in an elegant way. In thispaper; we show that these concepts can be captured in a F-logic style declarative querylanguage; called MultiLog; for MLS deductive databases for which a model theoreticsemantics exists. This development is significant from a database perspective as it nowenables us to compute the semantics of MultiLog databases in a bottom-up fashion. Thesemantics developed here is reminiscent of the stable model semantics of logic programswith negation. We also define a bottom-up procedure to compute unique models of …,International Conference on Logic Programming,2002,*
Te Whare Wananga o te Upoko o te Ika a Maui,James Noble; Robert Biddle,Abstract Most program visualisation systems display either language level details ofprograms; or high level overviews of the program's algorithm. Producing high level viewsrequires that the abstractions in the program to be visualised (the target program) aredescribed to the visualisation system—either by modifying the target program; or byproviding the visualisation system with information about the details of the abstractions in thetarget program. Object Orientation can be used to organise the design of both the targetprogram and the architecture of an abstract program visualisation system. Such a systemcan produce flexible displays of the target program at multiple levels of abstraction; withoutany extra detailed information about the implementation of abstractions in the targetprogram. Publishing Inf orm ati on This was originally published as: J ames N oble; L …,*,2002,*
TR12/00,Gillian DOBBIE; Xiaoying WU; Tok Wang LING; Mong Li LEE,Abstract Semi-structured data is becoming increasingly important with the introduction ofXML and related languages and technologies. The recent shift from DTDs (document typedefinitions) to XML-Schema for XML data highlights the importance of a schema definitionfor semi-structured data applications. At the same time; there is a move to extend semi-structured data models to express richer semantics. In this paper we propose a semanticallyrich data model for semi-structured data; ORA-SS (Object-Relationship-Attribute model forSemi-Structured data). ORA-SS not only reflects the nested structure of semi-structured data;but it also distinguishes between objects; relationships and attributes. It is possible to specifythe degree of n-ary relationships and indicate if an attribute is an attribute of a relationship oran attribute of an object. Such information is lacking in existing semi-structured data …,*,2000,*
Recovering from Failed Data Warehouse Loads,Gillian Dobbie; Vibhore Anant,*,Information Integration and Web-based Applications & Services; 2000: Proceedings of the Second International Workshop on Information Integration and Web-based Applications & Services 2000; 26-28 September 2000; Yogyakarta; Indonesia,2000,*
Te Whare Wananga o te Upoko o te Ika a Maui,CS Experience Teaching; Peter Andreae; Robert Biddle; Gill Dobbie; Amy Gale; Linton Miller; Ewan Tempero,Abstract We describe our experiences teaching our CS1 course with Java. Java has anumber of features that complicate using it to teach introductory programming. Although wedesigned our course to deal with these features; there were some surprises in how thecourse worked out. We discuss the underlying cause of these surprises.,*,1999,*
Surprises in teaching CS1 with JAVA,Peter Andreae; Robert Biddle; Gill Dobbie; Amy Gale; Linton Miller; Ewan Tempero,Abstract We describe our experiences teaching our CS1 course with Java. Java has anumber of features that complicate using it to teach introductory programming. Although wedesigned our course to deal with these features; there were some surprises in how thecourse worked out. We discuss the underlying cause of these surprises.,*,1999,*
Problems with OOFNF: a proposed normal form for object oriented databases,Gillian Dobbie; Peter Andreae,Update anomolies arise in relational databases if the database schema is poorly designed.Normal forms that have been defined over relational database schemas disallow redundantdata in the resulting database. Without redundancy; update anomolies don't occur. Updateanomalies can also arise in object oriented databases if the schema is poorly designed.Several definitions of normal forms over object oriented databases have been proposed.Weare particularly interested in object oriented functional normal form (OOFNF). While theintuition behind OOFNF is good; the details of the definition are wrong. For example; thedefinition of OOFNF is based on the concept of path functional dependencies (PFD) thathave been defined over single valued properti es. The authors of the paper defining OOFNFneither extend the definition of PFDs to multi-valued properties; nor do they restrict their …,*,1999,*
Mapping from a relational to an object-oriented database: a survey of current approaches,Bryan Genet; G Dobbie,*,AUSTRALIAN COMPUTER SCIENCE COMMUNICATIONS,1997,*
Te Whare Wananga o te Upoko o te Ika a Maui,Judy Brown; Gillian Dobbie,Abstract This paper explores the methodologies for the development of interactive systemsproposed by software engineers and human-computer interaction specialists. These twodisciplines have proposed methodologies emphasizing different aspects of the designprocess. The purpose of this paper is to present some of these methodologies and to identifytheir strengths and weaknesses. Methodologies are examined for their ability to facilitateworking relationships between members of an integrated design team consisting of both SEand HCI specialists. Through a review of common SE and HCI methodologies;inadeÞuacies of the education system in educating SE and HCI specialists about the roles ofother specialists are identified. Differing value systems and work practices in the HCI and SEcommunities that block the creation of integrated methodologies are explored. Finally …,*,1996,*
VUW,Gillian Dobbie; Rodney Topor,Abstract We present declarative and procedural semantics for a deductive object-orientedlanguage; Gulog. The declarative semantics is based on preferred minimal models. Wedescribe both bottom-up and top-down query evaluation procedures and show that they aresound with respect to the declarative semantics. The results contribute to our understandingof the interaction of inheritance; overiding and deduction in the presence of both functionaland set-valued methods; and multiple inheritance.,*,1994,*
VUW,Peter Andreae; Robert Biddle; Gill Dobbie; Amy Gale; Linton Miller; Ewan Tempero,Abstract Despite nearly three decades of study in the area of code reusability; programmersare still writing code that they will not be able to use again. In this paper; we examine a set ofC and C++ programming language features usually considered to be relevant to code reuse:functions; de ned types; macros; composition; generics; overloaded functions and operators;and polymorphism. Our goal is to determine exactly how each of these features should beused to produce more reusable code; and so develop an understanding of the nature ofreusability. We also discuss common misunderstandings of some of these programminglanguage features and; in doing so; provide some practical advice for more e ectiveprogramming.,*,1993,*
Message from the eScience 2017 Program Committee Chairs,David Eyers; David Abramson; Gillian Dobbie,There were 124 papers submitted to eScience 2017: 32 experience papers and 92 researchpapers. The papers underwent a rigorous review process. Each paper was reviewed by threeProgram Committee (PC) members and the Program Committee Chairs initiated further discussionsbetween these reviewers. The Program Chairs then considered the recommendations; lookinginto each paper and its reviews; to make final paper selections. In the end; 12 experience and33 research papers were selected for the conference program and proceedings; resulting inan acceptance rate below 38% and 36% respectively. Additionally; 25 papers were acceptedas posters. The review process was supported by the EasyChair conference managementsystem … The conference started with a day of five high-quality workshops. During the subsequentthree days; the Technical Program included 14 paper presentation sessions covering …,*,*,*
2014 IEEE 10th International Conference on e-Science (e-Science)(2014),Prashant Gupta; Mark Gahegan; Gillian Dobbie,*,*,*,*
2014 IEEE 10th International Conference on e-Science (e-Science)(2014),Richard Hosking; Mark Gahegan; Gillian Dobbie,*,*,*,*
Making sense of disconected data; methods; models and workflows,Prashant Gupta; Mark Gahegan; Gillian Dobbie,Key efforts to aggregate scientific knowledge; as shown below; focus on the reproducibilityof a single experiment; whereas we focus on integrating science as an ongoing andevolving process. All of these systems integrate data and methods but ignore conceptualstructures and thus provide a mechanistic view of science; rather than as a dynamic andcyclic process of evolution.,*,*,*
2015 IEEE 11th International Conference on e-Science (e-Science),Prashant Gupta; Mark Gahegan; Gillian Dobbie,Categories are the fundamental components of scientific knowledge and are used in everyphase of the scientific process. However; they are often in a state of flux; with newobservations; discoveries and changes in our conceptual understanding leading to the birthand death of categories; drift in their identities; as well as merging or splitting. Contemporaryresearch tools rarely support such changes...,*,*,*
Predicting Concept Drift Severity,Ruolin Jia; Yun Sing Koh; Gillian Dobbie,Abstract In data streams; concept drift severity refers to the amount of change of a concept.Low severity concept drifts are hard to detect using drift detectors; and in these cases; a highdetection sensitivity is expected. However; high detection sensitivity comes with a higherfalse positive rate that degrades the performance of the drift detector. In this paper; wepresent PRESS (PREdictive Severity Seed) detector. PRESS learns the severity trends of astream with recurrent volatility (the frequency of experiencing concept drifts) and predicts theseverity of future concept drifts with a probability network. Experiments show that PRESSoutperformed other existing drift detectors by reducing false positive rates while maintainingtrue positive rates. To the best of our knowledge; it is the first algorithm predicting theseverity of concept drifts to improve the detection performance. In addition; we provide a …,Workshop on Learning in the Presence of Class Imbalance and Concept Drift (LPCICD'17),*,*
Visual Development Platform for Ruby on Rails,Anmol Desai; Nicholas Molloy; Jing Sun; Gillian Dobbie,Abstract—This paper briefly reviews the construction of Ruby on Rails applications; identifiesthe pitfalls of existing tools; and proposes the design and development of a lean cross-platformdesktop application; along with an evaluation of the prototype. Index Terms—Ruby on Rails;Visual tool; Web Applications … I. INTRODUCTION Ruby on Rails is a framework that runs onthe Ruby language; and provides developers the tools necessary to build modern web services[1]. While rails simplifies the creation of web-services; it can be found to be difficult for a beginnerto not only install the framework; but to also learn and use it. This in part is due to the fact thatthe developer interacts with rails predominantly through the command line. This paper presentsthe initial research on existing tools; the design decisions; the development and implementationof a visual development platform for Ruby on Rails; namely the Rails Editor. The tool …,*,*,*
While there has been much work on modeling and analysis of temporal constraints in workflows in the context of many real-world applications; there has not been m...,M Asif Naeem; Gillian Dobbie; Christof Lutteroth; Gerald Weber,Semi-stream join algorithms join a fast data stream with a disk-based relation. This isimportant; for example; in real-time data warehousing where a stream of transactions isjoined with master data before loading it into a data warehouse. In many importantscenarios; the stream input has a skewed distribution; which makes certain performanceoptimizations possible. We propose two such optimization...,*,*,*
Adventure of Categories,Prashant Gupta; Mark Gahegan; Gillian Dobbie,Abstract. Categories are the fundamental components of scientific knowledge and are usedin every phase of the scientific process. However; they are often in a state of flux; with newobservations; discoveries and changes in our conceptual understanding leading to the birthand death of categories; drift in their identities; as well as merging or splitting. Contemporaryresearch tools rarely support such changes in operationalized categories; neglecting theproblem of capturing and utilizing the knowledge lurking behind the process of change. Thispaper presents a tool–AdvoCate–that represents the dynamic nature of categories andallows them to be modelled and to evolve; while maintaining a category versioning systemthat captures all the different versions of a category along with the process of its evolution;this helps to better understand and communicate different versions of categories and the …,*,*,*
A Semantic Web Approach to Validating Semistructured Data,Yuan Fang Li; Jing Sun; Gillian Dobbie; Hai Wang; Jun Sun,Abstract. There has been a rapid growth in the use of semistructured data in both webapplications and database systems. Consequently; the design of good semistructured datamodels is essential. In the relational database area; algorithms have been defined totransform a relational schema from one form to a more suitable form; using algorithms suchas normalization; and these algorithms have been shown to preserve certain semantics. Thework presented in this paper is the first step to represent such algorithms for semistructureddata; namely formally defining the semantics necessary for such algorithms. Furthermore;formal semantics and automated reasoning tools enable us to reveal the inconsistencies ina semistructured data model and its instances. The Object Relationship Attribute model forSemistructured data (ORA-SS) is a graphical notation for designing and representing …,*,*,*
AZ Approach in Validating ORA-SS Data Models,Scott Uk-Jin Lee1 Jing Sun; Gillian Dobbie; Yuan Fang Li,Abstract The rapid growth of the World Wide Web has resulted in more data being accessedover the Internet. In turn there is an increase in the use of semistructured data; which plays acrucial role in many web applications particularly with the introduction of XML and its relatedtechnologies. This increase in use makes the design of good semistructured data structuresessential. The Object Relationship Attribute model for Semistructured data (ORA-SS) is agraphical notation for designing and representing semistructured data. In this paper; wedemonstrate an approach to formally validate the ORA-SS data models in order to enhancethe correctness of semistructured data design. A mathematical semantics for the ORA-SSnotation is defined using the Z formal language; and further validation processes are carriedout to check the correctness of the semistructured data models at both the schema and …,*,*,*
