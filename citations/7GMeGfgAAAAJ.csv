Conceptual modeling for ETL processes,Panos Vassiliadis; Alkis Simitsis; Spiros Skiadopoulos,Abstract Extraction-Transformation-Loading (ETL) tools are pieces of software responsiblefor the extraction of data from several sources; their cleansing; customization and insertioninto a data warehouse. In this paper; we focus on the problem of the definition of ETLactivities and provide formal foundations for their conceptual representation. The proposedconceptual model is (a) customized for the tracing of inter-attribute relationships and therespective ETL activities in the early stages of a data warehouse project;(b) enriched witha'palette'of a set of frequently used ETL activities; like the assignment of surrogate keys; thecheck for null values; etc; and (c) constructed in a customizable and extensible manner; sothat the designer can enrich it with his own re-occurring patterns for ETL activities.,Proceedings of the 5th ACM international workshop on Data Warehousing and OLAP,2002,457
Optimizing ETL processes in data warehouses,Alkis Simitsis; Panos Vassiliadis; Timos Sellis,Extraction-transformation-loading (ETL) tools are pieces of software responsible for theextraction of data from several sources; their cleansing; customization and insertion into adata warehouse. Usually; these processes must be completed in a certain time window;thus; it is necessary to optimize their execution time. In this paper; we delve into the logicaloptimization of ETL processes; modeling it as a state-space search problem. We considereach ETL workflow as a state and fabricate the state space through a set of correct statetransitions. Moreover; we provide algorithms towards the minimization of the execution costof an ETL workflow.,Data Engineering; 2005. ICDE 2005. Proceedings. 21st International Conference on,2005,243
Data integration flows for business intelligence,Umeshwar Dayal; Malu Castellanos; Alkis Simitsis; Kevin Wilkinson,Abstract Business Intelligence (BI) refers to technologies; tools; and practices for collecting;integrating; analyzing; and presenting large volumes of information to enable better decisionmaking. Today's BI architecture typically consists of a data warehouse (or one or more datamarts); which consolidates data from several operational databases; and serves a variety offront-end querying; reporting; and analytic tools. The back-end of the architecture is a dataintegration pipeline for populating the data warehouse by extracting data from distributedand usually heterogeneous operational sources; cleansing; integrating and transforming thedata; and loading it into the data warehouse. Since BI systems have been used primarily foroff-line; strategic decision making; the traditional data integration pipeline is a oneway; batchprocess; usually implemented by extract-transform-load (ETL) tools. The design and …,Proceedings of the 12th International Conference on Extending Database Technology: Advances in Database Technology,2009,191
A generic and customizable framework for the design of ETL scenarios,Panos Vassiliadis; Alkis Simitsis; Panos Georgantas; Manolis Terrovitis; Spiros Skiadopoulos,Abstract Extraction–transformation–loading (ETL) tools are pieces of software responsiblefor the extraction of data from several sources; their cleansing; customization and insertioninto a data warehouse. In this paper; we delve into the logical design of ETL scenarios andprovide a generic and customizable framework in order to support the DW designer in histask. First; we present a metamodel particularly customized for the definition of ETL activities.We follow a workflow-like approach; where the output of a certain activity can either bestored persistently or passed to a subsequent activity. Also; we employ a declarativedatabase programming language; LDL; to define the semantics of each activity. Themetamodel is generic enough to capture any possible ETL activity. Nevertheless; in thepursuit of higher reusability and flexibility; we specialize the set of our generic metamodel …,Information Systems,2005,169
Ranking and clustering web services using multicriteria dominance relationships,Dimitrios Skoutas; Dimitris Sacharidis; Alkis Simitsis; Timos Sellis,As the web is increasingly used not only to find answers to specific information needs butalso to carry out various tasks; enhancing the capabilities of current web search engineswith effective and efficient techniques for web service retrieval and selection becomes animportant issue. Existing service matchmakers typically determine the relevance between aweb service advertisement and a service request by computing an overall score thataggregates individual matching scores among the various parameters in their descriptions.Two main drawbacks characterize such approaches. First; there is no single matchingcriterion that is optimal for determining the similarity between parameters. Instead; there arenumerous approaches ranging from Information Retrieval similarity measures up tosemantic logic-based inference rules. Second; the reduction of individual scores to an …,IEEE Transactions on Services Computing,2010,138
Ontology-based conceptual design of ETL processes for both structured and semi-structured data,Dimitrios Skoutas; Alkis Simitsis,Abstract One of the main tasks in the early stages of a data warehouse project is theidentification of the appropriate transformations and the specification of inter-schemamappings from the data sources to the data warehouse. In this article; we propose anontology-based approach to facilitate the conceptual design of the back stage of a datawarehouse. A graph-based representation is used as a conceptual model for the datastores;so that both structured and semi-structured data are supported and handled in a uniformway. The proposed approach is based on the use of Semantic Web technologies tosemantically annotate the data sources and the data warehouse; so that mappings betweenthem can be inferred; thereby resolving the issue of heterogeneity. Specifically; a suitableapplication ontology is created and used to annotate the datastores. The language used …,International Journal on Semantic Web and Information Systems (IJSWIS),2007,124
State-space optimization of ETL workflows,Alkis Simitsis; Panos Vassiliadis; Timos Sellis,Extraction-transformation-loading (ETL) tools are pieces of software responsible for theextraction of data from several sources; their cleansing; customization; and insertion into adata warehouse. In this paper; we derive into the logical optimization of ETL processes;modeling it as a state-space search problem. We consider each ETL workflow as a state andfabricate the state space through a set of correct state transitions. Moreover; we provide anexhaustive and two heuristic algorithms toward the minimization of the execution cost of anETL workflow. The heuristic algorithm with greedy characteristics significantly outperformsthe other two algorithms for a large set of experimental cases.,IEEE Transactions on Knowledge and Data Engineering,2005,120
Supporting streaming updates in an active data warehouse,Neoklis Polyzotis; Spiros Skiadopoulos; Panos Vassiliadis; Alkis Simitsis; Nils-Erik Frantzell,Active data warehousing has emerged as an alternative to conventional warehousingpractices in order to meet the high demand of applications for up-to-date information. In anutshell; an active warehouse is refreshed on-line and thus achieves a higher consistencybetween the stored information and the latest data updates. The need for on-line warehouserefreshment introduces several challenges in the implementation of data warehousetransformations; with respect to their execution time and their overhead to the warehouseprocesses. In this paper; we focus on a frequently encountered operation in this context;namely; the join of a fast stream S of source updates with a disk-based relation R; under theconstraint of limited memory. This operation lies at the core of several commontransformations; such as; surrogate key assignment; duplicate detection or identification …,Data Engineering; 2007. ICDE 2007. IEEE 23rd International Conference on,2007,109
Mapping conceptual to logical models for ETL processes,Alkis Simitsis,Abstract Extraction-Transformation-Loading (ETL) tools are pieces of software responsiblefor the extraction of data from several sources; their cleansing; customization and insertioninto a data warehouse. In previous line of research; we have presented a conceptual and alogical model for ETL processes. In this paper; we describe the mapping of the conceptual tothe logical model. First; we identify how a conceptual entity is mapped to a logical entity.Next; we determine the execution order in the logical workflow using information adaptedfrom the conceptual model. Finally; we provide a methodology for the transition from theconceptual to the logical model.,Proceedings of the 8th ACM international workshop on Data warehousing and OLAP,2005,108
Designing ETL processes using semantic web technologies,Dimitrios Skoutas; Alkis Simitsis,Abstract One of the most important tasks performed in the early stages of a data warehouseproject is the analysis of the structure and content of the existing data sources and theirintentional mapping to a common data model. Establishing the appropriate mappingsbetween the attributes of the data sources and the attributes of the data warehouse tables iscritical in specifying the required transformations in an ETL workflow. The selected datamodel should besuitable for facilitating the redefinition and revision efforts; typicallyoccurring during the early phases of a data warehouse project; and serve as the means ofcommunication between the involved parties. In this paper; we argue that ontologiesconstitute a very suitable model for this purpose and show how the usage of ontologies canenable a high degree of automation regarding the construction of an ETL design.,Proceedings of the 9th ACM international workshop on Data warehousing and OLAP,2006,100
Modeling ETL activities as graphs.,Panos Vassiliadis; Alkis Simitsis; Spiros Skiadopoulos,Abstract. Extraction-Transformation-Loading (ETL) tools are pieces of software responsiblefor the extraction of data from several sources; their cleansing; customization and insertioninto a data warehouse. In this paper; we focus on the logical design of the ETL scenario of adata warehouse. We define a formal logical model for ETL processes. The data stores;activities and their constituent parts are formally introduced. An ETL scenario is defined asthe combination of ETL activities and data stores. Then; we show how this model is reducedto a graph; which we call the Architecture Graph. We model all the aforementioned entitiesas nodes and four different kinds of relationships (instance-of; part-of; regulator and providerrelationships) as edges. Also; we provide simple graph transformations that reduce thecomplexity of the graph. Finally; in order to support the engineering of the design and the …,DMDW,2002,95
Using semantic web technologies for exploratory OLAP: a survey,Alberto Abelló; Oscar Romero; Torben Bach Pedersen; Rafael Berlanga; Victoria Nebot; Maria Jose Aramburu; Alkis Simitsis,This paper describes the convergence of some of the most influential technologies in the lastfew years; namely data warehousing (DW); on-line analytical processing (OLAP); and theSemantic Web (SW). OLAP is used by enterprises to derive important business-criticalknowledge from data inside the company. However; the most interesting OLAP queries canno longer be answered on internal data alone; external data must also be discovered (mostoften on the web); acquired; integrated; and (analytically) queried; resulting in a new type ofOLAP; exploratory OLAP. When using external data; an important issue is knowing theprecise semantics of the data. Here; SW technologies come to the rescue; as they allowsemantics (ranging from very simple to very complex) to be specified for web-availableresources. SW technologies do not only support capturing the “passive” semantics; but …,IEEE transactions on knowledge and data engineering,2015,91
A Framework for the Design of ETL Scenarios,Panos Vassiliadis; Alkis Simitsis; Panos Georgantas; Manolis Terrovitis,Abstract Extraction-Transformation-Loading (ETL) tools are pieces of software responsiblefor the extraction of data from several sources; their cleansing; customization and insertioninto a data warehouse. In this paper; we delve into the logical design of ETL scenarios. Wedescribe a framework for the declarative specification of ETL scenarios with two maincharacteristics: genericity and customization. Moreover; we present a palette of severaltemplates; representing frequently used ETL activities along with their semantics and theirinterconnection. Finally; we discuss implementation issues and we present a graphical tool;A RKTOS II that facilitates the design of ETL scenarios; based on our model.,International Conference on Advanced Information Systems Engineering,2003,87
Meshing streaming updates with persistent data in an active data warehouse,Neoklis Polyzotis; Spiros Skiadopoulos; Panos Vassiliadis; Alkis Simitsis; Nils Frantzell,Active data warehousing has emerged as an alternative to conventional warehousingpractices in order to meet the high demand of applications for up-to-date information. In anutshell; an active warehouse is refreshed online and thus achieves a higher consistencybetween the stored information and the latest data updates. The need for online warehouserefreshment introduces several challenges in the implementation of data warehousetransformations; with respect to their execution time and their overhead to the warehouseprocesses. In this paper; we focus on a frequently encountered operation in this context;namely; the join of a fast stream 5" of source updates with a disk-based relation R; under theconstraint of limited memory. This operation lies at the core of several commontransformations such as surrogate key assignment; duplicate detection; or identification of …,IEEE Transactions on Knowledge and Data Engineering,2008,84
Deciding the physical implementation of ETL workflows,Vasiliki Tziovara; Panos Vassiliadis; Alkis Simitsis,Abstract In this paper; we deal with the problem of determining the best possible physicalimplementation of an ETL workflow; given its logical-level description and an appropriatecost model as inputs. We formulate the problem as a state-space problem and provide asuitable solution for this task. We further extend this technique by intentionally introducingsorter activities in the workflow in order to search for alternative physical implementationswith lower cost. We experimentally assess our method based on a principled organization oftest suites.,Proceedings of the ACM tenth international workshop on Data warehousing and OLAP,2007,77
Précis: The Essence of a Query Answer,Georgia Koutrika; Alkis Simitsis; Yannis Ioannidis,Wide spread use of database systems in modern society has brought the need to provideinexperienced users with the ability to easily search a database with no specific knowledgeof a query language. Several recent research efforts have focused on supporting keyword-based searches over relational databases. This paper presents an alternative proposal andintroduces the idea of précis queries. These are free-form queries whose answer (a précis)is a synthesis of results; containing not only information directly related to the queryselections but also information implicitly related to them in various ways. Our approach toprécis queries includes two additional novelties:(a) queries do not generate individualrelations but entire multi-relation databases; and (b) query results are personalized to user-specific and/or domain requirements. We develop a framework and system architecture …,22nd International Conference on Data Engineering (ICDE'06),2006,75
Near real time ETL,Panos Vassiliadis; Alkis Simitsis,Abstract Near real time ETL deviates from the traditional conception of data warehouserefreshment; which is performed off-line in a batch mode; and adopts the strategy ofpropagating changes that take place in the sources towards the data warehouse to theextent that both the sources and the warehouse can sustain the incurred workload. In thisarticle; we review the state of the art for both conventional and near real time ETL; wediscuss the background; the architecture; and the technical issues that arise in the area ofnear real time ETL; and we pinpoint interesting research challenges for future work.,*,2009,74
Near real time ETL,Panos Vassiliadis; Alkis Simitsis,Abstract Near real time ETL deviates from the traditional conception of data warehouserefreshment; which is performed off-line in a batch mode; and adopts the strategy ofpropagating changes that take place in the sources towards the data warehouse to theextent that both the sources and the warehouse can sustain the incurred workload. In thisarticle; we review the state of the art for both conventional and near real time ETL; wediscuss the background; the architecture; and the technical issues that arise in the area ofnear real time ETL; and we pinpoint interesting research challenges for future work.,*,2009,74
QoX-driven ETL design: reducing the cost of ETL consulting engagements,Alkis Simitsis; Kevin Wilkinson; Malu Castellanos; Umeshwar Dayal,Abstract As business intelligence becomes increasingly essential for organizations and as itevolves from strategic to operational; the complexity of Extract-Transform-Load (ETL)processes grows. In consequence; ETL engagements have become very time consuming;labor intensive; and costly. At the same time; additional requirements besides functionalityand performance need to be considered in the design of ETL processes. In particular; thedesign quality needs to be determined by an intricate combination of different metrics likereliability; maintenance; scalability; and others. Unfortunately; there are no methodologies;modeling languages or tools to support ETL design in a systematic; formal way for achievingthese quality requirements. The current practice handles them with ad-hoc approaches onlybased on designers' experience. This results in either poor designs that do not meet the …,Proceedings of the 2009 ACM SIGMOD International Conference on Management of data,2009,73
Optimizing ETL workflows for fault-tolerance,Alkis Simitsis; Kevin Wilkinson; Umeshwar Dayal; Malu Castellanos,Extract-Transform-Load (ETL) processes play an important role in data warehousing.Typically; design work on ETL has focused on performance as the sole metric to make surethat the ETL process finishes within an allocated time window. However; other qualitymetrics are also important and need to be considered during ETL design. In this paper; weaddress ETL design for performance plus fault-tolerance and freshness. There are manyreasons why an ETL process can fail and a good design needs to guarantee that it can berecovered within the ETL time window. How to make ETL robust to failures is not trivial.There are different strategies that can be used and they each have different costs andbenefits. In addition; other metrics can affect the choice of a strategy; eg; higher freshnessreduces the time window for recovery. The design space is too large for informal; ad-hoc …,Data Engineering (ICDE); 2010 IEEE 26th International Conference on,2010,71
A method for the mapping of conceptual designs to logical blueprints for ETL processes,Alkis Simitsis; Panos Vassiliadis,Abstract Extraction–Transformation–Loading (ETL) tools are pieces of software responsiblefor the extraction of data from several sources; their cleansing; customization and insertioninto a data warehouse. In previous work; we presented a modeling framework for ETLprocesses comprised of a conceptual model that concretely deals with the early stages of adata warehouse project; and a logical model that deals with the definition of data-centricworkflows. In this paper; we describe the mapping of the conceptual model to the logicalmodel. First; we identify how conceptual entities are mapped to logical entities. Next; wedetermine the execution order in the logical workflow using information adapted from theconceptual model. Finally; we provide a method for the transition from the conceptual modelto the logical model.,Decision Support Systems,2008,70
Top-k dominant web services under multi-criteria matching,Dimitrios Skoutas; Dimitris Sacharidis; Alkis Simitsis; Verena Kantere; Timos Sellis,Abstract As we move from a Web of data to a Web of services; enhancing the capabilities ofthe current Web search engines with effective and efficient techniques for Web servicesretrieval and selection becomes an important issue. Traditionally; the relevance of a Webservice advertisement to a service request is determined by computing an overall score thataggregates individual matching scores among the various parameters in their descriptions.Two drawbacks characterize such approaches. First; there is no single matching criterionthat is optimal for determining the similarity between parameters. Instead; there arenumerous approaches ranging from using Information Retrieval similarity metrics up tosemantic logic-based inference rules. Second; the reduction of individual scores to anoverall similarity leads to significant information loss. Since there is no consensus on how …,Proceedings of the 12th international conference on extending database technology: advances in database technology,2009,67
System; method; and apparatus for multidimensional exploration of content items in a content store,*,A computer-implemented method for accessing content items in a content store aredescribed. In one embodiment; the computer-implemented method includes maintaining atext index of content items in a content store to enable a keyword search on the contentitems; receiving a query having a keyword and generating a hit list from the text index usingthe keyword; and extracting frequent phrases from text within content items of the hit list. Thecomputer-implemented method also includes assigning a relative relevance to the frequentphrases and grouping content items into topics based on presence of relevant phraseswithin the content items of the hit list. The hit list includes one or more content items of thecontent store. The frequent phrases having a relatively high relevance are relevant phrases.,*,2013,66
Optimizing analytic data flows for multiple execution engines,Alkis Simitsis; Kevin Wilkinson; Malu Castellanos; Umeshwar Dayal,Abstract Next generation business intelligence involves data flows that span differentexecution engines; contain complex functionality like data/text analytics; machine learningoperations; and need to be optimized against various objectives. Creating correct analyticdata flows in such an environment is a challenging task and is both labor-intensive and time-consuming. Optimizing these flows is currently an ad-hoc process where the result is largelydependent on the abilities and experience of the flow designer. Our previous workaddressed analytic flow optimization for multiple objectives over a single execution engine.This paper focuses on optimizing flows for a single objective; namely performance; overmultiple execution engines. We consider flows that span a DBMS; a Map-Reduce engine;and an orchestration engine (eg; an ETL tool or scripting language). This configuration is …,Proceedings of the 2012 ACM SIGMOD International Conference on Management of Data,2012,65
GEM: requirement-driven generation of ETL and multidimensional conceptual designs,Oscar Romero; Alkis Simitsis; Alberto Abelló,Abstract At the early stages of a data warehouse design project; the main objective is tocollect the business requirements and needs; and translate them into an appropriateconceptual; multidimensional design. Typically; this task is performed manually; through aseries of interviews involving two different parties: the business analysts and technicaldesigners. Producing an appropriate conceptual design is an error-prone task thatundergoes several rounds of reconciliation and redesigning; until the business needs aresatisfied. It is of great importance for the business of an enterprise to facilitate and automatesuch a process. The goal of our research is to provide designers with a semi-automaticmeans for producing conceptual multidimensional designs and also; conceptualrepresentation of the extract-transform-load (ETL) processes that orchestrate the data flow …,International Conference on Data Warehousing and Knowledge Discovery,2011,63
Précis: from unstructured keywords as queries to structured databases as answers,Alkis Simitsis; Georgia Koutrika; Yannis Ioannidis,Abstract Précis queries represent a novel way of accessing data; which combines ideas andtechniques from the fields of databases and information retrieval. They are free-form;keyword-based; queries on top of relational databases that generate entire multi-relationdatabases; which are logical subsets of the original ones. A logical subset contains not onlyitems directly related to the given query keywords but also items implicitly related to them invarious ways; with the purpose of providing to the user much greater insight into the originaldata. In this paper; we lay the foundations for the concept of logical database subsets thatare generated from précis queries under a generalized perspective that removes severalrestrictions of previous work. In particular; we extend the semantics of précis queriesconsidering that they may contain multiple terms combined through the AND; OR; and …,The VLDB Journal—The International Journal on Very Large Data Bases,2008,62
A Methodology for the Conceptual Modeling of ETL Processes.,Alkis Simitsis; Panos Vassiliadis,Abstract. Extraction-Transformation-Loading (ETL) tools are pieces of software responsiblefor the extraction of data from several sources; their cleansing; customization and insertioninto a data warehouse. In this paper; we propose a methodology for the earliest stages of thedata warehouse design; with the goal of tracing the analysis of the structure and content ofthe existing data sources and their intentional mapping to the common conceptual datawarehouse model. The methodology comprises a set of steps that can be summarized asfollows:(a) identification of the proper data stores;(b) candidates and active candidates forthe involved data stores;(c) attribute mapping between the providers and the consumers;and (d) annotation of the diagram with runtime constraints.,CAiSE workshops,2003,62
On the logical modeling of ETL processes,Panos Vassiliadis; Alkis Simitsis; Spiros Skiadopoulos,Abstract Extraction-Transformation-Loading (ETL) tools are pieces of software responsiblefor the extraction of data from several sources; their cleansing; customization and insertioninto a data warehouse. Research has only recently dealt with the above problem andprovided few models; tools and techniques to address the issues around the ETLenvironment [1; 2; 3; 5]. In this paper; we present a logical model for ETL processes. Theproposed model is characterized by several templates; representing frequently used ETLactivities along with their semantics and their interconnection. In the full version of the paper[4] we present more details on the aforementioned issues and complement them with resultson the characterization of the content of the involved data stores after the execution of anETL scenario and impact-analysis results in the presence of changes.,International Conference on Advanced Information Systems Engineering,2002,61
A taxonomy of ETL activities,Panos Vassiliadis; Alkis Simitsis; Eftychia Baikousi,Abstract Extract-Transform-Load (ETL) activities are software modules responsible forpopulating a data warehouse with operational data; which have undergone a series oftransformations on their way to the warehouse. The whole process is very complex and ofsignifi-cant importance for the design and maintenance of the data ware-house. A plethoraof commercial ETL tools are already available in the market. However; each one of themfollows a different ap-proach for the modeling of ETL activities; ie; of the building blocks of anETL workflow. As a result; so far there is no standard or unified approach for describing suchactivities. In this paper; we are working towards the identification of generic properties thatcharacterize ETL activities. In doing so; we follow a black-box approach and provide ataxonomy that characterizes ETL activities in terms of the relationship of their input to their …,Proceedings of the ACM twelfth international workshop on Data warehousing and OLAP,2009,60
Extraction; transformation; and loading,Panos Vassiliadis; Alkis Simitsis,Definition eAccessibility refers to the access of Information and CommunicationTechnologies (ICT) by people with disabilities; with particular emphasis on the World WideWeb. It is the extent to which the use of an application or service is affected by the user'sparticular functional limitations or abilities (permanent or temporary). eAccessibility can beconsidered as a fundamental prerequisite of usability.,*,2009,57
A ranking mechanism for semanticweb service discovery,Dimitrios Skoutas; Alkis Simitsis; Timos Sellis,This paper presents an approach for ranking semantic Web service advertisements withrespect to a service request. The use of recall and precision is proposed as suitablemeasures for determining the degree of match between the request and the advertisement.Ranking is based on the use of the domain ontology to infer the semantic similarity betweenthe parameters of the request and the advertisement. The proposed approach is applicableto several types of ontologies; ranging from simple taxonomies to highly expressiveontologies; such as OWL ontologies.,Services; 2007 IEEE Congress on,2007,57
Leveraging business process models for ETL design,Kevin Wilkinson; Alkis Simitsis; Malu Castellanos; Umeshwar Dayal,Abstract As Business Intelligence evolves from off-line strategic decision making to on-lineoperational decision making; the design of the back-end Extract-Transform-Load (ETL)processes is becoming even more complex. Many challenges arise in this new context liketheir optimization and modeling. In this paper; we focus on the disconnection between the IT-level view of the enterprise presented by ETL processes and the business view of theenterprise required by managers and analysts. We propose the use of business processmodels for a conceptual view of ETL. We show how to link this conceptual view to existingbusiness processes and how to translate from this conceptual view to a logical ETL view thatcan be optimized. Thus; we link the ETL processes back to their underlying businessprocesses and so enable not only a business view of the ETL; but also a near real-time …,International Conference on Conceptual Modeling,2010,51
Modeling and managing ETL processes.,Alkis Simitsis,Abstract Extraction-Transformation-Loading (ETL) tools are pieces of software responsiblefor the extraction of data from several sources; their cleansing; customization and insertioninto a data warehouse. The design; development and deployment of ETL processes; whichis currently; performed in an ad-hoc; in house fashion; needs modeling; design andmethodological foundations. Unfortunately; the research community has a lot of work to do toconfront this shortcoming. Our research explores a coherent framework for the conceptual;the logical; and the physical design of ETL processes. We delve into the modeling of ETLactivities and provide a conceptual and a logical abstraction for the representation of theseprocesses. Moreover; we focus on the optimization of the ETL processes; in order tominimize the execution time of an ETL process.,VLDB PhD Workshop,2003,50
Multidimensional content exploration,Alkis Simitsis; Akanksha Baid; Yannis Sismanis; Berthold Reinwald,Abstract Content Management Systems (CMS) store enterprise data such as insuranceclaims; insurance policies; legal documents; patent applications; or archival data like in thecase of digital libraries. Search over content allows for information retrieval; but does notprovide users with great insight into the data. A more analytical view is needed throughanalysis; aggregations; groupings; trends; pivot tables or charts; and so on.Multidimensional Content eXploration (MCX) is about effectively analyzing and exploringlarge amounts of content by combining keyword search with OLAP-style aggregation;navigation; and reporting. We focus on unstructured data or generally speaking documentsor content with limited metadata; as it is typically encountered in CMS. We formally presenthow CMS content and metadata should be organized in a well-defined multidimensional …,Proceedings of the VLDB Endowment,2008,44
Towards a benchmark for etl workflows,Panos Vassiliadis; Anastasios Karagiannis; Vasiliki Tziovara; Alkis Simitsis; Ioannina Hellas,Abstract Extraction–Transform–Load (ETL) processes comprise complex data workflows;which are responsible for the maintenance of a Data Warehouse. Their practical importanceis denoted by the fact that a plethora of ETL tools currently constitutes a multi-million dollarsmarket. However; each one of them follows a different design and modeling technique andinternal language. So far; the research community has not agreed upon the basiccharacteristics of ETL tools. Hence; there is a necessity for a unified way to assess ETLworkflows. In this paper; we investigate the main characteristics and peculiarities of ETLprocesses and we propose a principled organization of test suites for the problem ofexperimenting with ETL scenarios. 1.,*,2007,43
Benchmarking ETL workflows,Alkis Simitsis; Panos Vassiliadis; Umeshwar Dayal; Anastasios Karagiannis; Vasiliki Tziovara,Abstract Extraction–Transform–Load (ETL) processes comprise complex data workflows;which are responsible for the maintenance of a Data Warehouse. A plethora of ETL tools iscurrently available constituting a multi-million dollar market. Each ETL tool uses its owntechnique for the design and implementation of an ETL workflow; making the task ofassessing ETL tools extremely difficult. In this paper; we identify common characteristics ofETL workflows in an effort of proposing a unified evaluation method for ETL. We also identifythe main points of interest in designing; implementing; and maintaining ETL workflows.Finally; we propose a principled organization of test suites based on the TPC-H schema forthe problem of experimenting with ETL workflows.,Technology Conference on Performance Evaluation and Benchmarking,2009,42
Explaining structured queries in natural language,Georgia Koutrika; Alkis Simitsis; Yannis E Ioannidis,Many applications offer a form-based environment for naïve users for accessing databaseswithout being familiar with the database schema or a structured query language. Userinteractions are translated to structured queries and executed. However; as a user is unlikelyto know the underlying semantic connections among the fields presented in a form; it is oftenuseful to provide her with a textual explanation of the query. In this paper; we take a graph-based approach to the query translation problem. We represent various forms of structuredqueries as directed graphs and we annotate the graph edges with template labels using anextensible template mechanism. We present different graph traversal strategies for efficientlyexploring these graphs and composing textual query descriptions. Finally; we presentexperimental results for the efficiency and effectiveness of the proposed methods.,Data Engineering (ICDE); 2010 IEEE 26th International Conference on,2010,41
Policy-regulated management of ETL evolution,George Papastefanatos; Panos Vassiliadis; Alkis Simitsis; Yannis Vassiliou,Abstract In this paper; we discuss the problem of performing impact prediction for changesthat occur in the schema/structure of the data warehouse sources. We abstract Extract-Transform-Load (ETL) activities as queries and sequences of views. ETL activities and itssources are uniformly modeled as a graph that is annotated with policies for themanagement of evolution events. Given a change at an element of the graph; our methoddetects the parts of the graph that are affected by this change and highlights the way theyare tuned to respond to it. For many cases of ETL source evolution; we present rules so thatboth syntactical and semantic correctness of activities are retained. Finally; we experimentwith the evaluation of our approach over real-world ETL workflows used in the Greek publicsector.,*,2009,37
Scheduling strategies for efficient ETL execution,Anastasios Karagiannis; Panos Vassiliadis; Alkis Simitsis,Abstract Extract-transform-load (ETL) workflows model the population of enterprise datawarehouses with information gathered from a large variety of heterogeneous data sources.ETL workflows are complex design structures that run under strict performance requirementsand their optimization is crucial for satisfying business objectives. In this paper; we deal withthe problem of scheduling the execution of ETL activities (aka transformations; tasks;operations); with the goal of minimizing ETL execution time and allocated memory. Weinvestigate the effects of four scheduling policies on different flow structures andconfigurations and experimentally show that the use of different scheduling policies mayimprove ETL performance in terms of memory consumption and execution time. First; weexamine a simple; fair scheduling policy. Then; we study the pros and cons of two other …,Information Systems,2013,36
What-if analysis for data warehouse evolution,George Papastefanatos; Panos Vassiliadis; Alkis Simitsis; Yannis Vassiliou,Abstract In this paper; we deal with the problem of performing what-if analysis for changesthat occur in the schema/structure of the data warehouse sources. We abstract softwaremodules; queries; reports and views as (sequences of) queries in SQL enriched withfunctions. Queries and relations are uniformly modeled as a graph that is annotated withpolicies for the management of evolution events. Given a change at an element of the graph;our method detects the parts of the graph that are affected by this change and indicates theway they are tuned to respond to it.,International Conference on Data Warehousing and Knowledge Discovery,2007,35
Representation of conceptual ETL designs in natural language using Semantic Web technology,Alkis Simitsis; Dimitrios Skoutas; Malú Castellanos,Abstract Extract-Transform-Load (ETL) processes constitute the back stage of DataWarehouse architectures. Several studies characterize the ETL design as a time-consumingand error-prone procedure. A critical phase in the ETL lifecycle involves the earlycommunications and design steps that aim at producing a conceptual ETL design. Variousresearch approaches have dealt with the conceptual modeling of ETL processes; but allshare two inconveniences: they require intensive human effort from the designers to createthem; as well as technical knowledge from the business people to understand them. In thispaper; we focus on the second aspect and provide a method for the representation of aconceptual ETL design as a narrative; which is the most natural means of communicationand does not require particular technical skills or familiarity with any specific model …,Data & Knowledge Engineering,2010,34
Ontology-driven conceptual design of ETL processes using graph transformations,Dimitrios Skoutas; Alkis Simitsis; Timos Sellis,Abstract One of the main tasks during the early steps of a data warehouse project is theidentification of the appropriate transformations and the specification of inter-schemamappings from the source to the target data stores. This is a challenging task; requiring firstlythe semantic and secondly the structural reconciliation of the information provided by theavailable sources. This task is a part of the Extract-Transform-Load (ETL) process; which isresponsible for the population of the data warehouse. In this paper; we propose acustomizable and extensible ontology-driven approach for the conceptual design of ETLprocesses. A graph-based representation is used as a conceptual model for the source andtarget data stores. We then present a method for devising flows of ETL operations by meansof graph transformations. In particular; the operations comprising the ETL process are …,*,2009,34
Graph-based modeling of ETL activities with multi-level transformations and updates,Alkis Simitsis; Panos Vassiliadis; Manolis Terrovitis; Spiros Skiadopoulos,Abstract Extract-Transform-Load (ETL) workflows are data centric workflows responsible fortransferring; cleaning; and loading data from their respective sources to the warehouse. Inthis paper; we build upon existing graph-based modeling techniques that treat ETLworkflows as graphs by (a) extending the activity semantics to incorporate negation;aggregation and self-joins;(b) complementing querying semantics with insertions; deletionsand updates; and (c) transforming the graph to allow zoom-in/out at multiple levels ofabstraction (ie; passing from the detailed description of the graph at the attribute level tomore compact variants involving programs; relations and queries and vice-versa).,International Conference on Data Warehousing and Knowledge Discovery,2005,32
Serving the sky: Discovering and selecting semantic web services through dynamic skyline queries,Dimitrios Skoutas; Dimitris Sacharidis; Alkis Simitsis; Timos Sellis,Semantic Web service descriptions are typically multi-parameter constructs. Discoveringsemantically relevant services given a desirable service description is typically addressedby performing a pairwise; logic-based match between the requested and offeredparameters. However; little or no attention is given to combining these partial results tocompile the final list of candidate services. Instead; this is often done in an ad hoc manner;implying a priori assumptions regarding the user's preferences. In this paper; we focus onidentifying the best candidate Semantic Web services given the description of a requestedservice. We model the problem as a skyline query; also known as the maximum vectorproblem; and we show how the service selection process can be performed efficiently. Weconsider different aspects of the service selection process; addressing both the …,Semantic Computing; 2008 IEEE International Conference on,2008,31
Natural language reporting for ETL processes,Alkis Simitsis; Dimitrios Skoutas; Malú Castellanos,Abstract The conceptual design of the Extract--Transform--Load (ETL) processes is a crucial;burdensome; and challenging procedure that takes places at the early phases of a DataWarehouse project. Several models have been proposed for the conceptual design andrepresentation of ETL processes; but all share two inconveniences: they require intensivehuman effort from the designers to create them; as well as technical knowledge from thebusiness people to understand them. In a previous work; we have relaxed the formerdifficulty by working on the automation of the conceptual design leveraging Semantic Webtechnology. In this paper; we built upon our previous results and we tackle the second issueby investigating the application of natural language generation techniques to the ETLenvironment. In particular; we provide a method for the representation of a conceptual …,Proceedings of the ACM 11th international workshop on Data warehousing and OLAP,2008,25
Blueprints and measures for ETL workflows,Panos Vassiliadis; Alkis Simitsis; Manolis Terrovitis; Spiros Skiadopoulos,Abstract Extract-Transform-Load (ETL) workflows are data centric workflows responsible fortransferring; cleaning; and loading data from their respective sources to the warehouse.Previous research has identified graph-based techniques that construct the blueprints for thestructure of such workflows. In this paper; we extend existing results by explicitlyincorporating the internal semantics of each activity in the workflow graph. Apart from thevalue that blueprints have per se; we exploit our modeling to introduce rigorous techniquesfor the measurement of ETL workflows. To this end; we build upon an existing formalframework for software quality metrics and formally prove how our quality measures fit withinthis framework.,International Conference on Conceptual Modeling,2005,25
Design metrics for data warehouse evolution,George Papastefanatos; Panos Vassiliadis; Alkis Simitsis; Yannis Vassiliou,Abstract During data warehouse design; the designer frequently encounters the problem ofchoosing among different alternatives for the same design construct. The behavior of thechosen design in the presence of evolution events is an important parameter for this choice.This paper proposes metrics to assess the quality of the warehouse design from theviewpoint of evolution. We employ a graph-based model to uniformly abstract relations andsoftware modules; like queries; views; reports; and ETL activities. We annotate thewarehouse graph with policies for the management of evolution events. The proposedmetrics are based on graph-theoretic properties of the warehouse graph to assess the sensitivity of the graph to a set of possible events. We evaluate our metrics with experiments overalternative configurations of the same warehouse schema.,International Conference on Conceptual Modeling,2008,24
Language Extensions for the Automation of Database Schema Evolution.,George Papastefanatos; Panos Vassiliadis; Alkis Simitsis; Konstantinos Aggistalis; Fotini Pechlivani; Yannis Vassiliou,Abstract: The administrators and designers of modern Information Systems face the problemof maintaining their systems in the presence of frequently occurring changes in anycounterpart of it. In other words; when a change occurs in any point of the system–eg;source; schema; view; software construct–they should propagate the change in all theinvolved parts of the system. Hence; it is imperative that the whole process should be donecorrectly; ie; the change should be propagated to all the appropriate points of the system;with a limited overhead imposed on both the system and the humans; who design andmaintain it. In this paper; we are dealing with the problem of evolution in the context ofdatabases. First; we present a coherent; graph-based framework for capturing the effect ofpotential changes in the database software of an Information System. Next; we describe a …,ICEIS (1),2008,24
HECATAEUS: Regulating schema evolution,George Papastefanatos; Panos Vassiliadis; Alkis Simitsis; Yannis Vassiliou,HECATAEUS is an open-source software tool for enabling impact prediction; what-ifanalysis; and regulation of relational database schema evolution. We follow a graphtheoretic approach and represent database schemas and database constructs; like queriesand views; as graphs. Our tool enables the user to create hypothetical evolution events andexamine their impact over the overall graph before these are actually enforced on it. It alsoallows definition of rules for regulating the impact of evolution via (a) default values for all thenodes of the graph and (b) simple annotations for nodes deviating from the default behavior.Finally; HECATAEUS includes a metric suite for evaluating the impact of evolution eventsand detecting crucial and vulnerable parts of the system.,Data Engineering (ICDE); 2010 IEEE 26th International Conference on,2010,23
Automating the loading of business process data warehouses,Malu Castellanos; Alkis Simitsis; Kevin Wilkinson; Umeshwar Dayal,Abstract Business processes drive the operations of an enterprise. In the past; the focus wasprimarily on business process design; modeling; and automation. Recently; enterpriseshave realized that they can benefit tremendously from analyzing the behavior of theirbusiness processes with the objective of optimizing or improving them. In our research; weaddress the problem of warehousing business process execution data so that we cananalyze their behavior using the analytic and reporting tools that are available in datawarehouse environments. We build upon our previous work that described the design andimplementation of a generic process data warehouse for use with any business processes.In this paper; we show how to automate the population of the generic process warehouse bytracking business events from an application environment. Typically; the source data …,Proceedings of the 12th International Conference on Extending Database Technology: Advances in Database Technology,2009,23
A requirement-driven approach to the design and evolution of data warehouses,Petar Jovanovic; Oscar Romero; Alkis Simitsis; Alberto Abelló; Daria Mayorova,Abstract Designing data warehouse (DW) systems in highly dynamic enterpriseenvironments is not an easy task. At each moment; the multidimensional (MD) schemaneeds to satisfy the set of information requirements posed by the business users. At thesame time; the diversity and heterogeneity of the data sources need to be considered inorder to properly retrieve needed data. Frequent arrival of new business needs requires thatthe system is adaptable to changes. To cope with such an inevitable complexity (both at thebeginning of the design process and when potential evolution events occur); in this paperwe present a semi-automatic method called ORE; for creating DW designs in an iterativefashion based on a given set of information requirements. Requirements are first consideredseparately. For each requirement; ORE expects the set of possible MD interpretations of …,Information Systems,2014,22
HFMS: Managing the lifecycle and complexity of hybrid analytic data flows,Alkis Simitsis; Kevin Wilkinson; Umeshwar Dayal; Meichun Hsu,To remain competitive; enterprises are evolving their business intelligence systems toprovide dynamic; near realtime views of business activities. To enable this; they deploycomplex workflows of analytic data flows that access multiple storage repositories andexecution engines and that span the enterprise and even outside the enterprise. We callthese multi-engine flows hybrid flows. Designing and optimizing hybrid flows is achallenging task. Managing a workload of hybrid flows is even more challenging since theirexecution engines are likely under different administrative domains and there is no singlepoint of control. To address these needs; we present a Hybrid Flow Management System(HFMS). It is an independent software layer over a number of independent executionengines and storage repositories. It simplifies the design of analytic data flows and …,Data Engineering (ICDE); 2013 IEEE 29th International Conference on,2013,21
Business Processes Meet Operational Business Intelligence.,Umeshwar Dayal; Kevin Wilkinson; Alkis Simitsis; Malu Castellanos,Abstract As Business Intelligence architectures evolve from off-line strategic decision-making to on-line operational decision-making; the design of the backend Extract-Transform-Load (ETL) processes is becoming even more complex. We describe the challenges in ETLdesign and implementation; and the approach we are taking to meet these challenges. Ourapproach is centered around a layered methodology that starts with modeling the businessprocesses of the enterprise; and their information requirements and service level objectives;and proceeds systematically through logical design to physical implementation. A keyelement of this approach is the explicit specification of a variety of quality objectives (we callthese collectively the QoX objectives) at the business level; and the use of these objectivesto drive the optimization of the design at the logical and physical levels.,IEEE Data Eng. Bull.,2009,20
A randomized approach for the incremental design of an evolving data warehouse,Dimitri Theodoratos; Theodore Dalamagas; Alkis Simitsis; Manos Stavropoulos,Abstract A Data Warehouse (DW) can be used to integrate data from multiple distributeddata sources. A DW can be seen as a set of materialized views that determine its schemaand its content in terms of the schema and the content of the data sources. DW applicationsrequire high query performance. For this reason; t he design of a typical DW consists ofselecting views to materialize that are able to answer a set of input user queries. However;the cost of answering the queries has to be balanced against the cost of maintaining thematerialized views. In an evolving DW application; ne w queries need to be answered by theDW. An incremental selection of materialized views uses the materialized views already inthe DW to answer parts of the new queries; an d avoids the re-implementation of the DWfrom scratch. This incremental design is complex and an exhaustive approach is not …,International Conference on Conceptual Modeling,2001,19
Integrating ETL processes from information requirements,Petar Jovanovic; Oscar Romero; Alkis Simitsis; Alberto Abelló,Abstract Data warehouse (DW) design is based on a set of requirements expressed asservice level agreements (SLAs) and business level objects (BLOs). Populating a DWsystem from a set of information sources is realized with extract-transform-load (ETL)processes based on SLAs and BLOs. The entire task is complex; time consuming; and hardto be performed manually. This paper presents our approach to the requirement-drivencreation of ETL designs. Each requirement is considered separately and a respective ETLdesign is produced. We propose an incremental method for consolidating these individualdesigns and creating an ETL design that satisfies all given requirements. Finally; the designproduced is sent to an ETL engine for execution. We illustrate our approach through anexample based on TPC-H and report on our experimental findings that show the …,International Conference on Data Warehousing and Knowledge Discovery,2012,18
Rule-based Management of Schema Changes at ETL sources,George Papastefanatos; Panos Vassiliadis; Alkis Simitsis; Timos Sellis; Yannis Vassiliou,Abstract In this paper; we visit the problem of the management of inconsistencies emergingon ETL processes as results of evolution operations occurring at their sources. We abstractExtract-Transform-Load (ETL) activities as queries and sequences of views. ETL activitiesand its sources are uniformly modeled as a graph that is annotated with rules for themanagement of evolution events. Given a change at an element of the graph; our frameworkdetects the parts of the graph that are affected by this change and highlights the way theyare tuned to respond to it. We then present the system architecture of a tool calledHecataeus that implements the main concepts of the proposed framework.,East European Conference on Advances in Databases and Information Systems,2009,18
DBMSs should talk back too,Alkis Simitsis; Yannis Ioannidis,Abstract: Natural language user interfaces to database systems have been studied forseveral decades now. They have mainly focused on parsing and interpreting naturallanguage queries to generate them in a formal database language. We envision the reversefunctionality; where the system would be able to take the internal result of that translation;say in SQL form; translate it back into natural language; and show it to the initiator of thequery for verification. Likewise; information extraction has received considerable attention inthe past ten years or so; identifying structured information in free text so that it may then bestored appropriately and queried. Validation of the records stored with a backwardtranslation into text would again be very powerful. Verification and validation of query anddata input of a database system correspond to just one example of the many important …,arXiv preprint arXiv:0909.1786,2009,15
Etl workflows: From formal specification to optimization,Timos K Sellis; Alkis Simitsis,Abstract In this paper; we present our work on a framework towards the modeling andoptimization of Extraction-Transformation-Loading (ETL) workflows. The goal of thisresearch was to facilitate; manage; and optimize the design and implementation of the ETLworkflows both during the initial design and deployment stage; as well as; during thecontinuous evolution of a data warehouse. In particular; we present our results whichinclude:(a) the provision of a novel conceptual model for the tracing of inter-attributerelationships and the respective ETL transformations in the early stages of a datawarehouse project; along with an attempt to use ontology-based mechanisms to semi-automatically capture the semantics and the relationships among the various sources;(b) theprovision of a novel logical model for the representation of ETL workflows with two main …,East European Conference on Advances in Databases and Information Systems,2007,15
ORE: an iterative approach to the design and evolution of multi-dimensional schemas,Petar Jovanovic; Oscar Romero; Alkis Simitsis; Alberto Abelló,Abstract Designing a data warehouse (DW) highly depends on the information requirementsof its business users. However; tailoring a DW design that satisfies all businessrequirements is not an easy task. In addition; complex and evolving business environmentsresult in a continuous emergence of new or changed business needs. Furthermore; forbuilding a correct multidimensional (MD) schema for a DW; the designer should deal withthe semantics and heterogeneity of the underlying data sources. To cope with such aninevitable complexity; both at the beginning of the design process and when a potentialevolution event occurs; in this paper we present a semi-automatic method; named ORE; forconstructing the MD schema in an iterative fashion based on the information requirements.In our approach; we consider each requirement separately and incrementally build the …,Proceedings of the fifteenth international workshop on Data warehousing and OLAP,2012,14
Modeling and optimization of extraction-transformation-loading (ETL) processes in data warehouse environments,Alkis Simitsis; P Vassiliadis; T Sellis; C Of; I Of,This chapter highlights the background of the dissertation and outlines its structure. InSection 1.1 we briefly present a high-level architecture of a data warehouse and we exhibitits main layers. In Section 1.2 we introduce the Extract–Transform–Load (ETL) processes;the general subject of this work. In Section 1.3; we sketch our approach for modeling ETLprocesses; and formulate our main objectives. An overview of the structure and contributionsof the dissertation is given in Section 1.4.,National Technical University of Athens: PhD Thesis; Athens; Greece,2004,14
Engine independence for logical analytic flows,Petar Jovanovic; Alkis Simitsis; Kevin Wilkinson,A complex analytic flow in a modern enterprise may perform multiple; logically independent;tasks where each task uses a different processing engine. We term these multi-engine flowshybrid flows. Using multiple processing engines has advantages such as rapid deployment;better performance; lower cost; and so on. However; as the number and variety of theseengines grows; developing and maintaining hybrid flows is a significant challenge becausethey are specified at a physical level and; so are hard to design and may break as theinfrastructure evolves. We address this problem by enabling flow design at a logical leveland automatic translation to physical flows. There are three main challenges. First; wedescribe how flows can be represented at a logical level; abstracting away details of anyunderlying processing engine. Second; we show how a physical flow; expressed in a …,Data Engineering (ICDE); 2014 IEEE 30th International Conference on,2014,13
Semantic web technologies for business intelligence,Rafael Berlanga; Oscar Romero; Alkis Simitsis; Victoria Nebot; Torben Bach Pedersen; Alberto Abelló; María José Aramburu,Abstract This chapter describes the convergence of two of the most influential technologiesin the last decade; namely business intelligence (BI) and the Semantic Web (SW). Businessintelligence is used by almost any enterprise to derive important business-critical knowledgefrom both internal and (increasingly) external data. When using external data; most oftenfound on the Web; the most important issue is knowing the precise semantics of the data.Without this; the results cannot be trusted. Here; Semantic Web technologies come to therescue; as they allow semantics ranging from very simple to very complex to be specified forany web-available resource. SW technologies do not only support capturing the “passive”semantics; but also support active inference and reasoning on the data. The chapter firstpresents a motivating running example; followed by an introduction to the relevant SW …,*,2012,13
Synthesizing structured text from logical database subsets,Alkis Simitsis; Georgia Koutrika; Yannis Alexandrakis; Yannis Ioannidis,Abstract In the classical database world; information access has been based on a paradigmthat involves structured; schema-aware; queries and tabular answers. In the currentenvironment; however; where information prevails in most activities of society; servingpeople; applications; and devices in dramatically increasing numbers; this paradigm hasproved to be very limited. On the query side; much work has been done on moving towardskeyword queries over structured data. In our previous work; we have touched the other sideas well; and have proposed a paradigm that generates entire databases in response tokeyword queries. In this paper; we continue in the same direction and propose synthesizingtextual answers in response to queries of any kind over structured data. In particular; westudy the transformation of a dynamically-generated logical database subset into a …,Proceedings of the 11th international conference on Extending database technology: Advances in database technology,2008,13
Metrics for the prediction of evolution impact in etl ecosystems: A case study,George Papastefanatos; Panos Vassiliadis; Alkis Simitsis; Yannis Vassiliou,Abstract The Extract-Transform-Load (ETL) flows are essential for the success of a datawarehouse and the business intelligence and decision support mechanisms that areattached to it. During both the ETL design phase and the entire ETL lifecycle; the ETLarchitect needs to design and improve an ETL design in a way that satisfies bothperformance and correctness guarantees and often; she has to choose among variousalternative designs. In this paper; we focus on ways to predict the maintenance effort of ETLworkflows and we explore techniques for assessing the quality of ETL designs under theprism of evolution. We focus on a set of graph-theoretic metrics for the prediction of evolutionimpact and we investigate their fit into real-world ETL scenarios. We present ourexperimental findings and describe the lessons we learned working on real-world cases.,Journal on Data Semantics,2012,12
Logos: a system for translating queries into narratives,Andreas Kokkalis; Panagiotis Vagenas; Alexandros Zervakis; Alkis Simitsis; Georgia Koutrika; Yannis Ioannidis,Abstract This paper presents Logos; a system that provides natural language translations forrelational queries expressed in SQL. Our translation mechanism is based on a graph-basedapproach to the query translation problem. We represent various forms of structured queriesas directed graphs and we annotate the graph edges with template labels using anextensible template mechanism. Logos uses different graph traversal strategies for efficientlyexploring these graphs and composing textual query descriptions. The audience mayinteractively explore Logos using various database schemata and issuing either sample orad hoc queries.,Proceedings of the 2012 ACM SIGMOD International Conference on Management of Data,2012,12
Designing integration flows using hypercubes,Kevin Wilkinson; Alkis Simitsis,Abstract The design and implementation of an ETL (extract-transform-load) process for adata warehouse proceeds from a conceptual model to a logical model; and then a physicalmodel and implementation. The conceptual model conveys at a high level the data sourcesand targets; and the transformation steps from sources to targets. The current state of the artis to express the conceptual model informally using text descriptions and diagrams. Thismakes the process of deriving a logical model time-consuming and error-prone. Our work istowards a system that covers the whole ETL lifecycle by injecting several layers ofoptimization and validation throughout the whole process starting with the business levelobjectives and ending with flow execution. In this paper; we focus on the ETL conceptuallayer and present a solution that assists consultants in their task of defining the needs and …,Proceedings of the 14th International Conference on Extending Database Technology,2011,12
Flexible and Customizable NL Representation of Requirements for ETL processes,Dimitrios Skoutas; Alkis Simitsis,Abstract The design of an Extract–Transform–Load (ETL) workflow for the population of aData Warehouse is a complex and challenging procedure. In previous work; we havepresented an ontology-based approach to facilitate the conceptual design of an ETLscenario. In this paper; we elaborate on this work; by investigating the application of NaturalLanguage (NL) techniques to the ETL environment and we present a flexible andcustomizable template-based mechanism for generating natural language representationsfor the ETL process requirements and operations.,International Conference on Application of Natural Language to Information Systems,2007,12
Quarry: Digging up the gems of your data treasury,Petar Jovanovic; Óscar Romero Moral; Alkis Simitsis; Alberto Abelló Gamazo; Héctor Candón Arenas; Sergi Nadal Francesch,Abstract The design lifecycle of a data warehousing (DW) system is primarily led byrequirements of its end-users and the complexity of underlying data sources. The process ofdesigning a multidimensional (MD) schema and back-end extracttransform-load (ETL)processes; is a long-term and mostly manual task. As enterprises shift to more real-timeand'on-the-fly'decision making; business intelligence (BI) systems require automated meansfor efficiently adapting a physical DW design to frequent changes of business needs. Toaddress this problem; we present Quarry; an end-to-end system for assisting users ofvarious technical skills in managing the incremental design and deployment of MDschemata and ETL processes. Quarry automates the physical design of a DW system fromhigh-level information requirements. Moreover; Quarry provides tools for efficiently …,Proceedings of the 18th International Conference on Extending Database Technology,2015,11
Partitioning real-time ETL workflows,Alkis Simitsis; Chetan Gupta; Song Wang; Umeshwar Dayal,Many organizations are aiming to move away from traditional batch processing ETL to real-time ETL (RT-ETL). This move is motivated by a need to analyze and take decisions on asfresh a data as possible. The RT-ETL engines operate on the abstraction of data flowexecuted on parallel architectures. For high throughput and low response times; there is aneed for partitioning the data over the large number of nodes in the engine. In this paper; weconsider the problem of partitioning realtime ETL flows and we propose a high levelarchitecture for that.,Data Engineering Workshops (ICDEW); 2010 IEEE 26th International Conference on,2010,10
DBPubs: multidimensional exploration of database publications,Akanksha Baid; Andrey Balmin; Heasoo Hwang; Erik Nijkamp; Jun Rao; Berthold Reinwald; Alkis Simitsis; Yannis Sismanis; Frank van Ham,Abstract DBPubs is a system for effectively analyzing and exploring the content of databasepublications by combining keyword search with OLAP-style aggregations; navigation; andreporting. DBPubs starts with keyword search over the content of publications. Thepublications' metadata such as title; authors; venues; year; and so on; provide traditionalOLAP static dimensions; which are combined with dynamic dimensions discovered from thecontent of the publications in the search result; such as frequent phrases; relevant phrases;and topics. We compute publication ranks based on the link structure between documents;ie; citations; and aggregate them to find seminal papers; discover trends; and rank authors.We deploy an OLAP tool for multidimensional content exploration through traditional OLAProllup-drilldown operations on the static and dynamic dimensions; solutions for multi-cube …,Proceedings of the VLDB Endowment,2008,10
Near real time ETL,Panos Vassiliadis; Alkis Simitsis,Abstract Near real time ETL deviates from the traditional conception of data warehouserefreshment; which is performed off-line in a batch mode; and adopts the strategy ofpropagating changes that take place in the sources towards the data warehouse to theextent that both the sources and the warehouse can sustain the incurred workload. In thisarticle; we review the state of the art for both conventional and near real time ETL; wediscuss the background; the architecture; and the technical issues that arise in the area ofnear real time ETL; and we pinpoint interesting research challenges for future work.,Springer Annals of Information Systems,2008,9
Ontology-based data sharing in P2P databases,Dimitrios Skoutas; Verena Kantere; Alkis Simitsis; Timos Sellis,Abstract We consider peer-to-peer systems in which peers share structured data through theuse of schema mappings. Peers express their queries and rewrite incoming queries on theirlocal schema. We assume the existence of one or more ontologies describing the domain ofinterest of the peers. The ontologies are used to semantically annotate each peer schema;making explicit the type of information provided by it. A major problem in such a system isthat peers cannot easily judge the semantic relativeness of their interests to interests of otherpeers; as these are expressed by the respective local schemas. Moreover; peers cannotevaluate the semantic relativeness of answers that they receive to their queries. In thispaper; we propose a semantic similarity measure for evaluating the semantic relativenessbetween peer schemas; as well as between queries and their rewritten versions on other …,*,2008,9
xPAD: a platform for analytic data flows,Alkis Simitsis; Kevin Wilkinson; Petar Jovanovic,Abstract As enterprises become more automated; real-time; and data-driven; they need tointegrate new data sources and specialized processing engines. The traditional businessintelligence architecture of Extract-Transform-Load (ETL) flows; followed by querying;reporting; and analytic operations; is being generalized to analytic data flows that utilize avariety of data types and operations. These complicated flows are difficult to design;implement and maintain since they span a variety of systems. Additionally; new designrequirements may be imposed such as design for fault-tolerance; freshness; maintainability;sampling; etc. To reduce development time and maintenance costs; automation is needed.We present xPAD; our platform to manage analytic data flows. xPAD enables flow design.We show how these designs can be optimized; not just for performance; but for other …,Proceedings of the 2013 ACM SIGMOD International Conference on Management of Data,2013,7
Propagating evolution events in data-centric software artifacts,George Papastefanatos; Panos Vassiliadis; Alkis Simitsis,The success and wellbeing of large organizations rely on the smooth functionality andoperability of their software. Such qualities are largely affected by evolution events andchanges; like software upgrades. In this paper; we are dealing with handling evolutionevents in data management systems. We consider a data-centric ecosystem that capturesrelational tables; views and queries (the latter are seeing as software modules that are eitherinternal to the database; eg; stored procedures; or external software applications that accessthe database). We also consider policies dictating the response of a software module to apossible event. We investigate the impact of such events to the database and present agraph-based mechanism to control event propagation. We show that our mechanismterminates and that every database construct is annotated with a single status; regardless …,Data Engineering Workshops (ICDEW); 2011 IEEE 27th International Conference on,2011,7
Comprehensible answers to précis queries,Alkis Simitsis; Georgia Koutrika,Abstract Users without knowledge of schemas or query languages have difficulties inaccessing information stored in databases. Commercial and research efforts have focusedon keyword-based searches. Among them; précis queries generate entire multi-relationdatabases; which are logical subsets of existing ones; instead of individual relations. Thelogical database subset contains not only items directly related to the query selections butalso items implicitly related to them in various ways. Earlier work has identified the need ofproviding the naïve user with meaningful answers to his questions and has suggested thetranslation of précis query answer in narrative form. In this paper; we present a semi-automatic method that translates the relational output of a précis query into a synthesis ofresults. We describe a translator engine that uses a template mechanism for generating a …,International Conference on Advanced Information Systems Engineering,2006,7
Data Warehouse Back-End Tools.,Alkis Simitsis; Dimitri Theodoratos,The back-end tools of a data warehouse are pieces of software responsible for the extractionof data from several sources; their cleansing; customization; and insertion into a datawarehouse. They are known under the general term extraction; transformation and loading(ETL) tools.,*,2009,6
Generalized précis queries for logical database subset creation,Alkis Simitsis; Georgia Koutrika; Yannis Ioannidis,As a large fraction of available information resides in databases; the need for facilitatingaccess for the large majority of users becomes increasingly more important. Precis queriesare free-form queries that generate entire multi-relation databases; which are logical subsetsof existing ones. A logical subset contains not only items directly related to the given queryselections but also items implicitly related to them in various ways with the purpose ofproviding to the user much greater insight into the original data. This paper is concernedwith the definition and generation of logical database subsets based on precis queriesunder a generalized perspective that removes several restrictions of previous work andhandles queries containing multiple terms combined using the operators AND; OR; andNOT.,Data Engineering; 2007. ICDE 2007. IEEE 23rd International Conference on,2007,6
Incremental consolidation of data-intensive multi-flows,Petar Jovanovic; Oscar Romero; Alkis Simitsis; Alberto Abello,Business intelligence (BI) systems depend on efficient integration of disparate and oftenheterogeneous data. The integration of data is governed by data-intensive flows and isdriven by a set of information requirements. Designing such flows is in general a complexprocess; which due to the complexity of business environments is hard to be done manually.In this paper; we deal with the challenge of efficient design and maintenance of data-intensive flows and propose an incremental approach; namely CoAl; for semi-automaticallyconsolidating data-intensive flows satisfying a given set of information requirements. CoAlworks at the logical level and consolidates data flows from either high-level informationrequirements or platform-specific programs. As CoAl integrates a new data flow; it opts formaximal reuse of existing flows and applies a customizable cost model tuned for …,IEEE Transactions on Knowledge and Data Engineering,2016,5
VQA: vertica query analyzer,Alkis Simitsis; Kevin Wilkinson; Jason Blais; Joe Walsh,Abstract Database query monitoring tools collect performance metrics; such as memory andcpu usage; while a query is executing and make them available through log files or systemtables. The metrics can be used to understand and diagnose query performance issues.However; analytic queries over big data presents new challenges for query monitoring tools.A long-running query may generate tens of thousands of values so simply reporting themetrics may overwhelm the user. Second; analytic queries may be written by databasenovices who have trouble interpreting the metrics. Third; analytic queries may access data orprocessing outside the database through user-defined functions and connectors. The impactof these on query performance must be understood. Vertica Query Analyzer (VQA) is a querymonitoring tool to address these challenges. VQA is both a useful tool and a research …,Proceedings of the 2014 ACM SIGMOD international conference on Management of data,2014,5
Requirement-driven creation and deployment of multidimensional and ETL designs,Petar Jovanovic; Oscar Romero; Alkis Simitsis; Alberto Abelló,Abstract We present our tool; GEM; for assisting designers in the error-prone and time-consuming tasks carried out at the early stages of a data warehousing project. Our tool semi-automatically produces multidimensional (MD) and ETL conceptual designs from a given setof business requirements (like SLAs) and data source descriptions. Subsequently; our tooltranslates both the MD and ETL conceptual designs produced into physical designs; so theycan be further deployed on a DBMS and an ETL engine. In this paper; we describe thesystem architecture and present our demonstration proposal by means of an example.,International Conference on Conceptual Modeling,2012,5
Searching semantic data warehouses: Models; issues; architectures,Alfredo Cuzzocrea; Alkis Simitsis,ABSTRACT This paper focuses the attention on the issues of searching Semantic DataWarehouses; by providing an overview on state- of-the-art approaches; along with a critical discussionon open issues and future research directions in the investigated scientific field. 1. INTRODUCTIONThe problem of searching Semantic Data Warehouses lies in the between of two leading andwell-understood research areas; ie Search Computing (also extended by means of semantictechnologies – eg; [1]) and Semantic Data Warehouses (eg; [2]). This problem has been of renewedattention at now; due to the important applications that found on a typical Semantics Data Warehouse(SDW) architecture. Among these; relevant ones convey in the large family represented by theSemantic Web applications such as Ontology-based Web Information Systems (eg; [3]);RDF-based Complex Systems (eg; [4]); Analytical Tools over Large Resource-based …,Proceedings of the 2nd International Workshop on Semantic Search over the Web,2012,5
Revisiting ETL benchmarking: The case for hybrid flows,Alkis Simitsis; Kevin Wilkinson,Abstract Modern business intelligence systems integrate a variety of data sources usingmultiple data execution engines. A common example is the use of Hadoop to analyzeunstructured text and merging the results with relational database queries over a datawarehouse. These analytic data flows are generalizations of ETL flows. We refer to multi-engine data flows as hybrid flows. In this paper; we present our benchmark infrastructure forhybrid flows and illustrate its use with an example hybrid flow. We then present a collectionof parameters to describe hybrid flows. Such parameters are needed to define and run ahybrid flows benchmark. An inherent difficulty in benchmarking ETL flows is the diversity ofoperators offered by ETL engines. However; a commonality for all engines is extract andload operations; operations which rely on data and function shipping. We propose that by …,Technology Conference on Performance Evaluation and Benchmarking,2012,5
Optimization of analytic data flows for next generation business intelligence applications,Umeshwar Dayal; Kevin Wilkinson; Alkis Simitsis; Malu Castellanos; Lupita Paz,Abstract This paper addresses the challenge of optimizing analytic data flows for modernbusiness intelligence (BI) applications. We first describe the changing nature of BI in today'senterprises as it has evolved from batch-based processes; in which the back-end extraction-transform-load (ETL) stage was separate from the front-end query and analytics stages; tonear real-time data flows that fuse the back-end and front-end stages. We describe industrytrends that force new BI architectures; eg; mobile and cloud computing; semi-structuredcontent; event and content streams as well as different execution engine architectures. Forexecution engines; the consequence of “one size does not fit all” is that BI queries andanalytic applications now require complicated information flows as data is moved amongdata engines and queries span systems. In addition; new quality of service objectives are …,Technology Conference on Performance Evaluation and Benchmarking,2011,5
Macro-level Scheduling of ETL Workflows,Anastasios Karagiannis; Panos Vassiliadis; Alkis Simitsis,ABSTRACT Extract-Transform-Load (ETL) workflows (a) extract data from varioussources;(b) transform; cleanse and homogenize these data; and (c) populate a target datastore (eg; a data warehouse). Typically; such processes should terminate during strict timewindows and thus; ETL workflow optimization is of significant interest. In this paper; we dealwith the problem of scheduling the execution of ETL activities; with the goal of minimizingETL execution time and allocated memory. Apart from a simple; fair scheduling policy wealso experiment with two policies; the first aiming to empty the largest input queue of theworkflow and the second to activate the activity with the maximum tuple consumption rate.We experimentally show that the use of different scheduling policies can improve ETLperformance in terms of memory consumption and execution time.,Submitted for publication,2009,5
Extraction-Transformation-Loading Processes.,Alkis Simitsis; Panos Vassiliadis; Timos K Sellis,A data warehouse (DW) is a collection of technologies aimed at enabling the knowledgeworker (executive; manager; analyst; etc.) to make better and faster decisions. Thearchitecture of a DW exhibits various layers of data in which data from one layer are derivedfrom data of the lower layer (see Figure 1). The operational databases; also called datasources; form the starting layer. They may consist of structured data stored in open databaseand legacy systems; or even in files. The central layer of the architecture is the global DW.The global DW keeps a historical record of data that result from the transformation;integration; and aggregation of detailed data found in the data sources. An auxiliary area ofvolatile data; data staging area (DSA) is employed for the purpose of data transformation;reconciliation; and cleaning. The next layer of data involves client warehouses; which …,*,2005,5
Pattern-based query answering,Alkis Simitsis; Georgia Koutrika,Abstract Users without knowledge of schemas or structured query languages havedifficulties in accessing information stored in databases. Commercial and research effortshave focused on keyword-based searches. Among them; précis queries generate entiremulti-relation databases; which are logical subsets of existing ones; instead of individualrelations. A logical database subset contains not only items directly related to the queryselections but also items implicitly related to them in various ways. Existing approaches toprécis query answering assume that a database is pre-annotated with a set of weights; andwhen a query is issued; an ad-hoc logical subset is constructed on the fly. This approachhas several limitations; such as dependence on users for providing appropriate weights andconstraints for answering précis queries; and difficulty to capture different query …,International Conference on Extending Database Technology,2006,4
Workflow based security incident management,Meletis A Belsis; Alkis Simitsis; Stefanos Gritzalis,Abstract Security incident management is one of the critical areas that offers valuableinformation to security experts; but still lacks much development. Currently; several securityincident database models have been proposed and used. The discrepancies of suchdatabases entail that worldwide incident information is stored in different formats and placesand; so; do not provide any means for Computer Security Incident Response Teams(CSIRTs) collaboration. This paper presents an architecture based on advance databasetechniques; able to collect incident related information from different sources. Our frameworkenhances the incident management process by allowing the law enforcement units to (a)collect the required evidence from incident data that are spread through a number ofdifferent incident management systems;(b) transform; clean; and homogenize them; and …,Panhellenic Conference on Informatics,2005,4
Babbleflow: a translator for analytic data flow programs,Petar Jovanovic; Alkis Simitsis; Kevin Wilkinson,Abstract A complex analytic data flow may perform multiple; inter-dependent tasks whereeach task uses a different processing engine. Such a multi-engine flow; termed a hybridflow; may comprise subflows written in more than one programming language. However; asthe number and variety of these engines grow; developing and maintaining hybrid flows atthe physical level becomes increasingly challenging. To address this problem; we presentBabbleFlow; a system for enabling flow design at a logical level and automatic translation tophysical flows. BabbleFlow translates a hybrid flow expressed in a number of languages to asemantically equivalent hybrid flow expressed in the same or a different set of languages. Tothis end; it composes the multiple physical flows of a hybrid flow into a single logicalrepresentation expressed in a unified flow language called xLM. In doing so; it enables a …,Proceedings of the 2014 ACM SIGMOD International Conference on Management of Data,2014,3
Hybrid analytic flows-the case for optimization,Alkis Simitsis; Kevin Wilkinson; Umeshwar Dayal,Abstract To remain competitive; enterprises are evolving in order to quickly respond tochanging market conditions and customer needs. In this new environment; a singlecentralized data warehouse is no longer sufficient. Next generation business intelligenceinvolves data flows that span multiple; diverse processing engines; that contain complexfunctionality like data/text analytics; machine learning operations; and that need to beoptimized against various objectives. A common example is the use of Hadoop to analyzeunstructured text and merging these results with relational database queries over the datawarehouse. We refer to these multi-engine analytic data flows as hybrid flows. Currently; it isa cumbersome task to create and run hybrid flows. Custom scripts must be written todispatch tasks to the individual processing engines and to exchange intermediate results …,Fundamenta Informaticae,2013,3
Cloudalloc: A monitoring and reservation system for compute clusters,Enrico Iori; Alkis Simitsis; Themis Palpanas; Kevin Wilkinson; Stavros Harizopoulos,Abstract Cloud computing has emerged as a promising environment capable of providingflexibility; scalability; elasticity; fail-over mechanisms; high availability; and other importantfeatures to applications. Compute clusters are relatively easy to create and use; but tools toeffectively share cluster resources are lacking. CloudAlloc addresses this problem andschedules workloads to cluster resources using allocation algorithms that can be easilychanged according to the objectives of the enterprise. It also monitors resource utilizationand thus; provides accountability for actual usage. CloudAlloc is a lightweight; flexible; easy-to-use tool for cluster resource allocation that has also proved useful as a research platform.We demonstrate its features and also discuss its allocation algorithms that minimize powerusage. CloudAlloc was implemented and is in use at HP Labs.,Proceedings of the 2012 ACM SIGMOD International Conference on Management of Data,2012,3
Data provenance in ETL scenarios,TK Sellis; Dimitrios Skoutas; Alkis Simitsis; Panos Vassiliadis,Data in large organizations are typically distributed in several heterogeneous sources;organized and stored under different naming conventions; structures; and formats. Forsupporting the functionality of On-Line Analytical Processing (OLAP) applications andDecision Support Systems (DSS); Data Warehouses (DW) are employed to integrate thedata and provide a uniform infrastructure for querying; reporting; mining; and otheradvanced analysis techniques. The process of populating the DW with data stemming fromthe operational sources; in a way that the schema and business requirements of the DW aremet; is referred to as Extract-Transform-Load (ETL) process. Typically; such processes arehandled by ETL tools; which are pieces of software responsible for the extraction of datafrom several sources; their cleansing; customization; and insertion into a DW. However …,Proceedings of the 1st Workshop on Principles of Provenance,2007,3
An enhanced search interface for information discovery from digital libraries,Georgia Koutrika; Alkis Simitsis,Abstract Libraries; museums; and other organizations make their electronic contentsavailable to a growing number of users on the Web. A large fraction of the informationpublished is stored in structured or semi-structured form. However; most users have nospecific knowledge of schemas or structured query languages for accessing informationstored in (relational or XML) databases. Under these circumstances; the need for facilitatingaccess to information stored in databases becomes increasingly more important. Précisqueries are free-form queries that instead of simply locating and connecting values in tables;they also consider information around these values that may be related to them. Therefore;the answer to a précis query might also contain information found in other parts of thedatabase. In this paper; we describe a précis query answering prototype system that …,International Conference on Theory and Practice of Digital Libraries,2006,3
Materialized view selection for data warehouse design,Dimitri Theodoratos; Alkis Simitsis,Abstract A data warehouse (DW) is a repository of information retrieved from multiple;possibly heterogeneous; autonomous; distributed databases and other information sourcesfor the purpose of complex querying; analysis; and decision support. Data in the DW areselectively collected from the sources; processed in order to resolve inconsistencies; andintegrated in advance (at design time) before data loading. DW data are usually organizedmulti-dimensionally to support online analytical processing (OLAP). A DW can be seenabstractly as a set of materialized views defined over the source relations. During the initialdesign of a DW; the DW designer faces the problem of deciding which views to materializein the DW. This problem has been addressed in the literature for different classes of queriesand views; and with different design goals.,*,2005,3
The many faces of data-centric workflow optimization: a survey,Georgia Kougka; Anastasios Gounaris; Alkis Simitsis,Abstract: Workflow technology is rapidly evolving and; rather than being limited to modelingthe control flow in business processes; is becoming a key mechanism to perform advanceddata management; such as big data analytics. This survey focuses on data-centric workflows(or workflows for data analytics or data flows); where a key aspect is data passing throughand getting manipulated by a sequence of steps. The large volume and variety of data; thecomplexity of operations performed; and the long time such workflows take to compute giverise to the need for optimization. In general; data-centric workflow optimization is atechnology in evolution. This survey focuses on techniques applicable to workflowscomprising arbitrary types of data manipulation steps and semantic inter-dependenciesbetween such steps. Further; it serves a twofold purpose. Firstly; to present the main …,arXiv preprint arXiv:1701.07723,2017,2
Conversational Databases: Explaining Structured Queries to Users,Georgia Koutrika; Alkis Simitsis; Yannis Ioannidis,Many applications offer a form-based environment for na\"{\i} ve users for accessingdatabases without being familiar with the database schema or a structured query language.Do-It-Yourself; database-driven web application platforms empower non-programmers torapidly create applications. Users interactions are translated to structured queries andexecuted. However; as a user is unlikely to know the underlying semantic connectionsamong the fields presented in a form; it is often useful to provide her with some feedbackabout the queries built without exposing her to the underlying query language; in order toassist her in forming queries correctly. Explaining queries may be also useful for users whoexplicitly use a structured query language for verification or debugging purposes. In thispaper; we take a graph-based approach to the query translation problem. We represent …,*,2009,2
DBMSs should talk back too,Yannis Ioannidis; Alkis Simitsis,ABSTRACT Natural language user interfaces to database systems have been studied forseveral decades now. They have mainly focused on parsing and interpreting naturallanguage queries to generate them in a formal database language. We envision the reversefunctionality; where the system would be able to take the internal result of that translation;say in SQL form; translate it back into natural language; and show it to the initiator of thequery for verification. Likewise; information extraction has received considerable attention inthe past ten years or so; identifying structured information in free text so that it may then bestored appropriately and queried. Validation of the records stored with a backwardtranslation into text would again be very powerful. Verification and validation of query anddata input of a database system correspond to just one example of the many important …,*,2009,2
A hybrid solution for mixed workloads on dynamic graphs.,Mahashweta Das; Alkis Simitsis; Kevin Wilkinson,ABSTRACT The scale and significance of graph structured data today has led to thedevelopment of graph management systems that are optimized either for graph navigationrequests or graph analytic requests. We present a general purpose graph system thatprovides high performance concurrently for both navigation and analytic requests. Inaddition; it supports highly dynamic graphs wherein vertices and edges are added ordeleted and properties are modified. Our solution employs a hybrid architecture comprisingtwo graph engines; one for each workload; with a synchronization unit to manage updatesand a federation layer to present the hybrid system as a single API to graph applications. Wedevelop a proof-of-concept; describe its implementation in details; and present experimentalresults that demonstrate its potential.,GRADES,2016,1
The Farm: where pig scripts are bred and raised,Craig P Sayers; Alkis Simitsis; Georgia Koutrika; Alejandro Guerrero Gonzalez; David Tamez Cantu; Meichun Hsu,Abstract Even though scripting languages like Pig allow for simpler coding; performinganalytics over Big Data using Map-Reduce engines remains challenging. To further assistdevelopers; and support novice users; we offer" The Farm"; a catalog of scriptable servicessupporting creation; discovery; composition; and optimized execution. Each Pig script addedto The Farm becomes an executable service; with inputs and outputs defined by relationschemas. Those services are discoverable using natural language search; and composableusing a drag-and-drop interface. To support efficient execution; composed services areautomatically merged to a single executable script; which can then be run by a growingselection of platform-specific optimizers and interpreters.,Proceedings of the 2013 ACM SIGMOD International Conference on Management of Data,2013,1
Mirror mirror on the wall; which query's fairest of them all?,Georgia Koutrika; Alkis Simitsis,ABSTRACT Scientists heavily use database technologies to store and analyze massiveamounts of experimental data. However these tasks require (sometimes; advanced)knowledge of a query language; which is not necessarily amongst the normal skills of ascientist. Database experts may help in the initial construction of such queries; which arethen stored in a repository. Afterwards; instead of writing queries from scratch; stored queriescan be re-used with few or no changes by people in the same or a different research group.However; as much as this is a desired reality; we are actually stepping into dreamland.Searching a pool of database queries for those that fit in a certain analysis is not easy evenfor experienced database users. One solution could be to provide a description for eachquery and then; use a keyword search technique to identify queries of interest. But doing …,CIDR,2013,1
Towards a Benchmark for ETL Workflows,Panos Vassiliadis Anastasios Karagiannis Vasiliki Tziovara; Alkis Simitsis,ABSTRACT Extraction–Transform–Load (ETL) processes comprise complex data workflows;which are responsible for the maintenance of a Data Warehouse. Their practical importanceis denoted by the fact that a plethora of ETL tools currently constitutes a multi-million dollarsmarket. However; each one of them follows a different design and modeling technique andinternal language. So far; the research community has not agreed upon the basiccharacteristics of ETL tools. Hence; there is a necessity for a unified way to assess ETLworkflows. In this paper; we investigate the main characteristics and peculiarities of ETLprocesses and we propose a principled organization of test suites for the problem ofexperimenting with ETL scenarios.,*,2007,1
Propagation of Evolution Events in Architecture Graphs,George Papastefanatos; Panos Vassiliadis; Alkis Simitsis,Abstract. The success and wellbeing of large organizations rely on the smooth functionalityand operability of their software. Such qualities are largely affected by evolution events andchanges. In this paper; we are dealing with handling evolution events in data managementsystems. In particular; we consider a data-centric ecosystem that captures relational tables;along with their schemata and constraints; as well as; views defined on top of them andqueries (being parts of software modules that are either internal to the database; eg; storedprocedures; or external software applications that access the database). We also considerpolicies that dictate the response of a software module to a possible event. We investigatethe impact of such events to the database and present a graph-based mechanism to controlpropagation of events. We formally show that this mechanism terminates and that every …,long version of this paper); url: web. imis. athena-innovation. gr/~ gpapas/Publications/TR2010,*,1
Citation explanations,*,Examples relate to citation explanations. A process to provide citation explanation isprovided herein. The process analyzes a primary document to extract a citation claim. Theprocess generates a set of candidate segments of a cited document that may correspond tothe citation claim. The process also analyzes the set of candidate segments.,*,2017,*
GnosisMiner: Reading Order Recommendations over Document Collections.,Georgia Koutrika; Alkis Simitsis; Yannis E Ioannidis,ABSTRACT Given a document collection; existing systems allow users to locate documentseither using search keywords or by navigating through some predefined organization of thecollection. Other approaches help the user understand a collection by generatingsummaries or clusters of the documents at hand. However; often users would like tounderstand how the documents may be related to each other and access them in somelogical order. In this work; we present an interactive reading recommendation system; calledGnosisMiner. Given a collection of documents and a theme; the system returns a partialorder of documents relevant to that theme organized from more general to more specific.The recommended reading order resembles the human approach of learning as we typicallystart our path to knowledge from more general documents that help us understand the …,EDBT,2017,*
Big Data Management: New Frontiers; New Paradigms,Alfredo Cuzzocrea; Alkis Simitsis; Il-Yeol Song,This special issue on “Big Data Management: New Frontiers; New Paradigms” of InformationSystems presents a rigorous selection of the best papers of the 17th ACM InternationalWorkshop on Data Warehousing and OLAP (DOLAP 2014); held in conjunction with the23rd ACM International Conference on Conference on Information and KnowledgeManagement (CIKM 2014); in Shanghai; China; during November 3–7; 2014.,Information Systems,2017,*
ACM SIGMOD Record Volume 45 Issue 3,Yanlei Diao; Vanessa Braganholo; Marco Brambilla; Chee Yong Chan; Rada Chirkova; Zackary Ives; Anastasios Kementsietsidis; Jeffrey Naughton; Frank Neven; Olga Papaemmanoui; Aditya Parameswaran; Anish Das Sarma; Alkis Simitsis; Wang-Chiew Tan; Nesime Tatbul; Marianne Winslett; Jun Yang,Google; Inc. (search). SIGN IN SIGN UP. ACM SIGMOD Record. Volume 45 Issue 3; September2016 table of contents. Editors: Yanlei Diao; University of Massachusetts Amherst. VanessaBraganholo; Universidade Federal Fluminense. Marco Brambilla; Politecnico di Milano.,*,2016,*
Multi-core column-store parallelization under concurrent workload,Mrunal Gawade; Martin Kersten; Alkis Simitsis,Abstract Columnar database systems; designed for an optimal OLAP workload performance;strive for maximum multi-core utilization under concurrent query executions. However; multi-core parallel plan generated for isolated execution leads to suboptimal performance duringconcurrent query execution. In this paper; we analyze the concurrent workload resourcecontention effects on multi-core plans using three intra-query parallelization techniques;static; adaptive; and cost model parallelization. We focus on a plan level comparison ofselected TPC-H queries; using in-memory multi-core columnar systems. Excessive partitionsin statically parallelized plans result into heavy L3 cache misses leading to memorycontention; degrading query performance severely. Overall; adaptive plans show morerobustness; less scheduling overheads; and an average 50% execution time …,Proceedings of the 12th International Workshop on Data Management on New Hardware,2016,*
Cloud Application Services Platform (CLASP): User Guide; Introduction; and Operation,Craig Sayers; Hernan Laffitte; Prakash Reddy; Kivanc Ozonat; Mehmet Sayal; Alkis Simitsis; Sharad Singhal; Georgia Koutrika; Mahashweta Das; Ablimit Aji; Hitesh Amrutlal Bosamiya; Marcelo Riss; Kevin Wilkinson; Lucio Clemilson de O,Summary Software developers at large tech companies spend a lot of time writing code fortasks that colleagues elsewhere in the organization have already addressed. Scripts arerarely written or documented with discovery in mind; and the APIs on which they depend arefrequently inconsistent; further limiting reuse. For mobile devices the App Catalog serves asan essential intermediary; streamlining the process both for developers and end users.We've created an experimental platform called CLASP (Cloud Application Services Platform)applying that model by publishing services and datasets instead of apps. It includes supportfor existing APIs; and we've also created an SDK (software development kit); so our userscan write other operations themselves and easily publish in the catalog for later discoveryand reuse.,*,2015,*
ACM SIGMOD Record Volume 43 Issue 1,Ioana Manolescu; Denilson Barbosa; Pablo Barceló; Vanessa Braganholo; Marco Brambilla; Chee Yong Chan; Rada Chirkova; Anish Das Sarma; Glenn Paulley; Alkis Simitsis; Nesime Tatbul; Marianne Winslett,Google; Inc. (search). SIGN IN SIGN UP. ACM SIGMOD Record. Volume 43 Issue 1; March 2014table of contents. Editors: Ioana Manolescu; INRIA Saclay. Denilson Barbosa; University of Alberta.Pablo Barceló; Universidad de Chile. Vanessa Braganholo; Universidade Federal Fluminense.,*,2014,*
DOLAP 2014 Chairs’ Welcome,I-Y Song; A Simitsis; Alfredo Cuzzocrea,Segnalazioni con codici 20501/20503/20504: Alcuni dati obbligatori per il sito CINECA nonsono presenti o invalidi; oppure il sito CINECA non è riuscito ad individuare una rivista con idati forniti; è necessario controllare la correttezza dell'ISSN e/o EISSN dove applicabili e iltitolo della rivista.Segnalazioni con codici 20201/20202: La pubblicazione non è statatrasferita SOLO per i docenti segnalati nel messaggio a causa di problemi nell'anagraficaCINECA e/o di Ateneo (pe i codici fiscali non sono gli stessi) oppure perché si tratta didocenti che; pur essendo abilitati all'inserimento nel sistema di Ateneo; non hanno facoltà disincronizzare le proprie pubblicazioni in CINECA. Tutti gli altri eventuali coautori senzasegnalazione troveranno la pubblicazione correttamente nel proprio spazio personaleCINECA.,*,2014,*
Proceedings of the 17th International Workshop on Data Warehousing and OLAP; DOLAP 2014; Shanghai; China; November 3-7; 2014,Il-Yeol Song; Alkis Simitsis; Alfredo Cuzzocrea,Segnalazioni con codici 20501/20503/20504: Alcuni dati obbligatori per il sito CINECA nonsono presenti o invalidi; oppure il sito CINECA non è riuscito ad individuare una rivista con idati forniti; è necessario controllare la correttezza dell'ISSN e/o EISSN dove applicabili e iltitolo della rivista.Segnalazioni con codici 20201/20202: La pubblicazione non è statatrasferita SOLO per i docenti segnalati nel messaggio a causa di problemi nell'anagraficaCINECA e/o di Ateneo (pe i codici fiscali non sono gli stessi) oppure perché si tratta didocenti che; pur essendo abilitati all'inserimento nel sistema di Ateneo; non hanno facoltà disincronizzare le proprie pubblicazioni in CINECA. Tutti gli altri eventuali coautori senzasegnalazione troveranno la pubblicazione correttamente nel proprio spazio personaleCINECA.,*,2014,*
Optimizing flows for real time operations management,Alkis Simitsis; Chetan Gupta; Kevin Wilkinson; Umeshwar Dayal,Abstract Modern data analytic flows involve complex data computations that may spanmultiple execution engines and need to be optimized for a variety of objectives likeperformance; fault-tolerance; freshness; and so on. In this paper; we present optimizationtechniques and tradeoffs in terms of a real-world; cyber-physical flow that starts with raw timeseries sensor data and external event data; and through a series of analytic operationsproduces automated actions and actionable insights.,International Conference on Scientific and Statistical Database Management,2012,*
λόγος: A System for Translating Queries into Narratives,Andreas Kokkalis; Panagiotis Vagenas; Alexandros Zervakis; Alkis Simitsis; Georgia Koutrika; Yannis Ioannidis,ABSTRACT This paper presents Logos; a system that provides natural languagetranslations for relational queries expressed in SQL. Our translation mechanism is based ona graph-based approach to the query translation problem. We represent various forms ofstructured queries as directed graphs and we annotate the graph edges with template labelsusing an extensible template mechanism. Logos uses different graph traversal strategies forefficiently exploring these graphs and composing textual query descriptions. The audiencemay interactively explore Logos using various database schemata and issuing eithersample or ad hoc queries.,*,2012,*
Preface to the industrial track,Alkis Simitsis; Hans Van Mingroot,Abstract The aim of the ER'11 Industrial Track was to serve as a forum for high qualitypresentations on innovative commercial software; systems; and services for all facets ofconceptual modeling methodologies and technologies as described in the list of topics of theER 2011 conference. We strongly believe that bringing together researchers andpractitioners is important for the progress and success of research on conceptual modeling.We do hope that this track will become stronger year by year and will serve as an excellentopportunity to discuss current practices and modern and future market trends and needs.,International Conference on Conceptual Modeling,2011,*
Advances in Conceptual Modeling. Recent Developments and New Directions: ER 2011 Workshops FP-UML; MoRE-BI; Onto-CoM; SeCoGIS; Variability@ ER; WIS...,Olga De Troyer; Claudia Bauzer Medeiros; Roland Billen; Pierre Hallot; Alkis Simitsis; Hans Van Mingroot,This book constitutes the refereed proceedings of workshops; held at the 30th InternationalConference on Conceptual Modeling; ER 2011; in Brussels; Belgium in October/November2011. The 31 revised full papers presented together with 9 posters and demonstrations (outof 88 submissions) for the workshops and the 6 papers (out of 11 submissions) for theindustrial track were carefully reviewed and selected. The papers are organized in sectionson the workshops Web Information Systems Modeling (WISM); Modeling and Reasoning forBusiness Intelligence (MORE-BI); Software Variability Management (Variability@ ER);Ontologies and Conceptual Modeling (Onto. Com); Semantic and Conceptual Issues in GIS(SeCoGIS); and Foundations and Practices of UML (FP-UML).,*,2011,*
Automating the multidimensional design of data warehouses,D Calvanese; A Olive; O Romero; A Simitsis; E Teniente; J Trujillo; T Urpi,*,*,2010,*
Policy regulated management of ETL evolution,P Vassiliadis; G Papastefanatos; A Simitsis; Y Vassiliou,In this paper; the authors discuss the problem of performing impact prediction for changesthat occur in the schema/structure of the data warehouse sources. They abstract Extract-Transform-Load (ETL) activities as queries and sequences of views. ETL activities and itssources are uniformly modeled as a graph that is annotated with policies for themanagement of evolution events. Given a change at an element of the graph; their methoddetects the parts of the graph that are affected by this change and highlights the way theyare tuned to respond to it. For many cases of ETL source evolution; they present rules so thatboth syntactical and semantic correctness of activities are retained.,*,2009,*
Meshing Streaming Updates with Persistent Data in an Active Data Warehouse,Alkis Simitsis; Nils-Erik Frantzell,Abstract—Active Data Warehousing has emerged as an alternative to conventionalwarehousing practices in order to meet the high demand of applications for up-to-dateinformation. In a nutshell; an active warehouse is refreshed online and thus achieves ahigher consistency between the stored information and the latest data updates. The need foronline warehouse refreshment introduces several challenges in the implementation of datawarehouse transformations; with respect to their execution time and their overhead to thewarehouse processes. In this paper; we focus on a frequently encountered operation in thiscontext; namely; the join of a fast stream S of source updates with a disk-based relation R;under the constraint of limited memory. This operation lies at the core of several commontransformations such as surrogate key assignment; duplicate detection; or identification of …,IEEE TRANSACTIONS ON KNOWLEDGE AND DATA ENGINEERING,2008,*
Discovery and Selection of Services on the Semantic Web,Dimitrios Skoutas; Alkis Simitsis; T Sellis,*,*,2008,*
Wireless Security,Meletis Belsis; Alkis Simitsis; Stefanos Gritzalis,Abstract The fast growth of wireless technology has exponentially increased the abilities andpossibilities of computing equipment. Corporate users can now move around enterprisebuildings with their laptops; PDAs; and WiFi; enable VoIP handsets; and retaincommunications with their offices. Business users can work from almost anywhere byattaching their laptops to WiFi hotspots and connecting to their corporate network. However;not many enterprises know and understand the potential security vulnerabilities that areintroduced by the use of WiFi technologies. Wireless technologies are insecure by theirnature. Anyone with the appropriate hardware can steal information transmitted using theairwaves. This article discusses the security vulnerabilities that are inherited in wirelessnetworks. Also; it provides a description of the current security trends and protocols used …,*,2007,*
Data warehouse refreshment,P Vassiliadis; A Simitsis; S Skiadopoulos; T Sellis,Skip navigation …,*,2006,*
Guest editors’ introduction: Special issue on the CAiSE 2003 conference,Johann Eder; Michele Missikoff,*,*,2005,*
KNOWLEDGE AND DATA ENGINEERING,DA Bell; JW Guan; Y Bi; L Gao; XS Wang; KS Goh; EY Chang; B Li; G Grahne; J Zhu; D Jiang; J Pei; A Zhang; PC Pendharkar; Y Shi; Y Song; A Simitsis; P Vassiliadis; T Sellis; AC Tsoi; S Zhang; M Hagenbuchner; WS Han; KY Whang; YS Moon,REGULAR PAPERS Data Mining On Combining Classifer Mass Functions for Text CategorizationDA Bell; JW Guan; and Y. Bi .......................................................................................................................................... Continuous Similarity-Based Queries on Streaming Time Series L. Gao and XSWang … Call for Papers for Special Issue on Customer RelationshipManagement: Data Mining Meets Marketing......,*,2005,*
A generic and customizable framework for the design of ETL scenarios,Πάνος Βασιλειάδης; Πάνος Γεωργαντάς; Μανώλης Τερροβίτης; Σπύρος Σκιαδόπουλος; Άλκης Σιμήτσης; Panos Vassiliadis; Panos Georgantas; Nikos Skiadopoulos; Alkis Simitsis; Manolis Terrovitis,Extraction–transformation–loading (ETL) tools are pieces of software responsible for theextraction of data from several sources; their cleansing; customization and insertion into adata warehouse. In this paper; we delve into the logical design of ETL scenarios and providea generic and customizable framework in order to support the DW designer in his task. First;we present a metamodel particularly customized for the definition of ETL activities. We followa workflow-like approach; where the output of a certain activity can either be storedpersistently or passed to a subsequent activity. Also; we employ a declarative databaseprogramming language; LDL; to define the semantics of each activity. The metamodel isgeneric enough to capture any possible ETL activity. Nevertheless; in the pursuit of higherreusability and flexibility; we specialize the set of our generic metamodel constructs with a …,*,2005,*
Querying OLAP databases,Alkis Simitsis,*,Data Warehousing and OLAP: Proceedings of the 8 th ACM international workshop on Data warehousing and OLAP,2005,*
Janus: Transactional Processing of Navigational and Analytical Graph Queries on Many-core Servers,Hideaki Kimura; Alkis Simitsis; Kevin Wilkinson,ABSTRACT Existing scale-up graph engines are tuned for either short; navigationalrequests (eg; Nearest-Neighbor) or longer; analytics requests (eg; PageRank). However;they do not have good performance for both workloads running concurrently. We presentJanus; a scale-up graph engine architected for modern; many-core servers with largememory. Janus has excellent scale-up performance on navigational requests; on analyticsrequests; and on a mixed workload running concurrently both navigational and analyticsrequests.,*,*,*
Demo Program Committee,Sihem Amer-Yahia; Arvind Arasu; Sunil Arvindam; Magdalena Balazinska; Fabio Casati; Malu Castellanos; Mariano Cilia; Brian F Cooper; Adina Crainiceanu; Abhinandan Das; Alin Dobra; Pablo Guerrero; Christian Konig; Georgia Koutrika; Wolfgang Lehner; Feifei Li; Ashwin Machanavajjhala; Thomas Neumann; Dan Olteanu; Carlos Ordonez; Peter Pietzuch; Adam Silberstein; Alkis Simitsis,Sihem Amer-Yahia; Qatar Computing Research Institute Arvind Arasu; Microsoft Research SunilArvindam; SAP Research; India Magdalena Balazinska; University of Washington FabioCasati; University of Trento; Italy Malu Castellanos; HP Labs; USA Mariano Cilia; IntelCorporation; Argentina Brian F Cooper; Google Adina Crainiceanu; US Naval Academy AbhinandanDas; Google Alin Dobra; University of Florida Javier Garcia-Garcia; UNAM University; MexicoPablo Guerrero; TU Darmstadt; Germany Melanie Herschel; Tubingen University ChristianKonig; Microsoft Research Georgia Koutrika; IBM Almaden Research Center WolfgangLehner; TU Dresden; Germany Feifei Li; Florida State University Ashwin Machanavajjhala; YahooResearch Thomas Neumann; TU Munchen Dan Olteanu; University of Oxford CarlosOrdonez; University of Houston Peter Pietzuch; Imperial College London Lin Qiao; IBM …,*,*,*
CoAl: Incremental requirement-driven design and deployment of data intensive flows,Petar Jovanovic; Oscar Romero; Alberto Abelló; Alkis Simitsis,Page 1. Fourth European Business Intelligence Summer School (eBISS 2014) – Berlin; GermanyCoAl : Incremental requirement-driven design and deployment of data intensive flows PetarJovanovic; Oscar Romero; Alberto Abelló Universitat Politècnica de Catalunya; BarcelonaTech[petar | oromero | aabello]@essi.upc.edu Alkis Simitsis HP Labs; Palo Alto; CA; USAalkis@hp.com ? Physical-level queries High-level information requirements Import plugins[4;5] ✓ Heterogeneous execution environments ✓ Distributed flow execution ✓ Fragmented dataflows ✓ Engine-specific parameters ✓ Engine availability ✓ Engine applicability ✓ Data vs. functionshipping Further reading: 1. Oscar Romero; Alkis Simitsis; Alberto Abelló: GEM: Requirement-Driven Generation of ETL and Multidimensional Conceptual Designs. DaWaK 2011: 80-95 …,group,*,*
GEM,Petar Jovanovic; Oscar Romero; Alberto Abelló; Alkis Simitsis,Page 1. Third European Business Intelligence Summer School (eBISS 2013) – Dagstuhl; GermanyRequirement-driven Design and Deployment of Multidimensional and ETL Designs PetarJovanovic; Oscar Romero; Alberto Abelló Universitat Politècnica de Catalunya; BarcelonaTechIterative processes to support the evolution of DW designs. ORE: Integrates each new requirementinto the existing DW constructs and produces the unified DW schema that satisfies the entire setof requirements. CoAl: Integrates ETL flows which answer each new requirement; into the existingETL process design and produces the unified ETL process that satisfies the entire set ofrequirements. [petar | oromero | aabello]@essi.upc.edu Domain ontology Data sources AlkisSimitsis HP Labs; Palo Alto; CA; USA alkis@hp.com ? Physical-level queries (Expressed in termsof data sources) High-level information requirements …,*,*,*
Volume 45 Special Issue Section: Data Warehousing and OLAP J. Trujillo and I.-Y. Song New Trends in Data Warehousing and OLAP,P Giorgini; S Rizzi; M Garzetti; A Simitsis; P Vassiliadis; JN Mazón,*,*,*,*
