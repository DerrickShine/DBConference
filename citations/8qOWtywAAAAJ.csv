Nearest neighbor retrieval using distance-based hashing,Vassilis Athitsos; Michalis Potamias; Panagiotis Papapetrou; George Kollios,A method is proposed for indexing spaces with arbitrary distance measures; so as toachieve efficient approximate nearest neighbor retrieval. Hashing methods; such as LocalitySensitive Hashing (LSH); have been successfully applied for similarity indexing in vectorspaces and string spaces under the Hamming distance. The key novelty of the hashingtechnique proposed here is that it can be applied to spaces with arbitrary distancemeasures; including non-metric distance measures. First; we describe a domain-independent method for constructing a family of binary hash functions. Then; we use thesefunctions to construct multiple multibit hash tables. We show that the LSH formalism is notapplicable for analyzing the behavior of these tables as index structures. We present a novelformulation; that uses statistical observations from sample data to analyze retrieval …,Data Engineering; 2008. ICDE 2008. IEEE 24th International Conference on,2008,106
Discovering frequent arrangements of temporal intervals,Panagiotis Papapetrou; George Kollios; Stan Sclaroff; Dimitrios Gunopulos,In this paper we study a new problem in temporal pattern mining: discovering frequentarrangements of temporal intervals. We assume that the database consists of sequences ofevents; where an event occurs during a time-interval. The goal is to mine arrangements ofevent intervals that appear frequently in the database. There are many applications wherethese type of patterns can be useful; including data network; scientific; and financialapplications. Efficient methods to find frequent arrangements of temporal intervals usingboth breadth first and depth first search techniques are described. The performance of theproposed algorithms is evaluated and compared with other approaches on real datasets(American sign language streams and network data) and large synthetic datasets.,Data Mining; Fifth IEEE International Conference on,2005,97
Approximate embedding-based subsequence matching of time series,Vassilis Athitsos; Panagiotis Papapetrou; Michalis Potamias; George Kollios; Dimitrios Gunopulos,Abstract A method for approximate subsequence matching is introduced; that significantlyimproves the efficiency of subsequence matching in large time series data sets under thedynamic time warping (DTW) distance measure. Our method is called EBSM; shorthand forEmbedding-Based Subsequence Matching. The key idea is to convert subsequencematching to vector matching using an embedding. This embedding maps each databasetime series into a sequence of vectors; so that every step of every time series in the databaseis mapped to a vector. The embedding is computed by applying full dynamic time warpingbetween reference objects and each database time series. At runtime; given a query object;an embedding of that object is computed in the same manner; by running dynamic timewarping between the reference objects and the query. Comparing the embedding of the …,Proceedings of the 2008 ACM SIGMOD international conference on Management of data,2008,74
Mining frequent arrangements of temporal intervals,Panagiotis Papapetrou; George Kollios; Stan Sclaroff; Dimitrios Gunopulos,Abstract The problem of discovering frequent arrangements of temporal intervals is studied.It is assumed that the database consists of sequences of events; where an event occursduring a time-interval. The goal is to mine temporal arrangements of event intervals thatappear frequently in the database. The motivation of this work is the observation that inpractice most events are not instantaneous but occur over a period of time and differentevents may occur concurrently. Thus; there are many practical applications that requiremining such temporal correlations between intervals including the linguistic analysis ofannotated data from American Sign Language as well as network and biological data. Threeefficient methods to find frequent arrangements of temporal intervals are described; the firsttwo are tree-based and use breadth and depth first search to mine the set of frequent …,Knowledge and Information Systems,2009,68
Embedding-based subsequence matching in time-series databases,Panagiotis Papapetrou; Vassilis Athitsos; Michalis Potamias; George Kollios; Dimitrios Gunopulos,Abstract We propose an embedding-based framework for subsequence matching in time-series databases that improves the efficiency of processing subsequence matching queriesunder the Dynamic Time Warping (DTW) distance measure. This framework partiallyreduces subsequence matching to vector matching; using an embedding that maps eachquery sequence to a vector and each database time series into a sequence of vectors. Thedatabase embedding is computed offline; as a preprocessing step. At runtime; given a queryobject; an embedding of that object is computed online. Relatively few areas of interest areefficiently identified in the database sequences by comparing the embedding of the querywith the database vectors. Those areas of interest are then fully explored using the exactDTW-based subsequence matching algorithm. We apply the proposed framework to …,ACM Transactions on Database Systems (TODS),2011,63
Significance testing of word frequencies in corpora,Jefrey Lijffijt; Terttu Nevalainen; Tanja Säily; Panagiotis Papapetrou; Kai Puolamäki; Heikki Mannila,Abstract Finding out whether a word occurs significantly more often in one text or corpusthan in another is an important question in analysing corpora. As noted by Kilgarriff(Language is never; ever; ever; random; Corpus Linguistics and Linguistic Theory; 2005; 1(2): 263–76.); the use of the χ 2 and log-likelihood ratio tests is problematic in this context; asthey are based on the assumption that all samples are statistically independent of eachother. However; words within a text are not independent. As pointed out in Kilgarriff(Comparing corpora; International Journal of Corpus Linguistics; 2001; 6 (1): 1–37) andPaquot and Bestgen (Distinctive words in academic writing: a comparison of three statisticaltests for keyword extraction. In Jucker; A.; Schreier; D.; and Hundt; M.(eds); Corpora:Pragmatics and Discourse. Amsterdam: Rodopi; 2009; pp. 247–69); it is possible to …,Literary and Linguistic Computing,2016,32
A statistical significance testing approach to mining the most informative set of patterns,Jefrey Lijffijt; Panagiotis Papapetrou; Kai Puolamäki,Abstract Hypothesis testing using constrained null models can be used to compute thesignificance of data mining results given what is already known about the data. We study thenovel problem of finding the smallest set of patterns that explains most about the data interms of a global p value. The resulting set of patterns; such as frequent patterns orclusterings; is the smallest set that statistically explains the data. We show that the newlyformulated problem is; in its general form; NP-hard and there exists no efficient algorithmwith finite approximation ratio. However; we show that in a special case a solution can becomputed efficiently with a provable approximation ratio. We find that a greedy algorithmgives good results on real data and that; using our approach; we can formulate and solvemany known data-mining tasks. We demonstrate our method on several data mining …,Data Mining and Knowledge Discovery,2014,31
Reference-based alignment in large sequence databases,Panagiotis Papapetrou; Vassilis Athitsos; George Kollios; Dimitrios Gunopulos,Abstract This paper introduces a novel method; called Reference-Based String Alignment(RBSA); that speeds up retrieval of optimal subsequence matches in large databases ofsequences under the edit distance and the Smith-Waterman similarity measure. RBSAoperates using the assumption that the optimal match deviates by a relatively small amountfrom the query; an amount that does not exceed a prespecified fraction of the query length.RBSA has an exact version that guarantees no false dismissals and can handle largequeries efficiently. An approximate version of RBSA is also described; that achievessignificant additional improvements over the exact version; with negligible losses in retrievalaccuracy. RBSA performs filtering of candidate matches using precomputed alignmentscores between the database sequence and a set of fixed-length reference sequences. At …,Proceedings of the VLDB Endowment,2009,26
A survey of query-by-humming similarity methods,Alexios Kotsifakos; Panagiotis Papapetrou; Jaakko Hollmén; Dimitrios Gunopulos; Vassilis Athitsos,Abstract Performing similarity search in large databases is a problem of particular interest inmany communities; such as music; database; and data mining. Although several solutionshave been proposed in the literature that perform well in many application domains; there isno best method to solve this kind of problem in a Query-By-Humming (QBH) application. InQBH the goal is to find the song (s) most similar to a hummed query in an efficient manner. Inthis paper; we focus on providing a brief overview of the representations to encode musicpieces; and also on the methods that have been proposed for QBH or other similarly definedproblems.,Proceedings of the 5th International Conference on PErvasive Technologies Related to Assistive Environments,2012,23
A subsequence matching with gaps-range-tolerances framework: a query-by-humming application,Alexios Kotsifakos; Panagiotis Papapetrou; Jaakko Hollmén; Dimitrios Gunopulos,ABSTRACT We propose a novel subsequence matching framework that allows for gaps inboth the query and target sequences; variable matching tolerance levels efficiently tuned foreach query and target sequence; and also constrains the maximum match length. Using thisframework; a space and time efficient dynamic programming method is developed: given ashort query sequence and a large database; our method identifies the subsequence of thedatabase that best matches the query; and further bounds the number of consecutive gapsin both sequences. In addition; it allows the user to constrain the minimum number ofmatching elements between a query and a database sequence. We show that the proposedmethod is highly applicable to music retrieval. Music pieces are represented by 2-dimensional time series; where each dimension holds information about the pitch and …,Proceedings of the VLDB Endowment,2011,21
Analyzing word frequencies in large text corpora using inter-arrival times and bootstrapping,Jefrey Lijffijt; Panagiotis Papapetrou; Kai Puolamäki; Heikki Mannila,Abstract Comparing frequency counts over texts or corpora is an important task in manyapplications and scientific disciplines. Given a text corpus; we want to test a hypothesis;such as “word X is frequent”;“word X has become more frequent over time”; or “word X ismore frequent in male than in female speech”. For this purpose we need a null model ofword frequencies. The commonly used bag-of-words model; which corresponds to aBernoulli process with fixed parameter; does not account for any structure present in naturallanguages. Using this model for word frequencies results in large numbers of words beingreported as unexpectedly frequent. We address how to take into account the inherentoccurrence patterns of words in significance testing of word frequencies. Based on studies ofwords in two large corpora; we propose two methods for modeling word frequencies that …,Joint European Conference on Machine Learning and Knowledge Discovery in Databases,2011,20
Artemis: Assessing the similarity of event-interval sequences,Orestis Kostakis; Panagiotis Papapetrou; Jaakko Hollmén,Abstract In several application domains; such as sign language; medicine; and sensornetworks; events are not necessarily instantaneous but they can have a time duration.Sequences of interval-based events may contain useful domain knowledge; thus; searching;indexing; and mining such sequences is crucial. We introduce two distance measures forcomparing sequences of interval-based events which can be used for several data miningtasks such as classification and clustering. The first measure maps each sequence ofinterval-based events to a set of vectors that hold information about all concurrent events.These sets are then compared using an existing dynamic programming method. The secondmethod; called Artemis; finds correspondence between intervals by mapping the twosequences into a bipartite graph. Similarity is inferred by employing the Hungarian …,Joint European Conference on Machine Learning and Knowledge Discovery in Databases,2011,18
Distance measure for querying sequences of temporal intervals,Orestis Kostakis; Panagiotis Papapetrou; Jaakko Hollmén,Abstract Time series representations are not always rich enough to describe the temporalactivity; for instance; when the context and the relations of the observed elements are ofinterest. Sequences of temporal intervals use such intervals as primitives in theirrepresentation; and allow focusing on the temporal relations of these elements. This is auseful representation of data across many domains. Searching; indexing; and mining suchsequences is essential for domain experts in order to discover useful information out ofthem. In this paper; we formulate the problem of comparing sequences of temporal intervalsand propose a novel distance measure. We discuss the properties of the measure and studyits robustness in the domain of sign language. Experiments on real data show that themeasure is robust in terms of retrieval accuracy even for high levels of artificially …,Proceedings of the 4th international conference on pervasive technologies related to assistive environments,2011,17
A peek into the black box: exploring classifiers by randomization,Andreas Henelius; Kai Puolamäki; Henrik Boström; Lars Asker; Panagiotis Papapetrou,Abstract Classifiers are often opaque and cannot easily be inspected to gain understandingof which factors are of importance. We propose an efficient iterative algorithm to find theattributes and dependencies used by any classifier when making predictions. Theperformance and utility of the algorithm is demonstrated on two synthetic and 26 real-worlddatasets; using 15 commonly used learning algorithms to generate the classifiers. Theempirical investigation shows that the novel algorithm is indeed able to find groupings ofinteracting attributes exploited by the different classifiers. These groupings allow for findingsimilarities among classifiers for a single dataset as well as for determining the extent towhich different classifiers exploit such interactions in general.,Data mining and knowledge discovery,2014,16
Benchmarking dynamic time warping for music retrieval,Jefrey Lijffijt; Panagiotis Papapetrou; Jaakko Hollmén; Vassilis Athitsos,Abstract We study the performance of three dynamic programming methods on musicretrieval. The methods are designed for time series matching but can be directly applied toretrieval of music. Dynamic Time Warping (DTW) identifies an optimal alignment betweentwo time series; and computes the matching cost corresponding to that alignment. Significantspeed-ups can be achieved by constrained Dynamic Time Warping (cDTW); which narrowsdown the set of positions in one time series that can be matched with specific positions in theother time series. Both methods are designed for full sequence matching but can also beapplied for subsequence matching; by using a sliding window over each databasesequence to compute a matching score for each database subsequence. In addition;SPRING is a dynamic programming approach designed for subsequence matching …,Proceedings of the 3rd international conference on pervasive technologies related to assistive environments,2010,15
IBSM: Interval-based sequence matching,Alexios Kotsifakos; Panagiotis Papapetrou; Vassilis Athitsos,Abstract Sequences of event intervals appear in several application domains including signlanguage; sensor networks; medicine; human motion databases; and linguistics. Suchsequences comprise events that occur at time intervals and are time stamped at their startand end time. In this paper; we propose a new method; called IBSM; for comparing suchsequences. IBSM performs full sequence matching using a vector-based representation ofthe original sequence. At each time point an event vector is computed; hence; the originalsequence is mapped to an ordered set of vectors; which we call event table. Given twosequences; their event tables are resized using bilinear interpolation; which ensures theyare of the same size. The resulting event tables are then compared using the Euclideandistance. In addition; we propose two techniques for reducing the computational cost of …,*,2013,14
Size matters: Finding the most informative set of window lengths,Jefrey Lijffijt; Panagiotis Papapetrou; Kai Puolamäki,Abstract Event sequences often contain continuous variability at different levels. In otherwords; their properties and characteristics change at different rates; concurrently. Forexample; the sales of a product may slowly become more frequent over a period of severalweeks; but there may be interesting variation within a week at the same time. To provide anaccurate and robust “view” of such multi-level structural behavior; one needs to determinethe appropriate levels of granularity for analyzing the underlying sequence. We introducethe novel problem of finding the best set of window lengths for analyzing discrete eventsequences. We define suitable criteria for choosing window lengths and propose an efficientmethod to solve the problem. We give examples of tasks that demonstrate the applicability ofthe problem and present extensive experiments on both synthetic data and real data from …,Joint European Conference on Machine Learning and Knowledge Discovery in Databases,2012,14
Discovering frequent poly-regions in dna sequences,Panagiotis Papapetrou; Gary Benson; George Kollios,The problem of discovering arrangements of regions of high occurrence of one or moreitems of a given alphabet in a sequence is studied; and two efficient algorithms areproposed. The first one is entropy-based and uses an existing recursive segmentationtechnique to split the input sequence into a set of homogeneous segments. The key idea ofthe second approach is to use a set of sliding windows over the sequence. Each slidingwindow keeps a set of statistics of a sequence segment that mainly includes the number ofoccurrences of each item in that segment. Combining these statistics efficiently yields thecomplete set of regions of high occurrence of the items of the given alphabet. Afteridentifying these regions; the sequence is converted to a sequence of labeled intervals(each one corresponding to a region). An efficient algorithm for mining frequent …,Data Mining Workshops; 2006. ICDM Workshops 2006. Sixth IEEE International Conference on,2006,14
Hum-a-song: a subsequence matching with gaps-range-tolerances query-by-humming system,Alexios Kotsifakos; Panagiotis Papapetrou; Jaakko Hollmén; Dimitrios Gunopulos; Vassilis Athitsos; George Kollios,Abstract We present" Hum-a-song"; a system built for music retrieval; and particularly for theQuery-By-Humming (QBH) application. According to QBH; the user is able to hum a part of asong that she recalls and would like to learn what this song is; or find other songs similar to itin a large music repository. We present a simple yet efficient approach that maps theproblem to time series subsequence matching. The query and the database songs arerepresented as 2-dimensional time series conveying information about the pitch and theduration of the notes. Then; since the query is a short sequence and we want to find its bestmatch that may start and end anywhere in the database; subsequence matching methodsare suitable for this task. In this demo; we present a system that employs and exposes to theuser a variety of state-of-the-art dynamic programming methods; including a newly …,Proceedings of the VLDB Endowment,2012,12
A shapley value approach for influence attribution,Panagiotis Papapetrou; Aristides Gionis; Heikki Mannila,Abstract Finding who and what is “important” is an ever-occurring question. Many methodsthat aim at characterizing important items or influential individuals have been developed inareas such as; bibliometrics; social-network analysis; link analysis; and web search. In thispaper we study the problem of attributing influence scores to individuals who accomplishtasks in a collaborative manner. We assume that individuals build small teams; in differentand diverse ways; in order to accomplish atomic tasks. For each task we are given anassessment of success or importance score; and the goal is to attribute those team-wisescores to the individuals. The challenge we face is that individuals in strong coalitions arefavored against individuals in weaker coalitions; so the objective is to find fair attributionsthat account for such biasing. We propose an iterative algorithm for solving this problem …,Joint European Conference on Machine Learning and Knowledge Discovery in Databases,2011,12
Genre classification of symbolic music with SMBGT,Alexios Kotsifakos; Evangelos E Kotsifakos; Panagiotis Papapetrou; Vassilis Athitsos,Abstract Automatic music genre classification is a task that has attracted the interest of themusic community for more than two decades. Music can be of high importance within thearea of assistive technologies as it can be seen as an assistive technology with hightherapeutic and educational functionality for children and adults with disabilities. Severalsimilarity methods and machine learning techniques have been applied in the literature todeal with music genre classification; and as a result data mining and Music InformationRetrieval (MIR) are strongly interconnected. In this paper; we deal with music genreclassification for symbolic music; and specifically MIDI; by combining the recently proposednovel similarity measure for sequences; SMBGT; with the k-Nearest Neighbor (k-NN)classifier. For all MIDI songs we first extract all of their channels and then transform each …,Proceedings of the 6th international conference on PErvasive technologies related to assistive environments,2013,11
Visually controllable data mining methods,Kai Puolamaki; Panagiotis Papapetrou; Jefrey Lijffijt,A large number of data mining methods are; as such; not applicable to fast; intuitive; andinteractive use. Thus; there is a need for visually controllable data mining methods. Suchmethods should comply with three major requirements: their model structure can berepresented visually; they can be controlled using visual; interaction; and they should be fastenough for visual interaction. We; define a framework for using data mining methods in;interactive visualization. These data mining methods are called;``visually controllable''andcombine data mining with visualization; and user-interaction; bridging the gap between datamining and; visual analytics. Our main objective is to define the interactive; visualizationscenario and the requirements for visually; controllable data mining. Basic data miningalgorithms are reviewed; and it is demonstrated how they can be controlled visually. We …,Data Mining Workshops (ICDMW); 2010 IEEE International Conference on,2010,10
Generalized random shapelet forests,Isak Karlsson; Panagiotis Papapetrou; Henrik Boström,Abstract Shapelets are discriminative subsequences of time series; usually embedded inshapelet-based decision trees. The enumeration of time series shapelets is; however;computationally costly; which in addition to the inherent difficulty of the decision tree learningalgorithm to effectively handle high-dimensional data; severely limits the applicability ofshapelet-based decision tree learning from large (multivariate) time series databases. Thispaper introduces a novel tree-based ensemble method for univariate and multivariate timeseries classification using shapelets; called the generalized random shapelet forestalgorithm. The algorithm generates a set of shapelet-based decision trees; where both thechoice of instances used for building a tree and the choice of shapelets are randomized. Forunivariate time series; it is demonstrated through an extensive empirical investigation that …,Data mining and knowledge discovery,2016,9
Finding the longest common sub-pattern in sequences of temporal intervals,Orestis Kostakis; Panagiotis Papapetrou,Abstract We study the problem of finding the longest common sub-pattern (LCSP) shared bytwo sequences of temporal intervals. In particular we are interested in finding the LCSP ofthe corresponding arrangements. Arrangements of temporal intervals are a powerful way toencode multiple concurrent labeled events that have a time duration. Discoveringcommonalities among such arrangements is useful for a wide range of scientific fields andapplications; as it can be seen by the number and diversity of the datasets we use in ourexperiments. In this paper; we define the problem of LCSP and prove that it is NP-completeby demonstrating a connection between graphs and arrangements of temporal intervals.This connection leads to a series of interesting open problems. In addition; we provide anexact algorithm to solve the LCSP problem; and also propose and experiment with three …,Data mining and knowledge discovery,2015,7
Social context discovery from temporal app use patterns,Panagiotis Papapetrou; George Roussos,Abstract A key ingredient of mobile computing is automated adaptation of system behaviourto match user context. In this paper we investigate how temporal patterns of app use canreveal the social context of the user; in the sense of their specific social role during a periodof interaction. Individual users typically have multiple distinct identities associated withdifferent social roles such as professional and family members. We are specificallyinterested in exploring whether we can employ Device Analyzer data to construct distinctprofiles for each of these roles. We introduce a temporal sequence clustering technique thatsuccessfully identifies periods associated with such distinct social contexts.,Proceedings of the 2014 ACM International Joint Conference on Pervasive and Ubiquitous Computing: Adjunct Publication,2014,7
Mining poly-regions in DNA,Panagiotis Papapetrou; Gary Benson; George Kollios,We study the problem of mining poly-regions in DNA. A poly-region is defined as a burstyDNA area; ie; area of elevated frequency of a DNA pattern. We introduce a generalformulation that covers a range of meaningful types of poly-regions and develop threeefficient detection methods. The first applies recursive segmentation and is entropy-based.The second uses a set of sliding windows that summarize each sequence segment usingseveral statistics. Finally; the third employs a technique based on majority vote. Theproposed algorithms are tested on DNA sequences of four different organisms in terms ofrecall and runtime.,International journal of data mining and bioinformatics,2012,7
Forests of randomized shapelet trees,Isak Karlsson; Panagotis Papapetrou; Henrik Boström,Abstract Shapelets have recently been proposed for data series classification; due to theirability to capture phase independent and local information. Decision trees based onshapelets have been shown to provide not only interpretable models; but also; in manycases; state-of-the-art predictive performance. Shapelet discovery is; however;computationally costly; and although several techniques for speeding up this task have beenproposed; the computational cost is still in many cases prohibitive. In this work; an ensemble-based method; referred to as Random Shapelet Forest (RSF); is proposed; which builds onthe success of the random forest algorithm; and which is shown to have a lowercomputational complexity than the original shapelet tree learning algorithm. An extensiveempirical investigation shows that the algorithm provides competitive predictive …,International Symposium on Statistical Learning and Data Sciences,2015,6
Model-based search in large time series databases,Alexios Kotsifakos; Vassilis Athitsos; Panagiotis Papapetrou; Jaakko Hollmén; Dimitrios Gunopulos,Abstract An important theoretical topic in assistive environments is reasoning about temporalpatterns; that represent the sequential output of various sensors; and that can give usinformation about the health and activities of humans and the state of the environment. Therecent growth in the quantity and quality of sensors for assistive environments has made itpossible to create large databases of temporal patterns; that store sequences ofobservations obtained from such sensors over large time intervals. A topic of significantinterest is being able to search such large databases so as to identify content of interest; forexample activities of a certain type; or information about a patient's well-being. In this paper;we study two different approaches for conducting such searches: an exemplar-basedapproach; where we describe what we are looking for by giving an example; and a model …,Proceedings of the 4th International Conference on PErvasive Technologies Related to Assistive Environments,2011,6
Learning from heterogeneous temporal data in electronic health records,Jing Zhao; Panagiotis Papapetrou; Lars Asker; Henrik Boström,Abstract Electronic health records contain large amounts of longitudinal data that arevaluable for biomedical informatics research. The application of machine learning is apromising alternative to manual analysis of such data. However; the complex structure of thedata; which includes clinical events that are unevenly distributed over time; poses achallenge for standard learning algorithms. Some approaches to modeling temporal datarely on extracting single values from time series; however; this leads to the loss of potentiallyvaluable sequential information. How to better account for the temporality of clinical data;hence; remains an important research question. In this study; novel representations oftemporal data in electronic health records are explored. These representations retain thesequential information; and are directly compatible with standard machine learning …,Journal of biomedical informatics,2017,5
Query-sensitive distance measure selection for time series nearest neighbor classification,Alexios Kotsifakos; Vassilis Athitsos; Panagiotis Papapetrou,Abstract Many distance or similarity measures have been proposed for time series similaritysearch. However; none of these measures is guaranteed to be optimal when used for 1-Nearest Neighbor (NN) classification. In this paper we study the problem of selecting themost appropriate distance measure; given a pool of time series distance measures and aquery; so as to perform NN classification of the query. We propose a framework for solvingthis problem; by identifying; given the query; the distance measure most likely to produce thecorrect classification result for that query. From this proposed framework; we derive threespecific methods; that differ from each other in the way they estimate the probability that adistance measure correctly classifies a query object. In our experiments; our pool ofmeasures consists of Dynamic Time Warping (DTW); Move-Split-Merge (MSM); and Edit …,Intelligent Data Analysis,2016,5
Embedding-based subsequence matching with gaps–range–tolerances: a Query-By-Humming application,Alexios Kotsifakos; Isak Karlsson; Panagiotis Papapetrou; Vassilis Athitsos; Dimitrios Gunopulos,Abstract We present a subsequence matching framework that allows for gaps in both queryand target sequences; employs variable matching tolerance efficiently tuned for each queryand target sequence; and constrains the maximum matching range. Using this framework; adynamic programming method is proposed; called SMBGT; that; given a short querysequence Q and a large database; identifies in quadratic time the subsequence of thedatabase that best matches Q. SMBGT is highly applicable to music retrieval. However; inQuery-By-Humming applications; runtime is critical. Hence; we propose a novel embedding-based approach; called ISMBGT; for speeding up search under SMBGT. Using a set ofreference sequences; ISMBGT maps both Q and each position of each database sequenceinto vectors. The database vectors closest to the query vector are identified; and SMBGT …,The VLDB Journal,2015,5
Entropy-based prediction of network protocols in the forensic analysis of dns tunnels,Irvin Homem; Panagiotis Papapetrou; Spyridon Dosis,Abstract: DNS tunneling techniques are often used for malicious purposes but networksecurity mechanisms have struggled to detect these. Network forensic analysis has thusbeen used but has proved slow and effort intensive as Network Forensics Analysis Toolsstruggle to deal with undocumented or new network tunneling techniques. In this paper wepresent a method to aid forensic analysis through automating the inference of protocolstunneled within DNS tunneling techniques. We analyze the internal packet structure of DNStunneling techniques and characterize the information entropy of different network protocolsand their DNS tunneled equivalents. From this; we present our protocol prediction methodthat uses entropy distribution averaging. Finally we apply our method on a dataset tomeasure its performance and show that it has a prediction accuracy of 75%. Our method …,arXiv preprint arXiv:1709.06363,2017,4
Inferring offline hierarchical ties from online social networks,Mohammad Jaber; Peter T Wood; Panagiotis Papapetrou; Sven Helmer,Abstract Social networks can represent many different types of relationships between actors;some explicit and some implicit. For example; email communications between users may berepresented explicitly in a network; while managerial relationships may not. In this paper wefocus on analyzing explicit interactions among actors in order to detect hierarchical socialrelationships that may be implicit. We start by employing three well-known ranking-basedmethods; PageRank; Degree Centrality; and Rooted-PageRank (RPR) to infer such implicitrelationships from interactions between actors. Then we propose two novel approacheswhich take into account the time-dimension of interactions in the process of detectinghierarchical ties. We experiment on two datasets; the Enron email dataset to infer manager-subordinate relationships from email exchanges; and a scientific publication co …,Proceedings of the 23rd International Conference on World Wide Web,2014,4
Extending snBench to Support a Graphical Programming Interface for a Sensor Network Tasking Language (STEP),Ching Chang; Raymond Sweha,The purpose of this project is the creation of a graphical" programming" interface for asensor network tasking language called STEP. The graphical interface allows the user tospecify a program execution graphically from an extensible pallet of functionalities and savethe results as a properly formatted STEP file. Moreover; the software is able to load a file inSTEP format and convert it into the corresponding graphical representation. During bothphases a type-checker is running on the background to ensure that both the graphicalrepresentation and the STEP file are syntactically correct. This project has been motivatedby the Sensorium project at Boston University. In this technical report we present the basicfeatures of the software; the process that has been followed during the design andimplementation. Finally; we describe the approach used to test and validate our software.,*,2006,4
Harnessing predictive models for assisting network forensic investigations of DNS tunnels,Irvin Homem; Panagiotis Papapetrou,ABSTRACT In recent times; DNS tunneling techniques have been used for maliciouspurposes; however network security mechanisms struggle to detect them. Network forensicanalysis has been proven effective; but is slow and effort intensive as Network ForensicsAnalysis Tools struggle to deal with undocumented or new network tunneling techniques. Inthis paper; we present a machine learning approach; based on feature subsets of networktraffic evidence; to aid forensic analysis through automating the inference of protocolscarried within DNS tunneling techniques. We explore four network protocols; namely; HTTP;HTTPS; FTP; and POP3. Three features are extracted from the DNS tunneled traffic: IPpacket length; DNS Query Name Entropy; and DNS Query Name Length. We benchmark theperformance of four classification models; ie; decision trees; support vector machines; k …,ADFSL Conference on Digital Forensics; Security and Law; Daytona Beach,2017,3
DRESS: dimensionality reduction for efficient sequence search,Alexios Kotsifakos; Alexandra Stefan; Vassilis Athitsos; Gautam Das; Panagiotis Papapetrou,Abstract Similarity search in large sequence databases is a problem ubiquitous in a widerange of application domains; including searching biological sequences. In this paper wefocus on protein and DNA data; and we propose a novel approximate method method forspeeding up range queries under the edit distance. Our method works in a filter-and-refinemanner; and its key novelty is a query-sensitive mapping that transforms the original stringspace to a new string space of reduced dimensionality. Specifically; it first identifies the ttmost frequent codewords in the query; and then uses these codewords to convert both thequery and the database to a more compact representation. This is achieved by replacingevery occurrence of each codeword with a new letter and by removing the remaining parts ofthe strings. Using this new representation; our method identifies a set of candidate …,Data mining and knowledge discovery,2015,3
Goldeneye++: A closer look into the black box,Andreas Henelius; Kai Puolamäki; Isak Karlsson; Jing Zhao; Lars Asker; Henrik Boström; Panagiotis Papapetrou,Abstract Models with high predictive performance are often opaque; ie; they do not allow fordirect interpretation; and are hence of limited value when the goal is to understand thereasoning behind predictions. A recently proposed algorithm; GoldenEye; allows detectionof groups of interacting variables exploited by a model. We employed this technique inconjunction with random forests generated from data obtained from electronic patientrecords for the task of detecting adverse drug events (ADEs). We propose a refined versionof the GoldenEye algorithm; called GoldenEye++; utilizing a more sensitive grouping metric.An empirical investigation comparing the two algorithms on 27 datasets related to detectingADEs shows that the new version of the algorithm in several cases finds groups of medicallyrelevant interacting attributes; corresponding to prescribed drugs; undetected by the …,International Symposium on Statistical Learning and Data Sciences,2015,3
Benchmarking dynamic time warping on nearest neighbor classification of electrocardiograms,Nikolaos Tselas; Panagiotis Papapetrou,Abstract The human cardiovascular system is a complicated structure that has been thefocus of research in many different domains; such as medicine; biology; as well as computerscience. Due to the complexity of the heart; even nowadays some of the most commondisorders are still hard to identify. In this paper; we map each ECG to a time series or set oftime series and explore the applicability of two common time series similarity matchingmethods; namely; DTW and cDTW; to the problem of ECG classification. We benchmark thetwo methods on four different datasets in terms of accuracy. In addition; we explore theirpredictive performance when various ECG channels are taken into account. The latter isperformed using a dataset taken from Physiobank. Our findings suggest that different ECGchannels are more appropriate for different cardiovascular malfunctions.,Proceedings of the 7th International Conference on PErvasive Technologies Related to Assistive Environments,2014,3
Tracking your steps on the track: body sensor recordings of a controlled walking experiment,Jefrey Lijffijt; Panagiotis Papapetrou; Jaakko Hollmén,Abstract Monitoring human motion has recently received great attention and can be used inmany applications; such as human motion prediction. We present the collected data set froma body sensor network attached to the human body. The set of sensors consists ofaccelerometers measuring acceleration in three directions that are attached to the upperand lower back as well as the knees and ankles. In addition; pressures on the insoles aremeasured with four pressure sensors inside each shoe. Two types of motion are considered:walking backwards on a straight line and walking forwards on a figure-8 path. Finally; westudy and present basic statistics of the data.,Proceedings of the 3rd International Conference on PErvasive Technologies Related to Assistive Environments,2010,3
Extracting news text from web pages: an application for the visually impaired,Erik Lundgren; Panagiotis Papapetrou; Lars Asker,Abstract Apart from the actual content; web pages contain several other components(referred to as boilerplate text) that describes how; and in what context the content should bedisplayed. We show how content bearing text can be efficiently separated from boilerplatetext using a random forest classifier. We compare the performance with another state-of-the-art method for boilerplate detection that uses a decision tree classifier and shallow featuresextracted from the text. The result is a general improvement using the random forestclassifier for both classifying problems analyzed; significantly so for the more complexproblem. We also show that a small increase in feature set range can lead to even furtherimproved accuracy. The conclusion is that random forest classification can achievesignificantly higher accuracy rates than at least one of the current state-of-the-art methods …,Proceedings of the 8th ACM International Conference on PErvasive Technologies Related to Assistive Environments,2015,2
Multi-channel ecg classification using forests of randomized shapelet trees,Isak Karlsson; Panagiotis Papapetrou; Lars Asker,Abstract Data series of multiple channels occur at high rates and in massive quantities inseveral application domains; such as healthcare. In this paper; we study the problem of multi-channel ECG classification. We map this problem to multivariate data series classificationand propose five methods for solving it; using a split-and-combine approach. The proposedframework is evaluated using three base-classifiers on real-world data for detectingMyocardial Infarction. Extensive experiments are performed on real ECG data extracted fromthe Physiobank data repository. Our findings emphasize the importance of selecting anappropriate base-classifier for multivariate data series classification; while demonstrating thesuperiority of the Random Shapelet Forest (0.825 accuracy) against competitor methods(0.664 accuracy for 1-NN under cDTW).,Proceedings of the 8th ACM International Conference on PErvasive Technologies Related to Assistive Environments,2015,2
Using time-sensitive rooted pagerank to detect hierarchical social relationships,Mohammad Jaber; Panagiotis Papapetrou; Sven Helmer; Peter T Wood,Abstract We study the problem of detecting hierarchical ties in a social network by exploitingthe interaction patterns between the actors (members) involved in the network. Motivated byearlier work using a rank-based approach; ie; Rooted-PageRank; we introduce a novel time-sensitive method; called T-RPR; that captures and exploits the dynamics and evolution ofthe interaction patterns in the network in order to identify the underlying hierarchical ties.Experiments on two real datasets demonstrate the performance of T-RPR in terms of recalland show its superiority over a recent competitor method.,International Symposium on Intelligent Data Analysis,2014,2
Mining candidates for adverse drug interactions in electronic patient records,Lars Asker; Henrik Boström; Isak Karlsson; Panagiotis Papapetrou; Jing Zhao,Abstract Electronic patient records provide a valuable source of information for detectingadverse drug events. In this paper; we explore two different but complementary approachesto extracting useful information from electronic patient records with the goal of identifyingcandidate drugs; or combinations of drugs; to be further investigated for suspected adversedrug events. We propose a novel filter-and-refine approach that combines sequential patternmining and disproportionality analysis. The proposed method is expected to identify groupsof possibly interacting drugs suspected for causing certain adverse drug events. We performan empirical investigation of the proposed method using a subset of the Stockholmelectronic patient record corpus. The data used in this study consists of all diagnoses andmedications for a group of patients diagnoses with at least one heart related diagnosis …,Proceedings of the 7th International Conference on PErvasive Technologies Related to Assistive Environments,2014,2
The smallest set of constraints that explains the data: a randomization approach,Jefrey Lijffijt; Panagiotis Papapetrou; Niko Vuokko; Kai Puolamäki,Randomization methods can be used to assess statistical significance of data mining results.A randomization method typically consists of a sampler which draws data sets from a nulldistribution; and a test statistic. If the value of the test statistic on the original data set is moreextreme than the test statistic on randomized data sets we can reject the null hypothesis. It isoften not immediately clear why the null hypothesis is rejected. For example; the cost ofclustering can be significantly lower in the original data than in the randomized data; butusually we would also like to know why the cost is small. We introduce a methodology forfinding the smallest possible set of constraints; or patterns; that explains the data. In principleany type of patterns can be used as long as there exists an appropriate randomizationmethod. We show that the problem is; in its general form; NP-hard; but that in a special …,*,2010,2
Constraint-based mining of frequent arrangements of temporal intervals,Panagiotis Papapetrou,The problem of discovering frequent arrangements of temporal intervals is studied. It isassumed that the database consists of sequences of events; where an event occurs during atime-interval. The goal is to mine temporal arrangements of event intervals that appearfrequently in the database. The motivation of this work is the observation that in practicemost events are not instantaneous but occur over a period of time and different events mayoccur concurrently. Thus; there are many practical applications that require mining suchtemporal correlations between intervals including the linguistic analysis of annotated datafrom American Sign Language as well as network and biological data. Two efficient methodsto find frequent arrangements of temporal intervals are described; the first one is tree-basedand uses depth first search to mine the set of frequent arrangements; whereas the second …,*,2006,2
Mining disproportional itemsets for characterizing groups of heart failure patients from administrative health records,Isak Karlsson; Panagiotis Papapetrou; Lars Asker; Henrik Boström; Hans E Persson,Abstract Heart failure is a serious medical conditions involving decreased quality of life andan increased risk of premature death. A recent evaluation by the Swedish National Board ofHealth and Welfare shows that Swedish heart failure patients are often undertreated and donot receive basic medication as recommended by the national guidelines for treatment ofheart failure. The objective of this paper is to use registry data to characterize groups of heartfailure patients; with an emphasis on basic treatment. Towards this end; we explore theapplicability of frequent itemset mining and disproportionality analysis for finding interestingand distinctive characterizations of a target group of patients; eg; those who have receivedbasic treatment; against a control group; eg; those who have not received basic treatment.Our empirical evaluation is performed on data extracted from administrative health …,Proceedings of the 10th International Conference on PErvasive Technologies Related to Assistive Environments,2017,1
On searching and indexing sequences of temporal intervals,Orestis Kostakis; Panagotis Papapetrou,Abstract In several application domains; including sign language; sensor networks; andmedicine; events are not necessarily instantaneous but they may have a time duration. Suchevents build sequences of temporal intervals; which may convey useful domain knowledge;thus; searching and indexing these sequences is crucial. We formulate the problem ofcomparing sequences of labeled temporal intervals and present a distance measure thatcan be computed in polynomial time. We prove that the distance measure is metric andsatisfies the triangle inequality. For speeding up search in large databases of sequences oftemporal intervals; we propose an approximate indexing method that is based onembeddings. The proposed indexing framework is shown to be contractive and canguarantee no false dismissal. The distance measure is tested and benchmarked through …,Data mining and knowledge discovery,2017,1
Identifying factors for the effectiveness of treatment of heart failure: a registry study,Lars Asker; Henrik Boström; Panagiotis Papapetrou; Hans Persson,An administrative health register containing health care data for over 2 million patients willbe used to search for factors that can affect the treatment of heart failure. In the study; we willmeasure the effects of employed treatment for various groups of heart failure patients; usingdifferent measures of effectiveness. Significant deviations in effectiveness of treatments ofthe various patient groups will be reported and factors that may help explaining the effect oftreatment will be analyzed. Identification of the most important factors that may help explainthe observed deviations between the different groups will be derived through generation ofpredictive models; for which variable importance can be calculated. The findings may affectrecommended treatments as well as highlighting deviations from national guidelines.,Computer-Based Medical Systems (CBMS); 2016 IEEE 29th International Symposium on,2016,1
Optimizing hashing functions for similarity indexing in arbitrary metric and nonmetric spaces,Pat Jangyodsuk; Panagiotis Papapetrou; Vassilis Athitsos,Abstract A large number of methods have been proposed for similarity indexing in Euclideanspaces; and several such methods can also be used in arbitrary metric spaces. Suchmethods exploit specific properties of Euclidean spaces or general metric spaces. Designinggeneral-purpose similarity indexing methods for arbitrary metric and non-metric distancemeasures is a more difficult problem; due to the vast heterogeneity of such spaces and thelack of common properties that can be exploited. In this paper; we propose a generallyapplicable method for similarity-based indexing in arbitrary metric and nonmetric spaces;based on hashing. We build upon the technique of Distance-Based Hashing (DBH); whichorganizes database objects in multiple hash tables; so that two similar objects tend to fall inthe same bucket in at least one of those hash tables. The main contribution is in showing …,*,2015,1
Analysing Online Education-based Asynchronous Communication Tools to Detect Students' Roles.,Mohammad Jaber; Panagiotis Papapetrou; Ana González-Marcos; Peter T Wood,Abstract: This paper studies the application of Educational Data Mining to examine theonline communication behaviour of students working together on the same project in orderto identify the different roles played by the students. Analysis was carried out using real datafrom students' participation in project communication tools. Several sets of features includingindividual attributes and information about the interactions between the project memberswere used to train different classification algorithms. The results show that considering theindividual attributes of students provided regular classification performance. The inclusion ofinformation about the reply relationships among the project members generally improvedmapping students to their roles. However;“time-based” features were necessary to achievethe best classification results; which showed both precision and recall of over 95% for a …,CSEDU (2),2015,1
Finding representative objects using link analysis ranking,Panagiotis Papapetrou; Tatiana Chistiakova; Jaakko Hollmén; Vana Kalogeraki; Dimitrios Gunopulos,Abstract Link analysis ranking methods are widely used for summarizing the connectivitystructure of large networks. We explore a weighted version of two common link analysisranking algorithms; PageRank and HITS; and study their applicability to assistiveenvironment data. Based on these methods; we propose a novel approach for identifyingrepresentative objects in large datasets; given their similarity matrix. The novelty of ourapproach is that it takes into account both the pair-wise similarities between the objects; aswell as the origin and" evolution path" of these similarities within the dataset. The key step ofour method is to define a complete graph; where each object is represented by a node andeach edge in the graph is given a weight equal to the pairwise similarity value of the twoadjacent nodes. Nodes with high ranking scores correspond to representative objects …,Proceedings of the 5th International Conference on PErvasive Technologies Related to Assistive Environments,2012,1
Benchmarking link analysis ranking methods in assistive environments,Konstantinos Georgatzis; Panagiotis Papapetrou,Abstract Several assistive applications exhibit a network structure. Characterizing thestructure of such networks is critical in many assistive applications. Existing methods in theof social network analysis aim to detect; analyze; and summarize interesting or surprisingcomponents and trends in the network. In this paper; we provide a benchmark of two graphranking methods: pagerank and HITS. The methods are tested on real social network datafrom three different domains: citation graphs; road networks; and a subgraph of Google. Ourfindings suggest that the quality of the ranking as well as the speed of convergence of bothalgorithms highly depends on the underlying network structure.,Proceedings of the 5th International Conference on PErvasive Technologies Related to Assistive Environments,2012,1
Optimization of weighted virtual sinogram-based metal artifact reduction in CT-based attenuation correction of PET data using a genetic algorithm,M Abdoli; MR Ay; A Ahmadian; RAJO Dierckx; H Zaidi,Dental metallic fillings and implants are known to generate streak artifacts in reconstructedCT images and; thus; the corresponding PET data which are corrected for attenuation usingCT based attenuation correction (CTAC) would suffer from over/underestimation of traceruptake. The purpose of this study is to develop an approach for correction of this effect inorder to obtain a reliable attenuation map and perform an accurate CTAC on PET data. Theproposed method corrects the artifacts in the virtual sinogram space by substituting theprojection bins which are affected by metallic objects for weighted values of the influencedbins in the corrected and non-corrected sinograms; as well as weighted values of thesinogram bins in the neighboring column of the sinogram matrix. Optimization of theweighting factors associated with the above mentioned data sets (α; β and γ) was …,Eur J Nucl Med Mol Imaging,2010,1
Embedding-based subsequence matching in large sequence databases,Panagiotis Papapetrou,ABSTRACT Sequential data; such as time series and categorical sequences; naturallyappear in a wide variety of domains including financial and scientific data; human activity;biological sequences; etc. In such domains large databases of sequences are used asknowledge repositories. Information retrieval from such repositories is challenging; due tothe large amount of data that needs to be searched. Our attention is focused onsubsequence matching methods that employ dynamic programmingbased distancemeasures. Such approaches are robust to misalignments and time warps and are widelyused for time series and DNA matching. Three methods are proposed for efficientsubsequence matching in large sequence databases. The first method works for time seriesdatabases and the Dynamic Time Warping (DTW) distance. It converts subsequence …,*,2010,1
ABIDE: Querying Time-Evolving Sequences of Temporal Intervals,Orestis Kostakis; Panagiotis Papapetrou,Abstract We study the problem of online similarity search in sequences of temporal intervals;given a standing query and a time-evolving sequence of event-intervals; we want to assessthe existence of the query in the sequence over time. Since indexing is inapplicable to ourproblem; the goal is to reduce runtime without sacrificing retrieval accuracy. We presentthree lower-bounding and two early-abandon methods for speeding up search; whileguaranteeing no false dismissals. We present a framework for combining lower bounds withearly abandoning; called ABIDE. Empirical evaluation on eight real datasets and twosynthetic datasets suggests that ABIDE provides speedups of at least an order of magnitudeand up to 6977 times on average; compared to existing approaches and a baseline. Weconclude that ABIDE is more powerful than existing methods; while we can attain the …,International Symposium on Intelligent Data Analysis,2017,*
KAPMiner: Mining Ordered Association Rules with Constraints,Isak Karlsson; Panagiotis Papapetrou; Lars Asker,Abstract We study the problem of mining ordered association rules from event sequences.Ordered association rules differ from regular association rules in that the events occurring inthe antecedent (left hand side) of the rule are temporally constrained to occur strictly beforethe events in the consequent (right hand side). We argue that such constraints can providemore meaningful rules in particular application domains; such as health care. Theimportance and interestingness of the extracted rules are quantified by adapting existingrule mining metrics. Our experimental evaluation on real data sets demonstrates thedescriptive power of ordered association rules against ordinary association rules.,International Symposium on Intelligent Data Analysis,2017,*
Detecting Hierarchical Ties Using Link-Analysis Ranking at Different Levels of Time Granularity,Hend Kareem; Lars Asker; Panagiotis Papapetrou,Abstract: Social networks contain implicit knowledge that can be used to infer hierarchicalrelations that are not explicitly present in the available data. Interaction patterns are typicallyaffected by users' social relations. We present an approach to inferring such information thatapplies a link-analysis ranking algorithm at different levels of time granularity. In addition; avoting scheme is employed for obtaining the hierarchical relations. The approach isevaluated on two datasets: the Enron email data set; where the goal is to infer manager-subordinate relationships; and the Co-author data set; where the goal is to infer PhD advisor-advisee relations. The experimental results indicate that the proposed approach outperformsmore traditional approaches to inferring hierarchical relations from social networks.Subjects: Social and Information Networks (cs. SI); Physics and Society (physics. soc-ph) …,arXiv preprint arXiv:1701.06861,2017,*
Discovering; Selecting and Exploiting Feature Sequence Records of Study Participants for the Classification of Epidemiological Data on Hepatic Steatosis,Tommy Hielscher; Myra Spiliopoulou; Henry Völzke; Panagiotis Papapetrou,diva-portal.org. Please wait …,*,2017,*
Conformal prediction using random survival forests,Henrik Boström; Ram Bahadur Gurung; Lars Asker; Isak Karlsson; Tony Lindgren; Panagiotis Papapetrou,diva-portal.org. Please wait …,International Conference on Machine Learning and Applications,2017,*
Learning from Administrative Health Registries,Jonathan Rebane; Isak Karlsson; Lars Asker; Henrik Boström; Panagiotis Papapetrou,Abstract. Over the last decades the healthcare domain has seen a tremendous increase andinterest in methods for making inference about patient care using large quantities of medicaldata. Such data is often stored in electronic health records and administrative healthregistries. As these data sources have grown increasingly complex; with millions of patientsrepresented by thousands of attributes; static or time evolving; finding relevant and accuratepatterns that can be used for predictive or descriptive modelling is impractical for humanexperts. In this paper; we concentrate our review on Swedish Administrative HealthRegistries (AHRs) and Electronic Health Records (EHRs) and provide an overview of recentand ongoing work in the area with focus on adverse drug events (ADEs) and heart failure.,Second Workshop on Data Science for Social Good co-located with European Conference on Machine Learning and Principles and Practice of Knowledge Dicovery in Databases (ECML-PKDD 2017); Skopje; Macedonia; September 18; 2017,2017,*
Clustering with Confidence: Finding Clusters with Statistical Guarantees,Andreas Henelius; Kai Puolamäki; Henrik Boström; Panagiotis Papapetrou,Abstract: Clustering is a widely used unsupervised learning method for finding structure inthe data. However; the resulting clusters are typically presented without any guarantees ontheir robustness; slightly changing the used data sample or re-running a clustering algorithminvolving some stochastic component may lead to completely different clusters. There is;hence; a need for techniques that can quantify the instability of the generated clusters. In thisstudy; we propose a technique for quantifying the instability of a clustering solution and forfinding robust clusters; termed core clusters; which correspond to clusters where the co-occurrence probability of each data item within a cluster is at least $1-\alpha $. Wedemonstrate how solving the core clustering problem is linked to finding the largest maximalcliques in a graph. We show that the method can be used with both clustering and …,arXiv preprint arXiv:1612.08714,2016,*
Early Random Shapelet Forest,Isak Karlsson; Panagiotis Papapetrou; Henrik Boström,Abstract Early classification of time series has emerged as an increasingly important andchallenging problem within signal processing; especially in domains where timely decisionsare critical; such as medical diagnosis in health-care. Shapelets; ie; discriminative sub-sequences; have been proposed for time series classification as a means to capture localand phase independent information. Recently; forests of randomized shapelet trees havebeen shown to produce state-of-the-art predictive performance at a low computational cost.In this work; they are extended to allow for early classification of time series. An extensiveempirical investigation is presented; showing that the proposed algorithm is superior toalternative state-of-the-art approaches; in case predictive performance is considered to bemore important than earliness. The algorithm allows for tuning the trade-off between …,International Conference on Discovery Science,2016,*
STIFE: A Framework for Feature-Based Classification of Sequences of Temporal Intervals,Leon Bornemann; Jason Lecerf; Panagiotis Papapetrou,Abstract In this paper; we study the problem of classification of sequences of temporalintervals. Our main contribution is the STIFE framework for extracting relevant features frominterval sequences to build feature-based classifiers. STIFE uses a combination of basicstatic metrics; shapelet discovery and selection; as well as distance-based approaches.Additionally; we propose an improved way of computing the state of the art IBSM distancemeasure between two interval sequences; that reduces both runtime and memory needsfrom pseudo-polynomial to fully polynomial; which greatly reduces the runtime of distancebased classification approaches. Our empirical evaluation not only shows that STIFEprovides a very fast classification time in all evaluated scenarios but also reveals that arandom forests using STIFE achieves similar or better accuracy than the state of the art k …,International Conference on Discovery Science,2016,*
A multi-granularity pattern-based sequence classification framework for educational data,Mohammad Jaber; Peter T Wood; Panagiotis Papapetrou; Ana González-Marcos,In many application domains; such as education; sequences of events occurring over timeneed to be studied in order to understand the generative process behind these sequences;and hence classify new examples. In this paper; we propose a novel multi-granularitysequence classification framework that generates features based on frequent patterns atmultiple levels of time granularity. Feature selection techniques are applied to identify themost informative features that are then used to construct the classification model. We showthe applicability and suitability of the proposed framework to the area of educational datamining by experimenting on an educational dataset collected from an asynchronouscommunication tool in which students interact to accomplish an underlying group project.The experimental results showed that our model can achieve competitive performance in …,Data Science and Advanced Analytics (DSAA); 2016 IEEE International Conference on,2016,*
Advances in Intelligent Data Analysis Xv: 15th International Symposium; Ida 2016; Stockholm; Sweden; October 13-15; 2016; Proceedings,Henrik Boström; Arno Knobbe; Carlos Soares; Panagiotis Papapetrou,This book constitutes the refereed conference proceedings of the 15th InternationalConference on Intelligent Data Analysis; which was held in October 2016 in Stockholm;Sweden. The 36 revised full papers presented were carefully reviewed and selected from 75submissions. The traditional focus of the IDA symposium series is on end-to-end intelligentsupport for data analysis. The symposium aims to provide a forum for inspiring researchcontributions that might be considered preliminary in other leading conferences andjournals; but that have a potentially dramatic impact.,*,2016,*
Semigeometric Tiling of Event Sequences,Andreas Henelius; Isak Karlsson; Panagiotis Papapetrou; Antti Ukkonen; Kai Puolamäki,Abstract Event sequences are ubiquitous; eg; in finance; medicine; and social media. Oftenthe same underlying phenomenon; such as television advertisements during Superbowl; isreflected in independent event sequences; like different Twitter users. It is hence of interestto find combinations of temporal segments and subsets of sequences where an event ofinterest; like a particular hashtag; has an increased occurrence probability. Such patternsallow exploration of the event sequences in terms of their evolving temporal dynamics; andprovide more fine-grained insights to the data than what for example straightforwardclustering can reveal. We formulate the task of finding such patterns as a novel matrix tilingproblem; and propose two algorithms for solving it. Our first algorithm is a greedy set-coverheuristic; while in the second approach we view the problem as time-series segmentation …,Joint European Conference on Machine Learning and Knowledge Discovery in Databases,2016,*
FindMyDoc: a P2P platform disrupting traditional healthcare models and matching patients to doctors,Myrsini Glinos; Svante Dahlberg; Nikolaos Tselas; Panagiotis Papapetrou,Abstract A variety of eHealth apps exist today ranging from ovulation calculators; such asGlow; to more sophisticated systems for determining the right therapist via semanticanalysis; such as Talkspace; or ZocDoc. Despite their promising functionality; existingsystems offer limited capabilities in terms of search filters; reviews; and doctorrecommendations. In this paper; we propose FindMyDoc; a novel peer-to-peer healthcareplatform that goes beyond existing traditional healthcare models. It provides doctorrecommendations by allowing proper filtering based on treatment procedures; quality oftreatment; and reviews of healthcare providers. In addition; the search results are refinedusing a recommendation engine that employs user-based collaborative filtering and exploitsa set of predefined review options provided by the patients in order to match them with …,Proceedings of the 9th ACM International Conference on PErvasive Technologies Related to Assistive Environments,2016,*
Learning from Swedish Healthcare Data,Lars Asker; Panagiotis Papapetrou; Henrik Boström,Abstract We present two ongoing projects aimed at learning from health care records. Thefirst project; DADEL; is focusing on high-performance data mining for detrecting adversedrug events in healthcare; and uses electronic patient records covering seven years ofpatient record data from the Stockholm region in Sweden. The second project is focusing onheart failure and on understanding the differences in treatment between various groups ofpatients. It uses a Swedish administrative health register containing health care data for overtwo million patients.,Proceedings of the 9th ACM International Conference on PErvasive Technologies Related to Assistive Environments,2016,*
Åldersdiskriminering av unga: Partsautonomi och kollektivavtal i ljuset av EU-rättens utveckling,Paul Eskilsson,Diskrimineringslagstiftningen är ett litet udda inslag i den arbetsrättsliga lagstiftningen.Sedan arbetsmarknaden till stor del avreglerades i mitten av 1800-talet har lagstiftaren varitrestriktiv med nya regleringar på arbetsrättens område. De lagar som tillkom under förstadelen av 1900-talet handlade antingen om grundläggande arbetarskydd eller syftade till attstärka den rådande partsordningen. Efter Saltsjöbadsavtalet 1938 förstärks denna passivaattityd från statsmakterna vilket ändras först på 1970-talet; då lagar som LAS och MBLtillkom. Men även dessa lagar; som kan ses som exempel på en ökad juridifiering avarbetsrätten; har sitt ursprung i kollektivavtalsregleringar eller syftar till att stärka parterna påolika sätt. Lagstiftningen är i hög utsträckning antingen en skyddslagstiftning eller; som ifallet med MBL; en reglering av spelregler. 2 I båda typerna av lagstiftning finns ett stort …,*,2016,*
Size matters: choosig the most iformative set of widow legths for miig patters i evet sequeces,Jefrey Lijffijt; Panagiotis Papapetrou; Kai Puolamäki,Abstract In order to find patterns in data; it is often necessary to aggregate or summarisedata at a higher level of granularity. Selecting the appropriate granularity is a challengingtask and often no principled solutions exist. This problem is particularly relevant in analysisof data with sequential structure. We consider this problem for a specific type of data; namelyevent sequences. We introduce the problem of finding the best set of window lengths foranalysis of event sequences for algorithms with real-valued output. We present suitablecriteria for choosing one or multiple window lengths and show that these naturally translateinto a computational optimisation problem. We show that the problem is NP-hard in general;but that it can be approximated efficiently and even analytically in certain cases. We giveexamples of tasks that demonstrate the applicability of the problem and present extensive …,Data mining and knowledge discovery,2015,*
Learning an Optimized Deep Neural Network for Link Prediction on Knowledge Graphs,WX Wilcke; J Hollmén; P Papapetrou,Recent years have seen the emergence of graph-based Knowl-edge Bases build uponSemantic Web technologies; known as Knowledge Graphs (KG). Popular examples areDBpedia and GeoNames. The formal system underlying these KGs provides inherentsupport for deductive reasoning. Growing popularity has exposed several limitations of thisability; amongst which are scalability and uncertainty issues; as well as coping withheterogeneous; noisy; and inconsistent data. By supplementing this form of reasoning withMachine Learning algorithms; these hurdles are much more easily overcome. Of the existingresearch in this area; only a handful have been considering a Deep Neural Network.Moreover; only one of these studies has addressed the problem of hyper-parameteroptimization; albeit under specific conditions. To contribute to this area of research; we …,*,2015,*
Proceedings of the ECMLPKDD 2015 Doctoral Consortium,Jaakko Hollmén; Panagiotis Papapetrou,ECMLPKDD 2015 Doctoral Consortium was organized for the second time as part of theEuropean Conference on Machine Learning and Principles and Practice of KnowledgeDiscovery in Databases (ECMLPKDD); organised in Porto during September 7-11; 2015.The objective of the doctoral consortium is to provide an environment for students toexchange their ideas and experiences with peers in an interactive atmosphere and to getconstructive feedback from senior researchers in machine learning; data mining; and relatedareas. These proceedings collect together and document all the contributions of theECMLPKDD 2015 Doctoral Consortium.,*,2015,*
Model-Based Time Series Classification,Alexios Kotsifakos; Panagiotis Papapetrou,Abstract We propose MTSC; a filter-and-refine framework for time series Nearest Neighbor(NN) classification. Training time series belonging to certain classes are first modeledthrough Hidden Markov Models (HMMs). Given an unlabeled query; and at the filter step; weidentify the top K models that have most likely produced the query. At the refine step; adistance measure is applied between the query and all training time series of the top Kmodels. The query is then assigned with the class of the NN. In our experiments; we firstevaluated the NN classification error rate of HMMs compared to three state-of-the-artdistance measures on 45 time series datasets of the UCR archive; and showed thatmodeling time series with HMMs achieves lower error rates in 30 datasets and equal errorrates in 4. Secondly; we compared MTSC with Cross Validation defined over the three …,International Symposium on Intelligent Data Analysis,2014,*
Analysis of Cluster Structure in Large-scale English Wikipedia Category Networks,Thidawan Klaysri; Trevor Fenner; Oded Lachish; Mark Levene; Panagiotis Papapetrou,Abstract In this paper we propose a framework for analysing the structure of a large-scalesocial media network; a topic of significant recent interest. Our study is focused on theWikipedia category network; where nodes correspond to Wikipedia categories and edgesconnect two nodes if the nodes share at least one common page within the Wikipedianetwork. Moreover; each edge is given a weight that corresponds to the number of pagesshared between the two categories that it connects. We study the structure of categoryclusters within the three complete English Wikipedia category networks from 2010 to 2012.We observe that category clusters appear in the form of well-connected components that arenaturally clustered together. For each dataset we obtain a graph; which we call the t-filteredcategory graph; by retaining just a single edge linking each pair of categories for which …,International Symposium on Intelligent Data Analysis,2013,*
COMMPER 2012,Jaakko Hollmén; Panagiotis Papapetrou; Luiz Augusto Pizzato,We are proud to present the workshop proceedings of The Second International Workshopon Mining Communities and People Recommenders (COMMPER 2012). The workshop wasorganized in conjunction with The European Conference on Machine Learning and Practiceof Knowledge Discovery in Databases (ECML PKDD) in Bristol; UK on the 28th ofSeptember 2012. This workshop is a sequel to the first COMMPER Workshop; which tookplace in conjunction with the The IEEE International Conference on Data Mining series inVancouver; Canada in December 2011. The call for papers for COMMPER2012 was issuedin the spring and distributed to e-mail lists for wide distribution. All submissions werereviewed by at least two members of the Program Committee. Finally; six contributions wereaccepted for inclusion in the program and the proceedings.,*,2011,*
Are you talking Bernoulli to me? Comparing methods of assessing word frequencies,Panagiotis Papapetrou; Jefrey Lijffijt; Tanja Säily; Kai Puolamäki; Terttu Nevalainen; Heikki Mannila,*,*,2011,*
Towards faster activity search using embedding-based subsequence matching,Panagiotis Papapetrou; Paul Doliotis; Vassilis Athitsos,Abstract Event search is the problem of identifying events or activity of interest in a largedatabase storing long sequences of activity. In this paper; our topic is the problem ofidentifying activities of interest in databases where such activities are represented as timeseries. In the typical setup; the user presents a query that represents an activity of interest;and the system needs to retrieve the most similar activities stored in the database. We focuson the case where the best database matches are not segmented a priori: the databasecontains representations of long; continuous activity; that occurs throughout relativelyextensive periods of time; and; given a query; there are no constraints as to when exactly adatabase match starts and ends within the longer activity pattern where it is contained. Usingthe popular DTW measure; the best database matches can be found using dynamic …,Proceedings of the 2nd International Conference on PErvasive Technologies Related to Assistive Environments,2009,*
Generalized Methods for Discovering Frequent Poly-Regions in DNA,Panagiotis Papapetrou; Gary Benson; George Kollios,The problem of discovering frequent poly-regions (ie regions of high occurrence of a set ofitems or patterns of a given alphabet) in a sequence is studied; and three efficientapproaches are proposed to solve it. The first one is entropy-based and applies a recursivesegmentation technique that produces a set of candidate segments which may potentiallylead to a poly-region. The key idea of the second approach is the use of a set of slidingwindows over the sequence. Each sliding window covers a sequence segment and keeps aset of statistics that mainly include the number of occurrences of each item or pattern in thatsegment. Combining these statistics efficiently yields the complete set of poly-regions in thegiven sequence. The third approach applies a technique based on the majority vote;achieving linear running time with a minimal number of false negatives. After identifying …,*,2008,*
Advances in intelligent data analysis XV,Arno J Knobbe; Carlos A Mota Soares; Panagiotis Papapetrou,Series/Report no.: Lecture notes in computer science;; 0302-9743;; 9897;; LNCS sublibrary.SL 3; Information systems and applications; incl. Internet/Web; and HCI;; Lecture notes incomputer science;; 9897.; 0302-9743;; LNCS sublibrary.; SL 3;; Information system,*,*,*
IEEE ICDM Workshop on Community Mining and People Recommenders,Panagiotis Papapetrou; Luiz Augusto Pizzato; Aristides Gionis; Xiongcai Cai,Data mining and knowledge discovery in social networks has advanced significantly overthe past several years; due to the availability of a large variety of online and online socialnetwork systems. The focus of COMMPER is on two main streams of social networks:community mining and system recommenders. The first focus of this workshop is on miningcommunities in social networks and in particular in scientific collaboration networks.Consider; for example; a dataset of scientific publications along with information about eachpublication and the complete citation network. Many data-analysis questions arise: what arethe underlying communities; who are the most influential authors; what are the set-skills ofindividual authors; what are the observed collaboration patterns; how does interest onpopular topics propagates; who does the network evolve in terms of collaborations; topics …,*,*,*
GRADUATE SCHOOL OF ARTS AND SCIENCES,PANAGIOTIS PAPAPETROU,ABSTRACT The problem of discovering frequent arrangements of temporal intervals isstudied. It is assumed that the database consists of sequences of events; where an eventoccurs during a time-interval. The goal is to mine temporal arrangements of event intervalsthat appear frequently in the database. The motivation of this work is the observation that inpractice most events are not instantaneous but occur over a period of time and differentevents may occur concurrently. Thus; there are many practical applications that requiremining such temporal correlations between intervals including the linguistic analysis ofannotated data from American Sign Language as well as network and biological data. Twoefficient methods to find frequent arrangements of temporal intervals are described; the firstone is tree-based and uses depth first search to mine the set of frequent arrangements …,*,*,*
In: Mastering the Information Age Solving Problems with Visual Analytics (2010) Eurographics Association; pp. 39-56.,Kai Puolamäki; Alessio Bertone; Roberto Théron; Otto Huisman; Jimmy Johansson; Silvia Miksch; Panagiotis Papapetrou; Salvo Rinzivillo,*,*,*,*
