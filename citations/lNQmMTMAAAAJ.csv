Shared memory parallelization of data mining algorithms: Techniques; programming interface; and performance,Ruoming Jin; Ge Yang; Gagan Agrawal,With recent technological advances; shared memory parallel machines have become morescalable; and offer large main memories and high bus bandwidths. They are emerging asgood platforms for data warehousing and data mining. In This work; we focus on sharedmemory parallelization of data mining algorithms. We have developed a series oftechniques for parallelization of data mining algorithms; including full replication; full locking;fixed locking; optimized full locking; and cache-sensitive locking. Unlike previous work onshared memory parallelization of specific data mining algorithms; all of our techniques applyto a large number of popular data mining algorithms. In addition; we propose a reduction-object-based interface for specifying a data mining algorithm. We show how our runtimesystem can apply any of the techniques we have developed starting from a common …,IEEE Transactions on Knowledge and Data Engineering,2005,208
3-hop: a high-compression indexing scheme for reachability query,Ruoming Jin; Yang Xiang; Ning Ruan; David Fuhry,Abstract Reachability queries on large directed graphs have attracted much attentionrecently. The existing work either uses spanning structures; such as chains or trees; tocompress the complete transitive closure; or utilizes the 2-hop strategy to describe thereachability. Almost all of these approaches work well for very sparse graphs. However; thechallenging problem is that as the ratio of the number of edges to the number of verticesincreases; the size of the compressed transitive closure grows very large. In this paper; wepropose a new 3-hop indexing scheme for directed graphs with higher density. The basicidea of 3-hop indexing is to use chain structures in combination with hops to minimize thenumber of structures that must be indexed. Technically; our goal is to find a 3-hop schemeover dense DAGs (directed acyclic graphs) with minimum index size. We develop an …,Proceedings of the 2009 ACM SIGMOD International Conference on Management of data,2009,186
Efficient decision tree construction on streaming data,Ruoming Jin; Gagan Agrawal,Abstract Decision tree construction is a well studied problem in data mining. Recently; therehas been much interest in mining streaming data. Domingos and Hulten have presented aone-pass algorithm for decision tree construction. Their work uses Hoeffding inequality toachieve a probabilistic bound on the accuracy of the tree constructed. In this paper; werevisit this problem. We make the following two contributions: 1) We present a numericalinterval pruning (NIP) approach for efficiently processing numerical attributes. Our resultsshow an average of 39% reduction in execution times. 2) We exploit the properties of thegain function entropy (and gini) to reduce the sample size required for obtaining a givenbound on the accuracy. Our experimental results show a 37% reduction in the number ofdata instances required.,Proceedings of the ninth ACM SIGKDD international conference on Knowledge discovery and data mining,2003,185
Efficiently answering reachability queries on very large directed graphs,Ruoming Jin; Yang Xiang; Ning Ruan; Haixun Wang,Abstract Efficiently processing queries against very large graphs is an important researchtopic largely driven by emerging real world applications; as diverse as XML databases; GIS;web mining; social network analysis; ontologies; and bioinformatics. In particular; graphreachability has attracted a lot of research attention as reachability queries are not onlycommon on graph databases; but they also serve as fundamental operations for many othergraph queries. The main idea behind answering reachability queries in graphs is to buildindices based on reachability labels. Essentially; each vertex in the graph is assigned withcertain labels such that the reachability between any two vertices can be determined by theirlabels. Several approaches have been proposed for building these reachability labels;among them are interval labeling (tree cover) and 2-hop labeling. However; due to the …,Proceedings of the 2008 ACM SIGMOD international conference on Management of data,2008,161
A topic modeling approach and its integration into the random walk framework for academic search,Jie Tang; Ruoming Jin; Jing Zhang,In this paper; we propose a unified topic modeling approach and its integration into therandom walk framework for academic search. Specifically; we present a topic model forsimultaneously modeling papers; authors; and publication venues. We combine theproposed topic model into the random walk framework. Experimental results show that ourproposed approach for academic search significantly outperforms the baseline methods ofusing BM25 and language model; and those of using the existing topic models (includingpLSI; LDA; and the AT model).,Data Mining; 2008. ICDM'08. Eighth IEEE International Conference on,2008,134
An algorithm for in-core frequent itemset mining on streaming data,Ruoming Jin; Gagan Agrawal,Frequent item set mining is a core data mining operation and has been extensively studiedover the last decade. This paper takes a new approach for this problem and makes twomajor contributions. First; we present a one pass algorithm for frequent item set mining;which has deterministic bounds on the accuracy; and does not require any out-of-coresummary structure. Second; because our one pass algorithm does not produce any falsenegatives; it can be easily extended to a two pass accurate algorithm. Our two passalgorithm is very memory efficient; and allows mining of datasets with large number ofdistinct items and/or very low support levels. Our detailed experimental evaluation onsynthetic and real datasets shows the following. First; our one pass algorithm is veryaccurate in practice. Second; our algorithm requires significantly lower memory than …,Data Mining; Fifth IEEE International Conference on,2005,134
Distance-constraint reachability computation in uncertain graphs,Ruoming Jin; Lin Liu; Bolin Ding; Haixun Wang,Abstract Driven by the emerging network applications; querying and mining uncertaingraphs has become increasingly important. In this paper; we investigate a fundamentalproblem concerning uncertain graphs; which we call the distance-constraint reachability(DCR) problem: Given two vertices s and t; what is the probability that the distance from s to tis less than or equal to a user-defined threshold d in the uncertain graph? Since thisproblem is# P-Complete; we focus on efficiently and accurately approximating DCR online.Our main results include two new estimators for the probabilistic reachability. One is aHorvitz-Thomson type estimator based on the unequal probabilistic sampling scheme; andthe other is a novel recursive sampling estimator; which effectively combines a deterministicrecursive computational procedure with a sampling process to boost the estimation …,Proceedings of the VLDB Endowment,2011,121
A survey of algorithms for dense subgraph discovery,Victor E Lee; Ning Ruan; Ruoming Jin; Charu Aggarwal,Abstract In this chapter; we present a survey of algorithms for dense subgraph discovery.The problem of dense subgraph discovery is closely related to clustering though the twoproblems also have a number of differences. For example; the problem of clustering islargely concerned with that of finding a fixed partition in the data; whereas the problem ofdense subgraph discovery defines these dense components in a much more flexible way.The problem of dense subgraph discovery may wither be defined over single or multiplegraphs. We explore both cases. In the latter case; the problem is also closely related to theproblem of the frequent subgraph discovery. This chapter will discuss and organize theliterature on this topic effectively in order to make it much more accessible to the reader.,*,2010,116
Fast and exact out-of-core and distributed k-means clustering,Ruoming Jin; Anjan Goswami; Gagan Agrawal,Abstract Clustering has been one of the most widely studied topics in data mining and k-means clustering has been one of the popular clustering algorithms. K-means requiresseveral passes on the entire dataset; which can make it very expensive for large disk-resident datasets. In view of this; a lot of work has been done on various approximateversions of k-means; which require only one or a small number of passes on the entiredataset. In this paper; we present a new algorithm; called fast and exact k-means clustering(FEKM); which typically requires only one or a small number of passes on the entire datasetand provably produces the same cluster centres as reported by the original k-meansalgorithm. The algorithm uses sampling to create initial cluster centres and then takes one ormore passes over the entire dataset to adjust these cluster centres. We provide …,Knowledge and Information Systems,2006,103
Communication and memory optimal parallel data cube construction,Ruoming Jin; Karthikeyan Vaidyanathan; Ge Yang; Gagan Agrawal,Data cube construction is a commonly used operation in data warehouses. Because of thevolume of data that is stored and analyzed in a data warehouse and the amount ofcomputation involved in data cube construction; it is natural to consider parallel machines forthis operation. This paper addresses a number of algorithmic issues in parallel data cubeconstruction. First; we present an aggregation tree for sequential (and parallel) data cubeconstruction; which has minimally bounded memory requirements. An aggregation tree isparameterized by the ordering of dimensions. We present a parallel algorithm based uponthe aggregation tree. We analyze the interprocessor communication volume and construct aclosed form expression for it. We prove that the same ordering of the dimensions in theaggregation tree minimizes both the computational and communication requirements. We …,IEEE Transactions on Parallel and Distributed Systems,2005,101
Topic level expertise search over heterogeneous networks,Jie Tang; Jing Zhang; Ruoming Jin; Zi Yang; Keke Cai; Li Zhang; Zhong Su,Abstract In this paper; we present a topic level expertise search framework forheterogeneous networks. Different from the traditional Web search engines that performretrieval and ranking at document level (or at object level); we investigate the problem ofexpertise search at topic level over heterogeneous networks. In particular; we study thisproblem in an academic search and mining system; which extracts and integrates theacademic data from the distributed Web. We present a unified topic model to simultaneouslymodel topical aspects of different objects in the academic network. Based on the learnedtopic models; we investigate the expertise search problem from three dimensions: ranking;citation tracing analysis; and topical graph search. Specifically; we propose a topic levelrandom walk method for ranking the different objects. In citation tracing analysis; we aim …,Machine Learning,2011,78
Data discretization unification,Ruoming Jin; Yuri Breitbart; Chibuike Muoh,Abstract Data discretization is defined as a process of converting continuous data attributevalues into a finite set of intervals with minimal loss of information. In this paper; we provethat discretization methods based on informational theoretical complexity and the methodsbased on statistical measures of data dependency are asymptotically equivalent.Furthermore; we define a notion of generalized entropy and prove that discretizationmethods based on Minimal description length principle; Gini index; AIC; BIC; and Pearson'sX 2 and G 2 statistics are all derivable from the generalized entropy function. We design adynamic programming algorithm that guarantees the best discretization based on thegeneralized entropy notion. Furthermore; we conducted an extensive performanceevaluation of our method for several publicly available data sets. Our results show that …,Knowledge and Information Systems,2009,77
Computing label-constraint reachability in graph databases,Ruoming Jin; Hui Hong; Haixun Wang; Ning Ruan; Yang Xiang,Abstract Our world today is generating huge amounts of graph data such as social networks;biological networks; and the semantic web. Many of these real-world graphs are edge-labeled graphs; ie; each edge has a label that denotes the relationship between the twovertices connected by the edge. A fundamental research problem on these labeled graphs ishow to handle the label-constraint reachability query: Can vertex u reach vertex v through apath whose edge labels are constrained by a set of labels? In this work; we introduce anovel tree-based index framework which utilizes the directed maximal weighted spanningtree algorithm and sampling techniques to maximally compress the generalized transitiveclosure for the labeled graphs. An extensive experimental evaluation on both real andsynthetic datasets demonstrates the efficiency of our approach in answering label …,Proceedings of the 2010 ACM SIGMOD International Conference on Management of data,2010,75
Learning personal+ social latent factor model for social recommendation,Yelong Shen; Ruoming Jin,Abstract Social recommendation; which aims to systematically leverage the socialrelationships between users as well as their past behaviors for automatic recommendation;attract much attention recently. The belief is that users linked with each other in socialnetworks tend to share certain common interests or have similar tastes (homophilyprinciple); such similarity is expected to help improve the recommendation accuracy andquality. There have been a few studies on social recommendations; however; they almostcompletely ignored the heterogeneity and diversity of the social relationship. In this paper;we develop a joint personal and social latent factor (PSLF) model for socialrecommendation. Specifically; it combines the state-of-the-art collaborative filtering and thesocial network modeling approaches for social recommendation. Especially; the PSLF …,Proceedings of the 18th ACM SIGKDD international conference on Knowledge discovery and data mining,2012,74
A highway-centric labeling approach for answering distance queries on large sparse graphs,Ruoming Jin; Ning Ruan; Yang Xiang; Victor Lee,Abstract The distance query; which asks the length of the shortest path from a vertex $ u $ toanother vertex v; has applications ranging from link analysis; semantic web and otherontology processing; to social network operations. Here; we propose a novel labelingscheme; referred to as Highway-Centric Labeling; for answering distance queries in a largesparse graph. It empowers the distance labeling with a highway structure and leverages anovel bipartite set cover framework/algorithm. Highway-centric labeling provides betterlabeling size than the state-of-the-art $2 $-hop labeling; theoretically and empirically. It alsooffers both exact distance and approximate distance with bounded accuracy. A detailedexperimental evaluation on both synthetic and real datasets demonstrates that highway-centric labeling can outperform the state-of-the-art distance computation approaches in …,Proceedings of the 2012 ACM SIGMOD International Conference on Management of Data,2012,71
Discovering highly reliable subgraphs in uncertain graphs,Ruoming Jin; Lin Liu; Charu C Aggarwal,Abstract In this paper; we investigate the highly reliable subgraph problem; which arises inthe context of uncertain graphs. This problem attempts to identify all induced subgraphs forwhich the probability of connectivity being maintained under uncertainty is higher than agiven threshold. This problem arises in a wide range of network applications; such asprotein-complex discovery; network routing; and social network analysis. Since exactdiscovery may be computationally intractable; we introduce a novel sampling scheme whichenables approximate discovery of highly reliable subgraphs with high probability.Furthermore; we transform the core mining task into a new frequent cohesive set problem indeterministic graphs. Such transformation enables the development of an efficient two-stageapproach which combines novel peeling techniques for maximal set discovery with depth …,Proceedings of the 17th ACM SIGKDD international conference on Knowledge discovery and data mining,2011,64
On dense pattern mining in graph streams,Charu C Aggarwal; Yao Li; Philip S Yu; Ruoming Jin,Abstract Many massive web and communication network applications create data which canbe represented as a massive sequential stream of edges. For example; conversations in atelecommunication network or messages in a social network can be represented as amassive stream of edges. Such streams are typically very large; because of the largeamount of underlying activity in such networks. An important application in these domains isto determine frequently occurring dense structures in the underlying graph stream. Ingeneral; we would like to determine frequent and dense patterns in the underlyinginteractions. We introduce a model for dense pattern mining and propose probabilisticalgorithms for determining such structural patterns effectively and efficiently. The purpose ofthe probabilistic approach is to create a summarization of the graph stream; which can be …,Proceedings of the VLDB Endowment,2010,64
Communication and memory efficient parallel decision tree construction,Ruoming Jin; Gagan Agrawal,Abstract Decision tree construction is an important data mining problem. In this paper; werevisit this problem; with a new goal; ie Can we develop an efficient parallel algorithm fordecision tree construction that can be parallelized in the same way as algorithms for othermajor mining tasks?. We report a new approach to decision tree construction; which we referto as SPIES (Statistical Pruning of Intervals for Enhanced Scalability). This approachcombines RainForest based AVC groups with sampling to achieve memory efficientprocessing of numerical attributes. Overall; this algorithm has the following properties: 1) nopreprocessing or sorting of input data is required; 2) the size of the data-structure required inthe main memory is very small; 3) the only disk-traffic required is one pass for splitting nodesfor each level of the tree; and no writing-back of data; 4) very low communication volume …,*,2003,64
Large scale real-time ridesharing with service guarantee on road networks,Yan Huang; Favyen Bastani; Ruoming Jin; Xiaoyang Sean Wang,Abstract Urban traffic gridlock is a familiar scene. At the same time; the mean occupancy rateof personal vehicle trips in the United States is only 1.6 persons per vehicle mile.Ridesharing has the potential to solve many environmental; congestion; pollution; andenergy problems. In this paper; we introduce the problem of large scale real-timeridesharing with service guarantee on road networks. Trip requests are dynamicallymatched to vehicles while trip waiting and service time constraints are satisfied. We firstpropose two scheduling algorithms: a branch-and-bound algorithm and an integerprograming algorithm. However; these algorithms do not adapt well to the dynamic nature ofthe ridesharing problem. Thus; we propose kinetic tree algorithms which are better suited toefficient scheduling of dynamic requests and adjust routes on-the-fly. We perform …,Proceedings of the VLDB Endowment,2014,62
A middleware for developing parallel data mining implementations,Ruoming Jin; Gagan Agrawal,Abstract Data mining is an interdisciplinary field; having applications in diverse areas likebioinformatics; medical informatics; scientific data analysis; financial analysis; consumerprofiling; etc. In each of these application domains; the amount of data available for analysishas exploded in recent years; making the scalability of data,In Proceedings of the first SIAM conference on Data Mining,2001,62
Axiomatic ranking of network role similarity,Ruoming Jin; Victor E Lee; Hui Hong,Abstract A key task in analyzing social networks and other complex networks is roleanalysis: describing and categorizing nodes by how they interact with other nodes. Twonodes have the same role if they interact with equivalent sets of neighbors. The mostfundamental role equivalence is automorphic equivalence. Unfortunately; the fastestalgorithm known for graph automorphism is nonpolynomial. Moreover; since exactequivalence is rare; a more meaningful task is measuring the role similarity between any twonodes. This task is closely related to the link-based similarity problem that SimRankaddresses. However; SimRank and other existing simliarity measures are not sufficientbecause they do not guarantee to recognize automorphically or structurally equivalentnodes. This paper makes two contributions. First; we present and justify several axiomatic …,Proceedings of the 17th ACM SIGKDD international conference on Knowledge discovery and data mining,2011,57
SCARAB: scaling reachability computation on large graphs,Ruoming Jin; Ning Ruan; Saikat Dey; Jeffrey Yu Xu,Abstract Most of the existing reachability indices perform well on small-to medium-sizegraphs; but reach a scalability bottleneck around one million vertices/edges. As graphsbecome increasingly large; scalability is quickly becoming the major research challenge forthe reachability computation today. Can we construct indices which scale to graphs with tensof millions of vertices and edges? Can the existing reachability indices which perform wellon moderate-size graphs be scaled to very large graphs? In this paper; we proposeSCARAB (standing for SCAlable ReachABility); a unified reachability computationframework: it not only can scale the existing state-of-the-art reachability indices; whichotherwise could only be constructed and work on moderate size graphs; but also can helpspeed up the online query answering approaches. Our experimental results demonstrate …,Proceedings of the 2012 ACM SIGMOD International Conference on Management of Data,2012,56
Path-tree: An efficient reachability indexing scheme for large directed graphs,Ruoming Jin; Ning Ruan; Yang Xiang; Haixun Wang,Abstract Reachability query is one of the fundamental queries in graph database. The mainidea behind answering reachability queries is to assign vertices with certain labels such thatthe reachability between any two vertices can be determined by the labeling information.Though several approaches have been proposed for building these reachability labels; itremains open issues on how to handle increasingly large number of vertices in real-worldgraphs; and how to find the best tradeoff among the labeling size; the query answering time;and the construction time. In this article; we introduce a novel graph structure; referred to aspath-tree; to help labeling very large graphs. The path-tree cover is a spanning subgraph ofG in a tree shape. We show path-tree can be generalized to chain-tree which theoreticallycan has smaller labeling cost. On top of path-tree and chain-tree index; we also introduce …,ACM Transactions on Database Systems (TODS),2011,56
Discovering frequent topological structures from graph datasets,Ruoming Jin; Chao Wang; Dmitrii Polshakov; Srinivasan Parthasarathy; Gagan Agrawal,Abstract The problem of finding frequent patterns from graph-based datasets is an importantone that finds applications in drug discovery; protein structure analysis; XML querying; andsocial network analysis among others. In this paper we propose a framework to minefrequent large-scale structures; formally defined as frequent topological structures; fromgraph datasets. Key elements of our framework include; fast algorithms for discoveringfrequent topological patterns based on the well known notion of a topological minor;algorithms for specifying and pushing constraints deep into the mining process fordiscovering constrained topological patterns; and mechanisms for specifying approximatematches when discovering frequent topological patterns in noisy datasets. We demonstratethe viability and scalability of the proposed algorithms on real and synthetic datasets and …,Proceedings of the eleventh ACM SIGKDD international conference on Knowledge discovery in data mining,2005,53
Relational approach for shortest path discovery over large graphs,Jun Gao; Ruoming Jin; Jiashuai Zhou; Jeffrey Xu Yu; Xiao Jiang; Tengjiao Wang,Abstract With the rapid growth of large graphs; we cannot assume that graphs can still befully loaded into memory; thus the disk-based graph operation is inevitable. In this paper; wetake the shortest path discovery as an example to investigate the technique issues whenleveraging existing infrastructure of relational database (RDB) in the graph datamanagement. Based on the observation that a variety of graph search queries can beimplemented by iterative operations including selecting frontier nodes from visited nodes;making expansion from the selected frontier nodes; and merging the expanded nodes intothe visited ones; we introduce a relational FEM framework with three correspondingoperators to implement graph search tasks in the RDB context. We show new features suchas window function and merge statement introduced by recent SQL standards can not …,Proceedings of the VLDB Endowment,2011,49
Efficient skyline computation in metric space,David Fuhry; Ruoming Jin; Donghui Zhang,Abstract Given a set of n query points in a general metric space; a metric-space skyline(MSS) query asks what are the closest points to all these query points in the database. Here;consider for any point p; if there are no other points in the database which have less or equaldistance to all the query points; then p is denoted as one of the closest points to the querypoints. This problem is a direct generalization of the recently proposed spatial-skyline queryproblem; where all the points are located in two or three dimensional Euclidean space. It isalso closely related with the nearest neighbor (NN) query; the range query and the commonskyline query problem. In this paper; we have developed new algorithms to aggressivelyprune non-skyline points from the search space. We also contribute two new optimizationtechniques to reduce the number of distance computations and dominance tests. Our …,Proceedings of the 12th International Conference on Extending Database Technology: Advances in Database Technology,2009,49
Neighborhood-privacy protected shortest distance computing in cloud,Jun Gao; Jeffrey Xu Yu; Ruoming Jin; Jiashuai Zhou; Tengjiao Wang; Dongqing Yang,Abstract With the advent of cloud computing; it becomes desirable to utilize cloud computingto efficiently process complex operations on large graphs without compromising theirsensitive information. This paper studies shortest distance computing in the cloud; whichaims at the following goals: i) preventing outsourced graphs from neighborhood attack; ii)preserving shortest distances in outsourced graphs; iii) minimizing overhead on the clientside. The basic idea of this paper is to transform an original graph G into a link graph Gl keptlocally and a set of outsourced graphs Go. Each outsourced graph should meet therequirement of a new security model called 1-neighborhood-d-radius. In addition; theshortest distance query can be answered using Gl and Go. Our objective is to minimize thespace cost on the client side when both security and utility requirements are satisfied. We …,Proceedings of the 2011 ACM SIGMOD International Conference on Management of data,2011,48
Robust local community detection: on free rider effect and its elimination,Yubao Wu; Ruoming Jin; Jing Li; Xiang Zhang,Abstract Given a large network; local community detection aims at finding the community thatcontains a set of query nodes and also maximizes (minimizes) a goodness metric. Thisproblem has recently drawn intense research interest. Various goodness metrics have beenproposed. However; most existing metrics tend to include irrelevant subgraphs in thedetected local community. We refer to such irrelevant subgraphs as free riders. Wesystematically study the existing goodness metrics and provide theoretical explanations onwhy they may cause the free rider effect. We further develop a query biased node weightingscheme to reduce the free rider effect. In particular; each node is weighted by its proximity tothe query node. We define a query biased density metric to integrate the edge and nodeweights. The query biased densest subgraph; which has the largest query biased density …,Proceedings of the VLDB Endowment,2015,46
Summarizing transactional databases with overlapped hyperrectangles,Yang Xiang; Ruoming Jin; David Fuhry; Feodor F Dragan,Abstract Transactional data are ubiquitous. Several methods; including frequent itemsetmining and co-clustering; have been proposed to analyze transactional databases. In thiswork; we propose a new research problem to succinctly summarize transactional databases.Solving this problem requires linking the high level structure of the database to a potentiallyhuge number of frequent itemsets. We formulate this problem as a set covering problemusing overlapped hyperrectangles (a concept generally regarded as tile according to someexisting papers); we then prove that this problem and its several variations are NP-hard; andwe further reveal its relationship with the compact representation of a directed bipartitegraph. We develop an approximation algorithm H yper which can achieve a logarithmicapproximation ratio in polynomial time. We propose a pruning strategy that can …,Data Mining and Knowledge Discovery,2011,46
Succinct summarization of transactional databases: an overlapped hyperrectangle scheme,Yang Xiang; Ruoming Jin; David Fuhry; Feodor F Dragan,Abstract Transactional data are ubiquitous. Several methods; including frequent itemsetsmining and co-clustering; have been proposed to analyze transactional databases. In thiswork; we propose a new research problem to succinctly summarize transactional databases.Solving this problem requires linking the high level structure of the database to a potentiallyhuge number of frequent itemsets. We formulate this problem as a set covering problemusing overlapped hyperrectangles; we then prove that this problem and its several variationsare NP-hard. We develop an approximation algorithm HYPER which can achieve a ln (k)+ 1approximation ratio in polynomial time. We propose a pruning strategy that can significantlyspeed up the processing of our algorithm. Additionally; we propose an efficient algorithm tofurther summarize the set of hyperrectangles by allowing false positive conditions. A …,Proceedings of the 14th ACM SIGKDD international conference on Knowledge discovery and data mining,2008,43
Effective and efficient itemset pattern summarization: regression-based approaches,Ruoming Jin; Muad Abu-Ata; Yang Xiang; Ning Ruan,Abstract In this paper; we propose a set of novel regression-based approaches to effectivelyand efficiently summarize frequent itemset patterns. Specifically; we show that the problemof minimizing the restoration error for a set of itemsets based on a probabilistic modelcorresponds to a non-linear regression problem. We show that under certain conditions; wecan transform the nonlinear regression problem to a linear regression problem. We proposetwo new methods; k-regression and tree-regression; to partition the entire collection offrequent itemsets in order to minimize the restoration error. The K-regression approach;employing a K-means type clustering method; guarantees that the total restoration errorachieves a local minimum. The tree-regression approach employs a decision-tree type oftop-down partition process. In addition; we discuss alternatives to estimate the frequency …,Proceedings of the 14th ACM SIGKDD international conference on Knowledge discovery and data mining,2008,42
Using gene co-expression network analysis to predict biomarkers for chronic lymphocytic leukemia,Jie Zhang; Yang Xiang; Liya Ding; Tara B Borlawsky; Hatice Gulcin Ozer; Ruoming Jin; Philip Payne; Kun Huang,Chronic lymphocytic leukemia (CLL) is the most common adult leukemia. It is a highlyheterogeneous disease; and can be divided roughly into indolent and progressive stagesbased on classic clinical markers. Immunoglobin heavy chain variable region (IgVH)mutational status was found to be associated with patient survival outcome; and biomarkerslinked to the IgVH status has been a focus in the CLL prognosis research field. However;biomarkers highly correlated with IgVH mutational status which can accurately predict thesurvival outcome are yet to be discovered. In this paper; we investigate the use of gene co-expression network analysis to identify potential biomarkers for CLL. Specifically we focusedon the co-expression network involving ZAP70; a well characterized biomarker for CLL. Weselected 23 microarray datasets corresponding to multiple types of cancer from the Gene …,BMC bioinformatics,2010,41
Reliable clustering on uncertain graphs,Lin Liu; Ruoming Jin; Charu Aggarwal; Yelong Shen,Many graphs in practical applications are not deterministic; but are probabilistic in naturebecause the existence of the edges is inferred with the use of a variety of statisticalapproaches. In this paper; we will examine the problem of clustering uncertain graphs.Uncertain graphs are best clustered with the use of a possible worlds model in which themost reliable clusters are discovered in the presence of uncertainty. Reliable clusters arethose which are not likely to be disconnected in the context of different instantiations of theuncertain graph. We present experimental results which illustrate the effectiveness of ourmodel and approach.,Data Mining (ICDM); 2012 IEEE 12th International Conference on,2012,39
Fast and exact out-of-core k-means clustering,Anjan Goswami; Ruoming Jin; Gagan Agrawal,Clustering has been one of the most widely studied topics in data mining and k-meansclustering has been one of the popular clustering algorithms. K-means requires severalpasses on the entire dataset; which can make it very expensive for large disk-residentdatasets. In view of this; a lot of work has been done on various approximate versions of k-means; which require only one or a small number of passes on the entire dataset. In thispaper; we present a new algorithm which typically requires only one or a small number ofpasses on the entire dataset; and provably produces the same cluster centers as reported bythe original k-means algorithm. The algorithm uses sampling to create initial cluster centers;and then takes one or more passes over the entire dataset to adjust these cluster centers.We provide theoretical analysis to show that the cluster centers thus reported are the …,Data Mining; 2004. ICDM'04. Fourth IEEE International Conference on,2004,39
Communication motifs: a tool to characterize social communications,Qiankun Zhao; Yuan Tian; Qi He; Nuria Oliver; Ruoming Jin; Wang-Chien Lee,Abstract Social networks mediate not only the relations between entities; but also thepatterns of information propagation among them and their communication behavior. In thispaper; we extensively study the temporal annotations (eg; time stamps and duration) ofhistorical communications in social networks and propose two novel tools--communicationmotifs and maximum-flow communication motifs--for characterizations of the patterns ofinformation propagation in social networks. Using these motifs; we verify the followinghypothesis in social communication network: 1) the functional behavioral patterns ofinformation propagation within both social networks are stable over time; 2) the patterns ofinformation propagation in synchronous and asynchronous social networks are different andsensitive to the cost of communication; and 3) the speed and the amount of information …,Proceedings of the 19th ACM international conference on Information and knowledge management,2010,38
Trend motif: A graph mining approach for analysis of dynamic complex networks,Ruoming Jin; Scott McCallen; Eivind Almaas,Complex networks have been used successfully in scientific disciplines ranging fromsociology to microbiology to describe systems of interacting units. Until recently; studies ofcomplex networks have mainly focused on their network topology. However; in many realworld applications; the edges and vertices have associated attributes that are frequentlyrepresented as vertex or edge weights. Furthermore; these weights are often not static;instead changing with time and forming a time series. Hence; to fully understand thedynamics of the complex network; we have to consider both network topology and relatedtime series data. In this work; we propose a motif mining approach to identify trend motifs forsuch purposes. Simply stated; a trend motif describes a recurring subgraph where each of itsvertices or edges displays similar dynamics over a user-defined period. Given this; each …,Data Mining; 2007. ICDM 2007. Seventh IEEE International Conference on,2007,38
New sampling-based estimators for OLAP queries,Ruoming Jin; Leonid Glimcher; Chris Jermaine; Gagan Agrawal,One important way in which sampling for approximate query processing in a databaseenvironment differs from traditional applications of sampling is that in a database; it isfeasible to collect accurate summary statistics from the data in addition to the sample. Thispaper describes a set of sampling-based estimators for approximate query processing thatmake use of simple summary statistics to to greatly increase the accuracy of sampling-basedestimators. Our estimators are able to give tight probabilistic guarantees on estimationaccuracy. They are suitable for low or high dimensional data; and work with categorical ornumerical attributes. Furthermore; the information used by our estimators can easily begathered in a single pass; making them suitable for use in a streaming environment.,Data Engineering; 2006. ICDE'06. Proceedings of the 22nd International Conference on,2006,36
Identifying dynamic network modules with temporal and spatial constraints,Ruoming Jin; Scott McCallen; Chun-Chi Liu; Yang Xiang; Eivind Almaas; Xianghong Jasmine Zhou,Abstract Despite the rapid accumulation of systems-level biological data; understanding thedynamic nature of cellular activity remains a difficult task. The reason is that most biologicaldata are static; or only correspond to snapshots of cellular activity. In this study; we explicitlyattempt to detangle the temporal complexity of biological networks by using compilations oftime-series gene expression profiling data. We define a dynamic network module to be a setof proteins satisfying two conditions:(1) they form a connected component in the protein-protein interaction (PPI) network; and (2) their expression profiles form certain structures inthe temporal domain. We develop an efficient mining algorithm to discover dynamic modulesin a temporal network. Using yeast as a model system; we demonstrate that the majority ofthe identified dynamic modules are functionally homogeneous. Additionally; many of …,*,2009,35
Migration motif: a spatial-temporal pattern mining approach for financial markets,Xiaoxi Du; Ruoming Jin; Liang Ding; Victor E Lee; John H Thornton Jr,Abstract A recent study by two prominent finance researchers; Fama and French; introducesa new framework for studying risk vs. return: the migration of stocks across size-valueportfolio space. Given the financial events of 2008; this first attempt to disentangle therelationships between migration behavior and stock returns is especially timely. Their work;however; derives results only for market segments; not individual companies; and only forone-year moves. Thus; we see a new challenge for financial data mining: how to captureand categorize the migration of individual companies; and how such behavior affects theirreturns. We propose a novel data mining approach to study the multi-year movement ofindividual companies. Specifically; we address the question:" How does one discoverfrequent migration patterns in the stock market?" We present a new trajectory mining …,Proceedings of the 15th ACM SIGKDD international conference on Knowledge discovery and data mining,2009,31
Simple; fast; and scalable reachability oracle,Ruoming Jin; Guan Wang,Abstract A reachability oracle (or hop labeling) assigns each vertex v two sets of vertices: Lout (v) and L in (v); such that u reaches v iff L out (u)∩ L in (v)≠ 0. Despite their simplicityand elegance; reachability oracles have failed to achieve efficiency in more than ten yearssince their introduction: The main problem is high construction cost; which stems from a set-cover framework and the need to materialize transitive closure. In this paper; we present twosimple and efficient labeling algorithms; Hierarchical-Labeling and Distribution-Labeling;which can work onmassive real-world graphs: Their construction time is an order ofmagnitude faster than the set-cover based labeling approach; and transitive closurematerialization is not needed. On large graphs; their index sizes and their queryperformance can now beat the state-of-the-art transitive closure compression and online …,Proceedings of the VLDB Endowment,2013,30
A hypergraph-based method for discovering semantically associated itemsets,Haishan Liu; Paea Le Pendu; Ruoming Jin; Dejing Dou,In this paper; we address an interesting data mining problem of finding semanticallyassociated itemsets; ie; items connected via indirect links. We propose a novel method fordiscovering semantically associated itemsets based on a hypergraph representation of thedatabase. We describe two similarity measures to compute the strength of associationsbetween items. Specifically; we introduce the average commute time similarity; s CT; basedon the random walk model on hypergraph; and the inner-product similarity; s L+; based onthe Moore-Penrose pseudoinverse of the hypergraph Laplacian matrix. Given semanticallyassociated 2-itemsets generated by these measures; we design a hypergraph expansionmethod with two search strategies; namely; the clique and connected component search; togenerate k-itemsets (k>; 2). We show the proposed method is indeed capable of …,Data Mining (ICDM); 2011 IEEE 11th International Conference on,2011,29
Frequent pattern mining in data streams,Ruoming Jin; Gagan Agrawal,Abstract Frequent pattern mining is a core data mining operation and has been extensivelystudied over the last decade. Recently; mining frequent patterns over data streams haveattracted a lot of research interests. Compared with other streaming queries; frequent patternmining poses great challenges due to high memory and computational costs; and accuracyrequirement of the mining results. In this chapter; we overview the state-of-art techniques tomine frequent patterns over data streams. We also introduce a new approach for thisproblem; which makes two major contributions. First; this one pass algorithm for frequentitemset mining has deterministic bounds on the accuracy; and does not require any out-of-core summary structure. Second; because the one pass algorithm does not produce anyfalse negatives; it can be easily extended to a two pass accurate algorithm. The two pass …,*,2007,25
Reachability querying: An independent permutation labeling approach,Hao Wei; Jeffrey Xu Yu; Can Lu; Ruoming Jin,Abstract Reachability query is a fundamental graph operation which answers whether avertex can reach another vertex over a large directed graph G with n vertices and m edgesand has been extensively studied. In the literature; all the approaches compute a label forevery vertex in a graph G by index construction offline. The query time for answeringreachability queries online is affected by the quality of the labels computed in indexconstruction. The three main costs are the index construction time; the index size; and thequery time. Some of the up-to-date approaches can answer reachability queries efficiently;but spend nonlinear time to construct an index. Some of the up-to-date approaches constructan index in linear time and space; but may need to depth-first search G at run-time in O (n+m) O (n+ m). In this paper; we discuss a new randomized labeling approach; named IP …,The VLDB Journal,2018,23
Systematic approach for optimizing complex mining tasks on multiple databases,Ruoming Jin; Gagan Agrawal,Many real world applications involve not just a single dataset; but a view of multipledatasets. These datasets may be collected from different sources and/or at different timeinstances. In such scenarios; comparing patterns or features from different datasets andunderstanding their relationships can be an extremely important part of the KDD process.This paper considers the problem of optimizing a mining task over multiple datasets; when ithas been expressed using a highlevel interface. Specifically; we make the followingcontributions: 1) We present an SQL-based mechanism for querying frequent patternsacross multiple datasets; and establish an algebra for these queries. 2) We develop asystematic method for enumerating query plans and present several algorithms for findingoptimized query plan which reduce execution costs. 3) We evaluate our algorithms on …,Data Engineering; 2006. ICDE'06. Proceedings of the 22nd International Conference on,2006,23
Distance preserving graph simplification,Ning Ruan; Ruoming Jin; Yan Huang,Large graphs are difficult to represent; visualize; and understand. In this paper; weintroduce" gate graph" a new approach to perform graph simplification. A gate graphprovides a simplified topological view of the original graph. Specifically; we construct a gategraph from a large graph so that for any" non-local" vertex pair (distance greater than somethreshold) in the original graph; their shortest-path distance can be recovered byconsecutive" local" walks through the gate vertices in the gate graph. We perform atheoretical investigation on the gate-vertex set discovery problem. We characterize itscomputational complexity and reveal the upper bound of minimum gate-vertex set using VC-dimension theory. We propose an efficient mining algorithm to discover a gate-vertex setwith guaranteed logarithmic bound. The detailed experimental results using both real and …,Data Mining (ICDM); 2011 IEEE 11th International Conference on,2011,22
Noah: a dynamic ridesharing system,Charles Tian; Yan Huang; Zhi Liu; Favyen Bastani; Ruoming Jin,Abstract This demo presents Noah: a dynamic ridesharing system. Noah supports largescale real-time ridesharing with service guarantee on road networks. Taxis and trip requestsare dynamically matched. Different from traditional systems; a taxi can have more than onecustomer on board given that all waiting time and service time constraints of trips aresatisfied. Noah's real-time response relies on three main components:(1) a fast shortest pathalgorithm with caching on road networks;(2) fast dynamic matching algorithms to scheduleridesharing on the fly;(3) a spatial indexing method for fast retrieving moving taxis. Users willbe able to submit requests from a smartphone; choose specific parameters such as numberof taxis in the system; service constraints; and matching algorithms; to explore the internalfunctionalities and implementations of Noah. The system analyzer will show the system …,Proceedings of the 2013 ACM SIGMOD International Conference on Management of Data,2013,20
Middleware for data mining applications on clusters and grids,Leonid Glimcher; Ruoming Jin; Gagan Agrawal,Abstract This paper gives an overview of two middleware systems that have been developedover the last 6 years to address the challenges involved in developing parallel anddistributed implementations of data mining algorithms. FREERIDE (FRamework for RapidImplementation of Data mining Engines) focuses on data mining in a cluster environment.FREERIDE is based on the observation that parallel versions of several well-known datamining techniques share a relatively similar structure; and can be parallelized by dividingthe data instances (or records or transactions) among the nodes. The computation on eachnode involves reading the data instances in an arbitrary order; processing each datainstance; and performing a local reduction. The reduction involves only commutative andassociative operations; which means the result is independent of the order in which the …,Journal of Parallel and Distributed Computing,2008,20
Overlapping matrix pattern visualization: A hypergraph approach,Ruoming Jin; Yang Xiang; David Fuhry; Feodor F Dragan,In this work; we study a visual data mining problem: Given a set of discovered overlappingsubmatrices of interest; how can we order the rows and columns of the data matrix to bestdisplay these submatrices and their relationships? We find this problem can be converted tothe hypergraph ordering problem; which generalizes the traditional minimal lineararrangement (or graph ordering) problem and then we are able to prove the NP-hardness ofthis problem. We propose a novel iterative algorithm which utilize the existing graphordering algorithm to solve the optimal visualization problem. This algorithm can alwaysconverge to a local minimum. The detailed experimental evaluation using a set of publiclyavailable transactional datasets demonstrates the effectiveness and efficiency of theproposed algorithm.,Data Mining; 2008. ICDM'08. Eighth IEEE International Conference on,2008,19
Performance prediction for random write reductions: a case study in modeling shared memory programs,Ruoming Jin; Gagan Agrawal,Abstract In this paper; we revisit the problem of performance prediction on shared memoryparallel machines; motivated by the need for selecting parallelization strategy for randomwrite reductions. Such reductions frequently arise in data mining algorithms. In our previouswork; we have developed a number of techniques for parallelizing this class of reductions.Our previous work has shown that each of the three techniques; full replication; optimizedfull locking; and cache-sensitive; can outperform others depending upon problem; dataset;and machine parameters. Therefore; an important question is;" Can we predict theperformance of these techniques for a given problem; dataset; and machine?". This paperaddresses this question by developing an analytical performance model that captures a two-level cache; coherence cache misses; TLB misses; locking overheads; and contention for …,ACM SIGMETRICS Performance Evaluation Review,2002,19
FREERIDE-G: Supporting Applications that Mine Remote FREERIDE-G: Supporting Applications that Mine Remote,Leonid Glimcher; Ruoming Jin; Gagan Agrawal,Analysis of large geographically distributed scientific datasets; also referred to as distributeddata-intensive science; has emerged as an important area in recent years. An applicationthat processes data from a remote repository needs to be broken into several stages;including a data retrieval task at the data repository; a data movement task; and a dataprocessing task at a computing site. Because of the volume of data that is involved and theamount of processing; it is desirable that both the data repository and computing site may beclusters. This can further complicate the development of such data processing applications.In this paper; we present a middleware; FREERIDE-G (framework for rapid implementationof datamining engines in grid); which support a high-level interface for developing datamining and scientific data processing applications that involve data stored in remote …,Parallel Processing; 2006. ICPP 2006. International Conference on,2006,18
A middleware for developing parallel data mining applications,Ruoming Jin; Gagan Agrawal,1 Introduction Data mining is an interdisciplinary field; having applications in diverse areaslike bioinformatics; medical informatics; scientific data analysis; financial analysis; consumerprofiling; etc. In each of these application domains; the amount of data available for analysishas exploded in recent years; making the scalability of data mining implementations acritical factor. To this end; parallel versions of most of the well-known data mining techniqueshave been developed in recent years. However; the expertise and effort currently required inimplementing; maintaining; and performance tuning a parallel data mining application is asevere impediment in the wide use of parallel computers for scalable data mining.,*,2001,18
Fast and unified local search for random walk based k-nearest-neighbor query in large graphs,Yubao Wu; Ruoming Jin; Xiang Zhang,Abstract Given a large graph and a query node; finding its k-nearest-neighbor (kNN) is afundamental problem. Various random walk based measures have been developed tomeasure the proximity (similarity) between nodes. Existing algorithms for the random walkbased top-k proximity search can be categorized as global and local methods based on theirsearch strategies. Global methods usually require an expensive precomputing step. By onlysearching the nodes near the query node; local methods have the potential to support moreefficient query. However; most existing local search methods cannot guarantee theexactness of the solution. Moreover; they are usually designed for specific proximitymeasures. Can we devise an efficient local search method that applies to different measuresand also guarantees result exactness? In this paper; we present FLoS (Fast Local Search …,Proceedings of the 2014 ACM SIGMOD international conference on Management of data,2014,17
Socialized gaussian process model for human behavior prediction in a health social network,Yelong Shen; Ruoming Jin; Dejing Dou; Nafisa Chowdhury; Junfeng Sun; Brigitte Piniewski; David Kil,Modeling and predicting human behaviors; such as the activity level and intensity; is the keyto prevent the cascades of obesity; and help spread wellness and healthy behavior in asocial network. In this work; we propose a Socialized Gaussian Process (SGP) for socializedhuman behavior modeling. In the proposed SGP model; we naturally incorporates human'spersonal behavior factor and social correlation factor into a unified model; where basicGaussian Process model is leveraged to capture individual's personal behavior pattern.Furthermore; we extend the Gaussian Process Model to socialized Gaussian Process (SGP)which aims to capture social correlation phenomena in the social network. The detailedexperimental evaluation has shown the SGP model achieves the best prediction accuracycompared with other baseline methods.,Data Mining (ICDM); 2012 IEEE 12th International Conference on,2012,16
Snpminer: A domain-specific deep web mining tool,Fan Wang; Gagan Agrawal; Ruoming Jin; Helen Piontkivska,In this paper; we propose a novel query-oriented; mediator-based biological data queryingtool; SNPMiner. The system searches and queries single nucleotide polymorphisms (SNPs)data from eight widely used web accessible databases. The system provides a domain-specific search utility; which can access and collect data from the deep web. This is a web-based system; so any user can use the system by accessing our server from their owncomputers. The system includes three important components; which are the Web serverinterface; the dynamic query planner; and the Web page parser. The Web server interfacecan provide end users a unified and friendly interface. The dynamic query planner canautomatically schedule an efficient query order on all available databases according touser's query request. The Web page parser analyzes the layout of HTML files and extracts …,Bioinformatics and Bioengineering; 2007. BIBE 2007. Proceedings of the 7th IEEE International Conference on,2007,16
Systems; methods; and software for unified analytics environments,*,Embodiments disclosed herein provide systems and methods for a unified analyticsenvironment. In a particular embodiment; a method provides; handling a plurality ofrelational functions within a relational analytics environment. The method further provides;while handling the plurality of relational functions; encountering at least one graph functionthat comprises a query intended for a graph analytics environment. The method furtherprovides; in response to encountering the at least one graph function; communicating withthe graph analytics environment to handle the at least one graph function.,*,2015,15
Cartesian contour: a concise representation for a collection of frequent sets,Ruoming Jin; Yang Xiang; Lin Liu,Abstract In this paper; we consider a novel scheme referred to as Cartesian contour toconcisely represent the collection of frequent itemsets. Different from the existing works; thisscheme provides a complete view of these itemsets by covering the entire collection of them.More interestingly; it takes a first step in deriving a generative view of the frequent patternformulation; ie; how a small number of patterns interact with each other and produce thecomplexity of frequent itemsets. We perform a theoretical investigation of the conciserepresentation problem and link it to the biclique set cover problem and prove its NP-hardness. We develop a novel approach utilizing the technique developed in frequentitemset mining; set cover; and max k-cover to approximate the minimal biclique set coverproblem. In addition; we consider several heuristic techniques to speedup the …,Proceedings of the 15th ACM SIGKDD international conference on Knowledge discovery and data mining,2009,15
Simultaneous optimization of complex mining tasks with a knowledgeable cache,Ruoming Jin; Kaushik Sinha; Gagan Agrawal,Abstract With an increasing use of data mining tools and techniques; we envision that aKnowledge Discovery and Data Mining System (KDDMS) will have to support and optimizefor the following scenarios: 1) Sequence of Queries: A user may analyze one or moredatasets by issuing a sequence of related complex mining queries; and 2) MultipleSimultaneous Queries: Several users may be analyzing a set of datasets concurrently; andmay issue related complex queries. This paper presents a systematic mechanism tooptimize for the above cases; targeting the class of mining queries involving frequent patternmining on one or multiple datasets. We present a system architecture and propose newalgorithms to simultaneously optimize multiple such queries and use a knowledgeablecache to store and utilize the past query results. We have implemented and evaluated our …,Proceedings of the eleventh ACM SIGKDD international conference on Knowledge discovery in data mining,2005,15
An efficient implementation of apriori association mining on cluster of smps,Ruoming Jin; Gagan Agrawal,*,Proceedings of the workshop on High Performance Data Mining; held with IPDPS 2001,2001,15
Using frequent co-expression network to identify gene clusters for breast cancer prognosis,Jie Zhang; Kun Huang; Yang Xiang; Ruoming Jin,In this paper; we investigated the use of gene coexpression network analyses to identifypotential biomarkers for breast carcinoma prognosis. The network mining algorithmCODENSE is used to identify highly connected genome-wide gene co-expression networksamong a variety of cancer types; and the resulted gene clusters are applied to a series ofbreast cancer microarray sets to categorize the patients into different groups. As a result; wehave identified a set of genes that are potential biomarkers for breast cancer prognosiswhich can categorize the patients into two groups with distinct prognosis. We also comparedthe gene clusters we discovered with gene subsets identified from similar studies usingother clustering algorithms.,Bioinformatics; Systems Biology and Intelligent Computing; 2009. IJCBS'09. International Joint Conference on,2009,14
Query planning for searching inter-dependent deep-web databases,Fan Wang; Gagan Agrawal; Ruoming Jin,Abstract Increasingly; many data sources appear as online databases; hidden behind queryforms; thus forming what is referred to as the deep web. It is desirable to have systems thatcan provide a high-level and simple interface for users to query such data sources; and canautomate data retrieval from the deep web. However; such systems need to address thefollowing challenges. First; in most cases; no single database can provide all desired data;and therefore; multiple different databases need to be queried for a given user query.Second; due to the dependencies present between the deep-web databases; certaindatabases must be queried before others. Third; some database may not be available atcertain times because of network or hardware problems; and therefore; the query planningshould be capable of dealing with unavailable databases and generating alternative …,International Conference on Scientific and Statistical Database Management,2008,14
Implementing data cube construction using a cluster middleware: Algorithms; implementation experience; and performance evaluation,Ge Yang; Ruoming Jin; Gagan Agrawal,Abstract With increases in the amount of data available for analysis in commercial settings;on line analytical processing (OLAP) and decision support have become importantapplications for high performance computing. Implementing such applications on clustersrequires a lot of expertise and effort; particularly because of the sizes of input and outputdatasets. In this paper; we describe our experiences in developing one such applicationusing a cluster middleware; called ADR. We focus on the problem of data cube construction;which commonly arises in multi-dimensional OLAP. We show how ADR; originallydeveloped for scientific data intensive applications; can be used for carrying out an efficientand scalable data cube construction implementation. A particular issue with the use of ADRis tiling of output datasets. We present new algorithms that combine interprocessor …,Future Generation Computer Systems,2003,14
Efficient location aware intrusion detection to protect mobile devices,Sausan Yazji; Peter Scheuermann; Robert P Dick; Goce Trajcevski; Ruoming Jin,Abstract This paper addresses the problem of efficient intrusion detection for mobile devicesvia correlating the user's location and time data. We developed two statistical profilingapproaches for modeling the normal spatio–temporal behavior of the users: one based onan empirical cumulative probability measure and the other based on the Markov propertiesof trajectories. An anomaly is detected when the probability of a particular (location; time)evolution matching the normal behavior of a given user becomes lower than a certainthreshold; determined by controlling the recall rate of the model of the normal user'sbehavior. We used compression techniques to reduce processing overhead whilemaintaining high accuracy. Our evaluation based on the Reality Mining and Geolife datasets shows that the proposed system is capable of detecting a potential intrusion within …,Personal and Ubiquitous Computing,2014,13
Finding dense and connected subgraphs in dual networks,Yubao Wu; Ruoming Jin; Xiaofeng Zhu; Xiang Zhang,Finding dense subgraphs is an important problem that has recently attracted a lot ofinterests. Most of the existing work focuses on a single graph (or network 1). In many real-lifeapplications; however; there exist dual networks; in which one network represents thephysical world and another network represents the conceptual world. In this paper; weinvestigate the problem of finding the densest connected subgraph (DCS) which has thelargest density in the conceptual network and is also connected in the physical network.Such pattern cannot be identified using the existing algorithms for a single network. Weshow that even though finding the densest subgraph in a single network is polynomial timesolvable; the DCS problem is NP-hard. We develop a two-step approach to solve the DCSproblem. In the first step; we effectively prune the dual networks while guarantee that the …,Data Engineering (ICDE); 2015 IEEE 31st International Conference on,2015,11
Mining biomedical ontologies and data using rdf hypergraphs,Haishan Liu; Dejing Dou; Ruoming Jin; Paea Lependu; Nigam Shah,As researchers analyze huge amounts of data that are annotated by large biomedicalontologies; one of the major challenges for data mining and machine learning is to leverageboth ontologies and data together in a systematic and scalable way. In this paper; weaddress two interesting and related problems for mining biomedical ontologies and data: i)how to discover semantic associations with the help of formal ontologies; ii) how to identifypotential errors in the ontologies with the help of data. By representing both ontologies anddata using RDF hyper graphs; and subsequently transforming the hyper graphs tocorresponding bipartite forms; we provide a generalized data mining method that scalesbeyond what existing ontology-based approaches can provide. We show the proposedmethod is indeed capable of capturing semantic associations while seamlessly …,Machine Learning and Applications (ICMLA); 2013 12th International Conference on,2013,11
A methodology for detailed performance modeling of reduction computations on smp machines,Ruoming Jin; Gagan Agrawal,Abstract In this paper; we revisit the problem of performance prediction on SMP machines;motivated by the need for selecting parallelization strategy for random write reductions. Suchreductions frequently arise in data mining algorithms. In our previous work; we havedeveloped a number of techniques for parallelizing this class of reductions. Our previouswork has shown that each of the three techniques; full replication; optimized full locking; andcache-sensitive; can outperform others depending upon problem; dataset; and machineparameters. Therefore; an important question is;“Can we predict the performance of thesetechniques for a given problem; dataset; and machine?”. This paper addresses this questionby developing an analytical performance model that captures a two-level cache; coherencecache misses; TLB misses; locking overheads; and contention for memory. Analytical …,Performance Evaluation,2005,11
Frequent pattern mining in data streams,Victor E Lee; Ruoming Jin; Gagan Agrawal,Abstract As the volume of digital commerce and communication has exploded; the demandfor data mining of streaming data has likewise grown. One of the fundamental data miningtasks; for both static and streaming data; is frequent pattern mining. The goal of patternmining is to identity frequently occurring patterns and structures. Such patterns may indicatescientific phenomena; economic or social trends; or even security threats. Moreover; not onlyis pattern discovery important by itself; but it is also a building block for machine learningtasks such as association rule induction. Traditionally; algorithms for pattern discovery haveprocessed the entire dataset as a batch; with no restriction on how many passes through thedata would be taken. However; when the data are arriving in a continuous and unendingstream; our algorithm must be limited to a single pass. Moreover; the length of the stream …,*,2014,10
Merging network patterns: a general framework to summarize biomedical network data,Yang Xiang; David Fuhry; Kamer Kaya; Ruoming Jin; Ümit V Çatalyürek; Kun Huang,Abstract The ability to summarize a large number of network patterns discovered frombiomedical data provides valuable information for use in many applications. We show thatseveral variants of the problem are all NP-hard; and merging network patterns is a practicalsolution for these applications. In this work; we propose an algorithmic framework formerging network patterns. We have developed fast algorithms under this general frameworkwhich supports several types of biomedical network data. In addition; our empirical studydemonstrates that our algorithms are efficient in merging a large number of biomedicalnetwork patterns and can be configured for various knowledge discovery purposes.,Network Modeling Analysis in Health Informatics and Bioinformatics,2012,10
Multi-view random walk framework for search task discovery from click-through log,Jianwei Cui; Hongyan Liu; Jun Yan; Lei Ji; Ruoming Jin; Jun He; Yingqin Gu; Zheng Chen; Xiaoyong Du,Abstract Search engine users often have clear search tasks hidden behind their queries.Inspired by this; the modern search engines are providing an increasing number of servicesto help users simplify their key tasks. However; the problem of what are the major usersearch tasks with high traffic for which search engines should design special services is stillunderexplored. In this paper; we propose a novel Multi-view Random Walk (MRW) algorithmto measure the search task oriented similarity between queries; and then group searchqueries with similar tasks so that the major search tasks of users can be identified fromsearch engine click-through log. The proposed MRW; which is a general framework tocombine knowledge from different views in a random walk process; allows the random surferto walk across different views to integrate information for search task discovery …,Proceedings of the 20th ACM international conference on Information and knowledge management,2011,10
Estimating the number of frequent itemsets in a large database,Ruoming Jin; Scott McCallen; Yuri Breitbart; Dave Fuhry; Dong Wang,Abstract Estimating the number of frequent itemsets for minimal support α in a large datasetis of great interest from both theoretical and practical perspectives. However; finding not onlythe number of frequent itemsets; but even the number of maximal frequent itemsets; is# P-complete. In this study; we provide a theoretical investigation on the sampling estimator. Wediscover and prove several fundamental but also rather surprising properties of the samplingestimator. We also propose a novel algorithm to estimate the number of frequent itemsetswithout using sampling. Our detailed experimental results have shown the accuracy andefficiency of our proposed approach.,Proceedings of the 12th International Conference on Extending Database Technology: Advances in Database Technology,2009,10
Shared memory parallelization of decision tree construction using a general data mining middleware,Ruoming Jin; Gagan Agrawal,Abstract Decision tree construction is a very well studied problem in data mining; machinelearning; and statistics communities [3; 2; 7; 8; 9]. The input to a decision tree constructionalgorithm is a database of training records. Each record has several attributes. An attributewhose underlying domain is totally ordered is called a numerical attribute. Other attributesare called categorical attributes. One particular attribute is called class label; and typicallycan hold only two values; true and false. All other attributes are referred to as predictorattributes.,European Conference on Parallel Processing,2002,10
Multiple Information Sources Cooperative Learning.,Xingquan Zhu; Ruoming Jin,Abstract Many applications are facing the problem of learning from an objective dataset;whereas information from other auxiliary sources may be beneficial but cannot be integratedinto the objective dataset for learning. In this paper; we propose an omni-view learningapproach to enable learning from multiple data collections. The theme is to organizeheterogeneous data sources into a unified table with global data view. To achieve the omni-view learning goal; we consider that the objective dataset and the auxiliary datasets sharesome instance-level dependency structures. We then propose a relational k-means tocluster instances in each auxiliary dataset; such that clusters can help build new features tocapture correlations between the objective and auxiliary datasets. Experimental resultsdemonstrate that omni-view learning can help build models which outperform the ones …,IJCAI,2009,9
A decomposition-based probabilistic framework for estimating the selectivity of XML twig queries,Chao Wang; Srinivasan Parthasarathy; Ruoming Jin,Abstract In this paper we present a novel approach for estimating the selectivity of XML twigqueries. Such a technique is useful for answering approximate queries as well as fordetermining an optimal query plan for complex queries based on said estimates. Ourapproach relies on a summary structure that contains the occurrence statistics of small twigs.We rely on a novel probabilistic approach for decomposing larger twig queries into smallerones. We then show how it can be used to estimate the selectivity of the larger query inconjunction with the summary information. We present and evaluate different strategies fordecomposition and compare this work against a state-of-the-art selectivity estimationapproach on synthetic and real datasets. The experimental results show that our proposedapproach is very effective in estimating the selectivity of XML twig queries.,International Conference on Extending Database Technology,2006,9
Parallelizing a defect detection and categorization application,Leonid Glimcher; Gagan Agrawal; Sameep Mehta; Rioming Jin; Raghu Machiraju,This paper presents a case study in creating a parallel and scalable implementation of ascientific data analysis application. We focus on a defect detection and categorizationapplication which analyzes datasets produced by molecular dynamics (MD) simulations. Inparallelizing this application; we had the following three goals. First; we obviously wanted toachieve high parallel efficiency. Second; we wanted to create an implementation that canscale to disk-resident datasets. Third; we wanted to create an easy to maintain and modifyimplementation; which is possible only through using high-level interfaces. We used anumber of techniques for organizing the input data; achieving load balance; and efficientlyparallelizing the step for updating and matching with the defect catalog. To meet our thirdgoal; we used a system called FREERIDE (FRamework for Rapid Implementation of …,Parallel and Distributed Processing Symposium; 2005. Proceedings. 19th IEEE International,2005,9
Optimizing index for taxonomy keyword search,Bolin Ding; Haixun Wang; Ruoming Jin; Jiawei Han; Zhongyuan Wang,Abstract Query substitution is an important problem in information retrieval. Much workfocuses on how to find substitutes for any given query. In this paper; we study how toefficiently process a keyword query whose substitutes are defined by a given taxonomy. Thisproblem is challenging because each term in a query can have a large number ofsubstitutes; and the original query can be rewritten into any of their combinations. Wepropose to build an additional index (besides inverted index) to efficiently process queries.For a query workload; we formulate an optimization problem which chooses the additionalindex structure; aiming at minimizing the query evaluation cost; under given index spaceconstraints. We show the NP-hardness of the problem; and propose a pseudo-polynomialtime algorithm using dynamic programming; as well as an 1 over 4 (1-1/e)-approximation …,Proceedings of the 2012 ACM SIGMOD International Conference on Management of Data,2012,8
High-level programming methodologies for data intensive computing,Gagan Agrawal; Renato Ferreira; Joel Saltz; Ruoming Jin,CiteSeerX - Document Details (Isaac Councill; Lee Giles; Pradeep Teregowda):,IN PROCEEDINGS OF THE FIFTH WORKSHOP ON LANGUAGES; COMPILERS; AND RUN-TIME SYSTEMS FOR SCALABLE COMPUTERS,2000,8
Dynamic socialized Gaussian process models for human behavior prediction in a health social network,Yelong Shen; NhatHai Phan; Xiao Xiao; Ruoming Jin; Junfeng Sun; Brigitte Piniewski; David Kil; Dejing Dou,Abstract Modeling and predicting human behaviors; such as the level and intensity ofphysical activity; is a key to preventing the cascade of obesity and helping spread healthybehaviors in a social network. In our conference paper; we have developed a socialinfluence model; named socialized Gaussian process (SGP); for socialized human behaviormodeling. Instead of explicitly modeling social influence as individuals' behaviors influencedby their friends' previous behaviors; SGP models the dynamic social correlation as the resultof social influence. The SGP model naturally incorporates personal behavior factor andsocial correlation factor (ie; the homophily principle: Friends tend to perform similarbehaviors) into a unified model. And it models the social influence factor (ie; an individual'sbehavior can be affected by his/her friends) implicitly in dynamic social correlation …,Knowledge and information systems,2016,7
Scalable and axiomatic ranking of network role similarity,Ruoming Jin; Victor E Lee; Longjie Li,Abstract A key task in analyzing social networks and other complex networks is roleanalysis: describing and categorizing nodes according to how they interact with other nodes.Two nodes have the same role if they interact with equivalent sets of neighbors. The mostfundamental role equivalence is automorphic equivalence. Unfortunately; the fastestalgorithms known for graph automorphism are nonpolynomial. Moreover; since exactequivalence is rare; a more meaningful task is measuring the role similarity between any twonodes. This task is closely related to the structural or link-based similarity problem thatSimRank addresses. However; SimRank and other existing similarity measures are notsufficient because they do not guarantee to recognize automorphically or structurallyequivalent nodes. This article makes two contributions. First; we present and justify …,ACM Transactions on Knowledge Discovery from Data (TKDD),2014,7
Visualizing clusters in parallel coordinates for visual knowledge discovery,Yang Xiang; David Fuhry; Ruoming Jin; Ye Zhao; Kun Huang,Abstract Parallel coordinates is frequently used to visualize multi-dimensional data. In thispaper; we are interested in how to effectively visualize clusters of multi-dimensional data inparallel coordinates for the purpose of facilitating knowledge discovery. In particular; wewould like to efficiently find a good order of coordinates for different emphases on visualknowledge discovery. To solve this problem; we link it to the metric-space Hamiltonian pathproblem by defining the cost between every pair of coordinates as the number of inter-cluster or intra-cluster crossings. This definition connects to various efficient solutions andleads to very fast algorithms. In addition; to better observe cluster interactions; we alsopropose to shape clusters smoothly by an energy reduction model which provides bothmacro and micro view of clusters.,Pacific-Asia Conference on Knowledge Discovery and Data Mining,2012,7
k-CoRating: Filling Up Data to Obtain Privacy and Utility.,Feng Zhang; Victor E Lee; Ruoming Jin,Abstract For datasets in Collaborative Filtering (CF) recommendations; even if the identifieris deleted and some trivial perturbation operations are applied to ratings before they arereleased; there are research results claiming that the adversary could discriminate theindividual's identity with a little bit of information. In this paper; we propose k-coRating; anovel privacy-preserving model; to retain data privacy by replacing some null ratings with”well-predicted” scores. They do not only mask the original ratings such that a k-anonymity-like data privacy is preserved; but also enhance the data utility (measured by predictionaccuracy in this paper); which shows that the traditional assumption that accuracy andprivacy are two goals in conflict is not necessarily correct. We show that the optimal k-coRated mapping is an NP-hard problem and design a naive but efficient algorithm to …,AAAI,2014,6
Shortest path computation in large networks,*,Embodiments disclosed herein provide systems; methods; and software for determining theshortest distance between vertices in relatively large graphs. In an embodiment a methodincludes identifying an original graph comprising a plurality of nodes and a plurality ofedges; identifying a plurality of hub nodes from within the original graph; creating a hubmatrix comprising the plurality of hub nodes and the shortest distance between the pluralityof hub nodes; and determining a shortest distance between the at least two nodes using theoriginal graph and/or the hub matrix.,*,2013,6
An efficient association mining implementation on clusters of SMP,Ruoming Jin; Gagan Agrawal,Note: OCR errors may be found in this Reference List extracted from the full text article. ACMhas opted to expose the complete List rather than only correct and linked references … ChristanBorgelt. Apriori. http://fuzzy.cs.Uni-Magdeburg.de/ borgelt/Software. Version 1.8 … ChialinChang; Tahsin Kurc; Alan Sussman; and Joel Saltz. Query planning for range queries withuser-defined aggregation on multi-dimensional scientific datasets. Technical Report CS-TR-3996and UMIACS-TR-99-15; University of Maryland; Department of Computer Science andUMIACS; February 1999 … Srinivasan Parthasarathy; Mohammed Zaki; and Wei Li. Memoryplacement techniques for parallel association mining. In Proceedings of the 4th InternationalConference on Knowledge Discovery and Data Mining (KDD); August 1998.,Proceedings of the 15th International Parallel & Distributed Processing Symposium,2001,6
Compiling data intensive applications with spatial coordinates,Renato Ferreira; Gagan Agrawal; Ruoming Jin; Joel Saltz,Abstract Processing and analyzing large volumes of data plays an increasingly importantrole in many domains of scientific research. We are developing a compiler which processesdata intensive applications written in a dialect of Java and compiles them for efficientexecution on cluster of workstations or distributed memory machines. In this paper; we focuson data intensive applications with two important properties: 1) data elements have spatialcoordinates associated with them and the distribution of the data is not regular with respectto these coordinates; and 2) the application processes only a subset of the available data onthe basis of spatial coordinates. These applications arise in many domains like satellite data-processing and medical imaging. We present a general compilation and execution strategyfor this class of applications which achieves high locality in disk accesses. We then …,International Workshop on Languages and Compilers for Parallel Computing,2000,6
Rule-Based Classification.,Xiaoli Li; Bing Liu,Classification is an important problem in machine learning and data mining. It has beenwidely applied in many real-world applications. Traditionally; to build a classifier; a user firstneeds to collect a set of training examples/instances that are labeled with predefinedclasses. A classification algorithm is then applied to the training data to build a classifier thatis subsequently employed to assign the predefined classes to test instances (for evaluation)or future instances (for application)[1]. In the past three decades; many classificationtechniques; such as Support Vector Machines (SVM)[2]; Neural Network (NN)[3]; RuleLearning [9]; Naıve Bayesian (NB)[5]; K-Nearest Neighbour (KNN)[6]; Decision Tree [4];have been proposed. In this chapter; we focus on rule learning; also called rule-basedclassification. Rule learning is valuable due to the following advantages.,*,2014,5
Hub-accelerator: Fast and exact shortest path computation in large social networks,Ruoming Jin; Ning Ruan; Bo You; Haixun Wang,Abstract: Shortest path computation is one of the most fundamental operations for managingand analyzing large social networks. Though existing techniques are quite effective forfinding the shortest path on large but sparse road networks; social graphs have quitedifferent characteristics: they are generally non-spatial; non-weighted; scale-free; and theyexhibit small-world properties in addition to their massive size. In particular; the existence ofhubs; those vertices with a large number of connections; explodes the search space; makingthe shortest path computation surprisingly challenging. In this paper; we introduce a set ofnovel techniques centered around hubs; collectively referred to as the Hub-Acceleratorframework; to compute the k-degree shortest path (finding the shortest path between twovertices if their distance is within k). These techniques enable us to significantly reduce …,arXiv preprint arXiv:1305.0507,2013,5
Mmis07; 08: mining multiple information sources workshop report,Xingquan Zhu; Ruoming Jin; Yuri Breitbart; Gagan Agrawal,Abstract In this report; we summarize the research issues; contents; and outcomes of the tworecent workshops on Mining Multiple Information Sources (MMIS-07; 08) collocated with the13th and the 14th ACM SIGKDD International Conference on Knowledge Discovery andData Mining (KDD-07 and KDD-08). We first summarize the research issues and topicswhich in workshop co-chairs' view are the major challenges for mining multiple informationsources. Then we briefiy introduce the content of the contributed papers in two years'program; along with the introduction to three keynote talks given by the invited speakers.,ACM SIGKDD Explorations Newsletter,2008,5
Data Streams,Charu C Aggarwal,*,*,2007,5
Using Data Mining Techniques to Learn Layouts of Flat-File Biological Datasets,Kaushik Sinha; Xuan Zhang; Ruoming Jin; Gagan Agrawal,One of the major problems in biological data integration is that many data sources are storedas atlasses; with a variety of different layouts. Integrating data from such sources can be anextremely time-consuming task. We have been developing data mining techniques to helplearn the layout of a dataset in a semi-automatic way. In this paper; we focus on the problemof identifying delimiters for optional fields. Since these fields do not occur in every record;frequency based methods are not able to identify the corresponding delimiters. We present amethod which uses contrast analysis on the frequency of sequences to identify suchdelimiters and help complete the layout descriptions. We demonstrate the effectiveness ofthis technique using three atlasses biological datasets.,Bioinformatics and Bioengineering; 2005. BIBE 2005. Fifth IEEE Symposium on,2005,5
Learning layouts of biological datasets semi-automatically,Kaushik Sinha; Xuan Zhang; Ruoming Jin; Gagan Agrawal,Abstract A key challenge associated with the existing approaches for data integration andworkflow creation for bioinformatics is the effort required to integrate a new data source. Asnew data sources emerge; and data formats and contents of existing data sources evolve;wrapper programs need to be written or modified. This can be extremely time consuming;tedious; and error-prone. This paper describes our semi-automatic approach for learning thelayout of a flat-file bioinformatics dataset. Our approach involves three key steps. The firststep is to use a number of heuristics to infer the delimiters used in the program. Specifically;we have developed a metric that uses information on the frequency and starting position ofsequences. Based on this metric; we are able to find a superset of delimiters; and then wecan seek user input to eliminate the incorrect ones. Our second step involves generating …,International Workshop on Data Integration in the Life Sciences,2005,5
Impact of data distribution; level of parallelism; and communication frequency on parallel data cube construction,Ge Yang; Ruoming Jin; Gagan Agrawal,Data cube construction is a commonly used operation in data warehouses. Because of thevolume of data that is stored and analyzed in a data warehouse and the amount ofcomputation involved in data cube construction; it is natural to consider parallel machines forthis operation. We have developed a set of parallel algorithms for data cube constructionusing a new data structure called aggregation tree. Our experience has shown that anumber of performance trade-offs arise in developing a parallel data cube implementation.We focus on three important issues; which are:(1) data distribution; ie; how the original arrayis distributed among the processors;(2) level of parallelism; ie; what parts of the computationare parallelized and sequentialized; and (3) frequency of communication; ie; does theimplementation require frequent interprocessor communication (and less memory) or less …,Parallel and Distributed Processing Symposium; 2003. Proceedings. International,2003,5
Mining dual networks: Models; algorithms; and applications,Yubao Wu; Xiaofeng Zhu; Li Li; Wei Fan; Ruoming Jin; Xiang Zhang,Abstract Finding the densest subgraph in a single graph is a fundamental problem that hasbeen extensively studied. In many emerging applications; there exist dual networks. Forexample; in genetics; it is important to use protein interactions to interpret geneticinteractions. In this application; one network represents physical interactions among nodes;for example; protein--protein interactions; and another network represents conceptualinteractions; for example; genetic interactions. Edges in the conceptual network are usuallyderived based on certain correlation measure or statistical test measuring the strength of theinteraction. Two nodes with strong conceptual interaction may not have direct physicalinteraction. In this article; we propose the novel dual-network model and investigate theproblem of finding the densest connected subgraph (DCS); which has the largest density …,ACM Transactions on Knowledge Discovery from Data (TKDD),2016,4
Block interaction: a generative summarization scheme for frequent patterns,Ruoming Jin; Yang Xiang; Hui Hong; Kun Huang,Abstract Frequent pattern mining is an essential tool in the data miner's toolbox; with dataapplications running the gamut from itemsets; sequences; trees; to graphs and topologicalstructures. Despite its importance; a major issue has clouded the frequent pattern miningmethodology: the number of frequent patterns can easily become too large to be analyzedand used. Though many efforts have tried to tackle this issue; it remains to be an openproblem. In this paper; we propose a novel block-interaction model to answer this call. Thismodel can help summarize a collection of frequent itemsets and provide accurate supportinformation using only a small number of frequent itemsets. At the heart of our approach is aset of core blocks; each of which is the Cartesian product of a frequent itemset and itssupport transactions. Those core blocks interact with each other through two basic …,Proceedings of the ACM SIGKDD Workshop on Useful Patterns,2010,4
A Tree-based Framework for Difference Summarization,Ruoming Jin; Yuri Breitbart; Rong Li,Understanding the differences between two datasets is a fundamental data mining questionand is also ubiquitously important across many real world scientific applications. In thispaper; we propose a tree-based framework to provide a parsimonious explanation of thedifference between two distributions based on rigorous two-sample statistical test. Wedevelop two efficient approaches. The first one is a dynamic programming approach thatfinds a minimal number of data subsets that describe the difference between two data sets.The second one is a greedy approach that approximates the dynamic programmingapproach. We employ the well-known Friedman's MST (minimal spanning tree) statistics fortwo-sample statistical tests in our summarization tree construction; and develop noveltechniques to speedup its computational procedure. We performed a detailed …,Data Mining; 2009. ICDM'09. Ninth IEEE International Conference on,2009,4
A sparsification approach for temporal graphical model decomposition,Ning Ruan; Ruoming Jin; Victor E Lee; Kun Huang,Temporal causal modeling can be used to recover the causal structure among a group ofrelevant time series variables. Several methods have been developed to explicitly constructtemporal causal graphical models. However; how to best understand and conceptualizethese complicated causal relationships is still an open problem. In this paper; we propose adecomposition approach to simplify the temporal graphical model. Our method clusters timeseries variables into groups such that strong interactions appear among the variables withineach group and weak (or no) interactions exist for cross-group variable pairs. Specifically;we formulate the clustering problem for temporal graphical models as a regression-coefficient sparsification problem and define an interesting objective function whichbalances the model prediction power and its cluster structure. We introduce an iterative …,Data Mining; 2009. ICDM'09. Ninth IEEE International Conference on,2009,4
A framework to support multiple query optimization for complex mining tasks,Ruoming Jin; Kaushik Sinha; Gagan Agrawal,Abstract With an increasing use of data mining tools and techniques; we envision that aKnowledge Discovery and Data Mining System (KDDMS) will have to support and optimizefor the following scenarios: 1) Sequence of Queries: A user may analyze one or moredatasets by issuing a sequence of related complex mining queries; and 2) MultipleSimultaneous Queries: Several users may be analyzing a set of datasets concurrently; andmay issue related complex queries. This paper presents a systematic mechanism tooptimize for the above cases; targetting the class of mining queries involving frequentpattern mining on one or multiple datasets. We present a system architecture and proposenew algorithms for this purpose. We show the design of a knowledgeable cache which canstore the past query results from queries on multiple datasets. We present algorithms …,Proceedings of the 6th international workshop on Multimedia data mining: mining integrated media and complex data,2005,4
Combining distributed memory and shared memory parallelization for data mining algorithms,Ruoming Jin; Gagan Agrawal,ABSTRACT In this paper; we focus on using a cluster of SMPs for scalable data mining. Wehave developed distributed memory and shared memory parallelization techniques that areapplicable to a number of common data mining algorithms. These techniques areincorporated in a middleware called FREERIDE (FRamework for Rapid Implementations ofDatamining Engines). We present experimental evaluation of our techniques and frameworkusing apriori association mining; k-means clustering; and a decision tree algorithm. Weachieve excellent speedups for apriori and k-means; and good distributed memory speedupfor decision tree construction. Despite using a common set of techniques and a middlewarewith a high-level interface; the speedups we achieve compare well against the reportedperformance from stand-alone implementations of individual parallel data mining …,HPDM: High Performance; Pervasive; and Data Stream Mining 6th International Workshop on High Performance Data Mining: Pervasive and Data Stream Mining (HPDM: PDS’03). In conjunction with Third International SIAM Conference on Data Mining; San Francisco; CA,2003,4
Efficient and exact local search for random walk based top-k proximity query in large graphs,Yubao Wu; Ruoming Jin; Xiang Zhang,Top-$ k $ proximity query in large graphs is a fundamental problem with a wide range ofapplications. Various random walk based measures have been proposed to measure theproximity between different nodes. Although these measures are effective; efficientlycomputing them on large graphs is a challenging task. In this paper; we develop an efficientand exact local search method; FLoS (Fast Local Search); for top-$ k $ proximity query inlarge graphs. FLoS guarantees the exactness of the solution. Moreover; it can be applied toa variety of commonly used proximity measures. FLoS is based on the no local optimumproperty of proximity measures. We show that many measures have no local optimum.Utilizing this property; we introduce several operations to manipulate transition probabilitiesand develop tight lower and upper bounds on the proximity values. The lower and upper …,IEEE Transactions on Knowledge and Data Engineering,2016,3
Outsourcing shortest distance computing with privacy protection,Jun Gao; Jeffrey Xu Yu; Ruoming Jin; Jiashuai Zhou; Tengjiao Wang; Dongqing Yang,Abstract With the advent of cloud computing; it becomes desirable to outsource graphs intocloud servers to efficiently perform complex operations without compromising their sensitiveinformation. In this paper; we take the shortest distance computation as a case to investigatethe technique issues in outsourcing graph operations. We first propose a parameter-free;edge-based 2-HOP delegation security model (shorten as 2-HOP delegation model); whichcan greatly reduce the chances of the structural pattern attack and the graph reconstructionattack. We then transform the original graph into a link graph G_l kept locally and a set ofoutsourced graphs\mathcal G _o. Our objectives include (i) ensuring each outsourced graphmeeting the requirement of 2-HOP delegation model;(ii) making shortest distance queries beanswered using G_l and\mathcal G _o;(iii) minimizing the space cost of G_l. We devise a …,The VLDB Journal,2013,3
A system for relational keyword search over deep Web data sources,Fan Wang; Gagan Agrawal; RM Jin,ABSTRACT Increasingly; many data sources appear as online databases; hidden behindquery forms; thus forming what is referred to as the deep web. It is desirable to have a toolthat can provide keyword search functionality on such data sources. However; to providesuch functionality; we need to address the following challenges. First; we only know queryschemas of deep web data sources and the real content of the backend databases is hiddenin web servers. Second; in most cases; no single database can provide all desired data; andmany relationships between keywords of interest can only be derived by querying acrossmultiple deep web data sources. Third; deep web data sources are often inter-dependent oneach other. This implies that multiple data sources need to be queried in an intelligent order.Fourth; unlike most traditional databases; there is much data redundancy in deep web …,*,2008,3
Graph and topological structure mining on scientific articles,Fan Wang; Ruoming Jin; Gagan Agrawal; Helen Piontkivska,In this paper; we investigate a new approach for literature mining. We use frequent subgraphmining; and its generalization topological structure mining; for finding interestingrelationships between gene names and other key biological terms from the text of scientificarticles. We show how we can find keywords of interest and represent them as nodes of thegraphs. We also propose several methods for inserting edges between these nodes. Ourstudy initially focused on comparing: 1) different methods for constructing edges; and 2)patterns found from sub-graph mining and topological structure mining. Subsequently; weanalyzed several frequent topological minors reported by our experiments; and explainedtheir scientific significance. Overall; our study shows the following. First; a simple method ofconstructing edges; which is based on sliding windows; seems to provide the best results …,Bioinformatics and Bioengineering; 2007. BIBE 2007. Proceedings of the 7th IEEE International Conference on,2007,3
Assigning schema labels using ontology and hueristics,Xuan Zhang; Ruoming Jin; Gagan Agrawal,Bioinformatics data is growing at a phenomenal rate. Besides the exponential growth ofindividual databases; the number of data depositories is increasing too. Because of thecomplexity of the biological concepts; bioinformatics data usually has complex datastructures and cannot be easily captured with relational model. As a result; various flat-fileformats have been used. Although easy for human interpretation; flat-file formats lack ofstandards and are hard to be recognized automatically. As a result; manually written parsersare widely used to extract data from them. This has limited the readiness of the data for dataconsuming programs; such as integration systems. This paper presents a data mining basedapproach for automatically assigning schema labels to the attributes in a flat-file biologicaldataset. In conjunction with our prior work on semi-automatically identifying the delimiters …,BioInformatics and BioEngineering; 2006. BIBE 2006. Sixth IEEE Symposium on,2006,3
Compiler and runtime support for shared memory parallelization of data mining algorithms,Xiaogang Li; Ruoming Jin; Gagan Agrawal,Abstract Data mining techniques focus on finding novel and useful patterns or models fromlarge datasets. Because of the volume of the data to be analyzed; the amount of computationinvolved; and the need for rapid or even interactive analysis; data mining applicationsrequire the use of parallel machines. We have been developing compiler and runtimesupport for developing scalable implementations of data mining algorithms. Our workencompasses shared memory parallelization; distributed memory parallelization; andoptimizations for processing disk-resident datasets. In this paper; we focus on compiler andruntime support for shared memory parallelization of data mining algorithms. We havedeveloped a set of parallelization techniques that apply across algorithms for a variety ofmining tasks. We describe the interface of the middleware where these techniques are …,International Workshop on Languages and Compilers for Parallel Computing,2002,3
A deep embedding model for co-occurrence learning,Yelong Shen; Ruoming Jin; Jianshu Chen; Xiaodong He; Jianfeng Gao; Li Deng,Co-occurrence Data is a common and important information source in many areas; such asthe word co-occurrence in the sentences; friends co-occurrence in social networks andproducts co-occurrence in commercial transaction data; etc; which contains rich correlationand clustering information about the items. In this paper; we study co-occurrence data usinga general energy-based probabilistic model; and we analyze three different categories ofenergy-based model; namely; the L1; L2 and Lk models; which are able to capture differentlevels of dependency in the co-occurrence data. We also discuss how several typicalexisting models are related to these three types of energy models; including the Fully VisibleBoltzmann Machine (FVBM)(L2); Matrix Factorization (L2); Log-BiLinear (LBL) models (L2);and the Restricted Boltzmann Machine (RBM) model (Lk). Then; we propose a Deep …,Data Mining Workshop (ICDMW); 2015 IEEE International Conference on,2015,2
Systems; methods and software for computing reachability in large graphs,*,Embodiments disclosed herein provide systems and methods for scaling reachabilitycomputations on relatively large graphs. In an embodiment; a method provides for scalingreachability computations on relatively large graphs; the method comprising; identifying aninitial graph comprising a plurality of vertices and a plurality of edges; processing at least aportion of the plurality of vertices and at least a portion of the plurality of edges to generate aplurality of reachability indices for the at least a portion of the plurality of vertices; andgenerating a backbone graph comprising a scaled-down version of the initial graph; basedat least in part on at least one of the plurality of reachability indices.,*,2015,2
Cost-based query optimization for complex pattern mining on multiple databases,Ruoming Jin; Dave Fuhry; Abdulkareem Alali,Abstract For complex data mining queries; query optimization issues arise; similar to thosefor the traditional database queries. However; few works have applied the cost-based queryoptimization; which is the key technique in optimizing traditional database queries; oncomplex mining queries. In this work; we develop a cost-based query optimizationframework to an important collection of data mining queries; ie frequent pattern miningacross multiple databases. Specifically; we make the following contributions: 1) We presenta rich class of queries on mining frequent itemsets across multiple datasets supported by aSQL-based mechanism. 2) We present an approach to enumerate all possible query plansfor the mining queries; and develop a dynamic programming approach and a branch-and-bound approach based on the enumeration algorithm to find optimal query plans with the …,Proceedings of the 11th international conference on Extending database technology: Advances in database technology,2008,2
Proceedings of the 2004 SIAM International Conference on Data Mining,Michael W Berry; Umeshwar Dayal; Chandrika Kamath; David Skillicorn,The Fourth SIAM International Conference on Data Mining continues the tradition ofproviding an open forum for the presentation and discussion of innovative algorithms as wellas novel applications of data mining. This is reflected in the talks by the four keynotespeakers; who will discuss data usability issues in systems for data mining in science andengineering (Graves); issues raised by new technologies that generate biological data(Page); ways to find complex structured patterns in linked data (Senator); and advances inBayesian inference techniques (Bishop).,*,2004,2
A compilation framework for distributed memory parallelization of data mining algorithms,Xiaogang Li; Ruoming Jin; Gagan Agrawal,With the availability of large datasets in a variety of scientific and commercial domains; datamining has emerged as an important area within the last decade. Data mining techniquesfocus on finding novel and useful patterns or models from large datasets. Because of thevolume of the data to be analyzed; the amount of computation involved; and the need forrapid or even interactive analysis; data mining applications require the use of parallelmachines. We believe that parallel compilation technology can be used for providing high-level language support for carrying out data mining implementations. Our study of a varietyof popular data mining techniques has shown that they can be parallelized in a similarfashion. In our previous work; we have developed a middleware system that exploits thissimilarity to support distributed memory parallelization and execution on disk-resident …,Parallel and Distributed Processing Symposium; 2003. Proceedings. International,2003,2
Compiler and middleware support for scalable data mining,Gagan Agrawal; Ruoming Jin; Xiaogang Li,Abstract The parallelizing compiler community has traditionally focused its efforts onscientific applications. This paper gives an overview of a compiler/runtime project targetingparallel and scalable execution of data mining algorithms. To the best of our knowledge; thisis the first project with such a focus. Data mining is the process of analyzing large datasetsfor extracting novel and useful patterns or models. Though a lot of effort has been put intodeveloping parallel algorithms for data mining tasks; the expertise and effort currentlyrequired in implementing; maintaining; and performance tuning a parallel data miningapplication is an impediment in the wide use of parallel computers for data mining. We havedeveloped a data parallel dialect of Java that can be used for expressing common datamining algorithms at a high level. Our compiler generates a middleware specification from …,International Workshop on Languages and Compilers for Parallel Computing,2001,2
Frequent subgraph summarization with error control,Zheng Liu; Ruoming Jin; Hong Cheng; Jeffrey Xu Yu,Abstract Frequent subgraph mining has been an important research problem in theliterature. However; the huge number of discovered frequent subgraphs becomes thebottleneck for exploring and understanding the generated patterns. In this paper; wepropose to summarize frequent subgraphs with an independence probabilistic model; withthe goal to restore the frequent subgraphs and their frequencies accurately from a compactsummarization model. To achieve a good summarization quality; our summarizationframework allows users to specify an error tolerance σ; and our algorithms will discover ksummarization templates in a top-down fashion and keep the frequency restoration errorwithin σ. Experiments on real graph datasets show that our summarization framework caneffectively control the frequency restoration error within 10% with a concise …,International Conference on Web-Age Information Management,2013,1
Network backbone discovery using edge clustering,Ning Ruan; Ruoming Jin; Guan Wang; Kun Huang,Abstract: In this paper; we investigate the problem of network backbone discovery. Incomplex systems; a" backbone" takes a central role in carrying out the system functionalityand carries the bulk of system traffic. It also both simplifies and highlight underlyingnetworking structure. Here; we propose an integrated graph theoretical and informationtheoretical network backbone model. We develop an efficient mining algorithm based onKullback-Leibler divergence optimization procedure and maximal weight connectedsubgraph discovery procedure. A detailed experimental evaluation demonstrates both theeffectiveness and efficiency of our approach. The case studies in the real world domainfurther illustrates the usefulness of the discovered network backbones. Subjects: Social andInformation Networks (cs. SI); Data Structures and Algorithms (cs. DS) Cite as: arXiv …,arXiv preprint arXiv:1202.1842,2012,1
New techniques for efficiently discovering frequent patterns,Ruoming Jin,Abstract Because of its theoretical and practical importance; the field of frequent patternmining has been and remain to be one of the most active research area in KDD. In thisdissertation; we study three different problems in frequent pattern mining; miningmultipledatasets; mining streaming data; and mining large-scale structures from graphdatasets. Our study has not only extended the breadth of frequent pattern mining; but alsobrought new techniques and algorithms into this field. Specifically; our contributions are asfollows. 1. Mining Multiple Datasets: We develop a systematic approach to generate efficientquery plans for a single mining query across multiple datasets. We also propose methods tosimultaneously optimize multiple such queries and utilize the past mining results in a query-intensive KDD environment. Our experimental results have shown a speedup up to two …,*,2005,1
Using tiling to scale parallel data cube construction,Ruoming Jin; Karthik Vaidyanathan; Ge Yang; Gagan Agrawal,Data cube construction is a commonly used operation in data warehouses. Because of thevolume of data that is stored and analyzed in a data warehouse and the amount ofcomputation involved in data cube construction; it is natural to consider parallel machines forthis operation. Also; for both sequential and parallel data cube construction; effectively usingthe main memory is an important challenge. In our prior work; we have developed parallelalgorithms for this problem. We show how sequential and parallel data cube constructionalgorithms can be further scaled to handle larger problems; when the memory requirementscould be a constraint. This is done by tiling the input and output arrays on each node. Weaddress the challenges in using tiling while still maintaining the other desired properties of adata cube construction algorithm; which are; using minimal parents; and achieving …,Parallel Processing; 2004. ICPP 2004. International Conference on,2004,1
Parallel data cube construction: Algorithms; theoretical analysis; and experimental evaluation,Ruoming Jin; Ge Yang; Gagan Agrawal,Abstract Data cube construction is a commonly used operation in data warehouses.Because of the volume of data that is stored and analyzed in a data warehouse and theamount of computation involved in data cube construction; it is natural to consider parallelmachines for this operation. This paper presents two new algorithms for parallel data cubeconstruction; along with their theoretical analysis and experimental evaluation. Our work isbased upon a new data-structure; called the aggregation tree; which results in minimallybounded memory requirements. An aggregation tree is parameterized by the ordering ofdimensions. We prove that the same ordering of the dimensions minimizes both thecomputational and communication requirements; for both the algorithms. We also describe amethod for partitioning the initial array; which again minimizes the communication volume …,International Conference on High-Performance Computing,2003,1
Design and evaluation of a high-level interface for data mining,Ruoming Jin; Gagan Agrawal,Abstract This paper presents a case study in developing an application class specific high-level interface for shared memory parallel programming. The application class we focus onis data mining. With the availability of large datasets in areas like bioinformatics; medicalinformatics; scientific data analysis; financial analysis; telecommunications; retailing; andmarketing; data mining tasks have become an important application class for highperformance computing. Our study of a number of common data mining algorithms hasshown that the same set of parallelization techniques can be applied to all of them. Toexploit this; we have developed a reduction-object based interface to rapidly specify ashared memory parallel data mining algorithm. The set of parallelization techniques wetarget include full replication; optimized full locking; and cachesensitive locking. We show …,ipdps,2002,1
Mining Data Streams,Ruoming Jin,The need to understand the enormous amount of data being generated every day in a timelyfashion has given rise to a new data processing model—data stream processing. In this newmodel; data arrives in the form of continuous; high-volume; fast; and time-varying streams;and the processing of such streams entails a near real-time constraint. Many importantapplications; ranging from network security; sensor data processing; to stock analysis;climate monitoring [12; 3; 26]; are a part of the data stream model.,Ohio State University; Columbus; OH,*,1
Parallelizing Data Intensive Reductions on SMP Clusters?,Ruoming Jin; Gagan Agrawal,Data intensive applications have received much attention in recent years. We consider twoseparate sets of applications that fall in this class. They are; parallel data mining; and codesthat perform processing over scienti c data repositories. Optimizing data intensive parallelapplications requires paying careful attention to computations; as well as data accesses.Recent technological developments have made cluster of SMPs as an increasingly popularclass of parallel architectures. By connecting one or more disk to each SMP workstation; acluster of SMPs can be con gured for data intensive applications. Such a cluster of SMPswith an associated disk farm can be built in an a ordable and exible fashion; and o ers highpeak performance for data intensive applications. However; e ectively using such a conguration requires exploiting both shared memory and distributed memory parallelism …,*,*,1
Privacy-aware smart city: A case study in collaborative filtering recommender systems,Feng Zhang; Victor E Lee; Ruoming Jin; Saurabh Garg; Kim-Kwang Raymond Choo; Michele Maasberg; Lijun Dong; Chi Cheng,Abstract Ensuring privacy in recommender systems for smart cities remains a researchchallenge; and in this paper we study collaborative filtering recommender systems forprivacy-aware smart cities. Specifically; we use the rating matrix to establish connectionsbetween a privacy-aware smart city and k k-coRating; a novel privacy-preserving rating datapublishing model. First; we model privacy concerns in a smart city as the problem of privacy-preserving collaborative filtering recommendation. Then; we introduce k k-coRating toaddress privacy concerns in published rating matrices; by filling the null ratings withpredicted scores. This allows us to mask the original ratings to preserve k k-anonymity-likedata privacy; and enhance data utility (quantified using prediction accuracy in this paper).We show that the optimal k k-coRated mapping is an NP-hard problem and design an …,Journal of Parallel and Distributed Computing,2018,*
System and method for real-time graph-based recommendations,*,Systems and methods for generating real-time; personalized recommendations aredisclosed. In one embodiment; a method operates upon an electronic data collectionorganized as a network of vertices and edge connections between the vertices. The methodprovides the recommendations includes iteratively traversing across edges that satisfysearch criteria to a new set of vertices and filtering each new set of vertices to satisfy thesearch criteria. At the conclusion of the traversing and filtering; a final set of verticesrepresents the recommended entities. In some embodiments; a control vector describes asequence of relationships between a requester and the items to be recommended. Themethod can assign scores to candidate recommendations and select the recommendationshaving the highest scores. Advantageously; the method provides flexibility and rapid …,*,2016,*
Leveraging a Graph-Powered; Real-Time Recommendation Engine to Create Rapid Business Value,Adam Anthony; Yu-Keng Shih; Ruoming Jin; Yang Xiang,Abstract Deployment of open source recommendation systems has been shown to be aneffective way to increase sale conversions on a variety of e-commerce sites. However; thereremains a large gap between deploying the core algorithm provided by these systems anddelivering an application-quality recommendation system; specifically tailored to addresscomplex and dynamically changing business needs. We will present a real-timerecommendation engine built on our graph data platform that provides the followingextensions to a basic recommendation model: True real-time recommendation algorithms:We provide a simple framework for customers to author and deploy real-timerecommendation algorithms with no pre-computation required. Streaming updates of userbehavior and product information: As quickly as data are generated; the recommendation …,Proceedings of the 10th ACM Conference on Recommender Systems,2016,*
Methods and systems for distributed graphical flight search,*,Methods and systems for real-time graphical search for airline flight itineraries that satisfypredetermined criteria (eg; place and time) using a distributed graph processing system aredisclosed. The advantages of the graphical method include: computational work is easilysplit across multiple processors for parallel processing; the resulting speed is appropriate forreal-time personalized search; the method naturally supports multi-segment routes up to anyuser-specified maximum; the method easily handles constraints or freedoms on connectionsbetween flights; such as connection time or transferring to another airport in the samemetropolis; and the method is efficient due to focusing only on viable flight segments.,*,2016,*
Methods and systems for distributed computation of graph data,*,Methods and systems for distributed computation of graph data permit edge collection andvertex collection; each to be partitioned among a plurality of computational units. In oneembodiment; the methods employ a two-phase computational cycle; which is repeated untilthe computation is complete. In a first phase; processing units process each active edge andvertex by doing the following: reading their current attribute values; executing programmedcomputational functions; updating edge attributes and sending data messages to vertices. Ina second phase; each vertex update processor processes each of its active vertices bydoing the following: reading its current attribute values and received data messages;executing a programmed computational function; and updating the vertex's attribute values.,*,2016,*
System and method for enhanced detection of fraudulent electronic transactions,*,Systems and methods for enhanced detection of fraudulent electronic transactions aredisclosed. In one embodiment; a system uses the ongoing stream of transactions toconstruct and maintain a dynamically evolving merchant relationship graph. When aproposed transaction is submitted to the system; the system computes a predicted likelihoodthat the given account would make a transaction with these characteristics with the givenmerchant. The graph is used to compute transitive relatedness between merchants whichmay be indirectly associated with one another; as well as to compute aggregate relatedness;when there are multiple avenues of relationship between two merchants.,*,2015,*
Method for the determination of scalable reachability,*,Embodiments disclosed herein provide systems and methods for scaling reachabilitycomputations on relatively large graphs. In an embodiment; a method provides for scalingreachability computations on relatively large graphs; the method comprising; identifying aninitial graph comprising a plurality of vertices and a plurality of edges; processing at least aportion of the plurality of vertices and at least a portion of the plurality of edges to generate aplurality of reachability indices for the at least a portion of the plurality of vertices; andgenerating a backbone graph comprising a scaled-down version of the initial graph; basedat least in part on at least one of the plurality of reachability indices.,*,2015,*
Limiting the Neighborhood: De-Small-World Network for Outbreak Prevention,Ruoming Jin; Yelong Shen; Lin Liu; Xue-wen Chen,Abstract: In this work; we study a basic and practically important strategy to help preventand/or delay an outbreak in the context of network: limiting the contact between individuals.In this paper; we introduce the average neighborhood size as a new measure for the degreeof being small-world and utilize it to formally define the desmall-world network problem. Wealso prove the NP-hardness of the general reachable pair cut problem and propose agreedy edge betweenness based approach as the benchmark in selecting the candidateedges for solving our problem. Furthermore; we transform the de-small-world networkproblem as an OR-AND Boolean function maximization problem; which is also an NP-hardness problem. In addition; we develop a numerical relaxation approach to solve theBoolean function maximization and the de-small-world problem. Also; we introduce the …,arXiv preprint arXiv:1305.0513,2013,*
Understanding and Utilizing the Influence of Social Networks on Health Care in YesiWell,Dejing Dou; Daniel Lowd; Jessica Greene; Brigitte Piniewski; Ruoming Jin; Xintao Wu; David Kil; Frances Shin,Motivation: Two thirds of the US population are now overweight or obese. This incurssignificant health risks and financial costs to society. Obesity and overweight; althoughmultifactorial; can largely be explained by the social and cultural spread of poor healthhabits such as lack of exercise; smoking; fast food consumption; and alcoholism spreadthrough communities; introducing and reinforcing harmful behaviors [1]. By the timebehaviors develop into diseases and individuals seek medical help; it is often too late toreverse the chronic poor health outcomes. Traditionally; support groups and other socialreinforcement approaches have been popular and effective in dealing with unhealthybehaviors including overweight. Of the factors associated with sustained weight loss one ofthe most important is continued intervention with frequent social contacts. Recent …,*,2010,*
We address the problem of prediction of data that is vertically partitioned; that is where local sites hold some of the attributes of all of the records. This situation is nat...,Sanguthevar Rajasekaran; Antonio Congiusta; Domenico Talia; Paolo Trunfio; Feng Gao; Mohammed J Zaki; Antonio J Plaza; Leonid Glimcher; Ruoming Jin; Gagan Agrawal; Ronaldo A Ferreira; Mehmet Koyutürk; Suresh Jagannathan; Ananth Grama; Sourav Mukherjee; Hillol Kargupta; Samee Ullah Khan; Ishfaq Ahmad,Distribution of data and computation allows for solving larger problems and executingapplications that are distributed in nature. The grid is a distributed computing infrastructurethat enables coordinated resource sharing within dynamic organizations consisting ofindividuals; institutions; and resources. The grid extends the distributed and parallelcomputing paradigms allowing for resource negotiation...,Journal of Parallel and Distributed Computing,2008,*
Mining Multiple Information Sources MMIS′ 08,Xingquan Zhu; Ruoming Jin; Yuri Breitbart,As data collection sources and channels continuous evolve; mining and correlatinginformation from multiple information sources has become a crucial step in data mining andknowledge discovery. On one hand; comparing patterns from different databases andunderstanding their relationships can be extremely beneficial for applications such asBioinformatics; Sensor Networking; and Business Intelligence. In particular; importantinformation such as pattern trends and evolving rules buried in each individual database;are very hard to discover by examining a single dataset only whereas comparatively miningmultiple databases will enable users to discover interesting patterns across a set of datacollections that would not have been possible otherwise. On the other hand; many datamining and data analysis tasks such as classification; regression; and clustering; can …,*,2008,*
First International Workshop on Mining Multiple Information Sources,Xingquan Zhu; Ruoming Jin; Gagan Agrawal,*,Proceedings of the 13th ACM SIGKDD international conference on Knowledge discovery and data mining,2007,*
Workshop Co-Chairs,Xingquan Zhu; Ruoming Jin; Gagan Agrawal,Recent developments in storage technology and network architectures have made itpossible and affordable for scientific institutes; commercial enterprises; and governmentagencies to gather and store data from multiple sources. The increasing globalization hasalso demanded that many business applications involve storing information atgeographically distributed locations for analysis. Examples include market baskettransaction data from different branches of a wholesale store; data collections of a particularbranch in different time periods; census data of different states in a particular year; and dataof a certain state in different years. For years; knowledge discovery and data mining (alsoreferred to as KDD) has proven to be crucial for discovering novel and actionable patternshidden in the data. Discovering patterns from multiple information sources provides a …,*,2007,*
Exploratory Tools for Follow-Up Studies to Microarray Experiments,Kaushik Sinha; Ruoming Jin; Gagan Agrawal; Helen Piontkivska,In this paper we present two different exploratory tools for data analysis following a genemicroarray experiment. The first tool is based on a novel data mining formulation; calledhypergraph mining. In the second tool; we provide a family of expectation based similaritymeasures between sets of genes or between a set and a single gene. We have evaluatedthese two tools using output from two different microarray studies. We showed how manyinteresting observations could be made using our tools; and how the results from the twotools were similar in many ways,BioInformatics and BioEngineering; 2006. BIBE 2006. Sixth IEEE Symposium on,2006,*
Runtime support for parallelizing data mining algorithms,Ruoming Jin; Gagan Agrawal,With recent technological advances; shared memory parallel machines have become morescalable; and offer large main memories and high bus bandwidths. They are emerging asgood platforms for data warehousing and data mining. In this paper; we focus on sharedmemory parallelization of data mining algorithms. We have developed a series oftechniques for parallelization of data mining algorithms; including full replication; full locking;fixed locking; optimized full locking; and cache-sensitive locking. Unlike previous work onshared memory parallelization of specific data mining algorithms; all of our techniques applyto a large number of common data mining algorithms. In addition; we propose a reduction-object based interface for specifying a data mining algorithm. We show how our runtimesystem can apply any of the technique we have developed starting from a common …,Data Mining and Knowledge Discovery: Theory; Tools; and Technology IV,2002,*
Session 1-I/O; Data-Intensive Computing-High Level Programming Methodologies for Data Intensive Computations,Gagan Agrawal; Renato Ferreira; Ruoming Jin; Joel Saltz,*,Lecture Notes in Computer Science,2000,*
FREERIDE-G: Supporting Applications that Mine Remote Data Repositories,Leonid Glimcher; Ruoming Jin; Gagan Agrawal,ABSTRACT Analysis of large geographically distributed scientific datasets; also referred toas distributed data-intensive science; has emerged as an important area in recent years. Anapplication that processes data from a remote repository needs to be broken into severalstages; including a data retrieval task at the data repository; a data movement task; and adata processing task at a computing site. Because of the volume of data that is involved andthe amount of processing; it is desirable that both the data repository and computing sitemay be clusters. This can further complicate the development of such data processingapplications. In this paper; we present a middleware; FREERIDE-G (FRamework for RapidImplementation of Datamining Engines in Grid); which support a high-level interface fordeveloping data mining and scientific data processing applications that involve data …,*,*,*
Compiling Data Intensive Applications with Spatial Coordinates,Renato Ferreira Gagan Agrawal; Ruoming Jin; Joel Saltz,*,*,*,*
Accurate One Pass Decision Tree Construction,Ruoming Jin; Anjan Goswami Gagan Agrawal,ABSTRACT In mining continuous data streams; one popular paradigm is using samplingand having a one-pass algorithm with probabilistic bound on the accuracy. A key applicationof this approach is in decision tree construction. A disadvantage; however; of an algorithmthat only achieves a probabilistic bound is that there are no guarantees from the resultsobtained from a particular application of the algorithm. In this paper; we present an approachfor making one-pass decision tree construction more accurate. We present a new algorithmwhich attempts to determine; and mark as such; exact split points for nodes. This is done bycreating a confidence interval near the probabilistic split point for a node; and storing andpotentially reassigning samples that belong to this interval. The confidence intervals areconstructed using Hoeffding inequality; and can be shrunk as additional samples are …,*,*,*
DENSE COMPONENTS IN GRAPHS,Victor E Lee; Ning Ruan; Ruoming Jin; Charu Aggarwal,In almost any network; density is an indication of importance. Just as someone reading aroad map is interesting in knowing the location of the larger cities and towns; investigatorswho seek information from abstract graphs are often interested in the dense components ofthe graph. Depending on what properties are being modeled by the graph's vertices andedges; dense regions may indicate high degrees of interaction; mutual similarity and hencecollective characteristics; attractive forces; favorable environments; or critical mass. From atheoretical perspective; dense regions have many interesting properties. Dense componentsnaturally have small diameters (worst case shortest path between any two members).Routing within these components is rapid. A simple strategy also exists for global routing. Ifmost vertices belong to,*,*,*
The 4th International Workshop on Mining Multiple Information Sources (MMIS-10),Ruoming Jin; Xingquan Zhu; Haixun Wang; Zoran Obradovic,As data collection sources and channels continuous evolve; mining and correlating informationfrom multiple information sources has become a crucial step in data mining and knowledgediscovery. Several emerging fields and applications from healthcare informatics to environmentalsciences to social computing in particular call for data mining methodologies and approachesto deal with multi-source data. On one hand; comparing patterns from different databases andunderstanding their relationships can be extremely beneficial for these applications. On the otherhand; many data mining and data analysis tasks such as classification; regression; andclustering; can significantly improve their performance if information from different sources canbe properly integrated and leveraged … The aim of this workshop is to bring together data miningexperts to advance research on integrating and mining multiple information sources …,*,*,*
