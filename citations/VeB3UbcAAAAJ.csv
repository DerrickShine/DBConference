CrowdScreen: Algorithms for Filtering Data with Humans,Aditya Parameswaran; Hector Garcia-Molina; Hyunjung Park; Neoklis Polyzotis; Aditya Ramesh; Jennifer Widom,Abstract Given a large set of data items; we consider the problem of filtering them based ona set of properties that can be verified by humans. This problem is commonplace incrowdsourcing applications; and yet; to our knowledge; no one has considered the formaloptimization of this problem.(Typical solutions use heuristics to solve the problem.) Weformally state a few different variants of this problem. We develop deterministic andprobabilistic algorithms to optimize the expected cost (ie; number of questions) andexpected error. We experimentally show that our algorithms provide definite gains withrespect to other strategies. Our algorithms can be applied in a variety of crowdsourcingscenarios and can form an integral part of any query processor that uses humancomputation.,*,2011,193
So who won?: dynamic max discovery with the crowd,Stephen Guo; Aditya Parameswaran; Hector Garcia-Molina,Abstract We consider a crowdsourcing database system that may cleanse; populate; or filterits data by using human workers. Just like a conventional DB system; such a crowdsourcingDB system requires data manipulation functions such as select; aggregate; maximum;average; and so on; except that now it must rely on human operators (that for examplecompare two objects) with very different latency; cost and accuracy characteristics. In thispaper; we focus on one such function; maximum; that finds the highest ranked object or tuplein a set. In particularm we study two problems: given a set of votes (pairwise comparisonsamong objects); how do we select the maximum? And how do we improve our estimate byrequesting additional votes? We show that in a crowdsourcing DB system; the optimalsolution to both problems is NP-Hard. We then provide heuristic functions to select the …,Proceedings of the 2012 ACM SIGMOD International Conference on Management of Data,2012,142
Human-assisted graph search: it's okay to ask questions,Aditya Parameswaran; Anish Das Sarma; Hector Garcia-Molina; Neoklis Polyzotis; Jennifer Widom,Abstract We consider the problem of human-assisted graph search: given a directed acyclicgraph with some (unknown) target node (s); we consider the problem of finding the targetnode (s) by asking an omniscient human questions of the form" Is there a target node that isreachable from the current node?". This general problem has applications in many domainsthat can utilize human intelligence; including curation of hierarchies; debugging workflows;image segmentation and categorization; interactive search and filter synthesis. To ourknowledge; this work provides the first formal algorithmic study of the optimization of humancomputation for this problem. We study various dimensions of the problem space; providingalgorithms and complexity results. We also compare the performance of our algorithmagainst other algorithms; for the problem of webpage categorization on a real taxonomy …,Proceedings of the VLDB Endowment,2011,131
Answering queries using humans; algorithms and databases,Aditya Parameswaran; Neoklis Polyzotis,For some problems; human assistance is needed in addition to automated (algorithmic)computation. In sharp contrast to existing data management approaches; where humaninput is either ad-hoc or is never used; we describe the design of the first declarativelanguage involving human-computable functions; standard relational operators; as well asalgorithmic computation. We consider the challenges involved in optimizing queries posedin this language; in particular; the tradeoffs between uncertainty; cost and performance; aswell as combination of human and algorithmic evidence. We believe that the vision laid outin this paper can act as a road-map for a new area of data management research wherehuman computation is routinely used in data analytics.,*,2011,130
Deco: Declarative Crowdsourcing,Aditya Parameswaran; Hyunjung Park; Hector Garcia-Molina; Neoklis Polyzotis; Jennifer Widom,Abstract Crowdsourcing enables programmers to incorporate" human computation" as abuilding block in algorithms that cannot be fully automated; such as text analysis and imagerecognition. Similarly; humans can be used as a building block in data-intensiveapplications--providing; comparing; and verifying data used by applications. Building uponthe decades-long success of declarative approaches to conventional data management; weuse a similar approach for data-intensive applications that incorporate humans. Specifically;declarative queries are posed over stored relational data as well as data computed on-demand from the crowd; and the underlying system orchestrates the computation of queryanswers. We present Deco; a database system for declarative crowdsourcing. We describeDeco's data model; query language; and our prototype. Deco's data model was designed …,*,2012,92
Evaluating the crowd with confidence,Manas Joglekar; Hector Garcia-Molina; Aditya Parameswaran,Abstract Worker quality control is a crucial aspect of crowdsourcing systems; typicallyoccupying a large fraction of the time and money invested on crowdsourcing. In this work;we devise techniques to generate confidence intervals for worker error rate estimates;thereby enabling a better evaluation of worker quality. We show that our techniquesgenerate correct confidence intervals on a range of real-world datasets; and demonstratewide applicability by using them to evict poorly performing workers; and provide confidenceintervals on the accuracy of the answers.,Proceedings of the 19th ACM SIGKDD international conference on Knowledge discovery and data mining,2013,80
Fuzzy Joins Using MapReduce,Foto N Afrati; Anish Das Sarma; David Menestrina; Aditya Parameswaran; Jeffrey D Ullman,Fuzzy/similarity joins have been widely studied in the research community and extensivelyused in real-world applications. This paper proposes and evaluates several algorithms forfinding all pairs of elements from an input set that meet a similarity threshold. Thecomputation model is a single MapReduce job. Because we allow only one MapReduceround; the Reduce function must be designed so a given output pair is produced by only onetask; for many algorithms; satisfying this condition is one of the biggest challenges. We breakthe cost of an algorithm into three components: the execution cost of the mappers; theexecution cost of the reducers; and the communication cost from the mappers to reducers.The algorithms are presented first in terms of Hamming distance; but extensions to editdistance and Jaccard distance are shown as well. We find that there are many different …,*,2012,78
Active Sampling for Entity Matching,Kedar Bellare; Suresh Iyengar; Aditya Parameswaran; Vibhor Rastogi,Abstract In entity matching; a fundamental issue while training a classifier to label pairs ofentities as either duplicates or non-duplicates is the one of selecting informative trainingexamples. Although active learning presents an attractive solution to this problem; previousapproaches minimize the misclassification rate (0-1 loss) of the classifier; which is anunsuitable metric for entity matching due to class imbalance (ie; many more non-duplicatepairs than duplicate pairs). To address this; a recent paper [1] proposes to maximize recall ofthe classifier under the constraint that its precision should be greater than a specifiedthreshold. However; the proposed technique requires the labels of all n input pairs in theworst-case. Our main result is an active learning algorithm that approximately maximizesrecall of the classifier while respecting a precision constraint with provably sub-linear …,*,2012,68
Datahub: Collaborative data science & dataset version management at scale,Anant Bhardwaj; Souvik Bhattacherjee; Amit Chavan; Amol Deshpande; Aaron J Elmore; Samuel Madden; Aditya G Parameswaran,Abstract: Relational databases have limited support for data collaboration; where teamscollaboratively curate and analyze large datasets. Inspired by software version controlsystems like git; we propose (a) a dataset version control system; giving users the ability tocreate; branch; merge; difference and search large; divergent collections of datasets; and (b)a platform; DataHub; that gives users the ability to perform collaborative data analysisbuilding on this version control system. We outline the challenges in providing datasetversion control at scale.,arXiv preprint arXiv:1409.0798,2014,67
Synthesizing view definitions from data,Anish Das Sarma; Aditya Parameswaran; Hector Garcia-Molina; Jennifer Widom,Abstract Given a database instance and a corresponding view instance; we address theview definitions problem (VDP): Find the most succinct and accurate view definition; whenthe view query is restricted to a specific family of queries. We study the tradeoffs amongsuccintness; level of approximation; and the family of queries through algorithms andcomplexity results. For each family of queries; we address three variants of the VDP:(1) Doesthere exist an exact view definition; and if so find it.(2) Find the best view definition; ie; oneas close to the input view instance as possible; and as succinct as possible.(3) Find anapproximate view definition that satisfies an input approximation threshold; and is assuccinct as possible.,Proceedings of the 13th International Conference on Database Theory,2010,66
Recommendation systems with complex constraints: A course recommendation perspective,Aditya Parameswaran; Petros Venetis; Hector Garcia-Molina,Abstract We study the problem of making recommendations when the objects to berecommended must also satisfy constraints or requirements. In particular; we focus oncourse recommendations: the courses taken by a student must satisfy requirements (eg; taketwo out of a set of five math courses) in order for the student to graduate. Our work is done inthe context of the CourseRank system; used by students to plan their academic program atStanford University. Our goal is to recommend to these students courses that not only helpsatisfy constraints; but that are also desirable (eg; popular or taken by similar students). Wedevelop increasingly expressive models for course requirements; and present a variety ofschemes for both checking if the requirements are satisfied; and for makingrecommendations that take into account the requirements. We show that some types of …,ACM Transactions on Information Systems (TOIS),2011,65
Deco: A system for declarative crowdsourcing,Hyunjung Park; Hector Garcia-Molina; Richard Pang; Neoklis Polyzotis; Aditya Parameswaran; Jennifer Widom,Abstract Deco is a system that enables declarative crowdsourcing: answering SQL queriesposed over data gathered from the crowd as well as existing relational data. Decoimplements a novel push-pull hybrid execution model in order to support a flexible datamodel and a precise query semantics; while coping with the combination of latency;monetary cost; and uncertainty of crowdsourcing. We demonstrate Deco using twocrowdsourcing platforms: Amazon Mechanical Turk and an in-house platform; to show howDeco provides a convenient means of collecting and querying crowdsourced data.,Proceedings of the VLDB Endowment,2012,63
Towards the web of concepts: Extracting concepts from large datasets,Aditya Parameswaran; Hector Garcia-Molina; Anand Rajaraman,Abstract Concepts are sequences of words that represent real or imaginary entities or ideasthat users are interested in. As a first step towards building a web of concepts that will formthe backbone of the next generation of search technology; we develop a novel technique toextract concepts from large datasets. We approach the problem of concept extraction fromcorpora as a market-basket problem; adapting statistical measures of support andconfidence. We evaluate our concept extraction algorithm on datasets containing data froma large number of users (eg; the AOL query log data set); and we show that a high-precisionconcept set can be extracted.,Proceedings of the VLDB Endowment,2010,53
SeeDB: efficient data-driven visualization recommendations to support visual analytics,Manasi Vartak; Sajjadur Rahman; Samuel Madden; Aditya Parameswaran; Neoklis Polyzotis,Abstract Data analysts often build visualizations as the first step in their analytical workflow.However; when working with high-dimensional datasets; identifying visualizations that showrelevant or desired trends in data can be laborious. We propose S ee DB; a visualizationrecommendation engine to facilitate fast visual analysis: given a subset of data to be studied;S ee DB intelligently explores the space of visualizations; evaluates promising visualizationsfor trends; and recommends those it deems most" useful" or" interesting". The two majorobstacles in recommending interesting visualizations are (a) scale: evaluating a largenumber of candidate visualizations while responding within interactive time scales; and (b)utility: identifying an appropriate metric for assessing interestingness of visualizations. Forthe former; S ee DB introduces pruning optimizations to quickly identify high-utility …,Proceedings of the VLDB Endowment,2015,49
Crowdsourced data management: Industry and academic perspectives,Adam Marcus; Aditya Parameswaran,Abstract Crowdsourcing and human computation enable organizations to accomplish tasksthat are currently not possible for fully automated techniques to complete; or require moreflexibility and scalability than traditional employment relationships can facilitate. In the areaof data processing; companies have benefited from crowd workers on platforms such asAmazon's Mechanical Turk or Upwork to complete tasks as varied as content moderation;web content extraction; entity resolution; and video/audio/image processing. Severalacademic researchers from diverse areas ranging from the social sciences to computerscience have embraced crowdsourcing as a research area; resulting in algorithms andsystems that improve crowd work quality; latency; or cost. Given the relative nascence of thefield; the academic and the practitioner communities have largely operated independently …,Foundations and Trends® in Databases,2015,42
Finding with the crowd,Anish Das Sarma; Aditya Parameswaran; Hector Garcia-Molina; Alon Halevy,We consider the problem of using humans to find a bounded number of items satisfyingcertain properties; from a data set. For instance; we may want humans to identify a selectnumber of travel photos from a data set of photos to display on a travel website; or acandidate set of resumes that meet certain requirements from a large pool of applicants.Since data sets can be enormous; and since monetary cost and latency of data processingwith humans can be large; optimizing the use of humans for finding items is an importantchallenge. We formally define the problem using the metrics of cost and time; and designoptimal algorithms that span the skyline of cost and time; ie; we provide designers the abilityto control the cost vs. time trade-off. We study the deterministic as well as error-prone humananswer settings; along with multiplicative and additive approximations. Lastly; we study …,*,2012,42
Blogs as Predictors of Movie Success.,Eldar Sadikov; Aditya G Parameswaran; Petros Venetis,Introduction In this work; we attempt to assess if blog data is useful for prediction of movie salesand user/critics ratings. Here are our main contributions: • We evaluate a comprehensive listof features that deal with movie references in blogs (a total of 120 features) using the fullspinn3r.com blog data set for 12 months. • We find that aggregate counts of movie referencesin blogs are highly predictive of movie sales but not predictive of user and critics ratings. • Weidentify the most useful features for making movie sales predictions using correlation and KLdivergence as metrics and use clustering to find similarity between the features. • We show; usingtime series analysis as in (Gruhl; D. et. al. 2005); that blog references generally precede moviesales by a week and thus weekly sales can be predicted from blog references in the precedingweeks. • We confirm low correlation between blog references and first week movie sales …,ICWSM,2009,42
Recommendations with prerequisites,Aditya G Parameswaran; Hector Garcia-Molina,Abstract We consider the problem of recommending the best set of k items when there is aninherent ordering between items; expressed as a set of prerequisites (eg; the courseRealAnalysis' is a prerequisite ofComplex Analysis'). Since this problem is NP-hard; we develop3 approximate algorithms to solve this problem. We experimentally evaluate thesealgorithms on synthetic data.,Proceedings of the third ACM conference on Recommender systems,2009,40
Finish them!: Pricing algorithms for human computation,Yihan Gao; Aditya Parameswaran,Abstract Given a batch of human computation tasks; a commonly ignored aspect is how theprice (ie; the reward paid to human workers) of these tasks must be set or varied in order tomeet latency or cost constraints. Often; the price is set up-front and not modified; leading toeither a much higher monetary cost than needed (if the price is set too high); or to a muchlarger latency than expected (if the price is set too low). Leveraging a pricing model fromprior work; we develop algorithms to optimally set and then vary price over time in order tomeet a (a) user-specified deadline while minimizing total monetary cost (b) user-specifiedmonetary budget constraint while minimizing total elapsed time. We leverage techniquesfrom decision theory (specifically; Markov Decision Processes) for both these problems; anddemonstrate that our techniques lead to upto 30% reduction in cost over schemes …,Proceedings of the VLDB Endowment,2014,39
Information seeking: convergence of search; recommendations; and advertising,Hector Garcia-Molina; Georgia Koutrika; Aditya Parameswaran,How to address user information needs amidst a preponderance of data. doi: 10.1145/2018396.2018423 Hector Garcia-Molina; Georgia Koutrika; and Aditya Parameswaran thegoal is to present to the user only information that is of interest and relevance; at the rightplace and time. 122 communications of the acm| november 2011| vol. 54| no. 11 viewpointsnism; except that the objects presented to the user are commercial advertisements; andfinancial considerations play a central role in ranking. An advertising mechanism alsoconsiders the user context; eg; what Web site is currently being visited; or what query theuser just entered. The selection of advertisements can be based on the similarity of thecontext to the ad; or the similarity of the context to a bid phrase (where the advertiserspecifies the contexts he is interested in); or on financial considerations (eg; which …,Communications of the ACM,2011,39
SEEDB: automatically generating query visualizations,Manasi Vartak; Samuel Madden; Aditya Parameswaran; Neoklis Polyzotis,Abstract Data analysts operating on large volumes of data often rely on visualizations tointerpret the results of queries. However; finding the right visualization for a query is alaborious and time-consuming task. We demonstrate SeeDB; a system that partiallyautomates this task: given a query; SeeDB explores the space of all possible visualizations;and automatically identifies and recommends to the analyst those visualizations it finds to bemost" interesting" or" useful". In our demonstration; conference attendees will see SeeDB inaction for a variety of queries on multiple real-world datasets.,Proceedings of the VLDB Endowment,2014,37
Seedb: Visualizing database queries efficiently,Aditya Parameswaran; Neoklis Polyzotis; Hector Garcia-Molina,Abstract Data scientists rely on visualizations to interpret the data returned by queries; butfinding the right visualization remains a manual task that is often laborious. We propose aDBMS that partially automates the task of finding the right visualizations for a query. In anutshell; given an input query Q; the new DBMS optimizer will explore not only the space ofphysical plans for Q; but also the space of possible visualizations for the results of Q. Theoutput will comprise a recommendation of potentially" interesting" or" useful" visualizations;where each visualization is coupled with a suitable query execution plan. We discuss thetechnical challenges in building this system and outline an agenda for future research.,Proceedings of the VLDB Endowment,2013,36
Rapid sampling for visualizations with ordering guarantees,Albert Kim; Eric Blais; Aditya Parameswaran; Piotr Indyk; Sam Madden; Ronitt Rubinfeld,Abstract Visualizations are frequently used as a means to understand trends and gatherinsights from datasets; but often take a long time to generate. In this paper; we focus on theproblem of rapidly generating approximate visualizations while preserving crucial visualproperties of interest to analysts. Our primary focus will be on sampling algorithms thatpreserve the visual property of ordering; our techniques will also apply to some other visualproperties. For instance; our algorithms can be used to generate an approximatevisualization of a bar chart very rapidly; where the comparisons between any two bars arecorrect. We formally show that our sampling algorithms are generally applicable andprovably optimal in theory; in that they do not take more samples than necessary to generatethe visualizations with ordering guarantees. They also work well in practice; correctly …,Proceedings of the VLDB Endowment,2015,35
Optimal crowd-powered rating and filtering algorithms,Aditya Parameswaran; Stephen Boyd; Hector Garcia-Molina; Ashish Gupta; Neoklis Polyzotis; Jennifer Widom,Abstract We focus on crowd-powered filtering; ie; filtering a large set of items using humans.Filtering is one of the most commonly used building blocks in crowdsourcing applicationsand systems. While solutions for crowd-powered filtering exist; they make a range of implicitassumptions and restrictions; ultimately rendering them not powerful enough for real-worldapplications. We describe two approaches to discard these implicit assumptions andrestrictions: one; that carefully generalizes prior work; leading to an optimal; but often-timesintractable solution; and another; that provides a novel way of reasoning about filteringstrategies; leading to a sometimes suboptimal; but efficiently computable solution (that isasymptotically close to optimal). We demonstrate that our techniques lead to significantreductions in error of up to 30% for fixed cost over prior work in a novel crowdsourcing …,Proceedings of the VLDB Endowment,2014,32
An overview of the deco system: data model and query language; query processing and optimization,Hyunjung Park; Richard Pang; Aditya Parameswaran; Hector Garcia-Molina; Neoklis Polyzotis; Jennifer Widom,Abstract Deco is a comprehensive system for answering declarative queries posed overstored relational data together with data obtained on-demand from the crowd. In thisoverview paper; we describe Deco's data model; query language; and system prototype;summarizing material from earlier papers. Deco's data model was designed to be general;flexible; and principled. Deco's query language extends SQL with simple constructsnecessary for crowdsourcing; and has a precise semantics for arbitrary queries. Deco'squery execution engine and cost-based query optimizer incorporate many novel techniquesto address the limitations of traditional query processing techniques in the crowdsourcingsetting. Query processing is guided by the objective of minimizing monetary cost andreducing latency.,ACM SIGMOD Record,2013,32
Recsplorer: recommendation algorithms based on precedence mining,Aditya G Parameswaran; Georgia Koutrika; Benjamin Bercovitz; Hector Garcia-Molina,Abstract We study recommendations in applications where there are temporal patterns in theway items are consumed or watched. For example; a student who has taken the AdvancedAlgorithms course is more likely to be interested in Convex Optimization; but a student whohas taken Convex Optimization need not be interested in Advanced Algorithms in the future.Similarly; a person who has purchased the Godfather I DVD on Amazon is more likely topurchase Godfather II sometime in the future (though it is not strictly necessary towatch/purchase Godfather I beforehand). We propose a precedence mining model thatestimates the probability of future consumption based on past behavior. We then proposeRecsplorer: a suite of recommendation algorithms that exploit the precedence information.We evaluate our algorithms; as well as traditional recommendation ones; using a real …,Proceedings of the 2010 international conference on Management of data,2010,30
Principles of dataset versioning: Exploring the recreation/storage tradeoff,Souvik Bhattacherjee; Amit Chavan; Silu Huang; Amol Deshpande; Aditya Parameswaran,Abstract The relative ease of collaborative data science and analysis has led to aproliferation of many thousands or millions of versions of the same datasets in manyscientific and commercial domains; acquired or constructed at various stages of dataanalysis across many users; and often over long periods of time. Managing; storing; andrecreating these dataset versions is a non-trivial task. The fundamental challenge here is thestorage-recreation trade-off: the more storage we use; the faster it is to recreate or retrieveversions; while the less storage we use; the slower it is to recreate or retrieve versions.Despite the fundamental nature of this problem; there has been a surprisingly little amount ofwork on it. In this paper; we study this trade-off in a principled manner: we formulate sixproblems under various settings; trading off these quantities in various ways; demonstrate …,Proceedings of the VLDB Endowment,2015,28
Identifying Reliable Workers Swiftly,Aditya Ramesh; Aditya Parameswaran; Hector Garcia-Molina; Neoklis Polyzotis,We study the evaluation and replacement of workers in a crowdsourcing system. We focuson evaluation based on result disagreement among workers; and on policies that replacelow accuracy workers with fresh ones from a large pool. We study how long it takes thesystem to identify an active set of high accuracy workers; and the achieved accuracy of theselected workers. We study through simulations the dynamics of such a system; and wepropose a rule of thumb that is helpful for selecting parameters of the evaluation/replacement algorithm.,*,2012,24
Datasift: An expressive and accurate crowd-powered search toolkit,Aditya Parameswaran; Ming Han Teh; Hector Garcia-Molina; Jennifer Widom,Abstract Traditional information retrieval systems have limited functionality. For instance;they are not able to adequately support queries containing non-textual fragments such asimages or videos; queries that are very long or ambiguous; or semantically-rich queries overnon-textual corpora. In this paper; we present DataSift; an expressive and accurate crowd-powered search toolkit that can connect to any corpus. We provide a number of alternativeconfigurations for DataSift using crowdsourced and automated components; anddemonstrate gains of 2–3x on precision over traditional retrieval schemes using experimentson real corpora. We also present our results on determining suitable values for parametersin those configurations; along with a number of interesting insights learned along the way.,First AAAI Conference on Human Computation and Crowdsourcing,2013,22
Effortless data exploration with zenvisage: an expressive and interactive visual analytics system,Tarique Siddiqui; Albert Kim; John Lee; Karrie Karahalios; Aditya Parameswaran,Abstract Data visualization is by far the most commonly used mechanism to explore andextract insights from datasets; especially by novice data scientists. And yet; current visualanalytics tools are rather limited in their ability to operate on collections of visualizations---bycomposing; filtering; comparing; and sorting them---to find those that depict desired trends orpatterns. The process of visual data exploration remains a tedious process of trial-and-error.We propose zenvisage; a visual analytics platform for effortlessly finding desired visualpatterns from large datasets. We introduce zenvisage's general purpose visual explorationlanguage; ZQL (" zee-quel") for specifying the desired visual patterns; drawing from use-cases in a variety of domains; including biology; mechanical engineering; climate science;and commerce. We formalize the expressiveness of ZQL via a visual exploration algebra …,Proceedings of the VLDB Endowment,2016,21
Challenges in data crowdsourcing,Hector Garcia-Molina; Manas Joglekar; Adam Marcus; Aditya Parameswaran; Vasilis Verroios,Crowdsourcing refers to solving large problems by involving human workers that solvecomponent sub-problems or tasks. In data crowdsourcing; the problem involves dataacquisition; management; and analysis. In this paper; we provide an overview of datacrowdsourcing; giving examples of problems that the authors have tackled; and presentingthe key design steps involved in implementing a crowdsourced solution. We also discusssome of the open challenges that remain to be solved.,IEEE Transactions on Knowledge and Data Engineering,2016,20
Comprehensive and reliable crowd assessment algorithms,Manas Joglekar; Hector Garcia-Molina; Aditya Parameswaran,Evaluating workers is a critical aspect of any crowdsourcing system. In this paper; we devisetechniques for evaluating workers by finding confidence intervals on their error rates. Unlikeprior work; we focus on “conciseness”-that is; giving as tight a confidence interval aspossible. Conciseness is of utmost importance because it allows us to be sure that we havethe best guarantee possible on worker error rate. Also unlike prior work; we providetechniques that work under very general scenarios; such as when not all workers haveattempted every task (a fairly common scenario in practice); when tasks have non-booleanresponses; and when workers have different biases for positive and negative tasks. Wedemonstrate conciseness as well as accuracy of our confidence intervals by testing them ona variety of conditions and multiple real-world datasets.,Data Engineering (ICDE); 2015 IEEE 31st International Conference on,2015,18
Collaborative data analytics with DataHub,Anant Bhardwaj; Amol Deshpande; Aaron J Elmore; David Karger; Sam Madden; Aditya Parameswaran; Harihar Subramanyam; Eugene Wu; Rebecca Zhang,Abstract While there have been many solutions proposed for storing and analyzing largevolumes of data; all of these solutions have limited support for collaborative data analytics;especially given the many individuals and teams are simultaneously analyzing; modifyingand exchanging datasets; employing a number of heterogeneous tools or languages fordata analysis; and writing scripts to clean; preprocess; or query data. We demonstrateDataHub; a unified platform with the ability to load; store; query; collaboratively analyze;interactively visualize; interface with external applications; and share datasets. We willdemonstrate the following aspects of the DataHub platform:(a) flexible data storage; sharing;and native versioning capabilities: multiple conference attendees can concurrently updatethe database and browse the different versions and inspect conflicts;(b) an app …,Proceedings of the VLDB Endowment,2015,17
Optimal Schemes for Robust Web Extraction,Aditya Parameswaran; Nilesh Dalvi; Hector Garcia-Molina; Rajeev Rastogi,In this paper; we consider the problem of constructing wrappers for web informationextraction that are robust to changes in websites. We consider two models to studyrobustness formally: the adversarial model; where we look at the worst-case robustness ofwrappers; and probabilistic model; where we look at the expected robustness of wrappers;as web-pages evolve. Under both models; we present optimal algorithms for constructingthe most robust wrapper. By evaluating on real websites; we demonstrate that in practice;our algorithms are highly effective in coping up with changes in websites; and reduce thewrapper breakage by up to 500% over existing techniques.,Proceedings of the VLDB Conference,2011,17
Decibel: The relational dataset branching system,Michael Maddox; David Goehring; Aaron J Elmore; Samuel Madden; Aditya Parameswaran; Amol Deshpande,Abstract As scientific endeavors and data analysis become increasingly collaborative; thereis a need for data management systems that natively support the versioning or branching ofdatasets to enable concurrent analysis; cleaning; integration; manipulation; or curation ofdata across teams of individuals. Common practice for sharing and collaborating ondatasets involves creating or storing multiple copies of the dataset; one for each stage ofanalysis; with no provenance information tracking the relationships between these datasets.This results not only in wasted storage; but also makes it challenging to track and integratemodifications made by different users to the same dataset. In this paper; we introduce theRelational Dataset Branching System; Decibel; a new relational storage system with built-inversion control designed to address these short-comings. We present our initial design for …,Proceedings of the VLDB Endowment,2016,15
Recommendation systems with complex constraints: A courserank perspective,Aditya Parameswaran; Petros Venetis; Hector Garcia-Molina,We study the problem of making recommendations when the objects to be recommendedmust also satisfy constraints or requirements. In particular; we focus on courserecommendations: the courses taken by a student must satisfy requirements (eg; take 2 outof a list of 5 math courses) in order for the student to graduate. Our work is done in thecontext of the CourseRank system at Stanford; used by students to plan their academicprogram at Stanford University. Our goal is to recommend to these students courses that notonly help satisfy constraints; but that are also desirable (eg; popular or taken by similarstudents). We develop increasingly expressive models for course requirements; and presenta variety of schemes for both checking if the requirements are satisfied; and for makingrecommendations that take into account the requirements. We show that some types of …,Transactions on Information Systems (TOIS)--To Appear,2011,14
Surpassing humans and computers with JELLYBEAN: crowd-vision-hybrid counting algorithms,Akash Das Sarma; Ayush Jain; Arnab Nandi; Aditya Parameswaran; Jennifer Widom,Abstract Counting objects is a fundamental image processisng primitive; and has manyscientific; health; surveillance; security; and military applications. Existing supervisedcomputer vision techniques typically require large quantities of labeled training data; andeven with that; fail to return accurate results in all but the most stylized settings. Using vanillacrowdsourcing; on the other hand; can lead to significant errors; especially on images withmany objects. In this paper; we present our JellyBean suite of algorithms; that combines thebest of crowds and computer vision to count objects in images; and uses judiciousdecomposition of images to greatly improve accuracy at low cost. Our algorithms haveseveral desirable properties:(i) they are theoretically optimal or near-optimal; in that they askas few questions as possible to humans (under certain intuitively reasonable …,Third AAAI Conference on Human Computation and Crowdsourcing,2015,13
Towards a unified query language for provenance and versioning,Amit Chavan; Silu Huang; Amol Deshpande; Aaron Elmore; Samuel Madden; Aditya Parameswaran,Abstract Organizations and teams collect and acquire data from various sources; such associal interactions; financial transactions; sensor data; and genome sequencers. Differentteams in an organization as well as different data scientists within a team are interested inextracting a variety of insights which requires combining and collaboratively analyzingdatasets in diverse ways. DataHub is a system that aims to provide robust version controland provenance management for such a scenario. To be truly useful for collaborative datascience; one also needs the ability to specify queries and analysis tasks over the versioningand the provenance information in a unified manner. In this paper; we present an initialdesign of our query language; called VQuel; that aims to support such unified querying overboth types of information; as well as the intermediate and final results of analyses. We …,arXiv preprint arXiv:1506.04815,2015,12
Query processing over crowdsourced data,Hyunjung Park; Aditya Parameswaran; Jennifer Widom,We are building Deco; a comprehensive system for answering declarative queries posedover stored relational data together with data gathered from the crowd. In this paper wepresent Deco's query processor; building on Deco's data model and query languagepresented earlier. In general; it has been observed that query processing overcrowdsourced data must contend with issues and tradeoffs involving cost; latency; anduncertainty that don't arise in traditional query processing. Deco's overall objective in queryexecution is to maximize parallelism while fetching data from the crowd (to keep latencylow); but only when the parallelism will not issue too many tasks (which would increasecost). Meeting this objective requires a number of changes from traditional query execution.First; Deco's query processor uses a hybrid execution model; which respects Deco …,*,2012,12
Towards globally optimal crowdsourcing quality management: The uniform worker setting,Akash Das Sarma; Aditya Parameswaran; Jennifer Widom,Abstract We study crowdsourcing quality management; that is; given worker responses to aset of tasks; our goal is to jointly estimate the true answers for the tasks; as well as the qualityof the workers. Prior work on this problem relies primarily on applying Expectation-Maximization (EM) on the underlying maximum likelihood problem to estimate true answersas well as worker quality. Unfortunately; EM only provides a locally optimal solution ratherthan a globally optimal one. Other solutions to the problem (that do not leverage EM) fail toprovide global optimality guarantees as well. In this paper; we focus on filtering; where tasksrequire the evaluation of a yes/no predicate; and rating; where tasks elicit integer scoresfrom a finite domain. We design algorithms for finding the global optimal estimates of correcttask answers and worker quality for the underlying maximum likelihood problem; and …,Proceedings of the 2016 International Conference on Management of Data,2016,10
Smart drill-down: A new data exploration operator,Manas Joglekar; Hector Garcia-Molina; Aditya Parameswaran,Abstract We present a data exploration system equipped with smart drill-down; a noveloperator for interactively exploring a relational table to discover and summarize" interesting"groups of tuples. Each such group of tuples is represented by a rule. For instance; the rule(a; b;*; 1000) tells us that there are a thousand tuples with value a in the first column and b inthe second column (and any value in the third column). Smart drill-down presents an analystwith a list of rules that together describe interesting aspects of the table. The analyst cantailor the definition of interesting; and can interactively apply smart drill-down on an existingrule to explore that part of the table. In the demonstration; conference attendees will be ableto use the data exploration system equipped with smart drill-down; and will be able tocontrast smart drill-down to traditional drill-down; for various interestingness measures …,Proceedings of the VLDB Endowment,2015,10
Debiasing crowdsourced batches,Honglei Zhuang; Aditya Parameswaran; Dan Roth; Jiawei Han,Abstract Crowdsourcing is the de-facto standard for gathering annotated data. While; intheory; data annotation tasks are assumed to be attempted by workers independently; inpractice; data annotation tasks are often grouped into batches to be presented andannotated by workers together; in order to save on the time or cost overhead of providinginstructions or necessary background. Thus; even though independence is usually assumedbetween annotations on data items within the same batch; in most cases; a worker'sjudgment on a data item can still be affected by other data items within the batch; leading toadditional errors in collected labels. In this paper; we study the data annotation bias whendata items are presented as batches to be judged by workers simultaneously. We propose anovel worker model to characterize the annotating behavior on data batches; and present …,Proceedings of the 21th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining,2015,9
Big data,Andrew Cron; Huy L Nguyen; Aditya Parameswaran,In such massive data contexts; getting data into a form amenable to analysis andvisualization is challenging. Jeff Heer and Sean Kandel write about cutting-edge work thatenables data analysts to quickly gain valuable insights from their data.Social networkanalysts have been using massive graph data to understand social interactions andbehavior. B. Aditya Prakash presents some of the challenges and strategies for studyingpropagation and immunization in the realm of large social networks.,XRDS: Crossroads; The ACM Magazine for Students,2012,9
Robust construction of the three-dimensional flow complex,Frederic Cazals; Aditya Parameswaran; Sylvain Pion,Abstract The Delaunay triangulation and its dual the Voronoi diagram are ubiquitousgeometric complexes. From a topological standpoint; the connection has recently beenmade between these cell complexes and the Morse theory of distance functions. Inparticular; in the generic setting; algorithms have been proposed to compute the flowcomplex--the stable and unstable manifolds associated to the critical points of the distancefunction to a point set. As algorithms ignoring degenerate cases and numerical issues arebound to fail on general inputs; this paper develops the first complete and robust algorithmto compute the flow complex. First; we present complete algorithms for the flow operator;unraveling a delicate interplay between the degenerate cases of Delaunay and those whichare flow specific. Second; we sketch how the flow operator unifies the construction of …,Proceedings of the twenty-fourth annual symposium on Computational geometry,2008,9
Understanding workers; developing effective tasks; and enhancing marketplace dynamics: a study of a large crowdsourcing marketplace,Ayush Jain; Akash Das Sarma; Aditya Parameswaran; Jennifer Widom,Abstract We conduct an experimental analysis of a dataset comprising over 27 millionmicrotasks performed by over 70;000 workers issued to a large crowdsourcing marketplacebetween 2012--2016. Using this data---never before analyzed in an academic context---weshed light on three crucial aspects of crowdsourcing:(1) Task design---helping requestersunderstand what constitutes an effective task; and how to go about designing one;(2)Marketplace dynamics---helping marketplace administrators and designers understand theinteraction between tasks and workers; and the corresponding marketplace load; and (3)Worker behavior---understanding worker attention spans; lifetimes; and general behavior;for the improvement of the crowdsourcing ecosystem as a whole.,Proceedings of the VLDB Endowment,2017,8
Interactive data exploration with smart drill-down,Manas Joglekar; Hector Garcia-Molina; Aditya Parameswaran,We present smart drill-down; an operator for interactively exploring a relational table todiscover and summarize “interesting” groups of tuples. Each group of tuples is described bya rule. For instance; the rule (a; b;*; 1000) tells us that there are a thousand tuples with valuea in the first column and b in the second column (and any value in the third column). Smartdrill-down presents an analyst with a list of rules that together describe interesting aspects ofthe table. The analyst can tailor the definition of interesting; and can interactively apply smartdrill-down on an existing rule to explore that part of the table. We demonstrate that theunderlying optimization problems are NP-HARD; and describe an algorithm for finding theapproximately optimal list of rules to display when the user uses a smart drill-down; and adynamic sampling scheme for efficiently interacting with large tables. Finally; we perform …,Data Engineering (ICDE); 2016 IEEE 32nd International Conference on,2016,8
DataSpread: Unifying databases and spreadsheets,Mangesh Bendre; Bofan Sun; Ding Zhang; Xinyan Zhou; Kevin Chen-Chuan Chang; Aditya Parameswaran,Abstract Spreadsheet software is often the tool of choice for ad-hoc tabular datamanagement; processing; and visualization; especially on tiny data sets. On the other hand;relational database systems offer significant power; expressivity; and efficiency overspreadsheet software for data management; while lacking in the ease of use and ad-hocanalysis capabilities. We demonstrate D ata S pread; a data exploration tool that holisticallyunifies databases and spreadsheets. It continues to offer a Microsoft Excel-basedspreadsheet front-end; while in parallel managing all the data in a back-end database;specifically; PostgreSQL. D ata S pread retains all the advantages of spreadsheets;including ease of use; ad-hoc analysis and visualization capabilities; and a schema-freenature; while also adding the advantages of traditional relational databases; such as …,Proceedings of the VLDB Endowment,2015,8
I've seen enough: incrementally improving visualizations to support rapid decision making,Sajjadur Rahman; Maryam Aliakbarpour; Ha Kyung Kong; Eric Blais; Karrie Karahalios; Aditya Parameswaran; Ronitt Rubinfield,Abstract Data visualization is an effective mechanism for identifying trends; insights; andanomalies in data. On large datasets; however; generating visualizations can take a longtime; delaying the extraction of insights; hampering decision making; and reducingexploration time. One solution is to use online sampling-based schemes to generatevisualizations faster while improving the displayed estimates incrementally; eventuallyconverging to the exact visualization computed on the entire data. However; theintermediate visualizations are approximate; and often fluctuate drastically; leading topotentially incorrect decisions. We propose sampling-based incremental visualizationalgorithms that reveal the" salient" features of the visualization quickly---with a 46× speeduprelative to baselines---while minimizing error; thus enabling rapid and error-free decision …,Proceedings of the VLDB Endowment,2017,6
FacetGist: Collective extraction of document facets in large technical corpora,Tarique Siddiqui; Xiang Ren; Aditya Parameswaran; Jiawei Han,Abstract Given the large volume of technical documents available; it is crucial toautomatically organize and categorize these documents to be able to understand andextract value from them. Towards this end; we introduce a new research problem calledFacet Extraction. Given a collection of technical documents; the goal of Facet Extraction is toautomatically label each document with a set of concepts for the key facets (eg; application;technique; evaluation metrics; and dataset) that people may be interested in. FacetExtraction has numerous applications; including document summarization; literature search;patent search and business intelligence. The major challenge in performing Facet Extractionarises from multiple sources: concept extraction; concept to facet matching; and facetdisambiguation. To tackle these challenges; we develop FacetGist; a framework for facet …,Proceedings of the 25th ACM International on Conference on Information and Knowledge Management,2016,6
DataSift: a crowd-powered search toolkit,Aditya Parameswaran; Ming Han Teh; Hector Garcia-Molina; Jennifer Widom,Abstract Traditional search engines are unable to support a large number of potentialqueries issued by users; for instance; queries containing non-textual fragments such asimages or videos; queries that are very long; ambiguous; or those that require subjectivejudgment; or semantically-rich queries over non-textual corpora. We demonstrate DataSift; acrowd-powered search toolkit that can be instrumented over any corpus supporting akeyword search API; and supports efficient and accurate querying for a rich general class ofqueries; including those described previously. Our demonstration will allow conferenceattendees to issue live queries for image; video; and product search; as well as" play back"the results of a wide variety of prior queries issued on DataSift. Attendees will also be able toperform a side-by-side comparison between DataSift and traditional retrieval schemes.,Proceedings of the 2014 ACM SIGMOD International Conference on Management of Data,2014,6
Active sampling for entity matching with guarantees,Kedar Bellare; Suresh Iyengar; Aditya Parameswaran; Vibhor Rastogi,Abstract In entity matching; a fundamental issue while training a classifier to label pairs ofentities as either duplicates or nonduplicates is the one of selecting informative trainingexamples. Although active learning presents an attractive solution to this problem; previousapproaches minimize the misclassification rate (0--1 loss) of the classifier; which is anunsuitable metric for entity matching due to class imbalance (ie; many more nonduplicatepairs than duplicate pairs). To address this; a recent paper [Arasu et al. 2010] proposes tomaximize recall of the classifier under the constraint that its precision should be greater thana specified threshold. However; the proposed technique requires the labels of all n inputpairs in the worst case. Our main result is an active learning algorithm that approximatelymaximizes recall of the classifier while respecting a precision constraint with provably …,ACM Transactions on Knowledge Discovery from Data (TKDD),2013,6
Human Powered Debugging of Large Data Pipelines,Nilesh Dalvi; Aditya Parameswaran; Vibhor Rastogi,*,*,2012,6
O rpheus DB: bolt-on versioning for relational databases,Silu Huang; Liqi Xu; Jialin Liu; Aaron J Elmore; Aditya Parameswaran,Abstract Data science teams often collaboratively analyze datasets; generating datasetversions at each stage of iterative exploration and analysis. There is a pressing need for asystem that can support dataset versioning; enabling such teams to efficiently store; track;and query across dataset versions. We introduce O rpheus DB; a dataset version controlsystem that" bolts on" versioning capabilities to a traditional relational database system;thereby gaining the analytics capabilities of the database" for free". We develop andevaluate multiple data models for representing versioned data; as well as a light-weightpartitioning scheme; L yre S plit; to further optimize the models for reduced query latencies.With L yre S plit; O rpheus DB is on average 10 3× faster in finding effective (and better)partitionings than competing approaches; while also reducing the latency of version …,Proceedings of the VLDB Endowment,2017,5
Social sites research through CourseRank,Benjamin Bercovitz; Filip Kaliszan; Georgia Koutrika; Henry Liou; Aditya Parameswaran; Petros Venetis; Zahra Mohammadi Zadeh; Hector Garcia-Molina,Abstract Social sites such as FaceBook; Orkut; Flickr; MySpace and many others havebecome immensely popular. At these sites; users share their resources (eg; photos; profiles;blogs) and learn from each other. On the other hand; higher education applications helpstudents and administrators track and manage academic information such as grades; courseevaluations and enrollments. Despite the importance of both these areas; there is relativelylittle research on the mechanisms that make them effective. Apart from being both asuccessful social site and an academic planning site; CourseRank provides a live testbedfor studying fundamental questions related to social networking; academic planning; and thefusion of these areas. In this paper; we provide a system overview and our main researchefforts through CourseRank.,ACM SIGMOD Record,2010,5
Towards visualization recommendation systems,Manasi Vartak; Silu Huang; Tarique Siddiqui; Samuel Madden; Aditya Parameswaran,Abstract Data visualization is often used as the first step while performing a variety ofanalytical tasks. With the advent of large; high-dimensional datasets and significant interestin data science; there is a need for tools that can support rapid visual analysis. In this paperwe describe our vision for a new class of visualization systems; namely visualizationrecommendation systems; that can automatically identify and interactively recommendvisualizations relevant to an analytical task. We detail the key requirements and designconsiderations for a visualization recommendation system. We also identify a number ofchallenges in realizing this vision and describe some approaches to address them.,ACM SIGMOD Record,2017,4
SLiMFast: Guaranteed results for data fusion and source reliability,Theodoros Rekatsinas; Manas Joglekar; Hector Garcia-Molina; Aditya Parameswaran; Christopher Ré,Abstract We focus on data fusion; ie; the problem of unifying conflicting data from datasources into a single representation by estimating the source accuracies. We proposeSLiMFast; a framework that expresses data fusion as a statistical learning problem overdiscriminative probabilistic models; which in many cases correspond to logistic regression.In contrast to previous approaches that use complex generative models; discriminativemodels make fewer distributional assumptions over data sources and allow us to obtainrigorous theoretical guarantees. Furthermore; we show how SLiMFast enables incorporatingdomain knowledge into data fusion; yielding accuracy improvements of up to 50% over state-of-the-art baselines. Building upon our theoretical results; we design an optimizer thatobviates the need for users to manually select an algorithm for learning SLiMFast's …,Proceedings of the 2017 ACM International Conference on Management of Data,2017,4
Crowdgather: Entity extraction over structured domains,Theodoros Rekatsinas; Amol Deshpande; Aditya Parameswaran,Abstract: Crowdsourced entity extraction is often used to acquire data for many applications;including recommendation systems; construction of aggregated listings and directories; andknowledge base construction. Current solutions focus on entity extraction using a singlequery; eg; only using" give me another restaurant"; when assembling a list of all restaurants.Due to the cost of human labor; solutions that focus on a single query can be highlyimpractical. In this paper; we leverage the fact that entity extraction often focuses on {\emstructured domains}; ie; domains that are described by a collection of attributes; eachpotentially exhibiting hierarchical structure. Given such a domain; we enable a richer spaceof queries; eg;" give me another Moroccan restaurant in Manhattan that does takeout".Naturally; enabling a richer space of queries comes with a host of issues; especially since …,arXiv preprint arXiv:1502.06823,2015,4
Efficient parsing-based keyword search over databases,Aditya Parameswaran; Raghav Kaushik; Arvind Arasu,We study a parsing-based semantics for keyword search over databases that relies onparsing the search query using a grammar. The parsing-based semantics is often used tooverride the traditional “bag-of-words” semantics in web search and enterprise searchscenarios. Compared to the “bag-of-words” semantics; the parsing-based semantics is richerand more customizable. While a formalism for parsing-based semantics for keyword searchhas been proposed in prior work and ad-hoc implementations exist; the problem ofdesigning efﬁcient algorithms to support the semantics is largely unstudied. In this paper; wepresent a suite of efﬁcient algorithms and auxiliary indexes for this problem. Our algorithmswork for a broad classes of grammars used in practice; and cover a variety of databasematching functions (set-and substring-containment; approximate and exact equality) and …,*,2012,4
ORPHEUSDB: A lightweight approach to relational dataset versioning,Liqi Xu; Silu Huang; Sili Hui; Aaron J Elmore; Aditya Parameswaran,Abstract We demonstrate OrpheusDB; a lightweight approach to versioning of relationaldatasets. OrpheusDB is built as a thin layer on top of standard relational databases; andtherefore inherits much of their benefits while also compactly storing; tracking; andrecreating dataset versions on demand. OrpheusDB also supports a range of queryingmodalities spanning both SQL and git-style version commands. Conference attendees willbe able to interact with OrpheusDB via an interactive version browser interface. The demowill highlight underlying design decisions of OrpheusDB; and provide an understanding ofhow OrpheusDB translates versioning commands into commands understood by a databasesystem that is unaware of the presence of versions. OrpheusDB has been developed asopen-source software; code is available at http://orpheus-db. github. io.,Proceedings of the 2017 ACM International Conference on Management of Data,2017,3
Human-powered data management,Aditya G Parameswaran,Abstract Fully automated algorithms are inadequate for a number of data analysis tasks;especially those involving images; video; or text. us; there is often a need to combine“human computation”(or crowdsourcing); together with traditional computation; in order toimprove the process of understanding and analyzing data. However; most datamanagement applications currently employ crowdsourcing in an ad-hoc fashion; theseapplications are not optimized for low monetary cost; low latency; or high accuracy. In thisthesis; we develop a formalism for reasoning about human-powered data management; anduse this formalism to design:(a) a toolbox of basic data processing algorithms; optimized forcost; latency; and accuracy; and (b) practical data management systems and applicationsthat use these algorithms. We demonstrate that our techniques lead to algorithms and …,*,2013,3
Quantum Cryptography and Quantum Computation,Hidayath Ansari; Aditya Parameswaran; Lakulish Antani; Bhaskara Aditya; Ankur Taly; Luv Kumar,Abstract Quantum Cryptography uses the principles of Quantum Mechanics to implement acryptographic system. The key problem which is solved by using quantum techniques is thatof eavesdropping detection. Conventional secret-key cryptography techniques require thecommunication of a secret key prior to message exchange. Quantum principles can be usedto detect eavesdropping probabilistically when it occurs. The bits are represented as qubits;physically modelled by photons; and communicated over a quantum channel. Thepolarization states of photons represent 0's and 1's.,*,2007,3
Tricore Port for GCC-An Analysis,Lakulish Antani; Hidayath Ansari; Aditya Parameswaran,*,*,2006,3
Fast-Forwarding to Desired Visualizations with Zenvisage.,Tarique Siddiqui; John Lee; Albert Kim; Edward Xue; Xiaofo Yu; Sean Zou; Lijin Guo; Changfeng Liu; Chaoran Wang; Karrie Karahalios; Aditya G Parameswaran,ABSTRACT Data exploration and analysis; especially for non-programmers; remains atedious and frustrating process of trial-and-error—data scientists spend many hours poringthrough visualizations in the hope of finding those that match desired patterns. Wedemonstrate zenvisage; an interactive data exploration system tailored towards“fastforwarding” to desired trends; patterns; or insights; without much effort from the user.zenvisage's interface supports simple dragand-drop and sketch-based interactions asspecification mechanisms for the exploration need; as well as an intuitive data explorationlanguage called ZQL for more complex needs. zenvisage is being developed incollaboration with ad analysts; battery scientists; and genomic data analysts; and will bedemonstrated on similar datasets.,CIDR,2017,2
Squish: Near-optimal compression for archival of relational datasets,Yihan Gao; Aditya Parameswaran,Abstract Relational datasets are being generated at an alarmingly rapid rate acrossorganizations and industries. Compressing these datasets could significantly reduce storageand archival costs. Traditional compression algorithms; eg; gzip; are suboptimal forcompressing relational datasets since they ignore the table structure and relationshipsbetween attributes. We study compression algorithms that leverage the relational structure tocompress datasets to a much greater extent. We develop Squish; a system that uses acombination of Bayesian Networks and Arithmetic Coding to capture multiple kinds ofdependencies among attributes and achieve near-entropy compression rate. Squish alsosupports user-defined attributes: users can instantiate new data types by simplyimplementing five functions for a new class interface. We prove the asymptotic optimality …,Proceedings of the 22nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining,2016,2
Speedy browsing and sampling with needletail,Albert Kim; Liqi Xu; Tarique Siddiqui; Silu Huang; Samuel Madden; Aditya Parameswaran,ABSTRACT Exploratory data analysis often involves repeatedly browsing small samples ofrecords that satisfy certain ad-hoc predicates; to form and test hypotheses; identifycorrelations; or make inferences. Unfortunately; existing database systems are not optimizedfor queries with a LIMIT clause—operating instead in an all-or-nothing manner. Whileworkload aware caching; indexing; or precomputation schemes may appear promisingremedies; they do not apply in an exploratory setting where the queries are ad-hoc andunpredictable. In this paper; we propose a fast sampling engine; called NEEDLETAIL; aimedat letting analysts browse a small sample of the query results on large datasets as quickly aspossible; independent of the overall size of the result set. NEEDLETAIL introduces densitymaps; a lightweight in-memory indexing structure; and a set of efficient algorithms (with …,CoRR,2016,2
Discovering Properties of Linear Programs: Termination and Invariant Generation,Aditya G Parameswaran,Abstract Termination is a property that is required for many real-time applications to avoidunexpected failures due to “bad” inputs. In this report we study the question of termination ofpiecewise-linear programs [3] and the associated decidability issues. We try to establishequivalences between termination queries on various classes of programs. We pose anumber of interesting open questions that remain to be answered in the next stage of theBTech Project. Discovery of invariants are useful for verifying the correctness of programsand also to study certain properties of programs. We look at the automatic generation oflinear invariants; both as affine inequalities [2] and as affine relations [1]. We also examine atthe technique of accelerations [5][6](also called exact widening) to speed up convergence ofreachability analysis for an infinite state space using decidable Presburger Arithmetic.,Bombay Mumbai: Department of Computer Science and Engineering Indian Institute of Technology,2006,2
Vector approach to ray tracing for reflection and refraction,Y Kanoria; AG Parameswaran,*,*,2005,2
Towards a Holistic Integration of Spreadsheets with Databases: A Scalable Storage Engine for Presentational Data Management,Mangesh Bendre; Vipul Venkataraman; Xinyan Zhou; Kevin Chen-Chuan Chang; Aditya Parameswaran,Abstract: Spreadsheet software is the tool of choice for interactive ad-hoc data management;with adoption by billions of users. However; spreadsheets are not scalable; unlike databasesystems. On the other hand; database systems; while highly scalable; do not supportinteractivity as a first-class primitive. We are developing DataSpread; to holistically integratespreadsheets as a front-end interface with databases as a back-end datastore; providingscalability to spreadsheets; and interactivity to databases; an integration we termpresentational data management (PDM). In this paper; we make a first step towards thisvision: developing a storage engine for PDM; studying how to flexibly represent spreadsheetdata within a database and how to support and maintain access by position. We first conductan extensive survey of spreadsheet use to motivate our functional requirements for a …,arXiv preprint arXiv:1708.06712,2017,1
On the interpretability of conditional probability estimates in the agnostic setting,Yihan Gao; Aditya Parameswaran; Jian Peng,Abstract We study the interpretability of conditional probability estimates for binaryclassification under the agnostic setting or scenario. Under the agnostic setting; conditionalprobability estimates do not necessarily reflect the true conditional probabilities. Instead;they have a certain calibration property: among all data points that the classifier haspredicted $\mathcal {P}(Y= 1| X)= p $; $ p $ portion of them actually have label $ Y= 1$. Forcost-sensitive decision problems; this calibration property provides adequate support for usto use Bayes Decision Rule. In this paper; we define a novel measure for the calibrationproperty together with its empirical counterpart; and prove a uniform convergence resultbetween them. This new measure enables us to formally justify the calibration property ofconditional probability estimations. It also provides new insights on the problem of …,Electronic Journal of Statistics,2017,1
Optimizing Open-Ended Crowdsourcing: The Next Frontier in Crowdsourced Data Management,Aditya Parameswaran; Akash Das Sarma; Vipul Venkataraman,Abstract Crowdsourcing is the primary means to generate training data at scale; and whencombined with sophisticated machine learning algorithms; crowdsourcing is an enabler for avariety of emergent automated applications impacting all spheres of our lives. This papersurveys the emerging field of formally reasoning about and optimizing open-endedcrowdsourcing; a popular and crucially important; but severely understudied class ofcrowdsourcing—the next frontier in crowdsourced data management. The underlyingchallenges include distilling the right answer when none of the workers agree with eachother; teasing apart the various perspectives adopted by workers when answering tasks;and effectively selecting between the many open-ended operators appropriate for aproblem. We describe the approaches that we've found to be effective for open-ended …,Bulletin of the Technical Committee on Data Engineering,2016,1
Efficient parsing-based search over structured data,Aditya Parameswaran; Raghav Kaushik; Arvind Arasu,Abstract Parsing-based search; ie; parsing keyword search queries using grammars; is oftenused to override the traditional" bag-of-words'" semantics in web search and enterprisesearch scenarios. Compared to the" bag-of-words" semantics; the parsing-based semanticsis richer and more customizable. While a formalism for parsing-based semantics for keywordsearch has been proposed in prior work and ad-hoc implementations exist; the problem ofdesigning efficient algorithms to support the semantics is largely unstudied. In this paper; wepresent a suite of efficient algorithms and auxiliary indexes for this problem. Our algorithmswork for a broad classes of grammars used in practice; and cover a variety of databasematching functions (set-and substring-containment; approximate and exact equality) andscoring functions (to filter and rank different parses). We formally analyze the time …,Proceedings of the 22nd ACM international conference on Information & Knowledge Management,2013,1
An interview with surajit chaudhuri,Aditya Parameswaran,SURAJIT CHAUDHURI: "Big data" has become a catch phrase and like many other catch phraseshas multiple interpretations. As a researcher interested in the data analytics space; I view theunderlying challenges as that of building platforms and tools that enable businesses to deriveactionable insights from raw data dramatically faster and finer-grained than is possibletoday. This aspiration maps into a set of concrete technical challenges. I described them in ashort article I prepared for my keynote at ACM Principles of Database Systems conference(PODS) earlier this year [1] … AP: The database community has been working on "very largedata bases" for a while now. What is new now? Are we simply marketing big data as old winein new bottles … SC: It is true that the database community has always paid close attentionto building scalable data platforms; but there have been big changes quantitatively as …,XRDS: Crossroads; The ACM Magazine for Students,2012,1
Low-Norm Graph Embedding,Yihan Gao; Chao Zhang; Jian Peng; Aditya Parameswaran,Abstract: Learning distributed representations for nodes in graphs has become an importantproblem that underpins a wide spectrum of applications. Existing methods to this problemlearn representations by optimizing a softmax objective while constraining the dimension ofembedding vectors. We argue that the generalization performance of these methods areprobably not due to the dimensionality constraint as commonly believed; but rather the smallnorm of embedding vectors. Both theoretical and empirical evidences are provided tosupport this argument:(a) we prove that the generalization error of these methods can bebounded regardless of embedding dimension by limiting the norm of vectors;(b) we showempirically that the generalization performance of existing embedding methods are likelydue to the early stopping of stochastic gradient descent. Motivated by our analysis; we …,arXiv preprint arXiv:1802.03560,2018,*
Towards a Theory of DATA-DIFF: Optimal Synthesis of Succinct Data Modification Scripts,Tana Wattanawaroon; Stephen Macke; Aditya Parameswaran,Abstract: This paper addresses the Data-Diff problem: given a dataset and a subsequentversion of the dataset; find the shortest sequence of operations that transforms the dataset tothe subsequent version; under a restricted family of operations. We consider operationssimilar to SQL UPDATE; each with a condition (WHERE) that matches a subset of tuples anda modifier (SET) that makes changes to those matched tuples. We characterize the problembased on different constraints on the attributes and the allowed conditions and modifiers;providing complexity classification and algorithms in each case. Subjects: Databases (cs.DB) Cite as: arXiv: 1801.06258 [cs. DB](or arXiv: 1801.06258 v1 [cs. DB] for this version)Submission history From: Tana Wattanawaroon [view email][v1] Fri; 19 Jan 2018 00: 02: 34GMT (50kb; D),arXiv preprint arXiv:1801.06258,2018,*
Characterizing Scalability Issues in Spreadsheet Software using Online Forums,Kelly Mack; John Lee; Kevin Chang; Karrie Karahalios; Aditya Parameswaran,Abstract: In traditional usability studies; researchers talk to users of tools to understand theirneeds and challenges. Insights gained via such interviews offer context; detail; andbackground. Due to costs in time and money; we are beginning to see a new form of toolinterrogation that prioritizes scale; cost; and breadth by utilizing existing data from onlineforums. In this case study; we set out to apply this method of using online forum data to aspecific issue---challenges that users face with Excel spreadsheets. Spreadsheets are aversatile and powerful processing tool if used properly. However; with versatility and powercome errors; from both users and the software; which make using spreadsheets lesseffective. By scraping posts from the website Reddit; we collected a dataset of questions andcomplaints about Excel. Specifically; we explored and characterized the issues users …,arXiv preprint arXiv:1801.03829,2018,*
Accelerating Scientific Data Exploration via Visual Query Systems,Doris Jung-Lin Lee; John Lee; Tarique Siddiqui; Jaewoo Kim; Karrie Karahalios; Aditya Parameswaran,Abstract: The increasing availability of rich and complex data in a variety of scientificdomains poses a pressing need for tools to enable scientists to rapidly make sense of andgather insights from data. One proposed solution is to design visual query systems (VQSs)that allow scientists to search for desired patterns in their datasets. While many existingVQSs promise to accelerate exploratory data analysis by facilitating this search; they areunfortunately not widely used in practice. Through a year-long collaboration with scientists inthree distinct domains---astronomy; genetics; and material science---we study the impact ofvarious features within VQSs that can aid rapid visual data analysis; and how VQSs fit into ascientists' analysis workflow. Our findings offer design guidelines for improving the usabilityand adoption of next-generation VQSs; paving the way for VQSs to be applied to a variety …,arXiv preprint arXiv:1710.00763,2017,*
Navigating the Data Lake with Datamaran: Automatically Extracting Structure from Log Datasets,Yihan Gao; Silu Huang; Aditya Parameswaran,Abstract: Organizations routinely accumulate semi-structured log datasets generated as theoutput of code; these datasets remain unused and uninterpreted; and occupy wasted space-this phenomenon has been colloquially referred to as" data lake" problem. One approach toleverage these semi-structured datasets is to convert them into a structured relational format;following which they can be analyzed in conjunction with other datasets. We presentDatamaran; an tool that extracts structure from semi-structured log datasets with no humansupervision. Datamaran automatically identifies field and record endpoints; separates thestructured parts from the unstructured noise or formatting; and can tease apart multiplestructures from within a dataset; in order to efficiently extract structured relational datasetsfrom semi-structured log datasets; at scale with high accuracy. Compared to other …,arXiv preprint arXiv:1708.08905,2017,*
Adaptive Sampling for Rapidly Matching Histograms,Stephen Macke; Yiming Zhang; Silu Huang; Aditya Parameswaran,Abstract: In exploratory data analysis; analysts often have a need to identify histograms thatpossess a specific distribution; among a large class of candidate histograms; eg; findhistograms of countries whose income distribution is most similar to that of Greece. Thisdistribution could be a new one that the user is curious about; or a known distribution froman existing histogram visualization. At present; this process of identification is brute-force;requiring the manual generation and evaluation of a large number of histograms. Wepresent FastMatch: an end-to-end architecture for interactively retrieving the histogramvisualizations that are most similar to a user-specified target; from a large collection ofhistograms. The primary technical contribution underlying FastMatch is a sublinearalgorithm; HistSim; a theoretically sound sampling-based approach to identify the top-$ k …,arXiv preprint arXiv:1708.05918,2017,*
Interactive Data Exploration with Smart Drill-Down (Extended Version),Manas Joglekar; Hector Garcia-Molina; Aditya G Parameswaran,We present smart drill-down; an operator for interactively exploring a relational table todiscover and summarize “interesting” groups of tuples. Each group of tuples is described bya rule. For instance; the rule (a; b;?; 1000) tells us that there are a thousand tuples with valuea in the first column and b in the second column (and any value in the third column). Smartdrill-down presents an analyst with a list of rules that together describe interesting aspects ofthe table. The analyst can tailor the definition of interesting; and can interactively apply smartdrill-down on an existing rule to explore that part of the table. We demonstrate that theunderlying optimization problems are NP-HARD; and describe an algorithm for finding theapproximately optimal list of rules to display when the user uses a smart drill-down; and adynamic sampling scheme for efficiently interacting with large tables. Finally; we perform …,IEEE Transactions on Knowledge and Data Engineering,2017,*
ACM SIGMOD Record Volume 45 Issue 3,Yanlei Diao; Vanessa Braganholo; Marco Brambilla; Chee Yong Chan; Rada Chirkova; Zackary Ives; Anastasios Kementsietsidis; Jeffrey Naughton; Frank Neven; Olga Papaemmanoui; Aditya Parameswaran; Anish Das Sarma; Alkis Simitsis; Wang-Chiew Tan; Nesime Tatbul; Marianne Winslett; Jun Yang,Google; Inc. (search). SIGN IN SIGN UP. ACM SIGMOD Record. Volume 45 Issue 3; September2016 table of contents. Editors: Yanlei Diao; University of Massachusetts Amherst. VanessaBraganholo; Universidade Federal Fluminense. Marco Brambilla; Politecnico di Milano.,*,2016,*
Optimally Leveraging Density and Locality to Support LIMIT Queries,Albert Kim; Liqi Xu; Tarique Siddiqui; Silu Huang; Samuel Madden; Aditya Parameswaran,Abstract: Existing database systems are not optimized for queries with a LIMIT clause---operating instead in an all-or-nothing manner. In this paper; we propose a fast LIMIT queryevaluation engine; called NeedleTail; aimed at letting analysts browse a small sample of thequery results on large datasets as quickly as possible; independent of the overall size of theresult set. NeedleTail introduces density maps; a lightweight in-memory indexing structure;and a set of efficient algorithms (with desirable theoretical guarantees) to quickly locatepromising blocks; trading off locality and density. In settings where the samples are used tocompute aggregates; we extend techniques from survey sampling to mitigate the bias in oursamples. Our experimental results demonstrate that NeedleTail returns results 4x faster onHDDs and 9x faster on SSDs on average; while occupying up to 23x less memory than …,arXiv preprint arXiv:1611.04705,2016,*
Crowd-Powered Data Management,Aditya Parameswaran,Description The data management community has been historically (and perhapsmyopically) focused on processing SQL queries on ever larger datasets: what does thishave to do with crowdsourcing? This tutorial will convey how it helps to think of humans asrelational data processors for the purpose of designing optimized crowd-powered algorithmsand systems; in order to generate or process orders of magnitude more data at the samecost and same accuracy. The tutorial will also cover how the crowdsourcing work done bythe data management community fits in with the other communities; its successes andfailures; and open questions and potential opportunities for collaboration.,*,2016,*
It's just a matter of perspective (s): Crowd-Powered Consensus Organization of Corpora,Ayush Jain; Joon Young Seo; Karan Goel; Andrew Kuznetsov; Aditya Parameswaran; Hari Sundaram,Abstract: We study the problem of organizing a collection of objects-images; videos-intoclusters; using crowdsourcing. This problem is notoriously hard for computers to doautomatically; and even with crowd workers; is challenging to orchestrate:(a) workers maycluster based on different latent hierarchies or perspectives;(b) workers may cluster atdifferent granularities even when clustering using the same perspective; and (c) workersmay only see a small portion of the objects when deciding how to cluster them (andtherefore have limited understanding of the" big picture"). We develop cost-efficient; accuratealgorithms for identifying the consensus organization (ie; the organizing perspective mostworkers prefer to employ); and incorporate these algorithms into a cost-effective workflow fororganizing a collection of objects; termed ORCHESTRA. We compare our algorithms with …,arXiv preprint arXiv:1601.02034,2016,*
Navigating the data lake: Unsupervised structure extraction for text-formatted data,Yihan Gao; Silu Huang; Aditya Parameswaran,ABSTRACT Many organizations routinely accumulate automatically-generated semi-structured log file datasets; these datasets remain unused and occupy wasted space—thisphenomenon has been termed as the “data lake” problem. One approach to put thesedatasets to use is to convert them into a structured relational format; following which they canbe analyzed in conjunction with other datasets. To address this; we present CATAMARAN;an automatic structure extraction tool that requires no human supervision. CATAMARANautomatically identifies field and record endpoints; separates the structured parts from theunstructured noise or formatting; and can tease apart multiple structures from within adataset; in order to efficiently extract structured relational datasets from semi-structured logfiles; at scale with high accuracy. Compared to unsupervised adaptations of supervised …,*,2016,*
GeoHashViz: interactive analytics for mapping spatiotemporal diffusion of Twitter hashtags,Kiumars Soltani; Aditya Parameswaran; Shaowen Wang,Abstract Since its birth in 2006; Twitter has evolved to a multi-purpose social media thatattracts hundreds of millions of users to share their activities and ideas on a daily basis. Thepotential of capturing fine-grained activity log of users; combined with ever increasinggeographical information derived from GPS-enabled devices; has made Twitter data avaluable source for spatiotemporal analysis of human activities. One of the early innovationsof Twitter is the use of hashtag as a unique tagging mechanism to provide additionalinformation about a user post. From its emergence in late 2007; hashtags have been usedextensively to express ideas; group tweets and report events among Twitter users. Theincreasing popularity of hashtags; in addition to their simple and concise structure; hasinspired multiple recent studies to propose hashtag as a medium to assess diffusion of …,Proceedings of the 2015 XSEDE Conference: Scientific Advancements Enabled by Enhanced Cyberinfrastructure,2015,*
On the Interpretability of Conditional Probability Estimates in the Agnostic Setting,Yihan Gao; Aditya Parameswaran; Jian Peng,Abstract: We study the interpretability of conditional probability estimates for binaryclassification under the agnostic setting or scenario. Under the agnostic setting; conditionalprobability estimates do not necessarily reflect the true conditional probabilities. Instead;they have a certain calibration property: among all data points that the classifier haspredicted P (Y= 1| X)= p; p portion of them actually have label Y= 1. For cost-sensitivedecision problems; this calibration property provides adequate support for us to use BayesDecision Theory. In this paper; we define a novel measure for the calibration propertytogether with its empirical counterpart; and prove an uniform convergence result betweenthem. This new measure enables us to formally justify the calibration property of conditionalprobability estimations; and provides new insights on the problem of estimating and …,arXiv preprint arXiv:1506.03018,2015,*
Exploiting Correlations for Expensive Predicate Evaluation,Manas Joglekar; Hector Garcia-Molina; Aditya Parameswaran; Christopher Re,Abstract User Defined Function (UDFs) are used increasingly to augment query languageswith extra; application dependent functionality. Selection queries involving UDF predicatestend to be expensive; either in terms of monetary cost or latency. In this paper; we studyways to efficiently evaluate selection queries with UDF predicates. We provide a family oftechniques for processing queries at low cost while satisfying user-specified precision andrecall constraints. Our techniques are applicable to a variety of scenarios including whenselection probabilities of tuples are available beforehand; when this information is availablebut noisy; or when no such prior information is available. We also generalize our techniquesto more complex queries. Finally; we test our techniques on real datasets; and show thatthey achieve significant savings in UDF evaluations of up to $80\% $; while incurring only …,Proceedings of the 2015 ACM SIGMOD International Conference on Management of Data,2015,*
Aditya parameswaran speaks out on human-powered computation,Marianne Winslett; Vanessa Braganholo; Aditya Parameswaran,Abstract ACM SIGMOD Record's Series of Interviews with distinguished members of thedatabase community is presented. As a result; one needs to rely on humans as an integralpart of the computation. So the system; DataSift; figures out the right way of decomposingthis query into the set of small tasks that are done by humans; as well as automated tasks;which are done by the algorithm; and then combining the two to give accurate results. As itturns out; a lot of companies use crowdsourcing at a large scale. So companies likeMicrosoft; Google; Facebook; all of them use crowdsourcing at a large scale and they areoften ashamed to admit it because it is their secret sauce.,SIGMOD Record,2015,*
Exploiting Features for Data Source Quality Estimation.,Manas Joglekar; Theodoros Rekatsinas; Hector Garcia-Molina; Aditya Parameswaran; Christopher Ré,ABSTRACT We study the problem of estimating the quality of data sources in data fusionsettings. In contrast to existing models that rely only on conflicting observations acrosssources to infer quality (internal signals); we propose a data fusion model; called FUSE; thatcombines internal signals with external data-source features. We show both theoreticallyand empirically; that FUSE yields better quality estimates with rigorous guarantees; incontrast; models which utilize only internal signals have weaker or no guarantees. We studydifferent approaches for learning FUSE's parameters;(i) empirical risk minimization (ERM);which utilizes ground truth and relies on fast convex optimization methods; and (ii)expectation maximization (EM); which assumes no ground truth and uses slow iterativeoptimization procedures. EM is the standard approach used in most existing methods. An …,CoRR,2015,*
Indexing Cost Sensitive Prediction,Leilani Battle; Edward Benson; Aditya Parameswaran; Eugene Wu,Abstract: Predictive models are often used for real-time decision making. However; typicalmachine learning techniques ignore feature evaluation cost; and focus solely on theaccuracy of the machine learning models obtained utilizing all the features available. Wedevelop algorithms and indexes to support cost-sensitive prediction; ie; making decisionsusing machine learning models taking feature evaluation cost into account. Given an itemand a online computation cost (ie; time) budget; we present two approaches to return anappropriately chosen machine learning model that will run within the specified time on thegiven item. The first approach returns the optimal machine learning model; ie; one with thehighest accuracy; that runs within the specified time; but requires significant up-frontprecomputation time. The second approach returns a possibly sub-optimal machine …,arXiv preprint arXiv:1408.4072,2014,*
SIGMOD Jim Gray Doctoral Dissertation Award Talk,Aditya Parameswaran,*,Proceedings of the 2014 ACM SIGMOD International Conference on Management of Data,2014,*
Smart Drill-Down,Manas Joglekar; Hector Garcia-Molina; Aditya Parameswaran,ABSTRACT We present smart drill-down; an operator for interactively exploring a relationaltable to discover and summarize “interesting” groups of tuples. Each group of tuples isdescribed by a rule. For instance; the rule (a; b;⋆; 1000) tells us that there are a thousandtuples with value a in the first column and b in the second column (and any value in the thirdcolumn). Smart drill-down presents an analyst with a list of rules that together describeinteresting aspects of the table. The analyst can tailor the definition of interesting; and caninteractively apply smart drill-down on an existing rule to explore that part of the table. Wedemonstrate that the underlying optimization problems are NP-HARD; and describe analgorithm for finding the approximately optimal list of rules to display when the user uses asmart drill-down; and a dynamic sampling scheme for efficiently interacting with large …,Target,2014,*
HCOMP-13 Organization,Björn Hartmann; Eric Horvitz,Paul Bennett (Microsoft Research; USA) Michael Bernstein (Stanford University; USA) YilingChen (Harvard University; USA) Ed H. Chi (Google; USA) Lydia B. Chilton (University ofWashington; USA) Janis L. Dickinson (Cornell University; USA) Mike Franklin (University ofCalifornia; Berkeley; USA) Krzysztof Gajos (Harvard University; USA) Hector Garcia-Molina(Stanford University; USA) Jeffrey Heer (University of Washington; USA) Haym Hirsh (RutgersUniversity; USA) Panos Ipeirotis (New York University; USA) Adam Tauman Kalai (MicrosoftResearch; USA) Ece Kamar (Microsoft Research; USA) Henry Kautz (University ofRochester; USA) Andreas Krause (ETH Zurich; Switzerland) Edith Law (Harvard University;USA) Chris Lintott (Oxford University; UK) Greg Little (oDesk; USA) … Proceedings of the FirstAAAI Conference on Human Computation and Crowdsourcing … Mausam (University of …,First AAAI Conference on Human Computation and Crowdsourcing,2013,*
NEEDLETAIL: A System for Browsing Queries,Albert Kim; Samuel Madden; Aditya Parameswaran,ABSTRACT Analysts performing data exploration often browse; ie; pose a query and thenexamine the details of a small number of the resulting records (independent of the size of thequery result). In a typical session; analysts will start with one browsing query; examine a fewof the resulting records; and then repeatedly issue new browsing queries by adding orremoving predicates from their previous queries until they eventually gain a betterunderstanding of the dataset. Unfortunately; traditional database systems are notengineered towards browsing: instead; these systems operate in an all-or-nothing manner;taking as long as it takes to return the entire set of results; however large it may be. To thisend; we demonstrate NEEDLETAIL; a database system tailored towards an alternativedatabase query interaction paradigm: browsing. NEEDLETAIL makes efficient use of …,Proceedings of the VLDB Endowment,2013,*
in the Virtual extension,CACM Staff,Abstract To ensure the timely publication of articles; Communications created the VirtualExtension (VE) to expand the page limitations of the print edition by bringing readers thesame high-quality articles in an online-only format. VE articles undergo the same rigorousreview process as those in the print edition and are accepted for publication on merit. Thefollowing synopses are from articles now available in their entirety to ACM members via theDigital Library.,Communications of the ACM,2011,*
Regularization of Context Free Grammars,Aditya Parameswaran; Ankur Taly,*,*,2007,*
Use of the Bird Meertens Formalism,Ankur Taly; Aditya Parameswaran; Ankit Jain,Abstract In this report; we deal with the paradigm of Constructive Algorithmics or the scienceof program transformation. We examine the basic ideas of Bird Meertens Formalism and itsapplication to segment problems. We first give the direct application of Bird MeertensFormalism to the Maximum Segment Sum Problem; and also indicate the underlyingconcepts involved. We then proceed to give an intuitive proof for the Sliding Tails theorem;and demonstrate how it can be applied to a problem.,*,2007,*
Termination of Linear Programs,Aditya Parameswaran,*,*,2006,*
Abstract Interpretation for Model Checking,Aditya G Parameswaran,*,*,2006,*
SAT Solvers,Aditya Parameswaran; Luv Kumar,*,*,*,*
Scaling up to Billions of Cells with DATASPREAD: Supporting Large Spreadsheets with Databases,Mangesh Bendre; Vipul Venkataraman; Xinyan Zhou; Kevin Chen-Chuan Chang; Aditya Parameswaran,ABSTRACT Spreadsheet software is the tool of choice for ad-hoc tabular data management;manipulation; querying; and visualization with adoption by billions of users. However;spreadsheets are not scalable; unlike database systems. We develop DATASPREAD; asystem that holistically unifies databases and spreadsheets with a goal to work with massivespreadsheets: DATASPREAD retains all of the advantages of spreadsheets; including easeof use; ad-hoc analysis and visualization capabilities; and a schema-free nature; while alsoadding the scalability and collaboration abilities of traditional relational databases. Wedesign DATASPREAD with a spreadsheet front-end and a regular relational database back-end. To integrate spreadsheets and databases; in this paper; we develop a storage andindexing engine for spreadsheet data. We first formalize and study the problem of …,*,*,*
The magazine archive includes every article published in Communications of the ACM for over the past 50 years.,Hector Garcia-Molina; Georgia Koutrika; Aditya Parameswaran,All of us are faced with a" deluge of data" 2 in our workplaces and our homes: an ever-growing World Wide Web; digital books and magazines; photographs; blogs; tweets; emailmessages; databases; activity logs; sensor streams; online videos; movies and music; andso on. Thus; one of the fundamental problems in computer science has become even morecritical today: how to identify objects satisfying a user's information need. The goal is topresent to the user only information that is of interest and relevance; at the right place andtime.,Communications of the ACM,*,*
Prediction from Blog Data,Aditya Parameswaran; Eldar Sadikov; Petros Venetis,We have approximately one year's worth of blog posts from [1] with over 12 million webblogs tracked. On average there are 500 thousand blog posts per day. In this project; we areattempting to extract from the blog data the set of features that are predictive of the moviegross sales; critics ratings; and viewers ratings (collected by sites like [3]). Having gainedthis insight; we are applying machine learning techniques to make predictions on sales andratings for future movies. This is useful for example; to see if the 'buzz'surrounding a movie issufficient to obtain high sales; or whether additional marketing is required. In addition; wecould automatically figure out ratings of movies based on their mentions in blogs. This couldbe useful for movie rating sites like Rotten Tomatoes [3] and IMDB [4]; either to verify thecorrectness of ratings; or to 'seed'ratings for a new movie or a movie that did not exist in …,*,*,*
SAT Solvers,Aditya Parameswaran Luv Kumar,• State Independent• Focus on recent clauses► BerkMin method• Simliar to the Chaffmethod• When a conflict occurs; all literals in the clauses responsible for the conflict havetheir scores increased• Periodic divison by a constant• Branch on one of the variablespresent in the last added clause,*,*,*
Research Statement: Human-Powered Information Management,Aditya Parameswaran,With the amount of data recorded or produced every minute—100;000 tweets transmitted;200;000 queries issued on Google; and 48 hours of video shared on YouTube—it is criticalto quickly process and understand this data in order to enable data-driven applications. Forexample; during hurricane Sandy; around 400;000 images were uploaded to Instagram; animage sharing site. These images; if properly understood; could help identify areas that arebadly affected; how much water has accumulated; or how many people need assistance.However; this recorded or produced data can be “messy”: either not amenable to algorithmicanalysis; or algorithms to fully comprehend the data have not been developed. For thisreason; using humans to analyze certain aspects of the data can be crucial. Humans havean innate understanding of language; speech; and images; they are able to process …,*,*,*
