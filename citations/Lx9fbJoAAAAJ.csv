Solving Big Data Challenges for Enterprise Application Performance Management,Tilmann Rabl; Mohammad Sadoghi; Hans-Arno Jacobsen; Sergio Gómez-Villamor; Victor Muntés-Mulero; Serge Mankovskii,Abstract As the complexity of enterprise systems increases; the need for monitoring andanalyzing such systems also grows. A number of companies have built sophisticatedmonitoring tools that go far beyond simple resource utilization reports. For example; basedon instrumentation and specialized APIs; it is now possible to monitor single methodinvocations and trace individual transactions across geographically distributed systems. Thishigh-level of detail enables more precise forms of analysis and prediction but comes at theprice of high data rates (ie; big data). To maximize the benefit of data monitoring; the datahas to be stored for an extended period of time for ulterior analysis. This new wave of bigdata analytics imposes new challenges especially for the application performancemonitoring systems. The monitoring data has to be stored in a system that can sustain the …,Proceedings of the VLDB Endowment,2012,209
Efficient event processing through reconfigurable hardware for algorithmic trading,Mohammad Sadoghi; Martin Labrecque; Harsh Singh; Warren Shum; Hans-Arno Jacobsen,Abstract In this demo; we present fpga-ToPSS (Toronto Publish/Subscribe System Family);an efficient event processing platform for high-frequency and low-latency algorithmic trading.Our event processing platform is built over reconfigurable hardware---FPGAs---to achieveline-rate processing. Furthermore; our event processing engine supports Booleanexpression matching with an expressive predicate language that models complex financialstrategies to autonomously buy and sell stocks based on real-time financial data.,Proceedings of the VLDB Endowment,2010,81
BE-Tree: An index structure to efficiently match boolean expressions over high-dimensional discrete space,Mohammad Sadoghi; Hans-Arno Jacobsen,Abstract BE-Tree is a novel dynamic tree data structure designed to efficiently index Booleanexpressions over a high-dimensional discrete space. BE-Tree copes with both high-dimensionality and expressiveness of Boolean expressions by introducing a novel two-phase space-cutting technique that specifically utilizes the discrete and finite domainproperties of the space. Furthermore; BE-Tree employs self-adjustment policies todynamically adapt the tree as the workload changes. We conduct a comprehensiveevaluation to demonstrate the superiority of BE-Tree in comparison with state-of-the-artindex structures designed for matching Boolean expressions.,Proceedings of the 2011 ACM SIGMOD international conference on Management of data,2011,79
Benchmarking declarative approximate selection predicates,Amit Chandel; Oktie Hassanzadeh; Nick Koudas; Mohammad Sadoghi; Divesh Srivastava,Abstract Declarative data quality has been an active research topic. The fundamentalprinciple behind a declarative approach to data quality is the use of declarative statementsto realize data quality primitives on top of any relational data source. A primary advantage ofsuch an approach is the ease of use and integration with existing applications. Over the lastfew years several similarity predicates have been proposed for common quality primitives(approximate selections; joins; etc) and have been fully expressed using declarative SQLstatements. In this paper we propose new similarity predicates along with their declarativerealization; based on notions of probabilistic information retrieval. In particular we show howlanguage models and hidden Markov models can be utilized as similarity predicates for dataquality and present their full declarative instantiation. We also show how other scoring …,Proceedings of the 2007 ACM SIGMOD international conference on Management of data,2007,57
Multi-Query Stream Processing on FPGAs,Mohammad Sadoghi; Rija Javed; Naif Tarafdar; Harsh Singh; Rohan Palaniappan; Hans-Arno Jacobsen,We present an efficient multi-query event stream platform to support query processing overhigh-frequency event streams. Our platform is built over reconfigurable hardware--FPGAs--toachieve line-rate multi-query processing by exploiting unprecedented degrees of parallelismand potential for pipelining; only available through custom-built; application-specific and low-level logic design. Moreover; a multi-query event stream processing engine is at the core ofa wide range of applications including real-time data analytics; algorithmic trading; targetedadvertisement; and (complex) event processing.,Proceedings of 28th International Conference on Data Engineering (ICDE 2012),2012,33
Towards highly parallel event processing through reconfigurable hardware,Mohammad Sadoghi; Harsh Singh; Hans-Arno Jacobsen,Abstract We present fpga-ToPSS (Toronto Publish/Subscribe System); an efficient eventprocessing platform to support high-frequency and low-latency event matching. fpga-ToPSSis built over reconfigurable hardware---FPGAs---to achieve line-rate processing by exploringvarious degrees of parallelism. Furthermore; each of our proposed FPGA-based designs isgeared towards a unique application requirement; such as flexibility; adaptability; scalability;or pure performance; such that each solution is specifically optimized to attain a high level ofparallelism. Therefore; each solution is formulated as a design trade-off between the degreeof parallelism versus the desired application requirement. Moreover; our event processingengine supports Boolean expression matching with an expressive predicate languageapplicable to a wide range of applications including real-time data analysis; algorithmic …,Proceedings of the 7th International Workshop on Data Management on New Hardware (DaMoN 2011),2011,30
Accuracy of approximate string joins using grams,Oktie Hassanzadeh; Mohammad Sadoghi; Renée J Miller,ABSTRACT Approximate join is an important part of many data cleaning and integrationmethodologies. Various similarity measures have been proposed for accurate and efficientmatching of string attributes. The accuracy of the similarity measures highly depends on thecharacteristics of the data such as amount and type of the errors and length of the strings.Recently; there has been an increasing interest in using methods based on q-grams(substrings of length q) made out of the strings; mainly due to their high efficiency. In thiswork; we evaluate the accuracy of the similarity measures used in these methodologies. Wepresent an overview of several similarity measures based on q-grams. We then thoroughlycompare their accuracy on several datasets with different characteristics. Since the efficiencyof approximate joins depend on the similarity threshold they use; we study how the value …,Proceedings of the 5th International Workshop on Quality in Databases (QDB 2007),2007,25
Flexible query processor on FPGAs,Mohammadreza Najafi; Mohammad Sadoghi; Hans-Arno Jacobsen,Abstract In this work; we demonstrate Flexible Query Processor (FQP); an onlinereconfigurable event stream query processor. FQP is an FPGA-based query processor thatsupports select; project and join queries over event streams at line rate. While processingincoming events; FQP can accept new query expressions; a key distinguishing characteristicfrom related approaches employing FPGAs for acceleration. Our solution aims to addressperformance limitations experienced with general purpose processors needing to operate atline rate and lack of on the fly reconfigurability with custom designed hardware solutions onFPGAs.,Proceedings of the VLDB Endowment,2013,23
Relevance Matters: Capitalizing on Less (Top-k Matching in Publish/Subscribe),Mohammad Sadoghi; Hans-Arno Jacobsen,The efficient processing of large collections of Boolean expressions plays a central role inmajor data intensive applications ranging from user-centric processing and personalizationto real-time data analysis. Emerging applications such as computational advertising andselective information dissemination demand determining and presenting to an end-user onlythe most relevant content that is both user-consumable and suitable for limited screen realestate of target devices. To retrieve the most relevant content; we present BE*-Tree; a novelindexing data structure designed for effective hierarchical top-k pattern matching; which asits by-product also reduces the operational cost of processing millions of patterns. To furtherreduce processing cost; BE*-Tree employs an adaptive and non-rigid space-cuttingtechnique designed to efficiently index Boolean expressions over a high-dimensional …,2012 IEEE 28th International Conference on Data Engineering (ICDE),2012,23
Safe distribution and parallel execution of data-centric workflows over the publish/subscribe abstraction,Mohammad Sadoghi; Martin Jergler; Hans-Arno Jacobsen; Richard Hull; Roman Vaculin,In this work; we develop an approach for the safe distribution and parallel execution of data-centric workflows over the publish/subscribe abstraction. In essence; we design a uniquerepresentation of data-centric workflows; specifically designed to exploit the loosely coupledand distributed nature of publish/subscribe systems. Furthermore; we argue for thepracticality and expressiveness of our approach by mapping a standard and industry-strength data-centric workflow model; namely; IBM Business Artifacts with Guard-Stage-Milestone (GSM); into the publish/subscribe abstraction. In short; the contributions of thiswork are three-fold:(1) mapping of data-centric workflows into publish/subscribe to achievedistributed and parallel execution;(2) detailed theoretical analysis of the mapping; and (3)formulation of the complexity of the optimal workflow distribution over the publish …,IEEE Transactions on Knowledge and Data Engineering,2015,20
Making updates disk-I/O friendly using SSDs,Mohammad Sadoghi; Kenneth A Ross; Mustafa Canim; Bishwaranjan Bhattacharjee,Abstract Multiversion databases store both current and historical data. Rows are typicallyannotated with timestamps representing the period when the row is/was valid. We developnovel techniques for reducing index maintenance in multiversion databases; so that indexescan be used effectively for analytical queries over current data without being a heavy burdenon transaction throughput. To achieve this end; we re-design persistent index data structuresin the storage hierarchy to employ an extra level of indirection. The indirection level is storedon solid state disks that can support very fast random I/Os; so that traversing the extra levelof indirection incurs a relatively small overhead. The extra level of indirection dramaticallyreduces the number of magnetic disk I/Os that are needed for index updates; and localizesmaintenance to indexes on updated attributes. Further; we batch insertions within the …,Proceedings of the VLDB Endowment,2013,20
Analysis and optimization for boolean expression indexing,Mohammad Sadoghi; Hans-Arno Jacobsen,Abstract BE-Tree is a novel dynamic data structure designed to efficiently index Booleanexpressions over a high-dimensional discrete space. BE Tree-copes with both high-dimensionality and expressiveness of Boolean expressions by introducing an effective two-phase space-cutting technique that specifically utilizes the discrete and finite domainproperties of the space. Furthermore; BE-Tree employs self-adjustment policies todynamically adapt the tree as the workload changes. Moreover; in BE-Tree; we develop twonovel cache-conscious predicate evaluation techniques; namely; lazy and bitmapevaluations; that also exploit the underlying discrete and finite space to substantially reduceBE-Tree's matching time by up to 75&percnt; BE-Tree is a general index structure formatching Boolean expression which has a wide range of applications including (complex …,ACM Transactions on Database Systems (TODS),2013,19
CaSSanDra: An SSD boosted key-value store,Prashanth Menon; Tilmann Rabl; Mohammad Sadoghi; Hans-Arno Jacobsen,With the ever growing size and complexity of enterprise systems there is a pressing need formore detailed application performance management. Due to the high data rates; traditionaldatabase technology cannot sustain the required performance. Alternatives are the morelightweight and; thus; more performant key-value stores. However; these systems tend tosacrifice read performance in order to obtain the desired write throughput by avoidingrandom disk access in favor of fast sequential accesses. With the advent of SSDs; built uponthe philosophy of no moving parts; the boundary between sequential vs. random access isnow becoming blurred. This provides a unique opportunity to extend the storage memoryhierarchy using SSDs in key-value stores. In this paper; we extensively evaluate the benefitsof using SSDs in commercialized key-value stores. In particular; we investigate the …,Data Engineering (ICDE); 2014 IEEE 30th International Conference on,2014,16
Distributed ranked data dissemination in social networks,Kaiwen Zhang; Mohammad Sadoghi; Vinod Muthusamy; Hans-Arno Jacobsen,The amount of content served on social networks can overwhelm users; who must siftthrough the data for relevant information. To facilitate users; we develop and implementdissemination of ranked data in social networks. Although top-k computation can beperformed centrally at the user; the size of the event stream can constitute a significantbottleneck. Our approach distributes the top-k computation on an overlay network to reducethe number of events flowing through. Experiments performed using real Twitter andFacebook datasets with 5K and 30K query subscriptions demonstrate that social workloadsexhibit properties that are advantageous for our solution.,Distributed Computing Systems (ICDCS); 2013 IEEE 33rd International Conference on,2013,14
GPX-Matcher: a generic Boolean predicate-based XPath expression matcher,Mohammad Sadoghi; Ioana Burcea; Hans-Arno Jacobsen,Abstract Content-based architectures for XML data dissemination are gaining increasingattention both in academia and industry. These dissemination networks are the buildingblocks of selective information dissemination applications which have wide applicabilitysuch as sharing and integrating information in both scientific and corporate domains. At theheart of these dissemination services is a fast engine for matching of an incoming XMLmessage against stored XPath expressions to determine interested consumers for themessage. To achieve the ultra-low response time; predominant in financial messageprocessing; the XPath expression matching must be done efficiently. In this paper; wedevelop and evaluate a novel algorithm based on a unique encoding of XPath expressionsand XML messages; unlike dominating automaton-based algorithms; for efficiently …,Proceedings of the 14th International Conference on Extending Database Technology,2011,14
Towards vulnerability-based intrusion detection with event processing,Amer Farroukh; Mohammad Sadoghi; Hans-Arno Jacobsen,Abstract Computer systems continue to be breached despite substantial investments indefense mechanisms to stop attacks from propagating. The accuracy of current intrusiondetection systems (IDSes) is hindered by the limited capability of regular expressions (REs)to express the exact vulnerability. Recent advances have proposed vulnerability-basedIDSes that parse traffic and retrieve protocol semantics to describe the vulnerability. Such adescription of attacks is analogous to subscriptions that specify events of interest in eventprocessing systems. However; the matching engine of state-of-the-art IDSes lacks efficientmatching algorithms that can process many signatures simultaneously. In this work; weplace event processing in the core of the IDS and propose novel algorithms to efficientlymatch vulnerability signatures. Also; we are among the first to detect complex attacks …,Proceedings of the 5th ACM International Conference on Distributed Event-Based Systems (ACM DEBS 2011),2011,13
Configurable hardware-based streaming architecture using online programmable-blocks,Mohammadreza Najafi; Mohammad Sadoghi; Hans-Arno Jacobsen,The limitations of traditional general-purpose processors have motivated the use ofspecialized hardware solutions (eg; FPGAs) to achieve higher performance in streamprocessing. However; state-of-the-art hardware-only solutions have limited support to adaptto changes in the query workload. In this work; we present a reconfigurable hardware-basedstreaming architecture that offers the flexibility to accept new queries and to change existingones without the need for expensive hardware reconfiguration. We introduce the OnlineProgrammable Block (OP-Block); a” Lego-like” connectable stream processing element; forconstructing a custom Flexible Query Processor (FQP); suitable to a wide range of datastreaming applications; including real-time data analytics; information filtering; intrusiondetection; algorithmic trading; targeted advertising; and complex event processing …,Data Engineering (ICDE); 2015 IEEE 31st International Conference on,2015,12
Reducing database locking contention through multi-version concurrency,Mohammad Sadoghi; Mustafa Canim; Bishwaranjan Bhattacharjee; Fabian Nagel; Kenneth A Ross,Abstract In multi-version databases; updates and deletions of records by transactionsrequire appending a new record to tables rather than performing in-place updates. Thismechanism incurs non-negligible performance overhead in the presence of multiple indexeson a table; where changes need to be propagated to all indexes. Additionally; anuncommitted record update will block other active transactions from using the index to fetchthe most recently committed values for the updated record. In general; in order to supportsnapshot isolation and/or multi-version concurrency; either each active transaction is forcedto search a database temporary area (eg; roll-back segments) to fetch old values of desiredrecords; or each transaction is forced to scan the entire table to find the older versions of therecord in a multi-version database (in the absence of specialized temporal indexes). In …,Proceedings of the VLDB Endowment,2014,12
Predicting Drug-Drug Interactions through Large-Scale Similarity-Based Link Prediction,Achille Fokoue; Mohammad Sadoghi; Oktie Hassanzadeh; Ping Zhang,Abstract Drug-Drug Interactions (DDIs) are a major cause of preventable adverse drugreactions (ADRs); causing a significant burden on the patients' health and the healthcaresystem. It is widely known that clinical studies cannot sufficiently and accurately identify DDIsfor new drugs before they are made available on the market. In addition; existing public andproprietary sources of DDI information are known to be incomplete and/or inaccurate and sonot reliable. As a result; there is an emerging body of research on in-silico prediction of drug-drug interactions. We present Tiresias; a framework that takes in various sources of drug-related data and knowledge as inputs; and provides DDI predictions as outputs. The processstarts with semantic integration of the input data that results in a knowledge graph describingdrug attributes and relationships with various related entities such as enzymes; chemical …,Proceedings of 13th European Semantic Web Conference (ESWC 2016),2016,11
D2WORM: A management infrastructure for distributed data-centric workflows,Martin Jergler; Mohammad Sadoghi; Hans-Arno Jacobsen,Abstract Unlike traditional activity-flow-based models; data-centric workflows primarily focuson the data to drive a business. This enables the unification of operational management;concurrent process analytics; compliance with process or associated data constraints; andadaptability to changing environments. In this demonstration; we present D2Worm; aDistributed Data-centric Workflow Management system. D2Worm allows users to (1)graphically model data-centric workflows in a declarative fashion based on the Guard-Stage-Milestone (GSM) meta-model;(2) automatically compile the modelled workflow into severalfine-granular workflow units (WFUs); and (3) deploy these WFUs on distributedinfrastructures. A WFU is a system component that manages a subset of the workflow's datamodel and; at the same time; represents part of the global control flow by evaluating …,Proceedings of the 2015 ACM SIGMOD International Conference on Management of Data,2015,10
fpga-ToPSS: line-speed event processing on fpgas,Mohammad Sadoghi; Harsh Singh; Hans-Arno Jacobsen,Abstract In this demo; we present fpga-ToPSS (a member of Toronto Publish/SubscribeSystem Family); an efficient event processing platform for high-frequency and low-latencyalgorithmic trading. Our event processing platform is built over reconfigurable hardware---FPGAs---to achieve line-rate processing. Furthermore; our event processing enginesupports Boolean expression matching with an expressive predicate language that modelscomplex financial strategies to autonomously mimic the buying and the selling of stocksbased on real-time financial data.,Proceedings of the 5th ACM international conference on Distributed event-based system,2011,10
Reducing database locking contention using multi-version data record concurrency control,*,Managing a multi-version data record database is provided. A mapping is maintainedbetween a logical record identifier and committed and uncommitted physical recordidentifiers corresponding to data records using an indirection mapping table. Entries areupdated within an index to point to the logical record identifier instead of the committed anduncommitted physical record identifiers. The committed physical record identifiercorresponding to a data record is read from the indirection mapping table to access acommitted version of the data record while a writer is modifying the data record to preventthe writer from blocking a reader. An uncommitted physical record identifier corresponding tothe data record is written in the indirection mapping table to insert a new uncommittedversion of the data record within a data table while the reader is reading the committed …,*,2016,9
Compressing a multi-version database,*,Managing a multi-version database is provided. A logical record identifier to physical recordrow identifier indirection mapping table on a solid-state storage device is extended toinclude a plurality of delta blocks. A delta block within the plurality of delta blocks ismaintained for each primary key in a plurality of primary keys associated with a data table ona magnetic hard disk storage device.,*,2016,9
Predicting Drug-Drug Interactions Through Similarity-Based Link Prediction Over Web Data,Achille Fokoue; Oktie Hassanzadeh; Mohammad Sadoghi; Ping Zhang,Abstract Drug-Drug Interactions (DDIs) are a major cause of preventable adverse drugreactions and a huge burden on public health and the healthcare system. On the other hand;there is a large amount of drug-related (open) data published on the Web; describingvarious properties of drugs and their relationships to other drugs; genes; diseases; andrelated concepts and entities. In this demonstration; we describe an end-to-end system wehave designed to take in various Web data sources as input and provide as output aprediction of DDIs along with an explanation of why two drugs may interact. The system firstcreates a knowledge graph out of input data sources through large-scale semanticintegration; and then performs link prediction among drug entities in the graph through large-scale similarity analysis and machine learning. The link prediction is performed using a …,Proceedings of the 25th International World Wide Web Conference (WWW),2016,8
The FQP vision: Flexible query processing on a reconfigurable computing fabric,Mohammadreza Najafi; Mohammad Sadoghi; Hans-Arno Jacobsen,Abstract The Flexible Query Processor (FQP) constitutes a family of hardware-based datastream processors that support dynamic changes to queries and streams; as well as staticchanges to the processor-internal fabric in order to maximize performance for givenworkloads. FQP is prototyped on field-programmable gate arrays (FPGAs). To this end; FQPsupports select; project and window-join queries over data streams. While processingincoming tuples; FQP can accept new queries; a key characteristic distinguishing FQP fromrelated approaches employing FPGAs for stream processing. In this paper; we present ourvision of FQP; focusing on few internal details to support the flexibility dimension; inparticular; the segment-at-a-time mechanism to realize processing of tuples of variablesizes. While many of these features are readily available in software; their hardware …,ACM SIGMOD Record,2015,8
Exploiting SSDs in operational multiversion databases,Mohammad Sadoghi; Kenneth A Ross; Mustafa Canim; Bishwaranjan Bhattacharjee,Abstract Multiversion databases store both current and historical data. Rows are typicallyannotated with timestamps representing the period when the row is/was valid. We developnovel techniques to reduce index maintenance in multiversion databases; so that indexescan be used effectively for analytical queries over current data without being a heavy burdenon transaction throughput. To achieve this end; we re-design persistent index data structuresin the storage hierarchy to employ an extra level of indirection. The indirection level is storedon solid-state disks that can support very fast random I/Os; so that traversing the extra levelof indirection incurs a relatively small overhead. The extra level of indirection dramaticallyreduces the number of magnetic disk I/Os that are needed for index updates and localizesmaintenance to indexes on updated attributes. Additionally; we batch insertions within the …,The VLDB Journal,2016,7
Solving Manufacturing Equipment Monitoring Through Efficient Complex Event Processing,Tilmann Rabl; Kaiwen Zhang; Mohammad Sadoghi; Navneet Kumar Pandey; Aakash Nigam; Chen Wang; Hans-Arno Jacobsen,*,Proceedings of the 6th ACM International Conference on Distributed Event-Based Systems (ACM DEBS 2012),2012,7
Grand challenge: the bluebay soccer monitoring engine,Hans-Arno Jacobsen; Kianoosh Mokhtarian; Tilmann Rabl; Mohammad Sadoghi; Reza Sherafat Kazemzadeh; Young Yoon; Kaiwen Zhang,Abstract This paper presents the design and implementation of a custom-built eventprocessing engine called BlueBay developed for live monitoring of soccer games. Weexperimentally evaluated our system using a real workload and report on its performance.Our results indicate that BlueBay achieves a throughput of up to 790k events per second;therefore processing the game's input sensor stream about 60 times faster than real-time. Inaddition to our custom implementation; we also investigated the applicability of off-the-shelfgeneral-purpose event processing engines to address the soccer monitoring problem. Thiseffort resulted in two additional and fully functional implementations based on Esper andStorm.,Proceedings of the 7th ACM international conference on Distributed event-based systems,2013,6
L-Store: A real-time OLTP and OLAP system,Mohammad Sadoghi; Souvik Bhattacherjee; Bishwaranjan Bhattacharjee; Mustafa Canim,Abstract: Arguably data is the new natural resource in the enterprise world with anunprecedented degree of proliferation. But to derive real-time actionable insights from thedata; it is important to bridge the gap between managing the data that is being updated at ahigh velocity (ie; OLTP) and analyzing a large volume of data (ie; OLAP). However; therehas been a divide where specialized solutions were often deployed to support either OLTPor OLAP workloads but not both; thus; limiting the analysis to stale and possibly irrelevantdata. In this paper; we present Lineage-based Data Store (L-Store) that combines the real-time processing of transactional and analytical workloads within a single unified engine byintroducing a novel lineage-based storage architecture. By exploiting the lineage; wedevelop a contention-free and lazy staging of columnar data from a write-optimized form …,arXiv preprint arXiv:1601.04084,2016,5
Joint Learning of Local and Global Features for Entity Linking via Neural Networks,Thien Huu Nguyen; Nicolas Fauceglia; Mariano Rodriguez Muro; Oktie Hassanzadeh; Alfio Massimiliano Gliozzo; Mohammad Sadoghi,Abstract Previous studies have highlighted the necessity for entity linking systems to capturethe local entity-mention similarities and the global topical coherence. We introduce a novelframework based on convolutional neural networks and recurrent neural networks tosimultaneously model the local and global features for entity linking. The proposed modelbenefits from the capacity of convolutional neural networks to induce the underlyingrepresentations for local contexts and the advantage of recurrent neural networks toadaptively compress variable length sequences of predictions for global constraints. Ourevaluation on multiple datasets demonstrates the effectiveness of the model and yields thestate-of-the-art performance on such datasets. In addition; we examine the entity linkingsystems on the domain adaptation setting that further demonstrates the cross-domain …,Proceedings of the 26th International Conference on Computational Linguistics (COLING),2016,5
Adaptive parallel compressed event matching,Mohammad Sadoghi; Hans-Arno Jacobsen,The efficient processing of large collections of patterns expressed as Boolean expressionsover event streams plays a central role in major data intensive applications ranging fromuser-centric processing and personalization to real-time data analysis. On the one hand;emerging user-centric applications; including computational advertising and selectiveinformation dissemination; demand determining and presenting to an end-user the relevantcontent as it is published. On the other hand; applications in real-time data analysis;including push-based multi-query optimization; computational finance and intrusiondetection; demand meeting stringent subsecond processing requirements and providinghigh-frequency event processing. We achieve these event processing requirements byexploiting the shift towards multi-core architectures by proposing novel adaptive parallel …,Data Engineering (ICDE); 2014 IEEE 30th International Conference on,2014,5
Location-based Matching in Publish/Subscribe Revisited,Mohammad Sadoghi; Hans-Arno Jacobsen,Abstract Event processing is gaining rising interest in industry and in academia. Thecommon application pattern is that event processing agents publish events while otheragents subscribe to events of interest. Extensive research has been devoted to developingefficient and scalable algorithms to match events with subscribers' interests. Thepredominant abstraction used in this context is the content-based publish/subscribe(pub/sub) paradigm for modeling an event processing application. Applications that havebeen referenced in this space include emerging applications in co-spaces that rely onlocation-based information [1; 7]; algorithmic trading and (financial) data dissemination [13];and intrusion detection system [4]. In this work; we focus primarily on the role of state-of-the-art matching algorithms in location-based pub/sub applications.,ACM/IFIP/USENIX 13th International Conference on Middleware (Middleware 2012),2012,5
Geo-distribution of flexible business processes over publish/subscribe paradigm,Martin Jergler; Mohammad Sadoghi; Hans-Arno Jacobsen,Abstract An increasing amount of business processes are inherently knowledge-intense andrequire ad-hoc decision making. Flexible modeling approaches such as the CaseManagement Model and Notation (CMMN) were designed to support such scenarios. At thesame time; many processes involve participants and data from different organizations acrossthe globe. Often; legal regulations such as data privacy render centralized executionengines impractical because data must be processed where it is collected. Instead;distributed approaches to coordinate process and data are necessary for supporting geo-scale execution. In this paper; we present a fully geo-distributed workflow engine thatimplements the core execution semantics of CMMN; the Guard-Stage-Milestone (GSM) meta-model; and supports locality of process data by distributing data and control-flow …,Proceedings of the 17th International Middleware Conference,2016,4
Safe distribution and parallel execution of data-centric workflows over the publish/subscribe abstraction,Matin Jergler; Hans-Arno Jacobsen; Mohammad Sadoghi; Richard Hull; Roman Vaculín,We present a unique representation of data-centric workflows; designed to exploit theloosely coupled nature of publish/subscribe systems to enable their safe distribution andparallel execution. We argue for the practicality of our approach by mapping a standard andindustry-strength data-centric workflow model; namely; IBM Business Artifacts with Guard-Stage-Milestone (GSM); into the publish/subscribe abstraction.,Data Engineering (ICDE); 2016 IEEE 32nd International Conference on,2016,4
SplitJoin: A Scalable; Low-latency Stream Join Architecture with Adjustable Ordering Precision,Hans-Arno Jacobsen Mohammadreza Najafi; Mohammad Sadoghi,*,USENIX Annual Technical Conference (USENIX ATC 2016),2016,4
Self-Curating Databases,Mohammad Sadoghi; Kavitha Srinivas; Oktie Hassanzadeh; Yuan-Chi Chang; Mustafa Canim; Achille Fokoue; Yishai Feldman,ABSTRACT The success of relational databases is due in part to the simplicity of the tabularrepresentation of data; the clear separation of the physical and logical view of data; and thesimple representation of the logical view (meta-data) as a flat schema. But we are nowwitnessing a paradigm shift owing to the explosion of data volume; variety and veracity; andas a result; there is a real need to knit together data that is naturally heterogeneous; butdeeply interconnected. To be useful in this world; we argue that today's tabular data modelmust evolve into a holistic data model that views meta-data as a new semantically richsource of data and unifies data and meta-data such that the data becomes descriptive.Furthermore; given the dynamicity of data; we argue that fundamental changes are neededin how data is consolidated continuously under uncertainty to make the data model …,Proceedings of the 19th International Conference on Extending Database Technology (EDBT),2016,3
Optimizing key-value stores for hybrid storage architectures,Prashanth Menon; Tilmann Rabl; Mohammad Sadoghi; Hans-Arno Jacobsen,Abstract Flash-based solid state drives (SSDs) are increasingly becoming a popular choiceas a storage device within database management systems and key-value stores alike. SSDsoffer fast throughput and low latency access to data; but their price-per-byte cost often makesthem uneconomical for exclusive use; especially in the era of big data workloads. A commonsolution to this problem is to augment existing database systems by adding smaller SSDsthat target only performance-critical areas. We believe this hybrid approach to be a stop-gapsolution. Rather than simply extending existing systems with SSDs; in this work wecompletely re-architect how a key-value database operates in a hybrid storage setting withboth small but fast SSDs and slower but high-capacity HDDs. We formulate an accurate I/Ocost model to study how popular key-value stores behave under several varying …,Proceedings of 24th Annual International Conference on Computer Science and Software Engineering,2014,3
Towards an extensible efficient event processing kernel,Mohammad Sadoghi,Abstract The efficient processing of large collections of patterns (Boolean expressions;XPath queries; or continuous SQL queries) over data streams plays a central role in majordata intensive applications ranging from user-centric processing and personalization to real-time data analysis. On the one hand; emerging user-centric applications; includingcomputational advertising and selective information dissemination; demand determiningand presenting to an end-user only the most relevant content that is both user-consumableand suitable for limited screen real estate of target (mobile) devices. We achieve these user-centric requirements through novel high-dimensional indexing structures and (parallel)algorithms. On the other hand; applications in real-time data analysis; includingcomputational finance and intrusion detection; demand meeting stringent subsecond …,Proceedings of the on SIGMOD/PODS 2012 PhD Symposium,2012,3
Pooling work across multiple transactions for reducing contention in operational analytics systems,*,A method includes scanning multiple incoming database transaction requests. Eachtransaction includes one or more operations. Operations are clustered into a set ofcombined operations based on type of operation constraints. Log records are prepared andwritten for re-performing operations upon system failures; and for undoing operations uponan operation or a transaction failing to be processed fully. Each set of combined operationsare performed within a thread. Each update operation is marked for a transaction withinwhich the update operation belongs. Recoverable update operations belonging to a pluralityof transactions are performed within a single logical thread of execution.,*,2017,2
Efficient performance of insert and point query operations in a column store,*,A method includes logically organizing; by an object hierarchy processor; data objects in afirst hierarchy. A portion of the data objects in the first hierarchy logically includes groupingsof other data objects. The object hierarchy processor physically organizes the data objectsacross two or more types of memory in a second hierarchy. Another portion of the dataobjects in the second hierarchy physically includes groupings of other data objects.Groupings of the data objects in the second hierarchy are dynamically moved across the twoor more types of memory. Levels of access of the data objects are tracked using a datastructure that maps groupings of the data objects in the first hierarchy onto metadatainformation including combined access frequencies of the data objects; and current numberof accessors to the data objects; in each grouping of the data objects.,*,2016,2
DL-Store: A distributed hybrid OLTP and OLAP data processing engine,Kaiwen Zhang; Mohammad Sadoghi; Hans-Arno Jacobsen,There has been a recent push in the database community towards supporting real-timeanalytical queries (OLAP) while sustaining a large volume of fine-grained updates (OLTP).Supporting these types of workloads require both an efficient data storage layer as well as adistributed architecture. In this demo; we address the latter point with our DistributedLineage-based Data Store (DL-Store); which is a distributed data processing engine. DL-Store is built on top of L-Store; which is a lineage-based storage architecture designed tohandle mixed OLTP and OLAP workloads; and provides scalability and elasticity bysupporting multiple L-Store nodes. To maintain the desired consistency semantics; DL-Storeemploys a distributed transaction handler component which can horizontally scaled byprovisioning additional transaction manager nodes. We leverage partitioning in the …,Distributed Computing Systems (ICDCS); 2016 IEEE 36th International Conference on,2016,2
Accelerating database workloads by software-hardware-system co-design,Rajesh R Bordawekar; Mohammad Sadoghi,The key objective of this tutorial is to provide a broad; yet an in-depth survey of the emergingfield of co-designing software; hardware; and systems components for acceleratingenterprise data management workloads. The overall goal of this tutorial is two-fold. First; weprovide a concise system-level characterization of different types of data managementtechnologies; namely; the relational and NoSQL databases and data stream managementsystems from the perspective of analytical workloads. Using the characterization; we discussopportunities for accelerating key data management workloads using software andhardware approaches. Second; we dive deeper into the hardware acceleration opportunitiesusing Graphics Processing Units (GPUs) and Field-Programmable Gate Arrays (FPGAs) forthe query execution pipeline. Furthermore; we explore other hardware acceleration …,Data Engineering (ICDE); 2016 IEEE 32nd International Conference on,2016,2
Supporting transient snapshot with coordinated/uncoordinated commit protocol,*,Methods and a system are provided. A method includes maintaining an in-page log forrecords in each of a plurality of data pages of a multi-version database. The method furtherincludes adding record update information to the in-page log when a corresponding one ofthe records is deleted or updated. The method also includes consulting the in-page log for arecently updated one of the records or a recently deleted one of the records to determine arecord status thereof. The method additionally includes spilling; by a processor-basedoverflow manager; to overflow pages when the in-page log is full. The data pages includeany of row-oriented data pages and column-oriented data pages.,*,2016,2
Annotating Web Tables Through Ontology Matching,Vasilis Efthymiou; Oktie Hassanzadeh; Mohammad Sadoghi; Mariano Rodriguez-Muro,Web tables have been proven to constitute valuable sources of information for applications;ranging from Web search; to data discovery in spreadsheet software and KB augmentation[1]. A requirement for those applications is to understand the semantics of Web tables andpotentially match their contents with existing URIs in the Web of Data; a process known asWeb table annotation [4]. Recent works on Web table annotation follow an iterativeapproach between instance-and schema-level refinements; until convergence [6; 7]. In thiswork; we annotate Web tables using ontology matching. As this field has solid tools andbenchmarks3; we design a framework that provides the required input to any ontologymatching tool; resulting in Web table annotations. Moreover; our blocking enables even theless scalable ontology matching tools provide annotations to large-scale KBs; such as …,Proceedings of the 11th International Workshop on Ontology Matching,2016,2
Poster: MADES-a multi-layered; adaptive; distributed event store,Tilmann Rabl; Mohammad Sadoghi; Kaiwen Zhang; Hans-Arno Jacobsen,Abstract Application performance monitoring (APM) is shifting towards capturing andanalyzing every event that arises in an enterprise infrastructure. Current APM systems; forexample; make it possible to monitor enterprise applications at the granularity of tracingeach method invocation (ie; an event). Naturally; there is great interest in monitoring theseevents in real-time to react to system and application failures and in storing the capturedinformation for an extended period of time to enable detailed system analysis; data analytics;and future auditing of trends in the historic data. However; the high insertion-rates (up tomillions of events per second) and the purposely limited resource; a small fraction of allenterprise resources (ie; 1-2% of the overall system resources); dedicated to APM are thekey challenges for applying current data management solutions in this context. Emerging …,Proceedings of the 7th ACM international conference on Distributed event-based systems,2013,2
eQoSystem: supporting fluid distributed service-oriented workflows,Vinod Muthusamy; Young Yoon; Mohammad Sadoghi; Hans-Arno Jacobsen,Many distributed applications have emerged as Web mashups [1]; as well as loosely-coupled decentralized services predominant in a business ecosystem [3]. Many of theseapplications are implemented as service-oriented workflows and operated over cloudinfrastructures. As a result; these applications demand agile development processes andlow-touch maintenance life-cycles. Furthermore; in the cloud environment; applicationdevelopers must account for the complex multi-tiered ecosystem that includes the servicesand resources they depend on; but which none of the developers have much control over.Therefore; it is essential for application developers to have tools that proactively adapt theapplication to the changes of the underlying ecosystem. We meet this need througheQoSystem 1; a framework that provides distributed workflow processing; declarative …,Proceedings of the 5th ACM international conference on Distributed event-based system,2011,2
Database query processing using horizontal data record alignment of multi-column range summaries,*,Organizing data within a database is provided. In response to determining that a group ofcoarsified data records within a database table is not an aligned group of data records; avirtually replicated subgroup of coarsified data records that corresponds to the group ofcoarsified data records is generated from different groups of coarsified data records withinthe database table. The virtually replicated subgroup of coarsified data records is alignedwith the corresponding group of coarsified data records.,*,2017,1
Rendezvous-based optimistic concurrency control,*,There is a paradigm shift in transaction processing (OLTP) from perspectives of both hardwareand software. The hardware trends are toward a cheaper and larger main-memory and largernumbers of cores per processor. These trends are paving the way for OLTP databases to becomeentirely memory-resident (substantially faster latency) and to potentially support more concurrentenvironment (substantially faster throughput). The software trend is the rise of multi-version databasesthat avoid in-place updates of records and retain the history of data (the old and new versionsof the modified record) … For state of the art optimistic models; transactions follow a strict serialpath as follows: (i) reading a set of records (read phase); (ii) performing any arbitrary computation(compute phase); (iii) validating that the read records have not been changed by other transactions(validate phase); (iv) writing a set of records (write phase); and (v) committing the …,*,2017,1
Subscription covering for relevance-based filtering in content-based publish/subscribe systems,Kaiwen Zhang; Vinod Muthusamy; Mohammad Sadoghi; Hans-Arno Jacobsen,Large-scale applications require a scalable data dissemination service with advancedfiltering capabilities. We propose the use of a content-based publish/subscribe system withsupport for top-k filtering in the context of such applications. We focus on the problem of top-k subscription filtering; where a publication is delivered only to the k highest scoringsubscribers. The naive approach to perform filtering early at the publisher edge works only ifcomplete knowledge of the subscriptions is available; which is not compatible with the well-established covering optimization in scalable content-based publish/subscribe systems. Wepropose an efficient rank-cover technique to reconcile top-k subscription filtering withcovering. We extend the covering model to support top-k and describe a novel algorithm forforwarding subscriptions to publishers while maintaining correctness. Finally; we …,Distributed Computing Systems (ICDCS); 2017 IEEE 37th International Conference on,2017,1
Large-scale structural and textual similarity-based mining of knowledge graph to predict drug–drug interactions,Ibrahim Abdelaziz; Achille Fokoue; Oktie Hassanzadeh; Ping Zhang; Mohammad Sadoghi,Abstract Drug–Drug Interactions (DDIs) are a major cause of preventable Adverse DrugReactions (ADRs); causing a significant burden on the patients' health and the healthcaresystem. It is widely known that clinical studies cannot sufficiently and accurately identify DDIsfor new drugs before they are made available on the market. In addition; existing public andproprietary sources of DDI information are known to be incomplete and/or inaccurate and sonot reliable. As a result; there is an emerging body of research on in-silico prediction of drug–druginteractions. In this paper; we present Tiresias; a large-scale similarity-based frameworkthat predicts DDIs through link prediction. Tiresias takes in various sources of drug-relateddata and knowledge as inputs; and provides DDI predictions as outputs. The process startswith semantic integration of the input data that results in a knowledge graph describing …,Web Semantics: Science; Services and Agents on the World Wide Web,2017,1
Reducing the cost of update; delete; and append-only insert operations in a database,*,A first request may be received to update a first set of values. The first set of values may bestored at a first location within a first data page of a database. The first location may be read-only. In response to the receiving of the first request; a first set of records may be insertedinto a second data page. The first set of records may include the update of the first set ofvalues. In response to the inserting; a forward pointer may be stored in the first data pagethat points to the first set of records on the second data page. One or more committed valuesmay be identified on the second data page. In response to the identifying; the one or morecommitted values may be merged from the second data page to a third data page.,*,2017,1
Kanzi: A distributed; in-memory key-value store,Masoud Hemmatpour; Bartolomeo Montrucchio; Maurizio Rebaudengo; Mohammad Sadoghi,Abstract Traditional database systems either sacrifice availability or partitionability at the costof offering strict consistency guarantee of data. However; the significant growth of Web-scaleapplications and the wider array of emerging workloads demand revisiting the need for fulltransactional consistency. One new dominant class of workload is the ability to efficientlysupport single statement transaction consisting of either Get or Put operation; thus;simplifying the consistency model. These simple workloads have given rise to decade-longefforts for building efficient key-value stores that often rely on disk-resident and log-structured storage model that is distributed across many machines. To further expand thescope of key-value stores; in this paper; we introduce Kanzi; a distributed; in-memory key-value stored over shared-memory architecture enabled by remote direct memory access …,Proceedings of the Posters and Demos Session of the 17th International Middleware Conference,2016,1
Accelerating multiversion concurrency control using hardware transactional memory,*,Atomically updating shared data in a transactional memory system comprising transactionalmemory storage and a transactional memory enabled processor. The computer creates apointer stored in a stable memory location that is used to locate a shared data stored in asecond memory location. The computer accesses the shared data and loads the pointerused to locate the accessed shared data into transactional memory storage. The computerupdates the accessed shared data using copy-on-write; whereby the updated shared data isstored in a third memory location; and performs the atomic update of the shared data byupdating the pointer such that it locates the updated shared data stored in the third memorylocation.,*,2016,1
Managing a multi-version database,*,Managing different versions of a data record is provided. A mapping is maintained betweena version-independent logical record identifier and a version-dependent physical record rowidentifier that correspond to each data record within a plurality of data records of a data tableusing a logical record identifier to physical record row identifier indirection mapping table.Entries within leaf pages of an index associated with the data table are updated to point tothe version-independent logical record identifier corresponding to a data record instead ofpointing to the version-dependent physical record row identifier corresponding to the datarecord. The logical record identifier to physical record row identifier indirection mappingtable is updated in response to performing an operation on the data record instead ofupdating the entries within the leaf pages of the index associated with the data table.,*,2016,1
Pre-filtering of join execution over multi-column range summaries and other synopses,*,Abstract Techniques are provided for pre-filtering of join execution over multi-column rangesummaries and other synopses. An exemplary method comprises maintaining a synopsis fora plurality of data tables; wherein a given synopsis summarizes a set of records in acorresponding data table; and; in response to a request for a join operation for a set of thedata tables: joining the synopses associated with the set of data tables to generate a joinedsynopsis; for joined records in the joined synopsis; obtaining corresponding records from theset of data tables as candidate records; and joining the candidate records. Two or more ofthe set of data tables can be distributed across a plurality of nodes and the synopses can bereplicated and/or broadcasted across the plurality of nodes. Incremental updates tobroadcasted and/or replicated synopses are optionally provided to at least one node.,*,2018,*
Expressive Temporal Predictions Over Semantically Driven Time Windows,*,Abstract Methods; systems; and computer program products for expressive temporalpredictions over semantically-driven time windows are provided herein. A computer-implemented method includes identifying; within a knowledge graph pertaining to a givenprediction; a subset of the knowledge graph related to one or more predicted trainingexamples; wherein the subset comprises (i) a set of nodes and (ii) one or more relationshipsamong the set of nodes; determining; for the identified subset; one or more snapshots of theknowledge graph relevant to the given prediction; quantifying a validity window for the oneor more predicted training examples; wherein the validity window comprises a temporalbound for prediction validity; and computing a validity window for the given prediction basedon the quantified validity window for the one or more predicted training examples.,*,2018,*
Methods and Apparatus for Incremental Frequent Subgraph Mining on Dynamic Graphs,*,Abstract Methods and apparatus are provided for incremental frequent subgraph mining ondynamic graphs are provided. An exemplary subgraph mining method comprisesmaintaining a set of embeddings comprising matching embeddings of a given subgraph inan input graph; maintaining a first fringe set of subgraphs comprising subgraphssubstantially on a fringe of frequent subgraphs in the input graph that satisfy a predefinedsupport threshold; maintaining a second fringe set of subgraphs comprising subgraphssubstantially on a fringe of infrequent subgraphs in the input graph that do not satisfy thepredefined support threshold; for an edge addition; checking a support of the subgraphs inthe second fringe set based on the set of the embeddings and searching for newembeddings created by the edge addition; and for an edge deletion; removing obsolete …,*,2018,*
In-memory latch-free index structure,*,Abstract In an approach for supporting queries for hash-based data structures; a processorcreates an ordered set of seeds; wherein the ordered set of seeds are a subset of values in akey domain. A processor links each hashed key of a plurality of hashed keys to at leastanother hashed key of the plurality of hashed keys using the ordered set of seeds; whereinthe ordered set of seeds allows retrieval access to data located in the hash-based datastructure.,*,2018,*
Efficient covering for top-k filtering in content-based publish/subscribe systems,Kaiwen Zhang; Mohammad Sadoghi; Vinod Muthusamy; Hans-Arno Jacobsen,Abstract We investigate the use of content-based publish/subscribe for data dissemination inlarge-scale applications with expressive filtering requirements. In particular; we focus on top-k subscription filtering; where a publication is delivered only to the k best rankedsubscribers; as ordered using expressive semantics such as relevance; fairness; anddiversity. The naive approach to perform filtering early at the publisher edge works only ifcomplete knowledge of the subscriptions is available; which is not compatible with the well-established covering optimization in scalable content-based publish/subscribe systems. Wepropose an efficient rank-cover technique to reconcile top-k subscription filtering withcovering. We extend the covering model to support top-k and describe a novel algorithm forforwarding subscriptions to publishers while maintaining correctness. We also establish a …,Proceedings of the 18th ACM/IFIP/USENIX Middleware Conference,2017,*
Incremental Frequent Subgraph Mining on Large Evolving Graphs,Ehab Abdelhamid; Mustafa Canim; Mohammad Sadoghi; Bishwaranjan Bhattacharjee; Yuan-Chi Chang; Panos Kalnis,Frequent subgraph mining is a core graph operation used in many domains; such as graphdata management and knowledge exploration; bioinformatics; and security. Most existingtechniques target static graphs. However; modern applications; such as social networks;utilize large evolving graphs. Mining these graphs using existing techniques is infeasible;due to the high computational cost. In this paper; we propose IncGM+; a fast incrementalapproach for continuous frequent subgraph mining on a single large evolving graph. Weadapt the notion of “fringe” to the graph context; that is the set of subgraphs on the borderbetween frequent and infrequent subgraphs. IncGM+ maintains fringe subgraphs andexploits them to prune the search space. To boost the efficiency; we propose an efficientindex structure to maintain selected embeddings with minimal memory overhead. These …,IEEE Transactions on Knowledge and Data Engineering,2017,*
Empowering In-Memory Relational Database Engines with Native Graph Processing,Mohamed S Hassan; Tatiana Kuznetsova; Hyun Chai Jeong; Walid G Aref; Mohammad Sadoghi,Abstract: The plethora of graphs and relational data give rise to many interesting graph-relational queries in various domains; eg; finding related proteins satisfying relationalpredicates in a biological network. The maturity of RDBMSs motivated academia andindustry to invest efforts in leveraging RDBMSs for graph processing; where efficiency isproven for vital graph queries. However; none of these efforts process graphs natively insidethe RDBMS; which is particularly challenging due to the impedance mismatch between therelational and the graph models. In this paper; we propose to treat graphs as first-classcitizens inside the relational engine so that operations on graphs are executed nativelyinside the RDBMS. We realize our approach inside VoltDB; an open-source in-memoryrelational database; and name this realization GRFusion. The SQL and the query engine …,arXiv preprint arXiv:1709.06715,2017,*
Sufism and Optimal Health,Saloumeh Bozorgzadeh; Nasim Bahadorani; Mohammad Sadoghi,Sufism is known as the mystical dimension of Islam. 1 As described by His HolinessSalaheddin Ali Nader Angha; Sufism is “the reality of religion”(2011; p. 91). This means“experiencing God in one's inner self; submitting to Him; and loving Him with one's mind;heart; and soul; until no other but the Beloved remains”(Angha 2000b; p. 3). Thus; Sufism isa “way of love; a way of devotion; and a way of knowledge”(Angha 2003; p. 35). Its teachingspromote physical; cognitive; emotional; and spiritual health; which enables one to attain astate of balance: oneness with the Divine Beloved. There are different orders in IslamicSufism; and their practices vary. This chapter focuses on the health-oriented teachings of theMaktab Tarighat Oveyssi (MTO) Shahmaghsoudi®; School of Islamic Sufism®. His HolinessSalaheddin Ali Nader Angha; or Professor Angha2 as he is referred to by his students; is …,Better Health through Spiritual Practices: A Guide to Religious Behaviors and Perspectives that Benefit Mind and Body,2017,*
Vectorized graph processing,*,An input graph is decomposed into a graph topology component and a graph propertiescomponent. A matrix representation is generated for each of the graph topology componentand the graph properties component. Each of the graph topology matrix representation andgraph properties matrix representation are partitioned into one or more sub-matrices. Aforward pass comprising one or more vectorized operations is performed over the one ormore sub-matrices. An output matrix is generated in response to the performing step.,*,2017,*
Real-time capture and translation of human thoughts and ideas into structured patterns,*,Examples of techniques for the real-time capture and translation of human thoughts andideas into structured patterns are disclosed. In one example implementation according toaspects of the present disclosure; a computer-implemented method may include capturing;by a processing device; unstructured data. The method may also include extracting keyterms from the unstructured data. Additionally; the method may include assigning anattribute to at least one of the key terms. The method may further include generating; by theprocessing device; a structured pattern based on the key terms and the attributes.,*,2017,*
Adaptive concurrency control using hardware transactional memory and locking mechanism,*,A method includes the following steps. Runtime statistics related to data transactionprocessing in a concurrent system are collected. A given request to access shared data inthe concurrent system is receive. Based on the collected runtime statistics; the number ofreattempts the given request can make to access the shared data prior to access controlbeing switched from a hardware transactional memory to a locking mechanism is adaptivelydetermined.,*,2017,*
System; method; and recording medium for knowledge graph augmentation through schema extension,*,A method; system; and recording medium for knowledge graph augmentation using databased on a statistical analysis of attributes in the data; including mapping classes; attributes;and instances of the classes of the data; indexing semantically similar input data elementsbased on the mapped data using at least one of a label-based analysis; a content-basedanalysis; and an attribute-based clustering; and ranking the semantically similar input dataelements to create a ranked list.,*,2017,*
Prediction of adverse drug events,*,Embodiments include method; systems and computer program products for predictingadverse drug events on a computational system. Aspects include receiving known drug datafrom drug databases and one or more of a candidate drug; a drug pair; and a candidate drug-patient pair. Aspects also include calculating an adverse event prediction ratingrepresenting a confidence level of an adverse drug event for the candidate drug; a drug pair;and a candidate drug-patient pair; the rating being based on the known drug data. Aspectsalso include associating adverse event features with the candidate drug; drug pair; or acandidate drug-patient pair; including a nature; cause; mechanism; or severity of theadverse drug event. Aspects also include calculating and outputting an adverse eventprediction rating.,*,2017,*
Prediction of adverse drug events,*,Embodiments include method; systems and computer program products for predictingadverse drug events on a computational system. Aspects include receiving known drug datafrom drug databases and one or more of a candidate drug; a drug pair; and a candidate drug-patient pair. Aspects also include calculating an adverse event prediction ratingrepresenting a confidence level of an adverse drug event for the candidate drug; a drug pair;and a candidate drug-patient pair; the rating being based on the known drug data. Aspectsalso include associating adverse event features with the candidate drug; drug pair; or acandidate drug-patient pair; including a nature; cause; mechanism; or severity of theadverse drug event. Aspects also include calculating and outputting an adverse eventprediction rating.,*,2017,*
Supporting updatable repeated values over variable schema,*,Data within a database is partitioned into one or more sets of read-only data pages and oneor more sets of append-only data pages; wherein each set of read-only data pages isassociated to one of the one or more sets of append-only data pages. A repeated map ismaintained for at least one of the one or more sets of append-only data pages. Anoperational position map is maintained for at least one of the one or more sets of append-only data pages. A request is received to update one or more records in a given set of read-only pages; wherein at least one of the one or more records comprises repeated values. Therepeated map and operational position map of the append-only pages associated with thegiven set of read-only pages are updated in response to the request. The one or more setsof append-only pages are automatically merged with their respective set of read-only …,*,2017,*
Data skipping and compression through partitioning of data,*,Conventionally; in addition to indexing; a synopsis of a base table of a database is used toskip and compress data. However; scanning of the entire synopsis for all queries is required;which takes a long time when the synopsis gets significantly big in a large data warehouse.A method for efficient data skipping and compression through vertical partitioning of data isprovided to eliminate the cost of synopsis storage overhead while enabling the synopsissearch functionality.,*,2017,*
Access frequency approximation for remote direct memory access,*,A method includes the following steps. One or more records are accessed from a databasememory bypassing a database access mechanism of a database system. Data representingaccess frequency of the one or more records are collected. The collected access frequencydata for the one or more records are maintained. The access frequency data for the one ormore records are aggregated until the access frequency reaches a threshold value. Theaggregated access frequency data are asynchronously reported for the one or more recordsto the database system.,*,2017,*
Hardware Acceleration Landscape for Distributed Real-time Analytics: Virtues and Limitations,Mohammadreza Najafi; Kaiwen Zhang; Hans-Arno Jacobsen; Mohammad Sadoghi,We are witnessing a technological revolution with a broad impact ranging from daily life (eg;personalized medicine and education) to industry (eg; data-driven healthcare; commerce;agriculture; and mining). At the core of this transformation lies" data". This transformation isfacilitated by embedded devices; collectively known as Internet of Things (IoT); whichproduce real-time feeds of sensor data which are collected and processed to produce adynamic physical model used for optimized real-time decision making. At the infrastructurelevel; there is a need to develop a scalable architecture for processing massive volumes ofpresent and historical data at an unprecedented velocity to support the IoT paradigm. Tocope with such extreme scale; we argue for the need to revisit the hardware and software co-design landscape in light of two key technological advancements. First is the virtualization …,37th IEEE International Conference on Distributed Computing Systems; ICDCS,2017,*
ExpoDB: An Exploratory Data Science Platform,Mohammad Sadoghi,ABSTRACT We are entering a new data era: on the one hand; we are witnessing anunprecedented explosion of data volume and variety; and on the other hand; the data is nowbecoming increasingly interconnected yet disconnected. To derive insights from data; thereis a pressing need to knit together a data model that is naturally heterogeneous while deeplyinterconnected. To construct a unified view of data; we must overcome the fundamentalmismatch in the way data and its meta-data are expressed in each source by making datamodel inherently descriptive—a step towards developing a unified data representation toserve as a common ground for fusing and exploring data. We argue that we mustfundamentally revisit how we cope with the dynamicity of data in order to offer a continuousconsolidation of data under uncertainty to make the data model inherently adaptive. We …,Proceedings of the of 8th Biennial Conference on Innovative Data Systems Research (CIDR),2017,*
Deep Embedded Joins,John Moore; Evan Hanau; Mohammad Sadoghi,*,*,2016,*
In-place updates with concurrent reads in a decomposed state,*,A method includes setting; by an update processor; a write latch in a first data structureassociated with an object. The first data structure is copied to a storage structure. A historytuple sequence number (TSN) of the first data structure is set to point to a TSN of the copiedfirst data structure. The version identifier is set to point to a transaction identification for theobject. Data portions are updated for the first data structure. The version identifier is readfrom the first data structure. It is determined whether the version identifier of the first datastructure is visible for a transaction including isolation requirements. If version identifier ofthe first data structure is visible; the first data structure is accessed and it is determinedwhether the version identifier of the first data structure changed since starting thetransaction.,*,2016,*
Towards Large-Scale Predictive Drug Safety: A Computational Framework for Inferring Drug Interactions Through Similarity-Based Link Prediction.,Achille Fokoue; Ping Zhang; Oktie Hassanzadeh; Mohammad Sadoghi,Drug-Drug Interactions (DDIs) may happen unexpectedly when more than one drugs are co-prescribed; causing serious side effects. Discovering and predicting DDIs will not onlyprevent life-threatening consequence in clinical practice; but also prompt safe drug co-prescriptions for better treatments. In this study; we propose a computational framework thattakes in various sources of drug-related data and knowledge as input; and provides asoutput a list of potential DDIs along with an explanation for each DDI.,AMIA,2016,*
Tiresias: Knowledge Engineering and Large-Scale Machine Learning for Interpretable Drug-Drug Interaction Prediction.,Achille Fokoue; Oktie Hassanzadeh; Mohammad Sadoghi; Ping Zhang,Abstract Accurate prediction of potential Drug-Drug Interactions (DDIs) is a majorrequirement both in drug development and in patient care. In this demonstration; we presentTiresias; a system that takes in heterogeneous sources of knowledge as input and providesas output an accurate and interpretable prediction of potential drug-drug interactions. Wewill show various components of the system that perform knowledge curation from publicsources of drug data; large-scale similarity analysis across all drugs using several similaritymeasures; and feature selection and efficient learning using a logistic regression model tonot only predict potential DDIs; but also explain the reason behind each prediction. We willshow an evaluation of the system using knowledge derived from an old drug database from2011; verifying the predictions and explanations with recently discovered interactions and …,AMIA,2016,*
3.8 Integrated Platforms for BPM & CEP,Mohammad Sadoghi Hamedani; Alejandro P Buchmann; Hans-Arno Jacobsen; Martin Jergler; Sankalita Mandal; Cesare Pautasso; Stefan Schulte; Jatinder Singh; Sergey Smirnov; Mathias Weske,*,Integrating Process-Oriented and Event-Based Systems,2016,*
Preplaying transactions that mix hot and cold data,*,Methods and systems for performing database transactions include executing a firsttransaction request in a preplay mode that locks the requested data with a prefetch-lock andreads one or more requested data items from storage into a main memory buffer; locking therequested data items with a read/write lock after said data items are read into the mainmemory buffer; and performing the requested transaction on the data items in the mainmemory buffer using a processor.,*,2015,*
Log data store that stores data across a plurality of storage devices using non-disjoint layers,*,Storing data records within a log data store is provided. The log data store that stores datarecords within a plurality of successive non-disjoint layers inserted across a plurality ofdifferent types of data storage devices associated with a data processing system isgenerated. A first non-disjoint layer of the plurality of successive non-disjoint layers isinserted within a main memory device. A set of intermediate non-disjoint layers of theplurality of successive non-disjoint layers is inserted within a set of storage-class memorydevices. A last non-disjoint layer of the plurality of successive non-disjoint layers is insertedwithin a hard disk drive. A size of each successive non-disjoint layer in the plurality ofsuccessive non-disjoint layers is increased exponentially. The data records are organizedinto the plurality of successive non-disjoint layers of the log data store inserted across the …,*,2015,*
Log data store that stores data across a plurality of storage devices using non-disjoint layers,*,Storing data records within a log data store is provided. The log data store that stores datarecords within a plurality of successive non-disjoint layers inserted across a plurality ofdifferent types of data storage devices associated with a data processing system isgenerated. A first non-disjoint layer of the plurality of successive non-disjoint layers isinserted within a main memory device. A set of intermediate non-disjoint layers of theplurality of successive non-disjoint layers is inserted within a set of storage-class memorydevices. A last non-disjoint layer of the plurality of successive non-disjoint layers is insertedwithin a hard disk drive. A size of each successive non-disjoint layer in the plurality ofsuccessive non-disjoint layers is increased exponentially. The data records are organizedinto the plurality of successive non-disjoint layers of the log data store inserted across the …,*,2015,*
Deferring data record changes using query rewriting,*,Staging data record changes from a faster storage medium to a slower storage mediumusing data query rewriting is provided. In response to receiving a data query correspondingto a particular data record; it is determined whether the data query is one of a transactionaldata query or an analytical data query. In response to determining that the data query is atransactional data query; the transactional data query is rewritten to apply transactional deltachanges to the particular data record on a storage-class memory of a computer. In responseto determining that the data query is an analytical data query; the analytical data query isrewritten to select and reconcile each data record corresponding to the particular datarecord stored on the storage-class memory with the particular data record stored on apersistent data storage device of the computer.,*,2015,*
Deferring data record changes using query rewriting,*,Staging data record changes from a faster storage medium to a slower storage mediumusing data query rewriting is provided. In response to receiving a data query correspondingto a particular data record; it is determined whether the data query is one of a transactionaldata query or an analytical data query. In response to determining that the data query is atransactional data query; the transactional data query is rewritten to apply transactional deltachanges to the particular data record on a storage-class memory of a computer. In responseto determining that the data query is an analytical data query; the analytical data query isrewritten to select and reconcile each data record corresponding to the particular datarecord stored on the storage-class memory with the particular data record stored on apersistent data storage device of the computer.,*,2015,*
The World Cup of Event Processing,Kaiwen Zhang; Hans-Arno Jacobsen; Kianoosh Mokhtarian; Tilmann Rabl; Mohammad Sadoghi; Reza Sherafat Kazemzadeh; Young Yoon,Zhang; Kaiwen et Jacobsen; Hans-Arno et Mokhtarian; Kianoosh et Rabl; Tilmann etSadoghi; Mohammad et Kazemzadeh; Reza Sherafat et Yoon; Young. 2014. « The World Cupof Event Processing ». Communication lors de la conférence : Big Data Research (Toronto;ON; Canada; July 16; 2014) … Le plein texte de ce document n'est pas hébergé sur ceserveur … Espace ÉTS version 2.0 École de technologie supérieure.,*,2014,*
An Efficient; Extensible; Hardware-aware Indexing Kernel,Mohammad Sadoghi Hamedani,Modern hardware has the potential to play a central role in scalable data managementsystems. A realization of this potential arises in the context of indexing queries; a recurringtheme in real-time data analytics; targeted advertising; algorithmic trading; and data-centricworkflows; and of indexing data; a challenge in multi-version analytical query processing. Toenhance query and data indexing; in this thesis; we present an efficient; extensible; andhardware-aware indexing kernel. This indexing kernel rests upon novel data structures and(parallel) algorithms that utilize the capabilities offered by modern hardware; especiallyabundance of main memory; multi-core architectures; hardware accelerators; and solid statedrives. This thesis focuses on presenting our query indexing techniques to cope withprocessing queries in data-intensive applications that are susceptible to ever increasing …,*,2013,*
Relevance Matters: Capitalizing on Less,Mohammad Sadoghi; Hans-Arno Jacobsen,A predicate P is a quadruple consisting of an attribute uniquely representing a dimension inn-dimensional space; an operator; a range of values; and an assigned predicate weightdenoted by P (attr; opt; val; wt). A predicate P (x) either accepts or rejects an input x such thatP: x−→{True; False}; where x∈ Dom (Pattr).,*,2012,*
Tech Report: Efficient Covering for Top-k Filtering in Content-Based Publish/Subscribe Systems,Kaiwen Zhang; Vinod Muthusamy; Mohammad Sadoghi; Hans-Arno Jacobsen,Abstract—Large-scale applications require a scalable data dissemination service withadvanced filtering capabilities. We propose the use of a content-based publish/subscribesystem with support for top-k filtering in the context of such applications. We focus on theproblem of top-k subscription filtering; where a publication is delivered only to the k bestranked subscribers. The naive approach to perform filtering early at the publisher edgeworks only if complete knowledge of the subscriptions is available; which is not compatiblewith the well-established covering optimization in scalable content-based publish/subscribesystems. We propose an efficient rank-cover technique to reconcile top-k subscriptionfiltering with covering. We extend the covering model to support top-k and describe a novelalgorithm for forwarding subscriptions to publishers while maintaining correctness. We …,*,*,*
Tiresias: Predicting Drug-Drug Interactions Through Large-Scale Similarity-Based Link Prediction,Achille Fokoue; Mohammad Sadoghi; Oktie Hassanzadeh; Ping Zhang,Page 1. Tiresias: Predicting Drug- Drug Interactions Through Large-Scale Similarity- Based LinkPrediction Achille Fokoue Mohammad Sadoghi Oktie Hassanzadeh Ping Zhang Page 2. AdverseDrug Reactions pose a serious challenge to the healthcare system Over 2 million $136 billionoften do not reveal rare toxicity of some drugs of in-hospital medication errors caused byunforeseen drug-drug interactions serious adverse drug reactions (ADRs) yearly: 100;000 deathsADR associated cost yearly ( > diabetic & cardiovascular care) Clinical Trials 3–5% Source:Flockhart et al.: Preventable adverse drug reactions: A focus on drug interactions. Centers forEducation & Research on Therapeutics Page 3. Similarity-based Drug-Drug Interaction (DDI)Predictions [Gottlieb et al.; Vilar et al.; Zhang et al.; etc.] • Inspired from content-basedrecommender systems: Predict the existence of an DDI through …,Clinical Trials,*,*
Distributed; Expressive Top-k Subscription Filtering using Covering in Publish/Subscribe Systems,Kaiwen Zhang; Vinod Muthusamy; Mohammad Sadoghi; Hans-Arno Jacobsen,Abstract—Top-k filtering is an effective way of reducing the amount of data sent tosubscribers in pub/sub applications. In this paper; we investigate top-k subscription filtering;where a publication is delivered only to the k best ranked subscribers. The naive approachto perform filtering early at the publisher edge broker works only if complete knowledge ofthe subscriptions is available; which is not compatible with the wellestablished coveringoptimization in publish/subscribe systems. We propose an efficient rank-cover technique toreconcile top-k subscription filtering with covering. We extend the covering model to supporttop-k and describe a novel algorithm for forwarding subscriptions to publishers whilemaintaining correctness. We also establish a framework for supporting different types ofranking semantics; such as fairness and diversity. Finally; we conduct an experiential …,*,*,*
