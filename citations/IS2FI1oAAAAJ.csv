Adaptive probabilistic search for peer-to-peer networks,Dimitrios Tsoumakos; Nick Roussopoulos,Peer-to-peer networks are gaining increasing attention from both the scientific and the largeInternet user community. Popular applications utilizing this new technology offer manyattractive features to a growing number of users. At the heart of such networks lies thesearch algorithm. Proposed methods either depend on the network-disastrous flooding andits variations or utilize various indices too expensive to maintain. We describe an adaptive;bandwidth-efficient algorithm for search in unstructured peer-to-peer networks; the adaptiveprobabilistic search method (APS). Our scheme utilizes feedback from previous searches toprobabilistically guide future ones. It performs efficient object discovery while inducing zerooverhead over dynamic network operations. Extensive simulation results show that APSachieves high success rates; increased number of discovered objects; very low …,Peer-to-Peer Computing; 2003.(P2P 2003). Proceedings. Third International Conference on,2003,449
A Comparison of Peer-to-Peer Search Methods.,Dimitrios Tsoumakos; Nick Roussopoulos,ABSTRACT Peer-to-Peer networks have become a major research topic over the last fewyears. Object location is a major part in the operation of these distributed systems. In thiswork; we present an overview of several search methods for unstructured peer-to-peernetworks. Popular file-sharing applications; through which enormous amounts of data aredaily exchanged; operate on such networks. We analyze the performance of the algorithmsrelative to their success rates; bandwidth consumption and adaptation to changingtopologies. Simulation results are used to empirically evaluate their behavior in directcomparison.,WebDB,2003,253
Analysis and comparison of P2P search methods,Dimitrios Tsoumakos; Nick Roussopoulos,Abstract The popularity attributed to current Peer-to-Peer applications makes the operationof these distributed systems very important for the Internet community. Efficient objectdiscovery is the first step towards the realization of distributed resource-sharing. In this work;we present a detailed overview of existing search methods for unstructured Peer-to-Peernetworks. We analyze the performance of the algorithms relative to various metrics; givingemphasis on the success rate; bandwidth-efficiency and adaptation to dynamic networkconditions. Simulation results are used to empirically evaluate the behavior of ninerepresentative schemes under a variety of different environments.,Proceedings of the 1st international conference on Scalable information systems,2006,142
H2RDF: adaptive query processing on RDF data in the cloud.,Nikolaos Papailiou; Ioannis Konstantinou; Dimitrios Tsoumakos; Nectarios Koziris,Abstract In this work we present H2RDF; a fully distributed RDF store that combines theMapReduce processing framework with a NoSQL distributed data store. Our system featurestwo unique characteristics that enable efficient processing of both simple and multi-joinSPARQL queries on virtually unlimited number of triples: Join algorithms that execute joinsaccording to query selectivity to reduce processing; and adaptive choice among centralizedand distributed (MapReduce-based) join execution for fast query responses. Our systemefficiently answers both simple joins and complex multivariate queries and easily scales to 3billion triples using a small cluster of 9 worker nodes. H2RDF outperforms state-of-the-artdistributed solutions in multi-join and nonselective queries while achieving comparableperformance to centralized solutions in selective queries. In this demonstration we …,Proceedings of the 21st International Conference on World Wide Web,2012,102
On the elasticity of NoSQL databases over cloud management platforms,Ioannis Konstantinou; Evangelos Angelou; Christina Boumpouka; Dimitrios Tsoumakos; Nectarios Koziris,Abstract NoSQL databases focus on analytical processing of large scale datasets; offeringincreased scalability over commodity hardware. One of their strongest features is elasticity;which allows for fairly portioned premiums and high-quality performance and directly appliesto the philosophy of a cloud-based platform. Yet; the process of adaptive expansion andcontraction of resources usually involves a lot of manual effort during cluster configuration.To date; there exists no comparative study to quantify this cost and measure the efficacy ofNoSQL engines that offer this feature over a cloud provider. In this work; we present a cloud-enabled framework for adaptive monitoring of NoSQL systems. We perform a study of theelasticity feature on some of the most popular NoSQL databases over an open-source cloudplatform. Based on these measurements; we finally present a prototype implementation of …,Proceedings of the 20th ACM international conference on Information and knowledge management,2011,73
Automated; elastic resource provisioning for nosql clusters using tiramola,Dimitrios Tsoumakos; Ioannis Konstantinou; Christina Boumpouka; Spyros Sioutas; Nectarios Koziris,This work presents TIRAMOLA; a cloud-enabled; open-source framework to performautomatic resizing of NoSQL clusters according to user-defined policies. Decisions onadding or removing worker VMs from a cluster are modeled as a Markov Decision Processand taken in real-time. The system automatically decides on the most advantageous clustersize according to user-defined policies; it then proceeds on requesting/releasing VMresources from the provider and orchestrating them inside a NoSQL cluster. TIRAMOLA'smodular architecture and standard API support allows interaction with most current IaaSplatforms and increased customization. An extensive experimental evaluation on an HBasecluster confirms our assertions: The system resizes clusters in real-time and adapts itsperformance through different optimization strategies; different permissible actions …,Cluster; Cloud and Grid Computing (CCGrid); 2013 13th IEEE/ACM International Symposium on,2013,67
H 2 RDF+: High-performance distributed joins over large-scale RDF graphs,Nikolaos Papailiou; Ioannis Konstantinou; Dimitrios Tsoumakos; Panagiotis Karras; Nectarios Koziris,The proliferation of data in RDF format calls for efficient and scalable solutions for theirmanagement. While scalability in the era of big data is a hard requirement; modern systemsfail to adapt based on the complexity of the query. Current approaches do not scale wellwhen faced with substantially complex; non-selective joins; resulting in exponential growthof execution times. In this work we present H 2 RDF+; an RDF store that efficiently performsdistributed Merge and Sort-Merge joins over a multiple index scheme. H 2 RDF+ is highlyscalable; utilizing distributed MapReduce processing and HBase indexes. Utilizingaggressive byte-level compression and result grouping over fast scans; it can process bothcomplex and selective join queries in a highly efficient manner. Furthermore; it adaptivelychooses for either single-or multi-machine execution based on join complexity estimated …,Big Data; 2013 IEEE International Conference on,2013,57
GrouPeer: Dynamic clustering of P2P databases,Verena Kantere; Dimitrios Tsoumakos; Timos Sellis; Nick Roussopoulos,Abstract Sharing structured data in a P2P network is a challenging problem; especially in theabsence of a mediated schema. The standard practice of answering a consecutivelyrewritten query along the propagation path often results in significant loss of information. Onthe opposite; the use of mediated schemas requires human interaction and globalagreement; both during creation and maintenance. In this paper we present GrouPeer; anadaptive; automated approach to both issues in the context of unstructured P2P databaseoverlays. By allowing peers to individually choose which rewritten version of a query toanswer and evaluate the received answers; information-rich sources left hidden otherwiseare discovered. Gradually; the overlay is restructured as semantically similar peers areclustered together. Experimental results show that our technique produces very accurate …,Information Systems,2009,47
Fast and cost-effective online load-balancing in distributed range-queriable systems,Ioannis Konstantinou; Dimitrios Tsoumakos; Nectarios Koziris,Distributed systems such as Peer-to-Peer overlays have been shown to efficiently supportthe processing of range queries over large numbers of participating hosts. In such systems;uneven load allocation has to be effectively tackled in order to minimize overloaded peersand optimize their performance. In this work; we detect the two basic methodologies used toachieve load-balancing: Iterative key redistribution between neighbors and node migration.We identify these two key mechanisms and describe their relative advantages anddisadvantages. Based on this analysis; we propose NIXMIG; a hybrid method that adaptivelyutilizes these two extremes to achieve both fast and cost-effective load-balancing indistributed systems that support range queries. We theoretically prove its convergence andas a case study; we offer an implementation on top of a Skip Graph; where we thoroughly …,IEEE Transactions on Parallel and Distributed Systems,2011,42
Tiramola: elastic nosql provisioning through a cloud management platform,Ioannis Konstantinou; Evangelos Angelou; Dimitrios Tsoumakos; Christina Boumpouka; Nectarios Koziris; Spyros Sioutas,Abstract NoSQL databases focus on analytical processing of large scale datasets; offeringincreased scalability over commodity hardware. One of their strongest features is elasticity;which allows for fairly portioned premiums and high-quality performance. Yet; the process ofadaptive expansion and contraction of resources usually involves a lot of manual effort; oftenrequiring the definition of the conditions for scaling up or down to be provided by the users.To date; there exists no open-source system for automatic resizing of NoSQL clusters. In thisdemonstration; we present TIRAMOLA; a modular; cloud-enabled framework for monitoringand adaptively resizing NoSQL clusters. Our system incorporates a decision-making modulewhich allows for optimal cluster resize actions in order to maximize any quantifiable rewardfunction provided together with life-long adaptation to workload or infrastructural changes …,Proceedings of the 2012 ACM SIGMOD International Conference on Management of Data,2012,32
H 2 RDF+: an efficient data management system for big RDF graphs,Nikolaos Papailiou; Dimitrios Tsoumakos; Ioannis Konstantinou; Panagiotis Karras; Nectarios Koziris,Abstract The proliferation of data in RDF format has resulted in the emergence of a plethoraof specialized management systems. While the ability to adapt to the complexity of aSPARQL query--given their inherent diversity--is crucial; current approaches do not scalewell when faced with substantially complex; non-selective joins; resulting in exponentialgrowth of execution times. In this demonstration we present H2 RDF+; an RDF store thatefficiently performs distributed Merge and Sort-Merge joins using a multiple-index schemeover HBase indexes. Through a greedy planner that incorporates our cost-model; itadaptively commands for either single or multi-machine query execution based on joincomplexity. In this paper; we present its key scientific contributions and allow participants tointeract with an H2RDF+ deployment over a Cloud infrastructure. Using a web-based GUI …,Proceedings of the 2014 ACM SIGMOD international conference on Management of data,2014,31
Distributed indexing of web scale datasets for the cloud,Ioannis Konstantinou; Evangelos Angelou; Dimitrios Tsoumakos; Nectarios Koziris,Abstract In this paper; we present a distributed architecture for indexing and serving largeand diverse datasets. It incorporates and extends the functionality of Hadoop; the opensource MapReduce framework; and of HBase; a distributed; sparse; NoSQL database; tocreate a fully parallel indexing system. Experiments with structured; semi-structured andunstructured data of various sizes demonstrate the flexibility; speed and robustness of ourimplementation and contrast it with similarly oriented projects. Our 11 node cluster prototypemanaged to keep full-text indexing time of 150GB raw content in less than 3 hours; whereasthe system's response time under sustained query load of more than 1000 queries/sec waskept in the order of milliseconds.,Proceedings of the 2010 Workshop on Massive Data Analytics on the Cloud,2010,28
Dependable horizontal scaling based on probabilistic model checking,Athanasios Naskos; Emmanouela Stachtiari; Anastasios Gounaris; Panagiotis Katsaros; Dimitrios Tsoumakos; Ioannis Konstantinou; Spyros Sioutas,The focus of this work is the on-demand resource provisioning in cloud computing; which iscommonly referredto as cloud elasticity. Although a lot of effort has been invested indeveloping systems and mechanisms that enable elasticity; the elasticity decision policiestend to be designed without quantifying or guaranteeing the quality of their operation. Wepresent an approach towards the development of more formalized and dependable elasticitypolicies. We make two distinct contributions. First; we propose an extensible approach toenforcing elasticity through the dynamic instantiation and online quantitative verification ofMarkov Decision Processes (MDP) using probabilistic model checking. Second; variousconcrete elasticity models and elasticity policies are studied. We evaluate the decisionpolicies using traces from a realNoSQL database cluster under constantly evolving …,Cluster; Cloud and Grid Computing (CCGrid); 2015 15th IEEE/ACM International Symposium on,2015,25
Graph-aware; workload-adaptive sparql query caching,Nikolaos Papailiou; Dimitrios Tsoumakos; Panagiotis Karras; Nectarios Koziris,Abstract The pace at which data is described; queried and exchanged using the RDFspecification has been ever increasing with the proliferation of Semantic Web. MinimizingSPARQL query response times has been an open issue for the plethora of RDF stores; yetSPARQL result caching techniques have not been extensively utilized. In this work wepresent a novel system that addresses graph-based; workload-adaptive indexing of largeRDF graphs by caching SPARQL query results. At the heart of the system lies a SPARQLquery canonical labelling algorithm that is used to uniquely index and reference SPARQLquery graphs as well as their isomorphic forms. We integrate our canonical labellingalgorithm with a dynamic programming planner in order to generate the optimal joinexecution plan; examining the utilization of both primitive triple indexes and cached query …,Proceedings of the 2015 ACM SIGMOD International Conference on Management of Data,2015,20
Cloud elasticity using probabilistic model checking,Athanasios Naskos; Emmanouela Stachtiari; Anastasios Gounaris; Panagiotis Katsaros; Dimitrios Tsoumakos; Ioannis Konstantinou; Spyros Sioutas,Abstract: Cloud computing has become the leading paradigm for deploying large-scaleinfrastructures and running big data applications; due to its capacity of achieving economiesof scale. In this work; we focus on one of the most prominent advantages of cloud computing;namely the on-demand resource provisioning; which is commonly referred to as elasticity.Although a lot of effort has been invested in developing systems and mechanisms thatenable elasticity; the elasticity decision policies tend to be designed without guaranteeing orquantifying the quality of their operation. This work aims to make the development ofelasticity policies more formalized and dependable. We make two distinct contributions.First; we propose an extensible approach to enforcing elasticity through the dynamicinstantiation and online quantitative verification of Markov Decision Processes (MDP) …,arXiv preprint arXiv:1405.4699,2014,14
A grid middleware for data management exploiting peer-to-peer techniques,Athanasia Asiki; Katerina Doka; Ioannis Konstantinou; Antonis Zissimos; Dimitrios Tsoumakos; Nectarios Koziris; Panayiotis Tsanakas,Abstract In this paper; we describe a service-oriented middleware architecture for Gridenvironments which enables efficient data management. Our design introduces conceptsfrom Peer-to-Peer computing in order to provide a scalable and reliable infrastructure forstorage; search and retrieval of annotated content. To ensure fast file lookups in thedistributed repositories; our system incorporates a multidimensional indexing scheme whichserves the need for supporting both exact match and range queries over a group ofmetadata attributes. Finally; file transfers are conducted using GridTorrent; a grid-enabled;Peer-to-Peer mechanism that performs efficient data transfers by enabling cooperationamong participating nodes and balances the cost of file transfer among them. The proposedarchitecture is the middleware component used by the GREDIA project; in which both …,Future Generation Computer Systems,2009,13
Kanis: preserving k-anonymity over distributed data,Katerina Doka; Dimitrios Tsoumakos; Nectarios Koziris,ABSTRACT In this paper we describe KANIS; a distributed system designed to preserve theprivacy of multidimensional; hierarchical data that are dispersed over a network. Whileallowing for efficient storing; indexing and querying of the data; our system employs anadaptive scheme that automatically adjusts the level of indexing according to the privacyconstrains: Efficient roll-up and drill-down operations take place in order to guarantee k-anonymity while minimizing data distortion and inconsistency. Thus; our system manages tomaintain k-anonymity of the published data in a distributed and on-line manner even underfrequent updates; without affecting its ability to efficiently answer queries. The initialexperimental evaluation of our prototype shows that KANIS manages to preserve k-anonymity while improving the data quality up to 22% compared to a popular centralized …,proceedings of the 5th International Workshop on Personalized Access; Profile Management; and Context Awareness in Databases,2011,12
Distributing and searching concept hierarchies: an adaptive DHT-based system,Athanasia Asiki; Dimitrios Tsoumakos; Nectarios Koziris,Abstract Concept hierarchies greatly help in the organization and reuse of information andare widely used in a variety of information systems applications. In this paper; we describe amethod for efficiently storing and querying data organized into concept hierarchies anddispersed over a DHT. In our method; peers individually decide on the level of indexingaccording to the granularity of the incoming queries. Roll-up and drill-down operations areperformed on a per-node basis in order to minimize the required bandwidth for answeringqueries on variable aggregation levels. We motivate our approach by applying it on a large-scale Grid system: Specifically; we apply our fully decentralized scheme that creates;queries and updates large volumes of hierarchical data on-line and replace the traditionalcentralized and strictly indexed information systems. Our extensive experimental results …,Cluster Computing,2010,12
DBalancer: distributed load balancing for NoSQL data-stores,Ioannis Konstantinou; Dimitrios Tsoumakos; Ioannis Mytilinis; Nectarios Koziris,Abstract Unanticipated load spikes or skewed data access patterns may lead to severeperformance degradation in data serving applications; a typical problem of distributedNoSQL data-stores. In these cases; load balancing is a necessary operation. In thisdemonstration; we present the DBalancer; a generic distributed module that can be installedon top of a typical NoSQL data-store and provide an efficient and highly configurable loadbalancing mechanism. Balancing is performed by simple message exchanges and typicaldata movement operations supported by most modern NoSQL data-stores. We present thesystem's architecture; we describe in detail its modules and their interaction and weimplement a suite of different algorithms on top of it. Through a web-based interactive GUIwe allow the users to launch NoSQL clusters of various sizes; to apply numerous skewed …,Proceedings of the 2013 ACM SIGMOD International Conference on Management of Data,2013,11
An adaptive probabilistic replication method for unstructured p2p networks,Dimitrios Tsoumakos; Nick Roussopoulos,Abstract We present APRE; a replication method for unstructured Peer-to-Peer overlays. Thegoal of our method is to achieve real-time replication of even the most sparsely locatedcontent relative to demand. APRE adaptively expands or contracts the replica set of anobject in order to improve the sharing process and achieve a low load distribution amongthe providers. To achieve that; it utilizes search knowledge to identify possible replicationtargets inside query-intensive areas of the overlay. We present detailed simulation resultswhere APRE exhibits both efficiency and robustness over the number of requesters and therespective request rates. The scheme proves particularly useful in the event of flash crowds;managing to quickly adapt to sudden surges in load.,OTM Confederated International Conferences" On the Move to Meaningful Internet Systems",2006,11
Brown Dwarf: A fully-distributed; fault-tolerant data warehousing system,Katerina Doka; Dimitrios Tsoumakos; Nectarios Koziris,Abstract In this paper we present the Brown Dwarf; a distributed data analytics systemdesigned to efficiently store; query and update multidimensional data over commoditynetwork nodes; without the use of any proprietary tool. Brown Dwarf distributes a centralizedindexing structure among peers on-the-fly; reducing cube creation and querying times byenforcing parallelization. Analytical queries are naturally performed on-line throughcooperating nodes that form an unstructured Peer-to-Peer overlay. Updates are alsoperformed on-line; eliminating the usually costly over-night process. Moreover; the systememploys an adaptive replication scheme that adjusts to the workload skew as well as thenetwork churn by expanding or shrinking the units of the distributed data structure. Oursystem has been thoroughly evaluated on an actual testbed: it manages to accelerate …,Journal of Parallel and Distributed Computing,2011,10
kdann+: A rapid aknn classifier for big data,Nikolaos Nodarakis; Evaggelia Pitoura; Spyros Sioutas; Athanasios Tsakalidis; Dimitrios Tsoumakos; Giannis Tzimas,Abstract A k-nearest neighbor (k NN) query determines the k nearest points; using distancemetrics; from a given location. An all k-nearest neighbor (A k NN) query constitutes avariation of ak NN query and retrieves the k nearest points for each point inside a database.Their main usage resonates in spatial databases and they consist the backbone of manylocation-based applications and not only. In this work; we propose a novel method forclassifying multidimensional data using an A k NN algorithm in the MapReduce framework.Our approach exploits space decomposition techniques for processing the classificationprocedure in a parallel and distributed manner. To our knowledge; we are the first to studythe k NN classification of multidimensional objects under this perspective. Through anextensive experimental evaluation we prove that our solution is efficient; robust and …,*,2016,9
Ires: Intelligent; multi-engine resource scheduler for big data analytics workflows,Katerina Doka; Nikolaos Papailiou; Dimitrios Tsoumakos; Christos Mantas; Nectarios Koziris,Abstract Big data analytics tools are steadily gaining ground at becoming indispensable tobusinesses worldwide. The complexity of the tasks they execute is ever increasing due tothe surge in data and task heterogeneity. Current analytics platforms; while successful inharnessing multiple aspects of this``data deluge"; bind their efficacy to a single data andcompute model and often depend on proprietary systems. However; no single executionengine is suitable for all types of computation and no single data store is suitable for alltypes of data. To this end; we demonstrate IReS; the Intelligent Resource Scheduler forcomplex analytics workflows executed over multi-engine environments. Our system modelsthe cost and performance of the required tasks over the available platforms. IReS is thenable to match distinct workflow parts to the execution and/or storage engine among the …,Proceedings of the 2015 ACM SIGMOD International Conference on Management of Data,2015,9
I/O performance modeling for big data applications over cloud infrastructures,Ioannis Mytilinis; Dimitrios Tsoumakos; Verena Kantere; Anastassios Nanos; Nectarios Koziris,Big Data applications receive an ever-increasing amount of attention; thus becoming adominant class of applications that are deployed over virtualized environments. Cloudenvironments entail a large amount of complexity relative to I/O performance. The use of BigData increases the complexity of I/O management as well as its characterization andprediction: As I/O operations become growingly dominant in such applications; theintricacies of virtualization; different storage back ends and deployment setups significantlyhinder our ability to analyze and correctly predict I/O performance. To that end; this workproposes an end-to-end modeling technique to predict performance of I/O--intensive BigData applications running over cloud infrastructures. We develop a model tuned overapplication and infrastructure dimensions: Primitive I/O operations; data access patterns …,Cloud Engineering (IC2E); 2015 IEEE International Conference on,2015,9
Online querying of d-dimensional hierarchies,Katerina Doka; Dimitrios Tsoumakos; Nectarios Koziris,Abstract In this paper we describe a distributed system designed to efficiently store; queryand update multidimensional data organized into concept hierarchies and dispersed over anetwork. Our system employs an adaptive scheme that automatically adjusts the level ofindexing according to the granularity of the incoming queries; without assuming any priorknowledge of the workload. Efficient roll-up and drill-down operations take place in order tomaximize the performance by minimizing query flooding. Updates are performed on-line;with minimal communication overhead; depending on the level of consistency needed.Extensive experimental evaluation shows that; on top of the advantages that a distributedstorage offers; our method answers the vast majority of incoming queries; both point andaggregate ones; without flooding the network and without causing significant storage or …,Journal of Parallel and Distributed Computing,2011,9
Replica-aware; multi-dimensional range queries in distributed hash tables,Antony Chazapis; Athanasia Asiki; Georgios Tsoukalas; Dimitrios Tsoumakos; Nectarios Koziris,Abstract In this paper; we present and evaluate a protocol that enables fast and accuraterange-query execution in Distributed Hash Tables (DHTs). Range queries are of particularimportance when the network is populated with groups or collections of data items; whoserespective identifiers are generated in a way that encodes semantic relationships into keydistances. Contrary to related work in the same direction; our proposed query engine isaware of data replicas at the DHT level and by grouping related nodes into replicaneighborhoods; resolves queries with the minimum amount of messaging overhead.Moreover; we suggest pairing respective operations with the core DHT routing mechanics;which allows for reusing existing management and monitoring structures and automaticallyadapting the query path to the dynamic characteristics of the overlay. We also present an …,Computer Communications,2010,9
Celar: automated application elasticity platform,Ioannis Giannakopoulos; Nikolaos Papailiou; Christos Mantas; Ioannis Konstantinou; Dimitrios Tsoumakos; Nectarios Koziris,One of the main promises of the cloud computing paradigm is the ability to scale resourceson-demand. This feature characterizes the cloud era; where the overhead of earlyexpenditure for infrastructure is eliminated. Innovative services are thus able to enter themarket quicker and adopt faster to new challenges and user demand. One of the mainaspects of this on-demand nature is the concept of elasticity; ie; the ability of autonomouslyprovision and de-provision resources by reacting to changes in the incoming load. An elasticservice is able to operate with an optimal cost by expanding and contracting its usedresources at runtime and according to demand. This does not only minimizes running cost;but also avoids disruptive outages due to spikes in service usage. While the various layerscomprising a cloud service can be scaled; this does not happen in a unified manner. The …,Big Data (Big Data); 2014 IEEE International Conference on,2014,8
A framework for semantic grouping in P2P databases,Verena Kantere; Dimitrios Tsoumakos; Timos Sellis,Abstract Sharing of structured data in decentralized environments is a challenging problem;especially in the absence of a global schema. Social network structures map network links tosemantic relations between participants in order to assist in efficient resource discovery andinformation exchange. In this work; we propose a scheme that automates the process ofcreating schema synopses from semantic clusters of peers which own autonomousrelational databases. The resulting mediated schemas can be used as global interfaces forrelevant queries. Active nodes are able to initiate the group schema creation process; whichproduces a mediated schema representative of nodes with similar semantics. Groupschemas are then propagated in the overlay and used as a single interface for relevantqueries. This increases both the quality and the quantity of the retrieved answers and …,Information Systems,2008,8
Querying structured data in an unstructured P2P system,Verena Kantere; Dimitrios Tsoumakos; Nick Roussopoulos,Abstract Peer-to-Peer networking has become a major research topic over the last fewyears. Sharing of structured data in such decentralized environments is a challengingproblem; especially in the absence of a global schema. The standard practice of answeringa query that is consecutively rewritten along the propagation path often results in significantloss of information. In this paper; we present an adaptive and bandwidth-efficient solution tothe problem in the context of an unstructured; purely decentralized system. Our methodallows peers to individually choose which rewritten version of a query to answer anddiscover information-rich sources left hidden otherwise. Utilizing normal query traffic only;we describe how efficient query routing and clustering of peers can be used to produce highquality answers. Simulation results show that our technique is both effective and …,Proceedings of the 6th annual ACM international workshop on Web information and data management,2004,8
Efficient multidimensional AkNN query processing in the cloud,Nikolaos Nodarakis; Evaggelia Pitoura; Spyros Sioutas; Athanasios Tsakalidis; Dimitrios Tsoumakos; Giannis Tzimas,Abstract A k-nearest neighbor (k NN) query determines the k nearest points; using distancemetrics; from a given location. An all k-nearest neighbor (A k NN) query constitutes avariation of ak NN query and retrieves the k nearest points for each point inside a database.Their main usage resonates in spatial databases and they consist the backbone of manylocation-based applications and not only. In this work; we propose a novel method forclassifying multidimensional data using an A k NN algorithm in the MapReduce framework.Our approach exploits space decomposition techniques for processing the classificationprocedure in a parallel and distributed manner. To our knowledge; we are the first to studythe k NN classification of multidimensional objects under this perspective. Through anextensive experimental evaluation we prove that our solution is efficient; robust and …,International Conference on Database and Expert Systems Applications,2014,7
Probabilistic knowledge discovery and management for p2p networks,Dimitrios Tsoumakos; N Rossopoulos,Abstract—The Peer-to-Peer (P2P) paradigm dictates a distributed network model which enablesthe sharing of resources between its participants. In many cases; the location of these resourcesis a non-trivial task with network-wide effects. In this work; we describe the Adaptive ProbabilisticSearch method (APS) for search in unstructured P2P networks. APS utilizes feedback from previoussearches to probabilistically guide future ones. Besides being a very cost-efficient technique;it enables the distribution and adaptation of search knowledge over the network. Based onthat; we provide examples where this scheme can prove useful in more demandingenvironments … Peer-to-Peer (hence P2P) networking has been growing rapidly in the lastfew years. Its success; originally boosted by some popular file-sharing applications (eg; [1]); ledto the emergence of numerous systems that utilize P2P technology (eg; [2]–[5]). These …,P2P Journal,2003,7
The case for multi-engine data analytics,Dimitrios Tsoumakos; Christos Mantas,Abstract As big data analytics have become an important driver for ICT development; a largevariety of approaches that apply these advanced technologies on a wide spectrum ofapplications has been introduced. In this paper we argue on the need of a multi-engineenvironment that will exploit the largely different models; cost and quality of the existinganalytics engines. Such an environment further requires an intelligent management systemfor orchestrating and coordinating complex analytics tasks over the different availableengines. After summarizing some of the current approaches in data analytics; we outline thestructure of our envisioned Multi-Engine Management System and present some of thecorresponding research directions in its design and development.,European Conference on Parallel Processing,2013,6
APRE: A replication method for unstructured P2P networks,Dimitrios Tsoumakos; Nick Roussopoulos,We present APRE; a replication method for structureless Peer-to-Peer overlays. The goal ofour method is to achieve real-time replication of even the most sparsely located contentrelative to demand. APRE adaptively expands or contracts the replica set of an object inorder to improve the sharing process and achieve a low load distribution among theproviders. To achieve that; it utilizes search knowledge to identify possible replication targetsinside query-intensive areas of the overlay. We present detailed simulation results whereAPRE exhibits both efficiency and robustness relative to the number of requesters and therespective request rates. The scheme proves particularly useful in the event of flash crowds;managing to quickly adapt to sudden surges in load.,*,2006,6
Agno: An adaptive group communication scheme for unstructured p2p networks,Dimitrios Tsoumakos; Nick Roussopoulos,Abstract We present the Adaptive Group Notification (AGNO) scheme for efficientlycontacting large peer populations in unstructured Peer-to-Peer networks. AGNO defines anovel implicit approach towards group membership by monitoring demand for content asthis is expressed through lookup operations. Utilizing search indices; together with a smallnumber of soft-state shortcuts; AGNO achieves effective and bandwidth-efficient contentdissemination; without the cost and restrictions of a membership protocol or a DHT. Ourmethod achieves high-success content transmission at a cost at least two times smaller thanproposed techniques for unstructured networks.,European Conference on Parallel Processing,2005,6
A network approach for managing and processing big cancer data in clouds,Wei Xing; Wei Jie; Dimitrios Tsoumakos; Moustafa Ghanem,Abstract Translational cancer research requires integrative analysis of multiple levels of bigcancer data to identify and treat cancer. In order to address the issues that data isdecentralised; growing and continually being updated; and the content living or archiving ondifferent information sources partially overlaps creating redundancies as well ascontradictions and inconsistencies; we develop a data network model and technology forconstructing and managing big cancer data. To support our data network approach for dataprocess and analysis; we employ a semantic content network approach and adopt theCELAR cloud platform. The prototype implementation shows that the CELAR cloud cansatisfy the on-demanding needs of various data resources for management and process ofbig cancer data.,Cluster Computing,2015,5
Panic: modeling application performance over virtualized resources,Ioannis Giannakopoulos; Dimitrios Tsoumakos; Nikolaos Papailiou; Nectarios Koziris,In this work we address the problem of predicting the performance of a complex applicationdeployed over virtualized resources. Cloud computing has enabled numerous companies todevelop and deploy their applications over cloud infrastructures for a wealth of reasonsincluding (but not limited to) decrease costs; avoid administrative effort; rapidly allocate newresources; etc. Virtualization however; adds an extra layer in the software stack; hardeningthe prediction of the relation between the resources and the application performance; whichis a key factor for every industry. To address this challenge we propose PANIC; a systemwhich obtains knowledge for the application by actually deploying it over a cloudinfrastructure and then; approximating the performance of the application for the all possibledeployment configurations. The user of PANIC defines a set of resources along with their …,Cloud Engineering (IC2E); 2015 IEEE International Conference on,2015,5
COCCUS: self-configured cost-based query services in the cloud,Ioannis Konstantinou; Verena Kantere; Dimitrios Tsoumakos; Nectarios Koziris,Abstract Recently; a large number of pay-as-you-go data services are offered over cloudinfrastructures. Data service providers need appropriate and flexible query chargingmechanisms and query optimization that take into consideration cloud operationalexpenses; pricing strategies and user preferences. Yet; existing solutions are static and non-configurable. We demonstrate COCCUS; a modular system for cost-aware query execution;adaptive query charge and optimization of cloud data services. The audience can set theirqueries along with their execution preferences and budget constraints; while COCCUSadaptively determines query charge and manages secondary data structures according tovarious economic policies. We demonstrate COCCUS's operation over centralized andshared nothing CloudDBMS architectures on top of public and private IaaS clouds. The …,Proceedings of the 2013 ACM SIGMOD International Conference on Management of Data,2013,5
Measuring the cost of online load-balancing in distributed range-queriable systems,Ioannis Konstantinou; Dimitrios Tsoumakos; Nectarios Koziris,Distributed systems such as Peer-to-Peer overlays have been shown to efficiently supportthe processing of range queries over large numbers of participating hosts. In such systems;uneven load allocation has to be effectively tackled in order to minimize overloaded peersand optimize their performance. In this work; we detect and analyze the two basicmethodologies used to achieve load-balancing: Iterative key re-distribution betweenneighbors and node migration. Based on this analysis; we propose a hybrid method thatadaptively utilizes these two extremes to achieve both fast and cost-effective load-balancingin distributed systems that support range queries. As a case study; we offer animplementation on top of a Skip Graph; where we validate our findings in a variety ofworkloads. Our experimental analysis shows that the hybrid method converges 10 …,Peer-to-Peer Computing; 2009. P2P'09. IEEE Ninth International Conference on,2009,5
HiPPIS: an online P2P system for efficient lookups on d-dimensional hierarchies,Katerina Doka; Dimitrios Tsoumakos; Nectarios Koziris,Abstract In this paper we describe HiPPIS; a system that enables efficient storage and on-line querying of multidimensional data organized into concept hierarchies and dispersedover a network. Our scheme utilizes an adaptive algorithm that automatically adjusts thelevel of indexing according to the granularity of the incoming queries; without assuming anyprior knowledge of the workload. Efficient roll-up and drill-down operations take place inorder to maximize the performance by minimizing query flooding. Extensive experimentalevaluations show that; on top of the advantages that a distributed storage offers; our methodanswers the large majority of incoming queries; both point and aggregate ones; withoutflooding the network. At the same time; it manages to preserve the hierarchical nature ofdata. These characteristics are maintained even after sudden shifts in the workload.,Proceedings of the 10th ACM workshop on Web information and data management,2008,5
Mix ‘n’match multi-engine analytics,Katerina Doka; Nikolaos Papailiou; Victor Giannakouris; Dimitrios Tsoumakos; Nectarios Koziris,Current platforms fail to efficiently cope with the data and task heterogeneity of modernanalytics workflows due to their adhesion to a single data and/or compute model. As aremedy; we present IReS; the Intelligent Resource Scheduler for complex analyticsworkflows executed over multi-engine environments. IReS is able to optimize a workflowwith respect to a user-defined policy relying on cost and performance models of the requiredtasks over the available platforms. This optimization consists in allocating distinct workflowparts to the most advantageous execution and/or storage engine among the available onesand deciding on the exact amount of resources provisioned. Our current prototype supports5 compute and 3 data engines; yet new ones can effortlessly be added to IReS by virtue ofits engine-agnostic mechanisms. Our extensive experimental evaluation confirms that …,Big Data (Big Data); 2016 IEEE International Conference on,2016,4
An equitable solution to the stable marriage problem,Ioannis Giannakopoulos; Panagiotis Karras; Dimitrios Tsoumakos; Katerina Doka; Nectarios Koziris,A stable marriage problem (SMP) of size n involves n men and n women; each of whom hasordered members of the opposite gender by descending preferability. A solution is a perfectmatching among men and women; such that there exists no pair who prefer each other totheir current spouses. The problem was formulated in 1962 by Gale and Shapley; whoshowed that any instance can be solved in polynomial time; and has attracted interest due toits application to any two-sided market. Still; the solution obtained by the Gale-Shapleyalgorithm is favorable to one side. Gusfield and Irving introduced the equitable stablemarriage problem (ESMP); which calls for finding a stable matching that minimizes thedistance between men's and women's sum-of-rankings of their spouses. Unfortunately;ESMP is strongly NP-hard; approximation algorithms therefor are impractical; while even …,Tools with Artificial Intelligence (ICTAI); 2015 IEEE 27th International Conference on,2015,4
k-Anonymization by freeform generalization,Katerina Doka; Mingqiang Xue; Dimitrios Tsoumakos; Panagiotis Karras,Abstract Syntactic data anonymization strives to (i) ensure that an adversary cannot identifyan individual's record from published attributes with high probability; and (ii) provide highdata utility. These mutually conflicting goals can be expressed as an optimization problemwith privacy as the constraint and utility as the objective function. Conventional researchusing the k-anonymity model has resorted to publishing data in homogeneous generalizedgroups. A recently proposed alternative does not create such cliques; instead; it recasts datavalues in a heterogeneous manner; aiming for higher utility. Nevertheless; such works neverdefined the problem in the most general terms; thus; the utility gains they achieve are limited.In this paper; we propose a methodology that achieves the full potential of heterogeneity andgains higher utility while providing the same privacy guarantee. We formulate the problem …,Proceedings of the 10th ACM Symposium on Information; Computer and Communications Security,2015,4
On controlling elasticity of cloud applications in celar,Georgiana Copil; Daniel Moldovan; Hung Duc Le; Hong-Linh Truong; Schahram Dustdar; Chrystalla Sofokleous; Nicholas Loulloudes; Demetris Trihinas; George Pallis; Marios D Dikaiakos; Ioannis Giannakopoulos; Nikolaos Papailiou; Ioannis Konstantinou; Craig Sheridan; Christos KK Loverdos; Evangelos Floros; Kam Star; Wei Xing,ABSTRACT Today's complex cloud applications are composed of multiple componentsexecuted in multi-cloud environments. For such applications; the possibility to manage andcontrol their cost; quality; and resource elasticity is of paramount importance. However;given that the cost of different services offered by cloud providers can vary a lot with theirquality/performance; elasticity controllers must consider not only complex; multi-dimensionalpreferences and provisioning capabilities from stakeholders but also various runtimeinformation regarding cloud applications and their execution environments. In this chapter;the authors present the elasticity control approach of the EU CELAR Project; which dealswith multi-dimensional elasticity requirements and ensures multi-level elasticity control forfulfilling user requirements. They show the elasticity control mechanisms of the CELAR …,*,2015,4
GrouPeer: A system for clustering PDMSs,Verena Kantere; Dimos Bousounis; Timos Sellis,ABSTRACT Sharing structured data in a PDMS is hard due to schema heterogeneity andpeer autonomy. To overcome heterogeneity; peer databases employ mappings that partiallymatch local information to that of their direct neighbors. Traditionally; a query is successivelyrewritten along the propagation path on each peer. This results in gradual querydegradation and the inability to retrieve data pertinent to the original version; even frompeers that store such data. This demonstration presents GrouPeer; a system that overcomesthe query degradation problem and enables the dynamic clustering of the overlay accordingto the semantics of the peer data; utilizing normal query traffic. Peers are provided with amethodology that allows them to choose which rewritten version of a query to answer anddiscover remote information-rich sources. The demonstration illustrates the functionalities …,Proceedings of the VLDB Endowment,2011,4
Efficient updates for a shared nothing analytics platform,Katerina Doka; Dimitrios Tsoumakos; Nectarios Koziris,Abstract In this paper we describe a cloud-based data-warehouselike system especiallytargeted to time series data. Apart from the benefits that a distributed storage built on top of ashared-nothing architecture offers; our system is designed to efficiently cope withcontinuous; on-line updates of temporally ordered data without compromising the querythroughput. Through a totally customizable process performing asynchronous aggregationof past records; we achieve significant gains in storage and update times compared totraditional methods; maintaining a high accuracy in query responses for our targetapplication. Experiments using our prototype implementation over an actual testbed provethat our scheme considerably accelerates (by a factor above 3) the update procedure andreduces required storage by at least 30%. We also show how these gains are related to …,Proceedings of the 2010 Workshop on Massive Data Analytics on the Cloud,2010,4
Support for Concept Hierarchies in DHTs,Athanasia Asiki; Katerina Doka; Dimitrios Tsoumakos; Nectarios Koziris,Concept hierarchies greatly help in the organization and reuse of information and are widelyused in a variety of applications; such as data warehouses. In this paper; we describe amethod for efficiently storing and querying data organized into concept hierarchies anddispersed over a DHT. In our method; peers individually decide on the level of indexingaccording to the incoming queries. Roll-up and drill-down operations are performed on a per-node basis in order to minimize the number of floods for answering queries on varying levelsof granularity. Initial experimental results support this argument on a variety of workloads.,Peer-to-Peer Computing; 2008. P2P'08. Eighth International Conference on,2008,4
Rapid aknn query processing for fast classification of multidimensional data in the cloud,Nikolaos Nodarakis; Spyros Sioutas; Dimitrios Tsoumakos; Giannis Tzimas; Evaggelia Pitoura,Abstract: A $ k $-nearest neighbor ($ k $ NN) query determines the $ k $ nearest points;using distance metrics; from a specific location. An all $ k $-nearest neighbor (A $ k $ NN)query constitutes a variation of a $ k $ NN query and retrieves the $ k $ nearest points foreach point inside a database. Their main usage resonates in spatial databases and theyconsist the backbone of many location-based applications and not only (ie $ k $ NN joins indatabases; classification in data mining). So; it is very crucial to develop methods thatanswer them efficiently. In this work; we propose a novel method for classifyingmultidimensional data using an A $ k $ NN algorithm in the MapReduce framework. Ourapproach exploits space decomposition techniques for processing the classificationprocedure in a parallel and distributed manner. To our knowledge; we are the first to …,arXiv preprint arXiv:1402.7063,2014,3
Automatic scaling of selective SPARQL joins using the TIRAMOLA system,Evangelos Angelou; Nikolaos Papailiou; Ioannis Konstantinou; Dimitrios Tsoumakos; Nectarios Koziris,Abstract Modern cloud infrastructures based on virtual hardware provide new opportunitiesand challenges for developers and system administrators alike. Most notable is the promiseof resource elasticity; whereby the infrastructure can increase or decrease in size based ondemand. Utilizing elastic resources; applications can provide better quality of service andreduce cost by only paying for the required amount of resources. In this work; we extensivelystudy the performance of some popular NoSQL databases over an elastic cloudinfrastructure. NoSQL databases focus on analytical processing of large scale datasets;offering increased scalability over commodity hardware. We then proceed to describeTIRAMOLA; a cloud-enabled framework for automatic provisioning of elastic resources onany NoSQL platform. Our system administers cluster resources (VMs) according to user …,Proceedings of the 4th International Workshop on Semantic Web Information Management,2012,3
Distributing the Power of OLAP,Katerina Doka; Dimitrios Tsoumakos; Nectarios Koziris,Abstract In this paper we present the Brown Dwarf; a distributed system designed toefficiently store; query and update multidimensional data over an unstructured Peer-to-Peeroverlay; without the use of any proprietary tool. Brown Dwarf manages to distribute a highlyeffective centralized structure among peers on-the-fly. Both point and aggregate queries arethen naturally answered on-line through cooperating nodes that hold parts of a fully orpartially materialized data cube. Updates are also performed on-line; eliminating the usuallycostly over-night process. Our initial evaluation on an actual testbed proves that BrownDwarf manages to distribute the structure across the overlay nodes incurring only a smallstorage overhead compared to the centralized algorithm. Moreover; it accelerates cubecreation up to 5 times and querying up to several tens of times by exploiting the …,Proceedings of the 19th ACM International Symposium on High Performance Distributed Computing,2010,3
Brown dwarf: Distributing the Power of Olap to Unstructured P2P overlays,Katerina Doka; Dimitrios Tsoumakos; Nectarios Koziris,Abstract In this paper we present the Brown Dwarf; a distributed system designed toefficiently store; query and update multidimensional data over a Peer-to-Peer overlay. TheBrown Dwarf manages to distribute a highly effective centralized structure among peers on-the-fly. Both point and aggregate queries are then naturally answered online throughcooperating nodes that hold parts of a fully or partially materialized data cube. Updates arealso performed on-line; eliminating the usually costly over-night process. To tackle dynamicshifts in skew as well as network and node failures; our system employs an adaptivereplication scheme; by creating copies of various units of the distributed data structureaccording to the load as well as the churn rate of the network. This process; called mirroring;ensures balanced load distribution; guarantees resilience and allows for smooth query …,*,2009,3
An adaptive online system for efficient processing of hierarchical data,Athanasia Asiki; Dimitrios Tsoumakos; Nectarios Koziris,Abstract Concept hierarchies greatly help in the organization and reuse of information andare widely used in a variety of information systems applications. In this paper; we describe amethod for efficiently storing and querying data organized into concept hierarchies anddispersed over a DHT. In our method; peers individually decide on the level of indexingaccording to the granularity of the incoming queries. Roll-up and drill-down operations areperformed on a per-node basis in order to minimize the required bandwidth for answeringqueries on variable aggregation levels. We motivate our approach by applying it on a large-scale Grid system: Specifically; we plan to apply our fully decentralized scheme that creates;queries and updates large volumes of hierarchical data on-line and replace the traditionalcentralized and strictly indexed information systems. Our extensive experimental results …,Proceedings of the 18th ACM international symposium on High performance distributed computing,2009,3
Semantic grouping of social networks in p2p database settings,Verena Kantere; Dimitrios Tsoumakos; Timos Sellis,Abstract Social network structures map network links to semantic relations betweenparticipants in order to assist in efficient resource discovery and information exchange. Inthis work; we propose a scheme that automates the process of creating schema synopsesfrom semantic clusters of peers which own autonomous relational databases. The resultingmediated schemas can be used as global interfaces for relevant queries. As ourexperimental evaluations show; this method increases both the quality and the quantity ofthe retrieved answers and allows for faster discovery of semantic groups by joining peers.,International Conference on Database and Expert Systems Applications,2007,3
Robust and Adaptive Multi-Engine Analytics using IReS,Nikolaos Papailiou; Katerina Doka; Victor Giannakouris; Vassilis Papaioannou; Dimitrios Tsoumakos; Nectarios Koziris,Abstract. The complexity of Big Data analytics has long outreached the capabilities of currentplatforms; which fail to efficiently cope with the data and task heterogeneity of modernworkflows due to their adhesion to a single data and/or compute model. As a remedy; wedemonstrate IReS; the Intelligent Resource Scheduler for complex analytics workflowsexecuted over multi-engine environments. IReS is able to optimize a workflow with respectto a user-defined policy by (a) allocating distinct parts of it to the most advantageousexecution and/or storage engine among the available ones and (b) deciding on the exactamount of resources provisioned. Moreover; IReS can efficiently adapt to the currentcluster/engine conditions and recover from failures by effectively monitoring the workflowexecution in real-time. During the demo; the attendees will be able to create; optimize and …,Proceedings of BIRTE,2016,2
Efficient Updates for Web-Scale Indexes over the Cloud,Panagiotis Antonopoulos; Ioannis Konstantinou; Dimitrios Tsoumakos; Nectarios Koziris,In this paper; we present a distributed system which enables fast and frequent updates onweb-scale Inverted Indexes. The proposed update technique allows incremental processingof new or modified data and minimizes the changes required to the index; significantlyreducing the update time which is now independent of the existing index size. By utilizingHadoop MapReduce; for parallelizing the update operations; and HBase; for distributing theInverted Index; we create a high-performance; fully distributed index creation and updatesystem. To the best of our knowledge; this is the first open source system that creates;updates and serves large-scale indexes in a distributed fashion. Experiments with over 23million Wikipedia documents demonstrate the speed and robustness of our implementation:It scales linearly with the size of the updates and the degree of change in the documents …,Data Engineering Workshops (ICDEW); 2012 IEEE 28th International Conference on,2012,2
PASS it on (passion): An adaptive online load-balancing algorithm for distributed range-query specialized systems,Ioannis Konstantinou; Dimitrios Tsoumakos; Nectarios Koziris,Abstract A basic requirement for every P2P system is fault-tolerance. Since the primaryobjective is resource location and sharing; we require that this basic operation takes place ina reliable manner. In a variety of situations with skewed data accesses (eg;[1]; etc) thedemand for content can become overwhelming for certain serving peers; forcing them toreject connections. In many cases; these skewed distributions take extreme forms: Flashcrowds; regularly documented surges in the popularity of certain content; are also known tocause severe congestion and degradation of service [2]. Data replication techniques is onecommonly utilized solution to remedy these situations. Nevertheless; there are cases inwhich the requested resources cannot be arbitrarily replicated. Distributed data-structuresthat support range-queries is such an example: The keys are stored in the network nodes …,OTM Confederated International Conferences" On the Move to Meaningful Internet Systems",2008,2
Online Querying of Concept Hierarchies in P2P Systems,Katerina Doka; Athanasia Asiki; Dimitrios Tsoumakos; Nectarios Koziris,Abstract In this paper we describe HIS; a system that enables efficient storage and queryingof data organized into concept hierarchies and dispersed over a network. Our schemeutilizes an adaptive algorithm that automatically adjusts the level of indexing according tothe granularity of the incoming queries; without assuming any prior knowledge of the queryworkload. Efficient roll-up and drill-down operations increase the exact-match query ratio byshifting to the most favorable hierarchy level. Combined with soft-state indices created afterquery misses; our system achieves maximization of performance by minimizing queryflooding. Extensive experimental evaluations show that; on top of the advantages that adistributed storage offers; our method answers the large majority of incoming queries withoutflooding the network and at the same time it manages to preserve the hierarchical nature …,OTM Confederated International Conferences" On the Move to Meaningful Internet Systems",2008,2
A Framework for Sharing Voluminous Content in P2P Systems.,Dimitrios Tsoumakos; Nick Roussopoulos,Abstract—File-sharing applications remain today the most representative and popularrealization of the Peerto-Peer paradigm. Large objects receive an increasing amount ofinterest in such systems. In this paper; we identify several challenges related to sharingvoluminous content such as movies; OS distributions; games; etc; in unstructured Peer-to-Peer networks. We then describe our scheme which adaptively expands or contracts systemresources in order to improve the sharing process and achieve a fair load distribution amongthe providers.,PDPTA,2004,2
Recovering from Cloud Application Deployment Failures through Re-execution,Ioannis Giannakopoulos; Ioannis Konstantinou; Dimitrios Tsoumakos; Nectarios Koziris,Abstract In this paper we study the problem of automated cloud application deployment andconfiguration. Transient failures are commonly found in current cloud infrastructures;attributed to the complexity of the software and hardware stacks utilized. These errors affectcloud application deployment; forcing the users to manually check and intervene in thedeployment process. To address this challenge; we propose a simple yet powerfuldeployment methodology with error recovery features that bases its functionality onidentifying the script dependencies and re-executing the appropriate configuration scripts.To guarantee the idempotent script execution; we adopt a filesystem snapshot mechanismthat enables our approach to revert to a healthy filesystem state in case of failed scriptexecutions. Our experimental analysis indicates that our approach can resolve any …,International Workshop of Algorithmic Aspects of Cloud Computing,2016,1
Scalable Indexing and Adaptive Querying of RDF Data in the cloud,Nikolaos Papailiou; Dimitrios Tsoumakos; Ioannis Konstantinou; Panagiotis Karras; Nectarios Koziris,Abstract Efficient RDF data management systems are central to the vision of the SemanticWeb. The enormous increase in both user and machine generated content dictates forscalable solutions in triple data stores. Current systems manage to decentralize some or allthe stages of RDF data management; scaling to arbitrarily large numbers of triples. Yet;these systems prove highly inflexible in adjusting their behavior relative to the query in hand.Queries over triple data include multiple joins with varying degrees of selectivity and cost. Inmany cases; a join performed on a single centralized computer node is highly preferable.Thus; both informed query planning and adaptive join execution are necessary to gainoptimal performance in both selective and non selective queries. Towards that direction; wedescribe H2RDF+; an RDF store that efficiently performs distributed joins over a multiple …,Proceedings of Semantic Web Information Management on Semantic Web Information Management,2014,1
Brown dwarf: a P2P data-warehousing system,Katerina Doka; Dimitrios Tsoumakos; Nectarios Koziris,Abstract In this demonstration we present the Brown Dwarf; a distributed system designed toefficiently store; query and update multidimensional data. Deployed on any number ofcommodity nodes; our system manages to distribute large volumes of data over networkpeers on-the-fly and process queries and updates on-line through cooperating nodes thathold parts of a materialized cube. Moreover; it adapts its resources according to demandand hardware failures and is cost-effective both over the required hardware and softwarecomponents. All the aforementioned functionality will be tested using various datasets andquery loads.,Proceedings of the 19th ACM international conference on Information and knowledge management,2010,1
Search; Replication and Grouping for Unstructured P2P Networks,Dimitrios Tsoumakos,In my dissertation; I present a suite of protocols that assist in efficient content location anddistribution in unstructured Peer-to-Peer overlays. The basis of these schemes is their abilityto learn from past interactions; increasing their performance with time. Peer-to-Peer (P2P)networks are gaining increasing attention from both the scientific and the large Internet usercommunity. Popular applications utilizing this new technology offer many attractive featuresto a growing number of users. P2P systems have two basic functions: Content search anddissemination. Search (or lookup) protocols define how participants locate remotelymaintained resources. In data dissemination; users transmit or receive content from single ormultiple sites in the network. P2P applications traditionally operate under purelydecentralized and highly dynamic environments. Unstructured systems represent a …,*,2006,1
A Framework for Distributed Human Tracking,Konstantinos Bitsakos; Dimitrios Tsoumakos; Yiannis Aloimonos; Nick Roussopoulos,Abstract—Today; more than ever; monitoring and surveillance systems play an importantrole in many aspects of our lives. Technology plays a vital role in our efforts to create; storeand analyze vast amounts of data for both security and commercial purposes. In this paper;we propose an application which combines research performed in computer networks;multimedia databases and computer vision. We consider the problem where a number ofnetworks are interconnected. Each of the individual nodes (networks) are collecting;processing and storing data from several sensors (cameras). Specifically; we emphasize onhow the data (images) are processed by the individual nodes and how the information istransmitted; so that queries involving multiple nodes can be answered. During this process;we also identify several challenges related to sharing voluminous content provided by …,Department of Computer Science; University of Maryland,*,1
A Similarity-based Approach to Modeling Graph Operators,Tasos Bakogiannis; Giannis Giannakopoulos; Dimitrios Tsoumakos; Nectarios Koziris,Abstract: As graph representations of data emerge in multiple domains; data analysts needto be able to select among a magnitude of different graph inputs based on the effects theyinduce when a variety of operators are applied to them. Exhaustive execution of an operatorover the bulk of the available data sources is impractical due to the massive resources itrequires. Additionally; the same process would have to be re-implemented whenever adifferent operator is considered. To address this challenge; this work proposes an efficientgraph operator modeling methodology. Our novel approach focuses on the inputsthemselves; utilizing graph similarity to infer knowledge about multiple input graphs. Themodeled operator is only executed for a small subset of the available graphs and itsbehavior is approximated for the rest of the graphs using Machine Learning. This method …,arXiv preprint arXiv:1802.05536,2018,*
Skyline Queries in O (1) time?,Spyros Sioutas; Kostas Tsichlas; Andreas Kosmatopoulos; Apostolos N Papadopoulos; Dimitrios Tsoumakos; Katerina Doka,Abstract: The skyline of a set $ P $ of points ($ SKY (P) $) consists of the" best" points withrespect to minimization or maximization of the attribute values. A point $ p $ dominatesanother point $ q $ if $ p $ is as good as $ q $ in all dimensions and it is strictly better than $q $ in at least one dimension. In this work; we focus on the static $2 $-d space and provideexpected performance guarantees for $3 $-sided Range Skyline Queries on the Grid; where$ N $ is the cardinality of $ P $; $ B $ the size of a disk block; and $ R $ the capacity of mainmemory. We present the MLR-tree; which offers optimal expected cost for finding planarskyline points in a $3 $-sided query rectangle; $ q=[a; b]\times (-\infty; d] $; in both RAM andI/O model on the grid $[1; M]\times [1; M] $; by single scanning only the points contained in $SKY (P) $. In particular; it supports skyline queries in a $3 $-sided range in $ O (t\cdot t …,arXiv preprint arXiv:1709.03949,2017,*
Towards an Algebraic Cost Model for Graph Operators,Alexander Singh; Dimitrios Tsoumakos,Abstract Graph Analytics has been gaining an increasing amount of attention in recentyears. This has given rise to the development of numerous graph processing and storageengines; each featuring different models in computation; storage and execution as well asperformance. Multi-Engine Analytics present a solution towards adaptive; cost-basedcomplex workflow scheduling to the best available underlying technology. To achieve this inthe Graph Analytics case; detailed and accurate cost models for the various runtimes andoperators must be defined and exported; such that intelligent planning can take place. In thiswork; we take a first step towards defining a cost model for graph-based operators based onan algebra and its primitives. We evaluate its accuracy over a state of the art graph databaseand discuss its advantages and shortcomings.,International Workshop on Algorithmic Aspects of Cloud Computing,2017,*
AURA: Recovering from Transient Failures in Cloud Deployments,Ioannis Giannakopoulos; Ioannis Konstantinou; Dimitrios Tsoumakos; Nectarios Koziris,In this work; we propose AURA; a cloud deployment tool used to deploy applications overproviders that tend to present transient failures. The complexity of modern cloudenvironments imparts an error-prone behavior during the deployment phase of anapplication; something that hinders automation and magnifies costs both in terms of timeand money. To overcome this challenge; we propose AURA; a framework that formulates anapplication deployment as a Directed Acyclic Graph traversal and re-executes the parts ofthe graph that failed. AURA achieves to execute any deployment script that updatesfilesystem related resources in an idempotent manner through the adoption of a layeredfilesystem technique. In our demonstration; we allow users to describe; deploy and monitorapplications through a comprehensive UI and showcase AURA's ability to overcome …,Cluster; Cloud and Grid Computing (CCGRID); 2017 17th IEEE/ACM International Symposium on,2017,*
A Decision Tree Based Approach Towards Adaptive Profiling of Cloud Applications,Ioannis Giannakopoulos; Dimitrios Tsoumakos; Nectarios Koziris,Abstract: Cloud computing has allowed applications to allocate and elastically utilizemassive amounts of resources of different types; leading to an exponential growth of theapplications' configuration space and increased difficulty in predicting their performance. Inthis work; we describe a novel; automated profiling methodology that makes no assumptionson application structure. Our approach utilizes oblique Decision Trees in order to recursivelypartition an application's configuration space in disjoint regions; choose a set ofrepresentative samples from each subregion according to a defined policy and returns amodel for the entire configuration space as a composition of linear models over eachsubregion. An extensive experimental evaluation over real-life applications and syntheticperformance functions showcases that our scheme outperforms other state-of-the-art …,arXiv preprint arXiv:1704.02855,2017,*
MuSQLE: Distributed SQL query execution over multiple engine environments,Victor Giannakouris; Nikolaos Papailiou; Dimitrios Tsoumakos; Nectarios Koziris,Multi-engine analytics has been gaining an increasing amount of attention from both theacademic and the industrial community as it can successfully cope with the heterogeneityand complexity that the plethora of frameworks; technologies and requirements havebrought forth. It is now common for a data analyst to combine data that resides on multipleand totally independent engines and perform complex analytics queries. Multi-enginesolutions based on SQL can facilitate such efforts; as SQL is a popular standard that themajority of data-scientists understands. Existing solutions propose a middleware thatcentrally optimizes query execution for multiple engines. Yet; this approach requires manualintegration of every primitive engine operator along with its cost model; rendering theprocess of adding new operators or engines highly inextensible. To address this issue we …,Big Data (Big Data); 2016 IEEE International Conference on,2016,*
Fair; Fast and Frugal Large-Scale Matchmaking for VM Placement,Nikolaos Korasidis; Ioannis Giannakopoulos; Katerina Doka; Dimitrios Tsoumakos; Nectarios Koziris,Abstract VM placement; be it in public or private clouds; has a decisive impact on theprovider's interest and the customer's needs alike; both of which may vary over time andcircumstances. However; current resource management practices are either statically boundto specific policies or unilaterally favor the needs of Cloud operators. In this paper we arguefor a flexible and democratic mechanism to map virtual to physical resources; trying tobalance satisfaction on both sides of the involved stakeholders. To that end; VM placementis expressed as an Equitable Stable Matching Problem (ESMP); where each party's policy istranslated to a preference list. A practical approximation for this NP-hard problem; modifiedaccordingly to ensure efficiency and scalability; is applied to provide equitable matchingswithin a reasonable time frame. Our experimental evaluation shows that; requiring no …,International Workshop of Algorithmic Aspects of Cloud Computing,2016,*
Distributed Wavelet Thresholding for Maximum Error Metrics,Ioannis Mytilinis; Dimitrios Tsoumakos; Nectarios Koziris,Abstract Modern data analytics involve simple and complex computations over enormousnumbers of data records. The volume of data and the increasingly stringent response-timerequirements place increasing emphasis on the efficiency of approximate query processing.A major challenge over the past years has been the efficient construction of fixed-spacesynopses that provide a deterministic quality guarantee; often expressed in terms of amaximum error metric. For data reduction; wavelet decomposition has proved to be a veryeffective tool; as it can successfully approximate sharp discontinuities and provide accurateanswers to queries. However; existing polynomial time wavelet thresholding schemes thatminimize maximum error metrics are constrained with impractical time and spacecomplexities for large datasets. In order to provide a practical solution to the problem; we …,Proceedings of the 2016 International Conference on Management of Data,2016,*
Algorithmic Aspects of Cloud Computing,Ioannis Karydis; Spyros Sioutas; Peter Triantafillou; Dimitrios Tsoumakos,The International Workshop on Algorithmic Aspects of Cloud Computing (ALGOCLOUD) isan annual event aiming to tackle the diverse new topics in the emerging area of algorithmicaspects of computing and data management in the cloud. The increasing adoption of cloudcomputing introduces a variety of parallel and distributed algorithmic models andarchitectures. To leverage elastic cloud resources; scalability has to be a fundamentalarchitectural design trait of new cloud databases. This challenge is manifested in new datamodels (NoSQL); replication; caching and partitioning schemes; relaxed consistency andtransaction guarantees; as well as new protocols; APIs; indexing and storage services. Theaim of the workshop is to bring together researchers and practitioners in cloud computingalgorithms; service design; and data architectures to exchange ideas and contribute to …,*,2016,*
kdANN+: A Rapid AkNN Classifier for Big Data,Athanasios Tsakalidis; Dimitrios Tsoumakos; Giannis Tzimas,Abstract. A k-nearest neighbor (kNN) query determines the k nearest points; using distancemetrics; from a given location. An all k-nearest neighbor (AkNN) query constitutes a variationof a kNN query and retrieves the k nearest points for each point inside a database. Theirmain usage resonates in spatial databases and they consist the backbone of many location-based applications and not only. In this work; we propose a novel method for classifyingmultidimensional data using an AkNN algorithm in the MapReduce framework. Ourapproach exploits space decomposition techniques for processing the classificationprocedure in a parallel and distributed manner. To our knowledge; we are the first to studythe kNN classification of multidimensional objects under this perspective. Through anextensive experimental evaluation we prove that our solution is efficient; robust and …,Transactions on Large-Scale Data-and Knowledge-Centered Systems XXIV: Special Issue on Database-and Expert-Systems Applications,2016,*
Optimizing; Planning and Executing Analytics Workflows over Multiple Engines.,Katerina Doka; Maxim Filatov; Victor Giannakouris; Verena Kantere; Nectarios Koziris; Christos Mantas; Nikolaos Papailiou; Vassilis Papaioannou; Dimitrios Tsoumakos,ABSTRACT Big data analytics have become a necessity to businesses worldwide. Thecomplexity of the tasks they execute is ever increasing due to the surge in data and taskheterogeneity. Current analytics platforms; while successful in harnessing multiple aspectsof this “data deluge”; bind their efficacy to a single data and compute model and oftendepend on proprietary systems. However; no single execution engine is suitable for all typesof computation and no single data store is suitable for all types of data. To this end; wepresent and demonstrate a platform that designs; optimizes; plans and executes complexanalytics workflows over multiple engines. Our system enables users to create workflows ofvariable detail concerning the execution semantics; depending on their level of expertiseand interest. The workflows are then analysed in order to determine missing execution …,EDBT/ICDT Workshops,2016,*
Heterogeneous k-anonymization with high utility,Katerina Doka; Mingqiang Xue; Dimitrios Tsoumakos; Panagiotis Karras; Alfredo Cuzzocrea; Nectarios Koziris,Among the privacy-preserving approaches that are known in the literature; h-anonymityremains the basis of more advanced models while still being useful as a stand-alonesolution. Applying h-anonymity in practice; though; incurs severe loss of data utility; thuslimiting its effectiveness and reliability in real-life applications and systems. However; suchloss in utility does not necessarily arise from an inherent drawback of the model itself; butrather from the deficiencies of the algorithms used to implement the model. Conventionalapproaches rely on a methodology that publishes data in homogeneous generalizedgroups. An alternative modern data publishing scheme focuses on publishing the data inheterogeneous groups and achieves higher utility; while ensuring the same privacyguarantees. As conventional approaches cannot anonymize data following this …,Big Data (Big Data); 2015 IEEE International Conference on,2015,*
D-P2P-Sim+: A novel distributed framework for P2P protocols performance testing,Spyros Sioutas; Evangelos Sakkopoulos; Alexandros Panaretos; Dimitrios Tsoumakos; Panagiotis Gerolymatos; Giannis Tzimas; Yannis Manolopoulos,Abstract In recent technologies like IoT (Internet of Things) and Web 2.0; a critical problemarises with respect to storing and processing the large amount of collected data. In thispaper we develop and evaluate distributed infrastructures for storing and processing largeamount of such data. We present a distributed framework that supports customizeddeployment of a variety of indexing engines over million-node overlays. The proposedframework provides the appropriate integrated set of tools that allows applicationsprocessing large amount of data; to evaluate and test the performance of various applicationprotocols for very large scale deployments (multi million nodes–billions of keys). The keyaim is to provide the appropriate environment that contributes in taking decisions regardingthe choice of the protocol in storage P2P systems for a variety of big data applications …,Journal of Systems and Software,2015,*
A Cloud-Based Data Network Approach for Translational Cancer Research,Wei Xing; Dimitrios Tsoumakos; Moustafa Ghanem,Abstract We develop a new model and associated technology for constructing andmanaging self-organizing data to support translational cancer research studies. We employa semantic content network approach to address the challenges of managing cancerresearch data. Such data is heterogeneous; large; decentralized; growing and continuallybeing updated. Moreover; the data originates from different information sources that may bepartially overlapping; creating redundancies as well as contradictions and inconsistencies.Building on the advantages of elasticity of cloud computing; we deploy the cancer datanetworks on top of the CELAR Cloud platform to enable more effective processing andanalysis of Big cancer data.,*,2015,*
D-P2P-Sim+: A novel distributed framework for P2P protocols performance testing,Spyros Sioutas; Evangelos Sakkopoulos; Alexandros Panaretos; Dimitrios Tsoumakos; Panagiotis Gerolymatos; Giannis Tzimas; Yannis Manolopoulos,Abstract: In recent IoT (Internet of Things) and Web 2.0 technologies; a critical problemarises with respect to storing and processing the large amount of collected data. In thispaper we develop and evaluate distributed infrastructures for storing and processing largeamount of such data. We present a distributed framework that supports customizeddeployment of a variety of indexing engines over million-node overlays. The proposedframework provides the appropriate integrated set of tools that allows applicationsprocessing large amount of data; to evaluate and test the performance of various applicationprotocols for very large scale deployments (multi million nodes-billions of keys). The key aimis to provide the appropriate environment that contributes in taking decisions regarding thechoice of the protocol in storage P2P systems for a variety of big data applications. Using …,arXiv preprint arXiv:1404.0696,2014,*
SART: speeding up query processing in sensor networks with an autonomous range tree structure,Spyros Sioutas; Dimitrios Tsoumakos; Alexandros Panaretos; Giannis Tzimas; Ioannis Karydis; Dimitrios Tsolis,Abstract We consider the problem of constructing efficient P2P overlays for sensornetsproviding" Energy-Level Application and Services". In this context; assuming that a sensor isresponsible for executing some program task but unfortunately it's energy-level is lower thana pre-defined threshold. Then; this sensor should be able to introduce a query to the wholesystem in order to discover efficiently another sensor with the desired energy level; in whichthe task overhead must be eventually forwarded. In this way; the" Life-Expectancy" of thewhole network could be increased. Sensor nodes are mapped to peers based on theirenergy level. As the energy levels change; the sensor nodes would have to move from onepeer to another and this operation is very crucial for the efficient scalability of the proposedsystem. Similarly; as the energy level of a sensor node becomes extremely low; that node …,ACM SIGAPP Applied Computing Review,2012,*
SART: dynamic P2P query processing in sensor networks with probabilistic guarantees,Spyros Sioutas; Alexandros Panaretos; Ioannis Karydis; Dimitrios Tsoumakos,Abstract We consider the problem of constructing efficient P2P overlays for sensornetsproviding" Energy-Level Application and Services". In this context; assuming that a sensor isresponsible for executing some program task but unfortunately it's energy-level is lower thana pre-defined threshold. Then; this sensor should be able to introduce a query to the wholesystem in order to discover efficiently another sensor with the desired energy level; in whichthe task overhead must be eventually forwarded. In this way; the" Life-Expectancy" of thewhole network could be increased. Sensor nodes are mapped to peers based on theirenergy level. As the energy levels change; the sensor nodes would have to move from onepeer to another and this operation is very crucial for the efficient scalability of the proposedsystem. Similarly; as the energy level of a sensor node becomes extremely low; that node …,Proceedings of the 27th Annual ACM Symposium on Applied Computing,2012,*
DREAM: A Distributed fRamework for customized dEployment of a vAriety of indexing engines over Million-node overlays,Evangelos Sakkopoulos; Alexandros Panaretos; Spyros Sioutas; Dimitrios Tsoumakos; George Papaloukopoulos; Anastasia Saltou,Abstract In this paper we present a distributed framework that supports customizeddeployment of a variety of indexing engines over million-node overlays. The key aim is toprovide the appropriate integrated set of tools that allows numerous applications with large-scale; different requirements to evaluate and test the performance of various applicationprotocols for very large scale deployments (multi million nodes-billions of keys). Usinglightweight and efficient collection mechanisms; our system enables real-time registration ofmultiple measures; integrating support for real-life parameters such as node failure modelsand recovery strategies. Experiments have been performed at the PlanetLab network and ata typical research laboratory in order to verify scalability and show maximum re-usability ofour setup.,Proceedings of the 27th Annual ACM Symposium on Applied Computing,2012,*
A DHT-Based system for the management of loosely structured; multidimensional data,Athanasia Asiki; Dimitrios Tsoumakos; Nectarios Koziris,Abstract In this paper we present LinkedPeers; a DHT-based system designed for efficientdistribution and processing of multidimensional; loosely structured data over a Peer-to-Peeroverlay. Each dimension is further annotated with the use of concept hierarchies. Thesystem design aims at incorporating two important features; namely large-scale support forpartially-structured data and high-performance; distributed query processing includingmultiple aggregates. To enable the efficient resolution of such queries; LinkedPeers utilizesa conceptual chain of DHT rings that stores data in a hierarchy-preserving manner.Moreover; adaptive mechanisms detect dynamic changes in the query workloads and adjustthe granularity of the indexing on a per node basis. The pre-computation of possible futurequeries is also performed during the resolution of an incoming query. Extensive …,*,2012,*
LinkedPeers: a distributed system for interlinking multidimensional data,Athanasia Asiki; Dimitrios Tsoumakos; Nectarios Koziris,Abstract In this paper we present LinkedPeers; a distributed system designed for efficientdistribution and processing of multidimensional hierarchical data over a Peer-to-Peeroverlay. he system design aims at incorporating two important features; namely large-scalesupport for partially-structured data and high-performance; distributed query processingincluding multiple aggregates. To achieve that; LinkedPeers utilizes a conceptual chain ofDHT rings that stores data in a hierarchy-preserving manner and is able to adjust both thegranularity of indexing and the amount of pre-computation according to the incomingworkload. Extensive experiments prove that our system is very efficient achieving over 85%precision in answering queries while minimizing communication cost and adapting itsindexing to the incoming queries.,International Conference on Database and Expert Systems Applications,2011,*
Brown Dwarf: A Distributed Data Warehouse for the Cloud,Katerina Doka; Dimitrios Tsoumakos; Nectarios Koziris,ABSTRACT In this paper we present the Brown Dwarf; a distributed system designed toefficiently store; query and update multidimensional data over commodity network nodes;without the use of any proprietary tool. Brown Dwarf manages to distribute a highly effectivecentralized structure among peers on-the-fly; reducing cube creation and query times byenforcing parallelization. Both point and aggregate queries as well as updates are naturallyperformed on-line through cooperating nodes that hold parts of a fully or partiallymaterialized data cube. The system also employs an adaptive replication scheme thatexpands or shrinks the units of the distributed data structure for minimal storageconsumption against failures and load skew. Brown Dwarf collects many of the features ofan application to be deployed in the Cloud: It adapts its resources according to demand …,*,2009,*
Optimizing Data Management in Grid Environments,Antonis Zissimos; Katerina Doka; Antony Chazapis; Dimitrios Tsoumakos; Nectarios Koziris,Abstract Grids currently serve as platforms for numerous scientific as well as businessapplications that generate and access vast amounts of data. In this paper; we address theneed for efficient; scalable and robust data management in Grid environments. We proposea fully decentralized and adaptive mechanism comprising of two components: A DistributedReplica Location Service (DRLS) and a data transfer mechanism called GridTorrent. Theyboth adopt Peer-to-Peer techniques in order to overcome performance bottlenecks andsingle points of failure. On one hand; DRLS ensures resilience by relying on a Byzantine-tolerant protocol and is able to handle massive concurrent requests even during node churn.On the other hand; GridTorrent allows for maximum bandwidth utilization throughcollaborative sharing among the various data providers and consumers. The proposed …,OTM Confederated International Conferences" On the Move to Meaningful Internet Systems",2009,*
Department of Electrical and Computer Engineering National Technical University of Athens,Katerina Doka; Dimitrios Tsoumakos; Nectarios Koziris,Abstract In this paper we present the Brown Dwarf; a distributed system designed toefficiently store; query and update multidimensional data over a Peer-to-Peer overlay. TheBrown Dwarf manages to distribute a highly effective centralized structure among peers on-the-fly. Both point and aggregate queries are then naturally answered online throughcooperating nodes that hold parts of a fully or partially materialized data cube. Updates arealso performed on-line; eliminating the usually costly over-night process. To tackle dynamicshifts in skew as well as network and node failures; our system employs an adaptivereplication scheme; by creating copies of various units of the distributed data structureaccording to the load as well as the churn rate of the network. This process; called mirroring;ensures balanced load distribution; guarantees resilience and allows for smooth query …,*,2009,*
Cooperative Information Systems (CoopIS) 2006 International Conference-P2P Systems-An Adaptive Probabilistic Replication Method for Unstructured P2P Networks,Dimitrios Roussopoulos; Nick Tsoumakos,*,Lecture Notes in Computer Science,2006,*
AUXILIARY REVIEWERS,Dimitrios Tsoumakos; Hung-Yu Wei; Yinlong Xu,Page 1. PROGRAM COMMITTEE Javier M. Aguiar; Universidad de Valladolid; Spain AntonioFernández Anta; IMDEA Networks Institute; Spain Carlos Henggeler Antunes; DEEC - Universityof Coimbra / INESC Coimbra; Portugal Jorge Barbosa; FEUP; Portugal Siegfried Benkner;University of Vienna; Austria Simona Bernardi; Centro Universitario de la Defensa - AcademiaGeneral Militar; Spain Dumitru Burdescu; University of Craiova; Romania Blanca Caminero;Universidad de Castilla-La Mancha; Spain Davide Careglio; Universitat Politècnica de Catalunya;Spain Calin Ciufudean; Stefan cel Mare University; Romania Georges Da Costa; IRIT; PaulSabatier University; France Amélie Coulbaut-Lazzarini; Université Versailles Saint Quentin enYvelines; France Brian Donnellan; Maynooth University; Ireland …,*,*,*
2009 IEEE Ninth International Conference on Peer-to-Peer Computing (P2P),R Jimenez; F Osmani; B Knutsson,The birth and evolution of peer-to-peer (P2P) protocols have; for the most part; been aboutpeer discovery. Napster; one of the first P2P protocols; was basically FTP/HTTP plus a wayof finding hosts willing to send you the file. Since then; both the transfer and peer discoverymechanisms have improved; but only recently have we seen a real push to completelydecentralized peer discovery to increase...,*,*,*
SustainCom 2015 Program Committee,Afrooz Moatari Kazerouni; Ahmed Zobaa; Blanca Caminero; Bo Mao; Bruce Nordman; Chang Wu Yu; Chau Yuen; Dimitrios Tsoumakos; Gianluca Rizzo; Igor Wojnicki; John Kaiser Calautit; Ken Christensen; Ligang He; Lingfeng Wang; Mani Krishna; Marco Listanti; Muhammad Hasan; Qiang Zou; Rabi Mahapatra; Sotirios Ziavras; Thangamani M Thangamani; France William Liu; Xiaodong Liu; Yingliang Yue,Afrooz Moatari Kazerouni; Ecole Polytechnique de Montreal; Canada Ahmed Zobaa; Universityof Exeter; UK Alessandro De Masi; Milan Polytechnic; Italy Blanca Caminero; Universidad deCastilla-La Mancha; Spain Bo Mao; Xiamen University; China Bruce Nordman; Lawrence BerkeleyNational Laboratory; USA Chang Wu Yu; Chung Hua University; Taiwan Chau Yuen; SingaporeUniversity of Technology and Design; Singapore Dimitrios Tsoumakos; Ionian University; GreeceGianluca Rizzo; University of Applied Sciences HES-SO; Switzerland Igor Wojnicki; AGH Universityof Science and Technology; Poland John Kaiser Calautit; University of Leeds; UK KenChristensen; University of South Florida; USA Ligang He; University of Warwick; UK LingfengWang; University of Toledo; USA Mani Krishna; University of Massachusetts Amherst; USA MarcoListanti; University of Roma "La Sapienza"; Italy Mitchell M. Tseng; Hong Kong University …,*,*,*
NoSQL-Net 2015 Workshop Program Committee,Irena Holubova; Volha Bryl; Ioana Ciuciu; Christian Dirschl; Wolters Kluwer; Germany Michal Kratky; Jaroslav Pokorny; NICTA Sherif Sakr; Dimitrios Tsoumakos; Ondrej Zamazal,Chairs Lena Wiese; Knowledge Engineering Research Group; Georg-August-UniversitätGöttingen; Germany Valentina Janev; Institute “Mihajlo Pupin;” University of Belgrade; Republicof Serbia Irena Holubova; Department of Software Engineering; Charles University inPrague; Czech Republic … Volha Bryl; University of Mannheim; Germany Ioana Ciuciu;Babes-Bolyai University; Cluj-Napoca; Romania Christian Dirschl; Wolters Kluwer; GermanyMichal Kratky; Technical University of Ostrava; Czech Republic Danh Le Phuoc; Insight Centrefor Data Analytics; National University of Ireland; Galway Jaroslav Pokorny; Charles Universityin Prague; Czech Republic Sherif Sakr; NICTA; Sydney; Australia Dimitrios Tsoumakos; NationalTechnical University of Athens; Greece Sanja Vranes; Institute Mihajlo Pupin; University ofBelgrade; Republic of Serbia Ondrej Zamazal; University of Economics; Prague; Czech …,*,*,*
D7. 1ARCOMEM Development Guideline,Dimitrios Tsoumakos,Executive Summary To enable the multiple international ARCOMEM software developmentteams to work together effectively; a software development infrastructure has to be setup atthe start of the project. This deliverable comprises an introduction of the developmentinfrastructure; describing the tools that will be used during the design; implementation anddeployment phases of the project. It also contains guidelines and recommendations on howto collaborate within ARCOMEM and use the tools involved in the software developmentlifecycle.,*,*,*
Intelligent; Multi-Engine Resource Scheduler for Big Data Analytics Workflows,Katerina Doka; Dimitrios Tsoumakos; Nectarios Koziris,Abstract—Big data analytics have become a necessity to businesses worldwide. Currentanalytics platforms; while successful in harnessing multiple aspects of this “data deluge”;bind their efficacy to a single data and compute model and often depend on proprietarysystems. However; no single execution engine is suitable for all types of computation and nosingle data store is suitable for all types of data. To this end; we present IReS; the IntelligentResource Scheduler for complex analytics workflows executed over multi-engineenvironments. Our system models the cost and performance of the required tasks over theavailable platforms. IReS is then able to match distinct workflow parts to the execution and/orstorage engine among the available ones in order to optimize with respect to a user-definedpolicy.,*,*,*
D1. 1User Requirements and System Architecture,Dimitrios Tsoumakos; Yannis Stavrakas; Katerina Doka; Cosmin Cabulea; Günther Schefbeck; France Lasfargues; Diana Maynard; Bart Thomee,Executive Summary The aim of this document is to gather the use cases; compile the userrequirements; and present the detailed ARCOMEM system architecture. The first step is tocollect the use cases relevant to the two ARCOMEM applications from the intended targetgroups. The uses cases are then prioritized and a set of requirements is extracted; whichleads to the specification of the overall architecture.,*,*,*
SustainCom 2014,Nour Ali; Siegfried Benkner; Rodrigo Calheiros; Blanca Caminero; Davide Careglio; Simon Caton; Luca Chiaraviglio; Ken Christensen; Yeh-Ching Chung; Bruno Ciciani; Edward Curry; Miguel Garcia Pineda; Saurabh Garg; Oriol Gomis; Muhammad Hasan; Ligang He; Lorenz Hilty; Houman Homayoun; Mani Krishna; Dimosthenis Kyriazis; Marco Listanti; William Liu; Mitchell M Tseng; Rabi Mahapatra; Apurva Mohan; Surya Nepal; Bruce Nordman; Carlo Alberto Nucci; Vitor Pires; Pierluigi Plebani; Radu Prodan; Gang Qu; Gang Quan; Gianluca Rizzo; Ivan Rodero; Enrique Romero-Cadaval; Afshin Tafazzoli; Dimitrios Tsoumakos; Lingfeng Wang; Igor Wojnicki; Chang Wu Yu; Ramin Yahyapour; Qi Yu; Chau Yuen,Nour Ali; University of Brighton; United Kingdom Siegfried Benkner ; University of Vienna; AustriaRodrigo Calheiros ; The University of Melbourne; Australia Blanca Caminero; Universidad deCastilla-La Mancha; Spain Davide Careglio; Universitat Politècnica de Catalunya; Spain SimonCaton ; Karlsruhe Institute of Technology; Germany Luca Chiaraviglio; University of RomeSapienza; Italy Ken Christensen; University of South Florida; USA Yeh-Ching Chung; NationalTsing Hua University; Taiwan Bruno Ciciani; University of Rome "La Sapienza"; Italy EdwardCurry; National University of Ireland; Galway; Ireland Miguel Garcia Pineda; Universitat deValencia; Spain Saurabh Garg ; IBM Research Australia; Australia Oriol Gomis; ETS d'EnginyeriaIndustrial de Barcelona; Spain Muhammad Hasan; Texas A&M University; USA Ligang He; Universityof Warwick; United Kingdom Lorenz Hilty; Empa; Switzerland Houman Homayoun …,*,*,*
ICDE 2009,Adam Silberstein; Akrivi Vlachou; Alexander G Connor; Alfredo Goñi; Ali Inan; Amar Phanishayee; Amruta Joshi; Anastasios Kementsietsidis; Ander de Keijzer; Anduo Wang; Anish Das Sarma; Arjun Dasgupta; Arthur H Lee; Arvind Arasu; Arvind Thiagarajan; Badrish Chandramouli; Barzan Mozafari; Bee-Chung Chen; Bhargav Kanagal; Bing-Rong Lin; Bingsheng He; Biswanath Panda; Bo Xu; Bogdan Alexe; Bolin Ding; Brandon Unger; Brian Ruttenberg; Bruce Lindsa; Caetano Traina Jr; Cao Yu; Carina F Dorneles; Changbin Liu; Changbin Song; Changliang Wang; Charalambos Charalambous; Chengkai Li; Choudur K Lakshminarayan; Chris Mayfield; Chris Re; Christian Beecks; Christoph Lofi; Christophe Bobineau; Christos Doulkeridis; Chuan Xiao; Congxing Cai; Conny Franke; Craig Freedman; Cyrus Shahabi; Daniela Leal Musa; David Detlefs; David Novak; Davide Mazza; Debojyoti Dutta; Derek Hao Hu; Dimitrios Tsoumakos; Dimitris Sacharidis; Dimitris Tsoumakos; Djoerd Hiemstra; Dominic Mueller; Duygu Ucar; Eduardo Mena; Eirinaios Michelakis; Emmanuel Müller; Eunseok Yang; Evan Welbourne; Evangelos Dellis; Fan Yang; Fatma Ozcan; Florin Rusu; Gabriel Ghinita; Gagan Agrawal; Gaoping Zhu; George Beskales; George Pallis; Grigoris Karvounarakis; Guadalupe Canahuate; Haibo Hu,Adam Silberstein Akrivi Vlachou Alexander G. Connor Alfredo Goñi Ali Inan Amar PhanishayeeAmruta Joshi Anastasios Kementsietsidis Ander de Keijzer Anduo Wang Anish Das Sarma ArjunDasgupta Arthur H. Lee Arvind Arasu Arvind Thiagarajan Badrish Chandramouli Barzan MozafariBee-Chung Chen Bhargav Kanagal Bing-Rong Lin Bingsheng He Biswanath Panda Bo Xu BogdanAlexe Bolin Ding Brandon Unger Brandon Unger Brian Ruttenberg Bruce Lindsa Caetano TrainaJr Cao Yu Carina F. Dorneles Changbin Liu Changbin Song Changliang Wang CharalambosCharalambous Chengkai Li Choudur K. Lakshminarayan Chris Mayfield … Chris Re ChristianBeecks Christoph Lofi Christophe Bobineau Christos Doulkeridis Chuan Xiao Congxing CaiConny Franke Craig Freedman Cyrus Shahabi Daniela Leal Musa David Detlefs David NovakDavide Mazza Debojyoti Dutta Derek Hao Hu Dimitrios Tsoumakos Dimitris Sacharidis …,*,*,*
Reviewer committee,Cecile Åberg; Johan Åberg; Torsten Ackemann; Kevin Almeroth; Gal Badishi; Daniel Bauer; Karlo Berket; Hannes Birck; Sabrina De Capitani di Vimercati; Tyson Condie; Vasilios Darlagiannis; Mayur Deshpande; Ralph Deters; Thomas Dübendorfer; Claudiu Duma; Patrick Eaton; Claus Eikemeier; Viiveke Fåk; George Fankhauser; Karoly Farkas; Prasanna Ganesan; Nitin Garg; Donatien Grolaux; Abhishek Gupta; Emir Halepovic; David Hausheer; Oliver Heckmann; Almut Herzog; Daniel Hughes; Paul Hurley; Evangelia Kalyvianaki; Kostas Katrinis; Christoph Kessler; Patrick Lambrix; Nicolas C Liebau; Tsung-Nan Lin; Dahlia Malkhi; Marco Mamei; Sergio Marti; Carlo Mastroianni; Håkan Mattsson; Martin Mauve; Roie Melamed; Valentin Mesaros; Mirco Musolesi; Kaj Nyström; Luc Onana Alima; Georgios Parissidis; Panayiotis Periorellis; Marius Portmann; Marc Rennhard; Pierangela Samarati; Glenn Scott; Diana Senn; Daniel Sigg; Alan Smith; Juha Takkinen; Dimitrios Tsoumakos; Eduard Turcan; Srikumar Venugopal; James Walkerdine; Honghao Wang; John Wilander; Bai Xiaole; Zhiyong Xu; Keping Zhao; Yue Zhao; Jianjun Zhang; Tingting Zhang; Yingwu Zhu; Gil Zussman,The program committee would like to express thanks to all the additional reviewers who helpedin reviewing the submitted papers … Cecile Åberg Johan Åberg Torsten Ackemann Kevin AlmerothGal Badishi Daniel Bauer Karlo Berket Hannes Birck Sabrina De Capitani di Vimercati TysonCondie Vasilios Darlagiannis Mayur Deshpande Ralph Deters Thomas Dübendorfer ClaudiuDuma Patrick Eaton Claus Eikemeier Viiveke Fåk George Fankhauser Karoly Farkas PrasannaGanesan Nitin Garg Donatien Grolaux Abhishek Gupta Emir Halepovic David Hausheer OliverHeckmann Almut Herzog Daniel Hughes Paul Hurley Evangelia Kalyvianaki Kostas KatrinisChristoph Kessler Patrick Lambrix Nicolas C. Liebau Tsung-Nan Lin … Dahlia Malkhi MarcoMamei Sergio Marti Carlo Mastroianni Håkan Mattsson Martin Mauve Roie Melamed ValentinMesaros Mirco Musolesi Kaj Nyström Luc Onana Alima Georgios Parissidis Panayiotis …,*,*,*
