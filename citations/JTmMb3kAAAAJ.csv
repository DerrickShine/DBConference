PLP: page latch-free shared-everything OLTP,Ippokratis Pandis; Pinar Tözün; Ryan Johnson; Anastasia Ailamaki,Abstract Scaling the performance of shared-everything transaction processing systems tohighly-parallel multicore hardware remains a challenge for database system designers.Recent proposals alleviate locking and logging bottlenecks in the system; leaving pagelatching as the next potential problem. To tackle the page latching problem; we proposephysiological partitioning (PLP). The PLP design applies logical-only partitioning;maintaining the desired properties of shared-everything designs; and introduces a multi-rooted B+ Tree index structure (MRBTree) which enables the partitioning of the accesses atthe physical page level. Logical partitioning and MRBTrees together ensure that allaccesses to a given index page come from a single thread and; hence; can be entirely latch-free; an extended design makes heap page accesses thread-private as well. Eliminating …,Proceedings of the VLDB Endowment,2011,82
OLTP on hardware islands,Danica Porobic; Ippokratis Pandis; Miguel Branco; Pınar Tözün; Anastasia Ailamaki,Abstract Modern hardware is abundantly parallel and increasingly heterogeneous. Thenumerous processing cores have nonuniform access latencies to the main memory and tothe processor caches; which causes variability in the communication costs. Unfortunately;database systems mostly assume that all processing cores are the same and thatmicroarchitecture differences are not significant enough to appear in critical databaseexecution paths. As we demonstrate in this paper; however; hardware heterogeneity doesappear in the critical path and conventional database architectures achieve suboptimal andeven worse; unpredictable performance. We perform a detailed performance analysis ofOLTP deployments in servers with multiple cores per CPU (multicore) and multiple CPUsper server (multisocket). We compare different database deployment strategies where we …,Proceedings of the VLDB Endowment,2012,51
From A to E: analyzing TPC's OLTP benchmarks: the obsolete; the ubiquitous; the unexplored,Pınar Tözün; Ippokratis Pandis; Cansu Kaynak; Djordje Jevdjic; Anastasia Ailamaki,Abstract Introduced in 2007; TPC-E is the most recently standardized OLTP benchmark byTPC. Even though TPC-E has already been around for six years; it has not gained thepopularity of its predecessor TPC-C: all the published results for TPC-E use a singledatabase vendor's product. TPC-E is significantly different than its predecessors. Some of itsdistinguishing characteristics are the non-uniform input creation; longer-running and morecomplicated transactions; more difficult partitioning etc. These factors slow down theadoption of TPC-E. In turn; there is little knowledge in the community about how TPC-Ebehaves micro-architecturally and within the database engine. To shed light on TPC-E; weimplement it on top of a scalable open-source database engine; Shore-MT; and perform aworkload characterization study; comparing it with the previous; much better known OLTP …,Proceedings of the 16th International Conference on Extending Database Technology,2013,41
ATraPos: Adaptive transaction processing on hardware Islands,Danica Porobic; Erietta Liarou; Pinar Tozun; Anastasia Ailamaki,Nowadays; high-performance transaction processing applications increasingly run onmultisocket multicore servers. Such architectures exhibit non-uniform memory accesslatency as well as non-uniform thread communication costs. Unfortunately; traditional shared-everything database management systems are designed for uniform inter-corecommunication speeds. This causes unpredictable access latencies in the critical path.While lack of data locality may be a minor nuisance on systems with fewer than 4processors; it becomes a serious scalability limitation on larger systems due to accesses tocentralized data structures. In this paper; we propose ATraPos; a storage manager designthat is aware of the non-uniform access latencies of multisocket systems. ATraPos achievesgood data locality by carefully partitioning the data as well as internal data structures (eg …,Data Engineering (ICDE); 2014 IEEE 30th International Conference on,2014,36
Slicc: Self-assembly of instruction cache collectives for oltp workloads,Islam Atta; Pinar Tozun; Anastasia Ailamaki; Andreas Moshovos,Abstract Online transaction processing (OLTP) is at the core of many data centerapplications. OLTP workloads are known to have large instruction footprints that foil existingL1 instruction caches resulting in poor overall performance. Prefetching can reduce theimpact of such instruction cache miss stalls; however; state-of-the-art solutions require largededicated hardware tables on the order of 40KB in size. SLICC is a programmer transparent;low cost technique to minimize instruction cache misses when executing OLTP workloads.SLICC migrates threads; spreading their instruction footprint over several L1 caches. Itexploits repetition within and across transactions; where a transaction's first iterationprefetches the instructions for subsequent iterations or similar subsequent transactions.SLICC reduces instruction misses by 58% on average for TPC-C and TPCE; thereby …,Proceedings of the 2012 45th Annual IEEE/ACM International Symposium on Microarchitecture,2012,22
Scalable and dynamically balanced shared-everything OLTP with physiological partitioning,Pınar Tözün; Ippokratis Pandis; Ryan Johnson; Anastasia Ailamaki,Abstract Scaling the performance of shared-everything transaction processing systems tohighly parallel multicore hardware remains a challenge for database system designers.Recent proposals alleviate locking and logging bottlenecks in the system; leaving pagelatching as the next potential problem. To tackle the page latching problem; we proposephysiological partitioning (PLP). PLP applies logical-only partitioning; maintaining thedesired properties of sharedeverything designs; and introduces a multi-rooted B+ Tree indexstructure (MRBTree) that enables the partitioning of the accesses at the physical page level.Logical partitioning and MRBTrees together ensure that all accesses to a given index pagecome from a single thread and; hence; can be entirely latch free; an extended design makesheap page accesses thread private as well. Moreover; MRBTrees offer an infrastructure …,The VLDB Journal—The International Journal on Very Large Data Bases,2013,20
STREX: boosting instruction cache reuse in OLTP workloads through stratified transaction execution,Islam Atta; Pinar Tözün; Xin Tong; Anastasia Ailamaki; Andreas Moshovos,Abstract Online transaction processing (OLTP) workload performance suffers frominstruction stalls; the instruction footprint of a typical transaction exceeds by far the capacityof an L1 cache; leading to ongoing cache thrashing. Several proposed techniques removesome instruction stalls in exchange for error-prone instrumentation to the code base; or asharp increase in the L1-I cache unit area and power. Others reduce instruction miss latencyby better utilizing a shared L2 cache. SLICC [2]; a recently proposed thread migrationtechnique that exploits transaction instruction locality; is promising for high core counts butperforms sub-optimally or may hurt performance when running on few cores. This papercorroborates that OLTP transactions exhibit significant intra-and inter-thread overlap in theirinstruction footprint; and analyzes the instruction stall reduction benefits. This paper …,ACM SIGARCH Computer Architecture News,2013,17
Dynamic fine-grained scheduling for energy-efficient main-memory queries,Iraklis Psaroudakis; Thomas Kissinger; Danica Porobic; Thomas Ilsche; Erietta Liarou; Pınar Tözün; Anastasia Ailamaki; Wolfgang Lehner,Abstract Power and cooling costs are some of the highest costs in data centers today; whichmake improvement in energy efficiency crucial. Energy efficiency is also a major designpoint for chips that power whole ranges of computing devices. One important goal in thisarea is energy proportionality; arguing that the system's power consumption should beproportional to its performance. Currently; a major trend among server processors; whichstems from the design of chips for mobile devices; is the inclusion of advanced powermanagement techniques; such as dynamic voltage-frequency scaling; clock gating; andturbo modes. A lot of recent work on energy efficiency of database management systems isfocused on coarse-grained power management at the granularity of multiple machines andwhole queries. These techniques; however; cannot efficiently adapt to the frequently …,Proceedings of the Tenth International Workshop on Data Management on New Hardware,2014,11
OLTP in wonderland: where do cache misses come from in major OLTP components?,Pınar Tözün; Brian Gold; Anastasia Ailamaki,Abstract For several decades; online transaction processing has been one of the mainapplications that drives innovations in the data management ecosystem; and in turn thedatabase and computer architecture communities. Despite the novel approaches fromindustry and various research proposals from academia; recent studies emphasize thatOLTP workloads still cannot exploit the full capability of modern processors. To betterintegrate OLTP and hardware in future systems; we perform a detailed analysis of instructionand data misses; the main causes of memory stalls. We demonstrate which operations andcomponents of a typical storage manager cause the majority of different types of misses ineach level of the memory hierarchy on a configuration that closely represents moderncommodity hardware. We also observe the impact of data working set size on these …,Proceedings of the Ninth International Workshop on Data Management on New Hardware,2013,11
Communix: A framework for collaborative deadlock immunity,Horatiu Jula; Pinar Tözün; George Candea,We present Communix; a collaborative deadlock immunity framework for Java programs.Deadlock immunity enables applications to avoid deadlocks that they previouslyencountered. Dimmunix; our deadlock immunity system; detects deadlocks and saves theirsignatures at runtime; then avoids execution flows that match these signatures; a signatureis an abstraction of the execution flow that led to deadlock. Dimmunix needs all the deadlockbugs in an application to manifest; in all possible ways; in order to provide full protectionagainst deadlocks for that application. Communix addresses this shortcoming by distributingthe deadlock signatures produced by Dimmunix. The signatures of a deadlock can protectagainst the deadlock any user connected to the Internet and running the same application;even if he/she did not experience the deadlock yet. Besides signature distribution …,Dependable Systems & Networks (DSN); 2011 IEEE/IFIP 41st International Conference on,2011,11
Micro-architectural Analysis of In-memory OLTP,Utku Sirin; Pinar Tözün; Danica Porobic; Anastasia Ailamaki,Abstract Micro-architectural behavior of traditional disk-based online transaction processing(OLTP) systems has been investigated extensively over thepast couple of decades. Resultsshow that traditional OLTP mostly under-utilize the available micro-architectural resources.In-memory OLTP systems; on the other hand; process all the data in main-memory; andtherefore; can omit the buffer pool. In addition; they usually adopt more lightweightconcurrency control mechanisms; cache-conscious data structures; and cleaner codebasessince they are usually designed from scratch. Hence; we expect significant differences inmicro-architectural behavior when running OLTP on platforms optimized for in-memoryprocessing as opposed to disk-based database systems. In particular; we expect that in-memory systems exploit micro architectural features such as instruction and data caches …,Proceedings of the 2016 International Conference on Management of Data,2016,9
A data-oriented transaction execution engine and supporting tools,Ippokratis Pandis; Pinar Tözün; Miguel Branco; Dimitris Karampinas; Danica Porobic; Ryan Johnson; Anastasia Ailamaki,Abstract Conventional OLTP systems assign each transaction to a worker thread and thatthread accesses data; depending on what the transaction dictates. This thread-to-transactionwork assignment policy leads to unpredictable accesses. The unpredictability forces eachthread to enter a large number of critical sections for the completion of even the simplest ofthe transactions; leading to poor performance and scalability on modern manycorehardware. This demonstration highlights the chaotic access patterns of conventional OLTPdesigns which are the source of scalability problems. Then; it presents a working prototypeof a transaction processing engine that follows a non-conventional architecture; called data-oriented or DORA. DORA is designed around the thread-to-data work assignment policy. Itdistributes the transaction execution to multiple threads and offers predictable accesses …,Proceedings of the 2011 ACM SIGMOD International Conference on Management of data,2011,8
ADDICT: advanced instruction chasing for transactions,Pinar Tözün; Islam Atta; Anastasia Ailamaki; Andreas Moshovos,Abstract Recent studies highlight that traditional transaction processing systems utilize themicro-architectural features of modern processors very poorly. L1 instruction cache and long-latency data misses dominate execution time. As a result; more than half of the executioncycles are wasted on memory stalls. Previous works on reducing stall time aim at improvinglocality through either hardware or software techniques. However; exploiting hardwareresources based on the hints given by the software-side has not been widely studied fordata management systems. In this paper; we observe that; independently of their high-levelfunctionality; transactions running in parallel on a multicore system execute actions chosenfrom a limited sub-set of predefined database operations. Therefore; we initially perform amemory characterization study of modern transaction processing systems using …,Proceedings of the VLDB Endowment,2014,7
How to stop under-utilization and love multicores,Anastasia Ailamaki; Erietta Liarou; Pınar Tözün; Danica Porobic; Iraklis Psaroudakis,Hardware trends oblige software to overcome three major challenges against systemsscalability:(1) taking advantage of the implicit/vertical parallelism within a core that isenabled through the aggressive micro-architectural features;(2) exploiting theexplicit/horizontal parallelism provided by multicores; and (3) achieving predictively efficientexecution despite the variability in communication latencies among cores on multisocketmulticores. In this three hour tutorial; we shed light on the above three challenges andsurvey recent proposals to alleviate them. The first part of the tutorial describes theinstruction-and data-level parallelism opportunities in a core coming from the hardware andsoftware side. In addition; it examines the sources of under-utilization in a modern processorand presents insights and hardware/software techniques to better exploit the micro …,Data Engineering (ICDE); 2015 IEEE 31st International Conference on,2015,6
Wildfire: Concurrent Blazing Data Ingest and Analytics,Ronald Barber; Matt Huras; Guy Lohman; C. Mohan; Rene Mueller; Fatma Ozcan; Hamid Pirahesh; Vijayshankar Raman; Richard Sidle; Oleg Sidorkin; Adam Storm; Yuanyuan Tian; Pinar Tozun,Abstract We demonstrate Hybrid Transactional and Analytics Processing (HTAP) on theSpark platform by the Wildfire prototype; which can ingest up to~ 6 million inserts per secondper node and simultaneously perform complex SQL analytics queries. Here; a simplifiedmobile application uses Wildfire to recommend advertising to mobile customers based upontheir distance from stores and their interest in products sold by these stores; whilecontinuously graphing analytics results as those customers move and respond to the adswith purchases.,SIGMOD,2016,4
Toward scalable transaction processing: evolution of shore-MT,Anastasia Ailamaki; Ryan Johnson; Ippokratis Pandis; Pínar Tözün,Abstract Designing scalable transaction processing systems on modern multicore hardwarehas been a challenge for almost a decade. The typical characteristics of transactionprocessing workloads lead to a high degree of unbounded communication on multicores forconventional system designs. In this tutorial; we initially present a systematic way ofeliminating scalability bottlenecks of a transaction processing system; which is based onminimizing the unbounded communication. Then; we show several techniques that applythe presented methodology to minimize logging; locking; latching etc. related bottlenecks oftransaction processing systems. In parallel; we demonstrate the internals of the Shore-MTstorage manager and how they have evolved over the years in terms of scalability onmulticore hardware through such techniques. We also teach how to use Shore-MT with …,Proceedings of the VLDB Endowment,2013,4
Reducing OLTP instruction misses with thread migration,Islam Atta; Pinar Tözün; Anastasia Ailamaki; Andreas Moshovos,Abstract During an instruction miss a processor is unable to fetch instructions. The morefrequent instruction misses are the less able a modern processor is to find useful work to doand thus performance suffers. Online transaction processing (OLTP) suffers from highinstruction miss rates since the instruction footprint of OLTP transactions does not fit intoday's L1-I caches. However; modern many-core chips have ample aggregate L1 cachecapacity across multiple cores. Looking at the code paths concurrently executingtransactions follow; we observe a high degree of repetition both within and acrosstransactions. This work presents TMi a technique that uses thread migration to reduceinstruction misses by spreading the footprint of a transaction over multiple L1 caches. TMi isa software-transparent; hardware technique; TMi requires no code instrumentation; and …,Proceedings of the Eighth International Workshop on Data Management on New Hardware,2012,4
Evolving Databases for New-Gen Big Data Applications,Ronald Barber; Christian Garcia-Arellano; Ronen Grosman; Rene Mueller; Vijayshankar Raman; Richard Sidle; Matt Spilchen; Adam Storm; Yuanyuan Tian; Pinar Tozun; Daniel Zilio; Matt Huras; Guy Lohman; C. Mohan; Fatma Ozcan; Pirahesh Hamid,ABSTRACT The rising popularity of large-scale real-time analytics applications (real-timeinventory/pricing; mobile apps that give you suggestions; fraud detection; risk analysis; etc.)emphasize the need for distributed data management systems that can handle fasttransactions and analytics concurrently. Efficient processing of transactional and analyticalrequests; however; require different optimizations and architectural decisions in a system.This paper presents the Wildfire system; which targets Hybrid Transactional and AnalyticalProcessing (HTAP). Wildfire leverages the Spark ecosystem to enable large-scale dataprocessing with different types of complex analytical requests; and columnar dataprocessing to enable fast transactions and analytics concurrently.,CIDR,2017,3
Characterization of the Impact of Hardware Islands on OLTP,Danica Porobic; Ippokratis Pandis; Miguel Branco; Pınar Tözün; Anastasia Ailamaki,Abstract Modern hardware is abundantly parallel and increasingly heterogeneous. Thenumerous processing cores have non-uniform access latencies to the main memory andprocessor caches; which causes variability in the communication costs. Unfortunately;database systems mostly assume that all processing cores are the same and thatmicroarchitecture differences are not significant enough to appear in critical databaseexecution paths. As we demonstrate in this paper; however; non-uniform core topology doesappear in the critical path and conventional database architectures achieve suboptimal andeven worse; unpredictable performance. We perform a detailed performance analysis ofOLTP deployments in servers with multiple cores per CPU (multicore) and multiple CPUsper server (multisocket). We compare different database deployment strategies where we …,The VLDB Journal,2016,2
Applying HTM to an OLTP system: No free lunch,David Cervini; Danica Porobic; Pınar Tözün; Anastasia Ailamaki,Abstract Transactional memory is a promising way for implementing efficient synchronizationmechanisms for multicore processors. Intel's introduction of hardware transactional memory(HTM) into their Haswell line of processors marks an important step toward mainstreamavailability of transactional memory. Transaction processing systems require execution ofdozens of critical sections to insure isolation among threads; which makes them one of thetarget applications for exploiting HTM. In this study; we quantify the opportunities andlimitations of directly applying HTM to an existing OLTP system that uses fine-grainedsynchronization. Our target is Shore-MT; a modern multithreaded transactional storagemanager that uses a variety of fine-grained synchronization mechanisms to providescalability on multicore processors. We find that HTM can improve performance of the …,Proceedings of the 11th International Workshop on Data Management on New Hardware,2015,2
Processing Java UDFs in a C++ environment,Viktor Rosenfeld; Rene Mueller; Pinar Tözün; Fatma Özcan,Abstract Many popular big data analytics systems today make liberal use of user-definedfunctions (UDFs) in their programming interface and are written in languages based on theJava Virtual Machine (JVM). This combination creates a barrier when we want to integrateprocessing engines written in a language that compiles down to machine code with a JVM-based big data analytics ecosystem. In this paper; we investigate efficient ways of executingUDFs written in Java inside a data processing engine written in C++. While it is possible tocall Java code from machine code via the Java Native Interface (JNI); a naiveimplementation that applies the UDF one row at a time incurs a significant overhead; up toan order of magnitude.,Proceedings of the 2017 Symposium on Cloud Computing,2017,1
Hybrid Transactional/Analytical Processing: A Survey,Fatma Özcan; Yuanyuan Tian; Pinar Tözün,Abstract The popularity of large-scale real-time analytics applications (real-timeinventory/pricing; recommendations from mobile apps; fraud detection; risk analysis; IoT;etc.) keeps rising. These applications require distributed data management systems that canhandle fast concurrent transactions (OLTP) and analytics on the recent data. Some of themeven need running analytical queries (OLAP) as part of transactions. Efficient processing ofindividual transactional and analytical requests; however; leads to different optimizationsand architectural decisions while building a data management system. For the kind of dataprocessing that requires both analytics and transactions; Gartner recently coined the termHybrid Transactional/Analytical Processing (HTAP). Many HTAP solutions are emergingboth from the industry as well as academia that target these new applications. While …,Proceedings of the 2017 ACM International Conference on Management of Data,2017,1
More than a network: distributed OLTP on clusters of hardware islands,Danica Porobic; Pınar Tözün; Raja Appuswamy; Anastasia Ailamaki,Abstract Multisocket multicores feature hardware islands-groups of cores that communicatefast among themselves and slower with other groups. With high speed networking becominga commodity; clusters of hardware islands with fast networks are becoming a preferredplatform for high end OLTP workloads. While behavior of OLTP on multisockets is wellunderstood; multi-machine OLTP deployments have been studied only in the geo-distributedcontext where network is much slower. In this paper; we analyze the behavior of differentOLTP designs when deployed on clusters of multisockets with fast networks. Wedemonstrate that choosing the optimal deployment configuration within a multisocket nodecan improve performance by 2 to 4 times. A slow network can decrease the throughput by40% when communication cannot be overlapped with other processing; while having …,Proceedings of the 12th International Workshop on Data Management on New Hardware,2016,1
Databases on Modern Hardware: How to Stop Underutilization and Love Multicores,Anastasia Ailamaki; Erietta Liarou; Pınar Tözün; Danica Porobic; Iraklis Psaroudakis,Abstract Data management systems enable various influential applications from high-performance online services (eg; social networks like Twitter and Facebook or financialmarkets) to big data analytics (eg; scientific exploration; sensor networks; businessintelligence). As a result; data management systems have been one of the main drivers forinnovations in the database and computer architecture communities for several decades.Recent hardware trends require software to take advantage of the abundant parallelismexisting in modern and future hardware. The traditional design of the data managementsystems; however; faces inherent scalability problems due to its tightly coupled components.In addition; it cannot exploit the full capability of the aggressive micro-architectural featuresof modern processors. As a result; today's most commonly used server types remain …,Synthesis Lectures on Data Management,2017,*
Transactions Chasing Scalability and Instruction Locality on Multicores,Pinar Tözün,Abstract For several decades; online transaction processing (OLTP) has been one of themain server applications that drives innovations in the data management ecosystem; and inturn the database and computer architecture communities. Recent hardware trends obligesoftware to overcome two major challenges against systems scalability on modern multicoreprocessors:(1) exploiting the abundant thread-level parallelism across cores and (2) takingadvantage of the implicit parallelism within a core. The traditional design of the OLTPsystems; however; faces inherent scalability problems due to its tightly coupled components.In addition; OLTP cannot exploit the full capability of the micro-architectural resources ofmodern processors because of the conventional scheduling decisions that ignore the cachelocality for transactions. As a result; today's commonly used server hardware remains …,*,2014,*
A Case for Thread Migration.,Pinar Tözün,Page 1. A Case for Thread Migration Pınar Tözün Data Intensive Applications and SystemsÉcole Polytechnique Fédérale de Lausanne Page 2. OLTP on a Intel Xeon5660 2Shore-MT Hyper-threading disabled IPC < 1 on a 4-issue machine 0 0.1 0.2 0.3 0.4 0.50.6 0.7 0.8 0.9 TPC-C TPC-E Instructions per Cycle 0% 10% 20% 30% 40% 50% 60%70% 80% 90% 100% TPC-C TPC-E Breakdown of Core Stalls Resource (includes data)Instructions better 70-80% of stalls are instruction stalls Page 3. Rethinking ThreadScheduling 3 0 1 2 3 T1 T2 T1 T3 T2 T1 T1 T3 T2 CORES 1 T3 0 1 2 3 T1 T1 T2 T1 T2T3 T1 T2 T3 CORES T3 Traditional SLICC L1I 3 6 9 10 1 2 3 4 4 T1 T2 T3 Threads timeTotal Misses Total Misses ~70% better performance with SLICC,CIDR,2013,*
Smart Thread Scheduling is the Key for OLTP,Pınar Tözün,Abstract Typical transactions of online transaction processing (OLTP) workloads have largeinstruction footprints; 128KB-1MB; that cannot fit in existing L1-I caches; 32KB [1]. Extensivecapacity misses due to instructions lead to severe under-utilization of modern hardware'smicro-architectural resources [3]. As opposed to the traditional way where a transactionstarts and completes its execution on a single core; some recent OLTP designs employmultiple cores to execute a single transaction [1; 2]; leading to performance improvementsup to 70%. The aggregate size of the caches of several cores creates ample L1-I capacity forthe instructions. In addition; the instructions are localized to caches to exploit instructioncommonality (∼ 90%) among different and within the same transactions. Spreadingtransactions to multiple cores; however; creates the need to share the data among …,*,2013,*
Metadata Front-end for Shore-MT Storage Manager,Bao Duy Tran,Abstract Shore-MT is a scalable storage manager offering high performance on multi-corearchitectures [1]. This report documents the design and implementation of Shore-MT front-end; a dynamic relational application layer for Shore-MT with metadata managementcapability. The work was conducted as an EPFL semester project.,*,2012,*
Conflict Avoidance in Software Transactional Memory,Pinar TOZUN,Abstract—Transactional Memory aims to become a superior alternative to lock-basedconcurrent programming. However; it is not widely deployed because it does not scale wellunder high contention scenarios. Aborts affect performance of a concurrent program thatuses Transactional Memory negatively when there is high contention. A high abort rate is ahuge burden for the performance of the program since aborts cause wasted work andexecution time. Therefore; the transactions should run in parallel in a way that the abort rateis as low as possible. Previous research shows that reducing abort rates can improveperformance significantly. This research proposal presents some previous work on avoidingconflicts in Software Transactional Memory and what can be done to further improve theexisting techniques.,*,*,*
