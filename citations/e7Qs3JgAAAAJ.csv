Towards time-aware link prediction in evolving social networks,Tomasz Tylenda; Ralitsa Angelova; Srikanta Bedathur,Abstract Prediction of links-both new as well as recurring-in a social network representinginteractions between individuals is an important problem. In the recent years; there issignificant interest in methods that use only the graph structure to make predictions.However; most of them consider a single snapshot of the network as the input; neglecting animportant aspect of these social networks viz.; their evolution over time. In this work; weinvestigate the value of incorporating the history information available on the interactions (orlinks) of the current social network state. Our results unequivocally show that time-stamps ofpast interactions significantly improve the prediction accuracy of new and recurrent linksover rather sophisticated methods proposed recently. Furthermore; we introduce a noveltesting method which reflects the application of link prediction better than previous …,Proceedings of the 3rd workshop on social network mining and analysis,2009,175
A language modeling approach for temporal information needs,Klaus Berberich; Srikanta Bedathur; Omar Alonso; Gerhard Weikum,Abstract This work addresses information needs that have a temporal dimension conveyedby a temporal expression in the user's query. Temporal expressions such as “in the 1990s”are frequent; easily extractable; but not leveraged by existing retrieval models. Onechallenge when dealing with them is their inherent uncertainty. It is often unclear whichexact time interval a temporal expression refers to. We integrate temporal expressions into alanguage modeling approach; thus making them first-class citizens of the retrieval modeland considering their inherent uncertainty. Experiments on the New York Times AnnotatedCorpus using Amazon Mechanical Turk to collect queries and obtain relevanceassessments demonstrate that our approach yields substantial improvements in retrievaleffectiveness.,European Conference on Information Retrieval,2010,165
Fast and accurate estimation of shortest paths in large graphs,Andrey Gubichev; Srikanta Bedathur; Stephan Seufert; Gerhard Weikum,Abstract Computing shortest paths between two given nodes is a fundamental operationover graphs; but known to be nontrivial over large disk-resident instances of graph data.While a number of techniques exist for answering reachability queries and approximatingnode distances efficiently; determining actual shortest paths (ie the sequence of nodesinvolved) is often neglected. However; in applications arising in massive online socialnetworks; biological networks; and knowledge graphs it is often essential to find out many; ifnot all; shortest paths between two given nodes. In this paper; we address this problem andpresent a scalable sketch-based index structure that not only supports estimation of nodedistances; but also computes corresponding shortest paths themselves. Generating theactual path information allows for further improvements to the estimation accuracy of …,Proceedings of the 19th ACM international conference on Information and knowledge management,2010,130
A time machine for text search,Klaus Berberich; Srikanta Bedathur; Thomas Neumann; Gerhard Weikum,Abstract Text search over temporally versioned document collections such as web archiveshas received little attention as a research problem. As a consequence; there is no scalableand principled solution to search such a collection as of a specified time. In this work; weaddress this shortcoming and propose an efficient solution for time-travel text search byextending the inverted file index to make it ready for temporal search. We introduceapproximate temporal coalescing as a tunable method to reduce the index size withoutsignificantly affecting the quality of results. In order to further improve the performance oftime-travel queries; we introduce two principled techniques to trade off index size for itsperformance. These techniques can be formulated as optimization problems that can besolved to near-optimality. Finally; our approach is evaluated in a comprehensive series of …,Proceedings of the 30th annual international ACM SIGIR conference on Research and development in information retrieval,2007,107
Engineering a fast online persistent suffix tree construction,Srikanta J Bedathur; Jayant R Haritsa,Online persistent suffix tree construction has been considered impractical due to itsexcessive I/O costs. However; these prior studies have not taken into account the effects ofthe buffer management policy and the internal node structure of the suffix tree on I/Obehavior of construction and subsequent retrievals over the tree. We study these two issuesin detail in the context of large genomic DNA and protein sequences. In particular; we makethe following contributions:(i) a novel; low-overhead buffering policy called TOP-Q whichimproves the on-disk behavior of suffix tree construction and subsequent retrievals; and (ii)empirical evidence that the space efficient linked-list representation of suffix tree nodesprovides significantly inferior performance when compared to the array representation.These results demonstrate that a careful choice of implementation strategies can make …,Data Engineering; 2004. Proceedings. 20th International Conference on,2004,68
High-Performance Reachability Query Processing under Index Size Restrictions,Stephan Seufert; Avishek Anand; Srikanta Bedathur; Gerhard Weikum,Abstract: In this paper; we propose a scalable and highly efficient index structure for thereachability problem over graphs. We build on the well-known node interval labelingscheme where the set of vertices reachable from a particular node is compactly encoded asa collection of node identifier ranges. We impose an explicit bound on the size of the indexand flexibly assign approximate reachability ranges to nodes of the graph such that thenumber of index probes to answer a query is minimized. The resulting tunable indexstructure generates a better range labeling if the space budget is increased; thus providing adirect control over the trade off between index size and the query processing performance.By using a fast recursive querying method in conjunction with our index structure; we showthat in practice; reachability queries can be answered in the order of microseconds on an …,arXiv preprint arXiv:1211.3375,2012,53
Bridging the Terminology Gap in Web Archive Search.,Klaus Berberich; Srikanta J Bedathur; Mauro Sozio; Gerhard Weikum,Page 1. Bridging the Terminology Gap in Web Archive Search Klaus Berberich; Srikanta Bedathur;Mauro Sozio; Gerhard Weikum Max-Planck Institute for Informatics; Saarbrücken; Germany Page2. Bridging the Terminology Gap in Web Archives (Klaus Berberich) ∎ http://www.liwa-project.eu ∎ European Union FP7 project that develops next generation web archiving technologiesPage 3. Bridging the Terminology Gap in Web Archives (Klaus Berberich) Web Archives ∎Archived contents increasingly made available on the Web – Web content increasingly archived ∎Web archives play an important role in providing access and preserving our cultural heritagehttp://archives.timesonline.co.uk Issues since 1785 digitized http://archive.org/web 150B webpages archived since 1996 Page 4. Bridging the Terminology Gap in Web Archives (KlausBerberich) What is the Terminology Gap? ∎ Terminology evolves constantly …,WebDB,2009,36
Time will tell: Leveraging temporal expressions in ir,Irem Arikan; Srikanta Bedathur; Klaus Berberich,Abstract Temporal expressions; such as between 1992 and 2000; are frequent across manykinds of documents. Text retrieval; though; treats them as common terms; thus ignoring theirinherent semantics. For queries with a strong temporal component; such as US president1997; this leads to a decrease in retrieval effectiveness; since relevant documents (eg; abiography of Bill Clinton containing the aforementioned temporal expression) can not bereliably matched to the query. We propose a novel approach; based on language models; tomake temporal expressions first-class citizens of the retrieval model. In addition; we presentexperiments that show actual improvements in retrieval effectiveness.,In WSDM,2009,32
Durable top-k search in document archives,Nikos Mamoulis; Klaus Berberich; Srikanta Bedathur,Abstract We propose and study a new ranking problem in versioned databases. Consider adatabase of versioned objects which have different valid instances along a history (eg;documents in a web archive). Durable top-k search finds the set of objects that areconsistently in the top-k results of a query (eg; a keyword query) throughout a given timeinterval (eg; from June 2008 to May 2009). Existing work on temporal top-k queries mainlyfocuses on finding the most representative top-k elements within a time interval. Suchmethods are not readily applicable to durable top-k queries. To address this need; wepropose two techniques that compute the durable top-k result. The first is adapted from theclassic top-k rank aggregation algorithm NRA. The second technique is based on a sharedexecution paradigm and is more efficient than the first approach. In addition; we propose …,Proceedings of the 2010 ACM SIGMOD International Conference on Management of data,2010,31
Index maintenance for time-travel text search,Avishek Anand; Srikanta Bedathur; Klaus Berberich; Ralf Schenkel,Abstract Time-travel text search enriches standard text search by temporal predicates; sothat users of web archives can easily retrieve document versions that are consideredrelevant to a given keyword query and existed during a given time interval. Different indexstructures have been proposed to efficiently support time-travel text search. None of them;however; can easily be updated as the Web evolves and new document versions are addedto the web archive. In this work; we describe a novel index structure that efficiently supportstime-travel text search and can be maintained incrementally as new document versions areadded to the web archive. Our solution uses a sharded index organization; bounds thenumber of spuriously read index entries per shard; and can be maintained using small in-memory buffers and append-only operations. We present experiments on two large-scale …,Proceedings of the 35th international ACM SIGIR conference on Research and development in information retrieval,2012,28
Sparqling kleene: fast property paths in RDF-3X,Andrey Gubichev; Srikanta J Bedathur; Stephan Seufert,Abstract As Semantic Web efforts continue to gather steam; the RDF engines are faced withgraphs with millions of nodes and billions of edges. While much recent work in addressingthe resulting scalability issues in processing queries over these datasets have mainlyconsidered SPARQL 1.0; the next-generation query language recommendations haveproposed the addition of regular expression restricted navigation queries into SPARQL. Weaddress the problem of supporting efficient processing of property paths into RDF-3X--a high-performance RDF engine. In this paper; we restrict our attention to a restricted definition ofproperty paths that is not only tractable but also most commonly used--instead ofenumerating all paths that satisfy the given query; we focus on regular expression basedreachability queries. Based on this; we make the following three major technical …,First International Workshop on Graph Data Management Experiences and Systems,2013,27
Temporal diversification of search results,Klaus Berberich; Srikanta Bedathur,ABSTRACT We investigate the notion of temporal diversity; bringing together two recentlyactive threads of research; namely temporal ranking and diversification of search results. Anovel method is developed to determine search results consisting of documents that arerelevant to the query and were published at diverse times of interest to the query.Preliminary experiments on twenty years' worth of newspaper articles from The New YorkTimes demonstrate characteristics of our method and compare it against two baselines.,Proceedings of the SIGIR 2013 workshop on time-aware information access,2013,24
Antourage: mining distance-constrained trips from flickr,Saral Jain; Stephan Seufert; Srikanta Bedathur,Abstract We study how to automatically extract tourist trips from large volumes of geo-taggedphotographs. Working with more than 8 million of these photographs that are publiclyavailable via photo-sharing communities such as Flickr and Panoramio; our goal is to satisfythe needs of a tourist who specifies a starting location (typically a hotel) together with abounded travel distance and demands a tour that visits the popular sites along the way. Oursystem; named ANTOURAGE; solves this intractable problem using a novel adaptation ofthe max-min ant system (MMAS) meta-heuristic. Experiments using GPS metadata crawledfrom Flickr show that ANTOURAGE can generate high-quality tours.,Proceedings of the 19th international conference on World wide web,2010,24
Temporal index sharding for space-time efficiency in archive search,Avishek Anand; Srikanta Bedathur; Klaus Berberich; Ralf Schenkel,Abstract Time-travel queries that couple temporal constraints with keyword queries areuseful in searching large-scale archives of time-evolving content such as the web archivesor wikis. Typical approaches for efficient evaluation of these queries involve slicing either theentire collection [20] or individual index lists [10] along the time-axis. Both these methods arenot satisfactory since they sacrifice compactness of index for processing efficiency makingthem either too big or; otherwise; too slow. We present a novel index organization schemethat shards each index list with almost zero increase in index size but still minimizes the costof reading index entries during query processing. Based on the optimal sharding thusbtained; we develop a practically efficient sharding that takes into account the different costsof random and sequential accesses. Our algorithm merges shards from the optimal …,Proceedings of the 34th international ACM SIGIR conference on Research and development in Information Retrieval,2011,23
Interesting-phrase mining for ad-hoc text analytics,Srikanta Bedathur; Klaus Berberich; Jens Dittrich; Nikos Mamoulis; Gerhard Weikum,Abstract Large text corpora with news; customer mail and reports; or Web 2.0 contributionsoffer a great potential for enhancing business-intelligence applications. We propose aframework for performing text analytics on such data in a versatile; efficient; and scalablemanner. While much of the prior literature has emphasized mining keywords or tags in blogsor social-tagging communities; we emphasize the analysis of interesting phrases. Theseinclude named entities; important quotations; market slogans; and other multi-word phrasesthat are prominent in a dynamically derived ad-hoc subset of the corpus; eg; being frequentin the subset but relatively infrequent in the overall corpus. We develop preprocessing andindexing methods for phrases; paired with new search techniques for the top-k mostinteresting phrases in ad-hoc subsets of the corpus. Our framework is evaluated using a …,Proceedings of the VLDB Endowment,2010,23
FluxCapacitor: efficient time-travel text search,Klaus Berberich; Srikanta Bedathur; Thomas Neumann; Gerhard Weikum,Abstract An increasing number of temporally versioned text collections is available todaywith Web archives being a prime example. Search on such collections; however; is often notsatisfactory and ignores their temporal dimension completely. Time-travel text search solvesthis problem by evaluating a keyword query on the state of the text collection as of a user-specified time point. This work demonstrates our approach to efficient time-travel text searchand its implementation in the FLUXCAPACITOR prototype.,Proceedings of the 33rd international conference on Very large data bases,2007,23
Computing n-gram statistics in MapReduce,Klaus Berberich; Srikanta Bedathur,Abstract Statistics about n-grams (ie; sequences of contiguous words or other tokens in textdocuments or other string data) are an important building block in information retrieval andnatural language processing. In this work; we study how n-gram statistics; optionallyrestricted by a maximum n-gram length and minimum collection frequency; can be computedefficiently harnessing MapReduce for distributed data processing. We describe differentalgorithms; ranging from an extension of word counting; via methods based on the Aprioriprinciple; to a novel method Suffix-σ that relies on sorting and aggregating suffixes. Weexamine possible extensions of our method to support the notions of maximality/closednessand to perform aggregations beyond occurrence counting. Assuming Hadoop as a concreteMap-Reduce implementation; we provide insights on an efficient implementation of the …,Proceedings of the 16th International Conference on Extending Database Technology,2013,22
Incorporating terminology evolution for query translation in text retrieval with association rules,Amal C Kaluarachchi; Aparna S Varde; Srikanta Bedathur; Gerhard Weikum; Jing Peng; Anna Feldman,Abstract Time-stamped documents such as newswire articles; blog posts and other web-pages are often archived online. When these archives cover long spans of time; theterminology within them could undergo significant changes. Hence; when users posequeries pertaining to historical information; over such documents; the queries need to betranslated; taking into account these temporal changes; to provide accurate responses tousers. For example; a query on Sri Lanka should automatically retrieve documents with itsformer name Ceylon. We call such concepts SITACs; ie; Semantically Identical TemporallyAltering Concepts. In order to discover SITACs; we propose an approach based on a novelframework constituting an integration of natural language processing; association rulemining; and contextual similarity as a learning technique. The proposed approach has …,Proceedings of the 19th ACM international conference on Information and knowledge management,2010,22
Efficient temporal keyword search over versioned text,Avishek Anand; Srikanta Bedathur; Klaus Berberich; Ralf Schenkel,Abstract Modern text analytics applications operate on large volumes of temporal text datasuch as Web archives; newspaper archives; blogs; wikis; and micro-blogs. In these settings;searching and mining needs to use constraints on the time dimension in addition to keywordconstraints. A natural approach to address such queries is using an inverted index whoseentries are enriched with valid-time intervals. It has been shown that these indexes have tobe partitioned along time in order to achieve efficiency. However; when the temporalpredicate corresponds to a long time range; requiring the processing of multiple partitions;naive query processing incurs high cost of reading of redundant entries across partitions.We present a framework for efficient approximate processing of keyword queries over atemporally partitioned inverted index which minimizes this overhead; thus speeding up …,Proceedings of the 19th ACM international conference on Information and knowledge management,2010,22
Efficient temporal keyword search over versioned text,Avishek Anand; Srikanta Bedathur; Klaus Berberich; Ralf Schenkel,Abstract Modern text analytics applications operate on large volumes of temporal text datasuch as Web archives; newspaper archives; blogs; wikis; and micro-blogs. In these settings;searching and mining needs to use constraints on the time dimension in addition to keywordconstraints. A natural approach to address such queries is using an inverted index whoseentries are enriched with valid-time intervals. It has been shown that these indexes have tobe partitioned along time in order to achieve efficiency. However; when the temporalpredicate corresponds to a long time range; requiring the processing of multiple partitions;naive query processing incurs high cost of reading of redundant entries across partitions.We present a framework for efficient approximate processing of keyword queries over atemporally partitioned inverted index which minimizes this overhead; thus speeding up …,Proceedings of the 19th ACM international conference on Information and knowledge management,2010,22
BuzzRank… and the trend is your friend,Klaus Berberich; Srikanta Bedathur; Michalis Vazirgiannis; Gerhard Weikum,Abstract Ranking methods like PageRank assess the importance of Web pages based onthe current state of the rapidly evolving Web graph. The dynamics of the resultingimportance scores; however; have not been considered yet; although they provide the key toan understanding of the Zeitgeist on the Web. This paper proposes the BuzzRank methodthat quantifies trends in time series of importance scores and is based on a relevant growthmodel of importance scores. We experimentally demonstrate the usefulness of BuzzRank ona bibliographic dataset.,Proceedings of the 15th international conference on World Wide Web,2006,22
EntityAuthority: Semantically Enriched Graph-Based Authority Propagation.,Julia Stoyanovich; Srikanta J Bedathur; Klaus Berberich; Gerhard Weikum,ABSTRACT This paper pursues the recently emerging paradigm of searching for entities thatare embedded in Web pages. We utilize informationextraction techniques to identify entitycandidates in documents; map them onto entries in a richly structured ontology; and derive ageneralized data graph that encompasses Web pages; entities; and ontological conceptsand relationships. We exploit this combination of pages and entities for a novel kind ofsearch-result ranking; coined EntityAuthority; in order to improve the quality of keywordqueries that return either pages or entities. To this end; we utilize the mutual reinforcementbetween authoritative pages and important entities. This resembles the HITS method forWeb-graph link analysis and recently proposed ObjectRank methods; but our approachoperates on a much richer; typed graph structure with different kinds of nodes and also …,WebDB,2007,20
Search-optimized suffix-tree storage for biological applications,Srikanta J Bedathur; Jayant R Haritsa,Abstract Suffix-trees are popular indexing structures for various sequence processingproblems in biological data management. We investigate here the possibility of enhancingthe search efficiency of disk-resident suffix-trees through customized layouts of tree-nodes todisk-pages. Specifically; we propose a new layout strategy; called Stellar; that providessignificantly improved search performance on a representative set of real genomicsequences. Further; Stellar supports both the standard root-to-leaf lookup queries as well assophisticated sequencesearch algorithms that exploit the suffix-links of suffix-trees. Ourresults are encouraging with regard to the ultimate objective of seamlessly integratingsequence processing in database engines.,International Conference on High-Performance Computing,2005,19
EverLast: a distributed architecture for preserving the web,Avishek Anand; Srikanta Bedathur; Klaus Berberich; Ralf Schenkel; Christos Tryfonopoulos,Abstract The World Wide Web has become a key source of knowledge pertaining to almostevery walk of life. Unfortunately; much of data on the Web is highly ephemeral in nature; withmore than 50-80% of content estimated to be changing within a short time. Continuing thepioneering efforts of many national (digital) libraries; organizations such as the InternationalInternet Preservation Consortium (IIPC); the Internet Archive (IA) and the European Archive(EA) have been tirelessly working towards preserving the ever changing Web. However;while these web archiving efforts have paid significant attention towards long termpreservation of Web data; they have paid little attention to developing an global-scaleinfrastructure for collecting; archiving; and performing historical analyzes on the collecteddata. Based on insights from our recent work on building text analytics for Web Archives …,Proceedings of the 9th ACM/IEEE-CS joint conference on Digital libraries,2009,17
Time-based exploration of news archives,Omar Alonso; Klaus Berberich; Srikanta Bedathur; Gerhard Weikum,ABSTRACT In this paper; we present NEAT; a prototype system that provides an explorationinterface to news archive search. Our prototype visualizes search results making use of twokinds of temporal information; namely; news articles' publication dates but also theircontained temporal expressions. The displayed timelines are annotated with major events;harvested using crowdsourcing; to make it easier for users to put the shown search resultsinto context. The prototype has been fully implemented and deployed on the New YorkTimes Annotated Corpus.,HCIR 2010,2010,15
Comparing apples and oranges: normalized pagerank for evolving graphs,Klaus Berberich; Srikanta Bedathur; Gerhard Weikum; Michalis Vazirgiannis,Abstract PageRank is the best known technique for link-based importance ranking. Thecomputed importance scores; however; are not directly comparable across differentsnapshots of an evolving graph. We present an efficiently computable normalization forPageRank scores that makes them comparable across graphs. Furthermore; we show thatthe normalized PageRank scores are robust to non-local changes in the graph; unlike thestandard PageRank measure.,Proceedings of the 16th international conference on World Wide Web,2007,12
InZeit: efficiently identifying insightful time points,Vinay Setty; Srikanta Bedathur; Klaus Berberich; Gerhard Weikum,Abstract Web archives are useful resources to find out about the temporal evolution ofpersons; organizations; products; or other topics. However; even when advanced text searchfunctionality is available; gaining insights into the temporal evolution of a topic can be atedious task and often requires sifting through many documents. The demonstrated systemnamed InZeit (pronounced" insight") assists users by determining insightful time points for agiven query. These are the time points at which the top-k time-travel query result changessubstantially and for which the user should therefore inspect query results. InZeit determinesthe m most insightful time points efficiently using an extended segment tree for in-memorybookkeeping.,Proceedings of the VLDB Endowment,2010,11
NEAT: news exploration along time,Omar Alonso; Klaus Berberich; Srikanta Bedathur; Gerhard Weikum,Abstract There are a number of efforts towards building applications that leverage temporalinformation in documents. The demonstration of our NEAT (News Exploration Along Time)prototype system that we propose here; is an attempt towards building an intuitive andexploratory interface for search results over large news archives using timelines. Thedemonstration uses the New York Times Annotated Corpus as an illustrative example ofsuch a news archive. The NEAT system consists of two parts: the back-end server extractsand stores in an index all the temporal information from documents; and performs importantphrase discovery from sentences that have time-sensitive information. The front-end userinterface; anchors the results of a keyword search along the timeline where the user canexplore and browse results at different points in time. To aid in this exploration; the …,Proceedings of the 32nd European conference on Advances in Information Retrieval,2010,11
Temporal knowledge for timely intelligence,Gerhard Weikum; Srikanta Bedathur; Ralf Schenkel,Abstract Knowledge bases about entities and their relationships are a great asset forbusiness intelligence. Major advances in information extraction and the proliferation ofknowledge-sharing communities like Wikipedia have enabled ways for the largelyautomated construction of rich knowledge bases. Such knowledge about entity-orientedfacts can greatly improve the output quality and possibly also efficiency of processingbusiness-relevant documents and event logs. This holds for information within the enterpriseas well as in Web communities such as blogs. However; no knowledge base will ever befully complete and real-world knowledge is continuously changing: new facts supersede oldfacts; knowledge grows in various dimensions; and completely new classes; relation types;or knowledge structures will arise. This leads to a number of difficult research questions …,International Workshop on Business Intelligence for the Real-Time Enterprise,2010,9
Efficient Time-Travel on Versioned Text Collections.,Klaus Berberich; Srikanta J Bedathur; Gerhard Weikum,Abstract: The availability of versioned text collections such as the Internet Archive opens upopportunities for time-aware exploration of their contents. In this paper; we propose time-travel retrieval and ranking that extends traditional keyword queries with a temporal contextin which the query should be evaluated. More precisely; the query is evaluated over allstates of the collection that existed during the temporal context. In order to support thesequeries; we make key contributions in (i) defining extensions to well-known relevancemodels that take into account the temporal context of the query and the version history ofdocuments;(ii) designing an immortal index over the full versioned text collection that avoidsa blowup in index size; and (iii) making the popular NRA algorithm for top-k queryprocessing aware of the temporal context. We present preliminary experimental analysis …,BTW,2007,9
The building of BODHI; a bio-diversity database system,Srikanta J Bedathur; Jayant R Haritsa; Uday S Sen,Abstract We have built a database system called BODHI; intended to store plant bio-diversityinformation. It is based on an object-oriented modeling approach and is developedcompletely around public-domain software. The unique feature of BODHI is that itseamlessly integrates diverse types of data; including taxonomic characteristics; spatialdistributions; and genetic sequences; thereby spanning the entire range from molecular toorganism-level information. A variety of sophisticated indexing strategies are incorporated toefficiently access the various types of data; and a rule-based query processor is employedfor optimizing query execution. In this paper; we report on our experiences in buildingBODHI and on its performance characteristics for a representative set of queries.,Information Systems,2003,7
RQ-RDF-3X: going beyond triplestores,Jyoti Leeka; Srikanta Bedathur,Efficient storage and querying of large repositories of RDF content is important due to thewidespread growth of Semantic Web and Linked Open Data initiatives. Many noveldatabase systems that store RDF in its native form or within traditional relational storagehave demonstrated their ability to scale to large volumes of RDF content. However; it isincreasingly becoming obvious that the simple dyadic relationship captured throughtraditional triples alone is not sufficient for modelling multi-entity relationships; provenance offacts; etc. Such richer models are supported in RDF through two techniques-first; calledreification which retains the triple nature of RDF and the second; a non-standard extensioncalled N-Quads. In this paper; we explore the challenges of supporting such richer semanticdata by extending the state-of-the-art RDF-3X system. We describe our implementation of …,Data Engineering Workshops (ICDEW); 2014 IEEE 30th International Conference on,2014,6
Flood little; cache more: effective result-reuse in P2P IR systems,Christian Zimmer; Srikanta Bedathur; Gerhard Weikum,Abstract State-of-the-art Peer-to-Peer Information Retrieval (P2P IR) systems suffer from theirlack of response time guarantee especially with scale. To address this issue; a number oftechniques for caching of multi-term inverted list intersections and query results have beenproposed recently. Although these enable speedy query evaluations with low networkoverheads; they fail to consider the potential impact of caching on result qualityimprovements. In this paper; we propose the use of a cache-aware query routing scheme;that not only reduces the response delays for a query; but also presents an opportunity toimprove the result quality while keeping the network usage low. In this regard; we makethree-fold contributions in this paper. First of all; we develop a cache-aware; multi-roundquery routing strategy that balances between query efficiency and result-quality. Next; we …,International Conference on Database Systems for Advanced Applications,2008,6
Tunable Word-Level Index Compression for Versioned Corpora,Klaus Berberich; Srikanta Bedathur; Gerhard Weikum,Abstract. This paper presents a tunable index compression scheme for supporting time-travel phrase queries over large versioned corpora such as web archives. Support forphrase queries makes maintenance of word positions necessary; thus increasing the indexsize significantly. We propose to fuse the word positions in many neighboring versions of adocument; and thus exploit the typically high level of redundancy and compressibility toshrink the index size. The resulting compression scheme called FUSION; can be tuned totrade off compression for query-processing overheads. Our experiments on the revisionhistory of Wikipedia demonstrate the effectiveness of our method.,Proc. of Workshop EIIR,2008,6
SIGIR 2007: Proceedings of the 30th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval; Amsterdam; The Netherla...,W Kraaij; AP de Vries; CLA Clarke; N Fuhr; N Kando,*,Proceedings of the 6th annual international ACM SIGIR conference on Research and development in information retrieval; SIGIR,2007,6
Inferring and exploiting categories for next location prediction,Ankita Likhyani; Deepak Padmanabhan; Srikanta Bedathur; Sameep Mehta,Abstract Predicting the next location of a user based on their previous visiting pattern is oneof the primary tasks over data from location based social networks (LBSNs) such asFoursquare. Many different aspects of these so-called" check-in" profiles of a user havebeen made use of in this task; including spatial and temporal information of check-ins aswell as the social network information of the user. Building more sophisticated predictionmodels by enriching these check-in data by combining them with information from othersources is challenging due to the limited data that these LBSNs expose due to privacyconcerns. In this paper; we propose a framework to use the location data from LBSNs;combine it with the data from maps for associating a set of venue categories with theselocations. For example; if the user is found to be checking in at a mall that has cafes …,Proceedings of the 24th International Conference on World Wide Web,2015,5
Rank synopses for efficient time travel on the web graph,Klaus Berberich; Srikanta Bedathur; Gerhard Weikum,The World Wide Web is increasingly becoming the key source of information pertaining notonly to business and entertainment but also to a spectrum of sciences; culture; and politics.However; the Web has an even greater source of information within it–evolutionary history ofits structure and content. It not only captures the evolution of digital content but embodies thenear-term history of our society; economy; and science. Although efforts such as the InternetArchive [1] are archiving a large fraction of the Web; there is a serious lack of tools that aredesigned for the effective search over these Web archives. Time travel queries are aimed atsupporting the evolutionary (temporal) analysis over Web archives extending the power ofWeb search-engines. Specifically; a time travel query Q is defined as a pair〈 Qir; Qtc〉;where Qir is the IR-style keyword query and Qtc is the target temporal context. For …,Proceedings of the 15th ACM international conference on Information and knowledge management,2006,5
Towards generating text summaries for entity chains,Shruti Chhabra; Srikanta Bedathur,Abstract Given a large knowledge graph; discovering meaningful relationships between agiven pair of entities has gained a lot of attention in the recent times. Most existingalgorithms focus their attention on identifying one or more structures–such as relationshipchains or subgraphs–between the entities. The burden of interpreting these results; aftercombining with contextual information and description of relationships; lies with the user. Inthis paper; we present a framework that eases this burden by generating a textual summarywhich incorporates the context and description of individual (dyadic) relationships; andcombines them to generate a ranked list of summaries. We develop a model that captureskey properties of a well-written text; such as coherence and information content. We focusour attention on a special class of relationship structures; two-length entity chains; and …,European Conference on Information Retrieval,2014,4
Label constrained shortest path estimation,Ankita Likhyani; Srikanta Bedathur,Abstract Shortest path querying is a fundamental graph problem which is computationallyquite challenging when operating over massive scale graphs. Recent results haveaddressed the problem of computing either exact or good approximate shortest pathdistances efficiently. Some of these techniques also return the path corresponding to theestimated shortest path distance fast. However; none of these techniques work very wellwhen we have additional constraints on the labels associated with edges that constitute thepath. In this paper; we develop SkIt index structure; which supports a wide range of labelconstraints on paths; and returns an accurate estimation of the shortest path that satisfies theconstraints. We conduct experiments over graphs such as social networks; and knowledgegraphs that contain millions of nodes/edges; and show that SkIt index is fast; accurate in …,Proceedings of the 22nd ACM international conference on Information & Knowledge Management,2013,4
Indexing strategies for constrained shortest paths over large social networks,Philipp Klodt; Gerhard Weikum; Srikanta Bedathur; Stephan Seufert,Abstract In this work we introduced the label-constrained shortest path problem as anextension to the shortest path problem that allows a shortest path query to specify whichedge labels are allowed on shortest paths. Furthermore we analyse its theoretical difficultyfor exact indexing strategies and come to the conclusion that exact indexing is hard forgraphs with not trivially small label sets. We then give simple and efficient extensions of theSketch algorithms from [1] to support these queries and analyse the performance of ouralgorithms on different constraint sizes. We come to the conclusion that the recall especiallyfor small constraint sizes needs to be improved and provide a simple but powerful extensionof the indexing step that increases recall significantly.,Universitat des Saarlandes,2011,4
Bonsai: Growing interesting small trees,Stephan Seufert; Srikanta Bedathur; Julián Mestre; Gerhard Weikum,Graphs are increasingly used to model a variety of loosely structured data such as biologicalor social networks and entity-relationships. Given this profusion of large-scale graph data;efficiently discovering interesting substructures buried within is essential. Thesesubstructures are typically used in determining subsequent actions; such as conductingvisual analytics by humans or designing expensive biomedical experiments. In suchsettings; it is often desirable to constrain the size of the discovered results in order to directlycontrol the associated costs. In this paper; we address the problem of finding cardinality-constrained connected sub trees in large node-weighted graphs that maximize the sum ofweights of selected nodes. We provide an efficient constant-factor approximation algorithmfor this strongly NP-hard problem. Our techniques can be applied in a wide variety of …,Data Mining (ICDM); 2010 IEEE 10th International Conference on,2010,4
Search-optimized persistent suffix tree storage for biological applications,Srikanta J Bedathur; Jayant R Haritsa,Abstract The suffix tree is a well known and popular indexing structure for various sequenceprocessing problems arising in biological data management. However; unlike traditionalindexing structures; suffix trees are orders of magnitude larger than the underlying data.Moreover; their construction and search algorithms are extremely inefficient whenimplemented directly on disk. Recently; we have shown that it is possible to significantlyspeedup the on-disk construction of suffix trees through a careful choice of buffering policyand physical representation of suffix tree nodes. In this paper; we explore the problem ofperforming efficient searches on disk-resident suffix trees. Specifically; we investigate thegains that can be achieved through customized node-to-page layout strategies. Throughdetailed experimentation on real-life genomic sequences; we demonstrate that a new …,*,2004,4
A pocket guide to web history,Klaus Berberich; Srikanta Bedathur; Gerhard Weikum,Abstract Web archives like the Internet Archive preserve the evolutionary history of largeportions of the Web. Access to them; however; is still via rather limited interfaces–a searchfunctionality is often missing or ignores the time axis. Time-travel search alleviates thisshortcoming by enriching keyword queries with a time-context of interest. In order to beeffective; time-travel queries require historical PageRank scores. In this paper; we addressthis requirement and propose rank synopses as a novel structure to compactly representand reconstruct historical PageRank scores. Rank synopses can reconstruct the PageRankscore of a web page as of any point during its lifetime; even in the absence of a snapshot ofthe Web as of that time. We further devise a normalization scheme for PageRank scores tomake them comparable across different graphs. Through a comprehensive evaluation …,International Symposium on String Processing and Information Retrieval,2007,3
Quark-X: An efficient top-k processing framework for RDF quad stores,Jyoti Leeka; Srikanta Bedathur; Debajyoti Bera; Medha Atre,Abstract There is a growing trend towards enriching the RDF content from its classicalSubject-Predicate-Object triple form to an annotated representation which can model richerrelationships such as including fact provenance; fact confidence; higher-order relationshipsand so on. One of the recommended ways to achieve this is to use reification and representit as N-Quads" or simply quads" where an additional identifier is associated with the entireRDF statement which can then be used to add further annotations. A typical use of suchannotations is to have quantifiable confidence values to be attached to facts. In suchsettings; it is important to support efficient top-k queries; typically over user-defined rankingfunctions containing sentence level confidence values in addition to other quantifiablevalues in the database. In this paper; we present Quark-X; an RDF-store and SPARQL …,Proceedings of the 25th ACM International on Conference on Information and Knowledge Management,2016,2
Instant Espresso: Interactive Analysis of Relationships in Knowledge Graphs,Stephan Seufert; Patrick Ernst; Srikanta J Bedathur; Sarath Kumar Kondreddi; Klaus Berberich; Gerhard Weikum,Abstract We demonstrate InstantEspresso; a system to explain the relationship between twosets of entities in knowledge graphs. Instant-Espresso answers questions of the form. WhichEuropean politicians are related to politicians in the United States; and how? or How canone summarize the relationship between China and countries from the Middle East? Eachquestion is specified by two sets of query entities. These sets (eg European politicians orUnited States politicians) can be determined by an initial graph query over a knowledgegraph capturing relationships between real-world entities. Instant-Espresso analyzes the(indirect) relationships that connect entities from both sets and provides a user-friendlyexplanation of the answer in the form of concise subgraphs. These so-called relatednesscores correspond to important event complexes involving entities from the two sets. Our …,Proceedings of the 25th International Conference Companion on World Wide Web,2016,2
Phrase query optimization on inverted indexes,Avishek Anand; Ida Mele; Srikanta Bedathur; Klaus Berberich,Abstract Phrase queries are a key functionality of modern search engines. Beyond that; theyincreasingly serve as an important building block for applications such as entity-orientedsearch; text analytics; and plagiarism detection. Processing phrase queries is costly; though;since positional information has to be kept in the index and all words; including stopwords;need to be considered. We consider an augmented inverted index that indexes selectedvariable-length multi-word sequences in addition to single words. We study how arbitraryphrase queries can be processed efficiently on such an augmented inverted index. We showthat the underlying optimization problem is NP-hard in the general case and describe anexact exponential algorithm and an approximation algorithm to its solution. Experiments onClueWeb09 and The New York Times with different real-world query workloads examine …,Proceedings of the 23rd ACM International Conference on Conference on Information and Knowledge Management,2014,2
Generating text summaries of graph snippets,Shruti Chhabra; Srikanta Bedathur,Abstract With the availability of large entity-relationship graphs; finding the best relationshipbetween entities is a problem that has attracted a lot of attention. Given two or more entities;the goal of most algorithms is to produce a graph structure of varying complexity (ie; a simplepath; a minimal weighted tree; or a dense subgraph etc.) as a way of characterizing therelationship between given entities. However; no attention is paid to the interpretability ofthese results--ie; the ability of humans to read these and comprehend the context in whichthese relationships exist. A key obstacle in this direction is the lack of necessary linguisticcontext and natural textual result formulations. We pursue the idea of using entity-centricsummarization as a way of closing this gap. We aim to turn the resulting graph structures intoone or more coherent textual snippets (or summaries) that can be easily read and …,Proceedings of the 19th International Conference on Management of Data,2013,2
BODHI: a database habitat for bio-diversity information,Srikanta J Bedathur; Abhijit Kadlag; Jayant R Haritsa,1. INTRODUCTION Modern biodiversity research involves systematic and simultane- ous studyof macro- and micro-level relationships between various biological entities. Multi-domain queriesof the following kind are increasingly common among the researchers in this field: Retrieve thenames of all plant species that have com- mon infloresence characteristics; share a part of theirhabitats; and have a high chromosomal DNA sequence similarity with Michelia-champa1 . Answeringthis query requires the ability to process data across: (a) taxonomy hierarchies (commoninfloresence); (b) recorded spa- tial distribution of species (common habitat); and (c) genomicse- quences (chromosomal DNA sequence similarity). Unfortunately; due to the lack of holisticdatabase systems; biologists are often forced to split the query into component queries; eachof which can be processed separately over specialized independent tools and ser- vices …,Proceedings of the 2004 ACM SIGMOD international conference on Management of data,2004,2
ESPRESSO: Explaining Relationships between Entity Sets,Stephan Seufert; Klaus Berberich; Srikanta J Bedathur; Sarath Kumar Kondreddi; Patrick Ernst; Gerhard Weikum,Abstract Analyzing and explaining relationships between entities in a knowledge graph is afundamental problem with many applications. Prior work has been limited to extracting themost informative subgraph connecting two entities of interest. This paper extends andgeneralizes the state of the art by considering the relationships between two sets of entitiesgiven at query time. Our method; coined ESPRESSO; explains the connection betweenthese sets in terms of a small number of relatedness cores: dense sub-graphs that havestrong relations with both query sets. The intuition for this model is that the cores correspondto key events in which entities from both sets play a major role. For example; to explain therelationships between US politicians and European politicians; our method identifies eventslike the PRISM scandal and the Syrian Civil War as relatedness cores. Computing cores …,Proceedings of the 25th ACM International on Conference on Information and Knowledge Management,2016,1
Mind your language: Effects of spoken query formulation on retrieval effectiveness,Apoorv Narang; Srikanta Bedathur,Abstract: Voice search is becoming a popular mode for interacting with search engines. As aresult; research has gone into building better voice transcription engines; interfaces; andsearch engines that better handle inherent verbosity of queries. However; when oneconsiders its use by non-native speakers of English; another aspect that becomes importantis the formulation of the query by users. In this paper; we present the results of a preliminarystudy that we conducted with non-native English speakers who formulate queries for givenretrieval tasks. Our results show that the current search engines are sensitive in theirrankings to the query formulation; and thus highlights the need for developing more robustranking methods. Subjects: Information Retrieval (cs. IR) Cite as: arXiv: 1312.4036 [cs. IR](orarXiv: 1312.4036 v1 [cs. IR] for this version) Submission history From: Apoorv Narang …,arXiv preprint arXiv:1312.4036,2013,1
Efficient Computation of Relationship-Centrality in Large Entity-Relationship Graphs.,Stephan Seufert; Srikanta J Bedathur; Johannes Hoffart; Andrey Gubichev; Klaus Berberich,Abstract. Given two sets of entities–potentially the results of two queries on a knowledge-graph like YAGO or DBpedia–characterizing the relationship between these sets in the formof important people; events and organizations is an analytics task useful in many domains.In this paper; we present an intuitive and efficiently computable vertex centrality measurethat captures the importance of a node with respect to the explanation of the relationshipbetween the pair of query sets. Using a weighted link graph of entities contained in theEnglish Wikipedia; we demonstrate the usefulness of the proposed measure.,International Semantic Web Conference (Posters & Demos),2013,1
D-Hive: Data Bees Pollinating RDF; Text; and Time,Srikanta Bedathur; Klaus Berberich; Ioannis Patlakas; Peter Triantafillou; Gerhard Weikum,ABSTRACT Although the problem of integrating IR and DB solutions is considered “old”; theincreasing importance of big data analytics and its formidable demands for both enrichedfunctionality and scalable performance creates the need to revisit the problem itself and tosee possible solutions from a new perspective. Our goal is to develop a system that willmake large corpora aware of entities and relationships (ER); addressing the challenges insearching and analyzing ER patterns in web data and social media. We put forward D-Hive;a system facilitating analytics over RDF-style (SPO) triples augmented with text and(validity/transaction) time capable of addressing the functionality and scalabilityrequirements which current solutions cannot meet. We consider various alternatives for thedata modeling; storage; indexing; and query processing engines of D-Hive paying …,Sixth Biennial Conference on Innovative Data Systems Research,2013,1
Efficiently identifying interesting time points in text archives,Vinay Setty; Gerhard Weikum; Srikanta Bedathur; Klaus Berberich,Abstract Large scale text archives are increasingly becoming available on the Web.Exploring their evolving contents along both text and temporal dimensions enables us torealize their full potential. Standard keyword queries facilitate exploration along the textdimension only. Recently proposed time-travel keyword queries enable query processingalong both dimensions; but require the user to be aware of the exact time point of interest.This may be impractical if the user does not know the history of the query within thecollection or is not familiar with the topic. In this work; our aim is to efficiently identifyinteresting time points in Web archives with an assumption that we receive a result list for agiven query in standard relevance-order from an existing retrieval system. We consider twoforms of Web archives:(i) one where documents have a publication time-stamp and never …,Master's thesis; Universität des Saarlandes; FR Informatik,2010,1
Index partitioning strategies for peer-to-peer web archival,Avishek Anand; Gerhard Weikum; Srikanta Bedathur; Christos Tryfonopoulos,Abstract The World Wide Web has become a key source of knowledge pertaining to almostevery walk of life. The goal is to build a scalable peer-to-peer framework for web archivaland to further support time-travel search over it. We provide an initial design with crawling;persistent storage and indexing and also analyze the partitioning strategies for historicalanalysis of data. Peer-to-peer (p2p) systems are a nice fit here but they suffer from churn andcommunication overhead and hence require controlled replication for availability and loadbalancing. The core of the contribution is of index organization by temporally partitioning thetime-travel index lists for supporting efficient time-travel search. We also analyze thepartitioning strategies in terms of improving replication to improve availability while stillkeeping the overall blowup if the index in check. We present various heuristic approaches …,*,2009,1
Exploiting Temporal References in Text Retrieval,Emine Irem Arıkan; Gerhard Weikum; Srikanta Bedathur; Klaus Berberich,Abstract Temporal expressions; such as between 1994 and 2000; are frequent across manykinds of documents. In state-of-art search engines the documents are retrieved based ontheir text relevancy to the given query. Text retrieval; though; treats temporal expressions ascommon terms; thus ignoring their inherent semantics. For queries with a strong temporalcomponent; such as US president 1999; this is problematic; since documents can not bereliably matched to the query. This work introduces a new aspect to the document retrievaland introduces temporal relevancy. The query will be processed not only taking intoconsideration the similarity between the query text and the textual content of the documentbut also the similarity between the temporal content of the document and temporal part of thequery if given. The introduction of the temporal aspect brings up some new problems to …,*,2009,1
A Machine Learning Approach to Quantitative Prosopography,Aayushee Gupta; Haimonti Dutta; Srikanta Bedathur; Lipika Dey,Abstract: Prosopography is an investigation of the common characteristics of a group ofpeople in history; by a collective study of their lives. It involves a study of biographies tosolve historical problems. If such biographies are unavailable; surviving documents andsecondary biographical data are used. Quantitative prosopography involves analysis ofinformation from a wide variety of sources about" ordinary people". In this paper; we presenta machine learning framework for automatically designing a people gazetteer which formsthe basis of quantitative prosopographical research. The gazetteer is learnt from the noisytext of newspapers using a Named Entity Recognizer (NER). It is capable of identifyinginfluential people from it by making use of a custom designed Influential Person Index (IPI).Our corpus comprises of 14020 articles from a local newspaper;" The Sun"; published …,arXiv preprint arXiv:1801.10080,2018,*
Sampling and reconstruction using Bloom filters,Neha Sengupta; Amitabha Bagchi; Srikanta Bedathur; Maya Ramanath,In this paper; we address the problem of sampling from a set and reconstructing a set storedas a Bloom filter. To the best of our knowledge our work is the first to address this question.We introduce a novel hierarchical data structure called BloomSampleTree that helps usdesign efficient algorithms to extract an almost uniform sample from the set stored in aBloom filter and also allows us to reconstruct the set efficiently. In the case where the hashfunctions used in the Bloom filter implementation are partially invertible; in the sense that it iseasy to calculate the set of elements that map to a particular hash value; we propose asecond; more space-efficient method called HashInvert for the reconstruction. We study theproperties of these two methods both analytically as well as experimentally. We providebounds on run times for both methods and sample quality for the BloomSampleTree …,IEEE Transactions on Knowledge and Data Engineering,2017,*
Tracking the Impact of Fact Deletions on Knowledge Graph Queries using Provenance Polynomials,Garima Gaur; Srikanta J Bedathur; Arnab Bhattacharya,Abstract Critical business applications in domains ranging from technical support tohealthcare increasingly rely on large-scale; automatically constructed knowledge graphs.These applications use the results of complex queries over knowledge graphs in order tohelp users in taking crucial decisions such as which drug to administer; or whether certainactions are compliant with all the regulatory requirements and so on. However; theseknowledge graphs constantly evolve; and the newer versions may adversely impact theresults of queries that the previously taken business decisions were based on. We proposea framework based on provenance polynomials to track the impact of knowledge graphchanges on arbitrary SPARQL query results. Focusing on the deletion of facts; we show howto efficiently determine the queries impacted by the change; develop ways to …,Proceedings of the 2017 ACM on Conference on Information and Knowledge Management,2017,*
STREAK: An Efficient Engine for Processing Top-k SPARQL Queries with Spatial Filters,Jyoti Leeka; Srikanta Bedathur; Debajyoti Bera; Sriram Lakshminarasimhan,Abstract: The importance of geo-spatial data in critical applications such as emergencyresponse; transportation; agriculture etc.; has prompted the adoption of recent GeoSPARQLstandard in many RDF processing engines. In addition to large repositories of geo-spatialdata--eg; LinkedGeoData; OpenStreetMap; etc.--spatial data is also routinely found inautomatically constructed knowledgebases such as Yago and WikiData. While there havebeen research efforts for efficient processing of spatial data in RDF/SPARQL; very little efforthas gone into building end-to-end systems that can holistically handle complex SPARQLqueries along with spatial filters. In this paper; we present Streak; a RDF data managementsystem that is designed to support a wide-range of queries with spatial filters includingcomplex joins; top-k; higher-order relationships over spatially enriched databases. Streak …,arXiv preprint arXiv:1710.07411,2017,*
LoCaTe: influence quantification for location promotion in location-based social networks,Ankita Likhyani; Srikanta Bedathur; P Deepak,Abstract Location-based social networks (LBSNs) such as Foursquare offer a platform forusers to share and be aware of each other's physical movements. As a result of such asharing of check-in information with each other; users can be influenced to visit at thelocations visited by their friends. Quantifying such influences in these LBSNs is useful invarious settings such as location promotion; personalized recommendations; mobilitypattern prediction etc. In this paper; we focus on the problem of location promotion anddevelop a model to quantify the influence specific to a location between a pair of users.Specifically; we develop a joint model called LoCaTe; consisting of (i) user mobility modelestimated using kernel density estimates;(ii) a model of the semantics of the location usingtopic models; and (iii) a model of time-gap between checkins using exponential …,Proceedings of the 26th International Joint Conference on Artificial Intelligence,2017,*
Tracking the conductance of rapidly evolving topic-subgraphs,Sainyam Galhotra; Amitabha Bagchi; Srikanta Bedathur; Maya Ramanath; Vidit Jain,Abstract Monitoring the formation and evolution of communities in large online socialnetworks such as Twitter is an important problem that has generated considerable interest inboth industry and academia. Fundamentally; the problem can be cast as studying evolvingsugraphs (each subgraph corresponding to a topical community) on an underlying socialgraph-with users as nodes and the connection between them as edges. A key metric ofinterest in this setting is tracking the changes to the conductance of subgraphs induced byedge activations. This metric quantifies how well or poorly connected a subgraph is to therest of the graph relative to its internal connections. Conductance has been demonstrated tobe of great use in many applications; such as identifying bursty topics; tracking the spread ofrumors; and so on. However; tracking this simple metric presents a considerable …,Proceedings of the VLDB Endowment,2015,*
Label constrained shortest path estimation on large graphs,Ankita Likhyani; Srikanta Bedathur,In applications arising in massive on-line social networks; biological networks; andknowledge graphs it is often required to ﬁnd shortest length path between two given nodes.Recent results have addressed the problem of computing either exact or good approximateshortest path dis-tances eﬃciently. Some of these techniques also return the pathcorresponding to the estimated shortest path distance fast. Many of the real-world graphsare edge-labeled graphs; ie; each edge has a label that denotes the relationship betweenthe two vertices connected by the edge. However; none of the techniques for estimatingshortest paths work very well when we have additional constraints on the labels associatedwith edges that constitute the path. In this work; we deﬁne the problem of retrieving shortestlength path between two given nodes which also satisﬁes user-provided constraints on …,*,2015,*
Semantic similarity through hierarchical abstraction of knowledge,Kanchan Arora; Srikanta Bedathur,Identifying semantic similarity between two texts has many applications in NLP includinginformation extraction and retrieval; word sense disambigua-tion; text summarization andtype classi cation. Similarity between texts is commonly determined using a taxonomy basedapproach; but the limited scalability of existing taxonomies has led recent research to useWikipedia's encyclopaedic knowledge base to nd similarity or relatedness. In this the-sis; wepropose Hierarchical Semantic Analysis; a method which represents semantics of a text inhigh dimensional space of Wikipedia concepts and category hierarchies. We represent themeaning of any text excerpt as a weighed vector of Wikipedia-based resources. To evaluatethe similarity of texts in this space; we compare the corresponding vectors usingconventional metrics (eg cosine). Compared with the previous state of the art; use of …,*,2014,*
TeKnowBase: a tool for enrichment of textbooks using discussion forums,Amani Kongara; Srikanta Bedathur,Several knowledge resources are available both online and o line in learning technicaltopics. Textbooks act as a basic reference with their general organization into sectionswhere each section is dedicated in explaining a single topic. Other online resources likeWikipedia articles and its topic hierarchy help the users in structured learning of a speci ctechnical topic by providing them with the details on advanced applications. Variousdiscussion forums aid the users in clarifying the doubts on real world implementation detailsof the technical topics. For an e ective learning of technical topics; all these features are tobe curated. By making use of online knowledge resources; through TeKnowBase; wepresent our early explorations in trying to bridge the gaps in textbooks by providing moredetails on the technical topic to be learnt. To extract the discussions on the details of real …,*,2014,*
The 3 rd Temporal Web Analytics Workshop (TempWeb),Ricardo Baeza-Yates; Julien Masanès; Marc Spaniol; Omar Alonso; Ralitsa Angelova; Srikanta Bedathur; Andras A Benczur; Klaus Berberich; Roi Blanco; Philipp Cimiano; Renata Galante; Adam Jatowt; Scott Kirkpatrick; Frank McCown; Michael Nelson; Kjetil Nørvåg; Nikos Ntarmos; Rodrygo Luis Teodoro Santos; Philippe Rigaux; Thomas Risse; Torsten Suel; Masashi Toyoda; Gerhard Weikum,Supporters: European Union 7th Framework IST programme STREP (contract no. 258105),*,2013,*
International Conference on Management of Data: COMAD 2011,Srikanta Bedathur,Abstract In the last decade or so; the scope of database research has witnessed anexplosive expansion. When one looks at the research publications in top DB conferences; itis not surprising to see papers on topics ranging from machine learning to distributedsystems; multi-modal datasets to petabytes of scientific data; solutions customized formodern hardware to visualization-driven analytics; and so on. In fact; these papers dominatethe proceedings compared to papers on" traditional" DB topics.,Proceedings of the 17th International Conference on Management of Data,2011,*
Distributed Analytics over Web Archives,Yagiz Kargin; Srikanta Bedathur; Avishek Anand; Gerhard Weikum,Abstract Evolving content of the Web is being accumulated over time into Web archivalcollections. This creates the need for time travel search to explore the dynamics of thecontent. Text analytics has also a key role in exploring interesting information in textcollections. Moreover; frequent phrase mining; a special case of text analytics; is animportant analytical task that is motivated by the need of knowledge on frequent phrases invarious areas of computer science; such as information retrieval and machine translationetc. However; time travel search and frequent phrase mining have to be conducted onincreasingly large-scale data. Distributed approaches such as MapReduce; which is mainlydesigned to work on vast amount of text; can be utilized in this case. We address twoseparate problems in this thesis. The first problem is that time travel inverted index; which …,*,2011,*
Efficiently Identifying Interesting Time-Points in Text Archive Search,Vinay Setty; Gerhard Weikum; Srikanta Bedathur,Autor: Setty; Vinay et al.; Genre: Hochschulschrift; Im Druck veröffentlicht: 2010; Titel:Efficiently Identifying Interesting Time-Points in Text Archive Search.,*,2010,*
Time-aware Link Prediction in Evolving Social Networks,Tomasz Tylenda; Gerhard Weikum; Srikanta Bedathur,Autor: Tylenda; Tomasz et al.; Genre: Hochschulschrift; Im Druck veröffentlicht: 2009;Titel: Time-aware Link Prediction in Evolving Social Networks.,*,2009,*
Scalable phrase mining for ad-hoc text analytics,Srikanta Bedathur; Klaus Berberich; Jens Dittrich; Nikos Mamoulis; Gerhard Weikum,Abstract Large text corpora with news; customer mail and reports; or Web 2.0 contributionsoffer a great potential for enhancing business-intelligence applications. We propose aframework for performing text analytics on such data in a versatile; efficient; and scalablemanner. While much of the prior literature has emphasized mining keywords or tags in blogsor social-tagging communities; we emphasize the analysis of interesting phrases. Theseinclude named entities; important quotations; market slogans; and other multi-word phrasesthat are prominent in a dynamically derived ad-hoc subset of the corpus; eg; being frequentin the subset but relatively infrequent in the overall corpus. The ad-hoc subset may bederived by means of a keyword query against the corpus; or by focusing on a particular timeperiod. We investigate alternative definitions of phrase interestingness; based on the …,*,2009,*
of Proceedings: String Processing and Information Retrieval: 14th International Symposium; SPIRE 2007,Ralf Schenkel; Andreas Broschart; Seungwon Hwang; Martin Theobald; Gerhard Weikum,Abstract/Description: In addition to purely occurrence-based relevance models; termproximity has been frequently used to enhance retrieval quality of keyword-oriented retrievalsystems. While there have been approaches on effective scoring functions that incorporateproximity; there has not been much work on algorithms or access methods for their efficientevaluation. This paper presents an efficient evaluation framework including a proximityscoring function integrated within a top-k query engine for text retrieval. We proposeprecomputed and materialized index structures that boost performance. The increasedretrieval effectiveness and efficiency of our framework are demonstrated through extensiveexperiments on a very large text benchmark collection. In combination with static indexpruning for the proximity lists; our algorithm achieves an improvement of two orders of …,*,2007,*
Standing On the Shoulders of Peers: Caching in Peer-to-Peer Information Retrieval,Christian Zimmer; Srikanta Bedathur; Gerhard Weikum,A number of research prototypes of P2P-based Web search and information retrievalengines have been developed recently. These systems allow users to autonomously collectand index a subsets of the Web and share it with the rest of the community over a P2Pnetwork. This network of collections is queried via a set of keywords; similar to modernsearch engines. In order to be effective; a P2P search engine has to address the followingtwo conflicting requirements while keeping the computational costs at each involved peerlow:(i) provide high quality results in terms of precision and recall; and (ii) support scalabilitysuch that the number of participating peers is unlimited while handling large volumes ofdata. A few recent research prototypes have successfully overcome many of the issues inP2P search systems [1–4]. Despite these advances; large-scale deployment of P2P …,Fifth International Workshop on Databases; Information Systems and Peer-to-Peer Computing,2007,*
M eta¦ ines: A Product Line Architecture for,Bharath Kumar; Srikanta J Bedathur,*,*,2004,*
Impact of buffering on persistent suffix tree construction,Srikanta J Bedathur; Jayant R Haritsa,Abstract Suffix trees are indexes that are used commonly to solve many pattern search anddiscovery problems in an efficient manner over relatively static text. They are considered apowerful datastructure for various sequence processing tasks in the bio-informatics domain.A serious disadvantage of suffix trees is that they are usually much larger than theunderlying data sequences. This makes it impractical to consider them as memory-residentstructures when indexing long sequences. The obvious solution of storing the index overflowon disk is severely hampered due to the random seeks induced by standard suffix treeconstruction algorithms. In this paper; using a variety of DNA sequences as our testbed; weempirically evaluate two practical issues not considered before; that impact the persistent on-line construction of suffix trees. First; the impact of buffering–in terms of policies for …,*,2003,*
Summarizing Entities: A Survey Report,Shruti Chhabra; Srikanta Bedathurb,Abstract. With the increasing dominance and importance of entities on web; a challengingtask of generating summaries for entities has emerged. The information about these entitiesis usually scattered over various documents or captured by a knowledge base. Thesummarizing entities task aims at extracting information associated with entities from thesesources and produce summaries. These summaries describe the relationship amongentities and connections through/with related entities. This survey categorizes the varioussummary tasks such as generating a textual or structural summary for a single entity ormultiple entities. Existing literature is discussed with an identification of important entitysummarizing tasks.,*,*,*
ICDE 2017 Reviewers,Yannis Papakonstantinou; Lei Chen; Reynold Cheng; Wolfgang Gatterbauer; Bingsheng He; Stratos Idreos; Christopher Jermaine; Chen Li; Gerome Miklau; Tamer Özsu; Olga Papaemmanouil; Evimaria Terzi; Eugene Wu; Ashraf Aboulnaga; Alex Alves; Amazon Gabriel Antoniu; INRIA Arvind Arasu; Andrey Balmin; Workday Zhifeng Bao; Sumita Barahmand; Srikanta Bedathur; Carsten Binnig; Spyros Blanas; Marco Brambilla; Stephane Bressan; K Selcuk Candan; Zhao Cao; James Cheng; Fei Chiang; Panos K Chrysanthis; Philippe Cudre-Mauroux,ICDE 2017 Program Committee Chairs Yannis Papakonstantinou; University of California; SanDiego Yanlei Diao; Ecole Polytechnique; France; and University of Massachusetts; Amherst …ICDE 2017 Area Chairs Lei Chen; Hong Kong University of Science and Technology ReynoldCheng; University of Hong Kong Wolfgang Gatterbauer; Carnegie Mellon University BingshengHe; National University of Singapore Stratos Idreos; Harvard University ChristopherJermaine; Rice University Chen Li; University of California Irvine Gerome Miklau; University ofMassachusetts Tamer Özsu; University of Waterloo Olga Papaemmanouil; Brandeis UniversityEvimaria Terzi; Boston University Eugene Wu; Columbia University … ICDE 2017 Program CommitteeAshraf Aboulnaga; Qatar Computing Research Institute Alex Alves; Amazon Gabriel Antoniu;INRIA Arvind Arasu; Microsoft Research Andrey Balmin; Workday Zhifeng Bao; RMIT …,*,*,*
Programme Chairs,Raoul-Sam Daruwala; Cong Yu; Gustavo Alonso; Srikanta Bedathur; Kevin Chang; Isabel Drost; Ariel Fuxman; Lee Giles; Sharad Goel; Richard Hankins; Jeffrey Korn; Chris Mattmann; Charles McCathieNevile; Peter Mika; Stelios Paparizos; Eugene Shekita; Jimeng Sun; Jian Shuo Wang; Ding Zhou; Aoying Zhou,Table of Contents Creating Your Own Web-Deployed Street Map Using Open Source Softwareand Free Data............................................ 1 Christopher Adams; Tony Abou-Assaleh QueryPortals.................................................... 4 Sanjay Agrawal; Kaushik Chakrabarti; SurajitChaudhuri; Venkatesh Ganti; Arnd Konig; Dong Xin A Semantic Web Ready Service Languagefor Large-Scale Earth Science Archives … A Virtual OceanographicData Center............................... 38 Sean McCleese; Chris Mattmann; Rob Raskin; DanCrichton; Sean Hardman A new tool to improve the filtering options in advancedsearching....... 40 Fernando Moreno-Torres Towards a Semantic Web Environment forXBRL..................... 43 Sheila MAndez NA Aez; Jose Emilio Labra Gayo; Javier De Andr AsPorqpine: a Distributed Social Search Engine......................... 46 Josep M. Pujol; Pablo …,*,*,*
Exploiting Replication in Peer-to-Peer Search Over Distributed Digital Libraries,Christian Zimmer; Srikanta Bedathur; Christos Tryfonopoulos; Gerhard Weikum,Abstract. Existing peer-to-peer (P2P) networks suffer from dynamics: Both high churn withjoining and leaving of peers with unknown rates and without notification; as well as highdata dynamics with adding of new and disappearing of older data. We develop replicationstrategies from the existing P2P search engine Minerva where each participating peer ordigital library manages its own local document collection. A distributed directory on top of aChord-DHT stores per-term summaries of all peers. Given this scenario of a conceptuallyglobal but physically distributed directory; we design different replication strategies that canbe integrated into the query execution process. In this paper; we explore algorithms:,*,*,*
