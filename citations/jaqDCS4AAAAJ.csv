FLUX-CIM: flexible unsupervised extraction of citation metadata,Eli Cortez; Altigran S da Silva; Marcos André Gonçalves; Filipe Mesquita; Edleno S de Moura,Abstract In this paper we propose a knowledge-base approach to help extracting the correctcomponents of citations in any given format. Differently from related approaches that rely onmanually built knowledge-bases (KBs) for recognizing the components of a citation; in ourcase; such a KB is automatically constructed from an existing set of sample metadatarecords from a given area (eg; computer science or health sciences). Our approach does notrely on patterns encoding specific delimitators of a particular citation style. It is alsounsupervised; in the sense that it does not rely on a learning method that requires a trainingphase. These features assign to our technique a high degree of automation and flexibility.To demonstrate the effectiveness and applicability of our proposed approach we have runexperiments in which we applied it to extract information from citations in papers of two …,Proceedings of the 7th ACM/IEEE-CS joint conference on Digital libraries,2007,75
Ondux: on-demand unsupervised learning for information extraction,Eli Cortez; Altigran S da Silva; Marcos André Gonçalves; Edleno S de Moura,Abstract Information extraction by text segmentation (IETS) applies to cases in which datavalues of interest are organized in implicit semi-structured records available in textualsources (eg postal addresses; bibliographic information; ads). It is an important practicalproblem that has been frequently addressed in the recent literature. In this paper weintroduce ONDUX (On Demand Unsupervised Information Extraction); a new unsupervisedprobabilistic approach for IETS. As other unsupervised IETS approaches; ONDUX relies oninformation available on pre-existing data to associate segments in the input string withattributes of a given domain. Unlike other approaches; we rely on very effective matchingstrategies instead of explicit learning strategies. The effectiveness of this matching strategyis also exploited to disambiguate the extraction of certain attributes through a …,Proceedings of the 2010 ACM SIGMOD International Conference on Management of data,2010,35
A probabilistic approach for automatically filling form-based web interfaces,Guilherme A Toda; Eli Cortez; Altigran S da Silva; Edleno de Moura,Abstract In this paper we present a proposal for the implementation and evaluation of anovel method for automatically using data-rich text for filling form-based input interfaces. Oursolution takes a text as input; extracts implicit data values from it and fills appropriate fields.For this task; we rely on knowledge obtained from values of previous submissions for eachfield; which are freely obtained from the usage of the interfaces. Our approach; called iForm;exploits features related to the content and the style of these values; which are combinedthrough a Bayesian framework. Through extensive experimentation; we show that ourapproach is feasible and effective; and that it works well even when only a few previoussubmissions to the input interface are available.,Proceedings of the VLDB Endowment,2010,34
A flexible approach for extracting metadata from bibliographic citations,Eli Cortez; Altigran S da Silva; Marcos André Gonçalves; Filipe Mesquita; Edleno S de Moura,Abstract In this article we present FLUX-CiM; a novel method for extracting components (eg;author names; article titles; venues; page numbers) from bibliographic citations. Our methoddoes not rely on patterns encoding specific delimiters used in a particular citation style. Thisfeature yields a high degree of automation and flexibility; and allows FLUX-CiM to extractfrom citations in any given format. Differently from previous methods that are based onmodels learned from user-driven training; our method relies on a knowledge baseautomatically constructed from an existing set of sample metadata records from a given field(eg; computer science; health sciences; social sciences; etc.). These records are usuallyavailable on the Web or other public data repositories. To demonstrate the effectiveness andapplicability of our proposed method; we present a series of experiments in which we …,Journal of the Association for Information Science and Technology,2009,25
Joint unsupervised structure discovery and information extraction,Eli Cortez; Daniel Oliveira; Altigran S da Silva; Edleno S de Moura; Alberto HF Laender,Abstract In this paper we present JUDIE (Joint Unsupervised Structure Discovery andInformation Extraction); a new method for automatically extracting semi-structured datarecords in the form of continuous text (eg; bibliographic citations; postal addresses;classified ads; etc.) and having no explicit delimiters between them. While in state-of-the-artInformation Extraction methods the structure of the data records is manually supplied the byuser as a training step; JUDIE is capable of detecting the structure of each individual recordbeing extracted without any user assistance. This is accomplished by a novel StructureDiscovery algorithm that; given a sequence of labels representing attributes assigned topotential values; groups these labels into individual records by looking for frequent patternsof label repetitions among the given sequence. We also show how to integrate this …,Proceedings of the 2011 ACM SIGMOD International Conference on Management of data,2011,23
Adaptive and flexible blocking for record linkage tasks,Luiz Osvaldo Evangelista; Eli Cortez; Altigran S da Silva; Wagner Meira Jr,Abstract In data integration tasks; records from a single dataset or from different sourcesmust often be compared to identify records that represent the same real world entity. Thecost of this search process for finding duplicate records grows quadratically as the number ofrecords available in the data sources increases and; for this reason; direct approaches; suchas comparing all record pairs; must be avoided. In this context; blocking methods are used tocreate,Journal of Information and Data Management,2010,12
Building a research social network from an individual perspective,Alberto HF Laender; Mirella M Moro; Marcos André Gonçalves; Clodoveu A Davis Jr; Altigran S da Silva; Allan JC Silva; Carolina AS Bigonha; Daniel Hasan Dalip; Eduardo M Barbosa; Eli Cortez; Peterson S Procópio Jr; Rafael Odon de Alencar; Thiago NC Cardoso; Thiago Salles,Abstract In this poster paper; we present an overview of CiênciaBrasil; a research socialnetwork involving researchers within the Brazilian INCT program. We describe itsarchitecture and the solutions adopted for data collection; extraction; and deduplication; andfor materializing and visualizing the network.,Proceedings of the 11th annual international ACM/IEEE joint conference on Digital libraries,2011,10
Automatically filling form-based web interfaces with free text inputs,Guilherme A Toda; Eli Cortez; Filipe Mesquita; Altigran S da Silva; Edleno Moura; Marden Neubert,Abstract On the web of today the most prevalent solution for users to interact with data-intensive applications is the use of form-based interfaces composed by several data inputfields; such as text boxes; radio buttons; pull-down lists; check boxes; etc. Although theseinterfaces are popular and effective; in many cases; free text interfaces are preferred overform-based ones. In this paper we discuss the proposal and the implementation of a novelIR-based method for using data rich free text to interact with form-based interfaces. Oursolution takes a free text as input; extracts implicitly data values from it and fills appropriatefields using them. For this task; we rely on values of previous submissions for each field;which are freely obtained from the usage of form-based interfaces,Proceedings of the 18th international conference on World wide web,2009,10
Unsupervised strategies for information extraction by text segmentation,Eli Cortez; Altigran S da Silva,Abstract Information extraction by text segmentation (IETS) applies to cases in which datavalues of interest are organized in implicit semi-structured records available in textualsources (eg postal addresses; bibliographic information; ads). It is an important practicalproblem that has been frequently addressed in the recent literature. We report here partialresults from a PhD thesis work in which we introduce ONDUX (On Demand UnsupervisedInformation Extraction); a new unsupervised probabilistic approach for IETS. As otherunsupervised IETS approaches; ONDUX relies on information available on pre-existing datato associate segments in the input string with attributes of a given domain. Unlike otherapproaches; we rely on very effective matching strategies instead of explicit learningstrategies. The effectiveness of this matching strategy is also exploited to disambiguate …,Proceedings of the Fourth SIGMOD PhD Workshop on Innovative Database Research,2010,7
CiênciaBrasil-The Brazilian Portal of Science and Technology,Alberto HF Laender; Mirella M Moro; Altigran S Silva; Clodoveu A Davis Jr; Marcos André Gonçalves; Renata Galante; Allan JC Silva; Carolina AS Bigonha; Daniel Hasan Dalip; Eduardo M Barbosa; Eduardo N Borges; Eli Cortez; Peterson Procópio Jr; Rafael Odon de Alencar; Thiago NC Cardoso; Thiago Salles,Research social networks are a potentially useful resource for studying science andtechnology indicators from specific communities (eg; acountry). However; building andanalyzing such networks beget challenges beyond those from regular social networks; sincedata about actors and their relationships are usually dispersed across various sources. Inthis paper; we present a research social network built from an individual perspective bygathering data from a Brazilian curricula vitae repository. We describe its architecture andthe solutions adopted for data collection; extraction and deduplication; and for materializingand visualizing the network.,SEMISH,2011,6
CiênciaBrasil-The Brazilian Portal of Science and Technology,Alberto HF Laender; Mirella M Moro; Altigran S Silva; Clodoveu A Davis Jr; Marcos André Gonçalves; Renata Galante; Allan JC Silva; Carolina AS Bigonha; Daniel Hasan Dalip; Eduardo M Barbosa; Eduardo N Borges; Eli Cortez; Peterson Procópio Jr; Rafael Odon de Alencar; Thiago NC Cardoso; Thiago Salles,Research social networks are a potentially useful resource for studying science andtechnology indicators from specific communities (eg; acountry). However; building andanalyzing such networks beget challenges beyond those from regular social networks; sincedata about actors and their relationships are usually dispersed across various sources. Inthis paper; we present a research social network built from an individual perspective bygathering data from a Brazilian curricula vitae repository. We describe its architecture andthe solutions adopted for data collection; extraction and deduplication; and for materializingand visualizing the network.,JCDL,2011,6
Lightweight methods for large‐scale product categorization,Eli Cortez; Mauro Rojas Herrera; Altigran S da Silva; Edleno S de Moura; Marden Neubert,Abstract In this article; we present a study about classification methods for large-scalecategorization of product offers on e-shopping web sites. We present a study about theperformance of previously proposed approaches and deployed a probabilistic approach tomodel the classification problem. We also studied an alternative way of modelinginformation about the description of product offers and investigated the usage of price andstore of product offers as features adopted in the classification process. Our experimentsused two collections of over a million product offers previously categorized by human editorsand taxonomies of hundreds of categories from a real e-shopping web site. In theseexperiments; our method achieved an improvement of up to 9% in the quality of thecategorization in comparison with the best baseline we have found.,Journal of the Association for Information Science and Technology,2011,5
On using wikipedia to build knowledge bases for information extraction by text segmentation,Elton Serra; Eli Cortez; Altigran S da Silva; Edleno S de Moura,*,Journal of Information and Data Management,2011,4
Unsupervised information extraction with the ondux tool,André Porto; Eli Cortez; Altigran S da Silva; Edleno S de Moura,Page 1. A Unsupervised Information Extraction with the ONDUX Tool Presented by André PortoAndré Porto; Eli Cortez; Altigran S. da Silva; Edleno S. de Moura Univ. Fed. do Amazonas (UFAM) -Brazil SBBD 2011 Florianópolis; Brazil Page 2. The IETS Problem ► Information Extraction byText Segmentation ► Goal: ► To extract attribute values occurring in implicit semi- structured datarecords ► Current IETS methods predict labels for sequence of text segments corresponding toattribute values ► HMM – Borkar et al. (SIGMOD01); CRF – Laferty et al. (ICML01); ONDUX –Cortez et. al (SIGMOD10) Page 3. Motivation ► Abundance of on-line sources of text documents ►Postal Addresses; Classified Ads; Bibliography references... ► Necessity of storing these datain structured format ► Relational DB; XML; ► Unsupervised Methods rely on attribute values frompre- existing data sources to perform extraction task …,Simpsio Brasileiro de Banco de Dados,2011,4
Annotating database schemas to help enterprise search,Eli Cortez; Philip A Bernstein; Yeye He; Lev Novik,Abstract In large enterprises; data discovery is a common problem faced by users who needto find relevant information in relational databases. In this scenario; schema annotation is auseful tool to enrich a database schema with descriptive keywords. In this paper; wedemonstrate Barcelos; a system that automatically annotates corporate databases. Unlikeexisting annotation approaches that use Web oriented knowledge bases; Barcelos minesenterprise spreadsheets to find candidate annotations. Our experimental evaluation showsthat Barcelos produces high quality annotations; the top-5 have an average precision of87%.,Proceedings of the VLDB Endowment,2015,3
Unsupervised information extraction by text segmentation,Eli Cortez; Altigran S Da Silva,Information Extraction (IE) refers to the automatic extraction of structured information such asentities; relationships between entities; and attributes describing entities from noisyunstructured textual sources. It derives from the necessity of having unstructured data storedin structured formats (tables; XML); so that it can be further queried; processed; andanalyzed. The IE problem encompasses many distinct sub-problems such as Named EntityRecognition (NER); Open Information Extraction; Relationship Extraction; and TextSegmentation. Information Extraction by Text Segmentation (IETS) is the problem ofsegmenting unstructured textual inputs to extract implicit data values contained in them. Inthis book; we present a novel unsupervised approach for the problem of IETS. Thisapproach relies on information available on pre-existing data to learn how to associate …,*,2013,3
FleDEx: flexible data exchange,Filipe Mesquita; Denilson Barbosa; Eli Cortez; Altigran S da Silva,Abstract We propose a lightweight framework for data exchange that is suitable for non-expert and casual users sharing data on the Web or through peer-to-peer systems. Unlikeprevious work; we consider a simplistic data model and schema formalism that are suitablefor describing typical online data; and propose algorithms for mapping such schemas aswell as for translating the corresponding instances. Our solution requires minimal overheadand setup costs compared to existing data exchange systems; making it very attractive in theWeb data exchange setting. We report experimental results indicating that our method workswell with real Web data from various domains.,Proceedings of the 9th annual ACM international workshop on Web information and data management,2007,3
Resource Central: Understanding and Predicting Workloads for Improved Resource Management in Large Cloud Platforms,Eli Cortez; Anand Bonde; Alexandre Muzio; Mark Russinovich; Marcus Fontoura; Ricardo Bianchini,Abstract Cloud research to date has lacked data on the characteristics of the productionvirtual machine (VM) workloads of large cloud providers. A thorough understanding of thesecharacteristics can inform the providers' resource management systems; eg VM scheduler;power manager; server health manager. In this paper; we first introduce an extensivecharacterization of Microsoft Azure's VM workload; including distributions of the VMs'lifetime; deployment size; and resource consumption. We then show that certain VMbehaviors are fairly consistent over multiple lifetimes; ie history is an accurate predictor offuture behavior. Based on this observation; we next introduce Resource Central (RC); asystem that collects VM telemetry; learns these behaviors offline; and provides predictionsonline to various resource managers via a general client-side library. As an example of …,Proceedings of the 26th Symposium on Operating Systems Principles,2017,2
ICE: Managing cold state for big data applications,Badrish Chandramouli; Justin Levandoski; Eli Cortez,The use of big data in a business revolves around a monitor-mine-manage (M3) loop: datais monitored in real-time; while mined insights are used to manage the business and derivevalue. While mining has traditionally been performed offline; recent years have seen anincreasing need to perform all phases of M3 in real-time. A stream processing engine (SPE)enables such a seamless M3 loop for applications such as targeted advertising;recommender systems; risk analysis; and call-center analytics. However; these M3applications require the SPE to maintain massive amounts of state in memory; leading toresource usage skew: memory is scarce and over-utilized; whereas CPU and I/O are under-utilized. In this paper; we propose a novel solution to scaling SPEs for memory-bound M3applications that leverages natural access skew in data-parallel subqueries; where a …,Data Engineering (ICDE); 2016 IEEE 32nd International Conference on,2016,1
Methods and Techniques for Information Extraction by Text Segmentation.,Altigran Soares da Silva; Eli Cortez,Abstract. The growing use of text files for information exchange; such as HTML pages; XMLdocuments; e-mail; blogs posts; tweets; RSS and SMS messages; has brought manyproblems related to how properly exploit the information implicitly contained therein. Inparticular; problems related to Information Extraction from such sources have motivatedmany studies in various scientific communities in areas such as Databases; Data Mining;Information Retrieval and Artificial Intelligence. In this tutorial; we present recent methodsand techniques in the literature to address the problem of Information Extraction by TextSegmentation (IETS); which consists in extracting values of interest organized into semi-structured records (eg; postal addresses; bibliographic citations; classified ads; etc.);implicitly present in textual sources. We will discuss the most recent major approaches …,AMW,2012,1
Blocagem Adaptativa e Flexıvel para o Pareamento Aproximado de Registros,Luiz Osvaldo Evangelista; Eli Cortez; Altigran S da Silva; Wagner Meira Jr,In data integration tasks; records from a single dataset or from different sources must beoften compared to identify records that represent the same real world entity. The cost of thissearch process for finding duplicate records grows quadratically as the number of recordsavailable in the data sources increases and; for this reason; direct approaches; ascomparing all record pairs; must be avoided. In this context; blocking methods that arebased on machine learning processes are used to find the best blocking function; based onthe combination of low cost rules; which define how to perform the record blocking. Thiswork presents a new blocking method based on machine learning. Different from othermethods; this new approach is based on genetic programming; allowing the use of moreflexible rules and a larger number of such rules for defining blocking functions; leading to …,*,2009,1
JUDIE,Eli Cortez; Altigran S da Silva,Abstract This chapter presents Joint Unsupervised Structure Discovery and InformationExtraction (JUDIE) a method for addressing the IETS problem. JUDIE was presented in(Cortez et al. 2011). First; it is introduced the scenario to which JUDIE is targeted to; then wego over the proposed solution detailing all the steps that comprise JUDIE. Finally; anexperimental evaluation of JUDIE is presented; comparing its result with different baselinesavailable in the literature.,*,2013,*
Exploiting Pre-Existing Datasets to Support IETS,Eli Cortez; Altigran S da Silva,Abstract This chapter describes in detail a new approach for exploiting preexisting datasetsto support Information Extraction by Text Segmentation methods. First; it presents a briefoverview of the approach and introduces the concept of knowledge base. Next; it discussesall the steps involved in the unsupervised approach; including how to learn content-basedfeatures from knowledge bases; how to automatically induce structure-based features withno previous human-driven training; a feature that is unique to this approach; and how toeffectively combine these features to label segments of a text input.,*,2013,*
Conclusions and Future Work,Eli Cortez; Altigran S da Silva,In this book; it was presented and evaluated an unsupervised approach for the problem of InformationExtraction by Text Segmentation (IETS). This approach relies on knowledge bases to associatesegments in the input string with attributes of a given domain by using a very effective setcontent-based features. The effectiveness of the content-based features is also exploited to directlylearn from test data structure-based features; with no previous human-driven training; a featureunique to this approach … It was studied different aspects regarding this approach and comparedit with state-of-the-art IE methods. Results indicate that this approach performs quite well whencompared with such methods; even without any user intervention … Based on thisapproach; it produced a number of results to address the IETS problem in a unsupervisedfashion. Particularly; it was developed; implemented; and evaluated distinct IETS …,*,2013,*
iForm,Eli Cortez; Altigran S da Silva,Abstract This chapter presents iForm; a method for automatically using data-rich text forfilling form-based input interfaces that rely on the presented unsupervised approach to dealwith the Information Extraction by Text Segmentation problem. iForm was first presented inToda et al.(2009; 2010). In the following is described the scenario where iForm is applied;and the method in detail. A set of experiments is also reported that shows that iForm iseffective and works well in different scenarios.,*,2013,*
ONDUX,Eli Cortez; Altigran S da Silva,Abstract This chapter presents ONDUX (On Demand Unsupervised Information Extraction) amethod that relies on the presented unsupervised approach to deal with the InformationExtraction by Text Segmentation problem. ONDUX was first presented in Cortez et al.(2010)and in Cortez and da Silva (2010). Following; a tool based on ONDUX was presented inPorto et al.(2011). As other unsupervised IETS approaches; ONDUX relies on informationavailable on pre-existing data; but; unlike previously proposed methods; it also relies on avery effective set of content-based features to bootstrap the learning of structure-basedfeatures. More specifically; structure-based features are exploited to disambiguate theextraction of certain attributes through a reinforcement step. The reinforcement step relies onsequencing and positioning of attribute values directly learned on-demand from test data …,*,2013,*
Uma Abordagem Flexıvel para Extraç ao de Metadados em Citaç oes Bibliográficas,Eli Cortez; Altigran Soares da Silva,Resumo. Neste artigo apresentamos o FLUX-CiM; um novo método de extraçao decomponentes de citaçoes bibliográficas; tais como nomes de autores; tıtulos de artigo; etc.Tal método nao se baseia em padroes especıficos de codificaç ao de delimitadores de umdeterminado estilo de citaç ao; o que lhe confere um alto grau de automaçao e flexibilidade.Diferentemente de abordagens anteriores que dependem de treinamento manual pararealizar o processo de extraçao; o nosso método necessita apenas de uma base deconhecimento que pode ser automaticamente construıda a partir de um conjunto existentede registros de metadados de um dado domınio; por exemplo: Ciência da Computaçao;Ciências da Saúde; etc. Para demonstrar a eficácia e aplicabilidade do método proposto;realizamos experimentos que de extraçao dados de citaç oes bibliográficas de artigos …,*,2009,*
A Lightweight Framework for Exchanging Web Data,Filipe Mesquita; Denilson Barbosa; Eli Cortez; Altigran S da Silva,We propose a lightweight framework for data exchange that is suitable for non-expert andcasual users sharing data on theWeb and/or through peer-to-peer systems. Unlike previ-ouswork; we consider a minimalistic data model and schema formalism that are suitable fordescribing online data and propose algorithms for mapping such schemas as well as fortranslating the corresponding instances. Also our solution requires minimal overhead andsetup costs (eg; we consider data stored in tables; XML or CSV files) comparing to ex-istingdata exchange systems; making it very attractive in our setting. We report experimentalresults indicating that our method works well with real Web data from various do-mains.,*,2007,*
