Calvin: fast distributed transactions for partitioned database systems,Alexander Thomson; Thaddeus Diamond; Shu-Chun Weng; Kun Ren; Philip Shao; Daniel J Abadi,Abstract Many distributed storage systems achieve high data access throughput viapartitioning and replication; each system with its own advantages and tradeoffs. In order toachieve high scalability; however; today's systems generally reduce transactional support;disallowing single transactions from spanning multiple partitions. Calvin is a practicaltransaction scheduling and data replication layer that uses a deterministic orderingguarantee to significantly reduce the normally prohibitive contention costs associated withdistributed transactions. Unlike previous deterministic database system prototypes; Calvinsupports disk-based storage; scales near-linearly on a cluster of commodity machines; andhas no single point of failure. By replicating transaction inputs rather than effects; Calvin isalso able to support multiple consistency levels---including Paxos-based strong …,Proceedings of the 2012 ACM SIGMOD International Conference on Management of Data,2012,271
The case for determinism in database systems,Alexander Thomson; Daniel J Abadi,Abstract Replication is a widely used method for achieving high availability in databasesystems. Due to the nondeterminism inherent in traditional concurrency control schemes;however; special care must be taken to ensure that replicas don't diverge. Log shipping;eager commit protocols; and lazy synchronization protocols are well-understood methods forsafely replicating databases; but each comes with its own cost in availability; performance;or consistency. In this paper; we propose a distributed database system which combines asimple deadlock avoidance technique with concurrency control schemes that guaranteeequivalence to a predetermined serial ordering of transactions. This effectively removes allnondeterminism from typical OLTP workloads; allowing active replication with nosynchronization overhead whatsoever. Further; our system eliminates the requirement for …,Proceedings of the VLDB Endowment,2010,100
Lightweight locking for main memory database systems,Kun Ren; Alexander Thomson; Daniel J Abadi,Abstract Locking is widely used as a concurrency control mechanism in database systems.As more OLTP databases are stored mostly or entirely in memory; transactional throughputis less and less limited by disk IO; and lock managers increasingly become performancebottlenecks. In this paper; we introduce very lightweight locking (VLL); an alternativeapproach to pessimistic concurrency control for main-memory database systems that avoidsalmost all overhead associated with traditional lock manager operations. We also propose aprotocol called selective contention analysis (SCA); which enables systems implementingVLL to achieve high transactional throughput under high contention workloads. Weimplement these protocols both in a traditional single-machine multi-core database serversetting and in a distributed database where data is partitioned across many commodity …,Proceedings of the VLDB Endowment,2012,68
CalvinFS: Consistent WAN Replication and Scalable Metadata Management for Distributed File Systems.,Alexander Thomson; Daniel J Abadi,Abstract Existing file systems; even the most scalable systems that store hundreds ofpetabytes (or more) of data across thousands of machines; store file metadata on a singleserver or via a shared-disk architecture in order to ensure consistency and validity of themetadata. This paper describes a completely different approach for the design of replicated;scalable file systems; which leverages a high-throughput distributed database system formetadata management. This results in improved scalability of the metadata layer of the filesystem; as file metadata can be partitioned (and replicated) across a (shared-nothing)cluster of independent servers; and operations on file metadata transformed into distributedtransactions. In addition; our file system is able to support standard file system semantics—including fully linearizable random writes by concurrent users to arbitrary byte offsets …,FAST,2015,51
Lazy evaluation of transactions in database systems,Jose M Faleiro; Alexander Thomson; Daniel J Abadi,Abstract Existing database systems employ an\textit {eager} transaction processing scheme---that is; upon receiving a transaction request; the system executes all the operations entailedin running the transaction (which typically includes reading database records; executinguser-specified transaction logic; and logging updates and writes) before reporting to theclient that the transaction has completed. We introduce a\textit {lazy} transaction executionengine; in which a transaction may be considered durably completed after only partialexecution; while the bulk of its operations (notably all reads from the database and allexecution of transaction logic) may be deferred until an arbitrary future time; such as when auser attempts to read some element of the transaction's write-set---all without modifying thesemantics of the transaction or sacrificing ACID guarantees. Lazy transactions are …,Proceedings of the 2014 ACM SIGMOD international conference on Management of data,2014,22
An evaluation of the advantages and disadvantages of deterministic database systems,Kun Ren; Alexander Thomson; Daniel J Abadi,Abstract Recent proposals for deterministic database system designs argue thatdeterministic database systems facilitate replication since the same input can beindependently sent to two different replicas without concern for replica divergence. Inaddition; they argue that determinism yields performance benefits due to (1) the introductionof deadlock avoidance techniques;(2) the reduction (or elimination) of distributed commitprotocols; and (3) light-weight locking. However; these performance benefits are notuniversally applicable; and there exist several disadvantages of determinism; including (1)the additional overhead of processing transactions for which it is not known in advance whatdata will be accessed;(2) an inability to abort transactions arbitrarily (eg; in the case ofdatabase or partition overload); and (3) the increased latency required by a …,Proceedings of the VLDB Endowment,2014,15
Fast distributed transactions and strongly consistent replication for oltp database systems,Alexander Thomson; Thaddeus Diamond; Shu-Chun Weng; Kun Ren; Philip Shao; Daniel J Abadi,Abstract As more data management software is designed for deployment in public andprivate clouds; or on a cluster of commodity servers; new distributed storage systemsincreasingly achieve high data access throughput via partitioning and replication. In order toachieve high scalability; however; today's systems generally reduce transactional support;disallowing single transactions from spanning multiple partitions. This article describesCalvin; a practical transaction scheduling and data replication layer that uses a deterministicordering guarantee to significantly reduce the normally prohibitive contention costsassociated with distributed transactions. This allows near-linear scalability on a cluster ofcommodity machines; without eliminating traditional transactional guarantees; introducing asingle point of failure; or requiring application developers to reason about data …,ACM Transactions on Database Systems (TODS),2014,12
Modularity and Scalability in Calvin.,Alexander Thomson; Daniel J Abadi,Abstract Calvin is a transaction scheduling and replication management layer for distributedstorage systems. By first writing transaction requests to a durable; replicated log; and thenusing a concurrency control mechanism that emulates a deterministic serial execution of thelog's transaction requests; Calvin supports strongly consistent replication and fully ACIDdistributed transactions while incurring significantly lower inter-partition transactioncoordination costs than traditional distributed database systems. Furthermore; Calvin'sdeclarative specification of target concurrency-control behavior allows system componentsto avoid interacting with actual transaction scheduling mechanisms—whereas in traditionalDBMSs; the analogous components often have to explicitly observe concurrency controlmodules'(highly nondeterministic) procedural behaviors in order to function correctly.,IEEE Data Eng. Bull.,2013,9
Low-overhead asynchronous checkpointing in main-memory database systems,Kun Ren; Thaddeus Diamond; Daniel J Abadi; Alexander Thomson,Abstract As it becomes increasingly common for transaction processing systems to operateon datasets that fit within the main memory of a single machine or a cluster of commoditymachines; traditional mechanisms for guaranteeing transaction durability---which typicallyinvolve synchronous log flushes---incur increasingly unappealing costs to otherwiselightweight transactions. Many applications have turned to periodically checkpointing fulldatabase state. However; existing checkpointing methods---even those which avoid freezingthe storage layer---often come with significant costs to operation throughput; end-to-endlatency; and total memory usage. This paper presents Checkpointing Asynchronously usingLogical Consistency (CALC); a lightweight; asynchronous technique for capturing databasesnapshots that does not require a physical point of consistency to create a checkpoint …,Proceedings of the 2016 International Conference on Management of Data,2016,7
VLL: a lock manager redesign for main memory database systems,Kun Ren; Alexander Thomson; Daniel J Abadi,Abstract Lock managers are increasingly becoming a bottleneck in database systems thatuse pessimistic concurrency control. In this paper; we introduce very lightweight locking(VLL); an alternative approach to pessimistic concurrency control for main memory databasesystems; which avoids almost all overhead associated with traditional lock manageroperations. We also propose a protocol called selective contention analysis (SCA); whichenables systems implementing VLL to achieve high transactional throughput under high-contention workloads. We implement these protocols both in a traditional single-machinemulti-core database server setting and in a distributed database where data are partitionedacross many commodity machines in a shared-nothing cluster. Furthermore; we show howVLL and SCA can be extended to enable range locking. Our experiments show that VLL …,The VLDB Journal,2015,2
Deterministic database systems,*,In an embodiment; a plurality of transactions for accessing a database may be acquired. Thedatabase may be associated with a plurality of locks. The plurality of transactions mayinclude a first transaction; a second transaction; and a third transaction. A logicalserialization sequence for executing the transactions may be identified. The logicalserialization sequence may indicate that (1) the first transaction is to be executed before thesecond transaction based on all locks that are required by the first transaction beingavailable;(2) the second transaction is to be executed after the first transaction hascompleted execution based on the second transaction requiring a lock that is required by thefirst transaction; and (3) the third transaction is to be executed before or during execution ofthe first transaction based on all locks required by the third transaction being different …,*,2014,2
Deterministic transaction execution in distributed database systems,Alexander Garvey Thomson,Abstract The concurrency control mechanisms traditionally used in database systems tosupport ACID transactions are highly nondeterministic. They allow (and often cause) in-progress transactions to abort for reasons unrelated to transaction logic; such as deadlock;hardware failures; and other unpredictable events. We propose an alternative approach toconcurrency control that emulates a deterministic serial execution of an (explicitly logged)input sequence of transaction requests. In a database system using a deterministicconcurrency control protocol; all system replicas that use the same transaction input logremain strongly consistent with no further synchronization. Distributed transactions that spanmultiple shards within a replica may also eschew the distributed commit protocols requiredby traditional nondeterministic database systems; reducing lock contention and thereby …,*,2013,*
Is the patronage of the theatre consistent with true Christianity? A sermon,Alexander Thomson,THESE words are part of a description of the practical corruption of Christianity; which;according to the Apostolic prediction; should take place in the period called" the last days."These days; I conceive; commenced with the great apostacy from the truth and purity of theGospel; that wrapt Europe in darkness for many ages; but they have not yet finished theircourse. The words are written for our warning; that we might be on our guard againstseduction to evils of a like kind—evils that abound in every age—perils which are far more tobe dreaded than any hostile assaults in the form of persecution. That the principles andpassions; the views and dispositions and habits of the world; should insinuate themselvesinto the Church; infecting men's souls with a subtle poison; blighting their graces;undermining and destroying their spiritual life—that; I say; is far worse than any suffering …,*,1877,*
13th USENIX Conference on File and Storage Technologies,Alexander Thomson; Daniel J Abadi,Erez Zadok opened the conference with the numbers: 130 submissions with 28 papersselected. They used a two round online review process; with each paper getting threereviews during the first round; and the 68 remaining papers getting two more reviews in thenext round. The final decisions were made in an all-day meeting at Stony Brook. JiriSchindler announced awards; starting with ACM Test-of-Time Fast Track awards going to“RAIDShield: Characterizing; Monitoring; and Proactively Protecting against Disk Failures;”by Ao Ma et al.; and “BetrFS: A Right-Optimized Write-Optimized File System;” by WilliamJannen et al. The Best Paper Award went to “Skylight—A Window on Shingled DiskOperation;” by Abutalib Aghayev and Peter Desnoyers. These researchers cut a window intoa shingled (SMR) drive so that they could use a high-speed camera to record disk seeks …,*,*,*
Building Deterministic Transaction Processing Systems without Deterministic Thread Scheduling,Alexander Thomson; Daniel J Abadi,ABSTRACT Standard implementations of transactional systems such as database systemsallow several sources of nondeterminism to introduce unpredictable behavior. The recentintroduction of an architecture and execution model that isolates sources of nondeterministicbehavior in online transaction processing systems in order to yield deterministic transactionresults makes active replication easier and mitigates major scalability barriers. We observehere that (a) this approach would nicely complement other determinism techniques in theassembly of a fully deterministic application stack and (b) the approach does not rely on anyspecial thread-scheduling machinery or deterministic concurrency primitives and evenbenefits from the nondeterminism inherent in typical OS schedulers.,*,*,*
