Discover: Keyword search in relational databases,Vagelis Hristidis; Yannis Papakonstantinou,DISCOVER operates on relational databases and facilitates information discovery on themby allowing its user to issue keyword queries without any knowledge of the databaseschema or of SQL. DISCOVER returns qualified joining networks of tuples; that is; sets oftuples that are associated because they join on their primary and foreign keys andcollectively contain all the keywords of the query. DISCOVER proceeds in two steps. First;the Candidate Network Generator generates all candidate networks of relations; that is; joinexpressions that generate the joining networks of tuples. Second; the Plan Generator buildsplans for the efficient evaluation of the set of candidate networks; exploiting the opportunitiesto reuse common sub expressions of the candidate networks. Keyword search is the mostpopular information discovery method because the user does not need to know either a …,*,2002,997
-Efficient IR-Style Keyword Search over Relational Databases,Vagelis Hristidis; Yannis Papakonstantinou; Luis Gravano,This chapter presents a system for efficient information retrieval (IR)-style keyword searchover relational databases. A query in the model is simply a list of keywords and does notneed to specify any relation or attribute names. The answer to such a query consists of arank of “tuple trees;” which potentially include tuples from multiple relations that arecombined via joins. To rank tuple trees; this chapter introduces a ranking function thatleverages and extends the ability of modern relational database systems to provide keywordsearch on individual text attributes and rank tuples accordingly. In particular; the rankingfunction appropriately combines the relational database management systems (RDBMS)provided scores of individual attributes and tuples. The chapter introduces several top-kquery-processing algorithms whose relative strengths depend; for example; on whether …,*,2003,670
Objectrank: Authority-based keyword search in databases,Andrey Balmin; Vagelis Hristidis; Yannis Papakonstantinou,Abstract The ObjectRank system applies authority-based ranking to keyword search indatabases modeled as labeled graphs. Conceptually; authority originates at the nodes(objects) containing the keywords and flows to objects according to their semanticconnections. Each node is ranked according to its authority with respect to the particularkeywords. One can adjust the weight of global importance; the weight of each keyword of thequery; the importance of a result actually containing the keywords versus being referencedby nodes containing them; and the volume of authority flow via each type of semanticconnection. Novel performance challenges and opportunities are addressed. First; schemasimpose constraints on the graph; which are exploited for performance purposes. Second; inorder to address the issue of authority ranking with respect to the given keywords (as …,Proceedings of the Thirtieth international conference on Very large data bases-Volume 30,2004,607
Keyword search on spatial databases,Ian De Felipe; Vagelis Hristidis; Naphtali Rishe,Many applications require finding objects closest to a specified location that contains a set ofkeywords. For example online yellow pages allow users to specify an address and a set ofkeywords. In return the user obtains a list of businesses whose description contains thesekeywords ordered by their distance from the specified address. The problems of nearestneighbor search on spatial data and keyword search on text data have been extensivelystudied separately. However to the best of our knowledge there is no efficient method toanswer spatial keyword queries that is queries that specify both a location and a set ofkeywords. In this work we present an efficient method to answer top-k spatial keywordqueries. To do so we introduce an indexing structure called IR 2-Tree (Information RetrievalR-Tree) which combines an R-Tree with superimposed text signatures. We present …,Data Engineering; 2008. ICDE 2008. IEEE 24th International Conference on,2008,479
Keyword proximity search on XML graphs,V Hristidis; Y Papakonstantinon; A Balmin,XKeyword provides efficient keyword proximity queries on large XML graph databases. Aquery is simply a list of keywords and does not require any schema or query languageknowledge for its formulation. XKeyword is built on a relational database and; hence; canaccommodate very large graphs. Query evaluation is optimized by using the graph'sschema. In particular; XKeyword consists of two stages. In the preprocessing stage a set ofkeyword indices are built along with indexed path relations that describe particular patternsof paths in the graph. In the query processing stage plans are developed that use a nearoptimal set of path relations to efficiently locate the keyword query results. The results arepresented graphically using the novel idea of interactive result graphs; which are populatedon-demand according to the user's navigation and allow efficient information discovery …,ICDE; Bangalore,2003,354
PREFER: A system for the efficient execution of multi-parametric ranked queries,Vagelis Hristidis; Nick Koudas; Yannis Papakonstantinou,Abstract Users often need to optimize the selection of objects by appropriately weighting theimportance of multiple object attributes. Such optimization problems appear often inoperations' research and applied mathematics as well as everyday life; eg; a buyer mayselect a home as a weighted function of a number of attributes like its distance from office; itsprice; its area; etc. We capture such queries in our definition of preference queries that use aweight function over a relation's attributes to derive a score for each tuple. Database systemscannot efficiently produce the top results of a preference query because they need toevaluate the weight function over all tuples of the relation. PREFER answers preferencequeries efficiently by using materialized views that have been pre-processed and stored.,ACM Sigmod Record,2001,345
Keyword proximity search in XML trees,Vagelis Hristidis; Nick Koudas; Yannis Papakonstantinou; Divesh Srivastava,Recent works have shown the benefits of keyword proximity search in querying XMLdocuments in addition to text documents. For example; given query keywords overShakespeare's plays in XML; the user might be interested in knowing how the keywordscooccur. In this paper; we focus on XML trees and define XML keyword; proximity queries toreturn the (possibly heterogeneous) set of minimum connecting trees (MCTs) of the matchesto the individual keywords in the query. We consider efficiently executing keyword proximityqueries on labeled trees (XML) in various settings: 1) when the XML database has beenpreprocessed and 2) when no indices are available on the XML database. We perform adetailed experimental evaluation to study the benefits of our approach and show that ouralgorithms considerably outperform prior algorithms and other applicable approaches.,IEEE Transactions on Knowledge and Data Engineering,2006,241
Correlating financial time series with micro-blogging activity,Eduardo J Ruiz; Vagelis Hristidis; Carlos Castillo; Aristides Gionis; Alejandro Jaimes,Abstract We study the problem of correlating micro-blogging activity with stock-marketevents; defined as changes in the price and traded volume of stocks. Specifically; we collectmessages related to a number of companies; and we search for correlations between stock-market events for those companies and features extracted from the micro-bloggingmessages. The features we extract can be categorized in two groups. Features in the firstgroup measure the overall activity in the micro-blogging platform; such as number of posts;number of re-posts; and so on. Features in the second group measure properties of aninduced interaction graph; for instance; the number of connected components; statistics onthe degree distribution; and other graph-based properties. We present detailed experimentalresults measuring the correlation of the stock market events with these features; using …,Proceedings of the fifth ACM international conference on Web search and data mining,2012,229
Experiences on processing spatial data with mapreduce,Ariel Cary; Zhengguo Sun; Vagelis Hristidis; Naphtali Rishe,Abstract The amount of information in spatial databases is growing as more data is madeavailable. Spatial databases mainly store two types of data: raster data (satellite/aerial digitalimages); and vector data (points; lines; polygons). The complexity and nature of spatialdatabases makes them ideal for applying parallel processing. MapReduce is an emergingmassively parallel computing model; proposed by Google. In this work; we present ourexperiences in applying the MapReduce model to solve two important spatial problems:(a)bulk-construction of R-Trees and (b) aerial image quality computation; which involve vectorand raster data; respectively. We present our results on the scalability of MapReduce; andthe effect of parallelism on the quality of the results. Our algorithms were executed on aGoogle&IBM cluster; which became available to us through an NSF-supported program …,International Conference on Scientific and Statistical Database Management,2009,201
Probabilistic ranking of database query results,Surajit Chaudhuri; Gautam Das; Vagelis Hristidis; Gerhard Weikum,Abstract We investigate the problem of ranking answers to a database query when manytuples are returned. We adapt and apply principles of probabilistic models from InformationRetrieval for structured data. Our proposed solution is domain independent. It leveragesdata and workload statistics and correlations. Our ranking functions can be furthercustomized for different applications. We present results of preliminary experiments whichdemonstrate the efficiency as well as the quality of our ranking system.,Proceedings of the Thirtieth international conference on Very large data bases-Volume 30,2004,166
Survey of data management and analysis in disaster situations,Vagelis Hristidis; Shu-Ching Chen; Tao Li; Steven Luis; Yi Deng,Abstract The area of disaster management receives increasing attention from multipledisciplines of research. A key role of computer scientists has been in devising ways tomanage and analyze the data produced in disaster management situations. In this paper wemake an effort to survey and organize the current knowledge in the management andanalysis of data in disaster situations; as well as present the challenges and future researchdirections. Our findings come as a result of a thorough bibliography survey as well as ourhands-on experiences from building a Business Continuity Information Network (BCIN) withthe collaboration with the Miami-Dade county emergency management office. We organizeour findings across the following Computer Science disciplines: data integration andingestion; information extraction; information retrieval; information filtering; data mining …,Journal of Systems and Software,2010,147
Probabilistic information retrieval approach for ranking of database query results,Surajit Chaudhuri; Gautam Das; Vagelis Hristidis; Gerhard Weikum,Abstract We investigate the problem of ranking the answers to a database query when manytuples are returned. In particular; we present methodologies to tackle the problem forconjunctive and range queries; by adapting and applying principles of probabilistic modelsfrom information retrieval for structured data. Our solution is domain independent andleverages data and workload statistics and correlations. We evaluate the quality of ourapproach with a user survey on a real database. Furthermore; we present andexperimentally evaluate algorithms to efficiently retrieve the top ranked results; whichdemonstrate the feasibility of our ranking system.,ACM Transactions on Database Systems (TODS),2006,146
BORG: Block-reORGanization for Self-optimizing Storage Systems.,Medha Bhadkamkar; Jorge Guerra; Luis Useche; Sam Burnett; Jason Liptak; Raju Rangaswami; Vagelis Hristidis,Abstract This paper presents the design; implementation; and evaluation of BORG; a self-optimizing storage system that performs automatic block reorganization based on theobserved I/O workload. BORG is motivated by three characteristics of I/O workloads: non-uniform access frequency distribution; temporal locality; and partial determinism in non-sequential accesses. To achieve its objective; BORG manages a small; dedicated partitionon the disk drive; with the goal of servicing a majority of the I/O requests from within thispartition with significantly reduced seek and rotational delays. BORG is transparent to therest of the storage stack; including applications; file system (s); and I/O schedulers; therebyrequiring no or minimal modification to storage stack implementations. We evaluated a Linuximplementation of BORG using several real-world workloads; including individual user …,FAST,2009,140
A system for query-specific document summarization,Ramakrishna Varadarajan; Vagelis Hristidis,Abstract There has been a great amount of work on query-independent summarization ofdocuments. However; due to the success of Web search engines query-specific documentsummarization (query result snippets) has become an important problem; which hasreceived little attention. We present a method to create query-specific summaries byidentifying the most query-relevant fragments and combining them using the semanticassociations within the document. In particular; we first add structure to the documents in thepreprocessing stage and convert them to document graphs. Then; the best summaries arecomputed by calculating the top spanning trees on the document graphs. We present andexperimentally evaluate efficient algorithms that support computing summaries in interactivetime. Furthermore; the quality of our summarization method is compared to current …,Proceedings of the 15th ACM international conference on Information and knowledge management,2006,107
Algorithms and applications for answering ranked queries using ranked views,Vagelis Hristidis; Yannis Papakonstantinou,Abstract. Ranked queries return the top objects of a database according to a preferencefunction. We present and evaluate (experimentally and theoretically) a core algorithm thatanswers ranked queries in an efficient pipelined manner using materialized ranked views.We use and extend the core algorithm in the described PREFER and MERGE systems.PREFER precomputes a set of materialized views that provide guaranteed queryperformance. We present an algorithm that selects a near optimal set of views under spaceconstraints. We also describe multiple optimizations and implementation aspects of thedownloadable version of PREFER. Then we discuss MERGE; which operates at ametabroker and answers ranked queries by retrieving a minimal number of objects fromsources that offer ranked queries. A speculative version of the pipelining algorithm is …,The VLDB Journal,2004,106
Authority-based keyword search in databases,Vagelis Hristidis; Heasoo Hwang; Yannis Papakonstantinou,Abstract Our system applies authority-based ranking to keyword search in databasesmodeled as labeled graphs. Three ranking factors are used: the relevance to the query; thespecificity and the importance of the result. All factors are handled using authority-flowtechniques that exploit the link-structure of the data graph; in contrast to traditionalInformation Retrieval. We address the performance challenges in computing the authorityflows in databases by using precomputation and exploiting the database schema if present.We conducted user surveys and performance experiments on multiple real and syntheticdatasets; to assess the semantic meaningfulness and performance of our system.,ACM Transactions on Database Systems (TODS),2008,81
Standing out in a crowd: Selecting attributes for maximum visibility,Muhammed Miah; Gautam Das; Vagelis Hristidis; Heikki Mannila,In recent years; there has been significant interest in development of ranking functions andefficient top-k retrieval algorithms to help users in ad-hoc search and retrieval in databases(eg; buyers searching for products in a catalog). In this paper we focus on a novel andcomplementary problem: how to guide a seller in selecting the best attributes of a new tuple(eg; new product) to highlight such that it stands out in the crowd of existing competitiveproducts and is widely visible to the pool of potential buyers. We develop several interestingformulations of this problem. Although these problems are NP-complete; we can giveseveral exact algorithms as well as approximation heuristics that work well in practice. Ourexact algorithms are based on Integer Programming (IP) formulations of the problems; aswell as on adaptations of maximal frequent itemset mining algorithms; while our …,Data Engineering; 2008. ICDE 2008. IEEE 24th International Conference on,2008,80
Ordering the attributes of query results,Gautam Das; Vagelis Hristidis; Nishant Kapoor; Shashank Sudarshan,Abstract There has been a great deal of interest in the past few years on ranking of results ofqueries on structured databases; including work on probabilistic information retrieval; rankaggregation; and algorithms for merging of ordered lists. In many applications; for examplesales of homes; used cars or electronic goods; data items have a very large number ofattributes. When displaying a (ranked) list of items to users; only a few attributes can beshown. Traditionally; these are selected manually. We argue that automatic selection ofattributes is required to deal with different requirements of different users. We formulate theproblem as an optimization problem of choosing the most" useful" set of attributes; that is; theattributes that are most influential in the ranking of the items. We discuss different variants ofour notion of attribute usefulness; and propose a hybrid Split-Pane approach that returns …,Proceedings of the 2006 ACM SIGMOD international conference on Management of data,2006,79
Branch-and-bound processing of ranked queries,Yufei Tao; Vagelis Hristidis; Dimitris Papadias; Yannis Papakonstantinou,Abstract Despite the importance of ranked queries in numerous applications involving multi-criteria decision making; they are not efficiently supported by traditional database systems.In this paper; we propose a simple yet powerful technique for processing such queriesbased on multi-dimensional access methods and branch-and-bound search. Theadvantages of the proposed methodology are:(i) it is space efficient; requiring only a singleindex on the given relation (storing each tuple at most once);(ii) it achieves significant (ie;orders of magnitude) performance gains with respect to the current state-of-the-art;(iii) it canefficiently handle data updates; and (iv) it is applicable to other important variations ofranked search (including the support for non-monotone preference functions); at no extraspace overhead. We confirm the superiority of the proposed methods with a detailed …,Information Systems,2007,72
Facetor: cost-driven exploration of faceted query results,Abhijith Kashyap; Vagelis Hristidis; Michalis Petropoulos,Abstract Faceted navigation is being increasingly employed as an effective technique forexploring large query results on structured databases. This technique of mitigatinginformation-overload leverages metadata of the query results to provide users with facetconditions that can be used to progressively refine the user's query and filter the queryresults. However; the number of facet conditions can be quite large; thereby increasing theburden on the user. We present the FACeTOR system that proposes a cost-based approachto faceted navigation. At each step of the navigation; the user is presented with a subset ofall possible facet conditions that are selected such that the overall expected navigation costis minimized and every result is guaranteed to be reachable by a facet condition. We provethat the problem of selecting the optimal facet conditions at each navigation step is NP …,Proceedings of the 19th ACM international conference on Information and knowledge management,2010,67
Towards a business continuity information network for rapid disaster recovery,Khalid Saleem; Steven Luis; Yi Deng; Shu-Ching Chen; Vagelis Hristidis; Tao Li,Abstract Crisis Management and Disaster Recovery have gained immense importance inthe wake of recent man and nature inflicted calamities such as the terrorist attacks ofSeptember 11 th 2001 and hurricanes/earthquakes ie Katrina (2005); Wilma (2005) andIndian Ocean Tsunami (2004). Most of the recent work has been conducted for crisismanagement under terrorist attacks and emergency management services under naturaldisasters with private business continuity and disaster recovery a secondary concern. In thispaper; we propose a model for pre-disaster preparation and post-disaster businesscontinuity/rapid recovery. The model is utilized to design and develop a web basedprototype of our Business Continuity Information Network (BCIN) system facilitatingcollaboration among local; state; federal agencies and the business community for rapid …,Proceedings of the 2008 international conference on Digital government research,2008,64
Searching digital information and databases,*,This application describes methods for searching digital information such as digitaldocuments (eg; web pages) and computer databases; and specific search techniques suchas authority ranking and information retrieval (IR) relevance ranking in keyword searches. Insome implementations; the technique includes analyzing digital information viewed as alabeled graph; including nodes and edges; based on a flow of authority among the nodesalong the edges; the flow of authority being derived at least in part from different authoritytransfer rates assigned to the edges based on edge type schema information. In someimplementations; the system includes an object rank module configured to generate multipleinitial rankings corresponding to multiple query keywords; each of the multiple initialrankings indicating authority of nodes in a graph with respect to each respective query …,*,2010,63
Objectrank: a system for authority-based search on databases,Heasoo Hwang; Vagelis Hristidis; Yannis Papakonstantinou,Abstract We present ObjectRank demo system that performs authority-based keywordsearch on bibliographic databases. We also provide Inverse ObjectRank as a keyword-specific specificity metric and other calibration parameters such as Global ObjectRank.Users can specify various combinations of calibration values to control the behavior of thedemo. Finally; we propose a methodology that enables us to extend query results using theontology graph.,Proceedings of the 2006 ACM SIGMOD international conference on Management of data,2006,55
Semantic Caching of XML Databases.,Vagelis Hristidis; Michalis Petropoulos,Abstract We present a novel framework for semantic caching of XML databases. The cachedXML data are organized using a modification of the incomplete tree [ASV01]; which hasmany desirable properties; as incremental maintenance; containment decidability andremainder queries generation in PTIME. The modification we propose alleviates theexponential blowup observed in [ASV01] by partitioning the domains of the XML schemanodes in domain ranges. We also provide an upper bound on the total size of the conditionaltree type of the modified incomplete tree (MIT); which describes the data stored in the MIT.XCacher operates on top of XML databases and intercepts the query requests from a webserver. We show how the MIT is maintained and how queries are answered by sending acomplete and non-redundant set of remainder queries to the XML database. Finally we …,WebDB,2002,47
-A System for Keyword Proximity Search on XML Databases,Andrey Balmin; Yannis Papakonstantinou; Vagelis Hristidis; Tianqiu Wang; Divesh Srivastava; Nick Koudas,This chapter discusses keyword proximity search on XML database. Keyword proximitysearch is a user-friendly information discovery technique that has been extensively studiedfor text documents. In extending this technique to structured databases; recent works providekeyword proximity search on labeled graphs. A keyword proximity search does not requirethe user to know the structure of the graph; the role of the objects containing the keywords;or the type of the connections between the objects. The user simply submits a list ofkeywords and the system returns the sub-graphs that connect the objects containing thekeywords. XML and its labeled graph/tree abstractions are becoming the data model ofchoice for representing semistructured; self-describing data; and keyword proximity searchis well-suited to XML documents as well.A System for Keyword Proximity Search on XML …,*,2003,45
Beyond single-page web search results,Ramakrishna Varadarajan; Vagelis Hristidis; Tao Li,Given a user keyword query; current Web search engines return a list of individual Webpages ranked by their" goodness" with respect to the query. Thus; the basic unit for searchand retrieval is an individual page; even though information on a topic is often spread acrossmultiple pages. This degrades the quality of search results; especially for long oruncorrelated (multitopic) queries (in which individual keywords rarely occur together in thesame document); where a single page is unlikely to satisfy the user's information need. Wepropose a technique that; given a keyword query; on the fly generates new pages; calledcomposed pages; which contain all query keywords. The composed pages are generated byextracting and stitching together relevant pieces from hyperlinked Web pages and retaininglinks to the original Web pages. To rank the composed pages; we consider both the …,IEEE Transactions on knowledge and data engineering,2008,44
CVM–A communication virtual machine,Yi Deng; S Masoud Sadjadi; Peter J Clarke; Vagelis Hristidis; Raju Rangaswami; Yingbo Wang,Abstract The convergence of data; voice; and multimedia communication over digitalnetworks; coupled with continuous improvement in network capacity and reliability hasresulted in a proliferation of communication technologies. Unfortunately; despite these newdevelopments; there is no easy way to build new application-specific communicationservices. The stovepipe approach used today for building new communication servicesresults in rigid technology; limited utility; lengthy and costly development cycle; and difficultyin integration. In this paper; we introduce communication virtual machine (CVM) thatsupports rapid conception; specification; and automatic realization of new application-specific communication services through a user-centric; model-driven approach. We presentthe concept; architecture; modeling language; prototypical design; and implementation of …,Journal of Systems and Software,2008,43
Authority-based keyword queries in databases using ObjectRank,Andrey Balmin; Vagelis Hristidis; Yannis Papakonstantinou,*,VLDB; Toronto,2004,40
Explaining and reformulating authority flow queries,Ramakrishna Varadarajan; Vagelis Hristidis; Louiqa Raschid,Authority flow is an effective ranking mechanism for answering queries on a broad class ofdata. Systems have been developed to apply this principle on the Web (PageRank and topicsensitive PageRank); bibliographic databases (ObjectRank); and biological databases(Hubs of Knowledge project). However; these systems have the following drawbacks:(a)There is no way to explain to the user why a particular result received its current score;(b)The authority flow rates; which have been shown to dramatically affect the results' quality inObjectRank; have to be set manually by a domain expert;(c) There is no query reformulationmethodology to refine the query results according to the user's preferences. In this work; weaddress these shortcomings by introducing a framework and algorithms to explain queryresults and reformulate authority flow queries based on the user's feedback. The query …,Data Engineering; 2008. ICDE 2008. IEEE 24th International Conference on,2008,39
Syntactic rule based approach toweb service composition,Ken Pu; Vagelis Hristidis; Nick Koudas,This paper studies a problem of web service composition from a syntactic approach. Incontrast with other approaches on enriched semantic description such as statetransitiondescription of web services; our focus is in the case when only the input-output typeinformation from the WSDL specifications is available. The web service composition problemis formally formulated as deriving a given desired type from a collection of available typesand web services using a prescribed set of rules with costs. We show that solving theminimal cost composition is NP-complete in general; and present a practical solution basedon dynamic programming. Experiements using a mixture of synthetic and real data setsshow that our approach is viable and produces good results.,Data Engineering; 2006. ICDE'06. Proceedings of the 22nd International Conference on,2006,36
Ranking database query results using probabilistic models from information retrieval,*,A system and methods rank results of database queries. An automated approach for rankingdatabase query results is disclosed that leverages data and workload statistics andassociations. Ranking functions are based upon the principles of probabilistic models fromInformation Retrieval that are adapted for structured data. The ranking functions areencoded into an intermediate knowledge representation layer. The system is generic; as theranking functions can be further customized for different applications. Benefits of thedisclosed system and methods include the use of adapted probabilistic information retrieval(PIR) techniques that leverage relational/structured data; such as columns; to providenatural groupings of data values. This permits the inference and use of pair-wiseassociations between data values across columns; which are usually not possible with …,*,2008,34
Using data mining techniques to address critical information exchange needs in disaster affected public-private networks,Li Zheng; Chao Shen; Liang Tang; Tao Li; Steve Luis; Shu-Ching Chen; Vagelis Hristidis,Abstract Crisis Management and Disaster Recovery have gained immense importance inthe wake of recent man and nature inflicted calamities. A critical problem in a crisis situationis how to efficiently discover; collect; organize; search and disseminate real-time disasterinformation. In this paper; we address several key problems which inhibit better informationsharing and collaboration between both private and public sector participants for disastermanagement and recovery. We design and implement a web based prototypeimplementation of a Business Continuity Information Network (BCIN) system utilizing thelatest advances in data mining technologies to create a user-friendly; Internet-based;information-rich service and acting as a vital part of a company's business continuityprocess. Specifically; information extraction is used to integrate the input data from …,Proceedings of the 16th ACM SIGKDD international conference on Knowledge discovery and data mining,2010,33
XOntoRank: Ontology-aware search of electronic medical records,Fernando Farfan; Vagelis Hristidis; Anand Ranganathan; Michael Weiner,As the use of Electronic Medical Records (EMRs) becomes more widespread; so does theneed for effective information discovery within them. Recently proposed EMR standards areXML-based. A key characteristic in these standards is the frequent use of ontologicalreferences; ie; ontological concept codes appear as XML elements and are used toassociate portions of the EMR document with concepts defined in a domain ontology. A richcorpus of work addresses searching XML documents. Unfortunately; these works do notmake use of ontological references to enhance search. In this paper we present theXOntoRank system which addresses the problem of ontology-aware keyword search of XMLdocuments with a particular focus on EMR XML documents. Our current prototypes andexperiments use the Health Level Seven (HL7) Clinical Document Architecture (CDA) …,Data Engineering; 2009. ICDE'09. IEEE 25th International Conference on,2009,30
Structure-based query-specific document summarization,Ramakrishna Varadarajan; Vagelis Hristidis,Abstract Summarization of text documents is increasingly important with the amount of dataavailable on the Internet. The large majority of current approaches view documents as linearsequences of words and create query-independent summaries. However; ignoring thestructure of the document degrades the quality of summaries. Furthermore; the popularity ofweb search engines requires query-specific summaries. We present a method to createquery-specific summaries by adding structure to documents by extracting associationsbetween their fragments.,Proceedings of the 14th ACM international conference on Information and knowledge management,2005,30
Facilitating document annotation using content and querying value,Eduardo J Ruiz; Vagelis Hristidis; Panagiotis G Ipeirotis,A large number of organizations today generate and share textual descriptions of theirproducts; services; and actions. Such collections of textual data contain significant amount ofstructured information; which remains buried in the unstructured text. While informationextraction algorithms facilitate the extraction of structured relations; they are often expensiveand inaccurate; especially when operating on top of text that does not contain any instancesof the targeted structured information. We present a novel alternative approach thatfacilitates the generation of the structured metadata by identifying documents that are likelyto contain information of interest and this information is going to be subsequently useful forquerying the database. Our approach relies on the idea that humans are more likely to addthe necessary metadata during creation time; if prompted by the interface; or that it is …,IEEE transactions on knowledge and data engineering,2014,25
A declarative approach for specifying user-centric communication,Peter J Clarke; Vagelis Hristidis; Yingbo Wang; Nagarajan Prabakar; Yi Deng,The rapidly growing; reliable network infrastructure available today is enabling severalclasses of communication and collaborative applications. Already; a wide range ofcommunication applications; tools and services (eg; IP telephony; instant messaging; digitalvideo conferencing; and multimedia collaboration); and many domain-or industry-specificcommunication applications (eg; telemedicine; disaster management; and defense) havebeen developed and deployed. However; these communication applications have beenconceived; designed and developed vertically and separately with little or no connection toeach other. In addition; there has been little or no attention paid to how the end-userspecifies his/her communication needs when using these applications. We propose a newparadigm to define user-centric communications; which is based on a simple and …,Collaborative Technologies and Systems; 2006. CTS 2006. International Symposium on,2006,25
Efficient prediction of difficult keyword queries over databases,Shiwen Cheng; Arash Termehchy; Vagelis Hristidis,Keyword queries on databases provide easy access to data; but often suffer from lowranking quality; ie; low precision and/or recall; as shown in recent benchmarks. It would beuseful to identify queries that are likely to have low ranking quality to improve the usersatisfaction. For instance; the system may suggest to the user alternative queries for suchhard queries. In this paper; we analyze the characteristics of hard queries and propose anovel framework to measure the degree of difficulty for a keyword query over a database;considering both the structure and the content of the database and the query results. Weevaluate our query difficulty prediction model against two effectiveness benchmarks forpopular keyword search ranking methods. Our empirical results show that our modelpredicts the hard queries with high accuracy. Further; we present a suite of optimizations …,IEEE transactions on knowledge and data engineering,2014,24
A communication virtual machine,Yi Deng; S Masoud Sadjadi; Peter J Clarke; Chi Zhang; Vagelis Hristidis; Raju Rangaswami; Nagarajan Prabakar,The convergence of data; voice and multimedia communication over digital networks;coupled with continuous improvement in network capacity and reliability has significantlyenriched the ways we communicate. However; the stovepipe approach used to developtoday's communication applications and tools results in rigid technology; limited utility;lengthy and costly development cycle; difficulty in integration; and hinders innovation. In thispaper; we present a fundamentally different approach; which we call communication virtualmachine (CVM) to address these problems. CVM provides a user-centric; model-drivenapproach for conceiving; synthesizing and delivering communication solutions acrossapplication domains. We argue that CVM represents a far more effective paradigm forengineering communication solutions. The concept; architecture; modeling language …,Computer Software and Applications Conference; 2006. COMPSAC'06. 30th Annual International,2006,24
Continuous keyword search on multiple text streams,Vagelis Hristidis; Oscar Valdivia; Michail Vlachos; Philip S Yu,Abstract In this paper we address the issue of continuous keyword queries on multipletextual streams. This line of work represents a significant departure from previous keywordsearch models that assumed a static database. In our model the user poses a querycomprised by a collection of keywords; which is subsequently applied on multiple textstreams (these can be RSS news feeds; TV closed captions; emails; etc). A result to a queryis a combination of streams" sufficiently correlated" to each other that collectively contain allquery keywords within a specified time span.,Proceedings of the 15th ACM international conference on Information and knowledge management,2006,23
Effective navigation of query results based on concept hierarchies,Abhijith Kashyap; Vagelis Hristidis; Michalis Petropoulos; Sotiria Tavoulari,Search queries on biomedical databases; such as PubMed; often return a large number ofresults; only a small subset of which is relevant to the user. Ranking and categorization;which can also be combined; have been proposed to alleviate this information overloadproblem. Results categorization for biomedical databases is the focus of this work. A naturalway to organize biomedical citations is according to their MeSH annotations. MeSH is acomprehensive concept hierarchy used by PubMed. In this paper; we present the BioNavsystem; a novel search interface that enables the user to navigate large number of queryresults by organizing them using the MeSH concept hierarchy. First; the query results areorganized into a navigation tree. At each node expansion step; BioNav reveals only a smallsubset of the concept nodes; selected such that the expected user navigation cost is …,IEEE Transactions on Knowledge and Data Engineering,2011,21
Information discovery on electronic health records,Vagelis Hristidis,Exploiting the rich information found in electronic health records (EHRs) can facilitate bettermedical research and improve the quality of medical practice. Until now; a trivial amount ofresearch has been published on the challenges of leveraging this information. Addressingthese challenges; Information Discovery on Electronic Health Records explores thetechnology to unleash the data stored in EHRs. Assembling a truly interdisciplinary team ofexperts; the book tackles medical privacy concerns; the lack of standardization for therepresentation of EHRs; missing or incorrect values; and the availability of multiple richhealth ontologies. It looks at how to search the EHR collection given a user query and returnrelevant fragments from the EHRs. It also explains how to mine the EHR collection to extractinteresting patterns; group entities to various classes; or decide whether an EHR satisfies …,*,2009,21
Flexible and efficient querying and ranking on hyperlinked data sources,Ramakrishna Varadarajan; Vagelis Hristidis; Louiqa Raschid; Maria-Esther Vidal; Luis Ibáñez; Héctor Rodríguez-Drumond,Abstract There has been an explosion of hyperlinked data in many domains; eg; thebiological Web. Expressive query languages and effective ranking techniques are requiredto convert this data into browsable knowledge. We propose the Graph Information Discovery(GID) framework to support sophisticated user queries on a rich web of annotated andhyperlinked data entries; where query answers need to be ranked in terms of somecustomized ranking criteria; eg; PageRank or ObjectRank. GID has a data model thatincludes a schema graph and a data graph; and an intuitive query interface. The GIDframework allows users to easily formulate queries consisting of sequences of hard filters(selection predicates) and soft filters (ranking criteria); it can also be combined with otherspecialized graph query languages to enhance their ranking capabilities. GID queries …,Proceedings of the 12th International Conference on Extending Database Technology: Advances in Database Technology,2009,21
How fresh do you want your search results?,Shiwen Cheng; Anastasios Arvanitis; Vagelis Hristidis,Abstract Researchers have recognized the importance of utilizing temporal features forimproving the performance of information retrieval systems. Specifically; the timeliness of aweb document can be a significant factor for determining whether it is relevant for a searchquery. Previous works have proposed time-aware retrieval models with particular focus onnews queries; where recent web documents related with a real-world event are generallypreferable. These queries typically exhibit bursts in the volume of published documents orsubmitted queries. However; no work has studied the role of time in queries such as" creditcard overdraft fees" that have no major spikes in either document or query volumes overtime; yet they still favor more recently published documents. In this work; we focus on thisclass of queries that we refer to as" timely queries". We show that the change in the terms …,Proceedings of the 22nd ACM international conference on Conference on information & knowledge management,2013,19
Predicting the effectiveness of keyword queries on databases,Shiwen Cheng; Arash Termehchy; Vagelis Hristidis,Abstract Keyword query interfaces (KQIs) for databases provide easy access to data; butoften suffer from low ranking quality; ie low precision and/or recall; as shown in recentbenchmarks. It would be useful to be able to identify queries that are likely to have lowranking quality to improve the user satisfaction. For instance; the system may suggest to theuser alternative queries for such hard queries. In this paper; we analyze the characteristicsof hard queries and propose a novel framework to measure the degree of difficulty for akeyword query over a database; considering both the structure and the content of thedatabase and the query results. We evaluate our query difficulty prediction model againsttwo relevance judgment benchmarks for keyword search on databases; INEX andSemSearch. Our study shows that our model predicts the hard queries with high accuracy …,Proceedings of the 21st ACM international conference on Information and knowledge management,2012,18
A flexible approach for electronic medical records exchange,Vagelis Hristidis; Peter J Clarke; Nagarajan Prabakar; Yi Deng; Jeffrey A White; Redmond P Burke,Abstract Many methodologies have been proposed in the last decade for integration andexchange of medical data. However; little progress has occurred due to the followingreasons. First; patients are reluctant to give full access to their historical medical data.Second; institutions are reluctant to open their systems to mediators or any type of externalaccess; due to security; privacy (HIPAA; unique patient id) and competitive advantage-related reasons.,Proceedings of the international workshop on Healthcare information and knowledge management,2006,18
BioNav: Effective Navigation on Query Results of Biomedical Databases,Abhijith Kashyap; Vagelis Hristidis; Michalis Petropoulos; Sotiria Tavoulari,Search queries on biomedical databases like PubMed often return a large number of results;only a small subset of which is relevant to the user. Ranking and categorization; which canalso be combined; have been proposed to alleviate this information overload problem.Results categorization for biomedical databases is the focus of this work. A natural way toorganize biomedical citations is according to their MeSH annotations; a comprehensiveconcept hierarchy used by PubMed. In this paper; we present the BioNav system; a novelsearch interface that enables the user to navigate large number of query results byorganizing them using the MeSH concept hierarchy. First; the query results are organizedinto a navigation tree. Previous works expand the hierarchy in a predefined static manner. Incontrast; BioNav uses an intuitive navigation cost model to decide what concepts to …,Data Engineering; 2009. ICDE'09. IEEE 25th International Conference on,2009,17
Pharmaceutical drugs chatter on online social networks,Matthew T Wiley; Canghong Jin; Vagelis Hristidis; Kevin M Esterling,Abstract The ubiquity of Online Social Networks (OSNs) is creating new sources forhealthcare information; particularly in the context of pharmaceutical drugs. We aimed toexamine the impact of a given OSN's characteristics on the content of pharmaceutical drugdiscussions from that OSN. We compared the effect of four distinguishing characteristicsfrom ten different OSNs on the content of their pharmaceutical drug discussions:(1) Generalversus Health OSN;(2) OSN moderation;(3) OSN registration requirements; and (4) OSNswith a question and answer format. The effects of these characteristics were measured bothquantitatively and qualitatively. Our results show that an OSN's characteristics indeed affectthe content of its discussions. Based on their information needs; healthcare providers mayuse our findings to pick the right OSNs or to advise patients regarding their needs. Our …,Journal of biomedical informatics,2014,16
Information discovery across multiple streams,Vagelis Hristidis; Oscar Valdivia; Michail Vlachos; S Yu Philip,Abstract In this paper we address the issue of continuous keyword queries on multipletextual streams and explore techniques for extracting useful information from them. Thepaper represents; to our best knowledge; the first approach that performs keyword search ona multiplicity of textual streams. The scenario that we consider is quite intuitive; let's assumethat a research or financial analyst is searching for information on a topic; continuouslypolling data from multiple (and possibly heterogeneous) text streams; such as RSS feeds;blogs; etc. The topic of interest can be described with the aid of several keywords. Currentfiltering approaches would just identify single text streams containing some of the keywords.However; it would be more flexible and powerful to search across multiple streams; whichmay collectively answer the analyst's question. We present such model that takes in …,Information Sciences,2009,14
A study of the demographics of web-based health-related social media users,Shouq A Sadah; Moloud Shahbazi; Matthew T Wiley; Vagelis Hristidis,Background The rapid spread of Web-based social media in recent years has impacted howpatients share health-related information. However; little work has studied the demographicsof these users. Objective Our aim was to study the demographics of users who participate inhealth-related Web-based social outlets to identify possible links to health care disparities.Methods We analyze and compare three different types of health-related social outlets:(1)general Web-based social networks; Twitter and Google+;(2) drug review websites; and (3)health Web forums. We focus on the following demographic attributes: age; gender;ethnicity; location; and writing level. We build and evaluate domain-specific classifiers toinfer missing data where possible. The estimated demographic statistics are comparedagainst various baselines; such as Internet and social networks usage of the population …,Journal of medical Internet research,2015,13
Need and potential use of information technology for case manager–physician communication in home care,Nicole Ruggiano; Natalia Shtompel; Vagelis Hristidis; Lisa Roberts; Julie Grochowski; Ellen L Brown,Case management has become a popular model for providing home care services tonursing home-eligible older adults. To maximize collaborative decision making and patientoutcomes; members of the case management team must engage in ongoing; opencommunication. However; little is known about the quality of communication between homecare case managers and their clients' physicians. This study examined geriatric home carecase managers' perceptions of their communication with their clients' physicians.Participating case managers were employed at two large home care agencies located in theSouth Florida region. The findings suggest that communication between home care casemanagers and physicians is limited and inefficient. Implication for policy and practice areprovided. Finally; we propose ways to leverage Information Technology to bridge this …,Home Health Care Management & Practice,2012,13
SonetRank: leveraging social networks to personalize search,Abhijith Kashyap; Reza Amini; Vagelis Hristidis,Abstract Earlier works on personalized Web search focused on the click-through graphs;while recent works leverage social annotations; which are often unavailable. On the otherhand; many users are members of the social networks and subscribe to social groups.Intuitively; users in the same group may have similar relevance judgments for queriesrelated to these groups. SonetRank utilizes this observation to personalize the Web searchresults based on the aggregate relevance feedback of the users in similar groups.SonetRank builds and maintains a rich graph-based model; termed Social Aware SearchGraph; consisting of groups; users; queries and results click-through information.SonetRank's personalization scheme learns in a principled way to leverage the followingthree signals; of decreasing strength: the personal document preferences of the user; of …,Proceedings of the 21st ACM international conference on Information and knowledge management,2012,13
Determining attributes to maximize visibility of objects,Muhammed Miah; Gautam Das; Vagelis Hristidis; Heikki Mannila,In recent years; there has been significant interest in the development of ranking functionsand efficient top-k retrieval algorithms to help users in ad hoc search and retrieval indatabases (eg; buyers searching for products in a catalog). We introduce a complementaryproblem: How to guide a seller in selecting the best attributes of a new tuple (eg; a newproduct) to highlight so that it stands out in the crowd of existing competitive products and iswidely visible to the pool of potential buyers. We develop several formulations of thisproblem. Although the problems are NP-complete; we give several exact and approximationalgorithms that work well in practice. One type of exact algorithms is based on integerprogramming (IP) formulations of the problems. Another class of exact methods is based onmaximal frequent item set mining algorithms. The approximation algorithms are based on …,IEEE Transactions on Knowledge and Data Engineering,2009,13
Searching digital information and databases,*,This application describes methods for searching digital information such as digitaldocuments (eg; web pages) and computer databases; and specific search techniques suchas authority ranking and information retrieval (IR) relevance ranking in keyword searches. Insome implementations; the technique includes analyzing digital information viewed as alabeled graph; including nodes and edges; based on a flow of authority among the nodesalong the edges; the flow of authority being derived at least in part from different authoritytransfer rates assigned to the edges based on edge type schema information. In someimplementations; the system includes an object rank module configured to generate multipleinitial rankings corresponding to multiple query keywords; each of the multiple initialrankings indicating authority of nodes in a graph with respect to each respective query …,*,2014,12
Multi-Query Diversification in Microblogging Posts.,Shiwen Cheng; Anastasios Arvanitis; Marek Chrobak; Vagelis Hristidis,ABSTRACT Effectively exploring data generated by microblogging services is challengingdue to its high volume and production rate. To address this issue; we propose a solution thathelps users effectively consume information from a microblogging stream; by filtering outredundant data. We formalize our approach as a novel optimization problem termed Multi-Query Diversification Problem (MQDP). In MQDP; the input consists of a list of microbloggingposts and a set of user queries (eg news topics); where each query matches a subset ofposts. The objective is to compute the smallest subset of posts that cover all other posts withrespect to a “diversity dimension” that may represent time or; say; sentiment. Roughly; thesolution (cover) has the property that each covered post has nearby posts in the cover thatare collectively related to all queries relevant to this covered post. This is distinct from …,EDBT,2014,12
Enabling the transition to the mobile web with websieve,Michael Butkiewicz; Zhe Wu; Shunan Li; Pavithra Murali; Vagelis Hristidis; Harsha V Madhyastha; Vyas Sekar,Abstract Web access on mobile platforms already constitutes a significant (> 20%) share ofweb traffic [3]. Furthermore; this share is projected to even surpass access from laptops anddesktops [11]. In conjunction with this growth; user expectations for the performance ofmobile applications and websites is also growing rapidly [15]. Surveys show that 71% ofusers expect websites to load almost as quickly as their desktops and 33% of annoyed usersare likely to go to a competitor's site leading to loss of ad-and click-based revenue streams[1].,Proceedings of the 14th Workshop on Mobile Computing Systems and Applications,2013,12
Relevance-based retrieval on hidden-web text databases without ranking support,Vagelis Hristidis; Yuheng Hu; Panagiotis Ipeirotis,Many online or local data sources provide powerful querying mechanisms but limitedranking capabilities. For instance; PubMed allows users to submit highly expressiveBoolean keyword queries; but ranks the query results by date only. However; a user wouldtypically prefer a ranking by relevance; measured by an information retrieval (IR) rankingfunction. A naive approach would be to submit a disjunctive query with all query keywords;retrieve all the returned matching documents; and then rerank them. Unfortunately; such anoperation would be very expensive due to the large number of results returned bydisjunctive queries. In this paper; we present algorithms that return the top results for aquery; ranked according to an IR-style ranking function; while operating on top of a sourcewith a Boolean query interface with no ranking capabilities (or a ranking capability of no …,IEEE Transactions on knowledge and data engineering,2011,12
Leveraging collaborative tagging for web item design,Mahashweta Das; Gautam Das; Vagelis Hristidis,Abstract The popularity of collaborative tagging sites has created new challenges andopportunities for designers of web items; such as electronics products; travel itineraries;popular blogs; etc. An increasing number of people are turning to online reviews and user-specified tags to choose from among competing items. This creates an opportunity fordesigners to build items that are likely to attract desirable tags when published. In this paper;we consider a novel optimization problem: given a training dataset of existing items withtheir user-submitted tags; and a query set of desirable tags; design the k best new itemsexpected to attract the maximum number of desirable tags. We show that this problem is NP-Complete; even if simple Naive Bayes Classifiers are used for tag prediction. We presenttwo principled algorithms for solving this problem:(a) an exact" two-tier" algorithm (based …,Proceedings of the 17th ACM SIGKDD international conference on Knowledge discovery and data mining,2011,12
CADS: A Collaborative Adaptive Data Sharing Platform 1,Vagelis Hristidis; Eduardo Ruiz,Abstract Content management tools like Microsoft's SharePoint allow users of an applicationdomain to share documents and tag them in an ad-hoc way. Similarly; Google Base allowsusers to define attributes for their objects or choose from predefined templates. This ad-hocor predefined annotation of the shared data incurs problems like schema explosion orinadequate data annotation; which in turn lead to poor search and analysis capabilities. Wepropose CADS; a Collaborative Adaptive Data Sharing platform; where the informationdemand of the community–eg; query workload–is exploited to annotate the data at insertion-time. A key novelty of CADS is that it learns with time the most important data attributes of theapplication; and uses this knowledge to guide the data insertion and querying. In thisposition paper; we present the challenges and preliminary design ideas for building a …,*,2009,11
Beyond lazy XML parsing,Fernando Farfán; Vagelis Hristidis; Raju Rangaswami,Abstract XML has become the standard format for data representation and exchange indomains ranging from Web to desktop applications. However; wide adoption of XML ishindered by inefficient document-parsing methods. Recent work on lazy parsing is a majorstep towards alleviating this problem. However; lazy parsers must still read the entire XMLdocument in order to extract the overall document structure; due to the lack of internalnavigation pointers inside XML documents. Further; these parsers must load and parse theentire virtual document tree into memory during XML query processing. These overheadssignificantly degrade the performance of navigation operations. We have developed aframework for efficient XML parsing based on the idea of placing internal physical pointerswithin the document; which allows skipping large portions of the document during parsing …,International Conference on Database and Expert Systems Applications,2007,11
Ranked queries over sources with boolean query interfaces without ranking support,Vagelis Hristidis; Yuheng Hu; Panagiotis G Ipeirotis,Many online or local data sources provide powerful querying mechanisms but limitedranking capabilities. For instance; PubMed allows users to submit highly expressiveBoolean keyword queries; but ranks the query results by date only. However; a user wouldtypically prefer a ranking by relevance; measured by an Information Retrieval (IR) rankingfunction. The naive approach would be to submit a disjunctive query with all querykeywords; retrieve the returned documents; and then re-rank them. Unfortunately; such anoperation would be very expensive due to the large number of results returned bydisjunctive queries. In this paper we present algorithms that return the top results for a query;ranked according to an IR-style ranking function; while operating on top of a source with aBoolean query interface with no ranking capabilities (or a ranking capability of no interest …,Data Engineering (ICDE); 2010 IEEE 26th International Conference on,2010,10
Storing semi-structured data on disk drives,Medha Bhadkamkar; Fernando Farfan; Vagelis Hristidis; Raju Rangaswami,Abstract Applications that manage semi-structured data are becoming increasinglycommonplace. Current approaches for storing semi-structured data use existing storagemachinery; they either map the data to relational databases; or use a combination of flat filesand indexes. While employing these existing storage mechanisms provides readilyavailable solutions; there is a need to more closely examine their suitability to this class ofdata. Particularly; retrofitting existing solutions for semi-structured data can result in amismatch between the tree structure of the data and the access characteristics of theunderlying storage device (disk drive). This study explores various possibilities in the designspace of native storage solutions for semi-structured data by exploring alternativeapproaches that match application data access characteristics to those of the underlying …,ACM Transactions on Storage (TOS),2009,10
2LP: A double-lazy XML parser,Fernando Farfán; Vagelis Hristidis; Raju Rangaswami,Abstract XML is acknowledged as the most effective format for data encoding and exchangeover domains ranging from the World Wide Web to desktop applications. However; large-scale adoption into actual system implementations is being slowed down due to theinefficiency of its document-parsing methods. The recent development of lazy parsingtechniques is a major step towards improving this situation; but lazy parsers still have a keydrawback—they must load the entire XML document in order to extract the overall documentstructure before document parsing can be performed. We have developed a framework forefficient parsing based on the idea of placing internal physical pointers within the XMLdocument that allow the navigation process to skip large portions of the document duringparsing. We show how to generate such internal pointers in a way that optimizes parsing …,Information Systems,2009,10
User effort minimization through adaptive diversification,Mahbub Hasan; Abhijith Kashyap; Vagelis Hristidis; Vassilis Tsotras,Abstract Ambiguous queries; which are typical on search engines and recommendationsystems; often return a large number of results from multiple interpretations. Given that manyusers often perform their searches on limited size screens (eg mobile phones); an importantproblem is which results to display first. Recent work has suggested displaying a set ofresults (Top-k) based on their relevance score with respect to the query and their diversitywith respect to each other. However; previous works balance relevance and diversity mostlyby a predefined fixed way. In this paper; we show that for different search tasks there is adifferent ideal balance of relevance and diversity. We propose a principled method foradaptive diversification of query results that minimizes the user effort to find the desiredresults; by dynamically balancing the relevance and diversity at each query step (eg …,Proceedings of the 20th ACM SIGKDD international conference on Knowledge discovery and data mining,2014,9
Patentssearcher: a novel portal to search and explore patents,Vagelis Hristidis; Eduardo Ruiz; Alejandro Hernández; Fernando Farfán; Ramakrishna Varadarajan,Abstract There is an abundance of systems today to search for relevant patents; rangingfrom free ones like Google Patents (google. com/patents) to subscription ones like Delphion(delphion. com). After studying many existing systems; we found that they all apply general-purpose Information Retrieval (IR) techniques to rank patents. We argue that the quality ofsearch can be significantly improved by exploiting the domain semantics: eg; patents areorganized into classes and subclasses; and have links to external publication and to otherpatents. Also patents' text is organized into various sections and uses specific legal wording.,Proceedings of the 3rd international workshop on Patent information retrieval,2010,9
Scalable Link-based Personalization for Ranking in Entity-Relationship Graphs.,Vagelis Hristidis; Louiqa Raschid; Yao Wu,ABSTRACT Authority flow techniques like PageRank and ObjectRank can providepersonalized ranking of typed entity-relationship graphs. There are two main ways topersonalize authority flow ranking: Nodebased personalization; where authority originatesfrom a set of userspecific nodes; Edge-based personalization; where the importance ofdifferent edge types is user-specific. We propose for the first time an approach to achieveefficient edge-based personization using a combination of precomputation and runtimealgorithms. In particular; we apply our method to the personalized authority flow bounds ofObjectRank; ie; a weight assignment vector (WAV) assigns different weights to each edgetype or relationship type. Our approach includes a repository of rankings for various WAVs.We consider the following two classes of approximation:(a) SchemaApprox is formulated …,WebDB,2011,8
Efficient Filtering on Hidden Document Streams.,Eduardo J Ruiz; Vagelis Hristidis; Panagiotis G Ipeirotis,Abstract Many online services like Twitter and GNIP offer streaming programming interfacesthat allow real-time information filtering based on keyword or other conditions. However; allthese services specify strict access constraints; or charge a cost based on the usage. Werefer to such streams as “hidden streams” to draw a parallel to the well-studied hidden Web;which similarly restricts access to the contents of a database through a querying interface. Atthe same time; the users' interest is often captured by complex classification models that;implicitly or explicitly; specify hundreds of keyword-based rules; along with the rules'accuracies. In this paper; we study how to best utilize a constrained streaming accessinterface to maximize the number of retrieved relevant items; with respect to a classifier;expressed as a set of rules. We consider two problem variants. The static version …,ICWSM,2014,7
A system for keyword search on textual streams,Vagelis Hristidis; Oscar Valdivia; Michail Vlachos; Philip S Yu,Abstract An increasing amount of data is produced in the form of text streams–these can beRSS news feeds; TV closed captions; emails; etc. We study the problem of answeringkeyword queries on multiple textual streams. We define the result of a keyword queryinspired by previous work on keyword search on static databases. A result to a query is acombination of streams “sufficiently correlated” to each other that collectively contain allquery keywords within a specified time span. On the algorithmic side; in this paper we focuson the component of continuously monitoring the streams and outputting results as soon asthey are available.,*,2007,7
Demographic-based content analysis of web-based health-related social media,Shouq A Sadah; Moloud Shahbazi; Matthew T Wiley; Vagelis Hristidis,Background An increasing number of patients from diverse demographic groups share andsearch for health-related information on Web-based social media. However; little is knownabout the content of the posted information with respect to the users' demographics.Objective The aims of this study were to analyze the content of Web-based health-relatedsocial media based on users' demographics to identify which health topics are discussed inwhich social media by which demographic groups and to help guide educational andresearch activities. Methods We analyze 3 different types of health-related social media:(1)general Web-based social networks Twitter and Google+;(2) drug review websites; and (3)health Web forums; with a total of about 6 million users and 20 million posts. We analyzedthe content of these posts based on the demographic group of their authors; in terms of …,Journal of medical Internet research,2016,6
An access cost-aware approach for object retrieval over multiple sources,Benjamin Arai; Gautam Das; Dimitrios Gunopulos; Vagelis Hristidis; Nick Koudas,Abstract Source and object selection and retrieval from large multi-source data sets arefundamental operations in many applications. In this paper; we initiate research on efficientsource (eg; database) and object selection algorithms on large multi-source data sets.Specifically; in order to acquire a specified number of satisfying objects with minimum costover multiple databases; the query engine needs to determine the access overhead forindividual data sources; the overhead of retrieving objects from each source; and possiblyother statistics such as estimating the frequency of finding a satisfying object in order todetermine how many objects to retrieve from each data source. We adopt a probabilisticapproach to source selection utilizing a cost structure and a dynamic programming model forcomputing the optimal number of objects to retrieve from each data source. Such a …,Proceedings of the VLDB Endowment,2010,6
Extracting k most important groups from data efficiently,Man Lung Yiu; Nikos Mamoulis; Vagelis Hristidis,Abstract We study an important data analysis operator; which extracts the k most importantgroups from data (ie; the k groups with the highest aggregate values). In a data warehousingcontext; an example of the above query is “find the 10 combinations of product-type andmonth with the largest sum of sales”. The problem is challenging as the potential number ofgroups can be much larger than the memory capacity. We propose on-demand methods forefficient top-k groups processing; under limited memory size. In particular; we design top-kgroups retrieval techniques for three representative scenarios as follows. For the scenariowith data physically ordered by measure; we propose the write-optimized multi-pass sortedaccess algorithm (WMSA); that exploits available memory for efficient top-k groupscomputation. Regarding the scenario with unordered data; we develop the recursive hash …,Data & Knowledge Engineering,2008,6
STAR: A System for Tuple and Attribute Ranking of Query Answers.,Nishant Kapoor; Gautam Das; Vagelis Hristidis; S Sudarshan; Gerhard Weikum,Abstract In recent years there has been a great deal of interest in developing effectivetechniques for ad-hoc search and retrieval in structured repositories such as relationaldatabases-eg; searching online databases of homes; used cars; and electronic goods. Inmany of these applications; the user often experiences “information overload”; which occurswhen the system responds to an under-specified user query by returning an overwhelmingnumber of tuples; each displayed with a huge number of features (or attributes). We havedeveloped a search and retrieval system that tackles this information overload problem fromtwo angles. First; we show how to automatically rank and display the top-n most relevanttuples. Second; our system offers techniques for ordering the attributes of the returned tuplesin decreasing order of “usefulness” and selects only a few of the most useful attributes to …,ICDE,2007,6
Aggregate estimation over a microblog platform,Saravanan Thirumuruganathan; Nan Zhang; Vagelis Hristidis; Gautam Das,Abstract Microblogging platforms such as Twitter have experienced a phenomenal growth ofpopularity in recent years; making them attractive platforms for research in diverse fieldsfrom computer science to sociology. However; most microblogging platforms impose strictaccess restrictions (eg; API rate limits) that prevent scientists with limited resources-eg; whocannot afford microblog-data-access subscriptions offered by GNIP et al.-to leverage thewealth of microblogs for analytics. For example; Twitter allows only 180 queries per 15minutes; and its search API only returns tweets posted within the last week. In this paper; weconsider a novel problem of estimating aggregate queries over microblogs; eg;" how manyusers mentioned the word'privacy'in 2013?". We propose novel solutions exploiting the user-timeline information that is publicly available in most microblogging platforms. Theoretical …,Proceedings of the 2014 ACM SIGMOD international conference on Management of data,2014,5
Efficient ranking on entity graphs with personalized relationships,Vagelis Hristidis; Yao Wu; Louiqa Raschid,Authority flow techniques like PageRank and ObjectRank can provide personalized rankingof typed entity-relationship graphs. There are two main ways to personalize authority flowranking: Node-based personalization; where authority originates from a set of user-specificnodes; edge-based personalization; where the importance of different edge types is user-specific. We propose the first approach to achieve efficient edge-based personalizationusing a combination of precomputation and runtime algorithms. In particular; we apply ourmethod to ObjectRank; where a personalized weight assignment vector (WAV) assignsdifferent weights to each edge type or relationship type. Our approach includes a repositoryof rankings for various WAVs. We consider the following two classes of approximation:(a)SchemaApprox is formulated as a distance minimization problem at the schema level;(b) …,IEEE Transactions on knowledge and data engineering,2014,5
Information discovery on electronic health records using authority flow techniques,Vagelis Hristidis; Ramakrishna R Varadarajan; Paul Biondich; Michael Weiner,As the use of electronic health records (EHRs) becomes more widespread; so does theneed to search and provide effective information discovery within them. Querying bykeyword has emerged as one of the most effective paradigms for searching. Most work inthis area is based on traditional Information Retrieval (IR) techniques; where each documentis compared individually against the query. We compare the effectiveness of twofundamentally different techniques for keyword search of EHRs. We built two rankingsystems. The traditional BM25 system exploits the EHRs' content without regard toassociation among entities within. The Clinical ObjectRank (CO) system exploits the entities'associations in EHRs using an authority-flow algorithm to discover the most relevant entities.BM25 and CO were deployed on an EHR dataset of the cardiovascular division of Miami …,BMC medical informatics and decision making,2010,5
Ontology-aware search on xml-based electronic medical records,Fernando Farfán; Vagelis Hristidis; Anand Ranganathan; Redmond P Burke,As the use of Electronic Medical Records (EMRs) becomes more widespread; so does theneed for effective information discovery on them. Recently proposed EMR standards areXML-based; having as a key characteristic the frequent use of ontological references; ie;ontological concept codes appear as XML elements and are used to associate portions ofthe EMR document with concepts defined in a domain ontology. In this paper we present theXOntoRank system which tackles the problem of ontology-aware keyword search on XMLdocuments with a particular focus on EMR XML documents. Our running examples andexperiments use the Health Level Seven (HL7) Clinical Document Architecture (CDA)Release 2.0 standard of EMR representation and the Systematized Nomenclature of Humanand Veterinary Medicine (SNOMED) ontology; although the presented techniques and …,Data Engineering; 2008. ICDE 2008. IEEE 24th International Conference on,2008,5
Information discovery on electronic medical records,Vagelis Hristidis; Fernando Farfán; Redmond P Burke; Anthony F Rossi; Jeffrey A White,Abstract As the use of Electronic Medical Records (EMRs) becomes more widespread; sodoes the need to search and provide effective information discovery on them. Informationdiscovery methods will allow practitioners and other healthcare stakeholders to locaterelevant pieces of information in the growing corpus of available EMRs. The success of Websearch engines has shown that,National Science Foundation Symposium on Next Generation of Data Mining and Cyber-Enabled Discovery for Innovation,2007,5
Searching the web using composed pages,Ramakrishna Varadarajan; Vagelis Hristidis; Tao Li,Given a user keyword query; current Web search engines return a list of pages ranked by their“goodness” with respect to the query. However; this technique misses results whose contentsare distributed across multiple physical pages and are connected via hyperlinks and frames[3]. That is; it is often the case that no single page contains all query keywords. Li et al. [3] makea first step towards this problem by returning a tree of hyperlinked pages that collectively containall query keywords. The limitation of this approach is that it operates at the page-levelgranularity; which ignores the specific context where the keywords are found within thepages. More importantly; it is cumbersome for the user to locate the most desirable tree of pagesdue to the amount of data in each page tree and a large number of page trees. We propose atechnique called composed pages that given a keyword query; generates new pages …,Proceedings of the 29th annual international ACM SIGIR conference on Research and development in information retrieval,2006,5
A unified architectural model for on-demand user-centric communications,Yi Deng; S Masoud Sadjadi; Peter Clarke; Chi Zhang; Vagelis Hristidis; Raju Rangaswami; Nagarajan Prabakar,Abstract: The rapid growth of networking technologies has drastically changed the way wecommunicate and enabled a wide range of communication applications. However; theseapplications have been conceived; designed; and developed separately with little or noconnection to each other; resulting in a fragmented and incompatible set of technologiesand products. Building new communication applications requires a lengthy and costlydevelopment cycle; which severely limits the pace of innovation. Current applications arealso typically incapable of responding to changes in user communication needs as well aschanging network infrastructure and device technology. In this article; we address theseissues and present the Unified Communication Model (UCM); a new and user-centricapproach for conceiving; generating; and delivering communication applications on …,*,2005,5
Query hidden attributes in social networks,Azade Nazi; Saravanan Thirumuruganathan; Vagelis Hristidis; Nan Zhang; Khaled Shaban; Gautam Das,Microblogs and collaborative content sites such as Twitter and Amazon are popular amongmillions of users who generate huge numbers of tweets; posts; and reviews every day.Despite their popularity; these sites only provide rudimentary mechanisms to navigate theirsites; programmatically or through a browser; like a keyword search interface or a get-neighbors (eg; Friends) interface. Many interesting queries cannot be directly answered byany of these interfaces; eg; Find Twitter users in Los Angeles that have tweeted the word"diabetes" in the last year. Note that the Twitter programming interface does not allowconditions on the user's home location. In this paper; we introduce the novel problem ofquerying hidden attributes in micro blogs and collaborative content sites by leveraging theexisting search mechanisms offered by those sites. We model these data sources as …,Data Mining Workshop (ICDMW); 2014 IEEE International Conference on,2014,4
Templated search over relational databases,Anastasios Zouzias; Michail Vlachos; Vagelis Hristidis,Abstract Businesses and large organizations accumulate increasingly large amounts ofcustomer interaction data. Analysis of such data holds great importance for tasks such asstrategic planning and orchestration of sales/marketing campaigns. However; discovery andanalysis over heterogeneous enterprise data can be challenging. Primary reasons for thisare dispersed data repositories; requirements for schema knowledge; and difficulties inusing complex user interfaces. As a solution to the above; we propose a TEmplated Searchparadigm (TES) for exploring relational data that combines the advantages of keywordsearch interfaces with the expressive power of question-answering systems. The user startstyping a few keywords and TES proposes data exploration questions in real time. A keyaspect of our approach is that the questions displayed are diverse to each other and …,Proceedings of the 23rd ACM International Conference on Conference on Information and Knowledge Management,2014,4
Adding home health care to the discussion on health information technology policy,Nicole Ruggiano; Ellen L Brown; Vagelis Hristidis; Timothy F Page,The potential for health information technology to improve the efficiency and effectiveness ofhealth care has resulted in several US policy initiatives aimed at integrating healthinformation technology into health care systems. However; home health care agencies havebeen excluded from incentive programs established through policies; raising concerns onthe extent to which health information technology may be used to improve the quality of carefor older adults with chronic illness and disabilities. This analysis examines the potentialissues stemming from this exclusion and explores potential opportunities of integratinghome health care into larger initiatives aimed at establishing health information technologysystems for meaningful use.,Home health care services quarterly,2013,4
Challenges and communities of medical informatics research,Vagelis Hristidis,Abstract This article discusses experiences and lessons learned from working on healthinformatics research as a computer scientist. In particular; I present challenges faced whenconducting research on medical informatics; and explain some of the aspects that makemedical data and systems unique. Then; I present the two broad research communitiesstudying medical informatics problems. Finally; I offer advice on how to bridge the gapbetween these communities and increase their research productivity.,Acm Sigmod Record,2013,4
Comprehension-based result snippets,Abhijith Kashyap; Vagelis Hristidis,Abstract Result snippets are used by most search interfaces to preview query results.Snippets help users quickly decide the relevance of the results; thereby reducing the overallsearch time and effort. Most work on snippets have focused on text snippets for Web pagesin Web search. However; little work has studied the problem of snippets for structured data;eg; product catalogs. Furthermore; all works have focused on the important goal of creatinginformative snippets; but have ignored the amount of user effort required to comprehend; ie;read and digest; the displayed snippets. In particular; they implicitly assume that thecomprehension effort or cost only depends on the length of the snippet; which we show isincorrect for structured data. We propose novel techniques to construct snippets of structuredheterogeneous results; which not only select the most informative attributes for each …,Proceedings of the 21st ACM international conference on Information and knowledge management,2012,4
Challenges for Information Discovery on Electronic Medical Records,Vagelis Hristidis; Fernando Farfán; R Burke; A Rossi; J White,ABSTRACT As the use of Electronic Medical Records (EMRs) becomes more widespread;so does the need to search and provide effective information discovery on them. Informationdiscovery methods will allow practitioners and other healthcare stakeholders to locaterelevant pieces of information in the growing corpus of available EMRs. The success of Websearch engines has shown that keyword queries are a useful tool for locating relevantinformation in an intuitive and effective manner. However; questions arise of the form: Whatare the semantics of keyword queries on EMRs? What is a meaningful result? What is therole of medical and clinical ontologies and dictionaries like SNOMED (SystematizedNomenclature of Human and Veterinary Medicine) in answering such queries?,Florida International University Technical Report,2007,4
Efficient native XML storage,Medha Bhadkamkar; Vagelis Hristidis; Raju Rangaswami,ABSTRACT XML has emerged as one of the popular data-representation formats forinformation storage and exchange. XML data today range from representing small files toencapsulating gigabytes of information. Large XML databases must be stored on massstorage devices for both persistence as well as costefficiency. For mass storage of datatoday; disk drives are the most cost-effective medium. Current approaches of mapping XMLdata to relational databases or simply using flat files incur a mismatch between the structureof XML data and the underlying storage device (disk drives). In this study; we investigate anew method to store XML data on disk drives that matches the characteristics of XML withthose of disk drives. In particular; we present algorithms that; given an XML document and adisk drive; decide how to store the document on the drive; in a way that will later allow …,*,2005,4
CareHeroes Web and Android™ Apps for Dementia Caregivers: A Feasibility Study,Ellen Leslie Brown; Nicole Ruggiano; Lisa Roberts; Vagelis Hristidis; Karen L Whiteman; Joana Castro; Timothy F Page,Abstract The purpose of the current feasibility study was to examine the use; utility; andareas for refinement of a newly developed web-based and Android™ application (app)(ie;CareHeroes) with multiple features to support individuals caring for loved ones withAlzheimer's disease or other forms of dementia (AD). The study was performed over an 11-week period with triads of AD caregivers; assigned home care case managers; and primarycare providers (PCP). The study involved quantitative and qualitative methodologies. ElevenAD caregivers (seven daughters; two sons; and two spouses); six case managers; and fivePCPs participated. Data demonstrate participants were mostly satisfied with the multiplefeatures and ability to access and use CareHeroes. Barriers for use include concerns abouttime constraints and not being familiar with technology. Although the study findings are …,Research in Gerontological Nursing,2016,3
Estimation of the investability of real estate properties through text analysis,Moloud Shahbazi; Joseph R Barr; Vagelis Hristidis; Nani Narayanan Srinivasan,The Multiple Listing Service; commonly known as the MLS; is the singularly most importantdatabase where real estate agents and brokers list real estate properties for sale. It iscommon that agents include textual comments pertinent to the property. Although theinformation content of comments varies; it is usually expressed in good faith and in manycases is helpful in shedding light on the overall condition and the value of the property.Therefore; it seems reasonable that semantic text analysis would be useful to evaluateproperties; or aspects thereof. As far as we're aware of; no methodology to effectively extractinsight from the MLS textual portion exists. In this paper we demonstrate how textualdescriptions may be exploited for property ranking. The proposed methodology; whichcombines supervised and unsupervised methods; identifies domain-specific concepts …,Semantic Computing (ICSC); 2016 IEEE Tenth International Conference on,2016,3
Answering Complex Queries in an Online Community Network.,Azade Nazi; Saravanan Thirumuruganathan; Vagelis Hristidis; Nan Zhang; Gautam Das,Abstract An online community network such as Twitter or amazon. com links entities (eg;users; products) with various relationships (eg; friendship; co-purchase) and make suchinformation available for access through a web interface. The web interfaces of thesenetworks often support features such as keyword search and “getneighbors”-so a visitor canquickly find entities (eg; users/products) of interest. Nonetheless; the interface is usually toorestrictive to answer complex queries such as (1) find 100 Twitter users from California withat least 100 followers who talked about ICWSM last year or (2) find 100 books with at least200 5-star reviews at amazon. com. In this paper; we introduce the novel problem ofanswering complex queries that involve nonsearchable attributes through the web interfaceof an online community network. We model such a network as a heterogeneous graph …,ICWSM,2015,3
Generating informative snippet to maximize item visibility,Mahashweta Das; Habibur Rahman; Gautam Das; Vagelis Hristidis,Abstract The widespread use and growing popularity of online collaborative content siteshas created rich resources for users to consult in order to make purchasing decisions onvarious items such as e-commerce products; restaurants; etc. Ideally; a user wants to quicklydecide whether an item is desirable; from the list of items returned as a result of her searchquery. This has created new challenges for producers/manufacturers (eg; Dell) or retailers(eg; Amazon; eBay) of such items to compose succinct summarizations of web itemdescriptions; henceforth referred to as snippets; that are likely to maximize the items' visibilityamong users. We exploit the availability of user feedback in collaborative content sites in theform of tags to identify the most important item attributes that must be highlighted in an itemsnippet. We investigate the problem of finding the top-k best snippets for an item that are …,Proceedings of the 22nd ACM international conference on Conference on information & knowledge management,2013,3
Improving care delivery using health information technology in the home care setting: Development of the Home Continuation Care Dashboard,TF Page; EL Brown; N Ruggiano,*,Ann Long Term Care,2012,3
Electronic Health Records,Fernando Farfán; Ramakrishna Varadarajan; Vagelis Hristidis,An electronic health record (EHR) is an individual patient's medical record stored in digitalformat. It can be viewed as a longitudinal report that can be generated in one or moreencounters in any care delivery setting. The EHR can contain several types of patient data;such as the patient's demographic information; clinical data such as vital signs; medicalhistory; immunizations; laboratory and radiology data; problems and progress notes;accounting and billing records; and even legal documents such as living wills and healthpowers of attorney.,Information Discovery on Electronic Health Records,2009,3
Exploring biomedical databases with BioNav,Abhijith Kashyap; Vagelis Hristidis; Michalis Petropoulos; Sotiria Tavoulari,Abstract We demonstrate the BioNav system; a novel search interface for biomedicaldatabases; such as PubMed. BioNav enables users to navigate large number of queryresults by categorizing them using MeSH; a comprehensive concept hierarchy used byPubMed. Once the query results are organized into a navigation tree; BioNav reveals only asmall subset of the concept nodes at each step; selected such that the expected usernavigation cost is minimized. In contrast; previous works expand the hierarchy in apredefined static manner; without navigation cost modeling. BioNav is available at http://db.cse. buffalo. edu/bionav.,Proceedings of the 2009 ACM SIGMOD International Conference on Management of data,2009,3
A case for self-optimizing file systems,Medha Bhadkamkar; Sam Burnett; Jason Liptak; Raju Rangaswami; Vagelis Hristidis; M Bhadkamkar; S Burnett; J Liptak; R Rangaswami; V Hristidis,Abstract Efficient file systems hold one of the keys to highperformance I/O systems. Today'sfile systems perform a static layout of file data; aiming to preserve the directory structure ofthe file system and optimizing for sequential access to entire files. In this paper; we re-examine the existing state-of-the-art in file system design and find it severely lacking in animportant aspect; application awareness. We argue that for optimal performance; filesystems must self-optimize by adapting data layout to accommodate the dynamism inapplication access patterns. We present the design and implementation of an automateddata layout reconfigurator which is at the heart of such a self-optimizing file system.Preliminary studies using file system traces indicate significant I/O performance gains whencompared to a state-of-the-art ext3 file system.,Florida; USA,2006,3
Correlating Ratings of Health Insurance Plans to Their Providers' Attributes,Prajna Shetty; Ryan Rivas; Vagelis Hristidis,Background There is a push towards quality measures in health care. As a consequence;the National Committee for Quality Assurance (NCQA) has been publishing insurance planquality measures. Objective The objective of this study was to examine the relationshipbetween insurance plan quality measures and the participating providers (doctors). MethodsWe collected and analyzed provider and insurance plan data from several online sources;including provider directories; provider referrals and awards; patient reviewing sites; andhospital rankings. The relationships between the provider attributes and the insurance planquality measures were examined. Results Our analysis yielded several findings:(1) there isa moderate Pearson correlation (r=. 376) between consumer satisfaction insurance planscores and review ratings of the member providers;(2) referral frequency and provider …,Journal of medical Internet research,2016,2
OSNI: Searching for Needles in a Haystack of Social Network Data.,Shiwen Cheng; James Fang; Vagelis Hristidis; Harsha V Madhyastha; Niluthpol Chowdhury Mithun; Dorian Perkins; Amit K Roy-Chowdhury; Moloud Shahbazi; Vassilis J Tsotras,1. INTRODUCTION The amount of user generated data increases every year; as more socialinteraction tools like Twitter; Instagram and Facebook are being created and more users usethem to share their everyday experiences. Most research on analyzing so- cial data has focusedon detecting trends and patterns such as bursty topics [11] and popular spatiotemporal paths[10]; event extraction [7]; studying how information is spread [12]; or analyzing properties of thesocial graph. In contrast; in this paper; we study how to search so- cial network data items; postsand images; based on spa- tiotemporal keyword queries. That is; we created methods to findthe right needles (social data items) in the haystack (social networks); which we refer to as investigativesearch; to contrast it to the trending queries studied by previous work. Investigative search canalso be viewed as exploring the currently untapped long tail of the distribution of top- ics …,EDBT,2016,2
Querying hidden attributes in an online community network,Azade Nazi; Saravanan Thirumuruganathan; Vagelis Hristidis; Nan Zhang; Gautam Das,An online community network such as Twitter; Yelp or amazon. com links entities (eg; Users;products) with various relationships (eg; Friendship; co-purchase; co-review) and make suchinformation available for access through a web interface. Often; these community networksact as" social sensors" in which users sense information in the real world and mention themonline. The web interfaces of these networks often support features such as keyword searchthat allow an user to quickly find entities of interest. While these interfaces are adequate forregular users; they are often too restrictive to answer complex queries such as (1) find 100Twitter users from California with at least 100 followers who talked about earthquakes lastyear or (2) find 25 restaurants in Yelp with at least 10 5-star reviews with 10 ormore'useful'points. In this paper; we investigate the problem of answering complex …,Mobile Ad Hoc and Sensor Systems (MASS); 2015 IEEE 12th International Conference on,2015,2
Efficient Concept-based Document Ranking.,Anastasios Arvanitis; Matthew T Wiley; Vagelis Hristidis,ABSTRACT Recently; there is increased interest in searching and computing the similaritybetween Electronic Medical Records (EMRs). A unique characteristic of EMRs is that theyconsist of ontological concepts derived from biomedical ontologies such as UMLS orSNOMEDCT. Medical researchers have found that it is effective to search and find similarEMRs using their concepts; and have proposed sophisticated similarity measures. However;they have not addressed the performance and scalability challenges to support searchingand computing similar EMRs using ontological concepts. In this paper; we formally definethese important problems and show that they pose unique algorithmic challenges due to thenature of the search and similarity semantics and the multi-level relationships between theconcepts. In particular; the similarity between two EMRs is a function of the minimum …,EDBT,2014,2
Efficient near-duplicate document detection using FPGAs,Xi Luo; Walid Najjar; Vagelis Hristidis,Detecting duplicate and near-duplicate documents is critical in applications like Webcrawling since it helps save document processing resources. Simhash is a state-of-artmethod to assign a bit-string fingerprint to a document; such that similar documents havesimilar fingerprints. Finding the near-duplicates in a large collection of documents consists oftwo stages:(a) compute the simhash fingerprint of each document; and (b) find pairs ofsimilar fingerprints by computing their Hamming distance. Previous work has focused onoptimizing the second stage; ie; avoiding the quadratic number of comparisons to computethe all to all Hamming distance. However; our experiments show that the total time isdominated by the first stage (the fingerprints computation); which is the focus of this paper.We propose an implementation of simhash on Field Programmable Gate Arrays (FPGAs) …,Big Data; 2013 IEEE International Conference on,2013,2
Measuring and Summarizing Movement in Microblog Postings.,Eduardo J Ruiz; Vagelis Hristidis; Carlos Castillo; Aristides Gionis,Abstract Every day; users publish hundreds of millions of microblog postings in popularsocial-networking platforms such as Twitter and Facebook. When considered inaggregation; microblog postings have been shown to exhibit temporal patterns that reflectevents of global significance. In this paper; we propose techniques to identify and quantifyspatial patterns: for instance; a hashtag that is popular in one city on a given day; maybecome popular in a different city on the next day. Detecting these patterns is challenginggiven that the data are noisy and posts are not physically moving; ie; they are not continuoustrajectories in space like vehicles. Second; we introduce a multi-granular summarizationmodel to describe the movement of a hashtag between two time periods. For interpretability;we seek representations of spatial changes that follow natural or administrative …,ICWSM,2013,2
LogRank: Summarizing Social Activity Logs.,Abhijith Kashyap; Vagelis Hristidis,ABSTRACT Online Social Networks (OSNs) allow users to create and share content (eg;posts; status updates; comments) in real-time. These activities are collected in an activitylog;(eg Facebook Wall; Google+ Stream; etc.) on the user's social network profile. With time;the activity logs of users; which record the sequences of social activities; become too longand consequently hard to view and navigate. To alleviate this cluttering; it is useful to selecta small subset of the social activities within the specified timeperiod as representative; ie; assummary; for this time-period. In this paper; we study the novel problem of social activity logsummarization. We propose LogRank; a novel and principled algorithm to select activitiesthat satisfy three desirable criteria: First; activities must be important for the user. Second;they must be diverse in terms of topic; eg; cover several of the major topics in the activity …,WebDB,2012,2
Overview of information discovery techniques on EMRs,Vagelis Hristidis,3 Overview of Information Discovery Techniques on EHRs Vagelis Hristidis COnTEnTS 3.1Introduction.................................................................................................. 41 3.1. 1 Searching............… 42 Information Discovery on Electronic HealthRecords Mining the EHRs collection to extract interesting patterns; group entities to variousclasses; or decide whether an EHR satisfies some given property. 3.1. 1 Searching The followingis an example of a user query to search the EHR collection: Find information related to“Asthma” in the collection. This type of query is very similar to the queries users are used to inWeb search engines; and are typically expressed as a list of keywords—hence called keywordqueries. Expressing search queries. In addition to keyword queries; other methods for the userto express a search query have been proposed. Ideally; the user should be able to write …,Information discovery on electronic health records,2010,2
Smartphone-based health technologies for dementia care: Opportunities; challenges; and current practices,Ellen Leslie Brown; Nicole Ruggiano; Juanjuan Li; Peter J Clarke; Emma S Kay; Vagelis Hristidis,Most of the 5.4 million people affected by Alzheimer's disease and other forms of dementia(AD) are noninstitutionalized; receiving care by unpaid family caregivers and medicallymanaged by a primary care provider (PCP). Health Information Technology has beenrecognized for its potential in improving efficiency and quality of AD care and support for ADcaregivers. Simultaneously; smartphone technologies have become an increasinglycommon way to deliver physical and behavioral health care. However; little is known abouthow smartphone technologies have been used to support AD caregiving and care. Thisarticle highlights the current need for smartphone-based interventions for AD andsystematically identified and appraised current smartphone apps targeting and available forAD caregivers. Findings indicate that individual available apps have limited functions …,Journal of Applied Gerontology,2017,1
Dualdb: An efficient lsm-based publish/subscribe storage system,Mohiuddin Abdul Qader; Vagelis Hristidis,Abstract Publish/Subscribe systems allow subscribers to monitor for events of interestgenerated by publishers. Current publish/subscribe query systems are efficient when thesubscriptions (queries) are relatively static--for instance; the set of followers in Twitter--or canfit in memory. However; an increasing number of applications in this era of Big Data andInternet of Things (IoT) are based on a highly dynamic query paradigm; where continuousqueries are in the millions and are created and expire in a rate comparable; or even higher;to that of the data (event) entries. For instance moving objects like airplanes; cars or sensorsmay continuously generate measurement data like air pressure or traffic; which areconsumed by other moving objects. In this paper we propose and compare a novelpublish/subscribe storage architecture; DualDB; based on the popular NoSQL Log …,Proceedings of the 29th International Conference on Scientific and Statistical Database Management,2017,1
Provider attributes correlation analysis to their referral frequency and awards,Matthew T Wiley; Ryan L Rivas; Vagelis Hristidis,There has been a recent growth in health provider search portals; where patients specifyfilters—such as specialty or insurance—and providers are ranked by patient ratings or otherattributes. Previous work has identified attributes associated with a provider's quality throughuser surveys. Other work supports that intuitive quality-indicating attributes are associatedwith a provider's quality. We adopt a data-driven approach to study how quality indicators ofproviders are associated with a rich set of attributes including medical school; graduationyear; procedures; fellowships; patient reviews; location; and technology usage. In this work;we only consider providers as individuals (eg; general practitioners) and not organizations(eg; hospitals). As quality indicators; we consider the referral frequency of a provider and apeer-nominated quality designation. We combined data from the Centers for Medicare …,BMC health services research,2016,1
Comparing top-k XML lists,Ramakrishna Varadarajan; Fernando Farfán; Vagelis Hristidis,Abstract Systems that produce ranked lists of results are abundant. For instance; Websearch engines return ranked lists of Web pages. There has been work on distance measurefor list permutations; like Kendall tau and Spearman's footrule; as well as extensions tohandle top-k lists; which are more common in practice. In addition to ranking whole objects(eg; Web pages); there is an increasing number of systems that provide keyword search onXML or other semistructured data; and produce ranked lists of XML sub-trees. Unfortunately;previous distance measures are not suitable for ranked lists of sub-trees since they do notaccount for the possible overlap between the returned sub-trees. That is; two sub-treesdiffering by a single node would be considered separate objects. In this paper; we presentthe first distance measures for ranked lists of sub-trees; and show under what conditions …,Information Systems,2013,1
Leveraging user query sessions to improve searching of medical literature,Shiwen Cheng; Vagelis Hristidis; Michael Weiner,Abstract Published reports about searching medical literature do not refer to leveraging thequery context; as expressed by previous queries in a session. We aimed to assess novelstrategies for context-aware searching; hypothesizing that this would be better thanbaseline. Building upon methods using term frequency-inverse document frequency; weadded extensions such as a function incorporating search results and terms of previousqueries; with higher weights for more recent queries. Among 60 medical students generatingqueries against the TREC 9 benchmark dataset; we assessed recall and mean averageprecision. For difficult queries; we achieved improvement (27%) in average precision overbaseline. Improvements in recall were also seen. Our methods outperformed baseline by4% to 14% on average. Furthermore; the effectiveness of context-aware search was …,AMIA Annual Symposium Proceedings,2013,1
Challenges in personalized authority flow based ranking of social media,Hassan Sayyadi; John Edmonds; Vagelis Hristidis; Louiqa Raschid,Abstract As the social interaction of Internet users increases; so does the need to effectivelyrank social media. We study the challenges of personalized ranking of blog posts. Websearch techniques are inadequate since social media lack many of the characteristics of theWeb such as rich document content and an extensive hyperlink graph. Further; userbehavior in social media has moved beyond keyword based search and must support userswho follow a particular blog or theme. In this research; we extend a social media dataset toexploit the associations between authors; blog posts; and categories (topics) of the posts.We then apply personalized authority flow based ranking algorithms based on the randomsurfer model. We evaluate our personalization approaches through an extensive study on arange of virtual users whose preferences are defined based on intuitive criteria. Our …,Proceedings of the 19th ACM international conference on Information and knowledge management,2010,1
Efficient Ranked Queries on Sources with Boolean Query Interfaces,Vagelis Hristidis; Yuheng Hu; Panagiotis G Ipeirotis,Abstract—Many online or local data sources provide powerful querying mechanisms butlimited ranking capabilities. For instance; PubMed allows users to submit highly expressiveBoolean keyword queries; but ranks the query results by date only. However; a user wouldtypically prefer a ranking by relevance; measured by an Information Retrieval (IR) rankingfunction. The naive approach would be to submit a disjunctive query with all querykeywords; retrieve the returned documents; and then re-rank them. Unfortunately; such anoperation would be very expensive due to the large number of results returned bydisjunctive queries. In this paper we present algorithms that return the top results for a query;ranked according to an IR-style ranking function; while operating on top of a source with aBoolean query interface with no ranking capabilities (or a ranking capability of no interest …,NYU/CeDER Working Paper CeDER-09,2009,1
Merging results from multi-parametric ranked queries,Vagelis Hristidis; Yannis Papakonstantinou,Abstract Many Web sources rank objects according to multiple attributes. As the number ofsuch sources increases; so does the number of meta-brokers; which provide integratedaccess to the sources. Metabrokers answer to user queries by accessing the sources andmerging the source responses. We study the fundamental problem of how a metabroker candeliver a prefix of the user query result (ie; the top results of the user query) by accessingonly a minimum prefix of the result of each source. The challenge is that the sources supportdifferent ranking functions from each other and from the ranking that the user query requests.We present an algorithm that inputs the query ranking function and the ranking functions ofthe sources and computes the minimum prefix required by each source in order to deliver aprefix of the query result. We consider ranking functions that are either linear functions of …,*,2001,1
Efficient Native Storage Systems for Semi-structured Data,Medha Bhadkamkar; Fernando Farfan; Vagelis Hristidis; Raju Rangaswami,Abstract Semi-structured data is becoming commonplace with examples such as XML;Bioinformatics suffix-trees; scientific computing data; and even generic directory-filehierarchies. Such semi-structured data must be stored on mass storage devices forpersistence as well as cost-efficiency. Current approaches; which map semi-structured datato relational databases or simply use flat files; incur a mismatch between the structure of thedata and the underlying storage device (disk drive). In this paper; we explore alternatenative strategies for storing semi-structured data that match its access characteristics tothose of disk drives; using XML data as a concrete case study. In particular; we presentalgorithms that; given semi-structured data and a disk drive; decide how to store the data onthe drive in a way that will later allow efficient navigation and retrieval. We evaluate our …,*,*,1
A BAD demonstration: towards big active data,Steven Jacobs; Md Yusuf Sarwar Uddin; Michael Carey; Vagelis Hristidis; Vassilis J Tsotras; N Venkatasubramanian,Abstract Nearly all of today's Big Data systems are passive in nature. We demonstrate ourBig Active Data (" BAD") system; a scalable system that continuously and reliably capturesBig Data and facilitates the timely and automatic delivery of new information to a largepopulation of interested users as well as supporting analyses of historical information. Webuilt our BAD project by extending an existing scalable; open-source BDMS (AsterixDB [1])in this active direction. In this demonstration; we allow our audience to participate in anemergency notification application built on top of our BAD platform; and highlight itscapabilities.,Proceedings of the VLDB Endowment,2017,*
HEALTH INFORMATION TECHNOLOGY FOR RURAL CAREGIVERS: INTERSECTING SCIENCE; POLICY AND PRACTICE,N Ruggiano; E Brown; P Clarke; L Roberts; V Hristidis,Abstract More than 5.4 million people in the US are affected by Alzheimer's disease andother dementias (AD); most of whom receive care and support from family caregivers andare medically managed by their primary care provider (PCP). However; there are a numberof barriers to providing care to those with AD: PCPs report difficulty in communicating withAD patients; their caregivers; and their in-home providers; in addition; caregivers experiencecompromised health and psychiatric and physical consequences to the burden associatedwith caregiving. AD caregivers in rural settings experience additional unique challenges;given local limitations in services; significant distance of services; and limited availability ofinformation regarding AD and available services. To address these issues; a multi-disciplinary team; along with community partners; has developed CareHeroes; a bilingual …,Innovation in Aging,2017,*
Efficient Computation of Top-k Frequent Terms over Spatio-temporal Ranges,Pritom Ahmed; Mahbub Hasan; Abhijith Kashyap; Vagelis Hristidis; Vassilis J Tsotras,Abstract The wide availability of tracking devices has drastically increased the role ofgeolocation in social networks; resulting in new commercial applications; for example;marketers can identify current trending topics within a region of interest and focus theirproducts accordingly. In this paper we study a basic analytics query on geotagged data;namely: given a spatiotemporal region; find the most frequent terms among the social postsin that region. While there has been prior work on keyword search on spatial data (find theobjects nearest to the query point that contain the query keywords); and on group keywordsearch on spatial data (retrieving groups of objects); our problem is different in that it returnskeywords and aggregated frequencies as output; instead of having the keyword as input.Moreover; we differ from works addressing the streamed version of this query in that we …,Proceedings of the 2017 ACM International Conference on Management of Data,2017,*
Using Online Social Network Data to Investigate Pain Experiences,Robert C Wright; Ryan Rivas; Vagelis Hristidis; Megan L Robbins,*,PSYCHOSOMATIC MEDICINE,2017,*
IRanker: Query-Specific Ranking of Reviewed Items,Moloud Shahbazi; Matthew Wiley; Vagelis Hristidis,Item (eg; product) reviews are one of the most popular types of user-generated content inWeb 2.0. Reviews have been effectively used in collaborative filtering to recommendproducts to users based on similar users; and also to compute a product's star rating.However; little work has studied how reviews can be used to perform query-specific rankingof items. In this paper; we present efficient top-k algorithms to rank items; by weighing eachreview's rating by its relevance to the user query. We propose a non-random accessalgorithm and perform a comprehensive evaluation of our method on multiple datasets. Weshow that our solution significantly outperforms the baseline approach in terms of queryresponse time.,Data Engineering (ICDE); 2017 IEEE 33rd International Conference on,2017,*
Ontology-and Sentiment-aware Review Summarization,Nhat XT Le; Vagelis Hristidisy; Neal Young,In this Web 2.0 era; there is an ever increasing number of product or service reviews; whichmust be summarized to help consumers effortlessly make informed decisions. Previous workon reviews summarization has simplified the problem by assuming that features (eg;"display") are independent of each other and that the opinion for each feature in a review isBoolean: positive or negative. However; in reality features may be interrelated–eg;" display"and" display color"–and the sentiment takes values in a continuous range–eg; somewhat vsvery positive. We present a novel review summarization framework that advances the state-of-the-art by leveraging a domain hierarchy of concepts to handle the semantic overlapamong the features; and by accounting for different sentiment levels. We show that theproblem is NP-hard and present bounded approximate algorithms to compute the most …,Data Engineering (ICDE); 2017 IEEE 33rd International Conference on,2017,*
EXPANDING HEALTH INFORMATION TECHNOLOGY TO SUPPORT HISPANIC CAREGIVERS AND IMPROVE DEMENTIA CARE,N Ruggiano; E Brown; L Roberts; V Hristidis; P Clarke,*,GERONTOLOGIST,2016,*
Slowing the Firehose: Multi-Dimensional Diversity on Social Post Streams.,Shiwen Cheng; Marek Chrobak; Vagelis Hristidis,ABSTRACT Web 2.0 users conveniently consume content through subscribing to contentgenerators such as Twitter users or news agencies. However; given the number ofsubscriptions and the rate of the subscription streams; users suffer from the informationoverload problem. To address this issue; we propose a novel and flexible diversificationparadigm to prune redundant posts from a collection of streams. A key novelty of ourdiversification model is that it holistically incorporates three important dimensions of socialposts; namely content; time and author. We show how different applications; such asmicroblogging; news or bibliographic services; require different settings for these threedimensions. Further; each dimension poses unique performance challenges towardsscaling the diversification model for many users and many high-throughput streams. We …,EDBT,2016,*
Top-K Product Design Based on Collaborative Tagging Data,Mahashweta Das; Gautam Das; Vagelis Hristidis,Abstract: The widespread use and popularity of collaborative content sites (eg; IMDB;Amazon; Yelp; etc.) has created rich resources for users to consult in order to makepurchasing decisions on various products such as movies; e-commerce products;restaurants; etc. Products with desirable tags (eg; modern; reliable; etc.) have higherchances of being selected by prospective customers. This creates an opportunity for productdesigners to design better products that are likely to attract desirable tags when published.In this paper; we investigate how to mine collaborative tagging data to decide the attributevalues of new products and to return the top-k products that are likely to attract the maximumnumber of desirable tags when published. Given a training set of existing products with theirfeatures and user-submitted tags; we first build a Naive Bayes Classifier for each tag. We …,arXiv preprint arXiv:1304.0419,2013,*
Survey of data management and analysis in disaster situations-Fd: 160,Vagelis Hristidis; Shu-Ching Chen; Tao Li; Steven Luis; Yi Deng,*,Operations Research Management Science,2011,*
Using Proximity Search to Estimate Authority Flow,Vagelis Hristidis; Yannis Papakonstantinou; Ramakrishna Varadarajan,Authority flow and proximity search have been used extensively in measuring theassociation between entities in data graphs; ranging from the web to relational and XMLdatabases. These two ranking factors have been used and studied separately in the past. Inaddition to their semantic differences; a key advantage of proximity search is the existence ofefficient execution algorithms. In contrast; due to the complexity of calculating the authorityflow; current systems only use precomputed authority flows in runtime. This limitationprohibits authority flow to be used more effectively as a ranking factor. In this paper; wepresent a comparative analysis of the two ranking factors. We present an efficientapproximation of authority flow based on proximity search. We analytically estimate theapproximation error and how this affects the ranking of the results of a query.,IEEE Transactions on Knowledge and Data Engineering,2010,*
Searching Electronic Health Records,Ramakrishna Varadarajan; Vagelis Hristidis; Fernando Farfán; Redmond Burke,The National Health Information Network and its data-sharing building blocks; RegionalHealth Information Organizations; are encouraging the widespread adoption of electronichealth records (EHR) for all hospitals within the next 5 years. To date; there has been little orno effort to define methods or approaches to rapidly search such documents and returnmeaningful results. As the use of EHRs becomes more widespread; so does the need tosearch and provide effective information discovery on them. Information discovery methodswill allow practitioners and other healthcare stakeholders to locate relevant pieces ofinformation in the growing corpus of available EHRs. Before going into the details andspecific challenges of searching EHRs; we provide an overview on searching documents;which is the focus of the Computer Science discipline of information retrieval (IR). In …,Information Discovery on Electronic Health Records,2009,*
Overview of XML,Fernando Farfán; Vagelis Hristidis,XML; which stands for Extensible Markup Language; is a general purpose language thatallows the creation of other new languages to be used in several domains. It is flexible;simple; and designed to meet the challenges of large-scale electronic publishing; facilitatingthe exchange of data among heterogeneous computer systems (particularly over theInternet); while maintaining the capability of being human-readable. XML uses acombination of notes and special symbols (called “markup”) to express information about thedata itself. These markups are basically strings of characters called tags; which are puttogether to delimit the main portions of data; called elements. XML is extensible because itlets users to define their own tags; element types; and overall document structure. Thisextensibility has allowed the development of many application languages for a large …,Information Discovery on Electronic Health Records,2009,*
Aggregate Surfer: Scaling Personalized Search in Entity-Relation Graphs,Yao Wu; Vagelis Hristidis; Louiqa Raschid,ABSTRACT Modern search engines improve the quality of search results usingpersonalized rankings. Google's PageRank authority flow algorithm has been tailored inprevious work with two personalization approaches. One approach uses a “base set” of userspecified pages and has been well studied. An alternative approach personalizes linkimportance by allowing a user to modify the weight assignment of links of some type and thisremains an open problem. The problem arises both in the context of the Web as well asother databases with association links between their entities; eg; biological or bibliographicdatabases. For instance; a biologist may assign a higher weight for the publication-to-genelink in PubMed compared to a clinical practitioner. Executing authority flow searchalgorithms at query time is very expensive. Similarly; so is the precomputation and …,*,2009,*
of Proceedings: Proceedings 2004 VLDB Conference: The 30th International Conference on Very Large Databases (VLDB),Martin Theobald; Gerhard Weikum; Ralf Schenkel,Abstract/Description: Top-k queries based on ranking elements of multidimensional datasetsare a fundamental building block for many kinds of information discovery. The best knowngeneral-purpose algo-rithm for evaluating top-k queries is Fagin's threshold algorithm (TA).Since the user's goal behind top-k queries is to identify one or a few relevant and novel dataitems; it is intriguing to use approximative variants of TA to reduce run-time costs. This paperintroduces a family of approximative top-k algorithms based on probabilistic arguments.When scanning index lists of the underlying multidimensional data space in descendingorder of local scores; various forms of convolution and derived bounds are employed topredict when it is safe; with high probability; to drop candidate items and to prune the indexscans. The precision and the efficiency of the developed methods are experimentally …,*,2004,*
In our earlier work; we proposed an architecture for a Web-based video database management system (VDBMS) providing an integrated support for spatiotemporal...,Christian S Jensen; Augustas Kligys; Torben Bach Pedersen; Igor Timko; Xin Zhang; Lingli Ding; Elke A Rundensteiner; Vagelis Hristidis; Yannis Papakonstantinou; Latifur Khan; Dennis McLeod; Eduard Hovy; Asaf Adi; Opher Etzion,With the recent and continuing advances in areas such as wireless communications andpositioning technologies; mobile; location-based services are becoming possible. Suchservices deliver location-dependent content to their users. More specifically; these servicesmay capture the movements and requests of their users in multidimensional databases; ie;data warehouses; and content delivery may be...,The VLDB Journal,2004,*
Keyword search in structured and semistructured databases,Vagelis Hristidis,Databases and Information Retrieval (IR) have followed distinct ways; mainly due the factthat databases used to store only rigidly structured data and handle rigidly structuredqueries; which serve the purposes of particular welldesigned applications. In contrast; IR isemployed for information discovery and primarily studies how (unstructured) documents areranked according to their relevance to an unstructured query (typically a set of keywords).However; due to the increasing availability of database data; the increasing popularity ofXML and the increasing amount of text stored in databases; it has become imperative toallow unstructured queries on structured and semistructured databases; in addition todocuments. The most popular type of unstructured query is keyword queries; whose successis proven by Web search engines.,*,2004,*
1Relevance-based Retrieval on Hidden-Web Text Databases without Ranking Support,Panos Ipeirotis; Vagelis Hristidis; Yuheng Hu; Panagiotis G Ipeirotis,CiteSeerX - Document Details (Isaac Councill; Lee Giles; Pradeep Teregowda):All in-text references underlined in blue are linked to publications onResearchGate; letting you access and read them immediately.,*,*,*
High-throughput Publish/Subscribe on top of LSM-based Storage,Mohiuddin Abdul Qader; Vagelis Hristidis,Abstract—State-of-the-art publish/subscribe systems are efficient when the subscriptions arerelatively static–for instance; the set of followers in Twitter–or can fit in memory. However;now-a-days; many Big Data and IoT based applications follow a highly dynamic queryparadigm; where both continuous queries and data entries are in the millions and can arriveand expire rapidly. In this paper we propose and compare several publish/subscribe storagearchitectures; based on the popular NoSQL Log-Structured Merge Tree (LSM) storageparadigm; to support high-throughput and highly dynamic publish/subscribe systems. Ourframework naturally supports subscriptions on both historic and future streaming data; andgenerate instant notifications. We also extend our framework to efficiently support self-joining subscriptions; where streaming pub/sub records join with past pub/sub entries …,*,*,*
Efficient Secondary Attribute Lookup in NoSQL Databases,Mohiuddin Abdul Qader; Shiwen Cheng; Abhinand Menon; Vagelis Hristidis,Abstract—NoSQL databases achieve fast write throughput and fast lookups on the primarykey. However; many applications also require queries on non-primary attributes. For that;several NoSQL databases have added support for secondary indexes. However; theseworks are fragmented as each system generally supports one type of secondary index; andmay be using different names or no name at all to refer to such indexes. Also there exists noexperimental head to head comparison or performance analysis of the various secondaryindexing techniques in terms of throughput and space; as there is no single system thatsupports all of them. In this paper; we present a taxonomy of NoSQL secondary indexes; andalso propose a natural new space-efficient secondary index; called embedded index; basedon Bloom filters. Further; we built a system; LevelDB++; on top of Google's popular open …,*,*,*
BUSINESS CONTINUITY INFORMATION NETWORK AT THE CENTER FOR INNOVATIVE INFORMATION SYSTEMS ENGINEERING,Naphtali Rishe; Steve Luis; Shu-Ching Chen; Tao Li; Vagelis Hristidis; Scott Graham; Li Zheng; Chao Shen; Liang Tang,Studies have shown that businesses risk failure if they are unable to reopen quickly after adisaster. To reduce these risks and improve communications within the business community;the Florida International University CREST Team developed the Business ContinuityInformation Network (BCIN; pronounced “bee-kin”); a web-based service ( www.bizrecovery. org) where local businesses; emergency management; and organizations thatassist businesses can gather to share critical information and support continuity effortsbefore; during and after a disaster. Available year-round as a public service; this business-to-business community network currently maps and shares critical information aboutinfrastructure conditions and recovery efforts by working with County EmergencyManagement Offices and major private infrastructure providers. BCIN localizes and tailors …,*,*,*
School of Computing and Information Sciences,Jainendra K Navlakha; Walid Akache; David Barton; Toby S Berk; Shu-Ching Chen; Peter Clarke; Timothy Downey; Xudong He; Vagelis Hristidis; Kip Irvine; Bill Kraynek; Tao Li; Christine Lisetti; Jason Liu; Patricia McDermott-Wells; Masoud Milani; Giri Narasimhan; Deng Pan; Ana Pasztor; Alex Pelin; Norman Pestaina; Niki Pissinou; Nagarajan Prabakar; Raju Rangaswami; Naphtali Rishe; S Masoud Sadjadi; Gregory Shaw; Geoffrey Smith; Joslyn Smith; Jinpeng Wei; Jill Weiss; Mark A Weiss; Zhenyu Yang; Ming Zhao; Hao Zhu,The School of Computing and Information Sciences offers two Master of Science degreesand a Doctor of Philosophy degree. The Master of Science in Computer Science degreeprovides study in state-of-the-art computer applications as well as an introduction to thetheoretical foundations of computer science. The Master of Science degree inTelecommunications and Networking is intended to provide study in state-of-the-arttelecommunications and networking technologies and management. The Doctor ofPhilosophy in Computer Science is designed to provide study in all major areas of computerscience while leading to the frontiers of knowledge in a chosen field of concentration.,*,*,*
Efficient Secondary Attribute Lookup in Key-Value Stores,Mohiuddin Abdul Qader; Shiwen Cheng; Abhinand Menon; Vagelis Hristidis,ABSTRACT NoSQL databases like key-value stores achieve fast write throughput and fastlookups on the primary key. However; many applications also require queries on non-primary attributes. For that; several NoSQL databases have added support for secondaryindexes. To our best knowledge; little work has studied how to support secondary indexingon pure key-value stores; which are a fundamental and popular category within the NoSQLdatabases range. We propose a novel lightweight secondary indexing technique on log-structure merge-tree (LSM tree)-based key-value stores; which we refer as “embeddedindex”. The embedded index; which utilizes Bloom filters; is very space-efficient; andachieves very high writethroughput rates; comparable to non-indexed key-value stores. It isembedded inside the data files; that is; no separate index table is maintained. To our best …,*,*,*
Feasibility; Efficiency; and Effectiveness of Self-Optimizing Storage Systems,Medha Bhadkamkar; Sam Burnett; Jason Liptak; Raju Rangaswami; Vagelis Hristidis,Abstract Recent work has proposed making intelligent use of data access patterns forbuilding self-optimizing storage systems. However; despite the continued increase in theCPU-I/O performance gap; such systems are far from wide adoption. We argue that the keyreason for the lack of real systems adopting this novel idea is that current studies leaveseveral key questions unanswered. We pinpoint the research and practical challenges thatmust be addressed in building effective self-optimizing storage systems. Our answers tothese questions are based on practical experience while building such a system. Ourprototype self-optimizing storage system offers performance improvement of 2.5 X-5X; whileincurring acceptable CPU and memory overheads.,*,*,*
Approximation Methods to Efficiently Compute Personalized Ranking in Entity-Relationship Graphs,Yao Wu; Vagelis Hristidis; Louiqa Raschid,*,*,*,*
