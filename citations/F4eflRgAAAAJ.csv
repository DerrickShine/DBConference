Mining email social networks,Christian Bird; Alex Gourley; Prem Devanbu; Michael Gertz; Anand Swaminathan,Abstract Communication & Co-ordination activities are central to large software projects; butare difficult to observe and study in traditional (closed-source; commercial) settings becauseof the prevalence of informal; direct communication modes. OSS projects; on the other hand;use the internet as the communication medium; and typically conduct discussions in anopen; public manner. As a result; the email archives of OSS projects provide a useful trace ofthe communication and co-ordination activities of the participants. However; there arevarious challenges that must be addressed before this data can be effectively mined. Oncethis is done; we can construct social networks of email correspondents; and begin toaddress some interesting questions. These include questions relating to participation in theemail; the social status of different types of OSS participants; the relationship of email …,Proceedings of the 2006 international workshop on Mining software repositories,2006,555
Demids: A misuse detection system for database systems,Christina Yip Chung; Michael Gertz; Karl Levitt,Abstract Despite the necessity of protecting information stored in database systems (DBS);existing security models are insufficient to prevent misuse; especially insider abuse bylegitimate users. Further; concepts for misuse detection in DBS have not been adequatelyaddressed by existing research in misuse detection. Even though there are available meansto guard the information stored in a database system against misuse; they are seldom usedby security officers because security policies of the organization are either imprecise or notknown at all. This paper presents a misuse detection system called DEMIDS which istailored to relational database systems. DEMIDS uses audit logs to derive profiles thatdescribe typical behavior of users working with the DBS. The profiles computed can be usedto detect misuse behavior; in particular insider abuse. Furthermore; the profiles can serve …,*,2000,279
Authentic third-party data publication,Premkumar Devanbu; Michael Gertz; Charles Martel; Stuart G Stubblebine,Abstract Integrity critical databases; such as financial data used in high-value decisions; arefrequently published over the Internet. Publishers of such data must satisfy the integrity;authenticity; and non-repudiation requirements of clients. Providing this protection overpublic networks is costly. This is partly because building and running secure systems ishard. In practice; large systems can not be verified to be secure and are frequentlypenetrated. The consequences of a system intrusion at the data publisher can be severe.This is further complicated by data and server replication to satisfy availability and scalabilityrequirements. We aim to reduce the trust required of the publisher of large; infrequentlyupdated databases. To do this; we separate the roles of owner and publisher. With a fewtrusted digital signatures from the owner; an untrusted publisher can use techniques …,*,2002,277
Heideltime: High quality rule-based extraction and normalization of temporal expressions,Jannik Strötgen; Michael Gertz,Abstract In this paper; we describe HeidelTime; a system for the extraction and normalizationof temporal expressions. HeidelTime is a rule-based system mainly using regularexpression patterns for the extraction of temporal expressions and knowledge resources aswell as linguistic clues for their normalization. In the TempEval-2 challenge; HeidelTimeachieved the highest F-Score (86%) for the extraction and the best results in assigning thecorrect value attribute; ie; in understanding the semantics of the temporal expressions.,Proceedings of the 5th International Workshop on Semantic Evaluation,2010,238
A general model for authenticated data structures,Charles Martel; Glen Nuckolls; Premkumar Devanbu; Michael Gertz; April Kwong; Stuart G Stubblebine,Abstract Query answers from on-line databases can easily be corrupted by hackers ormalicious database publishers. Thus it is important to provide mechanisms which allowclients to trust the results from on-line queries. Authentic publication allows untrustedpublishers to answer securely queries from clients on behalf of trusted off-line data owners.Publishers validate answers using hard-to-forge verification objects VOs); which clients cancheck efficiently. This approach provides greater scalability; by making it easy to add morepublishers; and better security; since on-line publishers do not need to be trusted. To makeauthentic publication attractive; it is important for the VOs to be small; efficient to compute;and efficient to verify. This has lead researchers to develop independently several differentschemes for efficient VO computation based on specific data structures. Our goal is to …,Algorithmica,2004,203
On the value of temporal information in information retrieval,Omar Alonso; Michael Gertz; Ricardo Baeza-Yates,Abstract Time is an important dimension of any information space and can be very useful ininformation retrieval. Current information retrieval systems and applications do not takeadvantage of all the time information available in the content of documents to provide bettersearch results and user experience. In this paper we show some of the areas that canbenefit from exploiting such temporal information.,ACM SIGIR Forum,2007,193
Flexible authentication of XML documents,Premkumar Devanbu; Michael Gertz; April Kwong; Charles Martel; Glen Nuckolls; Stuart G Stubblebine,Abstract XML is increasingly becoming the format of choice for information exchange on theInternet. As this trend grows; one can expect that documents (or collections thereof) may getquite large; and clients may wish to query for specific segments of these documents. Incritical areas such as healthcare; law and finance; integrity is essential. In such applications;clients must be assured that they are getting complete and correct answers to their queries.Existing methods for signing XML documents cannot be used to establish that an answer toa query is complete. A simple approach has a server processing queries and certifyinganswers by digitally signing them with an on-line private key; however; the server; and its on-line private key; would be vulnerable to external hacking and insider attacks. We propose anew approach to signing XML documents which allows untrusted servers to answer …,Journal of Computer Security,2004,166
Temporal information retrieval,Omar Rogelio Alonso,Abstract Time is an important dimension of any information space and can be very useful ininformation retrieval tasks such as document exploration; similarity search; and clustering.As search applications keep gathering new and diverse information sources; presentingrelevant information anchored in time becomes more important for exploration purposes.,*,2008,159
A model and framework for visualization exploration,TJ Jankun-Kelly; Kwan-Liu Ma; Michael Gertz,Visualization exploration is the process of extracting insight from data via interaction withvisual depictions of that data. Visualization exploration is more than presentation; theinteraction with both the data and its depiction is as important as the data and depictionitself. Significant visualization research has focused on the generation of visualizations (thedepiction); less effort has focused on the exploratory aspects of visualization (the process).However; without formal models of the process; visualization exploration sessions cannot befully utilized to assist users and system designers. Toward this end; we introduce the P-Setmodel of visualization exploration for describing this process and a framework toencapsulate; share; and analyze visual explorations. In addition; systems utilizing the modeland framework are more efficient as redundant exploration is avoided. Several examples …,IEEE Transactions on Visualization and Computer Graphics,2007,156
Authentic data publication over the Internet,Premkumar Devanbu; Michael Gertz; Charles Martel; Stuart G Stubblebine,Abstract Integrity critical databases; such as financial information used in high-valuedecisions; are frequently published over the Internet. Publishers of such data must satisfy theintegrity; authenticity; and non-repudiation requirements of clients. Providing this protectionover public data networks is an expensive proposition. This is; in part; due to the difficulty ofbuilding and running secure systems. In practice; large systems can not be verified to besecure and are frequently penetrated. The negative consequences of a system intrusion atthe publisher can be severe. The problem is further complicated by data and serverreplication to satisfy availability and scalability requirements.,Journal of Computer Security,2003,155
Multilingual and cross-domain temporal tagging,Jannik Strötgen; Michael Gertz,Abstract Extraction and normalization of temporal expressions from documents are importantsteps towards deep text understanding and a prerequisite for many NLP tasks such asinformation extraction; question answering; and document summarization. There aredifferent ways to express (the same) temporal information in documents. However; afteridentifying temporal expressions; they can be normalized according to some standardformat. This allows the usage of temporal information in a term-and language-independentway. In this paper; we describe the challenges of temporal tagging in different domains; givean overview of existing annotated corpora; and survey existing approaches for temporaltagging. Finally; we present our publicly available temporal tagger HeidelTime; which iseasily extensible to further languages due to its strict separation of source code and …,Language Resources and Evaluation,2013,147
Clustering and exploring search results using timeline constructions,Omar Alonso; Michael Gertz; Ricardo Baeza-Yates,Abstract Time is an important dimension of any information space and can be very useful ininformation retrieval and in particular clustering and exploration of search results. Searchresult clustering is a feature integrated in some of today's search engines; allowing users tofurther explore search results. However; only little work has been done on exploitingtemporal information embedded in documents for the presentation; clustering; andexploration of search results along well-defined timelines. In this paper; we present an add-on to traditional information retrieval applications in which we exploit various temporalinformation associated with documents to present and cluster documents along timelines.Temporal information expressed in the form of; eg; date and time tokens or temporalreferences; appear in documents as part of the textual context or metadata. Using …,Proceedings of the 18th ACM conference on Information and knowledge management,2009,144
Eventweet: Online localized event detection from twitter,Hamed Abdelhaq; Christian Sengstock; Michael Gertz,Abstract Microblogging services such as Twitter; Facebook; and Foursquare have becomemajor sources for information about real-world events. Most approaches that aim atextracting event information from such sources typically use the temporal context ofmessages. However; exploiting the location information of georeferenced messages; too; isimportant to detect localized events; such as public events or emergency situations. Usersposting messages that are close to the location of an event serve as human sensors todescribe an event. In this demonstration; we present a novel framework to detect localizedevents in real-time from a Twitter stream and to track the evolution of such events over time.For this; spatio-temporal characteristics of keywords are continuously extracted to identifymeaningful candidates for event descriptions. Then; localized event information is …,Proceedings of the VLDB Endowment,2013,139
Semantic integrity support in SQL: 1999 and commercial (object-) relational database management systems,Can Türker; Michael Gertz,Abstract The correctness of the data managed by database systems is vital to anyapplication that utilizes data for business; research; and decision-making purposes. Toguard databases against erroneous data not reflecting real-world data or business rules;semantic integrity constraints can be specified during database design. Current commercialdatabase management systems provide various means to implement mechanisms toenforce semantic integrity constraints at database run-time. In this paper; we give anoverview of the semantic integrity support in the most recent SQL-standard SQL: 1999; andwe show to what extent the different concepts and language constructs proposed in thisstandard can be found in major commercial (object-) relational database managementsystems. In addition; we discuss general design guidelines that point out how the …,The VLDB Journal—The International Journal on Very Large Data Bases,2001,123
Report on the dagstuhl seminar,Michael Gertz; M Tamer Özsu; Gunter Saake; Kai-Uwe Sattler,Over the past few years; techniques for managing; querying; and integrating data on theWeb have significantly matured. Well-founded and practical approaches to assess or evenguarantee a required degree of quality of the data in these frameworks; however; are stillmissing. This can be contributed to the lack of welldefined data quality metrics andassessment techniques; and the difficulty of handling information about data quality duringdata integration and query processing. Data quality problems arise in many settings; such asthe integration of business data; in Web mining; data dissemination; and in querying theWeb using search engines. Data quality (DQ) addresses various forms of data; includingstructured and semistructured data; text documents; multimedia; and streaming data.Different forms of metadata describing the quality of data is becoming increasingly …,ACM SIGMOD Record,2004,116
On Distributing XML Repositories.,Jan-Marco Bremer; Michael Gertz,ABSTRACT XML is increasingly used not only for data exchange but also to representarbitrary data sources as virtual XML repositories. In many application scenarios; fragmentsof such a repository are distributed over the Web. However; design and query models fordistributed XML data have not yet been studied in detail. In this paper; we introduce adistribution approach for a virtual XML repository. We present a fragmentation method andoutline an allocation model for distributed XML fragments. We also discuss an efficientrealization based on small; local index structures. The index structures encode global pathinformation and provide for an efficient; local evaluation of the most common types of globalqueries.,WebDB,2003,107
The Willow architecture: comprehensive survivability for large-scale distributed applications,John Knight; Dennis Heimbigner; Alexander L Wolf; Antonio Carzaniga; Jonathan Hill; Premkumar Devanbu; Michael Gertz,Abstract: The Willow architecture is a comprehensive approach to survivability in criticaldistributed applications. Survivability is achieved in a deployed system using a uniquecombination of (a) fault avoidance by disabling vulnerable network elements intentionallywhen a threat is detected or predicted;(b) fault elimination by replacing system softwareelements when faults are discovered; and (c) fault tolerance by reconfiguring the system ifnon-maskable damage occurs. The key to the architecture is a powerful reconfigurationmechanism that is combined with a general control structure in which network state issensed; analyzed; and required changes effected. The architecture can be used to deploysoftware functionality enhancements as well as survivability. Novel aspects include: nodeconfiguration control mechanisms; a workflow system for resolving conflicting …,*,2001,79
Reverse engineering for web data: From visual to semantic structures,Christina Yip Chung; Michael Gertz; Neel Sundaresan,Despite the advancement of XML; the majority of documents on the Web is still marked upwith HTML for visual rendering purposes only; thus building a huge amount of legacy data.In order to facilitate querying Web based data in a way more efficient and effective than justkeyword based retrieval; enriching such Web documents with both structure and semanticsis necessary. We describe a novel approach to the integration of topic specific HTMLdocuments into a repository of XML documents. In particular; we describe how topic specificHTML documents are transformed into XML documents. The proposed documenttransformation and semantic element tagging process utilizes document restructuring rulesand minimum information about the topic in the form of concepts. For the resulting XMLdocuments; a majority schema is derived that describes common structures among the …,Data Engineering; 2002. Proceedings. 18th International Conference on,2002,78
A model for the visualization exploration process,TJ Jankun-Kelly; Kwan Liu Ma; Michael Gertz,Abstract The current state of the art in visualization research places a strong emphasis ondifferent techniques to derive insight from disparate types of data. However; little work hasinvestigated the visualization process itself. The information content of the visualizationprocess---the results; history; and relationships between those results---is addressed by thiswork. A characterization of the visualization process is discussed; leading to a generalmodel of the visualization exploration process. The model; based upon a new parameterderivation calculus; can be used for automated reporting; analysis; or visualized directly. AnXML-based language for expressing visualization sessions using the model is alsodescribed. These sessions can then be shared and reused by collaborators. The model;along with the XML representation; provides an effective means to utilize the information …,Proceedings of the conference on Visualization'02,2002,75
Scientific data management: challenges; technology; and deployment,Arie Shoshani; Doron Rotem,Dealing with the volume; complexity; and diversity of data currently being generated byscientific experiments and simulations often causes scientists to waste productive time.Scientific Data Management: Challenges; Technology; and Deployment describes cutting-edge technologies and solutions for managing and analyzing vast amounts of data; helpingscientists focus on their scientific goals. The book begins with coverage of efficient storagesystems; discussing how to write and read large volumes of data without slowing thesimulation; analysis; or visualization processes. It then focuses on the efficient datamovement and management of storage spaces and explores emerging database systemsfor scientific data. The book also addresses how to best organize data for analysis purposes;how to effectively conduct searches over large datasets; how to successfully automate …,*,2009,66
XQuery/IR: Integrating XML Document and Data Retrieval.,Jan-Marco Bremer; Michael Gertz,One of the most important features of XML is to provide a unified view to all kinds ofstructured and semistructured data as well as loosely structured documents. Here; documentmeans a coherent unit of usually textual information while data stands for uninterpreted; rawcontent without a fixed context. Most content XML is applied to today is very text-rich. Thestructural aspects of the unified XML view are rigid enough to support data retrieval (DR)queries as known from database systems. Over the past few years; increasingly powerfulquery language; most notably the recent XQuery standard [2]; have exploited this fact toprovide expressive DR query capabilities for XML. On the other hand; XML's structuralaspects are transparent enough to treat arbitrary parts of the XML-represented data asdocuments. Document or information retrieval (IR) providing one of the most important …,WebDB,2002,61
Deriving integrity maintaining triggers from transition graphs,Michael Gertz; Udo W Lipeck,Methods for deriving constraint maintaining triggers from dynamic integrity constraintsrepresented by transition graphs are presented. The methods reduce integrity monitoring tochecking changing static conditions according to life cycle situations. Thus; triggers have tobe generated from these graphs; which depend not only on the operations that haveoccurred in a transaction; but also on the situations that have been reached by the objectsmentioned in the constraints. The techniques presented work for dynamic constraints andtheir corresponding transition graphs as well as for simple static constraints. Only passivereactions (rollbacks) to constraint violations are provided by the trigger patterns; but thesystematic generation of such patterns should help the database designer in identifyingpossible active reactions for repairing constraint violations.,Data Engineering; 1993. Proceedings. Ninth International Conference on,1993,57
Extraction and exploration of spatio-temporal information in documents,Jannik Strötgen; Michael Gertz; Pavel Popov,Abstract In the past couple of years; there have been significant advances in the areas oftemporal information retrieval (TIR) and geographic information retrieval (GIR); eachfocusing on extracting and utilizing temporal and geographic information; respectively; fromdocuments for search and exploration tasks. Interestingly; there is only little work thatcombines models; techniques and applications from these two areas to support scenariosand applications where temporal and geographic information in combination provideinteresting meaningful nuggets in document exploration tasks; such as visualizing achronological sequence of events with their locations. In this paper; we present an approachthat combines the two areas of TIR and GIR. Using temporal and geographic informationextracted from documents and recorded in temporal and geographic document profiles …,Proceedings of the 6th Workshop on Geographic Information Retrieval,2010,56
Exploratory search using timelines,Omar Alonso; Ricardo Baeza-Yates; Michael Gertz,ABSTRACT As search applications keep gathering new and diverse information sources;presenting relevant information anchored in time becomes more important. Temporalinformation is available in every document either explicitly; eg; in the form of temporalexpressions; or implicitly in the form of metadata. Recognizing such temporal informationand exploiting it for document retrieval and presentation purposes are important featuresthat can significantly improve the functionality of search applications. In this paper; wepresent an exploratory search interface that uses timelines to present and explore searchresults. We also describe a prototypical implementation that illustrates the main ideas of ourapproach.,SIGCHI 2007 Workshop on Exploratory Search and HCI Workshop,2007,51
Clustering of search results using temporal attributes,Omar Alonso; Michael Gertz,Abstract Clustering of search results is an important feature in many of today's informationretrieval applications. The notion of hit list clustering appears in Web search engines andenterprise search engines as a mechanism that allows users to further explore the coverageof a query. However; there has been little work on exposing temporal attributes forconstructing and presentation of clusters. These attributes appear in documents as part ofthe textual content; eg; as a date and time token or as a temporal reference in a sentence. Inthis paper; we outline a model and describe a prototype that shows the main ideas.,Proceedings of the 29th annual international ACM SIGIR conference on Research and development in information retrieval,2006,50
Effectiveness of temporal snippets,Omar Alonso; Ricardo Baeza-Yates; Michael Gertz,ABSTRACT We introduce the notion of time-centered snippets; called TSnippet; asdocument surrogates for document retrieval and exploration. We propose an alternativedocument snippet based on temporal information that can be useful for supportingexploratory search. The idea of using sentences that contain the most frequent chronons(units of time) can be used for constructing document surrogates. We conducted a series ofexperiments to evaluate this new approach using a crowdsourcing approach. Theevaluation against two Web search engines shows that our technique produces goodsnippets and users like to see time-sensitive information in search results.,WSSP Workshop at the World Wide Web Conference—WWW,2009,49
Handbook of database security: applications and trends,Michael Gertz; Sushil Jajodia,Motivation for the book Database security has been gaining a great deal of importance asindustry; military; and government organizations have increasingly adopted Internet-basedtechno-gies on a large-scale; because of convenience; ease of use; and the ability to takeadvantage of rapid advances in the commercial market. Along with the traditional securityaspects of data integrity and availability; there is an increasing interest in research anddevelopment in data privacy. This is because today's often missi-critical databases no longercontain only data used for day-to-day processing by organization; as new applications arebeing added; it is possible for organizations to collect and store vast amounts of data quicklyand ef ciently and to make the data readily accessible to the public; typically through Web-based applications. Unfor-nately; if security threats related to the integrity; availability; and …,*,2007,49
Managing data quality and integrity in federated databases,Michael Gertz,Abstract Today many organizations are facing the need to integrate multiple; previouslyindependent but semantically related information sources. Although often the quality andintegrity of the data at a single information source itself is a problem; issues and problemsregarding the quality and integrity of integrated data have been mainly neglected byapproaches to data integration. As recent studies show; this raises severe problems forglobal applications that depend on the reliability of the integrated data. In this paper wefocus on problems and possible solutions for modeling and managing data quality andintegrity of integrated data. For this; we propose a taxonomy of data quality aspects thatincludes important attributes such as timeliness and completeness of local informationsources. We use the federated database approach to describe how data quality aspects …,*,1998,45
Schema-based optimization of XPath expressions,April Kwong; Michael Gertz,CiteSeerX - Document Details (Isaac Councill; Lee Giles; Pradeep Teregowda): XPath expressionsplay a crucial role in several W3C proposals and recommendations; such as the XSLTransformation framework (XSLT) or the recently proposed XQuery language.,*,2002,44
Specifying reactive integrity control for active databases,Michael Gertz,Recent approaches to integrity enforcement in active databases suggest not only to checkconstraint violations by triggers but also to utilize triggers to perform inconsistency repairactions. However; for sophisticated reactions these approaches often require refinements ofalready derived integrity maintaining and inconsistency repairing triggers. We argue thatanalyzing and specifying reactions on constraint violations should exclusively be carried outin the conceptual design. We provide a declarative specification language for reactions onviolations with an operational semantics; suitable to express most of the designers' intendedbehavior on constraint violations. We describe a design methodology for reactionspecifications followed by a procedure to derive a set of stratified integrity enforcing triggers.,Research Issues in Data Engineering; 1994. Active Database Systems. Proceedings Fourth International Workshop on,1994,43
Temporal Tagging on Different Domains: Challenges; Strategies; and Gold Standards.,Jannik Strötgen; Michael Gertz,Abstract In the last years; temporal tagging has received increasing attention in the area ofnatural language processing. However; most of the research so far concentrated onprocessing news documents. Only recently; two temporal annotated corpora of narrative-style documents were developed; and it was shown that a domain shift results in significantchallenges for temporal tagging. Thus; a temporal tagger should be aware of the domainassociated with documents that are to be processed and apply domain-specific strategies forextracting and normalizing temporal expressions. In this paper; we analyze thecharacteristics of temporal expressions in different domains. In addition to news-andnarrative-style documents; we add two further document types; namely colloquial andscientific documents. After discussing the challenges of temporal tagging on the different …,LREC,2012,42
Annotating scientific images: A concept-based approach,Michael Gertz; K-U Sattler; Fredric Gorin; Michael Hogarth; Jim Stone,Data annotations are an important kind of metadata that occur in the form of externallyassigned descriptions of particular features in Web accessible documents. Such metadataare eventually used in data retrieval tasks on heterogeneous; possible distributed Web-accessible documents. In this paper; we present the model and realization of an annotationframework that scientists can employ to semantically enrich different types of documents;primarily scientific images made available through an image repository. Although we employontology like structures; called concepts; for metadata schemes used in annotations; ourprimary focus is on how concepts are actually used to annotate images and regions ofinterest; respectively; that exhibit features of interest to a researcher. It turns out that thecombined consideration of domain specific concepts and annotated regions in images …,Scientific and Statistical Database Management; 2002. Proceedings. 14th International Conference on,2002,42
Expertise identification and visualization from CVS,Omar Alonso; Premkumar T Devanbu; Michael Gertz,Abstract As software evolves over time; the identification of expertise becomes an importantproblem. Component ownership and team awareness of such ownership are signals of solidproject. Ownership and ownership awareness are also issues in open-source software(OSS) projects. Indeed; the membership in OSS projects is dynamic with team membersarriving and leaving. In large open source projects; specialists who know the system verywell are considered experts. How can one identify the experts in a project by mining aparticular repository like the source code? Have they gotten help from other people? Weprovide an approach using classification of the source code tree as a path to derive theexpertise of the committers. Because committers may get help from other people; we alsoretrieve their contributors. We also provide a visualization that helps to further explore the …,Proceedings of the 2008 international working conference on Mining software repositories,2008,41
An efficient XML node identification and indexing scheme,Jan-Marco Bremer; Michael Gertz,ABSTRACT Path and tree pattern queries build the core of almost all XML query languages.Current index structures that support an efficient evaluation of such queries; however; oftenhave several deficiencies in that they (a) are limited in their support of query patterns;(b)ignore data values and readily available structural summary information about the XML datasource;(c) require expensive joins for every edge in the query tree; or (d) are very spaceinefficient. Due to the nature of XML-represented data; the structural components of an XMLdata source are usually limited in depth and occurring path patterns. Based on thisobservation; we propose a novel approach to the indexing of XML data in which XML nodeidentifiers effectively encode complete rooted data paths as they occur in the data source. Incombination with an extended DataGuide; we utilize these identifiers in two indexes on …,Teach report. Department of Computer Science University of California; Davis,2003,41
The Willow survivability architecture,John Knight; Dennis Heimbigner; Alexander Wolf; Antonio Carzaniga; Jonathan Hill; Premkumar Devanbu; Michael Gertz,The Willow architecture provides a comprehensive architectural approach to the provision ofsurvivability [8] in critical information networks. It is based on the notion that survivability of anetwork requires reconfiguration at both the system and the application levels. The Willownotion of reconfiguration is very general; and the architecture provides reconfigurationmechanisms for both automatic and manual network control.,Fourth Information Survivability Workshop,2001,39
Identification of top relevant temporal expressions in documents,Jannik Strötgen; Omar Alonso; Michael Gertz,Abstract Temporal information is very common in textual documents; and thus; identifying;normalizing; and organizing temporal expressions is an important task in IR. Although thereare some tools for temporal tagging; there is a lack in research focusing on the relevance oftemporal expressions. Besides counting their frequency and verifying whether they satisfy atemporal search query; temporal expressions are often considered in isolation only. Thereare no methods to calculate the relevance of temporal expressions; neither in general norwith respect to a query. In this paper; we present an approach to identify top relevanttemporal expressions in documents using expression-; document-; corpus-; and query-based features. We present two relevance functions: one to calculate relevance scores fortemporal expressions in general; and one with respect to a search query; which consists …,Proceedings of the 2nd Temporal Web Analytics Workshop,2012,37
Heideltime: Tuning english and developing spanish resources for tempeval-3,Jannik Strötgen; Julian Zell; Michael Gertz,Abstract In this paper; we describe our participation in the TempEval-3 challenge. With ourmultilingual temporal tagger HeidelTime; we addressed task A; the extraction andnormalization of temporal expressions for English and Spanish. Exploiting HeidelTime'sstrict separation between source code and languagedependent parts; we tunedHeidelTime's existing English resources and developed new Spanish resources. For bothlanguages; we achieved the best results among all participants for task A; the combination ofextraction and normalization. Both the improved English and the new Spanish resources arepublicly available with HeidelTime.,Second Joint Conference on Lexical and Computational Semantics (* SEM); Volume 2: Proceedings of the Seventh International Workshop on Semantic Evaluation (SemEval 2013),2013,35
TimeTrails: a system for exploring spatio-temporal information in documents,Jannik Strötgen; Michael Gertz,Abstract Spatial and temporal data have become ubiquitous in many application domainssuch as the Geosciences or life sciences. Sophisticated database management systems areemployed to manage such structured data. However; an important source of spatio-temporalinformation that has not been fully utilized are unstructured text documents. In documents;combinations of temporal and spatial expressions form events; which can be mapped to adatabase structure and organized into trajectories that can be explored. In this context; thecoupling of information retrieval techniques with spatio-temporal database concepts leads tonew ways for managing and exploring document collections. In this demonstration; wepresent TimeTrails; a system for the extraction; querying; storage; and exploration of spatio-temporal information embedded in text documents. The user can query a document …,Proceedings of the VLDB Endowment,2010,34
An extensible framework for repairing constraint violations,Michael Gertz; Udo W Lipeck,Abstract In this paper we describe a new approach to repairing violations of integrityconstraints in relational databases with null values. By adopting basic concepts from model-based diagnosis; we show how simultaneous reasons for violations of (different) constraintscan be determined. These reasons; represented as sets of facts; directly indicate possiblerepair actions that guarantee to remove the observed violations. By interleaving thediagnosis of constraint violations and the execution of repair actions; we draw anenumeration schema for possible minimal repair transactions as sequences of repairactions. Each such transaction; when applied to the inconsistent database; guarantees toresult in a database consistent with all constraints. In order to enumerate possible repairtransactions; repair actions are performed hypothetically using auxiliary relations. This …,*,1997,33
Deriving optimized integrity monitoring triggers from dynamic integrity constraints,Michael Gertz; Udo W Lipeck,Abstract Modern approaches to integrity monitoring in active databases suggest the ideas ofgenerating triggers from constraints as part of database design and utilizing constraintsimplification techniques for trigger optimization. Such proposals; however; have beenrestricted to static conditions only. In this paper; we show how to derive triggers fromdynamic integrity constraints which describe properties of state sequences and which canbe specified by formulas in temporal logic. Such constraints can equivalently be transformedinto transition graphs which describe such life cycles of database objects that are admissiblewith respect to the constraints: Nodes correspond to situations in life cycles and edges givethe (changing) conditions under which a change into another situation is allowed. If objectsituations are stored; integrity monitoring triggers can be generated from transition graphs …,Data & Knowledge Engineering,1996,31
ORDEN: Outlier region detection and exploration in sensor networks,Conny Franke; Michael Gertz,Abstract Sensor networks play a central role in applications that monitor variables ingeographic areas such as the traffic volume on roads or the temperature in the environment.A key feature users are often interested in when employing such systems is the detection ofunusual phenomena; that is; anomalous values measured by the sensors. In thisdemonstration; we present a system; called ORDEN; that allows for the detection and(visual) exploration of outliers and anomalous events in sensor networks in real-time. Inparticular; the system constructs outlier regions from anomalous sensor measurements toprovide for a comprehensive description of the spatial extent of phenomena of interest. Withour system; users can interactively explore displayed outlier regions and investigate theheterogeneity within individual regions using different parameter and threshold settings …,Proceedings of the 2009 ACM SIGMOD International Conference on Management of data,2009,30
Security and privacy for geospatial data: concepts and research directions,Elisa Bertino; Bhavani Thuraisingham; Michael Gertz; Maria Luisa Damiani,Abstract Geospatial data play a key role in a wide spectrum of critical data managementapplications; such as disaster and emergency management; environmental monitoring; landand city planning; and military operations; often requiring the coordination among diverseorganizations; their data repositories; and users with different responsibilities. Although avariety of models and techniques are available to manage; access and share geospatialdata; very little attention has been paid to addressing security concerns; such as accesscontrol; security and privacy policies; and the development of secure and in particularinteroperable GIS applications. The objective of this paper is to discuss the technicalchallenges raised by the unique requirements of secure geospatial data management andto suggest a comprehensive framework for security and privacy for geospatial data and …,Proceedings of the SIGSPATIAL ACM GIS 2008 International Workshop on Security and Privacy in GIS and LBS,2008,30
Latent geographic feature extraction from social media,Christian Sengstock; Michael Gertz,Abstract In this work we present a framework for the unsupervised extraction of latentgeographic features from georeferenced social media. A geographic feature represents asemantic dimension of a location and can be seen as a sensor that measures a signal ofgeographic semantics. Our goal is to extract a small number of informative geographicfeatures from social media; to describe and explore geographic space; and for subsequentspatial analysis; eg; in market research. We propose a framework that; first; transforms theunstructured and noisy geographic information in social media into a high-dimensionalmultivariate signal of geographic semantics. Then; we use dimensionality reduction toextract latent geographic features. We conduct experiments using two large-scale Flickr datasets covering the LA area and the US. We show that dimensionality reduction techniques …,Proceedings of the 20th International Conference on Advances in Geographic Information Systems,2012,28
An event-centric model for multilingual document similarity,Jannik Strötgen; Michael Gertz; Conny Junghans,Abstract Document similarity measures play an important role in many document retrievaland exploration tasks. Over the past decades; several models and techniques have beendeveloped to determine a ranked list of documents similar to a given query document.Interestingly; the proposed approaches typically rely on extensions to the vector spacemodel and are rarely suited for multilingual corpora. In this paper; we present a noveldocument similarity measure that is based on events extracted from documents. An event issolely described by nearby occurrences of temporal and geographic expressions in adocument's text. Thus; a document is modeled as a set of events that can be compared andranked using temporal and geographic hierarchies. A key feature of our model is that it isterm-and language-independent as temporal and geographic expressions mentioned in …,Proceedings of the 34th international ACM SIGIR conference on Research and development in Information Retrieval,2011,27
A starting point strategy for nonlinear interior methods,Michael Gertz; Jorge Nocedal; A Sartenar,Abstract This paper presents a strategy for choosing the initial point; slacks; and multipliersin interior methods for nonlinear programming. It consists of first computing a Newton-likestep to estimate the magnitude of these three variables and then shifting the slacks andmultipliers so that they are sufficiently positive. The new strategy has the option of respectingthe initial estimate of the solution given by the user; and attempts to avoid the introduction ofartificial nonconvexities. Numerical experiments on a large test set illustrate the performanceof the strategy.,Applied mathematics letters,2004,25
“Temporal” Integrity Constraints in Temporal Databases,Michael Gertz; Udo W Lipeck,Abstract In this paper we consider a class of integrity constraints which describe admissiblelifecycles of database objects; and which can be specified by transition graphs. We presentan algorithmic scheme for monitoring such constraints in temporal databases whichefficiently support the concept of valid-time. The keys to efficient monitoring lie in storinglifecycle situations with respect to constraints; in utilizing the property of graphs beingiteration-invariant; and in using basic operations of temporal databases to determine validityintervals. In particular; we give hints how to extend monitoring to transactions that involveretroactive and proactive modifications.,*,1995,25
CONQUER: a system for efficient context-aware query suggestions,Christian Sengstock; Michael Gertz,Abstract Many of today's search engines provide autocompletion while the user is typing aquery string. This type of dynamic query suggestion can help users to formulate queries thatbetter represent their search intent during Web search interactions. In this paper; wedemonstrate our query suggestion system called CONQUER; which allows to efficientlysuggest queries for a given partial query and a number of available query contextobservations. The context-awareness allows for suggesting queries tailored to a givencontext; eg; the user location or the time of day. CONQUER uses a suggestion model that isbased on the combined probabilities of sequential query patterns and context observations.For this; the weight of a context in a query suggestion can be adjusted online; for example;based on the learned user behavior or user profiles. We demonstrate the functionality of …,Proceedings of the 20th international conference companion on World wide web,2011,24
Integrating document and data retrieval based on XML,Jan-Marco Bremer; Michael Gertz,Abstract For querying structured and semistructured data; data retrieval and documentretrieval are two valuable and complementary techniques that have not yet been fullyintegrated. In this paper; we introduce integrated information retrieval (IIR); an XML-basedretrieval approach that closes this gap. We introduce the syntax and semantics of anextension of the XQuery language called XQuery/IR. The extended language realizes IIRand thereby allows users to formulate new kinds of queries by nesting ranked documentretrieval and precise data retrieval queries. Furthermore; we detail index structures andefficient query processing approaches for implementing XQuery/IR. Based on a newidentification scheme for nodes in node-labeled tree structures; the extended indexstructures require only a fraction of the space of comparable index structures that only …,The VLDB Journal—The International Journal on Very Large Data Bases,2006,24
A baseline temporal tagger for all languages,Jannik Strötgen; Michael Gertz,Abstract Temporal taggers are usually developed for a certain language. Besides English;only few languages have been addressed; and only the temporal tagger HeidelTime coversseveral languages. While this tool was manually extended to these languages; there havebeen earlier approaches for automatic extensions to a single target language. In this paper;we present an approach to extend HeidelTime to all languages in the world. Our evaluationshows promising results; in particular considering that our approach neither requireslanguage skills nor training data; but results in a baseline tagger for 200+ languages.,Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing,2015,22
Security for automated; distributed configuration management,Premkumar Devanbu; Michael Gertz; Stuart Stubblebine,Abstract Installation; configuration; and administration of desktop software is a non-trivialprocess. Even a simple application can have numerous dependencies on hardware; devicedrivers; operating system versions; dynamically linked libraries; and even on otherapplications. These dependencies can cause surprising failures during the normal processof installations; updates and re-configurations. Diagnosing and resolving such failuresinvolves detailed knowledge of the hardware and software installed in the machine;configuration manifests of particular applications; version incompatibilities; etc. This isusually too hard for end-users; and even for technical support personnel; specially in smallbusinesses. It may be necessary to involve software vendors and outside consultants orlaboratories. Employees working on sensitive; proprietary projects may even have to …,ICSE Workshop on Software Engineering over the Internet,1999,21
Data Integration Techniques based on Data Quality Aspects.,Michael Gertz; Ingo Schmitt,Abstract In multidatabase systems; a major data integration problem is to resolve data conicts where two objects having the same de nition and representing the same real worldobject have different extensions. Traditional data integration approaches suggest static conict resolution functions that perform a computation over conicting attribute values; thusassuming a unique and time-independent resolution. In this paper; we argue that such typeof data con ict often arises due to heterogeneities among the data capturing and processingtechniques and methods used by component databases. That is; component database differin how and when they map real world data into local data structures. This diversity results inthe fact that the quality of the data stored at different sites can be different and that the qualitycan also vary over time; thus requiring dynamic data integration methods; depending on …,Föderierte Datenbanken,1998,21
Using type qualifiers to analyze untrusted integers and detecting security flaws in C programs,Ebrima N Ceesay; Jingmin Zhou; Michael Gertz; Karl Levitt; Matt Bishop,Abstract Incomplete or improper input validation is one of the major sources of security bugsin programs. While traditional approaches often focus on detecting string related bufferoverflow vulnerabilities; we present an approach to automatically detect potential integermisuse; such as integer overflows in C programs. Our tool is based on CQual; a staticanalysis tool using type theory. Our techniques have been implemented and tested onseveral widely used open source applications. Using the tool; we found known andunknown integer related vulnerabilities in these applications.,International Conference on Detection of Intrusions and Malware; and Vulnerability Assessment,2006,20
Distributed XML repositories: Top-down design and transparent query processing,Michael Gertz; Jan-Marco Bremer,Abstract XML is increasingly used not only for data exchange but also to represent arbitrarydata sources as virtual XML repositories. In many application scenarios; fragments of suchrepositories are distributed over the Web. However; design and query processing models fordistributed XML data have not yet been studied in detail. The goal of this paper is to studythe design and management of distributed XML repositories. Following the well-establishedconcepts of vertical and horizontal data fragmentation schemes for relational databases; weintroduce a flexible distribution design approach for XML repositories. We provide acomprehensive data allocation model with a particular focus on storage efficient indexstructures. These index structures encode global path information about XML fragment dataat local sites and provide for an efficient; local evaluation of the most common types of …,Department of Computer Science,2003,20
Discovery of multi-level security policies,Christina Yip Chung; Michael Gertz; Karl Levitt,Abstract With the increasing complexity and dynamics of database systems; it becomesmore and more difficult for administrative personnel to identify; specify and enforce securitypolicies that govern against the misuse of data. Often security policies are not known; tooimprecise or simply have been disabled because of changing requirements. Recentlyseveral proposals have been made to use data mining techniques to discover profiles andanomalous user behavior from audit logs. These approaches; however; are often too fine-grained in that they compute too many rules to be useful for an administrator inimplementing appropriate security enforcing mechanisms. In this paper we present a novelapproach to discover security policies from audit logs. The approach is based on usingmultiple concept hierarchies that specify properties of objects and data at different levels …,*,2002,20
Diagnosis and Repair of Constraint Violations in Database Systems,Michael Gertz,Abstract Integrity constraints play an essential role in database systems in order to specifythe semantics of an application domain in a more exact and complete manner. An importanttask is then to maintain the constraints at database run {time in order to guarantee thesemantic correctness of the stored data. The response action to constraint violations in thisprocess is typically a rollback of the violating transaction. Since this rigid behavior isundesirable for several application domains; approaches to constraint enforcement try torepair constraint violations by (prespecied) repairing modi cations on the stored data. Thegoal of this thesis is to present a framework for the diagnosis and repair of constraintviolations in relational databases. For the analyzing task we utilize basic concepts frommodel {based diagnosis as well as the representation of incomplete information by …,*,1996,20
Transitional Monitoring of Dynamic Inegrity Constraints,Udo W.  Lipeck; Michael Gertz; Gunter Saake,Database speci cation should include not only the static structure of a database system; butalso its dynamic behaviour. In order to determine admissible sequences of states dynamicintegrity constraints may be utilized. They give conditions on state transitions as well as long-term relations between database states in a descriptive manner. Complementarily; predened transactions; ie basic elements of application programs; or ad-hoc transactionscompleted by triggers induce executable state sequences in an operational manner. Wehave investigated how to monitor dynamic constraints without looking at entire statesequences; ie database histories; but considering only single state transitions; as it is usualin monitoring. Such monitoring can be achieved either by a universal (application-independent) monitor algorithm; or by (application-speci c and thus more e cient) …,IEEE Data Eng. Bull.,1994,20
Bend; don’t break: Using reconfiguration to achieve survivability,A Wolf; Dennis Heimbigner; John Knight; Premkumar Devanbu; Michael Gertz; Antonio Carzaniga,Our national interests are becoming increasingly dependent on the continuous; properfunctioning of large-scale; heterogeneous; and decentralized computing enterprises.Examples of such systems abound; ranging from military command and control to vitalnational security assets such as the financial and banking system. They are formed fromlarge numbers of components originating from multiple sources; some trusted and some not;assembled into complex and dynamically evolving structures. Protecting these interests iscritical; yet their sheer scale and diversity has gone far beyond our organizational andtechnical abilities to protect them. Manual procedures—however well designed and tested—cannot keep pace with the dynamicity of the environment and cannot react to securitybreaches in a timely and coordinated fashion; especially in the context of a networked …,Third Information Survivability Workshop,2000,19
Time for more languages: Temporal tagging of Arabic; Italian; Spanish; and Vietnamese,Jannik Strötgen; Ayser Armiti; Tran Van Canh; Julian Zell; Michael Gertz,Abstract Most of the research on temporal tagging so far is done for processing English textdocuments. There are hardly any multilingual temporal taggers supporting more than twolanguages. Recently; the temporal tagger HeidelTime has been made publicly available;supporting the integration of new languages by developing language-dependent resourceswithout modifying the source code. In this article; we describe our work on developing suchresources for two Asian and two Romance languages: Arabic; Vietnamese; Spanish; andItalian. While temporal tagging of the two Romance languages has been addressed before;there has been almost no research on Arabic and Vietnamese temporal tagging so far.Furthermore; we analyze language-dependent challenges for temporal tagging and explainthe strategies we followed to address them. Our evaluation results on publicly available …,ACM Transactions on Asian Language Information Processing (TALIP),2014,18
Spatial interestingness measures for co-location pattern mining,Christian Sengstock; Michael Gertz; Tran Van Canh,Co-location pattern mining aims at finding subsets of spatial features frequently locatedtogether in spatial proximity. The underlying motivation is to model the spatial correlationstructure between the features. This allows to discover interesting co-location rules (featureinteractions) for spatial analysis and prediction tasks. As in association rule mining; a majorproblem is the huge amount of possible patterns and rules. Hence; measures are needed toidentify interesting patterns and rules. Existing approaches so far focused on findingfrequent patterns; patterns including rare features; and patterns occurring in small (local)regions. In this paper; we present a new general class of interestingness measures that arebased on the spatial distribution of co-location patterns. These measures allow to judge theinterestingness of a pattern based on properties of the underlying spatial feature …,Data Mining Workshops (ICDMW); 2012 IEEE 12th International Conference on,2012,18
Event-centric search and exploration in document collections,Jannik Strötgen; Michael Gertz,Abstract Textual data ranging from corpora of digitized historic documents to largecollections of news feeds provide a rich source for temporal and geographic information.Such types of information have recently gained a lot of interest in support of different searchand exploration tasks; eg; by organizing news along a timeline or placing the origin ofdocuments on a map. However; for this; temporal and geographic information embedded indocuments is often considered in isolation. We claim that through combining suchinformation into (chronologically ordered) event-like features interesting and meaningfulsearch and exploration tasks are possible. In this paper; we present a framework for theextraction; exploration; and visualization of event information in document collections. Forthis; one has to identify and combine temporal and geographic expressions from …,Proceedings of the 12th ACM/IEEE-CS joint conference on Digital Libraries,2012,18
WikiWarsDE: A German corpus of narratives annotated with temporal expressions,Jannik Strötgen; Michael Gertz,Abstract Temporal information plays an important role in many natural language processingand understanding tasks. Therefore; the extraction and normalization of temporalexpressions from documents are crucial preprocessing steps in these research areas; andseveral temporal taggers have been developed in the past. The quality of such temporaltaggers is usually evaluated using annotated corpora as gold standards. However; existingannotated corpora only contain documents of the news domain; ie; short documents withonly few temporal expressions. A remarkable exception is the recently published corpusWikiWars; which is the first temporal annotated English corpus containing long narrativesthat are rich in temporal expressions. Following this example; in this paper; we describe thedevelopment and the characteristics of WikiWarsDE; a new temporal annotated corpus for …,Proceedings of the conference of the German society for computational linguistics and language technology (GSCL 2011),2011,18
VDM-RS: A visual data mining system for exploring and classifying remotely sensed images,Jianting Zhang; Le Gruenwald; Michael Gertz,Abstract Remotely sensed imagery has become increasingly important in severalapplications domains; such as environmental monitoring; change detection; fire riskmapping and land use; to name only a few. Several advanced image classificationtechniques have been developed to analyze such imagery and in particular to improve theaccuracy of classifying images in the context of such applications. However; most of theproposed classifiers remain a black box to users; leaving them with little to no means toexplore and thus further improve the classification process; in particular for misclassifiedpixel samples. In this paper; we present the concepts; design and implementation of VDM-RS; a visual data mining system for classifying remotely sensed images and exploringimage classification processes. The system provides users with two classes of …,Computers & Geosciences,2009,18
Detection and exploration of outlier regions in sensor data streams,Conny Franke; Michael Gertz,Sensor networks play an important role in applications concerned with environmentalmonitoring; disaster management; and policy making. Effective and flexible techniques areneeded to explore unusual environmental phenomena in sensor readings that arecontinuously streamed to applications. In this paper; we propose a framework that allows todetect outlier sensors and to efficiently construct outlier regions from respective outliersensors. For this; we utilize the concept of degree-based outliers. Compared to thetraditional binary outlier models (outlier versus non-outlier); this concept allows for a morefine-grained; context sensitive analysis of anomalous sensor readings and in particular theconstruction of heterogeneous outlier regions. The latter suitably reflect the heterogeneityamong outlier sensors and sensor readings that determine the spatial extent of outlier …,Data Mining Workshops; 2008. ICDMW'08. IEEE International Conference on,2008,18
Search results using timeline visualizations,Omar Alonso; Michael Gertz; Ricardo Baeza-Yates,As search applications keep gathering new and diverse information sources; presentingrelevant information anchored in time becomes more important. Time can help in describingthe context of a document or document collection or in recreating a particular historicalperiod. Temporal information is available in every document either explicitly or implicitly.Recognizing such temporal information and exploiting it for document retrieval andpresentation purposes are important features that can significantly improve the functionalityof today's search applications. A look at the functionality of any of the current search enginesshows that temporal aspects of documents are exclusively used to sort the hit list by date;which is primarily the date a Web page or a document has been created or last modified. Inthis demonstration; we present a new approach in which search results are arranged in a …,Proceedings of the 30th annual international ACM SIGIR conference on Research and development in information retrieval,2007,18
Spatio-temporal characteristics of bursty words in Twitter streams,Hamed Abdelhaq; Michael Gertz; Christian Sengstock,Abstract Social networking and microblogging services such as Twitter provide a continuoussource of data from which useful information can be extracted. The detection andcharacterization of bursty words play an important role in processing such data; as burstywords might hint to events or trending topics of social importance upon which actions can betriggered. While there are several approaches to extract bursty words from the content ofmessages; there is only little work that deals with the dynamics of continuous streams ofmessages; in particular messages that are geo-tagged. In this paper; we present aframework to identify bursty words from Twitter text streams and to describe such words interms of their spatio-temporal characteristics. Using a time-aware word usage baseline; asliding window approach over incoming tweets is proposed to identify words that satisfy …,Proceedings of the 21st ACM SIGSPATIAL international conference on advances in geographic information systems,2013,17
Enhancing document snippets using temporal information,Omar Alonso; Michael Gertz; Ricardo Baeza-Yates,Abstract In this paper we propose an algorithm to enhance the quality of document snippetsshown in a search engine by using temporal expressions. We evaluate our proposal in asubset of the Wikipedia corpus using crowdsourcing; showing that snippets that havetemporal information are preferred by the users.,International Symposium on String Processing and Information Retrieval,2011,17
A data and query model for streaming geospatial image data,Michael Gertz; Quinn Hart; Carlos Rueda; Shefali Singhal; Jie Zhang,Abstract Most of the recent work on adaptive processing and continuous querying of datastreams assume that data objects come in the form of tuples; thus relying on the relationaldata model and traditional relational operators as basis for query processing techniques.Complex types of objects; such as multidimensional data sets or the vast amounts of rasterimage data continuously streaming down to Earth from satellites have not been considered.In this paper; we introduce a data and query model as a comprehensive and practicallyrelevant basis for managing and querying streams of remotely-sensed geospatial imagedata. Borrowing basic concepts from Image Algebra; we detail a data model that reflectsbasic properties of such streams of imagery. We present a query model that includes streamrestrictions; transforms; and compositions; and provides a sound basis for formulating …,International Conference on Extending Database Technology,2006,16
A general model for authentic data publication,Chip Martel; Glen Nuckolls; Prem Devanbu; Michael Gertz; April Kwong; Stuart Stubblebine,Abstract Query answers from on-line databases can easily be corrupted by hackers ormalicious intent by the database publisher. Thus it is important to provide mechanismswhich allow clients to trust the results from on-line queries. Authentic publication is a novelscheme which allows untrusted publishers to securely answer queries from clients on behalfof trusted off-line data owners. Publishers validate answers using compact; unforgeableverification objects (VOs); which clients can check efficiently. To make authentic publicationattractive it is important for the VOs to be small; efficiently computable and verifiable. Thishas led to the development of a number of data representations for efficient VO computation.In this paper; we prove the security of VOs for a new general data model called SearchDAGs. Our security theorem for Search DAGS gives simple security proofs and efficient …,Algorithmica,2001,16
Chinese temporal tagging with HeidelTime,Hui Li; Jannik Strötgen; Julian Zell; Michael Gertz,Abstract Temporal information is important for many NLP tasks; and there has beenextensive research on temporal tagging with a particular focus on English texts. Recently;other languages have also been addressed; eg; HeidelTime was extended to process eightlanguages. Chinese temporal tagging has achieved less attention; and no Chinese temporaltagger is publicly available. In this paper; we address the full task of Chinese temporaltagging (extraction and normalization) by developing Chinese HeidelTime resources. Ourevaluation on a publicly available corpus–which we also partially re-annotated due to itsrather low quality–demonstrates the effectiveness of our approach; and we outperform arecent approach to normalize temporal expressions. The Chinese HeidelTime resource aswell as the corrected corpus are made publicly available.,Proceedings of the 14th Conference of the European Chapter of the Association for Computational Linguistics; volume 2: Short Papers,2014,15
Modeling and querying vague spatial objects using shapelets,Daniel Zinn; Jim Bosch; Michael Gertz,Abstract Research in modeling and querying spatial data has primarily focused ontraditional" crisp" spatial objects with exact location and spatial extent. More recent work;however; has begun to address the need for spatial data types describing spatialphenomena that cannot be modeled by objects having sharp boundaries. Other work hasfocused on point objects whose location is not precisely known and is typically describedusing a probability distribution. In this paper; we present a new technique for modeling andquerying vague spatial objects. Using shapelets; an image decomposition techniquedeveloped in astronomy; as base data type; we introduce a comprehensive set of low-leveloperations that provide building blocks for versatile high-level operations on vague spatialobjects. In addition; we describe an implementation of this data model as an extension to …,Proceedings of the 33rd international conference on Very large data bases,2007,15
Database techniques for the analysis and exploration of software repositories,Omar Alonso; Premkumar T Devanbu; Michael Gertz,In a typical software engineering project; there is a large and diverse body of documents thata development team produces; including requirement documents; specifications; designs;code; and bug reports. Documents typically have different formats and are managed inseveral repositories. The heterogeneity among document formats and the diversity ofrepositories make it often not feasible to query and explore the repositories in an integratedand transparent fashion during the different phases of the software development process.Here; we present a framework for the analysis and exploration of software repositories. Ourapproach applies database techniques to integrate; and manage different documentsproduced by a team. Tools that exploit the database functionality then allow for theprocessing of complex queries against a document collection to extract trends and …,MSR,2004,15
Integrating scientific data through external; concept-based annotations,Michael Gertz; Kai-Uwe Sattler,Abstract In several scientific application domains; such as the computational sciences; thetransparent and integrated access to distributed and heterogeneous data sources is key toleveraging the knowledge and findings of researchers. Standard database integrationapproaches; however; are either not applicable or insufficient because of lack of local andglobal schema structures. In these application domains; data integration often occursmanually in that researchers collect data and categorize them using “semantic indexing”; inthe most simple case through local bookmarking; which leaves them without appropriatedata query; sharing; and management mechanisms. In this paper; we present a dataintegration technique suitable for such application domains. This technique is based on thenotion of controlled data annotations; resembling the idea of associating semantic rich …,*,2003,15
A graphical query language for temporal databases,Vram Kouramajian; Michael Gertz,Abstract This paper addresses the issue of visual query formulation for temporal databases.We introduce a number of visual constructs that allow users to build queries in a modularfashion based on a temporal Extended Entity-Relationship Model. These constructs are:Temporal projection; temporal selection; time links; filtering and set operators; and temporalaggregates.,International Conference on Conceptual Modeling,1995,15
A diagnostic approach to repairing constraint violations in databases,Michael Gertz; Udo W Lipeck,Abstract Repairing violations of integrity constraints in databases can be seen as aninterleaving diagnostic/repair process. In this paper we introduce a new approach onrepairing constraint violations by adopting existing techniques from model {based diagnosis.Violations of integrity constraints observed in an inconsistent database state are diagnosedand repair actions are deduced from diagnoses. By interleaving diagnosing constraintviolations and performing repair actions; transactions are computed which restore theconsistency of the database.,*,1995,15
Databases that tell the Truth: Authentic Data Publication.,Michael Gertz; April Kwong; Charles U Martel; Glen Nuckolls; Premkumar T Devanbu; Stuart S Stubblebine,Abstract The publication of high-value and mission critical data on the Internet plays animportant role in the government; industry; and health-care sectors. However; owners ofsuch data are often not able or willing to serve millions of query requests per day andfurthermore satisfy clients' data requirements regarding the integrity; availability; andauthenticity of the data they manage in their databases. In this article; we give an overview ofour work on authentic publication schemes in which a data owner employs a (possiblyuntrusted) data publisher to answer queries from clients on behalf of the owner. In additionto query answers; publishers provide clients with verification objects a client uses to verifywhether the answer is the same as the owner would have provided. We consider twopopular types of database systems; those managing relational data and those managing …,IEEE Data Eng. Bull.,2004,14
The challenges and rewards of integrating diverse neuroscience information,Fredric Gorin; Michael Hogarth; Michael Gertz,The design of database models and schemas for storing; cross-referencing; and retrievingneuroscience information faces issues that are similar but more complex than most of theother biomedical disciplines; such as genomics and proteonomics. Specifically; thevisualization and manipulation of very large and diverse image data; such as digital brainatlases and functional magnetic resonance images; play a unique role in neurosciencewhile much of the associated information is textually recorded. Nongraphical information caninclude the annotation of large brain structures ranging from anatomical regions tointracellular structures; the description of cellular functional properties; and their variousinterrelationships; such as fiber connections. It is necessary that the heterogeneous anddistributed types of data be cross-referenced to each other so that this diverse information …,The Neuroscientist,2001,14
Terminology Query Language: a server interface for concept-oriented terminology systems.,Michael A Hogarth; Michael Gertz; Fredric A Gorin,Abstract Designers of medical computing applications increasingly require terminologysupport for their systems. Yet; terminology systems today lack standard methodologies forproviding terminology support. This invariably means increased implementation time andexpense for system developers who need to use terminologies in their applications. Weintroduce Terminology Query Language (TQL); a simple query language interface to serverimplementations of concept-oriented terminologies. TQL is a declarative; set-based querylanguage built on a generic entity-relationship (E/R) schema. TQL defines a common query-based mechanism for accessing terminology information from one or more terminologyservers over a network connection.,Proceedings of the AMIA Symposium,2000,14
A visual query editor for temporal databases,Vram Kouramajian; Michael Gertz,*,Proceedings of the 14th International Conference on Object-Oriented and Entity-Relationship Modelling,1995,14
Web data indexing through external semantic-carrying annotations,Jan-Marco Bremer; Michael Gertz,Data annotations provide an effective means to link data from diverse data archives to adomain conceptualization; eg; ontology; which then provides users with an integrated anduniform view for querying the data. Existing approaches typically use document annotationtechniques that require authors to embed linkage information into their documents. Thisprevents true collaborative extensions of documents by annotations and conceptual views ofmultiple users on the same data. This paper presents the concepts and architectureunderlying a data annotation framework that enables external annotations of remote data atdifferent levels of granularity. Semantic-carrying annotations; based on a domainconceptualization model; allow multiple users to enrich the same data under differentperspectives. XML and related techniques are used for managing; exchanging; and …,Research Issues in Data Engineering; 2001. Proceedings. Eleventh International Workshop on,2001,13
Oracle/SQL Tutorial,Michael Gertz,SQL* Plus è l'interfaccia utente (di basso livello) per il sistema di gestione dei databaseOracle. Tipicamente; SQL* Plus è usato per formulare query e ottenere il risultato a video.Alcune caratteristiche di SQL* Plus sono:• Un editor di linea integrato; che può essereutilizzato per correggere query sbagliate. E'possibile anche utilizzare qualsiasi altro editorinstallato nel computer al posto di questo editor di linea; ed è possibile richiamarlodirettamente dall'interno di SQL* Plus.• Ci sono numerosi comandi per formattare l'output diuna query.• SQL* Plus fornisce un help in linea.• I risultati delle query possono esserememorizzati in files che possono essere stampati o importati in altre applicazioni comeExcel.,Database and Information System Group; Department of Computer Science; University of California; Davis,2000,13
Structural constraints for XML,April Kwong; Michael Gertz,*,University of California Technical Report CSE-2002-24,2002,12
On specifying the reactive behavior on constraint violations,Michael Gertz,Abstract Recent approaches to integrity enforcement in active databases suggest not only tocheck for inconsistencies by triggers but also to utilize triggers to perform repair actions onconstraint violations. Typically; respective repairing triggers are derived automatically fromconstraint specifications following almost fixed derivation strategies. However; in order toincorporate more semantic knowledge of the application these approaches often requirerefinements or even revisions of already derived integrity checking and inconsistencyrepairing triggers by the designer. In this paper we argue that analyzing and specifyingrepair actions on constraint violations should be also a design task and exclusively becarried out in the conceptual design. For this purpose; we provide a declarative specificationlanguage for repair actions on inconsistencies with an operational semantics; suitable to …,*,1993,12
Terms over LOAD: Leveraging Named Entities for Cross-Document Extraction and Summarization of Events,Andreas Spitz; Michael Gertz,Abstract Real world events; such as historic incidents; typically contain both spatial andtemporal aspects and involve a specific group of persons. This is reflected in thedescriptions of events in textual sources; which contain mentions of named entities anddates. Given a large collection of documents; however; such descriptions may be incompletein a single document; or spread across multiple documents. In these cases; it is beneficial toleverage partial information about the entities that are involved in an event to extract missinginformation. In this paper; we introduce the LOAD model for cross-document event extractionin large-scale document collections. The graph-based model relies on co-occurrences ofnamed entities belonging to the classes locations; organizations; actors; and dates and putsthem in the context of surrounding terms. As such; the model allows for efficient queries …,Proceedings of the 39th International ACM SIGIR conference on Research and Development in Information Retrieval,2016,11
Proximity 2-aware ranking for textual; temporal; and geographic queries,Jannik Strötgen; Michael Gertz,Abstract Temporal and geographic information needs are frequent and important but notwell served by standard IR systems. Recent approaches address such needs by extractingand normalizing temporal and geographic expressions from documents. They calculatespecific scores for the temporal and/or geographic parts of a query. However; all approachesassume independence between the different query parts. In this paper; we present a newmodel to rank documents according to combined textual; temporal; and geographic queries.The independence assumption between the query parts is eliminated by calculatingproximity scores. Thus; documents are regarded to be more relevant if terms andexpressions satisfying the different query parts occur close to each other in a document. Asour evaluations based on the NTCIR-GeoTime data show; our proposed model …,Proceedings of the 22nd ACM international conference on Information & Knowledge Management,2013,11
Querying Streaming Geospatial Image Data: The GeoStreams Project.,Quinn Hart; Michael Gertz,*,SSDBM,2005,11
Spatio-temporal aggregates over raster image data,Jie Zhang; Michael Gertz; Demet Aksoy,Abstract Spatial; temporal and spatio-temporal aggregates over continuous streams ofremotely sensed image data build a fundamental operation in many applications in theenvironmental sciences. Several approaches to efficiently compute multi-dimensionalaggregates have been proposed in the literature. However; none of these approaches issuitable to compute aggregate values over streaming raster image data where the spatialextents and positions of individual images vary over time. In particular; the computation of asingle aggregate value becomes less meaningful when the image data contribute onlypartially to a query region. In this paper; we present an indexing scheme--based on the Box-Aggregation Tree--to efficiently compute spatio-temporal aggregates over streams of rasterimage data that vary in position and size. Using information about the spatial extent of …,Proceedings of the 12th annual ACM international workshop on Geographic information systems,2004,11
Misuse Detection in Database Systems Through User Profiling.,Christina Yip Chung; Michael Gertz; Karl N Levitt,Christina Yip Chung Ms. Chung received her B.Sci.(Computer Science) degree from the Universityof Hong Kong in 1996 and her M.Sci.(Computer Science) degree from the University ofCalifornia; Davis in 1998. She is currently a Ph.D. candidate in the Department of Computer Scienceat the University of California; Davis. Her research interests include data mining and knowledgediscovery; misuse detection and database security … Michael Gertz Dr.Gertz received his MSdegree in Computer Science from the University of Dortmund; Germany. In 1996 he receivedhis Ph.D. in Computer Science from the University of Hannover; Germany; where he workedas a research and teaching assistant from December 1991 to November 1997. Since October1997 Dr.Gertz is an Assistant Professor in the Department of Computer Science at the Universityof California; Davis … Dr.Gertz's research interests are in the design and …,Recent Advances in Intrusion Detection,1999,11
Beyond friendships and followers: The Wikipedia social network,Johanna Geiß; Andreas Spitz; Michael Gertz,Abstract Most traditional social networks rely on explicitly given relations between users;their friends and followers. In this paper; we go beyond well structured data repositories andcreate a person-centric network from unstructured text--the Wikipedia Social Network. Toidentify persons in Wikipedia; we make use of interwiki links; Wikipedia categories andperson related information available in Wikidata. From the co-occurrences of persons on aWikipedia page we construct a large-scale person-centric network and provide a weightingscheme for the relationship of two persons based on the distances of their mentions withinthe text. We extract key characteristics of the network such as centrality; clustering coefficientand component sizes for which we find values that are typical for social networks. Usingstate-of-the-art algorithms for community detection in massive networks; we identify …,Proceedings of the 2015 IEEE/ACM International Conference on Advances in Social Networks Analysis and Mining 2015,2015,10
Character retrieval of vectorized cuneiform script,Bartosz Bogacz; Michael Gertz; Hubert Mara,Motivated by the increasing demand for computerized analysis of documents within theDigital Humanities we present an approach to automating handwritten cuneiform characterrecognition on vectorized cuneiform tablets. Cuneiform is one of the oldest handwrittenscripts used for more than three millennia. In previous work we have shown how to extractvector drawings from 3D-models of cuneiform tablets similar to those manually drawn overdigital photographs. We approach the problem of recognizing these characters by applyingpattern matching against the basic structural features of cuneiform; the wedge-shapedimpressions. Then; we find an optimal assignment between the wedge configuration of twocharacters wrt wedge shape and position. The similarity of two characters is measured bythe quality of the assignment. We compare our method against well known methods for …,Document Analysis and Recognition (ICDAR); 2015 13th International Conference on,2015,10
A Constraint neighborhood based approach for co-location pattern mining,Tran Van Canh; Michael Gertz,Driven by the ever increasing amount of spatial data collected by observations and GPS-enabled devices; mining such data for interesting or previously unknown patterns hasbecome a major challenge. Among the many possible patterns; co-location patternsdescribing the frequently occurring spatial proximity of objects possessing some features areof particular interest. While several approaches have been proposed to discover suchpatterns; so called self co-location patterns where objects having the same feature (amongothers) are in spatial proximity; however; have not been effectively addressed. Furthermore;most of the co-location discovery methods suffer from expensive computations; such asspatial joins. To address these problems; in this paper; we propose a novel constraintneighborhood based approach to find co-location patterns. This approach can discover …,Knowledge and Systems Engineering (KSE); 2012 Fourth International Conference on,2012,10
Modeling and prediction of moving region trajectories,Conny Junghans; Michael Gertz,Abstract Data about moving objects is being collected in many different application domainswith the help of sensor networks; GPS-enabled devices; and in particular airborne sensorsand satellites. Such moving objects often represent not just point-based objects; but rathermoving regions like hurricanes; oil-spills; or animal herds. One key application feature usersare often interested in is the exploration and prediction of moving object trajectories. Whilethere exist models and techniques that help to predict the movement of moving point objects;no such method for moving regions has been proposed yet. In this paper; we present anapproach to model and predict the development of moving regions. Our method not onlypredicts the trajectory of regions; but also the evolution of a region's spatial extent andorientation. For this; moving regions are modelled using minimum enclosing boxes; and …,Proceedings of the ACM SIGSPATIAL International Workshop on GeoStreaming,2010,10
Real-time integration of geospatial raster and point data streams,Carlos Rueda; Michael Gertz,Abstract Sensor and network technology advances are increasingly placing an immenseamount of real-time geospatial data streams at the scientist's disposal. The effectiveintegration and assimilation of such datasets; however; is still a challenging goal. In thispaper; we describe a computational framework that simplifies the design; execution; andvisualization of processing workflows involving the integration of satellite raster and groundpoint data streams. The framework is enabled for interoperability by adhering to open sensordata standards; and demonstrated with the evaluation of key environmental inputs neededfor the estimation of reference evapotranspiration over California.,International Conference on Scientific and Statistical Database Management,2008,10
An extensible infrastructure for processing distributed geospatial data streams,Carlos Rueda; Michael Gertz; Bertram Ludascher; Bernd Hamann,Although the processing of data streams has been the focus of many research efforts inseveral areas; the case of remotely sensed streams in scientific contexts has received littleattention. We present an extensible architecture to compose streaming image processingpipelines spanning multiple nodes on a network using a scientific workflow approach. Thisarchitecture includes (i) a mechanism for stream query dispatching so new streams can bedynamically generated from within individual processing nodes as a result of local or remoterequests; and (ii) a mechanism for making the resulting streams externally available. Ascomplete processing image pipelines can be cascaded across multiple interconnectednodes in a dynamic; scientist-driven way; the approach facilitates the reuse of data and thescalability of computations. We demonstrate the advantages of our infrastructure with a …,Scientific and Statistical Database Management; 2006. 18th International Conference on,2006,10
A Model and Architecture for Conceptualized Data Annotations,Michael Gertz; Kai-Uwe Sattler,Abstract In many collaborative research environments; in particular computational sciences;novel tools and techniques allow researchers to generate data from experiments andobservations at a staggering rate. Researchers in these areas are now facing the strongneed for querying; sharing and exchanging the data in a uniform and transparent fashion tofurther leverage their findings. However; due to the nature of the various types ofheterogeneous data and lack of local and global database schema structures; standard dataintegration approaches fail or are not applicable. A viable solution to this problem is theextensive use of metadata. In this paper; we present the model and realization of a metadatamanagement systems suitable for such research environments. The core component of themodel are conceptualized data annotations that allow researchers to associate well …,Proc. 14th Int'l Conf. Scientific and Statistical Database Management,2001,10
Prov2ONE: an algorithm for automatically constructing ProvONE provenance graphs,Ajinkya Prabhune; Aaron Zweig; Rainer Stotzka; Michael Gertz; Juergen Hesser,Abstract Provenance traces history within workflows and enables researchers to validateand compare their results. Currently; modelling provenance in ProvONE is an arduous taskand lacks an automated approach. This paper introduces a novel algorithm; calledProv2ONE that automatically generates the ProvONE prospective provenance for scientificworkflows defined in BPEL4WS. The same prospective ProvONE graph is updated with therelevant retrospective provenance; preventing provenance to be captured in various non-standard provenance models and thus enabling research communities to share; compareand analyze workflows and its associated provenance. Finally; using the Prov2ONEalgorithm; a ProvONE provenance graph for the nanoscopy workflow is generated.,International Provenance and Annotation Workshop,2016,9
Authentic publication of XML document data,April Kwong; Michael Gertz,With XML becoming a major standard for the exchange and sharing of data; manyapplications now rely on XML to publish and utilize Web data. Data sources (data owners);however often do not have the means to provide high performance query mechanisms;serving hundreds of thousands of client queries per day. Furthermore; it is too costly for themto maintain a secure Web information system infrastructure preventing intruders fromtampering with the integrity of the data. As a solution to this problem; data owners candistribute XML document data to data publishers who then handle queries from clients onbehalf of the data owners. In this paper; we present a novel authentic publication scheme forXML document data that allows clients to efficiently verify query results from data publishersfor correctness and completeness. For this; data owners simply provide summary …,Web Information Systems Engineering; 2001. Proceedings of the Second International Conference on,2001,9
Domain-sensitive temporal tagging,Jannik Strötgen; Michael Gertz,Abstract This book covers the topic of temporal tagging; the detection of temporalexpressions and the normalization of their semantics to some standard format. It places aspecial focus on the challenges and opportunities of domain-sensitive temporal tagging.After providing background knowledge on the concept of time; the book continues with acomprehensive survey of current research on temporal tagging. The authors provide anoverview of existing techniques and tools; and highlight key issues that need to beaddressed. This book is a valuable resource for researchers and application developerswho need to become familiar with the topic and want to know the recent trends; current toolsand techniques; as well as different application domains in which temporal information is ofutmost importance. Due to the prevalence of temporal expressions in diverse types of …,Synthesis Lectures on Human Language Technologies,2016,8
State of the Union: A Data Consumer's Perspective on Wikidata and Its Properties for the Classification and Resolution of Entities.,Andreas Spitz; Vaibhav Dixit; Ludwig Richter; Michael Gertz; Johanna Geiß,Abstract Wikipedia is one of the most popular sources of free data on the Internet andsubject to extensive use in numerous areas of research. Wikidata on the other hand; theknowledge base behind Wikipedia; is less popular as a source of data; despite having the“data” already in its name; and despite the fact that many applications in Natural LanguageProcessing in general and Information Extraction in particular benefit immensely from theintegration of knowledge bases. In part; this imbalance is owed to the younger age ofWikidata; which launched over a decade after Wikipedia. However; this is also owed tochallenges posed by the still evolving properties of Wikidata that make its content moredifficult to consume for third parties than is desirable. In this article; we analzye the causes ofthese challenges from the viewpoint of a data consumer and discuss possible avenues of …,Wiki@ ICWSM,2016,8
On the locality of keywords in Twitter streams,Hamed Abdelhaq; Michael Gertz,Abstract The continuously increasing popularity of social media sites such as Twitter andFacebook has recently led to a number of approaches to detect and extract eventinformation from social media streams. Such events play an important role; eg; in supportinglocation-based services and improving situational awareness. Moreover; the introduction ofGPS-equipped communication devises has led to an increase in the percentage of geo-tagged messages. These help to detect localized events; ie; events occurring at a certainlocation; such as sport events or accidents. The main entities that indicate a localized eventare local keywords that exhibit a surge in usage at the event location. In this paper; wepropose an approach to extract local keywords from a Twitter stream by (1) identifying localkeywords; and (2) estimating the central location of each keyword. This extraction process …,Proceedings of the 5th ACM SIGSPATIAL International Workshop on GeoStreaming,2014,8
Extending HeidelTime for Temporal Expressions Referring to Historic Dates.,Jannik Strötgen; Thomas Bögel; Julian Zell; Ayser Armiti; Tran Van Canh; Michael Gertz,Abstract Research on temporal tagging has achieved a lot of attention during the last years.However; most of the work focuses on processing news-style documents. Thus; referencesto historic dates are often not well handled by temporal taggers although they frequentlyoccur in narrative-style documents about history; eg; in many Wikipedia articles. In thispaper; we present the AncientTimes corpus containing documents about different historictime periods in eight languages; in which we manually annotated temporal expressions.Based on this corpus; we explain the challenges of temporal tagging documents abouthistory. Furthermore; we use the corpus to extend our multilingual; cross-domain temporaltagger HeidelTime to extract and normalize temporal expressions referring to historic dates;and to demonstrate HeidelTime's new capabilities. Both; the AncientTimes corpus as well …,LREC,2014,8
Efficient geometric graph matching using vertex embedding,Ayser Armiti; Michael Gertz,Abstract For many applications such as road network analysis and image processing; it iscritical to study spatial properties of objects in addition to object relationships. Geometricgraphs provide a suitable modeling framework for such applications; where vertices arelocated in some 2D space. For applications where the similarity between the structures ofdifferent graphs plays an important role; typically; inexact graph matching algorithms areemployed. However; graph matching algorithms face many problems such as scalability withrespect to graph size and less tolerance to changes in graph structure or labels. In thispaper; we propose a solution to the problem of inexact graph matching for geometric graphsin the 2D space. Our approach allows to effectively answer subgraph and commonsubgraph queries for geometric graphs that differ in structure; spatial properties; and …,Proceedings of the 21st ACM SIGSPATIAL International Conference on Advances in Geographic Information Systems,2013,8
Efficiently managing large-scale raster species distribution data in PostgreSQL,Jianting Zhang; Michael Gertz; Le Gruenwald,Abstract Species distribution data play an important role in biodiversity related research;especially in exploring relationships with the environment. In the recent years; both thenumber of species being explored and the spatial resolution of species distribution data areincreasing fast. It is thus imperative to develop database systems that allow users toefficiently query such large-scale data based on spatial and non-spatial (eg; taxonomic andphylogenetics) criteria. In this paper; we present our approach to building such a system byintegrating several components; including a quadtree representation of binary raster data;tree path indexing and query processing in PostgreSQL; and window decompositiontechniques for spatial queries. Our unique contribution is in associating species identifierswith intermediate quadtree nodes and query optimization for multiple independent …,Proceedings of the 17th ACM SIGSPATIAL International Conference on Advances in Geographic Information Systems,2009,8
Constraint-based learning of distance functions for object trajectories,Wei Yu; Michael Gertz,Abstract With the drastic increase of object trajectory data; the analysis and exploration oftrajectories has become a major research focus with many applications. In particular; severalapproaches have been proposed in the context of similarity-based trajectory retrieval. Whilethese approaches try to be comprehensive by considering the different properties of objecttrajectories at different degrees; the distance functions are always pre-defined and thereforedo not support different views on what users consider (dis) similar trajectories in a particulardomain. In this paper; we introduce a novel approach to learning distance functions insupport of similarity-based retrieval of multi-dimensional object trajectories. Our approach ismore generic than existing approaches in that distance functions are determined based onconstraints; which specify what object trajectory pairs the user considers similar or …,International Conference on Scientific and Statistical Database Management,2009,8
Optimization of multiple continuous queries over streaming satellite data,Quinn Hart; Michael Gertz,Abstract Remotely sensed data; in particular satellite imagery; play many important roles inenvironmental applications. In particular applications that study rapid changes in theenvironment require frequent access to these data. For continuous data products; users areoften interested in formulating continuous queries that deliver results for each incomingimage. In the presence of multiple continuous queries; there is clearly an opportunity toshare common intermediate data and thus; increase the overall processing speed of thesystem. Based on the widely used GRASS; this paper describes a system that realizesmultiple query processing using two major components. A query optimizer maintains thecurrent set of active continuous queries. Queries are organized into a single processing plandesigned to share intermediate results. For each new image from the stream; the …,Proceedings of the 14th annual ACM international symposium on Advances in geographic information systems,2006,8
Trust Mediation for Distributed Information Systems,Brian Toone; Michael Gertz; Premkumar Devanbu,Abstract Distributed information systems are increasing in prevalence and complexity as wesee an increase in the number of both information consumers and information providers.Applications often need to integrate information from several different information providers.Current approaches for securing this process of integration do not scale well to handlecomplex trust relationships between consumer applications and providers. Trust mediationis a technique we introduce to address this problem by incorporating a model forrepresenting trust into a framework for retrieving information in a distributed system. Ourmodel for representing trust uses a type system by which data from a source is labeled witha trust type based on qualities of the data itself or the information source (s) providing thedata. With this model we develop algorithms to perform static analysis of data queries to …,IFIP International Information Security Conference,2003,8
The Wikipedia location network: overcoming borders and oceans,Johanna Geiß; Andreas Spitz; Jannik Strötgen; Michael Gertz,Abstract In social network analysis and information retrieval; research has recently beendevoted to the extraction of implicit relationships between persons from unstructured textualsources. In this paper; we adapt such a person-centric approach to the extraction oflocations and build the Wikipedia Location Network based on co-occurrences of placenames in the English Wikipedia. We summarize the network's characteristics anddemonstrate its value for future location relationship analysis tasks.,Proceedings of the 9th workshop on geographic information retrieval,2015,7
Mining spatio-temporal patterns in the presence of concept hierarchies,Michael Gertz,In the past; approaches to mining spatial and spatio-temporal data for interesting patternshave mainly concentrated on data obtained through observations and simulations wherepositions of objects; such as areas; vehicles; or persons; are collected over time. In the pastcouple of years; however; new datasets have been built by automatically extracting facts; assubject-predicate-object triples; from semi structured information sources such as Wikipedia.Recently some approaches; for example; in the context of YAGO2; have extended such factsby adding temporal and spatial information. The presence of such new data sources givesrise to new approaches for discovering spatio-temporal patterns. In this paper; we present aframework in support of the discovery of interesting spatio-temporal patterns from knowledgebase datasets. Different from traditional approaches to mining spatio-temporal data; we …,Data Mining Workshops (ICDMW); 2012 IEEE 12th International Conference on,2012,7
Quality-driven resource-adaptive data stream mining?,Conny Junghans; Marcel Karnstedt; Michael Gertz,Abstract Data streams have become ubiquitous in recent years and are handled on a varietyof platforms; ranging from dedicated high-end servers to battery-powered mobile sensors.Data stream processing is therefore required to work under virtually any dynamic resourceconstraints. Few approaches exist for stream mining algorithms that are capable to adapt togiven constraints; and none of them reflects from the resource adaptation to the resultingoutput quality. In this paper; we propose a general model to achieve resource and qualityawareness for stream mining algorithms in dynamic setups. The general applicability isgranted by classifying influencing parameters and quality measures as components of amultiobjective optimization problem. By the use of CluStream as an example algorithm; wedemonstrate the practicability of the proposed model.,ACM SIGKDD Explorations Newsletter,2011,7
Sensor data dissemination systems using Web-based standards: a case study of publishing data in support of evapotranspiration models in California,Jianting Zhang; Quinn Hart; Michael Gertz; Carlos Rueda; Jeffrey Bergamini,Developing real-time and near real-time systems and models based on sensor dataacquisition requires efficient access to distributed data sources. This is especially true whenmulti-source datasets are required for a comprehensive model. For example; developingdaily spatial estimations of water evaporation and transpiration requires access to weatherstations; combined with satellite imagery; and potentially weather prediction models as well.Most existing online data dissemination services support dissemination with ad-hocmethods; designed for specific limited purposes. General purpose access methods; requiredby a broadening range of uses; become increasingly important. In this study; we examinestandard Web services for sensor data and how clients can consume such servicesseamlessly in their applications. Specifically; we describe a prototype system that …,Civil Engineering and Environmental Systems,2009,7
Security re-engineering for databases: concepts and techniques,Michael Gertz; Madhavi Gandhi,Summary Despite major advancements in access control models and security mechanisms;most of today's databases are still very vulnerable to various security threats; as shown byrecent incident reports. A reason for this that existing databases used in e-businesses andgovernment organizations are rarely designed with much security in mind but rely onsecurity policies and mechansims that are added over time in an ad-hoc fashion. What isneeded in such cases is a coherent approach for organizations to first evaluate the currentsecrutiy setup of a database; ie; its policies and mechanisms; and then to re-design andimprove the mechanisms in a focused way; that is; to apply an evolutionary rather than arevolutionary approach to improving database security. In this book chapter; we presentimportant principles and techniques of such a security re-engineering approach. Our …,*,2008,7
So far away and yet so close: augmenting toponym disambiguation and similarity with text-based networks,Andreas Spitz; Johanna Geiß; Michael Gertz,Abstract Place similarity has a central role in geographic information retrieval andgeographic information systems; where spatial proximity is frequently just a poor substitutefor semantic relatedness. For applications such as toponym disambiguation; alternativemeasures are thus required to answer the non-trivial question of place similarity in a givencontext. In this paper; we discuss a novel approach to the construction of a network oflocations from unstructured text data. By deriving similarity scores based on the textualdistance of toponyms; we obtain a kind of relatedness that encodes the importance of the co-occurrences of place mentions. Based on the text of the English Wikipedia; we construct andprovide such a network of place similarities; including entity linking to Wikidata as anaugmentation of the contained information. In an analysis of centrality; we explore the …,Proceedings of the third international ACM SIGMOD workshop on managing and mining enriched geo-spatial data,2016,6
Cuneiform character similarity using graph representations,Bartosz Bogacz; Michael Gertz; Hubert Mara,Motivated by the increased demand for computerized analysis of documents within theDigital Humanities we are developing algorithms for cuneiform tablets; which contain theoldest handwritten script used for more than three millennia. These tablets are typicallyfound in the Middle East and contain a total amount of written words comparable to alldocuments in Latin or ancient Greek. In previous work we have shown how to extract vectordrawings from 3D-models similar to those manually drawn over digital photographs. Bothtypes of drawings share the Scalable Vector Graphic (SVG) format representing thecuneiform characters as splines. These splines are transformed into a graph representationand extend these by triangulation. Based on graph kernel methods we show a similaritymetric for cuneiform characters; which have higher degrees of freedom than handwriting …,*,2015,6
Computational Narratology: Extracting Tense Clusters from Narrative Texts.,Thomas Bögel; Jannik Strötgen; Michael Gertz,Abstract Computational Narratology is an emerging field within the Digital Humanities. In thispaper; we tackle the problem of extracting temporal information as a basis for eventextraction and ordering; as well as further investigations of complex phenomena in narrativetexts. While most existing systems focus on news texts and extract explicit temporalinformation exclusively; we show that this approach is not feasible for narratives. Based ontense information of verbs; we define temporal clusters as an annotation task and validatethe annotation schema by showing that the task can be performed with high inter-annotatoragreement. To alleviate and reduce the manual annotation effort; we propose a rule-basedapproach to robustly extract temporal clusters using a multi-layered and dynamic NLPpipeline that combines off-the-shelf components in a heuristic setting. Comparing our …,LREC,2014,6
A probablistic model for spatio-temporal signal extraction from social media,Christian Sengstock; Michael Gertz; Florian Flatow; Hamed Abdelhaq,Abstract It is nowadays possible to access a huge and increasing stream of social mediarecords. Recently; such data has been used to infer about spatio-temporal phenomena bytreating the records as proxy observations of the real world. However; since suchobservations are heavily uncertain and their spatio-temporal distribution is highlyheterogeneous; extracting meaningful signals from such data is a challenging task. In thispaper; we present a probabilistic model to extract spatio-temporal distributions ofphenomena (called spatio-temporal signals) from social media. Our approach models spatio-temporal and semantic knowledge about real-world phenomena embedded in records onthe basis of conditional probability distributions in a Bayesian network. Through this; werealize a generic and comprehensive model where knowledge and uncertainties about …,Proceedings of the 21st ACM SIGSPATIAL International Conference on Advances in Geographic Information Systems,2013,6
Temporal analysis of document collections: framework and applications,Omar Alonso; Michael Gertz; Ricardo Baeza-Yates,Abstract As the amount of generated information increases so rapidly in the digital world; theconcept of time as a dimension along which information can be organized and exploredbecomes more and more important. In this paper; we present a temporal document analysisframework for document collections in support of diverse information retrieval and seekingtasks. Our analysis is not based on document creation and/or modification timestamps buton extracting time from the content itself. We also briefly sketch some scenarios andexperiments for analyzing documents from a temporal perspective.,International Symposium on String Processing and Information Retrieval,2010,6
In-network detection of anomaly regions in sensor networks with obstacles,Conny Franke; Marcel Karnstedt; Daniel Klan; Michael Gertz; Kai-Uwe Sattler; Elena Chervakova,Abstract In the past couple of years; sensor networks have evolved into an importantinfrastructure component for monitoring and tracking events and phenomena in several;often mission critical application domains. An important task in processing streams of datagenerated by these networks is the detection of anomalies; eg; outliers or bursts; and inparticular the computation of the location and spatial extent of such anomalies in a sensornetwork. Such information is then used as an important input to decision making processes.In this paper; we present a novel approach that facilitates the efficient computation of suchanomaly regions from individual sensor readings. We propose an algorithm to deriveregions with a spatial extent from individual (anomalous) sensor readings; with a particularfocus on obstacles present in the sensor network and the influence of such obstacles on …,Computer Science-Research and Development,2009,6
Access control models for XML,S De Capitani di Vimercati; Sara Foresti; Stefano Paraboschi; Pierangela Samarati,Summary XML has become a crucial tool for data storage and exchange. In this chapter;after a brief introduction on the basic structure of XML; we illustrate the most importantcharacteristics of access control models. We then discuss two models for XML documents;pointing out their main characteristics. We finally present other proposals; describing theirmain features and their innovation compared to the previous two models.,*,2008,6
Extraction of contributor information from software repositories,Omar Alonso; P Devanbu; Michael Gertz,*,Unpublished http://wwwcsif. cs. ucdavis. edu/∼ bird/papers/alonsomsr2006. pdf,2006,6
Indexing Query Regions for Streaming Geospatial Data.,Quinn Hart; Michael Gertz,Abstract This paper introduces the Dynamic Cascade Tree (DCT); a structure designed toindex query regions on multi-dimensional data streams. The DCT is designed for a streammanagement system with a particular focus on Remotely-Sensed Imagery (RSI) datastreams. For these streams; an important query operation is to efficiently restrict incominggeospatial data to specified regions of interest. As nearly every query to an RSI stream has aspatial restriction; it makes sense to optimize specifically for this operation. In addition;spatial data is highly ordered in it's arrival. The DCT takes advantage of this trendiness. Theproblem generalizes to solving many stabbing point queries. While the worst caseperformance is quite bad; the DCT performs very well when the stabbing point exhibitscertain trending characteristics that are common in RSI data streams. This paper …,STDBM,2004,6
Neuroanatomical term generation and comparison between two terminologies,Prashanti R Srinivas; Daniel Gusfield; Oliver Mason; Michael Gertz; Michael Hogarth; James Stone; Edward G Jones; Fredric A Gorin,Abstract An approach and software tools are described for identifying and extractingcompound terms (CTs); acronyms and their associated contexts from textual material that isassociated with neuroanatomical atlases. A set of simple syntactic rules were appended tothe output of a commercially available part of speech (POS) tagger (Qtag v 3.01) that extractsCTs and their associated context from the texts of neuroanatomical atlases. This “hybrid”parser appears to be highly sensitive and recognized 96% of the potentially germaneneuroanatomical CTs and acronyms present in the cat and primate thalamic atlases. Acomparison of neuroanatomical CTs and acronyms between the cat and primate atlas textswas initially performed using exact-term matching. The implementation of string-matchingalgorithms significantly improved the identification of relevant terms and acronyms …,Neuroinformatics,2003,6
Quixote: Building XML Repositories from Topic Specific Web Documents.,Christina Yip Chung; Michael Gertz; Neel Sundaresan,Despite major advancements in information retrieval techniques employed by today's Websearch engines; building applications that allow users to e ciently manage; query; and utilizelarge collections of related Web documents from diverse; highly heterogeneous sources isstill a hard problem. Even in the case where potentially related documents that pertain to thesame topic can be gathered e ciently using; eg; a focused Web crawler; the documents arestill heterogeneous both in terms of structure and presentation; due to different authorship.More importantly; the documents are marked up in HTML for visual rendering purposes; thushampering sophisticated query schemes di erent from simple keyword-based searches. Inthis paper; we outline the concepts and methods underlying Quixote; a system that allowsusers to rapidly build XML document repositories from large collections of topic speci c …,WebDB,2001,6
SubQuery-By-Example: Eine orthogonale Erweiterung von QBE,Alexander Scharnofske; Udo W Lipeck; Michael Gertz,Zusammenfassung In diesem Papier wird eine graphische Anfrage-sprache für relationaleDatenbanken vorgestellt; die den Kern von Query-By-Example (QBE) um parametrisierbareUnteranfragen sowie um Men-gen-und Aggregationsoperatoren erweitert. Dadurch wirdeine größt-mögliche Orthogonalität bei der Formulierung von Anfragen erreicht; die sichzudem modularisieren und wiederverwenden lassen. Die Ausdrucksfähigkeit des QBE-Kerns wird zur streng relationalen Vollständigkeit erweitert. Für alle Erweiterungen läßt sicheine einheitliche und eindeutige Semantik in einem erweiterten Tupelkalkül angeben.Dieser Beitrag behandelt die Sprache “SubQuery-By-Example”(SQBE); ihre formaleSemantik; sowie ihre Übersetzung nach SQL im wesentlichen anhand von typischenBeispielen und berichtet schließlich über eine daraufaufbauende prototypische …,*,1997,6
Terms in time and times in context: A graph-based term-time ranking model,Andreas Spitz; Jannik Strötgen; Thomas Bögel; Michael Gertz,Abstract Approaches in support of the extraction and exploration of temporal information indocuments provide an important ingredient in many of today's frameworks for text analysis.Methods range from basic techniques; primarily the extraction of temporal expressions andevents from documents; to more sophisticated approaches such as ranking of documentswith respect to their temporal relevance to some query term or the construction of timelines.Almost all of these approaches operate on the document level; that is; for a collection ofdocuments a timeline is extracted or a ranked list of documents is returned for a temporalquery term. In this paper; we present an approach to characterize individual dates; whichcan be of different granularities; and terms. Given a query date; a ranked list of terms isdetermined that are highly relevant for that date and best summarize the date …,Proceedings of the 24th International Conference on World Wide Web,2015,5
A spatial LDA model for discovering regional communities,Tran Van Canh; Michael Gertz,Models and techniques for the extraction and analysis of communities from social networkdata have become a major area of research. Most of the prominent approaches exploit thelink structure among users based on; eg; information about followers or the exchange ofmessages among users. However; there are also other types of information that are usefulfor extracting communities from social network data; such as geographic informationassociated with postings and users. In this paper; we present a novel approach to discoverso-called regional communities. Motivated by the fact that more and more postings to socialnetworks include the geo-location of users; we claim that communities also form even if theirusers do not necessarily interact but are posting (similar) messages in both spatial andtemporal proximity. To discover such regional communities we propose a generative …,Advances in Social Networks Analysis and Mining (ASONAM); 2013 IEEE/ACM International Conference on,2013,5
Exploration and comparison of geographic information sources using distance statistics,Christian Sengstock; Michael Gertz,Abstract Given the steadily increasing amount of geographic information on the Web; thereis a strong need for suitable methods in exploratory data analysis that can be used toefficiently describe the characteristics of such large-scale; often noisy datasets. Existingmethods in spatial data mining focus primarily on mining patterns describing spatialproximity relationships such as co-location patterns or spatial associations rules. In thispaper; we present a novel approach to describe the spatial characteristics of geographicinformation sources comprised of instances of geographic features. Using the concept ofinteraction characteristics of geographic features; similarities in how features are distributedin space can be computed and interesting patterns of similar features in the datasetsregarding their geographic semantics (landmark; local; regional; global) can be …,Proceedings of the 19th ACM SIGSPATIAL International Conference on Advances in Geographic Information Systems,2011,5
Detection of intrusions and malware and vulnerability assessment,R Büschkes; Pavel Laskov,*,Proc. of Third International Conference DIMVA,2006,5
Web-based scholarship: annotating the digital library,Bruce Rosenstock; Michael Gertz,Abstract The DL offers the possibility of collaborative scholarship; but the ap propriate toolsmust be integrated within the DL to serve this purpose. We propose a Web-based tool toguide controlled data annotations that link items in the DL to a domain-specific ontology andwhich provide an effective means to query a data collection in an abstract and uniformfashion.,Proceedings of the 1st ACM/IEEE-CS joint conference on Digital libraries,2001,5
A visual query language for temporal databases,Vram Kouramajian; Michael Gertz,Abstract This paper addresses the issue of visual query formulation for temporal databases.We introduce a number of visual constructs that allow users to build queries in a modular;bottom {up fashion based on a temporal Extended Entity {Relationship Model. Theseconstructs are: Temporal projection; temporal selection; time links; ltering and set operators;and temporal aggregates.,*,1995,5
Efficient online extraction of keywords for localized events in twitter,Hamed Abdelhaq; Michael Gertz; Ayser Armiti,Abstract Messages published via social media sites; such as Twitter; Facebook; andFoursquare hide a considerable amount of information about real world events. The timelyidentification of such events from this huge; unstructured; and noisy user-generated contentplays an important role in increasing situation awareness and in supporting usefulapplications such as recommendation systems. Interestingly; a large number of thesemessages are enriched with location information; due to the recent advancements of today'slocation acquisition techniques. This; in turn; enables location-aware event mining; ie; thedetection and tracking of localized events such as sport events; demonstrations; or trafficjams; to name but a few. The main building blocks of a localized event are local keywordsthat exhibit a surge in usage at the event location. In this paper; we propose an approach …,GeoInformatica,2017,4
Heideltoul: A baseline approach for cross-document event ordering,Bilel Moulahi; Jannik Strötgen; Michael Gertz; Lynda Tamine,Abstract In this paper; we give an overview of our participation in the timeline generationtask of SemEval-2015 (task 4; TimeLine: Cross-Document Event Ordering). The main goalsof this new track are; given a collection of news articles and a so-called target entity; todetermine events that are relevant for the entity; to resolve event coreferences; and to orderthe events chronologically. We addressed the sub-tasks; in which event mentions wereprovided; ie; no additional event extraction was required. For this; we developed an ad-hocapproach based on a temporal tagger and a coreference resolution tool for entities. Afterdetermining relevant sentences; relevant events are extracted and anchored on a timeline.The evaluation conducted on three collections of news articles shows that our approach–despite its simplicity–achieves reasonable results and opens several promising issues for …,Proceedings of the 9th International Workshop on Semantic Evaluation (SemEval 2015),2015,4
Vertex Similarity-A Basic Framework for Matching Geometric Graphs.,Ayser Armiti; Michael Gertz,Abstract. Solutions to the graph matching problem play an important role in many applicationdomains; such as chemistry; proteomics; or image processing. Especially in these domains;graphs have geometric properties that describe the positions of the vertices in some 2-or 3-dimensional space. Several exact and approximate approaches have been proposed toaddress the problem of matching graphs; which is known to be NP-hard in general. For this;most approaches depend on the concept of vertex similarity to iteratively increase thematching quality. In this paper; we study the vertex similarity problem for geometric graphs.We formally define such a problem and prove that its complexity is NP-hard. For geometricgraphs in 2D; we propose an approximate solution with polynomial runtime. For this; weutilize techniques underlying attributed cyclic string matching and customized edit …,LWA,2014,4
Geometric graph matching and similarity: a probabilistic approach,Ayser Armiti; Michael Gertz,Abstract Finding common structures is vital for many graph-based applications; such as roadnetwork analysis; pattern recognition; or drug discovery. Such a task is formalized as theinexact graph matching problem; which is known to be NP-hard. Several graph matchingalgorithms have been proposed to find approximate solutions. However; such algorithms stillface many problems in terms of memory consumption; runtime; and tolerance to changes ingraph structure or labels. In this paper; we propose a solution to the inexact graph matchingproblem for geometric graphs in 2D space. Geometric graphs provide a suitable modelingframework for applications like the above; where vertices are located in some 2D space. Themain idea of our approach is to formalize the graph matching problem in a maximumlikelihood estimation framework. Then; the expectation maximization technique is used to …,Proceedings of the 26th International Conference on Scientific and Statistical Database Management,2014,4
HeidelTime at EVENTI: Tuning Italian Resources and Addressing TimeML’s Empty Tags,Giulio Manfredi; Jannik Strötgen; Julian Zell; Michael Gertz,Abstract English. In this paper; we describe our participation in the EVENTI task. Weaddressed subtask A; the extraction and normalization of temporal expressions in Italiantexts; by adapting our existing multilingual temporal tagger HeidelTime. In addition toimproving its ability to handle Italian texts; we added further functionality to support emptytags. Based on the main evaluation criterion; HeidelTime ranked first among theparticipating systems. The new HeidelTime version is publicly available. 1 Italiano. In questoarticolo descriviamo la nostra partecipazione al task EVENTI. Ci siamo dedicati al sottotaskA; cioè l'estrazione e normalizzazione di espressioni temporali all'interno di testi in linguaitaliana; ea questo scopo abbiamo adattato il nostro temporal tagger multilingue;HeidelTime. Oltre a migliorare le sue capacità di elaborare testi in italiano; abbiamo …,Proceedings of the Forth International Workshop EVALITA,2014,4
Reliable spatio-temporal signal extraction and exploration from human activity records,Christian Sengstock; Michael Gertz; Hamed Abdelhaq; Florian Flatow,Abstract Shared multimedia; microblogs; search engine queries; user comments; andlocation check-ins; among others; generate an enormous stream of human activity records.Such records consist of information in the form of text; images; or videos; and can often betraced in time and space using associated time/location information. Over the past yearssuch spatio-temporal activity streams have been heavily studied with the aim to extract andexplore spatio-temporal phenomena; like events; place descriptions; and geographicaltopics. Despite the clear intuition and often simple techniques to extract such knowledge; theamount of noise; sparsity; and heterogeneity in the data makes such tasks non-trivial anderroneous. This demonstration offers a visual interface to compare; combine; and evaluatespatio-temporal signal extraction and exploration approaches from large-scale sets of …,International Symposium on Spatial and Temporal Databases,2013,4
Integrity and Internal Control in Information Systems V: IFIP TC11/WG11. 5 Fifth Working Conference on Integrity and Internal Control in Information Systems (IICIS)...,Michael Gertz,Integrity and Internal Control in Information Systems V represents a continuation of thedialogue between researchers; information security specialists; internal control specialistsand the business community. The objectives of this dialogue are:-To present methods andtechniques that will help business achieve the desired level of integrity in informationsystems and data;-To present the results of research that may be used in the near future toincrease the level of integrity or help management maintain the desired level of integrity;-Toinvestigate the shortcomings in the technologies presently in use; shortcomings that requireattention in order to protect the integrity of systems in general. The book contains a collectionof papers from the Fifth International Working Conference on Integrity and Internal Control inInformation Systems (IICIS); sponsored by the International Federation for Information …,*,2013,4
Heuristic algorithms for the protein model assignment problem,Jörg Hauser; Kassian Kobert; Fernando Izquierdo-Carrasco; Karen Meusemann; Bernhard Misof; Michael Gertz; Alexandros Stamatakis,Abstract Assigning an optimal combination of empirical amino acid substitution models (eg;WAG; LG; MTART) to partitioned multi-gene datasets when branch lengths across partitionsare linked; is suspected to be an NP-hard problem. Given p partitions and the approximately20 empirical protein models that are available; one needs to compute the log likelihoodscore of 20 p possible model-to-partition assignments for obtaining the optimal assignment.Initially; we show that protein model assignment (PMA) matters for empirical datasets in thesense that different (optimal versus suboptimal) PMAs can yield distinct final tree topologieswhen tree searches are conducted using RAxML. In addition; we introduce and test severalheuristics for finding near-optimal PMAs and present generally applicable techniques forreducing the execution times of these heuristics. We show that our heuristics can find …,International Symposium on Bioinformatics Research and Applications,2013,4
Modeling satellite image streams for change analysis,Carlos Rueda; Michael Gertz,Abstract Fast detection of changes in environmental remotely sensed data is a majorrequirement in the Earth sciences; especially in natural disaster related scenarios. Assatellite; transmission; and network technologies continue to improve; the real-time streamprocessing and delivery of geospatial data from remote sensors requires a systematicapproach for change analysis and visualization in a streaming fashion. Although variousapproaches have been formulated to model the inherent spatial-temporal-spectralcomplexity of remotely sensed satellite data; there are still challenging peculiarities thatdemand a precise characterization in the context of environmental change detection. In thispaper; we present a formal characterization of fundamental operational aspects for theunambiguous specification of change detection and visualization queries in a streaming …,Proceedings of the 15th annual ACM international symposium on Advances in geographic information systems,2007,4
Evaluation of a dynamic tree structure for indexing query regions on streaming geospatial data,Quinn Hart; Michael Gertz; Jie Zhang,Abstract Most recent research on querying and managing data streams has concentrated ontraditional data models where the data come in the form of tuples or XML data. Complextypes of streaming data; in particular spatio-temporal data; have primarily been investigatedin the context of moving objects and location-aware services. In this paper; we study queryprocessing and optimization aspects for streaming (RSI) data. Streaming RSI is typical forthe vast amount of imaging satellites orbiting the Earth; and it exhibits certain characteristicsthat make it very attractive to tailored query optimization techniques. Our approach uses aDynamic Cascade Tree (DCT) to (1) index spatio-temporal query regions associated withcontinuous user queries and (2) efficiently determine what incoming RSI data is relevant towhat queries. The (DCT) supports the processing of different types of RSI data; ranging …,International Symposium on Spatial and Temporal Databases,2005,4
An Environment for Integrity-Centered Database Design,Michael Gertz; Udo W Lipeck,Abstract The speci cation and transformation of integrity constraints into integrity maintainingmechanisms forms a main task in the database design process. Since these transformationsrequire a lot of administration for combining; re ning; and revising elements of a databaseschema like static and dynamic integrity constraints; transactions and triggers; a computer-aided design environment is strongly needed.,*,1994,4
Metastore: a metadata framework for scientific data repositories,Ajinkya Prabhune; Hasebullah Ansari; Anil Keshav; Rainer Stotzka; Michael Gertz; Jürgen Hesser,In this paper; we present MetaStore; a metadata management framework for scientific datarepositories. Scientific experiments are generating a deluge of data and metadata. Metadatais critical for scientific research; as it enables discovering; analysing; reusing; and sharing ofscientific data. Moreover; metadata produced by scientific experiments is heterogeneousand subject to frequent changes; demanding a flexible data model. Currently; there does notexist an adaptive and a generic solution that is capable of handling heterogeneousmetadata models. To address this challenge; we present MetaStore; an adaptive metadatamanagement framework based on a NoSQL database. To handle heterogeneous metadatamodels and standards; the MetaStore automatically generates the necessary software code(services) and extends the functionality of the framework. To leverage the functionality of …,Big Data (Big Data); 2016 IEEE International Conference on,2016,3
With a little help from my neighbors: person name linking using the Wikipedia social network,Johanna Geiß; Michael Gertz,Abstract Driven by the popularity of social networks; there has been an increasing interest inemploying such networks in the context of named entity linking. In this paper; we present anovel approach to person name disambiguation and linking that uses a large-scale socialnetwork extracted from the English Wikipedia. First; possible candidate matches for anambiguous person name are determined. With each candidate match; a networksubstructure is associated. Based on the similarity between these network substructures andthe latent network of an ambiguous person name in a document; we propose an efficientranking method to resolve the ambiguity. We demonstrate the effectiveness of our approach;resulting in an overall precision of over 96% for disambiguating person names and linkingthem to real world entities.,Proceedings of the 25th International Conference Companion on World Wide Web,2016,3
Time will tell: Temporal linking of news stories,Thomas Bögel; Michael Gertz,Abstract Readers of news articles are typically faced with the problem of getting a goodunderstanding of a complex story covered in an article. However; as news articles mainlyfocus on current or recent events; they often do not provide sufficient information about thehistory of an event or topic; leaving the user alone in discovering and exploring other newsarticles that might be related to a given article. This is a time consuming and non-trivial task;and the only help provided by some news outlets is some list of related articles or a few linkswithin an article itself. What further complicates this task is that many of today's news storiescover a wide range of topics and events even within a single article; thus leaving the realmof traditional approaches that track a single topic or event over time. In this paper; wepresent a framework to link news articles based on temporal expressions that occur in the …,Proceedings of the 15th ACM/IEEE-CS joint conference on digital libraries,2015,3
An event-based framework for the semantic annotation of locations,Anh Le; Michael Gertz; Christian Sengstock,Abstract There is an increasing number of Linked Open Data sources that provideinformation about geographic locations; eg; GeoNames or LinkedGeoData. There are alsonumerous data sources managing information about events; such as concerts or festivals.Suitably combining such sources would allow to answer queries such as 'When and wheredo live-concerts most likely occur in Munich?'or 'Are two locations similar in terms of theirevents?'. Deriving correlations between geographic locations and event data; at differentlevels of abstraction; provides a semantically rich basis for location search; topic-basedlocation clustering or recommendation services. However; little work has been done yet toextract such correlations from event datasets to annotate locations. In this paper; we presentan approach to the discovery of semantic annotations for locations from event data. We …,East European Conference on Advances in Databases and Information Systems,2014,3
Mining Periodic Event Patterns from RDF Datasets,Anh Le; Michael Gertz,Abstract Exposing and sharing data and information using linked data sources is becominga major theme on the Web. Several approaches have been developed to model andefficiently query and match linked open data; primarily represented as RDF graphs fromRDF facts and associated ontological frameworks. Interestingly; little work has yet beenconducted to discover interesting patterns from such data. In this paper; we present anapproach that aims at discovering interesting periodic event patterns from RDF factsdescribing events; for example; music events or festivals. Our focus is on exploiting thetemporal and geographic properties associated with such event descriptions as well as theconcept hierarchies used to categorize the different components of event facts. Discoveredpatterns of periodic events can be used for prediction or detection of outliers in RDF …,East European Conference on Advances in Databases and Information Systems,2013,3
EvenPers: Event-based Person Exploration and Correlation.,Christian Kapp; Jannik Strötgen; Michael Gertz,Abstract: Searching for people on the Internet is one of the most frequent search activities. Inthis paper; we present EvenPers; a system for the event-based exploration of persons andperson similarities. We address challenges such as cross-document person namenormalization and present a novel approach to calculate person similarities based on theirevent information. In our demonstration; we show several exploration scenarios illustratingthe usefulness of EvenPers and its exciting functionality.,BTW,2013,3
Retro: time-based exploration of product reviews,Jannik Strötgen; Omar Alonso; Michael Gertz,Abstract Most e-commerce websites organize and present product reviews around ratingswith hardly any feature to view them in a time-oriented way. Often; there is a way to sortreviews by time but no further temporal analysis is possible. Thus; usually; only few reviewsare part of a user's review analysis process; and there is no way to analyze all reviews of aproduct collectively. In this paper; we describe Retro; a search engine for exploring productreviews using temporal information.,European Conference on Information Retrieval,2012,3
Exploring volunteered geographic information using scaledependent frequent pattern mining,Christian Sengstock; Michael Gertz,There is an explosion of geographic information generated by individuals on the Web. Usersprovide geotagged photos and tweets; geotag Wikipedia articles; create gazetteer entries;update geographic databases like OpenStreetMap (OSM) and much more. Such user-generated geodata; also called Volunteered Geographic Information; VGI (Goodchild 2007);is becoming an important source for geo-services like map generation; routing; search;spatial analysis and mashups. Different from traditional geodata; VGI often has no distinctclassifying attributes or explicit taxonomy. Users are free to create new tagging schemas oradd new properties or text. Although some schema checks may exist on the editor levelthrough auto-completion or templates; these checks are not strict and can be ignored by theuser. Analyzing the dynamic and heterogeneous schemas of VGI to find common …,Proceedings of GIScience,2010,3
Implementation of the COBIT-3 maturity model in Royal Philips Electronics,Alfred CE van Gils,Abstract Philips has an ongoing Business Excellence program for all business functions;including IT. As part of this program the COBIT standard from the IT Governance Institute TMis used to do maturity (self) assessments on IT processes. The program is implementedworldwide using 10 steps including; a workshop approach; improvement management;relation to the internal control framework; organisation and communication.,*,2002,3
Data annotation in collaborative research environments,Michael Gertz,In several of today's scientific application domains; in particular the computational sciences;the transparent and integrated access to distributed and heterogeneous collections ofscientific data is key to leveraging the knowledge and findings of researchers. Standarddatabase integration approaches; however; are either not applicable or insufficient due tothe lack of local and global (database-like) schema structures. In such domains; dataintegration often occurs” manually” in that remote data is copied into local repositories or”semantically indexed” through different forms of book-marking. Naturally; such techniquesdo not provide for rich data querying; sharing; and management techniques in suchenvironments. It is well accepted that the creation; management; and utilization of differentforms of metadata play a major role in realizing information system infrastructures that …,Workshop on Data Derivation and Provenance,2002,3
EVELIN: Exploration of Event and Entity Links in Implicit Networks,Andreas Spitz; Satya Almasian; Michael Gertz,Abstract Implicit networks that describe latent entity relations have been demonstrated to bevaluable tools in information retrieval; knowledge extraction; and search in documentcollections. While such implicit relations offer less insight into the types of connectionbetween entities than traditional knowledge bases; they are much easier to extract fromunstructured textual sources. Furthermore; they allow the derivation of relationship strengthbetween entities that can be used to identify and leverage important co-mentions; based onwhich complex constructs of semantically related entities can be assembled with ease. Oneexample of such implicit networks are LOAD graphs; which encode the textual proximity oflocation-; organization-; actor-; and date-mentions in document collections for theexploration; identification and summarization of events and entity relations. Here; we …,Proceedings of the 26th International Conference on World Wide Web Companion,2017,2
Breaking the news: Extracting the sparse citation network backbone of online news articles,Andreas Spitz; Michael Gertz,Abstract Networks of online news articles and blog posts are some of the most commonlyused data sets in network science. As a result; they have become a vital piece of networkanalysis and are used for the evaluation of algorithms that work on large networks; or serveas examples in the analysis of information diffusion and propagation. Similarly; scientificcitation networks are part of the bedrock upon which much of modern network analysis isbuilt and have been studied for decades. In this paper; we show that the backbone inherentto networks of online news articles shares significant structural similarities to scientificcitation networks once the noise of spurious links is stripped away. We present a data set ofnews articles that; while it is extremely sparse and lightweight; still contains informationrelevant to the propagation of information in mass media and is remarkably similar to …,Proceedings of the 2015 IEEE/ACM International Conference on Advances in Social Networks Analysis and Mining 2015,2015,2
A Hybrid Approach to Extract Temporal Signals from Narratives.,Thomas Bögel; Jannik Strötgen; Michael Gertz,Abstract When processing literary narratives; standard temporal annotation specifications–typically developed for processing newsstyle documents–do not match the expectations ofliterary scholars. Thus; a different definition of temporal signals is required. In this paper; wedefine this concept from the narratological perspective and present our hybrid approachdeveloped in the context of the heureCL EA1 project to extract temporal signals. Ourevaluation demonstrates high quality extraction results; making the approach directlyapplicable to the literary domain.,GSCL,2015,2
Collaborative Text Annotation Meets Machine Learning: heureCLÉA; a Digital Heuristic of Narrative,Thomas Bögel; Michael Gertz; Evelyn Gius; Janina Jacke; Jan Christoph Meister; Marco Petris; Jannik Strötgen; Ryan Cordell; Anne Baillot,This paper is about heureCLÉA 1; an interdisciplinary project for the development of a"digital heuristic" that can support research in narratives by automatically identifyingnarratologically salient features in textual narratives. 2 This heuristic will be integrated in theCATMA (Computer Aided Textual Markup and Analysis) 3 working environment as aprogram module and will provide an automatic annotation functionality that complements themanual annotation functionality already provided by CATMA. While the current projectfocuses on a specific field of application—ie; narratological text analysis and markup—heureCLÉA's methodological approach aims at bridging manual and automated proceduresin a more general sense; thus making it relevant to other digital humanities oriented markupprojects.In heureCLÉA we are currently analyzing and annotating a corpus of 21 short …,DHCommons Journal,2015,2
Anwendung von Frequent Itemset Mining auf nutzergenerierte Geodaten,C Sengstock; M Gertz,*,*,2010,2
Static type-inference for trust in distributed information systems,Premkumar T Devanbu; Michael Gertz; Brian Toone,Abstract Decision-makers in critical fields such as medicine and finance make use of a widerange of information available over the Internet. Mediation; a data integration technique fordistributed; heterogeneous data sources; manages the complexity and diversity of theinformation schemas on behalf of clients. We raise here the issue of trust: is the informationso obtained trustworthy? Each client can have different perspectives on the desiredtrustworthiness the information he or she needs. We consider here the scaling problem thatarises from a very large number of users accessing information from many different sources.A mediator cannot be expected to manage the potentially quadratic scaling of trustrelationships clients can have with information sources. Furthermore; the possibility of usinguntrustworthy data increases the risk that the resulting data will be unacceptable: a …,OTM Confederated International Conferences" On the Move to Meaningful Internet Systems",2003,2
On tree pattern constraints for XML documents,April Kwong; Michael Gertz,Abstract In this paper; we introduce the concept of tree pattern constraints (XTPCs) for XMLdocuments as a pattern-based schema formalism founded on XPath. XTPCs provide aneffective means to specify conditions on path or tree patterns that XML documents have tosatisfy. Conditions include implication; absence; and co-occurrence of patterns. XTPCs canbe used as stand-alone schema formalisms or in conjunction with a DTD or XML Schema.We study in detail the (bounded) implication and consistency problems for XTPCs; give asound and complete axiomatization as well as complexity results. If used in conjunction witha DTD; we study the consistency problem for XTPCs in the presence of DTDs.,Department of Computer Science; University of California at Davis; Davis; California; United States,2003,2
Monitoring mission critical data for integrity and availability,Michael Gertz; George Csaba,Abstract Protecting the integrity; confidentiality; and availability of mission critical data is oneof the primary objectives of IT departments in industry; government; and research. Standardtechniques to realize these objectives are often confined to network-and host-basedintrusion detection systems; which are known to be inappropriate for handling securitythreats caused by insiders. This paper introduces the concept of data monitoring systems asan additional line of defense against external and internal security threats. These systems;which are closely coupled with a database managing mission critical data; provide ITpersonnel with effective means for specifying; detecting; and responding to anomalousbehavior of data and data accesses caused by users and applications.,*,2003,2
Achieving semantic interoperability through controlled annotations,Michael Gertz,We consider the main goal of a Digital Library as to provide individual users andcollaborative research groups with a uniform and integrated access to a large collection ofheterogeneous data. The major hindrance in creating a respective infrastructure is tointegrate relevant data residing at different sites and encoded in different formats. Althoughrecent developments in high-speed networks and data protocols have achieved areasonably high degree of physical connectivity; that is; the fast exchange of bits and bytesamong computer systems; the logical connectivity; ie; the meaningful exchange andquerying of data; is far behind what is needed in current information system infrastructuresfor Digital Libraries. Describing data using metadata has proven to be useful not only forintegrating data from different sources; but also for better information retrieval methods …,Position paper; US-Korea joint workshop on digital libraries; Sand Diego,2000,2
Medical Database Security,David B Hill; M Gertz,What do people tell their doctor? What do people expect their doctor to tell others? What dopeople expect their doctor to not tell others? This last question is one that is becoming moreworrisome in the minds of the public. Needless to say; this concern is driven by theexponential increase in value of information that comes with the ability to rapidly andtransparently connect one computer with another via the internet. Any paper that discussessecurity must acknowledge that security is a somewhat general term that typically is used todenote three interrelated concepts: confidentiality; integrity and availability. This paper shallrestrict its focus to just the first component; but only because it serves as a foundation for allthree aspects. The concept of confidentiality in the medical record is a long standing one; tosay the least. Indeed; one of the oldest portions of themedical literature is the Hippocratic …,Advanced Database Systems ECS F,1998,2
NECKAr: A Named Entity Classifier for Wikidata,Johanna Geiß; Andreas Spitz; Michael Gertz,Abstract Many Information Extraction tasks such as Named Entity Recognition or EventDetection require background repositories that provide a classification of entities into thebasic; predominantly used classes location; person; and organization. Several availableknowledge bases offer a very detailed and specific ontology of entities that can be used as arepository. However; due to the mechanisms behind their construction; they are relativelystatic and of limited use to IE approaches that require up-to-date information. In contrast;Wikidata is a community-edited knowledge base that is kept current by its userbase; but hasa constantly evolving and less rigid ontology structure that does not correspond to thesebasic classes. In this paper we present the tool NECKAr; which assigns Wikidata entities tothe three main classes of named entities; as well as the resulting Wikidata NE dataset that …,International Conference of the German Society for Computational Linguistics and Language Technology,2017,1
Managing Provenance for Medical Datasets,Ajinkya Prabhune; Rainer Stotzka; Michael Gertz; Lei Zheng; Jürgen Hesser,2Database Systems Research Group; Institute of Computer Science; Heidelberg University;Heidelberg; Germany 3Experimental Radiation Oncology; Medical Faculty Mannheim;Heidelberg University; Mannheim; Germany 4Experimental Radiation Oncology; IWR;Heidelberg University; Heidelberg; Germany {ajinkya. prabhune; rainer. stotzka}@ kit. edu;gertz@ informatik. uni-heidelberg. de;{lei. zheng; juergen. hesser}@ medma. uni-heidelberg. de,BIOSTEC 2017,2017,1
MetaStore: an adaptive metadata management framework for heterogeneous metadata models,Ajinkya Prabhune; Rainer Stotzka; Vaibhav Sakharkar; Jürgen Hesser; Michael Gertz,Abstract In this paper; we present MetaStore; a metadata management framework forscientific data repositories. Scientific experiments are generating a deluge of data; and thehandling of associated metadata is critical; as it enables discovering; analyzing; reusing;and sharing of scientific data. Moreover; metadata produced by scientific experiments areheterogeneous and subject to frequent changes; demanding a flexible data model. Existingmetadata management systems provide a broad range of features for handling scientificmetadata. However; the principal limitation of these systems is their architecture design thatis restricted towards either a single or at the most a few standard metadata models. Supportfor handling different types of metadata models; ie; administrative; descriptive; structural; andprovenance metadata; and including community-specific metadata models is not possible …,Distributed and Parallel Databases,2017,1
HeidelPlace: An Extensible Framework for Geoparsing,Ludwig Richter; Johanna Geiß; Andreas Spitz; Michael Gertz,Abstract Geographic information extraction from textual data sources; called geoparsing; is akey task in text processing and central to subsequent spatial analysis approaches. Severalgeoparsers are available that support this task; each with its own (often limited orspecialized) gazetteer and its own approaches to toponym detection and resolution. In thisdemonstration paper; we present HeidelPlace; an extensible framework in support ofgeoparsing. Key features of HeidelPlace include a generic gazetteer model that supports theintegration of place information from different knowledge bases; and a pipeline approachthat enables an effective combination of diverse modules tailored to specific geoparsingtasks. This makes HeidelPlace a valuable tool for testing and evaluating different gazetteersources and geoparsing methods. In the demonstration; we show how to set up a …,Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing: System Demonstrations,2017,1
Refining imprecise spatio-temporal events: a network-based approach,Andreas Spitz; Johanna Geiß; Michael Gertz; Stefan Hagedorn; Kai-Uwe Sattler,Abstract Events as composites of temporal; spatial and actor information are a central objectof interest in many information retrieval (IR) scenarios. There are several challenges to suchevent-centric IR; which range from the detection and extraction of geographic; temporal andactor mentions in documents to the construction of event descriptions as triples of locations;dates; and actors that can support event query scenarios. For the latter challenge; existingapproaches fall short when dealing with imprecise event components. For example; if theexact location or date is unknown; existing IR methods are often unaware of differentgranularity levels and the conceptual proximity of dates or locations. To address theseproblems; we present a framework that efficiently answers imprecise event queries; whosegeographic or temporal component is given only at a coarse granularity level. Our …,Proceedings of the 10th Workshop on Geographic Information Retrieval,2016,1
A framework for scalable correlation of spatio-temporal event data,Stefan Hagedorn; Kai-Uwe Sattler; Michael Gertz,Abstract Spatio-temporal event data do not only arise from sensor readings; but also ininformation retrieval and text analysis. However; such events extracted from a text corpusmay be imprecise in both dimensions. In this paper we focus on the task of event correlation;ie; finding events that are similar in terms of space and time. We present a framework forApache Spark that provides correlation operators that can be configured to deal with suchimprecise event data.,British International Conference on Databases,2015,1
Spatial itemset mining: a framework to explore itemsets in geographic space,Christian Sengstock; Michael Gertz,Abstract Driven by the major adoption of mobile devices; user contributed geographicinformation has become ubiquitous. A typical example is georeferenced and tagged socialmedia; linking a location to a set of features or attributes. Mining frequent sets of discreteattributes to discover interesting patterns and rules of attribute usage in such data sets is animportant data mining task. In this work we extend the frequent itemset mining framework tomodel the spatial distribution of itemsets and association rules. For this; we expect the inputtransactions to have an associated spatial attribute; as; for example; present ingeoreferenced tag sets. Using the framework; we formulate interestingness measures thatare based on the underlying spatial distribution of the input transactions; namely area;spatial support; location-conditional support; and spatial confidence. We show that …,East European Conference on Advances in Databases and Information Systems,2013,1
Proximity2-aware Ranking for Textual; Temporal; and Geographic Queries (extended version),Jannik Strötgen; Michael Gertz,Abstract. Temporal and geographic information needs are frequent and important but notwell served by standard IR systems. There are neither good ways to add temporal orgeographic constraints to a normal text query; nor are geographic and temporal expressionsin the documents interpreted as such kind of information; ie; their semantics is not exploited.Recent approaches address such needs by extracting and normalizing temporal andgeographic expressions from documents. They calculate specific scores for the temporaland/or geographic parts of a query. However; all approaches assume independencebetween the different query parts. In this paper; we present a new model to rank documentsaccording to combined textual; temporal; and geographic queries. In this model; theindependence assumption between the query parts is eliminated by calculating different …,*,2013,1
Event-centric Document Similarity for Biomedical Literature,Brita Keller; Jannik Strötgen; Michael Gertz,Abstract Identifying similar documents for a given query document helps users to explorelarge document collections. However; most existing techniques are based on the vectorspace model and handle documents only as bags of words. Thus; more complex informationthat can be used for calculating similarities is not taken into account. For example; eventsplay an important role in the biomedical literature and could be valuable to identify similardocuments. In this paper; we present an event-centric document similarity model forbiomedical literature and demonstrate the effectiveness of our approach based onexperiments using the GENIA corpus.,Proceedings of the 5th International Symposium on Semantic Mining in Biomedicine (SMBM’12),2012,1
Latent contextual indexing of annotated documents,Christian Sengstock; Michael Gertz,Abstract In this paper we propose a simple and flexible framework to index context-annotated documents; eg; documents with timestamps or georeferences; by contextualtopics. A contextual topic is a distribution over document features with a particular meaningin the context domain; such as a repetitive event or a geographic phenomenon. Such aframework supports document clustering; labeling; and search; with respect to contextualknowledge contained in the document collection. To realize the framework; we introduce anapproach to project documents into a context-feature space. Then; dimensionality reductionis used to extract contextual topics in this context-feature space. The topics can then beprojected back onto the documents. We demonstrate the utility of our approach with a casestudy on georeferenced Wikipedia articles.,Proceedings of the 21st International Conference on World Wide Web,2012,1
Online Hot Spot Prediction in Road Networks.,Maik Häsner; Conny Junghans; Christian Sengstock; Michael Gertz,Abstract: Advancements in GPS-technology have spurred major research and developmentactivities for managing and analyzing large amounts of position data of mobile objects. Datamining tasks such as the discovery of movement patterns; classification and outlier detectionin the context of object trajectories; and the prediction of future movement patterns havebecome basic tools in extracting useful information from such position data. Especially theprediction of future movement patterns of vehicles; based on historical or recent positiondata; plays an important role in traffic management and planning. In this paper; we present anew approach for the online prediction of so-called hot spots; that is; components of a roadnetwork such as intersections that are likely to experience heavy traffic in the near future. Forthis; we employ an efficient path prediction model for vehicle movements that only utilizes …,BTW,2011,1
Time and information retrieval,Omar Alonso; Michael Gertz,There are two kinds of tables: frequency tables that display the count of respondents at thecrossing of the categorical attributes (in N) and magnitude tables that display information ona numerical attribute at the crossing of the categorical attributes (in R). For example; givensome census microdata containing attributes “Job” and “Town;” one can generate afrequency table displaying the count of respondents doing each job type in each town. If thecensus microdata also contain the “Salary;” attribute; one can generate a magnitude tabledisplaying the average salary for each job type in each town. The number n of cells in atable is normally much less than the number r of respondent records in a microdata file.However; tables must satisfy several linear constraints: marginal row and column totals.Additionally; a set of tables is called linked if they share some of the crossed categorical …,*,2009,1
Integrity; internal control and security in information systems: connecting governance and technology,Michael Gertz; Erik Guldentops; Leon AM Strous,IT Governance is finally getting the Board's and top management's attention. The value thatIT needs to return and the associated risks that need to be managed; have become soimportant in many industries that enterprise survival depends on it. Information integrity is asignificant part of the IT Governance challenge. Among other things; this conference willexplore how Information Integrity contributes to the overall control and governanceframeworks that enterprises need to put in place for IT to deliver business value and forcorporate officers to be comfortable about the IT risks the enterprise faces. The goals for thisinternational working conference are to find answers to the following questions:• whatprecisely do business managers need in order to have confidence in the integrity of theirinformation systems and their data;• what is the status quo of research and development …,*,2002,1
Authentic Re-Publication by Untrusted Servers: A Novel Approach to Database Survivability,Prem Devanbu; Michael Gertz; Chip Martel; Philip Rogaway; Stuart G Stubblebine,Abstract High-value information; such as geophysical (or cartographic) data;pharmacological information; and business data; which are used in high-value decisions;are frequently made available for on-line querying. Customers dependent on thisinformation for their work need high reliability and accuracy. However; operating such an on-line querying service; securely; on open networks is very difficult. Most large systems havevulnerabilities that can be exploited. An adversary who can break in and publish false datamight cause huge losses for users. Replicating the data service for reliability and scalabilityonly makes matters worse. We introduce a new approach; by which an untrusted publishercan answer queries from customers on behalf of the owner; or creator of the data. With just afew trusted digital signatures from the owner; the untrusted publisher can use techniques …,Third Information Survivability Workshop (ISW-2000); 2000,2000,1
A Flexible NLP Pipeline for Computational Narratology,Thomas Bögel; Jannik Strötgen; Christoph Mayer; Michael Gertz,Temporal dependencies reveal interesting insights into the semantic discourse structure ofnarrative texts. The investigations of literary scientists are; as of today; mostly based on labor-intensive manual annotations. Computational Narratology; an important subtopic of theDigital Humanities; aims at facilitating annotations and supporting literary scientists with theiranalyses. According to Mani (2013); one aspect of Computational Narratology focuses onexploring and testing literary hypotheses through mining narrative structures from corpora. Inthe context of the BMBF-funded eHumanities project heureCL EA; we address temporalphenomena in literary text; a genre whose temporal phenomena are different from others.For example; it is often not possible to anchor temporal expressions to real points in time; butliterary texts tend to have their own time frame. Our project partners; as well as many …,Jahrestagung der Digital Humanities im deutschsprachigen Raum (DHd),*,1
Extracting Descriptions of Location Relations from Implicit Textual Networks,Andreas Spitz; Gloria Feher; Michael Gertz,ABSTRACT For the retrieval of concise entity relation information from large collections orstreams of documents; existing approaches can be grouped into the categories of (multi-document) summarization and knowledge extraction. e former tend to fall short for this taskdue to the involved amount of information that cannot be easily condensed; whileknowledge extraction approaches are o en pa ern-based and too discriminative forexploratory purposes. For location relations in particular; this translates to a set of very shortrelationship descriptors that predominantly encode hierarchical or containment relationssuch as located in or capital of. As a result; available knowledge bases that are typicallypopulated through knowledge extraction are limited to these discrete and typed relations. Incontrast; the representation of document collections as implicit networks of entities; terms …,Proceedings of the 11th Workshop on Geographic Information Retrieval,2017,*
Intrinsic t-Stochastic Neighbor Embedding for Visualization and Outlier Detection,Erich Schubert; Michael Gertz,Abstract Analyzing high-dimensional data poses many challenges due to the “curse ofdimensionality”. Not all high-dimensional data exhibit these characteristics because manydata sets have correlations; which led to the notion of intrinsic dimensionality. Intrinsicdimensionality describes the local behavior of data on a low-dimensional manifold within thehigher dimensional space. We discuss this effect; and describe a surprisingly simpleapproach modification that allows us to reduce local intrinsic dimensionality of individualpoints. While this unlikely will be able to “cure” all problems associated with highdimensionality; we show the theoretical impact on idealized distributions and how topractically incorporate it into new; more robust; algorithms. To demonstrate the effect of thisadjustment; we introduce the novel Intrinsic Stochastic Outlier Score (ISOS); and we …,International Conference on Similarity Search and Applications,2017,*
Advances in Spatial and Temporal Databases: 15th International Symposium; SSTD 2017; Arlington; VA; USA; August 21–23; 2017; Proceedings,Michael Gertz; Matthias Renz; Xiaofang Zhou; Erik Hoel; Wei-Shinn Ku; Agnes Voisard; Chengyang Zhang; Haiquan Chen; Liang Tang; Yan Huang; Chang-Tien Lu; Siva Ravada,This book constitutes the refereed proceedings of the 15th International Symposium onSpatial and Temporal Databases; SSTD 2017; held in Arlington; VA; USA; in August 2017.The 19 full papers presented together with 8 demo papers and 5 vision papers werecarefully reviewed and selected from 90 submissions. The papers are organized around thecurrent research on concepts; tools; and techniques related to spatial and temporaldatabases.,*,2017,*
Semantic Word Clouds with Background Corpus Normalization and t-distributed Stochastic Neighbor Embedding,Erich Schubert; Andreas Spitz; Michael Weiler; Johanna Geiß; Michael Gertz,Abstract: Many word clouds provide no semantics to the word placement; but use a randomlayout optimized solely for aesthetic purposes. We propose a novel approach to model wordsignificance and word affinity within a document; and in comparison to a large backgroundcorpus. We demonstrate its usefulness for generating more meaningful word clouds as avisual summary of a given document. We then select keywords based on their significanceand construct the word cloud based on the derived affinity. Based on a modified t-distributedstochastic neighbor embedding (t-SNE); we generate a semantic word placement. For wordsthat cooccur significantly; we include edges; and cluster the words according to theircooccurrence. For this we designed a scalable and memory-efficient sketch-based approachusable on commodity hardware to aggregate the required corpus statistics needed for …,arXiv preprint arXiv:1708.03569,2017,*
P-PIF: a ProvONE provenance interoperability framework for analyzing heterogeneous workflow specifications and provenance traces,Ajinkya Prabhune; Aaron Zweig; Rainer Stotzka; Jürgen Hesser; Michael Gertz,Abstract Enabling provenance interoperability by analyzing heterogeneous provenanceinformation from different scientific workflow management systems is a novel research topic.With the advent of the ProvONE model; it is now possible to model both the prospective aswell as the retrospective provenance in a single provenance model. Scientific workflows arecomposed using a declarative definition language; such as BPEL; SCUFL/t2flow; or MoML.Associated with the execution of a workflow is its corresponding provenance that is modeledand stored in the data model specified by the workflow system. However; sharing ofprovenance generated by heterogeneous workflows is a challenging task and prevents theaggregate analysis and comparison of workflows and their associated provenance. Toaddress these challenges; this paper introduces a ProvONE-based Provenance …,Distributed and Parallel Databases,2017,*
Enabling rapid cloud-based analysis of thousands of human genomes via Butler,Sergei Yakneen; Sebastian Waszak; Michael Gertz; Jan O Korbel; PCAWG Germline Cancer Genome Working Group; PCAWG Technical Working Group,We present Butler; a computational framework developed in the context of the internationalPan-cancer Analysis of Whole Genomes (PCAWG) project to overcome the challenges oforchestrating analyses of thousands of human genomes on the cloud. Butler operatesequally well on public and academic clouds. This highly flexible framework facilitatesmanagement of virtual cloud infrastructure; software configuration; genomics workflowdevelopment; and provides unique capabilities in workflow execution management. Bycomprehensively collecting and analysing metrics and logs; performing anomaly detectionas well as notification and cluster self-healing; Butler enables large-scale analyticalprocessing of human genomes with 43% increased throughput compared to prior setups.Butler was key for delivering the germline genetic variant call-sets in 2;834 cancer …,bioRxiv,2017,*
Geometric Graph Indexing for Similarity Search in Scientific Databases,Ayser Armiti; Michael Gertz,Abstract Searching a database for similar graphs is a critical task in many scientificapplications; such as in drug discovery; geoinformatics; or pattern recognition. Typically;graph edit distance is used to estimate the similarity of non-identical graphs; which is a veryhard task. Several indexing structures and lower bound distances have been proposed toprune the search space. Most of them utilize the number of edit operations and assumegraphs with a discrete label alphabet that has a certain canonical order. Unfortunately; suchassumptions cannot be guaranteed for geometric graphs where vertices have coordinates insome two dimensional space. In this paper; we study similarity range queries for geometricgraphs with edit distance constraints. First; we propose an efficient index structure todiscover similar vertices. For this; we embed the vertices of different graphs in a higher …,Proceedings of the 28th International Conference on Scientific and Statistical Database Management,2016,*
ACM SIGSPATIAL 2015 conference report: the 23rd ACM SIGSPATIAL International Conference on Advances in Geographic Information Systems (ACM SIGSPATIA...,Michael Gertz; Matthias Renz; Jagan Sankaranarayanan,Abstract This is the conference report of the 23 rd ACM SIGSPATIAL InternationalConference on Advances in Geographic Information Systems (ACM SIGSPATIAL 2015);held in Seattle; Washington; USA; November 3-6; 2015. This conference was the twenty-third edition in a series of symposia and workshops that began in 1993 with the aim ofpromoting interdisciplinary discussions among researchers; developers; users; andpractitioners and fostering research in all aspects of geographic information systems;especially in relation to novel systems based on geospatial data and knowledge. Theconference is the premier annual event of the ACM Special Interest Group on SpatialInformation (ACM SIGSPATIAL) and provides a forum for original research contributionscovering all conceptual; design; and implementation aspects of geospatial data ranging …,SIGSPATIAL Special,2016,*
Prov2ONE: An Algorithm for Automatically Constructing ProvONE Provenance Graphs,Michael Gertz; Juergen Hesser,Abstract. Provenance traces history within workflows and enables researchers to validateand compare their results. Currently; modelling provenance in ProvONE is an arduous taskand lacks an automated approach. This paper introduces a novel algorithm; calledProv2ONE that automatically generates the ProvONE prospective provenance for scientificworkflows defined in BPEL4WS. The same prospective ProvONE graph is updated with therelevant retrospective provenance; preventing provenance to be captured in various non-standard provenance models and thus enabling research communities to share; compareand analyze workflows and its associated provenance. Finally; using the Prov2ONEalgorithm; a ProvONE provenance graph for the nanoscopy workflow is generated.,Provenance and Annotation of Data and Processes: 6th International Provenance and Annotation Workshop; IPAW 2016; McLean; VA; USA; June 7-8; 2016; Proceedings,2016,*
Highlights from ACM SIGSPATIAL GIS 2014: the 22nd ACM SIGSPATIAL International Conference on Advances in Geographic Information Systems (Dallas; Texas;...,Michael Gertz; John Krumm; Jagan Sankaranarayanan,ACM SIGSPATIAL GIS 2014 was held at Dallas; Texas and it was the 22nd gathering of theconference. It is now the seventh time the conference was organized under the auspices ofACM SIGSPATIAL. The conference is the premier event for a variety of researchers;developers; and users who work in related areas to spatial information and GIS. It is aninterdisciplinary gathering and provides a forum for original research contributions that coverconceptual; design; and implementation aspects of spatial information systems and GIS. Theattendance for the 2014 conference was 310. The call for papers attracted 216 paperssubmitted under four categories: research; industry/systems; PhD Showcase; and demo.Specifically; the research and industry/systems categories together attracted 184submissions; the PhD Showcase category received 3 submissions; and the …,SIGSPATIAL Special,2015,*
Did I Really Say That?-Combining Machine Learning and Dependency Relations to Extract Statements from German News Articles.,Thomas Bögel; Michael Gertz,Abstract We present a system to extract statements of public figures from unstructuredGerman news articles. We first motivate and define statements as a temporally-awareextension of quotations and present the three categories of statements:(1) direct;(2) indirect;and (3) mixed-style statements. We use a combination of machine learning and heuristicsbased on dependency parses to tackle all three types of statements. The quality of ourextraction approach is compared to related work in quotation attribution showing that rulesbased on syntactic structures increase the extraction quality compared to lexical patterns. Inaddition; we apply the system on a corpus of German news articles and show that it is ableto extract statements with high precision (82.4%).,GSCL,2015,*
Large-scale Analysis of Event Data.,Stefan Hagedorn; Kai-Uwe Sattler; Michael Gertz,ABSTRACT With the availability of numerous sources and the development of sophisticatedtext analysis and information retrieval techniques; more and more spatio-temporal data areextracted from texts such as news documents or social network data. Temporal andgeographic information obtained this way often form some kind of event; describing whenand where something happened. An important task in the context of business intelligenceand document exploration applications is the correlation of events in terms of their temporal;geographic or even semantic properties. In this paper we discuss the tasks related to eventdata analysis; ranging from the extraction of events to determining events that are similar interms of space and time by using skyline processing and clustering. We present a frameworkimplemented in Apache Spark that provides operators supporting these tasks and thus …,GvD,2015,*
rLinkTopic: A probabilistic model for discovering regional LinkTopic communities,Tran Van Canh; Michael Gertz,Although geographic and regional aspects of communities find many practical applications;eg; in social studies and marketing; to date; existing approaches to community detectionhave paid little attention to these features when analyzing social network data. To addressthese shortcomings; we introduce the concept of regional LinkTopic communities andpropose a novel probabilistic model for extracting such communities. Our model jointlyconsiders the spatio-temporal proximity of users in terms of the messages they post overtime; together with contextual links and message topics to determine communities. Themodel allows users to have a membership in more than just one community; an importantfeature when discovering communities based on topics. Each community derived by ourapproach is not only described by a mixture of topics but also by its regional properties …,Advances in Social Networks Analysis and Mining (ASONAM); 2014 IEEE/ACM International Conference on,2014,*
System for Database Systems,Christina Yip Chung; Michael Gertz; Karl Levitt,Abstract Despite the necessity of protecting information stored in database systems (DBS);existing security models are insufficient to prevent misuse; especially insider abuse bylegitimate users. Further; concepts for misuse detection in DBS have not been adequatelyaddressed by existing research in misuse detection. Even though there are available meansto guard the information stored in a database system against misuse; they are seldom usedby Security officers because Security policies of the organization are either imprecise or notknown at all. This paper presents a misuse detection system called DEMIDS which istailored to relational database systems. DEMIDS uses audit logs to derive profiles thatdescribe typical behavior of users working with the DBS. The profiles computed can be usedto detect misuse behavior; in particular insider abuse. Furthermore; the profiles can serve …,Integrity and Internal Control in Information Systems: Strategic Views on the Need for Control,2013,*
Der Lehrstuhl für Datenbanksysteme am Institut für Informatik der Universität Heidelberg,Michael Gertz,Kooperationsmöglichkeiten unter anderem mit den Geowissenschaften; der Physik undAstronomie; den Lebenswissenschaften und den Geisteswissenschaften insbesondere ander Universität Heidelberg einen fruchtbaren Boden. Ein Hauptaugenmerk der Forschungliegt hierbei auf der Analyse von räumlichen; zeitlichen und räumlich-zeitlichen Daten. Inden oben genannten Disziplinen werden hierzu mit Hilfe neuester Techniken durchExperimente; Beobachtungen und Simulationen enorme Mengen an Daten erzeugt undgesammelt. Die Daten reichen dabei von digitalisierten historischen Schriften bis hin zukomplexen Vektorfeldern; die zB im Rahmen der numerischen Strömungsmechanik erzeugtwerden. Derartige Datenmengen machen eine manuelle Analyse nahezu unmöglich underfordern daher; neben geeigneten Methoden der Visualisierung; entsprechende …,Datenbank-Spektrum,2010,*
Scientific and Statistical Database Management: 22nd International Conference; SSDBM 2010; Heidelberg; Germany; June 30-July 2; 2010; Proceedings,Michael Gertz; Bertram Ludäscher,The International Conference on Scientific and Statistical Database Management (SSDBM)is an established forum for the exchange of the latest research results on concepts; tools;and techniques for scientific database applications. The 2010 meeting marked the 22nd timethat scientific domain experts; databases researchers; practitioners; and developers cametogether to share their insights and to discuss future research directions in a stimulatingenvironment. The conference was held from June 30 to July 2 at Villa Bosch; near the CarlBosch Museum and Heidelberg Castle; overlooking the picturesque Neckar Valley. Theconference was organized at and co-sponsored by Heidelberg University and HITS; theHeidelberg Institute for Theoretical Studies; established in January 2010 by Dr. KlausTschira; co-founder of SAP AG; as a successor to the EML Research Institute. HITS …,*,2010,*
The role of security in scientific data management,Michael Gertz,Abstract In the past three decades; research and development activities in the area of datasecurity have primarily concentrated on security aspects in traditional domains; such as thebusiness and financial sectors; and; more recently; the medical and health care sectors.Interestingly; compared to major advancements made in these domains; resulting incomprehensive and flexible data security frameworks; there is only little work focusing onsecurity aspects specific to the management of data in natural science domains such as thephysical sciences; the life sciences; and the geosciences. Although one can argue thatsecurity models; techniques; and architectures developed for the traditional domains can beadopted; scientific data management activities posses some characteristics where importantand necessary data security features are either non-existent or are poorly developed …,Proceedings of the 2nd SIGSPATIAL ACM GIS 2009 International Workshop on Security and Privacy in GIS and LBS,2009,*
Can an inter-disciplinary research community on location privacy be successful?,Yücel Saygin; Elisa Bertino; Michael Gertz; Mohamed F Mokbel; Maria Luisa Damiani,The newly starting MODAP project (www. modap. org); funded by EU FP7 Future andEmerging Technologies Programme with nearly one million euro funding for three years;aims to coordinate and boost the research activities in the intersection of mobility; datamining; and privacy. The key challenge is to gather an interdisciplinary community of peopleincluding; lawyers; psychologists; computer scientists; geographers; and end-users. Thispanel discusses opportunities; challenges and risks.,SPRINGL,2009,*
Coast-to-Mountain Environmental Transect in Northern California (COMET) as part of the National Environmental Observing Network (NEON),D Zona; SL Ustin; M Gertz; M Falk; QJ Hart,Abstract The investigation of the impacts of climate variability on ecosystem processes is amajor goal of the National Environmental Observing Network (NEON). The Coast-to-Mountain Transect in Northern California (COMET) spans across a wide geographicaltransect that includes major ecosystems in California; from the Pacific Ocean (BodegaMarine Lab; BML) to the Lake Tahoe Environmental Research Center (TERC) at the summitof the Sierra Nevada range. COMET is a pioneer project that aims to develop and test thecyberinfrastructure (CI) required to integrate multiple information necessary for an adequateinvestigation of the complex ecology of the ecosystems across this wide geographicaltransect. The new research will support advanced data acquisition; data storage; datamanagement; data integration; data mining; data visualization and other computing and …,EGU General Assembly Conference Abstracts,2009,*
Einführung in die Praktische Informatik Informatik,Michael Gertz; Christian Sengstock,Page 1. RUPRECHT-KARLS-UNIVERSITÄT HEIDELBERG Institut für Informatik NeuenheimerFeld 348 69120 Heidelberg http://dbs.ifi.uni-heidelberg.de sengstock@informatik.uni-heidelberg.de Prof. Dr. Michael Gertz Christian Sengstock gertz@informatik.uni-heidelberg.de Einführungin die Praktische Informatik Informatik WS 09/10 Page 2. Einführung in die praktische Informatik –WS09/10 1.1 Überblick Michael Gertz 1. Einführung 1.2 Disziplinen 1.3 Aufgaben © 2009/10Institut für Informatik Ruprecht-Karls-Universität Heidelberg Folie 2 1.4 Grundkonzepte Kapitel1: Einführung ◆ 1.1 Was ist Informatik? ➢Definition; Historie und Bedeutung ◆ 1.2 Disziplinender Informatik ➢Teilgebiete; Beziehung zu anderen Wissenschaften ◆ 1.3 Aufgaben in derInformatik ➢Mehr als nur Programmieren… ◆ 1.4 Grundkonzepte ➢Daten; Algorithmus;Datenstruktur; Prozess; Maschine; Modell (siehe hierzu auch Skript 1.5-1.10) …,*,2009,*
This article presents a new interestingness measure for association rules called confidence gain (CG). Focus is given to extraction of human associations rather than...,Umit Y Ogras; Hakan Ferhatosmanoglu; Jan-Marco Bremer; Michael Gertz,Managing large-scale time series databases has attracted significant attention in thedatabase community recently. Related fundamental problems such as dimensionalityreduction; transformation; pattern mining; and similarity search have been studiedextensively. Although the time series data are dynamic by nature; as in data streams; currentsolutions to these fundamental problems have been mostly...,The VLDB Journal,2006,*
On the Benefits of Backup Reprovisioning After Failure Repair (and Failure Arrival) in Telecom Mesh Networks,Lei Song; Jing Zhang,Abstract—Backup bandwidth reprovisioning has been shown to be an effective approach forimproving network survivability as well as preventing existing services from unnecessaryinterruption. We investigate the benefits of reprovisioning new backup paths for connectionswhen a link failure is repaired (as well as when a link failure occurs). The simulation resultsdemonstrate that our approach achieves more network robustness and better capacityoptimization.,Recreation Pool Lodge Davis; California; USA October 8 th; 2005,2005,*
The editors-in-chief and the editorial board would like to acknowledge the following people for their expert and continuing assistance in evaluating manuscript submi...,Serge Abiteboul; Charu Agrawal; Sihem Ahmer-Yahia; Gustavo Alonso; Toshiyuki Amagasa; Hiroki Arimura; Masayoshi Aritsugi; Chris Atkinson; Paolo Atzeni; Elena Baralis; Sonia Bergamaschi; Elisa Bertino; Azer Bestavros; Philippe Bonnet; Jerzy Brezinski; Sjaak Brinkkemper; Kurt Brown; Nicolas Bruno; Janis Bubenko; Alejandro Buchmann; Christoph Bussler; Fabio Casati; Sharma Chakravarthy; Don Chamberlin; Yatin Chawathe; Shu-Ching Chen; Jan Chomicki; Vassilis Christophides; Panos Chountas; Lawrence Chung; Peter Dadam; David de Frutos Escrig; Joaquin Delgado; Alex Delis; Eric Dubois; J urgen Ebert; Johann Eder; David Embley; Gregor Engels; Georgios Evangelidis; Ron Fagin; Christian Fahrner; Christos Faloutsos; Patrick Fan; Leonidas Fegaras; Donal Flynn; Johann Christoph Freytag; Hans Fritschi; Norbert Fuhr; Richard Furuta; Dimitrios Georgakopoulos; Andreas Geppert; Michael Gertz; Martin Glinz; Matteo Golfarelli; Goetz Graefe; Peter Green; Sol Greenspan; Paul Grefen; Volker Gruhn; Giovanna Guerrini; G Ralf-Hartmut,*,Information Systems,2004,*
Querying and Managing Controlled Data Annotations through Spatial Metadata,Michael Gertz; Udo Lipeck,Abstract Large heterogeneous collections of images form the basis of research in manyscientific application domains. Typically; domain experts analyze these images for facts andartifacts and associate (spatial) metadata with images and portions thereof in the form ofannotations. This thesis is concerned with two objectives arising in this context of theannotation process:(1) the management of the specified metadata and (2) the assurance ofmetadata compatibility and thus quality. A conceptualization approach is taken for therecording of annotations. Each domain specific object or relationship type is described by aconcept. Annotations representing identifications of objects and relationships among themare considered instances of these concepts. For each identified object; a spatial extent isspecified in the image along with a number of property values. The spatial metadata is of …,*,2003,*
Cooperative Information Systems (CoopIS) 2003 International Conference-Trust Management-Static Type-Inference for Trust in Distributed Information Systems,Premkumar T Devanbu; Michael Gertz; Brian Toone,*,Lecture Notes in Computer Science,2003,*
Opportunities and challenges in tracing security breaches,Michael Gertz,Abstract The closing session of the working conference was a panel discussion onchallenges and recent developments in tracing security breaches of information systems thatmanage mission critical data The panel members were (in alphabetical order): CristinaBuchholz (SAP; Germany); Michael Gertz (University of California at Davis; USA; panelchair) Sushil Jajodia (George Mason University; USA); Fred de Koning (NyenrodeUniversity; The Netherlands); Leon Strous (De Nederlandsche Bank NV; The Netherlands).,*,2003,*
Efficiency and Effectiveness of XML Tools and Techniques (EEXTT)-Data Integration over the Web (DIWeb)-Integrating Scientific Data through External; Concept-Ba...,Michael Gertz; Kai-Uwe Sattler,*,Lecture Notes in Computer Science,2003,*
jTerm: An Open Source Terminology Server: AMIA 2003 Open Source Expo,Michael A Hogarth; Michael Gertz; Fred Gorin,*,AMIA Annual Symposium Proceedings,2003,*
M. Caporuscio; A. Carzaniga; and AL Wolf." An Experience in Evaluating Publish/Subscribe Services in a Wireless Network". Third International Workshop on Softwa...,A Kwong; P Devanbu; M Gertz; C Martel; P Rogaway; SG Stubblebine,M. Caporuscio; A. Carzaniga; and AL Wolf. "An Experience in Evaluating Publish/Subscribe Servicesin a Wireless Network". Third International Workshop on Software and Performance. July2002 … A. Carzaniga; DS Rosenblum; and AL Wolf. "Design and Evaluation of a Wide-AreaEvent Notification Service". ACM Transactions on Computer Systems. Vol. 9; No. 3. August2001 … P. Devanbu; M. Gertz; A. Kwong; C. Martel; SG Stubblebine. "Flexible Authenticationof XML Documents". Eighth ACM Conference on Computer and Communications Security.2001 … P. Devanbu; M. Gertz; C. Martel; SG Stubblebine. "Authentic Third-Party DataPublication". 14th IFIP 11.3 Working Conference in Database Security … P. Devanbu; M.Gertz; C. Martel; P. Rogaway; SG Stubblebine. "Authentic Re-Publication by UntrustedServers: A Novel Approach to Database Survivability". Third Information Survivability …,*,2002,*
Guarding the Integrity of Mission Critical Data: Opportunities; Methods; and Rewards,Michael Gertz,Data is the most valuable asset of almost every type of organization in industry; government;and research. It is not surprising that mission critical business decisions frequently rely onvarious data quality aspects; such as data integrity; reliability; correctness; completeness;availability; to name just a few [1; 2; 3]. In today's complex information system infrastructures;it becomes more and more difficult to guard the quality of mission critical data againstvarious types of threats from outsiders and insiders. While there have been major advancesin various areas of computer security; most notably in the context of intrusion detection at theoperating and network layer [5]; protecting data from unprivileged access or modifications atthe database layer is still a challenge many organizations are facing. This is despite the factthat most of today's commercial database management systems (DBMS) offer rich and …,*,2002,*
The Push and Pull of the Data Grid,Tamara Dahlgren; Michael Gertz,*,*,2001,*
1999 Reviewers list,Brad Adelberg; Jun-ichi Aoe; James Bailey; Elena Baralis; Roberto Bayardo; Elisa Bertino; Claudio Bettini; Athman Bouguettaya; J Breuker; K Selcuk Candan; Doris L Carver; Soumen Chakrabarti; Edward Chang; Ray Chen; Yaw-Huei Chen; Hui-Hsien Chou; Li-Der Chou; Christopher W Clifton; William W Cohen; Peter Dadam; Alan Dearle; Suzanne Dietrich; Khanh PV Doan; Guozhu Dong; Daniel Dvorak; Christoph F Eick; Carlos F Enguix; Henrik Eriksson; Opher Etzion; Charles Forgy; Shashi K Gadia; Avigdor Gal; Venkatesh Ganti; Minos Garofalakis; Stella Gatziu; Johannes Gehrke; Michael Gertz; Ashok K Goel; Angela Goh; Joachim Hammer; Susanne Heipcke; Ian Horrocks; Hui-I Hsiao; Stephen Huang; James K Huggins; Ben Jang; Lars J Kangas; Lina Khatib; Donald H Kraft; Gabriel Kuper; Mark Levene; Chung-Sheng Li; Dekang Lin; Witold Litwin; Jen-Chang Liu; Ling Liu; Xiaohui Liu; Rona Machlin; Bamshad Mobasher; Guido Moerkotte; Yasuhiko Morimoto; Shinichi Morishita; Mark A Najork; Vivek Narasayya; Erich J Neuhold; Thuy-Linh Nguyen; Lance Obermeyer; Dimitris Papadias; Jong Soo Park; Yun Peng; Alun Preece; Ivan Radev; Raghu Ramakrishnan; Paul Roback; Mark A Roth; Marie-Christine Rousset; Neil C Rowe; Ingrid Russell; Pierangela Samarati; Joerg Sander; Maria Luisa Sapino; Archana S Sathaye; Lawrence V Saxton; Edward Sciore; Hadas Shachnai; Fenn-Huei Simon Sheu; Jaideep Srivastava,142 IEEE TRANSACTIONS ON KNOWLEDGE AND DATA ENGINEERING; VOL. 12; NO. 1;JANUARY/FEBRUARY 2000 … —————————— 3 —————————— A Brad AdelbergJun-ichi Aoe B James Bailey Elena Baralis Roberto Bayardo Elisa Bertino Claudio Bettini AthmanBouguettaya J. Breuker C K. Selcuk Candan Doris L. Carver Soumen Chakrabarti Edward ChangIng-Ray Chen Yaw-Huei Chen Hui-Hsien Chou Li-Der Chou Christopher W. Clifton WilliamW. Cohen D Peter Dadam Alan Dearle Suzanne Dietrich Khanh PV Doan Guozhu Dong DanielDvorak E Christoph F. Eick Carlos F. Enguix Henrik Eriksson Opher Etzion F Charles Forgy GShashi K. Gadia Avigdor Gal Venkatesh Ganti Minos Garofalakis Stella Gatziu Johannes GehrkeMichael Gertz Ashok K. Goel Angela Goh … H Joachim Hammer Susanne Heipcke Ian HorrocksHui-I Hsiao Stephen Huang James K. Huggins J Ben Jang K Lars J. Kangas Lina Khatib …,IEEE Transactions on Knowledge and Data Engineering,2000,*
Integrity; Authentication; Privacy; and Delegation: Security Goals in automated software configuration management over the Internet,P Devanbu; M Gertz; S Stubblebine,Abstract Installation; con guration; and administration of desktop software is a non-trivialprocess. Even a simple application can have numerous dependencies to hardware; devicedrivers; operating system versions; dynamically linked libraries; and even to otherapplications. There are other complications including local customization; timelyannunciation of new release availability; timely annunciation constraints on valid congurations; protecting the privacy of con gurations; authentication of licenses; authenticationand delegation of con guration authority; and demarkation of administrative boundaries.These problems have not been completely considered in existing systems and in theliterature. We illustrate these problems using a scenario and describe our researchprogramme in this area.,*,1999,*
Entity-centric Topic Extraction and Exploration: A Network-based Approach,Andreas Spitz; Michael Gertz,Abstract. Topic modeling is an important tool in the analysis of corpora and the classificationand clustering of documents. Various extensions of the underlying graphical models havebeen proposed to address hierarchical or dynamical topics. However; despite theirpopularity; topic models face problems in the exploration and correlation of the (oftenunknown number of) topics extracted from a document collection; and rely on compute-intensive graphical models. In this paper; we present a novel framework for exploringevolving corpora of news articles in terms of topics covered over time. Our approach isbased on implicit networks representing the cooccurrences of entities and terms in thedocuments as weighted edges. Edges with high weight between entities are indicative oftopics; allowing the context of a topic to be explored incrementally by growing network …,*,*,*
Generating Small Models of First-Order Axioms,S Abiteboul; R Hull; V Vianu; C Ceri; G Gottlob; L Tanca; F Bry; F Bry; R Manthey; F Bry; R Manthey; F Bry; R Manthey; J Hintikka; J Slaney; S Lorenz; J Zhang; H Zhang; C Aravindan; P Baumgartner; M Gertz; U Lipeck; V Benzaken; X Schaefer; F Bry; S Torge; S Torge; F Bry; S Torge; C Aravindan; P Baumgartner,*,Proc. German Workshop on Artificial Intelligence,*,*
Introduction to Scientific Data and Workflow Management,Michael Gertz; Bertram Ludäscher,(13:30-14:15; Gertz) – What is Scientific Data Management (SDM) – Typical SDM processes– SDM domains: Earth Sciences; Astrophysics; Life Sciences … II. From Conventional to ScientificData Integration … (14:15—15:00; Ludäscher) – Conventional Data Integration(Mediation/Schema-based) – Ontology-based Extensions to Data Integration – The Role of Metadata– Link-based “Integration” … III. From Scientific Data Formats to Data Stream Processing …(15:30—16:15; Gertz) – Scientific Data Formats and Data Models – What are Recent Trends? What about XML ? – Data Processing Pipelines – Data Stream Processing … (16:15-17:00; Ludäscher) – Workflows in e-Science and Cyberinfrastructure – Scientific Workflows vs BusinessWorkflows – Features of a Scientific Workflow system (Kepler) – Flow-based Programming andScientific Workflow Design – Semantic Extensions … • Broad overview on/introduction …,*,*,*
24th International Conference on Scientific and Statistical Database Management,Marianne Winslett; Michael Gertz; Judith Cushing,The SSDBM international conference will bring together scientific domain experts; databaseresearchers; practitioners and developer for the presentation and exchange of currentresearch on concepts; tools and techniques for scientific and statistical databaseapplications. The 24th SSDBM will provide a forum for original research contributions andpractical system design; implementation and evaluation. The rich program of the researchtrack will be supplemented with invited talks and panel sessions; as well as illustrateddemonstrations of research prototypes and industrial systems.,*,*,*
A Flexible NLP Pipeline for Computational Narratology in Literary Text,Thomas Bögel; Jannik Strötgen; Christoph Mayer; Michael Gertz,Page 1. A Flexible NLP Pipeline for Computational Narratology in Literary Text Thomas Bögel;Jannik Strötgen; Christoph Mayer; Michael Gertz Database Systems Research Group; HeidelbergUniversity; Im Neuenheimer Feld 348; 69120 Heidelberg; Germany Context of this Work TheheureCLÉA Project [4] Computational Narratology •context: Digital Humanities •facilitateannotations from literary scientists •support hypotheses [1] •methods: Natural LanguageProcessing Temporal phenomena •field of study in narratology •temporal structure of literary texts•examples: time shi s; order phenomena (eg; prolepsis) Cooperation •BMBF-funded eHumanitiesproject •narratologists (Hamburg) •computer scientists (Heidel- berg) •temporal phenomena inliter- ary text Goals •collaborative annotation framework that automatically suggests annotations•reduce manual annotation e ort •analysis of temporal aspects …,*,*,*
An End-To-End Integration of Automatic Annotations into CATMA,Thomas Bögel; Marco Petris; Jannik Strötgen; Michael Gertz,Natural Language Processing offers solutions for predicting linguistic annotations at differentlevels of complexity. Thus; it seems obvious and–in general–a good idea to apply thesemethods to the Humanities in order to automate laborious manual annotations and tofacilitate a deeper text analysis understanding. Apart from the purely technical aspect ofdeveloping suitable models; however; additional challenges for NLP in the Humanitiesarise: in order to be used as part of an analysis tool; humanists often desire justifications andexplanations of automatic annotations. Just implementing a black-box approach; evaluatingit intrinsically and returning the presumably best results to the user is not sufficient. In thispaper; we suggest a transparent way of presenting the results of a NLP pipeline in acollaborative setting. This gives the user the possibility to judge the results directly within …,*,*,*
MDM 2014,Nitin Agrawal; Walid Aref; Nikolaos Armenatzoglou; Anas Basalamah; Claudio Bettini; Thomas Brinkhoff; Ying Cai; Dipanjan Chakraborty; Sriram Chellappan; Ming-Syan Chen; Chi-Yin Chow; Alfredo Cuzzocrea; Maria Luisa Damiani; Alex Delis; Thierry Delot; Ugur Demiryurek; Yunjun Gao; Michael Gertz; Ralf Hartmut Güting; Takahiro Hara; Khaled Harras; Yoshiharu Ishikawa; Vana Kalogeraki; Yutaka Kidawara; Kyoung-Sook Kim; Hiroyuki Kitagawa; Shonali Krishnaswamy; Peer Kröger; Lars Kulik; Mohan Kumar; Wang-Chien Lee; Wenjia Li; Seng Loke; Hua Lu; Chang-Tien Lu; Sanjay Madria; Sergio Mascetti,Nitin Agrawal; NEC Labs; USA Walid Aref; Purdue University; USA Nikolaos Armenatzoglou;Hong Kong University of Science and Technology; Hong Kong Anas Basalamah; Umm Al-QuraUniversity Makkah; Saudi Arabia Claudio Bettini; University of Milan; Italy Thomas Brinkhoff;Jade University Oldenburg; Germany Ying Cai; Iowa State University; USA DipanjanChakraborty; IBM Research Labs; India Sriram Chellappan; Missouri Univ. of Science &Technology; USA Ming-Syan Chen; National Taiwan University; Taiwan Chi-Yin Chow; City Universityof Hong Kong; Hong Kong Alfredo Cuzzocrea; ICAR-CNR and University of Calabria; Italy MariaLuisa Damiani; University of Milan; Italy Alex Delis; University of Athens; Greece ThierryDelot; INRIA Lille Nord Europe & Université de Valenciennes; France Ugur Demiryurek; Universityof Southern California; USA Yunjun Gao; Zhejiang University; China Michael Gertz …,*,*,*
A LRT Framework for fast spatial anomaly detection,Michael Gertz,*,*,*,*
Message from the MDM 2013 Program Chairs,X Sean Wang; Cyrus Shahabi; Michael Gertz,Following 13 successful IEEE International Conferences on Mobile Data Management; the14th edition of the series; MDM 2013; took place on June 3-6; 2013; in Milan; Italy. MDM2013 maintained the tradition of being a prestigious forum for the exchange of innovativeand significant research results in mobile data management. The term mobile in MDM hasbeen used from the very beginning in a broad sense to encompass all aspects of mobility-aspects related to wireless; portable and tiny devices; as well as vehicles. The conferenceprovides unique opportunities for researchers; engineers; practitioners; developers; andusers to explore new ideas; techniques; and tools; and to exchange experiences. We wouldlike to thank all the authors for submitting their work to this conference. The main technicalprogram received 69 submissions. Each paper was reviewed by at least 3 reviewers …,*,*,*
STEERING COMMITTEE LIAISON,Claudio Bettini; Ouri Wolfson; X Sean Wang; Cyrus Shahabi; Michael Gertz,Page 1. Organizing Committee GENERAL CHAIRS Claudio Bettini; University of Milan; Italy OuriWolfson; University of Illinois at Chicago; USA PROGRAM CHAIRS X. Sean Wang; Fudan University;China Cyrus Shahabi; University of Southern California; USA Michael Gertz; Heidelberg University;Germany STEERING COMMITTEE LIAISON Arkady Zaslavsky; CSIRO; Australia INDUSTRYTRACK CHAIRS Dipanjan Chakraborty; IBM Research; India Massimo Valla; Telecom Italia; ItalyWORKSHOP CHAIRS Daniele Riboni; University of Milan; Italy Jianliang Xu; Hong Kong BaptistUniversity; Hong Kong ADVANCED SEMINARS CHAIRS Takahiro Hara; Osaka University; JapanThierry Delot; University of Valenciennes; France PANEL CHAIRS Archan Misra; SingaporeManagement University; Singapore Juha Laurila; Nokia Research Center; Switzerland DEMOCHAIRS Yan Huang ; North Texas University; USA …,*,*,*
Teiresias: Predicting the Performance of a Query Engine for Large Scale Scientific Data,Deborah L Walker; Michael Gertz,*,*,*,*
fchungyjgertzjlevittg@ cs. ucdavis. edu Department of Computer Science; One Shields Avenue University of California; Davis; 95616 CA,Christina Yip Chung; Michael Gertz; Karl Levitt,*,*,*,*
Application-Level Misuse Detection in Relational DBMS,Christina Chung; Michael Gertz; Karl Levitt,The security goals of a computer system can be specied explicitly by security policies-whatactions a subject can or cannot perform on objects under speci ed conditions. The securitypolicies are enforced by security mechanisms. Compromising the security mechanisms isintrusion whereas violating the security policies without compromising the securitymechanisms by legitimate users is insider abuse. Misuse includes both intrusion and insiderabuse. Misuse can been handled by signature based and anomaly based approachesCFMS95]. In signature based detection; audit logs are matched against a database of knownattack patterns. In anomaly based detection; it is assumed that the set of intrusive andmisuse events equals the set of anomalous events and such anomalies can be detected inthe audit records. Pro les are derived from audit logs and policies to characterize the …,*,*,*
Dagstuhl Seminar" Data Quality on the Web" 31.08.-05.09. 2003; Seminar Nº 03362 Organizers,Michael Gertz; Tamer Özsu; Kai-Uwe Sattler; Gunter Saake,*,*,*,*
Enabling Near Real-time Re-Projection of Remotely Sensed Geospatial Data,Haiyan Yang; Michael Gertz,Remotely sensed data are information that sensors collect for a geographic area withoutbeing in physical contact with it [3]. Real-time access to remotely sensed satellite imagesplays an important role in emerging applications like environmental monitoring and disastermanagement [4]. Because vegetation has high near infrared and low visible reflectance; forinstance; a combinational image from multiple spectra data at near infrared; red and green isused to analyze change detection of vegetation. Hence anomaly such as forest fire can bedetected in near realtime. Currently most of the geospatial data retrieved from remotesensors; require the scientist to perform time consuming; repetitive; and complex routineslike image reprojection. These tasks often hamper the effective use of realtime data productsand thus decrease the utility of otherwise valuable data. In this paper; we present a model …,Recreation Pool Lodge Davis; California; USA October 8 th; 2005,*,*
Institut fur Informatik; Universitat Hannover Lange Laube 22; D-30159 Hannover; Germany,Michael Gertz; Udo W Lipeck,*,*,*,*
Institut fur Informatik Universitat Hannover,Michael Gertz; Udo W Lipeck,*,*,*,*
Data Engineering,Dan Boneh; Joan Feigenbaum; Avi Silberschatz; Rebecca N Wright; Michael Gertz; April Kwong; Charles U Martel; Glen Nuckolls; Arnon Rosenthal; Edward Sciore,Bulletin of the Technical Committee on Data Engineering March 2004 Vol. 27 No. 1 IEEE ComputerSociety Letters Letter from the Editor-in-Chief...................................................... David Lomet 1 TCDEElection Result................................ Paul Larson; Masaru Kitsuregawa; Betty Salzberg 1 Letter fromthe Special Issue Editor................................................ Johannes Gehrke 2 Special Issue on DataPrivacy and Security Privacy-enabled Management of Customer Data … Editorial BoardEditor-in-Chief David B. Lomet Microsoft Research One Microsoft Way; Bldg. 9 Redmond WA98052-6399 lomet@ microsoft. com Associate Editors Umeshwar Dayal Hewlett-Packard Laboratories1501 Page Mill Road; MS 1142 Palo Alto; CA 94304 Johannes Gehrke Department of ComputerScience Cornell University Ithaca; NY 14853 Christian S. Jensen Department of Computer ScienceAalborg University Fredrik Bajers Vej 7E DK-9220 Aalborg Øst; Denmark Renée J. Miller …,Urbana,*,*
Improving Wrappers and Wrapper Gener-ation for Web Sources,Stoney Jackson; Ben Gregorski; Michael Gertz,*,*,*,*
Database-driven Information Visualization,Omar Alonso; Michael Gertz; Premkumar Devanbu,ABSTRACT Information visualization metaphors have been around for many years yet theyhave not reached mass adoption. We argue that a possible reason is that without propercontent organization and structure; there is not much room for visualization. A databaseprovides the necessary infrastructure for organizing and accessing data in very flexible way.Adding a visualization on top of a database system to take advantage of the database'sfeatures thus is a natural choice. In this paper; we present an architecture for integratingdifferent visualization metaphors on top of a database for improving (dynamic) explorationand browsing of large data sets. Using email archives from the Apache development teamand a few commercial products; we present a working prototype that demonstrates the mainconcepts.,Recreation Pool Lodge Davis; California; USA October 8 th; 2005,*,*
ICWE 2008,Uwe Assmann; Luciano Baresi; Maria Bielikova; Judith Bishop; Marco Brambilla; Chris Brooks; Dan Chiorean; Maria da Graça Pimentel; Peter Dolog; Martin Gaedke; Franca Garzotto; Dragan Gasevic; Michael Gertz; Jaime Gomez; Volker Gruhn; Geert-Jan Houben; David Lowe; Bernd Krämer; Adriana P Medeiros; Emilia Mendes; Luis Olsina; Oscar Pastor; Vicente Pelechano; Peter Plessers; IV Ramakrishnan; Simos Retalis; Gustavo Rossi; Katsumi Tanaka; Bernhard Thalheim; Philippe Thiran; Riccardo Torlone; Jean Vanderdonckt; Fabio Vitali; Petri Vuorimaa; Marko Winkler; Bin Xu,Uwe Assmann; TUDresden; Germany Luciano Baresi; Politecnico di Milano; Italy MariaBielikova; Slovak University of Technology in Bratislava; Slovakia Judith Bishop; University ofPretoria; South Africa Marco Brambilla; Politecnico di Milano; Italy Chris Brooks; University ofSan Francisco; USA Dan Chiorean; University Babes-Bolgni; Romania Maria da GraçaPimentel; University of São Paulo; SC; Brazil Peter Dolog; Aalborg University; Denmark MartinGaedke; Chemnitz University of Technology; Germany Franca Garzotto; Politecnico diMilano; Italy Dragan Gasevic; Simon Fraser University; Canada Michael Gertz; UC-Davis; USAAngela Goh; NTU; Singapore Jaime Gomez; Universidad de Alicante; Spain Volker Gruhn; UniversitätLeipzig; Germany Geert-Jan Houben; Vrije Universiteit Brussel; Belgium Arun Iyengar; IBM; USADavid Lowe; University of Technology Sydney; Australia Bernd Krämer; FernUniversität …,*,*,*
Real-time visualization of streaming data from a GOES environmental satellite,Carlos Rueda-Velásquez; Michael Gertz,ABSTRACT We describe a novel Web application for real-time visualization of remotelysensed satellite data. The tool; developed as part of a research project aimed at the adaptiveprocessing of real-time streaming image data; provides navigational and selection facilitiesfor users to quickly visualize available channels at various levels of resolution. In the contextof the overall server-client streaming image pipeline; we describe the current capabilities ofthe tool and then briefly summarize the current efforts; which are mainly focused onproviding more user interactivity and an enriched set of mechanisms to formulate queriesover streaming data.,Recreation Pool Lodge Davis; California; USA October 8 th; 2005,*,*
в ми вз а ж б лгж гж,M Gertz; UW Lipeck,*,*,*,*
Abiteboul; S. 41 Aggarwal; CC 261;593 Agrawal; D 93; 274;496;639 Agrawal; S. 5,M Akinde; S AI-Khalifa; G Alonso; M Areal; WG Aref; V Atluri; I Atmosukarto; D Baker; R Barga; K Barker; B Benatallah; G Bhalotia; HE Blok; M Bohlen; A Bonifati; D Braga; S Bressan; N Bruno; F Buccafurri; A Campi; F Casati; AC Catlin; S Ceri; S Chakrabarti; NH Chan; S Chaudhuri; B Chen; CM Chen; J Chen; MS Chen; F Chiu; J Cho; HD Chon; L Cohen; B Cooper; R Cordova; G Cormode; G Das; S Davey; U Daya; S Decker; A Descour; A Deshpande; J Desmarais; DJ DeWitt; A Doan; M Dumas; J Dunn; MG Elfeky; CJ El1mann; AK Elmagarmid; R Elmasri; C Fa1outsos; J Fan; A Faradjian; P Felber; J Feng; S Flesca; I Foudos; J Freire; AW Fu; F Furfaro; A Gal; H Garcia-Molina; M Garofalakis; J Gehrke; D Georgakopoulos; M Gertz; A Goel,333 369 264 331 129 567; 685 ; 673 ; 490 ; 266 ; 271 263 29 393 490 212;276 716 498 492271 498 431 176 490 605 29 141 278;463 265; 663 335 488 262 ; 494 ; 266 ; 166 129 309 309333 494 275 673 309 141;567;605 309 262 453 706 329 … 267 269 176 583 269 617 268; 268 543 269;327 155;331;335 155 697 555 507 279 333 267 583 41;369 490 271 29 117 331685 333 212;498 685 685 ; 245 605 333 270 431 529 345;697 271 ;498 273 583 272 297 ;485685 274 275 333 265;663 327 … Ounopulos; D PUO; J. ..; Gtirel; A. Haas; L. ãas; p .J.Haclgtimti; H. I … ¥alevy; A. ãmmad; M. ¥aritsa; JR ¥ellerstein; J .M … Lee; D. Lee; MLLehner; W Leung; CK-S Ling; T. W ' … Ling; Y. Liu; B Liu; J Lomet; D. Low; WL Lu; H. ; Lu; JXLuo; G. Madden; S. Madhyastha; T. Maier; D. Major; G. Mani; M. Mannila; H Marian; A.,*,*,*
Interoperability and Data Integration in the Geosciences,Michael Gertz; Carlos Rueda; Jianting Zhang,The past decade has witnessed a dramatic increase in scientific data being generated in thephysical; earth; and life sciences. This development is primarily a result of majoradvancements in sensor technology; surveying techniques; computer-based simulations;and instrumentation of experiments. As stated by Szalay and Gray in [76]; it is estimated thatthe amount of scientific data generated in these disciplines is now doubling every year.Organizations in government; industry as well as academic and private sectors; have madesignificant investments in infrastructures to collect and maintain scientific data and makethem accessible to the public. Good examples of such efforts are the Sloan Digital SkySurvey in astronomy [67]; the GDB Human Genome Database and Entrez GenomeDatabase in genomics [13; 26]; and the Global Biodiversity Information Facility in ecology …,*,*,*
Repairing Constraint Violations in Databases,Michael Gertz; Udo W Lipeck,Abstract Repairing violations of integrity constraints in databases can be seen as aninterleaving diagnostic/repair process. In this paper we introduce a new approach onrepairing constraint violations by adopting existing techniques from model–based diagnosis.Violations of integrity constraints observed in an inconsistent database state are diagnosedand repair actions are deduced from diagnoses. By interleaving diagnosing violations andperforming repair actions; transactions are computed which restore the consistency of thedatabase.,*,*,*
Security in Distributed Configuration Management,Premkumar Devanbu; Michael Gertz,*,*,*,*
