Know your neighbors: Web spam detection using the web topology,Carlos Castillo; Debora Donato; Aristides Gionis; Vanessa Murdock; Fabrizio Silvestri,Abstract Web spam can significantly deteriorate the quality of search engine results. Thusthere is a large incentive for commercial search engines to detect spam pages efficiently andaccurately. In this paper we present a spam detection system that combines link-based andcontent-based features; and uses the topology of the Web graph by exploiting the linkdependencies among the Web pages. We find that linked hosts tend to belong to the sameclass: either both are spam or both are non-spam. We demonstrate three methods ofincorporating the Web graph topology into the predictions obtained by our base classifier:(i)clustering the host graph; and assigning the label of all hosts in the cluster by majorityvote;(ii) propagating the predicted labels to neighboring hosts; and (iii) using the predictedlabels of neighboring hosts as new features and retraining the classifier. The result is an …,Proceedings of the 30th annual international ACM SIGIR conference on Research and development in information retrieval,2007,366
The impact of caching on search engines,Ricardo Baeza-Yates; Aristides Gionis; Flavio Junqueira; Vanessa Murdock; Vassilis Plachouras; Fabrizio Silvestri,Abstract In this paper we study the trade-offs in designing efficient caching systems for Websearch engines. We explore the impact of different approaches; such as static vs. dynamiccaching; and caching query results vs. caching posting lists. Using a query log spanning awhole year we explore the limitations of caching and we demonstrate that caching postinglists can achieve higher hit rates than caching query answers. We propose a new algorithmfor static caching of posting lists; which outperforms previous methods. We also study theproblem of finding the optimal way to split the static cache between answers and postinglists. Finally; we measure how the changes in the query log affect the effectiveness of staticcaching; given our observation that the distribution of the queries changes slowly over time.Our results and observations are applicable to different levels of the data-access …,Proceedings of the 30th annual international ACM SIGIR conference on Research and development in information retrieval,2007,222
Boosting the performance of web search engines: Caching and prefetching query results by exploiting historical usage data,Tiziano Fagni; Raffaele Perego; Fabrizio Silvestri; Salvatore Orlando,Abstract This article discusses efficiency and effectiveness issues in caching the results ofqueries submitted to a Web search engine (WSE). We propose SDC (Static DynamicCache); a new caching strategy aimed to efficiently exploit the temporal and spatial localitypresent in the stream of processed queries. SDC extracts from historical usage data theresults of the most frequently submitted queries and stores them in a static; read-only portionof the cache. The remaining entries of the cache are dynamically managed according to agiven replacement policy and are used for those queries that cannot be satisfied by the staticportion. Moreover; we improve the hit ratio of SDC by using an adaptive prefetching strategy;which anticipates future requests by introducing a limited overhead over the back-end WSE.We experimentally demonstrate the superiority of SDC over purely static and dynamic …,ACM Transactions on Information Systems (TOIS),2006,220
Mining query logs: Turning search usage data into knowledge,Fabrizio Silvestri,Abstract Web search engines have stored in their logs information about users since theystarted to operate. This information often serves many purposes. The primary focus of thissurvey is on introducing to the discipline of query mining by showing its foundations and byanalyzing the basic algorithms and techniques that are used to extract useful knowledgefrom this (potentially) infinite source of information. We show how search applications maybenefit from this kind of analysis by analyzing popular applications of query log mining andtheir influence on user experience. We conclude the paper by; briefly; presenting some ofthe most challenging current open problems in this field.,Foundations and Trends® in Information Retrieval,2009,164
Challenges on distributed web retrieval,Ricardo Baeza-Yates; Carlos Castillo; Flavio Junqueira; Vassilis Plachouras; Fabrizio Silvestri,In the ocean of Web data; Web search engines are the primary way to access content. As thedata is on the order of petabytes; current search engines are very large centralized systemsbased on replicated clusters. Web data; however; is always evolving. The number of Websites continues to grow rapidly and there are currently more than 20 billion indexed pages.In the near future; centralized systems are likely to become ineffective against such a load;thus suggesting the need of fully distributed search engines. Such engines need to achievethe following goals: high quality answers; fast response time; high query throughput; andscalability. In this paper we survey and organize recent research results; outlining the mainchallenges of designing a distributed Web retrieval system.,Data Engineering; 2007. ICDE 2007. IEEE 23rd International Conference on,2007,135
Adaptive and resource-aware mining of frequent sets,Salvatore Orlando; Paolo Palmerini; Raffaele Perego; Fabrizio Silvestri,The performance of an algorithm that mines frequent sets from transactional databases mayseverely depend on the specific features of the data being analyzed. Moreover; somearchitectural characteristics of the computational platform used-eg the available mainmemory-can dramatically change its runtime behavior. In this paper we present DCI (DirectCount & Intersect); an efficient algorithm for discovering frequent sets from large databases.Due to the multiple heuristics strategies adopted; DCI can adapt its behavior not only to thefeatures of the specific computing platform; but also to the features of the dataset beingmined; so that it results very effective in mining both short and long patterns from sparse anddense datasets. Finally we also discuss the parallelization strategies adopted in the designof ParDCI; a distributed and multi-threaded implementation of DCI.,Data Mining; 2002. ICDM 2003. Proceedings. 2002 IEEE International Conference on,2002,135
Dynamic personalization of web sites without user intervention,Ranieri Baraglia; Fabrizio Silvestri,Web Usage Mining (WUM) typically extracts knowledge by analyzing historical data such asWeb server access logs; browser caches; or proxy logs. WUM techniques are important for severalreasons. It is possible to model user behavior and; therefore; to forecast their futuremovements. The information mined can subsequently be used in order to personalize the contentsof Web pages; to improve Web server performance; to structure a Web site according to the preferencesexpressed by the users; or to help the business to carry out a specific users' target … Web Personalization(WP) or recommender systems [3] are typical applications of WUM. These systems were introducedto improve Web site usage by customizing the contents of a Web site with respect to theusers' needs. They provide mechanisms that collect information describing user activity and elaboratethis information … In a first stage; WUM can be used to determine the number of Web …,Communications of the ACM,2007,133
Identifying task-based sessions in search engine query logs,Claudio Lucchese; Salvatore Orlando; Raffaele Perego; Fabrizio Silvestri; Gabriele Tolomei,Abstract The research challenge addressed in this paper is to devise effective techniques foridentifying task-based sessions; ie sets of possibly non contiguous queries issued by theuser of a Web Search Engine for carrying out a given task. In order to evaluate and comparedifferent approaches; we built; by means of a manual labeling process; a ground-truth wherethe queries of a given query log have been grouped in tasks. Our analysis of this ground-truth shows that users tend to perform more than one task at the same time; since about 75%of the submitted queries involve a multi-tasking activity. We formally define the Task-basedSession Discovery Problem (TSDP) as the problem of best approximating the manuallyannotated tasks; and we propose several variants of well known clustering algorithms; aswell as a novel efficient heuristic algorithm; specifically tuned for solving the TSDP. These …,Proceedings of the fourth ACM international conference on Web search and data mining,2011,127
Design trade-offs for search engine caching,Ricardo Baeza-Yates; Aristides Gionis; Flavio P Junqueira; Vanessa Murdock; Vassilis Plachouras; Fabrizio Silvestri,Abstract In this article we study the trade-offs in designing efficient caching systems for Websearch engines. We explore the impact of different approaches; such as static vs. dynamiccaching; and caching query results vs. caching posting lists. Using a query log spanning awhole year; we explore the limitations of caching and we demonstrate that caching postinglists can achieve higher hit rates than caching query answers. We propose a new algorithmfor static caching of posting lists; which outperforms previous methods. We also study theproblem of finding the optimal way to split the static cache between answers and postinglists. Finally; we measure how the changes in the query log influence the effectiveness ofstatic caching; given our observation that the distribution of the queries changes slowly overtime. Our results and observations are applicable to different levels of the data-access …,ACM Transactions on the Web (TWEB),2008,104
An online recommender system for large web sites,Ranieri Baraglia; Fabrizio Silvestri,Abstract In this paper we propose a WUM recommender system; called SUGGEST 3.0; thatdynamically generates links to pages that have not yet been visited by a user and might beof his potential interest. Differently from the recommender systems proposed so far;SUGGEST 3.0 does not make use of any off-line component; and is able to manage Websites made up of pages dynamically generated. To this purpose SUGGEST 3.0 incrementallybuilds and maintains historical information by means of an incremental graph partitioningalgorithm; requiring no off-line component. The main innovation proposed here is a novelstrategy that can be used to manage large Web sites. Experiments; conducted in order toevaluate SUGGEST 3.0 performance; demonstrated that our system is able to anticipateusers' requests that will be made farther in the future; introducing a limited overhead on …,Proceedings of the 2004 IEEE/WIC/ACM International Conference on Web Intelligence,2004,94
Sorting out the document identifier assignment problem,Fabrizio Silvestri,Abstract The compression of Inverted File indexes in Web Search Engines has received a lotof attention in these last years. Compressing the index not only reduces space occupancybut also improves the overall retrieval performance since it allows a better exploitation of thememory hierarchy. In this paper we are going to empirically show that in the case ofcollections of Web Documents we can enhance the performance of compression algorithmsby simply assigning identifiers to documents according to the lexicographical ordering of theURLs. We will validate this assumption by comparing several assignment techniques andseveral compression algorithms on a quite large document collection composed by aboutsix million documents. The results are very encouraging since we can improve thecompression ratio up to 40% using an algorithm that takes about ninety seconds to finish …,European conference on information retrieval,2007,87
kDCI: A multi-strategy algorithm for mining frequent sets,Claudio Lucchese; Salvatore Orlando; Paolo Palmerini; Raffaele Perego; Fabrizio Silvestri,Abstract This paper presents the implementation of kDCI; an enhancement of DCI [10]; ascalable algorithm for discovering frequent sets in large databases. The main contribution ofkDCI resides on a novel counting inference strategy; inspired by previously known results byBasted et al.[3]. Moreover; multiple heuristics and efficient data structures are used in orderto adapt the algorithm behavior to the features of the specific dataset mined and of thecomputing platform used. kDCI turns out to be effective in mining both short and longpatterns from a variety of datasets. We conducted a wide range of experiments on syntheticand real-world datasets; both in-core and out-of-core. The results obtained allow us to statethat kDCI performances are not over-fitted to a special case; and its high performance ismaintained on datasets with different characteristics.,Proceedings of the IEEE ICDM Workshop of Frequent Itemset Mining Implementations (FIMI); Melbourne; Florida,2003,80
A grid information service based on peer-to-peer,Diego Puppin; Stefano Moncelli; Ranieri Baraglia; Nicola Tonellotto; Fabrizio Silvestri,Abstract Information Services are fundamental blocks of the Grid infrastructure. They areresponsible for collecting and distributing information about resource availability and statusto users: the quality of these data may have a strong impact on scheduling algorithms andoverall performance. Many popular information services have a centralized structure. Thisclearly introduces problems related to information updating and fault tolerance. Also; in verylarge configurations; scalability may be an issue. In this work; we present a Grid InformationService based on the peer-to-peer technology. Our system offers a fast propagation ofinformation and has high scalability and reliability. We implemented our system complying tothe OGSA standard using the Globus Toolkit 3. Our system can run on Linux and Windowssystems; with different network configurations; so to trade off between redundancy …,European Conference on Parallel Processing,2005,78
Efficient diversification of web search results,Gabriele Capannini; Franco Maria Nardini; Raffaele Perego; Fabrizio Silvestri,Abstract In this paper we analyze the efficiency of various search results diversificationmethods. While efficacy of diversification approaches has been deeply investigated in thepast; response time and scalability issues have been rarely addressed. A unified frameworkfor studying performance and feasibility of result diversification solutions is thus proposed.First we define a new methodology for detecting when; and how; query results need to bediversified. To this purpose; we rely on the concept of" query refinement" to estimate theprobability of a query to be ambiguous. Then; relying on this novel ambiguity detectionmethod; we deploy and compare on a standard test set; three different diversificationmethods: IASelect; xQuAD; and OptSelect. While the first two are recent state-of-the-artproposals; the latter is an original algorithm introduced in this paper. We evaluate both …,Proceedings of the VLDB Endowment,2011,73
Query-driven document partitioning and collection selection,Diego Puppin; Fabrizio Silvestri; Domenico Laforenza,Abstract We present a novel strategy to partition a document collection onto several serversand to perform effective collection selection. The method is based on the analysis of querylogs. We proposed a novel document representation called query-vectors model. Eachdocument is represented as a list recording the queries for which the document itself is amatch; along with their ranks. To both partition the collection and build the collectionselection function; we co-cluster queries and documents. The document clusters are thenassigned to the underlying IR servers; while the query clusters represent queries that returnsimilar results; and are used for collection selection. We show that this document partitionstrategy greatly boosts the performance of standard collection selection algorithms;including CORI; wrt a round-robin assignment. Secondly; we show that performing …,Proceedings of the 1st international conference on Scalable information systems,2006,65
VSEncoding: efficient coding and fast decoding of integer lists via dynamic programming,Fabrizio Silvestri; Rossano Venturini,Abstract Encoding lists of integers efficiently is important for many applications in differentfields. Adjacency lists of large graphs are usually encoded to save space and to improvedecoding speed. Inverted indexes of Information Retrieval systems keep the lists of postingscompressed in order to exploit the memory hierarchy. Secondary indexes of DBMSs arestored similarly to inverted indexes in IR systems. In this paper we propose Vector of SplitsEncoding (VSEncoding); a novel class of encoders that work by optimally partitioning a list ofintegers into blocks which are efficiently compressed by using simple encoders. In previousworks heuristics were applied during the partitioning step. Instead; we find the optimalsolution by using a dynamic programming approach. Experiments show that our class ofencoders outperform all the existing methods in literature by more than 10%(with the …,Proceedings of the 19th ACM international conference on Information and knowledge management,2010,61
Assigning identifiers to documents to enhance the clustering property of fulltext indexes,Fabrizio Silvestri; Salvatore Orlando; Raffaele Perego,Abstract Web Search Engines provide a large-scale text document retrieval service byprocessing huge Inverted File indexes. Inverted File indexes allow fast query resolution andgood memory utilization since their d-gaps representation can be effectively and efficientlycompressed by using variable length encoding methods. This paper proposes andevaluates some algorithms aimed to find an assignment of the document identifiers whichminimizes the average values of d-gaps; thus enhancing the effectiveness of traditionalcompression methods. We ran several tests over the Google contest collection in order tovalidate the techniques proposed. The experiments demonstrated the scalability andeffectiveness of our algorithms. Using the proposed algorithms; we were able to sensiblyimprove (up to 20.81%) the compression ratios of several encoding schemes.,Proceedings of the 27th annual international ACM SIGIR conference on Research and development in information retrieval,2004,60
Predicting the next app that you are going to use,Ricardo Baeza-Yates; Di Jiang; Fabrizio Silvestri; Beverly Harrison,Abstract Given the large number of installed apps and the limited screen size of mobiledevices; it is often tedious for users to search for the app they want to use. Although somemobile OSs provide categorization schemes that enhance the visibility of useful apps amongthose installed; the emerging category of homescreen apps aims to take one step further byautomatically organizing the installed apps in a more intelligent and personalized way. Inthis paper; we study how to improve homescreen apps' usage experience through aprediction mechanism that allows to show to users which app she is going to use in theimmediate future. The prediction technique is based on a set of features representing thereal-time spatiotemporal contexts sensed by the homescreen app. We model the predictionof the next app as a classification problem and propose an effective personalized method …,Proceedings of the Eighth ACM International Conference on Web Search and Data Mining,2015,52
Assigning document identifiers to enhance compressibility of web search engines indexes,Fabrizio Silvestri; Raffaele Perego; Salvatore Orlando,Abstract Granting efficient accesses to the index is a key issue for the performances of WebSearch Engines (WSE). In order to enhance memory utilization and favor fast queryresolution; WSEs use Inverted File (IF) indexes where the posting lists are stored assequences of d_gaps (ie differences among successive document identifiers) compressedusing variable length encoding methods. This paper describes the use of a lightweightclustering algorithm aimed at assigning the identifiers to documents in a way that minimizesthe average values of d_gaps. The simulations performed on a real dataset; ie the Googlecontest collection; show that our approach allows to obtain an IF index which is; dependingon the d_gap encoding chosen; up to 23% smaller than the one built over randomlyassigned document identifiers. Moreover; we will show; both analytically and empirically …,Proceedings of the 2004 ACM symposium on Applied computing,2004,51
Mining query logs to optimize index partitioning in parallel web search engines,Claudio Lucchese; Salvatore Orlando; Raffaele Perego; Fabrizio Silvestri,Abstract Large-scale Parallel Web Search Engines (WSEs) needs to adopt a strategy forpartitioning the inverted index among a set of parallel server nodes. In this paper we areinterested in devising an effective term-partitioning strategy; according to which the globalvocabulary of terms and the associated inverted lists are split into disjoint subsets; andassigned to distinct servers. Due to the workload imbalance caused by the skeweddistribution of terms in user queries; finding an effective partitioning strategy is considered avery complex task.,Proceedings of the 2nd international conference on Scalable information systems,2007,50
Scheduling high performance data mining tasks on a data grid environment,Salvatore Orlando; Paolo Palmerini; Raffaele Perego; Fabrizio Silvestri,Abstract Increasingly the datasets used for data mining are becoming huge and physicallydistributed. Since the distributed knowledge discovery process is both data andcomputational intensive; the Grid is a natural platform for deploying a high performance datamining service. The focus of this paper is on the core services of such a Grid infrastructure. Inparticular we concentrate our attention on the design and implementation of specializedbroker aware of data source locations and resource needs of data mining tasks. Allocationand scheduling decisions are taken on the basis of performance cost metrics and modelsthat exploit knowledge about previous executions; and use sampling to acquire estimateabout execution behavior.,European Conference on Parallel Processing,2002,50
WebDocs: a real-life huge transactional dataset.,Claudio Lucchese; Salvatore Orlando; Raffaele Perego; Fabrizio Silvestri,This short note describes the main characteristics of WebDocs; a huge real-life transactionaldataset we made publicly available to the Data Mining community through the FIMIrepository. We built WebDocs from a spidered collection of web html documents. The wholecollection contains about 1.7 millions documents; mainly written in English; and its size isabout 5GB. The transactional dataset was built from the web collection in the following way.All the web documents were preliminarly filtered by removing html tags and the mostcommon words (stopwords); and by applying a stemming algorithm. Then we generatedfrom each document a distinct transaction containing the set of all the distinct terms (items)appearing within the document itself.,FIMI,2004,47
Discovering tasks from search engine query logs,Claudio Lucchese; Salvatore Orlando; Raffaele Perego; Fabrizio Silvestri; Gabriele Tolomei,Abstract Although Web search engines still answer user queries with lists of ten blue links towebpages; people are increasingly issuing queries to accomplish their daily tasks (eg;finding a recipe; booking a flight; reading online news; etc.). In this work; we propose a two-step methodology for discovering tasks that users try to perform through search engines.First; we identify user tasks from individual user sessions stored in search engine query logs.In our vision; a user task is a set of possibly noncontiguous queries (within a user searchsession); which refer to the same need. Second; we discover collective tasks by aggregatingsimilar user tasks; possibly performed by distinct users. To discover user tasks; we proposequery similarity functions based on unsupervised and supervised learning approaches. Wepresent a set of query clustering methods that exploit these functions in order to detect …,ACM Transactions on Information Systems (TOIS),2013,44
Context-and content-aware embeddings for query rewriting in sponsored search,Mihajlo Grbovic; Nemanja Djuric; Vladan Radosavljevic; Fabrizio Silvestri; Narayan Bhamidipati,Abstract Search engines represent one of the most popular web services; visited by morethan 85% of internet users on a daily basis. Advertisers are interested in making use of thisvast business potential; as very clear intent signal communicated through the issued queryallows effective targeting of users. This idea is embodied in a sponsored search model;where each advertiser maintains a list of keywords they deem indicative of increased userresponse rate with regards to their business. According to this targeting model; when aquery is issued all advertisers with a matching keyword are entered into an auctionaccording to the amount they bid for the query; and the winner gets to show their ad. One ofthe main challenges is the fact that a query may not match many keywords; resulting in lowerauction value; lower ad quality; and lost revenue for advertisers and publishers. Possible …,Proceedings of the 38th international ACM SIGIR conference on research and development in information retrieval,2015,41
Making your interests follow you on twitter,Marco Pennacchiotti; Fabrizio Silvestri; Hossein Vahabi; Rossano Venturini,Abstract In this paper we introduce the task of" tweet recommendation"; the problem ofsuggesting tweets that match a user's interests and likes. We propose an Information-Retrieval-like model that leverages the content of the user's tweets and those of her friends;and that effectively retrieves a set of tweets that is personalized and varied in nature. Ourapproach could be easily leveraged to build; for example; a Twitter or Facebook timeline thatcollects messages that are of interest for the user; but that are not posted by her friends. Wecompare to typical approaches used in similar tasks; reporting significant gains in terms ofoverall precision; up to about+ 20%; on both a corpus-based evaluation and real world userstudy.,Proceedings of the 21st ACM international conference on Information and knowledge management,2012,39
An efficient parallel and distributed algorithm for counting frequent sets,Salvatore Orlando; Paolo Palmerini; Raffaele Perego; Fabrizio Silvestri,Abstract Due to the huge increase in the number and dimension of available databases;efficient solutions for counting frequent sets are nowadays very important within the DataMining community. Several sequential and parallel algorithms were proposed; which inmany cases exhibit excellent scalability. In this paper we present ParDCI; a distributed andmultithreaded algorithm for counting the occurrences of frequent sets within transactionaldatabases. ParDCI is a parallel version of DCI (Direct Count & Intersect); a multi-strategyalgorithm which is able to adapt its behavior not only to the features of the specificcomputing platform (eg available memory); but also to the features of the dataset beingprocessed (eg sparse or dense datasets). ParDCI enhances previous proposals byexploiting the highly optimized counting and intersection techniques of DCI; and by …,International Conference on High Performance Computing for Computational Science,2002,39
Design of a parallel and distributed web search engine,Salvatore Orlando; Raffaele Perego; Fabrizio Silvestri,Abstract This paper describes the architecture of MOSE (My Own Search Engine); a scalableparallel and distributed engine for searching the web. MOSE was specifically designed toefficiently exploit affordable parallel architectures; such as clusters of workstations. Itsmodular and scalable architecture can be easily adjusted to fulfill the bandwidthrequirements of the application at hand. Both task-parallel and data-parallel approaches areexploited within MOSE in order to increase the throughput and efficiently usecommunication; storing and computational resources. We used a collection of htmldocuments as a benchmark and conducted preliminary experiments on a cluster of threeSMP Linux PCs.,*,2002,37
On-line generation of suggestions for web users,Fabrizio Silvestri; Ranieri Baraglia; Paolo Palmerini; Massimo Serrano,The knowledge extracted from the analysis of historical information of a Web server can beused to develop personalization or recommendation systems. Web usage mining (WUM)systems are specifically designed to carry out this task by analyzing the data representingusage data about a particular Web site. Typically these systems are composed by two parts.One; executed offline; that analyze the server access logs in order to find a suitablecategorization; and another executed online which is aimed at classifying the activerequests; according to the previous offline analysis. In this paper we propose a WUMrecommendation system; implemented as a module of the Apache Web server that is able todynamically generate suggestions to pages that have not yet been visited by a user andmight be of his potential interest. Differently from previously proposed WUM systems …,Information Technology: Coding and Computing; 2004. Proceedings. ITCC 2004. International Conference on,2004,36
Tuning the capacity of search engines: Load-driven routing and incremental caching to reduce and balance the load,Diego Puppin; Fabrizio Silvestri; Raffaele Perego; Ricardo Baeza-Yates,Abstract This article introduces an architecture for a document-partitioned search engine;based on a novel approach combining collection selection and load balancing; called load-driven routing. By exploiting the query-vector document model; and the incremental cachingtechnique; our architecture can compute very high quality results for any query; with only afraction of the computational load used in a typical document-partitioned architecture. Bytrading off a small fraction of the results; our technique allows us to strongly reduce thecomputing pressure to a search engine back-end; we are able to retrieve more than 2/3 ofthe top-5 results for a given query with only 10&percnt; the computing load needed by aconfiguration where the query is processed by each index partition. Alternatively; we canslightly increase the load up to 25&percnt; to improve precision and get more than …,ACM Transactions on Information Systems (TOIS),2010,35
Generating suggestions for queries in the long tail with an inverted index,Daniele Broccolo; Lorenzo Marcon; Franco Maria Nardini; Raffaele Perego; Fabrizio Silvestri,Abstract This paper proposes an efficient and effective solution to the problem of choosingthe queries to suggest to web search engine users in order to help them in rapidly satisfyingtheir information needs. By exploiting a weak function for assessing the similarity betweenthe current query and the knowledge base built from historical users' sessions; we re-conduct the suggestion generation phase to the processing of a full-text query over aninverted index. The resulting query recommendation technique is very efficient and scalable;and is less affected by the data-sparsity problem than most state-of-the-art proposals. Thus;it is particularly effective in generating suggestions for rare queries occurring in the long tailof the query popularity distribution. The quality of suggestions generated is assessed byevaluating the effectiveness in forecasting the users' behavior recorded in historical query …,Information Processing & Management,2012,34
Efficient query recommendations in the long tail via center-piece subgraphs,Francesco Bonchi; Raffaele Perego; Fabrizio Silvestri; Hossein Vahabi; Rossano Venturini,Abstract We present a recommendation method based on the well-known concept of center-piece subgraph; that allows for the time/space efficient generation of suggestions also forrare; ie; long-tail queries. Our method is scalable with respect to both the size of datasetsfrom which the model is computed and the heavy workloads that current web searchengines have to deal with. Basically; we relate terms contained into queries with highlycorrelated queries in a query-flow graph. This enables a novel recommendation generationmethod able to produce recommendations for approximately 99% of the workload of a real-world search engine. The method is based on a graph having term nodes; query nodes; andtwo kinds of connections: term-query and query-query. The first connects a term to thequeries in which it is contained; the second connects two query nodes if the likelihood …,Proceedings of the 35th international ACM SIGIR conference on Research and development in information retrieval,2012,32
Prefetching query results and its impact on search engines,Simon Jonassen; B Barla Cambazoglu; Fabrizio Silvestri,Abstract We investigate the impact of query result prefetching on the efficiency andeffectiveness of web search engines. We propose offline and online strategies for selectingand ordering queries whose results are to be prefetched. The offline strategies rely on querylog analysis and the queries are selected from the queries issued on the previous day. Theonline strategies select the queries from the result cache; relying on a machine learningmodel that estimates the arrival times of queries. We carefully evaluate the proposedprefetching techniques via simulation on a query log obtained from Yahoo! web search. Wedemonstrate that our strategies are able to improve various performance metrics; includingthe hit rate; query response time; result freshness; and query degradation rate; relative to astate-of-the-art baseline.,Proceedings of the 35th international ACM SIGIR conference on Research and development in information retrieval,2012,31
How random walks can help tourism,Claudio Lucchese; Raffaele Perego; Fabrizio Silvestri; Hossein Vahabi; Rossano Venturini,Abstract On-line photo sharing services allow users to share their touristic experiences.Tourists can publish photos of interesting locations or monuments visited; and they can alsoshare comments; annotations; and even the GPS traces of their visits. By analyzing suchdata; it is possible to turn colorful photos into metadata-rich trajectories through the points ofinterest present in a city. In this paper we propose a novel algorithm for the interactivegeneration of personalized recommendations of touristic places of interest based on theknowledge mined from photo albums and Wikipedia. The distinguishing features of ourapproach are multiple. First; the underlying recommendation model is built fullyautomatically in an unsupervised way and it can be easily extended with heterogeneoussources of information. Moreover; recommendations are personalized according to the …,European Conference on Information Retrieval,2012,31
State of the art report; gap analysis of knowledge on principles; techniques and methodologies for monitoring and adaptation of SBAs,Salima Benbernou; LCMS Hacid; R Kazhamiakin; G Kecskemeti; JL Poizat; F Silvestri; M Uhlig; B Wetzstein,*,S-Cube Consortium; Deliverable PO-JRA-1.2,2008,31
The social network of java classes,Diego Puppin; Fabrizio Silvestri,Abstract Several works in literature have analyzed the link structure of programs in relationwith software engineering: it has been observed that the programming standards causedsmall-world networks to emerge among classes in object-oriented programming. The needfor coherent design and the coding conventions introduce regular patterns in the linkstructure of code. In this work; we study the social network naturally emerging from unrelatedsoftware projects. We studied the links present among Java classes coming from differentcontexts. In this case; any observable patterns come from social behaviors; rather thansoftware engineering practices. In our analysis; we could observe a regular social network;organized according to a power-law distribution that is typical; for instance; of links amongWeb pages. We give a positive value to class links; which we consider a sign of relevance …,Proceedings of the 2006 ACM symposium on Applied computing,2006,28
Sorting on GPUs for large scale datasets: A thorough comparison,Gabriele Capannini; Fabrizio Silvestri; Ranieri Baraglia,Abstract Although sort has been extensively studied in many research works; it still remainsa challenge in particular if we consider the implications of novel processor technologiessuch as manycores (ie GPUs; Cell/BE; multicore; etc.). In this paper; we compare differentalgorithms for sorting integers on stream multiprocessors and we discuss their viability onlarge datasets (such as those managed by search engines). In order to fully exploit thepotentiality of the underlying architecture; we designed an optimized version of sortingnetwork in the K-model; a novel computational model designed to consider all the importantfeatures of many-core architectures. According to K-model; our bitonic sorting networkmapping improves the three main aspects of many-core architectures; ie the processorsexploitation; and the on-chip/off-chip memory bandwidth utilization. Furthermore we are …,Information Processing & Management,2012,23
Search shortcuts: a new approach to the recommendation of queries,Ranieri Baraglia; Fidel Cacheda; Victor Carneiro; Diego Fernandez; Vreixo Formoso; Raffaele Perego; Fabrizio Silvestri,Abstract The recommendation of queries; known as query suggestion; is a common practiceon major Web Search Engines. It aims to help users to find the information they are lookingfor; and is usually based on the knowledge learned from past interactions with the searchengine. In this paper we propose a new model for query suggestion; the Search ShortcutProblem; that consists in recommending" successful" queries that allowed other users tosatisfy; in the past; similar information needs. This new model has several advantages withrespect to traditional query suggestion approaches. First; it allows a straightforwardevaluation of algorithms from available query log data. Moreover; it simplifies the applicationof several recommendation techniques from other domains. Particularly; in this work weapplied Collaborative Filtering to this problem; and evaluated the interesting results …,Proceedings of the third ACM conference on Recommender systems,2009,23
Caching query-biased snippets for efficient retrieval,Diego Ceccarelli; Claudio Lucchese; Salvatore Orlando; Raffaele Perego; Fabrizio Silvestri,Abstract Web Search Engines' result pages contain references to the top-k documentsrelevant for the query submitted by a user. Each document is represented by a title; a snippetand a URL. Snippets; ie short sentences showing the portions of the document beingrelevant to the query; help users to select the most interesting results. The snippetgeneration process is very expensive; since it may require to access a number of documentsfor each issued query. We assert that caching; a popular technique used to enhanceperformance at various levels of any computing systems; can be very effective in this context.We design and experiment several cache organizations; and we introduce the concept ofsupersnippet; that is the set of sentences in a document that are more likely to answer futurequeries. We show that supersnippets can be built by exploiting query logs; and that in our …,Proceedings of the 14th International Conference on Extending Database Technology,2011,22
Sorting using bitonic network with CUDA,Ranieri Baraglia; Gabriele Capannini; Franco Maria Nardini; Fabrizio Silvestri,ABSTRACT Novel “manycore” architectures; such as graphics processors; are high-paralleland high-performance shared-memory architectures [7] born to solve specific problems suchas the graphical ones. Those architectures can be exploited to solve a wider range ofproblems by designing the related algorithm for such architectures. We present a fast sortingalgorithm implementing an efficient bitonic sorting network. This algorithm is highly suitablefor information retrieval applications. Sorting is a fundamental and universal problem incomputer science. Even if sort has been extensively addressed by many research works; itstill remains an interesting challenge to make it faster by exploiting novel technologies. Inthis light; this paper shows how to use graphics processors as coprocessors to speed upsorting while allowing CPU to perform other tasks. Our new algorithm exploits a memory …,the 7th Workshop on Large-Scale Distributed Systems for Information Retrieval (LSDS-IR); Boston; USA,2009,21
Load-balancing and caching for collection selection architectures,Diego Puppin; Fabrizio Silvestri; Raffaele Perego; Ricardo Baeza-Yates,Abstract To address the rapid growth of the Internet; modern Web search engines have toadopt distributed organizations; where the collection of indexed documents is partitionedamong several servers; and query answering is performed as a parallel and distributed task.Collection selection can be a way to reduce the overall computing load; by finding a trade-offbetween the quality of results retrieved and the cost of solving queries. In this paper; weanalyze the relationship between the collection selection strategy; the effect on loadbalancing and on the caching subsystem; by exploring the design-space of a distributedsearch engine based on collection selection. In particular; we propose a strategy to performcollection selection in a load-driven way; and a novel caching policy able to incrementallyrefine the effectiveness of the results returned for each subsequent cache hit. The …,Proceedings of the 2nd international conference on Scalable information systems,2007,19
The query-vector document model,Diego Puppin; Fabrizio Silvestri,Introduction. Modern Web IR systems have to manage collections of billions of documents.The indexes used to represent them are very large data structures; the form of which canhave a big impact on the quality and the speed of IR algorithms. Traditionally; two main waysare used to model the documents available: the bag-of-words model; and the vector-spacemodel. In the query-vector document model; documents are modeled with the list of queriesthey match; along with the rank they get for each. The query-vector representation of adocument is built out of a query-log. A reference search engine is used in the buildingphase: for every query in the training set; the system stores the first 100 results along withtheir rank. This creates a matrix; with documents on columns and queries on rows; whereeach entry is the rank of a document for a given query.,Proceedings of the 15th ACM international conference on Information and knowledge management,2006,19
Aging effects on query flow graphs for query suggestion,Ranieri Baraglia; Carlos Castillo; Debora Donato; Franco Maria Nardini; Raffaele Perego; Fabrizio Silvestri,Abstract World Wide Web content continuously grows in size and importance. Furthermore;users ask Web search engines to satisfy increasingly disparate information needs. Newtechniques and tools are constantly developed aimed at assisting users in the interactionwith the Web search engine. Query recommender systems suggesting interesting queries tousers are an example of such tools. Most query recommendation techniques are based onthe knowledge of the behaviors of past users of the search engine recorded in query logs. Arecent query-log mining approach for query recommendation is based on Query FlowGraphs (QFG). In this paper we propose an evaluation of the effects of time on this queryrecommendation model. As users interests change over time; the knowledge extracted fromquery logs may suffer an aging effect as new interesting topics appear. In order to validate …,Proceedings of the 18th ACM conference on Information and knowledge management,2009,18
The effects of time on query flow graph-based models for query suggestion,Ranieri Baraglia; Franco Maria Nardini; Carlos Castillo; Raffaele Perego; Debora Donato; Fabrizio Silvestri,Abstract A recent query-log mining approach for query recommendation is based on QueryFlow Graphs; a markov-chain representation of the query reformulation process followed byusers of Web Search Engines trying to satisfy their information needs. In this paper we aim atextending this model by providing methods for dealing with evolving data. In fact; users'interests change over time; and the knowledge extracted from query logs may suffer anaging effect as new interesting topics appear. Starting from this observation validatedexperimentally; we introduce a novel algorithm for updating an existing query flow graph.The proposed solution allows the recommendation model to be kept always updated withoutreconstructing it from scratch every time; by incrementally merging efficiently the past andpresent data.,Adaptivity; Personalization and Fusion of Heterogeneous Information,2010,17
Method of detecting spam hosts based on clustering the host graph,*,Systems and methods for identifying spam hosts are disclosed in which hosts are known tothe system and initially classified as spam or non-spam. Then the hosts are partitioned intoclusters based on how each host is linked to other hosts. Each cluster is then analyzed and;depending on the number of spam and non-spam hosts it contains; the cluster may beclassified as a spam cluster or a non-spam cluster. The hosts within the cluster may then bereclassified based on the cluster's classification. The results may then be used in manydifferent ways including to filter search results based on host classifications so that spamhosts are not displayed or displayed last in a results set.,*,2009,17
Promoting positive post-click experience for in-stream yahoo gemini users,Mounia Lalmas; Janette Lehmann; Guy Shaked; Fabrizio Silvestri; Gabriele Tolomei,Abstract Click-through rate (CTR) is the most common metric used to assess theperformance of an online advert; another performance of an online advert is the user post-click experience. In this paper; we describe the method we have implemented in YahooGemini to measure the post-click experience on Yahoo mobile news streams via anautomatic analysis of advert landing pages. We measure the post-click experience bymeans of two well-known metrics; dwell time and bounce rate. We show that these metricscan be used as proxy of an advert post-click experience; and that a negative post-clickexperience has a negative effect on user engagement and future ad clicks. We then putforward an approach that analyses advert landing pages; and show how these can affectdwell time and bounce rate. Finally; we develop a prediction model for advert quality …,Proceedings of the 21th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining,2015,16
A privacy preserving web recommender system,Ranieri Baraglia; Claudio Lucchese; Salvatore Orlando; Massimo Serrano; Fabrizio Silvestri,Abstract In this paper we propose a recommender system that helps users to navigatethough the Web by providing dynamically generated links to pages that have not yet beenvisited and are of potential interest. To this end; traditional recommender systems use WebUsage Mining (WUM) techniques in order to automatically extract knowledge from Webusage data. Thanks to WUM techniques we are able to classify users and adaptively provideuseful recommendations. The drawback of a user classification approach is that it makes thesystem prone to privacy breaches. Our contribution here is πSUGGEST; a privacy enhancedrecommender system that allows for creating serendipity recommendations withoutbreaching users privacy. We will show that our system does not provide malicious users withany mean to track or detect users activity or preferences.,Proceedings of the 2006 ACM symposium on Applied computing,2006,16
Improving post-click user engagement on native ads via survival analysis,Nicola Barbieri; Fabrizio Silvestri; Mounia Lalmas,Abstract In this paper we focus on estimating the post-click engagement on native ads bypredicting the dwell time on the corresponding ad landing pages. To infer relationshipsbetween features of the ads and dwell time we resort to the application of survival analysistechniques; which allow us to estimate the distribution of the length of time that the user willspend on the ad. This information is then integrated into the ad ranking function with the goalof promoting the rank of ads that are likely to be clicked and consumed by users (dwell timegreater than a given threshold). The online evaluation over live traffic shows that consideringpost-click engagement has a consistent positive effect on both CTR; decreases the numberof bounces and increases the average dwell time; hence leading to a better user post-clickexperience.,Proceedings of the 25th International Conference on World Wide Web,2016,15
High performance issues in web search engines: Algorithms and techniques,Fabrizio Silvestri,Abstract For hundreds of years the mankind has organized information in order to make itmore accessible to the others. The last media born to globally provide information is theInternet. With the Web; in particular; the name of the Internet has spread all over the World.Due to its impressive size and its high dinamicity; when we need to search for information onthe Web; usually we begin by querying a Web Search Engine. A Web Search Enginemaintains and catalogs the content of Web pages in order to make them easier to find andbrowse. Even though the various Search Engines are similar; each one of themdifferentiates from the other by the methods for scouring; storing; and retrieving informationfrom the Web. Usually Search Engines search through Web pages for specified keywords. Inresponse they return a list containing those documents containing the specified keywords …,*,2004,15
Load-sensitive selective pruning for distributed search,Daniele Broccolo; Craig Macdonald; Salvatore Orlando; Iadh Ounis; Raffaele Perego; Fabrizio Silvestri; Nicola Tonellotto,Abstract A search engine infrastructure must be able to provide the same quality of service toall queries received during a day. During normal operating conditions; the demand forresources is considerably lower than under peak conditions; yet an oversized infrastructurewould result in an unnecessary waste of computing power. A possible solution adopted inthis situation might consist of defining a maximum threshold processing time for each query;and dropping queries for which this threshold elapses; leading to disappointed users. In thispaper; we propose and evaluate a different approach; where; given a set of different queryprocessing strategies with differing efficiency; each query is considered by a framework thatsets a maximum query processing time and selects which processing strategy is the best forthat query; such that the processing time for all queries is kept below the threshold. The …,Proceedings of the 22nd ACM international conference on Information & Knowledge Management,2013,14
Recommendations for the long tail by term-query graph,Francesco Bonchi; Raffaele Perego; Fabrizio Silvestri; Hossein Vahabi; Rossano Venturini,Abstract We define a new approach to the query recommendation problem. In particular; ourmain goal is to design a model enabling the generation of query suggestions also for rareand previously unseen queries. In other words we are targeting queries in the long tail. Themodel is based on a graph having two sets of nodes: Term nodes; and Query nodes. Thegraph induces a Markov chain on which a generic random walker starts from a subset ofTerm nodes; moves along Query nodes; and restarts (with a given probability) only from thesame initial subset of Term nodes. Computing the stationary distribution of such a Markovchain is equivalent to extracting the so-called Center-piece Subgraph from the graphassociated with the Markov chain itself. Given a query; we extract its terms and we set therestart subset to this term set. Therefore; we do not require a query to have been …,Proceedings of the 20th international conference companion on World wide web,2011,14
Biological experiments on the grid: A novel workflow management platform,Domenico Laforenza; Rosario Lombardo; M Scarpellini; Massimo Serrano; Fabrizio Silvestri; P Faccioli,Bioinformatics is one of the key application of this century. The attention received by all thecurrent media is astonishing and both academics and industries are carrying on researchesin many fields related to computational methods applied to life sciences. In this paper wepresent some results obtained within an Italian funded research project calledESCOGITARE. We present the design and implementation of a grid-based architecture forscientific workflow management that; differently from others; allows the dynamic discovery ofexisting Web services in combination to ad-hoc developed ones. The paper presents themain features of current scientific workflow management systems. Using a real-world casestudy (taken by the agricultural research domain); we show how we overcome the limitationsof current approaches.,Computer-Based Medical Systems; 2007. CBMS'07. Twentieth IEEE International Symposium on,2007,14
A scalable multi-strategy algorithm for counting frequent sets,Salvatore Orlando; P Palmerini; R Perego; F Silvestri,Abstract In this paper we present DCI; a new data mining algorithm for frequent set counting.We also discuss in depth the parallelization strategies used in the design of ParDCI; thedistributed and multi-threaded algorithm derived from DCI. Multiple heuristics strategies areadopted within DCI; so that the algorithm is able to adapt its behavior not only to the featuresof the specific computing platform; but also to the features of the dataset being processed.Our approach turned out to be highly scalable and very efficient for mining both short andlong patterns present in real and synthetically generated datasets. The experimental resultsshowed that DCI outperforms others previously proposed algorithms under a variety ofconditions. ParDCI; the parallel version of DCI; is explicitly devised for targeting clusters ofSMP nodes: shared memory and message passing paradigms were used at intra-and …,Proc. Of the 4th International Conference on Knowledge Discovery and Data Mining (KDD); New York; USA,2002,13
LearNext: learning to predict tourists movements,Ranieri Baraglia; Cristina Ioana Muntean; Franco Maria Nardini; Fabrizio Silvestri,Abstract In this paper; we tackle the problem of predicting the" next" geographical position ofa tourist given her history (ie; the prediction is done accordingly to the tourist's current trail)by means of supervised learning techniques; namely Gradient Boosted Regression Treesand Ranking SVM. The learning is done on the basis of an object space represented by a 68dimension feature vector; specifically designed for tourism related data. Furthermore; wepropose a thorough comparison of several methods that are considered state-of-the-art intouristic recommender and trail prediction systems as well as a strong popularity baseline.Experiments show that the methods we propose outperform important competitors andbaselines thus providing strong evidence of the performance of our solutions.,Proceedings of the 22nd ACM international conference on Information & Knowledge Management,2013,12
Challenges in designing an interest-based distributed aggregation of users in p2p systems,Matteo Mordacchini; Patrizio Dazzi; Gabriele Tolomei; Ranieri Baraglia; Fabrizio Silvestri; Salvatore Orlando,Most users retrieve and access resources in complex systems; like distributed virtualenvironments (DVE); or the Web by querying centralized search engines. Such systemsnormally compute their answers by estimating query-document similarities to rank theresults; but also global ranks of the result pages by exploiting the hyperlink Web structure.User interests typically follow a sort of clustering property: users interested in a topic in thepast are likely to be interested in these same topic also in the future. It follows that searchresults considered relevant by a user belonging to a group of homogeneous users will likelyalso be of interest to other users from the same group. In this paper; we propose thearchitecture of a peer-to-peer system that exploits a collaborative search mechanism; basedon interest similarities among users. The paper discusses the challenges associated with …,Ultra Modern Telecommunications & Workshops; 2009. ICUMT'09. International Conference on,2009,12
You should read this! let me explain you why: explaining news recommendations to users,Roi Blanco; Diego Ceccarelli; Claudio Lucchese; Raffaele Perego; Fabrizio Silvestri,Abstract Recommender systems have become ubiquitous in content-based webapplications; from news to shopping sites. Nonetheless; an aspect that has been largelyoverlooked so far in the recommender system literature is that of automatically buildingexplanations for a particular recommendation. This paper focuses on the news domain; andproposes to enhance effectiveness of news recommender systems by adding; to eachrecommendation; an explanatory statement to help the user to better understand if; and why;the item can be her interest. We consider the news recommender system as a black-box;and generate different types of explanations employing pieces of information associatedwith the news. In particular; we engineer text-based; entity-based; and usage-basedexplanations; and make use of a Markov Logic Networks to rank the explanations on the …,Proceedings of the 21st ACM international conference on Information and knowledge management,2012,11
Incremental algorithms for effective and efficient query recommendation,Daniele Broccolo; Ophir Frieder; Franco Maria Nardini; Raffaele Perego; Fabrizio Silvestri,Abstract Query recommender systems give users hints on possible interesting queriesrelative to their information needs. Most query recommenders are based on staticknowledge models built on the basis of past user behaviors recorded in query logs. Thesemodels should be periodically updated; or rebuilt from scratch; to keep up with the possiblevariations in the interests of users. We study query recommender algorithms that generatesuggestions on the basis of models that are updated continuously; each time a new query issubmitted. We extend two state-of-the-art query recommendation algorithms and evaluatethe effects of continuous model updates on their effectiveness and efficiency. Testsconducted on an actual query log show that contrasting model aging by continuouslyupdating the recommendation model is a viable and effective solution.,International Symposium on String Processing and Information Retrieval,2010,11
A peer-to-peer information service for the grid,Diego Puppin; Stefano Moncelli; Ranieri Baraglia; Nicola Tonellotto; Fabrizio Silvestri,Abstract Information Services are fundamental blocks of the Grid infrastructure. They areresponsible for collecting and distributing information about resource availability and statusto users: the quality of these data may have a strong impact on scheduling algorithms andapplication performance. Many popular information services have a centralized structure.This clearly introduces problems related to information updating andfault tolerance. Also; invery large configurations; scalability may be an issue. In this work; we present a GridInformation Service based on the peer-to-peer technology. Our system offers a fastpropagation of information and has high scalability and reliability. We implemented oursystem complying to the OGSA standard using the Globus Toolkit 3. Our system can run onLinux and Windows systems; with different network configurations; so to trade off between …,Proc. of International Conference on Broadband Networks; San Jose; CA; USA,2004,11
Toward a search architecture for software components,Fabrizio Silvestri; Diego Puppin; Domenico Laforenza; Salvatore Orlando,Abstract The Grid and its related technologies enable large-scale sharing of resources ofvarious types. We envision that in the near future applications will be completely built in abottom-up fashion using software components deployed on various locations andinterconnected to form a workflow graph. In this paper; we make some proposals on thedesign of a component search service; enabling users to locate the components they needto deploy an application. Copyright© 2005 John Wiley & Sons; Ltd.,Concurrency and Computation: Practice and Experience,2006,10
Post-learning optimization of tree ensembles for efficient ranking,Claudio Lucchese; Franco Maria Nardini; Salvatore Orlando; Raffaele Perego; Fabrizio Silvestri; Salvatore Trani,Abstract Learning to Rank (LtR) is the machine learning method of choice for producing highquality document ranking functions from a ground-truth of training examples. In practice;efficiency and effectiveness are intertwined concepts and trading off effectiveness formeeting efficiency constraints typically existing in large-scale systems is one of the mosturgent issues. In this paper we propose a new framework; named CLEaVER; for optimizingmachine-learned ranking models based on ensembles of regression trees. The goal is toimprove efficiency at document scoring time without affecting quality. Since the cost of anensemble is linear in its size; CLEaVER first removes a subset of the trees in the ensemble;and then fine-tunes the weights of the remaining trees according to any given qualitymeasure. Experiments conducted on two publicly available LtR datasets show that …,Proceedings of the 39th International ACM SIGIR conference on Research and Development in Information Retrieval,2016,9
Scalable semantic matching of queries to ads in sponsored search advertising,Mihajlo Grbovic; Nemanja Djuric; Vladan Radosavljevic; Fabrizio Silvestri; Ricardo Baeza-Yates; Andrew Feng; Erik Ordentlich; Lee Yang; Gavin Owens,Abstract Sponsored search represents a major source of revenue for web search engines.The advertising model brings a unique possibility for advertisers to target direct user intentcommunicated through a search query; usually done by displaying their ads alongsideorganic search results for queries deemed relevant to their products or services. However;due to a large number of unique queries; it is particularly challenging for advertisers toidentify all relevant queries. For this reason search engines often provide a service ofadvanced matching; which automatically finds additional relevant queries for advertisers tobid on. We present a novel advance match approach based on the idea of semanticembeddings of queries and ads. The embeddings were learned using a large data set ofuser search sessions; consisting of search queries; clicked ads and search links; while …,Proceedings of the 39th International ACM SIGIR conference on Research and Development in Information Retrieval,2016,9
Heads: Headline generation as sequence prediction using an abstract feature-rich space,Carlos A Colmenares; Marina Litvak; Amin Mantrach; Fabrizio Silvestri,Abstract Automatic headline generation is a sub-task of document summarization with manyreported applications. In this study we present a sequence-prediction technique for learninghow editors title their news stories. The introduced technique models the problem as adiscrete optimization task in a feature-rich space. In this space the global optimum can befound in polynomial time by means of dynamic programming. We train and test our model onan extensive corpus of financial news; and compare it against a number of baselines byusing standard metrics from the document summarization domain; as well as some newones proposed in this work. We also assess the readability and informativeness of thegenerated titles through human evaluation. The obtained results are very appealing andsubstantiate the soundness of the approach.,Proceedings of the 2015 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies,2015,9
A trajectory-based recommender system for tourism,Ranieri Baraglia; Claudio Frattari; Cristina Ioana Muntean; Franco Maria Nardini; Fabrizio Silvestri,Abstract Recommendation systems provide focused information to users on a set of objectsbelonging to a specific domain. The proposed recommender system provides personalizedsuggestions about touristic points of interest. The system generates recommendations;consisting of touristic places; according to the current position of a tourist and previouslycollected data describing tourist movements in a touristic location/city. The touristic sitescorrespond to a set of points of interest identified a priori. We propose several metrics toevaluate both the spatial coverage of the dataset and the quality of recommendationsproduced. We assess our system on two datasets: a real and a synthetic one. Results showthat our solution is a viable one.,International Conference on Active Media Technology,2012,9
System and method for identifying spam hosts using stacked graphical learning,*,Systems and methods for identifying spam hosts are disclosed in which hosts known to thesystem and initially classified as spam or non-spam by a baseline classifier. Then for eachnode u in the host graph a new feature is computed. This feature is an aggregate function ofthe initial classifications produced by the baseline classifier for the neighbors of the node u.The set of neighbors can be defined in many different ways: in-link neighbors; out-linkneighbors; bi-directional neighbors; k-hops neighbors; etc. The new feature computedabove then is added to the existing set of features; and the baseline classifier is trainedagain; producing new predictions for each node. The results may then be used in manydifferent ways including to filter search results based on host classifications so that spamhosts are not displayed or displayed last in a results set.,*,2009,9
Method of detecting spam hosts based on propagating prediction labels,*,Systems and methods for identifying spam hosts are disclosed in which hosts are known tothe system and initially classified as spam or non-spam by a baseline classifier. Theaccuracy of the initial host classifications are then improved by propagating them using arandom walk algorithm. The random walk used may be modified in order to obtain aweighted or skewed characterization of the host. The hosts may then be reclassified basedon the characterization obtained from the random walk to obtain a final spam/non-spamclassification. The final classification may then be used in many different ways including tofilter search results based on host classifications so that spam hosts are not displayed ordisplayed last in a results set.,*,2009,9
Efficient diversification of search results using query logs,Gabriele Capannini; Franco Maria Nardini; Raffaele Perego; Fabrizio Silvestri,Abstract We study the problem of diversifying search results by exploiting the knowledgemined from query logs. Our proposal exploits the presence of different" specializations" ofqueries in query logs to detect the submission of ambiguous/faceted queries; and managethem by diversifying the search results returned in order to cover the different possibleinterpretations of the query. We present an original formulation of the results diversificationproblem in terms of an objective function to be maximized that admits the finding of anoptimal solution in linear time.,Proceedings of the 20th international conference companion on World wide web,2011,8
K-model: A new computational model for stream processors,Gabriele Capannini; Fabrizio Silvestri; Ranieri Baraglia,We introduce K-model; a computational model to evaluate the algorithms designed forgraphic processors; and other architectures adhering to the stream programming model. Weaddress the lack of a formal complexity model that properly accounts for memory contention;address coalescing in memory accesses; or the serial control of instruction flows. We studythe impact of K-model rules on algorithm design. We devise a coalesced and low contentiondata access technique for Batcher's networks; and we evaluate the effectiveness of thistechnique within our K-model. To evaluate the benefits in using K-model in evaluatingsolutions for streaming architectures; we compare the complexity of a sorting network builtusing our technique; and quick sort. Although in theory quick sort is more efficient thanbitonic sort; empirically; our bitonic sorting network has been shown to be faster than the …,High Performance Computing and Communications (HPCC); 2010 12th IEEE International Conference on,2010,8
On using query logs for static index pruning,Hoang Thanh Lam; Raffaele Perego; Fabrizio Silvestri,Static index pruning techniques aim at removing from the posting lists of an inverted file thereferences to documents which are likely to be not relevant for answering user queries. Thereduction in the size of the index results in a better exploitation of memory hierarchies andfaster query processing. On the other hand; pruning may affect the precision of theinformation retrieval system; since pruned entries are unavailable at query processing time.Static pruning techniques proposed so far exploit query-independent measures to evaluatethe importance of a document within a posting list. This paper proposes a general frameworkthat aims at enhancing the precision of any static pruning methods by exploiting usageinformation extracted from query logs. Experiments conducted on the TREC WT10g Webcollection and a large Altavista query log show that integrating usage knowledge into the …,Web Intelligence and Intelligent Agent Technology (WI-IAT); 2010 IEEE/WIC/ACM International Conference on,2010,8
Entry pairing in inverted file,Hoang Thanh Lam; Raffaele Perego; Nguyen Thoi Minh Quan; Fabrizio Silvestri,Abstract This paper proposes to exploit content and usage information to rearrange aninverted index for a full-text IR system. The idea is to merge the entries of two frequently co-occurring terms; either in the collection or in the answered queries; to form a single; paired;entry. Since postings common to paired terms are not replicated; the resulting index is morecompact. In addition; queries containing terms that have been paired are answered fastersince we can exploit the pre-computed posting intersection. In order to choose which termshave to be paired; we formulate the term pairing problem as a Maximum-Weight MatchingGraph problem; and we evaluate in our scenario efficiency and efficacy of both an exact anda heuristic solution. We apply our technique:(i) to compact a compressed inverted file builton an actual Web collection of documents; and (ii) to increase capacity of an in-memory …,International Conference on Web Information Systems Engineering,2009,8
On learning prediction models for tourists paths,Cristina Ioana Muntean; Franco Maria Nardini; Fabrizio Silvestri; Ranieri Baraglia,Abstract In this article; we tackle the problem of predicting the “next” geographical position ofa tourist; given her history (ie; the prediction is done accordingly to the tourist's current trail)by means of supervised learning techniques; namely Gradient Boosted Regression Treesand Ranking SVM. The learning is done on the basis of an object space represented by a 68-dimension feature vector specifically designed for tourism-related data. Furthermore; wepropose a thorough comparison of several methods that are considered state-of-the-art inrecommender and trail prediction systems for tourism; as well as a popularity baseline.Experiments show that the methods we propose consistently outperform the baselines andprovide strong evidence of the performance and robustness of our solutions.,ACM Transactions on Intelligent Systems and Technology (TIST),2015,7
Collaborative ranking of grid-enabled workflow service providers,Domenico Laforenza; Franco Maria Nardini; Fabrizio Silvestri,Abstract Service Oriented Architecture (SOA) and Grid computing are very hot researchtopics; nowadays. While Grid computing is aimed at sharing dynamically heterogeneousresources; SOAs is a meta-architectural style that enable business flexibility in aninteroperable way. There is a growing consensus that SOA (s) and Grid (s) might bebeneficial to each other. In Grid-based SOAs a central role is played by tools for thepublishing/discovering of services (resources). This work presents SPRanker (ServiceProvider Ranker): a service discovery tool that is able to retrieve providers from partiallyspecified service descriptions. It ranks providers found on the basis of an InformationRetrieval-based score formula that takes into account judgments expressed collaborativelyby past service users.,Proceedings of the 17th international symposium on High performance distributed computing,2008,7
WINGS: a parallel indexer for Web contents,Fabrizio Silvestri; Salvatore Orlando; Raffaele Perego,Abstract In this paper we discuss the design of a parallel indexer for Web documents. Byexploiting both data and pipeline parallelism; our prototype indexer efficiently builds apartitioned inverted compressed index; a suitable data structure commonly utilized bymodern Web Search Engines. We discuss implementation issues and report the results ofpreliminary tests conducted on a SMP PCs.,International Conference on Computational Science,2004,7
IntoNews: Online news retrieval using closed captions,Roi Blanco; Gianmarco De Francisci Morales; Fabrizio Silvestri,Abstract We present I nto N ews; a system to match online news articles with spoken newsfrom a television newscasts represented by closed captions. We formalize the newsmatching problem as two independent tasks: closed captions segmentation and newsretrieval. The system segments closed captions by using a windowing scheme: sliding ortumbling window. Next; it uses each segment to build a query by extracting representativeterms. The query is used to retrieve previously indexed news articles from a search engine.To detect when a new article should be surfaced; the system compares the set of retrievedarticles with the previously retrieved one. The intuition is that if the difference between thesesets is large enough; it is likely that the topic of the newscast currently on air has changedand a new article should be displayed to the user. In order to evaluate I nto N ews; we …,Information Processing & Management,2015,6
Modeling and predicting the task-by-task behavior of search engine users,Claudio Lucchese; Salvatore Orlando; Raffaele Perego; Fabrizio Silvestri; Gabriele Tolomei,Abstract Web search engines answer user needs on a query-by-query fashion; namely theyretrieve the set of the most relevant results to each issued query; independently. However;users often submit queries to perform multiple; related tasks. In this paper; we first discuss amethodology to discover from query logs the latent tasks performed by users. Furthermore;we introduce the Task Relation Graph (TRG) as a representation of users' search behaviorson a task-by-task perspective. The task-by-task behavior is captured by weighting the edgesof TRG with a relatedness score computed between pairs of tasks; as mined from the querylog. We validate our approach on a concrete application; namely a task recommendersystem; which suggests related tasks to users on the basis of the task predictions derivedfrom the TRG. Finally; we show that the task recommendations generated by our solution …,Proceedings of the 10th Conference on Open Research Areas in Information Retrieval,2013,6
Towards leveraging closed captions for news retrieval,Roi Blanco; Gianmarco De Francisci Morales; Fabrizio Silvestri,Abstract IntoNow from Yahoo! is a second screen application that enhances the way ofwatching TV programs. The application uses audio from the TV set to recognize the programbeing watched; and provides several services for different use cases. For instance; whilewatching a football game on TV it can show statistics about the teams playing; or show thetitle of the song performed by a contestant in a talent show. The additional content providedby IntoNow is a mix of editorially curated and automatically selected one. From a researchperspective; one of the most interesting and challenging use cases addressed by IntoNow isrelated to news programs (newscasts). When a user is watching a newscast; IntoNowdetects it and starts showing online news articles from the Web. This work presents apreliminary study of this problem; ie; to find an online news article that matches the piece …,Proceedings of the 22nd International Conference on World Wide Web,2013,6
S-Cube: Addressing Multidisciplinary Research Challenges for the Internet of Services.,Elisabetta Di Nitto; Dimka Karastoyanova; Andreas Metzger; Michael Parkin; Marco Pistore; Klaus Pohl; Fabrizio Silvestri; Willem-Jan Van den Heuvel,Abstract. The Service Oriented Architecture (SOA) is increasingly adopted by industry as aparadigm for building distributed software applications. Yet; the SOA has currently severalserious limitations and many crucial service issues are not addressed; including; forexample; how to establish; monitor and enforce quality in an end-to-end fashion; as well ashow to build service-based applications that proactively adapt to dynamically changingrequirements and context conditions. This paper provides an overview of the serviceresearch challenges identified in S-Cube; the European Network of Excellence on SoftwareServices and Systems. S-Cube strives to address those challenges by bringing togetherresearchers from leading research institutions across diverse disciplines. The S-Cuberesearchers are joining their competences to develop foundations and theories; as well …,Future Internet Assembly,2009,6
SIGIR workshop report: the SIGIR heterogeneous and distributed information retrieval workshop,Ranieri Baraglia; Domenico Laforenza; Fabrizio Silvestri,Abstract In the last few years there have been the explosion in the use of heterogeneousdistributed systems. Ranging from simple Network of Workstations to the more modern andcomplex Grid systems; the adoption of distributed systems instead of massively parallelsupercomputers has been preferred due to their reduced cost of ownership. These kinds ofsystems pose many challenges in terms of information access; storage and retrieval.Usually; in fact; instead of having collections stored at a single site they are collected; andsometimes managed; at different sites (possibly owned by different institutions). Particularinterest has been expressed on architectures and specifications for information retrieval inthe context of heterogeneous distributed computing systems.,ACM SIGIR Forum,2005,6
Tour recommendation for groups,Aris Anagnostopoulos; Reem Atassi; Luca Becchetti; Adriano Fazzone; Fabrizio Silvestri,Abstract Consider a group of people who are visiting a major touristic city; such as NY; Paris;or Rome. It is reasonable to assume that each member of the group has his or her owninterests or preferences about places to visit; which in general may differ from those of othermembers. Still; people almost always want to hang out together and so the followingquestion naturally arises: What is the best tour that the group could perform together in thecity? This problem underpins several challenges; ranging from understanding people'sexpected attitudes towards potential points of interest; to modeling and providing good andviable solutions. Formulating this problem is challenging because of multiple competingobjectives. For example; making the entire group as happy as possible in general conflictswith the objective that no member becomes disappointed. In this paper; we address the …,Data Mining and Knowledge Discovery,2017,5
Query processing in highly-loaded search engines,Daniele Broccolo; Craig Macdonald; Salvatore Orlando; Iadh Ounis; Raffaele Perego; Fabrizio Silvestri; Nicola Tonellotto,Abstract While Web search engines are built to cope with a large number of queries; querytraffic can exceed the maximum query rate supported by the underlying computinginfrastructure. We study how response times and results vary when; in presence of highloads; some queries are either interrupted after a fixed time threshold elapses or droppedcompletely. Moreover; we introduce a novel dropping strategy; based on machine learnedperformance predictors to select the queries to drop in order to sustain the largest possiblequery rate with a relative degradation in effectiveness.,International Symposium on String Processing and Information Retrieval,2013,5
State of the Art Report,S Benbernou; L Cavallaro; M Sahid-Hacid; R Kazhamiakin; G Kecskemeti; JL Poizat; F Silvestri; M Uhlig; B Wetzstein,*,Gap Analysis of Knowledge on Principles; Techniques and Methodologies for Monitoring and Adaptation of SBAs; S-Cube Consortium,2008,5
PO-JRA-1.2. 1; State of the Art Report; Gap Analysis of Knowledge on Principles; Techniques and Methodologies for Monitoring and Adaptation of SBAs,S Benbernou; L Cavallaro; MS Hacid; R Kazhamiakin; G Kecskemeti; JL Pazat; F Silvestri; M Uhlig; B Wetzstein,*,S-Cube Network of Excellence; Tech. Rep,2008,5
Index compression for information retrieval systems,Roi Blanco González; Barreiro García; Amparo Alonso Betanzos; Ricardo Baeza Yates; Fabio Crestani; Fabrizio Silvestri,Abstract Given the increasing amount of information that is available today; there is a clearneed for Information Retrieval (IR) systems that can process this information in an efficientand effective way. Efficient processing means minimising the amount of time and spacerequired to process data; whereas effective processing means identifying accurately whichinformation is relevant to the user and which is not. Traditionally; efficiency and effectivenessare at opposite ends (what is beneficial to efficiency is usually harmful to effectiveness; andvice versa); so the challenge of IR systems is to find a compromise between efficient andeffective data processing. This thesis investigates the efficiency of IR systems. It suggestsseveral novel strategies that can render IR systems more efficient by reducing the index sizeof IR systems; referred to as index compression. The index is the data structure that stores …,*,2008,5
Semantic workflow representation and samples,Barbara Cantalupo; Ludovico Giammarino; Nikolaos Matskanis; Mike Surridge; Fabrizio Silvestri Silvestri,Executive Summary This document describes the result of WP5. 3 activity in the first 12months concerning modelling and management of adaptive workflows and dynamic serviceorchestration. Activity was mainly focused on defining a Semantic Workflow RepresentationModel and Language to enable different kind of users in representing workflows at differentarchitectural levels; eg application and business process. The Language Workflow Modelwas developed and integrated within an Enactment Model aimed at evaluating abstractworkflows into concrete ones at runtime; using dynamic policy described; in turn; asworkflows. The initial step was clearly defining objectives for a workflow model definitionwithin NextGRID framework. It was agreed that this model would specify a sort of “GridVirtual Infrastructure Model”(Grid VIM) incorporating coherent evaluation and binding …,*,2005,5
A search architecture for grid software components,Fabrizio Silvestri; Diego Puppin; Domenico Laforenza; Salvatore Orlando,Diego Puppin HPC-Lab ISTI-CNR; Italy diego.puppin@isti.cnr.it Domenico Laforenza HPC-LabISTI-CNR; Italy domenico.laforenza@isti.cnr.it … Salvatore Orlando Dipartimento di InformaticaUniversit`a di Venezia - Mestre orlando@unive.it … Introduction. Today; the development ofGrid applica- tions is considered a nightmare; due to lack of grid pro- grammingenvironments; standards; off-the-shelf software components; and so on. Many authors envisionthe existence of a marketplace for software components where developers can gather thecom- ponents for their applications [3]. This model; if globally accepted; would find its naturalend in the Grid platform. The main obstacles to this goal seem to be the: (a) the lack of a standardfor describing components and their interac- tions; and (b) the need for a service able to locaterelevant components satisfying some kind of cost constraints. Re- garding standards …,Proceedings of the 2004 IEEE/WIC/ACM International Conference on Web Intelligence,2004,5
Method and system for displaying content relating to a subject matter of a displayed media program,*,Disclosed is a system and method for analyzing; by a server computer; closed captioningtext associated with a media program being experienced by a user having a client device.The server computer obtains; based on the analyzing; a subject matter of a portion of themedia program from the closed captioning text. The server computer constructs a queryassociated with the determined subject matter and submits the query to a computer networkas a search query. The server computer receives; in response to the submitting of the query;content relating to the subject matter and measures an elapsed time period between thereceiving of the content and the obtaining of the subject matter. If the elapsed time period isless than a predetermined period of time; the server computer communicates; to the clientdevice; information related to the content.,*,2017,4
Endorsements and rebuttals in blog distillation,Giacomo Berardi; Andrea Esuli; Fabrizio Sebastiani; Fabrizio Silvestri,Abstract In this paper we test a new approach to blog distillation; defined as the task inwhich; given a user query; the system ranks the blogs in descending order of relevance tothe query topic. Our approach is based on the idea of adding a link analysis phase to thestandard retrieval-by-topicality phase. However; differently from other link analysis methods;we check whether a given hyperlink is a citation with a positive or a negative nature; ie; if itexpresses approval or disapproval of the hyperlinked page by the hyperlinking page. Thisallows us to test the hypothesis that distinguishing approval from disapproval brings aboutbenefits in the blog distillation task. We have tested our method on the Blogs08 collectionused in the last two editions (2009 and 2010) of the TREC Blog Track; a collection consistingof more than one million blogs and more than 28 million blog posts. Unfortunately; the …,Information Sciences,2013,4
Rectour: a recommender system for tourists,Ranieri Baraglia; Claudio Frattari; Cristina Ioana Muntean; Franco Maria Nardini; Fabrizio Silvestri,Abstract This paper presents a recommender system that provides personalized informationabout locations of potential interest to a tourist. The system generates suggestions;consisting of touristy places; according to the current position and history data describing thetourist movements. For the selection of tourist sites; the system uses a set of points of interesta priori identified. We evaluate our system on two datasets: a real and a synthetic one; bothstoring trajectories describing previous movements of tourists. The proposed solution hashigh applicability and the results show that the solution is both efficient and viable.,Proceedings of the The 2012 IEEE/WIC/ACM International Joint Conferences on Web Intelligence and Intelligent Agent Technology-Volume 03,2012,4
An incremental prefix filtering approach for the all pairs similarity search problem,Hoang Thanh Lam; Dinh Viet Dung; Raffaele Perego; Fabrizio Silvestri,Given a set of records; a threshold value t and a similarity function; we investigate theproblem of finding all pairs of records such that similarity between each pair is above t. Wepropose several optimizations on the existing approaches to solve the problem. Ouralgorithm outperforms the state-of-the-art algorithms in the case with large and high-dimensional datasets. The speedup we achieved varied from 30% to 4-x depending on thesimilarity threshold and the dataset properties.,Web Conference (APWEB); 2010 12th International Asia-Pacific,2010,4
Mining query logs,Salvatore Orlando; Fabrizio Silvestri,Abstract Web Search Engines (WSEs) have stored in their query logs information aboutusers since they started to operate. This information often serves many purposes. Theprimary focus of this tutorial is to introduce to the discipline of query log mining. We will showits foundations; by giving a unified view on the literature on query log analysis; and alsopresent in detail the basic algorithms and techniques that could be used to extract usefulknowledge from this (potentially) infinite source of information. Finally; we will discuss howthe extracted knowledge can be exploited to improve different quality features of a WSEsystem; mainly its effectiveness and efficiency.,European Conference on Information Retrieval,2009,4
Search shortcuts using click-through data,Ranieri Baraglia; Fidel Cacheda; Victor Carneiro; Vreixo Formoso; Raffaele Perego; Fabrizio Silvestri,Abstract Major Web Search Engines take as a common practice to provide Suggestions tousers in order to enhance their search experience. Such suggestions have normally the formof queries that are; to some extent;" similar" to the queries already submitted by the same orrelated users. The final aim of query suggestions is typically to help users to satisfy theirinformation needs more quickly. In this paper we face this problem from a somewhatdifferent perspective; and we propose a new query suggestion model based on SearchShortcuts; that consist in finding and proposing to the user" Successful" queries that allowed;in the past; several users to satisfy their information needs. This model differs from traditionalquery suggestion approaches; and allows the evaluation to be performed effectively byexploiting actual user sessions from the Microsoft 2006 RFP dataset. We evaluate several …,Proceedings of the 2009 workshop on Web Search Click Data,2009,4
Web search result caching and prefetching,Ronny Lempel; Fabrizio Silvestri,W3C was founded in 1994 by the inventor of the World Wide Web Tim Berners-Lee as avendor-neutral forum for building consensus around Web technologies. The consortiumconsists of member organization and dedicated staff of technical experts. Membership isopen to any organization or individual whose application is reviewed and approved by theW3C. Usually W3C members invest significant resources into the Web technologies. W3Cfulfils its mission by creation of recommendations enjoying status of international standards.In the first 10 years of existence; it produced over eighty W3C recommendations. W3C isresponsible for such technologies as HTML; XHTML; XML; XML Schema; CSS; SOAP;WSDL and others. W3C members play a leading role in the development of therecommendations. W3C initiatives involve international; national; and regional …,*,2009,4
On the limits of cache-oblivious rational permutations,Francesco Silvestri,Abstract Permuting a vector is a fundamental primitive which arises in many applications. Inparticular; rational permutations; which are defined by permutations of the bits of the binaryrepresentations of the vector indices; are widely used. Matrix transposition and bit-reversalare notable examples of rational permutations. In this paper we contribute a number ofresults regarding the execution of these permutations in cache hierarchies; with particularemphasis on the cache-oblivious setting. We first bound from below the work needed toexecute a rational permutation with an optimal cache complexity. Then; we develop a cache-oblivious algorithm to perform any rational permutation; which exhibits optimal work andcache complexities under the tall cache assumption. We finally show that for certain familiesof rational permutations (including matrix transposition and bit reversal) no cache …,Theoretical Computer Science,2008,4
The CIKM 2006 workshop on information retrieval in peer-to-peer networks,IP Zarko; F Silvestri,*,SIGIR FORUM,2007,4
An open architecture for QoS information in business grids,Dimosthenis Kyriazis; Andreas Menychtas; Theodora Varvarigou; Fabrizio Silvestri; Domenico Laforenza; Konstantinos Tserpes,Grid Computing is now in the state of development that can offer dynamic management ofvarious parameters that affect the applications' properties such as performance andreliability capabilities. The importance of that achievement is great; given the trend ofmigrating traditional service markets to inter-enterprise infrastructures and the resultingdemand in more or different guarantees on the level of the Quality of Service. In that frame;we present a design pattern for monitoring and evaluating SLA terms on service-orientedarchitectures. This mechanism takes into account the actual capabilities of the serviceprovider infrastructure and maps them to customer-centric Quality of Service terms; thusensuring that agreements will not be validated. In this way it enables the estimation of theactual capability of the service to provide Quality of Service at a certain degree.,*,2007,4
Dynamic personalization of web sites without user intervention,Ranieri Baraglia; Fabrizio Silvestri,CiteSeerX - Document Details (Isaac Councill; Lee Giles; PradeepTeregowda): A novel online recommender system builds profiling modelsand offers suggestions without the user taking the lead.,CACM,2006,4
A highly scalable parallel caching system for web search engine results,Tiziano Fagni; Raffaele Perego; Fabrizio Silvestri,Abstract This paper discusses the design and implementation of SDC; a new cachingstrategy aimed to efficiently exploit the locality present in the stream of queries submitted to aWeb Search Engine. SDC stores the results of the most frequently submitted queries in afixed-sizeread-only portion of the cache; while the queries that cannot be satisfied by thestatic portion compete for the remaining entries of the cache according to a given cachereplacement policy. We experimentally demonstrated the superiority of SDC over purelystatic and dynamic policies by measuring the hit-ratio achieved on two large query logs byvarying cache parameters and the replacement policy used. Finally; we propose animplementation optimized for concurrent accesses; and we accurately evaluate itsscalability.,European Conference on Parallel Processing,2004,4
A Hybrid Strategy for Caching Web Search Engine Results.,Fabrizio Silvestri; Tiziano Fagni; Salvatore Orlando; Paolo Palmerini; Raffaele Perego,ABSTRACT This work discusses the design and implementation of an efficient cachingsystem aimed to exploit the locality present in the queries submitted to a Web Search Engine(WSE). We enhance previous proposals in several directions. First we propose the adoptionof a hybrid strategy for caching; and then we experimentally demonstrate the superiority ofour hybrid strategy. Further we show how to take advantage of the spatial locality present inWSE query logs by exploiting a sort of adaptive prefetching strategy.,WWW (Posters),2003,4
Exploiting search history of users for news personalization,Xiao Bai; B Barla Cambazoglu; Francesco Gullo; Amin Mantrach; Fabrizio Silvestri,Abstract Content personalization is a long-standing problem for online news services. Inmost personalization approaches users of a news service are represented by topical interestprofiles that are matched with news articles in order to properly decide which articles are tobe recommended. When constructing user profiles; existing personalization methods exploitthe user activity observed within the news service itself without incorporating additionalinformation that can be obtained from other sources. In this paper we study the problem ofnews personalization by leveraging usage information that is external to the news service.We propose a novel approach that relies on the concept of “search profiles”; which are userprofiles that are built based on the past interactions of the user with a web search engine.We extensively test our proposal on real-world datasets obtained from Yahoo. We explore …,Information Sciences,2017,3
On the Behaviour of Deviant Communities in Online Social Networks.,Mauro Coletto; Luca Maria Aiello; Claudio Lucchese; Fabrizio Silvestri,Abstract On-line social networks are complex ensembles of interlinked communities thatinteract on different topics. Some communities are characterized by what are usuallyreferred to as deviant behaviors; conducts that are commonly considered inappropriate withrespect to the society's norms or moral standards. Eating disorders; drug use; and adultcontent consumption are just a few examples. We refer to such communities as deviantnetworks. It is commonly believed that such deviant networks are niche; isolated socialgroups; whose activity is well separated from the mainstream socialmedia life. According tothis assumption; research studies have mostly considered them in isolation. In this work wefocused on adult content consumption networks; which are present in many on-line socialmedia and in the Web in general. We found that few small and densely connected …,ICWSM,2016,3
The Role of Relevance in Sponsored Search,Luca Aiello; Ioannis Arapakis; Ricardo Baeza-Yates; Xiao Bai; Nicola Barbieri; Amin Mantrach; Fabrizio Silvestri,Abstract Sponsored search aims at retrieving the advertisements that in the one hand meetusers' intent reflected in their search queries; and in the other hand attract user clicks togenerate revenue. Advertisements are typically ranked based on their expected revenuethat is computed as the product between their predicted probability of being clicked (ie;namely clickability) and their advertiser provided bid. The relevance of an advertisement to auser query is implicitly captured by the predicted clickability of the advertisement; assumingthat relevant advertisements are more likely to attract user clicks. However; this approacheasily biases the ranking toward advertisements having rich click history. This mayincorrectly lead to showing irrelevant advertisements whose clickability is not accuratelypredicted due to lack of click history. Another side effect consists of never giving a chance …,Proceedings of the 25th ACM International on Conference on Information and Knowledge Management,2016,3
Network-Aware Recommendations of Novel Tweets,Noor Aldeen Alawad; Aris Anagnostopoulos; Stefano Leonardi; Ida Mele; Fabrizio Silvestri,Abstract With the rapid proliferation of microblogging services such as Twitter; a largenumber of tweets is published everyday often making users feel overwhelmed withinformation. Helping these users to discover potentially interesting tweets is an importanttask for such services. In this paper; we present a novel tweet-recommendation approach;which exploits network; content; and retweet analyses for making recommendations oftweets. The idea is to recommend tweets that are not visible to the user (ie; they do notappear in the user timeline) because nobody in her social circles published or retweetedthem. To do that; we create the user's ego-network up to depth two and apply the transitivityproperty of the friends-of-friends relationship to determine interesting recommendations;which are then ranked to best match the user's interests. Experimental results …,Proceedings of the 39th International ACM SIGIR conference on Research and Development in Information Retrieval,2016,3
Predicting the next application that you are going to use on aviate,*,In one embodiment; a current context of a mobile device may be ascertained; where thecurrent context includes an indication of a last application opened via the mobile device;wherein the last application opened is one of a plurality of applications installed on themobile device. A probability; for each of the plurality of applications; that a user of the mobiledevice will use the corresponding application under the current context may be determined;where the probability for at least a portion of the plurality of applications is determined byapplying a computer-generated model to the current context; wherein the computer-generated model is associated with the mobile device. One or more of the plurality of theapplications may be identified based; at least in part; upon the probability; for each one ofthe plurality of applications; that the user of the mobile device will use the corresponding …,*,2016,3
Interactive and context-aware tag spell check and correction,Francesco Bonchi; Ophir Frieder; Franco Maria Nardini; Fabrizio Silvestri; Hossein Vahabi,Abstract Collaborative content creation and annotation creates vast repositories of all sortsof media; and user-defined tags play a central role as they are a simple yet powerful tool fororganizing; searching and exploring the available resources. We observe that when a userannotates a resource with a set of tags; those tags are introduced one at a time. Therefore;when the fourth tag is introduced; a knowledge represented by the previous three tags; ie;the context in which the fourth tag is produced; is available and exploitable for generatingpotential correction of the current tag. This context; together with the" wisdom of the crowd"represented by the co-occurrences of tags in all the resources of the repository; can beexploited to provide interactive tag spell check and correction. We develop this idea in aframework; based on a weighted tag co-occurrence graph and on nodes relatedness …,Proceedings of the 21st ACM international conference on Information and knowledge management,2012,3
Using machine learning and information retrieval techniques to improve software maintainability,Anna Corazza; Sergio Di Martino; Valerio Maggio; Alessandro Moschitti; Andrea Passerini; Giuseppe Scanniello; Fabrizio Silvestri,Abstract In this paper; we investigate some ideas based on Machine Learning; NaturalLanguage Processing; and Information Retrieval to outline possible research directions inthe field of software architecture recovery and clone detection. In particular; after presentingan extensive related work; we illustrate two proposals for addressing these two issues; thatrepresent hot topics in the field of Software Maintenance. Both proposals use KernelMethods for exploiting structural representation of source code and to automate thedetection of clones and the recovery of the actually implemented architecture in a subjectsoftware system.,International Workshop on Eternal Systems,2012,3
Blog distillation via sentiment-sensitive link analysis,Giacomo Berardi; Andrea Esuli; Fabrizio Sebastiani; Fabrizio Silvestri,Abstract In this paper we approach blog distillation by adding a link analysis phase to thestandard retrieval-by-topicality phase; where we also we check whether a given hyperlink isa citation with a positive or a negative nature. This allows us to test the hypothesis thatdistinguishing approval from disapproval brings about benefits in blog distillation.,International Conference on Application of Natural Language to Information Systems,2012,3
A study on the effect of application and resource characteristics on the QoS in service provisioning environments,Theodora Varvarigou; Konstantinos Tserpes; Dimosthenis Kyriazis; Fabrizio Silvestri; Nikolaos Psimogiannos,ABSTRACT This chapter deals with the problem of quality provisioning in business service-oriented environments; examining the resource selection process as an initial matching ofthe provided to the demanded QoS. It investigates how the application and resourcecharacteristics affect the provided level of QoS; a relationship that intuitively exists but hasnot yet being mapped. To do so; it focuses on identifying the application and resourceparameters that affect the customer-defined QoS parameters. The chapter realisticallycentres upon modeling a data mining application and simple PC nodes in order to studyhow they affect response times. It moves on; by proving the existence of these specificrelations and maps them using simple artificial neural networks so as to be able to wrapthem in a single mechanism for resource selection based on customer QoS requirements …,*,2012,3
Detecting task-based query sessions using collaborative knowledge,Claudio Lucchese; Salvatore Orlando; Raffaele Perego; Fabrizio Silvestri; Gabriele Tolomei,Our research challenge is to provide a mechanism for splitting into user task-based sessionsa long-term log of queries submitted to a Web Search Engine (WSE). The hypothesis is thatsome query sessions entail the concept of user task. We present an approach that relies ona centroid-based and a density-based clustering algorithm; which consider queries inter-arrival times and use a novel distance function that takes care of query lexical content andexploits the collaborative knowledge collected by Wiktionary and Wikipedia.,Web Intelligence and Intelligent Agent Technology (WI-IAT); 2010 IEEE/WIC/ACM International Conference on,2010,3
Towards a task-based search and recommender systems,Gabriele Tolomei; Salvatore Orlando; Fabrizio Silvestri,Nowadays; people have been increasingly interested in exploiting Web Search Engines(WSEs) not only for having access to simple Web pages; but mainly for carrying out evencomplex activities; namely Web-mediated processes (or taskflows). Therefore; users'information needs will become more complex; and (Web) search and recommender systemsshould change accordingly for dealing with this shift. We claim that such taskflows and theircomposing tasks are implicitly present in users' minds when they interact; thus; with a WSEto access the Web. Our first research challenge is thus to evaluate this belief by analyzing avery large; longterm log of queries submitted to a WSE; and associating meaningfulsemantic labels with the extracted tasks (ie; clusters of task-related queries) and taskflows.This large knowledge base constitutes a good starting point for building a model of users' …,Data Engineering Workshops (ICDEW); 2010 IEEE 26th International Conference on,2010,3
(Query) History Teaches Everything; Including the Future,Fabrizio Silvestri; Ranieri Baraglia; Claudio Lucchese; Salvatore Orlando; Raffaele Perego," History Teaches Everything; Including the Future"; wrote Alphonse de Lamartine in thenineteen century. Even if history cannot be really considered a predictive science; historicalinformation can successfully be used in many fields. This paper deals with Web SearchEngines and their Query logs; which contain historical information about past usage of suchsystems. We will present some of the most interesting results obtained in this field by theHigh Performance Computing Lab in Pisa in collaboration with Research Labs worldwide.The techniques reviewed are mainly focused on enhancing the efficiency of large-scaledistributed search systems.,Web Conference; 2008. LA-WEB'08.; Latin American,2008,3
Toward gridle: A way to build grid applications searching through an ecosystem of components,Diego Puppin; Fabrizio Silvestri; Salvatore Orlando; Domenico Laforenza,Today; the development of Grid applications is considered a nightmare; due to lack of Gridpro- gramming environments; standards; off-the-shelf software components; etc.Nonetheless; several researchers believe that economic principles will guide the future developmentof the Grid: an open market of services and resources will become available to developers; whowill choose to use computing time and software solutions from different vendors; sold at differentprices; with different performance and QoS. Standardization efforts on component models; integrationplatforms; and business domain con- cepts based on XML will accelerate the usage and spreadingof blocks for building component- based Grid services and applications. We can expect that;in a very near future; there will be thousands of open-market components available on theGrid. Grid programming will consist of selecting; coordinating and deploying components …,*,2006,3
Interpretable Predictions of Tree-based Ensembles via Actionable Feature Tweaking,Gabriele Tolomei; Fabrizio Silvestri; Andrew Haines; Mounia Lalmas,Abstract Machine-learned models are often described as" black boxes". In many real-worldapplications however; models may have to sacrifice predictive power in favour of human-interpretability. When this is the case; feature engineering becomes a crucial task; whichrequires significant and time-consuming human effort. Whilst some features are inherentlystatic; representing properties that cannot be influenced (eg; the age of an individual); otherscapture characteristics that could be adjusted (eg; the daily amount of carbohydrates taken).Nonetheless; once a model is learned from the data; each prediction it makes on newinstances is irreversible-assuming every instance to be a static point located in the chosenfeature space. There are many circumstances however where it is important to understand(i) why a model outputs a certain prediction on a given instance;(ii) which adjustable …,Proceedings of the 23rd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining,2017,2
Preserving privacy in Web recommender systems,Ranieri Baraglia; Claudio Lucchese; Salvatore Orlando; Raffaele Perego; Fabrizio Silvestri,The goal of Web recommendation and personalization techniques is to “provide users withthe information they want or need; without expecting from them to ask for it explicitly”[19].Web Mining has shown to be a viable technique to discover information “hidden” in Web-related data [11]. In particular; Web Usage Mining (WUM) is the process of extractingknowledge from Web user's access data (or clickstream) by exploiting Data Mining (DM)technologies [14]. It can be used for different purposes such as recommendation;personalization; system improvement and site optimization.,Privacy Aware Knowledge Discovery: Novel Applications and New techniques; F. Bonchi and E. Ferrari eds,2010,2
On tag spell checking,Franco Maria Nardini; Fabrizio Silvestri; Hossein Vahabi; Pedram Vahabi; Ophir Frieder,Abstract Exploiting the cumulative behavior of users is a common technique used to improvemany popular online services. We build a tag spell checker using a graph-based model. Inparticular; we present a novel technique based on the graph of tags associated with objectsmade available by online sites such as Flickr and YouTube. We show the effectiveness ofour approach on the basis of an experimentation done on real-world data. We show aprecision of up to 93% with a recall (ie; the number of errors detected) of up to 100%.,International Symposium on String Processing and Information Retrieval,2010,2
Search shortcuts: Driving users towards their goals,Ranieri Baraglia; Fidel Cacheda; Victor Carneiro; Vreixo Formoso; Raffaele Perego; Fabrizio Silvestri,Abstract Giving suggestions to users of Web-based services is a common practice aimed atenhancing their navigation experience. Major Web Search Engines usually provide"Suggestions" under the form of queries that are; to some extent; related to the current querytyped by the user; and the knowledge learned from the past usage of the system. In this workwe introduce" Search Shortcuts" as" Successful" queries allowed; in the past; users to satisfytheir information needs. Differently from conventional suggestion techniques; our searchshortcuts allows to evaluate effectiveness by exploiting a simple train-and-test approach. Wehave applied several Collaborative Filtering algorithms to this problem; evaluating them on areal query log data. We generate the shortcuts from all user sessions belonging to thetesting set; and measure the quality of the shortcuts suggested by considering the …,Proceedings of the 18th international conference on World wide web,2009,2
ECIR 2008 workshop on efficiency issues on information retrieval,Roi Blanco; Fabrizio Silvestri,Abstract The goal of EIIR 2008; the first Workshop on Efficiency Issues in InformationRetrieval; was to shed light on efficiency-related issues of modern high-scale informationretrieval (IR); eg; Web; distributed technologies; peer to peer architectures and also new IRenvironments such as desktop search; enterprise/expert search; mobile devices; etc. Inaddition; the workshop aimed at fostering collaboration between different research groups inthis area.,ACM SIGIR Forum,2008,2
String Processing and Information Retrieval,LMS Russo; AL Oliveira,*,Proceedings,2006,2
Component metadata management and publication for the grid,Diego Puppin; Fabrizio Silvestri; Domenico Laforenza,There is growing attention to component-oriented software design of grid applications.Within this framework; applications are built by assembling together independentlydeveloped software components. Two main approaches are commonly used to manage;develop and publish software components: one is based on an interface descriptionlanguage (IDL); the other is typical; for instance; of Java and is based on introspection anddesign conventions. In this paper; we compare them and we propose a third approach thatmerges the flexibility and fast learning curve of the latter; with the rigor of the former. Ourproposal is meant to help the transition towards more modern tools; which is required todevelop versatile grid applications.,Information Technology: Coding and Computing; 2005. ITCC 2005. International Conference on,2005,2
An evaluation of component-based software design approaches,Diego Puppin; Fabrizio Silvestri; Domenico Laforenza,Component-oriented software design of Grid applications is commanding growing attentionfor business and scientific problems. The goal is create applications by assembling togetherindependently developed software components. The components are independentlydeveloped; composable; reusable; substitutable software solutions; with clearly definedinterface and behaviour.,Cluster Computing and the Grid; 2004. CCGrid 2004. IEEE International Symposium on,2004,2
Report on ECIR 2016: 38th European conference on information retrieval,Nicola Ferro; Fabio Crestani; Marie-Francine Moens; Josiane Mothe; Fabrizio Silvestri; Jaana Kekäläinen; Paolo Rosso; Paul Clough; Gabriella Pasi; Christina Lioma; Stefano Mizzaro; Giorgio Maria Di Nunzio; Claudia Hauff; Omar Alonso; Pavel Serdyukov; Gianmaria Silvello,Abstract The 38th European Conference on Information Retrieval took place from the 20th tothe 23rd of March 2016 in Padua; Italy. This report summarizes the conference in terms ofthe presented keynotes; scientific and social programme; industry day; tutorials; workshopsand student support.,ACM SIGIR Forum,2016,1
Systems and methods for query rewriting,*,Systems and methods for rewriting query terms are disclosed. The system collects queriesand query session data and separates the queries into sequences of queries havingcommon sessions. The sequences of queries are then input into a deep learning network tobuild a multidimensional word vector in which related terms are nearer one another thanunrelated terms. An input query is then received and the system matches the input query inthe multidimensional word vector and rewrites the query using the nearest neighbors to theterm of the input query.,*,2016,1
Effective data access patterns on massively parallel processors,Gabriele Capannini; Ranieri Baraglia; Fabrizio Silvestri; Franco Maria Nardini; Emmanuel Jeannot; Julius Žilinskas,Summary The new generation of microprocessors incorporates a huge number of cores onthe same chip. Graphics processing units are an example of this kind of architectures. Thischapter discusses the characteristics and the issues of the memory systems of this kind ofarchitectures. It analyzes these architectures from a theoretical point of view using the K-model to estimate the complexity of a given algorithm defined on this computational model.The chapter describes how the K-model can be used to design efficient data access patternsfor implementing efficient GPU algorithms. It introduces some preliminary details of many-core architectures; describes the K-model; analyzes the two applications; parallel prefix sumand bitonic sorting networks; by means of the K-model. Finally; the chapter concludes thatexperiments conducted demonstrates that the K-model could be fruitfully exploited to …,High-Performance Computing on Complex Environments,2014,1
Learning to shorten query sessions,Cristina Ioana Muntean; Franco Maria Nardini; Fabrizio Silvestri; Marcin Sydow,Abstract We propose the use of learning to rank techniques to shorten query sessions bymaximizing the probability that the query we predict is the" final" query of the current searchsession. We present a preliminary evaluation showing that this approach is a promisingresearch direction.,Proceedings of the 22nd International Conference on World Wide Web,2013,1
A novel resource-driven job allocation scheme for desktop grid environments,Paolo Bertasi; Alberto Pettarin; Michele Scquizzato; Francesco Silvestri,Abstract In this paper we propose a novel framework for the dynamic allocation of jobs ingrid-like environments; in which such jobs are dispatched to the machines of the grid by acentralized scheduler. We apply a new; full resource-driven approach to the scheduling task:jobs are allocated and (possibly) relocated on the basis of the matching between theirresource requirements and the characteristics of the machines in the grid. We provideexperimental evidence that our approach effectively exploits the computational resources athand; successfully keeping the completion time of the jobs low; even without havingknowledge of the actual running times of the jobs.,International Symposium on Trustworthy Global Computing,2010,1
Special section: scalable information systems,Wang-Chien Lee; Jianliang Xu; Jianzhong Li; Fabrizio Silvestri,*,Future Generation Computer Systems,2009,1
Query Log Analysis for Enhancing Web Search,Salvatore Orlando; F Silvestri,The data set includes {AnonID; Query; QueryTime; ItemRank; ClickURL}. AnonID-ananonymous user ID number. Query-the query issued by the user; case shifted with mostpunctuation removed. QueryTime-the time at which the query was submitted for search.ItemRank-if the user clicked on a search result; the rank of the item on which they clicked islisted. ClickURL-if the user clicked on a search result; the domain portion of the URL in theclicked result is listed. Each line in the data represents one of two types of events: 1. A querythat was NOT followed by the user clicking on a result item. 2. A click through on an item inthe result list returned from a query. In the first case (query only) there is data in only the firstthree columns/fields--namely AnonID; Query; and QueryTime (see above). In the secondcase (click through); there is data in all five columns. For click through events; the query …,*,2009,1
Efficiency issues in information retrieval workshop,Roi Blanco; Fabrizio Silvestri,Abstract Today's technological advancements allow for vast amounts of information to bewidely generated; disseminated; and stored. This exponentially increasing amount ofinformation renders the retrieval of relevant information a necessary and cumbersome task.The field of Information Retrieval (IR) addresses this task by developing systems in aneffective and efficient way. Specifically; IR effectiveness deals with retrieving the mostrelevant information to a user need; while IR efficiency deals with providing fast and orderedaccess to large amounts of information.,European Conference on Information Retrieval,2008,1
Survey of Quality Related Aspects Relevant for Service-based Applications,Salima Benbernou; Ivona Brandic; Manuel Carro; Marco Comuzzi; Elisabetta Di Nitto; Maha Driss; Julia Hielscher; Raman Kazhamiakin; Gabor Kecskemeti; Attila Kertesz; Kyriakos Kritikos; Andreas Metzger; Hassina Meziane; Andrea Mocci; Barbara Pernici; Pierluigi Plebani; Sagar Sen; Fabrizio Silvestri; Branimir Wetzstein,Abstract Quality related aspects relevant for service-based applications cover a broad fieldof research; includingwork on quality modeling; QoS and SLA negotiation; as well asconstructive and analytical qualityassurance (like testing; monitoring and static analysis).This deliverable provides a survey of this broadfield of “service quality” and identifies the keyareas where research contributions are currentlyavailable. Based on this survey of the stateof the art; important and emerging research challenges areidentified that could be pursuedin the future in order to close several of the gaps which emerge from thecurrent state of theart on “service quality”.,*,2008,1
An effective recommender system for highly dynamic and large web sites,Ranieri Baraglia; Francesco Merlo; Fabrizio Silvestri,Abstract In this demo we show a recommender system; called SUGGEST; that dynamicallygenerates links to pages that have not yet been visited by a user and might be of hispotential interest. Usually other recommender systems exploit a kind of two-phasearchitecture composed by an off-line component that analyzes Web server access logs andgenerates information used by a successive online component that generatesrecommendations. SUGGEST collapse the two-phase into a single online Apache module.The component is able to manage very large Web sites made up of dinamically generatedpages by means of an efficient LRU-based database management strategy. The demo willshow the way SUGGEST is able to anticipate users' requests that will be made farther in thefuture; introducing a limited overhead on the Web server activity.,European Conference on Principles of Data Mining and Knowledge Discovery,2004,1
Adult content consumption in online social networks,Mauro Coletto; Luca Maria Aiello; Claudio Lucchese; Fabrizio Silvestri,Abstract Users in online social networks naturally organize themselves into overlapping andinterlinked communities that are formed around common identity or shared topical interests.Some communities gather people around specific deviant behaviors; conducts that arecommonly considered inappropriate with respect to the society's norms or moral standardssuch as drug use; eating disorders; and pornographic content consumption. From a networkanalysis perspective; the set of interactions between members of these communities formdeviant networks that map how the deviant content is shared and consumed. It is commonlybelieved that deviant networks are small and isolated from the mainstream social media life;accordingly; most research studies have considered them in isolation. We focus on adultcontent consumption networks; which is one deviant network with a significant presence …,Social Network Analysis and Mining,2017,*
Using exogenous sources for personalization of website services,*,Software running on servers at a website hosting a news service generates a first profile fora user of the news service. The first profile is based at least in part on implicit relevancefeedback from the user on content presented by the news service. The software obtains asecond profile for the user from a web-searching service. The software creates a score for acandidate item of content. The score is based on similarity of the candidate item to the firstprofile and similarity of the candidate item to the second profile. Similarity to the secondprofile measures at least similarity to a plurality of web-search queries and similarity to anytitles of any search results resulting from each of the queries. The software then presents theitem of content to the user in a content stream served by the news service; based on thescore.,*,2017,*
Generating actionable suggestions for improving user engagement with online advertisements,*,An online advertising system receives an advertisement from an advertiser. The systemanalyzes the advertisement; extracts its features and provides to the advertiser a qualityrating for the advertisement which depends on a user engagement factor such as thepredicted dwell time for the ad; given its features. The system further provides to theadvertiser suggestions for improvements to the advertisement; such as a list of actionableguidelines that can improve the expected dwell time of the ad; and likely its conversion rate.,*,2017,*
Friendly; Appealing or Both?: Characterising User Experience in Sponsored Search Landing Pages,Marc Bron; Miriam Redi; Mounia Lalmas; Fabrizio Silvestri; Huw Evans; Mahlon Chute,Abstract Many of today's websites have recognised the importance of mobile friendly pagesto keep users engaged and to provide a satisfying user experience. However; next to theexperience provided by the sites themselves; advertisements; when clicked; present userswith landing pages that are not necessarily mobile friendly. We explore what type of featuresare able to characterise the mobile friendliness of sponsored search ad landing pages. Tohave a complete understanding of the mobile ad experience in terms of layout and visualappearance; we also explore the notion of the ad page aesthetic appeal. We design andcollect annotations for both dimensions on a large set of ads; and find that mobilefriendliness and aesthetics represent different notions. We perform a comprehensive studyof the effectiveness of over 120 features on the tasks of friendliness and aesthetics …,Proceedings of the 26th International Conference on World Wide Web Companion,2017,*
Pornography consumption in Social Media,Mauro Coletto; Luca Maria Aiello; Claudio Lucchese; Fabrizio Silvestri,Abstract: The structure of a social network is fundamentally related to the interests of itsmembers. People assort spontaneously based on the topics that are relevant to them;forming social groups that revolve around different subjects. Online social media are alsofavorable ecosystems for the formation of topical communities centered on matters that arenot commonly taken up by the general public because of the embarrassment; discomfort; orshock they may cause. Those are communities that depict or discuss what are usuallyreferred to as deviant behaviors; conducts that are commonly considered inappropriatebecause they are somehow violative of society's norms or moral standards that are sharedamong the majority of the members of society. Pornography consumption; drug use;excessive drinking; illegal hunting; eating disorders; or any self-harming or addictive …,arXiv preprint arXiv:1612.08157,2016,*
Improving Profiles of Weakly-Engaged Users,Gaurav Singh; Amin Mantrach; Fabrizio Silvestri,Abstract The majority of online users do not engage highly with services that are offered viaWeb. This is a well-known fact and it is also one of the main issues that personalizationalgorithms try to overcome. A popular way of personalizing an online service is to recordusers' actions into user profiles. Weakly-engaged users lead to sparsely populated userprofiles; or weak profiles as we name them. Such weak profiles constitute a source ofpotential increase in user engagement and as a consequence; windfall profits for Internetcompanies. In this paper; we define the novel problem of enhancing weak profiles in positivespace and propose an effective solution based on learning collective embedding space inorder to capture a low-dimensional manifold designed to specifically reconstruct sparse userprofiles. Our method consistently outperforms baselines consisting of k NN and collective …,International Conference of the Cross-Language Evaluation Forum for European Languages,2016,*
Advances in Information Retrieval: 38th European Conference on IR Research; ECIR 2016; Padua; Italy; March 20-23; 2016. Proceedings,Nicola Ferro; Fabio Crestani; Marie-Francine Moens; Josiane Mothe; Fabrizio Silvestri; Giorgio Maria Di Nunzio; Claudia Hauff; Gianmaria Silvello,This book constitutes the refereed proceedings of the 38th European Conference on IRResearch; ECIR 2016; held in Padua; Italy; in March 2016. The 42 full papers and 28 posterpapers presented together with 3 keynote talks and 6 demonstration papers; were carefullyreviewed and selected from 284 submissions. The volume contains the outcome of 4workshops as well as 4 tutorial papers in addition. Being the premier European forum for thepresentation of new research results in the field of Information Retrieval; ECIR features awide range of topics such as: social context and news; machine learning; questionanswering; ranking; evaluation methodology; probalistic modeling; evaluation issues;multimedia and collaborative filtering; and many more.,*,2016,*
MUSETS: Diversity-Aware Web Query Suggestions for Shortening User Sessions,Marcin Sydow; Cristina Ioana Muntean; Franco Maria Nardini; Stan Matwin; Fabrizio Silvestri,Abstract We propose MUSETS (multi-session total shortening)–a novel formulation of thequery suggestion task; specified as an optimization problem. Given an ambiguous userquery; the goal is to propose the user a set of query suggestions that optimizes a diversity-aware objective function. The function models the expected number of query reformulationsthat a user would save until reaching a satisfactory query formulation. The function isdiversity-aware; as it naturally enforces high coverage of different alternative continuationsof the user session. For modeling the topics covered by the queries; we also use anextended query representation based on entities extracted from Wikipedia. We apply amachine learning approach to learn the model on a set of user sessions to be subsequentlyused for queries that are under-represented in historical query logs and present an …,International Symposium on Methodologies for Intelligent Systems,2015,*
Large-scale Contextual Query-to-Ad Matching and Retrieval System for Sponsored Search,Ricardo Baeza-Yates; Nemanja Djuric; Mihajlo Grbovic; Vladan Radosavljevic; Fabrizio Silvestri,Abstract Semantic embeddings of words (or objects in general) into a vector space haveproven to be a powerful tool in many applications. In this talk we are going to show onepossible application of semantic embeddings to sponsored search. Sponsored searchrepresents the major source of revenue for web search engines and it is based on thefollowing mechanism: each advertiser maintains a list of keywords they deem of interest withregards to their business. According to this targeting model; when a query is issued; alladvertisers with a matching keyword are entered into an auction according to the amountthey bid for the query; and the winner gets to show their ad; usually paying the next largestbid (this is called second price). The main challenges is that a query may not match manykeywords; resulting in lower auction value; lower ad quality; and lost revenue for both …,Proceedings of the 24th International Conference on World Wide Web,2015,*
Influence theories constitute formal models that identify those individuals that are able to affect and guide their peers through their activity. There is a large body of w...,Roi Blanco; Gianmarco De Francisci Morales; Fabrizio Silvestri,We present IntoNews; a system to match online news articles with spoken news from atelevision newscasts represented by closed captions. We formalize the news matchingproblem as two independent tasks: closed captions segmentation and news retrieval. Thesystem segments closed captions by using a windowing scheme: sliding or tumblingwindow. Next; it uses each segment to build a query by extracting...,Information Processing and Management,2015,*
Recommender Systems,Cristina Ioana Muntean; Hossein Vahabi; Rossano Venturini,Segnalazioni con codici 20501/20503/20504: Alcuni dati obbligatori per il sito CINECA nonsono presenti o invalidi; oppure il sito CINECA non è riuscito ad individuare una rivista con idati forniti; è necessario controllare la correttezza dell'ISSN e/o EISSN dove applicabili e iltitolo della rivista.Segnalazioni con codici 20201/20202: La pubblicazione non è statatrasferita SOLO per i docenti segnalati nel messaggio a causa di problemi nell'anagraficaCINECA e/o di Ateneo (pe i codici fiscali non sono gli stessi) oppure perché si tratta didocenti che; pur essendo abilitati all'inserimento nel sistema di Ateneo; non hanno facoltà disincronizzare le proprie pubblicazioni in CINECA. Tutti gli altri eventuali coautori senzasegnalazione troveranno la pubblicazione correttamente nel proprio spazio personaleCINECA.,*,2014,*
Information Retrieval Technology: 9th Asia Information Retrieval Societies Conference; AIRS 2013; Singapore; December 9-11; 2013; Proceedings,Rafael Banchs; Fabrizio Silvestri; Tie-Yan Liu; Min Zhang; Sheng Gao; Jun Lang,This book constitutes the refereed proceedings of the 9th Information Retrieval SocietiesConference; AIRS 2013; held in Singapore; in December 2013. The 27 full papers and 18poster presentations included in this volume were carefully reviewed and selected from 109submissions. They are organized in the following topical sections: IR theory; modeling andquery processing; clustering; classification and detection; natural language processing forIR; social networks; user-centered studies and personalization and applications.,*,2013,*
Mining Lifecycle Event Logs for Enhancing Service-Based Applications,Schahram Dustdar; Philipp Leitner; Franco Maria Nardini; Fabrizio Silvestri; Gabriele Tolomei,ABSTRACT Service-Oriented Architectures (SOAs); and traditional enterprise systems ingeneral; record a variety of events (eg; messages being sent and received between servicecomponents) to proper log files; ie; event logs. These files constitute a huge and valuablesource of knowledge that may be extracted through data mining techniques. To this end;process mining is increasingly gaining interest across the SOA community. The goal ofprocess mining is to build models without a priori knowledge; ie; to discover structuredprocess models derived from specific patterns that are present in actual traces of serviceexecutions recorded in event logs. However; in this work; the authors focus on detectingfrequent sequential patterns; thus considering process mining as a specific instance of themore general sequential pattern mining problem. Furthermore; they apply two sequential …,*,2013,*
ECIR 2012: 34th european conference on information retrieval research,Ricardo Baeza-Yates; Mari-Carmen Marcos; Arjen P de Vries; Hugo Zaragoza; B Barla Cambazoglu; Vanessa Murdock; Alvaro Barreiro; David E Losada; Ronny Lempel; Fabrizio Silvestri; Mounia Lalmas,Yates (Yahoo! Research). The conference was jointly organized by Yahoo! ResearchBarcelona; Barcelona Media Foundation; and Universitat Pompeu Fabra (UPF); with Mari-Carmen Marcos (UPF) as local arrangements chair. ECIR 2012 invited researchers tosubmit research papers; posters; and demonstrations. The conference also included anindustry track; a tutorial program; and three workshops. The conference received a total of261 submissions across four categories: 163 full paper submissions; 78 poster submissions;11 demonstration submissions and 9 industry track submissions. Naturally; the largestproportion originated from Europe (66%); but Asia (17%) and America (14%) were also wellrepresented. Including the tutorials; workshops and the industry day; the conferenceattracted more than 200 attendees.,ACM SIGIR Forum,2012,*
Advances in Information Retrieval: 34th European Conference on IR Research; ECIR 2012; Barcelona; Spain; April 1-5; 2012; Proceedings,Ricardo Baeza-Yates; Arjen P De Vries; Hugo Zaragoza; B Barla Cambazoglu; Vanessa Murdock; Ronny Lempel; Fabrizio Silvestri,This book constitutes the proceedings of the 34th European Conference on IR Research;ECIR 2012; held in Barcelona; Spain; in April 2012. The 37 full papers; 28 poster papersand 7 demonstrations presented in this volume were carefully reviewed and selected from167 submissions. The contributions are organized in sections named: query representation;blogs and online-community search; semi-structured retrieval; evaluation; applications;retrieval models; image and video retrieval; text and content classification; categorisation;clustering; systems efficiency; industry track; and posters.,*,2012,*
Cite-as-you-Write,Kris Jack; Maurizio Sambati; Fabrizio Silvestri; Salvatore Trani; Rossano Venturini,Segnalazioni con codici 20501/20503/20504: Alcuni dati obbligatori per il sito CINECA nonsono presenti o invalidi; oppure il sito CINECA non è riuscito ad individuare una rivista con idati forniti; è necessario controllare la correttezza dell'ISSN e/o EISSN dove applicabili e iltitolo della rivista.Segnalazioni con codici 20201/20202: La pubblicazione non è statatrasferita SOLO per i docenti segnalati nel messaggio a causa di problemi nell'anagraficaCINECA e/o di Ateneo (pe i codici fiscali non sono gli stessi) oppure perché si tratta didocenti che; pur essendo abilitati all'inserimento nel sistema di Ateneo; non hanno facoltà disincronizzare le proprie pubblicazioni in CINECA. Tutti gli altri eventuali coautori senzasegnalazione troveranno la pubblicazione correttamente nel proprio spazio personaleCINECA.,Cybercrime,2012,*
You Should Read This! Let Me Explain You Why,Roi Blanco; Diego Ceccarelli; Claudio Lucchese; Raffale Perego; Fabrizio Silvestri,ABSTRACT Recommender systems have become ubiquitous in contentbased webapplications; from news to shopping sites. Nonetheless; an aspect that has been largelyoverlooked so far in the recommender system literature is that of automatically buildingexplanations for a particular recommendation. This paper focuses on the news domain; andproposes to enhance effectiveness of news recommender systems by adding; to eachrecommendation; an explanatory statement to help the user to better understand if; and why;the item can be her interest. We consider the news recommender system as a black-box;and generate different types of explanations employing pieces of information associatedwith the news. In particular; we engineer text-based; entity-based; and usagebasedexplanations; and make use of a Markov Logic Networks to rank the explanations on the …,*,2012,*
String Processing and Information Retrieval: 18th International Symposium; SPIRE 2011; Pisa; Italy; October 17-21; 2011; Proceedings,Roberto Grossi; Fabrizio Silvestri; Fabrizio Sebastiani,This book constitutes the proceedings of the 18th International Symposium on StringProcessing and Information Retrieval; SPIRE 2011; held in Pisa; Italy; in October 2011. The30 long and 10 short papers together with 1 keynote presented were carefully reviewed andselected from 102 submissions. The papers are structured in topical sections on introductionto web retrieval; sequence learning; computational geography; space-efficient datastructures; algorithmic analysis of biological data; compression; text and algorithms.,*,2011,*
Representing document lengths with identifiers,Raffaele Perego; Fabrizio Silvestri; Nicola Tonellotto,Abstract The length of each indexed document is needed by most common text retrievalscoring functions to rank it with respect to the current query. For efficiency purposesinformation retrieval systems maintain this information in the main memory. This paperproposes a novel strategy to encode the length of each document directly in the documentidentifier; thus reducing main memory demand. The technique is based on a simpledocument identifier assignment method and a function allowing the approximate length ofeach indexed document to be computed analytically.,European Conference on Information Retrieval,2011,*
String Processing and Information Retrieval,Roberto Grossi Fabrizio Sebastiani; Fabrizio Silvestri,In the 18 years since its inauguration back in 1993 the International Symposium on StringProcessing and Information Retrieval (SPIRE) has become the reference meeting for theinterdisciplinary community of researchers whose activity lies at the crossroads of stringprocessing and information retrieval. This volume contains the proceedings of SPIRE 2011;the 18th symposium in the series. The first four events concentrated mainly on stringprocessing; and were held in South America under the title “South American Workshop onString Processing”(WSP) in 1993 (Belo Horizonte; Brazil); 1995 (Valparaiso; Chile); 1996(Recife; Brazil); and 1997 (Valparaiso; Chile). WSP was renamed SPIRE in 1998 (SantaCruz; Bolivia) when the scope of the event was broadened to include information retrieval.The change was motivated by the increasing relevance of information retrieval and its …,*,2011,*
A search architecture enabling efficient diversification of search results,Gabriele Capannini; Franco Maria Nardini; Raffaele Perego; Fabrizio Silvestri,Abstract. In this paper; we deal with efficiency of the diversification of results returned byWeb Search Engines (WSEs). We extend a search architecture based on additive MachineLearned Ranking (MLR) systems with a new module computing the diversity score of eachretrieved document. Our proposed solution is designed to be used with other techniques;(egearly termination of rank computation; etc.). Furthermore; we use an efficient state-of-the-artdiversification approach based on knowledge extracted from query logs; and prove that itcan efficiently works in a additive machine learned ranking system; and we study itsfeasibility.,DDR-2011 in conjunction with ECIR,2011,*
On using query logs for static index pruning,TL Hoang; R Perego; F Silvestri,Abstract Static index pruning techniques aim at removing from the posting lists of an invertedfile the references to documents which are likely to be not relevant for answering userqueries. The reduction in the size of the index results in a better exploitation of memoryhierarchies and faster query processing. On the other hand; pruning may affect the precisionof the information retrieval system; since pruned entries are unavailable at query processingtime. Static pruning techniques proposed so far exploit query-independent measures toevaluate the importance of a document within a posting list. This paper proposes a generalframework that aims at enhancing the precision of any static pruning methods by exploitingusage information extracted from query logs. Experiments conducted on the TREC WT10gWeb collection and a large Altavista query log show that integrating usage knowledge …,*,2010,*
An incremental prefix filtering approach for all pairs similarity search,TL Hoang; VD Dinh; R Perego; F Silvestri,Abstract Given a set of records; a threshold value t and a similarity function; we investigatethe problem of finding all pairs of records such that similarity between each pair is above t.We propose several optimizations on the existing approaches to solve the problem. Ouralgorithm outperforms the state-of-the-art algorithms in the case with large and high-dimensional datasets. The speedup we achieved varied from 30% to 4-x depending on thesimilarity threshold and the dataset properties.,*,2010,*
Refreshing Models to Provide Timely Query Recommendations.,Daniele Broccolo; Franco Maria Nardini; Raffaele Perego; Fabrizio Silvestri,ABSTRACT In this work we propose a comparative study of the effects of a continuousmodel update on the effectiveness of wellknown query recommendation algorithms. In theiroriginal formulation; these algorithms use static (ie pre-computed) models to generaterecommendations. We extend these algorithms to generate suggestions using: a staticmodel (no updates); a model updated periodically; and a model continuously updating (ieeach time a query is submitted). We assess the results by previously proposed evaluationmetrics and we show that the use of periodical and continuous updates of the model usedfor recommending queries provides better recommendations.,IIR,2010,*
Service Research Challenges and Solutions for the Future Internet,Klaus Pohl; Michael Parkin; Andreas Metzger,The field of software services has become increasingly significant as the ubiquitous Internethas provided global connectivity to networked software (ie; services) and allowed theflexible composition of those services into innovative service-based applications (SBAs).The number and scope of services available globally is predicted to grow exponentially intothe “Internet of Services”. Therefore; in order for these services to be used in and betweenSBAs; significant research effort is required into the broader aspects of services andespecially the multidisciplinary problems that cut across a number of scientific fields.Although many research organizations have developed research agendas to study servicesand SBAs; the multidisciplinary issues and challenges the Internet of Services brings haveso far not been investigated in an organized; systematic and coherent manner. S-Cube …,*,2010,*
Diversifying Search Results Using Query Logs,Gabriele Capannini; Franco M Nardini; Raffaele Perego; Fabrizio Silvestri,Abstract We study the problem of diversifying search results by exploiting the preciousknowledge stored in query logs. When an ambiguous or faceted query is submitted to asearch engine; the user has often to reformulate it in order to better satisfy her informationneed by improving the perceived precision of results returned. Our proposal exploits thepresence of dierent\specializations" of queries in query logs to detect the submission ofambiguous/faceted queries; and manage them by diversifying the search results returned tousers; in a way that better covers the dierent possible interpretations of the query. Wepresent an original formulation of the results diversication problem in terms of an objectivefunction to be maximized that admits the nding of an optimal solution in linear time. Weevaluate our approach by using both the TREC Web diversication track methodology; and …,*,2010,*
Foundations and Trends® in Information Retrieval,Fabrizio Silvestri,*,Foundations and Trends® in Information Retrieval,2009,*
Entry pairing in inverted file,TL Hoang; R Perego; TMQ Nguyen; F Silvestri,Abstract This paper proposes to exploit content and usage information to rearrange aninverted index for a full-text IR system. The idea is to merge the entries of two frequently co-occurring terms; either in the collection or in the answered queries; to form a single; paired;entry. Since postings common to paired terms are not replicated; the resulting index is morecompact. In addition; queries containing terms that have been paired are answered fastersince we can exploit the pre-computed posting intersection. In order to choose which termshave to be paired; we formulate the term pairing problem as a Maximum-Weight MatchingGraph problem; and we evaluate in our scenario efficiency and efficacy of both an exact anda heuristic solution. We apply our technique:(i) to compact a compressed inverted file builton an actual Web collection of documents; and (ii) to increase capacity of an in-memory …,*,2009,*
InfoScale 2008: The Third International ICST Conference on Scalable Information Systems,Ronny Lempel; Raffaele Perego; Fabrizio Silvestri,Abstract Scalability is the key word for today's modern software architectures. As data andknowledge volume keep increasing while global means for information disseminationcontinue to diversify; new methods; modeling paradigms; and structures are needed toefficiently support the mounting scalability requirements.,Proceedings of the 3rd international conference on Scalable information systems,2008,*
Workshop on large-scale distributed systems for information retrieval,Flavio P Junqueira; Vassilis Plachouras; Fabrizio Silvestri; Ivana Podnar,Abstract The Workshop on Large-Scale Distributed Systems for Information Retrieval was avenue for seminal ideas on the design of systems for search. The workshop focused mainlyon mechanisms for P2P IR; which is currently a highly popular research area; but it also hadfruitful discussions and presentations on other architectures for large-scale systems. Giventhe attendance and the good level of discussion; we conclude that systems for informationretrieval is a growing and promising area of research.,ACM SIGIR Forum,2007,*
TOIS reviewers January 2006 through May 2007,Gary Marchionini; Ahmed Abbasi; Eugene Agichtein; Khurshid Ahmad; Azzah Al-Maskari; Gianni Amati; Sihem Amer Yahia; Shlomo Argamon; Daniel Ashbrook; Paolo Atzeni; Michela Bacchin; Godmar Back; Antonio Badia; Andras Banczur; Bettina Berendt; Elisa Bertino; B Bhagyavati; Suresh Bhavnani; Devdutta Bhosale; David Bodoff; Paolo Boldi; Johan Bollen; Angela Bonifati; Pia Borlund; Jit Bose; Athman Bouguettaya; Michael Brinkmeier; Peter Brown; Peter Brusilovsky; Peter Bruza; Christopher Burges; Robin Burke; Ben Carterette; Arthur Cater; Kuiyu Chang; Hsin Hsi Chen; Zheng Chen; James Cheney; Pu Jen Cheng; Roger Chiang; Byron Choi; Tat Seng Chua; Charlie Clarke; Paul Clough; Mariano Consens; Gordon Cormack; Nick Craswell; Fabio Crestani; Carolyn Crouch; Silviu Petru Cucerzan; Hang Cui; Sally Jo Cunningham; Edward Cutrell; Pablo De La Fuente; Arjen De Vries; Anne Diekema; Sandor Dominich; Shyamala Doraisamy; Mark Dunlop; Georges Dupret; Miles Efron; Jeremy Ellman; Peter Enser; Gunes Erkan; Laura Fochtmann; Anders Fongen; Nigel Ford; Martin Franz; Xin Fu; Paolo Garza; Susan Gauch; Pierre Geneves; Henry Gladney; Melanie Gnasa; Andrew Goldberg; Marcos Goncalves; Cyril Goutte; David Grossman; Dennis Groth; Jacek Gwizdka; Stephanie Haas; Sanda Harabagiu; Donna Harman; Andreas Henrich; Djoerd Hiemstra; Lee Hollaar; Chun Nan Hsu; Fei Huang; Zan Huang; Mike Huhns; Carlos Hurtado; Keisuke Innoue; Panagiotis Ipeirotis; Bernard Jansen; Wang Jianqiang; Rong Jin; Marko Junkkari; Patrick Juola; Vinay Kakade; Jaap Kamps; In Ho Kang; Damianos Karakos; Vangelis Karkaletsis; Martin Kaszkiel; Siddharth Kaza; Jaana Kekäläinen; Diane Kelly; Benny Kimelfeld; Alek Kolcz; Joseph Konstan; Kui Lam Kwok; Abhimanyu Lad; Alberto Laender; Mounia Lalmas; Leah Larkey; Ray Larson; Nabil Layaida; Zhang Le; Dik Lun Lee; Dongwon Lee; Jochen Leidner; Gina Levow; Hang Li; Xin Li; Chin Yew Lin; Jimmy Lin; Tie Yan Liu; Zehua Liu; David Losada; Jie Lu; Yiming Ma; Inderjeet Mani; Murali Mani; Ioana Manolescu; Catherine Marshall; Mercedes Martinez; Yosi Mass; Paul McNamee; Sean McNee; Brahim Medjahed; Lokman Meho; Donald Metzler; Rada Mihalcea; Ruslan Mitkov; Bamshad Mobasher; Marina Mongiello; Ani Nenkova; Frank Neven; Dorbin Ng; Wilfred Ng,Marchionini; Gary; Abbasi; Ahmed; Agichtein; Eugene; Ahmad; Khurshid; Al-Maskari; Azzah;Amati; Gianni; Yahia; Sihem Amer; Argamon; Shlomo; Ashbrook; Daniel; Atzeni; Paolo;Bacchin; Michela; Back; Godmar; Badia; Antonio; Banczur; Andras; Berendt; Bettina; Bertino;Elisa; Bhagyavati; B.; Bhavnani; Suresh; Bhosale; Devdutta; Bodoff; David; Boldi; Paolo;Bollen; Johan; Bonifati; Angela; Borlund; Pia; Bose; Jit; Bouguettaya; Athman; Brinkmeier;Michael; Brown; Peter; Brusilovsky; Peter; Bruza; Peter; Burges; Christopher; Burke; Robin;Carterette; Ben; Cater; Arthur; Chang; Kuiyu; Chen; Hsin Hsi; Chen; Zheng; Cheney; James;Cheng; Pu Jen; Chiang; Roger; Choi; Byron; Chua; Tat Seng; Clarke; Charlie; Clough; Paul;Consens; Mariano; Cormack; Gordon; Craswell; Nick; Crestani; Fabio; Crouch … In: ACMTransactions on Information Systems; Vol. 25; No. 4; 15; 01.10.2007.,ACM Transactions on Information Systems,2007,*
LSDS-IR,Vassilis Plachouras; Fabrizio Silvestri; Ivana Podnar Zarko,We; the organizers of the LSDS-IR workshop; are very enthusiastic with the program wehave been able to put together. We have received a number of very good papers; that weare sure are going to promote very interesting and fruitful discussions during the workshop.Before moving to a discussion on the actual program; we would like to say a word on thereasons for organizing it. It is not a new observation that the Web is growing. Researchersacross the world have spent so far a significant amount of effort to invent techniques toimprove the experience of users when they navigate on the Web. In particular; we refer toinformation retrieval and related areas targeting Web search. An important issue; however;is that work in these areas has mostly concentrated on algorithms and application-levelstrategies; and infrastructure is unquestionably an important component as well. At a very …,*,2007,*
Special issue on heterogeneous and distributed IR,Fabrizio Silvestri,*,*,2007,*
On the Value of Query Logs for Modern Information Retrieval,Domenico Laforenza; Claudio Lucchese; Salvatore Orlando; Raffaele Perego; Diego Puppin; Fabrizio Silvestri,Abstract Query Logs collected by a Web Search Engine (WSE) constitute a valuable sourceof information which can be used in several ways to enhance efficiency and efficacy of thecomplex process of searching. This paper surveys the results recently achieved by ourgroup in the design of innovative solutions targeting parallel Information Retrieval (IR)systems. Our solutions exploit the knowledge deriving from the patterns of common usage ofthe system extracted from query logs. Such knowledge has been used:(1); to devise aneffective policy for caching WSE query results;(2); to drive the partitioning of the invertedindex among the nodes of a termpartitioned; parallel IR system;(3); to perform documentpartitioning and effective collection selection in a document-partitioned; parallel IR system.The techniques and algorithms used vary from simple statistical analysis; to frequent …,A. Soro; G. Paddeu; G. Armano. Distributed Agent-based Retrieval Tools. Polimetrica International Scientific Publisher,2006,*
A Grid Information Service Based on Peer-to-Peer,Ranieri Baraglia; Fabrizio Silvestri; Stefano Moncelli; Nicola Tonellotto,Abstract. Information Services are fundamental blocks of the Grid in-frastructure. They areresponsible for collecting and distributing infor-mation about resource availability and statusto users: the quality of these data may have a strong impact on scheduling algorithms andover-all performance. Many popular information services have a centralized structure. Thisclearly introduces problems related to information updating and fault tolerance. Also; in verylarge configurations; scalability may be an issue. In this work; we present a Grid InformationService based on the peer-to-peer technology. Our system offers a fast propagation ofinformation and has high scalability and reliability. We implemented our system com-plyingto the OGSA standard using the Globus Toolkit 3. Our system can run on Linux and Windowssystems; with different network config-urations; so to trade off between redundancy …,In Proceedings of the Euro-Par 2005,2005,*
Topic 5-Parallel and Distributed Databases; Data Mining and Knowledge Discovery-A Highly Scalable Parallel Caching System for Web Search Engine Results,T Fagni; R Perego; F Silvestri,*,Lecture Notes in Computer Science,2004,*
An Online Recommender System.,Ranieri Baraglia; Fabrizio Silvestri,Abstract One of the most important class of Data Mining applications is the so called “WebMining Systems” which analyzes and extracts important and non-trivial knowledge from Webrelated data. Typical applications of Web Mining are represented by the personalization orrecommender systems. These systems are aimed to extract knowledge from the analysis ofhistorical information of a web server in order to improve the web site expressiveness interms of readability and content availability. Typically; these systems are made up of twoparts. One; which is usually executed off-line; analyzes the server access logs in order tofind a suitable categorization; and another; which is usually executed online; classifies theactive requests; according to the previous off-line analysis. In this paper we proposeSUGGEST 2.0 a recommender system which differently from previously proposed WUM …,SEBD,2004,*
A hybrid strategy for caching web search engine results,Tiziano Fagni; Salvatore Orlando; Paolo Palmerini; Raffaele Perego; Fabrizio Silvestri; Consiglio Nazionale delle Ricerche; Pisa (Italy). Istituto di Scienza e Tecnologie della Informazione'Alessandro Faedo';,*,Poster paper Twelfth International World Wide Web Conference (WWW2003),2003,*
An Efficient Parallel and Distributed Algorithm for Counting Frequent Sets,Fabrizio Silvestri,*,Logic-Based Program Synthesis and Transformation: 8th International Workshop; LOPSTR'98; Manchester; UK; June 15-19; 1998; Selected Papers,1999,*
Load-Balancing and Caching for Collection Selection Architectures,Fabrizio Silvestri; Raffaele Perego; Ricardo Baeza-yates,Abstract—To address the rapid growth of the Internet; modern Web search engines have toadopt distributed organizations; where the collection of indexed documents is partitionedamong several servers; and query answering is performed as a parallel and distributed task.Collection selection can be a way to reduce the overall computing load; by finding a trade-offbetween the quality of results retrieved and the cost of solving queries. In this paper; weanalyze the relationship between the collection selection strategy; the effect on loadbalancing and on the caching subsystem; by exploring the design-space of a distributedsearch engine based on collection selection. In particular; we propose a strategy to performcollection selection in a load-driven way; and a novel caching policy able to incrementallyrefine the effectiveness of the results returned for each subsequent cache hit. The …,*,*,*
Foreword ix Contributing Authors xv,David Snelling; Ali Anjomshoaa; Francis Wray; Achim Basermann; Mike Fisher; Mike Surridge; Philipp Wieder; Catalin L Dumitrescu; Alexandru Iosup; Ozan Sonmez; Hashim Mohamed; Dick Epema; Veronika Rehn-Sonigo; Konstantinos Tserpes; Dimosthenis Kyriazis; Andreas Menychtas; Theodora Varvarigou; Fabrizio Silvestri; Domenico Laforenza; Amit D Lakhani; Erica Y Yang; Brian Matthews; Ian Johnson; Syed Naqvi; Gheorghe C Silaghi; Gheorghe Cosmin Silaghi; Alvaro E Arenas; Luis Moura Silva; Amit Lakhani; Yvon Jégou; Christine Morin; Oscar David Sánchez; Carsten Franke; Philip Robinson; Adolf Hohl; Bernd Scheuermann; Daniel Vladusic; Haiyan Yu; An Qin; Rubao Lee; Erich Focht; Massimo Coppola; Martin Kuba; Daniel Kouril; Michal Procházka,Page 1. Contents Foreword ix Contributing Authors xv Part I Service Level Agreement and Qualityof Service NextGRID Architectural Concepts 3 David Snelling; Ali Anjomshoaa; Francis Wray;Achim Basermann; Mike Fisher; Mike Surridge; Philipp Wieder Virtual Domain Sharing ine-Science based on Usage Service Level Agreements 15 Catalin L. Dumitrescu; Alexandru Iosup;Ozan Sonmez; Hashim Mohamed; and Dick Epema Optimal Closest Policy with QoS andBandwidth Constraints 27 Veronika Rehn-Sonigo An Open Architecture for QoS Information inBusiness Grids 37 Konstantinos Tserpes; Dimosthenis Kyriazis; Andreas Menychtas and TheodoraVar- varigou; Fabrizio Silvestri and Domenico Laforenza Part II Trust; Security and VirtualOrganization Threat Analysis and Attacks on XtreemOS: a Grid–enabled Operating System 53 …,*,*,*
Doc Ref: P5. 3.1,Barbara Cantalupo; Ludovico Giammarino; Nikolaos Matskanis; Mike Surridge; Fabrizio Silvestri,*,*,*,*
An Oblivious Approach to Parallel Algorithms,Francesco Silvestri,Abstract This extended abstract describes my dissertation work undertaken at the Universityof Padova under the supervision of Prof. A. Pietracaprina. My work has focused on thedevelopment of network-oblivious algorithms; that is; parallel algorithms that can rununchanged yet efficiently on a variety of machines characterized by different degrees ofparallelism and communication capabilities. Also; I have studied the limitations of the cache-oblivious and network-oblivious approaches.,POSTER,*,*
ASONAM 2016 program committee,Alessandro Epasto; Alex Beutel; Aneesh Sharma; Anirban Dasgupta; Anna Squicciarini; Aris Anagnostopoulos; Austin Benson; B Aditya Prakash; Carlos Castillo; Chi Wang; Cristina Ioana Muntean; Danai Koutra; David Liben-Nowell; Edgar Meij; Edoardo Serra; Evangelos Papalexakis; Fabrizio Silvestri; Feida Zhu; Francesco Gullo; Franco Maria; ISTI-CNR Nardini; Freddy Chong Tat Chua; Gabriele Tolomei; Hasan Davulcu; ASU Huawei Shen; Iadh Ounis; Ingmar Weber; Irwin King; Jaap Kamps; James Cook; Jaya Kawale; Adobe Jian Pei; Jiayu Zhou; Jia-Yu Pan; Jiliang Tang; Jing Zhang; Tsinghua Jingrui He; Jingwei Xu; Juanzi Li,Aditya Pal; Facebook Alessandro Epasto; Brown University Alex Beutel; Carnegie Mellon UniversityAlfredo Cuzzocrea; ICAR-CNR and University of Calabria Aneesh Sharma; Twitter Inc AnirbanDasgupta; IIT Gandhinagar Anna Squicciarini; The Pennsylvania State University ArisAnagnostopoulos; Sapienza University of Rome Austin Benson; Stanford University B. AdityaPrakash; Virginia Tech Carlos Castillo; Qatar Computing Research Institute Chi Wang; MicrosoftResearch Claudio Lucchese; ISTI-CNR Cristina Ioana Muntean; ISTI CNR Danai Koutra; Universityof Michigan; Ann Arbor David Liben-Nowell; Carleton College Edgar Meij; Yahoo Labs EdoardoSerra; Boise State University Evangelos Papalexakis; Carnegie Mellon University FabricioBenevenuto; Federal University of Minas Gerais (UFMG) Fabrizio Silvestri; Yahoo Labs FeidaZhu; Singapore Management University Francesco Gullo; Yahoo Labs Franco Maria …,*,*,*
Improve Ranking Efficiency by Optimizing Tree Ensembles,Claudio Lucchese; Franco Maria Nardini; Salvatore Orlando; Raffaele Perego; Fabrizio Silvestri; Salvatore Trani,Abstract. Learning to Rank (LtR) is the machine learning method of choice for producinghighly effective ranking functions. However; efficiency and effectiveness are two competingforces and trading off effectiveness for meeting efficiency constraints typical of productionsystems is one of the most urgent issues. This extended abstract shortly summarizes thework in [4] proposing CLEaVER; a new framework for optimizing LtR models based onensembles of regression trees. We summarize the results of a comprehensive evaluationshowing that CLEaVER is able to prune up to 80% of the trees and provides an efficiencyspeed-up up to 2.6 x without affecting the effectiveness of the model. Modern searchengines are expected to return highly relevant results in a fractions of seconds to satisfyefficiency constraints. Learning-to-Rank (LtR)[1] methodologies are nowadays …,*,*,*
Program Track Committees,David Webster; Django Armstrong; Aris Gkoulalas-Divanis; Pietro Colombo; Gregorio Martinez; Shiyong Lu; Kwan Liu Ma; Robert van Engelen; Deng Lei; Peter Garraghan; Zhengyi Le; Matt Bishop; Bhavani Thuraisingham; Gang Zhou; Fillia Makedon; Abel Wang; Aaron Ling; Yuliang Zheng; Shuyu Li; Younghee Park; Magdalini Eirinaki; Iraklis Varlamis; Eirini Ntoutsi; Kjetil Norvag; Fabrizio Silvestri; Patrick Marcel; George Tsatsaronis; Theodore Dalamagas; Aikaterini Potika; Panagiotis Bouros; Uraz Yavanoglou; Dimitris Michail,Big Data Computing and Service David Webster; University of Leeds; United Kingdom DjangoArmstrong; University of Leeds; United Kingdom Aris Gkoulalas-Divanis; IBMResearch-Ireland; Ireland Pietro Colombo; University of Insubria; Italy Gregorio Martinez; Universityof Murcia; Spain Shiyong Lu; Wayne State University; USA Kwan Liu Ma; University of CaliforniaDavis; USA Robert van Engelen; Florida State University; USA Deng Lei; Northwestern PolytechnicalUniversity; China Peter Garraghan; University of Leeds; United Kingdom … Big Data SecurityZhengyi Le; Suning Palo Alto R&D Center; USA Matt Bishop; University of California Davis; USABhavani Thuraisingham; University of Texas Dallas; USA Gang Zhou; College of William andMary; USA Fillia Makedon; University of Texas at Arlington; USA George Venececk; FICO; USAAbel Wang; Suning Palo Alto R&D Center; USA Aaron Ling; Ancestry.com; USA Yuliang …,*,*,*
The CIKM 2006 Workshop on Information Retrieval in Peer-to-Peer Networks,Ivana PodnarZarko; Fabrizio Silvestri,Information Retrieval (IR) in distributed and decentralized environments has become anactive field of research during the last years. Recently; Peer-to-Peer (P2P) networks haveemerged as an attractive architectural paradigm for IR; both for technical and economicreasons. P2P networks are distributed and self-organizing systems that support resourcesharing. For this reasons; they are promising building blocks for next-generation searchengines that will have to deal with huge amounts of heterogeneous (eg textual; multimedia;audiovisual) and continuously changing data. Moreover; P2P search is appealing from aneconomic perspective since it requires minimal in-place infrastructure and maintenance; yetfacilitating higher diversity in contents and search methods. However; P2P retrieval methodsstill pose a lot of research challenges. Search methods are typically limited to simple …,*,*,*
Full-Flavored Data Intensive Algorithms on Low-Carb Architectures,Ranieri Baraglia; Dino Pedreschi; Fabrizio Silvestri; Gabriele Capannini,*,*,*,*
Share this,Nguyen Hoang Vu,I laughed my head off. Not until I took a course in client management did I realize that jokesomehow rang true; at least in terms of agency remuneration. That is; if you want to be eithera good account person or a thriving prostitute; one of the fundamental tricks to learn is howto bill intangible values in a way that appeals to your clients while ensuring your (agency's)income. Indeed; the art of account management has nothing to do with the ability to produceart or copy; but rather lies within the financial and relationship sides of this creative business(Hameroff 1998).,*,*,*
SNOW’14 Chairs’ Welcome,Gianmarco De Francisci Morales; Luca Maria Aiello; Fabrizio Silvestri; Symeon Papadopoulos,In recent years; the topics addressed by SNOW have become very popular among diversescientific communities. Data-mining researchers have studied how information spreads anddiffuses in social networks. Journalists; social scientists; economists; are typical users whocan improve their respective fields by adopting technologies of interest to SNOW. Theworkshop aims to provide a new forum to foster communication between these communities.In particular; the workshop has attracted a small number of high-quality submissions on therelationships between online news and social media. With this workshop we aim atcontinuing a tradition of interdisciplinary exchange and cross-domain fertilization amongdifferent research communities. The goal of the workshop is to share novel ideas and todiscuss future directions in the emerging areas of news search; news mining; and news …,*,*,*
Advances in Information Retrieval,Hugo Zaragoza B Barla Cambazoglu; Vanessa Murdock Ronny Lempel; Fabrizio Silvestri,These proceedings contain the high-quality papers; posters; and demonstrations presentedat the 34th European Conference on Information Retrieval (ECIR 2012); held during April 1–5; 2012; in Barcelona; Spain. The conference was jointly organized by Yahoo! ResearchBarcelona; Universitat Pompeu Fabra and the Barcelona Media Foundation. It wassupported by the Information Retrieval Specialist Group at the British Computer Society(BCS-IRSG) and in cooperation with the Special Interest Group in Information Retrieval ofthe Association for Computing Machinery (ACM SIGIR). ECIR 2012 received a total of 261submissions across four categories: 163 fullpaper submissions; 78 poster submissions; 11demonstration submissions and 9 industry track submissions. Of these submissions; 66%were from Europe; 17% from Asia; 14% from America and 3% from the rest of the world …,*,*,*
SNOW Chairs’ Welcome,Gianmarco De Francisci Morales; Aristides Gionis; Fabrizio Silvestri,In recent years; the topics addressed by SNOW have become very popular among diversescientific communities. Data-mining researchers have studied how information spreads anddiffuses in social networks. Journalists; social scientists; economists; are typical users whocan improve their respective fields by adopting technologies of interest to SNOW. Theworkshop aims to provide a new forum to foster communication between these communities.In particular; for its first edition; the workshop has attracted a small number of high-qualitysubmissions on the relationships between online news and social media. With thisworkshop we hope to start a tradition of interdisciplinary exchange and cross-domainfertilization among different research communities. The goal of the workshop is to sharenovel ideas and to discuss future directions in the emerging areas of news search; news …,*,*,*
WI-IAT Workshops 2012,ISTI-CNR Ranieri Baraglia; Franco Maria Nardini; Rossano Venturini; M-Dyaa Albakour; Michele Berlingerio; Ophir Frieder; Udo Kruschwitz; Ronny Lempel; Mirko Nanni; Marco Pennacchiotti; Fabio Pinelli; Fabrizio Silvestri,Ranieri Baraglia; ISTI-CNR; Pisa; Italy Franco Maria Nardini; ISTI-CNR; Pisa; Italy RossanoVenturini; University of Pisa; Pisa; Italy … M-Dyaa Albakour; University of Glasgow; UK RanieriBaraglia; ISTI-CNR; Italy Michele Berlingerio; IBM Research; Ireland Ophir Frieder; GeorgetownUniversity; USA Udo Kruschwitz ; University of Essex; UK Ronny Lempel; Yahoo! Research;Israel Mirko Nanni; ISTI-CNR; Italy Franco Maria Nardini; ISTI-CNR; Italy MarcoPennacchiotti; Yahoo! Labs; USA Fabio Pinelli; IBM Research; Ireland Fabrizio Silvestri;ISTI-CNR; Italy Rossano Venturini; University of Pisa; Italy,*,*,*
Manuel Montes-y-Gómez; INAOE; Mexico David Nichols; University of Waikato; New Zealand Yoan J. Pinzón; National University of Colombia; Colombia Manuel Re...,Oscar Pastor-López; Daniel Schwabe; Steffen Staab; Altigran S Da Silva; Fabrizio Silvestri; Elaine Toms; Genoveva Vargas; Bebo White,Paolo Boldi; University of Milano; Italy Carlos Castillo; QFRI; Qatar Pablo César; CWI; NetherlandsCesar Collazos; University del Cauca; Colombia Pablo de la Fuente; GRINBD. Universidad deValladolid; Spain Claudio Gutiérrez; Universidad de Chile; Chile Claudia LucíaJiménez-Guarín; Universidad de los Andes; Colombia Alejandro López-Ortiz; University ofWaterloo; Canada Mauricio Marín; Yahoo! Research; Santiago; Chile Massimo Melucci; Universityof Padova; Italy Manuel Montes-y-Gómez; INAOE; Mexico David Nichols; University ofWaikato; New Zealand Yoan J. Pinzón; National University of Colombia; Colombia ManuelReyes-Gómez; Microsoft Research; USA Marcela Rodríguez; UABC; Mexico OscarPastor-López; Polytechnic of Valencia; Spain Daniel Schwabe; Department of Informatics;PUC-Rio; Brazil Steffen Staab; University of Koblenz-Landau; Germany Altigran S. Da …,*,*,*
Hary Agius; Brunel University; United Kingdom Yannis Avrithis; National Technical University of Athens; Greece Makram Bouzid; Motorola Labs Claudia Buzzi; Italia...,Pablo Castells; Patricia Charlton; Qingcai Chen; Anastasios Delopoulos; William Grosky; Pascal Hitzler; Jane Hunter; Anthony Jameson; Franciska de Jong; Joemon Jose; Kostas Karpouzis; Judy Kay; Hyoung Joong Kim; Alexander Kroener; John WT Lee; Ilias Maglogiannis; Ferran Marques; Mark Maybury; Bamshad Mobasher; Daniela Nicklas; Thrasos Pappas; Ioannis Pitas; Daming Shi; Timothy Shih; Fabrizio Silvestri; Murat Tekalp; Paulo Villegas; Xiaolong Wang,Hary Agius; Brunel University; United Kingdom Yannis Avrithis; National Technical Universityof Athens; Greece Makram Bouzid; Motorola Labs Claudia Buzzi; Italian National Research Council- Institute of Informatics and Telematics (IIT); Italy Pablo Castells; Universidad Autónonoma deMadrid; Spain Patricia Charlton; Motorola Labs; United Kingdom Qingcai Chen; Harbin Instituteof Technology; China Anastasios Delopoulos; Aristotle University of Thessaloniki; Greece WilliamGrosky; University of Michigan - Dearborn; USA Pascal Hitzler; University of Karlsruhe; GermanyJane Hunter; The University of Queensland; Australia Anthony Jameson; German ResearchCenter for Artificial Intelligence (DFKI) - International University; Bruchsal Franciska de Jong;University of Twente; The Netherlands Joemon Jose; University of Glasgow; United KingdomKostas Karpouzis; National Technical University of Athens; Greece Judy Kay; University …,*,*,*
xvii,Abhishek Guarev; Aditya Kwatra; Alexandre Sena; Alexandru Jugravu; Aline Nascimento; Amol Bakshi; Anastasios Gounaris; Andreas Boklund; Andrey Mirtchovsky; Andrzej M Goscinski; Andy Hospodor; Animesh Pathak; Anirban Chakrabarty; Artur Andrzejak; Ashiq Anjum; Bernd Schuller; Bo Xing; Brian Tierney; Cam Macdonell; Chen Chunxi; Chen Lin; Christina Cunningham; Christos Tryfonopoulos; Clovis Seragiotto; Colin Enticott; Cong Zhang; Cristina Schmidt; Dan S Katz; Daniel Massaguer; Darin England; Dean Jacobs; Dean Kuo; Diego Puppin; Douglas Lyon; Eran Shir; Fabrizio Silvestri; Felix Hupfeld; Florian Schintke; Garry Smith; Gee-Bum Koo; Guangsen Zhang; Helen Xiang; Helmut Wanek; Hidemoto Nakada; Hun Joo Myung; Ioannis Kotsiopoulos; J Ram Ramanujam; Jacques da Silva; Jaegyoon Hahm; Jaspal Subholk; Jean-Patrick Gelas; Jeff Tan; Jingzhao Ou; Joachim Flammer; John P Dougherty; Jon MacLaren; Juergen Mangler; Julie McCabe; Jun Qin; Jussipekka Leiwo,Page 1. xvii External Reviewers Abhishek Guarev Aditya Kwatra Alexandre Sena AlexandruJugravu Aline Nascimento Amol Bakshi Anastasios Gounaris Andreas Boklund AndreyMirtchovsky Andrzej M. Goscinski Andy Hospodor Animesh Pathak Anirban Chakrabarty ArturAndrzejak Ashiq Anjum Bernd Schuller Bo Xing Brian Tierney Cam Macdonell Chen ChunxiChen Lin Christina Cunningham Christos Tryfonopoulos Clovis Seragiotto Colin Enticott CongZhang Cristina Schmidt Dan S. Katz Daniel Massaguer Darin England Dean Jacobs Dean KuoDiego Puppin Douglas Lyon Eran Shir Fabrizio Silvestri Felix Hupfeld Florian Schintke GarrySmith Gee-Bum Koo Guangsen Zhang Helen Xiang Helmut Wanek Hidemoto Nakada Hun JooMyung Ioannis Kotsiopoulos J. (Ram) Ramanujam Jacques da Silva Jaegyoon Hahm JaspalSubholk Jean-Patrick Gelas Jeff Tan Jingzhao Ou Joachim Flammer …,*,*,*
P2P-RDM 2011 Committees,Patrizio Dazzi; Matteo Mordacchini; Amitabha Bagchi; Massimo Coppola; Paolo Costa; Franca Delmastro; Dick HJ Epema; Stefano Ferretti; Vivi Fragopoulou; Pedro Garcia Lopez; Nazli Goharian; Mark Jelasity; Miroslaw Korzeniowski; Yevgeni Koucheryavy; Aleksandra Kovacevic; Nicolas Le Scouarnec; Claudio Lucchese; Victor Malyshkin; Alberto Montresor; Gianluca Moro; Salvatore Orlando; Marcelo Pasin; Raffaele Perego; Marinho Pilla Barcellos; Etienne Riviere; Marco Roccetti; Fabrizio Silvestri; Giandomenico Spezzano; Domenico Talia; Paolo Trunfio; Alexey Vinel,Organizing Committee Patrizio Dazzi; ISTI-CNR; Pisa; Italy Matteo Mordacchini; IIT-CNR;Pisa; Italy … Programme Committee Amitabha Bagchi; IIT Massimo Coppola; ISTI-CNR PaoloCosta; Imperial College London Franca Delmastro; IIT-CNR Dick HJ Epema; University of DelftStefano Ferretti; University of Bologna Vivi Fragopoulou; FORTH-ICS Pedro Garcia Lopez; UniversityRovira i Virgili Nazli Goharian; Georgetown University Mark Jelasity; Hungarian Academy ofSciences and University of Szeged Miroslaw Korzeniowski; Wroclaw University of TechnologyYevgeni Koucheryavy; Tampere University of Technology Aleksandra Kovacevic; TU DarmstadtNicolas Le Scouarnec; Technicolor Rennes Claudio Lucchese; ISTI-CNR Victor Malyshkin; SiberianDivision of the Russian Academy of Sciences Alberto Montresor; University of Trento GianlucaMoro; University of Bologna Salvatore Orlando; University of Venice Marcelo Pasin …,*,*,*
An Effective Recommender System for Highly Dynamic and Large Web Sites (Demo Paper),Ranieri Baraglia; Francesco Merlo; Fabrizio Silvestri,Abstract. In this demo we show a recommender system; called SUGGEST; that dynamicallygenerates links to pages that have not yet been visited by a user and might be of hispotential interest. Usually other recommender systems exploit a kind of two-phasearchitecture composed by an off-line component that analyzes Web server access logs andgenerates information used by a successive online component that generatesrecommendations. SUGGEST collapse the two-phase into a single online Apache module.The component is able to manage very large Web sites made up of dinamically generatedpages by means of an efficient LRU-based database management strategy. The demo willshow the way SUGGEST is able to anticipate users' requests that will be made farther in thefuture; introducing a limited overhead on the Web server activity3. The continuous and …,*,*,*
ACM SIGIR 2005 Workshop on Heterogeneous and Distributed Information Retrieval (HDIR 2005),Domenico Laforenza; Pisa Italy ISTI–CNR; Fabrizio Silvestri,In the last few years there have been the explosion in the use of heterogeneous distributedsystems. Ranging from simple Network of Workstations to the more modern and complexGrid systems; the adoption of distributed systems instead of massively parallelsupercomputers has been preferred due to their reduced cost of ownership. These kinds ofsystems pose many challenges in terms of information access; storage and retrieval.Usually; in fact; instead of having collections stored at a single site they are collected; andsometimes managed; at different sites (possibly owned by different institutions). Particularinterest has been expressed on architectures and specifications for information retrieval inthe context of heterogeneous distributed computing systems. This workshop will focus onnew methods and algorithms to efficiently and effectively access data distributed over …,*,*,*
Web Spam Detection,Ricardo Baeza-Yates; A Gionis; S Leonardi; V Murdock; M Santini; F Silvestri; S Vigna,1. Yahoo! Research Barcelona – Catalunya; Spain 2. Universit`a di Roma “La Sapienza” –Rome; Italy 3. Yahoo! Research Santiago – Chile 4. ISTI-CNR –Pisa;Italy 5. Universit`a degliStudi di Milano – Milan; Italy … This is a talk about academic research … 1 Web Spam 2 WebSpam Detection 3 A Reference Collection 4 Web Links 5 Topological Web Spam 6 Countingof Supporters 7 Content-based Spam detection 8 Web Topology 9 Conclusions … “The sumof all human knowledge plus porn” – Robert Gilbert … Keyword stuffing Link farms Spam blogs(splogs) Cloaking … Every undeserved gain in ranking for a spammer; is a loss of … 1 WebSpam 2 Web Spam Detection 3 A Reference Collection 4 Web Links 5 Topological Web Spam6 Counting of Supporters 7 Content-based Spam detection 8 Web Topology 9 Conclusions …1 Web Spam 2 Web Spam Detection 3 A Reference Collection 4 Web Links 5 …,*,*,*
The Web Object Store: an infrastructure for mining semantics from web resources and their usage,Mirco Nanni; Fabrizio Silvestri; Fosca Giannotti; Dino Pedreschi,Abstract. The development of methods for an effective and efficient access to the informationcontained in large masses of digital documents is a long-standing objective in computerscience research; and its importance is emphasized by the growing availability of largeinformation repositories. With the advent of the web; the methods for content deliveryevolved in the services offered by search engines; categorization and topic search services;related pages services; etc.: the main innovation needed was a shift from content-onlyanalysis methods to the combined analysis of contents and hyperlinked structure of webdocuments; as witnessed by the PageRank metric for document relevance. However; as theweb explosion continues; the limitations of the current generation of access services to webcontents are becoming clearer; in terms of scarce quality and freshness of the results; etc …,*,*,*
