Retrieving and integrating data from multiple information sources,Yigal Arens; Chin Y Chee; Chun-nan Hsu; Craig Knoblock,With the current explosion of data; retrieving and integrating information from varioussources is a critical problem. Work in multidatabase systems has begun to address thisproblem; but it has primarily focused on methods for communicating between databases andrequires significant effort for each new database added to the system. This paper describesa more general approach that exploits a semantic model of a problem domain to integratethe information from various information sources. The information sources handled includeboth databases and knowledge bases; and other information sources (eg programs) couldpotentially be incorporated into the system. This paper describes how both the domain andthe information sources are modeled; shows how a query at the domain level is mapped intoa set of queries to individual information sources; and presents algorithms for …,*,1993,626
Generating finite-state transducers for semi-structured data extraction from the web,Chun-Nan Hsu; Ming-Tzung Dung,Abstract Integrating a large number of Web information sources may significantly increasethe utility of the World-Wide Web. A promising solution to the integration is through the use ofa Web Information mediator that provides seamless; transparent access for the clients.Information mediators need wrappers to access a Web source as a structured database; butbuilding wrappers by hand is impractical. Previous work on wrapper induction is toorestrictive to handle a large number of Web pages that contain tuples with missing attributes;multiple values; variant attribute permutations; exceptions and typos. This paper presentsSoftMealy; a novel wrapper representation formalism. This representation is based on afinite-state transducer (FST) and contextual rules. This approach can wrap a wide range ofsemistructured Web pages because FSTs can encode each different attribute permutation …,Information systems,1998,605
FASTSNP: an always up-to-date and extendable service for SNP function analysis and prioritization,Hsiang-Yu Yuan; Jen-Jie Chiou; Wen-Hsien Tseng; Chia-Hung Liu; Chuan-Kun Liu; Yi-Jung Lin; Hui-Hung Wang; Adam Yao; Yuan-Tsong Chen; Chun-Nan Hsu,Abstract Single nucleotide polymorphism (SNP) prioritization based on the phenotypic risk isessential for association studies. Assessment of the risk requires access to a variety ofheterogeneous biological databases and analytical tools. FASTSNP (function analysis andselection tool for single nucleotide polymorphisms) is a web server that allows users toefficiently identify and prioritize high-risk SNPs according to their phenotypic risks andputative functional effects. A unique feature of FASTSNP is that the functional effectinformation used for SNP prioritization is always up-to-date; because FASTSNP extracts theinformation from 11 external web servers at query time using a team of web wrapper agents.Moreover; FASTSNP is extendable by simply deploying more Web wrapper agents. Tovalidate the results of our prioritization; we analyzed 1569 SNPs from the SNP500Cancer …,Nucleic acids research,2006,526
Query processing in the sims information mediator,Yigal Arens; Chun-Nan Hsu; Craig A Knoblock,Abstract A critical problem in building an information mediator is how to translate a domain-level query into an efficient query plan for accessing the required data. We have built aflexible and efficient information mediator; called SIMS. This system takes a domain-levelquery and dynamically selects the appropriate information sources based on their contentand availability; generates a query access plan that specifies the operations and their orderfor processing the data; and then performs semantic query optimization to minimize theoverall execution time. This paper describes these three basic components of the queryprocessing in SIMS.,Advanced Planning Technology,1996,338
Overview of BioCreative II gene normalization,Alexander A Morgan; Zhiyong Lu; Xinglong Wang; Aaron M Cohen; Juliane Fluck; Patrick Ruch; Anna Divoli; Katrin Fundel; Robert Leaman; Jörg Hakenberg; Chengjie Sun; Heng-hui Liu; Rafael Torres; Michael Krauthammer; William W Lau; Hongfang Liu; Chun-Nan Hsu; Martijn Schuemie; K Bretonnel Cohen; Lynette Hirschman,The goal of the gene normalization task is to link genes or gene products mentioned in theliterature to biological databases. This is a key step in an accurate search of the biologicalliterature. It is a challenging task; even for the human expert; genes are often describedrather than referred to by gene symbol and; confusingly; one gene name may refer todifferent genes (often from different organisms). For BioCreative II; the task was to list theEntrez Gene identifiers for human genes or gene products mentioned in PubMed/MEDLINEabstracts. We selected abstracts associated with articles previously curated for humangenes. We provided 281 expert-annotated abstracts containing 684 gene identifiers fortraining; and a blind test set of 262 documents containing 785 identifiers; with a goldstandard created by expert annotators. Inter-annotator agreement was measured at over …,Genome biology,2008,296
Overview of BioCreative II gene mention recognition,Larry Smith; Lorraine K Tanabe; Rie Johnson nee Ando; Cheng-Ju Kuo; I-Fang Chung; Chun-Nan Hsu; Yu-Shi Lin; Roman Klinger; Christoph M Friedrich; Kuzman Ganchev; Manabu Torii; Hongfang Liu; Barry Haddow; Craig A Struble; Richard J Povinelli; Andreas Vlachos; William A Baumgartner; Lawrence Hunter; Bob Carpenter; Richard Tzong-Han Tsai; Hong-Jie Dai; Feng Liu; Yifei Chen; Chengjie Sun; Sophia Katrenko; Pieter Adriaans; Christian Blaschke; Rafael Torres; Mariana Neves; Preslav Nakov; Anna Divoli; Manuel Mana-Lopez; Jacinto Mata; W John Wilbur,Nineteen teams presented results for the Gene Mention Task at the BioCreative II Workshop.In this task participants designed systems to identify substrings in sentences correspondingto gene name mentions. A variety of different methods were used and the results varied witha highest achieved F1 score of 0.8721. Here we present brief descriptions of all the methodsused and a statistical analysis of the results. We also demonstrate that; by combining theresults from all submissions; an F score of 0.9066 is feasible; and furthermore that the bestresult makes use of the lowest scoring submissions.,Genome biology,2008,248
Automatic information extraction from semi-structured web pages by pattern discovery,Chia-Hui Chang; Chun-Nan Hsu; Shao-Cheng Lui,Abstract The World Wide Web is now undeniably the richest and most dense source ofinformation; yet; its structure makes it difficult to make use of that information in a systematicway. This paper proposes a pattern discovery approach to the rapid generation ofinformation extractors that can extract structured data from semi-structured Web documents.Previous work in wrapper induction aims at learning extraction rules from user-labeledtraining examples; which; however; can be expensive in some practical applications. In thispaper; we introduce IEPAD (an acronym for Information Extraction based on PAtternDiscovery); a system that discovers extraction patterns from Web pages without user-labeledexamples. IEPAD applies several pattern discovery techniques; including PAT-trees;multiple string alignments and pattern matching algorithms. Extractors generated by …,Decision Support Systems,2003,172
The gene normalization task in BioCreative III,Zhiyong Lu; Hung-Yu Kao; Chih-Hsuan Wei; Minlie Huang; Jingchen Liu; Cheng-Ju Kuo; Chun-Nan Hsu; Richard Tzong-Han Tsai; Hong-Jie Dai; Naoaki Okazaki; Han-Cheol Cho; Martin Gerner; Illes Solt; Shashank Agarwal; Feifan Liu; Dina Vishnyakova; Patrick Ruch; Martin Romacker; Fabio Rinaldi; Sanmitra Bhattacharya; Padmini Srinivasan; Hongfang Liu; Manabu Torii; Sergio Matos; David Campos; Karin Verspoor; Kevin M Livingston; W John Wilbur,We report the Gene Normalization (GN) challenge in BioCreative III where participatingteams were asked to return a ranked list of identifiers of the genes detected in full-textarticles. For training; 32 fully and 500 partially annotated articles were prepared. A total of507 articles were selected as the test set. Due to the high annotation cost; it was not feasibleto obtain gold-standard human annotations for all test articles. Instead; we developed anExpectation Maximization (EM) algorithm approach for choosing a small number of testarticles for manual annotation that were most capable of differentiating team performance.Moreover; the same algorithm was subsequently used for inferring ground truth based solelyon team submissions. We report team performance on both gold standard and inferredground truth using a newly proposed metric called Threshold Average Precision (TAP-k) …,BMC bioinformatics,2011,112
The ANNIGMA-wrapper approach to fast feature selection for neural nets,Chun-Nan Hsu; Hung-Ju Huang; S Dietrich,This paper presents a novel feature selection approach for backpropagation neuralnetworks (NNs). Previously; a feature selection technique known as the wrapper model wasshown effective for decision trees induction. However; it is prohibitively expensive whenapplied to real-world neural net training characterized by large volumes of data and manyfeature choices. Our approach incorporates a weight analysis-based heuristic called artificialneural net input gain measurement approximation (ANNIGMA) to direct the search in thewrapper model and allows effective feature selection feasible for neural net applications.Experimental results on standard datasets show that this approach can efficiently reduce thenumber of features while maintaining or even improving the accuracy. We also report twosuccessful applications of our approach in the helicopter maintenance applications.,IEEE Transactions on Systems; Man; and Cybernetics; Part B (Cybernetics),2002,108
Integrating high dimensional bi-directional parsing models for gene mention tagging,Chun-Nan Hsu; Yu-Ming Chang; Cheng-Ju Kuo; Yu-Shi Lin; Han-Shen Huang; I-Fang Chung,Abstract Motivation: Tagging gene and gene product mentions in scientific text is animportant initial step of literature mining. In this article; we describe in detail our genemention tagger participated in BioCreative 2 challenge and analyze what contributes to itsgood performance. Our tagger is based on the conditional random fields model (CRF); themost prevailing method for the gene mention tagging task in BioCreative 2. Our tagger isinteresting because it accomplished the highest F-scores among CRF-based methods andsecond over all. Moreover; we obtained our results by mostly applying open sourcepackages; making it easy to duplicate our results. Results: We first describe in detail how wedeveloped our CRF-based tagger. We designed a very high dimensional feature set thatincludes most of information that may be relevant. We trained bi-directional CRF models …,Bioinformatics,2008,92
Introducing meta-services for biomedical information extraction,Florian Leitner; Martin Krallinger; Carlos Rodriguez-Penagos; Jörg Hakenberg; Conrad Plake; Cheng-Ju Kuo; Chun-Nan Hsu; Richard Tzong-Han Tsai; Hsi-Chuan Hung; William W Lau; Calvin A Johnson; Rune Sætre; Kazuhiro Yoshida; Yan Hua Chen; Sun Kim; Soo-Yong Shin; Byoung-Tak Zhang; William A Baumgartner; Lawrence Hunter; Barry Haddow; Michael Matthews; Xinglong Wang; Patrick Ruch; Frédéric Ehrler; Arzucan Özgür; Güneş Erkan; Dragomir R Radev; Michael Krauthammer; ThaiBinh Luong; Robert Hoffmann; Chris Sander; Alfonso Valencia,We introduce the first meta-service for information extraction in molecular biology; theBioCreative MetaServer (BCMS; http://bcms. bioinfo. cnio. es/). This prototype platform is ajoint effort of 13 research groups and provides automatically generated annotations forPubMed/Medline abstracts. Annotation types cover gene names; gene IDs; species; andprotein-protein interactions. The annotations are distributed by the meta-server in bothhuman and machine readable formats (HTML/XML). This service is intended to be used bybiomedical researchers and database annotators; and in biomedical language processing.The platform allows direct comparison; unified access; and result aggregation of theannotations.,Genome biology,2008,84
Why discretization works for na ve Bayesian classifiers,Chun-Nan Hsu; Hung-Ju Huang; Tzu-Tsung Wong,Abstract This paper explains why well-known discretization methods; such as entropy-basedand ten-bin; work well for naive Bayesian classi ers with continuous variables; regardless oftheir complexities. These methods usually assume that discretized variables have Dirichletpriors. Since perfect aggregation holds for Dirichlets; we can show that; generally; a widevariety of discretization methods can perform well with insigni cant di erence. We identifysituations where discretization may cause performance degradation and show that they areunlikely to happen for well-known methods. We empirically test our explanation withsynthesized and real data sets and obtain con rming results. Our analysis leads to a lazydiscretization method that can simplify the training for naive Bayes. This new method canperform as well as well-known methods in our experiment.,Proceedings of the Seventeenth International Conference on Machine Learning; Morgan Kaufmann; San Francisco; CA,2000,79
Initial results on wrapping semistructured web pages with finite-state transducers and contextual rules,Chun-Nan Hsu,Abstract This paper presents SoftMealy; a novel Web wrapper representation formalism.This representation is based on a finite-state transducer (FST) and contextual rules; whichallow a wrapper to wrap semistructured Web pages containing missing attributes; multipleattribute values; variant attribute permutations; exceptions and typos; the features that noprevious work can handle. A SoftMealy wrapper can be learned from labeled example itemsusing a simple induction algorithm. Learnability analysis shows that SoftMealy scales wellwith the number of attributes and the number of different attribute permutations.Experimental results show that the learning algorithm can learn correct wrappers for a widerange of Web pages with a handful of examples and generalize well over unseen pages andstructural patterns.,Proceedings of the AAAI Workshop on AI and Information Integration,1998,74
Finite-state transducers for semi-structured text mining,Chun-Nan Hsu; Chien-Chi Chang,Abstract Text mining for semi-structured documents requires information extractors.Programming extractors by hand is di cult to catch up with the amount and the variation ofthe documents placed on the World-Wide Web everyday. This paper presents our recentresult on applying machine learning techniques to automatize the generation of theextractors. Our goal is to develop a domain and language independent approach thatautomatically learns an extractor from training examples of extraction. In particular; thispaper discusses the use of nite-state transducers (FST) as the representation formalism ofthe extractors. Previously; we have shown that only a small number of examples is enoughfor learning perfect FST-based extractors for documents from a variety of real Web sites. Inthis paper; we introduce two classes of FST-based extractors: singlepass and multi-pass …,Proceedings of IJCAI-99 Workshop on Text Mining: Foundations; Techniques and Applications,1999,73
Semantic query optimization for query plans of heterogeneous multidatabase systems,Chun-Nan Hsu; Craig A Knoblock,New applications of information systems need to integrate a large number of heterogeneousdatabases over computer networks. Answering a query in these applications usuallyinvolves selecting relevant information sources and generating a query plan to combine thedata automatically. As significant progress has been made in source selection and plangeneration; the critical issue has been shifting to query optimization. This paper presents asemantic query optimization (SQO) approach to optimizing query plans of heterogeneousmultidatabase systems. This approach provides global optimization for query plans as wellas local optimization for subqueries that retrieve data from individual database sources. Animportant feature of our local optimization algorithm is that we prove necessary and sufficientconditions to eliminate an unnecessary join in a conjunctive query of arbitrary join …,IEEE Transactions on Knowledge and Data Engineering,2000,64
Discovery and characterization of medaka miRNA genes by next generation sequencing platform,Sung-Chou Li; Wen-Ching Chan; Meng-Ru Ho; Kuo-Wang Tsai; Ling-Yueh Hu; Chun-Hung Lai; Chun-Nan Hsu; Pung-Pung Hwang; Wen-chang Lin,MicroRNAs (miRNAs) are endogenous non-protein-coding RNA genes which exist in a widevariety of organisms; including animals; plants; virus and even unicellular organisms.Medaka (Oryzias latipes) is a useful model organism among vertebrate animals. However;no medaka miRNAs have been investigated systematically. It is beneficial to conduct agenome-wide miRNA discovery study using the next generation sequencing (NGS)technology; which has emerged as a powerful sequencing tool for high-throughput analysis.In this study; we adopted ABI SOLiD platform to generate small RNA sequence reads frommedaka tissues; followed by mapping these sequence reads back to medaka genome. Themapped genomic loci were considered as candidate miRNAs and further processed by asupport vector machine (SVM) classifier. As result; we identified 599 novel medaka pre …,BMC genomics,2010,62
Implications of the Dirichlet assumption for discretization of continuous variables in naive Bayesian classifiers,Chun-Nan Hsu; Hung-Ju Huang; Tzu-Tsung Wong,Abstract In a naive Bayesian classifier; discrete variables as well as discretized continuousvariables are assumed to have Dirichlet priors. This paper describes the implications andapplications of this model selection choice. We start by reviewing key properties of Dirichletdistributions. Among these properties; the most important one is “perfect aggregation;” whichallows us to explain why discretization works for a naive Bayesian classifier. Since perfectaggregation holds for Dirichlets; we can explain that in general; discretization canoutperform parameter estimation assuming a normal distribution. In addition; we can explainwhy a wide variety of well-known discretization methods; such as entropy-based; ten-bin;and bin-log l; can perform well with insignificant difference. We designed experiments toverify our explanation using synthesized and real data sets and showed that in addition to …,Machine Learning,2003,59
Mining skewed and sparse transaction data for personalized shopping recommendation,Chun-Nan Hsu; Hao-Hsiang Chung; Han-Shen Huang,Abstract A good shopping recommender system can boost sales in a retailer store. Toprovide accurate recommendation; the recommender needs to accurately predict acustomer's preference; an ability difficult to acquire. Conventional data mining techniques;such as association rule mining and collaborative filtering; can generally be applied to thisproblem; but rarely produce satisfying results due to the skewness and sparsity oftransaction data. In this paper; we report the lessons that we learned in two real-world datamining applications for personalized shopping recommendation. We learned that extendinga collaborative filtering method based on ratings (eg; GroupLens) to perform personalizedshopping recommendation is not trivial and that it is not appropriate to apply association-rulebased methods (eg; the IBM SmartPad system) for large scale prediction of customers' …,Machine Learning,2004,55
Automatic morphological subtyping reveals new roles of caspases in mitochondrial dynamics,Jyh-Ying Peng; Chung-Chih Lin; Yen-Jen Chen; Lung-Sen Kao; Young-Chau Liu; Chung-Chien Chou; Yi-Hung Huang; Fang-Rong Chang; Yang-Chang Wu; Yuh-Show Tsai; Chun-Nan Hsu,Morphological dynamics of mitochondria is associated with key cellular processes related toaging and neuronal degenerative diseases; but the lack of standard quantification ofmitochondrial morphology impedes systematic investigation. This paper presents anautomated system for the quantification and classification of mitochondrial morphology. Wediscovered six morphological subtypes of mitochondria for objective quantification ofmitochondrial morphology. These six subtypes are small globules; swollen globules; straighttubules; twisted tubules; branched tubules and loops. The subtyping was derived byapplying consensus clustering to a huge collection of more than 200 thousand mitochondrialimages extracted from 1422 micrographs of Chinese hamster ovary (CHO) cells treated withdifferent drugs; and was validated by evidence of functional similarity reported in the …,PLoS computational biology,2011,53
Identification of homologous microRNAs in 56 animal genomes,Sung-Chou Li; Wen-Ching Chan; Ling-Yueh Hu; Chun-Hung Lai; Chun-Nan Hsu; Wen-chang Lin,MicroRNAs (miRNAs) are endogenous non-protein-coding RNAs of approximately 22nucleotides. Thousands of miRNA genes have been identified (computationally and/orexperimentally) in a variety of organisms; which suggests that miRNA genes have beenwidely shared and distributed among species. Here; we used unique miRNA sequencepatterns to scan the genome sequences of 56 bilaterian animal species for locatingcandidate miRNAs first. The regions centered surrounding these candidate miRNAs werethen extracted for folding and calculating the features of their secondary structure. Using asupport vector machine (SVM) as a classifier combined with these features; we identified anadditional 13;091 orthologous or paralogous candidate pre-miRNAs; as well as theircorresponding candidate mature miRNAs. Stem-loop RT-PCR and deep sequencing …,Genomics,2010,51
Detection of the inferred interaction network in hepatocellular carcinoma from EHCO (E ncyclopedia of H epatocellular C arcinoma genes O nline),Chun-Nan Hsu; Jin-Mei Lai; Chia-Hung Liu; Huei-Hun Tseng; Chih-Yun Lin; Kuan-Ting Lin; Hsu-Hua Yeh; Ting-Yi Sung; Wen-Lian Hsu; Li-Jen Su; Sheng-An Lee; Chang-Han Chen; Gen-Cher Lee; DT Lee; Yow-Ling Shiue; Chang-Wei Yeh; Chao-Hui Chang; Cheng-Yan Kao; Chi-Ying F Huang,The significant advances in microarray and proteomics analyses have resulted in anexponential increase in potential new targets and have promised to shed light on theidentification of disease markers and cellular pathways. We aim to collect and decipher theHCC-related genes at the systems level. Here; we build an integrative platform; the Encyclopedia of H epatocellular C arcinoma genes O nline; dubbed EHCO http://ehco. iis.sinica. edu. tw; to systematically collect; organize and compare the pileup of unsorted HCC-related studies by using natural language processing and softbots. Among the eight geneset collections; ranging across PubMed; SAGE; microarray; and proteomics data; there are2;906 genes in total; however; more than 77% genes are only included once; suggestingthat tremendous efforts need to be exerted to characterize the relationship between HCC …,BMC bioinformatics,2007,51
Speech recognition on code-switching among the Chinese dialects,Dau-Cheng Lyu; Ren-Yuan Lyu; Yuang-chin Chiang; Chun-Nan Hsu,We propose an integrated approach to do automatic speech recognition on code-switchingutterances; where speakers switch back and forth between at least 2 languages. This one-pass framework avoids the degradation of accuracy due to the imperfectly intermediatedecisions of language detection and language identification. It is based on a three-layerrecognition scheme; which consists of a mixed-language HMM-based acoustic model; aknowledge-based plus data-driven probabilistic pronunciation model; and a tree-structuredsearching net. The traditional multi-pass recognizer including language boundary detection;language identification and language-dependent speech recognition is also implementedfor comparison. Experimental results show that the proposed approach; with a much simplerrecognition scheme; could achieve as high accuracy as that could be achieved by using …,Acoustics; Speech and Signal Processing; 2006. ICASSP 2006 Proceedings. 2006 IEEE International Conference on,2006,51
Bayesian classification for data from the same unknown class,Hung-Ju Huang; Chun-Nan Hsu,In this paper; we address the problem of how to classify a set of query vectors that belong tothe same unknown class. Sets of data known to be sampled from the same class arenaturally available in many application domains; such as speaker recognition. We refer tothese sets as homologous sets. We show how to take advantage of homologous sets inclassification to obtain improved accuracy over classifying each query vector individually.Our method; called homologous naive Bayes (HNB); is based on the naive Bayes classifier;a simple algorithm shown to be effective in many application domains. RNB uses a modifiedclassification procedure that classifies multiple instances as a single unit. Compared with avoting method and several other variants of naive Bayes classification; HNB significantlyoutperforms these methods in a variety of test data sets; even when the number of query …,IEEE Transactions on Systems; Man; and Cybernetics; Part B (Cybernetics),2002,48
Using Inductive Learning to Generate Rules for Semantic Query Optimization.,Chun-Nan Hsu; Craig A Knoblock,Abstract: Semantic query optimization can dramatically speed up database query answeringby knowledge intensive reformulation. But the problem of how to learn the required semanticrules has not been previously solved. This report presents a learning approach to solvingthis problem. In our approach; the learning is triggered by user queries. Then the systemuses an inductive learning algorithm to generate semantic rules. This inductive learningalgorithm can automatically select useful join paths and attributes to construct rules from adatabase with many relations. The learned semantic rules are effective for optimizationbecause they will match query patterns and reflect data regularities. Experimental resultsshow that this approach learns sufficient rules for optimization that produces a substantialcost reduction. Descriptors:* OPTIMIZATION;* SEMANTICS;* INTERROGATION; DATA …,*,1995,48
Induction of integrated view for XML data with heterogeneous DTDs,Euna Jeong; Chun-Nan Hsu,Abstract This paper proposes a novel approach to integrating heterogeneous XML DTDs.With this approach; an information agent can be easily extended to integrate heterogeneousXML-based contents and perform federated search. Based on a tree grammar inferencetechnique; this approach derives an integrated view of XML DTDs in an informationintegration framework. The derivation takes advantages of naming and structural similaritiesamong DTDs in similar domains. The complete approach consists of three main steps.(1)DTD clustering clusters DTDs in similar domains into classes.(2) Schema learning applies atree grammar inference technique to generate a set of tree grammar rules from the DTDs ina class from the previous step.(3) Minimization optimizes the rules generated in the previousstep and transforms them into an integrated view. We have implemented the proposed …,Proceedings of the tenth international conference on Information and knowledge management,2001,43
Rich feature set; unification of bidirectional parsing and dictionary filtering for high F-score gene mention tagging,Cheng-Ju Kuo; Yu-Ming Chang; Han-Shen Huang; Kuan-Ting Lin; Bo-Hou Yang; Yu-Shi Lin; Chun-Nan Hsu; I-Fang Chung,In the first BioCreative (2004)[3]; conditional random fields (CRFs)[5] were employed intagging gene and protein mentioned in the biomedical text with high performance [8].Therefore; we chose CRFs as our starting point and carefully selected a rich set of 5;059;368predicates as the features. To further improve its performance; we combined the taggingresults of forward and backward parsing [4]. We tried different combination methods;including set operations and Co-Training [1]. However; we found that Co-Training performedpoorly. Instead; we selected the best solutions from the “adjacent” ten candidates ofbidirectional parsing and then applied dictionary filtering to obtain the best F-score result.Details are given as follows. We applied MALLET [7] to take advantage of its featureinduction capability [6]. Due to the special characteristics of name-entities of genes and …,Proceedings of the second BioCreative challenge evaluation workshop,2007,42
BIOADI: a machine learning approach to identifying abbreviations and definitions in biological literature,Cheng-Ju Kuo; Maurice HT Ling; Kuan-Ting Lin; Chun-Nan Hsu,To automatically process large quantities of biological literature for knowledge discoveryand information curation; text mining tools are becoming essential. Abbreviation recognitionis related to NER and can be considered as a pair recognition task of a terminology and itscorresponding abbreviation from free text. The successful identification of abbreviation andits corresponding definition is not only a prerequisite to index terms of text databases toproduce articles of related interests; but also a building block to improve existing genemention tagging and gene normalization tools. Our approach to abbreviation recognition(AR) is based on machine-learning; which exploits a novel set of rich features to learn rulesfrom training data. Tested on the AB3P corpus; our system demonstrated a F-score of89.90% with 95.86% precision at 84.64% recall; higher than the result achieved by the …,BMC bioinformatics,2009,41
Reformulating query plans for multidatabase systems,Chun-Nan Hsu; Craig A Knoblock,Abstract A practical heterogeneous; distributed multidatabase system must answer queriesefficiently. Conventional query optimization techniques are not adequate here becausethese techniques are dependent on the database structure; and rely on limited informationwhich is not sufficient in complicated multidat abase queries. This paper presents anautomated approach to reformulating query plans to improve the efficiency of multidatabasequeries. This approach uses database abstractions; the knowledge about the contents ofdatabases; to reformulate a query plan into less expensive but semantically equivalent one.We present two algorithms. The first algorithm reformulates sub queries to individualdatabases; the second algorithm extends the first one and reformulates the entire queryplan. Empirical results show that the reformulations can provide significant savings with …,Proceedings of the second international conference on Information and knowledge management,1993,38
Rule induction for semantic query optimization,Chun-Nan Hsu; Craig A Knoblock,Abstract Semantic query optimization can dramatically speed up database query answeringby knowledge intensive reformulation. But the problem of how to learn required semanticrules has not previously been solved. This paper describes an approach using an inductivelearning algorithm to solve the problem. In our approach; learning is triggered by userqueries and then the system induces semantic rules from the information in databases. Theinductive learning algorithm used in this approach can select an appropriate set of relevantattributes from a potentially huge number of attributes in real-world databases. Experimentalresults demonstrate that this approach can learn sufficient background knowledge toreformulate queries and provide a 57 percent average performance improvement.,*,1994,37
Gene expression-based chemical genomics identifies potential therapeutic drugs in hepatocellular carcinoma,Ming-Huang Chen; Wu-Lung R Yang; Kuan-Ting Lin; Chia-Hung Liu; Yu-Wen Liu; Kai-Wen Huang; Peter Mu-Hsin Chang; Jin-Mei Lai; Chun-Nan Hsu; Kun-Mao Chao; Cheng-Yan Kao; Chi-Ying F Huang,Hepatocellular carcinoma (HCC) is an aggressive tumor with a poor prognosis. Currently;only sorafenib is approved by the FDA for advanced HCC treatment; therefore; there is anurgent need to discover candidate therapeutic drugs for HCC. We hypothesized that if a drugsignature could reverse; at least in part; the gene expression signature of HCC; it might havethe potential to inhibit HCC-related pathways and thereby treat HCC. To test this hypothesis;we first built an integrative platform; the “Encyclopedia of Hepatocellular Carcinoma genesOnline 2”; dubbed EHCO2; to systematically collect; organize and compare the publiclyavailable data from HCC studies. The resulting collection includes a total of 4;020 genes. Tosystematically query the Connectivity Map (CMap); which includes 6;100 drug-mediatedexpression profiles; we further designed various gene signature selection and enrichment …,PloS one,2011,29
Boosting multiclass learning with repeating codes and weak detectors for protein subcellular localization,Chung-Chih Lin; Yuh-Show Tsai; Yu-Shi Lin; Tai-Yu Chiu; Chia-Cheng Hsiung; May-I Lee; Jeremy C Simpson; Chun-Nan Hsu,Abstract Motivation: Determining locations of protein expression is essential to understandprotein function. Advances in green fluorescence protein (GFP) fusion proteins andautomated fluorescence microscopy allow for rapid acquisition of large collections of proteinlocalization images. Recognition of these cell images requires an automated image analysissystem. Approaches taken by previous work concentrated on designing a set of optimalfeatures and then applying standard machine-learning algorithms. In fact; trends of recentadvances in machine learning and computer vision can be applied to improve theperformance. One trend is the advances in multiclass learning with error-correcting outputcodes (ECOC). Another trend is the use of a large number of weak detectors with boostingfor detecting objects in images of real-world scenes. Results: We take advantage of these …,Bioinformatics,2007,29
High-recall gene mention recognition by unification of multiple backward parsing models,Han-Shen Huang; Yu-Shi Lin; Kuan-Ting Lin; Cheng-Ju Kuo; Yu-Ming Chang; Bo-Hou Yang; I-Fang Chung; Chun-Nan Hsu,We considered the gene mention tagging task as a classification problem and appliedsupport vector machines (SVM) to solve it. We selected a large set of features as the inputand trained two SVM models with different multiclass extension methods. We found thatbackward parsing constantly outperformed forward parsing regardless of the multiclassextension methods and obtained high precision rates; but recall rates were not assatisfactory. To enhance recall rates; our approach is to construct divergent but highperformance models to cover different aspects of the feature space; and then combine theminto an ensemble. We applied union and intersection to combine the outputs of SVM modelswith that of a CRF model; which was trained with the same feature set; and successfullyenhanced recall rates without degrading too much precision.,Proceedings of the second BioCreative challenge evaluation workshop,2007,29
Wrapping semistructured web pages with finite-state transducers,Chun-Nan Hsu; Ming-Tzung Dung,Page 1. Page 1 Wrapping Semistructured Web Pages with Finite-State TransducersChun-Nan Hsu and Ming-Tzung Dung Department of Computer Science & EngineeringArizona State University Tempe; AZ; USA 2 Information Integration Systems need wrappersUnprocessed; Unintegrated Details Text; Images/Video; Spreadsheets Hierarchical & NetworkDatabases Relational Databases Object & Knowledge Bases SQL ORB Wrapper WrapperMediator Mediator Human & Computer Users Heterogeneous Data Sources InformationIntegration Service Translation and Wrapping Semantic Integration Mediation AbstractedInformation Mediator User Services: •Query •Monitor •Update Agent/Module Coordination3 Web wrappers ∎ Web wrappers wrap... ? `Query-able''or ``Search-able''Web sites ? Webpages with large itemized lists ∎ The primary issues are …,Proceedings of the Conference on Automated Learning and Discovery,1998,24
MetaMirClust: discovery of miRNA cluster patterns using a data-mining approach,Wen-Ching Chan; Meng-Ru Ho; Sung-Chou Li; Kuo-Wang Tsai; Chun-Hung Lai; Chun-Nan Hsu; Wen-chang Lin,Recent genome-wide surveys on ncRNA have revealed that a substantial fraction of miRNAgenes is likely to form clusters. However; the evolutionary and biological functionimplications of clustered miRNAs are still elusive. After identifying clustered miRNA genesunder different maximum inter-miRNA distances (MIDs); this study intended to revealevolution conservation patterns among these clustered miRNA genes in metazoan speciesusing a computation algorithm. As examples; a total of 15–35% of known and predictedmiRNA genes in nine selected species constitute clusters under the MIDs ranging from 1kbto 50kb. Intriguingly; 33 out of 37 metazoan miRNA clusters in 56 metazoan genomes are co-conserved with their up/down-stream adjacent protein-coding genes. Meanwhile; a co-expression pattern of miR-1 and miR-133a in the mir-133-1 cluster has been …,Genomics,2012,23
Time-aware ranking in dynamic citation networks,Rumi Ghosh; Tsung-Ting Kuo; Chun-Nan Hsu; Shou-De Lin; Kristina Lerman,Many algorithms have been developed to identify important nodes in a complex network;including various centrality metrics and Page Rank; but most fail to consider the dynamicnature of the network. They therefore suffer from recency bias and fail to recognize importantnew nodes that have not had as much time to accumulate links as their older counterparts.This paper describes the Effective Contagion Matrix (ECM); a solution to address recencybias in the analysis of dynamic complex networks. The idea of ECM is to explicitly considerthe temporal order of links and chains of links connecting to a node with some temporaldecay factors. We tested ECM with three large real world citation networks on the task ofpredicting papers' future importance. We compared ECM's performance with two staticmetrics; degree-centrality and Page Rank; and two time-aware metrics; age-based Page …,Data Mining Workshops (ICDMW); 2011 IEEE 11th International Conference on,2011,23
Clustering of change patterns using Fourier coefficients,Jaehee Kim; Haseong Kim,Abstract Motivation: To understand the behavior of genes; it is important to explore how thepatterns of gene expression change over a time period because biologically related genegroups can share the same change patterns. Many clustering algorithms have beenproposed to group observation data. However; because of the complexity of the underlyingfunctions there have not been many studies on grouping data based on change patterns. Inthis study; the problem of finding similar change patterns is induced to clustering with thederivative Fourier coefficients. The sample Fourier coefficients not only provide informationabout the underlying functions; but also reduce the dimension. In addition; as their limitingdistribution is a multivariate normal; a model-based clustering method incorporatingstatistical properties would be appropriate. Results: This work is aimed at discovering …,Bioinformatics,2007,22
Interrogation of rabbit miRNAs and their isomiRs,Sung-Chou Li; Yu-Lun Liao; Wen-Ching Chan; Meng-Ru Ho; Kuo-Wang Tsai; Ling-Yueh Hu; Chun-Hung Lai; Chun-Nan Hsu; Wen-chang Lin,Rabbit (Oryctolagus cuniculus) is the only lagomorph animal of which the genome has beensequenced. Establishing a rabbit miRNA resource will benefit subsequent functionalgenomic studies in mammals. We have generated small RNA sequence reads with SOLiDand Solexa platforms to identify rabbit miRNAs; where we identified 464 pre-miRNAs and886 mature miRNAs. The brain and heart miRNA libraries were used for further in-depthanalysis of isomiR distributions. There are several intriguing findings. First; several rabbit pre-miRNAs form highly conserved clusters. Second; there is a preference in selecting onestrand as mature miRNA; resulting in an arm selection preference. Third; we analyzed theisomiR expression and validated the expression of isomiR types in different rabbit tissues.Moreover; we further performed additional small RNA libraries and defined miRNAs …,Genomics,2011,21
Fusion of systems for automated cell phenotype image classification,Loris Nanni; Alessandra Lumini; Yu-Shi Lin; Chun-Nan Hsu; Chung-Chih Lin,Abstract Automated cell phenotype image classification is related to the problem ofdetermining locations of protein expression within living cells. Localization of proteins incells is directly related to their functions and it is crucial for several applications ranging fromearly diagnosis of a disease to monitoring of therapeutic effectiveness of drugs. Recentadvances in imaging instruments and biological reagents have allowed fluorescencemicroscopy to be extensively used as a tool to understand biology at the cellular level bymeans of the visualization of biological activity within cells. However; human classification offluorescence cell micrographs is still subjective and very time consuming; thus an automatedapproach for the systematic determination of protein subcellular locations from fluorescencemicroscopy images is required. Existing approaches concentrated on designing a set of …,Expert Systems with Applications,2010,21
Discovering robust knowledge from databases that change,Chun-Nan Hsu; Craig A Knoblock,Abstract Many applications of knowledge discovery and data mining such as rule discoveryfor semantic query optimization; database integration and decision support; require theknowledge to be consistent with the data. However; databases usually change over timeand make machine-discovered knowledge inconsistent. Useful knowledge should be robustagainst database changes so that it is unlikely to become inconsistent after databaseupdates. This paper defines this notion of robustness in the context of relational databasesand describes how robustness of first-order Horn-clause rules can be estimated.Experimental results show that our estimation approach can accurately identify robust rules.We also present a rule antecedent pruning algorithm that improves the robustness andapplicability of machine discovered rules to demonstrate the usefulness of robustness …,Data Mining and Knowledge Discovery,1998,20
Cation-exchange properties of soil organic matter: I. Effects of conditions for the measurement on cation-exchange capacity values of humic acid preparations,Yasuo Harada; Akio Inoko,Abstract The CEC was determined for humic acid preparations by changing the conditionsfor the CEC procedure and the CEC values obtained were compared with those of clayminerals. Humic acid was extracted from Kodonbaru and Kuriyagawa surface soils;Iwanuma peat; and straw with 0.1 M Na4P2O7-0. l M NaOH. The CEC was measured by amethod which eliminates washing for the removal of excess saturating salt. The CEC ofhumic acid became larger as humification progressed; and increased in the order: Straw<Iwanuma< Kuriyagawa< Kodonbaru. An equilibrium of cation exchange for the humic acidpreparations was attained in a short time in contrast with that for allophane. No effect of saltconcentration on the CEC of the humic acid preparations was recognized. The CEC ofhumic acid was also determine using the procedure in which tbe excess salt was …,Soil science and plant nutrition,1975,20
Analysis of protein-protein interactions in cross-talk pathways reveals CRKL protein as a novel prognostic marker in hepatocellular carcinoma,Chia-Hung Liu; Tzu-Chi Chen; Gar-Yang Chau; Yi-Hua Jan; Chun-Houh Chen; Chun-Nan Hsu; Kuan-Ting Lin; Yue-Li Juang; Pei-Jung Lu; Hui-Chuan Cheng; Ming-Huang Chen; Chia-Fen Chang; Yu-Shan Ting; Cheng-Yan Kao; Michael Hsiao; Chi-Ying F Huang,Abstract Deciphering the network of signaling pathways in cancer via protein-proteininteractions (PPIs) at the cellular level is a promising approach but remains incomplete. Weused an in situ proximity ligation assay to identify and quantify 67 endogenous PPIs among21 interlinked pathways in two hepatocellular carcinoma (HCC) cells; Huh7 (minimallymigratory cells) and Mahlavu (highly migratory cells). We then applied a differential networkbiology analysis and determined that the novel interaction; CRKL-FLT1; has a high centralityranking; and the expression of this interaction is strongly correlated with the migratory abilityof HCC and other cancer cell lines. Knockdown of CRKL and FLT1 in HCC cells leads to adecrease in cell migration via ERK signaling and the epithelial-mesenchymal transitionprocess. Our immunohistochemical analysis shows high expression levels of the CRKL …,Molecular & Cellular Proteomics,2013,19
Estimating the robustness of discovered knowledge,Chun-Nan Hsu; Craig A Knoblock,Abstract This paper introduces a new measurement; robustness; to measure the quality ofmachine-discovered knowledge from real-world databases that change over time. A piece ofknowledge is robust if it is unlikely to become inconsistent with new database states.Robustness is different from predictive accuracy in that by the latter; the system considersonly the consistency of a rule with unseen data; while by the former; the consistency afterdeletions and updates of existing data is also considered. Combining robustness with otherutility measurements; a system can make intelligent decisions in learning and maintenanceof knowledge learned from changing databases. This paper defines robustness; thenpresents an estimation approach for the robustness of Horn-clause rules learned from arelational database. The estimation approach applies the Laplace law of succession …,KDD,1995,19
Query processing in an information mediator,Yigal Arens; Chin Chee; Chun-Nan Hsu; Hoh In; Craig A Knoblock,Abstract A critical problem in building an information mediator is how to translate a domain-level queries into an efficient query plan for accessing the required data. We have built aflexible and efficient information mediator; called SIMS. SIMS takes a domain-level queryand dynamically selects the appropriate information sources based on their content andavailability; generates a query access plan that; specifies the operations and their order forprocessing the data; and then performs semantic query reformulation to minimize the overallexecution time. This paper describes these three basic components of the query processingin SIMS.,Knowledge-Based Planning and Scheduling Initiative: Workshop Proceedings: Tucson; Arizona; February 21-24; 1994,1994,18
Learning database abstractions for query reformulation,Chun-Nan Hsu; Craig A Knoblock,*,*,1993,18
Triple jump acceleration for the EM algorithm,Han-Shen Huang; Bou-Ho Yang; Chun-Nan Hsu,This paper presents the triple jump framework for accelerating the EM algorithm and otherbound optimization methods. The idea is to extrapolate the third search point based on theprevious two search points found by regular EM. As the convergence rate of regular EMbecomes slower; the distance of the triple jump is longer; and thus provide higher speedupfor data sets where EM converges slowly. Experimental results show that the triple jumpframework significantly outperforms EM and other acceleration methods of EM for a varietyof probabilistic models; especially when the data set is sparse. The results also show thatthe triple jump framework is particularly effective for cluster models.,Data Mining; Fifth IEEE International Conference on,2005,16
Periodic step-size adaptation in second-order gradient descent for single-pass on-line structured learning,Chun-Nan Hsu; Han-Shen Huang; Yu-Ming Chang; Yuh-Jye Lee,Abstract It has been established that the second-order stochastic gradient descent (SGD)method can potentially achieve generalization performance as well as empirical optimum ina single pass through the training examples. However; second-order SGD requirescomputing the inverse of the Hessian matrix of the loss function; which is prohibitivelyexpensive for structured prediction problems that usually involve a very high dimensionalfeature space. This paper presents a new second-order SGD method; called Periodic Step-size Adaptation (PSA). PSA approximates the Jacobian matrix of the mapping function andexplores a linear relation between the Jacobian and Hessian to approximate the Hessian;which is proved to be simpler and more effective than directly approximating Hessian in anon-line setting. We tested PSA on a wide variety of models and tasks; including large …,Machine learning,2009,15
Reconfigurable Web wrapper agents,Chia-Hui Chang; Harianto Siek; Jiann-Jyh Lu; Chun-Nan Hsu; Jen-Jie Chiou,Page 1. 34 1094-7167/03/$17.00 © 2003 IEEE IEEE INTELLIGENT SYSTEMS Published bythe IEEE Computer Society I nformation I ntegration Reconfigurable Web Wrapper AgentsChia-Hui Chang; National Central University; Taiwan Harianto Siek; Jiann-Jyh Lu; andChun-Nan Hsu; Institute of Information Science; Taiwan Jen-Jie Chiou; Deepspot IntelligentSystems; Taiwan Web information integration differs from database information integrationbecause of the Web's nature; where data is in interlinked; heterogeneous Web pages ratherthan tables or objects with a clearly defined schema. Building wrappers for relational databasesis relatively easy because the defined structure lets other programs directly access the data.Web wrappers; however; must automate Web browsing sessions to extract data from the targetWeb pages so other applications can process that data …,IEEE Intelligent Systems,2003,15
Speaker independent acoustic modeling for large vocabulary bi-lingual Taiwanese/Mandarin continuous speech recognition,Dau-Cheng Lyu; Bo-hou Yang; Min-Siong Liang; Ren-Yuan Lyu; Chun-Nan Hsu,ABSTRACT: In this paper; we describe the acoustic modelling technique for a bi-lingualTaiwanese/Mandarin speech recognition system; which deals with speaker independentcontinuous speech based on HMMs clustered by an acoustic phonetic decision tree. A bi-lingual recogniser with a bilingual database of 120 people was built. The vocabulary size ofthis system is up to 40 thousands. Unigram; bi-gram; and tree lexicon language modelshave been used. In order to share the common part of the two languages; a decision-treebased clustering is adopted in inter-syllable triphone units. A 89.8% word accuracy isachieved by searching on a tree lexicon net under a context free grammar.,Proc. SST,2002,15
Citing a data repository: a case study of the protein data bank,Yi-Hung Huang; Peter W Rose; Chun-Nan Hsu,The Protein Data Bank (PDB) is the worldwide repository of 3D structures of proteins; nucleicacids and complex assemblies. The PDB's large corpus of data (> 100;000 structures) andrelated citations provide a well-organized and extensive test set for developing andunderstanding data citation and access metrics. In this paper; we present a systematicinvestigation of how authors cite PDB as a data repository. We describe a novel metricbased on information cascade constructed by exploring the citation network to measureinfluence between competing works and apply that to analyze different data citationpractices to PDB. Based on this new metric; we found that the original publication of RCSBPDB in the year 2000 continues to attract most citations though many follow-up updateswere published. None of these follow-up publications by members of the wwPDB …,PloS one,2015,14
Speaker verification without background speaker models,Chun-Nan Hsu; Hau-Chung Yu; Bo-Hou Yang,Speaker verification concerns the problem of verifying whether a given utterance has beenpronounced by a claimed authorized speaker. This problem is important because anaccurate speaker verification system can be applied to many security applications. Wepresent a new algorithm for speaker verification called OSCILLO. By applying toleranceinterval analysis in statistics; OSCILLO can verify a speaker's ID without background speakermodels. This greatly reduces the space requirement of the system and the time for bothtraining and verification. Experimental results show that OSCILLO can achieve error ratescomparable or better than the GMM-based system with background speaker models forthree benchmark databases: TCC-300; TIMIT and NIST 2000.,Acoustics; Speech; and Signal Processing; 2003. Proceedings.(ICASSP'03). 2003 IEEE International Conference on,2003,14
From NPC therapeutic target identification to potential treatment strategy,Ming-Ying Lan; Chi-Long Chen; Kuan-Ting Lin; Sheng-An Lee; Wu-Lung R Yang; Chun-Nan Hsu; Jaw-Ching Wu; Ching-Yin Ho; Jin-Ching Lin; Chi-Ying F Huang,Nasopharyngeal carcinoma (NPC) is relatively rare in Western countries but is a commoncancer in southern Asia. Many differentially expressed genes have been linked to NPC;however; how to prioritize therapeutic targets and potential drugs from unsorted gene listsremains largely unknown. We first collected 558 upregulated and 993 downregulated NPCgenes from published microarray data and the primary literatures. We then postulated thatconversion of gene signatures into the protein-protein interaction network and analyzing thenetwork topologically could provide insight into key regulators involved in tumorigenesis ofNPC. Of particular interest was the presence of cliques; called fully connected subgraphs; inthe inferred NPC networks. These clique-based hubs; connecting with more than threequeries and ranked higher than other nodes in the NPC protein-protein interaction …,Molecular cancer therapeutics,2010,13
Large Vocabulary Taiwanese (Min-nan) Speech Recognition Using Tone Features and Statistical Pronunciation Modeling,Dau-Cheng Lyu; Min-Siong Liang; Yuang-Chin Chiang; Chun-Nan Hsu; Ren-Yuan Lyu,Abstract A large vocabulary Taiwanese (Min-nan) speech recognition system is described inthis paper. Due to the severe multiple pronunciation phenomenon in Taiwanese partlycaused by tone sandhi; a statistical pronunciation modeling technique based on tonalfeatures is used. This system is speaker independent. It was trained by a bi-lingualMandarin/Taiwanese speech corpus to alleviate the lack of pure Taiwanese speech corpus.The searching network is constructed based on nodes of Chinese characters and results inthe direct output Chinese character string. Experiments show that by using the approachesproposed in this paper; the character error rate can decrease significantly from 21.50% to11.97%.,Eighth European Conference on Speech Communication and Technology,2003,13
A spectral graph theoretic approach to quantification and calibration of collective morphological differences in cell images,Yu-Shi Lin; Chung-Chih Lin; Yuh-Show Tsai; Tien-Chuan Ku; Yi-Hung Huang; Chun-Nan Hsu,Abstract Motivation: High-throughput image-based assay technologies can rapidly producea large number of cell images for drug screening; but data analysis is still a major bottleneckthat limits their utility. Quantifying a wide variety of morphological differences observed incell images under different drug influences is still a challenging task because the result canbe highly sensitive to sampling and noise. Results: We propose a graph-based approach tocell image analysis. We define graph transition energy to quantify morphological differencesbetween image sets. A spectral graph theoretic regularization is applied to transform thefeature space based on training examples of extremely different images to calibrate thequantification. Calibration is essential for a practical quantification method because we needto measure the confidence of the quantification. We applied our method to quantify the …,Bioinformatics,2010,12
A recommender for targeted advertisement of unsought products in e-commerce,Koung-Lung Lin; JY-J Hsu; Han-Shen Huang; Chun-Nan Hsu,Recommender systems are a powerful tool for promoting sales in electronic commerce. Aneffective shopping recommender system can help boost the retailer's sales by remindingcustomers to purchase additional products originally not on their shopping lists. Existingrecommender systems are designed to identify the top selling items; also called hot sellers;based on the store's sales data and customer purchase behaviors. It turns out that timelyreminders for unsought products; which are cold sellers that the consumer either does notknow about or does not normally think of buying; present great opportunities for significantsales growth. In this paper; we propose the framework and process of a recommendersystem that identifies potential customers of unsought products using boosting-SVM. Theempirical results show that the proposed approach provides a promising solution to …,E-Commerce Technology; 2005. CEC 2005. Seventh IEEE International Conference on,2005,12
Automatic extraction of information blocks using pat trees,Chia-Hui Chang; Chun-Nan Hsu,Abstract: Information extraction from semi-structured Web documents is a critical issue forsoftware agents on the Internet. Previous work in wrapper induction aim to solve thisproblem by applying machine learning to automatically generate extractors; but thisapproach still requires human intervention to provide training examples. In this paper; wepresent a novel approach that extracts information blocks without training examples using adata structure called a PAT tree. PAT trees allow the system to efficiently recognize repeatedpatterns in a semi-structured Web page. From these repeated patterns; information blockscan be easily located based on some domain independent selection criteria. The entiresystem runs automatically without any human intervention. Experimental results show thatour approach performs well with a recall rate near 90 percent on a wide range of output …,Proceedings of 1999 National Computer Symposium (NCS-1999),1999,12
A weight analysis-based wrapper approach to neural nets feature subset selection,Dietrich Schuschel; Chun-Nan Hsu,This paper presents a novel attribute selection approach for backprop neural networks.Previously; an attribute selection technique known as the wrapper model was showneffective for decision tree induction. However; it is prohibitively expensive when applied toreal-world neural net training characterized by large volumes of data and many attributechoices. Our approach incorporates a weight analysis based heuristic called ANNIGMA todirect the search in the wrapper model and allows effective attribute selection feasible forneural net applications. Experimental results on standard data sets show that this approachcan efficiently reduce the number of inputs while maintaining or even improving theaccuracy. We also report two successful applications of our approach in the helicoptermaintenance applications.,Tools with Artificial Intelligence; 1998. Proceedings. Tenth IEEE International Conference on,1998,12
Building the scientific knowledge mine (SciKnowMine): a community-driven framework for text mining tools in direct service to biocuration,Cartic Ramakrishnan; William A Baumgartner Jr; Judith A Blake; Gully APC Burns; K Bretonnel Cohen; Harold Drabkin; Janan Eppig; Eduard Hovy; Chun-Nan Hsu; Lawrence E Hunter; Tommy Ingulfsen; Sandeep Pokkunuri Hiroaki'Rocky'Onda; Ellen Riloff; Christophe Roeder; Karin Verspoor,Abstract Although there exist many high-performing text-mining tools to address literaturebiocuration (populating biomedical databases from the published literature); the challengeof delivering effective computational support for curation of large-scale biomedicaldatabases is still unsolved. We describe a community-driven solution (the SciKnowMineProject) implemented using the Unstructured Information Management Architecture (UIMA)framework. This system's design is intended to provide knowledge engineeringenhancement of pre-existing biocuration systems by providing a large-scale text-processingpipeline bringing together multiple Natural Language Processing (NLP) toolsets for usewithin well-defined biocuration tasks. By working closely with biocurators at the MouseGenome Informatics2 (MGI) group at The Jackson Laboratory in the context of their …,Language Resources and Evaluation,2010,11
Reconfigurable web wrapper agents for web information integration.,Chun-Nan Hsu; Chia-Hui Chang; Harianto Siek; Jiann-Jyh Lu; Jen-Jie Chiou,Abstract This paper provides a solution for rapidly building software agents that can serve asWeb wrappers for biological information integration. We define an XML-based languagecalled WNDL; which provides a representation of a Web browsing session. A WNDL scriptdescribes how to locate the data; extract the data and combine the data. By executingdifferent WNDL scripts; user can automate virtually all types of Web browsing sessions. Wealso describe IEPAD; a data extractor based on pattern discovery techniques. IEPAD allowsour software agents to automatically discover the extraction rules to extract the contents of astructurally formatted Web page without the need to label a Web page to train a wrapper.With a programmingby-example authoring tool; a user can generate a complete Webwrapper agent by browsing the target Web sites. We have built a variety of applications to …,IIWeb,2003,11
Query Answering Using Ontologies in Agent-based Resource Sharing Environment for Biological Web Information Integrating.,Jiann-Jyh Lu; Chun-Nan Hsu,Abstract A variety of biological data is transferred and exchanged in overwhelming volumeson the World Wide Web. How to rapidly capture; utilize and integrate hundreds of biologicaldatabases on the Web is one of the most critical issues in bioinformatics. In this paper; wedescribe our preliminary study to address this issue in an agent-based resource-sharingenvironment; where we apply the Web agent technology and DAML+ OIL ontologies ofbiological knowledge to enable biologists to make concept-to-concept query. Given a query;the agent coordination service in this environment will search for a set of suitable paths inthe ontologies that links the query concept to the goal concept. The Web agents will belaunched to extract the data from the target Web resources and transfer the data accordingto the found path to answer the query. This approach makes the details of querying Web …,IIWeb,2003,11
PombeX: robust cell segmentation for fission yeast transillumination images,Jyh-Ying Peng; Yen-Jen Chen; Marc D Green; Sarah A Sabatinos; Susan L Forsburg; Chun-Nan Hsu,Schizosaccharomyces pombe shares many genes and proteins with humans and is a goodmodel for chromosome behavior and DNA dynamics; which can be analyzed by visualizingthe behavior of fluorescently tagged proteins in vivo. Performing a genome-wide screen forchanges in such proteins requires developing methods that automate analysis of a largeamount of images; the first step of which requires robust segmentation of the cell. Wedeveloped a segmentation system; PombeX; that can segment cells from transmittedillumination images with focus gradient and varying contrast. Corrections for focus gradientare applied to the image to aid in accurate detection of cell membrane and cytoplasm pixels;which is used to generate initial contours for cells. Gradient vector flow snake evolution isused to obtain the final cell contours. Finally; a machine learning-based validation of cell …,PloS one,2013,10
Sequence features involved in the mechanism of 3'splice junction wobbling,Kuo-Wang Tsai; Wen-Ching Chan; Chun-Nan Hsu; Wen-chang Lin,Alternative splicing is an important mechanism mediating the diversified functions of genesin multicellular organisms; and such event occurs in around 40-60% of human genes.Recently; a new splice-junction wobbling mechanism was proposed that subtlemodifications exist in mRNA maturation by alternatively choosing at 5'-GTNGT and 3'-NAGNAG; which created single amino acid insertion and deletion isoforms. By browsing theAlternative Splicing Database information; we observed that most 3'alternative splice sitechoices occur within six nucleotides of the dominant splice site and the incidencesignificantly decreases further away from the dominant acceptor site. Although a lowerfrequency of alternative splicing occurs within the intronic region (alternative splicing at theproximal AG) than in the exonic region (alternative splicing at the distal AG); alternative …,BMC molecular biology,2010,10
Learning to predict expression efficacy of vectors in recombinant protein production,Wen-Ching Chan; Po-Huang Liang; Yan-Ping Shih; Ueng-Cheng Yang; Wen-chang Lin; Chun-Nan Hsu,Recombinant protein production is a useful biotechnology to produce a large quantity ofhighly soluble proteins. Currently; the most widely used production system is to fuse a targetprotein into different vectors in Escherichia coli (E. coli). However; the production efficacy ofdifferent vectors varies for different target proteins. Trial-and-error is still the commonpractice to find out the efficacy of a vector for a given target protein. Previous studies arelimited in that they assumed that proteins would be over-expressed and focused only on thesolubility of expressed proteins. In fact; many pairings of vectors and proteins result in noexpression. In this study; we applied machine learning to train prediction models to predictwhether a pairing of vector-protein will express or not express in E. coli. For expressedcases; the models further predict whether the expressed proteins would be soluble. We …,BMC bioinformatics,2010,10
Training conditional random fields by periodic step size adaptation for large-scale text mining,Han-Shen Huang; Yu-Ming Chang; Chun-Nan Hsu,For applications with consecutive incoming training examples; on-line learning has thepotential to achieve a likelihood as high as off-line learning without scanning all availabletraining examples and usually has a much smaller memory footprint. To train CRFson-line;this paper presents the Periodic Step size Adaptation (PSA) method to dynamically adjustthe learning rates in stochastic gradient descent. We applied our method to three large scaletext mining tasks. Experimental results show that PSA outperforms the best off-line algorithm;L-BFGS; by many hundred times; and outperforms the best on-line algorithm; SMD; by anorder of magnitude in terms of the number of passes required to scan the training data set.,Data Mining; 2007. ICDM 2007. Seventh IEEE International Conference on,2007,10
Ranking of multidimensional drug profiling data by fractional-adjusted bi-partitional scores,Dorit S Hochbaum; Chun-Nan Hsu; Yan T Yang,Abstract Motivation: The recent development of high-throughput drug profiling (high contentscreening or HCS) provides a large amount of quantitative multidimensional data. Despiteits potentials; it poses several challenges for academia and industry analysts alike. This isespecially true for ranking the effectiveness of several drugs from many thousands of imagesdirectly. This paper introduces; for the first time; a new framework for automatically orderingthe performance of drugs; called fractional adjusted bi-partitional score (FABS). This generalstrategy takes advantage of graph-based formulations and solutions and avoids manyshortfalls of traditionally used methods in practice. We experimented with FABS frameworkby implementing it with a specific algorithm; a variant of normalized cut—normalized cutprime (FABS-NC′); producing a ranking of drugs. This algorithm is known to run in …,Bioinformatics,2012,9
UMARS: un-mappable reads solution,Sung-Chou Li; Wen-Ching Chan; Chun-Hung Lai; Kuo-Wang Tsai; Chun-Nan Hsu; Yuh-Shan Jou; Hua-Chien Chen; Chun-Hong Chen; Wen-chang Lin,Un-MAppable Reads Solution (UMARS) is a user-friendly web service focusing on retrievingvaluable information from sequence reads that cannot be mapped back to referencegenomes. Recently; next-generation sequencing (NGS) technology has emerged as apowerful tool for generating high-throughput sequencing data and has been applied tomany kinds of biological research. In a typical analysis; adaptor-trimmed NGS reads werefirst mapped back to reference sequences; including genomes or transcripts. However; afraction of NGS reads failed to be mapped back to the reference sequences. Such un-mappable reads are usually imputed to sequencing errors and discarded without furtherconsideration. We are investigating possible biological relevance and possible sources ofun-mappable reads. Therefore; we developed UMARS to scan for virus genomic …,BMC bioinformatics,2011,9
Modeling a discrete event system using statecharts,YiSheng Huang; MuDer Jeng; ChienNin Hsu,Statecharts have been proposed as a visual formalism for the behavioral of complexsystems. The dynamical behavior of an elevation is a example to illustrate the operation ofstatechart systems because it shares with many other discrete event systems (DES's) thefeatures of: simple actions; aggregating complexity of state descriptions; and great variety ofpossible control strategies and resulting trajectories. This paper applies the statechartterminologies to cope with the difficult situation of elevator system problems. In this paper;we present the modeling; control and implementation of an elevator system. A statechart-based for an elevator controller design and implementation is proposed. The intendedadvantage of the proposed controller is that using statechart terminologies; we can describethe system's behavior over time; including the dynamics of activities; and the conditions …,Networking; Sensing and Control; 2004 IEEE International Conference on,2004,9
View inference for heterogeneous XML information integration,Euna Jeong; Chun-Nan Hsu,Abstract This paper proposes a novel approach to integrating heterogeneous XML DTDs.With this approach; an information agent can be easily extended to integrate heterogeneousXML-based contents and perform federated search. Based on a tree grammar inferencetechnique; this approach derives an integrated view of XML DTDs in an informationintegration framework. The derivation takes advantages of naming and structural similaritiesamong DTDs in similar domains. The complete approach consists of three main steps.(1)DTD clustering clusters DTDs in similar domains into classes.(2) Schema learner applies atree grammar inference technique to generate a set of tree grammar rules from the DTDs ina class from the previous step.(3) Minimizer optimizes the rules generated in the previousstep; transforms them into an integrated view; and generates source descriptions. We …,Journal of Intelligent Information Systems,2003,9
Building a natural language processing tool to identify patients with high clinical suspicion for Kawasaki disease from emergency department notes,Son Doan; Cleo K Maehara; Juan D Chaparro; Sisi Lu; Ruiling Liu; Amanda Graham; Erika Berry; Chun‐Nan Hsu; John T Kanegaye; David D Lloyd; Lucila Ohno‐Machado; Jane C Burns; Adriana H Tremoulet,Objective Delayed diagnosis of Kawasaki disease (KD) may lead to serious cardiaccomplications. We sought to create and test the performance of a natural languageprocessing (NLP) tool; the KD-NLP; in the identification of emergency department (ED)patients for whom the diagnosis of KD should be considered. Methods We developed anNLP tool that recognizes the KD diagnostic criteria based on standard clinical terms andmedical word usage using 22 pediatric ED notes augmented by Unified Medical LanguageSystem vocabulary. With high suspicion for KD defined as fever and three or more KDclinical signs; KD-NLP was applied to 253 ED notes from children ultimately diagnosed witheither KD or another febrile illness. We evaluated KD-NLP performance against ED notesmanually reviewed by clinicians and compared the results to a simple keyword search …,Academic Emergency Medicine,2016,8
The BioCreative II-critical assessment for information extraction in biology challenge,Martin Krallinger; A Morgan; L Smith; F Leitner; L Tanabe; J Wilbur; L Hirschman; A Valencia,<p><i>Genome Biology</i> covers all areas of biology and biomedicine studied from a genomicand post-genomic perspective. Content includes research; new methods and software tools;and reviews; opinions and commentaries. Areas covered include; but are not limited to: sequenceanalysis; bioinformatics; insights into molecular; cellular and organismal biology; functionalgenomics; epigenomics; population genomics; proteomics; comparative biology and evolution;systems and network biology; genome editing and engineering; genomics of disease; and clinicalgenomics. All content is open access immediately on publication.<i></i></p>.,Genome Biology,2008,8
Gene name service: no-nonsense alias resolution service for homo sapiens genes,Kuan-Ting Lin; Chia-Hung Liu; Jen-Jie Chiou; Wen-Hsien Tseng; Kuang-Lung Lin; Chun-Nan Hsu,Abstract Gene Name Service (GNS) provides up-to-date alias resolution services for 26types of gene identifiers of Homo sapiens genes via both Web server (for human users) andWeb Service (for other applications). GNS automatically updates its database to keep itscontents up-to-date.,Proceedings of the 2007 IEEE/WIC/ACM International Conferences on Web Intelligence and Intelligent Agent Technology-Workshops,2007,8
Modeling pronunciation variation for bi-lingual Mandarin/Taiwanese speech recognition,Dau-Cheng Lyu; Ren-Yuan Lyu; Yuang-Chin Chiang; Chun-Nan Hsu,Abstract In this paper; a bi-lingual large vocaburary speech recognition experiment basedon the idea of modeling pronunciation variations is described. The two languages understudy are Mandarin Chinese and Taiwanese (Min-nan). These two languages are basicallymutually unintelligible; and they have many words with the same Chinese characters andthe same meanings; although they are pronounced differently. Observing the bi-lingualcorpus; we found five types of pronunciation variations for Chinese characters. A one-pass;three-layer recognizer was developed that includes a combination of bi-lingual acousticmodels; an integrated pronunciation model; and a tree-structure based searching net. Therecognizer's performance was evaluated under three different pronunciation models. Theresults showed that the character error rate with integrated pronunciation models was …,International Journal of Computational Linguistics & Chinese Language Processing; Volume 10; Number 3; September 2005: Special Issue on Selected Papers from ROCLING XVI,2005,8
LEARNING EFFECTIVE AND ROBUST KNOWLEDGE FOR SEMANTIC QUERY OPTIMIZATION,Chun-Nan Hsu,Abstract: Optimizing queries to heterogeneous; distributed multidatabases is an importantproblem. Due to the query complexity and the heterogeneity of databases; it is difficult forconventional optimization approaches to solve the problem satisfactorily. Semantic QueryOptimization (SQO) can complement conventional approaches to overcome theheterogeneity and considerably reduce redundant data transmission. SQO optimizers userules about data regularities to yield significant cost reduction. However; hand coding usefulrules for SQO is impracticable. This dissertation presents a machine learning approach tothis knowledge bottleneck problem. Unlike search control rules or classification rules studiedextensively in machine learning; two roughly correlated measures must be maximized in thelearning of high utility rules for SQO. The first measure is the effectiveness. Effective rules …,*,1997,8
Global and componentwise extrapolations for accelerating training of Bayesian networks and conditional random fields,Han-Shen Huang; Bo-Hou Yang; Yu-Ming Chang; Chun-Nan Hsu,Abstract The triple jump extrapolation method is an effective approximation of Aitken'sacceleration that can accelerate the convergence of many algorithms for data mining;including EM and generalized iterative scaling (GIS). It has two options—global andcomponentwise extrapolation. Empirical studies showed that neither can dominate the otherand it is not known which one is better under what condition. In this paper; we investigatethis problem and conclude that; when the Jacobian is (block) diagonal; componentwiseextrapolation will be more effective. We derive two hints to determine the block diagonality.The first hint is that when we have a highly sparse data set; the Jacobian of the EM mappingfor training a Bayesian network will be block diagonal. The second is that the blockdiagonality of the Jacobian of the GIS mapping for training CRF is negatively correlated …,Data Mining and Knowledge Discovery,2009,7
Analysis and Enhancement of Conditional Random Fields Gene Mention Taggers in BioCreative II Challenge Evaluation.,Yu-Ming Chang; Cheng-Ju Kuo; Han-Shen Huang; Yu-Shi Lin; Chun-Nan Hsu,Abstract Background: Tagging gene and gene product mentions in scientific text is animportant initial step of literature mining. In BioCreative 2 challenge; the conditional randomfields model (CRF) was the most prevailing method in the gene mention task. In this paper;we analyze two best performing CRF-based systems in BioCreative 2. We examine their keyclaims and propose enhancement based on the analysis results. Results: We implementedtheir systems in MALLET as specified in their report and in CRF++; a different CRF package;to empirically analyze their claims. We found that their feature set is effective for modelstrained by MALLET; but a smaller set works better for those by CRF++. We confirmed theeffectiveness of pairing parentheses as a post processing step. We found that backwardparsing is not always superior to forward parsing. The benefit of applying bidirectional …,LBM (Short Papers),2007,7
Global and componentwise extrapolation for accelerating data mining from large incomplete data sets with the EM algorithm,Chun-Nan Hsu; Han-Shen Huang; Bo-Hou Yang,The expectation-maximization (EM) algorithm is one of the most popular algorithms for datamining from incomplete data. However; when applied to large data sets with a largeproportion of missing data; the EM algorithm may converge slowly. The triple jumpextrapolation method can effectively accelerate the EM algorithm by substantially reducingthe number of iterations required for EM to converge. There are two options for the triplejump method; global extrapolation (TJEM) and componentwise extrapolation (CTJEM). Wetried these two methods for a variety of probabilistic models and found that in general; globalextraplolation yields a better performance; but there are cases where componentwiseextrapolation yields very high speedup. In this paper; we investigate when componentwiseextrapolation should be preferred. We conclude that; when the Jacobian of the EM …,Data Mining; 2006. ICDM'06. Sixth International Conference on,2006,7
Reconfigurable Web wrapper agents for biological information integration,Chun‐Nan Hsu; Chia‐Hui Chang; Chang‐Huain Hsieh; Jiann‐Jyh Lu; Chien‐Chi Chang,Abstract A variety of biological data is transferred and exchanged in overwhelming volumeson the World Wide Web. How to rapidly capture; utilize; and integrate the information on theInternet to discover valuable biological knowledge is one of the most critical issues inbioinformatics. Many information integration systems have been proposed for integratingbiological data. These systems usually rely on an intermediate software layer calledwrappers to access connected information sources. Wrapper construction for Web datasources is often specially hand coded to accommodate the differences between each Website. However; programming a Web wrapper requires substantial programming skill; and istime-consuming and hard to maintain. In this article we provide a solution for rapidly buildingsoftware agents that can serve as Web wrappers for biological information integration. We …,Journal of the Association for Information Science and Technology,2005,7
Discovering robust knowledge from dynamic closed-world data,Chun-Nan Hsu; Craig A Knoblock,Abstract Many applications of knowledge discovery require the knowledge to be consistentwith data. Examples include discovering rules for query optimization; database integration;decision support; etc. However; databases usually change over time and make machine-discovered knowledge inconsistent with data. Useful knowledge should be robust againstdatabase changes so that it is unlikely to become inconsistent after database changes. Thispaper defines this notion of robustness; describes how to estimate the robustness ofHornclause rules in closed-world databases; and describes how the robustness estimationcan be applied in rule discovery systems.,AAAI/IAAI; Vol. 1,1996,7
Identifying transformative scientific research,Yi-Hung Huang; Chun-Nan Hsu; Kristina Lerman,Transformative research refers to research that shifts or disrupts established scientificparadigms. Notable examples include the discovery of high-temperature superconductivitythat disrupted the theory established 30 years ago. Identifying potential transformativeresearch early and accurately is important for funding agencies to maximize the impact oftheir investments. It also helps scientists identify and focus their attention on promisingemerging works. This paper presents a data driven approach where citation patterns ofscientific papers are analyzed to quantify how much a potential challenger idea shifts anestablished paradigm. The key idea is that transformative research creates an observabledisruption in the structure of" information cascades;" chains of references that can be tracedback to the papers establishing some scientific paradigm. Such a disruption is visible …,Data Mining (ICDM); 2013 IEEE 13th International Conference on,2013,6
Adaptive image enhancement for fluorescence microscopy,Jyh-Ying Peng; Chung-Chih Lin; Chun-Nan Hsu,Fluorescent cell micrographs contain inhomogeneous contrast levels due to fluorescenceintensity variations and the existence of out-of-focus objects. A novel image enhancementmethod based on adaptive local region sizes is proposed; which can correctly highlightsalient objects from changing background intensity. The local region size for each pixel isdetermined adaptively; then locally normalized intensity values based on the regions areobtained; automatically taking inhomogeneous contrast and background intensity intoaccount. Object background binarization can be done by applying simple thresholding to theenhanced image. The method is validated by comparison with ground truth segmentationsof cell micrographs; which shows that after applying the proposed signal enhancement;binarization using common global thresholding methods produces segmentations much …,Technologies and Applications of Artificial Intelligence (TAAI); 2010 International Conference on,2010,6
Exploring Match Scores to Boost Precision of Gene Normalization,Cheng-Ju Kuo; Yu-Ming Chang; Han-sen Huang; K Lin; B Yang; Y Lin; C Hsu; I Chung,Gene normalization task is to identify EntrezGene IDs corresponding to the human genesand direct gene products appearing in a given MEDLINE abstract. Given a dictionary thatmaps gene and protein synonyms to EntrezGene IDs; a naive approach to the problem is toapply a gene mention tagger to identify all potential name entities of genes and then lookthem up in the dictionary. However; mostly due to the difficulty to compile a complete yetnoise-free dictionary for gene synonyms [5]; the results are far from satisfactory. In ourexperiments using a gene mention tagger based on a conditional random field (CRF)[4]model and a string matcher based on softTFIDF [1] to look up the dictionary; the F-score isbelow 0. 5. To improve the performance; previous work proposed many methods to clean updictionaries. These methods may help case by case but may not applicable in general. In …,Proceedings of the BioCreAtIvE II Workshop 2007; Madrid,2007,6
Language identification by using syllable-based duration classification on code-switching speech,Dau-cheng Lyu; Ren-yuan Lyu; Yuang-chin Chiang; Chun-nan Hsu,Abstract Many approaches to automatic spoken language identification (LID) onmonolingual speech are successfully; but LID on the code-switching speech identifying atleast 2 languages from one acoustic utterance challenges these approaches. In [6]; we havesuccessfully used one-pass approach to recognize the Chinese character on the Mandarin-Taiwanese code-switching speech. In this paper; we introduce a classification method(named syllable-based duration classification) based on three clues: recognized commontonal syllable tonal syllable; the corresponding duration and speech signal to identifyspecific language from code-switching speech. Experimental results show that theperformance of the proposed LID approach on code-switching speech exhibits closely tothat of parallel tonal syllable recognition LID system on monolingual speech.,*,2006,6
Item-triggered recommendation for identifying potential customers of cold sellers in supermarkets,Han-Shen Huang; Koung-Lung Lin; Jane Yung-jen Hsu; Chun-Nan Hsu,ABSTRACT Recommendation has achieved successful results in many applications.However; for supermarkets; since the transaction data is extremely skewed in the sense thata large portion of sales is concentrated in a small number of hot seller items; collaborativefiltering recommenders usually recommend hot sellers while rarely recommend cold sellers.But recommenders are supposed to provide better campaigns for cold sellers to increasesales. In this paper; we propose an alternative “item-triggered” recommendation; which aimsat returning a ranked list of potential customers for a given cold-seller item. This problem canbe formulated as a problem of rare class learning. We present a Boosting-SVM algorithm tosolve the rare class problem and apply our algorithm to a real-world supermarket database.Experimental results show that our algorithm can improve from a baseline approach by …,Proceedings of Beyond Personalization,2005,6
A Unified Framework for Large Vocabulary Speech Recognition of Mutually Unintelligible Chinese" Regionalects",Ren-Yuan Lyu; Dau-Cheng Lyu; Min-Siong Liang; Min-Hong Wang; Yuang-Chin Chiang; Chun-Nan Hsu,Abstract In this paper; a new approach is proposed for recognizing speech of mutuallyunintelligible spoken Chinese regionalects based on a unified three-layer framework and aone-stage searching strategy. This framework includes (1) a unified acoustic model for allthe considered regionalects;(2) a multiple pronunciation lexicon constructed by both a rule-based and a data-driven approaches;(3) a one-stage searching network; whose nodesrepresent the Chinese characters with their multiple pronunciations. Unlike the traditionalapproaches; the new approach avoids searching the intermediate local optimal syllablesequences or lattices. Instead; by using the Chinese characters as the searching nodes; thenew approach can search to find the globally optimal character sequences directly. Thispaper reports the experiments on two of the Chinese regionalects; ie; Taiwanese and …,Eighth International Conference on Spoken Language Processing,2004,6
Personal navigating agents,Hui-Lung Wang; Wei-Kuan Shih; CN Hsu; Yi-Shiou Chen; Yu-Lin Wang; Wen-Lian Hsu,In this paper; we consider a framework for constructing agents that can simulate thebehavior of human browsing on the Internet. Given a specific target; such an agent will makeuse of existing search engines to navigate through the web to locate the sites containing thetarget information and extract them into a database. We refer to these types of agents asPersonal Navigating Agents (PNA). Since information service is domain specific; we shallfirst focus on those PNA that can retrieve people's information on the web in this paper. Inthis particular experiment; given the name of a university; we shall extract the followinginformation about its faculty: name; telephone number; fax number; email address and URL.The extracted information will soon be expanded to include title; affiliation and mailingaddress. The techniques developed are general enough for constructing PNA that can …,Proceedings of the third annual conference on Autonomous Agents,1999,6
Learning phenotype mapping for integrating large genetic data,Chun-Nan Hsu; Cheng-Ju Kuo; Congxing Cai; Sarah A Pendergrass; Marylyn D Ritchie; Jose Luis Ambite,Abstract Accurate phenotype mapping will play an important role in facilitating Phenome-Wide Association Studies (PheWAS); and potentially in other phenomics based studies. ThePhe-WAS approach investigates the association between genetic variation and an extensiverange of phenotypes in a high-throughput manner to better understand the impact of geneticvariations on multiple phenotypes. Herein we define the phenotype mapping problem posedby PheWAS analyses; discuss the challenges; and present a machine-learning solution. Ourkey ideas include the use of weighted Jaccard features and term augmentation by dictionarylookup. When compared to string similarity metric-based features; our approach improvesthe F-score from 0.59 to 0.73. With augmentation we show further improvement in F-score to0.89. For terms not covered by the dictionary; we use transitive closure inference and …,Proceedings of BioNLP 2011 Workshop,2011,5
Adaptive local thresholding for fluorescence cell micrographs,Jyh-Ying Peng; Chun-Nan Hsu,Abstract An adaptive local thresholding method for microscope based high content analysis(HCA) is proposed. Cell micrographs of HCA contain detailed objects both in and out offocus; which cannot be correctly segmented by global thresholding methods. The proposedmethod utilizes adaptive local neighborhood size and double thresholding; and is able toproduce segmentations that conform closely to perceptually relevant structures in theoriginal image; robust to background noise and variation. The proposed method is appliedto the segmentation of mitochondria in fluorescence cell micrographs. Comparison with bothhand segmentation and other global and local thresholding methods shows that theproposed method produces results of comparable quality to hand segmentation anddiscovers much more detailed structure than any previous thresholding methods.,Technical Rep. No. TR-IIS-09-008,2009,5
Feature space transformation for semi-supervised learning for protein subcellular localization in fluorescence microscopy images,Yu-Shi Lin; Yi-Hung Huang; Chung-Chih Lin; Chun-Nan Hsu,As rapid acquisition of large collections of fluorescence microscopy cell images can beautomated; large-scale subcellular localizations of GFP-tagged fusion proteins can bepractically accomplished. Semi-supervised learning has the potential of using a large set ofunlabeled images for the recognition of subcellular organelle patterns; but the performancestill has room for improvement. This paper presents a feature space transformation methodbased on the spectral graph theory to improve semi-supervised learning. Experimentalresult shows that our feature space transformation method can improve the classificationaccuracy substantially.,Biomedical Imaging: From Nano to Macro; 2009. ISBI'09. IEEE International Symposium on,2009,5
SIMS: Single interface to multiple sources,Yigal Arens; Craig A Knobloch; Chin Y Chee; Chunnan Hsu,Abstract: With the current explosion of data; retrieving and integrating information fromvarious sources is a critical problem. This report describes work performed at USC/ISI;aimed at developing a general and extensible approach to this problem. The SIMSapproach exploits a semantic model of a problem domain to integrate the information fromvarious sources; ie; databases and knowledge bases. The domain and the informationsources are modeled. Queries submitted to SIMS are mapped into a set of queries toindividual information sources. The set of queries is then further optimized; usingknowledge; about the domain and the information sources. The data obtained is thenreturned to the user. SIMS utilizes techniques from the areas of knowledge representation;planning; and learning Descriptors:* COMPUTER PROGRAMMING;* DATA BASES …,*,1996,5
Acoustic model optimization for multilingual speech recognition,Dau-Cheng Lyu; Chun-Nan Hsu; Yuang-Chin Chiang; Ren-Yuan Lyu,Abstract Due to abundant resources not always being available for resource-limitedlanguages; training an acoustic model with unbalanced training data for multilingual speechrecognition is an interesting research issue. In this paper; we propose a three-step data-driven phone clustering method to train a multilingual acoustic model. The first step is toobtain a clustering rule of context independent phone models driven from a well-trainedacoustic model using a similarity measurement. For the second step; we further clustered thesub-phone units using hierarchical agglomerative clustering with delta Bayesian informationcriteria according to the clustering rules. Then; we chose a parametric modeling technique--model complexity selection--to adjust the number of Gaussian components in a Gaussianmixture for optimizing the acoustic model between the new phoneme set and the …,International Journal of Computational Linguistics & Chinese Language Processing; Volume 13; Number 3; September 2008: Special Issue on Selected Papers from ROCLING XIX,2008,4
A ν-support vector regression based approach for predicting imputation quality,Yi-Hung Huang; John P Rice; Scott F Saccone; José Luis Ambite; Yigal Arens; Jay A Tischfield; Chun-Nan Hsu,Decades of genome-wide association studies (GWAS) have accumulated large volumes ofgenomic data that can potentially be reused to increase statistical power of new studies; butdifferent genotyping platforms with different marker sets have been used as biotechnologyhas evolved; preventing pooling and comparability of old and new data. For example; topool together data collected by 550K chips with newer data collected by 900K chips; we willneed to impute missing loci. Many imputation algorithms have been developed; but theposteriori probabilities estimated by those algorithms are not a reliable measure the qualityof the imputation. Recently; many studies have used an imputation quality score (IQS) tomeasure the quality of imputation. The IQS requires to know true alleles to estimate. Onlywhen the population and the imputation loci are identical can we reuse the estimated IQS …,BMC proceedings,2012,3
Soft tagging of overlapping high confidence gene mention variants for cross-species full-text gene normalization,Cheng-Ju Kuo; Maurice HT Ling; Chun-Nan Hsu,Previously; gene normalization (GN) systems are mostly focused on disambiguation usingcontextual information. An effective gene mention tagger is deemed unnecessary becausethe subsequent steps will filter out false positives and high recall is sufficient. However;unlike similar tasks in the past BioCreative challenges; the BioCreative III GN task isparticularly challenging because it is not species-specific. Required to process full-lengtharticles; an ineffective gene mention tagger may produce a huge number of ambiguous falsepositives that overwhelm subsequent filtering steps while still missing many true positives.We present our GN system participated in the BioCreative III GN task. Our system applies atypical 2-stage approach to GN but features a soft tagging gene mention tagger thatgenerates a set of overlapping gene mention variants with a nearly perfect recall. The …,BMC bioinformatics,2011,3
Boosting multiclass learning with repeating codes,Yu-Shi Lin; Chun-Nan Hsu,Abstract A long-standing goal of machine learning is to build a system which can detect alarge number of classes with accuracy and efficiency. Some relationships between classeswould become a scale-free network in which we can classify the assigned class very fast.Many available methods for multiclass problems have been proposed in the literatures; suchas AdaBoost. ECC [4]; AdaBoost. ERP;[7] and JointBoost [12]. However; many of them areinaccurate or time-consuming on training. In this paper; we propose a new algorithm; calledAdaBoost. ERC; which combines the approach of Dietterich and Bakiri [2] based on errorcorrecting output codes (ECOC) and Shapire's boosting algorithm [3][10]. With advantagesof both concepts; our new approach achieves better performance compared to AdaBoost.ECC; AdaBoost. ERP; and JointBoost.,Technical report TR-IIS-07-014,2007,3
TJ 2 aEM: targeted aggressive extrapolation method for accelerating the em algorithm,Han-Shen Huang; Bo-Hou Yang; Chun-Nan Hsu,Abstract The Expectation-Maximization (EM) algorithm is one of the most popular algorithmsfor parameter estimation from incomplete data; but its convergence can be slow for somelarge-scale or complex machine learning problems. Extrapolation methods can effectivelyaccelerate EM; but to ensure stability; the learning rate of extrapolation must becompromised. This paper describes the TJ2aEM algorithm; a targeted aggressiveextrapolation method that can make much more aggressive extrapolations without causinginstability problems. We show that for a wide variety of probabilistic models; TJ2aEM canconverge many times faster than other acceleration methods under different datadistributions and initial conditions. In addition to EM; TJ2aEM can also be applied to otherbound optimization methods; including generalized iterative scaling; non-negative matrix …,*,2007,3
The Hybrid Poisson Aspect Model for Personalized Shopping Recommendation.,Chun-Nan Hsu; Hao-Hsiang Chung; Han-Shen Huang,Abstract Predicting an individual customer's likelihood of purchasing a specific item formsthe basis of many marketing activities; such as personalized shopping recommendation.Collaborative filtering and association rule mining can be applied to this problem; but inretail supermarkets; the problem becomes particularly challenging because of the sparsityand skewness of transaction data. This paper presents HyPAM (Hybrid Poisson AspectModel); a new probabilistic graphical model that combines a Poisson mixture with a latentaspect class model to model customers' shopping behavior. We empirically compareHyPAM with two well-known recommenders; GroupLens (a correlationbased method); andIBM SmartPad (association rules and cosine similarity). Experimental results show thatHyPAM outperforms the other recommenders by a large margin for two real-world retail …,ICDM,2003,3
Smoothing of recommenders' ratings for collaborative filtering,Han-Shen Huang; Chun-Nan Hsu,Abstract This paper presents the idea of rating smoothing to improve the performance ofcollaborative filtering algorithms. We identify the role smoothing of recommenders' ratings incollaborative filtering; and propose two approaches to smooth recommenders' ratings. Thefirst approach; scale smoothing; is supposed to reduce the difference in rating scalesbetween the active user and recommenders. The second approach; preference smoothing;tries to decrease the difference in preferences by rearranging recommenders' ratings. Wealso present the experimental results for the two smoothing approaches. The results showthat the first smoothing approach can make collaborative filtering predict better and ispromising for further improving the performance of collaborative filtering algorithms.,*,2001,3
The SIMS Manual. Version 1.0.,Jose-Luis Ambite; Yigal Arens; Naveen Ashish; Chin Y Chee; Chun-Nan Hsu,Abstract: SIMS provides intelligent access to heterogeneous; distributed informationsources; while insulating human users and application programs from the need to be awareof the location of the sources; their query languages; organization; size; etc. This manualexplains how to bring up a SIMS information server in a new domain. After providing a shortoverview of relevant features of the SIMS system; it describes the modeling andprogramming work that has to be performed to support the application of SIMS to a givencollection of information sources in the domain. To aid the user inexperienced with thetechnological infrastructure underlying SIMS; the manual contains examples structured as atutorial that can be followed to actually produce a working SIMS system. Descriptors:* USERMANUALS;* INFORMATION SYSTEMS; SOURCES; DISTRIBUTED DATA PROCESSING …,*,1995,3
The SIMS Manual,J Ambite; Yigal Arens; Chun-Nan Hsu; Craig A Knoblock; Wei-Min Shen; Sheila Tejada,Abstract SIMS provides intelligent access to heterogeneous; distributed information sources;while insulating human users and application programs from the need to be aware of thelocation of the sources; their query languages; organization; size; etc. This manual explainshow to bring up a SIMS information server in a new application domain. After providing ashort overview of relevant features of the SIMS system; it describes the modeling andprogramming work that has to be performed to support the extension of SIMS to a givencollection of information sources in the domain. To aid a user inexperienced with thetechnological infrastructure underlying SIMS; the manual contains examples structured as atutorial that can be followed to actually produce a working SIMS system.,ISI,1995,3
Periodic step size adaptation for single pass on-line learning,Chun-Nan Hsu; Yu-Ming Chang; Hanshen Huang; Yuh-Jye Lee,Abstract It has been established that the second-order stochastic gradient descent (2SGD)method can potentially achieve generalization performance as well as empirical optimum ina single pass (ie; epoch) through the training examples. However; 2SGD requires computingthe inverse of the Hessian matrix of the loss function; which is prohibitively expensive. Thispaper presents Periodic Step-size Adaptation (PSA); which approximates the Jacobianmatrix of the mapping function and explores a linear relation between the Jacobian andHessian to approximate the Hessian periodically and achieve near-optimal results inexperiments on a wide variety of models and tasks.,Advances in Neural Information Processing Systems,2009,2
Cross-lingual audio-to-text alignment for multimedia content management,Dau-Cheng Lyu; Ren-Yuan Lyu; Yuang-Chin Chiang; Chun-Nan Hsu,Abstract This paper addresses a content management problem in situations where we havea collection of spoken documents in audio stream format in one language and a collection ofrelated text documents in another. In our case; we have a huge digital archive of audiobroadcast news in Taiwanese; but its transcriptions are unavailable. Meanwhile; we have acollection of related text-based news stories; but they are written in Chinese characters. Dueto the lack of a standard written form for Taiwanese; manual transcription of spokendocuments is prohibitively expensive; and automatic transcription by speech recognition isinfeasible because of its poor performance for Taiwanese spontaneous speech. We presentan approximate solution by aligning Taiwanese spoken documents with related textdocuments in Mandarin. The idea is to take advantage of the abundance of Mandarin text …,Decision Support Systems,2008,2
華台雙語發音變異性之語音辨識研究及 PDA 之應用,呂道誠， 謝鴻文， 李勇憲， 劉仲英， 許鈞南， 江永進， 呂仁園,*,The Association for Computational Linguistics and Chinese Language Processing,2004,2
Integration and Reuse of Heterogeneous XML DTDs for Information Agents,Euna Jeong; Chun-Nan Hsu,Abstract This paper proposes a novel approach to integrating heterogeneous XML DTDs.With this approach; an information agent can be easily extended to integrate heterogeneousXML-based contents and perform federated searches. Based on a tree grammar inferencetechnique; this approach derives an integrated view and source descriptions of XML DTDsin an information integration framework. The derivation takes advantage of naming andstructural similarities among DTDs in similar domains. The complete approach consists ofthree main steps.(1) DTD clustering clusters DTDs of similar domains into classes.(2)Schema learning takes the DTDs in a class as input and applies a tree grammar inferencetechnique to generate a set of tree grammar rules.(3) Minimization optimizes the rulespreviously generated and transforms them into an integrated view as well as source …,*,2001,2
The ANNIGMA-Wrapper Approach to Neural Nets Feature Selection for Knowledge Discovery and Data Mining,Chun-nan Hsu; Dietrich Schuschel; Ya-ting Yang,Abstract Feature selection is critical in data mining and knowledge discovery. Previously; afeature selection technique known as the wrapper model was shown e ective for decisiontrees induction. However; it is prohibitively expensive when applied to real-world neural netdata mining characterized by large volumes of data and many attribute choices. Ourapproach incorporates the wrapper model with a weight based heuristic metric calledANNIGMA which allows the wrapper model feature selection feasible for neural nets. Wepresent three search strategies guided by ANNIGMA: greedy forward selection (FS);backward elimination with backtracking (BEB); and backward stepwise elimination (BSE).FS performs particularly well for datasets that need a small number of features and runs thefastest; BEB and BSE perform consistently well for all datasets; while BSE is e ective for …,Institute of Information Science,1999,2
bioPDFX: preparing PDF scientific articles for biomedical text mining,Shitij Bhargava; Tsung-Ting Kuo; Ankit Goyal; Vincent Kuri; Gordon Lin; Chun-Nan Hsu,Background. There is huge amount of full-text biomedical literatures available in publicrepositories like PubMed Central (PMC). However; a substantial number of the papers are inPortable Document Format (PDF) and do not provide plain text format ready for text miningand natural language processing (NLP). Although there exist many PDF-to-text converters;they still suffer from several challenges while processing biomedical PDFs; such as thecorrect transcription of titles/abstracts; segmenting references/acknowledgements; specialcharacters; jumbling errors (the wrong order of the text); and word boundaries. Methods. Inthis paper; we present bioPDFX; a novel tool which complements weaknesses withstrengths of multiple state-of-the-art methods and then applies machine learning methods toaddress all issues above Results. The experiment results on publications of Genome …,PeerJ PrePrints,2017,1
Deduplication in a massive clinical note dataset,Sanjeev Shenoy; Tsung-Ting Kuo; Rodney Gabriel; Julian McAuley; Chun-Nan Hsu,Abstract: Duplication; whether exact or partial; is a common issue in many datasets. Inclinical notes data; duplication (and near duplication) can arise for many reasons; such asthe pervasive use of templates; copy-pasting; or notes being generated by automatedprocedures. A key challenge in removing such near duplicates is the size of such datasets;our own dataset consists of more than 10 million notes. To detect and correct suchduplicates requires algorithms that both accurate and highly scalable. We describe asolution based on Minhashing with Locality Sensitive Hashing. In this paper; we present thetheory behind this method and present a database-inspired approach to make the methodscalable. We also present a clustering technique using disjoint sets to produce denseclusters; which speeds up our algorithm.,arXiv preprint arXiv:1704.05617,2017,1
Weakly supervised learning of biomedical information extraction from curated data,Suvir Jain; R Kashyap; Tsung-Ting Kuo; Shitij Bhargava; Gordon Lin; Chun-Nan Hsu,Numerous publicly available biomedical databases derive data by curating from literatures.The curated data can be useful as training examples for information extraction; but curateddata usually lack the exact mentions and their locations in the text required for supervisedmachine learning. This paper describes a general approach to information extraction usingcurated data as training examples. The idea is to formulate the problem as cost-sensitivelearning from noisy labels; where the cost is estimated by a committee of weak classifiersthat consider both curated data and the text. We test the idea on two information extractiontasks of Genome-Wide Association Studies (GWAS). The first task is to extract targetphenotypes (diseases or traits) of a study and the second is to extract ethnicity backgroundsof study subjects for different stages (initial or replication). Experimental results show that …,BMC bioinformatics,2016,1
Natural Language Processing Using Kepler Workflow System: First Steps,Ankit Goyal; Alok Singh; Shitij Bhargava; Daniel Crawl; Ilkay Altintas; Chun-Nan Hsu,Abstract Scientific community across many disciplines is exploring new ways to extractknowledge from all available sources. Historically; written manuscripts have been the mediaof choice for recording experimental findings. Many disciplines such as social science;medical science are exploring ways to automate knowledge discovery from a vast repositoryof published scientific work. This work attempts to accelerate the process of informationextraction by extending Kepler; a graphical workflow management tool. Kepler provides asimple way of designing and executing complex workflows in the form of directed graphs.This work presents a scalable approach to convert published research as PDF documentsinto indexable XML documents using Kepler. This conversion is a critical step in the NaturalLanguage Processing pipeline. Kepler's distributed data processing capability enables …,Procedia Computer Science,2016,1
Robust cell segmentation for schizosaccharomyces pombe images with focus gradient,Jyh-Ying Peng; Yen-Jen Chen; Marc D Green; Susan L Forsburg; Chun-Nan Hsu,Schizosaccharomyces pombe shares many genes and proteins with humans and is a goodmodel for chromosome behavior and DNA dynamics; which can be analyzed by visualizingthe behavior of fluorescently tagged proteins in vivo. Performing a genome-wide screen forchanges in such proteins requires developing methods that automate analysis of multipleimages; the first step of which requires robust segmentation of the cell. We developed asegmentation system; PombeX; that can segment cells from transmitted illumination imageswith focus gradient and varying contrast. Corrections for focus gradient are applied to theimage to accurately detect cell membrane and cytoplasm pixels. Quantitative evaluationsshow overall good segmentation performance on a large set of images; regardless ofdifferent image quality; lighting condition; focus condition and phenotypic profile …,Biomedical Imaging (ISBI); 2013 IEEE 10th International Symposium on,2013,1
Reconstructing big semantic similarity networks,Ai He; Shefali Sharma; Chun-Nan Hsu,Abstract Distance metric learning from high (thousands or more) dimensional data withhundreds or thousands of classes is intractable but in NLP and IR; high dimensionality isusually required to represent data points; such as in modeling semantic similarity. Thispaper presents algorithms to scale up learning of a Mahalanobis distance metric from alarge data graph in a high dimensional space. Our novel contributions include randomprojection that reduces dimensionality and a new objective function that regularizes intra-class and inter-class distances to handle a large number of classes. We show that the newobjective function is convex and can be efficiently optimized by a stochastic-batchsubgradient descent method. We applied our algorithm to two different domains; semanticsimilarity of documents collected from the Web; and phenotype descriptions in genomic …,Proceedings of TextGraphs-8 Graph-based Methods for Natural Language Processing,2013,1
Exploring label dependency in active learning for phenotype mapping,Shefali Sharma; Leslie Lange; Jose Luis Ambite; Yigal Arens; Chun-Nan Hsu,Abstract Many genetic epidemiological studies of human diseases have multiple variablesrelated to any given phenotype; resulting from different definitions and multiplemeasurements or subsets of data. Manually mapping and harmonizing these phenotypes isa time-consuming process that may still miss the most appropriate variables. Previously; asupervised learning algorithm was proposed for this problem. That algorithm learns todetermine whether a pair of phenotypes is in the same class. Though that algorithmaccomplished satisfying F-scores; the need to manually label training examples becomes abottleneck to improve its coverage. Herein we present a novel active learning solution tosolve this challenging phenotype-mapping problem. Active learning will make phenotypemapping more efficient and improve its accuracy.,Proceedings of the 2012 Workshop on Biomedical Natural Language Processing,2012,1
Genome-Wide Detection of Putative Oncofetal Genes in Human Hepatocellular Carcinoma by Splicing Pattern Comparison.,Chia-Hung Liu; Kuan-Ting Lin; Chi-Ying F Huang; Yih-Jyh Shann; Yu-Shi Lin; Cheng-Yan Kao; Chun-Nan Hsu,Abstract ncofetal genes are those genes that express themselves similarly in fetal andtumorous adult tissues but differently or below detectable levels in normal adult tissues.These genes are thought to play important roles in cell proliferation; differentiation andcarcinogenesis. They have recently been used as biomarkers of cancer. For example; thealpha-fetoprotein (AFP) is one of the most commonly used diagnostic markers forhepatocellular carcinoma (HCC). In this paper; we present a computational method thatcompares the distributions of co-expression splicing patterns to detect potential biomarkergenes in HCC; according to the cDNA/EST data. Using this method; we successfullyidentified 84 putative oncofetal genes (POFG) in HCC. We also found that the fetal andtumorous isoforms of POFG tended to be longer than their normal counterparts. Our …,*,2011,1
Phenotype-wide association study (PheWAS) for exploration of novel SNP and phenotype relationships within PAGE,Sarah A Pendergrass; Kristin D Brown-Gentry; Scott Dudek; Jose L Ambite; Christy L Avery; Steve Buyske; Congxing Cai; Gerardo Heiss; Lucia Hindorff; Charles Kooperberg; Yi Lin; Teri A Manolio; Tara Matise; Lynne Wilkens; Megan D Fesinmeyer; Chun-Nan Hsu; Dana C Crawford; Marylyn D Ritchie,*,GENETIC EPIDEMIOLOGY,2010,1
Automated cell phenotype image classification combining different methods,Loris Nanni; Chun-Nan Hsu; Alessandra Lumini; Yu-Shi Lin; Chung-Chih Lin,Abstract In this paper our aim is to study how an ensemble of classifiers can improve theperformance of a machine learning technique for cell phenotype image classification. Wewant to point out some of the advantages that an ensemble of classifiers permits to obtainrespect a stand-alone method. Finally; the preliminary results on the 2D-HeLa dataset;obtained by the fusion between a random subspace of Levenberg-Marquardt neuralnetworks and a variant of the AdaBoost; are reported. It is interesting to note that theproposed system obtains an outstanding 97.5% Rank-1 accuracy and a> 99% Rank-2accuracy.,Proceeding of the Workshop on Automated Interpretation and Modeling of Cell Images,2009,1
Recognizing 100 speakers using homologous naive bayes,Hung-Ju Huang; Chun-Nan Hsu,Abstract This paper presents an extension of the naive Bayesian classifier; called“homologous naive Bayes (HNB);” which is applied to the problem of text-independent;close-set speaker recognition. Unlike the standard naive Bayes; HNB can take advantage ofthe prior information that a sequence of input feature vectors belongs to the same unknownclass. We refer to such a sequence a homologous set; which is naturally available inspeaker recognition. We empirically compare HNB with the Gaussian mixture model (GMM);the most widely used approach to speaker recognition. Results show that; in spite of itssimplisity; HNB can achieve comparable classification accuracies for up to a hundredspeakers while taking much less resources in terms of time and code size for both trainingand classification.,Pacific Rim International Conference on Artificial Intelligence,2002,1
Bayesian networks for Medicare expert systems,Tzu-Tsung Wong; Chun-Nan Hsu,*,*,2002,1
Ontology Integration in XML,Euna Jeong; Chun-Nan Hsu,*,PROCEEDINGS OF THE NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE,2000,1
Tradeoff in rule induction for semantic query optimization,Chun-Nan Hsu,Abstract Semantic query optimization (SQO) is a promising approach to the optimization ofincreasingly complex query plans in global information systems. The idea of SQO is to usesemantic rules about data to reformulate a query into an equivalent but less expensive one.Since it is difficult to encode required semantic rules; a complete SQO system also includesa rule induction system and a rule maintainer. To maximize the net utility of learning; a ruleinduction system needs to learn those rules that are effective in reducing the queryexecution cost while robust against data changes to minimize the rule maintenance cost.This paper focuses on this tradeoff between effectiveness and robustness in the ruleinduction for SQO. The solution is to explicitly estimate the degree of the robustness of rules.The system can use the estimated robustness to make decisions to guide rule …,AAAI Workshop on Building Resource-Bounded Reasoning Systems,1997,1
Assessing value of biomedical digital repositories,Chun-Nan Hsu; Anita Bandrowski; Jeffrey S Grethe; Maryann E Martone,Abstract Digital repositories bring direct impact and influence on the research communityand society but measuring their value using formal metrics remains challenging. their value.It is challenging to define a single perfect metric that covers all quality aspects. Here; wedistinguish here between impact and influence and discuss measures and mentions as thebasis of quality metrics of a digital repository. We argue that these challenges maypotentially be overcome through the introduction of standard resource identification and datacitation practices. We briefly summarize our research and experience in the NeuroscienceInformation Framework; the BD2K BioCaddie project on data citation; and the ResourceIdentification Initiative. Full implementation of these standards will depend on cooperationfrom all stakeholders---digital repositories; authors; publishers; and funding agencies; but …,PeerJ PrePrints,2017,*
Ensembles of NLP Tools for Data Element Extraction from Clinical Notes,Tsung-Ting Kuo; Pallavi Rao; Cleo Maehara; Son Doan; Juan D Chaparro; Michele E Day; Claudiu Farcas; Lucila Ohno-Machado; Chun-Nan Hsu,Abstract Natural Language Processing (NLP) is essential for concept extraction fromnarrative text in electronic health records (EHR). To extract numerous and diverse concepts;such as data elements (ie; important concepts related to a certain medical condition); aplausible solution is to combine various NLP tools into an ensemble to improve extractionperformance. However; it is unclear to what extent ensembles of popular NLP tools improvethe extraction of numerous and diverse concepts. Therefore; we built an NLP ensemblepipeline to synergize the strength of popular NLP tools using seven ensemble methods; andto quantify the improvement in performance achieved by ensembles in the extraction of dataelements for three very different cohorts. Evaluation results show that the pipeline canimprove the performance of NLP tools; but there is high variability depending on the …,AMIA Annual Symposium Proceedings,2016,*
Profiling mitochondrial complex I inhibitors by combining mitochondrial morphological features and maximum common chemical substructures,Chung-Chih Lin; Jyh-Ying Peng; Yi-Hsuan Tseng; Chung-Chien Chou; Fang-Rong Chang; Yang-Chang Wu; Lung-Sen Kao; Chun-Nan Hsu,Studies on the mechanism of toxins are important to reveal the etiology of Parkinson'sdisease (PD). Complex I inhibitors are a main group of PD toxins; and their chemicalfeatures have been intensively studied. However; the chemical structures specific tomitochondrial morphological changes are still unknown. We developed a drug profilingsystem that combines mitochondrial morphological quantification and chemical substructurecomputation; which allows us to discover chemical substructures specific to mitochondrialmorphological changes. Using this system; we quantified the mitochondrial morphologyinduced by annonaceous acetogenins; and calculated the maximum common substructureof acetogenins inducing similar cell responses. We discovered that (1) the hydroxyl groupsclose to γ-lactone in annonacin may result in stronger effects on nuclear size reduction …,Bioelectronics and Bioinformatics (ISBB); 2014 IEEE International Symposium on,2014,*
Automatic phenotyping of multi-channel Schizosaccharomyces pombe images,Yen-Jen Chen; Marc D Green; Sarah A Sabatinos; Susan L Forsburg; Chun-Nan Hsu; Jyh-Ying Peng,Schizosaccharomyces pombe shares many genes and proteins with humans and is a goodmodel for chromosome behavior and DNA dynamics; which can be analyzed by visualizingthe behavior of fluorescently tagged proteins in vivo. However; performing a genome-widescreen for changes in such proteins requires developing methods that automate analysis ofmultiple images. We developed a high content analysis system to robustly segmenttransmitted illumination images; extract cell and nucleus boundaries; and quantitativelycharacterize the fluorescence within each compartment. A support vector machine (SVM) istrained to automatically judge if a cell is undergoing septation; and another two SVMs aretrained to classify pombe cells into various phenotypes according to its cell shape andfluorescence signal profile. We applied this system to automatically calculate the …,Bioelectronics and Bioinformatics (ISBB); 2014 IEEE International Symposium on,2014,*
Simultaneous segmentation of cell and nucleus in Schizosaccharomyces pombe images with focus gradient,Jyh-Ying Peng; Yen-Jen Chen; Marc D Green; Susan L Forsburg; Chun-Nan Hsu,Schizosaccharomyces pombe shares many genes and proteins with humans and is a goodmodel for chromosome behavior and DNA dynamics; which can be analyzed by visualizingthe behavior of fluorescently tagged proteins in vivo [1]. However; performing a genome-wide screen for changes in such proteins requires developing methods that automateanalysis of multiple images. The first step requires robust segmentation of the cell and themost distinguishable compartments (the nucleus) from images with varying focus conditionsand qualities. We developed a segmentation system that can segment transmittedillumination images with focus gradient and varying contrast; and extract cell and nucleusboundaries. Global and locally adaptive corrections for focus gradient are applied to theimage to accurately detect cell membrane and cytoplasm pixels. We use the gradient …,Healthcare Informatics; Imaging and Systems Biology (HISB); 2012 IEEE Second International Conference on,2012,*
ezTrial,Yi-Ru Cian; Chung-Tsuo Lin; Hong-Yi Chen; Chia-Hui Chang; Yi-Fang Lee; Chun-Nan Hsu,After logging into the system; if you do not have a current trial; the system will redirect you tothe switch trial page. You can then select a current trial on this page; and click the [Save]button to store the setting. The next time you log in; the system will display the Today's Visitpage of the trial setting stored previously.,*,2010,*
ezTrial,Hong-Yi Chen; Chung-Tsuo Lin; Chia-Hui Chang; Yi-Ru Cian; Yi-Fang Lee; Chun-Nan Hsu,1.1 Purpose ezTrial provides users with a web-based clinical trial management service;which is simple to operate and can be conveniently accessed from the internet. The serviceprovides the function of creating and designing multiple clinical trials with predefined studyplans; and is able to integrate customized phase assignment rules within each trial. Theservice provides easy to use visit-scheduling and recording functions with user friendlyinterface; and the recorded data can later be searched and exported for further analysis. Theservice also provides the progress report function for consistent data tracking. All the dataare securely stored in the database and protected by user-specific authorizations andpermissions.,*,2010,*
Accelerating EM by targeted aggressive double extrapolation,Han-Shen Huang; Bo-Hou Yang; Ren-Yuan Lyu; Chun-Nan Hsu,The Expectation-Maximization (EM) algorithm is one of the most popular algorithms forparameter estimation from incomplete data; but its convergence can be slowfor some large-scale or complex problems. Extrapolation methods can effectively accelerate EM; but toensure stability; the learning rate of extrapolation must be compromised. This paperdescribes the TJ 2 aEM method; a targeted extrapolation method that can extrapolate muchmore aggressively than competing methods without causing instability problems. Weanalyze its convergence properties and report experimental results.,Acoustics; Speech and Signal Processing; 2009. ICASSP 2009. IEEE International Conference on,2009,*
多語聲學單位分類之最佳化研究 (The Study of Acoustic Model Clustering in Multilingual Speech Recognition)[In Chinese],Dau-cheng Lyu; Ren-yuan Lyu; Yung-Jien Chiang; Chun-Nan Hsu,摘要由於全球化的形成; 人與人之間的溝通不再限於同一種語言; 因此多語的語音辨識也變的格外的重要. 如何有效整合多語的聲學模型是一個關鍵議題; 因為一組好的多語聲學單位將影響辨識結果. 本論文提出了一套整合專家背景知識與實際語音分析的方法; 來產生一組新的聲學單位; 並且對這組聲學單位的數目; 使用差分貝式資訊法則來做最佳的處理. 從訓練好的隱藏式馬可夫聲學模型中; 計算其單位間的相似度矩陣; 之後透過語音學和音韻學的知識;限定了各個聲學單位能群化的上限; 根據不同限定的群化上限; 使用聚合階層式分群法;來建立不同的結構樹. 之後; 利用差分貝式資訊法則; 將每個結構樹中發音相近的聲學單位做合併; 當差分貝式資訊法則的值小於零的時候; 就停止合併; 而新合併成一群的聲學單位則為新的聲學單. 我們將用ForSDAT01 華台雙語語料庫來實驗評量; 而實驗結果顯示; 本論文所提出的新方法比只用專家知識所定義的聲學單位所訓練出的辨識器有較高的辨識效果.,Proceedings of the 19th Conference on Computational Linguistics and Speech Processing,2007,*
Efficient Off-line and On-line Algorithms for Training Conditional Random Fields by Approximating Jacobians,Chun-Nan Hsu; Han-Shen Huang; Yu-Ming Chang,Abstract Previously; algorithms for training conditional random fields were derived from thesecond-order Taylor expansion of the log-likelihood of the training data and the key issue isto approximate the Hessian matrix; which usually requires O (n2) computations per iteration.In this paper; we show that efficient off-line and online algorithms for training conditionalrandom fields (CRF) can also be derived from approximating the Jacobian of thegeneralized iterative scaling (GIS) mapping to reduce per iteration complexity to O (n).Experimental results show that in terms of the rate of convergence; algorithms derived in thisway can be as efficient as the best performing second-order algorithms or even better.,NIPS* 2007 Workshop on Efficient Machine Learning,2007,*
Triple Jump Acceleration for the EM Algorithm and Its Extrapolation-based Variants,Han-Shen Huang; Bo-Hou Yang; Chun-Nan Hsu,Page 1. Institute of Information Science; Academia Sinica 中研院資訊所 Adaptive Internet IntelligentAgent Lab 機器學習與網路代理人實驗室 Triple Jump Acceleration for the EM Algorithm and ItsExtrapolation-based Variants Han-Shen Huang (黃漢申) Bo-Hou Yang (楊博厚) Chun-Nan Hsu(許鈞南) Institute of Information Science; Academia Sinica 2006/7/24 Page 2. Adaptive InternetIntelligent Agent Lab 機器學習與網路代理人實驗室 2 Motivation ◆Given an incomplete data set;the EM [Dempster et al. 1977] algorithm iteratively searches for the maximum likelihood estimateof a probabilistic model. However; the search usually converges slowly under these conditionsbecause more iterations or time for each iteration are required: ●High missing rate ●Large trainingdata set ●Large parameter vector ◆Therefore; accelerating EM is desired for training probabilisticmodels. Page 3. Adaptive Internet Intelligent Agent Lab …,*,2006,*
Taiwanese TV news-to-document index system,Dau-Cheng Lyu; Bo-Hou Yang; Ren-Yuan Lyu; Chun-Nan Hsu,This paper describes an index system from Taiwanese TV speech news to World Wide WebChinese text documents. This system is based on two main techniques: automatic speechrecognition (ASR) and bi-lingual text alignment. For the former; we utilized the speech-to-textapproach to recognize the utterance of anchors in the TV news as Taiwanese tonal syllablesequences. Then we translated the Chinese text documents which obtained from thecorresponding news website to the Taiwanese tonal syllables by a bi-lingual pronunciationlexicon. Afterward; a dynamic programming algorithm is used in the syllable-level alignmentfor linking the TV news and the documents. A corpus of speech data about 100 speakersand the text data with 840k Chinese characters were used to train the acoustic andlanguage models in ASR. A bi-lingual lexicon contains 70k vocabularies is used as the …,Cellular Neural Networks and Their Applications; 2005 9th International Workshop on,2005,*
Molecular epidemiology of avian influenza virus H6N1 in Taiwan.,Lee Hsin-Chun; Hsu Chieh-Ning; Wang Ching-Ho,English | 正體中文 | 简体中文 | 全文筆數/總筆數: 83846/216839 (39%) 造訪人次: 17461533線上人數: 2990. RC Version 7.0 © Powered By DSPACE; MIT. Enhanced by NTU Library IR team …,Taiwan Vet J,2005,*
An item-triggered approach to serendipitous recommendation for supermarket customers,Chun-Nan Hsu; Koung-Lung Lin; Han-Shen Huang; Jane Yung-jen Hsu,English | 正體中文 | 简体中文 | 全文筆數/總筆數: 83846/216839 (39%) 造訪人次: 17452456線上人數: 3813. RC Version 7.0 © Powered By DSPACE; MIT. Enhanced by NTU Library IR team …,In Workshop on the Sciences of the Artificial,2005,*
A Bi-lingual TV News-to-Document Indexing System,Dau-Cheng Lyu; Ren-Yuan Lyu; Yuang-chin Chiang; Chun-Nan Hsu,ABSTRACT Based on a bi-lingual speech recognition engine and a parallel text alignmenttechnique; we initially developed an audio search engine for indexing bilingual broadcastnews to documents found on the World Wide Web (WWW). First; the automatic audiosegmentation technique is used for extracting the anchor streams; and then the speechrecognizer transformed the bilingual audio data to tonal syllable sequences. Secondly weutilized the parallel text and text-to-phone processing to translate the Chinese characters tothe language dependent spoken style tonal syllable sequences. Afterward; the dynamicprogramming algorithm scored both sequences; and output the index number as theanswer. Our system finally indexed both 22 Mandarin and 40 Taiwanese news on a widerange of topics; and the performance is achieved 82% accuracy rate.,In Proceedings TAAI Conference on Artificial Intelligence and Applications (TAAI2005)(National Kaohsiung University; Kaohsiung; Taiwan. 2005. 台灣高雄大學.),2005,*
Learning Hybrid Poisson Aspect Model for Personalized Shopping Recommendation,Chun-Nan Hsu,Abstract R ecommendations that really match customers' needs can boost sales. Researchers have proposed and evaluated many approaches for generatingrecommendations. In this thesis; we proposed a model-based collaborative approach; calledHybrid Poisson Aspect Model (HyPAM). HyP АМ is a hybrid system combining twoprobabilistic models; cluster and aspect; which model the relationship between customerclusters and product types. G iven a new customer and his/her shopping record; HyP АМcan estimate his/her degree of preference of each product item accurately. W e use the EМalgorithm to learn the parameters of HyP АМ from customers' shopping records. T o evaluateour approach; we apply HyP АМ and two well-known recommender systems; GroupLensand IBM; to a shopping-record data set provided by a local supermarket. T his data set …,*,2002,*
The SIMS Manual Version 2.0,Yigal Arens; Naveen Ashish; Craig A Knoblock; Steven Minton; Jay Modi; Maria Muslea; Andrew Philpot; Wei-Min Shen; Sheila Tejada; Weixiong Zhang,Abstract SIMS provides intelligent access to heterogeneous; distributed information sources;while insulating human users and application programs from the need to be aware of thelocation of the sources; their query languages; organization; size; etc. This manual explainshow to bring up a SIMS information server in a new application domain. After providing ashort overview of relevant features of the SIMS system; it describes the modeling andprogramming work that has to be performed to support the extension of SIMS to a givencollection of information sources in the domain. To aid a user inexperienced with thetechnological infrastructure underlying SIMS; the manual contains examples structured as atutorial that can be followed to actually produce a working SIMS system.,*,1997,*
The Presence of Highly Similar Notes Within the MIMIC-III Dataset,Rodney A Gabriel; Sanjeev Shenoy; Tsung-Ting Kuo; Julian McAuley; Chun-Nan Hsu,Materials and Methods-We found that there were multiple instances of exact copies;common outputs; and similar notes from the public domain MIMIC-III dataset-It is unclear forthe reasons of highly similar notes; but this could be related to pervasive practice of copy-andpasting; note template utilization; common outputted notes from automated machines;and technical errors in note processing,*,*,*
View Inference for Heterogeneous XML Information Integration Euna Jeong (eaj eong@ munhak. inha. ac. kr) School of Computer Science and Engineering; Inha U...,Chun-Nan Hsu,Abstract. This paper proposes a novel approach to integrating heterogeneous XML DTDs.With this approach; an information agent can be easily extended to integrate heterogeneousXML-based contents and perform federated search. Based on a tree grammar inferencetechnique; this approach derives an integrated view of XML DTDs in an informationintegration framework. The derivation takes advantages of naming and structural similaritiesamong DTDs in similar domains. The complete approach consists of three main steps.(1)DTD clustering clusters DTDs in similar domains into classes.(2) Schema learner applies atree grammar inference technique to generate a set of tree grammar rules from the DTDs ina class from the previous step.(3) Minimizer optimizes the rules generated in the previousstep; transforms them into an integrated view; and generates source descriptions. We …,*,*,*
Last but not least; we would like to thank all authors who submitted their work to this conference. Our special thanks go to the Local Chair; Chia-Hui Chang; for handli...,Chun-Nan Hsu; Wee Sun Lee,Abstract: Information Extraction (IE) is the task of mapping natural-language sentences tomachine-processable representations of the sentences' content. IE is often formulated as amachine-learning problem where an extractor for a particular relation (eg; seminar speaker)is learned from labeled training examples. My talk will describe Open IE—an approach toscaling IE to the Web where the set of potential relations is not known in advance making astandard machine learning approach impossible. I will describe various bootstrappingapproaches that enables us to utilize machine learning at Web scale.,*,*,*
TAAI 2012 Program Committee,Ajith Abraham; Naveen Ashish; Klaus Brinker; Tristan Cazenave; Bao-Rong Chang; Chia-Hui Chang; Berlin Chen; Ching-Han Chen; Jr-Chang Chen; Ken Chen; Lieu-Hen Chen; Lung-Pin Chen; Rung-Ching Chen; Shih-Hsin Chen; Shyi-Ming Chen; Ying-Ju Chen; Ying-Ping Chen; Chuan-Wen Chiang; Tsung-Che Chiang; Been-Chian Chien; Jyh-Horng Chou; Wei-Ta Chu; Kun-Ta Chuang; Dai Bi-Ru; Min-Yuh Day; Dejing Dou; Tuan-Fang Fan; Cheng-Seen Ho; Tzung-Pei Hong; Mong-Fong Horng; Jieh Hsiang; Ching-Hsien Hsu; Chunnan Hsu; Hui-Huang Hsu; Hsu Pei-Lun,Page 1. TAAI 2012 Program Committee Ajith Abraham; Machine Intelligence ResearchLabs Naveen Ashish; University of California Klaus Brinker; University of Applied SciencesHamm-Lippstadt Tristan Cazenave; Université de Paris Dauphine Bao-Rong Chang; NationalUniversity of Kaohsiung Chia-Hui Chang; National Central University Berlin Chen; NationalTaiwan Normal University Ching-Han Chen; National Central University Jr-Chang Chen;Chung Yuan Christian University Ken Chen; University City Boulevard; Charlotte Lieu-HenChen; National Chi Nan University Lung-Pin Chen; TungHai University Rung-Ching Chen;Chaoyang University of Technology Shih-Hsin Chen; Nanhua University Shyi-Ming Chen;National Taichung University of Education …,*,*,*
A Relational Database Approach to Bayesian Network Knowledge Discovery,Chun Nan Hsu; Chia Che Ma,Abstract A Bayesian network is a powerful formalism for decision making and knowledgediscovery. An approach to Bayesian network training for large scaled real world applicationsis important. Bayesian network training includes the following two steps. Experts first selectappropriate parameters consistent with their confidence to transform the conditionalprobabilities into Dirichlet priors. Then the conditional posteriors for the variables in thenetwork can be obtained by Bayesian updating. In this paper; we present a databasescheme to store and manipulate a large Bayesian network as well as training data sets in arelational database. This scheme facilitates Bayesian network training and allows thesystem to take advantage of the benefits of relational data models. Other features of thisscheme are that it tolerates incomplete training data and is generally applicable for …,*,*,*
TAAI 2011,Reda Alhajj; Naveen Ashish; Tristan Cazenave; Berlin Chen; Keh-Hsun Chen; Phoebe Chen; Shu-Yuan Chen; Shyi-Ming Chen; Cheng-Seen Ho; Tsung Pei Hong; Ching-Hsien Hsu; Chunnan Hsu; Frank Hsu; Hui-Huang Hsu; Shun-Chin Hsu; Tsan-Sheng Hsu; Yuh-Jyh Hu; Xiangji Huang; Tan Ah Hwee; Irwin King; Yau-Hwang Kuo; K Robert Lai; Chang-Shing Lee; Yuh-Jye Lee; Churn-Jung Liau; Shun-Shii Lin; Wen-Yang Lin; Chao-Lin Liu; Tetsuya Murai; Tomoharu Nakashima; Wen-Chih Peng; Zbigniew W Ras; Lipo Wang; Anita Wasilewska; I-Chen Wu; Jean-Daniel Zucker,Reda Alhajj; University of Calgary; Canada Naveen Ashish; University of California-Irvine; USATristan Cazenave; Universite Paris Dauphine; France Berlin Chen; National Taiwan NormalUniversity; Taiwan Keh-Hsun Chen; University of North Carolina at Charlotte; USA PhoebeChen; La Trobe University; Australia Shu-Yuan Chen; Yuan Ze University; Taiwan Shyi-MingChen; National Taichung University of Education; Taiwan Cheng-Seen Ho; TungnanUniversity; Taiwan Tsung Pei Hong; National University of Kaohsiung; Taiwan Ching-HsienHsu; Chung Hua University; Taiwan Chunnan Hsu; Academia Sinica; Taiwan Frank Hsu; FordhamUniversity; USA Hui-Huang Hsu; Tamkang University; Taiwan Shun-Chin Hsu; Chang Jung ChristianUniversity; Taiwan Tsan-Sheng Hsu; Academia Sinica; Taiwan Yuh-Jyh Hu; National Chiao TungUniversity; Taiwan Xiangji Huang; York University; Canada Tan Ah Hwee; Nanyang …,*,*,*
Open Information Extraction at Web Scale.,Chun-Nan Hsu; Wee Sun Lee,*,*,*,*
WI-IAT Workshops 2007,Chun-Nan Hsu; Vincent Shin-Mu; Wen-Hsiang Lu; Howard CT Ho; Rong Pan; Yue Pan; Samson Tu; Ueng-Cheng Yang,Abstract: Provides an abstract of the workshop presentation and a brief professional biographyof the presenter. The complete presentation was not made available for publication as part ofthe conference proceedings … A not-for-profit organization; IEEE is the world's largest technicalprofessional organization dedicated to advancing technology for the benefit of humanity. © Copyright2017 IEEE - All rights reserved. Use of this web site signifies your agreement to the terms andconditions.,*,*,*
Componentwise Triple Jump Acceleration for Training Linear SVM,Han-Shen Huang; Yu-Ming Chang; Chun-Nan Hsu,The triple jump extrapolation method is an effective approximation of Aitken's accelerationfor accelerating the convergence of many machine learning algorithms that can beformulated as fixedpoint iteration. In the remainder of this abstract; we briefly review thegeneral idea of the triple jump method and then describe how to apply it to acceleratestochastic gradient descent (SGD) for training linear support vector machines (SVM).,*,*,*
Advanced Gene Mention Tagging System for CALBC Challenge,Cheng-Ju Kuo; Chun-Nan Hsu; Maurice HT Ling,In gene mention tagging task (GM) of BioCreative II (2007) challenge; we had built a systembased on bi-directional parsing models of Conditional Random Fields (CRFs); achieved a F-score of 86.83 [2] on GM test corpus and ranked second among twenty-one participants.After which; we improved its performance to a F-score of 88.3 by integrating highdimensional bi-directional parsing models (up to 6 models)[1]. For inter-operability within theBioCreative MetaServer; the system input was changed from a single sentence to a PubMedabstract which can be segmented to multi-sentences. This means that we can takeadvantage of the contextual information among sentences to optimize the taggingperformance. For example;“NAA” is a candidate gene mention tagged from a text of “...metabolites in 5 patients: N-acetyl-aspartate (NAA); creatine...”. If we could link the …,*,*,*
Dissecting protein-protein interaction-mediated cross-talk pathways in hepatocellular carcinoma,Chia-Hung Liu; Chun-Nan Hsu; Cheng-Yan Kao; Minoru Kanehisa; Susumu Goto; Chi-Ying F Huang,Multiple dys-regulated cell signaling pathways and extensive cross-talks among individualsignaling pathways characterize cancer development and progression [1]. The complexity ofthese cross-talk events can be; at least in part; depicted via protein-protein interactions(PPIs). However; systematic analysis of the cross-talk events from distinct pathways via PPIsremains fragmentary and is not readily apparent from PPI datasets. Moreover; the reliabilityof PPI datasets; particularly at the cellular level; remains to be vigorously examined.Metastasis is the main cause of mortality in patients with solid tumors; ie HepatocellularCarcinoma (HCC). A search for regulators of cancer metastasis may gain novel insighttoward how cancer cells develop metastatic potential. We used two HCC cell lines; Huh7(low invasion cells) and Mahalvu (high invasion cells); as cancer invasive model to …,*,*,*
Periodic Stepsize Adaptation,Chun-Nan Hsu; Han-Shen Huang; Yu-Ming Chang,Previously; Bottou and LeCun [1] established that the second-order stochastic gradientdescent (SGD) method can potentially achieve generalization performance as well asempirical optimum in a single pass through the training examples. However; second-orderSGD requires computing the inverse of the Hessian matrix of the loss function; which isusually prohibitively expensive. Recently; we invented a new second-order SGD method;called Periodic Stepsize Adaptation (PSA). PSA explores a simple linear relation betweenthe Hessian matrix and the Jacobian matrix of the mapping function. Instead ofapproximating Hessian; PSA approximates the Jacobian matrix which is proved to besimpler and more effective than approximating Hessian in an on-line setting. Experimentalresults for conditional random fields (CRF) and neural networks (NN) show that single …,*,*,*
Design and Implementation of WNDL---Web Navigation Description Language,Chun-Nan Hsu; Hung-Hsuan Huang; Siek Harianto; Elan Hung; Jiann-Jyh Lu; Chien-Chi Chang,Abstract Utilization of the World Wide Web can be boosted if we can explore the “deep Web”and integrate information from various Web sites together. However; to automate deep Webexploration and data integration requires custom-made software to accommodate thedifferences among Web sites; and thus is error-prone and time-consuming. This paperdefines a language called Web Navigation Description,*,*,*
CIAO 2009,Tzung-Pei Hong; Chang-Shing Lee; Vincenzo Loia; Antonina Dattolo; Wen-Yang Lin; Chao-Lin Liu; Shyue-Liang Wang; Witold Pedrycz; Francisco Herrera; Shusaku Tsumoto; Dariusz Krol; Andrzej Bargiela; Yiyu Yao; Hani Hagras; Trevor Martin; Chun-Nan Hsu; Hideyuki Takagi; Chia Liang-Tien; Marek Reformat; Ronald R Yager,Tzung-Pei Hong; National University of Kaohsiung; Taiwan Chang-Shing Lee; National Universityof Tainan; Taiwan Vincenzo Loia; University of Salerno; Italy … Antonina Dattolo; Universitàdi Udine; Italy Wen-Yang Lin; National University of Kaohsiung; Taiwan Chao-Lin Liu; NationalChengchi University; Taiwan Shyue-Liang Wang; National University of Kaohsiung; Taiwan WitoldPedrycz; University of Alberta; Canada Francisco Herrera; University of Granada; Spain ShusakuTsumoto; Shiame University; Japan Dariusz Krol; Wroclaw University of Technology; PolandAndrzej Bargiela; University of Nottingham; UK Yiyu Yao; University of Regina; Canada HaniHagras; University of Essex; UK Trevor Martin; University of Bristol; UK Chun-Nan Hsu; AcademiaSinica; Taiwan Hideyuki Takagi; Kyushu University; Japan Chia Liang-Tien; Nanyang TechnologicalUniversity; Singapore Marek Reformat; University of Alberta; Canada Ronald R. Yager …,*,*,*
