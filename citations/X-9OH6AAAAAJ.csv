Active database systems,Norman W Paton; Oscar Díaz,Abstract Active database systems support mechanisms that enable them to respondautomatically to events that are taking place either inside or outside the database systemitself. Considerable effort has been directed towards improving understanding of suchsystems in recent years; and many different proposals have been made and applicationssuggested. This high level of activity has not yielded a single agreed-upon standardapproach to the integration of active functionality with conventional database systems; buthas led to improved understanding of active behavior description languages; executionmodels; and architectures. This survey presents the fundamental characteristics of activedatabase systems; describes a collection of representative systems within a commonframework; considers the consequences for implementations of certain design decisions …,ACM Computing Surveys (CSUR),1999,827
A common open representation of mass spectrometry data and its application to proteomics research,Patrick GA Pedrioli; Jimmy K Eng; Robert Hubley; Mathijs Vogelzang; Eric W Deutsch; Brian Raught; Brian Pratt; Erik Nilsson; Ruth H Angeletti; Rolf Apweiler; Kei Cheung; Catherine E Costello; Henning Hermjakob; Sequin Huang; Randall K Julian Jr; Eugene Kapp; Mark E McComb; Stephen G Oliver; Gilbert Omenn; Norman W Paton; Richard Simpson; Richard Smith; Chris F Taylor; Weimin Zhu; Ruedi Aebersold,Abstract A broad range of mass spectrometers are used in mass spectrometry (MS)-basedproteomics research. Each type of instrument possesses a unique design; data system andperformance specifications; resulting in strengths and weaknesses for different types ofexperiments. Unfortunately; the native binary data formats produced by each type of massspectrometer also differ and are usually proprietary. The diverse; nontransparent nature ofthe data structure complicates the integration of new instruments into preexistinginfrastructure; impedes the analysis; exchange; comparison and publication of results fromdifferent experiments and laboratories; and prevents the bioinformatics community fromaccessing data sets required for software development. Here; we introducethe'mzXML'format; an open; generic XML (extensible markup language) representation of …,Nature biotechnology,2004,763
The minimum information about a proteomics experiment (MIAPE),Chris F Taylor; Norman W Paton; Kathryn S Lilley; Pierre-Alain Binz; Randall K Julian Jr; Andrew R Jones; Weimin Zhu; Rolf Apweiler; Ruedi Aebersold; Eric W Deutsch; Michael J Dunn; Albert JR Heck; Alexander Leitner; Marcus Macht; Matthias Mann; Lennart Martens; Thomas A Neubert; Scott D Patterson; Peipei Ping; Sean L Seymour; Puneet Souda; Akira Tsugita; Joel Vandekerckhove; Thomas M Vondriska; Julian P Whitelegge; Marc R Wilkins; Ioannnis Xenarios; John R Yates III; Henning Hermjakob,Abstract Both the generation and the analysis of proteomics data are now widespread; andhigh-throughput approaches are commonplace. Protocols continue to increase in complexityas methods and technologies evolve and diversify. To encourage the standardizedcollection; integration; storage and dissemination of proteomics data; the Human ProteomeOrganization's Proteomics Standards Initiative develops guidance modules for reporting theuse of techniques such as gel electrophoresis and mass spectrometry. This paper describesthe processes and principles underpinning the development of these modules; discussesthe ramifications for various interest groups such as experimentalists; funders; publishersand the private sector; addresses the issue of overlap with other reporting guidelines; andhighlights the criticality of appropriate tools and resources in enabling'MIAPE-compliant' …,Nature biotechnology,2007,620
The design and implementation of Grid database services in OGSA‐DAI,Mario Antonioletti; Malcolm Atkinson; Rob Baxter; Andrew Borley; Neil P Chue Hong; Brian Collins; Neil Hardman; Alastair C Hume; Alan Knox; Mike Jackson; Amy Krause; Simon Laws; James Magowan; Norman W Paton; Dave Pearson; Tom Sugden; Paul Watson; Martin Westhead,Abstract Initially; Grid technologies were principally associated with supercomputer centresand large-scale scientific applications in physics and astronomy. They are now increasinglyseen as being relevant to many areas of e-Science and e-Business. The emergence of theOpen Grid Services Architecture (OGSA); to complement the ongoing activity on WebServices standards; promises to provide a service-based platform that can meet the needs ofboth business and scientific applications. Early Grid applications focused principally on thestorage; replication and movement of file-based data. Now the need for the full integration ofdatabase technologies with Grid middleware is widely recognized. Not only do many Gridapplications already use databases for managing metadata; but increasingly many areassociated with large databases of domain-specific information (eg biological or …,Concurrency and Computation: Practice and Experience,2005,415
Active rules in database systems,Norman W Paton,Active rules provide a new and important method for designing databases and the subject isseeing an increasing amount of attention from commercial database companies. This bookprovides a timely survey of the field from the point of view of some of the subject's mostactive researchers. The book is divided into several parts; organized by theme: the first;Fundamentals covers the underlying methodology reagrding active rules; next comes acollection of chapters which cover formal specification; rule analysis; performance analysis;and support tools; the third part is devoted to a number of chapters covering theimplementation of active rules in a number of commercial systems. Finally; come sections onapplications and future directions that research may take. All researchers in databases willfind this provides a valuable overview of this topic.,*,2012,363
TAMBIS: transparent access to multiple bioinformatics information sources,Robert Stevens; Patricia Baker; Sean Bechhofer; Gary Ng; Alex Jacoby; Norman W Paton; Carole A Goble; Andy Brass,Abstract Summary: TAMBIS (Transparent Access to Multiple Bioinformatics InformationSources) is an application that allows biologists to ask rich and complex questions over arange of bioinformatics resources. It is based on a model of the knowledge of the conceptsand their relationships in molecular biology and bioinformatics. Availability: TAMBIS isavailable as an applet from http://img. cs. man. ac. uk/tambis Supplementary Information: Afull user manual; tutorial and videos can be found at http://img. cs. man. ac. uk/tambis.Contact: tambis@ cs. man. ac. uk,Bioinformatics,2000,347
An ontology for bioinformatics applications.,Patricia G.  Baker; Carole A.  Goble; Sean Bechhofer; Norman W.  Paton; Robert Stevens; Andy Brass,Abstract MOTIVATION: An ontology of biological terminology provides a model of biologicalconcepts that can be used to form a semantic framework for many data storage; retrieval andanalysis tasks. Such a semantic framework could be used to underpin a range of importantbioinformatics tasks; such as the querying of heterogeneous bioinformatics sources or thesystematic annotation of experimental results. RESULTS: This paper provides an overviewof an ontology [the Transparent Access to Multiple Biological Information Sources (TAMBIS)ontology or TaO] that describes a wide range of bioinformatics concepts. The present paperdescribes the mechanisms used for delivering the ontology and discusses the ontology'sdesign and organization; which are crucial for maintaining the coherence of a largecollection of concepts and their relationships. AVAILABILITY: The TAMBIS system; which …,Bioinformatics (Oxford; England),1999,322
A systematic approach to modeling; capturing; and disseminating proteomics experimental data,Chris F Taylor; Norman W Paton; Kevin L Garwood; Paul D Kirby; David A Stead; Zhikang Yin; Eric W Deutsch; Laura Selway; Janet Walker; Isabel Riba-Garcia; Shabaz Mohammed; Michael J Deery; Julie A Howard; Tom Dunkley; Ruedi Aebersold; Douglas B Kell; Kathryn S Lilley; Peter Roepstorff; John R Yates III; Andy Brass; Alistair JP Brown; Phil Cash; Simon J Gaskell; Simon J Hubbard; Stephen G Oliver,Abstract Both the generation and the analysis of proteome data are becoming increasinglywidespread; and the field of proteomics is moving incrementally toward high-throughputapproaches. Techniques are also increasing in complexity as the relevant technologiesevolve. A standard representation of both the methods used and the data generated inproteomics experiments; analogous to that of the MIAME (minimum information about amicroarray experiment) guidelines for transcriptomics; and the associated MAGE (microarraygene expression) object model and XML (extensible markup language) implementation; hasyet to emerge. This hinders the handling; exchange; and dissemination of proteomics data.Here; we present a UML (unified modeling language) approach to proteomics experimentaldata; describe XML and SQL (structured query language) implementations of that model …,Nature biotechnology,2003,299
A proposed framework for the description of plant metabolomics experiments and their results,Helen Jenkins; Nigel Hardy; Manfred Beckmann; John Draper; Aileen R Smith; Janet Taylor; Oliver Fiehn; Royston Goodacre; Raoul J Bino; Robert Hall; Joachim Kopka; Geoffrey A Lane; B Markus Lange; Jang R Liu; Pedro Mendes; Basil J Nikolau; Stephen G Oliver; Norman W Paton; Sue Rhee; Ute Roessner-Tunali; Kazuki Saito; Jørn Smedsgaard; Lloyd W Sumner; Trevor Wang; Sean Walsh; Eve Syrkin Wurtele; Douglas B Kell,Abstract The study of the metabolite complement of biological samples; known asmetabolomics; is creating large amounts of data; and support for handling these data sets isrequired to facilitate meaningful analyses that will answer biological questions. We present adata model for plant metabolomics known as ArMet (architecture for metabolomics). Itencompasses the entire experimental time line from experiment definition and description ofbiological source material; through sample growth and preparation to the results of chemicalanalysis. Such formal data descriptions; which specify the full experimental context; enableprincipled comparison of data sets; allow proper interpretation of experimental results;permit the repetition of experiments and provide a basis for the design of systems for datastorage and transmission. The current design and example implementations are freely …,Nature biotechnology,2004,285
TAMBIS: Transparent access to multiple bioinformatics information sources.,Patricia G Baker; Andy Brass; Sean Bechhofer; Carole A Goble; Norman W Paton; Robert Stevens,Abstract The TAMBIS project aims to provide transparent access to disparate biologicaldatabases and analysis tools; enabling users to utilize a wide range of resources with theminimum of effort. A prototype system has been developed that includes a knowledge baseof biological terminology (the biological Concept Model); a model of the underlying datasources (the Source Model) and a 'knowledge-driven'user interface. Biological concepts arecaptured in the knowledge base using a description logic called GRAIL. The Concept Modelprovides the user with the concepts necessary to construct a wide range of multiple-sourcequeries; and the user interface provides a flexible means of constructing and manipulatingthose queries. The Source Model provides a description of the underlying sources andmappings between terms used in the sources and terms in the biological Concept Model …,Ismb,1998,263
Rule Management in Object Oriented Databases: A Uniform Approach.,Oscar Díaz; Norman W Paton; Peter MD Gray,Abstract Rules have been proposed for providing active be-haviour in DBMS. Previousattempts to add rules to Object Oriented DBs have often resulted in a dichotomy betweenrules and other kind of objects. Bere a uniform approach is presented; in which rules aredescribed and handled in the same way as any other object in the system; without anyadditional mechanisms being introduced. Thus rules can be related to other objects orarranged in hierarchies; and rules can even be defined which are triggered by methodsattached to rules themselves. Since rules and classes are both objects; a relationshipbetween these two kinds of objects can be used to provide a class-based index for rules. Inthis way; the search for applicable rules is considerably reduced. An early implementationand several examples are shown in ADAM; an Object Oriented DB in PROLOG.,VLDB,1991,255
Growth control of the eukaryote cell: a systems biology study in yeast,Juan I Castrillo; Leo A Zeef; David C Hoyle; Nianshu Zhang; Andrew Hayes; David CJ Gardner; Michael J Cornell; June Petty; Luke Hakes; Leanne Wardleworth; Bharat Rash; Marie Brown; Warwick B Dunn; David Broadhurst; Kerry O'Donoghue; Svenja S Hester; Tom PJ Dunkley; Sarah R Hart; Neil Swainston; Peter Li; Simon J Gaskell; Norman W Paton; Kathryn S Lilley; Douglas B Kell; Stephen G Oliver,Cell growth underlies many key cellular and developmental processes; yet a limited numberof studies have been carried out on cell-growth regulation. Comprehensive studies at thetranscriptional; proteomic and metabolic levels under defined controlled conditions arecurrently lacking. Metabolic control analysis is being exploited in a systems biology study ofthe eukaryotic cell. Using chemostat culture; we have measured the impact of changes influx (growth rate) on the transcriptome; proteome; endometabolome and exometabolome ofthe yeast Saccharomyces cerevisiae. Each functional genomic level shows clear growth-rate-associated trends and discriminates between carbon-sufficient and carbon-limitedconditions. Genes consistently and significantly upregulated with increasing growth rate arefrequently essential and encode evolutionarily conserved proteins of known function that …,Journal of biology,2007,236
Transparent access to multiple bioinformatics information sources,Carole A.  Goble; Robert Stevens; Gary Ng; Sean Bechhofer; Norman W.  Paton; Patricia G.  Baker; Martin Peim; Andy Brass,This paper describes the Transparent Access to Multiple Bioinformatics Information Sourcesproject; known as TAMBIS; in which a domain ontology for molecular biology andbioinformatics is used in a retrieval-based information integration system for biologists. Theontology; represented using a description logic and managed by a terminology server; isused both to drive a visual query interface and as a global schema against which complexintersource queries are expressed. These source-independent declarative queries are thenrewritten into collections of ordered source-dependent queries for execution by amiddleware layer. In bioinformatics; the majority of data sources are not databases but toolswith limited accessible interfaces. The ontology helps manage the interoperation betweenthese resources. The paper emphasizes the central role that is played by the ontology in …,IBM Systems Journal,2001,236
Object-oriented databases: a semantic data model approach,Peter Gray; Krishnarao G Kulkarni; Norman W Paton,*,*,1992,207
Introduction,Norman W Paton; Oscar Díaz,Abstract This chapter introduces the main features of active database systems; outlines howthese features can be exploited in a range of application domains; and presents aframework that is used later in the book to characterize the functionality of different activesystems. The framework is the major contribution of the chapter; but an important side-effectof its presentation for the book is that much of the terminology associated with activedatabase systems is introduced and defined.,*,1999,204
Data access and integration in the ISPIDER Proteomics Grid,Lucas Zamboulis; Hao Fan; Khalid Belhajjame; Jennifer Siepen; Andrew Jones; Nigel Martin; Alexandra Poulovassilis; Simon Hubbard; Suzanne M Embury; Norman W Paton,Abstract Grid computing has great potential for supporting the integration of complex; fastchanging biological data repositories to enable distributed data analysis. One scenariowhere Grid computing has such potential is provided by proteomics resources which arerapidly being developed with the emergence of affordable; reliable methods to study theproteome. The protein identifications arising from these methods derive from multiplerepositories which need to be integrated to enable uniform access to them. A number oftechnologies exist which enable these resources to be accessed in a Grid environment; butthe independent development of these resources means that significant data integrationchallenges; such as heterogeneity and schema evolution; have to be met. This paperpresents an architecture which supports the combined use of Grid data access (OGSA …,International Workshop on Data Integration in the Life Sciences,2006,157
Distributed query processing on the grid,Jim Smith; Anastasios Gounaris; Paul Watson; Norman W Paton; Alvaro AA Fernandes; Rizos Sakellariou,Abstract Distributed query processing (DQP) has been widely used in data intensiveapplications where data of relevance to users is stored in multiple locations. This paperargues:(i) that DQP can be important in the Grid; as a means of providing high-level;declarative languages for integrating data access and analysis; and (ii) that the Gridprovides resource management facilities that are useful to developers of DQP systems. Aswell as discussing and illustrating how DQP technologies can be deployed within the Grid;the paper describes a prototype implementation of a DQP system running over Globus.,International Workshop on Grid Computing,2002,146
Comparative genome analysis of filamentous fungi reveals gene family expansions associated with fungal pathogenesis,Darren M Soanes; Intikhab Alam; Mike Cornell; Han Min Wong; Cornelia Hedeler; Norman W Paton; Magnus Rattray; Simon J Hubbard; Stephen G Oliver; Nicholas J Talbot,Fungi and oomycetes are the causal agents of many of the most serious diseases of plants.Here we report a detailed comparative analysis of the genome sequences of thirty-sixspecies of fungi and oomycetes; including seven plant pathogenic species; that aims toexplore the common genetic features associated with plant disease-causing species. Thepredicted translational products of each genome have been clustered into groups ofpotential orthologues using Markov Chain Clustering and the data integrated into the e-Fungi object-oriented data warehouse (http://www. e-fungi. org. uk/). Analysis of the speciesdistribution of members of these clusters has identified proteins that are specific tofilamentous fungal species and a group of proteins found only in plant pathogens. Bycomparing the gene inventories of filamentous; ascomycetous phytopathogenic and free …,PLoS One,2008,144
User interface modeling in UMLi,Paulo Pinheiro Da Silva; Norman W Paton,Although user interfaces represent an essential part of software systems; the UnifiedModeling Language) UML) seems to have been developed with little specific attention givento user interface issues. Several researchers have investigated integrating interfacemodeling techniques with UML. In UML; one models tasks using extended activity diagramsrather than by incorporating a completely new notation into UML. UMLi also addresses therelationships between use cases; tasks; and views; and thoroughly addresses therelationship between tasks and the data on which they act. UMLi is probably the mosttechnically mature proposal for interface development in UML.,IEEE software,2003,144
Teallach: a model-based user interface development environment for object databases,Tony Griffiths; Peter J Barclay; Norman W Paton; Jo McKirdy; Jessie Kennedy; Philip D Gray; Richard Cooper; Carole A Goble; Paulo Pinheiro da Silva,Abstract Model-based user interface development environments show promise for improvingthe productivity of user interface developers; and possibly for improving the quality ofdeveloped interfaces. While model-based techniques have previously been applied to thearea of database interfaces; they have not been specifically targeted at the important area ofobject database applications. Such applications make use of models that are semanticallyricher than their relational counterparts in terms of both data structures and applicationfunctionality. In general; model-based techniques have not addressed how the informationreferenced in such applications is manifested within the described models; and is utilisedwithin the generated interface itself. This lack of experience with such systems has led tomany model-based projects providing minimal support for certain features that are …,Interacting with Computers,2001,141
Web Service Grids: an evolutionary approach,Malcolm Atkinson; David DeRoure; Alistair Dunlop; Geoffrey Fox; Peter Henderson; Tony Hey; Norman Paton; Steven Newhouse; Savas Parastatidis; Anne Trefethen; Paul Watson; Jim Webber,Abstract The UK e-Science Programme is a£ 250 million; five-year initiative which hasfunded over 100 projects. These application-led projects are underpinned by an emergingset of core middleware services that allow the coordinated; collaborative use of distributedresources. This set of middleware services runs on top of the research network and beneaththe applications we call the 'Grid'. Grid middleware is currently in transition from pre-WebService versions to a new version based on Web Services. Unfortunately; only a very basicset of Web Services embodied in the Web Services Interoperability proposal; WS-I; areagreed by most IT companies. IBM and others have submitted proposals for Web Servicesfor Grids—the Web Services ResourceFramework and Web Services Notificationspecifications—to the OASIS organization for standardization. This process could take up …,Concurrency and Computation: Practice and Experience,2005,134
The Functional Genomics Experiment model (FuGE): an extensible framework for standards in functional genomics,Andrew R Jones; Michael Miller; Ruedi Aebersold; Rolf Apweiler; Catherine A Ball; Alvis Brazma; James DeGreef; Nigel Hardy; Henning Hermjakob; Simon J Hubbard; Peter Hussey; Mark Igra; Helen Jenkins; Randall K Julian Jr; Kent Laursen; Stephen G Oliver; Norman W Paton; Susanna-Assunta Sansone; Ugis Sarkans; Christian J Stoeckert Jr; Chris F Taylor; Patricia L Whetzel; Joseph A White; Paul Spellman; Angel Pizarro,Abstract The Functional Genomics Experiment data model (FuGE) has been developed tofacilitate convergence of data standards for high-throughput; comprehensive analyses inbiology. FuGE models the components of an experimental activity that are common acrossdifferent technologies; including protocols; samples and data. FuGE provides a foundationfor describing entire laboratory workflows and for the development of new data formats. TheMicroarray Gene Expression Data society and the Proteomics Standards Initiative havecommitted to using FuGE as the basis for defining their respective standards; and otherstandards groups; including the Metabolomics Standards Initiative; are evaluating FuGE intheir development efforts. Adoption of FuGE by multiple standards bodies will enableuniform reporting of common parts of functional genomics workflows; simplify data …,Nature biotechnology,2007,121
UMLi: The unified modeling language for interactive applications,Paulo Pinheiro Da Silva; Norman W Paton,Abstract User interfaces (UIs) are essential components of most software systems; andsignificantly affect the effectiveness of installed applications. In addition; UIs often representa significant proportion of the code delivered by a development activity. However; despitethis; there are no modelling languages and tools that support contract elaboration betweenUI developers and application developers. The Unified Modeling Language (UML) has beenwidely accepted by application developers; but not so much by UI designers. For thisreason; this paper introduces the notation of the Unified Modelling Language for InteractiveApplications (UML i); that extends UML; to provide greater support for UI design. UI elementselicited in use cases and their scenarios can be used during the design of activities and UIpresentations. A diagram notation for modelling user interface presentations is introduced …,International Conference on the Unified Modeling Language,2000,115
Conceptual modelling of genomic information,Norman W Paton; Shakeel A Khan; Andrew Hayes; Fouzia Moussouni; Andy Brass; Karen Eilbeck; Carole A Goble; Simon J Hubbard; Stephen G Oliver,Abstract Motivation: Genome sequencing projects are making available complete records ofthe genetic make-up of organisms. These core data sets are themselves complex; andpresent challenges to those who seek to store; analyse and present the information.However; in addition to the sequence data; high throughput experiments are makingavailable distinctive new data sets on protein interactions; the phenotypic consequences ofgene deletions; and on the transcriptome; proteome; and metabolome. The effectivedescription and management of such data is of considerable importance to bioinformatics inthe post-genomic era. The provision of clear and intuitive models of complex information issurprisingly challenging; and this paper presents conceptual models for a range of importantemerging information resources in bioinformatics. It is hoped that these can be of benefit …,Bioinformatics,2000,115
Service-based distributed querying on the grid,M Nedim Alpdemir; Arijit Mukherjee; Norman W Paton; Paul Watson; Alvaro AA Fernandes; Anastasios Gounaris; Jim Smith,Abstract Service-based approaches (such as Web Services and the Open Grid ServicesArchitecture) have gained considerable attention recently for supporting distributedapplication development in e-business and e-science. The emergence of a service-orientedview of hardware and software resources raises the question as to how databasemanagement systems and technologies can best be deployed or adapted for use in such anenvironment. This paper explores one aspect of service-based computing and datamanagement; viz.; how to integrate query processing technology with a service-based Grid.The paper describes in detail the design and implementation of a service-based distributedquery processor for the Grid. The query processor is service-based in two orthogonalsenses: firstly; it supports querying over data storage and analysis resources that are …,International Conference on Service-Oriented Computing,2003,113
Query processing in the TAMBIS bioinformatics source integration system,Norman W Paton; Robert Stevens; Pat Baker; Carole A Goble; Sean Bechhofer; Andy Brass,Conducting bioinformatic analyses involves biologists in expressing requests over a rangeof highly heterogeneous information sources and software tools. Such activities arelaborious; and require detailed knowledge of the data structures and call interfaces of thedifferent sources. The TAMBIS (Transparent Access to Multiple Bioinformatics InformationSources) project seeks to make the diversity in data structures; call interfaces and locationsof bioinformatics sources transparent to users. In TAMBIS; queries are expressed in terms ofan ontology implemented using a description logic; and queries over the ontology arerewritten to a middleware level for execution over the diverse sources. The paper describesquery processing in TAMBIS; focusing in particular on the way source-independent conceptsin the ontology are related to source-dependent middleware calls; and describing how …,Scientific and Statistical Database Management; 1999. Eleventh International Conference on,1999,113
Identification of database objects by key,Norman W Paton; Peter MD Gray,Abstract In relational databases one or more user-supplied scalar values are used toconstruct an identifier key representing the identity of an object. By contrast; object-orientedprogramming-languages and databases support the notion of object identity which isindependent of the attribute values of the object. In this paper we compare the twoapproaches and describe a compromise based upon objects with keys.,International Workshop on Object-Oriented Database Systems,1988,111
Dimensions of active behaviour,Norman W Paton; Oscar Díaz; M Howard Williams; Jack Campin; Andrew Dinn; Arturo Jaime,Summary This paper introduces a number of dimensions of active rule system behaviourwhich can be used both to highlight differences between proposals for active rule systems;and to identify the requirements of different applications. These dimensions relate to thestructure; execution model and management of active rules; and enable the conciseexpression of what facilities a system supports and what features an application requires.,*,1994,103
A Prolog interface to a Functional Data Model database,Peter MD Gray; David S Moffat; Norman W Paton,Abstract This paper describes a new database architecture for the manipulation of objects;based on an extended version of Prolog with modules. The modules permit the entityclasses of the Functional Data Model to be viewed as Abstract Data Types to which methodsstored in the modules can be applied. The database is stored as linked structures in apersistent heap. This architecture facilitates the use of Prolog as a navigational querylanguage which can explore relationships in an object-oriented database.,International Conference on Extending Database Technology,1988,100
Optimising and executing daplex queries using prolog,Norman W.  Paton; Peter M. D.  Gray,Abstract In this paper a query optimiser for use with functional data model databases isdescribed. The system is in use with a large database of protein structures from whichexamples are taken. The optimiser; which evaluates alternative paths through the objectbase; is written in Prolog and integrated with a parser for DAPLEX. The constructs ofDAPLEX are easily expressed in Prolog; which has also proved suitable for implementingboth the parser and rewrite rules. The implementation of the optimiser using rewrite rules isboth concise and extensible.,The Computer Journal,1990,99
Adaptive workflow processing and execution in pegasus,Kevin Lee; Norman W Paton; Rizos Sakellariou; Ewa Deelman; Alvaro AA Fernandes; Gaurang Mehta,Abstract Workflows are widely used in applications that require coordinated use ofcomputational resources. Workflow definition languages typically abstract over someaspects of the way in which a workflow is to be executed; such as the level of parallelism tobe used or the physical resources to be deployed. As a result; a workflow managementsystem has the responsibility of establishing how best to execute a workflow given theavailable resources. The Pegasus workflow management system compiles abstractworkflows into concrete execution plans; and has been widely used in large-scale e-Scienceapplications. This paper describes an extension to Pegasus whereby resource allocationdecisions are revised during workflow evaluation; in the light of feedback on theperformance of jobs at runtime. The contributions of this paper include:(i) a description of …,Concurrency and Computation: Practice and Experience,2009,96
PEDRo: a database for storing; searching and disseminating experimental proteomics data,Kevin Garwood; Thomas McLaughlin; Chris Garwood; Scott Joens; Norman Morrison; Christopher F Taylor; Kathleen Carroll; Caroline Evans; Anthony D Whetton; Sarah Hart; David Stead; Zhikang Yin; Alistair JP Brown; Andrew Hesketh; Keith Chater; Lena Hansson; Muriel Mewissen; Peter Ghazal; Julie Howard; Kathryn S Lilley; Simon J Gaskell; Andy Brass; Simon J Hubbard; Stephen G Oliver; Norman W Paton,Proteomics is rapidly evolving into a high-throughput technology; in which substantial andsystematic studies are conducted on samples from a wide range of physiological;developmental; or pathological conditions. Reference maps from 2D gels are widelycirculated. However; there is; as yet; no formally accepted standard representation tosupport the sharing of proteomics data; and little systematic dissemination of comprehensiveproteomic data sets. This paper describes the design; implementation and use of a Proteome E xperimental D ata R epo sitory (PEDRo); which makes comprehensiveproteomics data sets available for browsing; searching and downloading. It is also serves toextend the debate on the level of detail at which proteomics data should be captured; thesorts of facilities that should be provided by proteome data management systems; and the …,Bmc Genomics,2004,96
OGSA-DQP: A service for distributed querying on the grid,M Nedim Alpdemir; Arijit Mukherjee; Anastasios Gounaris; Norman W Paton; Paul Watson; Alvaro AA Fernandes; Desmond J Fitzgerald,Abstract OGSA-DQP is a distributed query processor exposed to users as an Open GridServices Architecture (OGSA)-compliant Grid service. This service supports the compilationand evaluation of queries that combine data obtained from multiple services on the Grid;including Grid Database Services (GDSs) and computational web services. Not only doesOGSA-DQP support integrated access to multiple Grid services; it is itself implemented as acollection of interacting Grid services. OGSA-DQP illustrates how Grid service orchestrationscan be used to perform complex; data-intensive parallel computations. The OGSA-DQPprototype is downloadable from www. ogsadai. org. uk/dqp/. This demonstration aims toillustrate the capabilities of OGSA-DQP prototype via a GUI Client over a collection ofbioinformatics databases and analysis tools.,International Conference on Extending Database Technology,2004,96
Optimizing utility in cloud computing through autonomic workload execution,Norman Paton; Marcelo AT De Aragão; Kevin Lee; Alvaro AA Fernandes; Rizos Sakellariou,Cloud computing provides services to potentially numerous remote users with diverserequirements. Although predictable performance can be obtained through the provision ofcarefully delimited services; it is straightforward to identify applications in which a cloudmight usefully host services that support the composition of more primitive analysis servicesor the evaluation of complex data analysis requests. In such settings; a service provider mustmanage complex and unpredictable workloads. This paper describes how utility functionscan be used to make explicit the desirability of different workload evaluation strategies; andhow optimization can be used to select between such alternatives. The approach isillustrated for workloads consisting of workflows or queries.,Bulletin of the Technical Committee on Data Engineering,2009,93
An object-oriented database for protein structure analysis,Peter MD Gray; Norman W Paton; Graham JL Kemp; John E Fothergill,Abstract An object-oriented database system has been developed which is being used tostore protein structure data. The database can be queried using the logic programminglanguage Prolog or the query language Daplex. Queries retrieve information by navigatingthrough a network of objects which represent the primary; secondary and tertiary structuresof proteins. Routines written in both Prolog and Daplex can integrate complex calculationswith the retrieval of data from the database; and can also be stored in the database forsharing among users. Thus object-oriented databases are better suited to prototypingapplications and answering complex queries about protein structure than relationaldatabases. This system has been used to find loops of varying length and anchor positionswhen modelling homologous protein structures.,Protein Engineering; Design and Selection,1990,93
Database access and integration services on the grid,Norman W Paton; Malcolm P Atkinson; Vijay Dialani; Dave Pearson; Tony Storey; Paul Watson,Abstract Research and development activities relating to the Grid have generally focused onapplications where data is stored in files. Although this has allowed progress to be maderapidly with various aspects of Grid infrastructure; database management systems have acentral role in data storage; access; organisation; authorisation; reorganisation; etc; fornumerous applications; including those in e-Science. This document makes a proposal for acollection of services that support:(i) consistent access to databases from Grid applications;and (ii) coordinated use of multiple databases from Grid middleware. It is hoped that theproposal; which should be considered to be preliminary; can help to foster a wider activity onthe formulation of standards for databases and the Grid.,Manchester University,2002,90
Comparative genome analysis across a kingdom of eukaryotic organisms: specialization and diversification in the fungi,Michael J Cornell; Intikhab Alam; Darren M Soanes; Han Min Wong; Cornelia Hedeler; Norman W Paton; Magnus Rattray; Simon J Hubbard; Nicholas J Talbot; Stephen G Oliver,Abstract The recent proliferation of genome sequencing in diverse fungal species hasprovided the first opportunity for comparative genome analysis across a eukaryotic kingdom.Here; we report a comparative study of 34 complete fungal genome sequences;representing a broad diversity of Ascomycete; Basidiomycete; and Zygomycete species. Wehave clustered all predicted protein-encoding gene sequences from these species toprovide a means of investigating gene innovations; gene family expansions; protein familydiversification; and the conservation of essential gene functions—empirically determined inSaccharomyces cerevisiae—among the fungi. The results are presented with reference to aphylogeny of the 34 fungal species; based on 29 universally conserved protein-encodinggene sequences. We contrast this phylogeny with one based on gene presence and …,Genome Research,2007,89
Identification of novel genes in intestinal tissue that are regulated after infection with an intestinal nematode parasite,R Datta; C Hedeler; NW Paton; AM Brass; KJ Else,ABSTRACT Infection of resistant or susceptible mice with Trichuris muris provokesmesenteric lymph node responses which are polarized towards Th2 or Th1; respectively.These responses are well documented in the literature. In contrast; little is known about thelocal responses occurring within the infected intestine. Through microarray analyses; wedemonstrate that the gene expression profile of infected gut tissue differs according towhether the parasite is expelled or not. Genes differentially regulated postinfection inresistant BALB/c mice include several antimicrobial genes; in particular; intelectin (Itln). Incontrast; analyses in AKR mice which ultimately progress to chronic infection provideevidence for a Th1-dominated mucosa with up-regulated expression of genes regulated bygamma interferon. Increases in the expression of genes associated with tryptophan …,Infection and immunity,2005,86
Adaptive query processing: A survey,Anastasios Gounaris; Norman W Paton; Alvaro AA Fernandes; Rizos Sakellariou,Abstract In wide-area database systems; which may be running on unpredictable andvolatile environments (such as computational grids); it is difficult to produce efficientdatabase query plans based on information available solely at compile time. A solution tothis problem is to exploit information that becomes available at query runtime and adapt thequery plan to changing conditions during execution. This paper presents a survey onadaptive query processing techniques; examining the opportunities they offer to modify aplan dynamically and classifying them into categories according to the problem they focuson; their objectives; the nature of feedback they collect from the environment; the frequencyat which they can adapt; their implementation environment and which component isresponsible for taking the adaptation decisions.,British National Conference on Databases,2002,85
The SuBliMinaL Toolbox: automating steps in the reconstruction of metabolic networks,Neil Swainston; Kieran Smallbone; Pedro Mendes; Douglas B Kell; Norman W Paton,Summary The generation and use of metabolic network reconstructions has increased overrecent years. The development of such reconstructions has typically involved a time-consuming; manual process. Recent work has shown that steps undertaken inreconstructing such metabolic networks are amenable to automation.,Journal of integrative bioinformatics,2011,82
Improving sensitivity in proteome studies by analysis of false discovery rates for multiple search engines,Andrew R Jones; Jennifer A Siepen; Simon J Hubbard; Norman W Paton,Abstract LC-MS experiments can generate large quantities of data; for which a variety ofdatabase search engines are available to make peptide and protein identifications. Decoydatabases are becoming widely used to place statistical confidence in result sets; allowingthe false discovery rate (FDR) to be estimated. Different search engines produce differentidentification sets so employing more than one search engine could result in an increasednumber of peptides (and proteins) being identified; if an appropriate mechanism forcombining data can be defined. We have developed a search engine independent score;based on FDR; which allows peptide identifications from different search engines to becombined; called the FDR Score. The results demonstrate that the observed FDR issignificantly different when analysing the set of identifications made by all three search …,Proteomics,2009,82
An effective deductive object-oriented database through language integration,Maria L Barja; Norman W Paton; Alvaro AA Fernandes; M Howard Williams; Andrew Dinn,Abstract This paper presents an approach to the development of a practical deductiveobjectoriented database (DOOD) system based upon the integration of a logic querylanguage with an imperative programming language in the context of an object-orienteddata model. The approach is novel; in that a formally defined data model has been used asthe starting point for the development of the two languages. This has enabled a seamlessintegration of the two languages; which is the central theme of this paper. It is shown how thetwo languages have been developed from the underlying data model; and severalalternative approaches to their integration are presented; one of which has been chosen forimplementation. The approach is compared with other examples of language integration in adatabase context; and it is argued that the resulting system overcomes a number of …,VLDB,1994,82
CA DRE: the Central Aspergillus Data REpository,JE Mabey; MJ Anderson; Peter F Giles; Crispin J Miller; Terri K.  Attwood; Norman W.  Paton; Erich Bornberg‐Bauer; GD Robson; Stephen G.  Oliver; David W Denning,Abstract CA DRE is a public resource for housing and analysing genomic data extractedfrom species of Aspergillus. It arose to enable maintenance of the complete annotatedgenomic sequence of Aspergillus fumigatus and to provide tools for searching; analysingand visualizing features of fungal genomes. By implementing CA DRE using Ensembl; aframework is in place for storing and comparing several genomes: the resource will thusexpand by including other Aspergillus genomes (such as Aspergillus nidulans) as theybecome available. CA DRE is accessible at http://www. cadre. man. ac. uk.,Nucleic acids research,2004,80
The design and implementation of OGSA-DQP: A service-based distributed query processor,Steven Lynden; Arijit Mukherjee; Alastair C Hume; Alvaro AA Fernandes; Norman W Paton; Rizos Sakellariou; Paul Watson,Abstract Service-based approaches are rising to prominence because of their potential tomeet the requirements for distributed application development in e-business and e-science.The emergence of a service-oriented view of hardware and software resources raises thequestion as to how database management systems and technologies can best be deployedor adapted for use in such an environment. This paper explores one aspect of service-basedcomputing and data management; viz.; how to integrate query processing technology with aservice-based architecture suitable for a Grid environment. The paper addresses this bydescribing in detail the design and implementation of a service-based distributed queryprocessor. The query processor is service-based in two orthogonal senses: firstly; it supportsquerying over data storage and analysis resources that are made available as services …,Future Generation Computer Systems,2009,77
Automatic annotation of web services based on workflow definitions,Khalid Belhajjame; Suzanne M Embury; Norman W Paton; Robert Stevens; Carole A Goble,Abstract Semantic annotations of web services can support the effective and efficientdiscovery of services; and guide their composition into workflows. At present; however; thepractical utility of such annotations is limited by the small number of service annotationsavailable for general use. Manual annotation of services is a time consuming and thusexpensive task; so some means are required by which services can be automatically (orsemi-automatically) annotated. In this paper; we show how information can be inferred aboutthe semantics of operation parameters based on their connections to other (annotated)operation parameters within tried-and-tested workflows. Because the data links in theworkflows do not necessarily contain every possible connection of compatible parameters;we can infer only constraints on the semantics of parameters. We show that despite their …,ACM Transactions on the Web (TWEB),2008,70
Kaleidoquery: a visual query language for object databases,Norman Murray; Norman Paton; Carole Goble,Abstract In this paper we describe Kaleidoquery; a visual query language for objectdatabases with the same expressive power as OQL. We will describe the design philosophybehind the filter flow nature of Kaleidoquery and present each of the language's constructs;giving examples and relating them to OQL. The Kaleidoquery language is describedindependent of any implementation details; but a brief description of a 3D interface currentlyunder construction for Kaleidoquery is presented. The queries in this implementation of thelanguage are translated into OQL and then passed to the object database O 2 for evaluation.,Proceedings of the working conference on Advanced visual interfaces,1998,69
Design and implementation of ROCK & ROLL: a deductive object-oriented database system,Maria L Barja; Alvaro AA Fernandes; Norman W Paton; M Howard Williams; Andrew Dinn; Alia I Abdelmoty,Abstract This paper presents an approach to the development of a deductive object-orienteddatabase system; describing the key design decisions and their consequences forimplementation. The approach is novel; in that it integrates an object-oriented databasesystem manipulated using an imperative programming language (ROCK) with a logiclanguage for expressing queries and methods (ROLL). The integration is made seamless byderiving both the imperative and logic languages from a single formally defined data model;thereby avoiding impedance mismatches when they are integrated.,Information Systems,1995,67
Knowledge based information integration systems,Norman W.  Paton; Carole A.  Goble; Sean Bechhofer,Abstract Information integration systems provide facilities that support access toheterogeneous information sources in a way that isolates users from differences in theformats; locations and facilities of those sources. A number of systems have been proposedthat exploit knowledge based techniques to assist with information integration; but it is notalways obvious how proposals differ from each other in their scope; in the quality ofintegration afforded; or in the cost of exploitation. This paper presents a framework for thecomparison of proposals for information integration systems; and applies the framework to arange of representative proposals. It is shown that proposals differ greatly in all of the criteriastated and that the selection of an approach is thus highly dependent on the requirements ofspecific applications.,Information and Software Technology,2000,66
DEAR: a DEbugger for Active Rules in an object-oriented context,Oscar Diaz; Arturo Jaime; Norman Paton,Abstract Experience using active rules in database systems has shown that; while such rulescan be utilised beneficially in a range of applications; it is not a straightforward task toimplement; debug or maintain large rule bases. It is thus important for active rule systems toprovide debugging and explanation facilities for two reasons: to inform the user which activerules have been fired during the execution of an operation thereby increasing the user'sconfidence and understanding of the system; and to help the designer to refine and analyzeinteractions among rules at; execution time. The idiosyncrasies of the rule's flow of control;where the rules to be fired cannot be known in advance; introduce some requirementsdifferent from those found in debuggers for conventional programming languages. Thispaper presents an approach to the design and implementation of a debugger for active …,*,1994,65
Grid database access and integration: Requirements and functionalities,Malcolm P Atkinson; Vijay Dialani; Leanne Guy; Inderpal Narang; Norman W Paton; Dave Pearson; Tony Storey; Paul Watson,*,Global Grid Forum; Lemont; Illinois; USA; GFD-I,2003,60
A model of yeast glycolysis based on a consistent kinetic characterisation of all its enzymes,Kieran Smallbone; Hanan L Messiha; Kathleen M Carroll; Catherine L Winder; Naglis Malys; Warwick B Dunn; Ettore Murabito; Neil Swainston; Joseph O Dada; Farid Khan; Pınar Pir; Evangelos Simeonidis; Irena Spasić; Jill Wishart; Dieter Weichart; Neil W Hayes; Daniel Jameson; David S Broomhead; Stephen G Oliver; Simon J Gaskell; John EG McCarthy; Norman W Paton; Hans V Westerhoff; Douglas B Kell; Pedro Mendes,Abstract We present an experimental and computational pipeline for the generation ofkinetic models of metabolism; and demonstrate its application to glycolysis inSaccharomyces cerevisiae. Starting from an approximate mathematical model; we employ a“cycle of knowledge” strategy; identifying the steps with most control over flux. Kineticparameters of the individual isoenzymes within these steps are measured experimentallyunder a standardised set of conditions. Experimental strategies are applied to establish a setof in vivo concentrations for isoenzymes and metabolites. The data are integrated into amathematical model that is used to predict a new set of metabolite concentrations andreevaluate the control properties of the system. This bottom-up modelling study reveals thatcontrol over the metabolic network most directly involved in yeast glycolysis is more …,FEBS letters,2013,59
A semantically enabled service architecture for mashups over streaming and stored data,Alasdair JG Gray; Raúl García-Castro; Kostis Kyzirakos; Manos Karpathiotakis; Jean-Paul Calbimonte; Kevin Page; Jason Sadler; Alex Frazer; Ixent Galpin; Alvaro AA Fernandes; Norman W Paton; Oscar Corcho; Manolis Koubarakis; David De Roure; Kirk Martinez; Asunción Gómez-Pérez,Abstract Sensing devices are increasingly being deployed to monitor the physical worldaround us. One class of application for which sensor data is pertinent is environmentaldecision support systems; eg flood emergency response. However; in order to interpret thereadings from the sensors; the data needs to be put in context through correlation with othersensor readings; sensor data histories; and stored data; as well as juxtaposing with mapsand forecast models. In this paper we use a flood emergency response planning applicationto identify requirements for a semantic sensor web. We propose a generic servicearchitecture to satisfy the requirements that uses semantic annotations to support well-informed interactions between the services. We present the SemSor-Grid4Env realisation ofthe architecture and illustrate its capabilities in the context of the example application.,Extended Semantic Web Conference,2011,59
Conceptual data modelling for bioinformatics,Erich Bornberg-Bauer; Norman W Paton,Abstract Current research in the biosciences depends heavily on the effective exploitation ofhuge amounts of data. These are in disparate formats; remotely dispersed; and based on thedifferent vocabularies of various disciplines. Furthermore; data are often stored or distributedusing formats that leave implicit many important features relating to the structure andsemantics of the data. Conceptual data modelling involves the development ofimplementation independent models that capture and make explicit the principal structuralproperties of data. Entities such as a biopolymer or a reaction; and their relations; egcatalyses; can be formalised using a conceptual data model. Conceptual models areimplementation-independent and can be transformed in systematic ways for implementationusing different platforms; eg traditional database management systems. This paper …,Briefings in bioinformatics,2002,59
Workflow adaptation as an autonomic computing problem,Kevin Lee; Rizos Sakellariou; Norman W Paton; Alvaro AA Fernandes,Abstract The performance of long running scientific workflows stands to benefit fromadapting to changes in their environment. Autonomic Computing provides methodologies formanaging run-time adaptations in managed systems. In this paper; we apply the monitoring;analysis; planning and execution (MAPE) model from autonomic computing to support theruntime modification of workflows with the aim of improving their performance. Wesystematically identify run-time adaptations and indicate how such behaviours can becaptured using the MAPE model from the Autonomic Computing community. Bycharacterising these as autonomic computing problems we make a proposal about howworkflow adaptation can be achieved.,Proceedings of the 2nd workshop on Workflows in support of large-scale science,2007,58
Fine-grained and efficient lineage querying of collection-based workflow provenance,Paolo Missier; Norman W Paton; Khalid Belhajjame,Abstract The management and querying of workflow provenance data underpins a collectionof activities; including the analysis of workflow results; and the debugging of workflows orservices. Such activities require efficient evaluation of lineage queries over potentiallycomplex and voluminous provenance logs. Näive implementations of lineage queriesnavigate provenance logs by joining tables that represent the flow of data betweenconnected processors invoked from workflows. In this paper we provide an approach toprovenance querying that:(i) avoids joins over provenance logs by using information aboutthe workflow definition to inform the construction of queries that directly target relevantlineage results;(ii) provides fine grained provenance querying; even for workflows thatcreate and consume collections; and (iii) scales effectively to address complex workflows …,Proceedings of the 13th International Conference on Extending Database Technology,2010,57
On the use of agents in a bioinformatics grid,Luc Moreau; Simon Miles; Carole Goble; Mark Greenwood; Vijay Dialani; Matthew Addis; Nedim Alpdemir; Rich Cawley; David De Roure; Justin Ferris; Rob Gaizauskas; Kevin Glover; Chris Greenhalgh; Peter Li; Xiaojian Liu; Phillip Lord; Michael Luck; Darren Marvin; Tom Oinn; Norman Paton; Steve Pettifer; Milena V Radenkovic; Angus Roberts; Alan Robinson; Tom Rodden; Martin Senger; Nick Sharman; Robert Stevens; Brian Warboys; Anil Wipat; Chris Wroe,My Grid is an e-Science Grid project that aims to help biologists and bioinformaticians toperform workflow-based in silico experiments; and help them to automate the managementof such workflows through personalisation; notification of change and publication ofexperiments. In this paper; we describe the architecture of my Grid and how it will be used bythe scientist. We then show how my Grid can benefit from agents technologies. We haveidentified three key uses of agent technologies in my Grid: user agents; able to customizeand personalise data; agent communication languages offering a generic and portablecommunication medium; and negotiation allowing multiple distributed entities to reachservice level agreements.,Cluster Computing and the Grid; 2003. Proceedings. CCGrid 2003. 3rd IEEE/ACM International Symposium on,2003,57
Automated tracking of gene expression in individual cells and cell compartments,Hailin Shen; Glyn Nelson; David E Nelson; Stephnie Kennedy; David G Spiller; Tony Griffiths; Norman Paton; Stephen G Oliver; Michael RH White; Douglas B Kell,Many intracellular signal transduction processes involve the reversible translocation fromthe cytoplasm to the nucleus of transcription factors. The advent of fluorescently taggedprotein derivatives has revolutionized cell biology; such that it is now possible to follow thelocation of such protein molecules in individual cells in real time. However; the quantitativeanalysis of the location of such proteins in microscopic images is very time consuming. Wedescribe CellTracker; a software tool designed for the automated measurement of thecellular location and intensity of fluorescently tagged proteins. CellTracker runs in the MSWindows environment; is freely available (at http://www. dbkgroup. org/celltracker/); andcombines automated cell tracking methods with powerful image-processing algorithms thatare optimized for these applications. When tested in an application involving the nuclear …,Journal of The Royal Society Interface,2006,56
User interface modeling in UMLi,Paulo PINHEIRO DA SILVA; Norman W PATON,*,IEEE software,2003,56
User interface modelling with UML,Paulo Pinheiro Da Silva; Norman W Paton,Abstract. The Unified Modeling Language (UML) is a natural candidate for user interface (UI)modelling since it is the standard notation for object oriented modelling of applications.However; it is by no means clear how to model UIs using UML. This paper presents a userinterface modelling case study using UML. This case study identifies some aspects of UIsthat cannot be modelled using UML notation; and a set of UML constructors that may beused to model UIs. The modelling problems indicate some weaknesses of UML formodelling UIs; while the constructors exploited indicate some strengths. The identification ofsuch strengths and weaknesses can be used in the formulation of a strategy for extendingUML to provide greater support for user interface design.,FRONTIERS IN ARTIFICIAL INTELLIGENCE AND APPLICATIONS,2001,55
A logic-based integration of active and deductive databases,Alvaro AA Fernandes; M Howard Williams; Norman W Paton,Abstract A logic-based approach to the specification of active database functionality ispresented which not only endows active databases with a well-defined and well-understoodformal semantics; but also tightly integrates them with deductive databases. The problem ofendowing deductive databases with rule-based active behaviour has been addressed indifferent ways. Typical approaches include accounting for active behaviour by extending theoperational semantics of deductive databases; or; conversely; accounting for deductivecapabilities by constraining the operational semantics of active databases. The maincontribution of the paper is an alternative approach in which a class of active databases isdefined whose operational semantics is naturally integrated with the operational semanticsof deductive databases without either of them strictly subsuming the other. The approach …,New Generation Computing,1997,55
SNEE: a query processor for wireless sensor networks,Ixent Galpin; Christian YA Brenninkmeijer; Alasdair JG Gray; Farhana Jabeen; Alvaro AA Fernandes; Norman W Paton,Abstract A wireless sensor network (WSN) can be construed as an intelligent; large-scaledevice for observing and measuring properties of the physical world. In recent years; thedatabase research community has championed the view that if we construe a WSN as adatabase (ie; if a significant aspect of its intelligent behavior is that it can executedeclaratively-expressed queries); then one can achieve a significant reduction in the cost ofengineering the software that implements a data collection program for the WSN while stillachieving; through query optimization; very favorable cost: benefit ratios. This paperdescribes a query processing framework for WSNs that meets many desiderata associatedwith the view of WSN as databases. The framework is presented in the form ofcompiler/optimizer; called SNEE; for a continuous declarative query language over …,Distributed and Parallel Databases,2011,54
Five years of progress in the Standardization of Proteomics Data 4th Annual Spring Workshop of the HUPO‐Proteomics Standards Initiative April 23–25; 2007 Ecole...,Sandra Orchard; Luisa Montechi‐Palazzi; Eric W Deutsch; Pierre‐Alain Binz; Andrew R Jones; Norman Paton; Angel Pizarro; David M Creasy; Jérôme Wojcik; Henning Hermjakob,Abstract Over the last five years; the Human Proteome Organisation Proteomics StandardsInitiative (HUPO PSI) has produced and released community-accepted XML interchangeformats in the fields of mass spectrometry; molecular interactions and gel electrophoresis;have led the field in the discussion of the minimum information with which such data shouldbe annotated and are now in the process of publishing much of this information. At this 4 thSpring workshop; the emphasis was on consolidating this effort; refining and improving theexisting models and in pushing these forward to align with more broadly encompassingefforts such as FuGE (Jones; AR; Pizarro; A.; Spellman; P.; Miller; M.; FuGE Working GroupFuGE: Functional Genomics Experiment Object Model. OMICS 2006; 10; 179-184) and theOntology for Biomedical Investigation (OBI). The effort to merge the existing mass …,Proteomics,2007,54
User Feedback as a First Class Citizen in Information Integration Systems.,Khalid Belhajjame; Norman W Paton; Alvaro AA Fernandes; Cornelia Hedeler; Suzanne M Embury,ABSTRACT User feedback is gaining momentum as a means of addressing the difficultiesunderlying information integration tasks. It can be used to assist users in building informationintegration systems and to improve the quality of existing systems; eg; in dataspaces.Existing proposals in the area are confined to specific integration sub-problems consideringa specific kind of feedback sought; in most cases; from a single user. We argue in this paperthat; in order to maximize the benefits that can be drawn from user feedback; it should beconsidered and managed as a first class citizen. Accordingly; we present generic operationsthat underpin the management of feedback within information integration systems; and thatare applicable to feedback of different kinds; potentially supplied by multiple users withdifferent expectations. We present preliminary solutions that can be adopted for realizing …,CIDR,2011,53
Guidelines for reporting the use of gel electrophoresis in proteomics,Frank Gibson; Leigh Anderson; Gyorgy Babnigg; Mark Baker; Matthias Berth; Pierre-Alain Binz; Andy Borthwick; Phil Cash; Billy W Day; David B Friedman; Donita Garland; Howard B Gutstein; Christine Hoogland; Neil A Jones; Alamgir Khan; Joachim Klose; Angus I Lamond; Peter F Lemkin; Kathryn S Lilley; Jonathan Minden; Nicholas J Morris; Norman W Paton; Michael R Pisano; John E Prime; Thierry Rabilloud; David A Stead; Chris F Taylor; Hans Voshol; Anil Wipat; Andrew R Jones,We wish to alert your readers to the MIAPE Gel Electrophoresis (MIAPE-GE) guidelinesspecifying the minimum information that should be provided when reporting the use of n-dimensional gel electrophoresis in a proteomics experiment. Developed through a jointeffort between the gelbased analysis working group of the Human Proteome Organisation'sProteomics Standards Initiative (HUPO-PSI; http://www. psidev. info/) and the widerproteomics community; they constitute one part of the overall Minimum Information about aProteomics Experiment (MIAPE) documentation system published last August in Nature,Nature biotechnology,2008,53
ADAM: An object-oriented database system implemented in Prolog,Norman W Paton,*,Proceedings of the seventh British national conference on Databases,1990,53
SBRML: a markup language for associating systems biology data with models,Joseph O Dada; Irena Spasić; Norman W Paton; Pedro Mendes,Abstract Motivation: Research in systems biology is carried out through a combination ofexperiments and models. Several data standards have been adopted for representingmodels (Systems Biology Markup Language) and various types of relevant experimentaldata (such as FuGE and those of the Proteomics Standards Initiative). However; until now;there has been no standard way to associate a model and its entities to the correspondingdatasets; or vice versa. Such a standard would provide a means to represent computationalsimulation results as well as to frame experimental data in the context of a particular model.Target applications include model-driven data analysis; parameter estimation; and sharingand archiving model simulations. Results: We propose the Systems Biology Results MarkupLanguage (SBRML); an XML-based language that associates a model with several …,Bioinformatics,2010,51
GIMS: an integrated data storage and analysis environment for genomic and functional data,Michael Cornell; Norman W Paton; Cornelia Hedeler; Paul Kirby; Daniela Delneri; Andrew Hayes; Stephen G Oliver,Abstract Effective analyses in functional genomics require access to many kinds of biologicaldata. For example; the analysis of upregulated genes in a microarray experiment might beaided by information concerning protein interactions or proteins' cellular locations. However;such information is often stored in different formats at different sites; in ways that may not beamenable to integrated analysis. The Genome Information Management System (GIMS) isan object database that integrates genomic data with data on the transcriptome; protein–protein interactions; metabolic pathways and annotations; such as gene ontology terms andidentifiers. The resulting system supports the running of analyses over this integrated dataresource; and provides comprehensive facilities for handling and interrelating the results ofthese analyses. GIMS has been used to store Saccharomyces cerevisiae data; and we …,Yeast,2003,51
Distributed query processing on the grid,Jim Smith; Paul Watson; Anastasios Gounaris; Norman W Paton; Alvaro AA Fernandes; Rizos Sakellariou,Distributed query processing (DQP) has been widely used in data intensive applicationswhere data of relevance to users are stored at multiple locations. This paper argues:(i) thatDQP can be important in the Grid; as a means of providing high-level; declarative languagesfor integrating data access and analysis; and (ii) that the Grid provides resourcemanagement facilities that are useful to developers of DQP systems. As well as discussingand illustrating how DQP technologies can be deployed within the Grid; the paper describesPolar*; a prototype implementation of a DQP system running over Globus. Polar* can handlecomplex data by adopting the ODMG object model and its query language OQL; whichsupports the invocation of user-defined operations. The Globus components are accessedthrough the MPICH-G interface rather than in a lower level way. A case study from …,The International Journal of High Performance Computing Applications,2003,51
The design and implementation of grid database services in ogsa-dai,A Anjomshoaa; M Antonioletti; M Atkinson; R Baxter; A Borley; N Hong; B Collins; N Hardman; G Hicken; A Hume; A Knox; M Jackson; A Krause; S Laws; J Magowan; C Palansuriya; N Paton; D Pearson; T Sugden; P Watson; M Westhead,Abstract This paper presents a high-level overview of the design and implementation of thecore components of the OGSA-DAI project. It describes the design decisions made; theproject's interaction with the Data Access and Integration Working Group of the Global GridForum and provides an overview of implementation characteristics. Further details of theimplementation are provided in the extensive documentation available from the project website.,Proc. UK e-Science All Hands Meeting,2003,51
Formal specification of active database functionality: A survey,Norman W Paton; Jack Campin; Alvaro AA Fernandes; M Howard Williams,Abstract This paper reviews research on the formal specification of active behaviour;indicating both what has been done in this area; and how. The scope of differentapproaches is compared within a common framework; which reveals that although manyaspects of active behaviour have been described formally; no single proposal covers allphenomena associated with active database systems.,International Workshop on Rules in Database Systems,1995,50
Deduction and deductive databases for geographic data handling,Alia I Abdelmoty; M Howard Williams; Norman W Paton,Abstract The representation of complex spatial domains in conventional databases suffersfrom fragmented representation of object structure; lack of instance-level spatialrelationships; and the generation of large combinatoric search spaces in query analysis. Thedeductive capabilities provided by a deductive database offer some assistance in solvingthese problems; in particular by enabling spatial reasoning to be performed by a GeographicInformation System (GIS). Deduction in the database is used to support the naturalrepresentation of complex spatial object structures in single and multi-layered GeographicDataBases (GDB); inference of implicit spatial relationships; and the manipulation of multipleresolution spatial representations. In addition; deductive capabilities are shown to beessential for automatic data input and update in a GDB. Coupled with appropriate …,International Symposium on Spatial Databases,1993,50
Adapting to changing resource performance in grid query processing,Anastasios Gounaris; Jim Smith; Norman W Paton; Rizos Sakellariou; Alvaro AA Fernandes; Paul Watson,Abstract The Grid provides facilities that support the coordinated use of diverse resources;and consequently; provides new opportunities for wide-area query processing. However;Grid resources; as well as being heterogeneous; may also exhibit unpredictable; volatilebehaviour. Thus; query processing on the Grid needs to be adaptive; in order to cope withevolving resource characteristics; such as machine load. To address this challenge; anarchitecture is proposed that has been empirically evaluated over a prototype Grid-enabledadaptive query processor instantiating it.,Workshop on Data Management in Grids,2005,48
The WS-DAI family of specifications for web service data access and integration,Mario Antonioletti; Amy Krause; Norman W Paton; Andrew Eisenberg; Simon Laws; Susan Malaika; Jim Melton; Dave Pearson,Page 1. The WS-DAI Family of Specifications for Web Service Data Access and Integration MarioAntonioletti; Amy Krause EPCC; University of Edinburgh; Edinburgh EH9 3JZ; UK (mario;amrey)@epcc.ed.ac.uk Simon Laws IBM; Hursley Park Winchester; SO21 2JN; UKsimon_laws@uk.ibm.com Norman W. Paton School of Computer Science; University ofManchester; Manchester M13 9PL; UK norm@cs.manchester.ac.uk Susan Malaika IBM; SanJose; CA 95141; USA malaika@us.ibm.com Dave Pearson Oracle Corp;Thames Valley Park;Reading; RG6 1RA; UK Dave.Pearson@oracle.com Andrew Eisenberg IBM; Westford; MA 01886andrew.eisenberg@us.ibm.com Jim Melton Oracle Corp.; Sandy; UT 84093 jim.melton@acm.org Guest Column Introduction This month; we are pleased to provide to our readers a columnthat addresses an important aspect of grid computing: data access …,ACM SIGMOD Record,2006,47
GIMS-a data warehouse for storage and analysis of genome sequence and functional data,Mike Cornell; Norman W Paton; Shengli Wu; Carole A Goble; Crispin J Miller; Paul Kirby; Karen Eilbeck; Andy Brass; Andrew Hayes; Stephen G Oliver,Effective analysis of genome sequences and associated functional data requires access tomany different kinds of biological information. For example; when analysing geneexpression data; it may be useful to have access to the sequences upstream of the genes; orto the cellular location of their protein products. Such information is currently stored indifferent formats at different sites in a way that does not readily allow integrated analyses.The Genome Information Management System (GIMS) is an object database that integratesgenome sequence data with functional data on the transcriptome and on protein-proteininteractions in a single data warehouse. We have used GIMS to store the Saccharomycescerevisiae (yeast) genome and to demonstrate how the integrated storage of diverse kindsof genomic data can be beneficial for analysing data using context-rich queries and …,Bioinformatics and Bioengineering Conference; 2001. Proceedings of the IEEE 2nd International Symposium on,2001,47
Generating user interface code in a model based user interface development environment,Paulo Pinheiro da Silva; Tony Griffiths; Norman W Paton,Abstract Declarative models play an important role in most software design activities; byallowing designs to be constructed that selectively abstract over complex implementationdetails. In the user interface setting; Model-Based User Interface Development Environments(MB-UIDEs) provide a context within which declarative models can be constructed andrelated; as part of the interface design process. However; such declarative models are notusually directly executable; and may be difficult to relate to existing software components. Itis therefore important that MB-UIDEs both fit in well with existing software architectures andstandards; and provide an effective route from declarative interface specification to runninguser interfaces. This paper describes how user interface software is generated fromdeclarative descriptions in the Teallach MB-UIDE. Distinctive features of Teallach include …,Proceedings of the working conference on Advanced visual interfaces,2000,47
Feedback-based annotation; selection and refinement of schema mappings for dataspaces,Khalid Belhajjame; Norman W Paton; Suzanne M Embury; Alvaro AA Fernandes; Cornelia Hedeler,Abstract The specification of schema mappings has proved to be time and resourceconsuming; and has been recognized as a critical bottleneck to the large scale deploymentof data integration systems. In an attempt to address this issue; dataspaces have beenproposed as a data management abstraction that aims to reduce the up-front cost requiredto setup a data integration system by gradually specifying schema mappings throughinteraction with end users in a pay-as-you-go fashion. As a step in this direction; we explorean approach for incrementally annotating schema mappings using feedback obtained fromend users. In doing so; we do not expect users to examine mapping specifications; rather;they comment on results to queries evaluated using the mappings. Using annotationscomputed on the basis of user feedback; we present a method for selecting from the set of …,Proceedings of the 13th International Conference on Extending Database Technology,2010,46
The Teallach tool: using models for flexible user interface design,Peter J Barclay; Tony Griffiths; Jo McKirdy; Norman W Paton; Richard Cooper; Jessie Kennedy,Abstract Model-based user interface development environments aim to provide designerswith a more systematic approach to user interface development using a particular designmethod. This method is realised through tools which support the construction and linkage ofthe supported models. This paper presents the tools which support the construction of theTeallach models in the context of the Teallach design method. Distinctive features of theTeallach tool include comprehensive facilities for relating the different models; and theprovision of a flexible design method in which models can be constructed and related bydesigners in different orders and in different ways.,*,1999,45
Ogsa-dqp: A service-based distributed query processor for the grid,M Nedim Alpdemir; Arijit Mukherjee; Norman W Paton; Paul Watson; AA Fernandes; Anastasios Gounaris; Jim Smith,Abstract The Grid is an emerging infrastructure that supports the discovery; access and useof distributed computational resources. The emergence of a serviceoriented view ofhardware and software resources on the grid raises the question as to how databasemanagement systems and technologies can best be deployed or adapted for use in such anenvironment. We argue that distributed query processing (DQP) can provide effectivedeclarative support for service orchestration; and we describe an approach to service-basedDQP (OGSA-DQP) on the Grid that supports queries over Grid Data Services (GDS) sprovided by OGSA-DAI project; and over other services available on the Grid; therebycombining data access with analysis; uses the facilities of the OGSA to dynamically obtainthe resources necessary for efficient evaluation of a distributed query; adapts techniques …,Proc. of UK e-Science All Hands Meeting Nottingham,2003,44
Query processing with description logic ontologies over object-wrapped databases,Martin Peim; Enrico Franconi; Norman W Paton; Carole A Goble,This paper presents an approach to answering queries over an ontology modelled using adescription logic. The ontology acts as a global schema; providing a declarative descriptionof the concepts of the domain; the instances of which are stored in (potentially many) object-wrapped sources. Queries are expressed using terms from the rich vocabulary of theontology; and are translated into an equivalent calculus expression; which references onlythe objects available in the source databases. The query is then optimized on the basis ofinformation from the ontology and the source databases. Distinctive features of the approachinclude: the use of the expressive ALCQI description logic; which supports both ontologydefinition and query expression; the adoption of a global-as-view approach to relating theontology to the sources; and the use of the ontology to direct semantic optimization of …,Scientific and Statistical Database Management; 2002. Proceedings. 14th International Conference on,2002,44
The PSI formal document process and its implementation on the PSI website,Juan Antonio Vizcaíno; Lennart Martens; Henning Hermjakob; Randall K Julian; Norman W Paton,Abstract The Human Proteome Organisation's Proteomics Standards Initiative (HUPO-PSI)has recently developed formal document processes for reviewing MIAPE documents;specifications; community practice and informational documents. These document workflowsrely on community participation as well as more traditional expert review. We here presentthe web interface used to support these document processes; and explain briefly howinterested parties can participate in the review process. The HUPO-PSI website can befound at http://www. psidev. info.,Proteomics,2007,43
Resource scheduling for parallel query processing on computational grids,Anastasios Gounaris; Rizos Sakellariou; Norman W Paton; Alvaro AA Fernandes,Abstract Advances in network technologies and the emergence of Grid computing have bothincreased the need and provided the infrastructure for computation and data intensiveapplications to run over collections of heterogeneous and autonomous nodes. In the contextof database query processing; existing parallelisation techniques cannot operate well inGrid environments because the way they select machines and allocate tasks compromisespartitioned parallelism. The main contribution of this paper is the proposal of a low-complexity; practical resource selection and scheduling algorithm that enables queries toemploy partitioned parallelism; in order to achieve better performance in a Grid setting.,Proceedings of the 5th IEEE/ACM International Workshop on Grid Computing,2004,43
Data access; integration; and management,Malcolm Atkinson; Ann L Chervenak; Peter Kunszt; Inderpal Narang; Norman W Paton; Dave Pearson; Arie Shoshani; P Wilson,D igital data are now fundamental to all branches of science and engineering; such dataplay a major role in medical research and diagnosis and underpin business andgovernmental decision processes. Increasingly; these data are organized as shared andstructured collections held in databases; XML docu-ments; and structured assemblies ofbinary files. Driven by advances in simulation and sensor technology (Chapter 2); datacollections have grown to the extent that multiple terabyte-sized; and soon petabyte-sized;collections of data are becoming prevalent (359). The sheer size of datasets beinggenerated makes the interpretation of the data in any one collection challenging. Analysismay demand teraflops of com-pute power and require access to terabytes of data distributedacross millions of binary files and multiple databases. Furthermore; analysis may require …,The Grid: Blueprint for a New Computing Infrastructure,2003,43
Autonomic query parallelization using non-dedicated computers: an evaluation of adaptivity options,Norman W Paton; Jorge Buenabad-Chavez; Mengsong Chen; Vijayshankar Raman; Garret Swart; Inderpal Narang; Daniel M Yellin; Alvaro A Fernandes,Abstract Writing parallel programs that can take advantage of non-dedicated processors ismuch more difficult than writing such programs for networks of dedicated processors. In anon-dedicated environment such programs must use autonomic techniques to respond tothe unpredictable load fluctuations that prevail in the computational environment. In adaptivequery processing (AQP); several techniques have been proposed for dynamicallyredistributing processor load assignments throughout a computation to take account ofvarying resource capabilities; but we know of no previous study that compares theirperformance. This paper presents a simulation-based evaluation of these autonomicparallelization techniques in a uniform environment and compares how well they improvethe performance of the computation. Four published strategies are compared with a new …,The VLDB Journal—The International Journal on Very Large Data Bases,2009,42
A semantics for a query language over sensors; streams and relations,Christian YA Brenninkmeijer; Ixent Galpin; Alvaro AA Fernandes; Norman W Paton,Abstract We introduce a query language over sensors; streams and relations and formallydescribe its semantics. Although the language was specifically designed for sensor networkquerying; where data is pulled into streams; the semantics contributed in the paper alsoencompasses the case in which data is pushed onto streams or else lies stored in classicalrelations. The approach taken is that continuous queries over streams are an extension ofclassical queries over stored extents. Apart from the fact that query evaluation over streamsis reactive; or periodic; the main difference is the conception of windows as an additionalcollection type with the consequent use of type converter operations to and from streamsand windows (which; as bounded collections of tuples; can be operated on in a relational-algebraic setting). The language and the semantics we provide for it advance on previous …,British National Conference on Databases,2008,41
A novel approach to resource scheduling for parallel query processing on computational grids,Anastasios Gounaris; Rizos Sakellariou; Norman W Paton; Alvaro AA Fernandes,Abstract Advances in network technologies and the emergence of Grid computing have bothincreased the need and provided the infrastructure for computation and data intensiveapplications to run over collections of heterogeneous and autonomous nodes. In the contextof database query processing; existing parallelisation techniques cannot operate well inGrid environments because the way they select machines and allocate tasks compromisespartitioned parallelism. The main contribution of this paper is the proposal of a low-complexity; practical resource selection and scheduling algorithm that enables queries toemploy partitioned parallelism; in order to achieve better performance in a Grid setting. Theevaluation results show that the scheduler proposed outperforms current techniques withoutsacrificing the efficiency of resource utilisation.,Distributed and Parallel Databases,2006,41
MOVIE: An incremental maintenance system for materialized object views,M Akhtar Ali; Alvaro AA Fernandes; Norman W Paton,Abstract View materialization is an important technique for high performance queryprocessing; data integration and replication. Solutions to the problem of incrementallymaintaining materialized views are very relevant. So far; most work on this problem hasbeen confined to relational settings and solutions have not been comprehensivelyevaluated. This paper describes MOVIE; a complete; implemented and evaluated solution tothe problem of incrementally maintaining materialized OQL views in ODMG-compliant objectdatabases. The evaluation throws light into how the effectiveness of incrementalmaintenance is affected by issues such as database size; and the complexity and selectivityof views.,Data & Knowledge Engineering,2003,41
e-Fungi: a data resource for comparative analysis of fungal genomes,Cornelia Hedeler; Han Min Wong; Michael J Cornell; Intikhab Alam; Darren M Soanes; Magnus Rattray; Simon J Hubbard; Nicholas J Talbot; Stephen G Oliver; Norman W Paton,The number of sequenced fungal genomes is ever increasing; with about 200 genomesalready fully sequenced or in progress. Only a small percentage of those genomes havebeen comprehensively studied; for example using techniques from functional genomics.Comparative analysis has proven to be a useful strategy for enhancing our understanding ofevolutionary biology and of the less well understood genomes. However; the data requiredfor these analyses tends to be distributed in various heterogeneous data sources; makingsystematic comparative studies a cumbersome task. Furthermore; comparative analysesbenefit from close integration of derived data sets that cluster genes or organisms in a waythat eases the expression of requests that clarify points of similarity or difference betweenspecies. To support systematic comparative analyses of fungal genomes we have …,BMC genomics,2007,40
Kaleidoquery—a flow-based visual language and its evaluation,Norman S Murray; Norman W Paton; Carole A Goble; Joanne Bryce,Abstract This paper describes the Kaleidoquery visual query language for object databasesand its comparative evaluation with object query language (OQL). The design philosophybehind the filter flow nature of Kaleidoquery and each of the language's constructs isdescribed; and examples are given that allow comparisons to be made with OQL. This isfollowed by a description of an experiment with the Kaleidoquery and OQL languages. Twogroups of subjects; programmers and non-programmers; were taught aspects of OQL andKaleidoquery; and then tested under experimental conditions. Results show that bothgroups answered significantly more correct queries using certain constructs of theKaleidoquery language.,Journal of Visual Languages & Computing,2000,40
INTERACT: an object oriented protein-protein interaction database.,Karen Eilbeck; Andy Brass; Norman W Paton; Charlie Hodgman,Abstract Motivation: Protein-protein interactions provide vital information concerning thefunction of proteins; complexes and networks. Currently there is no widely acceptedrepository of this interaction information. Our aim is to provide a single database with thenecessary architecture to fully store; query and analyse interaction data. Results: An objectoriented database has been created which provides scientists with a resource for examiningexisting protein-protein interactions and inferring possible interactions from the data stored.It also provides a basis for examining networks of interacting proteins; via analysis of thedata stored. The database contains over a thousand interactions. Contact: k. eilbeck@ stud.man. ac. uk,ISMB,1999,40
Combining active rules and metaclasses for enhanced extensibility in object-oriented systems,Norman W Paton; Oscar Diaz; Maria L Barja,Abstract This paper is concerned with techniques for supporting extensibility in object-oriented data models. It has been recognised for a number of years that; in systems whichsupport metaclasses as first-class objects; extensibility can be achieved by usingspecialisation to refine built-in object creation behaviour. At the same time; research intoactive rules has indicated the utility of mapping high-level descriptions of functionality ontoactive rules for evaluation. This paper proposes the integration of these two techniques;arguing that certain constructs which would be difficult to represent using either one alonecan be supported effectively by a judicious mixing of the two.,Data & Knowledge Engineering,1993,38
The Tripod spatio-historical data model,Tony Griffiths; Alvaro AA Fernandes; Norman W Paton; Robert Barr,Abstract The storage and analysis of large amounts of time-varying spatial and aspatial datais becoming an important feature of many application domains. This has fuelled the need forspatio-temporal extensions to data models and their associated querying facilities. To date;much of this work has focused on the relational data model; with object data modelsreceiving far less consideration. Where descriptions of such object models do exist; thesemodels fail to fully integrate their spatial; aspatial and temporal dimensions into a uniformand coherent model. In addition; there is currently a lack of systems which build upon thesemodels to produce database architectures that address the broad spectrum of issues relatedto the delivery of a fully functional spatio-temporal DBMS. This paper presents a foundationfor the development of such a system; called Tripod; by describing a spatio-historical …,Data & Knowledge Engineering,2004,36
A UML-based design environment for interactive applications,P Pinheiro da Silva; Norman W Paton,The Unified Modeling Language (UML) can be used for modelling both the structure andbehaviour of software applications. However; although UML supports many differentmodelling notations; minimal support is provided for user interface (UI) design. The UnifiedModeling Language for Interactive Applications (UMLi) is an extension of UML that providessupport for UI design. UMLi has a user interface diagram for modelling abstract UIpresentations and an extended activity diagram that provides constructors for modellingcommon UI behaviours. The paper presents the support provided for UI design by the UMLidesign environment. Designers can use the environment to model applications and their UIsusing UML and its extensions in UMLi. The tool provides facilities for modelling interactionobjects; and the collaboration of these interaction objects with domain objects.,User Interfaces to Data Intensive Systems; 2001. UIDIS 2001. Proceedings. Second International Workshop on,2001,36
Comprehensive optimization of declarative sensor network queries,Ixent Galpin; Christian YA Brenninkmeijer; Farhana Jabeen; Alvaro AA Fernandes; Norman W Paton,Abstract We present a sensor network query processing architecture that covers all thequery optimization phases that are required to map a declarative query to executable code.The architecture is founded on the view that a sensor network truly is a distributed computinginfrastructure; albeit a very constrained one. As such; we address the problem of how todevelop a comprehensive optimizer for an expressive declarative continuous querylanguage over acquisitional streams as one of finding extensions to classical distributedquery processing techniques that contend with the peculiarities of sensor networks as anenvironment for distributed computing.,International Conference on Scientific and Statistical Database Management,2009,35
Complex query formulation over diverse information sources in TAMBIS,Robert Stevens; Carole Goble; Norman W Paton; Sean Bechhofer; Gary Ng; Patricia Baker; Andy Brass,Abstract Biologists increasingly need to ask complex questions over the large number ofdata and analysis tools that are available on the Internet. To do this; the individual resourcesneed to be made to work together. The knowledge needed to accomplish this; for exampleabout the locations of the sources and their capabilities; places barriers between biologistsand the questions they would like to ask. The TAMBIS project (Transparent Access toMultiple Bioinformatics Information Sources) has sought to remove some of these barriers;thereby making the process of asking questions against multiple sources morestraightforward. Central to the TAMBIS system is an ontology of bioinformatics and biologicalterms. Users express retrieval requests in terms of the concepts and relationships describedin the ontology; rather than by making direct reference to individual sources. This allows …,Bioinformatics: Managing Scientific Data. Morgan Kaufmann,2003,35
A framework for describing visual interfaces to databases,Norman Murray; Carole Goble; Norman W Paton,Abstract In the field of HCI there exist many formalisms for analysing; describing andevaluating interactive systems. However; in developing and evaluating user interfaces todatabases; we found it necessary to be able to describe presentation and interactionaspects that are catered for poorly or not at all in current formalisms. This paper presents aframework for the systematic description of data model; presentation and interactioncomponents that together form a graphical user interface. The utility of the framework is thendemonstrated by showing how it can be used to describe two existing visual queryinterfaces. These examples show that the framework provides a systematic method for theconcise description of graphical interfaces to databases that can be used either duringinterface design or as a communication aid.,Journal of Visual Languages & Computing,1998,35
Dimensions of dataspaces,Cornelia Hedeler; Khalid Belhajjame; Alvaro AA Fernandes; Suzanne M Embury; Norman W Paton,Abstract The vision of dataspaces has been articulated as providing various of the benefitsof classical data integration; but with reduced up-front costs; combined with opportunities forincremental refinement; enabling a “pay as you go” approach. However; results that seek torealise the vision exhibit considerable variety in their contexts; priorities and techniques; tothe extent that the definitional characteristics of dataspaces are not necessarily becomingclearer over time. With a view to clarifying the key concepts in the area; encouraging the useof consistent terminology; and enabling systematic comparison of proposals; this paperdefines a collection of dimensions that capture both the components that a dataspacemanagement system may contain and the lifecycle it may support; and uses thesedimensions to characterise representative proposals.,British National Conference on Databases,2009,34
Facilitating the development of controlled vocabularies for metabolomics technologies with text mining,Irena Spasić; Daniel Schober; Susanna-Assunta Sansone; Dietrich Rebholz-Schuhmann; Douglas B Kell; Norman W Paton,Many bioinformatics applications rely on controlled vocabularies or ontologies toconsistently interpret and seamlessly integrate information scattered across publicresources. Experimental data sets from metabolomics studies need to be integrated with oneanother; but also with data produced by other types of omics studies in the spirit of systemsbiology; hence the pressing need for vocabularies and ontologies in metabolomics.However; it is time-consuming and non trivial to construct these resources manually. Wedescribe a methodology for rapid development of controlled vocabularies; a study originallymotivated by the needs for vocabularies describing metabolomics technologies. We presentcase studies involving two controlled vocabularies (for nuclear magnetic resonancespectroscopy and gas chromatography) whose development is currently underway as …,BMC bioinformatics,2008,33
A semantic sensor web for environmental decision support applications,Alasdair JG Gray; Jason Sadler; Oles Kit; Kostis Kyzirakos; Manos Karpathiotakis; Jean-Paul Calbimonte; Kevin Page; Raúl García-Castro; Alex Frazer; Ixent Galpin; Alvaro AA Fernandes; Norman W Paton; Oscar Corcho; Manolis Koubarakis; David De Roure; Kirk Martinez; Asunción Gómez-Pérez,Abstract: Sensing devices are increasingly being deployed to monitor the physical worldaround us. One class of application for which sensor data is pertinent is environmentaldecision support systems; eg; flood emergency response. For these applications; the sensorreadings need to be put in context by integrating them with other sources of data about thesurrounding environment. Traditional systems for predicting and detecting floods rely onmethods that need significant human resources. In this paper we describe a semanticsensor web architecture for integrating multiple heterogeneous datasets; including live andhistoric sensor data; databases; and map layers. The architecture provides mechanisms fordiscovering datasets; defining integrated views over them; continuously receiving data inreal-time; and visualising on screen and interacting with the data. Our approach makes …,Sensors,2011,32
Systematic integration of experimental data and models in systems biology,Peter Li; Joseph O Dada; Daniel Jameson; Irena Spasic; Neil Swainston; Kathleen Carroll; Warwick Dunn; Farid Khan; Naglis Malys; Hanan L Messiha; Evangelos Simeonidis; Dieter Weichart; Catherine Winder; Jill Wishart; David S Broomhead; Carole A Goble; Simon J Gaskell; Douglas B Kell; Hans V Westerhoff; Pedro Mendes; Norman W Paton,The behaviour of biological systems can be deduced from their mathematical models.However; multiple sources of data in diverse forms are required in the construction of amodel in order to define its components and their biochemical reactions; and correspondingparameters. Automating the assembly and use of systems biology models is dependentupon data integration processes involving the interoperation of data and analyticalresources. Taverna workflows have been developed for the automated assembly ofquantitative parameterised metabolic networks in the Systems Biology Markup Language(SBML). A SBML model is built in a systematic fashion by the workflows which starts with theconstruction of a qualitative network using data from a MIRIAM-compliant genome-scalemodel of yeast metabolism. This is followed by parameterisation of the SBML model with …,BMC bioinformatics,2010,32
Pedro: a configurable data entry tool for XML,Kevin L Garwood; Chris F Taylor; Kai J Runte; Andy Brass; Stephen G Oliver; Norman W Paton,Abstract Summary: Pedro is a Java™ application that dynamically generates data entryforms for data models expressed in XML Schema; producing XML data files that validateagainst this schema. The software uses an intuitive tree-based navigation system; cansupply context-sensitive help to users and features a sophisticated interface for populatingdata fields with terms from controlled vocabularies. The software also has the ability toimport records from tab delimited text files and features various validation routines.Availability: The application; source code; example models from several domains andtutorials can be downloaded from http://pedro. man. ac. uk/,Bioinformatics,2004,32
Tripod: a comprehensive system for the management of spatial and aspatial historical objects,Tony Griffiths; Alvaro AA Fernandes; Norman W Paton; Bo Huang; Mike Worboys; Chris Johnson; Keith T Mason; John Stell,Abstract Spatio-temporal databases have been the focus of considerable research attentionin recent years. To date; much of this work has focused on the relational data model; withobject data models receiving far less consideration. Where descriptions of such objectmodels do exist; there is currently a lack of systems that build upon these models to producedatabase architectures that address the broad spectrum of issues related to the delivery for afully fuctional spatio-temporal DBMS. This paper presents an overview of such a system bydescribing a spatio-historical object DBMS that utilises a specialised mechanism; called ahistory; for maintaining knowledge about entities that change over time. Key features of theresulting proposal include:(i) consistent representations of primitive spatial and temporaltypes;(ii) a component-based design in which spatial; temporal and historical extensions …,Proceedings of the 9th ACM international symposium on Advances in geographic information systems,2001,31
Geographic data handling in a deductive object-oriented database,Alia I Abdelmoty; Norman W Paton; M Howard Williams; Alvaro AA Fernandes; Maria L Barja; Andrew Dinn,Abstract This paper describes how a deductive object-oriented database (DOOD) can beused to support the storage and management of data which is typical of that found ingeographic information systems (GIS). This is done with two aims in mind: to illustrate how acombination of deductive and object-oriented facilities can be applied effectively in anadvanced application; thereby motivating the development of DOOD systems; and to showhow geographic database systems stand to gain from the utilisation of advanced datamodelling and inference facilities as supported by a DOOD. The paper describes the DOODsystem which has been used for prototyping a range of geographic concepts; presents aframework for the structural organisation of GIS data using an object-oriented data model;and shows how a logic query language can be used within this structural framework to …,International Conference on Database and Expert Systems Applications,1994,31
Supporting dynamic displays using active rules,Oscar Díaz; Arturo Jaime; Norman W Paton; Ghassan al-Qaimari,Abstract In a graphical interface which is used to display database objects; dynamic displaysare updated automatically as modifications occur to the database objects being visualised.Approaches based on enlarging either the database system or the interface code to providethe appropriate communication; complicates the interaction between the two systems; aswell as making later updates cumbersome. In this paper; an approach based on active rulesis presented. The declarative and modular description of active rules enables active displaysto be supported with minimal changes to the database or its graphical interface. Althoughthis approach has been used to support the link between a database system and itsgraphical interface; it can easily be adapted to support dynamic interaction between anactive database system and other external systems.,ACM Sigmod Record,1994,31
Approaches to deductive object-oriented databases,Alvaro AA Fernandes; Norman W Paton; M Howard Williams; Andrew Bowles,Abstract The paper is concerned with the problem of combining deductive and object-oriented features to produce a deductive object-oriented database system which iscomparable to those currently available under the relational view of data modelling not onlyin its functionality but also in the techniques employed in its construction and use. Under thisassumption; the kinds of issues that have to be tackled for a similar research strategy toproduce comparable results are highlighted. The authors motivate their terms of comparison;characterize three broad approaches to deductive object-oriented databases and introducethe notion of language convergence to help in the characterization of some shortcomingsthat have been perceived in them. Three proposals that have come to light in the past threeyears are looked into in some detail; in so far as they exemplify some of the positions in …,Information and Software Technology,1992,31
Grid data service specification,Mario Antonioletti; Malcolm Atkinson; Susan Malaika; Simon Laws; Normal Paton; Dave Pearson; Greg Riccardi,Abstract Data management systems are central to many applications across multipledomains; and play a significant role in many others. Web services provide implementationneutral facilities for describing; invoking and orchestrating collections of networkedresources. The Open Grid Services Architecture (OGSA) extends Web Services withconsistent interfaces for creating; managing and exchanging information among GridServices; which are dynamic computational artifacts cast as Web Services. Both Web andGrid service communities stand to benefit from the provision of consistent; agreed serviceinterfaces to database management systems. Such interfaces must support the descriptionand use of database systems using Web Service standards; taking account of the designconventions and mandatory features of Grid Services. This document presents a …,Global Grid Forum GWD-R,2003,30
Exploiting model-based techniques for user interfaces to databases,Tony Griffiths; Jo McKirdy; G Forrester; N Paton; J Kennedy; P Barclay; Richard Cooper; C Goble; P Gray,Abstract Model-based systems provide methods for supporting the systematic and efficientdevelopment of application interfaces. This paper examines how model-based technologiescan be exploited to develop user interfaces to databases. To this end five model-basedsystems; namely Adept; HUMANOID; Mastermind; TADEUS and DRIVE are discussedthrough the use of a unifying case study which allows the examination of the approachesfollowed by the different systems.,*,1998,30
A new architecture for OGSA-DAI,Malcolm Atkinson; K Karasavvas; M Antonioletti; R Baxter; A Borley; N Chue Hong; A Hume; M Jackson; A Krause; S Laws; N Paton; J Schopf; T Sugden; K Tourlas; P Watson,Abstract OGSA-DAI is a widely used middleware infrastructure; aligned with the Global GridForum's (GGF) OGSA vision; to facilitate uniform access to data resources using a service-oriented architecture (SOA). It is intended to provide a reference implementation of WS-DAI.Initially OGSA-DAI was based on the OGSI infrastructure but recent releases support WS-I;WS-I+; and WSRF. The change to these new specifications raised new issues andrequirements. It has been taken as an opportunity to review all aspects of OGSA-DAI. Thispaper describes the new architecture for future releases and its rationale.,Proceedings of the UK e-Science All Hands Meeting 2005,2005,29
Improving UML Support for User Interface Design: A Metric Assessment of UMLi.,Paulo Pinheiro Da Silva; Norman W Paton,Abstract The Unified Modeling Language (UML) has been widely accepted by applicationdevelopers; but not so much by user interface (UI) designers. For this reason; the UnifiedModeling Language for Interactive Systems (UMLi) has been proposed to improve UMLsupport for UI design. UMLi introduces a diagram notation for modeling UI presentation andextends activity diagram notation to describe collaboration between interaction objects anddomain objects. This paper demonstrates using design metrics; in a quantitative way; thatUMLi models are significantly structurally; behaviorally and visually less complex thanstandard UML models when describing the same set of properties of an interactive system.,ICSE Workshop on SE-HCI,2003,29
Incrementally improving dataspaces based on user feedback,Khalid Belhajjame; Norman W Paton; Suzanne M Embury; Alvaro AA Fernandes; Cornelia Hedeler,Abstract One aspect of the vision of dataspaces has been articulated as providing variousbenefits of classical data integration with reduced up-front costs. In this paper; we presenttechniques that aim to support schema mapping specification through interaction with endusers in a pay-as-you-go fashion. In particular; we show how schema mappings; that areobtained automatically using existing matching and mapping generation techniques; can beannotated with metrics estimating their fitness to user requirements using feedback on queryresults obtained from end users. Using the annotations computed on the basis of userfeedback; and given user requirements in terms of precision and recall; we present amethod for selecting the set of mappings that produce results meeting the statedrequirements. In doing so; we cast mapping selection as an optimization problem …,Information Systems,2013,28
Using OGSA-DQP to support scientific applications for the grid,M Nedim Alpdemir; Arijit Mukherjee; Anastasios Gounaris; Norman W Paton; Alvaro AA Fernandes; Rizos Sakellariou; Paul Watson; Peter Li,Abstract The data management problems in grid computing are often challenging in manyaspects such as data volumes; heterogeneity; structural complexity and semantic content.Thus; e-Scientists and scientific application developers stand to benefit from tools andenvironments that either hide; or help to manage; the inherent complexity involved inaccessing and making concerted use of the diverse resources. This paper describes OGSA-DQP; a high level data integration tool for service-based grids; and illustrates how it can beused to support grid users; via an example scientific study in bioinformatics. The paper alsodiscusses various options for employing OGSA-DQP to handle data integration tasks asservice orchestrations involving both data and analysis services.,*,2005,28
Information quality in proteomics,David A Stead; Norman W Paton; Paolo Missier; Suzanne M Embury; Cornelia Hedeler; Binling Jin; Alistair JP Brown; Alun Preece,Abstract Proteomics; the study of the protein complement of a biological system; isgenerating increasing quantities of data from rapidly developing technologies employed in avariety of different experimental workflows. Experimental processes; eg for comparative 2Dgel studies or LC-MS/MS analyses of complex protein mixtures; involve a number of steps:from experimental design; through wet and dry lab operations; to publication of data inrepositories and finally to data annotation and maintenance. The presence of inaccuraciesthroughout the processing pipeline; however; results in data that can be untrustworthy; thusoffsetting the benefits of high-throughput technology. While researchers and practitionersare generally aware of some of the information quality issues associated with publicproteomics data; there are few accepted criteria and guidelines for dealing with them. In …,Briefings in bioinformatics,2008,27
Web Services Data Access and Integration–The Core (WS-DAI) Specification; Version 1.0,Mario Antonioletti; Malcolm Atkinson; A Krause; S Laws; S Malaika; Norman W Paton; D Pearson; G Riccardi,Abstract Data resources play a significant role in many applications across multipledomains. Web services provide implementation neutral facilities for describing; invoking andorchestrating collections of networked resources. The GGF (Global Grid Forum) Open GridServices Architecture (OGSA); and its associated specifications; defines consistentinterfaces through web services to components of a grid infrastructure. Both the web andgrid communities stand to benefit from the provision of consistent and agreed web serviceinterfaces for data resources and the systems that manage them. This document presents aspecification for a collection of generic data interfaces that can be extended to supportspecific kinds of data resources; such as relational databases; XML repositories; objectdatabases; or files. Related DAIS specifications define how specific data resources and …,Recommendation GFD,2006,27
Structure inference for linked data sources using clustering,Klitos Christodoulou; Norman W Paton; Alvaro AA Fernandes,Abstract Linked Data (LD) overlays the World Wide Web of documents with a Web of Data.This is becoming significant as shown in the growth of LD repositories available as part ofthe Linked Open Data (LOD) cloud. At the instance-level; LD sources use a combination ofterms from various vocabularies; expressed as RDFS/OWL; to describe data and publish it tothe Web. However; LD sources do not organise data to conform to a specific structureanalogous to a relational schema; instead data can adhere to multiple vocabularies.Expressing SPARQL queries over LD sources–usually over a SPARQL endpoint that ispresented to the user–requires knowledge of the predicates used so as to allow queries toexpress user requirements as graph patterns. Although LD provides low barriers to datapublication using a single language (ie; RDF); sources organise data with different …,*,2015,26
Automatic annotation of web services based on workflow definitions,Khalid Belhajjame; Suzanne M Embury; Norman W Paton; Robert Stevens; Carole A Goble,Abstract Semantic annotations of web services can facilitate the discovery of services; aswell as their composition into workflows. At present; however; the practical utility of suchannotations is limited by the small number of service annotations available for general use.Resources for manual annotation are scarce; and therefore some means is required bywhich services can be automatically (or semi-automatically) annotated. In this paper; weshow how information can be inferred about the semantics of operation parameters basedon their connections to other (annotated) operation parameters within tried-and-testedworkflows. In an open-world context; we can infer only constraints on the semantics ofparameters; but these so-called loose annotations are still of value in detecting errors withinworkflows; annotations and ontologies; as well as in simplifying the manual annotation …,International Semantic Web Conference,2006,26
Self-monitoring query execution for adaptive query processing,Anastasios Gounaris; Norman W Paton; Alvaro AA Fernandes; Rizos Sakellariou,Abstract Adaptive query processing generally involves a feedback loop comprisingmonitoring; assessment and response. So far; individual proposals have tended to grouptogether an approach to monitoring; a means of assessment; and a form of response.However; there are many benefits in decoupling these three phases; and in constructinggeneric frameworks for each of them. To this end; this paper discusses monitoring of queryplan execution as a topic in its own right; and advocates an approach based on self-monitoring algebraic operators. This approach is shown to be generic and independent ofany specific adaptation mechanism; easily implementable and portable; sufficientlycomprehensive; appropriate for heterogeneous distributed environments; and moreimportantly; capable of driving on-the-fly adaptations of query plan execution. An …,Data & Knowledge Engineering,2004,26
Adaptive query processing and the grid: Opportunities and challenges,Anastasios Gounaris; Norman W Paton; Rizos Sakellariou; Alvaro AA Fernandes,Grid technologies have been developed in response to an increase in demand forcomputing applications designed to yield the benefits from collaboration; data sharing andsophisticated interaction of autonomous and geographically dispersed resources.Distributed query processing (DQP) is an appealing solution for expressing and efficientlyevaluating requests across grid resources. In this paper:(i) we identify parts of the gridinfrastructure that facilitate; and open new directions for; query processing over grid-enabledheterogeneous and autonomous databases; stressing the need for adaptive queryprocessing (AQP);(ii) we discuss some basic challenges arising from the new opportunitiesand outline the unsuitability for use in a grid setting and narrow specialisation of existingproposals for AQP; and (iii) we suggest a generic adaptivity framework as a promising …,Database and Expert Systems Applications; 2004. Proceedings. 15th International Workshop on,2004,26
Deductive object-oriented database systems: a survey,Pedro R Falcone Sampaio; Norman W Paton,Abstract Deductive object-oriented databases (DOODs) seek to combine the complementarybenefits of the deductive and the object-oriented paradigms in the context of databases.Research into DOODs has now been taking place for almost ten years; and a significantnumber of designs and implementations have been developed. This paper categorisesproposals for DOODs; based on the language design strategy pursued; and compares theresulting systems in terms of the support provided for specific deductive and object-orientedfeatures. It is shown how comprehensive proposals have emerged from significantly differentdesign strategies; and it is argued that research on DO ODs is now quite mature; in thatconsensus is emerging on the capabilities that it is appropriate for DOODs to support.,International Workshop on Rules in Database Systems,1997,26
Extending ODBMSs using metaclasses,Oscar Diaz; Norman W Paton,Metaclasses let database designers extend Adam; an object-oriented database-management system; at the model level. Designers and programmers can use objects todescribe and extend the behavior of the database itself; without the coding involved inchanging the application system. In this article; the authors extend Adam to handleconstraints and relationships.,IEEE Software,1994,26
An architecture for query optimization in sensor networks,Ixent Galpin; Christian YA Brenninkmeijer; Farhana Jabeen; Alvaro AA Fernandes; Norman W Paton,We present a novel sensor network query processing architecture that (a) covers all thequery optimization phases that are required to map a declarative query to executable code;and (b) does so for a more expressive query language than has heretofore been supportedover sensor networks. The architecture is founded on the view that a sensor network truly isa distributed computing infrastructure; albeit a very constrained one. As such; we addressthe problem of how to develop a comprehensive optimizer for an expressive declarativecontinuous query language over acquisitional streams as one of finding extensions to aclassical distributed query processing architecture that contend with the peculiarities ofsensor networks as an environment for distributed computing.,Data Engineering; 2008. ICDE 2008. IEEE 24th International Conference on,2008,24
Enzyme kinetics informatics: from instrument to browser,Neil Swainston; Martin Golebiewski; Hanan L Messiha; Naglis Malys; Renate Kania; Sylvestre Kengne; Olga Krebs; Saqib Mir; Heidrun Sauer‐Danzwith; Kieran Smallbone; Andreas Weidemann; Ulrike Wittig; Douglas B Kell; Pedro Mendes; Wolfgang Müller; Norman W Paton; Isabel Rojas,Abstract A limited number of publicly available resources provide access to enzyme kineticparameters. These have been compiled through manual data mining of published papers;not from the original; raw experimental data from which the parameters were calculated. Thisis largely due to the lack of software or standards to support the capture; analysis; storageand dissemination of such experimental data. Introduced here is an integrative system tomanage experimental enzyme kinetics data from instrument to browser. The approach isbased on two interrelated databases: the existing SABIO-RK database; containing kineticdata and corresponding metadata; and the newly introduced experimental raw datarepository; MeMo-RK. Both systems are publicly available by web browser and web serviceinterfaces and are configurable to ensure privacy of unpublished data. Users of this …,The FEBS journal,2010,23
Guidelines for reporting the use of column chromatography in proteomics,Andrew R Jones; Kathleen Carrol; David Knight; Kirsty MacLellan; Paula J Domann; Cristina Legido-Quigley; Lihua Huang; Lance Smallshaw; Hamid Mirzaei; James Shofstahl; Norman W Paton,We wish to announce the column chromatography module (MIAPE-CC) of the minimuminformation about a proteomics experiment (MIAPE) guidelines (1); specifying the minimuminformation that should be provided when reporting the use of column chromatography in aproteomics experiment (Box 1). MIAPE-CC constitutes a further component of the MIAPEdocumentation system; developed by proteomics researchers working under the aegis of theHuman Proteome Organisation's Proteomics Standards Initiative (HUPO-PSI; http://www.psidev. info/). Prior modules for mass spectrometry and gel electrophoresis have alreadybeen described in Nature Biotechnology (2-4).MIAPE-CC covers the use of columns forprotein or peptide separation; with a view to supporting the sharing of best practices;validation of results; discovery of results and sharing of experimental data sets. For a full …,Nature biotechnology,2010,23
On characterising and identifying mismatches in scientific workflows,Khalid Belhajjame; Suzanne M Embury; Norman W Paton,Abstract Workflows are gaining importance as a means for modelling and enacting in silicoscientific experiments. A major issue which arises when aggregating a collection of analysisoperations within a workflow is the compatibility of their inputs and outputs: the analysisoperations are supplied by independently developed web services which are likely to haveincompatible inputs and outputs. We use the term mismatch to refer to such incompatibility.This paper characterises the mismatches a scientific workflow may suffer from and specifiesmappings for their resolution.,International Workshop on Data Integration in the Life Sciences,2006,23
OGSA-DAI: Two years on,Mario Antonioletti; Malcolm Atkinson; Rob Baxter; Andrew Borley; Neil Chue Hong; Brian Collins; Jonathan Davies; Neil Hardman; George Hicken; Ally Hume; Mike Jackson; Amrey Krause; Simon Laws; James Magowan; Jeremy Nowell; Norman W Paton; Dave Pearson; Tom Sugden; Paul Watson; Martin Westhead,February 2002 as a collaboration between various UK academic institutions and industrialpartners. The project is funded and motivated by the UK e-Science community; whoseproject requirements contribute to the goals that OGSA-DAI aims to satisfy. OGSA-DAI hasproduced several releases of Grid-enabled middleware implementing DAIS (Data Accessand Integration Services) specifications. This middleware is based on the GGF-defined OGSIspecification [OGSI] and layered on top of the Globus Toolkit 3 OGSI implementation (GT3Core). Now that OGSI has effectively been deprecated; OGSA-DAI will migrate to takeaccount of changes in the Web and Grid services standards space; to allow access to andintegration of data resources in an OGSA Grid environment. By a data resource we meanany object that can source and/or sink data and its associated management framework …,Global Grid Forum 10—Data Area Workshop,2004,23
Polar: An architecture for a parallel ODMG compliant object database,Jim Smith; Paul Watson; Sandra de F Mendes Sampaio; Norman Paton,ABSTRACT Object database management systems (ODBMS) are now established as thedatabase management technology of choice for a range of challenging data intensiv eapplications. Furthermore; the applications associated with object databases typically havestringen t performance requirements; and some are associated with very large data sets. How ever; despite the demands made on object databases by applications; there has beensurprisingly little work on parallel object databases. This paper presents the arc hitectureand some preliminary performance results for the Polar ODMG compliant parallel objectdatabase. The architecture described has been implemented in a shared-nothingenvironment on a network of PCs. The paper describes how OQL queries are compiled;parallelized and executed in this environment; and includes some preliminary …,Proceedings of the ninth international conference on Information and knowledge management,2000,23
Incremental maintenance of materialized OQL views,M Akhtar Ali; Alvaro AA Fernandes; Norman W Paton,ABSTRACT The importance of materialized views has grown significantly with the advent ofdata warehousing and OLAP technology. This increases the relevance of solutions to theproblem of incrementally maintaining materialized views. So far; most w orkon this problemhas been confined to relational settings. Proposals that apply to object databases haveeither used non-standard models or fallen short of providing a comprehensive framework.This paper contributes a solution to the incremental view maintenance problem for a largeclass of views expressed in OQL; the query language of the ODMG standard for objectdatabases. The solution applies to immediate update propagation; and works for any updateoperation on views defined over a substantial subset of ODMG types. The approach presented has been fully implemented and preliminary performance results are reported.,Proceedings of the 3rd ACM international workshop on Data warehousing and OLAP,2000,23
Spatio-temporal databases: contentions; components and consolidation,Norman W Paton; Alvaro AA Fernandes; Tony Griffiths,Spatio-temporal databases have been the focus of considerable research activity over asignificant period. However; there are as of yet very few prototypes of complete systems; farless products that provide effective support for applications tracking changes to spatial andaspatial data over time. We contend that this is because much of the activity in spatio-temporal databases has focused on specific parts of the problem; at the expense of a moreholistic view of database systems design and development. It is probably also the case thatthe database research community has been inclined to undervalue integration orconsolidation activities. This paper outlines some contentions relating to spatio-temporaldatabases; with a view to pruning the space of possible paths that consolidation activitiesmight follow. Suggestions are also made as to what areas are most likely to present …,Database and Expert Systems Applications; 2000. Proceedings. 11th International Workshop on,2000,23
Database programming languages,Norman Paton; Richard Cooper; Howard Williams; Philip Trinder,*,*,1996,23
A critical and integrated view of the yeast interactome,Michael Cornell; Norman W Paton; Stephen G Oliver,Abstract Global studies of protein–protein interactions are crucial to both elucidating genefunction and producing an integrated view of the workings of living cells. High-throughputstudies of the yeast interactome have been performed using both genetic and biochemicalscreens. Despite their size; the overlap between these experimental datasets is very limited.This could be due to each approach sampling only a small fraction of the total interactome.Alternatively; a large proportion of the data from these screens may represent false-positiveinteractions. We have used the Genome Information Management System (GIMS) tointegrate interactome datasets with transcriptome and protein annotation data and havefound significant evidence that the proportion of false-positive results is high. Not all high-throughput datasets are similarly contaminated; and the tandem affinity purification (TAP) …,Comparative and functional genomics,2004,22
Rules in Database Systems: Proceedings of the 1st International Workshop on Rules in Database Systems; Edinburgh; Scotland; 30 August–1 September 1993,Norman W Paton; M Howard Williams,This book is the proceedings of a workshop held at Heriot-Watt University in Edinburgh inAugust 1993. The central theme of the workshop was rules in database systems; and thepapers presented covered a range of different aspects of database rule systems. Theseaspects are reflected in the sessions of the workshop; which are the same as the sections inthis proceedings: Active Databases Architectures Incorporating Temporal Rules Rules andTransactions Analysis and Debugging of Active Rules Integrating Graphs/Objects withDeduction Integrating Deductive and Active Rules Integrity Constraints DeductiveDatabases The incorporation of rules into database systems is an important area ofresearch; as it is a major component in the integration of behavioural information with thestructural data with which commercial databases have traditionally been associated. This …,*,2012,21
ISPIDER Central: an integrated database web-server for proteomics,Jennifer A Siepen; Khalid Belhajjame; Julian N Selley; Suzanne M Embury; Norman W Paton; Carole A Goble; Stephen G Oliver; Robert Stevens; Lucas Zamboulis; Nigel Martin; Alexandra Poulovassillis; Philip Jones; Richard Côté; Henning Hermjakob; Melissa M Pentony; David T Jones; Christine A Orengo; Simon J Hubbard,Abstract Despite the growing volumes of proteomic data; integration of the underlying resultsremains problematic owing to differences in formats; data captured; protein accessions andservices available from the individual repositories. To address this; we present the ISPIDERCentral Proteomic Database search (http://www. ispider. manchester. ac. uk/cgi-bin/ProteomicSearch. pl); an integration service offering novel search capabilities overleading; mature; proteomic repositories including PRoteomics IDEntifications database(PRIDE); PepSeeker; PeptideAtlas and the Global Proteome Machine. It enables users tosearch for proteins and peptides that have been characterised in mass spectrometry-basedproteomics experiments from different groups; stored in different databases; and view thecollated results with specialist viewers/clients. In order to overcome limitations imposed …,Nucleic acids research,2008,21
Adaptive workload allocation in query processing in autonomous heterogeneous environments,Anastasios Gounaris; Jim Smith; Norman W Paton; Rizos Sakellariou; Alvaro AA Fernandes; Paul Watson,Abstract The increasing prevalence of networked storage and computational resources;along with middleware for managing resource access and sharing; raises the prospect thatqueries can be run over resources obtained on demand; rather than on dedicatedinfrastructures. However; the movement of query processing into non-dedicatedenvironments means that it is necessary to take account of the partial information andunstable conditions that characterise autonomous; shared; distributed settings. Thus; queryprocessing on grid platforms needs to be adaptive; revising evaluation strategies at queryruntime in response to the evolving environment; such as changes to machine load andavailability. To address this challenge; adaptive techniques are described that:(i) balanceload across plan partitions supporting intra-operator parallelism;(ii) remove bottlenecks in …,Distributed and Parallel Databases,2009,20
Utility Driven Adaptive Work? ow Execution,Kevin Lee; Norman W Paton; Rizos Sakellariou; Alvaro AA Fernandes,Abstract Workflows are widely used in applications that require coordinated use ofcomputational resources. Workflow definition languages typically abstract over someaspects of the way in which a workflow is to be executed; such as the level of parallelism tobe used or the physical resources to be deployed. As a result; a workflow managementsystem has responsibility for establishing how best to map tasks within a workflow to theavailable resources. As workflows are typically run over shared resources; and thus faceunpredictable and changing resource capabilties; there may be benefit to be derived fromadapting the task-to-resource mapping while a workflow is executing. This paper describesthe use of utility functions to express the relative merits of alternative mappings; in essence;a utility function can be used to give a score to a candidate mapping; and the exploration …,Proceedings of the 2009 9th IEEE/ACM International Symposium on Cluster Computing and the Grid,2009,20
Practical adaptation to changing resources in grid query processing,Anastasios Gounaris; Norman W Paton; Rizos Sakellariou; Alvaro AA Fernandes; Jim Smith; Paul Watson,Grid computational resources; as well as being heterogeneous; may also exhibitunpredictable; volatile behaviour. Therefore; query processing on the Grid needs to beadaptive in order to cope with evolving resource characteristics; such as machine load andavailability. To address this challenge in a Grid environment; the non-adaptive OGSA-DQP1system described in [1] has been enhanced with adaptive capabilities.,Data Engineering; 2006. ICDE'06. Proceedings of the 22nd International Conference on,2006,20
Contextualised workflow execution in myGrid,M Nedim Alpdemir; Arijit Mukherjee; Norman W Paton; Alvaro AA Fernandes; Paul Watson; Kevin Glover; Chris Greenhalgh; Tom Oinn; Hannah Tipney,Abstract e-Scientists stand to benefit from tools and environments that either hide; or help tomanage; the inherent complexity involved in accessing and making concerted use of thediverse resources that might be used as part of an in silico experiment. This paper illustratesthe benefits that derive from the provision of integrated access to contextual information thatlinks the phases of a problem-solving activity; so that the steps of a solution do not happen inisolation; but rather as the components of a coherent whole. Experiences with myGridworkflow execution environment (Taverna) are presented; where an information modelprovides the conceptual basis for contextualisation. This information model describes keycharacteristics that are shared by many e-Science activities; and is used both to organise thescientist's personal data resources; and to support data sharing and capture within the …,European Grid Conference,2005,20
Specifying active database systems in an object-oriented framework,Jack Campin; Norman Paton; M Howard Williams,This paper presents a framework for the formal specification of active database systems; andshows how the framework can be used to describe the functionality of three well knownexample systems; namely Starburst; POSTGRES and Ariel. The framework has beendeveloped using Object-Z to structure specifications in a way that emphasisescommonalities and key differences between the designs; and that is readily extensible tosupport new constructs and systems. Such a formal framework can be used to provideformal descriptions of systems that have previously been described only informally; tocompare the functionalities of different systems by contrasting support for fundamentalconcepts; and as a basis for reasoning about rule bases in the context of different active rulesystems. The paper also demonstrates the applicability of object-oriented formal methods …,International Journal of Software Engineering and Knowledge Engineering,1997,20
The gel electrophoresis markup language (GelML) from the Proteomics Standards Initiative,Frank Gibson; Christine Hoogland; Salvador Martinez‐Bartolomé; J Alberto Medina‐Aunon; Juan Pablo Albar; Gyorgy Babnigg; Anil Wipat; Henning Hermjakob; Jonas S Almeida; Romesh Stanislaus; Norman W Paton; Andrew R Jones,Abstract The Human Proteome Organisation's Proteomics Standards Initiative hasdeveloped the GelML (gel electrophoresis markup language) data exchange format forrepresenting gel electrophoresis experiments performed in proteomics investigations. Theformat closely follows the reporting guidelines for gel electrophoresis; which are part of theMinimum Information About a Proteomics Experiment (MIAPE) set of modules. GelMLsupports the capture of metadata (such as experimental protocols) and data (such as gelimages) resulting from gel electrophoresis so that laboratories can be compliant with theMIAPE Gel Electrophoresis guidelines; while allowing such data sets to be exchanged ordownloaded from public repositories. The format is sufficiently flexible to capture data from abroad range of experimental processes; and complements other PSI formats for MS data …,Proteomics,2010,19
KiPar; a tool for systematic information retrieval regarding parameters for kinetic modelling of yeast metabolic pathways,Irena Spasić; Evangelos Simeonidis; Hanan L Messiha; Norman W Paton; Douglas B Kell,Abstract Motivation: Most experimental evidence on kinetic parameters is buried in theliterature; whose manual searching is complex; time consuming and partial. Theseshortcomings become particularly acute in systems biology; where these parameters needto be integrated into detailed; genome-scale; metabolic models. These problems areaddressed by KiPar; a dedicated information retrieval system designed to facilitate access tothe literature relevant for kinetic modelling of a given metabolic pathway in yeast. Searchingfor kinetic data in the context of an individual pathway offers modularity as a way of tacklingthe complexity of developing a full metabolic model. It is also suitable for large-scale mining;since multiple reactions and their kinetic parameters can be specified in a single searchrequest; rather than one reaction at a time; which is unsuitable given the size of genome …,Bioinformatics,2009,19
An Experimental Performance Evaluation of Spatio‐Temporal Join Strategies,Seung‐Hyun Jeong; Norman W Paton; Alvaro AA Fernandes; Tony Griffiths,Abstract Many applications capture; or make use of; spatial data that changes over time. Thisrequirement for effective and efficient spatio-temporal data management has given rise to arange of research activities relating to spatio-temporal data management. Such work hassought to understand; for example; the requirements of different categories of application;and the modelling facilities that are most effective for these applications. However; atpresent; there are few systems with fully integrated support for spatio-temporal data; andthus developers must often construct custom solutions for their applications. Developers ofboth bespoke solutions and of generic spatio-temporal platforms will often need to supportthe fusion of large spatio-temporal data sets. Supporting such requests in a database settinginvolves the use of join operations with both spatial and temporal conditions–spatio …,Transactions in GIS,2005,19
Experience on performance evaluation with OGSA-DQP,M Nedim Alpdemir; Anastasios Gounaris; Arijit Mukherjee; Desmond Fitzgerald; Norman W Paton; Paul Watson; Rizos Sakellariou; AA Fernandes; Jim Smith,Abstract OGSA-DQP is an open source service-based Distributed Query Processor; as such;it supports the evaluation of queries over collections of potentially remote data access andanalysis services. As it operates over several layers of service-oriented infrastructure; oneparticular need (both among the developer team and the relevant community) has been toinvestigate the impact of the infrastructure layers; understand performance issues; identifybottlenecks and improve the response times of queries where possible. This paper conveysexperiences gained in doing so; by describing the experiments carried out and presentingthe results obtained.,Proceedings of the UK e-Science All Hands Meeting,2005,18
Teallach—a flexible user-interface development environment for object database applications,Peter J Barclay; Tony Griffiths; Jo McKirdy; J Kennedy; Richard Cooper; Norman W Paton; P Gray,Abstract The Teallach project has adapted model-based user-interface developmenttechniques to the systematic creation of user-interfaces for object-oriented databaseapplications. Model-based approaches aim to provide designers with a more principledapproach to user-interface development using a variety of underlying models; and toolswhich manipulate these models. Here we present the results of the Teallach project;describing the tools developed and the flexible design method supported. Distinctivefeatures of the Teallach system include provision of database-specific constructs;comprehensive facilities for relating the different models; and support for a flexible designmethod in which models can be constructed and related by designers in different orders andin different ways; to suit their particular design rationales. The system then creates the …,Journal of Visual Languages & Computing,2003,18
Tripod: A comprehensive model for spatial and aspatial historical objects,Tony Griffiths; Alvaro AA Fernandes; Norman W Paton; Keith T Mason; Bo Huang; Michael Worboys,Abstract Spatio-temporal extensions to data models have been an active area of researchfor a number of years. To date; much of this work has focused on the relational data model;with object data models receiving far less consideration. This paper presents a spatio-historical object model that uses a specialized mechanism; called a history; to maintainknowledge about entities that change over time. Key features of the resulting proposalinclude:(i) consistent representations of primitive spatial and temporal types;(ii) a component-based design in which spatial; temporal and historical extensions are formalizedincrementally; for subsequent use together or separately;(iii) a formally specified data model.The model can be used directly during the design of spatio-historical applications; but alsoforms the basis of an implementation activity developing a spatio-historical object …,International Conference on Conceptual Modeling,2001,18
A query calculus for spatio-temporal object databases,Tony Griffiths; Alvaro AA Fernandes; Nassima Djafri; Norman W Paton,The development of any comprehensive proposal for spatio-temporal databases involvessignificant extensions to many aspects of a non-spatio-temporal architecture. One aspectthat has received less attention than most is the development of a query calculus that can beused to provide a semantics for spatio-temporal queries and underpin an effective queryoptimization and evaluation framework. We show how a query calculus for spatio-temporalobject databases that builds upon the monoid calculus proposed by Fegaras and Maier(2000) for ODMG-compliant database systems can be developed. The paper shows how anextension of the ODMG type system with spatial and temporal types can be accommodatedinto the monoid approach. It uses several queries over historical (possibly spatial) data toillustrate how; by mapping them into monoid comprehensions; the way is open for the …,Temporal Representation and Reasoning; 2001. TIME 2001. Proceedings. Eighth International Symposium on,2001,18
VESPA: A benchmark for vector spatial databases,Norman W Paton; M Howard Williams; Kosmas Dietrich; Olive Liew; Andrew Dinn; Alan Patrick,Abstract Facilities for the storage and analysis of large quantities of spatial data areimportant to many applications; and are central to geographic information systems. This hasgiven rise to a range of proposals for spatial data models and software architectures thatallow database systems to be used cleanly and efficiently with spatial data. However;although many spatial database systems have been built; there have been few systematiccomparisons of the functionality or the performance of such systems. This is probably at leastpartly due to the lack of a widely used; standard spatial database benchmark. This paperpresents a benchmark for vector spatial databases that covers a range of typical GISfunctions; and shows how the benchmark has been implemented in two systems: the object-relational database PostgreSQL; and the deductive object-oriented database ROCK & …,British National Conference on Databases,2000,18
Multi-paradigm query interface to an object-oriented database,Dac Khoa Doan; Norman W Paton; Alistair C Kilgour; Ghassan al-Qaimari,Abstract The object-oriented paradigm has a number of widely recognised strengths whenapplied to data management; but the increased complexity of actual systems compared withtheir relational predecessors often means that such databases are less readily accessible tononprogrammers than relational systems. A number of proposals have been made fortextual; form-based and graph-based query interfaces to object-oriented databases; but it isclear that a single approach cannot be considered to be the best; given the wide range ofpotential user groups; application domains and tasks. The paper presents a query interfaceto an object-oriented database which supports alternative user-level query paradigms in afully integrated environment; thereby enabling different categories of user to select apreferred interface paradigm from a list of options. Furthermore; the interface enables …,Interacting with computers,1995,18
An extensible interface to an extensible Object-Oriented Database system,Norman W Paton; Ghassan al-Qaimari; Alistair C Kilgour,Abstract This paper describes how an extensible interface can be constructed for use withan extensible object-oriented database system. Extensibility is achieved at the data modellevel by using standard object-oriented features such as inheritance and overriding to refinethe behaviour of system objects. An extensible interface; which uses different visualisationsfor different categories of database object; is made possible by associating visualisationobjects with system-level database objects. In the system described; it is shown howimplementing an object-oriented database in itself gives rise to a uniform and accessibleform of extensibility; and it is argued that these characteristics can and should be supportedin an interface to such a database. The benefits of this approach are presented both ingeneral terms and by describing the implementation of EVE; an Extensible Visual …,*,1993,18
Adaptation in cloud resource configuration: a survey,Abdul R Hummaida; Norman W Paton; Rizos Sakellariou,Abstract With increased demand for computing resources at a lower cost by end-users;cloud infrastructure providers need to find ways to protect their revenue. To achieve this;infrastructure providers aim to increase revenue and lower operational costs. A promisingapproach to addressing these challenges is to modify the assignment of resources toworkloads. This can be used; for example; to consolidate existing workloads; the newcapability can be used to serve new requests or alternatively unused resources may beturned off to reduce power consumption. The goal of this paper is to highlight features;approaches and findings in the literature; in order to identify open challenges and facilitatefuture developments. We present a definition of cloud systems adaptation; a classification ofthe key features and a survey of adapting compute and storage configuration. Based on …,*,2016,17
Managing and sharing experimental data: standards; tools and pitfalls,Norman W Paton,Experimental processes in the life sciences are becoming increasingly complex. As a result;recording; archiving and sharing descriptions of these processes and of the results ofexperiments is becoming ever more challenging. However; validation of results; sharing ofbest practice and integrated analysis all require systematic description of experiments atcarefully determined levels of detail. The present paper discusses issues associated with themanagement of experimental data in the life sciences; including: the different tasks thatexperimental data and metadata can support; the role of standards in informing data sharingand archiving; and the development of effective databases and tools; building on thesestandards.,*,2008,17
The design; implementation and evaluation of an odmg compliant; parallel object database server,Jim Smith; Sandra Sampaio; Paul Watson; Norman W Paton,Abstract This paper describes the design; implementation and evaluation of a parallel objectdatabase server. While a number of research groups and companies now provide objectdatabase servers designed to run on uniprocessors; there has been surprisingly little workon the exploitation of parallelism to provide scalable performance in Object DatabaseManagement Systems (ODBMS). The work described in this paper takes as its starting-pointthe Object Database Management Group (ODMG) standard for object databases; therebyallowing the project to focus on research into parallelism; rather than on the ODBMSinterfaces. The system is designed to run on a distributed memory parallel machine; and thepaper describes the key issues and design decisions including: parallel query optimisationand execution; flow control; support for user-defined operations in queries; object …,Distributed and Parallel Databases,2004,17
An active rule language for ROCK & ROLL,Andrew Dinn; Norman W Paton; M Howard Williams; Alvaro AA Fernandes,Abstract This paper presents an active rule language for the ROCK & ROLL deductive object-oriented database system. A characteristic feature of ROCK & ROLL is that it blendsimperative and deductive programming styles so that both can be used together in supportof passive database applications. The aim in developing an active extension is to allowdeclarative expression of aspects of active behaviour wherever possible; without imposingprohibitive restrictions on the power of the resulting system. The proposal which results ismore powerful than most earlier declarative active rule systems; in both its language andexecution model; without resorting to the wholly procedural approach supported by mostproposals for active object-oriented databases. The paper indicates where retainingdeclarative features yields greatest benefits; but also where difficulties are encountered …,British National Conference on Databases,1996,17
Pay-as-you-go mapping selection in dataspaces,Cornelia Hedeler; Khalid Belhajjame; Norman W Paton; Alvaro AA Fernandes; Suzanne M Embury; Lu Mao; Chenjuan Guo,Abstract The vision of dataspaces proposes an alternative to classical data integrationapproaches with reduced up-front costs followed by incremental improvement on a pay-as-you-go basis. In this paper; we demonstrate DSToolkit; a system that allows users to providefeedback on results of queries posed over an integration schema. Such feedback is thenused to annotate the mappings with their respective precision and recall. The system thenallows a user to state the expected levels of precision (or recall) that the query results shouldexhibit and; in order to produce those results; the system selects those mappings that arepredicted to meet the stated constraints.,Proceedings of the 2011 ACM SIGMOD International Conference on Management of data,2011,16
Model-driven user interfaces for bioinformatics data resources: regenerating the wheel as an alternative to reinventing it,Kevin Garwood; Christopher Garwood; Cornelia Hedeler; Tony Griffiths; Neil Swainston; Stephen G Oliver; Norman W Paton,The proliferation of data repositories in bioinformatics has resulted in the development ofnumerous interfaces that allow scientists to browse; search and analyse the data that theycontain. Interfaces typically support repository access by means of web pages; but othermeans are also used; such as desktop applications and command line tools. Interfaces oftenduplicate functionality amongst each other; and this implies that associated developmentactivities are repeated in different laboratories. Interfaces developed by public laboratoriesare often created with limited developer resources. In such environments; reducing the timespent on creating user interfaces allows for a better deployment of resources for specialisedtasks; such as data integration or analysis. Laboratories maintaining data resources arechallenged to reconcile requirements for software that is reliable; functional and flexible …,BMC bioinformatics,2006,16
Proteomics and Beyond A report on the 3rd Annual Spring Workshop of the HUPO‐PSI 21–23 April 2006; San Francisco; CA; USA,Sandra Orchard; Rolf Apweiler; Robert Barkovich; Dawn Field; John S Garavelli; David Horn; Andy Jones; Philip Jones; Randall Julian; Ruth McNally; Jason Nerothin; Norman Paton; Angel Pizarro; Sean Seymour; Chris Taylor; Stefan Wiemann; Henning Hermjakob,Abstract The theme of the third annual Spring workshop of the HUPO-PSI was “proteomicsand beyond” and its underlying goal was to reach beyond the boundaries of the proteomicscommunity to interact with groups working on the similar issues of developing interchangestandards and minimal reporting requirements. Significant developments in many of theHUPO-PSI XML interchange formats; minimal reporting requirements and accompanyingcontrolled vocabularies were reported; with many of these now feeding into the broaderefforts of the Functional Genomics Experiment (FuGE) data model and Functional GenomicsOntology (FuGO) ontologies.,Proteomics,2006,16
Supporting production rules using ECA rules in an object-oriented context,Norman W Paton,Abstract This paper presents an approach to implementing production rules for object-oriented databases (OODBs). The approach builds upon earlier work on production rulealgorithms for relational databases; and exploits fundamental differences in the structuringmechanisms employed by OODBs. An implementation is described whereby the productionrules are mapped onto eventcondition action rules for execution. It is shown how theresulting implementation has minimal space overheads; and a time performance close tothat of the widely used TREAT algorithm which uses significantly more space.,Information and Software Technology,1995,16
On interface objects in object-oriented databases,Norman W Paton; Ghassan al-Qaimari; Khoa Doan,Abstract This paper describes an approach to the support of interface objects in an object-oriented database; and outlines some of the consequences of representing interface data asdatabase objects. Existing architectures for implementing database interfaces are reviewed;and certain shortcomings identified; which essentially stem from an impedance mismatchbetween the database and its interface. It is shown how an existing graphical component setcan be cleanly and transparently integrated with an existing object-oriented database;thereby removing the above impedance mismatch and providing persistent graphical data.This interface can then be used to implement generic; tailorable and application-specificinterface concepts; each of which is exemplified in the paper.,British National Conference on Databases,1994,16
Sharing Behaviour in an Object-Oriented Database using a Rule-Based Mechanism.,Oscar Diaz; Norman W Paton,*,BNCOD,1991,16
Proteome data integration: Characteristics and challenges,Khalid Belhajjame; SM Embury; Hao Fan; CA Goble; Henning Hermjakob; SJ Hubbard; D Jones; P Jones; N Martin; Stephen Oliver; C Orengo; NW Paton; Alexandra Poulovassilis; Jennifer Siepen; Robert Stevens; Chris Taylor; N Vinod; Lucas Zamboulis; Weimin Zhu,Abstract The aim of the ISPIDER project is to create a proteomics grid; that is; a technicalplatform that supports bioinformaticians in constructing; executing and evaluating in silicoanalyses of proteomics data. It will be constructed using a combination of generic e-scienceand Grid technologies; plus proteomics specific components and clients that embodyknowledge of the proteomics domain and the available resources. In this paper; we describesome of our earlier results in prototyping specific examples of proteomics data integration;and draw from it lessons about the kinds of domain-specific components that will berequired.,UK All Hands Meeting,2005,15
OGSA-DAI status and benchmarks,Mario Antonioletti; Malcolm Atkinson; Rob Baxter; Andrew Borley; NP Chue Hong; Patrick Dantressangle; Alastair C Hume; Mike Jackson; A Krause; S Laws; M Parsons; NW Paton; JM Schopf; T Sugden; P Watson; D Vyvyan,Abstract This paper presents a status report on some of the highlights that have taken placewithin the OGSADAI project since the last AHM. A description of Release 6.0 functionalityand details of the forthcoming release; due in September 2005; is given. Future directions forthis project are discussed. This paper also describes initial results of work being done tosystematically benchmark recent OGSADAI releases. The OGSA-DAI software distribution;and more information about the project; is available from the project website at www.ogsadai. org. uk.,UK e-Science All Hands Meeting,2005,15
Spatio-temporal evolution: querying patterns of change in databases,Nassima Djafri; Alvaro AA Fernandes; Norman W Paton; Tony Griffiths,Abstract This paper contributes a general approach to characterizing patterns of change in aspatio-temporal database. While there is a particular interest in modelling and querying howspatio-temporal entities evolve; the approach contributed by the paper is distinctive in beingapplicable without modification to aspatial entities as well. The paper uses the Tripod spatio-temporal model to describe and instantiate in detail the contributed approach. After brieflydescribing a typical application and providing basic knowledge about Tripod; the papercharacterizes and classifies evolution queries and describes in detail how they areevaluated.,Proceedings of the 10th ACM international symposium on Advances in geographic information systems,2002,15
ROCK and ROLL: a deductive object-oriented database with active and spatial extensions,Andrew Dinn; M Howard Williams; Norman Paton,ROCK & ROLL is a deductive object oriented database system that supports two languages;one imperative and the other deductive; both derived from the same object oriented datamodel. As the languages share a common type system; they can be integrated withoutmanifesting impedance mismatches; and thus programmers can conveniently exploit bothdeductive and imperative features in a single application. The components of ROCK & ROLLare as follows: data model OM-OM supports a range of conventional modelling constructs;such as sets; sequences; aggregations and (both single and multiple) inheritance; deductivelanguage ROLL-ROLL is a conventional first order deductive database language; whichdiffers from Datalog with negation in being strictly typed (through type inference); having astructured clause base that associates rules with classes; and in that the extensional …,Data Engineering; 1997. Proceedings. 13th International Conference on,1997,15
Data capture in bioinformatics: requirements and experiences with Pedro,Daniel Jameson; Kevin Garwood; Chris Garwood; Tim Booth; Pinar Alper; Stephen G Oliver; Norman W Paton,The systematic capture of appropriately annotated experimental data is a prerequisite formost bioinformatics analyses. Data capture is required not only for submission of data topublic repositories; but also to underpin integrated analysis; archiving; and sharing–bothwithin laboratories and in collaborative projects. The widespread requirement to capturedata means that data capture and annotation are taking place at many sites; but the smallscale of the literature on tools; techniques and experiences suggests that there is work to bedone to identify good practice and reduce duplication of effort. This paper reports onexperience gained in the deployment of the Pedro data capture tool in a range ofrepresentative bioinformatics applications. The paper makes explicit the requirements thathave recurred when capturing data in different contexts; indicates how these …,BMC bioinformatics,2008,14
An analysis of extensible modelling for functional genomics data,Andrew R Jones; Norman W Paton,Several data formats have been developed for large scale biological experiments; using avariety of methodologies. Most data formats contain a mechanism for allowing extensions toencode unanticipated data types. Extensions to data formats are important because theexperimental methodologies tend to be fairly diverse and rapidly evolving; which hinders thecreation of formats that will be stable over time. In this paper we review the data formats thatexist in functional genomics; some of which have become de facto or de jure standards; witha particular focus on how each domain has been modelled; and how each format allowsextensions. We describe the tasks that are frequently performed over data formats andanalyse how well each task is supported by a particular modelling structure. From ouranalysis; we make recommendations as to the types of modelling structure that are most …,Bmc Bioinformatics,2005,14
Virtual realms: an efficient implementation strategy for finite resolution spatial data types,Volker Muller; Norman W Paton; Alvaro AA Fernandes; Andrew Dinn; M Howard Williams,Abstract A realm is a planar graph over a finite resolution grid that has been proposed as ameans of overcoming problems of numerical robustness and topological correctness inspatial database systems. While the realm structure and the spatial algebra that isassociated with it provide a range of desirable facilities for modelling spatial information indatabase systems; widespread exploitation will only be practical if efficient implementationstrategies are identified. This paper shows how data types can be supported efficiently overvirtual realms; where the finite resolution grid is not stored explicitly; but is generated onlypartially and as needed. This approach avoids the considerable storage space overheadsassociated with the original proposal for the implementation of realms; and provides overallruntime performance that often improves upon that of less space efficient implementation …,IN SDH'96,1996,14
Pay-as-you-go data integration for linked data: opportunities; challenges and architectures,Norman W Paton; Klitos Christodoulou; Alvaro AA Fernandes; Bijan Parsia; Cornelia Hedeler,Abstract Linked Data (LD) provides principles for publishing data that underpin thedevelopment of an emerging web of data. LD follows the web in providing low barriers toentry: publishers can make their data available using a small set of standard technologies;and consumers can search for and browse published data using generic tools. Like the web;consumers frequently consume data in broadly the form in which it was published; this willbe satisfactory in some cases; but the diversity of publishers means that the data required tosupport a task may be stored in many different sources; and described in many differentways. As such; although RDF provides a syntactically homogeneous language fordescribing data; sources typically manifest a wide range of heterogeneities; in terms of howdata on a concept is represented. This paper makes the case that many aspects of both …,Proceedings of the 4th International Workshop on Semantic Web Information Management,2012,13
Validated cost models for sensor network queries,Christian YA Brenninkmijer; Ixent Galpin; Alvaro AA Fernandes; Norman W Paton,Abstract Generating a good execution plan for a declarative query has long been a centralproblem in data management research. With the rise in interest in wireless sensor networks(WSNs) as query processing platforms; it was quickly noticed that the correspondingoptimization problem is even more challenging than the classical one; since; in comparisonto classical platforms; a WSN is a very constrained computational infrastructure (in terms ofmemory; processing; and communication capabilities; and; crucially; depletable energystocks). Optimizing a declarative query for execution in WSNs is thereby made both moreimportant and more challenging. One of the requirements for effective query optimization isthe availability of effective models for estimating the cost of alternative execution plans. Thispaper describes how query cost models for space; time and energy were methodically …,Proceedings of the Sixth International Workshop on Data Management for Sensor Networks,2009,13
A foundation for the replacement of pipelined physical join operators in adaptive query processing,Kwanchai Eurviriyanukul; Alvaro AA Fernandes; Norman W Paton,Abstract Adaptive query processors make decisions as to the most effective evaluationstrategy for a query based on feedback received while the query is being evaluated. Inessence; any of the decisions made by the optimizer (eg; on operator order or on whichoperators to use) may be revisited in an adaptive query processor. This paper focuses onchanges to physical operators (eg; the specific join operators used; such as hash-join ormerge-join) in pipelined query evaluators. In so doing; the paper characterizes the runtimeproperties of pipelined operators in a way that makes explicit when specific operators maybe replaced; and that allows the validity of operator replacements to be proved. This isillustrated with reference to the substitution of join operators during their evaluation.,International Conference on Extending Database Technology,2006,13
Estimating the quality of answers when querying over description logic ontologies,Martin Peim; Enrico Franconi; Norman W Paton,Abstract Information integration systems allow users to express queries over high-levelconceptual models. However; such queries must subsequently be evaluated overcollections of sources; some of which are likely to be expensive to use or subject to periodsof unavailability. As such; it would be useful if information integration systems were able toprovide users with estimates of the consequences of omitting certain sources from queryexecution plans. Such omissions can affect both the soundness (the fraction of returnedanswers which are returned) and the completeness (the fraction of correct answers whichare returned) of the answer set returned by a plan. Many recent information integrationsystems have used conceptual models expressed in description logics (DLs). This paperpresents an approach to estimating the soundness and completeness of queries …,Data & Knowledge Engineering,2003,13
Grid database service specification,Neil P Chue Hong; Amy Krause; Susan Malaika; Gavin McCance; Simon Laws; James Magowan; Norman W Paton; G Ricardi,Abstract Data management systems are central to many applications across multipledomains; and play a significant role in many others. Web services provide implementationneutral facilities for describing; invoking and orchestrating collections of networkedresources. The Open Grid Services Architecture (OGSA) extends Web Services withconsistent interfaces for creating; managing and exchanging information among GridServices; which are dynamic computational artefacts cast as Web Services. Both Web andGrid service communities stand to benefit from the provision of consistent; agreed serviceinterfaces to database management systems. Such interfaces must support the descriptionand use of database systems using Web Service standards; taking account of the designconventions and mandatory features of Grid Services. This document presents a …,GGF Informational Document,2003,13
Active rule analysis and optimisation in the rock & roll deductive object-oriented database,Andrew Dinn; Norman W Paton; M Howard Williams,Abstract Active database systems provide facilities that monitor and respond to changes ofrelevance to the database. Active behaviour is normally described using Event ConditionAction rules (ECA-rules); and a number of systems have been developed; based upondifferent data models; that support such rules. However; experience using active databasesshows that while such systems are powerful and potentially useful in many applications; theyare hard to program and liable to exhibit poor performance at runtime. This documentaddresses both of these issues by examining both analysis and optimisation of active rulesin the context of a powerful active database system. It is shown how rule analysis methodsdeveloped for straightforward active rule languages for relational data models can beextended to take account of rich event description languages and more powerful …,Information Systems,1999,13
An Open-Model-Based Interface Development System: The Teallach Approach.,Tony Griffiths; Jo McKirdy; Norman W Paton; Jessie B Kennedy; Richard Cooper; Peter J Barclay; Carole A Goble; Philip D Gray; Michael Smyth; Adrian West; Andrew Dinn,Abstract. The goal of the Teallach project is to provide facilities for the systematicdevelopment of interfaces to object databases in a manner which is independent of both aspecific underlying database and operating system. Teallach's open architecture also allowsthe creation of interfaces to nondatabase applications in a platform-independent manner. Tothis end Teallach adopts model-based techniques in the process of interface construction;exploits the cross-platform capabilities of Java; and utilises the Java Beans API to allow third-party interface components to be exploited. Through the use of a simple case study thispaper introduces the Teallach approach to interface development; providing an overview ofthe system; its motivations; and underlying technology.,DSV-IS (2),1998,13
An Axiomatic approach to deductive object-oriented databases,Alvaro Adolfo Antunes Fernandes; M Howard Williams; Norman W Paton,This introduction constitutes a broadly sketched overview of all the research results reportedin this dissertation. The introduction discusses the background; motivation and challengesfor that research; and provides a preliminary overview of related work. The central problemwhich the research endeavoured to solve is then stated and the methods through which asolution was achieved are presented. The introduction closes with a brief summary of thecontributions reported. Relational databases (RDBs) 1 (Date; 1990; Kanellakis; 1990;Ullman; 1988) are the state-of-the-art in database management systems (DBMSs) in mostbusiness environments. However; a growing awareness of weaknesses in RDBs has led toresearch into; among others; two new classes of systems that speci cally address theseweaknesses: deductive relational databases (DRDBs)(Ceri et al.; 1990b; Das; 1992; …,*,1995,13
Data Wrangling for Big Data: Challenges and Opportunities.,Tim Furche; Georg Gottlob; Leonid Libkin; Giorgio Orsi; Norman W Paton,ABSTRACT Data wrangling is the process by which the data required by an application isidentified; extracted; cleaned and integrated; to yield a data set that is suitable forexploration and analysis. Although there are widely used Extract; Transform and Load (ETL)techniques and platforms; they often require manual work from technical and domainexperts at different stages of the process. When confronted with the 4 V's of big data(volume; velocity; variety and veracity); manual intervention may make ETL prohibitivelyexpensive. This paper argues that providing cost-effective; highly-automated approaches todata wrangling involves significant research challenges; requiring fundamental changes toestablished areas such as data extraction; integration and cleaning; and to the ways inwhich these areas are brought together. Specifically; the paper discusses the importance …,EDBT,2016,12
Utility functions for adaptively executing concurrent workflows,Kevin Lee; Norman W Paton; Rizos Sakellariou; Alvaro AA Fernandes,Abstract Workflows are widely used in applications that require coordinated use ofcomputational resources. Workflow definition languages typically abstract over someaspects of the way in which a workflow is to be executed; such as the level of parallelism tobe used or the physical resources to be deployed. As a result; a workflow managementsystem has the responsibility of establishing how best to map tasks within a workflow to theavailable resources. As workflows are typically run over shared resources; and thus faceunpredictable and changing resource capabilities; there may be benefit to be derived fromadapting the task-to-resource mapping while a workflow is executing. This paper describesthe use of utility functions to express the relative merits of alternative mappings; in essence;a utility function can be used to give a score to a candidate mapping; and the exploration …,Concurrency and Computation: Practice and Experience,2011,12
A parallel algebra for object databases,NW Paton; P Watson; Jim Smith,The paper describes an algebra for use with parallel object databases; and in particularODMG compliant databases with OQL. Although there have been many proposals forparallel relational database systems; there has been much less work on parallel objectdatabases; and on parallel query processing for object databases. The parallel algebrapresented in the paper is an extension of an existing physical algebra for OQL; and has animportant role during query optimization; and for describing execution plans. The paperpresents not only the algebra; but also its role in the architecture of a parallel database.,Database and Expert Systems Applications; 1999. Proceedings. Tenth International Workshop on,1999,12
Deductive queries in ODMG databases: the DOQL approach,Pedro RF Sampaio; Norman W Paton,Abstract The Deductive Object Query Language (DOQL) is a rule-based query languagedesigned to provide recursion; aggregates; grouping and virtual collections in the context ofan ODMG compliant object database system. This paper provides a description of theconstructs supported by DOQL and the algebraic operational semantics induced by DOQL'squery translation approach to implementation. The translation consists of a logical rewritingstep used to normalise DOQL expressions into molecular forms; and a mapping step thattransforms the canonical molecular form into algebraic expressions. The paper thus not onlydescribes a deductive language for use with ODMG databases; but indicates how thislanguage can be implemented using conventional query processing techniques.,*,1998,12
The implementation of a deductive query language over an OODB,Andrew Dinn; Norman W Paton; M Howard Williams; Alvaro AA Fernandes; Maria L Barja,Abstract The ROCK & ROLL database system cleanly integrates deductive and object-oriented capabilities by defining an imperative programming language; ROCK; and adeclarative; deductive language; ROLL; over a common object-oriented (OO) data model.Existing techniques for evaluation and optimization of deductive languages fail to addresskey requirements imposed by ROLL such as: strict typing; placement of deductive methods(predicates) within classes; encapsulation; overriding and late binding. This paper describesthe task of implementing an evaluator and optimizer for ROLL; explaining how existingimplementation techniques for deductive languages were adapted to meet theserequirements and extended to support novel types of optimization.,International Conference on Deductive and Object-Oriented Databases,1995,12
A structured specification of an active database system,Jack Campin; Norman W Paton; M Howard Williams,Abstract Active database systems are a current focus of considerable research interest; as ameans of supporting a range of tasks including constraint enforcement; real-timeapplications and derived data management. However; although many different proposalshave been made for active rule systems; such proposals are normally described in aninformal manner; which makes it difficult to understand how different proposals differ or howa set of rules will behave. This paper compares a range of formal specification methods;considering how suitable they are for describing active database functionality; and thenshows how the model-based notation Object-Z; an object-oriented extension of Z; can beused to specify the semantics of a representative active database system; namely Starburst.,Information and Software Technology,1995,12
Visualizing advanced data modelling constructs,Ghassan al-Qaimari; Norman W Paton; Alistair C Kilgour,Abstract Semantic data modelling constructs; such as relationships; composite objects andversions; are used to represent knowledge explicitly in object-oriented databases. Suchconstructs increase the ability of the database to capture not only the structural aspects ofdata; as in traditional databases; but also the meaning of data. The modelling process canbe further enhanced by supporting expressive visual representations of the constructs in adirect-manipulation interface. This paper focuses upon the development of effectivevisualizations for such constructs by presenting a range of sample visualizations; outlininghow they can be prototyped rapidly in an integrated interface development environment; anddescribing how evaluation techniques can be used to assess alternative proposals.,Information and Software Technology,1994,12
Optimizing virtual machine placement for energy and SLA in clouds using utility functions,Abdelkhalik Mosa; Norman W Paton,Abstract Cloud computing provides on-demand access to a shared pool of computingresources; which enables organizations to outsource their IT infrastructure. Cloud providersare building data centers to handle the continuous increase in cloud users' demands.Consequently; these cloud data centers consume; and have the potential to waste;substantial amounts of energy. This energy consumption increases the operational cost andthe CO 2 emissions. The goal of this paper is to develop an optimized energy and SLA-aware virtual machine (VM) placement strategy that dynamically assigns VMs to PhysicalMachines (PMs) in cloud data centers. This placement strategy co-optimizes energyconsumption and service level agreement (SLA) violations. The proposed solution adoptsutility functions to formulate the VM placement problem. A genetic algorithm searches the …,Journal of Cloud Computing,2016,11
An efficient load balancing LQR controller in parallel database queries under random perturbations,Anastasios Gounaris; Christos A Yfoulis; Norman W Paton,This work investigates the problem of dynamic; intra-query load balancing in paralleldatabase queries across heterogeneous nodes in a way that takes into account the inherentcost of adaptations and thus avoids both over-reacting and deciding when to adapt in acompletely heuristic manner. The latter may lead to serious performance degradation inseveral cases; such as periodic and random imbalances. We follow a control theoreticalapproach to this problem; more specifically; we propose a multiple-input multiple-outputfeedback linear quadratic regulation (LQR) controller; which captures the tradeoff betweenreaching a balanced state and the cost inherent in such adaptations. Our approach; apartfrom benefitting from and being characterized by a solid theoretical foundation; exhibitsbetter performance than state-of-the-art heuristics in realistic situations; as verified by …,Control Applications;(CCA) & Intelligent Control;(ISIC); 2009 IEEE,2009,11
Defining and using schematic correspondences for automatically generating schema mappings,Lu Mao; Khalid Belhajjame; Norman W Paton; Alvaro AA Fernandes,Abstract Mapping specification has been recognised as a critical bottleneck to the largescale deployment of data integration systems. A mapping is a description using which datastructured under one schema are transformed into data structured under a different schema;and is central to data integration and data exchange systems. In this paper; we argue thatthe classical approach of correspondence identification followed by (manual) mappinggeneration can be simplified through the removal of the second step by judicious refinementof the correspondences captured. As a step in this direction; we present in this paper amodel for schematic correspondences that builds on and extends the classificationproposed by Kim et al. to cater for the automatic derivation of mappings; and present analgorithm that shows how correspondences specified in the model proposed can be used …,International Conference on Advanced Information Systems Engineering,2009,11
Modeling and managing experimental data using FuGE,Andrew R Jones; Allyson L Lister; Leandro Hermida; Peter Wilkinson; Martin Eisenacher; Khalid Belhajjame; Frank Gibson; Phil Lord; Matthew Pocock; Heiko Rosenfelder; Javier Santoyo-Lopez; Anil Wipat; Norman W Paton,Abstract The Functional Genomics Experiment data model (FuGE) has been developed toincrease the consistency and efficiency of experimental data modeling in the life sciences;and it has been adopted by a number of high-profile standardization organizations. FuGEcan be used:(1) directly; whereby generic modeling constructs are used to representconcepts from specific experimental activities; or (2) as a framework within which method-specific models can be developed. FuGE is both rich and flexible; providing a considerablenumber of modeling constructs; which can be used in a range of different ways. However;such richness and flexibility also mean that modelers and application developers havechoices to make when applying FuGE in a given context. This paper captures emerging bestpractice in the use of FuGE in the light of the experience of several groups by:(1) …,OMICS A Journal of Integrative Biology,2009,11
An experience report on designing and building OGSA-DQP: A service based distributed query processor for the grid,M Nedim Alpdemir; Arijit Mukherjee; Anastasios Gounaris; Alvaro AA Fernandes; Norman W Paton; Paul Watson,Abstract OGSA-DQP is a distributed query processor exposed to users as an OGSA-compliant Grid service. This service supports the compilation and evaluation of queries thatcombine data obtained from multiple services on the Grid; including Grid Database Services(GDSs) provided by OGSA-DAI project. Not only does OGSA-DQP support integrated accessto multiple Grid services; it is itself implemented as a collection of interacting Grid services.Thus; OGSA-DQP is an example of a Grid service with a significant amount of aggregatedfunctionality that; in addition; illustrates how Grid service orchestrations can be used toperform reasonably complex; data-intensive parallel computations. OGSA-DQP prototypehas been released and it is downloadable from www. ogsadai. org. uk/dqp/. This papercontributes an experience report on the design of OGSA-DQP; with a particular emphasis …,Proceedings of Global Grid Forum Workshop on Designing and Building Grid Services,2003,11
Tripod: A spatio-historical object database system,Tony Griffiths; Alvaro AA Fernandes; Norman W Paton; Seung-Hyun Jeong; Nassima Djafri; Keith T Mason; Bo Huang; Mike Worboys,Abstract The storage and analysis of large amounts of time varying spatial and aspatial datais becoming an important feature of many application domains. This requirement has fueledthe need for spatio-temporal extensions to data models and their associated queryingfacilities. To date; much of this work has focused on the relational data model; with objectdata models receiving far less consideration. Where descriptions of such object models doexist; there is currently a lack of systems which build upon these models to producedatabase architectures that address the broad spectrum of issues related to the delivery of afully functional spatio-temporal DBMS. This chapter presents an overview of such a systemby describing a spatio-historical object model that utilizes a specialized mechanism; called ahistory; for maintaining knowledge about entities that change over time; and a tour …,*,2002,11
Extending a deductive object-oriented database system with spatial data handling facilities,Alvaro AA Fernandes; Andrew Dinn; Norman W Paton; M Howard Williams; Olive Liew,Abstract This paper describes the integration of a spatial data-handling component with theROCK & ROLL deductive object-oriented database system. The extended ROCK & ROLLsystem provides much more comprehensive and better integrated database programmingfacilities than other candidate platforms for spatial information systems. The extendedsystem serves developers with an intuitive; expressive; formally defined collection of spatialdata types as primitive types whose operations have state-of-the-art computationalcomplexity. The integration of these types with the object-oriented modelling; imperativeprogramming and deductive querying facilities of ROCK & ROLL makes available acomprehensive and integrated suite of complementary mechanisms for the development ofspatial information systems. The paper also provides preliminary benchmark results …,Information and Software Technology,1999,11
Design and user testing of a multi-paradigm query interface to an object-oriented database,Dac Khoa Doan; Norman W Paton; Alistair Kilgour,Abstract This paper reports on experience obtained during the design; implementation anduse of a multi-paradigm query interface to an object-oriented database. The specific systemwhich has been developed allows equivalent data retrieval tasks to be expressed usingtextual; form-based and graph-based notations; and supports automatic translation ofqueries between these three paradigms. The motivation behind the development of such aninterface is presented; as is the software architecture which supports the multi-paradigmfunctionality. Feedback from initial user trials with a dual-paradigm version of the systemindicates that users can use it to perform complex query tasks without difficulty; that given thechoice users overwhelmingly prefer the graph-based to the text-based interaction style; andthat graphical visualisation of textual queries appears to aid users in query construction.,ACM SIGMOD Record,1995,11
A Logical Query Language for an Object-Oriented Data Model,Alvaro AA Fernandes; Norman W Paton; M Howard Williams,Abstract We report on our experience in designing and prototyping ROLL; a logical querylanguage under which object-oriented databases conforming to the model defined in [14;15] can be seen as deductive object-oriented databases. The main contribution of ROLL isto demonstrate the possibility of pursuing for the object-oriented case the same researchstrategy used in the last decade to extend relation databases with deduction. This paperbriefly describes the rationale behind our approach to the field and the DOOD project that isunderway at Heriot-Watt. After an introduction to ROLL's underlying data model by means ofa simple example; the paper focusses on the implementation of ROLL in a prototype whichhas been built to experiment with both the language and the model. Certain techniquesused in the prototype are described; and ROLL is contrasted with some well-known …,*,1994,11
Adaptive join processing in pipelined plans,Kwanchai Eurviriyanukul; Norman W Paton; Alvaro AA Fernandes; Steven J Lynden,Abstract In adaptive query processing; the way in which a query is evaluated is changed inthe light of feedback obtained from the environment during query evaluation. Such feedbackmay; for example; establish that misleading selectivity estimates were used when the querywas compiled; leading to the optimizer choosing an inappropriate join order or unsuitablejoin algorithms. This paper describes how joins can be reordered; and the join algorithmsused replaced; while they are being evaluated in pipelined plans. Where joins are reorderedand/or replaced during their evaluation; the approach avoids duplicating work that hasalready been carried out; by resuming from where the previous plan left off. The approachhas been evaluated empirically; and shown to be effective for improving query performancein the light of misleading selectivity estimates.,Proceedings of the 13th International Conference on Extending Database Technology,2010,10
dataspaces,Cornelia Hedeler; Khalid Belhajjame; Norman W Paton; Alessandro Campi; Alvaro AA Fernandes; Suzanne M Embury,Abstract The vision of dataspaces is to provide various of the benefits of classical dataintegration; but with reduced up-front costs; combined with opportunities for incrementalrefinement; enabling a “pay as you go” approach. As such; dataspaces join a long stream ofresearch activities that aim to build tools that simplify integrated access to distributed data.To address dataspace challenges; many different techniques may need to be considered:data integration from multiple sources; machine learning approaches to resolving schemaheterogeneity; integration of structured and unstructured data; management of uncertainty;and query processing and optimization. Results that seek to realize the different visionsexhibit considerable variety in their contexts; priorities and techniques. This chapter presentsa classification of the key concepts in the area; encouraging the use of consistent …,*,2010,10
Measuring and modelling the performance of a parallel odmg compliant object database server,Sandra de F Mendes Sampaio; Norman W Paton; Jim Smith; Paul Watson,Abstract Object database management systems (ODBMSs) are now established as thedatabase management technology of choice for a range of challenging data intensiveapplications. Furthermore; the applications associated with object databases typically havestringent performance requirements; and some are associated with very large data sets. Animportant feature for the performance of object databases is the speed at which relationshipscan be explored. In queries; this depends on the effectiveness of different join algorithmsinto which queries that follow relationships can be compiled. This paper presents aperformance evaluation of the Polar parallel object database system; focusing in particularon the performance of parallel join algorithms. Polar is a parallel; shared-nothingimplementation of the Object Database Management Group (ODMG) standard for object …,Concurrency and Computation: Practice and Experience,2006,10
An outline of the global grid forum data access and integration service specifications,Mario Antonioletti; Amy Krause; Norman W Paton,Abstract Grid computing concerns itself with building the infrastructure to facilitate thesharing of computational and data resources to enable collaboration within virtualorganisations. The Global Grid Forum (GGF) provides a framework for users; developersand vendors to come together to develop standards to ensure interoperability betweenmiddleware from different service providers. Central to this effort is the Open Grid ServicesArchitecture (OGSA); and its associated specifications. These define consistent interfaces;generally couched as web services; and the components required to construct gridinfrastructures. Both the web service and grid communities stand to benefit from theprovision of consistent and agreed web service interfaces for data resources and thesystems that manage them. This paper describes; motivates and presents the context for …,Workshop on Data Management in Grids,2005,10
Web Services Data Access and Integration–The XML Realization (WS-DAIX) Specification; Version 1.0,M Antonioletti; Amy Krause; Stephen Langella; Simon Laws; Susan Malaika; Norman W Paton,Abstract Data resources play a significant role in many applications across multipledomains. Web services provide implementation neutral facilities for describing; invoking andorchestrating collections of networked resources. The GGF (Global Grid Forum) Open GridServices Architecture (OGSA); and its associated specifications; defines consistentinterfaces through web services to components of the grid infrastructure. Both the web andgrid communities stand to benefit from the provision of consistent and agreed web serviceinterfaces for data resources and the systems that manage them.,Draft. Global Grid Forum,2005,10
OGSA-DAI usage scenarios and behaviour: Determining good practice,Mario Antonioletti; M Atkinson; A Borley; N Chue Hong; B Collins; J Davies; H Hardman; A Hume; M Jackson; A Krause; S Laws; N Paton; T Sugden; D Vyvyan; P Watson; M Westhead,Abstract OGSA-DAI has been developing Grid middleware for over two years now. A highprofile project within the Grid community OGSA-DAI is increasingly being used by Gridbased projects to provide their Data Access and Integration (DAI) requirements. From asimple set of services relatively sophisticated usage scenarios may be realised. Thispresentation examines a number of DAI scenarios identified by OGSA-DAI and the GGFDAIS working group and demonstrates how the existing OGSA-DAI framework satisfiesthem. A number of real use-cases from the projects that are using OGSA-DAI are outlinedand gaps within the existing OGSA-DAI framework are identified. The OGSA-DAI softwaredistribution and further information about the project is available from the project website athttp://www. ogsadai. org. uk/.,Proceedings of the Third UK e Science All Hands Meeting,2004,10
Ogsa-dai status report and future directions,Mario Antonioletti; M Atkinson; R Baxter; A Borley; NP Chue Hong; B Collins; J Davies; D Fitzgerald; N Hardman; AC Hume; M Jackson; A Krause; S Laws; NW Paton; T Sugden; P Watson; M Westhead; D Vyvyan,Abstract The OGSA-DAI middleware has been publicly available for over two years. OGSA-DAI facilitates Data Access and Integration (DAI) of data resources; such as relational andXML databases; within a Grid context. Project members also participate in the developmentof DAI standards through the GGF DAIS WG. The standards that emerge through this effortwill be adopted by OGSA-DAI once they have stabilised. The OGSA-DAI developers are alsoengaging with a growing user community to gather their data and functionality requirements.Several large projects are already using OGSADAI to provide their DAI capabilities. Thispaper presents a status report on OGSA-DAI activities since the last AHM and announcesfuture directions. The OGSA-DAI software distribution and more information about the projectis available from the project website at http://www. ogsadai. org. uk/.,Proceedings of the UK e-Science All Hands Meeting,2004,10
Grid Database Service Specification,Amy Krause; Susan Malaika; Gavin McCance; James Magowan; Norman W Paton; Greg Riccardi,Abstract Data management systems are central to many applications across multipledomains; and play a significant role in many others. Web services provide implementationneutral facilities for describing; invoking and orchestrating collections of networkedresources. The Open Grid Services Architecture (OGSA) extends Web Services withconsistent interfaces for creating; managing and exchanging information among GridServices; which are dynamic computational artefacts cast as Web Services. Both Web andGrid service communities stand to benefit from the provision of consistent; agreed serviceinterfaces to database management systems. Such interfaces must support the descriptionand use of database systems using Web Service standards; taking account of the designconventions and mandatory features of Grid Services. This document presents a …,Global Grid Forum,2002,10
Information Management for Genome Level Bioinformatics.,Norman W Paton; Carole A Goble,Page 1. Information Management for Genome Level Bioinformatics Norman Paton and CaroleGoble Department of Computer Science University of Manchester Manchester; UK <norm;carole>@cs.man.ac.uk Structure of Tutorial ∎ Introduction - why it matters. ∎ Genome level data. ∎Genomic databases. ∎ Modelling challenges. ∎ Integrating biological databases. ∎ Analysinggenomic data. ∎ Summary and challenges. Information Management for Genome LevelBioinformatics - Paton; Goble 213 Page 2. Information Management for Genome LevelBioinformatics Norman Paton and Carole Goble Department of Computer Science Universityof Manchester Manchester; UK <norm; carole>@cs.man.ac.uk Structure of Tutorial ∎ Introduction -why it matters. ∎ Genome level data. ∎ Modelling challenges. ∎ Genomic databases. ∎ Integratingbiological databases. ∎ Analysing genomic data. ∎ Summary and challenges …,VLDB,2001,10
Database Challenges for Genome Information in the Post Sequencing Phase Moussouni,Fouzia Moussouni; Norman W Paton; Andy Hayes; Steve Oliver; Carole A Goble; Andy Brass,Abstract Genome sequencing projects are making available to scientists complete records ofthe genetic make-up of organisms. The resulting data sets; along with the results ofexperiments that seek systematically to find new information on the functions of genes; willpresent numerous opportunities and challenges to biologists. However; the complexity andvariety of both the data and the analyses required over such data sets also pose significantchallenges to computer scientists charged with providing effective information managementsystems for use with genome data. This paper presents models for the sorts of informationthat are being produced on genomes and genome-wide experiments; and outlines a projectdeveloping an information management system aimed at supporting analyses over genomicdata. This information management system replicates data from other sources; with a …,International Conference on Database and Expert Systems Applications,1999,10
Kaleidoscape: A 3D Environment for Querying ODMG Compliant Databases,Norman Murray; Carole Goble; Norman Paton,Abstract Kaleidoscape is a three dimensional (3D) implementation of a data-flow orientedvisual query language; which has been implemented in 3D to examine the advantages anddisadvantages of such an interface paradigm over current WIMP GUIs. This paper describesa version of Kaleidoscape that allows the user to construct queries from within a 3Denvironment. These queries are then translated into the ODMG standard textual querylanguage OQL for evaluation; the results of which can be viewed and browsed from withinthe Kaleidoscape environment.,*,1998,10
The structures of human C1r and C1s and their relationship to other serine proteases.,J Fothergill; G Kemp; N Paton; P Carter; P Gray,Abstract The recent sequencing of the C1 subcomponents has allowed comparison withother molecules of homologous primary structure. Where tertiary structures are available forat least one member of the family it is possible to make further progress by modelling theamino acid sequence of the complement protein into the three-dimensional coordinates ofthe directly determined structure; thereby obtaining an approximation of the structure of thecomplement protein. Molecular modelling allows structure-function relationships to beexplored and suggests further experiments that may be amenable to techniques such as site-directed mutagenesis.,*,1989,10
A toolkit for capturing and sharing FuGE experiments,Khalid Belhajjame; Andrew R Jones; Norman W Paton,Abstract Motivation: The Functional Genomics Experiment Object Model (FuGE) supportsmodelling of experimental processes either directly or through extensions that specializeFuGE for use in specific contexts. FuGE applications commonly include components thatcapture; store and search experiment descriptions; where the requirements of differentapplications have much in common. Results: We describe a toolkit that supports datacapture; storage and web-based search of FuGE experiment models; the toolkit can be useddirectly on FuGE compliant models or configured for use with FuGE extensions. The toolkit isillustrated using a FuGE extension standardized by the proteomics standards initiative;namely GelML. Availability: The toolkit and a demonstration are available at http://code.google. com/p/fugetoolkit Contact: khalid. belhajjame@ manchester. ac. uk,Bioinformatics,2008,9
Pedro ontology services: A framework for rapid ontology markup,Kevin Garwood; Phillip Lord; Helen Parkinson; Norman W Paton; Carole Goble,Abstract Semantic Web technologies offer the possibility of increased accuracy andcompleteness in search and retrieval operations. In recent years; curators of data resourceshave begun favouring the use of ontologies over the use of free text entries. Generally thishas been done by marking up existing database records with “annotations” that containontology term references. Although there are a number of tools available for developingontologies; there are few generic resources for enabling this annotation process. This paperexamines the requirements for such an annotation tool; and describes the design andimplementation of the Pedro Ontology Service Framework; which seeks to fulfill theserequirements.,European Semantic Web Conference,2005,9
Validated cost models for parallel OQL query processing,Sandra F Mendes de Sampaio; Norman W Paton; Jim Smith; Paul Watson,Abstract Query cost models are widely used; both for performance analysis and forcomparing execution plans during query optimisation. In essence; a cost modelp redictswhere time is being spent during query evaluation. Although many cost models have beenproposed; for serial; parallel and distributed database systems; surprisingly few of thesehave been validated against real systems. This paper presents cost models for the parallelevaluation of ODMG OQL queries; which have been compared with experimental resultsobtained using the Polar object database system. The paper describes the validation of thecost model for a collection of queries; using three join algorithms over the OO7 benchmarkdatabase. The results show that the cost model generally both ranks alternative plansappropriately; and gives a useful indication of the response times that can be expected …,International Conference on Object-Oriented Information Systems,2002,9
An experimental performance evaluation of join algorithms for parallel object databases,Sandra F de Mendes Sampaio; Jim Smith; Norman W Paton; Paul Watson,Abstract Parallel relational databases have been successful in providing scalableperformance for data intensive applications; and much work has been carried out on queryprocessing techniques in such systems. However; although many applications associatedwith object databases also have stringent performance requirements; there has been muchless work investigating parallel object database systems. An important feature for theperformance of object databases is the speed at which relationships can be explored. Inqueries; this depends upon the effectiveness of different join algorithms into which queriesthat follow relationships can be compiled. This paper presents the results of empiricalevaluations of four parallel join algorithms; two value based and two pointer based. Theexperiments have been run on Polar; a parallel ODMG object database system.,European Conference on Parallel Processing,2001,9
Integrated architectures for database interface development,NW Paton; RL Cooper; D England; G Al-Qaimari; AC Kilgour,Presents a number of approaches to the development of database interfaces; with aparticular emphasis upon the development of such interfaces within the confines of thedatabase system itself. Conventional approaches to interface development are reviewed;and weaknesses identified which stem from the decoupling of regularly interactingcomponents. It is shown how a more integrated approach; in which databases are used toimplement their own interfaces; provides significant direct benefits without precludingsubsequent support for mainstream interface development architectures.,IEE Proceedings-Computers and Digital Techniques,1994,9
An object-oriented database for storage and analysis of protein structure data,Norman W Paton; Peter MD Gray,*,Prolog and databases: implementations and new directions,1989,9
Verification of semantic web service annotations using ontology-based partitioning,Khalid Belhajjame; Suzanne M Embury; Norman W Paton,Semantic annotation of web services has been proposed as a solution to the problem ofdiscovering services to fit a particular need and reusing them appropriately. While there existtools that assist human users in the annotation task; eg; Radiant and Meteor-S; no semanticannotation proposal considers the problem of verifying the accuracy of the resultingannotations. Early evidence from workflow compatibility checking suggests that theproportion of annotations that contain some form of inaccuracy is high; and yet no tools existto help annotators to test the results of their work systematically before they are deployed forpublic use. In this paper; we adapt techniques from conventional software testing to theverification of semantic annotations for web service input and output parameters. We presentan algorithm for the testing process and discuss ways in which manual effort from the …,IEEE Transactions on Services Computing,2014,8
Efficient load balancing in partitioned queries under random perturbations,Anastasios Gounaris; Christos A Yfoulis; Norman W Paton,Abstract This work investigates a particular instance of the problem of designing efficientadaptive systems; under the condition that each adaptation decision incurs somenonnegligible cost when enacted. More specifically; we deal with the problem of dynamic;intraquery load balancing in parallel database queries across heterogeneous nodes in away that takes into account the inherent cost of adaptations and thus avoids bothoverreacting and deciding when to adapt in a completely heuristic manner. The latter maylead to serious performance degradation in several cases; such as periodic and randomimbalances. We follow a control theoretical approach to this problem; more specifically; wepropose a multiple-input multiple-output feedback linear quadratic regulation (LQR)controller; which captures the tradeoff between reaching a balanced state and the cost …,ACM Transactions on Autonomous and Adaptive Systems (TAAS),2012,8
Integrative information management for systems biology,Neil Swainston; Daniel Jameson; Peter Li; Irena Spasic; Pedro Mendes; Norman W Paton,Abstract Systems biology develops mathematical models of biological systems that seek toexplain; or better still predict; how the system behaves. In bottom-up systems biology;systematic quantitative experimentation is carried out to obtain the data required toparameterize models; which can then be analyzed and simulated. This paper describes anapproach to integrated information management that supports bottom-up systems biology;with a view to automating; or at least minimizing the manual effort required during; creationof quantitative models from qualitative models and experimental data. Automating theprocess makes model construction more systematic; supports good practice at all stages inthe pipeline; and allows timely integration of high throughput experimental results intomodels.,International Conference on Data Integration in the Life Sciences,2010,8
Flexible dataspace management through model management,Cornelia Hedeler; Khalid Belhajjame; Lu Mao; Norman Paton; Alvaro AA Fernandes; Chenjuan Guo; Suzanne M Embury,ABSTRACT The vision of dataspaces has been articulated as providing various of thebenefits of classical data integration but with reduced up-front costs; which; combined withopportunities for incremental refinement; enables a “pay as you go” approach to the dataintegration problem. However; results that seek to realise the vision tend to make designcommitments; often to meet quite specific application assumptions; that are likely to restricttheir wider use. Instead of precommitting to a specific solution; we build on research inmodel management and present a generic framework consisting of a collection of types andoperations for dataspace management systems that can be instantiated in various ways. Thekey extension for dataspaces is the integration of user feedback as annotations to modelmanagement constructs; and the development of operations that take account of these …,Proceedings of the 2010 EDBT/ICDT Workshops,2010,8
search computing and the life sciences,Marco Masseroli; Norman W Paton; Irena Spasić,Abstract Search Computing has been proposed to support the integration of the results ofsearch engines with other data and computational resources. A key feature of the resultingintegration platform is direct support for multi-domain ordered data; reflecting the fact thatsearch engines produce ranked outputs; which should be taken into account when theresults of several requests are combined. In the life sciences; there are many different typesof ranked data. For example; ranked data may represent many different phenomena;including physical ordering within a genome; algorithmically assigned scores that representlevels of sequence similarity; and experimentally measured values such as expressionlevels. This chapter explores the extent to which the search computing functionalitiesdesigned for use with search engine results may be applicable for different forms of …,*,2010,8
Applying functional languages in knowledge-based information integration systems,Martin Peim; Norman W Paton; Enrico Franconi,Summary Knowledge-based information integration systems exploit rich descriptions ofdomain knowledge to support query formulation; source reconciliation or query optimisation.A characteristic shared by most such systems is that at some stage during query compilation;a query is translated from an expression over the knowledge base into one phrased in termsof the data models of the (possibly wrapped) sources that are being integrated. Individualproposals differ (i) in the knowledge model used;(ii) in the source model and languageused;(iii) in the nature of the rewriting required from the knowledge model to the sourcemodel; and (iv) in the role of the source model and language. This chapter discusses someof the alternative options and describes in some detail a knowledge-based query processor;in which:(i) the knowledge model is an expressive Description Logic;(ii) the source model …,*,2004,8
Query processing in DOQL: A deductive database language for the ODMG model,Pedro R Falcone Sampaio; Norman W Paton,Abstract This paper describes the architecture; algebraic query processing framework andquery execution approach that comprise the implementation of the deductive object querylanguage (DOQL) query processing system. To the best of our knowledge; it is the firstdeductive object query language to be designed and implemented as a complementary andnon-intrusive query component within an ODMG OODBMS architecture. The queryprocessing framework enables the combined use of logical rewriting and algebraicoptimization; and features an object algebra; local and global query optimization; physicalexecution algorithms implemented as iterators; and a query execution engine implementedusing the dataflow technique. Several representative DOQL queries are also provided;illustrating the flexibility and expressiveness of querying object databases with DOQL.,Data & Knowledge Engineering,2000,8
A deductive object-oriented database for data intensive application development,Alvaro AA Fernandes; Maria L Barja; Norman W Paton; M Howard Williams,Abstract This paper outlines an approach to the development of a deductive object-orienteddatabase system. The approach presented uses a formally defined object-oriented datamodel as the starting point for the development of a logic query language and an imperativedatabase programming language. These languages can be used independently—the logiclanguage for expressing queries or defining rule-based applications; the imperativelanguage for manipulating the database—or together to support a flexible system for data-intensive application development.,British National Conference on Databases,1993,8
On using prolog to implement object-oriented databases,Norman W Paton; Scott Leishman; Suzanne M Embury; Peter MD Gray,Abstract This paper outlines the use of Prolog for implementing object-oriented databases(OODBs); to indicate both the benefits and costs associated with Prolog as animplementation platform. The different roles which Prolog can play in the implementation ofan OODB are illustrated by reference to example systems which; although they use Prologas an implementation language; have significantly different architectures. Thesearchitectures are compared and assessed; both in terms of the functionality provided tousers; and performance.,Information and Software Technology,1993,8
Utility-driven adaptive query workload execution,Norman W Paton; Marcelo AT De Aragão; Alvaro AAA Fernandes,Abstract Workload management coordinates access to and use of shared computationalresources; adaptive workload execution revises resource allocation decisions dynamicallyin response to feedback about the progress of the workload or the behavior of the resources.Where the workload contains or consists of database queries; adaptive query processing(AQP) changes the way in which a query is being evaluated while the query is running. Inparallel environments; available adaptations may change the allocation of query fragmentsto a machine; for example to remove load imbalance or change the parallelism level. MostAQP strategies act on individual queries with the objective of reducing response times.However; where adaptations affect the usage of shared resources; or the principal goal is tomeet quality of service targets rather than to minimize overall response times; locally …,Future Generation Computer Systems,2012,7
Dstoolkit: An architecture for flexible dataspace management,Cornelia Hedeler; Khalid Belhajjame; Lu Mao; Chenjuan Guo; Ian Arundale; Bernadette Farias Lóscio; Norman W Paton; Alvaro AA Fernandes; Suzanne M Embury,Abstract The vision of dataspaces is to provide various of the benefits of classical dataintegration; but with reduced up-front costs. Combining this with opportunities forincremental refinement enables a 'pay-as-you-go'approach to data integration; resulting insimplified integrated access to distributed data. It has been speculated that modelmanagement could provide the basis for Dataspace Management; however; this has notbeen investigated until now. Here; we present DSToolkit; the first dataspace managementsystem that is based on model management; and therefore; benefits from the flexibilityprovided by the approach for the management of schemas represented in heterogeneousmodels; supports the complete dataspace lifecycle; which includes automatic initialisation;maintenance and improvement of a dataspace; and allows the user to provide feedback …,*,2012,7
Modular adaptive query processing for service-based grids,Anastasios Gounaris; Norman W Paton; Rizos Sakellariou; Alvaro AA Fernandes; Jim Smith; Paul Watson,Distributed and heterogeneous environments present significant challenges to complexsoftware systems; which must operate in the context of continuously changing loads; withpartial or out-of-date information on resource capabilities. A distributed query processor(DQP) can be used to access and integrate data from distributed sources; as well as forcombining data access with data analysis. However in heterogeneous environments;statically constructed query plans may commit a query evaluator to following significantlysuboptimal strategies. As such; there is considerable interest in using adaptive queryprocessors (AQPs) in such settings to provide self-optimizing behaviour. However; withmany possible adaptive strategies available; it is important that AQPs can be constructed ina systematic and efficient manner. This paper outlines an approach to the development of …,Autonomic Computing; 2006. ICAC'06. IEEE International Conference on,2006,7
A classification of tasks for the systematic study of immune response using functional genomics data,C Hedeler; NW Paton; Jerzy M Behnke; Janette E Bradley; MG Hamshere; KJ Else,Abstract A full understanding of the immune system and its responses to infection bydifferent pathogens is important for the development of anti-parasitic vaccines. A growingnumber of large-scale experimental techniques; such as microarrays; are being used to gaina better understanding of the immune system. To analyse the data generated by theseexperiments; methods such as clustering are widely used. However; individual applicationsof these methods tend to analyse the experimental data without taking publicly availablebiological and immunological knowledge into account systematically and in an unbiasedmanner. To make best use of the experimental investment; to benefit from existing evidence;and to support the findings in the experimental data; available biological information shouldbe included in the analysis in a systematic manner. In this review we present a …,Parasitology,2006,7
A generic algorithmic framework for aggregation of spatio-temporal data,Seung-Hyun Jeong; Alvaro AA Fernandes; Norman W Paton; Tony Griffiths,Spatio-temporal databases are often associated with analyses that summarize stored dataover spatial; temporal or spatio-temporal dimensions. For example; a study of traffic patternsmight explore average traffic densities on a road network at different times; over differentareas in space; and over different areas in space at different times. The importance oftemporal; spatial and spatio-temporal aggregation has been reflected in a significantnumber of proposals for algorithms for efficient computation of specific kinds of aggregation.However; although such proposals may be effective in particular cases; as yet there is nogeneric framework that provides efficient support for the wide range of partitioning andaggregation operations that a spatio-temporal database management system might beexpected to support over both stored and derived data. This paper proposes an …,Scientific and Statistical Database Management; 2004. Proceedings. 16th International Conference on,2004,7
Grid data management systems & services,Arun Jagatheesan; Reagan Moore; Norman W Paton; Paul Watson,Page 1. VLDB 2003 Berlin Grid Data Management Systems & Services Data Grid ManagementSystems – Part I Arun Jagatheesan; Reagan Moore Grid Services for Structured data –Part IIPaul Watson; Norman Paton VLDB Tutorial Berlin; 2003 Page 2. VLDB 2003 Berlin Part I: DataGrid Management Systems Arun Jagatheesan Reagan Moore {arun; moore}@sdsc.edu SanDiego Supercomputer Center University of California; San Diego VLDB Tutorial Berlin; 2003http://www.npaci.edu/DICE/SRB/ Page 3. VLDB 2003 Berlin 3 Tutorial Part I Outline • Concepts •Introduction to Grid Computing • Proliferation of Data Grids • Data Grid Concepts • Practice •Real life use cases SDSC Storage Resource Broker (SRB) • Hands on Session • Research •Active Datagrid Collections • Data Grid Management Systems (DGMS) • Open Research IssuesPage 4. VLDB 2003 Berlin 4 Distributed Computing …,VLDB,2003,7
An experimental performance evaluation of incremental materialized view maintenance in object databases,M Akhtar Ali; Norman W Paton; Alvaro AA Fernandes,Abstract The development of techniques for supporting incremental maintenance ofmaterialized views has been an active research area for over twenty years. However;although there has been much research on methods and algorithms; there are surprisinglyfew systematic studies on the performance of different approaches. As a result;understanding of the circumstances in which materialized views are beneficial (or not) canbe seen to lag behind research on incremental maintenance techniques. This paperpresents the results of an experimental performance analysis carried out in a system thatincrementally maintains OQL views in an ODMG compliant object database. The resultsindicate how the effectiveness of incremental maintenance is affected by issues such asdatabase size; and the complexity and selectivity of views.,International Conference on Data Warehousing and Knowledge Discovery,2001,7
Formalizing and validating behavioral models through the event calculus,Oscar Diaz; Norman W Paton; Jon Iturrioz,Abstract Accurate gathering of requirements is a major concern during conceptualmodelling. Such accurateness can only be achieved through major involvement of users;who should check whether the system's specification conforms with their expectations. Thistask can be facilitated both by intuitive conceptual constructs and by executable models thatallow interaction with the user to explain the behavior of the system in accordance with itsspecification. This work proposes the notions of stimuli and business policies as intuitivebehavioral constructs; and the use of the event calculus as an appropriate formalism forbuilding executable specifications for behavioral models. The approach is borne out by anearly implementation that allows the user to question why and how a given state is reached;where the answer is given in terms of the specifications; ie stimuli and policies; being …,Information Systems,1998,7
Programming spatial databases: A deductive object-oriented approach,Norman W Paton; ALIA Abdelmoty; M Howard Williams,Geographical Information Systems present significant challenges to database technology.The data which has to be store is structurally complex; and can only be describedsatisfactorily by expressive data models with explicit support for spatial data types. Theanalyses which are applied to geographic data are generally complex; requiring extensiveaccess to derived relationships between spatially distributed concepts. Commercialrelational databases have been found to be inadequate for supporting geographicapplications because of their spartan data modelling facilities and the limited computationalpower of their query languages. This has lead to the use of coupled systems; where thespatial data manager and the database are distinct components; with consequentdisadvantages for programmer productivity and run-time performance. However; while it …,Innovations in GIS,1996,7
Object-oriented databases and frame-based systems: comparison,NW Paton; O Diaz,Abstract Research into knowledge representation within the artificial intelligence (AI)community has led to the development of AI tools that use frames to structure knowledge.Concurrent research in databases has led to the development of semantic data models andobject-oriented databases. These two types of system seem to have much in common—theyare structurally object-oriented; support inheritance; and store programs with the objects towhich they relate. What then are the differences between frame systems and object-orienteddatabases? The paper compares a frame system called CRL with an object-orienteddatabase called ADAM to identify common ground and differences between the systems andthe philosophies underlying them. What emerges from the comparison is that while thesystems have many superficial similarities; the different rationales that led to their …,Information and Software Technology,1991,7
Distributed Query Processing in an OGSA environment,MN Alpdemir; Norman W Paton; Alvaro AA Fernandes,*,Department of Computer Science; University of Manchester; Oxford Road Manchester M13 9PL; UK,2002,6
Techniques for the effective evaluation of database interfaces,Norman W Paton; Ghassan al-Qaimari; Khoa Doan; Alistair C Kilgour,Abstract Many proposals have been made for database interfaces which support a widerange of tasks in a variety of different ways using a wide selection of visual or textuallanguages. In this context of widespread experimentation; it is important that the proposalsbe effectively evaluated. If they are not; then flawed approaches could become widelyaccepted; good ideas could be let down by inappropriate implementations; or noveltechniques overlooked in the absence of suitable supporting evidence. This papersummarises our experience using several different evaluation techniques in the context of amulti-paradigm query interface and a browser which supports visualisations of advanceddata modelling constructs. It is shown how different evaluation techniques are suitable forevaluating different aspects of database interface functionality; and that different …,*,1995,6
Semantics based implementation of a deductive object-oriented database programming language,ML Barja; NW Paton; MH Williams,*,JOURNAL OF PROGRAMMING LANGUAGES,1994,6
Enabling community-driven information integration through clustering,Khalid Belhajjame; Norman W Paton; Cornelia Hedeler; Alvaro AA Fernandes,Abstract It has become widely recognized that user feedback can play a fundamental role infacilitating information integration tasks; eg; the construction of integration schema and thespecification of schema mappings. While promising; existing proposals make theassumption that the users providing feedback expect the same results from the integrationsystem. In practice; however; different users may anticipate different results; due; eg; to theirpreferences or application of interest; in which case the feedback they provide may beconflicting; thereby deteriorating the quality of the services provided by the integrationsystem. In this paper; we present clustering strategies for grouping information integrationusers into groups of users with similar expectations as to the results delivered by theintegration system. As well as grouping information integration users; we show that …,Distributed and Parallel Databases,2015,5
QoS-aware optimization of sensor network queries,Ixent Galpin; Alvaro AA Fernandes; Norman W Paton,Abstract The resource-constrained nature of mote-level wireless sensor networks (WSNs)poses challenges for the design of a general-purpose sensor network query processors(SNQPs). Existing SNQPs tend to generate query execution plans (QEPs) that are selectedon the basis of a fixed; implicit expectation; for example; that energy consumption should bekept as small as possible. However; in WSN applications; the same query may be subject toseveral; possibly conflicting; quality-of-service (QoS) expectations concomitantly (forexample maximizing data acquisition rates subject to keeping energy consumption low). It isalso not uncommon for the QoS expectations to change over the lifetime of a deployment (forexample from low to high data acquisition rates). This paper describes optimizationalgorithms that respond to stated QoS expectations (about acquisition rate; delivery time …,The VLDB Journal,2013,5
A comparative evaluation of XML difference algorithms with genomic data,Cornelia Hedeler; Norman W Paton,Abstract Genome sequence data and annotations are subject to frequent changes resultingfrom re-assembly and re-annotation; or community feedback based on experimentalevidence; giving rise to new data releases. These releases are rarely accompanied by adescription of the changes; making it difficult for biologists working with the data to identifyand work through the consequences of the changes that have taken place. This paperexplores the extent to which existing XML difference algorithms; namely X-Diff; JXyDiff and3DM; can be used to identify and document genome changes; in particular investigating:(i)their ability to detect typical changes in genome sequence documents; and (ii) the ease withwhich the difference report can be used to determine whether genes of interest are affectedby changes to the genome. The evaluation compares the performance of the algorithms …,International Conference on Scientific and Statistical Database Management,2008,5
Experimenting with object navigation in parallel object databases,Sde FM Sampaio; Jim Smith; Norman W Paton; Paul Watson,This paper addresses the problem of selecting the best object navigation strategy for a queryto be run in parallel; when considering multiple alternative strategies. This is done byperforming experiments with three pointer-based join algorithms; running simple andcomplex queries in a parallel ODMG-compliant object database system. We believe ourresults provide insights into how physical properties of queries impact on the performance ofdifferent joins operators in a parallel environment.,Database and Expert Systems Applications; 2001. Proceedings. 12th International Workshop on,2001,5
Stimuli and Business Policies as Modelling Constructs: their definition and validation through the event calculus,Oscar Díaz; Norman W Paton,Abstract Accurate gathering of requirements is a major concern during conceptualmodelling. Such accurateness can only be achieved through major involvement of users;who should check whether the system's specification conforms with their expectations. Thistask can be facilitated both by intuitive conceptual constructs and by executable models thatallow interaction with the user to explain the behaviour of the system in accordance with itsspecification. This work proposes the notions of stimuli and business policies as intuitivebehavioural constructs; and the use of the event calculus as an appropriate formalism forbuilding executable specifications for behavioural models. The approach is borne out by anearly implementation that allows the user to question why and how a given state is reached;where the answer is given in terms of the specifications; ie stimuli and policies; being …,International Conference on Advanced Information Systems Engineering,1997,5
Crowdsourcing feedback for pay-as-you-go data integration,Norman W Paton; AA Fernandes,ABSTRACT Providing an integrated representation of data from heterogeneous datasources involves the specification of mappings that transform the data into a consistentlogical schema. With a view to supporting large-scale data integration; the specification ofsuch mappings can be carried out automatically using algorithms and heuristics. However;automatically generated mappings typically provide partial and/or incorrect results. Userscan help to improve such mappings; expert users can act on the mappings directly usingdata integration tools; and end users or crowds can provide feedback in a pay-as-you-gofashion on results from the mappings. Such feedback can be used to inform the selectionand refinement of mappings; thus improving the quality of the integration and reducing theneed for expensive and potentially scarce expert staff. In this paper; we investigate the …,DBCrowd 2013,2013,4
A functional model for dataspace management systems,Cornelia Hedeler; Alvaro AA Fernandes; Khalid Belhajjame; Lu Mao; Chenjuan Guo; Norman W Paton; Suzanne M Embury,Abstract Dataspace management systems (DSMSs) hold the promise of pay-as-you-go dataintegration. We describe a comprehensive model of DSMS functionality using an algebraicstyle. We begin by characterizing a dataspace life cycle and highlighting opportunities forboth automation and user-driven improvement techniques. Building on the observation thatmany of the techniques developed in model management are of use in data integrationcontexts as well; we briefly introduce the model management area and explain howprevious work on both data integration and model management needs extending if the fulldataspace life cycle is to be supported. We show that many model management operatorsalready enable important functionalities (eg; the merging of schemas; the composition ofmappings; etc.) and formulate these capabilities in an algebraic structure; thereby giving …,*,2013,4
Information management for high content live cell imaging,Daniel Jameson; David A Turner; John Ankers; Stephnie Kennedy; Sheila Ryan; Neil Swainston; Tony Griffiths; David G Spiller; Stephen G Oliver; Michael RH White; Douglas B Kell; Norman W Paton,High content live cell imaging experiments are able to track the cellular localisation oflabelled proteins in multiple live cells over a time course. Experiments using high contentlive cell imaging will generate multiple large datasets that are often stored in an ad-hocmanner. This hinders identification of previously gathered data that may be relevant tocurrent analyses. Whilst solutions exist for managing image data; they are primarilyconcerned with storage and retrieval of the images themselves and not the data derivedfrom the images. There is therefore a requirement for an information management solutionthat facilitates the indexing of experimental metadata and results of high content live cellimaging experiments. We have designed and implemented a data model and informationmanagement solution for the data gathered through high content live cell imaging …,BMC bioinformatics,2009,4
Task modelling for database interface development,Tony Griffiths; Norman W Paton; Carole A Goble; Adrian West,*,Proceedings of HCI International (the 8th International Conference on Human-Computer Interaction) on Human-Computer Interaction: Ergonomics and User Interfaces-Volume I-Volume I,1999,4
TAMBIS Online: a bioinformatics source integration tool,Robert Stevens; Norman W Paton; Pat Baker; Gary Ng; Carole A Goble; Sean Bechhofer; Andy Brass,Conducting bioinformatic analyses involves biologists in expressing requests over a rangeof heterogeneous information sources. The TAMBIS (Transparent Access to MultipleBioinformatics Information Sources) project seeks to make the diversity in data structures;call interfaces and locations of bioinformatics sources transparent to users. TAMBIS isavailable at< http://img. cs. man. ac. uk/tambis>.,Scientific and Statistical Database Management; 1999. Eleventh International Conference on,1999,4
From OO through deduction to active databases—ROCK; ROLL & RAP,M Howard Williams; Norman W Paton,Abstract One important thread within advanced database systems research is the notion ofrule-based database systems. The power of definite rules coupled with relational technologyhas led to the emergence of deductive databases. However; while this type of databasesystem provides more advanced functionality; it suffers from other limitations of relationaldatabase systems such as the lack of data structures. The realisation that the objecto-rientedapproach is complementary to the deductive one and that the two can be combined toproduce deductive object-oriented databases with all the benefits of both represents animportant breakthrough for rule-based database systems. An alternative to the deductiverule approach is the active rule approach. Active rules are more powerful than deductiverules but lack the advantages of the sound theoretical foundation of the latter. The two …,International Conference on Current Trends in Theory and Practice of Computer Science,1997,4
Visualising data modelling constructs in an object-oriented database,Ghassan al-Qaimari; Alistair C Kilgour; Norman W Paton,Abstract Object-oriented databases are seen as potential successors to relationaldatabases; at least in part because they provide a richer set of data modelling constructs.This paper addresses the challenge to interface designers posed by such constructs tosupport data browsing and modelling through powerful and perspicuous visualisations; withthe additional requirement that the visualisations should be readily updatable when thesemantic model is modi ed; as is possible in some extensible object-oriented databases.The paper describes a range of visualisations for the semantic modelling constructs of theextensible object-oriented database ADAM; and reports the results of a series of empiricalevaluations to assess the e ectiveness of these visualisations. These results support thebelief that it is possible to make the advanced data modelling constructs of an extensible …,Proceedings of the 7th International Conference on Information Systems Engineering (CAiSE’95)–Workshop on End User Development,1995,4
The VADA architecture for cost-effective data wrangling,Nikolaos Konstantinou; Martin Koehler; Edward Abel; Cristina Civili; Bernd Neumayr; Emanuel Sallinger; Alvaro AA Fernandes; Georg Gottlob; John A Keane; Leonid Libkin; Norman W Paton,Abstract Data wrangling; the multi-faceted process by which the data required by anapplication is identified; extracted; cleaned and integrated; is often cumbersome and laborintensive. In this paper; we present an architecture that supports a complete data wranglinglifecycle; orchestrates components dynamically; builds on automation wherever possible; isinformed by whatever data is available; refines automatically produced results in the light offeedback; takes into account the user's priorities; and supports data scientists with diverseskill sets. The architecture is demonstrated in practice for wrangling property sales and opengovernment data.,Proceedings of the 2017 ACM International Conference on Management of Data,2017,3
Structuring linked data search results using probabilistic soft logic,Duhai Alshukaili; Alvaro AA Fernandes; Norman W Paton,Abstract On-the-fly generation of integrated representations of Linked Data (LD) searchresults is challenging because it requires successfully automating a number of complexsubtasks; such as structure inference and matching of both instances and concepts; each ofwhich gives rise to uncertain outcomes. Such uncertainty is unavoidable given thesemantically heterogeneous nature of web sources; including LD ones. This paperapproaches the problem of structuring LD search results as an evidence-based one. Inparticular; the paper shows how one formalism (viz.; probabilistic soft logic (PSL)) can beexploited to assimilate different sources of evidence in a principled way and to beneficialeffect for users. The paper considers syntactic evidence derived from matching algorithms;semantic evidence derived from LD vocabularies; and user evidence; in the form of …,International Semantic Web Conference,2016,3
Efficient feedback collection for pay-as-you-go source selection,Julio César Cortés Ríos; Norman W Paton; Alvaro AA Fernandes; Khalid Belhajjame,Abstract Technical developments; such as the web of data and web data extraction;combined with policy developments such as those relating to open government or openscience; are leading to the availability of increasing numbers of data sources. Indeed; giventhese physical sources; it is then also possible to create further virtual sources that integrate;aggregate or summarise the data from the original sources. As a result; there is a plethora ofdata sources; from which a small subset may be able to provide the information required tosupport a task. The number and rate of change in the available sources is likely to makemanual source selection and curation by experts impractical for many applications; leadingto the need to pursue a pay-as-you-go approach; in which crowds or data consumersannotate results based on their correctness or suitability; with the resulting annotations …,Proceedings of the 28th International Conference on Scientific and Statistical Database Management,2016,3
Pay-as-you-go data integration: Experiences and recurring themes,Norman W Paton; Khalid Belhajjame; Suzanne M Embury; Alvaro AA Fernandes; Ruhaila Maskat,Abstract Data integration typically seeks to provide the illusion that data from multipledistributed sources comes from a single; well managed source. Providing this illusion inpractice tends to involve the design of a global schema that captures the users datarequirements; followed by manual (with tool support) construction of mappings betweensources and the global schema. This overall approach can provide high quality integrationsbut at high cost; and tends to be unsuitable for areas with large numbers of rapidly changingsources; where users may be willing to cope with a less than perfect integration. Pay-as-you-go data integration has been proposed to overcome the need for costly manual dataintegration. Pay-as-you-go data integration tends to involve two steps. Initialisation:automatic creation of mappings (generally of poor quality) between sources. Improvement …,International Conference on Current Trends in Theory and Practice of Informatics,2016,3
Sensorbench: benchmarking approaches to processing wireless sensor network data,Ixent Galpin; Alan B Stokes; George Valkanas; Alasdair JG Gray; Norman W Paton; Alvaro AA Fernandes; Kai-Uwe Sattler; Dimitrios Gunopulos,Abstract Wireless sensor networks enable cost-effective data collection for tasks such asprecision agriculture and environment monitoring. However; the resource-constrainednature of sensor nodes; which often have both limited computational capabilities and batterylifetimes; means that applications that use them must make judicious use of these resources.Research that seeks to support data intensive sensor applications has explored a range ofapproaches and developed many different techniques; including bespoke algorithms forspecific analyses and generic sensor network query processors. However; all suchproposals sit within a multi-dimensional design space; where it can be difficult to understandthe implications of specific decisions and to identify optimal solutions. This paper presents abenchmark that seeks to support the systematic analysis and comparison of different …,Proceedings of the 26th International Conference on Scientific and Statistical Database Management,2014,3
Adapting to node failure in sensor network query processing,Alan B Stokes; Alvaro AA Fernandes; Norman W Paton,Abstract The typical nodes used in mote-level wireless sensor networks (WSNs) are oftenbrittle and severely resource-constrained. In particular; nodes are often battery-powered;thereby making energy depletion a significant risk. When changes to the connectivity graphoccur as a result of node failure; the overall computation may collapse unless it is capable ofadapting to the new WSN state. Sensor network query processors (SNQPs) construe a WSNas a distributed; continuous query platform where the streams of sensed values constitutethe logical extents of interest. Crucially; in the context of this paper; they must makeassumptions about the connectivity graph of the WSN at compile time that are likely not tohold for the lifetime of the compiled query evaluation plans (QEPs) the SNQPs generate.This paper address the problem of ensuring that a QEP continues to execute even if some …,British National Conference on Databases,2013,3
Resilient sensor network query processing using logical overlays,Alan B Stokes; Alvaro AA Fernandes; Norman W Paton,Abstract The typical nodes used in mote-level wireless sensor networks (WSNs) are oftenbrittle and severely resource-constrained. In particular; nodes are often battery-powered;thereby making energy depletion a significant risk. When changes to the connectivity graphoccur as a result of node failure; the overall computation may collapse unless it is capable ofadapting to the new WSN state. Sensor network query processors (SNQPs) construe a WSNas a distributed; continuous query platform where the streams of sensed values constitutethe logical extents of interest. Crucially; in the context of this paper; they must makeassumptions about the connectivity graph of the WSN at compile time that are likely not tohold for the lifetime of the compiled query evaluation plan (QEP) the SNQPs generate. Thispaper addresses the problem of extending the lifetime of an evaluating QEP in the event …,Proceedings of the Eleventh ACM International Workshop on Data Engineering for Wireless and Mobile Access,2012,3
Utilising the mism model independent schema management platform for query evaluation,Cornelia Hedeler; Norman W Paton,Abstract Model Management; and its associated operators; provides generic means fordealing with multiple schemas and the mappings between them; for example; in the contextof multiple heterogeneous data sources that need to be integrated. One example of a ModelManagement framework is the 'Model Independent Schema Management'(MISM) platform.In the context of MISM; algorithms and implementations of various operators have beenproposed that act on a source-model independent metamodel. However; although theresults on MISM indicate how to import and manipulate data from heterogeneous sourcetypes; to date no approach has been proposed to utilise MISM for querying across themultiple data sources. This paper presents SMql; a query language over the source-modelindependent supermodel; presents an algebra into which the query is translated and …,British National Conference on Databases,2011,3
Deploying in-network data analysis techniques in sensor networks,George Valkanas; Alexis Kotsifakos; Dimitrios Gunopulos; Ixent Galpin; Alasdair JG Gray; Alvaro AA Fernandes; Norman W Paton,Sensor Networks have received considerable attention recently; as they provide manifoldbenefits. Not only are they a means for data acquisition and monitoring of unexplored orinaccessible areas; they are also a low-cost alternative for sensing the environment; whichgreatly aids to better understand our surroundings. A major motivation in either occasion isto acknowledge endangering situations and take action (s) accordingly. To this end; wewould like to enable data mining or analysis techniques on top or; even better; within suchnetworks; due to the prohibitive cost of communication in this setting. In this work; wedemonstrate running data mining algorithms on a set of sensors; which are of low-processing power. In addition to showcasing the execution of data analysis algorithms onresource-constrained hardware; our demo is intended to show how to take advantage of …,Mobile Data Management (MDM); 2011 12th IEEE International Conference on,2011,3
Search computing: Integrating ranked data in the life sciences,Marco Masseroli; Norman W Paton; Giorgio Ghisalberti,Abstract Search computing has been proposed to support the integration of the results ofsearch engines with other data and computational resources. In essence; in searchcomputing; search services provide ranked answers to requests; and mechanisms areprovided for integrating results from multiple searches. This paper presents a case study ofthe use of a domain independent search computing platform for describing well knownbioinformatics resources as search services; and for carrying out integrated analyses overthe resulting services. In particular; this makes explicit how ranked data from sequencecomparisons and from gene expression results can be integrated in a way that takesaccount of the ranked results from the different types of data. In so doing; the paperillustrates the use of ranking as a first class citizen for data integration in the life sciences …,International Conference on Data Integration in the Life Sciences,2010,3
A methodology for comparative functional genomics,Intikhab Alam; Mike Cornell; Darren M Soanes; Cornelia Hedeler; Han Min Wong; Magnus Rattray; Simon J Hubbard; Nicholas J Talbot; Stephen G Oliver; Norman W Paton,Abstract The continuing and rapid increase in the number of fully sequenced genomes iscreating new opportunities for comparative studies. However; although many genomicdatabases store data from multiple organisms; for the most part they provide limited supportfor comparative genomics. We argue that refocusing genomic data management to providemore direct support for comparative studies enables systematic identification of importantrelationships between species; thereby increasing the value that can be obtained fromsequenced genomes. The principal result of the paper is a methodology; in whichcomparative analyses are constructed over a foundation based on sequence clusters andevolutionary relationships. This methodology has been applied in a systematic study of thefungi; and we describe how comparative analyses have been implemented as an …,Journal of Integrative Bioinformatics,2007,3
GML for Representing Data from Spatio‐Historical Databases: A Case Study,Fang Siyuan; Tony Griffiths; Norman W Paton,Abstract Many applications; in areas such as land use; traffic management and locationaware services; involve the storage; analysis and sharing of spatio-temporal data. The needto represent such data in a way that eases sharing across applications; has led to thedevelopment of the Geography Markup Language (GML); which provides a rich collection ofconstructs for representing spatial and associated aspatial data as XML documents.However; although there are a growing number of applications and tools that make use ofGML; there are surprisingly few experience reports on the representation of data fromexisting applications or models using GML constructs. This paper provides one such report;describing the use of GML as an exchange format for the Tripod spatio-historical database.This in turn involves identifying mappings between Tripod and GML constructs; and the …,Transactions in GIS,2007,3
Spatio-temporal databases in practice: directly supporting previously developed land data using tripod,Tony Griffiths; Alvaro AA Fernandes; Norman W Paton; S-H Jeong; Nassima Djafri; Keith T Mason,This article presents a complete spatio-temporal object DBMS called Tripod; in the context ofan application to support the management of previously developed land (PDL). In particularthe article focuses on: the techniques that are available to realise the application datamodel; the facilities necessary to realise the operational semantics of updates; and thefacilities that are available to identify interesting patterns of spatio-temporal change. Whilstthere exist other proposals for data models and query languages for spatio-temporal objectdatabases; Tripod is unique in that it provides: a complete implementation of an expressivespatio-temporal data model to allow modelling of (a) spatial time-varying data; the firstexample of an implementation of language bindings to support manipulation of stored data;and the first complete implementation of a spatio-temporal OQL that we know of. The …,Data Engineering; 2005. ICDE 2005. Proceedings. 21st International Conference on,2005,3
Speeding up navigational requests in a parallel object database system,Jim Smith; Paul Watson; Sandra de F Mendes Sampaio; Norman W Paton,Abstract In data intensive applications; both programming and declarative query languageshave attractions; the former in comprehensiveness and the latter for ease of use. Databasessometimes support the calling of side-effect free user defined functions from withindeclarative queries. As well as enabling more efficient coding of computationally intensivefunctions; this provision not only moves computation to data in a client-server setting; butalso enables speedup through data parallel execution if the server is parallel. There hasbeen little work on the combined use of query and program based database access in thecontext of parallel servers. We believe Polar is the first parallel object-oriented databasewhich supports this arbitrary navigation both in a client application and in functions(operations) which may be called from within declarative queries. This work introduces …,European Conference on Parallel Processing,2002,3
Conceptual modelling for database user interfaces,Richard Cooper; Jo McKirdy; Tony Griffiths; Peter J Barclay; Norman W Paton; Philip D Gray; Jessie Kennedy; Carole A Goble,Abstract Model-based user interface development environments show promise for improvingthe speed of production and quality of user interfaces. Such systems usually have separatedescription of domain; task and presentation structure. The Teallach system applies modelbased techniques to the important area of database interfaces; which increases theimportance of domain information. This exists in the form of a schema and can be capturedin a high-level format; so that the developer need not build a domain description arbitrarily.This paper describes such a Domain Model; how it is captured and how it contributes to thesystematic development of a user interface.,*,2000,3
Extending the ODMG architecture with a deductive object query language,Norman W Paton; Pedro R Falcone Sampaio,Abstract Deductive database languages have often evolved with little regard for ongoingdevelopments in other parts of the database community. This tendency has also beenprevalent in deductive object-oriented database (DOOD) research; where it is often difficultto relate proposals to the emerging standards for object-oriented or object-relationaldatabases. This paper seeks to buck the trend by indicating how deductive languages canbe integrated into the ODMG standard; and makes a proposal for a deductive component inthe ODMG context. The deductive component; which is called DOQL; is designed to conformto the main principles of ODMG compliant languages; providing a powerful complementarymechanism for querying; view definition and application development in ODMG databases.,British National Conference on Databases,1998,3
The formalisation of ROCK & ROLL: A deductive object-oriented database system,Alvaro AA Fernandes; Maria L Barja; Norman W Paton; M Howard Williams,Abstract This paper describes the formalisation of the deductive object-oriented databasesystem ROCK & ROLL. This is a system which integrates the deductive and object-orientedparadigms in a way that is both clean and consistent; and that has a sound theoreticalfoundation. The system uses a formally defined object-oriented data model as a foundationfor both a logic query language and an imperative data manipulation language in such away that impedance mismatches are minimised. This paper introduces the facilities offeredby ROCK & ROLL; and indicates how their formalisation has been achieved.,Information and Software Technology,1997,3
Exploitation of Object-Oriented and Active Constructsin Database Interface Development,Norman W Paton,Abstract: This paper presents some experiences in the exploitation of a databaseinterfacedevelopment architecture in which the interface is implementedusing the facilities of thedatabase. It is shown how novel interfaces; specifically a multi-paradigm query interface anda debugger for an activerule system; can benefit from and exploit the uniform representationofinterface and database system concepts as database objects.,*,1996,3
Proactive adaptations in sensor network query processing,Alan B Stokes; Norman W Paton; Alvaro AA Fernandes,Abstract Wireless sensor networks (WSN) are used by many applications for event andenvironmental monitoring. Due to the resource-limited nodes in WSNs; there has been muchresearch into extending the functional lifetime of the network through energy-savingtechniques. Sensor Network Query Processing (SNQP) is one such technique. SNQP usesinformation about a query and the WSN over which it is to be run; to generate an energy-efficient Query Execution Plan (QEP) that distributes processing in the form of QEPfragments to the nodes in the WSN. However; any QEP is likely to drain the batteries of thenodes unevenly; and; as a result; nodes used in a QEP may run out of energy when thereare significant energy stocks still available in the WSN. An adaptive query processor couldreact to energy depletion; for example; by generating a revised plan that refrains from …,Proceedings of the 26th International Conference on Scientific and Statistical Database Management,2014,2
Workflows for information integration in the life sciences,Paolo Missier; Norman Paton; Peter Li,Abstract The increasingly computationally-and data-intensive nature of experimentalscience motivates recent interest in workflows; as a way to specify complex data processingand integration pipelines in a fairly intuitive way. Such workflows orchestrate the invocationof data retrieval services in a way that resembles; to some extent; Search Computing queryplans. While the former are manually specified; however; the latter are the result of anautomated translation process. Using lessons learnt from experience in workflow design; inthis chapter we discuss some of the requirements on service curation that make automated;on-demand data integration processes possible and realistic.,*,2011,2
Querying sensor networks: requirements; semantics; algorithms and cost models,Christian YA Brenninkmeijer,Sensor Networks ; Semantics ; Algorithms ; Cost Models ; Streams ; Queries.,*,2010,2
Data requirements; data management and analysis issues; and query-based functionalities,Ixent Galpin; Alasdair JG Gray; Alvaro AA Fernandes; Norman W Paton; Alexis Kotsifakos; Dimitris Kotsakos; Dimitrios Gunopulos,Executive Summary A recent development; catalysed by advances in radio; processor andbattery technology; is the emergence of sensor networks [KW05] as an economically viablehardware platform with which to observe or monitor phenomena in situ; possibly over a widearea of interest and at a finer grain of observation than was previously possible. However; itis currently not straightforward for a remote user to discover relevant sensor networks; andintegrate them into applications on-the-fly (even if the sensor network is accessible via theInternet) due to the heterogeneity of their interfaces to the outside world; and the inability toresolve semantic inconsistencies between the data attributes collected by sensor networks.The potential exists; but currently cannot be exploited; for sensor networks to be added to ad-hoc; lightweight applications or mashups; possibly generated on-the-fly; that can …,Deliverable D2,2009,2
Systems Biology Results Markup Language (SBRML) level 1: structure and facilities for results representation,Joseph O Dada; Norman W Paton; Pedro Mendes,The introduction of SBML as an exchange format for models of biochemical systems hasbeen a major factor in advancing computational systems biology. The community ofscientists and software developers involved with SBML (hereafter called the “SBMLcommunity”) has also made several other technical advances as a consequence; forexample by creating software libraries that make it easier to develop programs compatiblewith SBML; and by creating collections of models that act as gold standards for testing andtherefore also for validating and comparing software. There have also been several otherstandardization activities; for example in defining what information should be communicatedwhen models are constructed. However; one aspect that has until now not been addressedin terms of standardization is the specification of the results of computational analyses of …,See http://www. comp-sys-bio. org/static/SBRML-specs-15-04-2009. pdf,2009,2
Data integration in the life sciences: Fun; findings and frustrations,Norman W Paton,Abstract This paper concerns the research topic of data integration in the life sciences. Thepaper presents no technical results; but rather provides a classification of research activitiesin terms of the contributions they seek to make to the life sciences; bioinformatics orcomputer science.,International Workshop on Data Integration in the Life Sciences,2008,2
Probabilistic adaptive load balancing for parallel queries,Daniel M Yellin; Jorge Buenabad-Chavez; Norman W Paton,In the context of adaptive query processing (AQP); several techniques have been proposedfor dynamically adapting/redistributing processor load assignments throughout acomputation to take account of varying resource capabilities. The effectiveness of thesetechniques depends heavily on when and to what they adapt processor load assignments;particularly in the presence of varying load imbalance. This paper presents a probabilisticapproach to decide when and to what to adapt processor load assignments. Using asimulation based evaluation; it is compared to two other approaches already reported.These two approaches are simpler in their decision making than the probabilistic approach;but the latter performs better under several scenarios of load imbalance.,Data Engineering Workshop; 2008. ICDEW 2008. IEEE 24th International Conference on,2008,2
User interface modeling in UML i [],Paulo Pinheiro da Silva; Norman W Paton,*,IEEE Software,2003,2
Database Access and Integration,Malcolm Atkinson; Peter Kunszt; Inderpal Narang; Norman W Paton; Dave Pearson; Paul Watson,Digital data are now fundamental to all branches of science and engineering; they play amajor role in medical research and diagnosis; and underpin business and governmentaldecision processes. Increasingly these data are organised as shared and structuredcollections; which are held in databases; in structured documents and in structuredassemblies of binary files. The advent of ubiquitous Internet computing and the scale ofmodern challenges; such as deciphering the function of all the genes in a large number ofspecies; from bacteria to crops; farm animals and humans; has led to widespreadcollaboration in the creation; curation; publication; management and exploitation of thesestructured collections. Although individual collections are typically specialised to hold data ofinterest to particular communities; substantial advances can be achieved by combining …,Draft chapter commissioned for the second edition of The Grid; Foster & Kesselman,2003,2
Querying Objects with Description Logics.,Martin Peim; Enrico Franconi; Norman W Paton; Carole A Goble,Abstract This paper presents an approach to answering queries over an ontology modelledusing a description logic. The ontology acts as a global schema; providing a declarativedescription of the concepts of the domain; the instances of which are stored in (potentiallymany) object-wrapped sources. Queries are expressed using terms from the rich vocabularyof the ontology; and are translated into an equivalent calculus expression; which referencesonly the objects available in the source databases. The query is then optimised on the basisof information from the ontology and the source databases.,Description Logics,2002,2
RAP: The ROCK & ROLL Active Programming System,Andrew Dinn; Norman W Paton; M Howard Williams,Abstract This chapter describes RAP (ROCK & ROLL Active Programming system); an activerule system embedded within the ROCK & ROLL deductive object-oriented databasesystem. A brief description of ROCK & ROLL is followed by an overview of RAP and acategorization of its Knowledge and Execution Models according to the dimensionsintroduced in Chapter 1.,*,1999,2
TAMBIS: Transparent Access to Bioinformatics Information Sources,Andy Brass; Carole Goble; Norman Paton,1. Background The biological community is a distributed one; with a culture of sharing andrapid dissemination of information. Each separate area of molecular biology generates itsown data and therefore its own information sources; including those for protein sequences;genome projects; DNA sequences; protein structures and motifs. Also available are a rangeof specialist interrogation and analysis tools; each typically associated with a particulardatabase format. Frequently the information sources have different structures; content andquery languages; and the tools have no common user interface and often only work on alimited subset of the data.,Final Report: BIF/05344,*,2
Crowdsourcing for data management,Valter Crescenzi; Alvaro AA Fernandes; Paolo Merialdo; Norman W Paton,Abstract Crowdsourcing provides access to a pool of human workers who can contributesolutions to tasks that are challenging for computers. Proposals have been made for the useof crowdsourcing in a wide range of data management tasks; including data gathering;query processing; data integration; and cleaning. We provide a classification of key featuresof these proposals and survey results to date; identifying recurring themes and open issues.,*,2017,1
Towards Automatic Data Format Transformations: Data Wrangling at Scale,Alex Bogatu; Norman W Paton; Alvaro AA Fernandes,Abstract Data wrangling is the process whereby data is cleaned and integrated for analysis.Data wrangling; even with tool support; is typically a labour intensive process. One aspect ofdata wrangling involves carrying out format transformations on attribute values; for exampleso that names or phone numbers are represented consistently. Recent research hasdeveloped techniques for synthesising format transformation programs from examples of thesource and target representations. This is valuable; but still requires a user to providesuitable examples; something that may be challenging in applications in which there arehuge data sets or numerous data sources. In this paper we investigate the automaticdiscovery of examples that can be used to synthesise format transformation programs. Inparticular; we propose an approach to identifying candidate data examples and validating …,British International Conference on Databases,2017,1
Observing the Data Scientist: Using Manual Corrections As Implicit Feedback,Nurzety A Azuan; Suzanne M Embury; Norman W Paton,Abstract Dataspaces aim to remove the up-front costs of information integration by gatheringthe needed domain information through targeted interactions with the end-user throughoutthe life-time of the integration. State-of-the-art tools are used to rapidly construct an initial(incorrect) integration; which is then refined in a pay-as-you-go manner by asking end-usersto supply feedback on the resulting data. The idea is that end-users will choose to put effortinto providing feedback on the areas of the integration where the quality is important to them;while other less well-used areas will receive a smaller share of user attention. This approachis promising but open problems remain. One issue is that the end-user loses control over theprocess. Their contribution is to specify their query requirements and to provide feedback onthe results; as directed by the dataspace. But what feedback should the user supply to get …,Proceedings of the 2nd Workshop on Human-In-the-Loop Data Analytics,2017,1
Combining syntactic and semantic evidence for improving matching over linked data sources,Klitos Christodoulou; Alvaro AA Fernandes; Norman W Paton,Abstract In the context of Linked Data (LD) sources; the ability to traverse links and retrievefurther information can be exploited to harvest semantic annotations. Such annotations can;in turn; underpin the inference of semantic correspondences between sources. This papershows that using semantic annotations as additional evidence of equivalence betweenschematic representations of LD sources can improve upon the prevalent; purely syntacticapproaches. The paper both describes the construction of probabilistic models that yielddegrees of belief on the equivalence of the real-world concepts represented by the data andshows how these models are crucial in underpinning a Bayesian approach to assimilatingboth syntactic evidence (in the form of similarity scores derived by string-based matchers)and semantic evidence (in the form of semantic annotations stemming from LD …,International Conference on Web Information Systems Engineering,2015,1
MatchBench: benchmarking schema matching algorithms for schematic correspondences,Chenjuan Guo; Cornelia Hedeler; Norman W Paton; Alvaro AA Fernandes,Abstract Schema matching algorithms aim to identify relationships between databaseschemas; which are useful in many data integration tasks. However; the results of mostmatching algorithms are expressed as semantically inexpressive; 1-to-1 associationsbetween pairs of attributes or entities; rather than semantically-rich characterisations ofrelationships. This paper presents a benchmark for evaluating schema matching algorithmsin terms of their semantic expressiveness. The definition of such semantics is based on theclassification of schematic heterogeneities of Kim et al.. The benchmark explores the extentto which matching algorithms are effective at diagnosing schematic heterogeneities. Thepaper contributes:(i) a wide range of scenarios that are designed to systematically coverseveral reconcilable types of schematic heterogeneities;(ii) a collection of experiments …,British National Conference on Databases,2013,1
Evomatch: An evolutionary algorithm for inferring schematic correspondences,Chenjuan Guo; Cornelia Hedeler; Norman W Paton; Alvaro AA Fernandes,Abstract Schema matching provides an important foundation for both manual and semi-automatic derivation of mappings between sources. However; schema matchers typicallyreturn large numbers of potentially inconsistent matches that are neither conducive toautomatic mapping generation nor readily digested by mapping developers. This paperpresents a method; EvoMatch; for automatically inferring schematic correspondences; fromwhich mappings can be generated directly. It aims to offer a more expressivecharacterization of the relationships between sources than matches identified by existingschema matching methods. In particular; the paper contributes: i) an evolutionary searchmethod for inferring schematic correspondences; ii) an objective function for calculating thefitness value of a solution within the search space; and iii) an empirical evaluation …,*,2013,1
Pay-as-You-Go ranking of schema mappings using query logs,Ruhaila Maskat; Norman W Paton; Suzanne M Embury,Abstract Data integration systems typically make use of mappings to capture therelationships between the data resources to be integrated and the integratedrepresentations presented to users. Manual development and maintenance of suchmappings is time consuming and thus costly. Pay-as-you-go approaches to data integrationsupport automatic construction of initial mappings; which are generally of rather poor quality;for refinement in the light of user feedback. However; automatic approaches that producethese mappings typically lead to the generation of multiple; overlapping candidatemappings. To present the most relevant set of results to user queries; the mappings have tobe ranked. We proposed a ranking technique that uses information from query logs todiscriminate among candidate mappings. The technique is evaluated in terms of how …,International Conference on Data Integration in the Life Sciences,2012,1
SBRML-A Markup Language for Encoding Systems Biology Results,Joseph O Dada,The initial state of a biochemical reaction network is defined in the SBML model. To simulateand analyse the reaction network; a software package takes the SBML model as input andtransforms that initial state through a specific operation. The outcome of an operation is anew state of the system. Often an operation produces a sequence of new states; eg a timecourse. The result of an operation therefore consists of one or more result components.SBRML describes the model that is used to generate the results; ontology terms that link allthe terms/vocabularies used to external ontologies; the operation that is performed on themodel and a flexible means for encoding the results of the operation. Below is the basicstructure of SBRML and a brief description of its main components.,*,2011,1
A Functional Model for Dataspace Management Systems,Alvaro AA Fernandes; Cornelia Hedeler; Khalid Belhajjame; Lu Mao; Chenjuan Guo; Norman W Paton; Suzanne M Embury,Abstract Dataspace management systems (DSMSs) hold the promise of pay-asyou-go dataintegration. We describe a comprehensive model of DSMS functionality using an algebraicstyle. We begin by characterizing a dataspace life cycle and highlighting opportunities forboth automation and user-driven improvement techniques. Building on the observation thatmany of the techniques developed in model management are of use in data integrationcontexts as well; we briefly introduce the model management area and explain howprevious work on both data integration and model management needs extending if the fulldataspace life cycle is to be supported. We show that many model management operatorsalready enable important functionality (eg; the merging of schemas; the composition ofmappings; etc.) and formulate these capabilities in an algebraic structure; thereby giving …,*,2011,1
Run-time adaptivity for search computing,Daniele Braga; Michael Grossniklaus; Norman W Paton,Abstract In Search Computing; queries act over internet resources; and combine access tostandard web services with exact results and to ranked search services. Such resourcesoften provide limited statistical information that can be used to inform static queryoptimization; and correlations between the values and ranks associated with differentresources may only become clear at query runtime. As a result; search computing seemslikely to benefit from adaptive query processing; where information obtained during queryevaluation is used to change the way in which a query is executing. This chapter provides aperspective on how run-time adaptivity can be achieved in the context of Search Computing.,*,2011,1
Semsorgrid4env architecture,Alasdair JG Gray; Ixent Galpin; Alvaro AA Fernandes; Norman W Paton; Kevin Page; Jason Sadler; Kostis Kyzirakos; Manolis Koubarakis; Jean-Paul Calbimonte; Raúl García Castro; Oscar Corcho; Jesus E Gabaldon; Juanjo Aparicio,This document specifies; designs; and validates the Semantic Sensor Grid RapidApplication Development for Environmental Management (SemSorGrid4Env) softwarearchitecture. The architecture enables the publication and querying of both stored (egdatabase) and streaming (eg sensor) data to support the rapid development of applicationsfor environmental monitoring. Significant benefits are provided by the use of semantictechnology for service discovery and data integration. The infrastructural backbone of thearchitecture is provided by four service-oriented services: Stored Data Service for thepublication of databases; Streaming Data Service for the publication of sensor data;Registration and Discovery Service to enable resources to found; and Integration andQuerying Service to enable multiple data sources to be accessed through a single model …,*,2010,1
Quality of service aware optimization of sensor network queries,Ixent Galpin,Sensor networks comprise resource-constrained wireless nodes with the capability ofgathering information about their surroundings and have recently risen to prominence withthe promise of being an effective computing platform for diverse applications; ranging fromevent detection to environmental monitoring. The database community proposed the use ofsensor network query processors (SNQPs) as means to meet data collection requirementsusing a declarative query language. Declarative queries posed against a sensor networkconstitute an effective means to repurpose sensor networks and reduce the high softwaredevelopment costs associated with them. The range of sensor network applications is verybroad. Such applications have diverse; and often conflicting; QoS expectations in terms ofthe delivery time of results; the acquisition interval at which data is collected; the total …,*,2010,1
Data Integration in the Life Sciences: 6th International Workshop; DILS 2009; Manchester; UK; July 20-22; 2009; Proceedings,Norman W Paton; Paolo Missier; Cornelia Hedeler,Data integration in the life sciences continues to be important but challe-ing. The ongoingdevelopment of new experimental methods gives rise to an increasingly wide range of datasets; which in turn must be combined to allow more integrative views of biological systems.Indeed; the growing prominence of systems biology; where mathematical modelscharacterize behaviors observed in experiments of di? erent types; emphasizes theimportance of data integration to the life sciences. In this context; the representation ofmodels of biological behavior as data in turn gives rise to challenges relating to provenance;data quality; annotation; etc.; all of which are associated with signi? cant research activitieswithin computer science. The Data Integration in the Life Sciences (DILS) Workshop Seriesbrings together data and knowledge management researchers from the computer s-ence …,*,2009,1
Ontology Visual Querying,Sean Bechhofer; Norman W Paton,OASIS was founded in 1993 under the name ''SGML Open.''The initial goal of theorganization was to develop guidelines for interoperability among products using StandardGeneralized Markup Language (SGML). In 1998 it changed name to OASIS to reflect onchanging scope of its technical work. OASIS consists of an open group of memberorganizations whose representatives work in committees developing standards; promotingstandards adoption; product interoperability and standards conformance. In 2007 OASIShad 5;000 participants representing 600 organizations and individual members in 100countries. OASIS is governed by a member-elected Board in an annual election process.The board membership is based on the personal merits of Board nominees. OASIS processallows participants to influence standards that affect their business; contribute to …,Encyclopedia of Database Systems,2009,1
Autonomics and data management,Norman W Paton,Abstract Traditionally; database management systems have been associated with high-cost;high-quality functionalities. That is; powerful capabilities are provided; but only in responseto careful design; procurement; deployment and administration. This has been successful inmany contexts; but in an environment in which data are available in increasing quantitiesunder the management of a growing collection of distributed applications; and whereeffective use of available data often provides a competitive edge; there is a requirement forvarious benefits of a comprehensive data management infrastructure to be made availablewith rather fewer of the costs. If this requirement is to be met; automation will need to bedeployed much more widely and systematically in data management platforms. This paperreviews recent results on autonomic data management; makes a case that current …,Concurrency and Computation: Practice and Experience,2008,1
MIAPE: Column Chromatography,Andrew R Jones; Kathleen Carroll; David Knight; Kirsty MacLellan; Paula J Domann; Cristina Legido-Quigley; Lihua Huang; Lance Smallshaw; Norman W Paton,Abstract MIAPE-Column Chromatography (MIAPE-CC) is one module of the MinimalInformation About a Proteomics Experiment (MIAPE) documentation system. MIAPE isdeveloped by the Proteomics Standards Initiative of the Human Proteome Organisation(HUPO-PSI). It aims at delivering a set of technical guidelines representing the minimalinformation required to report and sufficiently support assessment and interpretation of aproteomics experiment. This MIAPE-CC module is the result of work carried out through theSample Processing Workgroup of the Proteome Standards Initiative. It has been designed tospecify a minimal set of information to document a column chromatography experiment.,*,2008,1
Automation everywhere: autonomics and data management,Norman W Paton,Abstract Traditionally; database management systems (DBMSs) have been associated withhigh-cost; high-quality functionalities. That is; powerful capabilities are provided; but only inresponse to careful design; procurement; deployment and administration. This has beenvery successful in many contexts; but in an environment in which data is available inincreasing quantities under the management of a growing collection of applications; andwhere effective use of available data often provides a competitive edge; there is arequirement for various of the benefits of a comprehensive data management infrastructureto be made available with rather fewer of the costs. If this requirement is to be met;automation will need to be deployed much more widely and systematically in datamanagement platforms. This paper reviews recent results on autonomic data …,British National Conference on Databases,2007,1
e-Fungi: an e-science infrastructure for comparative functional genomics in fungal species,Mike Cornell; Intikhab Alam; Darren Soanes; H Wong; Magnus Rattray; S Hubbard; NJ Talbot; B Lings; D Hoyle; SG Oliver; NW Paton,Abstract e-Fungi aims to integrate sequence and functional data from multiple fungalspecies; to facilitate the systematic study of less well understood species with reference tomodel organisms. e-Fungi consists of a data warehouse and a library of bioinformaticsqueries and analyses; which can be combined in different ways to conduct studies of cellularprocesses; pathogenicity and evolution. Both the warehouse and analysis libraries will bemade available within a service-oriented Grid.,Proc. 4th UK e-Science All Hands Meeting (AHM 2005),2005,1
Language bindings for spatio-temporal database programming in Tripod,Tony Griffiths; Norman W Paton; Alvaro AA Fernandes; Seung-Hyun Jeong; Nassima Djafri,Abstract While there are many proposals for spatio-temporal data models and querylanguages; there is a lack of research into application development using spatio-temporaldatabase systems. This paper seeks to redress the balance by exploring how to supportdatabase programming for spatio-temporal object databases; with specific reference to theTripod spatio-temporal OODBMS.,British National Conference on Databases,2004,1
TAMBIS: transparent access to multiple bioinformatics services,Robert Stevens; Norman W Paton; Sean Bechhofer; Gary Ng; Martin Peim; Patricia Baker; Carole Goble; Andy Brass,Abstract Transparent Access to Multiple Bioinformatics Information Sources (TAMBIS)addresses the perennial problem of heterogeneity and distribution of bioinformaticsresources in performing bioinformatics analyses. Asking questions of these resourcesusually requires multiple resources to be used and data transferred between thoseresources. A biologist using these resources needs much knowledge of which resources touse; where they are to be found; in which order they should be used; and how to overcomethe heterogeneity between those resources. TAMBIS seeks to make this knowledge burdentransparent by cap turing knowledge about molecular biology and bioinformatics tasks in anontology. The TAMBIS ontology acts as a global schema over diverse resources and drivesa query formulation interface offering a common language over those resources. High …,Encyclopedia of Genetics; Genomics; Proteomics and Bioinformatics,2004,1
Monitoring the execution of query plans,Anastasios Gounaris; Norman W Paton; Alvaro AA Fernandes; Rizos Sakellariou,Monitoring the execution of a query plan is the activity concerned with the collection ofinformation that becomes available from the completed or on-going parts of the execution.Monitoring can be classified in three categories according to the transmission of data andmessages that are related to the monitoring procedure. First; monitoring can be performed atthe level of physical operators that comprise the query plan. In that case; no data isconveyed; and consequently; there is no communication overhead. Second; monitoring mayrequire a set of operators of the query plan on a node to communicate with each other. Inthat case; the communication overhead can remain very low. Third; operators or sets ofoperators on different nodes may send data to each other in order to monitor aspects of thequery plan. The third case applies to situations in which the query plan is executed in a …,citeseer. ist. psu. edu/641121. html,2003,1
Extending database technology,Norman W Paton,Abstract Throughout the 1980s and 1990s; a significant proportion of database researchactivity has been directed towards extending the modelling and programming facilitiessupported by database systems. This paper looks into the motivation for such activity;characterises and summarises representative proposals for extensions; and presents aconcrete example of a database system incorporating a range of advanced features.,International Conference on Current Trends in Theory and Practice of Computer Science,1995,1
Object-Oriented Database Programming Languages Founded on an Axiomatic Theory of Objects,Alvaro AA Fernandes; M Howard Williams; N Paton; Maria L Barja; Andrew Dinn,Introduction This paper is based on our experiences in designing; formalizing andimplementing the deductive object-oriented database (DOOD) system ROCK & ROLL 5; 7;13; 14; 15; 16]. Our overall goal has been to bring together the deductive and the object-oriented approaches in a clean; uniform and practical way for database systems. We haveachieved this by rst developing a rst-order theory that captures features of the object-oriented paradigm in a standard logical framework; and then developing a pair oflanguages; ROCK (Rule-Object Computational Kernel) and ROLL (Rule-Object LogicLanguage); that cater for the declarative and the imperative styles in database programming.In this position paper; we concentrate on the form taken by the logical characterization of theobject-oriented data model (OODM) that underpins these two language components …,Workshop on Logical Foundations of Object-oriented Programming,1994,1
Rules management in object oriented databases: a uniform approach,N Paton; O Diaz; P Gray,*,Proceedings of 17th International Conf. On Very Large Data Bases,1991,1
OGSA-DAI,Ali Anjomshoaa; Mario Antonioletti; Malcolm Atkinson; Rob Baxter; Andrew Borley; Neil P Chue Hong; Brian Collins; Neil Hardman; George Hicken; Ally Hume; Alan Knox; Mike Jackson; Amrey Krause; Simon Laws; James Magowan; Charaka Palansuriya; Norman W Paton; Dave Pearson; Tom Sugden; Paul Watson; Martin Westhead,Access and Integration (OGSA-DAI) project is constructing an efficient Grid-enabledmiddleware implementation of interfaces and services to access and control data sourcesand sinks. For the phase of the project just completed; these data sources/sinks wererestricted to be relational and XML database management systems (DBMS). The framework;however; has been designed to allow other data sources such as file systems to beaccessed through the same interfaces.,*,*,1
User driven multi-criteria source selection,Edward Abel; John Keane; Norman W Paton; Alvaro AA Fernandes; Martin Koehler; Nikolaos Konstantinou; Julio Cesar Cortes Rios; Nurzety A Azuan; Suzanne M Embury,Abstract Source selection is the problem of identifying a subset of available data sourcesthat best meet a user's needs. In this paper we propose a user-driven approach to sourceselection that seeks to identify sources that are most fit for purpose. The approach employs adecision support methodology to take account of a user's context; to allow end users to tunetheir preferences by specifying the relative importance between different criteria; looking tofind a trade-off solution aligned with his/her preferences. The approach is extensible toincorporate diverse criteria; not drawn from a fixed set; and solutions can use a subset of thedata from each selected source; rather than require that sources are used in their entirety ornot at all.,Information Sciences,2018,*
Data context informed data wrangling,Martin Koehler; Alex Bogatu; Cristina Civili; Nikolaos Konstantinou; Edward Abel; Alvaro AA Fernandes; John Keane; Leonid Libkin; Norman W Paton,The process of preparing potentially large and complex data sets for further analysis ormanual examination is often called data wrangling. In classical warehousing environments;the steps in such a process have been carried out using Extract-Transform-Load platforms;with significant manual involvement in specifying; configuring or tuning many of them. Cost-effective data wrangling processes need to ensure that data wrangling steps benefit fromautomation wherever possible. In this paper; we define a methodology to fully automate anend-to-end data wrangling process incorporating data context; which associates portions ofa target schema with potentially spurious extensional data of types that are commonlyavailable. Instance-based evidence together with data profiling paves the way to informautomation in several steps within the wrangling process; specifically; matching; mapping …,Big Data (Big Data); 2017 IEEE International Conference on,2017,*
Targeted Feedback Collection Applied to Multi-Criteria Source Selection,Julio César Cortés Ríos; Norman W Paton; Alvaro AA Fernandes; Edward Abel; John A Keane,Abstract A multi-criteria source selection (MCSS) scenario identifies; from a set of candidatedata sources; the subset that best meets a user's needs. These needs are expressed usingseveral criteria; which are used to evaluate the candidate data sources. A MCSS problemcan be solved using multi-dimensional optimisation techniques that trade-off the differentobjectives. Sometimes we may have uncertain knowledge regarding how well the candidatedata sources meet the criteria. In order to overcome this uncertainty; we may rely on endusers or crowds to annotate the data items produced by the sources in relation to theselection criteria. In this paper; we introduce an approach called Targeted FeedbackCollection (TFC); which aims to identify those data items on which feedback should becollected; thereby providing evidence on how the sources satisfy the required criteria …,Advances in Databases and Information Systems,2017,*
SHDF-A Scalable Hierarchical Distributed Framework for Data Centre Management,Abdul Rahman Hummaida; Norman W Paton; Rizos Sakellariou,A promising approach to increase the efficiency of infrastructure usage is to adapt theassignment of resources to workloads. This can be used; for example; to consolidateexisting workloads so that the new capability can be used to serve new requests; oralternatively unused resources may be turned off to reduce energy consumption. Manyarchitectural solutions have been presented for data centre management; however thesetend to be centralised and may suffer in their ability to scale and support data centres withtens of thousands of nodes. Distributed approaches solve the scalability problem; howeverthese do not have a global view of resources across the data centre. To address this; wepropose a novel hybrid distributed hierarchical framework that is effective at providing theinformation needed for decision making at scale. We evaluate the performance of our …,Parallel and Distributed Computing (ISPDC); 2017 16th International Symposium on,2017,*
DBaaS Cloud Capacity Planning-Accounting for Dynamic RDBMS System that Employ Clustering and Standby Architectures.,Antony Higginson; Norman W Paton; Suzanne M Embury; Clive Bostock,ABSTRACT There are several major attractions that Cloud Computing promises whendealing with computing environments; such as the ease with which databases can beprovisioned; maintained and accounted for seamlessly. However; this efficiency panaceathat company executives look for when managing their estates often brings furtherchallenges. Databases are an integral part of any organisation and can be a source ofbottlenecks when it comes to provisioning; managing and maintenance. Cloud computingcertainly can address some of these concerns when Database-as-a-Service (DBaaS) isemployed. However; one major aspect prior to adopting DBaaS is Capacity Planning; withthe aim of avoiding underestimation or over-estimation of the new resources required fromthe cloud architecture; with the aim of consolidating databases together or provisioning …,EDBT,2017,*
Pay-as-you-go Configuration of Entity Resolution,Ruhaila Maskat; Norman W Paton; Suzanne M Embury,Abstract Entity resolution; which seeks to identify records that represent the same entity; isan important step in many data integration and data cleaning applications. However; entityresolution is challenging both in terms of scalability (all-against-all comparisons arecomputationally impractical) and result quality (syntactic evidence on record equivalence isoften equivocal). As a result; end-to-end entity resolution proposals involve several stages;including blocking to efficiently identify candidate duplicates; detailed comparison to refinethe conclusions from blocking; and clustering to identify the sets of records that mayrepresent the same entity. However; the quality of the result is often crucially dependent onconfiguration parameters in all of these stages; for which it may be difficult for a humanexpert to provide suitable values. This paper describes an approach in which a complete …,*,2016,*
Interpreting Linked Data Search Results Using Markov Logic.,Duhai Alshukaili; Alvaro AA Fernandes; Norman W Paton,ABSTRACT Linked Data (LD) follows the web in providing low barriers to publication; and indeploying web-scale keyword search as a central way of identifying relevant data. As in theweb; searches initially identify results in broadly the form in which they were published; andthe published form may be provided to the user as the result of a search. This will besatisfactory in some cases; but the diversity of publishers means that the results of thesearch may be obtained from many different sources; and described in many different ways.As such; there seems to be an opportunity to add value to search results by providing userswith an integrated representation that brings together features from different sources. Thisinvolves an on-the-fly and automated data integration process being applied to searchresults; which raises the question as to what technologies might be most suitable for …,EDBT/ICDT Workshops,2015,*
STRUCTURE INFERENCE FOR LINKED DATA SOURCES,Klitos Christodoulou; Norman W Paton; Alvaro AA Fernandes,Downloaded from HEPHAESTUS Repository; Neapolis University institutional repository …Title: STRUCTURE INFERENCE FOR LINKED DATA SOURCES USING CLUSTERING …Year: 2015-11 Author: Christodoulou; Klitos ; Paton; Norman W. ; Fernandes; Alvaro AAAbstract: Linked Data (LD) overlays the World Wide Web of documents with a Web of Data. Thisis becoming significant as shown in the growth of LD repositories available as part of the LinkedOpen Data (LOD) cloud. At the instance- level; LD sources use a combination of terms from variousvocabularies; expressed as RDFS/OWL; to describe data and publish it to the Web.However; LD sources do not organise data to conform to a specific structure analogous to a relationalschema; instead data can adhere to multiple vocabularies. Expressing SPARQL queries overLD sources – usually over a SPARQL endpoint that is presented to the user – requires …,Structure,2015,*
COMBINING SYNTACTIC AND SEMANTIC EVIDENCE FOR,Klitos Christodoulou; Alvaro AA Fernandes; Norman W Paton,Title: COMBINING SYNTACTIC AND SEMANTIC EVIDENCE FOR IMPROVING MATCHING OVERLINKED DATA SOURCES … Year: 2015-11 Author: Christodoulou; Klitos ; Fernandes; AlvaroAA ; Paton; Norman W. Abstract: In the context of Linked Data (LD) sources; the ability to traverselinks and retrieve further information can be exploited to harvest semantic annotations. Suchannotations can; in turn; underpin the inference of semantic correspondences betweensources. This paper shows that using semantic annotations as additional evidence of equivalencebetween schematic representations of LD sources can improve upon the prevalent; purely syntacticapproaches. The paper both describes the construction of probabilistic models that yield degreesof belief on the equivalence of the real-world concepts represented by the data and shows howthese models are crucial in underpinning a Bayesian approach to assimilating both …,*,2015,*
Declarative In-Network Sensor Data Analysis,George Valkanas; Ixent Galpin; Alasdair JG Gray; Alvaro AA Fernandes; Norman W Paton; Dimitrios Gunopulos,Abstract. Bridging data analysis techniques with classic query processing has long been ofinterest in the database community. Most approaches; however; are usually developed witha specific domain in mind; eg relational; streaming etc.; use their own query language; orfocus on specific techniques. In this paper; we propose a simple; yet effective; extension tostandard or commonly used declarative processing languages to support data mining. Ourapproach is independent of a particular domain; and by utilizing a query refactoringtechnique; optimization issues are taken care of by the underlying query processing engine;which is already in place and knows best the setting's particularities. Therefore; ourapproach promotes ease of programmability; development; and use of the data miningtechniques; with minimal modifications in the query processing stack. We demonstrate …,WORKSHOP ON LANGUAGES FOR DATA MINING AND MACHINE LEARNING,2013,*
ODMG Compliant Databases,Norman Murray; Carole Goble; Norman Paton,Abstract Kaleidoscape is a three dimensional (3D) implementation of a data-flow orientedvisual query language; which has been implemented in 3D to examine the advantages anddisadvantages of such an interface paradigm over current WIMP GUIs. This paper describesa version of Kaleidoscape that allows the user to construct queries from within a 3Denvironment. These queries are then translated into the ODMG standard textual querylanguage OQL for evaluation; the results of which can be viewed and browsed from withinthe Kaleidoscape environment.,Visual Database Systems 4: IFIP TC2/WG2. 6 Fourth Working Conference on Visual Database Systems 4 (VDB4) 27–29 May 1998; L’Aquila; Italy,2013,*
MIMS EPrint: 2015.57 Manchester Institute for Mathematical Sciences School of Mathematics,Kieran Smallbone; Hanan L Messiha; Kathleen M Carroll; Catherine L Winder; Naglis Malys; Warwick B Dunn; Ettore Murabito; Neil Swainston; Joseph O Dada; Farid Khan; Pınar Pir; Evangelos Simeonidis; Irena Spasi; Jill Wishart; Dieter Weichart; Neil W Hayes; Daniel Jameson; David S Broomhead; Stephen G Oliver; Simon J Gaskell; John EG McCarthy; Norman W Paton; Hans V Westerhoff; Douglas B Kell; Pedro Pendes,abstract We present an experimental and computational pipeline for the generation of kineticmodels of metabolism; and demonstrate its application to glycolysis in Saccharomycescerevisiae. Starting from an approximate mathematical model; we employ a ''cycle ofknowledge''strategy; identifying the steps with most control over flux. Kinetic parameters ofthe individual isoenzymes within these steps are measured experimentally under astandardised set of conditions. Experimental strategies are applied to establish a set of invivo concentrations for isoenzymes and metabolites. The data are integrated into amathematical model that is used to predict a new set of metabolite concentrations andreevaluate the control properties of the system. This bottom-up modelling study reveals thatcontrol over the metabolic network most directly involved in yeast glycolysis is more …,FEBS Letters,2013,*
Pay-as-you-go data integration for linked data: opportunities; challenges and architectures,Bijan Parsia; Alvaro AA Fernandes; Norman W Paton; Cornelia Hedeler; Klitos Christodoulou,*,*,2012,*
Evaluation of the SemsorGrid4Env SNDM Software Platform,Alasdair JG Gray; Ixent Galpin; Alvaro AA Fernandes; Norman W Paton; George Valkanas; Dimitrios Gunopulos; Josep Rodrıguez; Juanjo Aparicio,Executive Summary One of the features of the SemSorGrid4Env architecture is the ability forusers to pose declarative queries in order to receive the data that they require. That is; theuser need not worry about where; when; or how data is gathered; they need only state theirdata needs. Work Package 2 (WP2) aims to support this vision by providing animplementation of the streaming data service through which users can pose declarativequeries in SNEEql. It is also intended to enhance the querying capabilities through dataanalysis functionality being made available directly in the query. Sensor networks fall intotwo different categories. The first type of sensor network has fixed functionality with a streamof data being generated at a fixed rate. In order to query this stream of data; the stream mustbe processed outwith of the sensor network; called out-of-network evaluation. The second …,*,2011,*
Executing in-network queries using SNEE,Ixent Galpin; Robert Taylor; Alasdair JG Gray; Christian YA Brenninkmeijer; Alvaro AA Fernandes; Norman W Paton,Abstract The SNEE query optimizer enables users to characterize data requests againstwireless sensor networks (WSNs); using a declarative query language called SNEEql(SNEE for S ensor NE twork E ngine; described in [GBG+ 11]; and publicly available athttp://code. google. com/p/snee). Queries are compiled into imperative query executionplans; which are translated into executable nesC source code. In this paper; we illustrate thelifecycle of a SNEEql query Q for in-network execution. This lifecycle encompasses the stepsof preparatory metadata collection; followed by the compilation of Q into a query executionplan QEP; the dissemination of binary images implementing QEP throughout the WSN; andthe generation of query results.,British National Conference on Databases,2011,*
Adaptive query processing in pipelined plans,Alvaro Fernandes; Norman Paton,*,*,2008,*
Adaptive query processing in pipelined plans,Alvaro Fernandes; Norman Paton,*,*,2008,*
An infrastructure for adaptive systems development,Kevin Lee; Norman W Paton; Alvaro AA Fernandes; Rizos Sakellariou; Jim Smith; Paul Watson,Page 1. An Infrastructure for Adaptive Systems Development Kevin Lee; Norman W. Paton;Alvaro AA Fernandes; Rizos Sakellariou School of Computer Science; University of ManchesterOxford Road; Manchester; M13 9PL; UK {klee; rizos; norm; alvaro}@cs.man.ac.uk Jim Smith;Paul Watson School of Computing Science; Newcastle University Claremont Road; Newcastleupon Tyne; NE1 7RU; UK {Jim.Smith; Paul.Watson}@ncl.ac.uk Objectives FoundationMethodology Business Workflows Distributed Query Processing DAG Scheduling ● Createan infrastructure to support the Systematic Development of Adaptive Systems ● Ease thedevelopment of adaptive systems. ● Support the development of better adaptive systems ●Investigate the use of the infrastructure in a number of different domains ● Use the infrastructureto improve the general understanding of adaptive systems …,*,2007,*
Storing; Searching; and Disseminating Experimental Proteomics Data,Norman W Paton; Andrew R Jones; Chris Garwood; Kevin Garwood; Stephen Oliver,Abstract The chapter introduces the challenges of storing; sharing; and querying proteomicsdata caused by the complexity of the experimental techniques; and the speed with which thetechniques evolve. Public proteome databases are difficult to develop and populatebecause of the range of data types and queries that must be supported; and the quantity ofmetadata required to validate results. There are several data standards under developmentthat should alleviate some of the challenges; and databases that utilize the standards arebecoming more widely supported. The chapter describes a model of a complete proteomicspipeline; including the metadata that should be captured to allow confidence to be placed onthe results. Software is also required; which can produce data conforming to the standardsand that can be used to query proteomics data repositories. The chapter outlines the …,*,2007,*
Web Services Data Access and Integration–The XML Realization (WS-DAIX) Specification; Version 1.0,Amy Krause; Stephen Langella; Steven Lynden; Simon Laws; Susan Malaika; Norman W Paton,Abstract Data resources play a significant role in many applications across multipledomains. Web services provide implementation neutral facilities for describing; invoking andorchestrating collections of networked resources. The GGF (Global Grid Forum) Open GridServices Architecture (OGSA); and its associated specifications; defines consistentinterfaces through web services to components of the grid infrastructure. Both the web andgrid communities stand to benefit from the provision of consistent and agreed web serviceinterfaces for data resources and the systems that manage them. This document presents aspecification for a collection of data access interfaces for XML data resources; which extendsinterfaces defined in the Web Services Data Access and Integration document [WS-DAI]. Thespecification can be applied in regular web services environments or as part of a grid …,*,2006,*
Web Services Data Access and Integration–The Relational Realisation (WS-DAIR) Specification; Version 1.0,Mike Jackson; Amy Krause; Simon Laws; James Magowan; Susan Malaika; Norman W Paton,Abstract Data resources play a significant role in many applications across multipledomains. Web services provide implementation neutral facilities for describing; invoking andorchestrating collections of networked resources. The OGF (Open Grid Forum) Open GridServices Architecture (OGSA); and its associated specifications; defines consistentinterfaces through web services to components of the grid infrastructure. Both the web andgrid communities stand to benefit from the provision of consistent and agreed web serviceinterfaces for data resources and the systems that manage them. This document presents aspecification for a collection of data access interfaces for relational data resources; whichextends interfaces defined in the “Web Services Data Access and Integration” document [WS-DAI]. The specification can be applied in regular web service environments or as part of a …,*,2006,*
An evaluation of representing proteomics experiments within FuGE-OM,Andrew Jones; Angel Pizarro; Paul Spellman; Chris Taylor; Norman Paton,*,*,2005,*
Core Database Technology Program Committee,Anastassia Ailamaki; Gustavo Alonso; Walid Aref; Lars Arge; Brian Babcock; Mikael Berndtsson; Elisa Bertino; Claudio Bettini; Michael Boehlen; Anthony Bonner; Philippe Bonnet; Alex Buchmann; Tiziana Catarci; Surajit Chaudhuri; Peter Dadam; Amol Deshpande; Asuman Dogac; Christos Faloutsos; Elena Ferrari; Johann-Christoph Freytag; Dieter Gawlick; Johannes Gehrke; Torsten Grust; Ralf Hartmut Güting; Jayant Haritsa; Chris Jermaine; Christoph Koch; George Kollios; Mong Li Lee; Wolfgang Lindner; David Lomet; Hongjun Lu; Samuel Madden; Giansalvatore Mecca; Alberto Mendelzon; Rosa Meo; Tova Milo; Michele Missikoff; C Mohan; Mario Nascimento; Shojiro Nishio; Ed Omiecinski; Norman Paton; Torben Bach Pedersen; Calton Pu; Philippe Pucheral; Raghu Ramakrishnan; Thomas Rölleke; Ken Ross; Gunther Saake; Albrecht Schmidt; Marc Scholl; Bernhard Seeger,Committee Chair: Martin Kersten; CWI; The Netherlands … Serge Abiteboul; INRIA; France AnastassiaAilamaki; Carnegie Mellon University; USA Gustavo Alonso; ETH Zurich; Switzerland WalidAref; Purdue University; USA Lars Arge; Aarhus University; Denmark Brian Babcock; StanfordUniversity; USA Mikael Berndtsson; University of Skövde; Sweden Elisa Bertino; PurdueUniversity; USA Claudio Bettini; University of Milan; Italy Michael Boehlen; Free University ofBolzano/Bozen; Italy Peter Boncz; CWI; The Netherlands Anthony Bonner; University ofToronto; Canada Philippe Bonnet; University of Copenhagen; Denmark Alex Buchmann; Universityof Darmstadt; Germany Tiziana Catarci; University of Rome 'La Sapienza'; Italy SurajitChaudhuri; Microsoft; USA Vassilis Christophides; FORTH; Greece Peter Dadam; Universityof Ulm; Germany Amol Deshpande; University of California; Berkeley; USA Asuman …,VLDB 2005: 31st International Conference on Very Large Data Bases: Proceedings of the 31st International Conference on Very Large Data Bases; Trondheim; Norway; August 30-September 2; 2005,2005,*
Publications in Journals,Andrea Calì; Diego Calvanese FUB; Giuseppe de Giacomo; Alessandro Artale FUB; Clare Dixon; Michael Fisher; Enrico Franconi; Stefan Brass; Jürgen Dix FUB; Teodor C Przymusinski; Super Logic; Giuseppe De Giacomo; Maurizio Lenzerini; Martin Peim; Enrico Franconi FUB; Norman Paton,We expect that most presentations at conferences and workshops will be submitted in acomplete version to Journals as well. However; the process of getting a paper published at ajournal usually takes 1-3 years; so the first publications appeared in the second year of theproject.,Information Systems,2004,*
Semantics of a Networked World. Semantics for Grid Databases: First International IFIP Conference; ICSNW 2004; Paris; France; June 17-19; 2004; Revised Selecte...,Norman W Paton; Mokrane Bouzeghoub; Carole Goble; Vipul Kashyap; Stefano Spaccapietra,*,*,2004,*
Chiu; DKW; see Radha Krishna; P. 31–58,J Cole; G Dedene; M Snoeck; N Desai; S Tai; L Ekenberg; V Boeva; AAA Fernandes; A Gounaris; S Gibson; PF Linington; F Goethals; NW Paton; AAA Fernandes; R Sakellariou; U Greiner; R Müller; M Kantarcıoglu; WS Li; K Karlapalem,*,Data & Knowledge Engineering,2004,*
Digital data are now fundamental to all branches of science and engineering; such data play a major role in medical research and diagnosis and underpin business...,Malcolm Atkinson; Ann L Chervenak; Peter Kunszt; Inderpal Narang; Norman W Paton; Dave Pearson; Arie Shoshani; Paul Watson,The sheer size of datasets being generated makes the interpretation of the data in any onecollection challenging. Analysis may demand teraflops of compute power and requireaccess to terabytes of data distributed across millions of binary files and multiple databases.Furthermore; analysis may require complex series of processing steps; each generatingintermediate data products of size comparable to the input datasets. These intermediatedata products need to be stored; either temporarily or permanently; and made available fordiscovery and use by other analysis processes. Effective manipulation; processing; and useof these large-scale; distributed data resources require an infrastructure in which shareddata; storage; networking; and compute resources can be delivered to data analysisactivities in an integrated; flexible manner. The advent of ubiquitous network connectivity …,The Grid: Blueprint for a New Computing Infrastructure,2004,*
Databases and the Grid: JDBC in WSDL; or something altogether different?,Norman W Paton,Abstract The Grid is rising to prominence both as a vision and as an infrastructure. Thevision is of dynamically formed virtual organisations that collaborate to address sharedgoals. The infrastructure; although still a work in progress; is a middleware that facilitates thesharing of networked resources on a global scale. Databases are important resources thatare central to many organisations; and as such must be able to be accessed; integrated andmanaged in a Grid environment. How should this be done? What problems must beovercome when working in a Grid environment? What new expectations; opportunities andpatterns of use come to the fore? This presentation both discusses core grid data accessservices and the wider implications and opportunities of Grids for database technologies.,*,2004,*
Web Services Data Access and Integration (WS-DAI),Malcolm Atkinson; NESC Amy Krause; Simon Laws; Susan Malaika; Norman W Paton; Dave Pearson; Oracle Greg Riccardi,Abstract Data resources play a significant role in many applications across multipledomains. Web services provide implementation neutral facilities for describing; invoking andorchestrating collections of networked resources. The GGF (Global Grid Forum) Open GridServices Architecture (OGSA); and its associated specifications; defines consistentinterfaces through web services between components of the grid infrastructure. Both the weband grid communities would benefit from the provision of consistent and agreed web serviceinterfaces for data resources and the systems that manage them.,*,2004,*
Efficient query evaluation in an ODMG-compliant spatio-historical database,Seung Hyun Jeong; NW Paton,*,*,2004,*
COGEME-Consortium for the functional genomics of microbial eukaryotes: Facilities for the functional analysis of microbial genomes.,C Merlotti; I Riba-Garcia; SJ Gaskell; ZK Yin; A Brown; P Cash; A Hayes; NJ Talbot; A Brass; N Paton; SG Oliver,*,YEAST,2003,*
Grid Database Access and Integration: Requirements and Functionalities,Norman W Paton; Dave Pearson; Oracle Tony Storey; Paul Watson,Abstract This document is intended to provide the context for developing Grid data servicestandard recommendations within the Global Grid Forum. It defines the genericrequirements for accessing and integrating persistent structured and semi-structured data. Inaddition; it defines the generic functionalities which a Grid data service needs to provide insupporting discovery of and controlled access to data; in performing data manipulationoperations; and in virtualising data resources. The document also defines the scope of Griddata service standard recommendations which are presented in a separate document.,*,2003,*
Grid Database Service Specification Primer,GFD-I Neil P Chue Hong; Amy Krause; Susan Malaika; Gavin McCance; Simon Laws; James Magowan; Norman W Paton; Greg Riccardi,Abstract This primer illustrates some of the proposed capabilities of Grid Data Services withdescriptions and examples. The document includes a brief introduction to the GDSspecification draft; a presentation of some of the possible scenarios for interaction betweenclients and GDSs; and a detailed description of several examples of Grid Data Servicerequests and responses.,DAIS Working Document,2003,*
de Moor; A.; see Weigand; H. 349–369,D Agrawal; WS Li; M Akhtar Ali; AAA Fernandes; NW Paton,*,Data & Knowledge Engineering,2003,*
Grid Data Service Specification: The Relational Realisation,Amy Krause; Shannon Hastings; Stephen Langella; Susan Malaika; James Magowan; Simon Laws; Norman W Paton,*,*,2003,*
International Journal of High Performance,Jim Smith; Paul Watson; Anastasios Gounaris; Norman W Paton; Alvaro AA Fernandes; Rizos Sakellariou,Abstract Distributed query processing (DQP) has been widely used in data intensiveapplications where data of relevance to users are stored at multiple locations. This paperargues:(i) that DQP can be important in the Grid; as a means of providing high-level;declarative languages for integrating data access and analysis; and (ii) that the Gridprovides resource management facilities that are useful to developers of DQP systems. Aswell as discussing and illustrating how DQP technologies can be deployed within the Grid;the paper describes Polar*; a prototype implementation of a DQP system running overGlobus. Polar* can handle complex data by adopting the ODMG object model and its querylanguage OQL; which supports the invocation of user-defined operations. The Globuscomponents are accessed through the MPICH-G interface rather than in a lower level way …,International Journal of High Performance Computing Applications,2003,*
Data Service Specification: The XML Realisation,Amy Krause; Shannon Hastings; Stephen Langella; Susan Malaika; Simon Laws; Norman W Paton,*,*,2003,*
GWD-I Malcolm P Atkinson; National e-Science Centre Category: INFORMTIONAL Vijay Dialani; University of Southampton DAIS-WG Leanne Guy; CERN Inderpal...,Norman W Paton; Dave Pearson; Oracle Tony Storey; Paul Watson,Abstract This document is intended to provide the context for developing Grid data servicestandard recommendations within the Global Grid Forum. It defines the genericrequirements for accessing and integrating persistent structured and semi-structured data. Inaddition; it defines the generic functionalities which a Grid data service needs to provide insupporting discovery of and controlled access to data; in performing data manipulationoperations; and in virtualising data resources. The document also defines the scope of Griddata service standard recommendations which are presented in a separate document..,*,2003,*
A Notification Service for Data Sources in a Service Oriented Grid Environment,MN Alpdemir; Norman W Paton; Alvaro AA Fernandes,*,*,2002,*
Databases,Alvaro AA Fernandes; Norman W Paton,*,*,2001,*
Franse ed.: kritisch theaterlexicon: Arne Sierens,Erwin Jans; Geert Opsomer; Christel Stalpaert,Arne Sierens naît le 15 août 1959. Il passe sa jeunesse dans une cité ouvrière à l'ouest deGand; le «Brugse Poort». Son sentiment d'appartenance à ce quartier le marquera au ferrouge. Comme Aalst pour Louis Paul Boon; Rimini pour Fellini ou Little Italy pour Scorsese;ce que représente cet îlot ouvrier de logements sociaux est; pour Sierens:«un endroit où lacondition humaine devient visible; là n'habitent pas de dieux; mais des paumés; on n'y voitpas de tragédies; mais des mélodrames.» 1. C'est de son père; le romancier et critique decinéma Frans Sierens; qu'il hérite son goût de la littérature et du cinéma. Ainsi; dès sa primejeunesse; Arne Sierens est confronté à la tension entre l'Art et son grand A et la culturepopulaire; tension qui jouera un rôle essentiel dans son œuvre. Après ses étudessecondaires; il s' inscrit au RITCS de Bruxelles où il suit des cours de mise en scène qu'il …,*,2001,*
Maintenance of Data Warehouses-An Experimental Performance Evaluation of Incremental Materialized View Maintenance in Object Databases,MA Ali; NW Paton; AAA Fernandes,*,Lecture Notes in Computer Science,2001,*
An Algebraic Approach to Materialized Views Maintenance in Object Databases,M Akhtar Ali; Alvaro AA Fernandes; Norman W Paton,Abstract View materialization is an important technique for data warehousing; highperformance query processing; and OLAP. Materialized views (MVs) are derived from baseextents that may not be local. Queries can be answered using MVs more quickly than usingthe base extents. However; MVs may be affected by updates to the base extents. MVs caneither be re-computed or incrementally updated to reflect the updates to the base extents.Generally; re-computing the entire view is more expensive than propagating changes to theview incrementally. The cost of incremental view maintenance (IVM) can further be reducedif access to base extents can be avoided. We incrementally maintain MVs defined in theObject Query Language (OQL) proposed in the ODMG standard for object databases. For acertain class of OQL views and for some update operations we avoid access to base …,*,2000,*
UMLi: The Unified Modeling Language for Interactive,Paulo Pinheiro da Silva; Norman W Paton,*,*,2000,*
Dietz; JLG; see Steuten; AAG 121±136,A Dusterhoft; B Thalheim; PR Falcone Sampaio; NW Paton; G Fliedl; C Kop; HC Mayr; W Mayerthaler; C Winkler; U Hahn; M Romacker; M Hon Wong; H Kwong Mak; K JaÈrvelin; T Niemi; A Salminen; X Jia; J Xiao; C Kop; M Hon Wong; WS Li; D Agrawal; W Mayerthaler; HC Mayr; E Metais; T Niemi; L Palopoli; L Pontieri; G Terracina; D Ursino; NW Paton; L Pontieri; M Romacker; A Salminen; K Selcßuk Candan; WS Li; M Lakshmi Priya; F Steimann,*,databases,2000,*
Generating User Interface Code from Declarative Models,Paulo Pinheiro da Silva; Tony Griffiths; Norman W Paton,*,*,1999,*
Generating User Interface Code from Declarative Models: The Teallach Approach,Norman W Paton,Abstract Declarative models can provide abstract descriptions of user interfaces. Therefore;it is desirable to use declarative models for designing user interfaces since complex detailsof the user interfaces can be avoided at the design time. However; declarative models areusually not able to describe all aspects required to generate user interfaces. This paperdescribes the code generation of complete user interfaces from declarative models. Theruntime context and the code generation process are presented and explained. Details ofthe declarative models and the runtime class library used by the code generator aredescribed. Further; an illustrative example of the use of the code generator is also provided.The code generator is part of the Teallach model-based user interface developmentenvironment.,*,1999,*
The ROCK & ROLL System User Manual,NW Paton; ML Barja; A Dinn; AAA Fernandes; O Liew,The purpose of this document is to introduce the ROCK & ROLL database system. ROCK &ROLL is a deductive object-oriented database system which supports an imperativedatabase programming language; ROCK; and a deductive query language; ROLL. TheROCK component can be used for schema de nition and data manipulation; while ROLL canbe used to express queries and to de ne declarative methods. Static type checking issupported throughout. The current version of ROCK & ROLL has been implemented as aninterpreter. There are two versions of the system: the main memory version rnr and thepersistent version prnr. There is a top level shell which accepts commands tocompile/execute a program; de ne persistent environments etc. The commands available atthis level are described in Section 2. In Section 3 the general structure of a program is …,*,1998,*
Extending a Deductive Object-Oriented Database System with Spatial Data Handling Facilities Alvaro AA Fernandes Department of Computer Science University of...,Norman W Paton; M Howard Williams; Olive Liew,Abstract This paper describes the integration of a spatial data handling component with theROCK & ROLL deductive object-oriented database system. The extended ROCK & ROLLsystem provides much more comprehensive and better integrated database programmingfacilities than other candidate platforms for spatial information systems. The extendedsystem serves developers with an intuitive; expressive; formally defined collection of spatialdata types as primitive types whose operations have state-of-the-art computationalcomplexity. The integration of these types with the object-oriented modelling; imperativeprogramming and deductive querying facilities of ROCK & ROLL makes available acomprehensive and integrated suite of complementary mechanisms for the development ofspatial information systems. The paper also provides preliminary benchmark results …,*,1998,*
HCIL-96-03 This paper presents some experiences in the exploitation of database interface development architecture in which the interface is implemented using th...,N Paton; K Doan; O Díaz; A Jaime,The HCIL has a long; rich history of transforming the experience people have with newtechnologies. From understanding user needs; to developing and evaluating thesetechnologies; the lab's faculty; staff; and students have been leading the way in HCIresearch and teaching.,Proceedings of the 3rd International Workshop on Database Interfaces (IDS3)(Edinburgh; Scotland; July 1996),1995,*
Extending ROCK & ROLL with Spatial Data Types: Part,Alvaro AA Fernandes; M Howard Williams; Norman W Paton,Abstract The ROCK & ROLL deductive object-oriented database system has been used todevelop applications that involve the querying and manipulation of spatial data. Theapproach to the development of these applications has hitherto required that a suitable setof spatial data types is de ned and handed over to applications as a class library for reuse.While this approach is functionally adequate; it leaves open the way to potentialinconsistencies in the treatment of geometries and to computational ine ciency; especiallydue to the absence of built-in spatialindexing facilities and spatial-query optimization. Part 1of this paper describes the embedding of a spatial algebra into the imperative language ofROCK & ROLL. This provides users with geometrically consistent; computationally e cientbuilt-in support for spatial data types and operations; thereby lessening the burden …,*,1995,*
Alvaro AA Fernandes; M. Howard Williams Department of Computing and Electrical Engineering Heriot-Watt University Riccarton; Edinburgh EH14 4AS; UK e-mail,Norman W Paton,*,*,1995,*
The ROCK & ROLL System User Manual,ML Barja; NW Paton; A Dinn; AAA Fernandes,*,*,1995,*
Andrew Dinn and Alia I. Abdelmoty Department of Computing and Electrical Engineering; Heriot-Watt University; Edinburgh EH14 4AS; UK,Maria L Barja; Alvaro AA Fernandes; Norman W Paton; M Howard Williams,*,*,1995,*
Also in this series,M Nivat; C Rattray; T Rus; G Scollo; Yves Deville; Catriel Beeri; Atsushi Ohori; Dennis E Shasha; Matt Smith; Alan Smaill; Geraint A Wiggins; Norman W Paton; M Howard Williams; DJ Andrews; JF Groote; CA Middelburg; B Thuraisingham; R Sandhu; TC Ting; JP Bowen; JA Hall; David Till; VS Alagar; S Bergler; FQ Dong; Wojciech P Ziarko; A Ponse; C Verhoef; SFM van Vlijmen; Pete Sawyer; Malcolm Atkinson; David Maier; Veronique Benzaken,This is the proceedings of the seventh annual workshop held by the Glasgow FunctionalProgramming Group. The purpose of the workshop is to provide a focus for new research; tofoster research contacts with other functional language researchers; and to provide aplatform for research students to develop their presentation skills. As in previous years; wespent three days closeted together in a pleasant seaside town; isolated from normal workcommitments. We were joined by colleagues from other universities (both UK and abroad)and from industry. Workshop participants presented a short talk about their current researchwork; and produced a paper which appeared in a draft proceedings. These papers werethen reviewed and revised in the light of discussions at the workshop and the referees'comments. A selection of those revised papers (the majority of those presented at the …,Proceedings of the Eighth Z User Meeting,1994,*
Also in this series,Yves Deville; Catriel Beeri; Atsushi Ohori; Matt Smith; Alan Smaill; Norman W Paton; DJ Andrews JF Groote; B Thuraisingham R Sandhu; David Till; Wojciech P Ziarko; A Ponse; C Verhoef; Pete Sawyer; Malcolm Atkinson David Maier; Kevin Hammond David N Turner,The contents of this book are an expanded and thorough treatment of a set of presentationsmade at a workshop held in Banff; Alberta; 28 August-3 September 1993 by leadingpractitioners in asynchronous hardware design. The papers cover a wide range of currentpractice from practical design; through silicon compilation; to the applications of formalspecifications.,Proceedings of the Eighth Z User Meeting,1994,*
Also in this series,Matt Smith; Alan Smaill; Norman W Paton; DJ Andrews; JF Groote; B Thuraisingham; R Sandhu; David Till; Wojciech P Ziarko; A Ponse; C Verhoef; Pete Sawyer; Malcolm Atkinson; David Maier; Kevin Hammond; David N Turner,I remember always; in drawing; the basic principles of shadow and light. Objects interceptingthe light cast shadows. Shadow is deprivation oflight. The shape of shadow is determined bythat of the object. But not always directly. Sometimes it is only indirectly affected by it.Sometimes the cause of the shadow cannot be found.,Proceedings of the Eighth Z User Meeting,1994,*
Rules in Database Systems: Proceedings,Howard M Williams; Norman W Paton,*,*,1994,*
Rules in Database Systems: Proceedings of the... International Workshop on Rules in Database Systems,Norman W Paton; M Howard Williams,*,*,1993,*
A Prolog implementation of an object-oriented database system,Norman William Paton,The logic programming language Prolog has been used extensively in conjunction withrelational database systems to exploit the similarity between relations and Prolog groundclauses. However; much of the experience gained in the use of Prolog with relationaldatabases has employed characteristics of the language which are independent of therelational model to build user interfaces and perform query transformation. This thesisdescribes the use of Prolog for developing semantic and object-oriented database systems.Two systems have been developed; one called P/FDM which is based upon the functionaldata model; and the other called ADAM which integrates ideas from semantic datamodelling with constructs developed for sharing behaviour in object-oriented programminglanguages. The thesis can be considered to be in three sections. The first reviews resarch …,*,1989,*
A PROLOG INTERFACE TO A FUNCTIONAL DATA MODEL DATABASE,Peter MD Gray David S Moffat; Norman W Paton,*,Advances in Database Technology-EDBT'88: International Conference on Extending Database Technology Venice; Italy; March 14-18; 1988. Proceedings,1988,*
Abiteboul; S.; Towards a deductive object-oriented database language AIonso; F.; JL Mat6 and J. Pazos; Knowledge engineering versus software engineering Angel...,PMG Apers; PWPJ Grefen; MAW Houtsma; AW Apon; RS Wall; G Ariav; P Atzeni; DS Parker Jr; R Torlone; ML Barja; NW Paton; E Barkmeyer; V Krishnamurthy; DT Barnard; AR Reuber; A Basu; TK Nayak; S Mukherjee; J Beal; C Beeri; DA Bell; J Shao; MEC Hull; J Bernstein; LJ Mazlack; E Bertino; C Guglielmina; D Musto; KK Bharadwaj; NK Jain; L Bic; EA Rundensteiner; H Blanken; HM Blanken; WB Teeuw; W Boe; N Gorla; NA Botten; T Raz; F Bry; DM Campbell; DW Embley; B Czejdo; F Cesarini; M Missikoff; G Soda,*,database,1985,*
2006 IEEE International Conference on Autonomic Computing,NW Paton; V Raman; G Swart; I Narang,Writing parallel programs that can take advantage of non-dedicated processors is muchmore difficult than writing such programs for networks of dedicated processors. In a non-dedicated environment such programs must use autonomic techniques to respond to theunpredictable load fluctuations that characterize the computational model. In the area ofadaptive query processing (AQP); several techniques...,*,*,*
Spatio-Temporal Evolution: Querying Patterns of Change in Spatio-Temporal Databases,Nassima Djafri; Alvaro AA Fernandes; Norman W Paton; Tony Griths,*,*,*,*
Object-oriented databases A semantic data model approach Prentice Hall International Series in Computer Science,Peter MD Gray Krishuarao G Kulkarni; Norman W Paton,Page 1. Object-oriented databases A semantic data model approach Prentice Hall InternationalSeries in Computer Science Details Category: Computer Object-oriented databases A semanticdata model approach Prentice Hall International Series in Computer Science Material TypeBook Language English Title Object-oriented databases A semantic data model approachPrentice Hall International Series in Computer Science Author(S) Peter MD Gray KrishuaraoG. Kulkarni Norman W. Paton Publication Data NY: Prentice-Hall Publication Date 1992 EditionNA Physical Description XV; 237p Subject Computer Subject Headings Object OrientedDatabases ISBN NA Copies NA Permanent Links click here,Computer,*,*
Journal of Cloud Computing,Abdul R Hummaida; Norman W Paton; Rizos Sakellariou,With increased demand for computing resources at a lower cost by end-users; cloudinfrastructure providers need to find ways to protect their revenue. To achieve this;infrastructure providers aim to increase revenue and lower operational costs. A promisingapproach to addressing these challenges is to modify the assignment of resources toworkloads. This can be used; for example; to consolidate existing...,*,*,*
A Methodology for Comparative Functional Genomics,Norman W Paton; Stephen G Oliver; Simon J Hubbard; Nicholas J Talbot; Magnus Rattray; Han Min Wong; Cornelia Hedeler; Darren M Soanes; Mike Cornell; Intikhab Alam,@article{escholarshiprepository250;. author = "Paton; Norman W.; Oliver; Stephen G.; Hubbard;Simon J.; Talbot; Nicholas J.; Rattray; Magnus; Wong; Han Min; Hedeler; Cornelia; Soanes; DarrenM.; Cornell; Mike; Alam; Intikhab";. title = "A Methodology for Comparative Functional Genomics";.year = "2007";. journal = "http://journal.imbio.de/index.php?paper_id=69";. publisher = "UniversityLibrary of Bielefeld". }. @article{escholarshiprepository5202;. author = "Paton; Norman W.; Oliver;Stephen G.; Hubbard; Simon J.; Talbot; Nicholas J.; Rattray; Magnus; Wong; Han Min; Hedeler;Cornelia; Soanes; Darren M.; Cornell; Mike; Alam; Intikhab; Swainston; Neil; Smallbone; Kieran;Mendes; Pedro; Kell; Douglas; Paton; Norman";. title = "The SuBliMinaL Toolbox: automating stepsin the reconstruction of metabolic networks";. year = "2011";. journal = "http://journal.imbio.de/article.php?aid=186";. publisher = "University of Bielefeld …,http://journal. imbio. de/index. php? paper_id= 69,*,*
Also in this series,Udo W Lipeck; Bernhard Thalheirn; Tony McEnery; Chris Paice; Iohn Launchbury; Patrick Sansom; IP Bowen; IE Nicholls; Richard Cooper; Kevin Ryan; Richard FE Sutcliffe; Geoffrey Bum; Simon Gay; Mark Ryan; M Nivat; C Rattray; T Rus; G Scollo; Yves Deville; Catriel Beeri; Atsushi Ohori; Dennis E Shasha; Matt Smith; Alan Smaill; Geraint A Wiggins; Norman W Paton; M Howard Williams; DJ Andrews; JF Groote; CA Middelburg; B Thuraisingham; R Sandhu; TC Ting; John T O'Donnell; Kevin Hammond; David Till,The Software Engineering and Knowledgebase Systems (SOFfEKS) Research Group of theDepartment of Computer Science; Concordia University; Canada; organized a workshop onIncompleteness and Uncertainty in Information Systems from October 8-9; 1993 in Montreal.A major aim of the workshop was to bring together researchers who share a concern forissues of incompleteness and uncertainty. The workshop attracted people doingfundamental research and industryoriented research in databases; software engineeringand AI from North America; Europe and Asia. The workshop program featured six invitedtalks and twenty other presentations. The invited speakers were:,*,*,*
I11,NW Paton; J Campin; AA Fernandes,6 Conclusions In this paper; we have proposed a general method for the definition of thesemantics of composite event speciﬁcation languages for active databases. Whereasdifferent operational formalisms have been used in the past for different languages; we haveshown that Dataloglg provides a flexible and convenient declarative framework for definingthe semantics of composite event,*,*,*
Proteomics data representation and management,Norman W Paton; Andrew Jones; Stephen G Oliver,Abstract Proteomics is rapidly evolving into a high-throughput technology; in whichsubstantial studies are conducted on samples from a wide range of physiological;developmental; or pathological conditions. This gives rise to a need for techniques andtechnologies that enable the systematic description and capture of experimental data andmetadata; which will allow for the archiving; sharing; and analysis of proteomic data sets.This chapter identifies the different aspects of an experiment that must be captured; and thederived information that underpins the interpretation of such data.,Encyclopedia of Genetics; Genomics; Proteomics and Bioinformatics,*,*
A model ofyeast glycolysis based on a consistent kinetic characterisation,Kieran Smallbone; Hanan L Messiha; Kathleen M Carroll; Catherine L Winder; Naglis Malys; Warwick B Dunn; Ettore Murabito; Neil Swainston; Joseph O Dada; Farid Khan; Pınar Pir; Evangelos Simeonidis; Irena Spasic; Jill Wishart; Dieter Weichart; Neil W Hayes; Daniel Jameson; David S Broomhead; Stephen G Oliver; Simon J Gaskell; John EG McCarthy; Norman W Paton; Hans V Westerhoff; Douglas B Kell; Pedro Mendes,abstract 54 We present an experimental and computational pipeline for the generation ofkinetic models of 55 metabolism; and demonstrate its application to glycolysis inSaccharomyces cerevisiae. Starting from 56 an approximate mathematical model; weemploy a ''cycle of knowledge''strategy; identifying the 57 steps with most control over flux.Kinetic parameters of the individual isoenzymes within these 58 steps are measuredexperimentally under a standardised set of conditions. Experimental strategies 59 areapplied to establish a set of in vivo concentrations for isoenzymes and metabolites. The dataare 60 integrated into a mathematical model that is used to predict a new set of metaboliteconcentrations 61 and reevaluate the control properties of the system. This bottom-upmodelling study reveals that 62 control over the metabolic network most directly involved …,metabolism,*,*
Web Services Data Access and Integration–The Core (WS-DAI) Specification; Version 1.0,Mike Jackson; Amy Krause; Simon Laws; Susan Malaika; Norman W Paton; Dave Pearson; Oracle Greg Riccardi,Abstract Data resources play a significant role in many applications across multipledomains. Web services provide implementation neutral facilities for describing; invoking andorchestrating collections of networked resources. The OGF (Open Grid Forum) Open GridServices Architecture (OGSA); and its associated specifications; defines consistentinterfaces through web services to components of a grid infrastructure. Both the web andgrid communities stand to benefit from the provision of consistent and agreed web serviceinterfaces for data resources and the systems that manage them. This document presents aspecification for a collection of generic data interfaces developed by the Database Accessand Integration Services (DAIS) Working Group that can be extended to support specifickinds of data resources; such as relational databases; XML repositories; RDF data …,*,*,*
PloS one Volume: 3 ISSN: 1932-6203 ISO Abbreviation: PLoS ONE Publication Date: 2008,Feng Ding; Hong Hua Li; Shengwen Zhang; Nicola M Solomon; Sally A Camper; Pinchas Cohen; Uta Francke,Histone modifications in chromatin regulate gene expression. A transcriptional co-repressorcomplex containing LSD1-CoREST-HDAC1 (termed LCH hereafter for simplicity) repressestranscription by coordinately removing histone modifications associated with transcriptionalactivation. RE1-silencing transcription factor (REST) recruits LCH to the promoters of neuron-specific genes; thereby silencing their transcription in non-neuronal tissues. ZNF198 is amember of a family of MYM-type zinc finger proteins that associate with LCH. Here; we showthat ZNF198-like proteins are required for the repression of E-cadherin (a gene known to berepressed by LSD1); but not REST-responsive genes. ZNF198 binds preferentially to theintact LCH ternary complex; but not its individual subunits. ZNF198-and REST-binding to theLCH complex are mutually exclusive. ZNF198 associates with chromatin independently of …,Detail:,*,*
Norman W. Paton,Tony Griffiths,*,*,*,*
INFORMATION AND so RE TECHNOLOGY,James Miller; Marc Roper; Murray Wood; Andrew Brooks; Chieh-Ying Kan; Xudong He; Neville Churcher; Jack Campin; Norman W Paton; M Howard Williams; Hee Beng Kuan Tan; Tok Wang Ling; Peretz Shoval; M Ancona; Marc H Van Liedekerke; Nicholas M Avouris; Bill C Hardgrave; Narasimhaiah Gorla; Hao-Che Pu; Wei Lu; Jiawei Han; Tzvi Raz; Alan T Yaung; David Livingstone; Bing Wang; Peter Hitchcock; Michael M Pickard; Bradley D Carter; Peter Sawyer; Ian Sommerville; KG van den Berg; PM van den Broek; Filippo Tangorra; Domenico Chiarolla; George S Pavlides; I Gaviotis; D Christodoulakis; Jonathan Bowen; Mike Hinchey; David Garlan; Mike Gordon; Peter Mataga; Pamela Zave; KC Mander; FAC Polack; Samuel H Valentine; K Lano; H Haughton; Susan Stepney; Rosalind Barden; Jonathan P Bowen; Johathan Bowen; B Henderson-Sellers; IR McChesney; Pranay Chaudhuri; John F Roddick; Robert Probert; Kassem Saleh; Hua-Long Yu,*,*,*,*
Angelis; L.; see Tsoumakas; G. 223–242,R Barr; T Griffiths; V Bhat; T Oates; V Shanbhag; C Nicholas; L Chen; S Wang; EA Rundensteiner; RHL Chiang; AHF Laender; EP Lim; A Corral; Y Manolopoulos; Y Theodoridis; M Vassilakopoulos; AS da Silva; J Palmieri Lage; AAA Fernandes; M Golfarelli; V Maniezzo; S Rizzi; PB Golgher; AAA Fernandes; NW Paton; R Barr; D Katsaros; AHF Laender; F Li; Z Liu; EP Lim; WK Ng; F Li; V Maniezzo; Y Manolopoulos; T Tzouramanis; WK Ng; C Nicholas; K Nørvåg; T Oates; AS da Silva; PB Golgher; NW Paton,*,Management (WIDM 2002),*,*
Transactions on Database Systems; Vol. 4 No. 1). Semantic models of data such as SDM (Hammer and McLeod) arose from a need for far richer represen-tations of'r...,PMD Gray; KG Kukarni; NW Paton,*,*,*,*
SCIENTIFIC DATABASES,Maria Zemankova; Wesley W Chu; Alfonso F Cardenas; Ricky K Taira; Amy J Lee; Elke A Rundenstelner; Terence Ft Smith; Jianwen Su; Amr El Abbadi; Divyakant Agrawal; Gustav Alonso; Amitabh Saran; LT Chen; R Drach; M Keating; S Louis; D Rotem; A Shoshani; Maria L Barja; Alvaro AA Fernandes; Norman W Paton; M Howard Williams; Andrew Dlnn,*,*,*,*
Theodore Johnson; AT&T Research Labs; USA Mick Jordan; Sun Microsystems Laboratories; USA Leonid Kalinichenko; Inst for Problems Informatics; Russia Ibrahi...,Alfons Kemper; Jessie B Kennedy; Donald Kossmann; Vijay Kumar; Ruqian Lu; Florian Matthes; U Hamburg; Germany Renee J Miller; Patrick O’Neil; Tamer Ozsu; Norman Paton; Philippe Pucheral; Kotagiri Ramamohanarao; Rajeev Rastogi; Elke A Rundensteiner; Ken Salem; Praveen Seshadri; Kyuseok Shim; YC Tay; Susan Urban; Howard Williams; Longxiang Zhou,*,*,*,*
Program Area Co-Chairs,Malcolm Atkinson; Alfons Kemper; Ken Salem; Christos Faloutsos; Surajit Chaudhuri; Christoph Freytag; Peter Apers; David Bell; Norman Paton,*,*,*,*
Program &airs’ Message,Christos Faloutsos; Christoph Freytag; Alfons Kemper; Norman Paton; Ken Salem,*,*,*,*
EVENT REPORTS (B. Cooper; editor) Report on the 10th International Symposium on Database Programming,G Bierman; C Koch; M Antonioletti; A Krause; NW Paton; A Eisenberg; S Laws; S Malaika; J Melton; D Pearson,[Editor's note: With the exception of the last pages–which would be the back cover of the printedissue–that are not included in this file; it has the same contents as the printed edition. All thearticles are also available individually online and have been put together here for convenienceonly.] SIGMOD OFFICERS; COMMITTEES AND AWARDS...................................................................... 1 EDITOR'S NOTES … SIGMOD Record SIGMOD Recordis a quarterly publication of the Special Interest Group on Management of Data (SIGMOD) ofthe Association for Computing Machinery (ACM). SIGMOD is dedicated to the study;development; and application of database and information technology. SIGMOD Record WebEdition is also freely available online at http://www. sigmod. org/record. SIGMOD Record solicitscontributions of articles; technical notes; reports; and proposals for special sections …,*,*,*
Stimuli and Business Policies as Modelling,Oscar Déiaz; Norman W Paton,*,*,*,*
VESPA: A Benchmark For Vector Spatial Databases Norman W. Paton1; M. Howard Williams; Kosmas Dietrich; Olive Liew; Andrew Dinn and Alan Patrick Departme...,Norman W Paton,Abstract. Facilities for the storage and analysis of large quantities of spatial data areimportant to many applications; and are central to geographic information systems. This hasgiven rise to a range of proposals for spatial data models and software architectures thatallow database systems to be used cleanly and efficiently with spatial data. However;although many spatial database systems have been built; there have been few systematiccomparisons of the functionality or the performance of such systems. This is probably at leastpartly due to the lack of a widely used; standard spatial database benchmark. This paperpresents a benchmark for vector spatial databases that covers a range of typical GISfunctions; and shows how the benchmark has been implemented in two systems: the object-relational database PostgreSQL; and the deductive object-oriented database ROCK & …,*,*,*
A UM L-Based Design Environment for Interactive Applications,Paulo Pinheiro da Silva; Norman W Paton,*,*,*,*
Services for Data Management in Grids,Ann L Chervenak; Arie ShoshaniMalcolm Atkinson; Peter Kunszt; Inderpal Narang; Norman W Paton; Dave Pearson; Arie Shoshani; Paul Watson,Digital data are now fundamental to all branches of science and engineering; they play amajor role in medical research and diagnosis; and underpin business and governmentaldecision processes. Increasingly these data are organised as shared and structuredcollections; which are held in databases; in XML documents and in structured assemblies ofbinary files. Driven by the advances in simulation and sensor technology discussed inChapter [SCIENCE IMPARITIVE]; we find that significant data collections have grown to theextent that multiple terabyte; and soon petabyte sized collections of data will becomeprevalent.The shear size of data sets being generated makes interpretation of the data inany one collection challenging: analysis might demand teraflops of compute power;requiring the access to terabytes of data distributed across millions of binary files and …,*,*,*
Email:{pjb; jessie}@ dcs. napier. ac. uk 3 Department of Computing Science; University of Glasgow; Glasgow G12 8QQ; UK. Email:{jo; pdg; rich}@ dcs. gla. ac. uk,Tony Griffiths; Peter J Barclay; Norman W Paton; Jo McKirdy; Jessie Kennedy; Philip D Gray; Richard Cooper; Carole A Goble; Paulo Pinherio da Silva,*,*,*,*
BioQuery: A Bioinformatics Source Querying Environment,Robert D Stevens; Martin Peim; Norman W Paton; Brian Donnelly,Abstract Formulating and executing queries over distributed; autonomous andheterogeneous resources is an important topic within e-science in general andbioinformatics in particular. Where resources have differing query capabilities and callinterfaces; and heterogeneous representations of the semantics of a domain; formulating asingle query that will work over multiple resources is difficult. In the TAMBIS (TransparentAccess to Multiple Bioinformatics Information Sources) system; an ontology of molecularbiology and bioinformatics is used to give the illusion of a common query interface to diverseresources. The ontology is also central to the query processing and reconciliation ofheterogeneities. The BioQuery project takes TAMBIS onto a new phase; where we willprovide a robust service over commercial middleware provided by our industrial …,*,*,*
Department of Computing and Electrical Engineering; Heriot-Watt University Riccarton; Edinburgh EH14 4AS; Scotland; UK,Maria L Barja; Norman W Paton; Alvaro AA Fernandes; M Howard Williams; Andrew Dinn,*,*,*,*
Systematic screening of yeast kinetic parameters for metabolic models using a text mining toolbox,Irena Spasić; Evangelos Simeonidis; Norman Paton; Douglas Kell,Abstract At the heart of systems biology is a classical inverse problem; which requires theiterative interplay between mathematical/computational simulation of the system of interestand experimental measurements with which the model can be compared. Our goal is todevelop and exploit appropriate methods for modelling metabolism. There are twodistinctive branches in metabolic modelling: qualitative and quantitative. Qualitative (orstructural) models are used to describe the relations between different components.Quantitative descriptions of these relations (eg binding and kinetic constants) are used toparameterise such models and represent dynamic aspects of biological systems (eg kineticbehaviour) in silico. While qualitative models are moderately well known; the new advancesin biotechnology have given rise to an enormous production of quantitative omics …,*,*,*
Metric Evaluation of Interactive System Models,Paulo Pinheiro da Silva; Norman W Paton,Abstract The Unified Modeling Language (UML) has been widely accepted by applicationdevelopers; but not so much by user interface (UI) designers. For this reason; the UnifiedModeling Language for Interactive Systems (UMLi) has been proposed to improve UMLsupport for UI design. UMLi introduces a diagram notation for modeling UI presentation andextends activity diagram notation to describe collaboration between interaction objects anddomain objects. This article demonstrates using design metrics; in a quantitative way; thatUML models that encompass the UI components are more complex than their correspondingmodels without UI components and that UMLi models are significantly structurally;behaviorally and visually less complex than standard UML models when describing thesame set of properties of an interactive system. In terms of models of interactive systems …,*,*,*
Conceptual Modelling of Genomic Information Norman W. Paton1; Shakeel A. Khan2; Andrew Hayes2; Fouzia Moussouni1; Andy Brass2; Karen Eilbeck2; Carole A....,Norman W Paton; Shakeel A Khan; Andrew Hayes; Fouzia Moussouni; Andy Brass; Karen Eilbeck; Carole A Goble; Simon J Hubbard; Stephen G Oliver,Abstract Motivation: Genome sequencing projects are making available complete records ofthe genetic make-up of organisms. These core data sets are themselves complex; andpresent challenges to those who seek to store; analyse and present the information.However; in addition to the sequence data; high throughput experiments are makingavailable distinctive new data sets on protein interactions; the phenotypic consequences ofgene deletions; and on the transcriptome; proteome; and metabolome. The effectivedescription and management of such data is of considerable importance to bioinformatics inthe postgenomic era. The provision of clear and intuitive models of complex information issurprisingly challenging; and this paper presents conceptual models for a range of importantemerging information resources in bioinformatics. It is hoped that these can be of benefit …,*,*,*
Interfaces to Databases (IDS-3),Norman W Paton; Khoa Doan; Oscar Diaz; Arturo Jaime,Abstract This paper presents some experiences in the exploitation of a database interfacedevelopment architecture in which the interface is implemented using the facilities of thedatabase. It is shown how novel interfaces; specifically a multiparadigm query interface anda debugger for an active rule system; can benefit from and exploit the uniform representationof interface and database system concepts as database objects.,*,*,*
BMC genomics Volume: 8 ISSN: 1471-2164 ISO Abbreviation: BMC Genomics Publication Date: 2007,Cornelia Hedeler; Han Min Wong; Michael J Cornell; Intikhab Alam; Darren M Soanes; Magnus Rattray; Simon J Hubbard; Nicholas J Talbot; Stephen G Oliver; Norman W Paton,BACKGROUND: The number of sequenced fungal genomes is ever increasing; with about200 genomes already fully sequenced or in progress. Only a small percentage of thosegenomes have been comprehensively studied; for example using techniques from functionalgenomics. Comparative analysis has proven to be a useful strategy for enhancing ourunderstanding of evolutionary biology and of the less well understood genomes. However;the data required for these analyses tends to be distributed in various heterogeneous datasources; making systematic comparative studies a cumbersome task. Furthermore;comparative analyses benefit from close integration of derived data sets that cluster genesor organisms in a way that eases the expression of requests that clarify points of similarity ordifference between species. DESCRIPTION: To support systematic comparative analyses …,Detail:,*,*
