Querying distributed RDF data sources with SPARQL,Bastian Quilitz; Ulf Leser,Abstract Integrated access to multiple distributed and autonomous RDF data sources is akey challenge for many semantic web applications. As a reaction to this challenge; SPARQL;the W3C Recommendation for an RDF query language; supports querying of multiple RDFgraphs. However; the current standard does not provide transparent query federation; whichmakes query formulation hard and lengthy. Furthermore; current implementations ofSPARQL load all RDF graphs mentioned in a query to the local machine. This usually incursa large overhead in network traffic; and sometimes is simply impossible for technical or legalreasons. To overcome these problems we present DARQ; an engine for federated SPARQLqueries. DARQ provides transparent query access to multiple SPARQL services; ie; it givesthe user the impression to query one single RDF graph despite the real data being …,European Semantic Web Conference,2008,482
The stratosphere platform for big data analytics,Alexander Alexandrov; Rico Bergmann; Stephan Ewen; Johann-Christoph Freytag; Fabian Hueske; Arvid Heise; Odej Kao; Marcus Leich; Ulf Leser; Volker Markl; Felix Naumann; Mathias Peters; Astrid Rheinländer; Matthias J Sax; Sebastian Schelter; Mareike Höger; Kostas Tzoumas; Daniel Warneke,Abstract We present Stratosphere; an open-source software stack for parallel data analysis.Stratosphere brings together a unique set of features that allow the expressive; easy; andefficient programming of analytical applications at very large scale. Stratosphere's featuresinclude “in situ” data processing; a declarative query language; treatment of user-definedfunctions as first-class citizens; automatic program parallelization and optimization; supportfor iterative programs; and a scalable and efficient execution engine. Stratosphere covers avariety of “Big Data” use cases; such as data warehousing; information extraction andintegration; data cleansing; graph analysis; and statistical analysis applications. In thispaper; we present the overall system architecture design decisions; introduce Stratospherethrough example queries; and then dive into the internal workings of the system's …,The VLDB Journal,2014,302
Quality-driven integration of heterogeneous information systems,Felix Naumann; Ulf Leser; Johann Christoph Freytag,*,*,1999,301
Fast and practical indexing and querying of very large graphs,Silke Trißl; Ulf Leser,Abstract Many applications work with graph-structured data. As graphs grow in size;indexing becomes essential to ensure sufficient query performance. We present the GRIPPindex structure (GRaph Indexing based on Pre-and Postorder numbering) for answeringreachability queries in graphs. GRIPP requires only linear time and space. Using GRIPP; wecan answer reachability queries on graphs with 5 million nodes on average in less than 5milliseconds; which is unrivaled by previous methods. We evaluate the performance andscalability of our approach on real and synthetic random and scale-free graphs andcompare our approach to existing indexing schemes. GRIPP is implemented as storedprocedure inside a relational database management system and can therefore very easilybe integrated into existing graph-oriented applications.,Proceedings of the 2007 ACM SIGMOD international conference on Management of data,2007,242
Federated information systems: Concepts; terminology and architectures,Susanne Busse; Ralf-Detlef Kutsche; Ulf Leser; Herbert Weber,Abstract We are currently witnessing the emerging of a new generation of software systems:Federated information systems. Their main characteristic is that they are constructed as anintegrating layer over existing legacy applications and databases. They can be broadlyclassified in three dimensions: the degree of autonomy they allow in integrated components;the degree of heterogeneity between components they can cope with; and whether or notthey support distribution. Whereas the communication and interoperation problem has comeinto a stage of applicable solutions over the past decade; semantic data integration has notbecome similarly clear. This report clarifies definitions and terms in the research area ofintegration of heterogeneous and distributed information systems. It gives classificationcriteria for such systems and particularly defines mediator-based information systems as …,Forschungsberichte des Fachbereichs Informatik,1999,216
Completeness of integrated information sources,Felix Naumann; Johann-Christoph Freytag; Ulf Leser,Abstract For many information domains there are numerous World Wide Web data sources.The sources vary both in their extension and their intension: They represent different real-world entities with possible overlap and provide different attributes of these entities. Mediator-based information systems allow integrated access to such sources by providing a commonschema against which the user can pose queries. Given a query; the mediator mustdetermine which participating sources to access and how to integrate the incoming results.This article describes how to support mediators in their source selection and query planningprocess. We propose three new merge operators; which formalize the integration of multiplesource responses. A completeness model describes the usefulness of a source to answer aquery. The completeness measure incorporates both extensional value (called coverage) …,Information Systems,2004,165
AliBaba: PubMed as a graph,Conrad Plake; Torsten Schiemann; Marcus Pankalla; Jörg Hakenberg; Ulf Leser,Abstract The biomedical literature contains a wealth of information on associations betweenmany different types of objects; such as protein–protein interactions; gene–diseaseassociations and subcellular locations of proteins. When searching such information usingconventional search engines; eg PubMed; users see the data only one-abstract at a timeand 'hidden'in natural language text. AliBaba is an interactive tool for graphicalsummarization of search results. It parses the set of abstracts that fit a PubMed query andpresents extracted information on biomedical objects and their relationships as a graphicalnetwork. AliBaba extracts associations between cells; diseases; drugs; proteins; species andtissues. Several filter options allow for a more focused search. Thus; researchers can graspcomplex networks described in various articles at a glance. Availability: Contact …,Bioinformatics,2006,163
Informationsintegration: Architekturen und Methoden zur Integration verteilter und heterogener Datenquellen,Ulf Leser; Felix Naumann,*,*,2006,157
What makes a gene name? Named entity recognition in the biomedical literature,Ulf Leser; Jörg Hakenberg,Abstract The recognition of biomedical concepts in natural text (named entity recognition;NER) is a key technology for automatic or semi-automatic analysis of textual resources.Precise NER tools are a prerequisite for many applications working on text; such asinformation retrieval; information extraction or document classification. Over the past years;the problem has achieved considerable attention in the bioinformatics community andexperience has shown that NER in the life sciences is a rather difficult problem. Severalsystems and algorithms have been devised and implemented. In this paper; the problemsand resources in NER research are described; the principal algorithms underlying mostsystems sketched; and the current state-of-the-art in the field surveyed.,Briefings in bioinformatics,2005,151
A comprehensive benchmark of kernel methods to extract protein–protein interactions from literature,Domonkos Tikk; Philippe Thomas; Peter Palaga; Jörg Hakenberg; Ulf Leser,The most important way of conveying new findings in biomedical research is scientificpublication. Extraction of protein–protein interactions (PPIs) reported in scientificpublications is one of the core topics of text mining in the life sciences. Recently; a new classof such methods has been proposed-convolution kernels that identify PPIs using deepparses of sentences. However; comparing published results of different PPI extractionmethods is impossible due to the use of different evaluation corpora; different evaluationmetrics; different tuning procedures; etc. In this paper; we study whether the reportedperformance metrics are robust across different corpora and learning settings and whetherthe use of deep parsing actually leads to an increase in extraction quality. Our ultimate goalis to identify the one method that performs best in real-life scenarios; where information …,PLoS computational biology,2010,145
ChemSpot: a hybrid system for chemical named entity recognition,Tim Rocktäschel; Michael Weidlich; Ulf Leser,Abstract Motivation: The accurate identification of chemicals in text is important for manyapplications; including computer-assisted reconstruction of metabolic networks or retrieval ofinformation about substances in drug development. But due to the diversity of namingconventions and traditions for such molecules; this task is highly complex and should besupported by computational tools. Results: We present ChemSpot; a named entityrecognition (NER) tool for identifying mentions of chemicals in natural language texts;including trivial names; drugs; abbreviations; molecular formulas and International Union ofPure and Applied Chemistry entities. Since the different classes of relevant entities haverather different naming characteristics; ChemSpot uses a hybrid approach combining aConditional Random Field with a dictionary. It achieves an F 1 measure of 68.1% on the …,Bioinformatics,2012,143
A flexible framework for integrating annotations from different tools and tagsets,Christian Chiarcos; Stefanie Dipper; Michael Götze; Ulf Leser; Anke Lüdeling; Julia Ritz; Manfred Stede,ABSTRACT. We present a general framework for integrating annotations from different toolsand tag sets. When annotating corpora at multiple linguistic levels; annotators may usedifferent expert tools for different phenomena or types of annotation. These tools employdifferent data models and accompanying approaches to visualization; and they producedifferent output formats. For the purposes of uniformly processing these outputs; wedeveloped a pivot format called PAULA; along with converters to and from tool formats.Different annotations are not only integrated at the level of data format; but are also joinedon the level of conceptual representation. For this purpose; we introduce OLiA; an ontologyof linguistic annotations that mediates between alternative tag sets that cover the same classof linguistic phenomena. All components are integrated in the linguistic information …,Traitement Automatique des Langues,2008,100
A query language for biological networks,Ulf Leser,Abstract Motivation: Many areas of modern biology are concerned with the management;storage; visualization; comparison and analysis of networks; but no appropriate querylanguage for such complex data structures yet exists. Results: We have designed andimplemented the pathway query language (PQL) for querying large protein interaction orpathway databases. PQL is based on a simple graph data model with extensions reflectingproperties of biological objects. Queries match subgraphs in the database based on nodeproperties and paths between nodes. The syntax is easy to learn for anybody familiar withSQL. As an important feature; a query may require a certain structure in the database to existbut return a different subgraph. We have tested PQL queries on networks of up to 16 000nodes and found it to scale very well. Availability: The code is available on request from …,Bioinformatics,2005,97
A hierarchical approach to model web query interfaces for web source integration,Eduard C Dragut; Thomas Kabisch; Clement Yu; Ulf Leser,Abstract Much data in the Web is hidden behind Web query interfaces. In most cases theonly means to" surface" the content of a Web database is by formulating complex queries onsuch interfaces. Applications such as Deep Web crawling and Web database integrationrequire an automatic usage of these interfaces. Therefore; an important problem to beaddressed is the automatic extraction of query interfaces into an appropriate model. Wehypothesize the existence of a set of domain-independent" commonsense design rules" thatguides the creation of Web query interfaces. These rules transform query interfaces intoschema trees. In this paper we describe a Web query interface extraction algorithm; whichcombines HTML tokens and the geometric layout of these tokens within a Web page. Tokensare classified into several classes out of which the most significant ones are text tokens …,Proceedings of the VLDB Endowment,2009,88
Gene mention normalization and interaction extraction with context models and sentence motifs,Jörg Hakenberg; Conrad Plake; Loic Royer; Hendrik Strobelt; Ulf Leser; Michael Schroeder,The goal of text mining is to make the information conveyed in scientific publicationsaccessible to structured search and automatic analysis. Two important subtasks of textmining are entity mention normalization-to identify biomedical objects in text-and extractionof qualified relationships between those objects. We describe a method for identifying genesand relationships between proteins. We present solutions to gene mention normalizationand extraction of protein-protein interactions. For the first task; we identify genes by usingbackground knowledge on each gene; namely annotations related to function; location;disease; and so on. Our approach currently achieves an f-measure of 86.4% on theBioCreative II gene normalization data. For the extraction of protein-protein interactions; wepursue an approach that builds on classical sequence analysis: motifs derived from …,Genome biology,2008,82
BioCreative III interactive task: an overview,Cecilia N Arighi; Phoebe M Roberts; Shashank Agarwal; Sanmitra Bhattacharya; Gianni Cesareni; Andrew Chatr-Aryamontri; Simon Clematide; Pascale Gaudet; Michelle Gwinn Giglio; Ian Harrow; Eva Huala; Martin Krallinger; Ulf Leser; Donghui Li; Feifan Liu; Zhiyong Lu; Lois J Maltais; Naoaki Okazaki; Livia Perfetto; Fabio Rinaldi; Rune Sætre; David Salgado; Padmini Srinivasan; Philippe E Thomas; Luca Toldo; Lynette Hirschman; Cathy H Wu,The BioCreative challenge evaluation is a community-wide effort for evaluating text miningand information extraction systems applied to the biological domain. The biocuratorcommunity; as an active user of biomedical literature; provides a diverse and engaged enduser group for text mining tools. Earlier BioCreative challenges involved many text miningteams in developing basic capabilities relevant to biological curation; but they did notaddress the issues of system usage; insertion into the workflow and adoption by curators.Thus in BioCreative III (BC-III); the InterActive Task (IAT) was introduced to address the utilityand usability of text mining tools for real-life biocuration tasks. To support the aims of the IATin BC-III; involvement of both developers and end users was solicited; and the developmentof a user interface to address the tasks interactively was requested. A User Advisory …,BMC bioinformatics,2011,71
GeneView: a comprehensive semantic search engine for PubMed,Philippe Thomas; Johannes Starlinger; Alexander Vowinkel; Sebastian Arzt; Ulf Leser,Abstract Research results are primarily published in scientific literature and curation effortscannot keep up with the rapid growth of published literature. The plethora of knowledgeremains hidden in large text repositories like MEDLINE. Consequently; life scientists have tospend a great amount of time searching for specific information. The enormous ambiguityamong most names of biomedical objects such as genes; chemicals and diseases oftenproduces too large and unspecific search results. We present GeneView; a semantic searchengine for biomedical knowledge. GeneView is built upon a comprehensively annotatedversion of PubMed abstracts and openly available PubMed Central full texts. This semi-structured representation of biomedical texts enables a number of features extendingclassical search engines. For instance; users may search for entities using unique …,Nucleic acids research,2012,64
Columba: an integrated database of proteins; structures; and annotations,Silke Trissl; Kristian Rother; Heiko Müller; Thomas Steinke; Ina Koch; Robert Preissner; Cornelius Frömmel; Ulf Leser,Structural and functional research often requires the computation of sets of protein structuresbased on certain properties of the proteins; such as sequence features; fold classification; orfunctional annotation. Compiling such sets using current web resources is tedious becausethe necessary data are spread over many different databases. To facilitate this task; we havecreated COLUMBA; an integrated database of annotations of protein structures. COLUMBAcurrently integrates twelve different databases; including PDB; KEGG; Swiss-Prot; CATH;SCOP; the Gene Ontology; and ENZYME. The database can be searched using eitherkeyword search or data source-specific web forms. Users can thus quickly select anddownload PDB entries that; for instance; participate in a particular pathway; are classified ascontaining a certain CATH architecture; are annotated as having a certain molecular …,BMC bioinformatics,2005,62
Relation extraction for drug-drug interactions using ensemble learning,Philippe Thomas; Mariana Neves; Illés Solt; Domonkos Tikk; Ulf Leser,Abstract. We describe our approach for the extraction of drug-drug interactions fromliterature. The proposed method builds majority voting ensembles of contrasting machinelearning methods; which exploit different linguistic feature spaces. We evaluated ourapproach in the context of the DDI Extraction 2011 challenge; where using document-wisecrossvalidation; the best single classifier achieved an F1 of 57.3% and the best ensembleachieved 60.6%. On the held out test set; our best run achieved a F1 of 65.7%.,Training,2011,60
Integrating protein-protein interactions and text mining for protein function prediction,Samira Jaeger; Sylvain Gaudan; Ulf Leser; Dietrich Rebholz-Schuhmann,Functional annotation of proteins remains a challenging task. Currently the scientificliterature serves as the main source for yet uncurated functional annotations; but curationwork is slow and expensive. Automatic techniques that support this work are still lackingreliability. We developed a method to identify conserved protein interaction graphs and topredict missing protein functions from orthologs in these graphs. To enhance the precision ofthe results; we furthermore implemented a procedure that validates all predictions based onfindings reported in the literature. Using this procedure; more than 80% of the GOannotations for proteins with highly conserved orthologs that are available inUniProtKb/Swiss-Prot could be verified automatically. For a subset of proteins we predictednew GO annotations that were not available in UniProtKb/Swiss-Prot. All predictions were …,BMC bioinformatics,2008,59
EDITtoTrEMBL: a distributed approach to high-quality automated protein sequence annotation.,S M√∂ ller; Ulf Leser; Wolfgang Fleischmann; Rolf Apweiler,Abstract SUMMARY: Many databases in molecular biology face the problem that the everincreasing rate of data production can no longer be handled by traditional methods;especially human curation. Therefore; a number of projects are currently investigatingmethods for automated sequence annotation. This paper describes the EBI's approach tothis problem for protein sequences by integration of arbitrary analysis programs into adistributed and highly flexible environment. Our software framework allows an individualtreatment of sequences depending on their particular properties; which is achieved througha high-level description of the preconditions and capabilities of analysing modules. This notonly improves the overall performance of the annotation process; as unnecessary steps areavoided; but also enhances its quality since dependencies between different modules are …,Bioinformatics (Oxford; England),1999,55
Efficiently detecting inclusion dependencies,Jana Bauckmann; Ulf Leser; Felix Naumann; Véronique Tietz,Data sources for data integration often come with spurious schema definitions such asundefined foreign key constraints. Such metadata are important for querying the databaseand for database integration. We present our algorithm SPIDER (single pass inclusiondependency recognition) for detecting inclusion dependencies; as these are theautomatically testable part of a foreign key constraint. For IND detection all pairs of attributesmust be tested. SPIDER solves this task very efficiently by testing all attribute pairs inparallel. It analyzes a 2 GB database in~ 20 min and a 21 GB database in~ 4 h.,Data Engineering; 2007. ICDE 2007. IEEE 23rd International Conference on,2007,54
Search; adapt; and reuse: the future of scientific workflows,Sarah Cohen-Boulakia; Ulf Leser,Abstract Over the last years; a number of scientific workflow management systems (SciWFM)have been brought to a state of maturity that should permit their usage in a production-styleenvironment. This is especially true for the Life Sciences; but SciWFM also attractconsiderable attention in fields like geophysics or climate research. These developments;accompanied by the growing availability of analytical tools wrapped as (web) services; weredriven by a series of very interesting promises: End users will be empowered to developtheir own pipelines; reuse of services will be enhanced by easier integration into customworkflows; time necessary for developing analysis pipelines will decrease; etc. But despiteall efforts; SciWFM have not yet found widespread acceptance in their intended audience. Inthis paper; we argue that a wider adoption of SciWFM will only be achieved if the focus of …,ACM SIGMOD Record,2011,53
Implications for molecular mechanisms of glycoprotein hormone receptors using a new sequence-structure-function analysis resource,Gunnar Kleinau; Mara Brehm; Urs Wiedemann; Dirk Labudde; Ulf Leser; Gerd Krause,Abstract Comparison between wild-type and mutated glycoprotein hormone receptors(GPHRs); TSH receptor; FSH receptor; and LH-chorionic gonadotropin receptor isestablished to identify determinants involved in molecular activation mechanism. The basicaims of the current work are 1) the discrimination of receptor phenotypes according to thedifferences between activity states they represent; 2) the assignment of classifiedphenotypes to three-dimensional structural positions to reveal 3) functional-structural hotspots and 4) interrelations between determinants that are responsible for correspondingactivity states. Because it is hard to survey the vast amount of pathogenic and site-directedmutations at GPHRs and to improve an almost isolated consideration of individual pointmutations; we present a system for systematic and diversified sequence-structure-function …,Molecular Endocrinology,2007,53
Mining phenotypes for gene function prediction,Philip Groth; Bertram Weiss; Hans-Dieter Pohlenz; Ulf Leser,Health and disease of organisms are reflected in their phenotypes. Often; a geneticcomponent to a disease is discovered only after clearly defining its phenotype. In the pastyears; many technologies to systematically generate phenotypes in a high-throughputmanner; such as RNA interference or gene knock-out; have been developed and used todecipher functions for genes. However; there have been relatively few efforts to make use ofphenotype data beyond the single genotype-phenotype relationships. We present results ona study where we use a large set of phenotype data–in textual form–to predict geneannotation. To this end; we use text clustering to group genes based on their phenotypedescriptions. We show that these clusters correlate well with several indicators for biologicalcoherence in gene groups; such as functional annotations from the Gene Ontology (GO) …,BMC bioinformatics,2008,52
Adapters; shims; and glue—service interoperability for in silico experiments,Uwe Radetzki; Ulf Leser; SC Schulze-Rauschenbach; Jörg Zimmermann; Jens Lüssem; Thomas Bode; Armin B Cremers,Abstract Motivation: Computationally; in silico experiments in biology are workflowsdescribing the collaboration of people; data and methods. The Grid and Web services areproposed to be the next generation infrastructure supporting the deployment ofbioinformatics workflows. But the growing number of autonomous and heterogeneousservices pose challenges to the used middleware wrt composition; ie discovery andinteroperability of services required within in silico experiments. In the IRIS project; wehandle the problem of service interoperability by a semi-automatic procedure for identifyingand placing customizable adapters into workflows built by service composition. Results: Weshow the effectiveness and robustness of the software-aided composition procedure by acase study in the field of life science. In this study we combine different database services …,Bioinformatics,2006,50
LLL’05 challenge: Genic interaction extraction-identification of language patterns based on alignment and finite state automata,Jörg Hakenberg; Conrad Plake; Ulf Leser; Harald Kirsch; Dietrich Rebholz-Schuhmann,Abstract We present a system for the identification of syntax patterns describing interactionsbetween genes and proteins in scientific text. The system uses sequence alignmentsapplied to sentences annotated with interactions and syntactical information (part-of-speech); as well as finite state automata optimized with a genetic algorithm. Both methodsidentified syntactical patterns that are generalizations of textual representations ofagenttarget relations. We match the generated patterns against arbitrary text to extractinteractions and their respective partners. Our best system uses finite state automataoptimized with a genetic algorithm; and scored an F1-measure of 51.8% on the LLL'05evaluation set.,Proceedings of the 4th Learning Language in Logic workshop (LLL05),2005,48
Ras-mediated deregulation of the circadian clock in cancer,Angela Relógio; Philippe Thomas; Paula Medina-Pérez; Silke Reischl; Sander Bervoets; Ewa Gloc; Pamela Riemer; Shila Mang-Fatehi; Bert Maier; Reinhold Schäfer; Ulf Leser; Hanspeter Herzel; Achim Kramer; Christine Sers,Circadian rhythms are essential to the temporal regulation of molecular processes in livingsystems and as such to life itself. Deregulation of these rhythms leads to failures in biologicalprocesses and eventually to the manifestation of pathological phenotypes including cancer.To address the questions as to what are the elicitors of a disrupted clock in cancer; weapplied a systems biology approach to correlate experimental; bioinformatics and modellingdata from several cell line models for colorectal and skin cancer. We found strong and weakcircadian oscillators within the same type of cancer and identified a set of genes; whichallows the discrimination between the two oscillator-types. Among those genes are IFNGR2;PITX2; RFWD2; PPARγ; LOXL2; Rab6 and SPARC; all involved in cancer-related pathways.Using a bioinformatics approach; we extended the core-clock network and present its …,PLoS genetics,2014,47
Dynamiccloudsim: Simulating heterogeneity in computational clouds,Marc Bux; Ulf Leser,Abstract Simulation has become a commonly employed first step in evaluating novelapproaches towards resource allocation and task scheduling on distributed architectures.However; existing simulators fall short in their modeling of the instability common to sharedcomputational infrastructure; such as public clouds. In this work; we presentDynamicCloudSim which extends the popular simulation toolkit CloudSim with severalfactors of instability; including inhomogeneity and dynamic changes of performance atruntime as well as failures during task execution. As a validation of the introducedfunctionality; we simulate the impact of instability on scientific workflow scheduling byassessing and comparing the performance of four schedulers in the course of severalexperiments both in simulation and on real cloud infrastructure. Results indicate that our …,Future Generation Computer Systems,2015,45
Optimizing syntax patterns for discovering protein-protein interactions,Conrad Plake; Jörg Hakenberg; Ulf Leser,Abstract We propose a method for automated extraction of protein-protein interactions fromscientific text. Our system matches sentences against syntax patterns typically describingprotein interactions. We define a set of 22 patterns; each a regular expression consisting ofanchor positions and parameterizable constraints. This small set is then refined andoptimized using a genetic algorithm on a training set. No heuristic definitions are necessary;and the final pattern set can be generated completely without manual curation. Our methodcan be applied to any syntax pattern-based protein-protein interaction system and thuscomplements related work on building comprehensive sets of such patterns. The applicationof different fitness-functions during evolution provides an easy way to tune the system eithertoward precision; recall; or f-measure. We evaluate our system on two samples; one …,Proceedings of the 2005 ACM symposium on Applied computing,2005,45
Systematic feature evaluation for gene name recognition,Jörg Hakenberg; Steffen Bickel; Conrad Plake; Ulf Brefeld; Hagen Zahn; Lukas Faulstich; Ulf Leser; Tobias Scheffer,In task 1A of the BioCreAtIvE evaluation; systems had to be devised that recognize wordsand phrases forming gene or protein names in natural language sentences. We approachthis problem by building a word classification system based on a sliding window approachwith a Support Vector Machine; combined with a pattern-based post-processing for therecognition of phrases. The performance of such a system crucially depends on the type offeatures chosen for consideration by the classification method; such as pre-or postfixes;character n-grams; patterns of capitalization; or classification of preceding or followingwords. We present a systematic approach to evaluate the performance of different featuresets based on recursive feature elimination; RFE. Based on a systematic reduction of thenumber of features used by the system; we can quantify the impact of different feature sets …,BMC bioinformatics,2005,44
Finding kinetic parameters using text mining,Jörg Hakenberg; Sebastian Schmeier; Axel Kowald; Edda Klipp; Ulf Leser,The mathematical modeling and description of complex biological processes has becomemore and more important over the last years. Systems biology aims at the computationalsimulation of complex systems; up to whole cell simulations. An essential part focuses onsolving a large number of parameterized differential equations. However; measuring thoseparameters is an expensive task; and finding them in the literature is very laborious. Wedeveloped a text mining system that supports researchers in their search for experimentallyobtained parameters for kinetic models. Our system classifies full text documents regardingthe question whether or not they contain appropriate data using a support vector machine.We evaluated our approach on a manually tagged corpus of 800 documents and found thatit outperforms keyword searches in abstracts by a factor of five in terms of precision.,Omics: a journal of integrative biology,2004,44
FRESCO: Referential compression of highly similar sequences,Sebastian Wandelt; Ulf Leser,In many applications; sets of similar texts or sequences are of high importance. Prominentexamples are revision histories of documents or genomic sequences. Modern high-throughput sequencing technologies are able to generate DNA sequences at an ever-increasing rate. In parallel to the decreasing experimental time and cost necessary toproduce DNA sequences; computational requirements for analysis and storage of thesequences are steeply increasing. Compression is a key technology to deal with thischallenge. Recently; referential compression schemes; storing only the differences betweena to-be-compressed input and a known reference sequence; gained a lot of interest in thisfield. In this paper; we propose a general open-source framework to compress largeamounts of biological sequence data called Framework for REferential Sequence …,IEEE/ACM Transactions on Computational Biology and Bioinformatics,2013,42
A machine learning approach to foreign key discovery.,Alexandra Rostin; Oliver Albrecht; Jana Bauckmann; Felix Naumann; Ulf Leser,ABSTRACT We study the problem of automatically discovering semantic associationsbetween schema elements; namely foreign keys. This problem is important in allapplications where data sets need to be integrated that are structured in tables but withoutexplicit foreign key constraints. If such constraints could be recovered automatically;querying and integrating such databases would become much easier. Clearly; one may findcandidates for foreign key constraints in a given database instance by computing allinclusion dependencies (IND) between attributes. However; this set usually contains manyfalse positives due to spurious set inclusions. We present a machine learning approach totackle this problem. We first compute all INDs of a given schema and let each be judged by abinary classification algorithm using a small set of features that can be derived efficiently …,WebDB,2009,42
WBI-DDI: drug-drug interaction extraction using majority voting,Philippe Thomas; Mariana Neves; Tim Rocktäschel; Ulf Leser,Abstract This work describes the participation of the WBI-DDI team on the SemEval 2013–Task 9.2 DDI extraction challenge. The task consisted of extracting interactions betweenpairs of drugs from two collections of documents (DrugBank and MEDLINE) and theirclassification into four subtypes: advise; effect; mechanism; and int. We developed a two-step approach in which pairs are initially extracted using ensembles of up to five differentclassifiers and then relabeled to one of the four categories. Our approach achieved thesecond rank in the DDI competition. For interaction detection we achieved F1 measuresranging from 73% to almost 76% depending on the run. These results are on par or evenhigher than the performance estimation on the training dataset. When considering the fourinteraction subtypes we achieved an F1 measure of 60.9%.,Second Joint Conference on Lexical and Computational Semantics (* SEM); Volume 2: Proceedings of the Seventh International Workshop on Semantic Evaluation (SemEval 2013),2013,39
Regular path queries on large graphs,André Koschmieder; Ulf Leser,Abstract The significance of regular path queries (RPQs) on graph-like data structures hasgrown steadily over the past decade. RPQs are; often in restricted forms; part of graph-oriented query languages such as XQuery/XPath and SPARQL; and have applications inareas such as semantic; social; and biomedical networks. However; existing systems forevaluating RPQs are restricted either in the type of the graph (eg; only trees); the type ofregular expressions (eg; only single steps); and/or the size of the graphs they can handle.No method has yet been developed that would be capable of efficiently evaluating generalRPQs on large graphs; ie; with millions of nodes/edges. We present a novel approach foranswering RPQs on large graphs. Our method exploits the fact that not all labels in a graphare equally frequent. We devise an algorithm which decomposes an RPQ into a series of …,International Conference on Scientific and Statistical Database Management,2012,39
Meteor/sopremo: An extensible query language and operator model,Arvid Heise; Astrid Rheinländer; Marcus Leich; Ulf Leser; Felix Naumann,ABSTRACT Recently; quite a few query and scripting languages for Map-Reduce-basedsystems have been developed to ease formulating complex data analysis tasks. However;existing tools mainly provide basic operators for rather simple analyses; such asaggregating or filtering. Analytic functionality for advanced applications; such as datacleansing or information extraction can only be embedded in user-defined functions wherethe semantics is hidden from the query compiler and optimizer. In this paper; we present alanguage that treats application-specific functions as first-class operators; so that operatorsemantics can be evaluated and exploited for optimization at compile time. We presentSopremo; a semantically rich operator model; and Meteor; an extensible query languagethat is grounded in Sopremo. Sopremo also provides a programming framework that …,Workshop on End-to-end Management of Big Data; Istanbul; Turkey,2012,38
A proposal for a standard CORBA interface for genome maps.,Emmanuel Barillot; Ulf Leser; Philip Lijnzaad; Christophe Cussat-Blanc; Kim Jungfer; Frédéric Guyon; Guy Vaysseix; Carsten Helgesen; P Rodriguez-Tom√©,Abstract MOTIVATION: The scientific community urgently needs to standardize the exchangeof biological data. This is helped by the use of a common protocol and the definition ofshared data structures. We have based our standardization work on CORBA; a technologythat has become a standard in the past years and allows interoperability between distributedobjects. RESULTS: We have defined an IDL specification for genome maps and present it tothe scientific community. We have implemented CORBA servers based on this IDL todistribute RHdb and HuGeMap maps. The IDL will co-evolve with the needs of the mappingcommunity. AVAILABILITY: The standard IDL for genome maps is available at http://corba.ebi. ac. uk/RHdb/EUCORBA/MapIDL. htm l. The IORs to browse maps from Infobiogen andEBI are at http://www. infobiogen. fr/services/Hugemap/IOR and http://corba. ebi. ac. uk …,Bioinformatics (Oxford; England),1999,38
Parallelization in scientific workflow management systems,Marc Bux; Ulf Leser,Abstract: Over the last two decades; scientific workflow management systems (SWfMS) haveemerged as a means to facilitate the design; execution; and monitoring of reusable scientificdata processing pipelines. At the same time; the amounts of data generated in various areasof science outpaced enhancements in computational power and storage capabilities. This isespecially true for the life sciences; where new technologies increased the sequencingthroughput from kilobytes to terabytes per day. This trend requires current SWfMS to adapt:Native support for parallel workflow execution must be provided to increase performance;dynamically scalable" pay-per-use" compute infrastructures have to be integrated todiminish hardware costs; adaptive scheduling of workflows in distributed computeenvironments is required to optimize resource utilization. In this survey we give an …,arXiv preprint arXiv:1303.7195,2013,36
Mining for patterns in contradictory data,Heiko Müller; Ulf Leser; Johann-Christoph Freytag,*,Proceedings of the 2004 international workshop on Information quality in information systems,2004,35
Deep web integration with visqi,Thomas Kabisch; Eduard C Dragut; Clement Yu; Ulf Leser,Abstract In this paper; we present VisQI (VISual Query interface Integration system); a DeepWeb integration system. VisQI is capable of (1) transforming Web query interfaces intohierarchically structured representations;(2) of classifying them into application domains and(3) of matching the elements of different interfaces. Thus VisQI contains solutions for themajor challenges in building Deep Web integration systems.,Proceedings of the VLDB Endowment,2010,33
Cross talk between Wnt/β-catenin and Irf8 in leukemia progression and drug resistance,Marina Scheller; Jörg Schönheit; Karin Zimmermann; Ulf Leser; Frank Rosenbauer; Achim Leutz,Progression and disease relapse of chronic myeloid leukemia (CML) depends on leukemia-initiating cells (LIC) that resist treatment. Using mouse genetics and a BCR-ABL model ofCML; we observed cross talk between Wnt/β-catenin signaling and the interferon-regulatoryfactor 8 (Irf8). In normal hematopoiesis; activation of β-catenin results in up-regulation of Irf8;which in turn limits oncogenic β-catenin functions. Self-renewal and myeloproliferationbecome dependent on β-catenin in Irf8-deficient animals that develop a CML-like disease.Combined Irf8 deletion and constitutive β-catenin activation result in progression of CML intofatal blast crisis; elevated leukemic potential of BCR-ABL–induced LICs; and Imatinibresistance. Interestingly; activated β-catenin enhances a preexisting Irf8-deficient genesignature; identifying β-catenin as an amplifier of progression-specific gene regulation in …,Journal of Experimental Medicine,2013,32
Similarity search for scientific workflows,Johannes Starlinger; Bryan Brancotte; Sarah Cohen-Boulakia; Ulf Leser,Abstract With the increasing popularity of scientific workflows; public repositories are gainingimportance as a means to share; find; and reuse such workflows. As the sizes of theserepositories grow; methods to compare the scientific workflows stored in them become anecessity; for instance; to allow duplicate detection or similarity search. Scientific workflowsare complex objects; and their comparison entails a number of distinct steps from comparingatomic elements to comparison of the workflows as a whole. Various studies haveimplemented methods for scientific workflow comparison and came up with oftencontradicting conclusions upon which algorithms work best. Comparing these results iscumbersome; as the original studies mixed different approaches for different steps and useddifferent evaluation data and metrics. We contribute to the field (i) by disecting each …,Proceedings of the VLDB Endowment,2014,31
Trends in genome compression,Sebastian Wandelt; Marc Bux; Ulf Leser,Technological advancements in high throughput sequencing have led to a tremendousincrease in the amount of genomic data produced. With the cost being down to 2;000 USDfor a single human genome; sequencing dozens of individuals is an undertaking that isfeasible even for a smaller projects or organizations established. However; generating thesequence is only one issue; another one is storing; managing; and analyzing it. These tasksbecome more and more challenging due to the sheer size of the data sets and areincreasingly considered to be the major bottlenecks in larger genome projects. One possiblecountermeasure is to compress the data; compression reduces costs in terms of requiringless hard disk storage and in terms of requiring less bandwidth if data is shipped to largecompute clusters for parallel analysis. Accordingly; sequence compression has recently …,Current Bioinformatics,2014,30
RCSI: Scalable similarity search in thousand (s) of genomes,Sebastian Wandelt; Johannes Starlinger; Marc Bux; Ulf Leser,Abstract Until recently; genomics has concentrated on comparing sequences betweenspecies. However; due to the sharply falling cost of sequencing technology; studies ofpopulations of individuals of the same species are now feasible and promise advances inareas such as personalized medicine and treatment of genetic diseases. A core operation insuch studies is read mapping; ie; finding all parts of a set of genomes which are within editdistance k to a given query sequence (k-approximate search). To achieve sufficient speed;current algorithms solve this problem only for one to-be-searched genome and computeonly approximate solutions; ie; they miss some k-approximate occurrences. We presentRCSI; Referentially Compressed Search Index; which scales to a thousand genomes andcomputes the exact answer. It exploits the fact that genomes of different individuals of the …,Proceedings of the VLDB Endowment,2013,30
CPU and cache efficient management of memory-resident databases,Holger Pirk; Florian Funke; Martin Grund; Thomas Neumann; Ulf Leser; Stefan Manegold; Alfons Kemper; Martin Kersten,Memory-Resident Database Management Systems (MRDBMS) have to be optimized for tworesources: CPU cycles and memory bandwidth. To optimize for bandwidth in mixedOLTP/OLAP scenarios; the hybrid or Partially Decomposed Storage Model (PDSM) hasbeen proposed. However; in current implementations; bandwidth savings achieved bypartial decomposition come at increased CPU costs. To achieve the aspired bandwidthsavings without sacrificing CPU efficiency; we combine partially decomposed storage withJust-in-Time (JiT) compilation of queries; thus eliminating CPU inefficient function calls.Since existing cost based optimization components are not designed for JiT-compiled queryexecution; we also develop a novel approach to cost modeling and subsequent storagelayout optimization. Our evaluation shows that the JiT-based processor maintains the …,Data Engineering (ICDE); 2013 IEEE 29th International Conference on,2013,30
A survey on annotation tools for the biomedical literature,Mariana Neves; Ulf Leser,Abstract New approaches to biomedical text mining crucially depend on the existence ofcomprehensive annotated corpora. Such corpora; commonly called gold standards; areimportant for learning patterns or models during the training phase; for evaluating andcomparing the performance of algorithms and also for better understanding the informationsought for by means of examples. Gold standards depend on human understanding andmanual annotation of natural language text. This process is very time-consuming andexpensive because it requires high intellectual effort from domain experts. Accordingly; thelack of gold standards is considered as one of the main bottlenecks for developing novel textmining methods. This situation led the development of tools that support humans inannotating texts. Such tools should be intuitive to use; should support a range of different …,Briefings in bioinformatics,2012,30
Selecting materialized views for RDF data,Roger Castillo; Ulf Leser,Abstract In the design of a relational database; the administrator has to decide; given a fixedor estimated workload; which indexes should be created. This so called index selectionproblem is an non-trivial optimization problem in relational databases. In this paper wedescribe a novel approach for index selection on RDF data sets. We propose an algorithm toautomatically suggest a set of indexes as materialized views based on a workload ofSPARQL queries. The selected set of indexes aims to decrease the cost of the workload. Weprovide a cost model to estimate the potential impact of candidate indexes on queryperformance and an algorithm to select an optimal set of indexes. This algorithm may beintegrated into an existing SPARQL query engine. We experimentally evaluate our approachon a standard query processor. We claim that our approach is the first comprehensive …,International Conference on Web Engineering,2010,30
High-performance information extraction with AliBaba,Peter Palaga; Long Nguyen; Ulf Leser; Jörg Hakenberg,Abstract A wealth of information is available only in web pages; patents; publications etc.Extracting information from such sources is challenging; both due to the typically complexlanguage processing steps required and to the potentially large number of texts that need tobe analyzed. Furthermore; integrating extracted data with other sources of knowledge oftenis mandatory for subsequent analysis. In this demo; we present the AliBaba system forscalable information extraction from biomedical documents. Unlike many other systems;AliBaba performs both entity extraction and relationship extraction and graphically visualizesthe resulting network of inter-connected objects. It leverages the PubMed search engine forselection of relevant documents. The technical novelty of AliBaba is twofold:(a) its ability toautomatically learn language patterns for relationship extraction without an annotated …,Proceedings of the 12th International Conference on Extending Database Technology: Advances in Database Technology,2009,29
Completeness of information sources,Felix Naumann; Johann-Christoph Freytag; Ulf Leser,Information quality plays a crucial role in every application that integrates data fromautonomous sources. However; information quality is hard to measure and complex toconsider for the tasks of information integration; even if the integrating sources cooperate.We present a systematic and formal approach to the measurement of information quality andthe combination of such measurements for information integration. Our approach is basedon a value model that incorporates both extensional value (coverage) and intensional value(density) of information. For both aspects we provide merge functions for adequately scoringintegrated results. Also; we combine the two criteria to an overall completeness criterion thatformalizes the intuitive notion of completeness of query results. This completeness measureis a valuable tool to assess source size and to predict result sizes of queries in integrated …,*,2003,29
Columba: multidimensional data integration of protein annotations,Kristian Rother; Heiko Müller; Silke Trissl; Ina Koch; Thomas Steinke; Robert Preissner; Cornelius Frömmel; Ulf Leser,Abstract We present COLUMBA; an integrated database of protein annotations. COLUMBAis centered around proteins whose structure has been resolved and adds as muchannotations as possible to those proteins; describing their proper-ties such as function;sequence; classification; textual description; participation in pathways; etc. Annotations areextracted from seven (soon eleven) external data sources. In this paper we describe themotivation for building COLUMBA; its integrational architecture and the software tools wedeveloped for the integrated data sources and keeping COLUMBA up-to-date. We putspecial focus on two aspects: First; COLUMBA does not try to remove redundancies andoverlaps in data sources; but views each data source as a proper dimension describing aprotein. We explain the advantages of this approach compared to a tighter semantic …,International Workshop on Data Integration in the Life Sciences,2004,28
Query planning with information quality bounds,Ulf Leser; Felix Naumann,Abstract Query planning for information integration using a local-as-view approach isexponential in the size of the user query. Furthermore; it may generate an exponentialnumber of plans; many of which will produce results of very poor quality. We propose to useinformation quality reasoning to speed up query planning. We construct tight upper qualitybounds for a branch & bound algorithm. The algorithm uses these quality scores to filter outnon-promising plans early on. Experiments show that this approach dramatically improvesplanning time without compromising the quality of the result.,*,2001,28
Data management challenges in next generation sequencing,Sebastian Wandelt; Astrid Rheinländer; Marc Bux; Lisa Thalheim; Berit Haldemann; Ulf Leser,Abstract Since the early days of the Human Genome Project; data management has beenrecognized as a key challenge for modern molecular biology research. By the end of thenineties; technologies had been established that adequately supported most ongoingprojects; typically built upon relational database management systems. However; recentyears have seen a dramatic increase in the amount of data produced by typical projects inthis domain. While it took more than ten years; approximately three billion USD; and morethan 200 groups worldwide to assemble the first human genome; today's sequencingmachines produce the same amount of raw data within a week; at a cost of approximately2000 USD; and on a single device. Several national and international projects now deal with(tens of) thousands of genomes; and trends like personalized medicine call for efforts to …,Datenbank-Spektrum,2012,26
Querying ontologies in relational database systems,Silke Trißl; Ulf Leser,Abstract In many areas of life science; such as biology and medicine; ontologies arenowadays commonly used to annotate objects of interest; such as biological samples;clinical pictures; or species in a standardized way. In these applications; an ontology ismerely a structured vocabulary in the form of a tree or a directed acyclic graph of concepts.Typically; ontologies are stored together with the data they annotate in relational databases.Querying such annotations must obey the special semantics encoded in the structure of theontology; ie relationships between terms; which is not possible using standard SQL alone. Inthis paper; we develop a new method for querying DAGs using a pre-computed indexstructure. Our new indexing method extends the pre-/postorder ranking scheme; which hasbeen studied intensively for trees; to DAGs. Using typical queries on ontologies; we …,International Workshop on Data Integration in the Life Sciences,2005,26
Query Planning in Mediator Based Information Systems,Ulf Leser,Information integration has gained new importance since the widespread success of theWorld Wide Web. The simplicity of data publishing on the web and the promises of theemerging eCommerce markets pose a strong incentive for data providers to offer theirservices on the Internet. Due to the exponential growth rate of the number of web sites; usersare already faced with an overwhelming amount of accessible information. Finding thedesired piece of information is difficult and time-consuming due to the inherently chaoticorganisation of the Web. For this reason; information integration services are becomingincreasingly important. The idea of such a service is to offer to a user a single point of accessthat provides him or her ex-actly with the information he or she is interested in. To achievethis goal; the service dynami-cally integrates and customises data from various data …,*,2000,26
Efficiently computing inclusion dependencies for schema discovery,Jana Bauckmann; Ulf Leser; Felix Naumann,Large data integration projects must often cope with undocumented data sources. Schemadiscovery aims at automatically finding structures in such cases. An important class ofrelationships between attributes that can be detected automatically are inclusiondependencies (IND); which provide an excellent basis for guessing foreign key constraints.INDs can be discovered by comparing the sets of distinct values of pairs of attributes. In thispaper we present efficient algorithms for finding unary INDs. We first show that (and why)SQL is not suitable for this task. We then develop two algorithms that compute inclusiondependencies outside of the database. Both are much faster than the SQL-based methods;in fact; for larger schemas they are the only feasible solution. Our experiments show that wecan compute all unary INDs in a schema of 1; 680 attributes with a total database size of …,Data Engineering Workshops; 2006. Proceedings. 22nd International Conference on,2006,25
Molecular event extraction from link grammar parse trees,Jörg Hakenberg; Illés Solt; Domonkos Tikk; Luis Tari; Astrid Rheinländer; Quang Long Ngyuen; Graciela Gonzalez; Ulf Leser,Abstract We present an approach for extracting molecular events from literature based on adeep parser; using in a query language for parse trees. Detected events range from geneexpression to protein localization; and cover a multitude of different entity types; includinggenes/proteins; binding sites; and locations. Furthermore; our approach is capable ofrecognizing negation and the speculative character of extracted statements. We first parsedocuments using Link Grammar (BioLG) and store the parse trees in a database. Events areextracted using a newly developed query language with traverses the BioLG linkagesbetween trigger terms; arguments; and events. The concrete queries are learnt from anannotated corpus. On BioNLP Shared Task data; we achieve an overall F1-measure of29.6%.,Proceedings of the Workshop on Current Trends in Biomedical Natural Language Processing: Shared Task,2009,24
(Almost) hands-off information integration for the life sciences,Ulf Leser; Felix Naumann,Data integration in complex domains; such as the life sciences; involves either manual datacuration; offering highest information quality at highest price; or follows a schema integrationand mapping approach; leading to moderate information quality at a moderate price. Wesuggest a radically differ-ent integration approach; called ALADIN; for the life sciencesapplication domain. The predominant feature of the ALADIN system is an architecture thatallows almost automatic integration of new data sources into the system; ie; it offers data in-tegration at almost no cost. We suggest a novel combination of data and text mining; schemamatching; and duplicate detection to combat the reduction in information quality that seemsinevitable when demanding a high degree of automatism. These heuristics can also lead tothe detection of previously unknown or unseen rela-tionships between objects; thus …,*,2005,24
Challenges in modelling a richly annotated diachronic corpus of German,Stefanie Dipper; Lukas Faulstich; Ulf Leser; Anke Lüdeling,Abstract This paper presents the design and architecture of a diachronic corpus of German.We describe the corpus architecture with a focus on the use and restrictions of XML as thedata exchange and storage format. In our approach; a relational database will supplementthe XML representation to support sophisticated search and presentation facilities. This is areport about ongoing work; the architecture presented here is being developed in a pilotstudy.,Workshop on XML-based richly annotated corpora; Lisbon; Portugal,2004,24
Issues in developing integrated genomic databases and application to the human X chromosome.,Ulf Leser; Hans Lehrach; H Roest Crollius,Abstract MOTIVATION: In the past decade; a vast amount of mapping data has beengenerated on the human X chromosome; without a mechanism which would provide aglobal view of exactly what has been achieved. Large datasets are available electronically;but in heterogeneous formats and with incompatible access modes. In addition;relationships between objects in different datasets are often not specified. RESULTS: Wediscuss the problem of integrating these data into one database and define a number ofrequirements that are vital for any integration approach. We have developed IXDB; theIntegrated X chromosome database; which fulfils those requirements and aims at providinga global view on genomic data at a chromosomal level. IXDB represents a conceptualframework based on identifying; storing and analysing relationships between biological …,Bioinformatics (Oxford; England),1998,24
Adaptive efficient compression of genomes,Sebastian Wandelt; Ulf Leser,Modern high-throughput sequencing technologies are able to generate DNA sequences atan ever increasing rate. In parallel to the decreasing experimental time and cost necessaryto produce DNA sequences; computational requirements for analysis and storage of thesequences are steeply increasing. Compression is a key technology to deal with thischallenge. Recently; referential compression schemes; storing only the differences betweena to-be-compressed input and a known reference sequence; gained a lot of interest in thisfield. However; memory requirements of the current algorithms are high and run times oftenare slow. In this paper; we propose an adaptive; parallel and highly efficient referentialsequence compression method which allows fine-tuning of the trade-off between requiredmemory and compression speed. When using 12 MB of memory; our method is for human …,Algorithms for Molecular Biology,2012,23
Graph-based concept identification and disambiguation for enterprise search,Falk Brauer; Michael Huber; Gregor Hackenbroich; Ulf Leser; Felix Naumann; Wojciech M Barczynski,Abstract Enterprise Search (ES) is different from traditional IR due to a number of reasons;among which the high level of ambiguity of terms in queries and documents and existence ofgraph-structured enterprise data (ontologies) that describe the concepts of interest and theirrelationships to each other; are the most important ones. Our method identifies conceptsfrom the enterprise ontology in the query and corpus. We propose a ranking scheme forontology sub-graphs on top of approximately matched token q-grams. The rankingleverages the graph-structure of the ontology to incorporate not explicitly mentionedconcepts. It improves previous solutions by using a fine-grained ranking function that isspecifically designed to cope with high levels of ambiguity. This method is able to capturemuch more of the semantics of queries and documents than previous techniques. We …,Proceedings of the 19th international conference on World wide web,2010,23
High-Precision Function Prediction using Conserved Interactions.,Samira Jaeger; Ulf Leser,Abstract: The recent availability of large data sets of protein-protein-interactions (PPIs) fromvarious species offers new opportunities for functional genomics and proteomics. Wedescribe a method for exploiting conserved and connected subgraphs (CCSs) in the PPInetworks of multiple species for the prediction of protein function. Structural conservation iscombined with functional conservation using a GeneOntologybased scoring scheme. Weapplied our method to the PPI networks of five species; ie; E. coli; D. melanogaster; M.musculus; H. sapiens and S. cerevisiae. We detected surprisingly large CCSs for groups ofthree species but not beyond. A manual analysis of the biological coherence of exemplarysubgraphs strongly supports a close relationship between structural and functionalconservation. Based on this observation; we devised an algorithm for function prediction …,German Conference on Bioinformatics,2007,23
A detailed error analysis of 13 kernel methods for protein-protein interaction extraction,Domonkos Tikk; Illés Solt; Philippe Thomas; Ulf Leser,Kernel-based classification is the current state-of-the-art for extracting pairs of interactingproteins (PPIs) from free text. Various proposals have been put forward; which divergeespecially in the specific kernel function; the type of input representation; and the featuresets. These proposals are regularly compared to each other regarding their overallperformance on different gold standard corpora; but little is known about their respectiveperformance on the instance level. We report on a detailed analysis of the sharedcharacteristics and the differences between 13 current methods using five PPI corpora. Weidentified a large number of rather difficult (misclassified by most methods) and easy(correctly classified by most methods) PPIs. We show that kernels using the same inputrepresentation perform similarly on these pairs and that building ensembles using …,BMC bioinformatics,2013,22
WBI-NER: The impact of domain-specific features on the performance of identifying and classifying mentions of drugs,Tim Rocktäschel; Torsten Huber; Michael Weidlich; Ulf Leser,Abstract Named entity recognition (NER) systems are often based on machine learningtechniques to reduce the labor-intensive development of hand-crafted extraction rules anddomain-dependent dictionaries. Nevertheless; time-consuming feature engineering is oftenneeded to achieve state-of-the-art performance. In this study; we investigate the impact ofsuch domain-specific features on the performance of recognizing and classifying mentionsof pharmacological substances. We compare the performance of a system based on generalfeatures; which have been successfully applied to a wide range of NER tasks; with a systemthat additionally uses features generated from the output of an existing chemical NER tooland a collection of domain-specific resources. We demonstrate that acceptable results canbe achieved with the former system. Still; our experiments show that using domain …,Second Joint Conference on Lexical and Computational Semantics (* SEM); Volume 2: Proceedings of the Seventh International Workshop on Semantic Evaluation (SemEval 2013),2013,22
Discovering conditional inclusion dependencies,Jana Bauckmann; Ziawasch Abedjan; Ulf Leser; Heiko Müller; Felix Naumann,Abstract Data dependencies are used to improve the quality of a database schema; tooptimize queries; and to ensure consistency in a database. Conditional dependencies havebeen introduced to analyze and improve data quality. A conditional dependency is adependency with a limited scope defined by conditions over one or more attributes. Only thematching part of the instance must adhere to the dependency. In this paper we focus onconditional inclusion dependencies (CINDs). We generalize the definition of CINDs;distinguishing covering and completeness conditions. We present a new use case for suchCINDs showing their value for solving complex data quality tasks. Further; we proposeefficient algorithms that identify covering and completeness conditions conforming to givenquality thresholds. Our algorithms choose not only the condition values but also the …,Proceedings of the 21st ACM international conference on Information and knowledge management,2012,21
Combining Heterogeneous Data Sources through Query Correspondence Assertions.,Ulf Leser,1. ABSTRACT The WWW today offers free access to a wealth of heterogeneous datasources. Combining related data from different sources in a comfortable and automaticfashion is not possible. We present our approach to this problem that is based on adeclarative representation of the content of heterogeneous data sources with respect to aglobal schema. We describe our language to express these correspondences and give thealgorithm that uses them to answer global queries.,Workshop on Web Information and Data Management,1998,21
Annotating and evaluating text for stem cell research,Mariana Neves; Alexander Damaschun; Andreas Kurtz; Ulf Leser,Abstract The regeneration of vital organs and tissues remains one of the biggest medicalchallenges. However; the use of embryonic stem cells and induced pluripotent stem cellsallows novel replacement strategies. The CellFinder project aims to create a stem cell datarepository by linking information from existing public databases and by performing textmining on the research literature. We present the first version of our corpus which iscomposed of 10 full text documents containing more than 2;100 sentences; 65;000 tokensand 5;200 annotations for entities. The corpus has been annotated with six types of entities(anatomical parts; cell components; cell lines; cell types; genes/protein and species) with anoverall inter-annotator agreement around 80%. Preliminary results using baseline methodsbased on freely available terminologies and systems have returned a recall which ranges …,Proceedings of the Third Workshop on Building and Evaluation Resources for Biomedical Text Mining (BioTxtM 2012) at Language Resources and Evaluation (LREC). Istanbul; Turkey,2012,20
Tools for managing and analyzing microarray data,André Koschmieder; Karin Zimmermann; Silke Trißl; Thomas Stoltmann; Ulf Leser,Abstract The microarray-based analysis of gene expression has become a workhorse forbiomedical research. Managing the amount and diversity of data that such experimentsproduce is a task that must be supported by appropriate software tools; which led to thecreation of literally hundreds of systems. In consequence; choosing the right tool for a givenproject is difficult even for the expert. We report on the results of a survey encompassing 78of such tools; of which 22 were inspected in detail and seven were tested hands-on. Wereport on our experiences with a focus on completeness of functionality; ease-of-use; andnecessary effort for installation and maintenance. Thereby; our survey provides a valuableguideline for any project considering the use of a microarray data management system. Itreveals which tasks are covered by mature tools and also shows that important …,Briefings in bioinformatics,2011,20
RDFMatView: Idexing RDF Data for SPARQL Queries,Roger Castillo; Christian Rothe; Ulf Leser,Abstract. The Semantic Web as an evolution of the World Wide Web aims to create auniversal medium for the exchange of semantically described data. The idea of representingthis information by means of directed labelled graphs; RDF; has been widely accepted bythe scientific community. However querying RDF data sets to find the desired informationoften is highly time consuming due to the number of comparisons that are needed. In thisarticle we propose indexes on RDF to reduce the search space and the SPARQL queryprocessing time. Our approach is based on materialized queries; ie; precomputed querypatterns and their occurrences in the data sets. We provide a formal definition ofRDFMatView indexes for SPARQL queries; a cost model to evaluate their potential impacton query performance; and a rewriting algorithm to use indexes in SPARQL queries. We …,*,2010,20
Phenoclustering: online mining of cross-species phenotypes,Philip Groth; Ivan Kalev; Ivaylo Kirov; Borislav Traikov; Ulf Leser; Bertram Weiss,Abstract Summary: Recently; several methods for analyzing phenotype data have beenpublished; but only few are able to cope with data sets generated in different studies; withdifferent methods; or for different species. We developed an online system in which morethan 300 000 phenotypes from a wide variety of sources and screening methods can beanalyzed together. Clusters of similar phenotypes are visualized as networks of highlysimilar phenotypes; inducing gene groups useful for functional analysis. This system is partof PhenomicDB; providing the world's largest cross-species phenotype data collection with atool to mine its wealth of information. Availability: Freely available at http://www.phenomicdb. de Contact: bertram. weiss@ bayerhealthcare. com Supplementaryinformation: Supplementary data are available at Bioinformatics online.,Bioinformatics,2010,20
Integrating and warehousing liver gene expression data and related biomedical resources in GEDAW,Emilie Guérin; Gwenaëlle Marquet; Anita Burgun; Olivier Loréal; Laure Berti-Equille; Ulf Leser; Fouzia Moussouni,Abstract Researchers at the medical research institute Inserm U522; specialized in the liver;use high throughput technologies to diagnose liver disease states. They seek to identify theset of dysregulated genes in different physiopathological situations; along with the molecularregulation mechanisms involved in the occurrence of these diseases; leading at mid-term tonew diagnostic and therapeutic tools. To be able to resolve such a complex question; onehas to consider both data generated on the genes by in-house transcriptome experimentsand annotations extracted from the many publicly available heterogeneous resources inBiomedicine. This paper presents GEDAW; a gene expression data warehouse that hasbeen developed to assist such discovery processes. The distinctive feature of GEDAW is thatit systematically integrates gene information from a multitude of structured data sources …,International Workshop on Data Integration in the Life Sciences,2005,20
State-of-the-art in string similarity search and join,Sebastian Wandelt; Dong Deng; Stefan Gerdjikov; Shashwat Mishra; Petar Mitankin; Manish Patil; Enrico Siragusa; Alexander Tiskin; Wei Wang; Jiaying Wang; Ulf Leser,Abstract String similarity search and its variants are fundamental problems with manyapplications in areas such as data integration; data quality; computational linguistics; orbioinformatics. A plethora of methods have been developed over the last decades.Obtaining an overview of the state-of-the-art in this field is difficult; as results are published invarious domains without much cross-talk; papers use different data sets and often studysubtle variations of the core problems; and the sheer number of proposed methods exceedsthe capacity of a single research group. In this paper; we report on the results of the probablylargest benchmark ever performed in this field. To overcome the resource bottleneck; weorganized the benchmark as an international competition; a workshop at EDBT/ICDT 2013.Various teams from different fields and from all over the world developed or tuned …,ACM SIGMOD Record,2014,19
Classical Hodgkin lymphoma shows epigenetic features of an abortive plasma cellular differentiation,Volkhard Seitz; Philippe E Thomas; Karin Zimmermann; Ulrike Paul; Anke Ehlers; Maria Joosten; Lora Dimitrova; Dido Lenze; Anke Sommerfeld; Elisabeth Oker; Ulf Leser; Harald Stein; Michael Hummel,Background. Epigenetic changes are involved in the extinction of the B-cell gene expressionprogram of classical Hodgkin lymphoma. However; little is known regarding epigeneticsimilarities between classical Hodgkin lymphoma and plasma cell myeloma cells both ofwhich share an extinction of the gene expression program of mature B-cells. Design andmethods. Global histone H3 acetylation patterns were determined in cell lines derived fromclassical Hodgkin lymphoma; plasma cell myeloma and B-cell lymphoma by chromatinimmunoprecipitation and subsequent hybridization onto promoter tiling arrays. H3K27trimethylation was analyzed by chromatin immunoprecipitation and real-time DNA-PCR forselected genes. Epigenetic modifications were compared to gene expression data. Results.B-cell characteristic genes were hypoacetylated in classical Hodgkin lymphoma and …,haematologica,2011,19
Question answering for biology,Mariana Neves; Ulf Leser,Abstract Biologists often pose queries to search engines and biological databases to obtainanswers related to ongoing experiments. This is known to be a time consuming; andsometimes frustrating; task in which more than one query is posed and many databases areconsulted to come to possible answers for a single fact. Question answering comes as analternative to this process by allowing queries to be posed as questions; by integratingvarious resources of different nature and by returning an exact answer to the user. We havesurveyed the current solutions on question answering for Biology; present an overview onthe methods which are usually employed and give insights on how to boost performance ofsystems in this domain.,Methods,2015,18
(Re) use in public scientific workflow repositories,Johannes Starlinger; Sarah Cohen-Boulakia; Ulf Leser,Abstract Scientific workflows help in designing; managing; monitoring; and executing in-silico experiments. Since scientific workflows often are complex; sharing them by means ofpublic workflow repositories has become an important issue for the community. However;due to the increasing numbers of workflows available in such repositories; users have acrucial need for assistance in discovering the right workflow for a given task. To this end;identification of functional elements shared between workflows as a first step to derivemeaningful similarity measures for workflows is a key point. In this paper; we present theresults of a study we performed on the probably largest open workflow repository;myExperiment. org. Our contributions are threefold:(i) We discuss the critical problem ofidentifying same or similar (sub-) workflows and workflow elements;(ii) We study; for the …,International Conference on Scientific and Statistical Database Management,2012,18
Combining modularity; conservation; and interactions of proteins significantly increases precision and coverage of protein function prediction,Samira Jaeger; Christine T Sers; Ulf Leser,While the number of newly sequenced genomes and genes is constantly increasing;elucidation of their function still is a laborious and time-consuming task. This has led to thedevelopment of a wide range of methods for predicting protein functions in silico. We reporton a new method that predicts function based on a combination of information about proteininteractions; orthology; and the conservation of protein networks in different species. Weshow that aggregation of these independent sources of evidence leads to a drastic increasein number and quality of predictions when compared to baselines and other methodsreported in the literature. For instance; our method generates more than 12;000 novelprotein functions for human with an estimated precision of~ 76%; among which are 7;500new functional annotations for 1;973 human proteins that previously had zero or only one …,BMC genomics,2010,18
HUODINI–Flexible information integration for disaster management,Dirk Fahland; Timo Mika Gläßer; Bastian Quilitz; Stephan Weißleder; Ulf Leser,1 ABSTRACT Fast and effective disaster management requires access to a multitude ofheterogeneous; distributed; and quickly changing data sets; such as maps; satellite images;or governmental databases. In the last years; also the information created by affectedpersons on web sites such as flickr. com or blogger. com became an important and veryquickly adapting source of information. We developed HUODINI; a prototype system for theflexible integration and visualization of heterogeneous data sources for disastermanagement. HUODINI is based on Semantic Web technologies; and in particular RDF; tooffer maximal flexibility in the types of data sources it can integrate. It supports a hybridpush/pull approach to cater for the requirements of fast-changing sources; such as newsfeeds; and maximum performance for querying the integrated data set. In this paper; we …,4th International Conference on Information Systems for Crisis Response and Management(ISCRAM); Delft; NL http://www. informatik. huberlin. de/forschung/gebiete/wbi/research/publications/2007/huodini_final. pdf,2007,18
SETH detects and normalizes genetic variants in text,Philippe Thomas; Jörg Hakenberg; Tim Rocktäschel; Yvonne Lichtblau; Ulf Leser,Abstract Summary: Descriptions of genetic variations and their effect are widely spreadacross the biomedical literature. However; finding all mentions of a specific variation; or allmentions of variations in a specific gene; is difficult to achieve due to the many ways suchvariations are described. Here; we describe SETH; a tool for the recognition of variationsfrom text and their subsequent normalization to dbSNP or UniProt. SETH achieves highprecision and recall on several evaluation corpora of PubMed abstracts. It is freely availableand encompasses stand-alone scripts for isolated application and evaluation as well as athorough documentation for integration into other applications. Availability andImplementation: SETH is released under the Apache 2.0 license and can be downloadedfrom http://rockt. github. io/SETH/. Contact: thomas@ informatik. hu-berlin. de or leser …,Bioinformatics,2016,17
Not all links are equal: Exploiting dependency types for the extraction of protein-protein interactions from text,Philippe Thomas; Stefan Pietschmann; Illés Solt; Domonkos Tikk; Ulf Leser,Abstract The extraction of protein-protein interactions (PPIs) reported in scientificpublications is one of the most studied topics in Text Mining in the Life Sciences; as suchalgorithms can substantially decrease the effort for databases curators. The currently bestmethods for this task are based on analyzing the dependency tree (DT) representation ofsentences. Many approaches exploit only topological features and thus do not yet fullyexploit the information contained in DTs. We show that incorporating the grammaticalinformation encoded in the types of the dependencies in DTs noticeably improves extractionperformance by using a pattern matching approach. We automatically infer a large set oflinguistic patterns using only information about interacting proteins. Patterns are then refinedbased on shallow linguistic features and the semantics of dependency types. Together …,Proceedings of BioNLP 2011 Workshop,2011,17
Prefix tree indexing for similarity search and similarity joins on genomic data,Astrid Rheinländer; Martin Knobloch; Nicky Hochmuth; Ulf Leser,Abstract Similarity search and similarity join on strings are important for applications such asduplicate detection; error detection; data cleansing; or comparison of biological sequences.Especially DNA sequencing produces large collections of erroneous strings which need tobe searched; compared; and merged. However; current RDBMS offer similarity operationsonly in a very limited and inefficient form that does not scale to the amount of data producedin Life Science projects. We present PETER; a prefix tree based indexing algorithmsupporting approximate search and approimate joins. Our tool supports Hamming and editdistance as similarity measure and is available as C++ library; as Unix command line tool;and as cartridge for a commercial database. It combines an efficient implementation ofcompressed prefix trees with advanced pre-filtering techniques that exclude many …,International Conference on Scientific and Statistical Database Management,2010,17
Strategies for the Conceptual Design of Federated Information Systems.,Susanne Busse; Ralf-Detlef Kutsche; Ulf Leser,Abstract. We analyse two basic strategies for the development of tightly coupled; federatedinformation systems: top-down and bottom-up. Both approaches are compared relative tothe specific requirements of information integration in evolving environments; such as theintention of treating different kinds of heterogeneity; preserving source autonomy andenabling change management while ensuring consistency. We describe in detail how theintrinsic properties of such strategies affect their ability to cope with these requirements.Based on the results of this study and on extensive experiences; we propose a combinedstrategy based on the intensive use of object-oriented modelling concepts. We show that thisapproach is well-suited to fulfil our vision of a consistent evolution within the paradigm ofcontinuous engineering of federated information systems.,EFIS,2000,17
SOFA: An extensible logical optimizer for UDF-heavy data flows,Astrid Rheinländer; Arvid Heise; Fabian Hueske; Ulf Leser; Felix Naumann,Abstract Recent years have seen an increased interest in large-scale analytical data flowson non-relational data. These data flows are compiled into execution graphs scheduled onlarge compute clusters. In many novel application areas the predominant building blocks ofsuch data flows are user-defined predicates or functions (U df s). However; the heavy use ofU df s is not well taken into account for data flow optimization in current systems. S ofa is anovel and extensible optimizer for U df-heavy data flows. It builds on a concise set ofproperties for describing the semantics of Map/Reduce-style U df s and a small set of rewriterules; which use these properties to find a much larger number of semantically equivalentplan rewrites than possible with traditional techniques. A salient feature of our approach isextensibility: we arrange user-defined operators and their properties into a subsumption …,Information Systems,2015,16
Simple tricks for improving pattern-based information extraction from the biomedical literature,Quang Long Nguyen; Domonkos Tikk; Ulf Leser,Pattern-based approaches to relation extraction have shown very good results in manyareas of biomedical text mining. However; defining the right set of patterns is difficult;approaches are either manual; incurring high cost; or automatic; often resulting in large setsof noisy patterns. We propose several techniques for filtering sets of automatically generatedpatterns and analyze their effectiveness for different extraction tasks; as defined in the recentBioNLP 2009 shared task. We focus on simple methods that only take into account thecomplexity of the pattern and the complexity of the texts the patterns are applied to. We showthat our techniques; despite their simplicity; yield large improvements in all tasks weanalyzed. For instance; they raise the F-score for the task of extraction gene expressionevents from 24.8% to 51.9%. Already very simple filtering techniques may improve the F …,Journal of biomedical semantics,2010,16
Layer decomposition: An effective structure-based approach for scientific workflow similarity,Johannes Starlinger; Sarah Cohen-Boulakia; Sanjeev Khanna; Susan B Davidson; Ulf Leser,Scientific workflows have become a valuable tool for large-scale data processing andanalysis. This has led to the creation of specialized online repositories to facilitate workflowsharing and reuse. Over time; these repositories have grown to sizes that call for advancedmethods to support workflow discovery; in particular for effective similarity search. Here; wepresent a novel and intuitive workflow similarity measure that is based on layerdecomposition. Layer decomposition accounts for the directed dataflow underlying scientificworkflows; a property which has not been adequately considered in previous methods. Wecomparatively evaluate our algorithm using a gold standard for 24 query workflows from arepository of almost 1500 scientific workflows; and show that it a) delivers the best results forsimilarity search; b) has a much lower runtime than other; often highly complex …,e-Science (e-Science); 2014 IEEE 10th International Conference on,2014,15
Efficient similarity search in very large string sets,Dandy Fenz; Dustin Lange; Astrid Rheinländer; Felix Naumann; Ulf Leser,Abstract String similarity search is required by many real-life applications; such as spellchecking; data cleansing; fuzzy keyword search; or comparison of DNA sequences. Given avery large string set and a query string; the string similarity search problem is to efficientlyfind all strings in the string set that are similar to the query string. Similarity is defined using asimilarity (or distance) measure; such as edit distance or Hamming distance. In this paper;we introduce the State Set Index (SSI) as an efficient solution for this search problem. SSI isbased on a trie (prefix index) that is interpreted as a nondeterministic finite automaton. SSIimplements a novel state labeling strategy making the index highly space-efficient.Furthermore; SSI's space consumption can be gracefully traded against search time. Weevaluated SSI on different sets of person names with up to 170 million strings from a …,International Conference on Scientific and Statistical Database Management,2012,15
Effective and efficient similarity search in scientific workflow repositories,Johannes Starlinger; Sarah Cohen-Boulakia; Sanjeev Khanna; Susan B Davidson; Ulf Leser,Abstract Scientific workflows have become a valuable tool for large-scale data processingand analysis. This has led to the creation of specialized online repositories to facilitateworkflow sharing and reuse. Over time; these repositories have grown to sizes that call foradvanced methods to support workflow discovery; in particular for similarity search. Effectivesimilarity search requires both high quality algorithms for the comparison of scientificworkflows and efficient strategies for indexing; searching; and ranking of search results. Yet;the graph structure of scientific workflows poses severe challenges to each of these steps.Here; we present a complete system for effective and efficient similarity search in scientificworkflow repositories; based on the Layer Decomposition approach to scientific workflowcomparison. Layer Decomposition specifically accounts for the directed dataflow …,Future Generation Computer Systems,2016,14
BiobankCloud: a Platform for the Secure Storage; Sharing; and Processing of Large Biomedical Data Sets,Alysson Bessani; Jörgen Brandt; Marc Bux; Vinicius Cogo; Lora Dimitrova; Jim Dowling; Ali Gholami; Kamal Hakimzadeh; Micheal Hummel; Mahmoud Ismail; Erwin Laure; Ulf Leser; Jan-Eric Litton; Roxanna Martinez; Salman Niazi; Jane Reichel; Karin Zimmermann,Abstract Biobanks store and catalog human biological material that is increasingly beingdigitized using next-generation sequencing (NGS). There is; however; a computationalbottleneck; as existing software systems are not scalable and secure enough to store andprocess the incoming wave of genomic data from NGS machines. In the BiobankCloudproject; we are building a Hadoop-based platform for the secure storage; sharing; andparallel processing of genomic data. We extended Hadoop to include support for multi-tenant studies; reduced storage requirements with erasure coding; and added support forextensible and consistent metadata. On top of Hadoop; we built a scalable scientificworkflow engine featuring a proper workflow definition language focusing on simpleintegration and chaining of existing tools; adaptive scheduling on Apache Yarn; and …,Workshop on Data Management and Analytics for Medicine and Healthcare,2015,14
Eine vergleichende Analyse von historischen und diachronen digitalen Korpora,Emil Kroymann; Sebastian Thiebes; Anke Lüdeling; Ulf Leser,Wie hat sich ein bestimmtes Wort/ein bestimmter Laut/eine bestimmte syntaktischeKonstruktion verändert? Wie unterscheiden sich Geschäftsbriefe von Privatbriefen im 18.Jahrhundert? Wie unterscheiden sich Liebesbriefe des 18. Jahrhunderts von Liebesbriefendes 20. Jahrhunderts? Wie sehen überhaupt die ersten uns erhaltenen Liebesbriefe aus?Wann gab es die ersten Romane? Wie hat sich die Schrift entwickelt? Zur Beantwortungdieser und ähnlicher Fragen werden–zusätzlich zu Buchausgaben–in den letztenJahrzehnten alte Manuskripte und Drucke digitalisiert und über das Internet oder CDs zurVerfügung gestellt. Im vorliegenden Bericht werden solche sogenannten historischenTextkorpora (Korpora; die sich mit älteren Sprachstufen befassen) und diachronen Korpora(Korpora; die Texte aus mehreren Sprachstufen enthalten) vorgestellt und aufgrund einer …,*,2011,14
Learning protein protein interaction extraction using distant supervision,Philippe Thomas; Illés Solt; Roman Klinger; Ulf Leser,Abstract Most relation extraction methods; especially in the domain of biology; rely onmachine learning methods to classify a cooccurring pair of entities in a sentence to berelated or not. Such an approach requires a training corpus; which involves expertannotation and is tedious; timeconsuming; and expensive. We overcome this problem by theuse of existing knowledge in structured databases to automatically generate a trainingcorpus for protein-protein interactions. An extensive evaluation of different instance selectionstrategies is performed to maximize robustness on this presumably noisy resource.Successful strategies to consistently improve performance include a majority votingensemble of classifiers trained on subsets of the training corpus and the use of knowledgebases consisting of proven non-interactions. Our best configured model built without …,Proceedings of Workshop on Robust Unsupervised and Semisupervised Methods in Natural Language Processing,2011,14
Tuning Text Classification for Hereditary Diseases with Section Weighting,Juliane Rutsch; Ulf Leser,*,Semantic Mining in Biomedicine (SMBM),2005,14
SAASFEE: scalable scientific workflow execution engine,Marc Bux; Jörgen Brandt; Carsten Lipka; Kamal Hakimzadeh; Jim Dowling; Ulf Leser,Abstract Across many fields of science; primary data sets like sensor read-outs; time series;and genomic sequences are analyzed by complex chains of specialized tools and scriptsexchanging intermediate results in domain-specific file formats. Scientific workflowmanagement systems (SWfMSs) support the development and execution of these toolchains by providing workflow specification languages; graphical editors; fault-tolerantexecution engines; etc. However; many SWfMSs are not prepared to handle large data setsbecause of inadequate support for distributed computing. On the other hand; most SWfMSsthat do support distributed computing only allow static task execution orders. We presentSAASFEE; a SWfMS which runs arbitrarily complex workflows on Hadoop YARN. Workflowsare specified in Cuneiform; a functional workflow language focusing on parallelization …,Proceedings of the VLDB Endowment,2015,13
Extended feature set for chemical named entity recognition and indexing,Torsten Huber; Tim Rocktäschel; Michael Weidlich; Philippe Thomas; Ulf Leser,Abstract. The BioCreative IV CHEMDNER Task provides participants with the opportunity tocompare their methods for chemical named entity recognition (NER) and indexing in acontrolled environment. We contributed to this task with our previous conditional randomfield based system [1] extended by a number of novel general and domain-specific features.For the latter; we used features derived from two existing chemical NER systems; ChemSpot[2] and OSCAR [3]; as well as various external resources. In this paper; we describe ourapproach and present a detailed ablation study that underlines the positive effect of domain-specific features for chemical NER.,BioCreative Challenge Evaluation Workshop,2013,13
Preliminary evaluation of the CellFinder literature curation pipeline for gene expression in kidney cells and anatomical parts,Mariana Neves; Alexander Damaschun; Nancy Mah; Fritz Lekschas; Stefanie Seltmann; Harald Stachelscheid; Jean-Fred Fontaine; Andreas Kurtz; Ulf Leser,Abstract Biomedical literature curation is the process of automatically and/or manuallyderiving knowledge from scientific publications and recording it into specialized databasesfor structured delivery to users. It is a slow; error-prone; complex; costly and; yet; highlyimportant task. Previous experiences have proven that text mining can assist in its manyphases; especially; in triage of relevant documents and extraction of named entities andbiological events. Here; we present the curation pipeline of the CellFinder database; arepository of cell research; which includes data derived from literature curation andmicroarrays to identify cell types; cell lines; organs and so forth; and especially patterns ingene expression. The curation pipeline is based on freely available tools in all text miningsteps; as well as the manual validation of extracted data. Preliminary results are …,Database,2013,13
Inference of surface membrane factors of HIV-1 infection through functional interaction networks,Samira Jaeger; Gokhan Ertaylan; David van Dijk; Ulf Leser; Peter Sloot,Background HIV infection affects the populations of T helper cells; dendritic cells andmacrophages. Moreover; it has a serious impact on the central nervous system. It is yet notclear whether this list is complete and why specifically those cell types are affected. Toaddress this question; we have developed a method to identify cellular surface proteins thatpermit; mediate or enhance HIV infection in different cell/tissue types in HIV-infectedindividuals. Receptors associated with HIV infection share common functions and domainsand are involved in similar cellular processes. These properties are exploited bybioinformatics techniques to predict novel cell surface proteins that potentially interact withHIV. Methodology/Principal Findings We compiled a set of surface membrane proteins(SMP) that are known to interact with HIV. This set is extended by proteins that have direct …,PLoS One,2010,13
Efficient and exact computation of inclusion dependencies for data integration,Jana Bauckmann; Ulf Leser; Felix Naumann,Data obtained from foreign data sources often come with only superficial structuralinformation; such as relation names and attribute names. Other types of metadata that areimportant for effective integration and meaningful querying of such data sets are missing. Inparticular; relationships among attributes; such as foreign keys; are crucial metadata forunderstanding the structure of an unknown database. The discovery of such relationships isdifficult; because in principle for each pair of attributes in the database each pair of datavalues must be compared. A precondition for a foreign key is an inclusion dependency (IND)between the key and the foreign key attributes. We present with Spider an algorithm thatefficiently finds all INDs in a given relational database. It leverages the sorting facilities ofDBMS but performs the actual comparisons outside of the database to save computation …,*,2010,13
Design Issues of Database Access in a CORBA Environment.,Ulf Leser; Stefan Tai; Susanne Busse,Abstract CORBA is an architecture aiming to provide an infrastructure for the cooperation ofdistributed and heterogeneous software components in a network. One of the most importantcomponents of real-life applications are database systems. In this paper we investigate theuse of CORBA to access data stored in a database system. We evaluate the designdecisions a developer has to take if he wants to use CORBA to make his data accessible forremote clients; grouping them into five different dimensions. We also evaluate the usability ofthe Object Query Service and the Object Transaction Service; as specified by the OMG. Thisleads to the identification of three different scenarios; each of which uses CORBA in acompletely different manner; which we call\Old-Fashioned";\Object Collections"; and\PureCORBA".,Workshop Integration heterogener Softwaresysteme,1998,13
Deregulation of the endogenous C/EBPβ LIP isoform predisposes to tumorigenesis,Valérie Bégay; Jeske J Smink; Christoph Loddenkemper; Karin Zimmermann; Cornelia Rudolph; Marina Scheller; Doris Steinemann; Ulf Leser; Brigitte Schlegelberger; Harald Stein; Achim Leutz,Abstract Two long and one truncated isoforms (termed LAP*; LAP; and LIP; respectively) ofthe transcription factor CCAAT enhancer binding protein beta (C/EBPβ) are expressed froma single intronless Cebpb gene by alternative translation initiation. Isoform expression issensitive to mammalian target of rapamycin (mTOR)-mediated activation of the translationinitiation machinery and relayed through an upstream open reading frame (uORF) on theC/EBPβ mRNA. The truncated C/EBPβ LIP; initiated by high mTOR activity; has been impliedin neoplasia; but it was never shown whether endogenous C/EBPβ LIP may function as anoncogene. In this study; we examined spontaneous tumor formation in C/EBPβ knockin micethat constitutively express only the C/EBPβ LIP isoform from its own locus. Our data showthat deregulated C/EBPβ LIP predisposes to oncogenesis in many tissues. Gene …,Journal of Molecular Medicine,2015,12
CellFinder: a cell data repository,Harald Stachelscheid; Stefanie Seltmann; Fritz Lekschas; Jean-Fred Fontaine; Nancy Mah; Mariana Neves; Miguel A Andrade-Navarro; Ulf Leser; Andreas Kurtz,Abstract CellFinder (http://www. cellfinder. org) is a comprehensive one-stop resource formolecular data characterizing mammalian cells in different tissues and in differentdevelopment stages. It is built from carefully selected data sets stemming from other curateddatabases and the biomedical literature. To date; CellFinder describes 3394 cell types and50 951 cell lines. The database currently contains 3055 microscopic and anatomicalimages; 205 whole-genome expression profiles of 194 cell/tissue types from RNA-seq andmicroarrays and 553 905 protein expressions for 535 cells/tissues. Text mining of a corpusof> 2000 publications followed by manual curation confirmed expression information on∼900 proteins and genes. CellFinder's data model is capable to seamlessly represent entitiesfrom single cells to the organ level; to incorporate mappings between homologous …,Nucleic acids research,2014,12
Next generation data integration for Life Sciences,Sarah Cohen-Boulakia; Ulf Leser,Ever since the advent of high-throughput biology (eg; the Human Genome Project);integrating the large number of diverse biological data sets has been considered as one ofthe most important tasks for advancement in the biological sciences. Whereas the early daysof research in this area were dominated by virtual integration systems (such as multi-/federated databases); the current predominantly used architecture uses materialization.Systems are built using ad-hoc techniques and a large amount of scripting. However; recentyears have seen a shift in the understanding of what a “data integration system” actuallyshould do; revitalizing research in this direction. In this tutorial; we review the past andcurrent state of data integration for the Life Sciences and discuss recent trends in detail;which all pose challenges for the database community.,Data Engineering (ICDE); 2011 IEEE 27th International Conference on,2011,12
Index support for sparql,Ralf Heese; Ulf Leser; Bastian Quilitz; Christian Rothe,Abstract. The Resource Description Framework (RDF) is the fundamental data modelunderlying the Semantic Web. Recently; SPARQL has been proposed as W3C standard forquerying RDF repositories. As RDF is a graph-based data model; the core problem ofevaluating SPARQL queries is matching query graph patterns against the data graph; whichis computationally very expensive. We address this problem by indexing graph patterns. Inthe spirit of SQL; we assume that users select the patterns to be indexed. We formally definethe problem of covering indexes; ie; finding those indexes whose graph-patterns arecontained in the query pattern; and derive formulas for estimating index selectivity. Finally;we study the problem of finding optimal sets of indexes for a given query. We believe thatour framework is the first comprehensive suggestion for indexing RDF for SPARQL …,European Semantic Web Conference; Innsbruck; Austria,2007,12
CELDA-an ontology for the comprehensive representation of cells in complex systems,Stefanie Seltmann; Harald Stachelscheid; Alexander Damaschun; Ludger Jansen; Fritz Lekschas; Jean-Fred Fontaine; Throng Nghia Nguyen-Dobinsky; Ulf Leser; Andreas Kurtz,The need for detailed description and modeling of cells drives the continuous generation oflarge and diverse datasets. Unfortunately; there exists no systematic and comprehensiveway to organize these datasets and their information. CELDA (Cell: Expression;Localization; Development; Anatomy) is a novel ontology for the association of primaryexperimental data and derived knowledge to various types of cells of organisms. CELDA is astructure that can help to categorize cell types based on species; anatomical localization;subcellular structures; developmental stages and origin. It targets cells in vitro as well as invivo. Instead of developing a novel ontology from scratch; we carefully designed CELDA insuch a way that existing ontologies were integrated as much as possible; and only minimalextensions were performed to cover those classes and areas not present in any existing …,BMC bioinformatics,2013,11
Improving data quality by source analysis,Heiko Müller; Johann-Christoph Freytag; Ulf Leser,Abstract In many domains; data cleaning is hampered by our limited ability to specify acomprehensive set of integrity constraints to assist in identification of erroneous data. Analternative approach to improve data quality is to exploit different data sources that containinformation about the same set of objects. Such overlapping sources highlight hot-spots ofpoor data quality through conflicting data values and immediately provide alternative valuesfor conflict resolution. In order to derive a dataset of high quality; we can merge theoverlapping sources based on a quality assessment of the conflicting values. The quality ofthe resulting dataset; however; is highly dependent on our ability to asses the quality ofconflicting values effectively. The main objective of this article is to introduce methods thataid the developer of an integrated system over overlapping; but contradicting sources in …,Journal of Data and Information Quality (JDIQ),2012,11
Equatornlp: Pattern-based information extraction for disaster response,Lars Döhling; Ulf Leser,Abstract. One of the most severe problems in early phases of disaster response is the lack ofinformation about the current situation. Such information is indispensable for planning andmonitoring rescue operations; but hardly available due to the breakdown of informationchannels and normal message routes. However; during recent disasters in developedcountries; such as the flooding of New Orleans or the earthquake in New Zealand; a wealthof detailed information was posted by affected persons in media; such as Flickr; Twitter; orpersonal blogs. Finding and extracting such information may provide valuable clues fororganizing aid; but currently requires humans to constantly read and analyze thesemessages. In this work; we report on a study for extracting such facts automatically by usinga combination of deep natural language processing and advanced machine learning …,Terra Cognita 2011 Workshop; Foundations; Technologies and Applications of the Geospatial Web,2011,11
Gene mention normalization in full texts using GNAT and LINNAEUS,Illés Solt; Martin Gerner; Philippe Thomas; Goran Nenadic; Casey M Bergman; Ulf Leser; Jörg Hakenberg,Abstract Gene mention normalization (GN) refers to the automated mapping of gene namesto a unique identifier; such as an NCBI Entrez Gene ID. Such knowledge helps in indexingand retrieval; linkage to additional information (such as sequences); database curation; anddata integration. We present here an ensemble system encompassing LINNAEUS forrecognizing organism names and GNAT for recognition and normalization of gene mentions;taking into account the species information provided by LINNAEUS. Candidate identifiersare filtered through a series of steps that take the local context of a given mention intoaccount. On the BioCreative III high-quality training data; our system achieves TAP-5 andTAP-20 scores of 0.36 and 0.41; respectively. On the evaluation set of 50 documents thatwere provided to participants; we achieve scores of 0.16 and 0.20 for TAP-5 and TAP-20 …,Proceedings of the BioCreative III workshop (Bethesda; USA),2010,11
Integration molekularbiologischer daten,Ulf Leser; Peter Rieger,Abstrakt: Molekularbiologische Forschung ist undenkbar geworden ohne den massivenEinsatz von Computern; sowohl zur Datenanalyse als auch zur Datenverwaltung. Bedingtdurch die thematische und räumliche Fragmentierung der weltweiten Forschung in eineVielzahl von Gruppen; Firmen und Konsortien spielt dabei die Integration von Daten eineherausragende Rolle. Zu diesem Zweck wurden sowohl Lösungen entwickelt; die auf demintegrierten Zugriff auf verteilte Datensammlungen basieren; als auch solche; die dasphysikalische Kopieren der Ausgangsdaten in ein integriertes System vorsehen. Derfolgende Artikel gibt einen Überblick über die spezifischen Probleme der Datenintegration inder Bioinformatik; stellt die wichtigsten Projekte und Produkte in diesem Gebiet vor undweist auf neue Entwicklungen und offene Forschungsthemen hin.,Datenbank-Spektrum,2003,11
IXDB; an X chromosome integrated database,Ulf Leser; Robert Wagner; Andrei Grigoriev; Hans Lehrach; Hugues Roest Crollius,Abstract The integrated X chromosome database (IXDB) is a repository for physical mappingdata of the human X chromosome. Its current content is the result of a strict integration ofdata stemming from many different sources. The main features of IXDB include a flexible andextendible schema; a comfortable and fully crossreferenced WWW interface (http://ixdb.mpimg-berlin-dahlem. mpg. de) and a graphical map viewer implemented in JAVA. Thedatabase stores objects used in physical mapping as well as the maps resulting from thiswork; but a strong emphasis is placed on recording experiments that connect objectstogether. This should greatly contribute to fulfilling one of the major goals of the database: tosupport the construction of an integrated physical; genetic; transcript and sequence map ofthe human X chromosome.,Nucleic Acids Research,1998,11
Computer-assisted curation of a human regulatory core network from the biological literature,Philippe Thomas; Pawel Durek; Illés Solt; Bertram Klinger; Franziska Witzel; Pascal Schulthess; Yvonne Mayer; Domonkos Tikk; Nils Blüthgen; Ulf Leser,Abstract Motivation: A highly interlinked network of transcription factors (TFs) orchestratesthe context-dependent expression of human genes. ChIP-chip experiments that interrogatethe binding of particular TFs to genomic regions are used to reconstruct gene regulatorynetworks at genome-scale; but are plagued by high false-positive rates. Meanwhile; a largebody of knowledge on high-quality regulatory interactions remains largely unexplored; as itis available only in natural language descriptions scattered over millions of scientificpublications. Such data are hard to extract and regulatory data currently contain togetheronly 503 regulatory relations between human TFs. Results: We developed a text-mining-assisted workflow to systematically extract knowledge about regulatory interactions betweenhuman TFs from the biological literature. We applied this workflow to the entire Medline …,Bioinformatics,2014,10
Histone acetylation and DNA demethylation of T cells result in an anaplastic large cell lymphoma-like phenotype,Maria Joosten; Volkhard Seitz; Karin Zimmermann; Anke Sommerfeld; Erika Berg; Dido Lenze; Ulf Leser; Harald Stein; Michael Hummel,A characteristic feature of anaplastic large cell lymphoma is the significant repression of theT-cell expression program despite its T-cell origin. The reasons for this down-regulation of T-cell phenotype are still unknown. To elucidate whether epigenetic mechanisms areresponsible for the loss of the T-cell phenotype; we treated anaplastic large cell lymphomaand T-cell lymphoma/leukemia cell lines (n= 4; each) with epigenetic modifiers to evokeDNA demethylation and histone acetylation. Global gene expression data from treated anduntreated cell lines were generated and selected; and differentially expressed genes wereevaluated by real-time reverse transcriptase polymerase chain reaction and western blotanalysis. Additionally; histone H3 lysine 27 trimethylation was analyzed by chromatinimmunoprecipitation. Combined DNA demethylation and histone acetylation of anaplastic …,Haematologica,2013,10
RDFMatView: Indexing RDF data using materialized SPARQL queries,Roger Castillo; Christian Rothe; Ulf Leser,Abstract. The Semantic Web aims to create a universal medium for the exchange ofsemantically tagged data. The idea of representing and querying this information by meansof directed labelled graphs; ie; RDF and SPARQL; has been widely accepted by thescientific community. However; even when most current implementations of RDF/SPARQLare based on ad-hoc storage systems; processing complex queries on large data sets incursa high number of joins; which may slow down performance. In this article we proposematerialized SPARQL queries as indexes on RDF data sets to reduce the number ofnecessary joins and thus query processing time. We provide a formal definition ofmaterialized SPARQL queries; a cost model to evaluate their impact on query performance;a storage scheme for the materialization; and an algorithm to find the optimal set of …,International Workshop on Scalable Semantic Web Knowledge Base Systems (SSWS),2010,10
Collecting a large corpus from all of Medline,Jörg Hakenberg; Ulf Leser; Harald Kirsch; Dietrich Rebholz-Schuhmann,Abstract We present our ideas and first results for a system to extract interactions betweenproteins from scientific publications. This system consists of three main stages. First; weextract a large sample of sentences from unannotated text. Second; we generate languagepatterns using multiple sentence alignment to identify consensus phrases. Last; we applythese patterns to arbitrary text; again using sentence alignment. In this paper; weconcentrate on the first step; were we extract a training sample from MEDLINE. We searchfor occurrences of both partners of a known protein-protein interaction in a single sentenceand further refine the resulting set to exclude false positives. We are able to extract almost68;000 examples for sentences that discuss protein-protein interactions.,SMBM,2006,10
A support vector machine classifier for gene name recognition,Steffen Bickel; Ulf Brefeld; Lukas Faulstich; Jörg Hakenberg; Ulf Leser; Conrad Plake; Tobias Scheffer,Abstract This summary describes our solution for task 1A of the BioCreAtIvE Challenge Cup2003. Essentially; we reduce the entity recognition problem to the problem of classifyingsingle words using a Support Vector Machine followed by a term expansion. Our researchquestion is therefore to find those types of features that eventually yield the highest precisionand recall. We implemented and evaluated different features and combinations of features;such as n-grams; neighborhood defined by a sliding window; classification results ofpreceding words; appearance of special characters or digits; or appearance of the word in adictionary. Multi-word entity names are gathered in a context-sensitive post-processing step.Our best set of features on the training set leads to a precision of 71.4% and a recall of72.8%; corresponding to an F-measure of 72.1%; for the closed division.,EMBO Workshop: A critical assessment of text mining methods in molecular biology; Granada; Spain,2004,10
Deep learning with word embeddings improves biomedical named entity recognition,Maryam Habibi; Leon Weber; Mariana Neves; David Luis Wiegandt; Ulf Leser,Abstract Motivation: Text mining has become an important tool for biomedical research. Themost fundamental text-mining task is the recognition of biomedical named entities (NER);such as genes; chemicals and diseases. Current NER methods rely on pre-defined featureswhich try to capture the specific surface properties of entity types; properties of the typicallocal context; background knowledge; and linguistic information. State-of-the-art tools areentity-specific; as dictionaries and empirically optimal feature sets differ between entitytypes; which makes their development costly. Furthermore; features are often optimized for aspecific gold standard corpus; which makes extrapolation of quality measures difficult.Results: We show that a completely generic method based on deep learning and statisticalword embeddings [called long short-term memory network-conditional random field …,Bioinformatics,2017,9
Cuneiform: a Functional Language for Large Scale Scientific Data Analysis.,Jörgen Brandt; Marc Bux; Ulf Leser,*,EDBT/ICDT Workshops,2015,9
Soa-based integration of text mining services,Johannes Starlinger; Florian Leitner; Alfonso Valencia; Ulf Leser,Text Mining has established itself as a valuable tool for knowledge extraction in manycommercial and scientific areas. Accordingly; a large number of different methods havebeen developed focusing on a broad range of different tasks. We report on a novel systemarchitecture that is fundamentally service-based; ie; it models and implements text miningand knowledge extraction routines as independent; yet federated services. The system hasseveral layers:(1) Base services perform various fundamental extraction tasks. They allimplement a fixed interface but keep their particular algorithms and functionality.(2) Ametaservice acting as a central access point to those base services; thus providing ahomogeneous interface to different algorithms.(3) An aggregation service on top of themetaservice which implements functionality to graphically show; compare; and aggregate …,Services-I; 2009 World Conference on,2009,9
Describing differences between databases,Heiko Müller; Johann-Christoph Freytag; Ulf Leser,Abstract We study the novel problem of efficiently computing the update distance for a pair ofrelational databases. In analogy to the edit distance of strings; we define the update distanceof two databases as the minimal number of set-oriented insert; delete and modificationoperations necessary to transform one database into the other. We show how this distancecan be computed by traversing a search space of database instances connected by updateoperations. This insight leads to a family of algorithms that compute the update distance orapproximations of it. In our experiments we observed that a simple heuristic performssurprisingly well in most considered cases. Our motivation for studying distance measuresfor databases stems from the field of scientific databases. There; replicas of a singledatabase are often maintained at different sites; which typically leads to (accidental or …,Proceedings of the 15th ACM international conference on Information and knowledge management,2006,9
Cooperative query answering with density scores,Felix Naumann; Ulf Leser,Abstract Mediator-based information systems answer global queries by rewriting them into acombination of queries against physical data sources. One assumption in most systems isthat only such combinations are considered as valid that obtain values for each selectedattribute of the query. Another assumption is that systems must compute and execute allvalid combinations; ie; they strive to retrieve all possible answers. These assumptionsfrequently lead to user frustration: First; in many scenarios an incomplete answer is muchmore appreciated than no answer at all. Second; if many valid combinations exist; it is verytime-consuming to execute them all. We present a cooperative query planning method thatavoids both problems. First; it treats incomplete and complete source combinations in alogically equivalent manner; ie; incomplete answers are also considered. Second; it ranks …,*,2000,9
Assembly of a comprehensive regulatory network for the mammalian circadian clock: a bioinformatics approach,Robert Lehmann; Liam Childs; Philippe Thomas; Monica Abreu; Luise Fuhr; Hanspeter Herzel; Ulf Leser; Angela Relógio,By regulating the timing of cellular processes; the circadian clock provides a way to adaptphysiology and behaviour to the geophysical time. In mammals; a light-entrainable masterclock located in the suprachiasmatic nucleus (SCN) controls peripheral clocks that arepresent in virtually every body cell. Defective circadian timing is associated with severalpathologies such as cancer and metabolic and sleep disorders. To better understand thecircadian regulation of cellular processes; we developed a bioinformatics pipelineencompassing the analysis of high-throughput data sets and the exploitation of publishedknowledge by text-mining. We identified 118 novel potential clock-regulated genes andintegrated them into an existing high-quality circadian network; generating the to-date mostcomprehensive network of circadian regulated genes (NCRG). To validate particular …,PLoS One,2015,8
String Searching in Referentially Compressed Genomes.,Sebastian Wandelt; Ulf Leser,Abstract: Background: Improved sequencing techniques have led to large amounts ofbiological sequence data. One of the challenges in managing sequence data is efficientstorage. Recently; referential compression schemes; storing only the differences between ato-be-compressed input and a known reference sequence; gained a lot of interest in thisfield. However; so far sequences always have to be decompressed prior to an analysis.There is a need for algorithms working on compressed data directly; avoiding costlydecompression. Summary: In our work; we address this problem by proposing an algorithmfor exact string search over compressed data. The algorithm works directly on referentiallycompressed genome sequences; without needing an index for each genome and only usingpartial decompression. Results: Our string search algorithm for referentially compressed …,KDIR,2012,8
Weakly labeled corpora as silver standard for drug-drug and protein-protein interaction,Philippe Thomas; Tamara Bobić; Ulf Leser; Martin Hofmann-Apitius; Roman Klinger,Abstract Relation extraction is frequently and successfully addressed by machine learningmethods. The downside of this approach is the need for annotated training data; typicallygenerated in tedious manual; cost intensive work. Distantly supervised approaches makeuse of weakly annotated data; which can be derived automatically. Recent work in thebiomedical domain has applied distant supervision for protein-protein interaction (PPI) withreasonable results; by employing the IntAct database. Training from distantly labeledcorpora is more challenging than from manually curated ones; as such data is inherentlynoisy. With this paper; we make two corpora publicly available to the community to allow forcomparison of different methods that deal with the noise in a uniform setting. The first corpusis addressing protein-protein interaction (PPI); based on named entity recognition and the …,Proceedings of the Workshop on Building and Evaluating Resources for Biomedical Text Mining (BioTxtM) on Language Resources and Evaluation Conference (LREC),2012,8
Design and evaluation of an ontology-based drug application database,Christian Senger; HM Seidling; R Quinzler; U Leser; WE Haefeli,Objectives: Several recently published cases of preventable adverse drug reactions wereassociated with flaws in drug application. However; current clinical decision support (CDS)systems do not properly consider drug application issues and thus do not support effectiveprevention of such medication errors. With the aim to improve CDS in this respect; wedeveloped a comprehensive model precisely describing all aspects of drug application.Methods: The model consists of 1) a schema comprising all relevant attributes of drugapplication and 2) an ontology providing a hierarchically structured vocabulary of terms thatdescribe the possible values of the schema's attributes. Finally; medical products wereannotated by a semi-automatic term assignment process. For evaluation; we developed analgorithm that uses our model to compute a meaningful similarity between medicinal …,Methods of information in medicine,2011,8
Phenotype mining for functional genomics and gene discovery,Philip Groth; Ulf Leser; Bertram Weiss,Abstract In gene prediction; studying phenotypes is highly valuable for reducing the numberof locus candidates in association studies and to aid disease gene candidate prioritization.This is due to the intrinsic nature of phenotypes to visibly reflect genetic activity; making thempotentially one of the most useful data types for functional studies. However; systematic useof these data has begun only recently.'Comparative phenomics' is the analysis of genotype–phenotype associations across species and experimental methods. This is an emergingresearch field of utmost importance for gene discovery and gene function annotation. In thischapter; we review the use of phenotype data in the biomedical field. We will give anoverview of phenotype resources; focusing on PhenomicDB–a cross-species genotype–phenotype database–which is the largest available collection of phenotype descriptions …,*,2011,8
What’s new? What’s certain?–scoring search results in the presence of overlapping data sources,Philipp Hussels; Silke Trißl; Ulf Leser,Abstract Data integration projects in the life sciences often gather data on a particularsubject from multiple sources. Some of these sources overlap to a certain degree. Therefore;integrated search results may be supported by one; few; or all data sources. To reflect thesedifferences; results should be ranked according to the number of data sources that supportthem. How such a ranking should look like is not clear per se. Either; results supported byonly few sources are ranked high because this information is potentially new; or such resultsare ranked low because the strength of evidence supporting them is limited. We present twoscoring schemes to rank search results in the integrated protein annotation databaseColumba. We define a surprisingness score; preferring results supported by few sources;and a confidence score; preferring frequently encountered information. Unlike many other …,International Conference on Data Integration in the Life Sciences,2007,8
GRIPP Indexing and Querying Graphs Based on Pre-and Postorder Numbering,Silke Trißl; Ulf Leser,Abstract Many applications require querying graph-structured data. As graphs grow in size;indexing becomes essential to ensure sufficient query performance. We present the GRIPPindex structure (GRaph Indexing based on Pre-and Postorder numbering) for answeringreachability and distance queries in graphs. GRIPP requires only linear space and can becomputed very efficiently. Using GRIPP; we can answer reachability queries on graphs with5;000;000 nodes on average in less than 5 milliseconds; which is unrivaled by previousmethods. We can also answer distance queries on large graphs more efficiently using theGRIPP index strucutre. We evaluate the performance and scalability of our approach on real;random; and scale-free networks using an implementation of GRIPP inside a relationaldatabase management system. Thus; GRIPP can be integrated very easily into existing …,*,2006,8
A critical assessment of text mining methods in molecular biology,Lynette Hirschman; Alexander Yeh; Christian Blaschke; Alfonso Valencia; Alexander Morgan; Marc Colosimo; Lorraine Tanabe; Natalie Xie; Lynne H Thom; Wayne Matten; W John Wilbur; Shuhei Kinoshita; K Bretonnel Cohen; Philip V Ogren; Lawrence Hunter; Jenny Finkel; Shipra Dingare; Christopher D Manning; Malvina Nissim; Beatrice Alex; Claire Grover; Ryan McDonald; Fernando Pereira; GuoDong Zhou; Dan Shen; Jie Zhang; Jian Su; SoonHeng Tan; Tomohiro Mitsumori; Sevrani Fation; Masaki Murata; Kouichi Doi; Hirohumi Doi; Jörg Hakenberg; Steffen Bickel; Conrad Plake; Ulf Brefeld; Hagen Zahn; Lukas Faulstich; Ulf Leser; Tobias Scheffer; Javier Tamames; Marc E Colosimo; Alexander A Morgan; Alexander S Yeh; Jeffrey B Colombe; Jeremiah Crim; Daniel Hanisch; Katrin Fundel; Heinz-Theodor Mevissen; Ralf Zimmer; Juliane Fluck; Daniel Güttler; Joannis Apostolakis; Eduardo Andres Leon; Martin Krallinger; Evelyn B Camon; Daniel G Barrell; Emily C Dimmer; Vivian Lee; Michele Magrane; John Maslen; David Binns; Rolf Apweiler; Soumya Ray; Mark Craven; Maria Padron; Karin Verspoor; Judith Cohn; Cliff Joslyn; Sue Mniszewski; Andreas Rechtsteiner; Luis M Rocha; Tiago Simas,<p><i>BMC Bioinformatics</i> is part of the <i>BMC</i> series which publishessubject-specific journals focused on the needs of individual research communities acrossall areas of biology and medicine. We do not make editorial decisions on the basis of theinterest of a study or its likely impact. Studies must be scientifically valid; for research articlesthis includes a scientifically sound research question; the use of suitable methods andanalysis; and following community-agreed standards relevant to the researchfield.</p><p>Specific criteria for other article types can be found in the submissionguidelines.</p><p><i>BMC</i> series - open; inclusive and trusted.</p>.,BMC Bioinformatics,2005,8
Data mining: The next generation,Raghu Ramakrishnan; Rakesh Agrawal; Johann-Christoph Freytag; Toni Bollinger; Christopher W Clifton; Saso Dzeroski; Jochen Hipp; Daniel Keim; Stefan Kramer; Hans-Peter Kriegel; Ulf Leser; Bing Liu; Heikki Mannila; Rosa Meo; Shinichi Morishita; Raymond Ng; Jian Pei; Prabhakar Raghavan; Myra Spiliopoulou; Jaideep Srivastava; Vicenc Torra,Abstract Data Mining (DM) has enjoyed great popularity in recent years; with advances inboth research and commercialization. The first generation of DM research and developmenthas yielded several commercially available systems; both stand-alone and integrated withdatabase systems; produced scalable versions of algorithms for many classical DMproblems; and introduced novel pattern discovery problems. In recent years; research hastended to be fragmented into several distinct pockets without a comprehensive framework.Researchers have continued to work largely within the parameters of their parentdisciplines; building upon existing and distinct research methodologies. Even when theyaddress a common problem (for example; how to cluster a dataset) they apply differenttechniques; different perspectives on what the important issues are; and different …,Dagstuhl Seminar Proceedings,2005,8
Text mining for systems biology using statistical learning methods,Sebastian Schmeier; Jörg Hakenberg; Axel Kowald; Edda Klipp; Ulf Leser,Abstract The understanding and modelling of biological systems relies on the availability ofnumerical values for physical and chemical properties of biological macro molecules. Kineticparameters; rate constants; specificities and half-lifes are examples of those properties. Thisdata is mostly published in free text form in scientific journals; which is unsatisfactory for theautomatic search and retrieval of specific information. No individual nor a group is able tokeep up with the huge amount of input coming from new and old publications. The gatheringof documents relevant to kinetic modelling and the extraction of needed data has to besupported by automated processes. This work describes first steps towards the automaticrecognition and extraction of kinetic parameters from full text articles. We describe theprocessing of full text publications by text mining methods to classify the texts regarding …,Workshop des Arbeitskreises Knowledge Discovery (AKKD),2003,8
MRCSI: compressing and searching string collections with multiple references,Sebastian Wandelt; Ulf Leser,Abstract Efficiently storing and searching collections of similar strings; such as largepopulations of genomes or long change histories of documents from Wikis; is a timely andchallenging problem. Several recent proposals could drastically reduce space requirementsby exploiting the similarity between strings in so-called reference-based compression.However; these indexes are usually not searchable any more; ie; in these methods searchefficiency is sacrificed for storage efficiency. We propose Multi-Reference CompressedSearch Indexes (MRCSI) as a framework for efficiently compressing dissimilar stringcollections. In contrast to previous works which can use only a single reference forcompression; MRCSI (a) uses multiple references for achieving increased compressionrates; where the reference set need not be specified by the user but is determined …,Proceedings of the VLDB Endowment,2015,7
How well are protein structures annotated in secondary databases?,Kristian Rother; Elke Michalsky; Ulf Leser,Abstract We investigated to what extent Protein Data Bank (PDB) entries are annotated withsecond-party information based on existing cross-references between PDB and 15 otherdatabases. We report 2 interesting findings. First; there is a clear “annotation gap” forstructures less than 7 years old for secondary databases that are manually curated. Second;the examined databases overlap with each other quite well; dividing the PDB into 2 well-annotated thirds and one poorly annotated third. Both observations should be taken intoaccount in any study depending on the selection of protein structures by their annotation.Proteins 2005.© 2005 Wiley-Liss; Inc.,Proteins: Structure; Function; and Bioinformatics,2005,7
Learning patterns for information extraction from free text,Conrad Plake; Jörg Hakenberg; Ulf Leser,Abstract We describe a general approach to the task of information extraction from free textand propose methods for learning syntax patterns automatically from annotated corpora. Westudy the application of our approach to the extraction of protein-protein interactions fromscientific texts. Based on this evaluation; we find that learning patterns outperformstechniques based on handcrafted patterns.,Proc Workshop des Arbeitskreises Knowledge Discovery. Karlruhe; Germany,2005,7
Constructing IDL views on relational databases,Kim Jungfer; Ulf Leser; Patricia Rodriguez-Tomé,Abstract Data collections are distributed at many different sites and stored in numerousdifferent database management systems. The industry standard CORBA can help toalleviate the technical problems of distribution and diverging data formats. In a CORBAenvironment; data structures can be represented using the Interface Definition LanguageIDL. Manually coding a server; which implements the IDL through calls to the underlyingdatabase; is tedious. On the other hand; it is in general impossible to automatically generatethe CORBA server because the IDL is not only determined by the schema of the databasebut also by other factors such as performance requirements. We therefore have developed amethod for the semi-automatic generation of CORBA wrappers for relational databases. Adeclarative language is presented; which is used to describe the mapping between …,International Conference on Advanced Information Systems Engineering,1999,7
IXDB; an X chromosome integrated database (update),Ulf Leser; Hugues Roest Crollius; Hans Lehrach; Ralf Sudbrak,Abstract Chromosome specific databases are an important research tool as they integratedata from different directions; such as genetic and physical mapping data; expression data;sequences etc. They supplement the genome-wide repositories in molecular biology; suchas GenBank; Swiss-Prot or OMIM; which usually concentrate on one type of information. TheIntegrated X Chromosome Database (IXDB; http://ixdb. mpimgberlin-dahlem. mpg. de/) is arepository for physical mapping data of the human X chromosome and aims at providing aglobal view of genomic data at a chromosomal level. We present here an update of IXDBwhich includes schema extensions for storing submaps and sequence information;additional links to external databases; and the integration of an increasing number ofphysical and transcript mapping data. The gene data was completely updated according …,Nucleic acids research,1999,7
Extracting and aggregating temporal events from text,Lars Döhling; Ulf Leser,Abstract Finding reliable information about a given event from large and dynamic textcollections is a topic of great interest. For instance; rescue teams and insurance companiesare interested in concise facts about damages after disasters; which can be found in webblogs; newspaper articles; social networks etc. However; finding; extracting; and condensingspecific facts is a highly complex undertaking: It requires identifying appropriate textualsources; recognizing relevant facts within the sources; and aggregating extracted facts into acondensed answer despite inconsistencies; uncertainty; and changes over time. In thispaper; we present a three-step framework providing techniques and solutions for each ofthese problems. We tested the feasibility of extracting time-associated event facts using ourframework in a comprehensive case study: gathering data on particular earthquakes from …,Proceedings of the 23rd International Conference on World Wide Web,2014,6
Species identification for gene name normalization,Illés Solt; Domonkos Tikk; Ulf Leser,Background Protein interaction networks are expensive to construct experimentally.Therefore; researchers usually refer to the literature or domain-specific databases to conveyknowledge on currently known interactions. Yet the task of manual collection of knowledgefrom scientific papers is labor intensive; and therefore should be automated to the extentpossible. For this; an important step is identifying gene and protein names (termed entities).After identification; gene names must be mapped to database identifiers to connect them tostructured knowledge. One particular problem in this step are homonymous; ie; identicalnames referring to different genes in different species. Methods We present differentapproaches that aim at assigning species labels to MEDLINE abstracts. We use (1) as abaseline; the most frequent species MeSH term of the corresponding journal represented …,BMC bioinformatics,2010,6
Graph-based ontology construction from heterogenous evidences,Christoph Böhm; Philip Groth; Ulf Leser,Abstract Ontologies are tools for describing and structuring knowledge; with manyapplications in searching and analyzing complex knowledge bases. Since building themmanually is a costly process; there are various approaches for bootstrapping ontologiesautomatically through the analysis of appropriate documents. Such an analysis needs to findthe concepts and the relationships that should form the ontology. However; sincerelationship extraction methods are imprecise and cannot homogeneously cover allconcepts; the initial set of relationships is usually inconsistent and rather imbalanced-aproblem which; to the best of our knowledge; was mostly ignored so far. In this paper; wedefine the problem of extracting a consistent as well as properly structured ontology from aset of inconsistent and heterogeneous relationships. Moreover; we propose and compare …,International Semantic Web Conference,2009,6
Designing a Global Information Resource for Molecular Biology (Short Paper),Ulf Leser,Abstract Research in molecular biology is continuously producing an immense amount ofdata; but this information is spread over numerous heterogeneous data repositories. Theirintegration into a federated information system would drastically reduce the time a biologisthas to spend browsing different WWW sites or databases in search for a particular piece ofinformation. In this study we point out the specific problems that molecular biology is posingto data integration. We present our approach to cope with these problems. It is based on amediator architecture and uses query correspondence assertions (QCA) to describe sourcesin a flexible yet expressive manner. QCAs both capture content and query capabilities ofarbitrary data sources with respect to a federated schema. Based on such QCAs a mediatorcan answer queries against the federated schema by constructing semantically …,*,1999,6
Maintenance and mediation in federated databases,Ulf Leser,*,8th Workshop on Information Technology and Systems; Helsinki; Finland; TR-19; University of Jyvaeskylae,1998,6
Fast and accurate time series classification with weasel,Patrick Schäfer; Ulf Leser,Abstract Time series (TS) occur in many scientific and commercial applications; ranging fromearth surveillance to industry automation to the smart grids. An important type of TS analysisis classification; which can; for instance; improve energy load forecasting in smart grids bydetecting the types of electronic devices based on their energy consumption profilesrecorded by automatic sensors. Such sensor-driven applications are very oftencharacterized by (a) very long TS and (b) very large TS datasets needing classification.However; current methods to time series classification (TSC) cannot cope with such datavolumes at acceptable accuracy; they are either scalable but offer only inferior classificationquality; or they achieve state-of-the-art classification quality but cannot scale to large datavolumes. In this paper; we present WEASEL (Word ExtrAction for time SEries …,Proceedings of the 2017 ACM on Conference on Information and Knowledge Management,2017,5
Optimization of complex dataflows with user-defined functions,Astrid Rheinländer; ULF Leser; Goetz Graefe,Abstract In many fields; recent years have brought a sharp rise in the size of the data to beanalyzed and the complexity of the analysis to be performed. Such analyses are oftendescribed as dataflows specified in declarative dataflow languages. A key technique toachieve scalability for such analyses is the optimization of the declarative programs;however; many real-life dataflows are dominated by user-defined functions (UDFs) toperform; for instance; text analysis; graph traversal; classification; or clustering. This calls forspecific optimization techniques as the semantics of such UDFs are unknown to theoptimizer. In this article; we survey techniques for optimizing dataflows with UDFs. Weconsider methods developed over decades of research in relational database systems aswell as more recent approaches spurred by the popularity of Map/Reduce-style data …,ACM Computing Surveys (CSUR),2017,5
Alternative Routing: k-Shortest Paths with Limited Overlap,Theodoros Chondrogiannis; Panagiotis Bouros; Johann Gamper; Ulf Leser,Abstract Shortest path computation is a fundamental problem in road networks withapplication in various domains in research and industry. However; returning only theshortest path is often not satisfying; users are also interested in alternative paths which mightbe longer but have other advantages; eg; less frequent traffic congestion. In this paper; weformally introduce the k-Shortest Paths with Limited Overlap (k-SPwLO) problem seeking torecommend k alternative paths which are (a) as short as possible and (b) sufficientlydissimilar based on a user-controlled similarity threshold. We propose two algorithms thatexamine the paths from a source s to a target t in increasing order of their length andprogressively construct the result set. The baseline algorithm BSL builds upon a standardalgorithm for computing k-Shortest Paths; followed by a filter step. The OnePass algorithm …,SIGSPATIAL,2016,5
Massively Parallel Analysis of Similarity Matrices on Heterogeneous Hardware.,Tobias Rawald; Mike Sips; Norbert Marwan; Ulf Leser,ABSTRACT We conduct a study that investigates the performance characteristics of a set ofparallel implementations of the recurrence quantification analysis (RQA) using OpenCL.Being an important tool in climate impact and medical research; a central aspect of RQA isthe construction of a binary matrix that captures the similarities of multi-dimensional vectors.Based on this matrix; quantitative measures are derived. Starting with a baselineimplementation; we diversify its properties along four dimensions: the representation of inputdata; the materialisation of the similarity matrix; the representation of similarity values andthe recycling of intermediate results. We evaluate the performance of five implementationsby varying the input parameter assignments; the hardware platform employed for executionand the default OpenCL compiler optimisations status. We come to the conclusion that the …,EDBT/ICDT Workshops,2015,5
Fast Sampling-based Whole-Genome Haplotype Block Recognition,Daniel Taliun; Johann Gamper; Ulf Leser; Cristian Pattaro,Scaling linkage disequilibrium (LD) based haplotype block recognition to the entire humangenome has always been a challenge. The best-known algorithm has quadratic runtimecomplexity and; even when sophisticated search space pruning is applied; still requiresseveral days of computations. Here; we propose a novel sampling-based algorithm; called S-MIG $^{++} $; where the main idea is to estimate the area that most likely contains allhaplotype blocks by sampling a very small number of SNP pairs. A subsequent refinementstep computes the exact blocks by considering only the SNP pairs within the estimated area.This approach significantly reduces the number of computed LD statistics; making therecognition of haplotype blocks very fast. We theoretically and empirically prove that thearea containing all haplotype blocks can be estimated with a very high degree of certainty …,IEEE Transactions on Bioinformatics and Computational Biology,2015,5
Learning to extract protein–protein interactions using distant supervision,Philippe Thomas; Illés Solt; Roman Klinger; Ulf Leser,Abstract Most relation extraction methods; especially in the domain of biology; rely onmachine learning methods to classify a cooccurring pair of entities in a sentence to berelated or not. Such an approach requires a training corpus; which involves expertannotation and is tedious; timeconsuming; and expensive. We overcome this problem by theuse of existing knowledge in structured databases to automatically generate a trainingcorpus for protein-protein interactions. An extensive evaluation of different instance selectionstrategies is performed to maximize robustness on this presumably noisy resource.Successful strategies to consistently improve performance include a majority votingensemble of classifiers trained on subsets of the training corpus and the use of knowledgebases consisting of proven non-interactions. Our best configured model built without …,ROBUS 2011,2011,5
Scalable sequence similarity search and join in main memory on multi-cores,Astrid Rheinländer; Ulf Leser,Abstract Similarity-based queries play an important role in many large scale applications. Inbioinformatics; DNA sequencing produces huge collections of strings; that need to becompared and merged. We present PeARL; a data structure and algorithms for similarity-based queries on many-core servers. PeARL indexes large string collections in compressedtries which are entirely held in main memory. Parallelization of searches and joins isperformed using MapReduce as the underlying execution paradigm. We show that our datastructure is capable of performing many real-world applications in sequence comparisons inmain memory. Our evaluation reveals that PeARL reaches a significant performance gaincompared to single-threaded solutions. However; the evaluation also shows that scalabilityshould be further improved; eg; by reducing sequential parts of the algorithms.,European Conference on Parallel Processing,2011,5
Pepper: Handling a multiverse of formats,Florian Zipser; Amir Zeldes; Julia Ritz; Laurent Romary; Ulf Leser,With the rising importance of empirical data in many fields of linguistic research; we see anincrease not only in the amount of electronically available corpora; but also in the number oftools used to make this data accessible; processable and searchable. Most of these toolshave been developed in the course of specific linguistic projects and therefore can onlyhandle a certain kinds of linguistic information; such as syntactic-structures (egTIGERSearch; Lezius 2002); or dialogue-structures (eg EXMARaLDA; Schmidt 2004) etc. Atthe same time; each tool uses its own; proprietary format for representing the text and itsannotations. Such formats are optimized for a specific kind of analysis and the performanceof a specific processing tool. Consequently they cannot easily be mapped onto each other.This impedes those linguistic research questions which pre-suppose a global view on …,Poster presented at,2011,5
PiPa: Custom Integration of Protein Interactions and Pathways,Sebastian Arzt; Johannes Starlinger; Oliver Arnold; Stefan Kröger; Samira Jaeger; Ulf Leser,Abstract: Information about proteins and their relationships to each other are a commonsource of input for many areas of Systems Biology; such as protein function prediction;relevance-ranking of disease genes and simulation of biological networks. While there arenumerous databases that focus on collecting such data from; for instance; literature curation;expert knowledge; or experimental studies; their individual coverage is often low; making thebuilding of an integrated protein-protein interaction database a pressing need. Accordingly;a number of such systems have emerged. But in most cases their content is only accessibleover the web on a per-protein basis; which renders them useless for automatic analysis ofsets of proteins. Even if the databases are available for download; often certain data sourcesare missing (eg because redistribution is forbidden by license); and update intervals are …,Workshop Daten In den Lebenswissenschaften; Berlin; Germany,2011,5
A fast and effective dependency graph kernel for PPI relation extraction,Domonkos Tikk; Peter Palaga; Ulf Leser,Background Extraction of protein-protein interactions (PPIs) reported in scientificpublications is a core topic of biomedical text mining. The ultimate goal is to devise a PPIextraction method that performs well on large amount of unseen text independently from thetraining corpus. One popular; machine-learning based approach to PPI extraction builds onthe convolution kernels; ie; similarity functions defined on the parse-based representation ofsentences and interactions. Kernel functions differ in (1) the underlying sentencerepresentation (bag-of-words; syntax tree parse; dependency graphs);(2) the substructuresretrieved from the sentence representation to define interactions; and (3) calculation of thesimilarity function. Method We present a novel kernel method called k-band shortest pathspectrum kernel (kBSPS); an extension of the spectrum tree kernel (SpT)[1]. It combines …,BMC bioinformatics,2010,5
Geneview–gene-centric ranking of biomedical text,Philippe Thomas; Johannes Starlinger; Christoph Jacob; Illés Solt; Jörg Hakenberg; Ulf Leser,Abstract Background: Life scientists spend a great amount of time searching for gene-specific information. It is widely acknowledged that research results are primarily publishedin scientific literature and current curation efforts can not keep up with the fast increase ofsuch literature. It can therefore be estimated that the plethora of gene-specific knowledge isstill hidden in large text repositories like MEDLINE. Searching text data sources is difficult; asuser queries are usually ambiguous and lead to hundreds of results. Faced with such anumber of relevant publications; an appropriate article ranking is important. PubMed; forexample; ranks articles per default by indexing date; making it difficult to find seminal papersabout a specific topic. In this paper; we introduce GeneView; a genecentric text miningapplication capable of searching; ranking; and visualizing biomedical publications …,Proc. of the BioCreative III Workshop,2010,5
Analysis of Affymetrix exon arrays,Karin Zimmermann; Ulf Leser,Exon arrays enable the monitoring of expression on a more fine-grained level thanconventional 3'arrays. By targeting single exons alternative splicing events can be detected.However; the increased amount of data resulting from the denser coverage of thetranscribed regions gives rise to new challenges in data analysis compared to 3'arrays. Onemust carefully decide which probes are considered for the final analysis to avoidmeasurements that are not reflecting biological reality. The most outstanding differencebetween gene level and exon level analysis emerges in the detection of differentialexpression. To decide whether an exon is differentially expressed between two conditions itmust be set in relation to its corresponding gene. Therefore; completely new algorithmsneed to be applied. This work gives an overview on the analysis of Affymetrix exon arrays …,*,2010,5
Consensus pattern alignment to find protein-protein interactions in text,Jörg Hakenberg; Michael Schroeder; Ulf Leser,Methods The system we propose falls into two components: searching sentences thatcontain two identified proteins and searching for PPIs described in these sentences. Theinitial recognition of protein names is based on a dictionary derived from UniProt (proteinnames; gene names and respective synonyms). The identification is a variation of thesystem we presented for the GN task (see elsewhere in this proceedings). The extraction ofPPIs builds on ideas presented with the Ali Baba tool [3].,Proceedings of the Second BioCreative Challenge Workshop-Critical Assessment of Information Extraction in Molecular Biology,2007,5
A structural keystone for drug design,Kristian Rother; Mathias Dunkel; Elke Michalsky; Silke Trissl; Andrean Goede; Ulf Leser; Robert Preissner,Abstract 3D-structures of proteins and potential ligands are the cornerstones of rational drugdesign. The first brick to build upon is selecting a protein target and finding out whetherbiologically active compounds are known. Both tasks require more information than thestructures themselves provide. For this purpose we have built a web resource bridgingprotein and ligand databases. It consists of three parts: i) A data warehouse on annotation ofprotein structures that integrates many well-known databases such as Swiss-Prot; SCOP;ENZYME and others. ii) A conformational library of structures of approved drugs. iii) Aconformational library of ligands from the PDB; linking the realms of proteins and smallmolecules.,Journal of Integrative Bioinformatics (JIB),2006,5
Storing and querying historical texts in a relational database,Lukas C Faulstich; Ulf Leser; Anke Lüdeling,Diese Arbeit beschreibt einen Ansatz für die Speicherung und Anfrage eines großen Korpuslinguistisch annotierter historischer Texte mit Hilfe eines relationalen Datenbanksystems.Texte in solch einem Korpus haben eine reichhaltige Struktur bestehend aus mehreren Text-Ebenen die detailliert annotiert und miteinander aligniert sein können. Die Modellierung undVerwaltung solcher Korpora bereitet diverse Herausforderungen; die bei einfacherenTextsammlungen nicht auftreten. Eine besondere Herausforderung ist das Design und dieImplementierung einer geeigneten Anfragesprache für solche komplexenAnnotationsstrukturen. In diesem Bericht beschreiben wir erste Schritte in diese Richtung.Wir stellen ein Datenmodell und Speicherkonzept für beliebig komplexe linguistischeAnnotationsschemata über in unterschiedlichsten Transliterationen und Varianten …,*,2005,5
How to improve information extraction from German medical records,Johannes Starlinger; Madeleine Kittner; Oliver Blankenstein; Ulf Leser,Abstract Vast amounts of medical information are still recorded as unstructured text. Theknowledge contained in this textual data has a great potential to improve clinical routinecare; to support clinical research; and to advance personalization of medicine. To accessthis knowledge; the underlying data has to be semantically integrated–an essentialprerequisite to which is information extraction from clinical documents.,it-Information Technology,2017,4
DNA copy number changes define spatial patterns of heterogeneity in colorectal cancer,Soulafa Mamlouk; Liam Harold Childs; Daniela Aust; Daniel Heim; Friederike Melching; Cristiano Oliveira; Thomas Wolf; Pawel Durek; Dirk Schumacher; Hendrik Bläker; Moritz Von Winterfeld; Bastian Gastl; Kerstin Möhr; Andrea Menne; Silke Zeugner; Torben Redmer; Dido Lenze; Sascha Tierling; Markus Möbs; Wilko Weichert; Gunnar Folprecht; Eric Blanc; Dieter Beule; Reinhold Schäfer; Markus Morkel; Frederick Klauschen; Ulf Leser; Christine Sers,Abstract Genetic heterogeneity between and within tumours is a major factor determiningcancer progression and therapy response. Here we examined DNA sequence and DNAcopy-number heterogeneity in colorectal cancer (CRC) by targeted high-depth sequencingof 100 most frequently altered genes. In 97 samples; with primary tumours and matchedmetastases from 27 patients; we observe inter-tumour concordance for coding mutations; incontrast; gene copy numbers are highly discordant between primary tumours andmetastases as validated by fluorescent in situ hybridization. To further investigate intra-tumour heterogeneity; we dissected a single tumour into 68 spatially defined samples andsequenced them separately. We identify evenly distributed coding mutations in APC andTP53 in all tumour areas; yet highly variable gene copy numbers in numerous genes. 3D …,Nature communications,2017,4
Recognizing chemicals in patents: a comparative analysis,Maryam Habibi; David Luis Wiegandt; Florian Schmedding; Ulf Leser,Abstract Recently; methods for Chemical Named Entity Recognition (NER) have gainedsubstantial interest; driven by the need for automatically analyzing todays ever growingcollections of biomedical text. Chemical NER for patents is particularly essential due to thehigh economic importance of pharmaceutical findings. However; NER on patents hasessentially been neglected by the research community for long; mostly because of the lackof enough annotated corpora. A recent international competition specifically targeted thistask; but evaluated tools only on gold standard patent abstracts instead of full patents;furthermore; results from such competitions are often difficult to extrapolate to real-lifesettings due to the relatively high homogeneity of training and test data. Here; we evaluatethe two state-of-the-art chemical NER tools; tmChem and ChemSpot; on four different …,Journal of cheminformatics,2016,4
Comparative assessment of differential network analysis methods,Yvonne Lichtblau; Karin Zimmermann; Berit Haldemann; Dido Lenze; Michael Hummel; Ulf Leser,Abstract Differential network analysis (DiNA) denotes a recent class of network-basedBioinformatics algorithms which focus on the differences in network topologies between twostates of a cell; such as healthy and disease; to identify key players in the discriminatingbiological processes. In contrast to conventional differential analysis; DiNA identifieschanges in the interplay between molecules; rather than changes in single molecules. Thisability is especially important in cases where effectors are changed; eg mutated; but theirexpression is not. A number of different DiNA approaches have been proposed; yet acomparative assessment of their performance in different settings is still lacking. In thispaper; we evaluate 10 different DiNA algorithms regarding their ability to recover genetic keyplayers from transcriptome data. We construct high-quality regulatory networks and enrich …,Briefings in bioinformatics,2016,4
SCARE – The Sentiment Corpus of App Reviews with Fine-grained Annotations in German,Mario Sänger; Ulf Leser; Steffen Kemmerer; Peter Adolphs; Roman Klinger,Abstract The automatic analysis of texts containing opinions of users about; eg; products orpolitical views has gained attention within the last decades. However; previous work on thetask of analyzing user reviews about mobile applications in app stores is limited. Publiclyavailable corpora do not exist; such that a comparison of different methods and models isdifficult. We fill this gap by contributing the Sentiment Corpus of App Reviews (SCARE);which contains fine-grained annotations of application aspects; subjective (evaluative)phrases and relations between both. This corpus consists of 1;760 annotated applicationreviews from the Google Play Store with 2;487 aspects and 3;959 subjective phrases. Wedescribe the process and methodology how the corpus was created. The Fleiss-κ betweenfour annotators reveals an agreement of 0.72. We provide a strong baseline with a linear …,Int. Conf. on Language Resources and Evaluation,2016,4
On-demand indexing for referential compression of DNA sequences,Fernando Alves; Vinicius Cogo; Sebastian Wandelt; Ulf Leser; Alysson Bessani,The decreasing costs of genome sequencing is creating a demand for scalable storage andprocessing tools and techniques to deal with the large amounts of generated data.Referential compression is one of these techniques; in which the similarity between the DNAof organisms of the same or an evolutionary close species is exploited to reduce the storagedemands of genome sequences up to 700 times. The general idea is to store in thecompressed file only the differences between the to-be-compressed and a well-knownreference sequence. In this paper; we propose a method for improving the performance ofreferential compression by removing the most costly phase of the process; the completereference indexing. Our approach; called On-Demand Indexing (ODI) compresses humanchromosomes five to ten times faster than other state-of-the-art tools (on average); while …,PloS one,2015,4
SOFA: An Extensible Logical Optimizer for UDF-heavy Dataflows,Astrid Rheinländer; Arvid Heise; Fabian Hueske; Ulf Leser; Felix Naumann,Abstract: Recent years have seen an increased interest in large-scale analytical dataflowson non-relational data. These dataflows are compiled into execution graphs scheduled onlarge compute clusters. In many novel application areas the predominant building blocks ofsuch dataflows are user-defined predicates or functions (UDFs). However; the heavy use ofUDFs is not well taken into account for dataflow optimization in current systems. SOFA is anovel and extensible optimizer for UDF-heavy dataflows. It builds on a concise set ofproperties for describing the semantics of Map/Reduce-style UDFs and a small set of rewriterules; which use these properties to find a much larger number of semantically equivalentplan rewrites than possible with traditional techniques. A salient feature of our approach isextensibility: We arrange user-defined operators and their properties into a subsumption …,arXiv preprint arXiv:1311.6335,2013,4
Experiences from Developing the Domain-Specific Entity Search Engine GeneView.,Philippe E Thomas; Johannes Starlinger; Ulf Leser,Abstract:. GeneView is a semantic search engine for the Life Sciences. Unlike traditionalsearch engines; GeneView searches indexed documents not only at the textual (syntactic)level; but analyzes texts upon import to recognize and properly handle biomedical entities;relationships between those entities; and the structure of documents. This allows for anumber of advanced features required to work effectively with scientific texts; such asprecise search despite large numbers of synonyms and homonyms; entity disambiguation;ranking of documents by entity content; linking to structured knowledge about entities; user-friendly highlighting of recognized entities etc. As of now; GeneView indexes approximately~21; 4 million abstracts and~ 358.000 full texts with more than 200 Million entities of 11different types and more than 100;000 relationships of three different types. In this paper …,BTW,2013,4
Word sense disambiguation in biomedical applications: A machine learning approach,Torsten Schiemann; Ulf Leser; Jörg Hakenberg,Ambiguity is a common phenomenon in text; especially in the biomedical domain. Forinstance; it is frequently the case that a gene; a protein encoded by the gene; and a diseaseassociated with the protein share the same name. Resolving this problem; that is; assigningto an ambiguous word in a given context its correct meaning is called word sensedisambiguation (WSD). It is a pre-requisite for associating entities in text to externalidentifiers and thus to put the results from text mining into a larger knowledge framework. Inthis chapter; we introduce the WSD problem and sketch general approaches for solving it.The authors then describe in detail the results of a study in WSD using classification. Foreach sense of an ambiguous term; they collected a large number of exemplary textsautomatically and used them to train an SVM-based classifier. This method reaches a …,Information Retrieval in Biomedicine: Natural Language Processing for Knowledge Integration. Hershey; PA; USA: IGI Global,2009,4
Graph management in the life sciences,Ulf Leser; Silke Triβl,A simple definition is that gazetteers are dictionaries of placenames. The digital gazetteer asa component of georeferenced information systems; however; is more formally modeled. Agazetteer is defined as a collection of gazetteer entries; each of which contains; at aminimum; the tuple N; F; T where N is a place name; F is a formal expression of geographiclocation–a footprint; and T is a place type expressed with a term (or code) from a typingscheme. Applications often require; in addition; relationships between gazetteer entries;documentation of time frames; and additional information (as described below). Thegazetteer model is a type of knowledge organization system (KOS)–or ontology–which canbe modified to represent other classes of spatial-temporal information; such as named timeperiods and named events [3].,*,2009,4
On the distance of databases,Heiko Müller; Johann Christoph Freytag; Ulf Leser,We study the novel problem of efficiently computing the update distance for a pair ofrelational databases. In analogy to the edit distance of strings; we define the update distanceof two databases as the minimal number of set-oriented insert; delete and modificationoperations necessary to transform one database into the other. We show how this distancecan be computed by traversing a search space of database instances connected by updateoperations. This insight leads to a family of algorithms that compute the update distance orapproximations of it. In our experiments we observed that a simple heuristic performssurprisingly well in most considered cases. Our motivation for studying distance measuresfor databases stems from the field of scientific databases. There; replicas of a singledatabase are often maintained at different sites; which typically leads to (accidental or …,*,2006,4
Implementing a linguistic query language for historic texts,Lukas C Faulstich; Ulf Leser; Thorsten Vitt,Abstract We describe the design and implementation of the linguistic query languageDDDquery. This language aims at querying a large linguistic database storing a corpus ofrichly annotated historic German texts. We use a graph-based data model that supportsmultiple independent annotation layers on a shared text layer as well as alignments of textlayers representing the same text or related texts (eg; translations). The corpus is stored inan object-relational database system with a text retrieval extension. DDDquery is based onXPath to leverage the familiarity of many users with this language. It is translated to SQL in atwo phase compilation with first order logic as an intermediate language. This approacheffectively decouples the query language from the schema of the underlying corpus. Weprovide an overview of DDDquery; the underlying ODAG data model; its implementation …,International Conference on Extending Database Technology,2006,4
GandrKB—ontological microarray annotation and visualization,Daniel Schober; Ulf Leser; Martin Zenke; Jens Reich,Abstract Summary: The Gandr (gene annotation data representation) knowledgebase is anontological framework for laboratory-specific gene annotation. Gandr uses Protégé 2000 forediting; querying and visualizing microarray data and annotations. Genes can be annotatedwith provided; newly created or imported ontological concepts. Annotated genes can inheritassigned concept properties and can be related to each other. The resulting knowledgebasecan be visualized as interactive network of nodes and edges representing genes and theirfunctional relationships. This allows for immediate and associative gene context exploration.Ontological query techniques allow for powerful data access. Availability: GandrKB isplatform independent and available free of charge either as web-application or as downloadfrom http://www. bioinf. mdc-berlin. de Contact: schober@ mdc-berlin. de Supplementary …,Bioinformatics,2005,4
Storing and Querying Historical Texts in a Database,Lukas C Faulstich; Ulf Leser; Anke Lüdeling,*,*,2005,4
Erkennen und Bereinigen von Datenfehlern in naturwissenschaftlichen Daten.,Heiko Müller; Melanie Weis; Jens Bleiholder; Ulf Leser,Die Ausführung zusätzlicher Experimente ist aber vergleichsweise teuer und unterUmständen auch unmöglich. Im naturwissenschaftlichen Bereich kommt es uns dabeizugute; dass weltweit unterschiedliche Arbeitsgruppen oftmals eine teilweise odervollständig überlappende Menge an Objekten untersuchen; wie zB eine bestimmteProteinfamilie oder das gleiche Genom. Es handelt sich dabei sowohl um die Ausführungvon Experimenten als auch um die überlappende Auswertung experimenteller Ergebnisse.Dies erfolgt häufig unter Ausnutzung unterschiedlicher Techniken und Reagenzien. Somitstehen oftmals genügend überlappende Datensätze bereit. In einigen Fällen können unterAusnutzung von Domänenwissen die benötigten Daten aus existierenden Daten abgeleitetwerden; wie dies in [Müller 2003] zur Korrektur fehlerhaft annotierter Startpositionen der …,Datenbank-Spektrum,2005,4
Reflection of successful anticancer drug development processes in the literature,Fabian Heinemann; Torsten Huber; Christian Meisel; Markus Bundschus; Ulf Leser,The development of cancer drugs is time-consuming and expensive. In particular; failures inlate-stage clinical trials are a major cost driver for pharmaceutical companies. This puts ahigh demand on methods that provide insights into the success chances of new potentialmedicines. In this study; we systematically analyze publication patterns emerging along thedrug discovery process of targeted cancer therapies; starting from basic research to drugapproval–or failure. We find clear differences in the patterns of approved drugs comparedwith those that failed in Phase II/III. Feeding these features into a machine learning classifierallows us to predict the approval or failure of a targeted cancer drug significantly better thaneducated guessing. We believe that these findings could lead to novel measures forsupporting decision making in drug development.,Drug discovery today,2016,3
Potential and Pitfalls of Domain-Specific Information Extraction at Web Scale,Astrid Rheinländer; Mario Lehmann; Anja Kunkel; Jörg Meier; Ulf Leser,Abstract In many domains; a plethora of textual information is available on the web as newsreports; blog posts; community portals; etc. Information extraction (IE) is the defaulttechnique to turn unstructured text into structured fact databases; but systematically applyingIE techniques to web input requires highly complex systems; starting from focused crawlersover quality assurance methods to cope with the HTML input to long pipelines of naturallanguage processing and IE algorithms. Although a number of tools for each of these stepsexists; their seamless; flexible; and scalable combination into a web scale end-to-end textanalytics system still is a true challenge. In this paper; we report our experiences frombuilding such a system for comparing the" web view" on health related topics with thatderived from a controlled scientific corpus; ie; Medline. The system combines a focused …,SIGMOD,2016,3
Sequence factorization with multiple references,Sebastian Wandelt; Ulf Leser,The success of high-throughput sequencing has lead to an increasing number of projectswhich sequence large populations of a species. Storage and analysis of sequence data is akey challenge in these projects; because of the sheer size of the datasets. Compression isone simple technology to deal with this challenge. Referential factorization and compressionschemes; which store only the differences between input sequence and a referencesequence; gained lots of interest in this field. Highly-similar sequences; eg; Humangenomes; can be compressed with a compression ratio of 1;000: 1 and more; up to twoorders of magnitude better than with standard compression techniques. Recently; it wasshown that the compression against multiple references from the same species can boostthe compression ratio up to 4;000: 1. However; a detailed analysis of using multiple …,PloS one,2015,3
Versatile optimization of UDF-heavy data flows with Sofa,Astrid Rheinländer; Martin Beckmann; Anja Kunkel; Arvid Heise; Thomas Stoltmann; Ulf Leser,Abstract Currently; we witness an increased interest in large-scale analytical data flows onnon-relational data. The predominant building blocks of such data flows are user-definedfunctions (UDFs); a fact that is not well taken into account for data flow language design andoptimization in current systems. In this demonstration; we present Meteor; a declarative dataflow language; and Sofa; a logical optimizer for UDF-heavy data flows; which are both part ofthe Stratosphere system. Meteor queries seamlessly combine self-descriptive; domain-specific operators with standard relational operators. Such queries are optimized by Sofa;building on a concise set of UDF annotations and a small set of rewrite rules to enablesemantically equivalent plan rewriting of UDF-heavy data flows. A salient feature of Meteorand Sofa is extensibility: User-defined operators and their properties are arranged into a …,Proceedings of the 2014 ACM SIGMOD International Conference on Management of Data,2014,3
Comprehensive benchmark of gene ontology concept recognition tools,Christoph Jacob; Philippe Thomas; Ulf Leser,Abstract The Gene Ontology has evolved as the de facto standard for describing genefunction in the biomedical domain. Information about gene function can be often found inwritten articles. In this work we evaluate three tools capable of recognizing Gene Ontologyconcepts in text on an automatically generated gold standard of 88;573 articles. Theanalysis reveals differences in concept recognition for these tools. An ensemble basedapproach is implemented to exploit idiosyncrasies between different tools and substantiallyimproves recognition quality.,Proceedings of BioLINK Special Interest Group. Berlin; Germany: Proceedings of BioLINK SIG,2013,3
Exploiting scientific workflows for large-scale gene expression data analysis,Alessandro De Stasio; Marcus Ertelt; Wolfgang Kemmner; Ulf Leser; Michele Ceccarelli,Microarrays are state technologies of the art for the measurement of expression ofthousands of genes in a single experiment. The treatment of these data are typicallyperformed with a wide range of tools; but the understanding of complex biological system bymeans of gene expression usually requires integrating different types of data from multiplesources and different services and tools. Many efforts are being developed on the new areaof scientific workflows in order to create a technology that links both data and tools to createworkflows that can easily be used by researchers. Currently technologies in this area aren'tmature yet; making arduous the use of these technologies by the researcher. In this paperwe present an architecture that helps the researchers to make large-scale gene expressiondata analysis with cutting edge technologies. The main underlying idea is to automate …,Computer and Information Sciences; 2009. ISCIS 2009. 24th International Symposium on,2009,3
Data Integration in the Life Sciences (3 conf.),Ulf Leser; Felix Naumann; Barbara Eckman,Data management and data integration are fundamental problems in the life sciences.Advances in molecular biology and molecular medicine are almost universally underpinnedby enormous efforts in data management; data integration; automatic data qualityassurance; and computational data analysis. Many hot topics in the life sciences; such assystems biology; personalized medicine; and pharmacogenomics; critically depend onintegrating data sets and applications produced by different experimental methods; indifferent research groups; and at different levels of granularity. Despite more than a decadeof intensive research in these areas; there remain many unsolved problems. In somerespects; these problems are becoming more severe; both due to continuous increases indata volumes and the growing diversity in types of data that need to be managed. And the …,*,2006,3
IRIS: a mediator-based approach achieving interoperability of web services in life science applications,Uwe Radetzki; Ulf Leser; Armin B Cremers,Web Services are loosely coupled software components that are published; located; andinvoked across the web. The growing number of web services raises new challenges;namely the discovery; composition; and integration of services required for a given task.Especially in life science applications the scenery is changing rapidly; with new servicesemerging and others being no longer maintained. For instance; the Molecular BiologyDatabase Collection (MBDC) has doubled the number of registered data and methodproviders in less than four years [2]; which makes the development of stable applicationsusing external web services a difficult task. On the other hand; biologists need severalinformation services and analyzing tools in their daily work. Due to heterogeneity; especiallyin semantic aspects; the current automatic interoperation of services still requires high …,3rd E-BioSci/ORIEL Annual Workshop,2004,3
Density Scores for Cooperative Query Answering.,Felix Naumann; Ulf Leser,Abstract Mediator-based information systems answer global queries by rewriting them into acombination of queries against physical data sources. One inherent assumption in mostsystems is that only a combination that satis es the global query completely is consideredvalid; ie; it must obtain values for each required attribute. Furthermore; most systems strivefor complete answers; ie; they try to access all relevant sources. These requirementsfrequently lead to a system behavior that entails a high potential for user frustration: In manyscenarios a partially incomplete answer is much more appreciated than no answer at all.Also; obtaining the data from all sources; which can be very costly; is often not necessary.Based on this observation; we developed a cooperative query planning method. For a givenquery; the set of data sources is selected based on density scores obeying a userde ned …,Föderierte Datenbanken,1999,3
Query Mediation for Heterogeneous Data Sources.,Ulf Leser,Abstract: We present a novel approach to the problem of query mediation in a tightfederation of heterogeneous; distributed data sources. It is based on query correspondenceassertions (QCAs); which are set-equation between conjunctive queries. We use them asrules to express relationships between heterogeneous and autonomously maintainedschemas. We describe an algorithm that uses QCAs to translate queries against the globalschema in semantically meaningful and minimal sequences of queries against data sources.A salient feature of our approach is that it is; due to the declarativeness of QCAs; relativelyeasy to react on schema changes in sources or on the global level. This supportsmaintainability; which we regard as a key requirement for large-scale projects in informationintegration.,Föderierte Datenbanken,1998,3
Estimating genome-wide regulatory activity from multi-omics data sets using mathematical optimization,Saskia Trescher; Jannes Münchmeyer; Ulf Leser,Gene regulation is one of the most important cellular processes; indispensable for theadaptability of organisms and closely interlinked with several classes of pathogenesis andtheir progression. Elucidation of regulatory mechanisms can be approached by a multitudeof experimental methods; yet integration of the resulting heterogeneous; large; and noisydata sets into comprehensive and tissue or disease-specific cellular models requiresrigorous computational methods. Recently; several algorithms have been proposed whichmodel genome-wide gene regulation as sets of (linear) equations over the activity andrelationships of transcription factors; genes and other factors. Subsequent optimization findsthose parameters that minimize the divergence of predicted and measured expressionintensities. In various settings; these methods produced promising results in terms of …,BMC systems biology,2017,2
Hi-WAY: Execution of Scientific Workflows on Hadoop YARN,Marc Bux; Jörgen Brandt; Carl Witt; Jim Dowling; Ulf Leser,*,Extending Database Technology (EDBT),2017,2
Cache-Sensitive Skip List: Efficient Range Queries on modern CPUs,Stefan Sprenger; Steffen Zeuch; Ulf Leser,Abstract Due to ever falling prices and advancements in chip technologies; many of today'sdatabases can be entirely kept in main memory. However; reusing existing disk-based indexstructures for managing data in memory leads to suboptimal performance due to inefficientcache usage and negligence of the capabilities of modern CPUs. Accordingly; a number ofmain-memory optimized index structures have been proposed; yet most of them focusentirely on single-key lookups; neglecting the equally important range queries. We presentCache-Sensitive Skip Lists (CSSL) as a novel index structure that is optimized for rangequeries and exploits modern CPUs. CSSL is based on a cache-friendly data layout andtraversal algorithm that minimizes cache misses; branch mispredictions; and allows toexploit SIMD instructions for search. In our experiments; CSSL's range query performance …,ADMS-IMDM workshop,2016,2
SoFIA: A Data Integration Framework for Annotating High-Throughput Data Sets,Liam Childs; Soulafa Mamlouk; Jörgen Brandt; Christine Sers; Ulf Leser,Abstract Motivation: Integrating heterogeneous datasets from several sources is a commonbioinformatics task that often requires implementing a complex workflow intermixingdatabase access; data filtering; format conversions; identifier mapping; among furtherdiverse operations. Data integration is especially important when annotating next generationsequencing data; where a multitude of diverse tools and heterogeneous databases can beused to provide a large variety of annotation for genomic locations; such a single nucleotidevariants or genes. Each tool and data source is potentially useful for a given project andoften more than one are used in parallel for the same purpose. However; software thatalways produces all available data is difficult to maintain and quickly leads to an excess ofdata; creating an information overload rather than the desired goal-oriented and …,Bioinformatics,2016,2
Algorithms for differential splicing detection using exon arrays: a comparative assessment,Karin Zimmermann; Marcel Jentsch; Axel Rasche; Michael Hummel; Ulf Leser,The analysis of differential splicing (DS) is crucial for understanding physiological processesin cells and organs. In particular; aberrant transcripts are known to be involved in variousdiseases including cancer. A widely used technique for studying DS are exon arrays. Overthe last decade a variety of algorithms for the detection of DS events from exon arrays hasbeen developed. However; no comprehensive; comparative evaluation including sensitivityto the most important data features has been conducted so far. To this end; we createdmultiple data sets based on simulated data to assess strengths and weaknesses of sevenpublished methods as well as a newly developed method; KLAS. Additionally; we evaluatedall methods on two cancer data sets that comprised RT-PCR validated results. Our studiesindicated ARH as the most robust methods when integrating the results over all scenarios …,BMC genomics,2015,2
QGramProjector: Q-gram projection for indexing highly-similar strings,Sebastian Wandelt; Ulf Leser,Abstract Q-gram (or n-gram; k-mer) models are used in many research areas; eg incomputational linguistics for statistical natural language processing; in computer science forapproximate string searching; and in computational biology for sequence analysis and datacompression. For a collection of N strings; one usually creates a separate positional q-gramindex structure for each string; or at least an index structure which needs roughly N times ofstorage compared to a single string index structure. For highly-similar strings; redundanciescan be identified; which do not need to be stored repeatedly; for instance two humangenomes have more than 99 percent similarity. In this work; we propose QGramProjector; anew way of indexing many highly-similar strings. In order to remove the redundanciescaused by similarities; our proposal is to 1) create all q-grams for a fixed reference; 2) …,East European Conference on Advances in Databases and Information Systems,2013,2
HistoNer: Histone modification extraction from text,Philippe Thomas; Ulf Leser,Abstract Systematic recognition of histone modifications in text is an important task to copewith the fast increase of biomedical literature. The high variability of phrases to expresshistone modifications renders keyword based search as insufficient for retrieval of histonemodifications. We present HistoNer; a rule based system for the recognition of histonemodifications from text. Pattern are collected semiautomatically and manually refined. With305 distinct pattern the system achieves an F1 measure of 93.6% on an unseen test set of1;000 annotated documents.,Proceedings of BioLINK SIG 2013,2013,2
InterOnto–Ranking Inter-Ontology Links,Silke Trißl; Philipp Hussels; Ulf Leser,Abstract Entries in biomolecular databases are often annotated with concepts from differentontologies and thereby establish links between pairs of concepts. Such links may revealmeaningful relationships between linked concepts; however they could as well relateconcepts by chance. In this work we present InterOnto; a methodology that allows us to rankconcept pairs to identify the most meaningful associations. The novelty of our approachcompared to previous works is that we take the entire structure of the involved ontologiesinto account. This way; our method even finds links that are not present in the annotateddata; but may be inferred through subsumed concept pairs. We have evaluated ourmethodology both quantitatively and qualitatively. Using real-life data from TAIR we showthat our proposed scoring function is able to identify the most representative concept pairs …,International Conference on Data Integration in the Life Sciences,2012,2
Molecular event extraction from Link Grammar parse trees in the BioNLP’09 Shared Task,Jörg Hakenberg; Illés Solt; Domonkos Tikk; Vo Há Nguyên; Luis Tari; Quang Long Nguyen; Chitta Baral; Ulf Leser,Abstract The BioNLP'09 Shared Task deals with extracting information on molecular events;such as gene expression and protein localization; from natural language text. Information inthis benchmark are given as tuples including protein names; trigger terms for each event;and possible other participants such as bindings sites. We address all three tasks ofBioNLP'09: event detection; event enrichment; and recognition of negation and speculation.Our method for the first two tasks is based on a deep parser; we store the parse tree of eachsentence in a relational database scheme. From the training data; we collect thedependencies connecting any two relevant terms of a known tuple; that is; the shortest pathslinking these two constituents. We encode all such linkages in a query language to retrievesimilar linkages from unseen text. For the third task; we rely on a hierarchy of hand-crafted …,Computational Intelligence,2011,2
Estimating Result Size and Execution Times for Graph Queries.,Silke Trißl; Ulf Leser,Abstract. In recent years several languages have been proposed to pose queries on graphs.These languages allow to state graph queries that contain multiple node and path variables.Nodes and paths of the graph are incrementally bound to these variables when evaluatingthe query. For an efficient execution the order of the bindings is important. To optimize thisorder we must be able to estimate the sizes of intermediate result sets and the time requiredto produce these. Therefore; in this paper we present estimation functions for reachabilityand path queries. We show that it is possible to estimate the sizes and times using easy topre-compute key features of a graph; such as number of nodes and edges; number of nodeswithout outgoing edges; and the outdegree of the node with highest degree.,ADBIS (Local Proceedings),2010,2
08131 Executive Summary--Ontologies and Text Mining for Life Sciences: Current Status and Future Perspectives,Michael Ashburner; Ulf Leser; Dietrich Rebholz-Schuhmann,Researchers in Text Mining and researchers active in developing ontological re- sources providesolutions to preserve semantic information properly; ie in ontologies and/or fact databases. Researchersfrom both fields tend to work independently from each other; but there is a shared interest to profitfrom ongoing research in the com- plementary domain. The relatedness of both domains hasled to the idea to organize a workshop that brings together members of both researchdomains … 2 The gap between Text Mining and ontologies … Life Science researchers delivertheir findings in scientific publications. These docu- ments are nowadays distributed electronicallyand increasingly processed by auto- matic means to also incorporate those findings and thedata into structured; scientific databases. Methods for this purpose are generally subsumed underthe term “Text Mining”; encompassing techniques belonging to the fields of machine …,Dagstuhl Seminar Proceedings,2008,2
Applying GRIPP to XML Documents containing XInclude and XLink Elements,Silke Trißl; Florian Zipser; Ulf Leser,Abstract: XML documents have an inherent tree structure well suited for reflectinghierarchical relationships in data. However; data often also contain relationships; which arenot hierarchical but; for instance; cyclic or many to many relationships. These relationshipsmay be modeled by embedding XInclude or XLink elements into an XML document.Unfortunately; XML query languages usually cannot cope very well with these references. Inthis paper; we evaluate the applicability of GRIPP; a graph indexstructure originallydeveloped for indexing large biological networks; for enhancing XML query processing overXInclude and XLink elements. We show how such XML queries can be represented asgraph queries and how they can be answered efficiently using GRIPP. Compared to XQueryformulations of such queries on top of the native XML database eXist; our approach …,Proceedings of the XML Tage,2007,2
Implementing Linguistic Query Languages Using LoToS,Lukas C Faulstich; Ulf Leser,A linguistic database is a collection of texts where sentences and words are annotated withlinguistic information; such as part of speech; morphology; and syntactic sentence structure.While early linguistic databases focused on word annotations; and later also on parse-treesof sentences (so-called treebanks); the recent years have seen a growing interest in richlyannotated corpora of historic texts that include not only syntactic annotations but furthercomplex annotations; such as alignments between related text layers. This raises the issueof efficiently querying such complex structured linguistic databases. We present a genericapproach for defining domain-specific query languages that we use in developing a querylanguage for richly annotated historic corpora. In our approach; a query language is definedas a set of predicates. A query in form of a logic rule is translated by our LoToS query …,*,2005,2
Data Mining and Text Mining for Bioinformatics,Tobias Scheffer; Ulf Leser,In the past years; research in molecular biology and molecular medicine has accumulatedenormous amounts of data. This includes genomic sequences gathered by the HumanGenome Project; gene expression data from microarray experiments; protein identificationand quantification data from proteomics experiments; and SNP data from high-throughputSNP arrays. However; our understanding of the biological processes underlying these datalags far behind. There is a strong interest in employing methods of knowledge discovery anddata mining to generate models of biological systems. Mining biological databases imposeschallenges which knowledge discovery and data mining have to address; and which formthe focus of the European Workshop on Data Mining and Text Mining for Bioinformatics.,Proceedings of the European Workshop on Data Mining and Text Mining for Bioinformatics,2003,2
Multivariate Time Series Classification with WEASEL+ MUSE,Patrick Schäfer; Ulf Leser,Abstract: Multivariate time series (MTS) arise when multiple interconnected sensors recorddata over time. Dealing with this high-dimensional data is challenging for every classifier forat least two aspects: First; a MTS is not only characterized by individual feature values; butalso by the co-occurrence of features in different dimensions. Second; this typically addslarge amounts of irrelevant data and noise. We present our novel MTS classifier WEASEL+MUSE (Word ExtrAction for time SEries cLassification+ MUltivariate Symbols anddErivatives) which addresses both challenges. WEASEL+ MUSE builds a multivariatefeature vector; first using a sliding-window approach applied to each dimension of the MTS;then extracts discrete features per window and dimension. The feature vector issubsequently fed through feature selection; removing non-discriminative features; and …,arXiv preprint arXiv:1711.11343,2017,1
Basal subtype is predictive for response to cetuximab treatment in patient derived xenografts of squamous cell head and neck cancer,Konrad Klinghammer; Raik Otto; Jan‐Dirk Raguse; Andreas E Albers; Ingeborg Tinhofer; Iduna Fichtner; Ulf Leser; Ulrich Keilholz; Jens Hoffmann,Abstract Cetuximab is the single targeted therapy approved for the treatment of head andneck cancer (HNSCC). Predictive biomarkers have not been established and patientstratification based on molecular tumor profiles has not been possible. Since EGFR pathwayactivation is pronounced in basal subtype; we hypothesized this activation could be apredictive signature for an EGFR directed treatment. From our patient derived xenograftplatform of HNSCC; 28 models were subjected to Affymetrix gene expression studies on HGU133+ 2.0. Based on the expression of 821 genes; the subtype of each of the 28 modelswas determined by integrating gene expression profiles through centroid-clustering withpreviously published gene expression data by Keck et al. The models were treated ingroups of 5-6 animals with docetaxel; cetuximab; everolimus; cis-or carboplatin and 5 …,International journal of cancer,2017,1
Robust in-silico identification of cancer cell lines based on next generation sequencing,Raik Otto; Christine Sers; Ulf Leser,Abstract Cancer cell lines (CCL) are important tools for cancer researchers world-wide.However; handling of cancer cell lines is error-prone; and critical errors such asmisidentification and cross-contamination occur more often than acceptable. Based on thefact that CCL today very often are sequenced (partly or entirely) anyway as part of thestudies performed; we developed Uniquorn; a computational method that reliably identifiesCCL samples based on variant profiles derived from whole exome or whole genomesequencing. Notably; Uniquorn does neither require a particular sequencing technology nordownstream analysis pipeline but works robustly across different NGS platforms andanalysis steps. We evaluated Uniquorn by comparing more than 1900 CCL profiles fromthree large CCL libraries; embracing 1585 duplicates; against each other. In this setting …,Oncotarget,2017,1
Multi-lingual ICD-10 coding using a hybrid rule-based and supervised classification approach at CLEF eHealth 2017,Jurica Ševa; Madeleine Kittner; Roland Roller; Ulf Leser,Abstract. In this paper we present our research efforts and obtained results within the CLEFeHealth challenge 2017; Track 1. The task involves the recognition and mapping of ICD-10codes to English and French death certificates. Our approach proposes a two tier; two stageprocess. First; we use a rule-based system; based on handcrafted rules and the use ofApache Solr; to perform ICD-10 code Named Entity Recognition (NER). This step producesa set of possible candidates extracted from the input text. Next; we use tf-idf weightedcharacter n-gram classification models to normalize and rank a previously generated ICD-10candidate set. Classification models used are generated and follow the hierarchicalstructure of the given ICD-10 dictionaries; by creating individual classification models for thefirst two hierarchical levels (chapters and blocks). Finally; the top candidate; generated …,*,2017,1
Scalability of Univariate Time Series Classifiers,Patrick Schäfer; Ulf Leser,*,Conf. on Databases in Business; Technology and the Web (BTW),2017,1
PIEJoin: Towards Parallel Set Containment Joins,Anja Kunkel; Astrid Rheinländer; Christopher Schiefer; Sven Helmer; Panagiotis Bouros; Ulf Leser,Abstract The efficient computation of set containment joins (SCJ) over set-valued attributes isa well-studied problem with many applications in commercial and scientific fields.Nevertheless; there still exists a number of open questions: An extensive comparativeevaluation is still missing; the two most recent algorithms have not yet been compared toeach other; and the exact impact of item sort order and properties of the data on algorithmsperformance still is largely unknown. Furthermore; all previous works only consideredsequential join algorithms; although modern servers offer ample opportunities forparallelization. We present PIEJoin; a novel algorithm for computing SCJ based onintersecting prefix trees built at runtime over the to-be-joined attributes. We also present ahighly optimized implementation of PIEJoin which uses tree signatures for saving space …,Proceedings of the 28th International Conference on Scientific and Statistical Database Management,2016,1
Performance of Gene Name Recognition Tools on Patents,Maryam Habibi; David Luis Wiegandt; Florian Schmedding; Ulf Leser,Abstract The accurate identification of gene and protein names in patents is an essentialstep in many commercially highly relevant applications; such as patent retrieval; prior artsearch; or patent classification. Since patents exhibit a number of properties that make themquite different from scientific articles; it is questionable whether tools developed for the lattersort of texts will work equally well for the former. Answering this question is aggravated bythe fact that only few annotated patent corpora exist which makes training hard. In this paper;we report on a comparative evaluation of four existing gene/protein named entity recognitionand normalization tools trained on scientific articles regarding their performance on the twopatent corpora. We analyze the tools with respect to different evaluation metrics to highlighttheir respective strengths and limitations. Our results reveal that the performances of …,Semantic Mining in Biomedicine (SMBM),2016,1
Data integration for identification of important transcription of STAT6-mediated cell fate decisions,Manja Jargosch; Stefan Kroeger; Elzbieta Gralinska; Ulrike Klotz; Zhuo Fang; Wei Chen; Ulf Leser; Joachim Selbig; Detlef Groth; Ria Baumgrass,ABSTRACT. Data integration has become a useful strategy for uncovering new insights intocomplex biological networks. We studied whether this approach can help to delineate thesignal transducer and activator of transcription 6 (STAT6)-mediated transcriptional networkdriving T helper (Th) 2 cell fate decisions. To this end; we performed an integrative analysisof publicly available RNA-seq data of Stat6-knockout mouse studies together with STAT6ChIP-seq data and our own gene expression time series data during Th2 cell differentiation.We focused on transcription factors (TFs); cytokines; and cytokine receptors and delineated59 positively and 41 negatively STAT6-regulated genes;,Genetics and Molecular Research,2016,1
RRCA: ultra-fast multiple in-species genome alignments,Sebastian Wandelt; Ulf Leser,Abstract Multiple sequence alignment is an important method in Bioinformatics; for instance;to reconstruct phylogenetic trees or for identifying functional domains within genes. Findingan optimal MSA is computationally intractable; and therefore many alignment heuristicswere proposed. However; computing MSA for sequences at chromosome/genome scale in areasonable time with good alignment results remains an open challenge. In this paper wepropose RRCA; a very fast method to compute high-quality in-species MSAs at genomescale. RRCA uses referential compression to efficiently find long common subsequences into-be-aligned sequences. A colinear sub collection of these subsequences is used for aninitial alignment and the not yet covered subsequences are aligned following the sameapproach recursively. Our evaluation shows that RRCA achieves MSAs at similar quality …,International Conference on Algorithms for Computational Biology,2014,1
Using ontologies to study cell transitions,Georg Fuellen; Ludger Jansen; Ulf Leser; Andreas Kurtz,Understanding; modelling and influencing the transition between different states of cells; beit reprogramming of somatic cells to pluripotency or trans-differentiation between cells; is ahot topic in current biomedical and cell-biological research. Nevertheless; the large body ofpublished knowledge in this area is underused; as most results are only represented innatural language; impeding their finding; comparison; aggregation; and usage. Scientificunderstanding of the complex molecular mechanisms underlying cell transitions could beimproved by making essential pieces of knowledge available in a formal (and thuscomputable) manner. We describe the outline of two ontologies for cell phenotypes and forcellular mechanisms which together enable the representation of data curated from theliterature or obtained by bioinformatics analyses and thus for building a knowledge base …,Journal of biomedical semantics,2013,1
Evaluation of the CellFinder pipeline in the BioCreative IV user interactive task,Mariana Neves; Julian Braun; Alexander Diehl; G Thomas Hayman; Shur-Jen Wang; Ulf Leser; Andreas Kurtz,Abstract We present results on the participation of the CellFinder text mining pipeline forcuration of gene/protein expression in anatomical parts in the BioCreative IV User Interactivetask. The pipeline integrates state-of-the-art and freely available tools for the following steps:triage of potentially relevant documents; retrieval of documents; preprocessing; named-entityrecognition; event extraction and a graphical user interface for manual validation of theresults. Four curators have been recruited for this evaluation and have suggested threetopics of interest: kidney-related diseases in rat; human dendritic cells and humanmesenchymal stem cells. Each curator validated gene/protein expression eventsautomatically extracted from 30 Medline abstracts. A total of 634 expression events wereobtained from the three datasets and approximately 35% of them (216 events) were …,Proceedings of the Fourth BioCreative Challenge Evaluation Workshop,2013,1
OmixAnalyzer–A Web-Based System for Management and Analysis of High-Throughput Omics Data Sets,Thomas Stoltmann; Karin Zimmermann; André Koschmieder; Ulf Leser,Abstract Current projects in Systems Biology often produce a multitude of different high-throughput data sets that need to be managed; processed; and analyzed in an integratedfashion. In this paper; we present the OmixAnalyzer; a web-based tool for management andanalysis of heterogeneous omics data sets. It currently supports gene microarrays; miRNAs;and exon-arrays; support for mass spectrometry-based proteomics is on the way; and furthertypes can easily be added due to its plug-and-play architecture. Distinct from competitorsystems; the OmixAnalyzer supports management; analysis; and visualization of data sets; itfeatures a mature system of access rights; handles heterogeneous data sets includingmetadata; supports various import and export formats; includes pipelines for performing allsteps of data analysis from normalization and quality control to differential analysis …,International Conference on Data Integration in the Life Sciences,2013,1
Text mining for characterizing cells and tissues,Mariana Neves; Alexander Damaschun; Nancy Mah; Fritz Lekschas; Stefanie Seltmann; Harald Stachelscheid; Jean-Fred Fontaine; Andreas Kurtz; Ulf Leser,Regenerative medicine is an important field for translational medical research provided itspotential for repair; restoration and replacement of tissues [1]. One of the requirement ofregenerative approaches is the well characterization of therapeutic cell populations basedon reliable measurement and analysis techniques. The biological scientific literaturecontains a huge number of citations on the expression of genes/proteins in a variety of celllines; cell types or tissues; for instance (PMID 20085633): Pros is never expressed in glialcells. In this work; we show that text mining can help characterizing cell and tissues and wedescribe the results we have achieved so far in the scope of the CellFinder database. TheCellFinder database1 is a repository of cell research which aims to integrate data derivedfrom many sources; such as literature curation and microarray data. As part of the text …,Proceedings of BioLINK SIG 2013,2013,1
Covering or complete? discovering conditional inclusion dependencies,Jana Bauckmann; Ziawasch Abedjan; Ulf Leser; Heiko Müller; Felix Naumann,Data dependencies; or integrity constraints; are used to improve the quality of a databaseschema; to optimize queries; and to ensure consistency in a database. In the last yearsconditional dependencies have been introduced to analyze and improve data quality. Inshort; a conditional dependency is a dependency with a limited scope defined by conditionsover one or more attributes. Only the matching part of the instance must adhere to thedependency. In this paper we focus on conditional inclusion dependencies (CINDs). Wegeneralize the definition of CINDs; distinguishing covering and completeness conditions.We present a new use case for such CINDs showing their value for solving complex dataquality tasks. Further; we define quality measures for conditions inspired by precision andrecall. We propose efficient algorithms that identify covering and completeness conditions …,*,2012,1
Equator: Faster decision making for geoscientists,Lars Döhling; Heiko Woith; Dirk Fahland; Ulf Leser,Abstract: Earthquakes form a permanent threat to humankind; causing death and injurieseach year. For this reason; studying earthquakes has become an important area of researchin geoscience. Responding to an earthquake event; for mitigation or for research purposes;demands quick decision processes which require timely and precise situational information.In this paper; we present Equator; a web-based content management system thatautomatically collects; integrates; and visualizes earthquake related information from variousagencies. Equator was developed to meet specific requirements of the German Task ForceEarthquake. It is in productive use by the Task Force since 2008 and proved to significantlyreduce time required for acquiring situational awareness.,Proceeding of Workshop on IT support for rescue teams,2011,1
Challenges in Automatic Diagnosis Extraction from Medical Examination Summaries,Johannes Starlinger; Bernd T Schmeck; Ulf Leser,Page 1. Challenges in Automatic Diagnosis Extraction from Medical Examination SummariesJohannes Starlinger Ulf Leser Bernd Schmeck Page 2. J. Starlinger Challenges in AutomaticDiagnosis Extraction from Medical Examination Summaries Agenda • Project background •Challenges in diagnosis-NER/NEN from examination summaries • Approach • Conclusions forthe medical web Page 3. J. Starlinger Challenges in Automatic Diagnosis Extraction from MedicalExamination Summaries Initial situation 3 BAL reports Clinical discharge summaries Page 4.J. Starlinger Challenges in Automatic Diagnosis Extraction from Medical Examination SummariesInitial situation 4 BAL reports Clinical discharge summaries http://www.scleroderma.org Page5. J. Starlinger Challenges in Automatic Diagnosis Extraction from Medical ExaminationSummaries Goal: Statistical Analysis of Data • Questions …,Web Science in the Medical Domain,2011,1
Ontologies improve cross-species phenotype analysis,Philip Groth; Bertram Weiss; Ulf Leser,ABSTRACT As phenotype data analysis has become an important component of functionalgenomics; many methods for analyzing these data have been published in the recent past.For example; RNA interference (RNAi) in mice has significantly improved our understandingof gene regulation; even for human disease. However; as phenotypes are obtained throughspecies-specific experiments; they are usually described with unstructured text using veryspecific terminology. Such descriptions lack a common vocabulary; ie a universal phenotypeontology. This heterogeneity considerably hampers the analysis of phenotypes acrossspecies. We have shown recently that clustering the free-text descriptions of phenotypes(phenoclustering) induces a clustering of genes that leads to gene function prediction withhigh precision. However; the method suffered from the fact that phenotypes of different …,Special Interest Group on Bioontologies: Semantic Applications in Life Sciences,2010,1
An urban health risk analysis for Berlin: exploration and integration of spatio-temporal information on the urban environment.,Tobia Lakes; Ulf Leser; Cornelius Senf,Abstract Urban areas provide the living space for the majority of the world population. Well-being and health within urban areas is influenced by environmental and socioeconomicvariables. To analyze the potential health risk in cities one has to integrate multi-dimensionaland multi-scale information describing socioeconomic; environmental and healthrelatedattributes. The aim of this paper is to study the urban health risk for different parts of the cityof Berlin using a data-driven analysis approach. We focus on the detection and explorationof correlations between environmental; socioeconomic and health-related attributes inBerlin. We showcase the further study of selected correlations; including the biophysical andsocioeconomic burden of certain diseases; and their visual exploration using advancedgeovisualization.,EnviroInfo,2010,1
Fast similarity searches and similarity joins in Oracle DB,Astrid Rheinländer; Ulf Leser,Similarity search and similarity join on strings are important operations for applications suchas duplicate detection; error detection; data cleansing; or comparison of biologicalsequences [GIJ+ 01; NMS04]. Especially DNA sequencing produces large collections oferroneous strings which need to be searched; compared; and merged. In our talk; we willuse ESTs as our running example. ESTs (Expressed Sequence Tags) are short DNAsequences with lengths mostly in the region of 300 to 800 bases that are commonly used toidentify genes and their localization on a chromosome. However; to be cost-effective; ESTsare obtained by a single sequencing pass which yields in an estimated error rate of1%[KA06]. This implies that searching and joining EST data sets should always be carriedout approximately rather than exactly. Since the EST sets that are considered go in the …,DOAG,2010,1
Classification of Contradiction Patterns,Heiko Müller; Ulf Leser; Johann-Christoph Freytag,Abstract Solving conflicts between overlapping databases requires an understanding of thereasons that lead to the inconsistencies. Provided that conflicts do not occur randomly butfollow certain regularities; patterns in the form of “If condition Then conflict” provide avaluable means to facilitate their understanding. In previous work; we adopt existingassociation rule mining algorithms to identify such patterns. Within this paper we discussextensions to our initial approach aimed at identifying possible update operations thatcaused the conflicts between the databases. This is done by restricting the items used forpattern mining. We further propose a classification of patterns based on mappings betweenthe contradicting values to represent special cases of conflict generating updates.,*,2007,1
Versionierung in relationalen Datenbanken.,Stephan Rieche; Ulf Leser,Zusammenfassung Für viele wissenschaftliche Anwendungen ist es wünschenswert;gleichzeitig auf verschiedene zeitliche Zustände einer Datenbank zuzugreifen; alsoverschiedene Versionen der Datenbank im Zugriff zu halten. HeutigeDatenbankmamagementsysteme unterstützen dies primär nicht. In der Arbeit werdenStrategien zur Versionierung relationaler Datenbanken untersucht. Aufbauend auf einerKlassifikation möglicher Definitionen des Begriffs Versionierung werden aussichtsreicheVorgehensweisen ausgewählt. Diese wurden implementiert und einer detailierten Analysebzgl. ihrer Performanz bei unterschiedlichen Operationen untersucht. Die Messungenzeigen; dass die gewählen Strategien in nahezu allen Belangen deutlich performanter alsein kommerzielles Versionierungssystem sind.,BTW Studierenden-Programm,2005,1
Cooperative Transaction Processing between Clients and Servers.,Steffen Jurk; Ulf Leser; José-Luis Marzo,Abstract. Business rules are often implemented as stored procedures in a database server.These procedures are triggered by various clients; but the execution load is fully centralizedon the server. We improve the overall response time and increase server throughput bybalancing this load between the server and the clients. In our novel scheme; parts of thestored procedures are executed on cached data at the client. The critical issue in such asystem is the trade-off between synchronization effort among clients and the server and theincrease in systems performance gained by load balancing. We present an architectureusing an optimistic synchronization protocol together with an algorithm for data verification atthe server. The experience we gained through a detailed case study; based on a real-lifeeCommerce application; shows that in many situations a considerable speed-up is …,ADBIS (Local Proceedings),2004,1
Integration durch Standards: Erfahrungen mit CORBA in Life Science Research.,Heiko Müller; Ulf Leser,Abstrakt: Der einheitliche Zugriff auf verteilte und autonome Datenquellen wird in vielenBereichen durch die vorhandene Heterogenität erheblich erschwert. Eine Möglichkeit zumUmgang mit dieser Heterogenität liegt in der Definition von geeigneten Zugriffsstandards.Dieser Weg wird beispielsweise von der OMG durch die Definition von Domainstandardsgefördert. In unserer Arbeit skizzieren wir Erfahrungen aus der Implementation undEvaluation eines vorgeschlagenen Standards für den Zugriff auf Genomkarten. Wirbeschreiben sowohl den vorgeschlagenen Standard als auch die einzelnen Schritte seinerUmsetzung auf eine existierende molekularbiologische Datenbank. Aus den dabeigewonnen Erfahrungen leiten wir eine Reihe von Verbesserungsvorschlägen ab.,Föderierte Datenbanken,1999,1
Maintenance and Mediation in Database Federations,Ulf Leser,*,WITS; Helsinki,1998,1
Mediator-basierte; heterogene verteilte Informationssysteme,Ulf Leser; Susanne Busse; Herbert Weber; Christoph Holzheuer; Holger Last; M Christian; Felix Naumann; Tom Ritter; Leon Rosenberg,Hier wird der Begri Schemaintegration ausschlie lich im Sinne der Datenbankintegrationverwendet; dh wir betrachten hier die Integration von strukturierten Daten; wie sie durchDatenbankschemata beschrieben werden. Die Anwendung der weiter unten vorgestelltenIntegrationsmethoden auf semistrukturierte Daten ist nicht vorgesehen. Sie w urdezumindest eine zus atzliche\Umsetzungsschicht" erfordern; die semistrukturierteDatenquellen auf wohlde nierte Schemata abbildet. Inwieweit die Schemaintegration imKontext semistrukturierter Daten sinnvoll ist; bleibt fraglich. Die im folgenden betrachtetenAnforderungen an ein globales; integriertes Schema liegen im Kon ikt mit der densemistrukturierten Daten innewohnenden Vagheit.,*,1998,1
Multidimensional Range Queries on Modern Hardware,Stefan Sprenger; Patrick Schäfer; Ulf Leser,Abstract: Range queries over multidimensional data are an important part of databaseworkloads in many applications. Their execution may be accelerated by usingmultidimensional index structures (MDIS); such as kd-trees or R-trees. As for most indexstructures; the usefulness of this approach depends on the selectivity of the queries; andcommon wisdom told that a simple scan beats MDIS for queries accessing more than 15%-20% of a dataset. However; this wisdom is largely based on evaluations that are almost twodecades old; performed on data being held on disks; applying IO-optimized data structures;and using single-core systems. The question is whether this rule of thumb still holds whenmultidimensional range queries (MDRQ) are performed on modern architectures with largemain memories holding all data; multi-core CPUs and data-parallel instruction sets. In this …,arXiv preprint arXiv:1801.03644,2018,*
Mouse Lymphoma Model-Based Senescence Exploitation to Predict Treatment Outcome of DLBCL Patients,Kolja Schleich; Julia Kase; Jan R Dörr; Saskia Trescher; Animesh Battacharya; Yong Yu; Philipp Lohneis; Dido Lenze; Dorothy Ngo-Yin Fan; Michael Hummel; Ulf Leser; Clemens A Schmitt,Introduction: Molecularly informed treatment decisions are the basis of personalized cancerprecision medicine. While gene expression profiling has been used to map the molecularlandscape of tumors and to study the impact of molecularly defined subtypes on treatmentoutcome; biological effector principles; specifically cellular senescence; remain largelyunderstudied. Syngeneic mouse models of cancer that recapitulate core molecular featuresof human malignancies could serve as useful models to explore mechanisms of drugsensitivity; and; likewise; to dissect molecular mechanisms of treatment failure. In particular;we focus here on the role of therapy-induced senescence; a histone H3 lysine 9trimethylation (H3K9me3)-governed terminal cell-cycle arrest program. Methods: The Eµ-myc transgenic lymphoma mouse was used as a cross-species model of …,*,2017,*
Mouse model-based investigations unveil senescence mediators that predict treatment outcome of DLBCL patients,K Schleich; J Kase; JR Doerr; S Trescher; A Battacharya; Y Yu; P Lohneis; D Lenze; DNY Fan; M Hummel; U Leser; CA Schmitt,*,ONCOLOGY RESEARCH AND TREATMENT,2017,*
Modeling Data Flow Execution in a Parallel Environment,Georgia Kougka; Anastasios Gounaris; Ulf Leser,Abstract Although the modern data flows are executed in parallel and distributedenvironments; eg on a multi-core machine or on the cloud; current cost models; eg; thoseconsidered by state-of-the-art data flow optimization techniques; do not accurately reflect theresponse time of real data flow execution in these execution environments. This is mainlydue to the fact that the impact of parallelism; and more specifically; the impact of concurrenttask execution on the running time is not adequately modeled. In this work; we propose acost modeling solution that aims to accurately reflect the response time of a data flow that isexecuted in parallel. We focus on the single multi-core machine environment provided bymodern business intelligence tools; such as Pentaho Kettle; but our approach can beextended to massively parallel and distributed settings. The distinctive features of our …,International Conference on Big Data Analytics and Knowledge Discovery,2017,*
Fine-grained Opinion Mining from Mobile App Reviews with Word Embedding Features,Mario Sänger; Ulf Leser; Roman Klinger,Abstract Existing approaches for opinion mining mainly focus on reviews from Amazon;domain-specific review websites or social media. Little efforts have been spent on fine-grained analysis of opinions in review texts from mobile smart phone applications. In thispaper; we propose an aspect and subjective phrase extraction model for German reviewsfrom the Google Play store. We analyze the impact of different features; including domain-specific word embeddings. Our best model configuration shows a performance of 0.63 F_1for aspects and 0.62 F_1 for subjective phrases. Further; we perform cross-domainexperiments: A model trained on Amazon reviews and tested on app reviews achieves lowerperformance (drop by 27% points for aspects and 15% points for subjective phrases). Theresults indicate that there are strong differences in the way personal opinions on product …,International Conference on Applications of Natural Language to Information Systems,2017,*
Fast and Accurate Time Series Classification with WEASEL,U Schäfer; P. and Leser,*,Int. Conf. on Information and Knowledge Management (CIKM),2017,*
Computation Semantics of the Functional Scientific Workflow Language Cuneiform.,U Brandt; J.; Reisig; W. and Leser,Abstract Cuneiform is a minimal functional programming language for large-scale scientificdata analysis. Implementing a strict black-box view on external operators and data; it allowsthe direct embedding of code in a variety of external languages like Python or R; providesdata-parallel higher order operators for processing large partitioned data sets; allowsconditionals and general recursion; and has a naturally parallelizable evaluation strategysuitable for multi-core servers and distributed execution environments like Hadoop;HTCondor; or distributed Erlang. Cuneiform has been applied in several data-intensiveresearch areas including remote sensing; machine learning; and bioinformatics; all of whichcritically depend on the flexible assembly of pre-existing tools and libraries written indifferent languages into complex pipelines. This paper introduces the computation …,Journal of Functional Programming,2017,*
graphANNIS: A Fast Query Engine for Deeply Annotated Linguistic Corpora.,A. Krause; T.; Leser; U. and Lüdeling,*,Language Technology and Computational Linguistics,2017,*
Exact and Approximate Algorithms for Finding k-Shortest Paths with Limited Overlap,Theodoros Chondrogiannis; Panagiotis Bouros; Johann Gamper; Ulf Leser,ABSTRACT Shortest path computation is a fundamental problem in road networks withvarious applications in research and industry. However; returning only the shortest path isoften not satisfying. Users might also be interested in alternative paths that are slightlylonger but have other desired properties; eg; less frequent traffic congestion. In this paper;we study alternative routing and; in particular; the k-Shortest Paths with Limited Overlap (k-SPwLO) query; which aims at computing paths that are (a) sufficiently dissimilar to eachother; and (b) as short as possible. First; we propose MultiPass; an exact algorithm whichtraverses the network k− 1 times and employs two pruning criteria to reduce the number ofpaths that have to be examined. To achieve better performance and scalability; we alsopropose two approximate algorithms that trade accuracy for efficiency. OnePass+ …,Extending Database Technology (EDBT),2017,*
Graph n-grams for Scientific Workflow Similarity Search,David Luis Wiegandt; Johannes Starlinger; Ulf Leser,Abstract. As scientific workflows increasingly gain popularity as a means of automated dataanalysis; the repositories such workflows are shared in have grown to sizes that requireadvanced methods for managing the workflows they contain. To facilitate clustering ofsimilar workflows as well as reuse of existing components; a similarity measure forworkflows is required. We explore a new structure-based approach to scientific workflowsimilarity assessment that measures similarity as the overlap in local structure patternsrepresented as n-grams. Our evaluation shows that this approach reaches state-of-the-artquality in scientific workflow comparison and outperforms some established scientificworkflow similarity measures.,LWDA,2016,*
A Study in Domain-Independent Information Extraction for Disaster Management,Lars Döhling; Jirka Lewandowski; Ulf Leser,Abstract During and after natural disasters; detailed information about their impact is a keyfor successful relief operations. In the 21st century; such information can be found on theWeb; traditionally provided by news agencies and recently through social media by affectedpeople themselves. Manual information acquisition from such texts requires ongoingreading and analyzing; a costly process with very limited scalability. Automatic extractionoffers fast information acquisition; but usually requires specifically trained extraction modelsbased on annotated data. Due to changes in the language used; switching domains likefrom earthquake to flood requires training a new model in many approaches. Retraining inturn demands annotated data for the new domain. In this work; we study the cross-domainrobustness of models for extracting casualty numbers from disaster reports. Our models …,DIMPLE: DIsaster Management and Principled Large-scale information Extraction Workshop Programme,2014,*
OLAP Queries on Big Data Processing Systems,Ulf Leser,–Manage cluster: IP; capacity; port number; credentials;…–Start/stop/monitor tasks onworker nodes–Restart nodes in case of failure–Manage files and provide access to data (ina fail-safe manner)–Login; logging; administrative interfaces–Scheduling: Which task shouldstart when on which node?–All these are provided by the MapReduce infrastructure,*,2013,*
Retrospective Analysis of a Gene by Mining Texts: The Hepcidin gene use-case,F Moussouni; B Ameline de Cadeville; U Leser; O Loréal,*,JOBIM 2012,2012,*
Datenbankintegration; automatische Diagnosenklassifikation und statistische Analyse von BAL-Befunden,J Starlinger; B Temmesfeld-Wollbrück; N Suttorp; U Leser; B Schmeck,Während eines Krankenhausaufenthaltes werden oft verschiedene diagnostische Verfahrenherangezogen; die Ergebnisse jeder durchgeführten Untersuchung jedoch separat erfasst.Untersuchungsergebnisse und andere Patientendaten werden oft in unterschiedlicherelektronischer Form festgehalten und abgelegt werden; etwa alsTextverarbeitungsdokumente oder in Datenbanken. Als Konsequenz sind diese physischgetrennten und strukturell heterogenen Daten einer gemeinsamen Analyse zunächstentzogen.Zum Zweck der klinischen Forschung und zur Qualitätssicherung ist es jedochnotwendig; die Untersuchungsdaten vieler Patienten zu betrachten. So interessieren etwadie Korrelation von Verdachtsdiagnosen; die aufgrund von bestimmten Untersuchungengestellt wurden; mit der endgültigen Diagnose oder auch ein mögliches Vorhandensein …,Pneumologie,2011,*
Ali Baba: A Text Mining Tool for Systems Biology,Jörg Hakenberg; Conrad Plake; Ulf Leser,Text mining is the process of automatically deriving information from text (as opposed to datamining that works on structured data). This process starts with accessing the relevantliterature and ends with extracting the desired pieces of information. Access mostly isprovided by Web-based search tools; the best known of which is PubMed [1]. PubMedcurrently contains citations from close to 18 million publications in the biomedical domain(biology; biochemistry; medicine; and related fields); from approximately 5200 journals;since 1865. Up to 4000 citations (abstract and bibliographical information) are added toPubMed per day; which necessitates automated means to efficiently handle searches forhigh-quality information.,Elements of Computational Systems Biology,2010,*
Stratosphere: Informationsmanagement “above the Clouds”,Johann-Christoph Freytag; Odej Kao; Ulf Leser; Volker Markl; Felix Naumann,*,Datenbank Spektrum,2010,*
Semantic Data Integration for Life Science Entities,Ulf Leser,The values in the relations of a relational database are elements of one or more underlyingsets called domains. In practical applications; a domain may be infinite; eg; the set of naturalnumbers. In this case; the value of a relational calculus query when applied to such adatabase may be infinite; eg;{njn! 10}. A query Q is called finite if the value of Q whenapplied to any database is finite. Even when the database domains are finite; all that isnormally known about them is that they are some finite superset of the values that occur inthe database. In this case; the value of a relational calculus query may depend on such anunknown domain; eg;{xj 8yR (x; y)}. A query Q is called domain independent if the value of Qwhen applied to any database is the same for any two domains containing the databasevalues or; equivalently; if the value of Q when applied to a database contains only values …,*,2009,*
Simulating and reconstructing language change,Mirko Hochmuth; Anke Lüdeling; Ulf Leser,In this work we probe phylogenetic algorithms for their ability to reconstruct historic languagerelationships. We present a formal model for the development of languages incorporatingvertical (genealogical) and horizontal (language contact) effects. As a distinctive feature; wealso added a geographic model to mimic the effects of constrained population movements.Using our model; we generated a large number of simulated language histories whoseresults were analyzed by a variety of established phylogenetic algorithms. Therein; wesystematically investigated the effects of different contact intensities and of geographic aswell as genealogic topologies. We found that tree-based algorithms are robust under avariety of different settings and are capable of inferring (parts of) the relationships correctlyeven under high levels of network-like influences. We also studied the SplitsTree …,*,2008,*
4. Workshop" Föderierte Datenbanken": Berlin; November 1999,Ralf-Detlef Kutsche; Ulf Leser,*,*,1999,*
Globale Anfragebearbeitung mit verteilten und heterogenen Datenquellen,Ulf Leser,Zusammenfassung Im Rahmen des Berlin/Brandenburger Graduiertenkolleg „VerteilteInformationssysteme “(GKVI 2) arbeiten zur Zeit 15 Stipendiaten an verschiedenen Aspektender Konzeption; Erstellung und des Betriebs von Informationssystemen in verteilten undheterogenen Umgebungen. Die prinzipiell interdisziplinäre Ausrichtung des GKVI; die einefruchtbare Verbindung zwischen Wirtschaftsinformatik; Datenbanktechnik und Aspekten derSoftwaretechnik sucht; schafft ein breites Themenspektrum; das von Internet-Pricing [20] undIndexstrukturen [8] über objektorientierte Middleware [6] bis zur Modellierung vonBenutzerschnittstellen [15] reicht.,*,1999,*
IXDB; an integrated database for genomic data of the Human X Chromosome.,Ulf Leser; Robert Wagner; Hans Lehrach; Hugues Roest Crollius,The generation of physical maps at the chromosomal scale and at a resolution su cient forlarge scale sequencing requires more data; experiments and resources than can beproduced by a single research group. This is re ected by the fact that most chromosomes areinformally split into regions of research interest. These are then often exclusively tackled bya small number of groups; following certain specialized research interests such as thesearch for a speci c gene. In addition; many interesting questions other than those aimed atgenome sequencing require an overall overview; such as the determination of chromosomestructure conservation across species. Such questions are currently very tiresome and error-prone to approach; as no single-point and comprehensive interface to all the di erentdatasets is available (1]). We have developed IXDB; a database focused on the human X …,German Conference on Bioinformatics,1997,*
Updates and developments of ACEDB for chromosome 21: integrating all published data in a common database,ML Yaspo; U Leser; H Lehrach,*,CYTOGENETICS AND CELL GENETICS,1997,*
2014 IEEE 10th International Conference on e-Science (e-Science)(2014),Johannes Starlinger; Sarah Cohen-Boulakia; Sanjeev Khanna; Susan B Davidson; Ulf Leser,*,*,*,*
