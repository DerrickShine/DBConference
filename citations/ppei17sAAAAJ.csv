Security and privacy in cloud computing: A survey,Minqi Zhou; Rong Zhang; Wei Xie; Weining Qian; Aoying Zhou,Cloud Computing is becoming a well-known buzzword nowadays. Many companies; suchas Amazon; Google; Microsoft and so on; accelerate their paces in developing CloudComputing systems and enhancing their services to provide for a larger amount of users.However; security and privacy issues present a strong barrier for users to adapt into CloudComputing systems. In this paper; we investigate several Cloud Computing systemproviders about their concerns on security and privacy issues. We find those concerns arenot adequate and more should be added in terms of five aspects (ie; availability;confidentiality; data integrity; control; audit) for security. Moreover; released acts on privacyare out of date to protect users' private information in the new environment (ie; CloudComputing system environment) since they are no longer applicable to the new …,Semantics Knowledge and Grid (SKG); 2010 Sixth International Conference on,2010,451
Services in the cloud computing era: A survey,Minqi Zhou; Rong Zhang; Dadan Zeng; Weining Qian,Cloud Computing is becoming a well-known buzzword nowadays. As a brand newinfrastructure to offer services; Cloud Computing systems have many superiorities incomparing to those existed traditional service provisions; such as reduced upfrontinvestment; expected performance; high availability; infinite scalability; tremendous fault-tolerance capability and so on and consequently chased by most of the IT companies; suchas Google; Amazon; Microsoft; Salesforce. com. Based on their overwhelmingpredominance in traditional service provisions and capital accumulation; most of these ITcompanies have more chance to adapt their services into such a new environment earlier;say Cloud Computing systems. On the other hand; a large number of new companies arespawned with competitive services relayed on those provided Cloud Computing systems …,Universal Communication Symposium (IUCS); 2010 4th International,2010,157
At the frontiers of information and software as services,K Selçuk Candan; Wen-Syan Li; Thomas Phan; Minqi Zhou,Abstract The high cost of creating and maintaining software and hardware infrastructures fordelivering services to businesses has led to a notable trend toward the use of third-partyservice providers; which rent out network presence; computation power; and data storagespace to clients with infrastructural needs. These third party service providers can act asdata stores as well as entire software suites for improved availability and system scalability;reducing small and medium businesses' burden of managing complex infrastructures. Thisis called information/application outsourcing or software as a service (SaaS). Emergence ofenabling technologies; such as service oriented architectures (SOA); virtual machines; andcloud computing; contribute to this trend. Scientific Grid computing; on-line softwareservices; and business service networks are typical examples leveraging database and …,*,2011,80
An efficient peer-to-peer indexing tree structure for multidimensional data,Rong Zhang; Weining Qian; Aoying Zhou; Minqi Zhou,Abstract As one of the most important technologies for implementing large-scale distributedsystems; peer-to-peer (P2P) computing has attracted much attention in both research andindustrial communities; for its advantages such as high availability; high performance; andhigh flexibility to the dynamics of networks. However; multidimensional data indexingremains as a big challenge to P2P computing; because of the inefficiency in search andnetwork maintenance caused by the complicated existing index structures; which greatlylimits the scalability of applications and dimensionality of the data to be indexed. Wepropose SDI (Swift tree structure for multidimensional Data Indexing); a swift index schemewith a simple tree structure for multidimensional data indexing in large-scale distributedsystems. While keeping the query efficiency in O (log N) in terms of routing hops; SDI has …,Future Generation Computer Systems,2009,23
Join optimization in the MapReduce environment for column-wise data store,Minqi Zhou; Rong Zhang; Dadan Zeng; Weining Qian; Aoying Zhou,The chain join processing which combines records from two or more tables sequentially hasbeen well studied in the centralized databases. However; it has seldom been discussed inthe cloud computing era; and remains imperative to be solved; especially where structured(or relational) data are stored in a column (attribute) wise fashion in distributed file systems(eg; Google File System) over hundreds of or even thousands of commodities PCs. In thispaper; we propose a novel method for chain join processing; which is one of the commonprimitives in the cloud era for column-wise stored data analysis. By effectively selecting thededicated records (tuples) for the chain join based on the information exploited withinbipartite join graph; communication cost for record transmission could be reduceddramatically. A bushy tree structure is deployed to regulate the chain join sequence …,Semantics Knowledge and Grid (SKG); 2010 Sixth International Conference on,2010,19
Exploiting shopping and reviewing behavior to re-score online evaluations,Rong Zhang; ChaoFeng Sha; Minqi Zhou; Aoying Zhou,Abstract Analysis to product reviews has attracted great attention from both academia andindustry. Generally the evaluation scores of reviews are used to generate the averagescores of products and shops for future potential users. However; in the real world; there isthe inconsistency problem between the evaluation scores and review content; and somecustomers do not give out fair reviews. In this work; we focus on detecting the credibility ofcustomers by analyzing online shopping and review behaviors; and then we re-score thereviews for products and shops. In the end; we evaluate our algorithm based on the realdata set from Taobao; the biggest E-commerce site in China.,Proceedings of the 21st International Conference on World Wide Web,2012,13
Chronos: An elastic parallel framework for stream benchmark generation and simulation,Ling Gu; Minqi Zhou; Zhenjie Zhang; Ming-Chien Shan; Aoying Zhou; Marianne Winslett,In the coming big data era; stress test to IT systems under extreme data volume is crucial tothe adoption of computing technologies in every corner of the cyber world. Appropriatelygenerated benchmark datasets provide the possibility for administrators to evaluate thecapacity of the systems when real datasets hard obtained have not extreme cases.Traditional benchmark data generators; however; mainly target at producing relation tablesof arbitrary size following fixed distributions. The output of such generators are insufficientwhen it is used to measure the stability of the architecture with extremely dynamic and heavyworkloads; caused by complicated/hiden factors in the generation mechanism of real world;eg dependency between stocks in the trading market and collaborative human behaviors onthe social network. In this paper; we present a new framework; called Chronos; to support …,Data Engineering (ICDE); 2015 IEEE 31st International Conference on,2015,11
Computational advertising: A data-centric comprehensive web application,Ao-Ying Zhou; Min-Qi Zhou; Xue-Qing Gong,*,Jisuanji Xuebao(Chinese Journal of Computers),2011,10
Searching XML data by SLCA on a MapReduce cluster,Mengjie Zhou; Haoji Hu; Minqi Zhou,XML keyword search is a popular topic in research field; and the Smallest Lowest CommonAncestor (SLCA) concept is fundamental for XML keyword search algorithms. With the rapidgrowth of XML data in internet; we are confronted with big data issues; it's becoming a newresearch direction for managing massive XML data now. Conventional centralized datamanagement technologies are limited in the aspects of efficiency; throughout andmaintenance cost. MapReduce framework is a recent trend to process large-scale data. It isimplemented on clusters built by numbers of business machines; to conquer limitationsmentioned above by parallel computation. In this paper; we provide a SLCA-based keywordsearch implementation for large-scale XML data sets on a MapReduce cluster. Main steps ofour implementation include XML data partition; parse and sort; index setup and SLCA …,Universal Communication Symposium (IUCS); 2010 4th International,2010,9
Elastic pipelining in an in-memory database cluster,Li Wang; Minqi Zhou; Zhenjie Zhang; Yin Yang; Aoying Zhou; Dina Bitton,Abstract An in-memory database cluster consists of multiple interconnected nodes with alarge capacity of RAM and modern multi-core CPUs. As a conventional query processingstrategy; pipelining remains a promising solution for in-memory parallel database systems;as it avoids expensive intermediate result materialization and parallelizes the dataprocessing among nodes. However; to fully unleash the power of pipelining in a cluster withmulti-core nodes; it is crucial for the query optimizer to generate good query plans withappropriate intra-node parallelism; in order to maximize CPU and network bandwidthutilization. A suboptimal plan; on the contrary; causes load imbalance in the pipelines andconsequently degrades the query performance. Parallelism assignment optimization atcompile time is nearly impossible; as the workload in each node is affected by numerous …,Proceedings of the 2016 International Conference on Management of Data,2016,7
Efficient star join for column-oriented data store in the mapreduce environment,Haitong Zhu; Minqi Zhou; Fan Xia; Aoying Zhou,Map Reduce is a parallel computing paradigm that has gained a lot of attention from bothindustry and academia recent years. Unlike parallel DBMSs; with Map Reduce; it is easierfor non-expert to develop scalable parallel programs for analytical applications over hugedata sets across clusters of commodity machines. As the nature of scan-oriented processing;the performance of Map Reduce for relation operators can be enhanced dramatically since itis inevitably accessing lots of unnecessary data tuples; especially for table join operators. Inthis paper; we propose an efficient star join strategy called HdBmp join for column-orienteddata store by using a three-level content aware index (ie; HdBmp Index). Armed with thisindex; most of the unnecessary tuples in the join processing can be filtered out; andconsequently result in immense reduction in both communication cost and execution time …,Web Information Systems and Applications Conference (WISA); 2011 Eighth,2011,7
Optimized data placement for column-oriented data store in the distributed environment,Minqi Zhou; Chen Xu,Abstract Column-oriented data storage becomes a buzzword nowadays for its highefficiency in massive data access; high compression ratio on individual columns and etc.However; the initial observations turn out to not be trivially true. The seek time andbandwidth of current hard disk drivers (HDD) become the bottleneck for massive dataprocessing day by day; when comparing to other component enhancements of computersduring the past four decades. In this paper; we provide a novel data placement strategy formassive data analysis (ie; read-optimized) based on Gray Code; which enhances the ratio ofsequential access to a great extent for diverse query evaluations (eg; range query; partialmatch range query; aggregation query and etc). A centralized/distributed structured index isemployed in the popularly deployed distributed file systems (eg; GFS); which achieves …,International Conference on Database Systems for Advanced Applications,2011,6
GChord: indexing for multi-attribute query in P2P system with low maintenance cost,Minqi Zhou; Rong Zhang; Weining Qian; Aoying Zhou,Abstract To provide complex query processing in peer-to-peer systems has attracted muchattention in both academic and industrial community. We present GChord; a scalabletechnique for evaluating queries with multi-attributes. Both exact match and range queriescan be handled by GChord. It has advantages over existing methods in that each tuple onlyneeds to be indexed once; while the query efficiency is guaranteed. Thus; indexmaintenance cost and search efficiency are balanced. Additional optimization techniquesfurther improves the performance of GChord. Extensive experiments are conducted tovalidate the efficiency of the proposed method.,International Conference on Database Systems for Advanced Applications,2007,6
Numa-aware scalable and efficient in-memory aggregation on large domains,Li Wang; Minqi Zhou; Zhenjie Zhang; Ming-Chien Shan; Aoying Zhou,Business Intelligence (BI) is recognized as one of the most important IT applications in thecoming big data era. In recent years; non-uniform memory access (NUMA) has become thede-facto architecture of multiprocessors on the new generation of enterprise servers. Suchnew architecture brings new challenges to optimization techniques on traditional operatorsin BI. Aggregation; for example; is one of the basic building blocks of BI; while its processingperformance with existing hash-based algorithms scales poorly in terms of the number ofcores under NUMA architecture. In this paper; we provide new solutions to tackle theproblem of parallel hash-based aggregation; especially targeting at domains of extremelylarge cardinality. We propose a NUMA-aware radix partitioning (NaRP) method whichdivides the original huge relation table into subsets; without invoking expensive remote …,IEEE Transactions on Knowledge and Data Engineering,2015,5
Multi-dimensional data density estimation in P2P networks,Minqi Zhou; Weining Qian; Xueqing Gong; Aoying Zhou,Abstract Estimating the global data distribution in Peer-to-Peer (P2P) networks is animportant issue and has not yet been well addressed. It can benefit many P2P applications;such as load balancing analysis; query processing; data mining; and so on. In this paper; wepropose a novel algorithm which is based on compact multi-dimensional histograminformation to achieve high estimation accuracy with low estimation cost. Maintaining datadistribution in a multi-dimensional histogram which is spread among peers withoutoverlapping and each part of which is further condensed by a set of discrete cosinetransform coefficients; each peer is capable to hierarchically accumulate the compactinformation to the entire histogram by information exchange and consequently estimates theglobal data density with accuracy and efficiency. Algorithms on discrete cosine transform …,Distributed and Parallel Databases,2009,5
Detecting user preference on microblog,Chen Xu; Minqi Zhou; Feng Chen; Aoying Zhou,Abstract Microblog attracts a tremendous large number of users; and consequently affectstheir daily life deeply. Detecting user preference for profile construction on microblog issignificant and imperative; since it facilitates not only the enhancement of users' utilities butalso the promotion of business values (eg; online advertising; commercial recommendation).Users might be instinctively reluctant to exposure their preferences in their own publishedmessages for the privacy protection issues. However; their preferences can never beconcealed in those information they read (or subscribed); since users do need to getsomething useful in their readings; especially in the microblog application. Based on thisobservation; in this work; we successfully detect user preference; by proposing to filter outfollowees' noisy postings under a dedicated commercial taxonomy; followed by clustering …,International Conference on Database Systems for Advanced Applications,2013,4
Adaptive query scheduling in key-value data stores,Chen Xu; Mohamed A Sharaf; Minqi Zhou; Aoying Zhou; Xiaofang Zhou,Abstract Large-scale distributed systems such as Dynamo at Amazon; PNUTS at Yahoo!;and Cassandra at Facebook; are rapidly becoming the data management platform of choicefor most web applications. Those key-value data stores rely on data partitioning andreplication to achieve higher levels of availability and scalability. Such design choicestypically exhibit a trade-off in which data freshness is sacrificed in favor of reduced accesslatencies. Hence; it is indispensable to optimize resource allocation in order to minimize: 1)query tardiness; ie; maximize Quality of Service (QoS); and 2) data staleness; ie; maximizeQuality of Data (QoD). That trade-off between QoS and QoD is further manifested at the local-level (ie; replica-level) and is primarily shaped by the resource allocation strategiesdeployed for managing the processing of foreground user queries and background …,International Conference on Database Systems for Advanced Applications,2013,4
Personalized query evaluation in ring-based P2P networks,Minqi Zhou; Heng Tao Shen; Xueqing Gong; Weining Qian; Aoying Zhou,Abstract Personalized query evaluation which returns top-k results according to users'individual interests was once confined mainly to the web literature; while now it isincreasingly becoming a factor in many other search systems; such as peer-to-peer systems;cloud computing systems etc. In this paper; we propose a novel method for efficientpersonalized query processing in P2P systems. The problem has never been discussed andremains imperative to be solved. By effectively calculating a corresponding search range on-the-fly which contains the dedicated top-k results based on the estimated multiscale datadensity in the current system; a personalized query is transformed into a special range queryfor efficient processing at run time. Singular value decomposition of the personalizationmatrix is deployed to simplify the process of range computation. Search request is then …,Information Sciences,2013,4
Credibility-based product ranking for C2C transactions,Rong Zhang; Chao Feng Sha; Min Qi Zhou; Ao Ying Zhou,Abstract A fundamental issue for C2C transactions is how to rank the products based on thereviews written by the previous customers. In this paper; we present an approach to improveproducts ranking by tackling the noisy ratings that exist in the practical systems. The firstproblem is the credibility of the customers. We design an iterative algorithm to measure thecustomer credibility. In the algorithm; we use a feedback strategy to increase or decrease thecustomer credibility. We increase the credibility for a customer if the customer gives a high(low) score to a good (bad) product and decrease the value if the customer gives a low(high) score to a good (bad) product. The second problem is the inconsistency between thereview comments and scores. To deal with it; we train a classifier on a training data that isconstructed automatically. The trained classifier is used to predict the scores of the …,Proceedings of the 21st ACM international conference on Information and knowledge management,2012,4
Scalable parallel join for huge tables,Nianlong Weng; Minqi Zhou; Ming-Chien Shan; Aoying Zhou,The parallel join processing which combines tuples from two or more relational tablestogether in a parallel manner is becoming more and more important and imperative to besolved; since tables may be huge; especially in this big data era. A few algorithms havealready been proposed based on the prevailing mapreduce paradigm; while most of themimpose both high communication costs and synchronization costs. In this paper; we proposea novel algorithm for scalable parallel join processing for the column-wise stored dataanalyzing. To cater for the prevailing deployed Hadoop system; we adopt the HadoopDistributed File System (HDFS) as the file system across over a large set of machines.Tables are projected (ie; vertical partition); segmented (ie; horizontal partition); clustered andplaced in a column-wise format over the distributed file system based on Gray Code. By …,Big Data (BigData Congress); 2013 IEEE International Congress on,2013,3
Effective data density estimation in ring-based P2P networks,Minqi Zhou; Heng Tao Shen; Xiaofang Zhou; Weining Qian; Aoying Zhou,Estimating the global data distribution in Peer-to-Peer (P2P) networks is an important issueand has yet to be well addressed. It can benefit many P2P applications; such as loadbalancing analysis; query processing; and data mining. Inspired by the inversion method forrandom variate generation; in this paper we present a novel model named distribution-freedata density estimation for dynamic ring-based P2P networks to achieve high estimationaccuracy with low estimation cost regardless of distribution models of the underlying data. Itgenerates random samples for any arbitrary distribution by sampling the global cumulativedistribution function and is free from sampling bias. In P2P networks; the key idea fordistribution-free estimation is to sample a small subset of peers for estimating the global datadistribution over the data domain. Algorithms on computing and sampling the global …,Data Engineering (ICDE); 2012 IEEE 28th International Conference on,2012,3
Sonnet: an efficient distributed content-based dissemination broker,Aoying Zhou; Weining Qian; Xueqing Gong; Minqi Zhou,Abstract In this demonstration; we present a prototype content-based dissemination broker;called Sonnet; which is built upon structured overlay network. It combines approximatefiltering of XML packets with routing in the overlay network. Deliberate optimizationtechnologies are implemented. The running and tracing of the system in a real-lifeapplication are to be demonstrated.,Proceedings of the 2007 ACM SIGMOD international conference on Management of data,2007,3
Sdi: a swift tree structure for multi-dimensional data indexing in peer-to-peer networks,Rong Zhang; Weining Qian; Minqi Zhou; Aoying Zhou,Abstract Efficient multi-dimensional data search has received much attention in centralizedsystems. However; its implementation in large-scale distributed systems is not a trivial joband remains to be a challenge. In this paper; SDI; a new succinct multi-dimensionalbalanced tree structure based on peer-to-peer technology; is presented. With SDI structure;the query efficiency can be bounded by O (log N). Compared with previous tree-basedmethods; SDI has extremely low maintenance cost. This is due to the carefully chosen fingerlinks. Furthermore; new algorithms are designed for both point query and range queryprocessing; which make SDI free from the root-bottleneck problem. Experimental resultsvalidate the efficiency and effectiveness of the proposed approach.,Proceedings of the 2nd international conference on Scalable information systems,2007,3
BSMA-Gen: a parallel synthetic data generator for social media timeline structures,Chengcheng Yu; Fan Xia; Qunyan Zhang; Haixin Ma; Weining Qian; Minqi Zhou; Cheqing Jin; Aoying Zhou,Abstract A synthetic social media data generator; namely BSMA-Gen is introduced in thisdemonstration. It can parallelly generate timeline structures of social media. The datagenerator is part of BSMA; a benchmark for analytical queries over social media data. Bothits internal process and generated data are to be shown in the demonstration.,International Conference on Database Systems for Advanced Applications,2014,2
AQUAS: A quality-aware scheduler for NoSQL data stores,Chen Xu; Fan Xia; Mohamed A Sharaf; Minqi Zhou; Aoying Zhou,NoSQL key-value data stores provide an attractive solution for big data management. Withthe help of data partitioning and replication; those data stores achieve higher levels ofavailability; scalability and reliability. Such design choices typically exhibit a tradeoff inwhich data freshness is sacrificed in favor of reduced access latency. At the replica-level;this tradeoff is primarily shaped by the resource allocation strategies deployed for managingthe processing of user queries and replica updates. In this demonstration; we showcaseAQUAS: a quality-aware scheduler for Cassandra; which allows application developers tospecify requirements on quality of service (QoS) and quality of data (QoD). AQUAS efficientlyallocates the available replica resources to execute the incoming read/write tasks so that tominimize the penalties incurred by violating those requirements. We demonstrate AQUAS …,Data Engineering (ICDE); 2014 IEEE 30th International Conference on,2014,2
Massive parallel join in NUMA architecture,Wei He; Minqi Zhou; Xueqing Gong; Xiaofeng He,Advance in hardware technology and growing demands for fast response of databaseapplication have led to active research in In-Memory Database (IMDB). Compared totraditional on-disk database; IMDB has advantages such as faster access to storage andsimpler internal optimization algorithms. Because of the importance of join operation indatabase system; join algorithm is always a hot research topic and many join algorithmshave been proposed for distributed database system. Nevertheless; due to the nature ofmemory access in Non-Uniform Memory Access (NUMA) architecture; most existing joinalgorithms for classic Symmetric Multi-Processing (SMP) architecture cannot be applied toNUMA architecture directly. In this work; we present the Distributed Bitmap Join algorithmdesigned exclusively for IMDB in NUMA architecture. This Distributed Bitmap Join …,Big Data (BigData Congress); 2013 IEEE International Congress on,2013,2
An SVM-based approach to discover microRNA precursors in plant genomes,Yi Wang; Cheqing Jin; Minqi Zhou; Aoying Zhou,Abstract MicroRNAs (miRNAs) are noncoding RNAs of~ 22 nucleotides that play versatileregulatory roles in multicelluler organisms. Since the cloning methods for miRNAsidentification are biased towards abundant miRNAs; the computational approaches provideuseful complements to identify miRNAs which are highly constrained by tissue-and time-specifically expression manners. In this paper; we propose a novel Support Vector Machine(SVM) based detector; named MiR-PD; to identify pre-miRNAs in plants. The classifier isconstructed based on twelve features of pre-miRNAs; inclusive of five global features andseven sub-structure features. Trained on 790 plant pre-miRNAs and 7;900 pseudo pre-miRNAs; MiR-PD achieves 96.43% five-fold cross-validation accuracy. Tested on the newlyidentified 441 plant pre-miRNAs and 62;883 pseudo pre-miRNAs; MiR-PD reports an …,Pacific-Asia Conference on Knowledge Discovery and Data Mining,2011,2
Aucweb: A prototype for analyzing user-created web data,Weining Qian; Feng Chen; Juan Du; Weiming Zhang; Can Zhang; Haixin Ma; Peng Cai; Minqi Zhou; Aoying Zhou,Abstract In this demonstration; we present a prototype system; called AUCWeb; that isdesigned for analyzing user-created web data. It has novel features in that 1) it may utilizeexternal resources for semantic annotation on low-quality user-created content; and 2) itprovides a descriptive language for definition of analytical tasks. Both internal mechanismand the usage of AUCWeb for building advanced applications are to be shown in thedemonstration.,International Conference on Database Systems for Advanced Applications,2011,2
Materialized view maintenance in columnar storage for massive data analysis,Chen Xu; Minqi Zhou; Weining Qian,Data-intensive computing becomes a buzz word nowadays; where constant data for currentoperational processing and historical data for massive analysis are often separated into twosystems. How to keep the historical data for analysis (often in a materialized view manner)consistent with their data sources (often in the operational databases) is the main problem tobe solved imperatively. In this paper; we proposed a novel method for data consistencymaintenance between the data located in the two systems. Two basic operators (ie; insertionand deletion) for consistency maintenance are provided as well as their implementations inthe new environment of column-oriented storage on large-scale data analysis platform forefficient processing. Two data consistency models (ie; eventual consistency model andtimeline-based consistency model) are proposed to tradeoff data consistency for …,Universal Communication Symposium (IUCS); 2010 4th International,2010,2
Different File Systems Data Access Support on MapReduce,Dadan Zeng; Zhebing Chen; Jianpu Wang; Minqi Zhou; Aoying Zhou,In this paper; the interface between MapReduce and different storage systems is proposed.MapReduce based computing platform can access various file systems by the interfacewithout modifying the existing computing system so that to simplify the construction ofdistributed applications. Different file systems can be configured and get quick switch by theinterface. The interface is also integrated in Hadoop to make the experiments. The resultsshow the interface can achieve different storage systems switched at the same time the dataaccess efficiency gets better with increasing data volume. Further experiment with largerdata volume will be done and the deeper development of the interface is being taken in thecomputing platform of our work.,Computational Intelligence and Software Engineering; 2009. CiSE 2009. International Conference on,2009,2
Complex query processing in large-scale distributed system,Ao-Ying Zhou; Min-Qi Zhou; Wei-Ning Qian; Rong Zhang,Abstract Complex query processing in large-scale distributed systems is an importantproblem in bringing peer-to-peer techniques into applications. It has attracted much attentionin both academic and industrial community. This paper presents a generalized Chord-liketechnique; GChord; for evaluating queries with multi-attributes with scalability and efficiency.GChord supports not only exact match queries but also range queries. It has advantagesover existing methods in that each tuple is only encoded and indexed once; while the queryefficiency is guaranteed. Thus; index maintenance cost and search efficiency are balanced.Additional optimization techniques further improve the performance of GChord. Extensiveexperiments are conducted to validate the efficiency of the proposed method.,Chinese Journal of Computers,2008,2
Low Overhead Log Replication for Main Memory Database System,Jinwei Guo; Chendong Zhang; Peng Cai; Minqi Zhou; Aoying Zhou,Abstract Log replication is the key component of high available database system. Toguarantee data consistency and reliability; modern database systems often use Paxosprotocol to replicate log in multiple database instance sites. Since the replicated logs needto contain some metadata such as committed log sequence number (LSN); this increasesthe overhead of storage and network. It has significantly negative impact on the throughputin the update intensive work load. In this paper; we present an implementation of logreplication and database recovery; which adopts the idea of piggybacking; ie committedLSN is embedded in the commit logs. This practice not only retains virtues of Paxosreplication; but also reduces disk and network IO effectively; which enhances performanceand decreases recovery time. We implemented and evaluated our approach in a main …,International Conference on Web-Age Information Management,2016,1
ACID Encountering the CAP Theorem: Two Bank Case Studies,Chao Kong; Ming Gao; Weining Qian; Minqi Zhou; Xueqing Gong; Rong Zhang; Aoying Zhou,In the era of big data; we may adopt the distributed architecture for a transaction processingsystem due to some reasons; including distributed branches; heavy demand andoperational expenditure; etc. In terms of the CAP Theorem; a transaction processing systemassociated with ACID properties is infeasible to work well in the distributed architecture. It isindispensable to address how to make a trade-off between availability and partitiontolerance for a bank as it favors the consistency in the distributed system. In this research;we conduct two case studies to address the question using two transaction logs collectedfrom a bank in China. We mainly analyze the table dependency and the table concurrency;and find that (1) it is arduous to partition the data in the database system associated withACID properties;(2) in-memory architecture for updating transactions may be an …,Web Information System and Application Conference (WISA); 2015 12th,2015,1
Computing rarity on uncertain data,CheQing Jin; MinQi Zhou; AoYing Zhou,Abstract The essence of uncertain data management has been well adopted since datauncertainty widely exists in lots of applications; such as Web; sensor networks; etc. Most ofthe uncertain data models are based on the possible world semantics. Because the numberof the possible worlds will blowup exponentially with the growth of the data set; it is muchmore challenging to handle uncertain data than deterministic data. In this paper; we take thefirst attempt to study the rarity; an important statistic that describes the proportion of itemswith the same frequency; upon uncertain data. We have proposed three novel solutions;including an exact method and an approximate method to compute the rarity of a givenfrequency respectively; and a method to find the frequency of the maximum rarity. Analysis intheorem and extensive experimental results demonstrate the effectiveness and efficiency …,Science China Information Sciences,2011,1
A best-effort approach to an infrastructure for Chinese Web related research,Weining Qian; Aoying Zhou; Minqi Zhou,Abstract The design of the infrastructure for Chinese Web (CWI); a prototype system aimedat forum data analysis; is introduced. CWI takes a best effort approach. 1) It tries its best toextract or annotate semantics over the web data. 2) It provides flexible schemes for users totransform the web data into eXtensible Markup Language (XML) forms with more semanticannotations that are more friendly for further analytical tasks. 3) A distributed graphrepository; called DISGR is used as backend for management of web data. The paperintroduces the design issues; reports the progress of the implementation; and discusses theresearch issues that are under study.,Frontiers of Electrical and Electronic Engineering in China,2011,1
Value of the spiral CT and MPR in diagnosing trachea foreign bodies in the children [J],Fang CHEN; Fu-bin YANG; Min ZHOU,*,Journal of China Clinic Medical Imaging,2008,1
S ONNET: subscription using path queries over structured overlay networks,Weining Qian; Linhao Xu; Aoying Zhou; Minqi Zhou,Abstract Application-level content-based routing using XML is a key technology fordecentralized publish/subscribe systems. In this paper; a new approach is proposed tosupport the efficient dissemination of XML packets when allowing the clients to specify theirsubscriptions with path queries. The proposed method is based on Chord-liked distributedhash table (DHT) scheme. The integration of XML packet filtering and finger table basedrouting in structured overlay networks provides an elegant base for the proposed SONNETsystem; upon which the optimization techniques are studied. Analytical and empirical resultshave shown that the coupling of disseminating and routing in publish/subscribe systemscould offer robustness and extensibility for the systems; while the decoupling of the twoaspects brings more scalability and workload balance. Extensive empirical studies have …,Frontiers of Computer Science in China,2007,1
A Fast Learning Algorithm for Part of Speech Tagging: an Improvment on Brill's Transformation-Based Algorithm,M Zhou,*,CHINESE JOURNAL OF COMPUTERS-CHINESE EDITION-,1998,1
Low-Overhead Paxos Replication,Jinwei Guo; Jiajia Chu; Peng Cai; Minqi Zhou; Aoying Zhou,Abstract Log replication is a key component in highly available database systems. In order toguarantee data consistency and reliability; it is common for modern database systems toutilize Paxos protocol; which is responsible for replicating transactional logs from oneprimary node to multiple backups. However; the Paxos replication needs to store andsynchronize some additional metadata; such as committed log sequence number (commitpoint); to guarantee the consistency of the database. This increases the overhead of storageand network; which would have a negative impact on the throughput in the update intensivework load. In this paper; we present an implementation of log replication and databaserecovery methods; which adopts the idea of piggybacking; ie; commit point can beembedded in the commit logs. This practice not only retains virtues of Paxos replication …,Data Science and Engineering,2017,*
Detecting anomaly in data streams by fractal model,Rong Zhang; Minqi Zhou; Xueqing Gong; Xiaofeng He; Weining Qian; Shouke Qin; Aoying Zhou,Abstract Detecting anomaly in data streams attracts great attention in both academic andindustry communities due to its wide range application in venture analysis; networkmonitoring; trend analysis and so on. However; existing methods on anomaly detectionsuffer three problems. 1) A large number of false positive results are generated. 2) Trainingdata are needed to build the detection model; and an appropriate time window size alongwith corresponding threshold has to be set empirically. 3) Both time and space overhead isusually very high. To address these limitations. We propose a fractal-model-based approachto detection of anomalies that change underlying data distribution in this paper. Both ahistory-based algorithm and a parameter-free algorithm are introduced. We show that thelater method consumes only limited memory and does not involve any training process …,World Wide Web,2015,*
A Scalable Framework for Universal Data Generation in Parallel,Ling Gu; Minqi Zhou; Qiangqiang Kang; Aoying Zhou,Abstract Nowadays; more and more companies; such as Amazon; Twitter and etc.; arefacing the big data problem; which requires higher performance to manage tremendouslarge data sets. Data management systems with a new architecture taking full advantages ofcomputer hardware are emerging; on the purpose of maximizing the system performanceand fulfilling customs' current or even future requirements. How to test performance andconfirm the suitability of the new data management system becomes a primary task of thesecompanies. Hence; how to generate a scaled data set with desired volumes and in desiredvelocity effectively becomes a problem imperative to be solved; together with the goal tokeep the characters of their real data set as many as possible (realistic). In this paper; weproposed PSUG to generate a realistic database in terms of required volume and velocity …,Technology Conference on Performance Evaluation and Benchmarking,2014,*
Graph-Based Hierarchical Categorization of Microblog Users,Kun Yue; Minqi Zhou; Jixian Zhang; Ping Zhang; Qiyu Fang; Weiyi Liu,Microblogging has created a big social network with big social media data. Modeling andanalyzing the relationships of behaviors among micro log users; and achieving the inherentcategories or communities; are paid much attention in social network and big dataparadigms. In this paper; we presented a graph-based model for describing therelationships of microblog users; in which the distributed storage and map/reduce programswere incorporated. Then; we proposed the map/reduce based algorithm for hierarchicalcategorization of microblog users based on the concepts of chordal sub graph and join treein the graph theory. Thus; the categories of microblog users with overlapping andhierarchical properties in various abstraction hierarchies can be obtained flexibly.Experimental results show the feasibility of our method.,Big Data (BigData Congress); 2013 IEEE International Congress on,2013,*
Distribution-free data density estimation in large-scale networks,Minqi Zhou; Rong Zhang; Weining Qian; Aoying Zhou,Abstract Estimating the global data distribution in large-scale networks is an important issueand yet to be well addressed. It can benefit many applications; especially in the cloudcomputing era; such as load balancing analysis; query processing; and data mining.Inspired by the inversion method for random variate (number) generation; in this paper; wepresent a novel model called distribution-free data density estimation for large ring-basednetworks to achieve high estimation accuracy with low estimation cost regardless of thedistribution models of the underlying data. This model generates random samples for anyarbitrary distribution by sampling the global cumulative distribution function and is free fromsampling bias. Armed with this estimation method; we can estimate data densities over bothone-dimensional and multidimensional tuple sets; where each dimension could be either …,Frontiers of Computer Science,*,*
郭心语; 刘 鹏 2; 周敏奇; 周傲英,Xin-yu GUO; Peng LIU; Min-qi ZHOU; Ao-ying ZHOU,*,*,*,*
ACID Encountering the CAP Theorem,Chao Kong; Ming Gao; Weining Qian; Minqi Zhou; Xueqing Gong; Rong Zhang; Aoying Zhou,Abstract—In the era of big data; we may adopt the distributed architecture for a transactionprocessing system due to some reasons; including distributed branches; heavy demand andoperational expenditure; etc. In terms of the CAP Theorem; a transaction processing systemassociated with ACID properties is infeasible to work well in the distributed architecture. It isindispensable to address how to make a trade-off between availability and partitiontolerance for a bank as it favors the consistency in the distributed system. In this research;we conduct two case studies to address the question using two transaction logs collectedfrom a bank in China. We mainly analyze the table dependency and the table concurrency;and find that (1) it is arduous to partition the data in the database system associated withACID properties;(2) in-memory architecture for updating transactions may be an …,*,*,*
