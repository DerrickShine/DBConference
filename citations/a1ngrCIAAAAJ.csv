TAG: A tiny aggregation service for ad-hoc sensor networks,Samuel Madden; Michael J Franklin; Joseph M Hellerstein; Wei Hong,Abstract We present the Tiny AGgregation (TAG) service for aggregation in low-power;distributed; wireless environments. TAG allows users to express simple; declarative queriesand have them distributed and executed efficiently in networks of low-power; wirelesssensors. We discuss various generic properties of aggregates; and show how thoseproperties affect the performance of our in network approach. We include a performancestudy demonstrating the advantages of our approach over traditional centralized; out-of-network methods; and discuss a variety of optimizations for improving the performance andfault tolerance of the basic solution.,ACM SIGOPS Operating Systems Review,2002,3858
TinyDB: an acquisitional query processing system for sensor networks,Samuel R Madden; Michael J Franklin; Joseph M Hellerstein; Wei Hong,Abstract We discuss the design of an acquisitional query processor for data collection insensor networks. Acquisitional issues are those that pertain to where; when; and how oftendata is physically acquired (sampled) and delivered to query processing operators. Byfocusing on the locations and costs of acquiring data; we are able to significantly reducepower consumption over traditional passive systems that assume the a priori existence ofdata. We discuss simple extensions to SQL for controlling data acquisition; and show howacquisitional issues influence query optimization; dissemination; and execution. Weevaluate these issues in the context of TinyDB; a distributed query processor for smartsensor devices; and show how acquisitional techniques can provide significant reductions inpower consumption on our sensor devices.,ACM Transactions on database systems (TODS),2005,2441
TelegraphCQ: continuous dataflow processing,Sirish Chandrasekaran; Owen Cooper; Amol Deshpande; Michael J Franklin; Joseph M Hellerstein; Wei Hong; Sailesh Krishnamurthy; Samuel R Madden; Fred Reiss; Mehul A Shah,At Berkeley; we are developing TelegraphCQ [1; 2]; a dataflow system for processingcontinuous queries over data streams. TelegraphCQ is based on a novel; highly-adaptivearchitecture supporting dynamic query workloads in volatile data streaming environments. Inthis demonstration we show our current version of TelegraphCQ; which we implemented byleveraging the code base of the open source PostgreSQL database system. AlthoughTelegraphCQ differs significantly from a traditional database system; we found that asignificant portion of the PostgreSQL code was easily reusable. We also found theextensibility features of PostgreSQL very useful; particularly its rich data types and the abilityto load user-developed functions. Challenges: As discussed in [1]; sharing and adaptivityare our main techniques for implementing a continuous query system. Doing this in the …,Proceedings of the 2003 ACM SIGMOD international conference on Management of data,2003,1848
TinyOS: An operating system for sensor networks,Philip Levis; Sam Madden; Joseph Polastre; Robert Szewczyk; Kamin Whitehouse; Alec Woo; David Gay; Jason Hill; Matt Welsh; Eric Brewer; David Culler,Abstract We present TinyOS; a flexible; application-specific operating system for sensornetworks; which form a core component of ambient intelligence systems. Sensor networksconsist of (potentially) thousands of tiny; low-power nodes; each of which executeconcurrent; reactive programs that must operate with severe memory and power constraints.The sensor network challenges of limited resources; event-centric concurrent applications;and low-power operation drive the design of TinyOS. Our solution combines flexible; fine-grain components with an execution model that supports complex yet safe concurrentoperations. TinyOS meets these challenges well and has become the platform of choice forsensor network research; it is in use by over a hundred groups worldwide; and supports abroad range of applications and research topics. We provide a qualitative and …,*,2005,1706
Model-driven data acquisition in sensor networks,Amol Deshpande; Carlos Guestrin; Samuel R Madden; Joseph M Hellerstein; Wei Hong,Abstract Declarative queries are proving to be an attractive paradigm for ineracting withnetworks of wireless sensors. The metaphor that" the sensornet is a database" isproblematic; however; because sensors do not exhaustively represent the data in the realworld. In order to map the raw sensor readings onto physical reality; a model of that reality isrequired to complement the readings. In this paper; we enrich interactive sensor queryingwith statistical modeling techniques. We demonstrate that such models can help provideanswers that are both more meaningful; and; by introducing approximations withprobabilistic confidences; significantly more efficient to compute in both time and energy.Utilizing the combination of a model and live data acquisition raises the challengingoptimization problem of selecting the best sensor readings to acquire; balancing the …,Proceedings of the Thirtieth international conference on Very large data bases-Volume 30,2004,1340
The design of an acquisitional query processor for sensor networks,Samuel Madden; Michael J Franklin; Joseph M Hellerstein; Wei Hong,Abstract We discuss the design of an acquisitional query processor for data collection insensor networks. Acquisitional issues are those that pertain to where; when; and how oftendata is physically acquired (sampled) and delivered to query processing operators. Byfocusing on the locations and costs of acquiring data; we are able to significantly reducepower consumption over traditional passive systems that assume the a priori existence ofdata. We discuss simple extensions to SQL for controlling data acquisition; and show howacquisitional issues influence query optimization; dissemination; and execution. Weevaluate these issues in the context of TinyDB; a distributed query processor for smartsensor devices; and show how acquisitional techniques can provide significant reductions inpower consumption on our sensor devices.,Proceedings of the 2003 ACM SIGMOD international conference on Management of data,2003,1262
C-store: a column-oriented DBMS,Mike Stonebraker; Daniel J Abadi; Adam Batkin; Xuedong Chen; Mitch Cherniack; Miguel Ferreira; Edmond Lau; Amerson Lin; Sam Madden; Elizabeth O'Neil; Pat O'Neil; Alex Rasin; Nga Tran; Stan Zdonik,Abstract This paper presents the design of a read-optimized relational DBMS that contrastssharply with most current systems; which are write-optimized. Among the many differencesin its design are: storage of data by column rather than by row; careful coding and packing ofobjects into storage including main memory during query processing; storing an overlappingcollection of column-oriented projections; rather than the current fare of tables and indexes;a non-traditional implementation of transactions which includes high availability andsnapshot isolation for read-only transactions; and the extensive use of bitmap indexes tocomplement B-tree structures. We present preliminary performance data on a subset of TPC-H and show that the system we are building; C-Store; is substantially faster than popularcommercial products. Hence; the architecture looks very encouraging.,Proceedings of the 31st international conference on Very large data bases,2005,1250
CarTel: a distributed mobile sensor computing system,Bret Hull; Vladimir Bychkovsky; Yang Zhang; Kevin Chen; Michel Goraczko; Allen Miu; Eugene Shih; Hari Balakrishnan; Samuel Madden,Abstract CarTel is a mobile sensor computing system designed to collect; process; deliver;and visualize data from sensors located on mobile units such as automobiles. A CarTelnode is a mobile embedded computer coupled to a set of sensors. Each node gathers andprocesses sensor readings locally before delivering them to a central portal; where the datais stored in a database for further analysis and visualization. In the automotive context; avariety of on-board and external sensors collect data as users drive. CarTel provides asimple query-oriented programming interface; handles large amounts of heterogeneousdata from sensors; and handles intermittent and variable network connectivity. CarTel nodesrely primarily on opportunistic wireless (eg; Wi-Fi; Bluetooth) connectivity to the Internet; orto" data mules" such as other CarTel nodes; mobile phone flash memories; or USB keys …,Proceedings of the 4th international conference on Embedded networked sensor systems,2006,1210
A comparison of approaches to large-scale data analysis,Andrew Pavlo; Erik Paulson; Alexander Rasin; Daniel J Abadi; David J DeWitt; Samuel Madden; Michael Stonebraker,Abstract There is currently considerable enthusiasm around the MapReduce (MR) paradigmfor large-scale data analysis [17]. Although the basic control flow of this framework hasexisted in parallel SQL database management systems (DBMS) for over 20 years; somehave called MR a dramatically new computing model [8; 17]. In this paper; we describe andcompare both paradigms. Furthermore; we evaluate both kinds of systems in terms ofperformance and development complexity. To this end; we define a benchmark consisting ofa collection of tasks that we have run on an open source version of MR as well as on twoparallel DBMSs. For each task; we measure each system's performance for various degreesof parallelism on a cluster of 100 nodes. Our results reveal some interesting trade-offs.Although the process to load data into and tune the execution of parallel DBMSs took …,Proceedings of the 2009 ACM SIGMOD International Conference on Management of data,2009,1209
Continuously adaptive continuous queries over streams,Samuel Madden; Mehul Shah; Joseph M Hellerstein; Vijayshankar Raman,Abstract We present a continuously adaptive; continuous query (CACQ) implementationbased on the eddy query processing framework. We show that our design providessignificant performance benefits over existing approaches to evaluating continuous queries;not only because of its adaptivity; but also because of the aggressive cross-query sharing ofwork and space that it enables. By breaking the abstraction of shared relational algebraexpressions; our Telegraph CACQ implementation is able to share physical operators---bothselections and join state---at a very fine grain. We augment these features with a grouped-filter index to simultaneously evaluate multiple selection predicates. We includemeasurements of the performance of our core system; along with a comparison to existingcontinuous query approaches.,Proceedings of the 2002 ACM SIGMOD international conference on Management of data,2002,821
The pothole patrol: using a mobile sensor network for road surface monitoring,Jakob Eriksson; Lewis Girod; Bret Hull; Ryan Newton; Samuel Madden; Hari Balakrishnan,Abstract This paper investigates an application of mobile sensing: detecting and reportingthe surface conditions of roads. We describe a system and associated algorithms to monitorthis important civil infrastructure using a collection of sensor-equipped vehicles. This system;which we call the Pothole Patrol (P 2); uses the inherent mobility of the participatingvehicles; opportunistically gathering data from vibration and GPS sensors; and processingthe data to assess road surface conditions. We have deployed P 2 on 7 taxis running in theBoston area. Using a simple machine-learning approach; we show that we are able toidentify potholes and other severe road surface anomalies from accelerometer data. Viacareful selection of training data and signal features; we have been able to build a detectorthat misidentifies good road segments as having potholes less than 0.2% of the time. We …,Proceedings of the 6th international conference on Mobile systems; applications; and services,2008,764
VTrack: accurate; energy-aware road traffic delay estimation using mobile phones,Arvind Thiagarajan; Lenin Ravindranath; Katrina LaCurts; Samuel Madden; Hari Balakrishnan; Sivan Toledo; Jakob Eriksson,Abstract Traffic delays and congestion are a major source of inefficiency; wasted fuel; andcommuter frustration. Measuring and localizing these delays; and routing users aroundthem; is an important step towards reducing the time people spend stuck in traffic. As othershave noted; the proliferation of commodity smartphones that can provide location estimatesusing a variety of sensors---GPS; WiFi; and/or cellular triangulation---opens up the attractivepossibility of using position samples from drivers' phones to monitor traffic delays at a finespatiotemporal granularity. This paper presents VTrack; a system for travel time estimationusing this sensor data that addresses two key challenges: energy consumption and sensorunreliability. While GPS provides highly accurate location estimates; it has severallimitations: some phones don't have GPS at all; the GPS sensor doesn't work in" urban …,Proceedings of the 7th ACM conference on embedded networked sensor systems,2009,759
Scalable semantic web data management using vertical partitioning,Daniel J Abadi; Adam Marcus; Samuel R Madden; Kate Hollenbach,Abstract Efficient management of RDF data is an important factor in realizing the SemanticWeb vision. Performance and scalability issues are becoming increasingly pressing asSemantic Web technology is applied to real-world applications. In this paper; we examinethe reasons why current data management solutions for RDF data scale poorly; and explorethe fundamental scalability limitations of these approaches. We review the state of the art forimproving performance for RDF databases and consider a recent suggestion;" propertytables." We then discuss practically and empirically why this solution has undesirablefeatures. As an improvement; we propose an alternative solution: vertically partitioning theRDF data. We compare the performance of vertical partitioning with prior art on queriesgenerated by a Web-based RDF browser over a large-scale (more than 50 million triples) …,Proceedings of the 33rd international conference on Very large data bases,2007,745
The end of an architectural era:(it's time for a complete rewrite),Michael Stonebraker; Samuel Madden; Daniel J Abadi; Stavros Harizopoulos; Nabil Hachem; Pat Helland,Abstract In previous papers [SC05; SBC+ 07]; some of us predicted the end of" one size fitsall" as a commercial relational DBMS paradigm. These papers presented reasons andexperimental evidence that showed that the major RDBMS vendors can be outperformed by1--2 orders of magnitude by specialized engines in the data warehouse; stream processing;text; and scientific database markets. Assuming that specialized engines dominate thesemarkets over time; the current relational DBMS code lines will be left with the business dataprocessing (OLTP) market and hybrid markets where more than one kind of capability isrequired. In this paper we show that current RDBMSs can be beaten by nearly two orders ofmagnitude in the OLTP market as well. The experimental evidence comes from comparing anew OLTP prototype; H-Store; which we have built at MIT to a popular RDBMS on the …,Proceedings of the 33rd international conference on Very large data bases,2007,689
Fjording the stream: An architecture for queries over streaming sensor data,Samuel Madden; Michael J Franklin,If industry visionaries are correct; our lives will soon be full of sensors; connected together inloose conglomerations via wireless networks; each monitoring and collecting data about theenvironment at large. These sensors behave very differently from traditional databasesources: they have intermittent connectivity; are limited by severe power constraints; andtypically sample periodically and push immediately; keeping no record of historicalinformation. These limitations make traditional database systems inappropriate for queriesover sensors. We present the Fjords architecture for managing multiple queries over manysensors; and show how it can be used to limit sensor resource demands while maintaininghigh query throughput. We evaluate our architecture using traces from a network of trafficsensors deployed on Interstate 80 near Berkeley and present performance results that …,Data Engineering; 2002. Proceedings. 18th International Conference on,2002,674
Supporting aggregate queries over ad-hoc wireless sensor networks,Samuel Madden; Robert Szewczyk; Michael J Franklin; David Culler,We show how the database community's notion of a generic query interface for dataaggregation can be applied to ad-hoc networks of sensor devices. As has been noted in thesensor network literature; aggregation is important as a data reduction tool; networkingapproaches; however; have focused on application specific solutions; whereas our in-network aggregation approach is driven by a general purpose; SQL-style interface that canexecute queries over any type of sensor data while providing opportunities for significantoptimization. We present a variety of techniques to improve the reliability and performance ofour solution. We also show how grouped aggregates can be efficiently computed and offer acomparison to related systems and database projects.,Mobile Computing Systems and Applications; 2002. Proceedings Fourth IEEE Workshop on,2002,649
A measurement study of vehicular internet access using in situ Wi-Fi networks,Vladimir Bychkovsky; Bret Hull; Allen Miu; Hari Balakrishnan; Samuel Madden,Abstract The impressive penetration of 802.11-based wireless networks in manymetropolitan areas around the world offers; for the first time; the opportunity of a" grassroots"wireless Internet service provided by users who" open up" their 802.11 (Wi-Fi) access pointsin a controlled manner to mobile clients. While there are many business; legal; and policyissues to be ironed out for this vision to become reality; we are concerned in this paper withan important technical question surrounding such a system: can such an unplanned networkservice provide reasonable performance to network clients moving in cars at vehicularspeeds. To answer this question; we present the results of a measurement study carried outover 290" drive hours" over a few cars under typical driving conditions; in and around theBoston metropolitan area (some of our data also comes from a car in Seattle). With a …,Proceedings of the 12th annual international conference on Mobile computing and networking,2006,602
Column-stores vs. row-stores: how different are they really?,Daniel J Abadi; Samuel R Madden; Nabil Hachem,Abstract There has been a significant amount of excitement and recent work on column-oriented database systems (" column-stores"). These database systems have been shown toperform more than an order of magnitude better than traditional row-oriented databasesystems (" row-stores") on analytical workloads such as those found in data warehouses;decision support; and business intelligence applications. The elevator pitch behind thisperformance difference is straightforward: column-stores are more I/O efficient for read-onlyqueries since they only have to read from disk (or from memory) those attributes accessedby a query. This simplistic view leads to the assumption that one can obtain the performancebenefits of a column-store using a row-store: either by vertically partitioning the schema; orby indexing every column so that columns can be accessed independently. In this paper …,Proceedings of the 2008 ACM SIGMOD international conference on Management of data,2008,580
The Emergence of Networking Abstractions and Techniques in TinyOS.,Philip Levis; Samuel Madden; David Gay; Joseph Polastre; Robert Szewczyk; Alec Woo; Eric A Brewer; David E Culler,Abstract The constraints of sensor networks; an emerging area of network research; requirenew approaches in system design. We study the evolution of abstractions and techniques inTinyOS; a popular sensor network operating system. Examining CVS repositories of severalresearch institutions that use TinyOS; we trace three areas of development: single-hopnetworking; multi-hop networking; and network services. We note common techniques anddraw conclusions on the emerging abstractions as well as the novel constraints that haveshaped them.,NSDI,2004,570
Integrating compression and execution in column-oriented database systems,Daniel Abadi; Samuel Madden; Miguel Ferreira,Abstract Column-oriented database system architectures invite a re-evaluation of how andwhen data in databases is compressed. Storing data in a column-oriented fashion greatlyincreases the similarity of adjacent records on disk and thus opportunities for compression.The ability to compress many adjacent tuples at once lowers the per-tuple cost ofcompression; both in terms of CPU and space overheads. In this paper; we discuss how weextended C-Store (a column-oriented DBMS) with a compression sub-system. We show howcompression schemes not traditionally used in row-oriented DBMSs can be applied tocolumn-oriented systems. We then evaluate a set of compression schemes and show thatthe best scheme depends not only on the properties of the data but also on the nature of thequery workload.,Proceedings of the 2006 ACM SIGMOD international conference on Management of data,2006,567
MapReduce and parallel DBMSs: friends or foes?,Michael Stonebraker; Daniel Abadi; David J DeWitt; Sam Madden; Erik Paulson; Andrew Pavlo; Alexander Rasin,The technology press has been focusing on the revolution of "cloud computing;" a paradigmthat entails the harnessing of large numbers of processors working in parallel to solve computingproblems. In effect; this suggests constructing a data center by lining up a large number oflow-end servers; rather than deploying a smaller set of high-end servers. Along with this interestin clusters has come a proliferation of tools for programming them. MR is one such tool; an attractiveoption to many because it provides a simple model through which users are able to expressrelatively sophisticated distributed programs … Given the interest in the MR model both commerciallyand academically; it is natural to ask whether MR systems should replace parallel databasesystems. Parallel DBMSs were first available commercially nearly two decades ago; and;today; systems (from about a dozen vendors) are available. As robust; high-performance …,Communications of the ACM,2010,549
PIPENET: A wireless sensor network for pipeline monitoring,Ivan Stoianov; Lama Nachman; Sam Madden; Timur Tokmouline; M Csail,US water utilities are faced with mounting operational and maintenance costs as a result ofaging pipeline infrastructures. Leaks and ruptures in water supply pipelines and blockagesand overflow events in sewer collectors cost millions of dollars a year; and monitoring andrepairing this underground infrastructure presents a severe challenge. In this paper; wediscuss how wireless sensor networks (WSNs) can increase the spatial and temporalresolution of operational data from pipeline infrastructures and thus address the challenge ofnear real-time monitoring and eventually control. We focus on the use of WSNs formonitoring large diameter bulk-water transmission pipelines. We outline a system; PipeNet;we have been developing for collecting hydraulic and acoustic/vibration data at highsampling rates as well as algorithms for analyzing this data to detect and locate leaks …,Information Processing in Sensor Networks; 2007. IPSN 2007. 6th International Symposium on,2007,510
Twitinfo: aggregating and visualizing microblogs for event exploration,Adam Marcus; Michael S Bernstein; Osama Badar; David R Karger; Samuel Madden; Robert C Miller,Abstract Microblogs are a tremendous repository of user-generated content about worldevents. However; for people trying to understand events by querying services like Twitter; achronological log of posts makes it very difficult to get a detailed understanding of an event.In this paper; we present TwitInfo; a system for visualizing and summarizing events onTwitter. TwitInfo allows users to browse a large collection of tweets using a timeline-baseddisplay that highlights peaks of high tweet activity. A novel streaming algorithm automaticallydiscovers these peaks and labels them meaningfully using text from the tweets. Users candrill down to subevents; and explore further via geolocation; sentiment; and popular URLs.We contribute a recall-normalized aggregate sentiment visualization to produce morehonest sentiment overviews. An evaluation of the system revealed that users were able to …,Proceedings of the SIGCHI conference on Human factors in computing systems,2011,507
Cabernet: vehicular content delivery using WiFi,Jakob Eriksson; Hari Balakrishnan; Samuel Madden,Abstract Cabernet is a system for delivering data to and from moving vehicles using open802.11 (WiFi) access points encountered opportunistically during travel. Using open WiFiaccess from the road can be challenging. Network connectivity in Cabernet is both fleeting(access points are typically within range for a few seconds) and intermittent (because theaccess points do not provide continuous coverage); and suffers from high packet loss ratesover the wireless channel. On the positive side; WiFi data transfers; when available; canoccur at broadband speeds. In this paper; we introduce two new components for improvingopenWiFi data delivery to moving vehicles: The first; QuickWiFi; is a streamlined client-sideprocess to establish end-to-end connectivity; reducing mean connection time to less than400 ms; from over 10 seconds when using standard wireless networking software. The …,Proceedings of the 14th ACM international conference on Mobile computing and networking,2008,498
Distributed regression: an efficient framework for modeling sensor network data,Carlos Guestrin; Peter Bodik; Romain Thibaux; Mark Paskin; Samuel Madden,Abstract We present distributed regression; an efficient and general framework for in-network modeling of sensor data. In this framework; the nodes of the sensor networkcollaborate to optimally fit a global function to each of their local measurements. Thealgorithm is based upon kernel linear regression; where the model takes the form of aweighted sum of local basis functions; this provides an expressive yet tractable class ofmodels for sensor network data. Rather than transmitting data to one another or outside thenetwork; nodes communicate constraints on the model parameters; drastically reducing thecommunication required. After the algorithm is run; each node can answer queries for itslocal region; or the nodes can efficiently transmit the parameters of the model to a useroutside the network. We present an evaluation of the algorithm based upon data from a …,Proceedings of the 3rd international symposium on Information processing in sensor networks,2004,497
Query processing in sensor networks,Johannes Gehrke; Samuel Madden,Smart sensors are small wireless computing devices that sense information such as lightand humidity at extremely high resolutions. A smart sensor query-processing architectureusing database technology can facilitate deployment of sensor networks. Smart-sensortechnology enables a broad range of ubiquitous computing applications. Their low cost;small size; and untethered nature lets them sense information at previously unobtainableresolutions. We discuss about query processing in sensor networks.,IEEE Pervasive computing,2004,452
H-store: a high-performance; distributed main memory transaction processing system,Robert Kallman; Hideaki Kimura; Jonathan Natkins; Andrew Pavlo; Alexander Rasin; Stanley Zdonik; Evan PC Jones; Samuel Madden; Michael Stonebraker; Yang Zhang; John Hugg; Daniel J Abadi,Abstract Our previous work has shown that architectural and application shifts have resultedin modern OLTP databases increasingly falling short of optimal performance [10]. Inparticular; the availability of multiple-cores; the abundance of main memory; the lack of userstalls; and the dominant use of stored procedures are factors that portend a clean-slateredesign of RDBMSs. This previous work showed that such a redesign has the potential tooutperform legacy OLTP databases by a significant factor. These results; however; wereobtained using a bare-bones prototype that was developed just to demonstrate the potentialof such a system. We have since set out to design a more complete execution platform; andto implement some of the ideas presented in the original paper. Our demonstrationpresented here provides insight on the development of a distributed main memory OLTP …,Proceedings of the VLDB Endowment,2008,439
Schism: a workload-driven approach to database replication and partitioning,Carlo Curino; Evan Jones; Yang Zhang; Sam Madden,Abstract We present Schism; a novel workload-aware approach for database partitioningand replication designed to improve scalability of shared-nothing distributed databases.Because distributed transactions are expensive in OLTP settings (a fact we demonstratethrough a series of experiments); our partitioner attempts to minimize the number ofdistributed transactions; while producing balanced partitions. Schism consists of two phases:i) a workload-driven; graph-based replication/partitioning phase and ii) an explanation andvalidation phase. The first phase creates a graph with a node per tuple (or group of tuples)and edges between nodes accessed by the same transaction; and then uses a graphpartitioner to split the graph into k balanced partitions that minimize the number of cross-partition transactions. The second phase exploits machine learning techniques to find a …,Proceedings of the VLDB Endowment,2010,430
From databases to big data,Sam Madden,There is a tremendous amount of buzz around the concept of" big data." In this article; theauthor discusses the origins of this trend; the relationship between big data and traditionaldatabases and data processing platforms; and some of the new challenges that big datapresents.,IEEE Internet Computing,2012,403
BlinkDB: queries with bounded errors and bounded response times on very large data,Sameer Agarwal; Barzan Mozafari; Aurojit Panda; Henry Milner; Samuel Madden; Ion Stoica,Abstract In this paper; we present BlinkDB; a massively parallel; approximate query enginefor running interactive SQL queries on large volumes of data. BlinkDB allows users to trade-off query accuracy for response time; enabling interactive queries over massive data byrunning queries on data samples and presenting results annotated with meaningful errorbars. To achieve this; BlinkDB uses two key ideas:(1) an adaptive optimization frameworkthat builds and maintains a set of multi-dimensional stratified samples from original dataover time; and (2) a dynamic sample selection strategy that selects an appropriately sizedsample based on a query's accuracy or response time requirements. We evaluate BlinkDBagainst the well-known TPC-H benchmarks and a real-world analytic workload derived fromConviva Inc.; a company that manages video distribution over the Internet. Our …,Proceedings of the 8th ACM European Conference on Computer Systems,2013,399
Relational cloud: A database-as-a-service for the cloud,Carlo Curino; Evan PC Jones; Raluca Ada Popa; Nirmesh Malviya; Eugene Wu; Sam Madden; Hari Balakrishnan; Nickolai Zeldovich,This paper introduces a new transactional “database-as-a-service”(DBaaS) calledRelational Cloud. A DBaaS promises to move much of the operational burden ofprovisioning; configuration; scaling; performance tuning; backup; privacy; and access controlfrom the database users to the service operator; offering lower overall costs to users. EarlyDBaaS efforts include Amazon RDS and Microsoft SQL Azure; which are promising in termsof establishing the market need for such a service; but which do not address three importantchallenges: efficient multi-tenancy; elastic scalability; and database privacy. We argue thatthese three challenges must be overcome before outsourcing database software andmanagement becomes attractive to many users; and cost-effective for service providers. Thekey technical features of Relational Cloud include:(1) a workload-aware approach to multi …,*,2011,347
Beyond average: Toward sophisticated sensing with queries,Joseph M Hellerstein; Wei Hong; Samuel Madden; Kyle Stanek,Abstract High-level query languages are an attractive interface for sensor networks;potentially relieving application programmers from the burdens of distributed; embeddedprogramming. In research to date; however; the proposed applications of such interfaceshave been limited to simple data collection and aggregation schemes. In this paper; wepresent initial results that extend the TinyDB sensornet query engine to support moresophisticated data analyses; focusing on three applications: topographic mapping; wavelet-based compression; and vehicle tracking. We use these examples to motivate the feasibilityof implementing sophisticated sensing applications in a query-based system; and presentsome initial results and research questions raised by this agenda.,*,2003,335
Mobiscopes for human spaces,Tarek Abdelzaher; Yaw Anokwa; Peter Boda; Jeff Burke; Deborah Estrin; Leonidas Guibas; Aman Kansal; Samuel Madden; Jim Reich,Mobiscopes extend the traditional sensor network model; introducing challenges in datamanagement and integrity; privacy; and network system design. Researchers need anarchitecture and general methodology for designing future mobiscopes. A mobiscope is afederation of distributed mobile sensors into a taskable sensing system that achieves high-density sampling coverage over a wide area through mobility.,IEEE pervasive computing,2007,310
Reed: Robust; efficient filtering and event detection in sensor networks,Daniel J Abadi; Samuel Madden; Wolfgang Lindner,Abstract This paper presents a set of algorithms for efficiently evaluating join queries overstatic data tables in sensor networks. We describe and evaluate three algorithms that takeadvantage of distributed join techniques. Our algorithms are capable of running in limitedamounts of RAM; can distribute the storage burden over groups of nodes; and are tolerant todropped packets and node failures. REED is thus suitable for a wide range of event-detection applications that traditional sensor network database and data collection systemscannot be used to implement.,Proceedings of the 31st international conference on Very large data bases,2005,287
PAQ: Time series forecasting for approximate query answering in sensor networks,Daniela Tulone; Samuel Madden,Abstract In this paper; we present a method for approximating the values of sensors in awireless sensor network based on time series forecasting. More specifically; our approachrelies on autoregressive models built at each sensor to predict local readings. Nodestransmit these local models to a sink node; which uses them to predict sensor values withoutdirectly communicating with sensors. When needed; nodes send information about outlierreadings and model updates to the sink. We show that this approach can dramaticallyreduce the amount of communication required to monitor the readings of all sensors in anetwork; and demonstrate that our approach provides provably-correct; user-controllableerror bounds on the predicted values of each sensor.,European Workshop on Wireless Sensor Networks,2006,284
OLTP through the looking glass; and what we found there,Stavros Harizopoulos; Daniel J Abadi; Samuel Madden; Michael Stonebraker,Abstract Online Transaction Processing (OLTP) databases include a suite of features-disk-resident B-trees and heap files; locking-based concurrency control; support for multi-threading-that were optimized for computer technology of the late 1970's. Advances inmodern processors; memories; and networks mean that today's computers are vastlydifferent from those of 30 years ago; such that many OLTP databases will now fit in mainmemory; and most OLTP transactions can be processed in milliseconds or less. Yetdatabase architecture has changed little. Based on this observation; we look at someinteresting variants of conventional database systems that one might build that exploit recenthardware trends; and speculate on their performance through a detailed instruction-levelbreakdown of the major components involved in a transaction processing database …,Proceedings of the 2008 ACM SIGMOD international conference on Management of data,2008,283
Overview of SciDB: large scale array storage; processing and analysis,Paul G Brown,Abstract SciDB [4; 3] is a new open-source data management system intended primarily foruse in application domains that involve very large (petabyte) scale array data; for example;scientific applications such as astronomy; remote sensing and climate modeling; bio-scienceinformation management; risk management systems in financial applications; and theanalysis of web log data. In this talk we will describe our set of motivating examples and usethem to explain the features of SciDB. We then briefly give an overview of the project'inflight'; explaining our novel storage manager; array data model; query language; andextensibility frameworks.,Proceedings of the 2010 ACM SIGMOD International Conference on Management of data,2010,280
SW-Store: a vertically partitioned DBMS for Semantic Web data management,Daniel J Abadi; Adam Marcus; Samuel R Madden; Kate Hollenbach,Abstract Efficient management of RDF data is an important prerequisite for realizing theSemantic Web vision. Performance and scalability issues are becoming increasinglypressing as Semantic Web technology is applied to real-world applications. In this paper; weexamine the reasons why current data management solutions for RDF data scale poorly;and explore the fundamental scalability limitations of these approaches. We review the stateof the art for improving performance of RDF databases and consider a recentsuggestion;“property tables”. We then discuss practically and empirically why this solutionhas undesirable features. As an improvement; we propose an alternative solution: verticallypartitioning the RDF data. We compare the performance of vertical partitioning with prior arton queries generated by a Web-based RDF browser over a large-scale (more than 50 …,The VLDB Journal,2009,279
Adaptive query processing: Technology in evolution,Joseph M.  Hellerstein; Michael J.  Franklin; Sirish Chandrasekaran; Amol Deshpande; Kris Hildrum; Samuel Madden; Vijayshankar Raman; Mehul A.  Shah,Abstract As query engines are scaled and federated; they must cope with highlyunpredictable and changeable environments. In the Telegraph project; we are attempting toarchitect and implement a continuously adaptive query engine suitable for global-areasystems; massive parallelism; and sensor networks. To set the stage for our research; wepresent a survey of prior work on adaptive query processing; focusing on threecharacterizations of adaptivity: the frequency of adaptivity; the effects of adaptivity; and theextent of adaptivity. Given this survey; we sketch directions for research in the Telegraphproject.,IEEE Data Eng. Bull.,2000,278
Materialization strategies in a column-oriented DBMS,Daniel J Abadi; Daniel S Myers; David J DeWitt; Samuel R Madden,There has been renewed interest in column-oriented database architectures in recent years.For read-mostly query workloads such as those found in data warehouse and decisionsupport applications;" column-stores" have been shown to perform particularly well relativeto" row-stores" In order for column-stores to be readily adopted as a replacement for row-stores; however; they must present the same interface to client applications as do row stores;which implies that they must output row-store-style tuples. Thus; the input columns stored ondisk must be converted to rows at some point in the query plan; but the optimal point atwhich to do the conversion is not obvious. This problem can be considered as the oppositeof the projection problem in row-store systems: while row-stores need to determine where inquery plans to place projection operators to make tuples narrower; column-stores need to …,Data Engineering; 2007. ICDE 2007. IEEE 23rd International Conference on,2007,259
Human-powered sorts and joins,Adam Marcus; Eugene Wu; David Karger; Samuel Madden; Robert Miller,Abstract Crowdsourcing markets like Amazon's Mechanical Turk (MTurk) make it possible totask people with small jobs; such as labeling images or looking up phone numbers; via aprogrammatic interface. MTurk tasks for processing datasets with humans are currentlydesigned with significant reimplementation of common workflows and ad-hoc selection ofparameters such as price to pay per task. We describe how we have integrated crowds intoa declarative workflow engine called Qurk to reduce the burden on workflow designers. Inthis paper; we focus on how to use humans to compare items for sorting and joining data;two of the most common operations in DBMSs. We describe our basic query interface andthe user interface of the tasks we post to MTurk. We also propose a number of optimizations;including task batching; replacing pairwise comparisons with numerical ratings; and pre …,Proceedings of the VLDB Endowment,2011,256
TASK: Sensor network in a box,Philip Buonadonna; David Gay; Joseph M Hellerstein; Wei Hong; Samuel Madden,Sensornet systems research is being conducted with various applications and deploymentscenarios in mind. In many of these scenarios; the presumption is that the sensornet will bedeployed and managed by users who do not have a background in computer science. In thispaper we describe the" tiny application sensor kit"(TASK); a system we have designed foruse by end-users with minimal sensornet sophistication. We describe the requirements thatguided our design; the architecture of the system and results from initial deployments. Basedon our experience to date we present preliminary design principles and research challengesthat arise in delivering sensornet research to end users.,Wireless Sensor Networks; 2005. Proceeedings of the Second European Workshop on,2005,239
HYRISE: a main memory hybrid storage engine,Martin Grund; Jens Krüger; Hasso Plattner; Alexander Zeier; Philippe Cudre-Mauroux; Samuel Madden,Abstract In this paper; we describe a main memory hybrid database system called HYRISE;which automatically partitions tables into vertical partitions of varying widths depending onhow the columns of the table are accessed. For columns accessed as a part of analyticalqueries (eg; via sequential scans); narrow partitions perform better; because; whenscanning a single column; cache locality is improved if the values of that column are storedcontiguously. In contrast; for columns accessed as a part of OLTP-style queries; widerpartitions perform better; because such transactions frequently insert; delete; update; oraccess many of the fields of a row; and co-locating those fields leads to better cache locality.Using a highly accurate model of cache misses; HYRISE is able to predict the performanceof different partitionings; and to automatically select the best partitioning using an …,Proceedings of the VLDB Endowment,2010,219
MauveDB: supporting model-based user views in database systems,Amol Deshpande; Samuel Madden,Abstract Real-world data---especially when generated by distributed measurementinfrastructures such as sensor networks---tends to be incomplete; imprecise; and erroneous;making it impossible to present it to users or feed it directly into applications. The traditionalapproach to dealing with this problem is to first process the data using statistical orprobabilistic models that can provide more robust interpretations of the data. Currentdatabase systems; however; do not provide adequate support for applying models to suchdata; especially when those models need to be frequently updated as new data arrives inthe system. Hence; most scientists and engineers who depend on models for managing theirdata do not use database systems for archival or querying at all; at best; databases serve asa persistent raw data store. In this paper we define a new abstraction called model-based …,Proceedings of the 2006 ACM SIGMOD international conference on Management of data,2006,217
Processing analytical queries over encrypted data,Stephen Tu; M Frans Kaashoek; Samuel Madden; Nickolai Zeldovich,Abstract MONOMI is a system for securely executing analytical workloads over sensitivedata on an untrusted database server. MONOMI works by encrypting the entire databaseand running queries over the encrypted data. MONOMI introduces split client/server queryexecution; which can execute arbitrarily complex queries over encrypted data; as well asseveral techniques that improve performance for such workloads; including per-rowprecomputation; space-efficient encryption; grouped homomorphic addition; and pre-filtering. Since these optimizations are good for some queries but not others; MONOMIintroduces a designer for choosing an efficient physical design at the server for a givenworkload; and a planner to choose an efficient execution plan for a given query at runtime. Aprototype of MONOMI running on top of Postgres can execute most of the queries from the …,Proceedings of the VLDB Endowment,2013,211
Performance tradeoffs in read-optimized databases,Stavros Harizopoulos; Velen Liang; Daniel J Abadi; Samuel Madden,Abstract Database systems have traditionally optimized performance for write-intensiveworkloads. Recently; there has been renewed interest in architectures that optimize readperformance by using column-oriented data representation and light-weight compression.This previous work has shown that under certain broad classes of workloads; column-basedsystems can outperform row-based systems. Previous work; however; has not characterizedthe precise conditions under which a particular query workload can be expected to performbetter on a column-oriented database. In this paper we first identify the distinctivecomponents of a read-optimized DBMS and describe our implementation of a high-performance query engine that can operate on both row and column-oriented data. We thenuse our prototype to perform an in-depth analysis of the tradeoffs between column and …,Proceedings of the 32nd international conference on Very large data bases,2006,211
The sensor network as a database,Ramesh Govindan; Joseph Hellerstein; Wei Hong; Samuel Madden; Michael Franklin; Scott Shenker,Abstract Wireless sensor networks are an emerging area of research interest with a numberof compelling potential applications. By architecting sensor networks as virtual databases;we can provide a well-understood nonprocedural programming interface suitable to datamanagement; allowing the community to realize sensornet applications rapidly. We arguehere that in order to achieve an energy-efficient and useful implementation; queryprocessing operators should be implemented within the sensor network; and thatapproximate query results will play a key role. We observe that innetwork implementations ofdatabase operators require novel data-centric routing mechanisms; as well as areconsideration of traditional network and database interface layering.,*,2002,207
Fault-tolerance in the Borealis distributed stream processing system,Magdalena Balazinska; Hari Balakrishnan; Samuel Madden; Michael Stonebraker,Abstract We present a replication-based approach to fault-tolerant distributed streamprocessing in the face of node failures; network failures; and network partitions. Ourapproach aims to reduce the degree of inconsistency in the system while guaranteeing thatavailable inputs capable of being processed are processed within a specified timethreshold. This threshold allows a user to trade availability for consistency: a larger timethreshold decreases availability but limits inconsistency; while a smaller threshold increasesavailability but produces more inconsistent results based on partial data. In addition; whenfailures heal; our scheme corrects previously produced results; ensuring eventualconsistency. Our scheme uses a data-serializing operator to ensure that all replicas processdata in the same order; and thus remain consistent in the absence of failures. To regain …,Proceedings of the 2005 ACM SIGMOD international conference on Management of data,2005,203
Crowdsourced databases: Query processing with people,Adam Marcus; Eugene Wu; David R Karger; Samuel Madden; Robert C Miller,Amazon's Mechanical Turk (\MTurk") service allows users to post short tasks (\HITs") thatother users can receive a small amount of money for completing. Common tasks on thesystem include labelling a collection of images; com-bining two sets of images to identifypeople which appear in both; or extracting sentiment from a corpus of text snippets.Designing a work ow of various kinds of HITs for ltering; aggregating; sorting; and joiningdata sources together is common; and comes with a set of challenges in optimizing the costper HIT; the overall time to task completion; and the accuracy of MTurk results. We proposeQurk; a novel query system for managing these work ows; allowing crowd-poweredprocessing of relational databases. We describe a number of query execution andoptimization challenges; and discuss some potential solutions.,*,2011,192
Zstream: a cost-based query processor for adaptively detecting composite events,Yuan Mei; Samuel Madden,Abstract Composite (or Complex) event processing (CEP) systems search sequences ofincoming events for occurrences of user-specified event patterns. Recently; they havegained more attention in a variety of areas due to their powerful and expressive querylanguage and performance potential. Sequentiality (temporal ordering) is the primary way inwhich CEP systems relate events to each other. In this paper; we present a CEP systemcalled ZStream to efficiently process such sequential patterns. Besides simple sequentialpatterns; ZStream is also able to detect other patterns; including conjunction; disjunction;negation and Kleene closure. Unlike most recently proposed CEP systems; which use non-deterministic finite automata (NFA's) to detect patterns; ZStream uses tree-based queryplans for both the logical and physical representation of query patterns. By carefully …,Proceedings of the 2009 ACM SIGMOD International Conference on Management of data,2009,186
Accurate; low-energy trajectory mapping for mobile devices,Arvind Thiagarajan; Lenin Ravindranath; Hari Balakrishnan; Samuel Madden; Lewis Girod,Abstract CTrack is an energy-efficient system for trajectory mapping using raw positiontracks obtained largely from cellular base station fingerprints. Trajectory mapping; whichinvolves taking a sequence of raw position samples and producing the most likely pathfollowed by the user; is an important component in many locationbased services includingcrowd-sourced traffic monitoring; navigation and routing; and personalized tripmanagement. Using only cellular (GSM) fingerprints instead of power-hungry GPS and WiFiradios; the marginal energy consumed for trajectory mapping is zero. This approach is non-trivial because we need to process streams of highly inaccurate GSM localization samples(average error of over 175 meters) and produce an accurate trajectory. CTrack meets thischallenge using a novel two-pass Hidden Markov Model that sequences cellular GSM …,*,2011,185
Speedy transactions in multicore in-memory databases,Stephen Tu; Wenting Zheng; Eddie Kohler; Barbara Liskov; Samuel Madden,Abstract Silo is a new in-memory database that achieves excellent performance andscalability on modern multicore machines. Silo was designed from the ground up to usesystem memory and caches efficiently. For instance; it avoids all centralized contentionpoints; including that of centralized transaction ID assignment. Silo's key contribution is acommit protocol based on optimistic concurrency control that provides serializability whileavoiding all shared-memory writes for records that were only read. Though this might seemto complicate the enforcement of a serial order; correct logging and recovery is provided bylinking periodically-updated epochs with the commit protocol. Silo provides the sameguarantees as any serializable database without unnecessary scalability bottlenecks ormuch additional latency. Silo achieves almost 700;000 transactions per second on a …,Proceedings of the Twenty-Fourth ACM Symposium on Operating Systems Principles,2013,178
Custody transfer for reliable delivery in delay tolerant networks,Kevin Fall; Wei Hong; Samuel Madden,Abstract—We investigate the custody transfer mecha-nism proposed for enhancing reliabilityin delay-tolerant networks. This mechanism; which utilizes hop-by-hop transfer of reliabledelivery responsibility; shares many features in common with a database transaction. Byconsidering custody transfer in this light; we observe that it can cause the creation ofduplicate message fragments within the network that ordinarily may pose no significantproblem; but can be cause for concern if in-network processing and data fusion areemployed. We also extend the DTN architecture with the concept of a transaction abort; andshow how it can be used for helping to free network resources being consumed byfragments that remain after completion of a previous message transfer.,IRB-TR-03-030; July,2003,174
Exploiting correlated attributes in acquisitional query processing,Amol Deshpande; Carlos Guestrin; Wei Hong; Samuel Madden,Sensor networks and other distributed information systems (such as the Web) mustfrequently access data that has a high per-attribute acquisition cost; in terms of energy;latency; or computational resources. When executing queries that contain several predicatesover such expensive attributes; we observe that it can be beneficial to use correlations toautomatically introduce low-cost attributes whose observation will allow the query processorto better estimate die selectivity of these expensive predicates. In particular; we show how tobuild conditional plans that branch into one or more sub-plans; each with a different orderingfor the expensive query predicates; based on the runtime observation of low-cost attributes.We frame the problem of constructing the optimal conditional plan for a given user query andset of candidate low-cost attributes as an optimization problem. We describe an …,Data Engineering; 2005. ICDE 2005. Proceedings. 21st International Conference on,2005,172
MDCC: Multi-data center consistency,Tim Kraska; Gene Pang; Michael J Franklin; Samuel Madden; Alan Fekete,Abstract Replicating data across multiple data centers allows using data closer to the client;reducing latency for applications; and increases the availability in the event of a data centerfailure. MDCC (Multi-Data Center Consistency) is an optimistic commit protocol for geo-replicated transactions; that does not require a master or static partitioning; and is stronglyconsistent at a cost similar to eventually consistent protocols. MDCC takes advantage ofGeneralized Paxos for transaction processing and exploits commutative updates with valueconstraints in a quorum-based system. Our experiments show that MDCC outperformsexisting synchronous transactional replication protocols; such as Megastore; by requiringonly a single message round-trip in the normal operational case independent of the master-location and by scaling linearly with the number of machines as long as transaction …,Proceedings of the 8th ACM European Conference on Computer Systems,2013,169
Workload-aware database monitoring and consolidation,Carlo Curino; Evan PC Jones; Samuel Madden; Hari Balakrishnan,Abstract In most enterprises; databases are deployed on dedicated database servers. Often;these servers are underutilized much of the time. For example; in traces from almost 200production servers from different organizations; we see an average CPU utilization of lessthan 4%. This unused capacity can be potentially harnessed to consolidate multipledatabases on fewer machines; reducing hardware and operational costs. Virtual machine(VM) technology is one popular way to approach this problem. However; as we demonstratein this paper; VMs fail to adequately support database consolidation; because databasesplace a unique and challenging set of demands on hardware resources; which are not well-suited to the assumptions made by VM-based consolidation. Instead; our system fordatabase consolidation; named Kairos; uses novel techniques to measure the hardware …,Proceedings of the 2011 ACM SIGMOD International Conference on Management of data,2011,162
The Claremont report on database research,Rakesh Agrawal; Anastasia Ailamaki; Philip A Bernstein; Eric A Brewer; Michael J Carey; Surajit Chaudhuri; AnHai Doan; Daniela Florescu; Michael J Franklin; Hector Garcia-Molina; Johannes Gehrke; Le Gruenwald; Laura M Haas; Alon Y Halevy; Joseph M Hellerstein; Yannis E Ioannidis; Hank F Korth; Donald Kossmann; Samuel Madden; Roger Magoulas; Beng Chin Ooi; Tim O'Reilly; Raghu Ramakrishnan; Sunita Sarawagi; Michael Stonebraker; Alexander S Szalay; Gerhard Weikum,Abstract In late May; 2008; a group of database researchers; architects; users and punditsmet at the Claremont Resort in Berkeley; California to discuss the state of the research fieldand its impacts on practice. This was the seventh meeting of this sort in twenty years; andwas distinguished by a broad consensus that we are at a turning point in the history of thefield; due both to an explosion of data and usage scenarios; and to major shifts in computinghardware and platforms. Given these forces; we are at a time of opportunity for researchimpact; with an unusually large potential for influential results across computing; thesciences and society. This report details that discussion; and highlights the group'sconsensus view of new focus areas; including new database engine architectures;declarative programming languages; the interplay of structured and unstructured data …,ACM Sigmod Record,2008,161
Fault-tolerance in the borealis distributed stream processing system,Magdalena Balazinska; Hari Balakrishnan; Samuel R Madden; Michael Stonebraker,Abstract Over the past few years; Stream Processing Engines (SPEs) have emerged as anew class of software systems; enabling low latency processing of streams of data arriving athigh rates. As SPEs mature and get used in monitoring applications that must continuouslyrun (eg; in network security monitoring); a significant challenge arises: SPEs must be able tohandle various software and hardware faults that occur; masking them to provide highavailability (HA). In this article; we develop; implement; and evaluate DPC (Delay; Process;and Correct); a protocol to handle crash failures of processing nodes and network failures ina distributed SPE. Like previous approaches to HA; DPC uses replication and masks manytypes of node and network failures. In the presence of network partitions; the designer of anyreplication system faces a choice between providing availability or data consistency …,ACM Transactions on Database Systems (TODS),2008,155
A demonstration of SciDB: a science-oriented DBMS,Philippe Cudré-Mauroux; Hideaki Kimura; K-T Lim; Jennie Rogers; Roman Simakov; Emad Soroush; Pavel Velikhov; Daniel L Wang; Magdalena Balazinska; Jacek Becla; D DeWitt; Bobbi Heath; David Maier; Samuel Madden; J Patel; Michael Stonebraker; S Zdonik,Abstract In CIDR 2009; we presented a collection of requirements for SciDB; a DBMS thatwould meet the needs of scientific users. These included a nested-array data model; science-specific operations such as regrid; and support for uncertainty; lineage; and named versions.In this paper; we present an overview of SciDB's key features and outline a demonstration ofthe first version of SciDB on data and operations from one of our lighthouse users; the LargeSynoptic Survey Telescope (LSST).,Proceedings of the VLDB Endowment,2009,153
Model-based approximate querying in sensor networks,Amol Deshpande; Carlos Guestrin; Samuel R Madden; Joseph M Hellerstein; Wei Hong,Abstract Declarative queries are proving to be an attractive paradigm for interacting withnetworks of wireless sensors. The metaphor that “the sensornet is a database” isproblematic; however; because sensors do not exhaustively represent the data in the realworld. In order to map the raw sensor readings onto physical reality; a model of that reality isrequired to complement the readings. In this article; we enrich interactive sensor queryingwith statistical modeling techniques. We demonstrate that such models can help provideanswers that are both more meaningful; and; by introducing approximations withprobabilistic confidences; significantly more efficient to compute in both time and energy.Utilizing the combination of a model and live data acquisition raises the challengingoptimization problem of selecting the best sensor readings to acquire; balancing the …,The VLDB journal,2005,146
Low overhead concurrency control for partitioned main memory databases,Evan PC Jones; Daniel J Abadi; Samuel Madden,Abstract Database partitioning is a technique for improving the performance of distributedOLTP databases; since" single partition" transactions that access data on one partition donot need coordination with other partitions. For workloads that are amenable to partitioning;some argue that transactions should be executed serially on each partition without anyconcurrency at all. This strategy makes sense for a main memory database where there areno disk or user stalls; since the CPU can be fully utilized and the overhead of traditionalconcurrency control; such as two-phase locking; can be avoided. Unfortunately; many OLTPapplications have some transactions which access multiple partitions. This introducesnetwork stalls in order to coordinate distributed transactions; which will limit the performanceof a database that does not allow concurrency. In this paper; we compare two low …,Proceedings of the 2010 ACM SIGMOD International Conference on Management of data,2010,144
TelegraphCQ: An architectural status report,Sailesh Krishnamurthy; Sirish Chandrasekaran; Owen Cooper; Amol Deshpande; Michael J.  Franklin; Joseph M.  Hellerstein; Wei Hong; Samuel Madden; Frederick Reiss; Mehul A.  Shah,Abstract We are building TelegraphCQ; a system to process continuous queries over datastreams. Although we had implemented some parts of this technology in earlier Java-basedprototypes; our experiences were not positive. As a result; we decided to use PostgreSQL;an open source RDBMS as a starting point for our new implementation. In March 2003; wecompleted an alpha milestone of TelegraphCQ. In this paper; we report on the developmentstatus of our project; with a focus on architectural issues. Specifically; we describe ourexperiences extending a traditional DBMS towards managing data streams; and anoverview of the current early-access release of the system.,IEEE Data Eng. Bull.,2003,138
Query execution in column-oriented database systems,Daniel J Abadi,There are two obvious ways to map a two-dimension relational database table onto a one-dimensional storage interface: store the table row-by-row; or store the table column-by-column. Historically; database system implementations and research have focused on therow-by row data layout; since it performs best on the most common application for databasesystems: business transactional data processing. However; there are a set of emergingapplications for database systems for which the row-by-row layout performs poorly. Theseapplications are more analytical in nature; whose goal is to read through the data to gainnew insight and use it to drive decision making and planning. In this dissertation; we studythe problem of poor performance of row-by-row data layout for these emerging applications;and evaluate the column-by-column data layout opportunity as a solution to this problem …,*,2008,136
The design and evaluation of a query processing architecture for sensor networks,Samuel Ross Madden; Michael J Franklin,Samuel Ross Madden Doctor of Philosophy in Computer Science University of California;Berkeley Professor Michael J. Franklin; Chair With the advent of small; battery-powered;wireless computing and sensing technology; it is now possible to monitor and observe theworld at unprecedented levels of granularity. Networks of such devices typically consist oftens or hundreds of small; power constrained nodes deployed in remote locations whichthey are expected to monitor for months or years at a time. Such networks present significantnew opportunities for the data management community. In this dissertation; we summarizethe issues and opportunities associated with collecting and processing information fromthese wireless sensor networks; focusing on the performance and easeof-use advantages ofa declarative; query-based approach. We present the architecture of a query processing …,*,2003,135
Trajstore: An adaptive storage system for very large trajectory data sets,Philippe Cudre-Mauroux; Eugene Wu; Samuel Madden,The rise of GPS and broadband-speed wireless devices has led to tremendous excitementabout a range of applications broadly characterized as “location based services”. Currentdatabase storage systems; however; are inadequate for manipulating the very large anddynamic spatio-temporal data sets required to support such services. Proposals in theliterature either present new indices without discussing how to cluster data; potentiallyresulting in many disk seeks for lookups of densely packed objects; or use static quadtreesor other partitioning structures; which become rapidly suboptimal as the data or queriesevolve. As a result of these performance limitations; we built TrajStore; a dynamic storagesystem optimized for efficiently retrieving all data in a particular spatiotemporal region.TrajStore maintains an optimal index on the data and dynamically co-locates and …,Data Engineering (ICDE); 2010 IEEE 26th International Conference on,2010,130
Using Probabilistic Models for Data Management in Acquisitional Environments.,Amol Deshpande; Carlos Guestrin; Samuel Madden; JM Hellerstein; W Hong,Abstract Traditional database systems; particularly those focused on capturing andmanaging data from the real world; are poorly equipped to deal with the noise; loss; anduncertainty in data. We discuss a suite of techniques based on probabilistic models that aredesigned to allow database to tolerate noise and loss. These techniques are based onexploiting correlations to predict missing values and identify outliers. Interestingly;correlations also provide a way to give approximate answers to users at a significantly lowercost and enable a range of new types of queries over the correlation structure itself. Weillustrate a host of applications for our new techniques and queries; ranging from sensornetworks to network monitoring to data stream management. We also present a unifiedarchitecture for integrating such models into database systems; focusing in particular on …,CIDR,2005,128
The design and implementation of modern column-oriented database systems,Daniel Abadi; Peter Boncz; Stavros Harizopoulos; Stratos Idreos; Samuel Madden,Abstract In this article; we survey recent research on column-oriented database systems; orcolumn-stores; where each attribute of a table is stored in a separate file or region onstorage. Such databases have seen a resurgence in recent years with a rise in interest inanalytic queries that perform scans and aggregates over large portions of a few columns of atable. The main advantage of a column-store is that it can access just the columns needed toanswer such queries. We specifically focus on three influential research prototypes;MonetDB [46]; MonetDB/X100 [18]; and C-Store [86]. These systems have formed the basisfor several well-known commercial column-store implementations. We describe theirsimilarities and differences and discuss their specific architectural features for compression;late materialization; join processing; vectorization and adaptive indexing (database …,Foundations and Trends® in Databases,2013,124
TinyDB: In-network query processing in tinyos,Sam Madden; Joe Hellerstein; Wei Hong,TinyDB is a query processing system for extracting information from a network of TinyOSsensors. Unlike existing solutions for data processing in TinyOS; TinyDB does not requireyou to write embedded C code for sensors. Instead; TinyDB provides a simple; SQL-likeinterface to specify the data you want to extract; along with additional parameters; like therate at which data should be refreshed–much as you would pose queries against atraditional database. Given a query specifying your data interests; TinyDB collects that datafrom motes in the environment; filters it; aggregates it together; and routes it out to a PC.TinyDB does this via power-efficient in-network processing algorithms. To use TinyDB; youinstall its TinyOS components onto each mote in your sensor network. TinyDB provides asimple Java API for writing PC applications that query and extract data from the network; it …,*,2003,123
Networking support for query processing in sensor networks,Alec Woo; Sam Madden; Ramesh Govindan,Sensor networks have the potential to support applications ranging from habitat and structuralmonitoring; to home and building automation; to supply chain management. Users are typicallyinterested in continuous streams of information representing the evolving status of systems; combinedwith periodic statistical reports about specific phenomena. Query processing systems; includingDirected Diffusion [3]; TinyDB [6]; and Cougar [10]; provide high-level interfaces that allow usersto collect and process such continuous streams. They are especially attractive as ways to efficientlyimplement monitoring applications without forcing users to write complex; low-level code formanaging multihop network topologies or for acquiring samples from sensors … Researchersare beginning to formulate languages and enumerate the types of queries needed by users ofsensor networks [2]. Sensor networks also need distributed query processing; whereby …,Communications of the ACM,2004,119
An energy-efficient querying framework in sensor networks for detecting node similarities,Daniela Tulone; Samuel Madden,Abstract We propose an energy-efficient framework; called SAF; for approximate queryingand clustering of nodes in a sensor network. SAF uses simple time series forecastingmodels to predict sensor readings. The idea is to build these local models at each node;transmit them to the root of the network (the" sink"); and use them to approximately answeruser queries. Our approach dramatically reduces communication relative to previousapproaches for querying sensor networks by exploiting properties of these local models;since each sensor communicates with the sink only when its local model varies due tochanges in the underlying data distribution. In our experimental results performed on a traceof real data; we observed on average about 150 message transmissions from each sensorover a week (including the learning phase) to correctly predict temperatures to within+ …,Proceedings of the 9th ACM international symposium on Modeling analysis and simulation of wireless and mobile systems,2006,115
Tolerating byzantine faults in transaction processing systems using commit barrier scheduling,Ben Vandiver; Hari Balakrishnan; Barbara Liskov; Sam Madden,Abstract This paper describes the design; implementation; and evaluation of areplicationscheme to handle Byzantine faults in transaction processing database systems. The schemecompares answers from queries and updates on multiple replicas which are unmodified; off-the-shelf systems; to provide a single database that is Byzantine fault tolerant. The schemeworks when the replicas are homogeneous; but it also allows heterogeneous replication inwhich replicas come from different vendors. Heterogeneous replicas reduce the impact ofbugs and security compromises because they are implemented independently and are thusless likely to suffer correlated failures. The main challenge in designing a replication schemefor transactionprocessing systems is ensuring that the different replicas execute transactionsin equivalent serial orders while allowing a high degreeof concurrency. Our scheme …,ACM SIGOPS Operating Systems Review,2007,109
Improving wireless network performance using sensor hints,Lenin Ravindranath; Calvin Newport; Hari Balakrishnan; Samuel Madden,Abstract With the proliferation of mobile wireless devices such as smartphones and tabletsthat are used in a wide range of locations and movement conditions; it has becomeimportant for wireless protocols to adapt to different settings over short periods of time.Network protocols that perform well in static settings where channel conditions are relativelystable tend to perform poorly in mobile settings where channel conditions change rapidly;and vice versa. To adapt to the conditions under which communication is occurring; wepropose the use of external sensor hints to augment network protocols. Commoditysmartphones and tablet devices come equipped with a variety of sensors; including GPS;accelerometers; magnetic compasses; and gyroscopes; which can provide hints about thedevice's mobility state and its operating environment. We present a wireless protocol …,Proceedings of the 8th USENIX conference on Networked systems design and implementation,2011,108
Challenges and Opportunities with big data 2011-1,Divyakant Agrawal; Philip Bernstein; Elisa Bertino; Susan Davidson; Umeshwas Dayal; Michael Franklin; Johannes Gehrke; Laura Haas; Alon Halevy; Jiawei Han; HV Jagadish; Alexandros Labrinidis; Sam Madden; Yannis Papakonstantinou; Jignesh Patel; Raghu Ramakrishnan; Kenneth Ross; Cyrus Shahabi; Dan Suciu; Shiv Vaithyanathan; Jennifer Widom,Abstract The promise of data-driven decision-making is now being recognized broadly; andthere is growing enthusiasm for the notion of``Big Data.''While the promise of Big Data is real--for example; it is estimated that Google alone contributed 54 billion dollars to the USeconomy in 2009--there is currently a wide gap between its potential and its realization.,*,2011,107
Wishbone: Profile-based Partitioning for Sensornet Applications.,Ryan Newton; Sivan Toledo; Lewis Girod; Hari Balakrishnan; Samuel Madden,Abstract: The ability to partition sensor network application code across sensor nodes andbackend servers is important for running complex; data-intensive applications on sensorplatforms that have CPU; energy; and bandwidth limitations. This paper presents Wishbone;a system that takes a dataflow graph of operators and produces an optimal partitioning. WithWishbone; users can run the same program on a range of sensor platforms; includingTinyOS motes; smartphones running JavaME; and the iPhone. The resulting programpartitioning will in general be different in each case; reflecting the different node capabilities.Wishbone uses profiling to determine how each operator in the dataflow graph will actuallyperform on sample data; without requiring cumbersome user annotations. Its partitioningalgorithm models the problem as an integer linear program that minimizes a linear …,NSDI,2009,103
Top-k queries on uncertain data: on score distribution and typical answers,Tingjian Ge; Stan Zdonik; Samuel Madden,Abstract Uncertain data arises in a number of domains; including data integration andsensor networks. Top-k queries that rank results according to some user-defined score arean important tool for exploring large uncertain data sets. As several recent papers haveobserved; the semantics of top-k queries on uncertain data can be ambiguous due totradeoffs between reporting high-scoring tuples and tuples with a high probability of being inthe resulting data set. In this paper; we demonstrate the need to present the scoredistribution of top-k vectors to allow the user to choose between results along this score-probability dimensions. One option would be to display the complete distribution of allpotential top-k tuple vectors; but this set is too large to compute. Instead; we propose toprovide a number of typical vectors that effectively sample this distribution. We propose …,Proceedings of the 2009 ACM SIGMOD International Conference on Management of data,2009,100
The Claremont report on database research,Rakesh Agrawal; Anastasia Ailamaki; Philip A Bernstein; Eric A Brewer; Michael J Carey; Surajit Chaudhuri; Anhai Doan; Daniela Florescu; Michael J Franklin; Hector Garcia-Molina; Johannes Gehrke; Le Gruenwald; Laura M Haas; Alon Y Halevy; Joseph M Hellerstein; Yannis E Ioannidis; Hank F Korth; Donald Kossmann; Samuel Madden; Roger Magoulas; Beng Chin Ooi; Tim O'Reilly; Raghu Ramakrishnan; Sunita Sarawagi; Michael Stonebraker; Alexander S Szalay; Gerhard Weikum,Here; we explore the conclusions of this self-assessment. It is by definition somewhatinward-focused but may be of interest to the broader computing community as both a windowinto upcoming directions in database research and a description of some of the community issuesand initiatives that surfaced. We describe the group's consensus view of new focus areas forresearch; including database engine architectures; declarative programming languages; interplayof structured data and free text; cloud data services; and mobile and virtual worlds. We also reporton discussions of the database community's growth and processes that may be of interest toother research areas facing similar challenges … Over the past 20 years; small groups of databaseresearchers have periodically gathered to assess the state of the field and propose directionsfor future research. 1;3;4;5;6;7 Reports of the meetings served to foster debate within the …,Communications of the ACM,2009,100
Knowing when you're wrong: building fast and reliable approximate query processing systems,Sameer Agarwal; Henry Milner; Ariel Kleiner; Ameet Talwalkar; Michael Jordan; Samuel Madden; Barzan Mozafari; Ion Stoica,Abstract Modern data analytics applications typically process massive amounts of data onclusters of tens; hundreds; or thousands of machines to support near-real-time decisions.The quantity of data and limitations of disk and memory bandwidth often make it infeasible todeliver answers at interactive speeds. However; it has been widely observed that manyapplications can tolerate some degree of inaccuracy. This is especially true for exploratoryqueries on data; where users are satisfied with" close-enough" answers if they can comequickly. A popular technique for speeding up queries at the cost of accuracy is to executeeach query on a sample of data; rather than the whole dataset. To ensure that the returnedresult is not too inaccurate; past work on approximate query processing has used statisticaltechniques to estimate" error bars" on returned results. However; existing work in the …,Proceedings of the 2014 ACM SIGMOD international conference on Management of data,2014,98
Rethinking main memory OLTP recovery,Nirmesh Malviya; Ariel Weisberg; Samuel Madden; Michael Stonebraker,Fine-grained; record-oriented write-ahead logging; as exemplified by systems like ARIES;has been the gold standard for relational database recovery. In this paper; we show that inmodern high-throughput transaction processing systems; this is no longer the optimal way torecover a database system. In particular; as transaction throughputs get higher; ARIES-stylelogging starts to represent a non-trivial fraction of the overall transaction execution time. Wepropose a lighter weight; coarse-grained command logging technique which only recordsthe transactions that were executed on the database. It then does recovery by starting from atransactionally consistent checkpoint and replaying the commands in the log as if they werenew transactions. By avoiding the overhead of fine-grained logging of before and afterimages (both CPU complexity as well as substantial associated 110); command logging …,Data Engineering (ICDE); 2014 IEEE 30th International Conference on,2014,87
Osprey: Implementing MapReduce-style fault tolerance in a shared-nothing distributed database,Christopher Yang; Christine Yen; Ceryen Tan; Samuel R Madden,In this paper; we describe a scheme for tolerating and recovering from mid-query faults in adistributed shared nothing database. Rather than aborting and restarting queries; oursystem; Osprey; divides running queries into subqueries; and replicates data such that eachsubquery can be rerun on a different node if the node initially responsible fails or returns tooslowly. Our approach is inspired by the fault tolerance properties of MapReduce; in whichmap or reduce jobs are greedily assigned to workers; and failed jobs are rerun on otherworkers.,Data Engineering (ICDE); 2010 IEEE 26th International Conference on,2010,85
The emergence of a networking primitive in wireless sensor networks,Philip Levis; Eric Brewer; David Culler; David Gay; Samuel Madden; Neil Patel; Joe Polastre; Scott Shenker; Robert Szewczyk; Alec Woo,Abstract The wireless sensor network community approached networking abstractions as anopen question; allowing answers to emerge with time and experience. The Trickle algorithmhas become a basic mechanism used in numerous protocols and systems. Trickle bringsnodes to eventual consistency quickly and efficiently while remaining remarkably robust tovariations in network density; topology; and dynamics. Instead of flooding a network withpackets; Trickle uses a" polite gossip" policy to control send rates so each node hears justenough packets to stay consistent. This simple mechanism enables Trickle to scale to 1000-fold changes in network density; reach consistency in seconds; and require only a few bytesof state yet impose a maintenance cost of a few sends an hour. Originally designed fordisseminating new code; experience has shown Trickle to have much broader …,Communications of the ACM,2008,84
Blink and it's done: interactive queries on very large data,Sameer Agarwal; Anand P Iyer; Aurojit Panda; Samuel Madden; Barzan Mozafari; Ion Stoica,Abstract In this demonstration; we present BlinkDB; a massively parallel; sampling-basedapproximate query processing framework for running interactive queries on large volumes ofdata. The key observation in BlinkDB is that one can make reasonable decisions in theabsence of perfect answers. BlinkDB extends the Hive/HDFS stack and can handle thesame set of SPJA (selection; projection; join and aggregate) queries as supported by thesesystems. BlinkDB provides real-time answers along with statistical error guarantees; and canscale to petabytes of data and thousands of machines in a fault-tolerant manner. Ourexperiments using the TPC-H benchmark and on an anonymized real-world video contentdistribution workload from Conviva Inc. show that BlinkDB can execute a wide range ofqueries up to 150x faster than Hive on MapReduce and 10--150x faster than Shark (Hive …,Proceedings of the VLDB Endowment,2012,81
Information survival threshold in sensor and p2p networks,Deepayan Chakrabarti; Jure Leskovec; Christos Faloutsos; Samuel Madden; Carlos Guestrin; Michalis Faloutsos,Consider a network of; say; sensors; or P2P nodes; or Bluetooth-enabled cell-phones;where nodes transmit information to each other and where links and nodes can go up ordown. Consider also a'datum'; that is; a piece of information; like a report of an emergencycondition in a sensor network; a national traditional song; or a mobile phone virus. Howoften should nodes transmit the datum to each other; so that the datum can survive (or; in thevirus case; under what conditions will the virus die out)? Clearly; the link and node faultprobabilities are important-what else is needed to ascertain the survivability of the datum?We propose and solve the problem using non-linear dynamical systems and fixed pointstability theorems. We provide a closed-form formula that; surprisingly; depends on only oneadditional parameter; the largest eigenvalue of the connectivity matrix. We illustrate the …,INFOCOM 2007. 26th IEEE International Conference on Computer Communications. IEEE,2007,81
Scaling up crowd-sourcing to very large datasets: a case for active learning,Barzan Mozafari; Purna Sarkar; Michael Franklin; Michael Jordan; Samuel Madden,Abstract Crowd-sourcing has become a popular means of acquiring labeled data for manytasks where humans are more accurate than computers; such as image tagging; entityresolution; and sentiment analysis. However; due to the time and cost of human labor;solutions that rely solely on crowd-sourcing are often limited to small datasets (ie; a fewthousand items). This paper proposes algorithms for integrating machine learning into crowd-sourced databases in order to combine the accuracy of human labeling with the speed andcost-effectiveness of machine learning classifiers. By using active learning as ouroptimization strategy for labeling tasks in crowd-sourced databases; we can minimize thenumber of questions asked to the crowd; allowing crowd-sourced applications to scale (ie;label much larger datasets at lower costs). Designing active learning algorithms for a …,Proceedings of the VLDB Endowment,2014,78
An integration framework for sensor networks and data stream management systems,Daniel J Abadi; Wolfgang Lindner; Samuel Madden; Jörg Schuler,Abstract This demonstration shows an integrated query processing environment whereusers can seamlessly query both a data stream management system and a sensor networkwith one query expression. By integrating the two query processing systems; theoptimization goals of the sensor network (primarily power) and server network (primarilylatency and quality) can be unified into one quality of service metric. The demo showsvarious steps of the unified optimization process for a sample query where the effects ofeach step that the optimizer takes can be directly viewed using a quality of service monitor.Our demo includes sensors deployed in the demo area in a tiny mockup of a factoryapplication.,Proceedings of the Thirtieth international conference on Very large data bases-Volume 30,2004,78
Counting with the crowd,Adam Marcus; David Karger; Samuel Madden; Robert Miller; Sewoong Oh,Abstract In this paper; we address the problem of selectivity estimation in a crowdsourceddatabase. Specifically; we develop several techniques for using workers on a crowdsourcingplatform like Amazon's Mechanical Turk to estimate the fraction of items in a dataset (eg; acollection of photos) that satisfy some property or predicate (eg; photos of trees). We do thiswithout explicitly iterating through every item in the dataset. This is important in crowd-sourced query optimization to support predicate ordering and in query evaluation; whenperforming a GROUP BY operation with a COUNT or AVG aggregate. We compare samplingitem labels; a traditional approach; to showing workers a collection of items and asking themto estimate how many satisfy some predicate. Additionally; we develop techniques toeliminate spammers and colluding attackers trying to skew selectivity estimates when …,Proceedings of the VLDB Endowment,2012,77
The sensor spectrum: technology; trends; and requirements,Joseph M Hellerstein; Wei Hong; Samuel R Madden,Abstract Though physical sensing instruments have long been used in astronomy; biology;and civil engineering; the recent emergence of wireless sensor networks and RFID hasspurred a renaissance in sensor interest in both academia and industry. In this paper; weexamine the spectrum of sensing platforms; from billion dollar satellites to tiny RF tags; anddiscuss the technological differences between them. We show that battery powered sensornetworks; with low-power multihop radios and low-cost processors; occupy a sweet spot inthis spectrum that is rife with opportunity for novel database research. We briefly summarizesome of our research work in this space and present a number of examples of interestingsensor network-related problems that the database community is uniquely equipped toaddress.,ACM SIGMOD Record,2003,76
Report from the first workshop on geo sensor networks,Silvia Nittel; Anthony Stefanidis; I Cruz; M Egenhofer; D Goldin; A Howard; Alexandros Labrinidis; Samuel Madden; Agnès Voisard; M Worboys,Advances in sensor technology and deployment strategies are revolutionizing the way thatgeospatial information is collected and analyzed. For example; cameras and GPS sensorson-board static or mobile platforms have the ability to provide continuous streams ofgeospatiallyrich information. Furthermore; with the advent of nanotechnology it becomesfeasible and economically viable to develop and deploy low-cost; low-power devices thatare general-purpose computing platforms with multi-purpose on-board sensing and wirelesscommunications capabilities. Today; research efforts are taking place developinginfrastructure for systems consisting of large numbers of small unattended; untethered andcollaborative sensor nodes that have non-renewable power supply and communicate viashort range radio frequency with neighboring nodes. These types of sensors may also act …,ACM SIGMOD Record,2004,73
Scorpion: Explaining away outliers in aggregate queries,Eugene Wu; Samuel Madden,Abstract Database users commonly explore large data sets by running aggregate queriesthat project the data down to a smaller number of points and dimensions; and visualizing theresults. Often; such visualizations will reveal outliers that correspond to errors or surprisingfeatures of the input data set. Unfortunately; databases and visualization systems do notprovide a way to work backwards from an outlier point to the common properties of the(possibly many) unaggregated input tuples that correspond to that outlier. We proposeScorpion; a system that takes a set of user-specified outlier points in an aggregate queryresult as input and finds predicates that explain the outliers in terms of properties of the inputtuples that are used to compute the selected outlier results. Specifically; this explanationidentifies predicates that; when applied to the input data; cause the outliers to disappear …,Proceedings of the VLDB Endowment,2013,71
Querying continuous functions in a database system,Arvind Thiagarajan; Samuel Madden,Abstract Many scientific; financial; data mining and sensor network applications need towork with continuous; rather than discrete data eg; temperature as a function of location; orstock prices or vehicle trajectories as a function of time. Querying raw or discrete data isunsatisfactory for these applications--eg; in a sensor network; it is necessary to interpolatesensor readings to predict values at locations where sensors are not deployed. In othersituations; raw data can be inaccurate owing to measurement errors; and it is useful to fitcontinuous functions to raw data and query the functions; rather than raw data itself--eg;fitting a smooth curve to noisy sensor readings; or a smooth trajectory to GPS datacontaining gaps or outliers. Existing databases do not support storing or queryingcontinuous functions; short of brute-force discretization of functions into a collection of …,Proceedings of the 2008 ACM SIGMOD international conference on Management of data,2008,70
Optimizing database-backed applications with query synthesis,Alvin Cheung; Armando Solar-Lezama; Samuel Madden,Abstract Object-relational mapping libraries are a popular way for applications to interactwith databases because they provide transparent access to the database using the samelanguage as the application. Unfortunately; using such frameworks often leads to poorperformance; as modularity concerns encourage developers to implement relationaloperations in application code. Such application code does not take advantage of theoptimized relational implementations that database systems provide; such as efficientimplementations of joins or push down of selection predicates. In this paper we presentQBS; a system that automatically transforms fragments of application logic into SQL queries.QBS differs from traditional compiler optimizations as it relies on synthesis technology togenerate invariants and postconditions for a code fragment. The postconditions and …,ACM SIGPLAN Notices,2013,69
Streaming similarity search over one billion tweets using parallel locality-sensitive hashing,Narayanan Sundaram; Aizana Turmukhametova; Nadathur Satish; Todd Mostak; Piotr Indyk; Samuel Madden; Pradeep Dubey,Abstract Finding nearest neighbors has become an important operation on databases; withapplications to text search; multimedia indexing; and many other areas. One popularalgorithm for similarity search; especially for high dimensional data (where spatial indexeslike kd-trees do not perform well) is Locality Sensitive Hashing (LSH); an approximationalgorithm for finding similar objects. In this paper; we describe a new variant of LSH; calledParallel LSH (PLSH) designed to be extremely efficient; capable of scaling out on multiplenodes and multiple cores; and which supports high-throughput streaming of new data. Ourapproach employs several novel ideas; including: cache-conscious hash table layout; usinga 2-level merge algorithm for hash table construction; an efficient algorithm for duplicateelimination during hash-table querying; an insert-optimized hash table structure and …,Proceedings of the VLDB Endowment,2013,68
Transactional consistency and automatic management in an application data cache,Dan RK Ports; Austin T Clements; Irene Zhang; Samuel Madden; Barbara Liskov,Abstract Distributed in-memory application data caches like memcached are a popularsolution for scaling database-driven web sites. These systems are easy to add to existingdeployments; and increase performance significantly by reducing load on both the databaseand application servers. Unfortunately; such caches do not integrate well with the databaseor the application. They cannot maintain transactional consistency across the entire system;violating the isolation properties of the underlying database. They leave the applicationresponsible for locating data in the cache and keeping it up to date; a frequent source ofapplication complexity and programming errors. Addressing both of these problems; weintroduce a transactional cache; TxCache; with a simple programming model. TxCacheensures that any data seen within a transaction; whether it comes from the cache or the …,*,2010,68
Xstream: A signal-oriented data stream management system,Lewis Girod; Yuan Mei; Ryan Newton; Stanislav Rost; Arvind Thiagarajan; Hari Balakrishnan; Samuel Madden,Sensors capable of sensing phenomena at high data rates on the order of tens to hundredsof thousands of samples per second are now widely deployed in many industrial; civilengineering; scientific; networking; and medical applications. In aggregate; these sensorseasily generate several million samples per second that must be processed withinmilliseconds or seconds. The computation required includes both signal processing andevent stream processing. XStream is a stream processing system for such applications.XStream introduces a new data type; the signal segment; which allows applications tomanipulate isochronous (regularly spaced in time) collections of sensor samples moreconveniently and efficiently than the asynchronous representation used in previous work.XStream includes a memory manager and scheduler optimizations tuned for processing …,Data Engineering; 2008. ICDE 2008. IEEE 24th International Conference on,2008,68
Datahub: Collaborative data science & dataset version management at scale,Anant Bhardwaj; Souvik Bhattacherjee; Amit Chavan; Amol Deshpande; Aaron J Elmore; Samuel Madden; Aditya G Parameswaran,Abstract: Relational databases have limited support for data collaboration; where teamscollaboratively curate and analyze large datasets. Inspired by software version controlsystems like git; we propose (a) a dataset version control system; giving users the ability tocreate; branch; merge; difference and search large; divergent collections of datasets; and (b)a platform; DataHub; that gives users the ability to perform collaborative data analysisbuilding on this version control system. We outline the challenges in providing datasetversion control at scale.,arXiv preprint arXiv:1409.0798,2014,67
The CarTel mobile sensor computing system,Vladimir Bychkovsky; Kevin Chen; Michel Goraczko; Hongyi Hu; Bret Hull; Allen Miu; Eugene Shih; Yang Zhang; Hari Balakrishnan; Samuel Madden,Worldwide; there are over 600 million automobiles on the road. Each automobile is apotentially rich source of sensor data; with the current generation of cars having over 100sensors. Unlike many other mobile platforms; an automobile is a resource-rich environmentthat can support relatively robust computation and communication systems. Moreimportantly; because automobiles interface with a vast amount of the physical world and arewell-integrated into our daily lives; they are uniquely positioned to enable a broad range ofsensing applications. What can we do with 600 million mobile computing units (cars); eachwith tens of sensors; and on which we can place large amounts of computation? Here aresome classes of applications that would arise if we expanded the reach of today's Internet-based computing substrate to include automobiles. In all these applications; cars are …,SenSys,2006,67
Code in the air: simplifying sensing and coordination tasks on smartphones,Lenin Ravindranath; Arvind Thiagarajan; Hari Balakrishnan; Samuel Madden,Abstract A growing class of smartphone applications are tasking applications that runcontinuously; process data from sensors to determine the user's context (such as location)and activity; and optionally trigger certain actions when the right conditions occur. Manysuch tasking applications also involve coordination between multiple users or devices.Example tasking applications include location-based reminders; changing the ring-mode ofa phone automatically depending on location; notifying when friends are nearby; disablingWiFi in favor of cellular data when moving at more than a certain speed outdoors;automatically tracking and storing movement tracks when driving; and inferring the numberof steps walked each day. Today; these applications are non-trivial to develop; although theyare often trivial for end users to state. Additionally; simple implementations can consume …,Proceedings of the Twelfth Workshop on Mobile Computing Systems & Applications,2012,64
On the use of NAND flash memory in high-performance relational databases,Daniel Daniel Sumers Myers,High-density NAND flash storage has become relatively inexpensive due to the popularity ofvarious consumer electronics. Recently; several manufacturers have released IDE-compatible NAND flash-based drives in sizes up to 64 GB at reasonable (sub-$1000) prices.Because flash is significantly more durable than mechanical hard drives and requiresconsiderably less energy; there is some speculation that large data centers will adopt thesedevices. As database workloads make up a substantial fraction of the processing done bydata centers; it is interesting to ask how switching to flash-based storage will affect theperformance of database systems. We evaluate this question using IDE-based flash drivesfrom two major manufacturers. We measure their read and write performance and find thatflash has excellent random read performance; acceptable sequential read performance …,*,2008,64
The bigdawg polystore system,Jennie Duggan; Aaron J Elmore; Michael Stonebraker; Magda Balazinska; Bill Howe; Jeremy Kepner; Sam Madden; David Maier; Tim Mattson; Stan Zdonik,Abstract This paper presents a new view of federated databases to address the growingneed for managing information that spans multiple data models. This trend is fueled by theproliferation of storage engines and query languages based on the observation that “no onesize fits all”. To address this shift; we propose a polystore architecture; it is designed to unifyquerying over multiple data models. We consider the challenges and opportunitiesassociated with polystores. Open questions in this space revolve around query optimizationand the assignment of objects to storage engines. We introduce our approach to thesetopics and discuss our prototype in the context of the Intel Science and Technology Centerfor Big Data,ACM Sigmod Record,2015,63
Intel lab data,Samuel Madden,*,Web page; Intel,2004,62
Voxnet: An interactive; rapidly-deployable acoustic monitoring platform,Michael Allen; Lewis Girod; Ryan Newton; Samuel Madden; Daniel T Blumstein; Deborah Estrin,Abstract Distributed acoustic sensing underlies an increasingly important class of sensornetwork applications; from habitat monitoring and bio acoustic census to securityapplications and virtual fences. VoxNet is a complete hardware and software platform fordistributed acoustic monitoring applications that focuses on three key goals:(1) rapiddeployment in realistic environments;(2) a high level programming language that abstractsthe user from platform and network details and compiles into a high performance distributedapplication; and (3) an interactive usage model based on run-time installable programs; withthe ability to run the same high level program seamlessly over live or stored data. TheVoxNet hardware is self-contained and weather-resistant; and supports a four-channelmicrophone array with automated time synchronization; localization; and network …,Proceedings of the 7th international conference on Information processing in sensor networks,2008,61
DBSeer: Resource and Performance Prediction for Building a Next Generation Database Cloud.,Barzan Mozafari; Carlo Curino; Samuel Madden,ABSTRACT Cloud computing is characterized by shared infrastructure and a decouplingbetween its operators and tenants. These two characteristics impose new challenges todatabases applications hosted in the cloud; namely:(i) how to price database services;(ii)how to isolate database tenants; and (iii) how to optimize database performance on thisshared infrastructure. We argue that today's solutions; based on virtual-machines; do notproperly address these challenges. We hint at new research directions to tackle theseproblems and argue that these three challenges share a common need for accuratepredictive models of performance and resource utilization. We present our approach; calledDBSeer; with our initial results on predictive models for the important class of OLTP/Webworkloads and show how they can be used to address these challenges.,CIDR,2013,60
The Case for a Signal-Oriented Data Stream Management System.,Lewis Girod; Yuan Mei; Ryan Newton; Stanislav Rost; Arvind Thiagarajan; Hari Balakrishnan; Samuel Madden,ABSTRACT Sensors capable of sensing phenomena at high data rates—on the order oftens to hundreds of thousands of samples per second—are useful in many industrial; civilengineering; scientific; networking; and medical applications. In these applications; high-ratestreams of data produced by sensors must be processed and analyzed using a combinationof both event-stream and signal-processing operations. This paper motivates the need for adata management and continuous query processing architecture that integrates these twodifferent desired classes of functions into a single; unified software system. The key goals ofsuch a system include: the ability to treat a sequence of samples that constitute a “signalsegment” as a basic data type; ease of writing arbitrary event-stream and signal-processingfunctions; the ability to process several million samples per second on conventional PC …,CIDR,2007,59
Resource-Aware Wireless Sensor-Actuator Networks.,Amol Deshpande; Carlos Guestrin; Samuel Madden,Abstract Innovations in wireless sensor networks (WSNs) have dramatically expanded theapplicability of control technology in day-to-day life; by enabling the cost-effectivedeployment of large scale sensor-actuator systems. In this paper; we discuss the issues andchallenges involved in deploying control-oriented applications over unreliable; resource-constrained WSNs; and describe the design of our planned Sensor Control System (SCS)that can enable the rapid development and deployment of such applications.,IEEE Data Eng. Bull.,2005,59
A continuous query system for dynamic route planning,Nirmesh Malviya; Samuel Madden; Arnab Bhattacharya,In this paper; we address the problem of answering continuous route planning queries overa road network; in the presence of updates to the delay (cost) estimates of links. A simpleapproach to this problem would be to recompute the best path for all queries on arrival ofevery delay update. However; such a naive approach scales poorly when there are manyusers who have requested routes in the system. Instead; we propose two new classes ofapproximate techniques-K-paths and proximity measures to substantially speed upprocessing of the set of designated routes specified by continuous route planning queries inthe face of incoming traffic delay updates. Our techniques work through a combination of pre-computation of likely good paths and by avoiding complete recalculations on every delayupdate; instead only sending the user new routes when delays change significantly …,Data Engineering (ICDE); 2011 IEEE 27th International Conference on,2011,57
An integrated approach to recovery and high availability in an updatable; distributed data warehouse,Edmond Lau; Samuel Madden,Abstract Any highly available data warehouse will use some form of data replication totolerate machine failures. In this paper; we demonstrate that we can leverage this dataredundancy to build an integrated approach to recovery and high availability. Our approach;called HARBOR; revives a crashed site by querying remote; online sites for missing updatesand uses timestamps to determine which tuples need to be copied or updated. HARBORdoes not require a stable log; recovers without quiescing the system; allows replicated datato be stored non-identically; and is simpler than a log-based recovery algorithm. Wecompare the runtime overhead and recovery performance of HARBOR to those of two-phasecommit and ARIES; the gold standard for log-based recovery; on a three-node distributeddatabase system. Our experiments demonstrate that HARBOR suffers lower runtime …,Proceedings of the 32nd international conference on Very large data bases,2006,56
A demonstration of the bigdawg polystore system,Aaron Elmore; Jennie Duggan; Mike Stonebraker; Magdalena Balazinska; Ugur Cetintemel; Vijay Gadepally; Jeffrey Heer; Bill Howe; Jeremy Kepner; Tim Kraska; Samuel Madden; David Maier; Timothy Mattson; Stavros Papadopoulos; Jeff Parkhurst; Nesime Tatbul; Manasi Vartak; Stan Zdonik,Abstract This paper presents BigDAWG; a reference implementation of a new architecturefor" Big Data" applications. Such applications not only call for large-scale analytics; but alsofor real-time streaming support; smaller analytics at interactive speeds; data visualization;and cross-storage-system queries. Guided by the principle that" one size does not fit all"; webuild on top of a variety of storage engines; each designed for a specialized use case. Toillustrate the promise of this approach; we demonstrate its effectiveness on a hospitalapplication using data from an intensive care unit (ICU). This complex application serves theneeds of doctors and researchers and provides real-time support for streams of patient data.It showcases novel approaches for querying across multiple storage engines; datavisualization; and scalable real-time analytics.,Proceedings of the VLDB Endowment,2015,55
Performance and resource modeling in highly-concurrent OLTP workloads,Barzan Mozafari; Carlo Curino; Alekh Jindal; Samuel Madden,Abstract Database administrators of Online Transaction Processing (OLTP) systemsconstantly face difficult questions. For example;" What is the maximum throughput I cansustain with my current hardware?";" How much disk I/O will my system perform if therequests per second double?"; or" What will happen if the ratio of transactions in my systemchanges?". Resource prediction and performance analysis are both vital and difficult in thissetting. Here the challenge is due to high degrees of concurrency; competition for resources;and complex interactions between transactions; all of which non-linearly impactperformance. Although difficult; such analysis is a key component in enabling databaseadministrators to understand which queries are eating up the resources; and how theirsystem would scale under load. In this paper; we introduce our framework; called DBSeer …,Proceedings of the 2013 acm sigmod international conference on management of data,2013,55
Stochastic motion planning and applications to traffic,Sejoon Lim; Hari Balakrishnan; David Gifford; Samuel Madden; Daniela Rus,This paper presents a stochastic motion planning algorithm and its application to trafficnavigation. The algorithm copes with the uncertainty of road traffic conditions by stochasticmodeling of travel delay on road networks. The algorithm determines paths between twopoints that optimize a cost function of the delay data probability distribution. It can be used tofind paths that maximize the probability of reaching a destination within a particular traveldeadline. For such problems; standard shortest-path algorithms do not work because theoptimal substructure property does not hold. We evaluate our algorithm using bothsimulations and real-world drives; using delay data gathered from a set of taxis equippedwith global positioning system sensors and a wireless network. Our algorithm can beintegrated into on-board navigation systems as well as route-finding websites; providing …,The International Journal of Robotics Research,2011,54
Intel lab data,Peter Bodik; Wei Hong; Carlos Guestrin; Sam Madden; Mark Paskin; Romain Thibaux,*,Online dataset,2004,53
Bigdansing: A system for big data cleansing,Zuhair Khayyat; Ihab F Ilyas; Alekh Jindal; Samuel Madden; Mourad Ouzzani; Paolo Papotti; Jorge-Arnulfo Quiané-Ruiz; Nan Tang; Si Yin,Abstract Data cleansing approaches have usually focused on detecting and fixing errorswith little attention to scaling to big datasets. This presents a serious impediment since datacleansing often involves costly computations such as enumerating pairs of tuples; handlinginequality joins; and dealing with user-defined functions. In this paper; we presentBigDansing; a Big Data Cleansing system to tackle efficiency; scalability; and ease-of-useissues in data cleansing. The system can run on top of most common general purpose dataprocessing platforms; ranging from DBMSs to MapReduce-like frameworks. A user-friendlyprogramming interface allows users to express data quality rules both declaratively andprocedurally; with no requirement of being aware of the underlying distributed platform.BigDansing takes these rules into a series of transformations that enable distributed …,Proceedings of the 2015 ACM SIGMOD International Conference on Management of Data,2015,52
Java support for data-intensive systems: Experiences building the Telegraph dataflow system,Mehul A Shah; Michael J Franklin; Samuel Madden; Joseph M Hellerstein,Abstract Database system designers have traditionally had trouble with the default servicesand interfaces provided by operating systems. In recent years; developers and enthusiastshave increasingly promoted Java as a serious platform for building data-intensive servers.Java provides a number of very helpful language features; as well as a full run-timeenvironment reminiscent of a traditional operating system. This combination of features andcommunity support raises the question of whether Java is better or worse at supporting data-intensive server software than a traditional operating system coupled with a weakly-typedlanguage such as C or C++. In this paper; we summarize and discuss our experiencebuilding the Telegraph dataflow system in Java. We highlight some of the pleasures ofcoding with Java; and some of the pains of coding around Java in order to obtain good …,ACM Sigmod Record,2001,52
Ninja paths: An architecture for composing services over wide area networks,Sirish Chandrasekaran; Sirish Ch; Samuel Madden; Mihut Ionescu,Abstract This paper describes an architecture for composing arbitrarily complex servicesfrom simpler services over a Wide Area Network. Services register themselves with aService Discovery Service; and advertise their capabilities in terms of structural andsemantic information about their inputs and outputs. A type system for this information isused to determine the validity of composing two operators. A request for a complex servicebetween source (s) and sink (s) of data is specied as a combination of the output type (s) ofthe source (s) and the input type (s) of the sink (s) and a (possibly empty) list of intermediateservices specied by unique names. We introduce the concept of a\path": an orderedsequence of services that; when composed; result in the desired complex service. Theconcept of a path is further rened to distinguish\control paths" from\data paths" and\logical …,*,2000,51
Automatic partitioning of database applications,Alvin Cheung; Samuel Madden; Owen Arden; Andrew C Myers,Abstract Database-backed applications are nearly ubiquitous in our daily lives. Applicationsthat make many small accesses to the database create two challenges for developers:increased latency and wasted resources from numerous network round trips. A well-knowntechnique to improve transactional database application performance is to convert part ofthe application into stored procedures that are executed on the database server.Unfortunately; this conversion is often difficult. In this paper we describe Pyxis; a system thattakes database-backed applications and automatically partitions their code into two pieces;one of which is executed on the application server and the other on the database server.Pyxis profiles the application and server loads; statically analyzes the code's dependencies;and produces a partitioning that minimizes the number of control transfers as well as the …,Proceedings of the VLDB Endowment,2012,50
Relational cloud: The case for a database service,Carlo Curino; Evan Jones; Yang Zhang; Eugene Wu; Samuel Madden,ABSTRACT In this paper; we make the case for “databases as a service”(DaaS); with twotarget scenarios in mind:(i) consolidation of data management functionality for largeorganizations and (ii) outsourcing data management to a cloud-based service provider forsmall/medium organizations. We analyze the many challenges to be faced; and discuss thedesign of a database service we are building; called Relational Cloud. The system has beendesigned from scratch and combines many recent advances and novel solutions. Theprototype we present exploits multiple dedicated storage engines; provides high-availabilityvia transparent replication; supports automatic workload partitioning and live data migration;and provides serializable distributed transactions. While the system is still under activedevelopment; we are able to present promising initial results that showcase the key …,New England Database Summit,2010,50
The case for data visualization management systems: vision paper,Eugene Wu; Leilani Battle; Samuel R Madden,Abstract Most visualizations today are produced by retrieving data from a database andusing a specialized visualization tool to render it. This decoupled approach results insignificant duplication of functionality; such as aggregation and filters; and missestremendous opportunities for cross-layer optimizations. In this paper; we present the case foran integrated Data Visualization Management System (DVMS) based on a declarativevisualization language that fully compiles the end-to-end visualization pipeline into a set ofrelational algebra queries. Thus the DVMS can be both expressive via the visualizationlanguage; and performant by lever-aging traditional and visualization-specific optimizationsto scale interactive visualizations to massive datasets.,Proceedings of the VLDB Endowment,2014,49
Crowddb: Query processing with the vldb crowd,Amber Feng; Michael Franklin; Donald Kossmann; Tim Kraska; Samuel R Madden; Sukriti Ramesh; Andrew Wang; Reynold Xin,Databases often give incorrect answers when data are missing or semantic understandingof the data is required. Processing such queries requires human input for providing themissing information; for performing computationally difficult functions; and for matching;ranking; or aggregating results based on fuzzy criteria. In this demo we present CrowdDB; ahybrid database system that automatically uses crowdsourcing to integrate human input forprocessing queries that a normal database system cannot answer. CrowdDB uses SQL bothas a language to ask complex queries and as a way to model data stored electronically andprovided by human input. Furthermore; queries are automatically compiled and optimized.Special operators provide user interfaces in order to integrate and cleanse human input.Currently CrowdDB supports two crowdsourcing platforms: Amazon Mechanical Turk and …,*,2011,48
Scoop: An adaptive indexing scheme for stored data in sensor networks,Thomer M Gil; Samuel Madden,We present the design of Scoop; a system for indexing and querying stored data in sensornetworks. Scoop works by collecting statistics about the rate of queries and distribution ofsensor readings in a sensor network; and uses those statistics to build an index that tellsnodes where in the network to store their data. Using this index; a queries over that stored;data can be answered; efficiently; without flooding those queries throughout the network.This approach offers a substantial advantage over other solutions that either store all dataexternally on a base station (requiring every reading to be collected from all nodes); or thatstore all data locally on the node that produced it (requiring queries to be flooded throughoutthe network). Our results show that Scoop offers a factor of four reduction in messagetransmissions relative to existing techniques in a real implementation on a 64-node mote …,Data Engineering; 2007. ICDE 2007. IEEE 23rd International Conference on,2007,48
S ee DB: efficient data-driven visualization recommendations to support visual analytics,Manasi Vartak; Sajjadur Rahman; Samuel Madden; Aditya Parameswaran; Neoklis Polyzotis,Abstract Data analysts often build visualizations as the first step in their analytical workflow.However; when working with high-dimensional datasets; identifying visualizations that showrelevant or desired trends in data can be laborious. We propose S ee DB; a visualizationrecommendation engine to facilitate fast visual analysis: given a subset of data to be studied;S ee DB intelligently explores the space of visualizations; evaluates promising visualizationsfor trends; and recommends those it deems most" useful" or" interesting". The two majorobstacles in recommending interesting visualizations are (a) scale: evaluating a largenumber of candidate visualizations while responding within interactive time scales; and (b)utility: identifying an appropriate metric for assessing interestingness of visualizations. Forthe former; S ee DB introduces pruning optimizations to quickly identify high-utility …,Proceedings of the VLDB Endowment,2015,47
The beckman report on database research,Daniel Abadi; Rakesh Agrawal; Anastasia Ailamaki; Magdalena Balazinska; Philip A Bernstein; Michael J Carey; Surajit Chaudhuri; Jeffrey Dean; AnHai Doan; Michael J Franklin; Johannes Gehrke; Laura M Haas; Alon Y Halevy; Joseph M Hellerstein; Yannis E Ioannidis; HV Jagadish; Donald Kossmann; Samuel Madden; Sharad Mehrotra; Tova Milo; Jeffrey F Naughton; Raghu Ramakrishnan; Volker Markl; Christopher Olston; Beng Chin Ooi; Christopher Ré; Dan Suciu; Michael Stonebraker; Todd Walter; Jennifer Widom,Abstract Every few years a group of database researchers meets to discuss the state ofdatabase research; its impact on practice; and important new directions. This reportsummarizes the discussion and conclusions of the eighth such meeting; held October 14-15;2013 in Irvine; California. It observes that Big Data has now become a defining challenge ofour time; and that the database research community is uniquely positioned to address it; withenormous opportunities to make transformative impact. To do so; the report recommendssignificantly more attention to five research areas: scalable big/fast data infrastructures;coping with diversity in the data management landscape; end-to-end processing andunderstanding of data; cloud services; and managing the diverse roles of people in the datalife cycle.,ACM SIGMOD Record,2014,47
CORADD: Correlation aware database designer for materialized views and indexes,Hideaki Kimura; George Huo; Alexander Rasin; Samuel Madden; Stanley B Zdonik,Abstract We describe an automatic database design tool that exploits correlations betweenattributes when recommending materialized views (MVs) and indexes. Although there is asubstantial body of related work exploring how to select an appropriate set of MVs andindexes for a given workload; none of this work has explored the effect of correlatedattributes (eg; attributes encoding related geographic information) on designs. Our toolidentifies a set of MVs and secondary indexes such that correlations between the clusteredattributes of the MVs and the secondary indexes are enhanced; which can dramaticallyimprove query performance. It uses a form of Integer Linear Programming (ILP) called ILPFeedback to pick the best set of MVs and indexes for given database size constraints. Wecompare our tool with a state-of-the-art commercial database designer on two workloads …,Proceedings of the VLDB Endowment,2010,46
The Beckman report on database research,Daniel Abadi; Rakesh Agrawal; Anastasia Ailamaki; Magdalena Balazinska; Philip A Bernstein; Michael J Carey; Surajit Chaudhuri; Jeffrey Dean; AnHai Doan; Michael J Franklin; Johannes Gehrke; Laura M Haas; Alon Y Halevy; Joseph M Hellerstein; Yannis E Ioannidis; HV Jagadish; Donald Kossmann; Samuel Madden; Sharad Mehrotra; Tova Milo; Jeffrey F Naughton; Raghu Ramakrishnan; Volker Markl; Christopher Olston; Beng Chin Ooi; Christopher Ré; Dan Suciu; Michael Stonebraker; Todd Walter; Jennifer Widom,A group of database researchers meets periodically to discuss the state of the field and its keydirections going forward. Past meetings were held in 1989; 6 1990; 11 1995; 12 1996; 101998; 7 2003; 1 and 2008. 2 Continuing this tradition; 28 database researchers and two invitedspeakers met in October 2013 at the Beckman Center on the University of California-Irvine campusfor two days of discussions. The meeting attendees represented a broad cross-section ofinterests; affiliations; seniority; and geography. Attendance was capped at 30 so the meetingwould be as interactive as possible. This article summarizes the conclusions from thatmeeting; an extended report and participant presentations are available at http://beckman.cs.wisc.edu … The meeting participants quickly converged on big data as a defining challengeof our time. Big data arose due to the confluence of three major trends. First; it has …,Communications of the ACM,2016,45
S-Store: a streaming NewSQL system for big velocity applications,Ugur Cetintemel; Jiang Du; Tim Kraska; Samuel Madden; David Maier; John Meehan; Andrew Pavlo; Michael Stonebraker; Erik Sutherland; Nesime Tatbul; Kristin Tufte; Hao Wang; Stanley Zdonik,Abstract First-generation streaming systems did not pay much attention to state managementvia ACID transactions (eg;[3; 4]). S-Store is a data management system that combines OLTPtransactions with stream processing. To create S-Store; we begin with H-Store; a main-memory transaction processing engine; and add primitives to support streaming. Thisincludes triggers and transaction workflows to implement push-based processing; windowsto provide a way to bound the computation; and tables with hidden state to implementscoping for proper isolation. This demo explores the benefits of this approach by showinghow a naïve implementation of our benchmarks using only H-Store can yield incorrectresults. We also show that by exploiting push-based semantics and our implementation oftriggers; we can achieve significant improvement in transaction throughput. We demo two …,Proceedings of the VLDB Endowment,2014,44
Efficient versioning for scientific array databases,Adam Seering; Philippe Cudre-Mauroux; Samuel Madden; Michael Stonebraker,In this paper; we describe a versioned database storage manager we are developing for theSciDB scientific database. The system is designed to efficiently store and retrieve array-oriented data; exposing a" no-overwrite" storage model in which each update creates a new"version" of an array. This makes it possible to perform comparisons of versions produced atdifferent times or by different algorithms; and to create complex chains and trees of versions.We present algorithms to efficiently encode these versions; minimizing storage space whilestill providing efficient access to the data. Additionally; we present an optimal algorithm that;given a long sequence of versions; determines which versions to encode in terms of eachother (using delta compression) to minimize total storage space or query execution cost. Wecompare the performance of these algorithms on real world data sets from the National …,Data Engineering (ICDE); 2012 IEEE 28th International Conference on,2012,43
Lookup tables: Fine-grained partitioning for distributed databases,Aubrey L Tatarowicz; Carlo Curino; Evan PC Jones; Sam Madden,The standard way to get linear scaling in a distributed OLTP DBMS is to horizontally partitiondata across several nodes. Ideally; this partitioning will result in each query being executedat just one node; to avoid the overheads of distributed transactions and allow nodes to beadded without increasing the amount of required coordination. For some applications;simple strategies; such as hashing on primary key; provide this property. Unfortunately; formany applications; including social networking and order-fulfillment; many-to-manyrelationships cause simple strategies to result in a large fraction of distributed queries.Instead; what is needed is a fine-grained partitioning; where related individual tuples (eg;cliques of friends) are co-located together in the same partition. Maintaining such a fine-grained partitioning requires the database to store a large amount of metadata about …,Data Engineering (ICDE); 2012 IEEE 28th International Conference on,2012,43
Demonstration of qurk: a query processor for humanoperators,Adam Marcus; Eugene Wu; David R Karger; Samuel Madden; Robert C Miller,Abstract Crowdsourcing technologies such as Amazon's Mechanical Turk (" MTurk") servicehave exploded in popularity in recent years. These services are increasingly used forcomplex human-reliant data processing tasks; such as labelling a collection of images;combining two sets of images to identify people that appear in both; or extracting sentimentfrom a corpus of text snippets. There are several challenges in designing a workflow thatfilters; aggregates; sorts and joins human-generated data sources. Currently; crowdsourcing-based workflows are hand-built; resulting in increasingly complex programs. Additionally;developers must hand-optimize tradeoffs among monetary cost; accuracy; and time tocompletion of results. These challenges are well-suited to a declarative query interface thatallows developers to describe their worflow at a high level and automatically optimizes …,Proceedings of the 2011 ACM SIGMOD International Conference on Management of data,2011,41
ICEDB: Intermittently-connected continuous query processing,Yang Zhang; Bret Hull; Hari Balakrishnan; Samuel Madden,Current distributed database and stream processing systems assume that the networkconnecting nodes in the data processor is" always on;" and that the absence of a networkconnection is a fault that needs to be masked to avoid failure. Several emerging wirelesssensor network applications must cope with a combination of node mobility (eg; sensors onmoving cars) and high data rates ('media-rich sensors capturing videos; images; sounds;etc.). Due to their mobility; these sensor networks display intermittent and variable networkconnectivity; and often have to deliver large quantities of data relative to the bandwidthavailable during periods of connectivity. This paper describes ICEDB (IntermittentlyConnected Embedded Database); a continuous query processing system for intermittentlyconnected mobile sensor networks. ICEDB incorporates two key ideas:(1) a delay …,Data Engineering; 2007. ICDE 2007. IEEE 23rd International Conference on,2007,41
A trigger-based middleware cache for ORMs,Priya Gupta; Nickolai Zeldovich; Samuel Madden,Abstract Caching is an important technique in scaling storage for high-traffic webapplications. Usually; building caching mechanisms involves significant effort from theapplication developer to maintain and invalidate data in the cache. In this work we presentCacheGenie; a caching middleware which makes it easy for web application developers touse caching mechanisms in their applications. CacheGenie provides high-level cachingabstractions for common query patterns in web applications based on Object-RelationalMapping (ORM) frameworks. Using these abstractions; the developer does nothave to worry about managing the cache (eg; insertion and deletion) or maintainingconsistency (eg; invalidation or updates) when writing application code. We design andimplement CacheGenie in the popular Django web application framework; with …,ACM/IFIP/USENIX International Conference on Distributed Systems Platforms and Open Distributed Processing,2011,40
Sensor networks for monitoring water supply and sewer systems: Lessons from boston,Ivan Stoianov; Lama Nachman; Andrew Whittle; Sam Madden; Ralph Kling,In recent years; research in wireless sensor networks (WSN) has been undergoing a quietrevolution; promising to have significant impact on a broad range of applications relating toenvironmental monitoring; structural health monitoring; security and water safety. Theconvergence of the Internet; telecommunications; and novel information technologies withtechniques for miniaturisation now provides vast opportunities for the development andapplication of low-cost monitoring solutions which could drastically increase the spatial andtemporal resolution of environmental data. The paper describes the development of aprototype monitoring system which bridges advances in wireless sensor networks withadvances in hydraulic and water quality modeling. The prototype monitoring system wasdeployed at Boston Water and Sewer Commission (BWSC) in December 2004; and it has …,*,2008,40
Mobius: unified messaging and data serving for mobile apps,Byung-Gon Chun; Carlo Curino; Russell Sears; Alexander Shraer; Samuel Madden; Raghu Ramakrishnan,Abstract Mobile application development is challenging for several reasons: intermittent andlimited network connectivity; tight power constraints; server-side scalability concerns; and anumber of fault-tolerance issues. Developers handcraft complex solutions that include client-side caching; conflict resolution; disconnection tolerance; and backend database sharding.To simplify mobile app development; we present Mobius; a system that addresses themessaging and data management challenges of mobile application development. Mobiusintroduces MUD (Messaging Unified with Data). MUD presents the programming abstractionof a logical table of data that spans devices and clouds. Applications using Mobius canasynchronously read from/write to MUD tables; and also receive notifications when tableschange via continuous queries on the tables. The system combines dynamic client-side …,Proceedings of the 10th international conference on Mobile systems; applications; and services,2012,39
S-Store: streaming meets transaction processing,John Meehan; Nesime Tatbul; Stan Zdonik; Cansu Aslantas; Ugur Cetintemel; Jiang Du; Tim Kraska; Samuel Madden; David Maier; Andrew Pavlo; Michael Stonebraker; Kristin Tufte; Hao Wang,Abstract Stream processing addresses the needs of real-time applications. Transactionprocessing addresses the coordination and safety of short atomic computations. Heretofore;these two modes of operation existed in separate; stove-piped systems. In this work; weattempt to fuse the two computational paradigms in a single system called S-Store. In thisway; S-Store can simultaneously accommodate OLTP and streaming applications. Wepresent a simple transaction model for streams that integrates seamlessly with a traditionalOLTP system; and provides both ACID and stream-oriented guarantees. We chose to build S-Store as an extension of H-Store-an open-source; in-memory; distributed OLTP databasesystem. By implementing S-Store in this way; we can make use of the transaction processingfacilities that H-Store already provides; and we can concentrate on the additional features …,Proceedings of the VLDB Endowment,2015,38
Using the Barton libraries dataset as an RDF benchmark,Daniel J Abadi; Adam Marcus; Samuel R Madden; Kate Hollenbach,Page 1. Computer Science and Artificial Intelligence Laboratory Technical Report massachusettsinstitute of technology; cambridge; ma 02139 usa — www.csail.mit.edu MIT-CSAIL-TR-2007-036 July 6; 2007 Using The Barton Libraries Dataset As An RDF benchmark Daniel J. Abadi;Adam Marcus; Samuel R. Madden; and Kate Hollenbach Page 2. Using The Barton LibrariesDataset As An RDF benchmark Daniel J. Abadi MIT dna@csail.mit.edu Adam Marcus MITmarcua@csail.mit.edu Samuel R. Madden MIT madden@csail.mit.edu Kate Hollenbach MITkjhollen@mit.edu ABSTRACT This report describes the Barton Libraries RDF dataset and Long-well query benchmark that we use for our recent VLDB paper on Scalable Semantic Web DataManagement Using Vertical Partition- ing [4] …,*,2007,38
Dwarf: Delay-aware robust forwarding for energy-constrained wireless sensor networks,Mario Strasser; Andreas Meier; Koen Langendoen; Philipp Blum,Abstract With the field of wireless sensor networks rapidly maturing; the focus shifts from“easy” deployments; like remote monitoring; to more difficult domains where applicationsimpose strict; real-time constraints on performance. One such class of applications is safetycritical systems; like fire and burglar alarms; where events detected by sensor nodes have tobe reported reliably and timely to a sink node. A complicating factor is that systems mustoperate for years without manual intervention; which puts very strong demands on theenergy efficiency of protocols running on current sensor-node platforms. Since we are notaware of a solution that meets all requirements of safety-critical systems; ie provides reliabledata delivery and low latency and low energy consumption; we present Dwarf; an energy-efficient; robust and dependable forwarding algorithm. The core idea is to use unicast …,International Conference on Distributed Computing in Sensor Systems,2007,38
SEEDB: automatically generating query visualizations,Manasi Vartak; Samuel Madden; Aditya Parameswaran; Neoklis Polyzotis,Abstract Data analysts operating on large volumes of data often rely on visualizations tointerpret the results of queries. However; finding the right visualization for a query is alaborious and time-consuming task. We demonstrate SeeDB; a system that partiallyautomates this task: given a query; SeeDB explores the space of all possible visualizations;and automatically identifies and recommends to the analyst those visualizations it finds to bemost" interesting" or" useful". In our demonstration; conference attendees will see SeeDB inaction for a variety of queries on multiple real-world datasets.,Proceedings of the VLDB Endowment,2014,37
Design and evaluation of a compiler for embedded stream programs,Ryan R Newton; Lewis D Girod; Michael B Craig; Samuel R Madden; John Gregory Morrisett,Abstract Applications that combine live data streams with embedded; parallel; anddistributed processing are becoming more commonplace. WaveScript is a domain-specificlanguage that brings high-level; type-safe; garbage-collected programming to thesedomains. This is made possible by three primary implementation techniques; each of whichleverages characteristics of the streaming domain. First; we employ a novel evaluationstrategy that uses a combination of interpretation and reification to partially evaluateprograms into stream dataflow graphs. Second; we use profile-driven compilation to enablemany optimizations that are normally only available in the synchronous (rather thanasynchronous) dataflow domain. Finally; we incorporate an extensible system for rewriterules to capture algebraic properties in specific domains (such as signal processing). We …,ACM Sigplan Notices,2008,36
Rapid sampling for visualizations with ordering guarantees,Albert Kim; Eric Blais; Aditya Parameswaran; Piotr Indyk; Sam Madden; Ronitt Rubinfeld,Abstract Visualizations are frequently used as a means to understand trends and gatherinsights from datasets; but often take a long time to generate. In this paper; we focus on theproblem of rapidly generating approximate visualizations while preserving crucial visualproperties of interest to analysts. Our primary focus will be on sampling algorithms thatpreserve the visual property of ordering; our techniques will also apply to some other visualproperties. For instance; our algorithms can be used to generate an approximatevisualization of a bar chart very rapidly; where the comparisons between any two bars arecorrect. We formally show that our sampling algorithms are generally applicable andprovably optimal in theory; in that they do not take more samples than necessary to generatethe visualizations with ordering guarantees. They also work well in practice; correctly …,Proceedings of the VLDB Endowment,2015,35
Vertexica: your relational friend for graph analytics!,Alekh Jindal; Praynaa Rawlani; Eugene Wu; Samuel Madden; Amol Deshpande; Mike Stonebraker,Abstract In this paper; we present Vertexica; a graph analytics tools on top of a relationaldatabase; which is user friendly and yet highly efficient. Instead of constraining programmersto SQL; Vertexica offers a popular vertex-centric query interface; which is more natural foranalysts to express many graph queries. The programmers simply provide their vertex-compute functions and Vertexica takes care of efficiently executing them in the standard SQLengine. The advantage of using Vertexica is its ability to leverage the relational features andenable much more sophisticated graph analysis. These include expressing graphalgorithms which are difficult in vertex-centric but straightforward in SQL and the ability tocompose end-to-end data processing pipelines; including pre-and post-processing ofgraphs as well as combining multiple algorithms for deeper insights. Vertexica has a …,Proceedings of the VLDB Endowment,2014,35
Tweets as data: demonstration of tweeql and twitinfo,Adam Marcus; Michael S Bernstein; Osama Badar; David R Karger; Samuel Madden; Robert C Miller,Abstract Microblogs such as Twitter are a tremendous repository of user-generated content.Increasingly; we see tweets used as data sources for novel applications such as disastermapping; brand sentiment analysis; and real-time visualizations. In each scenario; theworkflow for processing tweets is ad-hoc; and a lot of unnecessary work goes into repeatingcommon data processing patterns. We introduce TweeQL; a stream query processinglanguage that presents a SQL-like query interface for unstructured tweets to generatestructured data for downstream applications. We have built several tools on top of TweeQL;most notably TwitInfo; an event timeline generation and exploration interface thatsummarizes events as they are discussed on Twitter. Our demonstration will allow theaudience to interact with both TweeQL and TwitInfo to convey the value of data …,Proceedings of the 2011 ACM SIGMOD International Conference on Management of data,2011,35
Distributing queries over low-power wireless sensor networks,Samuel Madden; Joseph M Hellerstein,Over the past few years; a great deal of attention in the networking and mobile-computingcommunities has been directed towards building networks of ad-hoc collections of sensorsscattered throughout the world. The UC Berkeley SmartDust project [2]; as well asresearchers at UCLA and MIT [3; 1; 4] have embarked on projects to produce small;wireless; battery-powered sensors and low-level networking protocols. These projects havebrought us close to the the vision of ubiquitous eompnting [6]; in which computers andsensors assist in every aspect of our lives. To fully realize this vision; however; it will benecessary to combine and query the sensor readings produced by these collections ofsensors. In this demo; we show how database-style declarative queries can be executedover data streaming from sensor networks. Our demo consists of two major components …,Proceedings of the 2002 ACM SIGMOD international conference on Management of data,2002,33
Intel big data science and technology center vision and execution plan,Michael Stonebraker; Sam Madden; Pradeep Dubey,Abstract Intel has moved to a collaboration model with universities consisting of" Scienceand Technology Centers"(ISTCs). These are located at a" hub" university with participationfrom other universities; contain embedded Intel personnel; and are focused on someresearch theme. Intel held a national competition for a 5th Science and Technology center in2012 and selected a proposal from MIT with a theme of" Big Data". This paper presents thebig data vision of this technology center and the execution plan for the first few years.,ACM SIGMOD Record,2013,32
MAQSA: a system for social analytics on news,Sihem Amer-Yahia; Samreen Anjum; Amira Ghenai; Aysha Siddique; Sofiane Abbar; Sam Madden; Adam Marcus; Mohammed El-Haddad,Abstract We present MAQSA; a system for social analytics on news. MAQSA provides aninteractive topic-centric dashboard that summarizes news articles and social activity (eg;comments and tweets) around them. MAQSA helps editors and publishers in newsroomsunderstand user engagement and audience sentiment evolution on various topics ofinterest. It also helps news consumers explore public reaction on articles relevant to a topicand refine their exploration via related entities; topics; articles and tweets. Given a topic; eg;"Gulf Oil Spill;" or" The Arab Spring"; MAQSA combines three key dimensions: time;geographic location; and topic to generate a detailed activity dashboard around relevantarticles. The dashboard contains an annotated comment timeline and a social graph ofcomments. It utilizes commenters' locations to build maps of comment sentiment and …,Proceedings of the 2012 ACM SIGMOD International Conference on Management of Data,2012,30
A measurement-based analysis of the interaction between network layers in TinyOS,Umberto Malesci; Samuel Madden,Abstract There have been a number of recent proposals for link and network-layer protocolsin the sensor networking literature; each of which claims to be superior to other approaches.However; a proposal for a networking protocol at a given layer in the stack is typicallyevaluated in the context of a single set of carefully selected protocols at other layers.Because of the limited data available about interactions between different protocols atvarious layers of the stack; it is difficult for developers of sensor network applications toselect from amongst the range of alternative sensor networking protocols. This paperevaluates the interaction between several protocols at the MAC and network layersmeasuring their performance in terms of end-to-end throughput and loss on a large testbed.We identify some common sources of poor performance; based on this experience; we …,European Workshop on Wireless Sensor Networks,2006,29
Active learning for crowd-sourced databases,Barzan Mozafari; Purnamrita Sarkar; Michael J Franklin; Michael I Jordan; Samuel Madden,Abstract: Crowd-sourcing has become a popular means of acquiring labeled data for a widevariety of tasks where humans are more accurate than computers; eg; labeling images;matching objects; or analyzing sentiment. However; relying solely on the crowd is oftenimpractical even for data sets with thousands of items; due to time and cost constraints ofacquiring human input (which cost pennies and minutes per label). In this paper; wepropose algorithms for integrating machine learning into crowd-sourced databases; with thegoal of allowing crowd-sourcing applications to scale; ie; to handle larger datasets at lowercosts. The key observation is that; in many of the above tasks; humans and machinelearning algorithms can be complementary; as humans are often more accurate but slowand expensive; while algorithms are usually less accurate; but faster and cheaper. Based …,arXiv preprint arXiv:1209.3686,2012,28
Processing and visualizing the data in tweets,Adam Marcus; Michael S Bernstein; Osama Badar; David R Karger; Samuel Madden; Robert C Miller,Abstract Microblogs such as Twitter provide a valuable stream of diverse user-generateddata. While the data extracted from Twitter is generally timely and accurate; the process bywhich developers extract structured data from the tweet stream is ad-hoc and requiresreimplementation of common data manipulation primitives. In this paper; we present twosystems for querying and extracting structure from Twitter-embedded data. The first;TweeQL; provides a streaming SQL-like interface to the Twitter API; making common tweetprocessing tasks simpler. The second; TwitInfo; shows how end-users can interact with andunderstand aggregated data from the tweet stream; in addition to showcasing the power ofthe TweeQL language. Together these systems show the richness of content that can beextracted from Twitter.,ACM SIGMOD Record,2012,28
Sync kit: a persistent client-side database caching toolkit for data intensive websites,Edward Benson; Adam Marcus; David Karger; Samuel Madden,Abstract We introduce a client-server toolkit called Sync Kit that demonstrates how client-side database storage can improve the performance of data intensive websites. Sync Kit isdesigned to make use of the embedded relational database defined in the upcoming HTML5standard to offload some data storage and processing from a web server onto the webbrowsers to which it serves content. Our toolkit provides various strategies for synchronizingrelational database tables between the browser and the web server; along with a client-sidetemplate library so that portions web applications may be executed client-side. Unlike priorwork in this area; Sync Kit persists both templates and data in the browser across websessions; increasing the number of concurrent connections a server can handle by up to afactor of four versus that of a traditional server-only web stack and a factor of three versus …,Proceedings of the 19th international conference on World wide web,2010,27
Model-based querying in sensor networks,Amol Deshpande; Carlos Guestrin; Sam Madden,Advances in high throughput sequencing and ''omics''technologies and the resultingexponential growth in the amount of macromolecular sequence; structure; gene expressionmeasurements; have unleashed a transformation of biology from a data-poor science into anincreasingly data-rich science. Despite these advances; biology today; much like physicswas before Newton and Leibnitz; has remained a largely descriptive science. Machinelearning [6] currently offers some of the most cost-effective tools for building predictivemodels from biological data; eg; for annotating new genomic sequences; for predictingmacromolecular function; for identifying functionally important sites in proteins; for identifyinggenetic markers of diseases; and for discovering the networks of genetic interactions thatorchestrate important biological processes [3]. Advances in machine learning eg …,*,2009,27
Sloth: Being lazy is a virtue (when issuing database queries),Alvin Cheung; Samuel Madden; Armando Solar-Lezama,Abstract Many web applications store persistent data in databases. During execution; suchapplications spend a significant amount of time communicating with the database forretrieval and storing of persistent data over the network. These network round-trips representa significant fraction of the overall execution time for many applications (especially those thatissue a lot of database queries) and; as a result; increase their latency. While there has beenprior work that aims to eliminate round-trips by batching queries; they are limited by (1) arequirement that developers manually identify batching opportunities; or (2) the fact that theyemploy static program analysis techniques that cannot exploit many opportunities forbatching; as many of these opportunities require knowing precise information about the stateof the running program. In this article; we present S loth; a new system that extends …,ACM Transactions on Database Systems (TODS),2016,26
Subzero: a fine-grained lineage system for scientific databases,Eugene Wu; Samuel Madden; Michael Stonebraker,Data lineage is a key component of provenance that helps scientists track and queryrelationships between input and output data. While current systems readily support lineagerelationships at the file or data array level; finer-grained support at an array-cell level isimpractical due to the lack of support for user defined operators and the high runtime andstorage overhead to store such lineage. We interviewed scientists in several domains toidentify a set of common semantics that can be leveraged to efficiently store fine-grainedlineage. We use the insights to define lineage representations that efficiently capturecommon locality properties in the lineage data; and a set of APIs so operator developers caneasily export lineage information from user defined operators. Finally; we introduce twobenchmarks derived from astronomy and genomics; and show that our techniques can …,Data Engineering (ICDE); 2013 IEEE 29th International Conference on,2013,26
The case for rodentstore; an adaptive; declarative storage system,Philippe Cudre-Mauroux; Eugene Wu; Sam Madden,Abstract: Recent excitement in the database community surrounding new applications?analytic; scientific; graph; geospatial; etc.? has led to an explosion in research on databasestorage systems. New storage systems are vital to the database community; as they are atthe heart of making database systems perform well in new application domains.Unfortunately; each such system also represents a substantial engineering effort including agreat deal of duplication of mechanisms for features such as transactions and caching. Inthis paper; we make the case for RodentStore; an adaptive and declarative storage systemproviding a high-level interface for describing the physical representation of data.Specifically; RodentStore uses a declarative storage algebra whereby administrators (ordatabase design tools) specify how a logical schema should be grouped into collections …,arXiv preprint arXiv:0909.1779,2009,26
Guest Editors' Introduction: Distributed Data Mining--Framework and Implementations,Anup Kumar; Mehmed Kantardzic; Samuel Madden,It is now possible to gather and store incredible volumes of data; creating opportunities forlarge-scale data-driven knowledge discovery. Data mining technology has emerged as ameans of performing this discovery; and the added dimension of distributed data miningincreases this process's complexity.,IEEE Internet Computing,2006,26
Acquisitional Query Processing in TinyDB,Samuel Madden,Page 1. 1 Acquisitional Query Processing in TinyDB Sam Madden UC Berkeley NEST WinterRetreat 2003 Page 2. 2 Acquisitional Query Processing (ACQP) • Cynical DB person question:what's really different about sensor networks? –Low Power? –Lots of Nodes? –Limited ProcessingCapabilities? Laptops! Distributed DBs! Moore's Law! Being a little bit facetious; but… Page 3.3 Answer • Long running queries on physically embedded devices that control when and andwith what frequency data is collected! • Versus traditional systems where data is provided a prioriData collection aware query processing → “acqusitional query processing”; or ACQP! Page 4.4 ACQP: What's Different? • How does the user control acquisition? – Rates or lifetimes –Event-based triggers • How should the query be processed? – Sampling as a first class operation –Events or joins • Which nodes have relevant data …,Powerpoint Presentation,*,26
Partitioning techniques for fine-grained indexing,Eugene Wu; Samuel Madden,Many data-intensive websites use databases that grow much faster than the rate that usersaccess the data. Such growing datasets lead to ever-increasing space and performanceoverheads for maintaining and accessing indexes. Furthermore; there is often considerableskew with popular users and recent data accessed much more frequently. Theseobservations led us to design Shinobi; a system which uses horizontal partitioning as amechanism for improving query performance to cluster the physical data; and increasinginsert performance by only indexing data that is frequently accessed. We present databasedesign algorithms that optimally partition tables; drop indexes from partitions that areinfrequently queried; and maintain these partitions as workloads change. We show a 60×performance improvement over traditionally indexed tables using a real-world query …,Data Engineering (ICDE); 2011 IEEE 27th International Conference on,2011,25
Correlation maps: a compressed access method for exploiting soft functional dependencies,Hideaki Kimura; George Huo; Alexander Rasin; Samuel Madden; Stanley B Zdonik,Abstract In relational query processing; there are generally two choices for access pathswhen performing a predicate lookup for which no clustered index is available. One option isto use an unclustered index. Another is to perform a complete sequential scan of the table.Many analytical workloads do not benefit from the availability of unclustered indexes; thecost of random disk I/O becomes prohibitive for all but the most selective queries. It has beenobserved that a secondary index on an unclustered attribute can perform well under certainconditions if the unclustered attribute is correlated with a clustered index attribute [4]. Theclustered index will co-locate values and the correlation will localize access through theunclustered attribute to a subset of the pages. In this paper; we show that in a realapplication (SDSS) and widely used benchmark (TPC-H); there exist many cases of …,Proceedings of the VLDB Endowment,2009,25
StatusQuo: Making Familiar Abstractions Perform Using Program Analysis.,Alvin Cheung; Owen Arden; Samuel Madden; Armando Solar-Lezama; Andrew C Myers,ABSTRACT Modern web applications rely on databases for persistent storage; but thestrong separation between the application and the database layer makes it difficult to satisfyend-to-end goals; such as performance; reliability; and security. In this paper; we describeStatusQuo; a system that aims to address this problem by using program analysis andprogram synthesis to enable the seamless movement of functionality between the databaseand application layers. It does so by taking the functionality that was originally written asimperative code and translating it into relational queries that execute in the database. Inaddition; it makes runtime decisions about the optimal placement of computation; in order toreduce data movement between the database and application server. In this paper; wedescribe promising empirical results from the two key technologies that make up …,CIDR,2013,23
Automatic reconfiguration for large-scale reliable storage systems,Rodrigo Rodrigues; Barbara Liskov; Kathryn Chen; Moses Liskov; David Schultz,Byzantine-fault-tolerant replication enhances the availability and reliability of Internetservices that store critical state and preserve it despite attacks or software errors. However;existing Byzantine-fault-tolerant storage systems either assume a static set of replicas; orhave limitations in how they handle reconfigurations (eg; in terms of the scalability of thesolutions or the consistency levels they provide). This can be problematic in long-lived; large-scale systems where system membership is likely to change during the system lifetime. Inthis paper; we present a complete solution for dynamically changing system membership ina large-scale Byzantine-fault-tolerant system. We present a service that tracks systemmembership and periodically notifies other system nodes of membership changes. Themembership service runs mostly automatically; to avoid human configuration errors; is …,IEEE Transactions on Dependable and Secure Computing,2012,23
How to build a high-performance data warehouse,David J DeWitt; Samuel Madden; Michael Stonebraker,Over the last decade; the largest data warehouses have increased from 5 to 100 terabytes;according to Winter Corp.; and by 2010; most of today's data warehouses will be 10 timeslarger; according to The Data Warehouse Institute (TDWI). As data warehouses grow in sizeto accommodate regulatory requirements and competitive pressures; ensuring adequatedatabase performance will be a big challenge in order to answer more ad hoc queries frommore people. This article examines the various ways databases are architected to handlethe rapidly increasing scalability requirements; and the best combination of approaches forachieving high performance at low cost. Obviously; there are limits to the performance of anyindividual processor (CPU) or individual disk. Hence; all high-performance computersinclude multiple CPUs and multiple disks. Similarly; a high-performance DBMS must take …,Availabl e: http://db. lcs. mit. edu/madden/high_perf. pdf [Ac cessed: June 2011]. BIBLIOGRAPHY BIBLIOGRAPHY,2005,23
Genbase: A complex analytics genomics benchmark,Rebecca Taft; Manasi Vartak; Nadathur Rajagopalan Satish; Narayanan Sundaram; Samuel Madden; Michael Stonebraker,Abstract This paper introduces a new benchmark designed to test database managementsystem (DBMS) performance on a mix of data management tasks (joins; filters; etc.) andcomplex analytics (regression; singular value decomposition; etc.) Such mixed workloadsare prevalent in a number of application areas including most science workloads and webanalytics. As a specific use case; we have chosen genomics data for our benchmark andhave constructed a collection of typical tasks in this domain. In addition to beingrepresentative of a mixed data management and analytics workload; this benchmark is alsomeant to scale to large dataset sizes and multiple nodes across a cluster. Besidespresenting this benchmark; we have run it on a variety of storage systems includingtraditional row stores; newer column stores; Hadoop; and an array DBMS. We present …,Proceedings of the 2014 ACM SIGMOD international conference on Management of data,2014,22
Macrobase: Prioritizing attention in fast data,Peter Bailis; Edward Gan; Samuel Madden; Deepak Narayanan; Kexin Rong; Sahaana Suri,Abstract As data volumes continue to rise; manual inspection is becoming increasinglyuntenable. In response; we present MacroBase; a data analytics engine that prioritizes end-user attention in high-volume fast data streams. MacroBase enables efficient; accurate; andmodular analyses that highlight and aggregate important and unusual behavior; acting as asearch engine for fast data. MacroBase is able to deliver order-of-magnitude speedups overalternatives by optimizing the combination of explanation and classification tasks and byleveraging a new reservoir sampler and heavy-hitters sketch specialized for fast datastreams. As a result; MacroBase delivers accurate results at speeds of up to 2M events persecond per query on a single core. The system has delivered meaningful results inproduction; including at a telematics company monitoring hundreds of thousands of …,Proceedings of the 2017 ACM International Conference on Management of Data,2017,21
Challenges and Opportunities with Big Data,Elisa Bertino; Philip Bernstein; Divyakant Agrawal; Susan Davidson; Umeshwas Dayal; Michael Franklin; Johannes Gehrke; Laura Haas; Alon Halevy; Jiawei Han; HV Jadadish; Alexandros Labrinidis; Sam Madden; Yannis Papokonstantinou; Jignesh Patel; Raghu Ramakrishnan; Kenneth Ross; Cyrus Shahabi; Dan Suciu; Shiv Vaithyanathan; Jennifer Widom,Abstract The promise of data-driven decision-making is now being recognized broadly; andthere is growing enthusiasm for the notion of" Big Data". While the promise of Bid Data isreal-for example; it is estimated that Google alone contributed 54 billion dollars to the USeconomy in 2009-there is currently a wide gap between its potential and its realization.,*,2011,21
Ss-db: A standard science dbms benchmark,Philippe Cudre-Mauroux; Hideaki Kimura; Kian-Tat Lim; Jennie Rogers; Samuel Madden; Michael Stonebraker; Stanley B Zdonik; Paul G Brown,*,Under submission,2010,21
M odel DB: a system for machine learning model management,Manasi Vartak; Harihar Subramanyam; Wei-En Lee; Srinidhi Viswanathan; Saadiyah Husnoo; Samuel Madden; Matei Zaharia,Abstract Building a machine learning model is an iterative process. A data scientist will buildmany tens to hundreds of models before arriving at one that meets some acceptance criteria(eg AUC cutoff; accuracy threshold). However; the current style of model building is ad-hocand there is no practical way for a data scientist to manage models that are built over time.As a result; the data scientist must attempt to" remember" previously constructed models andinsights obtained from them. This task is challenging for more than a handful of models andcan hamper the process of sensemaking. Without a means to manage models; there is noeasy way for a data scientist to answer questions such as" Which models were built using anincorrect feature?";" Which model performed best on American customers?" or" How did thetwo top models compare?" In this paper; we describe our ongoing work on ModelDB; a …,Proceedings of the Workshop on Human-In-the-Loop Data Analytics,2016,20
The bigdawg polystore system and architecture,Vijay Gadepally; Peinan Chen; Jennie Duggan; Aaron Elmore; Brandon Haynes; Jeremy Kepner; Samuel Madden; Tim Mattson; Michael Stonebraker,Organizations are often faced with the challenge of providing data management solutions forlarge; heterogenous datasets that may have different underlying data and programmingmodels. For example; a medical dataset may have unstructured text; relational data; timeseries waveforms and imagery. Trying to fit such datasets in a single data managementsystem can have adverse performance and efficiency effects. As a part of the Intel Scienceand Technology Center on Big Data; we are developing a polystore system designed forsuch problems. BigDAWG (short for the Big Data Analytics Working Group) is a polystoresystem designed to work on complex problems that naturally span across differentprocessing or storage engines. BigDAWG provides an architecture that supports diversedatabase systems working with different data models; support for the competing notions …,High Performance Extreme Computing Conference (HPEC); 2016 IEEE,2016,19
Partial replay of long-running applications,Alvin Cheung; Armando Solar-Lezama; Samuel Madden,Abstract Bugs in deployed software can be extremely difficult to track down. Invasive loggingtechniques; such as logging all non-deterministic inputs; can incur substantial runtimeoverheads. This paper shows how symbolic analysis can be used to re-create pathequivalent executions for very long running programs such as databases and web servers.The goal is to help developers debug such long-running programs by allowing them to walkthrough an execution of the last few requests or transactions leading up to an error. Thechallenge is to provide this functionality without the high runtime overheads associated withtraditional replay techniques based on input logging or memory snapshots. Our approachachieves this by recording a small amount of information about program execution; such asthe direction of branches taken; and then using symbolic analysis to reconstruct the …,Proceedings of the 19th ACM SIGSOFT symposium and the 13th European conference on Foundations of software engineering,2011,19
Data management in the CarTel mobile sensor computing system,Vladimir Bychkovsky; Kevin Chen; Michel Goraczko; Hongyi Hu; Bret Hull; Allen Miu; Eugene Shih; Yang Zhang; Hari Balakrishnan; Samuel Madden,Abstract We propose a reusable data management system; called CarTel; for querying andcollecting data from intermittently connected devices. CarTel provides a simple;incrementally-deployable platform for developing automobile-based sensor applications.Our platform provides a dynamic query system that allows both continuous (standing) andone-shot geo-spatial queries over car position; speed; and sensory data as well as a both alow-cost/high-bandwidth substrate for communicating with a large network of mobiledevices.,Proceedings of the 2006 ACM SIGMOD international conference on Management of data,2006,19
Intel berkeley research lab,Samuel Madden,*,*,2004,19
Graph analytics using vertica relational database,Alekh Jindal; Samuel Madden; Malú Castellanos; Meichun Hsu,Graph analytics is becoming increasingly popular; with a number of new applications andsystems developed in the past few years. In this paper; we study Vertica relational databaseas a platform for graph analytics. We show that vertex-centric graph analysis can betranslated to SQL queries; typically involving table scans and joins; and that modern column-oriented databases are very well suited to running such queries. Furthermore; we show howdevelopers can trade memory footprint for significantly reduced I/O costs in Vertica. Wepresent an experimental evaluation of the Vertica relational database system on a variety ofgraph analytics; including iterative analysis; a combination of graph and relational analyses;and more complex 1-hop neighborhood graph analytics; showing that it is competitive to twopopular vertex-centric graph analytics systems; namely Giraph and GraphLab.,Big Data (Big Data); 2015 IEEE International Conference on,2015,18
GRAPHiQL: A graph intuitive query language for relational databases,Alekh Jindal; Samuel Madden,Graph analytics is becoming increasingly popular; driving many important businessapplications from social network analysis to machine learning. Since most graph data iscollected in a relational database; it seems natural to attempt to perform graph analyticswithin the relational environment. However; SQL; the query language for relationaldatabases; makes it difficult to express graph analytics operations. This is because SQLrequires programmers to think in terms of tables and joins; rather than the more naturalrepresentation of graphs as collections of nodes and edges. As a result; even relativelysimple graph operations can require very complex SQL queries. In this paper; we presentGRAPHiQL; an intuitive query language for graph analytics; which allows developers toreason in terms of nodes and edges. GRAPHiQL provides key graph constructs such as …,Big Data (Big Data); 2014 IEEE International Conference on,2014,18
Cabernet: A content delivery network for moving vehicles,Jakob Eriksson; Hari Balakrishnan; Sam Madden,This paper describes the design; implementation; and evaluation of Cabernet; a system todeliver data to and from moving vehicles using open 802.11 (WiFi) access pointsencountered opportunistically during travel. Network connectivity in Cabernet is both fleeting(access points are typicallywithin range for a few seconds) and intermittent (because theaccess points don't provide continuous coverage); and suffers from high packet loss ratesover the wireless channel. On the positive side; in the absence of losses; achievable datarates over WiFi can reach many megabits per second. Unfortunately; current protocols don'testablish end-to-end connectivity fast enough; don't cope well with intermittent connectivity;and don't handle high packet loss rates well enough to achieve this potential throughput.Cabernet incorporates two new techniques to improve data delivery throughput: QuickWifi …,*,2008,18
Wavescope: a signal-oriented data stream management system,Lewis Girod; Kyle Jamieson; Yuan Mei; Ryan Newton; Stanislav Rost; Arvind Thiagarajan; Hari Balakrishnan; Samuel Madden,Abstract WaveScope is a data management and continuous sensor data system thatintegrates relational database and signal processing operations into a single system.WaveScope is motivated by a large number of signal-oriented streaming sensorapplications; such as: preventive maintenance of industrial equipment; detection of fracturesand ruptures in various structures; in situ animal behavior studies using acoustic sensing;network traffic analysis; and medical applications such as anomaly detection in EKGs. Thesetarget applications use a variety of embedded sensors; each sampling at fine resolution andproducing data at high rates ranging from hundreds to hundreds of thousands of samplesper second. Though there has been some work on applications in the sensor networkcommunity that do this kind of signal processing (for example; shooter localization [5] …,Proceedings of the 4th international conference on Embedded networked sensor systems,2006,18
Impact of double-blind reviewing on SIGMOD publication rates,Samuel Madden; David DeWitt,Abstract Starting with the 2001 SIGMOD conference; the SIGMOD Chair; in consultation withthe SIGMOD Advisory Committee; imposed a double blind rule on all future SIGMODconferences. While there are many reasons why double-blind reviewing might be a goodidea; the one most frequently cited is that it is fairer to more junior researchers. It is not;however; without its problems; including anecdotal reports of papers being rejected becausetheir authors failed to cite their own papers as related work in order to not violate theanonymity rules and a complication of the job of the program chair who must interpret andenforce the double-blind rules. One very qualified individual turned down an offer to be PCchair of an upcoming SIGMOD conference because he did not want to have to deal with theheadaches of double-blind reviewing.,ACM SIGMOD Record,2006,18
The TileDB array data storage manager,Stavros Papadopoulos; Kushal Datta; Samuel Madden; Timothy Mattson,Abstract We present a novel storage manager for multi-dimensional arrays that arise inscientific applications; which is part of a larger scientific data management system calledTileDB. In contrast to existing solutions; TileDB is optimized for both dense and sparsearrays. Its key idea is to organize array elements into ordered collections called fragments.Each fragment is dense or sparse; and groups contiguous array elements into data tiles offixed capacity. The organization into fragments turns random writes into sequential writes;and; coupled with a novel read algorithm; leads to very efficient reads. TileDB enablesparallelization via multi-threading and multi-processing; offering thread-/process-safety andatomicity via lightweight locking. We show that TileDB delivers comparable performance tothe HDF5 dense array storage manager; while providing much faster random writes. We …,Proceedings of the VLDB Endowment,2016,17
Collaborative data analytics with DataHub,Anant Bhardwaj; Amol Deshpande; Aaron J Elmore; David Karger; Sam Madden; Aditya Parameswaran; Harihar Subramanyam; Eugene Wu; Rebecca Zhang,Abstract While there have been many solutions proposed for storing and analyzing largevolumes of data; all of these solutions have limited support for collaborative data analytics;especially given the many individuals and teams are simultaneously analyzing; modifyingand exchanging datasets; employing a number of heterogeneous tools or languages fordata analysis; and writing scripts to clean; preprocess; or query data. We demonstrateDataHub; a unified platform with the ability to load; store; query; collaboratively analyze;interactively visualize; interface with external applications; and share datasets. We willdemonstrate the following aspects of the DataHub platform:(a) flexible data storage; sharing;and native versioning capabilities: multiple conference attendees can concurrently updatethe database and browse the different versions and inspect conflicts;(b) an app …,Proceedings of the VLDB Endowment,2015,17
Using Program Analysis to Improve Database Applications.,Alvin Cheung; Samuel Madden; Armando Solar-Lezama; Owen Arden; Andrew C Myers,Abstract Applications that interact with database management systems (DBMSs) areubiquitous. Such database applications are usually hosted on an application server andperform many small accesses over the network to a DBMS hosted on the database server toretrieve data for processing. For decades; the database and programming systems researchcommunities have worked on optimizing such applications from different perspectives:database researchers have built highly efficient DBMSs; and programming systemsresearchers have developed specialized compilers and runtime systems for hostingapplications. However; there has been relatively little work that optimizes databaseapplications by considering these specialized systems in combination and looking foroptimization opportunities that span across them. In this article; we highlight three projects …,IEEE Data Eng. Bull.,2014,17
The impact of meta-information on decision-making in intelligence operations,Jonathan Pfautz; Adam Fouse; Ted Fichtl; Emilie Roth; Ann Bisantz; Samuel Madden,Decision-making in complex; dynamic; high-risk environments is clearly challenging. Part ofthis challenge is due to the presence of qualifiers of information; or meta-information (eg;staleness; uncertainty; source); that alter a person's information processing; situationalawareness; and decision-making. We investigated the influence of meta-information ondecision-making in a Military Intelligence Operations (IO) environment using Cognitive TaskAnalysis (CTA) techniques. We performed a CTA on IO tasks surrounding the use of smartsensor webs; a relatively new technology that can be used for a variety of IO purposes. Ouranalysis addressed information management tasks and tactical decision-making tasks usingsensor webs. We discovered that a variety of types of meta-information significantlyimpacted decision-making; and that the influence of meta-information was both context …,*,2005,17
Telematics using personal mobile devices,*,An approach to telematics using mobile devices provides battery-efficient trajectory andmileage inference from inaccurate and intermittent location data. Accurate trajectories ofhow users or vehicles move in the physical world are formed by processing raw positionestimates obtained from noisy; inaccurate; and error-prone position sensors on mobiledevices; where the position data may also arrive intermittently with long time gaps. Thetrajectory is formed using the process of map matching; which determines the trajectory on amap that best explains the sequence of position observations.,*,2013,16
An overview of HYRISE-a Main Memory Hybrid Storage Engine.,Martin Grund; Philippe Cudré-Mauroux; Jens Krüger; Samuel Madden; Hasso Plattner,Abstract HYRISE is a new relational storage engine for main memory database systems. It isbuilt on the premise that enterprise application workloads can benefit from a dedicated main-memory storage engine. The key idea behind HYRISE is that it provides dynamic verticalpartitioning of the tables it stores. Since enterprise applications typically use a large numberof very wide tables; we designed a novel layout algorithm specifically tailored for enterprisedata. Our algorithm uses a main memory cost model that is able to precisely estimate thephysical access cost of database operators and to determine a vertical partitioning thatyields the best execution performance.,IEEE Data Eng. Bull.,2012,16
Upi: A primary index for uncertain databases,Hideaki Kimura; Samuel Madden; Stanley B Zdonik,Abstract Uncertain data management has received growing attention from industry andacademia. Many efforts have been made to optimize uncertain databases; including thedevelopment of special index data structures. However; none of these efforts have exploredprimary (clustered) indexes for uncertain databases; despite the fact that clustering has thepotential to offer substantial speedups for non-selective analytic queries on large uncertaindatabases. In this paper; we propose a new index called a UPI (Uncertain Primary Index)that clusters heap files according to uncertain attributes with both discrete and continuousuncertainty distributions. Because uncertain attributes may have several possible values; aUPI on an uncertain attribute duplicates tuple data once for each possible value. To preventthe size of the UPI from becoming unmanageable; its size is kept small by placing low …,Proceedings of the VLDB Endowment,2010,16
Decibel: The relational dataset branching system,Michael Maddox; David Goehring; Aaron J Elmore; Samuel Madden; Aditya Parameswaran; Amol Deshpande,Abstract As scientific endeavors and data analysis become increasingly collaborative; thereis a need for data management systems that natively support the versioning or branching ofdatasets to enable concurrent analysis; cleaning; integration; manipulation; or curation ofdata across teams of individuals. Common practice for sharing and collaborating ondatasets involves creating or storing multiple copies of the dataset; one for each stage ofanalysis; with no provenance information tracking the relationships between these datasets.This results not only in wasted storage; but also makes it challenging to track and integratemodifications made by different users to the same dataset. In this paper; we introduce theRelational Dataset Branching System; Decibel; a new relational storage system with built-inversion control designed to address these short-comings. We present our initial design for …,Proceedings of the VLDB Endowment,2016,15
Using program synthesis for social recommendations,Alvin Cheung; Armando Solar-Lezama; Samuel Madden,Abstract This paper presents a new approach to select events of interest to users in a socialmedia setting where events are generated from mobile devices. We argue that the problemis best solved by inductive learning; where the goal is to first generalize from the users'expressed" likes" and" dislikes" of specific events; then to produce a program that can beused to collect only data of interest. The key contribution of this paper is a new algorithm thatcombines machine learning techniques with program synthesis technology to learn users'preferences. We show that when compared with the more standard approaches; our newalgorithm provides up to order-of-magnitude reductions in model training time; andsignificantly higher prediction accuracies for our target application. 1,Proceedings of the 21st ACM international conference on Information and knowledge management,2012,15
Query processing for streaming sensor data,Samuel Madden,*,Comput. Sci. Div,2002,15
Social analytics,*,A computer-implemented method; comprises extracting a measure from a content articlerepresenting a probability that the article relates to a topic; allocating the article to a group ofarticles relating to at least one topic on the basis of the measure; using a set of social mediaobjects relating to the article to extract a measure representing a sentiment for the article;and aggregating respective measures for the sentiment of articles in the group to provide anaggregate measure.,*,2015,14
Database abstractions for managing sensor network data,Samuel Madden,Sensor networking hardware; networking; and operating system software has matured to thepoint that the major challenges facing the field now have to do with storing; cleaning; andquerying the data such networks produce. In this paper; we survey several research systemsdesigned for managing sensor data using declarative database-like abstractions from thedatabase community and specifically the Massachusetts Institute of Technology (MIT;Cambridge) database group. The systems we discuss are designed to help prioritize datacollection in the face of intermittent bandwidth; clean and smooth data using statisticalmodels stored inside the database; and run declarative queries over probabilistic data.,Proceedings of the IEEE,2010,14
Performance profiling with EndoScope; an acquisitional software monitoring framework,Alvin Cheung; Samuel Madden,Abstract We propose EndoScope; a software monitoring framework that allows users to posedeclarative queries that monitor the state and performance of running programs. Unlike mostexisting monitoring tools; EndoScope is acquisitional; meaning that it only instruments theportions of the program that need to be monitored to answer queries. The use of a high leveldeclarative language allows EndoScope to search for efficient physical instantiations ofqueries by applying a suite of optimizations; including control flow graph analysis; andtraditional database query optimization techniques; such as predicate pushdown and joinoptimization; to minimize the number of program instrumentation points and overhead to themonitored program. Furthermore; a flexible; high level language and the ability to attach torunning programs enable developers to build various program analysis and monitoring …,Proceedings of the VLDB Endowment,2008,14
Wavescript: A case-study in applying a distributed stream-processing language,Ryan Newton; Lewis Girod; Michael Craig; Sam Madden; Greg Morrisett,Applications that combine live data streams with embedded; parallel; and distributedprocessing are becoming more commonplace. WaveScriptis a domain-specific languagethat brings high-level; type-safe; garbage-collected programming to these domains. This ismade possibleby three primary implementation techniques. First; we employ anovelevaluation strategy that uses a combination of interpretation andreification to partiallyevaluate programs into stream dataflowgraphs. Second; we use profile-driven compilation toenable manyoptimizations that are normally only available in the synchronous (rather thanasynchronous) dataflow domain. Finally; we incorporatean extensible system for rewriterules to capture algebraic propertiesin specific domains (such as signal processing). Wehave used our language to build and deploy a sensor-network for theacoustic localization …,*,2008,14
The Aurora and Borealis Stream Processing Engines,Uğur Çetintemel; Daniel Abadi; Yanif Ahmad; Hari Balakrishnan; Magdalena Balazinska; Mitch Cherniack; Jeong-Hyon Hwang; Samuel Madden; Anurag Maskey; Alexander Rasin; Esther Ryvkina; Mike Stonebraker; Nesime Tatbul; Ying Xing; Stan Zdonik,Abstract Over the last several years; a great deal of progress has been made in the area ofstream-processing engines (SPEs). Three basic tenets distinguish SPEs from current dataprocessing engines. First; they must support primitives for streaming applications. UnlikeOnline Transaction Processing (OLTP); which processes messages in isolation; streamingapplications entail time series operations on streams of messages. Second; streamingapplications entail a real-time component. If one is content to see an answer later; then onecan store incoming messages in a data warehouse and run a historical query on thewarehouse to find information of interest. This tactic does not work if the answer must beconstructed in real time. The need for real-time answers also dictates a fundamentallydifferent storage architecture. DBMSs universally store and index data records before …,*,2016,13
The Data Civilizer System.,Dong Deng; Raul Castro Fernandez; Ziawasch Abedjan; Sibo Wang; Michael Stonebraker; Ahmed K Elmagarmid; Ihab F Ilyas; Samuel Madden; Mourad Ouzzani; Nan Tang,ABSTRACT In many organizations; it is often challenging for users to find relevant data forspecific tasks; since the data is usually scattered across the enterprise and ofteninconsistent. In fact; data scientists routinely report that the majority of their effort is spentfinding; cleaning; integrating; and accessing data of interest to a task at hand. In order todecrease the “grunt work” needed to facilitate the analysis of data “in the wild”; we presentDATA CIVILIZER; an end-to-end big data management system. DATA CIVILIZER has alinkage graph computation module to build a linkage graph for the data and a data discoverymodule which utilizes the linkage graph to help identify data that is relevant to user tasks. Italso uses the linkage graph to discover possible join paths that can then be used in a query.For the actual query execution; we use a polystore DBMS; which federates query …,CIDR,2017,12
Towards a unified query language for provenance and versioning,Amit Chavan; Silu Huang; Amol Deshpande; Aaron Elmore; Samuel Madden; Aditya Parameswaran,Abstract Organizations and teams collect and acquire data from various sources; such associal interactions; financial transactions; sensor data; and genome sequencers. Differentteams in an organization as well as different data scientists within a team are interested inextracting a variety of insights which requires combining and collaboratively analyzingdatasets in diverse ways. DataHub is a system that aims to provide robust version controland provenance management for such a scenario. To be truly useful for collaborative datascience; one also needs the ability to specify queries and analysis tasks over the versioningand the provenance information in a unified manner. In this paper; we present an initialdesign of our query language; called VQuel; that aims to support such unified querying overboth types of information; as well as the intermediate and final results of analyses. We …,arXiv preprint arXiv:1506.04815,2015,12
Implementation and research issues in query processing for wireless sensor networks,Wei Hong; Samuel Madden,This is a three-hour seminar discussing the design and implementation of software systemsas well as open research problems related to data processing and collection in wirelesssensor networks. During the first hour-and-ahalf; we focus on the design of the TinyDB datacollection system for networks of Berkeley motes running the TinyOS operating system.Then; during the remainder of the seminar; we survey relevant literature from the database;networking; and OS communities and identify a number of unsolved and inadequatelyaddressed research problems. This seminar is intended for anyone interested in wirelesssensor networks with a general background in computer science; be they users of sensornetworks looking for an easy way to collect data; developers interested in the design ofTinyOS and TinyDB; or researchers in search of challenging new problems.,Data Engineering; 2004. Proceedings. 20th International Conference on,2004,12
Voodoo-a vector algebra for portable database performance on modern hardware,Holger Pirk; Oscar Moll; Matei Zaharia; Sam Madden,Abstract In-memory databases require careful tuning and many engineering tricks to achievegood performance. Such database performance engineering is hard: a plethora of data andhardware-dependent optimization techniques form a design space that is difficult to navigatefor a skilled engineer---even more so for a query compiler. To facilitate performance-orienteddesign exploration and query plan compilation; we present Voodoo; a declarativeintermediate algebra that abstracts the detailed architectural properties of the hardware;such as multi-or many-core architectures; caches and SIMD registers; without losing theability to generate highly tuned code. Because it consists of a collection of declarative; vector-oriented operations; Voodoo is easier to reason about and tune than low-level C and relatedhardware-focused extensions (Intrinsics; OpenCL; CUDA; etc.). This enables our Voodoo …,Proceedings of the VLDB Endowment,2016,11
Compression and query execution within column oriented databases,Miguel C Ferreira,Compression is a known technique used by many database management systems ("DBMS") to increase performance [4; 5; 14]. However; not much research has been done inhow compression can be used within column oriented architectures. Storing data in columnincreases the similarity between adjacent records; thus increase the compressibility of thedata. In addition; compression schemes not traditionally used in row-oriented DBMSs can beapplied to column-oriented systems. This thesis presents a column-oriented query executordesigned to operate directly on compressed data.'We show that operating directly oncompressed data can improve query performance. Additionally; the choice of compressionscheme depends on the expected query workload; suggesting that for ad-hoc queries wemay wish to store a column redundantly under different coding schemes. Furthermore; the …,*,2005,11
Supporting fast iteration in model building,Manasi Vartak; Pablo Ortiz; Kathryn Siegel; Harihar Subramanyam; Samuel Madden; Matei Zaharia,Abstract Building real-world machine learning models involves an iterative process ofengineering features; fitting models; and tuning parameters until a model that meets specificacceptance criteria is identified. Over the course of a modeling session; tens to hundreds ofmodels may be built and evaluated. Although the modeling process is iterative; current toolsare optimized for individual models as opposed to modeling sessions. In this paper; weargue the need for a system to support the entire modeling process by making it cheap torun and track experiments. We describe the desiderata for such a system spanning systemsoptimizations to visual interfaces; and describe the ongoing implementation of SHERLOCK;a system optimized for iterative model building.,NIPS Workshop LearningSys,2015,10
CARTILAGE: adding flexibility to the Hadoop skeleton,Alekh Jindal; Jorge Quiané-Ruiz; Samuel Madden,Abstract Modern enterprises have to deal with a variety of analytical queries over very largedatasets. In this respect; Hadoop has gained much popularity since it scales to thousand ofnodes and terabytes of data. However; Hadoop suffers from poor performance; especially inI/O performance. Several works have proposed alternate data storage for Hadoop in order toimprove the query performance. However; many of these works end up making deepchanges in Hadoop or HDFS. As a result; they are (i) difficult to adopt by several users; and(ii) not compatible with future Hadoop releases. In this paper; we present CARTILAGE; acomprehensive data storage framework built on top of HDFS. CARTILAGE allows users fullcontrol over their data storage; including data partitioning; data replication; data layouts; anddata placement. Furthermore; CARTILAGE can be layered on top of an existing HDFS …,Proceedings of the 2013 ACM SIGMOD International Conference on Management of Data,2013,10
CHIC: a combination-based recommendation system,Manasi Vartak; Samuel Madden,Abstract Current recommender systems are focused largely on recommending items basedon similarity. For instance; Netflix can recommend movies similar to previously viewedmovies; and Amazon can recommend items based on ratings of similar users. Althoughsimilarity-based recommendation works well for books and movies; it provides anincomplete solution for items such as clothing or furniture which are inherently used incombination with other items of the same type; eg; shirt with pants; and desk with a chair. Asa result; the decision to buy a clothing or furniture item depends not only on the item itself;but also on how well it works with other items of that type. Recommending such itemstherefore requires a combination-based recommendation system that given an item; cansuggest interesting and diverse combinations containing that item. This problem is …,Proceedings of the 2013 ACM SIGMOD International Conference on Management of Data,2013,9
Scoop: a hybrid; adaptive storage policy for sensor networks,Thomer M Gil; Samuel Madden,Abstract—One problem with existing store-and-query sensor networks is that they fail to takedata and query rates or network topology information into account. This leads to expensive(and avoidable) communication overhead that reduces the lifespan of battery-poweredsensor networks. Scoop reduces this overhead (up to a factor of four in our experiments) bydynamically creating and adapting an in-network storage policy based on statistics it collectsabout data; queries; and network conditions. Whereas existing in-network storagetechniques are often at the extreme ends of the storage policy spectrum (eg; store all dataexternally on a basestation; or store all data locally); Scoop's storage policy allows it to adaptbetween these extremes depending on the situation. The intuition behind our scheme is thatdata should be stored close to where it is needed; if it is needed. If query rates are high …,MIT CSAIL Technical Report,2006,9
A demonstration of DBWipes: clean as you query,Eugene Wu; Samuel Madden; Michael Stonebraker,Abstract As data analytics becomes mainstream; and the complexity of the underlying dataand computation grows; it will be increasingly important to provide tools that help analystsunderstand the underlying reasons when they encounter errors in the result. While dataprovenance has been a large step in providing tools to help debug complex workflows; itscurrent form has limited utility when debugging aggregation operators that compute a singleoutput from a large collection of inputs. Traditional provenance will return the entire inputcollection; which has very low precision. In contrast; users are seeking precise descriptionsof the inputs that caused the errors. We propose a Ranked Provenance System; whichidentifies subsets of inputs that influenced the output error; describes each subset withhuman readable predicates and orders them by contribution to the error. In this …,Proceedings of the VLDB Endowment,2012,8
Code in the air: simplifying sensing on smartphones,Tim Kaler; John Patrick Lynch; Timothy Peng; Lenin Ravindranath; Arvind Thiagarajan; Hari Balakrishnan; Sam Madden,Abstract Modern smartphones are equipped with a wide variety of sensors including GPS;WiFi and cellular radios capable of positioning; accelerometers; magnetic compasses andgyroscopes; light and proximity sensors; and cameras. These sensors have madesmartphones an attractive platform for collaborative sensing (aka crowdsourcing)applications where phones cooperatively collect sensor data to perform various tasks.Researchers and mobile application developers have developed a wide variety of suchapplications. Examples of such systems include BikeTastic [4] and BikeNet [1] which allowbicyclists to collaboratively map and visualize biking trails; SoundSense [3] for collecting andanalyzing microphone data; iCartel [2] which crowdsources driving tracks from users tomonitor road traffic in real time; and Transitgenie [5]; which cooperatively tracks buses …,Proceedings of the 8th ACM Conference on Embedded Networked Sensor Systems,2010,8
W.: TAG: Tiny AGgregate queries in ad-hoc sensor networks,Samuel Madden; Michael J Franklin; Joseph Hellerstein; Wei Hong,Abstract We present the Tiny AGgregation (TAG) ap-proach to distributing declarative SQL-style ag-gregate queries with grouping over networks of low-power; wireless sensors. Wediscuss vari-ous generic properties of aggregates; and show how those properties affect theperformance of our in-network approach. We include a per-formance study demonstratingthe advantages of our approach over traditional centralized; out-of-network methods; anddiscuss a variety of op-timizations for improving the performance and fault-tolerance of thebasic solution. 1,In: Proc. USENIX Symposium on Operating Systems Design and Implementation,2002,8
Database parallelism choices greatly impact scalability. DatabaseColumn Blog,S Madden; D DeWitt; M Stonebraker,*,*,*,8
Attendee-sourcing: Exploring the design space of community-informed conference scheduling,Anant Bhardwaj; Juho Kim; Steven Dow; David Karger; Sam Madden; Rob Miller; Haoqi Zhang,Abstract Constructing a good conference schedule for a large multi-track conference needsto take into account the preferences and constraints of organizers; authors; and attendees.Creating a schedule which has fewer conflicts for authors and attendees; and thematicallycoherent sessions is a challenging task. Cobi introduced an alternative approach toconference scheduling by engaging the community to play an active role in the planningprocess. The current Cobi pipeline consists of committee-sourcing and author-sourcing toplan a conference schedule. We further explore the design space of community-sourcing byintroducing attendee-sourcing--a process that collects input from conference attendees andencodes them as preferences and constraints for creating sessions and schedule. For CHI2014; a large multi-track conference in human-computer interaction with more than 3;000 …,Second AAAI conference on human computation and crowdsourcing,2014,7
Inferring SQL queries using program synthesis,Alvin Cheung; Armando Solar-Lezama; Samuel Madden,Abstract: Developing high-performance applications that interact with databases is a difficulttask; as developers need to understand both the details of the language in which theirapplications are written in; and also the intricacies of the relational model. One popularsolution to this problem is the use of object-relational mapping (ORM) libraries that providetransparent access to the database using the same language that the application is writtenin. Unfortunately; using such frameworks can easily lead to applications with poorperformance because developers often end up implementing relational operations inapplication code; and doing so usually does not take advantage of the optimizedimplementations of relational operations; efficient query plans; or push down of predicatesthat database systems provide. In this paper we present QBS; an algorithm that …,arXiv preprint arXiv:1208.2013,2012,7
Probabilistic models for mobile phone trajectory estimation,Arvind Thiagarajan,This dissertation is concerned with the problem of determining the track or trajectory of amobile device-for example; a sequence of road segments on an outdoor map; or asequence of rooms visited inside a building-in an energy-efficient and accurate manner.GPS; the dominant positioning technology today; has two major limitations. First; itconsumes significant power on mobile phones; making it impractical for continuousmonitoring. Second; it does not work indoors. This dissertation develops two ways toaddress these limitations:(a) subsampling GPS to save energy; and (b) using alternatives toGPS such as WiFi localization; cellular localization; and inertial sensing (with theaccelerometer and gyroscope) that consume less energy and work indoors. The keychallenge is to match a sequence of infrequent (from sub-sampling) and inaccurate (from …,*,2011,7
QCD precision measurements and structure function extraction at a high statistics; high energy neutrino scattering experiment: NuSOnG,T Adams; P Batra; L Bugel; L Camilleri; Janet Marie Conrad; A De Gouvêa; PH Fisher; JA Formaggio; J Jenkins; G Karagiorgi; TR Kobilarcik; S Kopp; G Kyle; WA Loinaz; DA Mason; R Milner; R Moore; JG Morfín; M Nakamura; D Naples; P Nienaber; FI Olness; JF Owens; SF Pate; A Pronin; WG Seligman; MH Shaevitz; H Schellman; I Schienbein; MJ Syphers; TMP Tait; T Takeuchi; CY Tan; RG Van de Water; RK Yamamoto; JY Yu,We extend the physics case for a new high-energy; ultra-high statistics neutrino scatteringexperiment; NuSOnG (Neutrino Scattering On Glass) to address a variety of issues includingprecision QCD measurements; extraction of structure functions; and the derived PartonDistribution Functions (PDF's). This experiment uses a Tevatron-based neutrino beam toobtain a sample of Deep Inelastic Scattering (DIS) events which is over two orders ofmagnitude larger than past samples. We outline an innovative method for fitting the structurefunctions using a parametrized energy shift which yields reduced systematic uncertainties.High statistics measurements; in combination with improved systematics; will enableNuSOnG to perform discerning tests of fundamental Standard Model parameters as wesearch for deviations which may hint of" Beyond the Standard Model" physics.,International Journal of Modern Physics A,2010,7
Distributed data streams,Minos Garofalakis,realized using such logical structures. For example; in tree based data acquisition protocols;a collection tree is built that is rooted at the data collection center such as the sink node [8].The dissemination of the data requests from the participating nodes and collection of datafrom the sensor nodes are accomplished using this tree. A cluster based data acquisitionmechanism has been proposed in [3]. As shown in Fig. 1; nodes are organized into a fixednumber of clusters; and nodes within each cluster dynamically elect a cluster head. The dataacquisition is carried out in two phases. In the first phase; cluster heads collect data fromtheir cluster nodes. In the second phase; cluster heads send collected data to the nodes thathave subscribed to the data. The cluster heads are re-elected to balance energyconsumption among the nodes in the cluster. Zhang et al.[13] have proposed an adaptive …,*,2009,7
Mesh networking research and technology for multihop wireless networks,Samuel Madden; Philip Levis,Mesh Networking Applications The simplest examples of meshes involve a few 802.11 repeatersextending wireless access in homes. More sophisticated examples of 802.11 meshes includethe municipal area networks that cover some cities; these networks use hundreds of access points(APs); only some of which have Internet connectivity. Clients connect to nearby APs; which mightin turn send data directly to the Internet or route through another AP if In- ternet connectivityisn't available. Examples of companies selling such products include Tropos Networks and MerakiNetworks. These meshes extend an Internet AP's reach; providing con- nectivity to urban as wellas rural areas. Sensor networks also depend on wireless meshes. The typical sensor networkingappli- cation involves several small; wireless; bat- tery-powered sensing nodes; which collectand report information about remote environments. For example; a group of researchers …,IEEE Internet Computing,2008,7
Thinking Big About Tiny Databases.,Michael J Franklin; Joseph M Hellerstein; Samuel Madden; U Berkeley; M CSAIL,Abstract Work on early tiny database systems; like TinyDB [17] and Cougar [23] has shownthat a declarative approach can provide a powerful and easy to use interface for collectingdata from static sensor networks. These early systems; however; have significant limitations;in particular; they are useful only for low-rate data collection applications on static sensornetworks and they don't integrate well with existing database and IT tools. In this paper; wediscuss recent research that has addressed these limitations; showing that similar “tinydatabase thinking” can provide solutions to much bigger problems; including networkprotocol specification and mobile and high data rate signal-oriented data processing.,IEEE Data Eng. Bull.,2007,7
Data Management Issues in Disconnected Sensor Networks.,Wolfgang Lindner; Samuel Madden,Abstract: The possibility of disconnection is one of the fundamental new networkingproblems presented by sensor networks. The goal of this paper is to address the problem ofresult collection in periodically disconnected sensor networks; focusing; in particular; onopportunities for in-network processing. Our hypothesis is that; through careful augmentationof the networking layer underneath the declarative query processor; it will be possible toexpose information that will make the query processor able to adapt to and handledisconnections.,GI Jahrestagung (2),2004,7
Inference of vehicular trajectory characteristics with personal mobile devices,*,Accurate longitudinal acceleration; lateral acceleration (perpendicular to the principaldirection of motion; and velocity; is inferred by processing raw data from a commodity three-axis accelerometer that may be oriented arbitrarily in a moving vehicle (or carried by amoving user); and whose orientation and position may change arbitrarily during the motion.The approach is applicable to a range of applications; including insurance telematics; driverbehavior and risk assessment; and road surface quality assessment.,*,2016,6
Coverage-oriented sensor deployment,Yi Zou; Krishnendu Chakrabarty,Wireless sensor networks that are capable of observing the environment; processing data;and making decisions based on these observations have recently attracted considerableattention [1–4]. These networks are important for a number of applications; such ascoordinated target detection and localization; surveillance; and environmental monitoring.Breakthroughs in miniaturization; hardware design techniques; and system software haveled to cheaper sensors and fueled recent advances in wireless sensor networks [1; 2; 5]. Inthis chapter; we are focusing on coverage-driven sensor deployment. The coverage of asensor network refers to the extent to which events in the monitored region can be detectedby the sensors deployed. We present strategies for enhancing the coverage of sensornetworks with low computation cost; a small number of sensors; and low energy …,*,2005,6
Generating concise entity matching rules,Rohit Singh; Vamsi Meduri; Ahmed Elmagarmid; Samuel Madden; Paolo Papotti; Jorge-Arnulfo Quiané-Ruiz; Armando Solar-Lezama; Nan Tang,Abstract Entity matching (EM) is a critical part of data integration and cleaning. In manyapplications; the users need to understand why two entities are considered a match; whichreveals the need for interpretable and concise EM rules. We model EM rules in the form ofGeneral Boolean Formulas (GBFs) that allows arbitrary attribute matching combined byconjunctions (∨); disjunctions (∧); and negations.(¬) GBFs can generate more conciserules than traditional EM rules represented in disjunctive normal forms (DNFs). We useprogram synthesis; a powerful tool to automatically generate rules (or programs) thatprovably satisfy a high-level specification; to automatically synthesize EM rules in GBFformat; given only positive and negative matching examples. In this demo; attendees willexperience the following features:(1) Interpretability--they can see and measure the …,Proceedings of the 2017 ACM International Conference on Management of Data,2017,5
Speeding up database applications with pyxis,Alvin Cheung; Owen Arden; Samuel Madden; Andrew C Myers,Abstract We propose to demonstrate Pyxis; a system that optimizes database applications bypushing computation to the database server. Our system applies program analysistechniques to the application source code to determine pieces of application logic thatshould be moved to the database server to improve performance. This frees the developerfrom the need to understand the intricacies of database operations or learn a newprogramming language for stored procedures. In addition; by dynamically monitoringresource utilization on the database server; Pyxis can migrate computation betweenapplication and database in response to workload changes. Our previous experiments haveshown that Pyxis can decrease latency up to 3x for transactional applications; and improvethroughput up to 1.7 x when compared to a standard implementation using embedded …,Proceedings of the 2013 ACM SIGMOD International Conference on Management of Data,2013,5
Sensor based monitoring of social networks,*,A method and system for detecting and monitoring discrete interactions within a physicalsocial network is provided. The system and method detects attributes associated with humancommunication activities and distinguishes them from other concurrently detected activitiesin order to identify discrete interactions that are in turn transmitted across a network having alimited data rate. Generally; in its simplest form a plurality of wireless sensors are deployedacross a cross-section of people of interest. Once deployed; the wireless sensors establishan ad-hoc network that transmits a small amount of data relating to the each of the discreteindividuals bearing a sensor. The collected data is analyzed through the application of rulesset forth in a Bayesian belief network to make a determination regarding the probability thatan actual interaction between two individuals bearing sensors in fact occurred.,*,2010,5
Representing and Querying Regression Models in an RDBMS,Arvind Thiagarajan; Samuel Madden,ABSTRACT Curve fitting is a widely employed and useful modeling tool in several financial;scientific; engineering and data mining applications; as well as in applications like sensornetworks that need to tolerate missing and/or noisy data. These applications need to both fitfunctions to their data using regression; and pose relational-style queries over thesefunctional models. Unfortunately; existing DBMSs are ill suited for this task because they donot include support for creating; representing and querying this functional data short ofbruteforce discretization of the functions into a collection of tuples. In this paper; we describeFunctionDB; a novel DBMS that treats functions output by regression as first-class citizensthat can be queried and manipulated like traditional relations. The key contributions of thispaper are a simple; compact; algebraic representation for regression models in a DBMS …,*,2007,5
Intel Berkeley research lab data [OL],S Madden,*,*,2006,5
A signal oriented stream processing system for pipeline monitoring,Timur Tokmouline,In this thesis; we develop SignalDB; a framework for composing signal processingapplications from primitive stream and signal processing operators. SignalDB allows theuser to focus on the signal processing task and avoid needlessly spending time on learninga particular application programming interface (API). We use SignalDB to express acousticand pressure transient methods for water pipeline monitoring as query plans consisting ofsignal processing operators.,*,2006,5
Towards visualization recommendation systems,Manasi Vartak; Silu Huang; Tarique Siddiqui; Samuel Madden; Aditya Parameswaran,Abstract Data visualization is often used as the first step while performing a variety ofanalytical tasks. With the advent of large; high-dimensional datasets and significant interestin data science; there is a need for tools that can support rapid visual analysis. In this paperwe describe our vision for a new class of visualization systems; namely visualizationrecommendation systems; that can automatically identify and interactively recommendvisualizations relevant to an analytical task. We detail the key requirements and designconsiderations for a visualization recommendation system. We also identify a number ofchallenges in realizing this vision and describe some approaches to address them.,ACM SIGMOD Record,2017,4
AdaptDB: adaptive partitioning for distributed joins,Yi Lu; Anil Shanbhag; Alekh Jindal; Samuel Madden,Abstract Big data analytics often involves complex join queries over two or more tables.Such join processing is expensive in a distributed setting both because large amounts ofdata must be read from disk; and because of data shuffling across the network. Manytechniques based on data partitioning have been proposed to reduce the amount of datathat must be accessed; often focusing on finding the best partitioning scheme for a particularworkload; rather than adapting to changes in the workload over time. In this paper; wepresent AdaptDB; an adaptive storage manager for analytical database workloads in adistributed setting. It works by partitioning datasets across a cluster and incrementallyrefining data partitioning as queries are run. AdaptDB introduces a novel hyper-join thatavoids expensive data shuffling by identifying storage blocks of the joining tables that …,Proceedings of the VLDB Endowment,2017,4
Extra-sensory perception for wireless networks,Lenin Ravindranath; Calvin Newport; Hari Balakrishnan; Samuel Madden,Abstract Commodity smartphones and tablet devices now come equipped with a variety ofsensors; including accelerometers; multiple positioning sensors; magnetic compasses; andinertial sensors (gyros). In this paper; we posit that these sensors can be profitably used toimprove the performance of wireless network protocols running on these mobile devices;and introduce the idea of using external sensor hints for this purpose. We focus on mobilityhints; including the device's state of motion; speed; direction of movement; and position. Weoutline how these hints can be used to: increase throughput by adapting bit rate selection tothe state of movement; reduce the bandwidth required for estimating link deliveryprobabilities; improve the connectivity of routes in vehicular mesh networks usingdirectionality hints; and enable access points to tailor the management of clients to their …,Proceedings of the 9th ACM SIGCOMM Workshop on Hot Topics in Networks,2010,4
Demonstration of the trajstore system,Eugene Wu; Philippe Cudre-Mauroux; Samuel Madden,Abstract The proliferation of GPS devices has led to a substantial interest in location basedservices. In particular; modern vehicles can generate an incredible amount of drive data.However; current storage systems are not optimized for storing and querying such largespatial-temporal data sets. In this demonstration; we show the performance of the TrajStoresystem; a dynamic storage system optimized for quickly accessing data in a particular spatial-temporal region. In particular; TrajStore uses a novel adaptive indexing technique thatdynamically adjusts itself to co-locate spatially close trajectories on disk; as well as anumber of compression techniques in the storage layer that significantly reduce access timefor a given index cell. In this demonstration; we will store a set of real world taxi cab drivetraces in TrajStore; and users will be able to query the data through a map based …,Proceedings of the VLDB Endowment,2009,4
Design and evaluation of a benchmark for main memory transaction processing systems,Elizabeth G Reid,We designed a diverse collection of benchmarks for Main Memory Database Systems(MMDBs) to validate and compare entries in a programming contest. Each entrant to thecontest programmed an indexing system optimized for multicore multithread execution. Thecontest framework provided an API for the contestants; and benchmarked their submissions.This thesis describes the test goals; the API; and the test environment. It documents thewebsite used by the contestants; describes the general nature of the tests run on eachsubmission; and summarizes the results for each submission that was able to complete thetests.,*,2009,4
Sensor networks for social networks,Michael Patrick Farry,This thesis outlines the development of software that makes use of Bayesian belief networksand signal processing techniques to make meaningful inferences about real-worldphenomena using data obtained from sensor networks. The effectiveness of the software isvalidated by applying it to the problem of detecting face-to-face social interactions betweengroups of people; given data readings from sensors that record light; temperature;acceleration; sound; and proximity. This application represents a novel method for socialnetwork construction which is potentially more accurate and less intrusive than traditionalmethods; but also more meaningful than newer methods that analyze digitally mediatedcommunication.,*,2006,4
Availability-consistency trade-offs in a fault-tolerant stream processing system,Magdalena Balazinska; Hari Balakrishnan; Samuel Madden; Mike Stonebraker,processing. In contrast to previous techniques that handlenode failures; our approach alsotolerates network failuresand network partitions. The approach is based on a principledtrade-off between consistency and availability in theface of failure; that (1) ensures that all data onan inputstream is processed within a specified time threshold; but (2) reduces the impact offailures by limiting if possible thenumber of results produced based on partially availableinputdata; and (3) corrects these results when failures heal. Our approach is well-suited forapplications such as environmentmonitoring; where high availability and Â real-timeÂresponse is preferable to perfect answers. Our approach uses replication and guaranteesthat all processingreplicas achieve state consistency; both in the absenceof failures andafter a failure heals. We achieve consistencyin the former case by defining a data …,*,2004,4
Weld: Rethinking the Interface Between Data-Intensive Applications,Shoumik Palkar; James Thomas; Deepak Narayanan; Anil Shanbhag; Rahul Palamuttam; Holger Pirk; Malte Schwarzkopf; Saman Amarasinghe; Samuel Madden; Matei Zaharia,Abstract: Data analytics applications combine multiple functions from different libraries andframeworks. Even when each function is optimized in isolation; the performance of thecombined application can be an order of magnitude below hardware limits due to extensivedata movement across these functions. To address this problem; we propose Weld; a newinterface between data-intensive libraries that can optimize across disjoint libraries andfunctions. Weld exposes a lazily-evaluated API where diverse functions can submit theircomputations in a simple but general intermediate representation that captures their data-parallel structure. It then optimizes data movement across these functions and emits efficientcode for diverse hardware. Weld can be integrated into existing frameworks such as Spark;TensorFlow; Pandas and NumPy without changing their user-facing APIs. We …,arXiv preprint arXiv:1709.06416,2017,3
A moeba: a shape changing storage system for big data,Anil Shanbhag; Alekh Jindal; Yi Lu; Samuel Madden,Abstract Data partitioning significantly improves the query performance in distributeddatabase systems. A large number of techniques have been proposed to efficiently partitiona dataset for a given query workload. However; many modern analytic applications involvead-hoc or exploratory analysis where users do not have a representative query workloadupfront. Furthermore; workloads change over time as businesses evolve or as analysts gainbetter understanding of their data. Static workload-based data partitioning techniques aretherefore not suitable for such settings. In this paper; we describe the demonstration of Amoeba; a distributed storage system which uses adaptive multi-attribute data partitioning toefficiently support ad-hoc as well as recurring queries. A moeba applies a robust partitioningalgorithm such that ad-hoc queries on all attributes have similar performance gains …,Proceedings of the VLDB Endowment,2016,3
Towards large-scale data discovery: position paper,Raul Castro Fernandez; Ziawasch Abedjan; Samuel Madden; Michael Stonebraker,Abstract With thousands of data sources spread across multiple databases and data lakes;modern organizations face a data discovery challenge. Analysts spend more time findingrelevant data to answer the questions at hand than analyzing it. In this paper we introduce adata discovery system that facilitates locating relevant data among thousands of datasources. We represent data sources succinctly through signatures; and then create searchpaths that permit quick execution of a set of data discovery primitives used for findingrelevant data. We have built a prototype that is being used to solve data discoverychallenges of two big organizations.,Proceedings of the Third International Workshop on Exploratory Search in Databases and the Web,2016,3
By their fruits shall ye know them: A Data Analyst's Perspective on Massively Parallel System Design,Holger Pirk; Sam Madden; Mike Stonebraker,Abstract Increasingly parallel systems promise a remedy for the current stagnation of single-core performance. However; the battle to find the most appropriate architecture for theresulting massively parallel systems is still ongoing. Currently; there are two activecontenders: Massively Parallel Single Instruction Multiple Threads (SIMT) systems such asGPGPUs and Many Core Single Instruction Multiple Data (SIMD) systems such as Intel'sXeon Phi. While the former is more versatile; the latter is an efficient; time-tested technologywith a clear migration path. In this study; we provide a data management perspective to thedebate: we study the implementation and performance of a set of common datamanagement operations on an SIMT device (an Nvidia GTX 780) and compare it to a ManyCore SIMD system (an Intel Xeon Phi). We interpret the results to pinpoint architectural …,Proceedings of the 11th International Workshop on Data Management on New Hardware,2015,3
SeeDB: supporting visual analytics with data-driven recommendations,Manasi Vartak; Samuel Madden; Aditya Parameswaran; Neoklis Polyzotis,ABSTRACT Data analysts often build visualizations as the first step in their analyticalworkflow. However; when working with high-dimensional datasets; identifying visualizationsthat show relevant or desired trends in data can be laborious. We propose SEEDB; avisualization recommendation engine to facilitate fast visual analysis: given a subset of datato be studied; SEEDB intelligently explores the space of visualizations; evaluates promisingvisualizations for trends; and recommends those it deems most “useful” or “interesting”. Thetwo major obstacles in recommending interesting visualizations are (a) scale: dealing with alarge number of candidate visualizations and evaluating all of them in parallel; whileresponding within interactive time scales; and (b) utility: identifying an appropriate metric forassessing interestingness of visualizations. For the former; SEEDB introduces pruning …,*,2015,3
Optimizing index deployment order for evolving OLAP,Hideaki Kimura; Carleton Coffrin; Alexander Rasin; Stanley B Zdonik,Abstract Many database applications deploy hundreds or thousands of indexes to speed upquery execution. Despite a plethora of prior work on index selection; designing anddeploying indexes remains a difficult task for database administrators. First; real-worldbusinesses often require online index deployment; and the traditional off-line approach toindex selection ignores intermediate workload performance during index deployment.Second; recent work on on-line index selection does not address effects of complexinteractions that manifest during index deployment. In this paper; we propose a newapproach that incorporates transitional design performance into the overall problem ofphysical database design. We call our approach Incremental Database Design. As the firststep in this direction; we study the problem of ordering index deployment. The benefits of …,Proceedings of the 15th International Conference on Extending Database Technology,2012,3
Guest Editors' Introduction: Internet-Scale Data Management,Sam Madden; Maarten van Steen,General consensus is that data volumes available across the Internet are growing at atremendous pace. Well-known solutions for data management have reached their scalabilitylimits; requiring new and innovative alternatives. This special issue gives a snapshot ofsome of those alternatives; with articles that address relaxed data consistency; dataheterogeneity; NoSQL databases; continuous aggregation queries; and handling of largedata sets in Web services.,IEEE Internet Computing,2012,3
Automatically generating interesting events with lifejoin,Alvin Cheung; Arvind Thiagarajan; Samuel Madden,Abstract This demo will showcase LifeJoin; a system that collects raw sensor data fromphones and laptop computers to generate interesting events. Given the raw sensor data;LifeJoin implements a number of activity recognition algorithms to generate higher-levelevents. Furthermore; it uses supervised learning techniques to learn from users' feedback togenerate only events of interest. In this demo; the audience will get to interact with theLifeJoin system and be able to examine the internals of LifeJoin.,Proceedings of the 9th ACM Conference on Embedded Networked Sensor Systems,2011,3
No bits left behind,Eugene Wu; Carlo Curino; Samuel Madden,One of the key tenets of database system design is making efficient use of storage andmemory resources. However; existing database system implementations are actuallyextremely wasteful of such resources; for example; most systems leave a great deal of emptyspace in tuples; index pages; and data pages; and spend many CPU cycles reading coldrecords from disk that are never used. In this paper; we identify a number of such sources ofwaste; and present a series of techniques that limit this waste (eg; forcing better memorylocality for hot data and using empty space in index pages to cache popular tuples) withoutsubstantially complicating interfaces or system design. We show that these techniqueseffectively reduce memory requirements for real scenarios from the Wikipedia database (byup to 17.8×) while increasing query performance (by up to 8×).,*,2011,3
PCP: the personal commute portal,Hari Balakrishnan; Nikolaus Correll; Jakob Erikkson; Sejoon Lim; Samuel Madden; Daniela Rus,Hari Balakrishnan; Nikolaus Correll; Jakob Erikkson; Sejoon Lim; Samuel Madden; and DanielaRus MIT Computer Science and Artificial Intelligence Laboratory The Stata Center; 32 VassarSt.; Cambridge; MA 02139 {hari;nikolaus;jakob;sjlim;madden;rus}@csail.mit.edu … ABSTRACTThe Personal Commute Portal (PCP) is a Web-based traffic infor- mation system that providesa good driving direction and person- alized route recommendation using historical and real-timetraffic data obtained by a vehicular sensor network … Categories and Subject DescriptorsH.4 [Information Systems Applications]: Miscellaneous … 1. OVERVIEW Traffic congestion isa global problem that results in tremendous personal and social costs. Drivers go along familiarroutes every day without understanding their travel costs. Although several In- ternet servicesprovide driving directions; their level of information about the roads is sparse and not …,Proceedings of the 6th ACM conference on Embedded network sensor systems,2008,3
BlendDB: blending table layouts to support efficient browsing of relational databases,Adam Marcus,The physical implementation of most relational databases follows their logical description;where each relation is stored in its own file or collection of files on disk. Such animplementation is good for queries that filter or aggregate large portions of a single table;and provides reasonable performance for queries that join many records from one table toanother. It is much less ideal; however; for join queries that follow paths from a small numberof tuples in one table to small collections of tuples in other tables to accumulate facts about arelated collection of objects (eg; co-authors of a particular author in a publicationsdatabase); since answering such queries involves one or more random I/Os per tableinvolved in the path. If the primary workload of a database consists of many such pathqueries; as is likely to be the case when supporting browsing-oriented applications …,*,2008,3
Data management in sensor networks,Samuel Madden,Abstract This tutorial will cover recent topics in data management for sensor networks;focusing in particular on high-level systems and languages for querying stored andstreaming data in such networks. We will begin with a survey of language proposals;including TinyDB; Cougar; Regions; and other more recent work; and will then examine arange of implementation issues that arise in such systems; including issues related to powerefficiency; time synchronization; data collection and dissemination; fault-tolerance; and statemanagement. After attending the tutorial; audience members should have a goodunderstanding of the various systems in this space as well as an awareness of the technicalissues that make building such systems difficult.,Proceedings of the Third European conference on Wireless Sensor Networks,2006,3
CarTel,B Hull; V Bychkovsky; Y Zhang; K Chen; M Goraczko; A Miu; E Shih; H Balakrishnan; S Madden,*,Proceedings of the 4th international conference on Embedded networked sensor systems-SenSys’ 06,2006,3
TinySchema: Creating attributes and commands in TinyOS,Wei Hong; Sam Madden,*,*,2006,3
TinySchema: Managing Attributes; Commands and Events in TinyOS,Wei Hong; Sam Madden,TinySchema is a collection of TinyOS components that manages a small respository ofnamed attributes; commands and events that can be easily queried; invoked or signaledfrom inside or outside a mote network. A TinySchema attribute is much like a column in atraditional database system. It has a name and a type. In addition; TinySchema allows you toassociate arbitrary TinyOS code to each attribute for getting and setting the attribute value.Once an attribute is created; it can be retrieved or updated through a unified interfaceprovided by TinySchema. Tiny DB (see TinyDB document); the in-network query processingsystem for TinyOS; is one of the applications built on top of this interface. You can also buildyour own application for manipulating attributes based on the interfaces provided byTinySchema. Typically; there are three classes of attributes:,*,2003,3
TOADS: A two-dimensional open-ended architectural database system,Samuel Madden; Thomas E von Wiegand,The TOADS system is an innovative tool for building interior-space virtual environments(VEs) in two dimensions. Existing VE design tools typically operate in three dimensions;which makes it difficult to manipulate objects on the inherently two-dimensional computerscreen. TOADS allows nearly the same functionality as those three-dimensional systems inan easy-to-use; two-dimensional environment. Users edit and enhance DXF floorplans withheight and texture information. The software includes an inference engine that automaticallyidentifies doors in the floorplan and generates openable polygons in the final environment. Italso includes a sophisticated mechanism for embedding complex textures; such astransparent windows; at arbitrary heights in wall polygons. The entire interface is integratedwith software that drives a custom texture-acquisition device. This device consists of a …,Presence,2001,3
Exploring big volume sensor data with Vroom,Oscar Moll; Aaron Zalewski; Sudeep Pillai; Sam Madden; Michael Stonebraker; Vijay Gadepally,Abstract State of the art sensors within a single autonomous vehicle (AV) can produce videoand LIDAR data at rates greater than 30 GB/hour. Unsurprisingly; even small AV researchteams can accumulate tens of terabytes of sensor data from multiple trips and multiplevehicles. AV practitioners would like to extract information about specific locations or specificsituations for further study; but are often unable to. Queries over AV sensor data are differentfrom generic analytics or spatial queries because they demand reasoning about fields ofview as well as heavy computation to extract features from scenes. In this article and demowe present Vroom; a system for ad-hoc queries over AV sensor databases. Vroom combinesdomain specific properties of AV datasets with selective indexing and multi-queryoptimization to address challenges posed by AV sensor data.,Proceedings of the VLDB Endowment,2017,2
Version 0.1 of the bigdawg polystore system,Vijay Gadepally; Kyle OBrien; Adam Dziedzic; Aaron Elmore; Jeremy Kepner; Samuel Madden; Tim Mattson; Jennie Rogers; Zuohao She; Michael Stonebraker,Abstract: A polystore system is a database management system (DBMS) composed ofintegrated heterogeneous database engines and multiple programming languages. Bymatching data to the storage engine best suited to its needs; complex analytics run fasterand flexible storage choices helps improve data organization. BigDAWG (Big Data WorkingGroup) is our reference implementation of a polystore system. In this paper; we describe thecurrent BigDAWG software release which supports PostgreSQL; Accumulo and SciDB. Wedescribe the overall architecture; API and initial results of applying BigDAWG to the MIMIC IImedical dataset.,arXiv preprint arXiv:1707.00721,2017,2
Speedy browsing and sampling with needletail,Albert Kim; Liqi Xu; Tarique Siddiqui; Silu Huang; Samuel Madden; Aditya Parameswaran,ABSTRACT Exploratory data analysis often involves repeatedly browsing small samples ofrecords that satisfy certain ad-hoc predicates; to form and test hypotheses; identifycorrelations; or make inferences. Unfortunately; existing database systems are not optimizedfor queries with a LIMIT clause—operating instead in an all-or-nothing manner. Whileworkload aware caching; indexing; or precomputation schemes may appear promisingremedies; they do not apply in an exploratory setting where the queries are ad-hoc andunpredictable. In this paper; we propose a fast sampling engine; called NEEDLETAIL; aimedat letting analysts browse a small sample of the query results on large datasets as quickly aspossible; independent of the overall size of the result set. NEEDLETAIL introduces densitymaps; a lightweight in-memory indexing structure; and a set of efficient algorithms (with …,CoRR,2016,2
Telematics using personal mobile devices,*,An approach to telematics using mobile devices provides battery-efficient trajectory andmileage inference from inaccurate and intermittent location data. Accurate trajectories ofhow users or vehicles move in the physical world are formed by processing raw positionestimates obtained from noisy; inaccurate; and error-prone position sensors on mobiledevices; where the position data may also arrive intermittently with long time gaps. Thetrajectory is formed using the process of map matching; which determines the trajectory on amap that best explains the sequence of position observations.,*,2015,2
Interactive data analytics: the new frontier,Samuel Madden,Abstract Data analytics often involves data exploration; where a data set is repeatedlyanalyzed to understand root causes; find patterns; or extract insights. Such analysis isfrequently bottlenecked by the underlying data processing system; as analysts wait for theirqueries to complete against a complex multilayered software stack. In this talk; I'll describesome exploratory analytics applications we've build in the MIT database group over the pastfew years; and will then describe some of the challenges and opportunities that arise whenbuilding more efficient data exploration systems that will allow these applications to becometruly interactive; even when processing billions of data points.,Proceedings of the Sixth ACM Symposium on Cloud Computing,2015,2
The bigdawg architecture and reference implementation,Jennie Duggan; Aaron Elmore; Tim Kraska; Sam Madden; Tim Mattson; Michael Stonebraker,ABSTRACT This paper presents the reference implementation of a new architecture forfuture “Big Data” applications. Such applications require “big analytics” as one might expect;but they also require real-time streaming support; real-time analytics; data visualization; andcross-storage queries. We are guided by the principle “one size does not fit all”[7]; and webuild on top of three storage engines; each designed for specialized use cases. In addition;we demonstrate novel support for querying across multiple storage engines as well aspioneering solutions to data visualization. In the remainder of this short paper; we describethe first of three BigDawg reference implementations; Bulldog. In the next two years weexpect to follow with Pitbull and Rottweiler releases.,New England Database Day,2015,2
Dirty salt velocity model building with constrained iterative tomography: Methodology and application,Hans Kristian Helgesen; Jun Tang; Jinjun Liu; Antoun Salama; Randolph Pepper; Sam Madden; Marta Woodward; Anna Klebleeva; Eric Frugier Dorrington; Amr EL Sabaa; Can Evren Yarman; Aimé Fournier; Yi Yang; Konstantin S Osypov,Summary Subsalt imaging has been a challenge for Gulf of Mexico (GoM) exploration;mostly due to the complexity of salt geometry and high salt-sediment velocity contrast. Inaddition to these; the presence of inclusions within the salt; also referred to as dirty salt;presents an additional significant challenge in subsalt imaging. Following a systematic studywith synthetic datasets; we propose a new method for automatically determining the dirty saltgeometry; and a further consolidated constrained iterative dirty salt velocity model buildingflow. We applied this workflow on a real GoM dataset and demonstrate its effectiveness bypresenting an improved subsalt image.,2013 SEG Annual Meeting,2013,2
Efficient storage of versioned matrices,Adam B Seering,Versioned-matrix storage is increasingly important in scientific applications. Variouscomputer-based scientific research; from astronomy observations to weather predictions tomechanical finite-element analyses; results in the generation of large matrices that must bestored and retrieved. Such matrices are often versioned; an initial matrix is stored; then asubsequent matrix based on the first is produced; then another subsequent matrix after that.For large databases of matrices; available disk storage can be a substantial constraint. Ipropose a framework and programming interface for storing such versioned matrices; andconsider a variety of intra-matrix and inter-matrix approaches to data storage andcompression; taking into account disk-space usage; performance for inserting data; andperformance for retrieving data from the database. For inter-matrix" delta" compression; I …,*,2011,2
Traffic delay prediction from historical observations,Paresh Malalur,Road traffic congestion is one of the biggest frustrations for the daily commuter. By improvingthe currently available travel estimates; one can hope to save time; fuel and the environmentby avoiding traffic jams. Before one can predict the best route for a user to take; one mustfirst be able to accurately predict future travel times. In this thesis; we develop a classification-based technique to extract information from historical traffic data to help improve delayestimates for road segments. Our techniques are able to reduce the traffic delay predictionerror rate from over 20% to less than 10%. We were hence able to show that by usinghistorical information; one can drastically increase the accuracy of traffic delay prediction.The algorithm is designed to enable delay prediction on a per-segment basis in order toenable the use of simple routing schemes to solve the bigger problem of predicting best …,*,2011,2
A Demonstration of HYRISE—A Main Memory Hybrid Storage Engine,Martin Grund; Philippe Cudre-Mauroux; Samuel Madden,ABSTRACT We propose to demonstrate HYRISE; a main memory hybrid database system;which automatically partitions tables into vertical partitions consisting of variable numbers ofcolumns based on access patterns to each table. Using an accurate model of cache misses;HYRISE is able to predict the performance of different partitionings; and to automaticallyselect the best partitions using an automated database partitioning algorithm. Ourdemonstration will show the results of the physical partitioning based on different queryworkloads; allowing demo attendees to visualize; fine-tune; and modify the partitioning usinga GUI. It will then show how the various physical designs affect the query plans and theperformance of the database as a whole. Attendees can thus experiment with variousphysical models; and can grasp the potential of hybrid partitionings; which achieve a 20 …,Proceedings of the VLDB Endowment,2011,2
Relational cloud: The case for a database service,Eugene Wu; Samuel Madden; Yang Zhang; Evan Jones; Carlo Curino,In this paper; we make the case for â databases as a serviceâ (DaaS); with two targetscenarios in mind:(i) consolidation of data management functionality for large organizationsand (ii) outsourcing data management to a cloud-based service provider for small/mediumorganizations. We analyze the many challenges to be faced; and discuss the design of adatabase service we are building; called Relational Cloud. The system has been designedfrom scratch and combines many recent advances and novel solutions. The prototype wepresent exploits multiple dedicated storage engines; provides high-availability viatransparent replication; supports automatic workload partitioning and live data migration;and provides serializable distributed transactions. While the system is still under activedevelopment; we are able to present promising initial results that showcase the key …,*,2010,2
A file system for accessing mysql tables as csv files,Nizameddin Ordulu,In this thesis; we describe the design and implementation of a userspace file system thatrepresents MySQL tables as comma-separated values (CSV) files. The users can accessand modify the data through both the file system and MySQL's query interface. In order totransform read and write operations to SQL queries; we maintain a reverse index from fileoffsets to line numbers. Changes to the database outside of the file system are reflected onthe file system by means of MySQL's master-slave replication feature. We evaluate oursystem by comparing its performance to a regular file system's performance using popularcommand line tools (grep; sed; awk) and user applications (OpenOffice. org spreadsheets).The choice of the database for this system was MySQL because of its popularity and theavailability of its source code; however; the same ideas can be applied to any relational …,*,2010,2
iNav: A hybrid approach to WiFi localization and tracking of mobile devices,Lev Popov,This thesis presents iNav-a hybrid system for 802.11-based localization targeted at low-power mobile devices. WiFi localization enables numerous location-based services andapplications without requiring a separate GPS module; thus offering device cost and powerconsumption savings. iNav is a WiFi localization system targeted at low-power mobiledevices; capable of utilizing multiple data sources to produce location estimates withaccuracy higher than that of pure WiFi estimates. iNav uses a stochastic location estimationalgorithm based on particle filters to integrate streams of WiFi access point observations and3-axis accelerometer data. The system is tailored towards localization of vehicles and relieson a road network map to increase localization accuracy. iNav is designed with low-powerdevices in mind; and is capable of computing real-time location estimates on embedded …,*,2008,2
Scorpion,Eugene Wu; Samuel Madden,Q: Why the average temperature at 12PM and 1PM are unexpectedly high? A: The hightemperature caused by sensors near windows that heat up under the sun around noon andanother sensor running out of energy that starts producing erroneous readings.• MedicalCost Analysis: Amongst a population of cancer patients; the top 15% of patients by costrepresented more than 50% of the total dollars spent. Q: Were these patients significantlysicker? Did they have significantly better or worse outcomes than the median-cost patient. A:Small number of doctors were over-prescribing these procedures; which were presumablynot necessary because the outcomes didn't improve.,*,2005,2
A robust partitioning scheme for ad-hoc query workloads,Anil Shanbhag; Alekh Jindal; Samuel Madden; Jorge Quiane; Aaron J Elmore,Abstract Data partitioning is crucial to improving query performance several workload-basedpartitioning techniques have been proposed in database literature. However; many modernanalytic applications involve ad-hoc or exploratory analysis where users do not have arepresentative query workload a priori. Static workload-based data partitioning techniquesare therefore not suitable for such settings. In this paper; we propose Amoeba; a distributedstorage system that uses adaptive multi-attribute data partitioning to efficiently support ad-hoc as well as recurring queries. Amoeba requires zero set-up and tuning effort; allowinganalysts to get the benefits of partitioning without requiring an upfront query workload. Thekey idea is to build and maintain a partitioning tree on top of the dataset. The partitioningtree allows us to answer queries with predicates by reading a subset of the data. The …,Proceedings of the 2017 Symposium on Cloud Computing,2017,1
BigDAWG version 0.1,Vijay Gadepally; Kyle O'Brien; Adam Dziedzic; Aaron Elmore; Jeremy Kepner; Samuel Madden; Tim Mattson; Jennie Rogers; Zuohao She; Michael Stonebraker,A polystore system is a database management system composed of integratedheterogeneous database engines and multiple programming languages. By matching datato the storage engine best suited to its needs; complex analytics run faster and flexiblestorage choices helps improve data organization. BigDAWG (Big Data Working Group) isour prototype implementation of a polystore system. In this paper; we describe the currentBigDAWG software release which supports PostgreSQL; Accumulo and SciDB. We describethe overall architecture; API and initial results of applying BigDAWG to the MIMIC II medicaldataset.,High Performance Extreme Computing Conference (HPEC); 2017 IEEE,2017,1
Bigdawg polystore release and demonstration,Kyle OBrien; Vijay Gadepally; Jennie Duggan; Adam Dziedzic; Aaron Elmore; Jeremy Kepner; Samuel Madden; Tim Mattson; Zuohao She; Michael Stonebraker,Abstract: The Intel Science and Technology Center for Big Data is developing a referenceimplementation of a Polystore database. The BigDAWG (Big Data Working Group) systemsupports" many sizes" of database engines; multiple programming languages and complexanalytics for a variety of workloads. Our recent efforts include application of BigDAWG to anocean metagenomics problem and containerization of BigDAWG. We intend to release anopen source BigDAWG v1. 0 in the Spring of 2017. In this article; we will demonstrate anumber of polystore applications developed with oceanographic researchers at MIT anddescribe our forthcoming open source release of the BigDAWG system. Subjects: Databases(cs. DB) Cite as: arXiv: 1701.05799 [cs. DB](or arXiv: 1701.05799 v1 [cs. DB] for this version)Submission history From: Vijay Gadepally [view email][v1] Thu; 19 Jan 2017 00: 29: 31 …,arXiv preprint arXiv:1701.05799,2017,1
The BigDAWG Architecture,Vijay Gadepally; Jennie Duggan; Aaron Elmore; Jeremy Kepner; Samuel Madden; Tim Mattson; Michael Stonebraker,Abstract: BigDAWG is a polystore system designed to work on complex problems thatnaturally span across different processing or storage engines. BigDAWG provides anarchitecture that supports diverse database systems working with different data models;support for the competing notions of location transparency and semantic completeness viaislands of information and a middleware that provides a uniform multi-island interface. In thisarticle; we describe the current architecture of BigDAWG; its application on the MIMIC IImedical dataset; and our plans for the mechanics of cross-system queries. During thepresentation; we will also deliver a brief demonstration of the current version of BigDAWG.Subjects: Databases (cs. DB) Cite as: arXiv: 1602.08791 [cs. DB](or arXiv: 1602.08791 v1[cs. DB] for this version) Submission history From: Vijay Gadepally [view email][v1] Mon …,arXiv preprint arXiv:1602.08791,2016,1
Sensor Network Integration with Streaming Database Systems,Daniel Abadi; Samuel Madden; Wolfgang Lindner,Abstract Recent advances in computing technology have led to the production of a newclass of computing device: the wireless; battery powered; smart sensor. Traditional sensorsdeployed throughout buildings; labs; and equipment are passive devices that simplymodulate a voltage based on some environmental parameter. In contrast; these newsensors are active; full fledged computers; capable not only of sampling real worldphenomena but also filtering; sharing; and combining those sensor readings with each otherand nearby Internet-equipped endpoints. Over the past several years; we have designedand implemented a query processor for such sensor networks called TinyDB. TinyDB is adistributed query processor that runs on each of the nodes in a sensor network that isexplicitly designed to simplify many of the data collection applications described above …,*,2016,1
MacroBase: Analytic Monitoring for the Internet of Things,Peter Bailis; Edward Gan; Samuel Madden; Deepak Narayanan; Kexin Rong; Sahaana Suri,ABSTRACT An increasing proportion of data today is generated by automated processes;sensors; and devices—collectively; the Internet of Things (IoT). IoT applications' rising datavolume; demands for timesensitive analysis; and heterogeneity exacerbate the challenge ofidentifying and highlighting important trends in IoT deployments. In response; we presentMacroBase; a data analytics engine that performs statistically-informed analytic monitoringof IoT data streams by identifying deviations within streams and generating potentialexplanations for each. MacroBase is the first analytics engine to combine streaming outlierdetection and streaming explanation operators; allowing cross-layer optimizations thatdeliver order-of-magnitude speedups over existing; primarily non-streaming alternatives. Asa result; MacroBase can deliver accurate results at speeds of up to 2M events per second …,CoRR,2016,1
Mobile applications need targeted micro-updates,Alvin Cheung; Lenin Ravindranath; Eugene Wu; Samuel Madden; Hari Balakrishnan,Abstract Smart-phone applications (" apps") run across a wide range of environmentalconditions; locations; and hardware platforms. They are often subject to an array ofinteractions that are hard or impossible for developers to emulate or even anticipate duringtesting. Once an application is released; feedback obtained from users and from analyticsover usage and performance data result in further modifications. Many of these changes arerelatively small; and can often be parameterized.,Proceedings of the 4th Asia-Pacific Workshop on Systems,2013,1
Multi-Network Control Framework for Mobile Applications,Shuo Deng; Alvin Cheung; Sam Madden; Hari Balakrishnan,ABSTRACT Mobile phones now come equipped with an assortment of sensors capable ofgenerating data at high rates; as well as various wireless networks over which to transmitthis data. In this paper; we introduce the design for a multi-network control framework formobile applications. Our goal is to build a deployable framework that is compatible withcurrent network architectures. It enables mobile application developers to use multiplenetworks easily and expressively via a comprehensive set of APIs for them to express theirrequirements. We also show some initial results demonstrating potential networkperformance (throughput; delay; etc.) improvement this framework can bring to mobileapplications.,ACM MobiCom S3 Workshop,2013,1
Data In Context: Aiding News Consumers while Taming Dataspaces,Adam Marcus; Eugene Wu; Sam Madden,ABSTRACT We present MuckRaker; a tool that provides news consumers with datasets andvisualizations that contextualize facts and figures in the articles they read. MuckRaker takesadvantage of data integration techniques to identify matching datasets; and makes use ofdata and schema extraction algorithms to identify data points of interest in articles. Itpresents the output of these algorithms to users requesting additional context; and allowsusers to further refine these outputs. In doing so; MuckRaker creates a synergisticrelationship between news consumers and the database research community; providingtraining data to improve existing algorithms; and a grand challenge for the next generation ofdataspace management research.,DBCrowd 2013,2013,1
code in the air-simplifying tasking on smartphones,Lenin Ravindranath; Tiffany Yu-Han Chen; Somak Das; Raluca Ifrim; Hari Balakrishnan; Sam Madden,Abstract Smartphones now are equipped with a variety of sensors including inertial sensors(accelerometers and gyroscopes) and multiple position sensors (GPS; WiFi; and cellularradios). These powerful capabilities have made smartphones an attractive platform fortasking applications. Tasking applications are rapid developing mobile applications whichprocess data from multiple sensors continuously to determine user's context (such aslocation or activity) and take certain actions based on pre-defined conditions. Examples ofsuch applications include location-based reminders; notifying when friends are nearby;changing the ring-mode of a phone automatically depending on the location; automaticallytracking and storing movement tracks when driving; and inferring the number of stepswalked each day. However; today; developing tasking applications is non-trivial for two …,Proceedings of the 10th international conference on Mobile systems; applications; and services,2012,1
Bribecaster: documenting bribes through community participation,Manas Mittal; Wei Wu; Steve Rubin; Sam Madden; Björn Hartmann,Abstract Corruption is endemic in many emerging economies-many transactions of privatecitizens with government institutions require payment of bribes. While well known as ageneral phenomenon; specific data about the" bribe economy" are hard to come by. Butsuch data are needed for rational responses to corruption at the societal and individual level-to expose it; to know which offices to avoid; or to know how much to pay if other recourse isnot available. In response to a corruption survey of 102 Indian participants we aredeveloping Bribecaster; a mobile application that enables citizen collection and curation ofcorruption data. A key research question is how to create a system that has accurate datawhile simultaneously protecting users from repercussions of having their identities revealed.,Proceedings of the ACM 2012 conference on Computer Supported Cooperative Work Companion,2012,1
Improving Wireless Network Performance Using Sensor Hints,Hari Balakrishnan; Lenin Ravindranath; Calvin Newport; Samuel Madden,*,Proc. of USENIX NSDI,2011,1
Platform considerations in human computation,Adam Marcus; Eugene Wu; David R Karger; Samuel Madden; Robert C Miller,ABSTRACT With the recent growth of interest in human computation; the number ofcrowdsourcing platforms and corresponding workflows has been growing rapidly. Thispresents problems for both platform developers; who reimplement the same building blockswith each new platform; and human computation workflow developers; who must cope withthe increasing complexity of tasks that may span multiple platforms. In this paper; wedescribe two systems designed to alleviate these pain points. Qurk is a system that letsdevelopers describe workflows in a high-level declarative language; and whichautomatically optimizes the workflow across multiple platforms. Djurk is an open sourcehuman computation platform that is both usable out-of-the-box; and provides a feature-richstarting point for building new crowdsourcing platforms.,Workshop on crowdsourcing and human computation,2011,1
Stochastic Motion Planning and Applications to Trafﬁc,Sejoon Lim; Hari Balakrishnan; David Gifford; Samuel Madden; Daniela Rus,Abstract. This paper presents a stochastic motion planning algorithm and its application totrafﬁc navigation. The algorithm copes with the uncertainty of road trafﬁc conditions bystochastic modeling of travel delay on road networks. The algorithm determines pathsbetween two points that optimize a cost function of the delay probability distribution. It can beused to ﬁnd paths that maximize the probability of reaching a destination within a particulartravel deadline. For such problems; standard shortest-path algorithms don't work becausethe optimal substructure property doesn't hold. We evaluate our algorithm using bothsimulations and real-world drives; using delay data gathered from a set of taxis equippedwith GPS sensors and a wireless network. Our algorithm can be integrated into on-boardnavigation systems as well as route-ﬁnding Web sites; providing drivers with good paths …,Algorithmic Foundations of Robotics VIII: Selected Contributions of the Eighth International Workshop on the Algorithmic Foundations of Robotics,2010,1
Shinobi: Insert-aware partitioning and indexing techniques for skewed database workloads,Eugene Wu,Many data-intensive websites are characterized by a dataset that grows much faster than therate that users access the data and possibly high insertion rates. In such systems; thegrowing size of the dataset leads to a larger overhead for maintaining and accessingindexes even while the query workload becomes increasingly skewed. Additionally; thedatabase index update costs can be a non-trivial proportion of the overall system cost.Shinobi introduces a cost model that takes index update costs account; and proposesdatabase design algorithms that optimally partition tables and drop indexes from partitionsthat are not queried often; and that maintain these partitions as workloads change. We showa 60x performance improvement over traditionally indexed tables using a real-world queryworkload derived from a traffic monitoring application and over 8x improvement for a …,*,2010,1
Providing caching abstractions for web applications,Priya Gupta,Web-based applications are used by millions of users daily; and as a result a key challengefacing web application designers is scaling their applications to handle this load. A crucialcomponent of this challenge is scaling the data storage layer; especially for the newer classof social networking applications that have huge amounts of shared data. Caching is animportant scaling technique and is a critical part of the storage layer for such high-traffic webapplications. Usually; building caching mechanisms involves significant effort from theapplication developer to maintain and invalidate data in the cache. In this work we presentCacheGenie; a system which aims to make it easy for web application developers to buildcaching mechanisms in their applications. It achieves this by proposing high-level cachingabstractions for frequently observed query patterns in web applications. These …,*,2010,1
A hybrid data structure for dense keys in in-memory database systems,José Alberto Muñiz Navarro,This thesis presents a data structure which performs well for in-memory indexing of keys thatare unevenly distributed into clusters with a high density of keys. This pattern is prevalent; forexample; in systems that use tables with keys where one field is auto-incremented. Thesetypes of tables are widely used. The proposed data structure consists of a B+ Tree withintervals as keys; and arrays as values. Each array holds a cluster of values; while theclusters themselves are managed by the B+ Tree for space and cache efficiency. Using theH-Tree as an in-memory indexing structure for an implementation of the TPC-C benchmarksped up the transaction processing time by up to 50% compared to an implementationbased on B+ Trees; and showed even more dramatic performance gains in the presence offew and large clusters of data.,*,2010,1
How best to build web-scale data managers?,Philip A Bernstein; Daniel J Abadi; Michael J Cafarella; Joseph M Hellerstein; Donald Kossmann; Samuel Madden,1. PANEL OVERVIEW Many of the largest database-driven web sites use custom web- scaledata managers (WDMs). On the surface; these WDMs are being applied to problems that arewell-suited for relational database systems. Some examples are the following: • Map-Reduce[5]; Hadoop [7]; and Dryad [9] are used to process queries on large data sets using sequentialscan and aggregation. Hive [8] is a data warehouse built on Hadoop. • Google's Bigtable [3] isused to store a replicated table of rows of semi-structured data. • Amazon's Dynamo [6] is usedto store partitioned; replicated databases of key-value pairs. Cassandra [2] is similar. • Objectcaching systems are used instead of a persistent store; such as memcached [10]; Oracle'sCoherence; and Microsoft's Velocity project … These WDMs have challenging requirementsthat are not met by current relational database products. They need to scale out to …,Proceedings of the VLDB Endowment,2009,1
In-network query processing,Samuel Madden,An example of index oriented towards human navigation is the web directory. In such anindex; links to sites are organized into hierarchical categories; according to the sites'contents. In web directories; normally the tasks of collecting and categorizing pages arecarried out under supervision of human editors. An example of index not oriented to humansis a hidden list of metadata. Metadata are data about data. As a mean of assisting a searchengine to locate content or an information entity; they can be used to describe that content orentity. While not visible to humans; this information can provide contextual clues to automaticalgorithms used by search engines.,Encyclopedia of Database Systems,2009,1
Declarative; Domain-Specific Languages-Elegant Simplicity or a Hammer in Search of a Nail?,Samuel Madden; Johannes Gehrke,I. PANEL DESCRIPTION Recent years have seen a proliferation in proposals for database-inspired declarative languages for a number of nondatabase domains; including sensornetworks [1; 3; 6]; network protocol specification [2]; event monitoring [5]; program analysis[4]; computer games [7]; and the design of three-tier applications [8]. The typical argumentput forth in these proposals is that a declarative language is simple and hides many of theugly details that are inherent in whatever domain is being addressed. For example; insensor networks; a declarative language might allow users to specify what data they wantfrom a collection of sensors without worrying about low-level details like power managementor network organization. For network protocols; a set of declarative rules can be used tospecify how routing decisions should be made; allowing the protocol designer to avoid …,Data Engineering; 2008. ICDE 2008. IEEE 24th International Conference on,2008,1
Zstream: a cost-based query processor for composite event detection,Yuan Mei,Composite (or Complex) event processing (CEP) systems search sequences of incomingprimitive events for occurrences of user-specified event patterns. Recently; they are gainingmore and more attention in a variety of areas due to their powerful and expressive querylanguage and performance potential. Sequentiality (temporal ordering) is the primary way inwhich CEP relates events to each other. Examples include tracing a car's movement in apredefined area (where a car moves through a series of places); detecting anomalies instock prices (where the rise and fall of the price of some stocks is monitored); detectingintrusion in network monitoring (where a specific sequence of malicious activities isdetected) or catching break points in debugging systems (where a sequence of functioncalls are made). But even searching for a simple sequence pattern involving only equality …,*,2008,1
Database-Style Aggregation in Sensor Networks,Samuel R Madden; David Culler; Michael J Franklin; Joseph M Hellerstein; Robert Szewczyk; Wei Hong,*,Demo. In 4th IEEE Workshop on Mobile Computing Systems and Applications (WMCSA); Callicoon; NY,2002,1
Weld: Rethinking the Interface Between Data-Intensive Libraries,Shoumik Palkar; James Thomas; Deepak Narayanan; Anil Shanbhag; Rahul Palamuttam; Holger Pirk; Malte Schwarzkopf; Saman Amarasinghe; Samuel Madden; Matei Zaharia,Abstract Data analytics applications combine multiple functions from different libraries andframeworks. Even when each function is optimized in isolation; the performance of thecombined application can be an order of magnitude below hardware limits due to extensivedata movement across these functions. To address this problem; we propose Weld; a newinterface between data-intensive libraries that can optimize across disjoint libraries andfunctions. Weld exposes a lazily-evaluated API where diverse functions can submit theircomputations in a simple but general intermediate representation that captures their data-parallel structure. It then optimizes data movement across these functions and emits efficientcode for diverse hardware. Weld can be integrated into existing frameworks such as Spark;TensorFlow; Pandas and NumPy without changing their user-facing APIs. We …,*,*,1
Seedb: towards automatic query result visualizations,Manasi Vartak; Samuel Madden; Aditya Parameswaran; Neoklis Polyzotis,ABSTRACT Data analysts operating on large volumes of data often rely on visualizations tointerpret the results of queries. However; finding the right visualization given a query ofinterest is a laborious and time-consuming task. We propose SEEDB; a visualizationrecommendation engine that aims to partially automate this task: given a query; SEEDBintelligently explores the space of all possible visualizations; evaluates promisingvisualizations; and automatically recommends the most “interesting” or “useful”visualizations to the analyst. We present two types of optimizations for SEEDB: sharing-based optimizations; that try to share as much computation as possible; and pruning-basedoptimizations; that try to avoid as much computation on not-so-useful visualizations aspossible; and show that these optimizations may be applied to implementations of …,*,*,1
Unthule: An Incremental Graph Construction Process for Robust Road Map Extraction from Aerial Images,Favyen Bastani; Songtao He; Sofiane Abbar; Mohammad Alizadeh; Hari Balakrishnan; Sanjay Chawla; David DeWitt; Sam Madden,Abstract: The availability of highly accurate maps has become crucial due to the increasingimportance of location-based mobile applications as well as autonomous vehicles.However; mapping roads is currently an expensive and human-intensive process. High-resolution aerial imagery provides a promising avenue to automatically infer a road network.Prior work uses convolutional neural networks (CNNs) to detect which pixels belong to aroad (segmentation); and then uses complex post-processing heuristics to infer graphconnectivity. We show that these segmentation methods have high error rates (poorprecision) because noisy CNN outputs are difficult to correct. We propose a novel approach;Unthule; to construct highly accurate road maps from aerial images. In contrast to prior work;Unthule uses an incremental search process guided by a CNN-based decision function to …,arXiv preprint arXiv:1802.03680,2018,*
Extracting Syntactic Patterns from Databases,Andrew Ilyas; Joana MF da Trinidade; Raul Castro Fernandez; Samuel Madden,Abstract: Many database columns contain string or numerical data that conforms to a pattern;such as phone numbers; dates; addresses; product identifiers; and employee ids. Thesepatterns are useful in a number of data processing applications; including understandingwhat a specific field represents when field names are ambiguous; identifying outlier values;and finding similar fields across data sets. One way to express such patterns would be tolearn regular expressions for each field in the database. Unfortunately; exist-ing techniqueson regular expression learning are slow; taking hundreds of seconds for columns of just afew thousand values. In contrast; we develop XSystem; an efficient method to learn patternsover database columns in significantly less time. We show that these patterns can not onlybe built quickly; but are expressive enough to capture a number of key applications …,arXiv preprint arXiv:1710.11528,2017,*
Synthesizing entity matching rules by examples,Rohit Singh; Venkata Vamsikrishna Meduri; Ahmed Elmagarmid; Samuel Madden; Paolo Papotti; Jorge-Arnulfo Quiané-Ruiz; Armando Solar-Lezama; Nan Tang,Abstract Entity matching (EM) is a critical part of data integration. We study how to synthesizeentity matching rules from positive-negative matching examples. The core of our solution isprogram synthesis; a powerful tool to automatically generate rules (or programs) that satisfya given high-level specification; via a predefined grammar. This grammar describes aGeneral Boolean Formula (GBF) that can include arbitrary attribute matching predicatescombined by conjunctions (∧); disjunctions (∨) and negations (¬); and is expressiveenough to model EM problems; from capturing arbitrary attribute combinations to handlingmissing attribute values. The rules in the form of GBF are more concise than traditional EMrules represented in Disjunctive Normal Form (DNF). Consequently; they are moreinterpretable than decision trees and other machine learning algorithms that output deep …,Proceedings of the VLDB Endowment,2017,*
Entity Consolidation: The Golden Record Problem,Dong Deng; Wenbo Tao; Ziawasch Abedjan; Ahmed Elmagarmid; Ihab F Ilyas; Samuel Madden; Mourad Ouzzani; Michael Stonebraker; Nan Tang,Abstract: Four key subprocesses in data integration are: data preparation (ie; transformingand cleaning data); schema integration (ie; lining up like attributes); entity resolution (ie;finding clusters of records that represent the same entity) and entity consolidation (ie;merging each cluster into a" golden record" which contains the canonical values for eachattribute). In real scenarios; the output of entity resolution typically contains multiple dataformats and different abbreviations for cell values; in addition to the omnipresent problem ofmissing data. These issues make entity consolidation challenging. In this paper; we studythe entity consolidation problem. Truth discovery systems can be used to solve this problem.They usually employ simplistic heuristics such as majority consensus (MC) or sourceauthority to determine the golden record. However; these techniques are not capable of …,arXiv preprint arXiv:1709.10436,2017,*
Query optimization for dynamic imputation,José Cambronero; John K Feser; Micah J Smith; Samuel Madden,Abstract Missing values are common in data analysis and present a usability challenge.Users are forced to pick between removing tuples with missing values or creating a cleanedversion of their data by applying a relatively expensive imputation strategy. Our system;ImputeDB; incorporates imputation into a cost-based query optimizer; performing necessaryimputations on-the-fly for each query. This allows users to immediately explore their data;while the system picks the optimal placement of imputation operations. We evaluate thisapproach on three real-world survey-based datasets. Our experiments show that our queryplans execute between 10 and 140 times faster than first imputing the base tables.Furthermore; we show that the query results from on-the-fly imputation differ from thetraditional base-table imputation approach by 0--8%. Finally; we show that while dropping …,Proceedings of the VLDB Endowment,2017,*
S ilk M oth: an efficient method for finding related sets with maximum matching constraints,Dong Deng; Albert Kim; Samuel Madden; Michael Stonebraker,Abstract Determining if two sets are related-that is; if they have similar values or if one setcontains the other--is an important problem with many applications in data cleaning; dataintegration; and information retrieval. For example; set relatedness can be a useful tool todiscover whether columns from two different databases are joinable; if enough of the valuesin the columns match; it may make sense to join them. A common metric is to measure therelatedness of two sets by treating the elements as vertices of a bipartite graph andcalculating the score of the maximum matching pairing between elements. Compared toother metrics which require exact matchings between elements; this metric uses a similarityfunction to compare elements between the two sets; making it robust to small dissimilaritiesin elements and more useful for real-world; dirty data. Unfortunately; the metric suffers …,Proceedings of the VLDB Endowment,2017,*
Triggering application action using non-standard controls,*,A lock button of a mobile device with an iOS operating system; to be used by a user to effectan action when the mobile device is in the locked state; is enabled for other functions byexecuting an application on the mobile device. When the mobile device is in a locked state;the application is in a dormant mode. The OS of the mobile device monitors for a change oflocation of the device and/or for the receipt of a short range wireless data signal. Upondetecting either; the operating system communicates this to the application which inresponse enters a background mode and monitors the on/off state of a screen of the mobiledevice. If the screen state changes at least twice within a predetermined period of time; theapplication effects an action; such as sending a panic signal.,*,2017,*
A Demo of the Data Civilizer System,Raul Castro Fernandez; Dong Deng; Essam Mansour; Abdulhakim A Qahtan; Wenbo Tao; Ziawasch Abedjan; Ahmed Elmagarmid; Ihab F Ilyas; Samuel Madden; Mourad Ouzzani; Michael Stonebraker; Nan Tang,Abstract Finding relevant data for a specific task from the numerous data sources availablein any organization is a daunting task. This is not only because of the number of possibledata sources where the data of interest resides; but also due to the data being scattered allover the enterprise and being typically dirty and inconsistent. In practice; data scientists areroutinely reporting that the majority (more than 80%) of their effort is spent finding; cleaning;integrating; and accessing data of interest to a task at hand. We propose to demonstrateDATA CIVILIZER to ease the pain faced in analyzing data" in the wild". DATA CIVILIZER isan end-to-end big data management system with components for data discovery; dataintegration and stitching; data cleaning; and querying data from a large variety of storageengines; running in large enterprises.,Proceedings of the 2017 ACM International Conference on Management of Data,2017,*
INGESTBASE: A Declarative Data Ingestion System,Alekh Jindal; Jorge-Arnulfo Quiane-Ruiz; Samuel Madden,Abstract: Big data applications have fast arriving data that must be quickly ingested. At thesame time; they have specific needs to preprocess and transform the data before it could beput to use. The current practice is to do these preparatory transformations once the data isalready ingested; however; this is expensive to run and cumbersome to manage. As a result;there is a need to push data preprocessing down to the ingestion itself. In this paper; wepresent a declarative data ingestion system; called INGESTBASE; to allow applicationdevelopers to plan and specify their data ingestion logic in a more systematic manner. Weintroduce the notion of ingestions plans; analogous to query plans; and present adeclarative ingestion language to help developers easily build sophisticated ingestionplans. INGESTBASE provides an extensible ingestion optimizer to rewrite and optimize …,arXiv preprint arXiv:1701.06093,2017,*
We Are Boring.,Samuel Madden,Despite all of these applications revolving around data; the database community appears tobe content to cede these domains to our AI colleagues. This is absurdly short-sighted; andjust as with the world-wide web; and (nearly) big data; we risk being an also-ran in the mostsignificant trend in computer science in the coming decade. These smart systems willchange the way we commute; work; and play; and the database community ought to bethinking about how we can contribute rather than sitting on the sidelines optimizing ourelephants.,CIDR,2017,*
Optimally Leveraging Density and Locality to Support LIMIT Queries,Albert Kim; Liqi Xu; Tarique Siddiqui; Silu Huang; Samuel Madden; Aditya Parameswaran,Abstract: Existing database systems are not optimized for queries with a LIMIT clause---operating instead in an all-or-nothing manner. In this paper; we propose a fast LIMIT queryevaluation engine; called NeedleTail; aimed at letting analysts browse a small sample of thequery results on large datasets as quickly as possible; independent of the overall size of theresult set. NeedleTail introduces density maps; a lightweight in-memory indexing structure;and a set of efficient algorithms (with desirable theoretical guarantees) to quickly locatepromising blocks; trading off locality and density. In settings where the samples are used tocompute aggregates; we extend techniques from survey sampling to mitigate the bias in oursamples. Our experimental results demonstrate that NeedleTail returns results 4x faster onHDDs and 9x faster on SSDs on average; while occupying up to 23x less memory than …,arXiv preprint arXiv:1611.04705,2016,*
Locality-Adaptive Parallel Hash Joins using Hardware Transactional Memory,Anil Shanbhag; Holger Pirk; Sam Madden,Abstract Previous work [1] has claimed that the best performing implementation of in-memory hash joins is based on (radix-) partitioning of the build-side input. Indeed; despitethe overhead of partitioning; the benefits from increased cache-locality and synchronizationfree parallelism in the build-phase outweigh the costs when the input data is randomlyordered. However; many datasets already exhibit significant spatial locality (ie; non-randomness) due to the way data items enter the database: through periodic ETL or trickleloaded in the form of transactions. In such cases; the first benefit of partitioning—increasedlocality—is largely irrelevant. In this paper; we demonstrate how hardware transactionalmemory (HTM) can render the other benefit; freedom from synchronization; irrelevant aswell. Specifically; using careful analysis and engineering; we develop an adaptive hash …,*,2016,*
What Makes a Good Physical plan?: Experiencing Hardware-Conscious Query Optimization with Candomblé,Holger Pirk; Oscar Moll; Sam Madden,Abstract Query optimization is hard and the current proliferation of" modern" hardware doesnothing to make it any easier. In addition; the tools that are commonly used by performanceengineers; such as compiler intrinsics; static analyzers or hardware performance countersare neither integrated with data management systems nor easy to learn. This fact makes it(unnecessarily) hard to educate engineers; to prototype and to optimize database queryplans for modern hardware. To address this problem; we developed a system calledCandomblé that lets database performance engineers interactively examine; optimize andevaluate query plans using a touch-based interface. Candomblé puts attendants in the placeof a physical query optimizer that has to rewrite a physical query plan into a better equivalentplan. Attendants experience the challenges when ad-hoc optimizing a physical plan for …,Proceedings of the 2016 International Conference on Management of Data,2016,*
Technical Perspective: Mesa takes data warehousing to new heights,Sam Madden,Leave it to Google to make business data processing—among the stodgiest topics in therather buttoned-up world of database systems—seem cool. The application here involvesproducing reports over Google's ads infrastructure: Google executives want to see howmany ads each Google property is serving; and how profitable they are; and Google'scustomers want to see how many users are clicking on their ads; how much they are paying;and so on.At a small scale; solving this problem is straightforward—new ad click and salesdata are appended to a database file as they are sent from the processing system; andcomputing the answer to a particular query over the data involves reading the contents of ("scanning") the data file to compute a running total of the records in the groups the user isinterested in. Making this perform at the scale of Google Ads; where billions of clicks …,Communications of the ACM,2016,*
Outlier Detection in Heterogeneous Datasets using Automatic Tuple Expansion,Zelda Mariet; Rachael Harding; Sam Madden,Rapidly developing areas of information technology are generating massive amounts ofdata. Human errors; sensor failures; and other unforeseen circumstances unfortunately tendto undermine the quality and consistency of these datasets by introducing outliers--datapoints that exhibit surprising behavior when compared to the rest of the data. Characterizing;locating; and in some cases eliminating these outliers offers interesting insight about thedata under scrutiny and reinforces the confidence that one may have in conclusions drawnfrom otherwise noisy datasets. In this paper; we describe a tuple expansion procedure whichreconstructs rich information from semantically poor SQL data types such as strings;integers; and floating point numbers. We then use this procedure as the foundation of a newuser-guided outlier detection framework; dBoost; which relies on inference and statistical …,*,2016,*
Optimizing WahooML; A Query Optimizer for the Spark Machine Learning Pipeline,Kathryn Siegel; Sam Madden; Manasi Vartak,*,*,2015,*
Foundations and Trends® in Databases,Daniel Abadi; Peter Boncz; Stavros Harizopoulos; Stratos Idreos; Samuel Madden,*,Foundations and Trends® in Databases,2013,*
NEEDLETAIL: A System for Browsing Queries,Albert Kim; Samuel Madden; Aditya Parameswaran,ABSTRACT Analysts performing data exploration often browse; ie; pose a query and thenexamine the details of a small number of the resulting records (independent of the size of thequery result). In a typical session; analysts will start with one browsing query; examine a fewof the resulting records; and then repeatedly issue new browsing queries by adding orremoving predicates from their previous queries until they eventually gain a betterunderstanding of the dataset. Unfortunately; traditional database systems are notengineered towards browsing: instead; these systems operate in an all-or-nothing manner;taking as long as it takes to return the entire set of results; however large it may be. To thisend; we demonstrate NEEDLETAIL; a database system tailored towards an alternativedatabase query interaction paradigm: browsing. NEEDLETAIL makes efficient use of …,Proceedings of the VLDB Endowment,2013,*
BFT-Practical Byzantine Fault Tolerance,Rodrigo Rodrigues; Barbara Liskov; Kathryn Chen; Moses Liskov; David Schultz; Barbara Liskov; David Schultz; Moses Liskov; Benjamin Wester; James Cowling; Edmund B Nightingale; Peter M Chen; Jason Flinn; Ben Vandiver; You Zhou; Ben Vandiver; Hari Balakrishnan; Sam Madden; James Cowling; Daniel Myers; Liuba Shrira; Rodrigo Rodrigues; Kathryn Chen; Tracey Ho; Ben Leong; Ralf Koetter; Muriel Médard; Michelle Effros; David Karger; Miguel Castro; Miguel Castro; Sarah Ahmed; Zheng Yang,This project is aimed at developing algorithms and implementation techniques to buildpractical Byzantine-fault-tolerant systems; that is; systems that work correctly even whensome components are faulty and exhibit arbitrary behavior. We believe that these systemswill be increasingly important in the future because malicious attacks and software errors areincreasingly common and can cause faulty nodes to exhibit arbitrary behavior.,IEEE Transactions on Dependable and Secure Computing,2012,*
Internet-Scale Data Management Guest Editors' Introduction,Sam Madden; Maarten van Steen,*,*,2012,*
6.033 Computer Systems Engineering: Spring 2012,THIS IS AN OPEN BOOK; OPEN NOTES; BUTDONTU LAPTOP,For true/false and yes/no questions; you will receive 0 points for no answer; and negative pointsfor an incorrect answer. We will round up the score for every numbered question to 0 if it's otherwisenegative (ie; you cannot get less than 0 on a numbered question) … If you find a questionambiguous; be sure to write down any assumptions you make. Be neat and legible. If wecan't understand your answer; we can't give you credit … Write your name in the spacebelow. Write your initials at the bottom of each page … THIS IS AN OPEN BOOK; OPENNOTES; OPEN LAPTOP QUIZ; BUT DON'T USE YOUR LAPTOP FOR COMMUNICATION WITHOTHERS. TURN YOUR NETWORK DEVICES OFF … 10:00 1. Butler/Eirik 2. Katrina/Pratiksha3. Arvind/Qian … 11:00 4. Butler/Eirik 5. Arvind/Qian 6. Katrina/Pratiksha … 1:00 7. Karen/Bryan9. Peter/Tiffany 12. Mark/Lixin … Do not write in the boxes below,Computer,2012,*
Current Research II,M Frans Kaashoek; Leslie Kaelbling; Fredo Durand; Regina Barzilay; Samuel Madden,*,MIT150 Symposia Series,2011,*
Look-up tables: the benefit of enabling fine-grained routing and load balancing,Aubrey Lynn Tatarowicz,Data volumes are exploding. It is essential to use multiple machines to store such largeamounts of data. To address this explosion; storage systems like databases need to bedistributed across many machines. Transactions that access a few tuples; often seen in webworkloads such as Twitter; do not run optimally using traditional partitioning schemes [25].Hence; increasing the number of machines often presents a bottleneck for workloads whereeach transaction accesses just a few tuples. Fine-grained partitioning can fix the scale outproblem introduced by simplistic partitioning schemes. In this thesis; I introduce a design of adistributed query execution system that handles fine-grained partitioning using look-uptables. I introduce look-up tables; which is a mapping from a tuple attribute to a tuple back-end location such that fine grained partitioning can be supported. I show through both …,*,2011,*
Hold the Accusations That Limit Scientific Innovation Response,Michael Stonebraker; Daniel Abadi; David J DeWitt; Sam Madden; Erik Paulson; Andrew Pavlo; Alexander Rasin,*,COMMUNICATIONS OF THE ACM,2010,*
Database architecture (R) evolution: New hardware vs. new software,Stavros Harizopoulos; Tassos Argyros; Peter A Boncz; Dan Dietterich; Samuel Madden; Florian M Waas,The last few years have been exciting for data management system designers. Theexplosion in user and enterprise data coupled with the availability of newer; cheaper; andmore capable hardware have lead system designers and researchers to rethink and; insome cases; reinvent the traditional DBMS architecture. In the space of data warehousingand analytics alone; more than a dozen new database product offerings have recentlyappeared; and dozens of research system papers are routinely published each year. Amongthese efforts; one school of thought promotes research on exploiting and anticipating newhardware (many-core CPUs [4; 7; 8]; GPUs [3]; FPGAs [5; 11]; flash SSDs [6]; other non-volatile storage technologies). Another school of thought focuses on software andalgorithmic issues (column and hybrid stores [1; 10; 13]; scale out architectures using …,Data Engineering (ICDE); 2010 IEEE 26th International Conference on,2010,*
Design and implementation of wavescope storage manager and access scheduler,Jeremy Elliot Smith,In this thesis; I designed; implemented; and analyzed the performance of an optimizedstorage manager for the Wavescope project. In doing this; I implemented an importationsystem that converts CENSAM data into a format specific to the processing system andcleans that data from measurement errors and irregularities; designed and implemented ahighly efficient bulk-data processing system that is further optimized with a parallel-processor and disk access reorderer; carefully analyzed various methods for accessing thedisk and our processing system; resulting in an accurate and predictive system model; andcarefully ran a set of different applications to analyze the performance of our processingsystem. The project involves low-level optimization of Linux disk I/O and high-leveloptimizations such as parallel-processing. In the end; I created a system that is highly …,*,2010,*
Hold the Accusations That Limit Scientific Innovation. Authors' reply,Jonathan Grier; Michael STONEBRAKER; Daniel ABADI; David J DEWITT; Sam MADDEN; Erik PAULSON; Andrew PAVLO; Alexander RASIN,*,Communications of the ACM,2010,*
Database Languages for Sensor Networks,Samuel Madden,realized using such logical structures. For example; in tree based data acquisition protocols;a collection tree is built that is rooted at the data collection center such as the sink node [8].The dissemination of the data requests from the participating nodes and collection of datafrom the sensor nodes are accomplished using this tree. A cluster based data acquisitionmechanism has been proposed in [3]. As shown in Fig. 1; nodes are organized into a fixednumber of clusters; and nodes within each cluster dynamically elect a cluster head. The dataacquisition is carried out in two phases. In the first phase; cluster heads collect data fromtheir cluster nodes. In the second phase; cluster heads send collected data to the nodes thathave subscribed to the data. The cluster heads are re-elected to balance energyconsumption among the nodes in the cluster. Zhang et al.[13] have proposed an adaptive …,Encyclopedia of Database Systems,2009,*
Designing Bayesian networks for highly expert-involved problem diagnosis domains,Dennis L Ramdass,Systems for diagnosing problems in highly complicated problem domains have beentraditionally very difficult to design. Such problem diagnosis systems have often beenrestricted to the use of primarily rule-based methods for problem diagnosis in cases wheremachine learning for probabilistic methods has been made difficult by limited availabletraining data. The probabilistic diagnostic methods that do not require a substantial amountof available training data usually require considerable expert involvement in design. Thisthesis proposes a model which balances the amount of expert involvement needed and thecomplexity of design in cases where training data for machine learning is limited. This modelaims to use a variety of techniques and methods to translate; and augment; experts'quantitative knowledge of their problem diagnosis domain into quantitative parameters for …,*,2009,*
Language design for distributed stream processing,Samuel Madden; Ryan Rhodes Newton,*,*,2009,*
Analyzing data streams in scientific applications,Tore Risch; Samuel Madden; Hari Balakrishan; Lewis Girod; Ryan Newton; Milena Ivanova; Erik Zeitler; Johannes Gehrke; Biswanath Panda; Mirek Riedewald,diva-portal.org. Please wait …,*,2009,*
Wai Ho Li Alan M. Zhang,Lindsay Kleeman,*,The International Journal of Robotics Research,2008,*
H-Store: A High-Performance; Distributed Main Memory Transaction Processing System,Evan PC Jones; Samuel Madden; Michael Stonebraker; Yang Zhang; John Hugg; Daniel J Abadi,ABSTRACT Our previous work has shown that architectural and application shifts haveresulted in modern OLTP databases increasingly falling short of optimal performance [10]. Inparticular; the availability of multiple-cores; the abundance of main memory; the lack of userstalls; and the dominant use of stored procedures are factors that portend a clean-slateredesign of RDBMSs. This previous work showed that such a redesign has the potential tooutperform legacy OLTP databases by a significant factor. These results; however; wereobtained using a bare-bones prototype that was developed just to demonstrate the potentialof such a system. We have since set out to design a more complete execution platform; andto implement some of the ideas presented in the original paper. Our demonstrationpresented here provides insight on the development of a distributed main memory OLTP …,*,2008,*
Compiler optimizations for an asynchronous stream-oriented programming language,Michael B Craig,Stream-oriented programs allow different opportunities for optimization than proceduralprograms. Moreover; as compared to purely synchronous stream-oriented programs;optimizing for asynchronous stream-based programs is difficult; owing to the latters' inherentunpredictability. In this thesis; we present several compiler optimizations for WaveScript; ahigh-level; functional; stream-oriented programming language. We also present a frameworkfor using profiling of stream-graph execution to drive optimizations; two of the optimizationsuse this profiled information to generate noticeable performance benefits for real-worldapplications written in WaveScript. Thus; it is shown that profiling presents an importantavenue by which to optimize asynchronous stream-based programs.,*,2008,*
Report on the Fourth International Workshop on Data Management for Sensor Networks (DMSN 2007),Magdalena Balazinska; Amol Deshpande; Alexandros Labrinidis; Qiong Luo; Samuel Madden; Jun Yang,Abstract Sensor networks enable an unprecedented level of access to the physical world;and hold tremendous potential to revolutionize many application domains. Research onsensor networks spans many areas of computer science; and there are now majorconferences; eg; IPSN and SenSys; devoted to sensor networks. However; there is nofocused forum for discussion of early and innovative work on data management in sensornetworks. The International Workshop on Data Management for Sensor Networks (DMSN);inaugurated in 2004; aims to fill this significant gap in the database and sensor networkcommunities.,ACM SIGMOD Record,2007,*
Distributed Computing in Sensor Systems Third IEEE International Conference; DCOSS 2007; Santa Fe; NM; USA; June 18-20; 2007. Proceedings,James Aspnes; Christian Scheideler; Anish Arora; Samuel Madden,The 27 revised full papers presented were carefully reviewed and selected from 71submissions. The papers class in three tracks covering the areas of algorithms; applications;and systems; thus bridging the gap between theory and practice and between the broaderfield of distributed computing and the specific issues arising in sensor networks and relatedsystems.,Conference proceedings DCOSS,2007,*
Correlation indices: a new access method to exploit correlated attributes,George Huo,In relational query processing; one generally chooses between two classes of access pathswhen performing a predicate lookup for which no clustered index is available. One option isto use an unclustered index. Another is to perform a complete sequential scan of the table.Online analytical processing (OLAP) workloads often do not benefit from the availability ofunclustered indices; the cost of random disk I/O becomes prohibitive for all but the mostselective queries. Unfortunately; this means that data warehouses and other OLAP systemsfrequently perform sequential scans; unless they can satisfy nearly all of the queries posedto them by a single clustered index [7]; or unless they have available specialized datastructures-like bitmap indices; materialized views; or cubes-to answer queries directly. Thisthesis presents a new index data structure called a correlation index (CI) that enables …,*,2007,*
Quiz I11 Solutions,THIS IS AN OPEN BOOK,Most questions are multiple-choice questions. Next to each choice; circle the word True orFalse; as appropriate. A correct choice will earn positive points; a wrong choice may earnnegative points; and not picking a choice will score 0. The exact number of positive andnegative points for each choice in a question depends on the question and choice. Themaximum score for each question is given near each question; the minimum for eachquestion is 0. Some questions are harder than others and some questions earn more pointsthan others-you may want to skim all questions before starting.,Computer,2007,*
Proceedings of the 3rd IEEE International Conference on Distributed Computing in Sensor Systems,James Aspnes,*,*,2007,*
Stephen Tu,Wenting Zheng; Stephen Tu; Eddie Kohler; Barbara Liskov; Justin DeBrabant; Andrew Pavlo; Michael Stonebraker; Stan Zdonik; Samuel Madden; M Frans Kaashoek; Nickolai Zeldovich; Haiping Zhao; Iain Proctor; Minghui Yang; Xin Qi; Mark Williams; Guilherme Ottoni; Charlie Gao; Andrew Paroski; Scott MacVicar; Jason Evans; Michael Armbrust; Nick Lanham; Armando Fox; Michael Franklin; David Patterson; Michael J Franklin; David A Patterson; Beth Trushkowsky; Jesse Trutna,Page 1. Stephen Tu http://www.cs.berkeley.edu/~stephentu Education University of California;Berkeley Aug. 2014 - Present Ph.D. student in Electrical Engineering and Computer Science(EECS) Advised by Professor Ben Recht Massachusetts Institute of Technology Sept. 2011 -May 2014 SM in Electrical Engineering and Computer Science (EECS) Advised by ProfessorSamuel Madden Thesis: Fast Transactions for Multicore In-Memory Databases GPA:5.0/5.0 University of California; Berkeley Aug. 2006 - Dec. 2010 BA in Computer Scienceand BS in Mechanical Engineering GPA: 3.97/4.0 Publications Fast Databases with FastDurability and Recovery through Multicore Parallelism. Wenting Zheng; Stephen Tu; EddieKohler; and Barbara Liskov OSDI 2014. Anti-Caching: A New Approach to Swapping inMain Memory OLTP Database Systems …,University of California; Berkeley,2006,*
Stephen Tu,Justin DeBrabant; Andrew Pavlo; Stephen Tu; Michael Stonebraker; Stan Zdonik; Wenting Zheng; Eddie Kohler; Barbara Liskov; Samuel Madden; M Frans Kaashoek; Nickolai Zeldovich; Haiping Zhao; Iain Proctor; Minghui Yang; Xin Qi; Mark Williams; Guilherme Ottoni; Charlie Gao; Andrew Paroski; Scott MacVicar; Jason Evans; Michael Armbrust; Nick Lanham; Armando Fox; Michael Franklin; David Patterson; Michael J Franklin; David A Patterson; Beth Trushkowsky; Jesse Trutna,Ph.D. student in Electrical Engineering and Computer Science (EECS) Advised by ProfessorSamuel Madden Master's thesis: Fast Transactions for Multicore In-Memory Databases GPA:5.0/5.0 … BA in Computer Science and BS in Mechanical Engineering GPA: 3.97/4.0 … PublicationsAnti-Caching: A New Approach to Swapping in Main Memory OLTP Database Systems. JustinDeBrabant; Andrew Pavlo; Stephen Tu; Michael Stonebraker; Stan Zdonik To appear in VLDB2014 … Speedy Transactions in Multicore In-Memory Databases. Stephen Tu; WentingZheng; Eddie Kohler; Barbara Liskov; and Samuel Madden SOSP 2013 … Processing AnalyticalQueries over Encrypted Data. Stephen Tu; M. Frans Kaashoek; Samuel Madden; and NickolaiZeldovich VLDB 2013 … The HipHop Compiler for PHP. Haiping Zhao; Iain Proctor; MinghuiYang; Xin Qi; Mark Williams; Guilherme Ottoni; Charlie Gao; Andrew Paroski; Scott …,University of California; Berkeley,2006,*
Selected Publications,KINAM PARK,[2] Park; H.; Park; K.; and Kim; D.: Preparation and swelling behavior of chitosan-basedsuperporous hydrogels for gastric retention application; J. Biomed. Mater. Res.; 76A: 144–150; 2006.[3] Jeong; JH; Cho; YW; Jung; B.; Park; K. and Kim; JD.: Self-assemblednanoparticles of ribozymes with poly (ethylene glycol)-b-poly (l-lysine) block copolymers;Japanese Journal of Applied Physics; 45: 591-595; 2006.,Journal of Polymer Science: Part B: Polymer Physics,2006,*
HARBOR: an integrated approach to recovery and high availability in an updatable; distributed data warehouse,Edmond Lau,Any highly available data warehouse will use some form of data replication to ensure that itcan continue to service queries despite machine failures. In this thesis; I demonstrate that itis possible to leverage the data replication available in these environments to build a simpleyet efficient crash recovery mechanism that revives a crashed site by querying remotereplicas for missing updates. My new integrated approach to recovery and high availability;called HARBOR (High Availability and Replication-Based Online Recovery); targetsupdatable data warehouses and offers an attractive alternative to the widely used log-basedcrash recovery algorithms found in existing database systems. Aside from its simplicity overlog-based approaches; HARBOR also avoids the runtime overhead of maintaining an on-disk log; accomplishes recovery without quiescing the system; allows replicated data to …,*,2006,*
Core Database Technology Program Committee,Anastassia Ailamaki; Gustavo Alonso; Walid Aref; Lars Arge; Brian Babcock; Mikael Berndtsson; Elisa Bertino; Claudio Bettini; Michael Boehlen; Anthony Bonner; Philippe Bonnet; Alex Buchmann; Tiziana Catarci; Surajit Chaudhuri; Peter Dadam; Amol Deshpande; Asuman Dogac; Christos Faloutsos; Elena Ferrari; Johann-Christoph Freytag; Dieter Gawlick; Johannes Gehrke; Torsten Grust; Ralf Hartmut Güting; Jayant Haritsa; Chris Jermaine; Christoph Koch; George Kollios; Mong Li Lee; Wolfgang Lindner; David Lomet; Hongjun Lu; Samuel Madden; Giansalvatore Mecca; Alberto Mendelzon; Rosa Meo; Tova Milo; Michele Missikoff; C Mohan; Mario Nascimento; Shojiro Nishio; Ed Omiecinski; Norman Paton; Torben Bach Pedersen; Calton Pu; Philippe Pucheral; Raghu Ramakrishnan; Thomas Rölleke; Ken Ross; Gunther Saake; Albrecht Schmidt; Marc Scholl; Bernhard Seeger,Committee Chair: Martin Kersten; CWI; The Netherlands … Serge Abiteboul; INRIA; France AnastassiaAilamaki; Carnegie Mellon University; USA Gustavo Alonso; ETH Zurich; Switzerland WalidAref; Purdue University; USA Lars Arge; Aarhus University; Denmark Brian Babcock; StanfordUniversity; USA Mikael Berndtsson; University of Skövde; Sweden Elisa Bertino; PurdueUniversity; USA Claudio Bettini; University of Milan; Italy Michael Boehlen; Free University ofBolzano/Bozen; Italy Peter Boncz; CWI; The Netherlands Anthony Bonner; University ofToronto; Canada Philippe Bonnet; University of Copenhagen; Denmark Alex Buchmann; Universityof Darmstadt; Germany Tiziana Catarci; University of Rome 'La Sapienza'; Italy SurajitChaudhuri; Microsoft; USA Vassilis Christophides; FORTH; Greece Peter Dadam; Universityof Ulm; Germany Amol Deshpande; University of California; Berkeley; USA Asuman …,VLDB 2005: 31st International Conference on Very Large Data Bases: Proceedings of the 31st International Conference on Very Large Data Bases; Trondheim; Norway; August 30-September 2; 2005,2005,*
6.830 Database Systems; Fall 2005,Samuel Madden,This course relies on primary readings from the database community to introduce graduatestudents to the foundations of database systems; focusing on basics such as the relationalalgebra and data model; schema normalization; query optimization; and transactions. It isdesigned for students who have taken MIT course 6.033 (or equivalent); no prior databaseexperience is assumed though students who have taken an undergraduate course indatabases are encouraged to attend. Topics related to the engineering and design ofdatabase systems; including: data models; database and schema design; schemanormalization and integrity constraints; query processing; query optimization and costestimation; transactions; recovery; concurrency control; isolation and consistency;distributed; parallel; and heterogeneous databases; adaptive databases; trigger systems; …,*,2005,*
Eventing architecture: RFID and sensors in supply chain,Kevin Eric Emery,We propose data structures to describe and query streaming RFID and sensor data.Furthermore; we propose an architecture built atop these data structures to build arbitraryreal-time applications. To understand the nature of these applications; we decompose suchsystems into four layers: Physical; Data; Filtering; and Application. We describe each layer interms of our presented data structures; and we discuss architecture optimizations in terms ofBandwidth; Computational Capacity; and Subsystem Transparency. We provide animplementation of Track and Trace and Cold-Chain model applications to demonstrate ourarchitecture.,*,2005,*
1st International Workshop on,Alexandros Labrinidis; Samuel Madden,The past few years have seen substantial amounts of computer science research on sensornetworks. Other subfields have had a number of workshops on the topic (eg; the Workshopon Wireless Sensor Networks and Applications (WSNA) in 2002 and 2003 and the SensorNetworks Protocols and Applications (SNPA) Workshop in 2002 and 2003; both of which aresystems/networking focused). Furthermore; there are now at least two major conferences–the Conference on Information Processing in Sensor Networks (IPSN); started in 2002; andthe ACM Conference on Sensor Systems (SenSys); started in 2003. These conferenceshave published a small number of database papers; but there is no forum for discussion onearly and innovative work on data management in sensor networks. We believe that theWorkshop on Data Management for Sensor Networks (DMSN'04) fills a significant gap in …,*,2004,*
Reminiscences on Influential Papers - Kenneth A. Ross,Nicolas Bruno; Samuel Madden; Wei Wang,*,SIGMOD Record,2004,*
Aggregation,S Madden,*,Conference On Embedded Networked Sensor Systems: Proceedings of the 2 nd international conference on Embedded networked sensor systems,2004,*
Continuous Queries Over Eddies,Samuel Madden,Abstract We present a continuous query system built on top of Eddies; a query-processingengine which replaces static query plans with per-tuple dynamic routing decisions. Wediscuss why this implementation is superior to traditional continuous query schemes; andpresent encouraging initial performance results which demonstrate the scalability andefficiency of our system.,*,2001,*
Training Spatial Knowledge Acquisition Using Virtual Environments,Nathaniel I Durlach; Thomas E von Wiegand; Andrew Brooks; Sam Madden; Lorraine Delhorne,Abstract: This report summarizes the work done by MIT in Year 4 (1 February 1999 through31 January 2000) of the ONR Grant N00014-96-1-0937 entitled" Training SpatialKnowledge Acquisition Using Virtual Environments." It has been prepared by NathanielDurlach (PI); Dr. Thomas E. von Wiegand; Andrew Brooks; Sam Madden; Lorraine Delhorneand Rebecca Lee Garnett Descriptors:* KNOWLEDGE BASED SYSTEMS;* VIRTUALREALITY; DATA BASES; COMPUTERIZED SIMULATION; IMAGE PROCESSING;AUTOMATION; RANDOM WALK; OPEN SYSTEM ARCHITECTURE.,*,2000,*
1.1 lntroduction,Louis D Braida; Nathaniel I Durlach; Richard M Held; Paul Duchnowski; Julie E Greenberg; Karen L Payton; Matthew H Power; William M Rabinowitz; Christine M Rankovic; Charlotte M Reed; J Kenneth Salisbury; Barbara G Shinn Cunningham; Mandayam A Srini; Cagatay Basdogan; Susan L Goldman; Kenneth W Grant; Kourosh Saberi; Kaoru Sekiyama; Annie H Takeuchi; Geoffrey L Plant; Amanda S Birch; Andrew G Brooks; Douglas S Brungart; Joshua P Cysyk; Suvranu De; Matthew E Esch; Isaac J Graf; Chi Hao Ho; Alexandra I Hou; Salim F Kassem; Glenn Koh; Jean C Krause; David S Lum; Sharieff A Mansour; Lajos Molnar; Sadiki P Mwanyoha; Balasundar I Raju; David W Schloerb; Steven J Schlueter; Matthew G Sexton; Jason J Sroka; Maciej Stachowiak; Prasanna B Tambe; Xudong Tang; Dinh Yen Tran; Kimberly J Voss; Evan F Wies; Wan Chen Wu; Hanfeng Yuan; Jonathan L Zalesky; David E DiFranco; Brian D Kincy; Kari Anne H Kjolaas; Samuel R Madden; David H Manowitz; Adrienne H Slaughter; Rebecca L Garnett; Eleanora M Luongo,The Sensory Communication group is interested in understanding sensorimotor andcognitive processes and applying this understanding to solve practical problems in a varietyof domains. Our basic research is characterized by behavioral (psychophysical)experimentation and quantitative theoretical model ing. Facilities to support this research aredeveloped as needed. Although some research is conducted on vision; most of the group¶ swork is focused on audition and taction. The main applications are concerned with aidingindividuals who suffer from impaired hearing; developing improved human machineinterfaces for virtual environments and teleoperation (virtual real ity); and using virtualenvironment technology for training. The main facilities of the group are associ ated with thepsychoacoustics; touch (or haptics); and virtual environment laboratories.,Science,1997,*
A Comparison of Approaches to Large-Scale Data Analysis g y,Sam Madden,Page 1. A Comparison of Approaches to Large-Scale Data Analysis g y Sam Madden MIT CSAILwith Andrew Pavlo; Erik Paulson; Alexander Rasin; Daniel Abadi; David DeWitt; and MichaelStonebraker In SIGMOD 2009 Page 2. MapReduce (MR) vs. Databases • Our goal: understandperformance and Our goal: understand performance and architectural differences • Both are suitablefor large-scale data processing – Ie analytical processing workloads – Bulk loads u oads – Queriesover large amounts of data – Not transactional Page 3. Why Compare Them? • Reason 1: CACM'09: MapReduce is a new way of thinking about p y g programming large distributed systems –To DBMS researchers; programming model doesn't feel new Other communities don't know this;important to evangelize – Other communities don t know this; important to evangelize • Reason2: Facebook is using Hive (a SQL layer) on Hadoop …,*,*,*
Learning Network Size While Training with ShrinkNets,Guillaume Leclerc; Raul Castro Fernandez; Samuel Madden,When designing neural networks; one of the key parameters is the network size; ie; thenumber of layers and neurons per layer. Choosing these parameters appropriately candramatically affect performance; yet there is no reliable way to efficiently set them. Althoughmany search strategies and heuristics [1] have been proposed; including random search;meta-gradient descent [11]; Gaussian processes [2]; and Parzen Estimators [2]; theygenerally require a compute-intensive search of parameter space. In this paper we present amethod to automatically find an appropriate network size; drastically reducing optimizationtime. The key idea is to learn the right network size at the same time that the network islearning the main task. For example; for an image classification task; with our approach wecan provide the training data to a network—without sizing it a priori—and expect to end …,*,*,*
Screen Shot 2017-03-13 at 5.15. 39 PM,Sam Madden; Jane Greenberg; Carsten Binnig; Tim Kraska; Danny Weitzner; Sam Grabus,Summary A part of the NSF Big Data regional innovation hub program; the Northeast hub; isaddressing key data sharing challenges by:• Creating a licensing model for data thatfacilitates sharing data that is not necessarily open or free between different organizations;•Developing a prototype data sharing software platform; ShareDB; which will enforces theterms and restrictions of the developed licenses; and• Developing and integrating relevantmetadata that will accompany the datasets shared under the different licenses; making themeasily searchable and interpretable.,*,*,*
Research Statement and Agenda,Samuel Madden,In my research; I have proposed; built; and evaluated a declarative query processor forwireless; battery-powered sensor networks; and explored the research challenges; such asdesigning appropriate language abstractions and devising query optimization and executiontechniques; that arise in building such a system. Each node in a sensor network is a small;radio-equipped; battery powered computer that carries some set of sensors which provideinformation about the physical environment–for example; light levels; acceleration; orambient gas concentration. These networks are increasingly being deployed in remotelocations to monitor and respond to events; for instance; scientists have placed a sensornetwork on Great Duck Island (off the coast of Maine) to monitor the occupancy of nests ofStorm Petrels; a type of endangered sea-bird traditionally monitored by physical …,*,*,*
Sloth: Being Lazy Is a Virtue (When Issuing Database Queries),SAMUEL MADDEN; ARMANDO SOLAR-LEZAMA,Many web applications store persistent data in databases. During execution; suchapplications spend a significant amount of time communicating with the database forretrieval and storing of persistent data over the network. These network round-trips representa significant fraction of the overall execution time for many applications (especially those thatissue a lot of database queries) and; as a result; increase their latency. While there has beenprior work that aims to eliminate round-trips by batching queries; they are limited by (1) arequirement that developers manually identify batching opportunities; or (2) the fact that theyemploy static program analysis techniques that cannot exploit many opportunities forbatching; as many of these opportunities require knowing precise information about the stateof the running program. In this article; we present SLOTH; a new system that extends …,*,*,*
Networking Support for Query Processing in Sensor Networks センサネットワークにおける問い合わせ処理のネットワークサポート,Alec Woo; Sam Madden; Ramesh Govindan,*,*,*,*
Graph Analytics on Relational Databases,Alekh Jindal; Samuel Madden; Amol Deshpande; Michael Stonebraker,Abstract Graph analytics is getting increasingly popular these days and there is a deluge ofnew systems for graph analytics. However; it is not clear how good or bad are the relationaldatabases for graph analytics. In this talk; I will share our experiences with graph analyticson relational databases. Contrary to the popular belief; modern relational databases canhave very good performance over graph analytics. Furthermore; we can offer better (andefficient) programming interfaces for expressing graph queries in relational databases;thereby not forcing the users to SQL.,*,*,*
Low Overhead Concurrency Control for Partitioned Main Memory Databases,Evan PC Jones Daniel J Abadi; Samuel Madden,Page 1. Low Overhead Concurrency Control for Partitioned Main Memory Databases EvanPC Jones Daniel J. Abadi Samuel Madden Page 2. Banks Payment Processing AirlineReservations E-Commerce Web 2.0 Page 3. Problem: Millions of transactions per second Page4. Problem: Millions of transactions per second Page 5. Problem: Millions of transactions persecond = $$$$ Page 6. Alternative: H-Store Project Redesign specifically for OLTP Prototype:~10X throughput Idea: Remove un-needed features Source: Stonebraker et. al; “The End ofan Architectural Era”; VLDB 2007. Page 7. H-Store: High Throughput OLTP Redesign DBspecifically for OLTP Prototype: ~10X throughput Main memory database Concurrency controlconsumes ~30-40% of CPU time Page 8. CPU Cycle Breakdown for Shore on TPC-C NewOrder Source: Harizopoulos; Abadi; Madden and Stonebraker …,*,*,*
Program Co-Chair,Peter Markstein; Steve Madden; Liping Wei; Puja Gupta; Jean Tsukamoto; David Dehoney; Nicole Litchfield; Ying Xu; Kathleen Sullivan; Arun Jagota; Al Shpuntoff; David Grosof; Pat Blauvelt; Vicky Markstein; Mark Luo; Ted Hudacho; Bob Marinelli; Douglas Weigel; Karen Hauge; Darlene Holt; Misty Hice; Dawei Lin; Brendan Mumey; Heidi Sofia,The members of the IEEE Computer Society Technical Committee on Bioinformatics arepleased to present the 2 nd International Computational Systems Bioinformatics CSB2003conference at Stanford University; August 11-14; 2003; in cooperation with the ACM andwith support from the Hewlett-Packard Company; the platinum sponsor; and the USDepartment of Energy. After the first CSB conference; the committee found itself eagerlylooking ahead to future conferences and redefining what it is that CSB means to ourattendees. Our vision for program content must reflect a perspective that is applicable for allparticipants and provide a critical mass across a broad spectrum in the multi-disciplinaryfield of bioinformatics.,*,*,*
IEEE CS Technical Chair on Bioinformatics,Steven Brenner; Eric Davidson; Steven Salzberg; John Wooley; Pat Blauvelt; Ed Buckingham; David Grosof; Arun Jagota; Tom Lee; Xiaole Liu; Peter Markstein; Vicky Markstein; Kathleen Sullivan; Jean Tsukamoto; Liping Wei; Ying Xu; Betty Cheng; Kass Goldfein; Karen Hauge; Ann Loraine; Mark Luo; Steve Madden; Bob Marinelli; Doug Weigel,Serafim Batzoglou; CSB 2004 Stanford University Faculty Sponsor Steven Brenner; Universityof California; Berkeley Eric Davidson; California Institute of Technology Steven Salzberg; Institutefor Genomic Research John Wooley; University of California; San Diego; San Diego SupercomputerCenter … Pat Blauvelt; Publications Chair Ed Buckingham; General Co-Chair; Treasury ChairDavid Grosof; Special Events Chair Arun Jagota; Tutorial Co-Chair; UCSC Extension TomLee; CSBB SIG Chair; University of California; Davis Xiaole Liu; Tutorial Co-Chair; Harvard UniversityPeter Markstein; Program Co-Chair; Hewlett-Packard Labs Vicky Markstein; General Chair andPublicity; in silico Labs Al Shpuntoff; Local Chair; AFS Informatics Kathleen Sullivan; Poster ChairJean Tsukamoto; Web Master and Design Chair Liping Wei; Tutorial Co-Chair; Nexus GenomicsYing Xu; Program Co-Chair; University of Georgia … Betty Cheng; Stanford University …,*,*,*
Publications Chair,Pat Blauvelt; Fang Wang; Kass Goldfein; Robert Stewart; David Grosof; Liz Rogers; Ed Buckingham; Al Shpuntoff; Steve Madden; Vicky Markstein; Cary Kornfeld; Jean Tsukomoto; Designer Nicole Litchfield; Press Agent; Eser Ayanoglu; Arun Swami,The CSB2002 Chairs and Committees welcome you to the IEEE Computer SocietyBioinformatics Conference. We hope that the CSB program that we have assembled will bechallenging for your present and future research activities. We sought to provide anopportunity for academic and industry scientists to share knowledge and exchange scientificachievements by bridging two very important research fields; Biology and ComputerSciences. CSB2002 received 103 submissions from the USA; Canada; Germany;Switzerland; Mexico; Brazil; Singapore; Pakistan; India; Russia; France; China; Japan; Italy;and after peer review 30 papers were accepted for the 2002 IEEE Computer SocietyBioinformatics Proceedings. These papers constitute the podium presentations as well assome of the poster sessions. Additional poster sessions are represented by abstracts in …,*,*,*
Preparing Data For The Data Lake,Alekh Jindal; Samuel Madden,Abstract Data preparation is increasingly becoming one of the biggest challenges inprocessing big data. While recent tools such as Tamer and Trifacta address the problem ofintegrating and cleaning the datasets as they come in; preparing these datasets for efficientprocessing over a variety of query workloads is still challenging. In this talk; I will discussthese challenges and describe our tool which allows for fine-grained data preparation; via adata preparation plan; and efficiently runs this plan while uploading the data to HDFS.,*,*,*
SYMPOSIUM ORGANIZERS,Eric Brewer; Peter Chen; Miguel Castro; Jason Flinn; Greg Ganger; Samuel Madden; Jeff Mogul; Andrew Myers; Jason Nieh; Timothy Roscoe; Mendel Rosenblum; Margo Seltzer; Geoff Voelker; David Wagner; Matt Welsh; David Culler; Peter Druschel; Mike Jones,The 6th Symposium on Operating Systems Design & Implementation (OSDI'04) continuesthe conference's tradition of presenting the best innovative work in “systems;” with a broadinterpretation of area. We believe that this year's conference contains some of the mostoriginal; intriguing; and important work in the field today—work that you; as a systemspractitioner; will find both stimulating and useful. By coming to this year's OSDI; you will hearfrom and interact with researchers who are addressing a wide range of important questions.How should we structure a system to tolerate buggy components? Can we manage systemsautomatically in the presence of malicious attacks; configuration errors; overloadedcomponents; and network outages? What should be the foundations and techniques forbuilding fast; robust; secure; low-power storage systems? How can we find or tolerate …,*,*,*
Wishbone: Profile-based Partitioning for Sensornet Applications Non-final version,Ryan Newton; Sivan Toledo; Lewis Girod; Samuel Madden; Hari Balakrishnan,Abstract The ability to partition sensor network application code across both sensor nodesand backend servers is important for running complex; data-intensive applications on sensorplatforms that have CPU; energy; and bandwidth limitations. This paper presents Wishbone;a system that takes a dataflow graph of operators and produces an optimal partitioning. WithWishbone; users can run the same program on a range of sensor platforms; includingTinyOS motes; any smartphone running JavaME; and the iPhone. The resulting programpartitioning will in general be different in each case; reflecting the different node capabilities.Wishbone uses profiling to determine how each operator in the dataflow graph will actuallyperform on sample data; without requiring cumbersome user annotations. Its partitioningalgorithm models the problem as an integer linear program that minimizes a linear …,*,*,*
Non-final version.,Ryan Newton; Sivan Toledo; Lewis Girod; Samuel Madden; Hari Balakrishnan,Abstract The ability to partition sensor network application code across both sensor nodesand backend servers is important for running complex; data-intensive applications on sensorplatforms that have CPU; energy; and bandwidth limitations. This paper presents Wishbone;a system that takes a dataflow graph of operators and produces an optimal partitioning. WithWishbone; users can run the same program on a range of sensor platforms; includingTinyOS motes; any smartphone running JavaME; and the iPhone. The resulting programpartitioning will in general be different in each case; reflecting the different node capabilities.Wishbone uses profiling to determine how each operator in the dataflow graph will actuallyperform on sample data; without requiring cumbersome user annotations. Its partitioningalgorithm models the problem as an integer linear program that minimizes a linear …,*,*,*
Data Engineering,Stratis D Viglas; Gavin Bierman; Fabian Nagel; Craig Freedman; Erik Ismert; Per-Ake Larson; Surajit Chaudhuri; Vivek Narasayya; Manoj Syamala; Alvin Cheung; Samuel Madden; Armando Solar-Lezama; Owen Arden; Andrew C Myers; Karthik Ramachandra; Ravindra Guravannavar,Abstract On modern servers the working set of database management systems becomesmore and more main memory resident. Slow disk accesses are largely avoided; and thus thein-memory processing speed of databases becomes an important factor. One very attractiveapproach for fast query processing is justin-time compilation of incoming queries. Byproducing machine code at runtime we avoid the overhead of traditional interpretationsystems; and by carefully organizing the code around register usage we minimize memorytraffic and get excellent performance. In this paper we show how queries can be brought intoa form suitable for efficient translation; and how the underlying code generation can beorchestrated. By carefully abstracting away the necessary plumbing infrastructure we canbuild a query compiler that is both maintainable and efficient. The effectiveness of the …,*,*,*
VoxNet: A Platform for Distributed Acoustic Sensing,Michael Allen; Lewis Girod; Ryan Newton; Samuel Madden; Travis Collier; Deborah Estrin; Daniel T Blumstein,Abstract-VoxNet is a hardware and software platform for distributed acoustic sensing whichintegrates previous experience in acoustic sensing networks with a high level programmingand interaction model. This single-node demonstrator shows the VoxNet node hardwareand software running a component of an acoustic source localisation application.,*,*,*
Master Thesis “Advanced Aggregation in Ad-Hoc Sensor Networks”,Roger Wattenhofer; S Madden; MJ Franklin; JM Hellerstein; W Hong,Abstract Due to the relative ease of deployment; sensor networks are suitable for variousmonitoring and data collection tasks. In order to make use of the monitored values; thesevalues need be forwarded to a central component; eg; a powered basestation. Instead offorwarding all measurements to the basestation; it is possible for several queries toaggregate the measurements along the path to the basestation which substantially reducesthe number of exchanged messages and hence the total power consumption. Aggregationservices for ad-hoc sensor networks capable of answering simple aggregation queries suchas “what is the sum/average of all measurements?” or “what is the maximum/minimumvalue?” have been proposed [1; 2]. In this thesis; the goal is to provide an aggregationservice tailored to more sophisticated queries which necessitates the implementation of …,*,*,*
Flattening the Internet: A Proposal for Global Device-to-Device Connectivity,Hari Balakrishnan; John Guttag; M Frans Kaashoek; Dina Katabi; Sam Madden; Robert Morris; Marten van Dijk,*,*,*,*
Data Management in an Connected World,Hari Balakrishnan; John Guttag; Frans Kaashoek; Bradley C Kuszmaul; Charles E Leiserson; Barbara Liskov; Sam Madden; Robert Morris; Michael Stonebraker,*,*,*,*
Message from the Organizing Committee,Alexandros Labrinidis; Samuel R Madden; Amol Deshpande; Qiong Luo,The past few years have seen substantial amounts of computer science research on sensornetworks as they have the potential to bring an unprecedented level of access to thephysical world. Other subfields of Computer Science have had a number of workshops onthe topic. Also; there are now at least two major conferences–the Conference on InformationProcessing in Sensor Networks (IPSN); started in 2002 (the 2006 IPSN was held in April);and the ACM Conference on Sensor Systems (SenSys); started in 2003 (the 2006 SenSyswill be held in November). These conferences have published a small number of databasepapers; but there is no exclusive forum for discussion on early and innovative work on datamanagement in sensor networks. We believe that the DMSN 2006 workshop; building on thesuccesses of the DMSN 2004 and DMSN 2005 workshops; fills a significant gap in the …,*,*,*
Explanatory Lineage,Eugene Wu; Samuel Madden,ABSTRACT As data analytics becomes mainstream; and the complexity of the underlyingdata and computation grows; end-users will increasingly rely on visualizations to presentsimplified statistics that summarizes interesting properties in the data. It is even moreimportant to provide tools that help analysts understand the underlying reasons when theysee anomalous results. We envision adding a new explanatory dimension into visualizationlibraries and creation tools that automatically give end-users the capability to mine andunderstand the reasons for outliers and trends that they see in the visualizations. In thispaper; we propose an initial problem formulation targeted towards business dashboardapplications; and propose a set of modifications to existing declarative visualization librariesthat enables this ability in existing visualizations with minimal changes by the developer.,*,*,*
Monitoring Infrastructure Using Sensor Networks,Timur Tokmouline; Samuel R Madden; Ivan Stoianov,The purpose of this project is to assist with the development and evaluation of a wirelesssensor network-based system for monitoring large-scale urban infrastructure such as watersupply and sewer networks. The work is in collaboration with a research group at the CivilEngineering Department at MIT led by Professor Andrew Whittle (sensor. mit. edu). The mainobjective is to bridge advances in hydraulic modeling; signal processing and sensornetworks in order to demonstrate a prototype low-cost system for continuous monitoring;fault identification (leak detection) and optimal control (pressure optimization) in waterdistribution and sewer networks.,*,*,*
Processamento de Consulta para Streaming de Dados em Sensores,Samuel Madden,*,*,*,*
Training Spatial Knowledge Acquisition using Virtual Environments Sponsor US Navy-Office of Naval Research,Nathaniel I Durlach; Thomas Ev Wiegand; Lorraine Delhorne; Rebecca L Garnett; Andrew G Brooks; Samuel R Madden,Page 1. 1 Training Spatial Knowledge Acquisition using Virtual Environments Sponsor USNavy - Office of Naval Research Grant N00014-96-1-0379 Project Staff Nathaniel I. Durlach;Dr. Thomas Ev Wiegand; Lorraine Delhorne; Rebecca L. Garnett; Andrew G. Brooks; SamuelR. Madden 1 Overview Background on this project can be found in RLE Progress ReportsNumbers 140 and 141. A large portion of our effort during the past year has been directedtowards the development of a generic simulation involving a World in Miniature or WIM(Stoakley; Conway; and Pausch; 1995). We believe that the WIM will prove to be a valuabletraining aid for the acquisition of configurational knowledge of specific spaces. The genericnature of the simulation will accommodate both completely virtual environments as wellas virtual copies of real-world environments …,*,*,*
Distributed Regression in Sensor Networks,Carlos Guestrin; Peter Bodik; Romain Thibaux; Mark A Paskin; Samuel Madden,Small low-power devices that can sense and actuate in their environment; and communicateinformation; provide an effective framework for tackling many tasks in science and industry.In recent years; developments in hardware and low-level software have lead to viablesystems that have been deployed in many real-world tasks (Mainwaring et al. 2002). Figure1 (a) shows an example deployment of 25 sensor nodes (motes) in the Intel Lab in Berkeley.Each mote; shown in Figure 1 (b); has a set of sensors measuring various environmentalquantities; such as temperature; humidity; etc. Such sensor net systems are often used intwo typical modes of operations: either all the data from the sensors is extracted from thenetwork; and analyzed off-line (Mainwaring et al. 2002); or the information from obtainedfrom these sensor is aggregated using simple local operations that compute; for example …,*,*,*
An Integration Framework for Sensor Networks and DSMSs,Daniel Abadi; Samuel Madden; Michael Stonebraker,DSMSs [1; 4; 2] were developed to support an emerging class of applications-monitoringapplications-that proved problematic for traditional DBMSs. Monitoring applications areapplications that monitor continuous streams of data. Their fundamental data-active/human-passive; real-time; trigger oriented model is difficult to support in the traditional human-active/data-passive trigger-as-secondclass-citizen DBMS model. DSMSs are better suited tosupporting these applications by organizing query operators in a work-flow diagram andallowing data to actively stream through these operators; which transform the input dataaccording to a continuous query plan. The performance of a DSMS can be measured usinga Quality of Service (QoS) metric in which an application can specify the utility of observedlatency; throughput; or quality of result tuples that reach the application.Sensor networks …,*,*,*
Data Engineering,Stan Zdonik; Michael Stonebraker; Mitch Cherniack; Magdalena Balazinska; Hari Balakrishnan; Sailesh Krishnamurthy; Sirish Chandrasekaran; Owen Cooper; Amol Deshpande; Michael J Franklin; Joseph M Hellerstein; Wei Hong; Samuel R Madden; Fred Reiss; Mehul A Shah,Bulletin of the Technical Committee on Data Engineering March 2003 Vol. 26 No. 1 IEEE ComputerSociety Letters Letter from the Editor-in-Chief...................................................... David Lomet 1 Letterfrom the Special Issue Editor................................................ Johannes Gehrke 2 Special Issue onData Stream Processing The Aurora and Medusa Projects … EditorialBoard Editor-in-Chief David B. Lomet Microsoft Research One Microsoft Way; Bldg. 9 RedmondWA 98052-6399 lomet@ microsoft. com Associate Editors Umeshwar Dayal Hewlett-PackardLaboratories 1501 Page Mill Road; MS 1142 Palo Alto; CA 94304 Johannes Gehrke Departmentof Computer Science Cornell University Ithaca; NY 14853 Christian S. Jensen Department ofComputer Science Aalborg University Fredrik Bajers Vej 7E DK-9220 Aalborg Øst; DenmarkRenée J. Miller Dept. of Computer Science University of Toronto 6 King's College Rd …,Urbana,*,*
Research Abstracts-2006,Daniel J Abadi; David J DeWitt; Stavros Harizopoulos; Samuel R Madden; Daniel S Myers; Michael R Stonebraker; Transparent Accountable Data Mining Initiative; Harold Abelson; Tim Berners-Lee; Chris Hanson; Lalana Kagal; Gerald Jay Sussman; K Krasnow Waterman; Daniel J Weitzner; Varun Aggarwal; Wesley O Jin; Una-May O'Reilly; RF Circuit Sizing; Unbounded Transactional Memory; C Scott Ananian; Krste Asanovic; Bradley C Kuszmaul; Charles E Leiserson; Shay Artzi; Michael Ernst; David Glasser; Adam Kiezun; Carlos Pacheco; Jeff Perkins; Hari Balakrishnan; Samuel Madden; Vladimir Bychkovsky; Kevin Chen; Waseem Daher; Michel Goraczko; Hongyi Hu; Bret Hull; Allen Miu; Eugene Shih; Kenneth C Barr; Michael A Bender; Martin Farach-Colton; Simai He; Robert Beverly; Steven Bauer; Karen Sollins; Michael Bolin; Greg Little; Ricarose Roque; Darris Hupp; Vikki Chou; Robert Miller; David D Clark; Peyman Faratin; Steve Bauer; W Lehr; R Sami; Charles Fine; Andrew Lippman; James Cowling; Daniel Myers; Barbara Liskov; Dorothy Curtis; Asfandyar Qureshi; Esteban Pino; Lucila Ohno-Machado; Robert Greenes; John Guttag; Marcelo d'Amorim; Darko Marinov; Tao Xie; Michael D Ernst; Nirav Dave; Michael Pellauer; Joel Emer; Brian Demsky; Philip J Guo; Stephen McCamant; Jeff H Perkins; Martin Rinard; Jack B Dennis; Matthew Drake; Rodric Rabbah; Saman Amarasinghe; Jonathan Edwards; Raimondas Lencevicius; Eric Fellheimer; Bryan Ford; Jacob Strauss; Chris Lesniewski-Laas; Sean Rhea; Frans Kaashoek; Robert Morris; Simson L Garfinkel; Robert C Miller; Steve Gerding; Lewis Girod; Kyle Jamieson; Yuan Mei; Stan Rost,Most major DBMS vendors implement record-oriented storage systems; where the attributesof a record (or tuple) are placed contiguously in storage. With this row store architecture; asingle disk write suffices to push all of the fields of a single record out to disk. Hence; highperformance writes are achieved; and a DBMS with a row store architecture is a write-optimized system. These are especially effective on OLTP-style applications.In contrast;systems oriented toward ad-hoc querying of large amounts of data should be read-optimized. Data warehouses represent one class of read-optimized system; in whichperiodically a bulk load of new data is performed; followed by a relatively long period of ad-hoc queries. Other read-mostly applications include customer relationship management(CRM) systems; electronic library card catalogs; and other ad-hoc inquiry systems. In …,*,*,*
Data Engineering,Michael Stonebraker; Mitch Cherniack; Ugur Cetintemel; Magdalena Balazinska; Hari Balakrishnan; Sailesh Krishnamurthy; Sirish Chandrasekaran; Owen Cooper; Amol Deshpande; Michael J Franklin; Joseph M Hellerstein; Wei Hong; Samuel R Madden; Fred Reiss; Mehul A Shah,Bulletin of the Technical Committee on Data Engineering March 2003 Vol. 26 No. 1 IEEE ComputerSociety Letters Letter from the Editor-in-Chief...................................................... David Lomet 1 Letterfrom the Special Issue Editor................................................ Johannes Gehrke 2 Special Issue onData Stream Processing The Aurora and Medusa Projects … EditorialBoard Editor-in-Chief David B. Lomet Microsoft Research One Microsoft Way; Bldg. 9 RedmondWA 98052-6399 lomet@ microsoft. com Associate Editors Umeshwar Dayal Hewlett-PackardLaboratories 1501 Page Mill Road; MS 1142 Palo Alto; CA 94304 Johannes Gehrke Departmentof Computer Science Cornell University Ithaca; NY 14853 Christian S. Jensen Department ofComputer Science Aalborg University Fredrik Bajers Vej 7E DK-9220 Aalborg Øst; DenmarkRenée J. Miller Dept. of Computer Science University of Toronto 6 King's College Rd …,Urbana,*,*
Application of Privacy Principles to Wireless Sensor Networks,Samuel Madden; Doug Tygar,Networks of small; wireless computers equipped with sensing hardware that can detectenvironmental characteristics like light; temperature; vibration; humidity; or gasconcentration are becoming increasingly widespread. Researchers have proposed thatsuch sensor networks be used to monitor a variety of environments; and there is particularinterest in monitoring in indoor building environments [6; 10]. Possible benefits of suchnetworks include increased efficiency of heating and cooling systems; increased awarenessfor building occupants of their surroundings (eg which conference rooms are in use; whethera fellow employee is at his desk); improved security; safety; and alarm systems; and so on.Unfortunately; such networks also pose substantial privacy risks to users of buildings:continuous monitoring and data collection; especially when combined with personally …,*,*,*
Mesh NeTWorkINg,Samuel Madden; Philip Levis; Andrew T Campbell; Shane B Eisenman; Nicholas D Lane; Emiliano Miluzzo; Ronald A Peterson; Hong Lu; Xiao Zheng; Mirco Musolesi; Kristóf Fodor; Gahng-Seop Ahn,Technological advances in sensing; computation; storage; and communications will turn thenear-ubiquitous mobile phone into a global mobile sensing device. People-centric sensingwill help drive this trend by enabling a different way to sense; learn; visualize; and shareinformation about ourselves; friends; communities; the way we live; and the world we live in.It juxtaposes the traditional view of mesh sensor networks with one in which people; carryingmobile devices; enable opportunistic sensing coverage. In the MetroSense Project's visionof people-centric sensing; users are the key architectural system component; enabling ahost of new application areas such as personal; public; and social sensing.,*,*,*
Research Abstracts-2006,Edmond Lau; Samuel Madden,A traditional data warehouse consists of a large distributed database system that processesread-only analytical queries over historical data loaded from an operational database. Suchwarehouses often do not need traditional database recovery or concurrency control featuresbecause they are updated via bulk-load utilities rather than standard SQL INSERT/UPDATEcommands. They do; however; require high availability and disaster recovery mechanismsso that they can provide always-on access.Recent years have seen increasing interest inproviding support for warehouse-like systems that support fine-granularity insertions of newdata and even occasional updates of incorrect or missing historical data; these modificationsneed to be supported concurrently with traditional updates. Such systems are useful forproviding flexible load support in traditional warehouse settings; for reducing the delay for …,*,*,*
Message from the Track Chairs,Sam Madden; Subhash Suri; Jie Liu; Andreas Savvides,Welcome to IPSN 2008—the Seventh International Conference on Information Processing inSensor Networks! The Technical Program Committee of the IPSN consists of two tracks: theInformation Processing (IP) track; which focuses on algorithms; systems; and theorypertaining to information processing using networks of embedded sensors; and the SensorPlatforms; Tools; and Design Methods (SPOTS) track; which focuses on platforms and toolsdesigned for networked embedded sensors. In the IP track; 30 technical papers wereselected from 126 completed paper submissions. Most submissions were reviewed by fourreviewers; and in some cases one or two additional reviewers. Most of these reviews weredone by members of the Tchnical Pogram Cmmittee (TPC); but when appropriate theProgram Committee members sought the expertise of external reviewers to generate a …,*,*,*
Research Abstracts-2006,Lewis Girod; Kyle Jamieson; Yuan Mei; Stan Rost; Arvind Thiagarajan; Timur Tokmouline; Hari Balakrishnan; Sam Madden,The WaveScope project is developing a software platform to make it easy to develop;deploy; and operate wireless sensor networks that exhibit high data rates. In contrast to the"first generation" of wireless sensor networks that are characterized by relatively low sensorsampling rates; there are several important emerging applications in which high rates ofhundreds to tens of thousands of sensor samples per second are common. These include:,*,*,*
CarTelDB: Continuous Query Processing in an Intermittently Connected World,Sam Madden; Yang Zhang; Bret Hull; Vladimir Bychkovsky; Hari Balakrishnan,Over the past few years; the" first generation" of wireless sensor computing systems havetaken root [13; 14]; and the idea of thinking of a sensor network as a streaming datarepository over which one can run continuous queries [7; 9]; with optimizations such as" in-network" aggregation [6]; is now well-established. This approach works well for a class ofapplications that are characterized by static sensor nodes with relatively low data rates;where the primary function of the sensor network (" sensornet") is to periodically monitor aremote environment or to track some event of interest. We believe that the next generation ofsensornets will display much higher degrees of mobility and significantly higher data rates.For example; media-rich sensors; such as cameras to capture images and video; chemicalsensors to monitor pollution; vibration (acceleration) sensors to monitor car and road …,*,*,*
Bulletin of the Technical Committee on,Sirish Chandrasekaran; Amol Deshpande; Kris Hildrum; Sam Madden; Vijayshankar Raman; Mehul A Shah; Zachary G Ives; Alon Y Levy; Daniel S Weld; Daniela Florescu; Marc Friedman,Bulletin of the Technical Committee on Ø Ò Ò Ö Ò June 2000 Vol. 23 No. 2 IEEE Computer SocietyLetters Letter from the Editor-in-Chief...................................................... David Lomet 1 Letter fromthe Special Issue Editor...................................................... Alon Levy 2 Special Issue on AdaptiveQuery Processing Dynamic Query Evaluation Plans: Some Course Corrections?.............................. Goetz Graefe 3 Adaptive … Editorial Board Editor-in-Chief David B. Lomet MicrosoftResearch One Microsoft Way; Bldg. 9 Redmond WA 98052-6399 lomet@ microsoft. com AssociateEditors Luis Gravano Computer Science Department Columbia University 1214 Amsterdam AvenueNew York; NY 10027 Alon Levy University of Washington Computer Science and EngineeringDept. Sieg Hall; Room 310 Seattle; WA 98195 Sunita Sarawagi School of Information TechnologyIndian Institute of Technology; Bombay Powai Street Mumbai; India 400076 Gerhard …,*,*,*
