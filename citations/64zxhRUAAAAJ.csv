SCOPE: easy and efficient parallel processing of massive data sets,Ronnie Chaiken; Bob Jenkins; Per-Åke Larson; Bill Ramsey; Darren Shakib; Simon Weaver; Jingren Zhou,Abstract Companies providing cloud-scale services have an increasing need to store andanalyze massive data sets such as search logs and click streams. For cost and performancereasons; processing is typically done on large clusters of shared-nothing commoditymachines. It is imperative to develop a programming model that hides the complexity of theunderlying system but provides flexibility by allowing users to extend functionality to meet avariety of requirements. In this paper; we present a new declarative and extensible scriptinglanguage; SCOPE (Structured Computations Optimized for Parallel Execution); targeted forthis type of massive data analysis. The language is designed for ease of use with no explicitparallelism; while being amenable to efficient parallel execution on large clusters. SCOPEborrows several features from SQL. Data is modeled as sets of rows composed of typed …,Proceedings of the VLDB Endowment,2008,796
Implementing database operations using SIMD instructions,Jingren Zhou; Kenneth A Ross,Abstract Modern CPUs have instructions that allow basic operations to be performed onseveral data elements in parallel. These instructions are called SIMD instructions; since theyapply a single instruction to multiple data elements. SIMD technology was initially built intocommodity processors in order to accelerate the performance of multimedia applications.SIMD instructions provide new opportunities for database engine design andimplementation. We study various kinds of operations in a database context; and show howthe inner loop of the operations can be accelerated using SIMD instructions. The use ofSIMD instructions has two immediate performance benefits: It allows a degree of parallelism;so that many operands can be processed at once. It also often leads to the elimination ofconditional branch instructions; reducing branch mispredictions. We consider the most …,Proceedings of the 2002 ACM SIGMOD international conference on Management of data,2002,200
MTCache: Transparent mid-tier database caching in SQL server,P-A Larson; Jonathan Goldstein; Jingren Zhou,Many applications today run in a multitier environment with browser-based clients; midtier(application) servers and a backend database server. Midtier database caching attempts toimprove system throughput and scalability by offloading part of the database workload tointermediate database servers that partially replicate data from the backend server. The factthat some queries are offloaded to an intermediate server should be completely transparentto applications-one of the key distinctions between caching and replication. MTCache is aprototype midtier database caching solution for SQL server that achieves this transparency.It builds on SQL server's support for materialized views; distributed queries and replication.We describe MTCache and report experimental results on the TPC-W benchmark. Theexperiments show that a significant part of the query workload can be offloaded to cache …,Data Engineering; 2004. Proceedings. 20th International Conference on,2004,142
Re-optimizing data-parallel computing,Sameer Agarwal; Srikanth Kandula; Nicolas Bruno; Ming-Chuan Wu; Ion Stoica; Jingren Zhou,Abstract Performant execution of data-parallel jobs needs good execution plans. Certainproperties of the code; the data; and the interaction between them are crucial to generatethese plans. Yet; these properties are difficult to estimate due to the highly distributed natureof these frameworks; the freedom that allows users to specify arbitrary code as operations onthe data; and since jobs in modern clusters have evolved beyond single map and reducephases to logical graphs of operations. Using fixed apriori estimates of these properties tochoose execution plans; as modern systems do; leads to poor performance in severalinstances. We present RoPE; a first step towards re-optimizing data-parallel jobs. RoPEcollects certain code and data properties by piggybacking on job execution. It adaptsexecution plans by feeding these properties to a query optimizer. We show how this …,Proceedings of the 9th USENIX conference on Networked Systems Design and Implementation,2012,135
Apollo: Scalable and Coordinated Scheduling for Cloud-Scale Computing.,Eric Boutin; Jaliya Ekanayake; Wei Lin; Bing Shi; Jingren Zhou; Zhengping Qian; Ming Wu; Lidong Zhou,Abstract Efficiently scheduling data-parallel computation jobs over cloud-scale computingclusters is critical for job performance; system throughput; and resource utilization. It isbecoming even more challenging with growing cluster sizes and more complex workloadswith diverse characteristics. This paper presents Apollo; a highly scalable and coordinatedscheduling framework; which has been deployed on production clusters at Microsoft toschedule thousands of computations with millions of tasks efficiently and effectively on tensof thousands of machines daily. The framework performs scheduling decisions in adistributed manner; utilizing global cluster information via a loosely coordinated mechanism.Each scheduling decision considers future resource availability and optimizes variousperformance and system factors together in a single unified model. Apollo is robust; with …,OSDI,2014,133
SCOPE: parallel databases meet MapReduce,Jingren Zhou; Nicolas Bruno; Ming-Chuan Wu; Per-Ake Larson; Ronnie Chaiken; Darren Shakib,Abstract Companies providing cloud-scale data services have increasing needs to store andanalyze massive data sets; such as search logs; click streams; and web graph data. For costand performance reasons; processing is typically done on large clusters of tens ofthousands of commodity machines. Such massive data analysis on large clusters presentsnew opportunities and challenges for developing a highly scalable and efficient distributedcomputation system that is easy to program and supports complex system optimization tomaximize performance and reliability. In this paper; we describe a distributed computationsystem; Structured Computations Optimized for Parallel Execution (Scope); targeted for thistype of massive data analysis. Scope combines benefits from both traditional paralleldatabases and MapReduce execution engines to allow easy programmability and deliver …,The VLDB Journal—The International Journal on Very Large Data Bases,2012,100
Improving database performance on simultaneous multithreading processors,Jingren Zhou; John Cieslewicz; Kenneth A Ross; Mihir Shah,Abstract Simultaneous multithreading (SMT) allows multiple threads to supply instructions tothe instruction pipeline of a superscalar processor. Because threads share processorresources; an SMT system is inherently different from a multiprocessor system and;therefore; utilizing multiple threads on an SMT processor creates new challenges fordatabase implementers. We investigate three thread-based techniques to exploit SMTarchitectures on memory-resident data. First; we consider running independent operationsin separate threads; a technique applied to conventional multi-processor systems. Second;we describe a novel implementation strategy in which individual operators are implementedin a multi-threaded fashion. Finally; we introduce a new data-structure called a work-aheadset that allows us to use one of the threads to aggressively preload data into the cache …,Proceedings of the 31st international conference on Very large data bases,2005,100
Efficient exploitation of similar subexpressions for query processing,Jingren Zhou; Per-Ake Larson; Johann-Christoph Freytag; Wolfgang Lehner,Abstract Complex queries often contain common or similar subexpressions; either within asingle query or among multiple queries submitted as a batch. If so; query execution time canbe improved by evaluating a common subexpression once and reusing the result in multipleplaces. However; current query optimizers do not recognize and exploit similarsubexpressions; even within the same query. We present an efficient; scalable; andprincipled solution to this long-standing optimization problem. We introduce a light-weightand effective mechanism to detect potential sharing opportunities among expressions.Candidate covering subexpressions are constructed and optimization is resumed todetermine which; if any; such subexpressions to include in the final query plan. The chosensubexpression (s) are computed only once and the results are reused to answer other …,Proceedings of the 2007 ACM SIGMOD international conference on Management of data,2007,94
Lazy maintenance of materialized views,Jingren Zhou; Per-Ake Larson; Hicham G Elmongui,Abstract Materialized views can speed up query processing greatly but they have to be keptup to date to be useful. Today; database systems typically maintain views eagerly in thesame transaction as the base table updates. This has the effect that updates pay for viewmaintenance while beneficiaries (queries) get a free ride! View maintenance overhead canbe significant and it seems unfair to have updates bear the cost. We present a novel way tolazily maintain materialized views that relieves updates of this overhead. Maintenance of aview is postponed until the system has free cycles or the view is referenced by a query. Viewmaintenance is fully or partly hidden from queries depending on the system load. Ideally;views are maintained entirely on system time at no cost to updates and queries. Theefficiency of lazy maintenance is improved by combining updates from several …,Proceedings of the 33rd international conference on Very large data bases,2007,86
Buffering databse operations for enhanced instruction cache performance,Jingren Zhou; Kenneth A Ross,Abstract As more and more query processing work can be done in main memory access isbecoming a significant cost component of database operations. Recent database researchhas shown that most of the memory stalls are due to second-level cache data misses andfirst-level instruction cache misses. While a lot of research has focused on reducing the datacache misses; relatively little research has been done on improving the instruction cacheperformance of database systems. We first answer the question" Why does a databasesystem incur so many instruction cache misses?" We demonstrate that current demand-pullpipelined query execution engines suffer from significant instruction cache thrashingbetween different operators. We propose techniques to buffer database operations duringquery execution to avoid instruction cache thrashing. We implement a new light-weight" …,Proceedings of the 2004 ACM SIGMOD international conference on Management of data,2004,82
Buffering accesses to memory-resident index structures,Jingren Zhou; Kenneth A Ross,Abstract Recent studies have shown that cache-conscious indexes outperform conventionalmain memory indexes. Cache-conscious indexes focus on better utilization of each cacheline for improving search performance of a single lookup. None has exploited cache spatialand temporal locality between consecutive lookups. We show that conventional indexes;even" cache-conscious" ones; suffer from significant cache thrashing between accesses.Such thrashing can impact the performance of applications such as stream processing andquery operations such as index-nested-loops join. We propose techniques to bufferaccesses to memory-resident tree-structured indexes to avoid cache thrashing. We studyseveral alternative designs of the buffering technique; including whether to use fixed-size orvariable-sized buffers; whether to buffer at each tree level or only at some of the levels …,Proceedings of the 29th international conference on Very large data bases-Volume 29,2003,79
Incorporating partitioning and parallel plans into the SCOPE optimizer,Jingren Zhou; Per-Ake Larson; Ronnie Chaiken,Massive data analysis on large clusters presents new opportunities and challenges forquery optimization. Data partitioning is crucial to performance in this environment. However;data repartitioning is a very expensive operation so minimizing the number of suchoperations can yield very significant performance improvements. A query optimizer for thisenvironment must therefore be able to reason about data partitioning including its interactionwith sorting and grouping. SCOPE is a SQL-like scripting language used at Microsoft formassive data analysis. A transformation-based optimizer is responsible for converting scriptsinto efficient execution plans for the Cosmos distributed computing platform. In this paper;we describe how reasoning about data partitioning is incorporated into the SCOPEoptimizer. We show how relational operators affect partitioning; sorting and grouping …,Data Engineering (ICDE); 2010 IEEE 26th International Conference on,2010,72
Optimizing Data Shuffling in Data-Parallel Computation by Understanding User-Defined Functions.,Jiaxing Zhang; Hucheng Zhou; Rishan Chen; Xuepeng Fan; Zhenyu Guo; Haoxiang Lin; Jack Y Li; Wei Lin; Jingren Zhou; Lidong Zhou,ABSTRACT Map/Reduce style data-parallel computation is characterized by the extensiveuse of user-defined functions for data processing and relies on data-shuffling stages toprepare data partitions for parallel computation. Instead of treating user-defined functions as“black boxes”; we propose to analyze those functions to turn them into “gray boxes” thatexpose opportunities to optimize data shuffling. We identify useful functional properties foruserdefined functions; and propose SUDO; an optimization framework that reasons aboutdata-partition properties; functional properties; and data shuffling. We have assessed thisoptimization opportunity on over 10;000 dataparallel programs used in production SCOPEclusters; and designed a framework that is incorporated it into the production system.Experiments with real SCOPE programs on real production data have shown that this …,NSDI,2012,66
Dynamic materialized views,Jingren Zhou; Per-Ake Larson; Jonathan Goldstein; Luping Ding,A conventional materialized view blindly materializes and maintains all rows of a view; evenrows that are never accessed. We propose a more flexible materialization strategy aimed atreducing storage space and view maintenance costs. A dynamic materialized viewselectively materializes only a subset of rows; for example; the most frequently accessedrows. One or more control tables are associated with the view and define which rows arecurrently materialized. The set of materialized rows can be changed dynamically; eithermanually or automatically by an internal cache manager using a feedback loop. Dynamicexecution plans are generated to decide whether the view is applicable at run time.Experimental results in Microsoft SQL Server show that compared with conventionalmaterialized views; dynamic materialized views greatly reduce storage requirements and …,Data Engineering; 2007. ICDE 2007. IEEE 23rd International Conference on,2007,63
Partially materialized views,*,Partially materialized views in the field of database systems are described herein. A methodof partially materializing a view computed from one or more source tables comprisesgenerating a view definition including a query expression and at least one control predicatereferencing at least one control table. The query expression specifies the maximal content ofthe view; that is; the complete set of records that could be materialized. One or more controlpredicates and the contents of one or more control tables restrict what records are actuallymaterialized and stored in the view. This allows the content of the partially materialized viewto be adjusted simply by updating one or more control tables.,*,2006,54
Use of materialized transient views in query optimization,*,Methods and systems for integrating use of materialized transient views into generation ofan optimized query execution plan. Features and aspects hereof provide rapid identificationof common expressions in a query as transient view candidates and then rapidly selectamong the transient view candidates for those transient views that most benefit the cost ofexecution of the query. The selected transient views are incorporated into a generated final;optimized query execution plan including operator to materialize the selected transientviews for re-use in execution of the query.,*,2010,51
A multi-resolution block storage model for database design,Jingren Zhou; Kenneth A Ross,We propose a new storage model called MBSM (multiresolution block storage model) forlaying out tables on disks. MBSM is intended to speed up operations such as scans that aretypical of data warehouse workloads. Disk blocks are grouped into" super-blocks;" with asingle record stored in a partitioned fashion among the blocks in a superblock. The intentionis that a scan operation that needs to consult only a small number of attributes can accessjust those blocks of each super-block that contain the desired attributes. To achieve goodperformance given the physical characteristics of modern disks; we organize super-blockson the disk into fixed-size" mega-blocks." Within a megablock; blocks of the same type (fromvarious super-blocks) are stored contiguously. We describe the changes needed in aconventional database system to manage tables using such a disk organization. We …,Database Engineering and Applications Symposium; 2003. Proceedings. Seventh International,2003,41
Cardinality estimation using sample views with quality assurance,Per-Ake Larson; Wolfgang Lehner; Jingren Zhou; Peter Zabback,Abstract Accurate cardinality estimation is critically important to high-quality queryoptimization. It is well known that conventional cardinality estimation based on histograms orsimilar statistics may produce extremely poor estimates in a variety of situations; forexample; queries with complex predicates; correlation among columns; or predicatescontaining user-defined functions. In this paper; we propose a new; general cardinalityestimation technique that combines random sampling and materialized view technology toproduce accurate estimates even in these situations. As a major innovation; we exploitfeedback information from query execution and process control techniques to assure thatestimates remain statistically valid when the underlying data changes. Experimental resultsbased on a prototype implementation in Microsoft SQL Server demonstrate the practicality …,Proceedings of the 2007 ACM SIGMOD international conference on Management of data,2007,39
Asynchronous database index maintenance,*,This disclosure provides techniques for asynchronously maintaining database indexes orsub-indexes. For example; a database management server may receive a data manipulationstatement to modify particular data stored in a database and determine whether an indexassociated with executing the statement is maintained asynchronously. When the index ismaintained asynchronously; maintenance of the index to reflect changes made to theparticular data by executing the data manipulation statement may be delayed until an indexmaintenance event. The index maintenance may be based on an isolation level of atransaction including a query that triggered the index maintenance.,*,2012,37
Advanced partitioning techniques for massively distributed computation,Jingren Zhou; Nicolas Bruno; Wei Lin,Abstract An increasing number of companies rely on distributed data storage andprocessing over large clusters of commodity machines for critical business decisions.Although plain MapReduce systems provide several benefits; they carry certain limitationsthat impact developer productivity and optimization opportunities. Higher level programminglanguages plus conceptual data models have recently emerged to address such limitations.These languages offer a single machine programming abstraction and are able to performsophisticated query optimization and apply efficient execution strategies. In massivelydistributed computation; data shuffling is typically the most expensive operation and canlead to serious performance bottlenecks if not done properly. An important optimizationopportunity in this environment is that of judicious placement of repartitioning operators …,Proceedings of the 2012 ACM SIGMOD International Conference on Management of Data,2012,33
Distributed multi-phase batch job processing,*,A distributed job-processing environment including a server; or servers; capable of receivingand processing user-submitted job queries for data sets on backend storage servers. Theserver identifies computational tasks to be completed on the job as well as a time frame tocomplete some of the computational tasks. Computational tasks may include; withoutlimitation; preprocessing; parsing; importing; verifying dependencies; retrieving relevantmetadata; checking syntax and semantics; optimizing; compiling; and running. The serverperforms the computational tasks; and once the time frame expires; a message is transmittedto the user indicating which tasks have been completed. The rest of the computational tasksare subsequently performed; and eventually; job results are transmitted to the user.,*,2015,32
Large-scale L-BFGS using MapReduce,Weizhu Chen; Zhenghao Wang; Jingren Zhou,Abstract L-BFGS has been applied as an effective parameter estimation method for variousmachine learning algorithms since 1980s. With an increasing demand to deal with massiveinstances and variables; it is important to scale up and parallelize L-BFGS effectively in adistributed system. In this paper; we study the problem of parallelizing the L-BFGS algorithmin large clusters of tens of thousands of shared-nothing commodity machines. First; we showthat a naive implementation of L-BFGS using Map-Reduce requires either a significantamount of memory or a large number of map-reduce steps with negative performanceimpact. Second; we propose a new L-BFGS algorithm; called Vector-free L-BFGS; whichavoids the expensive dot product operations in the two loop recursion and greatly improvescomputation efficiency with a great degree of parallelism. The algorithm scales very well …,Advances in Neural Information Processing Systems,2014,32
Optimizing parameterized queries in a relational database management system,*,Parameterized queries are optimized by a transformational optimizer. The optimizerproduces a dynamic plan that embeds multiple plan options that may be selected to executea particular query. Parameter distribution improves query execution efficiency andperformance by exploring a sample parameter space representative of the parameter valuesactually used. The dynamic plans can be simplified while maintaining an acceptable level ofoptimality by reducing the number of plan options. The reduction is achieved by eliminatingswitch unions to alternatives that are close in cost. Both approaches of parameter spaceexploration and dynamic plan generation are deeply integrated into the query optimizer.,*,2011,30
Spotting Code Optimizations in Data-Parallel Pipelines through PeriSCOPE.,Zhenyu Guo; Xuepeng Fan; Rishan Chen; Jiaxing Zhang; Hucheng Zhou; Sean McDirmid; Chang Liu; Wei Lin; Jingren Zhou; Lidong Zhou,ABSTRACT To minimize the amount of data-shuffling I/O that occurs between the pipelinestages of a distributed dataparallel program; its procedural code must be optimized with fullawareness of the pipeline that it executes in. Unfortunately; neither pipeline optimizers nortraditional compilers examine both the pipeline and procedural code of a data-parallelprogram so programmers must either hand-optimize their program across pipeline stages orlive with poor performance. To resolve this tension between performance andprogrammability; this paper describes PeriSCOPE; which automatically optimizes a data-parallel program's procedural code in the context of data flow that is reconstructed from theprogram's pipeline topology. Such optimizations eliminate unnecessary code and data;perform early data filtering; and calculate small derived values (eg; predicates) earlier in …,OSDI,2012,29
StreamScope: Continuous Reliable Distributed Processing of Big Data Streams.,Wei Lin; Haochuan Fan; Zhengping Qian; Junwei Xu; Sen Yang; Jingren Zhou; Lidong Zhou,Abstract STREAMSCOPE (or STREAMS) is a reliable distributed stream computation enginethat has been deployed in shared 20;000-server production clusters at Microsoft. STREAMSprovides a continuous temporal stream model that allows users to express complex streamprocessing logic naturally and declaratively. STREAMS supports business-critical streamingapplications that can process tens of billions (or tens of terabytes) of input events per daycontinuously with complex logic involving tens of temporal joins; aggregations; andsophisticated userdefined functions; while maintaining tens of terabytes inmemorycomputation states on thousands of machines. STREAMS introduces two abstractions;rVertex and rStream; to manage the complexity in distributed stream computation systems.The abstractions allow efficient and flexible distributed execution and failure recovery …,NSDI,2016,28
Using query expression signatures in view matching,*,A system for optimizing queries against a database is described. The system comprises amemo structure that encodes a plurality of query expressions. The system also includes asignature mechanism that enables an assignment of the query expressions into equivalenceclasses. Methods of using such a system are additionally provided.,*,2009,28
Efficient maintenance of materialized outer-join views,Per-Ake Larson; Jingren Zhou,Queries containing outer joins are common in data warehousing applications. Materializedouter-join views could greatly speed up many such queries but most database systems donot allow outer joins in materialized views. In part; this is because outer-join views could notpreviously be maintained efficiently when base tables are updated. In this paper we showhow to efficiently maintain general outer-join views; that is; views composed of selection;projection; inner and outer joins. Foreign-key constraints are exploited to reducemaintenance overhead. Experimental results show that maintaining an outer-join view neednot be more expensive than maintaining an inner-join view.,Data Engineering; 2007. ICDE 2007. IEEE 23rd International Conference on,2007,28
Exploiting common subexpressions for cloud query processing,Yasin N Silva; Paul-Ake Larson; Jingren Zhou,Many companies now routinely run massive data analysis jobs--expressed in some scriptinglanguage--on large clusters of low-end servers. Many analysis scripts are complex andcontain common sub expressions; that is; intermediate results that are subsequently joinedand aggregated in multiple different ways. Applying conventional optimization techniques tosuch scripts will produce plans that execute a common sub expression multiple times; oncefor each consumer; which is clearly wasteful. Moreover; different consumers may havedifferent physical requirements on the result: one consumer may want it partitioned on acolumn A and another one partitioned on column B. To find a truly optimal plan; theoptimizer must trade off such conflicting requirements in a cost-based manner. In this paperwe show how to extend a Cascade-style optimizer to correctly optimize scripts containing …,Data Engineering (ICDE); 2012 IEEE 28th International Conference on,2012,27
Scope: a structured computations optimized for parallel execution script language,*,Embodiments of the present invention relate to systems; methods and computer storagemedia for providing Structured Computations Optimized for Parallel Execution (SCOPE) thatfacilitate analysis of a large-scale dataset utilizing row data of those data sets. SCOPEincludes; among other features; an extract command for extracting data bytes from a datastream and structuring the data bytes as data rows having strictly defined columns. SCOPEalso includes a process command and a reduce command that identify data rows as inputs.The reduce command also identifies a reduce key that facilitates the reduction based on thereduce key. SCOPE additionally includes a combine command that identifies two data rowsets that are to be combined based on an identified joint condition. Additionally; SCOPEincludes a select command that leverages SQL and C# languages to create an …,*,2010,27
Parallel computing execution plan optimization,*,The use of statistics collected during the parallel distributed execution of the tasks of a jobmay be used to optimize the performance of the task or similar recurring tasks. An executionplan for a job is initially generated; in which the execution plan includes tasks. Statisticsregarding operations performed in the tasks are collected while the tasks are executed viaparallel distributed execution. Another execution plan is then generated for anotherrecurring job; in which the additional execution plan has at least one task in common withthe execution plan for the job. The additional execution plan is subsequently optimizedbased at least on the statistics to produce an optimized execution plan.,*,2016,25
Transparent mid-tier database caching in sql server,Per-Åke Larson; Jonathan Goldstein; Jingren Zhou,Many applications today are designed for a multi-tier environment typically consisting ofbrowser-based clients; application servers and a backend database server. Applicationservers do not maintain persistent state and typically run on fairly inexpensive machines.Hence; bottlenecks in the application server tier can be solved easily and cheaply byincreasing the number of servers. All persistent state is maintained by the backend databaseserver. A user request may cause tens or even hundreds of queries against the backenddatabase; potentially overwhelming the backend server. One promising way of addressingthis problem is mid-tier database caching; that is; running a local database server on eachapplication server that caches data from the backend database. This allows some queries tobe computed locally.,Proceedings of the 2003 ACM SIGMOD international conference on Management of data,2003,25
Continuous cloud-scale query optimization and processing,Nicolas Bruno; Sapna Jain; Jingren Zhou,Abstract Massive data analysis in cloud-scale data centers plays a crucial role in makingcritical business decisions. High-level scripting languages free developers fromunderstanding various system trade-offs; but introduce new challenges for queryoptimization. One key optimization challenge is missing accurate data statistics; typically dueto massive data volumes and their distributed nature; complex computation logic; andfrequent usage of user-defined functions. In this paper we propose novel techniques toadapt query processing in the Scope system; the cloud-scale computation environment inMicrosoft Online Services. We continuously monitor query execution; collect actual runtimestatistics; and adapt parallel execution plans as the query executes. We discuss similaritiesand differences between our approach and alternatives proposed in the context of …,Proceedings of the VLDB Endowment,2013,24
Cardinality estimation in database systems using sample views,*,A system and method that facilitates and effectuates estimating the result of performing adata analysis operation on a set of data. Employing an approximation of the data analysisoperation on a statistically valid random sample view of the data allows for a statisticallyaccurate estimate of the result to be obtained. Sequential sampling in the view enables theapproximated operation to evaluate accuracy conditions at intervals during the scan of thesample view and obtain the estimated result without having to scan the entire sample view.Feedback regarding the accuracy of the estimated result can be captured when the dataanalysis operation is performed against the set of data. Process control techniques can beemployed with the feedback to maintain the statistical validity of the sample view.,*,2008,21
Stacked indexed views in Microsoft SQL Server,David DeHaan; Per-Ake Larson; Jingren Zhou,Abstract Appropriately selected materialized views (also called indexed views) can speedup query execution by orders of magnitude. Most database systems limit support formaterialized views to select-project-join expressions; possibly with a group-by; over basetables because this class of views can be efficiently maintained incrementally and thus keptup to date with the underlying source tables. However; limiting views to reference only basetables restricts the class of queries that can be supported by materialized views. Viewstacking (also called views on views) relaxes one restriction by allowing a materialized viewto reference both base tables and other materialized views. This extends materialized viewsupport to additional types of queries. This paper describes a prototype implementation ofstacked views within Microsoft SQL Server and explains which classes of queries can be …,Proceedings of the 2005 ACM SIGMOD international conference on Management of data,2005,21
View matching for outer-join views,Per-Åke Larson; Jingren Zhou,Abstract Prior work on computing queries from materialized views has focused on viewsdefined by expressions consisting of selection; projection; and inner joins; with an optionalaggregation on top (SPJG views). This paper provides the first view matching algorithm forviews that may also contain outer joins (SPOJG views). The algorithm relies on a normalform for SPOJ expressions and does not use bottom-up syntactic matching of expressions. Ithandles any combination of inner and outer joins; deals correctly with SQL bag semanticsand exploits not-null constraints; uniqueness constraints and foreign key constraints.,Proceedings of the 31st international conference on Very large data bases,2005,20
Recurring job optimization in scope,Nicolas Bruno; Sameer Agarwal; Srikanth Kandula; Bing Shi; Ming-Chuan Wu; Jingren Zhou,An increasing number of applications require distributed data storage and processinginfrastructure over large clusters of commodity hardware for critical business decisions. TheMapReduce programming model [2] helps programmers write distributed applications onlarge clusters; but requires dealing with complex implementation details (eg; reasoning withdata distribution and overall system configuration). Recent proposals; such as SCoPE [1];raise the level of abstraction by providing a declarative language that not only increasesprogramming productivity but is also amenable to sophisticated optimization. Like intraditional database systems; such optimization relies on detailed data statistics to choosethe best execution plan in a cost-based fashion. However; in contrast to database systems; itis very difficult to obtain and maintain good quality statistics in a highly distributed …,Proceedings of the 2012 ACM SIGMOD International Conference on Management of Data,2012,19
View matching for outer-join views,Per-Åke Larson; Jingren Zhou,Abstract Prior work on computing queries from materialized views has focused on viewsdefined by expressions consisting of selection; projection; and inner joins; with an optionalaggregation on top (SPJG views). This paper provides a view matching algorithm for viewsthat may also contain outer joins (SPOJG views). The algorithm relies on a normal form forouter-join expressions and is not based on bottom-up syntactic matching of expressions. Ithandles any combination of inner and outer joins; deals correctly with SQL bag semantics;and exploits not-null constraints; uniqueness constraints and foreign key constraints.,The VLDB Journal—The International Journal on Very Large Data Bases,2007,19
Transparent lazy maintenance of indexes and materialized views,*,Described herein is a materialized view or index maintenance system that includes a taskgenerator component that receives an indication that an update transaction has committedagainst a base table in a database system. The task generator component; in response tothe update transaction being received; generates a maintenance task for one or more of amaterialized view or an index that is affected by the update transaction. A maintenancecomponent transparently performs the maintenance task when a workload of a CPU in thedatabase system is below a threshold or when an indication is received that a query thatuses the one or more of the materialized view or the index has been received.,*,2009,18
Maintenance of materialized outer-join views,*,Maintenance of materialized view for query optimization in a database. The architectureprovides the first practical algorithms for incrementally maintaining views with multiple outerjoins and aggregated outer-join views. Materialized views with any combination of innerjoins; one-sided outer joins and full outer joins; plus an optional aggregation on top; can beprocessed by algorithm (s) that construct incremental maintenance expressions based onconverting the view definition a join-disjunctive normal form and exploiting databaseconstraints to reduce maintenance overhead. A system comprises a view creationcomponent for creating a materialized view definition that includes outer-joins; a conversioncomponent for converting an outer-join view expression into a normal form; and amaintenance component for updating the stored materialized view result associated with …,*,2008,13
Sampling based range partition methods for big data analytics,Milan Vojnovic; Fei Xu; Jingren Zhou,Abstract–Big Data Analytics requires partitioning datasets into thousands of partitionsaccording to a specific set of keys so that different machines can process different partitionsin parallel. Range partition is one of the ways to partition the data that is needed wheneverglobal ordering is required. It partitions the data according to a pre-defined set of exclusiveand continuous ranges that covers the entire domain of the partition key. Providing high-quality (approximately equal-sized) partitions is a key problem for the big data analyticsbecause the job latency is determined by the most loaded node. This problem is especiallychallenging because typically no statistics about the key distribution over machines for aninput dataset is available at the beginning of a range partition. The system needs to find away to determine the partition boundaries that is both cost-effective and accurate. This …,Technical Report MSR-TR-2012-18,2012,10
View matching for materialized outer-join views,*,A computer implemented system that facilitates view matching for outer join views comprisesan interface component that receives at least one query that includes one or more outer joinoperators. A view matching-component converts the at least one query and outputs asubstitute query expression. In accordance with one aspect of the subject invention; the view-matching component can comprise a normalization component that converts the at least onequery and at least one materialized view into a normalized query expression and anormalized view expression. Furthermore; the view-matching component can include ananalysis component that receives the normalized query expression and the normalized viewexpression; and a construction component that constructs the substitute query expression.,*,2008,9
Partially materialized views,Jingren Zhou; P Larson; Jonathan Goldstein,Judicious use of materialized views can speed up the processing of some queries byseveral orders of magnitude. The idea of using materialized views to speed up queryprocessing is more than twenty years old [19; 23] and all major database systems (DB2;Oracle; SQL Server) now support materialized views [2; 24; 5]. The support included in thosesystems consists of computing; materializing; and maintaining all rows of the view result andwill be referred to as fully materialized views. Since fully materialized views store andmaintain all their rows; storage cost may be high for large views and maintenance can becostly for frequently updated views. If only a small subset of the fully materialized view isused over a period of time; disk storage is wasted for the unused records and many recordsthat are never used are unnecessarily kept up to date. In current systems; it is very …,submitted to this conference,2005,7
Exploiting partitioning; grouping; and sorting in query optimization,*,An optimizer uses comprehensive reasoning regarding partitioning; sorting; and groupingproperties for query optimization. When optimizing an input query expression; logicalexploration generates alternative logical expressions. Physical optimization exploresphysical operator alternatives for logical operators. Required partitioning; sorting; andgrouping properties of inputs to physical operators are determined. Additionally; deliveredpartitioning; sorting; and grouping properties of outputs from physical operators aredetermined. In some embodiments; enforcer rules are employed to modify structural propertyrequirements to introduce alternatives for consideration. Property matching identifies validexecution plans in which the delivered partitioning; sorting; and grouping properties satisfycorresponding required partitioning; sorting; and grouping properties. An execution plan …,*,2014,6
View matching of materialized XML views,*,A materialized XML view matching system and method for processing of SQLXML queriesusing view matching of materialized XML views. The view matching process of theembodiments of the system and method use a multi-path tree (MPT) data structure.Embodiments of the materialized XML view matching system and method construct an MPTdata structure for each input query and view expression. View matching is performed on theMPT data structures to generate a set of partial matches; which then are cleaned to generatea set of candidate matches. A valid match definition is generated by testing each candidatematch for different forms of compliance. Using the valid match definition; a set of validmatches is identified and extracted. For each valid match; a substitute query expression isconstructed that can serve as a replacement for the original query. These substitute …,*,2013,6
Architecture Sensitive Database Design: Examples from the Columbia Group.,Kenneth A Ross; John Cieslewicz; Jun Rao; Jingren Zhou,In this article; we discuss how different aspects of modern CPU architecture can beeffectively used by database systems. While we shall try to cover most important aspects ofmodern architectures; we shall not aim to provide an exhaustive survey of the literature.Rather; we will use examples from our own recent work to illustrate the principles involved.While there is related work on using other components of modern machines such asgraphics cards and intelligent disk controllers for database work; we limit our discussionhere to just a single CPU and the memory hierarchy (excluding disks). In recent years theprimary focus of database performance research has fundamentally shifted from disks tomain memory. Systems with a very large main memory allow a database's working set to fitin RAM. At the same time processors have continued to double in performance roughly …,IEEE Data Eng. Bull.,2005,6
Analyzing multiple data streams as a single data object,*,Embodiments of the present invention allow multiple data streams to be analyzed as asingle data set. The single data set may be described as a stream set herein. The multiplestreams that are included in the stream set may be specified through a user script or query.For example; a query may be used to gather all streams created within a date range. Thequery could include one or more filters to gather certain information from the data streams orto exclude certain data streams that otherwise are in the query's range. A stream may be anunstructured byte stream of data. The stream may be created by append-only writing to theend of the stream. The stream could also be a structured stream that includes metadata thatdefines column structure and affinity/clustering information.,*,2014,5
Data mining survey,Qin Ding; Maria Canton; David Diaz; Qinghua Zou; Baojing Lu; A Roy; J Zhou; Q Wei; A Habib; MA Khan,*,Computer Science Dept.; North Dakota State University. See http://midas. cs. ndsu. nodak. edu/~ ding/datamining/dm-survey. doc,2000,5
Nested loop join,Jingren Zhou,The simplest way to incorporate unknown values into the relational model; is to allowvariables; in addition to constants; as entries in the columns of relations. Such constructs arecalled tables; instead of relations. A table is an incomplete database; and represents a set ofcomplete databases; each obtained by substituting all variables with constants. Differentoccurrences of the same variable (marked null) are substituted with the same constant. Thesubstitution is thus a function from the variables and constants; to the constants; such thatthe function is identity on the constants. A table T then represents the set of relations;denoted rep (T); defined as {v (T): v is a valuation}. Then the certain answer to a query q on atable T; denoted sure (q; T) is the set of tuples that occur in every answer obtained byapplying the query to every database in rep (T). In other words; the certain answer to q on …,*,2009,4
Sort-merge join,Jingren Zhou,The values in the relations of a relational database are elements of one or more underlyingsets called domains. In practical applications; a domain may be infinite; eg; the set of naturalnumbers. In this case; the value of a relational calculus query when applied to such adatabase may be infinite; eg;{njn! 10}. A query Q is called finite if the value of Q whenapplied to any database is finite. Even when the database domains are finite; all that isnormally known about them is that they are some finite superset of the values that occur inthe database. In this case; the value of a relational calculus query may depend on such anunknown domain; eg;{xj 8yR (x; y)}. A query Q is called domain independent if the value of Qwhen applied to any database is the same for any two domains containing the databasevalues or; equivalently; if the value of Q when applied to a database contains only values …,*,2009,4
Architecture-sensitive database query processing,Jingren Zhou,ABSTRACT During the last decade; microprocessors have experienced tremendousimprovement. This architectural growth has not been equally distributed over all aspects ofhardware performance. Recent advances in the speed of commodity CPUs have faroutpaced advances in memory latency. Main memory access is therefore becoming asignificant cost component of database operations. Database systems face newperformance bottlenecks; such as memory access and poor utilization of sophisticatedexecution hardware. Research has shown that the DBMS hardware behavior is suboptimal;compared with scientific workloads. This illustrates the importance of rethinking anddeveloping database query processing algorithms in the context of new computerarchitectures. This thesis focuses on studying interactions between DBMSs and modern …,*,2004,4
Efficient partitioning techniques for massively distributed computation,*,A repartitioning optimizer identifies alternative repartitioning strategies and selects optimalones; accounting for network transfer utilization and partition sizes in addition to traditionalmetrics. If prior partitioning was hash-based; the repartitioning optimizer can determinewhether a hash-based repartitioning can result in not every computing device providing datato every other computing device. If prior partitioning was range-based; the repartitioningoptimizer can determine whether a range-based repartitioning can generate similarly sizedoutput partitions while aligning input and output partition boundaries; increasing the numberof computing devices that do not provide data to every other computing device. Individualcomputing devices; as they are performing a repartitioning; assign a repartitioning index toeach individual data element; which represents the computing device to which such a …,*,2015,3
Exploiting self-monitoring sample views for cardinality estimation,Per-Ake Larson; Wolfgang Lehner; Jingren Zhou; Peter Zabback,Abstract Good cardinality estimates are critical for generating good execution plans duringquery optimization. Complex predicates; correlations between columns; and user-definedfunctions are extremely hard to handle when using the traditional histogram approach. Thisdemo illustrates the use of sample views for cardinality estimations as prototyped inMicrosoft SQL Server. We show the creation of sample views; discuss how they areexploited during query optimization; and explain their potential effect on query plans. Inaddition; we also show our implementation of maintenance policies using statistical qualitycontrol techniques based on query feedback.,Proceedings of the 2007 ACM SIGMOD international conference on Management of data,2007,3
Spotting code optimizations in data-parallel pipelines through periscope,Xuepeng Fan; Zhenyu Guo; Hai Jin; Xiaofei Liao; Jiaxing Zhang; Hucheng Zhou; Sean McDirmid; Wei Lin; Jingren Zhou; Lidong Zhou,To minimize the amount of data-shuffling I/O that occurs between the pipeline stages of adistributed data-parallel program; its procedural code must be optimized with full awarenessof the pipeline that it executes in. Unfortunately; neither pipeline optimizers nor traditionalcompilers examine both the pipeline and procedural code of a data-parallel program soprogrammers must either hand-optimize their program across pipeline stages or live withpoor performance. To resolve this tension between performance and programmability; thispaper describes PeriSCOPE; which automatically optimizes a data-parallel program'sprocedural code in the context of data flow that is reconstructed from the program's pipelinetopology. Such optimizations eliminate unnecessary code and data; perform early datafiltering; and calculate small derived values (eg; predicates) earlier in the pipeline; so that …,IEEE Transactions on Parallel and Distributed Systems,2015,2
Recurring Job Optimization for Massively Distributed Query Processing.,Nicolas Bruno; Sapna Jain; Jingren Zhou,Abstract Companies providing cloud-scale data services have increasing needs to store andanalyze massive data sets. For cost and performance reasons; processing is typically doneon large clusters of tens of thousands of commodity machines. Developers use high-levelscripting languages that simplify understanding various system trade-offs; but introduce newchallenges for query optimization. One key optimization challenge is missing accurate datastatistics; typically due to massive data volumes and their distributed nature; complexcomputation logic; and frequent usage of user-defined functions. In this paper we describe atechnique to optimize a class of jobs that are recurring over time in a cloud-scalecomputation environment. By leveraging information gathered during previous executionswe are able to obtain accurate statistics for new instances of recurring jobs; resulting in …,IEEE Data Eng. Bull.,2013,2
Hash Join,Jingren Zhou,A hash function is a well-defined deterministic algorithm that takes as input data of arbitrarylength and produces a short fixed-length digital representation of the data; or a digest; as itsoutput. The output of a hash function can serve the role of a digital ''fingerprint''of the inputdata; as an important design property of hash functions is that of collision resilience: twohashes produced on different inputs are very unlikely to result in the same value.Furthermore; given a hash function output; it is normally infeasible to find a (previouslyunseen) input that matches that output (this property is called preimage resistance).,*,2009,2
Distributed stream processing in the cloud,*,A low-latency cloud-scale computation environment includes a query language;optimization; scheduling; fault tolerance and fault recovery. An event model can be used toextend a declarative query language so that temporal analysis of event of an event streamcan be performed. Extractors and outputters can be used to define and implement functionsthat extend the capabilities of the event-based query language. A script written in theextended query language can be translated into an optimal parallel continuous executionplan. Execution of the plan can be orchestrated by a streaming job manager whichschedules vertices on available computing machines. The streaming job manager canmonitor overall job execution. Fault tolerance can be provided by tracking executionprogress and data dependencies in each vertex. In the event of a failure; another instance …,*,2017,1
JetScope: reliable and interactive analytics at cloud scale,Eric Boutin; Paul Brett; Xiaoyu Chen; Jaliya Ekanayake; Tao Guan; Anna Korsun; Zhicheng Yin; Nan Zhang; Jingren Zhou,Abstract Interactive; reliable; and rich data analytics at cloud scale is a key capability tosupport low latency data exploration and experimentation over terabytes of data for a widerange of business scenarios. Besides the challenges in massive scalability and low latencydistributed query processing; it is imperative to achieve all these requirements with effectivefault tolerance and efficient recovery; as failures and fluctuations are the norm in such adistributed environment. We present a cloud scale interactive query processing system;called JetScope; developed at Microsoft. The system has a SQL-like declarative scriptinglanguage and delivers massive scalability and high performance through advancedoptimizations. In order to achieve low latency; the system leverages various accessmethods; optimizes delivering first rows; and maximizes network and scheduling …,Proceedings of the VLDB Endowment,2015,1
Affinitizing datasets based on efficient query processing,*,Embodiments of the present invention relate to systems; methods; and computer-storagemedia for affinitizing datasets based on efficient query processing. In one embodiment; aplurality of datasets within a data stream is received. The data stream is partitioned based onefficient query processing. Once the data stream is partitioned; an affinity identifier isassigned to datasets based on the partitioning of the dataset. Further; when datasets arebroken into extents; the affinity identifier of the parent dataset is retained in the resultingextent. The affinity identifier of each extent is then referenced to preferentially store extentshaving common affinity identifiers within close proximity of one other across a data center.,*,2014,1
Data Engineering,Per-Ake Larson; Jonathan Goldstein; Hongfei Guo; Jingren Zhou,The Bulletin of the Technical Committee on Data Engineering is published quarterly and isdistributed to all TC members. Its scope includes the design; implementation; modelling;theory and application of database systems and their technology. Letters; conferenceinformation; and news should be sent to the Editor-in-Chief. Papers for each issue aresolicited by and should be sent to the Associate Editor responsible for the issue. Opinionsexpressed in contributions are those of the authors and do not necessarily reflect thepositions of the TC on Data Engineering; the IEEE Computer Society; or the authors'organizations. Membership in the TC on Data Engineering is open to all current members ofthe IEEE Computer Society who are interested in database systems. There are two DataEngineering Bulletin web sites: http://www. research. microsoft. com/research/db/debull …,Ann Arbor,*,1
Continuous cloud-scale query optimization and processing,*,Abstract Runtime statistics from the actual performance of operations on a set of data arecollected and utilized to dynamically modify the execution plan for processing a set of data.The operations performed are modified to include statistics collection operations; thestatistics being tailored to the specific operations being quantified. Optimization policydefines how often optimization is attempted and how much more efficient an execution planshould be to justify transitioning from the current one. Optimization is based on the collectedruntime statistics but also takes into account already materialized intermediate data to gainfurther optimization by avoiding reprocessing.,*,2017,*
Distributed stage-wise parallel machine learning,*,Abstract A method for machine learning a data set in a data processing framework isdisclosed. A forest is trained with the data set that generates a plurality of trees in parallel.Each tree includes leaf nodes having a constant weight. A discriminative value for each leafnode is learned with a supervised model. The forest is reconstructed with the discriminativevalues replacing the constant weight for each leaf node.,*,2017,*
Distributed stream processing in the cloud,*,Abstract A low-latency cloud-scale computation environment includes a query language;optimization; scheduling; fault tolerance and fault recovery. An event model can be used toextend a declarative query language so that temporal analysis of event of an event streamcan be performed. Extractors and outputters can be used to define and implement functionsthat extend the capabilities of the event-based query language. A script written in theextended query language can be translated into an optimal parallel continuous executionplan. Execution of the plan can be orchestrated by a streaming job manager whichschedules vertices on available computing machines. The streaming job manager canmonitor overall job execution. Fault tolerance can be provided by tracking executionprogress and data dependencies in each vertex. In the event of a failure; another instance …,*,2017,*
Processing requests for multi-versioned service,*,Processing received job requests for a multi-versioned distributed computerized service. Foreach received job request; the job request is channeled to an appropriate serviceprocessing node that depends on the version of the distributed computing service that is tohandle the job request. A version of the distributed computing service is assigned to theincoming job request. A service processing node that runs a runtime library for the assignedservice version is then identified. The identified service processing node also has anappropriate set of one or more executables that allows the service processing node to planan appropriate role (eg; compiler; scheduler; worker) in the distributed computing service.The job request is then dispatched to the identified service processing node.,*,2017,*
Processing requests for multi-versioned service,*,Processing a job request for multiple versions of a distributed computing service. Theservice processing node does this by at least interleavingly (eg; via time sharing with rapidcontext switching; or by actually concurrently) running a first runtime library associated with afirst service version of the distributed computerized service and a second runtime libraryassociated with a different service version of the distributed computerized service. Whilerunning the first runtime library; job requests of a first service version may be at least partiallyprocessed using a first set of one or more executables that interact with the first runtimelibrary. While running the second runtime library; job requests of a second service versionmay be at least partially processed using a second set of one or more executables thatinteract with the second runtime library.,*,2017,*
Job scheduling using expected server performance information,*,A job scheduler that schedules ready tasks amongst a cluster of servers. Each job might bemanaged by one scheduler. In that case; there are multiple job schedulers which conductscheduling for different jobs concurrently. To identify a suitable server for a given task; thejob scheduler uses expected server performance information received from multiple servers.For instance; the server performance information might include expected performanceparameters for tasks of particular categories if assigned to the server. The job managementcomponent then identifies a particular task category for a given task; determines which of theservers can perform the task by a suitable estimated completion time; and then assignsbased on the estimated completion time. The job management component also uses cluster-level information in order to determine which server to assign a task to.,*,2016,*
Publication list,Jia Wang,Advanced Materials; 22; 3017-3021 (2010) (Highlighted on the front inside cover of thejournal) … Kyojiro Morikawa; Kazuma Mawatari; Masaru Kato; Takehiko Tsukahara; and TakehikoKitamori … Development of a Micro-Potentiometric Sensor for the Microchip Analysis of AlkaliIons Adelina SMIRNOVA; Kazuma MAWATARI; Hiroko TAKAHASHI; Yo TANAKA; HiroakiNAKANISHI; and Takehiko KITAMORI. Analytical Sciences; 25(12); 1397-1402 (2009) … Graftlinker immobilization for spatial control of protein immobilization inside fused microchips K.Shirai; B. Renberg; K. Sato; K. Mawatari; T. Konno; K. Ishihara; and T. Kitamori.Electrophoresis; 30(24); 4251-4255 (2009) … Development of Differential Interference ContrastThermal Lens Microscope (DIC-TLM) for Sensitive Individual Nanoparticle Detection in LiquidHisashi Shimizu; Kazuma Mawatari; and Takehiko Kitamori Analytical Chemistry; 81(23) …,Electrophoresis,2012,*
Scope playback: self-validation in the cloud,Ming-Chuan Wu; Jingren Zhou; Nicolas Bruno; Yu Zhang; Jon Fowler,Abstract The last decade witnessed the emergence of various distributed storage andcomputation systems for cloud-scale data processing. Scope is the distributed computationplatform targeted for a variety of data analysis and data mining applications; powering Bingand other online services at Microsoft. Scope combines benefits of both traditional paralleldatabases and MapReduce execution engines to allow easy programmability. It features aSQL-like declarative scripting language with .NET extensions; and delivers massivescalability and high performance through advanced optimization. Scope currently operatesover tens of thousands of machines and processes over a million jobs per month. Suchmassive data computation platform presents new challenges and opportunities for efficientand effective testing and validation. Traditional approaches for testing database systems …,Proceedings of the Fifth International Workshop on Testing Database Systems,2012,*
Evaluation of Relational Operators,Jingren Zhou,Definition eAccessibility refers to the access of Information and CommunicationTechnologies (ICT) by people with disabilities; with particular emphasis on the World WideWeb. It is the extent to which the use of an application or service is affected by the user'sparticular functional limitations or abilities (permanent or temporary). eAccessibility can beconsidered as a fundamental prerequisite of usability.,*,2009,*
Index Join,Jingren Zhou,An example of index oriented towards human navigation is the web directory. In such anindex; links to sites are organized into hierarchical categories; according to the sites'contents. In web directories; normally the tasks of collecting and categorizing pages arecarried out under supervision of human editors. An example of index not oriented to humansis a hidden list of metadata. Metadata are data about data. As a mean of assisting a searchengine to locate content or an information entity; they can be used to describe that content orentity. While not visible to humans; this information can provide contextual clues to automaticalgorithms used by search engines.,*,2009,*
MTCache: Mid-Tier Database Caching for SQL Server,Per-Ake Larson Jonathan Goldstein; Hongfei Guo; Jingren Zhou,Abstract MTCache is a prototype mid-tier database caching solution for SQL Server thattransparently offloads part of the query workload from a backend server to front-end servers.The goal is to improve system throughput and scalability but without requiring applicationchanges. This paper outlines the architecture of MTCache and highlights several of its keyfeatures: modeling of data as materialized views; integration with query optimization; andsupport for queries with explicit data currency and consistency requirements.,Data Engineering,2004,*
Data Engineering,Kenneth A Ross; John Cieslewicz; Jun Rao; Jingren Zhou,The Bulletin of the Technical Committee on Data Engineering is published quarterly and isdistributed to all TC members. Its scope includes the design; implementation; modelling;theory and application of database systems and their technology. Letters; conferenceinformation; and news should be sent to the Editor-in-Chief. Papers for each issue aresolicited by and should be sent to the Associate Editor responsible for the issue. Opinionsexpressed in contributions are those of the authors and do not necessarily reflect thepositions of the TC on Data Engineering; the IEEE Computer Society; or the authors'organizations. Membership in the TC on Data Engineering is open to all current members ofthe IEEE Computer Society who are interested in database systems. There are two DataEngineering Bulletin web sites: http://www. research. microsoft. com/research/db/debull …,Ann Arbor,*,*
Transparent Mid-Tier Database Caching in SQL Server,Per-Åke Larson Jonathan Goldstein; Jingren Zhou,Many applications today are designed for a multi-tier environment typically consisting ofbrowser-based clients; application servers and a backend database server. Applicationservers do not maintain persistent state and typically run on fairly inexpensive machines.Hence; bottlenecks in the application server tier can be solved easily and cheaply byincreasing the number of servers. All persistent state is maintained by the backend databaseserver. A user request may cause tens or even hundreds of queries against the backenddatabase; potentially overwhelming the backend server. One promising way of addressingthis problem is mid-tier database caching; that is; running a local database server on eachapplication server that caches data from the backend database. This allows some queries tobe computed locally.,*,*,*
