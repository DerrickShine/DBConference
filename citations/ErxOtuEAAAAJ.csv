Data summaries for on-demand queries over linked data,Andreas Harth; Katja Hose; Marcel Karnstedt; Axel Polleres; Kai-Uwe Sattler; Jürgen Umbrich,Abstract Typical approaches for querying structured Web Data collect (crawl) and pre-process (index) large amounts of data in a central data repository before allowing for queryanswering. However; this time-consuming pre-processing phase however leverages thebenefits of Linked Data--where structured data is accessible live and up-to-date atdistributed Web resources that may change constantly--only to a limited degree; as queryresults can never be current. An ideal query answering system for Linked Data should returncurrent answers in a reasonable amount of time; even on corpora as large as the Web.Query processors evaluating queries directly on the live sources require knowledge of thecontents of data sources. In this paper; we develop and evaluate an approximate indexstructure summarising graph-structured content of sources adhering to Linked Data …,Proceedings of the 19th international conference on World wide web,2010,204
Datenbanken: Implementierungstechniken,Gunter Saake; Andreas Heuer,*,*,1999,201
Report on the dagstuhl seminar,Michael Gertz; M Tamer Özsu; Gunter Saake; Kai-Uwe Sattler,Over the past few years; techniques for managing; querying; and integrating data on theWeb have significantly matured. Well-founded and practical approaches to assess or evenguarantee a required degree of quality of the data in these frameworks; however; are stillmissing. This can be contributed to the lack of welldefined data quality metrics andassessment techniques; and the difficulty of handling information about data quality duringdata integration and query processing. Data quality problems arise in many settings; such asthe integration of business data; in Web mining; data dissemination; and in querying theWeb using search engines. Data quality (DQ) addresses various forms of data; includingstructured and semistructured data; text documents; multimedia; and streaming data.Different forms of metadata describing the quality of data is becoming increasingly …,ACM SIGMOD Record,2004,116
SQL database primitives for decision tree classifiers,Kai-Uwe Sattler; Oliver Dunemann,Abstract Scalable data mining in large databases is one of today's challenges to databasetechnologies. Thus; substantial effort is dedicated to a tight coupling of database and datamining systems leading to database primitives supporting data mining tasks. In order tosupport a wide range of tasks and to be of general usage these primitives should be ratherbuilding blocks than implementations of specific algorithms. In this paper; we describeprimitives for building and applying decision tree classifiers. Based on the analysis ofavailable algorithms and previous work in this area we have identified operations which areuseful for a number of classification algorithms. We discuss the implementation of theseprimitives on top of a commercial DBMS and present experimental results demonstrating theperformance benefit.,Proceedings of the tenth international conference on Information and knowledge management,2001,81
Adding Conflict Resolution Features to a Query Language for Database Federations.,Kai-Uwe Sattler; Stefan Conrad; Gunter Saake,Abstract A main problem of data integration is the treatment of conflicts caused by differentmodeling of real-world entities; different data models or simply by different representations ofone and the same object. During the integration phase these conflicts have to be identifiedand resolved as part of the mapping between local and global schemata. Therefore; conflictresolution affects the definition of the integrated view as well as query transformation andevaluation. In this paper we present a SQL extension for defining and querying databasefederations. This language addresses in particular the resolution of integration conflicts byproviding mechanisms for mapping attributes; restructuring relations as well as extendedintegration operations. Finally; the application of these resolution strategies is brieflyexplained by presenting a simple conflict resolution method.,EFIS,2000,80
The mixed workload CH-benCHmark,Richard Cole; Florian Funke; Leo Giakoumakis; Wey Guy; Alfons Kemper; Stefan Krompass; Harumi Kuno; Raghunath Nambiar; Thomas Neumann; Meikel Poess; Kai-Uwe Sattler; Michael Seibold; Eric Simon; Florian Waas,Abstract While standardized and widely used benchmarks address either operational or real-time Business Intelligence (BI) workloads; the lack of a hybrid benchmark led us to thedefinition of a new; complex; mixed workload benchmark; called mixed workload CH-benCHmark. This benchmark bridges the gap between the established single-workloadsuites of TPC-C for OLTP and TPC-H for OLAP; and executes a complex mixed workload: atransactional workload based on the order entry processing of TPC-C and a correspondingTPC-H-equivalent OLAP query suite run in parallel on the same tables in a single databasesystem. As it is derived from these two most widely used TPC benchmarks; the CH-benCHmark produces results highly relevant to both hybrid and classic single-workloadsystems.,Proceedings of the Fourth International Workshop on Testing Database Systems,2011,72
Algorithmen und Datenstrukturen: Eine Einführung mit Java,Gunter Saake; Kai-Uwe Sattler,*,*,2014,70
Processing relaxed skylines in PDMS using distributed data summaries,Katja Hose; Christian Lemke; Kai-Uwe Sattler,Abstract Peer Data Management Systems (PDMS) are a natural extension of heterogeneousdatabase systems. One of the main tasks in such systems is efficient query processing.Insisting on complete answers; however; leads to asking almost every peer in the network.Relaxing these completeness requirements by applying approximate query answeringtechniques can significantly reduce costs. Since most users are not interested in the exactanswers to their queries; rank-aware query operators like top-k or skyline play an importantrole in query processing. In this paper; we present the novel concept of relaxed skylines thatcombines the advantages of both rank-aware query operators and approximate queryprocessing techniques. Furthermore; we propose a strategy for processing relaxed skylinesin distributed environments that allows for giving guarantees for the completeness of the …,Proceedings of the 15th ACM international conference on Information and knowledge management,2006,69
Efficient similarity-based operations for data integration,Eike Schallehn; Kai-Uwe Sattler; Gunter Saake,Abstract Dealing with discrepancies in data is still a big challenge in data integrationsystems. The problem occurs both during eliminating duplicates from semantic overlappingsources as well as during combining complementary data from different sources. Thoughusing SQL operations like grouping and join seems to be a viable way; they fail if theattribute values of the potential duplicates or related tuples are not equal but only similar bycertain criteria. As a solution to this problem; we present in this paper similarity-basedvariants of grouping and join operators. The extended grouping operator produces groups ofsimilar tuples; the extended join combines tuples satisfying a given similarity condition. Wedescribe the semantics of this operator; discuss efficient implementations for the editdistance similarity and present evaluation results. Finally; we give examples of …,Data & Knowledge Engineering,2004,63
Speeding up queries in column stores,Christian Lemke; Kai-Uwe Sattler; Franz Faerber; Alexander Zeier,Abstract BI accelerator solutions like the SAP NetWeaver database engine TREX achievehigh performance when processing complex analytic queries in large data warehouses.They do so with a combination of column-oriented data organization; memory-basedprocessing; and a scalable multiserver architecture. The use of data compressiontechniques further reduces both memory consumption and processing time. In this paper westudy query operators like scan and aggregation on compressed data structuresimplemented in TREX.,International Conference on Data Warehousing and Knowledge Discovery,2010,61
Autonomous management of soft indexes,Martin Luhring; Kai-Uwe Sattler; Karsten Schmidt; Eike Schallehn,In recent years the support for index tuning as pan of physical database design has gainedfocus in research and product development; which resulted in index and design advisors.Nevertheless; these tools provide a one-off solution for a continuous task and are not deeplyintegrated with the DBMS functionality by only applying the query optimizer for indexrecommendation and profit estimation and decoupling the decision about and execution ofindex configuration changes from the core system functionality. In this paper we propose anapproach that continuously collects statistics for recommended indexes and based on this;repetitively solves the Index Selection Problem (lSP). A key novelty is the on-the-fly indexgeneration during query processing implemented by new query plan operators In-dexBuildScan and SwitchPlan. Finally; we present the implementation and evaluation of …,Data Engineering Workshop; 2007 IEEE 23rd International Conference on,2007,61
Distributed databases and peer-to-peer databases: past and present,Angela Bonifati; Panos K Chrysanthis; Aris M Ouksel; Kai-Uwe Sattler,Abstract The need for large-scale data sharing between autonomous and possiblyheterogeneous decentralized systems on the Web gave rise to the concept of P2P databasesystems. Decentralized databases are; however; not new. Whereas a definition for a P2Pdatabase system can be readily provided; a comparison with the more establisheddecentralized models; commonly referred to as distributed; federated and multi-databases;is more likely to provide a better insight to this new P2P data management technology. Thus;in the paper; by distinguishing between db-centric and P2P-centric features; we examinefeatures common to these database systems as well as other ad-hoc features that solelycharacterize P2P databases. We also provide a non-exhaustive taxonomy of the mostprominent research efforts toward the realization of full-fledged P2P databases.,ACM SIGMOD Record,2008,58
A data preparation framework based on a multidatabase language,K-U Sattler; Eike Schallehn,Integration and analysis of data from different sources have to deal with several problemsresulting from potential heterogeneities. The activities addressing these problems are calleddata preparation and are supported by various available tools. However; these tools processmostly in a batch-like manner; not supporting the iterative and explorative nature of theintegration and analysis process. The authors present a framework for important datapreparation tasks based on a multidatabase language. This language offers features forsolving common integration and cleaning problems as part of query processing. Combiningdata preparation mechanisms and multidatabase query facilities permits applying andevaluating different integration and cleaning strategies without explicit loading andmaterialization of data. The paper introduces the language concepts and discusses their …,Database Engineering and Applications; 2001 International Symposium on.,2001,57
Unistore: Querying a dht-based universal storage,Marcel Karnstedt; Kai-Uwe Sattler; Martin Richtarsky; Jessica Muller; Manfred Hauswirth; Roman Schmidt; Renault John,The idea of collecting and combining large public data sets and services became more andmore popular. The special characteristics of such systems and the requirements of theparticipants demand for strictly decentralized solutions. However; this comes along withseveral ambitious challenges a corresponding system has to overcome. In thisdemonstration paper; we present a lightweight distributed universal storage capable ofdealing with those challenges; and providing a powerful and flexible way of building Internet-scale public data management systems. We introduce our approach based on a triplestorage on top of a distributed hash table (DHT) overlay system; based on the ideas of auniversal relation model and the resource description framework (RDF); and outline solvedchallenges as well as open issues.,Data Engineering; 2007. ICDE 2007. IEEE 23rd International Conference on,2007,55
Concept-based querying in mediator systems,Kai-Uwe Sattler; Ingolf Geist; Eike Schallehn,Abstract One approach to overcoming heterogeneity as a part of data integration in mediatorsystems is the use of metadata in the form of a vocabulary or ontology to represent domainknowledge explicitly. This requires including this meta level during query formulation andprocessing. In this paper; we address this problem in the context of a mediator that uses aconcept-based integration model and an extension of the XQuery language called CQuery.This mediator has been developed as part of a project for integrating data about culturalassets. We describe the language extensions and their semantics as well as the rewritingand evaluation steps. Furthermore; we discuss aspects of caching and keyword-basedsearch in support of an efficient query formulation and processing.,The VLDB Journal—The International Journal on Very Large Data Bases,2005,53
-QUIET: Continuous Query-driven Index Tuning** This research was partially supported by the DFG (FOR 345/1).,Kai-Uwe Sattler; Ingolf Geist; Eike Schallehn,This chapter presents a middleware-based approach supporting such query-driven indextuning. Index tuning as part of database tuning is the task of selecting and creating indexeswith the goal of reducing query-processing times. However; in dynamic environments withvarious ad-hoc queries; it is difficult to identify potential useful indexes in advance. Thischapter presents the tool QUIET addressing this problem. This tool “intercepts” queries and—based on a cost model as well as runtime statistics about profits of index configurations—decides about index creation automatically at runtime. In this way; index tuning is driven byqueries without explicit actions of the database users. This approach is used to improve theresponse time for a sequence of queries by dynamically creating additional indexes withoutexplicit intervention of a user or DBA.QUIET: Continuous Query-driven Index Tuning* Kai …,*,2003,53
Efficient co-processor utilization in database query processing,Sebastian Breß; Felix Beier; Hannes Rauhe; Kai-Uwe Sattler; Eike Schallehn; Gunter Saake,Abstract Specialized processing units such as GPUs or FPGAs provide great opportunities tospeed up database operations by exploiting parallelism and relieving the CPU. However;distributing a workload on suitable (co-) processors is a challenging task; because of theheterogeneous nature of a hybrid processor/co-processor system. In this paper; we presenta framework that automatically learns and adapts execution models for arbitrary algorithmson any (co-) processor. Our physical optimizer uses the execution models to distribute aworkload of database operators on available (co-) processing devices. We demonstrate itsapplicability for two common use cases in modern database systems. Additionally; wecontribute an overview of GPU-co-processing approaches; an in-depth discussion of ourframework's operator model; the required steps for deploying our framework in practice …,Information Systems,2013,52
Extensible and similarity-based grouping for data integration,Eike Schallehn; Kai-Uwe Sattler; Gunter Saake,Abstract Data integration as required in a variety of applications like data warehousing;information system integration etc. makes great demands regarding features to deal withoverlapping and inconsistent data. Object-relational and other data management systemsavailable today provide only limited concepts to deal with these requirements. The generalconcept of grouping and aggregation appears to be a fitting paradigm for various of thecurrent issues in data integration; but in its common form of equality-based grouping anumber of problems remain unsolved. Various extensions to this concept have beenintroduced over the last years regarding user-defined functions for aggregation andgrouping. Especially; existing extensions to the grouping operation like simple derivations ofgroup-by values do not meet the requirements of data integration applications. We …,PROCEEDINGS OF THE INTERNATIONAL CONFERENCE ON DATA ENGINEERING,2002,50
Advanced grouping and aggregation for data integration,Eike Schallehn; Kai-Uwe Sattler; Gunter Saake,Abstract New applications from the areas of analytical data processing and data integrationrequire powerful features to condense and reconcile available data. As outlined in [1]; thegeneral concept of grouping and aggregation appears to be a fitting paradigm for a numberof these issues; but in its common form of equality based groups or with current extensionslike simple user-defined functions to derive group-by values on a per tuple basis andrestricted aggregate functions a number of problems remain unsolved. We describe twoextensions to the grouping mechanism; a generic one to support holistic user-definedgrouping functions and higher level construct that provides similarity based groupingsuitable in a number of applications like duplicate detection and elimination.,Proceedings of the tenth international conference on Information and knowledge management,2001,50
Viewpoints on emergent semantics,Philippe Cudré-Mauroux; Karl Aberer; Alia I Abdelmoty; Tiziana Catarci; Ernesto Damiani; Arantxa Illaramendi; Mustafa Jarrar; Robert Meersman; Erich J Neuhold; Christine Parent; Kai-Uwe Sattler; Monica Scannapieco; Stefano Spaccapietra; Peter Spyns; Guy De Tré,Abstract We introduce a novel view on how to deal with the problems of semanticinteroperability in distributed systems. This view is based on the concept of emergentsemantics; which sees both the representation of semantics and the discovery of the properinterpretation of symbols as the result of a self-organizing process performed by distributedagents exchanging symbols and having utilities dependent on the proper interpretation ofthe symbols. This is a complex systems perspective on the problem of dealing withsemantics. We highlight some of the distinctive features of our vision and point outpreliminary examples of its application.,*,2006,42
Annotating scientific images: A concept-based approach,Michael Gertz; K-U Sattler; Fredric Gorin; Michael Hogarth; Jim Stone,Data annotations are an important kind of metadata that occur in the form of externallyassigned descriptions of particular features in Web accessible documents. Such metadataare eventually used in data retrieval tasks on heterogeneous; possible distributed Web-accessible documents. In this paper; we present the model and realization of an annotationframework that scientists can employ to semantically enrich different types of documents;primarily scientific images made available through an image repository. Although we employontology like structures; called concepts; for metadata schemes used in annotations; ourprimary focus is on how concepts are actually used to annotate images and regions ofinterest; respectively; that exhibit features of interest to a researcher. It turns out that thecombined consideration of domain specific concepts and annotated regions in images …,Scientific and Statistical Database Management; 2002. Proceedings. 14th International Conference on,2002,42
Autonomous query-driven index tuning,K-U Sattler; Eike Schallehn; Ingolf Geist,Index tuning as part of database tuning is the task of selecting and creating indexes with thegoal of reducing query processing times. However; in dynamic environments with various ad-hoc queries it is difficult to identify potentially useful indexes in advance. We investigate anapproach addressing this problem by deciding about index creation automatically at runtimein order to speed up processing of subsequent queries. We present a cost model taking intoaccount the benefits of indexes for an evolving query workload and discuss strategies forchoosing indexes to be created in a space-limited environment.,Database Engineering and Applications Symposium; 2004. IDEAS'04. Proceedings. International,2004,41
Interactive example-driven integration and reconciliation for accessing database federations,Kai-Uwe Sattler; Stefan Conrad; Gunter Saake,Abstract The integration of heterogeneous databases affects two main problems: schemaintegration and instance integration. At both levels a mapping from local elements to globalelements is specified and various conflicts caused by the heterogeneity of the sources haveto be resolved. For the detection and resolution of instance-level conflicts we propose aninteractive; example-driven approach. The basic idea is to combine an interactive query toolsimilar to query-by-example with facilities for defining and applying integration operations.This integration approach is supported by a multidatabase query language; which providesspecial mechanisms for conflict resolution. The foundations of these mechanisms areintroduced and their usage in instance integration and reconciliation is presented. Inaddition; we discuss basic techniques for supporting the detection of instance-level …,Information systems,2003,30
Sql based frequent pattern mining without candidate generation,Xuequn Shang; Kai Uwe Sattler; Ingolf Geist,Abstract Scalable data mining in large databases is one of today's real challenges todatabase research area. The integration of data mining with database systems is anessential component for any successful large-scale data mining application. A fundamentalcomponent in data mining tasks is finding frequent patterns in a given dataset. Most of theprevious studies adopt an Apriori-like candidate set generation-and-test approach.However; candidate set generation is still costly; especially when there exist prolific patternsand/or long patterns. In this study we present an evaluation of SQL based frequent patternmining with a novel frequent pattern growth (FP-growth) method; which is efficient andscalable for mining both long and short patterns without candidate generation. We examinesome techniques to improve performance. In addition; we have made performance …,Proceedings of the 2004 ACM symposium on Applied computing,2004,28
Datenbanken & Java,Gunter Saake; Kai-Uwe Sattler,Page 1. Datenbankstammtisch Dresden; 27. November 2002 Datenbanken & Java Gunter SaakeInstitut für Technische und Betriebliche Informationssysteme Otto-von-Guericke-UniversitätMagdeburg saake@iti.cs.uni-magdeburg.de Page 2. 1. Überblick Datenbanken & Java 2 GunterSaake Motivation Java und DB-Anwendungsentwicklung JDBC Embedded SQL: SQLJ Javaim DB-Server Java und OO-Datenbanken Objektrelationale Abbildung Ausblick Page 3. 2.Motivation Datenbanken & Java 3 Gunter Saake Datenbanken: Basis vieler AnwendungssystemeInternet-Anwendungen; E-Commerce Betriebliche Informationssysteme Java als Plattform fürEntwicklung solcher Anwendungen Objektorientierung Plattformunabhängigkeit Vielzahl vonverfügbaren Bibliotheken Datenbankzugriff mit Java Page 4. DB-AnwendungsentwicklungDatenbanken & Java 4 Gunter Saake Kopplung von SQL und prozeduraler …,JDBC; SQLJ; ODMG und JDO,2000,27
Automatic selection of processing units for coprocessing in databases,Sebastian Breß; Felix Beier; Hannes Rauhe; Eike Schallehn; Kai-Uwe Sattler; Gunter Saake,Abstract Specialized processing units such as GPUs or FPGAs provide great opportunities tospeed up database operations by exploiting parallelism and relieving the CPU. But utilizingcoprocessors efficiently poses major challenges to developers. Besides finding fine-granulardata parallel algorithms and tuning them for the available hardware; it has to be decided atruntime which (co) processor should be chosen to execute a specific task. Depending oninput parameters; wrong decisions can lead to severe performance degradations sinceinvolving coprocessors introduces a significant overhead; eg; for data transfers. In thispaper; we present a framework that automatically learns and adapts execution models forarbitrary algorithms on any (co) processor to find break-even points and support schedulingdecisions. We demonstrate its applicability for three common use cases in modern …,East European Conference on Advances in Databases and Information Systems,2012,26
A research agenda for query processing in large-scale peer data management systems,Katja Hose; Armin Roth; André Zeitz; Kai-Uwe Sattler; Felix Naumann,Abstract Peer Data Management Systems (P dms) are a novel; useful; but challengingparadigm for distributed data management and query processing. Conventional integratedinformation systems have a hierarchical structure with an integration component thatmanages a global schema and distributes queries against this schema to the underlyingdata sources. P dms are a natural extension to this architecture by allowing eachparticipating system (peer) to act both as a data source and as an integrator. Peers areinterconnected by schema mappings; which guide the rewriting of queries between theheterogeneous schemas; and thus form a P2P (peer-to-peer)-like network. Despite severalyears of research; the development of efficient P dms still holds many challenges. In thisarticle we first survey the state of the art on peer data management: We classify P dms by …,Information Systems,2008,25
Distributed complex event processing in sensor networks,Omran Saleh; Kai-Uwe Sattler,Mobile systems which include sensor networks; generate a continuous unmatched volumeof primitive event streams with various properties where the interior semantic information ofthese events is generally very limited. Moreover; forwarding all these events to a centralprocessing entity is not favored for limited-resource systems; it would deplete nodes'resources eg; the energy. The goal of this work is to address these issues by extractinguseful information locally; transmitting only this information and avoiding transmission ofunnecessary low-level data between nodes. Therefore; an In-Network Distributed ComplexEvent Processing (INDCEP) based solution is proposed. INDCEP technology is used toperform the processing within the network by pushing complex event processing intonetwork nodes. This research aims to develop a robust and high performance Distributed …,Mobile Data Management (MDM); 2013 IEEE 14th International Conference on,2013,24
Stream engines meet wireless sensor networks: cost-based planning and processing of complex queries in AnduIN,Daniel Klan; Marcel Karnstedt; Katja Hose; Liz Ribe-Baumann; Kai-Uwe Sattler,Abstract Wireless sensor networks are powerful; distributed; self-organizing systems usedfor event and environmental monitoring. In-network query processors like TinyDB offer auser friendly SQL-like application development. Due to the sensor nodes' resourcelimitations; monolithic approaches often support only a restricted number of operators. Forthis reason; complex processing is typically outsourced to the base station. Nevertheless;previous work has shown that complete or partial in-network processing can be moreefficient than the base station approach. In this paper; we introduce AnduIN; a system fordeveloping; deploying; and running complex in-network processing tasks. In particular; wepresent the query planning and execution strategies used in AnduIN; a system combiningsensor-local in-network processing and a data stream engine. Query planning employs a …,Distributed and Parallel Databases,2011,24
Similarity queries on structured data in structured overlays,Marcel Karnstedt; Kai-Uwe Sattler; Manfred Hauswirth; Roman Schmidt,Structured P2P systems based on distributed hash tables are a popular choice for buildinglarge-scaled data management systems. Generally; they only support exact match queries;but data heterogeneities often demand for more complex query types; particularly similarityqueries. In this work; we suggest a vertical data organization; which allows for efficientprocessing of similarity queries on instance as well as on schema level; and we introducecorresponding physical similarity operators. Our novel approach is shown to be suitable inconjunction with P-Grid; as an example of robust; large-scaled and self-organizing P2Psystems.,Data Engineering Workshops; 2006. Proceedings. 22nd International Conference on,2006,24
Semantic Caching in Ontology-based Mediator Systems.,Marcel Karnstedt; Kai-Uwe Sattler; Ingolf Geist; Hagen Höpfner,Abstract: The integration of heterogenous web sources is still a big challenge. One approachto deal with integration problems is the usage of domain knowledge in form of vocabulariesor ontologies during the integration (mapping of source data) as well as during queryprocessing. However; such an ontology-based mediator system still have to overcomeperformance issues because of high communication costs to the local sources. Therefore; aglobal cache can reduce the response time significantly. In this work we describe thesemantic cache of the ontology-based mediator system YACOB. In this approach the cacheentries are organized by semantic regions and the cache itself is tightly coupled with theontology on the concept level. Furthermore; the cache-based query processing is shown aswell as the advantages of the global concept schema in the creation of complementary …,Berliner XML Tage,2003,24
Database as a service (DBaaS),Wolfgang Lehner; Kai-Uwe Sattler,Modern Web or “Eternal-Beta” applications necessitate a flexible and easy-to-use datamanagement platform that allows the evolutionary development of databases andapplications. The classical approach of relational database systems following strictly theACID properties has to be extended by an extensible and easy-to-use persistency layer withspecialized DB features. Using the underlying concept of Software as a Service (SaaS) alsoenables an economic advantage based on the “economy of the scale “; where applicationand system environments only need to be provided once but can be used by thousands ofusers. Within this tutorial; we are looking at the current state-of-the-art from differentperspectives. We outline foundations and techniques to build database services based onthe SaaS-paradigm. We discuss requirements from a programming perspective; show …,Data Engineering (ICDE); 2010 IEEE 26th International Conference on,2010,23
Processing Top-N Queries in P2P-based Web Integration Systems with Probabilistic Guarantees.,Katja Hose; Marcel Karnstedt; Kai-Uwe Sattler; Daniel Zinn,ABSTRACT Efficient query processing in P2P-based Web integration systems poses avariety of challenges resulting from the strict decentralization and limited knowledge. As aspecial problem in this context we consider the evaluation of top-N queries on structureddata. Due to the characteristics of large-scaled P2P systems it is nearly impossible toguarantee complete and exact query answers without exhaustive search; which usuallyends in flooding the network. In this paper; we address this problem by presenting anapproach relying on histogram-based routing filters. These allow for reducing the number ofqueried peers as well as for giving probabilistic guarantees concerning the goodness of theanswer.,WebDB,2005,22
Robust query processing.,Goetz Graefe; Arnd Christian König; Harumi Kuno; Volker Markl; Kai-Uwe Sattler,Abstract The 2012 Dagstuhl 12321 Workshop on Robust Query Processing; held from 5–10August 2012; brought together researchers from both academia and industry to discussvarious aspects of robustness in database management systems and ideas for futureresearch. The Workshop was designed as a sequel to an earlier Workshop; DagstuhlWorkshop 10381; that studied a similar set of topics. In this article we summarize some of themain discussion topics of the 12321 Workshop; the results to date; and some open problemsthat remain.,ICDE,2011,21
Data Warehouse Technologien,Veit Köppen; Gunter Saake; Kai-Uwe Sattler,Architekturprinzipien von Data-Warehouse-Systemen Datenstrukturen und AlgorithmenAnwendungsfeld Business Intelligence Aus dem Inhalt: Data WarehousingArchitekturkonzepte Extraktion; Transformation und Laden Datenqualität BusinessIntelligence Modellierung Multidimensionales Modell Relationale Umsetzung Star-undSnowflake-Schema Slowly Changing Dimensions Speicher-und Indexstrukturen ROLAPund MOLAP Partitionierung Row Stores; Column Stores und In-Memory Bitmap-IndexeMehrdimensionale Indexstrukturen Data Warehouse: Anfragen und Verarbeitung OLAP-Anfrage-operatoren SQL-Operatoren im Data Warehouse Anfrageplanung MaterialisierteSichten Dieses Lehrbuch behandelt Konzepte und Techniken von Data-Warehouse-Systemen; die eine wesentliche Komponente in betrieblichen Entscheidungsprozessen …,*,2014,20
Multi-level parallel query execution framework for cpu and gpu,Hannes Rauhe; Jonathan Dees; Kai-Uwe Sattler; Franz Faerber,Abstract Recent developments have shown that classic database query executiontechniques; such as the iterator model; are no longer optimal to leverage the features ofmodern hardware architectures. This is especially true for massive parallel architectures;such as many-core processors and GPUs. Here; the processing of single tuples in one stepis not enough work to utilize the hardware resources and the cache efficiently and to justifythe overhead introduced by iterators. To overcome these problems; we use just-in-timecompilation to execute whole OLAP queries on the GPU minimizing the overhead fortransfer and synchronization. We describe several patterns; which can be used to buildefficient execution plans and achieve the necessary parallelism. Furthermore; we show thatwe can use similar processing models (and even the same source code) on GPUs and …,East European Conference on Advances in Databases and Information Systems,2013,20
Web-scale data management for the cloud,Wolfgang Lehner; Kai-Uwe Sattler; Kai-Uwe Sattler,The efficient management of data is a core asset of almost every organization. Data iscollected; stored; manipulated; and analysed to drive the business and derive support for thedecision making process. Establishing and running the data management platform within alarger organization is a complex; time-and budget-intensive tasks. Not only do datamanagement systems have to be installed; deployed; and populated with different sets ofdata. The data management platform of an organization has to constantly maintained on atechnical as well as on a content level. Changing applications and business requirementshave to be reflected within the technical setup; new software versions have to be installed;hardware has to be exchanged etc. Although the benefit of an efficient data managementplatform can be enormous not only in terms of a direct controlling of the business or a …,*,2013,20
Scalable distributed indexing and query processing over Linked Data,Marcel Karnstedt; Kai-Uwe Sattler; Manfred Hauswirth,Abstract Linked Data is becoming the core part of modern Web applications and thusefficient access to structured information expressed in RDF gains paramount importance. Anumber of efficient local RDF stores exist already; while distributed indexing and distributedquery processing over Linked Data with similar efficiency and data management features asknown from traditional database and data integration systems are only starting to develop.Distributed approaches will necessarily co-exist with centralized schemes; as data will beowned by different stakeholders who may not want to provide their complete data sets to acentral place. Additionally; central/integrated storage may be prohibited for organizational orlegal reasons in certain areas. To support decentralized schemes; only a few attempts in thisdirection exist so far; but they are limited in terms of capabilities and the degree of …,Web Semantics: Science; Services and Agents on the World Wide Web,2012,20
Best effort query processing in dht-based p2p systems,Philipp Rosch; K Sattler; Christian von der Weth; Erik Buchmann,Structured P2P systems in the form of distributed hash tables (DHT) are a promisingapproach for building massively distributed data management platforms. However; for manyapplications the supported key lookup queries are not sufficient. Instead; techniques formanaging and querying (relational) structured data are required. In this paper; we argue thatin order to cope with the dynamics in large-scale P2P systems such query techniquesshould be work in a best effort manner. We describe such operations (namelygrouping/aggregation; similarity and nearest neighbor search) and discuss appropriatequery evaluation strategies.,Data Engineering Workshops; 2005. 21st International Conference on,2005,20
SQL based frequent pattern mining with fp-growth,Xuequn Shang; Kai-Uwe Sattler; Ingolf Geist,Abstract Scalable data mining in large databases is one of today's real challenges todatabase research area. The integration of data mining with database systems is anessential component for any successful large-scale data mining application. A fundamentalcomponent in data mining tasks is finding frequent patterns in a given dataset. Most of theprevious studies adopt an Apriori-like candidate set generation-and-test approach.However; candidate set generation is still costly; especially when there exist prolific patternsand/or long patterns. In this study we present an evaluation of SQL based frequent patternmining with a novel frequent pattern growth (FP-growth) method; which is efficient andscalable for mining both long and short patterns without candidate generation. We examinesome techniques to improve performance. In addition; we have made performance …,*,2005,19
Query routing and processing in schema-based P2P systems,Marcel Karnstedt; Katja Hose; K-U Sattler,Recently; the peer-to-peer (P2P) paradigm has emerged; mainly by file sharing systemssuch as Napster and Gnutella and in terms of scalable distributed data structures. Due to thedecentralization; P2P systems promise an improved robustness and scalability andtherefore open also a new view on data integration solutions. However; several design andtechnical challenges arise in building scalable P2P-based integration systems. We addressone of them: the problem of distributed query processing. We discuss strategies of querydecomposition and routing based on different kinds of routing indexes and present results ofan experimental evaluation.,Database and Expert Systems Applications; 2004. Proceedings. 15th International Workshop on,2004,19
Datenbanken kompakt,Andreas Heuer; Gunter Saake; Kai-Uwe Sattler,*,*,2001,19
Data3--a kinect interface for olap using complex event processing,Steffen Hirte; Andreas Seifert; Stephan Baumann; Daniel Klan; Kai-Uwe Sattler,Motion sensing input devices like Microsoft's Kinect offer an alternative to traditionalcomputer input devices like keyboards and mouses. Daily new applications using thisinterface appear. Most of them implement their own gesture detection. In our demonstrationwe show a new approach using the data stream engine Andu IN. The gesture detection isdone based on Andu IN's complex event processing functionality. This way we build asystem that allows to define new and complex gestures on the basis of a declarativeprogramming interface. On this basis our demonstration data^ 3 provides a basic naturalinteraction OLAP interface for a sample star schema database using Microsoft's Kinect.,Data Engineering (ICDE); 2012 IEEE 28th International Conference on,2012,18
Rule-based schema matching for ontology-based mediators,Gunter Saake; Kai-Uwe Sattler; Stefan Conrad,Abstract Mediating heterogeneous data sources heavily relies on explicit domain knowledgeexpressed; for example; as ontologies and mapping rules. We discuss the use of logicrepresentations for mapping schema elements onto concepts expressed in a simplifiedontology for cultural assets. Starting with a logic representation of the ontology; criteria for arule-based schema matching are exemplified. Special requirements are the handling ofuncertain information and the processing of hierarchical XML structures representinginstances.,Journal of Applied Logic,2005,18
Supporting information fusion with federated database technologies,Kai-Uwe Sattler; Gunter Saake,Abstract. A common problem facing many users today is to extract and combine informationfrom multiple; heterogeneous sources and to derive information of a new quality orabstraction level. Though essential parts of this information fusion process can be supportedby techniques developed in the field of federated databases; new approaches for managingconsistency; uncertainty or quality of data and enabling efficient analysis of distributed;heterogenous sources are still required. This paper presents a brief survey of requirementsand applications of information fusion from the database view; discusses the usage offederated database technologies in fusion systems and points out possible researchdirections.,Conrad et al. CHS99,1999,18
Monitoring and autoscaling IaaS clouds: a case for complex event processing on data streams,Omran Saleh; Francis Gropengießer; Heiko Betz; Waseem Mandarawi; Kai-Uwe Sattler,Cloud computing is the notion for delivering access to scalable on-demand computingresources and IT services. The resource management system in IaaS Clouds dynamicallyallocates the resources based on predefined customers' needs using Service LevelAgreements (SLAs) between the Cloud provider and customers. One of the challenges ofresource management is to continuously monitor resource utilization; manage; and adjustthese resources in real-time fashion to meet the SLAs while not over provisioning resources.Though; there exist numerous Cloud monitoring solutions; they are often highly specializedand restrict the administrator in defining automation rules. Our work aims to develop aframework based on concepts from Complex Event Processing (CEP) and data streamprocessing where data from various primitive metrics streams are collected and treated as …,Utility and Cloud Computing (UCC); 2013 IEEE/ACM 6th International Conference on,2013,17
Distributed data summaries for approximate query processing in PDMS,Katja Hose; Daniel Klan; Kai-Uwe Sattler,Evolving from heterogeneous database systems one of the main problems in peer datamanagement systems (PDMS) is distributed query processing. With the absence of globalknowledge such strategies have to focus on routing the query efficiently to only those peersthat are most likely to contribute to the final result. Using routing indexes is one possibility toachieve this. Since data may change over time these structures have to be updated andmaintained which can be very expensive. In this paper; we present a novel kind of routingindexes that enables efficient query routing. Furthermore; we propose a threshold basedupdate strategy that can help to reduce maintenance costs by far. We exemplify the benefitof these indexes using a distributed skyline strategy as an example. Finally; we show howrelaxing exactness requirements; that are usually posed on results; can compensate the …,Database Engineering and Applications Symposium; 2006. IDEAS'06. 10th International,2006,17
Adapter Generation for Extraction and Querying Data from Web Sources,Kai-Uwe Sattler; Michael Höding,Abstract Accessing and integrating data from heterogeneous sources has become asignificant challenge. So-called adapters provide the functionality for translating SQLqueries into queries understandable by the source as well as converting the results into acommon model. In this paper; we present our approach of an adapter for Web sources;which is configurable by specifying a sourcespecific extraction function. We focus on twomain tasks: query modification in order to extend the source capabilities and data extraction.The extraction step bases on an operational description; that enables an interactiveexploration of the result format during the development phase. Finally; we present our ideasfor semi-automatic discovery of extraction patterns by analyzing example documents.,Proc. of 2nd ACM SIGMOD Workshop WebDB’99,1999,17
Scaling up mixed workloads: a battle of data freshness; flexibility; and scheduling,Iraklis Psaroudakis; Florian Wolf; Norman May; Thomas Neumann; Alexander Böhm; Anastasia Ailamaki; Kai-Uwe Sattler,Abstract The common “one size does not fit all” paradigm isolates transactional andanalytical workloads into separate; specialized database systems. Operational data isperiodically replicated to a data warehouse for analytics. Competitiveness of enterprisestoday; however; depends on real-time reporting on operational data; necessitating anintegration of transactional and analytical processing in a single database system. Themixed workload should be able to query and modify common data in a shared schema. Thedatabase needs to provide performance guarantees for transactional workloads; and; at thesame time; efficiently evaluate complex analytical queries. In this paper; we share ouranalysis of the performance of two main-memory databases that support mixed workloads;SAP HANA and HyPer; while evaluating the mixed workload CH-benCHmark. By …,Technology Conference on Performance Evaluation and Benchmarking,2014,16
GiST scan acceleration using coprocessors,Felix Beier; Torsten Kilias; Kai-Uwe Sattler,Abstract Efficient lookups in huge; possibly multi-dimensional datasets are crucial for theperformance of numerous use cases that generate multiple search operations at the sametime; like point queries in ray tracing or spatial joins in collision detection of interactive 3Dapplications. These applications greatly benefit from index structures that quickly filterrelevant candidates for further processing. Since different lookup operations areindependent from each other; they might be processed in parallel on modern hardware likemulti-core CPUs or GPUs. But implementing efficient algorithms for all kinds of indexes onvarious hardware platforms is a challenging task. In this paper; we present a new approachthat extends the existing GiST index framework with an abstraction layer for the hardwarewhere index operations are executed. Furthermore; we provide first performance …,Proceedings of the Eighth International Workshop on Data Management on New Hardware,2012,16
Adaptive burst detection in a stream engine,Marcel Karnstedt; Daniel Klan; Christian Pölitz; Kai-Uwe Sattler; Conny Franke,Abstract Detecting bursts in data streams is an important and challenging task. Due to thecomplexity of this task; usually burst detection cannot be formulated using standard queryoperators. Therefore; we show how to integrate burst detection for stationary as well as non-stationary data into query formulation and processing; from the language level to theoperator level. Afterwards; we present fundamentals of threshold-based burst detection. Wefocus on the applicability of time series forecasting techniques in order to dynamicallyidentify suitable thresholds for stream data containing arbitrary trends and periods. Theproposed approach is evaluated with respect to quality and performance on synthetic andreal-world sensor data using a full-fledged DSMS.,Proceedings of the 2009 ACM symposium on Applied Computing,2009,16
Processing rank-aware queries in P2P systems,Katja Hose; Marcel Karnstedt; Anke Koch; Kai-Uwe Sattler; Daniel Zinn,Abstract Efficient query processing in P2P systems poses a variety of challenges. As aspecial problem in this context we consider the evaluation of rank-aware queries; namelytop-N and skyline; on structured data. The optimization of query processing in a distributedmanner at each peer requires locally available statistics. In this paper; we address thisproblem by presenting approaches relying on the R-tree and histogram-based indexstructures. We show how this allows for optimizing rank-aware queries even over multipleattributes and thus significantly enhances the efficiency of query processing.,*,2007,16
Using similarity-based operations for resolving data-level conflicts,Eike Schallehn; Kai-Uwe Sattler,Abstract Dealing with discrepancies in data is still a big challenge in data integrationsystems. The problem occurs both during eliminating duplicates from semantic overlappingsources as well as during combining complementary data from different sources. Thoughusing SQL operations like grouping and join seems to be a viable way; they fail if theattribute values of the potential duplicates or related tuples are not equal but only similar bycertain criteria. As a solution to this problem; we present in this paper similarity-basedvariants of grouping and join operators. The extended grouping operator produces groups ofsimilar tuples; the extended join combines tuples satisfying a given similarity condition. Wedescribe the semantics of these operators; discuss efficient implementations for the editdistance similarity and present evaluation results. Finally; we give examples how the …,British National Conference on Databases,2003,16
An integrated approach to performance monitoring for autonomous tuning,Alexander Thiem; Kai-Uwe Sattler,With an ever growing complexity and data volume; the administration of today's relationaldatabase management systems has become one of the most important cost factors in theiroperation. Dynamic workloads and shifting demands require continuous effort from the DBAto deliver adequate performance. The goal of a modern DBMS must be to support the DBA'swork with automated processes and workflows that facilitate quick and precise decisions. Inthis paper; we present the concept of an integrated performance monitoring in the IngresDBMS that provides long-term collection of information valuable for performance tuning;problem identification and prediction. The approach of enhancing the DBMS core withmonitoring features rather than adding an additional watchdog on top of the system leads toa high data resolution while still having only a minimal overhead. This concept was …,Data Engineering; 2009. ICDE'09. IEEE 25th International Conference on,2009,15
Towards data mining operators in database systems: Algebra and implementation,Ingolf Geist; Kai-uwe Sattler,Abstract The KDD process is a non-trivial process of identifying valid; novel; potentiallyuseful; and ultimately understandable patterns in data. This process comprises several stepswhich are invoked and parametrized in an interactive and iterative manner. A uniformframework for different kinds of patterns and operators is needed to support KDD efficientlyand in an integrated way. Furthermore; because of large data sets it is necessary to scale upmining algorithms in order to achieve fast user support. One task of scaling data miningalgorithms is the integration of KDD operators in database management systems.,University of Manchester; Department of Computer Science,2004,15
Integrating scientific data through external; concept-based annotations,Michael Gertz; Kai-Uwe Sattler,Abstract In several scientific application domains; such as the computational sciences; thetransparent and integrated access to distributed and heterogeneous data sources is key toleveraging the knowledge and findings of researchers. Standard database integrationapproaches; however; are either not applicable or insufficient because of lack of local andglobal schema structures. In these application domains; data integration often occursmanually in that researchers collect data and categorize them using “semantic indexing”; inthe most simple case through local bookmarking; which leaves them without appropriatedata query; sharing; and management mechanisms. In this paper; we present a dataintegration technique suitable for such application domains. This technique is based on thenotion of controlled data annotations; resembling the idea of associating semantic rich …,*,2003,15
Informationsfusion—Herausforderungen an die Datenbanktechnologie—Kurzbeitrag—,Stefan Conrad; Gunter Saake; Kai-Uwe Sattler,Zusammenfassung In vielen Anwendungsbereichen besteht die Aufgabe; Daten oderInformationen aus verschiedenen; zum Teil heterogenen Quellen zu kombinieren; zuverdichten und daraus Informationen einer neuen Qualität abzuleiten. WesentlicheKernfunktionen dieses als Informationsfusion bezeichneten Prozesses sind dabei durchMethoden der Datenintegration und der Datenanalyse/Data Mining bereitzustellen. Diegewachsenen Strukturen der heute genutzten Informationsquellen und die damit imZusammenhang stehenden Probleme wie Heterogenität; Inkonsistenz oder Ungenauigkeitder Daten sind mit den aktuell verfügbaren Techniken nur bedingt beherrschbar.Ausgehend vom aktuellen Stund der Forschung diskutiert der vorliegende BeitragAnforderungen an Datenbanktechnologien aus Sicht der Informationsfusion; zeigt …,*,1999,15
Datenbanken: Implementierungstechniken,Gunter Saake; Kai-Uwe Sattler; Andreas Heuer,Das Gebiet der Datenbanksysteme gehört zu den klassischen Ausbildungsgebieten derInformatikstudiengänge. Datenbanksysteme kommen immer dann zum Einsatz; wenn an dieDatenhaltung besondere Anforderungen hinsichtlich der Zuverlässigkeit; des zuspeichernden Volumens; der Ausfallsicherheit; des Mehrbenutzerzugriffs; der Komplexitätder Datenbeschreibung oder der Datenqualität gestellt werden. Zu Beginn desInformationszeitalters ist es daher nicht verwunderlich; dass der Umgang mitDatenbanksystemen für viele Absolventinnen und Absolventen der Informatikstudiengängezum Berufsalltag gehört. Viele Grundkonzepte der Datenbanktechnologie wurden in den70er-Jahren entwickelt und seitdem beständig weiterentwickelt. Nach einer Stabilisierung inden 80er-Jahren–die damalige relationale Basistechnologie wurde fälschlicherweise als …,*,2011,14
Flashing databases: expectations and limitations,Stephan Baumann; Giel de Nijs; Michael Strobel; Kai-Uwe Sattler,Abstract Flash devices (solid state disks) promise a significant performance improvement fordisk-based database processing. However; database storage structures and processingstrategies originally designed for magnetic disks prevent the optimal utilization of SSDs.Based on previous work on bench-marking SSDs and a detailed discussion of I/O methods;in this paper; we analyze appropriate execution methods for database processing as well asimportant parameters and boundaries and present a tool which helps to derive theseparameters.,Proceedings of the Sixth International Workshop on Data Management on New Hardware,2010,14
Towards Trie-Based Query Caching in Mobile DBS,Hagen Höpfner; Kai-Uwe Sattler,Abstract: The usage of mobile equipment like PDAs; mobile phones; Tablet PCs or laptops isalready common in our current information society. Typically; mobile information systemswork in a context dependent (eg location dependent) manner which means that queriesdiffer mostly only in some context-related predicates on the same set of relations.Considering this characteristics; query processing on mobile devices can take benefit fromresults of previously performed queries by using a query cache. In this paper; we describesuch a caching approach based on a trie structure and organized by the query predicateswhich are associated with the corresponding result sets. We present the cache structure andthe process of query rewriting as well as discuss implementation issues.,Post-Proceedings of the Workshop Scalability; Persistence; Transactions-Database Mechanisms for Mobile Applications; Lecture Notes in Informatics (LNI),2003,14
Cost-aware processing of similarity queries in structured overlays,Marcel Karnstedt; K-U Sattler; Manfred Hauswirth; Roman Schmidt,Large-scale distributed data management with P2P systems requires the existence ofsimilarity operators for queries as we cannot assume that all users agree on exactly thesame schema and value representations and data quality problems due to spelling errorsand typos. In this paper; we present an approach for efficient processing of similarityselections and joins in a structured overlay. We show that there are several possiblestrategies exploiting DHT features to a different extent (ie; key organization; routing;multicasting) and thus the choice of the best operator implementation in a given situation(selectivity; data distribution; load) should be based on cost information allowing the systemto estimate the computation and communication costs of query execution plans. Hence; wepresent a cost model for similarity operations on structured data in a DHT and …,Peer-to-Peer Computing; 2006. P2P 2006. Sixth IEEE International Conference on,2006,13
Change detection in streaming data in the era of big data: models and issues,Dang-Hoan Tran; Mohamed Medhat Gaber; Kai-Uwe Sattler,Abstract Big Data is identified by its three Vs; namely velocity; volume; and variety. The areaof data stream processing has long dealt with the former two Vs velocity and volume. Over adecade of intensive research; the community has provided many important researchdiscoveries in the area. The third V of Big Data has been the result of social media and thelarge unstructured data it generates. Streaming techniques have also been proposedrecently addressing this emerging need. However; a hidden factor can represent animportant fourth V; that is variability or change. Our world is changing rapidly; andaccounting to variability is a crucial success factor. This paper provides a survey of changedetection techniques as applied to streaming data. The review is timely with the rise of BigData technologies; and the need to have this important aspect highlighted and its …,ACM SIGKDD Explorations Newsletter,2014,12
Online tuning of aggregation tables for olap,Katja Hose; Daniel Klan; Kai-Uwe Sattler,Materializing results from complex aggregation queries helps to significantly improveresponse times in OLAP servers. This problem is known as the view selection problem:choosing the optimal set of aggregation tables (called configuration) for a given workload. Inthis paper we present an online approach for adjusting the configuration dynamically to thecurrent workload. This approach is implemented as part of an open source OLAP server andacts on the level of multidimensional MDX queries. The work presents the details of costestimation and optimization of the system demonstrated in [10] and extends it by an onlinetuning strategy.,Data Engineering; 2009. ICDE'09. IEEE 25th International Conference on,2009,12
Quality-Aware Mining of Data Streams.,Conny Franke; Michael Hartung; Marcel Karnstedt; Kai-Uwe Sattler,Abstract: Due to the inherent characteristics of data streams; appropriate mining techniquesheavily rely on window-based processing and/or (approximating) data summaries. Becauseresources such as memory and CPU time for maintaining such summaries are usuallylimited; the quality of the mining results is affected in different ways. Based on selectedmining techniques; we discuss in this paper relevant quality measures for analysis results.Furthermore; we describe extensions to two specific stream mining algorithms allowing (1) toestimate resource consumptions (mainly memory space) based on user-specified qualityrequirements and (2) to determine the output quality for changes in the available resources.,IQ,2005,12
Accelerated query operators for high-speed; in-memory online analytical processing queries and operations,*,An additional data structure can be initialized for a column of compressed data to include aprefix storing; for each block of values in the column; a total number of bits set in previousblocks in the bit vector. A block number can be determined for a target block of the pluralityof blocks; for example by checking whether or not a specified row number is located in theprefix. If the specified row number is located in the prefix; the prefix value of the prefix isreturned; the most frequently occurring value is returned if a corresponding bit in the bitvector in the specified row number is not located in the prefix; or a position of the specifiedrow in an index vector for the column is returned.,*,2014,11
Towards Elastic Stream Processing: Patterns and Infrastructure.,Kai-Uwe Sattler; Felix Beier,ABSTRACT Distributed; highly-parallel processing frameworks as Hadoop are deemed tobe state-of-the-art for handling big data today. But they burden application developers withthe task to manually implement program logic using lowlevel batch processing APIs. Thus; amovement can be observed that high-level languages are developed which allow todeclaratively model dataflows that are automatically optimized and mapped to the batch-processing backends. However; most of these systems are based on programming modelsas MapReduce that provide elasticity and fault-tolerance in a natural manner sinceintermediate results are materialized and; therefore; processes can simply be restarted andscaled with partitioning input datasets. For continuous query processing on data streams;these concepts cannot be applied directly since it must be guaranteed that no data is lost …,BD3@ VLDB,2013,11
How to juggle columns: an entropy-based approach for table compression,Marcus Paradies; Christian Lemke; Hasso Plattner; Wolfgang Lehner; Kai-Uwe Sattler; Alexander Zeier; Jens Krueger,Abstract Many relational databases exhibit complex dependencies between data attributes;caused either by the nature of the underlying data or by explicitly denormalized schemas. Indata warehouse scenarios; calculated key figures may be materialized or hierarchy levelsmay be held within a single dimension table. Such column correlations and the resultingdata redundancy may result in additional storage requirements. They may also result in badquery performance if inappropriate independence assumptions are made during querycompilation. In this paper; we tackle the specific problem of detecting functionaldependencies between columns to improve the compression rate for column-baseddatabase systems; which both reduces main memory consumption and improves queryperformance. Although a huge variety of algorithms have been proposed for detecting …,Proceedings of the Fourteenth International Database Engineering & Applications Symposium,2010,11
A DHT-based infrastructure for ad-hoc integration and querying of semantic data,Marcel Karnstedt; Kai-Uwe Sattler; Manfred Hauswirth; Roman Schmidt,Abstract A crucial prerequisite for the deployment and success of Peer-to-Peer datamanagement applications is the availability of metadata in a way that makes it easy toaccess and combine data from different sources and domains. In this paper; we argue for aunified and distributed infrastructure providing a repository for semantic data by offeringlocation transparency and advanced query services. After discussing the challenges of suchan approach; we present our solution which applies extended SPARQL-like query featuresfor dealing with large and possibly heterogeneous data sets. We focus on the integrationinto efficient distributed query processing and evaluate our approach in a series ofexperiments.,Proceedings of the 2008 international symposium on Database engineering & applications,2008,11
A physical query algebra for dht-based p2p systems,Kai-Uwe Sattler; Philipp Rösch; Erik Buchmann; Klemens Böhm,Abstract In this paper we present initial results of our efforts to build a distributed queryengine for a Peerto-Peer system implementing a distributed hash table (DHT). Based on adiscussion of requirements to process SQL-like queries we describe our extensions to theDHT API and discuss data fragmentation issues. We show the realization of a physical queryalgebra in terms of selected plan operators and present a strategy for processing queriescomposed from these operators.,Proceedings of the 6th Workshop on Distributed Data and Structures; Lausanne; Switzerland,2004,11
Distributed Query Processing in P2P Systems with Incomplete Schema Information.,Marcel Karnstedt; Katja Hose; Kai-Uwe Sattler,Abstract. The peer-to-peer (P2P) paradigm has emerged recently; mainly by file sharingsystems like Napster or Gnutella and in terms of scalable distributed data structures.Because of the decentralization P2P systems promise an improved scalability androbustness; and they open a new view on data integration approaches; too. By exploitingalready available mappings between pairs of peers a new peer joining the systems canimmediately participate and access all the available data after establishing acorrespondence mapping to at least one other peer. One of the technical challenges inbuilding scalable P2P based integration systems is the efficient processing of queries whichis complicated by the locally restricted knowledge about data placement and schemainformation. In this paper; we address this problem by investigating query processing …,DIWeb,2004,11
Verteiltes und paralleles datenmanagement: von verteilten datenbanken zu big data und cloud,Erhard Rahm; Gunter Saake; Kai-Uwe Sattler,Verteilte und parallele Verarbeitung in Datenbanken erlebte eine erste Blüte in den 80er-Jahren; als parallele Verarbeitung und geografisch verteilte Speicherung von relationalenDaten erstmals intensiv untersucht wurden. In dieser Ära erschienen ein ganze Reihe vonfundamentalen Veröffentlichungen und Lehrbüchern; die die Grundlagen für derartigeVerfahren legten. In den darauffolgenden Jahren wurden diese Verfahren genutzt; ohnedass dabei ein erneuter Hype zu beobachten war. Dies änderte sich in den letzten Jahrenmit Konzepten wie der Cloud-Speicherung und der Analyse in Big-Data-Szenarien; die nunmoderne Anforderungen an die Skalierbarkeit mit 20 Jahre altem Lehrbuchwissenkonfrontierten. Auch wenn viele der damaligen Entwicklungen auch nach dieser Zeitunverändert gültig sind; fügen diese neuen Szenarien neue Aspekte hinzu; die damals …,*,2015,10
Customizable feature based design pattern recognition integrating multiple techniques.,Ghulam Rasool,Abstract Recovering design information from legacy applications is a complex; expensive;quiet challenging; and time consuming task due to ever increasing complexity of softwareand advent of modern technology. The growing demand for maintenance of legacy systems;which can cope with the latest technologies and new business requirements; the reuse ofartifacts from the existing legacy applications for new developments become very importantand vital for software industry. Due to constant evolution in architecture of legacy systems;they often have incomplete; inconsistent and obsolete documents which do not provideenough information about the structure of these systems. Mostly; source code is the onlyreliable source of information for recovering artifacts from legacy systems. Extraction ofdesign artifacts from the source code of existing legacy systems supports program …,*,2011,10
Towards Burst Detection for Non-Stationary Stream Data.,Daniel Klan; Marcel Karnstedt; Christian Pölitz; Kai-Uwe Sattler,Abstract Detecting bursts in data streams is an important and challenging task; especially instock market; traffic control or sensor network streams. Burst detection means theidentification of non regular behavior within data streams. A specifically crucial challenge onburst detection is to identify bursts in the case of non-stationary data. One approach is toapply thresholds to discover such bursts. In this paper; we propose a new approach todynamically identify suitable thresholds using techniques known from time seriesforecasting. We present fundamentals and discuss requirements for threshold-based burstdetection on stream data containing arbitrary trends and periods.,LWA,2008,10
An extensible; distributed simulation environment for peer data management systems,Katja Hose; Andreas Job; Marcel Karnstedt; Kai-Uwe Sattler,Abstract Peer Data Management Systems (PDMS) have recently attracted attention by thedatabase community. One of the main challenges of this paradigm is the development andevaluation of indexing and query processing strategies for large-scale networks. So far;research groups working in this area build their own testing environment which first causes ahuge effort and second makes it difficult to compare different strategies. In this demonstrationpaper; we present a simulation environment that aims to be an extensible platform forexperimenting with query processing techniques in PDMS and allows for running largesimulation experiments in distributed environments such as workstation clusters or evenPlanetLab. In the demonstration we plan to show the evaluation of processing strategies forqueries with specialized operators like top-k and skyline computation on structured data.,International Conference on Extending Database Technology,2006,10
Towards indexing schemes for self-tuning dbms,K-U Sattler; Eike Schallehn; Ingolf Geist,Index tuning as part of database tuning is the task of selecting and creating indexes with thegoal of reducing query processing times. However; in dynamic environments with various ad-hoc queries it is difficult to identify potentially useful indexes in advance. In this paper; basedon previous research regarding automatic index creation at runtime we point out the needfor new indexing schemes suitable for self-tuning. Based on problems with previousapproaches we describe the key concepts; which are sparse and partial indexing; usage-balanced instead of data-balanced structures; and dynamic resource assignment. Weillustrate the approach by a simple index structure; which provides adaptability as well asimproved access characteristics. Furthermore; we will outline key tasks to introduceaccording concepts in future DBMS.,Data Engineering Workshops; 2005. 21st International Conference on,2005,10
Supporting similarity operations based on approximate string matching on the web,Eike Schallehn; Ingolf Geist; Kai-Uwe Sattler,Abstract Querying and integrating sources of structured data from the Web in most casesrequires similarity-based concepts to deal with data level conflicts. This is due to the oftenerroneous and imprecise nature of the data and diverging conventions for theirrepresentation. On the other hand; Web databases offer only limited interfaces and almostno support for similarity queries. The approach presented in this paper maps string similaritypredicates to standard predicates like substring and keyword search as offered by many ofthe mentioned systems. To minimize the local processing costs and the required networktraffic; the mapping uses materialized information on the selectivity of string samples such asq-samples; substrings; and keywords. Based on the predicate mapping similarity selectionsand joins are described and the quality and required effort of the operations is evaluated …,OTM Confederated International Conferences" On the Move to Meaningful Internet Systems",2004,10
A database-supported workbench for information fusion: INFUSE,Oliver Dunemann; Ingolf Geist; Roland Jesse; Kai-Uwe Sattler; Andreas Stephanik,Abstract Information Fusion is the process of integration and interpretation of heterogeneousdata in order to gain new information of higher quality [3]. A successful support for this taskrequires a tight coupling of different integration and analysis tools: accessing heterogeneousdata sources; their integration; preparation and transformation; analysis of syntactic;semantic and temporal structures as well as their visualisation. The InFuse framework relieson database techniques with the goal to meet these requirements. The proposeddemonstration studies Comparative Genomics as one Information Fusion scenario. Geneinformation from different; heterogeneous sequence databases are used by severaloperators to analyse the function of unknown gene sequences within the demonstration.,International Conference on Extending Database Technology,2002,10
A Model and Architecture for Conceptualized Data Annotations,Michael Gertz; Kai-Uwe Sattler,Abstract In many collaborative research environments; in particular computational sciences;novel tools and techniques allow researchers to generate data from experiments andobservations at a staggering rate. Researchers in these areas are now facing the strongneed for querying; sharing and exchanging the data in a uniform and transparent fashion tofurther leverage their findings. However; due to the nature of the various types ofheterogeneous data and lack of local and global database schema structures; standard dataintegration approaches fail or are not applicable. A viable solution to this problem is theextensive use of metadata. In this paper; we present the model and realization of a metadatamanagement systems suitable for such research environments. The core component of themodel are conceptualized data annotations that allow researchers to associate well …,Proc. 14th Int'l Conf. Scientific and Statistical Database Management,2001,10
Federation services for heterogeneous digital libraries accessing cooperative and non-cooperative sources,Martin Endig; Michael Hoding; Gunter Saake; K-U Sattler; Eike Schallehn,Today; bibliographical information is kept in a variety of digital libraries available on theInternet. The integration of bibliographical data is considered as one of the most importanttasks in the area of digital library community. The available sources of data vary widely interms of data representation and access interfaces. To overcome this heterogeneity duringthe last years attempts were made to apply methods developed for information systemintegration. We describe our approach of a federation service for digital libraries using theloosely coupled federated system FRAQL that offers a variety of conflict resolutionmechanisms. Furthermore; we present different kinds of adapters for accessing cooperativeand noncooperative sources of bibliographical information. In order to integrate systems withlimited query capabilities we introduce concepts for source descriptions.,Digital Libraries: Research and Practice; 2000 Kyoto; International Conference on.,2000,10
Extending database task schedulers for multi-threaded application code,Florian Wolf; Iraklis Psaroudakis; Norman May; Anastasia Ailamaki; Kai-Uwe Sattler,Abstract Modern databases can run application logic defined in stored procedures inside thedatabase server to improve application speed. The SQL standard specifies how to callexternal stored routines implemented in programming languages; such as C; C++; or JAVA;to complement declarative SQL-based application logic. This is beneficial for scientific andanalytical algorithms because they are usually too complex to be implemented entirely inSQL. At the same time; database applications like matrix calculations or data miningalgorithms benefit from multi-threading to parallelize compute-intensive operations. Multi-threaded application code; however; introduces a resource competition between the threadsof applications and the threads of the database task scheduler. In this paper; we show thatmulti-threaded application code can render the database's workload scheduling …,Proceedings of the 27th International Conference on Scientific and Statistical Database Management,2015,9
Partitioning for scalable complex event processing on data streams,Omran Saleh; Heiko Betz; Kai-Uwe Sattler,Abstract Many applications processing dynamic data require to filter; aggregate; join as wellas to recognize event patterns in streams of data in an online fashion. However; dataanalysis and complex event processing (CEP) on high volume and/or high rate streams arechallenging tasks. Typically; partitioning techniques are leveraged for achieving low latencyand scalable processing. Unfortunately; sequence-based operations such as CEPoperations as well as long-running continuous queries make partitioning much more difficultthan for batch-oriented approaches. In this paper; we address this challenge by presentingpartitioning strategies for CEP queries. We discuss two strategies for stream and patternpartitioning and we present a cost-based optimization approach for determining the numberof partitions as well as the split points in the queries to achieve better load balancing and …,*,2015,9
Power-aware data analysis in sensor networks,Daniel Klan; Katja Hose; Marcel Karnstedt; Kai-Uwe Sattler,Sensor networks have evolved to a powerful infrastructure component for event monitoringin many application scenarios. In addition to simple filter and aggregation operations; animportant task in processing sensor data is data mining-the identification of relevantinformation and patterns. Limited capabilities of sensor nodes in terms of storage andprocessing capacity; battery lifetime; and communication demand a power-efficient;preferably sensor-local processing. In this paper; we present AnduIN; a system fordeveloping; deploying; and running in-network data mining tasks. The system consists of adata stream processing engine; a library of operators for sensor-local processing; a box-and-arrow editor for specifying data mining tasks and deployment; a GUI providing the user withcurrent information about the network and running queries; and an alerter notifying the …,Data Engineering (ICDE); 2010 IEEE 26th International Conference on,2010,9
Developing and deploying sensor network applications with AnduIN,Daniel Klan; Katja Hose; Kai-Uwe Sattler,Abstract Wireless sensor networks have become important architectures for manyapplication scenarios; eg; traffic monitoring or environmental monitoring in general. As thesesensors are battery-powered; query processing strategies aim at minimizing energyconsumption. Because sending all sensor readings to a central stream data managementsystem consumes too much energy; parts of the query can already be processed within thenetwork (in-network query processing). An important optimization criterion in this context iswhere to process which intermediate results and how to route them efficiently. To overcomethese problems; we propose AnduIN; a system addressing these problems and offering anoptimizer that decides which parts of the query should be processed within the sensornetwork. It also considers optimization with respect to complex data analysis tasks; such …,Proceedings of the Sixth International Workshop on Data Management for Sensor Networks,2009,9
Estimating the number of answers with guarantees for structured queries in p2p databases,Marcel Karnstedt; Kai-Uwe Sattler; Michael Haß; Manfred Hauswirth; Brahmananda Sapkota; Roman Schmidt,Abstract Structured P2P overlays supporting standard database functionalities are a popularchoice for building large-scale distributed data management systems. In such systems;estimating the number of answers for structured queries can help approximating querycompleteness; but is especially challenging. In this paper; we propose to use routing graphsin order to achieve this. We introduce the general approach and briefly discuss furtheraspects like overhead and guarantees.,Proceedings of the 17th ACM conference on Information and knowledge management,2008,9
Information quality: Fundamentals; techniques; and use,Felix Naumann; Kai-Uwe Sattler,Page 1. Information Quality: Fundamentals; Techniques; and Use Felix NaumannHumboldt-Universität zu Berlin Kai-Uwe Sattler TU Ilmenau EDBT Tutorial; Munich; March 282006 Page 2. March 28; 2006 Felix Naumann; Kai-Uwe Sattler 2 Our Personal Motivation ●Now: Motivation ● IQ is big business ● IQ is (also) a database topic ● This tutorial: The past ●Where we are now ● The future: Open Problems ● Much to do 1.5 hours ⇒ no details Page3. March 28; 2006 Felix Naumann; Kai-Uwe Sattler 3 Tutorial Overview ● Motivation ● DefiningIQ ● IQ Dimensions ● IQ Models ● IQ Assessment ● Assessment techniques ● IQ aggregationand ranking ● IQ Improvement ● Profiling & Data Scrubbing ● Outlier Detection ● DuplicateDetection ● Wrapup Page 4. Information Quality: Fundamentals; Techniques; and Use Part1: Motivation Felix Naumann Humboldt-Universität zu Berlin …,Tutorial at EDBT,2006,9
Mining Data Streams under Dynamicly Changing Resource Constraints.,Conny Franke; Marcel Karnstedt; Kai-Uwe Sattler,Abstract Due to the inherent characteristics of data streams; appropriate mining techniquesheavily rely on window-based processing and/or (approximating) data summaries. Becauseresources such as memory and CPU time for maintaining such summaries are usuallylimited; the quality of the mining results is affected in different ways. Based on FrequentItemset Mining and an according Change Detection as selected mining techniques; wediscuss in this paper extensions of stream mining algorithms allowing to determine theoutput quality for changes in the available resources (mainly memory space). Furthermore;we give directions how to estimate resource consumptions based on user-specified qualityrequirements.,LWA,2006,9
Adaptive routing filters for robust query processing in schema-based P2P systems,Katja Hose; Marcel Karnstedt; K-U Sattler; E-A Stehr,Peer data management systems (PDMS) currently gain attention at an emerging scale inorder to cope with the needs of growing organizational integration. Efficient queryprocessing; as one of the main requirements in these systems; provides three majorchallenges: achieving robustness; scalability and self organization. In this paper we dealwith the physical aspects of these requirements. We introduce an adaptive maintenancetechnique based on query feedback for keeping routing filters; used to optimize routing; up-to-date. These filters are applied in conjunction with an iterative query processing strategyand we show that this can improve robustness and scalability of query processing indistributed data management systems.,Database Engineering and Application Symposium; 2005. IDEAS 2005. 9th International,2005,9
Depth-first frequent itemset mining in relational databases,Xuequn Shang; Kai Uwe Sattler,Abstract Data mining on large relational databases has gained popularity and itssignificance is well recognized. However; the performance of SQL based data mining isknown to fall behind specialized implementation since the prohibitive nature of the costassociated with extracting knowledge; as well as the lack of suitable declarative querylanguage support. We investigate approaches based on SQL for the problem of findingfrequent patterns from a transaction table; including an algorithm that we recently proposed;called Propad (PRO-jection PAttern Discovery). Propad fundamentally differs from an Apriori-like candidate set generation-and-test approach. This approach successively projects thetransaction table into frequent itemsets to avoid making multiple passes over the largeoriginal transaction table and generating a huge sets of candidates. We have made …,Proceedings of the 2005 ACM symposium on Applied computing,2005,9
An indexing scheme for update notification in large mobile information systems,Hagen Höpfner; Stephan Schosser; Kai-Uwe Sattler,Abstract Due to the increasing usage of small and low footprinted devices like mobilephones as clients of mobile information systems a new problem arises:“How to determinethe relevance of updates for a large number of mobile clients?” In this paper we present anindexing scheme that represents conjunctive queries posed by the mobile clients in a trie.So; IDs of the clients are referenced by their queries and checking the relevance of anupdate can be efficiently done by a trie lookup.,International Conference on Extending Database Technology,2004,9
SmoS: A Scalable Mobility Server.,Hagen Höpfner; Kai-Uwe Sattler,Mobile information systems are often distinguished as traditional information systems withadditional support for mobile devices. This idea is based on the mostly used cellular networkarchitecture. Mobile units have to be wirelessly connected via a base station to a serverintegrated in a fixed network if their users want to use the capabilities of the informationsystem which are provided by this server. Due to the increasing distribution and use of smallfootprinted hardware like mobile phones or PDAs such solutions have to consider a newrequirement; the great number of involved mobile units. In this contribution we presentSMoS; a scalable mobility server; we are currently developing. Our approach to handle agreat number of clients is based on the subsumption of semantically related data to logicalfragments which are computed on an integrated global view over heterogeneous data …,BNCOD Posters,2003,9
A Framework for Component-Oriented Tool Integration,Kai-Uwe Sattler,Abstract Tool environments supporting the development of complex products need to beopen and flexible. These requirements cannot be fulfilled in an adequate way by predefinedcoordination structures and interfaces. This paper presents a framework for controlintegration in open tool environments. The approach is based on a component model whichsupports the description of tool interconnections in an abstract implementation-independentmanner.,*,1998,9
Query processing of pre-partitioned data using sandwich operators,Stephan Baumann; Peter Boncz; Kai-Uwe Sattler,Abstract In this paper we present the “Sandwich Operators”; an elegant approach to exploitpre-sorting or pre-grouping from clustered storage schemes in operators such asAggregation/Grouping; HashJoin; and Sort of a database management system. Thereby;each of these operator types is “sandwiched” by two new operators; namely PartitionSplitand PartitionRestart. PartitionSplit splits the input relation into its smaller independentgroups on which the sandwiched operator is executed. After a group is processed;PartitionRestart is used to trigger the execution on the following group. Executing each ofthese operator types with the help of the Sandwich Operators introduces minimal overheadand does not penalize performance of the sandwiched operator; as its implementationremains unchanged. On the contrary; we show that sandwiched execution of each …,International Workshop on Business Intelligence for the Real-Time Enterprise,2012,8
Architecture of a highly scalable data warehouse appliance integrated to mainframe database systems.,Knut Stolze; Felix Beier; Kai-Uwe Sattler; Sebastian Sprenger; Carlos Caballero Grolimund; Marco Czech,Main memory processing and data compression are valuable techniques to address thenew challenges of data warehousing regarding scalability; large data volumes; nearrealtime response times; and the tight connection to OLTP. The IBM Smart AnalyticsOptimizer (ISAOPT) is a data warehouse appliance that implements a main memorydatabase system for OLAP workloads using a cluster-based architecture. It is tightlyintegrated with IBM DB2 for z/OS (DB2) to speed up complex queries issued against DB2. Inthis paper; we focus on autonomic cluster management; high availability; and incrementalupdate mechanisms for data maintenance in ISAOPT.,BTW,2011,8
An extended cooperative transaction model for xml,Francis Gropengießer; Kai-Uwe Sattler,Abstract In many application areas; for example in design or media production processes;several authors have to work cooperatively on the same project. Thereby; a frequently useddata format is XML. In this paper; we address the special requirements of cooperativeworking on shared XML graph structures; such as early visibility of updates; multi-directionalinformation flow; and parallel working. Since most existing transaction models are hardlyapplicable; we present a novel transaction model based on multi-level transactions anddynamic actions that meets these requirements. Additional advantages of this model areappropriate concepts for transaction synchronization and resolution of conflicts.,Proceedings of the 2nd PhD workshop on Information and knowledge management,2008,8
A relaxed but not necessarily constrained way from the top to the sky,Katja Hose; Christian Lemke; Kai-Uwe Sattler; Daniel Zinn,Abstract As P2P systems are a very popular approach to connect a possibly large number ofpeers; efficient query processing plays an important role. Appropriate strategies have to takethe characteristics of these systems into account. Due to the possibly large number of peers;extensive flooding is not possible. The application of routing indexes is a commonly usedtechnique to avoid flooding. Promising techniques to further reduce execution costs arequery operators such as top-N and skyline; constraints; and the relaxation of exactnessand/or completeness. In this paper; we propose strategies that take all these aspects intoaccount. The choice is left to the user if and to what extent he is willing to relax exactness orapply constraints. We provide a thorough evaluation that uses two types of distributed datasummaries as examples for routing indexes.,OTM Confederated International Conferences" On the Move to Meaningful Internet Systems",2007,8
Cost-aware skyline queries in structured overlays,Marcel Karnstedt; Jessica Muller; Kai-Uwe Sattler,Recently; systems providing access to extremely large data collections; managed in adistributed manner; gain emerging attention. A promising approach to implement thephysical layer of such systems are structured overlays based on the peer-to-peer paradigm.On the level of query expressiveness. ranking queries like skyline queries are predestinatedfor providing a fast but concise overview of the data. The problem is that structured overlaysare able to handle dynamic and unreliable environments. but usually support only limitedquery processing capabilities; which are very improper for processing such sophisticatedqueries. In this work; we propose three variants of a skyline operator and two extensions;especially suitable for efficient determination of skylines in the before mentioned overlaysystems. Additionally; we back the introduced approaches on an appropriate cost model …,Data Engineering Workshop; 2007 IEEE 23rd International Conference on,2007,8
Information Integration und Semantic Web,Kai-Uwe Sattler; Frank Leymann,*,Datenbank-Spektrum,2003,8
Extensible Grouping and Aggregation for Data Reconciliation.,Eike Schallehn; Kai-Uwe Sattler; Gunter Saake,Abstract. New applications from the areas of analytical data processing and data integrationrequire powerful features to condense and reconcile available data. Object-relational andother data management systems available today provide only limited concepts to deal withthese requirements. The general concept of grouping and aggregation appears to be afitting paradigm for a number of the mentioned issues; but in its common form of equalitybased groups and restricted aggregate functions a number of problems remain unsolved.Various extensions to this concept have been introduced over the last years; especiallyregarding user-defined functions for aggregation and derivation of grouping properties. Wepropose generic interfaces for user-defined grouping and aggregation as part of a SQLextension; allowing for more complex functions; for instance integration of data mining …,EFIS,2001,8
An SQL-based query language and engine for graph pattern matching,Christian Krause; Daniel Johannsen; Radwan Deeb; Kai-Uwe Sattler; David Knacker; Anton Niadzelka,Abstract The interest for graph databases has increased in the recent years. Several variantsof graph query languages exist–from low-level programming interfaces to high-level;declarative languages. In this paper; we describe a novel SQL-based language for modelinghigh-level graph queries. Our approach is based on graph pattern matching concepts;specifically nested graph conditions with distance constraints; as well as graph algorithmsfor calculating nested projections; shortest paths and connected components. ExtendingSQL with graph concepts enables the reuse of syntax elements for arithmetic expressions;aggregates; sorting and limits; and the combination of graph and relational queries. Weevaluate the language concepts and our experimental SAP HANA Graph Scale-OutExtension (GSE) prototype (This paper is not official SAP communication material. It …,International Conference on Graph Transformation,2016,7
Complex event processing on linked stream data,Omran Saleh; Stefan Hagedorn; Kai-Uwe Sattler,Abstract Social networks and Sensor Web technologies typically generate a massiveamount of data published as streams. In order to give these streams a meaningful sense andenrich them with semantic descriptions; the concept of Linked Stream Data (LSD) hasemerged. However; to support a wide range of LSD scenarios and queries comprehensivesolutions providing not only classic data stream operators such as windows; but also forprocessing of complex events; linking of (static) datasets; and scalable processing arerequired. In this paper; we present our approach for processing LSD and addressing theserequirements. In contrast to existing LSD engines relying on streaming extensions toSPARQL; our PipeFlow system is a (relational) dataflow language and engine providingsupport for complex event processing (CEP) and a few dedicated operators for RDF data …,Datenbank-Spektrum,2015,7
Sparqling pig-processing linked data with pig latin,Stefan Hagedorn; Katja Hose; Kai-Uwe Sattler,In recent years; dataflow languages such as Pig Latin have emerged as flexible andpowerful tools for handling complex analysis tasks on big data. These languages supportschema flexibility as well as common programming patterns such as iteration. They offerextensibility through user-defined functions while running on top of scalable distributedplatforms. In doing so; these languages enable analytical tasks while avoiding the limitationsof classical query languages such as SQL and SPARQL. However; the tuple-oriented viewof general-purpose languages like Pig does not match very well the specifics of moderndatasets available on the Web; which often use the RDF data model. Graph patterns; forinstance; are one of the core concepts of SPARQL but have to be formulated as explicitjoins; which burdens the user with the details of efficient query processing strategies. In …,Datenbanksysteme für Business; Technologie und Web (BTW 2015),2015,7
Efficient parallel processing of analytical queries on linked data,Stefan Hagedorn; Kai-Uwe Sattler,Abstract Linked data has become one of the most successful movements of the SemanticWeb community. RDF and SPARQL have been established as de-facto standards forrepresenting and querying linked data and there exists quite a number of RDF stores andSPARQL engines that can be used to work with the data. However; for many types of querieson linked data these stores are not the best choice regarding query execution times. Forexample; users are interested in analytical tasks such as profiling or finding correlatedentities in their datasets. In this paper we argue that currently available RDF stores are notoptimal for such scan-intensive tasks. In order to address this issue; we discuss queryevaluation techniques for linked data exploiting the features of modern hardwarearchitectures such as big memory and multi-core processors. Particularly; we describe …,OTM Confederated International Conferences" On the Move to Meaningful Internet Systems",2013,7
Energy-efficient collaborative query processing framework for mobile sensing services,Jin Yang; Tianli Mo; Lipyeow Lim; Kai-Uwe Sattler; Archan Misra,Many emerging context-aware mobile applications involve the execution of continuousqueries over sensor data streams generated by a variety of on-board sensors on multiplepersonal mobile devices (aka smartphones). To reduce the energy-overheads of such large-scale; continuous mobile sensing and query processing; this paper introduces CQP; acollaborative query processing framework that exploits the overlap (in both the sensorsources and the query predicates) across multiple smartphones. The frameworkautomatically identifies the shareable parts of multiple executing queries; and then reducesthe overheads of repetitive execution and data transmissions; by having a setofleader'mobile nodes execute and disseminate these shareable partial results. To furtherreduce energy; CQP utilizes lower-energy short-range wireless links (such as Bluetooth) …,Mobile Data Management (MDM); 2013 IEEE 14th International Conference on,2013,7
Hibernating in the Cloud-Implementation and Evaluation of Object-NoSQL-Mapping.,Florian Wolf; Heiko Betz; Francis Gropengießer; Kai-Uwe Sattler,Abstract: Object-relational mappers such as Hibernate are often used in applications topersist business objects in relational databases. The availability of commercial cloud-baseddatabase services opens new opportunities for developing and deploying databaseapplications. In addition; highly scalable cloud services belong to the class of NoSQLsystems promising to avoid the paradigm mismatch between the objectorientedprogramming model and the relational backend. In this paper; we discuss and analyze theusage of a scalable NoSQL solution such as Basho's RIAK as backend for Hibernate. Wedescribe the necessary mapping and translation steps for an integration avoiding the detouron SQL. Finally; we present results of an experimental evaluation showing the benefits andlimitations of this class of NoSQL backends for object-relational mappers.,BTW,2013,7
Learning from the history of distributed query processing: A heretic view on Linked Data management,Heiko Betz; Francis Gropengießer; Katja Hose; Kai-Uwe Sattler,Abstract. The vision of the Semantic Web has triggered the development of various newapplications and opened up new directions in research. Recently; much effort has been putinto the development of techniques for query processing over Linked Data. Being basedupon techniques originally developed for distributed and federated databases; some of theminherit the same or similar problems. Thus; the goal of this paper is to point out pitfalls thatthe previous generation of researchers has already encountered and to introduce the LinkedData as a Service as an idea that has the potential to solve the problem in some scenarios.Hence; this paper discusses nine theses about Linked Data processing and sketches aresearch agenda for future endeavors in the area of Linked Data processing.,Proceedings of the Third International Conference on Consuming Linked Data-Volume 905,2012,7
Entity matching for semistructured data in the Cloud,Marcus Paradies; Susan Malaika; Jérôme Siméon; Shahan Khatchadourian; Kai-Uwe Sattler,Abstract The rapid expansion of available information; on the Web or inside companies; isincreasing. With Cloud infrastructure maturing (including tools for parallel data processing;text analytics; clustering; etc.); there is more interest in integrating data to produce higher-value content. New challenges; notably include entity matching over large volumes ofheterogeneous data. In this paper; we describe an approach for entity matching over largeamounts of semistructured data in the Cloud. The approach combines ChuQL [4]; a recentlyproposed extension of XQuery with MapReduce; and a blocking technique for entitymatching which can be efficiently executed on top of MapReduce. We illustrate the proposedapproach by applying it to extract automatically and enrich references in Wikipedia andreport on an experimental evaluation of the approach.,Proceedings of the 27th Annual ACM Symposium on Applied Computing,2012,7
Apparatus and method for controlling a wave field synthesis rendering means,*,For controlling a wave field synthesis renderer arranged in a wave field synthesis system; ascene description; in which not an absolute position or an absolute time instant; but a timespan or location span within which the audio object may vary is indicated for a source; isused. Furthermore; there is provided a monitor; which monitors a utilization situation of thewave field synthesis system. An audio object manipulator finally varies the starting point ofthe audio object to be considered by the wave field synthesis renderer or the actual positionof the audio object within the time span and/or location span; in order to avoid capacitybottlenecks on the transmission lines or in the renderer.,*,2010,7
Maintenance strategies for routing indexes,Katja Hose; Christian Lemke; Kai-Uwe Sattler,Abstract Query processing in large-scale unstructured P2P networks is a crucial part ofoperating such systems. In order to avoid expensive flooding of the network during queryprocessing so-called routing indexes are used. Each peer maintains such an index for itsneighbors. It provides a compact representation (data summary) of data accessible via eachneighboring peer. An important problem in this context is to keep these data summaries up-to-date without paying high maintenance costs. In this paper; we investigate the problem ofmaintaining distributed data summaries in P2P-based environments without globalknowledge and central instances. Based on a classification of update propagationstrategies; we discuss several approaches to reduce maintenance costs and present resultsfrom an experimental evaluation.,Distributed and Parallel Databases,2009,7
Data Quality Dimensions,Kai-Uwe Sattler,realized using such logical structures. For example; in tree based data acquisition protocols;a collection tree is built that is rooted at the data collection center such as the sink node [8].The dissemination of the data requests from the participating nodes and collection of datafrom the sensor nodes are accomplished using this tree. A cluster based data acquisitionmechanism has been proposed in [3]. As shown in Fig. 1; nodes are organized into a fixednumber of clusters; and nodes within each cluster dynamically elect a cluster head. The dataacquisition is carried out in two phases. In the first phase; cluster heads collect data fromtheir cluster nodes. In the second phase; cluster heads send collected data to the nodes thathave subscribed to the data. The cluster heads are re-elected to balance energyconsumption among the nodes in the cluster. Zhang et al.[13] have proposed an adaptive …,*,2009,7
Distributed data streams,Minos Garofalakis,realized using such logical structures. For example; in tree based data acquisition protocols;a collection tree is built that is rooted at the data collection center such as the sink node [8].The dissemination of the data requests from the participating nodes and collection of datafrom the sensor nodes are accomplished using this tree. A cluster based data acquisitionmechanism has been proposed in [3]. As shown in Fig. 1; nodes are organized into a fixednumber of clusters; and nodes within each cluster dynamically elect a cluster head. The dataacquisition is carried out in two phases. In the first phase; cluster heads collect data fromtheir cluster nodes. In the second phase; cluster heads send collected data to the nodes thathave subscribed to the data. The cluster heads are re-elected to balance energyconsumption among the nodes in the cluster. Zhang et al.[13] have proposed an adaptive …,*,2009,7
Kompressionstechniken für spaltenorientierte BI-Accelerator-Lösungen.,Christian Lemke; Kai-Uwe Sattler; Franz Färber,Abstract: BI-Accelerator-Lösungen wie SAP's TREX ermöglichen durch die Kombination vonspaltenorientierter Datenorganisation; hauptspeicherbasierter Verarbeitung undskalierbarer Multiserver-Architektur eine deutliche Beschleunigung bei der Verarbeitungkomplexer OLAP-Anfragen in riesigen Data Warehouses. Durch den Einsatz vonDatenkompressionstechniken lässt sich der Speicherbedarf der Spalten und damit auch dieVerarbeitungszeit weiter reduzieren. In diesem Beitrag untersuchen wir daher Verfahren zurSpaltenkompression und deren Implementierung in TREX. Da für eine effektiveKompression eine Sortierung der Werte pro Spalte notwendig ist; stellen wir weiterhinStrategien zur Optimierung der Spaltenreihenfolge für die Sortierung vor.,BTW,2009,7
Informationsfusion auf heterogenen Datenbeständen,Oliver Dunemann; Ingolf Geist; Roland Jesse; Gunter Saake; Kai-Uwe Sattler,Zusammenfassung. Die Informationsfusion als Prozess der Integration und Interpretationheterogener Daten mit dem Ziel der Gewinnung von Informationen einer neuen; höherenQualität eröffnet eine Vielzahl von Anwendungsgebieten. Dabei erfordert dieser Prozesseine enge Verzahnung der bislang häufig noch isoliert vorliegenden Werkzeuge undTechniken zum Zugriff auf heterogene Datenquellen; deren Integration; Aufbereitung; eineAnalyse der syntaktischen; semantischen sowie temporalen Strukturen und Visualisierungderselben. In diesem Beitrag werden Rahmenbedingungen der Informationsfusion ebensodargestellt wie die sich aus ihnen ergebenden Aufgaben. Es werden Lösungsansätze zurErstellung einer Workbench vorgestellt; die eine durchgängige Unterstützung vonFusionsschritten ermöglicht. Dabei wird das Ziel einer konsequenten Nutzung von …,Informatik Forschung und Entwicklung,2002,7
I N F USE-Eine datenbankbasierte Plattform für die Informationsfusion,Oliver Dunemann; Ingolf Geist; Roland Jesse; Gunter Saake; Kai-Uwe Sattler,Zusammenfassung Informationsfusion als Prozess der Integration und Interpretationheterogener Daten mit dem Ziel der Gewinnung neuer Informationen einer höheren Qualitäteröffnet eine Vielzahl von Anwendungsgebieten. Gleichzeitig erfordert dieser Prozess aberauch eine enge Verzahnung der bislang häufig noch isoliert vorliegenden Werkzeuge undTechniken zum Zugriff auf heterogene Datenquellen; deren Integration; Aufbereitung;Analyse und Visualisierung. In diesem Beitrag werden erste Ergebnisse der Entwicklungeiner Workbench vorgestellt; die durch konsequente Nutzung von Datenbanktechniken einedurchgängige Unterstützung dieser Schritte ermöglicht.,*,2001,7
Citation Linking in Federated Digital Libraries.,Eike Schallehn; Martin Endig; Kai-Uwe Sattler,Abstract Today; bibliographical information is kept in a variety of data sources world wide;some of them publically available; and some of them also offering information about citationsmade in publications. But as most of those sources cover only certain areas of publications itis currently not possible to follow citation links when information about the referencedpublication is not stored locally. This is known as the citation linking problem. In this paperwe present an approach to integrating bibliographical information including citationinformation from various sources providing a platform for the solution of the citation linkingproblem. The approach is based on a loosely coupled federation using the FRAQLlanguage and its conflict resolution mechanisms. Furthermore; we describe an adapterallowing a seamless integration of various sources in an heterogeneous and highly …,EFIS,2000,7
Piglet: Interactive and platform transparent analytics for rdf & dynamic data,Stefan Hagedorn; Kai-Uwe Sattler,Abstract Data analytics has gained more and more focus during recent years and many dataprocessing platforms have been developed. They all provide a powerful but often complexAPI that users have to learn. Furthermore; results can only be stored or printed; without anypossibility for visualization. In this paper we present Piglet; a compiler for the high-level PigLatin script language that generates code for various platforms like Spark; Flink; Storm; andPipeFabric. Piglet lets users write elegant code with extensions for SPARQL and RDF; aswell as support for streaming data. An integration into the notebook-based frontend Zeppelinprovides a homogeneous and interactive user interface for exploring; analyzing; andvisualizing data from different sources and lets users share their scripts and results.,Proceedings of the 25th International Conference Companion on World Wide Web,2016,6
Database backend as a service: Automatic generation; deployment; and management of database backends for mobile applications,Francis Gropengießer; Kai-Uwe Sattler,Abstract Managing data in the Cloud is a challenging task; especially scaling resources inorder to prevent under-and over-provisioning. In this paper; we consider a specific domain ofapplications; namely mobile applications for events like conferences or festivals; whereautomatic managing and scaling the backend part of the application would be beneficial interms of efficient resource utilization as well as a good end-user experience. In order toachieve this; we make the following contributions. We automate generation; deployment;operation; and management of the backend in an Infrastructure as a Service Cloud.Thereby; we address the fluctuating load characteristics of mobile applications for events byapplying our monitoring and autoscaling framework based on data stream processing andcomplex event processing.,Datenbank-Spektrum,2014,6
Discovery querying in linked open data,Stefan Hagedorn; Kai-Uwe Sattler,Abstract The problem of the inability of machines to interpret and process informationpublished on web pages caused the development of a web of data; next to the web ofdocuments. The idea is known as the Semantic Web; where links between information areestablished in a way that machines can understand and interpret. With its development; newapplications were introduced to query and process this linked data. Additionally the opendata initiative was launched with the goal to publish governmental; scientific; and culturaldata freely accessible on the web. Often; this open data is offered in a semi-structured form;like CSV files; but can also be transformed into linked data format. With this linked opendata; programs can be created that efficiently process queries and find information. Thiswork is supposed to integrate the support for discovery queries into an existing LOD …,Proceedings of the Joint EDBT/ICDT 2013 Workshops,2013,6
In-network detection of anomaly regions in sensor networks with obstacles,Conny Franke; Marcel Karnstedt; Daniel Klan; Michael Gertz; Kai-Uwe Sattler; Elena Chervakova,Abstract In the past couple of years; sensor networks have evolved into an importantinfrastructure component for monitoring and tracking events and phenomena in several;often mission critical application domains. An important task in processing streams of datagenerated by these networks is the detection of anomalies; eg; outliers or bursts; and inparticular the computation of the location and spatial extent of such anomalies in a sensornetwork. Such information is then used as an important input to decision making processes.In this paper; we present a novel approach that facilitates the efficient computation of suchanomaly regions from individual sensor readings. We propose an algorithm to deriveregions with a spatial extent from individual (anomalous) sensor readings; with a particularfocus on obstacles present in the sensor network and the influence of such obstacles on …,Computer Science-Research and Development,2009,6
An extended transaction model for cooperative authoring of XML data,Francis Gropengießer; Katja Hose; Kai-Uwe Sattler,Abstract In many application scenarios; for example in design or media productionprocesses; several authors have to work cooperatively on the same project andconsequently on the same data. In this context; a frequently used data format is XML. Toenable cooperative authoring of shared XML graph structures; several requirements have tobe fulfilled; eg; early visibility of updates; multi-directional information flow; and processingdata in parallel. Most transaction models proposed in the literature are hardly applicable inthis context. In this paper; we propose a novel transaction model based on multi-leveltransactions and dynamic actions that meets these requirements. We describe thetransaction model as well as its formal properties and discuss issues such assynchronization and logging.,Computer Science-Research and Development,2009,6
Approximating query completeness by predicting the number of answers in DHT-based web applications,Marcel Karnstedt; Kai-Uwe Sattler; Michael Haß; Manfred Hauswirth; Brahmananda Sapkota; Roman Schmidt,Abstract Due to the rapid development of theWeb; applications based on the P2P paradigmgain more and more interest. Recently; such systems start to evolve to adopt standarddatabase functionalities in terms of complex query processing support. This goes far beyondsimple key lookups; as provided by standard DHT systems; which makes estimating thecompleteness of query answers a crucial challenge. In this paper; we discuss the semanticsof completeness for complex queries in P2P database systems and propose methods basedon the notion of routing graphs for estimating the number of expected query answers.Further; we discuss probabilistic guarantees for the estimated values and evaluate theproposed methods through an implemented system.,Proceedings of the 10th ACM workshop on Web information and data management,2008,6
When is it time to rethink the aggregate configuration of your OLAP server?,Katja Hose; Daniel Klan; Matthias Marx; Kai-Uwe Sattler,Abstract OLAP servers based on relational backends typically exploit materializedaggregate tables to improve response times of complex analytical queries. One of the keyproblems in this context is the view selection problem: choosing the optimal set ofaggregation tables (called configuration) for a given workload. In this paper; we present asystem that continuously monitors the workload and raises a quantified alert; when a betterconfiguration is available. We address the tasks of query monitoring and view selection atthe OLAP level instead of the SQL level; which simplifies the containment checks as well asrewriting and in this way helps to reduce the complexity of the backend system. At the demowe plan to show how our system works; ie; how the system reacts upon arbitrary (interactive)workloads and how the user is alerted that a better configuration is available.,Proceedings of the VLDB Endowment,2008,6
Completeness estimation of range queries in structured overlays,Marcel Karnstedt; Kai-Uwe Sattler; Roman Schmidt,Range queries are a very powerful tool in a wide range of data management systems andare vital to a multitude of applications. The hierarchy of structured overlay systems can beutilized in order to provide efficient techniques for processing them; resulting in the supportof applications and techniques based on range queries in large-scale distributed informationsystems. But; due to the limited knowledge and the usually best-effort characteristics;deciding about the completeness of query results; eg; getting an idea when a query isfinished or what amount of results is still missing; is very challenging. There is not only anurgent need to provide this information to the user issuing queries; but also for implementingsophisticated and efficient processing techniques based on them. In this work; we propose amethod for solving this task. We discuss the applicability and quality of our estimations …,Peer-to-Peer Computing; 2007. P2P 2007. Seventh IEEE International Conference on,2007,6
SmurfPDMS: A Platform for Query Processing in Large-Scale PDMS.,Katja Hose; Christian Lemke; Jana Quasebarth; Kai-Uwe Sattler,Abstract: As Peer Data Management Systems (PDMS) are a focus of current research; thereare lots of approaches like query processing or routing issues that have to be evaluated.Since there is no common platform approaches are evaluated in separate. This isdisadvantageous for research groups in two ways. First; it means a huge effort to build asimulation environment from scratch. Second; this makes a direct comparison of approachesmore difficult. In this paper; we present SmurfPDMS an extensible system that means toprovide a common platform for all researchers in that they can easily integrate theirapproaches and that allows for running large simulation experiments in distributedenvironments such as workstation clusters or even PlanetLab.,BTW,2007,6
Relevanz von Änderungen für Datenbestände mobiler Clients,Hagen Höpfner,Zusammenfassung Aufgrund der Entwicklungen auf dem Sektor der Mobiletelefone istdavon auszugehen; dass die Anzahl kleiner; leichtgewichtiger mobiler Endgeräte; welcheals Clients von Datenbanksystemen genutzt werden; weiter ansteigt. Ein wesentlichesProblem in diesem Szenario ist die langsame und teure Datenübertragung inFunknetzwerken. Aus Sicht der Nutzer derartiger Technologien ist es somit nicht sinnvollbzw. wünschenswert; Daten; welche keinen direkten Nutzen für sie bieten; auf dasMobilgerät zu übertragen. Des Weiteren werden einmal empfangene Daten lokalgespeichert und wiederverwendet (Caching). Ändern sich Daten auf dem Server desInformationssystems; müssen die mobilen Clients; welche von einer Änderung betroffensind; ermittelt und darüber informiert werden. Im Rahmen dieser Dissertation wird gezeigt …,*,2005,6
Efficient Frequent Pattern Mining in Relational Databases.,Xuequn Shang; Kai-Uwe Sattler; Ingolf Geist,Abstract Data mining on large relational databases has gained popularity and itssignificance is well recognized. However; the performance of SQL based data mining isknown to fall behind specialized implementation since the prohibitive nature of the costassociated with extracting knowledge; as well as the lack of suitable declarative querylanguage support. We investigate approaches based on SQL for the problem of findingfrequent patterns from a transaction table; including an algorithm that we recently proposed;called Propad (PROjection PAttern Discovery). Propad fundamentally differs from anApriorilike candidate set generation-and-test approach. This approach successively projectsthe transaction table into frequent itemsets to avoid making multiple passes over the largeoriginal transaction table and generating a huge sets of candidates. We have made …,LWA,2004,6
Cache-supported Processing of Queries in Mobile DBS.,Hagen Höpfner; Kai-Uwe Sattler,Abstract: The usage of mobile equipment like PDAs; mobile phones; Tablet PCs or laptops isalready common in our current information society. Typically; mobile information systemswork in a context dependent (eg location dependent) manner. Considering thischaracteristics; we present a cache which uses trie-based indexing for the optimization ofaccessing data cached on the mobile devices.,Database Mechanisms for Mobile Applications,2003,6
Konzeptbasierte Anfrageverarbeitung in Mediatorsystemen,Kai-Uwe Sattler; Ingolf Geist; Rainer Habrecht; Eike Schallehn,Abstract: Ein Weg zur Überwindung der Heterogenität bei der Datenintegration inMediatorsystemen ist die Nutzung semantischer Metadaten in Form eines Vokabulars odereiner Ontologie zur expliziten Modellierung des Hintergrundwissens. Dementsprechendmuss die verwendete Anfragesprache diese Metaebene in die Anfrageformulierung und-auswertung einbeziehen. In diesem Beitrag wird hierzu ein Mediator für kulturhistorischeDatenbanken vorgestellt; der auf einem konzeptbasierten Integrationsmodell basiert und dieAnfragesprache CQuery–eine XQuery-Erweiterung–implementiert. Weiterhin werdenausgehend von der Semantikdefinition der Anfrageoperationen die Phasen des Rewriting;der Ausführung sowie die Nutzung eines Anfrage-Caches beschrieben.,Gerhard Weikum; Harald Schöning und Erhard Rahm (Herausgeber); Proc. BTW,2003,6
Resource Planning for SPARQL Query Execution on Data Sharing Platforms.,Stefan Hagedorn; Katja Hose; Kai-Uwe Sattler; Jürgen Umbrich,Abstract. To increase performance; data sharing platforms often make use of clusters ofnodes where certain tasks can be executed in parallel. Resource planning and especiallydeciding how many processors should be chosen to exploit parallel processing is complexin such a setup as increasing the number of processors does not always improve runtimedue to communication overhead. Instead; there is usually an optimum number of processorsfor which using more or fewer processors leads to less efficient runtimes. In this paper; wepresent a cost model based on widely used statistics (VoiD) and show how to compute theoptimum number of processors that should be used to evaluate a particular SPARQL queryover a particular configuration and RDF dataset. Our first experiments show the generalapplicability of our approach but also how shortcomings in the used statistics limit the …,COLD,2014,5
Tractor pulling on data warehouses,Martin L Kersten; Alfons Kemper; Volker Markl; Anisoara Nica; Meikel Poess; Kai-Uwe Sattler,Abstract Robustness of database systems under stress is hard to quantify; because there aremany factors involved; most notably the user expectation to perform a job within certainbounds of the user requirements. Nevertheless; robustness of database system is veryimportant to end users. In this paper we develop a database benchmark suite; inspired bytractor pulling; where robustness is measured as a system's ability to process data despite acontinuous increase in system load; as defined in terms of data volume; query volume andcomplexity. A functional evaluation is performed against several systems to highlight thebenchmark capabilities.,Proceedings of the Fourth International Workshop on Testing Database Systems,2011,5
Decentralized change detection in wireless sensor network using dft-based synopsis,Dang-Hoan Tran; Jin Yang; Kai-Uwe Sattler,Wireless sensor networks are often deployed to detect occurring changes in theenvironment. Detectability of the changes in the ambient environment contributes to thesuccess of emerging sensor networks. The major challenges in designing change detectionalgorithms for wireless sensor networks are the restricted resources of sensors such asmemory; communication bandwidth; and battery power. We propose a decentralized changedetection framework for wireless sensor networks; present a novel algorithm using DFTcoefficients as synopsis structures from signal-oriented data streams; which can reduce theamount of local memory required by the change detector while assuring accuracy of localdetection. Furthermore; we show how to use a gossip-based framework for transmitting andaggregating the change detection results from the ambient area of events to the sink. This …,Mobile Data Management (MDM); 2011 12th IEEE International Conference on,2011,5
Decentralized managing of replication objects in massively distributed systems,Daniel Klan; Kai-Uwe Sattler; Katja Hose; Marcel Karnstedt,Abstract Data replication is a central technique to increase availability and performance ofdistributed systems. While offering many advantages it also requires more effort for ensuringdata consistency in case of updates. In the research literature various approaches forreplication management in distributed databases have been presented; but they are mostlylimited either in scalability or in the consistency guarantees they provide. On the other hand;P2P systems usually provide replication support but ignore the update problem. In this paperwe present a new approach for managing replicated data in wide area distributed networks.Our solution is orthogonal to the underlying infrastructure and managed in a decentralizedmanner. It guarantees single-master consistency and allows updates at any node of thesystem by combining traditional replication techniques with ideas known from P2P …,Proceedings of the 2008 international workshop on Data management in peer-to-peer systems,2008,5
Data-Warehouse-Technologien,K Sattler; Gunter Saake; Veit Köppen,Page 1. Data-Warehouse-Technologien Prof. Dr.-Ing. Kai-Uwe Sattler1 Prof. Dr. Gunter Saake2Dr. Veit Köppen2 1TU Ilmenau FG Datenbanken & Informationssysteme 2UniversitätMagdeburg Institut für Technische und Betriebliche Informationssysteme Letzte Änderung:15.12.2014 c Sattler / Saake / Köppen Data-Warehouse-Technologien Letzte Änderung:15.12.2014 0–1 Page 2. Organisatorisches Überblick 1 Einführung & Grundbegriffe 2Data-Warehouse-Architektur 3 Multidimensionales Datenmodell 4 Extraktion; Transformationund Laden 5 Anfragen an Data Warehouses 6 Speicherstrukturen 7 Indexstrukturen 8Anfrageverarbeitung und -optimierung 9 Materialisierte Sichten 10 Business IntelligenceAnwendungen c Sattler / Saake / Köppen Data-Warehouse-Technologien Letzte Änderung:15.12.2014 0–2 Page 3. Organisatorisches Lehrbuch zur Veranstaltung …,Modulhandbuch,2004,5
An Integration Framework for Open Tool Environments.,Georg Paul; Kai-Uwe Sattler; Martin Endig,Abstract Tool environments supporting the development of complex products need to beopen and flexible. These requirements cannot be fulfilled in an adequate way by predefinedcoordination structures and interfaces. Based on the notion of component–oriented softwaredevelopment this paper presents a framework for open tool environments. Besides theruntime environment this framework provides language support for describing toolinterconnections in an implementation–independent manner.,DAIS,1997,5
An approach for incremental semi-supervised svm,Wael Emara; Mehmed Kantardzic Marcel Karnstedt; Kai-Uwe Sattler; Dirk Habich; Wolfgang Lehner,In this paper we propose an approach for incremental learning of semi-supervised SVM. Theproposed approach makes use of the locality of radial basis function kernels to do local andincremental training of semi-supervised support vector machines. The algorithm introducesa se-quential minimal optimization based implementation of the branch and boundtechnique for training semi-supervised SVM problems. The novelty of our approach lies inthe,Data Mining Workshops; 2007. ICDM Workshops 2007. Seventh IEEE International Conference on,2007,4
Autonomes Index Tuning-DBMS-integrierte Verwaltung von Soft Indexen.,Martin Lühring; Kai-Uwe Sattler; Eike Schallehn; Karsten Schmidt,Abstract: Das Self Management in DBMS; und das Self Tuning als wichtiger Teil davon;gewinnt auf Grund der wachsenden Komplexität von Systemen und Anwendungen und dendaraus resultierenden steigenden Betriebskosten zunehmend an Beachtung. Der Stand derTechnik bezüglich des Index Tunings sind Administrations-Tools; die aus einem gegebenenWorkload eine empfohlene Indexkonfiguration ableiten. Diese muss jedoch bei Änderungendes Systems; dessen Umgebung oder der Zugriffsmuster wiederholt angepasst werden. Wirstellen in diesem Beitrag einen dynamischen Ansatz zum Index Tuning vor; der zur Laufzeitdas Systemverhalten und die-nutzung überwacht; Entscheidungen bezüglich möglicherVerbesserungen der aktuellen Indexkonfiguration trifft und diese integriert mit derAnfrageverarbeitung umsetzt. Für den zuletzt genannten Aspekt führen wir mit …,BTW,2007,4
An extensible storage manager for mobile dbms,Erik Buchmann; Hagen Höpfner; Kai-Uwe Sattler,Abstract The increasing usage of mobile devices like PDAs; laptops; or embedded devicesresults in a new type of application which must especially consider the strict limitations of theused mobile hardware. One aspect of the application development is the storage andretrieval of data. For non-mobile application this is often efficiently realized with databasemanagement systems; which offer standardized interfaces and can be easily integrated intothe applications. For mobile devices DBMS are also already available. But existing solutionsare not extensible; and therefore; limited to the builtin functionality. That means also; thatthey include functions which are not always necessary. The optimal DBMS for mobiledatabase systems must allow for the special requirements of its applications in order toreduce the hardware requirements. Thus; it must offer core funtionality which can be …,*,2002,4
Limiting result cardinalities for multidatabase queries using histograms,Kai-Uwe Sattler; Oliver Dunemann; Ingolf Geist; Gunter Saake; Stefan Conrad,Abstract Integrating; cleaning and analyzing data from heterogeneous sources is oftencomplicated by the large amounts of data and its physical distribution which can result inpoor query response time. One approach to speed up the processing is to reduce thecardinality of results–either by querying only the first tuples or by obtaining a sample forfurther processing. In this paper we address the processing of such queries in amultidatabase environment. We discuss implementations of the query operators; strategiesfor their placement in a query plan and particularly the usage of histograms for estimatingattribute value distributions and result cardinalities in order to parameterize the operators.,British National Conference on Databases,2001,4
Integrating Bibliographical Data from Heterogeneous Digital Libraries.,Eike Schallehn; Martin Endig; Kai-Uwe Sattler,Abstract. The integration of bibliographical data today is considered one of the mostimportant tasks in the area of digital libraries. Various available sources of bibliographicalinformation vary widely in terms of data representation and access interfaces. To overcomethis heterogeneity during the last years attempts were made to apply methods developed forinformation system integration; like federated databases and mediators. In this paper wedescribe our approach using the loosely coupled federated system FRAQL. Furthermore; wepresent a generic adapter that can be used in highly distributed scenarios which uses XMLand related technology for transfer and homogenization of data. As an application scenariowe describe global citation linking for integrated digital libraries.,ADBIS-DASFAA Symposium,2000,4
Bitwise dimensional co-clustering for analytical workloads,Stephan Baumann; Peter Boncz; Kai-Uwe Sattler,Abstract Analytical workloads in data warehouses often include heavy joins where queriesinvolve multiple fact tables in addition to the typical star-patterns; dimensional grouping andselections. In this paper we propose a new processing and storage framework called bitwisedimensional co-clustering (BDCC) that avoids replication and thus keeps updates fast; yet isable to accelerate all these foreign key joins; efficiently support grouping and pushes downmost dimensional selections. The core idea of BDCC is to cluster each table on a mix ofdimensions; each possibly derived from attributes imported over an incoming foreign keyand this way creating foreign key connected tables with partially shared clusterings. Theseare later used to accelerate any join between two tables that have some dimension incommon and additionally permit to push down and propagate selections (reduce I/O) and …,The VLDB Journal,2016,3
Efficient Query Processing in Co-Processor-accelerated Databases,Sebastian Breß; Gunter Saake; Jens Teubner; Kai-Uwe Sattler,Abstract Advancements in hardware changed the bottleneck of modern database systemsfrom disk IO to main memory access and processing power. Since the performance ofmodern processors is primarily limited by a fixed energy budget; hardware vendors areforced to specialize processors. Consequently; processors become increasinglyheterogeneous; which already became commodity in the form of accelerated processingunits or dedicated co-processors such as graphics processing units. However; building arobust and efficient query engine for such heterogeneous co-processor environments is stilla significant challenge. Although the database community developed fast parallel algorithmsfor a large number of heterogeneous processors; we still require methods to use theseprocessors efficiently during query processing.,*,2015,3
The pipeflow approach,Omran Saleh; Kai-Uwe Sattler,Abstract In this paper; we present a description of our solution for solving the DEBS GrandChallenge 2015 that targets the analysis of taxi trips. Our implementation of this challenge isbased on a general-purpose stream processing system called P ipe F low; which isdesigned and implemented to efficiently process continuous queries over highvolume/speed data streams with low latency. Moreover; we present an experimentalevaluation to show the effectiveness of the proposed solution with respect to querythroughput and latency.,Proceedings of the 9th ACM International Conference on Distributed Event-Based Systems,2015,3
The pipeflow approach: write once; run in different stream-processing engines,Omran Saleh; Kai-Uwe Sattler,Abstract Recently; some distributed stream computing platforms; such as Storm and SparkStreaming; have been developed for processing massive data streams. However; theseplatforms lack support for higher-level declarative languages and provide only programminginterfaces. Moreover; the users should be well versed of the syntax and programmingconstructs of each language in these platforms. In this paper; we are going to demonstrateour PipeFlow system. In the PipeFlow system; the user can write a stream-processing script(ie; query) using a higher-level dataflow language. This script can be translated into differentstream-processing programs that run in the corresponding engines. In this case; the user isonly willing to know a single language; thus; he/she can write one stream-processing scriptand expects to execute this script on different engines.,Proceedings of the 9th ACM International Conference on Distributed Event-Based Systems,2015,3
On efficient processing of linked stream data,Omran Saleh; Kai-Uwe Sattler,Abstract Today; many application areas require continuous processing of data streams in anefficient manner and real-time fashion. Processing these continuous flows of data;integrating dynamic data with other data sources; and providing the required semantics leadto real challenges. Thus; Linked Stream Data (LSD) has been proposed which combinestwo concepts: Linked Open Data and Data Stream Processing (DSP). Recently; several LSDengines have been developed; including C-SPARQL and CQELS; which are based onSPARQL extensions for continuous query processing. However; this SPARQL-centric viewmakes it difficult to express complex processing pipelines. In this paper; we propose a LSDengine based on a more general stream processing approach. Instead of a variant ofSPARQL; our engine provides a dataflow specification language called PipeFlow which …,OTM Confederated International Conferences" On the Move to Meaningful Internet Systems",2014,3
Sensorbench: benchmarking approaches to processing wireless sensor network data,Ixent Galpin; Alan B Stokes; George Valkanas; Alasdair JG Gray; Norman W Paton; Alvaro AA Fernandes; Kai-Uwe Sattler; Dimitrios Gunopulos,Abstract Wireless sensor networks enable cost-effective data collection for tasks such asprecision agriculture and environment monitoring. However; the resource-constrainednature of sensor nodes; which often have both limited computational capabilities and batterylifetimes; means that applications that use them must make judicious use of these resources.Research that seeks to support data intensive sensor applications has explored a range ofapproaches and developed many different techniques; including bespoke algorithms forspecific analyses and generic sensor network query processors. However; all suchproposals sit within a multi-dimensional design space; where it can be difficult to understandthe implications of specific decisions and to identify optimal solutions. This paper presents abenchmark that seeks to support the systematic analysis and comparison of different …,Proceedings of the 26th International Conference on Scientific and Statistical Database Management,2014,3
Transactional data management services for the cloud,Wolfgang Lehner; Kai-Uwe Sattler,Abstract Since the early years of database applications; transactional processing has beenone of the main use cases of database systems. Applications like booking; billing; fundtransfer in banking; and order processing–usually known as Online TransactionalProcessing (OLTP) applications–require not only to manipulate data but also to ensureatomicity and consistency even in case of concurrent updates.,*,2013,3
On detection of changes in sensor data streams,Dang-Hoan Tran; Kai-Uwe Sattler,Abstract Change detection is the process of identifying differences in the state of an object orphenomenon by observing it at different times. This problem has been researched andapplied in many fields for a long time. However; designing and developing a changedetection algorithm in sensor data streams is a challenging task due to the inherentdifficulties in developing change detection scheme and the restricted resources of sensornetwork. This paper proposes a general framework for detecting changes in sensor datastreams by using data synopsis structures extracted from sensor data streams. We designand implement a specific change detection algorithm by using Discrete Fourier Transform(DFT) to extract DFT coefficients as synopsis structures. We make empirical evaluations ofthe proposed algorithms with both synthetic and real data to show the effectiveness and …,Proceedings of the 9th International Conference on Advances in Mobile Computing and Multimedia,2011,3
Integrating cluster-based main-memory accelerators in relational data warehouse systems,Knut Stolze; Felix Beier; Oliver Koeth; Kai-Uwe Sattler,Abstract Today; data warehouse systems are faced with challenges for providing nearlyrealtime response times even for complex analytical queries on enormous data volumes.Highly scalable computing clusters in combination with parallel in-memory processing ofcompressed data are valuable techniques to address these challenges. In this paper; wegive an overview on core techniques of the IBM Smart Analytics Optimizer—an acceleratorengine for IBM's mainframe database system DB2 for z/OS. We particularly discuss aspectsof a seamless integration between the two worlds and describe techniques exploitingfeatures of modern hardware such as parallel processing; cache utilization; and SIMD. Wedescribe issues encountered during the development and evaluation of our system andoutline current research activities for solving them.,Datenbank-Spektrum,2011,3
Apparatus and method for providing data in a multi-renderer system,*,An apparatus for providing data for wave field synthesis rendering in a wave field synthesissystem with plurality of renderer modules; at least one loudspeaker being associated witheach renderer module; and the loudspeakers associated with the renderer modules beingattachable at different positions in a reproduction room; includes a provider for providing aplurality of audio files; wherein a virtual source at a source position is associated with anaudio file; and a data output for providing the audio file to a renderer with which an activeloudspeaker is associated; with the data output further formed to not provide the audio file toa renderer if all loudspeakers associated with the renderer are not to be active for thereproduction of the source. Thus; unnecessary data transmissions in the wave fieldsynthesis system are avoided; while making optimum use of the renderer maximum …,*,2011,3
Online reorganization in read optimized mmdbs,Felix Beier; Knut Stolze; Kai-Uwe Sattler,Abstract Query performance is a critical factor in modern business intelligence and datawarehouse systems. An increasing number of companies uses detailed analyses forconducting daily business and supporting management decisions. Thus; several techniqueshave been developed for achieving near realtime response times-techniques which try toalleviate I/O bottlenecks while increasing the throughputs of available processing units; ie bykeeping relevant data in compressed main-memory data structures and exploiting the read-only characteristics of analytical workloads. However; update processing and skews in datadistribution result in degenerations in these densely packed and highly compressed datastructures affecting the memory efficiency and query performance negatively.Reorganization tasks can repair these data structures; but--since these are usually costly …,Proceedings of the 2011 ACM SIGMOD International Conference on Management of data,2011,3
Transactions a la carte-implementation and performance evaluation of transactional support on top of amazon s3,Francis Gropengießer; Kai-Uwe Sattler,Most providers of Cloud-based database services favor availability and processingperformance over consistency and hence provide only limited transaction support.Guaranteeing strict consistency is left to application developers. In this paper; we present aflexible transactional framework built on top of Amazon S3. It is intended for processingstructured data under consideration of user-defined ACID guarantees ranging from non-transactional data querying and updating to full transactional data processing ensuring strictACID properties. It supports the development of Cloud-based database applications withoutexplicitly writing code for transactions. Instead; transactional semantics are weaved-inautomatically using aspect-oriented programming techniques. In this way; applicationdevelopers as well as end-users profit from transactional guarantees without having to …,Parallel and Distributed Processing Workshops and Phd Forum (IPDPSW); 2011 IEEE International Symposium on,2011,3
On lightweight data summaries for optimised query processing over linked data,Andreas Harth; Katja Hose; Marcel Karnstedt; Axel Polleres; Kai-Uwe Sattler; Jürgen Umbrich,Abstract. Typical approaches for querying structured Web Data collect (crawl) and pre-process (index) large amounts of data in a central data repository before allowing for queryanswering. This time-consuming pre-processing phase however leverages the benefits ofLinked Data–where structured data is accessible live and up-to-date at distributed Webresources that may change constantly–only to a limited degree; as query results can neverbe up-to-date. An ideal query answering system for Linked Data should return currentanswers in a reasonable amount of time; even on corpora as large as the Web. Queryprocessors evaluating queries directly on the live sources require knowledge of the contentsof data sources. In this paper; we develop and evaluate an approximate index structuresummarising graph-structured content of sources adhering to Linked Data principles …,DERI; NUI Galway; Tech. Rep,2009,3
Cooperative data management for XML data,Katja Hose; Kai-Uwe Sattler,Abstract Emerging non-standard applications like the production of high-quality spatialsound pose new challenges to data management. Beside the need for a flexibletransactional management of complex hierarchical scene descriptions a main requirement isthe support of cooperative processes allowing a group of authors to edit a scene together ina distributed environment. Based on previous work on cooperative and non-standardtransactions we present in this paper a transaction model and protocol for XML databasesaddressing this issues.,International Conference on Database and Expert Systems Applications,2007,3
Interoperability in peer data management systems,Katja Hose; Jana Quasebarth; Kai-Uwe Sattler,ABSTRACT Interoperability plays an important role for a variety of applications. One of themare Peer Data Management Systems; where autonomous data sources (peers) interact witheach other based on semantic mappings between their schemas. The building blocks thatenable interoperability and thus the main challenges in such systems are mappingrepresentation; query rewriting; and efficient query processing. While most approachesregard these aspects in separate this paper presents a comprehensive study of theinteractions between these blocks. Our considerations try to provide a holistic view onsemantic interoperability in distributed environments such as PDMS. We discuss techniquesfor distributed query processing and rewriting that consider high-level query operators suchas top-N and skyline. Furthermore; we discuss how to increase efficiency by applying …,SDSI,2007,3
Objektrelationale Datenbanken,Gunter Saake; C Türker,*,Ein Lehrbuch. Heidelberg,2006,3
Towards Trie Based Indexing of Mobile Clients in Large Mobile Information Systems,Hagen Höpfner; Stephan Schosser; Kai-Uwe Sattler,Abstract Due to the increasing usage of small and low footprinted devices like mobilephones as clients of mobile information systems a new problem arises:“How to determinethe relevance of updates for a large number of mobile clients?” In this paper we present anindexing scheme that represents conjunctive queries posed by the mobile clients in a trie.So; IDs of the clients are referenced by their queries and checking the relevance of anupdate is done by traversing the trie.,*,2004,3
D-Loop-BASE is online now Central European database of mitochondrial DNA,Holger Wittig; Mike Koecke; Kai-Uwe Sattler; Dieter Krause,Abstract At the 18th Stain workshop held in Magdeburg in 1998; 15 university institutes offorensic medicine from Germany; Austria and Switzerland agreed to establish a CentralEuropean database of forensically secured mitochondrial DNA (mtDNA) sequences as acommon project at the Magdeburg institute. Since then; more than 1600 sequences havebeen included into the D-Loop-BASE data stock which is now a profound basis for bothfrequency inquiries for expert opinions and scientific investigations into population geneticmatters. Due to the consent agreement signed by the institutes involved; it was not possiblein the beginning to access the data via the Internet; which made it difficult for all partiesinterested to use this database. Among the number of mtDNA databases in the Internet;there has been only one to date offering access to its data which; however; could be used …,International Congress Series,2003,3
Konfliktbehandlung in einer Anfragesprache für Datenbankföderationen.,Kai-Uwe Sattler; Stefan Conrad,Zusammenfassung Ein Hauptproblem bei der Integration heterogener Datenbeständebilden Konflikte; die durch unterschiedliche Modellierung eines Sachverhaltes der Real-Welt; durch verschiedene Datenmodelle oder auch nur durch unterschiedlicheRepräsentation der Real-Welt-Objekte entstehen. Die Konflikte müssen im Rahmen derIntegration erkannt und bei der Definition der Abbildung zwischen globalen und lokalenSchemata aufgelöst werden. Da diese Abbildung die Grundlage für die Bearbeitung vonAnfragen ist; ergibt sich eine enge Verzahnung von Konfliktbehandlung;Anfragetransformation und-ausführung. Vor diesem Hintergrund wird in diesem Beitrag eineAnfragesprache für Datenbankföderationen vorgestellt und die Behandlung der wichtigstenKonflikte mit den Mitteln dieser Sprache diskutiert.,Föderierte Datenbanken,1999,3
The STARK Framework for Spatio-Temporal Data Analytics on Spark,Stefan Hagedorn; Philipp Götze; Kai-Uwe Sattler,Big Data sets can contain all types of information: from server log files to tracking informationof mobile users with their location at a point in time. Apache Spark has been widelyaccepted for Big Data analytics because of its very fast processing model. However; Sparkhas no native support for spatial or spatio-temporal data. Spatial filters or joins using; eg; acontains predicate are not supported and would have to be implemented ine ciently by theusers. Also; Spark cannot make use of; eg; spatial distribution for optimal partitioning. Herewe present our STARK framework that adds spatio-temporal support to Spark. It includesspatial partitioners; different modes for indexing; as well as filter; join; and clusteringoperators. In contrast to existing solutions; STARK integrates seamlessly into any (Scala)Spark program and provides more flexible and comprehensive operators. Furthermore …,Datenbanksysteme für Business; Technologie und Web (BTW 2017),2017,2
A hierarchical approach to resource awareness in dhts for mobile data management,Liz Ribe-Baumann; Kai-Uwe Sattler,Abstract Data is increasingly distributed across heterogeneous networks of mobile nodessuch as distributed smartphone applications; where nodes' access to resources such asbattery power; connectivity; or computing power varies; but must still be reliably collected;stored; and retrieved. In this paper; we present a scalable; location aware; hierarchical DHTthat utilizes nodes' varying resource availability levels to increase the mobile network's datastorage and retrieval capabilities. We compare this hierarchical DHT to other location awareflat and hierarchical approaches; examining the structures' suitability for nodes with varyingresource availability; and examine the effects of varying numbers of hierarchy levels.,Pervasive and Mobile Computing,2014,2
LODHub—A platform for sharing and integrated processing of linked open data,Stefan Hagedorn; Kai-Uwe Sattler,In this paper we discuss the need for a new platform that combines existing solutions forpublishing and sharing linked open data with the infrastructure of services for exploring;processing; and analyzing data across multiple data sets. We identify various requirementsfor such a platform; describe the architecture; and sketch initial results of our prototype.,Data Engineering Workshops (ICDEW); 2014 IEEE 30th International Conference on,2014,2
Data Warehouse Technologien,Gunter Saake; Kai-Uwe Sattler; Veit Köppen,*,*,2014,2
10381 Summary and Abstracts Collection--Robust Query Processing,Götz Graefe; Arnd Christian König; Harumi Anne Kuno; Volker Markl; Kai-Uwe Sattler,Abstract Dagstuhl seminar 10381 on robust query processing (held 19.09. 10-24.09. 10)brought together a diverse set of researchers and practitioners with a broad range ofexpertise for the purpose of fostering discussion and collaboration regarding causes;opportunities; and solutions for achieving robust query processing. The seminar strove tobuild a unified view across the loosely-coupled system components responsible for thevarious stages of database query processing. Participants were chosen for their experiencewith database query processing and; where possible; their prior work in academic researchor in product development towards robustness in database query processing. In order topave the way to motivate; measure; and protect future advances in robust query processing;seminar 10381 focused on developing tests for measuring the robustness of query …,Dagstuhl Seminar Proceedings,2011,2
Cloudy Transactions: Cooperative XML Authoring on Amazon S3.,Francis Gropengießer; Stephan Baumann; Kai-Uwe Sattler,Abstract: Over the last few years cloud computing has received great attention in theresearch community. Customers are entitled to rent infrastructure; storage; and evensoftware in form of services. This way they just have to pay for the actual use of thesecomponents or services. Cloud computing also comes with great opportunities for distributeddesign applications; which often require multiple users to work cooperatively on shareddata. In order to enable cooperation; strict consistency is necessary. However; cloud storageservices often provide only eventual consistency. In this paper; we propose a system thatallows for strict consistent and cooperative XML authoring in distributed environments basedon Amazon S3. Our solution makes use of local and distributed transactions; which aresynchronized in an optimistic fashion; in order to ensure correctness. An important …,BTW,2011,2
Optimistic synchronization of cooperative xml authoring using tunable transaction boundaries,Francis Gropengießer; Kai-Uwe Sattler,Design applications; eg; CAD or media production; often require multiple users to workcooperatively on shared data; eg; XML documents. Using explicit transactions in suchenvironments is difficult; because designers usually do not want to consider transactions orACID. However; applying transactions in order to control visibility of changes or specifyrecovery units; is reasonable; but determining transaction boundaries must be transparentfor the designer. For this reason we propose a novel approach for the automaticdetermination of transaction boundaries which considers the degree of cooperationdesigners want to achieve. Furthermore; we present an optimistic synchronization modelbased on the traditional backward oriented concurrency control (BOCC) algorithm; in orderto synchronize the determined transactions in multi-user environments. It exploits the …,Advances in Databases Knowledge and Data Applications (DBKDA); 2010 Second International Conference on,2010,2
Query Processing in a DHT-Based Universal Storage-The World as a Peer-toPeer Database,Marcel Karnstedt,CiteSeerX - Document Details (Isaac Councill; Lee Giles; Pradeep Teregowda): von / by.,*,2009,2
Ein kooperativer XMLEditor für Workgroups.,Francis Gropengießer; Katja Hose; Kai-Uwe Sattler,Abstract: In vielen Anwendungsgebieten; zB im Design oder inMedienproduktionsprozessen; hat sich XML als Format für den Datenaustausch etabliert.Zur Verarbeitung von XML-Daten in Mehrbenutzerumgebungen sind spezielle Werkzeugenötig. Allerdings berücksichtigen die derzeit auf dem Markt verfügbaren Editoren nurunzureichend die Anforderungen kooperativer Arbeitsumgebungen. In dieser Arbeit wirddaher ein transaktionsbasierter XML-Editor vorgestellt; der diese Anforderungen erfüllt. Er istfür den Einsatz in eng gekoppelten Systemumgebungen; auch Workgroups genannt;konzipiert. Der Editor erlaubt ein intuitives Bearbeiten von XML-Daten und machtAnderungen eines Nutzers an den Daten anderen Nutzern sehr früh zugänglich. Weiterhinermöglicht er durch dein Einsatz eines intelligenten Sperrprotokolls einen hochgradig …,BTW,2009,2
Quality of service and predictability in dbms,Kai-Uwe Sattler; Wolfgang Lehner,Abstract DBMS are a ubiquitous building block of the software stack in many complexapplications. Middleware technologies; application servers and mapping approaches hidethe core database technologies just like power; networking infrastructure and operatingsystem services. Furthermore; many enterprise-critical applications demand a certaindegree of quality of service (QoS) or guarantees; eg wrt. response time; transactionthroughput; latency but also completeness or more generally quality of results. Examples ofsuch applications are billing systems in telecommunication; where each telephone call hasto be monitored and registered in a database; Ecommerce applications where orders haveto be accepted even in times of heavy load and the waiting time of customers should notexceed a few seconds; ERP systems processing a large number of transactions in …,Proceedings of the 11th international conference on Extending database technology: Advances in database technology,2008,2
Light-weight Internet-scale Universal Storage,Marcel Karnstedt; Kai-Uwe Sattler; Manfred Hauswirth; Roman Schmidt,ABSTRACT Many new applications; for example Wikis; social networks; and distributedrecommender systems; require the efficient integration of decentralized and heterogenousdata sources at a large scale. In this paper; we present our vision of a universal storage forRDF-like triple data based on a structured P2P system and the universal relation model asits key enabling technologies to achieve flexibility; robustness; and efficiency for large-scaledistributed data storage and query processing. We outline the steps we have alreadyaccomplished successfully and discuss a roadmap to achieve the final goal of a practical;light-weight implementation of our storage system.,*,2006,2
Modelling and streaming spatiotemporal audio data,Thomas Heimrich; Katrin Reichelt; Hendrik Rusch; Kai-Uwe Sattler; Thomas Schröder,Abstract In this paper; we describe a special application domain of data management–theproduction of high-quality spatial sound. The IOSONO system; developed by FraunhoferIDMT; is based on the wave field synthesis. Here; a large number of loudspeakers isinstalled around the listening room. A rendering component computes the signal for eachindividual speaker from the position of the audio source in a scene and the characteristics ofthe listening room. So; we can achieve the impression that sound sources are on specificpositions in the listening room.,Proceedings of the 2005 OTM Confederated international conference on On the Move to Meaningful Internet Systems,2005,2
Processing sequential patterns in relational databases,Xuequn Shang; Kai-Uwe Sattler,Abstract Database integration of data mining has gained popularity and its significance iswell recognized. However; the performance of SQL based data mining is known to fallbehind specialized implementation since the prohibitive nature of the cost associated withextracting knowledge; as well as the lack of suitable declarative query language support.Recent studies have found that for association rule mining and sequential pattern miningwith carefully tuned SQL formulations it is possible to achieve performance comparable tosystems that cache the data in files outside the DBMS. However most of the previous patternmining methods follow the method of Apriori which still encounters problems when asequential database is large and/or when sequential patterns to be mined are numerousand long. In this paper; we present a novel SQL based approach that we recently …,International Conference on Data Warehousing and Knowledge Discovery,2005,2
Verteilte Anfrageverarbeitung in DHT-basierten P2P-Systemen.,Philipp Rösch; Christian von der Weth; Kai-Uwe Sattler; Erik Buchmann,Abstract: Peer-to-Peer (P2P)-Systeme und hierbei speziell verteilte Datenstrukturenversprechen Skalierbarkeit bis auf Internet-Größe bei fairer Verteilung derInfrastrukturkosten und hoher Robustheit. Für viele potenzielle Anwendungen sind die vonderartigen Systemen unterstützten einfachen Schlüsselzugriffe nicht ausreichend–vielmehrist die Verwaltung und Anfrage komplex strukturierter Daten notwendig. In diesem Beitraguntersuchen wir daher; ob und wie sich Operationen und Strategien für die verteilteVerarbeitung SQL-artiger Anfragen in P2P-Systemen auf Basis verteilter Hashtabelleneffizient realisieren lassen.,BTW,2005,2
An Indexing Scheme for Update Propagation in Large Mobile Information Systems,Hagen Höpfner; Stephan Schosser; Kai-Uwe Sattler,Abstract. Due to the increasing usage of small and low footprinted devices like mobilephones as clients of mobile information systems a new problem arises:“How to determinethe relevance of updates for a large number of mobile clients?” In this paper we present anindexing scheme that represents conjunctive queries posed by the mobile clients in a trie.So; IDs of the clients are referenced by their queries and checking the relevance of anupdate can be efficiently done by a trie lookup.,Proceedings of the EDBT-Workshop on Pervasive Information Management,2004,2
Query Reformulation for Keyword Searching in Mediator Systems,Ingolf Geist; Torsten Declercq; Kai-uwe Sattler; Eike Schallehn,Abstract Integration of heterogeneous data sources is still an important task. Mediatorsystems are one approach to support a structured search over heterogeneous sources.These systems provide comprehensive query languages; which are very powerful but hardto use for inexperienced users. Therefore; easier query interfaces have to be developed.One well-known and effective interface is the keyword search. However; one has to considerthe capabilities of sources; which mostly support only structured queries. The aim of thispaper is the development of a keyword query component based on a conceptbasedmediator to overcome this problem. The efficient keyword query execution is supported byan index on global level as well as a concept model; consisting of concepts and theirproperties and relationships. The search is performed in a two-step process that …,*,2003,2
Algorithmen und Datenstrukturen,KU Sattler; G Saake,*,Eine Einführung mit Java,2001,2
Combining a Formal with an Example-driven Approach for Data Integration.,Ingolf Geist; Kai-Uwe Sattler; Ingo Schmitt,Abstract Integrating data sources is a general problem in many scenarios. The main problemis the heterogeneity between data sources which were created and developed separately. Inthe literature there exist many different approaches to solve that problem. Schemaintegration approaches derive an integrated schema by resolving conflicts on schema anddata model level. Another kind of approaches are multidatabase languages and systemswhich define and verify views on top of example databases. They try to map local data to apredefined; integrated schema. In this paper we investigate how the schema integrationapproach GIM and the example-driven approach VIBE basing on FRAQL can be combinedfor a new combined approach. The combined approach benefits from the powerful mappinglanguage FRAQL and the verification feature by using example databases and from the …,Föderierte Datenbanken,2001,2
Datenbank-und Visualisierungstechnologien in der Informationsfusion.,Gunter Saake; Kai-Uwe Sattler; Daniel A Keim,Zusammenfassung In vielen Anwendungsbereichen besteht die Aufgabe; Daten oderInformationen aus verschiedenen; zum Teil heterogenen Quellen zu kombinieren; zuverdichten und daraus Informationen einer neuen Qualität abzuleiten. WesentlicheKernfunktionen dieses als Informationsfusion bezeichneten Prozesses sind dabei durchMethoden der Datenintegration und der Datenanalyse/Data Mining bereitzustellen. Diegewachsenen Strukturen der heute genutzten Informationsquellen und die damit imZusammenhang stehenden Probleme wie Heterogenität; Inkonsistenz oder Ungenauigkeitder Daten sind mit den aktuell verfügbaren Techniken nur bedingt beherrschbar.Ausgehend vom aktuellen Stand der Forschung diskutiert der vorliegende BeitragAnforderungen an Datenbank-und Visualisierungstechnologien aus Sicht der …,SimVis,2000,2
SIGMAFDB: Overview of the Magdeburg-Approach to Database Federations.,Michael Höding; Kerstin Schwarz; Stefan Conrad; Gunter Saake; Sören Balko; A Diekmann; Eyk Hildebrandt; Kai-Uwe Sattler; Ingo Schmitt; Can Türker,Kurzfassung: The SIGMA FDB project attempts to offer an approach to schema integrationand integrity constraint maintenance in the field of federated database systems. In thisextended abstract; we present our view on federated database systems and sketch the mainresults of our group's work. Especially; we briefly discuss different research aspects andimplementation activities.,EFIS,1999,2
MediatorService-Integration von verteilten Objekten durch Beschreibung der Interaktionen,Georg Paul; Kai-Uwe Sattler,Zusammenfassung Bei einer Vielzahl von Softwareentwicklungsaufgaben spielt dieIntegration vorhandener Softwarekomponenten eine wichtige Rolle. Moderne verteilteArchitekturen wie CORBA k onnen f ur diese Aufgaben die geeignete Systembasisbereitstellen; erfordern aber oft betr achtliche Anderungen am Quellcode der Komponenten.Eine der Ursachen hierf ur liegt in der unzureichenden Unterst utzung vonInteraktionsbeziehungen durch das CORBA {Objektmodell. Ausgehend von der in derLiteratur beschriebenen Mediator {Methode wird daher im vorliegenden Artikel ein CORBA{basierter Objektservice vorgestellt; der durch die Realisierung expliziterInteraktionsbeziehungen die Integration existierender Softwarekomponenten vereinfacht.,Proc. Int. Workshop Trends in Distributed Systems,1996,2
Big Spatial Data Processing Frameworks: Feature and Performance Evaluation.,Stefan Hagedorn; Philipp Götze; Kai-Uwe Sattler,ABSTRACT Nowadays; a vast amount of data is generated and collected every moment andoften; this data has a spatial and/or temporal aspect. To analyze the massive data sets; bigdata platforms like Apache Hadoop MapReduce and Apache Spark emerged andextensions that take the spatial characteristics into account were created for them. In thispaper; we analyze and compare existing solutions for spatial data processing on Hadoopand Spark. In our comparison; we investigate their features as well as their performances ina micro benchmark for spatial filter and join queries. Based on the results and ourexperiences with these frameworks; we outline the requirements for a general spatio-temporal benchmark for Big Spatial Data processing platforms and sketch first solutions tothe identified problems.,EDBT,2017,1
Refining imprecise spatio-temporal events: a network-based approach,Andreas Spitz; Johanna Geiß; Michael Gertz; Stefan Hagedorn; Kai-Uwe Sattler,Abstract Events as composites of temporal; spatial and actor information are a central objectof interest in many information retrieval (IR) scenarios. There are several challenges to suchevent-centric IR; which range from the detection and extraction of geographic; temporal andactor mentions in documents to the construction of event descriptions as triples of locations;dates; and actors that can support event query scenarios. For the latter challenge; existingapproaches fall short when dealing with imprecise event components. For example; if theexact location or date is unknown; existing IR methods are often unaware of differentgranularity levels and the conceptual proximity of dates or locations. To address theseproblems; we present a framework that efficiently answers imprecise event queries; whosegeographic or temporal component is given only at a coarse granularity level. Our …,Proceedings of the 10th Workshop on Geographic Information Retrieval,2016,1
Stream processing platforms for analyzing big dynamic data,Stefan Hagedorn; Philipp Götze; Omran Saleh; Kai-Uwe Sattler,Abstract Nowadays; data is produced in every aspect of our lives; leading to a massiveamount of information generated every second. However; this vast amount is often too largeto be stored and for many applications the information contained in these data streams isonly useful when it is fresh. Batch processing platforms like Hadoop MapReduce do not fitthese needs as they require to collect data on disk and process it repeatedly. Therefore;modern data processing engines combine the scalability of distributed architectures with theone-pass semantics of traditional stream engines. In this paper; we survey the current stateof the art in scalable stream processing from a user perspective. We examine and describetheir architecture; execution model; programming interface; and data analysis support aswell as discuss the challenges and limitations of their APIs. In this connection; we …,it-Information Technology,2016,1
DFG-Schwerpunktprogramm „Skalierbares Datenmanagement für zukünftige Hardware “,Kai-Uwe Sattler,Zusammenfassung Der Senat der DFG hat Ende März 2016 die Einrichtung von 17 neuenSchwerpunktprogrammen beschlossen. Eines dieser neu eingerichteten Programme ist dasSPP 2037 zum Thema „Skalierbares Datenmanagement für zukünftige Hardware “; das ausder GI-Fachgruppe Datenbanksysteme heraus gemeinsam von Alfons Kemper (TUMünchen); Thomas Neumann (TU München); Kai-Uwe Sattler (TU Ilmenau) und JensTeubner (TU Dortmund) initiiert wurde. Ziel des Programms ist es; die bundesweitenForschungsaktivitäten im Datenbankbereich und angrenzenden Gebieten zu bündeln; umneue; variable Datenmanagementlösungen zu entwickeln; die zukünftigenHerausforderungen gerecht werden.,Datenbank-Spektrum,2016,1
A framework for scalable correlation of spatio-temporal event data,Stefan Hagedorn; Kai-Uwe Sattler; Michael Gertz,Abstract Spatio-temporal event data do not only arise from sensor readings; but also ininformation retrieval and text analysis. However; such events extracted from a text corpusmay be imprecise in both dimensions. In this paper we focus on the task of event correlation;ie; finding events that are similar in terms of space and time. We present a framework forApache Spark that provides correlation operators that can be configured to deal with suchimprecise event data.,British International Conference on Databases,2015,1
Konsistenz in Cloud-Datenbanken,Erhard Rahm; Gunter Saake; Kai-Uwe Sattler,Zusammenfassung Die bisher diskutierten Verfahren zur Konsistenzsicherung in VerteiltenDatenbanksystemen zielen auf strikte Konsistenz; also kurz gefasst auf die Gewährleistungder ACID-Eigenschaften unter allen Umständen. Derartige Verfahren skalieren jedoch oftnur eingeschränkt und begrenzen die Leistungsfähigkeit der betroffenen Systeme. Daherwurden und werden gerade in Cloud-Anwendungen abgeschwächteKonsistenzforderungen und zugehörige Verfahren diskutiert; die besser skalieren; aberEinschränkungen in der Konsistenz bedeuten. Der erste Abschnitt dieses Kapitels motiviertund detailliert den Einsatz abgeschwächter Konsistenzforderungen in Cloud-Szenarien.Replikationstechniken; die durch derartige abgeschwächte Konsistenzforderungenermöglicht werden; werden danach behandelt. Abschließend wird die Realisierung …,*,2015,1
LODHub-A Platform for Sharing and Analyzing large-scale Linked Open Data.,Stefan Hagedorn; Kai-Uwe Sattler,Abstract. In this demo paper we describe the current prototype of our new platform LodHubthat allows users to publish and share linked datasets. The platform further allows to runSPARQL queries and execute Pig scripts on these datasets to support users in their dataprocessing and analysis tasks.,International Semantic Web Conference (Posters & Demos),2014,1
Autonomic physical database design–from indexing to multidimensional clustering,Stephan Baumann; Kai-Uwe Sattler,Abstract Database design is a well-studied and well-understood problem in developingdatabase applications. However; modern application requirements in terms of queryresponse time; query throughput; database sizes; database maintenance and databaseinteractivity capabilities on the one hand; and the manifold features of modern DBMS forphysical schema design such as numerous different index structures; materialized views;partitioning; and clustering schemes on the other hand make high demands on the databasedesign process. With this growing number of impact factors on physical database designautomatic solutions have been developed and are provided in most systems; while researchin this area still continues. In this paper; we give a survey on the state of the art in autonomicphysical design. Starting with the classic index tuning problem and possible solutions; we …,it–Information Technology,2014,1
Learning Event Patterns for Gesture Detection.,Felix Beier; Nedal Alaqraa; Yuting Lai; Kai-Uwe Sattler,ABSTRACT Usability often plays a key role when software is brought to market; includingclearly structured workflows; the way of presenting information to the user; and; last but notleast; how he interacts with the application. In this context; input devices as 3D cameras or(multi-) touch displays became omnipresent in order to define new intuitive ways of userinteraction. State-of-the-art systems tightly couple application logic with separate gesturedetection components for supported devices. Hard-coded rules or static models obtained byapplying machine learning algorithms on many training samples are used in order torobustly detect a pre-defined set of gesture patterns. If possible at all; it becomes difficult toextend these sets with new patterns or to modify existing ones–difficult for both; applicationdevelopers and end users. Further; adding gesture support for legacy software or for …,EDBT,2014,1
Communication-Efficient Exact Clustering of Distributed Streaming Data,Dang-Hoan Tran; Kai-Uwe Sattler,Abstract A widely used approach to clustering a single data stream is the two-phasedapproach in which the online phase creates and maintains micro-clusters while the off-linephase generates the macro-clustering from the micro-clusters. We use this approach topropose a distributed framework for clustering streaming data. Every remote-site processgenerates and maintains micro-clusters that represent cluster information summary from itslocal data stream. Remote sites send the local micro-clusterings to the coordinator; or thecoordinator invokes the remote methods in order to get the local micro-clusterings from theremote sites. Having received all the local micro-clusterings from the remote sites; thecoordinator generates the global clustering by the macro-clustering method. Our theoreticaland empirical results show that the global clustering generated by our distributed …,International Conference on Computational Science and Its Applications,2013,1
Automatic schema design for co-clustered tables,Stephan Baumann; Peter Boncz; Kai-Uwe Sattler,Schema design of analytical workloads provides opportunities to index; cluster; partitionand/or materialize. With these opportunities also the complexity of finding the right setuprises. In this paper we present an automatic schema design approach for a table co-clustering scheme called Bitwise Dimensional Co-Clustering; aimed at schemas with amoderate amount dimensions; but not limited to typical star and snowflake schemas. Thegoal is to design one primary schema and keep the knobs to turn to a minimum whileproviding a robust schema for a wide range of queries. In our approach a clustered schemais derived by trying to apply dimensions throughout the whole schema and co-cluster asmany tables as possible according to at least one common dimension. Our approach isbased on the assumption that initially foreign key relationships and a set of dimensions …,Data Engineering Workshops (ICDEW); 2013 IEEE 29th International Conference on,2013,1
Overview and Comparison of Current Database-as-a-Service Systems,Wolfgang Lehner; Kai-Uwe Sattler,Abstract As described in Chap. 1 the different services that can be obtained from a cloud aretypically classified by the categories Infrastructure-as-a-Service (IaaS); Platform-as-a-Service (PaaS); and Software-as-a-Service (SaaS). The three different layers are oftendisplayed as a stack; indicating that the services of one cloud layer can be built based on theservices offered by the lower layers. For example; a Software-as-a-Service application canexploit the scalability and robustness offered by the services on the Platform-as-a-Servicelayer. That way the Software-as-a-Service application is in the position to achieve goodscalability and availability properties by itself.,*,2013,1
Virtualization for Data Management Services,Wolfgang Lehner; Kai-Uwe Sattler,Abstract Virtualization is the key concept to provide a scalable and flexible computingenvironment in general. In this chapter; we focus on virtualization concepts in the context ofdata management tasks. We review existing concepts and technologies spanning multiplesoftware layers.,*,2013,1
Special issue on querying the data web,Paolo Ceravolo; Chengfei Liu; Mustafa Jarrar; Kai-Uwe Sattler,The rapid growth of structured data on the Web has created a high demand for making thiscontent more reusable and consumable. Companies are competing not only on gatheringstructured content and making it public; but also on encouraging people to reuse and profitfrom this content. Many companies have made their content publicly accessible not onlythrough APIs but also started to widely adopt web metadata standards such as XML; RDF;RDFa; and microformats. This trend of structured data on the Web (Data Web) is shifting thefocus of Web technologies towards new paradigms of structured-data retrieval. Traditionalsearch engines cannot serve such data as the results of a keyword-based query will not beprecise or clean; because the query itself is still ambiguous although the underlying data isstructured. On the other side; traditional structured querying languages cannot be used …,World Wide Web,2011,1
Autonomous workload-driven reorganization of column groupings in MMDBS,Felix Beier; Knut Stolze; Kai-Uwe Sattler,A current trend to achieve high query performance even for huge data warehouse andbusiness intelligence systems is to exploit main-memory-based processing techniques suchas compression; cache-conscious strategies; and optimized data structures. However;update processing and skews in data distribution might lead to degenerations in suchdensely packed and highly compressed data structures affecting the memory efficiency andquery performance negatively. Thus; reorganization tasks for repairing these data structuresare necessary but should be carefully applied in order to not impact query execution or evensystem availability significantly. In this paper; we consider the special problem of tuple layoutin banked storage structures. Based on runtime statistics capturing typical access patterns inthe current workload; we present a bank reassignment approach that can be piggybacked …,Data Engineering Workshops (ICDEW); 2011 IEEE 27th International Conference on,2011,1
AnduIN: Anwendungsentwicklung für drahtlose Sensornetzwerke,Daniel Klan; Kai-Uwe Sattler,Zusammenfassung Eine der größten Herausforderung bei der Anwendungsentwicklung fürdrahtlose Sensornetzwerke ist der effiziente Umgang mit den oftmals stark beschränktenRessourcen. Die Entwicklung neuer Systeme gestaltet sich entsprechend aufwendig undteuer. In der vorliegenden Arbeit soll mit AnduIN ein Ansatz gezeigt werden; welcher dieEntwicklung entsprechender Lösungen dahingehend vereinfacht; dass lediglich dieZielstellung beschrieben werden muss. Das System analysiert diese und entscheidetselbstständig; welche Funktionen in welcher Form zu realisieren sind.,Datenbank-Spektrum,2011,1
Quantitatives Frequent Pattern Mining in drahtlosen Sensornetzen.,Daniel Klan; Thomas Rohe; Kai-Uwe Sattler,Abstract: In drahtlosen Sensornetzen ist die effiziente und möglichst sensorlokale Analyseder Daten ein wichtiger Ansatz zur Verlängerung der Batterielaufzeit der Sensoren. Nebenden klassischen primitiven Analyseverfahren; wie zum Beispiel Filtern oder Aggregation;werden zunehmend auch komplexe Verfahren teilweise oder vollständig innerhalb derGrenzen der Sensornetze verarbeitet. Die vorliegende Arbeit widmet sich einem dieserVerfahren–der Erkennung von häufig auftretenden Mustern (Frequent Itemsets) überAttributen mit kontinuierlichen Werten. Schwerpunkt ist die teilweise Auslagerung desvorgestellten Verfahrens auf die Knoten des Sensornetzes.,BTW Workshops,2011,1
Comparing and Refining Gossip Protocols for Fault Tolerance in Wireless P2P Systems,Jin Yang; Tobias Simon; Christopher Mueller; Daniel Klan; Kai-Uwe Sattler,As a special type of wireless P2P systems; sensor networks are often deployed for detectingevents caused by disasters. The peer-to-peer mode of the sensor system itself getschallenged either directly by damages of the disaster or by unreliable wireless links. Thiswork explores possible failure models and compares the performance of several gossipprotocols corresponding to the failures models. With further refinement of the gossipprotocols; the performance in the failure modes caused by disasters is improved. Theevaluation of our simulation results shows that using refined gossip protocols incorrespondence to the failure models; the information aggregation and disseminationspeed; communication cost and the accuracy of the aggregated data can be improved.,Parallel; Distributed and Network-Based Processing (PDP); 2011 19th Euromicro International Conference on,2011,1
A small-world DHT built on generalized network coordinates,Liz Ribe-Baumann; Kai-Uwe Sattler,Abstract Large-scale distributed hash tables (DHT) are typically implemented withoutrespect to node location or characteristics; thus producing physically long routes andsquandering network resources. Some systems have integrated round trip times throughproximity-aware identifier selection (PIS); proximity-aware route selection (PRS); andproximity-aware neighbor selection (PNS). While PRS and PNS tend to optimize existingsystems; PIS deterministically selects node identifiers based on physical node location;leading to a loss of scalability and robustness. The trade off between the scalability androbustness gained from a DHT's randomness and the better allocation of network resourcesthat comes with a location-aware; deterministically structured DHT make it difficult to designa system that is both robust and scalable and resource conserving. We present initial …,Proceedings of the 2010 EDBT/ICDT Workshops,2010,1
Report: 5th Int'l Workshop on Self-Managing Database Systems (SMDB 2010).,Shivnath Babu; Kai-Uwe Sattler,The SMDB Workshop series sponsored by the IEEE TCDE Workgroup on Self-ManagingDatabase Systems brings together researchers and practitioners to exchange ideas relatedto autonomic data management systems. Previous workshops of the SMDB series focusedon core topics in self-managing databases like physical design tuning; problem diagnosisand recovery; and database integration and protection. In addition to core topics; the 2010workshop aimed to broaden the interest range by covering emerging research areas likeCloud computing; multitenant databases; large-scale storage systems; and datacenteradministration.,IEEE Data Eng. Bull.,2010,1
Distributed Join,Kai-Uwe Sattler,realized using such logical structures. For example; in tree based data acquisition protocols;a collection tree is built that is rooted at the data collection center such as the sink node [8].The dissemination of the data requests from the participating nodes and collection of datafrom the sensor nodes are accomplished using this tree. A cluster based data acquisitionmechanism has been proposed in [3]. As shown in Fig. 1; nodes are organized into a fixednumber of clusters; and nodes within each cluster dynamically elect a cluster head. The dataacquisition is carried out in two phases. In the first phase; cluster heads collect data fromtheir cluster nodes. In the second phase; cluster heads send collected data to the nodes thathave subscribed to the data. The cluster heads are re-elected to balance energyconsumption among the nodes in the cluster. Zhang et al.[13] have proposed an adaptive …,*,2009,1
Semijoin,Kai-Uwe Sattler,The values in the relations of a relational database are elements of one or more underlyingsets called domains. In practical applications; a domain may be infinite; eg; the set of naturalnumbers. In this case; the value of a relational calculus query when applied to such adatabase may be infinite; eg;{njn! 10}. A query Q is called finite if the value of Q whenapplied to any database is finite. Even when the database domains are finite; all that isnormally known about them is that they are some finite superset of the values that occur inthe database. In this case; the value of a relational calculus query may depend on such anunknown domain; eg;{xj 8yR (x; y)}. A query Q is called domain independent if the value of Qwhen applied to any database is the same for any two domains containing the databasevalues or; equivalently; if the value of Q when applied to a database contains only values …,*,2009,1
Quality of service-driven stream mining,Marcel Karnstedt; Kai-Uwe Sattler; Dirk Habich; Wolfgang Lehner,Abstract Scalable stream processing systems have to continuously manage changingresources efficiently; which is usually achieved by applying best-effort approaches on thelevel of processing operations. Thus; several authors have recently dealt with the problem ofresource-aware stream processing; proposing methods and techniques capable of adaptingto changing resources; both on the system and operator level. In this paper; we argue thatQuality-of-Service (QoS) requirements are as mandatory as resource awareness whencreating stream processing systems applicable in a wide and general range of data streamapplications. We discuss QoS requirements and QoS-driven stream mining techniques asbuilding blocks of the proposed framework for resource-and quality-aware streamprocessing systems. We exemplify the applicability of our approach by presenting and …,Proceedings of the 2nd International Workshop on Data Stream Mining and Management in conjunction with the 7th IEEE International Conference on Data Mining,2007,1
Working Group Report on Managing and Integrating Data in P2P Databases,Peter A Boncz; Angela Bonifati; Peter Janacik; Birgitta Konig-Ries; Arantza Illarramendi; Wolfgang Lehner; Wolfgang May; Aris Ouksel; Kay Romer; Brahmananda Sapkota; Kai-Uwe Sattler; Heinz Schweppe; Rita Steinmetz; Can Turker,Page 1. Working Group Report on Managing and Integrating Data in P2P Databases PeterA. Boncz CWI; The Netherlands Angela Bonifati ∗ National Research Council; Italy PeterJanacik University of Padeborn; Germany Birgitta K¨onig-Ries Jena University; GermanyArantza Illarramendi Basque Country University; Spain Wolfgang Lehner TU Dresden;Germany Pedro J. Marr ˙on University of Stuttgart; Germany Wolfgang May G¨ottingenUniversity; Germany Aris Ouksel University of Illinois at Chicago; USA Kay R¨omer ETH Zurich;Switzerland Brahmananda Sapkota DERI Research Center; Ireland Kai-Uwe Sattler TUIlmenau; Germany Heinz Schweppe Freie Universitaet Berlin; Germany Rita SteinmetzUniversity of Padeborn; Germany Can T¨urker ETH Zurich; Switzerland …,Proc. of the conference on Scalable Data Management in Evolving Networks,2007,1
Datenqualität-eine datenbankorientierte Sichtweise,Kai-Uwe Sattler,*,*,2005,1
Verwaltung spatio-temporaler Audiodaten für die Wellenfeldsynthese.,Thomas Heimrich; Kai-Uwe Sattler; Katrin Reichelt; Gabriel Gatzsche,Abstract: Neue Anwendungsgebiete für Datenbanksysteme resultieren aus neuenEntwicklungen in der Medientechnologie. Mit dem am Fraunhofer-Institut entwickeltenIOSONO-System können Schallquellen an einer beliebigen Position in einem Hörraum (zBKinosaal) erzeugt werden. So entstehen räumliche Klänge in einer bisher nicht gekanntenQualität. Die Verwaltung der benötigten spatio-temporalen Audiodaten erfordert spezielleDatenbanktechniken. Wir zeigen; wie die von uns entwickelten Ausgabebedingungen fürdie Datenmodellierung und die korrekte Datenausgabe genutzt werden können. Für dieDatenausgabe erzeugen wir Ausgabe-Schedules; die die Grundlage für die Optimierungder Datenorganisation bilden.,BTW,2005,1
Dynamic Visualisation for Feedback-driven Online Aggregation,Roland Jesse; Gunter Saake; Kai-Uwe Sattler; Thomas Strothotte,Abstract Aggregation is generally a time consuming process only marginally suited forinteractive result exploration. We present a framework of techniques to support an extendedaggregation; which works online and can be controlled via user feedback. Supportivevisualisation methods are presented with an overview of applicable interaction techniquesand a generic architecture that combines relevant individual components.,*,2003,1
A Component-based Integration Framework for Technical Information Systems,G Paul; M Endig; KU Sattler,Abstract Today's software market is characterized by the existence of a multitude of atomicsoftware systems for various application areas. These systems are usually" closed" solutionsfor certain functions. In general; a communication between the systems is only possiblethrough system-specific interfaces. An integration (communication) of these softwaresystems is enabled by recent developments in the area of computer science. For example;by the application of special middleware platforms an integration of software systems ispossible. The aspect of integration is essential for software systens in the area of thetechnical product development. Currently; software systems are available for the support ofthe individual steps of the product development process. Such systems are denoted astechnical information systems. However due to the inherent complexity; an integration of …,Component Based Information Systems Engineering,1998,1
Datenbank-Implementierungstechniken,Kai-Uwe Sattler; Gunter Saake,Datenbanksysteme und Anwendungsentwicklung Bachelor Informatik 2010 Modul:Datenbank-Implementierungstechniken Sommersemester Turnus: Prof. Dr. Kai-Uwe Sattler 248Fachverantwortlich: Sprache: Prüfungsleistung alternativ Fachnummer: Deutsch 2200188Prüfungsnummer: Fachabschluss: 2 2 0 VSP PSVPSVPSVPSVPSVPSV SWS nach Fachsemester1. FS 2. FS 3. FS 4. FS 5. FS 6. FS 7. FS Medienformen Vorlesung mit Präsentation undTafel; Handouts; Moodle Architektur von DBMS; Verwaltung des Hintergrundspeichers;Pufferverwaltung; Dateiorganisation und Zugriffsstrukturen: indexsequentielle Speicherung;B-Baum; Hashing; Spezielle Indexstrukturen: Dynamisches Hashing; mehrdimensionaleSpeichertechniken; geometrische Zugriffsstrukturen; Indexierung von Texten; Basisalgorithmenfür DB-Operationen: unäre Operatoren; binäre Operatoren; Verbund-implementierungen; …,Bachelor,*,1
Knowledge Discovery in Databases,Kai-Uwe Sattler,Knowledge Discovery in Databases Master Medientechnologie 2017 Modul: Knowledge Discoveryin Databases Wintersemester Turnus: Prof. Dr. Kai-Uwe Sattler 8232 Fachverantwortlich:Sprache: Prüfungsleistung mündlich 30 min Fachnummer: Deutsch 2200212Prüfungsnummer: Fachabschluss: 2 1 0 VSP SWS nach Fach- semester 1. FS 2. FS 3. FS 4.FS 5. FS 6. FS 7. FS Medienformen Vorlesung mit Präsentation und Tafel; Handouts; MoodleEinführung; Grundlagen: Statistik; Daten; Datenaufbereitung; KlassischeData-Mining-Techniken: Clustering; Frequent Itemset Mining; Klassifikation; Online Mining inDatenströmen: Datenstromverarbeitung; Datenzusammenfassungen; Frequent PatternMining; Clustering in Datenströmen; Klassifikation; Graph Mining: Mustersuche in Graphen; Erkennenvon Communities; Erkennung häufiger Subgraphen; Spatio-Temporal Mining: Sequential …,Modulhandbuch,*,1
GPU-GIST–a case of generalized database indexing on modern hardware,Felix Beier; Kai-Uwe Sattler,Abstract A lot of different indexes have been developed for accelerating search operationson large data sets. Search trees; representing the most prominent class; are ubiquitous indatabase management systems but are also widely used in non-DBMS applications. Anapproach for lowering the implementation complexity of these structures are indexframeworks like generalized search trees (GiST). Common data management operationsare implemented within the framework which can be specialized by data organization andevaluation strategies in order to model the actual index type. These frameworks areparticularly useful in scientific and engineering applications where characteristics of theunderlying data set are not known a priori and a lot of prototyping is required in order to findsuitable index structures for the workload.,it-Information Technology,2017,*
A framework for co-location patterns mining in big spatial data,A Garaeva; F Makhmutova; I Anikin; Kai-Uwe Sattler,Modern big data platforms such as Apache Hadoop and Apache Spark are able to processand analyse huge data sets; but still lack comprehensive support for spatial data analysis.Nevertheless; spatial data mining requires an efficient distributed processing of big spatialdata. Spatial data mining is a subclass of data mining; which mainly focuses on obtainingexplicit knowledge; spatial relations and interesting patterns from spatial data. Co-locationpattern mining is one of the spatial data mining challenges. Spatial co-location pattern couldbe defined as a set of spatial objects or relationships which are frequently observed togetherin a spatial proximity. This work is mainly focused on development of a framework for co-location patterns mining in big spatio-temporal data. We also make evaluation of appliedalgorithms from the point of their efficiency and scalability.,Soft Computing and Measurements (SCM); 2017 XX IEEE International Conference on,2017,*
A Cost Model for Data Stream Processing on Modern Hardware,Constantin Pohl; Philipp Götze; Kai-Uwe Sattler,ABSTRACT For stream processing application domains; using queries to process or analyzedata incoming from potentially endless streams; low latency and high throughput are keyrequirements. It is not easy to achieve this as many factors influence the actual runtime ofquery execution plans and one can not measure all of them individually. Therefore; queryoptimizers try to overcome this hurdle by using cost models for decision making. Modernhardware architectures and devices; like manycore CPUs or the NVRAM storage technologydemonstrate new properties for query execution; which have not received much attentionwithin the model. Thus; traditional optimizers are not capable of dealing with these newfactors leading to results possibly far away from optimum. Our work addresses this problemproviding a new cost model based on modern hardware characteristics. We analyze …,Proceedings of the VLDB Endowment,2017,*
Das Fachgebiet Datenbanken & Informationssysteme an der TU Ilmenau,Kai-Uwe Sattler,Einer der wesentlichen Beiträge von Datenbanksystemen ist zweifellos die Bereitstellung vongeeigneten Abstraktionen für die Repräsentation von Daten und den effizienten Zugriffdarauf. Anfragesprachen sowie Techniken der Anfrageverarbeitung spielen dabei eine wichtigeRolle. An dieser Sichtweise orientieren sich die Forschungsarbeiten des Fachgebiets; indemAnfrageverarbeitung in verschiedenen Aspekten ein zentrales Thema bildet. Ziel ist dabei; einerseitsSkalierbarkeit auch für große Datenbestände zu gewährleisten und andererseits dieVerarbeitungs- und Analysemöglichkeiten von Datenmanagementsystemen zu verbessern(Abb. 1) … Das Problem der Skalierbarkeit wird u. a. durch Verteilungs- und Parallelisierungstechnikensowie die Nutzung moderner Hardwaretechnologien adressiert. Die Arbeiten hierzu gehen zurückauf Verfahren zur verteilten Anfrageverarbeitung in P2P-Systemen basierend auf …,Datenbank-Spektrum,2016,*
Rewriting and Code Generation for Dataflow Programs.,Philipp Götze; Wieland Hoffmann; Kai-Uwe Sattler,ABSTRACT Nowadays; several data processing engines to analyze and query big dataexist. In most of the cases; if users want to perform queries using these engines; thecomplete program has to be implemented in a supported programming language by theusers themselves. This requires them to understanding both the programming language aswell as the API of the platform and also learning how to control or even enable parallelismand concurrency. Especially with this tight integration into programming languages; theinternal rewriting of queries to optimize the flow and order of the data and operators isanother big challenge since the query optimization techniques are difficult to apply. In thispaper; we want to address these problems by utilizing the dataflow model and a codegenerator and compiler for various platforms based on it; namely Piglet. The focus of this …,GvD,2016,*
Dataflow programming for big engineering data,Felix Beier; Kai-Uwe Sattler; Christoph Dinh; Daniel Baumgarten,Nowadays; advanced sensing technologies are used in many scientific and engineeringdisciplines; eg; in medical or industrial applications; enabling the usage of data-driventechniques to derive models. Measures are collected; filtered; aggregated; and processed ina complex analytic pipeline; joining them with static models to perform high-level tasks likemachine learning. Final results are usually visualized for gaining insights directly from thedata which in turn can be used to adapt the processes and their analyses iteratively to refineknowledge further. This task is supported by tools like R or MATLAB; allowing to quicklydevelop analytic pipelines. However; they offer limited capabilities of processing very largedata sets that require data management and processing in distributed environments–tasksthat have vastly been analyzed in the context of database and data stream management …,Datenbanksysteme für Business; Technologie und Web (BTW 2015)-Workshopband,2015,*
Many-Core-Architekturen zur Datenbankbeschleunigung,Kai-Uwe Sattler; Jens Teubner; Felix Beier; Sebastian Breß,Physikalische und technologische Grenzen bei der Erhöhung der Taktfrequenz von Pro- zessorenhaben in den letzten Jahren die Entwicklung von Multi- und Many-Core- Architekturenforciert. Die Ausnutzung dieser Architekturen erfordert jedoch eine weitge- hende Parallelisierungvon Berechnungen. Für den Datenbankbereich bedeutet dies einer- seits ein Überdenken etablierterDatenstrukturen und Verfahren; eröffnet aber gleichzeitig neue Möglichkeiten der Beschleunigungund Skalierung der Datenbankverarbeitung. Ziel des Tutoriums ist es daher; einen Überblicküber den Stand der Forschung und die Ein- satzmöglichkeiten von Many-Core-Architekturenin Datenbanksystemen zu geben. Neben Standard-Prozessoren stehen dabei insbesondereGPGPU-Architekturen im Mittelpunkt; die schon heute die Nutzung von Tausenden Coresermöglichen. Ausgehend von einer Vorstellung aktueller Many-Core- und GPU …,Datenbanksysteme für Business; Technologie und Web (BTW 2015)-Workshopband,2015,*
Datenbanksysteme für Business; Technologie und Web (BTW 2015),Thomas Seidl; Norbert Ritter; Harald Schöning; Kai-Uwe Sattler; Theo Härder; Steffen Friedrich; Wolfram Wingerath,Die 16. Fachtagung „Datenbanksysteme für Business; Technologie und Web “(BTW) desFachbereichs „Datenbanken und Informationssysteme “(DBIS) der Gesellschaft fürInformatik (GI) findet vom 4. bis 6. März 2015 an der Universität Hamburg statt. Auf der BTWtrifft sich im zweijährigen Rhythmus die deutschsprachige Datenbankgemeinde; um neueFragestellungen zu erörtern und aktuelle Forschungsergebnisse zu präsentieren und zudiskutieren. Zu ihrem 30-jährigen Jubiläum ist die BTW zu Gast in Hamburg; wo schon 32Jahre vorher im Jahr 1983 ein GI-Fachgespräch zum Thema „Sprachen für Datenbanken“durchgeführt wurde; das sich als unmittelbarer Vorläufer der BTW-Konferenzreiheverstehen lässt.,*,2015,*
Verteilte Transaktionsausführungen,Erhard Rahm; Gunter Saake; Kai-Uwe Sattler,Zusammenfassung In verteilten Datenbanken ergibt sich eine Reihe von neuenFragestellungen bei der Verarbeitung von Transaktionen nach dem ACID-Prinzip. EineTransaktion; die auf mehreren Konten unterschiedliche Änderungen initiiert; muss durcheine strukturierte Transaktion mit lokalen Subtransaktionen realisiert werden. Der ersteAbschnitt dieses Kapitels diskutiert die Struktur und Ausführung derartiger verteilterTransaktionen. In verteilten Systemen existiert keine echte Gleichzeitigkeit-das atomareCommit muss daher im Konsens mehrerer Subtransaktionen gefunden werden. Hierzuwerden Commit-Protokolle wie das Zwei-Phasen-Commit oder auf dem Paxos-Konsensbasierende Protokolle vorgestellt. Das Kapitel schliesst mit der Diskussion speziellerAnforderungen an das Recovery und erweiterter Transaktionsmodelle für verteilte …,*,2015,*
Parallele Anfrageverarbeitung,Erhard Rahm; Gunter Saake; Kai-Uwe Sattler,Zusammenfassung In Kap. 3 haben wir bereits die verschiedenen Arten derParallelverarbeitung von Datenbankoperationen vorgestellt und dabei die KriterienParallelität innerhalb bzw. zwischen Verarbeitungseinheiten; Daten-vs. Pipelineparallelitätsowie Verarbeitungs-vs. E/A-Parallelität diskutiert. Für die Parallelisierung von Anfragen hatdarüber hinaus die Systemarchitektur in Form der bereits eingeführten Shared-*-Architekturen eine große Bedeutung: Parallele DBMS für Multicore-oderMultiprozessorsysteme erfordern als Shared-Memory-Variante andere Verfahren als etwaMultiserverlösungen; die als Shared-Disk-oder Shared-Nothing-Variante realisiert seinkönnen. In diesem Kapitel werden wir die sich daraus ergebenden parallelenRealisierungsmöglichkeiten für Anfrageoperatoren wie Aggregation; Sortierung und …,*,2015,*
Architekturen für verteiltes und paralleles Datenmanagement,Erhard Rahm; Gunter Saake; Kai-Uwe Sattler,Zusammenfassung Zur verteilten und parallelen Datenverwaltung besteht ein breitesSpektrum an Architekturen; um den unterschiedlichen Anforderungen wie Skalierbarkeit;Verfügbarkeit; Knotenautonomie ua gerecht zu werden. Die wenig einschränkendeRandbedingung ist dabei nur; dass die Datenverwaltung kooperativ auf mehrerenProzessoren und Rechnerknoten durchgeführt wird; was bereits bei einem Server mitmehreren Prozessoren bzw. Cores der Fall ist. Wir wollen in diesem Kapitel diewesentlichen Architekturklassen mit ihren Eigenschaften und Varianten unterscheiden;deren Realisierungskonzepte dann in den nachfolgenden Kapiteln vertieft werden. Bevorwir auf die einzelnen Architekturen eingehen; diskutieren wir zunächst welche Arten derParallelverarbeitung zu unterscheiden und nach Möglichkeit zu unterstützen sind …,*,2015,*
Grundlagen der Datenverteilung,Erhard Rahm; Gunter Saake; Kai-Uwe Sattler,Zusammenfassung Der Einsatz eines Verteilten Datenbanksystems bzw. von Shared-Nothing-Systemen generell verlangt die Festlegung einer physischen Aufteilung desDatenbestandes. Die Bestimmung der Datenverteilung ist dabei für die Leistungsfähigkeitdes Systems von fundamentaler Bedeutung; da sie zu einem großen Teil denKommunikationsaufwand zur DB-Verarbeitung bestimmt. Zur Festlegung einerDatenverteilung gilt es zu entscheiden; wie die Objekte auf die einzelnen Rechner verteiltwerden. Diese Aufgabe läßt sich in zwei Teilprobleme untergliedern: Fragmentierung undAllokation. Im Rahmen der Fragmentierung werden dabei zunächst die Einheiten derDatenverteilung (Fragmente) festgelegt. In relationalen Datenbanken kommen hierzu vorallem horizontale und vertikale Fragmentierungen in Betracht; die eine Relation zeilen …,*,2015,*
Schemaarchitektur und Katalogverwaltung,Erhard Rahm; Gunter Saake; Kai-Uwe Sattler,Zusammenfassung Das Schema einer verteilten Datenbank beschreibt; welche Daten wiestrukturiert an welchem Ort gespeichert sind. In diesem Kapitel werden Varianten diskutiert;wie die Schemainformationen (die Metadaten) verteilt organisiert und verwaltet werdenkönnen. Im ortsverteilten Fall ist dabei eine möglichst hohe Knotenautonomie der beteiligtenStandorte zu erhalten. Ein spezieller Punkt betrifft die Vergabe und Verwaltung von globaleindeutigen Namen für Datenobjekte.,*,2015,*
Transaktionsverarbeitung für Shared Disk,Erhard Rahm; Gunter Saake; Kai-Uwe Sattler,Zusammenfassung Shared Disk bezeichnet einen allgemeinen Architekturtyp vonParallelen DBS; bei denen alle Rechner und ihre DBMS-Instanzen gemeinsamen Zugriff aufdie Externspeicher und die dort gespeicherte Datenbank besitzen. Die Rechner sind dabeilokal angeordnet und in der Regel lose gekoppelt; möglich ist jedoch auch eine naheKopplung. In diesem Kapitel diskutieren wir zunächst kurz Merkmale solcher Shared-Disk-DBS und zu lösende technische Probleme. Danach gehen wir auf einzelne Lösungsansätzezur Transaktionsverarbeitung im Detail ein; insbesondere zur Synchronisation;Kohärenzkontrolle (Erkennung bzw. Vermeidung von invalidierten Daten; Austausch vonÄnderungen) sowie für Logging und Recovery. Zudem stellen wir Einsatzmöglichkeiteneiner nahen Kopplung vor; wie sie ua für IBM Parallel Sysplex Verwendung findet.,*,2015,*
Grundlagen zu Datenbanken und verteilten Systemen,Erhard Rahm; Gunter Saake; Kai-Uwe Sattler,Zusammenfassung Dieses Kapitel behandelt kurz Grundlagen zu Datenbanksystemen undRechnernetzen bzw. verteilten Systemen; die für das weitere Verständnis des Buchsbenötigt werden. Das im größten Teil dieses Buchs unterstellte Datenmodell ist dasrelationale Datenmodell; da die relationale Datenbanktechnologie weiterhin die in derPraxis dominierende Form des Datenmanagements darstellt. Jedoch sind viele Prinzipiender verteilten und parallelen Datenbankverarbeitung auch auf nicht-relationaleSystemansätze wie NoSQL-Systeme übertragbar. Wir diskutieren zunächst Grundlagen desrelationales Datenmodells und seiner Operationen. Es folgt die Beschreibung des internenAufbaus von Datenbanksystemen (DBS) sowie der zur Transaktionsverwaltung benötigtenFunktionen. Nach einer Diskussion wesentlicher DBS-Einsatzformen (OLTP; OLAP) …,*,2015,*
Datenverteilung in Parallelen DBS,Erhard Rahm; Gunter Saake; Kai-Uwe Sattler,Zusammenfassung Voraussetzung für die parallele Verarbeitung von Anfragen und dieNutzung von Datenparallelität in Parallelen Datenbanksystemen ist eine geeigneteDatenverteilung; sodass mehrere Prozesse auf disjunkten Datenbereichen parallel arbeitenkönnen. Während in Shared-Everything-und in Shared-Disk-Systemen lediglich eineVerteilung der Daten über mehrere Platten bzw. Externspeicher zu finden ist; erfordertShared Nothing zugleich eine Verteilung der Daten unter den Verarbeitungsrechnern. DieDatenverteilung hat in dieser Architektur daher auch direkten Einfluss auf denKommunikations-Overhead und ist daher von besonderer Bedeutung für dieLeistungsfähigkeit. Wir konzentrieren uns daher weitgehend auf die Bestimmung derDatenverteilung für Shared Nothing; die ähnlich wie für Verteilte DBS die Schritte der …,*,2015,*
Synchronisationsverfahren,Erhard Rahm; Gunter Saake; Kai-Uwe Sattler,Zusammenfassung Wir führen zunächst einige Grundlagen zur Synchronisation vonTransaktionen ein; so die zu vermeidenden Mehrbenutzeranomalien sowie dasKorrektheitskriterium der Serialisierbarkeit. Es folgt die Behandlung der wichtigstenSynchronisationstechniken (Sperrverfahren; Zeitstempelansätze und optimistischeVerfahren); wobei meist zunächst kurz die Realisierung in zentralisiertenDatenbanksystemen besprochen wird bevor die Alternativen zur Realisierung in VerteiltenDBS vorgestellt werden. Danach gehen wir auf die Realisierung einer Mehrversionen-Synchronisation ein; mit der das Ausmaß an Synchronisationskonflikten zwischenTransaktionen stark reduziert werden kann und die in derzeitigenDatenmanagementsystemen zunehmend an Bedeutung gewinnt. Abschließend werden …,*,2015,*
Parallele Analyse großer Datenmengen mit MapReduce,Erhard Rahm; Gunter Saake; Kai-Uwe Sattler,Zusammenfassung MapReduce ist ein von Google entwickeltes Programmiermodell für diedatenparallele Verarbeitung riesiger Datenmengen in Clustern. Aufgrund seiner Einfachheit;hohen Flexibilität und der Möglichkeit; auf vergleichsweise einfache Weise hochparalleleDatenverarbeitungs-und Analyseprogramme zu schreiben; hat das MapReduce-Modell inkurzer Zeit eine weite Verbreitung gefunden. Nachdem wir in Kap. 3 bereits am Beispiel vonHadoop auf Architekturaspekte von MapReduce-Systemen eingegangen sind; wollen wir indiesem Kapitel die Techniken zur parallelen Datenverarbeitung mit dem MapReduce-Paradigma vorstellen. Neben dem Grundprinzip und dessen Umsetzung in Hadooperläutern wir insbesondere die Realisierung von klassischen Datenbankoperationen mitMapReduce. Weiterhin stellen wir auf MapReduce aufbauende Ansätze wie die …,*,2015,*
Replikation,Erhard Rahm; Gunter Saake; Kai-Uwe Sattler,Zusammenfassung Replikation bedeutet im Bereich der Datenbanken die kontrollierte;mehrfache Speicherung von Teilen des Datenbestandes. Während im logischen Entwurfmehrfache Speicherung unter dem Gesichtspunkt der Redundanz und der mit ihrverbundenen Probleme vorwiegend negativ gesehen wird; kann eine kontrollierte; interneRedundanz gerade in verteilten Szenarien sowohl die Performanz als auch dieZuverlässigkeit von Systemen erhöhen. Die Unterstützung der Replikation vonDatenbeständen kann durch unterschiedliche Verfahren gewährleistet werden. Wirbeginnen mit den allgemeinen Prinzipien der Replikation. Anschliessend diskutieren wirdann die Freiheitsgrade bei der Wahl der Replikationsunterstützung. Anschliessend stellenwir die drei wichtige Verfahrensklassen zur Aktualisierung von und Synchronisation auf …,*,2015,*
Verteilte Anfrageverarbeitung,Erhard Rahm; Gunter Saake; Kai-Uwe Sattler,Zusammenfassung Verteilte Anfrageverarbeitung unterscheidet sich in mehreren Aspektenvon der Anfrageverarbeitung in einfachen DBMS. Hierzu betrachten wir ein erweitertesPhasenmodell für die verteilte Verarbeitung. Darauf aufbauend diskutieren wir zunächst dieProbleme der Datenlokalisierung und der Anfragezerlegung für die verschiedenenFragmentierungsstrategien. Anschließend behandeln wir Erweiterungen des Kostenmodellsfür verteilte Anfrageauswertung. Einen weiteren Schwerpunkt bilden verteilte Strategien fürdie Berechnung von Verbunden sowie die Optimierung von Mehr-Wege-Verbunden.,*,2015,*
Grundlagen der Anfrageverarbeitung,Erhard Rahm; Gunter Saake; Kai-Uwe Sattler,Zusammenfassung Für ein Verständnis der Verarbeitung von Anfragen in einemDatenbanksystem ist es notwendig; sich den gesamten Ablauf vom Eintreffen einer Anfrageüber die Planung und Optimierung der Anfrage bis hin zur Bereitstellung der Ergebnisdatenzu verdeutlichen. Ausgehend von einer Beschreibung dieser Phasen derAnfrageverarbeitung diskutieren wir in diesem Kapitel zunächst die Realisierung vonBasisoperatoren wie Scans; Sortierung und Verbundberechnung. Weiterhin erläutern wirdie Grundlagen der Optimierung von Anfragen-die Auswahl des optimalen Ausführungsplanaus der Menge äquivalenter Pläne-und gehen dazu auch auf Verfahren zur Abschätzungder Ausführungskosten sowie die dafür benötigten Kostenmodelle ein. Die in diesem Kapitelbeschriebenen Techniken zur Anfrageübersetzung und-optimierung sind Standardstoff in …,*,2015,*
Large-scale Analysis of Event Data.,Stefan Hagedorn; Kai-Uwe Sattler; Michael Gertz,ABSTRACT With the availability of numerous sources and the development of sophisticatedtext analysis and information retrieval techniques; more and more spatio-temporal data areextracted from texts such as news documents or social network data. Temporal andgeographic information obtained this way often form some kind of event; describing whenand where something happened. An important task in the context of business intelligenceand document exploration applications is the correlation of events in terms of their temporal;geographic or even semantic properties. In this paper we discuss the tasks related to eventdata analysis; ranging from the extraction of events to determining events that are similar interms of space and time by using skyline processing and clustering. We present a frameworkimplemented in Apache Spark that provides operators supporting these tasks and thus …,GvD,2015,*
P2P-Based Query Processing over Linked Data.,Marcel Karnstedt; Kai-Uwe Sattler; Manfred Hauswirth,*,*,2014,*
Index-Based Source Selection and Optimization.,Jürgen Umbrich; Marcel Karnstedt; Axel Polleres; Kai-Uwe Sattler,*,*,2014,*
Evaluation of Multicore Query Execution Techniques for Linked Open Data,Ahmed Imad Aziz; Heiko Betz; Kai-Uwe Sattler,Abstract LODcache–a project of the Database & Information Systems Group at IlmenauUniversity of Technology–aims at developing an in-memory database system for managingLinked Data in RDF format and processing SPARQL queries. One of the main goals of thisproject is to investigate techniques for exploiting modern hardware architectures such asmany-core CPUs; cache hierarchies; large main memory; and coprocessing. In this context;the specific focus of the project performed at the HPI Future SOC Lab was to evaluate andimprove newly developed indexing and parallelization techniques. In this paper; we give abrief report on the main results of this work.,HPI Future SOC Lab: Proceedings 2012,2014,*
Feedback-driven Online Aggregation,ROLAND JESSE; GUNTER SAAKE; KAIUWE SATTLER; THOMAS STROTHOTTE,Aggregation is generally a time consuming process only marginally suited for interactiveresult exploration. We present a framework of techniques to support an extendedaggregation; which works online and can be controlled via user feedback. Supportivevisualisation methods are presented with an overview of applicable interaction techniquesand a generic architecture that combines relevant individual components.,Computational Visualistics; Media Informatics; and Virtual Communities,2013,*
FOR MOBILE DBMS,Erik Buchmann; Hagen Höpfner; Kai-Uwe Sattler,Abstract The increasing usage of mobile devices like PDAs; laptops; or embedded devicesresults in a new type of application which must especially consider the strict limitations of theused mobile hardware. One aspect of the application development is the storage andretrieval of data. For non-mobile application this is often efficiently realized with databasemanagement systems; which offer standardized interfaces and can be easily integrated intothe applications. For mobile devices DBMS are also already available. But existing solutionsare not extensible; and therefore; limited to the builtin functionality. That means also; thatthey include functions which are not always necessary. The optimal DBMS for mobiledatabase systems must allow for the special requirements of its applications in order toreduce the hardware requirements. Thus; it must offer core funtionality which can be …,Databases and Information Systems II: Fifth International Baltic Conference; Baltic DB&IS’2002 Tallinn; Estonia; June 3–6; 2002 Selected Papers,2013,*
Interoperation in Complex Information Ecosystems (Dagstuhl Seminar 13252),Andreas Harth; Craig A Knoblock; Kai-Uwe Sattler; Rudi Studer,Report from Dagstuhl Seminar 13252 Interoperation in Complex Information Ecosystems Editedby Andreas Harth1; Craig A. Knoblock2; Kai-Uwe Sattler3; and Rudi Studer4 1 KIT–KarlsruheInstitute of Technology; DE; harth@ kit. edu 2 University of Southern California–Marina delRey; US; knoblock@ isi. edu 3 TU Ilmenau; DE; kus@ tu-ilmenau. de 4 KIT–Karlsruhe Instituteof Technology; DE; studer@ kit. edu Abstract This report documents the program and the outcomesof Dagstuhl Seminar 13252 “Interoperation in Complex Information Ecosystems”. Seminar16.–19. June; 2013–www. dagstuhl. de/13252 1998 ACM Subject Classification D. 3.1 FormalDefinitions and Theory; H. 2.3 Languages; H. 2.4 Systems; H. 2.8 Database Applications; I. 2.4Knowledge Representation Formalisms and Methods Keywords and phrases Informationintegration; System interoperation; Complex information ecosystems; Dataspaces …,Dagstuhl Reports,2013,*
Cloud-Specific Services for Data Management,Wolfgang Lehner; Kai-Uwe Sattler,Abstract Cloud-based data management poses several challenges which go beyondtraditional database technologies. Outsourcing the operation of database applications to aprovider who; on the one hand; takes responsibility not only for providing the infrastructurebut also for maintaining the system and; on the other hand; can pool resources and operatethem in a cost-efficient and dynamic way promise cost savings and elasticity in usage.However; most customers are willing to move their on-premise setup to a hostedenvironment only if their data are kept securely and privately as well as non-functionalproperties such as availability or performance are guaranteed.,*,2013,*
Data Cloudification,Wolfgang Lehner; Kai-Uwe Sattler,Although we already live in a world of data; we just see the tip of an iceberg. Data is everywhereand decisions based on large data sets are driving not only business related but more and morepersonal decisions. The challenges are enormous and range from technical questions on howto setup and run an efficient and cost-effective data management platform to security and privacyconcerns to prevent the loss of personal self-determination. Within this section; we present thegeneral setup of the “-as-a-Service”-paradigm and discuss certain facets of data managementsolutions to cope with the existing and upcoming challenges … Over the last years the worldcollected an astonishing amount of digital information. This particularly applies to data collectedand generated within modern web applications which leads to unprecedented challenges indata and information management. Search engines such as Google; Bing or Yahoo …,*,2013,*
Summary and Outlook,Wolfgang Lehner; Kai-Uwe Sattler,Abstract The overall goal of this book is to give an in-depth introduction into the context ofdata management services running in the cloud. Since the “as-a-Service”-philosophy isconsidered one of the extremely relevant developments in computer and informationtechnology and a huge number of different variants of services–ranging from infrastructuralservices to services providing access to complex software components–is already existing; itis time to provide a comprehensive overview and list of challenges for “Data-as-a-Service”(DaaS). The DaaS approach is not only relevant because data management is oneof the ubiquitous core tasks in many service and application stacks and the market fordatabase technologies is a very big and growing market. We also believe that this kind ofservice will change the way of how we will work with data and databases in the near …,*,2013,*
Web-Scale Analytics for BIG Data,Wolfgang Lehner; Kai-Uwe Sattler,Abstract Virtualization is the key concept to provide a scalable and flexible computingenvironment in general. In this chapter; we focus on virtualization concepts in the context ofdata management tasks. We review existing concepts and technologies spanning multiplesoftware layers.,*,2013,*
Estimating the Completeness of Range Queries over Structured P2P Databases: Fundamentals; Theory; and,Alfredo Cuzzocrea; Marcel Karnstedt; Manfred Hauswirth; Kai-Uwe Sattler; Roman Schmidt,ABSTRACT Range queries are a very powerful tool in a wide range of data managementsystems and are vital to a multitude of applications. The hierarchy of structured overlaysystems can be utilized in order to provide efficient techniques for processing them; resultingin the support of applications and techniques based on range queries in large-scaledistributed information systems. On the other hand; due to the rapid development of theWeb; applications based on the P2P paradigm gain more and more interest; having suchsystems started to evolve towards adopting standard database functionalities in terms ofcomplex query processing support. This goes far beyond simple key lookups; as provided bystandard distributed hashtables (DHTs) systems; which makes estimating the completenessof query answers a crucial chal-,Next Generation Content Delivery Infrastructures: Emerging Paradigms and Technologies: Emerging Paradigms and Technologies,2012,*
Report on the 8th International Workshop on Quality in Databases (QDB10),Andrea Maurino; Cinzia Cappiello; Panos Vassiliadis; Kai-Uwe Sattler,The eighth international workshop on Quality in Database was held in Singapore; onSeptember 13th; 2010 and co-located with the 36th Conference on Very Large DataBase(VLDB). The main objective of the workshop was to address the challenge to detect dataanomalies and assess; monitor; improve; and maintain the quality of information. Theworkshop attracted 12 submissions from Asia; Australia; Europe; and the United States; outof which the Program Committee finally accepted 9 full papers. The accepted papersfocused on important issues especially related to Data Quality assessment; Entity Matching;and Information Overloading.,ACM SIGMOD Record,2012,*
Query processing of pre-partitioned data using Sandwich Operators,PA Boncz; S Baumann; K-U Sattler,Abstract. In this paper we present the “Sandwich Operators”; an elegant approach to exploitpre-sorting or pre-grouping from clustered storage schemes in operators such asAggregation/Grouping; HashJoin; and Sort of a database management system. Thereby;each of these operator types is “sandwiched” by two new operators; namely PartitionSplitand PartitionRestart. PartitionSplit splits the input relation into its smaller independentgroups on which the sandwiched operator is executed. After a group is processedPartitionRestart is used to trigger the execution on the following group. Executing one ofthese operator types with the help of the Sandwich Operators introduces minimal overheadand does not penalty performance of the sandwiched operator as its implementationremains unchanged. On the contrary; we show that sandwiched execution of an operator …,*,2012,*
Cloud-Services und effiziente Anfrageverarbeitung für Linked Open Data.,Heiko Betz; Kai-Uwe Sattler,ABSTRACT Der Verbreitungsgrad von Linked Open Data hat in den letzten Jahren massivzugenommen. Stetig erscheinen neue Quellen; die RDF-Daten frei zur Verfügung stellen.Aktuell diskutiert die Bundesregierung über ein neues Gesetz; welches zur Offenlegung vonDaten der öffentlichen Hand verpflichtet. Durch diese Maßnahme; steigt ua die Menge anLinked Open Data sehr schnell an. Es werden neue Verfahren benötigt; die mit sehr vielenRDF-Daten gleichzeitig eine effiziente; skalierbare und mit Garantien versehene Abfragevon Daten mittels SPARQL gewährleistet. In dieser Arbeit wird ein reines In-Memory Shared-Nothing-System vorgestellt; das die genannten Anforderungen in effizienter Weise erfüllt.Hierfür werden verschiedenste Optimierungsmaßnahmen ergriffen; die das Potenzialmoderner Hardware umfassend ausnutzen.,Grundlagen von Datenbanken,2012,*
Dagstuhl Reports; Vol. 1; Issue 3 ISSN 2192-5283,Jürgen Dix; Sven Ove Hansson; Gabriele Kern-Isberner; Guillermo Simari; Sebastian Maneth; Gonzalo Navarro; Guido Brunnett; Sabine Coquillart; Robert van Liere; Gregory Welch; Artur Andrzejak; Joachim Giesen; Raghu Ramakrishnan; Ion Stoica; Andreas Harth; Craig A Knoblock; Kai-Uwe Sattler; Rudi Studer,Belief Change and Argumentation in Multi-Agent Scenarios (Dagstuhl Seminar 13231) JürgenDix; Sven Ove Hansson; Gabriele Kern-Isberner; and Guillermo Simari … Indexes and Computationover Compressed Structured Data (Dagstuhl Seminar 13232) Sebastian Maneth and GonzaloNavarro ......................................... 22 … Virtual Realities (Dagstuhl Seminar 13241) GuidoBrunnett; Sabine Coquillart; Robert van Liere; and Gregory Welch ........ 38 … Parallel Data Analysis(Dagstuhl Seminar 13251) Artur Andrzejak; Joachim Giesen; Raghu Ramakrishnan; and IonStoica ......... 67 … Interoperation in Complex Information Ecosystems (Dagstuhl Seminar13252) Andreas Harth; Craig A. Knoblock; Kai-Uwe Sattler; and Rudi Studer ............ 83 … Publishedonline and open access by Schloss Dagstuhl – Leibniz-Zentrum für Informatik GmbH; DagstuhlPublishing; Saarbrücken/Wadern; Germany. Online available at http://www.dagstuhl.de …,*,2011,*
Deklarative Verarbeitung von Datenströmen in Sensornetzwerken.,Daniel Klan,Zusammenfassung Sensoren finden sich heutzutage in vielen Teilen des täglichen Lebens.Sie dienen dabei der Erfassung und Uberführung von physikalischen oder chemischenEigenschaften in digital auswertbare Größen. Drahtlose Sensornetzwerke als Mittel zurgroßflächigen; weitestgehend autarken Uberwachung von Regionen oder Gebäuden sindTeil dieser Brücke und halten immer stärker Einzug in den industriellen Einsatz. DieEntwicklung von geeigneten Systemen ist mit einer Vielzahl von Herausforderungenverbunden. Aktuelle Lösungen werden oftmals gezielt für eine spezielle Aufgabe entworfen;welche sich nur bedingt für den Einsatz in anderen Umgebungen eignen. Die sichwiederholende Neuentwicklung entsprechender verteilter Systeme sowohl aufHardwareebene als auch auf Softwareebene; zählt zu den wesentlichen Gründen …,*,2011,*
Topiek-Dokumentenmanagementsystem trifft semantischesWeb.,Daniel Klan; Stefan Hagedorn; Steffen Hirte; Heiko Betz; Firas Kassem; Kai-Uwe Sattler; NT AG,Abstract Die Verwaltung großer Datenmengen ist heute eine der wesentlichen Aufgaben imUnternehmensumfeld. Insbesondere das Wiederfinden relevanter und interessanterInformationen gestaltet sich dabei als Herausforderung. Im Folgenden soll mit Topiek einSystem vorgestellt werden; welches zu diesem Zweck die Funktionalität herkömmlicherDokumentenmanagementsysteme um Techniken aus dem Bereich des semantischen Webserweitert.,LWA,2011,*
Datenbank-Spektrum im Springer-Verlag,Hagen Höpfner; Kai-Uwe Sattler,Liebe Leserinnen und Leser; vielleicht wundern Sie sich über das leicht verspäteteErscheinen der ersten Ausgabe des Datenbank-Spektrums im Jahr 2010 oder über dasveränderte Erscheinungsbild. Vielleicht haben Sie sich in den letzten Monaten gefragt; waseigentlich aus dem Datenbank-Spektrum geworden ist? Wir sind im Springer-Verlagangekommen! Wie in der letzten Ausgabe angekündigt; wurde die Zusammenarbeit mit demdpunkt. verlag beendet und das Datenbank-Spektrum erscheint nun bei Springer. Damitverbunden sind einige Änderungen: So wird es in Zukunft nur noch 3 Ausgaben pro Jahrgeben und auch das Layout wird verändert; wie Sie sicher am Cover bemerkt haben. DieÄhnlichkeit mit dem Informatik-Spektrum kommt nicht von ungefähr; auch diese GI-Zeitschriftwird ja vom Springer-Verlag herausgegeben. Schließlich gab es bereits Ende letzten …,*,2010,*
Von Mediatoren über Ontologien zu Linked Open Data-Zum Stand der Informationsintegration und-fusion aus Sicht der Life Sciences.,Kai-Uwe Sattler,Abstract: Die Verknüpfung von Daten aus unterschiedlichen Quellen ist in vielenAnwendungsbereichen eine zentrale Aufgabe. In den vergangenen 25 Jahren wurde dahereine Vielzahl von Ansätzen zur Lösung dieses Problems entwickelt. Während jedoch imBusiness-Bereich Data-Warehouse-Systeme als Integrationsplattform fest etabliert sind;stellen die Lebenswissenschaften besondere Anforderungen. So wurden in den letztenJahren unzählige wissenschaftliche Datensammlungen veröffentlicht und über das Internetzugänglich gemacht; die in verschiedenster Weise genutzt werden können. EineVerknüpfung und übergreifende Analyse der Daten wird jedoch durch Systemgrenzen undHeterogenitäten erschwert. Benötigt werden daher Techniken zur Informationsintegration;die nicht nur einen transparenten Zugriff auf Daten aus anderen Systemen ermöglichen …,GI Jahrestagung (1),2010,*
10042 Abstracts Collection--Semantic Challenges in Sensor Networks,Karl Aberer; Avigdor Gal; Manfred Hauswirth; Kai-Uwe Sattler; Amit P Sheth,Abstract From 24.01. to 29.01. 2010; the Dagstuhl Seminar 10042``Semantic Challenges inSensor Networks''was held in Schloss Dagstuhl~--~ Leibniz Center for Informatics. Duringthe seminar; several participants presented their current research; and ongoing work andopen problems were discussed. Abstracts of the presentations given during the seminar aswell as abstracts of seminar results and ideas are put together in this paper. The first sectiondescribes the seminar topics and goals in general. Links to extended abstracts or full papersare provided; if available.,Dagstuhl Seminar Proceedings,2010,*
10042 Executive Summary--Semantic Challenges in Sensor Networks,Karl Aberer; Avigdor Gal; Manfred Hauswirth; Kai-Uwe Sattler; Amit P Sheth,Abstract There has been significant progress in the number and capabilities of mobiledevices; wireless sensors; and sensor networks. These developments; combined with theimproved ability to bridge between the physical and cyber world in a more seamless way;have fostered the broad availability of sensor data capturing the state of the physical world.Promising and already successful examples are applications in environmental monitoring;agriculture; surveillance and intrusion detection; public security; and supply chainmanagement. Furthermore; ideas towards a Web of sensors have been proposed; which isto be understood as a (large scale) network of spatially distributed sensors. In particular;terms like" Internet of Things";" Collaborating Objects" and" Ambient Intelligence" emphasizethe trend towards a tighter connection between the cyber space and the physical world.,Dagstuhl Seminar Proceedings,2010,*
Structured Data in Peer-to-Peer Systems,Kai-Uwe Sattler,The values in the relations of a relational database are elements of one or more underlyingsets called domains. In practical applications; a domain may be infinite; eg; the set of naturalnumbers. In this case; the value of a relational calculus query when applied to such adatabase may be infinite; eg;{njn! 10}. A query Q is called finite if the value of Q whenapplied to any database is finite. Even when the database domains are finite; all that isnormally known about them is that they are some finite superset of the values that occur inthe database. In this case; the value of a relational calculus query may depend on such anunknown domain; eg;{xj 8yR (x; y)}. A query Q is called domain independent if the value of Qwhen applied to any database is the same for any two domains containing the databasevalues or; equivalently; if the value of Q when applied to a database contains only values …,*,2009,*
Distributed Query Processing,Kai-Uwe Sattler,realized using such logical structures. For example; in tree based data acquisition protocols;a collection tree is built that is rooted at the data collection center such as the sink node [8].The dissemination of the data requests from the participating nodes and collection of datafrom the sensor nodes are accomplished using this tree. A cluster based data acquisitionmechanism has been proposed in [3]. As shown in Fig. 1; nodes are organized into a fixednumber of clusters; and nodes within each cluster dynamically elect a cluster head. The dataacquisition is carried out in two phases. In the first phase; cluster heads collect data fromtheir cluster nodes. In the second phase; cluster heads send collected data to the nodes thathave subscribed to the data. The cluster heads are re-elected to balance energyconsumption among the nodes in the cluster. Zhang et al.[13] have proposed an adaptive …,*,2009,*
Adaptive burst detection in a stream engine,Daniel Klan; Marcel Karnstedt; Christian Pölitz; Kai-Uwe Sattler; Conny Franke,ABSTRACT Detecting bursts in data streams is an important and challenging task. Due tothe complexity of this task; usually burst detection cannot be formulated using standardquery operators. Therefore; we show how to integrate burst detection for stationary as wellas non-stationary data into query formulation and processing; from the language level to theoperator level. Afterwards; we present fundamentals of threshold-based burst detection. Wefocus on the applicability of time series forecasting techniques in order to dynamicallyidentify suitable thresholds for stream data containing arbitrary trends and periods. Theproposed approach is evaluated with respect to quality and performance on synthetic andreal-world sensor data using a full-fledged DSMS.,In SAC’09: Proceedings of the 2009 ACM symposium on Applied Computing (New,2009,*
Autonomie und Vorhersagbarkeit in DBMS.,Kai-Uwe Sattler,Zusammenfassung Datenbanksysteme sind seit vielen Jahren ein unverzichtbarerBestandteil von IT-Infrastrukturen in allen Bereichen. Die ursprünglich exponierte Rolle mtdedizierten Systemen und Administratoren verändert sich jedoch zunehmend in Richtungeiner Black-Box-Komponente innerhalb komplexer Software-Stacks. Die Bandbreite reichthierbei von vorkonfigurierten Paketen wie LAMP über datenbankbasierte Appliances bis hinzum Cloud Storage. Wesentliche Anforderungen in diesem Kontext sind einerseits eingeringer Aufwand im Betrieb; andererseits aber auch die Einhaltung von konkretenDienstgüten wie Antwortzeit oder Durchsatz. Einen wichtigen Beitrag können hier Technikenzum autonomen Management (Self-*-Techniken) von Datenbanksystemen leisten; dieTuningbzw. Optimierungsaufgaben automatisieren. Im Beitrag werden ausgehend von …,Grundlagen von Datenbanken,2008,*
Processing sequential patterns in relational databases,Xuequn Shang; Kai-Uwe Sattler,Abstract Integrating data mining techniques into database systems has gained popularityand its significance is well recognized. However; the performance of SQL based data miningis known to fall behind specialized implementations. Reasons for this are among others theprohibitive nature of the cost associated with extracting knowledge as well as the lack ofsuitable declarative query language support. Recent studies have found that for associationrule mining and sequential pattern mining with carefully tuned SQL formulations it ispossible to achieve performance comparable to systems that cache the data in files outsidethe DBMS. However; most of the previous pattern mining methods follow the method ofApriori; which still encounters problems when a sequential database is large and/or whensequential patterns to be mined are numerous and long. In this paper; we present a novel …,*,2007,*
06431 Working Group Report on Managing and Integrating Data in P2P Databases,Peter A Boncz; Angela Bonifati; Arantza Illarramendi; Peter Janacik; Birgitta König-Ries; Wolfgang Lehner; Pedro Jose Marrón; Wolfgang May; Aris Ouksel; Kay Römer; Brahmananda Sapkota; Kai-Uwe Sattler; Heinz Schweppe; Rita Steinmetz; Can Türker,Abstract In this report; to our best recollection; we provide a summary of the working groupĆ¢ ā ‚¬ Ė Managing and Integrating Data in P2P DatabasesĆ¢ ā ‚¬ ā „¢ of the DagstuhlSeminar nr. 6431 on Ć¢ ā ‚¬ Ė Scalable Data Management in Evolving NeworksĆ¢ ā ‚¬ ā „¢;held on October 23-27 in Dagstuhl (Germany).,Dagstuhl Seminar Proceedings,2007,*
Current Trends in Database Technology-EDBT 2006: EDBT 2006 Workshop PhD; DataX; IIDB; IIHA; ICSNW; QLQP; PIM; PaRMa; and Reactivity on the Web; Munich...,Torsten Grust,You arestudying the joint proceedingsof the scienti'c workshopsthat wereheld th just beforeand after the 10 International Conference on Extending Database Technology (EDBT 2006)in the historicMunich Kunstler ̈ haus; Germany; in late March 2006. The workshopscontributing to this volume are: th-The4 EDBT Ph. D. Workshop-DataX 2006 (DBTechnologies for Handling XML Information on the Web)-IIDB (Inconsistency andIncompleteness in Databases)-IIHA (Information Integration in Healthcare Applications)-ICSNW 2006 (Semantics of a Networked World)-QLQP 2006 (Query Languages and QueryProcessing)-PIM 2006 (Pervasive Information Management)-PaRMa 2006 (PatternRepresentation and Management)-Reactivity on the Web If we let the raw numbers speak;then; compared with EDBT 2004; the number of collocated workshops almost doubled …,*,2006,*
Processing Approximate Queries in PDMS,Kai-Uwe Sattler; Katja Hose,*,*,2006,*
Frequent itemset mining with parallel RDBMS,Xuequn Shang; Kai-Uwe Sattler,Abstract Data mining on large relational databases has gained popularity and itssignificance is well recognized. However; the performance of SQL based data mining isknown to fall behind specialized implementation. We investigate approaches based on SQLfor the problem of finding frequent patterns from a transaction table; including an algorithmthat we recently proposed; called Ppropad (Parallel PROjection PAttern Discovery). Ppropadsuccessively projects the transaction table into frequent itemsets to avoid making multiplepasses over the large original transaction table and generating a huge sets of candidates.We have built a parallel database system with DB2 and made performance evaluation on it.We prove that data mining with SQL can achieve sufficient performance by the utilization ofdatabase tuning.,Pacific-Asia Conference on Knowledge Discovery and Data Mining,2005,*
04441 Working Group--Research Issues in Mobile Querying,Martin Breunig; Christian S Jensen,Abstract This document reports on key aspects of the discussions conducted within theworking group. In particular; the document aims to offer a structured and somewhat digestedsummary of the group's discussions. The document first offers concepts that enablecharacterization of" mobile queries''as well as the types of systems that enable such queries.It explores the notion of context in mobile queries. The document ends with a fewobservations; mainly regarding challenges.,Dagstuhl Seminar Proceedings,2005,*
04441 Working Group-Some Open Aspects of Mobile Ad-hoc NETwork; Peer-to-Peer; and Self-organizing Systems,Joos-Hendrik Böse; Stefan Böttcher; Le Gruenwald; Pedro Jóse Marrón; Philipp Obreiter; Evaggelia Pitoura; Peter Reiher; Kai-Uwe Sattler; Frank Seliger,1 Freie Universität Berlin; Computer Science; Takustraße 9; 14195 Berlin; Germanyboese@fu-berlin.de 2 University of Paderborn; Computer Science; Fürstenallee 11; 33102Paderborn; Germany stb@uni-paderborn.de 3 The University of Oklahoma; School of ComputerScience; 200 Felgar Street; Room 116 EL; Norman; OK 73019; USA ggruenwald@ou.edu 4Universität Stuttgart; Computer Science; IPVS; 70569 Stuttgart; Germanypedro.marron@informatik.uni-stuttgart.de 5 Universität Karlsruhe (TH); Computer Science;IPD; 76128 Karlsruhe; Germany obreiter@ipd.uni-karlsruhe.de 6 University of Ioannina; ComputerScience Department; GR 45110; Ioannina; Greece pitoura@cs.uoi.gr 7 UCLA; 405 HilgardAve; Los Angeles; CA 90095; USA reiher@cs.ucla.edu 8 Department of Computer Science &Automation; TU Ilmenau; Postfach 100 565; D-98684 Ilmenau; Germany …,Dagstuhl Seminar Proceedings,2005,*
Research Issues in Mobile Querying,M Breunig; Christian Søndergaard Jensen; M Klein; A Zeitz; G Koloniari; J Grünbauer; PJ Marrón; C Panieyiotoa; S Boll; Simonas Saltenis; K-U Sattler; M Hauswirth; W Lehner; O Wolfson,Abstract: This document reports on key aspects of the discussions conducted within theworking group. In particular; the document aims to offer a structured and somewhat digestedsummary of the group's discussions. The document first offers concepts that enablecharacterization of" mobile queries" as well as the types of systems that enable suchqueries. It explores the notion of context in mobile queries. The document ends with a fewobservations; mainly regarding challenges.,Dagstuhl Seminar Proceedings,2004,*
Ad-hoc-Integration in schemabasierten P2P-Systemen.,Marcel Karnstedt; Kai-Uwe Sattler; Eike Schallehn; Martin Endig,Abstract: Die weite Verfügbarkeit von Daten zu verschiedensten Aspekten in elektronischverarbeitbarer Form eröffnet für Anwendungen wie das Katastrophenmanagement neueMöglichkeiten der entscheidungsunterstützenden Informationsbereitstellung. Notwendig istdafür jedoch eine dynamische; aufgabengetriebene Verbindung der verschiedenenDatenbestände; die durch klassische Datenintegrationstechniken nur bedingt erzielt werdenkann. In diesem Beitrag diskutieren wir daher Techniken; die eine derartige Ad-hoc-Integration auf der Basis von schemabasierten Peer-to-Peer (P2P)-Systemen unterstützen.Im Mittelpunkt stehen dabei die Probleme der Korrespondenzfindung und-definition sowieeine effiziente Anfrageverarbeitung.,GI Jahrestagung (1),2004,*
Database Technologies for Handling-XML-Information on the Web (DataX)-Pervasive Information Management (PIM)-An Indexing Scheme for Update Notification in...,Hagen Hopfner; Stephan Schosser; Kai-Uwe Sattler,*,Lecture Notes in Computer Science,2004,*
Cooperative Information Systems (CoopIS) 2004 International Conference-Schema Integration/Agents-Supporting Similarity Operations Based on Approximate Strin...,Eike Schallehn; Ingolf Geist; Kai-Uwe Sattler,*,Lecture Notes in Computer Science,2004,*
1st International Symposium on Applications of Constraint Databases in conjunction with SIGMOD/PODS 2004 June 12-13; Paris; France,Bart Kuijpers; Peter Revesz; Saugata Basu; Alex Brodsky; Jan Chomicki; Berthe Choueiry; Giorgio Delzanno; Floris Geerts; Marc Giusti; Dina Goldin; Stephane Grumbach; Joxan Jaffar; Manolis Koubarakis; Stephan Kreutzer; Gabriel Kuper; Zoe Lacroix; Lixin Li; Jan Paredaens; Philippe Rigaux; Kai-Uwe Sattler; Jianwen Su; David Toman; Jan Van den Bussche; Dirk Van Gucht; Nicolai Vorobjov; Mark Wallace; Joos Heintz; Leonid Libkin; Andreas Podelski,Scope: The last few years saw a growing interest of constraint database theory; queryevaluation; and applications in a variety of conferences; journals; and books. Thissymposium wants to bring together people from several diverse areas that can contribute tothe practice and the application of constraint databases. It is a continuation and extension ofprevious workshops held in Friedrichshafen; Germany (1995); Cambridge; USA (1996);Delphi; Greece (1997); and Seattle; USA (1998) as well as of the work in the comprehensivevolume" Constraint Databases" edited by G. Kuper; L. Libkin and J. Paredaens (2000) andthe textbook" Introduction to Constraint Databases" by P. Revesz (2002).,SIGMOD Record,2003,*
Anfragetechniken für heterogene Datenbanksysteme,Kai-Uwe Sattler,*,*,2003,*
Föderierungsdienst für heterogene Dokumentenquellen: Abschlußbericht,Eike Schallehn; M Endig; KU Sattler; G Saake; Magdeburg Univ.(Germany). Fakultaet fuer Informatik;,*,*,2003,*
Efficiency and Effectiveness of XML Tools and Techniques (EEXTT)-Data Integration over the Web (DIWeb)-Integrating Scientific Data through External; Concept-Ba...,Michael Gertz; Kai-Uwe Sattler,*,Lecture Notes in Computer Science,2003,*
DBFusion 2002 Information Integration and Mining in Databases and on the Web: Proceedings of the 2nd International Workshop on Databases; Documents; and Inf...,Alexander Mädche; Kai-Uwe Sattler; Gerd Stumme,*,*,2002,*
Information Integration and Mining in Databases and on the Web: Proceedings of the 2nd International Workshop on Databases; Documents; and Information Fusion...,Alexander Mädche; Kai-Uwe Sattler; Gerd Stumme,*,CEUR workshop proceedings,2002,*
Algorithmen und Datenstrukturen Vorlesungsskript WS/SS 99-00,Gunter Saake; Kai-Uwe Sattler,Das vorliegende Skript ist zum großen Teil erst während der aktuellenVorlesungsvorbereitung entstanden. Dies war nur dadurch möglich; daß die Autoren aufeine Reihe von Vorarbeiten zur uckgreifen konnten. Teile des Skriptes; insbesondereBeispiele und Definitionen; sind aus dem Material anderer Skripte entnommen und geeignetabgewandelt worden. Besonders nennen möchten wir hierbei,*,2000,*
Anwendungsentwicklung mit DBMS,Kai-Uwe Sattler,Datenbanksysteme 2 Master Wirtschaftsinformatik 2013 Modul: Anwendungsentwicklung mitDBMS Sommersemester Turnus: Prof. Dr. Kai-Uwe Sattler 251 Fachverantwortlich: Sprache:über Komplexprüfung Fachnummer: Deutsch 2200435 Prüfungsnummer: Fachabschluss: 1 30 VSP SWS nach Fach- semester 1. FS 2. FS 3. FS 4. FS 5. FS 6. FS 7. FS Medienformen Vorlesungmit Präsentation und Tafel; Handouts; Moodle; praktische Projektarbeit Datenbankentwurf imER-Modell; Transformation in relationale Datenbankschema; Softwareentwurfsprozess fürDatenbankanwendungen; Techniken für den Datenbankzugriff; Einführung in MobileComputing; Strategien zur Umsetzung mobiler Lösungen; Abstraktionen der Software-Infrastrukturenheutiger mobiler Plattformen Inhalt Vorkenntnisse Vorlesung DatenbanksystemeLernergebnisse/Kompetenzen Studierende; die diese Veranstaltung besucht haben …,Modulhandbuch,2000,*
Workshop Internet-Datenbanken,Gunter Saake; Kai-Uwe Sattler,Zusammenfassung Die rasante Entwicklung des Web hat gerade im Datenbankbereicheinerseits eine Vielzahl neuer Anwendungsfelder eröffnet; andererseits aber auch neueHerausforderungen geschaffen. So ist über das Web der Zugriff auf Datenbestände möglich;ohne daß sich der Nutzer der Komplexität von Anfragesprachen und-schnittstellenausgesetzt sieht. Datenbanken und Datenbanktechnologien bilden damit das Rückgrataktueller Internet-Anwendungen; wie Informationsdienste und Portale sowie E-Commerce-Anwendungen.,*,2000,*
Informationsfusion-Herausforderungen an die Datenbank-und Visualisierungstechnologie: Kurzbeitrag,Stefan Conrad; Gunter Saake; Kai-Uwe Sattler; Daniel A Keim,In vielen Anwendungsbereichen besteht die Aufgabe; Daten oder Informationen ausverschiedenen; zum Teil heterogenen Quellen zu kombinieren; zu verdichten und darausInformationen einer neuen Qualität abzuleiten. Wesentliche Kernfunktionen dieses alsInformationsfusion bezeichneten Prozesses sind dabei durch Methoden derDatenintegration und der Datenanalyse/Data Mining bereitzustellen. Die gewachsenenStrukturen der heute genutzten Informationsquellen und die damit im Zusammenhangstehenden Probleme wie Heterogenität; Inkonsistenz oder Ungenauigkeit der Daten sind mitden aktuell verfügbaren Techniken nur bedingt beherrschbar. Ausgehend vom aktuellenStand der Forschung diskutiert der vorliegende Beitrag Anforderungen anDatenbanktechnologien aus Sicht der Informationsfusion; zeigt mögliche …,Simulation und Visualisierung,2000,*
Citation Linking in Federated Digital Libraries,Hike Schallehn Martin Endig; Kai-Uwe Sattler,Abstract Today; bibliographical information is kept in a variety of data sources world wide;some of them also offering information about citations made in publications. But as most ofthose sources cover only certain areas of publications it is not possible to follow citation linkswhen information about me referenced publication is not stored locally. This is known as thecitation linking problem. In this paper we present an approach to integrating bibliographicalinformation including citation information based on a loosely coupled federation using theFRAQL language and its conflict resolution mechanisms. Furthermore; we describe anadapter allowing a seamless integration of various sources in an heterogeneous and highlydistributed environment.,Engineering Federated Information Systems: Proceedings of the 3rd Workshop; EFIS 2000; June 19-20; 2000; Dublin (Ireland),2000,*
Knowledge discovery zur Unterstuetzung des dezentralisierten Fehlermanagements in Mobilfunksystemen,Kai-Uwe Sattler; Gunter Saake,*,*,1999,*
We would like to thank everyone who submitted a paper to the STD3S workshop for their interest; the members of the program committee for their high-quality and o...,Klemens Böhm; Ruth Breu; Sonja Buchegger; David Chadwick; Schahram Dustdar; Mark Jelasity; Wim Jonker; Ling Liu; Alberto Montresor; Evaggelia Pitoura; Thomas Risse; Germany Pierangela Samarati; Kai-Uwe Sattler; Anna Squicciarini,Decentralized/distributed data structures (D3S) have recently received a lot of attention withthe successful introduction of peer-to-peer systems; Web services; Grids; and ubiquitouscomputing systems as specific examples of D3S. The “persuasive” arguments in favor ofthese systems are that they try to avoid centralization as a performance bottleneck; strive fordecreasing infrastructure costs and increasing performance by using available distributedresources; and are relatively easy to deploy and maintain due to inherent self-organizationproperties. Distribution; decentralization and selforganization are the basic underlyingconcepts facilitating these advantages. However; they also introduce new security problemsand make trust a central issue as the behavior and functioning of the system heavilydepends on the cooperation and resource contributions of the participants. In hostile …,*,*,*
Nötiges Vorwissen,Kai-Uwe Sattler,1. Aufgaben und Prinzipien von Datenbanksystemen 2. Architektur von Datenbanksystemen3. Basisalgorithmen für Datenbankoperationen 4. Optimierung von Anfragen 5. Transaktionsmodelleund -verwaltung 6. Wiederherstellung und Datensicherheit 7. Neuere Entwicklungen und Ausblick… Datenbanken I: s Grundprinzipien Datenbanksysteme s Tabellen; Attribute; Schlüssel s RelationaleAlgebra und SQL Wird am Anfang der Vorlesung kurz wiederholt … 1. Integration 2. Operationen3. Katalog 4. Benutzersichten 5. Konsistenzüberwachung 6. Datenschutz 7. Transaktionen8. Synchronisation 9. Datensicherung … Wichtigste Modelle in kommerziellen Systemen s dashierarchische Datenmodell: Daten in Baumform als hierarchisch strukturierte Datensätze; s dasNetzwerkmodell: Unterstützung von Netzwerken von verzeigerten Datensätzen; s das relationaleDatenbankmodell: Daten in Tabellenform; s das objektorientierte Datenmodell …,*,*,*
MDM 2016 Program Committee,Walid G Aref; Nikolaos Armenatzoglou; Christian Becker; Claudio Bettini; Dipanjan Chakraborty; Ming-Syan Chen; Raymond Chi-Wing Wong; Chi-Yin Chow; Christophe Claramunt; Maria Luisa Damiani; Alex Delis; Ugur Demiryurek; Yunjun Gao; Gabriel Ghinita; Ralf Hartmut Güting; Takahiro Hara; Yoshiharu Ishikawa; Vana Kalogeraki; Peer Kroger; Wei-Shinn Ku; Vimal Kumar; Wang-Chien Lee; Wenjia Li; Hua Lu; Sergio Mascetti; Sanjay Madria; Archan Misra; Mohamed Mokbel; Anirban Mondal; Kyriakos Mouratidis; Mirco Nanni; Praveen Rao; Yugyung Lee; Alfredo Cuzzocrea; Ho Shen-Shyang; Bernhard Mitschang; Dimitris Papadias; Torben Bach Pedersen; Matthias Renz; Daniele Riboni; Nirmalya Roy; Dimitris Sacharidis; Kai-Uwe Sattler,Debopam Acharya; SNU; India Walid G. Aref; Purdue University; USA NikolaosArmenatzoglou; Hong Kong University of Science and Technology; Hong Kong ChristianBecker; University of Mannheim; Germany Claudio Bettini; University of Milan; Italy DipanjanChakraborty; IBM Research; India Ming-Syan Chen; National Taiwan University; Taiwan RaymondChi-Wing Wong; Hong Kong University of Science and Technology; Hong Kong Chi-YinChow; City University of Hong Kong; Hong Kong Christophe Claramunt; Naval Academy; FranceMaria Luisa Damiani; University of Milan; Italy Alex Delis; University of Athens; Greece UgurDemiryurek; University of Southern California; USA Yunjun Gao; Zhejiang University; China GabrielGhinita; University of Massachusetts–Boston; USA Le Gruenwald; University of Oklahoma; USARalf Hartmut Güting; Fernuniversität Hagen; Germany Takahiro Hara; Osaka University …,*,*,*
Data Engineering,Surajit Chaudhuri Ailamaki; Sam Lightstone; Guy Lohman; Pat Martin; Ken Salem; Gerhard Weikum,Information management systems are growing rapidly in scale and complexity; while skilleddatabase administrators are becoming rarer and more expensive. Increasingly; the total costof ownership of information management systems is dominated by the cost of people; ratherthan hardware or software costs. This economic dynamic dictates that information systems ofthe future be more automated and simpler to use; with most administration tasks transparentto the user. Autonomic; or self-managing; systems provide a promising approach toachieving the goal of systems that are increasingly automated and easier to use. But howcan that be achieved? The aim of this workshop was to present and discuss ideas towardachieving self-managing information systems in an intimate; informal; and interactiveenvironment.,*,*,*
Programm-Komittee Stefan Brass Universität Halle Erik Buchmann Universität Karlsruhe Stefan Conrad Universität Düsseldorf,Rainer Gemulla; Friederike Klan; Holger Meyer; Gunter Saake; Kai-Uwe Sattler; Eike Schallehn; Ingo Schmitt; Holger Schwarz; Günther Specht,Page 1. Komittee Organisationskomittee David Broneske Sebastian Dorok Andreas Meister SibaMohammad Veit Köppen Gunter Saake Programm-Komittee Stefan Brass Universität Halle ErikBuchmann Universität Karlsruhe Stefan Conrad Universität Düsseldorf Rainer Gemulla UniversitätMannheim Friederike Klan Friedrich-Schiller Universität Jena Holger Meyer Universität RostockKlaus Meyer-Wegener Universität Erlangen Gunter Saake Universität Magdeburg Kai-Uwe SattlerTU Ilmenau Eike Schallehn Universität Magdeburg Ingo Schmitt TU Cottbus Holger SchwarzUniversität Stuttgart Günther Specht Universität Innsbruck Jens Teubner TU Dortmund 5,*,*,*
Optimierung von Datenflussprogrammen-ein Fall klassischer Anfrageoptimierung?,Kai-Uwe Sattler,ABSTRACT Datenflusssprachen haben in den vergangenen Jahren speziell im Kontext vonBig-Data-Plattformen-etwa in Form von Pig oder Jaql-große Aufmerksamkeit gewonnen. Siebieten sich jedoch auch für die Verarbeitung und Analyse dynamischer Daten bzw.Datenströme an. Ähnlich wie bei klassischen Anfragesprachen besteht beiDatenflusssprachen die Aufgabe; aus (mehr oder weniger) deklarativen Spezifikationeneffiziente Ausführungspläne abzuleiten. Der Vortrag behandelt die Herausforderungenderartiger Optimierungen; geht auf Besonderheiten im Vergleich zur klassischenAnfrageoptimierung ein und diskutiert anhand von Beispielen aus den BereichenDatenstromverarbeitung und MapReduce konkrete Problemstellungen.,Grundlagen von Datenbanken,*,*
Distributed Data Management,Kai-Uwe Sattler,Distributed Data Management Master Ingenieurinformatik 2014 Modul: Distributed Data ManagementWintersemester Turnus: Prof. Dr. Kai-Uwe Sattler 101155 Fachverantwortlich: Sprache: Prüfungsleistungmündlich 30 min Fachnummer: Englisch 2200457 Prüfungsnummer: Fachabschluss: 2 1 0 VSPSWS nach Fach- semester 1. FS 2. FS 3. FS 4. FS 5. FS 6. FS 7. FS Medienformen Vorlesungmit Präsentationen und Tafel; Handouts; Moodle Einführung und Motivation; Grundlagen verteilterDatenbanken: Architektur und Datenverteilung; verteilte Anfrageverarbeitung;Replikationsverfahren; Parallele Datenbanksysteme: Architektur und Datenverteilung; paralleleAnfrageverarbeitung; Shared-Disk-Systeme; Web-Scale Data Mangement: SaaS und MultiTenancy; Virtualisierungstechniken; Konsistenzmodelle; QoS; Partitionierung; Replikation;DHTs; MapReduce Inhalt Vorkenntnisse Vorlesung Datenbanksysteme; Transaktionale …,Modulhandbuch,*,*
Praktikum Informatik für WIW,Kai-Uwe Sattler,Ingenieurwissenschaften Bachelor Wirtschaftsingenieurwesen 2010 Vertiefung MB Modul: PraktikumInformatik für WIW ganzjährig Turnus: Prof. Dr. Kai-Uwe Sattler 5123 Fachverantwortlich:Sprache: Studienleistung alternativ Fachnummer: Deutsch 2200088 Prüfungsnummer:Fachabschluss: 0 0 1 VSP PSVPSVPSVPSVPSVPSV SWS nach Fachsemester 1. FS 2. FS3. FS 4. FS 5. FS 6. FS 7. FS Medienformen praktische Übung am Rechner Programmierungeinfacher Algorithmen für eine kleine; abgeschlossene Problemstellung Inhalt VorkenntnisseVorlesung/Übung „Algorithmen und Programmierung “(1. Semester) Lernergebnisse/KompetenzenFachkompetenz: Die Studierenden verfügen über grundlegende Kenntnisse zu Basisalgorithmenund einfachen Datenstrukturen der Informatik. Die Studierenden können Problemlösungen algorithmischbeschreiben und in einer höheren Programmiersprache implementieren …,Bachelor,*,*
Dataflow Programming for Big Engineering Data–extended abstract–,Felix Beier; Kai-Uwe Sattler; Christoph Dinh; Daniel Baumgarten,Nowadays; advanced sensing technologies are used in many scientific and engineeringdisciplines; eg; in medical or industrial applications; enabling the usage of data-driventechniques to derive models. Measures are collected; filtered; aggregated; and processed ina complex analytic pipeline; joining them with static models to perform high-level tasks likemachine learning. Final results are usually visualized for gaining insights directly from thedata which in turn can be used to adapt the processes and their analyses iteratively to refineknowledge further. This task is supported by tools like R or MATLAB; allowing to quicklydevelop analytic pipelines. However; they offer limited capabilities of processing very largedata sets that require data management and processing in distributed environments–tasksthat have vastly been analyzed in the context of database and data stream management …,GI-Edition,*,*
2007 International Workshop on Peer-to-Peer Networked Virtual Environments (P2P-NVE 2007),Sonja Buchegger; David Hales; Aaron Harwood; Jiung-yao Huang; ROC Sam Joseph; Yoshihiro Kawahara; Chung-Ta King; ROC Nicolas Liebau; Gianluca Moro; Juan Orduna; Kai-Uwe Sattler; Sandeep Singhal; Wernhuar Tarng; ROC Pedro Morillo Tena; Orazio Tomarchio; Li-Ming Tseng; ROC Shinichi Ueshima; Spyros Voulgaris,Page 1. 2007 International Workshop on Peer-to-Peer Networked Virtual Environments(P2P-NVE 2007) Organizing Committees General Chair: Shing-Tsaan Huang; National CentralUniversity; Taiwan; ROC Program Chair: Jehn-Ruey Jiang; National Central University; Taiwan;ROC International Program Committee Members (Listed in alphabet order): Sonja Buchegger;University of California; Berkeley; USA Bing-Yu Chen; National Taiwan University; Taiwan;ROC Jui-Fa Chen; TamKang University; Taiwan; ROC Li-Der Chou; National Central University;Taiwan; ROC Zoran Despotovic; NTT DoCoMo Euro-Labs; Germany Gwendal SIMON; GET /ENST-Bretagne; France David Hales; University of Bologna; Italy Aaron Harwood; Universityof Melbourne; Australia Pilar Herrero; Madrid University of Technology; Spain Jiung-yao Huang;National Taipei University; Taiwan; ROC …,*,*,*
Eliminating memory knobs,Goetz Graefe; Wendy Powley; Kai-Uwe Sattler; Kostas Tzoumas; Jingren Zhou,One of the tasks of workload management is to allocate resources to consumers withconflicting demands. Systems typically contain “knobs” that dictate resource allocation; forexample how much memory should be allocated to the buffer pool; how much memoryshould be allocated to sorting; etc. Eliminating knobs for tuning data management systems isan important task to reduce maintenance costs and make the systems more usable tostandard customers. Eliminating knobs makes the problem of workload managementsignificantly easier by removing free variables. We consider the problem of memory tuning insuch systems as a building block towards this overall goal: given an externally definedamount of memory (which may vary over time); how should this memory be internallydistributed among different heterogeneous consumers? Using a basic model taking utility …,*,*,*
Organization Committee,Denilson Barbosa; Rachel Pottinger; Grigoris Antoniou; ICS FORTH; Greece Smriti Bhagat; Vanessa Braganholo; Diego Calvanese; Paolo Cappellari; Roberto De Virgilio; Irini Fundulaki; Greece James Geller; Fausto Giunchiglia; Claudio Gutierrez; Andreas Harth; Zachary Ives; Solmaz Kolahi; Spyros Kotoulas; Carlos Eduardo Santos Pires; Kai-Uwe Sattler; Martin Theobald; Thanh Tran; Cong Yu; Francesco Guerra; Yannis Velegrakis,The Data Engineering Meets the Semantic Web (DESWEB) workshop series aims atbringing together researchers; developers and practitioners working in the intersectionbetween Databases and the Semantic Web. DESWEB welcomes work related to:(1) the useof Semantics in data management (eg; semanticaware schema matching; and he use ofsemantics in annotation; lineage and provenance of data);(2) Management of Semantic WebData (eg; languages; tools; and methodologies for representing and managing SemanticWeb data); and (3) Semantic Search and Linked Open Data (eg; Searching for and rankingontologies; Social Networking and the Semantic Web; and Semantic-aware searchengines). This third edition of DESWEB features a keynote presentation and four peer-reviewed articles (selected out of twelve submissions). In the keynote “Making the …,*,*,*
ICEBE 2013,Dagmar Auer; Eike Schallehn; Saake Gunter; Specht Günther; Kai-Uwe Sattler; Turowski Klaus; Ladjel Bellatreche; Mark Roantree; Richard B Hull; Ur Rahman Saif; Conrad Stefan; Lehner Wolfgang; Shang Xuequn; Ron Kwok; Chunping Li; Yunqing Xia; Eleanna Kafeza; Elvira Popescu; Maolin Tang; Xiaohui Zhao; Xiaohui Tao; Yi Cai; Kaiquan Xu; Zakaria Maamar; Gordon Hao; Yunjun Gao; Qiudan Li; Wei Xu; Simon Fong; Yain-Whar Si; An Liu; Richi Nayak,Data and Knowledge Management for e-Business Track … Dagmar Auer; University of Linz;Austria Eike Schallehn; University of Magdeburg; Germany Saake Gunter; University ofMagdeburg; Germany Specht Günther; University of Innsbruck; Austria Kai-Uwe Sattler; TechnicalUniversity of Ilmenau; Germany Turowski Klaus; University of Magdeburg; Germany LadjelBellatreche; National Engineering School for Mechanics and Aerotechnics; France MarkRoantree; Dublin City University; Ireland Richard B. Hull; IBM Thomas J. Watson ResearchCenter; USA Ur Rahman Saif; Shaheed Zulfikar Ali Bhutto Institute of Science andTechnology; Pakistan Conrad Stefan; University of Düsseldorf; Germany Lehner Wolfgang; Universityof Dresden; Germany Shang Xuequn; Northwestern Polytechnical University; China RonKwok; City University of Hong Kong; Hong Kong Chunping Li; Tsinghua University …,*,*,*
Informatik der Systeme,Gunter Saake; Kai-Uwe Sattler; Thomas H Cormen; Charles E Leiserson; Ronald L Rivest; Clifford Stein,Modulhandbuch des Fachbereichs 4: Informatik Dieses PDF wurde automatisch generiert. LetzteÄnderung: 24.07. 2013 um 13: 26: 15 Uhr Voraussetzung für die Vergabe vonLeistungspunkten: regelmäßige und qualifizierte Teilnahme (maximal 2 Fehlsitzungen) Stellenwertfür die Note in der Endnote: BEd: 4; 44% entsprechend den LP (8: 180) Literatur GunterSaake; Kai-Uwe Sattler. Algorithmen und Datenstrukturen. dpunkt-Verlag Thomas H.Cormen; Charles E. Leiserson; Ronald L. Rivest; Clifford Stein. Introduction to Algorithms. MITPress Thomas Ottmann; Peter Widmayer. Algorithmen und Datenstrukturen. Spektrum-VerlagInformatik der Systeme 04IN1002: Grundlagen der Rechnernetze Kürzel 04IN1002 ModulbezeichnungGrundlagen der Rechnernetze Name (English) Essentials in computer networks Zuordnungzum Curriculum Bachelor Lehramt Informatik (Gym); 3. Jahr Bachelor Lehramt Informatik …,Modulhandbuch des Fachbereichs 4: Informatik,*,*
Example-driven Integration of Heterogeneous Data Sources,Kai-Uwe Sattler; Stefan Conrad; Ingolf Geist; Gunter Saake,Abstract The integration of heterogeneous databases affects two main problems: schemaintegration and instance integration. At both levels a mapping from local elements to globalelements is specified and various conflicts caused by the heterogeneity of the sources haveto be resolved. For the detection and resolution of instance-level conflicts we propose anexample-driven approach. The basic idea is to combine an interactive query tool similar toquery-by-example with facilities for defining and applying integration operations. Thisintegration approach is supported by a multidatabase query language; which providesspecial mechanisms for conflict resolution. The foundations of these mechanisms areintroduced and their usage in instance integration is presented. In addition; we discuss basictechniques for supporting the detection of instance-level conflicts.,*,*,*
Energy-Efficient Collabrative Query Processing for Mobile Sensing Data,Jin Yang; Tianli Mo; Lipyeow Lim; Kai-Uwe Sattler; Archan Misra,*,*,*,*
Dimension Encoding for Bitwise Dimensional Co-Clustering,Stephan Baumann; Peter Boncz; Kai-Uwe Sattler,Abstract—In this technical report we explain how to create skew-resistant balanceddimensions for our clustering scheme Bitwise Dimensional Co-Clustering (short BDCC)based on histograms and Hu-Tucker encoding. This is needed to avoid unreliable precisionin BDCCscan when scanning tables at different granularities.,America,*,*
Zum Einsatz von SSDs in DBMS: Festplattenersatz oder Herausforderung an neue Speicherstrukturen?!,Kai-Uwe Sattler,Page 1. Zum Einsatz von SSDs in DBMS: Festplattenersatz oder Herausforderung an neueSpeicherstrukturen?! Kai-Uwe Sattler Database & Information Systems Group Ilmenau Universityof Technology; Germany www.tu-ilmenau.de/dbis Page 2. Zum Einsatz von SSDs in DBMS |Kai-Uwe Sattler | TU Ilmenau | 09.06.2010 ▶ Überblick • Einführung & Motivation • Funktionsweise& Eigenschaften von SSDs • Performance-Erwartungen • Micro-Benchmarking • SSDs für DBMS •Konsequenzen • Fazit & Ausblick 2 Page 3. Zum Einsatz von SSDs in DBMS | Kai-Uwe Sattler |TU Ilmenau | 09.06.2010 ▶ Motivation • Rasant wachsendes Datenvolumen: Google (Melnik@BTW 2009) • 20 PB Daten täglich verarbeiten • strukturierte Daten; Text; Bilder; Video • 15 hVideo-Upload jede Minute • 20 PB von Disk lesen: bei 50 MB/s = 12 Jahre • 1TB-Disks verfügbar(ab 170 €); aber (Gray 2006): • 5 .. 15h bei sequentiellem Lesen …,*,*,*
MDM 2010 Workshops Organization,Birgitta König-Ries; Wathiq Mansoor; Jari Veijalainen; Yuki Arase; Erdogan Dogdu; France Takahiro Hara; Nafaâ Jabeur; Qun Jin; Antonio Liotta; Vladimir Oleshchuk; Tore Risch; Brahmananda Sapkota; Kai-Uwe Sattler; Quanzheng Sheng; Vagan Terziyan; Anirban Mondal; Bharat Bhargava,International Workshop on the Role of Services; Ontologies; and Context in Mobile Environments(RoSOC-M 2010) … Organizing Committee Birgitta König-Ries; University of Jena; Jena; GermanyWathiq Mansoor; American University in Dubai; United Arab Emirates Dumitru Roman; SINTEFOslo; Norway Jari Veijalainen; University of Jyvaskyla; Jyvaskyla; Finland … Yuki Arase; OsakaUniversity; Japan Klemens Böhm; Universität Karlsruhe; Germany Erik Buchmann; UniversitätKarlsruhe; Germany Erdogan Dogdu; TOBB University of Economics and Technology; TurkeyNikolaos Georgantas; INRIA; France Takahiro Hara; Osaka University; Japan Nafaâ Jabeur;Dhofar University; Oman Qun Jin; Waseda University; Japan Takahiro Kawamura; ToshibaCorp; Japan Antonio Liotta; University of Essex; UK Andreas Nauerz; IBM Research andDevelopment; Germany Vladimir Oleshchuk; University of Agder; Norway Tore Risch …,*,*,*
Part 1: Motivation,Felix Naumann; Kai-Uwe Sattler,● In 2006 the Fortune 1000 companies will spend more money on IQ problems than forERP; CRM; and BI together.[Gartner]● More than 35% of all IT projects fail due to poor IQ.Poor IQ causes annual expenses of 2-4 billion $ in US.[Meta Group]● IQ is one of the mostimportant success factors in DWH and CRM projects.[PriceWaterhouseCoopers]● Datacollection in the wake of 2004 tsunami● Fatalities and injuries● Housing damages●Property damages● http://www. informationquality. org/publiclyexposediqproblems. cfm,*,*,*
Department of Computer Science & Automation TU Ilmenau; Germany {first. last}@ tu-ilmenau. de,Heiko Betz; Daniel Klan; Kai-Uwe Sattler,Abstract Das Erfassen der Bedeutung von geschriebener oder gesprochener Sprache ist bisheute eine der größten Herausforderung in der Informatik. Für eine effizientecomputergestützte Analyse und Suche ist dies aber unumgänglich. Gegenwärtig ist es nichtmöglich Informationen in ausreichender Qualität vollständig automatisch auf ihre Bedeutunghin zu analysieren und entsprechend zu annotieren. Häufig wird daher auf teilautomatischeSysteme zurückgegriffen; welche eine Nutzerinteraktion erfordern. In der folgenden Arbeitwollen wir zwei neue Ansätze zur automatischen Annotation von Dokumenten präsentieren.,*,*,*
Dagstuhl Seminar" Data Quality on the Web" 31.08.-05.09. 2003; Seminar Nº 03362 Organizers,Michael Gertz; Tamer Özsu; Kai-Uwe Sattler; Gunter Saake,*,*,*,*
P2P’08,Ernst Biersack; Sonja Buchegger; John Buford; Fabian Bustamante; Bruno Crispo; Zoran Despotovic; Joerg Eberspaecher; Lars Eggert; Dick Epema; Bernd Freisleben; Alain Gefflaut; Ali Ghodsi; Christos Gkantsidis; Andrei Gurtov; Gerhard Hasslinger; David Hausheer; Manfred Hauswirth; Pilar Herero; Yiming Hu; Matthias Jarke; Mark Jelasity; Jussi Kangasharju; Daniel Catrein; Manolis Koubarakis; Aleksandra Kovacevic; Fabrice Le Fessant; Christoph Lindemann; Andreas Mauthe; Martin May; Alberto Montresor; Gianluca Moro; Aaron J Quigley; Douglas Reeves; Matei Ripeanu; Kai-Uwe Sattler; Christoph Schuba; Henning Schulzrinne; Sherman Shen; Henk Sips; Phuoc Tran-Gia; Peter Triantafillou; Kurt Tutschku; Maarten van Steen; Yushun Wang; Michael Welzl; Roger Zimmermann,Karl Aberer; EPFL; Switzerland Wolf-Tilo Balke; L3S; Germany Marinho Barcellos; PUCRS; BrazilErnst Biersack; Institut Eurecom; France Sonja Buchegger; US Berkeley; USA John Buford;Avaya; USA Fabian Bustamante; Northwestern University; USA Bruno Crispo; University ofTrento; Italy Anwitaman Datta; NTU; Singapore Zoran Despotovic; NTT DoCoMo Euro-Labs;Germany Joerg Eberspaecher; TU Munich; Germany Lars Eggert; Nokia; Finland DickEpema; TU Delft; The Netherlands Bernd Freisleben; University of Marburg; Germany AlainGefflaut; Microsoft; Germany Ali Ghodsi; KTH/SICS; Sweden Christos Gkantsidis; MicrosoftResearch; UK Andrei Gurtov; University of Helsinki; Finland Gerhard Hasslinger; T-Systems;Germany David Hausheer; University of Zurich; Switzerland Manfred Hauswirth; National Universityof Ireland Pilar Herero; Madrid University of Technology; Spain Yiming Hu; University of …,*,*,*
SIGMA FDB: Overview of the Magdeburg-Approach to Database Federations?,E Hildebrandt; KU Sattler; I Schmitt,Abstract. The SIGMAFDB project attempts to o er an approach to schema integration andintegegrity constraint maintenance in the eld of federated database systems. In thisextended abstract; we present our view on federated database systems and sketch the mainresults of our group's work. Especially; we brie y discuss di erent research aspects andimplementation activities.,*,*,*
Modeling and Managing Spatiotemporal Audio Data,Thomas Heimrich; Katrin Reichelt; Hendrik Rusch; Kai-Uwe Sattler; Thomas Schröder,Abstract. During the recent years database technologies have entered many new non-standard application domains such as media production. At the same time; new trends inthese areas come along with new challenges to the database field. An example of such anemerging application is a new sound system based on the wave field synthesis; whereobjectoriented audio scenes are modeled using spatiotemporal relationships and renderedin realtime in order to produce high-quality spatial sound. In this paper; we discuss thedesign challenges for the data management component of this system and presenttechniques for modeling; storing; and streaming audio data scenes.,*,*,*
Query Reformulation for Keyword Searching in Mediator Systems,Ingolf Geist Torsten Declercq; Kai-Uwe Sattler Eike Schallehn,Abstract Integration of heterogeneous data sources is still an important task. Mediatorsystems are one approach to support a structured search over heterogeneous sources.These systems provide comprehensive query languages; which are very powerful but hardto use for inexperienced users. Therefore; easier query interfaces have to be developed.One well-known and effective interface is the keyword search. However; one has to considerthe capabilities of sources; which mostly support only structured queries. The aim of thispaper is the development of a keyword query component based on a conceptbasedmediator to overcome this problem. The efficient keyword query execution is supported byan index on global level as well as a concept model; consisting of concepts and theirproperties and relationships. The search is performed in a two-step process that …,*,*,*
SIGMA: Overview of the Magdeburg-Approach to Database Federations* M. Hioding; K. Schwarz; S. Conrad; G. Saake; S. Balko; A. Diekmann; E. Hildebrandt; K.-U....,M Hioding,Abstract. The SIGMAÐÑÒ project attempts to offer an approach to schema integration andintegegrity constraint maintenance in the field of federated database systems. In thisextended abstract; we present our view on federated database systems and sketch the mainresults of our group's work. Especially; we briefly discuss different research aspects andimplementation activities.,*,*,*
SAINT 2009,Morris Chang; Kenichi Yoshida; Artur Hecker; Atsuhiro Goto; Bharat Bhargava; Carl K Chang; Charles A Shoniregun; Christopher Edwards; Claude Godart; Dae Young Kim; Dan Massey; Elvira Popescu; Fumio Teraoka; Hideki Sunahara; Hiroki Horiuchi; Hiroshi Mineno; Hiroyuki Morikawa; Hiroyuki Ohsaki; Hitoshi Okada; Ivana Podnar Zarko; Jari Veijalainen; Javed I Khan; Jiangbo Dang; Jun Bi; Kai-Uwe Sattler; Karsten Martin; Katsunori Yamaoka; Katsuyoshi Iida; Katsuyuki Yamazaki; Kazutoshi Fujikawa; Kenichi Yamazaki; Kenji Saito; Klaus David; Koji Okamura; Kouji Nishimura,Program Chairs Morris Chang; Iowa State University Kenichi Yoshida; University of Tsukuba… Program Committee Members Artur Hecker; TELECOM ParisTech Atsuhiro Goto; NTT BharatBhargava; Purdue university Carl K. Chang; Iowa State University Charles A. Shoniregun; SheridanInstitute of Technology and Advanced Learning Christopher Edwards; Lancaster University ClaudeGodart; University Henri Poincare; Nancy Dae Young Kim; Chungnam National University DanMassey; Colorado State University Elvira Popescu; University of Craiova Fumio Teraoka; KeioUniversity Hideki Sunahara; Nara Institute of Science and Technology Hiroki Horiuchi; KDDIR&D Laboratories Inc. Hiroshi Mineno; University of Shizuoka Hiroyuki Morikawa; The Universityof Tokyo Hiroyuki Ohsaki; Osaka University Hitoshi Okada; National Institute of Informatics IvanaPodnar Zarko; University Zagreb Jari Veijalainen; University of Jyväskylä Javed I. Khan …,*,*,*
Program Committee Reviewers,Michel Adiba; Gilbert Babin; Roger Barga; Karin Becker; Zohra Bellahsene; Jorge Bernardino; Peter Bodorik; Andre Clouatre; Isabel Cruz; Bin Cui; Frank Dehne; Bipin C Desai; Klaus R Dittrich; Anne Doucet; Todd Eavis; Matteo Golfarelli; Shyam K Gupta; Volker Haarslev; Theo Haerder; Bettina Kemme; Dominique Laurent; Mark Levene; Feng Ling; Arturas Mazeika; Tim Merrett; Tore Risch; Domenico Sacca; Kai-Uwe Sattler; Nematollaah Shiri; Nicolas Spyratos; Yannis Theodoridis; Manuel Torres; Rainer Unland; Jari Veijalainen; Krishnamurty Vidyasankar; Gottfried Vossen; Mathias Weske; Jeffery Xu Yu,Michel Adiba; University of Grenoble; France Gilbert Babin; HEC Montréal Roger Barga; MicrosoftResearch; USA Karin Becker; Pontifícia Universidade Católica do Rio Grande do Sul ZohraBellahsene; Laboratoire d'Informatique; de Robotique et de Microelectronique de MontpellierJorge Bernardino; ISEC Peter Bodorik; Dalhousie University; Canada Andre Clouatre; Universityof Montreal Stefan Conrad; University of Duesseldorf; Institut fuer Informatik Isabel Cruz; Universityof Illinois at Chicago; USA Bin Cui; National University of Singapore Frank Dehne; Griffith UniversityBipin C. Desai; Concordia University; Canada Klaus R. Dittrich; University of Zurich AnneDoucet; Pierre et Marie Curie University; France Todd Eavis; Department of Computer Scienceand Software Engineering; Concordia University; Canada Matteo Golfarelli; University of BolognaShyam K. Gupta; Indian Institute of Technology Volker Haarslev; Concordia University …,*,*,*
An Extended Transaction Model for Cooperative Authoring of XML Documents,Francis Gropengießer; Katja Hose; Kai-Uwe Sattler,Abstract In many application scenarios; for example in design or media productionprocesses; several authors have to work cooperatively on the same project andconsequently on the same data. A frequently used data format in this context is XML. Toenable cooperative authoring of shared XML graph structures; several requirements have tobe fulfilled; eg; early visibility of updates; multi-directional information flow; and processingdata in parallel. Most transaction models proposed in the literature are hardly applicable inthis context. In this paper; we propose a novel transaction model based on multi-leveltransactions and dynamic actions that meets these requirements. We describe thetransaction model as well as its formal properties and discuss issues such assynchronization and logging.,*,*,*
Software-Agenten zur Informationssuche und-filterung,Kai-Uwe Sattler,3.1 InformationRetrievalundFilterung . . . . . . . . . . . . . . . . . . . . . 20 3.1.1 ¨Uberblick . . . . . . . . . . .. . . . . . . . . . . . . . . . . . . . 20 3.1.2 Daten–Wissen–Information . . . . . . . . . . . . . . . . . . . . 21 3.1.3 GrundmodelldesIR. . . . . . . . . . . . . . . . . . . . . . . . . 22 3.1.4 Evaluierung . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 22 3.1.5 RepräsentationfürTexte. . . . . . . . . . . . . . . . . . . . . . . 23 3.1.6 IR-Modelle … 3.4.1 Grundlagen . . . . . . . . .. . . . . . . . . . . . . . . . . . . . . 51 3.4.2 Lernen . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 51 3.4.3 Planen .. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 57 3.5 Nutzermodellierung . . . . . . . . . . . . . . . . . . . . . . . . . . .. . . 64 3.6 SicherheitundVertraulichkeit . . . . . . . . . . . . . . . . . . . . . . . . 70 3.6.1 Motivation . . . . . .… 4.1 Architekturen . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 77 4.1.1¨Uberblick . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 77 4.1.2 DeliberativeAgentensysteme:BDI-Modell. . . . . . . . . . . . . 77 4.1.3 ReaktiveAgentensysteme:Subsumption . . . . . . . . . . . . . . . 80 4.1.4 …,*,*,*
Eddies und verteilte Eddies,KU Sattler,*,*,*,*
P2P,Ernst Biersack; Sonja Buchegger; Fabian Bustamante; Bruno Crispo; Jon Crowcroft; Philippe Cudre-Mauroux; Zoran Despotovic; Dick Epema; Pascal Felber; Christos Gkantsidis; David Hales; Pilar Herrero; Yiming Hu; Mark Jelasity; Manolis Koubarakis; Fabrice Le Fessant; Marco Mamei; Cecilia Mascolo; Martin May; Gianluca Moro; Paolo Penna; Evaggelia Pitoura; Aaron J Quigley; Douglas Reeves; Matei Ripeanu; Timothy Roscoe; Keith Ross; Kai-Uwe Sattler; Detlef Schoder; Christoph Schuba; Nahid Shahmehri; Sandeep Singhal; Henk Sips; Steffen Staab,Karl Aberer; EPFL; Switzerland Wolf-Tilo Balke; L3S; Germany Ernst Biersack; InstitutEurecom; France Sonja Buchegger; Deutsche Telekom Laboratories; Germany FabianBustamante; Northwestern University; USA Bruno Crispo; University of Trento; Italy JonCrowcroft; University of Cambridge; UK Philippe Cudre-Mauroux; EPFL; Switzerland AnwitamanDatta; NTU; Singapore Zoran Despotovic; NTT DoCoMo Euro-Labs; Germany Dick Epema; DelftUniversity of Technology; The Netherlands Pascal Felber; University of Neuchatel; SwitzerlandChristos Gkantsidis; Microsoft Research; UK David Hales; University of Bologna; Italy PilarHerrero; Madrid University of Technology; Spain Yiming Hu; University of Cincinnati; USA MarkJelasity; Hungarian Acad. Sci. and University of Szeged; Hungary Anne-Marie Kermarrec;INRIA; France Manolis Koubarakis; University of Athens; Greece Fabrice Le Fessant …,*,*,*
Rule-based Mapping in Ontology-based Mediators,Gunter Saake; Kai-Uwe Sattler; Stefan Conrad,Integrating data from heterogeneous sources on the Web is an important topic of interestwithin the database community. Here; several issues arise such as autonomy; heterogeneityas well as scalability and adaptability with regard to a great number of–possibly changing–data sources. Suitable solutions range from simple meta search engines over materializedapproaches to mediator systems which answer queries on a global schema bydecomposing them; forwarding the subqueries to the source systems and combining theresults into a global answer. In mediator systems of the first generation integration isachieved mainly on a structural level. Data from the diverse sources are combined based onstructural correspondences such as membership in classes of the same structure or theexistence of common attributes. This works well in more or less homogeneous domains …,*,*,*
Diplomarbeit zur Erlangung des akademischen Grades Diplominformatiker vorgelegt der Fakultät für Informatik und Automatisierung der Technischen Universität Ilm...,Kai-Uwe Sattler; Dipl-Inf Marcel Karnstedt,Die Astronomie stellt eine Wissenschaft dar; bei deren Ausübung große Mengen an Datenzu bearbeiten; zu archivieren und auszuwerten sind. Das Anliegen Archive dieser Dateneiner breiten Öffentlichkeit innerhalb der Gemeinde von Astronomen und Astrophysikern zurVerfügung zu stellen; führte zu einer Vision eines Virtuellen Observatoriums bestehend auseiner Vernetzung astronomischer Archive. Hierfür werden neue oder angepassteDatenhaltungsstrukturen benötigt. Diese Arbeit beschäftigt sich deshalb mit einerDatenbankintegration für Virtuelle Observatorien.,*,*,*
Doktoringenieur (Dr.-Ing.),Gunter Saake; Kai-Uwe Sattler; Stefan Manegold,Abstract Database management systems (DBMS) were developed decades ago withconsideration for the legacy hardware and data management requirements. Over years;developments in the hardware and the data management have forced DBMS to grow infunctionalities. These functionalities got tightly integrated into the DBMS core because oftheir monolithic architecture. This has resulted in increased complexity of DBMS; whichmakes them difficult to tune for consistent performance. Furthermore; the decreasing cost ofthe hardware and the software has resulted in making the human resource a major factor inthe total cost of ownership for the data management. There exists a need to revisit existingdatabase architecture using unconventional and unexplored techniques towards morediversified and loosely coupled architectures. We present the Cellular DBMS architecture …,*,*,*
Quantitatives Frequent-Pattern Mining uber Datenströmen,Daniel Klan; Thomas Rohe,Abstract Das Aufdecken unbekannter Zusammenhänge zählt zu einer der wichtigstenAufgaben im Data Mining. Für das Problem des Frequent Pattern Mining über statischenDaten finden sich daher in der Literatur eine Vielzahl an Lösungen. Die Integration vonSensorik in nahezu jeden Lebensbereich führt allerdings zu Datenmengen; welche mittelsder klassischen Verfahren zumeist nicht mehr bewältigt werden können. EinParadigmenwechsel hin zur Datenstrom-Verarbeitung ist oftmals unumgänglich. Eininteressantes Problem; welches im Zusammenhang mit der Verarbeitung von Sensordatenauftritt ist der prinzipiell stetige Wertebereich von Messungen. Die bekannten Lösungen sindfür die Analyse von kontinuierlichen Daten über stetigen Wertebereichen nur bedingtgeeignet. Im folgenden soll mit dem FP2-Stream ein entsprechendes Verfahren für die …,LWA 2010,*,*
Advanced Query Processing in P2P Databases,Kai-Uwe Sattler,*,*,*,*
IQ2S'11: The Third International Workshop on Information Quality and Quality of Service for Pervasive Computing-Committees and welcome,Chatschik Bisdikian; Sajal K Das; Archan Misra; Kai-Uwe Sattler; Habib M Ammari; Liz Ribe-Baumann; Wendong Xiao,Quality of Information (QoI or IQ) touches every part of the end-to-end flow of informationfrom its pervasive sources; like sensors and the observation data they produce; to thevarious fusion layers that process these data and eventually to the applications (and theirusers) that use them. The effectiveness of actions taken by these applications using thisinformation serves as the ultimate assessor of the quality and value-add provided by theentire sensor-enabled application. Complementing “traditional” provisioning of QoS with QoIfor pervasive computing is challenging and difficult due to the resource-constrained;dynamic and distributed nature of the system; the weakness under security attacks; theincomplete understanding of the impact that different characteristics of the sensor-generateddata (eg; freshness; resolution & sampling frequency) have on the applications' utility; and …,*,*,*
