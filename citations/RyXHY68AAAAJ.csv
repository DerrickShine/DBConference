Aether: A Scalable Approach to Logging,Ryan Johnson; Ippokratis Pandis; Radu Stoica; Manos Athanassoulis; Anastasia Ailamaki,Abstract The shift to multi-core hardware brings new challenges to database systems; as thesoftware parallelism determines performance. Even though database systems traditionallyaccommodate simultaneous requests; a multitude of synchronization barriers serializeexecution. Write-ahead logging is a fundamental; omnipresent component in ARIES-styleconcurrency and recovery; and one of the most important yet-to-be addressed potentialbottlenecks; especially in OLTP workloads making frequent small changes to data. In thispaper; we identify four logging-related impediments to database system scalability. Eachissue challenges different level in the software architecture:(a) the high volume of small-sized I/O requests may saturate the disk;(b) transactions hold locks while waiting for the logflush;(c) extensive context switching overwhelms the OS scheduler with threads executing …,Proceedings of the VLDB Endowment,2010,104
Evaluating and repairing write performance on flash devices,Radu Stoica; Manos Athanassoulis; Ryan Johnson; Anastasia Ailamaki,Abstract In the last few years NAND flash storage has become more and more popular asprice per GB and capacity both improve at exponential rates. Flash memory offers significantbenefits compared to magnetic hard disk drives (HDDs) and DBMSs are highly likely to useflash as a general storage backend; either alone or in heterogeneous storage solutions withHDDs. Flash devices; however; respond quite differently than HDDs for common accesspatterns; and recent research shows a strong asymmetry between read and writeperformance. Moreover; flash storage devices behave unpredictably; showing a highdependence on previous IO history and usage patterns. In this paper we investigate how aDBMS can overcome these issues to take full advantage of flash memory as persistentstorage. We propose new a flash aware data layout---append and pack---which stabilizes …,Proceedings of the Fifth International Workshop on Data Management on New Hardware,2009,59
TPC-E vs. TPC-C: characterizing the new TPC-E benchmark via an I/O comparison study,Shimin Chen; Anastasia Ailamaki; Manos Athanassoulis; Phillip B Gibbons; Ryan Johnson; Ippokratis Pandis; Radu Stoica,Abstract TPC-E is a new OLTP benchmark recently approved by the Transaction ProcessingPerformance Council (TPC). In this paper; we compare TPC-E with the familiar TPCCbenchmark in order to understand the behavior of the new TPC-E benchmark. In particular;we compare the I/O access patterns of the two benchmarks by analyzing two OLTP disktraces. We find that (i) TPC-E is more read intensive with a 9.7: 1 I/O read to write ratio; whileTPC-C sees a 1.9: 1 read-to-write ratio; and (ii) although TPC-E uses pseudo-realistic data;TPC-E's I/O access pattern is as random as TPC-C. The latter suggests that like TPC-C; TPC-E can benefit from SSDs; which have superior random I/O support. To verify this; we replayboth disk traces on an Intel X25-E SSD and see dramatic improvements for both TPC-C andTPC-E.,ACM SIGMOD Record,2011,51
Scalability of write-ahead logging on multicore and multisocket hardware,Ryan Johnson; Ippokratis Pandis; Radu Stoica; Manos Athanassoulis; Anastasia Ailamaki,Abstract The shift to multi-core and multi-socket hardware brings new challenges todatabase systems; as the software parallelism determines performance. Even thoughdatabase systems traditionally accommodate simultaneous requests; a multitude ofsynchronization barriers serialize execution. Write-ahead logging is a fundamental;omnipresent component in ARIES-style concurrency and recovery; and one of the mostimportant yet-to-be addressed potential bottlenecks; especially in OLTP workloads makingfrequent small changes to data. In this paper; we identify four logging-related impediments todatabase system scalability. Each issue challenges different level in the softwarearchitecture:(a) the high volume of small-sized I/O requests may saturate the disk;(b)transactions hold locks while waiting for the log flush;(c) extensive context switching …,The VLDB Journal—The International Journal on Very Large Data Bases,2012,43
A New Look at the Roles of Spinning and Blocking,Ryan Johnson; Manos Athanassoulis; Radu Stoica; Anastasia Ailamaki,Abstract Database engines face growing scalability challenges as core counts exponentiallyincrease each processor generation; and the efficiency of synchronization primitives used toprotect internal data structures is a crucial factor in overall database performance. The trade-offs between different implementation approaches for these primitives shift significantly withincreasing degrees of available hardware parallelism. Blocking synchronization; which haslong been the favored approach in database systems; becomes increasingly unattractive asgrowing core counts expose its bottlenecks. Spinning implementations improve peak systemthroughput by a factor of 2x or more for 64 hardware contexts; but suffer from poorperformance under load. In this paper we analyze the shifting trade-off between spinningand blocking synchronization; and observe that the trade-off can be simplified by isolating …,Proceedings of the Fifth International Workshop on Data Management on New Hardware,2009,32
Flash in a DBMS: Where and How?,Manos Athanassoulis; Anastasia Ailamaki; Shimin Chen; Phillip Gibbons; Radu Stoica,Abstract Over the past decade; new solid state storage technologies; with flash being themost mature one; have become increasingly popular. Such technologies store data durably;and can alleviate many handicaps of hard disk drives (HDDs). Nonetheless; they have verydifferent characteristics compared to HDDs; making it challenging to integrate suchtechnologies into data intensive systems; such as database management systems (DBMS);that rely heavily on underlying storage behaviors. In this paper; we ask the question: Whereand how will flash be exploited in a DBMS? We describe techniques for making effective useof flash in three contexts:(i) as a log device for transaction processing on memory-residentdata;(ii) as the main data store for transaction processing; and (iii) as an update cache forHDD-resident data warehouses.,IEEE Data Eng. Bull.,2010,28
Energy efficiency in wireless sensor networks: A utility-based architecture,Manoussos Athanassoulis; Ioannis Alagiannis; Stathes Hadjiefthymiades,Abstract—Wireless Sensor Networks (WSN) comprise a fast-developing research area witha vast spectrum of applications. A WSN design is influenced by many factors such astransmission errors; network topology and power consumption. Consequently; developing aWSN application introduces several implementation challenges. In this paper; we describe amulti-criteria architecture in order to achieve energy-aware and consistent messageforwarding over a WSN. Using the proposed architecture a directed acyclic graph (DAG) isformed throughout the WSN. Such DAG is used for multi-source data aggregation to a singlesink. Intermediate nodes evaluate their energy reserve and induced error and decidewhether message retransmission is needed. A sink is necessary in order to collect; processand probably forward these data to a more sophisticated system for further processing …,European Wireless,2007,28
MaSM: Efficient Online Updates in Data Warehouses,Manos Athanassoulis; Shimin Chen; Anastasia Ailamaki; Phillip Gibbons; Radu Ioan Stoica,Abstract Data warehouses have been traditionally optimized for read-only queryperformance; allowing only offline updates at night; essentially trading off data freshness forperformance. The need for 24x7 operations in global markets and the rise of online andother quickly-reacting businesses make concurrent online updates increasingly desirable.Unfortunately; state-of-the-art approaches fall short of supporting fast analysis queries overfresh data. The conventional approach of performing updates in place can dramatically slowdown query performance; while prior proposals using differential updates either requirelarge in-memory buffers or may incur significant update migration cost. This paper presentsa novel approach for supporting online updates in data warehouses that overcomes thelimitations of prior approaches; by making judicious use of available SSDs to cache …,Proceedings of the ACM SIGMOD International Conference on Management of Data,2011,27
Beyond the wall: Near-data processing for databases,Sam Likun Xi; Oreoluwa Babarinsa; Manos Athanassoulis; Stratos Idreos,Abstract The continuous growth of main memory size allows modern data systems toprocess entire large scale datasets in memory. The increase in memory capacity; however;is not matched by proportional decrease in memory latency; causing a mismatch for in-memory processing. As a result; data movement through the memory hierarchy is now oneof the main performance bottlenecks for main memory data systems. Database systemsresearchers have proposed several innovative solutions to minimize data movement and tomake data access patterns hardware-aware. Nevertheless; all relevant rows and columnsfor a given query have to be moved through the memory hierarchy; hence; movement oflarge data sets is on the critical path. In this paper; we present JAFAR; a Near-DataProcessing (NDP) accelerator for pushing selects down to memory in modern column …,Proceedings of the 11th International Workshop on Data Management on New Hardware,2015,23
BF-tree: Approximate Tree Indexing,Manos Athanassoulis; Anastasia Ailamaki,Abstract The increasing volume of time-based generated data and the shift in storagetechnologies suggest that we might need to reconsider indexing. Several workloads-likesocial and service monitoring-often include attributes with implicit clustering because of theirtime-dependent nature. In addition; solid state disks (SSD)(using flash or other low-leveltechnologies) emerge as viable competitors of hard disk drives (HDD). Capacity and accesstimes of storage devices create a trade-off between SSD and HDD. Slow random accessesin HDD have been replaced by efficient random accesses in SSD; but their availablecapacity is one or more orders of magnitude more expensive than the one of HDD. Indexing;however; is designed assuming HDD as secondary storage; thus minimizing randomaccesses at the expense of capacity. Indexing data using SSD as secondary storage …,Proceedings of the VLDB Endowment,2014,22
Sharing data and work across concurrent analytical queries,Iraklis Psaroudakis; Manos Athanassoulis; Anastasia Ailamaki,Abstract Today's data deluge enables organizations to collect massive data; and analyze itwith an ever-increasing number of concurrent queries. Traditional data warehouses (DW)face a challenging problem in executing this task; due to their query-centric model: eachquery is optimized and executed independently. This model results in high contention forresources. Thus; modern DW depart from the query-centric model to execution modelsinvolving sharing of common data and work. Our goal is to show when and how a DWshould employ sharing. We evaluate experimentally two sharing methodologies; based ontheir original prototype systems; that exploit work sharing opportunities among concurrentqueries at run-time: Simultaneous Pipelining (SP); which shares intermediate results ofcommon sub-plans; and Global Query Plans (GQP); which build and evaluate a single …,Proceedings of the VLDB Endowment,2013,21
Queriosity: Automated Data Exploration,Abdul Wasay; Manos Athanassoulis; Stratos Idreos,Curiosity; a fundamental drive amongst higher living organisms; is what enables exploration;learning and creativity. In our increasingly data-driven world; data exploration; ie; Makingsense of mounting haystacks of data; is akin to intelligence for science; business andindividuals. However; modern data systems--designed for data retrieval rather thanexploration--only let us retrieve data and ask if it is interesting. This makes knowledgediscovery a game of hit-and-trial which can only be orchestrated by expert data scientists.We present the vision toward Queriosity; an automated and personalized data explorationsystem. Designed on the principles of autonomy; learning and usability; Queriosity envisionsa paradigm shift in data exploration and aims to become aa personalized" data robot" thatprovides a direct answer to what is interesting in a user's data set; instead of just …,IEEE BigData Congress 2015,2015,19
Designing Access Methods: The RUM Conjecture.,Manos Athanassoulis; Michael S Kester; Lukas M Maas; Radu Stoica; Stratos Idreos; Anastasia Ailamaki; Mark Callaghan,ABSTRACT The database research community has been building methods to store; access;and update data for more than four decades. Throughout the evolution of the structures andtechniques used to access data; access methods adapt to the ever changing hardware andworkload requirements. Today; even small changes in the workload or the hardware lead toa redesign of access methods. The need for new designs has been increasing as datageneration and workload diversification grow exponentially; and hardware advancesintroduce increased complexity. New workload requirements are introduced by theemergence of new applications; and data is managed by large systems composed of moreand more complex and heterogeneous hardware. As a result; it is increasingly important todevelop application-aware and hardware-aware access methods. The fundamental …,EDBT,2016,15
Path Processing using Solid State Storage,Manos Athanassoulis; Bishwaranjan Bhattacharjee; Mustafa Canim; Kenneth A. Ross,ABSTRACT Recent advances in solid state technology have led to the introduction of SolidState Drives (SSDs). Todays SSDs store data persistently using NAND flash memory. WhileSSDs are more expensive than hard disks when measured in dollars per gigabyte; they aresignificantly cheaper when measured in dollars per random I/O per second. Additionalstorage technologies are under development; Phase Change Memory (PCM) being the nextone to enter the marketplace. PCM is nonvolatile; it can be byte-addressable; and in futureMulti Level Cell (MLC) devices; PCM is expected to be denser than DRAM. PCM has lowerread and write latency compared to NAND flash memory; and it can endure orders ofmagnitude more write cycles before wearing out. Recent research has shown that solid statedevices can be particularly beneficial for latency-bound applications involving dependent …,Third International Workshop on Accelerating Data Management Systems Using Modern Processor and Storage Architectures,2012,13
Monkey: Optimal navigable key-value store,Niv Dayan; Manos Athanassoulis; Stratos Idreos,Abstract In this paper; we show that key-value stores backed by an LSM-tree exhibit anintrinsic trade-off between lookup cost; update cost; and main memory footprint; yet allexisting designs expose a suboptimal and difficult to tune trade-off among these metrics. Wepinpoint the problem to the fact that all modern key-value stores suboptimally co-tune themerge policy; the buffer size; and the Bloom filters' false positive rates in each level. Wepresent Monkey; an LSM-based key-value store that strikes the optimal balance between thecosts of updates and lookups with any given main memory budget. The insight is that worst-case lookup cost is proportional to the sum of the false positive rates of the Bloom filtersacross all levels of the LSM-tree. Contrary to state-of-the-art key-value stores that assign afixed number of bits-per-element to all Bloom filters; Monkey allocates memory to filters …,Proceedings of the 2017 ACM International Conference on Management of Data,2017,6
Design Tradeoffs of Data Access Methods,Manos Athanassoulis; Stratos Idreos,Abstract Database researchers and practitioners have been building methods to store;access; and update data for more than five decades. Designing access methods has been aconstant effort to adapt to the ever changing underlying hardware and workloadrequirements. The recent explosion in data system designs-including; in addition totraditional SQL systems; NoSQL; NewSQL; and other relational and non-relational systems-makes understanding the tradeoffs of designing access methods more important than ever.Access methods are at the core of any new data system. In this tutorial we survey recentdevelopments in access method design and we place them in the design space where eachapproach focuses primarily on one or a subset of read performance; update performance;and memory utilization. We discuss how to utilize designs and lessons-learned from past …,Proceedings of the 2016 International Conference on Management of Data,2016,6
Upbit: Scalable in-memory updatable bitmap indexing,Manos Athanassoulis; Zheng Yan; Stratos Idreos,Abstract Bitmap indexes are widely used in both scientific and commercial databases. Theybring fast read performance for specific types of queries; such as equality and selectiverange queries. A major drawback of bitmap indexes; however; is that supporting updates isparticularly costly. Bitmap indexes are kept compressed to minimize storage footprint; as aresult; updating a bitmap index requires the expensive step of decoding and then encodinga bitvector. Today; more and more applications need support for both reads and writes;blurring the boundaries between analytical processing and transaction processing. Thisrequires new system designs and access methods that support general updates and; at thesame time; offer competitive read performance. In this paper; we propose scalable in-memory Updatable Bitmap indexing (UpBit); which offers efficient updates; without hurting …,Proceedings of the 2016 International Conference on Management of Data,2016,6
Scaling up analytical queries with column-stores,Ioannis Alagiannis; Manos Athanassoulis; Anastasia Ailamaki,Abstract As data analytics is used by an increasing number of applications; data analyticsengines are required to execute workloads with increased concurrency; ie; an increasingnumber of clients submitting queries. Data management systems designed for data analytics-a market dominated by column-stores-however; were initially optimized for single queryexecution; minimizing its response time. Hence; they do not treat concurrency as a first classcitizen. In this paper; we experiment with one open-source and two commercial column-stores using the TPC-H and SSB benchmarks in a setup with an increasing number ofconcurrent clients submitting queries; focusing on whether the tested systems can scale upin a single node instance. The tested systems for in-memory workloads scale up; to somedegree; however; when the server is saturated they fail to fully exploit the available …,Proceedings of the 6th International Workshop on Testing Database Systems,2013,5
A Multi-Criteria Message Forwarding Architecture for Wireless Sensor Networks,Manoussos Athanassoulis; Ioannis Alagiannis; S Hadjieuthimiades,Abstract. Wireless Sensor Networks (WSN) comprise a fast-developing research area with avast spectrum of applications. A WSN design is influenced by many factors such astransmission errors; network topology and power consumption. Consequently; developing aWSN application introduces several implementation challenges. In this paper; we describe amulti-criteria architecture in order to achieve energy-aware and consistent messageforwarding over a WSN. Using the proposed architecture a directed acyclic graph (DAG) isformed throughout the WSN. Such DAG is used for multi-source data aggregation to a singlesink. Intermediate nodes evaluate their energy reserve and induced error and decidewhether message retransmission is needed. A sink is necessary in order to collect; processand probably forward these data to a more sophisticated system for further processing …,the proceedings of the 10th Pan-Hellenic Conference on Informatics; Volos; Greece,2005,5
Online Updates on Data Warehouses via Judicious Use of Solid-State Storage,Manos Athanassoulis; Shimin Chen; Anastasia Ailamaki; Philip B Gibbons; Radu Stoica,Abstract Data warehouses have been traditionally optimized for read-only queryperformance; allowing only offline updates at night; essentially trading off data freshness forperformance. The need for 24x7 operations in global markets and the rise of online andother quickly reacting businesses make concurrent online updates increasingly desirable.Unfortunately; state-of-the-art approaches fall short of supporting fast analysis queries overfresh data. The conventional approach of performing updates in place can dramatically slowdown query performance; while prior proposals using differential updates either requirelarge in-memory buffers or may incur significant update migration cost. This article presentsa novel approach for supporting online updates in data warehouses that overcomes thelimitations of prior approaches by making judicious use of available SSDs to cache …,ACM Transactions on Database Systems (TODS),2015,3
Slalom: Coasting through raw data via adaptive partitioning and indexing,Matthaios Olma; Manos Karpathiotakis; Ioannis Alagiannis; Manos Athanassoulis; Anastasia Ailamaki,Abstract The constant flux of data and queries alike has been pushing the boundaries ofdata analysis systems. The increasing size of raw data files has made data loading anexpensive operation that delays the data-to-insight time. Hence; recent in-situ queryprocessing systems operate directly over raw data; alleviating the loading cost. At the sametime; analytical workloads have increasing number of queries. Typically; each query focuseson a constantly shifting--yet small--range. Minimizing the workload latency; now; requires thebenefits of indexing in in-situ query processing. In this paper; we present Slalom; an in-situquery engine that accommodates workload shifts by monitoring user access patterns.Slalom makes on-the-fly partitioning and indexing decisions; based on information collectedby lightweight monitoring. Slalom has two key components:(i) an online partitioning and …,Proceedings of the VLDB Endowment,2017,2
Access Path Selection in Main-Memory Optimized Data Systems: Should I Scan or Should I Probe?,Michael S Kester; Manos Athanassoulis; Stratos Idreos,Abstract The advent of columnar data analytics engines fueled a series of optimizations onthe scan operator. New designs include column-group storage; vectorized execution; sharedscans; working directly over compressed data; and operating using SIMD and multi-coreexecution. Larger main memories and deeper cache hierarchies increase the efficiency ofmodern scans; prompting a revisit of the question of access path selection. In this paper; wecompare modern sequential scans and secondary index scans. Through detailed analyticalmodeling and experimentation we show that while scans have become useful in more casesthan before; both access paths are still useful; and so; access path selection (APS) is stillrequired to achieve the best performance when considering variable workloads. We showhow to perform access path selection. In particular; contrary to the way traditional systems …,Proceedings of the 2017 ACM International Conference on Management of Data,2017,2
Reactive and proactive sharing across concurrent analytical queries,Iraklis Psaroudakis; Manos Athanassoulis; Matthaios Olma; Anastasia Ailamaki,Abstract Today an ever increasing amount of data is collected and analyzed by researchers;businesses; and scientists in data warehouses (DW). In addition to the data size; the numberof users and applications querying data grows exponentially. The increasing concurrency isitself a challenge in query execution; but also introduces an opportunity favoring synergybetween concurrent queries. Traditional execution engines of DW follows a query-centricapproach; where each query is optimized and executed independently. On the other hand;workloads with increased concurrency have several queries with common parts of data andwork; creating the opportunity for sharing among concurrent queries. Sharing can bereactive to the inherently existing sharing opportunities; or proactive by redesigning queryoperators to maximize the sharing opportunities. This demonstration showcases the …,Proceedings of the 2014 ACM SIGMOD International Conference on Management of Data,2014,1
Secure Data Systems and Performance: Friends or Foe?,Manos Athanassoulis,The increasing trend in data collection and data processing has lead to the aggressivedevelopment of public clouds which store; process; and query data collections fromcompletely heterogenous sources; with different requirements not only in performance; butalso in confidentiality and security. The performance considerations have been leading tobigger public clouds where economy at scale allows for more efficient solutions. Today datamanagement is being commoditized and offered as database-as-a-service over private andpublic cloud infrastructure. At the same time the increasing number of data breaches overthe past 15 years have raised the awareness of privacy and security. For a company; its dataneed to be private in order not to lose its business advantage; for a government it can bestrategic economical and national security reasons; and for a scientist it is to protect work …,CIDR,2017,*
Querying Persistent Graphs using Solid State Storage,Manos Athanassoulis; Bishwaranjan Bhattacharjee; Mustafa Canim; Kenneth A. Ross,ABSTRACT Solid State Drives (SSDs) are an important component of secondary storagesystems. While Hard Disk Drives (HDDs) are cheaper per gigabyte; SSDs are cheaper perrandom I/O per second. A variety of of solid-state technologies are being developed withNAND flash being the most mature; and Phase Change Memory (PCM) beginning to enterthe marketplace. Compared with flash; PCM has finer-grained addressability and higherwrite endurance. PCM is also expected to offer lower read and write response times. In thiswork we study the use of solid-state storage in latencybound applications; a type of workloadthat can benefit from the characteristics of flash and PCM technologies. We identify graphprocessing and Resource Description Framework (RDF) query processing as candidateapplications. Using an early PCM prototype device; we demonstrate the benefits of PCM …,4th Annual Non-Volatile Memories Workshop 2013,2013,*
Improving OLTP concurrency through Early Lock Release,Manos Athanassoulis; Ryan Johnson; Anastasia Ailamaki; Radu Stoica,ABSTRACT Since the beginning of the multi-core era; database systems research hasrestarted focusing on increasing concurrency. Even though database systems have beenable to accommodate concurrent requests; the exploding number of available cores per chiphas surfaced new difficulties. More and more transactions can be served in parallel (sincemore threads can run simultaneously) and; thus; concurrency in a database system is moreimportant than ever in order to exploit the available resources. In this paper; we evaluateEarly Lock Release (ELR); a technique that allows early release of locks to improveconcurrency level and overall throughput in OLTP. This technique has been proven to leadto a database system that can produce correct and recoverable histories but it has neverbeen implemented in a full scale DBMS. A new action is introduced which decouples the …,*,2009,*
