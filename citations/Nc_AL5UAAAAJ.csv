The R*-tree: an efficient and robust access method for points and rectangles,Norbert Beckmann; Hans-Peter Kriegel; Ralf Schneider; Bernhard Seeger,Abstract The R-tree; one of the most popular access methods for rectangles; is based on theheuristic optimization of the area of the enclosing rectangle in each inner node. By runningnumerous experiments in a standardized testbed under highly varying data; queries andoperations; we were able to design the R*-tree which incorporates a combined optimizationof area; margin and overlap of each enclosing rectangle in the directory. Using ourstandardized testbed in an exhaustive performance comparison; it turned out that the R*-treeclearly outperforms the existing R-tree variants. Guttman's linear and quadratic R-tree andGreene's variant of the R-tree. This superiority of the R*-tree holds for different types ofqueries and operations; such as map overlay; for both rectangles and multidimensionalpoints in all experiments. From a practical point of view the R*-tree is very attractive …,Acm Sigmod Record,1990,5817
Progressive skyline computation in database systems,Dimitris Papadias; Yufei Tao; Greg Fu; Bernhard Seeger,Abstract The skyline of a d-dimensional dataset contains the points that are not dominatedby any other point on all dimensions. Skyline computation has recently receivedconsiderable attention in the database community; especially for progressive methods thatcan quickly return the initial results without reading the entire database. All the existingalgorithms; however; have some serious shortcomings which limit their applicability inpractice. In this article we develop branch-and-bound skyline (BBS); an algorithm based onnearest-neighbor search; which is I/O optimal; that is; it performs a single access only tothose nodes that may contain skyline points. BBS is simple to implement and supports alltypes of progressive processing (eg; user preferences; arbitrary dimensionality; etc).Furthermore; we propose several interesting variations of skyline computation; and show …,ACM Transactions on Database Systems (TODS),2005,865
An optimal and progressive algorithm for skyline queries,Dimitris Papadias; Yufei Tao; Greg Fu; Bernhard Seeger,Abstract The skyline of a set of d-dimensional points contains the points that are notdominated by any other point on all dimensions. Skyline computation has recently receivedconsiderable attention in the database community; especially for progressive (or online)algorithms that can quickly return the first skyline points without having to read the entiredata file. Currently; the most efficient algorithm is NN (< u> n</u> earest< u> n</u>eighbors); which applies the divide-and-conquer framework on datasets indexed by R-trees.Although NN has some desirable features (such as high speed for returning the initialskyline points; applicability to arbitrary data distributions and dimensions); it also presentsseveral inherent disadvantages (need for duplicate elimination if d> 2; multiple accesses ofthe same node; large space overhead). In this paper we develop BBS (< u> b</u> ranch …,Proceedings of the 2003 ACM SIGMOD international conference on Management of data,2003,858
Efficient processing of spatial joins using R-trees,Thomas Brinkhoff; Hans-Peter Kriegel; Bernhard Seeger,Abstract Spatial joins are one of the most important operations for combining spatial objectsof several relations. The efficient processing of a spatial join is extremely important since itsexecution time is superlinear in the number of spatial objects of the participating relations;and this number of objects may be very high. In this paper; we present a first detailed studyof spatial join processing using R-trees; particularly R*-trees. R-trees are very suitable forsupporting spatial queries and the R*-tree is one of the most efficient members of the R-treefamily. Starting from a straightforward approach; we present several techniques forimproving its execution time with respect to both; CPU-and I/O-time. Eventually; we end upwith an algorithm whose total execution time is improved over the first approach by an orderof magnitude. Using a buffer of reasonable size; I/O-time is almost optimal; ie it almost …,ACM SIGMOD Record,1993,852
An asymptotically optimal multiversion B-tree,Bruno Becker; Stephan Gschwind; Thomas Ohler; Bernhard Seeger; Peter Widmayer,Abstract In a variety of applications; we need to keep track of the development of a data setover time. For maintaining and querying these multiversion data efficiently; external storagestructures are an absolute necessity. We propose a multiversion B-tree that supportsinsertions and deletions of data items at the current version and range queries and exactmatch queries for any version; current or past. Our multiversion B-tree is asymptoticallyoptimal in the sense that the time and space bounds are asymptotically the same as those ofthe (single-version) B-tree in the worst case. The technique we present for transforming a(single-version) B-tree into a multiversion B-tree is quite general: it applies to a number ofhierarchical external access structures with certain properties directly; and it can be modifiedfor others.,The VLDB Journal—The International Journal on Very Large Data Bases,1996,423
Multi-step processing of spatial joins,Thomas Brinkhoff; Hans-Peter Kriegel; Ralf Schneider; Bernhard Seeger,Abstract Spatial joins are one of the most important operations for combining spatial objectsof several relations. In this paper; spatial join processing is studied in detail for extendedspatial objects in two-dimensional data space. We present an approach for spatial joinprocessing that is based on three steps. First; a spatial join is performed on the minimumbounding rectangles of the objects returning a set of candidates. Various approaches foraccelerating this step of join processing have been examined at the last year's conference[BKS 93a]. In this paper; we focus on the problem how to compute the answers from the setof candidate which is handled by the following two steps. First of all; sophisticatedapproximations are used to identify answers as well as to filter out false hits from the set ofcandidates. For this purpose; we investigate various types of conservative and …,ACM SIGMOD Record,1994,344
Slim-trees: High performance metric trees minimizing overlap between nodes,Caetano Traina; Agma Traina; Bernhard Seeger; Christos Faloutsos,Abstract In this paper we present the Slim-tree; a dynamic tree for organizing metric datasetsin pages of fixed size. The Slim-tree uses the “fat-factor” which provides a simple way toquantify the degree of overlap between the nodes in a metric tree. It is well-known that thedegree of overlap directly affects the query performance of index structures. There are manysuggestions to reduce overlap in multidimensional index structures; but the Slim-tree is thefirst metric structure explicitly designed to reduce the degree of overlap. Moreover; wepresent new algorithms for inserting objects and splitting nodes. The new insertion algorithmleads to a tree with high storage utilization and improved query performance; whereas thenew split algorithm runs considerably faster than previous ones; generally without sacrificingsearch performance. Results obtained from experiments with real-world data sets show …,International Conference on Extending Database Technology,2000,339
Efficient computation of reverse skyline queries,Evangelos Dellis; Bernhard Seeger,Abstract In this paper; for the first time; we introduce the concept of Reverse Skyline Queries.At first; we consider for a multidimensional data set P the problem of dynamic skyline queriesaccording to a query point q. This kind of dynamic skyline corresponds to the skyline of atransformed data space where point q becomes the origin and all points of P arerepresented by their distance vector to q. The reverse skyline query returns the objectswhose dynamic skyline contains the query object q. In order to compute the reverse skylineof an arbitrary query point; we first propose a Branch and Bound algorithm (called BBRS);which is an improved customization of the original BBS algorithm. Furthermore; we identify asuper set of the reverse skyline that is used to bound the search space while computing thereverse skyline. To further reduce the computational cost of determining if a point belongs …,Proceedings of the 33rd international conference on Very large data bases,2007,278
The Buddy Effect: An efficient and robust access method for spatial data base systems,Bernhard Seeger; Hans-Peter Kriegel,In this paper; we propose a new multidimensional access method; called the buddy-tree; tosupport point as well as spatial data in a dynamic environment. The buddy-tree can be seenas a compromise of the R-tree and the grid file; but it is fundamentally different from each ofthem. Because grid files loose performance for highly correlated data; the buddy-tree isdesigned to organize such data very efficiently; partitioning only such parts of the data spacewhich contain data and not partitioning empty data space. The directory consists of a veryflexible partitioning and reorganization scheme based on a generalization of the buddy-system. As for B-trees; the buddy-tree fulfills the property that insertions and deletions arerestricted to exactly one path of the directory. Additional important properties which are notfulfilled in this combination by any other multidimensional tree-based access method are …,*,1990,271
Fast indexing and visualization of metric data sets using slim-trees,Caetano Traina; Agma Traina; Christos Faloutsos; Bernhard Seeger,Many recent database applications need to deal with similarity queries. For suchapplications; it is important to measure the similarity between two objects using the distancebetween them. Focusing on this problem; this paper proposes the slim-tree; a new dynamictree for organizing metric data sets in pages of fixed size. The slim-tree uses the triangleinequality to prune the distance calculations that are needed to answer similarity queriesover objects in metric spaces. The proposed insertion algorithm uses new policies to selectthe nodes where incoming objects are stored. When a node overflows; the slim-tree uses aminimal spanning tree to help with the splitting. The new insertion algorithm leads to a treewith high storage utilization and improved query performance. The slim-tree is a metricaccess method that tackles the problem of overlaps between nodes in metric spaces and …,IEEE Transactions on Knowledge and Data Engineering,2002,230
A generic approach to bulk loading multidimensional index structures,Jochen Van den Bercken; Bernhard Seeger; Peter Widmayer,Abstract: Recently there has been an increasing interest in supporting bulk operations onmultidimensional index structures. Bulk loading refers to the process of creating an initialindex structure for a presumably very large data set. In this paper; we present a genericalgorithm for bulk loading which is applicable to a broad class of index structures. Ourapproach differs completely from previous ones for the following reasons. First; sortingmultidimensional data according to a predefined global ordering is completely avoided.Instead; our approach is based on the standard routines for splitting and merging pageswhich are already fully implemented in the corresponding index structure. Second; incontrast to inserting records one by one; our approach is based on the idea of insertingmultiple records simultaneously. As an example we demonstrate in this paper how to …,VLDB,1997,170
Parallel processing of spatial joins using R-trees,Thomas Brinkhoff; H-P Kriegel; Bernhard Seeger,We show that spatial joins are very suitable to be processed on a parallel hardware platform.The parallel system is equipped with a so called shared virtual memory which is well suitedfor the design and implementation of parallel spatial join algorithms. We start with analgorithm that consists of three phases: task creation; task assignment and parallel taskexecution. In order to reduce CPU and I/O cost; the three phases are processed in a fashionthat preserves spatial locality. Dynamic load balancing is achieved by splitting tasks intosmaller ones and reassigning some of the smaller tasks to idle processors. In anexperimental performance comparison; we identify the advantages and disadvantages ofseveral variants of our algorithm. The most efficient one shows an almost optimal speed upunder the assumption that the number of disks is sufficiently large.,Data Engineering; 1996. Proceedings of the Twelfth International Conference on,1996,165
Techniques for design and implementation of efficient spatial access methods,H Kriegel; B Seeger,Abstract In order to handle spatial data efficiently; as required in computer aided design andgeo-data applications; a database management system (DBMS) needs an access methodthat will help it retrieve data items quickly according to their spatial location. In this paper wepresent a classification of existing spatial access methods and show that they use one of thefollowing three techniques: clipping; overlapping regions; and transformation. From apractical point of view we provide a tool box supporting simple design of a spatial accessmethod for a given point access method using one of the above techniques. We analyze thetechnique of transformation in more detail and show that our new concept of asymmetricpartitioning is more retrieval efficient than the traditional symmetric approach. Furthermorewe suggest a hybrid method combining the techniques of overlapping regions and …,Proceedings of the 14th VLDB Conference,1988,160
Semantics and implementation of continuous sliding window queries over data streams,Jürgen Krämer; Bernhard Seeger,Abstract In recent years the processing of continuous queries over potentially infinite datastreams has attracted a lot of research attention. We observed that the majority of workaddresses individual stream operations and system-related issues rather than thedevelopment of a general-purpose basis for stream processing systems. Furthermore;example continuous queries are often formulated in some declarative query languagewithout specifying the underlying semantics precisely enough. To overcome thesedeficiencies; this article presents a consistent and powerful operator algebra for datastreams which ensures that continuous queries have well-defined; deterministic results. Inanalogy to traditional database systems; we distinguish between a logical and a physicaloperator algebra. While the logical algebra specifies the semantics of the individual …,ACM Transactions on Database Systems (TODS),2009,155
PIPES: a public infrastructure for processing and exploring streams,Jürgen Krämer; Bernhard Seeger,Abstract PIPES is a flexible and extensible infrastructure providing fundamental buildingblocks to implement a data stream management system (DSMS). It is seamlessly integratedinto the Java library XXL [1; 2; 3] for advanced query processing and extends XXL's scopetowards continuous data-driven query processing over autonomous data sources.,Proceedings of the 2004 ACM SIGMOD international conference on Management of data,2004,124
Progressive Merge Join: A Generic and Non-Blocking Sort-Based Join Algorithm** This work has been supported by grant no. SE 553/2-2 from DFG.,Jens-Peter Dittrich; Bernhard Seeger; David Scot Taylor; Peter Widmayer,This chapter presents a generic technique called progressive merge join (PMJ) thateliminates the blocking behavior of sort-based join algorithms. The basic idea behind PMJ isto have the join produce results; as early as the external mergesort generates initial runs.Many state-of-the-art join techniques require the input relations to be almost fully sortedbefore the actual join processing starts. Thus; these techniques start producing first resultsonly after a considerable time has passed. This blocking behavior is a serious problemwhen consequent operators have to stop processing in order to wait for first results of thejoin. Furthermore; this behavior is not acceptable if the result of the join is visualized or/andrequires user interaction. These are typical scenarios for data mining applications. The off-time of existing techniques even increases with growing problem sizes.Progressive …,*,2002,124
Design and Implementation of a Geographic Search Engine.,Alexander Markowetz; Yen-Yu Chen; Torsten Suel; Xiaohui Long; Bernhard Seeger,ABSTRACT In this paper; we describe the design and initial implementation of a geographicsearch engine prototype for Germany; based on a large crawl of the de domain. Geographicsearch engines provide a flexible interface to the Web that allows users to constrain andorder search results in an intuitive manner; by focusing a query on a particular geographicregion. Geographic search technology has recently received significant commercial interest;but there has been only a limited amount of academic work. Our prototype performs massiveextraction of geographic features from crawled data; which are then mapped to coordinatesand aggregated across link and site structure. This assigns to each web page a set ofrelevant locations; called the geographic footprint of the page. The resulting footprint data isthen integrated into a high-performance query processor on a cluster-based architecture …,WebDB,2005,119
XXL-a library approach to supporting efficient implementations of advanced database queries,J v Bercken; Björn Blohsfeld; Jens-Peter Dittrich; Jürgen Krämer; Tobias Schäfer; Martin Schneider; Bernhard Seeger,Abstract Today's DBMS are still too inflexible to adapt fast enough to the query processingneeds of new applications [CW00]. Instead of using the cumbersome functionality of amonolithic DBMS; it is not uncommon that users implement their own functionality on top ofthe system. For such a scenario; the implementation would be substantially facilitatedthrough a powerful library. This paper introduces XXL (eXtensible and fleX-ible Library); ahigh-level; easy-to-use; platform independent Java library supporting the implementation ofnew query functionality. XXL provides framework implementations as well as toolboxeswhose applications are independent from the underlying data types and data structures. Weintroduce the most important concepts of XXL and discuss different application scenarioswhere XXL has been used recently. In particular; we show how an implementation of an …,Proc. of the Conf. on Very Large Databases (VLDB),2001,112
Performance comparison of point and spatial access methods,Hans-Peter Kriegel; Michael Schiwietz; Ralf Schneider; Bernhard Seeger,Abstract In the past few years a large number of multidimensional point access methods;also called multiattribute index structures; has been suggested; all of them claiming goodperformance. Since no performance comparison of these structures under arbitrary (stronglycorrelated nonuniform; short" ugly") data distributions and under various types of querieshas been performed; database researchers and designers were hesitant to use any of thesenew point access methods. As shown in a recent paper; such point access methods are notonly important in traditional database applications. In new applications such as CAD/CIMand geographic or environmental information systems; access methods for spatial objectsare needed. As recently shown such access methods are based on point access methods interms of functionality and performance. Our performance comparison naturally consists of …,Symposium on Large Spatial Databases,1989,108
Spatial join selectivity using power laws,Christos Faloutsos; Bernhard Seeger; Agma Traina; Caetano Traina Jr,Abstract We discovered a surprising law governing the spatial join selectivity across two setsof points. An example of such a spatial join is “find the libraries that are within 10 miles ofschools”. Our law dictates that the number of such qualifying pairs follows a power law;whose exponent we call “pair-count exponent”(PC). We show that this law also holds for self-spatial-joins (“find schools within 5 miles of other schools”) in addition to the general casethat the two point-sets are distinct. Our law holds for many real datasets; including diverseenvironments (geographic datasets; feature vectors from biology data; galaxy data fromastronomy). In addition; we introduce the concept of the Box-Occupancy-Product-Sum(BOPS) plot; and we show that it can compute the pair-count exponent in a timely manner;reducing the run time by orders of magnitude; from quadratic to linear. Due to the pair …,ACM SIGMOD Record,2000,105
Data redundancy and duplicate detection in spatial join processing,J-P Dittrich; Bernhard Seeger,The partition-based spatial-merge join (PBSM) of JM Patel and DJ DeWitt (1996) and thesize separation spatial join (S/sup 3/J) of N. Koudas and KC Sevcik (1997) are considered tobe among the most efficient methods for processing spatial (intersection) joins on two ormore spatial relations. Neither method assumes the presence of pre-existing spatial indiceson the relations. In this paper; we propose several improvements to these join algorithms. Inparticular; we deal with the impact of data redundancy and duplicate detection on theperformance of these methods. For PBSM; we present a simple and inexpensive onlinemethod to detect duplicates in the response set. There is no longer any need to eliminateduplicates in a final sorting phase; as was originally suggested. We also investigate theimpact of different internal algorithms on the total run-time of PBSM. For S/sup 3/J; we …,Data Engineering; 2000. Proceedings. 16th International Conference on,2000,100
Multi-disk B-trees,Bernhard Seeger; Per-Åke Larson,Dept. of Computer Science; University of Waterloo Waterloo; Ontario; Canada; N2L 3G1 weconsider how to exploit multiple disks to improve the performance of B-tree structured files.Attention is paid both to the response time of individual operations and to the throughput ofthe system in a multi-user environment. We begin with a survey of three different approachesto designing multi-disk B-trees: distributing records among disks; using large multi-diskpages; and distributing pages among disks. For each approach; several alternatives arediscussed and their main advantages and disadvantages are identified. We then propose anew scheme; based on page distribution; that is intended to provide a better local balancingof the request load than previous schemes. Preliminary performance results confirm that thisirrproves both response time and throughput.,ACM SIGMOD Record,1991,95
Efficient computation of temporal aggregates with range predicates,Donhui Zhang; Alexander Markowetz; Vassilis Tsotras; Dimitrios Gunopulos; Bernhard Seeger,Abstract A temporal aggregation query is an important but costly operation for applicationsthat maintain time-evolving data (data warehouses; temporal databases; etc.). Due to thelarge volume of such data; performance improvements for temporal aggregation queries arecritical. In this paper we examine techniques to compute temporal aggregates that includekey-range predicates (range temporal aggregates). In particular we concentrate on SUM;COUNT and AVG aggregates. This problem is novel; to handle arbitrary key ranges;previous methods would need to keep a separate index for every possible key range. Wepropose an approach based on a new index structure called the Multiversion SB-Tree;which incorporates features from both the SB-Tree and the Multiversion B-Tree; to handlearbitrary key-range temporal SUM; COUNT and AVG queries. We analyze the …,Proceedings of the twentieth ACM SIGMOD-SIGACT-SIGART symposium on Principles of database systems,2001,90
A temporal foundation for continuous queries over data streams,Jürgen Krämer; Bernhard Seeger,ABSTRACT Despite the surge of research in continuous stream processing; there is still asemantical gap. In many cases; continuous queries are formulated in an enriched SQL-likequery language without specifying the semantics of such a query precisely enough. Toovercome this problem; we present a sound and well defined temporal operator algebraover data streams ensuring deterministic query results of continuous queries. In analogy totraditional database systems; we distinguish between a logical and physical operatoralgebra. While our logical operator algebra specifies the semantics of each operation in adescriptive way over temporal multisets; the physical operator algebra provides adequateimplementations in form of stream-to-stream operators. We show that query plans built witheither the logical or the physical algebra produce snapshot-equivalent results. Moreover …,*,2004,84
Multidimensional order preserving linear hashing with partial expansions,Hans-Peter Kriegel; Bernhard Seeger,Abstract We present a new multidimensional dynamic hashing scheme without directoryintended for files which grow and shrink dynamically. For previous schemes; the retrievalperformance either suffers from a superlinearly growing directory or from an unevendistribution of the records over the pages of a file even for uniform record distribution. Ourscheme is a multidimensional order preserving extension of (one-dimensional) linearhashing with partial expansions and thus overcomes these disadvantages. For uniformdistribution our scheme performs better than its competitors which is underligned byexperimental runs with an implementation of our scheme. In the last section we give a briefoutline of the quantile method which guarantees that our scheme performs for a non-uniformdistribution practically as well as for a uniform distribution. In addition to its excellent …,International Conference on Database Theory,1986,83
An evaluation of generic bulk loading techniques,J Bercken; Bernhard Seeger,Abstract Bulk loading refers to the process of creating an index from scratch for a given dataset. This problem is well understood for B-trees; but so far; non-traditional index structuresreceived modest attention. We are particularly interested in fast generic bulk loadingtechniques whose implementations only employ a small interface that is satisfied by a broadclass of index structures. Generic techniques are very attractive to extensible databasesystems since different user-implemented index structures implementing that small interfacecan be bulk-loaded without any modification of the generic code. The main contribution ofthe paper is the proposal of two new generic and conceptually simple bulk loadingalgorithms. These algorithms recursively partition the input by using a main-memory index ofthe same type as the target index to be build. In contrast to previous generic bulk loading …,Proc. of VLDB,2001,81
Plop-hashing: A grid file without directory,H-P Kriegel; Bernhard Seeger,The authors consider the case of nonuniform weakly correlated or independentmultidimensional record distributions. After demonstrating the advantages ofmultidimensional hashing schemes without directory; they suggest using piecewise linearexpansions to distribute the load more evenly over the pages of the file. The resultingpiecewise linear order preserving hashing scheme (PLOP-hashing) is then compared to thetwo-level grid file; which turned out to be the most popular scheme in practical applications.,Data Engineering; 1988. Proceedings. Fourth International Conference on,1988,78
Temporal and spatio-temporal aggregations over data streams using multiple time granularities,Donghui Zhang; Dimitrios Gunopulos; Vassilis J Tsotras; Bernhard Seeger,Abstract Temporal and spatio-temporal aggregations are important but costly operations forapplications that maintain time-evolving data (data warehouses; temporal databases; etc.).In this paper; we examine the problem of computing such aggregates over data streams.The aggregates are maintained using multiple levels of temporal granularities: older data isaggregated using coarser granularities while more recent data is aggregated with finerdetail. We present specialized indexing schemes for dynamically and progressivelymaintaining temporal and spatio-temporal aggregates. Moreover; these schemes can beparameterized. The levels of granularity as well as their corresponding index sizes (orvalidity lengths) can be dynamically adjusted. This provides a useful trade-off betweenaggregation detail and storage space. Analytical and experimental results show the …,Information Systems,2003,68
A comparison of selectivity estimators for range queries on metric attributes,Björn Blohsfeld; Dieter Korus; Bernhard Seeger,Abstract In this paper; we present a comparison of nonparametric estimation methods forcomputing approximations of the selectivities of queries; in particular range queries. Incontrast to previous studies; the focus of our comparison is on metric attributes with largedomains which occur for example in spatial and temporal databases. We also assume thatonly small sample sets of the required relations are available for estimating the selectivity. Inaddition to the popular histogram estimators; our comparison includes so-called kernelestimation methods. Although these methods have been proven to be among the mostaccurate estimators known in statistics; they have not been considered for selectivityestimation of database queries; so far. We first show how to generate kernel estimators thatdeliver accurate approximate selectivities of queries. Thereafter; we reveal that two …,ACM SIGMOD Record,1999,68
Temporal aggregation over data streams using multiple granularities,Donghui Zhang; Dimitrios Gunopulos; Vassilis J Tsotras; Bernhard Seeger,Abstract Temporal aggregation is an important but costly operation for applications thatmaintain time-evolving data (data warehouses; temporal databases; etc.). In this paper weexamine the problem of computing temporal aggregates over data streams. Suchaggregates are maintained using multiple levels of temporal granularities: older data isaggregated using coarser granularities while more recent data is aggregated with finerdetail. We present specialized indexing schemes for dynamically and progressivelymaintaining temporal aggregates. Moreover; these schemes can be parameterized. Thelevels of granularity as well as their corresponding index sizes (or validity lengths) can bedynamically adjusted. This provides a useful trade-o. between aggregation detail andstorage space. Analytical and experimental results show the efficiency of the proposed …,International Conference on Extending Database Technology,2002,67
GESS: a scalable similarity-join algorithm for mining large data sets in high dimensional spaces,Jens-Peter Dittrich; Bernhard Seeger,Abstract The similarity join is an important operation for mining high-dimensional featurespaces. Given two data sets; the similarity join computes all tuples (x; y) that are within adistance &egr;. One of the most efficient algorithms for processing similarity-joins is theMultidimensional-Spatial Join (MSJ) by Koudas and Sevcik. In our previous work---pursuedfor the two-dimensional case---we found however that MSJ has several performanceshortcomings in terms of CPU and I/O cost as well as memory-requirements. Therefore; MSJis not generally applicable to high-dimensional data. In this paper; we propose a newalgorithm named Generic External Space Sweep (GESS). GESS introduces a modest rate ofdata replication to reduce the number of expensive distance computations. We present anew cost-model for replication; an I/O model; and an inexpensive method for duplicate …,Proceedings of the seventh ACM SIGKDD international conference on Knowledge discovery and data mining,2001,66
The user's view on biodiversity data sharing—Investigating facts of acceptance and requirements to realize a sustainable use of research data—,Neela Enke; Anne Thessen; Kerstin Bach; Jörg Bendix; Bernhard Seeger; Birgit Gemeinholzer,Abstract Data sharing has become an important issue in modern biodiversity research toaddress large scale questions. Despite the steadily growing scientific demand; data are noteasily accessed. Why is this the case? This study explores the reasons for the reluctance toshare data on the one hand and the motivations for sharing on the other by summarisingresults from> 60 interviews and> 700 survey participants within the biodiversity sciencecommunity. As result; there is a clear commitment to share biodiversity data; but also areluctance to actually do so due to a mixture of social and technical impediments; such asloss of control over data and lack of professional reward for sharing. This exploratory studysummarises the formal and technical requirements for data sharing and reuse; stated byvoluntarily participating scientists worldwide. To ensure sustainable data use; user …,Ecological Informatics,2012,65
On optimal multiversion access structures,Bruno Becker; Stephan Gschwind; Thomas Ohler; Bernhard Seeger; Peter Widmayer,Abstract We propose an asymptotically optimal multiversion B-tree. In our setting; insertionsand deletions of data items are allowed only for the present version; whereas range queriesand exact match queries are allowed for any version; present or past. The technique wepresent for transforming a (usual single version) B-tree into a multiversion B-tree is moregeneral: it applies to a number of spatial and non-spatial hierarchical external accessstructures with certain properties directly; and it can be modified for others. For the B-treeand several other hierarchical external access structures; multiversion capabilities come atno extra cost; neither for storage space nor for runtime; asymptotically in the worst case. Theanalysis of the behavior of the multiversion B-tree shows that the constant loss of efficiencyis low enough to make our suggestion not only a theoretical; but also a practical one.,International Symposium on Spatial Databases,1993,65
Efficient temporal join processing using indices,Donghui Zhang; Vassilis J Tsotras; Bernhard Seeger,We examine the problem of processing temporal joins in the presence of indexing schemes.Previous work on temporal joins has concentrated on non-indexed relations which were fullyscanned. Given the large data volumes created by the ever increasing time dimension;sequential scanning is prohibitive. This is especially true when the temporal join involvesonly parts of the joining relations (eg; a given time interval instead of the whole timeline).Utilizing an index becomes then beneficial as it directs the join to the data of interest. Weconsider temporal join algorithms for three representative indexing schemes; namely a B+-tree; an R*-tree and a temporal index; the Multiversion B+-tree (MVBT). Both the B+-tree andR*-tree result in simple but not efficient join algorithms because neither index achieves goodtemporal data clustering. Better clustering is maintained by the MVBT through record …,Data Engineering; 2002. Proceedings. 18th International Conference on,2002,63
Reading a set of disk pages,Bernhard Seeger; Per-Ake Larson; Ron McFadyen,Abstract The problem studied in this paper is as follows. Consider a file stored in contiguousspace on disk. Given a list of pages to be retrieved from the file; what is the fastest way ofretrieving them? It is assumed that adjacent pages on disk can be read with a single readrequest. The straightforward solution is to read the desired pages one by one. However; iftwo or more pages are located close to each other it may be faster to read them with a singleread request; possibly even reading some intervening\empty" pages. It is shown that findingan optimal read schedule is equivalent to finding the shortest path in a certain graph. A verysimple approximate algorithm is then introduced and (experimentally) shown to produceschedules that are close to optimal. The expected cost of schedules produced by thisalgorithm is derived. It is found that significant speed-up can be achieved by the simple …,VLDB,1993,62
A revised r*-tree in comparison with related index structures,Norbert Beckmann; Bernhard Seeger,Abstract In this paper we present an improved redesign of the R*-tree that is entirely suitablefor running within a DBMS. Most importantly; an insertion is guaranteed to be restricted to asingle path because re-insertion could be abandoned. We re-engineered both; subtreechoice and split algorithm; to be more robust against specific data distributions and insertionorders; as well as peculiarities often found in real multidimensional data sets. This comesalong with a substantial reduction in CPU-time. Our experimental setup covers a wide rangeof different artificial and real data sets. The experimental comparison shows that the searchperformance of our revised R*-tree is superior to that of its three most important competitors.In comparison to its predecessor; the original R*-tree; the creation of a tree is substantiallyfaster; while the I/O cost required for processing queries is improved by more than 30 …,Proceedings of the 2009 ACM SIGMOD International Conference on Management of data,2009,54
Hybmig: A hybrid approach to dynamic plan migration for continuous queries,Yin Yang; Jurgen Kramer; Dimitris Papadias; Bernhard Seeger,In data stream environments; the initial plan of a long-running query may gradually becomeinefficient due to changes of the data characteristics. In this case; the query optimizergenerates a more efficient plan based on the current statistics. The online transition from theold to the new plan is called dynamic plan migration. In addition to correctness; an effectivetechnique for dynamic plan migration should achieve the following objectives: 1) minimizethe memory and CPU overhead of the migration; 2) reduce the duration of the transition; and3) maintain a steady output rate. The only known solutions for this problem are the movingstates (MS) and parallel track (PT) strategies; which have some serious shortcomingsrelated to the above objectives. Motivated by these shortcomings; we first propose HybMig;which combines the merits of MS and PT and outperforms both in every aspect. As a …,IEEE Transactions on Knowledge and Data Engineering,2007,44
Constrained subspace skyline computation,Evangelos Dellis; Akrivi Vlachou; Ilya Vladimirskiy; Bernhard Seeger; Yannis Theodoridis,Abstract In this paper we introduce the problem of Constrained Subspace Skyline Queries.This class of queries can be thought of as a generalization of subspace skyline queriesusing range constraints. Although both constrained skyline queries and subspace skylinequeries have been addressed previously; the implications of constrained subspace skylinequeries has not been examined so far. Constrained skyline queries are usually moreexpensive than regular skylines. In case of constrained subspace skyline queries additionalperformance degradation is caused through the projection. In order to support constrainedskylines for arbitrary subspaces; we present approaches exploiting multiple low-dimensionalindexes instead of relying on a single high-dimensional index. Effective pruning strategiesare applied to discard points from dominated regions. An important ingredient of our …,Proceedings of the 15th ACM international conference on Information and knowledge management,2006,44
Query processing techniques for multiversion access methods,Jochen Van den Bercken; Bernhard Seeger,Abstract Multiversion access methods have been emerged in the literature primarily tosupport queries on a transaction-time database where records are never physically deleted.For a popular class of efficient methods (including the multiversion B-tree); data records andindex entries are occasionally duplicated to separate data according to time. In this paper;we present techniques for improving query processing in multiversion access methods. Inparticular; we address the problem of avoiding duplicates in the response sets. We firstdiscuss traditional approaches that eliminate duplicates using hashing and sorting. Next; wepropose two new algorithms for avoiding duplicates without using additional data structures.The one performs queries in a depth-first order starting from a root; whereas the otherexploits links between data pages. These methods are discussed in full details and their …,*,1996,38
A cost-based approach to adaptive resource management in data stream systems,Michael Cammert; Jurgen Kramer; Bernhard Seeger; Sonny Vaupel,Data stream management systems need to adaptively control their resources; since streamcharacteristics and query workload may vary over time. In this paper; we investigate anapproach to adaptive resource management for continuous sliding-window queries thatadjusts window sizes and time granularities to keep resource usage within bounds. Thesetwo novel techniques differ from standard load shedding approaches based on sampling; asthey ensure exact query answers for given user-defined quality of service specifications;even under query reoptimization. In order to quantify the effects of both techniques on thevarious operations in a query plan; we develop an appropriate cost model for estimatingoperator resource allocation in terms of memory usage and processing costs. A thoroughexperimental study not only validates the accuracy of our cost model but also …,IEEE Transactions on Knowledge and Data Engineering,2008,35
Towards Kernel Density Estimation over Streaming Data.,Christoph Heinz; Bernhard Seeger,Abstract A variety of real-world applications heavily relies on the analysis of transient datastreams. Due to the rigid processing requirements of data streams; common analysistechniques as known from data mining are not applicable. A fundamental building block ofmany data mining and analysis approaches is density estimation. It provides a well-definedestimation of a continuous data distribution; a fact which makes its adaptation to datastreams desirable. A convenient method for density estimation utilizes kernels. However; itscomputational complexity collides with the processing requirements of data streams. In thiswork; we present a new approach to this problem that combines linear processing cost witha constant amount of allocated memory. We even support a dynamic memory adaptation tochanging system resources. Our kernel density estimators over streaming data are …,COMAD,2006,32
Multidimensional quantile hashing is very efficient for nonuniform distributions,Hans-Peter Kriegel; Bernhard Seeger,Abstract Previous multidimensional hashing schemes without directory which generalize theconcept of Litwin's linear hashing partition the data space into equidistant cells using adynamic orthogonal grid. Thus the performance of these schemes degenerates in case ofnonuniform record distributions. We propose a new scheme without directory; calledmultidimensional quantile hashing; which avoids this important drawback. Quantile hashingexhibits for independent nonuniform record distributions practically the same performanceas for uniform distributions. The performance gain of quantile hashing in comparison withother schemes without directory is demonstrated by experiments.,Information Sciences,1989,31
Cluster kernels: Resource-aware kernel density estimators over streaming data,Christoph Heinz; Bernhard Seeger,A variety of real-world applications heavily relies on an adequate analysis of transient datastreams. Due to the rigid processing requirements of data streams; common analysistechniques as known from data mining are not directly applicable. A fundamental buildingblock of many data mining and analysis approaches is density estimation. It provides a well-defined estimation of a continuous data distribution; a fact; which makes its adaptation todata streams desirable. A convenient method for density estimation utilizes kernels. Thecomputational complexity of kernel density estimation; however; renders its application todata streams impossible. In this paper; we tackle this problem and propose our ClusterKernel approach which provides continuously computed kernel density estimators overstreaming data. Not only do Cluster Kernels meet the rigid processing requirements of …,IEEE Transactions on Knowledge and Data Engineering,2008,29
Stream processing in production-to-business software,Michael Cammert; Christoph Heinz; Jurgen Kramer; Tobias Riemenschneider; Maxim Schwarzkopf; Bernhard Seeger; Alexander Zeiss,In order to support continuous queries over data streams; a plethora of suitable techniquesas well as prototypes have been developed and evaluated in recent years. In particular; it isof utmost importance to confirm their necessity and feasibility in real-world applications. Forthat reason; we have successfully coupled our infrastructure for data stream processing(PIPES) with an industrial Production-to-Business software (i-Plant) dedicated to highlyautomated manufacturing processes.,Data Engineering; 2006. ICDE'06. Proceedings of the 22nd International Conference on,2006,29
On computing temporal aggregates with range predicates,Donghui Zhang; Alexander Markowetz; Vassilis J Tsotras; Dimitrios Gunopulos; Bernhard Seeger,Abstract Computing temporal aggregates is an important but costly operation forapplications that maintain time-evolving data (data warehouses; temporal databases; etc.)Due to the large volume of such data; performance improvements for temporal aggregatequeries are critical. Previous approaches have aggregate predicates that involve only thetime dimension. In this article we examine techniques to compute temporal aggregates thatinclude key-range predicates as well (range-temporal aggregates). In particular weconcentrate on the SUM aggregate; while COUNT is a special case. To handle arbitrary keyranges; previous methods would need to keep a separate index for every possible keyrange. We propose an approach based on a new index structure called the Multiversion SB-Tree; which incorporates features from both the SB-Tree and the Multiversion B+--tree; to …,ACM Transactions on Database Systems (TODS),2008,27
An approach to adaptive memory management in data stream systems,Michael Cammert; Jurgen Kramer; Bernhard Seeger; Sonny Vaupel,Adaptivity is a challenging open issue in data stream management. In this paper; we tacklethe problem of memory adaptivity inside a system executing temporal sliding windowqueries over continuous data streams. Two different techniques to control the memory usageat runtime are proposed which refer to changes in window sizes and time granularities. Bothtechniques differ from standard load shedding approaches based on sampling as theyensure precise query answers for user-defined Quality of Service (QoS) specifications; evenunder query re-optimization.,Data Engineering; 2006. ICDE'06. Proceedings of the 22nd International Conference on,2006,27
Geographic information retrieval,Alexander Markowetz; Thomas Brinkhoff; Bernhard Seeger,ABSTRACT: The World Wide Web is the largest collection of geospatial data; a resource thatgoes almost unexploited. The access to its geographic data is complicated and takesconsiderable efforts. So far; little work has been done in this area and the general directionof research and development has been uncertain. In this paper we address essentialquestions in this field: First; we outline a three-stage architecture for an efficient and effectivemapping of Internet resources to geographic locations. Second; we present geospatialsearch engines; one of the two major applications. Such search engines differ fundamentallyfrom their traditional counterparts; particularly regarding selecting and ranking searchresults. Third; we propose geospatial analysis of web crawls; the other major area ofapplication. Such analyses allow new types of queries as well as reducing the cost in …,Next Generation Geospatial Information: From Digital Image Analysis to Spatiotemporal Databases,2005,27
Exploiting the internet as a geospatial database,Alexander Markowetz; Thomas Brinkhoff; Bernhard Seeger,Abstract The World Wide Web is the largest collection of geospatial data; a resource thatgoes almost unexploited. For using the Internet as a reliable and fast geospatial database;considerable efforts are necessary. However; little work has been done in this area so farand the general direction of research and development has been uncertain. In this paper;essential questions in this field are addressed: First; we outline a three-stage architecture foran efficient and effective mapping of Internet resources to geographic locations. Geospatialsearch engines are one important application of this mapping. Such search enginesfundamentally differ from their traditional counterparts; particularly in respect to selecting andranking search results. Finally; we propose geospatial analyses using localized web crawls.Such analyses allow the support of new types of queries as well as the reduction of cost …,International Workshop on Next Generation Geospatial Information,2003,26
A comparative evaluation of technical solutions for long-term data repositories in integrative biodiversity research,Kerstin Bach; Daniel Schäfer; Neela Enke; Bernhard Seeger; Birgit Gemeinholzer; Jörg Bendix,Abstract The current study investigates existing infrastructure; its technical solutions andimplemented standards for data repositories related to integrative biodiversity research. Thestorage and reuse of complex biodiversity data in central databases are becomingincreasingly important; particularly in attempts to cope with the impacts of environmentalchange on biodiversity and ecosystems. From the data side; the main challenge ofbiodiversity repositories is to deal with the highly interdisciplinary and heterogeneouscharacter of standardized and unstandardized data and metadata covering information fromgenes to ecosystems. Furthermore; the technical improvements in data acquisitiontechniques produce ever larger data volumes; which represent a challenge for databasestructure and proper data exchange. The current study is based on comprehensive in …,Ecological Informatics,2012,25
Dynamic metadata management for scalable stream processing systems,Michael Cammert; Jurgen Kramer; Bernhard Seeger,Adaptive query processing is of utmost importance for the scalability of data streamprocessing systems due to the long-running queries and fluctuating stream characteristics.An essential prerequisite for adaptive runtime components is the presence of suitablemetadata capturing the runtime state. As most of the metadata in such a system getsoutdated over time; appropriate update mechanisms are required. Dynamic metadatamanagement deals with the dynamic provision and continuous maintenance of metadata.This paper does not only address the issues in dynamic metadata management such asmetadata dependencies and metadata update concepts; but also presents a scalableframework to efficiently manage the diversity of dynamic metadata in todays data streamprocessing systems. The core of our field-tested metadata framework is a publish …,Data Engineering Workshop; 2007 IEEE 23rd International Conference on,2007,25
An analysis of schedules for performing multi-page requests,Bernhard Seeger,Abstract In this paper; we address the problem of efficiently reading a set of pages from a filewhich is kept on some cylinders of a magnetic disk. It is assumed that several pages can beread from disk in a single multi-page request without interruption by other requests. First; asimple algorithm is presented for computing a schedule how the required pages are readfrom disk. Then; the expected cost of the schedules is analyzed by using a pure analyticalmodel. In addition to the disk geometry; the analysis takes into account the three major costcomponents (seek time; rotational delay and transfer time) which occur when pages areretrieved from magnetic disk. The derived cost function depends on two parameters: thenumber of required pages and the degree of clustering of the underlying file. The costfunction demonstrates that significant performance improvements can be achieved by …,Information Systems,1996,25
Towards an integrated biodiversity and ecological research data management and archiving platform: the German federation for the curation of biological data (GFBio),Michael Diepenbroek; Frank Oliver Glöckner; Peter Grobe; Anton Güntsch; Robert Huber; Birgitta König-Ries; Ivaylo Kostadinov; Jens Nieschulze; Bernhard Seeger; Robert Tolksdorf; Dagmar Triebel,Biodiversity research brings together the many facets of biological environmental research.Its data management is characterized by integration and is particularly challenging due tothe large volume and tremendous heterogeneity of the data. At the same time; it isparticularly important: A lot of the data is not reproducible. Once it is gone; potentialknowledge that could have been gained from it is irrevocably lost. In this paper; we describechallenges to biodiversity data management along the data life cycle and sketch the solutionthat is currently being developed within the GFBio project; a collaborative effort of nineteenGerman research institutions ranging from museums and archives to biodiversityresearchers and computer scientists.,Informatik 2014,2014,23
Transactional support for adaptive indexing,Goetz Graefe; Felix Halim; Stratos Idreos; Harumi Kuno; Stefan Manegold; Bernhard Seeger,Abstract Adaptive indexing initializes and optimizes indexes incrementally; as a side effect ofquery processing. The goal is to achieve the benefits of indexes while hiding or minimizingthe costs of index creation. However; index-optimizing side effects seem to turn read-onlyqueries into update transactions that might; for example; create lock contention. This paperstudies concurrency control and recovery in the context of adaptive indexing. We show thatthe design and implementation of adaptive indexing rigorously separates index structuresfrom index contents; this relaxes constraints and requirements during adaptive indexingcompared to those of traditional index updates. Our design adapts to the fact that anadaptive index is refined continuously and exploits any concurrency opportunities in adynamic way. A detailed experimental analysis demonstrates that (a) adaptive indexing …,The VLDB Journal,2014,22
On producing join results early,Jens-Peter Dittrich; Bernhard Seeger; David Scot Taylor; Peter Widmayer,Abstract Support for exploratory interaction with databases in applications such as datamining requires that the first few results of an operation be available as quickly as possible.We study the algorithmic side of what can and what cannot be achieved for processing joinoperations. We develop strategies that modify the strict two-phase processing of the sort-merge paradigm; intermingling join steps with selected merge phases of the sort. Wepropose an algorithm that produces early join results for a broad class of join problems;including many not addressed well by hash-based algorithms. Our algorithm has nosignificant increase in the number of I/O operations needed to complete the join compared tostandard sort-merge algorithms.,Proceedings of the twenty-second ACM SIGMOD-SIGACT-SIGART symposium on Principles of database systems,2003,22
javax. XXL: A prototype for a Library of Query processing Algorithms,Jochen Van den Bercken; Jens-Peter Dittrich; Bernhard Seeger,Abstract Therefore; index structures can easily be used in queries. A typical example is ajoin cursor which consumes the outputs of two underlying cursors. Most of our work ishowever not dedicated to the area of relational databases; but mainly refers to spatial andtemporal data. For spatial databases; for example; we provide several implementations ofspatial join algorithms [3]. The cursor-based processing is however the major advantage ofXXL in contrast to approaches like LEDA [6] and TPIE [7]. For more information on XXL seehttp://www. mathematik. uni-marburg. de/DBS/xxl. We will demonstrate the latest version ofXXL using examples to show its core functionality. We will concentrate on three key aspectsof XXL. Usage: We show how easily state-of-the-art spatial join-algorithms can beimplemented in XXL using data from different sources. Reuse: We will demonstrate how …,ACM SIGMOD Record,2000,21
Pipes: A multi-threaded publish-subscribe architecture for continuous queries over streaming data sources,Michael Cammert; Christoph Heinz; Jürgen Krämer; Alexander Markowetz; Bernhard Seeger,Abstract In contrast to traditional query processing based on persistent data; new applicationscenarios arise that heavily rely on the continuous evaluation of data streams. Thesestreams often emerge from autonomous data sources. In this paper; we present the novelpublish-subscribe architecture PIPES (Public Infrastructure for Processing and ExploringStreams); which easily allows the composition of complex query graphs with an inherentlydynamic resource sharing; even during runtime. We sketch essential design andimplementation considerations of PIPES; which contains a generic operator framework forstreaming data. PIPES is completely implemented and integrated in XXL; a flexible andextensible Java library for data processing. In contrast to related system prototypes; whosecommunication between operators solely depends on queues; we permit direct …,Technical report; Citeseer,2003,20
Performance comparison of segment access methods implemented on top of the buddy-tree,Bernhard Seeger,Abstract Multidimensional segment access methods efficiently organize one-andmultidimensional intervals on secondary storage. In this paper; we present a detaileddiscussion and a comprehensive experimental performance comparison of these methods.Each of the segment access methods is implemented on top of an ordinary point accessmethod using the techniques clipping; overlapping regions and transformation. As the basicpoint access method we have chosen the buddy-tree. The performance of the buddy-tree isless influenced by the underlying data distribution; and therefore; the resulting segmentaccess methods can be judged with respect to their individual techniques. Besides thedifferent versions of buddy-trees; the R*-tree (an improved approach of the R-tree) and thegrid file participate in our experimental performance comparison.,Symposium on Spatial Databases,1991,20
Geometry-based similarity retrieval of rotational parts,R Schneider; H Kriegel; B Seeger; S Heep,In available retrieval and classification systems; parts are described using attributescomparable to those in traditional database systems. The authors suggest a system forretrieval of parts having geometric similarity which accesses a database system storing thegeometric data provided by the CAD system. By maintaining; storing and manipulating thecomplete geometric information of objects; the approach leads to great flexibility andefficiency for similarity and other queries.,Data and Knowledge Systems for Manufacturing and Engineering; 1989.; Second International Conference on,1989,20
Anomaly management using complex event processing: extending data base technology paper,Bastian Hoßbach; Bernhard Seeger,Abstract During the last decade; complex event processing (CEP) has emerged as atechnological foundation for many time-critical monitoring applications. CEP is powerful;effective; easy to use and low in costs at the same time. Common CEP applications are forexample stock-market analysis; detection of fraudulent credit card use; traffic monitoring andconsumption forecasting in power grids. Many application domains are still hard to target byCEP; because state of the art CEP technology is characterized by a static behavior and by asignature-based detection paradigm. In this paper; we motivate substantial improvements ofCEP technology by making the behavior of the infrastructure dynamic and by switching thedetection paradigm from signatures to anomalies. This leads to multiple changes in theinfrastructure that raise interesting and challenging research questions. The resulting …,Proceedings of the 16th International Conference on Extending Database Technology,2013,19
Sort-based query-adaptive loading of R-trees,Daniar Achakeev; Bernhard Seeger; Peter Widmayer,Abstract Bulk-loading of R-trees has been an important problem in academia and industryfor more than twenty years. Current algorithms create R-trees without any information aboutthe expected query profile. However; query profiles are extremely useful for the design ofefficient indexes. In this paper; we address this deficiency and present query-adaptivealgorithms for building R-trees optimally designed for a given query profile. Since optimal R-tree loading is NP-hard (even without tuning the structure to a query profile); we provideefficient; easy to implement heuristics. Our sort-based algorithms for query-adaptive loadingconsist of two steps: First; sorting orders are identified resulting in better R-trees than thoseobtained from standard space-filling curves. Second; for a given sorting order; we propose adynamic programming algorithm for generating R-trees in linear runtime. Our …,Proceedings of the 21st ACM international conference on Information and knowledge management,2012,18
The bulk index join: A generic approach to processing non-equijoins,Jochen Van den Bercken; Bernhard Seeger; Peter Widmayer,Presents a new algorithm called the'bulk index join'that can be applied to a broad class ofnon-equijoins. Similar to the well-known index nested-loops join algorithm; the bulk indexjoin probes the records of the outer relation against the inner relation by using a pre-existingindex structure. Like the index nested-loops join; our algorithm is generic in that any tree-based index structure supporting the join predicate can be used. Moreover; the designer of anew index structure might use our generic code to extend the functionality of the indexstructure without any additional effort. Our experience indicates that the bulk index join is ageneric algorithm that performs very fast; and that its implementation is simple enough to beof immediate practical value.,Data Engineering; 1999. Proceedings.; 15th International Conference on,1999,18
Flexible multi-threaded scheduling for continuous queries over data streams,Michael Cammert; Christoph Heinz; Jurgen Kramer; Bernhard Seeger; Sonny Vaupel; Udo Wolske,A variety of real-world applications share the property that data arrives inform of transientstreams. Data stream management systems (DSMS) provide convenient solutions to theproblem of processing continuous queries on those streams. Within a DSMS; the schedulingof the queries and their operators has proved to be of utmost importance. Previousapproaches addressing this issue can be divided into two categories: either each operatorruns in its own thread or all operators; combined in one query graph; run in a single thread.Both approaches suffer from severe drawbacks concerning the thread overhead on the onehand and the stalls due to expensive operators on the other hand. To overcome thesedrawbacks; we propose in this work a hybrid approach that flexibly assigns threads tosubgraphs of the query graph. We complement this approach with a suitable strategy to …,Data Engineering Workshop; 2007 IEEE 23rd International Conference on,2007,17
Maintaining Nonparametric Estimators over Data Streams.,Björn Blohsfeld; Christoph Heinz; Bernhard Seeger,*,BTW,2005,17
A Status Report on XXL - a Software Infrastructure for Efficient Query Processing,Michael Cammert; Christoph Heinz; Jürgen Krämer; Martin Schneider; Bernhard Seeger,Abstract XXL is a Java library that contains a rich infrastructure for implementing advancedquery processing functionality. The library offers low-level components like access to rawdisks as well as high-level ones like a query optimizer. On the intermediate levels; XXLprovides a demand-driven cursor algebra; a framework for indexing and a powerful packagefor supporting aggregation. The library is publicly available under GNU LGPL and comeswith a full documentation.,IEEE Data Eng. Bull.,2003,17
Complex event processing for reactive security monitoring in virtualized computer systems,Lars Baumgärtner; Christian Strack; Bastian Hoßbach; Marc Seidemann; Bernhard Seeger; Bernd Freisleben,Abstract The number of security incidents in computer systems is steadily increasing; despiteintrusion detection and prevention mechanisms deployed as countermeasures. Manyexisting intrusion detection and prevention systems struggle to keep up with new threatsposed by zero-day attacks and/or have serious performance impacts through extensivemonitoring; questioning their effectiveness in most real-life scenarios. In this paper; wepresent a new approach for reactive security monitoring in a virtualized computerenvironment based on minimally-intrusive dynamic sensors deployed vertically acrossvirtualization layers and horizontally within a virtual machine instance. The sensor streamsare analyzed using a novel federation of complex event processing engines and anoptimized query index to maximize the performance of continuous queries; and the …,Proceedings of the 9th ACM International Conference on Distributed Event-Based Systems,2015,16
Dynamic plan migration for snapshot-equivalent continuous queries in data stream systems,Jürgen Krämer; Yin Yang; Michael Cammert; Bernhard Seeger; Dimitris Papadias,Abstract A data stream management system executes a large number of continuous queriesin parallel. As stream characteristics and query workload change over time; the plan initiallyinstalled for a continuous query may become inefficient. As a consequence; the queryoptimizer will re-optimize this plan based on the current statistics. The replacement of therunning plan with a more efficient but semantically equivalent plan at runtime is calleddynamic plan migration. In order to have a sound semantic foundation for queryoptimization; we investigate dynamic plan migration for snapshot-equivalent plans. Wedevelop a general method for dynamic plan migration that treats the old and new plan assnapshot-equivalent black boxes. This enables the query optimizer to apply theconventional transformation rules during re-optimization. As a consequence; our …,International Conference on Extending Database Technology,2006,16
Quality-of-service-aware data stream processing,Sven Schmidt,Data stream processing in the industrial as well as in the academic field has gained moreand more importance during the last years. Consider the monitoring of industrial processesas an example. There; sensors are mounted to gather lots of data within a short time range.Storing and post-processing these data may occasionally be useless or even impossible. Onthe one hand; only a small part of the monitored data is relevant. To efficiently use thestorage capacity; only a preselection of the data should be considered. On the other hand; itmay occur that the volume of incoming data is generally too high to be stored in time or–inother words–the technical efforts for storing the data in time would be out of scale.Processing data streams in the context of this thesis means to apply database operations tothe stream in an on-the-fly manner (without explicitly storing the data). The challenges for …,*,2006,15
Nearest neighbor search on vertically partitioned high-dimensional data,Evangelos Dellis; Bernhard Seeger; Akrivi Vlachou,Abstract In this paper; we present a new approach to indexing multidimensional data that isparticularly suitable for the efficient incremental processing of nearest neighbor queries. Thebasic idea is to use index-striping that vertically splits the data space into multiple low-andmedium-dimensional data spaces. The data from each of these lower-dimensionalsubspaces is organized by using a standard multi-dimensional index structure. In order toperform incremental NN-queries on top of index-striping efficiently; we first develop analgorithm for merging the results received from the underlying indexes. Then; an accuratecost model relying on a power law is presented that determines an appropriate number ofindexes. Moreover; we consider the problem of dimension assignment; where eachdimension is assigned to a lower-dimensional subspace; such that the cost of nearest …,International Conference on Data Warehousing and Knowledge Discovery,2005,13
Wavelet density estimators over data streams,Christoph Heinz; Bernhard Seeger,Abstract Density estimation is a building block of many data analysis techniques. A recentlyexamined approach based on wavelets promises to be superior to traditional densityestimation techniques. For possibly infinite data streams; however; this approach is notfeasible due to the limited resources; eg memory. In this paper; we propose a new techniquefor computing wavelet density estimators over data streams that only requires a fixed amountof memory. Our estimators are updated in an online manner such that a continuous analysisof data streams is supported during runtime.,Proceedings of the 2005 ACM symposium on Applied computing,2005,13
GENESYS: A system for efficient spatial query processing,Thomas Brinkhoff; Hans-Peter Kriegel; Ralf Schneider; Bernhard Seeger,Institute for Computer Science; University of Munich Leopoldstr. 11 B; D-80802 Munchen; Germanye-mail: {brink;kriegel;ralf;bseeger} @informatik.uni-muenchen.de … 1 Introduction Recently;spatial databare systems (SDBS) have gained increasing importance in variousapplications. Due to the high complexity of … * Fig. 1: Multi-step query processing In a secondstep; all elements of the candldatc set are examined us- ing ageometry-falter. This filter exploitsmore accurate approxima- tions than the MBR. The approximations are used for determiningelements of the candidate set as hits fultWing the query; false hits not fulfilling the query andcandidates possibly fulfilling the query. The remaining candidates are eventually investigatedin the last … A spatial query is abstractly executed as a sequence of steps. In the fist step; aspa- tial access method (SAM) is used for scaling down the search space. Due to the …,ACM SIGMOD Record,1994,13
Sort-based parallel loading of R-trees,Daniar Achakeev; Marc Seidemann; Markus Schmidt; Bernhard Seeger,Abstract Due to the increasing amount of spatial data; parallel algorithms for processing bigspatial data become more and more important. In particular; the shared nothing architectureis attractive as it offers low cost data processing. Moreover; popular MapReduce frameworkssuch as Hadoop allow developing conceptually simple and scalable algorithms forprocessing big data using this architecture. In this work we address the problem of parallelloading of R-trees on a shared-nothing platform. The R-tree is a key element for efficientquery processing in large spatial database; but its creation is expensive. We proposed anovel scalable parallel loading algorithm for MapReduce. The core of our parallel loading isthe state of the art sequential sort-based query-adaptive R-tree loading algorithm that buildsR-trees optimized according to a commonly used cost model. In contrast to previous …,Proceedings of the 1st ACM SIGSPATIAL International Workshop on Analytics for Big Geospatial Data,2012,12
Self-diagnosing and self-healing indexes,Goetz Graefe; Harumi Kuno; Bernhard Seeger,Abstract Transactional storage and indexing is the heart of every database; not only forperformance and functionality but also for reliability and availability. For high concurrency;these components must be programmed carefully with short critical sections; a variety ofconsistent states with short transitions; etc. Many-core CPUs exacerbate these requirements.Testing software with 100s or 1; 000s of threads is very difficult. In order to test such code;we suggest verifying the B-tree structure in each traversal. With carefully designed treestructure and node contents; a root-to-leaf pass can verify all nodes along its pathcomprehensively; ie; it can verify all B-tree invariants including its consistency constraintswith respect to its siblings and cousins (defined below). Thus; instead of testing the indeximplementation by running a stress-test and verifying the B-tree structure and contents …,Proceedings of the Fifth International Workshop on Testing Database Systems,2012,12
Anfrageverarbeitung auf Datenströmen.,Michael Cammert; Christoph Heinz; Jürgen Krämer; Bernhard Seeger,PIPES selbst verfügt zudem über eine Laufzeitumgebung; die sich im Wesentlichen ausKomponenten zur Speicherverwaltung; Ablaufsteuerung und Anfrageoptimierungzusammensetzt. Die Speicherverwaltung teilt den zur Verfügung stehenden Speicher zurLaufzeit dynamisch unter den statusbehafteten Knoten eines Operatorgraphen auf; alsodenjenigen Knoten; die Speicher benötigen; wie zB Verbundoperationen (Join). Wann; wieoft und wie lange ein Knoten zum Zuge kommt; entscheidet dabei die Ablaufsteuerung; diesomit die verfügbaren CPU-Ressourcen eines Systems adaptiv verwaltet. DerAnfrageoptimierer hat das Ziel; einen möglichst optimalen Anfragegraphen zu erstellen;wobei Umformungen von Subgraphen zur Laufzeit aufgrund der kontinuierlichen Anfrageneine besondere Rolle spielen. Hierbei stellt sich die Frage nach geeigneten …,Datenbank-Spektrum,2004,12
JEPC: the java event processing connectivity,Bastian Hoßbach; Nikolaus Glombiewski; Andreas Morgen; Franz Ritter; Bernhard Seeger,Zusammenfassung Today; event processing (EP) is the first choice technology for analyzingmassive event streams in a timely manner. EP allows to detect user-defined situations ofinterest; like in streaming position events for example; in near real-time such that actions canbe taken immediately. Unfortunately; each specific EP system has its very own API andquery language because there are no standards. The exchange of EP systems as well astheir use within a federation is challenging; error-prone; and expensive. To overcome theseproblems; we introduce the Java Event Processing Connectivity (JEPC) that is a middlewarefor uniform EP functionality in Java. JEPC provides always the same API and querylanguage for EP completely independent of the EP system beneath. Furthermore; we showin detail how JEPC can integrate database systems besides EP systems and evaluate the …,Datenbank-Spektrum,2013,11
Statistical modeling of sensor data and its application to outlier detection,Christoph Heinz; Bernhard Seeger,Abstract. Various applications rely on a continuous processing of data streams originatingfrom a network of interconnected and collaborated sensors. The processing of those streamshas turned out to be a difficult task as sensors only have limited resources and the data theyproduce is inherently uncertain and unreliable. In order to bridge the gap from raw; uncertainsensor readings to a meaningful model of the physical phenomenon observed; statisticalmodeling techniques have proved to be an adequate approach. By means of a statisticalmodel; a wide range of sensor network related topics can be covered. In this work; wepresent an initial approach to tackle an important problem in sensor processing; namely thedetection of outliers; with a statistical model.,5. GI/ITG KuVS Fachgespräch „Drahtlose Sensornetze “,2006,11
Efficient bulk updates on multiversion b-trees,Daniar Achakeev; Bernhard Seeger,Abstract Partial persistent index structures support efficient access to current and pastversions of objects; while updates are allowed on the current version. The Multiversion B-Tree (MVBT) represents a partially persistent index-structure with both; asymptotic worst-case performance and excellent performance in real life applications. Updates areperformed tuple-by-tuple with the same asymptotic performance as for standard B+ trees. Tothe best of our knowledge; there is no efficient algorithm for bulk loading and bulk update ofMVBT and other partially persistent index structures. In this paper; we propose the firstloading algorithm for MVBT that meets the lower-bound of external sorting. In addition; ourapproach is also applicable to bulk updates. This is achieved by combining two basictechnologies; weight balancing and buffer tree. Our extensive set of experiments confirm …,Proceedings of the VLDB Endowment,2013,10
Resource-aware kernel density estimators over streaming data,Christoph Heinz; Bernhard Seeger,Abstract A fundamental building block of many data mining and analysis approaches isdensity estimation as it provides a comprehensive statistical model of a data distribution. Forthat reason; its application to transient data streams is highly desirable. A convenient;nonparametric method for density estimation utilizes kernels. However; its computationalcomplexity collides with the rigid processing requirements of data streams. In this work; wepresent a new approach to this problem that combines linear processing cost with a constantamount of allocated memory. Our approach also supports a dynamic memory adaptation tochanging system resources.,Proceedings of the 15th ACM international conference on Information and knowledge management,2006,10
VAT: a system for visualizing; analyzing and transforming spatial data in science,Christian Authmann; Christian Beilschmidt; Johannes Drönner; Michael Mattig; Bernhard Seeger,Abstract The amount of available data changes the style of research in geo-scientificdomains; and thus influences the requirements for spatial processing systems. To supportdata-driven research and exploratory workflows; we propose the V isualization; A nalysis & Transformation system (VAT). We first identify ten fundamental requirements; which span fromsupporting spatial data types over low latency computations to visualization techniques.Based on these we evaluate state-of-the-art systems from the domains of spatialframeworks; GIS; workflow systems; scientific databases and Big Data solutions. The goal ofthe VAT system is to overcome the identified limitations by a holistic approach to raster andvector data; demand-driven and tiled processing; and the efficient usage of heterogeneoushardware architectures. A first comparison with other systems shows the validity of our …,Datenbank-Spektrum,2015,9
Adaptive Wavelet Density Estimators over Data Streams,Christoph Heinz; Bernhard Seeger,A variety of scientific and commercial applications requires an immediate analysis oftransient data streams. Many approaches for analyzing data share the property that anestimation of the underlying data distribution is used as a fundamental building block. Toestimate the density of a continuous data distribution; wavelet density estimation; atechnique from the area of nonparametric statistics; is very appealing as it is theoreticallywell-founded and practically approved. For that reason; its application to data streams ishighly promising; it provides a convenient way to analyze the characteristics of a stream.However; the heavy computational cost of wavelet density estimators renders their directapplication to the streaming scenario impossible. In this work; we tackle this problem andpresent a novel approach to adaptive wavelet density estimators over data streams. Not …,Scientific and Statistical Database Management; 2007. SSBDM'07. 19th International Conference on,2007,9
Reaktives cloud monitoring mit complex event processing,Bastian Hoßbach; Bernd Freisleben; Bernhard Seeger,Zusammenfassung In den letzten Jahren hat Cloud Computing ein rasantes wirtschaftlichesWachstum erfahren. Um das Anbieten und Nutzen von virtualisierten IT-Ressourcen wieServer; Speicher; Plattformen und Anwendungen als immer und überall verfügbare sowieelastische Dienste im Web hat sich schnell eine wichtige Industrie entwickelt. Jedoch konntedie Beseitigung der Risiken nicht mit dieser rapiden Entwicklung von Cloud Computingmithalten. Vielmehr traten mit der Zeit immer mehr gravierende und bisher ungelösteProbleme auf. Dieser Beitrag zeigt; wie mit Hilfe von Complex Event Processing (CEP) eineganzheitliche Überwachung (Monitoring) von Clouds in nahezu Echtzeit realisiert werdenkann. Zusätzlich ist das vorgeschlagene Cloud Monitoring in der Lage; selbstständig auf dieErgebnisse von Analysen zu reagieren und in das gerade beobachtete Geschehen …,Datenbank-Spektrum,2012,8
Transactions on the multiversion b+-tree,Tuukka Haapasalo; Ibrahim Jaluta; Bernhard Seeger; Seppo Sippu; Eljas Soisalon-Soininen,Abstract The multiversion B+-tree (MVBT) by Becker et al. assumes a single-data-itemupdate model in which each new version created for a data item is given a timestamp that isunique across the entire MVBT. In this paper; we extend the MVBT model with multi-actiontransactions such that all (final) data-item versions created by a transaction are given thesame timestamp. We show that the MVBT algorithms can be modified to work in a setting inwhich multiple readonly transactions and a single updating transaction operate concurrentlyin snapshot isolation on the MVBT; without compromising the asymptotically optimal timecomplexity of key inserts; key deletes; and key-range scans on any version. The structuralconsistency and balance of the MVBT is guaranteed by short-duration latching of pages;redo-only logging of structure modifications (version splits; key splits and page merges) …,Proceedings of the 12th International Conference on Extending Database Technology: Advances in Database Technology,2009,8
Toward simulation-based optimization in data stream management systems,Christoph Heinz; Jurgen Kramer; Tobias Riemenschneider; Bernhard Seeger,Our demonstration introduces a novel system architecture which massively facilitatesoptimization in data stream management systems (DSMS). The basic idea is to decoupleoptimization from the operative system by means of a secondary optimization system; whichbears the burden of determining new query plans. Within the secondary system; whichtypically runs on a separate machine; we utilize suitable statistical models of the originaldata streams to simulate them. As the simulation can run at much faster rates; we are able toexamine and assess new query plans in a shorter period of time without running the risk ofdeteriorating the original plan; we only migrate practically approved plans into the operativesystem. In our demonstration; we will present our prototypical implementation of thisoptimization architecture. We will demonstrate the interaction between primary and …,Data Engineering; 2008. ICDE 2008. IEEE 24th International Conference on,2008,8
Exploring data streams with nonparametric estimators,Christoph Heinz; Bernhard Seeger,A variety of real-world applications requires a meaningful online analysis of transient datastreams. An important building block of many analysis tasks is the characterization of theunderlying data distribution. Sophisticated techniques from the area of nonparametricstatistics provide a well-defined estimation of continuous data distributions. The analysis ofdata streams may gain advantage of these techniques; however; the rigid processingrequirements of streams render a direct application impossible. In our work; we tackle theadaptation of nonparametric techniques to streaming data. We concentrate on densityestimation as it provides a convenient basis for the exploration of an unknown continuousdata distribution. Specifically; we have developed kerneland wavelet-based densityestimators for data streams in compliance with their processing requirements. Both …,Scientific and Statistical Database Management; 2006. 18th International Conference on,2006,8
Sortierbasierte Joins uber Datenströmen,Michael Cammert; Christoph Heinz; Jürgen Krämer; Bernhard Seeger,Abstract: Der effektiven Berechnung von Joins kommt auch in der Datenstromverarbeitungessentielle Bedeutung zu. In dieser Arbeit adaptieren wir daher die für eine Vielzahlverschiedener Joinprädikate geeignete sortierbasierte Joinverarbeitung von der passivenauf die aktive Datenverarbeitung. Wir zeigen auf; wie man das Problem der Verarbeitungpotentiell unbegrenzter Datenströme mit Hilfe einer exakten Zeitfenstersemantik löst. Zuderen Realisierung stellen wir verschiedene Haupt-und Externspeicheralgorithmen vor.Abschließend erweitern wir die vorgestellten Operatoren zur Berechnungmehrdimensionaler Joins und zeigen experimentell die Vorteile dieses Ansatzes gegenüberbinär kaskadierten Joins auf.,Proc. of the Conf. on Database Systems for Business; Technology; and the Web (BTW),2005,8
A comparison of indexed temporal joins,Donghui Zhang; Vassilis J Tsotras; Bernhard Seeger,Abstract We examine temporal joins in the presence of indexing schemes. Utilizing an indexwhen processing join queries is especially advantageous if the join predicates involve onlya portion of the temporal relations. This is a novel problem since temporal indices havevarious characteristics that can affect join processing drastically. For example; temporalindices commonly introduce record copies to achieve better clustering of records with longintervals. We first identify such issues and show that naïve approaches do not work. Weconcentrate on common temporal join queries and examine various index-based algorithmsfor processing them. Two optimization techniques for indexed joins are proposed; namely;the balancing condition optimization and the virtual height optimization. While we use theMultiversion B+-tree as the temporal index; our results apply to other efficient tree-based …,History,2000,8
Event Processing on your own Database.,Nikolaus Glombiewski; Bastian Hoßbach; Andreas Morgen; Franz Ritter; Bernhard Seeger,Abstract: Event processing (EP) is widely used for reacting on events in the very momentwhen they occur. Events that require immediate reactions can be found in variousapplications; eg algorithmic trading; business process monitoring and sensorbased human-computer interaction. For the support of EP in an application; a specialpurpose EP systemwith its own API and query language has to be used. Typically; EP systems as well as theirintegration in applications are expensive. In this paper; we show how every standarddatabase system can be used as an EP system via JDBC. An experimental evaluationproofs that databases behind JDBC are able to support small and medium-sized EPworkloads.,BTW workshops,2013,7
Continuous queries on trajectories of moving objects,Philip Schmiegelt; Bernhard Seeger; Andreas Behrend; Wolfgang Koch,Abstract Since navigation systems and tracking devices are becoming ubiquitous in ourdaily life; the development of efficient methods for processing massive sets of mobile objectsare of utmost importance. Although future routes of mobile objects are often known inadvance in many applications; this information is not fully utilized in most methods so far. Inthis paper; we reveal the beneficial effects of exploiting future routes for the early generationof the expected results of spatio-temporal queries. This kind of probable results is importantfor operative analytics in many applications like smart fleet management or intelligentlogistics. For efficiently computing the high number of future trajectory points; a new indexstructure is presented which allows for a fast maintenance of query results under continuouschanges of mobile objects. Our methods make use of specific update patterns; which …,Proceedings of the 16th International Database Engineering & Applications Sysmposium,2012,7
Plug&Join: An easy-to-use generic algorithm for efficiently processing equi and non-equi joins,Jochen Van den Bercken; Martin Schneider; Bernhard Seeger,Abstract This paper presents Plug&Join; a new generic algorithm for efficiently processing abroad class of different join types in extensible database systems. Depending on the joinpredicate Plug&Join is called with a suitable type of index structure as a parameter. If theinner relation fits in memory; the algorithm builds a memory resident index of the desiredtype on the inner relation and probes all tuples of the outer relation against the index.Otherwise; a memory resident index is created by sampling the inner relation. The index isthen used as a partitioning function for both relations. In order to demonstrate the flexibility ofPlug&Join; we present how to implement equi joins; spatial joins and subset joins by usingmemory resident B+-trees; R-trees and S-trees; respectively. Moreover; results obtainedfrom different experiments for the spatial join show that Plug&Join is competitive to …,International Conference on Extending Database Technology,2000,7
Rethinking spatial processing in data-intensive science,Christian Authmann; Christian Beilschmidt; Johannes Drönner; Michael Mattig; Bernhard Seeger,In this paper we address the problem of supporting data-driven science in geo-scientificapplication domains where scientists need to filter; analyze; and correlate large data sets inan interactive manner. We identify ten fundamental requirements for such a new type ofprocessing system. They span from supporting spatial data types over using workflows fordata lineage; to fast and flexible computations for exploratory analysis. Our study of relatedwork looks at a range of established systems of different domains and shows significantdrawbacks with respect to our requirements. We propose the Visualization; Aggregation\&Transformation system (VAT) as an architecture to overcome current limitations. It bases onstandard software and implements performance-relevant parts using state-of-the-arttechnology like GPU computing. Our first comparison with other systems shows the …,Datenbanksysteme für Business; Technologie und Web (BTW 2015)-Workshopband,2015,6
A class of r-tree histograms for spatial databases,Daniar Achakeev; Bernhard Seeger,Abstract Spatial histograms are extremely useful for approximate query processing in largespatial databases. The problem of generating optimal spatial histograms is NP-hard;therefore; many heuristic-based methods have emerged over the last 15 years.Shortcomings of these methods are their complex algorithmic design and their sensitivity toparameter setting; preventing them to be easily integrated into real systems. In this paper;we present a class of spatial histograms derived from the popular family of R-tree indexes.We propose a cost-optimized approach that combines bulk-loading of R-trees and theconstruction of spatial histograms. This results in a robust histogram method with highaccuracy for selectivity estimation of spatial queries. Our method does not require the settingof intuitive parameters at all. In addition; the estimation error continuously decreases with …,Proceedings of the 20th International Conference on Advances in Geographic Information Systems,2012,6
Querying the future of spatio-temporal objects,Philip Schmiegelt; Bernhard Seeger,Abstract Since navigation systems and tracking devices are becoming ubiquitous in ourdaily life; the development of efficient methods for processing massive sets of mobile objectsare of utmost importance. Although future routes of mobile objects are often known inadvance in many applications; this information is not fully utilized in most methods so far. Inthis paper; we reveal the beneficial effects of exploiting future routes for the early generationof the expected results of spatio-temporal queries. This kind of probable results is importantfor operative analytics in many applications like smart fleet management. In order tomaintain the results of spatio-temporal queries under continuous changes of mobile objects;we present efficient methods for the maintenance of the results. Our methods make use ofspecific update patterns; which require substantially less maintenance costs than the …,Proceedings of the 18th SIGSPATIAL International Conference on Advances in Geographic Information Systems,2010,5
Interactive Data Exploration for Geoscience,Christian Beilschmidt; Johannes Drönner; Michael Mattig; Marco Schmidt; Christian Authmann; Aidin Niamir; Thomas Hickler; Bernhard Seeger,Data-driven research requires interactive systems supporting fast and intuitive data ex-ploration. An important component is the user interface that facilitates this process. Inbiodiversity research; data is commonly of spatio-temporal nature. This poses uniqueopportunities for visual analytics approaches. In this paper we present the core concepts ofthe web-based front end of our VAT (Visualization; Analysis and Transformation) system; adistributed geo-processing application. We present the results of a user study and highlightunique features for the management of time and the generalization of data.,Datenbanksysteme für Business; Technologie und Web (BTW 2017)-Workshopband,2017,4
Logical recovery from single-page failures.,Goetz Graefe; Bernhard Seeger,Abstract: Modern hardware technologies and ever-increasing data sizes increase probabilityand frequency of local storage failures; eg; unrecoverable read errors on individual disksectors or pages on flash storage. Our prior work has formalized singlepage failures andoutlined efficient methods for their detection and recovery. These prior techniques rely onold backup copies of individual pages; eg; as part of a database backup or as old versionsretained after a page migration. Those might not be available; however; eg; after recentindex creation in “non-logged” or “allocation-only logging” mode; which industrial databaseproducts commonly use.,BTW,2013,4
About adopting event processing in manufacturing,Manfred Grauer; Bernhard Seeger; Daniel Metz; Sachin Karadgi; Marco Schneider,Abstract Manufacturing enterprises strive for improvements in their monitoring and control ofenterprise processes to sustain competitive advantages. In this context; enterpriseintegration (EI) across various enterprise levels and event processing are indispensable.However in reality; enabling EI and employing event processing for online monitoring andcontrol of enterprise processes are elusive goals for many of the manufacturing enterprises.In the contribution; a framework for enabling EI is elaborated; which can be considered as abuilding block towards realizing the aforementioned goals. The framework encompassesvarious components: data collection engine; data aggregation engine; event processingengine; performance measurement; and offline analysis. This framework can be exploited inenhancing online monitoring and control of enterprise processes by employing event …,European Conference on a Service-Based Internet,2010,4
Temporal search in web archives,Klaus Lorenz Berberich,Webarchive bezeichnen einerseits Archive ursprünglich im Web veröffentlichter Inhalte (z. B.das Internet Archive); andererseits Archive; die vor langer Zeit veröffentlichter Inhalte imWeb zugreifbar machen (z. B. das Archiv von The Times). Ein gewachsenes Bewusstein;dass originär digitale Inhalte bewahrenswert sind; sowie verbesserteDigitalisierungsverfahren haben dazu geführt; dass Anzahl und Umfang von Webarchivenzugenommen haben. Um das volle Potenzial von Webarchiven auszuschöpfen; bedarf esdurchdachter Suchverfahren. Diese Arbeit befasst sich mit drei relevanten Teilproblemenund leistet die folgenden Beiträge:-Vorstellung des Time-Travel Inverted indeX (TTIX) alseine Erweiterung des invertierten Index; um Zeitreise-Textsuche auf Webarchiven effizientzu unterstützen.-Eine neue Methode zur automatischen Umformulierung von …,*,2010,4
Accelerating the retrieval of 3D shapes in geometrical similarity search using M-tree-based indexing,Ulf Müller; Thomas Barth; Bernhard Seeger,Abstract. Increasing the efficiency of knowledge-intensive processes is a major challengeespecially in those domains where expert knowledge is the decisive factor for the successfuland efficient fulfillment of complex tasks. In the engineering domain; one of the mostknowledge-intensive and time-consuming core processes is the cost estimation; design; andconstruction of a product and its production tools (eg an automotive supplier part) answeringa customer's specific request. Most of the knowledge necessary to fulfill these processes andwhich is in turn generated in the course of these processes is represented through theproduct's three-dimensional geometry. Hence; efficient retrieval of geometrical data is a keyissue when supporting these processes with a casebased reasoning (CBR) approach. CBRtechniques for supporting these processes enable a process participant to analyze …,Sarah Jane Delany,2009,4
A benchmark for multidimensional index structures,Norbert Beckmann; Bernhard Seeger,In this paper we give an overview of our benchmark for multidimensional index structures.The benchmark consists of 28 data files. From each of them 3 query files were derived;corresponding to 1; 100 and 1000 answers per query on average. In Section 2; we provide adetailed description of the data distributions; Section 3 explaines how the query distributionswere derived. In Section 4; the values of important parameters of the data distributions aswell as the query distributions are depicted in a table.,*,2008,4
Datenströme im Kontext des Verkehrsmanagements.,Michael Cammert; Christoph Heinz; Jürgen Krämer; Bernhard Seeger,Abstract: Anhand mobiler Objekte im Verkehrsmanagement diskutieren wir die Verarbeitungder dabei entstehenden Datenströme. Wir skizzieren typische Anforderungen anDatenverarbeitungssysteme und begründen; warum traditionelleDatenbankmanagementsysteme im Kontext von Datenströmen weniger geeignet sind.Vielmehr motivieren wir den Einsatz von Datenstrommanagementsystemen; wobei wir einenUberblick über allgemeine Problemstellungen und Ansätze bei der Verarbeitung vonDatenströmen geben. Neben prototpyischen Systemen präsentieren wir unserbibliotheksorientiertes Rahmenwerk; mit dem sich Anfragen über Datenströmen adäquatformulieren und ausführen lassen. Im Ausblick erläutern wir die Konstruktion einesallgemeinen Datenstrommanagementsystems aus den Komponenten unseres …,Mobilität und Informationssysteme,2003,4
VAT: A System for Data-Driven Biodiversity Research.,Christian Beilschmidt; Johannes Drönner; Michael Mattig; Bernhard Seeger,ABSTRACT Visual analytics plays a leading role in data-driven research. This requiressystems for fast and intuitive data exploration. In this paper we demonstrate Vat; a system forVisualizing; Analyzing and Transforming spatio-temporal data. The system consists of adistributed back end for low-latency processing and a web front end that allows creatingworkflows of computations in an exploratory fashion. A novel quality of the system is thecombination of scientific processing while simultaneously tracking the provenance of thedata and aggregating a list of data citations. These features make a visual analyticsapproach for large; heterogeneous spatiotemporal data feasible.,EDBT,2017,3
Mastering Security Anomalies in Virtualized Computing Environments via Complex Event Processing,Lars Baumgärtner; Pablo Graubner; Matthias Leinweber; Roland Schwarzkopf; Matthias Schmidt; Bernhard Seeger; Bernd Freisleben,Abstract—To protect computer systems and their users against security attacks; all potentialsecurity related incidents should be detected by monitoring system behavior. In this paper; anovel approach to detect; analyze and handle security anomalies in virtualized computingsystems is presented. Adequate sensors on different virtualization layers monitor relevantevents; a Complex Event Processing engine is used to aggregate and correlate events onthe same or different layers to find genuine attacks and eliminate false positives; andcorresponding actions are performed if a security anomaly is detected. To enhance thequality of the results; machine learning techniques are used to analyze a historical databaseof recorded events offline to generate new or modify existing queries on the monitored eventstream automatically. Furthermore; sensors can be activated and deactivated during …,Proceedings of the The Fourth International Conference on Information; Process; and Knowledge Management (eKNOW 2011),2012,3
Spatial Access Methods based on Dynamic Hashing,Bernhard Seeger; Hans-Peter Kriegel,Abstract In order to handle spatial data efficiently; as required in computer aided design andgeo-data applications; a database management system (DBMS) needs an access methodthat will help it retrieve data items quickly according to their spatial location. In this paper wegive a classification of existing spatial access methods and show that they use one of thefollowing three techniques: clipping; overlapping regions; and transformation. Theperformance of all previous schemes depends on and varies with the application. There isno scheme with a good overall performance. Thus our approach is to combine thesetechniques in one hybrid method to achieve good performance independent of theapplication. In an analysis we show the performance gain of our new scheme in comparisonto previous proposed methods.,*,1988,3
Quality Measures for Visual Point Clustering in Geospatial Mapping,Christian Beilschmidt; Thomas Fober; Michael Mattig; Bernhard Seeger,Abstract Visualizing large amounts of point data in a way that resembles the density of thedistribution is a complex problem if the size of the drawing area is constrained. Naïvelydrawing points on top of each other leads to occlusion and therefore a loss of information.An intuitive approach is combining close points as clusters that resemble their size as wellas their geographic location. However; traditional clustering algorithms are not designed forvisual clusterings rather than minimizing an error function independent of a graphicalrepresentation. This paper introduces measures for the quality of circle representationsbased on clustering outputs. Our experimental evaluation revealed that all methods hadweaknesses regarding at least one of these criteria.,International Symposium on Web and Wireless Geographical Information Systems,2017,2
Complex event processing as a service,Daniar Achakeyev; Bernhard Seeger; Daniel Schäfer; Philip Schmiegelt,In den letzten Jahren wurde in Unternehmen immer mehr die Notwendigkeit erkannt;kontinuierliche Informationen zur operativen Überwachung und Steuerunggeschäftsrelevanter Prozesse in Echtzeit bereitzustellen. Die technologische Grundlagenbietet dafür das sogenannte Complex Event Processing (CEP)[1]; das Datenströme inEchtzeit filtert; aggregiert und korreliert und sich somit zu einer zentralen IT-Technologieinnerhalb der Informationsinfrastruktur von Unternehmen entwickelt hat. Jedoch haben sichauch Hemmschwellen für CEP in Unternehmen ergeben; wie zB die anfallenden Kosten beider Einführung der Technologie und die geringe Erfahrung mit CEP im kommerziellenUmfeld. Eine Möglichkeit ist es deshalb; CEP-Systeme nicht direkt im Unternehmen zuinstallieren; sondern CEP als einen Service zur Verfügung zu stellen. Unternehmen …,GI-workshop database as a service; HTWK Leipzig,2010,2
Stream Mining via Density Estimators: A Concrete Application.,Christoph Heinz; Bernhard Seeger,Abstract Many real-world applications share the property that the data they process arrivesin streams. The transient and volatile nature of these streams renders the application ofcommon processing and analysis techniques difficult. In particular; the mining of streamshas proved to be a difficult task due to the rigid processing requirements that must be metwithin the data stream scenario. We propose to exploit kernel density estimation for streammining. Kernel density estimation as a technique from the area of mathematical statisticsfound its way into many mining related topics and applications. However; its heavycomputational cost makes the direct application to streams impossible. On account of this;we developed in a previous work a sophisticated adaptation that continuously computeskernel density estimators over streams. By means of these estimators; we can tackle a …,COMAD,2006,2
An asymptotically optimal multiversion b-tree,Peter Widmayer; Bruno Becker; Dipl-Inf Stephan Gschwind; Dipl Wi-Ing Thomas Ohler; Bernhard Seeger,Abstract In a variety of applications; we need to keep track of the development of a data setover time. For maintaining and querying these multiversion data e ciently; external storagestructures are an absolute necessity. We propose a multiversion B-tree that supportsinsertions and deletions of data items at the present version; and range queries and exactmatch queries for any version; present or past. Our multiversion B-tree is asymptoticallyoptimal in the sense that the time and space bounds are asymptotically the same as those ofthe (single version) B-tree in the worst case. The technique we present for transforming a(single version) B-tree into a multiversion B-tree is quite general: it applies to a number ofhierarchical external access structures with certain properties directly; and it can be modi edfor others. yisys software gmbh; Ensisheimer Str. 2a; D {79110 Freiburg i. Br. zInstitut f ur …,Very Large Data Bases Journal,1996,2
The R"-tree,Norbert Beckmann; H Kriegel; Ralf Schneider; Bernhard Seeger,Abstract The R-tree; one of the most popular access methods for rectangles; 1s based on theheurıstıc optımızatıon of the area of the enclosıng rectangle ın each 1nner node By runnıngnumerous experıments ın a standardızed testbed under hıghly varyıng data; queres andoperatıons; we were able to design the R*-tree whıch ıncorporates a combıned optımızatıonof area; margın and overlap of each enclosıng rectangle ın the dırectory Usıng ourstandardızed testbed ın an exhaustıve performance comparıson; ıt turned out that the R*-treeclearly outperforms the exıstıng R-tree varıants Guttman's lınear and quadratıc R-tree andGreene's varıant of the R-tree Thıs superiority of the R*-tree holds for dıfferent types ofquerıes and operatıons; such as map overlay; for both rectangles and multıdımensıonalpoınts ın all experıments From a practıcal poınt of view the R*-tree ıs very attractive …,An Efficient and Robust Access,1990,2
Design; Implementation and Performance Comparison of the Buddy-Tree,Bernhard Seeger; Hans-Peter Kriegel,Abstract In this paper; we introduce a new multidimensional access method; called thebuddy-tree; to support point as well as spatial data in a dynamic environment. The buddy-tree can be seen as a compromise of the R-tree and the grid file; but it is fundamentallydifferent from each of them. Because grid files loose performance for highly correlated data;the buddy-tree is designed to organize such data very efficiently; partitioning only such partsof the data space which contain data and not partitioning empty data space. The directoryconsists of a very flexible partitioning and reorganization scheme based on a generalizationof the buddy-system. As for B-trees; the buddy-tree fulfills the property that insertions anddeletions are restricted to exactly one path of the directory. Additional important propertieswhich are in this combination not fulfilled by any other multidimensional tree-based …,*,1990,2
VAT: A Scientific Toolbox for Interactive Geodata Exploration,Christian Beilschmidt; Johannes Drönner; Michael Mattig; Marco Schmidt; Christian Authmann; Aidin Niamir; Thomas Hickler; Bernhard Seeger,Abstract Data-driven research requires interactive systems supporting fast and intuitive dataexploration. An important component is the user interface that facilitates this process. Inbiodiversity research; data is commonly of spatio-temporal nature. This poses uniqueopportunities for visual analytics approaches. In this paper we present the core concepts ofthe web-based front end of our vat (Visualization; Analysis and Transformation) system; adistributed geo-processing application. We present the results of two user studies andhighlight unique features; among others for the management of time and the generalizationof data.,Datenbank-Spektrum,2017,1
Behavior analysis for safety and security in automotive systems,Roland Rieke; Marc Seidemann; Elise Kengni Talla; Daniel Zelle; Bernhard Seeger,The connection of automotive systems with other systems such as road-side units; othervehicles; and various servers in the Internet opens up new ways for attackers to remotelyaccess safety relevant subsystems within connected cars. The security of connected carsand the whole vehicular ecosystem is thus of utmost importance for consumer trust andacceptance of this emerging technology. This paper describes an approach for on-boarddetection of unanticipated sequences of events in order to identify suspicious activities. Theresults show that this approach is fast enough for in-vehicle application at runtime. Severalbehavior models and synchronization strategies are analyzed in order to narrow downsuspicious sequences of events to be sent in a privacy respecting way to a global securityoperations center for further in-depth analysis.,Parallel; Distributed and Network-based Processing (PDP); 2017 25th Euromicro International Conference on,2017,1
ChronicleDB: A High-Performance Event Store.,Marc Seidemann; Bernhard Seeger,ABSTRACT Reactive security monitoring; self-driving cars; the Internet of Things (IoT) andmany other novel applications require systems for both writing events arriving at very highand fluctuating rates to persistent storage as well as supporting analytical ad-hoc queries.As standard database systems are not capable to deliver the required write performance;logbased systems; key-value stores and other write-optimized data stores have emergedrecently. However; the drawbacks of these systems are a fair query performance and thelack of suitable instant recovery mechanisms in case of system failures. In this paper; wepresent ChronicleDB; a novel database system with a well-designed storage layout toachieve high write-performance under fluctuating data rates and powerful indexingcapabilities to support ad-hoc queries. In addition; ChronicleDB offers low-cost fault …,EDBT,2017,1
A concurrently updatable index structure for predicted paths of moving objects,Philip Schmiegelt; Andreas Behrend; Bernhard Seeger; Wolfgang Koch,Abstract While location-aware services; both in professional and private context; are widelyused today; not all the available knowledge is exploited. The predicted path moving objectsfollow when being guided eg by a smartphone; is not used; instead only the current positionis taken into account. In this article; we describe how the exploitation of not only point butalso route information can be used to offer a new value to the users as well as a reduction ofresource usage. It allows having queries on the future position of moving objects; taking theprobability of its estimation into account. An index structure to handle this kind of objects andqueries is introduced. Different methods for updating objects are proposed; allowing foreven less consumption of resources. A set of experiments shows the performance of ourapproach. This enables new services to be able to cope with a growing demand; both in …,Data & Knowledge Engineering,2014,1
A probabilistic index structure for querying future positions of moving objects,Philip Schmiegelt; Andreas Behrend; Bernhard Seeger; Wolfgang Koch,Abstract We are witnessing a tremendous increase in internet connected; geo-positionedmobile devices; eg; smartphones and personal navigation devices. Therefore; locationrelated services are becoming more and more important. This results in a very high load onboth communication networks and server-side infrastructure. To avoid an overload we pointout the beneficial effects of exploiting future routes for the early generation of the expectedresults of spatio-temporal queries. Probability density functions are employed to model theuncertain movement of objects. This kind of probable results is important for operativeanalytics in many applications like smart fleet management or intelligent logistics. An indexstructure is presented which allows for a fast maintenance of query results under continuouschanges of mobile objects. We present a cost model to derive initialization parameters of …,East European Conference on Advances in Databases and Information Systems,2013,1
How Foreign is FDI in China?,Kellee Sing Tsai,How Foreign is FDI in China?," What’s Land Got to do With it: Global Lessons About the Optimal Level of Control Over Property and Land Use”,2007,1
A Cost Model for Adaptive Resource Management in Data Stream Systems,Michael Cammert; Jürgen Krämer; Bernhard Seeger; Sonny Vaupel,Abstract Data stream management systems need to control their resources adaptively sincestream characteristics as well as query workload vary over time. In this paper we investigatean approach to adaptive resource management for continuous sliding window queries thatadjusts window sizes and time granularities to keep resource usage within bounds. In orderto quantify the impact of both methods on a query plan; we develop an efficient cost modelfor estimating the resource allocation in terms of memory usage and processing costs. Athorough experimental study not only validates the accuracy of our cost model but alsodemonstrates the efficacy and scalability of the applied methods.,*,2006,1
Tuning access methods to supporting data-intensive queries,Bernhard Seeger,Abstract In this paper; we consider how to improve dynamic access methods which aredesigned to perform data-intensive selection queries in a dynamic setting. A large number ofdynamic access methods have been proposed for supporting such queries. Almost all ofthem are designed with the primarily goal to reduce the number of page accesses; whereasour main attention is paid to decreasing the cost of individual page requests. There is a greatpotential for such improvements since the average (page) access time on a magnetic diskdrive is typically by a factor of 10 higher than the transfer time. In our approach; twotechniques are jointly used: clustering and multi-page requests. The technique of clusteringtakes care of storing pages on one cylinder which are frequently required by the same queryin common. In contrast to issuing a request for each qualifying page of a query; one multi …,*,1994,1
Konzepte zur Suche geometrisch ähnlicher Bauteile,Stephan Heep; H-P Kriegel; Ralf Schneider; Bernhard Seeger,Zusammenfassung Der verstärkte Einsatz von CAD-Systemen erfordert heute auch imingenieur-wissenschaftlichen Bereich den Einsatz von DB-Systemen. Eine wesentlicheForm der Anfrage ist die Suche nach ähnlichen Teilen-im Maschinenbau auch alsWiederholteilsuche bezeichnet-; um den Aufwand für die Konstruktion und dieProduktionsplanung wesentlich zu verringern. In allen bereits verfügbaren Systemenwerden Objekte durch einmalig festzulegende Attribute beschrieben. In diesem Artikel wirdnun ein System zur geometrischen Wiederholteilsuche vorgeschlagen; welches auf ein DB-System zugreift; in dem die Objekte durch die von einem CAD-System bereitgestellteGeometrieinformation beschrieben sind. Vorteil dieser Vorgehensweise sind die Erhaltungder vollständigen Information über die Objekte; die automatische Generierung der zu …,*,1988,1
A Linear-Time Algorithm for the Aggregation and Visualization of Big Spatial Point Data,Christian Beilschmidt; Thomas Fober; Michael Mattig; Bernhard Seeger,Abstract The visualization of spatial data becomes increasingly important in science;business and many other domains. In geography; data often corresponds to a large numberof point observations that should be displayed on a constrained screen with limitedresolution. This causes; however; a loss of information due to an overloaded and occludedvisualization. In this paper we present a new visualization algorithm that avoids this problemby aggregating point data into a set of non-overlapping circles that capture all importantinformation. Our algorithm based on a quadtree computes the circles in linear time withrespect to the number of points.,Proceedings of the 25th ACM SIGSPATIAL International Conference on Advances in Geographic Information Systems,2017,*
IDESSA: An Integrative Decision Support System for Sustainable Rangeland Management in Southern African Savannas,Hanna Meyer; Christian Authmann; Niels Dreber; Bastian Hess; Klaus Kellner; Theunis Morgenthal; Thomas Nauss; Bernhard Seeger; Zivanai Tsvuura; Kerstin Wiegand,Abstract Bush encroachment is a syndrome of land degradation that occurs in manysavannas including those of southern Africa. The increase in density; cover or biomass ofwoody vegetation often has negative effects on a range of ecosystem functions and services;which are hardly reversible. However; despite its importance; neither the causes of bushencroachment; nor the consequences of different resource management strategies tocombat or mitigate related shifts in savanna states are fully understood. The project"IDESSA"(An Integrative Decision Support System for Sustainable Rangeland Managementin Southern African Savannas) aims to improve the understanding of the complex interplaysbetween land use; climate patterns and vegetation dynamics and to implement anintegrative monitoring and decision-support system for the sustainable management of …,EGU General Assembly Conference Abstracts,2017,*
Workshop Big (and small) Data in Science and Humanities (BigDS17),Anika Groß; Birgitta König-Ries; Peter Reimann; Bernhard Seeger,The importance of data has dramatically increased in almost all scientific disciplines over thelast decade; eg; in meteorology; genomics; complex physics simulations; biological andenvironmental research; and recently also in humanities. This development is due to greatadvances in data acquisition and data accessibility; such as improvements in remotesensing; powerful mobile devices; popularity of social networks and the ability to handleunstructured data (including texts). On the one hand; the availability of such data massesleads to a rethinking in scientific disciplines on how to extract useful information and on howto foster research. On the other hand; researchers feel lost in the data masses becauseappropriate data management; integration; analysis and visualization tools have not beenavailable so far. However; this is starting to change with the recent development of big …,Datenbanksysteme für Business; Technologie und Web (BTW 2017)-Workshopband,2017,*
German Federation for Biological Data (GFBio),Michaeal Diepenbroek; Frank Oliver; Robert Huber; Jens Nieschulze; Bernhard Seeger; Dagmar Triebel; Christian Wirth,Abstract The German Federation for Biological Data (GFBio; http://www. gfbio. org) is asustainable; service-oriented; national data infrastructure project funded by the GermanResearch Foundation with the aim of facilitating data sharing for biological andenvironmental research.,TDWG 2016 ANNUAL CONFERENCE,2016,*
Die Arbeitsgruppe Datenbanksysteme an der Philipps-Universität Marburg,Bernhard Seeger,Zusammenfassung In diesem Beitrag wird die Arbeitsgruppe Datenbanksysteme an derUniversität Marburg vorgestellt. Es wird ein kurzer historischer Rückblick gegeben und aufaktuelle Forschungsgebiete eingegangen. Zudem wird das Engagement der Arbeitsgruppein der Lehre dargestellt und die Kooperation mit anderen Wissenschaftlern kurz skizziert.,Datenbank-Spektrum,2015,*
Joint workshop on data management for science (DMS),Sebastian Dorok; Birgitta König-Ries; Matthias Lange; Erhard Rahm; Gunter Saake; Bernhard Seeger,The Workshop on Data Management for Science (DMS) is a joint workshop consisting of thetwo workshops Data Management for Life Sciences (DMforLS) and Big Data in Science(BigDS). BigDS focuses on addressing big data challenges in various scientific disciplines.In this context; DMforLS focuses especially on life sciences. In the following; we give shortexcerpts of the call for papers of both workshops: Data Management for Life Sciences In lifesciences; scientists collect an increasing amount of data that must be stored; integrated;processed; and analyzed efficiently to make effective use of them. Thereby; not only thehuge volume of available data raises challenges regarding storage space and analysisthroughput; but also data quality issues; incomplete semantic annotation; long termpreservation; data access; and compliance issues; such as data provenance; make it …,Datenbanksysteme für Business; Technologie und Web (BTW 2015)-Workshopband,2015,*
Analytical Workflows for Large Data,Christian Authmann; Christian Beilschmidt; Michael Mattig; Bernhard Seeger,Abstract In order to support data-driven biodiversity research; scientists need fast andunrestricted access to data as well as the ability to correlate and aggregate arbitrary datasets. New insights are often gained from data via an explorative approach: a workflow iscreated and executed; its results are visualized; and the workflow is then kept; discarded;adjusted or extended and executed again. We call these workflows analytical to differentiatethem from the common operative workflows that refer to a well-specified scientific task. Thehighly interactive approach of analytical workflow is only viable when (intermediate) resultsare produced in a timely manner. This poses unique challenges when large data sets areinvolved; eg remote sensing data whose size can exceed hundreds of gigabytes. It istherefore crucial to minimize the data transfers among processing operators of analytical …,TDWG 2014 ANNUAL CONFERENCE,2014,*
Master Seminar Topics,Jiakui Zhao; Dongqing Yang; Bin Cui; Lijun Chen; Jun Gao; Hailong Liu; Zhanhuai Li; Qun Chen; Shanglian Peng; Donghui Zhang; Alexander Markowetz; Vassilis J Tsotras; Dimitrios Gunopulos; Bernhard Seeger; Sudipto Das; Shyam Antony; Divyakant Agrawal; Amr El Abbadi; Vagelis Hristidis; Oscar Valdivia; Michail Vlachos; Philip S Yu; Yan-Nei Law; Haixun Wang; Carlo Zaniolo; Thanh TL Tran; Liping Peng; Yanlei Diao; Andrew McGregor; Anna Liu,Sorting is another example of a blocking operator. Data streams are characterised by theirenormous size (potentially infinite); rapid arrival rate and their transient nature (in terms ofdata distributions). Since the data streams are open-ended by definition (ie; they have andinfinite size as data keeps arriving); these operators would go into a perpetual wait state.Moreover; these conventional operators are designed to give the exact answers and alwaysmake a complete iteration over all the available data whenever they are invoked; hence; areextremely resource intensive; not in terms of time and space. In the context of stream mining;where resources are limited; the algorithms make a trade off of accuracy for efficiency. Theanswers provided by the streaming algorithms are approximation of the original answers(with error bounds). Please find a list of articles that proposes new techniques that aim at …,*,2012,*
Scalable Uncertainty Management: 6th International Conference; SUM 2012; Marburg; Germany; September 17-19; 2012; Proceedings,Eyke Hüllermeier; Sebastian Link; Thomas Fober; Bernhard Seeger,This book constitutes the refereed proceedings of the 6th International Conference onScalable Uncertainty Management; SUM 2012; held in Marburg; Germany; in September2012. The 41 revised full papers and 13 revised short papers were carefully reviewed andselected from 75 submissions. The papers cover topics in all areas of managing andreasoning with substantial and complex kinds of uncertain; incomplete or inconsistentinformation including applications in decision support systems; machine learning;negotiation technologies; semantic web applications; search engines; ontology systems;information retrieval; natural language processing; information extraction; image recognition;vision systems; data and text mining; and the consideration of issues such as provenance;trust; heterogeneity; and complexity of data and knowledge.,*,2012,*
Deklarative Verarbeitung von Datenströmen in Sensornetzwerken.,Daniel Klan,Zusammenfassung Sensoren finden sich heutzutage in vielen Teilen des täglichen Lebens.Sie dienen dabei der Erfassung und Uberführung von physikalischen oder chemischenEigenschaften in digital auswertbare Größen. Drahtlose Sensornetzwerke als Mittel zurgroßflächigen; weitestgehend autarken Uberwachung von Regionen oder Gebäuden sindTeil dieser Brücke und halten immer stärker Einzug in den industriellen Einsatz. DieEntwicklung von geeigneten Systemen ist mit einer Vielzahl von Herausforderungenverbunden. Aktuelle Lösungen werden oftmals gezielt für eine spezielle Aufgabe entworfen;welche sich nur bedingt für den Einsatz in anderen Umgebungen eignen. Die sichwiederholende Neuentwicklung entsprechender verteilter Systeme sowohl aufHardwareebene als auch auf Softwareebene; zählt zu den wesentlichen Gründen …,*,2011,*
From Event-Driven Business Process Management to Ubiquitous Complex Event Processing,Rainer von Ammon,1. An instance of a transaction process is started in the case of withdrawing at a certain ATM.2. A lot of process instances of the same type are instantiated in a more or less short/certaintimeframe at different ATM's. 3. Each process step generates an event; if so of different eventtypes (JMS publish/subscribe; special ATM-banking event type according to the bankingstandard “<…>” 4. The global event cloud is analyzed in real-time by the CEP-system andoptionally by some “intelligent” components like discriminant analysis and neural networks.A suspicious event pattern is detected because the login-data respectively the card is usedmore than once and at different locations in a timeframe whereas a service is called in orderto check the probability that the same customer could use the same card at the differentlocations. 5.…< see Mona+ 09 paper>,*,2009,*
IT-Supported Long-Term Risk Analysis for the Savigny Estate at Marburg University Library,Ulrike Hähner; Bernhard Seeger,Abstract Machine learning and data mining in information technology can assist in theassessment of documents endangered in the long term by ink corrosion. Using this kind ofdata collection; useful information could be extrapolated; such as the stages of the progressof ink corrosion and the inclusion of external damage factors. In this way; the change inmanuscripts resulting from differing storage conditions could be simulated in order tosupport decisions taken about the choice of treatment. In addition; criteria forrecommendations could be assembled by means of machine learning processes; whichcould form a decision-making tool about treatment options. In order to create such a system;it is necessary to establish damage stages; key words as a threshold value forrecommendations and for the assignment of additional distinguishing features such as …,Restaurator,2009,*
Mehrdimensionale Indexstrukturen: Die Geister; die ich rief;...,Bernhard Seeger,Zusammenfassung Vor etwa 25 Jahren war eine der zentralen Forschungsfragestellungen;wie dynamische; eindimensionale Indexstrukturen für mehrdimensionale Daten so erweitertwerden können; dass die bekannten Leistungseigenschaften eindimensionaler Strukturenerhalten bleiben. Im Zuge dessen wurden Hash-Verfahren; wie das Grid-File; und diverseBaumstrukturen; wie der R-Baum; entwickelt. Primäres Ziel war es dabei Suchoperationen;wie z. B. die Fensteranfrage; für zweidimensionale Geo-Daten effizient zu unterstützen. ImZuge dessen arbeitete ich in der Arbeitsgruppe von Professor Kriegel maßgeblich an derEntwicklung von Hash-basierten Zugriffstrukturen mit. Man sprach damals vonordnungserhaltenden Hash-Verfahren; eigentlich hätte der Begriff Interpolationsverfahrenbesser gepasst. Auf Grund der Suche nach experimentellen Vergleichsstrukturen …,Grundlagen von Datenbanken,2008,*
Auf dem Weg zur allwissenden Fabrik,Christoph Heinz; Jürgen Krämer; Tobias Riemenschneider; Bernhard Seeger,Page 1. Auf dem Weg zur allwissenden Fabrik Vertikale Integration auf Basis kontinuierlicherDatenverarbeitung Christoph Heinz; Jürgen Krämer; Tobias Riemenschneider; Bernhard Seeger27.09.2007 Page 2. Agenda ∎ Production Intelligence □ Vertikale Integration und deren Nutzen ∎Kontinuierliche Anfragen über Datenströmen □ Spezifikation und Verarbeitungsprinzipien p gpp ∎ Unsere Softwareinfrastruktur PIPES □ Architekturelle Grundlagen und Funktionsumfang □Architekturelle Grundlagen und Funktionsumfang ∎ Einsatz von PIPES in der Fabrikautomation □K l di I t ti iddl i Pl t □ Kopplung an die Integrationsmiddleware i-Plant □ Synergieeffekte K D 2 □Kurze Demo Page 3. Agenda ∎ Production Intelligence □ Vertikale Integration und deren Nutzen ∎Kontinuierliche Anfragen über Datenströmen □ Spezifikation und Verarbeitungsprinzipien p gpp ∎ Unsere Softwareinfrastruktur PIPES …,*,2007,*
Online-Data-Mining auf Datenströmen,Jürgen Beringer,*,*,2007,*
International Conference on Semantics of a Networked World: Semantics of Sequence and Time Dependent Data (ICSNW'06)-Dynamic Plan Migration for Snapshot...,Jurgen Kramer; Yin Yang; Michael Cammert; Bernhard Seeger; Dimitris Papadias,Sign in | Create an account. PhilPapers PhilArchive PhilEvents PhilJobs. PhilPapers home. Syntax;Advanced Search. New: All new items; Books; Journal articles; Manuscripts. Topics: All Categories;Metaphysics and Epistemology: Metaphysics and Epistemology; Epistemology; Metaphilosophy;Metaphysics; Philosophy of Action; Philosophy of Language; Philosophy of Mind; Philosophyof Religion; M&E; Misc. Value Theory: Value Theory; Aesthetics; Applied Ethics; Meta-Ethics;Normative Ethics; Philosophy of Gender; Race; and Sexuality; Philosophy of Law; Social andPolitical Philosophy; Value Theory; Miscellaneous. Science; Logic; and Mathematics: Science;Logic; and Mathematics; Logic and Philosophy of Logic; Philosophy of Biology; Philosophy …,*,2006,*
51. Jahrestagung der Deutschen Gesellschaft für Medizinische Informatik; Biometrie und Epidemiologie,Ursula Hübner,Deutsche Gesellschaft für Medizinische Informatik; Biometrie und Epidemiologie e. V.(gmds) … Nutzung gemeinsamer IT Strukturen im Rahmen der … Integrierten Versorgung:aktueller Stand and Pläne aus … Deutsche Gesellschaft für Medizinische Informatik; Biometrieund Epidemiologie eV (gmds). 51. Jahrestagung der Deutschen Gesellschaft für MedizinischeInformatik; Biometrie und Epidemiologie. Leipzig; 10.-14.09.2006. Düsseldorf; Köln: GermanMedical Science; 2006. Doc06gmds306 … Die elektronische Version dieses Artikels ist vollständigund ist verfügbar unter: http://www.egms.de /de/meetings/gmds2006/06gmds341.shtml … ©2006 Hübner. Dieser Artikel ist ein Open Access-Artikel und steht unter den Creative CommonsLizenzbedingungen (http://creativecommons.org /licenses/by-nc-nd/3.0/deed.de ). Er darfvervielf&aauml;ltigt; verbreitet und &oauml;ffentlich zug&aauml;nglich gemacht werden …,*,2006,*
Design and Implementation of a Geographic Search Engine,Torsten Suel; Alexander Markowetz; Yen Yu Chen; Xiaohui Long; B Seeger,Suel; T; Markowetz; A; Chen; YY; Long; X & Seeger; B 2005; Design and Implementation of aGeographic Search Engine. in 8th International Workshop on the Web and Databases(WebDB) … Suel T; Markowetz A; Chen YY; Long X; Seeger B. Design and Implementationof a Geographic Search Engine. In 8th International Workshop on the Web and Databases(WebDB). 2005 … Suel; Torsten ; Markowetz; Alexander ; Chen; Yen Yu ; Long; Xiaohui ;Seeger; B. / Design and Implementation of a Geographic Search Engine. 8th International Workshopon the Web and Databases (WebDB). 2005 … Powered by Pure; Scopus & Elsevier FingerprintEngine™ © 2018 Elsevier BV.,*,2005,*
Core Database Technology Program Committee,Anastassia Ailamaki; Gustavo Alonso; Walid Aref; Lars Arge; Brian Babcock; Mikael Berndtsson; Elisa Bertino; Claudio Bettini; Michael Boehlen; Anthony Bonner; Philippe Bonnet; Alex Buchmann; Tiziana Catarci; Surajit Chaudhuri; Peter Dadam; Amol Deshpande; Asuman Dogac; Christos Faloutsos; Elena Ferrari; Johann-Christoph Freytag; Dieter Gawlick; Johannes Gehrke; Torsten Grust; Ralf Hartmut Güting; Jayant Haritsa; Chris Jermaine; Christoph Koch; George Kollios; Mong Li Lee; Wolfgang Lindner; David Lomet; Hongjun Lu; Samuel Madden; Giansalvatore Mecca; Alberto Mendelzon; Rosa Meo; Tova Milo; Michele Missikoff; C Mohan; Mario Nascimento; Shojiro Nishio; Ed Omiecinski; Norman Paton; Torben Bach Pedersen; Calton Pu; Philippe Pucheral; Raghu Ramakrishnan; Thomas Rölleke; Ken Ross; Gunther Saake; Albrecht Schmidt; Marc Scholl; Bernhard Seeger,Committee Chair: Martin Kersten; CWI; The Netherlands … Serge Abiteboul; INRIA; France AnastassiaAilamaki; Carnegie Mellon University; USA Gustavo Alonso; ETH Zurich; Switzerland WalidAref; Purdue University; USA Lars Arge; Aarhus University; Denmark Brian Babcock; StanfordUniversity; USA Mikael Berndtsson; University of Skövde; Sweden Elisa Bertino; PurdueUniversity; USA Claudio Bettini; University of Milan; Italy Michael Boehlen; Free University ofBolzano/Bozen; Italy Peter Boncz; CWI; The Netherlands Anthony Bonner; University ofToronto; Canada Philippe Bonnet; University of Copenhagen; Denmark Alex Buchmann; Universityof Darmstadt; Germany Tiziana Catarci; University of Rome 'La Sapienza'; Italy SurajitChaudhuri; Microsoft; USA Vassilis Christophides; FORTH; Greece Peter Dadam; Universityof Ulm; Germany Amol Deshpande; University of California; Berkeley; USA Asuman …,VLDB 2005: 31st International Conference on Very Large Data Bases: Proceedings of the 31st International Conference on Very Large Data Bases; Trondheim; Norway; August 30-September 2; 2005,2005,*
Geographical Information Systems,Bernhard Seeger; Peter Widmayer,*,*,2004,*
PIPES–A Public Infrastructure for Processing and Exploring Streams,Bernhard Seeger,Abstract PIPES is a flexible and extensible infrastructure offering fundamental buildingblocks that allow the construction of a fully functional prototype of a data streammanagement system (DSMS). It is seamlessly integrated into the Java library XXL [5; 7] foradvanced query processing and extends its scope towards continuous data-driven queryprocessing over autonomous data sources. Our demonstration considers two realisticscenarios as example applications; namely traffic management and online auctions; whoserelevance results from the fact that these represent a foundation for the development ofbenchmarks in stream processing. Subsequently; we will demonstrate how PIPES can beemployed to these application domains. We will illustrate the construction and execution ofquery plans based on our generic operations. This is accomplished by a visual style of …,In Proceedings of the 2004 ACM SIGMOD international conference on Managementof data; pages 925–926,2004,*
Advances in Spatial and Temporal Databases: 7th International Symposium; SSTD 2001; Redondo Beach; CA; USA; July 12-15; 2001 Proceedings,Christian S Jensen; Markus Schneider; Bernhard Seeger; Vassilis J Tsotras,The Seventh International Symposium on Spatial and Temporal Databases (SSTD 2001);held in Redondo Beach; CA; USA; July 12 {15; 2001; brought together leading researchersand developers in the area of spatial; temporal; and spatio-temporal databases to discussthe state of the art in spatial and temporal data management and applications; and tounderstand the challenges and-search directions in the advancing area of datamanagement for moving objects. The symposium served as a forum for disseminatingresearch in spatial and temporal data management; and for maximizing the interchange ofknowledge among researchers from the established spatial and temporal database com-nities. The exchange of research ideas and results not only contributes to the academicarena; but also bene ts the user and commercial communities. SSTD 2001 was the …,*,2003,*
Introduction to special issue with best papers from EDBT 2002,Christian S Jensen,*,*,2003,*
Temporal and spatio-temporal aggregations are important but costly operations for applications that maintain time-evolving data (data warehouses; temporal databa...,Donghui Zhang; Dimitrios Gunopulos; Vassilis J Tsotras; Bernhard Seeger,The success of Internet applications has led to an explosive growth in the demand forbandwidth from Internet Service Providers. Managing an Internet protocol network requirescollecting and analyzing network data; such as flow-level traffic statistics. Such analyses cantypically be expressed as OLAP queries; eg; correlated aggregate queries and data cubes.Current day OLAP tools for this task...,Information Systems,2003,*
Data Engineering,Michael Cammert; Christoph Heinz; Jürgen Krämer; Martin Schneider; Bernhard Seeger,Abstract Designing and tuning access methods (AMs) has always been more of a black artthan a rigorous discipline; with performance assessments being mostly reduced topresenting aggregate runtime or I/O numbers. This paper presents amdb; a comprehensivegraphical design tool for AMs that are constructed on top of the Generalized Search Treeabstraction. At the core of amdb lies an an analysis framework for AMs that definesperformance metrics that are more useful than traditional summary numbers and therebyallow the AM designer to detect and isolate deficiencies in an AM design. Amdbcomplements the analysis framework with visualization and debugging functionality;allowing the AM designer to investigate the source of those deficiencies that were brought tolight with the help of the performance metrics. Several AM design projects undertaken at …,Urbana,2003,*
Query Systems-PlugJoin,Jochen van den Bercken; Martin Schneider; Bernhard Seeger,*,Lecture Notes in Computer Science,2000,*
The Bulk Index Join,Jochen van den Bercken; Bernhard Seeger; Peter Widmayer,*,15th International Conference on Data Engineering: proceedings: March 23-26; 1999; Sydney; Autralia,1999,*
Ludwig-Maximilians-Universit at M unchen Institut f ur Informatik Bericht 9419,Bernhard Seeger,*,*,1994,*
Low-level I/O Optimization in Database Systems: A Case for Multi-page Requests,Bernhard Seeger,Abstract Magnetic disks are the most important storage medium today and are expected toplay that role for at least the next ten years. Database systems primarily use magnetic diskdrives as their directly accessible persistent storage device. The performance of magneticdisk drives has been considerably improved over the last 25 years. However; theimprovement rates are far behind those achieved for processors. This is the most importantreason that the I/O to magnetic disks has been more and more the bottleneck of manydatabase applications; in particular of non-standard applications. This thesis starts with asurvey on common low-level techniques to improve the I/O performance of computersystems. Thereafter; the current magnetic disk technology is discussed in great details. Therest of the thesis is then dedicated to studying the impact of multi-page requests on query …,*,1994,*
Making Access Structures Partially Persistent,Bruno Becker; Stephan Gschwind; Thomas Ohler; Bernhard Seeger; Peter Widmayer,Abstract We present a general technique to make an important class of hierarchical externalaccess structures (including B--trees) partially persistent at no extra time or space costasymptotically; this behavior had not even been achieved for B--trees previously.,*,1992,*
Retrieving of parts with geometric similarity,Ralf Schneider; H-P Kriegel; Bernhard Seeger; Stephan Heep,Abstract Todays CAD applications become less and less manageable if no database systemis used. One of the most important queries in these applications is the retrieval of parts withgeometric similarity. The information obtained from such similar parts will drastically reducethe overhead for production planning and construction. In available retrieval andclassification systems parts are described using attributes comparable to those in traditionaldatabase systems. In our paper; we suggest a system for retrieval of parts with geometricsimilarity which accesses to a database system storing the geometric data provided by theCAD system. By maintaining; storing and manipulating the complete geometric informationof objects; our approach exhibits a flexibility and efficiency for similarity and other querieswhich is not known in available systems.,International Conference on Foundations of Data Organization and Algorithms,1989,*
51. Jahrestagung der Deutschen Gesellschaft für Medizinische Informatik; Biometrie und Epidemiologie,N Grabe; P Tomakidi; T Pommerencke; S Huber; D Müller; T Steinberg; K Neuber; H Dickhaus,Es konnten insgesamt 12 Studien identifiziert werden. Von diesen wurden zwei von dreiStudien der gleichen Autorengruppe aufgrund Mehrfachpublikation der gleichen Daten nichtin die Auswertungen einbezogen. Bei zwei weiteren Publikationen wurden überlappendeTeile des Datenkörpers mehrfach ausgewertet. Hier wurde eine der beiden Studieneingeschlossen und in Sensitivitätsanalysen die Auswirkung der Auswahl auf die gepooltenSchätzer untersucht.,*,*,*
Big (and Small) Data in Science and Humanities,Anika Groß; Birgitta König-Ries; Peter Reimann; Bernhard Seeger,The importance of data has dramatically increased in almost all scientiĄc disciplines overthe last decade; eg; in meteorology; genomics; complex physics simulations; biological andenvironmental research; and recently also in humanities. This development is due to greatadvances in data acquisition and data accessibility; such as improvements in remotesensing; powerful mobile devices; popularity of social networks and the ability to handleunstructured data (including texts). On the one hand; the availability of such data massesleads to a rethinking in scientiĄc disciplines on how to extract useful information and on howto foster research. On the other hand; researchers feel lost in the data masses becauseappropriate data management; integration; analysis and visualization tools have not beenavailable so far. However; this is starting to change with the recent development of big …,*,*,*
Invited Project Review,Christian S Jensen; Richard T Snodgrass; Kamalakar Karlapalem; Shamkant B Navathe; Mostafa Ammar; Valery Soloviev; Bernhard Seeger; Alexander Thomasian; Mengchi Liu; Andrew Johnson; Farshad Fotouhi; Duen-Ren Liu; Shashi Shekhar; Ricardo Baeza-Yates; Eduardo F Barbosa; Nivio Ziviani,*,*,*,*
Effiziente Algorithmen,Bernhard Seeger,*,*,*,*
SSTD 2001: advances in spatial and temporal databases(Redondo Beach CA; 12-15 July 2001),Christian S Jensen; Markus Schneider; Bernhard Seeger; Vassilis J Tsotras,*,Lecture notes in computer science,*,*
Informatik II,Bernhard Seeger,Page 1. Informatik II Universität Marburg 1. Informatik II Bernhard Seeger FachbereichMathematik und Informatik Universität Marburg email: seeger@informatik.uni-marburg.deTel.: 28-1526 Sprechstunde: freitags; 10-12 Uhr und nach Vereinbarung Page 2. InformatikII Universität Marburg 2. Literatur Literatur ❑ Einführung in die Informatik – Goldschlager; Lister:“Informatik - Eine moderne Einführung”; Hanser – Gumm; Sommer: “Einführung in dieInformatik”; Addison-Wesley – Rechenberg: “Was ist Informatik”; Hanser Verlag – Goos:“Vorlesungen über Informatik”; Band 2 (Objektorientiertes Programmieren und Algorithmen);Springer; 1996. ❑ Objektorientiertes Programmieren – Goos: “Vorlesungen über Informatik”;Band 2 (Objektorientiertes Programmieren und Algorithmen); Springer; 1996. – Meyer:“Object-Oriented Software Construction”; Prentice Hall; 1988. JAVA …,*,*,*
Objektorientierter Entwurf und Implementierung effizienter Datenstrukturen,Bernhard Seeger,*,*,*,*
Geo-Informatik,KH Müller; B Seeger,*,*,*,*
Low-Level I/O Optimization in Database Systems,Bernhard Seeger,*,*,*,*
Fachbereich Mathematik und Informatik; Universität Marburg; D-35032 Marburg; Germany 2 Institut für Theoretische Informatik; ETH-Zentrum; CH-8092 Zürich; Switz...,Jochen van den Bercken; Bernhard Seeger; Peter Widmayer,Abstract: Efficient join algorithms have been developed for processing different types of non-equijoins like spatial join; band join; temporal join or similarity join. Each of these previouslyproposed join algorithms is tailor-cut for a specific type of join; and a generalization of thesealgorithms to other join types is not obvious. We present an efficient algorithm called bulkindex join that can be easily applied to a broad class of non-equijoins. Similar to the well-known hash join algorithms; the bulk index join performs in two phases. In the build-phase;an appropriate index structure is created that serves as a partitioning function on the firstrelation. In the probing-phase; the records of the second relation are probed against the firstrelation by using the index structure of the build-phase. In order to support both phasesefficiently; we adopt a technique recently proposed for bulk loading index structures. We …,*,*,*
Temporal Aggregation with Range Predicates,Donghui Zhang; Alexander Markowetz; Vassilis Tsotras; Dimitrios Gunopulos; Bernhard Seeger,Abstract A temporal aggregation query is an important but costly operation for applicationsthat maintain time-evolving data (data warehouses; temporal databases; etc.). Due to thelarge volume of such data; performance improvements for temporal aggregation queries arecritical. Previous approaches have aggregate predicates that involve only the timedimension. In this paper we examine techniques to compute temporal aggregates thatinclude key-range predicates as well (range-temporal aggregates). In particular weconcentrate on the SUM aggregate; while COUNT is a special case. This problem is novel;to handle arbitrary key ranges; previous methods would need to keep a separate index forevery possible key range. We propose an approach based on a new index structure calledthe Multiversion SB-Tree; which incorporates features from both the SB-Tree and the …,*,*,*
