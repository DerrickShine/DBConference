Data mining and analysis: fundamental concepts and algorithms,Mohammed J Zaki; Wagner Meira Jr; Wagner Meira,The fundamental algorithms in data mining and analysis form the basis for the emergingfield of data science; which includes automated methods to analyze patterns and models forall kinds of data; with applications ranging from scientific discovery to business intelligenceand analytics. This textbook for senior undergraduate and graduate data mining coursesprovides a broad yet in-depth overview of data mining; integrating related concepts frommachine learning and statistics. The main parts of the book include exploratory dataanalysis; pattern mining; clustering; and classification. The book lays the basic foundationsof these tasks; and also covers cutting-edge topics such as kernel methods; high-dimensional data analysis; and complex graphs and networks. With its comprehensivecoverage; algorithmic perspective; and wealth of examples; this book offers solid …,*,2014,409
A hierarchical characterization of a live streaming media workload,Eveline Veloso; Virgílio Almeida; Wagner Meira; Azer Bestavros; Shudong Jin,Abstract We present what we believe to be the first thorough characterization of livestreaming media content delivered over the Internet. Our characterization of over 3.5 millionrequests spanning a 28-day period is done at three increasingly granular levels;corresponding to clients; sessions; and transfers. Our findings support two importantconclusions. First; we show that the nature of interactions between users and objects isfundamentally different for live versus stored objects. Access to stored objects is user driven;whereas access to live objects is object driven. This reversal of active/passive roles of usersand objects leads to interesting dualities. For instance; our analysis underscores a Zipf-likeprofile for user interest in a given object; which Is in contrast to the classic Zipf-like popularityof objects for a given user. Also; our analysis reveals that transfer lengths are highly …,Proceedings of the 2nd ACM SIGCOMM Workshop on Internet measurment,2002,357
Energy conservation in heterogeneous server clusters,Taliver Heath; Bruno Diniz; Enrique V Carrera; Wagner Meira Jr; Ricardo Bianchini,Abstract The previous research on cluster-based servers has focused on homogeneoussystems. However; real-life clusters are almost invariably heterogeneous in terms of theperformance; capacity; and power consumption of their hardware components. In this paper;we argue that designing efficient servers for heterogeneous clusters requires defining anefficiency metric; modeling the different types of nodes with respect to the metric; andsearching for request distributions that optimize the metric. To concretely illustrate thisprocess; we design a cooperative Web server for a heterogeneous cluster that usesmodeling and optimization to minimize the energy consumed per request. Our experimentalresults for a cluster comprised of traditional and blade nodes show that our server canconsume 42% less energy than an energy-oblivious server; with only a negligible loss in …,Proceedings of the tenth ACM SIGPLAN symposium on Principles and practice of parallel programming,2005,325
Characterizing a spam traffic,Luiz Henrique Gomes; Cristiano Cazita; Jussara M Almeida; Virgílio Almeida; Wagner Meira Jr,Abstract The rapid increase in the volume of unsolicited commercial e-mails; also known asspam; is beginning to take its toll in system administrators; business corporations and end-users. Widely varying estimates of the cost associated with spam are available in theliterature. However; a quantitative analysis of the determinant characteristics of spam trafficis still an open problem. This work fills this gap and presents what we believe to be the firstextensive characterization of a spam traffic. As basis for our characterization; standard spamdetection techniques are used to classify over 360 thousand incoming e-mails to a largeuniversity into two categories; namely spam and non-spam. For each of the two resultingworkloads; as well as for the aggregate workload; we analyze a set of parameters; aiming atidentifying the characteristics that significantly distinguish spam from non-spam traffic …,Proceedings of the 4th ACM SIGCOMM conference on Internet measurement,2004,179
Rank-preserving two-level caching for scalable search engines,Patricia Correia Saraiva; Edleno Silva de Moura; Nivio Ziviani; Wagner Meira; Rodrigo Fonseca; Berthier Ribeiro-Neto,ABSTRACT We present an effective caching scheme that reduces the computing and I/Orequirements of a Web search engine without altering its ranking characteristics. The noveltyis a two-level caching scheme that simultaneously combines cached query results andcached inverted lists on a real case search engine. A set of log queries are used to measureand compare the performance and the scalability of the search engine with no cache; withthe cache for query results; with the cache for inverted lists; and with the two-level cache.Experimental results show that the two-level cache is superior; and that it allows increasingthe maximum number of queries processed per second by a factor of three; while preservingthe response time. These results are new; have not been reported before; and demonstratethe importance of advanced caching schemes for real case search engines.,Proceedings of the 24th annual international ACM SIGIR conference on Research and development in information retrieval,2001,176
In search of invariants for e-business workloads,Daniel Menascé; Virgílio Almeida; Rudolf Riedi; Flávia Ribeiro; Rodrigo Fonseca; Wagner Meira Jr,ABSTRACT Understanding the nature and characteristics of e-business workloads is acrucial step to improve the quality of service offered to customers in electronic businessenvironments. However; the variety and complexity of the interactions between customersand sites make the characterization of ebusiness workloads a challenging problem. Using amultilayer hierarchical model; this paper presents a detailed characterization of the workloadof two actual e-business sites: an online bookstore and an electronic auction site. Throughthe characterization process; we found the presence of autonomous agents; or robots; in theworkload and used the hierarchical structure to determine their characteristics. We alsofound that search terms follow a Zipf distribution.,Proceedings of the 2nd ACM conference on Electronic commerce,2000,164
Lazy associative classification,Adriano Veloso; Wagner Meira Jr; Mohammed J Zaki,Decision tree classifiers perform a greedy search for rules by heuristically selecting the mostpromising features. Such greedy (local) search may discard important rules. Associativeclassifiers; on the other hand; perform a global search for rules satisfying some qualityconstraints (ie; minimum support). This global search; however; may generate a largenumber of rules. Further; many of these rules may be useless during classification; andworst; important rules may never be mined. Lazy (non-eager) associative classificationovercomes this problem by focusing on the features of the given test instance; increasing thechance of generating more rules that are useful for classifying the test instance. In this paperwe assess the performance of lazy associative classification. First we demonstrate that anassociative classifier performs no worse than the corresponding decision tree classifier …,Data Mining; 2006. ICDM'06. Sixth International Conference on,2006,161
Dengue surveillance based on a computational model of spatio-temporal locality of Twitter,Janaína Gomide; Adriano Veloso; Wagner Meira Jr; Virgílio Almeida; Fabrício Benevenuto; Fernanda Ferraz; Mauro Teixeira,Abstract Twitter is a unique social media channel; in the sense that users discuss and talkabout the most diverse topics; including their health conditions. In this paper we analyzehow Dengue epidemic is reflected on Twitter and to what extent that information can be usedfor the sake of surveillance. Dengue is a mosquito-borne infectious disease that is a leadingcause of illness and death in tropical and subtropical regions; including Brazil. We proposean active surveillance methodology that is based on four dimensions: volume; location; timeand public perception. First we explore the public perception dimension by performingsentiment analysis. This analysis enables us to filter out content that is not relevant for thesake of Dengue surveillance. Then; we verify the high correlation between the number ofcases reported by official statistics and the number of tweets posted during the same time …,Proceedings of the 3rd international web science conference,2011,149
Limiting the power consumption of main memory,Bruno Diniz; Dorgival Guedes; Wagner Meira Jr; Ricardo Bianchini,Abstract The peak power consumption of hardware components affects their powersupply;packaging; and cooling requirements. When the peak power consumption is high; thehardware components or the systems that use them can become expensive and bulky.Given that components and systems rarely (if ever) actually require peak power; it is highlydesirable to limit power consumption to a less-than-peak power budget; based on whichpower supply; packaging; and cooling infrastructure scan be more intelligently provisioned.In this paper; we study dynamic approaches for limiting the powerconsumption of mainmemories. Specifically; we propose four techniques that limit consumption by adjusting thepower states of thememory devices; as a function of the load on the memory subsystem. Oursimulations of applications from three benchmarks demonstrate that our techniques can …,ACM SIGARCH Computer Architecture News,2007,141
Studying user footprints in different online social networks,Anshu Malhotra; Luam Totti; Wagner Meira Jr; Ponnurangam Kumaraguru; Virgilio Almeida,With the growing popularity and usage of online social media services; people now haveaccounts (some times several) on multiple and diverse services like Facebook; Linked In;Twitter and You Tube. Publicly available information can be used to create a digital footprintof any user using these social media services. Generating such digital footprints can be veryuseful for personalization; profile management; detecting malicious behavior of users. A veryimportant application of analyzing users' online digital footprints is to protect users frompotential privacy and security risks arising from the huge publicly available user information.We extracted information about user identities on different social networks through SocialGraph API; Friend Feed; and Profilactic; we collated our own dataset to create the digitalfootprints of the users. We used username; display name; description; location; profile …,Advances in Social Networks Analysis and Mining (ASONAM); 2012 IEEE/ACM International Conference on,2012,135
From bias to opinion: a transfer-learning approach to real-time sentiment analysis,Pedro Henrique Calais Guerra; Adriano Veloso; Wagner Meira Jr; Virgílio Almeida,Abstract Real-time interaction; which enables live discussions; has become a key feature ofmost Web applications. In such an environment; the ability to automatically analyze useropinions and sentiments as discussions develop is a powerful resource known as real timesentiment analysis. However; this task comes with several challenges; including the need todeal with highly dynamic textual content that is characterized by changes in vocabulary andits subjective meaning and the lack of labeled data needed to support supervised classifiers.In this paper; we propose a transfer learning strategy to perform real time sentiment analysis.We identify a task-opinion holder bias prediction-which is strongly related to the sentimentanalysis task; however; in constrast to sentiment analysis; it builds accurate models sincethe underlying relational data follows a stationary distribution. Instead of learning textual …,Proceedings of the 17th ACM SIGKDD international conference on Knowledge discovery and data mining,2011,115
Watch me playing; i am a professional: a first study on video game live streaming,Mehdi Kaytoue; Arlei Silva; Loïc Cerf; Wagner Meira Jr; Chedy Raïssi,Abstract" Electronic-sport"(E-Sport) is now established as a new entertainment genre. Moreand more players enjoy streaming their games; which attract even more viewers. In fact; in arecent social study; casual players were found to prefer watching professional gamers ratherthan playing the game themselves. Within this context; advertising provides a significantsource of revenue to the professional players; the casters (displaying other people's games)and the game streaming platforms. For this paper; we crawled; during more than 100 days;the most popular among such specialized platforms: Twitch. tv. Thanks to these gigabytes ofdata; we propose a first characterization of a new Web community; and we show; amongother results; that the number of viewers of a streaming session evolves in a predictableway; that audience peaks of a game are explainable and that a Condorcet method can be …,Proceedings of the 21st International Conference on World Wide Web,2012,114
VM-based shared memory on low-latency; remote-memory-access networks,Leonidas Kontothanassis; Galen Hunt; Robert Stets; Nikolaos Hardavellas; Michał Cierniak; Srinivasan Parthasarathy; Wagner Meira Jr; Sandhya Dwarkadas; Michael Scott,Abstract Recent technological advances have produced network interfaces that provideusers with very low-latency access to the memory of remote machines. We examine theimpact of such networks on the implementation and performance of software DSM.Specifically; we compare two DSM systems---Cashmere and TreadMarks---on a 32-processor DEC Alpha cluster connected by a Memory Channel network. Both Cashmereand TreadMarks use virtual memory to maintain coherence on pages; and both use lazy;multi-writer release consistency. The systems differ dramatically; however; in themechanisms used to track sharing information and to collect and merge concurrent updatesto a page; with the result that Cashmere communicates much more frequently; and at amuch finer grain. Our principal conclusion is that low-latency networks make DSM based …,ACM SIGARCH Computer Architecture News,1997,114
Coordinating the use of GPU and CPU for improving performance of compute intensive applications,George Teodoro; Rafael Sachetto; Olcay Sertel; Metin N Gurcan; Wagner Meira; Umit Catalyurek; Renato Ferreira,GPUs have recently evolved into very fast parallel co-processors capable of executinggeneral purpose computations extremely efficiently. At the same time; multi-core CPUsevolution continued and today's CPUs have 4-8 cores. These two trends; however; havefollowed independent paths in the sense that we are aware of very few works that considerboth devices cooperating to solve general computations. In this paper we investigate thecoordinated use of CPU and GPU to improve efficiency of applications even further thanusing either device independently. We use Anthill runtime environment; a data-flow orientedframework in which applications are decomposed into a set of event-driven filters; where foreach event; the runtime system can use either GPU or CPU for its processing. Forevaluation; we use a histopathology application that uses image analysis techniques to …,Cluster Computing and Workshops; 2009. CLUSTER'09. IEEE International Conference on,2009,96
Mining frequent itemsets in evolving databases,AA Veloso; Wagner Meira Jr; MB de Carvalho; Bruno Pôssas; Srinivasan Parthasarathy; M Javeed Zaki,1 Introduction The field of knowledge discovery and data mining (KDD); spurred byadvances in data collection technology; is concerned with the process of deriving interestingand useful patterns from large datasets. The KDD process is computational and data-intensive and is inherently interactive and iterative in nature. In fact; interactivity is often thekey to facilitating effective data understanding and knowledge discovery. In such anenvironment; response time is crucial because lengthy time delay between responses ofconsecutive user requests can disturb the flow of human perception and formation of insight.The task of guaranteeing quick response times is more complicated in dynamic datasets;where there is a constant influx of data. Changes to the data can invalidate existing patternsor introduce new. Simply re-executing algorithms from scratch when a database is …,*,2002,94
Mining attribute-structure correlated patterns in large attributed graphs,Arlei Silva; Wagner Meira Jr; Mohammed J Zaki,Abstract In this work; we study the correlation between attribute sets and the occurrence ofdense subgraphs in large attributed graphs; a task we call structural correlation patternmining. A structural correlation pattern is a dense subgraph induced by a particular attributeset. Existing methods are not able to extract relevant knowledge regarding how vertexattributes interact with dense subgraphs. Structural correlation pattern mining combinesaspects of frequent itemset and quasi-clique mining problems. We propose statisticalsignificance measures that compare the structural correlation of attribute sets against theirexpected values using null models. Moreover; we evaluate the interestingness of structuralcorrelation patterns in terms of size and density. An efficient algorithm that combines searchand pruning strategies in the identification of the most relevant structural correlation …,Proceedings of the VLDB Endowment,2012,93
Ladies First: Analyzing Gender Roles and Behaviors in Pinterest.,Raphael Ottoni; Joao Paulo Pesce; Diego B Las Casas; Geraldo Franciscani Jr; Wagner Meira Jr; Ponnurangam Kumaraguru; Virgílio AF Almeida,Abstract Online social networks (OSNs) have become popular platforms for people toconnect and interact with each other. Among those networks; Pinterest has recently becomenoteworthy for its growth and promotion of visual over textual content. The purpose of thisstudy is to analyze this imagebased network in a gender-sensitive fashion; in order tounderstand (i) user motivation and usage pattern in the network;(ii) how communicationsand social interactions happen and (iii) how users describe themselves to others. This workis based on more than 220 million items generated by 683;273 users. We were able to findsignificant differences wrt all mentioned aspects. We observed that; although the networkdoes not encourage direct social communication; females make more use of lightweightinteractions than males. Moreover; females invest more effort in reciprocating social links …,ICWSM,2013,84
Learning to rank at query-time using association rules,Adriano A Veloso; Humberto M Almeida; Marcos A Gonçalves; Wagner Meira Jr,Abstract Some applications have to present their results in the form of ranked lists. This is thecase of many information retrieval applications; in which documents must be sortedaccording to their relevance to a given query. This has led the interest of the informationretrieval community in methods that automatically learn effective ranking functions. In thispaper we propose a novel method which uncovers patterns (or rules) in the training dataassociating features of the document with its relevance to the query; and then uses thediscovered rules to rank documents. To address typical problems that are inherent to theutilization of association rules (such as missing rules and rule explosion); the proposedmethod generates rules on a demand-driven basis; at query-time. The result is an extremelyfast and effective ranking method. We conducted a systematic evaluation of the proposed …,Proceedings of the 31st annual international ACM SIGIR conference on Research and development in information retrieval,2008,84
Word co-occurrence features for text classification,Fábio Figueiredo; Leonardo Rocha; Thierson Couto; Thiago Salles; Marcos André Gonçalves; Wagner Meira Jr,Abstract In this article we propose a data treatment strategy to generate new discriminativefeatures; called compound-features (or c-features); for the sake of text classification. These c-features are composed by terms that co-occur in documents without any restrictions on orderor distance between terms within a document. This strategy precedes the classification task;in order to enhance documents with discriminative c-features. The idea is that; when c-features are used in conjunction with single-features; the ambiguity and noise inherent totheir bag-of-words representation are reduced. We use c-features composed of two terms inorder to make their usage computationally feasible while improving the classifiereffectiveness. We test this approach with several classification algorithms and single-labelmulti-class text collections. Experimental results demonstrated gains in almost all …,Information Systems,2011,83
Distance-based outlier detection: consolidation and renewed bearing,Gustavo H Orair; Carlos HC Teixeira; Wagner Meira Jr; Ye Wang; Srinivasan Parthasarathy,Abstract Detecting outliers in data is an important problem with interesting applications in amyriad of domains ranging from data cleaning to financial fraud detection and from networkintrusion detection to clinical diagnosis of diseases. Over the last decade of research;distance-based outlier detection algorithms have emerged as a viable; scalable; parameter-free alternative to the more traditional statistical approaches. In this paper we assess severaldistance-based outlier detection approaches and evaluate them. We begin by surveying andexamining the design landscape of extant approaches; while identifying key designdecisions of such approaches. We then implement an outlier detection framework andconduct a factorial design experiment to understand the pros and cons of variousoptimizations proposed by us as well as those proposed in the literature; both …,Proceedings of the VLDB Endowment,2010,79
Divergence analysis and optimizations,Bruno Coutinho; Diogo Sampaio; Fernando Magno Quintao Pereira; Wagner Meira Jr,The growing interest in GPU programming has brought renewed attention to the SingleInstruction Multiple Data (SIMD) execution model. SIMD machines give applicationdevelopers a tremendous computational power; however; the model also brings restrictions.In particular; processing elements (PEs) execute in lock-step; and may lose performancedue to divergences caused by conditional branches. In face of divergences; some PEsexecute; while others wait; this alternation ending when they reach a synchronization point.In this paper we introduce divergence analysis; a static analysis that determines whichprogram variables will have the same values for every PE. This analysis is useful in threedifferent ways: it improves the translation of SIMD code to non-SIMD CPUs; it helpsdevelopers to manually improve their SIMD applications; and it also guides the compiler …,Parallel Architectures and Compilation Techniques (PACT); 2011 International Conference on,2011,69
Multi-label lazy associative classification,Adriano Veloso; Wagner Meira; Marcos Gonçalves; Mohammed Zaki,Abstract Most current work on classification has been focused on learning from a set ofinstances that are associated with a single label (ie; single-label classification). However;many applications; such as gene functional prediction and text categorization; may allow theinstances to be associated with multiple labels simultaneously. Multi-label classification is ageneralization of single-label classification; and its generality makes it much more difficult tosolve. Despite its importance; research on multi-label classification is still lacking. Commonapproaches simply learn independent binary classifiers for each label; and do not exploitdependencies among labels. Also; several small disjuncts may appear due to the possiblylarge number of label combinations; and neglecting these small disjuncts may degradeclassification accuracy. In this paper we propose a multi-label lazy associative classifier …,European Conference on Principles of Data Mining and Knowledge Discovery,2007,65
A characterization of broadband user behavior and their e-business activities,Humberto T Marques Neto; Jussara M Almeida; Leonardo CD Rocha; Wagner Meira; Pedro HC Guerra; Virgilio AF Almeida,Abstract This paper presents a characterization of broadband user behavior from an InternetService Provider standpoint. Users are broken into two major categories: residential andSmall-Office/Home-Office (SOHO). For each user category; the characterization is performedalong four criteria:(i) session arrival process;(ii) session duration;(iii) number of bytestransferred within a session and (iv) user request patterns. Our results show that bothresidential and SOHO session inter-arrival times are exponentially distributed. Whereasresidential session arrival rates remain relatively high during the day; SOHO session arrivalrates vary much more significantly during the day. On the other hand; a typical SOHO usersession is longer and transfers a larger volume of data. Furthermore; our analysis uncoverstwo main groups of session request patterns within each user category. The first group …,ACM SIGMETRICS Performance Evaluation Review,2004,64
Workload models of spam and legitimate e-mails,Luiz Henrique Gomes; Cristiano Cazita; Jussara M Almeida; Virgílio Almeida; Wagner Meira Jr,Abstract This article presents an extensive characterization of a spam-infected e-mailworkload. The study aims at identifying and quantifying the characteristics that significantlydistinguish spam from non-spam (ie; legitimate) traffic; assessing the impact of spam on theaggregate traffic; providing data for creating synthetic workload models; and drawinginsights into more effective spam detection techniques. Our analysis reveals significantdifferences in the spam and non-spam workloads. We conjecture that these differences areconsequence of the inherently different mode of operation of the e-mail senders. Whereaslegitimate e-mail transmissions are driven by social bilateral relationships; spamtransmissions are a unilateral spammer-driven action.,Performance Evaluation,2007,63
A hierarchical and multiscale approach to analyze E-business workloads,Daniel A Menascé; Virgilio AF Almeida; Rudolf Riedi; Flávia Ribeiro; Rodrigo Fonseca; Wagner Meira Jr,Abstract Understanding the characteristics of electronic business (E-business) workloads isa crucial step to improve the quality of service offered to customers in E-businessenvironments. This paper proposes a hierarchical and multiple time scale approach tocharacterize E-business workloads. The three levels of the hierarchy are user; application;and protocol; and are associated with customer sessions; functions requested; and HTTPrequests; respectively. Within each layer; an analysis across several time scales isconducted. The approach is illustrated by presenting a detailed characterization of twoactual E-business sites: an online bookstore and an electronic auction site. Our analysis ofthe workloads showed that the session length; measured in number of requests to execute E-business functions; is heavy-tailed; especially for sites subject to requests generated by …,Performance Evaluation,2003,62
Masks: Bringing anonymity and personalization together,Lucila Ishitani; Virgilio Almeida; Wagner Meira Jr,Unlike most privacy tools; the Masks framework gives Web sites general information about auser to personalize services but without compromising the user's identity … Note: OCR errorsmay be found in this Reference List extracted from the full text article. ACM has opted to exposethe complete List rather than only correct and linked references … S. Fox; et al.; Trust and PrivacyOnline: Why Americans Want to Rewrite the Rules; The Pew Internet & American LifeProject; Washington; DC; Aug. 2000; www.pewinternet. org/reports/toc.asp?Report=19 … "TheEnd of Privacy" editorial; The Economist; vol. 351; no. 8117; 1 May 1999; p. 15 … A. Westin;Privacy and Freedom; Bodley Head; 1987; p. 7 … MS Ackerman and LF Cranor; "PrivacyCritics—Safeguarding Users' Personal Data;" Web Techniques; Sept. 1999;www.newarchitectmag.com/archives/1999/ 09/ackerman … Lucila Ishitani; Virgilio …,IEEE Security and Privacy,2003,62
Is there a best quality metric for graph clusters?,Hélio Almeida; Dorgival Guedes; Wagner Meira; Mohammed J Zaki,Abstract Graph clustering; the process of discovering groups of similar vertices in a graph; isa very interesting area of study; with applications in many different scenarios. One of themost important aspects of graph clustering is the evaluation of cluster quality; which isimportant not only to measure the effectiveness of clustering algorithms; but also to giveinsights on the dynamics of relationships in a given network. Many quality evaluation metricsfor graph clustering have been proposed in the literature; but there is no consensus on howdo they compare to each other and how well they perform on different kinds of graphs. In thiswork we study five major graph clustering quality metrics in terms of their formal biases andtheir behavior when applied to clusters found by four implementations of classic graphclustering algorithms on five large; real world graphs. Our results show that those popular …,Joint European Conference on Machine Learning and Knowledge Discovery in Databases,2011,60
Set-based vector model: An efficient approach for correlation-based ranking,Bruno Pôssas; Nivio Ziviani; Wagner Meira Jr; Berthier Ribeiro-Neto,Abstract This work presents a new approach for ranking documents in the vector spacemodel. The novelty lies in two fronts. First; patterns of term co-occurrence are taken intoaccount and are processed efficiently. Second; term weights are generated using a datamining technique called association rules. This leads to a new ranking mechanism calledthe set-based vector model. The components of our model are no longer index terms butindex termsets; where a termset is a set of index terms. Termsets capture the intuition thatsemantically related terms appear close to each other in a document. They can be efficientlyobtained by limiting the computation to small passages of text. Once termsets have beencomputed; the ranking is calculated as a function of the termset frequency in the documentand its scarcity in the document collection. Experimental results show that the set-based …,ACM Transactions on Information Systems (TOIS),2005,59
Parallel and distributed methods for incremental frequent itemset mining,Matthew Eric Otey; Srinivasan Parthasarathy; Chao Wang; Adriano Veloso; Wagner Meira,Traditional methods for data mining typically make the assumption that the data iscentralized; memory-resident; and static. This assumption is no longer tenable. Suchmethods waste computational and input/output (I/O) resources when data is dynamic; andthey impose excessive communication overhead when data is distributed. Efficientimplementation of incremental data mining methods is; thus; becoming crucial for ensuringsystem scalability and facilitating knowledge discovery when data is dynamic anddistributed. In this paper; we address this issue in the context of the important task offrequent itemset mining. We first present an efficient algorithm which dynamically maintainsthe required information even in the presence of data updates without examining the entiredataset. We then show how to parallelize this incremental algorithm. We also propose a …,IEEE Transactions on Systems; Man; and Cybernetics; Part B (Cybernetics),2004,59
Learning to rank for content-based image retrieval,Fabio F Faria; Adriano Veloso; Humberto M Almeida; Eduardo Valle; Ricardo da S Torres; Marcos A Gonçalves; Wagner Meira Jr,Abstract In Content-based Image Retrieval (CBIR); accurately ranking the returned images isof paramount importance; since users consider mostly the topmost results. The typicalranking strategy used by many CBIR systems is to employ image content descriptors; so thatreturned images that are most similar to the query image are placed higher in the rank.While this strategy is well accepted and widely used; improved results may be obtained bycombining multiple image descriptors. In this paper we explore this idea; and introducealgorithms that learn to combine information coming from different descriptors. The proposedlearning to rank algorithms are based on three diverse learning techniques: Support VectorMachines (CBIR-SVM); Genetic Programming (CBIR-GP); and Association Rules (CBIR-AR). Eighteen image content descriptors (color; texture; and shape information) are used …,Proceedings of the international conference on Multimedia information retrieval,2010,58
Protein cutoff scanning: A comparative analysis of cutoff dependent and cutoff free methods for prospecting contacts in proteins,Carlos H da Silveira; Douglas EV Pires; Raquel C Minardi; Cristina Ribeiro; Caio JM Veloso; Julio CD Lopes; Wagner Meira; Goran Neshich; Carlos HI Ramos; Raul Habesch; Marcelo M Santoro,Abstract In this study; we carried out a comparative analysis between two classicalmethodologies to prospect residue contacts in proteins: the traditional cutoff dependent (CD)approach and cutoff free Delaunay tessellation (DT). In addition; two alternative coarse-grained forms to represent residues were tested: using alpha carbon (CA) and side chaingeometric center (GC). A database was built; comprising three top classes: all alpha; allbeta; and alpha/beta. We found that the cutoff value at about 7.0 Å emerges as an importantdistance parameter. Up to 7.0 Å; CD and DT properties are unified; which implies that at thisdistance all contacts are complete and legitimate (not occluded). We also have shown thatDT has an intrinsic missing edges problem when mapping the first layer of neighbors. Inproteins; it may produce systematic errors affecting mainly the contact network in beta …,Proteins: Structure; Function; and Bioinformatics,2009,58
Anteater: A service-oriented architecture for high-performance data mining,Dorgival Guedes; Wagner Meira; Renato Ferreira,Data mining focuses on extracting useful information from large volumes of data; and thushas been the center of much attention in recent years. Building scalable; extensible; andeasy-to-use data mining systems; however; has proved to be difficult. In response; theauthors developed Anteater; a service-oriented architecture for data mining that relies onWeb services to achieve extensibility and interoperability; offers simple abstractions forusers; and supports computationally intensive processing on large amounts of data throughmassive parallelism,IEEE Internet computing,2006,50
Waiting time analysis and performance visualization in Carnival,Wagner Meira Jr; Thomas J LeBlanc; Alexandros Poulos,Abstract Waiting time (where one processor is blocked while waiting for another) arises froma variety of sources in parallel programs; includlng communication; synchronization; loadimbalance; and resource contention. Many tools can identify portions of the source codewhere waiting time arises and measure it during execution; but the programmer must inferthe underlying cause of waiting time from other measurements. Carnival is a performancemeasurement and analysis tool that automates this inference process. Using traces ofprogram executions; the tool identifies the differences in execution paths leading up to asynchronization point; and explains waiting time to the user in terms of those differences. Italso supports several different types of performance profiles; which can be used to isolateand quantify important sources of waiting time. We present algorithms for characterizing …,Proceedings of the SIGMETRICS symposium on Parallel and distributed tools,1996,49
A Measure of Polarization on Social Media Networks Based on Community Boundaries.,Pedro Henrique Calais Guerra; Wagner Meira Jr; Claire Cardie; Robert Kleinberg,Abstract Polarization in social media networks is a fact in several scenarios such as politicaldebates and other contexts such as same-sex marriage; abortion and gun control.Understanding and quantifying polarization is a longterm challenge to researchers fromseveral areas; also being a key information for tasks such as opinion analysis. In this paper;we perform a systematic comparison between social networks that arise from both polarizedand non-polarized contexts. This comparison shows that the traditional polarization metric–modularity–is not a direct measure of antagonism between groups; since non-polarizednetworks may be also divided into fairly modular communities. To bridge this conceptualgap; we propose a novel polarization metric based on the analysis of the boundary of a pairof (potentially polarized) communities; which better captures the notions of antagonism …,ICWSM,2013,46
Anthill: A scalable run-time environment for data mining applications,Renato A Ferreira; Wagner Meira; Dorgival Guedes; Lúcia Maria de A Drummond; Bruno Coutinho; George Teodoro; Tulio Tavares; Renata Araujo; Guilherme T Ferreira,Data mining techniques are becoming increasingly more popular as a reasonable means tocollect summaries from the rapidly growing datasets in many areas. However; as the size ofthe raw data increases; parallel data mining algorithms are becoming a necessity. In thispaper; we present a run-time support system that was designed to allow the efficientimplementation of data-mining algorithms on heterogeneous distributed environments. Webelieve that the runtime framework is suitable for a broader class of applications; beyonddata mining. We also present a parallelization strategy that is supported by the run-timesystem. We show scalability results of three different data-mining algorithms that wereparallelized using our approach and our run-time support. All applications scale almostlinearly up to a large number of nodes.,Computer Architecture and High Performance Computing; 2005. SBAC-PAD 2005. 17th International Symposium on,2005,46
Mining frequent itemsets in distributed and dynamic databases,Matthew Eric Otey; Chao Wang; Srinivasan Parthasarathy; Adriano Veloso; Wagner Meira,Traditional methods for frequent itemset mining typically assume that data is centralized andstatic. Such methods impose excessive communication overhead when data is distributed;and they waste computational resources when data is dynamic. We present what we believeto be the first unified approach that overcomes these assumptions. Our approach makes useof parallel and incremental techniques to generate frequent itemsets in the presence of dataupdates without examining the entire database; and imposes minimal communicationoverhead when mining distributed databases. Further; our approach is able to generate bothlocal and global frequent itemsets. This ability permits our approach to identify high-contrastfrequent itemsets; which allows one to examine how the data is skewed over different sites.,Data Mining; 2003. ICDM 2003. Third IEEE International Conference on,2003,46
Of Pins and Tweets: Investigating How Users Behave Across Image-and Text-Based Social Networks.,Raphael Ottoni; Diego B Las Casas; Joao Paulo Pesce; Wagner Meira Jr; Christo Wilson; Alan Mislove; Virgílio AF Almeida,Abstract Today; it is the norm for online social (OSN) users to have accounts on multipleservices. For example; a recent study showed that 34% of all Twitter users also usePinterest. This situation leads to interesting questions such as: Are the activities that usersperform on each site disjoint? Alternatively; if users perform the same actions on multiplesites; where does the information originate? Given the interlinking between social networks;failure to understand activity across multiple sites may obfuscate the true informationdissemination dynamics of the social web. In this study; we take the first steps towards amore complete understanding of user behavior across multiple OSNs. We collect a sampleof over 30;000 users that have accounts on both Twitter and Pinterest; crawling their profileinformation and activity on a daily basis for a period of almost three months. We develop a …,ICWSM,2014,44
Effective sentiment stream analysis with self-augmenting training and demand-driven projection,Ismael Santana Silva; Janaína Gomide; Adriano Veloso; Wagner Meira Jr; Renato Ferreira,Abstract How do we analyze sentiments over a set of opinionated Twitter messages? Thisissue has been widely studied in recent years; with a prominent approach being based onthe application of classification techniques. Basically; messages are classified according tothe implicit attitude of the writer with respect to a query term. A major concern; however; isthat Twitter (and other media channels) follows the data stream model; and thus theclassifier must operate with limited resources; including labeled data for trainingclassification models. This imposes serious challenges for current classification techniques;since they need to be constantly fed with fresh training messages; in order to track sentimentdrift and to provide up-to-date sentiment analysis. We propose solutions to this problem. Theheart of our approach is a training augmentation procedure which takes as input a small …,Proceedings of the 34th international ACM SIGIR conference on Research and development in Information Retrieval,2011,43
A campaign-based characterization of spamming strategies,Pedro Henrique Calais; Douglas EV Pires; Dorgival Olavo Guedes; Wagner Meira Jr; Cristine Hoepers; Klaus Steding Jessen,Abstract This paper presents a methodology for the characterization of spamming strategiesbased on the identification of spam campaigns. To deeply understand how spammers abusenetwork resources and obfuscate their messages; an aggregated analysis of spammessages is not enough. Grouping spam messages into campaigns is important to unveilbehaviors that cannot be noticed when looking at the whole set of spams collected. Wepropose a spam identification technique based on a frequent pattern tree; which naturallycaptures the invariants on message content and detect campaigns that differ only due toobfuscated fragments. After that; we characterize these campaigns both in terms of contentobfuscation and exploitation of network resources. Our methodology includes the use ofattribute association analysis: by applying an association rule mining algorithm; we were …,*,2008,42
ProfileRank: finding relevant content and influential users based on information diffusion,Arlei Silva; Sara Guimarães; Wagner Meira Jr; Mohammed Zaki,Abstract Understanding information diffusion processes that take place on the Web;specially in social media; is a fundamental step towards the design of effective informationdiffusion mechanisms; recommendation systems; and viral marketing/advertisingcampaigns. Two key concepts in information diffusion are influence and relevance. Influenceis the ability to popularize content in an online community. To this end; influentials introduceand propagate relevant content; in the sense that such content satisfies the informationneeds of a significant portion of this community. In this paper; we study the problem ofidentifying influential users and relevant content in information diffusion data. We proposeProfileRank; a new information diffusion model based on random walks over a user-contentgraph. ProfileRank is a PageRank inspired model that exploits the principle that relevant …,Proceedings of the 7th Workshop on Social Network Mining and Analysis,2013,41
From an artificial neural network to a stock market day-trading system: A case study on the bm&f bovespa,Leonardo C Martinez; Diego N da Hora; Joao R de M Palotti; Wagner Meira; Gisele L Pappa,Predicting trends in the stock market is a subject of major interest for both scholars andfinancial analysts. The main difficulties of this problem are related to the dynamic; complex;evolutive and chaotic nature of the markets. In order to tackle these problems; this workproposes a day-trading system that “translates” the outputs of an artificial neural network intobusiness decisions; pointing out to the investors the best times to trade and make profits.The ANN forecasts the lowest and highest stock prices of the current trading day. The systemwas tested with the two main stocks of the BM&FBOVESPA; an important and understudiedmarket. A series of experiments were performed using different data input configurations;and compared with four benchmarks. The results were evaluated using both classicalevaluation metrics; such as the ANN generalization error; and more general metrics; such …,Neural Networks; 2009. IJCNN 2009. International Joint Conference on,2009,41
Understanding temporal aspects in document classification,Fernando Mourão; Leonardo Rocha; Renata Araújo; Thierson Couto; Marcos Gonçalves; Wagner Meira Jr,Abstract Due to the increasing amount of information present on the Web; AutomaticDocument Classification (ADC) has become an important research topic. ADC usuallyfollows a standard supervised learning strategy; where we first build a model usingpreclassified documents and then use it to classify new unseen documents. One majorchallenge for ADC in many scenarios is that the characteristics of the documents and theclasses to which they belong may change over time. However; most of the currenttechniques for ADC are applied without taking into account the temporal evolution of thecollection of documents In this work; we perform a detailed study of the temporal evolution inthe ADC; introducing an analysis methodology. We discuss that temporal evolution may beexplained by three factors: 1) class distribution; 2) term distribution; and 3) class similarity …,Proceedings of the 2008 International Conference on Web Search and Data Mining,2008,41
Sistemas de comércio eletrônico: projeto e desenvolvimento,Wagner Meira; Cristina Duarte Murta; Sérgio Vale Aguiar Campos; Dorgival Olavo Guedes Neto,*,*,2002,40
Analyzing Web robots and their impact on caching,Virgilio Almeida; Daniel Menascé; Rudolf Riedi; Flávia Peligrinelli; Rodrigo Fonseca; Wagner Meira Jr,Abstract Understanding the nature and the characteristics of Web robots is an essential stepto analyze their impact on caching. Using a multi-layer hierarchical workload model; thispaper presents a characterization of the workload generated by autonomous agents androbots. This characterization focuses on the statistical properties of the arrival process andon the robot behavior graph model. A set of criteria is proposed for identifying robots in reallogs. We then identify and characterize robots from real logs applying a multi-layeredapproach. Using a stack distance-based analytical model for the interaction between robotsand Web site caching; we assess the impact of robots' requests on Web caches. Ouranalyses point out that robots cause a significant increase in the miss ratio of a server-sidecache. Robots have a referencing pattern that completely disrupts locality assumptions …,Proc. Sixth Workshop on Web Caching and Content Distribution,2001,40
Temporally-aware algorithms for document classification,Thiago Salles; Leonardo Rocha; Gisele L Pappa; Fernando Mourão; Wagner Meira Jr; Marcos Gonçalves,Abstract Automatic Document Classification (ADC) is still one of the major informationretrieval problems. It usually employs a supervised learning strategy; where we first build aclassification model using pre-classified documents and then use this model to classifyunseen documents. The majority of supervised algorithms consider that all documentsprovide equally important information. However; in practice; a document may be consideredmore or less important to build the classification model according to several factors; such asits timeliness; the venue where it was published in; its authors; among others. In this paper;we are particularly concerned with the impact that temporal effects may have on ADC andhow to minimize such impact. In order to deal with these effects; we introduce a temporalweighting function (TWF) and propose a methodology to determine it for document …,Proceedings of the 33rd international ACM SIGIR conference on Research and development in information retrieval,2010,38
Self-Configuring Heterogeneous Server Clusters Ѓ,Taliver Heath; Bruno Diniz; Enrique V Carrera; Wagner Meira Jr; Ricardo Bianchini,Abstract Previous research on cluster-based servers has focused on homogeneoussystems. However; real-life clusters are almost invariably heterogeneous in terms of theperformance; capacity; and power consumption of their hardware components. In this paper;we describe a self-configuring Web server for a heterogeneous cluster. The self-configuration is guided by analytical models of throughput and power consumption. Ourexperimental results for a cluster comprised of traditional and blade nodes show that themodelbased server can consume 29% less energy than an energyoblivious server; with onlya negligible loss in throughput. The results also show that our server conserves more thantwice as much energy as an energy-conscious server that we previously proposed forhomogeneous clusters.,*,2003,38
Set-based model: A new approach for information retrieval,Bruno Pôssas; Nivio Ziviani; Wagner Meira Jr; Berthier Ribeiro-Neto,Abstract The objective of this paper is to present a new technique for computing termweights for index terms; which leads to a new ranking mechanism; referred to as set-basedmodel. The components in our model are no longer terms; but termsets. The novelty is thatwe compute term weights using a data mining technique called association rules; which istime efficient and yet yields nice improvements in retrieval effectiveness. The set-basedmodel function for computing the similarity between a document and a query considers thetermset frequency in the document and its scarcity in the document collection. Experimentalresults show that our model improves the average precision of the answer set for all threecollections evaluated. For the TReC-3 collection; our set-based model led to a gain; relativeto the standard vector space model; of 37% in average precision curves and of 57% in …,Proceedings of the 25th annual international ACM SIGIR conference on Research and development in information retrieval,2002,38
Calibrated lazy associative classification,Adriano Veloso; Wagner Meira Jr; Marcos Gonçalves; Humberto M Almeida; Mohammed Zaki,Abstract Classification is a popular machine learning task. Given an example x and a classc; a classifier usually works by estimating the probability of x being member of c (ie;membership probability). Well calibrated classifiers are those able to provide accurateestimates of class membership probabilities; that is; the estimated probability p ˆ (c| x) isclose to p (c| p ˆ (c| x)); which is the true;(unknown) empirical probability of x being memberof c given that the probability estimated by the classifier is p ˆ (c| x). Calibration is not anecessary property for producing accurate classifiers; and; thus; most of the research hasfocused on direct accuracy maximization strategies rather than on calibration. However; non-calibrated classifiers are problematic in applications where the reliability associated with aprediction must be taken into account. In these applications; a sensible use of the …,Information Sciences,2011,37
Analyzing the behavior of a proxy server in the light of regional and cultural issues,V Almeida; M Cesario; Rodrigo Fonseca; Wagner Meira Jr; Cristina Murta,*,Proceedings of the Third International WWW Caching Workshop,1998,37
Named entity disambiguation in streaming data,Alexandre Davis; Adriano Veloso; Altigran S Da Silva; Wagner Meira Jr; Alberto HF Laender,Abstract The named entity disambiguation task is to resolve the many-to-manycorrespondence between ambiguous names and the unique real-world entity. This task canbe modeled as a classification problem; provided that positive and negative examples areavailable for learning binary classifiers. High-quality sense-annotated data; however; arehard to be obtained in streaming environments; since the training corpus would have to beconstantly updated in order to accomodate the fresh data coming on the stream. On theother hand; few positive examples plus large amounts of unlabeled data may be easilyacquired. Producing binary classifiers directly from this data; however; leads to poordisambiguation performance. Thus; we propose to enhance the quality of the classifiersusing finer-grained variations of the well-known Expectation-Maximization (EM) algorithm …,Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics: Long Papers-Volume 1,2012,36
Cost-effective on-demand associative author name disambiguation,Adriano Veloso; Anderson A Ferreira; Marcos André Gonçalves; Alberto HF Laender; Wagner Meira Jr,Abstract Authorship disambiguation is an urgent issue that affects the quality of digital libraryservices and for which supervised solutions have been proposed; delivering state-of-the-arteffectiveness. However; particular challenges such as the prohibitive cost of labeling vastamounts of examples (there are many ambiguous authors); the huge hypothesis space(there are several features and authors from which many different disambiguation functionsmay be derived); and the skewed author popularity distribution (few authors are very prolific;while most appear in only few citations); may prevent the full potential of such techniques. Inthis article; we introduce an associative author name disambiguation approach thatidentifies authorship by extracting; from training examples; rules associating citation features(eg; coauthor names; work title; publication venue) to specific authors. As our main …,Information Processing & Management,2012,36
Structural correlation pattern mining for large graphs,Arlei Silva; Wagner Meira Jr; Mohammed J Zaki,Abstract In this paper we define the Structural Correlation Pattern (SCP) mining problem;which consists of determining correlations among vertex attributes and dense componentsin an undirected graph. Vertex attributes play an important role in several real-life graphsand SCPs help to understand how they relate to the associated graph topology. SCPs maydescribe; for example; interesting relationships between personal characteristics and thecommunity structure in social networks. We also propose an efficient algorithm; calledSCORP; to extract SCPs from large graphs; and compare it against a naive approach forSCP mining; demonstrating its scalability and efficiency. We also discuss the application ofSCORP to two actual scenarios; co-authorship networks and social music discovery;showing relevant results that demonstrate the applicability of the proposed approach.,Proceedings of the Eighth Workshop on Mining and Learning with Graphs,2010,35
Multi-evidence; multi-criteria; lazy associative document classification,Adriano Veloso; Wagner Meira Jr; Marco Cristo; Marcos Gonçalves; Mohammed Zaki,Abstract We present a novel approach for classifying documents that combines differentpieces of evidence (eg; textual features of documents; links; and citations) transparently;through a data mining technique which generates rules associating these pieces ofevidence to predefined classes. These rules can contain any number and mixture of theavailable evidence and are associated with several quality criteria which can be used inconjunction to choose the" best" rule to be applied at classification time. Our method is ableto perform evidence enhancement by link forwarding/backwarding (ie; navigating amongdocuments related through citation); so that new pieces of link-based evidence are derivedwhen necessary. Furthermore; instead of inducing a single model (or rule set) that is goodon average for all predictions; the proposed approach employs a lazy method which …,Proceedings of the 15th ACM international conference on Information and knowledge management,2006,35
Analyzing performance of partitioned caches for the WWW,Cristina Duarte Murta; Virgılio Almeida; Wagner Meira Jr,*,Proceedings of the 3rd International WWW Caching Workshop,1998,33
Traffic observatory: a system to detect and locate traffic events and conditions using Twitter,Sílvio S Ribeiro Jr; Clodoveu A Davis Jr; Diogo Rennó R Oliveira; Wagner Meira Jr; Tatiana S Gonçalves; Gisele L Pappa,Abstract Twitter has become one of the most popular platforms for sharing user-generatedcontent; which varies from ordinary conversations to information about recent events.Studies have already showed that the content of tweets has a high degree of correlation withwhat is going on in the real world. A type of event which is commonly talked about in Twitteris traffic. Aiming to help other drivers; many users tweet about current traffic conditions; andthere are even user accounts specialized on the subject. With this in mind; this paperproposes a method to identify traffic events and conditions in Twitter; geocode them; anddisplay them on the Web in real time. Preliminary results showed that the method is able todetect neighborhoods and thoroughfares with a precision that varies from 50 to 90%;depending on the number of places mentioned in the tweets.,Proceedings of the 5th ACM SIGSPATIAL International Workshop on Location-Based Social Networks,2012,32
Efficient; accurate and privacy-preserving data mining for frequent itemsets in distributed databases,Adriano A Veloso; Wagner Meira Jr; Srinivasan Parthasarathy; Márcio Bunte De Carvalho,Abstract Mining distributed databases is emerging as a fundamental computational problem.A common approach for mining distributed databases is to move all of the data from eachdatabase to a central site and a single model is built. This approach is accurate; but tooexpensive in terms of time required. For this reason; several approaches were developed toefficiently mine distributed databases; but they still ignore a key issue- privacy. Privacy is theright of individuals or organizations to keep their own information secret. Privacy concernscan prevent data movement- data may be distributed among several custodians; none ofwhich is allowed to transfer its data to another site. In this paper we present an efficientapproach for mining frequent itemsets in distributed databases. Our approach is accurateand uses a privacy-preserving communication mechanism. The proposed approach is …,Computer Science,2003,32
Deployment of roadside units based on partial mobility information,Cristiano M Silva; Andre LL Aquino; Wagner Meira Jr,Abstract This work presents an algorithm for deployment of roadside units based on partialmobility information. We propose the partition of the road network into same size urban cells;and we use the migration ratios between adjacent urban cells in order to infer the betterlocations for the deployment of the roadside units. Our goal is to identify those α locationsmaximizing the number of distinct vehicles experiencing at least one V2I contact opportunity.We compare our strategy to two deployment algorithms: MCP-g relies on full mobilityinformation (full knowledge of the vehicles trajectories); while MCP-kp does not assume anymobility information at all. Results demonstrate that our strategy increases the number ofdistinct vehicles contacting the infrastructure in 6.8% when compared to MCP-kp. On theother hand; MCP-g overcomes our strategy by 8.5%. We must evaluate whether the 8.5 …,Computer Communications,2015,31
Parallelizing MPEG video encoding using multiprocessors,Denilson M Barbosa; Joao Paulo Kitajima; W Weira,Many computer applications are currently using digital video. Recent advances in digitalimaging and faster networking infrastructure made this technology very popular; not only forentertainment; but also in health and education applications. However; high quality videorequires more storage space and communication bandwidth than traditional data. To dealwith this problem; most of the digital video encoding techniques use a compression scheme.The MPEG committee has defined widely used standards for digital video encodingproviding high quality images and high compression rates. However; real-time MPEGencoding also demands high computational power; usually far beyond traditional sequentialcomputers can provide. Fortunately; the algorithms compliant to the MPEG standard can beparallelized. In this work; we propose a novel and simple shared-memory parallel …,Computer Graphics and Image Processing; 1999. Proceedings. XII Brazilian Symposium on,1999,27
Quantifying the performability of cluster-based services,Kiran Nagaraja; Gustavo Gama; Ricardo Bianchini; Richard P Martin; W Meira; Thu D Nguyen,In this paper; we propose a two-phase methodology for systematically evaluating theperformability (performance and availability) of cluster-based Internet services. In the firstphase; evaluators use a fault-injection infrastructure to characterize the service's behavior inthe presence of faults. In the second phase; evaluators use an analytical model to combinean expected fault load with measurements from the first phase to assess the service'sperformability. Using this model; evaluators can study the service's sensitivity to differentdesign decisions; fault rates; and other environmental factors. To demonstrate ourmethodology; we study the performability of a multitier Internet service. In particular; weevaluate the performance and availability of three soft state maintenance strategies for anonline bookstore service in the presence of seven classes of faults. Among other …,IEEE Transactions on Parallel and Distributed Systems,2005,26
The impact of visual attributes on online image diffusion,Luam Catao Totti; Felipe Almeida Costa; Sandra Avila; Eduardo Valle; Wagner Meira Jr; Virgilio Almeida,Abstract Little is known on how visual content affects the popularity on social networks;despite images being now ubiquitous on the Web; and currently accounting for aconsiderable fraction of all content shared. Existing art on image sharing focuses mainly onnon-visual attributes. In this work we take a complementary approach; and investigateresharing from a mainly visual perspective. Two sets of visual features are proposed;encoding both aesthetical properties (brightness; contrast; sharpness; etc.); and semanticalcontent (concepts represented by the images). We collected data from a large image-sharing service (Pinterest) and evaluated the predictive power of different features onpopularity (number of reshares). We found that visual properties have low predictive powercompared that of social cues. However; after factoring-out social influence; visual features …,Proceedings of the 2014 ACM conference on Web science,2014,25
Sentiment analysis on evolving social streams: How self-report imbalances can help,Pedro Calais Guerra; Wagner Meira Jr; Claire Cardie,Abstract Real-time sentiment analysis is a challenging machine learning task; due to scarcityof labeled data and sudden changes in sentiment caused by real-world events that need tobe instantly interpreted. In this paper we propose solutions to acquire labels and cope withconcept drift in this setting; by using findings from social psychology on how humans preferto disclose some types of emotions. In particular; we use findings that humans are moremotivated to report positive feelings rather than negative feelings and also prefer to reportextreme feelings rather than average feelings. We map each of these self-report imbalanceson two machine learning sub-tasks. The preference on the disclosure of positive feelingscan be explored to generate labeled data on polarizing topics; where a positive event forone group usually induces negative feelings from the opposing group; generating an …,Proceedings of the 7th ACM international conference on Web search and data mining,2014,25
Asynchronous and anticipatory filter-stream based parallel algorithm for frequent itemset mining,Adriano Veloso; Wagner Meira; Renato Ferreira; Dorgival Guedes Neto; Srinivasan Parthasarathy,Abstract In this paper we propose a novel parallel algorithm for frequent itemset mining. Thealgorithm is based on the filter-stream programming model; in which the frequent itemsetmining process is represented as a data flow controlled by a series of producer andconsumer components (called filters); and the data flow (communication) between suchfilters is made via streams. When production rate matches consumption rate; andcommunication overhead between producer and consumer filters is minimized; a highdegree of asynchrony is achieved. Following this strategy; our algorithm employs anasynchronous candidate generation; and minimizes communication between filters bytransferring only the necessary aggregated information. Another nice feature of ouralgorithm is a look forward approach which accelerates frequent itemset determination …,European Conference on Principles of Data Mining and Knowledge Discovery,2004,25
Cutoff Scanning Matrix (CSM): structural classification and function prediction by protein inter-residue distance patterns,Douglas EV Pires; Raquel C de Melo-Minardi; Marcos A dos Santos; Carlos H da Silveira; Marcelo M Santoro; Wagner Meira,The unforgiving pace of growth of available biological data has increased the demand forefficient and scalable paradigms; models and methodologies for automatic annotation. Inthis paper; we present a novel structure-based protein function prediction and structuralclassification method: Cutoff Scanning Matrix (CSM). CSM generates feature vectors thatrepresent distance patterns between protein residues. These feature vectors are then usedas evidence for classification. Singular value decomposition is used as a preprocessing stepto reduce dimensionality and noise. The aspect of protein function considered in the presentwork is enzyme activity. A series of experiments was performed on datasets based onEnzyme Commission (EC) numbers and mechanistically different enzyme superfamilies aswell as other datasets derived from SCOP release 1.75. CSM was able to achieve a …,BMC genomics,2011,24
Exploiting temporal contexts in text classification,Leonardo Rocha; Fernando Mourão; Adriano Pereira; Marcos André Gonçalves; Wagner Meira Jr,Abstract Due to the increasing amount of information being stored and accessible throughthe Web; Automatic Document Classification (ADC) has become an important researchtopic. ADC usually employs a supervised learning strategy; where we first build aclassification model using pre-classified documents and then use it to classify unseendocuments. One major challenge in building classifiers is dealing with the temporalevolution of the characteristics of the documents and the classes to which they belong.However; most of the current techniques for ADC do not consider this evolution whilebuilding and using the models. Previous results show that the performance of classifiers maybe affected by three different temporal effects (class distribution; term distribution and classsimilarity). Further; it is shown that using just portions of the pre-classified documents …,Proceedings of the 17th ACM conference on Information and knowledge management,2008,24
Parallel and distributed frequent itemset mining on dynamic datasets,Adriano Veloso; Matthew Eric Otey; Srinivasan Parthasarathy; Wagner Meira,Abstract Traditional methods for data mining typically make the assumption that data iscentralized and static. This assumption is no longer tenable. Such methods wastecomputational and I/O resources when the data is dynamic; and they impose excessivecommunication overhead when the data is distributed. As a result; the knowledge discoveryprocess is harmed by slow response times. Efficient implementation of incremental datamining ideas in distributed computing environments is thus becoming crucial for ensuringscalability and facilitating knowledge discovery when data is dynamic and distributed. In thispaper we address this issue in the context of frequent itemset mining; an important datamining task. Frequent itemsets are most often used to generate correlations and associationrules; but more recently they have been used in such far-reaching domains as bio …,International Conference on High-Performance Computing,2003,23
Load balancing on stateful clustered web servers,George Teodoro; Tulio Tavares; Bruno Coutinho; W Meira; D Guedes,One of the main challenges to the wide use of the Internet is the scalability of the servers;that is; their ability to handle the increasing demand. Scalability in stateful servers; whichcomprise e-commerce and other transaction-oriented servers; is even more difficult; since itis necessary to keep transaction data across requests from the same user. One commonstrategy for achieving scalability is to employ clustered servers; where the load is distributedamong the various servers. However; as a consequence of the workload characteristics andthe need of maintaining data coherent among the servers that compose the cluster; loadimbalance arise among servers; reducing the efficiency of the server as a whole. Wepropose and evaluate a strategy for load balancing in stateful clustered servers. Our strategyis based on control theory and allowed significant gains over configurations that do not …,Computer Architecture and High Performance Computing; 2003. Proceedings. 15th Symposium on,2003,23
Efficiency analysis of brokers in the electronic marketplace,Virgı́lio AF Almeida; Wagner Meira Jr; Victor F Ribeiro; Nivio Ziviani,Abstract In this paper we analyze the behavior of e-commerce users based on actual logsfrom two large non-English e-brokers. We start by presenting a quantitative study of thebehavior of e-brokers and discuss the influence of regional and cultural issues on them. Wethen discuss a model that quantifies the efficiency of the results provided by brokers in theelectronic marketplace. This model is a function of factors such as server response time andregional factors. Our findings clearly indicate that e-commerce is strongly tied to locallanguage; national customs and regulations; currency conversion and logistics; and Internetinfrastructure. We found that the behavior of customers of online bookstores is stronglyaffected by brand and regional factors. Music CD shoppers show a different behavior thatmight stem from the fact that music is universal and not so language dependent.,Computer Networks,1999,23
Lazy associative classification for content-based spam detection,Adriano Veloso; Wagner Meira Jr,Despite all tricks and mechanisms spammers use to avoid detection; one fact is certain:spammers have to deliver their message; whatever it is. This fact makes the message itself aweak point of spammers; and thus special attention has being devoted to content-basedspam detection. In this paper we introduce a novel pattern discovery approach for spamdetection. The proposed approach discovers patterns hidden in the message; and then itbuilds a classification model by exploring the associations among the discovered patterns.The model is composed by rules; showing the relationships between the discoveredpatterns and classes (ie; spam/legitimate message). Differently from typical eager classifierswhich build a single model that is good on average for all messages; our lazy approachbuilds a specific model for each message being classified; possibly taking advantage of …,Web Congress; 2006. LA-Web'06. Fourth Latin American,2006,22
E-representative: a scalability scheme for e-commerce,W Meira; Daniel Menascé; Virgılio Almeida; Rodrigo Fonseca,In order to meet the quality of service demanded by a growing number of online customers;e-commerce services need to use scalability techniques. This paper introduces the conceptof e-commerce representatives; a means of scaling the performance of e-commerceservices. E-representatives are programs that execute on a cache server or at nearbymachines. E-representatives can be implemented using redirection; a mechanism availablein popular cache servers. Using analytical and simulation models; we show the potentialperformance gains obtained by e-commerce sites that distribute their services among e-representatives and contribute to reduce bandwidth consumption and network latency.,Advanced Issues of E-Commerce and Web-Based Information Systems; 2000. WECWIS 2000. Second International Workshop on,2000,22
Modeling performance of parallel programs,Jr Wagner Meira,Abstract The actual performance of parallel programs is often disappointing; especially incomparison to the peak performance o ered by the underlying hardware. There are manysources of performance degradation and understanding these sources is necessary toimprove application performance. In this paper we discuss performance modeling; anapproach to understanding the performance of parallel systems. We present a survey ofcurrent approaches to modeling (both analytical modeling based on system parameters; andstructural modeling based on the structure of the program); and propose a combination ofthese two approaches as a promising direction for new work. This combination is exploredby evaluating and proposing improvements to lost cycles analysis; which already containsfeatures from both approaches; and also combines measurement and modeling.,TR859. Computer Science Department; University of Rochester,1995,22
Reachability Queries in Very Large Graphs: A Fast Refined Online Search Approach.,Renê Rodrigues Veloso; Loïc Cerf; Wagner Meira Jr; Mohammed J Zaki,*,EDBT,2014,21
Aggregating productivity indices for ranking researchers across multiple areas,Harlley Lima; Thiago HP Silva; Mirella M Moro; Rodrygo LT Santos; Wagner Meira Jr; Alberto HF Laender,Abstract The impact of scientific research has traditionally been quantified using productivityindices such as the well-known h-index. On the other hand; different research fields---in fact;even different research areas within a single field---may have very different publishingpatterns; which may not be well described by a single; global index. In this paper; we arguethat productivity indices should account for the singularities of the publication patterns ofdifferent research areas; in order to produce an unbiased assessment of the impact ofscientific research. Inspired by ranking aggregation approaches in distributed informationretrieval; we propose a novel approach for ranking researchers across multiple researchareas. Our approach is generic and produces cross-area versions of any global productivityindex; such as the volume of publications; citation count and even the h-index. Our …,Proceedings of the 13th ACM/IEEE-CS joint conference on Digital libraries,2013,21
aCSM: noise-free graph-based signatures to large-scale receptor-based ligand prediction,Douglas EV Pires; Raquel C de Melo-Minardi; Carlos H Da Silveira; Frederico F Campos; Wagner Meira Jr,Abstract Motivation: Receptor-ligand interactions are a central phenomenon in mostbiological systems. They are characterized by molecular recognition; a complex processmainly driven by physicochemical and structural properties of both receptor and ligand.Understanding and predicting these interactions are major steps towards protein ligandprediction; target identification; lead discovery and drug design. Results: We propose anovel graph-based–binding pocket signature called aCSM; which proved to be efficient andeffective in handling large-scale protein ligand prediction tasks. We compare our results withthose described in the literature and demonstrate that our algorithm overcomes thecompetitor's techniques. Finally; we predict novel ligands for proteins from Trypanosomacruzi; the parasite responsible for Chagas disease; and validate them in silico via a …,Bioinformatics,2013,21
Fundamentals of data mining algorithms,Mohammed J Zaki; Wagner Meira Jr,*,*,2011,21
Assessing the impact of reactive workloads on the performance of web applications,Adriano Pereira; Leonardo Silva; W Meira; Walter Santos,Designing systems with better performance and scalability is a real need to fulfill the userdemands and generate profitable Web services. Being able to mimic user behavior and theworkload they generate on the servers is fundamental to evaluate the performance ofsystems and their improvements. One aspect that is usually neglected by workloadgenerators is the user reactivity; that is; how the users react to variable server response time.Further; it is not clear how the reactivity-related changes in the user generated workloadaffect the server and how these dependences converge. This paper addresses this problemby proposing; implementing; and validating a workload generator that accounts for reactivitywhile interacting with servers. Our workload generator is used; for instance; to generateworkloads based on a TPC-W benchmark. These workloads are used to assess the …,Performance Analysis of Systems and Software; 2006 IEEE International Symposium on,2006,21
Tree projection-based frequent itemset mining on multicore cpus and gpus,George Teodoro; Nathan Mariano; Wagner Meira Jr; Renato Ferreira,Frequent itemset mining (FIM) is a core operation for several data mining applications asassociation rules computation; correlations; document classification; and many others; whichhas been extensively studied over the last decades. Moreover; databases are becomingincreasingly larger; thus requiring a higher computing power to mine them in reasonabletime. At the same time; the advances in high performance computing platforms aretransforming them into hierarchical parallel environments equipped with multi-coreprocessors and many-core accelerators; such as GPUs. Thus; fully exploiting these systemsto perform FIM tasks poses as a challenging and critical problem that we address in thispaper. We present efficient multi-core and GPU accelerated parallelizations of the TreeProjection; one of the most competitive FIM algorithms. The experimental results show …,Computer Architecture and High Performance Computing (SBAC-PAD); 2010 22nd International Symposium on,2010,19
Exploring the spam arms race to characterize spam evolution,Pedro H Calais Guerra; Dorgival Guedes; J Wagner Meira; Cristine Hoepers; MHPC Chaves; Klaus Steding-Jessen,ABSTRACT Current studies on spam evolution usually extract evolution patterns and trendsby analyzing historical spam message corpora. In this paper; we propose a novelmethodology that incorporates spam filters to the spam trend analysis; as they are theagents that may force spammers to change their tactics. Moreover; filters also evolve overtime and different filter releases present different characteristics; providing different views ofthe spams. We considered both outdated and recent releases of the Open SourceSpamAssassin filter and applied their criteria on spams collected from the Spam Archivedataset; a dataset that contains spams collected from 1998 to 2010. When we compare theeffectiveness of old and recent filters over old and recent spams; spam trends naturallyemerge. Our results give a general picture of the dynamic nature of spam over the last 12 …,Proceedings of the 7th Collaboration; Electronic messaging; Anti-Abuse and Spam Conference (CEAS); Redmond; WA,2010,19
A scalable parallel deduplication algorithm,Walter Santos; Thiago Teixeira; Carla Machado; Wagner Meira Jr; Renato Ferreira; Dorgival Guedes; Altigran S Da Silva,The identification of replicas in a database is fundamental to improve the quality of theinformation. Deduplication is the task of identifying replicas in a database that refer to thesame real world entity. This process is not always trivial; because data may be corruptedduring their gathering; storing or even manipulation. Problems such as misspelled names;data truncation; data input in a wrong format; lack of conventions (like how to abbreviate aname); missing data or even fraud may lead to the insertion of replicas in a database. Thededuplication process may be very hard; if not impossible; to be performed manually; sinceactual databases may have hundreds of millions of records. In this paper; we present ourparallel deduplication algorithm; called FER-APARDA. By using probabilistic record linkage;we were able to successfully detect replicas in synthetic datasets with more than 1 million …,Computer Architecture and High Performance Computing; 2007. SBAC-PAD 2007. 19th International Symposium on,2007,19
It is not just a picture: revealing some user practices in instagram,Camila Souza Araújo; Luiz Paulo Damilton Corrêa; Ana Paula Couto da Silva; Raquel Oliveira Prates; Wagner Meira,In this work we investigate the user practices in Instagram; a social photo sharing service.Some interesting conclusions emerge from our analysis. For instance; users tend toconcentrate their posts during the weekend and at the end of the day. Furthermore; peopletend to endorse photos with many likes and comments; inducing the rich get richerphenomenon. Our findings can support future research on sociology and cultural analyticsresearch areas; such as on the proposal of new clustering algorithms based on the userpractices in different social media networks.,Web Congress (LA-WEB); 2014 9th Latin American,2014,18
Modeling and analyzing the video game live-streaming community,Gustavo Nascimento; Manoel Ribeiro; Loïc Cerf; Natália Cesário; Mehdi Kaytoue; Chedy Raïssi; Thiago Vasconcelos; Wagner Meira,In parallel to the exponential growth of the gaming industry; video game live-streaming isrising as a major form of online entertainment. Gathering a heterogeneous community; thepopularity of this new media led to the creation of web services just for streaming videogames; such as Twitch. TV. In this paper; we propose a model to characterize how streamersand spectators behave; based on their possible actions in Twitch and; using it; we perform acase study on the Star craft II streamers and spectators. In the case study we analyze a largeamount of data collected in Twitch. TV's chat in order to better understand how streamersbehave; and how this new form of online entertainment is different from previous ones.Based on this analysis; we were able to better understand channel switching; channelsurfing; and to create a model for predicting the number of chat messages based on the …,Web Congress (LA-WEB); 2014 9th Latin American,2014,18
Approximate similarity search for online multimedia services on distributed CPU–GPU platforms,George Teodoro; Eduardo Valle; Nathan Mariano; Ricardo Torres; Wagner Meira; Joel H Saltz,Abstract Similarity search in high-dimensional spaces is a pivotal operation for severaldatabase applications; including online content-based multimedia services. With theincreasing popularity of multimedia applications; these services are facing new challengesregarding (1) the very large and growing volumes of data to be indexed/searched and (2)the necessity of reducing the response times as observed by end-users. In addition; thenature of the interactions between users and online services creates fluctuating queryrequest rates throughout execution; which requires a similarity search engine to adapt tobetter use the computation platform and minimize response times. In this work; we addressthese challenges with Hypercurves; a flexible framework for answering approximate k-nearest neighbor (kNN) queries for very large multimedia databases. Hypercurves …,The VLDB Journal,2014,18
Combining distributed populations and periodic centralized selections in coarse-grain parallel genetic algorithms,Ricardo Bianchini; Christopher M Brown; M Cierniak; W Meira,Abstract In this paper we demonstrate that parallel genetic algorithms can profit fromperforming periodic centralized selections of distributed populations. With this combination;implementations can benefit from the variety of environments provided by distributedapproaches; while periodically being able to consider the population as a whole anddisregard very unfit individuals. We study four different parallel genetic algorithmimplementation strategies; each of them striking a different balance between centralizationand distribution. These strategies are applied to several well-known benchmark problems.Our results show that the implementations using periodic centralized selections exhibitremarkable robustness in terms of their search quality; while keeping running timeoverheads under control. Our main conclusion is that performing centralized selections …,*,1995,18
Characterizing the effectiveness of twitter hashtags to detect and track online population sentiment,Glívia Angélica Rodrigues Barbosa; Ismael S Silva; Mohammed Zaki; Wagner Meira Jr; Raquel O Prates; Adriano Veloso,Abstract In this paper we describe the preliminary results and future directions of a researchin progress; which aims at assessing the hashtag effectiveness as a resource for sentimentanalysis expressed on Twitter. The results so far support our hypothesis that hashtags mayfacilitate the detection and automatic tracking of online population sentiment about differentevents.,CHI'12 Extended Abstracts on Human Factors in Computing Systems,2012,17
The usar characterization model,Adriano Pereira; Gustavo Franco; Leonardo Silva; W Meira; Walter Santos,Understanding the user behavior is a need to analyze the performance and the scalability ofWeb servers. This knowledge is used; for instance; to build workload generators that helpevaluating the performance of those servers. Current workload generators are typicallymemory-less; being unable to mimic actual user interaction with the system. In this work wepropose a hierarchical characterization and simulation model focused on the user behavior;named USAR. We use the latency and inter-arrival time of the requests to model useractions; which are the basis of our model. We validate this model through a proxy-cacheserver case study; where we perform the characterization and construct a user behaviorsimulator. We foresee from the results the possibility to generate more realistic workloads.,Workload Characterization; 2004. WWC-7. 2004 IEEE International Workshop on,2004,17
A formal methodology to specify e-commerce systems,Adriano Pereira; Mark Song; Gustavo Gorgulho; Wagner Meira; Sérgio Campos,Abstract Electronic commerce is an important application that has evolved significantlyrecently. It gives companies the possibility of reaching an unprecedented number of clientsat very low cost. However; electronic commerce systems are complex and difficult to becorrectly designed. Currently; most approaches are ad-hoc; and frequently lead toexpensive; unreliable systems that may take a long time to implement. In this work wepropose a methodology that uses formal-method techniques; specifically symbolic modelchecking; to design electronic commerce applications and to automatically verify that thesedesigns satisfy properties such as atomicity; isolation; and consistency. Using the proposedmethodology; the designer is able to identify errors early in the design process and correctthem before they propagate to later stages. Thus; it is possible to generate more reliable …,International Conference on Formal Engineering Methods,2002,17
Efficiently mining approximate models of associations in evolving databases,Adriano Veloso; Bruno Gusmão; Wagner Meira; Marcio Carvalho; Srini Parthasarathy; Mohammed Zaki,Abstract Much of the existing work in machine learning and data mining has relied ondevising efficient techniques to build accurate models from the data. Research on how theaccuracyof a model changes as a function of dynamic updates to the databases is verylimited. In this work we show that extracting this information: knowing which aspects of themodel are changing; and how theyare changing as a function of data updates; can be veryeeffective for interactive data mining purposes (where response time is often more importantthan model qualityas long as model qualityi s not too far off the best (exact) model. In thispaper we consider the problem of generating approximate models within the context ofassociation mining; a keyda ta mining task. We propose a new approach to incrementallygenerate approximate models of associations in evolving databases. Our approach is able …,European Conference on Principles of Data Mining and Knowledge Discovery,2002,17
Non-intrusive planning the roadside infrastructure for vehicular networks,Cristiano M Silva; Wagner Meira; Joao FM Sarubbi,In this article; we describe a strategy for planning the roadside infrastructure for vehicularnetworks based on the global behavior of drivers. Instead of relying on the trajectories of allvehicles; our proposal relies on the migration ratios of vehicles between urban regions inorder to infer the better locations for deploying the roadside units. By relying on the globalbehavior of drivers; our strategy does not incur in privacy concerns. Given a set of αavailable roadside units; our goal is to select those α-better locations for placing theroadside units in order to maximize the number of distinct vehicles experiencing at least oneV2I contact opportunity. Our results demonstrate that full knowledge of the vehicletrajectories are not mandatory for achieving a close-to-optimal deployment performancewhen we intend to maximize the number of distinct vehicles experiencing (at least one) …,IEEE Transactions on Intelligent Transportation Systems,2016,16
Evaluating the performance of heterogeneous vehicular networks,Cristiano Maciel da Silva; Wagner Meira,There are several kinds of envisioned vehicular applications: video delivery; accidentsdetection; dissemination of traffic announcements; and so forth. Such applications demandminimal (and possibly distinct) Quality of Service guarantees that must couple the vehicularnetwork. Since the vehicular networks will become reality soon; we demand strategies forplanning and managing such networks. In this work we propose the concept of a DeltaNetwork: the Delta Network is a metric for evaluating the performance of heterogeneousvehicular networks. By using the concept of a Network Delta; we expect network providersbeing able to measure and compare the performance of distinct heterogeneous vehicularnetworks (Delta is technology-independent). Finally; the concept of a Delta Network mayalso be applied to couple vehicular applications and vehicular networks in order to …,Vehicular Technology Conference (VTC Fall); 2015 IEEE 82nd,2015,16
Community-based endogamy as an influence indicator,Thiago HP Silva; Mirella M Moro; Ana Paula C Silva; Wagner Meira Jr; Alberto HF Laender,Abstract Evaluating researchers (individually or in groups) usually depends on qualifyingtheir publications and influence. Here; we aid such crucial task by introducing two newmetrics (C-Endo and Comb) that rely on the concept of endogamy for communities ofauthors who publish in conferences and journals; and produce patents. Endogamy heremeasures how tightly structured the groups of authors are within a community. We validateand evaluate the metrics by using real datasets; two ground-truth rankings and citationcount. We also perform random sampling analysis to account for any unbalance from theground-truth rankings. Overall; such a thorough evaluation shows that our metrics aresuccessful in defining community-based endogamy as an influence indicator.,Proceedings of the 14th ACM/IEEE-CS Joint Conference on Digital Libraries,2014,16
Economically-efficient sentiment stream analysis,Roberto Lourenco Jr; Adriano Veloso; Adriano Pereira; Wagner Meira Jr; Renato Ferreira; Srinivasan Parthasarathy,Abstract Text-based social media channels; such as Twitter; produce torrents of opinionateddata about the most diverse topics and entities. The analysis of such data (aka. sentimentanalysis) is quickly becoming a key feature in recommender systems and search engines. Aprominent approach to sentiment analysis is based on the application of classificationtechniques; that is; content is classified according to the attitude of the writer. A majorchallenge; however; is that Twitter follows the data stream model; and thus classifiers mustoperate with limited resources; including labeled data and time for building classificationmodels. Also challenging is the fact that sentiment distribution may change as the streamevolves. In this paper we address these challenges by proposing algorithms that selectrelevant training instances at each time step; so that training sets are kept small while …,Proceedings of the 37th international ACM SIGIR conference on Research & development in information retrieval,2014,16
Using cause-effect analysis to understand the performance of distributed programs,Wagner Meira Jr; Thomas J LeBlanc; Virgílio AF Almeida,Abstract Understanding the performance of distributed programs can be very difficult; since aprogram's performance depends on characteristics of the application; the underlyinghardware; the software environment; and interactions among all three. In this paper wepresent cause-effect analysis (CEA); a general approach to understanding distributedprogram performance that facilitates performance analysis; tuning; and prediction. Usingdetailed program traces gathered at execution time as input; CEA automatically generatesexplanations for important performance phenomena; identifying code segments that areresponsible for the occurrence of the phenomena. We illustrate our approach by describingCEA techniques for three classes of overheads in distributed programs: contention;synchronization; and communication. Using the explanations produced by CEA; we are …,Proceedings of the SIGMETRICS symposium on Parallel and distributed tools,1998,16
Design of roadside infrastructure for information dissemination in vehicular networks,Cristiano M Silva; Andre LL Aquino; Wagner Meira,This work presents a probabilistic constructive heuristic to design the roadside infrastructurefor information dissemination in vehicular networks. We formulate the problem as aProbabilistic Maximum Coverage Problem (PMCP) and we use them to maximize thenumber of vehicles in contact with the infrastructure. We compare our approach to a non-probabilistic MCP in simulated urban areas considering Manhattan-style topology withvariable traffic conditions. The results reveal that our approach (Probabilistic MCP)increases the number of contacts between vehicles and dissemination points; optimizes theallocation of dissemination points; distributes the dissemination points in a layout that betterfits the traffic flow and provides more regularity in the number of contacts experienced byvehicles.,Network Operations and Management Symposium (NOMS); 2014 IEEE,2014,15
Tuning genetic programming parameters with factorial designs,Elisa Boari De Lima; Gisele L Pappa; Jussara Marques de Almeida; Marcos A Gonçalves; Wagner Meira,Parameter setting of Evolutionary Algorithms is a time consuming task with two mainapproaches: parameter tuning and parameter control. In this work we describe a newmethodology for tuning parameters of Genetic Programming algorithms using factorialdesigns; one-factor designs and multiple linear regression. Our experiments show thatfactorial designs can be used to determine which parameters have the largest effect on thealgorithm's performance. This way; parameter setting efforts can focus on them; largelyreducing the parameter search space. Two classical GP problems were studied; with sixparameters for the first problem and seven for the second. The results show the maximumtree depth as the parameter with the largest effect on both problems. A one-factor designwas performed to fine-tune tree depth on the first problem and a multiple linear regression …,Evolutionary Computation (CEC); 2010 IEEE Congress on,2010,15
Achieving multi-level parallelism in the filter-labeled stream programming model,George Teodoro; Daniel Fireman; Dorgival Guedes; Wagner Meira Jr; Renato Ferreira,New architectural trends in chip design resulted in machines with multiple processing unitsas well as efficient communication networks; leading to the wide availability of systems thatprovide multiple levels of parallelism; both inter-and intra-machine. Developing applicationsthat efficiently make use of such systems is a challenge; specially for application-domainprogrammers. In this paper we present a new version of the Anthill programmingenvironment that efficiently exploits multi-level parallelism and experimental results thatdemonstrate such efficiency. Anthill is based on the filter-stream model; in this model;applications are decomposed into a set of filters communicating through streams; which hasalready been shown to be efficient for expressing inter-machine parallelism. We replacedthe filter run-time environment; originally process-oriented; with an event-oriented version …,Parallel Processing; 2008. ICPP'08. 37th International Conference on,2008,15
Analyzing robot behavior in e-business sites,Virgilío Almeida; Daniel Menascé; Rudolf Riedi; Flávia Peligrinelli; Rodrigo Fonseca; Wagner Meira Jr,The population of robots; ie; crawlers; shopbots; pricebots; and autonomous software agentsinteracting with Web servers and e-business sites; will increase significantly in the future [2;3; 5]. Indeed; directories and search engines are among the most popular sites of theInternet. At the same time; with the dawn of E-business and News sites came along a steepgrowth of dynamic documents on the web. Thus; search engines require exhaustivecrawling work to maintain and update their indices to the increasingly time-sensitive webcontent. Currently; publicly indexed documents exceed one billion in numbers [2]. In additionto the general-purpose crawlers; an ever growing number of focused crawlers selectivelyseek out information relevant to a specific pre-defined set of subjects [3]. These are part of abroader class of agents that perform resource discovery and retrieval functions; such as …,ACM SIGMETRICS Performance Evaluation Review,2001,15
Comparing CUDA; OpenCL and OpenGL implementations of the cardiac monodomain equations,Rafael Sachetto Oliveira; Bernardo Martins Rocha; Ronan Mendonça Amorim; Fernando Otaviano Campos; Wagner Meira; Elson Magalhães Toledo; Rodrigo Weber dos Santos,Abstract Computer simulations of cardiac electrophysiology are a helpful tool in the study ofbioelectric activity of the heart. The cardiac monodomain model comprises a nonlinearsystem of partial differential equations and its numerical solution represents a very intensivecomputational task due to the required fine spatial and temporal resolution. Recent studieshave shown that the use of GPU as a general purpose processor can greatly improve theperformance of simulations. The aim of this work is to study the performance of different GPUprogramming interfaces for the solution of the cardiac monodomain equations. Threedifferent GPU implementations are compared; OpenGL; NVIDIA CUDA and OpenCL; to aCPU multicore implementation that uses OpenMP. The OpenGL approach showed to be thefastest with a speedup of 446 (compared to the multicore implementation) for the solution …,International Conference on Parallel Processing and Applied Mathematics,2011,14
Analyzing seller practices in a Brazilian marketplace,Adriano Pereira; Diego Duarte; Wagner Meira Jr; Virgilio Almeida; Paulo Góes,Abstract E-commerce is growing at an exponential rate. In the last decade; there has beenan explosion of online commercial activity enabled by World Wide Web (WWW). These days;many consumers are less attracted to online auctions; preferring to buy merchandise quicklyusing fixed-price negotiations. Sales at Amazon. com; the leader in online sales of fixed-price goods; rose 37% in the first quarter of 2008. At eBay; where auctions make up 58% ofthe site's sales; revenue rose 14%. In Brazil; probably by cultural influence; online auctionsare not been popular. This work presents a characterization and analysis of fixed-priceonline negotiations. Using actual data from a Brazilian marketplace; we analyze sellerpractices; considering seller profiles and strategies. We show that different sellers adoptstrategies according to their interests; abilities and experience. Moreover; we confirm that …,Proceedings of the 18th international conference on World wide web,2009,14
Finding protein-protein interaction patterns by contact map matching,RC Melo; C Ribeiro; CS Murray; CJ Veloso; CH da Silveira; G Neshich; W Meira Jr; RL Carceroni; MM Santoro,ABSTRACT. We propose a novel method for defining patterns of contacts present in protein-protein complexes. A new use of the traditional contact maps (more frequently used forrepresentation of the intra-chain contacts) is presented for analysis of inter-chain contacts.Using an algorithm based on image processing techniques; we can compare protein-proteininteraction maps and also obtain a dissimilarity score between them. The same algorithmused to compare the maps can align the contacts of all the complexes and be helpful in thedetermination of a pattern of conserved interactions at the interfaces. We present anexample for the application of this method by analyzing,Genet. Mol. Res,2007,14
Characterizing broadband user behavior,Humberto T Marques Nt; Leonardo CD Rocha; Pedro HC Guerra; Jussara M Almeida; Wagner Meira Jr; Virgilio AF Almeida,Abstract This paper presents a characterization of broadband user behavior from a Internetservice provider. Users are broken into two major categories: residential and Small-Office/Home-Office (SOHO). For each user category; the characterization is performed alongfour criteria:(i) session arrival process;(ii) session duration;(iii) number of bytes transferredwithin a session and (iv) user request patterns. Our results show that both residential andSOHO session inter-arrival times are exponentially distributed. Whereas residential sessionarrival rates remain relatively high during the day; SOHO session arrival rates vary muchmore significantly during the day. On the other hand; a typical SOHO user session is longerand transfers a larger volume of data. Furthermore; our analysis uncovers two main groupsof session request patterns within each user category. Sessions from the first group use …,Proceedings of the 2004 ACM workshop on Next-generation residential broadband challenges,2004,14
Parallel; incremental and interactive mining for frequent itemsets in evolving databases,Adriano Veloso; Wagner Meira Jr; Marcio Bunte De Carvalho; Srinivasan Parthasarathy; Mohammed Zaki,Abstract This paper deals with new approaches to maintaining frequent itemsets in evolvingdatabases. Our new approaches make use of incremental techniques to provide significantI/O reduction; and parallel techniques to provide computational savings. At the same time;our approaches are able to effectively handle online data updates (deletions/insertions) andinteractive response times (approximate/partial results). Some additional highlights of theproposed approaches include extending the validity of the itemsets (generating approximatemodels of itemsets); and performing selective updates (tracking stable and predictableitemsets). These features allow our approaches to mine evolving data stored in warehousesas well as (potentially) streaming data. Extensive experimental benchmarking on evolvingdata demonstrates the potential advantages of the proposed approaches. We believe that …,Proceedings of the 6th International Workshop on High Performance Data Mining: Pervasive and Data Stream Mining,2003,14
Using quantitative information for efficient association rule generation,Bruno Pôssas; Wagner Meira Jr; Márcio Carvalho; Rodolfo Resende,The solution of the mining association rules problem in customer transactions wasintroduced by Agrawal; Imielinski and Swami in 1993. Their approach was extended inseveral directions such as adding or replacing the confidence and support by othermeasures; or how to also account for quantitative attributes. In this paper we present analgorithm that can be used in the context of several of the extensions provided in theliterature while preserving its performance; as illustrated by a case study. Our approach istargeted at two of the most computationally demanding phases in the process of generatingassociation rules: the enumeration of the candidate sets and the verification of which of themare frequent. The minimization of the cost of these phases is achieved by pruning earlycandidate sets based on additional quantitative information about the transactions. In …,Journal of the Brazilian Computer Society,2000,14
An efficient and reliable scientific workflow system,Tulio Tavares; George Teodoro; Tahsin Kurc; Renato Ferreira; Dorgival Guedes; W Meira; Umit Catalyurek,This paper presents a fault tolerance framework for applications that process data using adistributed network of user-defined operations in a pipelined fashion. The framework savesintermediate results and messages exchanged among application components in adistributed data management system to facilitate quick recovery from failures. Theexperimental results show that the framework scales well and our approach introduces verylittle overhead to application execution.,Cluster Computing and the Grid; 2007. CCGRID 2007. Seventh IEEE International Symposium on,2007,13
Automatic Moderation of Comments in a Large On-line Journalistic Environment.,Adriano Veloso; Wagner Meira Jr; Tiago Alves Macambira; Dorgival O Guedes; Hélio Almeida,Abstract On-line journalistic sites publish several news and stories every day. Readers ofthese sites may comment a story; and; as a consequence; a single story might receivethousands of comments. The quality of these comments may vary a lot; from spams and trollsto truly useful information. Separating good from bad comments is an important task; and isthe primary goal of comment moderation. Moderators usually classify and score thecomments; promoting high quality ones and; likewise; discouraging low quality ones.However; moderators usually face a very large number of comments; and thus; moderationmay require a huge amount of time. In this paper we address the problem of automaticmoderation of comments in a large journalistic Web site. Participants of the site may engagein discussions and interact with each other (ie; friends; fans; enemies etc.); constituting a …,ICWSM,2007,13
Enhancing the set-based model using proximity information,Bruno Pôssas; Nivio Ziviani; Wagner Meira,Abstract (SBM); which is an effective technique for computing term weights based on co-occurrence patterns; employing the information about the proximity among query terms indocuments. The intuition that semantically related term occurrences often occur closer toeach other is taken into consideration; leading to a new information retrieval model calledproximity set-based model (PSBM). The novelty is that the proximity information is used as apruning strategy to determine only related co-occurrence term patterns. This technique istime efficient and yet yields nice improvements in retrieval effectiveness. Experimentalresults show that PSBM improves the average precision of the answer set for all fourcollections evaluated. For the CFC collection; PSBM leads to a gain relative to the standardvector space model (VSM); of 23% in average precision values and 55% in average …,International Symposium on String Processing and Information Retrieval,2002,13
Knowledge management in association rule mining,Adriano Veloso; Bruno Pôssas; Wagner Meira Jr,Abstract Most current work on discovery of association rules assumes that the database fromwhich the rules are determined is static. The mining operation is performed just once andtherefore there is no need of knowledge management integration techniques. However;there are several domains where the database is updated on a regular basis. In thesedynamic databases; it is hard to maintain the discovered rules since the updates may notonly invalidate some existing rules but also make other rules relevant. We present anefficient algorithm; PELICAN; for incrementally updating the association rules when newtransactions are added to or old transactions are removed from a dynamic database. Itsefficiency comes from addressing several knowledge management issues in itsimplementation. The incremental mining operation is enabled by the maintenance and …,In Integrating Data Mining and Knowledge Management; held in conjunction with the 2001 IEE International Conference on Data Mining (ICDM,2001,13
Integrating www caches and search engines,W Meira; R Fonseca; M Cesario; N Ziviani,In this paper we propose the concept of cache plugins; which are customized programs thatrun WWW cache servers and perform some of the search engine tasks. We describe aprototype implementation of cache plugin to answer client requests directed to a largesearch engine; using a nearby cache server to store static objects. Experimental resultsusing actual logs show a significant improvement on the quality of service of the searchengine; doubling its predictability; improving its availability by a factor of 24; and reducingboth its response time by 8% and the network traffic by a factor of 20.,Global Telecommunications Conference; 1999. GLOBECOM'99,1999,13
Temporal contexts: Effective text classification in evolving document collections,Leonardo Rocha; Fernando Mourão; Hilton Mota; Thiago Salles; Marcos André GonçAlves; Wagner Meira Jr,Abstract The management of a huge and growing amount of information availablenowadays makes Automatic Document Classification (ADC); besides crucial; a verychallenging task. Furthermore; the dynamics inherent to classification problems; mainly onthe Web; make this task even more challenging. Despite this fact; the actual impact of suchtemporal evolution on ADC is still poorly understood in the literature. In this context; this workconcerns to evaluate; characterize and exploit the temporal evolution to improve ADCtechniques. As first contribution we highlight the proposal of a pragmatical methodology forevaluating the temporal evolution in ADC domains. Through this methodology; we canidentify measurable factors associated to ADC models degradation over time. Going a stepfurther; based on such analyzes; we propose effective and efficient strategies to make …,*,2013,12
Min-hash fingerprints for graph kernels: A trade-off among accuracy; efficiency; and compression,Carlos HC Teixeira; Arlei Silva; Wagner Meira Jr,Abstract Graph databases that emerge from several relevant scenarios (eg; social networks;the Web) require powerful data management algorithms and techniques. A fundamentaloperation in graph data management is computing the similarity between two graphs.However; due to the large scale and high dimensionality of real graph databases; computinggraph similarity becomes a challenging problem in real settings.,Journal of Information and Data Management,2012,12
Mining biclusters of similar values with triadic concept analysis,Mehdi Kaytoue; Sergei O Kuznetsov; Juraj Macko; Wagner Meira; Amedeo Napoli,Abstract: Biclustering numerical data became a popular data-mining task in the beginning of2000's; especially for analysing gene expression data. A bicluster reflects a strongassociation between a subset of objects and a subset of attributes in a numericalobject/attribute data-table. So called biclusters of similar values can be thought as maximalsub-tables with close values. Only few methods address a complete; correct and nonredundant enumeration of such patterns; which is a well-known intractable problem; whileno formal framework exists. In this paper; we introduce important links between biclusteringand formal concept analysis. More specifically; we originally show that Triadic ConceptAnalysis (TCA); provides a nice mathematical framework for biclustering. Interestingly;existing algorithms of TCA; that usually apply on binary data; can be used (directly or with …,arXiv preprint arXiv:1111.3270,2011,12
From individual behavior to influence networks: A case study on twitter,Arlei Silva; Hérico Valiati; Sara Guimarães; Wagner Meira Jr,ABSTRACT Understanding social influence and its related phenomena is a major challengein the study of the human collective behavior. In the recent years; the availability of internet-based communication and interactivity data has enabled studies on social influence at anunprecedented scale and time resolution. In this work; we study how individual behaviordata may provide knowledge regarding influence relationships in a social network. Wedefine what we call the influence network discovery problem; which consists of identifyinginfluence relationships based on user behavior across time. Our objective is the design ofaccurate models that are able to exploit different types of behavior in order to discover howpeople influence each other. Several strategies for influence network discovery areproposed and discussed. Moreover; we present a case study on the application of such …,Proc. of the 17th Brazilian Symposium on Multimedia; Hypermedia and Web,2011,12
Adaptive and flexible blocking for record linkage tasks,Luiz Osvaldo Evangelista; Eli Cortez; Altigran S da Silva; Wagner Meira Jr,Abstract In data integration tasks; records from a single dataset or from different sourcesmust often be compared to identify records that represent the same real world entity. Thecost of this search process for finding duplicate records grows quadratically as the number ofrecords available in the data sources increases and; for this reason; direct approaches; suchas comparing all record pairs; must be avoided. In this context; blocking methods are used tocreate,Journal of Information and Data Management,2010,12
Spamming chains: a new way of understanding spammer behavior,Pedro H Calais Guerra; Dorgival Guedes; W Meira; Cristine Hoepers; MHPC Chaves; KS Jessen,ABSTRACT In the effort of keeping their identities hidden; spammers rely on many weapons;such as the use of open proxies; open relays and compromised machines to conceal thespam origin before they deliver messages through SMTP. In this work; we study how today'ssophisticated spammers combine such techniques; chaining machines along the network todeliver their messages anonymously. Our analysis was based on the observation of HTTPand SMTP traffic from connections established by spammers to a set of low-interactionhoneypots. The main contribution of this paper is to show how the understanding of suchchains can unveil information beyond that obtained from previous spam analysistechniques; often characterized by focusing on a single point of the spam disseminationprocess. In particular; we show that honeypots that emulate open proxies and open relays …,The 6th g Conference on Email and Anti-Spam,2009,12
Maximal termsets as a query structuring mechanism,Bruno Pôssas; Nivio Ziviani; Berthier Ribeiro-Neto; Wagner Meira Jr,Abstract Search engines process queries conjunctively to restrict the size of the answer set.Further; it is not rare to observe a mismatch between the vocabulary used in the text of Webpages and the terms used to compose the Web queries. The combination of these twofeatures might lead to irrelevant query results; particularly in the case of more specificqueries composed of three or more terms. To deal with this problem we propose a newtechnique for automatically structuring Web queries as a set of smaller subqueries. To selectrepresentative subqueries we use information on their distributions in the documentcollection. This can be adequately modeled using the concept of maximal termsets derivedfrom the formalism of association rules theory. Experimentation shows that our techniqueleads to improved results. For the TREC-8 test collection; for instance; our technique led …,Proceedings of the 14th ACM international conference on Information and knowledge management,2005,12
Assessing the profile of top Brazilian computer science researchers,Harlley Lima; Thiago HP Silva; Mirella M Moro; Rodrygo LT Santos; Wagner Meira; Alberto HF Laender,Abstract Quantitative and qualitative studies of scientific performance provide a measure ofscientific productivity and represent a stimulus for improving research quality. Whatever thegoal (eg; hiring; firing; promoting or funding); such analyses may inform research agencieson directions for funding policies. In this article; we perform a data-driven assessment of theperformance of top Brazilian computer science researchers considering three centraldimensions: career length; number of students mentored; and volume of publications andcitations. In addition; we analyze the researchers' publishing strategy; based upon their areaof expertise and their focus on venues of different impact. Our findings demonstrate that it isnecessary to go beyond counting publications to assess research quality and show theimportance of considering the peculiarities of different areas of expertise while carrying …,Scientometrics,2015,11
HydroPaCe: understanding and predicting cross-inhibition in serine proteases through hydrophobic patch centroids,Valdete M Gonçalves-Almeida; Douglas EV Pires; Raquel Cardoso de Melo-Minardi; Carlos Henrique da Silveira; W Meira; Marcelo M Santoro,Abstract Motivation: Protein–protein interfaces contain important information aboutmolecular recognition. The discovery of conserved patterns is essential for understandinghow substrates and inhibitors are bound and for predicting molecular binding. When aninhibitor binds to different enzymes (eg dissimilar sequences; structures or mechanismswhat we call cross-inhibition); identification of invariants is a difficult task for which traditionalmethods may fail. Results: To clarify how cross-inhibition happens; we model the problem;propose and evaluate a methodology called HydroPaCe to detect conserved patterns.Interfaces are modeled as graphs of atomic apolar interactions and hydrophobic patches arecomputed and summarized by centroids (HP-centroids); and their conservation is detected.Despite sequence and structure dissimilarity; our method achieves an appropriate level of …,Bioinformatics,2011,11
Watershed: A high performance distributed stream processing system,Thatyene Louise Alves de Souza Ramos; Rodrigo Silva Oliveira; Ana Paula de Carvalho; Renato Antônio Celso Ferreira; Wagner Meira Jr,The task of extracting information from datasets that become larger at a daily basis; such asthose collected from the web; is an increasing challenge; but also provides more interestinginsights and analysis. Current analyses went beyond content and now focus on tracking andunderstanding users' relationships and interactions. Such computation is intensive both interms of the processing demand imposed by the algorithms and also the sheer amount ofdata that has to handled. In this paper we introduce Watershed; a distributed computingframework designed to support the analysis of very large data streams online and in real-time. Data are obtained from streams by the system's processing components; transformed;and directed to other streams; creating large flows of information. The processingcomponents are decoupled from each other and their connections are strictly data-driven …,Computer Architecture and High Performance Computing (SBAC-PAD); 2011 23rd International Symposium on,2011,11
Automatic document classification temporally robust,Thiago Salles; Leonardo Rocha; Fernando Mourao; Gisele L Pappa; Lucas Cunha; Marcos André Gonçalves; Wagner Meira Jr,Abstract. The widespread use of the Internet has increased the amount of information beingstored on and accessed through the Web. This information is frequently organized as textualdocuments and is the main target of search engines and other retrieval tools; which have toclassify documents; among other tasks. Automatic Document Classification (ADC)associates documents to semantically meaningful categories; and usually employs asupervised learning strategy; where we first build a classification model using pre-classifieddocuments; and then use the model to classify new documents. One major challenge inbuilding classifiers is dealing with the temporal evolution of the characteristics of thedocuments and the classes to which they belong. However; most of the current techniquesfor ADC do not consider this evolution while building and using the models. Previous …,Journal of Information and Data Management,2010,11
Seller's credibility in electronic markets: a complex network based approach,Adriano M Pereira; Arlei Silva; Wagner Meira Jr; Virgilio Almeida,Abstract In the last decade; there has been an explosion of online commercial activityenabled by the World Wide Web. An electronic marketplace (e-market) provides an onlinemethod to perform transactions between buyers and sellers; potentially supporting all of thesteps in the entire order fulfillment process. Credibility is an important requirement for thesuccess of an e-market. In this work we model and characterize an e-market as a complexnetwork and use the network structure to investigate the sellers' credibility. We propose anew algorithm; based on the structure of the negotiation network; to recommend whether theseller is trustable or not. We use real data from a online marketplace from the biggestBrazilian Internet Service Provider as case study. Besides being a prelimary work; ourtechnique achieves good results in terms of accuracy; predicting correctly the results in …,Proceedings of the 3rd workshop on Information credibility on the web,2009,11
Partricluster: a scalable parallel algorithm for gene expression analysis,Renata Araujo; Guilherme Trielli; Gustavo Orair; Wagner Meira Jr; Renato Ferreira; Dorgival Guedes,Analyzing gene expression patterns is becoming a highly relevant task in the bio informaticsarea. This analysis makes it possible to determine the behavior patterns of genes undervarious conditions; a fundamental information for treating diseases; among otherapplications. An advance in this area is the tricluster algorithm; which is the first algorithmcapable of determining 3D clusters; that is; it determines clusters of sets of genes thatbehave similarly in a set of samples and set of time stamps. However; while biologicalexperiments collect an increasing amount of data to be analyzed and correlated; thetriclustering problem is NP-complete; and its parallelization seems to be an essential steptowards obtaining feasible solutions. In this paper we propose and evaluate theimplementation of a parallel version of the tricluster algorithm using the filter-labeled …,Computer Architecture and High Performance Computing; 2006. SBAC-PAD'06. 18TH International Symposium on,2006,11
Disclosing users' data in an environment that preserves privacy,Bruno Gusmão Rocha; Virgílio AF Almeida; Lucila Ishitani; Wagner Meira Jr,Abstract The conflict between Web service personalization and privacy is a challenge in theinformation society. In this paper we address this challenge by introducing MASKS; anarchitecture that provides data on the users' interests to Web services; without violating theirprivacy. The proposed approach hides the actual identity of users by classifying them intogroups; according to their interests exhibited during the interaction with a Web service. Bymaking requests on behalf of a group; instead of an individual user; MASKS providesrelevant information to the Web services; without disclosing the identity of the users. Wehave implemented and tested a grouping algorithm; based on categories defined by thesemantic tree of DMOZ. We used access logs from actual e-commerce sites to evaluate thegrouping algorithm. Our tests show that 64% of the requests made to the e-commerce …,Proceedings of the 2002 ACM workshop on Privacy in the Electronic Society,2002,11
Design and implementation of a tool for measuring the performance of complex e-commerce sites,Goedson T Paixão; Wagner Meira; Virgilio AF Almeida; Daniel A Menascé; Adriano M Pereira,Abstract E-commerce applications are growing at unprecedent rates; resulting in overloadedsites with poor quality of service. The workload intensity of an e-commerce site is not totallypredictable given that external events can generate load spikes that exceed by far theaverage load. Therefore; e-commerce site managers need to be able to understand theperformance of the site and be able to tune it to cope with varying traffic patterns. In thispaper we present PROFIT; a new tool for profiling the performance of e-commerce sites.PROFIT measures both throughput and response time and breaks down the response timein terms of components (eg; Web server; application server; and database server) andservices (eg; search; browse; select; add to cart; and pay). To illustrate the use of the tool;the paper shows an analysis of performance and security in e-commerce applications …,International Conference on Modelling Techniques and Tools for Computer Performance Evaluation,2000,11
Profiling divergences in gpu applications,Bruno Coutinho; Diogo Sampaio; Fernando MQ Pereira; Wagner Meira,SUMMARY The increasing programmability and the high computational power of graphicsprocessing units make them attractive to general purpose programming. However; taking fullbenefit of this execution environment is a challenging task. One of these challenges stemsfrom divergences; a phenomenon that occurs when threads that execute in lock-step areforced to take different program paths because of branches in the code. In face ofdivergences; some threads will have to wait; idly; while their diverging siblings execute.Optimizing the code to avoid divergences is difficult because this task demands a deepunderstanding of programs that might be large and convoluted. To facilitate the detection ofdivergences; this paper introduces the divergence map; a data structure that indicates thelocation and the volume of divergences in a program. We build this map via dynamic …,Concurrency and Computation: Practice and Experience,2013,10
The Oblivion Problem: Exploiting Forgotten Items to Improve Recommendation Diversity.,Fernando Mourão; Claudiane Fonseca; Camila Souza Araujo; Wagner Meira Jr,ABSTRACT Recommender Systems (RSs) have become a crucial tool to assist users in theirchoices on various commercial applications. Despite recent advances; there is still room formore effective techniques that are applicable to a larger range of domains. A majorchallenge recurrently researched is the lack of diversity in the recommendation listsprovided by current RSs. That is; besides being effective to suggest interesting items tousers; a good RS should provide useful and diversified items. In order to address thisproblem; we evaluate the use of forgotten items in recommendation. By forgotten items; wemean items that have been very relevant to users in the past but are not anymore. Therefore;we formally define the Oblivion Problem; which is the problem of recommending forgottenitems; propose a methodology for verifying it in real scenarios; and perform a deep …,DiveRS@ RecSys,2011,10
Semi-supervised genetic programming for classification,Filipe de Lima Arcanjo; Gisele Lobo Pappa; Paulo Viana Bicalho; Wagner Meira Jr; Altigran Soares da Silva,Abstract Learning from unlabeled data provides innumerable advantages to a wide range ofapplications where there is a huge amount of unlabeled data freely available. Semi-supervised learning; which builds models from a small set of labeled examples and apotential large set of unlabeled examples; is a paradigm that may effectively use thoseunlabeled data. Here we propose KGP; a semi-supervised transductive geneticprogramming algorithm for classification. Apart from being one of the first semi-supervisedalgorithms; it is transductive (instead of inductive); ie; it requires only a training dataset withlabeled and unlabeled examples; which should represent the complete data domain. Thealgorithm relies on the three main assumptions on which semi-supervised algorithms arebuilt; and performs both global search on labeled instances and local search on …,Proceedings of the 13th annual conference on Genetic and evolutionary computation,2011,10
Performance debugging of GPGPU applications with the divergence map,Bruno Coutinho; Diogo Sampaio; Fernando MQ Pereira; Wagner Meira Jr,The increasing programability and the high computational power of Graphical ProcessingUnits (GPU) make them attractive to general purpose programming. However; taking fullbene t of this execution environment is a challenging task. One of these challenges stemfrom divergences; a phenomenon that occurs when threads that execute in lock-step areforced to take di erent program paths due to branches in the code. In face of divergences;some threads will have to wait; idly; while their diverging siblings execute. Optimizing thecode to avoid divergences is diffcult; because this task demands a deep understanding ofprograms that might be large and convoluted. In order to facilitate the detection ofdivergences; this paper introduces the divergence map; a data structure that indicates thelocation and the volume of divergences in a program. We build this map via dynamic …,Computer Architecture and High Performance Computing (SBAC-PAD); 2010 22nd International Symposium on,2010,10
A contact map matching approach to protein structure similarity analysis,Raquel C de Melo; CE Lopes; Fernando A Fernandes Jr; Carlos Henrique da Silveira; Marcelo M Santoro; Rodrigo L Carceroni; Wagner Meira Jr; A Araujo Ade,ABSTRACT. We modeled the problem of identifying how close two proteins are structurallyby measuring the dissimilarity of their contact maps. These contact maps are coloredimages; in which the chromatic information encodes the chemical nature of the contacts. Westudied two conceptually distinct image-processing algorithms to measure the dissimilaritybetween these contact maps; one was a content-based image retrieval method; and theother was based on image registration. In experiments with contact maps constructed fromthe protein data bank; our approach was able to identify; with greater than 80% precision;instances of monomers of apolipoproteins; globins; plastocyanins; retinol binding proteinsand thioredoxins; among the monomers of Protein Data Bank Select. The image registrationapproach was only slightly more accurate than the content-based image retrieval …,Genet Mol Res,2006,10
Processing conjunctive and phrase queries with the set-based model,Bruno Pôssas; Nivio Ziviani; Berthier Ribeiro-Neto; Wagner Meira,Abstract The objective of this paper is to present an extension to the set-based model (SBM);which is an effective technique for computing term weights based on co-occurrence patterns;for processing conjunctive and phrase queries. The intuition that semantically related termoccurrences often occur closer to each other is taken into consideration. The novelty is thatall known approaches that account for co-occurrence patterns was initially designed forprocessing disjunctive (OR) queries; and our extension provides a simple; effective andefficient way to process conjunctive (AND) and phrase queries. This technique is timeefficient and yet yields nice improvements in retrieval effectiveness. Experimental resultsshow that our extension improves the average precision of the answer set for all collectionevaluated; keeping computational cost small. For the TReC-8 collection; our extension …,International Symposium on String Processing and Information Retrieval,2004,10
A methodology for workload characterization of filesharing peer-to-peer networks,Diêgo Nogueira; Leonardo Rocha; Juliano Santos; Paulo Araújo; Virgılio Almeida; W Meira,The main characteristic of peer-to-peer (P2P) networks is that the hosts in the network mayact as both clients and servers at the same time; being called servents. These networks havebeen widely adopted for sharing idle computational resources available in the Internet;improving content accessibility while reducing costs and response latency; although hostavailability and content coherence is not usually guaranteed. As a consequence; traditionalworkload characterization strategies are not suitable for analyzing and understanding thesenetworks; motivating the design of specific strategies for their characterization. In this articlewe present a novel workload characterization methodology for P2P networks; which accountfor the main features of these networks. We validate our methodology through thecharacterization of the Gnutella network; through which we are able to characterize file …,WWC’02: Proceedings of the 5th IEEE International Workshop on Workload Characterization,2002,10
Characterizing and modeling robot workload on e-business sites,V Almeida; R Riedi; D Menascé; W Meira; F Ribeiro; R Fonseca,*,Proc. 2001 ACM Sigmetrics Conference,2001,10
The influence of geographical and cultural issues on the cache proxy server workload,Vírgilio F Almeida; Márcio G Cesário; Rodrigo C Fonseca; Wagner Meira Jr; Cristina D Murta,Abstract A key characteristic of the Internet is its global diffusion; that shows a rapid growth ofthe number of hosts and international links around the world. The diffusion of the Internethas been accompanied by serious performance problems; such as long response times;server overload and network congestion. Caching has been used as a standard solution tominimize the problem. In this paper; we analyze logs of caching proxy servers and showevidence that geographical; cultural and social issues have a strong influence on theworkload of a proxy server. Therefore; the cultural and social context provide relevantinformation to plan efficient caching proxy architectures.,Computer Networks and ISDN Systems,1998,10
Understanding parallel program performance using cause-effect analysis,Wagner Meira Jr,Abstract There is a constant need throughout the life cycle of a parallel program foranalyzing; tuning; and predicting its performance. These tasks all require that theprogrammer understand the performance exhibited by a program; and the performanceimplications of alternative implementations. Achieving such an understanding is extremelydifficult; however; since a program''s performance depends on characteristics of theapplication; the underlying hardware; the software environment; and interactions among allthree. In this dissertation; we show how to automatically generate explanations forperformance behavior and thereby facilitate performance analysis; tuning; and prediction..pp We propose an integrated framework for performance understanding called Carnival;which supports the acquisition and manipulation of large amounts of performance data …,*,1997,10
Demand-driven associative classification,Adriano Veloso; Wagner Meira,Abstract The ultimate goal of classification algorithms is to achieve the best possibleclassification performance for the problem at hand. Most often; classification performance isobtained by assessing some accuracy criterion using the test set; T. Therefore; an effectiveclassification in T. As discussed; it is often hard to approximate the target function definedover inputs in T; using a single mapping function. The key insight is to produce a specificallydesigned function; f^ x_i _ S; which approximates the target function at each input x_i ∈ T.Thus; a natural way to improve classification in T; on a demand-driven basis. In this case;particular characteristics of each input in T may be taken into account while predicting thecorresponding output. The expected result is a set of multiple mapping functions; whereeach function f^ x_i _ S is likely to perform particularly accurate predictions for input x_i ∈ …,*,2011,9
Increasing user's privacy control through flexible web bug detection,Fabiano Fonseca; Robert Pinto; W Meira,People usually provide personal information when visiting Web sites; even though they arenot aware of this fact. In some cases; the collected data is misused; resulting on user privacyviolation. The existing tools which aim at guaranteeing user privacy usually restrict access topersonalized services. In this work; we propose the Web bug detector. Upon detecting andinforming users about browsing tracking mechanisms which invisibly collect their personalinformation when visiting sites; it represents an alternative that provides a better control overprivacy while allowing personalization. Through experimental results; we demonstrate theapplicability of our strategy by applying the detector to a real workload. We found that about5.37% of user's requests were being tracked by third-party sites.,Web Congress; 2005. LA-WEB 2005. Third Latin American,2005,9
AnthillSched: A scheduling strategy for irregular and iterative I/O-intensive parallel jobs,Luís Fabrício Góes; Pedro Guerra; Bruno Coutinho; Leonardo Rocha; Wagner Meira; Renato Ferreira; Dorgival Guedes; Walfredo Cirne,Abstract Irregular and iterative I/O-intensive jobs need a different approach from parallel jobschedulers. The focus in this case is not only the processing requirements anymore:memory; network and storage capacity must all be considered in making a schedulingdecision. Job executions are irregular and data dependent; alternating between CPU-boundand I/O-bound phases. In this paper; we propose and implement a parallel job schedulingstrategy for such jobs; called AnthillSched; based on a simple heuristic: we map thebehavior of a parallel application with minimal resources as we vary its input parameters.From that mapping we infer the best scheduling for a certain set of input parameters giventhe available resources. To test and verify AnthillSched we used logs obtained from a realsystem executing data mining jobs. Our main contributions are the implementation of a …,Workshop on Job Scheduling Strategies for Parallel Processing,2005,9
Scheduling data flow applications using linear programming,Luiz Thomaz do Nascimento; Renato A Ferreira; W Meira; Dorgival Guedes,Grid environments are becoming cost-effective substitutes to supercomputers. Datacutter isone of several initiatives in creating mechanisms for applications to efficiently exploit the vastcomputation power of such environments. In Datacutter; applications are modeled as a set ofcommunicating filters that may run on several nodes of a computational grid. To achievehigh performance; a number of transparent copies of each of the filters that comprise theapplication need to be appropriately placed on different nodes of the grid. Such task iscarried out by a scheduler which is the focus of this work. We present LPSched; a schedulerfor Datacutter applications which uses linear programming to make decisions about thenumber of copies of each filter as well as the placement of each of the copies across thenodes. LPSched bases its decisions upon the performance behavior of each filter as well …,Parallel Processing; 2005. ICPP 2005. International Conference on,2005,9
State maintenance and its impact on the performability of multi-tiered internet services,G Gamat; Kiran Nagaraja; Ricardo Bianchini; RR Martin; W Meira; Thu D Nguyen,In this paper; we evaluate the performance; availability; and combined performability of foursoft state maintenance strategies in two multitier Internet services; an online book store andan auction service. To take soft state and service latency into account; we propose anextension of our previous quantification methodology; and novel availability andperformability metrics. Our results demonstrate that storing the soft state in a database canachieve better performability than storing it in main memory; even when the state isefficiently replicated. Strategies that offload the handling of soft state from the databaseincrease the load on other tiers and; consequently; increase the impact of faults in these tierson service availability. Based on these results; we conclude that service designers need toprovision the cluster and balance the load with availability and cost; as well as …,Reliable Distributed Systems; 2004. Proceedings of the 23rd IEEE International Symposium on,2004,9
New parallel algorithms for frequent itemset mining in very large databases,Adriano Veloso; Wagner Meira; Srinivasan Parthasarathy,Frequent itemset mining is a classic problem in data mining. It is a nonsupervised processwhich concerns in finding frequent patterns (or itemsets) hidden in large volumes of data inorder to produce compact summaries or models of the database. These models are typicallyused to generate association rules; but recently they have also been used in far reachingdomains like e-commerce and bio-informatics. Because databases are increasing in termsof both dimension (number of attributes) and size (number of records); one of the mainissues in a frequent itemset mining algorithm is the ability to analyze very large databases.Sequential algorithms do not have this ability; especially in terms of run-time performance;for such very large databases. Therefore; we must rely on high performance parallel anddistributed computing. We present new parallel algorithms for frequent itemset mining …,Computer Architecture and High Performance Computing; 2003. Proceedings. 15th Symposium on,2003,9
Real world association rule mining,Adriano Veloso; Bruno Rocha; Márcio de Carvalho; Wagner Meira,Abstract Across a wide variety of fields; data are being collected and accumulated at adramatic pace; and therefore a new generation of techniques has been proposed to assisthumans in extracting usefull information from the rapidly growing volumes of data. One ofthese techniques is the association rule discovery; a key data mining task which hasattracted tremendous interest among data mining researchers. Due to its vast applicability;many algorithms have been developed to perform the association rule mining task.However; an immediate problem facing researchers is which of these algorithms is likely tomake a good match with the database to be used in the mining operation. In this paper weconsider this problem; dealing with both algorithmic and data aspects of association rulemining by performing a systematic experimental evaluation of different algorithms on …,British National Conference on Databases,2002,9
Uncovering the location of Twitter users,Erica Rodrigues; Renato Assunção; Gisele L Pappa; Renato Miranda; Wagner Meira,Social networks; like Twitter and Facebook; are valuable sources to monitor real-timeevents; such as earthquakes and epidemics. For this type of surveillance the user's locationis an essential piece of information; but a substantial number of users choose not to disclosetheir geographical information. However; characteristics of the users' behavior; such as thefriends they associate with and the types of messages published may hint on their spatiallocation. In this paper; we present a method to infer the spatial location of Twitter users.Unlike the approaches proposed so far; we incorporate two sources of information to learnthe geographical position: the text posted by users and their friendship network. We proposea probabilistic approach that jointly models the geographical labels and the Twitter texts ofthe users organized in the form of a graph representing the friendship network. We use …,Intelligent Systems (BRACIS); 2013 Brazilian Conference on,2013,8
Spamming chains: A new way of understanding spammer behavior,Pedro Henrique Calais; Dorgival Guedes; Wagner Meira Jr; Cristine Hoepers; Marcelo HPC Chaves; Klaus Steding Jessen,*,*,2009,8
The ParTriCluster algorithm for gene expression analysis,Renata Braga Araújo; Guilherme Henrique Trielli Ferreira; Gustavo Henrique Orair; Wagner Meira; Renato Antônio Celso Ferreira; Dorgival Olavo Guedes Neto; Mohammed Javeed Zaki,Abstract Analyzing gene expression patterns is becoming a highly relevant task in theBioinformatics area. This analysis makes it possible to determine the behavior patterns ofgenes under various conditions; a fundamental information for treating diseases; amongother applications. A recent advance in this area is the Tricluster algorithm; which is the firstalgorithm capable of determining 3D clusters (genes× samples× timestamps); that is; groupsof genes that behave similarly across samples and timestamps. However; even thoughbiological experiments collect an increasing amount of data to be analyzed and correlated;the triclustering problem remains a bottleneck due to its NP-Completeness; so itsparallelization seems to be an essential step towards obtaining feasible solutions. In thiswork we propose and evaluate the implementation of a parallel version of the Tricluster …,International Journal of Parallel Programming,2008,8
A campaign-based characterization of spamming strategies,PHC Guerra; DEV Pires; D Guedes; J Wagner Meira; C Hoepers; K Steding-Jessen,*,Proceedings of the 5th Conference on e-mail and anti-spam (CEAS); Mountain View; CA,2008,8
Assessing reactive qos strategies for internet services,Adriano Pereira; Leonardo Silva; W Meira; Walter Santos,The design of systems with better performance is a real need to fulfil user demands andgenerate profitable Web applications. Understand user behavior and workload they produceon the server is fundamental to evaluate the performance of systems and theirimprovements. User reactivity; that is; how the users react to variable server response time;is usually neglected during performance evaluation. This work addresses the use ofreactivity to improve QoS of Internet services. We propose and evaluate new admissioncontrol policies. We designed and implemented the USAR-QoS simulator that allows theevaluation of the new QoS strategies considering the dynamic interaction between clientand server sides in Internet services. The simulation uses a TPC-W-based workload andshows the benefits of the reactive policies; which can result in better QoS. The …,Applications and the Internet; 2006. SAINT 2006. International Symposium on,2006,8
Real-time MPEG encoding in shared-memory multiprocessors,Denilson M Barbosa; Joao Paulo Kitajima; Wagner Meira Jr,Abstract Advances in digital imaging and faster networking resources enabled anunprecedent popularization of digital video applications; not only for entertainment; but alsofor health and education. However; capturing; digitizing; storing and displaying video in realtime remains a challenge for nowadays technology. Furthermore; the large number offrames that compose a digital video; each of them occupying hundreds of kilobytes; stresssignificantly both storage and networking resources available currently. A common strategyto reduce the amount of data that has to be handled while providing digital video services iscompression; as specified by the MPEG coding standards; for instance. The compressioncost then becomes the greatest; demanding the use of either specialized hardware orparallel computing to meet the real time demands. In this work; we propose a novel …,2nd International Conference on Parallel Computing Systems,1999,8
Analyzing performance of cache server hierarchies,W Meira; Erik Fonseca; Cristina Murta; Virgilio Almeida,Although caching and the creation of cache server hierarchies has became a popularstrategy for reducing user waiting time and network traffic; there is no recipe for determiningthe best hierarchy configuration given a set of machines and the workload that they have toserve. The paper presents a novel approach for analyzing the performance of cache proxyhierarchies that is based on two metrics: hierarchical hit ratio and cache efficiency. Thisapproach allows users to easily quantify trade-offs among configurations; facilitating thetuning of cache hierarchies. The authors illustrate their approach by analyzing possibleconfigurations for a proxy server.,Computer Science; 1998. SCCC'98. XVIII International Conference of the Chilean Society of,1998,8
Smart traffic light for low traffic conditions,Cristiano M Silva; Andre LL Aquino; Wagner Meira,Abstract This work presents a novel traffic device (LaNPro) that avoids the stop of vehicles atjunctions under low traffic conditions. To the best of our knowledge; this is the first smarttraffic light designed for low traffic conditions. LaNPro is a security solution to preserve thephysical integrity of drivers in countries with high social discrepancy. The server-side of thesolution is deployed as a module of a smart traffic light; and it senses the presence ofvehicles along the road through input devices (radars; cameras; road sensors; wirelesscommunication) to assign the right of way. While any smart traffic light is able to manage lowtraffic intersections; we argue that they are not specialized devices to perform such task; andthus they may lack important optimizations. The main aggregated value of our approach isthe ability to handle low traffic conditions; and that involves several challenges. Results …,Mobile Networks and Applications,2015,7
Exploiting non-content preference attributes through hybrid recommendation method,Fernando Mourão; Leonardo Rocha; Joseph A Konstan; Wagner Meira Jr,Abstract This paper explores a method for incorporating into a recommender system explicitrepresentations of user's preferences over non-content attributes such as popularity;recency; and similarity of recommended items. We show how such attributes can bemodeled as a preference vector that can be used in a vector-space content-basedrecommender; and how that content-based recommender can be integrated with variouscollaborative filtering techniques through re-weighting of Top-M recommendations. Weevaluate this approach on several recommender systems datasets and collaborative filteringmethods; and find that incorporating the three preference attributes can lead to a substantialincrease in Top-50 precision while also enhancing diversity and novelty.,Proceedings of the 7th ACM conference on Recommender systems,2013,7
Simulations of complex and microscopic models of cardiac electrophysiology powered by Multi-GPU platforms,Bruno Gouvêa de Barros; Rafael Sachetto Oliveira; Wagner Meira; Marcelo Lobosco; Rodrigo Weber dos Santos,Key aspects of cardiac electrophysiology; such as slow conduction; conduction block; andsaltatory effects have been the research topic of many studies since they are strongly relatedto cardiac arrhythmia; reentry; fibrillation; or defibrillation. However; to reproduce thesephenomena the numerical models need to use subcellular discretization for the solution ofthe PDEs and nonuniform; heterogeneous tissue electric conductivity. Due to the highcomputational costs of simulations that reproduce the fine microstructure of cardiac tissue;previous studies have considered tissue experiments of small or moderate sizes and usedsimple cardiac cell models. In this paper; we develop a cardiac electrophysiology model thatcaptures the microstructure of cardiac tissue by using a very fine spatial discretization (8 μm)and uses a very modern and complex cell model based on Markov chains for the …,Computational and mathematical methods in medicine,2012,7
Spam miner: a platform for detecting and characterizing spam campaigns,Pedro H Calais Guerra; Douglas EV Pires; Marco Túlio C Ribeiro; Dorgival Guedes; Wagner Meira Jr; Cristine Hoepers; Marcelo HPC Chaves; Klaus Steding-Jessen,ABSTRACT This demo presents Spam Miner; an online system designed for real-timemonitoring and characterization of spam traffic over the Internet. Our system is based onhigh-level abstractions such as spam message attributes; spam campaigns and spammingstrategies. A campaign is a cluster of messages that are generated from a single messagetemplate; campaign identification is a challenging problem because it has to handlespammer evolution; while seeking for a spam similarity function that combines differentmessage characteristics and for strategies that efficiently process large volumes of spams.Moreover; spam campaigns need to be identified on-the-fly; to allow incident responseteams and security specialists to react to the threat adequately. Spam Miner addressescampaign identification as a data clustering problem and campaigns are identified …,Proc. 6th Conf. Email Anti-Spam,2008,7
Multi-level parallelism in the computational modeling of the heart,Carolina Xavier; Rafael Sachetto; Vinicius Vieira; Rodrigo Weber dos Santos; Wagner Meira Jr,Computational modeling of the heart has demonstrated to be a useful tool for theinvestigation and comprehension of the complex biophysical processes that underliecardiac function. Unfortunately; large scale simulations; such as those resulting from thediscretization of an entire heart; remain a computational challenge. In order to reducesimulation execution times; parallel implementations have traditionally exploited dataparallelism via numerical schemes based on domain-decomposition. However; it has beenverified that the parallel efficiency of these implementations severely degrades as thenumber of processors increases. In this work; we propose and implement a new parallelalgorithm for the solution of cardiac models. By relaxing the coherence of the execution; anew level of parallelism could be identified and exploited: pipelining. A synchronous …,Computer Architecture and High Performance Computing; 2007. SBAC-PAD 2007. 19th International Symposium on,2007,7
Reactivity-based scheduling approaches for internet services,Leonardo Silva; Adriano Pereira; Wagner Meira Jr,Understanding the characteristics of Internet services workloads is a crucial step to improvethe quality of service offered to Web users. One aspect that is usually neglected during aperformance evaluation is the user reactivity; ie; how the users react to variable serverresponse time. This paper addresses the use of reactivity to improve the quality of service(QoS) of Internet services. We propose and evaluate two new scheduling approaches: thepatient-first impatient-next (PFIN); and the impatient-first patient-next (IFPN). We design andimplement the USAR-QoS simulator that allows the evaluation of QoS strategies consideringthe dynamic interaction between client and server sides. We simulate the new strategiesusing a TPC-W-based workload. The experiments show the benefits of the reactive policieswhich can result in better QoS for Internet services; improving the user satisfaction,Web Congress; 2006. LA-Web'06. Fourth Latin American,2006,7
Evaluating the impact of reactivity on the performance of web applications,Adriano Pereira; Leonardo Silva; Wagner Meira,The great success of the Internet has raised new challenges in terms of applications and thesatisfaction of their users. In fact; there is strong evidence that a significant part of the userbehavior depends on its satisfaction. Users reactions may affect the load of a server;establishing successive interactions where the user behavior affects the system behaviorand vice-versa. It is important to understand this interactive process to design systems moresuited to user requirements. In this work we study and explain how this reactive interaction isperformed by users and how it affects the system's performance. We perform experimentsusing a real server under a TPC-W-based workload generated using a reactive version ofhttperf. We also simulate different workload configurations in order to evaluate the effects onthe system's load. The results show that accounting for reactivity causes a significant …,Performance; Computing; and Communications Conference; 2006. IPCCC 2006. 25th IEEE International,2006,7
Reactivity in online auctions,Adriano Pereira; Fernando Mourão; Paulo Góes; Wagner Meira,Abstract Interactive computer systems; that is; systems in which users cyclically interact bygetting and providing information; have already a widespread and increasing use in allareas of our society. One characteristic of such systems is that the user behavior affects thesystem behavior and vice-versa. There is strong evidence that much of the user behavior isreactive; that is; the user reacts to the instantaneous conditions at the action time. This paperpresents the reactivity concept and describes a framework to model it in interactive systems;in particular Internet-based systems. We analyze an online auction within the framework.Based on eBay data; we identify attributes that affect the winner bidders' behavior; such asthe auction time to finish. This paper presents the first findings towards the formal descriptionand understanding of reactivity patterns in an e-commerce application; which will be …,International Conference on Extending Database Technology,2006,7
Rule Generation and Rule Selection Techniques for Cost-Sensitive Associative Classification.,Adriano Veloso; Wagner Meira Jr,Abstract. Classification aims to assign a data object to its appropriate class; what istraditionally performed through a small dataset model such as decision tree. Associativeclassification is a novel strategy for performing this task where the model is composed of aparticular set of association rules; in which the consequent of each rule (ie; its right-hand-side) is restricted to the classification class attribute. Rule generation and rule selection aretwo major issues in associative classification. Rule generation aims to find a set ofassociation rules that better describe the entire dataset; while rule selection aims to select;for a particular case; the best rule among all rules generated. Rule generation and ruleselection techniques dramatically affect the effectiveness of the classifier. In this paper wepropose new techniques for rule generation and rule selection. In our proposed …,SBBD,2005,7
Exploring multiple evidence to infer users’ location in Twitter,Erica Rodrigues; Renato Assunção; Gisele L Pappa; Diogo Renno; Wagner Meira Jr,Abstract Online social networks are valuable sources of information to monitor real-timeevents; such as earthquakes and epidemics. For this type of surveillance; users' location isan essential piece of information; but a substantial number of users choose not to disclosetheir geographical location. However; characteristics of the users׳ behavior; such as thefriends they associate with and the types of messages published may hint on their spatiallocation. In this paper; we propose a method to infer the spatial location of Twitter users.Unlike the approaches proposed so far; it incorporates two sources of information to learngeographical position: the text posted by users and their friendship network. We propose aprobabilistic approach that jointly models the geographical labels and Twitter texts of usersorganized in the form of a graph representing the friendship network. We use the Markov …,Neurocomputing,2016,6
Learning sequential classifiers from long and noisy discrete-event sequences efficiently,Gessé Dafé; Adriano Veloso; Mohammed Zaki; Wagner Meira,Abstract A variety of applications; such as information extraction; intrusion detection andprotein fold recognition; can be expressed as sequences of discrete events or elements(rather than unordered sets of features); that is; there is an order dependence among theelements composing each data instance. These applications may be modeled asclassification problems; and in this case the classifier should exploit sequential interactionsamong the elements; so that the ordering relationship among them is properly captured.Dominant approaches to this problem include:(i) learning Hidden Markov Models;(ii)exploiting frequent sequences extracted from the data and (iii) computing string kernels.Such approaches; however; are computationally hard and vulnerable to noise; especially ifthe data shows long range dependencies (ie; long subsequences are necessary in order …,Data Mining and Knowledge Discovery,2015,6
Thread scheduling and memory coalescing for dynamic vectorization of SPMD workloads,Teo Milanez; Sylvain Collange; Fernando Magno Quintão Pereira; Wagner Meira Jr; Renato Ferreira,Abstract Simultaneous Multi-Threading (SMT) is a hardware model in which different threadsshare the same processing unit. This model is a compromise between high parallelism andlow hardware cost. Minimal Multi-Threading (MMT) is one architecture recently proposedthat shares instruction decoding and execution between threads running the same programin an SMT processor; thereby generalizing the approach followed by Graphics ProcessingUnits to general-purpose processors. In this paper we propose new ways to exposeredundancies in the MMT execution model. First; we propose and evaluate a new threadreconvergence heuristic that handles function calls better than previous approaches. Ourheuristic only inspects the program counter and the stack frame to reconverge threads;hence; it is amenable to efficient and inexpensive hardware implementation. Second; we …,Parallel Computing,2014,6
ADVISe: Visualizing the dynamics of enzyme annotations in UniProt/Swiss-Prot,Sabrina A Silveira; Artur O Rodrigues; Raquel C de Melo-Minardi; Carlos Henrique da Silveira; Wagner Meira,In this paper; we propose an interactive visualization called ADVISe (Annotation DynamicsVisualization); which tackles the problem of visualizing evolutions in enzyme annotationsacross several releases of the UniProt/SwissProt database. More specifically; we visualizethe dynamics of Enzyme Commission numbers (EC numbers); which are a numerical andhierarchical classification scheme for enzymes based on the chemical reactions theycatalyze. An EC number consists of four numbers separated by periods and represents aprogressively finer classification of the catalyzed reaction. The proposed interactivevisualization gives a macro view of the changes and presents further details on demand;such as frequencies of change types segmented by levels of generalization andspecialization as well as by enzyme families. Users can also explore entry metadata. With …,Biological Data Visualization (BioVis); 2012 IEEE Symposium on,2012,6
Observatório do Trânsito: sistema para detecção e localização de eventos de trânsito no Twitter.,Sílvio S Ribeiro Jr; Diogo Rennó; Tatiana S Gonçalves; Clodoveu A Davis Jr; Wagner Meira Jr; Gisele L Pappa,Resumo. O Twitter se consolidou como uma plataforma popular para fornecer conteúdogerado por usuários; que varia de simples conversação a informação em tempo real sobreeventos recentes. Muitas pesquisas demostraram que o conteúdo produzido no Twitterpossui alto grau de correlação com o que ocorre no mundo real; o que levou aodesenvolvimento de aplicações em diversas áreas; abrangendo desde epidemias atéeleições. Nosso trabalho é baseado no fato de que existe muita informação sobre trânsitodisponível no Twitter; principalmente de perfis especializados; criados para coletar edivulgar notícias sobre eventos de trânsito em algumas grandes cidades. Neste artigo;propomos um método para; dado um evento; geolocalizá-lo a partir do conteúdo dos tweetsassim que são coletados. Os resultados mostram que conseguimos localizar bairros e …,SBBD (Short Papers),2012,6
Detecç ao de Conte udo Relevante e Usuários Influentes no Twitter,Hérico Valiati; Arlei Silva; Sara Guimaraes; Wagner Meira Jr,Abstract. Social networks are an increasingly important media for information and memberinfluence. The main target of this paper is to determine which users are influential and toidentify relevant content-ie ranking user groups and the content spread by them. Wepropose a novel technique that is based on an intuitive and circular definition of relevanceand influence. We describe the proposed technique in detail; as well as its efficientimplementation. In order to validate it; we considered the task of recommending users andcontent to users. We used two real data sets extracted from Twitter and our results show thatour technique outperforms by 37% a collaborative filtering strategy; while both influentialusers and relevant content are qualitatively better. Resumo. Redes sociais têmdesempenhado um papel cada vez mais fundamental como um meio para a …,*,2012,6
Adaptive parallel approximate similarity search for responsive multimedia retrieval,George Teodoro; Eduardo Valle; Nathan Mariano; Ricardo Torres; Wagner Meira Jr,Abstract This paper introduces Hypercurves; a flexible framework for pro-viding similaritysearch indexing to high throughput multimedia services. Hypercurves efficiently andeffectively answers k-nearest neighbor searches on multigigabyte high-dimensionaldatabases. It supports massively parallel processing and adapts at runtime its parallelizationregimens to keep answer times optimal for either low and high demands. In order to achieveits goals; Hypercurves introduces new techniques for selecting parallelism configurationsand allocating threads to computation cores; including hyperthreaded cores. Its efficiencygains are throughly validated on a large database of multimedia descriptors; where itpresented near linear speedups and superlinear scaleups. The adaptation reduces queryresponse times in 43% and 74% for both platforms tested; when compared to the best …,Proceedings of the 20th ACM international conference on Information and knowledge management,2011,6
From total hits to unique visitors model for election’s forecasting,Diego Saez Trumper; Wagner Meira; Virgilio Almeida,Using Internet to predict elections has been a topic of interest for different fields.Researchers from Google have showed an approach employing user's queries on thatsearch engine [4]. Other site; The Daily Beast; has create an “Election Oracle”[1]; scanning40;000 blogs and social media sites and applying a sentiment analysis to made theirpredictions. In both these case; the predictions are expressed as a likelihood of winning andnot the total amount candidate votes or percent expected. This makes sense because theyhave applied their methodology to USA elections which are based in a two-party systemwhere one candidate won and the other lose. An multi-party approach was proposed byTumasjan et al [3]; they state that is possible to predict the result by counting the number ofTwitter mentions of Political Parties and Candidates. They have tested this idea in 2009 …,*,2011,6
Learning to rank using query-level rules,Adriano Veloso; Marcos A Gonçalves; Wagner Meira Jr; Humberto Mossri,*,Journal of Information and Data Management,2010,6
Multi-level parallelism for the cardiac bidomain equations,Carolina Ribeiro Xavier; Rafael Sachetto Oliveira; Vinicius da Fonseca Vieira; Rodrigo Weber Dos Santos; Wagner Meira,Abstract Cardiovascular diseases are associated with high mortality rates in the globe. Thedevelopment of new drugs; new medical equipment and non-invasive techniques for theheart demand multidisciplinary efforts towards the characterization of cardiac anatomy andfunction from the molecular to the organ level. Computational modeling has demonstrated tobe a useful tool for the investigation and comprehension of the complex biophysicalprocesses that underlie cardiac function. The set of Bidomain equations is currently one ofthe most complete mathematical models for simulating the electrical activity in cardiac tissue.Unfortunately; large scale simulations; such as those resulting from the discretization of anentire heart; remain a computational challenge. In order to reduce simulation executiontimes; parallel implementations have traditionally exploited data parallelism via numerical …,International journal of parallel programming,2009,6
Distributed perfect hashing for very large key sets,Fabiano C Botelho; Daniel Galinkin; Wagner Meira Jr; Nivio Ziviani,Abstract A perfect hash function (PHF) h: S→[0; m--1] for a key set S⊆ U of size n; wherem≥ n and U is a key universe; is an injective function that maps the keys of S to uniquevalues. A minimal perfect hash function (MPHF) is a PHF with m= n; the smallest possiblerange. Minimal perfect hash functions are widely used for memory efficient storage and fastretrieval of items from static sets. In this paper we present a distributed and parallel versionof a simple; highly scalable and near-space optimal perfect hashing algorithm for very largekey sets; recently presented in [4]. The sequential implementation of the algorithm constructsa MPHF for a set of 1.024 billion URLs of average length 64 bytes collected from the Web inapproximately 50 minutes using a commodity PC.,Proceedings of the 3rd international conference on Scalable information systems,2008,6
Pdbest: Pdb enhanced structures toolkit,DEV Pires; CH Da Silveira; MM Santoro; W Meira,Abstract The Protein Data Bank (PDB)[1] is a well known free repository for 3-D structuraldata of biomolecules that is growing exponentially in the last decades. An vast and complexcontent information is carried in his tag oriented textual data files. Besides this; there arefrequent errors or omissions in the annotated data; that makes its massive manipulation adifficult task; especially for the accuracy of comparative structure algorithms. In many ofthese cases; the PDB files need to be previously treated; cleaned; filtered; and normalizedbefore being submitted to the structure data mining and analysis routines. We are felling thatthere is a growing demand to computational tools that put more order and uniformity in,In Proceedings of the 3rd International Conference of Brazilian Association for Bioinformatics and Computational Biology,2007,6
On the characterization of energy networks of proteins,CJ Veloso; CH Silveira; RC Melo; C Ribeiro; JC Lopes; MM Santoro; W Meira Jr,ABSTRACT. The construction of a realistic theoretical model of proteins is determinant forimproving the computational simulations of their structural and functional aspects. Modelingproteins as a network of non-covalent connections between the atoms of amino acidresidues has shown valuable insights into these macromolecules. The energy-relatedproperties of protein structures are known to be very important in molecular dynamics.However; these same properties have been neglected when the protein structures aremodeled as networks of atoms and amino acid residues. A new approach for theconstruction of protein models based on a network of atoms is presented. This method;based on interatomic interaction; takes into account the energy and geometric aspects of theprotein structures that were not employed before; such as atomic occlusion inside the …,Genet Mol Res,2007,6
A Run-time System for Efficient Execution of Scientific Workflows on Distributed Environments,George Teodoro; Tulio Tavares; Renato Ferreira; Tahsin Kurc; Wagner Meira Jr; Dorgival Guedes; Tony Pan; Joel Saltz,Scientific workflow systems have been introduced in response to the demand of researchersfrom several domains of science who need to process and analyze increasingly largerdatasets. The design of these systems is largely based on the observation that data analysisapplications can be composed as pipelines or networks of computations on data. In thispaper we present a run-time support system that is designed to facilitate this type ofcomputation in distributed computing environments. Our system is optimized for data-intensive workflows; in which efficient management and retrieval of data; coordination ofdata processing and data movement; and check-pointing of intermediate results are criticaland challenging issues. Experimental evaluation of our system shows that linear speedupscan be achieved for sophisticated applications; which are implemented as a network of …,Computer Architecture and High Performance Computing; 2006. SBAC-PAD'06. 18TH International Symposium on,2006,6
Understanding the performance of DSM applications,Wagner Meira; Thomas J LeBlanc; Nikolaos Hardavellas; Cláudio Amorim,Abstract Carnival is a performance measurement and analysis tool that assists users inunderstanding the performance of DSM applications and protocols. Using traces of programexecutions; Carnival presents performance data as a hierarchy of execution profiles. Duringanalysis; Carnival automates the inference process that relates performance phenomena tospecific causes in the source code or DSM protocol using techniques that focus on the twomost important sources of overhead in DSM systems: waiting time analysis identifies thecauses of synchronization overhead; and produces an explanation for each source ofwaiting time in the program; communication analysis identifies the sequence of requests thatresult in invalidations; and produces an explanation for each source of communication. Wedescribe these techniques and their implementation in TreadMarks; and show how to use …,International Workshop on Communication; Architecture; and Applications for Network-Based Parallel Computing,1997,6
Dengue prediction by the web: tweets are a useful tool for estimating and forecasting dengue at country and city level,Cecilia de Almeida Marques-Toledo; Carolin Marlen Degener; Livia Vinhal; Giovanini Coelho; Wagner Meira; Claudia Torres Codeço; Mauro Martins Teixeira,Background Infectious diseases are a leading threat to public health. Accurate and timelymonitoring of disease risk and progress can reduce their impact. Mentioning a disease insocial networks is correlated with physician visits by patients; and can be used to estimatedisease activity. Dengue is the fastest growing mosquito-borne viral disease; with anestimated annual incidence of 390 million infections; of which 96 million manifest clinically.Dengue burden is likely to increase in the future owing to trends toward increasedurbanization; scarce water supplies and; possibly; environmental change. Theepidemiological dynamic of Dengue is complex and difficult to predict; partly due to costlyand slow surveillance systems. Methodology/Principal findings In this study; we aimed toquantitatively assess the usefulness of data acquired by Twitter for the early detection and …,PLoS neglected tropical diseases,2017,5
Designing mobile content delivery networks for the internet of vehicles,Cristiano M Silva; Fabricio A Silva; João FM Sarubbi; Thiago R Oliveira; Wagner Meira Jr; Jose Marcos S Nogueira,Abstract Content delivery is a key functionality for developing the Internet of Vehicles. Insuch networks; vehicles act as sensors of the urban mobility by constantly exchangingmessages with another vehicles; the cellular network; and also the infrastructure (roadsideunits). However; the task of delivering content in such dynamic network is far from trivial. Inthis work; we investigate the development of Content Delivery Networks (CDN) in the contextof vehicular networks. Roadside units support the communication by replicating anddelivering contents to vehicles within their range of coverage. Initially; we devise a strategyfor measuring the performance of the content delivery in vehicular networks. Then; we usethe proposed metric for designing a deployment strategy allowing us to identify the betterlocations for deploying the roadside units in order to properly support the dissemination of …,Vehicular Communications,2017,5
A quantitative analysis of the temporal effects on automatic text classification,Thiago Salles; Leonardo Rocha; Marcos André Gonçalves; Jussara M Almeida; Fernando Mourão; Wagner Meira; Felipe Viegas,Abstract Automatic text classification (TC) continues to be a relevant research topic andseveral TC algorithms have been proposed. However; the majority of TC algorithms assumethat the underlying data distribution does not change over time. In this work; we areconcerned with the challenges imposed by the temporal dynamics observed in textual datasets. We provide evidence of the existence of temporal effects in three textual data sets;reflected by variations observed over time in the class distribution; in the pairwise classsimilarities; and in the relationships between terms and classes. We then quantify; using aseries of full factorial design experiments; the impact of these effects on four well-known TCalgorithms. We show that these temporal effects affect each analyzed data set differently andthat they restrict the performance of each considered TC algorithm to different extents …,*,2016,5
Managing infrastructure-based vehicular networks,Cristiano M Silva; Wagner Meira,In this thesis work the authors exploit the management of infrastructure-based vehicularnetworks. The authors begin to work by investigating the most basic problem faced by thenetwork designers when planning an infrastructure-based vehicular network: given a roadnetwork; a flow; and α available RSUs; where the RSUs must be located in order tomaximize the network performance? The authors propose a novel approach for locating theRSUs: the authors develop a deployment algorithm based on partial mobility information. Bypartial mobility information; we mean: i) density of vehicles along the road network; and; ii)migration ratios from distinct locations of the road network.,Mobile Data Management (MDM); 2015 16th IEEE International Conference on,2015,5
A holistic hybrid algorithm for user recommendation on twitter,Sara Guimarães; Marco Túlio Ribeiro; Renato Assunção; Wagner Meira Jr,Abstract As Twitter grows larger and larger; finding interesting users to follow becomes anincreasingly difficult task; making it a great scenario for the application of recommendersystems. Previous research has shown that there is value in combining differentrecommendation algorithms; as each algorithm has strengths and weaknesses. However;previous works have focused on specific classes of recommendation algorithms; or onnaïvely combining different algorithms. In contrast; in this work we present a holistic hybridalgorithm that simultaneously takes into account content-based; collaborative-based anduser-based information. Our algorithm learns how to combine different sources of evidence(including the output from other algorithms) from the data itself; by using a LogisticRegression model. Therefore; instead of manually determining the importance of each …,Journal of Information and Data Management,2013,5
Towards a better quality metric for graph cluster evaluation,Hélio Almeida; Dorgival Guedes Neto; Wagner Meira Jr; Mohammed J Zaki,*,Journal of Information and Data Management,2012,5
A parallel accelerated adaptive mesh algorithm for the solution of electrical models of the heart,Rafael Sachetto Oliveira; Bernardo M Rocha; Denise Burgarelli; Wagner Meira Jr; Rodrigo Weber Dos Santos,Computer models have become valuable tools for the study and comprehension of thecomplex phenomena of cardiac electrophysiology. However; the high complexity of thebiophysical processes translates into complex mathematical and computational models. Inthis paper; we evaluate a parallel numerical algorithm based on mesh adaptivity and finitevolume method aiming to accelerate these simulations. This is a very attractive approachsince the spreading electrical wavefront corresponds only to a small fraction of the cardiactissue. Usually; the numerical solution of the partial differential equations that model thephenomenon requires very fine spatial discretisation to follow the wavefront; which isapproximately 0.2 mm. The use of uniform meshes leads to high computational cost as itrequires a large number of mesh points. In this sense; the tests reported in this work show …,International Journal of High Performance Systems Architecture 12,2012,5
Spam detection using web page content: a new battleground,Marco Túlio Ribeiro; Pedro H Calais Guerra; Leonardo Vilela; Adriano Veloso; Dorgival Guedes; Wagner Meira Jr; Marcelo HPC Chaves; Klaus Steding-Jessen; Cristine Hoepers,Abstract Traditional content-based e-mail spam filtering takes into account content of e-mailmessages and apply machine learning techniques to infer patterns that discriminate spamsfrom hams. In particular; the use of content-based spam filtering unleashed an unendingarms race between spammers and filter developers; given the spammers' ability tocontinuously change spam message content in ways that might circumvent the current filters.In this paper; we propose to expand the horizons of content-based filters by taking intoconsideration the content of the Web pages linked by e-mail messages. We describe amethodology for extracting pages linked by URLs in spam messages and we characterizethe relationship between those pages and the messages. We then use a machine learningtechnique (a lazy associative classifier) to extract classification rules from the web pages …,Proceedings of the 8th Annual Collaboration; Electronic messaging; Anti-Abuse and Spam Conference,2011,5
Estimating the credibility of examples in automatic document classification,João Palotti; Thiago Salles; Gisele L Pappa; Filipe Arcanjo; Marcos A Gonçalves; Wagner Meira Jr,Abstract. Classification algorithms usually assume that any example in the raining set shouldcontribute equally to the classification model being generated. However; this is not alwaysthe case. This paper shows that the contribution of an example to the classification modelvaries according to many factors; which are application dependent; and can be estimatedusing what we call a credibility function. The credibility of an entity reflects how much value itaggregates to a task being performed; and here we investigate it in Automatic DocumentClassification; where the credibility of a document relates to its terms; authors; citations;venues; time of publication; among others. After introducing the concept of credibility inclassification; we investigate how to estimate a credibility function using informationregarding documents content; citations and authorship using mainly metrics previously …,Journal of Information and Data Management,2010,5
Efficient on-demand Opinion Mining.,Adriano Veloso; Wagner Meira Jr,Abstract. Every day; a multitude of people express their opinions regarding diverse entities;such as services; places and products; in blogs (eg; The BBC “Have Your Say” Blog); onlineforums (eg; slashdot. org) and review sites (eg; www. amazon. com). This constantly growingavailability of opinionated content has created massive amounts of extremely valuableinformation. Currently; search engines are unable to explore such information; because (1) itis difficult to distinguish opinionated content from factual content; and (2) opinionatedcontent may present different connotations or polarities (ie; positive or negative; interestingor boring etc.). Recently; some attention has been devoted to the first problem− opinionretrieval; which consists of distinguishing opinionated content from factual content. However;research on opinion mining; which consists in classifying opinionated content with …,SBBD,2007,5
Eager; lazy and hybrid algorithms for multi-criteria associative classification,Adriano Veloso; Wagner Meira Jr,Abstract. Classification aims to map a data instance to its appropriate class (or label). Inassociative classification the mapping is done through an association rule with theconsequent restricted to the class attribute. Eager associative classification algorithms builda single rule set during the training phase; and this rule set is used to classify all testinstances. Lazy algorithms; however; do not build a rule set during the training phase; therule set generation is delayed until a test instance is given. The choice between eager andlazy algorithms is not simple. Using a single rule set to perform all the predictions may nottake advantage of specific characteristics of a test instance. On the other hand; building aspecific rule set for each test instance may incur in excessive computational efforts. In thispaper we propose new eager and lazy algorithms for associative classification. Also; we …,Proceedings of the Data Mining Algorithms Workshop; Uberlandia; MG,2005,5
Modeling web site personalization strategies,Fabiana Ruas; Wagner Meira Jr; Paulo Araújo; Flávia Ribeiro,ABSTRACT Personalization is a key factor for differentiating services and retainingcustomers in World Wide Web sites. On the other hand; designing and implementing anefficient personalization strategy is still a challenge; because of the complexity of thetechniques used and the variety of sites and customers; which are always evolving. Thispaper presents a functional model of personalization strategies that allows not only a simpleand concise specification of those strategies; but also their simulation and validation. Wedemonstrate our model through e-Personal; a framework for estimating the effectiveness ofpersonalization strategies. The framework guides the user through the process of specifyinga strategy and estimates its impact based on previous interactions of customers with the site.It is based on our functional model and we illustrate its utilization for designing …,Journal of the Brazilian Computer Society,2002,5
Mining reliable models of associations in dynamic databases,Adriano A Veloso; Wagner Meira Jr; Marcio LB de Carvalho,Abstract Most current work on data mining has been focused on devising efficienttechniques to build accurate models from databases. Research on how the accuracy of amodel changes as a function of dynamic updates when the databases are collected overtime is lacking. In this work we show that extracting this information: knowing which aspectsof the model are changing and how they are changing as a function of data updates; can bevery effective for accuracy purposes.,*,2002,5
Assessing the impact of distribution on e-business services,Bruno Coutinho; George Teodoro; Túlio Tavares; Robert Pinto; Diego Nogueira; Wagner Meira Jr; Dorgival Guedes,*,*,2002,5
Resource placement in distributed e-commerce servers,Gustavo Machado Campagnani Gama; W Meira; Márcio LB Carvalho; Dorgival O Guedes; Virgílio AF Almeida,E-commerce services have become a promising and profitable application of the Internet. Inorder to keep them growing; solutions must be found to deal with unreliable connections andhigh latencies; among other problems. The best solutions to such problems tend to dependon the distribution of the service over the network; placing servers in multiple locations;closer to customers. If placement of servers is effective it tends to reduce delays and traffic-related costs. In this paper we discuss the distribution of e-commerce services by introducinga traffic-aware cost model and evaluating it using an actual log from an e-tailer. The resultsshow that the model yields good placement solutions; which perform better than simpler ad-hoc solutions.,Global Telecommunications Conference; 2001. GLOBECOM'01. IEEE,2001,5
Understanding Parallel Program Performance Using Cause-E ect Analysis,Wagner Meira Jr,The main motivation for parallel computing is to solve problems faster by using multipleprocessing units that cooperate and communicate. The development of e cient parallelprograms; however; is usually a di cult task; mainly due to the complexity of programs;parallel architectures; and their interactions. The life cycle of a parallel program starts withan initial parallelization; usually derived from a sequential version of the program. Theprogrammer then examines the performance of this initial parallelization in order todetermine whether improvements are necessary. If necessary; the program is tuned by theprogrammer through a series of\measure-modify" tuning sessions. Each tuning session isdivided into four steps:(1) the program is executed and performance measurements aregathered;(2) the programmer evaluates the measurements and decides whether the …,*,1997,5
Mobile robotics 1994,O Fuentes; J Karlsson; W MEira; R Rao; T Riopk; J Rosca; R Surukkai; M Van Wie; M Zaki; T Becker; R Frank; B Miller; CM Brown,*,*,1995,5
Antagonism also Flows through Retweets: The Impact of Out-of-Context Quotes in Opinion Polarization Analysis,Pedro Calais Guerra; Roberto CSNP Souza; Renato M Assunçao; Wagner Meira Jr,Abstract: In this paper; we study the implications of the commonplace assumption that mostsocial media studies make with respect to the nature of message shares (such as retweets)as a predominantly positive interaction. By analyzing two large longitudinal Brazilian Twitterdatasets containing 5 years of conversations on two polarizing topics-Politics and Sports-weempirically demonstrate that groups holding antagonistic views can actually retweet eachother more often than they retweet other groups. We show that assuming retweets asendorsement interactions can lead to misleading conclusions with respect to the level ofantagonism among social communities; and that this apparent paradox is explained in partby the use of retweets to quote the original content creator out of the message's originaltemporal context; for humor and criticism purposes. As a consequence; messages …,arXiv preprint arXiv:1703.03895,2017,4
Factors associated with weight change in online weight management communities: a case study in the LoseIt Reddit community,Gisele Lobo Pappa; Tiago Oliveira Cunha; Paulo Viana Bicalho; Antonio Ribeiro; Ana Paula Couto Silva; Wagner Meira Jr; Alline Maria Rezende Beleigoli,Background Recent research has shown that of the 72% of American Internet users whohave looked for health information online; 22% have searched for help to lose or controlweight. This demand for information has given rise to many online weight managementcommunities; where users support one another throughout their weight loss process.Whether and how user engagement in online communities relates to weight change is nottotally understood. Objective We investigated the activity behavior and analyze the semanticcontent of the messages of active users in LoseIt (r/loseit); a weight management communityof the online social network Reddit. We then explored whether these features are associatedwith weight loss in this online social network. Methods A data collection tool was used tocollect English posts; comments; and other public metadata of active users (ie; users with …,Journal of medical Internet research,2017,4
An architecture integrating stationary and mobile roadside units for providing communication on intelligent transportation systems,Cristiano M Silva; Wagner Meira,In this work we investigate the benefits of an hybrid architecture integrating both mobileroadside units; and stationary roadside units supporting the operation of vehicular networks.Since traffic fluctuates; an architecture employing just stationary roadside units might not beable to properly support the network operation all the time. Similarly; an architecturecomposed just of mobile roadside units may lack part of the robustness provided bystationary roadside units. Furthermore; the traffic fluctuations are limited by the underlyingroad network; and the road networks do not change so often as traffic does. Thus; it seemsstraight full to assume that a set of roadside units will always be left stationary; while otherroadside units will need to roam along the road network. As major roads counts on a highertransportation capacity; they tend to be very popular routes; and they are natural …,Network Operations and Management Symposium (NOMS); 2016 IEEE/IFIP,2016,4
An evolutionary methodology for handling data scarcity and noise in monitoring real events from social media data,Roberto CSNP Souza; Denise EF de Brito; Rodrigo L Cardoso; Derick M de Oliveira; Wagner Meira; Gisele L Pappa,Abstract Every day text-based social media channels are flooded with millions of messagesthat comprise the most diverse topics. These channels are being used as a rich data sourcefor monitoring different real world events such as natural disasters and disease outbreaks; toname a few. However; depending on the event being investigated; this monitoring may beseverely affected by data scarcity and noise; allowing just coarse grain analysis in terms oftime and space; which lack the specificity necessary for supporting actions at the local level.In this context; we present a methodology to handle data scarcity and noise while monitoringreal world events using social media data in a fine grain. We apply our methodology todengue-related data from Brazil; and show how it could improve significantly theperformance of event monitoring at a local scale almost doubling the correlation observed …,Ibero-American Conference on Artificial Intelligence,2014,4
Enzymap: Exploiting protein annotation for modeling and predicting ec number changes in uniprot/swiss-prot,Sabrina de Azevedo Silveira; Raquel Cardoso de Melo-Minardi; Carlos Henrique da Silveira; Marcelo Matos Santoro; Wagner Meira Jr,The volume and diversity of biological data are increasing at very high rates. Vast amountsof protein sequences and structures; protein and genetic interactions and phenotype studieshave been produced. The majority of data generated by high-throughput devices isautomatically annotated because manually annotating them is not possible. Thus; efficientand precise automatic annotation methods are required to ensure the quality and reliabilityof both the biological data and associated annotations. We proposed ENZYM atic Annotation P redictor (ENZYMAP); a technique to characterize and predict EC numberchanges based on annotations from UniProt/Swiss-Prot using a supervised learningapproach. We evaluated ENZYMAP experimentally; using test data sets from bothUniProt/Swiss-Prot and UniProt/TrEMBL; and showed that predicting EC changes using …,PloS one,2014,4
Cidade digital estratégica: modelo e aplicação em um município paulista,Denis Alcides Rezende,Abstract. Smarts cities projects are planning and making information; systems and servicesavailable for their own managers and citizens. The aim of this paper is to describe the modelfor and the project called Strategic Digital City; implemented in the municipality of Vinhedo-SP. The research methodology was based on a case study formed by an action-research;considering the City Hall and local units. The results describe; through a specificmethodology; the practical feasibility of the project and of the applied model. The conclusionreiterates the importance of a collective implementation of the model; and its acceptance asa tool to contribute to city management; to the fulfillment of the smart cities; to decision-making and to the citizens' quality of life. Resumo. Projetos de Cidades Inteligentesplanejam e disponibilizam informações; sistemas e serviços para seus gestores e …,Anais do VIII Simpósio Brasileiro de Sistemas de Informação; São Paulo: Universidade de São Paulo Campus Leste–USP Leste,2012,4
Extracting decision trees from interval pattern concept lattices,Zainab Assaghir; Mehdi Kaytoue; Wagner Meira; Jean Villerd,Formal Concept Analysis (FCA) and concept lattices have shown their e ffectiveness forbinary clustering and concept learning. Moreover; several links between FCA andunsupervised data mining tasks such as itemset mining and association rules extractionhave been emphasized. Several works also studied FCA in a supervised framework;showing that popular machine learning tools such as decision trees can be extracted fromconcept lattices. In this paper; we investigate the links between FCA and decision trees withnumerical data. Recent works showed the effciency of" pattern structures" to handlenumerical data in FCA; compared to traditional discretization methods such as conceptualscaling.,The Eighth International Conference on Concept Lattices and their Applications-CLA 2011,2011,4
Competence-conscious associative rank aggregation,Adriano Veloso; Marcos Gonçalves; Wagner Meira Jr,Abstract. The ultimate goal of ranking methods is to achieve the best possible ranking performancefor the problem at hand. Recently; a body of empirical evidence has emerged suggesting thatmethods that learn to rank offer substantial improvements in enough situations to be regardedas a relevant advance for applications that depend on ranking. Previous studies have shownthat different (learning to rank) methods may produce conflicting ranked lists. Rank aggregationis based on the idea that combining such lists may provide complementary information that canbe used to improve ranking performance. In this article we investigate learning to rank methodsthat uncover; from the training data; associations between document features and relevancelevels in order to estimate the relevance of documents with regard to a given query. There isa variety of statistic measures or metrics that provide a different interpretation for an …,Journal of Information and Data Management,2011,4
Self-training associative classification,Adriano Veloso; Wagner Meira,Abstract The acquisition of training examples usually requires skilled human annotators tomanually label the relationship between inputs and outputs. Due to various reasons;annotators may face inputs that are hard to label (Chapelle et al. Semi-supervised learning.MIT Press; Cambridge; 2006). The cost associated with this labeling process thus mayrender vast amounts of training examples unfeasible. The acquisition of unlabeled inputs (ie;inputs for which the corresponding output is unknown); on the other hand; is relativelyinexpensive. However; it is worthwhile to label at least some inputs; provided that this effortwill be then rewarded with an improvement in classification performance. In this chapterdemand-driven associative classification will be extended; so that the correspondingalgorithm achieves high classification performance even in the case of limited labeling …,*,2011,4
A run-time system for efficient execution of scientific workflows on distributed environments,George Teodoro; Tulio Tavares; Renato Ferreira; Tahsin Kurc; Wagner Meira; Dorgival Guedes; Tony Pan; Joel Saltz,Abstract Scientific workflow systems have been introduced in response to the demand ofresearchers from several domains of science who need to process and analyze increasinglylarger datasets. The design of these systems is largely based on the observation that dataanalysis applications can be composed as pipelines or networks of computations on data. Inthis work; we present a run-time support system that is designed to facilitate this type ofcomputation in distributed computing environments. Our system is optimized for data-intensive workflows; in which efficient management and retrieval of data; coordination ofdata processing and data movement; and check-pointing of intermediate results are criticaland challenging issues. Experimental evaluation of our system shows that linear speedupscan be achieved for sophisticated applications; which are implemented as a network of …,International journal of parallel programming,2008,4
An efficient algorithm for outlier detection in high dimensional real databases,Carlos HC Teixeira; Gustavo H Orair; Wagner Meira Jr; Srinivasan Parthasarathy,Abstract Detecting outlier patterns in data has been an important research topic in statistics;data mining and machine learning communities for many years. Research in identifyingeffective solutions to this problem have several interesting applications in a myriad ofdomains ranging from data cleaning to financial fraud detection and from network intrusiondetection to clinical diagnosis of diseases. Among the different algorithms; statistical(parametric) approaches and distance-based outlier detection are the most popular in use.The former is well grounded but often has difficulty scaling to large and high dimensionaldata. The latter is relatively efficient and empirically found to be effective on a number ofdomains but scalability is still an issue in spite of a fair bit of research on the topic. Toaddress this limitation; in this work; we propose Atalaia; an efficient and scalable distance …,Tech. Rep.,2008,4
Analyzing ebay negotiation patterns,A Pereira; L Rocha; Fernando Mourão; T Torres; Wagner Meira Jr; P Góes,Abstract: Online auctions have several aspects that violate the common assumptions madeby the traditional economic auction theory. An online auction can be seen as an interactiveeconomic information system; where usersystem interactions are usually very complex. It isimportant to note that the interactions are not isolated; but successive interactions become aloop-feedback mechanism; that we call reactivity; where the user behavior affects theauction negotiation and vice-versa. In this paper we describe a new hierarchicalcharacterization model for online auctions and apply this model to a real case study;showing its advantages in discovering some online auction negotiation patterns. The resultsdemonstrate that our characterization model provides an efficient way to open the auctiondynamics's “black box”. We also propose an abstraction named Auction Model Graph …,*,2007,4
An image-matching approach to protein similarity analysis,Fernando Fernandes; Carlos ER Lopes; Raquel C de Melo; Marcelo M Santoro; Rodrigo L Carceroni; Wagner Meira; Arnaldo de A Araújo; Carlos H Silveira,In this work we model the problem of identifying how close structurally two proteins are as aproblem of measuring the similarity between color images that represent their contact maps;where the chromatic information encodes the chemical nature of the contacts. We study twoconceptually distinct methods to measure the similarity between such contact maps: acontent-based image retrieval one and another based on image registration. In experimentswith contact maps constructed from the Protein Data Bank (PDB); the image registrationapproach was able to identify with 100% precision 8 instances of a protein class mixed with28 proteins of other classes. The content-based image retrieval approach had an accuracyonly a little worse than that.,Computer Graphics and Image Processing; 2004. Proceedings. 17th Brazilian Symposium on,2004,4
Modelagem Vetorial Estendida por Regras de Associação.,Bruno Possas; Nivio Ziviani; Wagner Meira Jr; Berthier A Ribeiro-Neto,*,SBBD,2001,4
SHMSquid: a scalable WWW cache server,Goedson T Paixao; W Meira; Fernado Caixeta Sanches,The increasing popularity of the World Wide Web has led to significant research targetingthe reduction of the latency perceived by users. Cache servers proved to be an importantresource in accomplishing this goal. Although the use of cache servers have reduced thedata traffic in the Internet; the cooperation strategies employed while building clusters ofthose servers scale poorly and are not able to sustain their throughput under increasingdemands. We present a novel cooperation strategy that does not significantly affect theserver performance. The use of this strategy allows clusters of cache servers to scale wellwith their usage growth.,Computer Science Society; 1999. Proceedings. SCCC'99. XIX International Conference of the Chilean,1999,4
Identifying stereotypes in the online perception of physical attractiveness,Camila Souza Araújo; Wagner Meira; Virgilio Almeida,Abstract Stereotyping can be viewed as oversimplified ideas about social groups. They canbe positive; neutral or negative. The main goal of this paper is to identify stereotypes forfemale physical attractiveness in images available in the Web. We look at the searchengines as possible sources of stereotypes. We conducted experiments on Google and Bingby querying the search engines for beautiful and ugly women. We then collect images andextract information of faces. We propose a methodology and apply it to analyze photosgathered from search engines to understand how race and age manifest in the observedstereotypes and how they vary according to countries and regions. Our findings demonstratethe existence of stereotypes for female physical attractiveness; in particular negativestereotypes about black women and positive stereotypes about white women in terms of …,International Conference on Social Informatics,2016,3
Using the inter-contact time for planning the communication infrastructure in vehicular networks,Cristiano M Silva; Daniel L Guidoni; Fernanda S Souza; Cristiano G Pitangui; João FM Sarubbi; Andre LL Aquino; Wagner Meira; Jose Marcos S Nogueira; Andreas Pitsillides,Intelligent Transportation Systems (ITS) demand sophisticated vehicular networksintegrating entities from the transportation sector. The ability to plan and manage suchnetworks represents a key challenge for moving ITS solutions from laboratories into thestreets. In this work; we propose Gamma Deployment as a metric for evaluating thedistribution of roadside units in vehicular networks by considering the inter-contact timebetween vehicles and infrastructure. By solving the location of roadside units in order tomeet the Gamma Deployment; the network designer assures a given share of vehicles tokeep frequent contacts with roadside units. Since Gamma Deployment reflects theconnectivity experienced by drivers; it can be used for comparing vehicular networksdeployed over distinct conditions.,Intelligent Transportation Systems (ITSC); 2016 IEEE 19th International Conference on,2016,3
An accurate gaussian process-based early warning system for dengue fever,Julio Albinati; Wagner Meira; Gisele L Pappa,Dengue fever is a mosquito-borne disease present in all Brazilian territory. Braziliangovernment; however; lacks an accurate early warning system to quickly predict futuredengue outbreaks. Such system would help health authorities to plan their actions and toreduce the impact of the disease in the country. However; most attempts to model denguefever use parametric models which enforce a specific expected behaviour and fail to capturethe inherent complexity of dengue dynamics. Therefore; we propose a new Bayesian non-parametric model based on Gaussian processes to design an accurate and flexible modelthat outperforms previous/standard techniques and can be incorporated into an earlywarning system; specially at cities from Southeast and Center-West regions. The model alsohelps understanding dengue dynamics in Brazil through the analysis of the covariance …,Intelligent Systems (BRACIS); 2016 5th Brazilian Conference on,2016,3
Pattern aided classification,Guozhu Dong; Vahid Taslimitehrani,Abstract This paper makes several contributions to research on classification. First; itintroduces a new style of classifiers; namely pattern aided classifiers (PXC); each defined byseveral pattern and group-specific-classifier pairs. A PXC uses patterns as conditions and itapplies a group-specific classifier only to data instances satisfying its associated pattern.Second; it introduces a new classification algorithm; called Contrast Pattern AidedClassification (CPXC); for learning accurate PXCs. Experiments over multiple benchmarkdatasets confirm that CPXC often builds significantly more accurate classifiers thantraditional classification algorithms. Third; it introduces the technique of opportunity-guidedboosting and the concept of conditional classifier ensembles; and it provides insight on whycertain datasets are very challenging to traditional classification algorithms.,*,2016,3
Rank Selection for Non-negative Matrix Factorization with Normalized Maximum Likelihood Coding,Yu Ito; Shin-ichi Oeda; Kenji Yamanishi,Abstract Non-negative matrix factorization (NMF) is one of the most important technologiesin data mining. This is the task of factorizing a matrix into the product of two non-negative lowrank matrices. In most of works on NMF; the rank is predetermined in ad hoc. This paperaddresses the issue of how we can select the best rank from given data. The problem is thatthe conventional statistical model selection criteria such as AIC; MDL etc. cannotstraightforwardly be applied to this issue because the regularity conditions for the criteria arenot fulfilled. We overcome this problem to propose a novel methodology for rank selection.The key ideas are to 1) use the technique of latent variable completion to make the modelregular and 2) then to apply the normalized maximum likelihood coding to rank selection forthe regular model. We further propose a novel method for rank change detection when …,*,2016,3
Entity matching: A case study in the medical domain,Luiz FM Carvalho; Alberto HF Laender; Wagner Meira Jr,Abstract. In this paper; we propose a simple and effective solution for the entity matchingproblem involving data records of healthcare professionals. Our method depends on threeattributes that are available in most data sources in the medical domain: name; specialty andaddress. We apply a blocking technique to avoid comparisons; three matchers forconciliating the data records and a rule-based heuristic to combine the matchers. Weperformed experiments involving data from three Brazilian Web sources of healthcareprofessionals. Our results show that our solution is able to avoid unnecessary comparisonsand provides good results.,Alberto Mendelzon International Workshop on Foundations of Data Management,2015,3
Analyzing the Coauthorship Networks of Latin American Computer Science Research Groups,Juan F Delgado-Garcia; Alberto HF Laender; Wagner Meira,In this paper; we analyze the co authorship networks of Latin American Computer Scienceresearch groups from 35 academic institutions in Argentina; Brazil; Chile; Colombia; Cuba;Mexico; Peru; Uruguay and Venezuela. Our analysis is based on data over a period of 20years collected from DBLP; and aims to know the topological structure of each of thesenetworks and provide a view of how they have evolved over time. Our results show that overthe 2004-2013 decade there has been a relevant increase in terms of publications andcollaborations in Latin America. We also identify the influential authors in the area accordingto complex network metrics and analyze the research networks originated from the coauthorships. Despite the increase in all per-country metrics; we observed that there is still alot to improve; since most of the collaborations happen between just Brazil-Chile and …,Web Congress (LA-WEB); 2014 9th Latin American,2014,3
Vermont: Visualizing mutations and their effects on protein physicochemical and topological property conservation,Sabrina A Silveira; Alexandre V Fassio; Valdete M Gonçalves-Almeida; Elisa B de Lima; Yussif T Barcelos; Flávia F Aburjaile; Laerte M Rodrigues; Wagner Meira Jr; Raquel C de Melo-Minardi,In this paper; we propose an interactive visualization called VERMONT which tackles theproblem of visualizing mutations and infers their possible effects on the conservation ofphysicochemical and topological properties in protein families. More specifically; wevisualize a set of structure-based sequence alignments and integrate several structuralparameters that should aid biologists in gaining insight into possible consequences ofmutations. VERMONT allowed us to identify patterns of position-specific properties as wellas exceptions that may help predict whether specific mutations could damage proteinfunction.,BMC proceedings,2014,3
SpamBands: uma metodologia para identificaç ao de fontes de spam agindo de forma orquestrada,Elverton Fazzion; Pedro Henrique B Las-Casas; Osvaldo Fonseca; Dorgival Guedes; Wagner Meira Jr; Cristine Hoepers; Klaus Steding-Jessen; Marcelo HP Chaves,Abstract. In 2012; estimates indicated that 68.8% of all e-mail traffic was spam; whatsuggests this is still a relevant problem. Recently; some works have focused on the analysisof spam's traffic inside the network; analyzing the protocols used and the AS which originatethe traffic. However; those works usually do not consider the relationships between themachines used to send spam. Such an analysis could reveal how different machines may beused by a single spammer to spread his messages; helping us to understand their behavior.To that end; this work proposes a methodology to cluster the machines used by spammersbased on the concept of spam campaigns. The groups identified were characterized toidentify different aspects of the spam dissemination process; which suggest differentorchestration strategies being used. Resumo. Em 2012; estimava-se que cerca de 68; 8 …,Proc. of Brazilian Symposium on Information and Computational Systems Security (SBSeg),2014,3
An adaptive mesh algorithm for the numerical solution of electrical models of the heart,Rafael S Oliveira; Bernardo M Rocha; Denise Burgarelli; Wagner Meira; Rodrigo W dos Santos,Abstract Computer models have become valuable tools for the study and comprehension ofthe complex phenomena of cardiac electrophysiology. However; the high complexity of thebiophysical processes translates into complex mathematical and computational models. Inthis paper we evaluate a numerical algorithm based on mesh adaptivity and finite volumemethod aiming to accelerate these simulations. This is a very attractive approach since thespreading electrical wavefront corresponds only to a small fraction of the cardiac tissue.Usually; the numerical solution of the partial differential equations that model thephenomenon requires very fine spatial discretization to follow the wavefront; which isapproximately 0.2 mm. The use of uniform meshes leads to high computational cost as itrequires a large number of mesh points. In this sense; the tests reported in this work show …,International Conference on Computational Science and Its Applications,2012,3
Distributed skycube computation with anthill,Renê R Veloso; Loïc Cerf; Chedy Raïssi; Wagner Meira Jr,Recently skyline queries have gained considerable attention and are among the mostimportant tools for multi-criteria analysis. In order to process all possible combinations ofcriteria along with their inherent analysis; researchers introduced and studied the notion ofskycube. Simply put; a skycube is a pre-materialization of all possible subspaces with theirassociated skylines. An efficient skycube computation relies on the detection ofredundancies in the different processing steps and enhanced result sharing betweensubspaces. Lately; the Orion algorithm was proposed to compute the skycube in a veryefficient way. The approach relies on the derivation of skyline points over differentsubspaces. Nevertheless; because there are 2| D|-1 subspaces (where D is the set ofdimensions) in a skycube; the running time still grows exponentially with the number of …,Computer Architecture and High Performance Computing (SBAC-PAD); 2011 23rd International Symposium on,2011,3
Observatório da Dengue: surveillance based on twitter sentiment stream analysis,Ismael S Silva; Janaína Gomide; Glívia AR Barbosa; Walter Santos; Adriano Veloso; Wagner Meira Jr; Renato Ferreira,*,Proceedings of the Brazilian Symposium on Databases; Demos Track. Florianópolis; Brazil,2011,3
Competence‐conscious associative classification,Adriano Veloso; Mohammed Zaki; Wagner Meira; Marcos Gonçalves,Abstract The classification performance of an associative classifier is strongly dependent onthe statistic measure or metric that is used to quantify the strength of the association betweenfeatures and classes (ie confidence; correlation; etc.). Previous studies have shown thatclassifiers produced by different metrics may provide conflicting predictions; and that thebest metric to use is data-dependent and rarely known while designing the classifier. Thisuncertainty concerning the optimal match between metrics and problems is a dilemma; andprevents associative classifiers to achieve their maximal performance. This dilemma is thefocus of this paper. A possible solution to this dilemma is to learn the competence; expertise;or assertiveness of metrics. The basic idea is that each metric has a specific sub-domain forwhich it is most competent (ie it consistently produces more accurate classifiers than the …,Statistical Analysis and Data Mining: The ASA Data Science Journal,2009,3
Using linear algebra for protein structural comparison and classification,Janaína Gomide; Raquel Melo-Minardi; Marcos Augusto dos Santos; Goran Neshich; Wagner Meira Jr; Júlio César Lopes; Marcelo Santoro,ABSTRACT In this article; we describe a novel methodology to extract semanticcharacteristics from protein structures using linear algebra in order to compose structuralsignature vectors which may be used efficiently to compare and classify protein structuresinto fold families. These signatures are built from the pattern of hydrophobic intrachaininteractions using Singular Value Decomposition (SVD) and Latent Semantic Indexing (LSI)techniques. Considering proteins as documents and contacts as terms; we have built aretrieval system which is able to find conserved contacts in samples of myoglobin fold familyand to retrieve these proteins among proteins of varied folds with precision of up to 80%.The classifier is a web tool available at our laboratory website. Users can search for similarchains from a specific PDB; view and compare their contact maps and browse their …,Genetics and molecular biology,2009,3
BUBA: Uma Ferramenta para Análise do Comportamento de Usuários de Internet Banda Larga,Pedro Henrique Calais; Elisa Tuler de Albergaria; Leonardo C Dutra Rocha; Humberto Marques Neto; Jussara M Almeida; Wagner Meira Jr; Virgílio Almeida,*,*,2005,3
Masks: Managing Anonymity while Sharing knowledge to Servers,Robert Pinto; Lucila Ishitani; Virgílio Almeida; Wagner Meira Júnior; Fabiano A Fonseca; Fernando D Castro,Abstract This work presents an architecture that allows users to enhance their privacy controlover the computational environment. Web privacy is a topic that is raising; nowadays; manydiscussions. Usually; people do not know how their privacy can be violated or what can bedone to protect it. Among the generated conflicts; we would like to show up the one thathappens between privacy and personalization: by one side; users appreciate the idea ofreceiving personalized services and do not approve the collection; tracing and analysis oftheir actions; by the other side; personalization services need this type of information inorder to profile their users. The architecture presented in this article helps users tounderstand better how their privacy can be invaded and; at the same time; gives them abetter control of their privacy; through anonymity; without preventing them from receiving …,*,2004,3
Quantitative analysis of strategies for streaming media distribution,Marisa A Vasconcelos; Leonardo C da Rocha; Jde C Santos; JP Ismael; Leonardo LP da Mata; Jussara M Almeida; Wagner Meira; Virgílio AF Almeida,Distribution of streaming media content; including live news; music and videos; is becomingincreasingly popular in today's Internet. Traditional client/server architectures are inefficientfor distributing streaming media objects because of the high demands for system resources;especially server and network bandwidth; which severely limit the total number ofsimultaneous users the system can support. One proposal for improving the scalability ofmedia distribution systems is the use of P2P overlay networks. Although a number ofprevious works has evaluated different aspects of P2P systems; mainly through simulation;there is a lack of a thorough quantitative analysis of the requirements for server and networkresources (ie; CPU; server and network bandwidth) in actual P2P systems; compared totraditional client/server systems. We aim at filling this gap by providing experimental …,Web Congress; 2003. Proceedings. First Latin American,2003,3
Traffic-aware distribution of e-commerce services,Gustavo Gama; Wagner Meira Jr; Márcio Bunte Carvalho; Dorgival Guedes,e-Commerce services have become a promising and profitable application of the Internet.Nevertheless; the use of the Internet as the communication environment in this case is notwithout its problems. For an e-commerce site to be successful it has to reduce the negativeeffects of unreliable connections and high network latencies; among others. Such problemsmay compromise customer satisfaction and therefore the success of the virtual business.Techniques based on improving the quality of a centralized server do not provide a reliablesolution; since the difficulties faced are inherent to the network infrastructure itself; not justthe server. A better solution tends to be the distribution of the service over the network;placing servers in multiple locations closer to the final users. The existence of multipleservers tends to increase availability; and assuming the placement is well planned; it …,*,2001,3
Análise de Desempenho da Terceirização de Serviços de Comércio Eletrônico,Bruno Diniz; Wagner Meira Jr; Virgílio Almeida,Resumo A escalabilidade de serviços de comércio eletrônico é fundamental para o mento epopularização dessa promissora aplicação tanto do ponto de vista de impacto social quantodo ponto de vista econômico. Este artigo discute as vantagens e desvantagens de umaestratégia comum para aumentar a escalabilidade de servidores de comércio eletrônico; aterceirização de serviços. Discutimos requisitos fundamentais para essa terceirização eanalisamos o impacto da terceirização no desempenho de sítios de comércio eletrônico; emparticular a terceirização de anúncios eletrônicos (banners).,Anais do XVIII Simposio Brasileiro de Redes de Computadores; Belo Horizonte; MG,2000,3
Geração de Regras de Associação Quantitativas.,Bruno Pôssas; Fabiana Ruas; Wagner Meira Jr; Rodolfo F Resende,*,SBBD,1999,3
A quantitative analysis of the user behavior of a large e-broker,Virgilio Almeida; Wagner Meira; Victor Ribeiro; Nivio Ziviani,The Internet and the World Wide Web provide a global virtual marketplace. However; thereis little information about the behavior of e-commerce users worldwide. The goal of thepaper is twofold. First; we give an overview of the architecture and implementation of theMiner family of Web agents for e-commerce. Then; we present a quantitative study of theuser behavior of a large e-broker (ie; the BookMiner). Considering that the e-broker is usedby a large number of users that only speak Portuguese and live in Brazil; we discuss theinfluence of regional and cultural issues on the e-commerce activities. Although the Webopens a company to a global market; our findings clearly indicate that e-commerce isstrongly tied to regional issues; such as language; national customs and regulations;currency conversion and logistics. Also; the Internet infrastructure; mainly the …,Advance Issues of E-Commerce and Web-Based Information Systems; WECWIS; 1999. International Conference on,1999,3
Evaluating the trade-offs in the parallelization of probabilistic search algorithms,RL Carceroni; Wagner Meira Jr; R Stets; S Dwarkadas,Abstract In this work; we propose a speculative parallelization strategy for ProbabilisticSearch algorithms. We design a parallel version of one such algorithm for a real--timecomputer vision problem with many practical applications. The implementation is performedon a cluster of eight DEC AlphaServer 2100 4/233 machines connected via a DEC MemoryChannel network. Four types of run--time systems are tested: Hardware--coherent SharedMemory (HSM); Distributed Shared Memory (DSM) with software coherence (Cashmere-2L);Reflective Shared Memory (RSM); and message passing (Digital PVM). A run--time systemthat is normally not the most efficient among these four (RSM) is found to be the best choicefor our combination of algorithm and architecture. This shows that algorithmic parallelizationand the selection of an implementation environment mutually interfere with each other …,*,1997,3
Implementation of cashmere,Michael L Scott; Wei Li; Leonidas Kontothanassis; Galen Hunt; Maged Michael; Robert Stets; Nikolaos Hardavellas; Wagner Meira; Alexandros Poulos; Michal Cierniak; Srinivasan Parthasarathy; Mohammed Zaki,The Cashmere project attempts to capture the" knee of the curve" in price-performance forshared-memory parallel computing: it exploits recent advances in local-area networks thatprovide low-latency; user-level access to remote locations in hardware; but implementscoherence in software. The project has recently moved from simulation to implementation;using a 32-processor Alpha-server cluster (eight 4-processor nodes) on DEC's MemoryChannel network. This talk will focus on the Cashmere implementation and on earlyexperience as a Memory Channel field test site. The Cashmere coherence protocol ischaracterized by (1) multi-writer lazy release consistency;(2) directories to keep track of whois sharing pages; and (3) update merging via write-through to a unique main-memory copyof each page. Like many software coherent systems; Cashmere uses virtual memory …,Workshop on Scalable Shared Memory Multiprocessors,1996,3
Parallel performance understanding via integration of modeling and diagnosis,Wagner Meira Jr; Thomas J LeBlanc,*,*,1996,3
" Everything I Disagree With is# FakeNews": Correlating Political Polarization and Spread of Misinformation,Manoel Horta Ribeiro; Pedro H Calais; Virgílio AF Almeida; Wagner Meira Jr,Abstract: An important challenge in the process of tracking and detecting the disseminationof misinformation is to understand the political gap between people that engage with the socalled" fake news". A possible factor responsible for this gap is opinion polarization; whichmay prompt the general public to classify content that they disagree or want to discredit asfake. In this work; we study the relationship between political polarization and contentreported by Twitter users as related to" fake news". We investigate how polarization maycreate distinct narratives on what misinformation actually is. We perform our study based ontwo datasets collected from Twitter. The first dataset contains tweets about US politics ingeneral; from which we compute the degree of polarization of each user towards theRepublican and Democratic Party. In the second dataset; we collect tweets and URLs that …,arXiv preprint arXiv:1706.05924,2017,2
A Characterization of Load Balancing on the IPv6 Internet,Rafael Almeida; Osvaldo Fonseca; Elverton Fazzion; Dorgival Guedes; Wagner Meira; Ítalo Cunha,Abstract As IPv6 deployment grows; it is important to develop new measurement techniquesthat allow us to study the IPv6 Internet. We implement an IPv6 version of the MultipathDetection Algorithm and use it from 12 geographically-distributed vantage points on twodifferent platforms to characterize IPv6 routers that perform load balancing. Overall; we findthat 74% of IPv6 routes traverse at least one router that performs load balancing. Similar toprevious reports for IPv4; we find per-destination is the most prevalent type of loadbalancing; surprisingly; we find a significantly higher prevalence of per-packet loadbalancing for IPv6 traffic than previously reported for IPv4. We investigate which headerfields are used for load balancing; and find that 4% of IPv6 routers that perform loadbalancing consider IPv6's Traffic Class or Flow Label fields. Finally; we quantify how often …,International Conference on Passive and Active Network Measurement,2017,2
Watershed‐ng: an extensible distributed stream processing framework,Rodrigo Rocha; Bruno Hott; Vinícius Dias; Renato Ferreira; Wagner Meira; Dorgival Guedes,Summary Most high-performance data processing (aka big data) systems allow users toexpress their computation using abstractions (like MapReduce); which simplify the extractionof parallelism from applications. Most frameworks; however; do not allow users to specifyhow communication must take place: That element is deeply embedded into the run-timesystem abstractions; making changes hard to implement. In this work; we describeWathershed-ng; our re-engineering of the Watershed system; a framework based on thefilter–stream paradigm and originally focused on continuous stream processing. Like otherbig-data environments; Watershed provided object-oriented abstractions to expresscomputation (filters); but the implementation of streams was a run-time system element. Byisolating stream functionality into appropriate classes; combination of communication …,Concurrency and Computation: Practice and Experience,2016,2
A Big Data architecture for security data and its application to phishing characterization,Pedro HB Las-Casas; Vinicius Santos Dias; Wagner Meira; Dorgival Guedes,As the Internet grows; cybersecurity problems also arise. Different types of maliciousactivities have been explored by attackers. However; the existent defense mechanisms arenot able to completely end the malicious threats; perpetuating this continuous arms race.The development of applications to mitigate those threats presents some complicatingfactors such as the growth in the amount of data; and the variety of data; that can come fromdifferent sources. In this paper we present an architecture built on top of Big Dataframeworks that aims to mitigate cybersecurity problems such as spam and phishing and weshow how it is being used to study spam and phishing collected using a global honeynet.,Big Data Security on Cloud (BigDataSecurity); IEEE International Conference on High Performance and Smart Computing (HPSC); and IEEE International Conference on Intelligent Data and Security (IDS); 2016 IEEE 2nd International Conference on,2016,2
Neighborhoods and bands: an analysis of the origins of spam,Osvaldo Fonseca; Elverton Fazzion; Pedro Henrique B Las-Casas; Dorgival Guedes; Wagner Meira; Cristine Hoepers; Klaus Steding-Jessen; Marcelo HP Chaves,Despite the continuous efforts to mitigate spam; the volume of such messages continues togrow and identifying spammers is still a challenge. Spam traffic analysis is an important toolin this context; allowing network administrators to understand the behavior of spammers;both as they obfuscate messages and try to hide inside the network. This work adds to thatbody of information by analyzing the sources of spam to understand to what extent theyexplain the traffic observed. Our results show that; in many cases; an Autonomous System(AS) represents an interesting neighborhood to observe; with most ASes falling into fourbasic types: heavy and light senders; which tend to have many or very few spammermachines respectively; frequent small offenders; where spammer machines appear everynow and then but disappear in a short time; and conniving ASes; where most machines …,Journal of Internet Services and Applications,2015,2
A latent shared-component generative model for real-time disease surveillance using Twitter data,Roberto CSNP Souza; Denise EF de Brito; Renato M Assunção; Wagner Meira Jr,Abstract: Exploiting the large amount of available data for addressing relevant socialproblems has been one of the key challenges in data mining. Such efforts have beenrecently named" data science for social good" and attracted the attention of severalresearchers and institutions. We give a contribution in this objective in this paperconsidering a difficult public health problem; the timely monitoring of dengue epidemics insmall geographical areas. We develop a generative simple yet effective model to connectthe fluctuations of disease cases and disease-related Twitter posts. We considered a hiddenMarkov process driving both; the fluctuations in dengue reported cases and the tweetsissued in each region. We add a stable but random source of tweets to represent the postswhen no disease cases are recorded. The model is learned through a Markov chain …,arXiv preprint arXiv:1510.05981,2015,2
Data mining and analysis,WAGNER MEIRA JR; MJ Zaki,This book is an outgrowth of data mining courses at Rensselaer Polytechnic Institute (RPI)and Universidade Federal de Minas Gerais (UFMG); the RPI course has been offered everyFall since 1998; whereas the UFMG course has been offered since 2002. Although there areseveral good books on data mining and related topics; we felt that many of them are eithertoo high-level or too advanced. Our goal was to write an introductory text that focuses on thefundamental algorithms in data mining and analysis. It lays the mathematical foundations forthe core data mining methods; with key concepts explained when first encountered; the bookalso tries to build the intuition behind the formulas to aid understanding. The main parts ofthe book include exploratory data analysis; frequent pattern mining; clustering; andclassification. The book lays the basic foundations of these tasks; and it also covers …,*,2014,2
An annotation process for data visualization techniques,Geraldo Franciscani Jr; Rodrygo LT Santos; Raphael Ottoni; Joao Paulo Pesce; Wagner Meira Jr; Raquel Melo-Minardi,Abstract—As the area of information visualization grows; a massive amount of visualizationtechniques has been developed. Consequently; the choice of an appropriate visualizationhas become more complex; usually resulting in unsatisfactory data analysis. Although thereexist models and classifications that could guide the choice of a visualization technique; theyare mostly generalist and do not present a clear methodology for evaluation and evolution.In contrast; we propose an annotation process for data visualization techniques based on aninitial capability-driven collection of terms and concepts that encompasses visualcomponents of both well established as well as modern visualization techniques. Todemonstrate the initial collections expressiveness; we present a qualitative analysis of anexperiment with specialist users at annotating visualization techniques from the D3 (Data …,Proceedings of the 3rd International Conference on Data Analytics,2014,2
Constraint-based search of straddling biclusters and discriminative patterns,Israel Guerra; Loïc Cerf; João Foscarini; Michel Boaventura; Wagner Meira Jr,*,Journal of Information and Data Management,2013,2
Caracterização do uso de hashtags do Twitter para mensurar o sentimento da população online: Um estudo de caso nas Eleições Presidenciais dos EUA em 2012.,Glívia AR Barbosa; Pedro HF Holanda; Geanderson E dos Santos; Conrado C da Costa; Ismael Santana Silva; Adriano Veloso; Wagner Meira Jr,In this paper we describe the partial results and future directions of a research in progress;which main goal is to analyze whether the opinion expressed through Twitter hashtags canhelp to identify and track online sentiment. Once confirmed this contribution; this type ofhashtag can be used as input for applications that aim to detect and track automaticallyonline population sentiment about different events.,SBBD (Short Papers),2013,2
Open Weekend and Rating Prediction Based on Visualization Techniques,Elverton Fazzion; Pedro Las Casas; Glauber Gonçalves; Raquel Melo-Minardi; Wagner Meira Jr,Abstract—Predicting gross revenue for movies is an important problem for the movieindustry. Several studies [3] in economics; marketing; statistics and computer science tried tosolve this problem. In this work; we propose an approach to accurately predict openingweekend box office (OW) and the rating of an upcoming movie which is based on avisualization technique. The visualization uses a regression model built with past movies'data about the same cast of the target movie.,Proc. IEEE Int. Conf. on Visual Analytics Science and Technology (VAST Challenge Paper),2013,2
Data and instruction uniformity in minimal multi-threading,Teo Milanez; Sylvain Collange; Fernando Magno Quintao Pereira; Wagner Meira Jr; Renato A Ferreira,Simultaneous Multi-Threading (SMT) is a hardware model in which different threads sharethe same instruction fetching unit. This model is a compromise between high parallelism andlow hardware cost. Minimal Multi-Threading (MMT) is a technique recently proposed toshare instructions and execution between threads in a SMT machine. In this paper wepropose new ways to explore redundancies in the MMT execution model. First; we proposeand evaluate a new thread reconvergence heuristics that handles function calls better thanprevious approaches. Second; we demonstrate the existence of substantial regularity in inter-thread memory access patterns. We validate our results on the four data-parallelapplications present in the PARSEC benchmark suite. The new thread reconvergenceheuristics is; on the average; 82% more efficient than MMT's original reconvergence …,Computer Architecture and High Performance Computing (SBAC-PAD); 2012 IEEE 24th International Symposium on,2012,2
Exploiting temporal locality to determine user bias in microblogging platforms,Pedro H Calais Guerra; Loic Cerf; Thiago C Porto; Adriano Veloso; Wagner Meira Jr; Virgílio Almeida,Abstract Bias is the human tendency to favor one side of a discussion in argumentation;lacking neutrality and balance. Determining user biases is key to applications that process;interpret; and recommend content generated by those users in social media platforms. Thispaper addresses the problem of determining (in a supervised way) biases of microbloggersfrom the stream of messages. In this paper; we evaluate the use of a new criterion to identifyuser bias in social media systems: the temporal locality among users that have similar bias;ie; the fact that people having similar biases express at about the same time. We show thatthis remarkable property indeed holds in some,Journal of Information and Data Management,2011,2
ROCK: uma Metodologia para Caracterização de Serviços Web Multimídia baseada na Hierarquia da Informação,Charles F Gonçalves; Luam C Totti; Diego Duarte; Wagner Meira Jr; Adriano CM Pereira,ABSTRACT Apesar da crescente popularizaçao do uso de conteúdos multimıdia na WebBrasileira; pouco é conhecido sobre a dinâmica de consumo desses conteúdos. A maioriadas metodologias de caracterizaçao existentes foca suas análises no acesso aos dados enos conceitos de sessoes e usuários; ignorando informaçoes potencialmente relevantesassociadas ao conteúdo dessas mıdias. Neste trabalho apresentamos uma novametodologia de caracterizaçao de serviços Web multimıdia organizada de formahierárquica em quatro nıveis: Requisiçao (R); Objeto (O); Conteúdo (C) e Conhecimento (K)-ROCK. A metodologia propoe uma segmentaçao das análises em diferentes camadasvisando a extraçao de informaçoes existentes nos conteúdos. Para validar a metodologiaapresentamos um estudo de caso utilizando dados da maior distribuidora de conteúdos …,XVII Simpósio Brasileiro de Sistemas Multimídia e Web WebMedia,2011,2
RT-NED: Real-time named entity disambiguation on Twitter streams,Alexandre Davis; Walter Santos; Adriano Veloso; Wagner Meira Jr; Alberto Laender; Altigran Soares da Silva,Abstract. Mining data from social midia channels; such as Twitter; is an increasinglyimportant challenge. Messages continuously flow through the Web in high volumes; and thelack of a syntactical structure makes it hard to extract information from them. For instance;Identifying entities in such messages is a requirement for applications such as contextextraction and sentiment analysis. In this paper; we present a novel technique to solve themany-to-many correspondence between ambiguous names and a unique real-world entity;in real-time; using only a stream of messages as data source. This novel technique isimplemented using a three-stage pipeline. In the first stage; previously defined filtering rules(colocations; users; hash tags) are used to identify clearly positive examples of messagestruly mentioning the real-world entity (ies). These messages are given as input to a …,Anais no XXVI Simpósio Brasileiro de Banco de Dados-Sessão de Demos. Florianópolis,2011,2
Assessing success factors of selling practices in electronic marketplaces,A Pereira; Diego Duarte; Wagner Meira Jr; P Góes,Abstract Electronic markets have early emerged as an important topic inside e-commerceresearch. An e-market is a digital ecosystem intended to provide their users with onlineservices that will facilitate information exchange and transactions. This work presents acharacterization and analysis of fixed-price online negotiations. Using actual data from aBrazilian marketplace; we analyze selling practices; considering seller profiles and sellingstrategies. There are important factors that can be considered when analyzing sellingpractices; such as the seller's reputation and experience; offer's price; duration; amongothers. We evaluate which factors impact on the success of selling practices in e-markets;which can be used to support seller's decision and recommend selling practices. Moreover;we investigate some important hypotheses about selling practices in online marketplaces …,Proceedings of the International Conference on Management of Emergent Digital EcoSystems,2009,2
Exploiting contexts to deal with uncertainty in classification,Bianca Zadrozny; Gisele L Pappa; Wagner Meira Jr; Marcos André Gonçalves; Leonardo Rocha; Thiago Salles,Abstract Uncertainty is often inherent to data and still there are just a few data miningalgorithms that handle it. In this paper we focus on how to account for uncertainty inclassification algorithms; in particular when data attributes should not be consideredcompletely truthful for classifying a given sample. Our starting point is that each piece of datacomes from a potentially different context and; by estimating context probabilities of anunknown sample; we may derive a weight that quantifies their influence. We propose a lazyclassification strategy that incorporates the uncertainty into both the training and usage ofclassifiers. We also propose uK-NN; an extension of the traditional K-NN that implementsour approach. Finally; we illustrate uK-NN; which is currently being evaluatedexperimentally; using a document classification toy example.,Proceedings of the 1st ACM SIGKDD Workshop on Knowledge Discovery from Uncertain Data,2009,2
Reactivity based model to study online auctions dynamics,Adriano Pereira; Leonardo Rocha; Fernando Mourão; Paulo Góes; Wagner Meira,Abstract Online auctions have challenged many assumptions and results from the traditionaleconomic auction theory. Observed bidder behavior in online auctions often deviates fromequilibrium strategies postulated by economic theory. In this research; we consider anonline auction as an information system that provides a long-duration; information-rich;dynamic application environment in which users (bidders) interact with the system in afeedback loop; in what we term reactivity. Bidders react to the observed conditions of theauction and events triggered by actions of other bidders. In this work we propose a newcharacterization model with the purpose of isolating the segments of the auction in whichusers react to the auction conditions and events. Through this model; it is possible to enrichthe auction characterization. Despite the existence of other bidding characterization …,Information Technology and Management,2009,2
Quantifying the impact of information aggregation on complex networks: a temporal perspective,Fernando Mourao; Leonardo Rocha; Lucas Miranda; Virgílio Almeida; Wagner Meira,Abstract Complex networks are a popular and frequent tool for modeling a variety of entitiesand their relationships. Understanding these relationships and selecting which data will beused in their analysis is key to a proper characterization. Most of the current approachesconsider all available information for analysis; aggregating it over time. In this work; westudied the impact of such aggregation while characterizing complex networks. We modelfour real complex networks using an extended graph model that enables us to quantify theimpact of the information aggregation over time. We conclude that data aggregation maydistort the characteristics of the underlying real-world network and must be performedcarefully.,International Workshop on Algorithms and Models for the Web-Graph,2009,2
Práticas de comercialização em mercados eletrônicos,Diego Duarte; Adriano Pereira; Wagner Meira Jr,RESUMO Recentemente; temos testemunhado um grande crescimento do comércioeletrônico. Por exemplo; as vendas na Amazon. com aumentaram 37% no primeiro trimestrede 2008. Este trabalho apresenta uma caracterizaçao e análise de negociaçoes online depreço fixo. Usando dados reais de um mercado eletrônico; analisamos práticas de venda;considerando perfis de vendedores e estratégias de venda. Verificamos que diferentesvendedores adotam estratégias de acordo com seus interesses e experiências. Além disso;confirmamos que é importante considerar as caracterısticas do vendedor para avaliar aaplicabilidade da estratégia de venda.,*,2009,2
A seller's perspective characterization methodology for online auctions,Arlei Silva; Pedro Calais; Adriano Pereira; Fernando Mourão; Jussara Almeida; Wagner Meira Jr; Paulo Góes,Abstract Online auction services have reached great popularity and revenue over the lastyears. A key component for this success is the seller. Few studies proposed analyzing howthe seller and the auction configuration affect the negotiation results. In this work we proposea methodology to characterize online auctions by the seller's perspective. This methodologyis based on:(1) recognizing the characteristics of the variables related to the auction resultsand (2) capturing the correlation among these variables to identify seller profiles and sellingstrategies. We applied our methodology to a real case study; using an eBay dataset; tovalidate two hypotheses about sellers and their practices. These results are useful tounderstand the complex mechanisms that guide ending prices; success (or failure); and theattraction of bids in online auctions; which can support decision strategies for buyers and …,Proceedings of the 10th international conference on Electronic commerce,2008,2
Modelo de interface extensível como solução para desafios de interação em sistemas de mineração de dados,Elisa Algergaria; Fernando Mourão; Wagner Meira; Raquel Prates,Abstract. Currently; one of the great challenges of computing is the enormous volume of datagenerated by the increasing use of the Internet by businesses; governments and individuals.The data mining field focuses on how to generate knowledge from large volumes of data.However; data mining systems are usually difficult to use; since they require users to havetechnical knowledge about the technique being used. This work aims at broadening theusage of such systems. To do so; we present an extensible interface model that allows forthe creation of new interfaces at a higher level of abstraction for a specific context. Resumo.Atualmente; um dos grandes desafios da computação é o enorme volume de dados geradocom o crescente uso da Internet por empresas; governos e indivíduos. A área de mineraçãode dados tem por objetivo a geração de conhecimento a partir de grandes volumes de …,*,2008,2
Knowledge Discovery in Databases: PKDD 2007,JN Kok; J Koronacki; RL de Mántaras; S Matwin; D Mladenic; A Skowron,*,11th European Conference on Principles and Practice of Knowledge Discovery in Databases; Warsaw; Poland,2007,2
Reactivity-based quality of service strategies for web applications,Leonardo Silva; Adriano Pereira; Wagner Meira Jr,The great success of the Internet has raised new challenges in terms of applications anduser satisfaction. Web applications demand requirements; such as performance andscalability; in order to guarantee quality of service (QoS) to users. Due to theserequirements; QoS has become a special topic of interest and many mechanisms to provideit have been proposed. Those mechanisms fail to consider aspects related to reactivity; ie;how the users react to variable server response time. This work addresses the use ofreactivity to provide new strategies. We design and evaluate a reactivity-based schedulingmechanism that gives priority according to user behavior. We also propose a hybridadmission control and scheduling mechanism that combines both reactive approaches. Theresults show benefits in terms of response time and user satisfaction,Applications and the Internet; 2007. SAINT 2007. International Symposium on,2007,2
Caracterizando desafios de interação com Sistemas de Mineração de Regras de Associação,Elisa Tuler; Raquel O Prates; Fernando Almir; Leonardo Rocha; Wagner Meira Jr,Abstract Data mining focuses on extracting useful information from great volumes of data;and thus has been the center of great attention in the recent years. Among the manytechniques available for data mining; identifying association rules is one of the most popular.The novel aspect of rule association mining systems brings new challenges to the HCI field.In this article; we identify these challenges and analyze them based on the theory of action;and characterize it within the semiotic engineering theoretical framework. Thus; we providedesigners with an explanation of aspects to be considered during use and design of suchsystems. This theoretical based explanation contributes to a deeper understanding of theissues involved in interacting with association rules mining systems; allowing for betterinformed decisions during design process. It also motivates future empirical investigations.,Proceedings of VII Brazilian symposium on Human factors in computing systems,2006,2
Assessing Data Virtualization for Irregularly Replicated Large Datasets,Bruno Diniz; Diego L Nogueira; Andre Cardoso; Renato A Ferreira; Dorgival Guedes; W Meira,Large volumes of data are generated every day by experiments; simulations and all sorts ofapplications. It is common to observe situations where portions of data are irregularlyreplicated and distributed in different data sources. It would be desirable to be able tohandle these several pieces of irregular data (replicated or not) as a unique large dataset.This is called data virtualization and is the focus of this paper. In this paper; we present asystem which is capable of dealing with irregularly replicated data and is able to create avirtual view of the union of the individual irregular portions of data hosted by each datasource. Our system indexes the data intervals from each data source and allows clients tosubmit queries against the virtual dataset created. In order to select what server will beresponsible for each data interval of a query; we use and compare three algorithms …,Cluster Computing and the Grid; 2006. CCGRID 06. Sixth IEEE International Symposium on,2006,2
Hash consistente como uma ferramenta para distribuição de tarefas em sistemas distribuídos reconfiguráveis,André Ribeiro da Silva; Hélio Marcos Paz de Almeida; Tiago Macambira; Dorgival Olavo Guedes; W Meira; Renato Antonio C Ferreira,Sistemas distribuídos que incluem processos replicados em várias máquinas têm queoferecer soluções para o problema de distribuição dinâmica de tarefas. No caso em que aaplicação requer a manutenção de algum de estado entre tarefas é preciso um esquemaconsistente de endereçamento. Isso é usualmente feito através de uma função de hashtradicional; que entretanto não funciona bem em ambientes com reconfiguração dinâmica.Neste trabalho avaliamos o uso de hash consistente; uma forma de hash onde a função dedistribuição se altera pouco com a alteração da sua faixa de operação; como uma soluçãopara esse problema. Comparamos o desempenho de duas soluções de hash consistentecom soluções tradicionais em termos da uniformidade do padrão de distribuição; do númerode mensagens trocadas quando de uma reconfiguração e do padrão de comunicação …,WORKSHOP EM SISTEMAS COMPUTACIONAIS (WSCAD); Rio de Janeiro. Proceedings… Rio de Janeiro,2005,2
Paralelizaç ao eficiente de um algoritmo de agrupamento hierárquico,G Ferreira; R Araujo; G Orair; L Gonçalves; D Guedes; R Ferreira; V Furtado; W Meira Jr,Resumo. O emprego de técnicas de mineraç ao de dados tem se mostrado essencial para aanálise de um crescente volume de dados das mais variadas áreas. O uso de paralelismose firma como uma alternativa necessária nesse cenário; porém; obter escalabilidade é umdesafio fundamental. Neste artigo discutimos a paralelizaçao de um algoritmo deagrupamento hierárquico conceitual; o Cobweb; no ambiente de programaçao paralelaAnthill. Os resultados mostram que o algoritmo paralelo resultante escala linearmente paraas maiores bases de dados testadas. Nossos resultados apontam também para uma soluçao interessante para paralelizaç ao eficiente de algoritmos em grafos. Abstract. Data miningtechniques have become essential to the analysis of growing datasets in many areas. Theuse of parallel techniques stands up as a necessary alternative in this context; however …,*,2005,2
A hierarchical characterization of user behavior,Adriano Pereira; Gustavo Franco; Leonardo Silva; Wagner Meira Jr,Abstract Understanding the characteristics of Internet services workloads is a crucial step toimprove the quality of service offered to Web users. This paper presents a hierarchical andmultiple time scale approach based on [16]; which propose a characterization at the session;function; and request levels. This work extends it; adding new insights to these three levelsand characterizing a new level that comprises the user behavior. The approach is illustratedby presenting a characterization of a proxy-cache server from one of the biggest Brazilianfederal universities. Through this case study we show clearly how to apply the methodologyconsidering some new analysis included for the three original levels (request; function; andsession) and for the new one (user). This new level of characterization is the novelty of thisresearch area; once it considers the interaction between users and servers; that answer …,*,2004,2
Distributed architecture for information retrieval,Claudine BadueН; Ricardo Baeza-YatesО; Wagner MeiraП; Berthier Ribeiro-Neto; Nivio Ziviani,ABSTRACT Я джгдгз ж в гб а нгйи гж зиж йи в гжб и гв ж Й иж к а знзи бз з гв аг а в мК Ь жв гб а нЙ гйи з йз иг бда б ви ж в гб аг а в мИ л ааглз а в в и аг в ии в в бджгк д ж гжЙ б в КЬ зиж йи знзи б гдиз в илгж г лгж Й зи и гвз бг а в и а виЙз жк ж д ж бК г йб виз ж ж в йз в ик игж зд бг а агв л и г Й йб ви Ќаи ж в и в ей К Св и ж в гб аг а в мИ аг а вк жи Ќа з в ж и гжаа г йб виз в и и ми и з в Ќм з о аг з г и вк жи а зиз ж ж вЙ гбан зиж йи бгв джг ззгжзК Эз вж а Я и гаа и гвИ л гбд ж из д ж гжб в взи илг ги ж в м д жи и гв в з б зИ в б ан а м г ж д а ага в м в аг а в мК гж и зИ в в ани а бг а гйда л и з бйа игж з к агд в к а и К Ъ ж в аг а в И и жв гб а нгйи гйид ж гжбз и а м г ж д а л и вз ж в илг и б зК Ъ ж в ж здгвз и б И и ж в гб а нгйив и а м г ж д а к з б а ж д ж гжЙ б в гв к ж К ги а нгйи з б з гйид ж гжб з в Й Ќ и к ан и аг а вмИ л и вз и и ж Ќк и б зК й иг из ии ж аг а в в И гбд и и к ей жн джг ззЙ в д ж гжб в в м а …,*,2002,2
Uma metodologia para verificaçao de modelos de sistemas de comércio eletrônico,Adriano Pereira; Mark Song; Gustavo Gorgulho; Wagner Meira Jr; Sérgio Campos,*,*,2002,2
A model checking methodology for e-commerce systems,Adriano Pereira; Wagner Meira Jr; Sérgio Campos,Abstract. Electronic commerce systems are complex and hard to design. This work proposesa methodology that uses formal methods; specifically symbolic model checking; to designelectronic commerce systems and to automatically verify that these designs satisfyproperties such as atomicity; isolation; and consistency. In order to demonstrate theapplicability and feasibility of the technique; two case studies were modeled and verified.Each of them has more than ½¼ ¾¿ states and verification has been completed in fewminutes; identifying in one of them a concurrency control error. As a result of this work; it ispossible to generate more reliable applications; developed faster and at lower costs.,*,2002,2
Formal-CAFE Methodology: an E-commerce System’s Case Study,Adriano Pereira; Mark Song; Gustavo Gorgulho; Wagner Meira Jr; Sérgio Campos,Abstract Electronic commerce is an important application that has evolved significantlyrecently. However; electronic commerce systems are complex and difficult to be correctlydesigned. Currently; most approaches are ad-hoc; and frequently lead to expensive;unreliable systems that may take a long time to implement due to the great amount of errors.Moreover; guaranteeing the correctness of an e-commerce system is not an easy task due tothe great amount of scenarios where errors occur; many of them very subtle. Such task isquite hard and laborious if only tests and simulation; common techniques of systemvalidation; are used. In this work we presents a methodology that uses formal-methodtechniques; specifically symbolic model checking; to design electronic commerceapplications and to automatically verify that these designs satisfy properties such as …,Proceedings of the Fifth International Conference on Electronic Commerce Research (ICECR-5),2002,2
Qos in parallelized e-commerce systems,Bruno Diniz; Rodrigo Pereira; Wagner Meira Jr; Virgılio Almeida,*,Proceedings of the XII SBAC-PAD-Simp osio Brasileiro de Arquitetura de Computadores e Processamento de Alto Desempenho; São Pedro; SP,2000,2
Dynamic aspects of documents of the Brazilian Web,Nahur M Fonseca; Rodolfo SF Resende; Wagner Meira,The huge number and the textual nature of Web documents have created the need forsearch engines. In this kind of system the user's queries are answered based on a staticview of the whole or part of the Web. However; the Web is a dynamic system and itsdocuments are inserted; changed and removed frequently; thus creating an inconsistencybetween the state of the Web and the static view of the documents of the search engine. Wedescribe the dynamic aspects of the HTML documents of the Brazilian Web; namely the rateof insertion; change and removal of its documents; from the point of view of search engines.We also describe the tools we used to support this study. Whenever possible; we comparemeasures of the Brazilian Web with related measures of the World Wide Web. We show howthe study of these aspects can be used in search engines to improve the quality of its …,Web Information Systems Engineering; 2000. Proceedings of the First International Conference on,2000,2
Paralelização de Geração de Regras de Associação,B Pôssas; F Peligrinelli; W Meira Jr; M Carvalho; R Resende,Resumo Mineração de dados é uma área de pesquisa emergente; cujo objetivo principal éextrair padrões e regras implícitos em banco de dados. Mui tos algoritmos para mineraçãode regras de associação foram propostos. Entretanto; a pesquisa tem dado atençãoprincipalmente à algoritmos seqüenciais. Neste artigo apresentamos a paralelização de umalgoritmo para determinação de regras de associação; utilizando o paradigma de memóriacompartilhada. Os resultados indicam que a nossa paralelização é escalável até oitoprocessadores; independentemente das características da massa de dados.,10o Simposio Brasileiro de Arquitetura de Computadores e Processamento de Alto Desempenho,1998,2
Universidade Federal de Minas Gerais,Adriano Veloso; Wagner Meira; Márcio Bunte De Carvalho; Srinivasan Parthasarathy; Mohammed Zaki,Abstract This paper deals with new approaches to maintaining frequent itemsets in evolvingdatabases. Our new approaches make use of incremental techniques to provide significantI/O reduction; and parallel techniques to provide computational savings. At the same time;our approaches are able to effectively handle online data updates (deletions/insertions) andinteractive response times (approximate/partial results). Some additional highlights of theproposed approaches include extending the validity of the itemsets (generating approximatemodels of itemsets); and performing selective updates (tracking stable and predictableitemsets). These features allow our approaches to mine evolving data stored in warehousesas well as (potentially) streaming data. Extensive experimental benchmarking on evolvingdata demonstrates the potential advantages of the proposed approaches. We believe that …,*,*,2
" Like Sheep Among Wolves": Characterizing Hateful Users on Twitter,Manoel Horta Ribeiro; Pedro H Calais; Yuri A Santos; Virgílio AF Almeida; Wagner Meira Jr,Abstract: Hateful speech in Online Social Networks (OSNs) is a key challenge for companiesand governments; as it impacts users and advertisers; and as several countries have strictlegislation against the practice. This has motivated work on detecting and characterizing thephenomenon in tweets; social media posts and comments. However; these approaches faceseveral shortcomings due to the noisiness of OSN data; the sparsity of the phenomenon;and the subjectivity of the definition of hate speech. This works presents a user-centric viewof hate speech; paving the way for better detection methods and understanding. We collect aTwitter dataset of $100;386 $ users along with up to $200 $ tweets from their timelines with arandom-walk-based crawler on the retweet graph; and select a subsample of $4;972 $ to bemanually annotated as hateful or not through crowdsourcing. We examine the difference …,arXiv preprint arXiv:1801.00317,2017,1
Characterizing videos; audience and advertising in Youtube channels for kids,Camila Souza Araújo; Gabriel Magno; Wagner Meira; Virgilio Almeida; Pedro Hartung; Danilo Doneda,Abstract Online video services; messaging systems; games and social media services aretremendously popular among young people and children in many countries. Most of thedigital services offered on the internet are advertising funded; which makes advertisingubiquitous in children's everyday life. To understand the impact of advertising-based digitalservices on children; we study the collective behavior of users of YouTube for kids channelsand present the demographics of a large number of users. We collected data from 12;848videos from 17 channels in US and UK and 24 channels in Brazil. The channels in Englishhave been viewed more than 37 billion times. We also collected more than 14 millioncomments made by users. Based on a combination of text-analysis and face recognitiontools; we show the presence of racial and gender biases in our large sample of users. We …,International Conference on Social Informatics,2017,1
PRIVAaaS: privacy approach for a distributed cloud-based data analytics platforms,Tania Basso; Regina Moraes; Nuno Antunes; Marco Vieira; Walter Santos; Wagner Meira Jr,Abstract Data privacy is a key challenge that is exacerbated by Big Data storage andanalytics processing requirements. Big Data and Cloud Computing are related and allow theusers to access data from any device; making data privacy essential as the data sets areexposed through the web. Organizations care about data privacy as it directly affects theconfidence that clients have that their personal data are safe. This paper presents a dataprivacy approach-PRIVAaaS-and its integration to the LEMONADE Web-based platform;developed to compose ETL (Extract; Transform; Load) process and Machine Learningworkflows. The 3-level approach of PRIVAaaS; based on data anonymization policies; isimplemented in a software toolkit that provides a set of libraries and tools which allowscontrolling and reducing data leakage in the context of Big Data processing.,Proceedings of the 17th IEEE/ACM International Symposium on Cluster; Cloud and Grid Computing,2017,1
Infection Hot Spot Mining from Social Media Trajectories,Roberto CSNP Souza; Renato M Assunção; Derick M de Oliveira; Denise EF de Brito; Wagner Meira,Abstract Traditionally; in health surveillance; high risk zones are identified based only on theresidence address or the working place of diseased individuals. This provides littleinformation about the places where people are infected; the truly important information fordisease control. The recent availability of spatial data generated by geotagged social mediaposts offers a unique opportunity: by identifying and following diseased individuals; weobtain a collection of sequential geo-located events; each sequence being issued by asocial media user. The sequence of map positions implicitly provides an estimation of theusers' social trajectories as they drift on the map. The existing data mining techniques forspatial cluster detection fail to address this new setting as they require a single location toeach individual under analysis. In this paper we present two stochastic models with their …,Joint European Conference on Machine Learning and Knowledge Discovery in Databases,2016,1
Stereotypes in Search Engine Results: Understanding The Role of Local and Global Factors,Gabriel Magno; Camila Souza Araújo; Wagner Meira Jr; Virgilio Almeida,Abstract: The internet has been blurring the lines between local and global cultures;affecting in different ways the perception of people about themselves and others. In theglobal context of the internet; search engine platforms are a key mediator betweenindividuals and information. In this paper; we examine the local and global impact of theinternet on the formation of female physical attractiveness stereotypes in search engineresults. By investigating datasets of images collected from two major search engines in 42countries; we identify a significant fraction of replicated images. We find that commonimages are clustered around countries with the same language. We also show thatexistence of common images among countries is practically eliminated when the queries arelimited to local sites. In summary; we show evidence that results from search engines are …,arXiv preprint arXiv:1609.05413,2016,1
Euclidean Co-Embedding of Ordinal Data for Multi-Type Visualization,Dung D Le; Hady W Lauw,Abstract Embedding deals with reducing the high-dimensional representation of data into alow-dimensional representation. Previous work mostly focuses on preserving similaritiesamong objects. Here; not only do we explicitly recognize multiple types of objects; but wealso focus on the ordinal relationships across types. Collaborative Ordinal Embedding orCOE is based on generative modelling of ordinal triples. Experiments show that COEoutperforms the baselines on objective metrics; revealing its capacity for informationpreservation for ordinal data.,*,2016,1
Binary classifier calibration using an ensemble of linear trend estimation,Mahdi Pakdaman Naeini; Gregory F Cooper,Abstract Learning accurate probabilistic models from data is crucial in many practical tasksin data mining. In this paper we present a new non-parametric calibration method calledensemble of linear trend estimation (ELiTE). ELiTE utilizes the recently proposed ℓ 1 trendfiltering signal approximation method [22] to find the mapping from uncalibratedclassification scores to the calibrated probability estimates. ELiTE is designed to address thekey limitations of the histogram binning-based calibration methods which are (1) the use of apiecewise constant form of the calibration mapping using bins; and (2) the assumption ofindependence of predicted probabilities for the instances that are located in different bins.The method post-processes the output of a binary classifier to obtain calibrated probabilities.Thus; it can be applied with many existing classification models. We demonstrate the …,*,2016,1
Diagnosing performance bottlenecks in massive data parallel programs,Vinícius Dias; Ruens Moreira; Wagner Meira; Dorgival Guedes,The increasing amount of data being stored and the variety of applications being proposedrecently to make use of those data enabled a whole new generation of parallel programmingenvironments and paradigms. Although most of these novel environments provide abstractprogramming interfaces and embed several run-time strategies that simplify several typicaltasks in parallel and distributed systems; achieving good performance is still a challenge. Inthis paper we identify some common sources of performance degradation in the Sparkprogramming environment and discuss some diagnosis dimensions that can be used tobetter understand such degradation. We then describe our experience in the use of thosedimensions to drive the identification performance problems; and suggest how their impactmay be minimized considering real applications.,Cluster; Cloud and Grid Computing (CCGrid); 2016 16th IEEE/ACM International Symposium on,2016,1
Simulations of cardiac electrophysiology combining gpu and adaptive mesh refinement algorithms,Rafael S Oliveira; Bernardo M Rocha; Denise Burgarelli; Wagner Meira; Rodrigo W dos Santos,Abstract Computer models have become valuable tools for the study and comprehension ofthe complex phenomena of cardiac electrophysiology. However; the high complexity of thebiophysical processes translates into complex mathematical and computational models. Inthis paper we evaluate a hybrid multicore and graphics processing unit numerical algorithmbased on mesh adaptivity and on the finite volume method to cope with the complexity andto accelerate these simulations. This is a very attractive approach since the electricalwavefront corresponds to only a small fraction of the cardiac tissue. Usually; the numericalsolution of the partial differential equations that model the phenomenon requires very finespatial discretization to follow the wavefront; which is approximately 0.2 mm. The use ofuniform meshes leads to high computational cost as it requires a large number of mesh …,International Conference on Bioinformatics and Biomedical Engineering,2016,1
Stereotypes in Search Engine Answers: Local or Global?,Gabriel Magno; Camila Souza Araújo; Wagner Meira Jr; Virgilio Almeida,ABSTRACT The internet has been blurring the lines between local and global cultures;affecting in different ways the perception of people about themselves and others. In theglobal context of the internet; search engine platforms are a key mediator betweenindividuals and information. In this paper; we examine the local and global impact of theinternet on the formation of female physical attractiveness stereotypes in search engineresults. By investigating datasets of images collected from two major search engines in 42countries; we identify a significant fraction of replicated images. We find that commonimages are clustered around countries with the same language. We also show thatexistence of common images among countries is practically eliminated when the queries arelimited to local sites. In summary; we show evidence that results from search engines are …,CoRR,2016,1
Uma metodologia para identificaç ao adaptativa e caracterizaç ao de phishing,Pedro Henrique B Las-Casas; Osvaldo Fonseca; Elverton Fazzion; Cristine Hoepers; Klaus Steding-Jessen; Marcelo HP Chaves; Ítalo Cunha; Wagner Meira Jr; Dorgival Guedes,Abstract. Phishing remains one of the most significant Internet security problems; causingfinancial damage to organizations and users. This type of attack combines socialengineering and other sophisticated techniques with which the attacker attempts to deceivethe victim to steal personal information. Usually; the fight against phishing is done with someof the same techniques used to combat spam; such as those that focus on sets of words andcharacteristic terms. However; there are few studies that specifically address phishing andthere are doubts about the stability and dynamics of message characteristics over time andhow they can be leveraged to improve the system's defenses. In this work; we present anadaptive method to identify phishing messages and apply it on a large data set to identifyand characterize hundreds of phishing campaigns. Resumo. Phishing continua sendo um …,Proc. of Brazilian Symposium on Computer Networks and Distributed Systems (SBRC),2016,1
Planning the communication infrastructure for vehicular networks without tracking vehicles,Cristiano M Silva; Joao FM Sarubbi; Wagner Meira,This work presents a novel algorithm for the deployment of roadside units based on partialmobility information. Instead of relying on the individual vehicles trajectories; our proposalrelies on the migration ratios between urban regions in order to infer the better locations forthe deployment of the roadside units. Our goal is to identify those α locations maximizing thenumber of distinct vehicles experiencing at least one vehicle-to-infrastructure contactopportunity. We compare our strategy to two deployment algorithms: MCP-g relies on fullmobility information (ie; full knowledge of the individual vehicles trajectories); while MCP-kpdoes not assume any mobility information at all (simply places the roadside units at thedensest locations of the road network). The results demonstrate that full knowledge of thevehicles trajectories is not mandatory for achieving a close-to-optimal deployment …,Wireless and Mobile Computing; Networking and Communications (WiMob); 2015 IEEE 11th International Conference on,2015,1
Design of roadside communication infrastructure with QoS guarantees,Cristiano M Silva; Wagner Meira,There are several kinds of envisioned vehicular applications: video delivery; accidentsdetection; dissemination of traffic announcements; and so forth. Such applications demandminimal (and possibly distinct) QoS guarantees that must couple the vehicular network.Given that vehicular networks will soon become reality; we demand strategies for planningand managing such networks. In this work we propose Delta (A); a QoS-based strategy forplanning the roadside infrastructure supporting a vehicular network. Thus; the networkprovider may employ our strategy to design a new network; compare the performance ofdistinct vehicular networks; and even evaluate the adherence between vehicularapplications and the network. Delta is based on two metrics: i) connectivity duration; and ii)percentage of vehicles presenting such connectivity duration. For instance; if a given …,Computers and Communication (ISCC); 2015 IEEE Symposium on,2015,1
PDBest: a user–friendly platform for manipulating and enhancing protein structures,Wellisson RS Gonçalves; Valdete M Gonçalves-Almeida; Aleksander L Arruda; Wagner Meira Jr; Carlos H da Silveira; Douglas EV Pires; Raquel C de Melo-Minardi,Abstract Summary: PDBest (PDB Enhanced Structures Toolkit) is a user-friendly; freelyavailable platform for acquiring; manipulating and normalizing protein structures in a high-throughput and seamless fashion. With an intuitive graphical interface it allows users with noprogramming background to download and manipulate their files. The platform also exportsprotocols; enabling users to easily share PDB searching and filtering criteria; enhancinganalysis reproducibility. Availability and implementation: PDBest installation packages arefreely available for several platforms at http://www. pdbest. dcc. ufmg. br Contact: wellisson@dcc. ufmg. br; dpires@ dcc. ufmg. br; raquelcm@ dcc. ufmg. br Supplementary information:Supplementary data are available at Bioinformatics online.,Bioinformatics,2015,1
Uma Estratégia não Supervisionada para Previsão de Eventos usando Redes Sociais.,Derick M de Oliveira; Roberto CSNP Souza; Denise EF de Brito; Wagner Meira Jr; Gisele L Pappa; Belo Horizonte–MG–Brasil,Resumo. Desde a popularizaçao de mıdias sociais baseadas em texto; vários estudos têmsido conduzidos utilizando dados destas plataformas para prever eventos do mundo real. Aabordagem tradicional é considerar usuários postando em mıdias sociais como sensores eas respectivas mensagens sobre um evento como um indicador da sua ocorrência ouintensidade. Em geral; uma fase de análise de sentimentos é realizada para assinalarmensagens a um conjunto pré-definido de categorias. Neste caso; rotulaçao manual dedados é necessária para treinar um classificador. Entretanto; tal rotulaç ao pode ser muitocustosa; demandar muito tempo e está sujeita a erros humanos. Mais ainda; algumas vezesé difıcil distinguir qual categoria pré-definida é a mais apropriada para uma dadamensagem. Neste sentido; propomos uma metodologia nao supervisionada para prever …,SBBD,2015,1
avaliando o desempenho de redes veiculares heterogêneas,Cristiano M Silva; Andre LL Aquino; Wagner Meira Jr; Belo Horizonte–MG–Brasil; Ouro Branco–MG–Brasil,Abstract. There are several kinds of envisioned vehicular applications. Such applicationsdemand minimal (and possibly distinct) QoS guarantees that must couple the vehicularnetwork. Given that vehicular networks will soon become reality; we demand strategies forplanning and managing such networks. In this work we propose the Delta Network metric.By using the Delta Network we may compare the performance of distinct vehicular networksetups; independently of the access technology. Resumo. Diversos tipos de aplicaçõesveiculares são vislumbradas. Tais aplicações demandam qualidades mínimas (epossivelmente distintas) de serviço que precisam casar com a rede veicular. Dado que asredes veiculares serão uma realidade em breve; existe uma demanda por estratégias queapóiem o planejamento e a gestão dessas redes. Nesse trabalho apresenta-se a métrica …,*,2015,1
A simple and effective method for anomaly detection in healthcare,LF Carvalho; CH Teixeira; Ester C Dias; Wagner Meira Jr; OF Carvalho,Abstract Anomaly detection in public health records is a challenging task that can revealfrauds; errors and other significant events. In this paper we propose a simple; intuitive andgeneric method for anomaly detection based on score transference from consumers toproviders for scenarios in which the analysis of the consumers enables the identification ofanomalous providers or when no data about the providers is available. Our method consistsof two steps: consumers score assignment and score transference to providers. Besidesdiscussing the method details and their implications; we create a modeling in which thecities represent the consumers and hospitals the providers and applied it to a real databaseof the Brazilian public health system. The three distinct types of procedures considered inour analysis earned for the hospitals about 3.5 billion dollars from 2008 to 2012. We also …,4th Workshop on DMMH; 2015 SIAM Int. Conf. on Data Mining; Vancouver; Canada,2015,1
A hadoop extension to process mail folders and its application to a spam dataset,Pedro HB Las-Casas; Vinicius Santos Dias; Renato Ferreira; Wagner Meira; Dorgival Guedes,Even as the web 2.0 grows; e-mail continues to be one of the most used forms ofcommunication in the Internet; being responsible for the generation of huge amounts of data.Spam traffic; for example; accounts for terabytes of data daily. It becomes necessary tocreate tools that are able to process these data efficiently; in large volumes; in order tounderstand their characteristics. Although mail servers are able to receive and storemessages as they arrive; applying complex algorithms to a large set of mailboxes; either forcharacterization; security reasons or for data mining goals is challenging. Big dataprocessing environments such as Hadoop are useful for the analysis of large data sets;although originally designed to handle text files in general. In this paper we present aHadoop extension used to process and analyze large sets of e-mail; organized in …,Computer Architecture and High Performance Computing Workshop (SBAC-PADW); 2014 International Symposium on,2014,1
Watershed reengineering: making streams programmable,Rodrigo Caetano Rocha; Renato Ferreira; Wagner Meira; Dorgival Guedes,Most high-performance data processing (aka big-data) systems allow users to express theircomputation using abstractions (like map-reduce) that simplify the extraction of parallelismfrom applications. Most frameworks; however; do not allow users to specify howcommunication must take place: that element is deeply embedded into the run-time system(RTS); making changes hard to implement. In this work we describe our reengineering of theWatershed system; a framework based on the filter-stream paradigm and focused oncontinuous stream processing. Like other big-data environments; watershed provided object-oriented abstractions to express computation (filters); but the implementation of streams wasan RTS element. By isolating stream functionality into appropriate classes; combination ofcommunication patterns and reuse of common message handling functions (like …,Computer Architecture and High Performance Computing Workshop (SBAC-PADW); 2014 International Symposium on,2014,1
Generating Cohesive Semantic Topics from Latent Factors,Paulo Viana Bicalho; Tiago de Oliveira Cunha; Fernando Henrique Jesus Mourao; Gisele Lobo Pappa; Wagner Meira,Extracting topics from posts in social networks is a challenging and relevant computationaltask. Traditionally; topics are extracted by analyzing syntactic properties in the messages;assuming a high correlation between syntax and semantics. This work proposes SToC; anew method for generating more cohesive and meaningful semantic topics within a context.SToC post-processes the output of a Non-Negative Matrix Factorization (NMF) method inorder to determine which latent factors should be further merged to improve cohesion.Based on NMF's output; SToC defines a topics transition graph and uses Markovian theoryto merge pairs of topics mutually reachable in this graph. Experiments on two real datasample from Twitter demonstrate that is statistically better than fair baselines in supervisedscenarios and able to determine cohesive and semantically valid topics in unsupervised …,Intelligent Systems (BRACIS); 2014 Brazilian Conference on,2014,1
Complete discovery of high-quality patterns in large numerical tensors,Loic Cerf; Wagner Meira,Many datasets are numerical tensors; ie; associate n-tuples with numerical values. Untilrecently; the discovery of relevant local patterns in such numerical and multidimensionaldata has received little attention despite the broad applicative perspectives offered by thisgeneral framework. Even in the simpler 2-dimensional case; almost every proposal so far iseither incomplete (ie; it does not list every pattern) or relies on binning and mines Booleantensors. In both cases; some information is lost during the process. In uncertain tensors; n-tuples satisfy the studied predicate to a certain extent and no information is lost wrt theoriginal data. Given an uncertain tensor; the closed patterns are its maximal “sub-tensors”covering n-tuples that “mostly” satisfy the predicate. Defining “mostly” is the key problem: thepatterns should be both relevant given the data and efficiently extractable. The proposed …,Data Engineering (ICDE); 2014 IEEE 30th International Conference on,2014,1
Probabilistic deployment of dissemination points in urban areas to support vehicular communication,Cristiano M Silva; Andre LL Aquino; Wagner Meira Jr,Abstract This work presents a probabilistic constructive heuristic to support the design ofroadside infrastructure for information dissemination in vehicular networks. We formulate thisas a Probabilistic Maximum Coverage Problem (PMCP) and we intend to maximize thenumber of vehicles that get in contact with the infrastructure. We compare our approach withnon-probabilistic MCP in simulated urban areas following a Manhattan-style topology withvariable traffic conditions. The main contributions of this work are (i) the formal definition ofthe Probabilistic Maximum Coverage Problem;(ii) the application of PMCP to solve oneinstance of the problem of facilities allocation and (iii) the application of a probabilisticapproach to model the volume of vehicles along the urban area; where the position of eachvehicle is no longer considered deterministic; but it is treated as a probability function …,Journal of Applied Computing Research,2014,1
Caracterização Temporal das Redes de Colaboração Científica nas Universidades Brasileiras: Anos 2000-2013,Michel Boaventura; K Bonson; APC Silva; Adriano Veloso; Wagner Meira Jr,*,BRASNAM–III Brazilian Workshop on Social Network Analysiand Mining; CSBC; Brasília,2014,1
A Preliminary Analysis of the Scientific Production of Latin American Computer Science Research Groups.,Juan F Delgado-Garcia; Alberto HF Laender; Wagner Meira Jr,Abstract. In this paper; we present a preliminary analysis of the scientific production of LatinAmerican Computer Science research groups. Our analysis is based on data over a periodof 20 years collected from DBLP; and addresses 24 groups from academic institutions inArgentina; Chile; Colombia; Cuba; Mexico; Peru; Uruguay and Venezuela. Our results showa clear improvement in the publication output of these groups in the last 10 years;particularly in Argentina; Chile and Mexico.,AMW,2014,1
A KDD-based methodology to rank trust in e-commerce systems,José Felipe Junior; Adriano Pereira; Wagner Meira Junior; Adriano Veloso,Abstract Due to the growing popularity of the Web; there is an increasing number of peoplewho perform e-business transactions. On the other hand; this popularity has also attractedthe attention of criminals; raising the number of frauds on the Web and associated financiallosses; which reach billions of dollars per year. This paper proposes a KDD-basedmethodology to detect fraud in e-payment systems. In order to evaluate this methodology wedefined the concept of economic efficiency and applied it to an actual dataset of one of thelargest Latin American electronic payment systems. The results show a very goodperformance; providing gains of up to 46.5% in comparison with the strategy currentlyemployed by the company.,Proceedings of the 2013 IEEE/WIC/ACM International Joint Conferences on Web Intelligence (WI) and Intelligent Agent Technologies (IAT)-Volume 01,2013,1
Uma estratégia baseada em difusão de informação para determinação de conteúdos relevantes e usuários influentes em redes sociais,Hérico Valiati; Arlei Silva; Sara Guimarães; Wagner Meira Jr,Resumo: Redes sociais têm desempenhado um papel muito importante como um meio paraa disseminação de informações e ideias; e exercício da influência de alguns usuários sobreoutros. O problema alvo deste trabalho é determinar quais usuários são influentes e quais osconteúdos relevantes; ou seja; ordenar tanto grupos de usuários quanto o conteúdo por elesdisseminado. Propomos uma nova técnica que se baseia em uma definição intuitiva e circularde relevância e influência. Nós descrevemos a técnica proposta em detalhes; assim como umaimplementação eficiente para a mesma. A fim de validá-la; nós utilizamos técnicas de recomendaçãode usuários e conteúdo. Nós utilizamos duas bases de dados reais do Twitter e os resultadosobtidos mostram que a técnica proposta apresenta ganhos de 37% quando comparada a ummétodo de filtragem colaborativa. Além disso; tanto os usuários influentes quanto os …,Revista de Informática Teórica e Aplicada,2013,1
Caractérisation et extraction de biclusters de valeurs similaires avec l'analyse de concepts triadiques.,Mehdi Kaytoue; Sergei O Kuznetsov; Amedeo Napoli; Juraj Macko; Wagner Meira Jr,Résumé. Le biclustering de données numériques est devenu depuis le début des années2000 une tâche importante d'analyse de données; particulièrement pour l'étude de donnéesbiologiques d'expression de gènes. Un bicluster représente une association forte entre unensemble d'objets et un ensemble d'attributs dans une table de données numériques. Lesbiclusters de valeurs similaires peuvent être vus comme des sous-tables maximales devaleurs proches. Seules quelques méthodes se sont penchées sur une extraction complète(ie non heuristique); exacte et non redondante de tels motifs; qui reste toujours un problèmedifficile; tandis qu'aucun cadre théorique fort ne permet leur caractérisation. Dans le présentarticle; nous introduisons des liens importants avec l'analyse formelle de concepts. Plusparticulièrement; nous montrons de manière originale que l'analyse de concepts …,EGC,2012,1
Positive or negative? Using blogs to assess vehicles features,SS Ribeiro; Zilton Junior; W Meira; Gisele L Pappa,Abstract. Social media has become a valuable source of information to know whatconsumers think about products. In this work; we focus on analyzing opinions on individualproduct's features presented in reviews and blog comments. We describe an adaptation of alexicon-based approach to sort out the problem; propose a new approach based onsupervised learning algorithms. We focus on vehicles; and present as a key finding thegeneralization performance of the models generated in different datasets from the samedomain. Our results show that is possible to achieve better precision and recall usingsupervised learning algorithms that do not require as much human effort as those obtainedby traditional natural language processing approaches.,Encontro Nacional de Inteligência Artificial,2012,1
Assessing documents' credibility with genetic programming,João Palotti; Thiago Salles; Gisele L Pappa; Marcos A Gonçalves; Wagner Meira,The concept of example credibility evaluates how much a classifier can trust an examplewhen building a classification model. It is given by a credibility function; which is applicationdependent and estimated according to a series of factors that influence the credibility of theexamples. Here we deal with automatic document classification and study the credibility of adocument according to three factors: content; authorship and citations. We propose agenetic programming algorithm to estimate the credibility of training examples; and then addthis estimation to a credibility-aware classifier. For that; we model the authorship and citationdata as a complex network; and select a set of structural metrics that can be used to estimatecredibility. These metrics are then merged with other content-related ones; and used asterminals for the GP. The GP was tested in a subset of the ACM-DL; and results showed …,Evolutionary Computation (CEC); 2011 IEEE Congress on,2011,1
Modeling and evaluating credibility of web applications,Sara Guimarães; Adriano Pereira; Arlei Silva; Wagner Meira Jr,Abstract The popularization of the Web has given rise to new services every day; demandingmechanisms to ensure the credibility of these services. In this work we adopt a framework forthe design; implementation and evaluation of credibility models. We call a credibility model afunction capable of assigning a credibility value to a transaction of a Web application;considering different criteria of this service and its supplier. To validate this framework andmodels; we perform experiments using an actual dataset; from which we evaluated differentcredibility models using distinct types of information. The obtained results are very good;showing representative gains; when compared to a baseline and also to a known state-of-the-art approach. The results show that the credibility framework can be used to enforce trustto users of services on the Web.,Proceedings of the 2011 Joint WICOW/AIRWeb Workshop on Web Quality,2011,1
Mining redundant industrial alarm occurrences with association rules extraction and complex networks modeling,Leandro Pfleger de Aguiar; Virgilio AF de Almeida; Wagner Meira Jr,Abstract Alarm management is a research area that is growing rapidly on industrialautomation. One of the major difficulties in alarm rationalization; in which the volume ofgenerated alarms is reduced to an appropriate number so that a human being can handlethem; is to identify patterns that might indicate unnecessary alarms in the middle of files anddatabases containing tens of thousands of daily records. This work presents a newapproach to analyze alarm occurrences; combining several techniques; such as: sequencemining; association rules extraction with MNR (Minimum Non Redundant AssociationRules); cross-correlation analysis; and complex network modeling for visualization. Thecombination of different techniques creates a more comprehensive alternative to thedetection process. The solution's performance; in terms of accuracy; shows improvements …,Journal of Computational Methods in Sciences and Engineering,2011,1
CredibilityRank: A Framework for the Design and Evaluation of Rank-based Credibility Models for Web Applications,Sara Guimaraes; Arlei Silva; Wagner Meira Jr; Adriano Pereira,The popularization of Web has given rise to new services every day; demandingmechanisms to ensure the credibility of these services. Since now; little has been done tomeasure and understand the credibility of this complex Web environment; which itself is amajor research challenge. From the challenges related to the task of assigning a credibilityvalue to an online service in Web 2.0 applications; we propose a framework for the design;implementation and evaluation of credibility models. To validate the framework; we performexperiments using an actual dataset; from which we evaluated different credibility modelsusing distinct types of information sources; and it allows to compare and evaluate thesecredibility models. The results show that the credibility framework is applicable and iscapable of supporting decision making by users of Web services.,Embedded and Ubiquitous Computing (EUC); 2010 IEEE/IFIP 8th International Conference on,2010,1
Análise de Padrões de Propagação no Twitter.,Arlei Lopes da Silva; Fernando Mourão; Lívia Simões; Nathan Mariano; Wagner Meira Jr; Walter Santos,*,SBBD (Posters),2010,1
Mining Twitter for Feelings and Opinions,Marco Túlio C Ribeiro; Adriano Veloso; Wagner Meira Jr; Gisele L Pappa; Letıcia Cherchiglia; Leonardo Vilela Teixeira; Gustavo Brunoro,*,*,2010,1
Selling Practices in Online Fixed-price Marketplaces,Adriano Pereira; Diego Duarte; Wagner Meira Jr; Paulo Goes,In the last decade; there has been an explosion of online commercial activity enabled by theWorld Wide Web (WWW). In Brazil; probably by cultural influence; online auctions are not sopopular; since users prefer fixed-price for online negotiation. This work presents acharacterization and analysis of fixed-price online negotiations. Using actual data from aBrazilian marketplace; we analyze selling practices; considering seller profiles and sellingstrategies. We study and confirm several important hypotheses about selling practices inonline marketplaces; which allow us to state interesting conclusions; such as: the productcategory impacts the seller profile and the selling strategies; and the best selling practicesvary for different products.,Applications and the Internet; 2009. SAINT'09. Ninth Annual International Symposium on,2009,1
The Metric Dilemma: Competence-Conscious Associative Classification,Adriano Veloso; Mohammed Zaki; Wagner Meira Jr; Marcos Gonçalves,Abstract The classification performance of an associative classifier is strongly dependent onthe statistic measure or metric that is used to quantify the strength of the association betweenfeatures and classes (ie; confidence; correlation etc.). Previous studies have shown thatclassifiers produced by different metrics may provide conflicting predictions; and that thebest metric to use is data-dependent and rarely known while designing the classifier. Thisuncertainty concerning the optimal match between metrics and problems is a dilemma; andprevents associative classifiers to achieve their maximal performance. This dilemma is thefocus of this paper. A possible solution to this dilemma is to learn the competence; expertise;or assertiveness of metrics. The basic idea is that each metric has a specific sub-domain forwhich it is most competent (ie; it consistently produces more accurate classifiers than the …,*,2009,1
Blocagem Adaptativa e Flexível para o Pareamento Aproximado de Registros.,Luiz Osvaldo Evangelista; Eli Cortez; Altigran Soares da Silva; Wagner Meira Jr,In data integration tasks; records from a single dataset or from different sources must beoften compared to identify records that represent the same real world entity. The cost of thissearch process for finding duplicate records grows quadratically as the number of recordsavailable in the data sources increases and; for this reason; direct approaches; ascomparing all record pairs; must be avoided. In this context; blocking methods that arebased on machine learning processes are used to find the best blocking function; based onthe combination of low cost rules; which define how to perform the record blocking. Thiswork presents a new blocking method based on machine learning. Different from othermethods; this new approach is based on genetic programming; allowing the use of moreflexible rules and a larger number of such rules for defining blocking functions; leading to …,SBBD,2009,1
Classificação Automática de Documentos Robusta Temporalmente.,Thiago Salles; Leonardo C da Rocha; Gisele L Pappa; Fernando Mourão; Marcos André Gonçalves; Wagner Meira Jr,Abstract. In this work; we present temporally robust technics for Auto matic DocumentClassification (ADC). This robustness is important since; due to language and knowledgedynamics; the characteristics of documents vary over time; causing a negative impact onADC. We defined a temporal adjustment factor and; with it; we derived temporally robustclassifiers ba sed on traditional classification methods (Rocchio and KNN). Experimentalresults; obtained using two real textual datasets point to significant gains up to 11%compared to the traditional versions; and up to 4% compared to SVM (at a significantlysmaller time).,SBBD,2009,1
Sequential medical treatment mining for survival analysis,Arlei Silva; Wagner Meira Jr; Odilon Queiroz; Mariângela Cherchiglia,Abstract. In this paper; we study the problem of evaluating the survival associated withsequential medical treatments. We propose a new data mining algorithm (SMTM) thatcombines the survival analysis framework with the sequence mining task. This research ismotivated by the necessity of assessing the quality of the renal replacement therapies(RRTs); what has become a policy issue in several countries. We apply SMTM to evaluatesequences of RRTs and show that SMTM is computationally efficient and able to provideimportant knowledge about the survival of patients in RRT; better describing the patients'survival pattern than the traditional survival analysis. The results obtained may supportfuture programs and health policies for the assistance of patients in RRT.,*,2009,1
Characterizing on/off pattern of broadband internet users,Emanuel V Valle; Humberto T Marques Neto; Wagner Meira Jr; Virgílio AF Almeida,It is well known that the duration of Internet user's sessions grows with the increase ofbroadband Internet access. Nevertheless; it is still not clear how much their usage increases;that is; whether the user issues requests during the whole session or there are periodsduring which users request nothing. This work presents a characterization of on/off pattern ofbroadband Internet users. We determine the statistical distribution of session on/off time andfound that on-time is fits better to the Weibull distribution and offtime to the Lognormal.Furthermore; we model the on/off pattern with a state transition graph called CBMG(Customer Behavior Model Graph).,Web Conference; 2008. LA-WEB'08.; Latin American,2008,1
Anteater: Service-oriented data mining,Renato A Ferreira; Dorgival O Guedes; Wagner Meira Jr,ABSTRACT Data mining focuses on extracting useful information from large volumes ofdata; and thus has been the centre of great attention in recent years. Building scalable;extensible and easy-to-use data mining systems; however; has proved to be a hard task.This chapter discusses Anteater; a service-oriented architecture for data mining; which relieson Web services to achieve extensibility; offers simple abstractions for users and supportscomputationally intensive processing on large amounts of data. Anteater relies on Anthill; arun-time system for irregular; data intensive; iterative distributed applications; to achievehigh performance. Data mining algorithms are irregular because the computation isirregularly distributed over the input data; which greatly complicates the parallelization. It isdata intensive; for it deals with potentially enormous data sets. And it is iterative as many …,Data Mining Techniques in Grid Computing Environments,2008,1
Caracterizaçao de estratégias de disseminaçao de spams,Pedro H Calais Guerra; D Guedes; Wagner Meira Jr; Cristine Hoepers; Klaus Steding-Jessen,*,*,2008,1
Estratégias de Balanceamento de Carga em Servidores Web Transacionais,Túlio Tavares; George Teodoro; Diego Nogueira; Bruno Coutinho; W Meira; J Guedes,One of the main challenges to the wide use of the Internet is the scalability of the servers;that is; their ability to handle the increasing demand without affecting the quality of theservices provided. Scalability in stateful servers; which comprise e-Commerce and othertransaction-oriented servers; is even more difficult; since it is necessary to keep transactiondata across requests from the same user. One common strategy for achieving scalability is toemploy clustered servers; where the load is distributed among the various servers. However;as a consequence of the workload characteristics and the need of maintaining data coherentamong the servers that compose the cluster; load imbalance arise among servers; reducingthe efficiency of the server as a whole. In this paper; we propose and evaluate a strategy forload balancing in stateful clustered servers that takes into consideration workload …,*,2008,1
Characterization of online auctions: Correlating negotiation patterns and bidding behavior,A Pereira; L Rocha; Fernando Mourao; W Meira; P Goes,Online auctions have become a major electronic commerce channel in terms of revenue;reaching an enormous and very diverse population of participants all over the world.Modeling the factors that drive the dynamics of an auction; that is; the interactions thathappen during its negotiation; is crucial to improve the customer experience for both sellersand buyers. Auction dynamics can be seen as complex and non-isolated interactions; wheresuccessive interactions become a loop-feedback mechanism. In what we call reactivity; theuser behavior affects the auction negotiation and vice-versa. In this work; we develop acharacterization approach for online auctions to capture the reactivity concept. Using thecharacterization; we are able to model both auction negotiation patterns and biddingbehavior and correlate them. Our approach is novel; and the results start to shed light into …,Web Conference; 2007. LA-WEB 2007. Latin American,2007,1
Um sistema de reputação resistente a ataques Sybil para redes overlay,Hélio Almeida; Tiago Macambira; Dorgival Guedes; Virgílio Almeida; Wagner Meira Jr,Resumo. Ataques Sybil sao um problema em redes overlay e peer-to-peer; pois neles umúnico nó pode utilizar várias identidades diferentes em conluio para confundir a rede.Mecanismos de reputaçao usuais nao sao capazes de lidar com esse ataque; uma vez queos votos das identidades em conluio pode facilmente deturpar mecanismos de votaçaotradicionais. Este trabalho apresenta uma extensao a um modelo de reputaç ao baseadoem teoria dos jogos proposto anteriormente; tornando-o capaz de resistir a ataques Sybil.As alteraçoes propostas sao derivadas de análises de comportamentos sociais; utilizando-os para impor restriçoes na polıtica de troca de informaçoes de reputaçao com outros nós.Quando aplicadas; essas novas polıticas permitem que nós participantes de um overlayidentifiquem o tipo de comportamento dos outros participantes (se é oportunista ou nao) …,*,2007,1
Mining structural signatures of proteins,RC Melo12; JS Gomide; PSL Dias; W Meira Jr; MM Santoro,Abstract. Proteins are the most important macromolecules in living systems. It is well knownthat their function is totally dependent on their structure. However; identical structures can beformed by very dissimilar amino acid sequences and little is known about how so differentsequences fold into identical structures and functions. In this work; we propose a clusteringapproach to obtain patterns of amino acid chemical interactions in protein families thatcompose a structural signature for each family.,*,2007,1
Análise e Entendimento de Desempenho com a Ferramenta Antfarm,Rui Pinho; Thiago Teixeira; Yuri Faria; George Teodoro; Túlio Tavares; Dorgival Guedes; Renato Ferreira; Wagner Meira Jr,O projeto e implementação de aplicações paralelizadas escaláveis e eficientes se mantémcomo um desafio; seja pela complexidade das aplicações e dos dados a serem analisados;seja pelas limitações dos paradigmas atuais de programação paralela para aplicações dealta demanda de processamento e comunicação como mineração de dados. O ambienteAnthill; baseado no paradigma filtro-fluxo identificado; tem se mostrado como um ambienteapropriado para paralelização dessas aplicações; permitindo explorar três estratégias deparalelização: dados; tarefas e assincronia. Entretanto; o entendimento e a depuração dedesempenho dessas aplicações pode ser complexo; dada a diversidade de padrões deinteração permitida pelo ambiente Anthill. A ferramenta Antfarm tem por objetivo nãoapenas apresentar o perfil de desempenho da aplicação mas identificar as imerações …,VI Workshop em Sistemas Computacionais de Alto Desempenho,2005,1
Uma arquitetura para controle de privacidade na web,R Pinto; Lucila Ishitani; F Fonseca; F Castro; Wagner Meira Jr; Virgılio Almeida,*,III Salao de Ferramentas-22 Simpósio Brasileiro de Redes de Computadores; Gramado,2004,1
A Scalable Approach for the Distribution of E-commerce Services Based on Application Level Active Networks,Fabrício Benevenuto; Breno Vitorino; Bruno Coutinho; Dorgival Guedes; Wagner Meira Jr,Abstract. In this paper we use the idea of Application Level Active Networks to implement anefficient and easily deployable solution for the distribution of e-commerce services usingcache servers which can hold dynamic content. The resulting system is an application of theALAN concept and framework to a real and complex application (an electronic bookstorethat makes use of dynamic document caching schemes). Our experiments show thatsignificant performance gains can be obtained by e-commerce sites that use this model;improving the scalability of the target service by distributing the load among the dynamiccaches. Results show reductions of server CPU load by up to 64% and improvements ofclient perceived response time of up to 70% under heavy load.,*,2004,1
Incremental Techniques for Mining Dynamic and Distributed Databases,Matthew Eric Otey; Adriano Veloso; Chao Wang; Srinivasan Parthasarathy; Wagner Meira Jr,Abstract Traditional methods for data mining typically make the assumptions that the data iscentralized and static. These assumptions are no longer tenable. Such methods imposeexcessive communication overhead when data is distributed. Also; they wastecomputational and I/O resources when data is dynamic. In this paper we present what webelieve to be the first data mining approach that overcomes all these assumptions. In fact;we consider a broader scenario in which the data is continuously updated and stored atgeographically different locations. This scenario imposes several challenges to data mining;especially those concerning performance and interactivity. Our approach makes use ofparallel and incremental techniques to generate frequent itemsets even in the presence ofdata updates without examining the entire database. It also imposes minimal …,The Third IEEE International Conference on Data Mining (ICDM’03); Melbourne; FL,2003,1
A Software Engineering Process to Specify and Verify E-Commerce Systems.,Mark AJ Song; Adriano CM Pereira; Fernanda Lima; Gustavo Gorgulho; Sérgio Vale Aguiar Campos; Wagner Meira Jr,*,Software Engineering Research and Practice,2003,1
Geraç ao Eficiente de Regras de Associaç ao em Bases de Dados Dinâmicas,A Veloso; Bruno Gusmao Rocha; Wagner Meira Jr; Márcio Bunte de Carvalho,*,Proc. of the Brazilian Computer Society Conference; SBC; Florianópolis; Brazil,2002,1
O Desafio da Universalização de Acesso à Internet: O Projeto do Computador Popular,Dorgival Guedes; Fabrício Konzen; Guilherme Ribeiro; Lamarque Souza; Sérgio Campos; Wagner Meira Jr,Abstract. Universal access to the Internet has been proposed as an efficient strategy tominimize the social divide and to grant access to technological advances and information tounderprivileged classes. However; a major obstacle in this process is the cost of thecomputational platform; both in terms of software and hardware. In this article we present thepopular computer project developed at the DCC-UFMG. The main aspects of the design arepresented; the major technical chalenges faced are discussed and the architecture (bothsoftware and hardware) is described with an emphasis on the development of an efficient;integrated system. Resumo. A universalização do acesso à Internet tem sido apontadacomo uma forma eficaz de diminuir as desigualdades sociais e promover camadas dapopulação que sempre foram discriminadas nos avanços tecnológicos. Entretanto; uma …,Anais do XXI Congresso da Sociedade Brasileira de Computaçao (SBC2001); Seminario Integrado de Software e Hardware (SEMISH),2001,1
Replicação de Dados em Servidores Paralelos de Comércio Eletrônico,A Pereira; Benício Gontijo; Tassini Cançado; Wagner Meira Jr,Comércio eletrônico; a exemplo de outras aplicações da WWW; tem crescido a taxas semprecedentes; resultando em servidores sobrecarregados e que oferecem serviços de máqualidade. No contexto de arquiteturas tradicionais de comércio eletrônico; o custo deconsultas aos servidores de banco de dados é comumente uma das principais causas dadegradação de desempenho dos servidores de comércio eletrônico. Esses custos sãoresultado da complexidade inerente às consultas e da contenção associada à manutençãoda integridade dos dados. Uma estratégia para minimizar o custo de acesso a dados é areplicação destes em outros componentes do servidor de comércio eletrônico. A replicaçãodeve ser coerente com os vários tipos de serviços providos pelo servidor e explorar alocalidade de referência a dados de cada tipo de serviço. Por outro lado; um servidor de …,Anais do I Workshop em Sistemas Computacionais de Alto Desempenho,2000,1
Depurando Desempenho de Aplicações Software DSM com Camival,Edison Ishikawa; Elcio José Pineschi; Wagner Meira Jr; Cláudio Amorim,Abstract-The difficulty of parallel applications to attain reasonable performance leveis hasmotivated the development of performance debugging tools such as Paradyn; StormWatch;and Camival. Although; developers have usually demonstrated tool capabilities on differentkind of applications; often no evaluation of to oi effec: tiveness has been reported from lessespecialized users facing lhe task of developing efficient parallel applications with lhe onlysupport of performance debugging tools. This paper begins to fill this gap. More specifically;we evaluate the effectiveness ofCarnivalto supporl the development of software DSMapplications by programmers having little background on parallel programming andperformance debugging tools. Using Carnival we port four parallel applications toTreadMarks; a well-known software DSM system. Two applications (Raytrace and LU) are …,*,1999,1
Performance Monitoring of Management Systems.,Wagner Meira Jr; José Marcos S Nogueira; Patrícia Aguiar; Christiano Mata Machado,Abstract Telecommunications Management Networks; when deployed in plants of mediumor high complexity; can have highly complex structured and a great number of hardware andsoftware components. In such cases; they are distributed systems with many interactionsbetween the computational processes; where the correct behavior and good performancebecome critical issues in the operation of the telecom plants. In this paper we presentSisMonit; the performance monitoring system of the SIS-Integrated Supervision System. It ischaracterized by high flexibility and multiple functionalities concerning data acquisitionsgranularity and detail level of performance information generated.,LANOMS,1999,1
Performance Analysis of WWW Cache Proxy Hierarchies,Wagner Meira Jr; Erik L S Fonseca; Virgílio AF Almeida; Cristina D Murta,Although caching and the creation of cache server hierarchies has became a popularstrategy for reducing user waiting time and network traffic; there is no recipe for determiningthe best hierarchy configuration given a set of machines and the workload that they have toserve. This paper presents a novel approach for analyzing the performance of cache proxyhierarchies that is based on two metrics: hierarchical hit ratio and cache efficiency. Thisapproach allows users to easily quantify trade-offs among configurations; facilitating thetuning of cache hierarchies. We illustrate our approach by analyzing possible configurationsfor a cache server hierarchy.,Journal of the Brazilian Computer Society,1998,1
Classificaç ao Semˆantica Automatica de Documentos da WWW,Ana Paula Ribeiro; Rodrigo Fonseca; Wagner Meira Jr; Virgılio Almeida,Resumo A cada dia que passa a Internet vem sendo acessada por uma parcela cada vezmaior da populaçao. Esse fato vem reforçar a observaçao de que fatores sócio-culturais egeográficos influenciam fortemente o tráfego de documentos na World Wide Web. Destaforma; a caracterizaçao dos acessosa rede e uma melhor compreensao do comportamentodos usuários sao ferramentas essenciais para quaisquer tarefas de planejamento epesquisa relacionadasa WWW. Um componente importante dessa caracterizaç ao é aclassificaç ao semântica os documentos acessados; ou seja; a divisao dos acessos emcategorias; cada uma associada a um assunto de interesse dos usuários. Este trabalhoapresenta uma proposta para a classificaçao semântica automática de páginas da WorldWide Web. Esta proposta foi aplicada a logs do POP-MG (Ponto de Presença Internet em …,*,1998,1
Parallel Branch-and-Bound: Design and Performance Understanding,Wagner Meira Jr; Annibal Sodero; Andréa Tavares; Márcio Carvalho,Abstract Branch-and-Bound techniques have been successfully used to solve combinatorialoptimization problems. One common approach to improve the effectiveness of thesetechniques is via parallelization. The parallelization of Branch-and-Bound computations;however; is not trivial and programmers may experiente difficulties both in terms ofcorrectness and efficiency of the parallelized applications. In this paper we present anenvironment that helps programmers in developing efficient parallel Branch-and-boundapplications. This environment integrates two tools:(1) Sabor; which aids in designing thoseapplications; and (2) Carnival; which is a performance measurement and analysis tool thathelps the programmer in understanding the performance of those applications. We alsopresent the Carnival user interface and illustrate its usefulness and functionality by …,Proceedings of the VIII Simpósio Brasileiro de Arquitetura de Computadores–Processamento de Alto Desempenho (VIII SBAC-PAD); Recife,1996,1
Performance Measurement and Modeling with the Lost Cycles Toolkit.,Mark E Crovella; Thomas J LeBlanc; Wagner Meira Jr,Abstract: Although there are many situations in which a model of application performance isvaluable; performance modeling of parallel programs is not commonplace; largely becauseof the difficulty of developing accurate models of real applications executing on realmultiprocessors. This paper describes a toolkit for performance tuning and prediction basedon lost cycles analysis. Lost cycles analysis decomposes parallel overheads into meaningfulcategories that are amenable to modeling; and uses a priori knowledge of the sources andcharacteristics of overhead in parallel systems to guide and constrain the modeling process.The Lost Cycles Toolkit automates the process of constructing a performance model for aparallel application by integrating empirical model building techniques from statistics withmeasurement and modeling techniques for parallel programs. We present several …,*,1995,1
SIRNEM: a parallel neural network simulation system,Wagner Meira; Marcio LB Carvalho,Resumen In this article; we present SIRNEM; a system to simulate the behavior of neuralnetworks using a message-passing multicomputer. The problem of designing an efficientinter-neuron communication algorithm is addressed; this algorithm should also enable areliable exchange of information; avoiding unpredictable situations as deadlock andstarvation. A brief description of the main modules of SIRNEM are presented.,Panel'92: actas; XVIII Conferencia Latinoamericana de Informática,1992,1
On the characterization of energy networks of proteins Genet. Mol. Res. 6 (4): 799-820,CJM Veloso; CH Silveira; RC Melo; C Ribeiro; JCD Lopes; MM Santoro; W Meira Jr,*,Genet. Mol. Res,*,1
Finding protein-protein interaction patterns by contact map matching Genet. Mol. Res. 6 (4): 946-963,RC Melo; C Ribeiro; CS Murray; CJM Veloso; CH da Silveira; G Neshich; W Meira Jr; RL Carceroni; MM Santoro,*,Genet. Mol. Res,*,1
Análise do tráfego de spam coletado ao redor do mundo,Pedro Henrique B Las-Casas; Dorgival Guedes; Wagner Meira Jr; Cristine Hoepers; Klaus Steding-Jessen; Marcelo HP Chaves; Osvaldo Fonseca; Elverton Fazzion; Rubens EA Moreira,Abstract. Several efforts have been pursued to create a comprehensive view of spam traffic.However; observations at isolated points of the Internet are always limited by factors ofspatial locality. This work aims to add a dimension to this analysis by contrasting samples ofspam traffic collected simultaneously at different points. Our analyses indicate that factorssuch as location and connectivity have significant impact on the observed traffic; but certainfeatures; such as profiles of messages sent by different protocols; source addresses and testpatterns from spammers repeat themselves around the world. Resumo. Diversos esforçostêm sido feitos para se criar uma visao abrangente do tráfego de spam. Entretanto;observaçoes em pontos isolados da Internet estao sempre limitadas por fatores delocalidade espacial. Este trabalho pretende acrescentar uma dimensao a essa análise …,*,*,1
Caracterizaç ao do Encadeamento de Conexoes para Envio de Spams,Pedro H Calais Guerra; Dorgival Olavo Guedes; Wagner Meira Jr; Cristine Hoepers; Klaus Steding-Jessen; Marcelo HPC Chaves,Abstract. In this work; we show how spammers exploit open proxies on the Brazilian Internetinfrastructure and then chain connections to open relays; bots and other open proxies beforedelivering spams to the recipients. Our conclusion was based on the analysis of HTTPconnections established by spammers to low-interaction honeypots. Although thesebehaviors are known to security specialists; there are no scientific works that identify andmeasure such behaviors. Knowing how spammers chain machines in order to send spamsmay impact the design of reputation-based anti-spam techniques and brings attention to thefact that; although botnets are the most common way to deliver spams nowadays; fightingopen proxies is still a need. Resumo. Neste trabalho; mostramos que spammers exploramproxies abertos na Internet brasileira e; em seguida; encadeiam abusos a relays abertos …,*,*,1
The ParTriCluster Algorithm for Gene Expression Analysis,Renata Araujo Guilherme Ferreira Gustavo Orair; Wagner Meira Jr; Renato Ferreira Dorgival Guedes; Mohammed Zaki,Abstract Analyzing gene expression patterns is becoming a highly relevant task in theBioinformatics area. This analysis makes it possible to determine the behavior patterns ofgenes under various conditions; a fundamental information for treating diseases; amongother applications. A recent advance in this area is the Tricluster algorithm; which is the firstalgorithm capable of determining 3D clusters (genes x samples x timestamps); that is;groups of genes that behave similarly across samples and timestamps. However; whilebiological experiments collect an increasing amount of data to be analyzed and correlated;the triclustering problem is NP-Complete; and its parallelization seems to be an essentialstep towards obtaining feasible solutions. In this work we propose and evaluate theimplementation of a parallel version of the Tricluster algorithm using the filter-labeled …,*,*,1
Mineração Assíncrona de Regras de Associação em Sistemas de Memória Compartilhada-Distribuída,A Veloso; B Coutinho; B Pôssas; G Menezes; W Meira Jr; M Carvalho; C Amorim,Resumo-Encontrar as regras de associação presentes em grandes bases de dados é umimportante problema em Mineração de Dados. Existe uma grande necessidade dedesenvolver algoritmos paralelos para esse problema; uma vez que ele corresponde a umprocesso computacional muito custoso. No entanto; a maioria dos algoritmos propostospara minerar tais regras seguem uma busca iterativa; que imp: íe a necessidade desincronização ao final de cada iteração; degradando o desempenho. Outra deficiênciadesses algoritmos é proveniente da contenção que ocorre no barramento de entrada esaída; uma vez que todos os processadores devem acessar simultaneamente suasrespectivas porcjies da base de dados. Mais ainda; esses algoritmos usam somenteesquemas de balanceamento de carga estático; baseados na decomposição inicial dos …,*,*,1
What surprises does your past have for you?,Fernando Mourão; Leonardo Rocha; Camila Araújo; Wagner Meira Jr; Joseph Konstan,Abstract Although the current Recommender Systems (RSs) focus on discovering unknownitems for users in several domains; users may be particularly interested in consuming itemsin which they are already familiar. As a result; this study aims to uncover subsets of knownitems that are useful for recommendations in the present. The main argument highlighted inthis study is that past consumption is a rich source of relevant recommendations neglectedor underexploited by current RSs. Thus; we propose a methodology to quantify theeffectiveness of recommending known items in real domains. Afterwards; we proposeddistinct heuristics to search the consumption history of each user items unexpected to beconsumed; but potentially relevant. Such heuristics exploit time-related; context-related; andrelevance-related information; as well as a combination of these three types of …,Information Systems,2017,*
Fairness; Accountability; and Transparency while Mining Data from the Web and Social Networks,Wagner Meira Jr,Abstract Digital media have been changing fundamentally our society; as a consequence ofeasier access to contents as well as better and cheaper generation and disseminationthrough the internet; as witnessed by services such as online videos; games and socialnetworks. More recently; there has been an increasing availability of" smart" services that;among other tasks; help users to locate; understand and analyze automatically media ofinterest. Smart services are often based on algorithms from data mining and related areassuch as machine learning and artificial intelligence. Beyond the efficiency and effectivenessof theses services; there is a growing concern about the fairness; accountability andtransparency associated with them; which is the subject of this talk. Fairness comprisesguarantees that algorithms are neither biased nor discriminatory; even when they are …,Proceedings of the 23rd Brazillian Symposium on Multimedia and the Web,2017,*
Efficient Gaussian Process-Based Inference for Modelling Spatio-Temporal Dengue Fever,Julio Albinati; Wagner Meira; Gisele L Pappa; Andrew G Wilson,Dengue fever is a disease that affects hundreds of millions of people every year worldwide.Despite its wide presence around the world; it still requires accurate early warning systems.In this paper; we propose an accurate model to forecast dengue fever incidence at hundredsof Brazilian cities simultaneously. In order to assure efficiency; we devise two strategies toreduce computational effort required for inference under the proposed model. As a result; wenot only reduce the computational effort that would be required to fit each model per city; butalso increase the accuracy by inducing spatial dependences between cities. Thesedependences do not require human specification and are learned from data; leading tomore accurate predictions than using typical neighborhood or distance-based methods.,Intelligent Systems (BRACIS); 2017 Brazilian Conference on,2017,*
Experimental Evaluation of Crowdsourcing on the Characterization of Data Visualization Techniques,Geraldo Ribeiro Franciscani; Rodrygo Santos; Michel Boaventura; Pedro Dalla Bernardina; Wagner Meira; Raquel Cardoso de Melo Minardi,*,2017 Brazilian Conference on Intelligent Systems (BRACIS),2017,*
A Two-Stage Machine learning approach for temporally-robust text classification,Thiago Salles; Leonardo Rocha; Fernando Mourão; Marcos Gonçalves; Felipe Viegas; Wagner Meira Jr,Abstract One of the most relevant research topics in Information Retrieval is AutomaticDocument Classification (ADC). Several ADC algorithms have been proposed in theliterature. However; the majority of these algorithms assume that the underlying datadistribution does not change over time. Previous work has demonstrated evidence of thenegative impact of three main temporal effects in representative datasets textual datasets;reflected by variations observed over time in the class distribution; in the pairwise classsimilarities and in the relationships between terms and classes [1]. In order to minimize theimpact of temporal effects in ADC algorithms; we have previously introduced the notion of atemporal weighting function (TWF); which reflects the varying nature of textual datasets. Wehave also proposed a procedure to derive the TWF's expression and parameters …,Information Systems,2017,*
Provider-Consumer Anomaly Detection for Healthcare Systems,Luiz FM Carvalho; Carlos HC Teixeira; Wagner Meira; Martin Ester; Osvaldo Carvalho; Maria Helena Brandao,Anomaly detection is an important task that has been widely applied to different scenarios. Inparticular; its application in public healthcare is a crucial management task that can improvethe quality of the health services and avoid loss of huge amounts of money. In this work wepropose and evaluate; in a real scenario; a method for anomaly detection in healthcarebased on a provider-consumer model. Our method is divided into two phases. In the firstphase it assigns anomaly scores to the cities (consumers) as a function of their demand;then; in the second phase; it transfers the scores from cities to hospitals (providers). Weapplied the method to a real database from the Brazilian public healthcare that recordsmedical procedures which cost more than $8.5 billion from 2008 to 2012; and demonstratedour method's ability to find potentially fraudulent hospitals. The method is being adopted …,Healthcare Informatics (ICHI); 2017 IEEE International Conference on,2017,*
Enhancement of Epidemiological Models for Dengue Fever Based on Twitter Data,Julio Albinati; Wagner Meira Jr; Gisele L Pappa; Mauro Teixeira; Cecilia Marques-Toledo,Abstract Epidemiological early warning systems for dengue fever rely on up-to-dateepidemiological data to forecast future incidence. However; epidemiological data typicallyrequires time to be available; due to the application of time-consuming laboratorial tests.This implies that epidemiological models need to issue predictions with larger antecedence;making their task even more difficult. On the other hand; online platforms; such as Twitter orGoogle; allow us to obtain samples of users' interaction in near real-time and can be used assensors to monitor current incidence. In this work; we propose a framework to exploit onlinedata sources to mitigate the lack of up-to-date epidemiological data by obtaining estimatesof current incidence; which are then explored by traditional epidemiological models. Weshow that the proposed framework obtains more accurate predictions than alternative …,Proceedings of the 2017 International Conference on Digital Health,2017,*
Detecção de Spams Utilizando ConteúdoWeb Associado a Mensagens,Marco Ribeiro; Leonardo Teixeira; Pedro Guerra; Adriano Veloso; Wagner Meira Jr; Dorgival Guedes; Cristine Hoepers; Klaus Steding-Jessen; Marcelo Chaves,Resumo Neste trabalho propomos uma estratégia de detecção de spams que explora oconteúdo das páginas Web para as quais mensagens apontam. Descrevemos umametodologia para a coleta dessas páginas; caracterizamos a relação entre as páginas e asmensagens de spam e; em seguida; utilizamos um algoritmo de aprendizado de máquinapara extrair as informações relevantes para a detecção de spam. Mostramos que autilização de informações das páginas mencionadas melhora significativamente aclassificação de spams e hams; gerando um baixo índice de falsos positivos. Nosso estudorevela que as páginas apontadas pelos spams ainda são um campo de batalha nãoexplorado pelos filtros; onde os spammers não se preocupam em esconder a suaidentidade.,Revista Brasileira de Redes de Computadores e Sistemas Distribuídos,2017,*
Performance evaluation of GPU parallelization; space‐time adaptive algorithms and their combination for simulating cardiac electrophysiology,Rafael S Oliveira; Bernardo M Rocha; Denise Burgarelli; Wagner Meira Jr; Christakis Constantinides; Rodrigo Weber dos Santos,Summary The use of computer models as a tool for the study and understanding of thecomplex phenomena of cardiac electrophysiology has attained increased importancenowadays. At the same time; the increased complexity of the biophysical processestranslates into complex computational and mathematical models. In order to speed upcardiac simulations and to allow more precise and realistic uses; two different techniqueshave been traditionally exploited: parallel computing and sophisticated numerical methods.In this work; we combine a modern parallel computing technique based on multicore andgraphics processing units (GPUs); and a sophisticated numerical method based on a newspace-time adaptive algorithm. We evaluate each technique alone and in differentcombinations: multicore and GPU; multicore and GPU and space adaptivity; multicore …,International journal for numerical methods in biomedical engineering,2017,*
Portinari: a data exploration tool to personalize cervical cancer screening,Sagar Sen; Manoel Horta Ribeiro; Racquel C De Melo Minardi; Wagner Meira; Mari Nygård,Socio-technical systems play an important role in public health screening programs toprevent cancer. Cervical cancer incidence has significantly decreased in countries thatdeveloped systems for organized screening engaging medical practitioners; laboratoriesand patients. The system automatically identifies individuals at risk of developing thedisease and invites them for a screening exam or a follow-up exam conducted by medicalprofessionals. A triage algorithm in the system aims to reduce unnecessary screeningexams for individuals at low-risk while detecting and treating individuals at high-risk. Despitethe general success of screening; the triage algorithm is a one-sizefits all approach that isnot personalized to a patient. This can easily be observed in historical data from screeningexams. Often patients rely on personal factors to determine that they are either at high risk …,Software Engineering: Software Engineering in Society Track (ICSE-SEIS); 2017 IEEE/ACM 39th International Conference on,2017,*
Lemonade: A scalable and efficient Spark-based platform for data analytics,Walter dos Santos; Luiz FM Carvalho; Gustavo de P Avelar; Átila Silva Jr; Lucas M Ponce; Dorgival Guedes; Wagner Meira Jr,Abstract Data Analytics is a concept related to pattern and relevant knowledge discoveryfrom large amounts of data. In general; the task is complex and demands knowledge in veryspecific areas; such as massive data processing and parallel programming languages.However; analysts are usually not versed in Computer Science; but in the original datadomain. In order to support them in such analysis; we present Lemonade---Live Explorationand Mining Of a Non-trivial Amount of Data from Everywhere---a platform for visual creationand execution of data analysis workflows. Lemonade encapsulates storage and dataprocessing environment details; providing higher-level abstractions for data source accessand algorithms coding. The goal is to enable batch and interactive execution of dataanalysis tasks; from basic ETL to complex data mining algorithms; in parallel; in a …,Proceedings of the 17th IEEE/ACM International Symposium on Cluster; Cloud and Grid Computing,2017,*
Antagonism also Flows through Retweets: The Impact of Out-of-Context Quotes in Opinion Polarization Analysis,Pedro Calais Guerra; Roberto CSNP Souza; Renato M Assunção; Wagner Meira Jr,Abstract In this paper; we study the implications of the commonplace assumption that mostsocial media studies make with respect to the nature of message shares (such as retweets)as a predominantly positive interaction. By analyzing two large longitudinal Brazilian Twitterdatasets containing 5 years of conversations on two polarizing topics-Politics and Sports-weempirically demonstrate that groups holding antagonistic views can actually retweet eachother more often than they retweet other groups. We show that assuming retweets asendorsement interactions can lead to misleading conclusions with respect to the level ofantagonism among social communities; and that this apparent paradox is explained in partby the use of retweets to quote the original content creator out of the message's originaltemporal context; for humor and criticism purposes. As a consequence; messages …,arXiv preprint arXiv:1703.03895,2017,*
COPPER-A Web-based platform for Characterization and Outlining of Popular Participation for Enhancing Regulation,Adriano Pereira; Wagner Meira Jr; Israel Guerra; Michel Boaventura; João Victor; Geraldo Franciscani Bárbara; Matheus Gonçalves; Pedro Nascimento; Diogo Cortiz Newton Calegari; Vagner Diniz,ABSTRACT The growth and popularization of the Web has enabled several solutions ofwhat has called e-democracy or cyberdemocracy. The most frequent manifestations ofcyberdemocracy occur in the interaction between the political system and citizens; inparticular mechanisms such as direct participation and debates; which tend to facilitate andamplify citizen participation in view of the direct interaction that facilitates and the removal ofGeographical limits for participation. This work presents the proposal; implementation andevaluation of an analytical intelligence platform for the social participation process; whichcontemplates all the traditional steps of the process of knowledge discovery in databases.The tool was validated using actual data from a public consultation about Personal DataProtection.,*,2017,*
DynWebStats: A Framework for Determining Dynamic and Up-to-date Web Indicators,Israel Guerra; Wagner Meira Jr; Adriano César Machado Pereira; Diogo Marques Santa; Vagner Diniz; Heitor Ganzeli; Marcelo Pitta; Alexandre Barbosa,Abstract It has been broadly discussed over the last years about the growth and popularity ofthe Internet and; more specifically; about the World Wide Web and its services andapplications. Despite being common sense; acquiring indicators about this growth andcharacteristics of the whole Web; or event parts of it; is a big challenge; which can beexplained by some factors:(1) the constant and dynamical evolution of the Web in manydimensions; that is; any analysis becomes obsolete instantly as soon as it's ready;(2) thegreat volume of data that is necessary to generate indicators; which is usually disruptive interms of bandwidth and storage. There are also problems related to ethics and networkviability of the crawl; and (3) the coverage and newness to generate indicators; whetherindicators about domains or Web pages. This paper presents a new methodology for …,Proceedings of the 22nd Brazilian Symposium on Multimedia and the Web,2016,*
Dynamic Reconfiguration of Data Parallel Programs,Vinícius Dias; Wagner Meira; Dorgival Guedes,Given the large amount of data from different sources that have become available toresearchers in multiple fields; Data Science has emerged as a new paradigm for exploringand getting value from that data. In that context; new parallel processing environments withabstract programming interfaces; like Spark; were proposed to try to simplify thedevelopment of distributed programs. Although such solutions have become widely used;achieving the best performance with them is still not always straight-forward; despite themultiple run-time strategies they use. In this work we analyze some of the causes ofperformance degradation in such systems and; based on that analysis; we propose a tool toimprove performance by dynamically adjusting data partitioning and parallelism degree inrecurrent applications based on previous executions. Our results applying that …,Computer Architecture and High Performance Computing (SBAC-PAD); 2016 28th International Symposium on,2016,*
Complexity-Aware Assignment of Latent Values in Discriminative Models for Accurate Gesture Recognition,Manoel Horta Ribeiro; Bruno Teixeira; Antônio Otávio Fernandes; Wagner Meira; Erickson R Nascimento,Many of the state-of-the-art algorithms for gesture recognition are based on ConditionalRandom Fields (CRFs). Successful approaches; such as the Latent-Dynamic CRFs; extendthe CRF by incorporating latent variables; whose values are mapped to the values of thelabels. In this paper we propose a novel methodology to set the latent values according tothe gesture complexity. We use an heuristic that iterates through the samples associatedwith each label value; estimating their complexity. We then use it to assign the latent valuesto the label values. We evaluate our method on the task of recognizing human gestures fromvideo streams. The experiments were performed in binary datasets; generated by groupingdifferent labels. Our results demonstrate that our approach outperforms the arbitrary one inmany cases; increasing the accuracy by up to 10%.,Graphics; Patterns and Images (SIBGRAPI); 2016 29th SIBGRAPI Conference on,2016,*
InfoSAS: um sistema de mineração de dados para controle da produção do SUS,Osvaldo Carvalho; Wagner Meira Jr; Marcos Prates; Renato Assunção; Raquel Minardi; José Nagib Cotrim Árabe,Osvaldo Carvalho has a PhD in Computer Science from the Pierre et Marie Curie University;France; and is an associate professor at the Federal University of the State of Minas Gerais(UFMG). He worked with distributed algorithms and currently teaches Computer Programingand develops information systems … Wagner Meira Jr. has a PhD from the University of Rochesterand is a Computer Science professor at the Federal University of the State of Minas Gerais(UFMG). His areas of interest are data mining; parallel and distributed systems and theirapplications … Marcos Prates has a BA in Computational Mathematics from the Federal Universityof the State of Minas Gerais (UFMG); an MA in Statistics from the same institution and a PhDin Statistics from the University of Connecticut. He develops statistic methods and algorithmsfor the analysis of spatial statistics and machine learning … Raquel Minardi has a BA in …,Revista do TCU,2016,*
Efficient Remapping of Internet Routing Events,Elverton Fazzion; Ítalo Cunha; Dorgival Guedes; Wagner Meira Jr; Renata Teixeira; Darryl Veitch; Christophe Diot,Abstract Routing events impact multiple paths in the Internet; but current active topologymapping techniques monitor paths independently. Detecting a routing event on one Internetpath does not trigger any measurements on other possibly-impacted paths. This approachleads to outdated and inconsistent routing information. We characterize routing events in theInternet and investigate probing strategies to efficiently identify paths impacted by a routingevent. Our results indicate that targeted probing can help us quickly remap routing eventsand maintain more up-to-date and consistent topology maps.,Proceedings of the 2016 ACM SIGCOMM Conference,2016,*
Measuring; Characterizing; and Avoiding Spam Traffic Costs,Osvaldo Fonseca; Elverton Fazzion; Italo Cunha; Pedro Henrique Bragioni Las-Casas; Dorgival Guedes; Wagner Meira; Cristine Hoepers; Klaus Steding-Jessen; Marcelo HP Chaves,Spam messages propagate malware; disseminate phishing exploits; and advertise illegalproducts. Those messages generate costs for users and network operators; but it's difficult tomeasure the costs associated with spam traffic and determine who actually pays for it. Here;the authors provide a method to quantify the transit costs of spam traffic; identifying theroutes traversed by spam messages collected at five honeypots. Combining the volume ofspam traffic with traceroute measurements and a database of internetwork businessrelationships; they show that stub networks are systematically subject to high spam trafficcosts. They also show that some networks profit from spam traffic and might not be interestedin filtering it. Finally; a simple-but-effective algorithm is presented to identify the networks thatwould benefit from cooperating to filter spam traffic at the origin; to reduce transit costs.,IEEE Internet Computing,2016,*
Discriminative Training of Structured Dictionaries via Block Orthogonal Matching Pursuit,Wenling Shang; Kihyuk Sohn; Honglak Lee; Anna Gilbert,Abstract It is well established that high-level representations learned via sparse coding areeffective for many machine learning applications such as denoising and classification. Inaddition to being reconstructive; sparse representations that are discriminative and invariantcan further help with such applications. In order to achieve these desired properties; thispaper proposes a new framework that discriminatively trains structured dictionaries via blockorthogonal matching pursuit. Specifically; the dictionary atoms are assumed to be organizedinto blocks. Distinct classes correspond to distinct blocks of dictionary atoms; however; ouralgorithm can handle the case where multiple classes share blocks. We provide theoreticaljustification and empirical evaluation of our method.,*,2016,*
Multi-Domain Manifold Learning for Drug-Target Interaction Prediction,Ruichu Cai; Zhenjie Zhang; Srinivasan Parthasarathy; Anthony KH Tung; Zhifeng Hao; Wen Zhang,Abstract Drug-target interaction (DTI) provides novel insights about the genomic drugdiscovery; and is a critical technique to drug discovery. Recently; researchers try toincorporate different information about drugs and targets for prediction. However; theheterogeneous and high-dimensional data poses huge challenge to existing machinelearning methods. In the last few years; extensive research efforts have been devoted to theutilization of manifold property on high dimensional data; eg dimension reduction methodspreserving local structures of the manifolds. Motivated by the successes of these studies; wepropose a general framework incorporating both manifold structures and knowninteraction/non-interaction information to predict the drug-target interactions. To overcomethe challenges of domain scaling and information inconsistency; we formulate the …,*,2016,*
SpamBands: a Methodology to Identify Sources of Spam Acting in Concert,Elverton Fazzion; Osvaldo Fonseca; Pedro Henrique B Las Casas; Dorgival Guedes; Wagner Meira Jr; Cristine Hoepers; Klaus Steding Jessen; Marcelo HP Chaves,In 2012; estimates indicated that 68.8% of all e-mail traffic was spam; what suggests this isstill a relevant problem. Recently; some works have focused on the analysis of spam's trafficinside the network; analyzing the protocols used and the AS which originate the traffic.However; those works usually do not consider the relationships between the machines usedto send spam. Such an analysis could reveal how different machines may be used by asingle spammer to spread his messages; helping us to understand their behavior. To thatend; this work proposes a methodology to cluster the machines used by spammers basedon the concept of spam campaigns. The groups identified were characterized to identifydifferent aspects of the spam dissemination process; which suggest different orchestrationstrategies being used.,IEEE Latin America Transactions,2016,*
Faster: a low overhead framework for massive data analysis,Matheus C Santos; Wagner Meira; Dorgival Guedes; Virgílio F Almeida,With the recent accelerated increase in the amount of social data available in the Internet;several big data distributed processing frameworks have been proposed and implemented.Hadoop has been used widely to process all kinds of data; not only from social media. Sparkis gaining popularity for offering a more flexible; object-functional; programming interface;and also by improving performance in many cases. However; not all data analysisalgorithms perform well on Hadoop or Spark. For instance; graph algorithms tend togenerate large amounts of messages between processing elements; which may result inpoor performance even in Spark. We introduce Faster; a low latency distributed processingframework; designed to explore data locality to reduce processing costs in such algorithms.It offers an API similar to Spark; but with a slightly different execution model and new …,Cluster; Cloud and Grid Computing (CCGrid); 2016 16th IEEE/ACM International Symposium on,2016,*
Vehicular Communications,Cristiano M Silva; Fabricio A Silva; João FM Sarubbi; Thiago R Oliveira; Wagner Meira Jr; Jose Marcos S Nogueira,Cristiano M. Silva a;∗ ; Fabricio A. Silva b; João FM Sarubbic; Thiago R. Oliveira a; Wagner MeiraJr. d; Jose Marcos S. Nogueira d … Article history: Received 16 June 2016 Received in revisedform 7 November 2016 Accepted 11 November 2016 Available online 16 November 2016 …Keywords: Vehicle-to-roadside communication Communication architecture Content delivery… Content delivery is a key functionality for developing the Internet of Vehicles. In suchnetworks; vehicles act as sensors of the urban mobility by constantly exchanging messages withanother vehicles; the cellular network; and also the infrastructure (roadside units). However;the task of delivering content in such dynamic network is far from trivial. In this work; we investigatethe development of Content Delivery Networks (CDN) in the context of vehicular networks. Roadsideunits support the communication by replicating and delivering contents to vehicles within …,*,2016,*
A Spam Traffic Cost Analysis for Network Operators,Osvaldo Fonseca; Elverton Fazzion; Ítalo Cunha; Pedro Las-Casas; Dorgival Guedes; Wagner Meira; Cristine Hoepers; Klaus Steding-Jessen; Marcelo HPC Chaves,Spam messages are used to disseminate malware; make phishing attacks; and advertiseillegal products. Spam generates costs to users; eg; victims of phishing; and to networkadministrators; eg; who provision and pay for the traffic. Recent proposals aim to identify andfilter spam messages at the origin; restraining message propagation and reducing wastedbandwidth on the route from the spammer to the destination. In this work we analyze spamtraffic costs for network operators. We measure the routes traversed by real spam messagescolected at five honeypots; and estimate spam traffic costs according to the businessrelationships between networks traversed on each route. We show that stub networks aresystematically encumbered by high spam traffic costs but can cooperate to filter up to 70% ofspam messages at the origin. Our results also indicate that transit networks that send a lot …,Computer Networks and Distributed Systems (SBRC); 2015 XXXIII Brazilian Symposium on,2015,*
Data Mining: Cause or Consequence.,Wagner Meira Jr,Abstract. Data mining arose as a merge of several areas such as databases; statistics andartificial intelligence; and has been growing steadily in the last 20 years. Recently; thepopularization of the concepts of Data Science and Big Data accelerated the process. In thisseminar we try to answer the question whether data mining is cause or consequence ofthese recent developments through an integrated view of four key components of datamining research and development; nominally models; algorithms; systems and applications;and how they are employed in scenarios such as internet and web. We will also discusssome trends related to knowledge and information discovery from massive data.,AMW,2015,*
Sentiment Analysis for Streams of Web Data: A Case Study of Brazilian Financial Markets,Bruna Neuenschwander; Adriano Pereira; Wagner Meira Jr; Denilson Barbosa,Abstract With the rise of Web 2.0 applications; most people started consuming informationand sharing opinions and ideas about most aspects of their lives on a variety of social mediaplatforms; creating massive and continuous streams of valuable data. While this opened thedoor for information extraction and mining techniques that can help us understand differentaspects of society; extracting useful information from such streams of Web data is far fromtrivial. In this setting; sentiment analysis techniques can be convenient as they are capableof summarizing general feeling about entities people care about; such as products andcompanies. Therefore; they can be quite applicable in scenarios like the stock market; whichalso has tremendous impact on society. This paper describes and evaluates two differenttechniques for sentiment analysis applied to the Brazilian stock market data: lexicon …,Proceedings of the 20th Brazilian Symposium on Multimedia and the Web,2014,*
Neighborhoods or condominiums: an analysis of the origin of spam based on the organization of autonomous systems,Osvaldo Fonseca; Pedro Las-Casas; Elverton Fazzion; Dorgival Guedes; Wagner Meira; Cristine Hoepers; Klaus Steding-Jessen; Marcelo HP Chaves,Despite the continuous efforts to mitigate spam; the volume of messages is huge andidentifying spammers is still a challenge. Spam traffic analysis has been performed todetermine the behavior of spammers; who are employing techniques more and moresophisticated to disseminate messages. This work analyzes the sources of spam towardsunderstanding to what extent they explain the traffic. Our results show that; beyond a similarbehavior among machines from the same autonomous system (AS); it is possible toseparate them according to their sending characteristics. Further; the results also show thatwe may apply the concept of Internet BadNeighborhoods to ASes; once the machines from agiven AS behave similarly.,Computer Networks and Distributed Systems (SBRC); 2014 Brazilian Symposium on,2014,*
Someato: characterizing and exploiting behavior and interests of users in social media,Camila Araújo; Fernando Mourão; Wagner Meira Jr,ABSTRACT Characterizing and understanding behavior and interests of social mediamembers is crucial for enhancing several practical applications in this environment; such astarget marketing or recommendation. Aiming to characterize and exploit such behavior andinterests; this work proposes Someato; a novel online analytics tool. Besides acharacterization methodology; Someato comprises a search and a recommender system. Itsmain goal is to discover information and people that each member potentially wants to findwithin a social media. A preliminary usage on a real social community evinces Someato'sanalytics capability and intuitive scientific visualization over log data from social media.,*,2014,*
Measuring; Characterizing; and Avoiding Spam Traffic Costs,Dorgival Guedes Casas; Wagner Meira Jr; Cristine Hoepers; Klaus Steding-Jessen; Marcelo HP Chaves,Spam messages accounted for 90 per-cent of all email messages and generatedapproximately 216 Tbytes of traffic per day in 2013. 1 The war against spammers is foughton multiple fronts. Recently; several proposals have focused on filtering spam at its origin; toprevent spam messages from reaching the destination and reduce network bandwidthconsumption. 2; 3 However; in practice; spam is usually treated only at the destination emailserver; by filtering content just before it's delivered to the end user. Although the volume oftraffic created by spam might be small when compared with other sources; such asstreaming video; spam is still an important problem for network administrators. 4 Anautonomous system (AS) in the Internet is an entity registered with Internet resourceallocation authorities. Each AS operates its own network; with end hosts; routers; and …,work,2013,*
Constraint-Based Search of Different Kinds of Discriminative Patterns,Loıc Cerf; Joao Foscarini; Israel Guerra; Michel Boaventura; Wagner Meira Jr,Abstract The state-of-the-art DATA-PEELER algorithm extracts closed patterns in n-aryrelations. Because it refines both a lower and an upper bound of the pattern space; DATA-PEELER can; in some circumstances; guarantee that a region of that space does not containany closed n-set satisfying some relevance constraint. Whenever it happens; such a regionis left unexplored and computation saved. This paper shows that some constraints; whichDATA-PEELER can efficiently enforce; define useful patterns in the context of a relation withgroups of elements in arbitrary dimensions. For instance; it can list the so-called straddlingbiclusters; which cover at least some given portions of every group. It can discover; as well;closed n-sets that discriminate a group from the others; which are the focus of theexperimental section. It shows that DATA-PEELER is highly competitive despite its …,ratio,2013,*
FPCluster: An Efficient Out-of-core Clustering Strategy without a Similarity Metric,Douglas EV Pires; Luam C Totti; Rubens EA Moreira; Elverton C Fazzion; Osvaldo LHM Fonseca; Wagner Meira Jr; Raquel C de Melo-Minardi; Dorgival Guedes Neto,Abstract Clustering is one of the most popular and relevant data mining tasks. Twochallenges for determining clusters arethe volume of data to be grouped and the difficulty indefining a similarity metric applicable to the entire data set. In this work we presentFPCluster; a new clustering algorithm that addresses both problems. The algorithm is basedon building out-of-core frequent pattern trees; a data structure originally proposed for miningpatterns. Additionally; the algorithm transparently handles missing features; a commonconstraint in real case scenarios. We applied FPCluster to two real scenarios:characterization of spam campaigns and clustering of protein families. We evaluated boththe quality of the obtained groups and the computational efficiency of the proposed strategy.In particular; we achieved precision above 90% while the storage demand increased sub …,Journal of Information and Data Management,2012,*
New evolutionary approaches to high-dimensional data,Luis Matoso; Felipe Junior; Adriano Pereira; Adriano Veloso; Wagner Meira Jr,Abstract High-dimensional data often threatens the performance of classification algorithms.We propose a two-step approach for dealing with high-dimensional data. In the first step;features are arranged into bins; where each bin corresponds to a much smaller sub-space offeatures. In the second step; classifiers are independently applied to the set of featureswithin each sub-space; and their results are then aggregated. We consider slicing a spaceRd into smaller subspaces as a multi-objective search problem; which can be solved byevolutionary algorithms. We performed a systematic evaluation using three classificationalgorithms on high-dimensional data.,Proceedings of the 14th annual conference companion on Genetic and evolutionary computation,2012,*
Special Issue on Computer Architecture and High-Performance Computing,Wagner Meira; Ricardo Bianchini,This special issue of International Journal of Parallel Programming features extendedversions of the best papers from SBAC-PAD 2009; the 21st International Symposium onComputer Architecture and High-Performance Computing. The symposium took place inSão Paulo; Brazil; between October 28th and 31st; 2009. SBAC-PAD has established areputation for high quality and has become a main event for the computer architecture andhigh-performance computing communities. SBAC-PAD 2009 was no exception; with anexcellent technical program. The topics covered a wide variety of areas; including parallelapplications and algorithms; scheduling; graphical processing units; and multi-corearchitectures. SBAC-PAD 2009 attracted 60 complete submissions; each of which wassubmitted to one of four tracks: Computer Architecture; Applications and Algorithms …,*,2012,*
Redes sociais na saúde: conectando os mundos real e virtual na investigação da obesidade,PPV Brum; KB Enes; DEF de Britto; TO Cunha; W Meira Jr; GL Pappa,Resumo. Redes sociais online são grandes fontes de extração de dados sobre os maisdiversos assuntos. É de particular interesse a obtenção de informações relevantes naprevisão de eventos do mundo real; incluindo assuntos relacionados à saúde dapopulação. A obesidade é uma questão de saúde pública e afeta cerca de um terço dapopulação mundial. Nesse sentido; é importante analisar como os dados de redes sociaispodem se relacionar com os indicadores de obesidade do mundo real. Por essa razão;esse trabalho apresenta um estudo comparativo entre os indicadores de obesidade dacomunidade loseit (Lose the fat) do Reddit e os indicadores de um estudo americano sobresaúde pública; o BRFSS. Os resultados obtidos mostram que a comunidade é composta emsua maioria por mulheres com menos de 30 anos. Ao final do intervalo de tempo …,*,2012,*
Min-Hash Fingerprints for Graph Kernels: A Trade-o among Accuracy; E ciency; and Compression,Carlos HC Teixeira; Arlei Silva; Wagner Meira Jr,Abstract. Graph databases that emerge from several relevant scenarios (eg; social networks;the Web) require powerful data management algorithms and techniques. A fundamentaloperation in graph data management is computing the similarity between two graphs.However; due to the large scale and high dimensionality of real graph databases; computinggraph similarity becomes a challenging problem in real settings. Many graph datamanagement tasks; such as graph mining; classification; and retrieval; can becontextualized in the framework of graph kernels. A graph kernel is; roughly speaking; afunction that computes the similarity between graph structures as means to enable theapplication of linear methods to graph data. Nevertheless; large databases usually requirethe use of compact representations of graphs known as graph fingerprints (or signatures) …,*,2012,*
Um sistema de alarme para vigilância epidemiológica de rumores utilizando redes sociais,Denise Brito; Janaina Gomide; Walter Santos; Wagner Meira Jr; Adriano Veloso; Virgilio Almeida,Resumo. As redes sociais online fazem parte do cotidiano de milhões de pessoas domundo inteiro. Cada vez mais pessoas utilizam essas redes para interagir; opinar ecompartilhar conteúdos sobre os mais diversos tópicos; como diversão; clima; trabalho;família; trânsito e mesmo sua condição de saúde. Em suma; as redes sociais se tornarammais um lugar social com significados próprios; evoluindo dinamicamente. Muitosacontecimentos são tardiamente percebidos e divulgados pelos meios de comunicaçãotradicionais; mas podem acontecer nas redes sociais em tempo real; sendo passíveis deserem detectados e de subsidiarem a construção de modelos de previsão. O objetivo destetrabalho é explorar conteúdo disponível nas redes sociais para detectar a ocorrência eprever surtos epidemiológicos; em particular de dengue. A partir da coleta e …,*,2012,*
Descoberta de n-conjuntos Fechados Eficiente e Restrita a Grupos de Interesse.,Israel Guerra; Loïc Cerf; João Foscarini; Michel Boaventura; Wagner Meira Jr,Abstract. The state-of-the-art Data-Peeler algorithm extracts closed patterns in n-aryrelations. Because it refines a lower bound and an upper bound of the pattern space; Data-Peeler can; in some circumstances; guarantee that a region of the pattern space does notcontain any closed n-set satisfying some relevance constraint. If it is so; this region is leftunexplored and some time is saved. Not all constraints enable such a pruning of the patternspace but both the monotone and the anti-monotone constraints do. This paper shows that aminimal (resp. maximal) cover of some arbitrary groups of elements is anti-monotone (resp.monotone). As a consequence; Data-Peeler can prune the search space with thoseconstraints and efficiently discover many different patterns. For instance; it can list the so-called straddling biclusters; which cover at least some given portions of every group. It …,SBBD (Short Papers),2012,*
Credibility of web applications,Sara Guimarães; Adriano Pereira; Arlei Silva; Wagner Meira Jr,Abstract The popularization of Web has given rise to new services every day; demandingmechanisms to ensure the credibility of these services. Since now; little has been done tomeasure and understand the credibility of this complex Web environment; which itself is amajor research challenge. From the challenges related to the task of assigning a credibilityvalue to an online service in Web 2.0 applications; we propose a framework for the design;implementation and evaluation of credibility models. We call a credibility model a functioncapable of assigning a credibility value to a transaction of a Web application; consideringdifferent criteria of this service and its supplier. To validate this framework and models; weperform experiments using an actual dataset; from which we evaluated different credibilitymodels using distinct types of information sources; and it allows to compare and evaluate …,Proceedings of the International Conference on Management of Emergent Digital EcoSystems,2011,*
Data Integration via Constrained Clustering: An Application to Enzyme Clustering,Elisa Boari de Lima; Raquel Cardoso de Melo Minardi; Wagner Meira Jr; Mohammed Javeed Zaki,Abstract When multiple data sources are available for clustering; an a priori data integrationprocess is usually required. This process may be costly and may not lead to goodclusterings; since important information is likely to be discarded. In this paper we proposeconstrained clustering as a strategy for integrating data sources without losing anyinformation. It basically consists of adding the complementary data sources as constraintsthat the algorithm must satisfy. As a concrete application of our approach; we focus on theproblem of enzyme function prediction; which is a hard task usually performed by intensiveexperimental work. We use constrained clustering as a means of integrating informationfrom diverse sources as constraints; and analyze how this additional information impactsclustering quality in an enzyme clustering application scenario. Our results show that …,*,2011,*
Unificação de Usuários em Redes Sociais.,Julio Albinati; Igor Altissimo; Fernando Mourão; Gisele L Pappa; Wagner Meira Jr,*,SBBD (Short Papers),2011,*
A Characterization Methodology of Evolutionary Behavior in Recommender Systems.,Alan Cardoso; Daniel Rocha; Rafael Sachetto Oliveira; Leonardo C da Rocha; Fernando Mourao; Wagner Meira Jr,Abstract: Recommender Systems (RSs) have become increasingly important tools forvarious commercial applications on the Web. Despite numerous efforts; RSs still requireimprovements to make recommendation more effective and applicable to many realscenarios. Recent studies point out the temporal evolution as a primordial manner forimproving RSs without; however; understand in detail how this evolution emerges. Thus; wepropose a methodology for evolutive characterization of users and applications in order toprovide a better understanding of this temporal dynamic in RSs. Applying our methodologyin a real scenario has proved to be useful even to help in the choice of RSs adherents ofeach scenario.,WEBIST,2011,*
Suporte de Ontologias Aplicadas à Mineração de Dados por Regras de Associação.,Eduardo de Mattos Pinto Coelho; Marcello Peixoto Bax; Wagner Meira Jr,Abstract. Data Mining (DM) for association rules tends to generate an unmanageablenumber of rules affecting the scope of its application. To solve this problem we propose theuse of ontologies in the stages of pre and post-processing tasks to support the MD. Inaddition; the article points out that human organizations require the notions of possibility;subjectivity and interpretation; contrasting with the notions of necessity; objectivity andexplanation; useful in fields of natural sciences. These requirements demand newperspective on ontologies and DM; often sheltered by soft computing. Resumo. Mineraçãode dados (MD) por regras de associação tende a gerar um número intratável de regrasprejudicando a abrangência de sua aplicação. Para solucionar esse problema propõe-se ouso de ontologias nas etapas de pré e pós-processamento no suporte às tarefas de MD …,ONTOBRAS-MOST,2011,*
Multi-Label Associative Classification,Adriano Veloso; Wagner Meira,Abstract A typical assumption in classification is that outputs are mutually exclusive; so thatan input can be mapped to only one output (ie; single-label classification). However; due toambiguity or multiplicity; it is quite natural that many applications violate this assumption;allowing inputs to be mapped to multiple outputs simultaneously. Multi-label classification isa generalization of single-label classification; and its generality makes it much more difficultto solve. Despite its importance; research on multi-label classification is still lacking.Common approaches simply learn independent functions (Brinker et al. Unified model formultilabel classification and ranking. In: Proceedings of the European Conference onArtificial Intelligence; ECAI; pp. 489–493; 2006); not exploiting dependencies among outputs(Boutell et al. Learning multi-label scene classification. Pattern Recogn. 37 (9); 1757 …,*,2011,*
Associative Classification,Adriano Veloso; Wagner Meira,Abstract The hypothesis space; H; may contain a huge (possibly infinite) number offunctions. Randomly producing functions; in the hope of finding one that approximates wellthe target function P (y| x); is not likely to be an efficient strategy. Fortunately; there arecountless more efficient strategies for producing approximations of P (y| x). One of thesestrategies is to directly exploit relationships; dependencies and associations between inputsand outputs (ie; classes)(Liu et al. Integrating classification and association rule mining. In:Proceedings of the Conference on Data Mining and Knowledge Discovery (KDD); 1998).Such associations are usually hidden in the examples in S; and; when uncovered; they mayreveal important aspects concerning the underlying phenomenon that generated theseexamples (ie; P (y| x)). These aspects can be exploited for the sake of producing only …,*,2011,*
The Classification Problem,Adriano Veloso; Wagner Meira,We present the classification problem; starting with definitions and notations that are necessaryto ground posterior discussions. Then; we discuss the Probably Approximately Correct learningframework; and some function approximation strategies … In this section we present definitionsand notations that form the basis of the classification problem … The 0–1 loss function is veryintuitive; since it states that one should make as few mistakes as possible. It may be consideredan upper bound for other loss functions; such as the hinge and the squared loss functions[11] … Next we discuss a well-known mathematical tool for the analysis of classification algorithms… The expected error is bounded by some constant \(\varepsilon\) (ie; the generalization error) … Classification is posed as synthesizing a mapping function that best approximates the relationshipbetween the inputs \(x_i\) and the corresponding outputs \(y_i\) (ie; the classes). Two …,*,2011,*
Calibrated Associative Classification,Adriano Veloso; Wagner Meira,Abstract Given an input x_i and an arbitrary output c_j; a classification algorithm usuallyworks by estimating the probability of x_i being related to c_j (ie; class membershipprobability). Well calibrated classification algorithms are those able to produce functions thatprovide accurate estimates of class membership probabilities; that is; the estimatedprobability ̂ p (c_j| x_i) is close to p (c_j| ̂ p (c_j| x_i)); which is the true;(unknown)empirical probability of x_i being related to output c_j given that the probability estimated bythe classification algorithm is ̂ p (c_j| x_i). Calibration is not a necessary property forproducing an accurate approximation of the target function; and; thus; most of the researchhas focused on direct accuracy maximization strategies rather than on calibration. However;non-calibrated functions are problematic in applications where the reliability associated …,*,2011,*
Ordinal Regression and Ranking,Adriano Veloso; Wagner Meira Jr,Abstract Accurate ordering or ranking over instances is of paramount importance for severalapplications (Faria et al. Learning to rank for content-based image retrieval. In: Proceedingsof the Multimedia Information Retrieval Conference; pp. 285–294; 2010; Veloso et al.Learning to rank at query-time using association rules. In: Proceedings of the Conference onResearch and Development in Information Retrieval (SIGIR); pp. 267–274; 2008; Veloso etal. J Inf Data Manag 1 (3): 567–582; 2010; Veloso and Meira; Efficient on-demand opinionmining. In: Proceedings of the Brazilian Symposium on Databases (SBBD); pp. 332–346;2007; Veloso et al. Automatic moderation of comments in a large on-line journalisticenvironment. In: Proceedings of the International AAAI Conference on Weblogs and SocialMedia (ICWSM); pp. 234–237; AAAI; 2007). One clear application is Information Retrieval …,*,2011,*
FPCluster: Uma estratégia eficiente de agrupamento out-of-core sem medida de similaridade.,Douglas EV Pires; Luam C Totti; Rubens EA Moreira; Elverton C Fazzion; Osvaldo LHM Fonseca; Wagner Meira Jr; Raquel Cardoso de Melo Minardi; Dorgival O Guedes,Abstract. Clustering is one of the most popular and relevant data mining tasks. Twochallenges for determining clusters are the volume of data to be grouped and the difficulty indefining a similarity measure applicable to the entire data set. In this work we presentFPCluster; a new clustering algorithm that addresses both problems. The algorithmdeveloped is based on the out-of-core building of frequent pattern trees; a data structureoriginally proposed for mining patterns. Additionally; the algorithm handles transparentlymissing features; a common constraint in real case scenarios. We applied FPCluster to tworeal scenarios: characterization of spam campaigns and clustering of protein families. Weevaluated both the quality of the obtained groups and the computational efficiency of theproposed strategy. Resumo. Agrupamento é a uma das tarefas mais populares e …,SBBD (Short Papers),2011,*
Análise Adaptativa de Fluxo de Sentimento Baseada em Janela Deslizante Ativa.,Ismael Santana Silva; Glívia AR Barbosa; Adriano Veloso; Wagner Meira Jr; Renato Ferreira,Abstract. In recent years; the task of sentiment analysis has attracted much interest from themachine learning community. Considering the benefits offered by this analysis; it isincreasingly necessary to analyze feelings and opinions that are expressed continuously insentiment streams provided by users in social media channels. Many automaticclassification techniques have been used to perform this sentiment analysis; however; thesetechniques are not always appropriate to address the changes that occur in the sentimentstream (ie; sentiment drift). This work aims to present an approach for adaptive analysis ofsentiment streams that allows not only model learning; but also forgetfulness of obsoletepieces of the model during sentiment analysis. In the proposed approach; we combined aclassifier based on association rules with a forgetfulness approach based on Active …,SBBD (Short Papers),2011,*
A Proposal of Parallelization of Local Search Procedures Applied to the Minimum Cost Hop-and-Root Constrained Forest Problem,DL Pereira; AS Cunha; W Meira Jr,In this work; we present two parallel heuristics that coordinate the application of many localsearch procedures to the Minimum Cost Hop-and-root Constrained Forest Problem(MCHCFP); a Combinatorial Optimization problem in which the minimization of thecommunication costs in a wireless sensor network with constrained delay and number ofhops is desired. The coordinated application of local search procedures in parallel must takeinto account that these search procedures may have different goals; since the MCHCFPrequires the minimization of trees and routes. The presented ideas can be generalized toother problems in which a similar situation occurs.,Computing Systems (WSCAD-SCC); 2010 11th Symposium on,2010,*
An End User Development Model to Augment Usability of Rule Association Mining Systems,Raquel Prates; Wagner Meira; Elisa Albergaria,*,IFIP International Federation for Information Processing,2010,*
Analyzing user profiles in electronic markets,Diego Duarte; Wagner Meira; Adriano Pereira,The electronic markets have reached a huge volume of users and transactions with thepopularization of the Web applications. Thus; it is essential to understand clearly thebehavior of the users of these applications to improve the services and also to offer newfeatures to them. In this context; this paper presents a workload characterization andevaluates the navigation profiles of humans and bots in an electronic market. We use agraph model to represent the user navigation; identifying typical differences among theirbehaviors; as the action of data collecting performed by bots; and the typical act of searchingfrom humans. Besides proposing a methodology for user session tracking characterization;the results of this paper can be applied in order to design new personalization techniques orto improve the user-system interaction.,Information Society (i-Society); 2010 International Conference on,2010,*
Avaliaç ao de Sistemas de Busca em Mercados Eletrônicos,D Duarte; A Pereira; Wagner Meira Jr,Abstract. Electronic markets; such as e-Bay and Amazon. com; have reached greatpopularity in the last few years. In this scenario; understanding the user behavior is achallenge. This work presents an analysis of the user navigation in TodaOferta; which is alarge Brazilian electronic market; with focus on the search system. From the classification ofuser requests; we distinguish navigation sessions with search functions from the ones thathave not. We conclude that the first group has more sessions with larger sizes; such as ahigher efficiency to perform transactions. The results can be aplied to improve the searchengines and create customized services. Resumo. Mercados eletrônicos; tais como eBay eAmazon. com; têm ampliado sua popularidade nos últimos anos. Neste cenário; um dosdesafios existentes é a compreensao da interaç ao dos usuários. Este trabalho apresenta …,VII Workshop de Trabalhos de Iniciaçao Cientıfica (WTIC’10),2010,*
Combinando Multi-Visoes através de um Algoritmo de Nuvens de Partıculas,Zilton Junior; Gisele L Pappa; Filipe de L Arcanjo; Wagner Meira Jr; Marcos A Gonçalves,Abstract. Classification problems can use several representations to express the sameconcept. Videos; for example; can be represented by their image or sound features. In recentyears; researchers start to integrate these representations into models called multi-view;which can significantly improve the outcome of classification. This paper presents a study ontwo multi-view datasets; and introduces a new algorithm based on particle swarmoptimization to weight views according to their relevance. As a result; we create MultiViL; anopen-source tool for multi-view classification. Resumo. Problemas de classificaç ao podemutilizar diversas representaç oes de um domınio do conhecimento. Por exemplo; um vıdeopode ser representado utilizando caracterısticas de som ou imagem. Nos últimos anos;pesquisadores passaram a integrar essas representaçoes em modelos denominados …,*,2010,*
Temporal Analysis of Seller Profiles in Electronic Markets,Adriano M Pereira; Diego Duarte; Sara Guimaraes; Wagner Meira Jr,In the last decade; there has been an explosion of online commercial activity enabled byWorld Wide Web (WWW). These days; many consumers are less attracted to onlineauctions; preferring to buy merchandise quickly using fixed price negotiations. This work ispart of a research to characterize and analyze selling practices in a fixed-price e-market. Animportant part of this research is to evaluate qualitatively how the e-market changes throughtime; considering the seller profiles and their negotiations and the impact of them in terms ofoutcomes; such as price and transaction. We use real data from TodaOferta; a largeBrazilian marketplace. In terms of transactions; we measure a variation from 10 to 15% ofunsatisfaction; showing that TodaOferta has a considerable credibility. The retailersrepresent around 40 to 45% of e-market transactions share. There is also a significant …,Web Congress; 2009. LA-WEB'09. Latin American,2009,*
Linguistic-Inspired Network Model for Document Classification,Fernando Mourão; Leonardo Rocha; Lucas Miranda; Thiago Salles; Marcos Gonçalves; Wagner Meira Jr,*,*,2009,*
Oportunidades para o uso de linguagens interpretadas em plataformas de computação paralela,Anolan Milanés; Ayala Barbosa; Wagner Meira; Renato Ferreira,Abstract. The high-performance requirements typical of parallel computing have traditionallybanished interpreted languages from the parallel toolbox. We argue that there is a space forthose languages on the development of parallel and distributed applications. It is well knownthat performance penalties can be minimized following a dual-programming approach whichcombines the advantages of both interpreted and compiled languages. Besides; the featuresinterpreted languages can offer; pays the price for the performance penalties its use wouldcause. In this paper; we explore the advantages of introducing interpreted languages on theimplementation of parallel and distributed platforms in the context of the Lua language andthe Anthill parallel execution platform. Resumo. O requisito de alto desempenho próprio dacomputação paralela tem levado a desconsiderar as linguagens interpretadas como …,Third Workshop on Languages and Tools for Parallel and Distributed Programming LTPD 2009,2009,*
A construção da Base Nacional de Dados em Terapia Renal Substitutiva (TRS) centrada no indivíduo: relacionamento dos registros de óbitos pelo subsistema de A...,Odilon Vanni de Queiroz; Augusto Afonso Guerra Júnior; Carla Jorge Machado; Eli Lola Gurgel Andrade; Wagner Meira Jr; Francisco de Assis Acúrcio; Walter dos Santos Filho; Mariângela Leal Cherchiglia,*,Epidemiologia e Serviços de Saúde,2009,*
Caracterização do Encadeamento de Conexões para Envio de Spams,Pedro Henrique Calais; Dorgival Guedes; Wagner Meira Jr; Cristine Hoepers; Klaus Steding Jessen; Marcelo HPC Chaves,*,*,2009,*
Um Modelo Temporal-Relacional para Classificaç ao de Documentos,Fernando Mourao; Wagner Meira Jr,Abstract. Automatic Document Classification (ADC) is one of the most relevant researchproblems in information retrieval. Despite the large number of ADC techniques alreadyproposed; there is still a demand for techniques that are effective and efficient in taking intoconsideration relationships among terms. In this paper we propose a new network-basedmodel for textual documents and introduce a family of relational algorithms for ADC thatconsider the temporal evolution of documents. Experimental evaluation of these algorithmsshows that they achieve results comparable to SVM in four real datasets. Further; itssimplicity; efficiency and the absence of a complex parameter tuning are characteristics thatmake our algorithm an interesting alternative to SVM. Resumo. Classificaçao Automática deDocumentos (CAD) é uma das mais relevantes tarefas em Recuperaçao de Informaçao …,*,2009,*
Temporal Analysis of Selling Strategies in Electronic Markets,Adriano Pereira; Diego Duarte; Sara Guimarães; Wagner Meira Jr,*,*,2009,*
Evolução de Funções de Avaliação de Regras em Classificadores Associativos,Arlei Silva; Gisele Pappa; Marcos Gonçalves; Wagner Meira Jr,This paper presents the first steps towards a genetic programming algorithm to evolve ruleevaluation metrics for associative classifiers. The method allows the combination ofcharacteristics found in a variety of metrics currently used for rule evaluation; creating newand more robust evaluation functions. Experiments in the Reuters database showed that asimple associative classification algorithm combined with the evolved functions obtainsbetter accuracy than the one using the confidence as an evaluation metric.,*,2009,*
Mineração de Tratamentos Sequenciais para Análise de Sobrevida,Arlei Silva; Wagner Meira Jr; Odilon Queiroz; Mariângela Cherchiglia,Abstract. In this paper; we study the problem of evaluating the survival associated withsequential medical treatments. We propose a new data mining algorithm (SMTM) thatcombines the survival analysis framework with the sequence mining task. This research ismotivated by the necessity of assessing the quality of the renal replacement therapies(RRTs); what has become a policy issue in several countries. We apply SMTM to evaluatesequences of RRTs and show that SMTM is computationally efficient and able to provideimportant knowledge about the survival of patients in RRT; better describing the patients'survival pattern than the traditional survival analysis. The results obtained may supportfuture programs and health policies for the assistance of patients in RRT. Resumo. Nesteartigo; nós estudamos o problema da avaliaçao da sobrevida associada a tratamentos …,*,2009,*
Mineração de Tratamentos Médicos Sequenciais para a Análise de Sobrevida,Arlei Silva; Wagner Meira Jr,*,*,2009,*
WI-IAT Workshops 2007,Yuefeng Li; Gabriella Pasi; Chengqi Zhang; Nick Cercone; Longbing Cao,Abstract: Provides an abstract of the workshop presentation and a brief professional biographyof the presenter. The complete presentation was not made available for publication as part ofthe conference proceedings … A not-for-profit organization; IEEE is the world's largest technicalprofessional organization dedicated to advancing technology for the benefit of humanity. © Copyright2017 IEEE - All rights reserved. Use of this web site signifies your agreement to the terms andconditions.,*,2008,*
Reactivity in Online Auctions: Understanding Bidding Behavior through Reactive Transitions,Adriano Pereira; Leonardo Rocha; Fernando Mourão; Wagner Meira; Paulo Góes,Internet systems are a typical scenario where sequences of interactions arise. Modeling thefactors that drive the dynamics of an online auction; for example; is complex; sincesuccessive interactions become a loop-feedback mechanism; that we call reactivity; that is;the user behavior affects the auction negotiation and vice-versa. In this paper we brieflydescribes our methodology for characterizing online auctions; considering reactivity. Wepresent the reactive transitions; that is the approach we adopt to model reactivity in onlineauctions. The reactive transition models the reactivity function; providing a way to discoverthe bidding behavior's patterns. We also validate our model using actual bidding data fromeBay. The results show rich details to understand bidding behavior; that can be used todesign support-decision agents and simulate e-markets.,E-Commerce Technology and the Fifth IEEE Conference on Enterprise Computing; E-Commerce and E-Services; 2008 10th IEEE Conference on,2008,*
Reactivity-based approaches to improve web systems' Quality of Service,Adriano Cesar Machado Pereira; Leonardo De Araujo Silva; Wagner Meira Jr; Walter Dos Santos Filho,*,JOURNAL OF WEB ENGINEERING,2008,*
Reactivity-based approaches to improve web systems' quality of service,Adriano César Machado Pereira; Leonardo De Araújo Silva; Wagner Meira,Abstract Understanding the characteristics of Internet services workloads is a crucial step toimprove the Quality of Service (QoS) offered to Web users. Moreover; studying and modelingthe user behavior is important to analyze the performance and the scalability of web servers.This knowledge may be used; for instance; to build workload generators that help evaluatingthe performance of those servers. Current workload generators are typically memory-less;being unable to mimic actual user interaction with the system. As the basis of this work; wepropose a hierarchical characterization and simulation model focused on the user behavior;named USAR. In fact; there is strong evidence that a significant part of the user behaviordepends on its satisfaction. Users reactions may affect the load of a server; establishingsuccessive interactions where the user behavior affects the system behavior and vice …,Journal of Web Engineering,2008,*
Proceedings of the Eighth SIAM International Conference on Data Mining,Chid Apte; Haesun Park; Ke Wang; Mohammad J Zaki; Chid Apte; Haesun Park; Ke Wang; Mohammad J Zaki,Abstract Contents: Message from the Conference Co-Chairs; Preface; SDM 2008Conference Organization; Program Committee; External Reviewers; Semi-SupervisedClustering via Matrix Factorization; Creating a Cluster Hierarchy under Constraints of aPartially Known Hierarchy; Constrained Co-clustering of Gene Expression Data; DATAPEELER: Constraint-Based Closed Pattern Mining in n-ary Relations; SpaRClus: SpatialRelationship Pattern-Based Hierarchial Clustering; Mining Tree Patterns with AlmostSmallest Supertrees; Maximal Quasi-Bicliques with Balanced Noise Tolerance: Conceptsand Co-clustering Applications; CISpan: Comprehensive Incremental Mining Algorithms ofClosed Sequential Patterns for Multi-Versional Software Mining; Mining Association Rules ofSimple Conjunctive Queries; Discovering Relational Item Sets Efficently; A Stagewise …,*,2008,*
Caracterização de Estratégias de Disseminação de Spams,Pedro Henrique Calais; Dorgival Guedes; Wagner Meira Jr; Cristine Hoepers; Klaus Steding Jessen,*,*,2008,*
Entendendo a Evoluēćo Temporal em Redes Complexas,Fernando Mourćo; Wagner Meira,*,*,2008,*
Virtual Integration of Biological Databases Through Web Services,Silveira SA; Lopes JCD; da Silveira CH; Pires DEV; Santoro MM,*,*,2008,*
Orangines: understanding proteins through sphere packing simulations,Pires DEV; da Silveira CH; Santoro MM,*,*,2008,*
An End User Development Model to Augment Usability of Rule Association Mining Systems,Elisa Albergaria; Fernando Mourão; Raquel Prates; Wagner Meira,Abstract One of the main challenges to a broader use of association rules data miningsystems is their usability. In this paper we propose the End User Development ConceptualModel aimed at enabling the user to customize the interface of rule mining systems andcreate domain and problem specific queries. To do so; the user must be an expert user; bothin the domain and system use (which usually requires knowledge of data mining technicalconcepts). The goal of the expert user is to create an abstract interface level that will allow adomain expert; with no knowledge of data mining; to use the system in specific problemsituations. Thus; expert users can be perceived as co-designers of the system. An initialassessment of the model's usefulness and implementation feasibility was made.,*,2008,*
Characterizing and Understanding the Impact of Temporal Evolution on Document Classification,Fernando Mourão; Leonardo Rocha; Renata Araújo; Thierson Couto; Marcos Gonçalves; Wagner Meira,*,*,2008,*
Entendendo a Evoluç ao Temporal em Redes Complexas,Fernando Mourao; Wagner Meira Jr,Abstract. Several practical problems are described by a set of objects and the relationshipbetween them. Understanding the relationship between these objects and selecting whichdata will be used in the analysis of relations is essencial to a proper characterization of thedefined model. Most of the applications considers all available information for analysis;aggregating it over time. In this work; we studied the impact of information aggregation overtime for the characterization in complex networks. We work with a generic model of network;applicable to a large and diverse range of areas. We propose and apply in a real database;a verification methodology of this impact over time. The results enabled us to conclude thatanalyzing the aggregate information degenerates the characterization of the networkstudied. Resumo. Vários problemas práticos sao descritos através de um conjunto de …,*,2008,*
Evaluating longitudinal aspects of online bidding behavior,L Rocha; A Pereira; Fernando Mourão; Arlei Silva; W Meira; P Goes,Abstract Online auctions have become a major e-commerce strategy in terms of bothnumber; diversity of participants and revenue. Recent research has characterized onlineauctions as synchronous interactive computer systems; considering successive interactionsas a" loop feedback" mechanism; called reactivity; where the user behavior affects thesystem behavior and vice-versa. Although some factors that explain user behavior in termsof instantaneous bidding conditions are identified by previous research; there has been noeffort to study how bidders' behavior changes over time. This work presents a longitudinalanalysis of bidding behavior over a series of auctions. The results show bidding behaviorevolves over time and these changes are not random. The identifiable evolution patternscan be partially explained by the presence of instantaneous reactivity patterns that …,WEBIST 2008-4th International Conference on Web Information Systems and Technologies,2008,*
Broadband User Behavior Characterization,Humberto T Marques Neto; Leonardo CD Rocha; Pedro HC Guerra; Jussara M Almeida; Wagner Meira Jr; Virgilio AF Almeida,Abstract This chapter presents a broadband user behavior characterization from an Internetservice provider standpoint. Understanding these user behavior patterns is important to thedevelopment of more efficient applications for broadband users. Our characterization dividesthe users into two categories: residential and small-office/home-office (SOHO). It employsfour characterization criteria: session arrival process; session duration; number of bytestransferred within a session; and user request patterns. Our results show that bothresidential and SOHO session interarrival times are exponentially distributed; and point outthat a typical SOHO user session is longer and transfers a larger volume of data. Ouranalysis also uncovers two main groups of session request patterns within each usercategory:(i) sessions that comprise traditional Internet services; such as WWW services; e …,*,2008,*
Um Algoritmo Eficiente para Detecção de Exceções em Bases Reais de Alta Dimensionalidade,Carlos Teixeira; Gustavo Orair; Wagner Meira Jr,Abstract. The outlier detection problem has been a research topic with interestingapplications in different domains; such as data cleaning and fraud detection. In this work; wepropose an efficient and scalable distance-based algorithm for detecting outliers in largehigh dimensional databases. Our algorithm partitions the database and sorts the objects thatare candidates to be an exception; reducing significantly the number of comparisons amongobjects. We evaluate the different sorting heuristics in a comprehensive set of real andsynthetic databases. The results show that our algorithm outperforms by 52% the state of theart algorithm. Resumo. A Mineraçao de Exceçoes tem sido uma área de pesquisa quepossui interessantes aplicaçoes em diferentes domınios; variando desde a limpeza dedadosa detecç ao de fraudes. Neste trabalho; propomos um algoritmo eficiente e …,*,2008,*
Fault-tolerance in filter-labeled-stream applications,Bruno Coutinho; Dorgival Guedes; Wagner Meira Jr; Renato A Ferreira,Fault tolerance is a desirable feature in distributed high-performance systems; sinceapplications tend to run for long periods of time and faults become more likely as the numberof nodes in the system increase. However; most distributed environments lack any faulttolerant features; since they tend to be hard to implement and use; and often hurtperformance dramatically. In this paper we discuss how we successfully added fault-tolerance to the Anthill distributed programming environment by using an application-levelcheckpoint/rollback solution. The programming model offers an abstraction where theprogrammer can easily identify points during the execution where the communicationpattern is well defined; forming a consistent cut where checkpoints may be savedconsistently without requiring extra communication; avoiding any domino effect during …,Computer Architecture and High Performance Computing; 2007. SBAC-PAD 2007. 19th International Symposium on,2007,*
PDBEST-PDB Enhanced Structures Toolkit,Lopes JCD; Silveira CH; Pires DEV; Santoro MM; Wagner Meira,*,*,2007,*
Metodologia de caracterizações em leilões eletrônicos para descoberta de padrões de negociação,Fernando Mourão; Adriano Pereira; Leonardo Rocha; Wagner Meira Jr; Paulo Goes,*,*,2007,*
Nº 185; ener Nº 185; enero-febrero 2007; año XXXIII o 2007; año XXXIII,Llorenç Pagés Casas; Ricardo Baeza-Yates; Paolo Boldi; José María Gómez Hidalgo; Gary Marchionini; Giuseppe Attardi; Paolo Ferragina; Antonio Gullí; Luis Alfonso Ureña López; Manuel Carlos Díaz Galiano; Arturo Montejo Raez; Mª Teresa Martín Valdivia; Carlos A Heuser; Wagner Meira Jr; Iadh Ounis; Christina Lioma; Craig Macdonald; Vassilis Plachouras; José Mayoralas García; Guillermo Ibáñez Fernández; Joan Batlle Montserrat; Alonso Alvarez García; Foro de Debate; Manuel Abellanas Oar; Manuel Freire Morán; Dolores Lodares González; Angel Herranz Nieva,Resumen: la Web es la aplicación de Internet por excelencia. Como tal; y del mismo modoque pasa con el correo electrónico; es un objetivo claro para el abuso. El spam ha invadidolos motores de búsqueda; las redes sociales; y aun más; la Web no sólo es objeto de abusopor los proveedores de contenidos; sino por sus propios usuarios. La Recuperación deInformación con Adversario (Adversarial Information Retrieval; AIR) se centra en laclasificación de los contenidos o de su uso en relación con su forma de abuso; y se enfrentaa un adversario (el abusador); que tiene como objetivo engañar al clasificador. El spam debuscadores y el filtrado de contenidos Web son dos ejemplos de tareas de AIR en la Web.En este trabajo de revisan una serie de problemas de AIR en la Web; junto con algunassoluciones propuestas. Prestamos especial atención a la detección de spam basado en …,novática,2007,*
Characterizing Bidding Behavior in Internet Auctions,Adriano Pereira; Leonardo Rocha; Fernando Mourão; Wagner Meira Jr; Paulo Goes,*,*,2007,*
GERINDO: Managing and Retrieving Information in Large Document Collections,Nivio Ziviani; Alberto HF Laender; Edleno S de Moura; Altigran S da Silva; Carlos A Heuser; Wagner Meira Jr,Abstract We present in this report a summary of the main results produced in the five years ofthe GERINDO research project. The aim of this project is to address the increasing demandfor software tools capable of dealing with information available in large documentcollections; such as the World Wide Web. It involves efforts of researchers from threeBrazilian universities to develop core technologies for a number of document managementapplications demanded by today's information society. These efforts are concentrated in sixmain research topics: document categorization; semistructured data management; agentsand focused crawlers; information retrieval models and searching techniques; efficiencyissues; and data mining. Besides specific contributions in these five research topics; theproject has stimulated the interaction among the researchers of the three universities who …,Departamento de Ciência da Computação; UFMG; Belo Horizonte,2007,*
PDPlan: Uma Paralelização Eficiente de um Algoritmo de Mineração de Planos,Arlei Silva; Guilherme Pimenta; Wagner Meira Jr,*,*,2007,*
Mining structural signatures in proteins using intrachain interactions.,RC MELO; JS Gomide; W MEIRA JUNIOR; JCD Lopes; G Neshich; MM Santoro,Abstract Proteins are the most versatile macromolecules in living systems serving crucialfunctions such as catalysts; transporters; and mechanical support. They are composed by asequence of amino acids which is called primary structure. Different regions of the sequenceform regular secondary structures such as helices or betasheets. The α tertiary structure;which is the 3D structure of the protein; is formed by packing such structural elements intocompact globular units called domains. The functional properties of proteins depend upontheir 3D structures that arises because a particular chain of amino acids folds to generatedomains with specific 3D structures. It is known that the chain completely determines thestructure of a protein. However; there may be several proteins with the same structure (orfamily); and the same function; but with very different sequences and many variations in …,Embrapa Informática Agropecuária-Resumo em anais de congresso (ALICE),2007,*
A Hierarchical Model and Characterization Methodology for Online Auctions,F Mourão; A Pereira; L Rocha; T Torres; W Meira Jr; P Góes,*,*,2007,*
Anteater: A Service-Oriented Architecture for High-Performance Data Mining (HTML),Dorgival Guedes; Wagner Meira Jr; Renato Ferreira,*,*,2006,*
Featuring challenges of interaction with systems of mining rules of the association,Elisa Tuler; Raquel O Prates; Fernando Almir; Leonardo Rocha; Wagner Meira Jr,*,ACM International Conference Proceeding Series: Proceedings of VII Brazilian symposium on Human factors in computing systems,2006,*
Reactivity-based Scheduling Approaches For Internet Services,Adriano Pereira; Leonardo Silva; Wagner Meira Jr,*,*,2006,*
Modeling Complex Patterns in e-Commerce,Adriano Pereira; L Rocha; Fernando Mourão; Wagner Meira Jr; P Góes; T Torres,*,*,2006,*
Captura e Análise de Tráfego da Camada de Aplicação por Software com Alto Desempenho,Tiago Macambira; Dorgival Guedes; Wagner Meira Jr,Resumo O aumento da utilizaçao comercial de redes de computadores tem aumentado anecessidade de se desenvolver sistemas que permitam aos administradores de redesmonitorar e analisar o tráfego das mesmas em detalhes. As soluç oes disponıveisusualmente dependem de hardware especializado; de alto custo. Neste trabalho discutimosos desafios para se desenvolver uma ferramenta de monitoraç ao e análise de tráfego dacamada de aplicaçao em tempo real baseada em software; utilizando hardwareconvencional. Apresentamos uma arquitetura de coleta que permite a análise do estadodas aplicaç oes utilizadas na rede; realizando a recuperaç ao do conteúdo trocado entre osusuários de uma rede P2P; por exemplo. Os resultados mostram que a arquitetura propostaapresenta uma taxa de perda de pacotes de apenas 3; 3% ao monitorar um tráfego a 500 …,*,2005,*
Evaluating Caching Strategies for Distributed Incremental Frequent Itemset Mining,Adriano A Veloso; Wagner Meira Jr; Srinivasan Parthasarathy; Renato Ferreira; Dorgival Guedes,*,*,2004,*
Dynamic task graph based decomposition of data intensive applications into a filter-stream runtime environment,A Veloso; W Meira Jr; R Ferreira; D Guedes; R Carceroni,*,system,2004,*
UML-CAFE: A Process to Specify and Verify E-Commerce Systems,Adriano Pereira; Mark Song; Gustavo Gorgulho; Wagner Meira Jr; Sérgio Campos; Fernanda Lima,*,*,2003,*
Extending UML to Specify and Verify E-commerce Systems,Adriano Pereira; Mark Song; Gustavo Gorgulho; Fernanda Lima; Sérgio Campos; Wagner Meira Jr,*,*,2003,*
A Software Engeneering Process to Specify and Verify E-Commerce Systems,Adriano Pereira; Mark Song; Gustavo Gorgulho; Fernanda Lima; Sérgio Campos; Wagner Meira Jr,*,*,2003,*
Efficient Data Mining for Frequent Itemsets in Dynamic and Distributed Databases,Adriano Veloso; Wagner Meira Jr,Abstract. Data Mining is one of the central activities associated with understanding andexploiting the world of digital data. It is the mechanized process of modeling large databasesby means of discovering useful patterns. A frequent itemset is a pattern describing a relevantsubset of the data; and a collection of frequent itemsets is particularly useful because it is anextremely compact model of the database. Discovering frequent itemsets in large databasesis usually a hard computational task; which can be even harder when data is dynamic anddistributed. Applying traditional algorithms in such data results in high communicationoverhead; excessive wastage of CPU and I/O resources; privacy violations; and often doesnot meet the stringent rapid response times; to essentially an interactive process ofexploiting the data. Hence; there is an urgent need for non-trivial algorithms that can …,*,2003,*
Model Checking Patterns for e-Commerce Systems,Adriano Pereira; Mark Song; Gustavo Gorgulho; Sérgio Campos; Wagner Meira Jr,*,*,2002,*
Proceedings of the Sixth International Workshop on Web Caching and Content Distribution,Ronald Doyle; Jeffrey Chase; Syam Gadde; Amin Vahdat; Michael Rabinovich; Sandeep Sibal; Oliver Spatscheck; Walter Sturm; Mark Nottingham; Jussi Kangasharju; James Roberts; Keith Ross; Pavlin Radoslavov; Ramesh Govindan; Deborah Estrin; Zongming Fei; Wei-Ying Ma; Bo Shen; Jack Brassil; Andre Beck; Markus Hofmann; O Ardaiz; F Freitag; L Navarro; Amy Hughes; Joseph Touch; Vsevolod Panteleenko; Vincent Freeh; Stanislav Rost; John Byers; Azer Bestavros; Arup Acharya; Anees Shaikh; Renu Tewari; Dinesh Verma; EG Coffman Jr; Predrag Jelenkovic; Petar Momcilovic; Arun Venkataramani; Praveen Yalagandula; Ravi Kokku; Sadia Sarif; Mike Dahlin; Brian Davison; Terence Kelly; Johnson Lee; William Miniscalco; Meng Li; W David Shambroom; John Buford; V Almeida; D Menasce; R Riedi; F Peligrinelli; R Fonseca; W Meira Jr; Richard Liston; Ellen Zegura; Mimika Koletsou; Geoffrey Voelker; Serge Krashakov; Lev Shchur; Sung-Ju Lee; Olivier Verscheure; Chitra Venkatramani; Pascal Frossard; Lisa Amini,OVERVIEW The International Web Content Caching and Distribution Workshop (WCW) is apremiere technical meeting for researchers and practitioners interested in all aspects ofcontent caching; distribution and delivery on the Internet. The 2001 WCW meeting was heldon the Boston University Campus. Building on the successes of the five previous WCWmeetings; WCW01 featured a strong technical program and record participation from leadingresearchers and practitioners in the field. This report includes all the technical paperspresented at WCW'01. Note: Proceedings of WCW'01 are published by Elsevier. Hardcopiesof these proceedings can be purchased through the workshop organizers. As a service tothe community; electronic copies of all WCW'01 papers are accessible through TechnicalReport BUCS‐TR‐2001‐017; available from the Boston University Computer Science …,*,2001,*
Balanceamento de Carga em Servidores de An uncios Eletr^ onicos Distribu dos,Rodrigo Pereira; Bruno Diniz; Fl avia Ribeiro; Wagner Meira Jr; Virg lio Almeida,Resumo Uma caracter stica fundamental para o sucesso de servi cos providos pela Internete a sua escalabilidade; ou seja; a capacidade dos servidores em suportar as taxas decrescimento de utiliza cão desses servi cos. Uma estrat egia de sucesso para aumentar aescalabilidade de servi cos e a sua distribui cão. Um exemplo de servi co Internet; onde anecessidade de escalabilidade e grande; e o de publicidade eletr^ onica (banner). Nesteartigo discutimos a distribui cão de servi cos de publicidade eletr^ onica e mecanismos parabalanceamento de carga em uma implementa cão distribu da; os quais são avaliadosutilizando uma simula cão da arquitetura proposta e uma carga de trabalho de um servidorde an uncios eletr^ onicos real.,*,2001,*
Balanceamento de Carga em Servidores de Anuncios Eletr^ onicos Distribudos,Rodrigo Pereira Bruno Diniz Flavia Ribeiro; Wagner Meira Jr; Virg lio Almeida,*,*,2001,*
On the Design of a Tool for Controlling Privacy in the WWW.,Lucila Ishitani; Gustavo Machado Campagnani Gama; Virgílio AF Almeida; Dorgival Olavo Guedes Neto; Wagner Meira Jr,*,Workshop on Information Integration on the Web,2001,*
Servidores Paralelos e Distribuidos de Comércio Eletrônico,Adriano Pereira; Tassini Cançado; Bruno D Abrahão; Rodrigo Pereira; Wagner Meira Jr; Cláudio Amorim,*,*,2001,*
Classificação Automática de Consumidores Eletrônicos,Fabiana Ruas; Paulo Araújo; Wagner Meira Jr,*,International Joint Conference; 7th Ibero-American Conference; 15th Brazilian Symposium on AI; IBERAMIA-SBIA 2000; Open Discussion Track Proceedings on AI,2000,*
Minimizing the impact of orphan requests in e-commerce services,E Kraemer; G Paixão; D Guedes; Wagner Meira Jr; V Almeida,Abstract The most common problem of an overloaded electronic-commerce server is anincrease in the response time perceived by customers; who may restart their requestshoping to get a faster response; or simply abort them; giving up on the store. Both behaviorsgenerate" orphan" requests: although they were received by the server; they should not beanswered because their requestors have already abandoned them. Orphan requests wastesystem resources; since the server becomes aware of their cancellation only when it tries tosend a response and finds out that the connection was closed. In this paper we propose anew kernel service; the Connection Sentry; which keeps track of requests being performedand notify processes about an eventual cancellation. Once notified; a process can interruptthe execution of the request; saving system resources and bandwidth. We evaluated the …,ACM SIGMETRICS Performance Evaluation Review,2000,*
Representantes eletrônicos: Integrando caches www e lojas virtuais,Gustavo Gama; E Kraemer W Meira Jr; V Almeida,Resumo Com o intuito de manter a qualidade de serviço demandada pelo crescentenúmero de clientes de lojas virtuais; os serviços de comércio eletrônico devem serescaláveis. Este artigo introduz o conceito e um modelo de implementação de"representante comercial eletrônico" como um meio de escalar o desempenho de servidoresde comércio eletrônico. Os representantes eletrônicos são programas que executam em umservidor cache WWW ou em máquinas próximas aos clientes; atuando como intermediáriosde transações. O modelo de implementação proposto utiliza uma arquitetura de trêscomponentes que será replicada parcialmente no servidor cache. Os resultados obtidos apartir de um protótipo são promissores; reduzindo a latència dos clientes em até 45% e autilização dos canais de comunicação em 80%.,Anais do XVIII Simpósio Brasileiro de Redes de Computadores,2000,*
Toxin data bank: a database of molecular and biological data on toxins,AM Siqueira; W Meira Jr; ACM Pereira; SL Novaes; MM Santoro,*,Toxicon,2000,*
Agentes para o comércio eletrônico no mercado de seguros,Marcello PEIXOTO BAX; Wagner JR MEIRA,*,Perspectivas em ciência da informação,2000,*
Efficient storage management in world wide Web caches,C DUARTE MURTA; VF ALMEIDA; W MEIRA JR,*,Teletraffic science and engineering,1999,*
Monitoração e Análise de Desempenho do Sistema NCP2,Adriano Pereira; Eduardo Kraemer; Wagner Meira Jr; Cláudio Amorim,A paralelização de aplicações tem como grande atrativo a redução do tempo computacionalnecessário para a sua execução. O desenvolvimento de aplicações paralelas eficientes;entretanto; é freqüentemente uma tarefa árdua; principalmente em razão da complexidadedas aplicações; arquiteturas e interações entre elas. No caso da arquitetura NCP2; ainovação representada pelo hardware e os protocolos de coerência de memória específicostornam essa tarefa ainda mais árdua; não apenas para programadores como para ospróprios projetistas. Esse artigo apresenta uma proposta para a monitoração e análise dedesempenho da arquitetura NCP2. Essa proposta foi implementada sobre um emuladordaarquitetura e a ferramenta resultante é apresentada e discutida em detalhes.,*,1999,*
Publicity Chairs,Kuan-Ching Li; Pacific Asia; Sébastien Monnet; Luciana Arantes; Christohe Cérin; Jean-François Méhaut; Vania Marangozova-Martin; Andrea Pinna; Julien Sopena; Claudio Amorim; Guido Araújo; Rajkumar Buyya; Jean-Luc Gaudiot; Manoel Eusébio de Lima; Wagner Meira Jr; José Eduardo Moreira; Philippe Olivier Alexandre Navaux; Jairo Panetta; Viktor Prasanna; Vinod Rebello; Liria Matsumoto Sato; Bruno Schulze; Siang Wun Song; Alberto F De Souza,● Luciana Arantes (Université Pierre et Marie Curie / CNRS / Inria; LIP6 Lab.; France) ● ChristoheCérin (Université Paris XIII; LIPN Lab.; France) ● Jean-François Méhaut (Université JosephFourier Grenoble; CNRS; LIG Lab.; France) ● Vania Marangozova-Martin(Université JosephFourier Grenoble; CNRS; LIG Lab.; France) ● Andrea Pinna (Université Pierre et Marie Curie/ CNRS; LIP6 Lab.; France) ● Julien Sopena (Université Pierre et Marie Curie / CNRS /Inria; LIP6 Lab.; France) … ● Claudio Amorim (Universidade Federal do Rio de Janeiro;Brazil) ● Guido Araújo (Unicamp: Universidade Estadual de Campinas; Brazil) ● RajkumarBuyya (The University of Melbourne; Australia) ● Jean-Luc Gaudiot (University of Californiaat Irvine; USA) ● Manoel Eusébio de Lima (Universidade Federal de Pernambuco; Brazil) ●Wagner Meira Jr (Universidade Federal de Minas Gerais; Brazil) ● José Eduardo …,*,*,*
ÍÒ Ó Í× Ù Ö Ó× Ñ Ê× ËÓ×,Julio Albinati; Igor Altissimo; Fernando Mourão; Gisele L Pappa; Wagner Meira Jr,O problema de resolução de entidades; frequente na integração de dados provenientes dediferentes fontes; vem sendo estudado há décadas pela comunidade de banco de dados[Garcia-Molina 2004; Newcombe et al. 1959]. Esse artigo; porém; trata do problema deresolução de entidades em um contexto mais atual: redes sociais. Com o frequenteaparecimento de novas redes e micro-blogs; bem como o uso de diferentes redes parapropósitos variados; usuários passaram a utilizar várias delas simultaneamente. Porexemplo; o Twitter consiste em um tipo de rede mais genérica; onde se segue e é seguidopor muitos usuários; em que grande parte deles são agências de notícias; empresas;celebridades; dentre outros [Wu et al. 2011]. O Facebook; por sua vez; ainda preserva umambiente mais fechado; com uma relação bilateral e menos usuários na rede de contato …,*,*,*
Real World Association Rule Mining Adriano Alonso Veloso1 Bruno Gusmnao Rocha1 M éarcio Luiz Bunte de Carvalho1,Wagner Meira Jr,Abstract. Across a wide variety of fields; data are being collected and accumulated at adramatic pace; and therefore a new generation of techniques has been proposed to assisthumans in extracting usefull information from the rapidly growing volumes of data. One ofthese techniques is the association rule discovery; a key data mining task which hasattracted tremendous interest among data mining researchers. Due to its vast applicability invarious domains; many algorithms have been developed to perform the association rulemining task. However; an immediate problem facing researchers is which of thesealgorithms is likely to make a good match with the database to be used in the miningoperation. In this paper we consider this problem; dealing with both algorithmic and dataaspects of association rule mining by performing a systematic experimental evaluation of …,*,*,*
Preface page ix,Mohammed J Zaki; Wagner Meira,Cambridge University Press 978-0-521-76633-3 - Data Mining and Analysis: Fundamental Conceptsand Algorithms Mohammed J. Zaki and Wagner Meira Table of Contents More information …5 Kernel Methods . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 134 5.1 Kernel Matrix … 5.3 Basic KernelOperations in Feature Space … 6 High-dimensional Data . . . . . . . . . . . . . . . . . . . . . . . . . . . 1636.1 High-dimensional Objects … 8 Itemset Mining . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 217 8.1Frequent Itemsets and Association Rules … 9 Summarizing Itemsets . . . . . . . . . . . . . . . . . . . . .. . . . . . 242 9.1 Maximal and Closed Frequent Itemsets … 9.2 Mining Maximal FrequentItemsets: GenMax Algorithm … 9.3 Mining Closed Frequent Itemsets: Charm Algorithm … ©in this web service Cambridge University Press … Cambridge University Press 978-0-521-76633-3 - Data Mining and Analysis: Fundamental Concepts and Algorithms Mohammed J …,*,*,*
Uma estratégia baseada no filtro de Kalman para monitoramento de epidemias de dengue a partir de redes sociais,Derick M de Oliveira; Roberto CSNP Souza; Denise EF de Brito; Rodrigo L Cardoso; Wagner Meira Jr,Abstract. Milhares de mensagens são propagadas em redes sociais diariamente;abordando os mais diversos assuntos. Com o grande crescimento desses canais decomunicação; os usuários tendem a discutir variados aspectos do seu cotidiano;preferências e até condições de saúde. A natureza dinâmica e de tempo real dessasmídias; tem transformado tais informações em uma importante ferramenta para pesquisasatuais. Entretanto; um dos grandes desafios na utilização de dados de redes sociais paraprevisão de eventos está relacionado ao ruído decorrente da ambiguidade da linguagemou outros fatores presentes nos dados de entrada. Este trabalho propõe uma estratégiabaseada no filtro de Kalman (FK) para monitoramento de epidemias de dengue a partir deredes sociais. O FK é uma solução recursiva do método de mínimos quadrados e …,*,*,*
Estuda Comigo? Oportunidades e Desafios para uma Aplicação de Coprodução para Estudos em Grupo,Luiz Paulo Damilton Corrêa; Raquel Oliveira Prates; Antônio Leite; Fabrício Benevenuto; Pedro Olmo de Melo; Camila Araújo; Ana Paula Silva; Wagner Meira Jr; Flávio Coutinho; Luiz Chaimowicz; Glívia Barbosa,ABSTRACT In a service coproduction; the relationship between stakeholders is reciprocal;and the roles of provider and recipient are not necessarily defined. This paper presents aninvestigation with students in order to understand their motivations and prospects ofcoproduction involved in their activities of studying in groups. From interviews; we raised 15categories; split into 3 groups. This analysis is presented as an initial stage in the design of amobile app and it is used to discuss potential opportunities and challenges for this type ofapplication.,*,*,*
Proc. Tools 2000 Conference; Chicago; IL; March 2000.,T Goedson; Wagner Meira Jr; Virgilio AF Almeida; Daniel A Menascée; Adriano M Pereira,*,*,*,*
Of Pins and Tweets,Raphael Ottoni; Diego Las Casas; João Paulo Pesce; Wagner Meira Jr; Christo Wilson; Alan Mislove; Virgilio Almeida,Page 1. Of Pins and Tweets Investigating how users behave across image- and text-based socialnetworks Raphael Ottoni <rapha@dcc.ufmg.br> Diego Las Casas <diegolascasas@ufmg.br>João Paulo Pesce <jpesce@dcc.ufmg.br> Wagner Meira Jr. <meira@dcc.ufmg.br> Christo Wilson<cbw@css.neu.edu> Alan Mislove <amislove@css.neu.edu> Virgilio Almeida <virgilio@dcc.ufmg.br> Page 2. Motivation Do users have distinct behavior across networks? Where does the contentoriginate? Does one network influence the other? Are OSNs used for the same purpose? Do peoplehave a strong identity or do they adapt to the context of each network? Page 3. Page 4. Men'sFashion Travel Hair Beauty Women's Fashion Products Women's Fashion Women's FashionWomen's Fashion Women's Fashion Products Twitter Link Page 5. Dataset Daily crawling over82 days 30k users ~2mi pins ~4.5mi tweets Page 6 …,*,*,*
SBAC-PAD 2016 Program Committee and External Reviewers,Abhinav Bhatele; Kei Davis; Todd Gamblin; Narayan Ganesan; Jing He; Travis Johnston; Daniel S Katz; Wagner Meira Jr; Alba De Melo; Hai Ah Nam; Vivek K Pallipuram; Jairo Panetta; Amanda Randles; Olaf Schenk; Rafael Ferreira da Silva; Francesco Silvestri; Suzanne Shontz; Tyler Simon; Rio Yokota; Jaroslaw Zola; Jose Amaral; Claudio Amorim; Guido Araujo; Rodolfo Azevedo; Mauricio Breternitz Jr; Sunita Chandrasekaran; Byunghyun Jang; David Kaeli; Hugh Leather; José Moreira; Onur Mutlu; Philippe Navaux; Alex Nicolau; Yale Patt; Per Stenström; Radu Teodorescu; Yash Ukidave,Applications Abhinav Bhatele (LLNL; USA) Kei Davis (LANL; USA) Todd Gamblin (LLNL;USA) Narayan Ganesan (Stevens Institute of Technology; USA) Jing He (Old DominionUniversity; USA) Travis Johnston (University of Delaware; USA) Daniel S. Katz (University ofIllinois Urbana Champaign; USA) Wagner Meira Jr (Federal University of Minas Gerais;Brazil) Alba De Melo (University of Brasilia; Brazil) Hai Ah Nam (LANL; USA) Vivek K. Pallipuram(University of the Pacific; USA) Jairo Panetta (ITA; Brazil) Amanda Randles (Duke University;USA) Olaf Schenk (University of Lugano; Switzerland) Rafael Ferreira da Silva (USC; USA) FrancescoSilvestri (IT University of Copenhagen; Denmark) Suzanne Shontz (University of Kansas;USA) Tyler Simon (Laboratory for Physical Sciences; USA) Rio Yokota (Tokyo Institute ofTechnology; Japan) Jaroslaw Zola (University at Buffalo; SUNY; USA),*,*,*
Reactivity-Based Quality of Service Strategies for Web Applications,Adriano CM Pereira; Wagner Meira Jr,Abstract The great success of the Internet has raised new challenges in terms of applicationsand user satisfaction. Web applications demand requirements; such as performance andscalability; in order to guarantee quality of service (QoS) to users. Due to theserequirements; QoS has become a special topic of interest and many mechanisms to provideit have been proposed. Those mechanisms fail to consider aspects related to reactivity; ie;how the users react to variable server response time. This work addresses the use ofreactivity to provide new strategies. We design and evaluate a reactivity-based schedulingmechanism that gives priority according to user behavior. We also propose a hybridadmission control and scheduling mechanism that combines both reactive approaches. Theresults show benefits in terms of response time and user satisfaction.,*,*,*
Caracterizaç ao Remota de Comportamento de Roteadores IPv6,Rafael Almeida; Elverton Fazzion; Osvaldo Fonseca; Dorgival Guedes; Wagner Meira; Ítalo Cunha,Abstract. Even though the IETF standardizes protocols and provides implementationguidelines; many implementation decisions are left to vendors and developers. Thebehavior of network devices are also dependent on their configuration. Over the years;researchers have developed many measurement techniques to characterize networkdevices. These characterization techniques are useful for network management; operation;troubleshooting; and security. With the depletion of IPv4 address space and increasing IPv6adoption; characterization techniques for IPv6 devices are increasingly important.Unfortunately; characterization techniques for IPv6 devices remain incipient. In this work wepropose and evaluate a new characterization technique for IPv6 devices along a networkpath that takes the behavior of intermediate devices into account. Resumo. Apesar da …,*,*,*
Processamento de dados massivos,Dorgival Guedes; Renato Ferreira; Wagner Meira Jr,Resumo A evoluçao dos sistemas de computaçao tem permitido o acúmulo de volumes dedados cada vez maiores. Sejam dados sobre relacionamentos em redes sociais; registrosde transaçoes comerciais; fluxos de dados gerados por sensores; modelos computacionaiscada vez mais precisos ou dados sobre a própria Web; extrair informaç ao útil desses dadosse tornou um desafio para a área de processamento de alto desempenho. Nesse contexto;o modelo MapReduce e o ambiente Hadoop; que o implementa; se tornaram largamenteconhecidos e adotados. Entretanto; é fato que MapReduce/Hadoop nao é a soluç ao idealpara todos os problemas. Para os casos onde isso ocorre; extensoes do modelo original ediversas outras soluç oes têm sido propostas na área de sistemas distribuıdos. Esteminicurso pretende discutir os elementos que tornam a tarefa de processar dados …,*,*,*
Uma metodologia para avaliar modelos de previsão de eventos a partir de redes sociais,Denise EF Brito; Wagner Meira Jr; Roberto CSNP Souza; Bruna O Neuenschwander; Walter dos Santos; Mauro M Teixeira,*,*,*,*
Como nos Sentimos: Uma Ferramenta de Mineração Visual de Sentimentos no Twitter,Artur O Rodrigues; Raquel C de Melo-Minardi; Wagner Meira Jr,*,*,*,*
2013 14th IEEE International Conference on Mobile Data Management (MDM),Miao Lin; Zhuo Qi Lee; Wen-Jing Hsu,Various Markov models have been proposed to model individuals' mobility; ie; thetransitions between locations. Although these studies are able to show high predictingaccuracy of individuals' next move; two basic assumptions of these studies; namely thestationarity of individuals' mobility sequence and the dependency of visiting the locations;have never been validated. Moreover; a famous recent...,*,*,*
Supplementary Material for “PDBest: a user-friendly platform for manipulating and enhancing protein structures”,Wellisson RS Gonçalves; Valdete M Gonçalves-Almeida; Aleksander L Arruda; Wagner Meira Jr; Carlos H da Silveira; Douglas EV Pires; Raquel C de Melo-Minardi,Fig. 1. PDBest-a freely available; user-friendly platform for manipulating protein structurefiles. The figure showcases an example of common filtering tasks that can be performed withPDBest: adding hydrogens; removing solvent molecules and multiple occupancies. Thefigure (generated using Pymol) depicts the structure of the sperm whale myoglobin (PDB:1A6M-on the left); the residues surrounding its bound Heme group (center); and the finalprocessed file (on the right).,*,*,*
Quantifying the Impact of Information Aggregation on Complex Networks,Fernando Mourao; Leonardo Rocha; Lucas Miranda; Virgılio Almeida; Wagner Meira Jr,Page 1. Quantifying the Impact of Information Aggregation on Complex Networks: A TemporalPerspective Fernando Mour˜ao Leonardo Rocha Lucas Miranda Virgılio Almeida WagnerMeira Jr. Federal University of Minas Gerais Department of Computer Science February; 12 -2009 Page 2. Introduction Motivation Demand for scalable and robust modeling tools: Anincreasing amount of data is being stored Data is getting more complex Complex Networksis a popular and successful model that has been applied to fields such as sport; economy;and biology; among others. Wagner Meira Jr. et. al. 2 Page 3 …,*,*,*
Economically-Efficient Data Stream Analysis,Roberto L de Oliveira Jr; Adriano Veloso; Wagner Meira Jr,Abstract. This is a brief review of Roberto Lourenço's Master's thesis; which introduced novelalgorithms that learn classification models from data streams. The key challenge studied inthis thesis is to learn classification models that are more robust to concept drifts. Theproposed learning algorithms employ key concepts from Economics; which enable theresulting model to adapt itself to new drifts and recovering itself from past drifts. Our resultsshow that our algorithms provide a 14% error reduction without compromising resourcessuch as execution time; memory and labeling efforts. Resumo. Este é um breve resumo dadissertaçao de mestrado de Roberto Lourenço; que introduz novos algoritmos queaprendem modelos de classificaç ao em fluxos de dados. O desafio chave estudado nestadissertaç ao é aprender modelos de classificaçao que sao mais robustos a mudanças de …,*,*,*
The Delta Network: Measuring and Comparing the Performance of Heterogeneous Vehicular Networks,Cristiano M Silva; Wagner Meira Jr,Abstract—There are several kinds of envisioned vehicular applications: video delivery;accidents detection; dissemination of traffic announcements; and so forth. Such applicationsdemand minimal (and possibly distinct) Quality of Service guarantees that must couple thevehicular network. Given that vehicular networks will hit the streets soon; we demandstrategies for planning and managing such networks. In this work we propose the concept ofa Delta Network: the Delta Network is a metric for evaluating the performance of vehicularnetworks. By using the concept of a Network Delta; we expect network providers being ableto measure and compare the performance of distinct heterogeneous vehicular networks(Delta is technology-independent). Finally; the concept of a Delta Network may also beapplied to couple vehicular applications and vehicular networks in order to support the …,*,*,*
Caracterizaç ao Temporal das Redes de Colaboraç ao Cientıfica nas Universidades Brasileiras: Anos 2000-2013,Michel Boaventura; Karina Boson; Ana Paula Couto da Silva; Adriano Veloso; Wagner Meira Jr,Abstract. The temporal analysis of scientific collaboration networks is crucial forunderstanding the emergence of new areas of research as well as the evolution of theimpact of the scientific production. Furthermore; effective grant policies can be defined. Thispaper presents the study of the evolution of the Brazilian scientific collaboration network;through classical metrics of complex networks as well as endogamy and stable researchgroups metrics. Resumo. A análise temporal de redes de colaboraçao cientıfica é deextrema importância para o entendimento do surgimento de novas áreas de pesquisa; bemcomo da evoluçao do impacto da produçao cientıfica das Universidades. Além disso;polıticas mais eficazes de financiamento de projetos podem ser definidas. Este artigoapresenta o estudo da evoluçao da rede de colaboraçao cientıfica no Brasil; através de …,*,*,*
Competence-Conscious Associative Classification,Adriano Velosoa; Mohammed Zakib; Wagner Meira Jr; Marcos Gonçalvesa,Abstract The classification performance of an associative classifier is strongly dependent onthe statistic measure or metric that is used to quantify the strength of the association betweenfeatures and classes (ie; confidence; correlation etc.). Previous studies have shown thatclassifiers produced by different metrics may provide conflicting predictions; and that thebest metric to use is data-dependent and rarely known while designing the classifier. Thisuncertainty concerning the optimal match between metrics and problems is a dilemma; andprevents associative classifiers to achieve their maximal performance. This dilemma is thefocus of this paper. A possible solution to this dilemma is to learn the competence; expertise;or assertiveness of metrics. The basic idea is that each metric has a specific sub-domain forwhich it is most competent (ie; it consistently produces more accurate classifiers than the …,*,*,*
Um modelo baseado na evolução temporal de consumo e sua aplicação em domínios de recomendação,Camila Araújo; Fernando Mourão; Wagner Meira Jr,Resumo Em domínios de recomendação o gosto dos usuários; bem como o própriodomínio; varia ao longo do tempo. Porém; essa evolução é pouco compreendida naliteratura. Um maior entendimento deste processo permitiria melhorar as recomendações.Neste trabalho; modelamos a evolução temporal de forma a identificar itens potencialmenterelevantes para recomendação. Utilizamos o conceito de transições evolutivasrepresentativas; transições entre quaisquer par de itens ao longo do tempo; e extraímos taistransições através da modelagem proposta. Além disso; realizamos experimentos paravalidar nossa premissa de que transições evolutivas representativas existem e são:mensuráveis; relevantes; úteis e não óbvias.,Revista de Iniciação Científica,*,*
Uma Análise do Custo do Tráfego de Spam para Operadores de Rede,Osvaldo Fonseca; Elverton Fazzion; Ítalo Cunha; Pedro Henrique B Las-Casas; Dorgival Guedes; Wagner Meira Jr; Cristine Hoepers; Klaus Steding-Jessen; Marcelo HP Chaves,Abstract. Spam messages are used to disseminate malware; make phishing attacks; andadvertise illegal products. Spam generates costs to users; eg; victims of phishing; and tonetwork administrators; eg; who provision and pay for the traffic. Recent proposals aim toidentify and filter spam messages at the origin; restraining message propagation andreducing wasted bandwidth on the route from the spammer to the destination. In this workwe analyze spam traffic costs for network operators. We measure the routes traversed byreal spam messages colected at five honeypots; and estimate spam traffic costs according tothe business relationships between networks traversed on each route. We show that stubnetworks are systematically encumbered by high spam traffic costs but can cooperate to filterup to 70% of spam messages at the origin. Our results also indicate that transit networks …,*,*,*
Anthill: A Filter-Stream Based Run-Time Framework for Heterogenous Parallel and Distributed Environments,Renato Ferreira; George Teodoro; Thiago Teixeira; Bruno Coutinho; Wagner Meira; Dorgival Guedes; Umit Catalyurek,ABSTRACT There is an increasing demand for performing expensive computations on largevolumes of data; making the use of parallel and distributed platforms a natural approach foraddressing these requirements. The current trend while building such platforms is to employmultiple machines containing multiple processors; each processor comprising multiplecores; which allows the exploitation of multiple levels of parallelism. However; developingefficient and scalable applications that exploit efficiently those levels remain a challenge;because both the application requirements are very diverse; and a large portion of theapplications is irregular; so that their characteristics and requirements change within asingle execution. In this paper we present Anthill; a runtime framework that supportsscalable and efficient parallelization of a wide range of applications on a variety of …,*,*,*
LA-WEB 2014,Wagner Meira Jr,Abstract: Provides an abstract for each of the keynote presentations and a brief professionalbiography of each presenter. The complete presentations were not made available for publicationas part of the conference proceedings … A not-for-profit organization; IEEE is the world's largesttechnical professional organization dedicated to advancing technology for the benefit ofhumanity. © Copyright 2017 IEEE - All rights reserved. Use of this web site signifies your agreementto the terms and conditions.,*,*,*
LA-WEB 2014,Gustavo Nascimento; Manoel Ribeiro; Loïc Cerf; Natália Cesário; Mehdi Kaytoue; Chedy Raïssi; Thiago Vasconcelos; Wagner Meira Jr,Modeling and Analyzing the Video Game Live-Streaming Community ..................................................1 Gustavo Nascimento; Manoel Ribeiro; Loïc Cerf; Natália Cesário; Mehdi Kaytoue; ChedyRaïssi; Thiago Vasconcelos; and Wagner Meira Jr … A User Interface Stereotype to Build WebPortals................................................................................10 Sofia Larissa da Costa; Valdemar VicenteGraciano Neto; and Juliano Lopes de Oliveira … It is Not Just a Picture: Revealing Some UserPractices in Instagram .................................................19 Camila Souza Araújo; Luiz Paulo DamiltonCorrêa; Ana Paula Couto da Silva; Raquel Oliveira Prates; and Wagner Meira Jr … ResearchSession 2: Data Mining and Learning Techniques … A Rendering-Based Method for Selectingthe Main Data Region in Web Pages....................................................................................................................................................24 Leandro Neiva Lopes Figueiredo; Anderson Almeida …,*,*,*
Lazy Associative Classification: Why it Works?,Adriano Velosoa; Wagner Meira Jr; Mohammed J Zakib,*,*,*,*
Interactive and Resource-Efficient Data Mining for Frequent Patterns in Multi-User Environments,Tiago Prado; Raquel Melo; Adriano Veloso; Wagner Meira Jr,*,*,*,*
Twig: An Adaptable and Scalable Distributed FPGrowth,Rubens Moreira; Bruno Coutinho; Filipe Arcanjo; Rodrigo Rocha; Wagner Meira Jr; Dorgival Guedes; Renato Ferreira,*,*,*,*
Combinando Interaç oes de Endosso e Comunicaç ao em Redes Sociais Multipolarizadas,Pedro H Calais Guerra; Wagner Meira Jr,Abstract. Polarized social networks arise from domains where people have two conflictingand opposing viewpoints regarding an issue; such as abortion; gun control and same-sexmarriage. However; in many real scenarios; multiple positions can be adopted in relation toa topic; as in multipartisan political systems and sports competitions. In this work; we showthat multipolarized social networks unveil inconsistencies and simplistic assumptions onmodels that deal with bipolarized networks. In particular; we find that the proximity of a pairof users in the social network does not necessarily implies sharing of viewpoints. Moreover;we propose a simple model that capture relationships of support; antagonism andindifference which can be seen on multipolarized networks; by combining endorsement andcommunication interactions among users. Resumo. Redes sociais polarizadas …,*,*,*
Vizinhanças ou condomınios: uma análise da origem de spams com base na organizaç ao de sistemas autônomos,Osvaldo Fonseca; Pedro Henrique B Las-Casas; Elverton Fazzion; Dorgival Guedes; Wagner Meira Jr; Cristine Hoepers; Klaus Steding-Jessen; Marcelo HP Chaves,Abstract. Despite the continuous efforts to mitigate spam; the volume of messages is hugeand identifying spammers is still a challenge. Spam traffic analysis has been performed todetermine the behavior of spammers; who are employing techniques more and moresophisticated to disseminate messages. This work analyzes the sources of spam towardsunderstanding to what extent they explain the traffic. Our results show that; beyond a similarbehavior among machines from the same autonomous system (AS); it is possible toseparate them according to their sending characteristics. Further; the results also show thatwe may apply the concept of Internet BadNeighborhoods to ASes; once the machines from agiven AS behave similarly. Resumo. Apesar dos esforços contınuos para combater o enviode spam; o volume de mensagens enviadas é muito grande e a identificaç ao dos …,*,*,*
SBAC-PAD 2013,Manoel Eusebio de Lima; Wagner Meira Jr,We are pleased to welcome you to the 25th International Symposium on ComputerArchitecture and High Performance Computing-SBAC-PAD 2013; held this year in Porto deGalinhas; Brazil. In 1996; we also hosted SBAC-PAD in Recife and we are very glad for thehonor and opportunity to do it again this second time.,*,*,*
Caracterização do uso de hashtags do Twitter para mensurar o sentimento da população online: Um estudo de caso nas Eleições Presidenciais dos EUA em 2012,Adriano Veloso; Wagner Meira Jr,Resumo. Neste artigo; descrevemos os resultados parciais e as direções futuras de umapesquisa em andamento; cujo objetivo principal é analisar se a opinião expressa através dehashtags do Twitter pode contribuir para identificar e monitorar o sentimento da populaçãoonline em relação a diferentes tópicos. Uma vez confirmada essa contribuição; esse tipo dehashtag pode ser utilizada como insumo para aplicações que visam detectar e monitorarautomaticamente o sentimento das pessoas; sobre eventos ou tópicos específicos;expresso a partir do grande fluxo de dados proveniente das mídias sociais. Abstract. In thispaper we describe the partial results and future directions of a research in progress; whichmain goal is to analyze whether the opinion expressed through Twitter hashtags can help toidentify and track online sentiment. Once confirmed this contribution; this type of hashtag …,*,*,*
" Information Technologies for Visually Impaired People,Paolo Boldi; José-María Gómez-Hidalgo; Gianna M Del Corso; Antonio Gullì; Francesco Romani; Arturo Montejo-Raez; Mª Teresa Martín-Valdivia; Silva de Moura; Altigran Soares da Silva; Carlos A Heuser; Wagner Meira Jr; Vassilis Plachouras; Miguel Fumero-Reverón; Fernando Sáez-Vacas; Philippe Draguet,As the amount of information and usage of the Web increases; so does its economic valueand the interest in abusing it. Since search engines are the most prominent entry point to theWeb; they are the focus of complex attacks named Search Engine Spam. Other forms ofabuse include surfing inappropriate Web contents in schools; libraries and,*,*,*
ProContactVisio: Visualizing Protein Intramolecular Contacts,Sabrina de A Silveira; Valdete MG Almeida; Raquel C Melo-Minardi; Wagner Meira Jr,*,*,*,*
Sistemas de Reputação: Arquitetura; Propriedades e Desafios,Bruno Dias Abrahão; Fernando Caixeta Sanches; Wagner Meira Jr,The construction of online communities is a task which involves challenges not onlytechnological; but also sociological. Trust has always been crucial to the accomplishment oftransactions between partners. Providing the construction of this trust; measured asreputation; is a necessity in such environments due to the impersonality of the relationshipsand the lack of information about the participants. This work describes aspects of thearchitecture of reputation systems and the minimun set of properties required for a robustmanagement of trust metrics. Following this; we consider a implementation that in addition tomaking it able to evaluate the discussed properties; it also reveals the challenges faced inthe design of reputation systems in online environments.,*,*,*
Monitoração e Análise de Desempenho do Sistema,A Pereira; E Kraemer; W Meira Jr; C Amorim; COPPE Sistemas-UFRJ,Resumo A paralelização de aplicações~ em como grande a~ ra~ ivo a redução do tempocompu~ acional necessário para a sua execução. O desenvolvimenw de aplicaçõesparalelas eficientes; entretan~ o; é freqüen~ emenw uma tarefa árdua; principalmente emrazão da complexidade das aplicações; arquiteturas e interações entre elas. No caso daarquitetura NCP2; a inovação representada pelo hardware e os protocolos de coerência dememória específicos tornam essa tarefa ainda mais árdua; não apenas para programadorescomo para os próprios proje~ istas. Esse artigo apresenta uma proposta para a monitoraçãoe análise de desempenho da arquite~ ura NCP2. Essa proposta foi implementada sobre umemulador da arquitetura e a ferramenta resultante é apresentada e discutida em detalhes.,*,*,*
Páginas Iniciais-WSCAD 2006,Gerson Geraldo H Cavalheiro; Mario Dantas; Wagner Meira Jr,Biblioteca Digital Brasileira de Computação - Apoio: Sociedade Brasileira de Computação -Realização: Laboratório de Banco de Dados (DCC da UFMG).,*,*,*
SPD: Um núcleo de programação distribuída em redes de computadores,Wilton S Caldas; Daniel Calvo; Renato AC Ferreira; Wagner Meira Jr; Osvaldo SF Carvalho,Resumo Este artigo descreve o SPD; um sistema de programação distribuída para redes deestações de trabalho; que funciona em plataformas UNIX onde se tenham disponíveis oprotocolo TCP/IP e a biblioteca TLI. O sistema é composto basicamente por trêsferramentas: um servidor; que é o responsável pela gerência do sistema e das trocas demensagens; uma biblioteca de funções; que fornece ao usuário o subsídio necessário paraa utilização dos recursos oferecidos pelos servidores: e; finalmente; um programa queinstancia as aplicações do usuário no sistema distribuído.,*,*,*
Páginas Iniciais-WSCAD 2003,Carlos AP da Silva Martins; Wagner Meira Jr; Edson T Midorikawa; Liria Matsumoto Sato,Biblioteca Digital Brasileira de Computação - Apoio: Sociedade Brasileira de Computação -Realização: Laboratório de Banco de Dados (DCC da UFMG).,*,*,*
eCache: uma Cache Cooperativa para Servidores de Comércio Eletrônico Baseados em Cluster,Silvano Dias; Anderson Silva; Thobias Trevisan; Wagner Meira Jr; Claudio Amorim; Laboratório de Computação Paralela-COPPE Sistemas,Resumo A popularidade do comércio eletrônico na WWW tem aumentado a demwula sobreos servidores; degradando seu desempenlw<'exigindo assim; novas soluç< ies paraassegurar sua qualidade de sen; iço. Normalmente um dos principais limitadores dodesempenho e escalabilidade do servidor é o gerenciador de banco de dados. Nestetrabalho. inflvduzimos a eCache; uma cache cooperativa no ntvel da aplicação quecombina os modelos de pmgramação de memória compartilhada e dt'passagem de men·sagens. afim de diminuir o número de acessos ao banco de dados e melhorar aescalabilidade de servidores de comércio eletrônico baseados em clustet: Nós avaliamosos potenciais beneftcios da eCache medindo o desempenho de um protótipo de livrariavirtual. submetido a uma carga de trabalho gerada a partir de wn log real. Nossos …,*,*,*
ApaMon: uma Ferramenta para Monitoramento do Fenômeno de Envelhecimento de Software do Apache,Frederico Marvila de Oliveira; Humberto Torres Marques Neto; Wagner Meira Jr; Virgílio Augusto F Almeida,Com o crescimento e a popularização de sistemas distribuídos; principalmente os queutilizam recursos da Internet; torna-se premente a necessidade de monitoramento dossoftwares que criam a infra-estrutura para funcionamento desses sistemas; onde sedestacam os servidores Web; como por exemplo o Apache. O software pode" envelhecer"precocemente a partir de situações inesperadas; longos períodos de execução; ou atémesmo em decorrência da incompatibilidade com os demais componentes de um sistemade computação; sendo uma de suas consequências a queda de sua performance. É nessecenário que será utilizado o ApaMon; pois ele provê de forma fácil e prática várias maneirasde se monitorar o Apache; permitindo uma ação mais rápida; caso seja identificado umcomportamento anormal deste. Para impedir uma maior queda de performance do …,*,*,*
Modelagem e Análise de Desempenho de uma Aplicação Paralela Utilizando Lost Cycles Toolkit,MCS de Castro; W Meira Jr; CL de Amorim,RESUMO Neste trabalho realizamos a modelagem e o desempenho de uma aplicaçãoparticular na área de processamento sísmico. Para isso; utilizamos o Lost Cycle Toolkit; quese baseia principalmente em medidas dinâmicas dos programas de aplicação. O toolkit usaa priori o conhecimento das fontes e características de overhead em um sistema paralelopara guiar o processo de modelamento e avaliar o desempenho. Podem ser medidos odesbalanceamento de carga; o paralelismo; as perdas por sincronização; por comunicaçãoe por contenção de recursos. Com este experimento foi possível observar o comportamentoda aplicação quando submetida a uma quantidade variável de processadores.,*,*,*
Servidores cache www em arquiteturas multiprocessadas,G Paixao; Wagner Meira Jr; F Sanches,Resumo-O grande crescimento em popularidade da World Wult Wtb tem motivado váriaspesquisas com o objetivo de reduzir a latência observada pelos usuários. Os servidorescache têm se mostrado uma ferramenta muito importante na busca desse objetivo. Emboraa utilização de servidores cache tenha contribuído para diminuir o tráfego na Internet; asestratégias de cooperação utilizadas na composição de grupos (clusters) de cachesnormalmente trazem uma degradação de desempenho aos servidores não sendo; por isso;escaláveis o suficiente para acompanhar o crescimento atual da WWW. Neste trabalho;propomos uma nova forma de cooperação entre servidores cache que não cause umimpacto tão grande no seu desempenho; permitindo; assim; a criação de grupos deservidores cache que sejam capazes de crescer junto com a demanda dos seus usuários …,Anais do XI SBAC-PAD,*,*
Paralelizaç ao do Algoritmo de Migraç ao Sısmica em Plataformas Heterogêneas,Thiago SFX Teixeira; Wagner Meira Jr; Jairo Panetta; Banca Avaliadora; Siang W Song; Dorgival O Guedes Neto; Renato Antônio C Ferreira; Belo Horizonte–MG–Brasil,Abstract. Petrobras daily uses Kirchhoff seismic migration to search for new oil and gasreserves. Kirchhoff is a CPU bound algorithm—a single run may use up to 1000 dedicatedx86 cores during a month. The emergence of novel parallel computing architectures; suchas GPUs; poses an oportunity and a challenge to reduce such execution times. In this thesis;we discuss the parallelization of the Kirchhoff seismic migration for an heterogeneousenvironment with CPUs and GPUs. We search and evaluate parallelism strategies thateficiently use the available hardware. We explore parallelism opportunities; by designing;implementing and evaluating various possible configurations. We also devise andimplement a finer grain dynamic scheduling for the devices; achieving highly efficientexecutions. Experiments show an acceleration of up to 87 times over a single x86 core …,*,*,*
Information and Communication Technologies and Development Program Committee,John Canny; John Chuang; Chris Coward; Uday Desai; Jonathan Donner; Pat Hall; Richard Heeks; Arding Hsu; Heather Hudson; Mahad Ibrahim; Ashok Jhunjhunwala; S Keshav; James Koch; Beth Kolko; Richa Kumar; Shirin Madon; Wagner Meira; Brian O'Connell; Joyojeet Pal; Tapan Parikh; Balaji Parthasarathy; Francisco Proenza; Krithi Ramamritham; Raul Roman; Tony Salvador; Eswaran Subrahmanian; Lin Mi Tao; Rahul Tongia; Ernest Wilson,Chair: Kentaro Toyama (Microsoft Research India) Jessica Aalami (UC Berkeley) P. Anandan(Microsoft) Richard Anderson (University of Washington) Akhtar Badshah (Microsoft) V. Balaji(ICRISAT) Anupam Basu (Indian Institute of Technology; Kharagpur) Mike Best (GeorgiaTech) Subhash Bhatnagar (Indian Institute of Management; Ahmedabad) Eric Brewer (UCBerkeley) John Canny (UC Berkeley) John Chuang (UC Berkeley) Royal Colle (Cornell) ChrisCoward (University of Washington) Uday Desai (Indian Institute of Technology; Bombay) BernardineDias (Carnegie Mellon - Qatar) Jonathan Donner (Microsoft) Kevin Fall (Intel) Ajay Gupta (HPLabs) Pat Hall(Open University) Richard Heeks (University of Manchester) Bill Hefley (CarnegieMellon University) Arding Hsu (Siemens-China) Heather Hudson (University of SanFrancisco) Mahad Ibrahim (UC Berkeley) Ashok Jhunjhunwala (Indian Institute of …,*,*,*
Projeto Tamanduá: Uma Aplicação de Alto Desempenho que deu certo,Wagner Meira,*,*,*,*
Nicolas Maillard Evangelos Markatos Osni Marques Marcos AD Martins,Josilene Aires; Jose Nelson Amaral; Claudio Amorim; Rafael Bohrer Ávila; Rosa M Badia; Valmir C Barbosa; Marcos Ennes Barreto; Carla Osthoff de Barros; Luiz Andre Barroso; Eduardo W Bergamini; Paul Berube; Ricardo Bianchini; Cristian Borcea; Luiz Maltar Castello Branco; Francisco Vilar Brasileiro; Enrique V Carrera; Luís Gustavo Castanheira; Wen-Ke Chen; Walfredo Cirne; Luis Augusto Consularo; Manuel Eduardo Correia; Vitor Santos Costa; Alvaro LGA Coutinho; Mark Crovella; Jeff Draper; José Duato; Ines de Castro Dutra; Sandhya Dwarkadas; Dênis Fernandes; Edil Fernandes; Renato Ferreira; Tiago Coelho Ferreto; Felipe MG França; Cláudio Geyer; Ronaldo AL Goncalves; Dorgival Guedes; Ziang Hu; Alessandro Noriaki Ide; Liviu Iftode; Edison Ishikawa; Dongsoo Kang; Sergio T Kofuji; Xiaobin Li; Rafael Dueire Lins; Marcelo Lobosco; Luis Lopes; Ricardo Lopes; Orlando G Loques; Jizhu Lu; Wagner Meira Jr; Elmar Melcher; Alba Melo; Celso L Mendes; Edson T Midorikawa; Enric Musoll; Philippe Navaux; Mario Nemirovsky; Jairo Panetta; Ron Perrott; Maurício Lima Pilla; Eduardo Pinheiro; Murali Rangarajan; Vinod Rebello; Wonwoo Ro; Ricardo Rocha; Jose Hiroki Saito; Hirofumi Sakane; Rafael Santos; Liria Matsumoto Sato; Renato Silva; Horst Simon; Siang W Song; Patricia Kayser Vargas; DeLiang Wang,*,*,*,*
Caracterizaç ao Temporal de Estratégias de Disseminaç ao de Spam,Luam C Totti; Rubens EA Moreira; Elverton Fazzion; Osvaldo Fonseca; Wagner Meira Jr; Dorgival Guedes; Cristine Hoepers; Klaus Steding-Jessen; Marcelo HP Chaves,Abstract. In this work we present a characterization of spam campaign disseminationstrategies; emphasizing their temporal aspects. Our analysis is based on spam campaignsdetected in 1.1 billion messages collected in eight countries using low interactivityhoneypots during a three-month period. We present a temporal analysis of the messagesgrouped both by campaigns and IP addresses; observing aspects such as message inter-arrival times; usage bursts; and inactivity periods. We also discuss how the observedbehaviors can be used in the design and evaluation of spam prevention systems. Resumo.Neste trabalho apresentamos uma caracterizaçao de estratégias empregadas nadisseminaçao de campanhas de spam; com enfoque em aspectos temporais. Nossasanálises se baseiam nas campanhas de spam detectadas a partir de 1; 1 bilhao de …,*,*,*
Caracterizaç ao de Padroes Estruturais de Redes Polarizadas,Pedro H Calais Guerra; Wagner Meira Jr,Abstract. Polarized networks are social networks that are increasingly gaining attention fromresearchers; social scientists and marketing agents. Such networks are found in manycontexts in which individuals organize themselves into opposing groups; since they haveideas; goals and viewpoints which are confliting. Such networks are found in relevantcontexts such as Politics; Sports and many polemic topics debated on our society. However;in the literature we do not find an accurate and coherent definition of what a polarizednetwork is. In this work; we show that the currently accepted conceptualization of a polarizednetwork–networks which exhibit communities with high degree of cohesion–is not enough toclassify a network as a polarized network; since that non-polarized networks (such asfriendship networks) also exhibit such property. Our major contribution is to demonstrate …,*,*,*
Análise de Padroes de Propagaç ao no Twitter,Arlei Silva; Fernando Mourao; Lıvia Simoes; Nathan Mariano; Wagner Meira Jr; Walter Santos; Gisele Pappa; Adriano Veloso,Abstract. As a consequence of the popularization of the social networks; analyzing theinformation propagation in such networks has become a relevant task in several scenarios.Propagation patterns support the understanding of phenomena such as opinion formationand the emergence leaders in social networks. In this paper we present a methodology forpropagation analysis on Twitter; the most popular micro-blogging service in the Webcurrently. Challenges related to the efficiency and scalability of the methodology aredescribed and evaluated through its application in a real site; the Observatorio da Web.Resumo. Com a popularizaçao das chamadas redes sociais; analisar a propagaçao deinformaçao nessas redes se tornou uma tarefa relevante em diversos contextos. Padroes depropagaçao podem permitir o entendimento de fenômenos como a formaç ao de opiniao …,*,*,*
Gerindo: New Technologies for Processing Information on Electronic Documents,Mara Abel; Joao MB Cavalcanti; Renato A Ferreira; Carlos A Heuser; Alberto HF Laender; Wagner Meira; Edleno S de Moura; Berthier A Ribeiro-Neto; Altigran S Da Silva; Nivio Ziviani,Abstract We present here a summary of the main developments obtained in the first twoyears of the Gerindo research project. The aim of this project is to address the increasingdemand for software capable of dealing with information stored in large documentdatabases; such as the World Wide Web. It unifies efforts of researchers from three differentBrazilian universities to develop core technologies to most of the applications related toprocessing documents demanded by the new information society. These efforts areconcentrated in five main research areas: document categorization; semi structured datamanagement; information retrieval models; efficiency for information retrieval and datamining. Besides the important contributions related to the five main areas of study describedhere; the interaction of researchers is starting to produce; as a side effect; the combination …,*,*,*
Gerindo: New Technologies for Processing Information on Electronic Documents,Alberto HF Laender; Altigran S da Silva; Berthier A Ribeiro-Neto; Carlos A Heuser; Edleno S de Moura; Joao MB Cavalcanti; Mara Abel; Nivio Ziviani; Renato A Ferreira; Wagner Meira,*,*,*,*
Uma Estratégia Eficiente para Balanceamento de Carga em Algoritmos de Mineraç ao de Conjuntos Frequentes,Fernando Mourao Luciano Lanna Adriano Veloso; Wagner Meira Jr; Renato Ferreira Dorgival Guedes,Resumo Mineraçao de dados compreende um conjunto de técnicas para extraçaoautomática de informaçoes a partir de grandes bases de dados; atividade cada vez maisfundamental tendo em visto o acúmulo contınuo e crescente de dados e uma carênciacrescente de extrair informaçoes úteis a partir desses dados. Uma estratégia comum paraatender essa demanda é a paralelizaçao dos algoritmos; os quais; tendo em vista anatureza irregular de muitas das técnicas de mineraçao de dados; tendem a apresentarsignificativo desbalanceamento de carga. Neste artigo avaliamos algumas estratégias debalanceamento de carga para algoritmos paralelos de mineraçao de dados e discutimos oscompromissos entre balanceamento estático e dinâmico. Também propomos e avaliamosuma nova técnica de balanceamento de carga que leva em consideraçao as …,*,*,*
O Projeto do Computador Popular,Wagner Meira; Sérgio Campos; Dorgival Guedes,*,*,*,*
ESTUDO 35: POLÍTICAS DE ACESSO: EQUIPAMENTOS; ALFABETIZAÇÃO E CAPACITAÇÃO DIGITAL; PRODUÇÃO E CONVERGÊNCIA DE CONTEÚDOS (TECN...,Virgilio Almeida; Wagner Meira Jr; Eduardo Costa; Simone Wajnman,Antes de apresentarmos um diagnóstico; consideramos que seria interessanteconceituarmos o que é inclusão digital e apresentarmos um breve histórico de ações deinclusão digital no Brasil. A seguir fazemos uma discussão com base nos indicadores quesão pertinentes; provendo os elementos necessários para realizar o diagnóstico do quadroinstitucional.,*,*,*
ANÁLISE DE TRÁFEGO INTERNET DE BANDA LARGA,Humberto Torres Marques Neto; Virgílio Augusto Fernandes Almeida; Wagner Meira Jr; Jussara Marques de Almeida,*,*,*,*
Uma Hierarquia para Caracterizaçao de Live Streaming Media,Eveline Veloso; Virgilio Almeida; Wagner Meira Jr,*,*,*,*
Caracterização de Carga de Redes Peer-to-Peer,Juliano Santos; Leonardo Rocha; Diêgo Nogueira; Paulo Araújo; Virgílio Almeida; Wagner Meira Jr,Peer-to-Peer networks came up recently with the goal of making possible the sharing ofcomputacional resources via Internet. So far; there is no definitive characterization of thebehavior for these networks. Because of some of their characteristics; the adoption ofspecialized strategies for their characterization becomes necessary. We present in thisarticle a workload characterization methodology for Peer-to-Peer networks that addressthese characteristics. To validate the methodology; we performed a case study with Gnutellanetwork; getting important results out of it. We identify; among others; the statisticaldistributions that characterize the shared files; the availability of the servents and thefrequency of the words in the search patterns at gNet.,*,*,*
Uma Metodologia para a Caracterizaçao de Comportamento Evolutivo em Sistemas de Recomendaçao,Alan Cardoso; Walkiria Resende; Daniel Rocha; Fernando Mourao; Leonardo Rocha; Wagner Meira Jr,Resumo. Sistemas de Recomendaçao (SRs) tornaram-se ferramentas de crescenterelevância para variadas aplicaçoes comerciais na Web. Apesar de muitos esforços; SRsainda requerem melhorias para tornar a recomendaçao mais eficaz e aplicável a várioscenários reais. Estudos recentes apontam a evoluçao temporal como uma forma primordialde melhorar SRs sem; entretanto; entender em detalhes como essa evoluçao se manifesta.Assim; propomos uma metodologia de caracterizaçao evolutiva de usuários e aplicaçoes afim de prover um maior entendimento sobre a dinâmica temporal em SRs. A aplicaçao dametodologia em um cenário real mostrou-se útil inclusive para auxiliar na escolha de SRsmais aderentes a cada cenário. Abstract. Recommender Systems (RSs) have becomeincreasingly important tools for various commercial applications on the Web. Despite …,*,*,*
Um Agente de Controle de Privacidade na Web,Fabiano Magalhaes Atalla da Fonseca; Robert Pereira Pinto; Wagner Meira Jr,Abstract. People usually provide personal information when visiting Web sites; even thoughthey are not aware of this fact. In some cases; the collected data is misused; resulting onuser privacy violation. The existing tools which aim at guaranteeing user privacy usuallyrestrict access to personalized services. In this work; we propose the Web Privacy ControlAgent. Upon detecting and informing users about browsing tracking mechanisms whichinvisibly collect their personal information when visiting sites; it represents an alternative thatprovides a better control over privacy while allowing personalization. Through experimentalresults; we demonstrate the applicability of our approach by showing that typically 5.37% ofuser's requests are tracked by third-party sites. Resumo. Pessoas navegam na Webrepassando informaç oes pessoais de forma consciente ou inconsciente. Em alguns …,*,*,*
Gerindo: New Technologies for Managing and Processing Information in Documents,Nivio Ziviani1 Edleno S de Moura; Alberto HF Laender; Altigran S da Silva; Berthier A Ribeiro-Neto; Carlos A Heuser; Joao MB Cavalcanti; Mara Abel; Renato A Ferreira; Wagner Meira Jr,Abstract We present in this report a summary of the main results produced in the first twoyears of the Gerindo research project. The aim of this project is to address the increasingdemand for software capable of dealing with information available in large documentcollections; such as the World Wide Web. It involves efforts of researchers from threeBrazilian universities to develop core technologies for a number of document managementapplications demanded by today's information society. These efforts are concentrated in fivemain research topics: document categorization; semistructured data management;information retrieval models; efficiency issues in information retrieval; and data mining.Besides specific contributions in these five research topics; the project has stimulated theinteraction among the researchers of the three universities who have worked together to …,*,*,*
Mineração incremental de regras de associação,Bruno Pôssas; Adriano Alonso Veloso; Gustavo Menezes Siqueira; Wagner Meira Jr; Márcio Luiz Bunte de Carvalho,A utilização efetiva e contínua de técnicas de mineração de dados e di? cultada pelaconstante adição de novas transações; que resultam em bases de dados enormes; e pormudancas nos critérios utilizados na atividade de mineração; no caso de regras deassociação; o suporte e a con? anca. O problema neste caso e que esse dinamismo podeinvalidar algumas regras existentes e provocar o surgimento de novas regras relevantes.Neste artigo apresentamos PELICANO; um algoritmo e? ciente para geração incrementalde regras de associação; que se baseia apenas nos itemsets maximais frequentes e naocorrência de itens em transações para atualizar a base de regras de associação. Ositemsets maximais são usados para realizar uma enumeração descendente de todos ositemsets frequentes; minimizando o número de conjuntos candidatos processados para a …,*,*,*
Análise e Entendimento de Desempenho com a Ferramenta Antfarm,R Pinho T Teixeira Y Faria; G Teodoro T Tavares; D Guedes R Ferreira; W Meira Jr,Resumo O projeto e implememação de aplicações para/elizadas escaláveis e eficientes semantem como um desafio; seja pela complexidade das aplicações e dos dados a seremanalisados; seja pelas limitações dos paradigmas atuais de programação paralela paraaplicações de alta demanda de processamento e comunicação como mineração de dados.O ambiente Anthi/1; baseado no paradigma filtro-fluxo identificado; tem se mostrado comoum ambiente apropriado para para/e/ização dessas aplicações; permitindo explorar trêsestratégias de parale/ização: dados; tarefas e assincronia. Entretanto; o entendimento e adepuração de desempenho dessas aplicações pode ser complexo; dada a diversidade depadrões de interação permitida pelo ambiente Anthi/1. A ferramenta Antfarm tem porobjetivo não apenas apresentar o perfil de desempenho da aplicação mas identificar as …,*,*,*
A Privacy-Preserving Architecture that allows Personalization of Web Services,Bruno Gusmão Rocha; Adriano Alonso Veloso; Lucila Ishitani; Virg lio Almeida; Wagner Meira Jr,*,*,*,*
Cause-E ect Analysis of Parallel Program Performance,Wagner Meira Jr; Thomas J LeBlanc,Abstract This paper describes a general framework and several speci c techniques for cause-e ect analysis: an automated inference process that presents explanations for dynamicphenomena of parallel program executions in terms of underlying causes and the relatedsource code. We illustrate the framework by describing the implementation of three analysistechniques: waiting time analysis identi es the cause of synchronization overhead as the dierences in execution paths taken by synchronizing processors; protocol analysis identi esthe sharing patterns to pages that produce invalidations in a DSM protocol; and transactionanalysisidenti es con icts between transactions in a parallel le system that cause aborts. Wepresent examples of how each technique can be used to understand observed performancee ects; and how insights derived from these techniques suggest program modi cations …,*,*,*
Proxy Ativo: Diminuindo a Lat encia atrav es de Pushing,Bruno Gusmão Rocha; Adriano Alonso Veloso; Wagner Meira Jr; Virgilio AF Almeida,Abstract The majority of the Internet users still access the Web via slow modem connections.Studies have shown that the limited modem bandwidth is the main contributor to the latencyperceived by users. In this paper we introduce one approach to reduce the latency bypushing between proxies and its clients; in special low-bandwidth clients. The approachtakes advantage of idle periods between requests to pull proxy-cached objects which will beprobably accessed next by the client. We use data mining concepts to develop a efficientprediction model and evaluate the potential of this technique at reducing client latencythrought simulations based on real workloads from a major proxy in Minas Gerais.,*,*,*
MPM: Middleware para Gerência de Energia em Clusters Web,Dorgival Guedes; Wagner Meira Jr; Diêgo Nogueira; Rodrigo Pereira,Considering the fast growth of the World Wide Web; servers for popular sites are designed tohandle peak workload levels that may exceed by orders of magnitude average levels duringmoments of lighter load. This excess processing capacity leads to an extra energycomsumption. The development of applications capable of handling energy consumptionlevels require efficient solutions to isolate application demands; in terms of latency andthroughput; from hardware details. This paper presents a middleware solution designed toachieve that. It uses control theory techniques to associate demands for satisfactoryperformance with energy saving goals. To verify the efficacy of the proposed solution weapplied it to a three-server Web cluster under typical workloads. The use of the middlewareproduced energy savings of 27% without significant impacts on the average latency and …,*,*,*
Applications and Algorithms Track-Chair,Albert Zomaya; Kunle Olukotun; Luiz de Rose; Rodolfo Azevedo; Claudine Badue; Maria Claudia Silva Boeres; Elias de Oliveira; Maria Cristina Rangel; Thomas Walter Rauber; Claudio Amorim; Ricardo Bianchini; Rajkumar Buyya; Alberto F De Souza; Jean-Luc Gaudiot; Wagner Meira Jr; Edson Midorikawa; Philippe Navaux; Jairo Panetta; Vinod Rebello; Liria Sato; Bruno Schulze; Siang Song,Page 1. Committees General Chair Alberto F. De Souza; Federal University of Espírito Santo;Brazil Lucia Catabriga; Federal University of Espírito Santo; Brazil Program Chairs Jean-LucGaudiot; University of California at Irvine; USA Alba Cristina MA de Melo; University of Brasília;Brazil Applications and Algorithms Track - Chair Albert Zomaya; University of Sydney; AustraliaArchitecture Track - Chair Kunle Olukotun; Stanford University; USA Software Track - Chair Luizde Rose; Cray Inc.; USA Organizing Committee Rodolfo Azevedo; State University of Campinas;Brazil Claudine Badue; Federal University of Espírito Santo; Brazil Maria Claudia Silva Boeres;Federal University of Espírito Santo; Brazil Elias de Oliveira; Federal University of Espírito Santo;Brazil Maria Cristina Rangel; Federal University of Espírito Santo; Brazil Thomas Walter Rauber;Federal University of Espírito Santo; Brazil …,*,*,*
Escalabilidade e Eficiência em Mineraç ao de Dados de Aplicaç oes Internet,Wagner Meira Jr; Renato Ferreira; Dorgival Guedes,Resumo. A Internet foi muito além de um artefato tecnológico; passando a ser uminstrumento crescente de interaçao social. Essas interaçoes sao usualmente complexas edifıceis de analisar automaticamente; demandando o desenvolvimento de novas técnicasde mineraçao de dados que se adaptemas peculiaridades dos cenários de aplicaçao. Porsua vez; essas novas técnicas;a semelhança de outras técnicas de mineraç ao de dados;sao intensivas em termos de computaç ao e de entrada e saıda; motivando a pesquisa e odesenvolvimento de novos paradigmas; ambientes de programaçao e algoritmos paralelosque executem essas tarefas com escalabilidade e eficiência. Os resultados descritos noartigo apontam nao apenas a pertinência do desenvolvimento dessas novas técnicas; comotambém a sua paralelizaçao. Mais ainda; permitem identificar três grupos de desafios de …,*,*,*
MINERAC AO INCREMENTAL DE REGRAS DE ASSOCIAC AO,A Veloso B Pôssas G Menezes; W Meira Jr; M Carvalho,Resumo A utilizaç ao efetiva e contınua de técnicas de mineraçao de dados é dificultadapela constante adiçao de novas transaçoes; que resultam em bases de dados enormes; epor mudanças nos critérios utilizados na atividade de mineraç ao; no caso de regras deassociaç ao; o suporte e a confiança. O problema neste caso é que esse dinamismo podeinvalidar algumas regras existentes e provocar o surgimento de novas regras relevantes.Neste artigo apresentamos PELICANO; um algoritmo eficiente para geraçao incremental deregras de associaç ao; que se baseia apenas nos itemsets maximais freqüentes e naocorrência de itens em transaçoes para atualizar a base de regras de associaçao. Ositemsets maximais sao usados para realizar uma enumeraçao descendente de todos ositemsets freqüentes; minimizando o número de conjuntos candidatos processados para a …,*,*,*
Identificaç ao e Caracterizaç ao de Spammers a partir de Honeypots,Pedro H Calais Guerra; Wagner Meira Jr; Dorgival Guedes,Abstract. Despite current strategies to minimize the impact of spams; it is necessary acontinuous effort to understand in detail how spammers generate and distribute theirmessages in the network; to maintain and even improve the effectiveness of anti-spammechanisms. This work proposes a methodology for characterization of spammingstrategies based on the identification of spam campaigns–groups of messages that sharethe same goal and are generated according to the same template. To identify spamcampaigns; we designed a data mining technique that detect message invariants and isable to deal with spam evolution. We implemented our campaign detection technique in asystem called Spam Miner; which is being used by the Brazilian Internet Steering Committee(CGI. br) and is helping the organization to better understand how the Brazilian network …,*,*,*
Explorando a Dissimilaridade em Sistemas Colaborativos de Recomendaç ao,Lucas Miranda; Fernando Mourao; Wagner Meira Jr,Abstract. The huge amount of options available in various commercial applications becameRecommender Systems (RS) crucial tools to assist users in their choices. Despite recentadvances in RS; there is still room for more effective techniques which are applicable to alarger number of domains. Most problems arise from the simplified model recurrently used.In this paper; we propose a richer user modeling which allows to extrapolate the usualsimilarity analysis. Furthermore; we propose a technique that; by exploiting an informationtype defined as dissimilarity; provides significant improvements over traditional techniquesbased on collaborative systems; as well as reduces the analysis cost required by suchtechniques. Resumo. O grande volume de opçoes existentes em variadas aplicaçoescomerciais tornaram Sistemas de Recomendaçao (SR) ferramentas cruciais para auxiliar …,*,*,*
An Open Large Dataset Processing Framework for Statistical Analysis,Charles F Gonçalves; Luam C Totti; Diego Duarte; Adriano CM Pereira; Wagner Meira Jr,*,*,*,*
SpSb: um ambiente seguro para o estudo de spambots,Gabriel C Silva; Alison C Arantes; Klaus Steding-Jessen; Cristine Hoepers; Marcelo HP Chaves; Wagner Meira Jr; Dorgival Guedes,Resumo. Botnets sao consideradas a origem de grande parte do spam observadoatualmente. Entretanto; a informaç ao que se tem sobre esses sistemas costuma serapócrifa ou deriva de esforços de engenharia reversa pontuais. Para se entender melhor ocomportamento desses sistemas é necessário um ambiente de monitoraçao que dê ao bota impressao de estar executando com liberdade na Internet; porém sem permitir que suasatividades causem danoa rede. Este artigo curto descreve uma implementaç ao de talsistema atualmente em curso.,*,*,*
Workshop Coordinator,Bruno R Schulze; Philippe OA Navaux; Claudio Amorim; Ricardo Bianchini; Rajkumar Buyya; Edson Cáceres; Walfredo Cirne; Alberto De Souza; Jean-Luc Gaudiot; Wagner Meira Jr; Edson Midorikawa; Philippe Navaux; Jairo Panetta; Viktor Prasanna; Liria Sato; Siang Song,General Chairs Bruno R. Schulze (National Laboratory for Scientific Computing (LNCC);Brazil) Philippe OA Navaux (Federal University of Rio Grande de Sul (UFRGS); Brazil) … SteeringCommittee Claudio Amorim (Federal University of Rio de Janeiro (UFRJ); Brazil) Ricardo Bianchini(Rutgers University; USA) Rajkumar Buyya (University of Melbourne; Australia) Edson Cáceres(Federal University of Mato Grosso do Sul (UFMS); Brazil) Walfredo Cirne (Google Inc.; USAand Federal University of Campina Grande (UFCG); Brazil) Alberto De Souza (Federal Universityof Espirito Santo (UFES); Brazil) Jean-Luc Gaudiot (University of California at Irvine; USA) WagnerMeira Jr. (Federal University of Minas Gerais (UFMG); Brazil) Edson Midorikawa (University ofSão Paulo (USP); Brazil) Philippe Navaux (Federal University of Rio Grande de Sul(UFRGS); Brazil) Jairo Panetta (National Institute for Space Research (INPE); Brazil) …,*,*,*
An Efficient Incremental Association Rule Mining Algorithm,Adriano A Veloso Gustavo M Siqueira; Bruno V Pôossas; Wagner Meira Jr; Márcio LB de Carvalho,Abstract There have been many studies on efficient discovery of association rules in largedatabases. However; it is hard to maintain such discovered rules in large dynamicdatabases since it allows frequent or occasional updates and such updates may not onlyinvalidate some existing rules but also turn some weak rules into strong ones. We presentan efficient algorithm (PELICAN) for updating the frequent itemsets when new transactionsare added to a transaction database or when the user changes the minimum support value.The incremental mining operation is enabled based only on the maximal frequent itemsetsand the items information about the original database. The set of maximal frequent itemsetsof the original database is used to enumerate the candidate sets (based on frequentitemsets information) and to compute the new maximal frequent itemsets set. PELICAN …,*,*,*
Avaliaç ao de Técnicas Paralelas de Blocagem para Resoluç ao de Entidades e Deduplicaç ao,Charles F Gonçalves; Walter Santos; Luis FD Flores; Matheus S Vilela; Carla Machado; Wagner Meira Jr; Altigran Silva; Depto de Ciência da Computaçao,Abstract. Data quality in databases is fundamental to many information managementapplications. One key criterion while measuring quality is the occurrence of duplicatedrecords in a database; justifying the development of deduplication and entity resolutiontechniques. In deduplication; the main challenge is the high complexity involved incomparing every single register in a database. In order to minimize such problem; blockingtechniques are used to reduce the number of comparisons; using fast and cheap metrics toidentify the similarity between each pair of records. In the present study; we evaluate someexisting blocking techniques implemented in a distributed; parallel and high scalablededuplication framework. We analyze them comparatively and identify the main advantagesand disadvantages achieved by a parallel execution. Resumo. A qualidade da …,*,*,*
Program Committee Chairs,Adenauer C Yamin; Rodolfo J de Azevedo; Edward David Moreno Ordonez; Henrique Cota de Freitas; César AF De Rose; Rodrigo Fernandes de Mello; Claudio Amorim; Ricardo Bianchini; Rajkumar Buyya; Edson Cáceres; Walfredo Cirne; Alberto De Souza; Jean-Luc Gaudiot; Wagner Meira Jr; Edson Midorikawa; Philippe Navaux; Jairo Panetta; Viktor Prasanna; Liria Sato; Siang Song,Page 1. Conference Organization General Chairs Bruno Schulze - LNCC; BR Philippe OANavaux - UFRGS; BR Program Committee Chairs Adenauer C. Yamin - UCPEL/UFPEL; BRRodolfo J. de Azevedo - UNICAMP; BR Undergraduate Research Workshop Chairs EdwardDavid Moreno Ordonez - UFS; BR Henrique Cota de Freitas - PUC Minas; BR Doctorate andMaster's Thesis Contest Coordinators César AF De Rose - PUCRS; BR Rodrigo Fernandesde Mello - USP; BR Steering Committee Claudio Amorim - UFRJ; BR Ricardo Bianchini - RutgersUniversity; EUA Rajkumar Buyya - University of Melbourne; Austrália Edson Cáceres UFMS;BR Walfredo Cirne - Google Inc.; USA e UFCG; BR Alberto De Souza - UFES; BR Jean-LucGaudiot University of California at Irvine; EUA Wagner Meira Jr …,*,*,*
Program Co-chairs,Viktor Prasanna; Walfredo Cirne; Alberto F De Souza; Claudio L Amorim; Jairo Panetta; Jean-Luc Gaudiot; Liria M Sato; Philippe OA Navaux; Siang W Song; Vinod Rabello; Wagner Meira Jr; Amaury Antônio de Castro Junior; Bruno R Schulze; Edson Norberto Cáceres; Henrique Mongelli; José Ademar Peixoto de Souza; Luciano Gonda; Marco Aurélio Stefanes; Rafael Ramos dos Santos; Ricardo Ribeiro dos Santos; Ronaldo Alves Ferreira; Silvana Morita; Tatiane Queiroz Moura; Wagner Meira,Organizing Committee Amaury Antônio de Castro Junior (UFMS; Brazil) Bruno R. Schulze(LNCC; Brazil) Edson Norberto Cáceres (UFMS; Brazil) Henrique Mongelli (UFMS; Brazil) JoséAdemar Peixoto de Souza (UFMS; Brazil) Luciano Gonda (UCDB; Brazil) Marco Aurélio Stefanes(UFMS; Brazil) Rafael Ramos dos Santos (UNISC; Brazil) Ricardo Ribeiro dos Santos(UCDB; Brazil) Ronaldo Alves Ferreira (UFMS; Brazil) Silvana Morita (UFMS; Brazil) TatianeQueiroz Moura (UFMS; Brazil) Viktor Prasanna (USC; USA) Wagner Meira (UFMG; Brazil) WalfredoCirne (Google; USA),*,*,*
CredibilityRank: um Arcabouço para Projeto e Avaliação de Modelos de Credibilidade de Serviços da Web,Sara Guimarães; Arlei Silva; Wagner Meira Jr; Adriano Pereira,RESUMO A popularização das aplicações Web tem feito surgir novos serviços a cada dia;bem como tem demandado mecanismos que assegurem a credibilidade desses serviços.Até o presente momento; muito pouco foi feito no sentido de medir e entender acredibilidade dos serviços neste complexo ambiente da Web; o que por si só representa umgrande desafio de pesquisa. Com base nas dificuldades relacionadas a essa tarefa deatribuir um valor de credibilidade a um serviço online da Web 2.0; propomos um arcabouçopara o projeto; a implementação e a avaliação de modelos de credibilidade. Denominamosmodelo de credibilidade uma função capaz de atribuir um valor de credibilidade a umserviço da Web; considerando diferentes critérios associados a esse serviço e a seufornecedor. Para validar o arcabouço; realizamos experimentos usando dados reais de …,*,*,*
SBAC-PAD 2010,Bruno Schulze; Philippe Navaux; José E Moreira; Vinod EF Rebello; Claudio Amorim; Ricardo Bianchini; Rajkumar Buyya; Edson Cáceres; Walfredo Cirne; Alberto De Souza; Jean-Luc Gaudiot; Wagner Meira Jr; Edson Midorikawa; Philippe Navaux; Jairo Panetta; Viktor Prasanna; Liria Sato; Siang Song; Antonio TA Gomes; Calebe de Paula Bianchini; Antonio R Mury,Bruno R. Schulze; National Laboratory for Scientific Computing (LNCC); Brazil Philippe OANavaux; Federal University of Rio Grande de Sul (UFRGS); Brazil … José E. Moreira; InternationalBusiness Machines Corporation (IBM); USA Vinod EF Rebello; Fluminense Federal University(UFF); Brazil … Claudio Amorim; Federal University of Rio de Janeiro (UFRJ); Brazil RicardoBianchini; Rutgers University; USA Rajkumar Buyya; University of Melbourne; Australia EdsonCáceres; Federal University of Mato Grosso do Sul (UFMS); Brazil Walfredo Cirne; GoogleInc.; USA and Federal University of Campina Grande (UFCG); Brazil Alberto De Souza; FederalUniversity of Espirito Santo (UFES); Brazil Jean-Luc Gaudiot; University of California atIrvine; USA Wagner Meira Jr.; Federal University of Minas Gerais (UFMG); Brazil EdsonMidorikawa; University of São Paulo (USP); Brazil Philippe Navaux; Federal University of …,*,*,*
LA-WEB 2008 Organization,Wagner Meira Jr; Luis Antonio Olsina; UFES Elias Oliveira; Brazil Alberto Ferreira de Souza; UDLA Alfredo Sanchez; Mexico Daniel Schwabe; Nora Koch; Germany Fernanda Lima,General Chair Ricardo Baeza-Yates; Yahoo! Research and CWR/DCC; U. of Chile; Chile …Program Co-chairs Wagner Meira Jr.; UFMG; Brazil Luis Antonio Olsina; UNLPam; Argentina… Organizing Committee Claudine Badue; UFES; Brazil (coordinator) Eduardo Graells;CWR; Univ. of Chile Elias Oliveira; UFES; Brazil Alberto Ferreira de Souza; UFES; Brazil JavierVelasco; CWR; Univ. of Chile … Steering Committee Virgilio Almeida; UFMG; Brazil RicardoBaeza-Yates; Yahoo! Research and U. of Chile; Chile (coordinator) Alfredo Sanchez; UDLA;Mexico Daniel Schwabe; PUC-Rio; Brazil … Program Committee Silvia Abrahão; Spain JussaraAlmeida; Brazil Virgilio Almeida; Brazil Azer Bestavros; USA Michele Colajanni; Italy CésarCollazos; Colombia Stefan Decker; Ireland Peter Dolog; Germany Ricardo Falbo; Brazil StevenFurnell; UK Martin Gaedke; Germany Claudio Gutierrez; Chile Nora Koch; Germany …,*,*,*
Mineraç ao de Tratamentos Sequenciais para o Suportea Tomada de Decisao Médica,Arlei Silva; Wagner Meira Jr; Odilon Queiroz; Mariângela Cherchiglia,*,*,*,*
Using quantitative information for,B PSossas; W Meira Jr; M Carvalho; R Resende; Belo Horizonte-MG-Brazil,*,*,*,*
Program Committee and Reviewers,Andre Bulcao; Andre Maximo; Cristiana Bentes; Cristina Boeres UFF; Gabriel Silva; Joao Comba; Lauro Whately; Lúcia MA Drummond UFF; Marcelo Lobosco; Rodrigo Weber dos Santos; Ricardo Farias; Vinod Rebello UFF; Wagner Meira; Alexandre Sena; Aline Nascimento UFF; André Maximo; Diego Dutra; Gabriel P Silva; Guilherme Cox; João Comba; Lucia Drummond UFF; Rodrigo dos Santos; Sergio Guedes; Wagner Meira Jr,Andre Bulcao (Petrobras) Andre Maximo (UFRJ) Cristiana Bentes (UERJ) Cristina Boeres(UFF) Gabriel Silva (UFRJ) Joao Comba (UFRGS) Lauro Whately (UFRJ) Lúcia MA Drummond(UFF) Marcelo Lobosco (UFJF) Rodrigo Weber dos Santos (UFJF) Ricardo Farias (UFRJ) VinodRebello (UFF) Wagner Meira (UFMG) … Alexandre Sena (LaSalle-RJ) Aline Nascimento(UFF) André Maximo (UFRJ) Cristiana Bentes (UERJ) Cristina Boeres (UFF) Diego Dutra(UFRJ) Gabriel P. Silva (UFRJ) Guilherme Cox (UFRJ) João Comba (UFRGS) Lauro Whately(UFRJ) Lucia Drummond (UFF) Marcelo Lobosco (UFJF) Ricardo Farias (UFRJ) Rodrigo dosSantos (UFJF) Sergio Guedes (UFRJ) Vinod Rebello (UFF) Wagner Meira Jr. (UFMG),*,*,*
ISPASS 2007 Reviewers,Dave Albonesi; Jose Nelson Amaral; Cristiana Amza; Krste Asanovic; Rajeev Balasubramonian; Leslie Barnes; Christopher Barton; Frank Bellosa; Paul Berube; Neil Birkbeck; Matthias Blumrich; Pradip Bose; David Brooks; Alper Buyuktosunoglu; Brad Calder; Enrique Carrera; John Carter; Deqing Chen; Howard Chen; Bruce Childers; Alan L Cox; Patrick Crowley; Stephen Curial; Chita Das; Bob Davies; Chen Ding; Steven Dropsho; Lieven Eeckhout; Noel Eisley; Paolo Faraboschi; Tim Furtak; Chris Gniady; Antonio Gonzalez; Boris Grot; Michael Gschwind; Sudhanva Gurumurthi; Erik Hagersten; John Haskins Jr; Martin Hirzel; Y Charlie Hu; Michael Huang; Galen Hunt; Ravishankar Iyer; Russ Joseph; Steve Keckler; Rakesh Krishnaiyer; Sriram Krishnamoorthy; Wei Li; Chu-cheow Lim; David Lilja; Margaret Loper; Nadeem Malik; Milo Martin; Margaret Martonosi; Xavier Martorell; Sally McKee; Wagner Meira Jr; Amy Murphy; Ravi Nair; Robert Niewiadomski; Vivek Pai; Athanasios Papathanasiou; Li-Shiuan Peh; Michael Powell; Thomas Puzak; Padma Raghavan; Karthick Rajamani; Ram Rajamony; Parthasarathy Ranganathan; Steve Reinhardt; Umit Rencuzogullari; Jude Rivers; Scott Rixner; Amir Roth; P Sadayappan; Andre Seznec; Kelly Shaw; Kai Shen; Xipeng Shen; Tim Sherwood; Anand Sivasubramaniam; Kevin Skadron; Jim Smith; Dan Sorin; Evan Speight; Vijayalakshmi Srinivasan; Jaspal Subhlok; Chunqiang Tang; Xinmin Tian; Chau-Wen Tseng; Dean Tullsen; Sumesh Udayakumaran; Jeffrey Vetter; TN Vijaykumar; Perry Wang; Sebastian Winkel; David Wood; Peng Wu,The ISPASS 2007 organizing committee extends its heartfelt appreciation to the dedicated teamof reviewers … Dave Albonesi Jose Nelson Amaral Cristiana Amza Krste Asanovic Rajeev BalasubramonianLeslie Barnes Christopher Barton Frank Bellosa Paul Berube Neil Birkbeck Matthias BlumrichPradip Bose David Brooks Alper Buyuktosunoglu Brad Calder Enrique Carrera John Carter DeqingChen Howard Chen Bruce Childers Alan L. Cox Patrick Crowley Stephen Curial Chita Das BobDavies Chen Ding Steven Dropsho Lieven Eeckhout Noel Eisley Paolo Faraboschi Tim FurtakChris Gniady Antonio Gonzalez Boris Grot Michael Gschwind Sudhanva Gurumurthi Erik HagerstenJohn Haskins; Jr. Martin Hirzel Y. Charlie Hu Michael Huang … Galen Hunt Ravishankar IyerRuss Joseph Steve Keckler Rakesh Krishnaiyer Sriram Krishnamoorthy Wei Li Chu-cheow LimDavid Lilja Margaret Loper Nadeem Malik Milo Martin Margaret Martonosi Xavier …,*,*,*
Program Co-Chairs of SBAC-PAD’09 SBAC-PAD 2009,Ricardo Bianchini; Wagner Meira Jr,We would like to say a few words about the process that got us here. In forming the ProgramCommittee (PC); we had three primary goals: (1) to select a group of recognized experts on thepredicted mix of submission topics; (2) to find the most appropriate reviewers for each submittedpaper; and (3) to inject new blood and energy into the conference. With those goals in mind;we organized the PC with four technical tracks: Computer Architecture; Algorithms andApplications; Networks and Distributed Systems; and Systems Software. We also selected fouroutstanding researchers to act as track vice-chairs: David Bader (Georgia Tech); David Brooks(Harvard); Dilma da Silva (IBM); and Y. Charlie Hu (Purdue). Each track was coordinated byits vice-chair and operated almost as an independent sub-PC: the vice-chairs selected the PCmembers for their tracks and interacted directly with them; we only provided guidance …,*,*,*
Fatores que afetam o comportamento de spammers na rede,Gabriel C Silva; Klaus Steding-Jessen; Cristine Hoepers; Marcelo HP Chaves; Wagner Meira Jr; Dorgival Guedes,Resumo. O propósito deste trabalho é entender melhor o comportamento de spammers(responsáveis pelo envio de mensagens de spam) na rede; e assim trazer maisinformaçoes para o combate a eles. Para isso utilizamos um sistema de honeypotsvirtualizados especialmente desenvolvidos para a coleta de spam que possibilita avaliar ainfluência de diversos fatores no comportamento dos transmissores. Os resultados mostramque as variaçoes na configuraçao dos cenários pode afetar drasticamente o volume despam recebido; bem como suas caracterısticas internas. Em particular; o trabalho identificoudois tipos bastante diversos de transmissores: spammers em larga escala; que usampoucas máquinas com muitos recursos; e botnets; que enviam cada uma um númerolimitado de mensagens.,*,*,*
SBAC-PAD 2006,Alberto Ferreira De Souza; Alfredo Goldman; Alvaro Coutinho; Andrea Valli; Bertil Folliot; Bruno Schulze; Celso Mendes; Cesar De Rose; Christophe Crin; Claudio Amorim; Claudio Geyer; Cristina Boeres; D Janaki Ram; David Kaeli; Denis Trystram; Edil Fernandes; Edson Cáceres; Eduardo Bergamini; Felipe França; Frank Dehne; Guido Araujo; Hans-Ulrich Heiss; Horst Simon; Howard Siegel; Jack Dongarra; Jairo Panetta; Jean-Luc Gaudiot; José Amaral; José Fortes; José Saito; Kuan Li; Lalit Patnaik; Laurence Yang; Liria Sato; Lucia Catabriga; Luiz Barroso; Luiz DeRose; Mario Nemirovsky; Nader Bagherzadeh; Neyval Reis Jr; Orlando Loques; Osni Marques; Peter Rounce; Philippe Navaux; Priscila MV Lima; Rafael Lins; Rajkumar Buyya; Renato Silva; Ricardo Bianchini; Ron Perrott; Ronaldo Goncalves; Sergio Bampi; Sergio Kofuji; Siang Song; Srikumar Venugopal; Tiarajú Diverio; Valmir Barbosa; Vinod Rebello; Wagner Meira Jr; Walfredo Cirne; Yale Patt,Alberto Ferreira De Souza (Brazil) Alfredo Goldman (Brazil) Alvaro Coutinho (Brazil) AndreaValli (Brazil) Bertil Folliot (France) Bruno Schulze (Brazil) Celso Mendes (USA) Cesar De Rose(Brazil) Christophe Crin (France) Claudio Amorim (Brazil) Claudio Geyer (Brazil) Cristina Boeres(Brazil) D. Janaki Ram (Índia) David Kaeli (USA) Denis Trystram (France) Edil Fernandes(Brazil) Edson Cáceres (Brazil) Eduardo Bergamini (Brazil) Felipe França (Brazil) Frank Dehne(Austrália) Guido Araujo (Brazil) Hans-Ulrich Heiss (Germany) Horst Simon (USA) Howard Siegel(USA) Jack Dongarra (USA) Jairo Panetta (Brazil) Jean-Luc Gaudiot (USA) José Amaral(Canada) José Fortes (USA) José Saito (Brazil) Kuan Li (Taiwán) … Lalit Patnaik (India) LaurenceYang (Canada) Liria Sato (Brazil) Lucia Catabriga (Brazil) Luiz Barroso (USA) Luiz DeRose(USA) Mario Nemirovsky (USA) Nader Bagherzadeh (USA) Neyval Reis Jr. (Brazil) …,*,*,*
A Implementaç ao de uma Arquitetura para Controle de Privacidade na Web,Robert P Pinto; Lucila Ishitani; Fernando D Castro; Fabiano A Fonseca; Wagner Meira Jr; Virgılio Almeida,*,*,*,*
A Scalable Approach for the Distribution of E-commerce\,Dorgival Guedes; Wagner Meira Jr,\Abstract. In this paper we use the idea of Application Level Active Networks\to implement aneﬂicient and easily deployable solution for the distribution of e-commerce services usingcache servers which can hold dynamic content. Thd resulting system is an application of theALAN concept and framework to at real and complex application (an electronic bookstorethat makes use of dyl namic document caching schemes). Our experiments show thatsigniﬁcant perl\formance gains can be obtained by e-commerce sites that use this model;iml\proving the scalability of the target service by distributing the load among thd dynamiccaches. Results show reductions of server CPU load by up to 64% anal improvements ofclient perceived response time of up to 70% under heavy load. ll. Introduction Recently; theWorld Wide Web (WWW) has become an important way of providing services and …,*,*,*
Identificaç ao e Caracterizaç ao de Spammers a partir de Listas de Destinatários,Pedro H Calais Guerra; Marco Túlio Ribeiro; Dorgival Olavo Guedes; Wagner Meira Jr; Cristine Hoepers; Klaus Steding-Jessen; Marcelo HPC Chaves,Resumo. Neste trabalho; analisamos padroes de disseminaçao de spams que podem serinferidos a partir das listas de destinat ários abusadas por spammers. A partir da determinaçao de conjuntos de endereços IP que abusam consistentemente os mesmos destinatários;caracterizamos propriedades da disseminaç ao de listas de destinatários desses conjuntosque podem ser utilizadas como critérios para identificaç ao e detecç ao de spams. Nossoestudo revela que até 100% dos destinatários abusados por um endereço IP sao tambémalvo de endereços IPs geograficamente próximos na rede; e que é possıvel isolar grupos despammers considerando apenas a origem e o destino das mensagens de spam. Abstract. Inthis work; we analyze spamming dissemination patterns that can be inferred from spam'srecipient lists. From the set of recipients associated to each source IP address; we …,*,*,*
Identificação e Caracterização de Spammers a partir de Listas de Destinatários,Pedro H Calais Guerra; Marco Túlio Ribeiro; Dorgival Olavo Guedes; Wagner Meira Jr; Cristine Hoepers; Klaus Steding-Jessen; Marcelo HPC Chaves,In this work; we analyze spamming dissemination patterns that canbe inferred from spam'srecipient lists. From the set of recipients associated toeach source IP address; wedetermined the sets of IP numbers that systematicallyabuse the same targets. We thencaracterized how those sets abuse theirrecipient lists and unveil properties that may beemployed as spam mitigationcriteria. Our study unveils that up to 100% of the recipientstargeted by a givenIP address are also targeted by other IP addresses geographically closewithinthe network and that it is possible to determine spammers considering onlyspamsource and targets.,*,*,*
ESTUDO 36: GOVERNO ELETRÔNICO E SERVIÇOS AO CIDADÃO,Wagner Meira Jr; Virgílio Augusto Fernandes de Almeida; Eduardo Moreira da Costa,*,*,*,*
On the Design of a Tool for Controlling Privacy in the WWW,Lucila Ishitani Gustavo MC Gama; Wagner Meira Jr,Abstract Concerns about users' privacy are currently attracting significant attention. Usersusually do not approve of someone mining their actions and habits while they use the Web.On the other hand; having some information about the user's behavior is essential forproviding personalized services. Thus; there is a clear demand for mechanisms that allowusers to control their privacy without relying on the visited site's policies. In this paper wepropose a tool that tells the user the level of privacy maintained throughout his herinteraction with a given site. By using our tool; the user can become aware of privacyviolations and may use privacy preservation mechanisms.,*,*,*
Program Committee Chairs,Ricardo Bianchini; Wagner Meira Jr; Alberto F De Souza; Claudio L Amorim; Edson Norberto Cáceres; Jairo Panetta; Jean-Luc Gaudiot; Liria M Sato; Philippe OA Navaux; Siang W Song; Viktor Prasanna; Vinod Rabello; Walfredo Cirne; Artur Baruchi; Calebe de Paula Bianchini; Denise Stringhini; Edson Toshimi Midorikawa; Francisco Isidro Massetto; Gabriel Pereira da Silva; Hélio Crestana Guardia; Francisco Ribacionka; Hermes Senger; Liria Matsumoto Sato; Alfredo Goldman vel Lejbman; Ismar Frango Silveira; Nicolas Kassalias,Artur Baruchi (USP-Brazil) Calebe de Paula Bianchini (Mackenzie – Brazil) Denise Stringhini(Mackenzie – Brazil) Edson Toshimi Midorikawa (USP-Brazil) Francisco Isidro Massetto(USP-Brazil) Gabriel Pereira da Silva (UFRJ - Brazil) Hélio Crestana Guardia (UFSCar –Brazil) Francisco Ribacionka (USP-Brazil) Hermes Senger (UFSCar – Brazil) Liria MatsumotoSato (USP-Brazil) Ricardo Bianchini (Rutgers University - USA) Wagner Meira Jr. (UFMG -Brazil) Program Committee Alfredo Goldman vel Lejbman (USP-Brazil) Ismar Frango Silveira(Mackenzie-Brazil) Nicolas Kassalias (USJT-Brazil) … Computer Architecture TrackVice-chair: David Brooks (Harvard) … Claudio L. Amorim (Federal University of Rio deJaneiro) Nader Bagherzadeh (University of California at Irvine) Mauricio Breternitz Jr. (Intel) PatrickCrowley (Washington University) Cesar De Rose (PUC Rio Grande do Sul) Alberto …,*,*,*
Proxy Ativo: Dimuindo a Latência através de Pushing,Bruno Gusmão Rocha; Adriano Alonso Veloso; Wagner Meira Jr; Virgilio AF Almeida,The majority of the Internet users still access the Web via slow modem connections. Studieshave shown that the limited modem bandwidth is the main contributor to the latencyperceived by users. In this paper we introduce one approach to reduce the latency bypushing between proxies and its clients; in special low-bandwidth clients. The approachtakes advantage of idle periods between requests to pull proxy-cached objects which will beprobably accessed next by the client. We use data mining concepts to develop a efficientprediction model and evaluate the potential of this technique at reducing client latencythrought simulations based on real workloads from a major proxy in Minas Gerais.,*,*,*
Servidores Paralelos e Distribuídos de Comércio Eletrônico,T Cançado; A Pereira; B Abrahão; R Pereira; W Meira Jr; C Amorim; A Faustino; S Dias,Resumo-A popularização da Internet torna o comércio eletrônico uma de suas aplicaçõesmais promissoras; o que explica o aumento significativo da carga observada nos sites e aconscquente degradação do desempenho de seus servidores. Em paralelo; os usuáriosestão mais exigentes c criteriosos ao escolher os serviços utilizados c; portanto;escalabilidadc tornou-se ponto chave para atender satisfatoriamente esses consumidores.Este artigo apresenta um mecanismo de distribuição de serviços c dados entre servidoresde transação estendendo o trabalho anterior; onde apenas a replicação de dados emservidores de comércio eletrônico foi abordada. Essa abordagem foi implementada evalidada no âmbito de uma livraria virtual c logs de acesso reais e demonstra que oesquema proposto aumenta efetivamente a escalabilidade do servidor. Por outro lado …,*,*,*
Analyzing Robot Behavior in E-Business Sites,Fl avia Peligrinelli; Rodrigo Fonseca; Wagner Meira Jr,Abstract Understanding the nature and characteristics of e-business workloads is anessential step to improve quality of service. Using a multi-layer hierarchical workload model;this paper presents a characterization of the workload generated by autonomous agents androbots. The characterization of the robot workload focuses on the statistical properties of thearrival process and on the robot behavior graph model. A multi-scale time analysis is used tounderstand the impact of robot workloads on the performance of ebusiness sites. Based onthe workload characterization; we develop an analytical model for the interaction betweenrobots and e-business sites. Using the model; we show the resource utilization associatedwith robots' requests. Multiple time-scale analysis point out that server overload may occur atfine time scales; even though average utilizations at larger time-scales do not show …,*,*,*
Computer Architecture and High Performance Computing,Carolina Xavier; Rafael Sachetto; Vinicius Vieira; Rodrigo Weber dos Santos; Wagner Meira Jr,Computational Characteristics of Production Seismic Migration and its Performance on NovelProcessor Architectures............................................................................................................... 11 JairoPanetta; Paulo RP de Souza Filho; Carlos A. da Cunha Filho; Fernando M. Roxo da Motta; SilvioS. Pinheiro; Ivan Pedrosa Junior; Andre LR Rosa; Luiz R. Monnerat; Leandro T. Carneiro; andCarlos HB de Albrecht … Voice Command Recognition with Dynamic Time Warping (DTW)using Graphics Processing Units (GPU) with Compute Unified Device Architecture (CUDA)............................................................... 19 Gustavo Poli; Alexandre LM Levada; João F. Mari; andJosé Hiroki Saito … Exploring Novel Parallelization Technologies for 3-D Imaging Applications.............................................. 26 Diego Rivera; Dana Schaa; Micha Moffie; and David Kaeli …Low-cost Techniques for Reducing Branch Context Pollution in a Soft Realtime …,*,*,*
Paralelismo Adaptativo de Algoritmos para Geraçao de Regras de Associaçao,A Veloso G Siqueira B Possas; W Meira Jr,*,*,*,*
Avaliação de Técnicas Paralelas de Blocagem para a Resolução de Entidades e Deduplicação,Charles F Goncalves; Walter Santos; Luis FD Flores; Matheus S Vilela; Carla Machado; Wagner Meira Jr; Altigran Silva,*,*,*,*
Gera cão de Regras de Associa cão Quantitativas,Wagner Meira Jr; Rodolfo Resende,Resumo As institui cões t^ em investido cada vez mais em explorar a informa cão econhecimento presentes nos dados correspondentes as suas atividades. Alguns tipos deinforma cão podem ser obtidos atrav es de uma ou mais consultas aos bancos de dados deuma organiza cão. Entretanto; existem v arias informa cões que não são obtidassimplesmente utilizando as consultas convencionais como; por exemplo; as consultasdispon veis em um sistema de ger^ encia de bancos de dados relacional. A minera cão dedados corresponde a um conjunto de t ecnicas para obten cão de informa cão que nãopode ser obtida atrav es de consultas convencionais. Uma destas t ecnicas e denominadaminera cão de regras de associa cão. As regras de associa cão são expressões queindicam afinidade ou correla cões entre dados. Diversos trabalhos t^ em descrito v arias …,*,*,*
SBAC-PAD 2006,Wagner Meira Jr; Alberto F De Souza; Rajkumar Buyya; Claudio L Amorim; Jean-Luc Gaudiot; Liria M Sato; Philippe OA Navaux; Siang W Song; Gabriel P Silva; Carlos Augusto Martins,Alberto F. De Souza; UFES; Brazil Rajkumar Buyya; University of Melbourne; Australia … AlbertoF. De Souza; UFES; Brazil Claudio L. Amorim; UFRJ; Brazil Jairo Panetta; INPE; BrazilJean-Luc Gaudiot; UC Irvine; USA Liria M. Sato; USP; Brazil Philippe OA Navaux; UFRGS; BrazilRajkumar Buyya; U Melbourne; Australia Siang W. Song; USP; Brazil Gabriel P. Silva; UFRJ;Brazil … Carlos Augusto Martins; PUC-MG; Brazil Dorgival Guedes; UFMG; Brazil RenatoFerreira; UFMG; Brazil Ricardo Duarte; UFOP; Brazil,*,*,*
ÁÆËÌÁÌÍÌÇ ÇÅÈÍÌ Ç,FA Faria; A Veloso; HM Almeida; W Meira Jr,Abstract In Content-based Image Retrieval (CBIR); accurately ranking the returned images isof paramount importance; since it is common-sense that users consider mostly the topmostresults. The typical ranking strategy used by many CBIR systems is to employ image contentdescriptors; so that returned images that are most similar to the query image are placedhigher in the rank. While this strategy is well accepted and widely used; improved resultsmay be obtained by combining multiple image descriptors. In this paper we explore thisidea; and introduce algorithms that learn to combine information coming from differentdescriptors. The proposed learning to rank algorithms are based on three diverse learningtechniques: Support Vector Machines (CBIR-SVM); Genetic Programming (CBIR-GP); andAssociation Rules (CBIR-AR). Eighteen image content descriptors (color; texture; and …,*,*,*
Mapeamento de Programas I3 para Aplicações Anthill Paralelas de Fluxos de Dados baseadas em Filtros,Luís FW Góes; Ítalo Giovani; Renato Ferreira; Wagner Meira Jr,Resumo Aplicações atuais de mineração de dados; simulação e visualização científicaoferecem várias oportunidades de paralelismo por serem iterativas; irregulares e intensivasem termos de E/S (programas I3). O mapeamento e escalonamento de programas I3 paraaplicações paralelas de fluxos de dados baseadas em filtros é bastante complexo; pois elesdevem considerar aspectos de localidade; dependência de dados e tarefas. A plataformaAnthill provê um modelo de programação adequado para implementação e execução deaplicações paralelas baseadas em filtros. Portanto; neste trabalho; nossos objetivosprincipais são: a proposta e implementação do algoritmo AnthillPart para o mapeamento deum grafo de tarefas de um programa I3 em filtros; a análise do desempenho das aplicaçõesmapeadas pelo AnthillPart e escalonadas pelo AnthillSched.,*,*,*
Caracterizaç ao de Estratégias de Disseminaç ao de Spams,Pedro H Calais Guerra; Dorgival Olavo Guedes; Wagner Meira Jr; Cristine Hoepers; Klaus Steding-Jessen,Abstract. To subsidize research on ways to identify and possibly block spam in its origin;avoiding network resources being consumed; we characterize some strategies that definespammers' behavior patterns. For that we use data collected from low-interaction honeypots;configured to emulate open relays and open proxies. After collecting data; we identifiedmessage groups that differ only due to text obfuscation; which correspond to a same originalspam campaign. We then applied data mining techniques on those groups to find out howsuch groups use the network resources. The results show that it is possible to identifyspammers with specific patterns on the way they abuse different ports in parallel and howthey start spam campaigns from different origins at the same time. Resumo. A fim desubsidiar estudos para identificar e possivelmente bloquear o spam em sua origem …,*,*,*
