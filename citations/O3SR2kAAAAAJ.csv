Don't Scrap It; Wrap It! A Wrapper Architecture for Legacy Data Sources.,Mary Tork Roth; Peter M Schwarz,Abstract Garlic is a middleware system that provides an integrated view of a variety of legacydata sources; without changing how or where data is stored. In this paper; we describe ourarchitecture for wrappers; key components of Garlic that encapsulate data sources andmediate between them and the middleware. Garlic wrappers model legacy data as objects;participate in query planning and provide standard interfaces for method invocation andquery execution. To date; we have built wrappers for 10 data sources. Our experienceshows that Garlic wrappers can be written quickly and that our architecture is flexibleenough to accommodate data sources with a variety of data models and a broad range oftraditional and non-traditional query processing capabilities.,VLDB,1997,582
Clio grows up: from research prototype to industrial tool,Laura M Haas; Mauricio A Hernández; Howard Ho; Lucian Popa; Mary Roth,Abstract Clio; the IBM Research system for expressing declarative schema mappings; hasprogressed in the past few years from a research prototype into a technology that is behindsome of IBM's mapping technology. Clio provides a declarative way of specifying schemamappings between either XML or relational schemas. Mappings are compiled into anabstract query graph representation that captures the transformation semantics of themappings. The query graph can then be serialized into different query languages;depending on the kind of schemas and systems involved in the mapping. Clio currentlyproduces XQuery; XSLT; SQL; and SQL/XML queries. In this paper; we revisit thearchitecture and algorithms behind Clio. We then discuss some implementation issues;optimizations needed for scalability; and general lessons learned in the road towards …,Proceedings of the 2005 ACM SIGMOD international conference on Management of data,2005,317
Transforming heterogeneous data with database middleware: Beyond integration,LHRMB Niswonger; M Tork Roth; PM Schwarz; EL Wimmers,Many applications today need information from diverse data sources; in which related datamay be represented quite differently. In one common scenario; a DBA wants to add datafrom a new source to an existing warehouse. The data in the new source may not match theexisting warehouse schema. The new data may also be partially redundant with that in theexisting warehouse; or formatted differently. Other applications may need to integrate datamore dynamically; in response to user queries. Even applications using data from a singlesource often want to present it in a form other than that it is stored in. For example; a usermay want to publish some information using a particular XML DTD; though the data is notstored in that form. In each of these scenarios; one or more data sets must be mapped into asingle target representation. Needed transformations may include schema …,Data Engineering,1999,266
Data integration through database federation,Laura M Haas; Eileen Tien Lin; Mary A Roth,In a large modern enterprise; it is almost inevitable that different portions of the organizationwill use different systems to produce; store and search their critical data. Yet; it is only bycombining the information from these various systems that the enterprise can realize the fullvalue of the data they contain. Information integration is a ubiquitous need for today'sbusinesses. Database federation is one approach to information integration in which arelational database management system serves as middleware providing transparentaccess to a number of heterogeneous data sources. The goal of this paper is to demonstratethat database federation is a fundamental tool for information integration. While otherapproaches to information integration may be useful for particular integration problems;database federation has some unique characteristics that make it suitable for a broad …,IBM Systems Journal,2002,192
The garlic project,Mary Tork Roth; Manish Arya; Laura M Haas; Michael J Carey; William Cody; Ronald Fagin; Peter M Schwarz; John Thomas; Edward L Wimmers,The goal of the Garlic [1] project is to build a multimedia information system capable of integratingdata that resides in different database systems as well as in a variety of non-data- base dataservers. This integration must be enabled while maintaining the independence of the dataservers; and without creating copies of their data. “Multimedia” should be inter- preted broadlyto mean not only images; video; and audio; but also text and application specific data types(eg; CAD draw- ings; medical objects; ...). Since much of this data is naturally modeled byobjects; Garlic provides an object-oriented schema to applications; interprets object queries;creates exe- cution plans for sending pieces of queries to the appropriate data servers; and assemblesquery results for delivery back to the applications. A significant focus of the project is supportfor “intelligent” data servers; ie; servers that provide media- specific indexing and query …,Sigmod Record,1996,162
Cost models do matter: Providing cost information for diverse data sources in a federated system,Mary Tork Roth; Laura M Haas; Fatma Ozcan,Abstract An important issue for federated systems of diverse data sources is how to optimizecross-source queries; without building knowledge of individual sources into the optimizer.Garlic is a federated system with an emphasis on extensibility and diverse sources. Toachieve these goals; data sources are attached to Garlic by means of a wrapper. Wrappersparticipate in query planning; telling Garlic what parts of a query a data source can do andhow much it will cost. This paper describes a framework through which wrappers provide thenecessary cost and cardinality information for optimization; and the facilities Garlic providesto make this task easier. Our framework makes it easy for wrappers to provide costinformation; requires few changes to a conventional bottomup optimizer and is easilyextensible to a broad range of sources. We believe that our framework for costing is the …,*,1999,141
Querying multimedia data from multiple repositories by content: the Garlic project,William F Cody; Laura M Haas; Wayne Niblack; Manish Arya; Michael J Carey; Ronald Fagin; Myron Flickner; Denis Lee; Dragutin Petkovic; Peter M Schwarz; Joachim Thomas; M Tork Roth; John H Williams; Edward L Wimmers,Abstract We describe Garlic; an object-oriented multimedia middleware query system. Garlicenables existing data management components; such as a relational database or a full textsearch engine; to be integrated into an extensible information management system thatpresents a common interface and user access tools. We focus in this paper on how QBIC; animage retrieval system that provides content-based image queries; can be integrated intoGarlic. This results in a system in which a single query can combine visual and nonvisualdata using type-specific search techniques; enabling a new breed of multimediaapplications,*,1995,102
Tolerant and extensible discovery of relationships in data using structural information and data analysis,*,Various embodiments of a method; system and article of manufacture to discoverrelationships among a first set of elements and a second set of elements are provided. Atleast one metric algorithm is identified based on a metric selection parameter. A raw result isdetermined based on the at least one metric algorithm; a first specified structural descriptionof the first set of elements and a second specified structural description of the second set ofelements. The raw result comprises a plurality of relationship measurements and the rawresult is ordered. In some embodiments; a balanced result is produced based on the rawresult and a matching strategy algorithm. In other embodiments; the matching strategyalgorithm is identified based on a matching strategy selection parameter.,*,2017,89
Information integration: A new generation of information technology,Mary A Roth; Daniel C Wolfson; JC Kleewein; Constance J Nelin,The explosion of the Internet and e-business in recent years has caused a secondaryexplosion in the amounts and types of information available to enterprise applications.Industry analysts predict that more data will be generated in the next three years than in allof recorded history. Because the adoption of Internet-based business transaction modelshas significantly outpaced the development of tools and technologies to deal with theinformation explosion; many businesses find their systems breaking under the sheer volumeand diversity of data being directed at them. The challenge facing businesses today isinformation integration. Enterprise applications must interact with databases; applicationservers; content management systems; data warehouses; workflow systems; searchengines; message queues; Web crawlers; mining and analysis packages; and other …,IBM systems journal,2002,83
Common interface to access catalog information from heterogeneous databases,*,Various embodiments of a system and computer program product to access metadata from aplurality of data servers from a federated database management system are provided. In oneembodiment; a request for metadata; from a client application; is received by the federateddatabase management system. Data servers which are accessible from the federateddatabase management system are identified. For each data server; metadata describingdata of a data source of that data server is retrieved in accordance with the applicationrequest. The retrieved metadata from each of the data servers is aggregated to produce anaggregated result in a uniform format. The aggregated result is provided. In anotherembodiment; for each data server; a source metadata request for metadata of that dataserver is generated in accordance with the application request and a source metadata …,*,2011,77
Technique for relationship discovery in schemas using semantic name indexing,*,Techniques are provided for semantic matching. A semantic index is created for one or moreschemas; wherein each of the one or more schemas includes one or more word attributes;and wherein each of the one or more word attributes includes one or more tokens; whereinthe semantic index identifies one or more keys and one or more values for each key;wherein each value specifies one of the one or more schemas; a word attribute from thespecified schema; and a token of the specified word attribute; and wherein the specifiedtoken is a synonym of the key. For a source word attribute from one of the one or moreschemas; the source word attribute is used as a key to index the semantic index to identifyone or more matching word attributes.,*,2006,57
Data Wrangling: The Challenging Yourney from the Wild to the Lake.,Ignacio G Terrizzano; Peter M Schwarz; Mary Roth; John E Colino,ABSTRACT Much has been written about the explosion of data; also known as the “datadeluge”. Similarly; much of today's research and decision making are based on the de factoacceptance that knowledge and insight can be gained from analyzing and contextualizingthe vast (and growing) amount of “open” or “raw” data. The concept that the large number ofdata sources available today facilitates analyses on combinations of heterogeneousinformation that would not be achievable via “siloed” data maintained in warehouses is verypowerful. The term data lake has been coined to convey the concept of a centralizedrepository containing virtually inexhaustible amounts of raw (or minimally curated) data thatis readily made available anytime to anyone authorized to perform analytical activities. Theoften unstated premise of a data lake is that it relieves users from dealing with data …,CIDR,2015,48
Using Fagin's algorithm for merging ranked results in multimedia middleware,Edward L Wimmers; Laura M Haas; Mary Tork Roth; Christoph Braendli,A distributed multimedia information system allows users to access data of differentmodalities; from different data sources; ranked by various combinations of criteria. Fagin(1996) gives an algorithm for efficiently merging multiple ordered streams of ranked results;to form a new stream ordered by a combination of those ranks. In this paper we describe theimplementation of Fagin's algorithm in an actual multimedia middleware system; including anovel; incremental version of the algorithm that supports dynamic exploration of data. Weshow that the algorithm would perform well as part of a single multimedia server and caneven be effective in the distributed environment (for a limited set of queries); but that theassumptions it makes about random access limit its applicability dramatically. Ourexperience provides a better understanding of an important algorithm; and exposes an …,Cooperative Information Systems; 1999. CoopIS'99. Proceedings. 1999 IFCIS International Conference on,1999,45
XML mapping technology: Making connections in an XML-centric world,Mary Roth; Mauricio A Hernández; Phil Coulthard; L Yan; Lucian Popa; HC-T Ho; CC Salter,Extensible Markup Language (XML) has grown rapidly over the last decade to become thede facto standard for heterogeneous data exchange. Its popularity is due in large part to theease with which diverse kinds of information can be represented as a result of the self-describing nature and extensibility of XML itself. The ease and speed with which informationcan be represented does not extend; however; to exchanging such information betweenautonomous sources. In the absence of controlling standards; such sources will typicallychoose differing XML representations for the same concept; and the actual exchange ofinformation between them requires that the representation produced by one source betransformed into a representation understood by the other. Creating this informationexchange “glue” is a tedious and error-prone process; whether expressed as Extensible …,IBM Systems Journal,2006,37
Using data mining algorithms including association rules and tree classifications to discover data rules,*,Provided are a method; system; and article of manufacture for using a data mining algorithmto discover data rules. A data set including multiple records is processed to generate datarules for the data set. Each record has a record format including a plurality of fields and eachrule provides a predicted condition for one field based on at least one predictor condition inat least one other field. The generated data rules are provided to a user interface to enable auser to edit the generated data rules. The data rules are stored in a rule repository to beavailable to use to validate data sets having the record format.,*,2010,34
Method and apparatus for semantic search of schema repositories,*,Mechanisms for searching XML repositories for semantically related schemas from a varietyof structured metadata sources; including web services; XSD documents and relationaltables; in databases and Internet applications. A search is formulated as a problem ofcomputing a maximum matching in pairwise bipartite graphs formed from query andrepository schemas. The edges of such a bipartite graph capture the semantic similaritybetween corresponding attributes of the schema based on their name and type semantics.Tight upper and lower bounds are also derived on the maximum matching that can be usedfor fast ranking of matchings whilst still maintaining specified levels of precision and recall.Schema indexing is performed by 'attribute hashing'; in which matching schemas of adatabase are found by indexing using query attributes; performing lower bound …,*,2007,31
Discovering transformations applied to a source table to generate a target table,*,Provided are a method; system; and article of manufacture for discovering transformationsapplied to a source table to generate a target table. Selection is made of a source tablecomprising a plurality of rows and a target table resulting from a transformation applied tothe rows of the source table. A first pre-processing method is applied with respect to columnsin the source and target tables to produce first category pre-processing output. The firstcategory pre-processing output is used to determine first category transformation rules withrespect to at least one source table column and at least one target table column. For eachunpredicted target column in the target table not predicted by the determined first categorytransformation rules; a second pre-processing method is applied to columns in the sourcetable and unpredicted target columns to produce second category pre-processing output …,*,2017,28
Managing validation models and rules to apply to data sets,*,Provided are a method; system; and article of manufacture for managing validation modelsand rules to apply to data sets. A schema definition describing a structure of at least onecolumn in a first data set having a plurality of columns and records providing data for each ofthe columns is received. At least one model is generated; wherein each model assertsconditions for at least one column in a record of the first data set. The schema definition andthe at least one model are stored in a data quality model. Selection is received of a seconddata set and the data quality model. A determination is made as to whether a structure of thesecond data set is compatible with the schema definition in the selected data quality model.Each model in the data quality model is applied to the records in the second data set tovalidate the records in the second data set in response to determining that the structure of …,*,2013,26
Deriving a Data Model From a Hierarchy Of Related Terms; And Deriving a Hierarchy Of Related Terms From a Data Model,*,Various embodiments of a method; system and computer program product generate a datamodel based on a glossary model. The glossary model comprises categories and terms. Atleast one category of the glossary model comprises at least one term of the terms. Thecategories have a hierarchical relationship. The categories are mapped to objects of a datamodel. The terms are mapped to attributes of the data model. The attributes are associatedwith the objects of the data model; wherein a particular attribute of the attributes isassociated with a particular object of the objects that is mapped from a particular category ofthe categories that comprises a particular term of the terms from which the particular attributeis mapped. The objects are associated in a hierarchical relationship based on thehierarchical relationship of the categories. In other embodiments; a method; system and …,*,2008,19
Collaborative derivation of an interface and partial implementation of programming code,*,A method; system and computer program product provide an implementation of software. Acontrol flow of a software component is constructed based on a specification model. Invarious embodiments; the specification model comprises at least one input and at least onerequirement referencing the at least one input. At least a partial implementation of thesoftware component is generated based on the control flow and the at least one input andthe at least one requirement of the specification model. In some embodiments; thespecification model further comprises at least one output; and the at least a partialimplementation of the software component is also based on the at least one output.,*,2012,18
Using a data mining algorithm to generate rules used to validate a selected region of a predicted column,*,Provided are an article of manufacture; system; and method for using a data miningalgorithm to generate rules used to validate a selected region of a predicted column. A dataset has a plurality of columns and records providing data for each of the columns. Selectionis received of at least one predicted column for which rules are to be generated and at leastone region of the selected at least one predicted column; wherein each region specifies datapositions in the column. The data set is processed to determine association relationshipsamong data in at least one predictor column and subsequences in the selected at least oneregion of the at least one predicted column. At least one rule is generated from therelationships specifying a condition involving at least one predictor column that predicts atleast one value in the selected region of the at least one predicted column.,*,2012,18
Using a data mining algorithm to generate format rules used to validate data sets,*,Provided are a method; system; and article of manufacture for using a data mining algorithmto generate format rules used to validate data sets. A data set has a plurality of columns andrecords providing data for each of the columns. Selection is received of at least one formatcolumn for which format rules are to be generated and selection is received of at least onepredictor column. A format mask column is generated for each selected format column. Forrecords in the data set; a value in the at least one format column is converted to a formatmask representing a format of the value in the format column and storing the format mask inthe format mask column in the record for which the format mask was generated. The at leastone predictor column and the at least one format mask column are processed to generate atleast one format rule. Each format rule specifies a format mask associated with at least …,*,2012,17
Schema mapping specification framework,*,A method; system and program product for specifying; in a schema mapping framework; amapping between a source schema and a target schema. The source and target schemasare schemas included in respective groups of registered; heterogeneous schemas. Thesource and target schemas may be of different types. Serialized versions of the source andtarget schemas include source objects and target objects; respectively. A mapping model isserialized into mapping objects that include logical references representing the sourceobjects and logical references representing the target objects. The logical references areresolved to the source objects and target objects; thereby storing pointers to the sourceobjects and to the target objects. After resolving the logical references; the mapping modelincludes the logical references and the pointers to the source and target objects.,*,2011,17
Enabling distributed enterprise integration with WebSphere and DB2 Information Integrator,Cynthia M Saracco; MA Roth; Daniel C Wolfson,Information technology architects increasingly find themselves searching for better ways toaccess; integrate; and leverage their information; applications; and business processes.Information integration; in particular; is critical to the community of Web-based businesses;as firms that are able to leverage their information resources most effectively are bestpositioned to emerge as leaders in their industries. In this paper; we explore how companiescan solve this complex business challenge by extending the reach of WebSphere®technology with DB2® Information Integrator (II). DB2 II offers WebSphere developers a newapproach to coping with diverse and distributed information sources; enabling them toreduce programming costs; shorten development cycles; and attain reasonable levels ofperformance for server-side components that need to integrate information throughout …,IBM Systems Journal,2004,16
From object-relational to federated databases,Nelson M Mattos; Jim Kleewein; Mary Tork Roth; Kathryn Zeidenstein,Abstract Object-relational databases allow users to manipulate rich data types that are notsupported by traditional relational database systems. However; the majority of such data arein systems that are outside of that database—either in file systems; specialized systems;hierarchical databases; or other varieties of relational database that do not provide as rich alevel of abstraction. Users want to take advantage of object-relational technology to exploitthe rich semantics and abstraction but cannot afford to change existing applications or tomove that data into the database to do so. The solution for enterprises is a federateddatabase system; which allows users to leverage their existing applications and existingdata; while allowing new applications to exploit the functional richness of object-relationaltechnology.,*,1999,15
LabBook: Metadata-driven social collaborative data analysis,Eser Kandogan; Mary Roth; Peter Schwarz; Joshua Hui; Ignacio Terrizzano; Christina Christodoulakis; Renée J Miller,Open data analysis platforms are being adopted to support collaboration in science andbusiness. Studies suggest that analytic work in an enterprise occurs in a complex ecosystemof people; data; and software working in a coordinated manner. These studies also point tofriction between the elements of this ecosystem that reduces user productivity and quality ofwork. LabBook is an open; social; and collaborative data analysis platform designedexplicitly to reduce this friction and accelerate discovery. Its goal is to help users leverageeach other's knowledge and experience to find the data; tools and collaborators they need tointegrate; visualize; and analyze data. The key insight is to collect and use more metadataabout all elements of the analytic ecosystem by means of an architecture and userexperience that reduce the cost of contributing such metadata. We demonstrate how …,Big Data (Big Data); 2015 IEEE International Conference on,2015,14
Data Integration and Data Exchange: It's Really About Time.,Mary Roth; Wang-Chiew Tan,ABSTRACT With the deluge in the amount and variety of data in the world; it is rare for datathat describes an entity to be completely contained and managed by a single data source.As a consequence; there is often great value in combining data about an entity from multiplesources; and also from versions of data reported by the same source over time. Dataintegration in which multiple dimensions of time may be expressed explicitly (eg; as part ofthe data itself) or implicitly (eg; the publication date of a data source); must be performedwith great care. This is because each data source contains only partial (time-specific)knowledge about an entity; and thus their collective knowledge about the entity may containconflicts that need to be resolved. In this paper; we call for a formal framework for dataintegration and data exchange across time that would facilitate the creation of consistent …,CIDR,2013,14
Information Quality: How Good are,Felix Naumann,ABSTRACT Commercial database management systems (DBMS) have come a long waywith respect to efficiency and more recently; with respect to quality and user friendliness. Notonly do they provide an efficient means to store large amounts of data and intuitive querylanguages to access the data; popular DBMS also provide a whole suite of tools to assess;store; manage; clean; and retrieve data in a user-friendly way. Some of these featureaddress database experts; others are targeted at end-users with little or even no databaseknowledge. The recent developments in the field of autonomic computing drive the ease-of-use even further. In this chapter we study how well a typical DBMS meets the goal ofproviding a high-quality data storage and retrieval facility. To this end; we draw on anestablished set of information quality criteria and assess how well an exemplary DBMS …,Challenges of Managing Information Quality in Service Organizations,2007,14
Algebras for nested relations,M Roth; J Kirkpatrick,*,Data Engineering,1989,14
Preference-aware integration of temporal data,Bogdan Alexe; Mary Roth; Wang-Chiew Tan,Abstract A complete description of an entity is rarely contained in a single data source; butrather; it is often distributed across different data sources. Applications based on personalelectronic health records; sentiment analysis; and financial records all illustrate thatsignificant value can be derived from integrated; consistent; and queryable profiles ofentities from different sources. Even more so; such integrated profiles are considerablyenhanced if temporal information from different sources is carefully accounted for. Wedevelop a simple and yet versatile operator; called prawn; that is typically called as a finalstep of an entity integration workflow. Prawn is capable of consistently integrating andresolving temporal conflicts in data that may contain multiple dimensions of time based on aset of preference rules specified by a user (hence the name prawn for preference-aware …,Proceedings of the VLDB Endowment,2014,13
A new medium for the aldohexose-o-toluidine reaction: Direct microdetermination of blood glucose,J Bierens De Haan; M Roth,(The thiourea and benzyl alcohol are Merck pa grade; crystalline glycollic acid may beobtained from Koch-Light Inc.; hexamethylphosphoric triamide and o-toluidine pa grade maybe obtained from Schuchardt; the latter product must be freshly redistilled and colourless;the resulting mixture shows low viscosity and is stable at least for several weeks.),Clinical Chemistry and Laboratory Medicine,1969,12
Data for all: A systems approach to accelerate the path from data to insight,Eser Kandogan; Mary Roth; Cheryl Kieliszewski; Fatma Özcan; Bob Schloss; Marc-Thomas Schmidt,Zettabytes of data are available to be harvested for competitive business advantage; soundgovernment policies; and new insights in a broad array of applications. Yet; most of this datais inaccessible for users; since current data analysis tools require an army of technicalpeople to find; transform; analyze; and visualize data in order to make it consumable fordecision making. In this paper; we present work in progress to lower the barriers for data-driven decision making by introducing a systems approach to scale the user experience; notonly in the volume and variety of data; but also in the skills required to harvest that data. Wecall for a new approach for data-intensive applications that engages the user as anintelligent partner in a social and intelligent conversation with data by automating; guiding;and recommending data; transformations; visualizations; analytics; and suggesting …,Big Data (BigData Congress); 2013 IEEE International Congress on,2013,10
Dynamically building and populating data marts with data stored in repositories,*,Methods; systems; and articles of manufacture for constructing and populating data martswith dimensional data models from a set of data repositories that contain factual andassociation information about a set of related assets are disclosed. An intermediate datawarehouse is generated to process the facts and associations for each asset. Using theintermediate warehouse; one or more data marts are generated with fact tables; dimensions;and hierarchies to fully model the information available for each asset.,*,2011,10
Transformation Rule Discovery through Data Mining.,Holger Kache; Yannick Saillet; Mary Roth,ABSTRACT Data-intensive software programs typically transform a set of source data valuesinto target data values. While the group of developers who write; compile and test thesoftware or the query have a clear understanding of the transformation logic (ortransformation rules) at the time the program is created; that understanding can quickly fadeat an enterprise level for a variety of reasons; including poor documentation; loss of thesource (uncompiled) version of the software; loss of the developers who wrote the software;or lack of available skills in the programming language (eg; COBOL). This leaves theenterprise in a precarious position of not being able to maintain; upgrade or migrate thesoftware programs at the heart of their operations unless they can recreate thetransformations that relate the source data to the target data.,NTII,2008,8
The IBM research accelerated discovery lab,Laura Haas; Melissa Cefkin; Cheryl Kieliszewski; Wil Plouffe; Mary Roth,Data analytics is becoming central to modern society. In the business world; financialinstitutions rely on data analysis to detect and prevent fraud; retailers combine transactiondata with social media and emails to build a better understanding of their clients; industrialgiants use sensor data to improve their carbon footprint. Meanwhile; bioinformatics;astronomy; and particle physics are just a few of the sciences that are being transformed bythe availability of large data sets and new techniques for analyzing data. Cities;governments and social agencies are leveraging data analytics for important causes suchas improving public health and planning for (and reacting to) natural disasters. But the pathfrom raw data to insight; or better yet; predictive or prescriptive capabilities; is still long;errorprone; and expensive. First; data must be acquired–not only the pertinent domain …,ACM SIGMOD Record,2014,7
Determining compliance of a database architecture to an enterprise data standard,*,Provided are a method; system; and program for determining compliance of a databasearchitecture to an enterprise data standard. A physical model is generated definingdatabase elements in a database. A logical model is provided representing a definition ofelements and their relationships. The logical model is used to generate a mapping ofdatabase element names in the physical model to corresponding elements in the logicalmodel. The mapping and the logical model are processed to determine an extent to whichthe database elements and relationships in the physical model violate rules of the logicalmodel.,*,2006,7
An Architecture for Transparent Access to Diverse Data Sources,Mary Tork Roth; Peter Schwarz; Laura Haas,Most large organizations have collected a considerable amount of data; and have investedheavily in systems and applications to manage and access that data. Powerful applicationscan be created by combining information stored in these historically separate data sources.There are several approaches to provide an integrated view of heterogeneous data. Oneapproach is to access data through a component database management system (CDBMS);a middleware system that provides an integrated view of heterogeneous legacy data withoutchanging how or where the data are stored. CDBMS relies on a particular kind ofcomponent; namely; wrappers; to encapsulate the underlying data and mediate between thedata source and the middleware. This chapter describes Garlic wrapper componentarchitecture and summarizes an experience of building wrappers for 10 data sources with …,*,2001,7
A standards-based open source application to gather health assessment data in developing countries,Alex Gainer; Mary Roth; Phil Strong; James Davis,Many organizations are working in developing countries to support local health careorganizations and infrastructure to provide sustainable; community-based health care. Thisrequires not only the influx of medical staff and supplies; but also requires maintainingindividual health care records and enabling the ability to collect; analyze and aggregatedata in the field to customize care to the local needs of the community; and to providecontinuity of care to its citizens. The recent rise of adoption of standards for electronic healthrecords (EHR) provides an alternative to using paper forms in mobile health clinics that oftenserve these countries. In this paper; we describe an open-source; standards-based healthassessment software application developed by the non-profit organization Health RecordsFor Everyone (HR4E) and field tested in a mobile health clinic in rural Ethiopia in the fall …,Global Humanitarian Technology Conference (GHTC); 2012 IEEE,2012,4
Method; system; and program for invoking methods between computer languages,*,Provided are a method; system; and program for invoking methods between computerlanguages. A plurality of subclasses of a class in a first computer language are instantiatedand a plurality of subclasses of a class in a second computer language are instantiated;wherein methods in the subclasses in the second computer language implementfunctionality of methods in the subclasses in the first computer language. A call is receivedfrom an application in the first computer language to one method in the subclasses of thefirst computer language; wherein the call to the method in the subclass of the first computerlanguage invokes a corresponding method in the subclasses of the second computerlanguage that implements the functionality of the called method in the first computerlanguage.,*,2008,4
Methods to integrate user-defined operations into a database,*,Systems; methods; and computer products that support techniques associated with highlyreliable transaction protocol semantics in databases. Such techniques extend databasetransaction semantics that support a single-phase or a two-phase commit protocol to includeuser-defined operations while supporting the XA X/Open® Distributed TransactionProcessing Protocol (“XA Transaction Protocol”). The preferred embodiment of the presentinvention novelly enables user-defined operations that access external resources by meansof the XA Transaction Protocol to be included in database transaction processing features.Thereby user-level access to well-defined APIs is provided. Further; the preferredembodiment of the present invention novelly ensures atomicity for the results of thedatabase transaction that includes both the user-defined operations and database …,*,2009,2
Systems; methods; and computer program products to integrate user-defined operations into a database transaction,*,Systems; methods; and computer products that support techniques associated with highlyreliable transaction protocol semantics in databases. Such techniques extend databasetransaction semantics that support a single-phase or a two-phase commit protocol to includeuser-defined operations while supporting the XA X/Open® Distributed TransactionProcessing Protocol (“XA Transaction Protocol”). The preferred embodiment of the presentinvention novelly enables user-defined operations that access external resources by meansof the XA Transaction Protocol to be included in database transaction processing features.Thereby user-level access to well-defined APIs is provided. Further; the preferredembodiment of the present invention novelly ensures atomicity for the results of thedatabase transaction that includes both the user-defined operations and database …,*,2005,2
Providing a visual and conversational experience in support of recommendations,*,The mapping system and method comprises receiving a query identifying a source entity;the source entity being of a first entity-type; generating a plurality of candidate entities froman analysis of an entity-relationship graph in response to the query based on the sourceentity; and computing feature values for each candidate entity of the plurality of candidateentities by passing the source entity and the plurality of candidate entities to a type-specificentity recommender particular to the first entity-type.,*,2017,1
Using Machine Learning to Accelerate Data Wrangling,Shilpi Ahuja; Mary Roth; Rashmi Gangadharaiah; Peter Schwarz; Rafael Bastidas,70% Of the time spent on data analytics is not actually spent on data analytics; but rather; indata wrangling: the process of finding; interpreting; extracting; preparing and recombiningthe data to be analyzed. For data that is collected as free-form text; the lack of standards orcompeting standards often results in a variety of formats for expressing the same type ofdata; making the data wrangling step a tedious and error-prone process. For example; USstreet addresses may be expressed with a house number; PO Box; rural or military route;and/or a direction-all of which can be abbreviated or spelled out in a variety of ways. In thispaper; we present an algorithm that uses machine learning to efficiently and automaticallyidentify categories of attributes; such as geo-spatial; that are present in a data file and wediscuss results on a variety of real data sets. Our implementation can be used to …,Data Mining Workshops (ICDMW); 2016 IEEE 16th International Conference on,2016,1
System and method of integrating time-aware data from multiple sources,*,Abstract A time-aware union operator is disclosed for consistent integration of time-awaredata; wherein the time-aware union produces a time-aware consistent integrated view ofunderlying sources according to specified key constraints and policies. The implementationof time-aware union is idempotent; commutative; and associative; thus making it suitable fordata integration; and it produces the same integrated outcome; modulo representation oftime; regardless of the order in which sources are integrated.,*,2018,*
System and method to automate provenance-aware application execution,*,Abstract A method to support ad hoc collaboration and generation of workflows for a team ofusers may comprise providing data from a provenance graph to launched applications;selectively using the provided data from the provenance graph and additional input to createderived data and derived outputs; and routing the derived data and the derived outputs tothe provenance graph; recording; in the provenance graph; subsequences of the launchedapplications; recommending one of the recorded subsequences; based on the history ofexecution of the recorded subsequences of the launched applications; creating a newapplication with the recommended subsequences of the launched applications; launchingthe newly created application; and storing the newly created application in a catalog ofapplications for use by the user.,*,2018,*
Autonomous agent system,*,According to an embodiment of the present invention; a method for operating a cognitivecomputing system comprises starting a capture agent on a processor; subscribing thecapture agent to a second agent; receiving a first message from the second agent; storingthe received first message in a memory; receiving a notification of a new subscription from athird agent; and registering the capture agent to subscribe to the new subscription from thethird agent.,*,2017,*
Web 2.0 system and method for dynamic categorization of heterogeneous and regulated enterprise assets,*,A system and method for the dynamic categorization of heterogeneous; regulated enterpriseinformation assets. In one embodiment of the invention a system includes a computernetwork controlled by an enterprise and a database including a plurality of enterprise dataentities. A user interface; through which a plurality of enterprise users may access theenterprise data entities; is also used by the plurality of users to assign user-definedcategories to the enterprise data entities. The user interface is configured to enable aplurality of the users to access and assign additional user-defined categories to enterprisedata entities having user-defined categories previously assigned by other users.,*,2017,*
Altersvorsorge im internationalen Vergleich: Staatliche Produkte für die zusätzliche Altersvorsorge in Schweden und dem Vereinigten Königreich,Axel Börsch-Supan; Markus Roth; Gert G Wagner,Die Kurzexpertise stellt aus sozio-ökonomischer und juristischer Sicht die zusätzlichenAltersvorsorgesysteme in Schweden und im Vereinigten Königreich dar. In Schweden wirddie obligatorische kapitalgedeckte Säule zentral im Rahmen der staatlichenRentenversicherung organisiert; Anlageentscheidungen obliegen dem Versicherten bzw.werden im Default-Fall unabhängig von staatlichem Einfluss gefällt. Die Versicherten habenzwar ein breites Spektrum von Wahlmöglichkeiten; empirisch dominiert der Default-Fonds.In Schweden sind nach Angaben der OECD zudem neunzig Prozent der Arbeitnehmer inein tarifvertraglich begründetes Betriebsrentensystem eingebunden. Im VereinigtenKönigreich wird die kapitalgedeckte Säule dagegen nur als Betriebsrente organisiert.Arbeitgeber müssen eine Betriebsrente anbieten; Arbeitnehmer werden automatisch …,*,2017,*
System and method of integrating time-aware data from multiple sources,*,A time-aware union operator is disclosed for consistent integration of time-aware data;wherein the time-aware union produces a time-aware consistent integrated view ofunderlying sources according to specified key constraints and policies. The implementationof time-aware union is idempotent; commutative; and associative; thus making it suitable fordata integration; and it produces the same integrated outcome; modulo representation oftime; regardless of the order in which sources are integrated.,*,2016,*
Querying Multimedia Data from Multiple Repositories by Content: the Garlic" Project,D Lee Flickner; D Petkovic; PM Schwarz; J Thomas; M Tork Roth,Abstract We describe Garlic; an object-oriented multimedia middleware query system. Garlicenables existing data management components; such as a relational database or a full textsearch engine; to be integrated into an extensible information management system thatpresents a common interface and user access tools. We focus in this paper on how QBIC; animage retrieval system that provides content-based image queries; can be integrated intoGarlic. This results in a system in which a single query can combine visual and nonvisualdata using type-specific search techniques; enabling a new breed of multimediaapplications,Visual Database Systems 3: Visual information management,2013,*
Tempura: Enabling When-provenance for Evolving Hierarchical Data,Mary Roth; Wang-Chiew Tan,*,Proceedings of the VLDB Endowment,2011,*
Successful Information Integration requires People Integration.,M Klumpp; M Roth,ABSTRACT Information integration technology has been a fertile ground for research overthe past two decades and has led to a number of commercially available products. However;the call for papers for this workshop rightly questions why the use of this technology is not aswidely adopted as one might expect in this information age. In this paper; we take theposition that the answer to this question lies not in examining what gaps might exist in theunderlying integration technology; but rather; that the answer might instead lie in examiningthe gaps that exist between the people who are tasked with information integration activityitself.,NTII,2008,*
Schwarz; Gunter Christian: Europaisches Gesellschaftsrecht.[2 Bande.] Baden-Baden 2000; Habersack; Mathias: Europaisches Gesellschaftsrecht. Munchen 1999 [...,M Roth,*,RABELS ZEITSCHRIFT FUR AUSLANDISCHES UND INTERNATIONALES PRIVATRECHT,2003,*
The Propel Distributed Services Platform,Mike Carey; Steve Kirsch; Mary Roth; Bert Van der Linden; Nicolas Adiba; Michael Blow; Daniela Florescu; David Li; Ivan Oprencak; Rajendra Panwar; Runping Qi; David Rieber; John C Shafer; Brian Sterling; Tolga Urhan; Brian Vickery; Dan Wineman; Kuan Yee,Abstract The Propel Distributed Services Platform (PDSP) is the core software product ofPropel; a new Internet infrastructure software company. The PDSP product was created toenable Java developers to architect; implement; deploy; and maintain Internet applicationsand services much more quickly and easily than before while still providing all of the RAS(reliability; availability and scalability) that such applications require. In this presentation; weprovide a brief overview of PDSP's key features; including its support for reliable andscalable data management; text indexing and searching; and persistent queuing. We alsodiscuss its integrated Java APIs; built-in support for online-deployable data and schemachanges; and system administration facilities.,VLDB,2001,*
EQUALLY IMPORTANT-LANGUAGE FACILITIES; HOW THEYRE USED,MA ROTH,*,COMPUTER,1982,*
Teaching in Clinical Chemistry: Evolution and Needs,M Roth,Summary: As a young discipline; clinical chemistry has undergone a rapid expansion since1950. The development of suitable teaching programs has not always followed withcorresponding speed. Different aspects of teaching in clinical chemistry must be considered:1. Postgraduate teaching; this may be provided to graduates in medicine; science orpharmacy in view of complementing their respective basic studies by knowledge from theother disciplines. The aim is to form clinical chemists having a good understanding both ofmedical problems related to the laboratory and of the technical and chemical bases ofanalytical work.,Clinical Chemistry and Laboratory Medicine,1978,*
Recovery or good results in the treatment of concomitant strabismus (reflections following a survey),MA Roth,Author: Roth MA; Journal: Bulletin des societes d'ophtalmologie de France[1974/11].,Bulletin des societes d'ophtalmologie de France,1974,*
Gesellschaft fur ultraschalldiagnostik der DDR,R MILLNER; H GROSSMANN; L FILIPCZYNSKI; J ETIENNE; G HELKE; B GRAMLICH; R MILLER; CH KRUG; G WAGNER; M WEHNER; K WALTHER; W HEIDEL; K BUSCHMANN; W BEINROTH; L WINKELMANN; W BOBE; H SCHRODER; B HERMANN; RM GOMULA; RJ KUBAK; K BORODZINSKI; G PARDEMANN; S MAGNUS; S VOGEL; H HOFFMANN; J OBRAZ; KP RICHTER; U HAACKE; HJ HEIN; G ORTMANN; M ROTH; K LUKAWSKA; JG HEIDELBACH; M MILLNER; W PFAU; R PELLICCIONI; B ROSCISCEWSKA; I HRAZDIRA; W BOCH; E ROSENFELD; H PETZOLD,*,*,*,*
Watter de Gmyter Berlin-New York,MARC ROTH,All submittcd papcrs will passed on fot asscssmcnt by the respective editor to two spedalistsin the particular Seid; in most cases a mcmbcr of the co-editorial board äs well äs anOutsider will be asked to evaluate the article. Only if both agree and both give positive voteswill the paper be accepted for publication. Only then will the contribution be passed on the tocditorial secretaries (Drs. JW DUDENHAUSEN and K. WAGNER; Genthiner Str. 13; 1000Berlin 30» Germany) for further editorial processing.,*,*,*
Program Committees,Sihem Amer Yahia; Kevin Beyer; CWI Peter Boncz; Netherlands Angela Bonifati; Arbee Chen; Jan Chomicki; Bobbie Cochrane; Latha Colby; Ada Fu; Sumit Ganguly; Torsten Grust; Raghav Kaushik; Arnd Christian Konig; Sailesh Krishnamurthy; Amalgamated Insight; David Lomet; Christopher Olston; Fatma Ozcan; Neoklis Polyzotis; Raghu Ramakrishnan; Krithi Ramamritham; Vijayshankar Raman; Rajeev Rastogi; Mary Roth; Jerome Simeon; Ioana Stanoi; Andrew Tomkins; AUEB Vasilis Vassalos; Greece Victor Vianu; Min Wang; Aidong Zhang,Foto Afrati; NTUA; Greece Natassa Ailamaki; CMU; USA Sihem Amer Yahia; YahooResearch; USA Paolo Atzeni; Univ. di Roma Tre; Italy Shivnath Babu; Duke Univ.; USA JamesA. Bailey; Univ. of Melbourne; Australia Magdalena Balazinska; Univ. of Washington; USA KevinBeyer; IBM Research; USA Michael Boehlen; Univ. of Bolzano; Italy Peter Boncz; CWI; NetherlandsAngela Bonifati; CNR; Italy Arbee Chen; National Tsing Hua Univ.; Taiwan Mitch Cherniack;Brandeis Univ.; USA Jan Chomicki; SUNY Buffalo; USA Stavros Christodoulakis; Tech Univ.of Crete; Greece Bobbie Cochrane; IBM Research; USA Edith Cohen; AT&T Labs; USA LathaColby; IBM Research; USA Graham Cormode; AT&T Labs; USA Abhinandan Das; GoogleLabs; USA Amol Deshpande; Univ. of Maryland; USA Alin Dobra; Univ. of Florida; USA ElenaFerrari; Univ. of Insubria; Italy J. Christoph Freytag; Humboldt Univ.; Germany Ada Fu …,*,*,*
Data Engineering,Serge Abiteboul; Sophie Cluet; Tova Milo; Pini Mogilevsky; Jerome Siméon; Sagit Zohar; Philip A Bernstein; Thomas Bergstraesser; Marco Carrer; Ashok Joshi; Paul Lin; Alok Srivastava; Laura Haas; Renee Miller; Bartholomew Niswonger; Mary Tork Roth; Peter Schwarz; Edward Wimmers,Membership in the TC on Data Engineering (http: www. is open to all current members of theIEEE Computer Society who are interested in database systems. The web page for the DataEngineering Bulletin is http://www. research. microsoft. com/research/db/debull. The webpage for the TC on Data Engineering is http://www. ccs. neu. edu/groups/IEEE/tcde/index.html.,*,*,*
Bulletin of the Technical Committee on,Serge Abiteboul; Sophie Cluet; Tova Milo; Pini Mogilevsky; Jerome Siméon; Sagit Zohar; Philip A Bernstein; Thomas Bergstraesser; Marco Carrer; Ashok Joshi; Paul Lin; Alok Srivastava; Laura Haas; Renee Miller; Bartholomew Niswonger; Mary Tork Roth; Peter Schwarz; Edward Wimmers,*,*,*,*
