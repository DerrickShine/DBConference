Keys for XML,Peter Buneman; Susan Davidson; Wenfei Fan; Carmem Hara; Wang-Chiew Tan,Keys are an essential part of database design [2;19]: they are fundamental to data models andconceptual design; they provide the means by which one tuple in a relational database mayrefer to another tuple; and they are important in update; for they enable us to guarantee that anupdate will affect precisely one tuple. More philosophically; if we think of a tuple as representingsome real-world entity; the key provides an invariant connection between the tuple andentity … If XML documents are to do double duty as databases; then we shall need keys forthem. In fact; a cursory examination 3 of existing document type definitions (DTDs) reveals anumber of cases in which some element or attribute is specified––in comments––as a “uniqueidentifier”. Moreover a number of scientific databases; which are typically stored in somespecial-purpose hierarchical data format ripe for conversion to XML; have a …,Computer networks,2002,467
Keys for XML,Peter Buneman; Susan Davidson; Wenfei Fan; Carmem Hara; Wang-Chiew Tan,Keys are an essential part of database design [2;19]: they are fundamental to data models andconceptual design; they provide the means by which one tuple in a relational database mayrefer to another tuple; and they are important in update; for they enable us to guarantee that anupdate will affect precisely one tuple. More philosophically; if we think of a tuple as representingsome real-world entity; the key provides an invariant connection between the tuple andentity … If XML documents are to do double duty as databases; then we shall need keys forthem. In fact; a cursory examination 3 of existing document type definitions (DTDs) reveals anumber of cases in which some element or attribute is specified––in comments––as a “uniqueidentifier”. Moreover a number of scientific databases; which are typically stored in somespecial-purpose hierarchical data format ripe for conversion to XML; have a …,Computer networks,2002,467
Reasoning about keys for XML,Peter Buneman; Susan Davidson; Wenfei Fan; Carmem Hara; Wang-Chiew Tan,Abstract We study absolute and relative keys for XML; and investigate their associateddecision problems. We argue that these keys are important to many forms of hierarchicallystructured data including XML documents. In contrast to other proposals of keys for XML; weshow that these keys are always (finitely) satisfiable; and their (finite) implication problem isfinitely axiomatizable. Furthermore; we provide a polynomial time algorithm for determining(finite) implication in the size of keys. Our results also demonstrate; among other things; thatthe analysis of XML keys is far more intricate than its relational counterpart.,Information Systems,2003,286
Reasoning about keys for XML,Peter Buneman; Susan Davidson; Wenfei Fan; Carmem Hara; Wang-Chiew Tan,Abstract We study absolute and relative keys for XML; and investigate their associateddecision problems. We argue that these keys are important to many forms of hierarchicallystructured data including XML documents. In contrast to other proposals of keys for XML; weshow that these keys are always (finitely) satisfiable; and their (finite) implication problem isfinitely axiomatizable. Furthermore; we provide a polynomial time algorithm for determining(finite) implication in the size of keys. Our results also demonstrate; among other things; thatthe analysis of XML keys is far more intricate than its relational counterpart.,Information Systems,2003,162
Reasoning about keys for XML,Peter Buneman; Susan Davidson; Wenfei Fan; Carmem Hara; Wang-Chiew Tan,Abstract We study absolute and relative keys for XML; and investigate their associateddecision problems. We argue that these keys are important to many forms of hierarchicallystructured data including XML documents. In contrast to other proposals of keys for XML; weshow that these keys are always (finitely) satisfiable; and their (finite) implication problem isfinitely axiomatizable. Furthermore; we provide a polynomial time algorithm for determining(finite) implication in the size of keys. Our results also demonstrate; among other things; thatthe analysis of XML keys is far more intricate than its relational counterpart.,Information Systems,2003,162
Querying and managing provenance through user views in scientific workflows,Olivier Biton; Sarah Cohen-Boulakia; Susan B Davidson; Carmem S Hara,Workflow systems have become increasingly popular for managing experiments wheremany bioinformatics tasks are chained together. Due to the large amount of data generatedby these experiments and the need for reproducible results; provenance has become ofparamount importance. Workflow systems are therefore starting to provide support forquerying provenance. However; the amount of provenance information may beoverwhelming; so there is a need for abstraction mechanisms to help users focus on themost relevant information. The technique we pursue is that of" user views". Sincebioinformatics tasks may themselves be complex sub-workflows; a user view determineswhat level of sub-workflow the user can see; and thus what data and tasks are visible inprovenance queries. In this paper; we formalize the notion of user views; demonstrate …,Data Engineering; 2008. ICDE 2008. IEEE 24th International Conference on,2008,148
Propagating XML constraints to relations,Susan Davidson; Wenfei Fan; Carmem Hara,Abstract We present a technique for refining the design of relational storage for XML data.The technique is based on XML key propagation: given a set of keys on XML data and amapping (transformation) from the XML data to relations; what functional dependencies musthold on the relations produced by the mapping? With the functional dependencies one canthen convert the relational design into; eg 3NF; BCNF; and thus develop efficient relationalstorage for XML data. We provide several algorithms for computing XML key propagation.One algorithm is to check whether a functional dependency is propagated from a set of XMLkeys via a predefined mapping; this allows one to determine whether or not the relationaldesign is in a normal form. The others are to compute a minimum cover for all functionaldependencies that are propagated from a set of XML keys and hold on a universal …,Journal of Computer and System Sciences,2007,107
Propagating XML constraints to relations,Susan Davidson; Wenfei Fan; Carmem Hara,Abstract We present a technique for refining the design of relational storage for XML data.The technique is based on XML key propagation: given a set of keys on XML data and amapping (transformation) from the XML data to relations; what functional dependencies musthold on the relations produced by the mapping? With the functional dependencies one canthen convert the relational design into; eg 3NF; BCNF; and thus develop efficient relationalstorage for XML data. We provide several algorithms for computing XML key propagation.One algorithm is to check whether a functional dependency is propagated from a set of XMLkeys via a predefined mapping; this allows one to determine whether or not the relationaldesign is in a normal form. The others are to compute a minimum cover for all functionaldependencies that are propagated from a set of XML keys and hold on a universal …,Journal of Computer and System Sciences,2007,107
-RRXS: Redundancy reducing XML storage in relations,Yi Chen; Susan Davidson; Carmem Hara; Yifeng Zheng,This chapter proposes a novel constraint definition called XML functional dependencies(XFDs) that capture structural as well as semantic information. It presents a set of rewritingrules for XFDs; and use them to design a polynomial time algorithm which; given an input setof XFDs; computes a reduced set of XFDs. Based on this algorithm; it presents a redundancyremoving storage mapping from XML to relations called redundancy reducing XML (RRXS).RRXS produces a relational design that preserves structural and semantic constraints of theXML data while reducing redundancies. The effectiveness of the mapping is demonstratedby experiments on three data sets. The chapter considers the problem of providing amapping from XML to a relational database taking structural as well as a broad class ofsemantic constraints into account. RRXS generates much smaller relational instances …,*,2003,77
Reasoning about nested functional dependencies,Carmem S Hara; Susan B Davidson,Abstract Functional dependencies add semantics to a database schema; and are useful forstudying various problems; such as database design; query optimization and howdependencies are carried into a view. In the context of a nested relational model; thesedependencies can be extended by using path expressions instead of attribute names;resulting in a class of dependencies that we call nested functional dependencies (NFDs).NFDs define a natural class of dependencies in complex data structures; in particular theyallow the specification of many useful intra-and inter-set dependencies (ie; dependenciesthat are local to a set and dependencies that require consistency between sets). Suchconstraints cannot be captured by existing notions of functional; multi-valued; or joindependencies. This paper presents the definition of NFDs and gives their meaning by …,Proceedings of the eighteenth ACM SIGMOD-SIGACT-SIGART symposium on Principles of database systems,1999,60
An efficient data acquisition model for urban sensor networks,Sérgio S Furlaneto; Aldri L Dos Santos; Carmem S Hara,Applications for Wireless sensor networks (WSN) usually take into consideration thespecificity of the environment in which they are deployed in order to save the sensors' limitedresources. In particular; the sensing task in urban environments requires hundreds and eventhousands of sensors to be spread over the monitored area. Moreover; in environmentalmonitoring applications; sensors that are closely located usually provide similar readings.That is; spatial proximity is related to data similarity. In this paper we propose SIDS (SpatialIndexing Based on Data Similarity for Sensor Networks); a data model that explores thischaracteristic in order to provide scalability and efficient query processing on urban WSNs.Scalability is achieved by grouping sensors with similar readings; while efficiency forprocessing queries relies on two strategies: the concept of repositories; which consist of …,Network Operations and Management Symposium (NOMS); 2012 IEEE,2012,17
Propagating XML keys to relations,S Davidson; W Fan; C Hara,*,*,2001,14
A flexible network monitoring tool based on a data stream management system,Natascha Petry Ligocki; Carmem S Hara; Christian Lyra,Network monitoring is a complex task that generally requires the use of different tools forspecific purposes. This paper describes a flexible network monitoring tool; called PaQueT;designed to meet a wide range of monitoring needs. The user can define metrics as queriesin a process similar to writing queries on a database management system. This approachprovides an easy mechanism to adapt the tool as system requirements evolve. PaQueTallows one to monitor values ranging from packet level metrics to those usually providedonly by tools based on Netflow or SNMP. PaQueT has been developed as an extension ofBorealis Data Stream Management System. The first advantage of our approach is the abilityto generate measurements in real time; minimizing the volume of data stored; second; thetool can be easily extended to consider several types of network protocols. We have …,Computers and Communications; 2008. ISCC 2008. IEEE Symposium on,2008,13
XML data fusion,Frantchesco Cecchin; Cristina Dutra de Aguiar Ciferri; Carmem Satie Hara,Abstract Ensuring high quality data when collecting and integrating information fromheterogeneous sources into a data warehouse is a challenging problem. In this paper; wepropose a model for XML data fusion; which allows the integrator to define data cleaningrules for solving value conflicts that may have been detected during the integration process.These rules resemble decisions that are made by users when data are manually curatedand; once defined; conflicts detected in subsequent integration processes that are within thecontext of existing rules can be automatically solved without user intervention. We alsointroduce a notion of fusion policy validation that prevents conflicting resolution rules to bedefined. To validate our proposal; we developed XFusion; a rule-based cleaning tool thatstores curated data in a integrated repository.,International Conference on Data Warehousing and Knowledge Discovery,2010,11
Querying an object-oriented database using CPL,Susan B Davidson; Carmem Hara; Lucian Popa,Abstract The Collection Programming Language is based on a complex value model of dataand has successfully been used for querying transforming and integrating data from a widevariety of structured data sources-relational; ACeDB; and ASN. 1 among others. However;since there is no notion of objects and classes in CPL; it cannot adequately model recursivetypes or inheritance; and hence cannot be used to query object-oriented databases(OODBs). By adding a reference type and four operations to CPL-dereference; methodinvocation; identity test and class type cast-it is possible to express a large class ofinteresting" safe" queries against OODBs. As an example of how the extended CPL can beused to query an OODB; we will describe how the extended language has been used as aquery interface to Shore databases.,Technical Reports (CIS),1997,11
Phoenix: A relational storage component for the cloud,Davi EM Arnaut; Rebeca Schroeder; Carmem S Hara,This paper describes the design and architecture of a cloud-based relational databasesystem. The system's core component is a storage engine; which is responsible for mappingthe logical schema; based on relations; to a physical storage; based on a distributed key-value data store. The proposed stratified architecture provides physical data independence;by allowing different approaches for data mapping and partitioning; while the distributeddata store is responsible for providing scalability; availability; data replication and ACIDproperties. A prototype of the system; named Phoenix; has been developed based on theproposed architecture using a transactional key-value store. Experimental studies on acluster of commodity servers show that Phoenix preserves the desired properties of key-value stores; while providing relational database functionality at a very low overhead.,Cloud Computing (CLOUD); 2011 IEEE International Conference on,2011,10
A model for XML instance level integration,Aldo Monteiro Do Nascimento; Carmem S Hara,Abstract There are two major problems for merging instances from different sources in orderto build a datawarehouse: entity identification ambiguity and attribute value conflict. In thispaper we propose a data model that facilitates the resolution of value attribute conflicts byexplicitly representing them in the integrated schema. In this model; the datawarehouse isan XML tree populated with data imported from one or more XML sources; and nodes areannotated with provenance information. The purpose of annotations is twofold: first; theyrepresent the origin of every element in the datawarehouse. This information is essential fordetermining the quality and amount of trust one places on the data. Second; they allow theportion of source XML tree used to populate the warehouse to be reconstructed. Thiscapability is important if one needs the original document to compare with new releases …,Proceedings of the 23rd Brazilian symposium on Databases,2008,7
A semantical change detection algorithm for XML,Rodrigo Cordeiro Dos Santos; Carmem Hara,Abstract XML diff algorithms proposed in the literature have focused on the structuralanalysis of the document. When XML is used for data exchange; or when different versionsof a document are downloaded periodically; a matching process based on keys defined onthe document can generate more meaningful results. In this paper; we use XML keysdefined in [5] to improve the quality of diff algorithms. That is; XML keys determine whichelements in different versions refer to the same entity in the real world; and therefore shouldbe matched by the diff algorithm. We present an algorithm that extends an existing diffalgorithm with a preprocessing phase for pairing elements based on keys.,SEKE 2007,2007,6
Inference rules for nested functional dependencies,Carmem S Hara; Susan B Davidson,Abstract Functional dependencies add semantics to a database schema; and are useful forstudying various problems; such as database design; query optimization and howdependencies are carried into a view. In the context of a nested relational model; thesedependencies can be extended by using path expressions instead of attribute names;resulting in a class of dependencies that we call nested functional dependencies (NFDs).NFDs define a natural class of dependencies in complex data structures; in particular theyallow the specification of many useful intra-and inter-set dependencies (ie; dependenciesthat are local to a set and dependencies that require consistency between sets). Suchconstraints cannot be captured by existing notions of functional; multi-valued; or joindependencies.,*,1999,6
Empowering integration processes with data provenance,Bruno Tomazela; Carmem Satie Hara; Ricardo Rodrigues Ciferri; Cristina Dutra de Aguiar Ciferri,Abstract In some integration applications; users are allowed to import data fromheterogeneous sources; but are not allowed to update these source data directly. Importeddata may be inconsistent; and even when inconsistencies are detected and solved; thesechanges may not be propagated to the sources due to their update policies. Therefore; theycontinue to provide the same inconsistent data in future imports until the proper authorityupdates them. In this paper; we propose PrInt; a model that supports user's decisions oncleaning data to be automatically reapplied in subsequent integration processes. Byreproducing previous decisions; the user may focus only on new inconsistencies originatedfrom source modified data. The reproducibility provided by PrInt is based on logging; and byincorporating data provenance into the integration process. Other major features of PrInt …,Data & Knowledge Engineering,2013,5
Affinity-based xml fragmentation,Rebeca Schroeder; Ronaldo Santos Mello; Carmem Satie Hara,ABSTRACT In this paper we tackle the fragmentation problem for highly distributeddatabases. In such an environment; a suitable fragmentation strategy may provide scalabilityand availability by minimizing distributed transactions. We propose an approach for XMLfragmentation that takes as input both the application's expected workload and a storagethreshold; and produces as output an XML fragmentation schema. Our workload-awaremethod aims to minimize the execution of distributed transactions by packing up related datain a small set of fragments. We present experiments that compare alternative fragmentationschemas; showing that the one produced by our technique provides a finer-grained resultand better system throughput.,arXiv preprint arXiv:1210.6272,2012,5
Uma ferramenta de monitoramento de redes usando sistemas gerenciadores de streams de dados,Natascha Petry Ligocki,ABSTRACT Network monitoring is a complex task that generally requires the use of differenttools for specific purposes. This paper describes a flexible network monitoring tool; calledPaQueT; designed to meet a wide range of monitoring needs. The user can define metricsas queries in a process similar to writing queries on a database management system. Thisapproach provides an easy mechanism to adapt the tool as system requirements evolve.PaQueT allows one to monitor values ranging from packet level metrics to those usuallyprovided only by tools based on Netflow and SNMP. Besides; the tool has a steepknowledge curve and allows one to obtain the desired information quickly. PaQueT hasbeen developed as an extension of Borealis Data Streams Management System. The firstadvantage of our approach is the ability to generate measurements in real time …,*,2008,5
Dysto-A dynamic storage model for wireless sensor networks,Nuno MF Gonçalves; Aldri L dos Santos; Carmem S Hara,Abstract One of the main problems in wireless sensor networks (WSN) is the energyconsumption needed for storing and querying sensed data; since sensors are devices withvery limited resources and battery. One of the main factors that has an impact on energyconsumption is the data repository location; that is; the location where the sensor data isstored. In this paper we propose DYSTO; an in-network and dynamic data storage; in whichthe location of the repository is chosen based on information collected over the network.Intuitively; DYSTO chooses to store sensed data close to where it is most frequently needed:close to the query entry point when the query rate is high; and close to data sources forcoping with high sensed data production rates. Moreover; the query load is analyzed inorder to keep values that are frequently queried together in the same repository. Our …,Journal of Information and Data Management,2012,4
Layering a dbms on a dht-based storage engine,Eduardo A Ribas; Roney Uba; Ana Paula Reinaldo; Arion de Campos Jr; Davi Arnaut; Carmem Hara,Abstract This article proposes an architecture for integrating a relational databasemanagement system (DBMS) with a distributed hash table (DHT). Systems developed basedon this architecture provide functionalities of DHTs; such as scalability; decentralization andfault tolerance; combined with a high level query language provided by a DBMS. The maincomponent of this architecture is the storage engine; responsible for implementing theinterface between an SQL query processor and a DHT. We have implemented a systembased on the MySQL DBMS and the Bamboo DHT; and conducted an experimental study,Journal of Information and Data Management,2011,4
XKeyDiff-Um algoritmo semântico para detecç ao de mudanças entre documentos XML,Rodrigo C Santos; Carmem S Hara,Abstract. There are several diff algorithms for XML proposed in the literature. Some of themfavor the quality of the changes detected while others aim at performance. In bothapproaches only the structure of the document is considered. In this paper; we present a diffalgorithm in which XML keys are used to match elements in the documents prior to theirstructural analisys. The effectiveness of this approach in improving the results of an existingdiff algorithm is shown by an example. Resumo. Existem diversos trabalhos de algoritmosde diff para documentos XML; alguns concernentesa qualidade da detecç ao dasmudanças; outros preocupados com a eficiência do método utilizado. Em ambas asabordagens; a análise do documento é apenas estrutural. Este trabalho propoe umalgoritmo que faz uso de chaves para XML e um outro algoritmo de diff; a fim de trabalhar …,*,2004,4
Partitioning templates for RDF,Rebeca Schroeder; Carmem S Hara,Abstract In this paper; we present an RDF data distribution approach which overcomes theshortcomings of the current solutions in order to scale RDF storage both with the volume ofdata and query requests. We apply a workload-aware method that identifies frequentpatterns accessed by queries in order to keep related data in the same partition. In order toavoid exhaustive analysis on large datasets; a summarized view of the datasets isconsidered to deploy our reasoning through partitioning templates for data items in an RDFstructure. An experimental study shows that our method scales well and is effective toimprove the overall performance by decreasing the amount of message passing amongservers; compared to alternative data distribution approaches for RDF.,East European Conference on Advances in Databases and Information Systems,2015,3
Um estudo sobre bancos de dados em grafos nativos,Raqueline RM Penteado; Rebeca Schroeder; Diego Hoss; Jaqueline Nande; Ricardo M Maeda; Walmir O Couto; Carmem S Hara,Abstract. Graph databases support applications based on complex data models where theinterconnectivity of data is an important aspect. The ever-increasing amount of data madeavailable by these systems has been handled by graph databases in order to scale suchsystems. In spite of the straightforward way to represent complex data; native graphdatabases provide efficient query processing by avoiding costly joins. This paper presents acomparative analysis among native graph databases by considering some importantfeatures for data management system in this context. Resumo. Sistemas de banco de dadosem grafos suportam aplicaç oes baseadas em modelos de dados cuja a interconectividadede dados é um aspecto importante. O volume de dados crescente envolvendo taisaplicaçoes vem sendo tratado por uma série de soluç oes de gerenciamento de dados …,X ERBD-Escola Regional de Banco de Dados,2014,3
Backstreamdb: A distributed system for backbone traffic monitoring providing arbitrary measurements in real-time,Christian Lyra; Carmem S Hara; Elias P Duarte,Abstract Monitoring the traffic of wide area networks consisting of several autonomoussystems connected through a high-speed backbone is a challenge due to the huge amountof traffic. Keeping logs for obtaining measurements is unfeasible. This work describes adistributed real-time strategy for backbone traffic monitoring that does not employ logs andallows arbitrary metrics to be collected about the traffic of the backbone as a whole. Traffic issampled by monitors that are distributed across the backbone and are accessed by aStream Processing Engine (SPE). Besides the distributed monitoring architecture; wepresent an implementation (BackStreamDB) that was deployed on a national backbone.Case studies are described that show the system flexibility. Experiments are reported inwhich we evaluated the amount of traffic that can be handled.,International Conference on Passive and Active Network Measurement,2012,3
Erratum to “Propagating XML constraints to relations”[J. Comput. System Sci. 73 (2007) 316–361],Susan Davidson; Wenfei Fan; Carmem Hara,*,Journal of Computer and System Sciences,2008,3
Reasoning about functional and key dependencies in hierarchically structured data,Carmem Satie Hara,This dissertation investigates key and functional dependencies in hierarchically structureddata and their implication problems. More specifically; we will present a definition offunctional dependencies for a nested relational model; and a definition of keys for XML; andshow that they are finitely satisfiable and moreover; that there exists a sound and completeset of inference rules for determining their implication. There is a natural analogy betweenthis work and the theory of functional dependencies for the relational model. The theory offunctional dependencies constitutes an important part of the relational database theory. Itforms the basis of the normalization theory for the relational model; and it is also useful forquery optimization and to study how dependencies are carried from a database to a view. Inall these applications; it is important to be able to reason about functional dependencies …,*,2004,3
Uma Interface Gráfica para Algoritmos de Detecç ao de Diferenças entre Documentos XML,Frantchesco Cecchin; Carmem Satie Hara,Abstract. There are many algorithms in the literature for detecting differences between XMLdocuments. However; only a few provide a graphical interface to display their results. Such atool allows the user to clearly identify the differences and check the correctress of the result.As a consequence; the verification step becomes faster and less prone to errors. Thepurpose of this work is to design and implement a graphical interface that interprets andpresents in a clear way the differences found by the execution of a diff algorithm. It displaystwo versions of an XML document; emphasizing the modifications detected by a diffalgorithm. The tool supports three diferent algorithms; allowing the user to choose whichalgorithm to execute; and presents the results in a uniform way. Resumo. Existem diversosalgoritmos voltadosa detecçao de diferenças entre documentos XML; comumente …,*,*,3
Uma Interface Gráfica para Algoritmos de Detecç ao de Diferenças entre Documentos XML,Frantchesco Cecchin; Carmem Satie Hara,Abstract. There are many algorithms in the literature for detecting differences between XMLdocuments. However; only a few provide a graphical interface to display their results. Such atool allows the user to clearly identify the differences and check the correctress of the result.As a consequence; the verification step becomes faster and less prone to errors. Thepurpose of this work is to design and implement a graphical interface that interprets andpresents in a clear way the differences found by the execution of a diff algorithm. It displaystwo versions of an XML document; emphasizing the modifications detected by a diffalgorithm. The tool supports three diferent algorithms; allowing the user to choose whichalgorithm to execute; and presents the results in a uniform way. Resumo. Existem diversosalgoritmos voltadosa detecçao de diferenças entre documentos XML; comumente …,*,*,3
Um Repositório Chave-Valor com Controle de Localidade.,Patrick Bungama; Carmen Hara; Wendel Muniz de Oliveira; Flávio RC Sousa,Abstract. The ever increasing volume of data produced nowadays presents challenges forstoring and processing this data. Traditional database solutions are not efficient to facethese challenges; especially with respect to scalability. One approach to provide scalabilityis the adoption of a layered architecture which combines a distributed storage system with asimple access interface. This paper presents ALOCS; a distributed repository which adoptsthe key-value model; allowing the user application to control the allocation of data intoservers. The goal is to allow the application to co-allocate data that are frequently usedtogether. Our experimental study shows that ALOCS improves query response times byreducing the amount of remote data accesses. Resumo. O aumento no volume de dadosproduzidos apresenta desafios no armazenamento e processamento destes dados …,SBBD,2016,2
Incremental data fusion based on provenance information,Carmem Satie Hara; Cristina Dutra de Aguiar Ciferri; Ricardo Rodrigues Ciferri,Abstract Data fusion is the process of combining multiple representations of the same object;extracted from several external sources; into a single and clean representation. It is usuallythe last step of an integration process; which is executed after the schema matching and theentity identification steps. More specifically; data fusion aims at solving attribute valueconflicts based on user-defined rules. Although there exist several approaches in theliterature for fusing data; few of them focus on optimizing the process when new versions ofthe sources become available. In this paper; we propose a model for incremental datafusion. Our approach is based on storing provenance information in the form of a sequenceof operations. These operations reflect the last fusion rules applied on the imported data. Bykeeping both the original source value and the new fused data in the operations …,*,2013,2
Print: a provenance model to support integration processes,Bruno Tomazela; Carmem S Hara; Ricardo R Ciferri; Cristina DA Ciferri,Abstract In some integration applications; users are allowed to import data fromheterogeneous sources; but are not allowed to update source data directly. Imported datamay be inconsistent; and even when inconsistencies are detected and solved; thesechanges may not be propagated to the sources due to their update policies. Therefore; theycontinue to provide the same inconsistent data in the future until the proper authorityupdates them. In this paper; we propose PrInt; a model that supports user's decisions oncleaning data to be automatically reapplied in subsequent integration processes. Byreproducing previous decisions; the user may focus only on new inconsistencies originatedfrom source modified data. The reproducibility provided by PrInt is based on logging; and byincorporating data provenance in the integration process.,Proceedings of the 19th ACM international conference on Information and knowledge management,2010,2
Uma Experiência de Sincronizaç ao de Bases de Dados Relacionais Utilizando SyncML,Alison LB Alonso; Cristiano Oliveira; Leonardo Fedalto; Fulvio Vilas Boas; Tiago LG de Assis; Carmem Satie Hara,Abstract. This paper describes SBDML; a SyncML-based middleware to replicate andsynchonize data between a relational database and either another relational database ormobile devices. We also present some experimental results that determine the overhead ofadopting SyncML as a synchronization protocol in this setting. Resumo. Este artigo descreveum arcabouço chamado SBDML; baseado em SyncML; desenvolvido para sincronizardados de um banco de dados relacional com outro banco de dados relacional ou comdispositivos móveis. Resultados de alguns experimentos executados para determinar odesempenho e overhead pela adoç ao do protocolo SyncML neste contexto sao tambémapresentados.,*,2009,2
Method and apparatus for validating propagation of XML constraints to relations,*,Method and apparatus for validating propagation of XML constraints to functionaldependencies when transforming XML to relational data. The method includes steps ofaccepting variables indicative of XML-based data; determining if one of the variables isunique based on checking the validity of XML keys defining XML constraints anddetermining if one or more fields in said relational data do not have a null value. Thevariables are selected from a set of XML keys (Σ); a transformation Rule (R) and a FunctionalDependency (φ). One determining step includes substeps of viewing a transformation Ruleas a Table Tree and traversing nodes in the Table Tree. The nodes are traversed until anXML key is found at a particular node and then said one of said plurality of variables (in oneembodiment identified as x) is determined to be unique when compared to the context of …,*,2005,2
RDF updates with constraints,Mirian Halfeld-Ferrari; Carmem S Hara; Flavio R Uber,Abstract This paper deals with the problem of updating an RDF database; expected to satisfyuser-defined constraints as well as RDF intrinsic semantic constraints. As updates mayviolate these constraints; side-effects are generated in order to preserve consistency. Weinvestigate the use of nulls (blank nodes) as placeholders for unknown required data as atechnique to provide this consistency and to reduce the number of side-effects. Experimentalresults validate our goals.,International Conference on Knowledge Engineering and the Semantic Web,2017,1
Exploring controlled RDF distribution,Raqueline RM Penteado; Rebeca Scroeder; Carmem S Hara,RDF datasets have increased rapidly over the last few years. In order to process SPARQLqueries on these large datasets; much effort has been spent on developing horizontallyscalable techniques; which involve data partitioning and parallel query processing. Whiledistribution may provide storage scalability; it may also incur high communication costs forprocessing queries. In this paper; we present a parallel and distributed query rocessingapproach that explores the existence of data allocation patterns; provided by a controlleddata distribution; that determine how RDF triples should be grouped and stored on the sameserver. Fragments of the RDF datastore follow a given allocation pattern and correspondalso to units of communication among servers. Based on this distribution model; we definetwo communication strategies for query processing: get-frag; which requests remote …,Cloud Computing Technology and Science (CloudCom); 2016 IEEE International Conference on,2016,1
An autonomic in-network query processing for urban sensor networks,Marcos A Carrero; Rone I da Silva; Aldri L dos Santos; Carmem S Hara,The sensing of urban environments usually takes into account the deployment of a largenumber of devices to measure their environmental attributes; such as temperature; pressure;humidity; luminosity and pollution. In such applications; nearby sensors usually producesimilar readings due to their spatial and temporal correlation. In the era of big data;management of collected data requires autonomous and scalable Wireless Sensor Network(WSN) structures. In this paper; we propose an in-network data storage model; called AQPM;that provides efficient processing of both spatial and value-based queries. AQPM isautonomous and scalable. That is; it does not rely on any central entity for neither managingdata storage on sensor devices nor for processing queries. Scalability is achieved bygrouping sensors with similar readings into clusters; while efficient query processing …,Computers and Communication (ISCC); 2015 IEEE Symposium on,2015,1
What if multiusers wish to reconcile their data?,Dayse Silveira de Almeida; Carmem Satie Hara; Cristina Dutra de Aguiar Ciferri,Reconciliation is the process of providing a consistent view of the data imported fromdifferent sources. Despite some efforts reported in the literature for providing datareconciliation solutions with asynchronous collaboration; the challenge of reconciling datawhen multiple users work asynchronously over local copies of the same imported data hasreceived less attention. In this paper; we propose AcCORD; an asynchronous collaborativedata reconciliation model based on data provenance. AcCORD is innovative because itsupports applications in which all users are required to agree on the data integration inorder to provide a single consistent view to all of them; as well as applications that allowusers to disagree on the correct data value; but promote collaboration by sharing updates.We also introduce different policies based on provenance for solving conflicts among …,International Conference on Enterprise Information Systems; 17th,2015,1
PVFS-Store: um repositório chave-valor com garantia de localidade,Ricardo M Maeda; Carmem Satie Hara,Resumo. Há uma demanda crescente por soluçoes distribuıdas de armazenamento; quepreservem a localidade dos dados nos servidores espalhados geograficamente. Grandeparte das soluçoes NoSQL distribuıdas sao baseadas em uma DHT e possuem pouco ounenhum controle sobre a colocaç ao dos dados. A garantia da localizaçao é importantepara permitir que as informaçoes sejam posicionadas próximasas aplicaç oesconsumidoras e agrupadas semanticamente para acessos otimizados. Este trabalho propoeo PVFS-Store; um sistema de armazenamento distribuıdo baseado no modelo chave-valor;cujo objetivo é permitir o controle da localidade dos dados pela aplicaç ao.,Anais do Workshop de Teses e Dissertações em Banco de Dados (WTDBD). Curitiba; Brazil,2015,1
A Policy-based storage model for sensor networks,Nuno MF Gonçalves; Aldri L Dos Santos; Carmem S Hara,Policies are used for developing adaptable and flexible systems in a variety of areas. Theyare especially suitable for reducing the complexity of managing tasks; by providing amechanism for automatically tuning the system without human intervention. Policy-basedsystems have been applied for wireless sensor networks (WSNs) for controlling severalfunctionalities. However; none of them has been proposed as a storage model; by making aclear distinction between storage functions and their behaviour. In this paper we proposeSeSP; a Sensor Storage model based on Policies. SeSP explores concepts that arecommon in storage models proposed for WSNs in order to reduce the number of messagetransmissions and thus minimize the sensors' energy consumption. We have conducted acase study applying our policy-based system on two existing storage models: Scoop and …,Network Operations and Management Symposium (NOMS); 2014 IEEE,2014,1
Um SGBD com Armazenamento Distribuıdo de Dados Baseado em DHT,Eduardo Augusto Ribas; Roney Uba; Ana Paula Dias; Arion de Campos Jr; Davi Arnaut; Carmem Hara,Abstract. This paper investigates the development of a DHT-based storage engine for adatabase management system (DBMS). The storage engine is responsible for implementingthe interface between an SQL query processor and a DHT; by translating operations basedon relations to DHT standard operations. By combining DHTs to DBMSs we achievescalability; decentralization; and fault tolerance; due to a DHT-based relational storage; andalso a general high level language for querying data stored on DHTs. Our experimentalstudy shows some initial results on two issues. The first determines the impact of developingan indexing structure on top of a DHT for processing range queries. The second investigatestwo approaches for mapping relations to DHT's key-value pairs: vertical and horizontalpartition of relations. Resumo. Este artigo apresenta o desenvolvimento de um módulo de …,*,2010,1
StereoMap: Um Mashup para Busca de Eventos Musicais,J Duszczak; L Zambom; Oliver Batista; Leandro Ferreira; Issam Ibrahim; C Hara,Resumo Este artigo apresenta uma aplicação Web que permite a busca de eventosmusicais por localidade; chamada StereoMap. Ela foi desenvolvida utilizando o conceito demashup; ou seja; através da integração de serviços e dados provenientes de diversasfontes. O StereoMap utiliza como provedores de conteúdo os seguintes serviços: Last. fm;Google Maps; Twitter e Wikipedia. Os mashups estão se tornando uma tendênciatecnológica; facilitando o desenvolvimento de serviços integrados e proporcionando maiorflexibilidade ao usuário final.,VI Escola Regional de Banco de Dados; ERBD,2010,1
Um sistema de auditoria baseado na análise de registros de log,Fernando Simon; Aldri L dos Santos; Carmem S Hara,Abstract. Database Management Systems are essential in many applications. They arefundamental to guarantee the safety of stored data; and thus it is important to monitor whenand which data has been read or written in order to prevent and detect misuse. This isusually achieved by auditing a log of records generated for this purpose. Nevertheless; if arecord is generated for every operation on the database; the volume of log data maybecome overwhelming. In this case; it is important to define more specific auditing policies;including the selection of data to audit. This paper proposes the use of a Data StreamManagement System (DSMS) to audit a database. The advantages of this approach aretwofold. First; the database administrator can filter out auditing records; and define policiesas DSMS queries. Second; auditing results are generated in real time; minimizing the …,Escola Regional de Banco de Dados (ERBD’2008),2008,1
Morphing sparsely populated data,Susan Davidson; Carmem Hara; Anthony Kosky; Chris Overton,The Human Genome Project; and the field of molecular biology; involves a proliferation ofdifferent data sources; including both archival (GenBank; GDB) and local notebookdatabases; and also various software systems and tools (BLAST; FASTA). These datasources frequently use incompatible structures to represent the same or overlapping data;and further may be implemented in a variety of data-models and database managementsystems (DBMSs); including object-oriented systems (ACEDB; OPM; Object Store); flat-relational databases (SYBASE); and data exchange formats stored as structured text files(ASN. 1). It is frequently necessary to transform data between these incompatible datasources and data-models. For example data stored in an archival database or generated byand stored in a local database at one HGP site may have an impact on the experiments …,Submitted to MIMBD,1995,1
Utilização de um Banco de Dados Orientado a Objetos em um Ambiente de Desenvolvimento de Software,Carmem Satie Hara,Resumo: Muito tem se pesquisado sobre banco de dados orientados a objetos (DDOO).Alguns protótipos de sistemas de gerenciamento para estes bancos de dados foramrecentemente desenvolvidos; porém há uma carência de experiências práticas nesta área.Esta tese procurou justamente experimentar com um destes protótipos utilizando umaaplicação apropriada à orientação a objetos; com o objetivo de identificar problemas namodelagem e implementação; bem como verificar se as facilidades oferecidas peloprotótipo são adequadas à solução do problema. Damokles é um protótipo de BDOOdesenvolvido na Universidade de Karlsruhe com o propósito de dar suporte a ambientes deprojeto. Seu modelo de dados estende o modelo entidade-relacionamento com osconceitos de composição de objetos e versões; além-de possuir um tipo de dado …,*,1990,1
An asynchronous collaborative reconciliation model based on data provenance,Dayse Silveira Almeida; Carmem Satie Hara; Ricardo Rodrigues Ciferri; Cristina Dutra Aguiar Ciferri,Summary Reconciliation is the process of providing a consistent view of the data importedfrom different sources. Despite some efforts reported in the literature for providing datareconciliation solutions with asynchronous collaboration; the challenge of reconciling datawhen multiple users work asynchronously over local copies of the same imported data hasreceived less attention. In this paper; we propose AcCORD; an asynchronous collaborativedata reconciliation model based on data provenance. AcCORD is innovative because itsupports applications in which all users are required to agree on the data values to providea single consistent view to all of them; as well as applications that allow users to disagree onthe data values to keep in their local copies but promote collaboration by sharing integrationdecisions. We also introduce a decision integration propagation method that keeps users …,Software: Practice and Experience,2018,*
ALOCS: An Allocation-aware Key-value Repository,Patrick A Bungama; Wendel M de Oliveira; Flávio RC Sousa; Carmem S Hara,Abstract Large volumes of data produced every day brought new challenges for developingefficient ways to extract; store and access the data. One approach to support increasingstorage capacity is to exploit distributed storage repositories; which can be used toimplement the physical layer of a Database Management System (DBMS). One of thedifficulties reported by DBMSs that adopted a Distributed Hash Table (DHT) as their storageback-end is the high cost of communication for query processing. This is because DHTs donot offer control over the location of the data; and thus data involved in a query may bespread over different servers. This article presents ALOCS; a distributed data repositorywhich provides to the application control over data locality. ALOCS adopts the key-valuedata model; and allows a set of key-value pairs to be grouped into buckets; that are stored …,Journal of Information and Data Management,2017,*
A Reusable Component-Based Model for WSN Storage Simulation,Marcos Aurélio Carrero; Martin Alejandro Musicante; Aldri Luiz dos Santos; Carmem Satie Hara,Abstract Sensor networks are a fast-evolving technology used for a variety of applications;ranging from environmental monitoring to cyber-physical systems (CPS) and IoT; includingapplications designed to support smart cities. The widespread use of sensor networks risesnew challenges to data management and storage. The development of data storagesystems is a hard task due to the specific nature of wireless sensor networks (WSNs) and thelack of a common general purpose development framework. Software component modelsprovide an appropriate level of system abstraction; reducing the development complexityand improving productivity. In this paper we propose RCBM; a Reusable Component-basedModel for wireless sensor network storage simulation. RCBM promotes software reuse fromexisting components to improve the efficiency of system development and evaluation …,Proceedings of the 13th ACM Symposium on QoS and Security for Wireless and Mobile Networks,2017,*
Graph Constraints in Urban Computing: Dealing with conditions in processing urban data,Laurent D'Orazio; Mirian Halfeld-Ferrari; Carmem Hara; Nadia Kozievitch; Martin Musicante,Smart Cities is a worldwide initiative leading to better exploit the resources in a city in orderto offer higher level services to people. In this context; urban computing is a process ofacquisition; integration; and analysis of big and heterogeneous data generated by adiversity of sources in urban spaces; such as sensors; traffic devices; vehicles; buildings;and humans; to tackle the major issues that cities face; eg air pollution; increased energyconsumption and traffic congestion. The majority of these information can be represented asgraphs; such as the transportation network; in which places (nodes) are connected by someform of public transportation (edges). A vision of the" city of the future"; or even the city of thepresent; rests on the integration of science and technology through information systems.This vision requires a rethinking of the relationships between technology; government …,International workshop on Data Analytics solutions for Real-LIfe Applications (DARLI-AP),2017,*
RDF Updates with Constraints,Mirian Halfeld Ferrari; Carmem Hara; Flávio Uber,*,nternational Conference on Knowledge Engineering and Semantic Web,2017,*
An Autonomic Spatial Query Processing Model for Urban Sensor Networks,Marcos A Carrero; Rone I da Silva; Aldri L dos Santos; Carmem S Hara,Wireless Sensor Networks (WSN) in urban environments manage a large amount ofsensoring data. The deployment of spatial query processing in a decentralized andautonomous large-scale WSN is a major challenge due to the network resourcesconstraints. This paper proposes ASQPM; a scalable and autonomous model for datastorage and spatial query processing. Scalability is provided by grouping sensors intoclusters based on the spatial similarity of their readings. The query processing efficiencyrelies on the concept of repositories; which are regions in the monitored area thatconcentrate information; storing the readings of a set of clusters. The experimental resultsshow that it is more effective for query processing than classical approaches.,Computer Networks and Distributed Systems (SBRC); 2015 XXXIII Brazilian Symposium on,2015,*
Exploring Data Fusion under the Image Retrieval Domain.,Nádia P Kozievitch; Carmem Satie Hara; Jaqueline Nande; Ricardo da Silva Torres,Abstract: Advanced services in data compression; data storage; and data transmission havebeen developed and are widely used to address the required capabilities of an assortmentof systems across diverse application domains. In order to reuse; integrate; unify; manage;and support heterogeneous resources; a number of works and concepts have emerged withthe aim of facilitating aggregation of content and helping system developers. In particular;images; along with existing Content-Based Image Retrieval services; have the potential toplay a key role in information systems; due to the large availability of images and the need tointegrate them with existing collections; metadata; and available image manipulationsoftwares and applications. In this work; we explore a data fusion approach for solving datavalue conflicts in the context of image retrieval domain. In particular; we target the process …,ICEIS (1),2014,*
Towards Full-fledged XML Fragmentation for Transactional Distributed Databases,Rebeca Schroeder; Carmem S Hara,Abstract. In data distribution design; fragmentation has been widely applied to providescalable and available database services. Recently; the advent of cloud computing and thedissemination of large-scale distributed systems have shown that the traditional solution fordata distribution is not suitable. In this paper we tackle the fragmentation problem fortransactional databases which are highly distributed. Our specific goal is to develop afragmentation approach that avoids distributed transactions and; consequently; improve thesystem throughput and maximize storage. To this purpose; we analyze a transactionalworkload in order to pack the most correlated data in the same fragment or in a set of fewfragments. We are particularly focused on the XML model since it is a flexible model tosupport several applications; including systems in the cloud. This paper presents the …,*,2014,*
Partitioning RDF exploiting workload information,Rebeca Schroeder; Raqueline Penteado; Carmem Satie Hara,Abstract One approach to leverage scalable systems for RDF management is partitioninglarge datasets across distributed servers. In this paper we consider workload data; given inthe form of query patterns and their frequencies; for determining how to partition RDFdatasets. Our experimental study shows that our workload-aware method is an effective wayto cluster related data and provides better query response times compared to an elementaryfragmentation method.,Proceedings of the 22nd International Conference on World Wide Web,2013,*
MyGFT: um Módulo de Integração entre MySQL e Google Fusion Tables,Alexandre Savaris; Carmem Satie Hara; Aldo von Wangenheim,Abstract. This work presents MyGFT; a storage engine for integrating MySQL DBMS andGoogle Fusion Tables; a cloud-based data management service. The module is describedin terms of architecture; its integration to MySQL and how its use can be a viable alternativeto data retrieval for controlled and structured vocabularies used in healthcare applications.Resumo. Este trabalho apresenta o MyGFT1; um storage engine para a integração doSGBD MySQL ao serviço de gerenciamento de dados em nuvem Google Fusion Tables. Omódulo é descrito em termos de arquitetura; integração ao MySQL e de como sua utilizaçãopode se tornar uma alternativa viável à recuperação de dados pertencentes a vocabulárioscontrolados e estruturados utilizados em aplicações na área da saúde.,27th BRAZILIAN SYMPOSIUM ON DATABASES,2012,*
Phoenis: um componente relacional para plataformas de armazenamento em nuvem,Davi Einstein Melges Arnaut,Resumo: O crescente volume e diversidade de dados; juntamente com a evolução dosconceitos da computação em nuvem; têm dado origem a um novo tipo de sistemas debanco de dados distribuído com foco em escalabilidade à custa de característicascomumente associadas a bancos de dados relacionais tradicionais. Na maioria dos casos;estes novos sistemas são destinados a implantação em larga escala e escalabilidademaciça; nos quais as características tradicionais de bancos de dados relacionais acabampor reduzir sua viabilidade como uma plataforma distribuída de armazenamento de dados.Para abordar esta questão; este trabalho propõe um novo design e arquitetura para umsistema de banco de dados relacional baseado em nuvem. O componente central destesistema é um módulo de armazenamento; que é responsável por mapear o esquema …,*,2010,*
Um modelo para integração de documentos XML em nível de instancia,Aldo Monteiro do Nascimento; Carmem Satie Hara,A forma como é realizada a publicaçao de dados através da Web está em evoluçaoconstante. Inicialmente; ela era baseada em HTML; que adota uma abordagem dedocumentos hiper-texto. Mais recentemente; ela passou a ser baseada em XML [Bray et al.1998]; promovendo uma abordagem mais focada nos dados. XML tem se tornado o padraopara a representaçao e troca de dados na Internet e; sendo um formato de dadossemiestruturado; também pode ser usado para a integraçao de dados. XML também tem setornado a opçao em sistemas de gerenciamento de dados e documentos; devidoa suacapacidade de representar dados irregulares enquanto mantém a estrutura dos dados;caso ela exista [Sawires et al. 2005]. A flexibilidade do formato XML permite quedocumentos sejam estendidos ou reduzidos para descrever conteúdo de qualquer …,*,2009,*
Z. Bar-Yossef; M. Fontoura; V. Josifovski; On the memory requirements of XPath evaluation over XML streams,S Davidson; W Fan; C Hara,*,Journal of Computer and System Sciences,2007,*
Special Issue: Computational Complexity 2003,Harry Buhrman; Ryan O’Donnell; Rocco A Servedio; Scott Aaronson; Albert Atserias; Víctor Dalmau; Subhash Khot; Oded Regev; Wolfgang Merkle; Lance Fortnow; A Pavan; Samik Sengupta; Pranab Sen; S Venkatesh; Chris Calabro; Russell Impagliazzo; Valentine Kabanets; Ramamohan Paturi; Detlef Sieling; Susan Davidson; Wenfei Fan; Carmem Hara,*,J. Comput. System Sci,2007,*
Utilização de Chaves em Algoritmos de Diff para XML.,Rodrigo Cordeirodos Santos; Carmem S Hara,Change detection algorithms for XML documents proposed in the lit erature have focused onthe structural analysis of the document. When XML is used for data exchange; a matchingprocess based on keys defined on the document can generate more meaningful results. Inthis paper; we use XML keys to determine which elements in different versions refer to thesame entity in the real world; and therefore should be matched by the algorithm. We presentan algorithm that extends the structural analysis with a semantical analysis based on keys.An experimental study has been conducted to determine the impact of this approach on theexecution time of the algorithm.,SBBD,2007,*
Jintegrator: A Heterogeneous Database Integration Tool,Carmem Satie Hara; Eduardo da Rocha Ruthes; Kemmel da Silva Scopim; Marcos Sfair Sunyé,Abstract Many applications nowadays involve databases that differ both on their technologyand architecture; and there is a need to integrate them. Although a number of tools exist tosupport the construction of a single schema; not many support the process of int,International Conference on Information Systems and Technology Management,2006,*
Satellite Events of the 32nd Brazilian Symposium on Databases,Carmem S Hara; Bernadette F Lóscio; Daniel de Oliveira; Carina F Dorneles; Vânia MP Vidal; Fernanda Baião; Mirella M Moro; Kary Ocaña; Humberto L Razente; Maria Camila N Barioni,Abstract. Bioinformatics workflows generate massive amounts of data and an efficientmanagement of the data and its provenance is a challenge. The use of the provenance ofdata has brought remarkable benefits to the research in Bioinformatics; allowing a greateraccuracy in the analyses due to the reproducibility and the refinement that it provides to theexperiments. Bioinformatics workflows demand scalability and performance. In such context;the use of non-relational database system (NoSQL) is becoming increasingly common. Thispaper presents a comparative study between the NoSQL databases Cassandra; MongoDBand OrientDB DBMS regarding the management of data and provenance; both collected inthe execution of a DNA assembly workflow. Resumo. Workflows em Bioinformática geramum grande volume de dados e o gerenciamento de tais dados e de sua proveniência é …,*,*,*
2015 XXXIII Brazilian Symposium on Computer Networks and Distributed Systems (SBRC),Marcos A Carrero; Rone I da Silva; Aldri L dos Santos; Carmem S Hara,Wireless Sensor Networks (WSN) in urban environments manage a large amount ofsensoring data. The deployment of spatial query processing in a decentralized andautonomous large-scale WSN is a major challenge due to the network resourcesconstraints. This paper proposes ASQPM; a scalable and autonomous model for datastorage and spatial query processing. Scalability is provided by grouping sensors...,*,*,*
Exploraç ao de Grafos RDF com Distribuiç ao Controlada,Raqueline RM Penteado; Rebeca Schroeder; Carmem S Hara,Abstract. The communication costs involved in retrieving distributed data in SPARQL querieshave a big impact on the system performance. In this paper; we define a parallel graphprocessing model that explores the existence of allocation patterns; which consist ofinformation on how data has been distributed among servers. Based on this model; wedefine two types of communication schedules: get-frag and send-result. These strategies areof great interest to query optimizers for efficient query processing on distributed RDF stores.Resumo. Grande parte do custo envolvido no processamento distribuıdo de consultasSPARQL resulta do custo de comunicaç ao para a obtenç ao dos dados envolvidos naconsulta. Neste trabalho é definido um modelo de exploraçao de grafos paralelo paraconsultas SPARQL que considera a existência de padroes de distribuiç ao de dados. A …,*,*,*
DASFlow: Uma Arquitetura Distribuıda de Processamento e Armazenamento para Dados de Monitoramento de Rede,Diego J Hoss; Christian Lyra; Carmem S Hara,Abstract. Network monitoring is an activity that demands an increasing storage andprocessing capacity. This follows from the continuous growth of the data volume that aretransmited daily on the Internet. Monitoring tools are generally based on a centralizedarchitecture. The centralized model has limitations associated with scalability that areinherent to the architecture; such as the lack of redundancy and a single point of failure. Inthis paper; we propose a distributed architecture called DASFlow. This solution aims atovercoming these limitations and providing scalability for the NfSen network monitoring tool.Resumo. O monitoramento de redes é uma atividade que demanda cada vez maiscapacidade de armazenamento e processamento. Isto decorre do contınuo aumento novolume de dados que trafega diariamente na Internet. Para realizar esta atividade; sao …,*,*,*
TÓPICOS EM GERENCIAMENTO DE DADOS E INFORMAÇÕES 2015,Carmem S Hara; Fábio Porto; Eduardo Ogasawara,Resumo Grafos são estruturas de dados ubíquas em inúmeros domínios de aplicações.Com o advento do fenômeno Big Data; o processamento e armazenamento dos grafos temexigido o uso de novas técnicas e ferramentas. Nos últimos anos; diversos sistemas paraprocessamento de grafos em larga escala foram desenvolvidos. Neste contexto; estecapítulo apresenta uma visão geral do estado da arte no processamento de grafos edetalha as principais características e limitações desses sistemas.,*,*,*
Um Modelo Autônomo de Processamento de Consultas Espaciais para Redes de Sensores Urbanas,Marcos A Carrero; Rone I da Silva; Carmem S Hara; Aldri L dos Santos,Abstract. Wireless Sensor Networks (WSN) in urban environments manage a large amountof sensoring data. The deployment of spatial query processing in a decentralized andautonomous large-scale WSN is a major challenge due to the network resourcesconstraints. This paper proposes ASQPM; a scalable and autonomous model for datastorage and spatial query processing. Scalability is provided by grouping sensors intoclusters based on the spatial similarity of their readings. The query processing efficiencyrelies on the concept of repositories; which are regions in the monitored area thatconcentrate information; storing the readings of a set of clusters. The experimental resultsshow that it is more effective for query processing than classical approaches. Resumo. AsRedes de Sensores sem Fio (RSSFs) urbanas lidam com grande quantidade de informaç …,*,*,*
WebS 2012 Workshop Committee,Christina Feilmayr; Wolfram Wöß; José Francisco Aldana Montes; Mario Arrigoni Neri; ISEC Jorge Bernardino; Devis Bianchini; Daniele Braga; Radek Burget; DISI Barbara Catania; Bin Chen; Cláudio De Souza Baptista; John Debenham; Steven A Demurjian; Nickolas JG Falkner; Bernadette Farias Lóscio; Ling Feng; Alfio Ferrara; Abdelkader Hameurlain; Carmem Satie Hara; Bernhard Haslhofer; Hiroyuki Kawano; Ralf Klischewski; Ora Lassila; Ismael Navas Delgado; Achille Peternier; Niko Popitsch; Isidoro Ramos; Bernhard Schandl,Chairs Christina Feilmayr; Johannes Kepler University Linz; Austria Wolfram Wöß; JohannesKepler University Linz; Austria … Program Committee Members José Francisco AldanaMontes; Universidad de Málaga; Spain Mario Arrigoni Neri; Università degli Studi diBergamo; Italy Jorge Bernardino; ISEC; Polytechnic Institute of Coimbra; Portugal DevisBianchini; University of Brescia; Italy Alessio Bosca; CELI srl; Turino; Italy Daniele Braga; Politecnicodi Milano; Italy Radek Burget; Faculty of Information Technology; Brno University ofTechnology; Czech Republic Barbara Catania; DISI; University of Genoa; Italy Bin Chen; IndianaUniversity; USA Sunil Choenni; Rotterdam University & Ministry of Justice; The Hague; The NetherlandsBrian Davis; Digital Enterprise Research Institute (DERI); National University of Galway; IrelandValeria De Antonellis; Dipartimento di Elettronica per l'Automazione; Brescia; Italy …,*,*,*
Tópicos em Gerenciamento de Dados e Informaçoes 2014,Bernadette Farias Lóscio; Carmem S Hara; Vidal Martins,Resumo Os dados das redes sociais online podem ser usados para extrair informaçõessobre padrões de interações interpessoais e opiniões. Esses dados podem auxiliar noentendimento de fenômenos; na previsão de um evento ou na tomada de decisões. Com aampla adoção dessas redes; esses dados aumentaram em volume; variedade e precisamde processamento rápido; exigindo; por esse motivo; que novas abordagens no tratamentosejam empregadas. Aos dados que possuem tais características (volume; variedade enecessidade de velocidade em seu tratamento); chamamo-los de Big Data. Este minicursovisa apresentar uma abordagem de análise de Big Data em redes sociais online (Big SocialData); incluindo a coleta e tratamento de grande volume de dados sociais; mineração eprincípios de análise de interações sociais.,*,*,*
WebS 2010 Program Committee/Reviewers,Christina Feilmayr; Wolfram Wöß; José Francisco Aldana Montes; Kerstin Altmanninger; Sören Auer; Elena Baralis; ISEC Jorge Bernardino; Walter Binder; Brian Blake; Barbara Carminati; DISI Barbara Catania; Cláudio De Souza Baptista; John Debenham; Steven A Demurjian; Ying Ding; Nickolas JG Falkner; Ling Feng; Alfio Ferrara; Elena Ferrari; Abdelkader Hameurlain; Carmem Satie Hara; Bernhard Haslhofer; Stijn Heymans; Hiroyuki Kawano; Ralf Klischewski; Ismael Navas Delgado; Dimitris Plexousakis; Isidoro Ramos; Bernhard Schandl; Ulrich Schiel; Elena Simperl; Bala Srinivasan,Chairs Christina Feilmayr; Johannes Kepler University of Linz; Austria Wolfram Wöß; JohannesKepler University of Linz; Austria … Program Committee Members José Francisco AldanaMontes; Universidad de Málaga; Spain Kerstin Altmanninger; Johannes Kepler UniversityLinz; Austria Sören Auer; University of Leipzig; Germany Elena Baralis; Politecnico di Torino;Italy Jorge Bernardino; ISEC; Polytechnic Institute of Coimbra; Portugal Walter Binder; Universityof Lugano; Switzerland Brian Blake; Georgetown University; Washington; DC; USA AlessioBosca; CELI srl; Turino; Italy Paul Buhler; Modus21; LLC; Charleston; South Carolina; USA BarbaraCarminati; University of Insubria; Italy Barbara Catania; DISI; University of Genoa; Italy SunilChoenni; Rotterdam University & Ministry of Justice; The Hague; The Netherlands BrianDavis; Digital Enterprise Research Institute (DERI); National University of Galway; Ireland …,*,*,*
Borislav Iordanov,Carmem Satie Hara,Page 1. PPGInf - UFPR CI829 - Oficina de Banco de Dados I Profa. Carmem Satie Hara RicardoMasashi Maeda www.hypergraphdb.org Borislav Iordanov Page 2. Introdução ● O que éHyperGraphDB? ● Um banco de dados para armazenar hipergrafos (!) ● Não é estritamenteem Grafo ● Pode ser relacional (NoSQL) ou em key-value ● Mais próximo a orientado a objetos(OO) ● Usos: IA; Web Semântica e Embedded OO Databases Page 3. Introdução Page 4.Introdução ● O que é Hipergrafo? ● É uma generalização do conceito de grafos ● Arestas sãoconjuntos ao invés de pares ● Permite uma aresta apontar para mais de dois nós ● Uma arestapode apontar para outra aresta ● O conceito de hipergrafo direcionado não é tão trivial Page5. Introdução ● Exemplos de Hipergrafos Page 6. Introdução ● Exemplos de Hipergrafos Page7. Características ● Armazenamento chave-valor: BerkeleyDB …,*,*,*
Special Issue: Database Theory 2004,Michael Benedikt; Mayank Bawa; Aristides Gionis; Hector Garcia-Molina; Rajeev Motwani; Edith Cohen; Haim Kaplan; Thomas Schwentick; Susan Davidson; Wenfei Fan; Carmem Hara; Wim Martens; Frank Neven; Ziv Bar-Yossef; Marcus Fontoura; Vanja Josifovski; Alin Deutsch; Liying Sui; Victor Vianu; Francesco Scarcello; Gianluigi Greco; Nicola Leone; Gerome Miklau; Dan Suciu,*,*,*,*
Monitoramento de Tráfego de Backbones Baseado em Sistemas Gerenciadores de Streams de Dados,Christian Lyra Gomes; Elias Procópio Duarte Junior; Carmem Satie Hara,Abstract. Traffic monitoring of long distance network backbones presents a number ofchallenges due to the huge amount of traffic; large number of network components; andgeographic and administrative distribution. Stream Processing Engines (SPE) are designedto perform stream analysis in real-time. This work describes a strategy for employing SPEsfor backbone traffic monitoring. We have developed a tool that allows arbitrary queries to beissued about the traffic on the backbone as a whole. The tool is based on the Borealis SPEand obtains backbone traffic information based on a stream of Netflow data. SeveralBorealis nodes can be deployed across the backbone in a distributed fashion in order toperform real-time traffic monitoring. The architecture of the tool is presented; as well as casestudies designed for validation as well as performance evaluation. Resumo. O …,*,*,*
XFusion: Uma Ferramenta para Fusao e Limpeza de Dados XML,Carlo Marcello; Cristian Stroparo; Elisângela de Assis da Silva; Carmem Satie Hara,Resumo. Este artigo apresenta a ferramenta XFusion; a qual permite a fusao dedocumentos XML provenientes de fontes de dados heterogêneas e a limpeza dasinconsistências detectadas. O XFusion utiliza um banco de dados XML nativo comorepositório de dados e oferece ao usuário duas abordagens para efetuar a limpeza dosdados conflitantes através de uma interface gráfica. Abstract. This paper presents XFusion;a tool that allows heterogeneous XML source documents to be combined into a single XMLdata repository. It also provides two approaches for solving value conflicts that may ariseduring the integration process. XFusion uses a native XML database as its underlying datarepository; and provides the user with a graphical interface for data cleaning.,*,*,*
Utilizaç ao de Chaves em Algoritmos de Detecç ao de Diferenças para Documentos XML,Rodrigo C Santos; Carmem Hara,Resumo. Algoritmos de detecç ao de diferenças para documentos XML realizam umaanálise estrutural do documento. Quando XML é utilizada para a troca de informaç oes; umacomparaç ao baseada em chaves definidas no documento pode gerar resultados maissignificativos. Neste trabalho; propoe-se utilizar chaves XML para determinar quaiselementos em diferentes versoes de um documento representam a mesma entidade nomundo real e que portanto devem ser casados pelo algoritmo. A abordagem propostaconsiste em estender a análise estrutural com uma análise semântica baseada em chaves.Estudos experimentais foram conduzidos para determinar o impacto desta abordagem notempo de execuç ao do algoritmo.,*,*,*
Um Módulo de Fusão de Dados para Mashups,Oliver Moraes Batista; William Komura; Hugo Bulegon; Carmem S Hara,Resumo. Web mashups sao aplicaçoes web que integram conteúdo de diversas fontes dedados disponibilizadas por terceiros através de uma interface de serviço. Para permitir queelas possam ser construıdas por profissionais que nao possuem a habilidade deprogramaçao; existem diversas ferramentas que facilitam a combinaç ao de serviçosexistentes através de uma interface simples e intuitiva. Dentre estas ferramentas pode sercitado o Exhibit. Através de uma análise das funcionalidades disponibilizadas por estaferramenta; observou-se que ela possui capacidade limitada para a integraçao de dadossobrepostos. Ou seja; se a mesma informaç ao é disponibilizada por mais de uma fonte;esta ferramenta nao fornece meios adequados para combinar os dados e resolver possıveisconflitos de valor. Motivado por esta deficiência; neste trabalho é proposto um novo …,*,*,*
Utilizaç ao de Chaves em Algoritmos de Detecç ao de Diferenças para XML,Rodrigo C Santos; Carmem Hara,Abstract. Change detection algorithms for XML documents proposed in the literature havefocused on the structural analysis of the document. When XML is used for data exchange; orwhen versions of a document are downloaded periodically; a matching process based onkeys defined on the document can generate more meaningful results. In this paper; we useXML keys to determine which elements in different versions refer to the same entity in thereal world; and therefore should be matched by the algorithm. We present an algorithm thatextends an existing change detection algorithm with a preprocessing phase for pairingelements based on keys. An experimental study has been conducted to determine theimpact of this approach on the execution time of the algorithm. Resumo. Algoritmos dedetecçao de diferenças para documentos XML realizam uma análise estrutural do …,*,*,*
Um Modelo de Grupos para MANETs,Henrique S dos Santos; Raqueline RM Penteado; Luiz Carlos P Albini; Carmem Hara,Abstract. Managing a mobile ad hoc network (MANET) is a complex task given the mobilityof nodes and resource limitation of the devices. One strategy for simplifying the developmentof applications in this context is by providing group management services to abstract thenetwork topology and assist the distributed data management. This paper proposes a groupmanagement service based on the “Friend of a Friend”(FOAF) ontology. We implemented anNS-2 agent based on the proposed model and simulate the system in a urban scenario inwhich vehicle drivers exchange information about the traffic. We considered two metrics forvalidating the system: energy consumption and traffic load. Resumo. O gerenciamento deredes ad hoc sem fio (MANETs) é uma tarefa complexa devido à mobilidade dos nós e àlimitação dos recursos dos dispositivos envolvidos. Uma estratégia para simplificar o …,*,*,*
Abordagens de Particionamento de Dados para Redes Sociais,Bruno S Velasco; Carmem S Hara,Abstract. Online Social Networks (OSN) have never been so popular as it is nowadays. Dueto its fast growth; designing a suitable infrastructure demands time and resources. Thus; acommon approach adopted by several OSN is to set them on the Cloud. Although data getsspread throughout servers; a good balancing of data is barely achieved. To overcome this;several methods have been developed towards a good partitioning. This paper presents themain techniques for OSNs partitioning: general approaches; such as Full Replications andDistributed Hashing; and more specific methods for OSN such as Partitioning andReplication and Time-dependent Partitioning. Also; a comparative study is presentedhighlighting which approaches are best for each possible context. Resumo. Redes SociaisOnline (RSO) nunca foram tao populares quanto sao hoje. Devido ao seu rápido …,*,*,*
Resolução de Conflitos em Documentos XML,Frantchesco Cecchin; Carmem Satie Hara,Resumo. Melhorar a qualidade dos dados provenientes de diferentes fontes é uma tarefacomplexa. Os dados importados destas fontes podem estar “sujos” e estruturados de formasdistintas. Além disso; dados que se referem ao mesmo objeto do mundo real podem serrepresentados múltiplas vezes; causando du plicidade e inconsistência. Quandopretendese manter essas informações de forma integrada; um aspecto importante paragarantir a qualidade dos dados é a utilização de um processo eficiente de limpeza dosdados. Este trabalho propõe um conjunto de métodos e estratégias para a resolução dosconflitos identificados entre instâncias durante o processo de integração. Além disso; éproposta a utilização de um registro contendo o histórico de resoluções com a finalidade deresolver unicamente um mesmo conflito que envolve a mesma enti dade do repositório …,*,*,*
GroupShare: Distribuiç ao e Gerência de Conteudo em Grupos de Interesse para Dispositivos Móveis,Elisa Mannes; Fernando Gielow; Paulo Ferreira; Aldri Santos; Carmem Hara,Abstract. This paper introduces an application for multimedia content sharing; focusing onthe availability and management of the content between mobile devices. The application;called GroupShare; groups the devices by the interest in shared data; originating groups ofinterest. The content is shared in a P2P fashion; with a coordinator responsible for sharingcontent and its location. It also answers requests from clients and manages the location ofreplicas. GroupShare is developed in J2ME and communicates via Bluetooth channels.Resumo. Esse artigo propoe um aplicativo para o compartilhamento de conteúdomultimıdia; focando na disponibilidade e na comunicaç ao direta entre dispositivos móveis.O aplicativo; chamado de GroupShare; agrupa os dispositivos por interesse no conteúdo;formando grupos de interesse. O conteúdo é compartilhado em uma abordagem P2P …,*,*,*
Using Keys to Improve the Quality of XML Diff Algorithms,Rodrigo Cordeiro dos Santos; Carmem Hara,Abstract XML diff algorithms proposed in the literature have focused on the structuralanalysis of the document. When XML is used for data exchange; or when different versionsof a document are downloaded periodically; a matching process based on keys defined onthe document can present more meaningful results. In this paper; we use XML keys definedin [5] to improve the quality of diff algorithms. That is; XML keys determine which elements indifferent versions refer to the same entity in the real world; and therefore should be matchedby the diff algorithm. Based on this approach; we propose an extension to diff algorithmswith a preprocessing phase for pairing elements according to a class of XML keys. Anexperimental study has been conducted to show the effectiveness of our proposal.,*,*,*
