P-Grid: a self-organizing structured P2P system,Karl Aberer; Philippe Cudré-Mauroux; Anwitaman Datta; Zoran Despotovic; Manfred Hauswirth; Magdalena Punceva; Roman Schmidt,In the P2P community a fundamental distinction is made among unstructured and structuredP2P systems for resource location. In unstructured P2P systems in principle peers areunaware of the resources that neighboring peers in the overlay networks maintain. Typicallythey resolve search requests by flooding techniques. Gnutella [9] is the most prominentexample of this class. In contrast; in structured P2P systems peers maintain informationabout what resources neighboring peers offer. Thus queries can be directed and inconsequence substantially fewer messages are needed. This comes at the cost of increasedmaintenance efforts during changes in the overlay network as a result of peers joining orleaving. The most prominent class of approaches to structured P2P systems are distributedhash tables (DHT); for example Chord [17]. Unstructured P2P systems have generated …,ACM SIGMOD Record,2003,532
Gridvine: Building internet-scale semantic overlay networks,Karl Aberer; Philippe Cudré-Mauroux; Manfred Hauswirth; Tim Van Pelt,Abstract This paper addresses the problem of building scalable semantic overlay networks.Our approach follows the principle of data independence by separating a logical layer; thesemantic overlay for managing and mapping data and metadata schemas; from a physicallayer consisting of a structured peer-to-peer overlay network for efficient routing ofmessages. The physical layer is used to implement various functions at the logical layer;including attribute-based search; schema management and schema mapping management.The separation of a physical from a logical layer allows us to process logical operations inthe semantic overlay using different physical execution strategies. In particular we identifyiterative and recursive strategies for the traversal of semantic overlay networks as twoimportant alternatives. At the logical layer we support semantic interoperability through …,International semantic web conference,2004,291
ZenCrowd: leveraging probabilistic reasoning and crowdsourcing techniques for large-scale entity linking,Gianluca Demartini; Djellel Eddine Difallah; Philippe Cudré-Mauroux,Abstract We tackle the problem of entity linking for large collections of online pages; Oursystem; ZenCrowd; identifies entities from natural language text using state of the arttechniques and automatically connects them to the Linked Open Data cloud. We show howone can take advantage of human intelligence to improve the quality of the links bydynamically generating micro-tasks on an online crowdsourcing platform. We develop aprobabilistic framework to make sensible decisions about candidate links and to identifyunreliable human workers. We evaluate ZenCrowd in a real deployment and show how acombination of both probabilistic reasoning and crowdsourcing techniques can significantlyimprove the quality of the links; while limiting the amount of work performed by the crowd.,Proceedings of the 21st international conference on World Wide Web,2012,255
The chatty web: emergent semantics through gossiping,Karl Aberer; Philippe Cudré-Mauroux; Manfred Hauswirth,Abstract This paper describes a novel approach for obtaining semantic interoperabilityamong data sources in a bottom-up; semi-automatic manner without relying on pre-existing;global semantic models. We assume that large amounts of data exist that have beenorganized and annotated according to local schemas. Seeing semantics as a form ofagreement; our approach enables the participating data sources to incrementally developglobal agreement in an evolutionary and completely decentralized process that solely relieson pair-wise; local interactions: Participants provide translations between schemas they areinterested in and can learn about other translations by routing queries (gossiping). Tosupport the participants in assessing the semantic quality of the achieved agreements wedevelop a formal framework that takes into account both syntactic and semantic criteria …,Proceedings of the 12th international conference on World Wide Web,2003,232
HYRISE: a main memory hybrid storage engine,Martin Grund; Jens Krüger; Hasso Plattner; Alexander Zeier; Philippe Cudre-Mauroux; Samuel Madden,Abstract In this paper; we describe a main memory hybrid database system called HYRISE;which automatically partitions tables into vertical partitions of varying widths depending onhow the columns of the table are accessed. For columns accessed as a part of analyticalqueries (eg; via sequential scans); narrow partitions perform better; because; whenscanning a single column; cache locality is improved if the values of that column are storedcontiguously. In contrast; for columns accessed as a part of OLTP-style queries; widerpartitions perform better; because such transactions frequently insert; delete; update; oraccess many of the fields of a row; and co-locating those fields leads to better cache locality.Using a highly accurate model of cache misses; HYRISE is able to predict the performanceof different partitionings; and to automatically select the best partitioning using an …,Proceedings of the VLDB Endowment,2010,219
Emergent semantics principles and issues,Karl Aberer; Philippe Cudré-Mauroux; Aris M Ouksel; Tiziana Catarci; Mohand-Said Hacid; Arantza Illarramendi; Vipul Kashyap; Massimo Mecella; Eduardo Mena; Erich J Neuhold; Olga De Troyer; Thomas Risse; Monica Scannapieco; Felix Saltor; Luca De Santis; Stefano Spaccapietra; Steffen Staab; Rudi Studer,Abstract Information and communication infrastructures underwent a rapid and extremedecentralization process over the past decade: From a world of statically and partiallyconnected central servers rose an intricate web of millions of information sources looselyconnecting one to another. Today; we expect to witness the extension of this revolution withthe wide adoption of meta-data standards like RDF or OWL underpinning the creation of asemantic web. Again; we hope for global properties to emerge from a multiplicity of pair-wise; local interactions; resulting eventually in a self-stabilizing semantic infrastructure. Thispaper represents an effort to summarize the conditions under which this revolution wouldtake place as well as an attempt to underline its main properties; limitations and possibleapplications.,International Conference on Database Systems for Advanced Applications,2004,164
A demonstration of SciDB: a science-oriented DBMS,Philippe Cudré-Mauroux; Hideaki Kimura; K-T Lim; Jennie Rogers; Roman Simakov; Emad Soroush; Pavel Velikhov; Daniel L Wang; Magdalena Balazinska; Jacek Becla; D DeWitt; Bobbi Heath; David Maier; Samuel Madden; J Patel; Michael Stonebraker; S Zdonik,Abstract In CIDR 2009; we presented a collection of requirements for SciDB; a DBMS thatwould meet the needs of scientific users. These included a nested-array data model; science-specific operations such as regrid; and support for uncertainty; lineage; and named versions.In this paper; we present an overview of SciDB's key features and outline a demonstration ofthe first version of SciDB on data and operations from one of our lighthouse users; the LargeSynoptic Survey Telescope (LSST).,Proceedings of the VLDB Endowment,2009,153
Trajstore: An adaptive storage system for very large trajectory data sets,Philippe Cudre-Mauroux; Eugene Wu; Samuel Madden,The rise of GPS and broadband-speed wireless devices has led to tremendous excitementabout a range of applications broadly characterized as “location based services”. Currentdatabase storage systems; however; are inadequate for manipulating the very large anddynamic spatio-temporal data sets required to support such services. Proposals in theliterature either present new indices without discussing how to cluster data; potentiallyresulting in many disk seeks for lookups of densely packed objects; or use static quadtreesor other partitioning structures; which become rapidly suboptimal as the data or queriesevolve. As a result of these performance limitations; we built TrajStore; a dynamic storagesystem optimized for efficiently retrieving all data in a particular spatiotemporal region.TrajStore maintains an optimal index on the data and dynamically co-locates and …,Data Engineering (ICDE); 2010 IEEE 26th International Conference on,2010,130
Oltp-bench: An extensible testbed for benchmarking relational databases,Djellel Eddine Difallah; Andrew Pavlo; Carlo Curino; Philippe Cudre-Mauroux,Abstract Benchmarking is an essential aspect of any database management system (DBMS)effort. Despite several recent advancements; such as pre-configured cloud database imagesand database-as-a-service (DBaaS) offerings; the deployment of a comprehensive testingplatform with a diverse set of datasets and workloads is still far from being trivial. In manycases; researchers and developers are limited to a small number of workloads to evaluatethe performance characteristics of their work. This is due to the lack of a universalbenchmarking infrastructure; and to the difficulty of gaining access to real data andworkloads. This results in lots of unnecessary engineering efforts and makes theperformance evaluation results difficult to compare. To remedy these problems; we presentOLTP-Bench; an extensible" batteries included" DBMS benchmarking testbed. The key …,Proceedings of the VLDB Endowment,2013,116
Pick-a-crowd: tell me what you like; and i'll tell you what to do,Djellel Eddine Difallah; Gianluca Demartini; Philippe Cudré-Mauroux,Abstract Crowdsourcing allows to build hybrid online platforms that combine scalableinformation systems with the power of human intelligence to complete tasks that are difficultto tackle for current algorithms. Examples include hybrid database systems that use thecrowd to fill missing values or to sort items according to subjective dimensions such aspicture attractiveness. Current approaches to Crowdsourcing adopt a pull methodologywhere tasks are published on specialized Web platforms where workers can pick theirpreferred tasks on a first-come-first-served basis. While this approach has many advantages;such as simplicity and short completion times; it does not guarantee that the task isperformed by the most suitable worker. In this paper; we propose and extensively evaluate adifferent Crowdsourcing approach based on a push methodology. Our proposed system …,Proceedings of the 22nd international conference on World Wide Web,2013,112
Gridvine: An infrastructure for peer information management,Philippe Cudré-Mauroux; Suchit Agarwal; Karl Aberer,GridVine is a semantic overlay infrastructure based on a peer-to-peer (P2P) accessstructure. Built following the principle of data independence; it separates a logical layer-inwhich data; schemas; and schema mappings are managed-from a physical layer consistingof a structured P2P network supporting decentralized indexing; key load-balancing; andefficient routing. The system is decentralized; yet fosters semantic interoperability throughpair-wise schema mappings and query reformulation. GridVine's heterogeneous butsemantically related information sources can be queried transparently using iterative queryreformulation. The authors discuss a reference implementation of the system and severalmechanisms for resolving queries collaboratively.,IEEE Internet Computing,2007,105
Start making sense: The Chatty Web approach for global semantic agreements,Karl Aberer; Philippe Cudré-Mauroux; Manfred Hauswirth,Abstract This paper describes a novel approach for obtaining semantic interoperability in abottom–up; semi-automatic manner without relying on pre-existing; global semantic models.We assume that large amounts of data exist that have been organized and annotatedaccording to local schemas. Seeing semantics as a form of agreement; our approachenables the participating data sources to incrementally develop global agreements in anevolutionary and completely decentralized process that solely relies on pair-wise; localinteractions.,Web Semantics: Science; Services and Agents on the World Wide Web,2003,86
The dynamics of micro-task crowdsourcing: The case of amazon mturk,Djellel Eddine Difallah; Michele Catasta; Gianluca Demartini; Panagiotis G Ipeirotis; Philippe Cudré-Mauroux,Abstract Micro-task crowdsourcing is rapidly gaining popularity among researchcommunities and businesses as a means to leverage Human Computation in their dailyoperations. Unlike any other service; a crowdsourcing platform is in fact a marketplacesubject to human factors that affect its performance; both in terms of speed and quality.Indeed; such factors shape the dynamics of the crowdsourcing market. For example; aknown behavior of such markets is that increasing the reward of a set of tasks would lead tofaster results. However; it is still unclear how different dimensions interact with each other:reward; task type; market competition; requester reputation; etc. In this paper; we adopt adata-driven approach to (A) perform a long-term analysis of a popular micro-taskcrowdsourcing platform and understand the evolution of its main actors (workers …,Proceedings of the 24th International Conference on World Wide Web,2015,66
A framework for semantic gossiping,Karl Aberer; Philippe Cudré-Mauroux; Manfred Hauswirth,Abstract Today the problem of semantic interoperability in information search on the Internetis solved mostly by means of centralization; both at a system and at a logical level. Thisapproach has been successful to a certain extent. Peer-to-peer systems as a new brand ofsystem architectures indicate that the principle of decentralization might offer new solutionsto many problems that scale well to very large numbers of users. In this paper we outlinehow the peer-to-peer system architectures can be applied to tackle the problem of semanticinteroperability in the large; driven in a bottom-up manner by the participating peers. Such asystem can readily be used to study semantic interoperability as a global scale phenomenontaking place in a social network of information sharing peers.,ACM SIGMOD Record,2002,66
NoSQL databases for RDF: an empirical evaluation,Philippe Cudré-Mauroux; Iliya Enchev; Sever Fundatureanu; Paul Groth; Albert Haque; Andreas Harth; Felix Leif Keppmann; Daniel Miranker; Juan F Sequeda; Marcin Wylot,Abstract Processing large volumes of RDF data requires sophisticated tools. In recent years;much effort was spent on optimizing native RDF stores and on repurposing relational queryengines for large-scale RDF processing. Concurrently; a number of new data managementsystems—regrouped under the NoSQL (for “not only SQL”) umbrella—rapidly rose toprominence and represent today a popular alternative to classical databases. ThoughNoSQL systems are increasingly used to manage RDF data; it is still difficult to grasp theirkey advantages and drawbacks in this context. This work is; to the best of our knowledge;the first systematic attempt at characterizing and comparing NoSQL stores for RDFprocessing. In the following; we describe four different NoSQL stores and compare their keycharacteristics when running standard RDF benchmarks on a popular cloud infrastructure …,International Semantic Web Conference,2013,64
Large-scale linked data integration using probabilistic reasoning and crowdsourcing,Gianluca Demartini; Djellel Eddine Difallah; Philippe Cudré-Mauroux,Abstract We tackle the problems of semiautomatically matching linked data sets and oflinking large collections of Web pages to linked data. Our system; ZenCrowd;(1) uses a three-stage blocking technique in order to obtain the best possible instance matches whileminimizing both computational complexity and latency; and (2) identifies entities from naturallanguage text using state-of-the-art techniques and automatically connects them to thelinked open data cloud. First; we use structured inverted indices to quickly find potentialcandidate results from entities that have been indexed in our system. Our system thenanalyzes the candidate matches and refines them whenever deemed necessary usingcomputationally more expensive queries on a graph database. Finally; we resort to humancomputation by dynamically generating crowdsourcing tasks in case the algorithmic …,The VLDB Journal,2013,62
Probabilistic message passing in peer data management systems,Philippe Cudre-Mauroux; Karl Aberer; Andras Feher,Until recently; most data integration techniques involved central components; eg; globalschemas; to enable transparent access to heterogeneous databases. Today; however; withthe democratization of tools facilitating knowledge elicitation in machine-processableformats; one cannot rely on global; centralized schemas anymore as knowledge creationand consumption are getting more and more dynamic and decentralized. Peer DataManagement Systems (PDMS) provide an answer to this problem by eliminating the centralsemantic component and considering instead compositions of local; pair-wise mappings topropagate queries from one database to the others. PDMS approaches proposed so farmake the implicit assumption that all mappings used in this way are correct. This obviouslycannot be taken as granted in typical PDMS settings where mappings can be created …,Data Engineering; 2006. ICDE'06. Proceedings of the 22nd International Conference on,2006,59
Mechanical Cheat: Spamming Schemes and Adversarial Techniques on Crowdsourcing Platforms.,Djellel Eddine Difallah; Gianluca Demartini; Philippe Cudré-Mauroux,ABSTRACT Crowdsourcing is becoming a valuable method for companies and researchersto complete scores of micro-tasks by means of open calls on dedicated online platforms.Crowdsourcing results remains unreliable; however; as those platforms neither conveymuch information about the workers' identity nor do they ensure the quality of the work done.Instead; it is the responsibility of the requester to filter out bad workers; poorly accomplishedtasks; and to aggregate worker results in order to obtain a final outcome. In this paper; wefirst review techniques currently used to detect spammers and malicious workers; whetherthey are bots or humans randomly or semi-randomly completing tasks; then; we describe thelimitations of existing techniques by proposing approaches that individuals; or groups ofindividuals; could use to attack a task on existing crowdsourcing platforms. We focus on …,CrowdSearch,2012,57
Sina: Semantic interpretation of user queries for question answering on interlinked data,Saeedeh Shekarpour; Edgard Marx; Axel-Cyrille Ngonga Ngomo; Sören Auer,Abstract The architectural choices underlying Linked Data have led to a compendium of datasources which contain both duplicated and fragmented information on a large number ofdomains. One way to enable non-experts users to access this data compendium is toprovide keyword search frameworks that can capitalize on the inherent characteristics ofLinked Data. Developing such systems is challenging for three main reasons. First;resources across different datasets or even within the same dataset can be homonyms.Second; different datasets employ heterogeneous schemas and each one may only containa part of the answer for a certain user query. Finally; constructing a federated formal queryfrom keywords across different datasets requires exploiting links between the differentdatasets on both the schema and instance levels. We present Sina; a scalable keyword …,Web Semantics: Science; Services and Agents on the World Wide Web,2015,55
idMesh: graph-based disambiguation of linked data,Philippe Cudré-Mauroux; Parisa Haghani; Michael Jost; Karl Aberer; Hermann De Meer,Abstract We tackle the problem of disambiguating entities on the Web. We propose a user-driven scheme where graphs of entities--represented by globally identifiable declarativeartifacts--self-organize in a dynamic and probabilistic manner. Our solution has the followingtwo desirable properties: i) it lets end-users freely define associations between arbitraryentities and ii) it probabilistically infers entity relationships based on uncertain links usingconstraint-satisfaction mechanisms. We outline the interface between our scheme and thecurrent data Web; and show how higher-layer applications can take advantage of ourapproach to enhance search and update of information relating to online entities. Wedescribe a decentralized infrastructure supporting efficient and scalable entitydisambiguation and demonstrate the practicability of our approach in a deployment over …,Proceedings of the 18th international conference on World wide web,2009,53
Emergent semantics systems,Karl Aberer; Tiziana Catarci; Philippe Cudré-Mauroux; Tharam Dillon; Stephan Grimm; Mohand-Said Hacid; Arantza Illarramendi; Mustafa Jarrar; Vipul Kashyap; Massimo Mecella; Eduardo Mena; Erich J Neuhold; Aris M Ouksel; Thomas Risse; Monica Scannapieco; Felix Saltor; Luca De Santis; Stefano Spaccapietra; Steffen Staab; Rudi Studer; Olga De Troyer,Abstract With new standards like RDF or OWL paving the way for the much anticipatedSemantic Web; a new breed of very large scale semantic systems is about to appear.Traditional semantic reconciliation techniques; dependent upon shared vocabularies orglobal ontologies; cannot be used in such open and dynamic environments. Instead; newheuristics based on emerging properties and local consensuses have to be exploited inorder to foster semantic interoperability in the large. In this paper; we outline the maindifferences between traditional semantic reconciliation methods and these new heuristics.Also; we characterize the resulting emergent semantics systems and provide a couple ofhints vis-à-vis their potential applications.,*,2004,48
Advanced peer-to-peer networking: The P-Grid System and its Applications,Karl Aberer; Ph Cudré-Mauroux; Anwitaman Datta; Zoran Despotovic; Manfred Hauswirth; Magdalena Punceva; Roman Schmidt; Jie Wu,ABSTRACT The limitations of client/server systems become evident in an Internet-scaledistributed environment. Peer-to-peer (P2P) systems offer an interesting alternative totraditional client/server systems: Every node acts both as a client and a server and „pays “itsparticipation by providing access to its computing resources. Systems such as Napster andGnutella have proven their practical applicability. In this article we give an overview of our P-Grid system which provides an advanced P2P infrastructure targeted at application domainsbeyond mere file-sharing. We present the conceptual foundations and outline some of theapplications we are developing at the moment.,Praxis der Informationsverarbeitung und Kommunikation,2003,48
Semantic overlay networks,Karl Aberer; Philippe Cudré-Mauroux,Page 1. ©2005; Karl Aberer and Philippe Cudré-Mauroux Semantic Overlay Networks VLDB2005 Karl Aberer and Philippe Cudré-Mauroux School of Computer and Communication SciencesEPFL -- Switzerland Page 2. ©2005; Karl Aberer and Philippe Cudré-Mauroux Overview of theTutorial • I. P2P Systems Overview • II. Query Evaluation in SONs – RDFPeers – PIER – Edutella •III. Semantic Mediation in SONs (PDMSs) – PeerDB – Hyperion – Piazza – GridVine • IV. CurrentResearch Directions Page 3. ©2005; Karl Aberer and Philippe Cudré-Mauroux What this tutorialis about • Describing a (pertinent) selection of systems managing data in large scale; decentralizedoverlays networks – Focus on architectures and approaches to evaluate / reformulate queries •It is not about – A comprehensive list of research projects in the area • But we'll give pointers forthat – Complete description of each project …,VLDB,2005,46
Combining inverted indices and structured search for ad-hoc object retrieval,Alberto Tonon; Gianluca Demartini; Philippe Cudré-Mauroux,Abstract Retrieving semi-structured entities to answer keyword queries is an increasinglyimportant feature of many modern Web applications. The fast-growing Linked Open Data(LOD) movement makes it possible to crawl and index very large amounts of structured datadescribing hundreds of millions of entities. However; entity retrieval approaches have yet tofind efficient and effective ways of ranking and navigating through those large data sets. Inthis paper; we address the problem of Ad-hoc Object Retrieval over large-scale LOD data byproposing a hybrid approach that combines IR and structured search techniques.Specifically; we propose an architecture that exploits an inverted index to answer keywordqueries as well as a semi-structured database to improve the search effectiveness byautomatically generating queries over the LOD graph. Experimental results show that our …,Proceedings of the 35th international ACM SIGIR conference on Research and development in information retrieval,2012,44
Neighborhood-based tag prediction,Adriana Budura; Sebastian Michel; Philippe Cudré-Mauroux; Karl Aberer,Abstract We consider the problem of tag prediction in collaborative tagging systems whereusers share and annotate resources on the Web. We put forward HAMLET; a novelapproach to automatically propagate tags along the edges of a graph which relates similardocuments. We identify the core principles underlying tag propagation for which we derivesuitable scoring models combined in one overall ranking formula. Leveraging these scores;we present an efficient top-k tag selection algorithm that infers additional tags by carefullyinspecting neighbors in the document graph. Experiments using real-world datademonstrate the viability of our approach in large-scale environments where tags arescarce.,European Semantic Web Conference,2009,44
Efficient versioning for scientific array databases,Adam Seering; Philippe Cudre-Mauroux; Samuel Madden; Michael Stonebraker,In this paper; we describe a versioned database storage manager we are developing for theSciDB scientific database. The system is designed to efficiently store and retrieve array-oriented data; exposing a" no-overwrite" storage model in which each update creates a new"version" of an array. This makes it possible to perform comparisons of versions produced atdifferent times or by different algorithms; and to create complex chains and trees of versions.We present algorithms to efficiently encode these versions; minimizing storage space whilestill providing efficient access to the data. Additionally; we present an optimal algorithm that;given a long sequence of versions; determines which versions to encode in terms of eachother (using delta compression) to minimize total storage space or query execution cost. Wecompare the performance of these algorithms on real world data sets from the National …,Data Engineering (ICDE); 2012 IEEE 28th International Conference on,2012,43
Viewpoints on emergent semantics,Philippe Cudré-Mauroux; Karl Aberer; Alia I Abdelmoty; Tiziana Catarci; Ernesto Damiani; Arantxa Illaramendi; Mustafa Jarrar; Robert Meersman; Erich J Neuhold; Christine Parent; Kai-Uwe Sattler; Monica Scannapieco; Stefano Spaccapietra; Peter Spyns; Guy De Tré,Abstract We introduce a novel view on how to deal with the problems of semanticinteroperability in distributed systems. This view is based on the concept of emergentsemantics; which sees both the representation of semantics and the discovery of the properinterpretation of symbols as the result of a self-organizing process performed by distributedagents exchanging symbols and having utilities dependent on the proper interpretation ofthe symbols. This is a complex systems perspective on the problem of dealing withsemantics. We highlight some of the distinctive features of our vision and point outpreliminary examples of its application.,*,2006,42
TripleProv: Efficient processing of lineage queries in a native RDF store,Marcin Wylot; Philippe Cudre-Mauroux; Paul Groth,Abstract Given the heterogeneity of the data one can find on the Linked Data cloud; beingable to trace back the provenance of query results is rapidly becoming a must-have featureof RDF systems. While provenance models have been extensively discussed in recentyears; little attention has been given to the efficient implementation of provenance-enabledqueries inside data stores. This paper introduces TripleProv: a new system extending anative RDF store to efficiently handle such queries. TripleProv implements two differentstorage models to physically co-locate lineage and instance data; and for each of themimplements algorithms for tracing provenance at two granularity levels. In the following; wepresent the overall architecture of our system; its different lineage storage models; and thevarious query execution strategies we have implemented to efficiently answer …,Proceedings of the 23rd international conference on World wide web,2014,41
dipLODocus [RDF]—short and long-tail rdf analytics for massive webs of data,Marcin Wylot; Jigé Pont; Mariusz Wisniewski; Philippe Cudré-Mauroux,Abstract The proliferation of semantic data on the Web requires RDF database systems toconstantly improve their scalability and transactional efficiency. At the same time; users areincreasingly interested in investigating or visualizing large collections of online data byperforming complex analytic queries. This paper introduces a novel database system forRDF data management called dipLODocus _RDF~; which supports both transactional andanalytical queries efficiently. dipLODocus _RDF~ takes advantage of a new hybrid storagemodel for RDF data based on recurring graph patterns. In this paper; we describe thegeneral architecture of our system and compare its performance to state-of-the-art solutionsfor both transactional and analytic workloads.,International Semantic Web Conference,2011,38
LSH At Large-Distributed KNN Search in High Dimensions.,Parisa Haghani; Sebastian Michel; Philippe Cudré-Mauroux; Karl Aberer,ABSTRACT We consider K-Nearest Neighbor search for high dimensional data in large-scale structured Peer-to-Peer networks. We present an efficient mapping scheme based onp-stable Locality Sensitive Hashing to assign hash buckets to peers in a Chord-style overlaynetwork. To minimize network traffic; we process queries in an incremental top-K fashionleveraging on a locality preserving mapping to the peer space. Furthermore; we considerload balancing by harnessing estimates of the resulting data mapping; which follows anormal distribution. We report on a comprehensive performance evaluation using highdimensional real-world data; demonstrating the suitability of our approach.,WebDB,2008,36
Trank: Ranking entity types using the web of data,Alberto Tonon; Michele Catasta; Gianluca Demartini; Philippe Cudré-Mauroux; Karl Aberer,Abstract Much of Web search and browsing activity is today centered around entities. Forthis reason; Search Engine Result Pages (SERPs) increasingly contain information aboutthe searched entities such as pictures; short summaries; related entities; and factualinformation. A key facet that is often displayed on the SERPs and that is instrumental formany applications is the entity type. However; an entity is usually not associated to a singlegeneric type in the background knowledge bases but rather to a set of more specific types;which may be relevant or not given the document context. For example; one can find on theLinked Open Data cloud the fact that Tom Hanks is a person; an actor; and a person fromConcord; California. All those types are correct but some may be too general to beinteresting (eg; person); while other may be interesting but already known to the user (eg …,International Semantic Web Conference,2013,34
Experience using web services for biological sequence analysis,Heinz Stockinger; Teresa Attwood; Shahid Nadeem Chohan; Richard Côté; Philippe Cudré-Mauroux; Laurent Falquet; Pedro Fernandes; Robert D Finn; Taavi Hupponen; Eija Korpelainen; Alberto Labarga; Aurelie Laugraud; Tania Lima; Evangelos Pafilis; Marco Pagni; Steve Pettifer; Isabelle Phan; Nazim Rahman,Abstract Programmatic access to data and tools through the web using so-called webservices has an important role to play in bioinformatics. In this article; we discuss the mostpopular approaches based on SOAP/WS-I and REST and describe our; a cross section ofthe community; experiences with providing and using web services in the context ofbiological sequence analysis. We briefly review main technological approaches as well asbest practice hints that are useful for both users and developers. Finally; syntactic andsemantic data integration issues with multiple web services are discussed.,Briefings in bioinformatics,2008,31
The case for rodentstore; an adaptive; declarative storage system,Philippe Cudre-Mauroux; Eugene Wu; Sam Madden,Abstract: Recent excitement in the database community surrounding new applications?analytic; scientific; graph; geospatial; etc.? has led to an explosion in research on databasestorage systems. New storage systems are vital to the database community; as they are atthe heart of making database systems perform well in new application domains.Unfortunately; each such system also represents a substantial engineering effort including agreat deal of duplication of mechanisms for features such as transactions and caching. Inthis paper; we make the case for RodentStore; an adaptive and declarative storage systemproviding a high-level interface for describing the physical representation of data.Specifically; RodentStore uses a declarative storage algebra whereby administrators (ordatabase design tools) specify how a logical schema should be grouped into collections …,arXiv preprint arXiv:0909.1779,2009,26
Emergent semantics,Philippe Cudré-Mauroux,Definition eAccessibility refers to the access of Information and CommunicationTechnologies (ICT) by people with disabilities; with particular emphasis on the World WideWeb. It is the extent to which the use of an application or service is affected by the user'sparticular functional limitations or abilities (permanent or temporary). eAccessibility can beconsidered as a fundamental prerequisite of usability.,*,2009,26
Scaling-up the crowd: Micro-task pricing schemes for worker retention and latency improvement,Djellel Eddine Difallah; Michele Catasta; Gianluca Demartini; Philippe Cudré-Mauroux,Abstract Retaining workers on micro-task crowdsourcing platforms is essential in order toguarantee the timely completion of batches of Human Intelligence Tasks (HITs). Workerretention is also a necessary condition for the introduction of SLAs on crowdsourcingplatforms. In this paper; we introduce novel pricing schemes aimed at improving theretention rate of workers working on long batches of similar tasks. We show how increasingor decreasing the monetary reward over time influences the number of tasks a worker iswilling to complete in a batch; as well as how it influences the overall latency. We compareour new pricing schemes against traditional pricing methods (eg; constant reward for all theHITs in a batch) and empirically show how certain schemes effectively function as anincentive for workers to keep working longer on a given batch of HITs. Our experimental …,Second AAAI Conference on Human Computation and Crowdsourcing,2014,25
Benchmarking oltp/web databases in the cloud: The oltp-bench framework,Carlo A Curino; Djellel E Difallah; Andrew Pavlo; Philippe Cudre-Mauroux,Abstract Benchmarking is a key activity in building and tuning data management systems;but the lack of reference workloads and a common platform makes it a time consuming andpainful task. The need for such a tool is heightened with the advent of cloud computing--withits pay-per-use cost models; shared multi-tenant infrastructures; and lack of control onsystem configuration. Benchmarking is the only avenue for users to validate the quality ofservice they receive and to optimize their deployments for performance and resourceutilization. In this talk; we present our experience in building several adhoc benchmarkinginfrastructures for various research projects targeting several OLTP DBMSs; ranging fromtraditional relational databases; main-memory distributed systems; and cloud-basedscalable architectures. We also discuss our struggle to build meaningful micro …,Proceedings of the fourth international workshop on Cloud data management,2012,25
Applying fuzzy DLs in the extraction of image semantics,Stamatia Dasiopoulou; Ioannis Kompatsiaris; Michael G Strintzis,Abstract Statistical learning approaches; bounded mainly to knowledge related to perceptualmanifestations of semantics; fall short to adequately utilise the meaning and logicalconnotations pertaining to the extracted image semantics. Instigated by the Semantic Web;ontologies have appealed to a significant share of synergistic approaches towards thecombined use of statistical learning and explicit semantics. While the relevant literaturetends to disregard the uncertainty involved; and treats the extracted image descriptions ascoherent; two valued propositions; this paper explores reasoning under uncertainty towardsa more accurate and pragmatic handling of the underlying semantics. Using fuzzy DLs; theproposed reasoning framework captures the vagueness of the extracted image descriptionsand accomplishes their semantic interpretation; while resolving inconsistencies rising …,*,2009,25
Executing provenance-enabled queries over web data,Marcin Wylot; Philippe Cudre-Mauroux; Paul Groth,Abstract The proliferation of heterogeneous Linked Data on the Web poses new challengesto database systems. In particular; because of this heterogeneity; the capacity to store; track;and query provenance data is becoming a pivotal feature of modern triple stores. In thispaper; we tackle the problem of efficiently executing provenance-enabled queries over RDFdata. We propose; implement and empirically evaluate five different query executionstrategies for RDF queries that incorporate knowledge of provenance. The evaluation isconducted on Web Data obtained from two different Web crawls (The Billion TripleChallenge; and the Web Data Commons). Our evaluation shows that using an adaptivequery materialization execution strategy performs best in our context. Interestingly; we findthat because provenance is prevalent within Web Data and is highly selective; it can be …,Proceedings of the 24th International Conference on World Wide Web,2015,24
A necessary condition for semantic interoperability in the large,Philippe Cudré-Mauroux; Karl Aberer,Abstract With new standards like RDF or OWL paving the way for the much anticipatedsemantic web; a new breed of large scale semantic systems is about to appear. Even ifresearch on semantic reconciliation methods is abundant; it is not clear how interoperablevery large scale semantic systems can be. This paper represents a first effort towardsanalytically analyzing semantic interoperability in the large: By adapting a recent graph-theoretic framework; we examine the dynamics of large scale semantic systems and derive anecessary condition for fostering global semantic interoperability.,OTM Confederated International Conferences" On the Move to Meaningful Internet Systems",2004,24
Big data analytics on high Velocity streams: A case study,Thibaud Chardonnens; Philippe Cudre-Mauroux; Martin Grund; Benoit Perroud,Big data management is often characterized by three Vs: Volume; Velocity and Variety.While traditional batch-oriented systems such as MapReduce are able to scale-out andprocess very large volumes of data in parallel; they also introduce some significant latency.In this paper; we focus on the second V (Velocity) of the Big Data triad; We present a case-study where we use a popular open-source stream processing engine (Storm) to performreal-time integration and trend detection on Twitter and Bitly streams. We describe our trenddetection solution below and experimentally demonstrate that our architecture caneffectively process data in real-time-even for high-velocity streams.,Big Data; 2013 IEEE International Conference on,2013,23
ScienceWISE: a Web-based Interactive Semantic Platform for scientific collaboration,Karl Aberer; Alexey Boyarsky; Philippe Cudré-Mauroux; Gianluca Demartini; Oleg Ruchayskiy,Organizing scientific knowledge in systematic ways becomes increasingly important.However; the creation of intra-and inter-disciplinary knowledge bases is hindered by theheterogeneity and the scale of the information to consider. This calls for scientific community-run systems (replacing classical publishers of encyclopedias) allowing to combinepresentation of new results; in-depth discussions;“user-friendly” introductions for youngscientists; and meta-data to relate semantically similar concepts or pieces of content. Today;there are no standard tools to insert; store and query such meta-data online; which mostlyremains “in the heads of the experts”. The goal of the ScienceWISE (SW) project is toimprove this situation. ScienceWISE 6 allows a community of scientists; working in a specificdomain; to generate dynamically as part of their daily work an interactive semantic …,ISWC (Demonstration Track),2011,22
Scalable anomaly detection for smart city infrastructure networks,Djellel Eddine Difallah; Philippe Cudre-Mauroux; Sean A McKenna,Dynamically detecting anomalies can be difficult in very large-scale infrastructure networks.The authors' approach addresses spatiotemporal anomaly detection in a smarter city contextwith large numbers of sensors deployed. They propose a scalable; hybrid Internetinfrastructure for dynamically detecting potential anomalies in real time using streamprocessing. The infrastructure enables analytically inspecting and comparing anomaliesglobally using large-scale array processing. Deployed on a real pipe network topology of1;891 nodes; this approach can effectively detect and characterize anomalies whileminimizing the amount of data shared across the network.,IEEE Internet Computing,2013,21
Noizcrowd: A crowd-based data gathering and management system for noise level data,Mariusz Wisniewski; Gianluca Demartini; Apostolos Malatras; Philippe Cudré-Mauroux,Abstract Many systems require access to very large amounts of data to properly function; likesystems allowing to visualize or predict meteorological changes in a country over a givenperiod of time; or any other system holding; processing and displaying scientific or sensordata. However; filling out a database with large amounts of valuable data can be a difficult;costly and time-consuming task. In this paper; we present techniques to create largeamounts of data by combining crowdsourcing; data generation models; mobile computing;and big data analytics. We have implemented our methods in a system; NoizCrowd;allowing to crowdsource noise levels in a given region and to generate noise models byusing state-of-the-art noise propagation models and array data management techniques.The resulting models and data can then be accessed using a visual interface.,International Conference on Mobile Web and Information Systems,2013,21
The Bowlogna ontology: Fostering open curricula and agile knowledge bases for Europe's higher education landscape,Gianluca Demartini; Iliya Enchev; Joël Gapany; Philippe Cudré-Mauroux,Abstract The Bologna Process initiated a radical change within higher education institutions.This change triggered the creation of new administrative procedures in the every day life ofEuropean universities. It also gave rise to the emergence of new concepts for the descriptionof curricula. It is critical for the successful continuation of this process to support thepublication and exchange of information among universities. With this aim in mind; wecreated the Bowlogna Ontology to model an academic setting as proposed by the Bolognareform. In this paper; we present our efforts to design this ontology and the entire processthat lead to its creation starting from the definition of a linguistic lexicon derived from theBologna reform and its conversion to a formal ontology. We also describe practicalapplications of our ontology for end-users at universities (such as a faceted search and …,Semantic Web,2013,21
Graph data management systems for new application domains,Philippe Cudré-Mauroux; Sameh Elnikety,ABSTRACT Graph data management has long been a topic of interest for databaseresearchers. The topic gained renewed interest recently; motivated by the rapid emergenceof new application domains including social networks and the Web of data. This tutorialcharacterizes graph data management techniques and categorizes recent graph datamanagement systems. In this context; we focus on the management of very large graphssuch as social networks or the Web of data; rather than on the management of many smallergraphs (which frequently appear in bioinformatics and cheminformatics). The first part of thistutorial describes the requirements imposed by new application domains; and provides aclassification of recent systems according to their data and computation models. Ourclassification also highlights the main representations used to store the graph (dense …,Proceedings of the VLDB Endowment,2011,21
Ss-db: A standard science dbms benchmark,Philippe Cudre-Mauroux; Hideaki Kimura; Kian-Tat Lim; Jennie Rogers; Samuel Madden; Michael Stonebraker; Stanley B Zdonik; Paul G Brown,*,Under submission,2010,21
FORA–A fuzzy set based framework for online reputation management,Edy Portmann; Andreas Meier; Philippe Cudré-Mauroux; Witold Pedrycz,Abstract The Social Web offers increasingly simple ways to publish and disseminatepersonal or opinionated information; which can rapidly exhibit a disastrous influence on theonline reputation of organizations. Based on social Web data; this study describes thebuilding of an ontology based on fuzzy sets. At the end of a recurring harvesting offolksonomies by Web agents; the aggregated tags are purified; linked; and transformed to aso-called fuzzy grassroots ontology by means of a fuzzy clustering algorithm. This self-updating ontology is used for online reputation analysis; a crucial task of reputationmanagement; with the goal to follow the online conversation going on around anorganization to discover and monitor its reputation. In addition; an application of the FuzzyOnline Reputation Analysis (FORA) framework; lessons learned; and potential extensions …,Fuzzy sets and systems,2015,19
Effective named entity recognition for idiosyncratic web collections,Roman Prokofyev; Gianluca Demartini; Philippe Cudré-Mauroux,Abstract Named Entity Recognition (NER) plays an important role in a variety of onlineinformation management tasks including text categorization; document clustering; andfaceted search. While recent NER systems can achieve near-human performance on certaindocuments like news articles; they still remain highly domain-specific and thus cannoteffectively identify entities such as original technical concepts in scientific documents. In thiswork; we propose novel approaches for NER on distinctive document collections (such asscientific articles) based on n-grams inspection and classification. We design and evaluateseveral entity recognition features---ranging from well-known part-of-speech tags to n-gramco-location statistics and decision trees---to classify candidates. In addition; we show howthe use of external knowledge bases (either specific like DBLP or generic like DBPedia) …,Proceedings of the 23rd international conference on World wide web,2014,19
PicShark: mitigating metadata scarcity through large-scale P2P collaboration,Philippe Cudré-Mauroux; Adriana Budura; Manfred Hauswirth; Karl Aberer,Abstract With the commoditization of digital devices; personal information and media sharingis becoming a key application on the pervasive Web. In such a context; data annotationrather than data production is the main bottleneck. Metadata scarcity represents a majorobstacle preventing efficient information processing in large and heterogeneouscommunities. However; social communities also open the door to new possibilities foraddressing local metadata scarcity by taking advantage of global collections of resources.We propose to tackle the lack of metadata in large-scale distributed systems through acollaborative process leveraging on both content and metadata. We develop a community-based and self-organizing system called PicShark in which information entropy—in terms ofmissing metadata—is gradually alleviated through decentralized instance and schema …,The VLDB Journal,2008,19
Compound term composition algebra: the semantics,Yannis Tzitzikas; Anastasia Analyti; Nicolas Spyratos,Abstract The Compound Term Composition Algebra (CTCA) is an algebra with fouralgebraic operators; whose composition can be used to specify the meaningful (valid)compound terms (conjunctions of terms) in a given faceted taxonomy in an efficient andflexible manner. The “positive” operations allow the derivation of valid compound termsthrough the declaration of a small set of valid compound terms. The “negative” operationsallow the derivation of valid compound terms through the declaration of a small set of invalidcompound terms. In this paper; we formally define the model-theoretic semantics of theoperations and the closed-world assumptions adopted in each operation. We prove thatCTCA is monotonic with respect to both valid and invalid compound terms; meaning that thevalid and invalid compound terms of a subexpression are not invalidated by a larger …,*,2005,19
Diplocloud: Efficient and scalable management of rdf data in the cloud,Marcin Wylot; Philippe Cudré-Mauroux,Despite recent advances in distributed RDF data management; processing large-amounts ofRDF data in the cloud is still very challenging. In spite of its seemingly simple data model;RDF actually encodes rich and complex graphs mixing both instance and schema-leveldata. Sharding such data using classical techniques or partitioning the graph usingtraditional min-cut algorithms leads to very inefficient distributed operations and to a highnumber of joins. In this paper; we describe DiploCloud; an efficient and scalable distributedRDF data management system for the cloud. Contrary to previous approaches; DiploCloudruns a physiological analysis of both instance and schema information prior to partitioningthe data. In this paper; we describe the architecture of DiploCloud; its main data structures;as well as the new algorithms we use to partition and distribute data. We also present an …,IEEE Transactions on Knowledge and Data Engineering,2016,18
Pooling-based continuous evaluation of information retrieval systems,Alberto Tonon; Gianluca Demartini; Philippe Cudré-Mauroux,Abstract The dominant approach to evaluate the effectiveness of information retrieval (IR)systems is by means of reusable test collections built following the Cranfield paradigm. Inthis paper; we propose a new IR evaluation methodology based on pooled test-collectionsand on the continuous use of either crowdsourcing or professional editors to obtainrelevance judgements. Instead of building a static collection for a finite set of systems knowna priori; we propose an IR evaluation paradigm where retrieval approaches are evaluatediteratively on the same collection. Each new retrieval technique takes care of obtaining itsmissing relevance judgements and hence contributes to augmenting the overall set ofrelevance judgements of the collection. We also propose two metrics: Fairness Score; andopportunistic number of relevant documents; which we then use to define new pooling …,Information Retrieval Journal,2015,18
A decentralized architecture for adaptive media dissemination,Philippe Cudré-Mauroux; Karl Aberer,P2P (peer-to-peer) content distribution networks have become extremely popular on theInternet. Due to their self-organization properties; they suffer from the lack of control tobalance the load among peers for contents of different popularity. We define and analyze afully decentralized architecture to support replication of popular media content in a peer-to-peer network. We show that by exploiting local knowledge only; this method achieves a near-optimal behavior with respect to response time in a scenario with limited storage capabilitiesat peers.,Multimedia and Expo; 2002. ICME'02. Proceedings. 2002 IEEE International Conference on,2002,18
Online anomaly detection over big data streams,Laura Rettig; Mourad Khayati; Philippe Cudré-Mauroux; Michal Piorkowski,Data quality is a challenging problem in many real world application domains. While a lot ofattention has been given to detect anomalies for data at rest; detecting anomalies forstreaming applications still largely remains an open problem. For applications involvingseveral data streams; the challenge of detecting anomalies has become harder over time; asdata can dynamically evolve in subtle ways following changes in the underlyinginfrastructure. In this paper; we describe and empirically evaluate an online anomalydetection pipeline that satisfies two key conditions: generality and scalability. Our techniqueworks on numerical data as well as on categorical data and makes no assumption on theunderlying data distributions. We implement two metrics; relative entropy and Pearsoncorrelation; to dynamically detect anomalies. The two metrics we use provide an efficient …,Big Data (Big Data); 2015 IEEE International Conference on,2015,17
Emergent semantics: rethinking interoperability for large scale decentralized information systems,Philippe Cudré-Mauroux,Abstract In the past; the problem of semantic interoperability in information systems wasmostly solved by means of centralization; both at a system and at a logical level. Thisapproach has been successful to a certain extent; but offers limited scalability and flexibility.Peer-to-Peer systems as a new brand of system architectures indicate that the principles ofdecentralization and self-organization might offer new solutions to many problems that scalewell to very large numbers of users; or to systems where central authorities do not prevail.Therefore; we suggest a new way of building global agreements; ie; semanticinteroperability; based on decentralized; self-organizing interactions only. In the first part ofthis thesis; we discuss traditional data integration techniques relying on global schemas;perfect schema mappings and contained query rewritings. We elaborate on the current …,Ecole Polytechnique Fédérale de Lausanne (EPFL); Lausanne,2006,17
Semantic web meets computational intelligence: State of the art and perspectives,Huajun Chen; Zhaohui Wu; Philippe Cudre-Mauroux,The Semantic Web; as a decentralized complex system; is akin to be fuzzy and evolutionary.In this article; a comprehensive survey on the applications of variant ComputationalIntelligence methods to enhance a variety of Semantic Web applications is provided. Thesurvey consists of three aspects: fuzzy logic to deal with vagueness and uncertainty in Websemantics; evolutionary computations to deal with the vastness and tractability issues instoring; querying; reasoning and mapping semantic data; artificial neural network to improvethe learning capability of the Semantic Web. Based on the survey of the existing approachesin the literature; some potential future research directions in this area have also beendiscussed and proposed.,IEEE Computational Intelligence Magazine,2012,16
An overview of HYRISE-a Main Memory Hybrid Storage Engine.,Martin Grund; Philippe Cudré-Mauroux; Jens Krüger; Samuel Madden; Hasso Plattner,Abstract HYRISE is a new relational storage engine for main memory database systems. It isbuilt on the premise that enterprise application workloads can benefit from a dedicated main-memory storage engine. The key idea behind HYRISE is that it provides dynamic verticalpartitioning of the tables it stores. Since enterprise applications typically use a large numberof very wide tables; we designed a novel layout algorithm specifically tailored for enterprisedata. Our algorithm uses a main memory cost model that is able to precisely estimate thephysical access cost of database operators and to determine a vertical partitioning thatyields the best execution performance.,IEEE Data Eng. Bull.,2012,16
BowlognaBench—Benchmarking RDF Analytics,Gianluca Demartini; Iliya Enchev; Marcin Wylot; Joël Gapany; Philippe Cudré-Mauroux,Abstract The proliferation of semantic data on the Web requires RDF database systems toconstantly improve their scalability and efficiency. At the same time; users are increasinglyinterested in investigating large collections of online data by performing complex analyticqueries (eg;“how did university student performance evolve over the last 5 years?”). Thispaper introduces a novel benchmark for evaluating and comparing the efficiency ofSemantic Web data management systems on analytic queries. Our benchmark models areal-world setting derived from the Bologna process and offers a broad set of queriesreflecting a large panel of concrete; data-intensive user needs.,International Symposium on Data-Driven Process Discovery and Analysis,2011,16
SANAPHOR: Ontology-based coreference resolution,Roman Prokofyev; Alberto Tonon; Michael Luggen; Loic Vouilloz; Djellel Eddine Difallah; Philippe Cudré-Mauroux,Abstract We tackle the problem of resolving coreferences in textual content by leveragingSemantic Web techniques. Specifically; we focus on noun phrases that coreferenceidentifiable entities that appear in the text; the challenge in this context is to improve thecoreference resolution by leveraging potential semantic annotations that can be added tothe identified mentions. Our system; SANAPHOR; first applies state-of-the-art techniques toextract entities; noun phrases; and candidate coreferences. Then; we propose an approachto type noun phrases using an inverted index built on top of a Knowledge Graph (eg;DBpedia). Finally; we use the semantic relatedness of the introduced types to improve thestate-of-the-art techniques by splitting and merging coreference clusters. We evaluateSANAPHOR on CoNLL datasets; and show how our techniques consistently improve the …,International Semantic Web Conference,2015,14
Large-scale Linked Data Processing-Cloud Computing to the Rescue?.,Michael Hausenblas; Robert Grossman; Andreas Harth; Philippe Cudré-Mauroux,Abstract: Processing large volumes of Linked Data requires sophisticated methods andtools. In the recent years we have mainly focused on systems based on relational databasesand bespoke systems for Linked Data processing. Cloud computing offerings such asSimpleDB or BigQuery; and cloud-enabled NoSQL systems including Cassandra orCouchDB as well as frameworks such as Hadoop offer appealing alternatives along withgreat promises concerning performance; scalability and elasticity. In this paper we state anumber of Linked Dataspecific requirements and review existing cloud computing offeringsas well as NoSQL systems that may be used in a cloud computing setup; in terms of theirapplicability and usefulness for processing datasets on a large-scale.,CLOSER,2012,14
To tag or not to tag-: harvesting adjacent metadata in large-scale tagging systems,Adriana Budura; Sebastian Michel; Philippe Cudré-Mauroux; Karl Aberer,Abstract We present HAMLET; a suite of principles; scoring models and algorithms toautomatically propagate metadata along edges in a document neighborhood. As ashowcase scenario we consider tag prediction in community-based Web 2.0 taggingapplications. Experiments using real-world data demonstrate the viability of our approach inlarge-scale environments where tags are scarce. To the best of our knowledge; HAMLET isthe first system to promote an efficient and precise reuse of shared metadata in highlydynamic; large-scale Web 2.0 tagging systems.,Proceedings of the 31st annual international ACM SIGIR conference on Research and development in information retrieval,2008,14
Uduvudu: a Graph-Aware and Adaptive UI Engine for Linked Data.,Michael Luggen; Adrian Gschwend; Bernhard Anrig; Philippe Cudré-Mauroux,ABSTRACT Creating good User Interfaces (UIs) to render Linked Data visually is a complextask; often involving both UI and Linked Data specialists. The resulting solutions are typicallyapplication-dependent and difficult to adapt or reuse in a different context. To tackle thisproblem; we propose Uduvudu; a flexible; open-source engine to visualize Linked Data. Ourengine is built in JavaScript and runs in the browser natively. Non-specialist users can useUduvudu to describe recurring subgraph patterns occurring in their data. They can thenflexibly and automatically extract; transform; and visually render such patterns in multipleways depending of the usage context. Uduvudu is intuitive; flexible; and efficient and makesit possible to jump-start the development of complex user interfaces based on Linked Datawithout the need of data specialists.,LDOW@ WWW,2015,13
The Semantic Web,Karl Aberer; Key-Sun Choi; Natasha Fridman Noy; Dean Allemang; Kyung-Il Lee; Lyndon JB Nixon; Jennifer Golbeck; Peter Mika; Diana Maynard; Riichiro Mizoguchi; Guus Schreiber; Philippe Cudré-Mauroux,The World-Wide Web continues to grow and new technologies; modes of interactions; andapplications are being developed. Building on this growth; Semantic Web technologies aimat providing a shared semantic information space; changing qualitatively our experiences onthe Web. As Semantic Web technologies mature and permeate more and more applicationareas; new research challenges are coming to the fore and some unsolved ones arebecoming more acute. These issues include creating and managing Semantic Web content;making Semantic Web applications robust and scalable; organizing and integratinginformation from different sources for novel uses; making semantics explicit in order toimprove our overall experience with information technologies; and thus enabling us to usethe wealth of information that is currently available in digital form for addressing our …,6th International Semantic Web Conference; 2nd Asian Semantic Web Conference; ISWC,2007,13
Self-organizing schema mappings in the gridvine peer data management system,Philippe Cudré-Mauroux; Suchit Agarwal; Adriana Budura; Parisa Haghani; Karl Aberer,Abstract GridVine is a Peer Data Management System based on a decentralized accessstructure. Built following the principle of data independence; it separates a logical layer--where data; schemas and mappings are managed--from a physical layer consisting of astructured Peer-to-Peer network supporting efficient routing of messages and index load-balancing. Our system is totally decentralized; yet it fosters semantic interoperability throughpairwise schema mappings and query reformulation. In this demonstration; we present a setof algorithms to automatically organize the network of schema mappings. We concentrate onthree key functionalities:(1) the sharing of data; schemas and schema mappings in thenetwork;(2) the dynamic creation and deprecation of mappings to foster globalinteroperability; and (3) the propagation of queries using the mappings. We illustrate …,Proceedings of the 33rd international conference on Very large data bases,2007,12
Database Systems for Advanced Applications: 9th International Conference; DASFAA 2004; Jeju Island; Korea; March 17-19; 2003; Proceedings,YoonJoon Lee; Jianzhong Li; Kyu-Young Whang; Doheon Lee,The 9th International Conference on Database Systems for Advanced Applications(DASFAA 2004) was held during March 17–19; 2004 on the beautiful Jeju island of Korea.The DASFAA conference provides an international forum for technical discussions amongresearchers; developers; and users of database systems from academia; business; andindustry. The main focus of DASFAA is on research in database theory; development ofadvanced DBMS technologies; and their advanced applications. A premier databaseconference in the Asia/Pacific region; DASFAA has been held every two years; and in manycountries in the region. To promote the area further and to answer the needs of manyparticipants; the steering committee decided to hold the conference annually. DASFAA 2004was the first such annual conference. The conference was organized by the Special …,*,2004,12
Contextualized ranking of entity types based on knowledge graphs,Alberto Tonon; Michele Catasta; Roman Prokofyev; Gianluca Demartini; Karl Aberer; Philippe Cudre-Mauroux,Abstract A large fraction of online queries targets entities. For this reason; Search EngineResult Pages (SERPs) increasingly contain information about the searched entities such aspictures; short summaries; related entities; and factual information. A key facet that is oftendisplayed on the SERPs and that is instrumental for many applications is the entity type.However; an entity is usually not associated to a single generic type in the backgroundknowledge graph but rather to a set of more specific types; which may be relevant or notgiven the document context. For example; one can find on the Linked Open Data cloud thefact that Tom Hanks is a person; an actor; and a person from Concord; California. All thesetypes are correct but some may be too general to be interesting (eg; person); while othermay be interesting but already known to the user (eg; actor); or may be irrelevant given …,Web Semantics: Science; Services and Agents on the World Wide Web,2016,10
Tag recommendation for large-scale ontology-based information systems,Roman Prokofyev; Alexey Boyarsky; Oleg Ruchayskiy; Karl Aberer; Gianluca Demartini; Philippe Cudré-Mauroux,Abstract We tackle the problem of improving the relevance of automatically selected tags inlarge-scale ontology-based information systems. Contrary to traditional settings where tagscan be chosen arbitrarily; we focus on the problem of recommending tags (eg; concepts)directly from a collaborative; user-driven ontology. We compare the effectiveness of a seriesof approaches to select the best tags ranging from traditional IR techniques such as TF/IDFweighting to novel techniques based on ontological distances and latent Dirichlet allocation.All our experiments are run against a real corpus of tags and documents extracted from theScienceWise portal; which is connected to ArXiv. org and is currently used by growingnumber of researchers. The datasets for the experiments are made available online forreproducibility purposes.,International Semantic Web Conference,2012,10
From bioinformatic web portals to semantically integrated Data Grid networks,Adriana Budura; Philippe Cudré-Mauroux; Karl Aberer,Abstract We propose a semi-automated method for redeploying bioinformatic databasesindexed in a Web portal as a decentralized; semantically integrated and service-orientedData Grid. We generate peer-to-peer schema mappings leveraging on cross-referencedinstances and instance-based schema matching algorithms. Analyzing real-world dataextracted from an existing portal; we show how a rather trivial combination of lexicographicalmeasures with set distance measures yields surprisingly good results in practice. Finally; wepropose data models for redeploying all instances; schemas and schema mappings in theData Grid; relying on standard Semantic Web technologies.,Future Generation Computer Systems,2007,10
Poisketch: Semantic place labeling over user activity streams,Dingqi Yang; Bin Li; Philippe Cudré-Mauroux,Abstract Capturing place semantics is critical for enabling location-based applications.Techniques for assigning semantic labels (eg;“bar” or “office”) to unlabeled places mainlyresort to mining user activity logs by exploiting visiting patterns. However; existingapproaches focus on inferring place labels with a static user activity dataset; and ignore thevisiting pattern dynamics in user activity streams; leading to the rapid decrease of labelingaccuracy over time. In this paper; we tackle the problem of semantic place labeling over useractivity streams. We formulate this problem as a classification problem by characterizingeach place through its finegrained visiting patterns; which encode the visiting frequency ofeach user in each typical time slot. However; with the incoming activities of new users indata streams; such fine-grained visiting patterns constantly grow; leading to a …,*,2016,9
Guest editorial: Special issue on human-centered web science,Ernesto Damiani; Miltiadis Lytras; Philippe Cudre-Mauroux,In the last five years; service orientation and social computing have radically changed thenature of the World Wide Web. With today's Service-Oriented Architectures (SOA); no strictdivision of labor should or can exist between the tasks for which software services areresponsible and those that are delegated to people. Rather; human actors and softwareprocess engines cooperate closely to enact business processes at a previously unheard-ofscale and complexity level. In turn; large scale social interaction on the Web has fostered thegeneration of an enormous amount of User-Generated Content (UCG); whose semanticsand pragmatics tend to gradually emerge as the result of large-scale human iteration ratherthan be conceived a priori by normative design. Large-scale cooperation; however; hasintroduced new weaknesses; in interorganizational distributed environments; software …,World Wide Web,2010,9
Scheduling human intelligence tasks in multi-tenant crowd-powered systems,Djellel Eddine Difallah; Gianluca Demartini; Philippe Cudré-Mauroux,Abstract Micro-task crowdsourcing has become a popular approach to effectively tacklecomplex data management problems such as data linkage; missing values; or schemamatching. However; the backend crowdsourced operators of crowd-powered systemstypically yield higher latencies than the machine-processable operators; this is mainly due toinherent efficiency differences between humans and machines. This problem can be furtherexacerbated by the lack of workers on the target crowdsourcing platform; or when theworkers are shared unequally among a number of competing requesters; including theconcurrent users from the same organization who execute crowdsourced queries withdifferent types; priorities and prices. Under such conditions; a crowd-powered system actsmostly as a proxy to the crowdsourcing platform; and hence it is very difficult to provide …,Proceedings of the 25th International Conference on World Wide Web,2016,8
The Entity Registry System: Implementing 5-Star Linked Data Without the Web,Marat Charlaganov; Philippe Cudré-Mauroux; Cristian Dinu; Christophe Guéret; Martin Grund; Teodor Macicas,Abstract: Linked Data applications often assume that connectivity to data repositories andentity resolution services are always available. This may not be a valid assumption in manycases. Indeed; there are about 4.5 billion people in the world who have no or limited Webaccess. Many data-driven applications may have a critical impact on the life of those people;but are inaccessible to those populations due to the architecture of today's data registries. Inthis paper; we propose and evaluate a new open-source system that can be used as ageneral-purpose entity registry suitable for deployment in poorly-connected or ad-hocenvironments.,arXiv preprint arXiv:1308.3357,2013,8
Ontology-based word sense disambiguation for scientific literature,Roman Prokofyev; Gianluca Demartini; Alexey Boyarsky; Oleg Ruchayskiy; Philippe Cudré-Mauroux,Abstract Scientific documents often adopt a well-defined vocabulary and avoid the use ofambiguous terms. However; as soon as documents from different research sub-communitiesare considered in combination; many scientific terms become ambiguous as the same termcan refer to different concepts from different sub-communities. The ability to correctly identifythe right sense of a given term can considerably improve the effectiveness of retrievalmodels; and can also support additional features such as search diversification. This is evenmore critical when applied to explorative search systems within the scientific domain. In thispaper; we propose novel semi-supervised methods to term disambiguation leveraging thestructure of a community-based ontology of scientific concepts. Our approach exploits thegraph structure that connects different terms and their definitions to automatically identify …,European conference on information retrieval,2013,8
PIX-Grid: A platform for P2P photo exchange,Karl Aberer; Philippe Cudré-Mauroux; Anwitaman Datta; Manfred Hauswirth,Abstract. The proliferation of digital camera devices (stand-alone or combined with cellphones); new protocols such as MMS and the desire of people to communicate and sharetheir experience call for new systems to support these needs in new Internet-scaleinfrastructures. In this paper we outline our plans for an Internet-scale P2P system thatenables users to share (globally or only within a group) and efficiently locate photographsbased on semi-automatically provided meta-information (by the devices and the user).,Ubiquitous Mobile Information and Collaboration Systems (UMICS 2003),2003,7
Mistral: An architecture for low-latency analytics on massive time series,Alice Marascu; Pascal Pompey; Eric Bouillet; Olivier Verscheure; Michael Wurst; Martin Grund; Philippe Cudre-Mauroux,Smart sensors are increasingly being used to manage and monitor critical urbaninfrastructures; eg; for telecommunication; transport; water; or energy networks; as well as forhealthcare or smart buildings. Sensor-based monitoring systems offer ways of continuouslymonitoring low frequency activities; and open the door to new analytic and predictiveapplications in Smarter Cities. Such sensors generate “tricklets”; ie; noisy and continuoustime series. Tricklets are typically misaligned; non-uniformly sampled; and comprise lowfrequency activities and recurring patterns. Storing and making sense of such data in atypical database management system is difficult; due to the impedance mismatch betweenclassical (eg; relational) data and tricklets. In this paper; we investigate the management oflarge amounts of tricklets from an architectural perspective; and propose MiSTRAL …,Big Data; 2013 IEEE International Conference on,2013,6
Semantic gossiping: fostering semantic interoperability in peer data management systems,Karl Aberer; Philippe Cudré-Mauroux; Manfred Hauswirth,Summary Until recently; most data integration techniques revolved around centralapproaches; eg; global schemas; to enable transparent access to heterogeneousdatabases. However; with the advent of the Internet and the democratization of toolsfacilitating knowledge elicitation in machine-processable formats; the situation is quicklyevolving. One cannot rely on global; centralized schemas anymore as knowledge creationand consumption are getting increasingly dynamic and decentralized. Peer DataManagement Systems (PDMS) address this problem by eliminating centralization andinstead applying compositions of local; pair-wise mappings to propagate queries amongdatabases. We present a method to foster global semantic interoperability in PDMS settingsin a totally decentralized way based on the analysis of the semantic graph linking data …,*,2006,6
PrivCheck: privacy-preserving check-in data publishing for personalized location based services,Dingqi Yang; Daqing Zhang; Bingqing Qu; Philippe Cudré-Mauroux,Abstract With the widespread adoption of smartphones; we have observed an increasingpopularity of Location-Based Services (LBSs) in the past decade. To improve userexperience; LBSs often provide personalized recommendations to users by mining theiractivity (ie; check-in) data from location-based social networks. However; releasing usercheck-in data makes users vulnerable to inference attacks; as private data (eg; gender) canoften be inferred from the users' check-in data. In this paper; we propose PrivCheck; acustomizable and continuous privacy-preserving check-in data publishing frameworkproviding users with continuous privacy protection against inference attacks. The key idea ofPrivCheck is to obfuscate user check-in data such that the privacy leakage of user-specifiedprivate data is minimized under a given data distortion budget; which ensures the utility of …,Proceedings of the 2016 ACM International Joint Conference on Pervasive and Ubiquitous Computing,2016,5
A demonstration of tripleprov: tracking and querying provenance over web data,Marcin Wylot; Philippe Cudré-Mauroux; Paul Groth,Abstract The proliferation of heterogeneous Linked Data on the Web poses new challengesto database systems. In particular; the capacity to store; track; and query provenance data isbecoming a pivotal feature of modern triple stores. In this demonstration; we presentTripleProv: a new system extending a native RDF store to efficiently handle the storage;tracking and querying of provenance in RDF data. In the following; we give an overview ofour approach providing a reliable and understandable specification of the way results werederived from the data and how particular pieces of data were combined to answer the query.Subsequently; we present techniques enabling to tailor queries with provenance data.Finally; we describe our demonstration and how the attendees will be able to interact withour system during the conference.,Proceedings of the VLDB Endowment,2015,5
Fixing the Domain and Range of Properties in Linked Data by Context Disambiguation.,Alberto Tonon; Michele Catasta; Gianluca Demartini; Philippe Cudré-Mauroux,ABSTRACT The amount of Linked Open Data available on the Web is rapidly growing. Thequality of the provided data; however; is generally-speaking not fundamentally improving;hampering its wide-scale deployment for many real-world applications. A key data qualityaspect for Linked Open Data can be expressed in terms of its adherence to an underlyingwelldefined schema or ontology; which serves both as a documentation for the end-users aswell as a fixed reference for automated processing over the data. In this paper; we first reporton an analysis of the schema adherence of domains and ranges for Linked Open Data. Wethen propose new techniques to improve the correctness of domains and ranges by i)identifying the cases in which a property is used in the data with several different semantics;and ii) resolving them by updating the underlying schema and/or by modifying the data …,LDOW@ WWW,2015,5
Hippocampus: answering memory queries using transactive search,Michele Catasta; Alberto Tonon; Djellel Eddine Difallah; Gianluca Demartini; Karl Aberer; Philippe Cudre-Mauroux,Abstract Memory queries denote queries where the user is trying to recall from his/her pastpersonal experiences. Neither Web search nor structured queries can effectively answer thistype of queries; even when supported by Human Computation solutions. In this paper; wepropose a new approach to answer memory queries that we call Transactive Search: Theuser-requested memory is reconstructed from a group of people by exchanging pieces ofpersonal memories in order to reassemble the overall memory; which is stored in adistributed fashion among members of the group. We experimentally compare our proposedapproach against a set of advanced search techniques including the use of MachineLearning methods over the Web of Data; online Social Networks; and Human Computationtechniques. Experimental results show that Transactive Search significantly outperforms …,Proceedings of the 23rd International Conference on World Wide Web,2014,4
The Semantic Web-ISWC 2012-11th International Semantic Web Conference; Boston; MA; USA; November 11-15; 2012,P Cudré-Mauroux; J Heflin; E Sirin; T Tudorache; J Euzenat; M Hauswirth; JX Parreira; J Hendler; G Schreiber; A Bernstein; E Blomqvist,*,Proceedings,2012,4
A Demonstration of DNS3: a Semantic-Aware DNS Service,Philippe Cudré-Mauroux; Gianluca Demartini; Djellel Eddine Difallah; Ahmed Elsayed Mostafa; Vincenzo Russo; Matthew Thomas,Abstract The Domain Name System (DNS) is a hierarchical and distributed database used toresolve domain names into IP addresses. The current Web infrastructure heavily relies onthe DNS service to allow endusers to access Web pages and Web data using meaningfulnames (like “www. verisign. com”) rather than cryptic sequences of numbers (eg;“69.58.181.89”). The main functionalities of the DNS have been specified more than 25 years agoand have not fundamentally evolved since then. In this paper; we propose to demonstrateDNS3; an extension of the current DNS service based on security mechanisms andsemantic metadata. Specifically; we show how one can embed authoritative RDF triplesusing the current DNS protocol; and how the naming service can take advantage of theembedded semantic metadata to publish authoritative information about the domains; to …,*,2011,4
Demonstration of the trajstore system,Eugene Wu; Philippe Cudre-Mauroux; Samuel Madden,Abstract The proliferation of GPS devices has led to a substantial interest in location basedservices. In particular; modern vehicles can generate an incredible amount of drive data.However; current storage systems are not optimized for storing and querying such largespatial-temporal data sets. In this demonstration; we show the performance of the TrajStoresystem; a dynamic storage system optimized for quickly accessing data in a particular spatial-temporal region. In particular; TrajStore uses a novel adaptive indexing technique thatdynamically adjusts itself to co-locate spatially close trajectories on disk; as well as anumber of compression techniques in the storage layer that significantly reduce access timefor a given index cell. In this demonstration; we will store a set of real world taxi cab drivetraces in TrajStore; and users will be able to query the data through a map based …,Proceedings of the VLDB Endowment,2009,4
Sentry pallets for automated monitoring of spatial constraints: Models and initial experiments,Philippe Cudré-Mauroux; Menasheh Fogel; Ken Goldberg; M Franklin,Abstract—Warehouses must maintain a number of spatial constraints concerning the safehandling of hazardous materials. In this paper; we address the problem of automatedmonitoring of spatial constraints as pallets are moved on forklifts by human operators. Wepropose using small; self-contained localizing sensor packages mounted on pallets. Weconsider two architectures: 1) a global architecture where sensors are mounted on palletsand on the warehouse ceiling; and 2) a local architecture where sensors are located only onthe pallets. We formally model the problem for a warehouse environment where sensors canbe installed on the pallets or on the ceiling. We also report on preliminary experimentalresults on the accuracy of constraint violation detection as a function of inter-sensor distanceand angle.,IEEE International Conference on Robotics and Automation (ICRA’06); Orlando; Florida; USA,2006,4
Multiagent system technologies,Torsten Eymann; Michael N Huhns,*,*,2005,4
ArmaTweet: Detecting Events by Semantic Tweet Analysis,Alberto Tonon; Philippe Cudré-Mauroux; Albert Blarer; Vincent Lenders; Boris Motik,Abstract Armasuisse Science and Technology; the R&D agency for the Swiss Armed Forces;is developing a Social Media Analysis (SMA) system to help detect events such as naturaldisasters and terrorist activity by analysing Twitter posts. The system currently supports onlykeyword search; which cannot identify complex events such as 'politician dying'or 'militiaterror act'since the keywords that correctly identify such events are typically unknown. In thispaper we present ArmaTweet; an extension of SMA developed in a collaboration betweenarmasuisse and the Universities of Fribourg and Oxford that supports semantic eventdetection. Our system extracts a structured representation from the tweets' text using NLPtechnology; which it then integrates with DBpedia and WordNet in an RDF knowledgegraph. Security analysts can thus describe the events of interest precisely and …,European Semantic Web Conference,2017,3
A comparison of data structures to manage URIs on the web of data,Ruslan Mavlyutov; Marcin Wylot; Philippe Cudre-Mauroux,Abstract Uniform Resource Identifiers (URIs) are one of the corner stones of the Web; Theyare also exceedingly important on the Web of data; since RDF graphs and Linked Data bothheavily rely on URIs to uniquely identify and connect entities. Due to their hierarchicalstructure and their string serialization; sets of related URIs typically contain a high degree ofredundant information and are systematically dictionary-compressed or encoded at the back-end (eg; in the triple store). The paper represents; to the best of our knowledge; the firstsystematic comparison of the most common data structures used to encode URI data. Weevaluate a series of data structures in term of their read/write performance and memoryconsumption.,European Semantic Web Conference,2015,3
TRISTAN: Real-time analytics on massive time series using sparse dictionary compression,Alice Marascu; Pascal Pompey; Eric Bouillet; Michael Wurst; Olivier Verscheure; Martin Grund; Philippe Cudre-Mauroux,Large-scale critical infrastructures such as transportation; energy; or water distributionnetworks are increasingly equipped with smart sensor technologies. Low-latency analyticson the resulting times series would open the door to many exciting opportunities to improveour grasp on complex urban systems. However; sensor-generated time series often turn outto be noisy; non-uniformly sampled; and misaligned in practice; making them ill-suited fortraditional data processing. In this paper; we introduce TRISTAN (massive TRIckletS Timeseries ANalysis); a new data management system for efficient storage and real-timeprocessing of fine-grained time series data. TRISTAN relies on a dedicated; compressedsparse representation of the time series using a dictionary. In contrast to previousapproaches; TRISTAN is able to execute most analytics queries on the compressed data …,Big Data (Big Data); 2014 IEEE International Conference on,2014,3
The entity registry system: Publishing and consuming linked data in poorly connected environments,Christophe Guéret; Philippe Cudré-Mauroux,Sixty-five percent of the world's population is deprived of ICT-enhanced data-sharingbecause of poor access to digital technology. The ExaScale Infolab and Data Archiving andNetworked Services (DANS) have designed a new framework; the" Entity RegistrySystem"(ERS); and produced a reference implementation making it possible to publish andconsume Linked Open Data in poorly connected environments.,ERCIM News,2014,3
Transactions on Large-Scale Data-and Knowledge-Centered Systems VIII: Special Issue on Advances in Data Warehousing and Knowledge Discovery,Abdelkader Hameurlain; Josef Küng; Roland Wagner; Alfredo Cuzzocrea; Umeshwar Dayal,Data warehousing and knowledge discovery is an extremely active research area where anumber of methodologies and paradigms converge; with coverage of both theoretical issuesand practical solutions. The area of data warehousing and knowledge discovery has beenwidely accepted as a key technology for enterprises and organizations; as it allows them toimprove their abilities in data analysis; decision support; and the automatic extraction ofknowledge from data. With the exponentially growing amount of information to be includedin the decision-making process; the data to be considered are becoming more and morecomplex in both structure and semantics. As a consequence; novel developments; both atthe methodological level; eg; complex analytics over data; and at the infrastructural level; eg;cloud computing architectures; are necessary. Orthogonal to the latter aspects; the …,*,2013,3
An integrated socio-technical crowdsourcing platform for accelerating returns in escience,Karl Aberer; Alexey Boyarsky; Philippe Cudré-Mauroux; Gianluca Demartini; Oleg Ruchayskiy,Page 1. An Integrated Socio-Technical Crowdsourcing Platform for Accelerating Returns ineScience Karl Aberer; Alexey Boyarsky; Philippe Cudré-Maurox; Gianluca Demartini; and OlegRuchayskiy Page 2. Science Yesterday Today Gifted Individuals Collaborative Effort Page 3.OPERA Collaboration Page 4. Scientist-Computer Symbiosis • A single scientist has no morethe capacity to process all the information – High complexity of systems and workflows – Variousfields of expertise involved • New discoveries will emerge from community- based socio-technicalsystems Page 5. Community-based Socio-technical Systems • Such platforms will be useful –Locally to the scientist – By extracting knowledge used globally • They will enable cross-pollination –All artifacts need to be interoperable – Higher order logic to combine them Page 6. ScienceTomorrow Collective Intelligence Page 7. What do we need …,ISWC (Outrageous Ideas Track),2011,3
Probabilistic information integration and retrieval in the Semantic Web,Livia Predoiu,Abstract The Semantic Web (SW) has been envisioned to enable software tools or WebServices; respectively; to process information provided on the Web automatically. For thispurpose; languages for representing the semantics of data by means of ontologies havebeen proposed such as RDF (S) and OWL. While the semantics of RDF (S) requires a non-standard model-theory that goes beyond first order logics; OWL is intended to model subsetsof first order logics. OWL consists of three variants that are layered on each other. The lessexpressive variants OWL-Light and OWL-DL correspond to the Description Logics SHIF (D)and SHOIN (D) 1; respectively; and thus to subsets of First Order Logics 2.,*,2007,3
Analyzing semantic interoperability in bioinformatic database networks,Philippe Cudré-Mauroux; Julien Gaugaz; Adriana Budura; Karl Aberer,Abstract. We consider the problem of analytically evaluating semantic interoperability inlarge-scale networks of schemas interconnected through pairwise schema mappings. Ourheuristics are based on a graphtheoretic framework capturing important statistical propertiesof the graphs. We validate our heuristics on a real collection of interconnected bioinformaticdatabases registered with the Sequence Retrieval System (SRS). Furthermore; we deriveand provide experimental evaluations of query propagation on weighted semantic networks;where weights model the quality of the various schema mappings in the network.,W8: Semantic Network Analysis,2005,3
On the convergence of structured search; information retrieval and trust management in distributed systems,Karl Aberer; Philippe Cudré-Mauroux; Zoran Despotovic,Abstract The database and information retrieval communities have long been recognized asbeing irreconcilable. Today; however; we witness a surprising convergence of thetechniques used by both communities in decentralized; large-scale environments. Thenewly emerging field of reputation based trust management; borrowing techniques from bothcommunities; best demonstrates this claim. We argue that incomplete knowledge andincreasing autonomy of the participating entities are the driving forces behind thisconvergence; pushing the adoption of probabilistic techniques typically borrowed from aninformation retrieval context. We argue that using a common probabilistic framework wouldbe an important step in furthering this convergence and enabling a common treatment andanalysis of distributed complex systems. We will provide a first sketch of such a framework …,German Conference on Multiagent System Technologies,2005,3
Special Section on Semantic Web and Data Management,R Meersman; A Sheth; P Spyns; M Jarrar; Y Sure; S Staab; R Studer; C Bussler; D Fensel; A Maedche; T Finin; A Joshi; EM Maximilien; M Singh; K Anyanwu; K Aberer; P Cudre-Mauroux; M Hauswirth; WI Grosky; DV Sreenath; F Fotouhi; David Buttler; Matthew Coleman; Terence Critchlow; Renato Fileto; Wei Han; Ling Liu; Calton Pu; Daniel Rocco; Li Xiong; C Goble; D De Rouce,*,ACM SIGMOD Record,2002,3
HistoSketch: Fast Similarity-Preserving Sketching of Streaming Histograms with Concept Drift,Dingqi Yang; Bin Li; Laura Rettig; Philippe Cudré-Mauroux,Abstract—Histogram-based similarity has been widely adopted in many machine learningtasks. However; measuring histogram similarity is a challenging task for streaming data;where the elements of a histogram are observed in a streaming manner. First; the ever-growing cardinality of histogram elements makes any similarity computation inefficient.Second; the concept-drift issue in the data streams also impairs the accurate assessment ofthe similarity. In this paper; we propose to overcome the above challenges with HistoSketch;a fast similarity-preserving sketching method for streaming histograms with concept drift.Specifically; HistoSketch is designed to incrementally maintain a set of compact and fixed-size sketches of streaming histograms to approximate similarity between the histograms;with the special consideration of gradually forgetting the outdated histogram elements …,Proceedings of the IEEE International Conference on Data Mining (ICDM’17),2017,2
Dependency-Driven Analytics: A Compass for Uncharted Data Oceans.,Ruslan Mavlyutov; Carlo Curino; Boris Asipov; Philippe Cudre-Mauroux,ABSTRACT In this paper; we predict the rise of Dependency-Driven Analytics (DDA); a newclass of data analytics designed to cope with growing volumes of unstructured data. DDAdrastically reduces the cognitive burden of data analysis by systematically leveraging acompact dependency graph derived from the raw data. The computational cost associatedwith the analysis is also reduced substantially; as the graph acts as an index for commonlyaccessed data items. We built a system supporting DDA using off-the-shelf Big Data andgraph DB technologies; and deployed it in production at Microsoft to support the analysis ofthe exhaust of our Big Data infrastructure producing petabytes of system logs daily. Thedependency graph in this setting captures lineage information among jobs and files and isused to guide the analysis of telemetry data. We qualitatively discuss the improvement …,CIDR,2017,2
Analyzing large-scale public campaigns on twitter,Julia Proskurnia; Ruslan Mavlyutov; Roman Prokofyev; Karl Aberer; Philippe Cudré-Mauroux,Abstract Social media has become an important instrument for running various types ofpublic campaigns and mobilizing people. Yet; the dynamics of public campaigns on socialnetworking platforms still remain largely unexplored. In this paper; we present an in-depthanalysis of over one hundred large-scale campaigns on social media platforms coveringmore than 6 years. In particular; we focus on campaigns related to climate change onTwitter; which promote online activism to encourage; educate; and motivate people to reactto the various issues raised by climate change. We propose a generic framework to identifyboth the type of a given campaign as well as the various actions undertaken throughout itslifespan: official meetings; physical actions; calls for action; publications on climate relatedresearch; etc. We study whether the type of a campaign is correlated to the actions …,International Conference on Social Informatics,2016,2
Voldemortkg: Mapping schema. org and web entities to linked open data,Alberto Tonon; Victor Felder; Djellel Eddine Difallah; Philippe Cudré-Mauroux,Abstract Increasingly; webpages mix entities coming from various sources and representedin different ways. It can thus happen that the same entity is both described by using schema.org annotations and by creating a text anchor pointing to its Wikipedia page. Often; thoserepresentations provide complementary information which is not exploited since thoseentities are disjoint. We explored the extent to which entities represented in different waysrepeat on the Web; how they are related; and how they complement (or link) to each other.Our initial experiments showed that we can unveil a previously unexploited knowledgegraph by applying simple instance matching techniques on a large collection of schema. organnotations and Wikipedia. The resulting knowledge graph aggregates entities (often tailentities) scattered across several webpages; and complements existing Wikipedia entities …,International Semantic Web Conference,2016,2
Please Sign to Save...: How Online Environmental Petitions Succeed.,Julia Proskurnia; Karl Aberer; Philippe Cudré-Mauroux,Abstract Social media have become one of the key platforms to support the debate onclimate change. In particular; Twitter allows easy information dissemination when runningenvironmental campaigns. Yet; the dynamics of these campaigns on social platforms stillremain largely unexplored. In this paper; we study the success factors enabling onlinepetitions to attain their required number of signatures. We present an analysis of e-petitionsand identify how their number of users; tweets and retweets correlate with their success. Inaddition; we show that environmental petitions are actively promoted by popular publiccampaigns on Twitter. Finally; we present an annotated corpus of petitions posted byenvironmental campaigns together with their corresponding tweets to enable furtherexploration.,EcoMo@ ICWSM,2016,2
Skalierbar Anomalien erkennen für Smart City Infrastrukturen,Djellel Eddine Difallah; Philippe Cudré-Mauroux; Sean A McKenna; Daniel Fasel,Zusammenfassung In diesem Kapitel wird ein Informationssystem beschrieben; welchesAnomalien in großen Netzwerken erkennen kann. Ein solches Netzwerk ist beispielsweisedas Wasserversorgungsnetz einer Stadt. Anhand eines Prototyps wird aufgezeigt; wiepotenzielle Anomalien dynamisch und in Echtzeit entdeckt werden können.,*,2016,2
Using lowly correlated time series to recover missing values in time series: a comparison between SVD and CD,Mourad Khayati; Michael H Böhlen; Philippe Cudré Mauroux,Abstract The Singular Value Decomposition (SVD) is a matrix decomposition technique thathas been successfully applied for the recovery of blocks of missing values in time series. Inorder to perform an accurate block recovery; SVD requires the use of highly correlated timeseries. However; using lowly correlated time series that exhibit shape and/or trendsimilarities could increase the recovery accuracy. Thus; the latter time series could also beexploited by including them in the recovery process. In this paper; we compare the accuracyof the Centroid Decomposition (CD) against SVD for the recovery of blocks of missing valuesusing highly and lowly correlated time series. We show that the CD technique better exploitsthe trend and shape similarity to lowly correlated time series and yields a better recoveryaccuracy. We run experiments on real world hydrological and synthetic time series to …,International Symposium on Spatial and Temporal Databases,2015,2
Correct Me If I'm Wrong: Fixing Grammatical Errors by Preposition Ranking,Roman Prokofyev; Ruslan Mavlyutov; Martin Grund; Gianluca Demartini; Philippe Cudré-Mauroux,Abstract The detection and correction of grammatical errors still represent very hardproblems for modern error-correction systems. As an example; the top-performing systems atthe preposition correction challenge CoNLL-2013 only achieved a F1 score of 17%. In thispaper; we propose and extensively evaluate a series of approaches for correctingprepositions; analyzing a large body of high-quality textual content to capture languageusage. Leveraging n-gram statistics; association measures; and machine learningtechniques; our system is able to learn which words or phrases govern the usage of aspecific preposition. Our approach makes heavy use of n-gram statistics generated from verylarge textual corpora. In particular; one of our key features is the use of n-gram associationmeasures (eg; Pointwise Mutual Information) between words and prepositions to …,Proceedings of the 23rd ACM International Conference on Conference on Information and Knowledge Management,2014,2
Crowdsourcing and the Semantic Web (Dagstuhl Seminar 14282),Abraham Bernstein; Jan Marco Leimeister; Natasha Noy; Cristina Sarasua; Elena Simperl,Abstract Semantic technologies provide flexible and scalable solutions to master and makesense of an increasingly vast and complex data landscape. However; while this potentialhas been acknowledged for various application scenarios and domains; and a number ofsuccess stories exist; it is equally clear that the development and deployment of semantictechnologies will always remain reliant of human input and intervention. This is due to thevery nature of some of the tasks associated with the semantic data management life cycle;which are famous for their knowledge-intensive and/or context-specific character; examplesrange from conceptual modeling in almost any flavor; to labeling resources (in differentlanguages); describing their content in terms of ontological terms; or recognizing similarconcepts and entities. For this reason; the Semantic Web community has always looked …,Dagstuhl Reports,2014,2
Hybrid graph and relational query processing in main memory,Martin Grund; Philippe Cudre-Mauroux; Jens Krueger; Hasso Plattner,Modern enterprise applications are a challenge for traditional database systems. In therecent years; enterprise workloads evolved from simple lookups and updates to complexqueries integrating both analytical and transactional data. In addition; graph structures andqueries today need to be integrated for applications like materials requirements planning;which add some further complexity to the workload. We hence observe new challenges forenterprise database systems: To improve the effectiveness of business processes; itbecomes necessary to semantically enrich business data with additional graph data.However; in order to achieve the best performance; we cannot store graph data in atraditional relational database management system. In this vision paper; we describe a newdatabase storage architecture that is able to work with multiple storage types like …,Data Engineering Workshops (ICDEW); 2013 IEEE 29th International Conference on,2013,2
A Demonstration of HYRISE—A Main Memory Hybrid Storage Engine,Martin Grund; Philippe Cudre-Mauroux; Samuel Madden,ABSTRACT We propose to demonstrate HYRISE; a main memory hybrid database system;which automatically partitions tables into vertical partitions consisting of variable numbers ofcolumns based on access patterns to each table. Using an accurate model of cache misses;HYRISE is able to predict the performance of different partitionings; and to automaticallyselect the best partitions using an automated database partitioning algorithm. Ourdemonstration will show the results of the physical partitioning based on different queryworkloads; allowing demo attendees to visualize; fine-tune; and modify the partitioning usinga GUI. It will then show how the various physical designs affect the query plans and theperformance of the database as a whole. Attendees can thus experiment with variousphysical models; and can grasp the potential of hybrid partitionings; which achieve a 20 …,Proceedings of the VLDB Endowment,2011,2
Peer data management system,Philippe Cudre-Mauroux,P/FDM [5–7] integrated a functional data model with the logic programming language Prologfor general-purpose computation. The data model can be seen as an Entity-Relationshipdiagram with sub-types; much like a UML Class Diagram. The idea was for the user to beable to define a computation over objects in the diagram; instead of just using it as a schemadesign aid. Later versions of P/FDM included a graphic interface [2; 4] to build queries inDAPLEX syntax by clicking on the diagram and filling in values from menus.,*,2009,2
Emergent semantics,Philippe Cudré-Mauroux,In the past; the problem of semantic interoperability in information systems was mostlysolved by means of centralization; both at a system and at a logical level. This approach hasbeen successful to a certain extent; but offers limited scalability and flexibility. Peer-to-Peersystems as a new brand of system architectures indicate that the principles ofdecentralization and self-organization might offer new solutions to many problems that scalewell to very large numbers of users; or to systems where central authorities do not prevail.Therefore; we suggest a new way of building global agreements; ie; semanticinteroperability; based on decentralized; self-organizing interactions only. In the first part ofthis thesis; we discuss traditional data integration techniques relying on global schemas;perfect schema mappings and contained query rewritings. We elaborate on the current …,*,2007,2
Storing; tracking; and querying provenance in linked data,Marcin Wylot; Philippe Cudré-Mauroux; Manfred Hauswirth; Paul Groth,The proliferation of heterogeneous Linked Data on the Web poses new challenges todatabase systems. In particular; the capacity to store; track; and query provenance data isbecoming a pivotal feature of modern triplestores. We present methods extending a nativeRDF store to efficiently handle the storage; tracking; and querying of provenance in RDFdata. We describe a reliable and understandable specification of the way results werederived from the data and how particular pieces of data were combined to answer a query.Subsequently; we present techniques to tailor queries with provenance data. We empiricallyevaluate the presented methods and show that the overhead of storing and trackingprovenance is acceptable. Finally; we show that tailoring a query with provenanceinformation can also significantly improve the performance of query execution.,IEEE Transactions on Knowledge and Data Engineering,2017,1
Linked Data Management,Manfred Hauswirth; Marcin Wylot; Martin Grund; Paul Groth; Philippe Cudré-Mauroux,Abstract The size of Linked Data is growing exponentially; thus a Linked Data managementsystem has to be able to deal with increasing amounts of data. Additionally; in the LinkedData context; variety is especially important. In spite of its seemingly simple data model;Linked Data actually encodes rich and complex graphs mixing both instance and schema-level data. Since Linked Data is schema-free (ie; the schema is not strict); standarddatabases techniques cannot be directly adopted to manage it. Even though organizingLinked Data in a form of a table is possible; querying a giant triple table becomes very costlydue to the multiple nested joins required typical queries. The heterogeneity of Linked Dataposes also entirely new challenges to database systems; where managing provenanceinformation is becoming a requirement. Linked Data queries usually include multiple …,*,2017,1
CINTIA: A distributed; low-latency index for big interval data,Ruslan Mavlyutov; Philippe Cudre-Mauroux,Intervals have become prominent in data management as they are the main data structure torepresent a number of key data types such as temporal or genomic data. Yet; there exists nosolution to compactly store and efficiently query big interval data. In this paper we introduceCINTIA-the Checkpoint INTerval Index Array-an efficient data structure to store and queryinterval data; which achieves high memory locality and outperforms state-of-the art solutions.We also propose a low-latency; Big Data system that implements CINTIA on top of a populardistributed file system and efficiently manages large interval data on clusters of commoditymachines. Our system can easily be scaled-out and was designed to accommodate largedelays between the various components of a distributed infrastructure. We experimentallyevaluate the performance of our approach on several datasets and show that it …,Big Data (Big Data); 2015 IEEE International Conference on,2015,1
The Semantic Web. Latest Advances and New Domains: 12th European Semantic Web Conference; ESWC 2015; Portoroz; Slovenia; May 31--June 4; 2015. Procee...,Fabien Gandon; Marta Sabou; Harald Sack; Claudia d’Amato; Philippe Cudré-Mauroux; Antoine Zimmermann,This book constitutes the refereed proceedings of the 12th Extended Semantic WebConference; ESWC 2014; held in Anissaras; Portoroz; Slovenia; in May/June 2015. The 43revised full papers presented together with three invited talks were carefully reviewed andselected from 164 submissions. This program was completed by a demonstration and postersession; in which researchers had the chance to present their latest results and advances inthe form of live demos. In addition; the PhD Symposium program included 12 contributions;selected out of 16 submissions. The core tracks of the research conference werecomplemented with new tracks focusing on linking machine and human computation at webscale (cognition and Semantic Web; Human Computation and Crowdsourcing) beside thefollowing subjects Vocabularies; Schemas; Ontologies; Reasoning; Linked Data …,*,2015,1
A low-latency; big database system and browser for storage; querying and visualization of 3D genomic data,Alexander Butyaev; Ruslan Mavlyutov; Mathieu Blanchette; Philippe Cudré-Mauroux; Jérôme Waldispühl,Abstract Recent releases of genome three-dimensional (3D) structures have the potential totransform our understanding of genomes. Nonetheless; the storage technology andvisualization tools need to evolve to offer to the scientific community fast and convenientaccess to these data. We introduce simultaneously a database system to store and query 3Dgenomic data (3DBG); and a 3D genome browser to visualize and explore 3D genomestructures (3DGB). We benchmark 3DBG against state-of-the-art systems and demonstratethat it is faster than previous solutions; and importantly gracefully scales with the size of data.We also illustrate the usefulness of our 3D genome Web browser to explore human genomestructures. The 3D genome browser is available at http://3dgb. cs. mcgill. ca/.,Nucleic acids research,2015,1
The Entity Registry System: Collaborative Editing of Entity Data in Poorly Connected Environments,Christophe Guéret; Philippe Cudré-Mauroux,Abstract There are about 4.5 billion people in the world who have no or limited Internetaccess. Those are deprived from using entitydriven applications that assume datarepositories and entity resolution services are always available. In this paper; we discuss theneed for a new architecture for entity registries. We propose and evaluate a new general-purpose Entity Registry System (ERS) supporting collaborative editing and deployment inpoorly-connected or ad-hoc environments. The reference open-source implementation isevaluated for scalability and data-sharing capabilities.,AAAI Spring Symposium,2015,1
B-hist: Entity-centric search over personal web browsing history,Michele Catasta; Alberto Tonon; Gianluca Demartini; Jean-Eudes Ranvier; Karl Aberer; Philippe Cudré-Mauroux,Abstract Web Search is increasingly entity centric; as a large fraction of common queriestarget specific entities; search results get progressively augmented with semi-structured andmultimedia information about those entities. However; search over personal web browsinghistory still revolves around keyword-search mostly. In this paper; we present a novelapproach to answer queries over web browsing logs that takes into account entitiesappearing in the web pages; user activities; as well as temporal information. Our system; B-hist; aims at providing web users with an effective tool for searching and accessinginformation they previously looked up on the web by supporting multiple ways of filteringresults using clustering and entity-centric search. In the following; we present our systemand motivate our User Interface (UI) design choices by detailing the results of a survey on …,Web Semantics: Science; Services and Agents on the World Wide Web,2014,1
TransactiveDB: tapping into collective human memories,Michele Catasta; Alberto Tonon; Djellel Eddine Difallah; Gianluca Demartini; Karl Aberer; Philippe Cudre-Mauroux,Abstract Database Management Systems (DBMSs) have been rapidly evolving in the recentyears; exploring ways to store multi-structured data or to involve human processes duringquery execution. In this paper; we outline a future avenue for DBMSs supporting transactivememory queries that can only be answered by a collection of individuals connected througha given interaction graph. We present TransactiveDB and its ecosystem; which allow usersto pose queries in order to reconstruct collective human memories. We describe a set of newtransactive operators including TUnion; TFill; TJoin; and TProjection. We also describe howTransactiveDB leverages transactive operators---by mixing query execution; social networkanalysis and human computation---in order to effectively and efficiently tap into thememories of all targeted users.,Proceedings of the VLDB Endowment,2014,1
Loose ontological coupling and the Social Semantic Web,Philippe Cudré-Mauroux,Abstract Best practices for the publication of Semantic Web data currently place anunacceptably high burden on the end-user; who is supposed to locate and embrace third-party; ontological structures prior to publishing any information. This paper argues for adifferent publication paradigm where end-users are encouraged to publish potentiallyincomplete or conflicting information according to their own local context; and whereheterogeneous data is consolidated a posteriori through bottom–up; decentralizedprocesses. This approach has two key advantages: first; it greatly simplifies the publicationof semantic information by allowing users to contribute purely local data; without anyconsideration for global schemas or third-party structures. Second; it takes advantage ofexpressive; semantic links to relate both schemas and instances; creating complex webs …,Journal of Ambient Intelligence and Humanized Computing,2013,1
A comparison of different data structures to store RDF data,Rashmi Bakshi; Philippe Cudre-Mauroux; Marcin Wylot,Abstract Main focus of my work was to compare data structures based on memory consumedby them during insertion and retrieval of elements (URIs). They were also compared on thebasis of CPU time taken to insert and retrieve data. Hash Functions were compared on thebasis of number of collisions they produced. ie generating same key for different URIs. Theirinfluence on CPU time consumed by the data structure was also considered for comparison.,*,2013,1
Demonstrating the entity registry system: implementing 5-star linked data without the web,Marat Charlaganov; Philippe Cudré-Mauroux; Christophe Guéret; Martin Grund; Teodor Macicas,Abstract. Linked Data applications often assume that connectivity to data repositories andentity resolution services are always available. This may not be a valid assumption in manycases. Indeed; there are about 4.5 billion people in the world who have no or limited Webaccess. Many data-driven applications may have a critical impact on the life of those people;but are inaccessible to such populations due to the architecture of today's data registries. Inthis demonstration; we show how our new open-source ERS system can be used as ageneral-purpose entity registry suitable for deployment in poorly-connected or ad-hocenvironments.,Proceedings of ISWC2013,2013,1
Will Graph Data Management Techniques Contribute to the Successful Large-Scale Deployment of Semantic Web Technologies?,Philippe Cudre-Mauroux,The Semantic Web vision ambitions to create a large-scale; interconnected Web of machine-processable data in addition to the current Web of documents currently available online. Itsmost recent and visible incarnation-the Linked Data movement1-is based on three mainprinciples: using dereferenceable Web identifiers (HTTP URIs) to uniquely identify thevarious pieces of data online; providing semi-structured information-most often usingstandard formats like RDF [1] and OWL [2]-about the data when dereferencing thecorresponding URIs; providing links to other; semantically related pieces of data.,Data Engineering Workshops (ICDEW); 2012 IEEE 28th International Conference on,2012,1
Downscaling Entity Registries for Ad-Hoc Environments,Philippe Cudré-Mauroux; Gianluca Demartini; Christophe Guéret; Benoit Perroud,Abstract. Web of Objects and Linked Data applications often assume that connectivity to datarepositories and entity resolution services are always available. This may not be a validassumption in many cases. Indeed; there are about 4.5 billion people in the world who haveno or limited Web access. Many data-driven applications may have a critical impact on thelife of those people; but are inaccessible to those populations due to the architecture oftoday's data registries. In this paper; we point out the limitations of current entity registrieswhen deployed in poorly connected or ad-hoc environments. We then sketch newarchitectures based on IPV6; structured P2P networks and data replication for entityregistries that could run in ad-hoc environments with limited Internet connectivity.,DownScaling the Semantic Web (DownScale2012),2012,1
Message Passing in Semantic Peer-to-Peer Overlay Networks [Exploratory DSP],Philippe Cudré-Mauroux; Karl Aberer,In this column; we discuss exploratory research related to data management in P2P overlaynetworks. First; we discuss the notions of unstructured and structured P2P overlay networks.Then; we discuss data management in such networks by introducing an additional layer tohandle semantic heterogeneity and data integration. Finally; we present a method based onsum-product message passing to detect inconsistent information in this setting.,IEEE Signal Processing Magazine,2007,1
2.2. Belief Propagation on Uncertain Schema Mappings in Peer Data Management Systems,Philippe Cudré-Mauroux; Karl Aberer,Abstract. Until recently; most data integration techniques involved central components; eg;global schemas; to enable transparent access to heterogeneous databases. Today;however; with the democratization of tools facilitating knowledge elicitation in machine-processable formats; one cannot rely on global; centralized schemas anymore asknowledge creation and consumption are getting more and more dynamic anddecentralized. Peer Data Management Systems (PDMS) provide an answer to this problemby eliminating the central semantic component and considering instead compositions oflocal; pair-wise mappings to propagate queries from one database to the others. In thefollowing; we give an overview of various PDMS approaches; all the approaches proposedso far make the implicit assumption that all schema mappings used to reformulate a query …,EMERGING COMMUNICATION,2006,1
Semantic Gossiping: Coping with Heterogeneous Semantic Knowledge Management Systems in the Large,Karl Aberer; Philippe Cudré-Mauroux,With the creation and wide adoption of Semantic Web standards like RDF or OWL; a newbreed of semantic networks is about to appear. For the first time; we can expect largenumbers of knowledge management systems to interoperate using common languages toexpress the semantics of the data they share or seek. We however foresee semanticheterogeneity to surface once more as a key problem in information integration; given thescale and variety of the systems we are dealing with: Indeed; we realistically cannot expectcommon global upper-ontologies to capture with sufficient adequacy the requirements of allthe different parties in our heterogeneous environment. Custom ontologies will bedeveloped for various application needs; thus endangering global semantic interoperabilityby introducing local concepts and properties. Also; the situation is somewhat complicated …,SIGSEMIS Bulletin,2004,1
A data-driven approach to predict NOx-emissions of gas turbines,Giuseppe Cuccu; Somayeh Danafar; Philippe Cudré-Mauroux; Martin Gassner; Stefano Bernero; Krzysztof Kryszczuk,Predicting the state of modern heavy-duty gas turbines for large-scale power generationallows for making informed decisions on their operation and maintenance. Their emissionbehavior however is coupled to a multitude of operating parameters and to the state andaging of the engine; making the underlying mechanisms very complex to model throughphysical; first-order approaches. In this paper; we demonstrate that accurate emissionmodels of gas turbines can be derived using machine learning techniques. We presentempirical results on a broad range of machine learning algorithms applied to historical datacollected from long-term engine operation. A custom data-cleaning pipeline is presented toconsiderably boost performance. Our best results match the measurement precision of theemission monitoring system; accurately describing the evolution of the engine state and …,Big Data (Big Data); 2017 IEEE International Conference on,2017,*
The Semantic Web–ISWC 2017: 16th International Semantic Web Conference; Vienna; Austria; October 21–25; 2017; Proceedings,Claudia d'Amato; Miriam Fernandez; Valentina Tamma; Freddy Lecue; Philippe Cudré-Mauroux; Juan Sequeda; Christoph Lange; Jeff Heflin,The two-volume set LNCS 10587+ 10588 constitutes the refereed proceedings of the 16thInternational Semantic Web Conference; ISWC 2017; held in Vienna; Austria; in October2017. ISWC 2017 is the premier international forum; for the Semantic Web/Linked DataCommunity. The total of 55 full and 21 short papers presented in this volume were carefullyreviewed and selected from 300 submissions. They are organized according to the tracksthat were held: Research Track; Resource Track; and In-Use Track.,*,2017,*
Efficient Document Filtering Using Vector Space Topic Expansion and Pattern-Mining: The Case of Event Detection in Microposts,Julia Proskurnia; Ruslan Mavlyutov; Carlos Castillo; Karl Aberer; Philippe Cudré-Mauroux,Abstract Automatically extracting information from social media is challenging given thatsocial content is often noisy; ambiguous; and inconsistent. However; as many stories breakon social channels first before being picked up by mainstream media; developing methodsto better handle social content is of utmost importance. In this paper; we propose a robustand effective approach to automatically identify microposts related to a specific topic definedby a small sample of reference documents. Our framework extracts clusters of semanticallysimilar microposts that overlap with the reference documents; by extracting combinations ofkey features that define those clusters through frequent pattern mining. This allows us toconstruct compact and interpretable representations of the topic; dramatically decreasing thecomputational burden compared to classical clustering and k-NN-based machine …,Proceedings of the 2017 ACM on Conference on Information and Knowledge Management,2017,*
SwissLink: High-Precision; Context-Free Entity Linking Exploiting Unambiguous Labels,Roman Prokofyev; Michael Luggen; Djellel Eddine Difallah; Philippe Cudré-Mauroux,ABSTRACT Webpages are an abundant source of textual information with manuallyannotated entity links; and are often used as a source of training data for a wide variety ofmachine learning NLP tasks. However; manual annotations such as those found onWikipedia are sparse; noisy; and biased towards popular entities. Existing entity linkingsystems deal with those issues by relying on simple statistics extracted from the data. Whilesuch statistics can effectively deal with noisy annotations; they introduce bias towards headentities and are ineffective for long tail (eg; unpopular) entities. In this work; we first analyzestatistical properties linked to manual annotations by studying a large annotated corpuscomposed of all English Wikipedia webpages; in addition to all pages from theCommonCrawl containing English Wikipedia annotations. We then propose and evaluate …,Proceedings of the 13th International Conference on Semantic Systems,2017,*
Big Data Integration,Philippe Cudré-Mauroux,Until recently; structured (eg; relational) and unstructured (eg; textual) data were managedvery differently: Structured data was queried declaratively using languages such as SQL;while unstructured data was searched using boolean queries over inverted indices. Today;we witness the rapid emergence of Big Data Integration techniques leveraging knowledgegraphs to bridge the gap between different types of contents and integrate both unstructuredand structured information more effectively. I will start this talk by giving a few examples ofBig Data Integration. I will then describe two recent systems built in my lab and leveragingsuch techniques: ZenCrowd; a socio-technical platform that automatically connects Webdocuments to semi-structured entities in a knowledge graph; and Guider; a Big DataIntegration system for the cloud.,Telecommunications (ConTEL); 2017 14th International Conference on,2017,*
Keynote: Big Data Integration for eGovernment,Philippe Cudré-Mauroux,Summary form only given: eGovernment data is typically very rich; mixing many differentkinds of content ranging from relational data to unstructured text. The complexity ofintegrating those various kinds of data is in my opinion one of the main hurdles slowingdown eGovernment endeavours. In this talk; I will advocate Big Data Integration techniquesto solve this issue. I will start this talk by giving an overview of Big Data Integrationtechniques. I will then describe two recent systems built in my lab and leveraging suchtechniques: Zen-Crowd; a socio-technical platform that automatically connects Webdocuments to semi-structured entities in a knowledge graph; and Guider; a Big DataIntegration system for the cloud.,eDemocracy & eGovernment (ICEDEG); 2017 Fourth International Conference on,2017,*
Managing Big Interval Data with CINTIA: the Checkpoint INTerval Array,Ruslan Mavlyutov; Philippe Cudre-Mauroux,Intervals have become prominent in data management as they are the main data structure torepresent a number of key data types such as temporal or genomic data. Yet; there exists nosolution to compactly store and efficiently query big interval data. In this paper we introduceCINTIA—the Checkpoint INTerval Index Array—an efficient data structure to store and queryinterval data; which achieves high memory locality and outperforms state-of-the art solutions.We also propose a low-latency; Big Data system that implements CINTIA on top of a populardistributed file system and efficiently manages large interval data on clusters of commoditymachines. Our system can easily be scaled-out and was designed to accommodate largedelays between the various components of a distributed infrastructure. We experimentallyevaluate the performance of our approach on several datasets and show that it …,IEEE Transactions on Big Data,2017,*
Predicting the Success of Online Petitions Leveraging Multidimensional Time-Series,Julia Proskurnia; Przemyslaw Grabowicz; Ryota Kobayashi; Carlos Castillo; Philippe Cudré-Mauroux; Karl Aberer,Abstract Applying classical time-series analysis techniques to online content is challenging;as web data tends to have data quality issues and is often incomplete; noisy; or poorlyaligned. In this paper; we tackle the problem of predicting the evolution of a time series ofuser activity on the web in a manner that is both accurate and interpretable; using relatedtime series to produce a more accurate prediction. We test our methods in the context ofpredicting signatures for online petitions using data from thousands of petitions posted onThe Petition Site-one of the largest platforms of its kind. We observe that the success ofthese petitions is driven by a number of factors; including promotion through social mediachannels and on the front page of the petitions platform. We propose an interpretable modelthat incorporates seasonality; aging effects; self-excitation; and external effects. The …,Proceedings of the 26th International Conference on World Wide Web,2017,*
CrimeTelescope: crime hotspot prediction based on urban and social media data fusion,Dingqi Yang; Terence Heaney; Alberto Tonon; Leye Wang; Philippe Cudré-Mauroux,Abstract Crime is a complex social issue impacting a considerable number of individualswithin a society. Preventing and reducing crime is a top priority in many countries. Givenlimited policing and crime reduction resources; it is often crucial to identify effectivestrategies to deploy the available resources. Towards this goal; crime hotspot prediction haspreviously been suggested. Crime hotspot prediction leverages past data in order to identifygeographical areas susceptible of hosting crimes in the future. However; most of the existingtechniques in crime hotspot prediction solely use historical crime records to identify crimehotspots; while ignoring the predictive power of other data such as urban or social mediadata. In this paper; we propose CrimeTelescope; a platform that predicts and visualizescrime hotspots based on a fusion of different data types. Our platform continuously …,World Wide Web,2017,*
ScienceWISE: Topic Modeling over Scientific Literature Networks,Andrea Martini; Artem Lutov; Valerio Gemmetto; Andrii Magalich; Alessio Cardillo; Alex Constantin; Vasyl Palchykov; Mourad Khayati; Philippe Cudré-Mauroux; Alexey Boyarsky; Oleg Ruchayskiy; Diego Garlaschelli; Paolo De Los Rios; Karl Aberer,Abstract: We provide an up-to-date view on the knowledge management systemScienceWISE (SW) and address issues related to the automatic assignment of articles toresearch topics. So far; SW has been proven to be an effective platform for managing largevolumes of technical articles by means of ontological concept-based browsing. However; asthe publication of research articles accelerates; the expressivity and the richness of the SWontology turns into a double-edged sword: a more fine-grained characterization of articles ispossible; but at the cost of introducing more spurious relations among them. In this context;the challenge of continuously recommending relevant articles to users lies in tackling anetwork partitioning problem; where nodes represent articles and co-occurring conceptscreate edges between them. In this paper; we discuss the three research directions we …,arXiv preprint arXiv:1612.07636,2016,*
Web Engineering: 16th International Conference; ICWE 2016; Lugano; Switzerland; June 6-9; 2016. Proceedings,Alessandro Bozzon; Philippe Cudré-Mauroux; Cesare Pautasso,This book constitutes the refereed proceedings of the 16th International Conference on WebEngineering; ICWE 2016; held in Lugano; Switzerland; in June 2016. The 19 full researchpapers; 13 short papers; 3 vision papers; 11 demonstrations; 5 posters; 6 PhD Symposiumand 4 tutorials presented were carefully reviewed and selected from 120 submissions. The16th edition of ICWE accepted contributions related to different research areas revolvingaround Web engineering; including: Web application modelling and engineering; Humancomputation and crowdsourcing; Web applications composition and mashups; SocialWebapplications; SemanticWeb; and; for the first time; also the Web of Things.,*,2016,*
LinkedPolitics: Incremental Semantic Lifting of Political Facts,Julien Tscherrig; Elena Mugellini; Omar Abou Khaled; Philippe Cudré-Mauroux,Exploiting facts that are published online using semi-structured or unstructured formats is ahighly complex task; pieces of data are typically published in isolation and periodicallyupdated in a bulk fashion without any coordination. In this paper; we propose a newsoftware pipeline tackling this issue and semantically lifting online facts as Linked Data in acontinuous manner. Our solution; LinkedPolitics; extracts; converts; interlinks; and finallymakes available as Linked Data online facts that could not be transparently exposed andexploited otherwise. Our system is online; in the sense that it automatically makes availablenew facts as they are uploaded online. We also present a deployment of LinkedPoliticscentered around the Swiss Parliament. Our deployment extracts and semantically lifts aflurry of political facts that are periodically published in unstructured form by the Library …,Advanced Information Networking and Applications (AINA); 2016 IEEE 30th International Conference on,2016,*
Master Thesis: Implemetation of Centroid Decomposition Algorithm on Big Data Platforms—Apache Spark vs. Apache Flink,Qian Liu; Mourad Khayati; Philippe Cudré-Mauroux,Abstract The Centroid Decomposition (CD) algorithm is the approximation of the SingularValue Decomposition (SVD) algorithm; which is one of the most used matrix decompositiontechniques to deal with real world data analysis tasks. CD algorithm is based on a greedyalgorithm; termed the Scalable Sign Vector (SSV); that efficiently determines vectors that areconsisted of 1s and-1s as elements; called sign vectors. CD algorithm is generally appliedfor data analysis tasks that involve long time series; ie where the number of rows(observations) is much larger than the number of columns (time series). The goal of thisthesis is to implement the CD algorithm on two Big Data platforms; ie; Apache Spark andApache Flink. The proposed implementation compares two different data structures for bothplatforms. The first data structure is the per-element data structure; which distributively …,*,2016,*
13th ICDAR'2015-Program at a Glance,Venu Govindaraju; Philippe Cudre-Mauroux,Page 1. 8:00 8:50 - 9:50 9:20 - 9:20 10:10 10:30 - 10:30 12:30 14:40 - 14:40 15:40 16:00 -16:00 18:00 II PI  13th ICDAR'2015 - Program at a Glance August 23--26; 2015; ProuveCongTess Center; Nancy; France [relocated from Tunisia] 24 August 2015 Registration Openingand IAPRJICDAR Award Ceremony [auditorium 300] IAPRJICDAR Award Lecture Prof. VenuGovindaraju (USA) [a 01 Coffee break [foyer 300] 25 August 2015 Registration Online Handwriting[room 202] Word Spotting II [auditorium 300] Document Analysis II [room 204] Keynote Prof.Philippe Cudre-Mauroux (Switzerland) 8:30 9:30 9:30 9:50 f-----i 9:50 26 August 2015 RegistrationPoster session 3 [salon 200] Coffee break [salon 200] Coffee break [foyer 300] 11:10 HistoricalDocument Processing f-----i Syntactic/Semantic Analysis [room 201] [room 202] …,*,2015,*
BenchPress: Dynamic Workload Control in the OLTP-Bench Testbed,Dana Van Aken; Djellel E Difallah; Andrew Pavlo; Carlo Curino; Philippe Cudré-Mauroux,Abstract Benchmarking is an essential activity when choosing database products; tuningsystems; and understanding the trade-offs of the underlying engines. But the workloadsavailable for this effort are often restrictive and non-representative of the ever changingrequirements of the modern database applications. We recently introduced OLTP-Bench; anextensible testbed for benchmarking relational databases that is bundled with 15 workloads.The key features that set this framework apart is its ability to tightly control the request rateand dynamically change the transaction mixture. This allows an administrator to composecomplex execution targets that recreate real system loads; and opens the doors to newresearch directions involving tuning for special execution patterns and multi-tenancy. In thisdemonstration; we highlight OLTP-Bench's important features through the BenchPress …,Proceedings of the 2015 ACM SIGMOD International Conference on Management of Data,2015,*
From Knowledge Engineering for Development to Development Informatics,Stéphane Boyera; Philippe Cudré-Mauroux,Abstract. Knowledge Sharing is a key enabler of development of the rural poor. ICTs canplay a critical role; providing for instance market data or weather information to sustenancefarmers; or education to children in remote areas. While advanced knowledge technologyhas proven its use in many applications in the so-called developed world most of the toolscannot be easily applied in developing countries; because of restricted infrastructure;unsuitable modes of communication or ignorance of the local context. In the K4D tutorial atEKAW 2014 we argued that a new of kind of research in Knowledge Engineering is neededin order to make knowledge technology useful outside privileged developed countries. Thisresearch will have to include existing social and economic structures as fundamentalrequirements in order to be successful. Finally; we claim that this holds for a broader …,Knowledge Engineering and Knowledge Management: EKAW 2014 Satellite Events; VISUAL; EKM1; and ARCOE-Logic; Linköping; Sweden; November 24-28; 2014. Revised Selected Papers.,2015,*
Data-Driven Process Discovery and Analysis: Third IFIP WG 2.6; 2.12 International Symposium; SIMPDA 2013; Riva del Garda; Italy; August 30; 2013; Revised Sele...,Paolo Ceravolo; Rafael Accorsi; Philippe Cudre-Mauroux,This book constitutes the thoroughly refereed proceedings of the Third InternationalSymposium on Data-Driven Process Discovery and Analysis held in Riva del Garda; Italy; inAugust 2013. The six revised full papers were carefully selected from 18 submissions.Following the event; authors were given the opportunity to improve their papers with theinsights they gained from the symposium. The selected papers cover theoretical issuesrelated to process representation; discovery and analysis or provide practical andoperational experiences in process discovery and analysis.,*,2015,*
From Knowledge Engineering for Development to Development Informatics,Stefan Schlobach; Victor De Boer; Christophe Guéret; Stéphane Boyera; Philippe Cudré-Mauroux,Abstract Knowledge Sharing is a key enabler of development of the rural poor. ICTs can playa critical role; providing for instance market data or weather information to sustenancefarmers; or education to children in remote areas. While advanced knowledge technologyhas proven its use in many applications in the so-called developed world most of the toolscannot be easily applied in developing countries; because of restricted infrastructure;unsuitable modes of communication or ignorance of the local context. In the K4D tutorial atEKAW 2014 we argued that a new of kind of research in Knowledge Engineering is neededin order to make knowledge technology useful outside privileged developed countries. Thisresearch will have to include existing social and economic structures as fundamentalrequirements in order to be successful. Finally; we claim that this holds for a broader …,International Conference on Knowledge Engineering and Knowledge Management,2014,*
Adaptive RDF Query Processing Based on Provenance,Marcin Wylot; Philippe Cudré-Mauroux; Paul Groth,Given the increasing amounts of RDF data available from multiple heterogenous sources; asevidenced by the Linked Open Data Cloud; there is a need to track provenance within RDF datamanagement systems [1]. In [8]; we presented TripleProv; a database system supporting thetransparent and automatic capture of detailed provenance information for arbitrary queries. Akey focus of TripleProv is the efficient implementation of provenance-enabled queries over largescale RDF datasets. TripleProv is based on a native RDF store; which we have extended withtwo different physical models to store provenance data on disk in a compact fashion. Inaddition; TripleProv supports several new query execution strategies to derive provenance informationat two different levels of aggregation. At one level; the exact sources for a query results can beidentified. The second; more detailed level; provides the full lineage of the query results …,International Provenance and Annotation Workshop,2014,*
Geographical Impact of Microblogging Social Networks,Roger Peter Kohler; Philippe Cudré-Mauroux; Gianluca Demartini,Abstract In this thesis the impact of microblogging social networks on the geographicaldistribution of bitly clicks is examined. The messages of the social platform Twitter arecombined with the geographical information; especially latitude and longitude; received bythe clicks on bitly URLs. Bitly itself is a URL-shortener providing different statistics and isused intensively for microblogging services. The tweets are streamed during September2013 and inserted with the bitly data provided by VeriSign into the used database systemHBase. Then the geographical data is clustered with the software Weka. To reveal theimpact of tweets on the bitly clicks; the clustering algorithm XMeans of Weka is applied onthe bitly clicks before posting a tweet with a certain bitly URL and afterwards separately. Thetwo clustering results are compared; especially the distortion of the clusters. The distortion …,*,2014,*
3.5 Crowdsourcing & the Semantic Web,Philippe Cudré-Mauroux,The Semantic Web was; from its inception; destined to create a machine-processable Webof data; a Web where computerized agents could collect; integrate; exchange and reasonupon large quantities of heterogeneous online information. Over the years; however; newapplications of the Semantic Web emerged. Today; some of its most exciting applications—such as the display of semi-structured information related to an entity; or the parsing ofnatural language for text summarization or question answering—are directly targetinghuman users. In that sense; the Web of data is increasingly used to help humans in theirdaily lives. In contrast; crowdsourcing leverages a Web of documents; made for humans; tohelp machines solve computationally complex tasks. Crowdsourcing and the Semantic Webwere in that sense bound to meet each other; and to come together to solve some of the …,Crowdsourcing and the Semantic Web,2014,*
Data-Driven Process Discovery and Analysis: Second IFIP WG 2.6; 2.12 International Symposium; SIMPDA 2012; Campione D'Italia; Italy; June 18-20; 2012; Revise...,Philippe Cudré-Mauroux; Paolo Ceravolo; Dragan Gaševic,This book constitutes the thoroughly refereed proceedings of the Second InternationalSymposium on Data-Driven Process Discovery and Analysis held in Campione d'Italia; Italy;in June 2012. The six revised full papers were carefully selected from 17 submissions. Toimprove the quality of the contributions the symposium fostered the discussion during thepresentation; giving authors the opportunity to improve their work extending the presentedresults. The selected papers cover topics spanning from theoretical issues related to processrepresentation; discovery and analysis to practical and operational experiences in processdiscovery and analysis.,*,2013,*
Data-Driven Process Discovery and Analysis SIMPDA 2013,Paolo Ceravolo; Rafael Accorsi; Philippe Cudre-Mauroux,Foreword The third edition of the International Symposium on Data-driven Process Discoveryand Analysis (SIMPDA 2013) conceived to offer a forum where researchers from different communitiesand the industry can share their insight in this hot new field. With the increasing automation ofbusiness processes; growing amounts of process data become available. This opens new researchopportunities for business process data analysis; mining and modeling. The aim of the IFIP2.6-2.12 International Symposium on Data-Driven Process Discovery and Analysis is to offera forum where researchers from different communities and the industry can share their insightin this hot new field. This year the symposium will be inserted among the VLDB 2013 workshopsand will feature a number of presentations on recent research results and competitive PhDseminar. All this in the charming setting of Riva del Garda at the north-western corner of …,*,2013,*
MEM0R1ES-Reclaim your digital life,Vincent Pasquier; Joël Dumoulin; Maria Sokhn; Omar Abou Khaled; Philippe Cudré-Mauroux,*,*,2013,*
NoSQL Databases for RDF: An Empirical Evaluation,S Fundatureanu; P Groth; M Wylot; P Cudré-Mauroux; I Enchev; A Haque; A Harth; FL Keppmann; D Miranker; J Sequeda,KNAW Narcis. Back to search results. Publication NoSQL Databases for RDF:An Empirical Evaluation (2013). Pagina-navigatie: Main …,*,2013,*
SIMPDA 2013: data-driven process discovery and analysis: proceedings of the 3rd International symposium on data-driven process discovery and analysis; co-locat...,R Accorsi; P Ceravolo; P Cudre-mauroux,SIMPDA 2013 : data-driven process discovery and analysis : proceedings of the 3rd Internationalsymposium on data-driven process discovery and analysis; co-located with 39th Internationalconference on very large databases (VLDB 2013) : Riva del Garda; Italy; august 30; 2013 / [acura di] R. Accorsi; P. Ceravolo; P. Cudre-Mauroux. - [sl] : CEUR; 2013 Aug.,*,2013,*
Data-Driven Process Discovery and Analysis,Wil Aalst; John Mylopoulos; Michael Rosemann; Michael Shaw; Clemens Szyperski; Philippe Cudre-Mauroux; Paolo Ceravolo; Dragan Gašević,Book Front Matter of LNBIP 162.,*,2013,*
Process prediction in noisy data sets: a case study in a Dutch hospital,Chintan Amrit; Philippe Cudre-Mauroux; Paolo Ceravolo; Dragan Gašević,*,*,2013,*
Highly Available Entity Registry System for Poorly Connected Environments,M Charlaganov; C Dinu; T Macicas; P Cudré-Mauroux; C Guéret,KNAW Narcis. Back to search results. Publication Highly Available Entity Registry Systemfor Poorly Connected Environments (2013). Pagina-navigatie: Main …,DOWNSCALE 2013,2013,*
Iliya Enchev,Philippe Cudre-Mauroux; Gianluca Demartini,Abstract The efficient reasoning about entities across distributed information sources andtheir efficient resolution are crucial prerequisites if the prescriptions of the Semantic Webmovement are to come into reality. These goals along with some of the most importantprincipal and technical issues of the Internet and the Web are presented in this work. Entityregistry systems provide capabilities like storing; serving and resolving data entities whichcould greatly facilitate the Semantic Web. Five such systems or approaches are presented inthis work-Domain Name System (DNS); Digital Object Architecture (DOA); Entity NameSystem; Chord DHT and CoralCDN. Further four data storage solutions are considered fortheir qualities in the context of handling structured RDF data entities and are put to extensivebenchmarking tests with the help of a developed Java benchmarking suit. These storage …,*,2012,*
Data-Driven Process Discovery and Analysis SIMPDA 2012,Paolo Ceravolo; Philippe Cudré-Mauroux,Abstract: Data engineering is a well-trodden field with established methods and tools thatallow engineers to capture complex data requirements and to refine these requirementsdown to the level of database schemas in a seamless and largely standardized manner.Concomitantly; database systems and associated middleware enable the development ofrobust and scalable data-driven applications to support a wide spectrum of businessfunctions. Eventually though; individual business functions supported by databaseapplications need to be integrated in order to automate end-to-end business processes. Thisfacet of information systems engineering falls under the realm of business processengineering. Business process engineering on the other hand is also an establisheddiscipline; with its own methods and tools. Process analysis and design methods typically …,*,2012,*
Special Issue on Semantic Web Meets Computational Intelligence [Guest Editorial],Huajun Chen; Philippe Cudre-Mauroux,The Semantic Web (SW)[1] carries out the vision of a global web of data directly consumableand understandable to machines. This vast data space; consisting of openlinked dataannotated with possibly expressive ontologies; promises significant opportunities for avariety of new web applications. The current Semantic Web languages and technologies aremainly built on traditional Artificial Intelligence approaches such as Description Logic; LogicProgramming; Ontology Reasoning; etc. However; in a highly open; decentralized; dynamic;and vast Web environment; the building and development of a global data space calls formore expressive languages capable of dealing with fuzziness and vagueness in websemantics [2][3]; and more efficient computational approaches to reduce the complexity of anumber of problems inherent to the Semantic Web such as Web-scale querying and …,IEEE Computational Intelligence Magazine,2012,*
Empowering Semantic Web with Computational Intelligence,Philippe Cudré-Mauroux,IEEE prohibits discrimination; harassment; and bullying. For more information; visithttp://www.ieee.org/web/ aboutus/whatis/policies/p9-26.html. Date of publication: 13 April 2012Digital Object Identifier 10.1109/MCI.2012.2188559 Digital Object Identifier 10.1109/MCI.2012.2191837… KC Tan and fellow CIS members at the Winter School on Advances in ComputationalIntelligence: Algorithms and Applications in Bhubaneswar; India.,IEEE Computational Intelligence Magazine,2012,*
Downscaling Entity Registries for Poorly-Connected Environments,Philippe Cudré-Mauroux; Christophe Guéret,Abstract. Emerging online applications based on the Web of Objects or Linked open Datatypically assume that connectivity to data repositories and entity resolution services arealways available. This may not be a valid assumption in many cases. Indeed; there areabout 4.5 billion people in the world who have no or limited Internet access. Many data-driven applications may have a critical impact on the life of those people; but areinaccessible to those populations due to the architecture of today's data registries. In thisproposal; we point out the limitations of current entity registries when deployed in poorlyconnected or adhoc environments. We then outline a research agenda based on a hybridmodel mixing decentralized and hierarchical infrastructures to support data-drivenapplication in environments with limited Internet connectivity.,*,2012,*
The semantic web; Proc. 10th Int. Semantic Web Conference ISWC-2012,P Cudré-Mauroux; J Heflin; E Sirin; T Tudorache; J Eurzenat; M Hauswirth; JX Parreira; J Hendler; A Th Schreiber; A Bernstein,KNAW Narcis. Back to search results. Publication The semantic web; Proc. 10th Int.Semantic Web Conference ISWC-2012 (2012). Pagina-navigatie: Main …,LNCS,2012,*
Ontology-driven E-Gov Portal for Swiss Public Services Access,Martin Maillard; Philippe Cudré-Mauroux; Maria Sokhn; Omar Abou Khaled; Elena Mugellini,Abstract E-Government is a fast-evolving field in Switzerland. In this paper; we address theproblem of applying Semantic Web technologies to this domain; in order to enhance theaccess to public services information for the citizen. For this purpose; we propose anarchitecture and an ontology to describe public services. This ontology is used as aknowledge base for the building of a portal seeking to meet the citizen needs in the processof searching public services. As a proof-of-concept; a prototype is presented at the end of thepaper.,*,2011,*
Bibliographic synthesis,Martin MAILLARD; Maria SOKHN; Elena MUGELLINI; Philippe CUDRE-MAUROUX; Omar ABOU KHALED,E-Government has been an interest for public administrations; citizens and business forseveral years since it emerged in the late 1990's [34]. E-Government aims to improve theefficiency and profitability of administrative activities while bringing them closer to the citizenthrough the use of information and communication technology. These activities involveexchange of information; products or services. E-Gov tends to allow citizens and business todo these on-line with minimal physical interactions with public entities. This project is part ofthe eGov Technology Center [7]; a consortium involving partners from academic; public andprivate sectors. The goals of this center are to allow the development of technologicalsolutions in the domain of E-Government in line with market standards and to foster the useof these solutions by community services and business.,*,2011,*
Hyrise-a Main Memory Hybrid Storage Engine,Philippe Cudré-Mauroux; Martin Grund; Jens Krueger; Hasso Plattner; Alexander Zeier HPI,Page 1. Hyrise - a Main Memory Hybrid Storage Engine Philippe Cudré-Mauroux eXascaleInfolab U. of Fribourg - Switzerland & MIT joint work w/ Martin Grund; Jens Krueger; HassoPlattner; Alexander Zeier (HPI) and Sam Madden (MIT) October 6; 2010 SAP Labs Palo altoPage 2. Outline ■ Motivation (OLTP VS OLAP) ■ Hyrise Architecture ■ Hybrid Layouts ■Query Execution ■ Cost Model ■ Physical Layouters ■Optimal Layouter ■Scalable Layouter ■Performance ■ Current & Future Work Page 3. OLTP HYRISE OLAP Motivation: the DBMSDivide ■ OLTP ■ Data entry ■ Mix of reads and writes to few rows at a time ■ Index structures(B+ Trees) ➡Transaction Processing System VS ■ OLAP ■ Aggregates ■ Bulk updates (ETL) ■Large sequential scans spanning few columns but many rows ➡Warehousing ➡Rise of column-stores Page 4. Problems w/ current divide …,*,2010,*
Digital Ecosystems (DEST) have emerged with the purpose of enhancing communications among small and medium enterprises (SMEs) within the worldwide Busin...,Ernesto Damiani; Miltiadis Lytras; Philippe Cudre-Mauroux,Semantic Web applications take off is being slower than expected; at least with respect to“real-world” applications and users. One of the main reasons for this lack of adoption is thatmost Semantic Web user interfaces are still immature from the usability and accessibilitypoints of view. This is due to the novelty of these technologies; but this also motivates theexploration of alternative interaction...,World Wide Web,2010,*
6.092 Introduction to Software Engineering in Java; January (IAP) 2009,Evan Jones; Olivier Koch; Philippe Cudre-Mauroux,This course is an introduction to Java programming and software engineering. It is designedfor those who have little or no programming experience in Java and covers concepts usefulto 6.005. The focus is on developing high quality; working software that solves realproblems. Students will learn the fundamentals of Java; and how to use 3rd party libraries toget more done with less work. Each session includes one hour of lecture and one hour ofassisted lab work. Short labs are assigned with each lecture. This course is offered duringthe Independent Activities Period (IAP); which is a special 4-week term at MIT that runs fromthe first week of January until the end of the month.,*,2009,*
Book: The Proceedings of the International Workshop on Emergent Semantics and Ontology Evolution (ESOE07),Liming Chen; Philippe Cudré-Mauroux; Peter Haase; Andreas Hotho; Ernie Ong,*,*,2007,*
International Workshop on Emergent Semantics and Ontology Evolution,Luke Liming Chen; Philippe Cudré-Mauroux; Peter Haase; Andreas Hotho; Ernie Ong,The Semantic Web and collaborative tagging are two complementary approaches aiming atmaking information search; retrieval; navigation and knowledge discovery easier. While theSemantic Web enforces semantics top-down via the use of ontologies; collaborative taggingtries to obtain semantics in a bottom-up fashion. Del. icio. us and flickr are success stories ofcollaborative tagging; the winners of the Semantic Web Challenge demonstrate the successof the Semantic Web. Still; both approaches face open issues. For the Semantic Web;ontology engineering; in particular; large-scale ontology construction; has been abottleneck. While effort and progress have been made in ontology matching; alignment;versioning and learning; it has become clear that constructing large ontologies requirescollaboration among multiple individuals or groups with expertise in specific areas. Also …,*,2007,*
" Sentry Pallets" for Automated Monitoring of Spatial Constraints,Philippe Cudré-Mauroux; Menasheh Fogel; Ken Goldberg; Michael J Franklin,Warehouses must maintain a number of spatial constraints concerning the safe handling ofhazardous materials. In this paper; we address the problem of automated monitoring ofspatial constraints as pallets are moved on forklifts by human operators. We propose usingsmall; self-contained localizing sensor packages mounted on pallets. We consider twoarchitectures: 1) a global architecture where sensors are mounted on pallets and on thewarehouse ceiling; and 2) a local architecture where sensors are located only on the pallets.We formally model the problem for a warehouse environment where sensors can beinstalled on the pallets or on the ceiling. We also report on preliminary experimental resultson the accuracy of constraint violation detection as a function of inter-sensor distance andangle.,21st International Conference on Robotics and Automation (ICRA2006),2006,*
Journal on Data Semantics VI,Karl Aberer; Philippe Cudré-Mauroux; Stefano Spaccapietra,Volume Editors Stefano Spaccapietra École Polytechnique Fédérale de Lausanne; EPFL ICLBD; Station 14 1015 Lausanne; Switzerland E-mail: stefano. spaccapietra@ epfl. ch Karl AbererPhilippe Cudré-Mauroux École Polytechnique Fédérale de Lausanne; EPFL I and C; LSIR; Station14 1015 Lausanne; Switzerland E-mail:{karl. aberer; philippe. cudre-mauroux}@ epfl. ch Libraryof Congress Control Number: 2006929224 CR Subject Classification (1998): H. 2; H. 3; I. 2;H. 4; C. 2 LNCS Sublibrary: SL 3–Information Systems and Application; incl. Internet/Web andHCI ISSN 1861-2032 ISBN-10 3-540-36712-8 Springer Berlin Heidelberg New York ISBN-13978-3-540-36712-3 Springer Berlin Heidelberg New York This work is subject to copyright. Allrights are reserved; whether the whole or part of the material is concerned; specifically the rightsof translation; reprinting; re-use of illustrations; recitation … The LNCS Journal on …,*,2006,*
School of Computer and Communication Sciences; Ecole Polytechnique Fe'de'rale de Lausanne (EPFL); Switzerland,Karl Aberer; Philippe Cudré-Mauroux; Manfred Hauswirth,Summary. Until recently; most data integration techniques revolved around centralapproaches; eg; global schemas; to enable transparent access to heterogeneousdatabases. However; with the advent of the Internet and the democratization of toolsfacilitating knowledge elicitation in machine-processable formats; the situation is quicklyevolving. One cannot rely on global; centralized schemas anymore as knowledge creationand consumption are getting increasingly dynamic and decentralized. Peer DataManagement Systems (PDMS) address this problem by eliminating centralization andinstead applying compositions of local; pair-wise mappings to propagate queries amongdatabases. We present a method to foster global semantic interoperability in PDMS settingsin a totally decentralized way based on the analysis of the semantic graph linking data …,Semantic Web and Peer-to-Peer: Decentralized Management and Exchange of Knowledge and Information,2005,*
Ontologies; Databases; and Applications of Semantics (ODBASE) 2004 International Conference (continued)-Advanced Information Systems-A Necessary Condition...,Philippe Cudre-Mauroux; Karl Aberer,*,Lecture Notes in Computer Science,2004,*
The Chatty Web Approach for Global Semantic Agreements.,Philippe Cudré-Mauroux; Karl Aberer; Manfred Hauswirth,Page 1. ©2003; Philippe Cudré-Mauroux; EPFL-I&C-IIF; Distributed Information Systems LabThe Chatty Web approach for global semantic agreements MMGPS Workshop; London PhilippeCudré-Mauroux; Karl Aberer Distributed Information Systems Laboratory (LSIR) Swiss FederalInstitute of Technology; Lausanne (EPFL) Page 2. ©2003; Philippe Cudré-Mauroux;EPFL-I&C-IIF; Distributed Information Systems Lab The Problem (1) Swissprot site at GenevaA lab at MIT A lab in Trondheim organism Query posted at EPFL species species EMBLChangesite at Cambridge organism organism EMBLChange peers species; … SwissProt peers authors;titles; organism; … other peers authors; … Page 3. ©2003; Philippe Cudré-Mauroux;EPFL-I&C-IIF; Distributed Information Systems Lab The Problem (2) • How to obtain semanticinteroperability among heterogeneous data sources without relying on pre-existing; global …,MMGPS,2003,*
Mark Fox (Enterprise Integration Laboratory; University of Toronto; Canada) Freddy Lecue (IBM Research; Dublin; Ireland) Sheila McIlraith (Department of Computer...,Rosario Uceda-Sosa; Mathieu D'Aquin; Soren Auer; Philippe Cudré-Mauroux; Fabien Gandon; Michael Gruninger; Anupam Joshi; Subbarao Kambhampati; Craig Knoblock; Raghuram Krishanpuram; Ullas Nambiar; Tope Omitola; Jeff Z Pan; Francois Scharffe; Neeta Verma,Program Committee Mathieu D'Aquin (Open University; UK) Soren Auer (Univeristy ofLeipzig; Germany) Philippe Cudré-Mauroux (University of Fribourg; Switzerland) Fabien Gandon(INRIA; France) Michael Gruninger (University of Toronto; Canada) Anupam Joshi (Universityof Maryland; Baltimore County; USA) Subbarao Kambhampati (Arizona State University;USA) Craig Knoblock (USC/ISI and Fetch Technologies; USA) Raghuram Krishanpuram (IBMResearch; India) Ullas Nambiar (EMC; India) Tope Omitola (University of Southampton; UK)Jeff Z.Pan (e University of Aberdeen; UK) Francois Scharffe (LIRMM; Montpellier; France) NeetaVerma (Data.gov.in/ NIC; India) … is AAAI workshop was held on Monday; July 28; 2014 inconjunction with the Twenty-Eighth AAAI Conference on Artificial Intelligence.,*,*,*
Biplav Srivastava (IBM Research; India) sbiplav@ in. ibm. com Freddy (IBM Research; Smarter Cities Technology Centre; Dublin; Ireland) freddy lecue@ ie. ibm. co...,Pol Mac Aonghusa; Craig Knoblock; Rahguram Krishnapuram; Mathieu D'Aquin; Soren Auer; Philippe Cudré-Mauroux; Michael Hausenblas,Organizers Biplav Srivastava (IBM Research; India) sbiplav@in.ibm.com Freddy (IBMResearch; Smarter Cities Technology Centre; Dublin; Ireland) freddy lecue@ie.ibm.com AnupamJoshi (University of Maryland; College Park; USA) joshi@cs.umbc.edu … Steering CommitteePol Mac Aonghusa (IBM SCTC - Dublin) Craig Knoblock (Information Sciences Institute; Universityof Southern California; USA) Rahguram Krishnapuram (IBM Research; India) … Program CommitteeMathieu D'Aquin (Open University; UK) Pol Mac Aonghusa (IBM Research; Smarter Cities TechnologyCentre; Dublin; Ireland) Soren Auer (University of Leipzig; Germany) Philippe Cudré-Mauroux(University of Fribourg; Switzerland) Michael Hausenblas (DERI; Galway; Ireland) Anupam Joshi(University of Maryland; College Park; USA) Subbarao Kambhampati (Arizona StateUniversity; USA) Spyros Kotoulas (IBM Research; Smarter Cities Technology Centre …,*,*,*
City-Stories: A Multimedia Hybrid Content and Entity Retrieval System for Historical Data,Shaban Shabani; Maria Sokhn; Philippe Cudré-Mauroux; Lukas Beck; Claudiu Tanase; Heiko Schuldt,ABSTRACT Information systems used in tourism rely mostly on up-to-date content on aractive places. In addition; these systems increasingly make use of archived photographs;documents; lms; or even ancient paintings and other artwork by integrating such curatedcontent from museums and memory institutions; possibly enriched with user-providedcontent. Hence the distinction between cultural heritage applications and tourism more andmore blurs. Users are not only interested in the current appearance of landscapes;monuments; or buildings; but also in the evolution of these places over time. is requireslarge multimedia collections which integrate content from several cultural heritageinstitutions. As a consequence; interactive retrieval systems for historical multimedia areneeded that support homogeneous content-based and semantic querying despite the …,*,*,*
SocialMatching++: A Novel Approach for Interlinking User Profiles on Social Networks,Hussein Hazimeh; Elena Mugellini; Omar Abou Khaled; Philippe Cudré-Mauroux,Abstract With the large number of users connected to social networks; screennameduplication is a rising problem; which leads to interference when trying to recognize users. Anumber of algorithms have been proposed to distinguish user profiles on one or multiplesocial networks. The main task in this context is to have robust features. According to thestate-of-the-art approaches; features can be: content and behavioural based features; thatcompare content similarity between posts or behaviour similarity (timestamps between posts(behavioural); or overlapping between content (content) for example). Attribute-basedfeatures that compare profiles attributes; such as gender; age; location or image. In thispaper; we tackle this problem and propose SocialMatching++ a novel approach thatleverages:(1) user life events such as graduation; marriage or new job; which used to …,*,*,*
ICDE 2017 Reviewers,Yannis Papakonstantinou; Lei Chen; Reynold Cheng; Wolfgang Gatterbauer; Bingsheng He; Stratos Idreos; Christopher Jermaine; Chen Li; Gerome Miklau; Tamer Özsu; Olga Papaemmanouil; Evimaria Terzi; Eugene Wu; Ashraf Aboulnaga; Alex Alves; Amazon Gabriel Antoniu; INRIA Arvind Arasu; Andrey Balmin; Workday Zhifeng Bao; Sumita Barahmand; Srikanta Bedathur; Carsten Binnig; Spyros Blanas; Marco Brambilla; Stephane Bressan; K Selcuk Candan; Zhao Cao; James Cheng; Fei Chiang; Panos K Chrysanthis; Philippe Cudre-Mauroux,ICDE 2017 Program Committee Chairs Yannis Papakonstantinou; University of California; SanDiego Yanlei Diao; Ecole Polytechnique; France; and University of Massachusetts; Amherst …ICDE 2017 Area Chairs Lei Chen; Hong Kong University of Science and Technology ReynoldCheng; University of Hong Kong Wolfgang Gatterbauer; Carnegie Mellon University BingshengHe; National University of Singapore Stratos Idreos; Harvard University ChristopherJermaine; Rice University Chen Li; University of California Irvine Gerome Miklau; University ofMassachusetts Tamer Özsu; University of Waterloo Olga Papaemmanouil; Brandeis UniversityEvimaria Terzi; Boston University Eugene Wu; Columbia University … ICDE 2017 Program CommitteeAshraf Aboulnaga; Qatar Computing Research Institute Alex Alves; Amazon Gabriel Antoniu;INRIA Arvind Arasu; Microsoft Research Andrey Balmin; Workday Zhifeng Bao; RMIT …,*,*,*
Adaptive 3D Index,Alexander Butyaev; Ruslan Mavlyutov; Mathieu Blanchette; Philippe Cudré-Mauroux; Jérôme Waldispühl,3DBG was devised to efficiently handle extremely large amounts of genomic dataassociated to fine-grained 3D models. Classical spatial indices such as R-Trees areinappropriate to our context; since they consider too many overlapping bounding boxes (andhence; too many distinct reads) when indexing complex 3D models and their associatedmetadata (see the database description section). Instead; we adapt our own; state-of-the-artTrajStore [1] spatial index to efficiently index arbitrary large amounts of genomic data andmetadata along three dimensions. Our index has the three following desirable properties: itis i) sparse (ie; it does not grow linearly as the indexed data grows); ii) non-overlapping(yielding limited index lookups event for 3D range queries on complex meshes) and iii)adaptive (ie; it continuously adjusts to the local densities of the indexed data). Formally …,*,*,*
View other issues,Christophe Guéret; Philippe Cudré-Mauroux,Sixty-five percent of the world's population is deprived of ICT-enhanced data-sharingbecause of poor access to digital technology. The ExaScale Infolab and Data Archiving andNetworked Services (DANS) have designed a new framework; the" Entity RegistrySystem"(ERS); and produced a reference implementation making it possible to publish andconsume Linked Open Data in poorly connected environments. There is no longer anydoubt about the social and economic value of accessible; open data. Leveraging thepervasive presence of the Web; Linked Data principles and Web-based portals arepromising technologies for implementing data-sharing applications. But the trivialarchitectural assumptions around data connectivity and availability of large-scale resourceskeeps ICT-enhanced data sharing out of reach for about 65% of the world's population …,*,*,*
3DGB: A Low-Latency; Big Database System and Browser for Storage; Querying and Visualization of 3D Genomic Data,Alexander Butyaev; Ruslan Mavlyutov; Mathieu Blanchette; Philippe Cudré-Mauroux; Jérôme Waldispühl,Abstract Recent releases of genome 3D structures have the potential to transform ourunderstanding of genomes. Nonetheless; the storage technology and visualization toolsneed to evolve to enable users fast and easy access to these data. We introducesimultaneously a database system to store and query 3D genomic data (3DBG); and agenome browser to visualize and explore 3D genome structures (3DGB). We benchmark3DBG against state-of-the-art systems; and demonstrate that it is faster than previoussolutions; and importantly gracefully scales with the size of data. The 3D genome browser isavailable at http://3dgb. cs. mcgill. ca/.,*,*,*
آزمایشی,آزمایشی,Skip navigation …,*,*,*
ICNDC 2013,Rajkumar Buyya; Mark Baker; John Brooke; Wentong Cai; Jie Cao; Gang Chen; Giuseppe Ciaccio; Zhen Chen; Philippe Cudre-Mauroux; Yong Fang; Shaoyi He; Jinzhu Gao; Weidong Geng; Jinyuan Jia; Keyuan Jiang; Gang Kou; Jianping Li; Keping Long; Willie W Lu; Kai Nan; Daowu Pei; PI Poromarenko; Omer F Rana; Yingwen Song; Ian J Taylor; Cho-Li Wang; Hecheng Wang; Jue Wang; Fenghua Wen; Zhiming Zhao; Chengxiong Zhou; Ligang Zhou; Yuanchun Zhou; Jinlou Zhao; Hongbo Zhu,Rajkumar Buyya; University of Melbourne; Australia Mark Baker; University of Reading; UnitedKingdom John Brooke; University of Manchester; United Kingdom Wentong Cai; Nanyang TechnologicalUniversity; Singapore Jie Cao; Nanjing University of Information Science & Technology; ChinaGang Chen; Chinese Academy of Science; China Giuseppe Ciaccio ; Universita' di Genova;Italy Zhen Chen; Tsinghua University; China Philippe Cudre-Mauroux; Massachusetts Instituteof Technology; USA Georgios Exarchakos; TUE; Netherlands Yong Fang; Chinese Academyof Sciences; China Haiwu He; INRIA; France Shaoyi He; California State University at SanMarcos; USA Jinzhu Gao; University of Pacific; USA Weidong Geng; Zhejiang University; ChinaJinyuan Jia; Tongji University; China Keyuan Jiang ; Purdue calmet University ; USA GangKou; University of Electronic Science and Technology of China; China Jianping Li …,*,*,*
mem0r1es: a Transactive Metamemory System for Personal Information Management,Karl Aberer; Michele Catasta; Philippe Cudré-Mauroux; Gianluca Demartini; Maria Sokhn; Alberto Tonon,*,*,*,*
2012 6th IEEE International Conference on Digital Ecosystems and Technologies (DEST),Anas Abouelkalam; Rafael Accorsi; Mohamed Achemlal; Jose M Alcaraz Calero; Luis Soares Barbosa; Karima Boudaoud; France de Nice Sophia Antipolis; Robert Biuk-Aghai; Daniele Bonetta; Mihaela Cardei; Richard Chbeir; Ioana Georgiana Ciuciu; Angelo Corallo; Philippe Cudre-Mauroux; Schahram Dustdar; Eduardo Fernandez; Eduardo Fernández-Medina; Hannelore Frank; Avigdor Gal; Mohand-Said Hacid; Artur Hecker; Chi Hung; Mustafa Jarrar; Palestinian Territory,The international program committee is charged with assisting the conference maintain its highstandard of technical excellence through the review of submitted papers and advice … AnasAbouelkalam Institut National Polytechnique de Toulouse; France Rafael Accorsi University ofFreiburg; Germany Mohamed Achemlal Orange Labs; France Jose M Alcaraz CaleroHewlett-Packard; UK Valentina Emilia Balas University of Arad; Romania Helen BalinskyHewlett-Packard Laboratories; UK Luis Soares Barbosa Universidade do Minho; Portugal KarimaBoudaoud Ecole Polytechnique de Nice Sophia Antipolis; France Johan Bellika Norw. Centerfor Telemedicine and University of Tromsoe; Norway Robert Biuk-Aghai University of Macau;China Daniele Bonetta Università della Svizzera Italiana; Switzerland Mihaela Cardei FloridaAtlantic University; US Richard Chbeir University of Bourgogne; France William Cheung …,*,*,*
Improving Business Process Models using Observed Behavior,Paolo Ceravolo; Philippe Cudre-Mauroux; Dragan Gasevic,@inproceedings{Buijs_RRDA_13; publisher = {Springer}; author = {Buijs; Joos CAM and LaRosa; Marcello and Reijers; Hajo A. and van Dongen; Boudewijn and van der Aalst; Wil MP};month = jun; editor = {{Paolo Ceravolo; Philippe Cudre-Mauroux; Dragan Gasevic }}; year ={2013}; keywords = {process mining; process improvement; reference model; process model;automated process discovery}; title = {Improving Business Process Models using ObservedBehavior}; booktitle = {nternational Symposium on Data-driven Process Discovery and Analysis(SIMPDA)}; pages = {TBA}; address = {Campione d'Italia; Italy} },nternational Symposium on Data-driven Process Discovery and Analysis (SIMPDA),*,*
Crowdsourced conceptualization of complex scientific knowledge and discovery of discoveries,Karl Aberer; Alexey Boyarsky; Philippe Cudré-Mauroux; Paolo De Los Rios,What should be the structure and the semantic organization of scientific knowledge? Howcan it be built? What defines a “discovery”? Under which conditions can a discovery“emerge” from a scientific infrastructure? What parts of the discovery process can beautomated? An inter-disciplinary team of physicists; complexity scientists and computerscientists is clearly required to answer those fundamental questions. The nature of scientificdiscoveries is drastically changing. Fewer and fewer scientific advances are carried out bysmall groups working in their laboratories in isolation. In today's data-driven sciences (be itbiology; physics; complex systems or economics); the progress is increasingly achieved bycollaborations of scientists with heterogeneous expertise; working in parallel; and having avery contextualized; local view on their problems and results. The research process is …,*,*,*
In addition to the Program Committee members; the following people reviewed papers for ECOWS 2005: Constantin Adam Samuil Angelov George Athanasopoulos,Frank Büscher; Zhixiong Chen; Maria Agustina Cibran; Philippe Cudre-Mauroux; Ivan Djordjevic; Paul Grace; Claudio Guidi; Jacek Kopecky; Michael Pantazoglou; Pierluigi Plebani; Stefan Pottinger; Livia Predoiu; Florian Rosenberg; Ali Salehi; Roman Schmidt; James Scicluna; Gleb Skobeltsyn; Leonid Titkov; Ioan Toma; Dennis Wagelaar; Fetahi Wuhib,A not-for-profit organization; IEEE is the world's largest technical professional organization dedicatedto advancing technology for the benefit of humanity. © Copyright 2017 IEEE - All rightsreserved. Use of this web site signifies your agreement to the terms and conditions.,*,*,*
Xian Xu Guizhen Yang Moustafa A. Youssef,Salman Akram; James Caverlee; Franois Charoy; Philippe Cudre-Mauroux; Adriano Di Pasquale; Alpay Erturkmen; Sarunas Girdzijauskas; Claude Godart; Jiang Haiying; Moustafa Hammad; Weiping He; Omer Horvitz; Lieming Huang; Ihab Ilyas; George-Dimitrios Kapos; Gokce Laleci; Bendick Mahleko; Zaki Malik; Brahim Medjahed; Iwaihara Mizuho; Mohamed Mokbel; Pascal Molli; Christine O’Keefe; Mourad Ouzzani; Ovgu Ozturk; Olivier Perrin; Thomais Pilioura; Lakshmish Ramaswamy; Abdelmounaam Rezgui; Chatvichienchai Somchai; Murakami Takaharu; Li Xiong,A not-for-profit organization; IEEE is the world's largest technical professional organization dedicatedto advancing technology for the benefit of humanity. © Copyright 2017 IEEE - All rightsreserved. Use of this web site signifies your agreement to the terms and conditions.,*,*,*
SERVICES-I 2009,Nils Gruschka; Yaacov Yesha; Celso Hirata; Reijo Sulonen; Timothy K Shih; Fa-Long Luo; Anca Ivan; Gang Li; Philippe Cudre-Mauroux; Abhik Roychoudhury; Liming Zhu; Khalid Al-Begain; Shiping Chen; Suresh Damodaran; Prashant Doshi; Wei CR Sun; Young B Choi; Pontus Johnson; Shiyong Lu; Calton Pu; Ernesto Damiani; Justin Zhu; Sanjay Chaudhary; Harry Perros; Yan Wang; Claude Godart; Claudio Bartolini; Meiko Jensen,Nils Gruschka (NEC Laboratories Europe; Germany) Yaacov Yesha (University of Maryland BaltimoreCounty; USA) Celso Hirata (ITA; Brazil) Reijo Sulonen (Helsinki University of Technology;Finland) Timothy K. Shih (Tamkang University; Taiwan) Fa-Long Luo (Anyka Inc.; USA) AncaIvan (IBM Thomas J Watson Center; USA) Gang Li (Chinese Academacy of Sciences; China)Philippe Cudre-Mauroux (MIT; USA) Abhik Roychoudhury (National University of Singapore;Singapore) Liming Zhu (NICTA; Australia) Khalid Al-Begain (University of Glamorgan; UK) ShipingChen (CSIRO; Australia) Suresh Damodaran (RosettaNet; USA) Prashant Doshi (University ofGeorgia; USA) Wei CR Sun (IBM China Research Lab; China) Young B. Choi (James MadisonUniversity; USA) Pontus Johnson (KTH; Sweden) Shiyong Lu (Wayne State University; USA)Calton Pu (Georgia Tech; USA) Ernesto Damiani (The University of Milan; Italy) Justin …,*,*,*
SERVICES 2010 Technical Steering and Program Committees,Carl K Chang; Ephraim Feig; Hemant Jain; Frank Leymann; Calton Pu; Liang-Jie Zhang; Sriram Anand; Ali Bahrami; Akhilesh Bajaj; Sujoy Basu; Manish A Bhide; Zhixiong Chen; Cecil Chua; Philippe Cudre-Mauroux; Nirmit Desai; Stefan Dessloch; Rachida Dssouli; Atilla Elci; Vadim Ermolayev; Onyeka Ezenwoye; Manish Gupta; Satoshi Hada; Michael Hafner; Seyyed Mohsen Hashemi; Sungbum Hong; Ken Hopkinson; Hai Jin; Akhil Kumar; Konstantin Laufer; Howard Leung; Gang Li; Haifei Li; Dong Liu; Ling Liu; Shiyong Lu,Carl K. Chang; Iowa State University; USA Ephraim Feig; Innovations-to-Market; USA HemantJain; University of Wisconsin–Milwaukee ; USA Frank Leymann; University of Stuttgart; GermanyCalton Pu; Georgia Tech; USA Liang-Jie Zhang; IBM TJ Watson Research Center; USA … SriramAnand; Accenture; India Ali Bahrami; Boeing Research and Technology; USA AkhileshBajaj; University of Tulsa; USA Sujoy Basu; HP Palo Alto Labs; USA Manish A. Bhide; IBM IndiaResearch Lab; India Zhixiong Chen; Mercy College; USA Cecil Chua; Nanyang TechnologicalUniversity; Singapore Philippe Cudre-Mauroux; Massachusetts Institute of Technology; USANirmit Desai; IBM India Research Lab; India Stefan Dessloch; Kaiserslautern University ofTechnology; Germany Rachida Dssouli; Concordia University; Canada Atilla Elci; Eastern MediterraneanUniversity; Turkey Vadim Ermolayev; Zaporozhye National University; Ukraine Onyeka …,*,*,*
SP2PN 2010 Workshop Committee,Lican Huang; Rajkumar Buyya; Junwei Cao; Philippe Cudre-Mauroux; Yike Guo; Maozhen Li; Omer F Rana; Xiaodong Wang; Zhiming Zhao,A not-for-profit organization; IEEE is the world's largest technical professional organization dedicatedto advancing technology for the benefit of humanity. © Copyright 2017 IEEE - All rightsreserved. Use of this web site signifies your agreement to the terms and conditions.,*,*,*
AP2PS 2009,Marco Aiello; Filip De Turck; Petre Dini; Giancarlo Fortino; Stephen Jarvis; Maozhen Li; Carl James Debono; Nick Antonopoulos; Antonio Liotta; Anders Fongen; Yasushi Kambayashi; Lisandro Zambenedetti Granville; George Exarchakos; Takahiro Hara; Jemal H Abawajy; Annamalai Annamalai Jr; Farnoush Banaei-Kashani; Ataul Bari; Paolo Bellavista; Frances MT Brazier; Dumitru Dan Burdescu; Carlos Tavares Calafate; Aldo Campi; Hsi-Ya Chang; Ruay-Shiung Chang; Jose Manuel Chaves-González; Chou Cheng-Fu; Giovanni Chiola; Yeh-Ching Chung; Noël Crespi; Fernando Cores Prado; Antonio Cuadra-Sanchez; Philippe Cudre-Mauroux; Daniel Cutting; Alfredo Cuzzocrea,Marco Aiello; University of Groningen; The Netherlands Filip De Turck; Ghent University -IBBT; Belgium Petre Dini; Cisco Systems; Inc.; USA / Concordia University; Canada GiancarloFortino; University of Calabria; Italy Stephen Jarvis; University of Warwick; UK Maozhen Li; BrunelUniversity; UK Carl James Debono; University of Malta & IEEE Malta Nick Antonopoulos; Universityof Surrey; UK Antonio Liotta; Eindhoven University of Technology; The Netherlands AndersFongen; Norwegian Defence Research Establishment; Norway Yasushi Kambayashi; NipponInstitute of Technology; Japan Lisandro Zambenedetti Granville; Federal University of Rio Grandedo Sul; Brazil George Exarchakos; University of Surrey; UK Takahiro Hara; Osaka University;Japan (Mehmet) Rasit Eskicioglu; University of Manitoba; Canada Jemal H. Abawajy; DeakinUniversity; Australia Annamalai; Annamalai Jr.; Prairie View A&M University (Texas A&M …,*,*,*
ICSC 2007,Eneko Agirre; Yannis Avrithis; Steven Bethard; Daniel Bikel; Andrew Byde; Marco Casassa Mont; Chia-Chu Chiang; Philipp Cimiano; Kevin Bretonnel Cohen; Philippe Cudre-Mauroux; Theodore Dalamagas; Juan Carlos De Martin; Li Deng; Mathew Magimai Doss; Miriam Eckert; Phil Edmonds; Miles Efron; Abdennour El Rhalibi; Khaled El-Maleh; Katrin Erk; Martin Franz; Joseph Andrew Giampapa; Gregory Grefenstette; William Grosky; Iryna Gurevych; Dilek Hakkani-Tur; Benjamin Ding-Jung Han; Ian Harris; Manfred Hauswirth; Keqing He; Xiaodong He; Graeme Hirst; Paola Hobson; Veronique Hoste; Yu Hen Hu; Chu-Ren Huang,Technical Program Members Eneko Agirre; Basque Country University; Spain YannisAvrithis; National Technical University of Athens; Greece Steven Bethard; University ofColorado; USA Daniel Bikel; IBM Research; USA Paul Buitelaar; DFKI; Germany AndrewByde; HP Laboratories; UK Marco Casassa Mont; HP Laboratories; UK Chia-Chu Chiang; Universityof Arkansas at Little Rock; USA Philipp Cimiano; Institut AIFB; Universität Karlsruhe; GermanyKevin Bretonnel Cohen; University of Colorado; USA Philippe Cudre-Mauroux; EPFL; SwitzerlandTheodore Dalamagas; National Technical University of Athens; Greece Juan Carlos DeMartin; Politecnico di Torino; Italy Li Deng; Microsoft Research; USA Mathew Magimai Doss;ICSI Berkeley; USA and IDIAP; Martigny; Switzerland Michael Dyer; UCLA; USA MiriamEckert; University of Colorado; USA Phil Edmonds; Sharp Laboratories of Europe; UK …,*,*,*
Technical program committees,Mohamed Abouelhoda; Devdatt Dubhashi; Scott Emrich; Ananth Kalyanaraman; Pang Ko; Mehmet Koyuturk; TM Murali; Desh Ranjan; Bertil Schmidt; Srikanta Tirthapura; Watheq El-Kharashi; Aiman El-Maleh; Hani Elgebaly; Fayez Gebali; Yasser Rasheed; Kassem Saleh; Ozgur Sinanoglu; Bellaachia Abdelghani; Ali Al-Jaoua; Mohammad Alrifai; Ahmet Cosar; Philippe Cudré-Mauroux; Margaret H Dunham; Sung Ho Ha; Siegfried Handschuh; Masaru Kitsuregawa; Claus-Peter Klas; Christian Lang; Carlo Meghini; Bhaskar Mehta; Erich Neuhold; Yucel Saygin,• Abdelghani; Bellaachia; George Washington University; USA • Aghbari; Zaher; University ofSharjah; UAE • Al-Jaoua; Ali; Qatar University; Qatar • Alrifai; Mohammad; L3S ResearchCenter; Germany • Cosar; Ahmet; Middle East Technical University; Turkey •Cudré-Mauroux; Philippe; EPFL; Switzerland • Dunham; Margaret H.; Southern MethodistUniversity; USA • Ha; Sung Ho; Kyungpook National University; Korea • Handschuh;Siegfried; DERI; Ireland • King; Ross; ARC Research Studio Digital Memory; Austria •Kitsuregawa; Masaru; University of Tokyo; Japan • Klas; Claus-Peter; FernUniversitätHagen; Germany • Knezevic; Predrag; Fraunhofer IPSI; Germany • Lang; Christian; IBM TJ WatsonResearch Center; USA • Meghini; Carlo; ISTI-CNR; Italy • Mehta; Bhaskar; L3S ResearchCenter; Germany • Neuhold; Erich; University of Vienna; Austria • Niederee; Claudia …,*,*,*
Program committee: Karl Aberer; EPFL,Marinho Barcellos; Danny Bickson; Ernst Biersack; Ken Birman; John Buford; Landon Cox; Jon Crowcroft; Philippe Cudré-Mauroux; Yafei Dai; Anwitaman Datta; Zoran Despotovic; John Douceur; Pascal Felber; Daniel Figueiredo; Pawel Garbacki; Pedro García López; Ali Ghodsi; Seif Haridi; Aaron Harwood; David Hausheer; Manfred Hauswirth; Mark Jelasity; Vana Kalogeraki,Page 1. Organization General co-chairs: Dick Epema; Delft University of Technology Henk Sips;Delft University of Technology Program co-chairs: Maarten van Steen; VU University Ben Zhao;University of California; Santa Barbara Demo organization chair: Johan Pouwelse; Delft Universityof Technology Industrial liaison chair: Wolfgang Kellerer; DOCOMO Local arrangements: Pien Rijnink;Delft University of Technology Esther van Seters; Delft University of Technology Laura Zondervan;Delft University of Technology Website: Stephen van der Laan; Delft University of TechnologyGraphic design: Martin Bor; Delft University of Technology Program committee: Karl Aberer; EPFLMarinho Barcellos; Federal University of Rio Grande Danny …,*,*,*
Carolyn McGregor; University of Western Sydney; Australia Brahim Medjahed; The University of Michigan; Dearborn; USA Aad Van Moorsel; University of NewCastl...,Fahim Akhter; Carminati Barbara; Italty Boualem Benatallah; Djamal Benslimane; M Brian Blake; David Bodoff; Christoph Bussler; Malu Castellanos; Stephen Chan; Kuo-Ming Chao; Patrick Chau; Kung Chen; Michael T Cheung; Shing-Chi Cheung; William Cheung; Philippe Cudre-Mauroux; Timon Chih-ting Du; Schahram Dustdar; Pascal van Eck; Ferrari Elena; Italty Stephane Gagnon; Gurnani Haresh; Switzerland Jane Hsu; Chih-Wen Hsueh; Patrick Hung; Junichi Iijima; James Joshi; Chun-hung Li; Haifei Li; Qing Li; Ziqi Liao; Fu-Ren Lin; Chao-Lin Liu; Jiming Liu; Zakaria Maamar; Clemens Martin; Miguel Vargas Martin,Fahim Akhter; Zayed University; United Arab Emirates Ali Arsanjani; SOA & Web services Centerof Excellence; IBM Corporation; USA Carminati Barbara; Universita degli Studi dell'Insubria;Italty Boualem Benatallah; The University of New South Wales; Australia DjamalBenslimane; Universite Claude Bernard Lyon 1; France M. Brian Blake; GeorgetownUniversity; Washington DC; USA David Bodoff; The Hong Kong University of Science andTechnology; Hong Kong Christoph Bussler; National University of Ireland; Galway; Ireland ChristerCarlsson; Abo Academi University; Finland Fabio Casati; Intelligent Enterprise TechnologyLab; Hewlett-Packard Company; USA Malu Castellanos; Hewlett-Packard Company; USA StephenChan; Hong Kong Baptist University; Hong Kong Kuo-Ming Chao; Coventry University; UK PatrickChau; The University of Hong Kong; Hong Kong Kung Chen; National Chengchi …,*,*,*
Self-Organizing Linked Data,Philippe Cudré-Mauroux; Hermann de Meer,Abstract. We tackle the problem of disambiguating entities on the Web. We propose a user-driven scheme where graphs of entities–represented by globally identifiable declarativeartifacts–self-organize in a dynamic and probabilistic manner. Our solution has the followingtwo desirable properties: i) it lets end-users freely define associations between arbitraryentities and ii) it probabilistically infers entity relationships based on uncertain links usingconstraint-satisfaction mechanisms.,*,*,*
Graph-Based Analyses of Large-Scale Social Data,Philippe Cudré-Mauroux; Saket Sathe,Abstract. In this paper; we make an attempt at analyzing the semantic mediation layer oflarge-scale online networks in a holistic way using graph theoretic tools. We model Peer-to-Peer data networks as graphs; derive a necessary condition to foster semanticinteroperability in the large in such graphs; and test our heuristics in the context of anexisting bioinformatic portal with hundreds of different schemas.,*,*,*
Position Paper (EPFL Technical Report IC/2003/13) PIX-Grid: A Platform for P2P Photo Exchange,Karl Aberer; Philippe Cudré-Mauroux; Anwitaman Datta; Manfred Hauswirth,Abstract. The proliferation of digital camera devices (stand-alone or combined with cellphones); new protocols such as MMS and the desire of people to communicate and sharetheir experience calls for new systems to support these needs in new Internet-scaleinfrastructures. In this paper we outline our plans for a Internet-scale P2P system thatenables users to share (globally or only within a group) and efficiently locate photographsbased on semi-automatically provided meta-information (by the devices and the user).,*,*,*
PicShark: Emergent Semantics Processes to Recontextualize Semi-Structured Metadata in Large Scale Media Sharing Environments,Philippe Cudré-Mauroux; Karl Aberer; Adriana Budura; Manfred Hauswirth,ABSTRACT With the ubiquitous availability of communication devices; personal informationand media sharing is becoming a key functionality of the pervasive Web. In this context;publishing and searching for media content heavily relies on the availability of meaningfulmetadata. Metadata scarcity and heterogeneity are among the major obstacles hamperingmeaningful media sharing in large communities. However; participating in a communityopens new perspectives for addressing metadata scarcity and heterogeneity throughsharing of semantic knowledge and metadata. Taking advantage of this opportunity; weprovide a solution to those two problems through a bottom-up; community-based andselforganizing recontextualization process in which information entropy–in terms of missingand heterogeneous metadata–is gradually alleviated. Our information recontextualization …,*,*,*
Position Paper PIX-Grid: A Platform for P2P Photo Exchange,Karl Aberer; Philippe Cudré-Mauroux; Anwitaman Datta; Manfred Hauswirth,Abstract. The proliferation of digital camera devices (stand-alone or combined with cellphones); new protocols such as MMS and the desire of people to communicate and sharetheir experience call for new systems to support these needs in new Internet-scaleinfrastructures. In this paper we outline our plans for an Internet-scale P2P system thatenables users to share (globally or only within a group) and efficiently locate photographsbased on semi-automatically provided meta-information (by the devices and the user).,*,*,*
