Big data and cloud computing: current state and future opportunities,Divyakant Agrawal; Sudipto Das; Amr El Abbadi,Abstract Scalable database management systems (DBMS)---both for update intensiveapplication workloads as well as decision support systems for descriptive and deepanalytics---are a critical part of the cloud infrastructure and play an important role in ensuringthe smooth transition of applications from the traditional enterprise infrastructures to nextgeneration cloud infrastructures. Though scalable data management has been a vision formore than three decades and much research has focussed on large scale datamanagement in traditional enterprise setting; cloud computing brings its own set of novelchallenges that must be addressed to ensure the success of data management solutions inthe cloud environment. This tutorial presents an organized picture of the challenges faced byapplication developers and DBMS designers in developing and deploying internet scale …,Proceedings of the 14th International Conference on Extending Database Technology,2011,509
Advanced transaction models in workflow contexts,Gustavo Alonso; Divyakant Agrawal; Amr El Abbadi; Mohan Kamath; Roger Gunthor; Chandrasekaran Mohan,In recent years; numerous transaction models have been proposed to address the problemsposed by advanced database applications; but only a few of these models are being used incommercial products. In this paper; we make the case that such models may be too centeredaround databases to be useful in real environments. Advanced applications raise a varietyof issues that are not addressed at all by transaction models. These same issues; however;are the basis for existing workflow systems; which are having considerable success ascommercial products in spite of not having a solid theoretical foundation. We explore someof these issues and show that; in many aspects; workflow models are a superset oftransaction models and have the added advantage of incorporating a variety of ideas thathave so far remained outside the scope of traditional transaction processing.,Data Engineering; 1996. Proceedings of the Twelfth International Conference on,1996,448
Efficient computation of frequent and top-k elements in data streams,Ahmed Metwally; Divyakant Agrawal; Amr El Abbadi,Abstract We propose an integrated approach for solving both problems of finding the mostpopular k elements; and finding frequent elements in a data stream. Our technique isefficient and exact if the alphabet under consideration is small. In the more practical largealphabet case; our solution is space efficient and reports both top-k and frequent elementswith tight guarantees on errors. For general data distributions; our top-k algorithm can returna set of k′ elements; where k′≈ k; which are guaranteed to be the top-k'elements; and weuse minimal space for calculating frequent elements. For realistic Zipfian data; our spacerequirement for the frequent elements problem decreases dramatically with the parameter ofthe distribution; and for top-k queries; we ensure that only the top-k elements; in the correctorder; are reported. Our experiments show significant space reductions with no loss in …,International Conference on Database Theory,2005,420
Meghdoot: content-based publish/subscribe over P2P networks,Abhishek Gupta; Ozgur D Sahin; Divyakant Agrawal; Amr El Abbadi,Abstract Publish/Subscribe systems have become a prevalent model for delivering data fromproducers (publishers) to consumers (subscribers) distributed across wide-area networkswhile decoupling the publishers and the subscribers from each other. In this paper wepresent Meghdoot; which adapts content-based publish/subscribe systems to DistributedHash Table based P2P networks in order to provide scalable content delivery mechanismswhile maintaining the decoupling between the publishers and the subscribers. Meghdoot isdesigned to adapt to highly skewed data sets; which is typical of real applications. Theexperimental results demonstrate that Meghdoot balances the load among the peers andthe design scales well with increasing number of peers; subscriptions and events.,ACM/IFIP/USENIX International Conference on Distributed Systems Platforms and Open Distributed Processing,2004,409
An efficient and fault-tolerant solution for distributed mutual exclusion,Divyakant Agrawal; Amr El Abbadi,Abstract In this paper; we present an efficient and fault-tolerant algorithm for generatingquorums to solve the distributed mutual exclusion problem. The algorithm uses a logical treeorganization of the network to generate tree quorums; which are logarithmic in the size of thenetwork in the best case. Our approach is resilient to both site and communication failures;even when such failures lead to network partitioning. Furthermore; the algorithm exhibits aproperty of graceful degradation; ie; it requires more messages only as the number offailures increase in the network. We describe how tree quorums can be used for variousdistributed applications for providing mutually exclusive access to a distributed resource;managing replicated objects; and atomically commiting a distributed transaction.,ACM Transactions on Computer Systems (TOCS),1991,400
Limiting the spread of misinformation in social networks,Ceren Budak; Divyakant Agrawal; Amr El Abbadi,Abstract In this work; we study the notion of competing campaigns in a social network andaddress the problem of influence limitation where a" bad" campaign starts propagating froma certain node in the network and use the notion of limiting campaigns to counteract theeffect of misinformation. The problem can be summarized as identifying a subset ofindividuals that need to be convinced to adopt the competing (or" good") campaign so as tominimize the number of people that adopt the" bad" campaign at the end of both propagationprocesses. We show that this optimization problem is NP-hard and provide approximationguarantees for a greedy solution for various definitions of this problem by proving that theyare submodular. We experimentally compare the performance of the greedy method tovarious heuristics. The experiments reveal that in most cases inexpensive heuristics such …,Proceedings of the 20th international conference on World wide web,2011,387
Functionality and limitations of current workflow management systems,Gustavo Alonso; Divyakant Agrawal; Amr El Abbadi; Carl Mohan,Abstract Work ow systems hold the promise of facilitating the everyday operation of manyenterprises and work environments. As a result; many commercial work ow managementsystems have been developed. These systems; although useful; do not scale well; havelimited fault-tolerance; and are in exible in terms of interoperating with other work owsystems. In this paper; we discuss the limitations of contemporary work ow managementsystems; and then elaborate on various directions for research and potential futureextensions to the design and modeling of work ow management systems.,IEEE expert,1997,379
Efficient view maintenance at data warehouses,Divyakant Agrawal; Amr El Abbadi; Ambuj Singh; Tolga Yurek,Abstract We present incremental view maintenance algorithms for a data warehouse derivedfrom multiple distributed autonomous data sources. We begin with a detailed framework foranalyzing view maintenance algorithms for multiple data sources with concurrent updates.Earlier approaches for view maintenance in the presence of concurrent updates typicallyrequire two types of messages: one to compute the view change due to the initial updateand the other to compensate the view change due to interfering concurrent updates. Thealgorithms developed in this paper instead perform the compensation locally by using theinformation that is already available at the data warehouse. The first algorithm; termedSWEEP; ensures complete consistency of the view at the data warehouse in the presence ofconcurrent updates. Previous algorithms for incremental view maintenance either …,ACM SIGMOD Record,1997,374
An efficient; fault-tolerant protocol for replicated data management,Amr El Abbadi; Dale Skeen; Flaviu Cristian,ABSTRACT The objective of data replication is to increase data availability in the presenceof processor and link failures and to decrease data retrieval costs by reading local or closecopies of data. Moreover; concurrent execution of transactions on replicated data basesmust be equivalent to the serial execution of the same transactions on non-replicateddatabases. We present a pedagogical derivation of a replicated data management protocolwhich meets the above requirements. The protocol tolerates any number of componentomission and performance failures (even when these lead to network partitioning); andhandles any number of (possibly simultaneous) processor and link recoveries. It implementsthe reading of a logical object efficiently--by reading the nearest; available copy. Whenreads outnumber writes and failures are rare; the protocol performs better than other …,Proceedings of the fourth ACM SIGACT-SIGMOD symposium on Principles of database systems,1985,302
Reverse nearest neighbor queries for dynamic databases.,Ioana Stanoi; Divyakant Agrawal; Amr El Abbadi,Abstract In this paper we propose an algorithm for answering reverse nearest neighbor(RNN) queries; a problem formulated only recently. This class of queries is strongly relatedto that of nearest neighbor (NN) queries; although the two are not necessarilycomplementary. Unlike nearest neighbor queries; RNN queries find the set of databasepoints that have the query point as the nearest neighbor. There is no other proposal we areaware of; that provides an algorithmic approach to answer RNN queries. The earlierapproach for RNN queries (KM99]) is based on the pre-computation of neighborhoodinformation that is organized in terms of auxiliary data structures. It can be argued that theprecomputation of the RNN information for all points in the database can be too restrictive. Inthe case of dynamic databases; insert and update operations are expensive and can lead …,ACM SIGMOD workshop on research issues in data mining and knowledge discovery,2000,282
Exotica/FMQM: A persistent message-based architecture for distributed workflow management,Gustavo Alonso; C Mohan; Roger Günthör; Divyakant Agrawal; Amr El Abbadi; Mohan Kamath,Abstract In the past few years there has been an increasing interest in workflow applicationsas a way of supporting complex business processes in modern corporations. Given thenature of the environment and the technology involved; workflow applications are inherentlydistributed and pose many interesting challenges to the system designer. In most cases; aclient/server architecture is used in which knowledge about the processes being executed iscentralized in one node to facilitate monitoring; auditing; and to simplify synchronization. Inthis paper; we explore a novel distributed architecture; Exotica/FMQM; for workflow systemsin which the need for such a centralized database is eliminated. Instead; we use persistentmessages as the means to store the information relevant to the execution of a businessprocess. Our approach is to completely distribute the execution of a process so individual …,*,1995,282
A comparison of DFT and DWT based similarity search in time-series databases,Yi-Leh Wu; Divyakant Agrawal; Amr El Abbadi,ABSTRACT Similarity search in time-series databases has received significant attentionlately. P opular tec hniques for efficient retrieval of time sequences in time-series databaseshas been to use Discrete Fourier Transform (DFT). Recently; the Discrete Wavelet Transform (DWT) has gained popular interest in database domain and several proposalshave been made to replace DFT by DWT for similarity search over time-series databases. Inthis paper; we explore the feasibility of replacing DFT by DWT with a comprehensiveanalysis of the DFT and DWT as matching functions in time-series databases. Our resultsshow that although the DWT based technique has several adv antages; eg; the D WThascomplexity of O (N) whereas DFT is O (N log N); D WT does not reduce relativ e matchingerror and does not increase query precision in similarity search as suggested by previous …,Proceedings of the ninth international conference on Information and knowledge management,2000,274
G-store: a scalable data store for transactional multi key access in the cloud,Sudipto Das; Divyakant Agrawal; Amr El Abbadi,Abstract Cloud computing has emerged as a preferred platform for deploying scalable web-applications. With the growing scale of these applications and the data associated withthem; scalable data management systems form a crucial part of the cloud infrastructure. Key-Value stores--such as Bigtable; PNUTS; Dynamo; and their open source analogues--havebeen the preferred data stores for applications in the cloud. In these systems; data isrepresented as Key-Value pairs; and atomic access is provided only at the granularity ofsingle keys. While these properties work well for current applications; they are insufficient forthe next generation web applications--such as online gaming; social networks; collaborativeediting; and many more--which emphasize collaboration. Since collaboration by definitionrequires consistent access to groups of keys; scalable and consistent multi key access is …,Proceedings of the 1st ACM symposium on Cloud computing,2010,264
Approximate Range Selection Queries in Peer-to-Peer systems.,Abhishek Gupta; Divyakant Agrawal; Amr El Abbadi,Abstract We present an architecture for a data sharing peer-to-peer system where the data isshared in the form of database relations. In general; peer-to-peer systems try to locateexactmatch data objects to simple user queries. Since peer-to-peer users generally tend tosubmit broad queries in order to find data of their interest; we develop a P2P data sharingarchitecture for computing approximate answers for the complex queries by finding dataranges that are similar to the user query. Thus this paper represents the first step towardssolving the general range lookup problem over P2P systems instead of exact lookupoperations.,CIDR,2003,251
Zephyr: live migration in shared nothing databases for elastic cloud platforms,Aaron J Elmore; Sudipto Das; Divyakant Agrawal; Amr El Abbadi,Abstract Multitenant data infrastructures for large cloud platforms hosting hundreds ofthousands of applications face the challenge of serving applications characterized by smalldata footprint and unpredictable load patterns. When such a platform is built on an elasticpay-per-use infrastructure; an added challenge is to minimize the system's operating costwhile guaranteeing the tenants' service level agreements (SLA). Elastic load balancing istherefore an important feature to enable scale-up during high load while scaling down whenthe load is low. Live migration; a technique to migrate tenants with minimal serviceinterruption and no downtime; is critical to allow lightweight elastic scaling. We focus on theproblem of live migration in the database layer. We propose Zephyr; a technique toefficiently migrate a live database in a shared nothing transactional database architecture …,Proceedings of the 2011 ACM SIGMOD International Conference on Management of data,2011,223
ElasTraS: An Elastic Transactional Data Store in the Cloud.,Sudipto Das; Amr El Abbadi; Divyakant Agrawal,Abstract Over the last couple of years;“Cloud Computing” or “Elastic Computing” hasemerged as a compelling and successful paradigm for internet scale computing. One of themajor contributing factors to this success is the elasticity of resources. In spite of the elasticityprovided by the infrastructure and the scalable design of the applications; the elephant (orthe underlying database); which drives most of these web-based applications; is not veryelastic and scalable; and hence limits scalability. In this paper; we propose ElasTraS whichaddresses this issue of scalability and elasticity of the data store in a cloud computingenvironment to leverage from the elastic nature of the underlying infrastructure; whileproviding scalable transactional data access. This paper aims at providing the design of asystem in progress; highlighting the major design choices; analyzing the different …,HotCloud,2009,223
Database management as a service: Challenges and opportunities,Divyakant Agrawal; Amr El Abbadi; Fatih Emekci; Ahmed Metwally,Data outsourcing or database as a service is a new paradigm for data management in whicha third party service provider hosts a database as a service. The service provides datamanagement for its customers and thus obviates the need for the service user to purchaseexpensive hardware and software; deal with software upgrades and hire professionals foradministrative and maintenance tasks. Since using an external database service promisesreliable data storage at a low cost it is very attractive for companies. Such a service wouldalso provide universal access; through the Internet to private data storedat reliable andsecure sites. A client would store their data; and not need to carry their data with them asthey travel. They would also not need to log remotely to their home machines; which maysuffer from crashes and be unavailable. However; recent governmental legislations …,Data Engineering; 2009. ICDE'09. IEEE 25th International Conference on,2009,211
Epidemic algorithms in replicated databases,Divyakant Agrawal; Amr El Abbadi; Robert C Steinke,We present a family of epidemic algorithms for maintaining replicated data in a transactionalframework. The algorithms are based on the causal delivery of log records where eachrecord corresponds to one transaction instead of one operation. The fist algorithm in thisfamily is a pessimistic protocol that ensures serializability and guarantees strict executions.Since we expect the epidemic algorithms to be used in environments with low probability ofconflicts among transactions; we develop a variant of the pessimistic algorithm in whichlocks are released as soon as transactions finish their execution locally. However; thisoptimistic releasing of locks introduces the possibility of cascading aborts while ensuringserializable executions. The last member of thii family of epidemic algorithms is motivatedfrom the need for asynchronous replication solutions that are being increasingly used in …,Proceedings of the sixteenth ACM SIGACT-SIGMOD-SIGART symposium on Principles of database systems,1997,209
Parallelizing skyline queries for scalable distribution,Ping Wu; Caijie Zhang; Ying Feng; Ben Y Zhao; Divyakant Agrawal; Amr El Abbadi,Abstract Skyline queries help users make intelligent decisions over complex data; wheredifferent and often conflicting criteria are considered. Current skyline computation methodsare restricted to centralized query processors; limiting scalability and imposing a single pointof failure. In this paper; we address the problem of parallelizing skyline query execution overa large number of machines by leveraging content-based data partitioning. We present anovel distributed skyline query processing algorithm (DSL) that discovers skyline pointsprogressively. We propose two mechanisms; recursive region partitioning and dynamicregion encoding; to enforce a partial order on query propagation in order to pipeline queryexecution. Our analysis shows that DSL is optimal in terms of the total number of local queryinvocations across all machines. In addition; simulations and measurements of a …,International Conference on Extending Database Technology,2006,203
Implementing fault-tolerant distributed objects,Kenneth P Birman; Thomas A Joseph; Thomas Raeuchle; Amr El Abbadi,This paper describes a technique for implementing k-resilient objects–distributed objectsthat remain available; and whose operations are guaranteed to progress to completion;despite up to k site failures. The implementation is derived from the object specificationautomatically; and does not require any information beyond what would be required for anonresilient nondistributed implementation. It is therefore unnecessary for an applicationsprogrammer to have knowledge of the complex protocols nonnally employed to implementfault-tolerant objects. Our technique is used in ISIS; a system being developed at Cornell tosupport resilient objects.,IEEE Transactions on Software Engineering,1985,201
The Tree Quorum Protocol: An Efficient Approach for Managing Replicated Data.,Divyakant Agrawal; Amr El Abbadi,Abstract In this paper; we present an efficient algorithm for managing replicated data. Weimpose a logical tree structure on the set of copies of an object. In a failurefree environmentthe protocol executes read operations by reading one copy of an object while guaranteeingfault-tolerance of write operations. It also exhibits the property of graceful degradation; ie;communication costs are minimal in a failure-free environment but may increase as failuresoccur. This approach in designing distributed systems is desirable since it providesfaulttolerance without imposing unnecessary costs on the failure-free mode of operations.,VLDB,1990,200
Exploiting atomic broadcast in replicated databases,Divyakant Agrawal; Gustavo Alonso; Amr El Abbadi; Ioana Stanoi,In spite of the fact that many applications require replicated databases either forperformance or fault-tolerance; replication has remained a research issue until recently.Today; the demand for practical replication schemes has greatly increased and some simpleprotocols are being implemented in databases (Oracle and Sybase; for instance) or inapplication development tools (Lotus Notes). These; however; are ad hoc implementationsand the issue of replicated data management is still a source of controversy amongdatabase practitioners and researchers. On one hand; traditional synchronous protocols aretoo expensive in terms of message cost and communication latency; and they aresusceptible to deadlocks when compared to non-replicated databases. An alternativeapproach based on asynchronous updates may result in inconsistencies and an ever …,European Conference on Parallel Processing,1997,180
Maintaining availability in partitioned replicated databases,A El Abbadi; Sam Toueg,Abstract In a replicated database; a data item may have copies residing on several sites. Areplica control protocol is necessary to ensure that data items with several copies behave asif they consist of a single copy; as far as users can tell. We describe a new replica controlprotocol that allows the accessing of data in spite of site failures and network partitioning.This protocol provides the database designer with a large degree of flexibility in deciding thedegree of data availability; as well as the cost of accessing data.,ACM Transactions on Database Systems (TODS),1989,179
A peer-to-peer framework for caching range queries,Ozgur D Sahin; Abhishek Gupta; Divyakant Agrawal; Amr El Abbadi,Peer-to-peer systems are mainly used for object sharing although they can provide theinfrastructure for many other applications. We extend the idea of object sharing to datasharing on a peer-to-peer system. We propose a method; which is based on themultidimensional CAN system; for efficiently evaluating range queries. The answers of therange queries are cached at the peers and are used to answer future range queries. Thescalability and efficiency of our design is shown through simulation.,Data Engineering; 2004. Proceedings. 20th International Conference on,2004,174
An integrated efficient solution for computing frequent and top-k elements in data streams,Ahmed Metwally; Divyakant Agrawal; Amr El Abbadi,Abstract We propose an approximate integrated approach for solving both problems offinding the most popular k elements; and finding frequent elements in a data stream comingfrom a large domain. Our solution is space efficient and reports both frequent and top-kelements with tight guarantees on errors. For general data distributions; our top-k algorithmreturns k elements that have roughly the highest frequencies; and it uses limited space forcalculating frequent elements. For realistic Zipfian data; the space requirement of theproposed algorithm for solving the exact frequent elements problem decreases dramaticallywith the parameter of the distribution; and for top-k queries; the analysis ensures that onlythe top-k elements; in the correct order; are reported. The experiments; using real andsynthetic data sets; show space reductions with hardly any loss in accuracy. Having …,ACM Transactions on Database Systems (TODS),2006,157
Discovery of influence sets in frequently updated databases,Ioana Stanoi; Mirek Riedewald; Divyakant Agrawal; Amr El Abbadi,Abstract An increasing number of organizations are currently working on ways to expressand provide location infor-mation to services and applications. A location aware systemknows the position of each component; and it is able to track devices through changes dueto movement. In this context; data management issues such as efficient storage and retrievalof data through frequent updates pose new challenges. While we believe that spatialqueries in general are going to gain in importance due to the emerging type of applications;we are particularly interested in the discovery of influence regions and influence sets arounda query point. An influence set is formed by all points that have q as their nearest neighbor;and are located within the boundaries of an influence region. In this paper we pro-pose forthe first time a technique that reduces such a query to the more familiar nearest neighbor …,VLDB,2001,156
Albatross: lightweight elasticity in shared storage databases for the cloud using live data migration,Sudipto Das; Shoji Nishimura; Divyakant Agrawal; Amr El Abbadi,Abstract Database systems serving cloud platforms must serve large numbers ofapplications (or tenants). In addition to managing tenants with small data footprints; differentschemas; and variable load patterns; such multitenant data platforms must minimize theiroperating costs by efficient resource sharing. When deployed over a pay-per-useinfrastructure; elastic scaling and load balancing; enabled by low cost live migration oftenant databases; is critical to tolerate load variations while minimizing operating cost.However; existing databases---relational databases and Key-Value stores alike---lack lowcost live migration techniques; thus resulting in heavy performance impact during elasticscaling. We present Albatross; a technique for live migration in a multitenant databaseserving OLTP style workloads where the persistent database image is stored in a network …,Proceedings of the VLDB Endowment,2011,152
MD-HBase: A scalable multi-dimensional data infrastructure for location aware services,Shoji Nishimura; Sudipto Das; Divyakant Agrawal; Amr El Abbadi,The ubiquity of location enabled devices has resulted in a wide proliferation of locationbased applications and services. To handle the growing scale; database managementsystems driving such location based services (LBS) must cope with high insert rates forlocation updates of millions of devices; while supporting efficient real-time analysis on latestlocation. Traditional DBMSs; equipped with multi-dimensional index structures; canefficiently handle spatio-temporal data. However; popular open source relational databasesystems are overwhelmed by the high insertion rates; real-time querying requirements; andterabytes of data that these systems must handle. On the other hand; Key-value stores caneffectively support large scale operation; but do not natively support multi-attribute accessesneeded to support the rich querying functionality essential for the LBSs. We present MD …,Mobile Data Management (MDM); 2011 12th IEEE International Conference on,2011,150
Vector approximation based indexing for non-uniform high dimensional data sets,Hakan Ferhatosmanoglu; Ertem Tuncel; Divyakant Agrawal; Amr El Abbadi,Abstract With the proliferation of multimedia data; there is increasing need to support theindexing and searching of high dimensional data. Recently; a vector appro ximationbasedtechnique called VA-file has been proposed for indexing high dimensional data. It has beenshown that the VA-file is an effective technique compared to the current approaches basedon space and data partitioning. The VA-file gives good performance especially when thedata set is uniformly distributed. Real data sets are not uniformly distributed; are oftenclustered; and the dimensions of the feature vectors in real data sets are usually correlated.More careful analysis for nonuniform or correlated data is needed for effectively indexinghigh dimensional data. We propose a solution to these problems and propose the VA+-file; anew technique for indexing high dimensional data sets based on vector approximations …,Proceedings of the ninth international conference on Information and knowledge management,2000,150
Duplicate detection in click streams,Ahmed Metwally; Divyakant Agrawal; Amr El Abbadi,Abstract We consider the problem of finding duplicates in data streams. Duplicate detectionin data streams is utilized in various applications including fraud detection. We develop asolution based on Bloom Filters [9]; and discuss the space and time requirements forrunning the proposed algorithm in both the contexts of sliding; and landmark streamwindows. We run a comprehensive set of experiments; using both real and synthetic clickstreams; to evaluate the performance of the proposed solution. The results demonstrate thatthe proposed solution yields extremely low error rates.,Proceedings of the 14th international conference on World Wide Web,2005,142
Constrained nearest neighbor queries,Hakan Ferhatosmanoglu; Ioanna Stanoi; Divyakant Agrawal; Amr El Abbadi,Abstract In this paper we introduce the notion of constrained nearest neighbor queries(CNN) and propose a series of methods to answer them. This class of queries can bethought of as nearest neighbor queries with range constraints. Although both nearestneighbor and range queries have been analyzed extensively in previous literature; theimplications of constrained nearest neighbor queries have not been discussed. Due to theirversatility; CNN queries are suitable to a wide range of applications from GIS systems toreverse nearest neighbor queries and multimedia applications. We develop methods foranswering CNN queries with different properties and advantages. We prove the optimality(with respect to I/O cost) of one of the techniques proposed in this paper. The superiority ofthe proposed technique is shown by a performance analysis.,International Symposium on Spatial and Temporal Databases,2001,141
Availability in partitioned replicated databases,Amr El Abbadi; Sam Toueg,ABSTRACT In a replicated database; a data item may be distributed at several sites. Areplica control protocol is necessary to ensure that data items with several copies behave asif they consist of a single copy; as far as users can tell. We describe a replica control protocolthat allows the accessing of data in spite of site failures and network partitioning. The newsolution is more efficient and more flexible than previous ones; while providing at least thesame degree of data availability.,Proceedings of the fifth ACM SIGACT-SIGMOD symposium on Principles of database systems,1985,137
Failure handling in large scale workflow management systems,Gustavo Alonso; Mohan Kamath; Divyakant Agrawal; Amr El Abbadi; R Günthör; C Mohan,ABSTRACT: Work ow management deals with the coordinated execution of businessprocesses. These processes are often of long duration; weeks or even months; are verylarge; involving many agents and distributed resources; and critical to the enterprise. Asorganizations adopt work ow technology; they become increasingly dependent on thesystem to carry on their daily business activities. Hence; a work ow management system;WFMS; must provide availability; reliability and scalability to cope with environments wherethe range of potential failures is very broad; from system failures to semantic failures. In thispaper; in the context of IBM's Exotica project; we propose a new architecture to address theavailability and scalability issues; and to deal with system failures such as site andcommunication failures. We also discuss how features of advanced transaction models …,IBM Research Report RJ9913,1994,135
Efficient solution to the distributed mutual exclusion problem,Divyakant Agrawal; Amr El Abbadi,Abstract We present an efficient fault-tolerant solution to the distributed mutual exclusionproblem. Our protocol requires logn messages in the best case and is resilient to both siteand communication failures; even when such failures lead to network partitioning.Furthermore; the protocol exhibits a property of graceful degradation; ie; it requires moremessage only as the number of failures increase in the network.,Proceedings of the eighth annual ACM Symposium on Principles of distributed computing,1989,131
A peer-to-peer framework for web service discovery with ranking,Fatih Emekci; Ozgur D Sahin; Divyakant Agrawal; Amr El Abbadi,Current Web service discovery methods are based on centralized approaches where Webservices are identified based on service functionality. Examples of service functionalityinclude car rental; hotel booking and book selling. Since higher level Web services areincreasingly composed in terms of lower level Web services; it is important that servicediscovery not only be based on service functionality but also be based on process behavior;ie; how a service functionality is served. Furthermore; centralized approaches to servicediscovery suffer from problems such as high operational and maintenance cost; single pointof failure; and scalability. Another issue that has not been considered in current Web servicediscovery paradigms is the issue of trust and quality of service of the service provider. We;therefore; propose a structured peer-to-peer framework for Web service discovery in …,Web Services; 2004. Proceedings. IEEE International Conference on,2004,130
Approximate nearest neighbor searching in multimedia databases,Hakan Ferhatosmanoglu; Ertem Tuncel; Divyakant Agrawal; Amr El Abbadi,Develops a general framework for approximate nearest-neighbor queries. We categorize thecurrent approaches for nearest-neighbor query processing based on either their ability toreduce the data set that needs to be examined; or their ability to reduce the representationsize of each data object. We first propose modifications to well-known techniques to supportthe progressive processing of approximate nearest-neighbor queries. A user may thereforestop the retrieval process once enough information has been returned. We then develop anew technique based on clustering that merges the benefits of the two general classes ofapproaches. Our cluster-based approach allows a user to progressively explore theapproximate results with increasing accuracy. We propose a new metric for evaluation ofapproximate nearest-neighbor searching techniques. Using both the proposed and the …,Data Engineering; 2001. Proceedings. 17th International Conference on,2001,129
Epidemic algorithms for replicated databases,JoAnne Holliday; Robert Steinke; Divyakant Agrawal; Amr El Abbadi,We present a family of epidemic algorithms for maintaining replicated database systems.The algorithms are based on the causal delivery of log records where each recordcorresponds to one transaction instead of one operation. The first algorithm in this family is apessimistic protocol that ensures serializability and guarantees strict executions. Since weexpect the epidemic algorithms to be used in environments with low probability of conflictsamong transactions; we develop a variant of the pessimistic algorithm which is optimistic inthat transactions commit as soon as they terminate locally and inconsistencies are detectedasynchronously as the effects of committed transactions propagate through the system. Thelast member of the family of epidemic algorithms is pessimistic and uses voting withquorums to resolve conflicts and improve transaction response time. A simulation study …,IEEE Transactions on Knowledge and Data Engineering,2003,127
The dynamic data cube,Steven Geffner; Divakant Agrawal; Amr El Abbadi,Abstract Range sum queries on data cubes are a powerful tool for analysis. A range sumquery applies an aggregation operation (eg; SUM; AVERAGE) over all selected cells in adata cube; where the selection is specified by providing ranges of values for numericdimensions. We present the Dynamic Data Cube; a new approach to range sum querieswhich provides efficient performance for both queries and updates; which handles clusteredand sparse data gracefully; and which allows for the dynamic expansion of the data cube inany direction.,International Conference on Extending Database Technology,2000,126
Detectives: detecting coalition hit inflation attacks in advertising networks streams,Ahmed Metwally; Divyakant Agrawal; Amr El Abbadi,Abstract Click fraud is jeopardizing the industry of Internet advertising. Internet advertising iscrucial for the thriving of the entire Internet; since it allows producers to advertise theirproducts; and hence contributes to the well being of e-commerce. Moreover; advertisingsupports the intellectual value of the Internet by covering the running expenses of publishingcontent. Some content publishers are dishonest; and use automation to generate traffic todefraud the advertisers. Similarly; some advertisers automate clicks on the advertisements oftheir competitors to deplete their competitors' advertising budgets. This paper describes theadvertising network model; and focuses on the most sophisticated type of fraud; whichinvolves coalitions among fraudsters. We build on several published theoretical results todevise the Similarity-Seeker algorithm that discovers coalitions made by pairs of …,Proceedings of the 16th international conference on World Wide Web,2007,123
Relative prefix sums: An efficient approach for querying dynamic OLAP data cubes,Steven Geffner; Divyakant Agrawal; Amr El Abbadi; Terry Smith,Range sum queries on data cubes are a powerful tool for analysis. A range sum queryapplies an aggregation operation (eg; SUM) over all selected cells in a data cube; where theselection is specified by providing ranges of values for numeric dimensions. Manyapplication domains require that information provided by analysis tools be current or" near-current." Existing techniques for range sum queries on data cubes; however; can incurupdate costs on the order of the size of the data cube. Since the size of a data cube isexponential in the number of its dimensions; rebuilding the entire data cube can be verycostly. We present an approach that achieves constant time range sum queries whileconstraining update costs. Our method reduces the overall complexity of the range sumproblem.,Data Engineering; 1999. Proceedings.; 15th International Conference on,1999,122
The generalized tree quorum protocol: an efficient approach for managing replicated data,Divyakant Agrawal; Amr El Abbadi,Abstract In this paper; we present a low-cost fault-tolerant protocol for managing replicateddata. We impose a logical tree structure on the set of copies of an object and develop aprotocol that uses the information available in the logical structure to reduce thecommunication requirements for read and write operations. The tree quorum protocol is ageneralization of the static voting protocol with two degrees of freedom for choosingquorums. In general; this results in significantly lower communication costs for comparabledata availability. The protocol exhibits the property of graceful degradation; ie;communication costs for executing operations are minimal in a failure-free environment butmay increase as failures occur. This approach in designing distributed systems is desirablesince it provides fault-tolerance without imposing unnecessary costs on the failure-free …,ACM Transactions on Database Systems (TODS),1992,120
Data management challenges in cloud computing infrastructures,Divyakant Agrawal; Amr El Abbadi; Shyam Antony; Sudipto Das,Abstract The challenge of building consistent; available; and scalable data managementsystems capable of serving petabytes of data for millions of users has confronted the datamanagement research community as well as large internet enterprises. Current proposedsolutions to scalable data management; driven primarily by prevalent applicationrequirements; limit consistent access to only the granularity of single objects; rows; or keys;thereby trading off consistency for high scalability and availability. But the growing popularityof “cloud computing”; the resulting shift of a large number of internet applications to thecloud; and the quest towards providing data management services in the cloud; has openedup the challenge for designing data management systems that provide consistencyguarantees at a granularity larger than single rows and keys. In this paper; we analyze …,International Workshop on Databases in Networked Information Systems,2010,114
Convergence rates of distributed average consensus with stochastic link failures,Stacy Patterson; Bassam Bamieh; Amr El Abbadi,We consider a distributed average consensus algorithm over a network in whichcommunication links fail with independent probability. In such stochastic networks;convergence is defined in terms of the variance of deviation from average. We first showhow the problem can be recast as a linear system with multiplicative random inputs whichmodel link failures. We then use our formulation to derive recursion equations for the secondorder statistics of the deviation from average in networks with and without additive noise. Wegive expressions for the convergence behavior in the asymptotic limits of small failureprobability and large networks. We also present simulation-free methods for computing thesecond order statistics in each network model and use these methods to study the behaviorof various network examples as a function of link failure probability.,IEEE Transactions on Automatic Control,2010,113
Hardware acceleration in commercial databases: A case study of spatial operations,Nagender Bandi; Chengyu Sun; Divyakant Agrawal; Amr El Abbadi,Abstract Traditional databases have focused on the issue of reducing I/O cost as it is thebottleneck in many operations. As databases become increasingly accepted in areas suchas Geographic Information Systems (GIS) and Bioinformatics; commercial DBMS need tosupport data types for complex data such as spatial geometries and protein structures.These non-conventional data types and their associated operations present newchallenges. In particular; the computational cost of some spatial operations can be orders ofmagnitude higher than the I/O cost. In order to improve the performance of spatial queryprocessing; innovative solutions for reducing this computational cost are beginning toemerge. Recently; it has been proposed that hard-ware acceleration of an off-the-shelfgraphics card can be used to reduce the computational cost of spatial operations …,Proceedings of the Thirtieth international conference on Very large data bases-Volume 30,2004,105
Exotica/FMDC: Handling disconnected clients in a workflow management system,Gustavo Alonso; G Alonso; Roger Gunthor; Divy Agrawal; Amr El Abbadi; Mohan Kamath; D Agrawal; A El Abbadi; C Mohan,Abstract Workflow Management Systems (WFMS) are a first generation of products thatattempt to manage the execution of business processes by large numbers of usersdistributed over a wide area and using heterogeneous resources. They are a very promisingvenue for collaborative systems but; in most cases; the autonomy of the users is greatlyrestricted due to architectural and design considerations. This is a severe restriction;especially when considering the emergence of mobile computing; and the increase in use oflaptops and small computers which are connected to a network only occasionally. In thispaper; we discuss how disconnected workflow clients can be supported while preserving thecorrectness of the overall execution and allowing coordinated interactions between thedifferent users. Disconnected client support provides a great deal of flexibility in the …,*,1995,102
ElasTraS: An elastic; scalable; and self-managing transactional database for the cloud,Sudipto Das; Divyakant Agrawal; Amr El Abbadi,Abstract A database management system (DBMS) serving a cloud platform must handlelarge numbers of application databases (or tenants) that are characterized by diverseschemas; varying footprints; and unpredictable load patterns. Scaling out using clusters ofcommodity servers and sharing resources among tenants (ie; multitenancy) are importantfeatures of such systems. Moreover; when deployed on a pay-per-use infrastructure;minimizing the system's operating cost while ensuring good performance is also animportant goal. Traditional DBMSs were not designed for such scenarios and hence do notpossess the mentioned features critical for DBMSs in the cloud. We present ElasTraS; whichcombines three design principles to build an elastically-scalable multitenant DBMS fortransaction processing workloads. These design principles are gleaned from a careful …,ACM Transactions on Database Systems (TODS),2013,101
Privacy preserving decision tree learning over multiple parties,Fatih Emekçi; Ozgur D Sahin; Divyakant Agrawal; Amr El Abbadi,Abstract Data mining over multiple data sources has emerged as an important practicalproblem with applications in different areas such as data streams; data-warehouses; andbioinformatics. Although the data sources are willing to run data mining algorithms in thesecases; they do not want to reveal any extra information about their data to other sources dueto legal or competition concerns. One possible solution to this problem is to usecryptographic methods. However; the computation and communication complexity of suchsolutions render them impractical when a large number of data sources are involved. In thispaper; we consider a scenario where multiple data sources are willing to run data miningalgorithms over the union of their data as long as each data source is guaranteed that itsinformation that does not pertain to another data source will not be revealed. We focus on …,Data & Knowledge Engineering,2007,100
Big data and cloud computing: new wine or just new bottles?,Divyakant Agrawal; Sudipto Das; Amr El Abbadi,Abstract Cloud computing is an extremely successful paradigm of service orientedcomputing and has revolutionized the way computing infrastructure is abstracted and used.Three most popular cloud paradigms include: Infrastructure as a Service (IaaS); Platform asa Service (PaaS); and Software as a Service (SaaS). The concept however can also beextended to Database as a Service and many more. Elasticity; pay-per-use; low upfrontinvestment; low time to market; and transfer of risks are some of the major enabling featuresthat make cloud computing a ubiquitous paradigm for deploying novel applications whichwere not economically feasible in a traditional enterprise infrastructure settings. This hasseen a proliferation in the number of applications which leverage various cloud platforms;resulting in a tremendous increase in the scale of the data generated as well as …,Proceedings of the VLDB Endowment,2010,99
Privacy preserving query processing using third parties,Fatih Emekci; Divyakant Agrawal; Amr El Abbadi; Aziz Gulbeden,Data integration from multiple autonomous data sources has emerged as an importantpractical problem. The key requirement for such data integration is that owners of such dataneed to cooperate in a competitive landscape in most of the cases. The research challengein developing a query processing solution is that the answers to the queries need to beprovided while preserving the privacy of the data sources. In general; allowing unrestrictedread access to the whole data may give rise to potential vulnerabilities as well as may havelegal implications. Therefore; there is a need for privacy preserving database operations forquerying data residing at different parties. In this paper; we propose a new query processingtechnique using third parties in a peer-to-peer system. We propose and evaluate twodifferent protocols for various database operations. Our scheme is able to answer queries …,Data Engineering; 2006. ICDE'06. Proceedings of the 22nd International Conference on,2006,97
Consistency and orderability: Semantics-based correctness criteria for databases,Divyakant Agrawal; Amr El Abbadi; Ambuj K Singh,Abstract The semantics of objects and transactions in database systems are investigated.User-defined predicates called consistency assertions are used to specify user programs.Three new correctness criteria are proposed. The first correctness criterion consistency isbased solely on the users' specifications and admit nonserializable executions that areacceptable to the users. Integrity constraints of the database are maintained throughconsistency assertions. The second correctness criterion orderability is a generalization ofview serializability and represents a weak notion of equivalence to a serial schedule. Finally;the third correctness criterion strong order-ability is introduced as a generalization of conflictserializability. Unlike consistency; the notions of orderability allow users to operate anisolation as maintenance of the integrity constrainst now becomes the responsibility of the …,ACM Transactions on Database Systems (TODS),1993,96
Cyclic allocation of two-dimensional data,Sunil Prabhakar; Khaled Abdel-Ghaffar; Divyakant Agrawal; Amr El Abbadi,Various proposals have been made for declustering 2D tiled data on multiple I/O devices.Strictly optimal solutions only exist under very restrictive conditions on the tiling of the 2Dspace or for very few I/O devices. In this paper; we explore allocation methods where nostrictly optimal solution exists. We propose a general class of allocation methods; referred toas cyclic allocation methods; and show that many existing methods are instances of thisclass. As a result; various seemingly ad hoc and unrelated methods are presented in asingle framework. Furthermore; the framework is used to develop new allocation methodsthat give better performance than any previous method and that approach the best feasibleperformance.,Data Engineering; 1998. Proceedings.; 14th International Conference on,1998,93
Hardware acceleration for spatial selections and joins,Chengyu Sun; Divyakant Agrawal; Amr El Abbadi,Abstract Spatial database operations are typically performed in two steps. In the filteringstep; indexes and the minimum bounding rectangles (MBRs) of the objects are used toquickly determine a set of candidate objects; and in the refinement step; the actualgeometries of the objects are retrieved and compared to the query geometry or each other.Because of the complexity of the computational geometry algorithms involved; the CPU costof the refinement step is usually the dominant cost of the operation for complex geometriessuch as polygons. In this paper; we propose a novel approach to address this problem usingefficient rendering and searching capabilities of modern graphics hardware. This approachdoes not require expensive pre-processing of the data or changes to existing storage andindex structures; and it applies to both intersection and distance predicates. Our …,Proceedings of the 2003 ACM SIGMOD international conference on Management of data,2003,92
Database scalability; elasticity; and autonomy in the cloud,Divyakant Agrawal; Amr El Abbadi; Sudipto Das; Aaron J Elmore,Abstract Cloud computing has emerged as an extremely successful paradigm for deployingweb applications. Scalability; elasticity; pay-per-use pricing; and economies of scale fromlarge scale operations are the major reasons for the successful and widespread adoption ofcloud infrastructures. Since a majority of cloud applications are data driven; databasemanagement systems (DBMSs) powering these applications form a critical component in thecloud software stack. In this article; we present an overview of our work on instilling theseabove mentioned “cloud features” in a database system designed to support a variety ofapplications deployed in the cloud: designing scalable database management architecturesusing the concepts of data fission and data fusion; enabling lightweight elasticity using lowcost live database migration; and designing intelligent and autonomic controllers for …,International Conference on Database Systems for Advanced Applications,2011,89
Storage and retrieval of moving objects,Hae Don Chon; Divyakant Agrawal; Amr El Abbadi,Abstract We investigate the problem and provide a data model storing; indexing; andretrieving future locations of moving objects in an efficient manner. Each moving object hasfour independent variables which allow us to predict its future location: a starting location; adestination; a starting time; and an initial velocity. To understand the underlying complexityof the problem; we investigate and categorize the configurations where two variables canvary. Based on that understanding; we choose a configuration which is to some extentrestrictive; but still can be used in a wide variety of realistic settings. A performance studyshows that our model has much less overhead in processing range queries compared toother proposed approaches.,International Conference on Mobile Data Management,2001,85
The performance of database replication with group multicast,JoAnne Holliday; Divyakant Agrawal; Amr El Abbadi,Replication with update-anywhere capability while maintaining global synchronization andisolation has long been thought impractical. Protocols have been proposed for distributedreplicated databases that take advantage of atomic broadcast systems to simplify messagepassing and conflict resolution in hopes of making replication efficient. This paper presentsperformance measurements on a simulation of a replicated database using those protocols.The results show that with the proper group broadcast mechanism; replication with update-anywhere capability is indeed practical.,Fault-Tolerant Computing; 1999. Digest of Papers. Twenty-Ninth Annual International Symposium on,1999,85
Using broadcast primitives in replicated databases,Ioana Stanoi; Divyakant Agrawal; Amr El Abbadi,We explore the use of different variants of broadcast protocols for managing replicateddatabases. Starting with the simplest broadcast primitive; the reliable broadcast protocol; weshow how it can be used to ensure correct transaction execution. The protocol is simple; andhas several advantages; including prevention of deadlocks. However; it requires a two-phase commitment protocol for ensuring correctness. We then develop a second protocolthat uses causal broadcast and avoids the overhead of two-phase commit by exploiting thecausal delivery properties of the broadcast primitives to implicitly collect the relevantinformation used in two-phase commit. Finally; we present a protocol that employs atomicbroadcast and completely eliminates the need for acknowledgements during transactioncommitment.,Distributed Computing Systems; 1998. Proceedings. 18th International Conference on,1998,84
Anonymizing weighted social network graphs,Sudipto Das; Ömer Eğecioğlu; Amr El Abbadi,The increasing popularity of social networks has initiated a fertile research area ininformation extraction and data mining. Although such analysis can facilitate betterunderstanding of sociological; behavioral; and other interesting phenomena; there is agrowing concern about personal privacy being breached; thereby requiring effectiveanonymization techniques. In this paper; we consider edge weight anonymization in socialgraphs. Our approach builds a linear programming (LP) model which preserves propertiesof the graph that are expressible as linear functions of the edge weights. Such propertiesform the foundations of many important graph-theoretic algorithms such as shortest paths; k-nearest neighbors; minimum spanning tree; etc. Off-the-shelf LP solvers can then be used tofind solutions to the resulting model where the computed solution constitutes the weights …,Data Engineering (ICDE); 2010 IEEE 26th International Conference on,2010,83
Exotica/FMDC: a workflow management system for mobile and disconnected clients,Gustavo Alonso; Roger Günthör; Mohan Kamath; Divyakant Agrawal; Amr El Abbadi; C Mohan,Abstract Workflow Management Systems (WFMSs) automate the execution of businessprocesses in environments encompassing large numbers of users distributed over a widegeographic area and using heterogeneous resources. Current implementations allow thedefinition and controlled execution of complex and long lived business processes as thebasis for an enterprise-wide collaborative system but; in most cases; the autonomy of theusers is greatly restricted due to architectural and design considerations. In particular;existing systems are built around a centralized server. As a result; users need to maintain anuninterrupted connection with the server to perform the different tasks assigned to them. Thisis a severe restriction; especially when considering the emergence of mobile computing;and the increase in use of laptops and small computers which are connected to the …,*,1996,82
From static distributed systems to dynamic systems,Achour Mostefaoui; Michel Raynal; Corentin Travers; Stacy Patterson; Divyakant Agrawal; AE Abbadi,A noteworthy advance in distributed computing is due to the recent development of peer-to-peer systems. These systems are essentially dynamic in the sense that no process can get aglobal knowledge on the system structure. They mainly allow processes to look up for datathat can be dynamically added/suppressed in a permanently evolving set of nodes. Althoughprotocols have been developed for such dynamic systems; to our knowledge; up to date nocomputation model for dynamic systems has been proposed. Nevertheless; there is a strongdemand for the definition of such models as soon as one wants to develop provably correctprotocols suited to dynamic systems. This paper proposes a model for (a class of) dynamicsystems. That dynamic model is defined by (1) a parameter (an integer denoted a) and (2)two basic communication abstractions (query-response and persistent reliable broadcast) …,Reliable Distributed Systems; 2005. SRDS 2005. 24th IEEE Symposium on,2005,81
Using association rules for fraud detection in web advertising networks,Ahmed Metwally; Divyakant Agrawal; Amr El Abbadi,Abstract Discovering associations between elements occurring in a stream is applicable innumerous applications; including predictive caching and fraud detection. These applicationsrequire a new model of association between pairs of elements in streams. We develop analgorithm; Streaming-Rules; to report association rules with tight guarantees on errors; usinglimited processing per element; and minimal space. The modular design of Streaming-Rulesallows for integration with current stream management systems; since it employs existingtechniques for finding frequent elements. The presentation emphasizes the applicability ofthe algorithm to fraud detection in advertising networks. Such fraud instances have not beensuccessfully detected by current techniques. Our experiments on synthetic data demonstratescalability and efficiency. On real data; potential fraud was discovered.,Proceedings of the 31st international conference on Very large data bases,2005,81
Preserving location privacy in geosocial applications,Krishna PN Puttaswamy; Shiyuan Wang; Troy Steinbauer; Divyakant Agrawal; Amr El Abbadi; Christopher Kruegel; Ben Y Zhao,Using geosocial applications; such as FourSquare; millions of people interact with theirsurroundings through their friends and their recommendations. Without adequate privacyprotection; however; these systems can be easily misused; for example; to track users ortarget them for home invasion. In this paper; we introduce LocX; a novel alternative thatprovides significantly improved location privacy without adding uncertainty into query resultsor relying on strong assumptions about server security. Our key insight is to apply secureuser-specific; distance-preserving coordinate transformations to all location data shared withthe server. The friends of a user share this user's secrets so they can apply the sametransformation. This allows all location queries to be evaluated correctly by the server; butour privacy mechanisms guarantee that servers are unable to see or infer the actual …,IEEE Transactions on Mobile Computing,2014,80
Structural trend analysis for online social networks,Ceren Budak; Divyakant Agrawal; Amr El Abbadi,Abstract The identification of popular and important topics discussed in social networks iscrucial for a better understanding of societal concerns. It is also useful for users to stay ontop of trends without having to sift through vast amounts of shared information. Trenddetection methods introduced so far have not used the network topology and has thus notbeen able to distinguish viral topics from topics that are diffused mostly through the newsmedia. To address this gap; we propose two novel structural trend definitions we callcoordinated and uncoordinated trends that use friendship information to identify topics thatare discussed among clustered and distributed users respectively. Our analyses andexperiments show that structural trends are significantly different from traditional trends andprovide new insights into the way people share information online. We also propose a …,Proceedings of the VLDB Endowment,2011,80
Distributed average consensus with stochastic communication failures,Stacy Patterson; Bassam Bamieh; Amr El Abbadi,We consider a distributed average consensus algorithm over a network in whichcommunication links fail with independent probability. Convergence in such stochasticnetworks is defined in terms of the variance of deviation from average. We characterize thedecay factor of the variance in terms of the eigenvalues of a Lyapunov-like matrix recursion.We give expressions for the decay factors in the asymptotic limits of small failure probabilityand large networks. We also present a simulation-free method for computing the decayfactor for any particular graph instance and use this method to study the behavior of variousnetwork examples as a function of link failure probability.,Decision and Control; 2007 46th IEEE Conference on,2007,78
Enhancing the fault tolerance of workflow management systems,Gustavo Alonso; Claus Hagen; Divyakant Agrawal; Amr El Abbadi; C Mohan,Today's commercial workflow systems; although useful; do not scale well; have limited faulttolerance; and don't interoperate well with other workflow systems. The authors discusscurrent research directions and potential future extensions that might enable workflowservices to meet the needs of mission-critical applications.,IEEE Concurrency,2000,77
Exploiting logical structures in replicated databases,Divyakant Agrawal; Amr El Abbadi,1. cated to achieve fault-tolerance. One of the most important advantages of replication isthat it masks and tolerates failures in the network gracefully. In particular; the system remainsoperational and available to the users despite failures. However; complex and expensivesynchronization protocols are needed to maintain the replicas. In this paper; we proposedreplica control protocols where the synchronization cost is reduced by exploiting thestructural information of the underlying system. We first show that distributed mutualexclusion can be achieved efficiently if a logical structure is imposed of the underlying net--work system. Several such protocols hav: appeared in the literature [9; 1&l]. We then arguethat solutions to the problem of mutual exclusion can be extended to solve the problem ofreplica GGliirol in a distributed database. We therefore use logically imposed structures …,Information Processing Letters,1990,77
Optimal allocation of two-dimensional data,Khaled AS Abdel-Ghaffar; Amr El Abbadi,Abstract Efficient browsing and retrieval of geographically referenced information requiresthe allocation of data on different storage devices for concurrent retrieval. By dividing a twodimensional space into tiles; a system can allow users to specify regions of interest using aquery rectangle and then retrieving all information related to tiles overlapping with the query.In this paper; we derive the necessary and sufficient conditions for strictly optimal allocationsof two-dimensional data. These methods; when they exist; guarantee that for any query; theminimum number of tiles are assigned the same storage device; and hence ensuresmaximal retrieval concurrency.,International Conference on Database Theory,1997,75
Disconnection modes for mobile databases,Joanne Holliday; Divyakant Agrawal; Amr El Abbadi,Abstract As mobility permeates into todays computing and communication arena; weenvision application infrastructures that will increasingly rely on mobile technologies.Traditional database applications and information service applications will need to integratemobile entities: people and computers. In this paper; we develop a distributed databaseframework for mobile environments. A key requirement in such an environment is to supportfrequent connection and disconnection of database sites. We present algorithms thatimplement this framework in an asynchronous system.,Wireless Networks,2002,73
Range and kNN query processing for moving objects in grid model,Hae Don Chon; Divyakant Agrawal; Amr El Abbadi,Abstract With the growing popularity of mobile computing devices and wirelesscommunications; managing dynamically changing information about moving objects isbecoming feasible. In this paper; we implement a system that manages such information andpropose two query algorithms: a range query algorithm and ak nearest neighbor algorithm.The range query algorithm is combined with an efficient filtering technique which determinesif a polyline corresponding to the trajectory of a moving object intersects with a given range.We study the performance of the system; which shows that despite the filtering step; formoderately large ranges; the range query algorithm we propose outperforms the algorithmwithout filtering.,Mobile Networks and Applications,2003,70
Efficient retrieval for browsing large image databases,Daniel Wu; Ambuj Singh; Divyakant Agrawal; Amr El Abbadi; Terence R Smith,Abstract The Alexandria project has been initiated to build a digital library for map andsatellite images. Designed for content-based retrieval; the relevant information in eachimage is encoded in the form of a multi-dimensional feature vector. Though representingimages by feature vectors~ eatly facilitates user queries; indexing these vectors degradesperformance when the number of dimensions is large. We consider 2 populartechniques(DFT and SVD) to reduce the dimension of feature vectors; and study theirretrieval performance with respect to recall and precision. We End that though SVDgenerally out-performs DFT; DFT comparesfavorably in alimited range suitable for browsinglarge image databases.,Proceedings of the fifth international conference on Information and knowledge management,1996,70
Efficient processing of distributed top-k queries,Hailing Yu; Hua-Gang Li; Ping Wu; Divyakant Agrawal; Amr El Abbadi,Abstract Ranking-aware queries; or top-k queries; have received much attention recently invarious contexts such as web; multimedia retrieval; relational databases; and distributedsystems. Top-k queries play a critical role in many decision-making related activities suchas; identifying interesting objects; network monitoring; load balancing; etc. In this paper; westudy the ranking aggregation problem in distributed systems. Prior research addressing thisproblem did not take data distributions into account; simply assuming the uniform datadistribution among nodes; which is not realistic for real data sets and is; in general;inefficient. In this paper; we propose three efficient algorithms that consider data distributionsin different ways. Our extensive experiments demonstrate the advantages of our approachesin terms of bandwidth consumption.,International Conference on Database and Expert Systems Applications,2005,69
Locks with constrained sharing,Divyakant Agrawal; Amr El Abbadi,Abstract In this paper; we propose a new mode for locks that permits sharing in aconstrained manner. We develop a family of locking protocols; the strictest of which is thetwo phase locking protocol while the most permissive recognizes all conflict-preservingserializable histories. This is the first locking-based protocol that can recognize the entireclass of conflict-preserving serializable histories.,Proceedings of the ninth ACM SIGACT-SIGMOD-SIGART symposium on Principles of database systems,1990,69
$\mathcal {MD} $-HBase: design and implementation of an elastic data infrastructure for cloud-scale location services,Shoji Nishimura; Sudipto Das; Divyakant Agrawal; Amr El Abbadi,Abstract The ubiquity of location enabled devices has resulted in a wide proliferation oflocation based applications and services. To handle the growing scale; databasemanagement systems driving such location based services (LBS) must cope with high insertrates for location updates of millions of devices; while supporting efficient real-time analysison latest location. Traditional DBMSs; equipped with multi-dimensional index structures; canefficiently handle spatio-temporal data. However; popular open-source relational databasesystems are overwhelmed by the high insertion rates; real-time querying requirements; andterabytes of data that these systems must handle. On the other hand; key-value stores caneffectively support large scale operation; but do not natively provide multi-attribute accessesneeded to support the rich querying functionality essential for the LBSs. We present the …,Distributed and Parallel Databases,2013,62
Flexible data cubes for online aggregation,Mirek Riedewald; Divyakant Agrawal; Amr El Abbadi,Abstract Applications like Online Analytical Processing depend heavily on the ability toquickly summarize large amounts of information. Techniques were proposed recently thatspeed up aggregate range queries on MOLAP data cubes by storing pre-computedaggregates. These approaches try to handle data cubes of any dimensionality by dealingwith all dimensions at the same time and treat the different dimensions uniformly. Thealgorithms are typically complex; and it is difficult to prove their correctness and to analyzetheir performance. We present a new technique to generate Iterative Data Cubes (IDC) thataddresses these problems. The proposed approach provides a modular framework forcombining one-dimensional aggregation techniques to create space-optimal high-dimensional data cubes. A large variety of cost tradeoffs for high-dimensional IDC can be …,International Conference on Database Theory,2001,61
Dimensionality reduction for similarity searching in dynamic databases,KV Ravi Kanth; Divyakant Agrawal; Amr El Abbadi; Ambuj Singh,Abstract Databases are increasingly being used to store multimedia objects such as maps;images; audio; and video. Storage and retrieval of these objects is accomplished usingmultidimensional index structures such as R*-trees and SS-trees. As dimensionalityincreases; query performance in these index structures degrades. This phenomenon;generally referred to as the dimensionality curse; can be circumvented by reducing thedimensionality of the data. Such a reduction is; however; accompanied by a loss of precisionof query results. Current techniques such as QBIC use SVD transform-based dimensionalityreduction to ensure high query precision. The drawback of this approach is that SVD isexpensive to compute and; therefore; not readily applicable to dynamic databases. In thispaper; we propose novel techniques for performing SVD-based dimensionality reduction …,Computer Vision and Image Understanding,1999,60
Optimal disk allocation for partial match queries,Khaled AS Abdel-Ghaffar; Amr El Abbadi,Abstract The problem of disk allocation addresses the issue of how to distribute a file onseveral disks in order to maximize concurrent disk accesses in response to a partial matchquery. In this paper a coding-theoretic analysis of this problem is presented; and bothnecessary and sufficient conditions for the existence of strictly optimal allocation methodsare provided. Based on a class of optimal codes; known as maximum distance separablecodes; strictly optimal allocation methods are constructed. Using the necessary conditionsproved; we argue that the standard definition of strict optimality is too strong and cannot beattained; in general. Hence; we reconsider the definition of optimality. Instead of basing it onan abstract definition that may not be attainable; we propose a new definition based on thebest possible allocation method. Using coding theory; allocation methods that are optimal …,ACM Transactions on Database Systems (TODS),1993,59
A comprehensive framework for secure query processing on relational data in the cloud,Shiyuan Wang; Divyakant Agrawal; Amr El Abbadi,Abstract Data security in the cloud is a big concern that blocks the widespread use of thecloud for relational data management. First; to ensure data security; data confidentialityneeds to be provided when data resides in storage as well as when data is dynamicallyaccessed by queries. Prior works on query processing on encrypted data did not providedata confidentiality guarantees in both aspects. Tradeoff between secrecy and efficiencyneeds to be made when satisfying both aspects of data confidentiality while being suitablefor practical use. Second; to support common relational data management functions; varioustypes of queries such as exact queries; range queries; data updates; insertion and deletionshould be supported. To address these issues; this paper proposes a comprehensiveframework for secure and efficient query processing of relational data in the cloud. Our …,Workshop on Secure Data Management,2011,58
Exotica: a project on advanced transaction management and workflow systems,C Mohan; Divyakant Agrawal; Gustavo Alonso; Amr El Abbadi; Roger Guenthoer; M Kamath,Abstract This paper is an overview of the Exotica project; currently in progress at the IBMAlmaden Research Center. The project aims at exploring several research areas fromadvanced transaction management concepts to client/server architectures and mobilecomputing within the context of business processes and workflow management. Theultimate goal is to incorporate these ideas into IBM's products and prototypes. The projectinvolves IBM groups in Almaden (USA); Hursley (UK); Boeblingen (Germany); and Vienna(Austria). In this paper we briefly describe two IBM products; FlowMark; a workflowmanagement system; and MQSeries; a messaging system; as the environments in which weare focusing our research. We also discuss some of our results in the areas of availability;replication; distribution; and advanced transaction models; as well as describe our future …,ACM Sigois Bulletin,1995,58
Deltasky: Optimal maintenance of skyline deletions without exclusive dominance region generation,Ping Wu; Divyakant Agrawal; Omer Egecioglu; Amr El Abbadi,This paper addresses the problem of efficient maintenance of a materialized skyline view inresponse to skyline removals. While there has been significant progress on skyline querycomputation; an equally important but largely unanswered issue is on the incrementalmaintenance for skyline deletions. Previous work suggested the use of the so calledexclusive dominance region (EDR) to achieve optimal I/O performance for deletionmaintenance. However; the shape of an EDR becomes extremely complex in higherdimensions; and algorithms for its computation have not been developed. We derive asystematic way to decompose a d-dimensional EDR into a collection of hyper-rectangles.We show that the number of such hyper-rectangles is O (md); where m is the current skylineresult size. We then propose a novel algorithm DeltaSky which determines whether an …,Data Engineering; 2007. ICDE 2007. IEEE 23rd International Conference on,2007,57
Partial database replication using epidemic communication,JoAnne Holliday; Divyakant Agrawal; Amr El Abbadi,Data replication in distributed databases has been investigated extensively with the hopethat it will improve performance; reliability; and availability. However the growth of theInternet has shown us that current replica management do not work well when the replicasare connected by an unreliable network; subject to congestion and dynamic topologychanges. In this paper we present a replica update protocol that handles an adaptive partialreplication scheme on such a network.,Distributed Computing Systems; 2002. Proceedings. 22nd International Conference on,2002,57
Using delayed commitment in locking protocols for real-time databases,Divyakant Agrawal; Amr El Abbadi; Richard Jeffers,Abstract In this paper; we propose locking protocols that are useful for real-time databases.Our approach is motivated from two main observations. First; locking protocols are widelyaccepted and used in most database systems. Second; in real-time databases it has beenshown that the blocking behavior of transactions in locking protocols results in performancedegradation. We use a new relationship between locks called ordered sharing to eliminateblocking that arises in the traditional locking protocols. Ordered sharing eliminates blockingof read and write operations but may result in delayed commitment. Since in real-timedatabases; timeliness and not response time is the crucial factor; or protocols exploit thisdelay to allow transactions to execute within the slacks of delayed transactions. We comparethe performance of the proposed protocols with the two phase locking protocol for real …,ACM SIGMOD Record,1992,57
Applying the golden rule of sampling for query estimation,Yi-Leh Wu; Divyakant Agrawal; Amr El Abbadi,Abstract Query size estimation is crucial for many database system components. Inparticular; query optimizers need efficient and accurate query size estimation when decidingamong alternative query plans. In this paper we propose a novel sampling technique basedon the golden rule of sampling; introduced by von Neumann in 1947; for estimating rangequeries. The proposed technique randomly samples the frequency domain using thecumulative frequency distribution and yields good estimates without any a priori knowledgeof the actual underlying distribution of spatial objects. We show experimentally that theproposed sampling technique gives smaller approximation error than the Min-Skewhistogram based and wavelet based approaches for both synthetic and real datasets.Moreover; the proposed technique can be easily extended for higher dimensional …,ACM SIGMOD Record,2001,56
Elastras: An elastic; scalable; and self managing transactional database for the cloud,Sudipto Das; Shashank Agarwal; Divyakant Agrawal; Amr El Abbadi; Chris Bunch; Navraj Chohan; Chandra Krintz; Jovan Chohan; Jonathan Kupferman; Puneet Lakhina; Yiming Li; Yoshihide Nomura; Ceren Budak; Divyakant Agrawal; Amr El Abbadi; Christopher Coffin; Sehwan Kim; Tobias Hollerer; Shiyuan Wang; Divyakant Agrawal; Amr El Abbadi; Lamia Youseff; Rich Wolski; Fang Yu; Tevfik Bultan; Oscar H Ibarra; Xia Zhou; Alessandra Sala; Haitao Zheng; Lorenzo Cavallaro; Christopher Kruegel; Giovanni Vigna; Fang Yu; Muath Alkhalaf; Tevfik Bultan; Lili Cao; Lei Yang; Heather Zheng; Christopher C Cipriano; Teofilo F Gonzalez; Steffen Gauglitz; Tobias Höllerer; Xia Zhou; Heather Zheng; Omer Egecioglu; Peterson Trethewey; Tobias Hollerer; Sudipto Das; Shyam Antony; Divyakant Agrawal; Amr El Abbadi; Sudipto Das; Ömer Egecioglu; Amr El Abbadi; Navraj Chohan; Chris Bunch; Sydney Pang; Chandra Krintz; Nagy Mostafa; Sunil Soman; Rich Wolski; Ömer Egecioglu; Oscar H Ibarra; Nagy Mostafa; Chandra Krintz; Sudipto Das; Shyam Antony; Divyakant Agrawal; Amr El Abbadi; Lamia Youseff; Dmitrii Zagorodnov; Rich Wolski,*,*,2010,55
Fates: Finding a time dependent shortest path,Hae Don Chon; Divyakant Agrawal; Amr El Abbadi,Abstract We model a moving object as a sizable physical entity equipped with GPS; wirelesscommunication capability; and a computer. Based on a grid model; we develop a distributedsystem; FATES; to manage data for moving objects in a two-dimensional space. The systemis used to provide time-dependent shortest paths for moving objects. The performance studyshows that FATES yields shorter average trip time when there is a more congested routethan any other routes in the domain space.,International Conference on Mobile Data Management,2003,55
Serializability; not serial: Concurrency control and availability in multi-datacenter datastores,Stacy Patterson; Aaron J Elmore; Faisal Nawab; Divyakant Agrawal; Amr El Abbadi,Abstract We present a framework for concurrency control and availability in multi-datacenterdatastores. While we consider Google's Megastore as our motivating example; we definegeneral abstractions for key components; making our solution extensible to any system thatsatisfies the abstraction properties. We first develop and analyze a transaction managementand replication protocol based on a straightforward implementation of the Paxos algorithm.Our investigation reveals that this protocol acts as a concurrency prevention mechanismrather than a concurrency control mechanism. We then propose an enhanced protocolcalled Paxos with Combination and Promotion (Paxos-CP) that provides true transactionconcurrency while requiring the same per instance message complexity as the basic Paxosprotocol. Finally; we compare the performance of Paxos and Paxos-CP in a multi …,Proceedings of the VLDB Endowment,2012,54
Selectivity estimation for spatial joins with geometric selections,Chengyu Sun; Divyakant Agrawal; Amr El Abbadi,Abstract Spatial join is an expensive operation that is commonly used in spatial databasesystems. In order to generate efficient query plans for the queries involving spatial joinoperations; it is crucial to obtain accurate selectivity estimates for these operations. In thispaper we introduce a framework for estimating the selectivity of spatial joins constrained bygeometric selections. The center piece of the framework is Euler Histogram; whichdecomposes the estimation process into estimations on vertices; edges and faces. Based onthe characteristics of different datasets; different probabilistic models can be plugged into theframework to provide better estimation results. To demonstrate the effectiveness of thisframework; we implement it by incorporating two existing probabilistic models; and comparethe performance with the Geometric Histogram [1] and the algorithm recently proposed by …,International Conference on Extending Database Technology,2002,54
Query processing for moving objects with space-time grid storage model,Hae Don Chon; Divyakant Agrawal; Amr El Abbadi,With the growing popularity of mobile computing devices and wireless communications;managing dynamically changing information about moving objects is becoming feasible. Inthis paper we implement a system that manages such information and propose an efficientrange query algorithm with a filtering step which efficiently determines if a polylinecorresponding to the trajectory of a moving object intersects with a given range. We studythe performance of the system; which shows that despite the filtering step; for moderatelylarge ranges; the range query algorithm we propose outperforms the algorithm withoutfiltering.,Mobile Data Management; 2002. Proceedings. Third International Conference on,2002,53
Low-latency multi-datacenter databases using replicated commit,Hatem Mahmoud; Faisal Nawab; Alexander Pucher; Divyakant Agrawal; Amr El Abbadi,Abstract Web service providers have been using NoSQL datastores to provide scalabilityand availability for globally distributed data at the cost of sacrificing transactionalguarantees. Recently; major web service providers like Google have moved towardsbuilding storage systems that provide ACID transactional guarantees for globally distributeddata. For example; the newly published system; Spanner; uses Two-Phase Commit and Two-Phase Locking to provide atomicity and isolation for globally distributed data; running on topof Paxos to provide fault-tolerant log replication. We show in this paper that it is possible toprovide the same ACID transactional guarantees for multi-datacenter databases with fewercross-datacenter communication trips; compared to replicated logging. Instead of replicatingthe transactional log; we replicate the commit operation itself; by running Two-Phase …,Proceedings of the VLDB Endowment,2013,52
Why go logarithmic if we can go linear?: Towards effective distinct counting of search traffic,Ahmed Metwally; Divyakant Agrawal; Amr El Abbadi,Abstract Estimating the number of distinct elements in a large multiset has severalapplications; and hence has attracted active research in the past two decades. Severalsampling and sketching algorithms have been proposed to accurately solve this problem.The goal of the literature has always been to estimate the number of distinct elements whileusing minimal resources. However; in some modern applications; the accuracy of theestimate is of primal importance; and businesses are willing to trade more resources forbetter accuracy. Throughout our experience with building a distinct count system at a majorsearch engine; Ask. com; we reviewed the literature of approximating distinct counts; andcompared most algorithms in the literature. We deduced that Linear Counting; one of theleast used algorithms; has unique and impressive advantages when the accuracy of the …,Proceedings of the 11th international conference on Extending database technology: Advances in database technology,2008,52
Spider: P2p-based web service discovery,Ozgur D Sahin; Cagdas E Gerede; Divyakant Agrawal; Amr El Abbadi; Oscar Ibarra; Jianwen Su,Abstract In this paper; we describe SPiDeR; a peer-to-peer (P2P) based framework thatsupports a variety of Web service discovery operations. SPiDeR organizes the serviceproviders into a structured P2P overlay and allows them to advertise and lookup services ina completely decentralized and dynamic manner. It supports three different kinds of searchoperations: For advertising and locating services; service providers can use keywordsextracted from service descriptions (keyword-based search); categories from a globalontology (ontology-based search); and/or paths from the service automaton (behavior-basedsearch). The users can also rate the quality of the services they use. The ratings areaccumulated within the system so that users can query for the quality ratings of thediscovered services. Finally; we present the performance of SPiDeR in terms of routing …,International Conference on Service-Oriented Computing,2005,52
Adaptive filtering and indexing for image databases,Albert D Alexandrov; Wei Y Ma; Amr El Abbadi; BS Manjunath,In this paper we combine image feature extraction with indexing techniques for efficientretrieval in large texture images databases. A 2D image signal is processed using a set ofGabor filters to derive a 120 component feature vector representing the image. The featurecomponents are ordered based on the relative importance in characterizing a given texturepattern; and this facilitates the development of efficient indexing mechanisms. We proposethree different sets of indexing features based on the best feature; the average feature and acombination of both. We investigate the tradeoff between accuracy and discriminating powerusing these different indexing approaches; and conclude that the combination of bestfeature and the average feature gives the best results.,Storage and retrieval for image and video databases III,1995,50
Geoscope: Online detection of geo-correlated information trends in social networks,Ceren Budak; Theodore Georgiou; Divyakant Agrawal; Amr El Abbadi,Abstract The First Law of Geography states" Everything is related to everything else; but nearthings are more related than distant things". This spatial significance has implications invarious applications; trend detection being one of them. In this paper we propose a newalgorithmic tool; GeoScope; to detect geo-trends. GeoScope is a data streams solution thatdetects correlations between topics and locations in a sliding window; in addition toanalyzing topics and locations independently. GeoScope offers theoretical guarantees fordetecting all trending correlated pairs while requiring only sub-linear space and runningtime. We perform various human validation tasks to demonstrate the value of GeoScope.The results show that human judges prefer GeoScope to the best performing baselinesolution 4: 1 in terms of the geographical significance of the presented information. As the …,Proceedings of the VLDB Endowment,2013,49
Pharos: A scalable distributed architecture for locating heterogeneous information sources,Ron Dolin; Divyakant Agrawal; Amr El Abbadi; L Dillon,Abstract Pharos is a. sca&zble distributed architecture for locating het-erogeneousinformatdon sources.! 7he system incorporates a hierarcfiical metaduta structure into a multi-level rettieval system. Queries are resolved through an iterative decisionmaking process.The first step retrieves coarse-grain metadata; about all sources; stored on iocal; mastivelyreplicated; high-level servers. Further steps retrieve more detailed matadata; about a greatlyreduced set of souwes; stored on remote; sparsety replicated; topic-based mid-level servers.We present results of a simulation which indicate the feasibility of the architecture. Wedescribe the structure; distribution; and retrieval of the metadata in Pharos to enable users tolocate desirable information soumes over the Internet.,Proceedings of the sixth international conference on Information and knowledge management,1997,49
Process synchronization in workflow management systems,Gustavo Alonso; Divyakant Agrawal; Amr El Abbadi,Workflow management systems automate the execution of business processes allowing theconcurrent execution of multiple process instances. Existing systems do not provide amechanism to guarantee correct concurrent execution and; as a result; it is not possible tocoordinate and synchronize different process instances. Part of the problem is thatconventional techniques are not entirely suitable for workflow environments. In databases;locks are the basic mechanism. In operating systems; this is achieved using semaphores ormonitors. Neither of these approaches is appropriate for workflow applications. A method isproposed to enforce correct interleavings and guarantee mutual exclusion; as defined by theuser; between concurrent workflow processes. The proposed protocol takes advantage ofthe semantic constructs associated with workflow management to solve some complex …,Parallel and Distributed Processing; 1996.; Eighth IEEE Symposium on,1996,49
Relative serializability (extended abstract): an approach for relaxing the atomicity of transactions,Divyakant Agrawal; John L Bruno; Amr El Abbadi; Vashudha Krishnaswamy,Abstract In the presence of semantic information; serializability is too strong a correctnesscriterion and unnecessarily restricts concurrency. We use the semantic information of atransaction to provide different atomicity views of the transaction to other transactions. Theproposed approach improves concurrency and allows interleavings among transactionswhich are non-serializable; but which nonetheless preserve the consistency of the databaseand are acceptable to other users. We develop a graph-based tool whose acyclicity is both anecessary and sufficient condition for the correctness of an execution. Our theoryencompasses earlier proposals that incorporate semantic information of transactions.Furthermore it is the first approach that provides an efficient graph based tool for recognizingcorrect schedules without imposing any restrictions on the application domain. Our …,Proceedings of the thirteenth ACM SIGACT-SIGMOD-SIGART symposium on Principles of database systems,1994,49
Ordered shared locks for real-time databases,Divyakant Agrawal; Amr El Abbadi; Richard Jeffers; Lijing Lin,Abstract We propose locking protocols for real-time databases. Our approach has two mainmotivations: First; locking protocols are widely accepted and used in most databasesystems. Second; in real-time databases it has been shown that the blocking behavior oftransactions in locking protocols results in performance degradation. We use a newrelationship between locks called ordered sharing to eliminate blocking that arises in thetraditional locking protocols. Ordered sharing eliminates blocking of read and writeoperations but may result in delayed termination. Since timeliness and not response time isthe crucial factor in real-time databases; our protocols exploit this delay to allow transactionsto execute within the slacks of delayed transactions. We compare the performance of theproposed protocols with the two-phase locking protocol for real-time databases. Our …,The VLDB Journal—The International Journal on Very Large Data Bases,1995,48
Semantic locking in object-oriented database systems,Rodolfo F Resende; Divyakant Agrawal; Amr El Abbadi,Abstract Object-oriented databases are being increasingly used to model non-standardapplications that emphasize modularity; composition; and rapid prototyping. A semanticlocking protocol is presented for transaction management for such object-orienteddatabases. In particular; the protocol incorporates the semantics of complex objects; nestedexecutions and dynamic conflicts resulting from referentially shared objects.,ACM Sigplan Notices,1994,48
Unifying concurrency control and recovery of transactions,Gustavo Alonso; Radek Vingralek; Divyakant Agrawal; Yuri Breitbart; Amr El Abbadi; Hans-J Schek; Gerhard Weikum,Abstract Transaction management in shared databases is generally viewed as acombination of two problems; concurrency control and recovery; which have beenconsidered as orthogonal problems. Consequently; the correctness criteria derived for theseproblems are incomparable. Recently a unified theory of concurrency control and recoveryhas been introduced that is based on commutativity and performs transaction recovery bysubmitting inverse operations for operations of aborted transactions. In this paper weprovide a constructive correctness criterion that leads to the design of unified protocols thatguarantee atomicity and serializability.,Information Systems,1994,47
PRISM: indexing multi-dimensional data in P2P networks using reference vectors,Ozgur D Sahin; Aziz Gulbeden; Fatih Emekçi; Divyakant Agrawal; Amr El Abbadi,Abstract Peer-to-peer (P2P) systems research has gained considerable attention recentlywith the increasing popularity of file sharing applications. Since these applications are usedfor sharing huge amounts of data; it is very important to efficiently locate the data of interestin such systems. However; these systems usually do not provide efficient search techniques.Existing systems offer only keyword search functionality through a centralized index or byquery flooding. In this paper; we propose a scheme based on reference vectors for sharingmulti-dimensional data in P2P systems. This scheme effectively supports a larger set ofquery operations (such as k-NN queries and content-based similarity search) than currentsystems; which generally support only exact key lookups and keyword searches. The basicidea is to store multiple replicas of an object's index at different peers based on the …,Proceedings of the 13th annual ACM international conference on Multimedia,2005,46
Concentric hyperspaces and disk allocation for fast parallel range searching,Hakan Ferhatosmanoglu; Divyakant Agrawal; Amr El Abbadi,Data partitioning and declustering have been extensively used in the past to parallelize I/Ofor range queries. Numerous declustering and disk allocation techniques have beenproposed in the literature. However most of these techniques were primarily designed fortwo-dimensional data and for balanced partitioning of the data space. As databasesincreasingly integrate multimedia information in the form of image; video; and audio data; itis necessary to extend the declustering techniques for multidimensional data. We firstestablish that traditional declustering techniques do not scale for high-dimensional data. Wethen propose several new partitioning schemes based on concentric hyperspaces. We thendevelop disk allocation methods for each of the proposed schemes. We conclude with anevaluation of range queries based on these schemes and show that partitioning based on …,Data Engineering; 1999. Proceedings.; 15th International Conference on,1999,46
Exploring spatial datasets with histograms,Chengyu Sun; Divyakant Agrawal; Amr El Abbadi,As online spatial datasets grow both in number and sophistication; it becomes increasinglydifficult for users to decide whether a dataset is suitable for their tasks; especially when theydo not have prior knowledge of the dataset. The GeoBrowsing service developed for theADL project provides users an effective and efficient way to explore the content of a spatialdataset. In this paper; we identify a set of spatial relations that need to be supported inbrowsing applications; namely; the contains; contained and the overlap relations. We provea storage lower bound to answer queries about the contains relation accurately at a givengrid resolution. We then present three storage-efficient approximation algorithms which webelieve to be the first to estimate query selectivities about these spatial relations.Experimental results show that these algorithms provide highly accurate estimates in real …,Data Engineering; 2002. Proceedings. 18th International Conference on,2002,45
Fast data stream algorithms using associative memories,Nagender Bandi; Ahmed Metwally; Divyakant Agrawal; Amr El Abbadi,Abstract The primary goal of data stream research is to develop space and time efficientsolutions for answering continuous on-line summarization queries. Research efforts over thelast decade have resulted in a number of efficient algorithms with varying degrees of spaceand time complexities. While these techniques are developed in a standard CPU setting;many of their applications such as click-fraud detection and network-traffic summarizationtypically execute on special networking architectures called Network Processing Units(NPUs). These NPUs interface with special associative memories known as Ternary ContentAddressable Memories (TCAMs) to provide gigabit rate forwarding at network routers. In thispaper; we describe how the integrated architecture of NPU and TCAMs can be exploitedtowards achieving the goal of developing high-speed stream summarization solutions …,Proceedings of the 2007 ACM SIGMOD international conference on Management of data,2007,44
-Tabular Placement of Relational Data on MEMS-based Storage Devices,Hailing Yu; Divyakant Agrawal; Amr El Abbadi,This chapter presents a first attempt to approach the data placement problem for microelectro mechanical systems (MEMS) based storage devices in a manner that exploitspotential properties of relational databases. The development shows that in terms of I/Outilization; the flexible retrieval model (FRM) is very beneficial and results in significantperformance improvements when compared to existing placement techniques for relationaldata. It is also cache-friendly by retrieving only the relevant values required for evaluating aquery; in this way; it further pushes some of the ideas earlier developed in Partition AttributesAcross (PAX) by not only avoiding cache pollution; but also memory pollution. As theperformance results also show; there is still a room for improvement. This chapter plans toexplore other cache-friendly techniques for MEMS-based storage devices that can further …,*,2003,44
An optimal strategy for comparing file copies,Khaled AS Abdel-Ghaffar; Amr El Abbadi,We study the problem of identifying corrupted pages between two remotely located copies ofa file in a distributed system. An efficient deterministic algorithm is presented to identify up toany given number of differing pages. The algorithm requires a single exchange of messagesand is based on the structure of the Reed-Solomon code. In order to identify up to f corruptedpages; 2f signatures are transmitted. The algorithm requires less communication costs thanpreviously proposed solutions. In fact; we prove that our algorithm is optimal; in the sensethat no other algorithm is guaranteed to identify with probability 1 the corrupted pages byexchanging less information.,IEEE Transactions on Parallel and Distributed Systems,1994,44
Range Cube: Efficient cube computation by exploiting data correlation,Ying Feng; Divyakant Agrawal; Amr El Abbadi; Ahmed Metwally,Data cube computation and representation are prohibitively expensive in terms of time andspace. Prior work has focused on either reducing the computation time or condensing therepresentation of a data cube. We introduce range cubing as an efficient way to computeand compress the data cube without any loss of precision. A new data structure; range trie; isused to compress and identify correlation in attribute values; and compress the input datasetto effectively reduce the computational cost. The range cubing algorithm generates acompressed cube; called range cube; which partitions all cells into disjoint ranges. Eachrange represents a subset of cells with the same aggregation value; as a tuple which has thesame number of dimensions as the input data tuples. The range cube preserves the roll-up/drill-down semantics of a data cube. Compared to H-cubing; experiments on real …,Data Engineering; 2004. Proceedings. 20th International Conference on,2004,43
Using space-time grid for efficient management of moving objects,Hae Don Chon; Divyakant Agrawal; Amr El Abbadi,Abstract Efficient storage and retrieval of moving objects in DBMS have received significantinterest recently. There are applications that would benefit from the management ofdynamically changing information about moving objects. In this paper; we develop a systemthat manages such information interacting with moving objects. We model the space-timedomain space as a grid (Space-Time Grid) and model the trajectory of a moving object as apolyline in the Space-Time Grid. The polyline is the result of the interactions among othermoving objects. In this paper; the insertion algorithm and several other query processingalgorithms are presented.,Proceedings of the 2nd ACM international workshop on Data engineering for wireless and mobile access,2001,43
Content-based similarity search over peer-to-peer systems,Ozgur D Sahin; Fatih Emekci; Divyakant Agrawal; Amr El Abbadi,Abstract Peer-to-peer applications are used to share large volumes of data. An importantrequirement of these systems is efficient methods for locating the data of interest in a largecollection of data. Unfortunately current peer-to-peer systems either offer exact keywordmatch functionality or provide inefficient text search methods through centralized indexing orflooding. In this paper we propose a method based on popular Information Retrievaltechniques to facilitate content-based searches in peer-to-peer systems. A simulation of theproposed design was implemented and its performance was evaluated using somecommonly used test collections; including Ohsumed which was used for the TREC-9Filtering Track. The experiments demonstrate that our approach is scalable as it achieveshigh recall by visiting only a small subset of the peers.,International Workshop on Databases; Information Systems; and Peer-to-Peer Computing,2004,41
Pagrol: Parallel graph olap over large-scale attributed graphs,Zhengkui Wang; Qi Fan; Huiju Wang; Kian-Lee Tan; Divyakant Agrawal; Amr El Abbadi,Attributed graphs are becoming important tools for modeling information networks; such asthe Web and various social networks (eg Facebook; LinkedIn; Twitter). However; it iscomputationally challenging to manage and analyze attributed graphs to support effectivedecision making. In this paper; we propose; Pagrol; a parallel graph OLAP (Online AnalyticalProcessing) system over attributed graphs. In particular; Pagrol introduces a new conceptualHyper Graph Cube model (which is an attributed-graph analogue of the data cube model forrelational DBMS) to aggregate attributed graphs at different granularities and levels. Theproposed model supports different queries as well as a new set of graph OLAP Roll-Up/Drill-Down operations. Furthermore; on the basis of Hyper Graph Cube; Pagrol provides anefficient MapReduce-based parallel graph cubing algorithm; MRGraph-Cubing; to …,Data Engineering (ICDE); 2014 IEEE 30th International Conference on,2014,40
Supporting sliding window queries for continuous data streams,Lin Qiao; Divyakant Agrawal; Amr El Abbadi,Although traditional databases and data warehouses have been exploited widely to managepersistent data; a large number of applications from sensor network need functionalsupports for transient data in the continuous data stream. One of the crucial functions is tosummarize the data items within a sliding window. A sliding window contains a fixed widthspan of data elements. The data items are implicitly deleted from the sliding window; when itmoves out of the window scope. Several one-dimensional histograms have been proposedto store the succinct time information in a sliding window. Such histograms; however; onlyhandle the data items with attribute values in unary domains. In this paper; we explore theproblem of extending the value to a multi-valued domain. A two-dimensional histogram; thehybrid histogram; is proposed to support sliding window queries on a practical multi …,Scientific and Statistical Database Management; 2003. 15th International Conference on,2003,40
Cooperative modeling in applied geographic research,Gustavo Alonso; AMR EL ABBADI,The characteristics of geographic data and the nature of geographic research require theparticipation of many agents. Data is generated by multiple sources (satellites; groundobservation; weather stations; photography; etc.); accessed; processed and transformed bymany users and available for use to an even larger population of users. Lack of coordinationamong all these different agents may render large amounts of work useless. Most existingGIS (Geographic Information Systems) do not provide any support for cooperative work;which adds to the problem. To overcome this serious limitation while still allowing users totake advantage of GIS technology; we propose GOOSE; a system implemented as a toplayer for existing GIS. GOOSE provides the tools for constructing large geographic models ina cooperative environment with potentially many users and participants.,International Journal of Intelligent and Cooperative Information Systems,1994,40
Anónimos: An lp-based approach for anonymizing weighted social network graphs,Sudipto Das; Omer Egecioglu; Amr El Abbadi,The increasing popularity of social networks has initiated a fertile research area ininformation extraction and data mining. Anonymization of these social graphs is important tofacilitate publishing these data sets for analysis by external entities. Prior work hasconcentrated mostly on node identity anonymization and structural anonymization. But withthe growing interest in analyzing social networks as a weighted network; edge weightanonymization is also gaining importance. We present Anónimos; a Linear Programming-based technique for anonymization of edge weights that preserves linear properties ofgraphs. Such properties form the foundation of many important graph-theoretic algorithmssuch as shortest paths problem; k-nearest neighbors; minimum cost spanning tree; andmaximizing information spread. As a proof of concept; we apply Anónimos to the shortest …,IEEE Transactions on Knowledge and Data Engineering,2012,39
Space-efficient data cubes for dynamic environments,Mirek Riedewald; Divyakant Agrawal; Amr El Abbadi; Renato Pajarola,Abstract Data cubes provide aggregate information to support the analysis of the contents ofdata warehouses and databases. An important tool to analyze data in data cubes is therange query. For range queries that summarize large regions of massive data cubes;computing the query result on-the-fly can result in non-interactive response times. To speedup range queries; values that summarize regions of the data cube are precomputed andstored. This faster response time results in more expensive updates and/or space overhead.While the emphasis is typically on low query and update costs; growing data collectionsincrease the demand for space-efficient approaches. In this paper two techniques arepresented that have the same update and query costs as earlier approaches; withoutintroducing any space overhead.,International Conference on Data Warehousing and Knowledge Discovery,2000,39
Characterizing tenant behavior for placement and crisis mitigation in multitenant DBMSs,Aaron J Elmore; Sudipto Das; Alexander Pucher; Divyakant Agrawal; Amr El Abbadi; Xifeng Yan,Abstract A multitenant database management system (DBMS) in the cloud mustcontinuously monitor the trade-off between efficient resource sharing among multipleapplication databases (tenants) and their performance. Considering the scale of\attn{hundreds to} thousands of tenants in such multitenant DBMSs; manual approaches forcontinuous monitoring are not tenable. A self-managing controller of a multitenant DBMSfaces several challenges. For instance; how to characterize a tenant given its variety ofworkloads; how to reduce the impact of tenant colocation; and how to detect and mitigate aperformance crisis where one or more tenants' desired service level objective (SLO) is notachieved. We present Delphi; a self-managing system controller for a multitenant DBMS;and Pythia; a technique to learn behavior through observation and supervision using …,Proceedings of the 2013 ACM SIGMOD International Conference on Management of Data,2013,38
Live database migration for elasticity in a multitenant database for cloud platforms,Sudipto Das; Shoji Nishimura; Divyakant Agrawal; Amr El Abbadi,ABSTRACT The growing popularity of cloud computing as a platform for deploying internetscale applications has seen a large number of web applications being deployed in thecloud. These applications (or tenants) are typically characterized by small data footprints;different schemas; and variable load patterns. Scalable multitenant database managementsystems (DBMS) running on a cluster of commodity servers are thus critical for a cloudservice provider to support a large number of small applications. Multitenant DBMSs oftencollocate multiple tenants' databases on a single server for effective resource sharing. Dueto the variability in load; elastic load balancing of tenants' data is critical for performance andcost minimization. On demand migration of tenants' databases to distribute load on anelastic cluster of machines is a critical technology for elastic load balancing. Therefore …,CS; UCSB; Santa Barbara; CA; USA; Tech. Rep,2010,38
pCube: Update-efficient online aggregation with progressive feedback and error bounds,Mirek Riedewald; Divyakant Agrawal,Multidimensional data cubes are used in large data warehouses as a tool for onlineaggregation of information. As the number of dimensions increases; supporting efficientqueries as well as updates to the data cube becomes difficult. Another problem that ariseswith increased dimensionality is the sparseness of the data space. In this paper we developa new data structure referred to as the pCube (data cube for progressive querying); tosupport efficient querying and updating of multidimensional data cubes in large datawarehouses. While the pCube concept is very general and can be applied to any type ofquery; we mainly focus on range queries that summarize the contents of regions of the datacube. pCube provides intermediate results with absolute error bounds (to allow tradingaccuracy for fast response time); efficient updates; scalability with increasing …,Scientific and Statistical Database Management; 2000. Proceedings. 12th International Conference on,2000,38
Efficient disk allocation for fast similarity searching,Sunil Prabhakar; Divyakant Agrawal; Amr El Abbadi,Abstract As databases increasingly integrate non-textual information it is becomingnecessary to support efficient similarity searching in addition to range searching. Recently;declustering techniques have been proposed for improving the performance of similaritysearches through parallel I/O. In this paper; we propose a new scheme which provides gooddeclustering for similarity searching. In particular; it does global declustering as opposed tolocal declustering; exploits the availability of extra disks and does not limit the partitioning ofthe data space. Our technique is based upon the Cyclic declustering schemes which weredeveloped for range and partial match queries. We establish; in general; that Cyclicdeclustering techniques outperform previously proposed techniques.,Proceedings of the tenth annual ACM symposium on Parallel algorithms and architectures,1998,38
Thread cooperation in multicore architectures for frequency counting over multiple data streams,Sudipto Das; Shyam Antony; Divyakant Agrawal; Amr El Abbadi,Abstract Many real-world data stream analysis applications such as network monitoring;click stream analysis; and others require combining multiple streams of data arriving frommultiple sources. This is referred to as multi-stream analysis. To deal with high stream arrivalrates; it is desirable that such systems be capable of supporting very high processingthroughput. The advent of multicore processors and powerful servers driven by theseprocessors calls for efficient parallel designs that can effectively utilize the parallelism of themulticores; since performance improvement is possible only through effective parallelism. Inthis paper; we address the problem of parallelizing multi-stream analysis in the context ofmulticore processors. Specifically; we concentrate on parallelizing frequent elements; top-k;and frequency counting over multiple streams. We discuss the challenges in designing an …,Proceedings of the VLDB Endowment,2009,37
High dimensional nearest neighbor searching,Hakan Ferhatosmanoglu; Ertem Tuncel; Divyakant Agrawal; Amr El Abbadi,Abstract As databases increasingly integrate different types of information such as time-series; multimedia and scientific data; it becomes necessary to support efficient retrieval ofmulti-dimensional data. Both the dimensionality and the amount of data that needs to beprocessed are increasing rapidly. As a result of the scale and high dimensional nature; thetraditional techniques have proven inadequate. In this paper; we propose search techniquesthat are effective especially for large high dimensional data sets. We first propose VA+-filetechnique which is based on scalar quantization of the data. VA+-file is especially useful forsearching exact nearest neighbors (NN) in non-uniform high dimensional data sets. We thendiscuss how to improve the search and make it progressive by allowing someapproximations in the query result. We develop a general framework for approximate NN …,Information Systems,2006,37
Distributed resource discovery in large scale computing systems,Abhishek Gupta; Divyakant Agrawal; Amr El Abbadi,There has been significant effort to build high throughput delivering computing systems outof distributed workstations. These systems are growing to accommodate larger number ofworkstations with growing demand. Discovery of available resources in such environmentsis a challenging problem. We present a completely distributed resource discovery solution;which utilizes P2P design to provide a scalable service. Our design allows jobs to search fordesired workstations; as well as; workstations to search for jobs that may run on them.,Applications and the Internet; 2005. Proceedings. The 2005 Symposium on,2005,37
RHist: adaptive summarization over continuous data streams,Lin Qiao; Divyakant Agrawal; Amr El Abbadi,Abstract Maintaining approximate aggregates and summaries over data streams is crucial tohandle the OLAP query workload that arises in applications; such as network monitoring andtelecommunications. Furthermore; since the entire data is not available at all times themaintenance task must be done incrementally. We show that R (elaxed) Hist (ogram) is anappropriate summarization under data stream scenario. In order to reduce query estimationerrors; we propose adaptive approaches which not only capture the data distribution; butalso integrate independent query patterns. We introduce a workload decay model toefficiently capture global workload information and ensure that the query patterns from therecent past are weighted more than queries that are further in the past. We verifyexperimentally that our approach successfully adapts to continuously changing workload …,Proceedings of the eleventh international conference on Information and knowledge management,2002,37
Using automated classification for summarizing and selecting heterogeneous information sources,Ron Dolin; Divyakant Agrawal; Amr El Abbadi; Justin Pearlman,Information retrieval over the Internet increasingly requires the filtering of thousands ofheterogeneous information sources. Important sources of information include not onlytraditional databases with structured data and queries; but also increasing numbers of non-traditional; semi-or unstructured collections such as Web sites; FTP archives; etc. As thenumber and variability of sources increases; new ways of automatically summarizing;discovering; and selecting collections relevant to a user's query are needed. One suchmethod involves the use of classification schemes; such as the Library of CongressClassification (LCC)[10]; within which a collection may be represented based on its content;irrespective of the structure of the actual data or documents. For such a system to be usefulin a large-scale distributed environment; it must be easy to use for both collection …,D-Lib Magazine,1998,37
Transaction management in database systems,Divyakant Agrawal; Amr El Abbadi,*,Database transaction models for advanced applications,1992,37
Towards an elastic and autonomic multitenant database,Aaron J Elmore; Sudipto Das; Divyakant Agrawal; Amr El Abbadi,ABSTRACT The success of cloud computing as a platform for deploying webapplicationshas led to a deluge of applications characterized by small data footprints with unpredictableaccess patterns. A scalable multitenant database management system (DBMS) is thereforean important component of the software stack for platforms supporting these applications.Elastic load balancing and efficient database migration techniques are key requirements foreffective resource utilization and operational cost minimization. Our vision is a DBMS wheremultitenancy is viewed as virtualization in the database layer; and elasticity is a first classnotion with the same stature as scalability; availability etc. We analyze the various models ofdatabase multitenancy; formalize the forms of migration; and identify the design space andresearch goals for an autonomic and elastic multitenant database.,Proc. of NetDB Workshop,2011,36
Epidemic quorums for managing replicated data,JoAnne Holliday; Robert Steinke; Divyakant Agrawal; Amr El Abbadi,In the epidemic model an update is initiated on a single site and is propagated to other sitesin a lazy manner. When combined with version vectors and event logs; this propagationmechanism delivers updates in causal order despite communication failures. We integratequorums into the epidemic model to process transactions on replicated data while ensuringglobal serializability. We present a detailed simulation of a distributed replicated databaseand demonstrate the performance improvements.,Performance; Computing; and Communications Conference; 2000. IPCCC'00. Conference Proceeding of the IEEE International,2000,36
Scalable access within the context of digital libraries,X Cheng; Ron Dolin; M Neary; Sunil Prabhakar; KV Ravi Kanth; Daniel Wu; Divyakant Agrawal; Amr El Abbadi; Michael Freeston; A Singh; T Smith; Jianwen Su,Abstract. This paper presents a summary of some of the work-in-progress within theAlexandria Digital Library Project. In particular; we present scalable methods for locatinginformation at different levels within a distributed digital library environment. Starting at thehigh level; we show how queries can be routed to appropriate information sources. At agiven source; efficient query processing is supported by using materialized views andmultidimensional index structures. Finally; we propose solutions to the problem of storageand retrieval of large objects on both secondary and tertiary storage devices.,International Journal on Digital Libraries,1998,36
Efficient retrieval of multidimensional datasets through parallel I/O,Sunil Prabhakar; Khaled Abdel-Ghaffar; Divyakant Agrawal; Amr El Abbadi,Many scientific and engineering applications process large multidimensional datasets. Animportant access pattern for these applications is the retrieval of data corresponding toranges of values in multiple dimensions. Performance is limited by disk largely due to highdisk latencies. Tiling and distributing the data across multiple disks is an effective techniquefor improving performance through parallel I/O. The distribution of tiles across the disks is animportant factor in achieving gains. Several schemes for declustering multidimensional datato improve the performance of range queries have been proposed in the literature. Weextend the class of cyclic schemes which have been developed earlier for two-dimensionaldata to multiple dimensions. We establish important properties of cyclic schemes; basedupon which we reduce the search space for determining good declustering schemes …,High Performance Computing; 1998. HIPC'98. 5th International Conference on,1998,35
Computational modeling systems,Terence R Smith; Jianwen Su; Amr El Abbadi; Divyakant Agrawal; Gustavo Alonso; Amitabh Saran,Abstract A computational modeling system (CMS) provides scientific investigators with aunified computational environment and easy access to a broad range of modeling tools. Thegoal of a CMS is to provide computational support that increases the efficiency of scientistsin the iterative process of modeling. A CMS consists of a computational modelingenvironment and transparent computational support for the environment. The modelingenvironment is based on a characterization of scientific modeling activities that is focussedon the manner in which scientific concepts are represented; manipulated; and evaluated; inthe scientific modeling process. Based on a formalization of the representation for a conceptas representational structures (or “R-structures”); the process of scientific modeling may beviewed as one in which (1) extensible collections R-structures are constructed; evaluated …,Information Systems,1995,35
Generalizing PIR for practical private retrieval of public data,Shiyuan Wang; Divyakant Agrawal; Amr El Abbadi,Abstract Private retrieval of public data is useful when a client wants to query a public dataservice without revealing the query to the server. Computational Private InformationRetrieval (c PIR) achieves complete privacy for clients; but is deemed impractical since itinvolves expensive computation on all the data on the server. Besides; it is inflexible if theserver wants to charge the client based on the service data that is exposed. k-Anonymity; onthe other hand; is flexible and cheap for anonymizing the querying process; but is vulnerableto privacy and security threats. We propose a practical and flexible approach for the privateretrieval of public data called Bounding-Box PIR (bb PIR). Using bb PIR; a client specifiesboth privacy requirements and a service charge budget. The server satisfies the client'srequirements; and achieves overall good performance in computation and …,IFIP Annual Conference on Data and Applications Security and Privacy,2010,34
On hit inflation techniques and detection in streams of web advertising networks,Ahmed Metwally; Divyakant Agrawal; Amr El Abbad; Qi Zheng,Click fraud is jeopardizing the industry of Internet advertising. Internet advertising is crucialfor the thriving of the entire Internet; since it allows producers to advertise their products; andhence contributes to the well being of e-commerce. Moreover; advertising supports theintellectual value of the Internet by covering the running expenses of the content publishers'sites. Some publishers are dishonest; and use automation to generate traffic to defraud theadvertisers. Similarly; some advertisers automate clicks on the advertisements of theircompetitors to deplete their competitors' advertising budgets. In this paper; we describe theadvertising network model; and discuss the issue of fraud that is an integral problem in suchsetting. We propose using online algorithms on aggregate data to accurately and proactivelydetect automated traffic; preserve surfers' privacy; while not altering the industry model …,Distributed Computing Systems; 2007. ICDCS'07. 27th International Conference on,2007,34
StratOSphere: mobile processing of distributed objects in Java,Daniel Wu; Divyakant Agrawal; Amr El Abbadi,Abstract We describe the dmign and implementation of our Stratosphere project; aframework which unifias distributed objects and mobile code applications. We begin by firstexamining dfierent mobile code parad] gms that distribute pr~ cessing of code and dataresource components across a network. After analyzing these paradigms; and prwenting alattice of functionality; we then develop a layered architecture for Stratosphere; incorporatinghigher levels of m~ bilit. y and interoperabifity at each successive layer. In our design; weprovide an object model that permiti objects to migrate to different sites; select amongdifferent method implementations; and provide new methods and behavior. We describehow we build new semantics in each software layer; and finally; we present sample objectsdeveloped for Stratosphere.,Proceedings of the 4th annual ACM/IEEE international conference on Mobile computing and networking,1998,34
Query processing over peer-to-peer data sharing systems,Ozgur D Sahin; Abhishek Gupta; Divyakant Agrawal; Amr El Abbadi,Abstract Peer-to-peer systems are mainly used for object sharing currently; but they canprovide the infrastructure for many other applications. In this paper; we extend the idea ofobject sharing to data sharing on a peer-to-peer system. We propose a method; which isbased on the CAN [9] system; for efficiently evaluating range queries on such a system. Theanswers of the range queries are cached at the peers and then they are used to answerfurther range queries. The scalability and efficiency of our design is shown throughsimulation.,*,2002,33
The performance of protocols based on locks with ordered sharing,Divyakant Agrawal; Amr El Abbadi; AE Lang,There is growing evidence that for a wide variety of database workloads and systemconfigurations; locking-based concurrency control outperforms other types of concurrencycontrol strategies. However; in the presence of increased data contention; locking protocolssuch as two-phase locking perform poorly. In this paper; we analyze a family of locking-based protocols that employ a new relationship between locks called ordered sharing.Using a centralized database simulation model; we demonstrate that these protocols exhibitcomparable performance to that of traditional locking-based protocols when data contentionis low; and they exhibit superior performance when data contention is high. Furthermore; weshow that the performance of these protocols improves as resources become more plentiful.This is particularly significant because the performance of two-phase locking degrades as …,IEEE Transactions on Knowledge and Data Engineering,1994,33
Using reconfiguration for efficient management of replicated data,Divyakant Agrawal; Amr El Abbadi,Replicated data management protocols have been proposed that exploit a logicallystructured set of copies. These protocols have the advantage that they provide limited fault-tolerance at low communication cost. The proposed protocols can be viewed as analoguesof the read-one write-all protocol in the context of logical structures. In this paper; we start bygeneralizing these protocols in two ways for logical structures. First; the quorum-basedapproach is applied to develop protocols that use structured read and write quorums; thusattaining a high degree of data availability for both read and write operations. Next; thereconfiguration or views approach is developed for these structures; resulting in protocolsthat attain high degrees of availability at significantly low communication cost for readoperations. In this sense; the proposed protocols have the advantages of the read-one …,IEEE Transactions on Knowledge and Data Engineering,1996,32
A non-restrictive concurrency control for object oriented databases,Divyakant Agrawal; Amr El Abbadi,Abstract We propose an algorithm for executing transactions in object oriented databases.The object oriented database model generalizes the classical model of databaseconcurrency control by permitting accesses to class and instance objects; by permittingarbitrary operations on objects as opposed to traditional read and write operations; and byallowing for the nested execution of transactions on objects. In this paper; we first develop auniform methodology for treating both classes and instances. We then develop a two phaselocking protocol with a new relationship between locks called ordered sharing for an objectoriented database. Ordered sharing does not restrict the execution of conflicting operations.Finally; we extend the protocol to allow for nesting. The resulting protocol permits moreconcurrency that other known locking-based protocols.,International Conference on Extending Database Technology,1992,32
Information diffusion in social networks: Observing and influencing societal interests,D Budak; Amr El Abbadi,With hundreds of millions of users worldwide; social networks provide great opportunities forsocial connection; learning; political and social change; as well as individual entertainmentand enhancement in a wide variety of forms. Because many social interactions currently takeplace in online networks; social scientists have access to unprecedented amounts ofinformation about social interaction. Prior to online networks; these investigations requiredresource-intensive activities such as random trials; surveys; and manual data collection togather even small data sets. Now; massive amounts of information about social networksand social interactions are recorded. This wealth of data can allow social scientists to studysocial interactions on a scale and at a level of detail that has never before been possible. Inaddition to providing a platform for scientists to observe social interactions in large scale …,PVLDB,2011,31
Sleuth: Single-publisher attack detection using correlation hunting,Ahmed Metwally; Fatih Emekçi; Divyakant Agrawal; Amr El Abbadi,Abstract Several data management challenges arise in the context of Internet advertisingnetworks; where Internet advertisers pay Internet publishers to display advertisements ontheir Web sites and drive traffic to the advertisers from surfers' clicks. Although advertiserscan target appropriate market segments; the model allows dishonest publishers to defraudthe advertisers by simulating fake traffic to their own sites to claim more revenue. This paperaddresses the case of publishers launching fraud attacks from numerous machines; which isthe most widespread scenario. The difficulty of uncovering these attacks is proportional tothe number of machines and resources exploited by the fraudsters. In general; detecting thisclass of fraud entails solving a new data mining problem; which is finding correlations inmultidimensional data. Since the dimensions have large cardinalities; the search space is …,Proceedings of the VLDB Endowment,2008,30
Multiple query optimization by cache-aware middleware using query teamwork,Kevin O'Gorman; Divyakant Agrawal; Amr El Abbadi,Queries with common sequences of disk accesses can make maximal use of a buffer pool.We developed middleware to promote the necessary conditions in concurrent querystreams; and achieved a speedup of 2.99 in executing a workload derived from the TCP-Hbenchmark.,Data Engineering; 2002. Proceedings. 18th International Conference on,2002,30
Billiard quorums on the grid,Divyakant Agrawal; Ömer Eğecioğlu; Amr El Abbadi,Abstract Maekawa considered a simple but suboptimal grid based quorum generationscheme in which N sites in a network are logically organized in the form of a√ N×√ N grid;and the quorum sets are row-column pairs. Even though the quorum size 2√ N of the gridscheme is twice as large as finite projective plane based optimal size quorums; it has theadvantage of being simple and geometrically evident. In this paper we construct grid basedquorums which use a modified grid; and paths that resemble billiard ball paths instead ofhorizontal and vertical line segments of rows and columns in the grid scheme. The size ofthese quorums is√ 2√ N. The construction and its properties are geometrically evident asin the case of Maekawa's grid; and the quorum sets can be generated efficiently.,Information Processing Letters,1997,30
Squall: Fine-grained live reconfiguration for partitioned main memory databases,Aaron J Elmore; Vaibhav Arora; Rebecca Taft; Andrew Pavlo; Divyakant Agrawal; Amr El Abbadi,Abstract For data-intensive applications with many concurrent users; modern distributedmain memory database management systems (DBMS) provide the necessary scale-outsupport beyond what is possible with single-node systems. These DBMSs are optimized forthe short-lived transactions that are common in on-line transaction processing (OLTP)workloads. One way that they achieve this is to partition the database into disjoint subsetsand use a single-threaded transaction manager per partition that executes transactions one-at-a-time in serial order. This minimizes the overhead of concurrency control mechanisms;but requires careful partitioning to limit distributed transactions that span multiple partitions.Previous methods used off-line analysis to determine how to partition data; but the dynamicnature of these applications means that they are prone to hotspots. In these situations; the …,Proceedings of the 2015 ACM SIGMOD International Conference on Management of Data,2015,29
Resilient logical structures for efficient management of replicated data,Divyakant Agrawal; Amr El Abbadi,Abstract Replicated data management protocols have been pro posed that exploit a logicallystructured set of copies. These protocols have the advantage that they provide limited fault-tolerance at low communication cost. The propceed protocols can be viewed as analoguesof the read-one write-all protocol in the context of logical structures. In this paper; theseprotocols are generalized in two ways for a grid and a tree structure. First; the quorum basedapproach is applied to develop protocols that use structured read and write quorums; thusattaining a high degree of data availability for both read and write operations. Next; thereconfiguration or views approach is developed for both grid and tree structures resulting inprotocols that attain high degrees of availability at significantly low communication cost forread operations. In this sense; the proposed protocols have the advantages of the …,VLDB,1992,29
Query estimation by adaptive sampling,Yi-Leh Wu; Divyakant Agrawal; Amr El Abbadi,The ability to provide accurate and efficient result estimations of user queries is veryimportant for the query optimizer in database systems. In this paper; we show that thetraditional estimation techniques with data reduction points of view do not producesatisfiable estimation results if the query patterns are dynamically changing. We further showthat to reduce query estimation error; instead of accurately capturing the data distribution; itis more effective to capture the user query patterns. In this paper; we propose queryestimation techniques that can adapt to user query patterns for more accurate estimates ofthe size of selection or range queries over databases.,Data Engineering; 2002. Proceedings. 18th International Conference on,2002,28
Planned disconnections for mobile databases,J Holliday; Divyakant Agrawal; Amr El Abbadi,As mobility permeates todays computing environment; we envision applicationinfrastructures that will increasingly use mobile technologies. Traditional databaseapplications will need to integrate mobile entities: people and computers. The authorsdevelop a distributed database framework for mobile environments. A key requirement insuch an environment is to support frequent connection and disconnection of database sites.,Database and Expert Systems Applications; 2000. Proceedings. 11th International Workshop on,2000,28
Integrating security with fault-tolerant distributed databases,Divyakant Agrawal; Amr El Abbadi,Abstract Replication reduces the security of data in a distributed environment. In this paper;we address the issue of maintaining security in a fault-tolerant replicated database. Wepresent a protocol that combines both security and reliability aspects in a database system.Although this protocol provides the desired level of security; it does so at the expense ofavailability. By integrating a propagation mechanism with our protocol; we are able toachieve a high level of security and availability.,The Computer Journal,1990,28
Anonymizing edge-weighted social network graphs,Sudipto Das; Omer Egecioglu; Amr El Abbadi,ABSTRACT The increasing popularity of social networks has initiated a fertile research areain information extraction and data mining. Although such analysis can facilitate betterunderstanding of sociological; behavioral; and other interesting phenomena; there isgrowing concern about personal privacy being breached; thereby requiring effectiveanonymization techniques. If we consider the social graph to be a weighted graph; then theproblem of anonymization can be of various types: node identity anonymization; structuralanonymization; or edge weight anonymization. In this paper; we consider edge weightanonymization. Our approach builds a linear programming (LP) model which preservesproperties of the graph that are expressible as linear functions of the edge weights. Suchproperties form the foundations of many important graph-theoretic algorithms such as …,Computer Science; UC Santa Barbara; Tech. Rep. CS-2009-03,2009,27
The performance of two phase commit protocols in the presence of site failures,Mei-Ling Liu; Divyakant Agrawal; Amr El Abbadi,Abstract The two phase commit is an important protocol in distributed database systems.Much of the existing literature on the protocol is restricted to discussing and analyzing theprotocol (and its variants) in the absence of failures. Very little; especially in quantitativeterms; has been written about its performance in the presence of site failures. In this study;we use a simulation testbed of a distributed database system to quantify the differences inthe performances of four widely known variants of the 2PC protocols (the generic 2PC;presumed commit; presumed abort; and early prepare). Our study covers both the no-failurecase and the case of site failures. We present a number of interesting results based on ourexperiments. One is that the performance of these protocols is highly dependent on themessage-processing latency at the transaction coordinator site. Another is that the …,Distributed and Parallel Databases,1998,27
A unified approach to concurrency control and transaction recovery,Gustavo Alonso; Radek Vingralek; Divyakant Agrawal; Yuri Breitbart; Amr El Abbadi; Hans Schek; Gerhard Weikum,Abstract In this paper; we have addressed an open problem posed by [SWY93]: how tocharacterize the class of histories PRED in a constructive way so that unified schedulingprotocols can be derived from it. We have slightly modified the original definitions ofexpanded histories and PRED to account for certain executions; and we have provided anequivalent class; SOT; with a more constructive definition. This new class is used as thebasis for several protocols that implement unified concurrency control and recovery in anefficient manner. So far; our model is restricted to read and write operations. However; boththe model and the developed protocols can be generalized to transactions with semanticallyrich operations where recovery is based on compensating operations.,International Conference on Extending Database Technology,1994,27
Browsing large digital library collections using classification hierarchies,Steven Geffner; Divyakant Agrawal; A El Abbadi; T Smith,Abstract Summarization of intermediary query result sets plays an important role when usersbrowse through digital library collections. Summarization enables users to quickly digest theresults of their queries; and provides users with important information they can use to narrowtheir search interactively. Techniques from the field of data analysis may be applied to theproblem of generating summaries of query results efficiently. Such techniques should permitthe incorporation of classification hierarchies in order to provide powerful browsingenvironments for digital library users.,Proceedings of the eighth international conference on Information and knowledge management,1999,26
Data management in the cloud: challenges and opportunities,Divyakant Agrawal; Sudipto Das; Amr El Abbadi,Abstract Cloud computing has emerged as a successful paradigm of service-orientedcomputing and has revolutionized the way computing infrastructure is used. This successhas seen a proliferation in the number of applications that are being deployed in variouscloud platforms. There has also been an increase in the scale of the data generated as wellas consumed by such applications. Scalable database management systems form a criticalpart of the cloud infrastructure. The attempt to address the challenges posed by themanagement of big data has led to a plethora of systems. This book aims to clarify some ofthe important concepts in the design space of scalable data management in cloudcomputing infrastructures. Some of the questions that this book aims to answer are: theappropriate systems for a specific set of application requirements; the research …,Synthesis Lectures on Data Management,2012,25
Diffusion of information in social networks: Is it all local?,Ceren Budak; Divyakant Agrawal; Amr El Abbadi,Recent studies on the diffusion of information in social networks have largely focused onmodels based on the influence of local friends. In this paper; we challenge thegeneralizability of this approach and revive theories introduced by social scientists in thecontext of diffusion of innovations to model user behavior. To this end; we study variousdiffusion models in two different online social networks; Digg and Twitter. We first evaluatethe applicability of two representative local influence models and show that the behavior ofmost social networks users are not captured by these local models. Next; driven by theoriesintroduced in the diffusion of innovations research; we introduce a novel diffusion modelcalled Gaussian Logit Curve Model (GLCM) that models user behavior with respect to thebehavior of the general population. Our analysis shows that GLCM captures user …,Data Mining (ICDM); 2012 IEEE 12th International Conference on,2012,25
Using multicast communication to reduce deadlock in replicated databases,J Holliday; Divyakant Agrawal; Amr El Abbadi,Obtaining good performance from a distributed replicated database that allows updatetransactions to originate at any site while ensuring one-copy serializability is a challenge. Apopular analysis of deadlock probabilities in replicated databases shows that the deadlockrate for the system is high and increases as the third power of the number of replicas. Weshow how a replica management protocol that uses atomic broadcast for replica updatereduces the occurrence of deadlocks and the dependency on the number of replicas. Theanalysis is confirmed by simulation experiments.,Reliable Distributed Systems; 2000. SRDS-2000. Proceedings The 19th IEEE Symposium on,2000,25
Data warehousing alternatives for mobile environments,Ioana Stanoi; Divyakant Agrawal; A El Abbadi; Shirish Hemant Phatak; BR Badrinath,With rapid advancement in technology; mobile devices are increasingly becomino the norm.These devices are char- P acterized by their need to operate even when they are dis- connectedfrom the fixed non-mobile world. Since existing software technology is tuned to applications thatoperate in a fully connected world; this requirement of disconnected 6p- eration creates a needto adapt existing software technology to a partially disconnected world. Databases and filesystemshave already been adapted to operate in a partially disconnected environment. However; littlework has been done in the context of data warehous- ing in such an environment. We believethat there is a real need for adapting existing data warehousing technology for the mobileworld. In this position paper; we show how tech- niques for hierarchical data warehouse managementcan be applied to data warehouses in a mobile environment. The techniques can be …,Proceedings of the 1st ACM international workshop on Data engineering for wireless and mobile access,1999,24
Managing Concurrent Activities in Collaborative Environments.,Divyakant Agrawal; John L Bruno; Amr El Abbadi; Vashudha Krishnaswamy,*,CoopIS,1995,24
Maintaining XPath views in loosely coupled systems,Arsany Sawires; Junichi Tatemura; Oliver Po; Divyakant Agrawal; Amr El Abbadi; K Selçuk Candan,Abstract We address the problem of maintaining materialized XPath views in environmentswhere the view maintenance system and the base data system are loosely-coupled. Weshow that the recently proposed XPath view maintenance techniques require tight coupling;and thus are not practical for loosely-coupled systems. Our solution adapts to loose-couplingby using information that is fully available through standard XPath interfaces. Thisinformation consists of the view definition; the update statement; and the current materializedview result. Under this model; incremental maintenance is not always possible; thus;maintaining the consistency of the views requires frequent view recomputations. Our goal isto reduce the frequency of view recomputation by detecting cases where a base update isirrelevant to a view; and cases where a view is self maintainable given a base update. We …,Proceedings of the 32nd international conference on Very large data bases,2006,23
Towards optimal I/O scheduling for MEMS-based storage,Hailing Yu; Divyakant Agrawal; Amr El Abbadi,MEMS-based storage devices are currently being developed to narrow the gap betweenprocessor and disk speeds. MEMS-based storage devices have a different architecture fromdisk devices; thus algorithms; such as I/O scheduling and data placement; designed fordisks need to be revisited. In this paper we focus on developing an I/O scheduling algorithmfor MEMS-based storage devices. Our theoretical analysis shows that this algorithm isguaranteed to perform within twice the optimal time for any workload.,Mass Storage Systems and Technologies; 2003.(MSST 2003). Proceedings. 20th IEEE/11th NASA Goddard Conference on,2003,23
Scheduling tertiary I/O in database applications,Sunil Prabhakar; Divyakant Agrawal; Amr El Abbadi; Ambuj Singh,We study the problem of scheduling I/O requests for tertiary storage libraries to improveperformance. The focus is on scheduling policies that process all requests on a loadedmedium before unloading it. For single drive settings; an efficient algorithm that producesoptimal schedules is developed. For multiple drives; the problem is shown to be NPcomplete. Efficient and effective heuristics are presented for the multiple drives case. Thescheduling policies developed achieve significant performance gains over more naive firstcome first served policies. The study is general enough to be applicable to any storagelibrary handling removable media; such as tapes or optical disks.,Database and Expert Systems Applications; 1997. Proceedings.; Eighth International Workshop on,1997,23
Synchronization in nested transactions,Rodolfo Ferreira Resende,Abstract Database systems take advantage of concurrent activities in order to offer betterthroughput and response time for programs accessing the shared data. In spite of employingconcurrency; database systems offer a programming environment where the applicationsprogrammer is not required to write programs that have to synchronize to each other. Thescheduler is the database system component that manages the concurrent accesses. Theexecution of application programs as seen by the scheduler is called a transaction. Thescheduler ensures that; in spite of the possible interleaving of accesses; the effects of thetransactions will appear atomic to each other. The scheduler does this by following aconcurrency control protocol. Transaction atomicity in term of concurrency control issues isknown as serializability. Most of the schedulers ensures conflict serializability; by basing …,*,1994,23
Performance characteristics of protocols with ordered shared locks,Divyakant Agrawal; Amr El Abbadi; AE Lang,A family of locking-based protocols is analyzed that use a novel mode of locks calledordered sharing. Using a centralized database simulation model; it is demonstrated thatthese protocols exhibit comparable performance to that of traditional locking-basedprotocols when data contention is low and exhibit superior performance when datacontention is high. It is shown that the performance of these protocols improves as physicalresources become more plentiful. This is particularly significant since two-phase lockingdegrades due to data and not resource contention. Thus; introducing additional resourcesimproves the performance of the proposed protocols while it does not benefit two-phaselocking significantly.,Data Engineering; 1991. Proceedings. Seventh International Conference on,1991,23
Progressive ranking of range aggregates,Hua-Gang Li; Hailing Yu; Divyakant Agrawal; Amr El Abbadi,Abstract Ranking-aware queries have been gaining much attention recently in manyapplications such as multimedia databases; search engines and data streams. They are;however; not only restricted to such applications but are also very useful in On-LineAnalytical Processing (OLAP) applications. In this paper; we introduce aggregation rankingqueries in OLAP data cubes motivated by an online advertisement tracking data warehouseapplication. These queries aggregate information over a specified range and then return theranked order of the aggregated values. For instance; an advertiser might be interested in thetop-k publishers over the last three months in terms of sales obtained through the onlineadvertisements placed on the publishers. They differ from range aggregate queries in thatrange aggregate queries are mainly concerned with an aggregate operator such as SUM …,Data & Knowledge Engineering,2007,22
Twix: Twig structure and content matching of selective queries using binary labeling,S Alireza Aghili; Hua-Gang Li; Divyakant Agrawal; Amr El Abbadi,Abstract XML queries specify predicates on the content and the structure of the elements oftree-structured XML documents. Hence; discovering the occurrences of twig (tree structure)query patterns is a core operation for XML query processing. In this paper; we propose anovel technique for matching XML twig query patterns; named TWIX; which results in asubstantial reduction of the search space; response time; size and structure invariancethrough a distributed binary labeling and tree traversal algorithm. Furthermore; TWIXbenefits from an interactive graphical user interface for twig query matching.,Proceedings of the 1st international conference on Scalable information systems,2006,22
Techniques for efficient routing and load balancing in content-addressable networks,Ozgur D Sahin; Divyakant Agrawal; Amr El Abbadi,As a distributed hash table (DHT); a content addressable network (CAN) provides efficientrouting and object location in a decentralized manner while offering fault tolerance anddynamic peer operations. However; as opposed to other DHTs that use a flat ID space; CANuses a multi-dimensional logical space. DHTs usually require O (logN) routing informationper peer and provide routing in O (logN) hops; where N is the number of peers in the system.In CAN; on the other hand; each peer keeps only constant amount of routing information andthe routing takes O (dN/sup 1/d/) hops; where d is the dimensionality of the logical space.Hence the routing performance of CAN is worse than other DHTs especially when d is small.In this paper; we describe and evaluate several schemes for efficient routing in CAN bykeeping additional routing information at the peers. Furthermore; due to the underlying …,Peer-to-Peer Computing; 2005. P2P 2005. Fifth IEEE International Conference on,2005,22
Posse: A framework for optimizing incremental view maintenance at data warehouses,Kevin O’Gorman; Divyakant Agrawal; Amr El Abbadi,Abstract We propose the Posse 1 framework for optimizing incremental view maintenance atdata warehouses. To this end; we show how for a particular method of consistent probing itis possible to have the power of SQL view queries with multiset semantics; and at the sametime have available a spectrum of concurrency from none at all as in previously proposedsolutions to the maximum concurrency obtained by issuing all probes in parallel. We thenshow how optimization of the probing process can be used to select various degrees ofconcurrency for the desired tradeoffs of concurrency against processing cost and messagesize.,International Conference on Data Warehousing and Knowledge Discovery,1999,22
Secure data management service on cloud computing infrastructures,Divyakant Agrawal; Amr El Abbadi; Fatih Emekci; Ahmed Metwally; Shiyuan Wang,Abstract Data outsourcing or database as a service is a new paradigm for data managementin which a third party service provider hosts a database as a service. The service providesdata management for its customers and thus obviates the need for the service user topurchase expensive hardware and software; deal with software upgrades and hireprofessionals for administrative and maintenance tasks. Since using an external databaseservice promises reliable data storage at a low cost it is very attractive for companies. Such aservice would also provide universal access; through the Internet to private data stored atreliable and secure sites in cloud computing infrastructures. However; recent governmentallegislations; competition among companies; and data thefts mandate companies to usesecure and privacy preserving data management techniques. The data provider …,*,2011,21
Efficient integration and aggregation of historical information,Mirek Riedewald; Divyakant Agrawal; Amr El Abbadi,Abstract Data warehouses support the analysis of historical data. This often involvesaggregation over a period of time. Furthermore; data is typically incorporated in thewarehouse in the increasing order of a time attribute; eg; date of sale or time of atemperature measurement. In this paper we propose a framework to take advantage of thisappend only nature of updates due to a time attribute. The framework allows us to integratelarge amounts of new data into the warehouse and generate historical summaries efficiently.Query and update costs are virtually independent from the extent of the data set in the timedimension; making our framework an attractive aggregation approach for append-only datastreams. A specific instantiation of the general approach is developed for MOLAP datacubes; involving a new data structure for append-only arrays with pre-aggregated values …,Proceedings of the 2002 ACM SIGMOD international conference on Management of data,2002,21
The group paradigm for concurrency control protocols,Amr El Abbadi; Sam Toueg,The authors propose a paradigm for developing; describing; and proving the correctness ofconcurrency control protocols for replicated databases in the presence of failures orcommunication restrictions. The approach used is to hierarchically divide the problem ofachieving one-copy serializability by introducing the notion of a'group'that is a higher level ofabstraction than transactions. Instead of dealing with the overall problem; the paradigmbreaks it into two simpler ones:(1) a local policy for each group that ensures a total order ofall transactions in that group; and (2) a global policy that ensures a correct serialization of allgroups. The paradigm is used to demonstrate the similarities between several concurrencycontrol protocols by comparing the way they achieve correctness.,IEEE transactions on knowledge and data engineering,1989,21
Minimizing commit latency of transactions in geo-replicated data stores,Faisal Nawab; Vaibhav Arora; Divyakant Agrawal; Amr El Abbadi,Abstract Cross datacenter replication is increasingly being deployed to bring data closer tothe user and to overcome datacenter outages. The extent of the influence of wide-areacommunication on serializable transactions is not yet clear. In this work; we derive a lower-bound on commit latency. The sum of the commit latency of any two datacenters is at leastthe Round-Trip Time (RTT) between them. We use the insights and lessons learned whilederiving the lower-bound to develop a commit protocol; called Helios; that achieves lowcommit latencies. Helios actively exchanges transaction logs (history) between datacenters.The received logs are used to decide whether a transaction can commit or not. The earliestpoint in the received logs that is needed to commit a transaction is decided by Helios toensure a low commit latency. As we show in the paper; Helios is theoretically able to …,Proceedings of the 2015 ACM SIGMOD International Conference on Management of Data,2015,20
Who’s driving this cloud? towards efficient migration for elastic and autonomic multitenant databases,Aaron Elmore; Sudipto Das; Divyakant Agrawal; Amr El Abbadi; Sudipto Das; Shashank Agarwal; Divyakant Agrawal; Amr El Abbadi; Chris Bunch; Navraj Chohan; Chandra Krintz; Jovan Chohan; Jonathan Kupferman; Puneet Lakhina; Yiming Li; Yoshihide Nomura; Ceren Budak; Divyakant Agrawal; Amr El Abbadi; Christopher Coffin; Sehwan Kim; Tobias Hollerer; Shiyuan Wang; Divyakant Agrawal; Amr El Abbadi; Lamia Youseff; Rich Wolski; Fang Yu; Tevfik Bultan; Oscar H Ibarra; Xia Zhou; Alessandra Sala; Haitao Zheng; Lorenzo Cavallaro; Christopher Kruegel; Giovanni Vigna; Fang Yu; Muath Alkhalaf; Tevfik Bultan; Lili Cao; Lei Yang; Heather Zheng; Christopher C Cipriano; Teofilo F Gonzalez; Steffen Gauglitz; Tobias Höllerer; Xia Zhou; Heather Zheng; Omer Egecioglu; Peterson Trethewey; Tobias Hollerer; Sudipto Das; Shyam Antony; Divyakant Agrawal; Amr El Abbadi; Sudipto Das; Ömer Egecioglu; Amr El Abbadi; Navraj Chohan; Chris Bunch; Sydney Pang; Chandra Krintz; Nagy Mostafa; Sunil Soman; Rich Wolski; Ömer Egecioglu; Oscar H Ibarra; Nagy Mostafa; Chandra Krintz; Sudipto Das; Shyam Antony; Divyakant Agrawal; Amr El Abbadi,Abstract The success of cloud computing as a platform for deploying webapplications hasled to a deluge of applications characterized by small data footprints but unpredictableaccess patterns. An autonomic and scalable multitenant database management system(DBMS) is therefore an important component of the software stack for platforms supportingthese applications. Elastic load balancing is a key requirement for effective resourceutilization and operational cost minimization. Efficient techniques for database migration arethus essential for elasticity in a multitenant DBMS. Our vision is a DBMS where multitenancyis viewed as virtualization in the database layer; and migration is a first class notion with thesame stature as scalability; availability etc. This paper serves as the first step in thisdirection. We analyze the various models of database multitenancy; formalize the forms of …,Tecnical Report,2010,20
Probe: Multi-dimensional range queries in p2p networks,Ozgur D Sahin; Shyam Antony; Divyakant Agrawal; Amr El Abbadi,Abstract Structured P2P systems are effective for exact key searches in a distributedenvironment as they offer scalability; self-organization; and dynamicity. These valuableproperties also make them a candidate for more complex queries; such as range queries. Inthis paper; we describe PRoBe; a system that supports range queries over multiple attributesin P2P networks. PRoBe uses a multi-dimensional logical space for this purpose and mapsdata items onto this space based on their attribute values. The logical space is divided intohyper-rectangles; each maintained by a peer in the system. The range queries correspondto hyper-rectangles which are answered by forwarding the query to the peers responsible foroverlapping regions of the logical space. We also propose load balancing techniques andshow how cached query answers can be utilized for the efficient evaluation of similar …,International Conference on Web Information Systems Engineering,2005,20
NAPA: Nearest available parking lot application,Hae Don Chon; Divyakant Agrawal; Amr El Abbadi,With the advances in wireless communications and mobile device technologies; location-based applications or services will become an essential part of future applications. We havedeveloped a location-based application called NAPA (Nearest Available Parking lotApplication) that assists users to find the nearest parking space on campus. NAPA is anexample of an application which combines a number of new features; such as location-based; wireless communication and a directory service like LDAP (Lightweight DirectoryAccess Protocol).,Data Engineering; 2002. Proceedings. 18th International Conference on,2002,20
Using wavelet decomposition to support progressive and approximate range-sum queries over data cubes,Yi-Leh Wu; Divyakant Agrawal; Amr El Abbadi,ABSTRACT Data cubes are designed to pro vide aggregateinformation that can be used toanalyze the contents of databases and data warehouses. A range query applies anaggregation operation (eg; SUM; AVERAGE) over all selected cells in a data cube; wherethe selection is specified by providing ranges of values on different dimensions. Previousapproaches to process the range sum query on data cubes (eg; prefix sum) have low querycosts but have high update costs. We use the discrete wavelet transformation to decomposea data cube into w avelet coefficients of different resolutions. The resulting decomposed datacube can be used for progressiv eand appro ximatequery processing. This new approachcan handle clustered and sparse data gracefully and can provide efficient performance forboth queries and updates; which makes the wavelet decomposition technique suitable for …,Proceedings of the ninth international conference on Information and knowledge management,2000,20
Analysis of quorum-based protocols for distributed (k+ 1)-exclusion,Divyakant Agrawal; Ömer Egecioglu; A Abbadi,A generalization of the majority quorum for the solution of the distributed (k+ 1)-exclusionproblem is proposed. This scheme produces a family of quorums of varying sizes andavailabilities indexed by integral divisors r of k. The cases r= 1 and r= k correspond to knownmajority based quorum generation algorithms MAJ and DIV; whereas intermediate values ofr interpolate between these two extremes. A cost and availability analysis of the proposedmethods is also presented. An interesting implication of this analysis is that in a reasonablyreliable environment with a large number of sites; even protocols with low communicationcosts attain high availability.,IEEE Transactions on Parallel and Distributed Systems,1997,20
Storage efficient replicated databases,Divyakant Agrawal; Amr El Abbadi,A fragmentation method that reduces the storage overhead of replicated objects isproposed. A data-management protocol for these fragmented objects is presented; and it isshown that this protocol is a generalization of quorum algorithms for replicated data in whichobjects are not fragmented. Although the protocol reduces storage requirements; it does notachieve a high level of resiliency for both read and write operations. By integrating apropagation mechanism with the protocol; the same level of resiliency is achieved for bothread and write operations as other quorum protocols; while the storage cost is reduced.,IEEE Transactions on Knowledge and Data Engineering,1990,20
An overview of the ISIS project,Kenneth P Birman; Amr El Abbadi; Wally Dietrich; Thomas A Joseph; Thomas Raeuchle,The goal of the ISIS projest is to provide a high-level support for fault-tolerant distributedcomputing by automatically replicating data and code. The extent to which information isreplicated and the physical location of information are not specified directly by theprogrammer; but are instead inferred from a specification; which looks much like aconventional program in an object-oriented language. This novel approach to fault-tolerantsoftware construction requires much less sophistication from programmers than currentalternatives. Moreover; optimization techniques that would be too complex forimplementation in general purpose applications can be supported by the ISIS system. Thisoverview discusses the goals of the project; its current status; and some of the implications ofour work.,*,1984,20
Where the blogs tip: connectors; mavens; salesmen and translators of the blogosphere,Ceren Budak; Divyakant Agrawal; Amr El Abbadi,Abstract Why is it that some ideas or products become unusually successful and get adoptedwidely while others don't? This question has been puzzling many social scientists;economists; politicians and educators for a long time. Knowing the answer to this questioncan help deliberately start such successful cascades. Many theories have been introducedin this topic by economists and social scientists and these theories have been backed bysmall numbers of case studies. In this paper; we will focus on the popular theoriesintroduced in" The Tipping Point" by Malcolm Gladwell. The basic idea is the crucial effect ofthree types of" fascinating" people that the author calls mavens; connectors and salesmenon the effectiveness of a cascade. Those people are claimed to" play a critical role in theword-of-mouth epidemics that dictate our tastes; trends and fashions". In this work; we …,Proceedings of the First Workshop on Social Media Analytics,2010,19
Reducing Storage for Quorum Consensus Algorithms.,Divyakant Agrawal; Amr El Abbadi,Abstract In this paper; we first develop a fragmentation method that reduces the storageoverhead of replicated objects. We then present a data management protocol for thesefragmented objects; and show that this protocol is a generalisation of quorum consensusalgorithms for replicated data in which objects are not fragmented. Although this protocolreduces storage requirements; it does not achieve the same level of resiliency for both readand write operations. By integrating a log-based propagation mechanism with our protocol;we are able to achieve the same level of resiliency for both read and write operations asother quorum consensus protocols; while reducing the storage cost.,VLDB,1988,19
Secure and privacy-preserving database services in the cloud,Divyakant Agrawal; Amr El Abbadi; Shiyuan Wang,Cloud computing becomes a very successful paradigm for data computing and storage.Increasing concerns about data security and privacy in the cloud; however; have arisen.Ensuring security and privacy for data management and query processing in the cloud iscritical for better and broader uses of the cloud. This tutorial covers recent research on cloudsecurity and privacy; while focusing on the works that protect data confidentiality and queryaccess privacy for sensitive data being stored and queried in the cloud. We provide acomprehensive study of state-of-the-art schemes and techniques for protecting dataconfidentiality and access privacy; and explain their tradeoffs in security; privacy;functionality and performance.,Data Engineering (ICDE); 2013 IEEE 29th International Conference on,2013,18
Secure and privacy-preserving data services in the cloud: A data centric view,Divyakant Agrawal; Amr El Abbadi; Shiyuan Wang,Abstract Cloud computing becomes a successful paradigm for data computing and storage.Increasing concerns about data security and privacy in the cloud; however; have emerged.Ensuring security and privacy for data management and query processing in the cloud iscritical for better and broader uses of the cloud. This tutorial covers some common cloudsecurity and privacy threats and the relevant research; while focusing on the works thatprotect data confidentiality and query access privacy for sensitive data being stored andqueried in the cloud. We provide a comprehensive study of state-of-the-art schemes andtechniques for protecting data confidentiality and access privacy; which make differenttradeoffs in the multidimensional space of security; privacy; functionality and performance.,Proceedings of the VLDB Endowment,2012,18
Is homomorphic encryption the holy grail for database queries on encrypted data?,Shiyuan Wang; Divyakant Agrawal; Amr El Abbadi,Abstract. Homomorphic encryption has been used for supporting simple aggregations;numeric calculations on encrypted data as well as for private information retrieval. Recently;theoretical breakthroughs on homomorphic encryption resulted in fully homomorphicencryption; which is able to compute arbitrary functions on encrypted data. As a result;homomorphic encryption is generally believed to be the holy grail for solving databasequeries on encrypted data. However; there has not been a systematic study that analyzesthe use of fully homomorphic encryption for solving database queries beyond simpleaggregations and numeric calculations; such as selection; range and join queries. Ourpaper fills this gap by identifying what fully homomorphic encryption can do and what itcannot do well for supporting general database queries at a conceptual level. We show …,University of California; Santa Barbara; USA,2012,18
Fast algorithms for heavy distinct hitters using associative memories,Nagender Bandi; Divyakant Agrawal; Amr El Abbadi,Real-time detection of worm attacks; port scans and distributed denial of service (DDoS)attacks; as network packets belonging to these security attacks flow through a networkrouter; is of paramount importance. In a typical worm attack; a worm infected host tries tospread the worm by scanning a number of other hosts thus resulting in significant number ofnetwork connections at an intermediate router. Detecting such attacks amounts to finding allhosts that are associated with unusually high number of other hosts; which is equivalent tosolving the classic heavy distinct hitter problem over data streams. While several heavydistinct hitter solutions have been proposed and evaluated in a standard CPU setting; mostof the above applications typically execute on special networking architectures callednetwork processing units (NPUs). These NPUs interface with special associative …,Distributed Computing Systems; 2007. ICDCS'07. 27th International Conference on,2007,18
FLUX: Fuzzy content and structure matching of XML range queries,Hua-Gang Li; S Alireza Aghili; Divyakant Agrawal; Amr El Abbadi,Abstract An XML range query may impose predicates on the numerical or textual contents ofthe elements and/or their respective path structures. In order to handle content and structurerange queries efficiently; an XML query processing engine needs to incorporate effectiveindexing and summarization techniques to efficiently partition the XML document and locatethe results. In this paper; we propose a dynamic summarization and indexing method; FLUX;based on Bloom filters and B+-trees to tackle these problems. The results of our extensiveexperimental evaluations indicated the efficiency of the proposed system.,Proceedings of the 15th international conference on World Wide Web,2006,18
Database replication using epidemic communication,JoAnne Holliday; Divyakant Agrawal; Amr El Abbadi,Abstract There is a growing interest in asynchronous replica management protocols in whichdatabase transactions are executed locally; and their effects are incorporatedasynchronously on remote database copies. In this paper we investigate an epidemicupdate protocol that guarantees consistency and serializability in spite of a write-anywherecapability and conduct simulation experiments to evaluate this protocol. Our results indicatethat this epidemic approach is indeed a viable alternative to eager update protocols for adistributed database environment where serializability is needed.,European Conference on Parallel Processing,2000,18
On the implementation of the quorum concensus protocol,ML Liu; D Agrawal; A El Abbadi,Abstract Although replica control has been the subject of intensive research; it has yet tofulfill its promise in practical applications. A major reason for this lack of acceptance is thecomplexity of the implementation of these protocols. This paper describes a simple andefficient implementational approach for one such protocols; the quorum consensus protocol.1 Introduction Replicated data is employed in distributed databases to enhance dataavailability: multiple copies of a critical data item are maintained on different sites; so that thedata item can be retrieved even if some copies of the data item cannot be accessed due tosystem failures. However; this benefit of data availability is only realized at the cost ofelaborate algorithms that hide the underlying complexity of maintaining multiple copies of asingle data item. Ideally; an application should not be cognizant of the existence of …,In Proc. Parallel and Distributed Computing Systems,1995,18
Database and modeling systems for the earth sciences,Terence R.  Smith; Jianwen Su; Divyakant Agrawal; Amr El  Abbadi,We are involved in a cooperative study with a group of EOS investigators at the University ofWashington whose long-term goals include the development and application of spatially-distributed models of water; sediment and solute transport in the Amazon basin. From adetailed examination of the computational activities and “requirements” of theseinvestigators; we have found that they lack adequate computational support for the iterativeconstruction and testing of their models. In particular; they are overwhelmed by the largesize and processing requirements of these models. This problem is further compounded bythe requirement to develop the models using a large and heterogeneous collection ofdatasets and the need to couple several complex models. They also lack genuine databasesupport for managing their growing collection of datasets; which contain information in the …,IEEE Data Eng. Bull.,1993,18
A dynamic accessibility protocol for replicated databases,Amr El Abbadi; Sanjay N Dani,Abstract In this paper; we present a protocol for managing replicated data in a distributedsystem. The protocol tolerates both site and communication failures even when they lead topartitioning. Two of the main features of the protocol are the availability levels it provides;and the low communication costs required of user transactions to attain these levels. Inparticular; an object may be accessible even after the failure of most of the sites wherecopies of the objects reside. Furthermore; an object can be read by accessing a single copy;and in general; the cost of executing operations is less than that required by protocols thatattain similar levels of availability. Finally; the protocol provides the database designer withthe flexibility of determining both the degree of availability as well as the cost of executingthe different operations of a data object.,Data & knowledge engineering,1991,18
Big data in online social networks: user interaction analysis to model user behavior in social networks,Divyakant Agrawal; Ceren Budak; Amr El Abbadi; Theodore Georgiou; Xifeng Yan,Abstract With hundreds of millions of users worldwide; social networks provide incredibleopportunities for social connection; learning; political and social change; and individualentertainment and enhancement in a multiple contexts. Because many social interactionscurrently take place in online networks; social scientists have access to unprecedentedamounts of information about social interaction. Prior to the advent of such online networks;these investigations required resource-intensive activities such as random trials; surveys;and manual data collection to gather even small data sets. Now; massive amounts ofinformation about social networks and social interactions are recorded. This wealth of bigdata can allow social scientists to study social interactions on a scale and at a level of detailthat has never before been possible. Our goal is to evaluate the value of big data in …,International Workshop on Databases in Networked Information Systems,2014,17
CloudOptimizer: Multi-tenancy for I/O-bound OLAP workloads,Hatem A Mahmoud; Hyun Jin Moon; Yun Chi; Hakan Hacıgümüş; Divyakant Agrawal; Amr El-Abbadi,Abstract Consolidation of multiple databases on the same server allows service providers tosave significant resources because many production database servers are often under-utilized. Recent research investigates the problem of minimizing the number of serversrequired to host a set of tenants when the working sets of tenants are kept in main memory(eg; in-memory OLAP workloads; or OLTP workloads); thus the memory assigned to eachtenant; as well as the I/O bandwidth and CPU time; are all dictated by the working set size ofthe tenant. Other research investigates the reverse problem when the number of servers isfixed; but the amount of resources allocated to different tenants on the same server needs tobe configured to optimize a cost function. In this paper we investigate the problem whenneither the number of servers nor the amount of resources allocated to each tenant are …,Proceedings of the 16th International Conference on Extending Database Technology,2013,17
Privacy preserving in weighted social network,S Das; O Egecioglu; AE Abbadi,*,Proc. Int’l Conf. Data Eng.(ICDE’10),2010,17
Binocular: a system monitoring framework,Fatih Emekci; Sezai E Tuna; Divyakant Agrawal; Amr El Abbadi,Abstract Recent advances in hardware technology facilitate applications requiring a largenumber of sensor devices; where each sensor device has computational; storage; andcommunication capabilities. However these sensors are subject to certain constraints suchas limited power; high communication cost; low computation capability; presence of noise inreadings and low bandwidth. Since sensor devices are powered by ordinary batteries;power is a limiting resource in sensor networks and power consumption is dominated bycommunication. In order to reduce power consumption; we propose to use a linear model oftemporal; spatial and spatio-temporal correlations among sensor readings. With this model;readings of all sensors can be estimated using the readings of a few sensors by using linearobservers and multiple queries can be answered more efficiently. Since a small set of …,Proceeedings of the 1st international workshop on Data management for sensor networks: in conjunction with VLDB 2004,2004,17
Data cubes in dynamic environments,Steven Geffner; Mirek Riedewald; Divyakant Agrawal; Amr El  Abbadi,*,IEEE Data Eng. Bull.,1999,17
The performance of two-phase commit protocols in the presence of site failures,ML Liu; Divyakant Agrawal; Amr El Abbadi,Much of the existing literature on the two phase commit protocol is restricted to discussingand analyzing the protocol (and its variants) in the absence of failure. Very little; especially inquantitative terms; has been written about its performance in the presence of site failures.We use a simulation test bed of a distributed database system to quantify the differences inthe performances of four 2PC protocols (the generic 2PC; presumed commit; presumedabort; and early prepare). Our study covers both the no-failure case and the case of sitefailures. We present a number of interesting experimental results. One is that theperformance of these protocols is highly dependent on the message-processing latency atthe transaction coordinator site. Another is that the presumed abort protocol does notnecessarily yield better performance in the presence of site failures.,Fault-Tolerant Computing; 1994. FTCS-24. Digest of Papers.; Twenty-Fourth International Symposium on,1994,17
Dividing secrets to secure data outsourcing,Fatih Emekci; Ahmed Methwally; Divyakant Agrawal; Amr El Abbadi,Abstract Data outsourcing or database as a service is a new paradigm for datamanagement. The third party service provider hosts databases as a service. These partiesprovide efficient and cheap data management by obviating the need to purchase expensivehardware and software; deal with software upgrades and hire professionals foradministrative and maintenance tasks. However; due to recent governmental legislations;competition among companies and database thefts; companies cannot use databaseservice providers directly. They need secure and privacy preserving data managementtechniques to be able to use them in practice. Since data is remotely stored in a privacypreserving manner; there are efficiency related problems such as poor query response time.We propose a new framework that provides efficient and scalable query response times …,Information Sciences,2014,16
Modeling and maintaining multi-view data warehouses,Ioana Stanoi; Divyakant Agrawal; Amr El Abbadi,Abstract Data warehouses are designed mostly as centralized systems; and the majority ofupdate maintenance algorithms are tailored for this specific model. Maintenance methodshave been proposed either under the assumption of a single view data warehouse; a multi-view centralized model; or a multi-view distributed system with strict synchronizationrestrictions. We argue that extending this model to a multi-view distributed one; is a practicalgeneralization of the data warehouse system; andt he basis for a growing number ofapplications basedon the idea of cooperative views. In this paper we develop a generalframework for modeling the maintenance of multi-views in a distributed; decentralized datawarehouse; together with an efficient incremental algorithm for view maintenance. To ourknowledge; there is no other proposal for a method that incorporates individually and …,International Conference on Conceptual Modeling,1999,16
Pharos: A scalable distributed architecture for locating heterogeneous information sources,Ron A Dolin; Divyakant Agrawal; L Dillon; A El Abbadi,Preface research: careful; systematic; patient study and investigation in some field ofknowledge; undertaken to discover or establish facts or principles. technology: 1. thescience or study of the practical or industrial arts; applied sciences; etc. 2. applied science.3. a method; process; etc. for handling a specific technical problem. 4. the system by which asociety provides its members with those things needed or desired. progress: 1. a movingforward or onward. 2. forward course; development. 3. advance toward perfection or to ahigher or better state; improvement.\The little farmers watched debt creep up on them likethe tide. They sprayed the trees and sold no crop; they pruned and grafted and could notpick the crop. And the men of knowledge have worked; have considered; and the fruit isrotting on the ground; and the decaying mash in the wine vat is poisoning the air. And …,*,1998,16
Browsing and placement of multi-resolution images on parallel disks,Sunil Prabhakar; Divyakant Agrawal; Amr El Abbadi; Ambuj Singh; Terence Smith,Abstract. With rapid advances in computer and communication technologies; there is anincreasing demand to build and maintain large image repositories. To reduce the demandson I/O and network resources; multi-resolution representations are being proposed for thestorage organization of images. Image decomposition techniques such as wavelets can beused to provide these multi-resolution images. The original image is represented by severalcoefficients; one of them with visual similarity to the original image; but at a lower resolution.These visually similar coefficients can be thought of as thumbnails or icons of the originalimage. This paper addresses the problem of storing these multi-resolution coefficients ondisks so that thumbnail browsing as well as image reconstruction can be performedefficiently. Several strategies are evaluated to store the image coefficients on parallel …,Multimedia systems,2003,15
Database replication: If you must be lazy; be consistent,JoAnne Holliday; Divyakant Agrawal; Amr El Abbadi,Due to the severe performance penalties associated with isochronous replication; there issignificant interest in asynchronous replica management protocols. Lazy protocols currentlyin use either do not guarantee consistency and serializability; as needed by transactionalsemantics; or they impose restrictions on the placement of data and on which data objectscan be updated. In this paper; we consider an alternative update protocol; based onepidemic communication; that guarantees consistency and serializability in spite of a write-anywhere capability.,Reliable Distributed Systems; 1999. Proceedings of the 18th IEEE Symposium on,1999,15
Tertiary storage: Current status and future trends,Sunil Prabhakar; Divyakant Agrawal; Amr El Abbadi; Ambuj Singh,Abstract This report summarizes current state of the art in tertiary storage systems. We beginwith a comprehensive discussion of magnetic tape and optical storage technologies. This isfollowed by a classification of commercial products based on their performancecharacteristics. Our analysis of product data indicates that in contrast to disk technology;tertiary storage products have significant variablility in terms of data transfer rates as well asother performance figures. We then summarize efforts in the areas of operating systems;databases and advanced applications to integrate tertiary storage. We point out that differentassumptions about the underlying technology result in entirely different algorithms andsystem design. We conclude the report with a speculation of future trends.,Computer Science Department; University of California; Santa Barbara,1996,15
Maat: Effective and scalable coordination of distributed transactions in the cloud,Hatem A Mahmoud; Vaibhav Arora; Faisal Nawab; Divyakant Agrawal; Amr El Abbadi,Abstract The past decade has witnessed an increasing adoption of cloud databasetechnology; which provides better scalability; availability; and fault-tolerance via transparentpartitioning and replication; and automatic load balancing and fail-over. However; only asmall number of cloud databases provide strong consistency guarantees for distributedtransactions; despite decades of research on distributed transaction processing; due topractical challenges that arise in the cloud setting; where failures are the norm; and humanadministration is minimal. For example; dealing with locks left by transactions initiated byfailed machines; and determining a multi-programming level that avoids thrashing withoutunder-utilizing available resources; are some of the challenges that arise when using lock-based transaction processing mechanisms in the cloud context. Even in the case of …,Proceedings of the VLDB Endowment,2014,14
Message Futures: Fast Commitment of Transactions in Multi-datacenter Environments.,Faisal Nawab; Divyakant Agrawal; Amr El Abbadi,*,CIDR,2013,14
Abacus: A distributed middleware for privacy preserving data sharing across private data warehouses,Fatih Emekci; Divyakant Agrawal; Amr El Abbadi,Abstract Recent trends in the global economy force competitive enterprises to collaboratewith each other to analyze markets in a better way and make decisions based on that.Therefore; they might want to share their data with each other to run data mining algorithmsover the union of their data to get more accurate and representative results. During thisprocess they do not want to reveal their data to each other due to the legal issues andcompetition. However; current systems do not consider privacy preservation in data sharingacross private data sources. To satisfy this requirement; we propose a distributedmiddleware; ABACUS; to perform intersection; join; and aggregation queries over multipleprivate data warehouses in a privacy preserving manner. Our analytical evaluations showthat ABACUS is efficient and scalable.,ACM/IFIP/USENIX International Conference on Distributed Systems Platforms and Open Distributed Processing,2005,14
Data management for moving objects,Hae Don  Chon; Divyakant Agrawal; Amr El  Abbadi,Abstract We model a moving object as a sizable physical entity equipped with GPS; wirelesscommunication capability; and a computer such as a PDA. Furthermore; we have observedthat a real trajectory of a moving object is the result of interactions among moving objects inthe system yielding a polyline instead of a line segment. In this paper; we first choose apartitioning approach to efficiently manage such trajectory information and develop a systemcalled RouteManager based on a space-time grid that manages moving objects in a one-dimensional space. We then extend this to two-dimensional space. The time-dependentshortest path problem is an interesting application where such a system can be used.,IEEE Data Eng. Bull.,2002,14
Using broadcast primitives in replicated databases,Ioana Stanoi; Divyakant Agrawal; Amr El Abbadi,Abstract In this paper; we explore the use of the simple variants of broadcast protocols formanaging replicated databases. In particular; we start with the simplest broadcast primitive;the reliable broadcast protocol; and show how it can be used to ensure correct transactionexecution. The protocol is simple; and has several advantages; including prevention ofdeadlocks. However; it requires a two-phase commitment protocol for ensuring correctness.We then develop a second protocol that uses causal broadcast and avoids the overhead oftwo-phase commit by exploiting the causal delivery properties of the broadcast primitives toimplicitly collect the relevant information used in two-phase commit. Finally; we present aprotocol that employs atomic broadcast and completely eliminates the need foracknowledgements during transaction commitment.,PODC,1997,14
Partitioned data objects in distributed databases,Gustavo Alonso; Amr El Abbadi,Abstract In many distributed databases “locality of reference” is crucial to achieve acceptableperformance. However; the purpose of data distribution is to spread the data among severalremote sites. One way to solve this contradiction is to use partitioned data techniques.Instead of accessing the entire data; a site works on a fraction that is made locally available;thereby increasing the site's autonomy. We present a theory of partitioned data thatformalizes the concept and establishes the basis to develop a correctness criterion and aconcurrency control protocol for partitioned databases. Set-serializability is proposed as acorrectness criterion and we suggest an implementation that integrates partitioned and non-partitioned data. To complete this study; the policies required in a real implementation arealso analyzed.,Distributed and Parallel Databases,1995,14
Reducing recovery constraints on locking based protocols,Gustavo Alonso; Divyakant Agrawal; Amr El Abbadi,Abstract Serializability is the standard correctness criterion for concurrency control. Toensure correctness in the presence of failures; recoverability is also imposed. Pragmaticconsiderations result in further constraints; for instance; the existing log-based recoveryimplementations that use before-images warrant that transaction executions be strict. Strictexecutions are restrictive; thus sacrificing concurrency and throughput. In this paper weidentify the relation between the recovery mechanism and the restrictions imposed byconcurrency control protocols. In particular; we propose a new inverse operation that can beintegrated with the underlying recovery mechanism. In order to establish the viability of ourapproach; we demonstrate the new implementation by making minor modifications to theconventional recovery architecture. This inverse operation is also designed to avoid the …,Proceedings of the thirteenth ACM SIGACT-SIGMOD-SIGART symposium on Principles of database systems,1994,14
An approach to eliminate transaction blocking in locking protocols,Divyakant Agrawal; Amr El Abbadi; Richard Jeffers,Locking based protocols are widely used for transaction management and concurrencycontrol in database systems. Much of the recent wo~ k on database concurrency control hasconcentrated on evaluating the performance of the two phase locking protocol[16] either bysimulation studies [13; 33; 7; 5] or by analytical modeling[32; 17; 27; 29; 34]. The simulationstudies have generally established the superiority of two phase locking over other types ofconcurrency control protocols such as timest amp ordering['28; 10] and optimisticconcurrency control [22]. More recently several researchers have become interested indeveloping techniques to stabilize the behavior of two phase loc! iiug at very highmultiprogramming levels (in particular beyond its thrash point). Tay; Suri; and Goodman[32]observed that if half the transactions ate blocked; the system is already thrashing. The …,Proceedings of the eleventh ACM SIGACT-SIGMOD-SIGART symposium on Principles of database systems,1992,14
Taostore: Overcoming asynchronicity in oblivious data storage,Cetin Sahin; Victor Zakhary; Amr El Abbadi; Huijia Lin; Stefano Tessaro,We consider oblivious storage systems hiding both the contents of the data as well asaccess patterns from an untrusted cloud provider. We target a scenario where multiple usersfrom a trusted group (eg; corporate employees) asynchronously access and edit potentiallyoverlapping data sets through a trusted proxy mediating client-cloud communication. Themain contribution of our paper is twofold. Foremost; we initiate the first formal study ofasynchronicity in oblivious storage systems. We provide security definitions for scenarioswhere both client requests and network communication are asynchronous (and in fact; evenadversarially scheduled). While security issues in ObliviStore (Stefanov and Shi; S&P 2013)have recently been surfaced; our treatment shows that also CURIOUS (Bindschaedler at al.;CCS 2015); proposed with the exact goal of preventing these attacks; is insecure under …,Security and Privacy (SP); 2016 IEEE Symposium on,2016,13
Secure data management in the cloud,Divyakant Agrawal; Amr El Abbadi; Shiyuan Wang,Abstract As the cloud paradigm becomes prevalent for hosting various applications andservices; the security of the data stored in the public cloud remains a big concern that blocksthe widespread use of the cloud for relational data management. Data confidentiality;integrity and availability are the three main features that are desired while providing datamanagement and query processing functionality in the cloud. We specifically discussachieving data confidentiality while preserving practical query performance in this paper.Data confidentiality needs to be provided in both data storage and at query access. As aresult; we need to consider practical query processing on confidential data and protectingdata access privacy. This paper analyzes recent techniques towards a practicalcomprehensive framework for supporting processing of common database queries on …,International Workshop on Databases in Networked Information Systems,2011,13
Aggregate skyline: Analysis for online users,Shyam Antony; Ping Wu; Divyakant Agrawal; Amr El Abbadi,Aggregation is among the core functionalities of OLAP systems. Frequently; such queriesare issued in decision support systems to identify interesting groups of data. In conventionalsettings; the queries take a long time to compute (hours!) and produce massive result-sets atvarying degrees of aggregation. Providing real time analysis results to web users canenhance the utility of sites dealing with large amounts of data. However; to do so; needssuccinct ways of capturing interesting analysis results rather than complex offline analysis.The result set should be presentable in a few web pages. Furthermore; such results shouldbe computed quickly and updated in the background whenever possible. We proposeskyline queries over aggregated data as a means of providing succinct but interestinganalysis results. We support aggregation functions from a large class of monotonous …,Applications and the Internet; 2009. SAINT'09. Ninth Annual International Symposium on,2009,13
Multiple query optimization in middleware using query teamwork,Kevin O'Gorman; Amr El Abbadi; Divyakant Agrawal,Abstract Multiple concurrent queries occur in many database settings. This paper describesthe use of middleware as an optimization tool for such queries. Since commonsubexpressions derive from common data and the data is usually greatest at the source; themiddleware exploits the presence of sharable access patterns to underlying data; especiallyscans of large portions of tables or indexes; in environments where query queuing orbatching is an acceptable approach. The results show that simultaneous queries with suchsharable accesses have a tendency to form synchronous groups (teams) which benefit eachother through the operation of the disk cache; in effect using it as an implicit pipeline. Themiddleware exploits this tendency by queuing and scheduling the queries to promote thisinteraction; using an algorithm designed to promote such teamwork. This is implemented …,Software: Practice and Experience,2005,13
Filtration of string proximity search via transformation,S Alireza Aghili; Divyakant Agrawal; Amr El Abbadi,The problem of proximity search in biological databases is addressed. We study vectortransformations and conduct the application of DFT (Discrete Fourier Transformation) andDWT (Discrete Wavelet Transformation; Haar) dimensionality reduction techniques for DNAsequence proximity search to reduce the search time of range queries. Our empirical resultson a number of Prokaryote and Eukaryote DNA contig databases demonstrate up to 50-foldfiltration ratio of the search space; up to 13 times faster filtration. The proposedtransformation techniques may easily be integrated as a preprocessing phase on top of thecurrent existing similarity search heuristics such as BLAST; PattenHunter; FastA; QUASARand to efficiently prune non-relevant sequences. We study the precision of applyingdimensionality reduction techniques for faster and more efficient range query searches …,Bioinformatics and Bioengineering; 2003. Proceedings. Third IEEE Symposium on,2003,13
The lord of the rings: Efficient maintenance of views at data warehouses,Divyakant Agrawal; Amr El Abbadi; Achour Mostéfaoui; Michel Raynal; Matthieu Roy,Abstract Data warehouses have become extremely important to support online analyticalprocessing (OLAP) queries in databases. Since the data view that is obtained at a datawarehouse is derived from multiple data sources that are continuously updated; keeping adata warehouse up-to-date becomes a crucial problem. An approach referred to as theincremental view maintenance is widely used. Unfortunately; a precise and formal definitionof view maintenance (which can actually be seen as a distributed computation problem)does not exist. This paper develops a formal model for maintaining views at datawarehouses in a distributed asynchronous system. We start by formulating the viewmaintenance problem in terms of abstract update and data integration operations and statethe notions of correctness associated with data warehouse views. We then present a …,International Symposium on Distributed Computing,2002,13
Exploiting planned disconnections in mobile environments,JoAnne Holliday; Divyakant Agrawal; Amr El Abbadi,We present the notion of a distributed database made up entirely of mobile components.Since disconnections will be frequent in such an environment; we develop a disconnectionand reconnection procedure to allow normal processing on the connected components. Webriefly discuss a protocol based on epidemic communication to support such a system whileensuring one-copy serializability.,Research Issues in Data Engineering; 2000. RIDE 2000. Proceedings. Tenth International Workshop on,2000,13
Clustering declustered data for efficient retrieval,Hakan Ferhatosmanoglu; Divyakant Agrawal; Amr El Abbadi,Abstract Modern databases increasingly integrate new kinds of information; such asmultimedia information in the form of image; video; and audio data. Both the dimensionalityand the amount of data that need to be processed is increasing rapidly; increasing thedemand for the efficient retrieval of large amounts of multi-dimensional data. Declusteringtechniques for multi-disk architectures have been effectively used for storage. In this paper;we first establish that besides exploiting the parallelism; a careful organization of each diskmust be considered for fast searching. We introduce the notion of page allocation and dataspace mapping which can be used to organize and retrieve multidimensional data. Wedevelop these notions based on three different partitioning strategies: regular gridpartitioning; concentric hypercubes and hyperpyramids. We develop techniques that …,Proceedings of the eighth international conference on Information and knowledge management,1999,13
Indexing non-uniform spatial data,Kothuri Venkata Ravi Kanth; Divyakant Agrawal; Ambuj K Singh; Amr El Abbadi,Non-uniformity in data extents is a general characteristic of spatial data. Indexing such non-uniform data using conventional spatial index structures such as R/sup*/-trees is inefficientfor two reasons:(1) the non-uniformity increases the likelihood of overlapping index entries;and (2) clustering of non-uniform data is likely to index more dead space than clustering ofuniform data. To reduce the impact of these anomalies; we propose a new scheme thatpromotes data objects to higher levels in tree-based index structures. We examine twocriteria for promotion of data objects and evaluate their relative merits using an R*-tree. Inexperiments on cartographic data; we observe that our promotion criteria yield up to 45%improvement in query performance for an R*-tree.,Database Engineering and Applications Symposium; 1997. IDEAS'97. Proceedings.; International,1997,13
A nonrestrictive concurrency control protocol for object-oriented databases,Divyakant Agrawal; Amr El Abbadi,Abstract We propose an algorithm for executing transactions in object-oriented databases.The object-oriented database model generalizes the classical model of databaseconcurrency control by permitting accesses to class and instance objects; by permittingarbitrary operations on objects as opposed to traditional read and write operations; and byallowing nested execution of transactions on objects. In this paper; we first develop auniform methodology for treating both classes and instances. We then develop a two-phaselocking protocol with a new relationship between locks called ordered sharing for an object-oriented database. Ordered sharing does not restrict the execution of conflicting operations.Finally; we extend the protocol to handle objects that execute methods on other objects thusresulting in the nested execution of transactions. The resulting protocol permits more …,Distributed and Parallel Databases,1994,13
Efficient detection of corrupted pages in a replicated file,Khaled AS Abdel-Ghaffar; Amr El Abbadi,Files are often replicated on tributed system for efficient several sites in a disand fastaccessibility purposes. If a copy of the file is available locally; the cost of read operations isnegligible. This is especially important in many large database applications; where manydata files are very large and are often used as a source for deriving data; ie; most operationsare read operations. One prominent example of such systems is the large satellitebasedimage databases where large (gega-bytes) images; often referred to as raw data; aretransmitted to a central repository of data; and scientists across the globe acquire copies ofthis raw data in order to derive more structured images. Due to failures; some pages may getcorrupted. Since the files are quite large and the portion of corrupted pages is expected tobe small; exchanging all copies and comparing them is unacceptable. Various …,Proceedings of the twelfth annual ACM symposium on Principles of distributed computing,1993,13
P2p systems with transactional semantics,Shyam Antony; Divyakant Agrawal; Amr El Abbadi,Abstract Structured P2P systems have been developed for constructing applications atinternet scale in cooperative environments and exhibit a number of desirable features suchas scalability and self-maintenance. We argue that such systems when augmented with welldefined consistency semantics provide an attractive building block for many large scale dataprocessing applications in cluster environments. Towards this end; we study the problem ofproviding transactional semantics to P-Ring a P2P system which supports efficient rangequeries. We first extend a commonly used replication protocol in P2P systems to providewell defined guarantees in the presence of concurrent updates and under well definedfailure assumptions. A multi-version concurrency control protocol called LSTP whichleverages the guarantees of the replication protocol to provide transactional semantics is …,Proceedings of the 11th international conference on Extending database technology: Advances in database technology,2008,12
Exploring spatial datasets with histograms,Chengyu Sun; Nagender Bandi; Divyakant Agrawal; Amr El Abbadi,Abstract As online spatial datasets grow both in number and sophistication; it becomesincreasingly difficult for users to decide whether a dataset is suitable for their tasks;especially when they do not have prior knowledge of the dataset. In this paper; we proposebrowsing as an effective and efficient way to explore the content of a spatial dataset.Browsing allows users to view the size of a result set before evaluating the query at thedatabase; thereby avoiding zero-hit/mega-hit queries and saving time and resources.Although the underlying technique supporting browsing is similar to range queryaggregation and selectivity estimation; spatial dataset browsing poses some uniquechallenges. In this paper; we identify a set of spatial relations that need to be supported inbrowsing applications; namely; the contains; contained and the overlap relations. We …,Distributed and Parallel Databases,2006,12
Scientific modeling using distributed resources,Amitabh Saran; Divyakant Agrawal; Amr El Abbadi; Terence R Smith; Jianwen Su,A reasonable response to this challenge involves two major components. The firstcomponent is a cotnpubotul modeling environment (CME) in which scientists may representand manipulate any scientific concept of potential value for the modcling enterprise. Inparticular; a CME should support the iterative process by which symbolic moclels ofphenomena are constructed; evaluated; and applied. The rep-resentation of modelingactivities in a CME should be at a level of abstraction at which irrelevant computationalissues are hidden.,Proceedings of the 4th ACM international workshop on Advances in geographic information systems,1996,12
Managing geo-replicated data in multi-datacenters,Divyakant Agrawal; Amr El Abbadi; Hatem A Mahmoud; Faisal Nawab; Kenneth Salem,Abstract Over the past few years; cloud computing and the growth of global large scalecomputing systems have led to applications which require data management across multipledatacenters. Initially the models provided single row level transactions with eventualconsistency. Although protocols based on these models provide high availability; they arenot ideal for applications needing a consistent view of the data. There has been now agradual shift to provide transactions with strong consistency with Google's Megastore andSpanner. We propose protocols for providing full transactional support while replicating datain multi-datacenter environments. First; an extension of Megastore is presented; which usesoptimistic concurrency control. Second; a contrasting method is put forward; which usesgossip-based protocol for providing distributed transactions across datacenters. Our aim …,International Workshop on Databases in Networked Information Systems,2013,11
Information diffusion in social networks: observing and affecting what society cares about,Divyakant Agrawal; Ceren Budak; Amr El Abbadi,Abstract Information diffusion in social networks provide great opportunities for political andsocial change as well as societal education. Therefore understanding information diffusionin social networks is a critical research goal. This greater understanding can be achievedthrough data analysis; development of reliable models that can predict outcomes of socialprocesses; and ultimately the creation of applications that can shape the outcome of theseprocesses. In this tutorial; we aim to provide an overview of such recent research based on awide variety of techniques such as optimization algorithms; data mining; data streamscovering a large number of problems such as influence spread maximization; misinformationlimitation and study of trends in online social networks.,Proceedings of the 20th ACM international conference on Information and knowledge management,2011,11
Optimal scheduling algorithms for tertiary storage,Sunil Prabhakar; Divyakant Agrawal; Amr El Abbadi,Abstract The ever growing needs of large multimedia systems cannot be met by magneticdisks due to their high cost and low storage density. Consequently; cheaper and densertertiary storage systems are being integrated into the storage hierarchies of theseapplications. Although tertiary storage is cheaper; the access latency is very high due to theneed to load and unload media on the drives. This high latency and the bursty nature of I/Otraffic result in the accumulation of I/O requests for tertiary storage. We study the problem ofscheduling these requests to improve performance. In particular we address the issues ofscheduling across multiple tapes or disks as opposed to most other studies which consideronly one or two media. We focus on algorithms that minimize the number of switches andshow through simulation that these result in near-optimal schedules. For single drive …,Distributed and Parallel Databases,2003,11
Efficient techniques for replicated data management,Divyakant Agrawal; Amr El Abbadi,Data replication in distributed systems is considered. Two approaches are developed topartially mitigate the costs associated with replicated data management. The first approach;termed the views protocol; is developed to address the concern of practitioners who rejectthe quorum protocol since it requires that a read operation be executed on more that onecopy. The second approach organizes the copies of data into a logical structure such as atree; a grid; etc. By using the additional information of the logical structure it is possible torelax the quorum intersection requirements. The two approaches are briefly described; andthe possibility of combining them to manage replicated data more efficiently is considered.,Management of Replicated Data; 1990. Proceedings.; Workshop on the,1990,11
CoTS: A scalable framework for parallelizing frequency counting over data streams,Sudipto Das; Shyam Antony; Divyakant Agrawal; Amr El Abbadi,Frequency counting; frequent elements and top-k queries form a class of operators that areused for a wide range of stream analysis applications. In spite of the abundance of thesealgorithms; all known techniques for answering data stream queries are sequential innature. The imminent ubiquity of Chip Multi-Processor (CMP) architectures requiresalgorithms that can exploit the parallelism of such architectures. In this paper; we firstevaluate different naive techniques for intra-operator parallelism; and summarize theinsights obtained from the naive techniques. Our experimental analysis of the naive designsshows that intra-operator parallelism is not straightforward and requires a complete redesignof the system. We then propose an efficient and scalable framework for parallelizingfrequency counting; frequent elements and top-k queries over data streams. The …,Data Engineering; 2009. ICDE'09. IEEE 25th International Conference on,2009,10
Moolap: Towards multi-objective olap,Shyam Antony; Ping Wu; Divyakant Agrawal; Amr El Abbadi,Aggregation is among the core functionalities of OLAP systems. Frequently; such queriesare issued in decision support systems to identify interesting groups of data. When morethan one aggregation function is involved and the notion of interest is not clearly defined;skyline queries provide a robust mechanism to capture the potentially interesting pointswhere (i) users do not need to specify a ranking function and (ii) the result is independent ofthe dimension scales. To provide better exploration functionalities in OLAP systems; wepropose to use skyline queries over aggregated data to identify the most interesting groups.Since aggregation functions have to be ad-hoc to cover a wide variety of user interests; theskyline over the aggregates has to be computed on the fly. Hence any algorithm to computesuch a skyline must be fast and be able to progressively produce the result set with …,Data Engineering; 2008. ICDE 2008. IEEE 24th International Conference on,2008,10
Pads: Protein structure alignment using directional shape signatures,S Alireza Aghili; Divyakant Agrawal; Amr El Abbadi,Abstract A novel data mining approach for similarity search and knowledge discovery inprotein structure databases is proposed. PADS (P rotein structure A lignment by D irectionalshape S ignatures) incorporates the three dimensional coordinates of the main atoms ofeach amino acid and extracts a geometrical shape signature along with the direction of eachamino acid. As a result; each protein structure is presented by a series of multidimensionalfeature vectors representing local geometry; shape; direction; and biological properties of itsamino acid molecules. Furthermore; a distance matrix is calculated and is incorporated intoa local alignment dynamic programming algorithm to find the similar portions of two givenprotein structures followed by a sequence alignment step for more efficient filtration. Theoptimal superimposition of the detected similar regions is used to assess the quality of the …,International Conference on Database Systems for Advanced Applications,2005,10
Ranking aggregates,Hua-Gang Li; Hailing Yu; Divyakant Agrawal; Amr El Abbadi,Abstract Ranking-aware queries have been gaining much attention recently in manyapplications such as search engines and data streams. They are; however; not onlyrestricted to such applications but are also very useful in OLAP applications. In this paper;we introduce aggregation ranking queries in OLAP data cubes motivated by an onlineadvertisement tracking data warehouse application. These queries aggregate informationover a specified range and then return the ranked order of the aggregated values. Forinstance; an advertiser might be interested in the top-k publishers over the last three monthsin terms of sales obtained through the online advertisements placed on the publishers. Theydiffer from range aggregate queries in that range aggregate queries are mainly concernedwith an aggregate operator such as SUM and MIN/MAX over the selected ranges of all …,*,2004,10
Energy-conscious data aggregation over large-scale sensor networks,Fatih Emekci; Hailing Yu; Divyakant Agrawal; AE Abbadi,Abstract Recent advances in hardware technology facilitate applications requiring largenumbers of sensor devices; where each sensor device has computational; storage; andcommunication capabilities. Since sensor devices are powered by ordinary batteries; poweris a limiting resource in sensor networks. Power usage can be reduced by pushing part ofthe computation into the network to reduce communication cost; which is the main energyconsumer in sensor networks. In order to further reduce power usage; we propose power-aware query processing techniques for aggregation queries. Instead of requiring exactanswers to queries; we introduce precision into queries to give users full control of thetradeoffs between precision and energy usage. Our query processing approachincorporates in-network prediction to further reduce the need for constant communication …,UCSB TechnicalReport,2003,10
Bft: Bit filtration technique for approximate string join in biological databases,S Alireza Aghili; Divyakant Agrawal; Amr El Abbadi,Abstract Joining massive tables in relational databases have received substantial attentionin the past decade. Numerous filtration and indexing techniques have been proposed toreduce the curse of dimensionality. This paper proposes a novel approach to map theproblem of pairwise whole-genome comparison into an approximate join operation in thewell-established relational database context. We propose a novel Bit Filtration Technique(BFT) based on vector transformation and furthermore conduct the application of DFT(Discrete Fourier Transformation) and DWT (Discrete Wavelet Transformation; Haar)dimensionality reduction techniques as a pre-processing filtration step which effectivelyreduces the search space and running time of the join operation. Our empirical results on anumber of Prokaryote and Eukaryote DNA contig datasets demonstrate very efficient …,International Symposium on String Processing and Information Retrieval,2003,10
Efficient I/O scheduling in tertiary libraries,Sunil Prabhakar; Divyakant Agrawal; Amr El Abbadi; Ambuj Singh,Abstract With the recent improvements in network and processor speeds; several dataintensive applications have become much more feasible than ever before. The only practicalsolution for storing such enormous amounts of data is tertiarystorage. Automated access totertiary storage is made possible through robotic libraries for tapes and optical disks. Due tothe slow speeds of operation of the drives and library robotics; access times for suchlibrariesare high resulting in the accumulation of I/O requests. In this paper we study theproblem of scheduling these requests for efficient performance. We focus on schedulingpolicies that process all requests on a loaded medium before unloading it. For single drivesettings an efficient algorithm that produces optimal schedules is developed. For multipledrives the problem is shown to be NP-Complete. Efficient and effective heuristics are …,*,1996,10
MDBS: A modeling and database system to support research in the earth sciences,Terence R Smith; Jianwen Su; Divyakant Agrawal; Amr El Abbadi,Abstract An interdisciplinary team of computer scientists and EOS earth-scienceinvestigators is jointly investigating the concept of a modeling and database system (MDBS).MDBS is intended to support large-scale earth science investigations by complementingEOS-DIS in terms of support for high-level modeling and data management. In particular;MDBS is intended to facilitate the iterative development of scienti c models in data-intensiveand computationally intensive applications. It is based on a simple characterization of scientic activity and on an advanced data model that together capture the essence of scienti cmodeling and database activities in terms of large lattices of representational domains andassociated transformations that are employed to organize scienti c knowledge; data andalgorithms. A high-level; declarative modeling and database language (MDBL) that is …,Chu Chu93,1993,10
The evolving landscape of data management in the cloud,Divyakant Agrawal; Amr El Abbadi; Beng Chin Ooi; Sudipto Das; Aaron J Elmore,Scalable database management systems (DBMSs) are a critical part of the cloudinfrastructure and play an important role in ensuring the smooth transition of applicationsfrom the classical enterprise infrastructures to next generation cloud infrastructures. Thoughscalable data management on distributed platforms has been a vision for more than threedecades and much research has focused on large scale data management in traditionalenterprise setting; cloud computing brings its own set of novel challenges that must beaddressed to ensure the success of data management solutions in the cloud environmentthat is inherently distributed. This article presents an organised picture of the challengesfaced by application developers and DBMS designers in developing and deploying internetscale applications. Our background study encompasses systems for supporting update …,International Journal of Computational Science and Engineering 6,2012,9
FLUX: content and structure matching of XPath queries with range predicates,Hua-Gang Li; S Alireza Aghili; Divyakant Agrawal; Amr El Abbadi,Abstract Range queries seek the objects residing in a constrained region of the data space.An XML range query may impose predicates on the numerical or textual contents of theelements and/or their respective path structures. In order to handle content and structurerange queries efficiently; an XML query processing engine needs to incorporate effectiveindexing and summarization techniques to efficiently partition the XML document and locatethe results. In this paper; we describe a dynamic summarization and indexing method;FLUX; based on Bloom filters and B+-trees to tackle these problems. We present the resultsof extensive experimental evaluations which indicate the efficiency of the proposedtechnique.,International XML Database Symposium,2006,9
Declustering two-dimensional datasets over MEMS-based storage,Hailing Yu; Divyakant Agrawal; Amr El Abbadi,Abstract Due to the large difference between seek time and transfer time in current disktechnology; it is advantageous to perform large I/O using a single sequential access ratherthan multiple small random I/O accesses. However; prior optimal cost and data placementapproaches for processing range queries over two-dimensional datasets do not considerthis property. In particular; these techniques do not consider the issue of sequential dataplacement when multiple I/O blocks need to be retrieved from a single device. In this paper;we reevaluate the optimal cost of range queries by declustering two-dimensional datasetsover multiple devices; and prove that; in general; it is impossible to achieve the new optimalcost. This is because disks cannot facilitate two-dimensional sequential access which isrequired by the new optimal cost. Fortunately; MEMS-based storage is being developed …,International Conference on Extending Database Technology,2004,9
Accessing scientific data: Simpler is better,Mirek Riedewald; Divyakant Agrawal; Amr El Abbadi; Flip Korn,Abstract A variety of index structures has been proposed for supporting fast access andsummarization of large multidimensional data sets. Some of these indices are fairly involved;hence few are used in practice. In this paper we examine how to reduce the I/O cost bytaking full advantage of recent trends in hard disk development which favor reading largechunks of consecutive disk blocks over seeking and searching. We present theMultiresolution File Scan (MFS) approach which is based on a surprisingly simple andflexible data structure which outperforms sophisticated multidimensional indices; even if theyare bulk-loaded and hence optimized for query processing. Our approach also has theadvantage that it can incorporate a priori knowledge about the query workload. It readilysupports summarization using distributive (eg; count; sum; max; min) and algebraic (eg …,International Symposium on Spatial and Temporal Databases,2003,9
Distributed deadlock detection,J Holliday; Amr El Abbadi,Deadlock can occur whenever two or more processes are competing for limited resourcesand the processes are allowed to acquire and hold a resource (obtain a lock) thuspreventing others from using the resource while the process waits for other resources.Twocommon places where deadlocks may occur are with processes in an operating system(distributed or centralized) and with transactions in a database. The concepts discussedhere are applicable to any system that allocates resources to processes.,Encyclopedia of Distributed Computing. Kluwer Academic Publishers; Dordrecht (accepted for publication),2000,9
Database replication using epidemic update,Joanne Holliday; Divyakant Agrawal; AE Abbadi,Abstract Due to severe performance penalties associated with synchronous replication;there is an increasing interest in asynchronous replica management protocols in whichdatabase transactions are executed locally; and the effects of these transactions areincorporated asynchronously on remote database copies. However; the asynchronousprotocols currently in use either do not guarantee consistency and serializability as neededby transactional semantics or they impose restrictions on placement of data and on whichdata objects can be updated. In this paper we investigate an epidemic update protocol thatguarantees consistency and serializability in spite of a write-anywhere capability. Weconducted experiments on a detailed simulation of a distributed; replicated database toevaluate this protocol. Our results establish that this epidemic approach is indeed a viable …,*,2000,9
A Taxonomy of Partitioned Replicated Cloud-based Database Systems.,Divy Agrawal; Amr El Abbadi; Kenneth Salem,Abstract The advent of the cloud computing paradigm has given rise to many innovative andnovel proposals for managing large-scale; fault-tolerant and highly available datamanagement systems. This paper proposes a taxonomy of large scale partitioned replicatedtransactional databases with the goal of providing a principled understanding of the growingspace of scalable and highly available database systems. The taxonomy is based on therelationship between transaction management and replica management. We illustratespecific instances of the taxonomy using several recent partitioned replicated databasesystems.,IEEE Data Eng. Bull.,2015,8
Mining the network behavior of bots,Lorenzo Cavallaro; Christopher Kruegel; Giovanni Vigna; Fang Yu; Muath Alkhalaf; Tevfik Bultan; Lili Cao; Lei Yang; Heather Zheng; Christopher C Cipriano; Teofilo F Gonzalez; Steffen Gauglitz; Tobias Höllerer; Xia Zhou; Heather Zheng; Omer Egecioglu; Peterson Trethewey; Tobias Hollerer; Sudipto Das; Shyam Antony; Divyakant Agrawal; Amr El Abbadi; Sudipto Das; Ömer Egecioglu; Amr El Abbadi; Navraj Chohan; Chris Bunch; Sydney Pang; Chandra Krintz; Nagy Mostafa; Sunil Soman; Rich Wolski; Ömer Egecioglu; Oscar H Ibarra; Nagy Mostafa; Chandra Krintz; Sudipto Das; Shyam Antony; Divyakant Agrawal; Amr El Abbadi; Lamia Youseff; Dmitrii Zagorodnov; Rich Wolski; Graham Hughes; Tevfik Bultan; Aydin Buluc; John R Gilbert; Ceren Budak; Navraj Chohan; Krishna PN Puttaswamy; Alessandra Sala; Ben Y Zhao; Krishna Puttaswamy; Alessandra Sala; Christo Wilson; Ben Y Zhao; Krishna PN Puttaswamy; Alessandra Sala; Omer Egecioglu; Ben Y Zhao; Daniel Nurmi; Rich Wolski; Chris Grzegorczyk; Graziano Obertelli; Sunil Soman; Lamia Youseff; Dmitrii Zagorodnov; Navraj Chohan; Camilla Fiorese,A botnet is a network of compromised hosts that fulfills the malicious intents of an attacker.Once installed; a bot is typically used to steal sensitive information; send SPAM; performDDoS attacks; and other illegal activities. Research in botnet detection has been quiteprolific in the past years; producing detection mechanisms that focus on specific commandand control structures; or on the correlation between the activities of the bots and thecommunication patterns shared by multiple infected machines. We present an approach thataims to detect bot-infected hosts. Our approach (i) is independent on the underlying botnetstructure;(ii) is able to detect individually infected hosts;(iii) deals with encryptedcommunication;(iv) does not rely on the presence of noisy malicious activities and can thusdetect legitimate-resembling communication patterns; and (v) has a low false positive rate …,Technical Report 2009-12,2009,8
PULSTORE.: Automated Storage Management with QoS Guarantee in,Lin Qiao; Balakrishna R Iyer; Divyakant Agrawal; Amr El Abbadi; Sandeep Uttamchandani,Traditionally storage has been purchased and attached to a single computer system. Suchstorage is accessible only through the computer system to which it is locally attached. In thelast 10 years; especially in corporate data centers; storage is being increasingly purchasedindependent of the processors; and independently managed and administered. Because ofthe standardization of disk IO protocols; storage can be easily shared amongst variousheterogeneous processors running various applications. The shared storage is accessedover a network interconnecting the processors to the shared disk subsystem; known as thestorage area network-a network on which processors send IO calls to virtual disks. It is thetask of the storage controller to manage the mapping of virtual disks to physical disks; a taskknown as storage virtualization; similar to memory virtualization of processors. The …,Autonomic Computing; 2005. ICAC 2005. Proceedings. Second International Conference on,2005,8
Relative serializability: An approach for relaxing the atomicity of transactions,Vashudha Krishnaswamy; Divyakant Agrawal; John L.  Bruno; Amr El Abbadi,Abstract Serializability is too strong a correctness criterion and unnecessarily restrictsconcurrency. We use the semantic information of a transaction to provide different atomicityviews of the transaction to other transactions. The proposed approach improves concurrencyand allows interleavings among transactions which are nonserializable; but whichnonetheless preserve the consistency of the database and are acceptable to the users. Wedevelop a graph-based tool whose acyclicity is both a necessary and sufficient condition forthe correctness of an execution. Our theory encompasses earlier proposals that incorporatesemantic information of transactions. Furthermore; it is the first approach that provides anefficient graph-based tool for recognizing correct schedules without imposing anyrestrictions on the application domain. Our approach is widely applicable to many …,journal of computer and system sciences,1997,8
A graph testing concurrency control protocol for object bases,Rodolfo F Resende; Amr El Abbadi,Presents a protocol for concurrency control in object bases. The object bases model ofHadzilacos and Hadzilacos (1991) is used as a framework to describe the protocol and toderive a proof of correctness. The protocol accepts all correct executions. A definition oforder preserving serializability suitable for the model is also presented. A slight modificationof the protocol ensures that the produced executions obeys the defined order-preservingserializability. The protocol detects inconsistencies by constructing a graph for each node ofthe nested execution and testing its acyclicity.,Computing and Information; 1992. Proceedings. ICCI'92.; Fourth International Conference on,1992,8
Mining complaints for traffic-jam estimation: A social sensor application,Theodore Georgiou; Amr El Abbadi; Xifeng Yan; Jemin George,Abstract Physical events in the real world are known to trigger reactions and thendiscussions in online social media. Mining these reactions through online social sensorsoffers a fast and low cost way to understand what is happening in the physical world. Insome cases; however; further study of the affected population's emotional state can improvethis understanding. In our study we analyzed how car commuters react on Twitter while stuckin heavy traffic. We discovered that the online social footprint does not necessarily follow astrict linear correlation with the volume of a traffic jam. Through our analysis we offer apotential explanation: people's mood could be an additional factor; apart from traffic severityitself; that leads in fluctuations of the observed reaction in social media. This finding can beimportant for social sensing applications where external factors; like sentiment; also …,Proceedings of the 2015 IEEE/ACM International Conference on Advances in Social Networks Analysis and Mining 2015,2015,7
Towards practical private processing of database queries over public data,Shiyuan Wang; Divyakant Agrawal; Amr El Abbadi,Abstract Privacy is a major concern when users query public online data services. Theprivacy of millions of people has been jeopardized in numerous user data leakage incidentsin many popular online applications. To address the critical problem of personal dataleakage through queries; we enable private querying on public data services so that thecontents of user queries and any user data are hidden and therefore not revealed to theonline service providers. We propose two protocols for private processing of databasequeries; namely BHE and HHE. The two protocols provide strong query privacy by usingPaillier's homomorphic encryption; and support common database queries such as rangeand join queries by relying on the bucketization of public data. In contrast to traditionalPrivate Information Retrieval proposals; BHE and HHE only incur one round of client …,Distributed and Parallel Databases,2014,7
HengHa: data harvesting detection on hidden databases,Shiyuan Wang; Divyakant Agrawal; Amr El Abbadi,Abstract The back-end databases of web-based applications are a major data securityconcern to enterprises. The problem becomes more critical with the proliferation ofenterprise hosted web applications in the cloud. While prior work has concentrated onmalicious attacks that try to break into the database using vulnerabilities of web applications;little work has focused on the threat of data harvesting through web form interfaces; in whichlarge collections of the underlying data can be harvested and sensitive information can belearnt by iteratively submitting legitimate queries and analyzing the returned results fordesigning new queries. To defend against data harvesting without compromising usability;we consider a detection approach. We summarize the characteristics of data harvesting; andpropose the notions of query correlation and result coverage for data harvesting detection …,Proceedings of the 2010 ACM workshop on Cloud computing security workshop,2010,7
Silverline: Toward data confidentiality in third-party clouds,Krishna PN Puttaswamy; Christopher Kruegel; Ben Y Zhao; Chris Bunch; Jonathon Kupferman; Chandra Krintz; Steffen Gauglitz; Tobias Höllerer; Matthew Turk; Aaron Elmore; Sudipto Das; Divyakant Agrawal; Amr El Abbadi; Sudipto Das; Shashank Agarwal; Divyakant Agrawal; Amr El Abbadi; Chris Bunch; Navraj Chohan; Chandra Krintz; Jovan Chohan; Jonathan Kupferman; Puneet Lakhina; Yiming Li; Yoshihide Nomura; Ceren Budak; Divyakant Agrawal; Amr El Abbadi; Christopher Coffin; Sehwan Kim; Tobias Hollerer; Shiyuan Wang; Divyakant Agrawal; Amr El Abbadi; Lamia Youseff; Rich Wolski; Fang Yu; Tevfik Bultan; Oscar H Ibarra; Xia Zhou; Alessandra Sala; Haitao Zheng; Lorenzo Cavallaro; Christopher Kruegel; Giovanni Vigna; Fang Yu; Muath Alkhalaf; Tevfik Bultan; Lili Cao; Lei Yang; Heather Zheng; Christopher C Cipriano; Teofilo F Gonzalez; Steffen Gauglitz; Tobias Höllerer; Xia Zhou; Heather Zheng; Omer Egecioglu; Peterson Trethewey; Tobias Hollerer; Sudipto Das; Shyam Antony; Divyakant Agrawal; Amr El Abbadi; Sudipto Das; Ömer Egecioglu; Amr El Abbadi; Navraj Chohan; Chris Bunch; Sydney Pang; Chandra Krintz; Nagy Mostafa; Sunil Soman; Rich Wolski,ABSTRACT By offering high availability and elastic access to resources; thirdparty cloudinfrastructures such as Amazon AWS and Microsoft Azure are revolutionizing the waytoday's businesses operate. Unfortunately; taking advantage of their benefits requiresbusinesses to accept a number of serious risks to data security. Factors such as softwarebugs; operator errors and external attacks can all compromise the confidentiality of sensitivedata on external clouds; making them vulnerable to unauthorized access by maliciousparties. In this paper; we study and seek to improve the confidentiality of application datastored on third-party computing clouds. We propose to identify and encrypt all functionallyencryptable data; sensitive data that can be encrypted without limiting the functionality of thecloud service. Such data would only be stored on the cloud in an encrypted form …,Computer Science Department; UC Santa Barbara,2010,7
CAM conscious integrated answering of frequent elements and top-k queries over data streams,Sudipto Das; Divyakant Agrawal; Amr El Abbadi,Abstract Frequent elements and top-k queries constitute an important class of queries fordata stream analysis applications. Certain applications require answers for both frequentelements and top-k queries on the same stream. In addition; the ever increasing data ratescall for providing fast answers to the queries; and researchers have been looking towardsexploiting specialized hardware for this purpose. Content Addressable Memory (CAM)provides an efficient way of looking up elements and hence are well suited for the class ofalgorithms that involve lookups. In this paper; we present a fast and efficient CAM consciousintegrated solution for answering both frequent elements and top-k queries on the samestream. We call our scheme CAM conscious Space Saving with Stream Summary(CSSwSS); and it can efficiently answer continuous queries. We provide an …,Proceedings of the 4th international workshop on Data management on new hardware,2008,7
Brief announcement: Convergence analysis of scalable gossip protocols,Stacy Patterson; Bassam Bamieh; Amr El Abbadi,Abstract We present a simple; deterministic gossip protocol for solving the distributedaveraging problem. Each node has an initial value and the objective is for all nodes to reachconsensus on the average of these values using only communication between neighbors inthe network. We first give an analysis of the protocol in structured networks; namely d-dimensional discrete tori and lattices; and show that in an n node network; the number ofrounds required for the protocol to converge to within ε of the average is O (| log (ε)| n 2/d).We then extend our results to derive upper and lower bounds on convergence for arbitrarygraphs based on the dimensions of spanning supergraphs and subgraphs.,International Symposium on Distributed Computing,2006,7
Data declustering for efficient range and similarity searching,Sunil Prabhakar; Divyakant Agrawal; Amr El Abbadi,Advances in processor and network technologies have catalyzed the growth of dataintensive applications such as image repositories and digital libraries. The lack ofcommensurate improvements in storage systems have resulted in I/O becoming a majorbottleneck in modern systems. The use of parallel I/O from multiple devices is a well knowntechnique for improving I/O performance. A key factor in exploiting parallel I/O is knowledgeof the access pattern--the sets of data items that are likely to be accessed concurrentlyshould be declustered across the disks. Range and nearest-neighbor (similarity) queries arethe most important class of queries for multimedia databases. Declustering schemes tailoredfor improving the performance of range only or similarity only queries have been proposedin the literature. The problem of declustering for combined range and similarity queries …,Multimedia Storage and Archiving Systems III,1998,7
A java-based framework for processing distributed objects,Daniel Wu; Divyakant Agrawal; Amr El Abbadi; Ambuj Singh,Abstract The Alexandria Digital Library Project at UC Santa Barbara has been building aninformation retrieval system for geographically referenced information and datasets. To meetthese requirements; we have designed a distributed Data Store to store its holdings. Thelibrary's map; image and geographical data are viewed as a collection of objects withevolving roles. Developed in the Java programming language and the HORB distributedobject system; the Data Store manages these objects for flexible and scalable processing.To implement the Data Store we provide a messaging layer that allows applications todistribute processing between the Data Store and the local host. We define a data model forData Store repositories that provide Client access to Data Store objects. We finally providesupport for specialized views of these Data Store items.,International Conference on Conceptual Modeling,1997,7
Browsing and placement of multiresolution images on secondary storage,Sunil Prabhakar; Divyakant Agrawal; Amr El Abbadi; Ambuj Singh; Terence R Smith,Image decomposition techniques such as wavelets are used to provide multiresolutionrepresentations of images. The original image is represented by several coefficients; one ofthem with visual similarity to the original image; but at a lower resolution. Several strategiesare evaluated to store the image coefficients on parallel disks so that thumbnail browsing aswell as image reconstruction can be performed efficiently. Disk simulation and experimentswith real disks are used to evaluate the performance of these strategies. The results indicatethat significant performance improvements can be achieved with as few as four disks byplacing image coefficients based upon browsing access patterns.,Multimedia Computing and Systems' 97. Proceedings.; IEEE International Conference on,1997,7
Classifying network architectures for locating information sources,Ron Dolin; Divyakant Agrawal; Amr El Abbadi,Abstract This paper presents three broad classes of network architecture that supportdiscovery of information sources. Relevant concepts such as query routing and theextraction; propagation; and retrieval of metadata are defined. Based on these concepts;different models of locating and querying relevant information sources are presented.Finally; we estimate several important characteristics of these models and classes as well astheir expected scalability.,*,1997,7
Parallelizing multidimensional index structures,Kothuri Venkata Ravi Kanth; Divyakant Agrawal; Amr El Abbadi; Ambuj Singh; Terence R Smith,Indexing multidimensional data is inherently complex leading to slow query processing. Thisbehavior becomes more pronounced with the increase in database size and/or number ofdimensions. In this paper we address this issue by processing an index structure in parallel.First; we study different ways of partitioning an index structure. We then propose efficientalgorithms for processing each query in parallel on the index structure. Using thesestrategies; we parallelized two multidimensional index structures-R* and LIB and evaluatedthe performance gains for the Gazetteer and the Catalog data of the Alexandria DigitalLibrary on the Meiko CS-2.,Parallel and Distributed Processing; 1996.; Eighth IEEE Symposium on,1996,7
Analysis of quorum-based protocols for distributed (k+ 1)-exclusion,Divyakant Agrawal; Ömer Eğecioğlu; Amr El Abbadi,Abstract A generalization of the majority quorum for the solution of the distributed (k+ 1)-exclusion problem is proposed. This scheme produces a family of quorums of varying sizesand availabilities indexed by integral divisors r of k. The cases r= 1 and r= k correspond toknown majority based quorum generation algorithms MAJ and DIV; whereas intermediatevalues of r interpolate between these two extremes. A cost and availability analysis of theproposed methods is also presented.,International Computing and Combinatorics Conference,1995,7
What price replication?,ML Liu; D Agrawal; AE Abbadi,Abstract Replicated data is employed in distributed databases to enhance data availability.However; the bene t of data availability is only realized at the cost of elaborate algorithmswhich hide the underlying complexity of maintaining multiple copies of a single data item.The concern about the performance impact of replica control is part of the reasons whyreplication; although extensively researched; has yet to receive wide acceptance in practice.This paper makes use of a simulation model to explore the performance tradeo s of datareplication.,Computer Science Technical Report TRCS94-14; Dept. of Computer Science; University of Santa Barbara,1994,7
Quorum consensus algorithms for secure and reliable data,Divyakant Agrawal; Amr El Abbadi,The authors address the issue of maintaining security in a fault-tolerant replicated database.They present a data-management protocol that integrates the information-dispersalalgorithm (for security) and the quorum-consensus algorithm (for reliability). Although thisprotocol provides the desired level of security; it does not achieve the same level ofavailability for both read and write operations as the quorum-consensus algorithm. Byintegrating a log-based propagation mechanism with their protocol; the authors are able toachieve the same level of availability for both read and write operations as other quorum-consensus protocols; while maintaining the desired level of security.,Reliable Distributed Systems; 1988. Proceedings.; Seventh Symposium on,1988,7
Key-Value Datastores Comparison in AppScale,Chris Bunch; Navraj Chohan; Chandra Krintz; Jovan Chohan; Jonathan Kupferman; Puneet Lakhina; Yiming Li; Yoshihide Nomura,Abstract We present a simple framework that employs a single API–the Datastore API fromthe Google App Engine cloud computing platform–to interface to different open sourcedistributed database technologies in use today. We use the framework to “plug in” differentdatabases to the API so that they can be used by web applications and services withoutmodification. The system facilitates empirical evaluation and comparison of these disparatesystems by web software developers; and reduces the barrier to entry for the use of suchsystems by automating their configuration and deployment. 1,*,2010,6
Clouded Data: Comprehending Scalable Data Management Systems,Sudipto Das; Shyam Antony; D Agrawal; A El Abbadi,ABSTRACT Managing petabytes of data for millions of users has been a challenge for biginternet based enterprises such as Google; Yahoo!; and Amazon. Even though databasemanagement systems have a long history of managing enterprise level data andinformation; they are deemed to be unsuitable in this context. This resulted in anarchitectural redesign of data management systems with an eye towards the requirements ofhigh scalability; high availability; and low latency while providing weaker consistency andlower application generality. In this paper; we try to comprehend what is fundamentallydifferent in the internet-scale applications that allowed these data management systems toachieve orders of magnitude higher levels of scalability compared to traditional databases.With an understanding of these modern systems; we also make an attempt to predict …,*,2008,6
Environmental tomography: Ubiquitous sensing with mobile devices,Stacy Patterson; Bassam Bamieh; Amr El Abbadi,The ubiquitous nature of mobile phones; which are location-aware devices; presents aunique platform for large-scale computing applications. In particular; if mobile phones arecoupled with sensors; they can be used for detection and monitoring of environmentalphenomena such as pollution and radiation. In this demonstration; we presentEnvironmental To-mography; a system for ubiquitous environmental sensing with mobiledevices. Aggregate sensor measurements are collected by the devices along fixed pathssuch as roads; and these aggregates are used to reconstruct an estimate of the distributionof the underlying physical phenomenon. Our system is robust to the dynamic characteristicsof mobile networks and also preserves the privacy of mobile user locations. We demonstratea prototype that generates estimate distributions from user specified data collection paths …,Data Engineering; 2008. ICDE 2008. IEEE 24th International Conference on,2008,6
Automated storage management with qos guarantees,Lin Qiao; Balakrishna R Iyer; Divyakant Agrawal; AE Abbadi,Automated storage management is critical for most dataintensive applications running onDBMSs. In large-scale storage subsystems; the workload is expected to vary with time. Inorder to ensure both QoS and efficient usage of storage resources; variation in the actualphysical disks is allowed to support a single virtual disk. Such data migration generatesextra IOs and consumes storage resources. Not only does data migration need to bescheduled ahead but it must also be scheduled in such a way that QoS violations do notoccur because of the extra migration IOs. In this paper; we present a novel analyticframework; PULSTORE; for autonomically managing the storage to provide performanceguarantee during migration.,Data Engineering; 2006. ICDE'06. Proceedings of the 22nd International Conference on,2006,6
Sequence similarity search using discrete Fourier and wavelet transformation techniques,S Alireza Aghili; Divyakant Agrawal; Amr El Abbadi,In this paper; we study the problem of sequence similarity search. We incorporate vectortransformations and apply DFT (Discrete Fourier Transformation) and DWT (DiscreteWavelet Transformation; Haar) dimensionality reduction techniques to reduce the searchspace/time of sequence similarity range queries. Our empirical results on a number ofProkaryote and Eukaryote DNA contig databases demonstrate up to 50-fold filtration ratioreduction of the search space and up to 13 times faster filtration. The proposedtransformation techniques may easily be integrated as a pre-processing phase on top ofcurrent similarity search heuristics/techniques such as BLAST; PatternHunter; FastA andQUASAR to efficiently prune non-relevant sequences. We study the precision of applyingdimensionality reduction techniques for faster and more efficient range query searches …,International Journal on Artificial Intelligence Tools,2005,6
Progressive ranking of range aggregates,Hua-Gang Li; Hailing Yu; Divyakant Agrawal; Amr El Abbadi,Abstract Ranking-aware queries have been gaining much attention recently in manyapplications such as search engines and data streams. They are; however; not onlyrestricted to such applications but are also very useful in OLAP applications. In this paper;we introduce aggregation ranking queries in OLAP data cubes motivated by an onlineadvertisement tracking data warehouse application. These queries aggregate informationover a specified range and then return the ranked order of the aggregated values. Theydiffer from range aggregate queries in that range aggregate queries are mainly concernedwith an aggregate operator such as SUM and MIN/MAX over the selected ranges of alldimensions in the data cubes. Existing techniques for range aggregate queries are not ableto process aggregation ranking queries efficiently. Hence; in this paper we propose new …,International Conference on Data Warehousing and Knowledge Discovery,2005,6
Attribute-based access to distributed data over p2p networks,Divyakant Agrawal; Amr El Abbadi; Subhash Suri,Abstract Peer-to-peer (P2P) networks are distributed data sharing systems with no dedicatedand centralized infrastructure. These systems are attractive because they deliver on theInternet's promise of true decentralization; offering scalability; availability; fault tolerance;robustness; and low barriers to entry. While P2P systems have been used so far mainly forfile sharing; their true potential lies as a vast; loosely connected world wide infrastructure forsharing resources; data and information. However; many challenging research problemsmust be addressed and solved before this vision can materialize. This paper addresses anatural step in the evolution of P2P: going beyond simple file sharing based on exact-namebased lookups to data and information sharing where data is accessed based on itsattributes or properties. We have identified diverse applications such as network …,International Workshop on Databases in Networked Information Systems,2005,6
Efficient filtration of sequence similarity search through singular value decomposition,S Alireza Aghili; Ozgur D Sahin; Divyakant Agrawal; Amr El Abbadi,Similarity search in textual databases and bioinformatics has received substantial attentionin the past decade. Numerous filtration and indexing techniques have been proposed toreduce the curse of dimensionality. This paper proposes a novel approach to map theproblem of whole-genome sequence similarity search into an approximate vectorcomparison in the well-established multidimensional vector space. We propose theapplication of the singular value decomposition (SVD) dimensionality reduction techniqueas a pre-processing filtration step to effectively reduce the search space and the runningtime of the search operation. Our empirical results on a prokaryote and a eukaryote DNAcontig dataset; demonstrate effective filtration to prune non-relevant portions of the databasewith up to 2.3 times faster running time compared with q-gram approach. SVD filtration …,Bioinformatics and Bioengineering; 2004. BIBE 2004. Proceedings. Fourth IEEE Symposium on,2004,6
Asynchronous RMI for CentiJ,Douglas A Lyon,Abstract CentiJ is a software synthesis system that; until recently; used synchronous; semi-automatic static proxy delegation to help in the automation of the creation of distributed Javaprograms on NOWS (Networks of Workstations). This paper reports our recent extension toCentiJ so that invocations are asynchronous. Further; we have achieved transparency withrespect to local vs. non-local asynchronous invocations so that software can be properlytested in a local mode. Reflection helps in the creation of bridge pattern code (ie; interfacesand proxies) for asynchronous message forwarding via RMI. The CentiJ technique improvesprogrammer productivity by automating the creation of the housekeeping code. The use ofcompile-time static delegation enables type-safety. CentiJ leaves the part of the code thatforms the core computation unchanged. It generates new code that enables …,Journal of Object Technology,2004,6
Efficient processing of conical queries,Hakan Ferhatosmanoglu; Divyakant Agrawal; Amr El Abbadi,Abstract Conical queries are a novel type of query with an increasing number ofapplications. Traditional index structures and retrieval mechanisms; in general; have beenoptimized for rectangular and circular queries; rather than conical queries. In this paper; wefocus on conical queries which can be defined as a multi-dimensional cone in a multi-dimensional data space. We develop a model for expressing such queries and suggestefficient techniques for evaluating them. In particular; we explore the retrieval problem in thecontext of conical query processing and develop multi-disk allocation methods specificallyfor processing conical queries.,Proceedings of the tenth international conference on Information and knowledge management,2001,6
On the importance of tuning in incremental view maintenance: An experience case study,Kevin O’Gorman; Divyakant Agrawal; Amr El Abbadi,Abstract We describe the tuning of a gigabyte-scale TPC-D database for investigation ofincremental maintenance of a materialized view. We find that incremental maintenance isfeasible over a wide range of update sizes (granularities); that intuitive SQL formulationsperform poorly; but that there are better alternatives. We show that these results can bemeaningfully evaluated and presented only in the context of reasonable instance tuning.,International Conference on Data Warehousing and Knowledge Discovery,2000,6
Mobility and extensibility in the StratOSphere framework,Daniel Wu; Divyakant Agrawal; Amr El Abbadi,Abstract We describe the design and implementation of our StratOSphere project; aframework which unifies distributed objects and mobile code applications. We begin by firstexamining different mobile code paradigms that distribute processing of code and dataresource components across a network. After analyzing these paradigms; and presenting alattice of functionality; we then develop a layered architecture for StratOSphere;incorporating higher levels of mobility and interoperability at each successive layer. In ourdesign; we provide an object model that permits objects to migrate to different sites; selectamong different method implementations; and provide new methods and behavior. Wedescribe how we build new semantics in each software layer; and present sample objectsdeveloped for the Alexandria Digital Library Project at UC Santa Barbara; which as been …,Distributed and Parallel Databases,1999,6
StratOSphere: Unification of code; data; location; scope; and mobility,Daniel Wu; Divyakant Agrawal; Amr El Abbadi,The StratOSphere system provides a framework for distributed objects written in Java;unifying mobile code and distributed programming systems by providing the basic entities:relocatable instances and methods; persistent repositories; and mobile execution state.Each StratOSphere host provides a repository to store object instances and methods in apersistent manner The repository is partitioned among different hosts; to distribute thestorage of objects; and to provide different implementations of an object specification amongparticular hosts. Client applications visit relevant repositories to acquire specializedbehavior from methods stored within the repository. At run-time these entities can beaccessed and dispatched; providing a means of invoking an operation in a dynamic fashion;while still ensuring type safety and correctness. In addition to unifying externally-defined …,Distributed Objects and Applications; 1999. Proceedings of the International Symposium on,1999,6
Weak Consistency in Distributed Data Warehouses.,Ioana Stanoi; Divyakant Agrawal; Amr El Abbadi,Abstract We propose and analyze a novel multiple-view model of a distributed datawarehouse. Views are represented in a hierarchical fashion; incorporating data from basesources as well as possibly other views. Current approaches to maintain consistency in sucha model require that data stored in a view derived from base data via di erent paths be fromthe same state of the base relation. This type of consistency criterion is too restrictive forsome applications. Hence; we propose relaxing the synchronization constraints at the viewlevel and develop a model that allows views to set their own constraints by enforcingindividual conditions for all pairs of paths. We de ne a correctness criteria for updates in thisparticular model; and analyze the new requirements necessary for maintaining theconsistency of data. Finally; we propose an algorithm to ensure that views are updated …,FODO,1998,6
Impact of Media Exchanges in Robotic Libraries,Sunil Prabhakar; Divyakant Agrawal; Amr El Abbadi,Abstract The large storage requirements of many commerical and scientific applicationscannot be met by magnetic disks due to their high cost and low storage density.Consequently; cheaper and more dense tertiary storage systems are being intergrated intothe storage hierarchies of these applications. Although tertiary storage can accomodatelarge amounts of data; the access latency is very high due to the need to load and unloadmedia from the read/write drives. These media exchanges are very slow with typical times inthe order of tens of seconds. In order to reduce this high latency research efforts havefocussed on minimizing media exchanges under the assumption that it is always beneficialto eliminate exchanges. We analyze the validity of this assumption. It is shown that there areinstances when the assumption does not hold. It is further shown that various factors …,*,1997,6
A brief survey of tertiary storage systems and research,Sunil Prabhakar; Divyakant Agrawal; A El Abbadi; A Singh,With the recent improvements in network and processor speeds; several data intensive applicationshave become much more feasible than ever before. These applications are characterized byvery large computational and stor- age requirements. In the present commercial setting and mostlikely in the near future; the only practical solution for storing such enormous amounts of datais tertiary storage. Although tertiary storage; in particu- lar magnetic tapes; has been used solelyfor archiving or backup purposes; the exploding storage requirements and the high cost of secondarystorage are forcing com- puter architects and designers to re-evaluate the role of tertiarystorage. In this paper we present some of the more recent research activities that study tertiarystorage and their integration into computer systems. • Work partially supported by a researchgrant from NSF/ARPA/NASA IR19411330; and from NSF CDA9421978 and by a …,Proceedings of the 1997 ACM symposium on Applied computing,1997,6
Exotica,Thomas J. Watson IBM Research Center. Research Division; G Alonso; D Agrawal; A El Abbadi; C Mohan; R Guenthoer; M Kamath,*,*,1994,6
Using data migration for heterogeneous databases,D Agrawal; EA Abbadi,The authors propose an approach to execute transactions in heterogeneous distributeddatabases. Instead of using the traditional approach of executing global transaction byremotely accessing distributed data; they propose that transactions be executed locally; anddata is dynamically migrated to the appropriate sites. Thus; they eliminate the need forglobal transactions. Since there are no global transactions; the problem of distributedcommitment does not arise. This is an important issue related to database recovery that isoften ignored by protocols for transaction processing in heterogeneous databases. A specialprotocol is executed for migrating data objects. They present a protocol for localizing theaccess of a data object.,Interoperability in Multidatabase Systems; 1991. IMS'91. Proceedings.; First International Workshop on,1991,6
Extracting topics with focused communities for social content recommendation,Theodore Georgiou; Amr El Abbadi; Xifeng Yan,ABSTRACT A thorough understanding of social media discussions and the demographics ofthe users involved in these discussions has become critical for many applications likebusiness or political analysis. Such an understanding and its ramifications on the real worldcan be enabled through the automatic summarization of Social Media. Trending topics areoffered as a high level content recommendation system where users are suggested to viewrelated content if they deem the displayed topics interesting. However; identifying thecharacteristics of the users focused on each topic can boost the importance even for topicsthat might not be popular or bursty. We define a way to characterize groups of users that arefocused in such topics and propose an efficient and accurate algorithm to extract suchcommunities. Through qualitative and quantitative experimentation we observe that topics …,Proceedings of the 2017 ACM Conference on Computer Supported Cooperative Work and Social Computing,2017,5
Towards database virtualization for database as a service,Aaron J Elmore; Carlo Curino; Divyakant Agrawal; Amr El Abbadi,Abstract Advances in operating system and storage-level virtualization technologies haveenabled the effective consolidation of heterogeneous applications in a shared cloudinfrastructure. Novel research challenges arising from this new shared environment includeload balancing; workload estimation; resource isolation; machine replication; live migration;and an emergent need of automation to handle large scale operations with minimal manualintervention. Given that databases are at the core of most applications that are deployed inthe cloud; database management systems (DBMSs) represent a very important technologycomponent that needs to be virtualized in order to realize the benefits of virtualization fromautonomic management of data-intensive applications in large scale data-centers. The goalof this tutorial is to survey the techniques used in providing elasticity in virtual machine …,Proceedings of the VLDB Endowment,2013,5
Dragonfly: Cloud assisted peer-to-peer architecture for multipoint media streaming applications,Erdinc Korpeoglu; Cetin Sahin; Divyakant Agrawal; Amr El Abbadi; Takeo Hosomi; Yoshiki Seo,Technology trends are not only transforming the hardware landscape of end-user devicesbut are also dramatically changing the types of software applications that are deployed onthese devices. With the maturity of cloud computing during the past few years; usersincreasingly rely on networked applications that are deployed in the cloud. In particular; newapplications will emerge where user interactions will be based on real-time continuousmedia streams instead of the traditional request-response types of interfaces. Furthermore;many of these applications will be multi-user streaming media based interactions instead ofa single user interaction with an application. In this paper; we propose a geographic location-aware; hybrid; scalable cloud assisted peer-to-peer (P2P) architecture to support suchapplications that targets low administration cost; reduced bandwidth consumption; low …,Cloud Computing (CLOUD); 2013 IEEE Sixth International Conference on,2013,5
Towards practical private processing of database queries over public data with homomorphic encryption,Shiyuan Wang; Divyakant Agrawal; AE Abbadi,Abstract—Data privacy is a major concern when users query public online data services.The privacy of millions of people has been jeopardized in numerous user data leakageincidents in many popular online applications. To address the critical problem of personaldata leakage through queries; we enable private querying on public data services so thatthe contents of user queries and any user data are hidden and therefore not revealed to theonline service provider. We propose two protocols for processing private database queries;namely BHE and HHE. BHE provides complete query privacy by using Paillier'shomomorphic encryption along with the bucketization of public data. In contrast to traditionalPrivate Information Retrieval (PIR) proposals; BHE only incurs one round of client serverinteraction for processing one query. Built upon BHE; HHE is a hybrid protocol that …,University of California. Department of Computer Science. Technical Report,2011,5
Fast computation of spatial selections and joins using graphics hardware,Nagender Bandi; Chengyu Sun; Divyakant Agrawal; Amr El Abbadi,Abstract Spatial database operations are typically performed in two steps. In the filteringstep; indexes and the minimum bounding rectangles (MBRs) of the objects are used toquickly determine a set of candidate objects. In the refinement step; the actual geometries ofthe objects are retrieved and compared to the query geometry or each other. Because of thecomplexity of the computational geometry algorithms involved; the CPU cost of therefinement step is usually the dominant cost of the operation for complex geometries such aspolygons. Although many run-time and pre-processing-based heuristics have beenproposed to alleviate this problem; the CPU cost still remains the bottleneck. In this paper;we propose a novel approach to address this problem using the efficient rendering andsearching capabilities of modern graphics hardware. This approach does not require …,Information Systems,2007,5
Hide and seek: Detecting hit inflation fraud in streams of web advertising networks,Ahmed Metwally; Divyakant Agrawal; A El Abbadi,Abstract As the Internet continues to grow; the Internet advertising industry flourishes as ameans of reaching the appropriate market segments. Internet advertisers provide themonetary incentive for Internet publishers to display advertisements on their Web sites.Internet advertisers and publishers contract through a commissioner that takes care of theaccounting issues; and earns a commission on the advertisers' payments. Some publishersare dishonest; and use automation to generate traffic to defraud the advertisers. Thecommissioner; who is supposed to distinguish fraudulent traffic from normal traffic; cannottrack individual computers in order not to violate surfers' privacy. In this paper; we describethe advertising network model in detail; and share; with the research community; our fieldexperience and concerns about detecting fraudulent publishers. This paper provides a …,*,2006,5
Efficient filtration of sequence homology search through singular value decomposition,S Alireza Aghili; Özgür D Sahin; Divyakant Agrawal; Amr El Abbadi,Similarity search in textual databases and bioinformatics has received substantial attentionin the past decade. Numerous filtration and indexing techniques have been proposed toreduce the curse of dimensionality. This paper proposes a novel approach to map theproblem of whole-genome sequence homology search into an approximate vectorcomparison in the well-established multidimensional vector space. We propose theapplication of Singular Value Decomposition (SVD) dimensionality reduction technique as apre-processing filtration step to effectively reduce the search space and the running time ofthe search operation. Our empirical results on a Prokaryote and a Eukaryote DNA contigdataset; demonstrate effective filtration to prune non-relevant portions of the database withup to 2. 3 times faster running time compared with q-gram approach. SVD filtration may …,Department of Computer Science,2003,5
Unattended deliveries and perinatal outcome: a tertiary hospital experience,EI Archibong; AA Sobande; HM Al-Bar; AA Asindi,Objective: To determine the neonatal morbidity and mortality pattern in a cohort of infantsborn outside hospital but admitted in Abha Maternity Hospital; Saudi Arabia. Patients andMethods: The charts of 151 women and their infants born at home or en route to the hospitalwere reviewed and the findings were compared with those of 300 in-hospital (in-born)deliveries from January 1990 to December 1996. Results: Of the 151 unattended deliveries;36 percent occurred at home and 64 percent in motor vehicles. Eighty-three percent of theout-born and 63 percent of the controls had no antenatal care. The incidence of respiratorydistress syndrome (RDS) was significantly higher (p= 0.002) among the out-born cases.Perinatal mortality among the out-born deliveries was 6.7 percent; in contrast to the 1.0percent in the in-born group. Conclusion: Despite adequate health facilities and …,Nigerian Journal of Paediatrics,2002,5
Optimal partitioning for efficient I/O in spatial databases,Hakan Ferhatosmanoglu; Divyakant Agrawal; Amr El Abbadi,Abstract It is desirable to design partitioning techniques that minimize the I/O time incurredduring query execution in spatial databases. In this paper; we explore optimal partitioningtechniques for spatial data for different types of queries; and develop multi-disk allocationtechniques that maximize the degree of I/O parallelism obtained during the retrieval. Weshow that hexagonal partitioning has optimal I/O cost for circular queries compared to allpossible non-overlapping partitioning techniques that use convex regions. For rectangularqueries; we show that although for the special case when queries are rectilinear; rectangulargrid partitioning gives superior performance; hexagonal partitioning has overall better I/Ocost for a general class of range queries. We then discuss parallel storage and retrievaltechniques for hexagonal partitioning using current techniques for rectangular grid …,European Conference on Parallel Processing,2001,5
Smart indexes for efficient browsing of library collections,Steven Geffner; Divyakant Agrawal; Amr El Abbadi; Terry Smith; Mary Larsgaard,To enable efficient browsing and interactive querying of very large collections; such as thosefound in digital libraries; it is essential to provide users with summaries of query result sets.Smart indexes can be used to generate summary statistics; aggregated classificationinformation; and/or aggregated content-based information for the result sets of arbitraryqueries. We present the basic model of a smart index; as well as variations of smart indexesthat are suitable when the size of summaries is large. An algorithm for generatingsummaries of the results of arbitrary queries is given; and algorithms for updating varioussummaries are discussed. Experimental results show that smart indexes generatesummaries much more efficiently than traditional trees for all query areas greater than 1%-2% of the data space; with a relatively small additional storage overhead. Contrary to …,Research and Technology Advances in Digital Libraries; 1998. ADL 98. Proceedings. IEEE International Forum on,1998,5
A unified implementation of concurrency control and recovery,Gustavo Alonso; Divyakant Agrawal; Amr El Abbadi,Abstract this paper; we discuss the characteristics of such a scheduler and develop efficientschedulers based on a new class of locks. We start by proposing an equivalent definition forPRED. The original definition of PRED was stated in a recursive manner; which hinders itsuse for the development of dynamic schedulers. Our definition is procedural; and providesus with an easy; graph testing protocol for recognizing all PRED executions. However;serialization graph testing is known to be inefficient; and since locking is widely used forconcurrency control; we propose a locking based protocol to recognize a subclass of PRED.The unified theory relied on a specific implementation of the recovery mechanism; viz.; logsand before images. We develop an alternative recovery mechanism; which also uses logsand before images; but allows more concurrency among transactions. This recovery …,*,1993,5
Adaptive protocols for managing replicated distributed databases,Amr El Abbadi,The author proposes a family of adaptive protocols for managing replicated databases.Adaptive protocols use information about the system configuration to determine howoperations are executed. Special system transactions are executed to maintain thisinformation in view objects. The author proposes using static as well as dynamic methods toexecute both system and user transactions. This results in a modular methodology fordesigning four different protocols. Two of these protocols are new and present the systemdesigner with several alternatives when compared with the previously known protocols.,Parallel and Distributed Processing; 1991. Proceedings of the Third IEEE Symposium on,1991,5
Ordered sharing: A new lock primitive for database systems,Divyakant Agrawal; Amr El Abbadi,*,*,1991,5
The group paradigm for concurrency control,Amr El Abbadi; Sam Toueg,Abstract We propose a paradigm for developing; describing and proving the correctness ofconcurrency control protocols for replicated databases in the presence of failures orcommunication restrictions. Our approach is to hierarchically divide the problem of achievingone-copy serializability by introducing the notion of a “group” that is a higher level ofabstraction than transactions. Instead of dealing with the overall problem of serializing alltransactions; our paradigm divides the problem into two simpler ones.(1) A local policy foreach group that ensures a total order of all transactions in that group.(2) A global policy thatensures a correct serialization of all groups. We use the paradigm to demonstrate thesimilarities between several concurrency control protocols by comparing the way theyachieve correctness.,ACM SIGMOD Record,1988,5
A paradigm for concurrency control protocols for distributed databases,Amr El Abbadi,In this thesis; we present a paradigm for concurrency control protocols for distributedreplicated databases. This paradigm presents a framework for both developing andanalyzing concurrency control protocols; especially those that are designed to handlepartitioning failures. Any concurrency control protocol that is an instance of the paradigmmust be correct. We show that several known protocols are instances of this paradigm.Consequently; these seemingly unrelated protocols can now be compared and theirunderstanding is simplified. We also present two new concurrency control protocols: thevirtual partitions protocol and the accessibility thresholds protocol. Both protocols allow thereading and writing of data in spite of site and communication failures; even when thesefailures lead to network partitioning. In neither protocol is it ever necessary for a read …,*,1987,5
Db-risk: The game of global database placement,Victor Zakhary; Faisal Nawab; Divyakant Agrawal; Amr El Abbadi,Abstract Geo-replication is the process of maintaining copies of data at geographicallydispersed datacenters for better availability and fault-tolerance. The distinguishingcharacteristic of geo-replication is the large wide-area latency between datacenters thatvaries widely depending on the location of the datacenters. Thus; choosing whichdatacenters to deploy a cloud application has a direct impact on the observable responsetime. We propose an optimization framework that automatically derives a geo-replicationplacement plan with the objective of minimizing latency. By running the optimizationframework on real placement scenarios; we learn a set of placement optimizations for geo-replication. Some of these optimizations are surprising while others are in retrospect straight-forward. In this demonstration; we highlight the geo-replication placement optimizations …,Proceedings of the 2016 International Conference on Management of Data,2016,4
Data-driven modeling and analysis of online social networks,Divyakant Agrawal; Bassam Bamieh; Ceren Budak; Amr El Abbadi; Andrew Flanagin; Stacy Patterson,Abstract With hundreds of millions of users worldwide; social networks provide incredibleopportunities for social connection; learning; political and social change; and individualentertainment and enhancement in a wide variety of forms. In light of these notableoutcomes; understanding information diffusion over online social networks is a criticalresearch goal. Because many social interactions currently take place in online networks; wenow have have access to unprecedented amounts of information about social interaction.Prior to the advent of such online networks; investigations about social behavior requiredresource-intensive activities such as random trials; surveys; and manual data collection togather even small data sets. Now; massive amounts of information about social networksand social interactions are recorded. This wealth of data can allow us to study social …,International Conference on Web-Age Information Management,2011,4
Efficient skyline computation over ad-hoc aggregations,Shyam Antony; Ping Wu; Divyakant Agrawal; AE Abbadi,Abstract Aggregation is among the core functionalities of OLAP systems. Frequently; suchqueries are issued in decision support systems to identify interesting groups of data. Whenmore than one aggregation function is involved and the notion of interest is not clearlydefined; skyline queries provide a robust mechanism to capture the potentially interestingpoints where (i) users do not need to specify a ranking function and (ii) the result isindependent of the dimension scales. For providing better exploration functionalities in theOLAP system; in this paper; we propose to use skyline queries over aggregated data toidentify the most interesting groups. Since the aggregation function has to be ad-hoc tocover a wide variety of user interests; the skyline over the aggregates has to be computed onthe fly. Hence any algorithm to compute such a skyline must be fast and be able to …,IEEE ICDE,2008,4
Tcam-conscious algorithms for data streams,Nagender Bandi; Ahmed Metwally; Divyakant Agrawal; Amr El Abbadi,There has been significant interest in developing space and time efficient solutions foranswering continuous summarization queries over data streams. While these techniquesare evaluated in a standard CPU setting; many of their applications such as click-frauddetection; and network-traffic summarization typically execute on special networkingarchitectures called network processing units (NPUs). These NPUs interface with specialkind of associative memories known as the ternary content addressable memories (TCAMs).In this paper; we describe how the integrated architecture of NPU and TCAMs can beexploited towards achieving the goal of developing high-speed stream summarizationsolutions. We analyze popular solutions for the frequent elements problem in data stream;discuss the bottleneck issues and motivate how TCAMs can help alleviate these …,Data Engineering; 2007. ICDE 2007. IEEE 23rd International Conference on,2007,4
Data space mapping for efficient I/O in large multi-dimensional databases,Hakan Ferhatosmanoglu; Aravind Ramachandran; Divyakant Agrawal; Amr El Abbadi,Abstract In this paper; we propose data space mapping techniques for storage and retrievalin multi-dimensional databases on multi-disk architectures. We identify the important factorsfor an efficient multi-disk searching of multi-dimensional data and develop secondarystorage organization and retrieval techniques that directly address these factors. Weespecially focus on high dimensional data; where none of the current approaches areeffective. In contrast to the current declustering techniques; storage techniques in this paperconsider both inter-and intra-disk organization of the data. The data space is first partitionedinto buckets; then the buckets are declustered to multiple disks while they are clustered ineach disk. The queries are executed through bucket identification techniques that locate thepages. One of the partitioning techniques we discuss is especially practical for high …,Information Systems,2007,4
Exploiting temporal correlation in temporal data warehouses,Ying Feng; Hua-Gang Li; Divyakant Agrawal; Amr El Abbadi,Abstract Data is typically incorporated in a data warehouse in increasing order of time.Furthermore; the MOLAP data cube tends to be sparse because of the large cardinality ofthe time dimension. We propose an approach to improve the efficiency of range aggregatequeries on MOLAP data cubes in a temporal data warehouse by factoring out the time-related dimensions. These time-related dimensions are handled separately to takeadvantage of the monotonic trend over time. The proposed technique captures local datatrends with respect to time by partitioning data points into blocks; and then uses a perfectbinary block tree as an index structure to achieve logarithmic time complexity for bothincremental updates and data retrievals. Experimental results establish the scalability andefficiency of the proposed approach on various datasets.,International Conference on Database Systems for Advanced Applications,2005,4
SVL: storage virtualization engine leveraging DBMS technology,Lin Qiao; Balakrishna R Iyer; Divyakant Agrawal; Amr E Abbadi,The demands on storage systems are increasingly requiring expressiveness; fault-tolerance;security; distribution; etc. Such functionalities have been traditionally provided by DBMS. Wepropose a storage management system; SVL that leverages DBMS technology. The primaryproblem in block storage management is block virtualization; which is essentially anabstraction layer that separates the user view of storage from the implementation of storage.Storage virtualization standardizes storage management in a heterogeneous storage and/orhost environment; and plays a crucial role in enhancing storage functionality and utilization.Currently specialized hardware or microcode-based solutions are popular for implementingblock storage management systems; commonly referred to as disk controllers. Wedemonstrate how to take a general purpose commercial RDBMS; rather than a …,Data Engineering; 2005. ICDE 2005. Proceedings. 21st International Conference on,2005,4
PULSATINGSTORE: An analytic framework for automated storage management,Lin Qiao; Divyakant Agrawal; Amr El Abbadi; Balakrishna R Iyer,Self-management of large information technology components; such as DBMSs; hasemerged as one important problem in the area of autonomic computing. In particular;automated storage management is critical for most data-intensive applications. The reasonis that the storage maintenance cost manifests one of the biggest factors in the overalloperational cost. At the same time; due to the interactive nature of most applications; userstypically pose the QoS constraints on IO access performance. Hence it is crucial to ensurethat the applications are not underprovisioned (giving rise to the risk of QoS violation) orover-provisioned (resulting in high operational costs). Such issue gets further complicatedwhen the application workload keeps changing. In this paper; we present a novel analyticframework; PULSATINGSTORE; for autonomically managing the storage to balance the …,Data Engineering Workshops; 2005. 21st International Conference on,2005,4
Optimal data-space partitioning of spatial data for parallel I/O,Hakan Ferhatosmanoğlu; Divyakant Agrawal; Ömer Eğecioğlu; Amr El Abbadi,Abstract It is desirable to design partitioning methods that minimize the I/O time incurredduring query execution in spatial databases. This paper explores optimal partitioning for two-dimensional data for a class of queries and develops multi-disk allocation techniques thatmaximize the degree of I/O parallelism obtained in each case. We show that hexagonalpartitioning has optimal I/O performance for circular queries among all partitioning methodsthat use convex non-overlapping regions. An analysis and extension of this result to allpossible partitioning techniques is also given. For rectangular queries; we show thathexagonal partitioning has overall better I/O performance for a general class of rangequeries; except for rectilinear queries; in which case rectangular grid partitioning is superior.By using current algorithms for rectangular grid partitioning; parallel storage and retrieval …,Distributed and Parallel Databases,2005,4
The Performance of Replicated Databases Using Atomic Broadcast Group Communication,JoAnne Holliday; Divyakant Agrawal; Amr El Abbadi,Abstract Database replication with update-anywhere capability while maintaining globalsynchronization and isolation has long been thought impractical. Protocols have beenproposed for distributed replicated databases that take advantage of atomic broadcastsystems to simplify message passing and conflict resolution in hopes of making replicationefficient. This paper presents performance measurements on a simulation of a distributedreplicated database using those protocols. The results show that with the proper groupbroadcast mechanism; replication with update-anywhere capability is indeed practical.,*,1999,4
Ordered sharing: A new lock primitive for database systems,Divyakant Agrawal; Amr El Abbadi,Abstract We propose a new lock primitive called ordered sharing that allows increasedconcurrency in database systems. A generalized two phase locking protocol is developedthat may employ locks with the standard shared and non-shared relationships as well as theproposed ordered shared relationships between locks. The paper then addresses thereliability and performance issues of the proposed protocol. We show that ordered sharingresults in a set of protocols that are optimal in both their reliability and concurrency aspects.A simulation study demonstrates that ordered sharing results in improved performance indatabase systems. The general applicability of the new primitive is further demonstrated byusing it in several representative database environments.,*,1995,4
Comparing multiple file copies with a primary copy using minimal communication,Khaled AS Abdel-Ghaffar; Amr El Abbadi,Abstract For data consistency in distributed database systems; it is necessary to compareremotely located copies of a file. The cost of such comparison is in the amount ofcommunication required to identify the erroneous pages in the different copies. We assumethat the sites at which the copies reside can communicate only with a primary site thatcontains an exact copy of the file. The minimum amount of communication necessary toidentify any given number of erroneous pages is determined and a technique to attain thisminimum is presented.,*,1993,4
Fast read-only transactions in replicated databases,PC Aristides; Amr El Abbadi,The authors present a propagation mechanism; called the commit propagation mechanism(CPM); which increases the availability of data for read-only transactions. The proposedmechanism is piggy-backed on the messages used in the two-phase commit protocol. TheCPM was combined with the standard quorum protocol in two different replicated databasesystems. In a fully replicated database; CPM allows any read-only transaction to executelocally at a single site without the need for any communication overhead. In a partiallyreplicated database; CPM either ensures that the set of copies residing at a site are mutuallyconsistent; or indicates which copies violate such consistency.,Data Engineering; 1992. Proceedings. Eighth International Conference on,1992,4
Localized-access protocols for replicated databases,Divyakant Agrawal; Amr El Abbadi,Abstract In this paper; we present two protocols for efficient execution of transactions inreplicated databases. Transactions are executed at a single site thus avoidingcommunication overhead and distributed commitment; which are required by most otherreplica control protocols. In the first protocol; data accessibility at a site can be dynamicallyreconfigured using special transactions; which are executed on demand. In the secondprotocol; data accessibility is reconfigured by migrating ownership of individual objects inthe database. The two protocols present trade-offs with respect to atomicity; resiliency; anddata availability. The approach of local execution of user transactions improves responsetime; eliminates the need for distributed commit protocols; and accommodates databaseheterogeneity.,International Workshop on Distributed Algorithms,1990,4
Multi-representation based data processing architecture for IoT applications,Vaibhav Arora; Faisal Nawab; Divyakant Agrawal; Amr El Abbadi,Internet of Things (IoT) applications like smart cars; smart cities and wearables arebecoming widespread and are the future of the Internet. One of the major challenges for IoTapplications is efficiently processing; storing and analyzing the continuous stream ofincoming data from a large number of connected sensors. We propose a multi-representation based data processing architecture for IoT applications. The data is stored inmultiple representations; like rows; columns; graphs which provides support for diverseapplication demands. A unifying update mechanism based on deterministic scheduling isused to update the data representations; which completely removes the need for datatransfer pipelines like ETL (Extract; Transform and Load). The combination of multiplerepresentations; and the deterministic update mechanism; provides the ability to support …,Distributed Computing Systems (ICDCS); 2017 IEEE 37th International Conference on,2017,3
Chariots: A Scalable Shared Log for Data Management in Multi-Datacenter Cloud Environments.,Faisal Nawab; Vaibhav Arora; Divyakant Agrawal; Amr El Abbadi,ABSTRACT Web-based applications face unprecedented workloads demanding theprocessing of a large number of events reaching to the millions per second. That is whydevelopers are increasingly relying on scalable cloud platforms to implement cloudapplications. Chariots exposes a shared log to be used by cloud applications. The log isessential for many tasks like bookkeeping; recovery; and debugging. Logs offerlinearizability and simple append and read operations of immutable records to facilitatebuilding complex systems like stream processors and transaction managers. As a cloudplatform; Chariots offers fault-tolerance; persistence; and high-availability; transparently.Current shared log infrastructures suffer from the bottleneck of serializing log recordsthrough a centralized server which limits the throughput to that of a single machine. We …,EDBT,2015,3
Mind your Ps and Vs: A perspective on the challenges of big data management and privacy concerns,Divyakant Agrawal; Amr El Abbadi; Vaibhav Arora; Ceren Budak; Theodore Georgiou; Hatem A Mahmoud; Faisal Nawab; Cetin Sahin; Shiyuan Wang,With large elastic and scalable infrastructures; the Cloud is the ideal storage repository forBig Data applications. Big Data is typically characterized by three V's: Volume; Variety andVelocity. Supporting these properties raises significant challenges in a cloud setting;including partitioning for scale out; replication across data centers for fault-tolerance;significant latency overheads due to consistency requirements; efficient traversal needs dueto high update and velocity; and continuous maintenance in the presence of large variety ofdata representations. Last but not least; the storage of private data necessitates the ability toefficiently execute queries in a privacy preserving manner (P); without revealing user accesspatterns. In this paper we highlight these challenges and illustrate sample state of the artsolutions.,Big Data and Smart Computing (BigComp); 2015 International Conference on,2015,3
Exploiting diversification in gossip-based recommendation,Maximilien Servajean; Esther Pacitti; Miguel Liroz-Gistau; Sihem Amer-Yahia; Amr El Abbadi,Abstract In the context of Web 2.0; the users become massive producers of diverse data thatcan be stored in a large variety of systems. The fact that the users' data spaces aredistributed in many different systems makes data sharing difficult. In this context of largescale distribution of users and data; a general solution to data sharing is offered bydistributed search and recommendation. In particular; gossip-based approaches providescalability; dynamicity; autonomy and decentralized control. Generally; in gossip-basedsearch and recommendation; each user constructs a cluster of “relevant” users that will beemployed in the processing of queries. However; considering only relevance introduces asignificant amount of redundancy among users. As a result; when a query is submitted; asthe user profiles in each user's cluster are quite similar; the probability of retrieving the …,International Conference on Data Management in Cloud; Grid and P2P Systems,2014,3
MEMS based storage architecture for relational databases,Hailing Yu; Divyakant Agrawal; Amr El Abbadi,Abstract Due to recent advances in semiconductor manufacturing; the gap between mainmemory and disks is constantly increasing. This leads to a significant performancebottleneck for Relational Database Management Systems. Recent advances innanotechnology have led to the invention of MicroElectroMechanical Systems (MEMS)based storage technology to replace disks. In this paper; we exploit the physicalcharacteristics of MEMS-based storage devices to develop a placement scheme forrelational data that enables retrieval in both row-wise and column-wise manner. We developalgorithms for different relational operations based on this data layout. Our experimentalresults and analysis demonstrate that this data layout not only improves I/O utilization; butresults in better cache performance for a variety of different relational operations.,The VLDB journal,2007,3
Using Linear Models to Monitor the Physical World with Sensors.,Fatih Emekçi; Sezai Emre Tuna; Divyakant Agrawal; Amr El Abbadi,Abstract Recent advances in hardware technology facilitate applications requiring a largenumber of sensor devices; where each sensor device has computational; storage; andcommunication capabilities. However these sensors are subject to certain constraints suchas limited power; high communication cost; low computation capability; presence of noise inreadings and low bandwidth. Since sensor devices are powered by ordinary batteries;power is a limiting resource in sensor networks and power consumption is dominated bycommunication. In order to reduce power consumption; we propose to use a linear model oftemporal; spatial and spatio-temporal correlations among sensor readings. With this model;readings of all sensors can be estimated using the readings of a few sensors by using linearobservers. Since a small set of sensors are accessed for query processing …,SSDBM,2005,3
Hardware acceleration for database systems using content addressable memories,Divyakant Agrawal; Amr El Abbadi,ABSTRACT Research efforts in conventional CPU architectures over the past decade havefocused primarily on performance enhancement. In contrast; the NPU (Network ProcessingUnit) architectures have evolved significantly. The memory hierarchy of a typical networkrouter features a Content-Addressable Memory (CAM) interfacing with the NPU in the sameway as a DRAM interfaces with a traditional CPU. CAM technology provides very fastconstant-time lookups over large amounts of data and facilitates a wide range of novelhighspeed networking solutions ranging from Packet Classification to Intrusion Detection.While these networking applications span an entirely different domain than the databaseapplications; they share a common operation namely lookup. Whether it is a databaseselectivity or join query; the core of many important database operators involves …,Proceedings of the 1st international workshop on Data management on new hardware,2005,3
Protein structure alignment using geometrical features,S Alireza Aghili; Divyakant Agrawal; Amr El Abbadi,Abstract A novel approach for similarity search on protein structure databases is proposedwhich incorporates the three dimensional coordinates of the main atoms of each amino acidand extracts a geometrical signature along with the direction of the given amino acid. As aresult; each protein is presented by a series of feature vectors representing local geometry;shape; direction; and secondary structure assignment of its amino acid constituents.Furthermore; a residue-to-residue distance matrix is calculated and is incorporated into alocal alignment dynamic programming algorithm to find the similar portions of two givenproteins and finally a sequence alignment step is used as the last filtration step. The optimalsuperimposition of the detected similar regions is used to assess the quality of the results.The proposed algorithm is fast and accurate and hence could be used for the analysis of …,Proceedings of the thirteenth ACM international conference on Information and knowledge management,2004,3
Exploiting the multi-append-only-trend property of historical data in data warehouses,Hua-Gang Li; Divyakant Agrawal; Amr El Abbadi; Mirek Riedewald,Abstract Data warehouses maintain historical information to enable the discovery of trendsand developments over time. Hence data items usually contain time-related attributes likethe time of a sales transaction or the order and shipping date of a product. Furthermore thevalues of these time-related attributes have a tendency to increase over time. We refer to thisas the Multi-Append-Only-Trend (MAOT) property. In this paper we formalize the notion ofMAOT and show how taking advantage of this property can improve query performanceconsiderably. We focus on range aggregate queries which are essential for summarizinglarge data sets. Compared to MOLAP data cubes the amount of pre-computation and henceadditional storage in the proposed technique is dramatically reduced.,International Symposium on Spatial and Temporal Databases,2003,3
Using transformation techniques towards efficient filtration of string proximity search of biological sequences,Alireza Aghili; Divyakant Agrawal; AE Abbadi,Abstract The problem of proximity search in biological databases is addressed. We studyvector transformations and conduct the application of DFT (Discrete Fourier Transformation)and DWT (Discrete Wavelet Transformation; Haar) dimensionality reduction techniques forDNA sequence proximity search to reduce the search time of range queries. Our empiricalresults on a number of Prokaryote and Eukaryote DNA contig databases demonstrate up to50-fold filtration ratio of the search space; up to 13 times faster filtration. The proposedtransformation techniques may easily be integrated as a preprocessing phase on top of thecurrent existing similarity search heuristics such as BLAST [1]; PattenHunter [11]; FastA [17];QUASAR [4] and to efficiently prune non-relevant sequences. We study the precision ofapplying dimensionality reduction techniques for faster and more efficient range query …,Technical Report,2003,3
Towards the integration of MEMS-based storage in computing systems,Hailing Yu; Divyakant Agrawal; Amr El Abbadi,*,Business Briefing: Data Management and Storage Technology,2003,3
Abbadi. Supporting sliding window queries for continuous data streams,Lin Qiao; Divyakant Agrawal; Amr El Abbadi,Abstract Although traditional databases and data warehouses have been exploited widely tomanage persistent data; a large number of applications from sensor network need functionalsupports for transient data in the continuous data stream. One of the crucial functions is tosummarize the data items within a sliding window. A sliding window contains a fixed widthspan of data elements. The data items are implicitly deleted from the sliding window; when itmoves out of the window scope. Several one-dimensional histograms have been proposedto store the succinct time information in a sliding window. Such histograms; however; onlyhandle the data items with attribute values in unary domains. In this paper; we explore theproblem of extending the value to a multi-valued domain. A two-dimensional histogram; thehybrid histogram; is proposed to support sliding window queries on a practical multi …,Proc. 15th Int. Conf. on Scientific and Statistical Database Management,2003,3
View derivation graph with edge fitting for adaptive data warehousing,Ioana Stanoi; Divyakant Agrawal; Amr El Abbadi,Abstract In this paper we propose adaptive data warehouse maintenance; based on theoptimistic partial replication of base local computation at the view as well as communicationwith the outside sources; and lowers the execution load on the base sources; which leads toa more up-to-date state of the data warehouse view.,International Conference on Data Warehousing and Knowledge Discovery,2000,3
Decentralized incremental maintenance of multi-view data warehouses,Ioana Stanoi; Divyakanth Agrawal; A El Abbadi,Decision support systems make up a big percentage of data base servers. Presently; theirsize increases due to the necessity of more detailed information; and the extended timerange of interest. As a result; data mining queries also span larger sets of data. To achievefast response time; a subset of the relevant information is sometimes materialized in views;separate from the database sources 4]. A data warehouse is an example of storage thatintegrates information from multiple sources; which may be stand-alone databases as wellas sites such as the Internet. Although data warehousing is a powerful concept forsupporting analytical processing; building a data warehouse runs into several pragmaticproblems. The cost of building a data warehouse that integrates disparate data sources inan organization can easily exceed millions of dollars. A more severe problem that arises …,University of California at Santa Barbara; Santa Barbara; CA,1999,3
Exotica/FMDC: Handling Disconnected Clients in a Workflow Management System,M Kamath; D Agrawal; A El Abbadi; C Mohan,*,Proc. of 3rd Int. Conference on Cooperative Information Systems. Wien,1995,3
Exotica/fmqm: A persistent message-based architecture for distributed workflow management,Alonso Mohan; G Alonso; C Mohan; R Gunthor; D Agrawal; A El Abbadi; M Kamath,Abstract In the past few years there has been an increasing interest in workflow applicationsas a way of supporting complex business processes in modern corporations. Given thenature of the environment and the technology involved; workflow applications are inherentlydistributed and pose many interesting challenges to the system designer. In most cases; aclient/server architecture is used in which knowledge about the processes being executed iscentralized in one node to facilitate monitoring; auditing; and to simplify synchronization. Inthis paper; we explore a novel distributed architecture; Exotica/FMQM; for workflow systemsin which the need for such a centralized database is eliminated. Instead; we use persistentmessages as the means to store the information relevant to the execution of a businessprocess. Our approach is to completely distribute the execution of a process so individual …,*,1995,3
Integrating Constraint Management and Concurrency Control in Distributed Databases,Gustavo Alonso; Amr El  Abbadi,Database systems often impose constraints on the values data items can take. Theseconstraints are determined by the application semantics. The traditional approach is toassume that user transactions respect such constraints. In particular; most transactionmanagers are based on the assumption that each transaction; if executed by itself on adatabase that meets the constraints; will transfer it to another state that also meets thoseconstraints. Serializability theory was developed to ensure that the interleaved execution ofa set of concurrent transactions is correct. Note that in this traditional model the system is notaware of the database constraints. The constraints are maintained by the transactions; notby the concurrency control protocol. Recently; proposals have been made to generalizethese protocols to shift the burden of constraint management from the transactions to the …,IEEE Data Eng. Bull.,1994,3
Computational Modeling Systems: Supporting the Development of Scientific Models,Terence R Smith; Jianwen Suy; Amr El Abbadi; Gustavo Alonso; Amitabh Saranz,Abstract We develop a conceptual model of the iterative process of scienti c modeling. Thismodel provides an appropriate speci cation for a large number of concepts relating to thoseaspects of the scienti c modeling process that require signi cant computational support. Inparticular; we develop; de ne and exemplify the unifying concept of representationalstructures. We employ the conceptual model in developing a framework for a\computationalmodeling system"(CMS) that supports scienti c activity within a simple; uni ed; computationalenvironment. A high level computational modeling language (CML) is presented with whichthe modeling concepts that are de nable in the computational framework may be constructedand manipulated in a simple; uniform manner. Finally; we describe the design andimplementation of a speci c computational modeling system; Amazonia; which is intended …,University of California at Santa Barbara; Santa Barbara; CA,1994,3
Autonomic; Elastic; Fault-tolerant; Scalable; and Secure Data Management in the Cloud,Sudipto Das; Aaron Elmore; Shiyuan Wang; Divyakant Agrawal; AE Abbadi,Abstract: Cloud computing has emerged as a revolutionary computing paradigm enabled byeconomies of scale due to large scale operations; pay-per-use pricing; and thecommoditizing of computing resources. Database management systems (DBMSs) poweringdata-rich applications deployed in the cloud face a unique set of challenges calling for noveltechniques; algorithms; and designs for cloud DBMSs. We present an overview of ourresearch addressing different challenges encountered by the next generation of databasemanagement systems. DBMSs powering cloud application platforms must serve largenumbers of applications with unpredictable load patterns while minimizing the operatingcost leveraging the underlying pay-per-use infrastructure. We have designed ElasTraS; anElastic TranSactional relational database for cloud platforms. ElasTraS is a confluence of …,University of California at Santa Barbara; Santa Barbara; CA,*,3
Privacy-preserving aggregation in life cycle assessment,Brandon Kuczenski; Cetin Sahin; Amr El Abbadi,Abstract Life cycle assessment (LCA) is the standard technique used to make a quantitativeevaluation about the ecological sustainability of a product or service. The life cycle inventory(LCI) data sets that provide input to LCA computations can express essential informationabout the operation of a process or production step. As a consequence; LCI data are oftenregarded as confidential and are typically concealed through aggregation with other datasets. Despite the importance of privacy protection in publishing LCA studies; the communitylacks a formal framework for managing private data; and no techniques exist for performingaggregation of LCI data sets that preserve the privacy of input data. However; emergingcomputational techniques known as “secure multiparty computation” enable datacontributors to jointly compute numerical results without enabling any party to determine …,Environment Systems and Decisions,2017,2
The challenges of global-scale data management,Faisal Nawab; Divyakant Agrawal; Amr El Abbadi,Abstract Global-scale data management (GSDM) empowers systems by providing higherlevels of fault-tolerance; read availability; and efficiency in utilizing cloud resources. This hasled to the emergence of global-scale data management and event processing. However; theWide-Area Network (WAN) latency separating data is orders of magnitude larger thanconventional network latencies; and this requires a reevaluation of many of the traditionaldesign trade-offs of data management systems. Therefore; data management problems mustbe revisited to account for the new design space. In this tutorial we survey recentdevelopments in GSDM focusing on identifying fundamental challenges and advancementsin addition to open research opportunities.,Proceedings of the 2016 International Conference on Management of Data,2016,2
InfoPuzzle: exploring group decision making in mobile peer-to-peer databases,Aaron J Elmore; Sudipto Das; Divyakant Agrawal; Amr El Abbadi,Abstract As Internet-based services and mobile computing devices; such as smartphonesand tablets; become ubiquitous; society's reliance on them to accomplish critical and time-sensitive tasks; such as information dissemination and collaborative decision making; alsoincreases. Dependence on these media magnifies the damage caused by their disruption;whether malicious or natural. For instance; a natural disaster disrupting cellular and Internetinfrastructures impedes information spread; which in turn leads to chaos; both among thevictims as well as the aid providers. Decentralized and ad-hoc mechanisms for informationdissemination and decision making are paramount to help restore order. We demonstrateInfoPuzzle; a mobile peer-to-peer database that utilizes direct device communication toenable group decision making; or consensus; without reliance on centralized …,Proceedings of the VLDB Endowment,2012,2
From a virtualized computing nucleus to a cloud computing universe: a case for dynamic clouds,Divyakant Agrawal; Sudipto Das; Amr El Abbadi,Abstract The current model of the cloud consists of a static set of data centers (or cloudcores) which drive the computation and storage needs of large numbers of applications. Weenvision a new paradigm where the cloud will be comprised of a large dynamic collection ofcloud cores along with a static set of cores; the nucleus; to create a cloud computinguniverse with a capacity much larger than the nucleus and a cost much smaller than owningthe entire infrastructure. This model is rooted by the observation that a tremendous amountof computation exists outside the core that can potentially augment the nucleus' capacity. Anexample of this surplus capacity are enterprizes with diurnal trends in usage behavior thatjoin the cloud during predicted periods of usage troughs. We propose to leverage this elasticand dynamic infrastructure to create a unified cloud service. A number of challenges; at …,*,2011,2
Vshmem: Shared-memory os-support for multicorebased hpc systems,Lamia Youseff; Rich Wolski; Fang Yu; Tevfik Bultan; Oscar H Ibarra; Xia Zhou; Alessandra Sala; Haitao Zheng; Lorenzo Cavallaro; Christopher Kruegel; Giovanni Vigna; Fang Yu; Muath Alkhalaf; Tevfik Bultan; Lili Cao; Lei Yang; Heather Zheng; Christopher C Cipriano; Teofilo F Gonzalez; Steffen Gauglitz; Tobias Höllerer; Xia Zhou; Heather Zheng; Omer Egecioglu; Peterson Trethewey; Tobias Hollerer; Sudipto Das; Shyam Antony; Divyakant Agrawal; Amr El Abbadi; Sudipto Das; Ömer Egecioglu; Amr El Abbadi; Navraj Chohan; Chris Bunch; Sydney Pang; Chandra Krintz; Nagy Mostafa; Sunil Soman; Rich Wolski; Ömer Egecioglu; Oscar H Ibarra; Nagy Mostafa; Chandra Krintz; Sudipto Das; Shyam Antony; Divyakant Agrawal; Amr El Abbadi; Lamia Youseff; Dmitrii Zagorodnov; Rich Wolski; Graham Hughes; Tevfik Bultan; Aydin Buluc; John R Gilbert; Ceren Budak; Navraj Chohan; Krishna PN Puttaswamy; Alessandra Sala; Ben Y Zhao; Krishna Puttaswamy; Alessandra Sala; Christo Wilson; Ben Y Zhao,*,*,2009,2
Dataset and evaluation of interest point detectors for visual tracking,Steffen Gauglitz; Tobias Höllerer; Matthew Turk,ABSTRACT In this report; we present an extensive dataset of 96 video streams with groundtruth. It includes various geometric changes; lighting conditions; and levels of motion blur;and can be used as testbed for a variety of algorithms in the context of visual tracking. Wethen use this dataset for a detailed quantitative evaluation of popular interest point detectors;which; in contrast to existing evaluations; is geared towards visual tracking in all relevantfactors of the evaluation design.,In practice,2009,2
Environmental tomography: Modeling the environment with mobile phones,Stacy Patterson; Bassam Bamieh; Amr El Abbadi,Abstract The coupling of sensors with mobile phones; which are ubiquitously available andlocation aware; opens the door to the creation of applications for pervasive sensing anddetailed spatial modeling of environmental phenomena. In order to ensure widespreadparticipation of mobile users; these applications must have limited per-device resourcerequirements; must place no expectations on individual user behaviors; and must besensitive to user privacy concerns. In this work; we introduce Environmental Tomography; anovel approach to environmental sensing and spatial data modeling that meets thechallenges of the mobile network. Environmental Tomography consists of two phases; adata collection phase in which the network of mobile devices computes aggregate values ofsensor readings along roads and sidewalks; and a reconstruction phase in which the …,University of California; Santa Barbara; Tech. Rep,2007,2
Attribute-based access to distributed data over P2P networks,Divyakant Agrawal; Amr El Abbadi; Subhash Suri,Peer-to-Peer (P2P) networks are distributed data sharing systems with no dedicated andcentralised infrastructure. While P2P systems have been used so far mainly for file sharing;their true potential lies as a vast; loosely connected worldwide infrastructure for sharingresources; data and information. This paper addresses a natural step in the evolution ofP2P: data and information sharing where data is accessed based on its attributes orproperties. We have identified diverse applications that can benefit directly from attribute-based access to distributed data over P2P systems. Based on the application requirements;we propose three new models for both data distribution and data accesses.,International Journal of Computational Science and Engineering,2007,2
Fast computation of database operations using content-addressable memories,Nagender Bandi; Divyakant Agrawal; Amr El Abbadi,Abstract Research efforts on conventional CPU architectures over the past decade havefocused primarily on performance enhancement. In contrast; the NPU (Network ProcessingUnit) architectures have evolved significantly in terms of functionality. The memory hierarchyof a typical network router features a Content-Addressable Memory (CAM) which providesvery fast constant-time lookups over large amounts of data and facilitates a wide range ofnovel high-speed networking solutions such as Packet Classification; Intrusion Detectionand Pattern Matching. While these networking applications span an entirely different domainthan the database applications; they share a common operation of searching for a particulardata entry among huge amounts of data. In this paper; we investigate how CAM-basedtechnology can help in addressing the existing memory hierarchy bottlenecks in database …,International Conference on Database and Expert Systems Applications,2006,2
Automated Storage Management with QoS Guarantee in Large-scale Virtualized Storage Systems.,Lin Qiao; Balakrishna R Iyer; Divyakant Agrawal; Amr El Abbadi,Abstract Storage virtualization in modern storage systems allows variability in the number of“physical” disks supporting a single “virtual” disk. In practice; IO workloads vary with time.Presuming the evolution of reasonable predictive models with the power of accuratelypredicting IO workload; it may be argued that it is straightforward to compute the number ofdisks needed at any time to satisfy QoS constraints. However; because disks contain data;the data also needs to be reallocated amongst disks. Not only does data migration need tobe scheduled ahead but it must also be scheduled in such a way that QoS violations do notoccur because of the extra migration IOs. In this paper; we present a novel analyticframework; PULSTORE; for autonomically managing the storage to balance both cost andperformance. Given the workload characteristics of an application and storage QoS …,IEEE Data Eng. Bull.,2006,2
MARS: A Matching and Ranking System for XML Content and Structure Retrieval,S Alireza Aghili; Hua-Gang Li; Divyakant Agrawal; Amr El Abbadi,Abstract Structural queries specify complex predicates on the content and the structure of theelements of tree-structured XML documents. Recent works have typically applied top-downdecomposition of the twig patterns into (i) parent-child or ancestordescendant relationships;or (ii) path expression queries; and then followed by a join operation to reconstruct matchedtwig patterns. This demonstration system is the implementation prototype of an efficientheuristic-based bottom-up approach named MARS (Matching And Ranking System for xmlstructure queries); for matching and ranking of structural query patterns for XML queryprocessing. An efficient nearest common ancestor labeling scheme is applied to utilize fastbottomup construction of the subtree matches from the potential keywords. MARS considersboth the content and structure of queries and incorporates a variation of IR-based …,*,2005,2
Efficient similarity search on vector sets,Hailing Yu; Wei Niu; Divyakant Agrawal; Amr El Abbadi; Ambuj K Singh,ABSTRACT Similarity search in applications such as multimedia databases has beengaining a lot of attention in recent years. Due to the curse of dimensionality; it is hard toimprove the query cost of similarity search in a high dimensional space. The problem isgetting even worse when objects are represented using sets of local feature vectors; sincethe distance measurement among vector sets is the minimum matching distance. In theminimum matching distance; the vectors from two sets are paired to minimize the sum of thedistance of all pairs while the distance measurements over single feature vectors do notneed the process of pairing. In this paper; we extend the minimum matching distance to theEuclidean minimum matching distance and the Manhattan minimum matching distancesince Euclidean and Manhattan distances are commonly used in similarity search over …,Department of Computer Science; University of California; Santa Barbara; Tech. Rep,2004,2
Disk allocation for fast range and nearest-neighbor queries,Sunil Prabhakar; Divyakant Agrawal; Amr El Abbadi,Abstract As databases increasingly integrate non-textual multimedia information it isbecoming necessary to support efficient similarity searching in addition to range searching.Range and nearest-neighbor (similarity) queries are the most important class of queries formultimedia and multi-dimensional databases. Due to the large sizes of the datasetsinvolved; I/O is a critical factor limiting performance. The use of parallel I/O throughdeclustering of the data is a promising approach to improve performance. Consequentlyseveral research efforts have addressed the problem of declustering multidimensional datafor optimizing range and partial match queries. Very limited work has been done forsimilarity queries; and the problem of declustering for combined range and similarity querieshas not been addressed in the literature. Consider a dataset of images where the …,Distributed and Parallel Databases,2003,2
Towards a formal model for view maintenance in data warehouses,Achour Mostefaoui; Michel Raynal; Matthieu Roy; Divyakant Agrawal; Amr El Abbadi,As the capability for storing data increases; there is a greater need for developing analysistools that provide aggregation and summarization capabilities. In the context of databases; anew class of query processing referred to as OLAP (OnLine Analytical Processing) hasemerged for aggregating and summarizing vast amount of data. A typical example of anOLAP query is to identify total sales for a product type in a geographic region over a specificperiod of time. As this example illustrates; since OLAP queries need to scan the data foraggregation; executing them on traditional DBMSs will adversely impact the OLTP (OnLineTransaction Processing) workload; which typically consists of short update transactions.Furthermore; enterprise wide data is typically stored on multiple database repositories. Suchgeographical distribution leads to expensive distributed processing for OLAP queries …,Proceedings of the twenty-first annual symposium on Principles of distributed computing,2002,2
Dynamic multidimensional data cubes,Mirek Riedewald; Divyakant Agrawal; Amr El Abbadi,ABSTRACT Data cubes are ubiquitous tools in data warehousing; online analyticalprocessing; and decision support applications. Based on a selection of precomputed andmaterialized aggregate values; they can dramatically speed up aggregation andsummarization over large data collections. Traditionally; the emphasis has been on loweringquery costs with little regard to maintenance; ie; update cost issues. We argue that currenttrends require data cubes to be not only query-efficient; but also dynamic at the same time;and we also show how this can be achieved. Several array-based techniques with differenttradeoffs between query and update cost are discussed in detail. We also survey selectedapproaches for sparse data and the popular data cube operator; CUBE. Moreover; this workincludes an overview of future trends and their impact on data cubes.,Multidimensional Databases: Problems and Solutions: Problems and Solutions,2002,2
Optimal partitioning for spatial data,Hakan Ferhatosmanoglu; Divyakant Agrawal; Amr El Abbadi,Abstract It is desirable to design partitioning techniques that minimize the I/O time incurredduring query execution in spatial databases. In this paper; we explore optimal partitioningtechniques for spatial data for di erent types of queries. In particular; we show thathexagonal partitioning has optimal I/O cost for circular queries compared to all possible non-overlapping partitioning techniques that use convex regions. For rectangular queries; weshow that although for the special case when queries are rectilinear; rectangular gridpartitioning gives superior performance; hexagonal partitioning has overall better I/O cost fora general class of range queries. We also discuss storage and retrieval techniques forhexagonal partitioning using current techniques for rectangular grid partitioning. i,Technical Report; Comp. Sci. Dept.,2000,2
Efficient detection of discrepancies in multiple file copies,Khaled AS Abdel-Ghaffar; Amr El Abbadi,Summary. For data consistency in distributed information systems; it is often necessary tocompare remotely located copies of a file. We develop several protocols for the efficientdetection of differing pages in a replicated file in different communication and failure models.The first set of protocols assumes a restricted but practical communication model. In thiscase; the minimum amount of communication necessary to identify any given number ofdiffering pages is determined and a technique to attain this minimum is presented. For themore general communication model and for more refined failure models; we show that moreefficient protocols can be derived. Our approach is based on the theory of Galois fields.,Distributed Computing,1998,2
Abbadi. Using broadcast primitives in replicated databases,I Stanoi; D Agrawal; A El Abbadi,Abstract We explore the use of di erent variants of broadcast protocols for managingreplicated databases. Starting with the simplest broadcast primitive; the reliable broadcastprotocol; we show how it can be used to ensure correct transaction execution. The protocolis simple; and has several advantages; including prevention of deadlocks. However; itrequires a twophase commitment protocol for ensuring correctness. We then develop asecond protocol that uses causal broadcast and avoids the overhead of two-phase commitby exploiting the causal delivery properties of the broadcast primitives to implicitly collect therelevant information used in two-phase commit. Finally; we present a protocol that employsatomic broadcast and completely eliminates the need for acknowledgements duringtransaction commitment. 1,*,1998,2
The performance of replica control protocols in the presence of site failures,ML Liu; Divyakant Agrawal; Amr El Abbadi,Abstract Replicated data were employed in distributed databases to enhance dataavailability. However; this benefit of data availability is only realized at the cost of elaboratealgorithms that hide the underlying complexity of maintaining multiple copies of a single dataitem. The difficulty lies in keeping the copies consistent in the face of system failures while atthe same time maximizing data availability. The algorithms which address these problemsare called replica control algorithms. Although replica control has been the subject ofextensive research for quite some time now; it has yet to fulfil its promise in practicalapplications. A major reason for this lack of acceptance is that the performance impact ofthese protocols cannot be easily quantified; as very few existing performance figures ofcommercial database systems which support copies are available. A natural question …,Distributed Systems Engineering,1997,2
An efficient implementation of the quorum consensus protocol,ML Liu; D Agrawal; AE Abbadi,Abstract The Quorum Consensus (QC) algorithm; a replication control algorithm whichprovides serializability even in the presence of network partitioning; has been studiedextensively but is not widely implemented in practice. One of the reasons for its lack ofacceptance is that the gathering of a quorum for each operation in a transaction is non-trivialto implement. The typical approach is either (i) to send each operation to all replica sites andwait for a quorum of sites to respond; or (ii) to send each operation to a random quorum set;then retry if not all responses are received after a timeout. Both alternatives are difficult toimplement. This paper proposes a simple implementation approach which makes use of anestimated uplist at the site of a transaction coordinator. Such a list provides a hint on whichreplica sites are currently communicable. We argue that such a list is typically maintained …,*,1994,2
Optimal detection of a corrupted page in a replicated file,Khaled AS Abdel-Ghaffar; Amr El Abbadi,The problem of detecting a corrupted page in a file with multiple copies is addressed. Alower bound is derived on the communication overhead and a protocol is developed thatrequires exactly the amount of communication specified by the lower bound. The lowerbound and the protocol are the first optimality results for the detection of a corrupted page ina file with more than two copies.,Distributed Computing Systems; 1994.; Proceedings of the 14th International Conference on,1994,2
Dynamic logical structures: A position statement for managing replicated data,Divyakant Agrawal; Amr El Abbadi,The authors discuss extensions to the grid protocol to improve the fault-tolerance of writeoperations by using the notions of structured read and write grid quorums. As is the case inthe standard quorum protocols; the increased fault-tolerance for write operations is at theincreased cost of executing read operations. In order to let users continue using theanalogues of the read-one-write-all protocol in the context of a logical structure; theydevelop reconfiguration protocols for dynamically adapting to failures and recovery. Thisresults in the following dichotomy. Users accesses are through the simple analogues of theread-one-write-all protocol with respect to a logical structure and therefore have lowcommunication cost for read operations. On the other hand; the reconfiguration protocoluses the notion of quorums in the context of a logical structure to ensure high data …,Management of Replicated Data; 1992.; Second Workshop on the,1992,2
On the optimality of disk allocation for Cartesian product files,Khaled AS Abdel-Ghaffar; Amr El Abbadi,Abstract In this paper we present a coding-theoretic analysis of the disk allocation problem.We provide both necessary and sufficient conditions for the existence of strictly optimalallocation methods. Based on a class of optimal codes; known as maximum distanceseparable codes; strictly optimal allocation methods are constructed. Using the necessaryconditions proved; we argue that the standard definition of strict optimality is too strong; andcannot be attained in general. A new criterion for optimality is therefore defined whoseobjective is to design allocation methods that yield a response time of one for all querieswith a minimum number of specified attributes. Using coding theory; we determined thisminimum number for binary files; assuming that the number of disks is a power of two. Ingeneral; our approach provides better allocation methods than previous techniques.,Proceedings of the ninth ACM SIGACT-SIGMOD-SIGART symposium on Principles of database systems,1990,2
Power-aware Query processing over Sensor Networks,Fatih Emekci; Hailing Yu; Divyakant Agrawal; Amr El Abbadi,Abstract. Recent advances in hardware technology make applications requiring largenumbers of sensor devices possible; where each sensor device has computation; memory;and communication capabilities. Since sensor devices are powered by ordinary batteries;power is a limiting resource in sensor networks. Some work has been proposed to reducethe power usage by pushing part of the computation into the network to reducecommunication cost; which is an expensive operation in sensor networks. In order to furtherreduce power usage based on the inherent property of sensor networks; we propose power-aware query processing techniques for aggregation queries. Instead of giving exact answersto users' queries; we introduce precision into queries to give users full control of the tradeoffbetween precision and energy usage. By employing the notion of value prediction at the …,Technical Reports,*,2
Caching at the web scale,Victor Zakhary; Divyakant Agrawal; Amr El Abbadi,Abstract Today's web applications and social networks are serving billions of users aroundthe globe. These users generate billions of key lookups and millions of data object updatesper second. A single user's social network page load requires hundreds of key lookups. Thisscale creates many design challenges for the underlying storage systems. First; thesesystems have to serve user requests with low latency. Any increase in the request latencyleads to a decrease in user interest. Second; storage systems have to be highly available.Failures should be handled seamlessly without affecting user requests. Third; usersconsume an order of magnitude more data than they produce. Therefore; storage systemshave to be optimized for read-intensive workloads. To address these challenges; distributedin-memory caching services have been widely deployed on top of persistent storage. In …,Proceedings of the VLDB Endowment,2017,1
Privacy Cyborg: Towards Protecting the Privacy of Social Media Users,Theodore Georgiou; Amr El Abbadi; Xifeng Yan,Towards the vision of building artificial intelligence systems that can assist with our everydaylife; we introduce a proof of concept for a social media privacy" cyborg" which can locallyand privately monitor a person's published content and offer advice or warnings when theirprivacy is at stake. The idea of a cyborg can be more general; as a separate local entity withits own computational resources; that can automatically perform several online tasks on ourbehalf. For this demonstration; we assume an attacker that can successfully infer userattributes; solely based on what the user has published (topic-based inference). We focus onSocial Media privacy and specifically on the issue of exposing sensitive user-attributes; likelocation; or race; through published content. We built a privacy cyborg that can monitor auser's posted topics and automatically warn them in real time when a sensitive attribute is …,Data Engineering (ICDE); 2017 IEEE 33rd International Conference on,2017,1
Increasing Coverage in Distributed Search and Recommendation with Profile Diversity,Maximilien Servajean; Esther Pacitti; Miguel Liroz-Gistau; Sihem Amer-Yahia; Amr El Abbadi,Abstract With the advent of Web 2.0 users are producing bigger and bigger amounts ofdiverse data; which are stored in a large variety of systems. Since the users' data spaces arescattered among those independent systems; data sharing becomes a challenging problem.Distributed search and recommendation provides a general solution for data sharing andamong its various alternatives; gossip-based approaches are particularly interesting as theyprovide scalability; dynamicity; autonomy and decentralized control. Generally; in theseapproaches each participant maintains a cluster of “relevant” users; which are lateremployed in query processing. However; as we show in the paper; only consideringrelevance in the construction of the cluster introduces a significant amount of redundancyamong users; which in turn leads to reduced recall. Indeed; when a query is submitted …,*,2015,1
Panel discussion on social networks and mobility in the cloud,Amr El Abbadi; Mohamed F Mokbel,Abstract Social networks; mobility and the cloud represent special and unique opportunitiesfor synergy among several existing and emerging communities that are now often evolvingin isolated silos. All three areas hold much promise for the future of computing; andrepresent significant challenges for large scale data management. As these three areasevolve; their direct influence on significant decisions on each other becomes evident andcritical. This panel will bring together a set of renowned researchers who will explore anddiscuss the synergy and tensions among critical and often intertwined research andapplication issues that arise in the context of social networks and mobility in a cloudinfrastructure setting.,Proceedings of the VLDB Endowment,2012,1
Towards Multitenancy for IO-bound OLAP Workloads,Hatem A Mahmoud; Hyun Jin Moon; Yun Chi; Divyakant Agrawal; Amr El-Abbadi,ABSTRACT Consolidation of multiple databases on the same server allows serviceproviders to save significant resources because many production database servers are oftenunder-utilized. We consider the problem of minimizing the number of servers needed to hosta set of tenants; while satisfying the service level agreement (SLA) on the throughput of eachtenant. Recent research investigates this problem under the assumption that the workingsets of tenants are kept in main memory (eg; OLTP workloads; or in-memory OLAPworkloads); thus the buffer size of each tenant is dictated by the working set size of thattenant. In this paper we instead investigate the problem when the throughput SLAs oftenants are low enough for queries to be answered from disk. We study the trade-offbetween buffer size and query execution time for IO-bound workloads and propose an …,Bericht; University of California; Santa Barbara,2012,1
Tackling bidder collusion in dynamic spectrum auctions (extended),Xia Zhou; Alessandra Sala; Haitao Zheng; Lorenzo Cavallaro; Christopher Kruegel; Giovanni Vigna; Fang Yu; Muath Alkhalaf; Tevfik Bultan; Lili Cao; Lei Yang; Heather Zheng; Christopher C Cipriano; Teofilo F Gonzalez; Steffen Gauglitz; Tobias Höllerer; Xia Zhou; Heather Zheng; Omer Egecioglu; Peterson Trethewey; Tobias Hollerer; Sudipto Das; Shyam Antony; Divyakant Agrawal; Amr El Abbadi; Sudipto Das; Ömer Egecioglu; Amr El Abbadi; Navraj Chohan; Chris Bunch; Sydney Pang; Chandra Krintz; Nagy Mostafa; Sunil Soman; Rich Wolski; Ömer Egecioglu; Oscar H Ibarra; Nagy Mostafa; Chandra Krintz; Sudipto Das; Shyam Antony; Divyakant Agrawal; Amr El Abbadi; Lamia Youseff; Dmitrii Zagorodnov; Rich Wolski; Graham Hughes; Tevfik Bultan; Aydin Buluc; John R Gilbert; Ceren Budak; Navraj Chohan; Krishna PN Puttaswamy; Alessandra Sala; Ben Y Zhao; Krishna Puttaswamy; Alessandra Sala; Christo Wilson; Ben Y Zhao; Krishna PN Puttaswamy; Alessandra Sala; Omer Egecioglu; Ben Y Zhao; Daniel Nurmi; Rich Wolski; Chris Grzegorczyk; Graziano Obertelli; Sunil Soman; Lamia Youseff; Dmitrii Zagorodnov,Abstract—Dynamic spectrum auction is an effective solution to manage spectrum acrossmany small networks. As the number of participants grows; collusion poses a serious threatto auction performance. Small groups of colluding bidders can make use of the interferenceconstraints to manipulate auction outcomes; leading to unfair spectrum distribution andsignificant loss in auction revenue. Prior designs; however; are either forced to give upspatial reuse for collusion-resistance; become computationally prohibitive; or can onlyaddress very limited types of collusion. In this paper; we present DC2; a systematic auctiondesign that can effectively discourage collusion and achieve spatial reuse; even whenmultiple collusion groups are present. DC2 achieves this using a novel 3-stage “Divide;Conquer; and Combine” procedure that integrates an efficient spectrum allocation …,*,2009,1
Using tomography for ubiquitous sensing,Stacy Patterson; Bassam Bamieh; Amr El Abbadi,Abstract By embedding sensors in mobile devices; it is possible to exploit the ubiquitouspresence of these devices to construct applications for large-scale sensing and monitoringof environmental phenomena. To this end; we present Environmental Tomography; a novelapproach in which mobile devices participate in the collection of aggregate sensor readingsalong roads or sidewalks; and these aggregates are used to reconstruct an estimate of thecontaminant distribution throughout a region. We demonstrate how our data collectionprocess preserves user location privacy and is robust to sensor and location reading errors.We also show how the estimation process can be formulated as a convex optimizationproblem that incorporates the physical dynamics of the phenomenon of interest. We studythe performance of Environmental Tomography using various road network layouts and …,Proceedings of the 16th ACM SIGSPATIAL international conference on Advances in geographic information systems,2008,1
Verification of string manipulating programs using multi-track automata,Fang Yu; Tevfik Bultan; Oscar H Ibarra,Abstract Verification of string manipulation operations is a crucial problem in computersecurity. We present a new symbolic string verification technique that can be used to provethat vulnerabilities that result from improper string manipulation do not exist in a givenprogram. We formally characterize the string verification problem as the reachability analysisof string systems; programs that contain only string variables and allow a limited set ofoperations on them. We show that string analysis problem is undecidable with even threevariables if branch conditions that compare different variables are allowed. We develop asound symbolic analysis technique for string verification that over-approximates thereachable states of the string system. We represent the set of string values that stringvariables can take using multi-track deterministic finite automata and implement a forward …,*,2008,1
On the feasibility of large-scale automated highways,Stacy Patterson; Bassam Bamieh; Amr El Abbadi; Mihailo Jovanovic,Abstract We investigate the use of large-scale Automated Highway Systems; also called one-dimensional vehicle platoons; as a practical traffic mitigation solution. We review recenttheoretical results related to vehicle platooning and discuss their implications on thescalability and safety of large-scale platoons. We also quantify the performance of differentplatoon control strategies through simulations that use realistic models of vehicle dynamicsand sensor accuracy.,Proceedings of the 5th Annual International Conference on Mobile and Ubiquitous Systems: Computing; Networking; and Services,2008,1
Guaranteeing correctness of lock-free range queries over P2P data,Stacy Patterson; Divyakant Agrawal; Amr El Abbadi,Abstract As P2P systems evolve into a platform for full-fledged distributed databasemanagement systems; the need arises for sophisticated query support and guarantees onquery correctness. While there has been recent work addressing range queries in P2Psystems; the work on query correctness is just beginning. Linga et al.[1] provided the firstformal definition of correctness for range queries in P2P systems and described a lock-based range query technique that is provably correct. A natural question that arises iswhether it is possible to develop a lock-free protocol that can meet the same guarantee ofcorrectness. In this paper; we demonstrate the feasibility of lock-free correct protocols by firstdeveloping a simple; proof-of-concept query protocol and verifying that this protocol meetsthe correctness conditions. We then describe a more robust extended protocol and prove …,*,2007,1
The optimality of allocation methods for bounded disagreement search queries: The possible and the impossible,Khaled AS Abdel-Ghaffar; A El Abbadi,Data allocation on multiple I/O devices manifests itself in many computing systems; bothcentralized and distributed. Data is partitioned on multiple I/O devices and clients issuevarious types of queries to retrieve relevant information. In this paper; we derive necessaryand sufficient conditions for a data allocation method to be optimal for two important types ofqueries: partial match and bounded disagreement search queries. We formally define thesequery types and derive the optimality conditions based on coding-theoretic arguments.Although these conditions are fairly strict; we show how to construct good allocationmethods for practical realistic situations. Not only are the response times bounded by asmall value; but also the identification of the relevant answer set is efficient,IEEE transactions on knowledge and data engineering,2006,1
Exploiting sequential access when declustering data over disks and MEMS-based storage,Hailing Yu; Divyakant Agrawal; Amr El Abbadi,Abstract Due to the large difference between seek time and transfer time in current disktechnology; it is advantageous to perform large I/O using a single sequential access ratherthan multiple small random I/O accesses. However; prior optimal cost and data placementapproaches for processing range queries over two-dimensional datasets do not considerthis property. In particular; these techniques do not consider the issue of sequential dataplacement when multiple I/O blocks need to be retrieved from a single device. In this paper;we reevaluate the optimal cost of range queries by declustering two-dimensional datasetsover multiple devices; and prove that; in general; it is impossible to achieve the new optimalcost. This is because disks cannot facilitate two-dimensional sequential access which isrequired by the new optimal cost. Then we revisit the existing data allocation schemes …,Distributed and Parallel Databases,2006,1
Scalable ranking for preference queries,Ying Feng; Divyakant Agrawal; Amr El Abbadi; Ambuj Singh,Abstract Top-k preference queries with multiple attributes are critical for decision-makingapplications. Previous research has concentrated on improving the computational efficiencymainly by using novel index structures and search strategies. Since current applicationsneed to scale to terabytes of data and thousands of users; performance of such systems isstrongly impacted by the amount of available memory. This paper proposes a scalableapproach for memory-bounded top-k query processing.,Proceedings of the 14th ACM international conference on Information and knowledge management,2005,1
BFT: A Relational-based Bit Filtration Technique for Efficient Approximate String Joins in Biological Databases,S Alireza Aghili; Divyakant Agrawal; Amr El Abbadi,Abstract. Joining massive tables in relational databases have received substantial attentionin the past decade. Numerous filtration and indexing techniques have been proposed toreduce the curse of dimensionality. This paper proposes a novel approach to map theproblem of pairwise whole genome comparison into an approximate join operation in thewellestablished relational database context. We propose a novel Bit Filtration Technique(BFT) based on vector transformation and furthermore conduct the application of DFT(Discrete Fourier Transformation) and DWT (Discrete Wavelet Transformation; Haar)dimensionality reduction techniques as a pre-processing filtration step to effectively reducethe search space. BFT reduces the search space and the running time of the join operationdrastically. Our empirical results on a number of Prokaryote and Eukaryote DNA contig …,Join in Biological Databases (Extended Version). UCSB Technical Report,2003,1
Towards a Formal Model for View Maintenance in Data Warehouses,Divyakant Agrawal; Amr El Abbadi; Achour Mostéfaoui; Michel Raynal; Matthieu Roy,Page 1. Towards a Formal Model for View Maintenance in Data Warehouses D. Agrawal а ; A.El Abbadi а ; A. Most┤efaoui б ; M. Raynal б and M. Roy б в Univ. Santa Barbara; Californiaг IRISA; Rennes; France Towards a Formal Modelfor View Maintenance in Data Warehouses –p.1/22 Page 2. Summary The Data Warehouse Problem Definitions Existing protocols A FormalDefinition of the Problem Formal Definition of Data Objects Abstract Definition of ViewManagement The Protocol A Virtual Topology A Pipelining Technique Towards a Formal ModelforView Maintenance in Data Warehouses – p.2/22 Page 3. The Data Warehouse Problem A setof databases ав б г ав д г еее г аз ж How to efficiently query a database aggregate? Query x2x3 x4 x5 x1 Towards a Formal Modelfor View Maintenance in Data Warehouses – p.3/22 Page4. The Data Warehouse Problem A set of databases ав б г ав д г еее г аз ж …,Proceedings of the 21th ACM SIGACT-SIGOPS International Symposium on Principles of Distributed Computing (PODC-2002). ACM Press,2002,1
Indexing without the Index: Scalable Multidimensional Aggregation for Data Warehouses,Mirek Riedewald; Divyakant Agrawal; Amr El Abbadi; Flip Korn,Abstract Aggregation plays an important role in data warehousing and has received muchattention to date. However; existing techniques do not su ciently address the issue of makingthe computation of multidimensional aggregates scale with increasing dimensionality. At thesame time the bene t of taking full advantage of the hard disk geometry is often overlooked.This paper presents the Multiresolution File Scan (MFS) approach which is based on aselection of at les which are accessed with fast sequential I/O operations. Its simple structureand low storage overhead allow MFS to scale to high dimensionality while making the bestuse of the increasing transfer speed of modern hard disks. We show that MFS outperformsmultidimensional index structures; even if these structures are bulk-loaded and henceoptimized for query processing. Our approach can incorporate a priori knowledge about …,Computer Science Technical Report,2002,1
Twenty-sixth International Conference on Very Large Databases,Amr El Abbadi,*,*,2000,1
performance Characteristics of the Dynamic Data Cube,S Geffner; D Agrawal; AE Abbadi,Abstract Range sum queries on data cubes are a powerful tool for analysis. A range sumquery applies an aggregation operation (eg; SUM; AVERAGE) over all selected cells in adata cube; where the selection is specified by providing ranges of values for numericdimensions. We present the Dynamic Data Cube; a new approach to range sum querieswhich provides efficient performance for both queries and updates; which handles clusteredand sparse data gracefully; and which allows for the dynamic expansion of the data cube inany direction.,*,1999,1
Dft techniques for size estimation of database join operations,Kamil Sarac; ÖMER EĞECİOĞLU; AMR EL ABBADI,Novel algorithms based on the Discrete Fourier Transform (DFT) are proposed to estimatethe size of relations resulting from join operations. We start with an approach in which thefrequency distribution values are transformed using the DFT and the Fourier coefficients areused to construct histograms. Our main contribution is a direct approach which uses theamplitudes of the DFT coefficients iteratively. The proposed algorithm gives the exact joinsize using logarithmic space for the special case of self join. A generalization to compute thejoin of arbitrary relations is then used to develop two tree-based techniques that provide aspectrum of algorithms which interpolate storage requirements versus accuracy of theestimation obtained. Finally; we present experimental results to exhibit the effectiveness ofour approach.,International Journal of Foundations of Computer Science,1999,1
Iterated DFT based techniques for join size estimation,Kamil Saraç; Ömer Eğecioǧlu; Amr El Abbadi,Abstract Novel techniques based on the Discrete Fourier Transform are proposed toestimate the size of relations resulting from join operations. For the special case of self jointhe proposed algorithm gives the exact join size using logarithmic space. A generalization tocompute the join of arbitrary relations is then used to develop two tree-based techniques thatprovide a spectrum of algorithms which interpolate storage requirements versus accuracy ofthe estimation obtained. Finally; we present experimental results to exhibit the effectivenessof our approach.,Proceedings of the seventh international conference on Information and knowledge management,1998,1
Transaction management in OOMDBS,D Agrawal; A El Abbadi,*,Object-oriented multidatabase systems,1995,1
Data Engineering,Divy Agrawal; Amr El Abbadi; Kenneth Salem; Manuel Bravo; Nuno Diegues; Jingna Zeng; Paolo Romano; Luıs Rodrigues; Philip A Bernstein; Sudipto Das; Justin Levandoski; Sudipta Sengupta; Ryan Stutsman; Rui Wang; Tudor-Ioan Salomie; Gustavo Alonso; Bettina Kemme; Ivan Brondino; José Pereira; Ricardo Vilaça; Francisco Cruz; Rui Oliveira; Yousuf Ahmad,Members of the Technical Committee on Data Engineering (TCDE) have voted for a newTCDE. The turnout for the election was higher than in past elections; which demonstrates; Ithink; two things. One; past TCDE Chair Kyu-Young Whang's initiative to enlargemembership has resulted in a larger overall TCDE membership; and hence a largerelectorate. Two; we had two strong candidates in Xiaofang Zhou and Erich Neuhold; whichgenerate more interest than in the past. The outcome is that Xiaofang Zhou is the new chairof the TCDE. I want to congratulate Xiaofang on his election victory. I am confident thatXiaofang will be a fine TCDE chair; and I look forward to working with him going forward.Xiaofang's letter as TC Chair appears on page 2 of the current issue. The TCDE Chair is theone empowered to appoint the TCDE Executive Committee. The new committee is shown …,*,1995,1
Comparing multiple file copies using minimal communication,Khaled AS Abdel-Ghaffar; Amr El Abbadi,The minimum amount of communication necessary to identify any given number oferroneous pages among the copies of a file is determined and a technique to attain thisminimum is presented. We study the general case of identifying all corrupted pager amongany number of secondary sites. We assume that secondary sites can communicate only withthe primary site. We present a protocol that identifies the corrupted pages and prove that thisprotocol is optimal in the sense of requiring the minimum amount of communication. Thisprotocol relies on the structure of Reed-Solomon codes.,Information Theory; 1994. Proceedings.; 1994 IEEE International Symposium on,1994,1
On the power of reconfiguration in fault-tolerant distributed databases,El Abbadi,Dynamic reconfiguration is used to significantly increase fault-tolerance in replicateddatabases. This is illustrated for both unstructured and logically structured replicateddatabases. Previous work on reconfiguration was mainly concerned with changes within aparticular replica management protocol. The authors extend this approach to applyreconfiguration from one protocol to another. A generalized reconfiguration mechanism isproposed for designing large and scalable distributed databases. Reconfiguration not onlyensures a high degree of fault-tolerance but also provides high performance. Finally; thegeneralized reconfiguration mechanism can be used by the database designers todynamically adapt database performance and availability to changing application needsand underlying network conditions.,System Sciences; 1994. Proceedings of the Twenty-Seventh Hawaii International Conference on,1994,1
Failure Handling in large scale workflow management systems,M Kamath; D Agrawal; A El Abbadi; R Gunthor; C Mohan,*,*,1994,1
An efficient; fault-tolerant protocol for replicated data management,Dale Skeen; Amr El Abbadi; Flaviu Cristian,Abstract A data management protocol for executing transactions on a replicated database ispresented. The protocol ensures one-copy serializability. ie; the concurrent execution oftransactions on a replicated database is equivalent to some serial execution of the sametransactions on a non-replicated database. The protocol tolerates a large class of failures;including: processor and communication link crashes; partitioning of the communicationnetwork; lost messages; and slow responses of processors and communication links.Processor and link recoveries are also handled. The protocol implements the reading of areplicated object efficiently by reading the nearest available copy of the object. When readsoutnumber writes; the protocol performs better than other known protocols.,*,1990,1
Hardware acceleration for database systems using content addressable memories,Nagender Bandi; Sam Schneider; Divyakant Agrawal; Amr El Abbadi,Page 1. DaMoN 2005 Hardware Acceleration for Database Systems using Content AddressableMemories Nagender Bandi; Sam Schneider; Divyakant Agrawal; Amr El Abbadi University ofCalifornia; Santa Barbara Page 2. DaMoN 2005 Overview • The “Memory Bottleneck” What isit? How does the Memory Bottleneck effect Database Performance? • Networking hardware -Can CAM-technology help? Content Addressable Memories (CAMs) • CAM-Cache ArchitectureDatabase equi-join • Concluding Remarks Page 3. DaMoN 2005 The “Memory Bottleneck” CPUspeed increases about 70% each year Memory speed has increased about 50% over the lastdecade Memory is increasingly becoming a performance bottleneck Solution: “Memory Hierarchy”Faster; smaller and more expensive memories (caches) Data kept near CPU Smaller latencyPage 4. DaMoN 2005 The “Memory Bottleneck” But …,DAMON 2005,*,1
TWIX: Approximate and Exact Twig Structure and Content Matching over XML Document Collections using Binary Labeling,S Alireza Aghili; Hua-Gang Li; Divyakant Agrawal; Amr El Abbadi,Abstract XML queries specify predicates on the content and the structure of the elements oftree-structured XML documents. Hence; discovering the occurrences of twig (tree structure)query patterns is a core operation for XML query processing. Prior works have typicallyapplied top-down decomposition of the twig patterns into (i) binary (parent-child or ancestor-descendant) relationships; or (ii) path expression queries; followed by a join operation toreconstruct matched twig patterns. However; most of these methods (i) rely on the user'sknowledge of the underlying database to pose well-formed queries; and (ii) suffer frominspecting too many irrelevant results. In this paper; we propose a novel heuristic formatching of XML twig query patterns; named TWIX; which imposed minimal restrictions onthe user and causes substantial reduction of the search space through a distributed …,University of California; Santa Barbara,*,1
Janus: A Hybrid Scalable Multi-Representation Cloud Datastore,Vaibhav Arora; Faisal Nawab; Divyakant Agrawal; Amr El Abbadi,Cloud-based data-intensive applications have to process high volumes of transactional andanalytical requests on large-scale data. Businesses base their decisions on the results ofanalytical requests; creating a need for real-time analytical processing. We propose Janus; ahybrid scalable cloud datastore; which enables the efficient execution of diverse workloadsby storing data in different representations. Janus manages big datasets in the context ofdatacenters; thus supporting scaling out by partitioning the data across multiple servers. Thisrequires Janus to efficiently support distributed transactions. In order to support the differentdatacenter requirements; Janus also allows diverse partitioning strategies for the differentrepresentations. Janus proposes a novel data movement pipeline to continuously ensure upto date data between the different representations. Unlike existing multi-representation …,IEEE Transactions on Knowledge and Data Engineering,2017,*
LocBorg: Hiding Social Media User Location while Maintaining Online Persona,Victor Zakhary; Cetin Sahin; Theodore Georgiou; Amr El Abbadi,Abstract Social media streams analysis can reveal the characteristics of people who engagewith or write about different topics. Recent works show that it is possible to reveal sensitiveattributes (eg; location; gender; ethnicity; political views; etc.) of individuals by analyzingtheir social media streams. Although; the prediction of a user's sensitive attributes can beused to enhance the user experience in social media; revealing some attributes like thelocation could represent a threat on individuals. Users can obfuscate their location byposting about random topics linked to different locations. However; posting about randomand sometimes contradictory topics that are not aligned with a user's online persona andposts could negatively affect the followers interested in her profile. This paper represents ourvision about the future of user privacy on social media. Users can locally deploy a cyborg …,Proceedings of the 25th ACM SIGSPATIAL International Conference on Advances in Geographic Information Systems,2017,*
Privacy-Preserving Community-Aware Trending Topic Detection in Online Social Media,Theodore Georgiou; Amr El Abbadi; Xifeng Yan,Abstract Trending Topic Detection has been one of the most popular methods to summarizewhat happens in the real world through the analysis and summarization of social mediacontent. However; as trending topic extraction algorithms become more sophisticated andreport additional information like the characteristics of users that participate in a trend;significant and novel privacy issues arise. We introduce a statistical attack to infer sensitiveattributes of Online Social Networks users that utilizes such reported community-awaretrending topics. Additionally; we provide an algorithmic methodology that alters an existingcommunity-aware trending topic algorithm so that it can preserve the privacy of the involvedusers while still reporting topics with a satisfactory level of utility.,IFIP Annual Conference on Data and Applications Security and Privacy,2017,*
Leader or Majority: Why have one when you can have both? Improving Read Scalability in Raft-like consensus protocols,Vaibhav Arora; Tanuj Mittal; Divyakant Agrawal; Amr El Abbadi; Xun Xue; Zhiyanan Zhiyanan; Zhujianfeng Zhujianfeng,Abstract: Consensus protocols are used to provide consistency guarantees over replicateddata in a distributed system; and allow a set of replicas to work together as a coherent group.Raft is a consensus protocol that is designed to be easy to understand and implement. It isequivalent to Multi-Paxos in fault-tolerance and performance. It uses a leader basedapproach for coordinating replication to a majority. The leader regularly informs the followersof its existence using heartbeats. All reads and writes go through the leader to ensure strongconsistency. However; read-heavy workloads increase load on the leader since thefollowers in Raft are maintained as cold standbys. Since the algorithm itself guaranteesreplication to at least a majority; why not exploit this fact to serve strongly consistent readswithout a leader? We propose mechanisms to use quorum reads in Raft to offload the …,Proceedings of the 9th USENIX Conference on Hot Topics in Cloud Computing,2017,*
Typhon: Consistency Semantics for Multi-Representation Data Processing,Vaibhav Arora; Faisal Nawab; Divyakant Agrawal; Amr El Abbadi,Variety of data has led to the fall of the" One size fits all" paradigm in databases. Applicationsnow store data in multiple data representations; rather than just storing the data in a singlerelational database. However; applications only provide consistency semantics at theboundaries of a single datastore; corresponding to specific representation. This can lead tosemantically inconsistent executions; which can have undesirable consequences for theapplication users. We propose; Typhon; a multi-representation data processing framework;which defines consistency semantics across multiple representations. Typhon introduces thenotion of entities; which link the data present in diverse representations; and defines implicitcausal guarantees; which capture the logical order intended by the application user. Typhonlays the foundation of a consistency model for multi-representation data; over which …,Cloud Computing (CLOUD); 2017 IEEE 10th International Conference on,2017,*
Understanding the security challenges of oblivious cloud storage with asynchronous accesses,Cetin Sahin; Aaron Magat; Victor Zakhary; Amr El Abbadi; Huijia Lin; Stefano Tessaro,This demonstration introduces the database community to state-of-the-art cryptographicmethods that ensure efficient oblivious access to cloud data. In particular; we exploreoblivious storage systems which hide both the content of data and data access patterns froman untrusted cloud provider. The demo considers the popular and realistic setting wheremultiple users from a trusted group asynchronously access and edit potentially overlappingdata sets through a trusted proxy. We present a detailed implementation of TaoStore (Sahinet al.; S&P 2016); a new tree-based ORAM scheme that processes client requestsconcurrently and asynchronously in a non-blocking fashion; resulting in substantial gains inthroughput; simplicity; and flexibility over previous systems. The demo is presented in thecontext of a pedagogical game; Guess the Access; which allows participants to play as an …,Data Engineering (ICDE); 2017 IEEE 33rd International Conference on,2017,*
Towards Practical Privacy-Preserving Life Cycle Assessment Computations,Cetin Sahin; Brandon Kuczenski; Omer Egecioglu; Amr El Abbadi,Abstract Life Cycle Assessment (LCA) is crucial for evaluating the ecological sustainability ofa product or service; and the accurate evaluation of sustainability requires detailed andtransparent information about industrial activities. However; such information is usuallyconsidered confidential and withheld from the public. In this paper; we present a rigorousstudy of privacy in the context of LCA. The main goal is to explore the privacy challenges insustainability assessment considering the protection of trade secrets while increasingtransparency of industrial activities. To overcome privacy concerns; we apply differentialprivacy to LCA computations considering the idiosyncratic features of LCA data. Ourassessments on a specific real-life example show that it is possible to achieve privacy-preserving LCA computations without losing the utility of data completely.,Proceedings of the Seventh ACM on Conference on Data and Application Security and Privacy,2017,*
Data Security and Privacy for Outsourced Data In the Cloud.,Cetin Sahin; Amr El Abbadi,ABSTRACT Although outsourcing data to cloud storage has become popular; the increasingconcerns about data security and privacy in the cloud blocks broader cloud adoption.Ensuring data security and privacy; therefore; is crucial for better and broader adoption ofthe cloud. This tutorial provides a comprehensive analysis of the state-of-the-art in thecontext of data security and privacy for outsourced data. We aim to cover common securityand privacy threats for outsourced data; and relevant novel schemes and techniques withtheir design choices regarding security; privacy; functionality; and performance. Our explicitfocus is on recent schemes from both the database and the cryptography and securitycommunities that enable query processing over encrypted data and access oblivious cloudstorage systems.,EDBT,2017,*
COP: Planning Conflicts for Faster Parallel Transactional Machine Learning.,Faisal Nawab; Divy Agrawal; Amr El Abbadi; Sanjay Chawla,ABSTRACT Machine learning techniques are essential to extracting knowledge from data.The volume of data encourages the use of parallelization techniques to extract knowledgefaster. However; schemes to parallelize machine learning tasks face the trade-off betweenobeying strict consistency constraints and performance. Existing consistency schemesrequire expensive coordination between worker threads to detect conflicts; leading to poorperformance. In this work; we consider the problem of improving the performance of multi-core machine learning while preserving strong consistency guarantees. We propose ConflictOrder Planning (COP); a consistency scheme that exploits special properties of machinelearning workloads to reduce the overhead of coordination. What is special about machinelearning workloads is that the dataset is often known prior to the execution of the machine …,EDBT,2017,*
2014 Index IEEE Transactions on Mobile Computing Vol. 13,BH Abay; Amr El Abbadi; T Abdelzaher; Z Abichar; K Abrougui; NB Abu-Ghazaleh; Onur Aciicmez; H Adam; Divyakant Agrawal; ME Ahmed; J Ahn; Attahiru S Alfa; Giusi Alfano; ST Ali; T Ali; K Almeroth; M Almulla; Basel Alomair; M Alouini; M Alves; MH Amerimehr,This index covers all technical items-papers; correspondence; reviews; etc.-that appeared inthis periodical during the year; and items from previous years that were commented upon orcorrected in this year. Departments and other items may also be covered if they have beenjudged to have archival value. The Author Index contains the primary entry for each item;listed under the first author's name. The primary entry includes the co-authors' names; thetitle of the paper or other item; and its location; specified by the publication abbreviation;year; month; and inclusive pagination. The Subject Index contains entries describing theitem under all appropriate subject headings; plus the first author's name; the publicationabbreviation; month; and year; and inclusive pages. Note that the item title is found onlyunder the primary entry in the Author Index.,IEEE Transactions on Mobile Computing,2015,*
Exploiting Diversification in Distributed Recommendation,Maximilien Servajean; Esther Pacitti; Miguel Liroz-Gistau; Sihem Amer-Yahia; Amr El Abbadi,Les utilisateurs du Web 2.0 sont de gros producteurs de données. Ces dernières sontstockées sur des systèmes très variés; allant des plateformes de partage aux réseauxsociaux. Le fait que l'espace de stockage soit distribué sur ces nombreuses et diversesplateformes rend le partage des données particulièrement difficile. Dans ce contexte dedistribution a grande echelle des utilisateurs et des données; une solution pour le partagede ces dernières est offerte par la recherche et recommandation distribuée. En particulier;les approches à base de bavardages (ie gossip) offrent le passage à l'échelle; ladynamicité; l'autonomie et un contrôle décentralisé. Généralement; dans la recherche etrecommandation à base de bavardages; chaque utilisateur s' emploie a construire uncluster des utilisateurs" pertinents" qui seront utilisés ultérieurement pour traiter les …,BDA: Bases de Données Avancées,2014,*
A Shared Log Storage for Applications Running on the Cloud,Faisal Nawab; Vaibhav Arora; Divyakant Agrawal; Amr El Abbadi,Abstract—Web applications are facing unprecedented demand with users issuing millions ofrequests per second. The developer needs to scale the application to this demand whileproviding fault-tolerance and availability. This process is error-prone and need expertise thatis not necessarily part of the arsenal of a web developer. The cloud platform attracted manydevelopers for its scalability and availability guarantees. Here; we propose a distributed logstore (FLStore) that bridges the gap between the developer and the cloud. This is done byexposing a simple interface (ie; the log) that is scalable; available; and faulttolerant. Thedeveloper uses a specific API to issue read and append operations which allows buildingcomplex applications without worrying about answering the question of scalability. FLStoreis designed to be fully distributed to allow the maximum possible scalability.,GSWC 2014,2014,*
Mass-storage secure portable tokens are emerging and provide a real breakthrough in the management of sensitive data. They can embed personal data and/or met...,Elena Ferrari; Murat Kantarcioglu; Madhushri Banerjee; Zhiyuan Chen; Aryya Gangopadhyay; Shiyuan Wang; Divyakant Agrawal; Amr El Abbadi,It is often necessary for organizations to perform data mining tasks collaboratively withoutgiving up their own data. This necessity has led to the development of privacy preservingdistributed data mining. Several protocols exist which deal with data mining methods in adistributed scenario but most of these methods handle a single data mining task. Therefore;if the participating parties are interested...,Distributed and Parallel Databases,2014,*
Profile Diversity for P2P Search and Recommendation,Maximilien Servajean; Esther Pacitti; Sihem Amer-Yahia; Amr El Abbadi; Pascal Neveu,We investigate profile diversity for P2P search and recommendation of scientific documents.In scientific domains; endorsements from different communities are important indicators ofthe broad focus of scientific documents and should be accounted for in search andrecommendation. To do so; we introduce profile diversity; a novel idea in searching scientificdocuments. Traditional content diversity has been thoroughly studied in centralized searchand advertising; database queries; and recommendations and addresses the question ofreturning relevant but too-similar documents. We argue that content diversity alone does notsuffice for finding documents endorsed by different scientific communities and that profilediversity is needed to alleviate returning popular but too-focused documents. Moreover; P2Pprofile diversity increases recall and reduces the search space compared with a …,*,2013,*
Exotica/FMQM: A Persistent,D Agrawal; A El Abbadi,Abstract In the past few years there has been an increasing interest in workflow applicationsas a way of supporting complex business processes in modern corporations. Given thenature of the environment and the technology involved; workflow applications are inherentlydistributed and pose many interesting challenges to the system designer. In most cases; aclient/server architecture is used in which knowledge about the processes being executed iscentralized in one node to facilitate monitoring; auditing; and to simplify synchronization. Inthis paper; we explore a novel distributed architecture; Exotica/FMQM; for workflow systemsin which the need for such a centralized database is eliminated. Instead; we use persistentmessages as the means to store the information relevant to the execution of a businessprocess. Our approach is to completely distribute the execution of a process so individual …,Information Systems Development for Decentralized Organizations: Proceedings of the IFIP working conference on information systems development for decentralized organizations; 1995,2013,*
Workshop Report: ElaStraS-An Elastic Transactional Datastore in the Cloud,Sudipto Das; Divyakant Agrawal; Amr El Abbadi,This report elaborates and discusses the paper” ElaStraS-An Elastic TransactionalDatastore in the Cloud”[1]. Some information goes beyond the scope of the paper itself.These Sections are referenced at the end. Some parts of the discussion in Section 4 alsoreflect the discussion had at the end of my talk.,*,2013,*
ImmuNet: Improved immunization of children through cellular network technology,Mariya Zheleva; Ceren Budak; Arghyadip Paul; Biyang Liu; Elizabeth M Belding; Amr El Abbadi,Abstract—Vaccination distribution and tracking; especially in remote areas in the developingworld; is an important problem that can benefit from recent technological improvements inattaining more effective distribution mechanisms. In this paper we describe ImmuNet; asystem that utilizes cellular network technology and allows rapid determination of immunestatus; reliable updates of vaccination records and quick targeted dissemination ofvaccination availability in rural areas. In Summer 2012 our research team traveled for threeweeks to the rural village of Macha; Zambia to deploy one of ImmuNet's modules and also toconduct interviews to gain understanding for immunization practices in remote rural areas.,GSWC 2012,2012,*
Highlights from ACM SIGSPATIAL GIS 2010: The 18th ACM SIGSPATIAL International Conference on Advances in Geographic Information Systems (San Jose; Calif...,Amr El Abbadi; Mohamed F Mokbel,Abstract ACM GIS 2010 was the eighteenth event of a series of conferences; symposia; andworkshops that began in 1993 with the mission of bringing together researchers;developers; users; and practitioners carrying out research and development of novelsystems based on geo-spatial data and knowledge. The conference fosters interdisciplinarydiscussions and research in all aspects of Geographic Information Systems and Science(GIS) and provides a forum for original research contributions covering all conceptual;design; and implementation aspects of GIS ranging from applications; user interfaceconsiderations; and visualization to storage management; indexing; and algorithmic issues.,SIGSPATIAL Special,2011,*
ACM Fellows honored,CACM Staff,The ACM Fellow Program was established by Council in 1993 to recognize and honoroutstanding ACM members for their achievements in computer science and informationtechnology and for their significant contributions to the mission of the ACM. The ACMFellows serve as distinguished colleagues to whom ACM and its members look for guidanceand leadership as the world of information technology evolves.The ACM Council endorsedthe establishment of a Fellows Program and provided guidance to the ACM FellowsCommittee; taking the view that the program represents a concrete benefit to which any ACMmember might aspire; and provides an important source of role models for existing andprospective ACM Members. The program is managed by the ACM Fellows Committee aspart of the general ACM Awards program administered by Calvin C. Gotlieb and James J …,Communications of the ACM,2011,*
GIS: Proceedings of the ACM International Symposium on Advances in Geographic Information Systems: Preface,Amr El Abbadi; Mohamed F Mokbel,Skip to main content Experts@Minnesota Logo …,Unknown Journal,2010,*
Connectors; Mavens; Salesmen and Translators of the Blogosphere,Ceren Budak; Divyakant Agrawal; Amr El Abbadi,Choosing the right set of people to first influence on a new idea to maximize the spread ofinfluence in social networks is a computationally expensive problem. Lately there have beenvarious optimization algorithms and models of communication introduced to tackle thatproblem. However; the scalability issues; the validity of these models and their robustness tosmall errors in the parameters of the models are unanswered problems that warrant theneed to identify simpler methods to serve the same purpose. In a recent work; Gladwellidentifies three types of important people that he claims make an idea tip and uses a smallnumber of success cases such as the sudden popularity of the Hush Puppies to support hisideas. We investigate the possible effectiveness of the three heuristics introduced in [2]; aswell as another heuristic that we call translators in a much larger scale.,GSWC 2010,2010,*
Generalized Private Querying on Public Data in Single Client-Server Settings,Shiyuan Wang; Divyakant Agrawal; Amr El Abbadi,ABSTRACT We consider the problem of general private queries on public data in singleclient server interactions; where a client executes queries on the server but does not want toreveal the query to the server. We propose a generalized private querying protocol calledBounding-Box PIR (bbPIR) which is practical and can be applied in large scale informationservices while permitting clients to specify the privacy level and private service chargebudget they desire.,GSWC 2009,2009,*
Hierarchical result views for keyword queries over relational databases,Shiyuan Wang; Junichi Tatemura; Arsany Sawires; Oliver Po; Divyakant Agrawal; Amr El Abbadi,Abstract Enabling keyword queries over relational databases (KQDB) benefits a largepopulation of users who have difficulty in understanding the database schema or usingSQLs. However; since there are different interpretations for a query; the results of KQDB thatmix different possible answers still make it hard for users to consume and extract theinformation that is interesting to them. To help users with different preferences understandthe query results and quickly locate the desired information; this paper proposes generatingeasy-to-navigate hierarchical result views for each interpretation to the query on the fly. Wedefine the structures for organizing these hierarchical views; provide metrics for evaluatingthem in terms of user navigation efforts; and develop an efficient algorithm for generating theview structures. The effectiveness and efficiency of the proposed approaches are verified …,Proceedings of the First International Workshop on Keyword Search on Structured Data,2009,*
CANDIDATE FOR ACM SIGMOD CHAIRPERSON,AMR EL ABBADI,• Assistant; Associate and Professor; Univ. of California; Santa Barbara; 1987-present • Chairof Computer Science Department; Univ of California; Santa Barbara; 2007--present •Director; Univ of Calif; Education Abroad Program; American University in Cairo; Egypt; 2002– 2003. • PhD; Department of Computer Science; Cornell University; 1987 … DataManagement; Distributed Information Systems; Data Stream; Digital Libraries; Data Privacy;Fault-tolerance; Hardware support for Databases … • ACM Distinguished Lecturer; DistinguishedSpeakers Program; 1991 – 1992. • Group Leader; SIGMOD Conference; 2005. • Program CommitteeMember; ICDE; ICDT; EDBT; PODS; SIGMOD; ACM GIS etc.; Many years … • Board ofTrustees; VLDB Endowment; 2002-2008. • Associate Editor; Information Systems; 1994 – 2001• Editor for Information Processing letters 1998-2002. • Americas Program Chair; Very …,SIGMOD Record,2009,*
Fraud; Anonymization; and Privacy in the Internet: A Database Perspective.,Divyakant Agrawal; Amr El Abbadi,Data is everywhere; and manifests itself in various formats. Data can be publicly availableand can be privately owned. Data can be persistent on a server or ephemeral in a datastream. Society depends on data and hence the security; privacy and reliability of the dataare critical in diverse ways. In this talk I will touch on various security aspects of data indifferent contexts that arise in diverse internet applications.,COMAD,2009,*
Environmental Tomography,Stacy Patterson; Bassam Bamieh; Amr El Abbadi,Mobile phones are ubiquitous computing devices. If these devices are coupled with sensors;they can provide a powerful computing platform for large-scale sensing applications.Phones can be equipped with sensors that measure the quantity of harmful pollutants suchas sulfur dioxide or contaminants such as radiation; and the sensor readings acquired fromthese devices can be used to detect and monitor the levels of these harmful substances inpopulated areas. Since modern mobile phones are GPS-enabled; it is possible to record notonly the concentration of the sensed phenomenon; but also the exact location of the sensorreading. This location information opens the door for the creation of detailed spatial modelsof the physical data distribution. However; the mobile computing platform also presentsseveral challenges. Mobile devices have limited power and storage capacities; and users …,The Second Annual Graduate Student Workshop on Computing,2007,*
PULSTORE.: Automated Storage Management with QoS Guarantee in,Balakrishna R Iyer; Divyakant Agrawal; Amr El Abbadi,Google; Inc. (search). SIGN IN SIGN UP.,Proceedings of the Second International Conference on Automatic Computing,2005,*
STORAGEDB: enhancing the storage sub-system with DBMS functionalities,Lin Qiao; Balakrishna R Iyer; Divyakant Agrawal; Amr El Abbadi; Sandeep Uttamchandani,This paper proposes STORAGEDB; a paradigm for implementing storage virtualizationusing databases. It describes details for storing the logical-to-physical mapping informationas tables within the database; handling the incoming I/O requests of the application asdatabase queries; bookkeeping of the I/O operations as database transactions. In addition;STORAGEDB uses built-in DBMS features to support storage virtualization functionalities; asan example we describe how online table space migration can be used to supportreallocation of logical disks. Finally; we describe our modifications to a traditional RDBMSimplementation; in order to make it light-weight. Improving the performance of a traditionalDBMS is critical for the acceptance of STORAGEDB since the performance overheads areconsidered a primary challenge in replacing existing storage virtualization engines. Our …,Mass Storage Systems and Technologies; 2005. Proceedings. 22nd IEEE/13th NASA Goddard Conference on,2005,*
Dynamic Multidimensional Data Cubes for Interactive Analysis of Massive Datasets,Mirek Riedewald; Divyakant Agrawal,Abstract Rapidly improving computing and networking technology enables enterprises tocollect data from virtually all its business units. The main challenge today is to extract usefulinformation from an overwhelmingly large amount of raw data. To support complex analysisqueries; data warehouses were introduced. They manage data; which is extracted from thedifferent operational databases and from external data sources; and they are optimized forfast query processing. For modern data warehouses; it is common to manage Terabytes ofdata. According to a recent survey by the Winter Corporation (2003); for instance; thedecision support database of SBC reached a size of almost 25 Terabytes; up from 10.5Terabytes in 2001 (Winter Corporation; 2001).,*,2005,*
New Hardware Support for Database Operations.,Nagender Bandi; Chengyu Sun; Hailing Yu; Divyakant Agrawal; Amr El Abbadi,Abstract Query processing cost in database applications can be divided into two parts: theI/O cost and the computational cost. Traditionally DBMS researchers have focused on theissue of reducing the I/O cost as it is the primary source of bottleneck in most of the databaseoperations. As the computer systems which run the DBMSs evolved; this problem worsenedbecause the speeds of secondary storage devices increased at a much slower pacecompared to the memory access and processing speeds. Further; as databases becomeincreasingly accepted in areas such as spatial databases; we encounter new challenges.For example; the computational cost has been known to be the bottleneck in certain spatialoperations. In this paper; we present a survey of our work where we present novel solutionswhich use hardware to alleviate the I/O cost bottleneck for traditional database …,IEEE Data Eng. Bull.,2005,*
Reminiscences on influential papers,Kenneth A Ross,This paper abstracts from the particular features of PRISMA/DB; and evaluates and analyzesthe performance trade-offs for a wide range of parallel query processing strategies. Its clearstyle of presentation; along with careful attention to previous work both in its discussion aswell as in the experiments and analysis; make this paper into a concise introductory or“refereshment” text for researchers interested in parallel query execution.,ACM SIGMOD Record,2004,*
VITA OF RAJENDRA KUMAR BOSE September 2004 EDUCATION Bachelor of Engineering in Electrical Engineering (with Honor); The Stevens Institute of Technol...,Rajendra Kumar Bose; James Frew; David Siegel; Amr El Abbadi,*,EDUCATION,2004,*
Industrial and Applications Sessions,Andreas Behm; Serge Rielau; Richard Swagerman; Conor Cunningham; Cesar Galindo-Legaria; Goetz Graefe; Walid Rjaibi; Paul Bird; Nagender Bandi; Chengyu Sun; Divyakant Agrawal; Amr El Abbadi; Sang K Cha; Changbin Song; Meikel Poess; John M Stephens Jr; Souripriya Das; Eugene Chong; George Eadon; Jagannathan Srinivasan; Sougata Mukherjea; Bhuvan Bamba; Nick Koudas; Amit Marathe; Divesh Srivastava; Benoit Dageville; Dinesh Das; Karl Dias; Khaled Yagoub; Mohamed Zait; Mohamed Ziauddin; Sanjay Agrawal; Surajit Chaudhuri; Lubor Kollar; Arun Marathe; Vivek Narasayya; Manoj Syamala; Muralidhar Krishnaprasad; Zhen Liu; Anand Manikutty; James W Warner; Vikas Arora; Susan Kotsovolos; Shankar Pal; Istvan Cseri; Oliver Seeliger; Gideon Schaller; Leo Giakoumakis; Vasili Zolotov; Ashraf Aboulnaga; Peter Haas; Mokhtar Kandil; Sam Lightstone; Guy Lohman; Volker Markl; Ivan Popivanov; Vijayshankar Raman; Marcus Fontoura; Eugene Shekita; Jason Zien; Sridhar Rajagopalan; Andreas Neumann; Bishwaranjan Bhattacharjee; Christof Bornhövd; Tao Lin; Stephan Haller; Joachim Schaper; Managing RDFI Data; Sudarshan S Chawathe; Venkat Krishnamurthyy; Sridhar Ramachandran; David Campbell; Toby Bloom; Ted Sharpe; Rakesh Nagarajan; Mushtaq Ahmed; Aditya Phatak; Raymie Stata; Patrick Hunt; William O'Connell; Ramesh Bhashyam; Roger MacNicol; Blaine French,PIVOT and UNPIVOT: Optimization and Execution Strategies in an RDBMS ConorCunningham; Cesar Galindo-Legaria; Goetz Graefe (Microsoft Corp.) … P*TIME: Highly ScalableOLTP DBMS for Managing Update-Intensive Stream Workload Sang K. Cha (Transact InMemory; Inc); Changbin Song (Seoul National Univ.) … Supporting Ontology-based SemanticMatching in RDBMS Souripriya Das; Eugene Chong; George Eadon; Jagannathan Srinivasan(Oracle Corp.) … Automatic SQL Tuning in Oracle 10g Benoit Dageville; Dinesh Das; KarlDias; Khaled Yagoub; Mohamed Zait; Mohamed Ziauddin (Oracle Corp.) … Database TuningAdvisor for Microsoft SQL Server 2005 Sanjay Agrawal; Surajit Chaudhuri; Lubor Kollar; ArunMarathe; Vivek Narasayya; Manoj Syamala (Microsoft Corp.) … Query Rewrite for XML in OracleXML DB Muralidhar Krishnaprasad; Zhen Liu; Anand Manikutty; James W. Warner; Vikas …,Proceedings of the Thirtieth International Conference on Very Large Data Bases: Toronto; Canada; August 31-September 3; 2004,2004,*
1 University of California Santa Barbara; CA 93106; USA,Hua-Gang Li; Divyakant Agrawal; Amr El Abbadi; Mirek Riedewald,*,Advances in Spatial and Temporal Databases: 8th International Symposium; SSTD 2003; Santorini Island; Greece; July 24-27; 2003. Proceedings,2003,*
Modeling and Maintaining Multi-View Data,I Stanoi; D Agrawal; A El Abbadi,Abstract. Data warehouses are designed mostly as centralized systems; and the majority ofupdate maintenance algorithms are tailored for this specific model. Maintenance methodshave been proposed either under the assumption of a single view data warehouse; a multi-view centralized model; or a multi-view distributed system with strict synchronizationrestrictions. We argue that extending this model to a multi-view distributed one; is a practicalgeneralization of the data warehouse system; and the basis for a growing number ofapplications based on the idea of cooperative views. In this paper we develop a generalframework for modeling the maintenance of multi-views in a distributed; decentralized datawarehouse; together with an efficient incremental algorithm for view maintenance. To ourknowledge; there is no other proposal for a method that incorporates individually and …,Conceptual Modeling ER'99: 18th International Conference on Conceptual Modeling Paris; France; November 15-18; 1999 Proceedings,2003,*
On the Importance of Tuning in Incremental,K O'Gorman; D Agrawal; A El Abbadi,Abstract. We describe the tuning of a gigabyte-scale TPC-D database for investigation ofincremental maintenance of a materialized view. We find that incremental maintenance isfeasible over a wide range of update sizes (granularities); that intuitive SQL formulationsperform poorly; but that there are better alternatives. We show that these results can bemeaningfully evaluated and presented only in the context of reasonable instance tuning.,Data Warehousing and Knowledge Discovery: Second International Conference; DaWaK 2000 London; UK; September 4-6; 2000 Proceedings,2003,*
Reminiscences on influential papers,A El Abbadi,*,*,2002,*
M ultiple Query Optim ization by Cache-Aware,K O'Gorman; D Agrawal; A El Abbadi,*,*,2002,*
Managing and analyzing massive data sets with data cubes,Mirek Riedewald; Divyakant Agrawal; Amr El Abbadi,Abstract Data cubes combine an easy-to-understand conceptual model with animplementation that enables the fast summarization of large data sets. This makes them apowerful tool for supporting the interactive analysis of massive data collections like datawarehouses and digital libraries. This article surveys some of the recent developments indata cube research. We mainly focus on techniques for fast aggregation in datawarehousing environments. This includes work on group-by and range queries;approximate query responses; and compression. Since sparse high-dimensional data cubesare of increasing interest; issues related to them are explicitly discussed.,*,2002,*
View maintenance and analytical processing at data warehouses,Divyakant Agrawa; Amr El Abbadi,Abstract In this paper; we describe techniques that can be used to incorporate updates at adata warehouse on-the-fly. An incremental view maintenance algorithm is described thatincorporates updates from datasources at a dynamic data warehouse. Similarly; partitioningand recursive decomposition techniques are described that allowe efficient querying andupdating of summary data at the warehouse for analytical processing.,International Workshop on Databases in Networked Information Systems,2000,*
The Iterative Data Cube,Mirek Riedewald; Divyakant Agrawal; Amr El Abbadi,Abstract. Data cubes provide aggregate information to support the analysis of the contents ofdata warehouses and databases. An important tool to analyze data in data cubes is therange query. For range queries that summarize large regions of massive data cubes;computing the query result on-the-y can result in non-interactive response times (eg in theorder of minutes). To speed up range queries; values that summarize regions of the datacube are pre-computed and stored. This faster response time results in more expensiveupdates and/or space overhead. In this paper a technique is presented that generates a newclass of schemes that support range queries on data cubes {Iterative Data Cubes. The mainidea is that techniques that provide a certain tradeo of query and update costs for a one-dimensional data cube are applied iteratively along the dimensions of data cubes of …,University of California; Santa Barbara; Computer Science Technical Report,2000,*
Session V: Coping with Movement-Storage and Retrieval of Moving Objects,Hae Don Chon; Divyakant Agrawal; Amr El Abbadi,*,Lecture Notes in Computer Science,2000,*
Technical Report TRCS99-32 Epidemic Quorums for Managing Replicated Data,JoAnne Holliday; Robert Steinke; Divyakant Agrawal; Amr El Abbadi,Abstract In the epidemic model an update is initiated on a single site; and is propagated toother sites in a lazy manner. When combined with version vectors and event logs; thispropagation mechanism delivers updates in causal order despite communication failures.We integrate quorums into the epidemic model to processes transactions on replicated data.Causal order helps establish the global serialization order on transactions. Our approachenforces serializability by aborting transactions that may cause inconsistency. In theabsence of con ict a transaction can commit as soon as it is known to a quorum of sites. Inthe presence of con ict; sites vote and a transaction can commit as soon as a quorum of sitesvote for it. We present a detailed simulation study of a distributed replicated database anddemonstrate the performance improvements.,*,1999,*
View Derivation Graph with Edge Fitting for Data Warehousing in Disconnected Environments,I Stanoi; D Agrawal; AE Abbadi,Abstract Data warehouse views cache summarized information from queries over one ormultiple distributed base sources. In this paper; we address the problem of data warehousemaintenance in an environment where base source data can be stored on mobile devices.The requirements of a partially disconnected world lead to significant tradeoffs between theview update cost on one hand; and the level of freshness of the view on the other hand.Current decentralized maintenance methods that can be applied to a disconnectedenvironment involve either replicating of source data at the view; or computing view updatesthrough queries to all base sources. Replication may involve excessive storage overhead;while view update may be blocked due to the disconnection of any of the base sources. Wepropose a view maintenance approach that stores path information corresponding to data …,*,1999,*
Posse: A Fram ework for Optim izing Increm ental View,K O'Gorman; D Agrawal; A El Abbadi,*,*,1999,*
Concentric Hyperspaces and Disk Allocation for Fast Parallel Searching,Hakan Ferhatosmanoglu; Divyakanth Agrawal; Amr El Abbadi,Abstract Data partitioning and declustering have been extensively used in the past toparallelize I/O for range queries. Numerous declustering and disk allocation techniqueshave been proposed in the literature. However; most of these techniques were primarilydesigned for two-dimensional data and for balanced partitioning of the data space. Asdatabases increasingly integrate multimedia information in the form of image; video; andaudio data; it is necessary to extend the declustering techniques for multidimensional data.In this paper; we first establish that traditional declustering techniques do not scale for high-dimensional data. We then propose several new partitioning schemes based on concentrichyperspaces. We then develop disk allocation methods for each of the proposed schemes.We conclude with an evaluation of range queries based on these schemes and show that …,*,1999,*
Letter from the Special Issue Editor,Amr El  Abbadi,*,IEEE Data Engineering Bulletin,1999,*
Letter from the Special Issue Editor,Divyakant Agrawal; Amr El  Abbadi,Data replication is one of the oldest and most persistent topics of research in distributeddatabases. It holds the promise of solving both problems of fault-tolerance and performance.By replicating the data on remote sites; failures may occur and users may still be able toaccess data; alternatively; if a data item is replicated on a local or nearby site; accesses tothat copy are efficient and may involve very low overhead. To obtain these benefits;however; complex and expensive synchronization mechanisms are often needed tomaintain the consistency and integrity of data. In fact it has often been argued that due to thesynchronization overheads and the increased possibility of deadlock; replication isimpractical. Nevertheless; the appeal of replication persists and sometimes even migrates tocommercial industrial products. In this special issue various researchers and practitioners …,IEEE Data Eng. Bull.,1998,*
Transactional memories: A new abstraction for parallel processing,JH Fasel; OM Lubeck; D Agrawal; JL Bruno; A El Abbadi,Abstract This is the final report of a three-year; Laboratory Directed Research andDevelopment (LDRD) project at Los Alamos National Laboratory (LANL). Current distributedmemory multiprocessor computer systems make the development of parallel programsdifficult From a programmer's perspective; it would be most desirable if the underlyinghardware and software could provide the programming abstraction commonly referred to assequential consistency—a single address space and multiple threads; but enforcement ofsequential consistency limits opportunities for architectural and operating systemperformance optimizations; leading to poor performance. Recently; Herlihy and Moss haveintroduced a new abstraction called transactional memories for parallel programming. Theprogramming model is shared memory with multiple threads. However; data consistency …,*,1997,*
Iterated DFT based techniques for join size estimation,Kamil Sarac; Omer Egecioglu; Amr El Abbadi,*,*,1997,*
Java-based architecture for digital library data storage,Daniel Wu; Divyakant Agrawal; Amr El Abbadi; Ambuj K Singh,The Alexandria Digital Library Project has been tasked with the goal of building a digitalgeographical library. To meet these requirements we have designed and prototyped anintelligent data store to store its holdings; the library's map; image; and geographical dataare viewed as a collection of distributed objects. Developed suing the Java language; theData Store was designed to address the problems associated with digital library storage:interoperability; extensibility; distribution; and elimination of server bottlenecks.,Multimedia Storage and Archiving Systems,1996,*
Browsing and Placement of Multiresolution Images on Secondary Storage,Sunil Prabhakar Divyakant Agrawal Amr El; Abbadi Ambuj Singh Terence R Smith,Abstract With the rapid advances in computer and communication technologies; there is anincreasing demand to build and maintain large image repositories. In order to reduce thedemands on I/O and network resources; multiresolution representations of images are beingproposed for the storage organization of images. Image decomposition techniques such aswavelets can be used to provide multiple resolution images. The image is represented byseveral coe cients; one of them with visual similarity to the original image but at a lowerresolution. Thus; these visually similar coe cients can be thought of as the thumbnails oricons of the original image. This paper addresses the problem of storing thesemultiresolution coe cients on disk (s) so that thumbnail browsing as well as imagereconstruction can be performed e ciently. Several strategies are evaluated to store the …,*,1996,*
evi rs List,B Abali; AE Abbadi; T Abdelrahman; M Aboelaze; AA Abonamah; J Abraham; S Abraham; M Abramovici; ED Adamides; SV Adve; A Agarwal; VK Agarwal; T Agerwala; G Agha; D Agrawal; V Agrawal; HM Ahmed; I Ahmed; RE Ahmed; M Ahuja; T Akaike; SB Akers; S Al-Bassam; K Al-Tawil; MS Alam; S Albassam; NJ Alewine; G Alia; B Allegre; D Allison; H Alnuweiri; H Alnuweri; DB Alpert; B Alspach; J Alspector; N Amato; H Ammar; C Anderson; M Andrews; S Anik; S Anily; F Annexstein; J Antonio; S Aoki; J Apnes; C Aras; B Arden; K Arimoto; J Arlat; M Arnold; A Arora; T Asano; MJ Atallah; BE Aupperle; T Austin; D Avresky; E Ayguade; M Azimi; S Baden; J Bae; JL Baer; R Baeza-Yates; A Bagchi; D Baghcrzaolch; N Bagherzadeh; S Balakrishnan; PT Balsara; I Banerjee; S Banerjee; U Banerjee; HR Barada; RH Bardell; C Baru; R Barua; S Baruah; R Basri; M Bassiouni; S Basu; K Batcher; B Baum-Waidner; M Baumslag; R Bay; M Bayoumi; I Beame; B Becker; J Bennett; C Bergman; JC Bermond; E Bernard; S Bettayeb; UN Bhat; S Bhattacherya; L Bhuyan; RB Bianchini Jr; L Bit,*,IEEE Transactions on Computers,1996,*
Distributed access system for uniform and scalable data and service access,Anuradha Mahadevan Sastri; Divyakant Agrawal; Amr El Abbadi; Terence R Smith,Computational modeling systems (CMS) are designed to resolve many of the shortcomingsassociated with systems currently employed in providing support for a wide range ofscientific modeling applications. We identify the requirements of a" reasonable" CMS andidentify the requirements of Amazonia; a CMS intended to support modeling in large-scaleearth science research. Amazonia has been implemented as an open and layeredarchitecture. In this paper we discuss the design and implementation of the distributedaccess system; a key component of the Amazonia Kernel that supports the organization ofand access to data and services in a distributed environment.,Mass Storage Systems; 1995.'Storage-At the Forefront of Information Infrastructures'; Proceedings of the Fourteenth IEEE Symposium on,1995,*
rery iarge,P Constantopoulos; M Jarke; J Mylopoulos; Y Vassiliou; C Clifton; H Garcia-Molina; D Bloom; D Agrawal; A El Abbadi; R Jeffers; L Lin; A Dan; PS Yu; JY Chung,The Journal is a quarterly publication of the VLDB Endowment. As a database systemsjournal it is dedicated to the international publication of scholarly contributions to theadvancement of information system architectures; the impact of emerging technologies oninformation systems; and the development of novel applications. It presents significantadvances in the design; implementation; and evaluation of systems for databases and forother information collections. Its scope ranges from the development of special-purposehardware; the design of innovative software approaches; integrated system architectures;the design analysis and performance evaluation of systems to new techniques forpresenting and capturing information.,*,1995,*
Adaptive filtering and indexing for image databases [2420-02],AD Alexandrov; WY Ma; A El Abbadi; BS Manjunath,*,PROCEEDINGS-SPIE THE INTERNATIONAL SOCIETY FOR OPTICAL ENGINEERING,1995,*
Set-Serializability: A Formal Theory for Partitioned Data,Gustavo Alonso; Amr El Abbadi,High transaction throughput in a distributed database system can be achieved by increasingthe autonomy of each site. This can be achieved by making more data available locally. Oneway to ensure this is to partition data items in several subsets and allocate one subset toeach site. As long as a transaction can execute locally using the data items allocated to asingle site; it will not need to access data at other sites. An example of partitioned data is aticket reservation system in which instead of locating all the tickets for an event in one centralsite; they are divided into several lots and each lot is allocated to a site. In that way; sites canproceed locally without communication with the central site or with other sites; speeding upthe processing of transactions BGM92; GT92; SS90]. To guarantee correct executions;constraints must be imposed on the operations that can be executed in parallel over the …,*,1993,*
List of,Amr El Abbadi; Paul Abrahams; MA Deerfield; William Agresti; Mustaq Ahamad; Mohan Ahuja; H Alblas; Rajeev Alur; Allen Ambler; Paul E Ammann; Hany Ammar; MH Ammar; Makis Anagnostou; G Ander; Sergio Antoy; William Appelbe; Paul Attie; Giorgi Ausiello; Albert N Badre; BR Badrinath; Bill Bail; Mary Baker; Gianfranco Balbo; David Barstow; Sanjoy K Baruah; MA Bassiouni; S Batory; Bernd Baumgarten; Z Bavel; R Bayer; Valdis Berzins; Bharat Bhargava; Robert P Cook; Keith Cooper; Jim Bieman; James Cordy; Jonathan Billington; Dr Cornell; Kenneth Birman; Daniel Craigen; Peter Bishop; Alex Blakemore; Gregor V Bochmann; Hans-J Boehm; Grady Booch; Douglas C Daniels; Stephen Cha; CK Chang; N Botros; James Bouhana; Ajoy K Datta; Lionel Briand; Samuel Chanson; WP de Roever; Susan Brilliant; Yiwei Chen; JN Brinkkemper; Giorgio De Michelis; Ed Brinksma; Tom DeMarco; Stephen Brobst; David DeWitt; Sarah Brocklehurst; M Broy; Steven C Bruell; Horst Bunke; Richard B Bunt; EE Doberkat; W Biittner; Ugo Buy; E Jane Cameron; Javier Campos; Costas Courcoubetis; Giovanni Cantone; Susan Dart; Juan Antonio de la Puente; Fiorella De Cindio; Shun Yan Cheung,IEEE TRANSACTIONS ON SOFTWARE ENGINEERING; VOL. lX; NO. 12; DECEMBER 1992… A Abbadi; Amr El University of California; Santa Bar- bara Abrahams; Paul Deerfield; MAAgresti; William The MITRE Corporation Ahamad; Mustaq Georgia Institute of TechnologyAhuja; Mohan Ohio State University Alblas; H. University of Twente Alur; Rajeev ' Ambler; AllenUniversity of Kansas Ammann; Paul E. George Mason University Ammar; Hany West ViginiaUniversity Ammar; MH Georgia Institute of Technology Anagnostou; Makis University of TorontoAnder; G. Lakewood; CO Antoy; Sergio Portland State University Appelbe; William Georgia Instituteof Technology Attie; Paul University of Texas Ausiello; Giorgi Avrunin; George S … BBadre; Albert N. Georgia Institute of Technology Badrinath; BR Rutgers University Bail; Bill TheMITRE Corporation Baker; Mary University of California; Berkeley Balbo; Gianfranco …,IEEE TRANSACTIONS ON SOFTWARE ENGINEERING,1992,*
A Graph-based Model for Concurrency and Version Control in Geographic Information Systems Databases,Gustavo Alonso; Amr El Abbadi,*,*,1992,*
RFC 2608 Guttman; E.; Perkins; C.; Veizades; J.; Day; M.;``Service Location Protocol; Version 2''(June 1999).,N Abramson; Y Afek; E Gafni; KC Almeroth; Multicast Backbone; K Almeroth; M Ammar; PA Alsberg; JD Day; S Bajaj; L Breslau; D Estrin; K Fall; S Floyd; P Haldar; M Handley; A Helmy; J Heidemann; P Huang; S Kumar; S McCanne; R Rejaie; P Sharma; K Varadhan; Y Xu; H Yu; D Zappala; F Baskett; M Chandy; R Muntz; F Palacios; L Berger; DH Gan; G Swallow; P Pan; F Tommasi; S Molendini; NT Bhatti; RD Schlichting; KP Birman; M Hayden; O Ozkasap; Z Xiao; M Budiu; Y Minsky; R van Renesse; TA Joseph; T Raeuchle; AE Abbadi; B Cain; S Deering; I Kouvelas; A Thyagarajan; KM Chandy; EM Schooler; A Systematic Framework; J Misra; I Cidon; O Mokryn; D Farinacci; M Handley; V Jacobson; C Liu; P Sharma; D Thaler; L Wei; E Farinacci; V Jacobson; SE Deering; S Deering; L Esibov; B Aboba; D Thaler; C Liu; L Wei; A Helmy; K Windisch; W Fenner; C Fetzer; F Cristian; MJ Fischer; NA Lynch; MS Paterson; L Zhang; T Friedman; D Towsley; H Garcia-Molina; MR Garey; DS Johnson; J Gemmell; E Schooler; J Gray; R Kermode,*,SIAM Journal on Computing,1991,*
Reliability of Protocols Based on Ordered Shared Locks,Divyakant Agrawal; Amr El Abbadi,*,*,1991,*
Failure Atomicity in Distributed Nested Transaction Systems,OT Satyanarayanan; Divyakant Agrawal; Amr El Abbadi,*,*,1989,*
Resilient Communication Structures for Local Area Networks,Amr El Abbadi; Thomas Rauchle,Reliable communication is crucial to the correct functioning of distributed systems. Wepropose a multi-ring communication structure and a reconfiguration algorithm that toleratemultiple link failures before the network divides into more than one partition. In case ofpartitioning; each partition is reconfigured to allow communication among the sites within thepartition. The algorithm handles recovery of links and merges partitions once links becomeoperational again. The algorithm itself is fault-tolerant; and it is fully distributed and does notrequire global knowledge about the status of the network at any one site.,*,1984,*
Data Engineering,Faisal Nawab; Vaibhav Arora; Victor Zakhary; Divyakant Agrawal; Amr El Abbadi,Abstract Global-scale data management (GSDM) empowers systems by providing higherlevels of fault-tolerance; read availability; and efficiency in utilizing cloud resources. This hasled to the emergence of globalscale data management and event processing. However; theWide-Area Network (WAN) latency separating datacenters is orders of magnitude largerthan typical network latencies; and this requires a reevaluation of many of the traditionaldesign trade-offs of data management systems. Therefore; data management problems mustbe revisited to account for the new design space. In this paper; we revisit the problem ofsupporting strongly-consistent transaction processing for GSDM. This includes providing anunderstanding of the limits imposed by the WAN latency on transaction latency in addition toa design of a system framework that aims to reduce response time and increase …,*,*,*
Environmental Tomography: Ubiquitous Sensing,Stacy Patterson; Bassam Bamieh; Amr El Abbadi,Abstract-The ubiquitous nature of mobile phones; which are location-aware devices;presents a unique platform for largescale computing applications. In particular; if mobilephones are coupled with sensors; they can be used for detection and monitoring ofenvironmental phenomena such as pollution and radiation. In this demonstration; wepresent Environmental To-mography; a system for ubiquitous environmental sensing withmobile devices. Aggregate sensor measurements are collected by the devices along fixedpaths such as roads; and these aggregates are used to reconstruct an estimate of thedistribution of the underlying physical phenomenon. Our system is robust to the dynamiccharacteristics of mobile networks and also preserves the privacy of mobile user locations.We demonstrate a prototype that generates estimate distributions from user specified data …,*,*,*
Techniques for E cient Routing and Load Balancing in Content-Addressable Networks£,Ozgur D Sahin; Divyakant Agrawal; Amr El Abbadi,Abstract As a Distributed Hash Table (DHT); a Content Addressable Network (CAN)provides e cient routing and object location in a decentralized manner while offering faulttolerance and dynamic peer operations. However; as opposed to other DHTs that use a at IDspace; CAN uses a multi-dimensional logical space. DHTs usually require O (logN) routinginformation per peer and provide routing in O (logN) hops; where N is the number of peers inthe system. In CAN; on the other hand; each peer keeps only constant amount of routinginformation and the routing takes O (dN1= d) hops; where d is the dimensionality of thelogical space. Hence the routing performance of CAN is worse than other DHTs especiallywhen d is small. In this paper; we describe and evaluate several schemes for e cient routingin CAN by keeping additional routing information at the peers. Furthermore; due to the …,*,*,*
TCAM-conscious Algorithms for Data Streams,Nagender Bandi Ahmed Metwally Divyakant Agrawal; Amr El Abbadi,Abstract Recently; there has been significant interest in developing space and time efficientsolutions for answering continuous summarization queries over data streams. While thesetechniques are evaluated in a standard CPU setting; many of their applications such as click-fraud detection; and network-traffic summarization typically execute on special networkingarchitectures called Network Processing Units (NPUs). These NPUs interface with specialkind of associative memories known as the Ternary Content Addressable Memories(TCAMs). In this paper; we describe how the integrated architecture of NPU and TCAMs canbe exploited towards achieving the goal of developing high-speed stream summarizationsolutions. We analyze popular solutions for the frequent elements problem in data stream;discuss the bottleneck issues and motivate how TCAMs can help alleviate these …,*,*,*
Vector Approximation based Indexing for Non-uniform High Dimensional Data Sets* Hakan Ferhatosmanoglu Department of Computer Science,Divyakant Agrawal; Amr El Abbadi,*,*,*,*
Browsing and Placement of Multi-resolution Images on Parallel Disks* Sunil Prabhakar Department of Computer Sciences Purdue University,Divyakant Agrawal; Amr El Abbadi; Ambuj Singh; Terence Smith,Abstract With rapid advances in computer and communication technologies; there is anincreasing demand to build and maintain large image repositories. In order to reduce thedemands on I/O and network resources; multi-resolution representations are beingproposed for the storage organization of images. Image decomposition techniques such aswavelets can be used to provide these multi-resolution images. The original image isrepresented by several coefficients; one of them with visual similarity to the original image;but at a lower resolution. These visually similar coefficients can be thought of as thumbnailsor icons of the original image. This paper addresses the problem of storing these multi-resolution coefficients on disks so that thumbnail browsing as well as image reconstructioncan be performed efficiently. Several strategies are evaluated to store the image …,*,*,*
Exploiting Storage Redundancy and Parallelism for Efficient Retrieval of Multimedia Data,Divyakant Agrawal; Amr El Abbadi; WWW Page,With the rapid advances in computing and communication technologies; there is increasingdemand and reliance to store a large variety of data types in digital form. Once data is storeddigitally; it becomes available for access and retrieval using a variety of parameters. Thisproposal addresses the problem of,*,*,*
Search this site,Subhash Suri; Ömer Eğecioğlu; Teofilo F Gonzalez; Wim van Dam; John Gilbert; Huijia Rachel Lin; Stefano Tessaro; Linda Petzold; Frederic G Gibou; Xifeng Yan; Tao Yang; Timothy Sherwood; Phillip Conrad; Divyakant Agrawal; Amr El Abbadi; Ambuj K Singh; Jianwen Su; Tobias Höllerer; William Wang; Matthew Turk; Kevin C Almeroth; Elizabeth M Belding; Chandra Krintz; Peter Cappello; Rich Wolski; Tevfik Bultan; Ben Hardekopf; Richard A Kemmerer; Giovanni Vigna; Christopher Kruegel; Yuan-Fang Wang,Computational algorithms and software tools for data mining; data analysis; linear algebra;large-scale graph computations; high performance computing; partial differential equations;and multi-scale stochastic simulation. Applications to systems biology; ecology; energy;materials; fluids; and social science.,*,*,*
Geo-placement: Geo-replicated Database Placement,Victor Zakhary; Faisal Nawab; Divyakant Agrawal; Amr El Abbadi,Abstract—Geo-replication is the process of maintaining copies of data at geographicallydispersed datacenters for better availability and fault-tolerance. The distinguishingcharacteristic of geo-replication is the large wide-area latency between datacenters thatvaries widely depending on the location of the datacenters. Thus; choosing whichdatacenters to deploy a cloud application has a direct impact on the observable responsetime. We propose an optimization framework that automatically derives a georeplicationplacement plan with the objective of minimizing latency. By running the optimizationframework on real placement scenarios; we learn a set of placement principles for geo-replication. In this paper; we highlight the geo-replication placement principles.,*,*,*
Faculty-Undergraduate Advising; Winter 2016; UCSB Computer Science,Amr El Abbadi; Tevfik Bultan,Dr. Tobias Höllerer is a Professor in the Department of Computer Science. Dr. Höllererjoined the Department in 2002. His PhD is from Columbia University. His research interestsinclude: Human computer interaction; virtual and augmented reality; computer graphics;wearable and ubiquitous computing; visualization and social computing.,*,*,*
Extracting Topics with Focused Communities in Multi-dimensional Social Data,Theodore Georgiou; Amr El Abbadi; Xifeng Yan,ABSTRACT Understanding what social media users discuss and what is happening in thereal world can be enabled through the automatic analysis and summarization of OnlineSocial Media. Trend Discovery; through the extraction of trending topics; is utilized inmarketing campaigns and by companies to identify customer interests and potential newmarkets. While there is a plethora of techniques to identify trending topics; there is a lack offocus on the characteristics of the underlying population that participate in a trend. Users thatmention a topic define a multivariate vector of demographics and user characteristics withthe potential to offer insights into the communities that are focused on a topic; both latent andobvious. We propose a novel algorithmic framework for the efficient and scalable extractionof the combination of user characteristics that define a community interested in a topic …,*,*,*
Message from the TCDE Chair Nominating Committee,David Lomet; Paul Larson; Amr El Abbadi,The Chair of the IEEE Computer Society Technical Committee on Data Engineering (TCDE)is elected for a two-year period. The mandate of the current Chair; Kyu-Young Whang; is comingto an end and it is time to elect a Chair for the next two years. The TCDE Chair NominatingCommittee; consisting of Amr El Abaddi; Paul Larson; and David Lomet; has nominated two candidatesfor the position as Chair of TCDE: Erich Neuhold and Xiaofang Zhou. The Committee regardsboth candidates as highly qualified to fill the office of Chair of the Technical Committee; and urgesmembers to cast their votes. More information about TCDE can be found at http://tab.computer.org/tcde/ as well as in the accompanying election announcement below from Brookes Little ofthe Computer Society … David Lomet; Paul Larson and Amr El Abbadi Microsoft; Microsoft;and UC Santa Barbara … Election for Chair of IEEE Computer Society TC on Data …,*,*,*
RELEVANT COURSEWORK,Faisal Nawab; Vaibhav Arora; Divyakant Agrawal; Amr El Abbadi; Aaron J Elmore; Rebecca Taft; Andrew Pavlo; Hatem Mahmoud; Chris Bunch; Navraj Chohan; Chandra Krintz; Shashank Hegde; Ankit Srivastava,● Developed a mapping service; which normalizes the talker data stored by providing amapping from numeric Ids to talker strings stored. The service is highly fault tolerant;available; provides low latency access and makes sure there aren't any duplicate mappingsand is accessed from geographically different regions.,*,*,*
Distributed Collaborative Filtering With Multiple and Diverse Data Sources,Mohamed Reda Bouadjenek; Esther Pacitti; Florent Masseglia; Amr El Abbadi,*,*,*,*
Secure Distributed Multi-Service Provider for Recommender System Using Matrix Factorization,Mohamed Reda Bouadjenek; Esther Pacitti; Florent Masseglia; Amr El Abbadi; Divyakant Agrawal,*,*,*,*
A Distributed Collaborative Filtering Algorithm With Multiple and Diverse Data Sources,Mohamed Reda Bouadjenek; Esther Pacitti; Florent Masseglia; Amr El Abbadi; Divyakant Agrawal,*,*,*,*
2012 IEEE 12th International Conference on Data Mining (ICDM),Wei Bi; James T Kwok,Hierarchical multilabel classification (HMC) allows an instance to have multiple labelsresiding in a hierarchy. A popular loss function used in HMC is the H-loss; which penalizesonly the first classification mistake along each prediction path. However; the H-loss metriccan only be used on tree-structured label hierarchies; but not on DAG hierarchies. Moreover;it may lead to misleading predictions...,*,*,*
List of Referees--Full Proceedings,GA Abandah; M Abdelguerfi; M Aboelaze; G Abram; A Acharya; GB Adams; V Adve; A Aggarwal; R Aggarwal; A Ailamaki; SG Akl; J Allen; G Almasi; G Alonso; B Alpern; RD Alpert; M Amin; HH Ammar; C Anderson; J Anderson; M Andesland; N Bagherzadeh; JW Baker; P Banerjee; I Banicescu; TA Bapty; R Bartos; D Basak; KE Batcher; A Beguelin; J Bennett; R Bennett; A Berenbaum; M Beynon; LN Bhuyan; A Bojanczik; R Brady; TA Braun; JJ Carrig; L Carter; T Casavant; R Castenada; R Chandra; C Chang; M Charney; C Chase; V Chaudhary; LC Chen; A Cheng; CT Cheng; B Chlebus; S Cho; L Choi; Y Choi; N Chrisochoides; M Cierniak; AJ Cleary; D Coleman; N Coletti; A Conception; J Conroy; TH Cormen; M Coyle; TW Crockett; D Dai; F Darema; C Das; S Dasgupta; M de Azevedo; J Dehnert; E Delp; J Demmel; R Deshmukh; H Dietz; R Dietz; K Diks; N Dimopoulos; DC DiNucci; V Donaldson; H Dwyer; A Edelman; A El-Abbadi; A El-Amawy; T El-Ghazawi; F Ercal; J Feo; T Fine; M Flynn; JAB Fortes,*,*,*,*
Computer Society Connection,Amr El Abbadi; Mohammad Alam; Gustavo Alonso; Krste Asanovi; Nader Bagherzadeh; Chandrajit Bajaj; Gautam Biswas; Alberto Broggi; Richard Brown; Kathleen Carley; Danny Chen; Kwok Cheung; Sunghyun Choi; James Colgate; Manuel Dabreu; Sujit Dey; Inderjit Dhillon; David Doermann; Paolo Faraboschi; Alejandro Frangi; Phillip Gibbons; Garth Gibson; Antonio Gonzalez; Ramesh Govindan; Adolfo Guzman; John Heidemann; Yiwei Hou; Weihua Jiang; Christopher Johnson; Mohan Kankanhalli; Krishna Kant; Yu-Kwong Kwok; David Laidlaw; Bing Liu; Daniel Menasce; Cecilia Metra; Paul Mockapetris; Paolo Montuschi; Yi Murphey; Jian Pei; Fatih Porikli; Padma Raghavan; Michael Reiter; Amir Said; Guillermo Sapiro; Steven Scott; Cyrus Shahabi; Shiuhpyng Shieh; Sandeep Shukla; Raghupathy Sivakumar; Ashok Srivastava; John Stasko; Hisao Taoka; Keiichi Tokuda; Wade Trappe; Rene Vidal; Ross Whitaker; Changsheng Xu; Sudhakar Yalamanchili; Franco Zambonelli; Yongguang Zhang,This year; IEEE celebrates its 50th year honoring select IEEE members with Fellow status.Fellows are those members whose accomplishments have advanced the engineering field;and as a result; they have brought significant value to society. The grade of Fellow was firstestablished in 1964; when the American Institute of Electrical Engineers (AIEE) and theInstitute of Radio Engineers (IRE) merged; it'sa highly selective elevation; as only one-tenthof one percent of the total voting membership can be elevated in any one year. Over the past50 years; IEEE has elevated roughly 10;000 members to this honor. Throughout 2014; IEEEwill celebrate its Fellows in a number of ways.,*,*,*
Tertiary Storage: Current Status and Future Trends,S Prabhakar D Agrawal A El; Abbadi A Singh,Abstract This report summarizes current state of the art in tertiary storage systems. We beginwith a comprehensive discussion of magnetic tape and optical storage technologies. This isfollowed by a classi cation of commercial products based on their performancecharacteristics. Our analysis of product data indicates that in contrast to disk technology;tertiary storage products have signi cant variablility in terms of data transfer rates as well asother performance gures. We then summarize e orts in the areas of operating systems;databases and advanced applications to integrate tertiary storage. We point out that di erentassumptions about the underlying technology result in entirely di erent algorithms andsystem design. We conclude the report with a speculation of future trends.,*,*,*
Department of Computer Science University of California Santa Barbara; CA 93106,S Prabhakar D Agrawal A El; Abbadi A Singh,*,*,*,*
Scheduling Tertiary I/O in Database Applications,Sunil Prabhakar Divyakant Agrawal Amr El; Abbadi Ambuj Singh,Abstract We study the problem of scheduling I/O requests for tertiary storage libraries toimprove performance. The focus is on scheduling policies that process all requests on aloaded medium before unloading it. For single drive settings an efficient algorithm thatproduces optimal schedules is developed. For multiple drives the problem is shown to beNP-Complete. Efficient and effective heuristics are presented for the multiple drives case.The scheduling policies developed achieve significant performance gains over more naivefirst come first server policies. The study is general enough to be applicable to any storagelibrary handling removable media; such as tapes or optical disks.,*,*,*
Browsing and Placement of Multiresolution Images on Parallel Disks,Sunil Prabhakar Divyakant Agrawal Amr El; Abbadi Ambuj Singh Terence Smith,*,*,*,*
SCIENTIFIC DATABASES,Maria Zemankova; Wesley W Chu; Alfonso F Cardenas; Ricky K Taira; Amy J Lee; Elke A Rundenstelner; Terence Ft Smith; Jianwen Su; Amr El Abbadi; Divyakant Agrawal; Gustav Alonso; Amitabh Saran; LT Chen; R Drach; M Keating; S Louis; D Rotem; A Shoshani; Maria L Barja; Alvaro AA Fernandes; Norman W Paton; M Howard Williams; Andrew Dlnn,*,*,*,*
A BRIEF SURVEY OF TERTIARY STORAGE SYSTEMS AND RESEARCH,S Prabhakar D Agrawal A El; Abbadi A Singh,'Appeared in ACM Symposium on Applied Computing; ACM SAC; San Jose Feb.-Mar. 1997'A BRIEF SURVEY OF TERTIARY STORAGE SYSTEMS AND RESEARCH * S. Prabhakar D.Agrawal A. El Abbadi A. Singh Department of Computer Science University of California SantaBarbara; CA 93106. {sunilp; agrawal; amr; ambuj}@cs.ucsb.edu Keywords: Tapes; DigitalLibraries; Mass Storage Abstract This report summarizes current state of the art in ter- tiary storagesystems. We also summarize the current technologies and research efforts to integrate tertiarystorage in operating systems; databases and advanced applications. 1 Introduction With therecent improvements in network and processor speeds; several data intensive applications havebecome much more feasible than ever before. These applications are characterized by verylarge computational and stor- age requirements. In the present commercial setting and …,*,*,*
Program Vice-Chairs,Elisa Bertino; Divesh Srivastava; Surajit Chaudhuri; Jiawei Han; Bernhard Mitschang; David Lomet; Keith Jeffery; Raghu Ramakrishnan; Alberto Mendelzon; Hongjun Lu; Amr El Abbadi; Yannis Ioannidis; Karl Aberer; Charu C Aggarwal; Divy Agrawal; Demet Aksoy; Sihem Amer-Yahia; Paolo Atzeni; Daniel Barbara; Roger Barga; Alfonso Cardenas; Barbara Catania; Sang K Cha; Soumen Chakrabarti; Sharma Chakravarthy; Edward Chang; Kevin Chang; Qiming Chen; David W Cheung; Stavros Christodoulakis; Lois Delcambre; Stefan Dessloch; Max Egenhofer; Ahmed Elmagarmid; Martin Ester; Georgios Evangelidis; Mary Fernandez; Daniela Florescu; Juliana Freire; Christoph Freytag,*,*,*,*
Steering Committee Members,Amr El Abbadi; Sanjoy Baruah; Amit Basu; Elisa Bertino; Alejandro P Buchmann; Aslihan Celik; Ludmila Cherkasova; Panos Chrysanthis; Umesh Dayal; Anant Jhingran; Pinar Keskinocak; Norihisa Komoda; Ramayya Krishnan; Vijay Kumar; Wen-Syan Li; Sridhar Narasimhan; Evaggelia Pitoura; Krithi Ramamritham; Kyuseok Shim; Sang Son; Dick Tsur; Wei Zhao,*,*,*,*
Myong Ho Kim; KAIST; Korea Bin Lan; Microsoft Research; USA Chiang Lee; National Cheng-Kung University; Taiwan Dik Lee; Hong Kong University of Science &...,Amr El Abbadi; Swarup Acharya; Elisa Bertino; Stephane Bressan; Ming-Syan Chen; Anindya Datta; Alex Delis; Maggie Dunham; Akira Fukuda; Johannes Gehrke; Jadwiga Indulska; Christian S Jensen; Anupam Joshi; Hyunchul Kang,*,*,*,*
Panel:“Networking Meets Databases: Do we meet or merge?”,K Aberer; A Abbadi; R Jain UCI; D Gunopulos UCR; W Hong,The recent years brought a massive change in the way data management is viewed. Data isbeing increasingly processed within networks. P2P computing and sensor networks are themost prominent examples. The classical separation of information systems fromcommunication systems is disolving. We can observe that very similar problems areaddressed by what before seemed fairly disparate research communities. For example; theproblem of aggregating and filtering data within networks is being studied simultanously ininformation theory and networking; both classical EE fields; as well as in distributed systemsand databases; both classical CS fields. Even researchers from so seemingly unrelateddisciplines such as physics start to investigate these problems. This raises a number ofissues of how research in this field is organized now and ought to be organized in the …,*,*,*
COOPERATIVE MODELING IN APPLIED GEOGRAPHIC RESEARCH,AMR EL ABBADI,ABSTRACT The characteristics of geographic data and the nature of geographic researchrequire the participation of many agents. Data is generated by multiple sources (satellites;ground observation; weather stations; photography; etc.); accessed; processed andtransformed by many users and available for use to an even larger population of users. Lackof coordination among all these di erent agents may render large amounts of work useless.Most existing GIS (Geographic Information Systems) do not provide any support forcooperative work; which adds to the problem. To overcome this serious limitation while stillallowing users to take advantage of GIS technology; we propose GOOSE; a systemimplemented as a top layer for existing GIS. GOOSE provides the tools for constructing largegeographic models in a cooperative environment with potentially many users and …,*,*,*
Technical Report TRCS00-01 Database Replication Using Epidemic Update,JoAnne Holliday; Divyakant Agrawal; Amr El Abbadi,Abstract Due to severe performance penalties associated with synchronous replication;there is an increasing interest in asynchronous replica management protocols in whichdatabase transactions are executed locally; and the effects of these transactions areincorporated asynchronously on remote database copies. However; the asynchronousprotocols currently in use either do not guarantee consistency and serializability as neededby transactional semantics or they impose restrictions on placement of data and on whichdata objects can be updated. In this paper we investigate an epidemic update protocol thatguarantees consistency and serializability in spite of a write-anywhere capability. Weconducted experiments on a detailed simulation of a distributed; replicated database toevaluate this protocol. Our results establish that this epidemic approach is indeed a viable …,*,*,*
Data Engineering,Raghu Ramakrishnan; Divesh Srivastava; Gustavo Alonso; Amr El Abbadi; Sudarshan S Chawathe; Hector Garcia-Molina; Jennifer Widom,Bulletin of the Technical Committee on Data Engineering Date of Issue Vol. N No. m IEEE ComputerSociety Letters Special Issue on Database Constraint Management Letter from the Special IssueEditor............................................ Jennifer Widom 2 Constraint Management in Chimera.............. Stefano Ceri; Piero Fraternali; Stefano Paraboschi 4 Integrity Control in Advanced DatabaseSystems.. Paul WPJ Grefen; Rolf A. de By; Peter MG Apers 9 Semantics and Optimization of ConstraintQueries in Databases …,Urbana,*,*
VLDB Endowment Board of Trustees,Gerhard Weikum; Laura M Haas; Paolo Atzeni; Michael J Franklin; Amr El Abbadi; Gustavo Alonso; Peter MG Apers; Elisa Bertino; Peter Buneman; Johann Christoph Freytag; HV Jagadish; Christian S Jensen; Donald Kossmann; David Lomet; Renée J Miller; Shojiro Nishio; Beng Chin Ooi; Meral Ozsoyoglu; Krithi Ramamritham; Raghu Ramakrishnan; Stanley B Zdonik,The VLDB Endowment is a non-profit foundation whose objective is to promote scientific andeducational activities in the area of large-scale data; information; and knowledgemanagement. The Endowment serves as the steering committee for the VLDB conferenceseries. The Endowment also sponsors various scholarly activities. It has established aprogram that supports summer schools; tutorials; and other training activities of this kind; incountries that could otherwise not afford the expenses for such events. The Endowment isalso the main sponsor of the biennial Conference on Innovative Data Systems Research(CIDR); and it runs the VLDB Journal; one of the most successful journals in the databasearea. On various activities; the Endowment closely cooperates with ACM SIGMOD. TheVLDB Endowment has a board of 21 elected trustees; who are the legal guardians of the …,*,*,*
Session 1A-Algorithms A Virtual Node-Based Tracking Algorithm for Mobile Networks Tina Nolte and Nancy Lynch Approximate Covering Detection among Content-...,Zhenhui Shen; Srikanta Tirthapura; Borzoo Bonakdarpour; Sandeep S Kulkarni; Sumit Ganguly; Minos Garofalakis; Rajeev Rastogi; Krishan Sabnani; Vassil Kriakov; Alex Delis; George Kollios; Nagender Bandi; Divyakant Agrawal; Amr El Abbadi; Yu Wang; Hongyi Wu; Feng Lin; Nian-Feng Tzeng; Yu Gu; Joengmin Hwang; Tian He; David Hung-Chang Du; Mo Li; Yunhao Lin; Lei Chen; Vivek Rai; Swaminathan Sivasubramanian; Sandjai Bhulai; Pawel Garbacki; Maarten van Steen,Page 1. Session 1A - Algorithms A Virtual Node-Based Tracking Algorithm for Mobile NetworksTina Nolte and Nancy Lynch Approximate Covering Detection among Content-BasedSubscriptions Using Space Filling Curves Zhenhui Shen and Srikanta Tirthapura ExploitingSymbolic Techniques in Automated Synthesis of Distributed Programs with Large State SpaceBorzoo Bonakdarpour and Sandeep S. Kulkarni Session 1B - Data Streaming StreamingAlgorithms for Robust; Real-Time Detection of DDoS Attacks Sumit Ganguly; Minos Garofalakis;Rajeev Rastogi; and Krishan Sabnani Approximate Data Stream Joins in Distributed SystemsVassil Kriakov; Alex Delis; and George Kollios Fast Algorithms for Heavy Distinct Hitters UsingAssociative Memories Nagender Bandi; Divyakant Agrawal; and Amr El Abbadi Session 1C -Sensor Networks: Sensing and Mobility …,*,*,*
Department of Computer Science University of California Santa Barbara; CA 93106,Hakan Ferhatosmanoglu; Divyakant Agrawal; Amr El Abbadi,*,*,*,*
From a Virtualized Computing Nucleus to a Cloud Computing Universe: A Case for Dynamic Clouds,Divyakant Agrawal Sudipto Das; Amr El Abbadi,ABSTRACT The current model of the cloud consists of a static set of data centers (or cloudcores) which drive the computation and storage needs of large numbers of applications. Weenvision a new paradigm where the cloud will be comprised of a large dynamic collection ofcloud cores along with a static set of cores; the nucleus; to create a cloud computinguniverse with a capacity much larger than the nucleus and a cost much smaller than owningthe entire infrastructure. This model is rooted by the observation that a tremendous amountof computation exists outside the core that can potentially augment the nucleus' capacity. Anexample of this surplus capacity are enterprizes with diurnal trends in usage behavior thatjoin the cloud during predicted periods of usage troughs. We propose to leverage this elasticand dynamic infrastructure to create a unified cloud service. A number of challenges; at …,*,*,*
An E cient Implementation of the Quorum Consensus Protocol,ML Liu; D Agrawal; A El Abbadi,While distributed database systems have been the subject of extensive research; itsacceptance in the industry remains tenuous 22]. A key reason for this phenomenon is that forsuch a system to function properly; it must perform correctly in the presence ofcommunication and site failures. Although many protocols which address failures have beenproposed; their implementation has not been widespread. For example; few in the the familyof replica control protocols have ever been put into practice 24; 22]. This lack of acceptanceis largely due to (i) the di culty involved in assessing the performance impact of theprotocols; and (ii) the high complexity typically associated with such protocols. In particular;there are not enough existing distributed database applications to provide a sound basis forempirical judgements that must be exercised by the designer of a distributed database …,*,*,*
Data Engineering,Gustavo Alonso; Amr El Abbadi; Sudarshan S Chawathe; Hector Garcia-Molina; Jennifer Widom,Bulletin of the Technical Committee on Data Engineering June; 1994 Vol. 17 No. 2 IEEE ComputerSociety Letters Letter from the Editor-in-Chief...................................................... David Lomet 1 SpecialIssue on Database Constraint Management Letter from the Special Issue Editor................................................ Jennifer Widom 2 Constraint Management in Chimera.................... Stefano Ceri;Piero Fraternali; Stefano Paraboschi 4 Integrity Control in Advanced Database Systems.......... Paul WPJ … Editorial Board Editor-in-Chief David B. Lomet DEC Cambridge ResearchLab One Kendall Square; Bldg. 700 Cambridge; MA 02139 lomet@ crl. dec. com Associate EditorsShahram Ghandeharizadeh Computer Science Department University of Southern CaliforniaLos Angeles; CA 90089 Goetz Graefe Portland State University Computer Science DepartmentPO Box 751 Portland; OR 97207 Meichun Hsu Digital Equipment Corporation 529 Bryant …,Urbana,*,*
The Golden Estimator: E cient Range Query Estimation,Yi-Leh Wu; Divyakant Agrawal; Amr El Abbadi,Abstract. Query size estimation is crucial for many database system components. Inparticular; query optimizers need e cient and accurate query size estimation when decidingamong alternative query plans. In this paper we propose the Golden Estimator; which isbased on the so called golden rule of sampling proposed by von Neumann; for estimatingthe size of single dimensional range queries. The Golden Estimator randomly samples thefrequency domain using the cumulative frequency distribution. We argue why this approachwill yield good estimates irrespective of the actual underlying distribution of values. We thenexperimentally show that the Golden Estimator gives better approximation than state of theart histogram based and wavelet based approaches under the same space requirement.,*,*,*
KNOWLEDGE AND,D Agrawal; A El Abbadi,The Computer Society is an association of people with professional interest in the field ofcomputers. All members of the IEEE are eligible for membership in the Society uponpayment of the annual Society membership fee of $15.00. Members of certain professionalsocieties and other computer professionals are eligible to be members of the ComputerSociety. For information on joining write to IEEE Computer Society; 1730 MassachusettsAvenue NW; Washington; DC 20036-1903. IEEE TRANSACTIONS ON KNOWLEDGE ANDDATA ENGINEERING,Urbana,*,*
Cyclic Declustering of Two-Dimensional Data,Amr El Abbadi,Abstract Various proposals have been made for declustering two-dimensionally tiled data onmultiple I/O devices. Recently in AE97]; it was shown that strictly optimal solutions only existunder very restrictive conditions on the tiling of the two-dimensional space or for very few I/Odevices. In this paper we explore allocation methods where no strictly optimal solutionexists. We propose a general class of allocation methods; referred to as cyclic declusteringmethods; and show that many existing methods are instances of this class. As a result;various seemingly ad hoc and unrelated methods are presented in a single framework.Furthermore; the framework is used to develop new allocation methods that give betterperformance than any previous method and that approach the best feasible performance.,*,*,*
E cient Processing of Conical Queries,Hakan Ferhatosmanoglu; Divyakant Agrawal; Amr El Abbadi,Abstract Conical queries are a novel type of query with an increasing number ofapplications. Traditional index structures and retrieval mechanisms; in general; have beenoptimized for rectangular and circular queries; rather than conical queries. In this paper; wefocus on conical queries which can be de ned as a multi-dimensional cone in a multi-dimensional data space. We develop a model for expressing such queries and suggest ecient techniques for evaluating them. In particular; we explore the retrieval problem in thecontext of conical query processing and develop multi-disk allocation methods speci cally forprocessing conical queries. i,*,*,*
Technical Report: Partial Database Replication using Epidemic Communication£,JoAnne Holliday; Divyakant Agrawal; Amr El Abbadi,Abstract Data replication in distributed databases has been investigated extensively with thehope that it will improve performance; reliability; and availability. However; the growth of theInternet has shown us that current replica management do not work well when the replicasare connected by an unreliable network; subject to congestion and dynamic topologychanges. In this paper; we present a replica update protocol that handles an adaptive partialreplication scheme on such a network.,*,*,*
Exploiting Atomic Broadcast in Replicated,Divyakant Agrawal; Gustavo Alonso; Amr El Abbadi; Ioana Stanoi,In spite of the fact that many applications require replicated databases either forperformance or fault-tolerance; replication has remained a research issue until recently.Today; the demand for practical replication schemes has greatly increased and some simpleprotocols are being implemented in databases (Oracle and Sybase; for instance) or inapplication development tools (Lotus Notes). These; however; are ad hoc implementationsand the issue of replicated data management is still a source of controversy amongdatabase practitioners and researchers. On one hand; traditional synchronous protocols aretoo expensive in terms of message cost and communication latency; and they aresusceptible to deadlocks when compared to non-replicated databases. An alternativeapproach based on asynchronous updates may result in inconsistencies and an ever …,*,*,*
Computer Science Department; University of California at Santa Barbara,H Ferhatosmanoglu; I Stanoi; D Agrawal; A El Abbadi,*,*,*,*
Position Statement on Mobile Sensor Networks,Amr El Abbadi,Both sensor networks and mobile systems pose interesting and challenging problems; eachin its own right. Mobile sensor networks; hence represent a very promising and fruitfuldomain for exploring and investigating diverse paradigms integrating distributed computingand data management. In fact it is fairly easy to argue that mobile sensor networks representa microcosm of many of the fundamental problems in Computer Science. In particular;successful mobile sensor networks will open new and intriguing venues for research indiverse topics such as:,*,*,*
CoTS: A Scalable Framework for Parallelizing Frequency Counting over Data Streams,Naïve Parallelization; Sudipto Das Shyam Antony Divyakant Agrawal; Amr El Abbadi,Page 1. Data Stream Processing Data tuples streaming in – Real-time processing requirementsFrequent Elements and Top-k Queries • Frequent Elements query: Return all the elements whosefrequency of occurrence is above a certain threshold • Top-k query: returns the k elements withthe highest frequency • Frequency counting forms the basis for both these queries Applicationsof Frequency Counting • Network Monitoring: detecting rogue users consuming higher share ofnetwork bandwidth • Click stream analysis for fraud detection and mining Need for Parallelism•Free lunch is over – No automatic performance boost through increasing processor clock speeds•Efficient parallel designs needed to effectively utilize the inherent parallelism • Present state ofthe art is sequential processing of the stream •Intra-operator parallelism (parallelizing singleoperator to effectively utilize the multiple cores) would be helpful …,*,*,*
ElasTraS: An Elastic; Scalable; and Self Managing Transactional Database for the Cloud,Sudipto Das Shashank Agarwal Divyakant Agrawal; Amr El Abbadi,ABSTRACT Cloud computing has emerged as a pervasive platform for deploying scalableand highly available Internet applications. To facilitate the migration of data-drivenapplications to the cloud: elasticity; scalability; fault-tolerance; and self-manageability(henceforth referred to as cloud features) are fundamental requirements for databasemanagement systems (DBMS) driving such applications. Even though extremely successfulin the traditional enterprise setting–the high cost of commercial relational database software;and the lack of the desired cloud features in the open source counterparts–relationaldatabases (RDBMS) are not a competitive choice for cloud-bound applications. As a result;Key-Value stores have emerged as a preferred choice for scalable and faulttolerant datamanagement; but lack the rich functionality; and transactional guarantees of RDBMS. We …,*,*,*
Program Committee Chair,Nick Koudas; Moustafa Hammad; Denilson Barbosa; Ashraf Aboulnaga; Periklis Andritsos; Peter Buneman; Gautam Das; Amr El Abbadi; Christos Faloutsos; Jarek Gryz; Dimitrios Gunopoulos; Ihab Ilyas; Chris Jermaine; Bettina Kemme; George Kollios; Manolis Koubarakis; Laks Lakshmanan; Silvia Nittel; Dimitris Papadias; Sunil Prabhakar; Ken Ross; Joerg Sander; Kyuseok Shim; Yufei Tao; Dimitri Theodoratos; Yannis Theodoridis; Anthony Tung; A Shoshani; W Grossmann,General Chair: Ken Barker University of Calgary … Program Committee Chair: Nick KoudasUniversity of Toronto … Proceedings/Local Organization Chairs: Moustafa Hammad Universityof Calgary Denilson Barbosa University of Calgary … Program Committee: Ashraf AboulnagaUniversity of Waterloo Periklis Andritsos University of Trento Peter Buneman University of EdinburghTiziana Catarci University of Roma Gautam Das University of Texas at Arlington Amr El AbbadiUC Santa Barbara Christos Faloutsos Carnegie Mellon University Jarek Gryz York UniversityDimitrios Gunopoulos UC Riverside Marios Hadjieleftheriou AT&T Research Ihab Ilyas Universityof Waterloo Chris Jermaine University of Florida Bettina Kemme McGill University George KolliosBoston University Manolis Koubarakis University of Athens Laks Lakshmanan University of BritishColumbia Silvia Nittel University of Maine Dimitris Papadias Hong Kong University Sunil …,*,*,*
Optimal Partitioning for E cient I/O in Spatial Databases,Hakan Ferhatosmanoglu; Divyakant Agrawal; Amr El Abbadi,Abstract It is desirable to design partitioning techniques that minimize the I/O time incurredduring query execution in spatial databases. In this paper; we explore optimal partitioningtechniques for spatial data for di erent types of queries; and develop multi-disk allocationtechniques that maximize the degree of I/O parallelism obtained during the retrieval. Weshow that hexagonal partitioning has optimal I/O cost for circular queries compared to allpossible non-overlapping partitioning techniques that use convex regions. For rectangularqueries; we show that although for the special case when queries are rectilinear; rectangulargrid partitioning gives superior performance; hexagonal partitioning has overall better I/Ocost for a general class of range queries. We then discuss parallel storage and retrievaltechniques for hexagonal partitioning using current techniques for rectangular grid …,*,*,*
IO-RTING 4HD I€ l€~ lON,Amr El Abbadi,Page 1. Page 2. IO-RTING 4HD I€l€~lON Amr El Abbadi University of California; Santa Barbara,*,*,*
Gustavo Alonso y Radek Vingralek z Divyakant Agrawal y Yuri Breitbart z,Amr El Abbadi; Hans-J Schek; Gerhard Weikum,*,*,*,*
Technical Report TRCS00-07 Planned Disconnections for Mobile Databases,JoAnne Holliday; Divyakant Agrawal; Amr El Abbadi,Abstract As mobility permeates into todays computing and communication arena; weenvision application infrastructures that will increasingly rely on mobile technologies.Traditional database applications and information service applications will need to integratemobile entities: people and computers. In this paper; we develop a distributed databaseframework for mobile environments. A key requirement in such an environment is to supportfrequent connection and disconnection of database sites. We present algorithms thatimplement this framework in an asynchronous system.,*,*,*
Query Processing Over Peer-To-Peer Data Sharing Systems,OD Sahin A Gupta D Agrawal; A El Abbadi,Abstract Peer-to-peer systems are mainly used for object sharing currently; but they canprovide the infrastructure for many other applications. In this paper; we extend the idea ofobject sharing to data sharing on a peer-to-peer system. We propose a method; which isbased on the CAN [9] system; for efficiently evaluating range queries on such a system. Theanswers of the range queries are cached at the peers and then they are used to answerfurther range queries. The scalability and efficiency of our design is shown throughsimulation.,*,*,*
