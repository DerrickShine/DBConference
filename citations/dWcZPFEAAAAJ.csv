Efficient and accurate nearest neighbor and closest pair search in high-dimensional space,Yufei Tao; Ke Yi; Cheng Sheng; Panos Kalnis,Abstract Nearest Neighbor (NN) search in high-dimensional space is an important problemin many applications. From the database perspective; a good solution needs to have twoproperties:(i) it can be easily incorporated in a relational database; and (ii) its query costshould increase sublinearly with the dataset size; regardless of the data and querydistributions. Locality-Sensitive Hashing (LSH) is a well-known methodology fulfilling bothrequirements; but its current implementations either incur expensive space and query cost;or abandon its theoretical guarantee on the quality of query results. Motivated by this; weimprove LSH by proposing an access method called the Locality-Sensitive B-tree (LSB-tree)to enable fast; accurate; high-dimensional NN search in relational databases. Thecombination of several LSB-trees forms a LSB-forest that has strong quality guarantees …,ACM Transactions on Database Systems (TODS),2010,241
The priority R-tree: A practically efficient and worst-case optimal R-tree,Lars Arge; Mark De Berg; Herman Haverkort; Ke Yi,Abstract We present the priority R-tree; or PR-tree; which is the first R-tree variant thatalways answers a window query using O ((N/B) 1− 1/d &plus; T/B) I/Os; where N is thenumber of d-dimensional (hyper-) rectangles stored in the R-tree; B is the disk block size;and T is the output size. This is provably asymptotically optimal and significantly better thanother R-tree variants; where a query may visit all N/B leaves in the tree even when T&equals; 0. We also present an extensive experimental study of the practical performance ofthe PR-tree using both real-life and synthetic data. This study shows that the PR-treeperforms similarly to the best-known R-tree variants on real-life and relatively nicelydistributed data; but outperforms them significantly on more extreme data.,ACM Transactions on Algorithms (TALG),2008,236
Semantics of ranking queries for probabilistic data and expected ranks,Graham Cormode; Feifei Li; Ke Yi,When dealing with massive quantities of data; top-k queries are a powerful technique forreturning only the k most relevant tuples for inspection; based on a scoring function. Theproblem of efficiently answering such ranking queries has been studied and analyzedextensively within traditional database settings. The importance of the top-k is perhaps evengreater in probabilistic databases; where a relation can encode exponentially many possibleworlds. There have been several recent attempts to propose definitions and algorithms forranking queries over probabilistic data. However; these all lack many of the intuitiveproperties of a top-k over deterministic data. Specifically; we define a number of fundamentalproperties; including exact-k; containment; unique-rank; value-invariance; and stability;which are all satisfied by ranking queries on certain data. We argue that all these …,Data Engineering; 2009. ICDE'09. IEEE 25th International Conference on,2009,234
Efficient processing of top-k queries in uncertain databases with x-relations,Ke Yi; Feifei Li; George Kollios; Divesh Srivastava,This work introduces novel polynomial algorithms for processing top-k queries in uncertaindatabases under the generally adopted model of x-relations. An x-relation consists of anumber of x-tuples; and each x-tuple randomly instantiates into one tuple from one or morealternatives. Our results significantly improve the best known algorithms for top-k queryprocessing in uncertain databases; in terms of both runtime and memory usage. In the single-alternative case; the new algorithms are 2 to 3 orders of magnitude faster than the previousalgorithms. In the multialternative case; we introduce the first-known polynomial algorithms;while the current best algorithms have exponential complexity in both time and space. Ouralgorithms run in near linear or low polynomial time and cover both types of top-k queries inuncertain databases. We provide both the theoretical analysis and an extensive …,IEEE transactions on knowledge and data engineering,2008,228
Tree indexing on solid state drives,Yinan Li; Bingsheng He; Robin Jun Yang; Qiong Luo; Ke Yi,Abstract Large flash disks; or solid state drives (SSDs); have become an attractivealternative to magnetic hard disks; due to their high random read performance; low energyconsumption and other features. However; writes; especially small random writes; on flashdisks are inherently much slower than reads because of the erase-before-write mechanism.To address this asymmetry of read-write speeds in tree indexing on the flash disk; wepropose FD-tree; a tree index designed with the logarithmic method and fractionalcascading techniques. With the logarithmic method; an FD-tree consists of the head tree--asmall B+-tree on the top; and a few levels of sorted runs of increasing sizes at the bottom.This design is write-optimized for the flash disk; in particular; an index search will potentiallygo through more levels or visit more nodes; but random writes are limited to a small area …,Proceedings of the VLDB Endowment,2010,222
Finding frequent items in probabilistic data,Qin Zhang; Feifei Li; Ke Yi,Abstract Computing statistical information on probabilistic data has attracted a lot of attentionrecently; as the data generated from a wide range of data sources are inherently fuzzy oruncertain. In this paper; we study an important statistical query on probabilistic data: findingthe frequent items. One straightforward approach to identify the frequent items in aprobabilistic data set is to simply compute the expected frequency of an item and decide if itexceeds a certain fraction of the expected size of the whole data set. However; this simpledefinition misses important information about the internal structure of the probabilistic dataand the interplay among all the uncertain entities. Thus; we propose a new definition basedon the possible world semantics that has been widely adopted for many query types inuncertain data management; trying to find all the items that are likely to be frequent in a …,Proceedings of the 2008 ACM SIGMOD international conference on Management of data,2008,209
Sliding-window top-k queries on uncertain streams,Cheqing Jin; Ke Yi; Lei Chen; Jeffrey Xu Yu; Xuemin Lin,Abstract Query processing on uncertain data streams has attracted a lot of attentions lately;due to the imprecise nature in the data generated from a variety of streaming applications;such as readings from a sensor network. However; all of the existing works on uncertaindata streams study unbounded streams. This paper takes the first step towards the importantand challenging problem of answering sliding-window queries on uncertain data streams;with a focus on arguably one of the most important types of queries---top-k queries. Thechallenge of answering sliding-window top-k queries on uncertain data streams stems fromthe strict space and time requirements of processing both arriving and expiring tuples in high-speed streams; combined with the difficulty of coping with the exponential blowup in thenumber of possible worlds induced by the uncertain data model. In this paper; we design …,The VLDB Journal,2010,167
An information-theoretic approach to detecting changes in multi-dimensional data streams,Tamraparni Dasu; Shankar Krishnan; Suresh Venkatasubramanian; Ke Yi,Abstract An important problem in processing large data streams is detecting changes in theunderlying distribution that generates the data. The challenge in designing change detectionschemes is making them general; scalable; and statistically sound. In this paper; we take ageneral; information-theoretic approach to the change detection problem; which works formultidimensional as well as categorical data. We use relative entropy; also called theKullback-Leibler distance; to measure the difference between two given distributions. TheKL-distance is known to be related to the optimal error in determining whether the twodistributions are the same and draws on fundamental results in hypothesis testing. The KL-distance also generalizes traditional distance measures in statistics; and has invarianceproperties that make it ideally suited for comparing distributions. Our scheme is general; it …,In Proc. Symp. on the Interface of Statistics; Computing Science; and Applications,2006,159
Algorithms for distributed functional monitoring,Graham Cormode; S Muthukrishnan; Ke Yi,Abstract Consider the following problem: We have k players each receiving a stream ofitems; and communicating with a central coordinator. Let the multiset of items received byplayer i up until time t be A i (t). The coordinator's task is to monitor a given function fcomputed over the union of the inputs∪ i A i (t); continuously at all times t. The goal is tominimize the number of bits communicated between the players and the coordinator. Ofinterest is the approximate version where the coordinator outputs 1 if f &geq; τ and 0 iff&leq;(1− &epsis;) τ. This defines the (k; f; τ; &epsis;) distributed functional monitoringproblem. Functional monitoring problems are fundamental in distributed systems; inparticular sensor networks; where we must minimize communication; they also connect tothe well-studied streaming model and communication complexity. Yet few formal bounds …,ACM Transactions on Algorithms (TALG),2011,151
Efficient maintenance of materialized top-k views,Ke Yi; Hai Yu; Jun Yang; Gangqiang Xia; Yuguo Chen,We tackle the problem of maintaining materialized top-k views. Top-k queries; including MINand MAX as important special cases; occur frequently in common database workloads. A top-k view can be materialized to improve query performance; but in general it is not self-maintainable unless it contains all tuples in the base table. Deletions and updates on thebase table may cause tuples to leave the top-k view; resulting in expensive queries over thebase table to" refill" the view. We propose an algorithm that reduces the frequency of refillsby maintaining a top-k'view instead of a top-k view; where k'changes at runtime between kand some k/sub max//spl ges/k. We show that in most practical cases; our algorithm canreduce the expected amortized cost of refill queries to O (1) while still keeping the viewsmall. The optimal value of k/sub max/depends on the update pattern and the costs of …,Data Engineering; 2003. Proceedings. 19th International Conference on,2003,105
Indexing uncertain data,Pankaj K Agarwal; Siu-Wing Cheng; Yufei Tao; Ke Yi,Abstract Querying uncertain data has emerged as an important problem in datamanagement due to the imprecise nature of many measurement data. In this paper we studyanswering range queries over uncertain data. Specifically; we are given a collection P of npoints in R; each represented by its one-dimensional probability density function (pdf). Thegoal is to build an index on P such that given a query interval I and a probability threshold τ;we can quickly report all points of P that lie in I with probability at least τ. We present variousindexing schemes with linear or near-linear space and logarithmic query time. Our schemessupport pdf's that are either histograms or more complex ones such as Gaussian orpiecewise algebraic. They also extend to the external memory model in which the goal is tominimize the number of disk accesses when querying the index.,Proceedings of the twenty-eighth ACM SIGMOD-SIGACT-SIGART symposium on Principles of database systems,2009,104
Continuous sampling from distributed streams,Graham Cormode; S Muthukrishnan; Ke Yi; Qin Zhang,Abstract A fundamental problem in data management is to draw and maintain a sample of alarge data set; for approximate query answering; selectivity estimation; and query planning.With large; streaming data sets; this problem becomes particularly difficult when the data isshared across multiple distributed sites. The main challenge is to ensure that a sample isdrawn uniformly across the union of the data while minimizing the communication needed torun the protocol on the evolving data. At the same time; it is also necessary to make theprotocol lightweight; by keeping the space and time costs low for each participant. In thisarticle; we present communication-efficient protocols for continuously maintaining a sample(both with and without replacement) from k distributed streams. These apply to the casewhen we want a sample from the full streams; and to the sliding window cases of only the …,Journal of the ACM (JACM),2012,100
Optimal tracking of distributed heavy hitters and quantiles,Ke Yi; Qin Zhang,Abstract We consider the problem of tracking heavy hitters and quantiles in the distributedstreaming model. The heavy hitters and quantiles are two important statistics forcharacterizing a data distribution. Let A be a multiset of elements; drawn from the universeU={1;…; u}. For a given 0≤ ϕ≤ 1; the ϕ-heavy hitters are those elements of A whosefrequency in A is at least ϕ| A|; the ϕ-quantile of A is an element x of U such that at most ϕ|A| elements of A are smaller than A and at most (1− ϕ)| A| elements of A are greater than x.Suppose the elements of A are received at k remote sites over time; and each of the siteshas a two-way communication channel to a designated coordinator; whose goal is to trackthe set of ϕ-heavy hitters and the ϕ-quantile of A approximately at all times with minimumcommunication. We give tracking algorithms with worst-case communication cost O (k/ϵ⋅ …,Algorithmica,2013,79
Mergeable summaries,Pankaj K Agarwal; Graham Cormode; Zengfeng Huang; Jeff M Phillips; Zhewei Wei; Ke Yi,Abstract We study the mergeability of data summaries. Informally speaking; mergeabilityrequires that; given two summaries on two datasets; there is a way to merge the twosummaries into a single summary on the two datasets combined together; while preservingthe error and size guarantees. This property means that the summaries can be merged in away akin to other algebraic operators such as sum and max; which is especially useful forcomputing summaries on massive distributed data. Several data summaries are triviallymergeable by construction; most notably all the sketches that are linear functions of thedatasets. But some other fundamental ones; like those for heavy hitters and quantiles; arenot (known to be) mergeable. In this article; we demonstrate that these summaries areindeed mergeable or can be made mergeable after appropriate modifications …,ACM Transactions on Database Systems (TODS),2013,78
TerraStream: from elevation data to watershed hierarchies,Andrew Danner; Thomas Mølhave; Ke Yi; Pankaj K Agarwal; Lars Arge; Helena Mitasova,Abstract We consider the problem of extracting a river network and a watershed hierarchyfrom a terrain given as a set of irregularly spaced points. We describe TERRASTREAM; a"pipelined" solution that consists of four main stages: construction of a digital elevation model(DEM); hydrological conditioning; extraction of river networks; and construction of awatershed hierarchy. Our approach has several advantages over existing methods. First; wedesign and implement the pipeline so that each stage is scalable to massive data sets; asingle non-scalable stage would create a bottleneck and limit overall scalability. Second; wedevelop the algorithms in a general framework so that they work for both TIN and grid DEMs.Furthermore; TERRASTREAM is flexible and allows users to choose from various modelsand parameters; yet our pipeline is designed to reduce (or eliminate) the need for manual …,Proceedings of the 15th annual ACM international symposium on Advances in geographic information systems,2007,78
Small synopses for group-by query verification on outsourced data streams,Ke Yi; Feifei Li; Graham Cormode; Marios Hadjieleftheriou; George Kollios; Divesh Srivastava,Abstract Due to the overwhelming flow of information in many data stream applications; dataoutsourcing is a natural and effective paradigm for individual businesses to address theissue of scale. In the standard data outsourcing model; the data owner outsources streamingdata to one or more third-party servers; which answer queries posed by a potentially largenumber of clients on the data owner's behalf. Data outsourcing intrinsically raises issues oftrust; making outsourced query assurance on data streams a problem with importantpractical implications. Existing solutions proposed in this model all build upon cryptographicprimitives such as signatures and collision-resistant hash functions; which only work forcertain types of queries; for example; simple selection/aggregation queries. In this article; weconsider another common type of queries; namely;“GROUP BY; SUM” queries; which …,ACM Transactions on Database Systems (TODS),2009,75
BOXes: Efficient maintenance of order-based labeling for dynamic XML data,Adam Silberstein; Hao He; Ke Yi; Jun Yang,Order-based element labeling for tree-structured XML data is an important technique in XMLprocessing. It lies at the core of many fundamental XML operations such as containment joinand twig matching. While labeling for static XML documents is well understood; less isknown about how to maintain accurate labeling for dynamic XML documents; whenelements and subtrees are inserted and deleted. Most existing approaches do not work wellfor arbitrary update patterns; they either produce unacceptably long labels or incurenormous relabeling costs. We present two novel I/O-efficient data structures; W-BOX and B-BOX that efficiently maintain labeling for large; dynamic XML documents. We showanalytically and experimentally that both; despite consuming minimal amounts of storage;gracefully handle arbitrary update patterns without sacrificing lookup efficiency. The two …,Data Engineering; 2005. ICDE 2005. Proceedings. 21st International Conference on,2005,74
Proof-infused streams: Enabling authentication of sliding window queries on streams,Feifei Li; Ke Yi; Marios Hadjieleftheriou; George Kollios,Abstract As computer systems are essential components of many critical commercialservices; the need for secure online transactions is now becoming evident. The demand forsuch applications; as the market grows; exceeds the capacity of individual businesses toprovide fast and reliable services; making outsourcing technologies a key player inalleviating issues of scale. Consider a stock broker that needs to provide a real-time stocktrading monitoring service to clients. Since the cost of multicasting this information to a largeaudience might become prohibitive; the broker could outsource the stock feed to third-partyproviders; who are in turn responsible for forwarding the appropriate sub-feed to clients.Evidently; in critical applications the integrity of the third-party should not be taken forgranted. In this work we study a variety of authentication algorithms for selection and …,Proceedings of the 33rd international conference on Very large data bases,2007,72
Nearest-neighbor searching under uncertainty ii,Pankaj K Agarwal; Boris Aronov; Sariel Har-Peled; Jeff M Phillips; Ke Yi; Wuzhou Zhang,Abstract Nearest-neighbor search; which returns the nearest neighbor of a query point in aset of points; is an important and widely studied problem in many fields; and it has a widerange of applications. In many of them; such as sensor databases; location-based services;face recognition; and mobile data; the location of data is imprecise. We therefore studynearest-neighbor queries in a probabilistic framework in which the location of each inputpoint is specified as a probability distribution function. We present efficient algorithms for (i)computing all points that are nearest neighbors of a query point with nonzero probability and(ii) estimating the probability of a point being the nearest neighbor of a query point; eitherexactly or within a specified additive error.,ACM Transactions on Algorithms (TALG),2016,71
Ranking distributed probabilistic data,Feifei Li; Ke Yi; Jeffrey Jestes,Abstract Ranking queries are essential tools to process large amounts of probabilistic datathat encode exponentially many possible deterministic instances. In many applicationswhere uncertainty and fuzzy information arise; data are collected from multiple sources indistributed; networked locations; eg; distributed sensor fields with imprecise measurements;multiple scientific institutes with inconsistency in their scientific data. Due to the networkdelay and the economic cost associated with communicating large amounts of data over anetwork; a fundamental problem in these scenarios is to retrieve the global top-k tuples fromall distributed sites with minimum communication cost. Using the well founded notion of theexpected rank of each tuple across all possible worlds as the basis of ranking; this workdesigns both communication-and computation-efficient algorithms for retrieving the top-k …,Proceedings of the 2009 ACM SIGMOD International Conference on Management of data,2009,71
The hardness and approximation algorithms for l-diversity,Xiaokui Xiao; Ke Yi; Yufei Tao,Abstract The existing solutions to privacy preserving publication can be classified into thetheoretical and heuristic categories. The former guarantees provably low information loss;whereas the latter incurs gigantic loss in the worst case; but is shown empirically to performwell on many real inputs. While numerous heuristic algorithms have been developed tosatisfy advanced privacy principles such as l-diversity; t-closeness; etc.; the theoreticalcategory is currently limited to k-anonymity which is the earliest principle known to havesevere vulnerability to privacy attacks. Motivated by this; we present the first theoretical studyon l-diversity; a popular principle that is widely adopted in the literature. First; we show thatoptimal l-diverse generalization is NP-hard even when there are only 3 distinct sensitivevalues in the microdata. Then; an (l· d)-approximation algorithm is developed; where d is …,Proceedings of the 13th International Conference on Extending Database Technology,2010,57
I/O-efficient batched union-find and its applications to terrain analysis,Pankaj K Agarwal; Lars Arge; Ke Yi,Abstract In this article we present an I/O-efficient algorithm for the batched (off-line) versionof the union-find problem. Given any sequence of N union and find operations; where eachunion operation joins two distinct sets; our algorithm uses O (SORT (N)) &equals; O (&frac;NB log M/B &frac; NB) I/Os; where M is the memory size and B is the disk block size. Thisbound is asymptotically optimal in the worst case. If there are union operations that join a setwith itself; our algorithm uses O (SORT (N)+ MST (N)) I/Os; where MST (N) is the number ofI/Os needed to compute the minimum spanning tree of a graph with N edges. We alsodescribe a simple and practical O (SORT (N) log (&frac; NM))-I/O algorithm for this problem;which we have implemented. We are interested in the union-find problem because of itsapplications in terrain analysis. A terrain can be abstracted as a height function defined …,ACM Transactions on Algorithms (TALG),2010,52
Restricted strip covering and the sensor cover problem,Adam L Buchsbaum; Alon Efrat; Shaili Jain; Suresh Venkatasubramanian; Ke Yi,Abstract Suppose we are given a set of objects that cover a region and a durationassociated with each object. Viewing the objects as jobs; can we schedule their beginningtimes to maximize the length of time that the original region remains covered? We call thisproblem the SENSOR COVER PROBLEM. It arises in the context of covering a region withsensors. For example; suppose you wish to monitor activity along a fence (interval) bysensors placed at various fixed locations. Each sensor has a range (also an interval) andlimited battery life. The problem is then to schedule when to turn on the sensors so that thefence is fully monitored for as long as possible. This one-dimensional problem involvesintervals on the real line. Associating a duration to each yields a set of rectangles in spaceand time; each specified by a pair of fixed horizontal endpoints and a height. The …,Proceedings of the eighteenth annual ACM-SIAM symposium on Discrete algorithms,2007,51
Probabilistic string similarity joins,Jeffrey Jestes; Feifei Li; Zhepeng Yan; Ke Yi,Abstract Edit distance based string similarity join is a fundamental operator in stringdatabases. Increasingly; many applications in data cleaning; data integration; and scientificcomputing have to deal with fuzzy information in string attributes. Despite the intensiveefforts devoted in processing (deterministic) string joins and managing probabilistic datarespectively; modeling and processing probabilistic strings is still a largely unexploredterritory. This work studies the string join problem in probabilistic string databases; using theexpected edit distance (EED) as the similarity measure. We first discuss two probabilisticstring models to capture the fuzziness in string values in real-world applications. The string-level model is complete; but may be expensive to represent and process. The character-level model has a much more succinct representation when uncertainty in strings only …,Proceedings of the 2010 ACM SIGMOD International Conference on Management of data,2010,48
Incremental maintenance of XML structural indexes,Ke Yi; Hao He; Ioana Stanoi; Jun Yang,Abstract Increasing popularity of XML in recent years has generated much interest in queryprocessing over graph-structured data. To support efficient evaluation of path expressions;many structural indexes have been proposed. The most popular ones are the 1-index;based on the notion of graph bisimilarity; and the recently proposed A (k)-index; based onthe notion of local similarity to provide a trade-off between index size and query answeringpower. For these indexes to be practical; we need effective and efficient incrementalmaintenance algorithms to keep them consistent with the underlying data. However; existingupdate algorithms for structural indexes essentially provide no guarantees on the quality ofthe index; the updated index is usually larger size than necessary; degrading theperformance for subsequent queries. In this paper; we propose update algorithms for the …,Proceedings of the 2004 ACM SIGMOD international conference on Management of data,2004,48
Multidimensional online tracking,Ke Yi; Qin Zhang,Abstract We propose and study a new class of online problems; which we call onlinetracking. Suppose an observer; say Alice; observes a multivalued function f: Z+ &rightarrow;Z d over time in an online fashion; that is; she only sees f (t) for t≤ t now where t now is thecurrent time. She would like to keep a tracker; say Bob; informed of the current value of f atall times. Under this setting; Alice could send new values of f to Bob from time to time; so thatthe current value of f is always within a distance of Δ to the last value received by Bob. Wegive competitive online algorithms whose communication costs are compared with theoptimal offline algorithm that knows the entire f in advance. We also consider variations ofthe problem where Alice is allowed to send predictions to Bob; to further reducecommunication for well-behaved functions. These online tracking problems have a variety …,ACM Transactions on Algorithms (TALG),2012,46
I/O-efficient construction of constrained Delaunay triangulations,Pankaj K Agarwal; Lars Arge; Ke Yi,Abstract In this paper; we designed and implemented an I/O-efficient algorithm forconstructing constrained Delaunay triangulations. If the number of constraining segments issmaller than the memory size; our algorithm runs in expected O(NB\rmlog_M/BNB) I/Os fortriangulating N points in the plane; where M is the memory size and B is the disk block size.If there are more constraining segments; the theoretical bound does not hold; but in practicethe performance of our algorithm degrades gracefully. Through an extensive set ofexperiments with both synthetic and real data; we show that our algorithm is significantlyfaster than existing implementations.,European Symposium on Algorithms,2005,46
Verifying computations with streaming interactive proofs,Graham Cormode; Justin Thaler; Ke Yi,Abstract When computation is outsourced; the data owner would like to be assured that thedesired computation has been performed correctly by the service provider. In theory; proofsystems can give the necessary assurance; but prior work is not sufficiently scalable orpractical. In this paper; we develop new proof protocols for verifying computations which arestreaming in nature: the verifier (data owner) needs only logarithmic space and a singlepass over the input; and after observing the input follows a simple protocol with a prover(service provider) that takes logarithmic communication spread over a logarithmic number ofrounds. These ensure that the computation is performed correctly: that the service providerhas not made any errors or missed out some data. The guarantee is very strong: even if theservice provider deliberately tries to cheat; there is only vanishingly small probability of …,Proceedings of the VLDB Endowment,2011,44
Randomized algorithms for tracking distributed count; frequencies; and ranks,Zengfeng Huang; Ke Yi; Qin Zhang,Abstract We show that randomization can lead to significant improvements for a fewfundamental problems in distributed tracking. Our basis is the count-tracking problem; wherethere are k players; each holding a counter ni that gets incremented over time; and the goalis to track an∑-approximation of their sum n=∑ ini continuously at all times; using minimumcommunication. While the deterministic communication complexity of the problem is θ (k/ε•log N); where N is the final value of n when the tracking finishes; we show that withrandomization; the communication cost can be reduced to θ (√ k/ε• log N). Our algorithm issimple and uses only O (1) space at each player; while the lower bound holds evenassuming each player has infinite computing power. Then; we extend our techniques to tworelated distributed tracking problems: frequency-tracking and rank-tracking; and obtain …,Proceedings of the 31st ACM SIGMOD-SIGACT-SIGAI symposium on Principles of Database Systems,2012,43
Building wavelet histograms on large data in MapReduce,Jeffrey Jestes; Ke Yi; Feifei Li,Abstract MapReduce is becoming the de facto framework for storing and processingmassive data; due to its excellent scalability; reliability; and elasticity. In many MapReduceapplications; obtaining a compact accurate summary of data is essential. Among variousdata summarization tools; histograms have proven to be particularly important and useful forsummarizing data; and the wavelet histogram is one of the most widely used histograms. Inthis paper; we investigate the problem of building wavelet histograms efficiently on largedatasets in MapReduce. We measure the efficiency of the algorithms by both end-to-endrunning time and communication cost. We demonstrate straightforward adaptations ofexisting exact and approximate methods for building wavelet histograms to MapReduceclusters are highly inefficient. To that end; we design new algorithms for computing exact …,Proceedings of the VLDB Endowment,2011,41
Flexible aggregate similarity search,Yang Li; Feifei Li; Ke Yi; Bin Yao; Min Wang,Abstract Aggregate similarity search; aka aggregate nearest neighbor (Ann) query; findsmany useful applications in spatial and multimedia databases. Given a group Q of M queryobjects; it retrieves the most (or top-k) similar object to Q from a database P; where thesimilarity is an aggregation (eg; sum; max) of the distances between the retrieved object pand all the objects in Q. In this paper; we propose an added flexibility to the query definition;where the similarity is an aggregation over the distances between p and any subset of ÆMobjects in Q for some support 0< Æ d 1. We call this new definition flexible aggregatesimilarity (Fann) search; which generalizes the Ann problem. Next; we present algorithms foranswering Fann queries exactly and approximately. Our approximation algorithms areespecially appealing; which are simple; highly efficient; and work well in both low and …,Proceedings of the 2011 ACM SIGMOD International Conference on Management of data,2011,38
Sampling based algorithms for quantile computation in sensor networks,Zengfeng Huang; Lu Wang; Ke Yi; Yunhao Liu,Abstract We study the problem of computing approximate quantiles in large-scale sensornetworks communication-efficiently; a problem previously studied by Greenwald and Khana[12] and Shrivastava et al [21]. Their algorithms have a total communication cost of O (k log 2n/ε) and O (k log u/ε); respectively; where k is the number of nodes in the network; n is thetotal size of the data sets held by all the nodes; u is the universe size; and ε is the requiredapproximation error. In this paper; we present a sampling based quantile computationalgorithm with O (√ kh/ε) total communication (h is the height of the routing tree); whichgrows sublinearly with the network size except in the pathological case h= Θ (k). In ourexperiments on both synthetic and real data sets; this improvement translates into a 10 to100-fold communication reduction for achieving the same accuracy in the computed …,Proceedings of the 2011 ACM SIGMOD International Conference on Management of data,2011,34
Streaming authenticated data structures,Charalampos Papamanthou; Elaine Shi; Roberto Tamassia; Ke Yi,Abstract We consider the problem of streaming verifiable computation; where both a verifierand a prover observe a stream of n elements x 1; x 2;…; xn and the verifier can laterdelegate some computation over the stream to the prover. The prover must return the outputof the computation; along with a cryptographic proof to be used for verifying the correctnessof the output. Due to the nature of the streaming setting; the verifier can only keep small localstate (eg; logarithmic) which must be updatable in a streaming manner and with nointeraction with the prover. Such constraints make the problem particularly challenging andrule out applying existing verifiable computation schemes. We propose streamingauthenticated data structures; a model that enables efficient verification of data structurequeries on a stream. Compared to previous work; we achieve an exponential …,Annual International Conference on the Theory and Applications of Cryptographic Techniques,2013,30
Top-k queries on temporal data,Feifei Li; Ke Yi; Wangchao Le,Abstract The database community has devoted extensive amount of efforts to indexing andquerying temporal data in the past decades. However; insufficient amount of attention hasbeen paid to temporal ranking queries. More precisely; given any time instance t; the queryasks for the top-k objects at time t with respect to some score attribute. Some genericindexing structures based on R-trees do support ranking queries on temporal data; but asthey are not tailored for such queries; the performance is far from satisfactory. We presentthe Seb-tree; a simple indexing scheme that supports temporal ranking queries much moreefficiently. The Seb-tree answers a top-k query for any time instance t in the optimal numberof I/Os in expectation; namely; $ ${O\left ({\rm log} _B\;\frac {N}{B}+\frac {k}{B}\right)} $ $ I/Os;where N is the size of the data set and B is the disk block size. The index has near-linear …,The VLDB Journal—The International Journal on Very Large Data Bases,2010,26
Tracking distributed aggregates over time-based sliding windows,Graham Cormode; Ke Yi,Abstract The area of distributed monitoring requires tracking the value of a function ofdistributed data as new observations are made. An important case is when attention isrestricted to only a recent time period; such as the last hour of readings—the sliding windowcase. In this paper; we introduce a novel paradigm for handling such monitoring problems;which we dub the “forward/backward” approach. This view allows us to provide optimal ornear-optimal solutions for several fundamental problems; such as counting; trackingfrequent items; and maintaining order statistics. The resulting protocols improve on previouswork or give the first solutions for some problems; and operate efficiently in terms of spaceand time needed. Specifically; we obtain optimal O(kϵ\log(ϵn/k)) communication perwindow of n updates for tracking counts and heavy hitters with accuracy ε across k sites; …,Proceedings of the 30th annual ACM SIGACT-SIGOPS symposium on Principles of distributed computing,2011,23
Wander join: Online aggregation via random walks,Feifei Li; Bin Wu; Ke Yi; Zhuoyue Zhao,Abstract Joins are expensive; and online aggregation over joins was proposed to mitigatethe cost; which offers users a nice and flexible tradeoff between query efficiency andaccuracy in a continuous; online fashion. However; the state-of-the-art approach; in bothinternal and external memory; is based on ripple join; which is still very expensive and evenneeds unrealistic assumptions (eg; tuples in a table are stored in random order). This paperproposes a new approach; the wander join algorithm; to the online aggregation problem byperforming random walks over the underlying join graph. We also design an optimizer thatchooses the optimal plan for conducting the random walks without having to collect anystatistics a priori. Compared with ripple join; wander join is particularly efficient for equalityjoins involving multiple tables; but also supports θ-joins. Selection predicates and group …,Proceedings of the 2016 International Conference on Management of Data,2016,22
An optimal dynamic interval stabbing-max data structure?,Pankaj K Agarwal; Lars Arge; Ke Yi,Abstract In this paper we consider the dynamic stabbing-max problem; that is; the problem ofdynamically maintaining a set S of n axis-parallel hyper-rectangles in R d; where eachrectangle s∈ S has a weight w (s)∈ R; so that the rectangle with the maximum weightcontaining a query point can be determined efficiently. We develop a linear-size structure forthe one-dimensional version of the problem; the interval stabbing-max problem; thatanswers queries in worst-case O (log n) time and supports updates in amortized O (log n)time. Our structure works in the pointer-machine model of computation and utilizes manyingredients from recently developed external memory structures. Using standard techniques;our one-dimensional structure can be extended to higher dimensions; while paying alogarithmic factor in space; update time; and query time per dimension. Furthermore; our …,Proceedings of the sixteenth annual ACM-SIAM symposium on Discrete algorithms,2005,22
Optimal External Memory Planar Point Enclosure,Lars Arge; Vasilis Samoladas; Ke Yi,Abstract In this paper we study the external memory planar point enclosure problem: GivenN axis-parallel rectangles in the plane; construct a data structure on disk (an index) such thatall K rectangles containing a query point can be reported I/O-efficiently. This problem hasimportant applications in eg spatial and temporal databases; and is dual to the importantand well-studied orthogonal range searching problem. Surprisingly; despite the fact that theproblem can be solved optimally in internal memory with linear space and O (log N+ K)query time; we show that one cannot construct a linear sized external memory pointenclosure data structure that can be used to answer a query in O (log BN+ K/B) I/Os; whereB is the disk block size. To obtain this bound; Ω (N/B 1− ε) disk blocks are needed for someconstant ε> 0. With linear space; the best obtainable query bound is O (log 2 N+ K/B) if a …,Algorithmica,2009,21
Enhancing wifi-based localization with visual clues,Han Xu; Zheng Yang; Zimu Zhou; Longfei Shangguan; Ke Yi; Yunhao Liu,Abstract Indoor localization is of great importance to a wide range of applications in the eraof mobile computing. Current mainstream solutions rely on Received Signal Strength (RSS)of wireless signals as fingerprints to distinguish and infer locations. However; those methodssuffer from fingerprint ambiguity that roots in multipath fading and temporal dynamics ofwireless signals. Though pioneer efforts have resorted to motion-assisted or peer-assistedlocalization; they neither work in real time nor work without the help of peer users; whichintroduces extra costs and constraints; and thus degrades their practicality. To get over theselimitations; we propose Argus; an image-assisted localization system for mobile devices.The basic idea of Argus is to extract geometric constraints from crowdsourced photos; and toreduce fingerprint ambiguity by mapping the constraints jointly against the fingerprint …,Proceedings of the 2015 ACM International Joint Conference on Pervasive and Ubiquitous Computing,2015,20
Quantiles over data streams: an experimental study,Lu Wang; Ge Luo; Ke Yi; Graham Cormode,Abstract A fundamental problem in data management and analysis is to generatedescriptions of the distribution of data. It is most common to give such descriptions in termsof the cumulative distribution; which is characterized by the quantiles of the data. The designand engineering of efficient methods to find these quantiles has attracted much study;especially in the case where the data is described incrementally; and we must compute thequantiles in an online; streaming fashion. Yet while such algorithms have proved to betremendously useful in practice; there has been limited formal comparison of the competingmethods; and no comprehensive study of their performance. In this paper; we remedy thisdeficit by providing a taxonomy of different methods; and describe efficient implementations.In doing so; we propose and analyze variations that have not been explicitly studied …,Proceedings of the 2013 ACM SIGMOD International Conference on Management of Data,2013,20
Indexing for summary queries: Theory and practice,Ke Yi; Lu Wang; Zhewei Wei,Abstract Database queries can be broadly classified into two categories: reporting queriesand aggregation queries. The former retrieves a collection of records from the database thatmatch the query's conditions; while the latter returns an aggregate; such as count; sum;average; or max (min); of a particular attribute of these records. Aggregation queries areespecially useful in business intelligence and data analysis applications where users areinterested not in the actual records; but some statistics of them. They can also be executedmuch more efficiently than reporting queries; by embedding properly precomputedaggregates into an index. However; reporting and aggregation queries provide only twoextremes for exploring the data. Data analysts often need more insight into the datadistribution than what those simple aggregates provide; and yet certainly do not want the …,ACM Transactions on Database Systems (TODS),2014,19
A dynamic data structure for top-k queries on uncertain data,Jiang Chen; Ke Yi,Abstract In an uncertain data set S=(S; p; f) where S is the ground set consisting of nelements; p: S→[0; 1] a probability function; and f: S→ R a score function; each element i∈ Swith score f (i) appears independently with probability p (i). The top-k query on S asks for theset of k elements that has the maximum probability of appearing to be the k elements withthe highest scores in a random instance of S. Computing the top-k answer on a fixed S isknown to be easy. In this paper; we consider the dynamic problem; that is; how to maintainthe top-k query answer when S changes; including element insertions and deletions in theground set S; changes in the probability function p and in the score function f. We present afully dynamic data structure that handles an update in O (k log n) time; and answers a top-jquery in O (log n+ j) time for any j≤ k. The structure has O (n) size and can be constructed …,Theoretical Computer Science,2008,18
I/O-efficient structures for orthogonal range-max and stabbing-max queries,Pankaj K Agarwal; Lars Arge; Jun Yang; Ke Yi,Abstract We develop several linear or near-linear space and I/O-efficient dynamic datastructures for orthogonal range-max queries and stabbing-max queries. Given a set of Nweighted points in ℝ d; the range-max problem asks for the maximum-weight point in aquery hyper-rectangle. In the dual stabbing-max problem; we are given N weighted hyper-rectangles; and we wish to find the maximum-weight rectangle containing a query point. Ourstructures improve on previous structures in several important ways.,European Symposium on Algorithms,2003,18
Renewable energy transmission through multiple routes in a mobile electrical grid,Ping Yi; Yixiong Tang; Yijie Hong; Yuzhe Shen; Ting Zhu; Qingquan Zhang; Miroslav M Begovic,Vehicle-to-Grid (V2G) technology utilizes the stored energy in electric vehicle batteries tocontribute electricity back to the grid. The energy in batteries can move with electric vehicles(EVs). Combining V2G and the mobility of vehicles; EVs can provide a natural energytransmission architecture called mobile electrical grid. The main idea of this paper focuseson multiple energy transmission route in mobile electrical grid from solar energy sources toplaces as capacity of every energy route is limited. The features of energy route in mobileelectrical grid are analyzed and a minimum cost flow algorithm is presented. Simulationsusing real-world transporting data in Manhattan. Simulations show that this method isefficient.,Innovative Smart Grid Technologies Conference (ISGT); 2014 IEEE PES,2014,17
Interactive proof to validate outsourced data stream processing,*,A method for validating outsourced processing of a data stream arriving at a streaming datawarehouse of a data service provider includes a proof protocol. A verifier acting on behalf ofa data owner of the data stream may interact with a prover acting on behalf of the dataservice provider. The verifier may calculate a first root hash value of a binary tree duringsingle-pass processing of the original data stream with limited computational effort. Asecond root hash value may be calculated using the proof protocol between the verifier andthe prover. The prover is requested to provide certain queried values before receivingrandom numbers used to generate subsequent responses dependent on the providedvalues. The proof protocol may be used to validate the data processing performed by thedata service provider.,*,2013,17
Methods and apparatus for ranking uncertain data in a probabilistic database,*,Methods and apparatus for ranking uncertain data in a probabilistic database are disclosed.An example method disclosed herein comprises using a set of data tuples representing aplurality of possible data set instantiations associated with a respective plurality ofinstantiation probabilities to store non-deterministic data in a database; each data tuplecorresponding to a set of possible data tuple instantiations; each data set instantiationrealizable by selecting a respective data tuple instantiation for at least some of the datatuples; the method further comprising determining an expected rank for each data tupleincluded in at least a subset of the set of data tuples; the expected rank for a particular datatuple representing a combination of weighted component ranks of the particular data tuple;each component rank representing a ranking of the data tuple in a corresponding data set …,*,2014,16
Clustering with diversity,Jian Li; Ke Yi; Qin Zhang,Abstract We consider the clustering with diversity problem: given a set of colored points in ametric space; partition them into clusters such that each cluster has at least ℓ points; all ofwhich have distinct colors. We give a 2-approximation to this problem for any ℓ when theobjective is to minimize the maximum radius of any cluster. We show that the approximationratio is optimal unless P= NP; by providing a matching lower bound. Several extensions toour algorithm have also been developed for handling outliers. This problem is mainlymotivated by applications in privacy-preserving data publication.,International Colloquium on Automata; Languages; and Programming,2010,16
Dynamic external hashing: The limit of buffering,Zhewei Wei; Ke Yi; Qin Zhang,Abstract Hash tables are one of the most fundamental data structures in computer science;in both theory and practice. They are especially useful in external memory; where their queryperformance approaches the ideal cost of just one disk access. Knuth [16] gave an elegantanalysis showing that with some simple collision resolution strategies such as linear probingor chaining; the expected average number of disk I/Os of a lookup is merely 1+ 1/2 Ω (b);where each I/O can read and/or write a disk block containing b items. Inserting a new iteminto the hash table also costs 1+ 1/2 Ω (b) I/Os; which is again almost the best one can do ifthe hash table is entirely stored on disk. However; this requirement is unrealistic since anyalgorithm operating on an external hash table must have some internal memory (at least Ω(1) blocks) to work with. The availability of a small internal memory buffer can dramatically …,Proceedings of the twenty-first annual symposium on Parallelism in algorithms and architectures,2009,16
Optimal sampling algorithms for frequency estimation in distributed data,Zengfeng Huang; Ke Yi; Guihai Chen,Consider a distributed system with n nodes where each node holds a multiset of items. Inthis paper; we design sampling algorithms that allow us to estimate the global frequency ofany item with a standard deviation of εN; where N denotes the total cardinality of all thesemultisets. Our algorithms have a communication cost of O (n+√ n/ε); which is never worsethan the O (n+ 1/ε 2) cost of uniform sampling; and could be much better when n≪ 1/ε 2. Inaddition; we prove that one version of our algorithm is instance-optimal in a fairly generalsampling framework. We also design algorithms that achieve optimality on the bit level; bycombining Bloom filters of various granularities. Finally; we present some simulation resultscomparing our algorithms with previous techniques. Other than the performanceimprovement; our algorithms are also much simpler and easily implementable in a large …,INFOCOM; 2011 Proceedings IEEE,2011,14
Correlation hiding by independence masking,Yufei Tao; Jian Pei; Jiexing Li; Xiaokui Xiao; Ke Yi; Zhengzheng Xing,Extracting useful correlation from a dataset has been extensively studied. In this paper; wedeal with the opposite; namely; a problem we call correlation hiding (CH); which isfundamental in numerous applications that need to disseminate data containing sensitiveinformation. In this problem; we are given a relational table T whose attributes can beclassified into three disjoint sets A; B; and C. The objective is to distort some values in T sothat A becomes independent from B; and yet; their correlation with C is preserved as muchas possible. CH is different from all the problems studied previously in the area of dataprivacy; in that CH demands complete elimination of the correlation between two sets ofattributes; whereas the previous research focuses on partial elimination up to a certain level.A new operator called independence masking is proposed to solve the CH problem …,Data Engineering (ICDE); 2010 IEEE 26th International Conference on,2010,14
Voice over the dins: improving wireless channel utilization with collision tolerance,Xiaoyu Ji; Yuan He; Jiliang Wang; Kaishun Wu; Ke Yi; Yunhao Liu,Packet corruption caused by collision is a critical problem that hurts the performance ofwireless networks. Conventional medium access control (MAC) protocols resort to collisionavoidance to maintain acceptable efficiency of channel utilization. According to ourinvestigation and observation; however; collision avoidance comes at the cost ofmiscellaneous overhead; which oppositely hurts channel utilization; not to mention the poorresiliency and performance of those protocols in face of dense networks or intensive traffic.Discovering the ability to tolerate collisions at the physical layer implementations of wirelessnetworks; we in this paper propose Coco; a MAC protocol that advocates simultaneousaccesses from multiple senders to a shared channel; ie; optimistically allowing collisionsinstead of simply avoiding them. With a simple but effective design; Coco addresses the …,Network Protocols (ICNP); 2013 21st IEEE International Conference on,2013,13
Method and apparatus for monitoring functions of distributed data,*,A method and system of monitoring computer network activity including determining a firstphase frequency estimate; associated with a first frequency vector; determined in responseto receiving first bits from a first plurality of remote computer network devices. The first bitsreceived from the first plurality of remote devices in response to satisfying a first activitythreshold. Also; determining a second phase frequency estimate associated with a secondfrequency vector and determined in response to receiving second bits from a secondplurality of remote devices. The second bits received from the second plurality of remotedevices in response to a second activity threshold being satisfied. The second phasefrequency estimate determined in response to the first phase frequency estimate exceedinga global threshold. Further; providing a frequency moment Fp in response to the second …,*,2013,12
Efficient external memory structures for range-aggregate queries,Pankaj K Agarwal; Lars Arge; Sathish Govindarajan; Jun Yang; Ke Yi,Abstract We present external memory data structures for efficiently answering range-aggregate queries. The range-aggregate problem is defined as follows: Given a set ofweighted points in R d; compute the aggregate of the weights of the points that lie inside a d-dimensional orthogonal query rectangle. The aggregates we consider in this paper includecount; sum; and max. First; we develop a structure for answering two-dimensional range-count queries that uses O (N/B) disk blocks and answers a query in O (log BN) I/Os; where Nis the number of input points and B is the disk block size. The structure can be extended toobtain a near-linear-size structure for answering range-sum queries using O (log BN) I/Os;and a linear-size structure for answering range-max queries in O (log B 2 N) I/Os. Ourstructures can be made dynamic and extended to higher dimensions.,Computational Geometry,2013,11
Spatial online sampling and aggregation,Lu Wang; Robert Christensen; Feifei Li; Ke Yi,Abstract The massive adoption of smart phones and other mobile devices has generatedhumongous amount of spatial and spatio-temporal data. The importance of spatial analyticsand aggregation is ever-increasing. An important challenge is to support interactiveexploration over such data. However; spatial analytics and aggregation using all data pointsthat satisfy a query condition is expensive; especially over large data sets; and could notmeet the needs of interactive exploration. To that end; we present novel indexing structuresthat support spatial online sampling and aggregation on large spatial and spatio-temporaldata sets. In spatial online sampling; random samples from the set of spatial (or spatio-temporal) points that satisfy a query condition are generated incrementally in an onlinefashion. With more and more samples; various spatial analytics and aggregations can be …,Proceedings of the VLDB Endowment,2015,10
An optimal dynamic data structure for stabbing-semigroup queries,Pankaj K Agarwal; Lars Arge; Haim Kaplan; Eyal Molad; Robert E Tarjan; Ke Yi,Let S be a set of n intervals in R; and let (S;+) be any commutative semigroup. We assign aweight ω(s)∈S to each interval in S. For a point x∈R; let S(x)⊆S be the set of intervals thatcontain x. Given a point q∈R; the stabbing-semigroup query asks for computings∈S(q)ω(s). We propose a linear-size dynamic data structure; under the pointer-machinemodel; that answers queries in worst-case O(\logn) time and supports both insertions anddeletions of intervals in amortized O(\logn) time. It is the first data structure that attains theoptimal O(\logn) bound for all three operations. Furthermore; our structure can easily beadapted to external memory; where we obtain a linear-size structure that answers queriesand supports updates in O(\log_Bn) I/Os; where B is the disk block size. For the restrictedcase of a nested family of intervals (either every pair of intervals is disjoint or one contains …,SIAM Journal on Computing,2012,10
The world in a nutshell: Concise range queries,Ke Yi; Xiang Lian; Feifei Li; Lei Chen,With the advance of wireless communication technology; it is quite common for people toview maps or get related services from the handheld devices; such as mobile phones andPDAs. Range queries; as one of the most commonly used tools; are often posed by theusers to retrieve needful information from a spatial database. However; due to the limits ofcommunication bandwidth and hardware power of handheld devices; displaying all theresults of a range query on a handheld device is neither communication-efficient norinformative to the users. This is simply because that there are often too many resultsreturned from a range query. In view of this problem; we present a novel idea that a conciserepresentation of a specified size for the range query results; while incurring minimalinformation loss; shall be computed and returned to the user. Such a concise range query …,Knowledge and Data Engineering; IEEE Transactions on,2011,10
Research directions for principles of data management (abridged),Serge Abiteboul; Marcelo Arenas; Pablo Barceló; Meghyn Bienvenu; Diego Calvanese; Claire David; Richard Hull; Eyke Hüllermeier; Benny Kimelfeld; Leonid Libkin; Wim Martens; Tova Milo; Filip Murlak; Frank Neven; Magdalena Ortiz; Thomas Schwentick; Julia Stoyanovich; Jianwen Su; Dan Suciu; Victor Vianu; Ke Yi,In April 2016; a community of researchers working in the area of Principles of DataManagement (PDM) joined in a workshop at the Dagstuhl Castle in Germany. The workshopwas organized jointly by the Executive Committee of the ACM Symposium on Principles ofDatabase Systems (PODS) and the Council of the International Conference on DatabaseTheory (ICDT). The mission of the workshop was to identify and explore some of the mostimportant research directions that have high relevance to society and to Computer Sciencetoday; and where the PDM community has the potential to make significant contributions.This article presents a summary of the report created by the workshop [4]. That reportdescribes the family of research directions that the workshop focused on from threeperspectives: potential practical relevance; results already obtained; and research …,ACM SIGMOD Record,2017,9
On the cell probe complexity of dynamic membership,Ke Yi; Qin Zhang,Abstract We study the dynamic membership problem; one of the most fundamental datastructure problems; in the cell probe model with an arbitrary cell size. We consider a cellprobe model equipped with a cache that consists of at least a constant number of cells;reading or writing the cache is free of charge. For nearly all common data structures; it isknown that with sufficiently large cells together with the cache; we can significantly lower theamortized update cost to o (1). In this paper; we show that this is not the case for the dynamicmembership problem. Specifically; for any deterministic membership data structure under arandom input sequence; if the expected average query cost is no more than 1+ δ for somesmall constant δ; we prove that the expected amortized update cost must be at least Ω (1);namely; it does not benefit from large block writes (and a cache). The space the structure …,Proceedings of the twenty-first annual ACM-SIAM symposium on Discrete algorithms,2010,9
Lexicographically optimal smoothing for broadband traffic multiplexing,Stergios Anastasiadis; Peter Varman; Jeffrey Scott Vitter; Ke Yi,Abstract We investigate the problem of smoothing multiplexed network traffic; when either astreaming server transmits data to multiple clients; or a server accesses data from multiplestorage devices or other servers. We introduce efficient algorithms for lexicographicallyoptimally smoothing the aggregate bandwidth requirements over a shared network link. Inthe data transmission problem; we consider the case in which the clients have differentbuffer capacities but no bandwidth constraints; or no buffer capacities but differentbandwidth constraints. For the data access problem; we handle the general case of a sharedbuffer capacity and individual network bandwidth constraints. Previous approaches in theliterature for the data access problem handled either the case of only a single stream or didnot compute the lexicographically optimal schedule. Lexicographically optimal smoothing …,Proceedings of the twenty-first annual symposium on Principles of distributed computing,2002,8
Indoor localization via multi-modal sensing on smartphones,Han Xu; Zheng Yang; Zimu Zhou; Longfei Shangguan; Ke Yi; Yunhao Liu,Abstract Indoor localization is of great importance to a wide range of applications inshopping malls; office buildings and public places. The maturity of computer vision (CV)techniques and the ubiquity of smartphone cameras hold promise for offering sub-meteraccuracy localization services. However; pure CV-based solutions usually involve hundredsof photos and pre-calibration to construct image database; a labor-intensive overhead forpractical deployment. We present ClickLoc; an accurate; easy-to-deploy; sensor-enriched;image-based indoor localization system. With core techniques rooted in semanticinformation extraction and optimization-based sensor data fusion; ClickLoc is able tobootstrap with few images. Leveraging sensor-enriched photos; ClickLoc also enables userlocalization with a single photo of the surrounding place of interest (POI) with high …,Proceedings of the 2016 ACM International Joint Conference on Pervasive and Ubiquitous Computing,2016,7
Persistent data sketching,Zhewei Wei; Ge Luo; Ke Yi; Xiaoyong Du; Ji-Rong Wen,Abstract A persistent data structure; also known as a multiversion data structure in thedatabase literature; is a data structure that preserves all its previous versions as it is updatedover time. Every update (inserting; deleting; or changing a data record) to the data structurecreates a new version; while all the versions are kept in the data structure so that anyprevious version can still be queried. Persistent data structures aim at recording all versionsaccurately; which results in a space requirement that is at least linear to the number ofupdates. In many of today's big data applications; in particular for high-speed streamingdata; the volume and velocity of the data are so high that we cannot afford to storeeverything. Therefore; streaming algorithms have received a lot of attention in the researchcommunity; which use only sublinear space by sacrificing slightly on accuracy.,Proceedings of the 2015 ACM SIGMOD International Conference on Management of Data,2015,7
Piecewise linear approximation of streaming time series data with max-error guarantees,Ge Luo; Ke Yi; Siu-Wing Cheng; Zhenguo Li; Wei Fan; Cheng He; Yadong Mu,Given a time series S=((x 1; y 1);(x 2; y 2);...) and a prescribed error bound ε; the piecewiselinear approximation (PLA) problem with max-error guarantees is to construct a piecewiselinear function f such that| f (xi)-yi|≤ ε for all i. In addition; we would like to have an onlinealgorithm that takes the time series as the records arrive in a streaming fashion; and outputsthe pieces of f on-the-fly. This problem has applications wherever time series data is beingcontinuously collected; but the data collection device has limited local buffer space andcommunication bandwidth; so that the data has to be compressed and sent back during thecollection process. Prior work addressed two versions of the problem; where either f consistsof disjoint segments; or f is required to be a continuous piecewise linear function. In bothcases; existing algorithms can produce a function f that has the minimum number of …,Data Engineering (ICDE); 2015 IEEE 31st International Conference on,2015,7
Counting triangles in large graphs by random sampling,Bin Wu; Ke Yi; Zhenguo Li,The problem of counting triangles in graphs has been well studied in the literature. However;all existing algorithms; exact or approximate; spend at least linear time in the size of thegraph (except a recent theoretical result); which can be prohibitive on today's large graphs.Nevertheless; we observe that the ideas in many existing triangle counting algorithms canbe coupled with random sampling to yield potentially sublinear-time algorithms that returnan approximation of the triangle count without looking at the whole graph. This paper makesthese random sampling algorithms more explicit; and presents an experimental andanalytical comparison of different approaches; identifying the best performers among anumber of candidates.,IEEE Transactions on Knowledge and Data Engineering,2016,6
Cache-oblivious hashing,Rasmus Pagh; Zhewei Wei; Ke Yi; Qin Zhang,Abstract The hash table; especially its external memory version; is one of the most importantindex structures in large databases. Assuming a truly random hash function; it is known thatin a standard external hash table with block size b; searching for a particular key only takesexpected average t_q= 1+ 1/2 Ω (b) disk accesses for any load factor α bounded away from$1 $. However; such near-perfect performance is achieved only when b is known and thehash table is particularly tuned for working with such a blocking. In this paper we study if it ispossible to build a cache-oblivious hash table that works well with any blocking. Such ahash table will automatically perform well across all levels of the memory hierarchy anddoes not need any hardware-specific tuning; an important feature in autonomous databases.We first show that linear probing; a classical collision resolution strategy for hash tables …,Proceedings of the twenty-ninth ACM SIGMOD-SIGACT-SIGART symposium on Principles of database systems,2010,6
STORM: Spatio-temporal online reasoning and management of large spatio-temporal data,Robert Christensen; Lu Wang; Feifei Li; Ke Yi; Jun Tang; Natalee Villa,Abstract We present the STORM system to enable spatio-temporal online reasoning andmanagement of large spatio-temporal data. STORM supports interactive spatio-temporalanalytics through novel spatial online sampling techniques. Online spatio-temporalaggregation and analytics are then derived based on the online samples; whereapproximate answers with approximation quality guarantees can be provided immediatelyfrom the start of query execution. The quality of these online approximations improve overtime. This demonstration proposal describes key ideas in the design of the STORM system;and presents the demonstration plan.,Proceedings of the 2015 ACM SIGMOD International Conference on Management of Data,2015,5
Logging every footstep: Quantile summaries for the entire history,Yufei Tao; Ke Yi; Cheng Sheng; Jian Pei; Feifei Li,Abstract Quantiles are a crucial type of order statistics in databases. Extensive research hasbeen focused on maintaining a space-efficient structure for approximate quantilecomputation as the underlying dataset is updated. The existing solutions; however; aredesigned to support only the current; most-updated; snapshot of the dataset. Queries on thepast versions of the data cannot be answered. This paper studies the problem of historicalquantile search. The objective is to enable ε-approximate quantile retrieval on any snapshotof the dataset in history. The problem is very important in analyzing the evolution of adistribution; monitoring the quality of services; query optimization in temporal databases;and so on. We present the first formal results in the literature. First; we prove a noveltheoretical lower bound on the space cost of supporting ε-approximate historical quantile …,Proceedings of the 2010 ACM SIGMOD International Conference on Management of data,2010,5
Cache-oblivious hashing,Rasmus Pagh; Zhewei Wei; Ke Yi; Qin Zhang,Abstract The hash table; especially its external memory version; is one of the most importantindex structures in large databases. Assuming a truly random hash function; it is known thatin a standard external hash table with block size b; searching for a particular key only takesexpected average tq= 1+ 1/2 Ω (b) disk accesses for any load factor α bounded away from 1.However; such near-perfect performance is achieved only when b is known and the hashtable is particularly tuned for working with such a blocking. In this paper we study if it ispossible to build a cache-oblivious hash table that works well with any blocking. Such ahash table will automatically perform well across all levels of the memory hierarchy anddoes not need any hardware-specific tuning; an important feature in autonomous databases.We first show that linear probing; a classical collision resolution strategy for hash tables …,Algorithmica,2014,4
Approximate Range Searching in External Memory,Micha Streppel; Ke Yi,Abstract In this paper; we present two linear-size external memory data structures forapproximate range searching. Our first structure; the BAR-B-tree; stores a set of N points in ℝd and can report all points inside a query range Q by accessing O (log BN+ ε γ+ k ε/B) diskblocks; where B is the disk block size; γ= 1− d for convex queries and γ=− d otherwise; and kε is the number of points lying within a distance of ε⋅ diam (Q) to the query range Q. Oursecond structure; the object-BAR-B-tree; is able to store objects of arbitrary shapes ofconstant complexity and provides similar query guarantees. In addition; both structures cansupport other types of range searching queries such as range aggregation and nearest-neighbor. Finally; we present I/O-efficient algorithms to build these structures.,Algorithmica,2011,4
Dynamic indexability and lower bounds for dynamic one-dimensional range query indexes,Ke Yi,Abstract The B-tree is a fundamental external index structure that is widely used foranswering one-dimensional range reporting queries. Given a set of N keys; a range querycan be answered in O (log B NoverM+ KoverB) I/Os; where B is the disk block size; K theoutput size; and M the size of the main memory buffer. When keys are inserted or deleted;the B-tree is updated in O (log BN) I/Os; if we require the resulting changes to be committedto disk right away. Otherwise; the memory buffer can be used to buffer the recent updates;and changes can be written to disk in batches; which significantly lowers the amortizedupdate cost. A systematic way of batching up updates is to use the logarithmic method;combined with fractional cascading; resulting in a dynamic B-tree that supports insertions inO (1overB log NoverM) I/Os and queries in O (log NoverM+ KoverB) I/Os. Such bounds …,Proceedings of the twenty-eighth ACM SIGMOD-SIGACT-SIGART symposium on Principles of database systems,2009,4
Two-Level Sampling for Join Size Estimation,Yu Chen; Ke Yi,Abstract Join size estimation is a critical step in query optimization; and has beenextensively studied in the literature. Among the many techniques; sampling basedapproaches are particularly appealing; due to their ability to handle arbitrary selectionpredicates. In this paper; we propose a new sampling algorithm for join size estimation;called two-level sampling; which combines the advantages of three previous samplingmethods while making further improvements. Both analytical and empirical comparisonsshow that the new algorithm outperforms all the previous algorithms on a variety of joins;including primary key-foreign key joins; many-to-many joins; and multi-table joins. The newsampling algorithm is also very easy to implement; requiring just one pass over the data. Itonly relies on some basic statistical information about the data; such as the ℓ k-norms and …,Proceedings of the 2017 ACM International Conference on Management of Data,2017,3
On improving wireless channel utilization: A collision tolerance-based approach,Xiaoyu Ji; Yuan He; Jiliang Wang; Kaishun Wu; Daibo Liu; Ke Yi; Yunhao Liu,Packet corruption caused by collision is a critical problem that hurts the performance ofwireless networks. Conventional medium access control (MAC) protocols resort to collisionavoidance to maintain acceptable efficiency of channel utilization. According to ourinvestigation and observation; however; collision avoidance comes at the cost ofmiscellaneous overhead; which oppositely hurts channel utilization; not to mention the poorresiliency and performance of those protocols in face of dense networks or intensive traffic.Discovering the ability to tolerate collisions at the physical layer implementations of wirelessnetworks; we in this paper propose Coco; a protocol that advocates simultaneous accessesfrom multiple senders to a shared channel; ie; optimistically allowing collisions instead ofsimply avoiding them. With a simple but effective design; Coco addresses the key …,IEEE Transactions on Mobile Computing,2017,3
Wander join: online aggregation for joins,Feifei Li; Bin Wu; Ke Yi; Zhuoyue Zhao,Abstract Joins are expensive; and online aggregation over joins was proposed to mitigatethe cost; which offers a nice and flexible tradeoff between query efficiency and accuracy in acontinuous; online fashion. However; the state-of-the-art approach; in both internal andexternal memory; is based on ripple join; which is still very expensive and may also needvery restrictive assumptions (eg; tuples in a table are stored in random order). We introducea new approach; wander join; to the online aggregation problem by performing randomwalks over the underlying join graph. We have also implemented and tested wander join inthe latest PostgreSQL.,Proceedings of the 2016 International Conference on Management of Data,2016,3
The space complexity of 2-dimensional approximate range counting,Zhewei Wei; Ke Yi,Abstract We study the problem of 2-dimensional orthogonal range counting with additiveerror. Given a set P of n points drawn from an nxn grid and an error parameter ε; the goal isto build a data structure; such that for any orthogonal range R; the data structure can returnthe number of points in P∩ R with additive error εn. A well-known solution for this problem isthe ε-approximation. Informally speaking; an ε-approximation of P is a subset A⊆ P thatallows us to estimate the number of points in P∩ R by counting the number of points in A∩R. It is known that an ε-approximation of size O (1/ε log 2.5 1/ε) exists for any P with respectto orthogonal ranges; and the best lower bound is Ω (1/ε log 1/ε). The ε-approximation is arather restricted data structure; as we are not allowed to store any information other than thecoordinates of a subset of points in P. In this paper; we explore what can be achieved …,Proceedings of the twenty-fourth annual ACM-SIAM symposium on Discrete algorithms,2013,3
Optimal lexicographic shaping of aggregate streaming data,Stergios V Anastasiadis; Peter Varman; Jeffrey Scott Vitter; Ke Yi,We investigate the problem of smoothing multiplexed network traffic when either a streamingserver transmits data to multiple clients or a storage server accesses data from multiplestorage devices or other servers. We introduce efficient algorithms for lexicographicallyoptimally smoothing the aggregate bandwidth requirements over a shared network link.Possible applications include improvement in the bandwidth utilization of network links andreduction in the energy consumption of server hosts. In the data transmission problem; weconsider the case in which the clients have different buffer capacities and unlimitedbandwidth constraints or unlimited buffer capacities and different bandwidth constraints. Forthe data access problem; we handle the general case of a shared buffer capacity andindividual network bandwidth constraints. Previous approaches for the data access …,Computers; IEEE Transactions on,2005,3
Brief Announcement: Tracking Distributed Aggregates over Time-based Sliding Windows,Graham Cormode; Ke Yi,ABSTRACT The area of distributed monitoring requires tracking the value of a function ofdistributed data as new observations are made. An important case is when attention isrestricted to only a recent time period; such as the last hour of readings—the sliding windowcase. In this announcement; we outline a novel paradigm for handling such monitoringproblems; which we dub the “forward/backward” approach. This provides clean solutions forseveral fundamental problems; such as counting; tracking frequent items; and maintainingorder statistics. We obtain efficient protocols for these problems that improve on previouswork; and are easy to implement. Specifically; we obtain optimal O (k ε log (εn/k))communication per window of n updates for tracking counts and heavy hitters with accuracyε across k sites; and near-optimal communication of O (k ε log2 (1/ε) log (n/k)) for …,PODC,*,3
Output-optimal Parallel Algorithms for Similarity Joins,Xiao Hu; Yufei Tao; Ke Yi,Abstract Parallel join algorithms have received much attention in recent years; due to therapid development of massively parallel systems such as MapReduce and Spark. In thedatabase theory community; most efforts have been focused on studying worst-optimalalgorithms. However; the worst-case optimality of these join algorithms relies on the hardinstances having very large output sizes. In the case of a two-relation join; the hard instanceis just a Cartesian product; with an output size that is quadratic in the input size. In practice;however; the output size is usually much smaller. One recent parallel join algorithm byBeame et al.[8] has achieved output-optimality; ie; its cost is optimal in terms of both the inputsize and the output size; but their algorithm only works for a 2-relation equi-join; and hassome imperfections. In this paper; we first improve their algorithm to true optimality. Then …,Proceedings of the 36th ACM SIGMOD-SIGACT-SIGAI Symposium on Principles of Database Systems,2017,2
Towards a Worst-Case I/O-Optimal Algorithm for Acyclic Joins,Xiao Hu; Ke Yi,Abstract Nested-loop join is a worst-case I/O-optimal algorithm for 2 relations. Recently; a lotof efforts have been devoted to the" triangle query"; for which an I/O-optimal algorithm isknown. This paper extends these results to a fairly large class of acyclic joins. Acyclic joinscan be computed optimally in internal memory using Yannakakis' algorithm from 1981;which simply performs a series of pairwise joins. However; no pairwise join algorithm can beI/O-optimal beyond 2 relations. To achieve I/O-optimality; the algorithm has to handle all theintermediate results carefully without writing them to disk. Unlike the optimal internal memoryjoin algorithm which has a nice tight bound (the AGM bound); the I/O-complexity of joinsturns out to be quite complex or even unknown. Yet; we are able to prove that our algorithmis I/O-optimal for certain classes of acyclic joins without deriving its bound explicitly.,Proceedings of the 35th ACM SIGMOD-SIGACT-SIGAI Symposium on Principles of Database Systems,2016,2
Exact and approximate flexible aggregate similarity search,Feifei Li; Ke Yi; Yufei Tao; Bin Yao; Yang Li; Dong Xie; Min Wang,Abstract Aggregate similarity search; also known as aggregate nearest-neighbor (Ann)query; finds many useful applications in spatial and multimedia databases. Given a group Qof M query objects; it retrieves from a database the objects most similar to Q; where thesimilarity is an aggregation (eg; sum sum;\max max) of the distances between each retrievedobject p and all the objects in Q. In this paper; we propose an added flexibility to the querydefinition; where the similarity is an aggregation over the distances between p and anysubset of ϕ M ϕ M objects in Q for some support 0< ϕ ≤ 1 0< ϕ≤ 1. We call this newdefinition flexible aggregate similarity search and accordingly refer to a query as a flexibleaggregate nearest-neighbor (Fann) query. We present algorithms for answering Fannqueries exactly and approximately. Our approximation algorithms are especially …,The VLDB Journal,2016,2
Equivalence between priority queues and sorting in external memory,Zhewei Wei; Ke Yi,Abstract A priority queue is a fundamental data structure that maintains a dynamic orderedset of keys and supports the followig basic operations: insertion of a key; deletion of a key;and finding the smallest key. The complexity of the priority queue is closely related to that ofsorting: A priority queue can be used to implement a sorting algorithm trivially. Thorup [11]proved that the converse is also true in the RAM model. In particular; he designed a priorityqueue that uses the sorting algorithm as a black box; such that the per-operation cost of thepriority queue is asymptotically the same as the per-key cost of sorting. In this paper; weprove an analogous result in the external memory model; showing that priority queues arecomputationally equivalent to sorting in external memory; under some mild assumptions.The reduction provides a possibility for proving lower bounds for external sorting via …,European Symposium on Algorithms,2014,2
Randomized synopses for query verification on data streams,K Yi; F Li; Marios Hadjieleftheriou; D Srivastava; G Kollios,ABSTRACT Due to the overwhelming flow of information in many data stream applications;many companies may not be willing to acquire the necessary resources for deploying a DataStream Management System (DSMS); choosing; alternatively; to outsource the data streamand the desired computations to a third-party. But data outsourcing and remotecomputations intrinsically raise issues of trust; making outsourced query verification on datastreams a problem with important practical implications. Consider a setting where acontinuous “GROUP BY; SUM” query is processed using a remote; untrusted server. A clientwith limited processing capabilities observing exactly the same stream as the server;registers the query on the server's DSMS and receives results upon request. The clientwants to verify the integrity of the results using significantly fewer resources than …,AT&T Labs Inc.; Tech. Rep,2007,2
Quantiles over data streams: experimental comparisons; new analyses; and further improvements,Ge Luo; Lu Wang; Ke Yi; Graham Cormode,Abstract A fundamental problem in data management and analysis is to generatedescriptions of the distribution of data. It is most common to give such descriptions in termsof the cumulative distribution; which is characterized by the quantiles of the data. The designand engineering of efficient methods to find these quantiles has attracted much study;especially in the case where the data are given incrementally; and we must compute thequantiles in an online; streaming fashion. While such algorithms have proved to beextremely useful in practice; there has been limited formal comparison of the competingmethods; and no comprehensive study of their performance. In this paper; we remedy thisdeficit by providing a taxonomy of different methods and describe efficient implementations.In doing so; we propose new variants that have not been studied before; yet which …,The VLDB Journal,2016,1
The priority R-tree,Ke Yi,Window queries. Let S be a set of N axis-parallel hypercubes in Rd. A very basic operationin a spatial database is to answer window queries on the set S. A window query Q is also anaxis-parallel hypercube in Rd that asks us to return all hypercubes in S that intersect Q.Since the set S is typically huge in a large spatial database; the goal is to design a disk-based; or external memory data structure (often called an index in the database literature)such that these window queries can be answered efficiently. In addition; given S; the datastructure should be constructed efficiently; and should be able to support insertions anddeletions of objects. R-trees. The R-tree; first proposed by Guttman [8]; is a multi-way tree T;very similar to a B-tree; that is used to store the set S such that a window query can beanswered efficiently. Each node of T fits in one disk block. The hypercubes of S are stored …,SIGSPATIAL Special,2012,1
Proceedings of the ACM SIGMOD International Conference on Management of Data: Foreword,Gautam Das; Bing Liu; S Yu Philip,Das; G; Liu; B & Yu; PS 2004; Proceedings of the ACM SIGMOD International Conference onManagement of Data: Foreword. in Proceedings of the ACM SIGMOD International Conferenceon Management of Data. 9th Workshop on Research Issues in Data Mining and KnowledgeDiscovery; DMKD 2004; In Conjunction with ACM SIGMOD International Conference on Managementof Data; SIGMOD-04; Paris; France; 6/13/04 … Das G; Liu B; Yu PS. Proceedings of the ACMSIGMOD International Conference on Management of Data: Foreword. In Proceedings of theACM SIGMOD International Conference on Management of Data. 2004 … Das; Gautam ;Liu; Bing ; Yu; Philip S./ Proceedings of the ACM SIGMOD International Conference on Managementof Data : Foreword. Proceedings of the ACM SIGMOD International Conference on Managementof Data. 2004 … Powered by Pure; Scopus & Elsevier Fingerprint Engine™ © 2017 …,9th Workshop on Research Issues in Data Mining and Knowledge Discovery; DMKD 2004; In Conjunction with ACM SIGMOD International Conference on Management of Data; SIGMOD-04,2004,1
Random Sampling over Joins Revisited,Zhuoyue Zhao; Robert Christensen; Feifei Li; Xiao Hu; Ke Yi,ABSTRACT Joins are expensive; especially on large data and/or multiple relations. Onepromising approach in mitigating their high costs is to just return a simple random sample ofthe full join results; which is sufficient for many tasks. Indeed; in as early as 1999; Chaudhuriet al. posed the problem of sampling over joins as a fundamental challenge in largedatabase systems. They also pointed out a fundamental barrier for this problem; that thesampling operator cannot be pushed through a join; ie; sample (R▷◁ S) sample (R)▷◁sample (S). To overcome this barrier; they used precomputed statistics to guide the samplingprocess; but only showed how this works for two-relation joins. This paper revisits thisclassic problem for both acyclic and cyclic multi-way joins. We build upon the idea ofChaudhuri et al.; but extend it in several nontrivial directions. First; we propose a general …,*,2018,*
Method and device for compressing flow data,*,Abstract: A method for compressing flow data; including: generating multiple line segmentsaccording to flow data and a predefined maximum error that are acquired; obtaining a targetpiecewise linear function according to the multiple line segments; where the targetpiecewise linear function includes multiple linear functions; and an intersection set of valueranges of independent variables of every two linear functions among the multiple linearfunctions includes a maximum of one value; and outputting a reference data point accordingto the target piecewise linear function; where the reference data point includes a point ofcontinuity and a point of discontinuity of the target piecewise linear function. In this way; amaximum error; a target piecewise linear function is further determined according to themultiple line segments; and a point of continuity and a point of discontinuity of the target …,*,2017,*
The communication complexity of distributed epsilon-approximations,Zengfeng Huang; Ke Yi,Data summarization is an effective approach to dealing with the “big data” problem. Whiledata summarization problems traditionally have been studied in the streaming model; thefocus is starting to shift to distributed models; as distributed/parallel computation seems to bethe only viable way to handle today's massive data sets. In this paper; we study ε-approximations; a classical data summary that; intuitively speaking; preserves approximatelythe density of the underlying data set over a certain range space. We consider the problemof computing ε-approximations for a data set which is held jointly by k players; and givegeneral communication upper and lower bounds that hold for any range space whosediscrepancy is known.,SIAM Journal on Computing,2017,*
Wander Join and XDB: Online Aggregation via Random Walks,Feifei Li; Bin Wu; Ke Yi; Zhuoyue Zhao,Abstract Joins are expensive; and online aggregation is an effective approach to explore thetradeoff between query efficiency and accuracy in a continuous; online fashion. However;the stateof-the-art approach; in both internal and external memory; is based on ripple join;which is still very expensive and needs strong assumptions (eg; the tuples in a table arestored in random order). This paper proposes a new approach; the wander join algorithm; tothe online aggregation problem by performing random walks over the underlying join graph.We also design an optimizer that chooses the optimal plan for conducting the random walkswithout having to collect any statistics a priori. Selection predicates and group-by clausescan be handled as well. We have developed an online engine called XDB by integratingwander join in the latest version of PostgreSQL. Extensive experiments using the TPC-H …,ACM SIGMOD Record,2017,*
TUM: Towards ubiquitous multi-device localization for cross-device interaction,Han Xu; Zheng Yang; Zimu Zhou; Ke Yi; Chunyi Peng,Cross-device interaction is becoming an increasingly hot topic as we often have multipledevices at our immediate disposal in this era of mobile computing. Various cross-deviceapplications such as file sharing; multi-screen display; and cross-device authentication havebeen proposed and investigated. However; one of the most fundamental enablers remainsunsolved: How to achieve ubiquitous multi-device localization? Though pioneer efforts haveresorted to gesture-assisted or sensing-assisted localization; they either require extensiveuser participation or impose some strong assumptions on device sensing abilities. Thisintroduces extra costs and constraints; and thus degrades their practicality. To overcomethese limitations; we propose TUM; an acoustic-assisted localization scheme TowardsUbiquitous Multi-device localization. The basic idea of TUM is to utilize the dual …,INFOCOM 2017-IEEE Conference on Computer Communications; IEEE,2017,*
模擬與挪用: 黔東南族群身份政治策略,Siu Woo Cheung,模擬與挪用: 黔東南族群身份政治策略.,*,2017,*
Sampling from distributed streams of data,*,The present disclosure is directed to systems; methods; and computer-readable storagemedia for sampling from distributed data streams. Data elements are received at site serversconfigured to collect and report data to a coordinator device. The site servers assign a binarystring to each of the data elements. Each bit of the binary strings can be independently set toa 0 or a 1 with a probability of one half. The binary string is used to sample from the receiveddata elements; and the data elements and/or the sampled data elements can be transmittedto a coordinator device. The coordinator device can examine one or more bits of the binarystring to draw samples of the received data elements in accordance with desiredprobabilities.,*,2015,*
Sampling from distributed streams of data,*,The present disclosure is directed to systems; methods; and computer-readable storagemedia for sampling from distributed data streams. Data elements are received at site serversconfigured to collect and report data to a coordinator device. The site servers assign a binarystring to each of the data elements. Each bit of the binary strings can be independently set toa 0 or a 1 with a probability of one half. The binary string is used to sample from the receiveddata elements; and the data elements and/or the sampled data elements can be transmittedto a coordinator device. The coordinator device can examine one or more bits of the binarystring to draw samples of the received data elements in accordance with desiredprobabilities.,*,2013,*
Database Systems and Theory-Article 10 (25 pages)-Continuous Sampling from Distributed Streams,G Cormode; S Muthukrishnan; K Yi; Q Zhang,*,Journal of the ACM-Association for ComputingMachinery,2012,*
A transcriptional regulator NIF-1 regulates neurite outgrowth and undergoes p35-dependent nuclear export,Xiao Su Zhao; Ada WY Fu; Winnie WY Chien; Zhen Li; Amy KY Fu; Nancy Y Ip,A transcriptional regulator NIF-1 regulates neurite outgrowthand undergoes p35-dependent nuclear export.,The Gordon Research Conference on Molecular and Cellular Neurobiology; Hong Kong,2008,*
Semantics of Ranking Queries for Probabilistic Data,Jeffrey Jestes; Graham Cormode; Feifei Li; Ke Yi,Abstract—Recently; there have been several attempts to propose definitions and algorithmsfor ranking queries on probabilistic data. However; these lack many intuitive properties of atop-k over deterministic data. We define numerous fundamental properties; including exact-k; containment; unique-rank; value-invariance; and stability; which are satisfied by rankingqueries on certain data. We argue these properties should also be carefully studied indefining ranking queries in probabilistic data; and fulfilled by definition for ranking uncertaindata for most applications. We propose an intuitive new ranking definition based on theobservation that the ranks of a tuple across all possible worlds represent a well-foundedrank distribution. We studied the ranking definitions based on the expectation; the medianand other statistics of this rank distribution for a tuple and derived the expected rank …,IEEE Transactions on Communications,1991,*
" Offizielle" elektronische Version der Publikation (entsprechend ihrem Digital Object Identifier-DOI),S Abiteboul; M Arenas; P Barceló; M Bienvenu; D Calvanese; C David; R Hull; E Hüllermeier; B Kimelfeld; L Libkin; W Martens; T Milo; F Murlak; F Neven; M Ortiz de la Fuente; T Schwentick; J Stoyanovich; J Su; D Suciu; V Vianu; K Yi,S. Abiteboul; M. Arenas; P. Barceló; M. Bienvenu; D. Calvanese; C. David; R. Hull; E.Hüllermeier; B. Kimelfeld; L. Libkin; W. Martens; T. Milo; F. Murlak; F. Neven; M. Ortiz de laFuente; T. Schwentick; J. Stoyanovich; J. Su; D. Suciu; V. Vianu; K. Yi: "Research Directions forPrinciples of Data Management (Abridged)"; ACM SIGMOD Record (eingeladen); 45 (2016);4; 13 S … Erstellt aus der Publikationsdatenbank der Technischen Universität Wien.,*,*,*
Efficient Processing of ${\rm Top}\hbox {-} k $ Queries in Uncertain Databases with x-Relations,Ke Yi; Feifei Li; George Kollios; Divesh Srivastava,*,*,*,*
Workshop Organization,Alberto HF Laender; Juliana Freire; Dan Suciu; Mirella M Moro; Vanessa Braganholo; Clodoveu Davis Jr; Marcos André Gonçalves; Francesco Bonchi; Angela Bonifati; Andrea Calì; Sara Cohen; Isabel Cruz; Wolfgang Gatterbauer; Boris Glavic; Claudio Gutierrez; Solmaz Kolahi; Dongwon Lee; Domenico Lembo; Marta Mattoso; Regina Motz; Frank Neven; Rachel Pottinger; Vibhor Rastogi; Altigran S da Silva; Cristina Sirangelo; Divesh Srivastava; Julia Stoyanovich; David Toman; Alejandro Vaisman; Stijn Vansummeren; Ke Yi; Daniel Oliveira,The Alberto Mendelzon International Workshop on Foundations of Data Management (AMW2012) held in Ouro Preto; Brazil; on June 27-30; 2012; is the sixth workshop of a serieswhich started in 2006; as part on an initiative of the Latin American community ofresearchers in data management to honor the memory of our friend; colleague and mentorAlberto Mendelzon. The AMW series has been a venue for high-quality research onfoundational aspects of data management and it has helped foster and solidify the researchin this area throughout Latin America. This event; as the previous ones; has encouraged theparticipation of Latin American graduate students and includes activities specially designedfor them. In addition; with sponsorship from the VLDB Endowment; travel grants have beenprovided for students to attend the event. The proceedings of the workshop consist of 14 …,*,*,*
PRINCIPLES OF DATABASE SYSTEMS (PODS 2014),Martin Grohe; Serge Abiteboul; Pablo Barcelo; Jan van den Bussche; Andrea Cali; Sara Cohen; Dario Colazzo; Claire David; Daniel Deutch; Thomas Eiter; Alexandre Evfimievski; Roberto Grossi; Sudipto Guha; André Hernich; Kristian Kersting; Jure Leskovec; Sebastian Maneth; Gabriele Puppis; Dan Suciu; Tony Tan; Wang-Chiew Tan; Yufei Tao; Ke Yi; Richard Rick Hull,Topics that fit the interests of the symposium include the following: design; semantics; andoptimization of query and database languages; data modeling; data structures andalgorithms for data management; dynamic aspects of databases (updates; views); querylanguages for semi-structured data (including XML and RDF); search query languages(including techniques from information retrieval); web services; automatic verification ofdatabase-driven systems; incompleteness; inconsistency; and uncertainty in databases;constraints (specification; reasoning; mining; constraint databases); domain-specificdatabases (multi-media; scientific; spatial; temporal; text); schema and query extraction;mining and learning of data models and queries; data integration; data exchange;provenance; workflows; metadata management; meta-querying; semantic; linked …,*,*,*
7UDFNLQJ'LVWULEXWHG $ JJUHJDWHV RYHU 7LPH EDVHG 6OLGLQJ: LQGRZV,Graham Cormode; Ke Yi,Page 1. %ULHI $QQRXQFHPHQW 7UDFNLQJ 'LVWULEXWHG $JJUHJDWHV RYHU7LPH EDVHG 6OLGLQJ :LQGRZV Graham Cormode AT&T Labs Ke Yi HKUST Page 2.&RQWLQXRXV 'LVWULEXWHG 0RGHO k sites local stream(s) seen at each site d ^ ^ 2 ■K ■ ^ ■ ' – ε ^ ^ Page 3. 3UREOHPV LQ 'LVWULEXWHG 0RQLWRULQJ ■ D d ^ ■ d –Y [C; Garofalakis; Muthukrishnan; Rastogi 05] – [Arackaparambil Brody Chakrabarti 09] –& D [C; Muthukrishnan; Yi 08] – & D [C; Muthukrishnan; Yi 08] – ' [Sharman; Schuster; Keren06] ■ d – ^ [C; Muthukrishnan; Yi; Zhang 10] – [Chan Lam Lee Ting 10] ■ d 3 Page 4.)RUZDUG EDFNZDUG IUDPHZRUN ■ < Current window Departing Arriving T 2T 3T 4T ■ <– – – K – K ε ε K ε ε – ; K ε ε K ε ε – Y K ε ε ε K ε ε ε 4,*,*,*
The SIGSPATIAL Special,Lars Arge; Kasper Green Larsen; Ke Yi; Thomas Mølhave; Nodari Sitchinava; Laura Toma,The SIGSPATIAL Special serves the community by publishing short contributions such asSIGSPATIAL conferences' highlights; calls and announcements for conferences andjournals that are of interest to the community; as well as short technical notes on currenttopics. The newsletter has three issues every year; ie; March; July; and November. For moredetailed information regarding the newsletter or suggestions please contact the editor viaemail at adanner@ cs. swarthmore. edu.,*,*,*
Indexing Uncertain Data,Ke Yi; Siu-Wing Cheng; Pankaj K Agarwal; Yufei Tao,Page 1. 1-1 Indexing Uncertain Data Ke Yi HKUST Siu-Wing Cheng HKUST Pankaj K. AgarwalDuke University Yufei Tao CUHK PODS '09 Page 2. 2-1 Motivation Two sessions devoted touncertain/probabilistic data manage- ment in each of SIGMOD'08; VLDB'08; and SIGMOD'09Page 3. 2-2 Motivation Two sessions devoted to uncertain/probabilistic data manage- ment ineach of SIGMOD'08; VLDB'08; and SIGMOD'09 So; let's skip the cliché and just get to the problemPage 4. 3-1 The Problem: Range Searching One of the very first and fundamental problemsstudied in query- ing uncertain data The certain case: The uncertain case: Report all points thatfall inside the range with probability ≥ τ SELECT * FROM sensorreadings WHERE Prob[20 <=temp <= 25] >= 0.5 Page 5. 3-2 The Problem: Range Searching One of the very first andfundamental problems studied in query- ing uncertain data The certain case …,*,*,*
Computing Statistical Summaries over Massive Distributed Data,Ke Yi,Page 1. 1-1 Computing Statistical Summaries over Massive Distributed Data Ke Yi Hong KongUniversity of Science and Technology Page 2. 2-1 Distributed Systems for Massive Data:MapReduce Open sourece implementation: Hadoop Page 3. 2-2 Distributed Systems for MassiveData: MapReduce Suitable for batch processing (eg; index construction) Open soureceimplementation: Hadoop Page 4. 3-1 Distributed Systems for Massive Data: Dremel No opensource implementation yet Page 5. 3-2 Distributed Systems for Massive Data: Dremel No opensource implementation yet Suitable for analytical queries (eg; extracting a summary) Page 6.4-1 base station Distributed Systems for Massive Data: Sensor Net sensor node data: {3;5;8;9;...}Page 7. 4-2 base station Distributed Systems for Massive Data: Sensor Net sensor node data:{3;5;8;9;...} Data aggregation: Extracting a summary of the data Page 8. 5-1 …,*,*,*
First International Workshop on Big Dynamic Distributed Data (BD3),Graham Cormode; Ke Yi; Antonios Deligiannakis Minos Garofalakis,As the amount of streaming data produced by large-scale systems such as environmentalmonitoring; scientific experiments and communication networks grows rapidly; newapproaches are needed to effectively process and analyze such data. There are severalpromising directions in the area of large-scale distributed computation; that is; wheremultiple computing entities work together over partitions of the massive; streaming data toperform complex computations. Two important paradigms in this realm are continuousdistributed monitoring (ie; continually maintaining an accurate estimate of a complex query);and distributed and cluster-based systems that allow the processing of big; streaming data(eg; IBM System S; Apache S4; and Twitter Storm). The aim of the BD3 workshop is to bringtogether computer scientists with interests in this field to present recent innovations; find …,*,*,*
Pankaj K. Agarwal; Graham Cormode; Zengfeng Huang; Jeff M. Phillips; Zhewei Wei; and,Ke Yi,We study the mergeability of data summaries. Informally speaking; mergeability requiresthat; given two summaries on two data sets; there is a way to merge the two summaries intoa single summary on the two data sets combined together; while preserving the error andsize guarantees. This property means that the summaries can be merged in a way akin toother algebraic operators such as sum and max; which is especially useful for computingsummaries on massive distributed data. Several data summaries are trivially mergeable byconstruction; most notably all the sketches that are linear functions of the data sets. But someother fundamental ones like those for heavy hitters and quantiles; are not (known to be)mergeable. In this paper; we demonstrate that these summaries are indeed mergeable orcan be made mergeable after appropriate modifications. Specifically; we show that for ε …,*,*,*
