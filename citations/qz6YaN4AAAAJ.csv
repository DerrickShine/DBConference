Cayuga: A General Purpose Event Monitoring System.,Alan J Demers; Johannes Gehrke; Biswanath Panda; Mirek Riedewald; Varun Sharma; Walker M White,ABSTRACT We describe the design and implementation of the Cornell Cayuga System forscalable event processing. We present a query language based on Cayuga Algebra fornaturally expressing complex event patterns. We also describe several novel system designand implementation issues; focusing on Cayuga's query processor; its indexing approach;how Cayuga handles simultaneous events; and its specialized garbage collector.,Cidr,2007,424
Approximate join processing over data streams,Abhinandan Das; Johannes Gehrke; Mirek Riedewald,Abstract We consider the problem of approximating sliding window joins over data streamsin a data stream processing system with limited resources. In our model; we deal withresource constraints by shedding load in the form of dropping tuples from the data streams.We first discuss alternate architectural models for data stream join processing; and wesurvey suitable measures for the quality of an approximation of a set-valued query result. Wethen consider the number of generated result tuples as the quality measure; and we giveoptimal offline and fast online algorithms for it. In a thorough experimental study withsynthetic and real data we show the efficacy of our solutions. For applications with demandfor exact results we introduce a new Archive-metric which captures the amount of workneeded to complete the join in case the streams are archived for later processing.,Proceedings of the 2003 ACM SIGMOD international conference on Management of data,2003,350
Towards expressive publish/subscribe systems,Alan Demers; Johannes Gehrke; Mingsheng Hong; Mirek Riedewald; Walker White,Abstract Traditional content based publish/subscribe (pub/sub) systems allow users toexpress stateless subscriptions evaluated on individual events. However; many applicationssuch as monitoring RSS streams; stock tickers; or management of RFID data streams requirethe ability to handle stateful subscriptions. In this paper; we introduce Cayuga; a statefulpub/sub system based on nondeterministic finite state automata (NFA). Cayuga allows usersto express subscriptions that span multiple events; and it supports powerful languagefeatures such as parameterization and aggregation; which significantly extend theexpressive power of standard pub/sub systems. Based on a set of formally defined languageoperators; the subscription language of Cayuga provides non-ambiguous subscriptionsemantics as well as unique opportunities for optimizations. We experimentally …,International Conference on Extending Database Technology,2006,319
Processing theta-joins using MapReduce,Alper Okcan; Mirek Riedewald,Abstract Joins are essential for many data analysis tasks; but are not supported directly bythe MapReduce paradigm. While there has been progress on equi-joins; implementation ofjoin algorithms in MapReduce in general is not sufficiently understood. We study theproblem of how to map arbitrary join conditions to Map and Reduce functions; ie; a parallelinfrastructure that controls data flow based on key-equality only. Our proposed join modelsimplifies creation of and reasoning about joins in MapReduce. Using this model; we derivea surprisingly simple randomized algorithm; called 1-Bucket-Theta; for implementingarbitrary joins (theta-joins) in a single MapReduce job. This algorithm only requires minimalstatistics (input cardinality) and we provide evidence that for a variety of join problems; it iseither close to optimal or the best possible option. For some of the problems where 1 …,Proceedings of the 2011 ACM SIGMOD International Conference on Management of data,2011,272
Cayuga: a high-performance event processing engine,Lars Brenna; Alan Demers; Johannes Gehrke; Mingsheng Hong; Joel Ossher; Biswanath Panda; Mirek Riedewald; Mohit Thatte; Walker White,Abstract We propose a demonstration of Cayuga; a complex event monitoring system forhigh speed data streams. Our demonstration will show Cayuga applied to monitoring Webfeeds; the demo will illustrate the expressiveness of the Cayuga query language; thescalability of its query processing engine to high stream rates; and a visualization of theinternals of the query processing engine.,Proceedings of the 2007 ACM SIGMOD international conference on Management of data,2007,245
Data-intensive science: a new paradigm for biodiversity studies,Steve Kelling; Wesley M Hochachka; Daniel Fink; Mirek Riedewald; Rich Caruana; Grant Ballard; Giles Hooker,Abstract The increasing availability of massive volumes of scientific data requires newsynthetic analysis techniques to explore and identify interesting patterns that are otherwisenot apparent. For biodiversity studies; a “data-driven” approach is necessary because of thecomplexity of ecological systems; particularly when viewed at large spatial and temporalscales. Data-intensive science organizes large volumes of data from multiple sources andfields and then analyzes them using techniques tailored to the discovery of complex patternsin high-dimensional data through visualizations; simulations; and various types of modelbuilding. Through interpreting and analyzing these models; truly novel and surprisingpatterns that are “born from the data” can be discovered. These patterns provide valuableinsight for concrete hypotheses about the underlying ecological processes that created …,BioScience,2009,176
Discovery of influence sets in frequently updated databases,Ioana Stanoi; Mirek Riedewald; Divyakant Agrawal; Amr El Abbadi,Abstract An increasing number of organizations are currently working on ways to expressand provide location infor-mation to services and applications. A location aware systemknows the position of each component; and it is able to track devices through changes dueto movement. In this context; data management issues such as efficient storage and retrievalof data through frequent updates pose new challenges. While we believe that spatialqueries in general are going to gain in importance due to the emerging type of applications;we are particularly interested in the discovery of influence regions and influence sets arounda query point. An influence set is formed by all points that have q as their nearest neighbor;and are located within the boundaries of an influence region. In this paper we pro-pose forthe first time a technique that reduces such a query to the more familiar nearest neighbor …,VLDB,2001,156
Spatiotemporal exploratory models for broad‐scale survey data,Daniel Fink; Wesley M Hochachka; Benjamin Zuckerberg; David W Winkler; Ben Shaby; M Arthur Munson; Giles Hooker; Mirek Riedewald; Daniel Sheldon; Steve Kelling,Abstract The distributions of animal populations change and evolve through time. Migratoryspecies exploit different habitats at different times of the year. Biotic and abiotic features thatdetermine where a species lives vary due to natural and anthropogenic factors. Thisspatiotemporal variation needs to be accounted for in any modeling of species' distributions.In this paper we introduce a semiparametric model that provides a flexible framework foranalyzing dynamic patterns of species occurrence and abundance from broad-scale surveydata. The spatiotemporal exploratory model (STEM) adds essential spatiotemporal structureto existing techniques for developing species distribution models through a simpleparametric structure without requiring a detailed understanding of the underlying dynamicprocesses. STEMs use a multi-scale strategy to differentiate between local and global …,Ecological Applications,2010,129
Data-mining discovery of pattern and process in ecological systems,Wesley M Hochachka; Rich Caruana; Daniel Fink; ART Munson; Mirek Riedewald; Daria Sorokina; Steve Kelling,Abstract Most ecologists use statistical methods as their main analytical tools whenanalyzing data to identify relationships between a response and a set of predictors; thus;they treat all analyses as hypothesis tests or exercises in parameter estimation. However;little or no prior knowledge about a system can lead to creation of a statistical model ormodels that do not accurately describe major sources of variation in the response variable.We suggest that under such circumstances data mining is more appropriate for analysis. Inthis paper we 1) present the distinctions between data-mining (usually exploratory) analysesand parametric statistical (confirmatory) analyses; 2) illustrate 3 strengths of data-miningtools for generating hypotheses from data; and 3) suggest useful ways in which data miningand statistical analyses can be integrated into a thorough analysis of data to facilitate …,Journal of Wildlife Management,2007,125
Hilda: A high-level language for data-drivenweb applications,Fan Yang; Jayavel Shanmugasundaram; Mirek Riedewald; Johannes Gehrke,We propose Hilda; a high-level language for developing data-driven web applications. Theprimary benefits of Hilda over existing development platforms are:(a) it uses a unified datamodel for all layers of the application;(b) it is declarative;(c) it models both applicationqueries and updates;(d) it supports structured programming for web sites; and (e) it enablesconflict detection for concurrent updates. We also describe the implementation of a simpleproof-ofconcept Hilda compiler; which translates a Hilda application program into JavaServlet code.,Data Engineering; 2006. ICDE'06. Proceedings of the 22nd International Conference on,2006,76
Tweetin'in the Rain: Exploring Societal-Scale Effects of Weather on Mood.,Aniko Hannak; Eric Anderson; Lisa Feldman Barrett; Sune Lehmann; Alan Mislove; Mirek Riedewald,Abstract There has been significant recent interest in using the aggregate sentiment fromsocial media sites to understand and predict real-world phenomena. However; the data fromsocial media sites also offers a unique and—so far—unexplored opportunity to study theimpact of external factors on aggregate sentiment; at the scale of a society. Using aTwitterspecific sentiment extraction methodology; we the explore patterns of sentimentpresent in a corpus of over 1.5 billion tweets. We focus primarily on the effect of the weatherand time on aggregate sentiment; evaluating how clearly the wellknown individual patternstranslate into population-wide patterns. Using machine learning techniques on the Twittercorpus correlated with the weather at the time and location of the tweets; we find thataggregate sentiment follows distinct climate; temporal; and seasonal patterns.,ICWSM,2012,68
What is next in event processing?,Walker White; Mirek Riedewald; Johannes Gehrke; Alan Demers,Abstract Event processing systems have wide applications ranging from managing eventsfrom RFID readers to monitoring RSS feeds. Consequently; there exists much work on themin the literature. The prevalent use of these systems is on-line recognition of patterns that aresequences of correlated events in event streams. Query semantics and implementationefficiency are inherently determined by the underlying temporal model: how events aresequenced (what is the" next" event); and how the time stamp of an event is represented.Many competing temporal models for event systems have been proposed; with noconsensus on which approach is best. We take a foundational approach to this problem. Wecreate a formal framework and present event system design choices as axioms. The axiomsare grouped into standard axioms and desirable axioms. Standard axioms are common to …,Proceedings of the twenty-sixth ACM SIGMOD-SIGACT-SIGART symposium on Principles of database systems,2007,64
Flexible data cubes for online aggregation,Mirek Riedewald; Divyakant Agrawal; Amr El Abbadi,Abstract Applications like Online Analytical Processing depend heavily on the ability toquickly summarize large amounts of information. Techniques were proposed recently thatspeed up aggregate range queries on MOLAP data cubes by storing pre-computedaggregates. These approaches try to handle data cubes of any dimensionality by dealingwith all dimensions at the same time and treat the different dimensions uniformly. Thealgorithms are typically complex; and it is difficult to prove their correctness and to analyzetheir performance. We present a new technique to generate Iterative Data Cubes (IDC) thataddresses these problems. The proposed approach provides a modular framework forcombining one-dimensional aggregation techniques to create space-optimal high-dimensional data cubes. A large variety of cost tradeoffs for high-dimensional IDC can be …,International Conference on Database Theory,2001,61
Massively multi-query join processing in publish/subscribe systems,Mingsheng Hong; Alan J Demers; Johannes E Gehrke; Christoph Koch; Mirek Riedewald; Walker M White,Abstract There has been much recent interest in XML publish/subscribe systems. Somesystems scale to thousands of concurrent queries; but support a limited query language(usually a fragment of XPath 1.0). Other systems support more expressive languages; but donot scale well with the number of concurrent queries. In this paper; we propose a set of novelquery processing techniques; referred to as Massively Multi-Query Join Processingtechniques; for processing a large number of XML stream queries involving value joins overmultiple XML streams and documents. These techniques enable the sharing ofrepresentations of inputs to multiple joins; and the sharing of join computation. Ourtechniques are also applicable to relational event processing systems and publish/subscribesystems that support join queries. We present experimental results to demonstrate the …,Proceedings of the 2007 ACM SIGMOD international conference on Management of data,2007,57
Mining citizen science data to predict orevalence of wild bird species,Rich Caruana; Mohamed Elhawary; Art Munson; Mirek Riedewald; Daria Sorokina; Daniel Fink; Wesley M Hochachka; Steve Kelling,Abstract The Cornell Laboratory of Ornithology's mission is to interpret and conserve theearth's biological diversity through research; education; and citizen science focused onbirds. Over the years; the Lab has accumulated one of the largest and longest-runningcollections of environmental data sets in existence. The data sets are not only large; but alsohave many attributes; contain many missing values; and potentially are very noisy. Theecologists are interested in identifying which features have the strongest effect on thedistribution and abundance of bird species as well as describing the forms of theserelationships. We show how data mining can be successfully applied; enabling theecologists to discover unanticipated relationships. We compare a variety of methods formeasuring attribute importance with respect to the probability of a bird being observed at …,Proceedings of the 12th ACM SIGKDD international conference on Knowledge discovery and data mining,2006,42
Additive groves of regression trees,Daria Sorokina; Rich Caruana; Mirek Riedewald,Abstract We present a new regression algorithm called Groves of trees and show empiricallythat it is superior in performance to a number of other established regression methods. AGrove is an additive model usually containing a small number of large trees. Trees added tothe Grove are trained on the residual error of other trees already in the Grove. We begin thetraining process with a single small tree in the Grove and gradually increase both thenumber of trees in the Grove and their size. This procedure ensures that the resulting modelcaptures the additive structure of the response. A single Grove may still overfit to the trainingset; so we further decrease the variance of the final predictions with bagging. We show thatin addition to exhibiting superior performance on a suite of regression test problems; baggedGroves of trees are very resistant to overfitting.,European Conference on Machine Learning,2007,39
Space-efficient data cubes for dynamic environments,Mirek Riedewald; Divyakant Agrawal; Amr El Abbadi; Renato Pajarola,Abstract Data cubes provide aggregate information to support the analysis of the contents ofdata warehouses and databases. An important tool to analyze data in data cubes is therange query. For range queries that summarize large regions of massive data cubes;computing the query result on-the-fly can result in non-interactive response times. To speedup range queries; values that summarize regions of the data cube are precomputed andstored. This faster response time results in more expensive updates and/or space overhead.While the emphasis is typically on low query and update costs; growing data collectionsincrease the demand for space-efficient approaches. In this paper two techniques arepresented that have the same update and query costs as earlier approaches; withoutintroducing any space overhead.,International Conference on Data Warehousing and Knowledge Discovery,2000,39
Rule-based multi-query optimization,Mingsheng Hong; Mirek Riedewald; Christoph Koch; Johannes Gehrke; Alan Demers,Abstract Data stream management systems usually have to process many long-runningqueries that are active at the same time. Multiple queries can be evaluated more efficientlytogether than independently; because it is often possible to share state and computation.Motivated by this observation; various Multi-Query Optimization (MQO) techniques havebeen proposed. However; these approaches suffer from two limitations. First; they focus onvery specialized workloads. Second; integrating MQO techniques for CQL-style streamengines and those for event pattern detection engines is even harder; as the processingmodels of these two types of stream engines are radically different. In this paper; we proposea rule-based MQO framework. This framework incorporates a set of new abstractions;extending their counterparts; physical operators; transformation rules; and streams; in a …,Proceedings of the 12th International Conference on Extending Database Technology: Advances in Database Technology,2009,38
pCube: Update-efficient online aggregation with progressive feedback and error bounds,Mirek Riedewald; Divyakant Agrawal,Multidimensional data cubes are used in large data warehouses as a tool for onlineaggregation of information. As the number of dimensions increases; supporting efficientqueries as well as updates to the data cube becomes difficult. Another problem that ariseswith increased dimensionality is the sparseness of the data space. In this paper we developa new data structure referred to as the pCube (data cube for progressive querying); tosupport efficient querying and updating of multidimensional data cubes in large datawarehouses. While the pCube concept is very general and can be applied to any type ofquery; we mainly focus on range queries that summarize the contents of regions of the datacube. pCube provides intermediate results with absolute error bounds (to allow tradingaccuracy for fast response time); efficient updates; scalability with increasing …,Scientific and Statistical Database Management; 2000. Proceedings. 12th International Conference on,2000,38
Approximation techniques for spatial data,Abhinandan Das; Johannes Gehrke; Mirek Riedewald,Abstract Spatial Database Management Systems (SDBMS); eg; Geographical InformationSystems; that manage spatial objects such as points; lines; and hyper-rectangles; often havevery high query processing costs. Accurate selectivity estimation during query optimizationtherefore is crucially important for finding good query plans; especially when spatial joinsare involved. Selectivity estimation has been studied for relational database systems; but todate has only received little attention in SDBMS. In this paper; we introduce novel methodsthat permit high-quality selectivity estimation for spatial joins and range queries. Ourtechniques can be constructed in a single scan over the input; handle inserts and deletes tothe database incrementally; and hence they can also be used for processing of streamingspatial data. In contrast to previous approaches; our techniques return approximate …,Proceedings of the 2004 ACM SIGMOD international conference on Management of data,2004,35
The ebird reference dataset; version 1.0,M Arthur Munson; Kevin Webb; Daniel Sheldon; Daniel Fink; Wesley M Hochachka; Marshall Iliff; Mirek Riedewald; Daria Sorokina; Brian Sullivan; Christopher Wood; Steve Kelling,The eBird reference data is freely available for all usages. The observational data included inthe data set have data access level 5 in the Avian Knowledge Network (AKN) data warehouseand are published here in compliance with the AKN data sharing policy.1 eBird2 is run by theNational Audubon Society3 and the Cornell Lab of Ornithology4; and the data is copyrightedby both organizations. A primary goal in publishing this data is to provide a common data resourcefor studying and comparing ecological models; as such; derivative versions of the eBird referencedata set must not be distributed without explicit permission from the copyright holders. The dataset is a snapshot of submitted observations for years prior to 2009 that were submitted to eBirdand reviewed by January 21; 2009. Published results using this data should cite this documentas follows … M. Arthur Munson; Kevin Webb; Daniel Sheldon; Daniel Fink; Wesley M …,Cornell Lab of Ornithology and National Audubon Society; Ithaca; NY,2009,34
Streaming operator placement for distributed stream processing,*,A streaming operator assignment system and method for determining a streaming operatorassignment that minimizes overload in a data processing system. Embodiments of thestreaming operator assignment system include an optimization goals definition module;which defines optimization goals in terms of fundamental quantities that systemadministrators and application writers want to control; such as minimizing the worst caselatency over all periods of time; or minimizing how much the system is backlogged with work.Embodiments of the streaming operator assignment system also include an optimizationgoals solution module that optimizes and solves a selected optimization goal. A specializedoptimization technique is used to find the best operator (or load) assignment using theoptimization goals to measure of the value of the assignment. This technique minimizes …,*,2011,29
Accurate latency estimation in a distributed event processing system,Badrish Chandramouli; Jonathan Goldstein; Roger Barga; Mirek Riedewald; Ivo Santos,A distributed event processing system consists of one or more nodes (machines); and canexecute a directed acyclic graph (DAG) of operators called a dataflow (or query); over long-running high-event-rate data sources. An important component of such a system is costestimation; which predicts or estimates the “goodness” of a given input; ie; operator graphand/or assignment of individual operators to nodes. Cost estimation is the foundation forsolving many problems: optimization (plan selection and distributed operator placement);provisioning; admission control; and user reporting of system misbehavior. Latency is asignificant user metric in many commercial real-time applications. Users are usuallyinterested in quantiles of latency; such as worst-case or 99 th percentile. However; existingcost estimation techniques for event-based dataflows use metrics that; while they may …,Data Engineering (ICDE); 2011 IEEE 27th International Conference on,2011,28
Semantic approximation of data stream joins,Abhinandan Das; Johannes Gehrke; Mirek Riedewald,We consider the problem of approximating sliding window joins over data streams in a datastream processing system with limited resources. In our model; we deal with resourceconstraints by shedding load in the form of dropping tuples from the data streams. We maketwo main contributions. First; we define the problem space by discussing architecturalmodels for data stream join processing and surveying suitable measures for the quality of anapproximation of a set-valued query result. Second; we examine in detail a large part of thisproblem space. More precisely; we consider the number of generated result tuples as thequality measure and we propose optimal offline and fast online algorithms for it. In athorough experimental study with synthetic and real data; we show the efficacy of oursolutions.,IEEE Transactions on Knowledge and Data Engineering,2005,27
Provenance in high-energy physics workflows,Andrew Dolgert; Lawrence Gibbons; Christopher D Jones; Valentin Kuznetsov; Mirek Riedewald; Daniel Riley; Gregory J Sharp; Peter Wittich,The adoption of large-scale distributed computing presents new opportunities andchallenges for the physicists analyzing data from the Large Hadron Collider experiments.With petabytes of data to manage; effective use of provenance is critical to understandingthe results.,Computing in Science & Engineering,2008,26
A general algebra and implementation for monitoring event streams,Alan Demers; Johannes Gehrke; Mingsheng Hong; Mirek Riedewald; Walker White,Recently there has been considerable research on Data Stream Management Systems(DSMS) to support analysis of data that arrives rapidly in high-speed streams. Most of thesesystems have very expressive query languages in order to address a wide range ofapplications. In this paper; we take a different approach. Instead of starting with a verypowerful data stream query language; we begin with a well-known class of languages--event languages. Through the addition of several simple; but powerful language constructs(namely parameterization and aggregates); we add pieces that extend their expressivenesstowards full-fledged languages for processing data streams. Our resulting contributions area novel algebra for expressing data stream queries; and a corresponding transformation ofalgebra expressions into finite state automata that can be implemented very efficiently …,*,2005,22
User-driven refinement of imprecise queries,Bahar Qarabaqi; Mirek Riedewald,We propose techniques for exploratory search in large databases. The goal is to providenew functionality that aids users in homing in on the right query conditions to find what theyare looking for. Query refinement proceeds interactively by repeatedly consulting the user tomanage query conditions. This process is characterized by three key challenges:(1) dealingwith incomplete and imprecise user input;(2) keeping user effort low; and (3) guaranteeinginteractive system response time. We address the first two challenges with a probability-based framework that guides the user to the most important query conditions. To recoverfrom input errors; we introduce the notion of sensitivity and propose efficient algorithms foridentifying the most sensitive user input; ie; those inputs that had the greatest influence onthe query results. For the third challenge; we develop techniques that can deliver …,Data Engineering (ICDE); 2014 IEEE 30th International Conference on,2014,21
Efficient integration and aggregation of historical information,Mirek Riedewald; Divyakant Agrawal; Amr El Abbadi,Abstract Data warehouses support the analysis of historical data. This often involvesaggregation over a period of time. Furthermore; data is typically incorporated in thewarehouse in the increasing order of a time attribute; eg; date of sale or time of atemperature measurement. In this paper we propose a framework to take advantage of thisappend only nature of updates due to a time attribute. The framework allows us to integratelarge amounts of new data into the warehouse and generate historical summaries efficiently.Query and update costs are virtually independent from the extent of the data set in the timedimension; making our framework an attractive aggregation approach for append-only datastreams. A specific instantiation of the general approach is developed for MOLAP datacubes; involving a new data structure for append-only arrays with pre-aggregated values …,Proceedings of the 2002 ACM SIGMOD international conference on Management of data,2002,21
Detecting statistical interactions with additive groves of trees,Daria Sorokina; Rich Caruana; Mirek Riedewald; Daniel Fink,Abstract Discovering additive structure is an important step towards understanding acomplex multi-dimensional function because it allows the function to be expressed as thesum of lower-dimensional components. When variables interact; however; their effects arenot additive and must be modeled and interpreted simultaneously. We present a newapproach for the problem of interaction detection. Our method is based on comparing theperformance of unrestricted and restricted prediction models; where restricted models areprevented from modeling an interaction in question. We show that an additive model-basedregression ensemble; Additive Groves; can be restricted appropriately for use with thisframework; and thus has the right properties for accurately detecting variable interactions.,Proceedings of the 25th international conference on Machine learning,2008,18
Data cubes in dynamic environments,Steven Geffner; Mirek Riedewald; Divyakant Agrawal; Amr El  Abbadi,*,IEEE Data Eng. Bull.,1999,17
The model-summary problem and a solution for trees,Biswanath Panda; Mirek Riedewald; Daniel Fink,Modern science is collecting massive amounts of data from sensors; instruments; andthrough computer simulation. It is widely believed that analysis of this data will hold the keyfor future scientific breakthroughs. Unfortunately; deriving knowledge from large high-dimensional scientific datasets is difficult. One emerging answer is exploratory analysisusing data mining; but data mining models that accurately capture natural processes tend tobe very complex and are usually not intelligible. Scientists therefore generate modelsummaries to find the most important patterns learned by the model. We formalize the model-summary problem and introduce it as a novel problem to the database community.Generating model summaries creates serious data management challenges: Scientistsusually want to analyze patterns in different “slices” and “dices” of the data space …,Data Engineering (ICDE); 2010 IEEE 26th International Conference on,2010,9
Accessing scientific data: Simpler is better,Mirek Riedewald; Divyakant Agrawal; Amr El Abbadi; Flip Korn,Abstract A variety of index structures has been proposed for supporting fast access andsummarization of large multidimensional data sets. Some of these indices are fairly involved;hence few are used in practice. In this paper we examine how to reduce the I/O cost bytaking full advantage of recent trends in hard disk development which favor reading largechunks of consecutive disk blocks over seeking and searching. We present theMultiresolution File Scan (MFS) approach which is based on a surprisingly simple andflexible data structure which outperforms sophisticated multidimensional indices; even if theyare bulk-loaded and hence optimized for query processing. Our approach also has theadvantage that it can incorporate a priori knowledge about the query workload. It readilysupports summarization using distributive (eg; count; sum; max; min) and algebraic (eg …,International Symposium on Spatial and Temporal Databases,2003,9
Large-scale collaborative analysis and extraction of web data,Felix Weigel; Biswanath Panda; Mirek Riedewald; Johannes Gehrke; Manuel Calimlim,Abstract Archived web data is a great resource for scientific research; but poses seriouschallenges in data processing and management. We demonstrate the Web LabCollaboration Server; a platform and service for large-scale collaborative web data analysisin a distributed computing environment; and show how it seamlessly supports non-technicalusers during search; data extraction and analysis.,Proceedings of the VLDB Endowment,2008,8
Indexing for function approximation,Biswanath Panda; Mirek Riedewald; Stephen B Pope; Johannes Gehrke; L Paul Chew,Abstract Simulation is one of the most powerful tools that scientists have at their disposal forstudying and understanding real-world physical phenomena. In order to be realistic; themathematical models which drive simulations are often very complex and run for a verylarge number of simulation steps. The required computational resources often make itinfeasible to evaluate simulation models exactly at each step; and thus scientists tradeaccuracy for reduced simulation cost. In this paper; we explore function approximation for acombustion simulation. In particular; we model high-dimensional function approximation(HFA) as a storage and retrieval problem; and we show that HFA defines a novel class ofapplications for high dimensional index structures. The interesting property of HFA is that itimposes a mixed query/update workload on the index which leads to novel tradeoffs …,Proceedings of the 32nd international conference on Very large data bases,2006,7
Automatic client-server partitioning of data-driven web applications,Nicholas Gerner; Fan Yang; Alan Demers; Johannes Gehrke; Mirek Riedewald; Jayavel Shanmugasundaram,Abstract Current application development tools provide completely different programmingmodels for the application server (eg; Java and J2EE) and the client web browser (eg;JavaScript and HTML). Consequently; the application developer is forced to partition theapplication code between the server and client at the time of writing the application.However; the partitioning of the code between the client and server may have to be changedduring the evolution of the application for performance reasons (it may be better to pushmore functionality to the client); for correctness reasons (data that conflicts with multipleclients cannot always be pushed to clients); and for supporting clients with differentcomputing power (browsers on desktops vs. PDAs). Since the client and server use differentprogramming models; moving application code from client to server (and vice versa) …,Proceedings of the 2006 ACM SIGMOD international conference on Management of data,2006,7
Research issues in distributed mining and monitoring,Alan Demers; JE Gehrke; Mirek Riedewald,Abstract In this paper we describe research problems in distributed mining and monitoring ofintelligence data. We first review the basic architecture of such a system; and then outlineresearch problems in multi-query optimization; online data mining; high-speed archiving;foundations of stream computations; distributed data mining; and data mining modelmanagement.,Proceedings of the National Science Foundation Workshop on Next Generation Data Mining. Baltimore; MD,2002,7
Making sense of entities and quantities in web tables,Yusra Ibrahim; Mirek Riedewald; Gerhard Weikum,Abstract HTML tables and spreadsheets on the Internet or in enterprise intranets oftencontain valuable information; but are created ad-hoc. As a result; they usually lacksystematic names for column headers and clear vocabulary for cell values. This limits the re-use of such tables and creates a huge heterogeneity problem when comparing oraggregating multiple tables.,Proceedings of the 25th ACM International on Conference on Information and Knowledge Management,2016,6
Anti-combining for mapreduce,Alper Okcan; Mirek Riedewald,Abstract We propose Anti-Combining; a novel optimization for MapReduce programs todecrease the amount of data transferred from mappers to reducers. In contrast to Combiners;which decrease data transfer by performing reduce work on the mappers; Anti-Combiningshifts mapper work to the reducers. It is also conceptually different from traditionalcompression techniques. While the latter are applied outside the MapReduce framework bycompressing map output and then decompressing it before the data is fed into the reducer;Anti-Combining is integrated into mapping and reducing functionality itself. This enableslightweight algorithms and data reduction even for cases where the Map output data showsno redundancy that could be exploited by traditional compression techniques. Anti-Combining can be enabled automatically for any given MapReduce program through …,Proceedings of the 2014 ACM SIGMOD International Conference on Management of Data,2014,6
Detecting and interpreting variable interactions in observational ornithology data,Daria Sorokina; Rich Caruana; Mirek Riedewald; Wesley Hochachka; Steve Kelling,In this paper we demonstrate a practical approach to interaction detection on real datadescribing the abundance of different species of birds in the prairies east of the southernRocky Mountains. This data is very noisy---predictive models built from it perform onlyslightly better than baseline. Previous approaches for interaction detection; including arecently proposed algorithm based on Additive Groves; often do not work well on such noisydata for a number of reasons. We describe the issues that appear when working with suchdata sets and suggest solutions to them. In the end; we discuss results of our analysis forseveral bird species.,Data Mining Workshops; 2009. ICDMW'09. IEEE International Conference on,2009,6
The architecture of the cornell knowledge broker,Alan Demers; Johannes Gehrke; Mirek Riedewald,Abstract Intelligence applications have to process massive amounts of data in order toextract relevant information. This includes archived historical data as well as continuouslyarriving new data. We propose a novel architecture that addresses this problem–the CornellKnowledge Broker. It will not only support knowledge discovery; but also security; privacy;information exchange; and collaboration.,International Conference on Intelligence and Security Informatics,2004,6
Automated template generation for question answering over knowledge graphs,Abdalghani Abujabal; Mohamed Yahya; Mirek Riedewald; Gerhard Weikum,Abstract Templates are an important asset for question answering over knowledge graphs;simplifying the semantic parsing of input utterances and generating structured queries forinterpretable answers. State-of-the-art methods rely on hand-crafted templates with limitedcoverage. This paper presents QUINT; a system that automatically learns utterance-querytemplates solely from user questions paired with their answers. Additionally; QUINT is ableto harness language compositionality for answering complex questions without having anytemplates for the entire question. Experiments with different benchmarks demonstrate thehigh quality of QUINT.,Proceedings of the 26th international conference on world wide web,2017,4
Exploratory Search in Databases and the Web.,Georgia Koutrika; Laks VS Lakshmanan; Mirek Riedewald; Kostas Stefanidis,The traditional way a user interacts with a database system is through queries. Structuredquery languages; such as SQL for relational data; XQuery for XML; and SPARQL for RDFdata; allow users to submit queries that may precisely capture their information needs; butusers need to be familiar with the underlying ontology and data structure and of course thequery language itself. Moreover; users need to some extent be familiar with the content ofthe database and have a clear understanding of their information needs. Theserequirements stand as the weaknesses of this interaction mode. As data stored in databasesgrows in unprecedented rates and becomes accessible to diverse and less technicallyoriented audience; new forms of data exploration and interaction become increasingly moreattractive. The World Wide Web represents the largest and arguably the most complex …,EDBT/ICDT Workshops,2014,4
Data-intensive Science: A New Paradigm for Biodiversity Studies.,Wesley M Hochachka; Daniel Fink; Giles Hooker; Steve Kelling; Mirek Riedewald; Rich Caruana; Grant Ballard,Abstract The increasing availability of massive volumes of scientific data requires newsynthetic analysis techniques to explore and identify interesting patterns that are otherwisenot apparent. For biodiversity studies; a" data-driven" approach is necessary because of thecomplexity of ecological systems; particularly when viewed at large spatial and temporalscales. Data-intensive science organizes large volumes of data from multiple sources andfields and then analyzes them using techniques tailored to the discovery of complex patternsin high-dimensional data through visualizations; simulations; and various types of modelbuilding. Through interpreting and analyzing these models; truly; novel and surprisingpatterns that are" born from the data" can be discovered. These patterns provide valuableinsight for concrete hypotheses about the underlying ecological processes that created …,BioScience,2009,4
Finding relevant patterns in bursty sequences,Alexander Lachmann; Mirek Riedewald,Abstract Sequence data is ubiquitous and finding frequent sequences in a large database isone of the most common problems when analyzing sequence data. Unfortunately manysources of sequence data; eg; sensor networks for data-driven science; RFID-based supplychain monitoring; and computing system monitoring infrastructure; produce a challengingworkload for sequence mining. It is common to find bursts of events of the same type. Suchbursts result in high mining cost; because input sequences are longer. An even greaterchallenge is that these bursts tend to produce an overwhelming number of irrelevantrepetitive sequence patterns with high support. Simply raising the support threshold is not asolution; because at some point interesting sequences will get eliminated. As an alternativewe propose a novel transformation of the input sequences. We show that this …,Proceedings of the VLDB Endowment,2008,4
High-speed function approximation,Biswanath Panda; Mirek Riedewald; Johannes Gehrke; Stephen B Pope,We address a new learning problem where the goal is to build a predictive model thatminimizes prediction time (the time taken to make a prediction) subject to a constraint onmodel accuracy. Our solution is a generic framework that leverages existing data miningalgorithms without requiring any modifications to these algorithms. We show a firstapplication of our framework to a combustion simulation problem. Our experimentalevaluation shows significant improvements over existing methods; prediction time typically isimproved by a factor between 2 and 6.,Data Mining; 2007. ICDM 2007. Seventh IEEE International Conference on,2007,4
Three case studies of large-scale data flows,William Y Arms; Selcuk Aya; Manuel Calimlim; Jim Cordes; Julia Deneva; Pavel Dmitriev; Johannes Gehrke; Lawrence Gibbons; Christopher D Jones; Valentin Kuznetsov; Dave Lifka; Mirek Riedewald; Daniel Riley; Anders Ryd; Gregory J Sharp,We survey three examples of large-scale scientific workflows that we are working with atCornell: the Arecibo sky survey; the CLEO high-energy particle physics experiment; and theWeb Lab project for enabling social science studies of the Internet. All three projects face thesame general challenges: massive amounts of raw data; expensive processing steps; andthe requirement to make raw data or data products available to users nation-or world-wide.However; there are several differences that prevent a one-sizefits-all approach to handlingtheir data flows. Instead; current implementations are heavily tuned by domain and datamanagement experts. We describe the three projects; and we outline research issues andopportunities to integrate Grid technology into these workflows.,Data Engineering Workshops; 2006. Proceedings. 22nd International Conference on,2006,4
A Vision for PetaByte Data Management and Analyis Services for the Arecibo Telescope.,Manuel Calimlim; Jim Cordes; Alan J Demers; Julia Deneva; Johannes Gehrke; Daniel Kifer; Mirek Riedewald; Jayavel Shanmugasundaram,Abstract We survey the initial steps of a project to build a data management and data miningsystem for astronomy data generated by the Arecibo Telescope. The total amount of datathat our project will have to manage will approach one Petabyte over five years. We describesome of the scientific challenges from the astronomy side; and we discuss initial thoughts onhow to address these challenges through novel data mining research.,IEEE Data Eng. Bull.,2004,4
Report on the first international workshop on exploratory search in databases and the web (exploredb 2014),Georgia Koutrika; Laks VS Lakshmanan; Mirek Riedewald; Kostas Stefanidis,Databases are well-organized collections of data. Structured query languages; such as SQL;XQuery; and SPARQL; enable users to formulate precise queries over the data stored in adatabase. To be successful; users need to be familiar with the query language and theunderlying data organization. They also need to understand; to some extent; the data stored;and have a fairly clear idea of what they are looking for. In contrast; the World Wide Webrepresents the largest and arguably the most complex repository of content; where theabove assumptions do not hold. Structured and unstructured data; files and records;multimedia and text; scientific and usergenerated data co-exist peacefully on the Web. Free-text queries provide an easy way for users to express their information seeking needswithout having to worry about the underlying data organization. Search engines typically …,ACM SIGMOD Record,2014,3
Ilp modulo data,Panagiotis Manolios; Vasilis Papavasileiou; Mirek Riedewald,The vast quantity of data generated and captured every day has led to a pressing need fortools and processes to organize; analyze and interrelate this data. Automated reasoning andoptimization tools with inherent support for data could enable advancements in a variety ofcontexts; from data-backed decision making to data-intensive scientific research. To thisend; we introduce a decidable logic aimed at database analysis. Our logic extends quantifier-free Linear Integer Arithmetic with operators from Relational Algebra; like selection andcross product. We provide a scalable decision procedure that is based on the BC (T)architecture for ILP Modulo Theories. Our decision procedure makes use of databasetechniques. We also experimentally evaluate our approach; and discuss potentialapplications.,Formal Methods in Computer-Aided Design (FMCAD); 2014,2014,3
What's" Next"?,Walker White; Mirek Riedewald; Johannes Gehrke; Alan Demers,Event processing systems have wide applications ranging from monitoring RSS feeds tomanaging events from RFID readers; and there exists much work on them in the literature.Many competing temporal models for event systems have been proposed; with noconsensus on which approach is best. In this paper we determine the important propertiesfor such temporal models. Our approach is to define a very general temporal model capableof representing time in all of the major event systems. We introduce axioms motivated by thetime stamp ordering relation and the semantics of the successor operator; which is presentin all event systems. Only two of our axioms are controversial; the remaining axioms aresatisfied by all event systems. We consider the temporal models obtained using our full setof axioms; and the models that result when one or the other of our controversial axioms is …,*,2006,3
Exploiting the multi-append-only-trend property of historical data in data warehouses,Hua-Gang Li; Divyakant Agrawal; Amr El Abbadi; Mirek Riedewald,Abstract Data warehouses maintain historical information to enable the discovery of trendsand developments over time. Hence data items usually contain time-related attributes likethe time of a sales transaction or the order and shipping date of a product. Furthermore thevalues of these time-related attributes have a tendency to increase over time. We refer to thisas the Multi-Append-Only-Trend (MAOT) property. In this paper we formalize the notion ofMAOT and show how taking advantage of this property can improve query performanceconsiderably. We focus on range aggregate queries which are essential for summarizinglarge data sets. Compared to MOLAP data cubes the amount of pre-computation and henceadditional storage in the proposed technique is dramatically reduced.,International Symposium on Spatial and Temporal Databases,2003,3
Report on the second international workshop on exploratory search in databases and the web (exploredb 2015),Georgia Koutrika; Laks VS Lakshmanan; Mirek Riedewald; Mohamed A Sharaf; Kostas Stefanidis,To make Big Data that is growing in both size and diversity widely accessible; datamanagement and analysis systems have to provide appropriate exploration services. Ananalysis might include structured (relations; tables); semi-structured (XML); and“unstructured”(text) data; linked together through relationships encoded as a graph. Some ofthe data can be precise; others might be probabilistic [15]; eg; due to measurement error orbecause it was generated by a statistical model. At the same time; the community of potentialusers is becoming more diverse as well; ranging from database experts and domainscientists to citizen scientists. These users need system services that help them understandthe data and enable them to find relevant information; even if they do not completelycomprehend the content and relationships in a complex data collection. This broad goal …,ACM SIGMOD Record,2016,2
Scolopax: exploratory analysis of scientific data,Alper Okcan; Mirek Riedewald; Biswanath Panda; Daniel Fink,Abstract The formulation of hypotheses based on patterns found in data is an essentialcomponent of scientific discovery. As larger and richer data sets become available; newscalable and user-friendly tools for scientific discovery through data analysis are needed.We demonstrate Scolopax; which explores the idea of a search engine for hypotheses. It hasan intuitive user interface that supports sophisticated queries. Scolopax can explore a hugespace of possible hypotheses; returning a ranked list of those that best match the userpreferences. To scale to large and complex data sets; Scolopax relies on parallel datamanagement and mining techniques. These include model training; efficient modelsummary generation; and novel parallel join techniques that together with traditionalapproaches such as clustering manipulate massive model-summary collections to find …,Proceedings of the VLDB Endowment,2013,2
Dynamic multidimensional data cubes,Mirek Riedewald; Divyakant Agrawal; Amr El Abbadi,ABSTRACT Data cubes are ubiquitous tools in data warehousing; online analyticalprocessing; and decision support applications. Based on a selection of precomputed andmaterialized aggregate values; they can dramatically speed up aggregation andsummarization over large data collections. Traditionally; the emphasis has been on loweringquery costs with little regard to maintenance; ie; update cost issues. We argue that currenttrends require data cubes to be not only query-efficient; but also dynamic at the same time;and we also show how this can be achieved. Several array-based techniques with differenttradeoffs between query and update cost are discussed in detail. We also survey selectedapproaches for sparse data and the popular data cube operator; CUBE. Moreover; this workincludes an overview of future trends and their impact on data cubes.,Multidimensional Databases: Problems and Solutions: Problems and Solutions,2002,2
Assistive design and production in computer games: Parametric systems; data mining; visual analytics,Bardia Aghabeigi; Tom Calvert; Magy Seif El-Nasr; Mirek Riedewald,Real Time Strategy (RTS) games are complex; often requiring modeling of economicbehaviors to develop a successful game. The design process for developing such an RTSgame usually involves designers developing rules and mechanics based on their intuitionand then revising these rules over several successive iterations to ensure that the modelworks for the target market. For the past year; we have been collaborating with a gamecompany (BlackBird Interactive Inc.) to create an economy model to assist in designing agame. BlackBird is developing a social multiplayer RTS game called HARDWARE. Our goalis to develop assistive technologies to allow designers to make informed decisionsregarding their game mechanics. In this paper we discuss the approach we took and ourmethod to validate it in future. In particular; we developed an innovative technique using …,Games Innovation Conference (IGIC); 2012 IEEE International,2012,1
Processing high-speed intelligence feeds in real-time,Alan Demers; Johannes Gehrke; Mingsheng Hong; Mirek Riedewald,Abstract Intelligence organizations face the daunting task of collecting all relevant pieces ofinformation and to draw conclusions about potential threats in a timely manner. Typicalinformation sources range from news tickers; financial transaction logs and message logs tosatellite images and speech recordings. This wealth of data is continuously updated andarrives in high-speed data streams; it needs to be analyzed both in real-time (eg; to estimatethe importance of the information and to generate early threat alerts) and offline bysophisticated data mining tools. This work focuses on the real-time aspects of processingthese massive streams of intelligence data. We also show how real-time and data miningcomponents can interact effectively.,International Conference on Intelligence and Security Informatics,2005,1
Indexing without the Index: Scalable Multidimensional Aggregation for Data Warehouses,Mirek Riedewald; Divyakant Agrawal; Amr El Abbadi; Flip Korn,Abstract Aggregation plays an important role in data warehousing and has received muchattention to date. However; existing techniques do not su ciently address the issue of makingthe computation of multidimensional aggregates scale with increasing dimensionality. At thesame time the bene t of taking full advantage of the hard disk geometry is often overlooked.This paper presents the Multiresolution File Scan (MFS) approach which is based on aselection of at les which are accessed with fast sequential I/O operations. Its simple structureand low storage overhead allow MFS to scale to high dimensionality while making the bestuse of the increasing transfer speed of modern hard disks. We show that MFS outperformsmultidimensional index structures; even if these structures are bulk-loaded and henceoptimized for query processing. Our approach can incorporate a priori knowledge about …,Computer Science Technical Report,2002,1
Any-k: Anytime Top-k Tree Pattern Retrieval in Labeled Graphs,Xiaofeng Yang; Deepak Ajwani; Wolfgang Gatterbauer; Patrick K Nicholson; Mirek Riedewald; Alessandra Sala,Abstract: Many problems in areas as diverse as recommendation systems; social networkanalysis; semantic search; and distributed root cause analysis can be modeled as patternsearch on labeled graphs (also called" heterogeneous information networks" or HINs).Given a large graph and a query pattern with node and edge label constraints; afundamental challenge is to nd the top-k matches ac-cording to a ranking function over edgeand node weights. For users; it is di cult to select value k. We therefore propose the novelnotion of an any-k ranking algorithm: for a given time budget; re-turn as many of the top-ranked results as possible. Then; given additional time; produce the next lower-rankedresults quickly as well. It can be stopped anytime; but may have to continues until all resultsare returned. This paper focuses on acyclic patterns over arbitrary labeled graphs. We are …,arXiv preprint arXiv:1802.06060,2018,*
A Case for Abstract Cost Models for Distributed Execution of Analytics Operators,Rundong Li; Ningfang Mi; Mirek Riedewald; Yizhou Sun; Yi Yao,Abstract We consider data analytics workloads on distributed architectures; in particularclusters of commodity machines. To find a job partitioning that minimizes running time; a costmodel; which we more accurately refer to as makespan model; is needed. In attempting tofind the simplest possible; but sufficiently accurate; such model; we explore piecewise linearfunctions of input; output; and computational complexity. They are abstract in the sense thatthey capture fundamental algorithm properties; but do not require explicit modeling ofsystem and implementation details such as the number of disk accesses. We show how thesimplified functional structure can be exploited by directly integrating the model into themakespan optimization process; reducing complexity by orders of magnitude. Experimentalresults provide evidence of good prediction quality and successful makespan …,International Conference on Big Data Analytics and Knowledge Discovery,2017,*
Report on the Third International Workshop on Exploratory Search in Databases and the Web (ExploreDB 2016),Senjuti Basu Roy; Kostas Stefanidis; Georgia Koutrika; Laks VS Lakshmanan; Mirek Riedewald,The traditional way of interaction between a user and a database system is through queries;for which the correctness and completeness of their answers are key challenges. Structuredquery languages; such as SQL; XQuery; and SPARQL; allow users to submit queries thatmay precisely identify their information needs; but often require users to be familiar with thestructure of data; the content of the database; and also have a clear understanding of theirneeds. As databases get larger and accessible to a more diverse audience; new forms ofdata exploration and interaction become increasingly more attractive to aid users navigatethrough the information space and overcome the challenges of information overload [6; 5].The Web represents the largest and most complex repository of content. Users seekinformation through two predominant modes: by browsing or by searching. In the first …,ACM SIGMOD Record,2016,*
Merlin: Exploratory Analysis with Imprecise Queries,Bahar Qarabaqi; Mirek Riedewald,Merlin supports exploratory search in large databases. The user interacts with it byspecifying probability distributions over attributes; which express imprecise conditions aboutthe entities of interest. Merlin helps the user home in on the right query conditions byaddressing three key challenges:(1) efficiently computing results for an imprecise query;(2)providing feedback about the sensitivity of the result to changes of individual conditions; and(3) suggesting new conditions. We formally introduce the notion of sensitivity and provestructural properties that enable efficient algorithms for quantifying the effect of uncertainty inuser-specified conditions. To support interactive responses; we also develop techniques thatcan deliver probability estimates within a given realtime limit and are able to adaptautomatically as interactive query refinement proceeds.,IEEE Transactions on Knowledge and Data Engineering,2016,*
Obtaining New Insights for Biodiversity Conservation from Broad-Scale Citizen Science Data,Steve Kelling; Daniel Fink; Wesley M Hochachka; Marshall J Iliff; Brian L Sullivan; Christopher L Wood; Arthur Munson; Mirek Riedewald,Increasing public engagement in volunteer science; either through data collection orprocessing; is both raising public awareness of science and gathering useful information forscientists. While the payoffs of citizen science are potentially large; achieving them requiresnew approaches to data management and analysis that can only result from strong cross-disciplinary collaborations. This is especially true in ecology and conservation biology;where historically the understanding of species' responses to environmental change hasbeen constrained by the limited spatial or temporal scale of available data. Here wedescribe collaborative research in ecology; computer science; and statistics to generate,*,2009,*
Database Techniques to Improve Scientific Simulations,Biswanath Panda; Johannes Gehrke; Mirek Riedewald,*,*,2009,*
Event and Pattern Detection over Streams,Mingsheng Hong; Alan Demers; Johannes Gehrke; Mirek Riedewald,Definition eAccessibility refers to the access of Information and CommunicationTechnologies (ICT) by people with disabilities; with particular emphasis on the World WideWeb. It is the extent to which the use of an application or service is affected by the user'sparticular functional limitations or abilities (permanent or temporary). eAccessibility can beconsidered as a fundamental prerequisite of usability.,*,2009,*
Analyzing data streams in scientific applications,Tore Risch; Samuel Madden; Hari Balakrishan; Lewis Girod; Ryan Newton; Milena Ivanova; Erik Zeitler; Johannes Gehrke; Biswanath Panda; Mirek Riedewald,diva-portal.org. Please wait …,*,2009,*
Dynamic Multidimensional Data Cubes for Interactive Analysis of Massive Datasets,Mirek Riedewald; Divyakant Agrawal,Abstract Rapidly improving computing and networking technology enables enterprises tocollect data from virtually all its business units. The main challenge today is to extract usefulinformation from an overwhelmingly large amount of raw data. To support complex analysisqueries; data warehouses were introduced. They manage data; which is extracted from thedifferent operational databases and from external data sources; and they are optimized forfast query processing. For modern data warehouses; it is common to manage Terabytes ofdata. According to a recent survey by the Winter Corporation (2003); for instance; thedecision support database of SBC reached a size of almost 25 Terabytes; up from 10.5Terabytes in 2001 (Winter Corporation; 2001).,*,2005,*
1 University of California Santa Barbara; CA 93106; USA,Hua-Gang Li; Divyakant Agrawal; Amr El Abbadi; Mirek Riedewald,*,Advances in Spatial and Temporal Databases: 8th International Symposium; SSTD 2003; Santorini Island; Greece; July 24-27; 2003. Proceedings,2003,*
Managing and analyzing massive data sets with data cubes,Mirek Riedewald; Divyakant Agrawal; Amr El Abbadi,Abstract Data cubes combine an easy-to-understand conceptual model with animplementation that enables the fast summarization of large data sets. This makes them apowerful tool for supporting the interactive analysis of massive data collections like datawarehouses and digital libraries. This article surveys some of the recent developments indata cube research. We mainly focus on techniques for fast aggregation in datawarehousing environments. This includes work on group-by and range queries;approximate query responses; and compression. Since sparse high-dimensional data cubesare of increasing interest; issues related to them are explicitly discussed.,*,2002,*
Efficient aggregation for data warehouses and digital libraries,Mirek Riedewald,Abstract With the almost ubiquitous presence of computing power and connectivity we arecurrently experiencing a rapid growth of the amount of available digital information. Forexample the data warehouses of large retailers are already managing dozens of Terabytesof business data. Similar trends occur in digital libraries; geographical information systems;and scientific databases. Analyzing large databases involves a high amount ofsummarization and aggregation. Data cubes have been proposed to combine an intuitivedata model with efficient processing of aggregate queries. We have developed a novelframework that configures data cubes for a large variety of applications with heterogeneousattributes and different requirements for query and update performance. For large datawarehouses whose contents evolve over time we propose another technique that …,*,2002,*
The Iterative Data Cube,Mirek Riedewald; Divyakant Agrawal; Amr El Abbadi,Abstract. Data cubes provide aggregate information to support the analysis of the contents ofdata warehouses and databases. An important tool to analyze data in data cubes is therange query. For range queries that summarize large regions of massive data cubes;computing the query result on-the-y can result in non-interactive response times (eg in theorder of minutes). To speed up range queries; values that summarize regions of the datacube are pre-computed and stored. This faster response time results in more expensiveupdates and/or space overhead. In this paper a technique is presented that generates a newclass of schemes that support range queries on data cubes {Iterative Data Cubes. The mainidea is that techniques that provide a certain tradeo of query and update costs for a one-dimensional data cube are applied iteratively along the dimensions of data cubes of …,University of California; Santa Barbara; Computer Science Technical Report,2000,*
TIME Symposium Steering Committee,Claudio Bettini; Alexander Bolotov; Estela Saquete Boro; Carlo Combi; Clare Dixon; Curtis Dyreson; Michael Fisher; Antony Galton; Johann Gamper; Alfonso Gerevini; Valentin Goranko; Ian Hodkinson; Vijay Khatri; Ranko Lazić; Nikos A Lorentzos; Claudio Masolo; Angelo Montanari; Ian Pratt-Hartmann; ULB Jean-Francois Raskin; Belgium Peter Revesz; Mirek Riedewald; John F Roddick; Richard T Snodgrass; Paolo Terenziani; David Toman; Sean Wang; Pierre Wolper; Frank Wolter; Alberto Zanardo,Claudio Bettini; University of Milan; Italy Alexander Bolotov; University of Westminster; UK EstelaSaquete Boro; University of Alicante; Spain Carlo Combi; University of Verona; Italy ClareDixon; University of Liverpool; UK Curtis Dyreson; Utah State University; USA MichaelFisher; University of Liverpool; UK Antony Galton; University of Exeter; UK Johann Gamper; FreeUniversity of Bozen-Bolzano; Italy Alfonso Gerevini; University of Brescia; Italy ValentinGoranko; University of Witwatersrand; South Africa Rajeev Goré; ANU; Australia FabioGrandi; Universita of Bologna; Italy Ian Hodkinson; Imperial College; UK Vijay Khatri; IndianaUniversity; USA Ranko Lazić; University of Warwick; UK Nikos A. Lorentzos; Agricultural Universityof Athens; Greece Claudio Masolo; LOA-CNR; Italy Angelo Montanari; University of Udine; ItalyIan Pratt-Hartmann; Manchester University; UK James Pustejovsky; Brandeis University …,*,*,*
Measuring and predicting sentiment on Twitter,Aniko Hannak; Eric Anderson; Lisa Feldman Barrett; Sune Lehmann; Alan Mislove; Mirek Riedewald,*,*,*,*
Groves of Trees,Daria Sorokina; Rich Caruana; Mirek Riedewald,We present Groves of trees—a new method for building an additive ensemble of trees.Groves are based on additive models enhanced by techniques of gradient boosting andbagging as well combined with a new algorithm for training additive models. Like bagging(but unlike boosting); the ensemble can use large trees and does not suffer from overfitting.Like gradient boosting; it can be adapted to optimize an arbitrary loss function. Likebackfitted additive models; it makes use of an additive structure of the response. As a result;it significantly outperforms other ensembles on regression problems; and on classificationproblems is consistently one of the top performing methods. The components of the Grovestraining algorithm are: Backfitting. A single Grove of trees is an additive model; where everyadditive component is a regression tree. We use a variant of backfitting algorithm [1] to …,*,*,*
pCube: Update-E cient Online Aggregation with Progressive Feedback and Error Bounds,Mirek Riedewald; Divyakant Agrawal Amr El Abbadi,Abstract Data Cubes are used in large data warehouses as a tool for online aggregation ofinformation. Typically; online aggregation is supported by specifying a range query over amultidimensional data cube. As the number of dimensions increases; supporting e cientrange queries as well as updates to the data cube becomes di cult. Another problem thatarises with increased dimensionality is the sparseness of the data space. In this paper wedevelop a new data structure referred to as the pCube (data cube for progressive querying);to support e cient querying and updating of multidimensional data cubes in large datawarehouses. pCube provides intermediate results with absolute error bounds (to allowtrading accuracy for fast response time); e cient updates; scalability with increasingdimensionality; and preaggregation to support large range queries. We present both a …,Education,*,*
Data Engineering,Manuel Calimlim; Jim Cordes; Alan Demers; Julia Deneva; Johannes Gehrke; Dan Kifer; Mirek Riedewald; Jayavel Shanmugasundaram,Abstract Scientists in all domains face a data avalanche-both from better instruments andfrom improved simulations. We believe that computer science tools and computer scientistsare in a position to help all the sciences by building tools and developing techniques tomanage; analyze; and visualize peta-scale scientific information. This article summarizesour experiences over the last seven years trying to bridge the gap between databasetechnology and the needs of the astronomy community in building the World-WideTelescope.,Ann Arbor,*,*
