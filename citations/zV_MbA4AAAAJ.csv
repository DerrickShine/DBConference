Sword: scalable workload-aware data placement for transactional workloads,Abdul Quamar; K Ashwin Kumar; Amol Deshpande,Abstract In this paper; we address the problem of transparently scaling out transactional(OLTP) workloads on relational databases; to support database-as-a-service in cloudcomputing environment. The primary challenges in supporting such workloads includechoosing how to partition the data across a large number of machines; minimizing thenumber of distributed transactions; providing high data availability; and tolerating failuresgracefully. Capturing and modeling the transactional workload over a period of time; andthen exploiting that information for data placement and replication has been shown toprovide significant benefits in performance; both in terms of transaction latencies and overallthroughput. However; such workload-aware data placement approaches can incur very highoverheads; and further; may perform worse than naive approaches if the workload …,Proceedings of the 16th International Conference on Extending Database Technology,2013,70
SWORD: workload-aware data placement and replica selection for cloud data management systems,K Ashwin Kumar; Abdul Quamar; Amol Deshpande; Samir Khuller,Abstract Cloud computing is increasingly being seen as a way to reduce infrastructure costsand add elasticity; and is being used by a wide range of organizations. Cloud datamanagement systems today need to serve a range of different workloads; from analyticalread-heavy workloads to transactional (OLTP) workloads. For both the service providers andthe users; it is critical to minimize the consumption of resources like CPU; memory;communication bandwidth; and energy; without compromising on service-level agreementsif any. In this article; we develop a workload-aware data placement and replicationapproach; called SWORD; for minimizing resource consumption in such an environment.Specifically; we monitor and model the expected workload as a hypergraph and developpartitioning techniques that minimize the average query span; ie; the average number of …,The VLDB Journal—The International Journal on Very Large Data Bases,2014,42
Scalable progressive analytics on big data in the cloud,Badrish Chandramouli; Jonathan Goldstein; Abdul Quamar,Abstract Analytics over the increasing quantity of data stored in the Cloud has become veryexpensive; particularly due to the pay-as-you-go Cloud computation model. Data scientiststypically manually extract samples of increasing data size (progressive samples) usingdomain-specific sampling strategies for exploratory querying. This provides them with user-control; repeatable semantics; and result provenance. However; such solutions result intedious workflows that preclude the reuse of work across samples. On the other hand;existing approximate query processing systems report early results; but do not offer theabove benefits for complex ad-hoc queries. We propose a new progressive analytics systembased on a progress model called Prism that (1) allows users to communicate progressivesamples to the system;(2) allows efficient and deterministic query processing over …,Proceedings of the VLDB Endowment,2013,29
NScale: neighborhood-centric large-scale graph analytics in the cloud,Abdul Quamar; Amol Deshpande; Jimmy Lin,Abstract There is an increasing interest in executing complex analyses over large graphs;many of which require processing a large number of multi-hop neighborhoods or subgraphs.Examples include ego network analysis; motif counting; finding social circles; personalizedrecommendations; link prediction; anomaly detection; analyzing influence cascades; andothers. These tasks are not well served by existing vertex-centric graph processingframeworks; where user programs are only able to directly access the state of a single vertexat a time; resulting in high communication; scheduling; and memory overheads in executingsuch tasks. Further; most existing graph processing frameworks ignore the challenges inextracting the relevant portions of the graph that an analysis task is interested in; andloading those onto distributed memory. This paper introduces NScale; a novel end-to-end …,The VLDB Journal,2016,20
NScale: Neighborhood-centric Analytics on Large Graphs;”,Abdul Quamar; Amol Deshpande; Jimmy Lin,Abstract There is an increasing interest in executing rich and complex analysis tasks overlarge-scale graphs; many of which require processing and reasoning about a large numberof multi-hop neighborhoods or subgraphs in the graph. Examples of such tasks include egonetwork analysis; motif counting in biological networks; finding social circles; personalizedrecommendations; link prediction; anomaly detection; analyzing influence cascades; and soon. These tasks are not well served by existing vertex-centric graph processing frameworkswhose computation and execution models limit the user program to directly access the stateof a single vertex; resulting in high communication; scheduling; and memory overheads inexecuting such tasks. Further; most existing graph processing frameworks also typicallyignore the challenges in extracting the relevant portions of the graph that an analysis task …,Proceedings of the VLDB Endowment,2014,18
DETERMINISTIC PROGRESSIVE BIG DATA ANALYTICS,*,A plurality of data items that are annotated with progress markers may be obtained. Theprogress markers may indicate progress points associated with atemporal processingprogress of the respective data items. Deterministic; massively parallel; progressiveprocessing may be initiated on the plurality of data items on a plurality of devices; theprogress markers indicating which of the plurality of data items are to be incorporated intoresults of the progressive processing; the progress markers further indicating an ordering forincorporation of the respective data items into the results.,*,2014,11
The Quill Distributed Analytics Library and Platform,Badrish Chandramouli; Raul Castro Fernandez; Jonathan Goldstein; Ahmed Eldawy; Abdul Quamar,ABSTRACT This technical report introduces Quill (stands for a quadrillion tuples per day); alibrary and distributed platform for relational and temporal analytics over large datasets inthe cloud. Quill exposes a new abstraction for parallel datasets and computation; calledSharded-Streamable. This abstraction provides the ability to express efficient distributedphysical query plans that are transferable; ie; movable from offline to real-time and viceversa. ShardedStreamable decouples incremental query logic specification; a small but richset of data movement operations; and keying; this allows Quill to express a broad space ofplans with complex querying functionality; while leveraging existing temporal libraries suchas Trill. Quill's layered architecture provides a careful separation of responsibilities withindependently useful components; while retaining high performance. We built Quill for the …,*,2016,3
NScaleSpark: subgraph-centric graph analytics on Apache Spark,Abdul Quamar; Amol Deshpande,Abstract In this paper; we describe NS cale S park; a framework for executing large-scaledistributed graph analysis tasks on the Apache Spark platform. NS cale S park is motivatedby the increasing interest in executing rich and complex analysis tasks over large graphdatasets. There is much recent work on vertex-centric graph programming frameworks forexecuting such analysis tasks--these systems espouse a" think-like-a-vertex"(TLV)paradigm; with some example systems being Pregel; Apache Giraph; GPS; Grace; andGraphX (built on top of Apache Spark). However; the TLV paradigm is not suitable for manycomplex graph analysis tasks that typically require processing of information aggregatedover neighborhoods or subgraphs in the underlying graph. Instead; NS cale S park is basedon a" think-like-a-subgraph" paradigm (also recently called" think-like-an-embedding"[23] …,Proceedings of the 1st ACM SIGMOD Workshop on Network Data Analytics,2016,2
Scaling transactional workloads on the cloud,Abdul Quamar,ABSTRACT In this paper; we address the problem of transparently scaling out transactional(OLTP) workloads on relational databases; to support database-as-a-service in cloudcomputing environment. The primary challenges in supporting such workloads includechoosing how to partition the data across a large number of machines; minimizing thenumber of distributed transactions; providing high data availability; and tolerating failuresgracefully. Capturing and modeling the transactional workload over a period of time; andthen exploiting that information for data placement and replication has been shown toprovide significant benefits in performance; both in terms of transaction latencies and overallthroughput. However; such workload-aware data placement approaches can incur very highoverheads; and further; may perform worse than naive approaches if the workload …,*,2013,2
High Performance Query Processing and Data Analytics,*,High performance query processing and data analytics can be performed acrossarchitecturally diverse scales; such as single core; multi-core and/or multi-nodes. The highperformance query processing and data analytics can include a separation of querycomputation; keying data; and data movement and parallel computation; thereby enhancingthe capabilities of the query processing and data analytics; while allowing the specificationof complex forms of data parallel computation that may execute across real-time and offline.The decoupling of data movement and parallel computation; as described herein canimprove query processing and data analytics speed; can provide for the optimization ofsearches in a plurality of computing environments; and can provide the ability to searchthrough a larger space of execution plans.,*,2017,*
Creation and interaction with large-scale domain-specific knowledge bases,S Bharadwaj; L Chiticariu; M Danilevsky; S Dhingra; S Divekar; A Carreno-Fuentes; H Gupta; N Gupta; S-D Han; M Hernández; H Ho; P Jain; S Joshi; H Karanam; S Krishnan; R Krishnamurthy; Y Li; S Manivannan; A Mittal; F Özcan; A Quamar; P Raman; D Saha; K Sankaranarayanan; J Sen; P Sen; S Vaithyanathan; M Vasa; H Wang; H Zhu,Abstract The ability to create and interact with large-scale domain-specific knowledge basesfrom unstructured/semi-structured data is the foundation for many industry-focused cognitivesystems. We will demonstrate the Content Services system that provides cloud services forcreating and querying high-quality domain-specific knowledge bases by analyzing andintegrating multiple (un/semi) structured content sources. We will showcase an instantiationof the system for a financial domain. We will also demonstrate both cross-lingual naturallanguage queries and programmatic API calls for interacting with this knowledge base.,Proceedings of the VLDB Endowment,2017,*
Quill: efficient; transferable; and rich analytics at scale,Badrish Chandramouli; Raul Castro Fernandez; Jonathan Goldstein; Ahmed Eldawy; Abdul Quamar,Abstract This paper introduces Quill (stands for a quadrillion tuples per day); a library anddistributed platform for relational and temporal analytics over large datasets in the cloud.Quill exposes a new abstraction for parallel datasets and computation; calledShardedStreamable. This abstraction provides the ability to express efficient distributedphysical query plans that are transferable; ie; movable from offline to real-time and viceversa. ShardedStreamable decouples incremental query logic specification; a small but richset of data movement operations; and keying; this allows Quill to express a broad space ofplans with complex querying functionality; while leveraging existing temporal libraries suchas Trill. Quill's layered architecture provides a careful separation of responsibilities withindependently useful components; while retaining high performance. We built Quill for the …,Proceedings of the VLDB Endowment,2016,*
Building efficient and cost-effective Cloud-based big data management systems,Abdul Hussain Quamar,Abstract In today's big data world; data is being produced in massive volumes; at greatvelocity and from a variety of different sources such as mobile devices; sensors; a plethora ofsmall devices hooked to the internet (Internet of Things); social networks; communicationnetworks and many others. Interactive querying and large-scale analytics are beingincreasingly used to derive value out of this big data. A large portion of this data is beingstored and processed in the Cloud due the several advantages provided by the Cloud suchas scalability; elasticity; availability; low cost of ownership and the overall economies ofscale. There is thus; a growing need for large-scale cloud-based data management systemsthat can support real-time ingest; storage and processing of large volumes of heterogeneousdata. However; in the pay-as-you-go Cloud environment; the cost of analytics can grow …,*,2015,*
Defence In-depth for Securing Wireless Ad-hoc Mesh Networks,AH Quamar; Timothy A Gonsalves,*,*,2007,*
Predicting Dense Regions in Dynamic Graphs,K Ashwin Kumar; Abdul Quamar,ABSTRACT Many of the real-world interactions and processes over the time can bemodelled using dynamic graphs. Temporal aspect of dynamic graphs poses lot of interestingproblems and has generated lot of interest in research community off-late. We considersolving one such problem; which is prediction of dense regions in dynamic graphs. Densityprediction in dynamic graphs involves the study of the growth processes of dynamic graphsand building models to assist in the temporal density prediction. In other words the modelwould predict the dense regions in a dynamic graph. Given the history of graphs over time;question is; how to predict the graph at a future time t and its dense regions? We present athree phase approach to solve this problem that includes temporal graph summarization;time based node and link prediction at each time step and min-cut partitioning to find …,*,*,*
Graph Partitioning using Parallel Clustering for Improving Performance of Distributed Databases Project Report,Abdul Quamar; Jayanta Mondal; Ethar Elsaka,In the recent years there has been an explosion of the amount of data associated withapplications which can be represented as graphs; eg; social network data; web graph data.Processing; querying; storing and programming such large size graphs poses significantchallenges and scaling out has emerged as natural solution to address these challengeseffectively. Scaling out involves deploying the graph on a distributed memory system andhence involves graph partitioning. An efficient partitioning of the graph would involve loadbalancing of the computation and minimization of communication among the distributed setof machines. Graph partitioning is a much researched problem which has applications inmany fields including VLSI; social network applications; database partitioning; large scaleweb analytics; etc. The graph partitioning problem can be stated as follows: Given the …,*,*,*
Neighborhood Cache for Mobile Ad-hoc Networks,Abdul Quamar; Souvik Bhattacherjee,*,*,*,*
