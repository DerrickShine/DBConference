BigBench: towards an industry standard benchmark for big data analytics,Ahmad Ghazal; Tilmann Rabl; Minqing Hu; Francois Raab; Meikel Poess; Alain Crolotte; Hans-Arno Jacobsen,Abstract There is a tremendous interest in big data by academia; industry and a large userbase. Several commercial and open source providers unleashed a variety of products tosupport big data storage and processing. As these products mature; there is a need toevaluate and compare the performance of these systems. In this paper; we presentBigBench; an end-to-end big data benchmark proposal. The underlying business model ofBigBench is a product retailer. The proposal covers a data model and synthetic datagenerator that addresses the variety; velocity and volume aspects of big data systemscontaining structured; semi-structured and unstructured data. The structured part of theBigBench data model is adopted from the TPC-DS benchmark; which is enriched with semi-structured and unstructured data components. The semi-structured part captures …,Proceedings of the 2013 ACM SIGMOD international conference on Management of data,2013,226
Solving big data challenges for enterprise application performance management,Tilmann Rabl; Sergio Gómez-Villamor; Mohammad Sadoghi; Victor Muntés-Mulero; Hans-Arno Jacobsen; Serge Mankovskii,Abstract As the complexity of enterprise systems increases; the need for monitoring andanalyzing such systems also grows. A number of companies have built sophisticatedmonitoring tools that go far beyond simple resource utilization reports. For example; basedon instrumentation and specialized APIs; it is now possible to monitor single methodinvocations and trace individual transactions across geographically distributed systems. Thishigh-level of detail enables more precise forms of analysis and prediction but comes at theprice of high data rates (ie; big data). To maximize the benefit of data monitoring; the datahas to be stored for an extended period of time for ulterior analysis. This new wave of bigdata analytics imposes new challenges especially for the application performancemonitoring systems. The monitoring data has to be stored in a system that can sustain the …,Proceedings of the VLDB Endowment,2012,209
A data generator for cloud-scale benchmarking,Tilmann Rabl; Michael Frank; Hatem Mousselly Sergieh; Harald Kosch,Abstract In many fields of research and business data sizes are breaking the petabytebarrier. This imposes new problems and research possibilities for the database community.Usually; data of this size is stored in large clusters or clouds. Although clouds have becomevery popular in recent years; there is only little work on benchmarking cloud applications. Inthis paper we present a data generator for cloud sized applications. Its architecture makesthe data generator easy to extend and to configure. A key feature is the high degree ofparallelism that allows linear scaling for arbitrary numbers of nodes. We show howdistributions; relationships and dependencies in data can be computed in parallel with linearspeed up.,Technology Conference on Performance Evaluation and Benchmarking,2010,62
Benchmarking big data systems and the bigdata top100 list,Chaitanya Baru; Milind Bhandarkar; Raghunath Nambiar; Meikel Poess; Tilmann Rabl,Abstract “Big data” has become a major force of innovation across enterprises of all sizes.New platforms with increasingly more features for managing big datasets are beingannounced almost on a weekly basis. Yet; there is currently a lack of any means ofcomparability among such platforms. While the performance of traditional database systemsis well understood and measured by long-established institutions such as the TransactionProcessing Performance Council (TCP); there is neither a clear definition of the performanceof big data systems nor a generally agreed upon metric for comparing these systems. In thisarticle; we describe a community-based effort for defining a big data benchmark. Over thepast year; a Big Data Benchmarking Community has become established in order to fill thisvoid. The effort focuses on defining an end-to-end application-layer benchmark for …,Big Data,2013,54
Setting the direction for big data benchmark standards,Chaitanya Baru; Milind Bhandarkar; Raghunath Nambiar; Meikel Poess; Tilmann Rabl,Abstract The Workshop on Big Data Benchmarking (WBDB2012); held on May 8-9; 2012 inSan Jose; CA; served as an incubator for several promising approaches to define a big databenchmark standard for industry. Through an open forum for discussions on a number ofissues related to big data benchmarking—including definitions of big data terms; benchmarkprocesses and auditing—the attendees were able to extend their own view of big databenchmarking as well as communicate their own ideas; which ultimately led to the formationof small working groups to continue collaborative work in this area. In this paper; wesummarize the discussions and outcomes from this first workshop; which was attended byabout 60 invitees representing 45 different organizations; including industry and academia.Workshop attendees were selected based on their experience and expertise in the areas …,Technology Conference on Performance Evaluation and Benchmarking,2012,46
TPC-DI: The First Industry Benchmark for Data Integration,Meikel Poess; Tilmann Rabl; Hans-Arno Jacobsen; Brian Caufield,Abstract Historically; the process of synchronizing a decision support system with data fromoperational systems has been referred to as Extract; Transform; Load (ETL) and the toolssupporting such process have been referred to as ETL tools. Recently; ETL was replaced bythe more comprehensive acronym; data integration (DI). DI describes the process ofextracting and combining data from a variety of data source formats; transforming that datainto a unified data model representation and loading it into a data store. This is done in thecontext of a variety of scenarios; such as data acquisition for business intelligence; analyticsand data warehousing; but also synchronization of data between operational applications;data migrations and conversions; master data management; enterprise data sharing anddelivery of data services in a service-oriented architecture context; amongst others. With …,Proceedings of the VLDB Endowment,2014,26
Variations of the star schema benchmark to test the effects of data skew on query performance,Tilmann Rabl; Meikel Poess; Hans-Arno Jacobsen; Patrick O'Neil; Elizabeth O'Neil,Abstract The Star Schema Benchmark (SSB); now in its third revision; has been widely usedto evaluate the performance of database management systems when executing star schemaqueries. SSB; based on the well known industry standard benchmark TPC-H; shares someof its drawbacks; most notably; its uniform data distributions. Today's systems rely heavily onsophisticated cost-based query optimizers to generate the most efficient query executionplans. A benchmark that evaluates optimizer's capability to generate optimal execution plansunder all circumstances must provide the rich data set details on which optimizers rely(uniform and non-uniform distributions; data sparsity; etc.). This is also true for otherdatabase system parts; such as indices and operators; and ultimately holds for an end-to-end benchmark as well. SSB's data generator; based on TPC-H's dbgen; is not easy to …,Proceedings of the 4th ACM/SPEC International Conference on Performance Engineering,2013,26
Discussion of BigBench: a proposed industry standard performance benchmark for big data,Chaitanya Baru; Milind Bhandarkar; Carlo Curino; Manuel Danisch; Michael Frank; Bhaskar Gowda; Hans-Arno Jacobsen; Huang Jie; Dileep Kumar; Raghunath Nambiar; Meikel Poess; Francois Raab; Tilmann Rabl; Nishkam Ravi; Kai Sachs; Saptak Sen; Lan Yi; Choonhan Youn,Abstract Enterprises perceive a huge opportunity in mining information that can be found inbig data. New storage systems and processing paradigms are allowing for ever larger datasets to be collected and analyzed. The high demand for data analytics and rapiddevelopment in technologies has led to a sizable ecosystem of big data processing systems.However; the lack of established; standardized benchmarks makes it difficult for users tochoose the appropriate systems that suit their requirements. To address this problem; wehave developed the BigBench benchmark specification. BigBench is the first end-to-end bigdata analytics benchmark suite. In this paper; we present the BigBench benchmark andanalyze the workload from technical as well as business point of view. We characterize thequeries in the workload along different dimensions; according to their functional …,Technology Conference on Performance Evaluation and Benchmarking,2014,20
Efficient update data generation for DBMS benchmarks,Michael Frank; Meikel Poess; Tilmann Rabl,Abstract It is without doubt that industry standard benchmarks have been proven to becrucial to the innovation and productivity of the computing industry. They are important to thefair and standardized assessment of performance across different vendors; different systemversions from the same vendor and across different architectures. Good benchmarks areeven meant to drive industry and technology forward. Since at some point; after allreasonable advances have been made using a particular benchmark even goodbenchmarks become obsolete over time. This is why standard consortia periodicallyoverhaul their existing benchmarks or develop new benchmarks. An extremely time andresource consuming task in the creation of new benchmarks is the development ofbenchmark generators; especially because benchmarks tend to become more and more …,Proceedings of the 3rd ACM/SPEC International Conference on Performance Engineering,2012,19
Landmark-assisted location and tracking in outdoor mobile network,Marco Anisetti; Claudio A Ardagna; Valerio Bellandi; Ernesto Damiani; Mario Döller; Florian Stegmaier; Tilmann Rabl; Harald Kosch; Lionel Brunie,Abstract Modern mobile devices integrating sensors; like accelerometers and cameras; arepaving the way to the definition of high-quality and accurate geolocation solutions based onthe informations acquired by these sensors; and data collected and managed by GSM/3Gnetworks. In this paper; we present a technique that provides geolocation and mobilityprediction of mobile devices; mixing the location information acquired with the GSM/3Ginfrastructure and the results of a landmark matching achieved thanks to the cameraintegrated on the mobile devices. Our geolocation approach is based on an advanced Time-Forwarding algorithm and on database correlation technique over Received Signal StrengthIndication (RSSI) data; and integrates information produced by a landmark recognitioninfrastructure; to enhance algorithm performances in those areas with poor signal and low …,Multimedia Tools and Applications,2012,18
Parallel data generation for performance analysis of large; complex RDBMS,Tilmann Rabl; Meikel Poess,Abstract The exponential growth in the amount of data retained by today's systems isfostered by a recent paradigm shift towards cloud computing and the vast deployment ofdata-hungry applications; such as social media sites. At the same time systems arecapturing more sophisticated data. Running realistic benchmarks to test the performanceand robustness of these applications is becoming increasingly difficult; because of theamount of data that needs to be generated; the number of systems that need to generate thedata and the complex structure of the data. These three reasons are intrinsically connected.Whenever large amounts of data are needed; its generation process needs to be highlyparallel; in many cases across-systems. Since the structure of the data is becoming moreand more complex; its parallel generation is extremely challenging. Over the years there …,Proceedings of the Fourth International Workshop on Testing Database Systems,2011,17
CaSSanDra: An SSD boosted key-value store,Prashanth Menon; Tilmann Rabl; Mohammad Sadoghi; Hans-Arno Jacobsen,With the ever growing size and complexity of enterprise systems there is a pressing need formore detailed application performance management. Due to the high data rates; traditionaldatabase technology cannot sustain the required performance. Alternatives are the morelightweight and; thus; more performant key-value stores. However; these systems tend tosacrifice read performance in order to obtain the desired write throughput by avoidingrandom disk access in favor of fast sequential accesses. With the advent of SSDs; built uponthe philosophy of no moving parts; the boundary between sequential vs. random access isnow becoming blurred. This provides a unique opportunity to extend the storage memoryhierarchy using SSDs in key-value stores. In this paper; we extensively evaluate the benefitsof using SSDs in commercialized key-value stores. In particular; we investigate the …,Data Engineering (ICDE); 2014 IEEE 30th International Conference on,2014,16
Interactive TV services on mobile devices,Günther Hölbling; Tilmann Rabl; David Coquil; Harald Kosch,The recent digitalization of television creates new opportunities for enhancing the viewer'sexperience with interactivity. Interactive TV (iTV) is often solely understood as the ability tochange a program's storyline. Besides this interpretation; iTV in general means providingsome kind of interactive add-ons or TV-related content and services. For example; theviewer might participate in a game show; gather additional information on news topics; orbuy a product presented in a commercial. The combination of digital TV and modern set-topboxes facilitates the deployment of such innovative services. In this context; we developed aprototype platform that uses mobile devices to support multiuser and personalized accessfor iTV services. The mobile devices connect to the set-top box with ad hoc mechanismsover an existing home network; enabling inexperienced users to access and use the …,IEEE MultiMedia,2008,16
DGFIndex for smart grid: enhancing hive with a cost-effective multidimensional range index,Yue Liu; Songlin Hu; Tilmann Rabl; Wantao Liu; Hans-Arno Jacobsen; Kaifeng Wu; Jian Chen; Jintao Li,Abstract In Smart Grid applications; as the number of deployed electric smart metersincreases; massive amounts of valuable meter data is generated and collected every day.To enable reliable data collection and make business decisions fast; high throughputstorage and high-performance analysis of massive meter data become crucial for gridcompanies. Considering the advantage of high efficiency; fault tolerance; and price-performance of Hadoop and Hive systems; they are frequently deployed as underlyingplatform for big data processing. However; in real business use cases; these data analysisapplications typically involve multidimensional range queries (MDRQ) as well as batchreading and statistics on the meter data. While Hive is high-performance at complex databatch reading and analysis; it lacks efficient indexing techniques for MDRQ. In this paper …,Proceedings of the VLDB Endowment,2014,15
Big data generation,Tilmann Rabl; Hans-Arno Jacobsen,Abstract Big data challenges are end-to-end problems. When handling big data it usuallyhas to be preprocessed; moved; loaded; processed; and stored many times. This has led tothe creation of big data pipelines. Current benchmarks related to big data only focus onisolated aspects of this pipeline; usually the processing; storage and loading aspects. To thisdate; there has not been any benchmark presented covering the end-to-end aspect for bigdata systems. In this paper; we discuss the necessity of ETL like tasks in big databenchmarking and propose the Parallel Data Generation Framework (PDGF) for its datageneration. PDGF is a generic data generator that was implemented at the University ofPassau and is currently adopted in TPC benchmarks.,*,2014,15
A BigBench implementation in the hadoop ecosystem,Badrul Chowdhury; Tilmann Rabl; Pooya Saadatpanah; Jiang Du; Hans-Arno Jacobsen,Abstract BigBench is the first proposal for an end to end big data analytics benchmark. Itfeatures a rich query set with complex; realistic queries. BigBench was developed based onthe decision support benchmark TPC-DS. The first proof-of-concept implementation wasbuilt for the Teradata Aster parallel database system and the queries were formulated in theproprietary SQL-MR query language. To test other systems; the queries have to betranslated. In this paper; an alternative implementation of BigBench for the Hadoopecosystem is presented. All 30 queries of BigBench were realized using Apache Hive;Apache Hadoop; Apache Mahout; and NLTK. We will present the different design choiceswe took and show a proof of concept evaluation.,Workshop on Big Data Benchmarks,2013,15
BigBench Specification V0. 1,Tilmann Rabl; Ahmad Ghazal; Minqing Hu; Alain Crolotte; Francois Raab; Meikel Poess; Hans-Arno Jacobsen,Abstract In this article; we present the specification of BigBench; an end-to-end big databenchmark proposal. BigBench models a retail product supplier. The benchmark proposalcovers a data model and a set of big data specific queries. BigBench's synthetic datagenerator addresses the variety; velocity and volume aspects of big data workloads. Thestructured part of the BigBench data model is adopted from the TPC-DS benchmark. Inaddition; the structured schema is enriched with semi-structured and unstructured datacomponents that are common in a retail product supplier environment. This specificationcontains the full query set as well as the data model.,*,2014,12
Just can't get enough: Synthesizing Big Data,Tilmann Rabl; Manuel Danisch; Michael Frank; Sebastian Schindler; Hans-Arno Jacobsen,Abstract With the rapidly decreasing prices for storage and storage systems ever larger datasets become economical. While only few years ago only successful transactions would berecorded in sales systems; today every user interaction will be stored for ever deeperanalysis and richer user modeling. This has led to the development of big data systems;which offer high scalability and novel forms of analysis. Due to the rapid development andever increasing variety of the big data landscape; there is a pressing need for tools fortesting and benchmarking. Vendors have little options to showcase the performance of theirsystems but to use trivial data sets like TeraSort or WordCount. Since customers' real data istypically subject to privacy regulations and rarely can be utilized; simplistic proof-of-conceptshave to be used; leaving both; customers and vendors; unclear of the target use-case …,Proceedings of the 2015 ACM SIGMOD International Conference on Management of Data,2015,11
Generating shifting workloads to benchmark adaptability in relational database systems,Tilmann Rabl; Andreas Lang; Thomas Hackl; Bernhard Sick; Harald Kosch,Abstract A large body of research concerns the adaptability of database systems. Manycommercial systems already contain autonomic processes that adapt configurations as wellas data structures and data organization. Yet there is virtually no possibility for a justmeasurement of the quality of such optimizations. While standard benchmarks have beendeveloped that simulate real-world database applications very precisely; none of themconsiders variations in workloads produced by human factors. Today's benchmarks test theperformance of database systems by measuring peak performance on homogeneousrequest streams. Nevertheless; in systems with user interaction access patterns areconstantly shifting. We present a benchmark that simulates a web information system withinteraction of large user groups. It is based on the analysis of a real online eLearning …,Technology Conference on Performance Evaluation and Benchmarking,2009,11
A PDGF Implementation for TPC-H,Meikel Poess; Tilmann Rabl; Michael Frank; Manuel Danisch,Abstract With 182 benchmark results from 20 hardware vendors; TPC-H has establisheditself as the industry standard benchmark to measure performance of decision supportsystems. The release of TPC-H twelve years ago by the Transaction ProcessingPerformance Council's (TPC) was based on an earlier decision support benchmark; calledTPC-D; which was released 1994. TPC-H inherited TPC-D's data and query generators;DBgen and Qgen. As systems evolved over time; maintenance of these tools has become amajor burden for the TPC. DBgen and Qgen need to be ported on new hardwarearchitectures and adapted as the system grew in size to multiple terabytes. In this paper wedemonstrate how Parallel Data Generation Framework (PDGF); a generic data generator;developed at the University of Passau for massively parallel data generation; can be …,Technology Conference on Performance Evaluation and Benchmarking,2011,9
Dualtable: A hybrid storage model for update optimization in hive,Songlin Hu; Wantao Liu; Tilmann Rabl; Shuo Huang; Ying Liang; Zheng Xiao; Hans-Arno Jacobsen; Xubin Pei; Jiye Wang,Hive is the most mature and prevalent data warehouse tool providing SQL-like interface inthe Hadoop ecosystem. It is successfully used in many Internet companies and shows itsvalue for big data processing in traditional industries. However; enterprise big dataprocessing systems as in Smart Grid applications usually require complicated businesslogics and involve many data manipulation operations like updates and deletes. Hive cannotoffer sufficient support for these while preserving high query performance. Hive using theHadoop Distributed File System (HDFS) for storage cannot implement data manipulationefficiently and Hive on HBase suffers from poor query performance even though it cansupport faster data manipulation. There is a project based on Hive issue Hive-5317 tosupport update operations; but it has not been finished in Hive's latest version. Since this …,Data Engineering (ICDE); 2015 IEEE 31st International Conference on,2015,8
Dynamic allocation in a self‐scaling cluster database,Tilmann Rabl; Marc Pfeffer; Harald Kosch,Abstract Database systems have been vital for all forms of data processing for a long time. Inrecent years; the amount of processed data has been growing dramatically; even in smallprojects. Nevertheless; database management systems tend to be static in terms of size andperformance; which makes scaling a difficult and an expensive task. This is especially anacute problem in dynamic environments such as grid systems.,Concurrency and Computation: Practice and Experience,2008,8
Volume calculation and estimation of parameterized integer polytopes,Tilmann Rabl,Abstract Mathematical models have proved to be useful abstractions in many divisions ofcomputer science. In automatic parallelization the conversion from concrete loop code to anabstract model such as a polytope allows the use of techniques such as linear programming;with the benefits of guaranteed correctness and optimal results. These techniques are;however; often restricted to fixed sized or at most linearly parameterized polytopes. Recentresearch has overcome this limitation. We will explain Chernikova's algorithm (a methodused to compute the extremal vertices and rays of a polytope defined by a set of inequalitiesand equations) and introduce an extension to process non-linearly parameterizedpolytopes. Based on the resulting dual descriptions we will show methods to compute thenumber of integral points in linearly parameterized polytopes; an algorithm for computing …,Unpublished thesis; Fakultät für Mathematik und Informatik; Universität Passau Google Scholar,2006,8
Big data benchmarking,Chaitan Baru; Milind Bhandarkar; Raghunath Nambiar; Meikel Poess; Tilmann Rabl,Abstract We provide a summary of the outcomes from the Workshop on Big DataBenchmarking (WBDB2012) held on May 8-9; 2012 in San Jose; CA. The workshopdiscussed a number of issues related to big data benchmarking definitions and benchmarkprocesses; and was attended by 60 invitees representing 45 different organizations fromindustry and academia. Attendees were selected based on their experience and expertise inone or more areas of big data; database systems; performance benchmarking; and big dataapplications. The participants concluded that there exists both a need and an opportunity fordefining benchmarks to capture the end-to-end aspects of big data applications. The metricsfor such benchmarks would need to include metrics for performance as well asprice/performance; and consider several costs including total system cost; setup cost; and …,Proceedings of the 2012 workshop on Management of big data systems,2012,7
Solving manufacturing equipment monitoring through efficient complex event processing: DEBS grand challenge,Tilmann Rabl; Kaiwen Zhang; Mohammad Sadoghi; Navneet Kumar Pandey; Aakash Nigam; Chen Wang; Hans-Arno Jacobsen,Abstract In this paper; we present an efficient complex event processing system tailoredtoward monitoring a large-scale setup of manufacturing equipment. In particular; the keychallenge in the equipment monitoring is to develop an event-based system for computingcomplex manufacturing queries coupled with event notifications and event and query resultvisualization components. Furthermore; we present an experimental evaluation to validatethe effectiveness of the proposed solution with respect to both query latency and throughput.,Proceedings of the 6th ACM International Conference on Distributed Event-Based Systems,2012,7
The vision of BigBench 2.0,Tilmann Rabl; Michael Frank; Manuel Danisch; Hans-Arno Jacobsen; Bhaskar Gowda,Abstract Data is one of the most important resources for modern enterprises. Better analyticsallow for a better understanding of customer requirements and market dynamics. The moredata is collected; the more information can be extracted. However; information valueextraction is limited by data processing speeds. Due to fast technological advances in bigdata management there is an abundance of big data systems. This leaves users in thedilemma of choosing a system that features good end-to-end performance for the use case.To get a good understanding of the actual performance of a system; realistic applicationlevel workloads are required. To this end; we have developed BigBench; an applicationlevel benchmark focused only on big data analytics. In this paper; we present the vision ofBigBench 2.0; a suite of benchmarks for all major aspects of big data processing in …,Proceedings of the Fourth Workshop on Data analytics in the Cloud,2015,6
Grand challenge: the bluebay soccer monitoring engine,Hans-Arno Jacobsen; Kianoosh Mokhtarian; Tilmann Rabl; Mohammad Sadoghi; Reza Sherafat Kazemzadeh; Young Yoon; Kaiwen Zhang,Abstract This paper presents the design and implementation of a custom-built eventprocessing engine called BlueBay developed for live monitoring of soccer games. Weexperimentally evaluated our system using a real workload and report on its performance.Our results indicate that BlueBay achieves a throughput of up to 790k events per second;therefore processing the game's input sensor stream about 60 times faster than real-time. Inaddition to our custom implementation; we also investigated the applicability of off-the-shelfgeneral-purpose event processing engines to address the soccer monitoring problem. Thiseffort resulted in two additional and fully functional implementations based on Esper andStorm.,Proceedings of the 7th ACM international conference on Distributed event-based systems,2013,6
Autorentool für interaktive Videos im E-Learning,Andreas Stephan; Günther Hölbling; Tilmann Rabl; Franz Lehner; Harald Kosch,Zusammenfassung Videos erfreuen sich immer größerer Beliebtheit im WWW. Auch in E-Learning-Applikationen kommen sie zunehmend zum Einsatz; da man sich erhofft; denLernerfolg zu steigern. Das Medium Video scheint für Betrachter einfacher verarbeitbar zusein als andere Symbolsysteme; da dieses der alltäglichen Wahrnehmung am nächstenkommt. Durch die Integration interaktiver Funktionalität kann der Lerner in seinemLernfortschritt maßgeblich unterstützt werden; was ihm ein individualisiertes Lernenermöglicht. Zwar sind Autorentools; welche die Produktion von interaktiven Videosermöglichen; bereits am Markt vorhanden; zeichnen sich jedoch durch eine hoheKomplexität; proprietäre Formate und hohe Lizenzkosten aus. Daher soll eine Applikationentwickelt werden; welche die Produktion von interaktiven Videos nebst Experten auch …,*,2010,6
Big data benchmark compendium,Todor Ivanov; Tilmann Rabl; Meikel Poess; Anna Queralt; John Poelman; Nicolas Poggi; Jeffrey Buell,Abstract The field of Big Data and related technologies is rapidly evolving. Consequently;many benchmarks are emerging; driven by academia and industry alike. As thesebenchmarks are emphasizing different aspects of Big Data and; in many cases; coveringdifferent technical platforms and uses cases; it is extremely difficult to keep up with the paceof benchmark creation. Also with the combinations of large volumes of data; heterogeneousdata formats and the changing processing velocity; it becomes complex to specify anarchitecture which best suits all application requirements. This makes the investigation andstandardization of such systems very difficult. Therefore; the traditional way of specifying astandardized benchmark with pre-defined workloads; which have been in use for years inthe transaction and analytical processing systems; is not trivial to employ for Big Data …,Technology Conference on Performance Evaluation and Benchmarking,2015,5
Materialized views in cassandra,Tilmann Rabl; Hans-Arno Jacobsen,Abstract Many web companies deal with enormous data sizes and request rates beyond thecapabilities of traditional database systems. This has led to the development of modern BigData Platforms (BDPs). BDPs handle large amounts of data and activity through massivelydistributed infrastructures. To achieve performance and availability at Internet scale; BDPsrestrict querying capability; and provide weaker consistency guarantees than traditionalACID transactions. The reduced functionality as found in key-value stores is sufficient formany web applications. An important requirement of many big data systems is an onlineview of the current status of the data and activity. Typical big data systems such as key-valuestores only allow a key-based access. In order to enable more complex queryingmechanisms; while satisfying necessary latencies materialized views are employed. The …,Proceedings of 24th Annual International Conference on Computer Science and Software Engineering,2014,5
Rapid development of data generators using meta generators in PDGF,Tilmann Rabl; Meikel Poess; Manuel Danisch; Hans-Arno Jacobsen,Abstract Generating data sets for the performance testing of database systems on aparticular hardware configuration and application domain is a very time consuming andtedious process. It is time consuming; because of the large amount of data that needs to begenerated and tedious; because new data generators might need to be developed orexisting once adjusted. The difficulty in generating this data is amplified by constantadvances in hardware and software that allow the testing of ever larger and morecomplicated systems. In this paper; we present an approach for rapidly developingcustomized data generators. Our approach; which is based on the Parallel Data GeneratorFramework (PDGF); deploys a new concept of so called meta generators. Meta generatorsextend the concept of column-based generators in PDGF. Deploying meta generators in …,Proceedings of the Sixth International Workshop on Testing Database Systems,2013,5
Relaxed operator fusion for in-memory databases: making compilation; vectorization; and prefetching work together at last,Prashanth Menon; Todd C Mowry; Andrew Pavlo,Abstract In-memory database management systems (DBMSs) are a key component ofmodern on-line analytic processing (OLAP) applications; since they provide low-latencyaccess to large volumes of data. Because disk accesses are no longer the principlebottleneck in such systems; the focus in designing query execution engines has shifted tooptimizing CPU performance. Recent systems have revived an older technique of using just-in-time (JIT) compilation to execute queries as native code instead of interpreting a plan. Thestate-of-the-art in query compilation is to fuse operators together in a query plan to minimizematerialization overhead by passing tuples efficiently between operators. Our empiricalanalysis shows; however; that more tactful materialization yields better performance. Wepresent a query processing model called" relaxed operator fusion" that allows the DBMS …,Proceedings of the VLDB Endowment,2017,4
Design and Implementation of the Fast Send Protocol.,Tilmann Rabl; Christoph Koch; Günther Hölbling; Harald Kosch,Over the last decades Internet traffic has grown dramatically. Besides the number oftransfers; data sizes have risen as well. Traditional transfer protocols do not adapt to thisevolution. Large-scale computational applications running on expensive parallel computersproduce large amounts of data which often have to be transferred to weaker machines at theclients' premises. As parallel computers are frequently charged by the minute; it isindispensable to minimize the transfer time after computation succeeded to keep downcosts. Consequently; the economic focus lies on minimizing the time to move away all datafrom the parallel computer whereas the actual time to arrival remains less (but still)important. This paper describes the design and implementation of a new transfer protocol;the Fast Send Protocol (FSP); which employs striping to intermediate nodes in order to …,JDIM,2009,4
Intertainment,Günther Hölbling; Tilmann Rabl; Harald Kosch,Abstract Traditional TV provides only a very passive experience. Recent trends suggest thatusers would be interested in taking a more active role while watching TV. This demo paperpresents the interactive television (iTV) platform; which offers a solution in giving the TV-audience a chance of active participation. The iTV platform enriches TV with additionalcontent and interactivity; making it more attractive for the audience. In order to support multi-user and personalized access to the iTV services mobile devices are used. To provide aneasy way to offer and use services an ad-hoc service architecture-the Universal Plug andPlay (UPnP) architecture-has been used.,Proceedings of the 15th ACM international conference on Multimedia,2007,4
Benchmarking data flow systems for scalable machine learning,Christoph Boden; Andrea Spina; Tilmann Rabl; Volker Markl,Abstract Distributed data flow systems such as Apache Spark or Apache Flink are popularchoices for scaling machine learning algorithms in production. Industry applications of largescale machine learning such as click-through rate prediction rely on models trained onbillions of data points which are both highly sparse and high-dimensional. ExistingBenchmarks attempt to assess the performance of data flow systems such as Apache Flink;Spark or Hadoop with non-representative workloads such as WordCount; Grep or Sort. Theyonly evaluate scalability with respect to data set size and fail to address the crucialrequirement of handling high dimensional data. We introduce a representative set ofdistributed machine learning algorithms suitable for large scale distributed settings whichhave close resemblance to industry-relevant applications and provide generalizable …,Proceedings of the 4th Algorithms and Systems on MapReduce and Beyond,2017,3
Gilbert: declarative sparse linear algebra on massively parallel dataflow systems,Till Rohrmann; Sebastian Schelter; Tilmann Rabl; Volker Markl,In recent years; the generated and collected data is increasing at an almost exponential rate.At the same time; the data's value has been identified in terms of insights that can beprovided. However; retrieving the value requires powerful analysis tools; since valuableinsights are buried deep in large amounts of noise. Unfortunately; analytic capacities did notscale well with the growing data. Many existing tools run only on a single computer and arelimited in terms of data size by its memory. A very promising solution to deal with large-scaledata is scaling systems and exploiting parallelism. In this paper; we propose Gilbert; adistributed sparse linear algebra system; to decrease the imminent lack of analyticcapacities. Gilbert offers a MATLAB®-like programming language for linear algebraprograms; which are automatically executed in parallel. Transparent parallelization is …,Datenbanksysteme für Business; Technologie und Web (BTW 2017),2017,3
From BigBench to TPCx-BB: standardization of a big data benchmark,Paul Cao; Bhaskar Gowda; Seetha Lakshmi; Chinmayi Narasimhadevara; Patrick Nguyen; John Poelman; Meikel Poess; Tilmann Rabl,Abstract With the increased adoption of Hadoop-based big data systems for the analysis oflarge volume and variety of data; an effective and common benchmark for big datadeployments is needed. There have been a number of proposals from industry andacademia to address this challenge. While most either have basic workloads (eg wordcounting); or port existing benchmarks to big data systems (eg TPC-H or TPC-DS); some arespecifically designed for big data challenges. The most comprehensive proposal amongthese is the BigBench benchmark; recently standardized by the Transaction ProcessingPerformance Council as TPCx-BB. In this paper; we discuss the progress made since theoriginal BigBench proposal to the standardized TPCx-BB. In addition; we will share thethought process went into creating the specification; challenges in navigating the …,Technology Conference on Performance Evaluation and Benchmarking,2016,3
Performance Evaluation and Optimization of Multi-dimensional Indexes in Hive,Yue Liu; Shuai Guo; Songlin Hu; Tilmann Rabl; Hans-Arno Jacobsen; Jintao Li; Jiye Wang,Apache Hive has been widely used for big data processing over large scale clusters bymany companies. It provides a declarative query language called HiveQL. The efficiency offiltering out query-irrelevant data from HDFS closely affects the performance of queryprocessing. This is especially true for multi-dimensional; high-selective; and few columnsinvolving queries; which provides sufficient information to reduce the amount of bytes read.Indexing (Compact Index; Aggregate Index; Bitmap Index; DGFIndex; and the index in ORCfile) and columnar storage (RCFile; ORC file; and Parquet) are powerful techniques toachieve this. However; it is not trivial to choosing a suitable index and columnar storagebased on data and query features. In this paper; we compare the data filtering performanceof the above indexes with different columnar storage formats by conducting …,IEEE Transactions on Services Computing,2016,3
Big Data Benchmarking,Tilmann Rabl; Kai Sachs; Meikel Poess; Chaitanya Baru; J Hans-Arno,Formed in 2012; the Big Data Benchmarking Community (BDBC) represents a major step infacilitating the development of benchmarks for objective comparisons of hardware andsoftware systems dealing with emerging big data applications. Led by Chaitanya Baru;Tilmann Rabl; Meikel Poess; Milind Bhandarkar; and Nambiar Raghunath; the BDBC hassuccessfully conducted five international Workshops on Big Data Benchmarking (WBDB).One strength of the WBDB is that it brings together practitioners and researchers; whichleads to a balance between industrial and academic contributions. It provides the rightenvironment in which to discuss the challenges and potential approaches to benchmark bigdata systems. The results of the WBDB have a high impact on the ongoing research in thedomain and WBDB itself is established as the leading event focusing on big data …,*,2015,3
Optimizing key-value stores for hybrid storage architectures,Prashanth Menon; Tilmann Rabl; Mohammad Sadoghi; Hans-Arno Jacobsen,Abstract Flash-based solid state drives (SSDs) are increasingly becoming a popular choiceas a storage device within database management systems and key-value stores alike. SSDsoffer fast throughput and low latency access to data; but their price-per-byte cost often makesthem uneconomical for exclusive use; especially in the era of big data workloads. A commonsolution to this problem is to augment existing database systems by adding smaller SSDsthat target only performance-critical areas. We believe this hybrid approach to be a stop-gapsolution. Rather than simply extending existing systems with SSDs; in this work wecompletely re-architect how a key-value database operates in a hybrid storage setting withboth small but fast SSDs and slower but high-capacity HDDs. We formulate an accurate I/Ocost model to study how popular key-value stores behave under several varying …,Proceedings of 24th Annual International Conference on Computer Science and Software Engineering,2014,3
Towards a complete BigBench implementation,Tilmann Rabl; Michael Frank; Manuel Danisch; Bhaskar Gowda; Hans-Arno Jacobsen,Abstract BigBench was the first proposal for an end-to-end big data analytics benchmark. Itfeatures a set of 30 realistic queries based on real big data use cases. It was fully specifiedand completely implemented on the Hadoop stack. In this paper; we present updates on ourdevelopment of a complete implementation on the Hadoop ecosystem. We will focus on thechanges that we have made to data set; scaling; refresh process; and metric.,Workshop on Big Data Benchmarks,2014,3
Specifying Big Data Benchmarks: First Workshop; WBDB 2012; San Jose; CA; USA; May 8-9; 2012 and Second Workshop; WBDB 2012; Pune; India; December 17-...,Tilmann Rabl; Meikel Poess; Chaitan Baru; Hans-Arno Jacobsen,This book constitutes the thoroughly refereed revised selected papers of the First Workshopon Big Data Benchmarks; WBDB 2012; held in San Jose; CA; USA; in May 2012 and theSecond Workshop on Big Data Benchmarks; WBDB 2012; held in Pune; India; in December2012. The 14 revised papers presented were carefully reviewed and selected from 60submissions. The papers are organized in topical sections on benchmarking; foundationsand tools; domain specific benchmarking; benchmarking hardware and end-to-end big databenchmarks.,*,2013,3
Overview of Open Standards for Interactive TV (iTV),Günther Hölbling; Tilmann Rabl; Harald Kosch,Television has become the most important mass medium. The digitalisation in progressgives new possibilities to enrich the television experience. The Electronic Program Guide-though still very limited-gives a first impression of future television. There are variousattempts to give the audience a more active role. All these can be found under the topicinteractive TV. Besides the world of television; there is a fast growing community for videosin the World Wide Web (eg YouTube 1 or MyVideo 2). Until today interactivity in “WWW-videos” is of minor importance; but has a great potential for growth. It has not reached asimilar level of professionalism as in iTV and no open standards have been introduced.Thus we will concentrate on interactivity in traditional TV. In this chapter; we present differentforms of interaction in television and give an extensive overview of existing platforms and …,*,2008,3
Generating Custom Code for Efficient Query Execution on Heterogeneous Processors,Sebastian Breß; Bastian Köcher; Henning Funke; Tilmann Rabl; Volker Markl,Abstract: Processor manufacturers build increasingly specialized processors to mitigate theeffects of the power wall to deliver improved performance. Currently; database engines aremanually optimized for each processor: A costly and error prone process. In this paper; wepropose concepts to enable the database engine to perform per-processor optimizationautomatically. Our core idea is to create variants of generated code and to learn a fastvariant for each processor. We create variants by modifying parallelization strategies;specializing data structures; and applying different code transformations.,arXiv preprint arXiv:1709.00700,2017,2
I2: Interactive Real-Time Visualization for Streaming Data.,Jonas Traub; Nikolaas Steenbergen; Philipp Grulich; Tilmann Rabl; Volker Markl,ABSTRACT Developing scalable real-time data analysis programs is a challenging task.Developers need insights from the data to define meaningful analysis flows; which oftenmakes the development a trial and error process. Data visualization techniques can provideinsights to aid the development; but the sheer amount of available data frequently makes itimpossible to visualize all data points at the same time. We present I2; an interactivedevelopment environment that coordinates running cluster applications and correspondingvisualizations such that only the currently depicted data points are processed andtransferred. To this end; we present an algorithm for the real-time visualization of time series;which is proven to be correct and minimal in terms of transferred data. Moreover; we showhow cluster programs can adapt to changed visualization properties at runtime to allow …,EDBT,2017,2
Apache Flink in current research,Tilmann Rabl; Jonas Traub; Asterios Katsifodimos; Volker Markl,Abstract Recent trends in data collection and the decreasing prices of storage result inconstantly growing amounts of analyzable data. These masses of data cannot easily beprocessed by traditional database systems as these do not allow for a sufficient degree ofscalability. Programs especially designed for parallel data analysis on large-scaledistributed systems are required. Developing such programs on clusters of commodityhardware is a complex challenge for even the most experienced system developers.Frameworks such as Apache Hadoop are scalable; but–when compared to SQL–extremelyhard to program. The open-source platform Apache Flink is a link between conventionaldatabase systems and big data analysis frameworks. Flink is based on a fault tolerantruntime for data stream processing; which manages the distribution of data as well as …,it-Information Technology,2016,2
Processing big events with showers and streams,Christoph Doblander; Tilmann Rabl; Hans-Arno Jacobsen,Abstract Emerging use cases derived from the area of cloud computing; smart power grids;and business process management require a set of capabilities not met by traditional eventprocessing systems. These use cases were chosen to illustrate the capabilities requiredfrom systems that are able to process what we refer to as Big Events; that is Big Data inmotion. To further illustrate Big Events; we identify three use cases and analyze thecharacteristics of the events involved. Based on this analysis; we specify requirementsregarding the event schema; event query language; historic event processing needs; eventtiming; and result accuracy. Collectively; we refer to the constellation of state changes in agiven system that exhibits these characteristics as event showers; referring to the collectiveof these events; similar to the notion of an event stream in the context of event stream …,*,2014,2
Poster: MADES-a multi-layered; adaptive; distributed event store,Tilmann Rabl; Mohammad Sadoghi; Kaiwen Zhang; Hans-Arno Jacobsen,Abstract Application performance monitoring (APM) is shifting towards capturing andanalyzing every event that arises in an enterprise infrastructure. Current APM systems; forexample; make it possible to monitor enterprise applications at the granularity of tracingeach method invocation (ie; an event). Naturally; there is great interest in monitoring theseevents in real-time to react to system and application failures and in storing the capturedinformation for an extended period of time to enable detailed system analysis; data analytics;and future auditing of trends in the historic data. However; the high insertion-rates (up tomillions of events per second) and the purposely limited resource; a small fraction of allenterprise resources (ie; 1-2% of the overall system resources); dedicated to APM are thekey challenges for applying current data management solutions in this context. Emerging …,Proceedings of the 7th ACM international conference on Distributed event-based systems,2013,2
Analysis of TPC-DS: the first standard benchmark for SQL-based big data systems,Meikel Poess; Tilmann Rabl; Hans-Arno Jacobsen,Abstract The advent of Web 2.0 companies; such as Facebook; Google; and Amazon withtheir insatiable appetite for vast amounts of structured; semi-structured; and unstructureddata; triggered the development of Hadoop and related tools; eg; YARN; MapReduce; andPig; as well as NoSQL databases. These tools form an open source software stack tosupport the processing of large and diverse data sets on clustered systems to performdecision support tasks. Recently; SQL is resurrecting in many of these solutions; eg; Hive;Stinger; Impala; Shark; and Presto. At the same time; RDBMS vendors are adding Hadoopsupport into their SQL engines; eg; IBM's Big SQL; Actian's Vortex; Oracle's Big Data SQL;and SAP's HANA. Because there was no industry standard benchmark that could measurethe performance of SQL-based big data solutions; marketing claims were mostly based …,Proceedings of the 2017 Symposium on Cloud Computing,2017,1
Optimized on-demand data streaming from sensor nodes,Jonas Traub; Sebastian Breß; Tilmann Rabl; Asterios Katsifodimos; Volker Markl,Abstract Real-time sensor data enables diverse applications such as smart metering; trafficmonitoring; and sport analysis. In the Internet of Things; billions of sensor nodes form asensor cloud and offer data streams to analysis systems. However; it is impossible to transferall available data with maximal frequencies to all applications. Therefore; we need to tailordata streams to the demand of applications. We contribute a technique that optimizescommunication costs while maintaining the desired accuracy. Our technique schedulesreads across huge amounts of sensors based on the data-demands of a huge amount ofconcurrent queries. We introduce user-defined sampling functions that define the data-demand of queries and facilitate various adaptive sampling techniques; which decrease theamount of transferred data. Moreover; we share sensor reads and data transfers among …,Proceedings of the 2017 Symposium on Cloud Computing,2017,1
Blockjoin: efficient matrix partitioning through joins,Andreas Kunft; Asterios Katsifodimos; Sebastian Schelter; Tilmann Rabl; Volker Markl,Abstract Linear algebra operations are at the core of many Machine Learning (ML)programs. At the same time; a considerable amount of the effort for solving data analyticsproblems is spent in data preparation. As a result; end-to-end ML pipelines often consist of(i) relational operators used for joining the input data;(ii) user defined functions used forfeature extraction and vectorization; and (iii) linear algebra operators used for model trainingand cross-validation. Often; these pipelines need to scale out to large datasets. In this case;these pipelines are usually implemented on top of dataflow engines like Hadoop; Spark; orFlink. These dataflow engines implement relational operators on row-partitioned datasets.However; efficient linear algebra operators use block-partitioned matrices. As a result;pipelines combining both kinds of operators require rather expensive changes to the …,Proceedings of the VLDB Endowment,2017,1
Peel: A framework for benchmarking distributed systems and algorithms,Christoph Boden; Alexander Alexandrov; Andreas Kunft; Tilmann Rabl; Volker Markl,Abstract During the last decade; a multitude of novel systems for scalable and distributeddata processing has been proposed in both academia and industry. While there arepublished results of experimental evaluations for nearly all systems; it remains a challengeto objectively compare different system's performance. It is thus imperative to enable andestablish benchmarks for these systems. However; even if workloads and data sets or datagenerators are fixed; orchestrating and executing benchmarks can be a major obstacle.Worse; many systems come with hardware-dependent parameters that have to be tuned andspawn a diverse set of configuration files. This impedes portability and reproducibility ofbenchmarks. To address these problems and to foster reproducible and portableexperiments and benchmarks of distributed data processing systems; we present PEEL; a …,Technology Conference on Performance Evaluation and Benchmarking,2017,1
Query Centric Partitioning and Allocation for Partially Replicated Database Systems,Tilmann Rabl; Hans-Arno Jacobsen,Abstract A key feature of database systems is to provide transparent access to stored data. Indistributed database systems; this includes data allocation and fragmentation. Transparentaccess introduces data dependencies and increases system complexity and inter-processcommunication. Therefore; many developers are exchanging transparency for betterscalability using sharding and similar techniques. However; explicitly managing datadistribution and data flow requires a deep understanding of the distributed system and thedata access; and it reduces the possibilities for optimizations. To address this problem; wepresent an approach for efficient data allocation that features good scalability while keepingthe data distribution transparent. We propose a workload-aware; query-centric;heterogeneity-aware analytical model. We formalize our approach and present an …,Proceedings of the 2017 ACM International Conference on Management of Data,2017,1
Towards Streamlined Big Data Analytics,András A Benczúr; Róbert Pálovics; Márton Balassi; Volker Markl; Tilmann Rabl; Juan Soto; Björn Hovstadius; Jim Dowling; Seif Haridi,Big data analytics promise to deliver valuable business insights. However; this will bedifficult to realise using today's state-of-the-art technologies; given the flood of datagenerated from various sources. The European STREAMLINE project develops scalable;fast reacting; and high accuracy machine learning techniques for the needs of Europeanonline media companies.,ERCIM News,2016,1
Die Apache Flink Plattform zur parallelen Analyse von Datenströmen und Stapeldaten.,Jonas Traub; Tilmann Rabl; Fabian Hueske; Till Rohrmann; Volker Markl,Abstract. Die Menge an analysierbaren Daten steigt aufgrund fallender Preise fürSpeicherlösungen und der Erschließung neuer Datenquellen rasant. Da klassischeDatenbanksysteme nicht ausreichend parallelisierbar sind; können sie die heuteanfallenden Datenmengen häufig nicht mehr verarbeiten. Hierdurch ist es notwendigspezielle Programme zur parallelen Datenanalyse zu verwenden. Die Entwicklung solcherProgramme für Computercluster ist selbst für erfahrene Systemprogrammierer einekomplexe Herausforderung. Frameworks wie Apache Hadoop MapReduce sind zwarskalierbar; aber im Vergleich zu SQL schwer zu programmieren.,LWA,2015,1
A protocol for disaster data evacuation,Tilmann Rabl; Florian Stegmaier; Mario Döller,Abstract Data is the basis of the modern information society. However; recent naturalcatastrophes have shown that it is not possible to definitively secure a data storage location.Even if the storage location is not destroyed itself the access may quickly becomeimpossible; due to the breakdown of connections or power supply. However; this rarelyhappens without any warning. While floods have hours or days of warning time; tsunamisusually leave only minutes for reaction and for earthquakes there are only seconds. In suchsituations; timely evacuation of important data is the key challenge. Consequently; the focuslies on minimizing the time to move away all data from the storage location whereas theactual time to arrival remains less (but still) important. This demonstration presents thedynamic fast send protocol (DFSP); a new bulk data transfer protocol. It employs striping …,ACM SIGCOMM Computer Communication Review,2011,1
Efficiency in Cluster Database Systems,T Rabl,Abstract Database systems have been vital in all forms of data processing for a long time. Inrecent years; the amount of processed data has been growing dramatically; even in smallprojects. Nevertheless; database management systems tend to be static in terms of size andperformance which makes scaling a difficult and expensive task. Because of performanceand especially cost advantages more and more installed systems have a shared nothingcluster architecture. Due to the massive parallelism of the hardware programmingparadigms from high performance computing are translated into data processing. Databaseresearch struggles to keep up with this trend. A key feature of traditional database systems isto provide transparent access to the stored data. This introduces data dependencies andincreases system complexity and inter process communication. Therefore; many …,*,2011,1
Fast Send Protocol-minimizing sending time in high-speed bulk data transfers,Christoph Koch; Tilmann Rabl; Gunther Holbling; Harald Kosch,Over the last decades Internet traffic has grown dramatically. Besides the number oftransfers; data sizes have risen as well. Traditional transfer protocols do not adapt to thisevolution. Large-scale computational applications running on expensive parallel computersproduce large amounts of data which often have to be transferred to weaker machines at theclients' premises. As parallel computers are frequently charged by the minute; it isindispensable to minimize the transfer time after computation succeeded to keep downcosts. Consequently; the economic focus lies on minimizing the time to move away all datafrom the parallel computer whereas the actual time to arrival remains less (but still)important. This paper describes the design and implementation of a new transfer protocol;the fast send protocol (FSP); which employs striping to intermediate nodes in order to …,Digital Information Management; 2007. ICDIM'07. 2nd International Conference on,2007,1
R-Bäume,Tilmann Rabl,*,Proseminar–Algorithmen und Datenstrukturen für Datenbanken; Universität Passau,2001,1
Setting the Direction for Big Data Benchmark Standards,Tilmann Rabl; Chaitanya Baru; Milind Bhandarkar; Meikel Poess; Raghunath Nambiar,• Audience: Who is the audience for this benchmark?• Application: What application shouldwe model?• Single benchmark spec: Is it possible to develop a single benchmark to capturecharacteristics of multiple applications?• Component vs. end-to-end benchmark. Is itpossible to factor out a set of benchmark “components”; which can be isolated and pluggedinto an end-to-end benchmark (s)?• Paper and Pencil vs Implementation-based. Should theimplementation be specification-driven or implementation-driven?• Reuse. Can we reuseexisting benchmarks?• Benchmark Data. Where do we get the data from?• Innovation orcompetition? Should the benchmark be for innovation or competition?,*,*,1
Benchmarking Distributed Stream Processing Engines,Jeyhun Karimov; Tilmann Rabl; Asterios Katsifodimos; Roman Samarev; Henri Heiskanen; Volker Markl,Abstract: Over the last years; stream data processing has been gaining attention both inindustry and in academia due to its wide range of applications. To fulfill the need for scalableand efficient stream analytics; numerous open source stream data processing systems(SDPSs) have been developed; with high throughput and low latency being their keyperformance targets. In this paper; we propose a framework to evaluate the performance ofthree SDPSs; namely Apache Storm; Apache Spark; and Apache Flink. Our evaluationfocuses in particular on measuring the throughput and latency of windowed operations. Forthis benchmark; we design workloads based on real-life; industrial use-cases. The maincontribution of this work is threefold. First; we give a definition of latency and throughput forstateful operators. Second; we completely separate the system under test and driver; so …,arXiv preprint arXiv:1802.08496,2018,*
Scalable Detection of Concept Drifts on Data Streams with Parallel Adaptive Windowing,Philipp M Grulich; René Saitenmacher; Jonas Traub; Sebastian Breß; Tilmann Rabl; Volker Markl,ABSTRACT Machine learning techniques for data stream analysis suffer from concept driftssuch as changed user preferences; varying weather conditions; or economic changes.These concept drifts cause wrong predictions and lead to incorrect business decisions.Concept drift detection methods such as adaptive windowing (Adwin) allow for adapting toconcept drifts on the fly. In this paper; we examine Adwin in detail and point out itsthroughput bottlenecks. We then introduce several parallelization alternatives to addressthese bottlenecks. Our optimizations lead to a speedup of two orders of magnitude over theoriginal Adwin implementation. Thus; we explore parallel adaptive windowing to providescalable concept detection for high-velocity data streams with millions of tuples per second.,*,2018,*
PROTEUS: Scalable online machine learning for predictive analytics and real-time interactive visualization,Bonaventura Del Monte; Jeyhun Karimov; Alireza Rezaei Mahdiraji; Tilmann Rabl; Volker Markl; Harry Xuegang Huang; Christian Thomsen,{"controller"=>"catalog"; "action"=>"show"; "locale"=>"en"; "id"=>"2373131513 …,Ceur Workshop Proceedings,2017,*
STREAMLINE-Streamlined analysis of data at rest and data in motion,Philipp M Grulich; Tilmann Rabl; Volker Markl; Csaba István Sidló; Andras Benczur,ABSTRACT STREAMLINE aims for improving the overall workflow of big data analyticssystems. For this goal; it combines research in different areas to reduce the complexity of thework with data at rest and data in motion in a unified fashion. As a foundation STREAMLINEoffers a uniform programming model on top of Apache Flink; for which it drives innovations ina wide range of areas; such as interactive data in motion visualization and advancedwindow aggregation techniques.,*,2017,*
Big Data Benchmarking: 6th International Workshop; WBDB 2015; Toronto; ON; Canada; June 16-17; 2015 and 7th International Workshop; WBDB 2015; New Delhi;...,Tilmann Rabl; Raghunath Nambiar; Chaitanya Baru; Milind Bhandarkar; Meikel Poess; Saumyadipta Pyne,This book constitutes the thoroughly refereed post-workshop proceedings of the 6thInternational Workshop on Big Data Benchmarking; WBDB 2015; held in Toronto; ON;Canada; in June 2015 and the 7th International Workshop; WBDB 2015; held in New Delhi;India; in December 2015. The 8 full papers presented in this book were carefully reviewedand selected from 22 submissions. They deal with recent trends in big data and HPCconvergence; new proposals for big data benchmarking; as well as tooling and performanceresults.,*,2016,*
Application-Level Benchmarking of Big Data Systems,Chaitanya Baru; Tilmann Rabl,Abstract The increasing possibilities to collect vast amounts of data—whether in science;commerce; social networking; or government—have led to the “big data” phenomenon. Theamount; rate; and variety of data that are assembled—for almost any application domain—are necessitating a reexamination of old technologies and development of new technologiesto get value from the data; in a timely fashion. With increasing adoption and penetration ofmobile technologies; and increasing ubiquitous use of sensors and small devices in the so-called Internet of Things; the big data phenomenon will only create more pressures on datacollection and processing for transforming data into knowledge for discovery and action. Avibrant industry has been created around the big data phenomena; leading also to anenergetic research agenda in this area. With the proliferation of big data hardware and …,*,2016,*
Improving Data Quality by Leveraging Statistical Relational Learning,LARYSA Visengeriyeva; ALAN Akbik; Manohar Kaul; TILMANN Rabl; VOLKER Markl,Digitally collected data su↵ ers from many data quality issues; such as duplicate; incorrect;or incomplete data. A common approach for counteracting these issues is to formulate a setof data cleaning rules to identify and repair incorrect; duplicate and missing data. Datacleaning systems must be able to treat data quality rules holistically; to incorporateheterogeneous constraints within a single routine; and to automate data curation. Wepropose an approach to data cleaning based on statistical relational learning (SRL). Weargue that a formalism-Markov logic-is a natural fit for modeling data quality rules. Ourapproach allows for the usage of probabilistic joint inference over interleaved data cleaningrules to improve data quality. Furthermore; it obliterates the need to specify the order of ruleexecution. We describe how data quality rules expressed as formulas in first-order logic …,*,2016,*
Log data store that stores data across a plurality of storage devices using non-disjoint layers,*,Storing data records within a log data store is provided. The log data store that stores datarecords within a plurality of successive non-disjoint layers inserted across a plurality ofdifferent types of data storage devices associated with a data processing system isgenerated. A first non-disjoint layer of the plurality of successive non-disjoint layers isinserted within a main memory device. A set of intermediate non-disjoint layers of theplurality of successive non-disjoint layers is inserted within a set of storage-class memorydevices. A last non-disjoint layer of the plurality of successive non-disjoint layers is insertedwithin a hard disk drive. A size of each successive non-disjoint layer in the plurality ofsuccessive non-disjoint layers is increased exponentially. The data records are organizedinto the plurality of successive non-disjoint layers of the log data store inserted across the …,*,2015,*
Enhancing Data Generation in TPCx-HS with a Non-uniform Random Distribution,Raghunath Nambiar; Tilmann Rabl; Karthik Kulkarni; Michael Frank,Abstract Developed by the Transaction Processing Performance Council; the TPC ExpressBenchmark™ HS (TPCx-HS) is the industry's first standard for benchmarking big datasystems. It is designed to provide an objective measure of hardware; operating system andcommercial Apache Hadoop File System API compatible software distributions; and toprovide the industry with verifiable performance; price-performance and availability metrics[1; 2]. It can be used to compare a broad range of system topologies and implementationmethodologies of big data systems in a technically rigorous and directly comparable andvendor-neutral manner. The modeled application is simple and the results are highlyrelevant to hardware and software dealing with Big Data systems in general. The datageneration is derived from TeraGen [3] which uses uniform distribution of data. In this …,Technology Conference on Performance Evaluation and Benchmarking,2015,*
High performance stream queries in scala,Dantong Song; Kaiwen Zhang; Tilmann Rabl; Prashanth Menon; Hans-Arno Jacobsen,Abstract Traffic monitoring is an important stream processing application; which is highlydynamic and requires aggregation of spatially collocated data. Inspired by this; the DEBS2015 Grand Challenge uses publicly available taxi transportation information to computeonline the most frequent routes and most profitable areas. We describe our solution to theDEBS 2015 Grand Challenge; which can process events at a 10 ms latency and at athroughput of 114;000 events per second.,Proceedings of the 9th ACM International Conference on Distributed Event-Based Systems,2015,*
PSBench: a benchmark for content-and topic-based publish/subscribe systems,Kaiwen Zhang; Tilmann Rabl; Yi Ping Sun; Rushab Kumar; Nayeem Zen; Hans-Arno Jacobsen,Abstract The publish/subscribe paradigm has found wide acceptance in a broad variety ofuse cases that differ dramatically in the characteristics of their workloads. Many differentsystems have been developed both by academia as well as industry; but there is nodefinitive benchmark; which enables a fair comparison between the different systems. In thisdemo; we present PSBench; a benchmark specification and suite for publish/subscribesystems that covers a broad variety of publish/subscribe workloads and scenarios. Thebenchmark suite is extensible and generic; but the specification targets social games. Socialgames are the ideal use case since they have a very broad range of requirements andproduce a variety of publications and subscriptions. We draw from our experience inmassive multiplayer online games to construct a highly realistic workload. In this demo …,Proceedings of the Posters & Demos Session,2014,*
Advancing Big Data Benchmarks: Proceedings of the 2013 Workshop Series on Big Data Benchmarking; WBDB. cn; Xi'an; China; July16-17; 2013 and WBDB. us; S...,Tilmann Rabl; Nambiar Raghunath; Meikel Poess; Milind Bhandarkar; Hans-Arno Jacobsen; Chaitanya Baru,This book constitutes the thoroughly refereed joint proceedings of the Third and FourthWorkshop on Big Data Benchmarking. The third WBDB was held in Xi'an; China; in July2013 and the Fourth WBDB was held in San José; CA; USA; in October; 2013. The 15papers presented in this book were carefully reviewed and selected from 33 presentations.They focus on big data benchmarks; applications and scenarios; tools; systems and surveys.,*,2014,*
Specifying Big Data Benchmarks: First Workshop; WBDB 2012; San Jose; CA; USA; May 8-9; 2012; and Second Workshop; WBDB 2012; Pune; India; December 17-...,Meikel Poess; Chaitanya Baru; Hans-Arno Jacobsen; Tilmann Rabl,*,*,2014,*
The World Cup of Event Processing,Kaiwen Zhang; Hans-Arno Jacobsen; Kianoosh Mokhtarian; Tilmann Rabl; Mohammad Sadoghi; Reza Sherafat Kazemzadeh; Young Yoon,Zhang; Kaiwen et Jacobsen; Hans-Arno et Mokhtarian; Kianoosh et Rabl; Tilmann etSadoghi; Mohammad et Kazemzadeh; Reza Sherafat et Yoon; Young. 2014. « The World Cupof Event Processing ». Communication lors de la conférence : Big Data Research (Toronto;ON; Canada; July 16; 2014) … Le plein texte de ce document n'est pas hébergé sur ceserveur … Espace ÉTS version 2.0 École de technologie supérieure.,*,2014,*
Demonstration des Parallel Data Generation Framework.,Tilmann Rabl; Hatem Mousselly Sergieh; Michael Frank; Harald Kosch,Abstract: In vielen akademischen und wirtschaftlichen Anwendungen durchbrechen dieDatenmengen die Petabytegrenze. Dies stellt die Datenbankforschung vor neue Aufgabenund Forschungsfelder. Petabytes an Daten werden gewöhnlich in großen Clustern oderClouds gespeichert. Auch wenn Clouds in den letzten Jahren sehr populär geworden sind;gibt es dennoch wenige Arbeiten zum Benchmarking von Anwendungen in Clouds. Indiesem Beitrag stellen wir einen Datengenerator vor; der für die Generierung von Daten inClouds entworfen wurde. Die Architektur des Generators ist auf einfache Erweiterbarkeit undKonfigurierbarkeit ausgelegt. Die wichtigste Eigenschaft ist die vollständigeParallelverarbeitung; die einen optimalen Speedup auf einer beliebigen Anzahl anRechnerknoten erlaubt. Die Demonstration umfasst sowohl die Erstellung eines Schemas …,BTW,2011,*
Efficiency in Cluster Database Systems-Dynamic and Workload-Aware Scaling and Allocation,Tilmann Rabl,Database systems have been vital in all forms of data processing for a long time. In recentyears; the amount of processed data has been growing dramatically; even in small projects.Nevertheless; database management systems tend to be static in terms of size andperformance which makes scaling a difficult and expensive task. Because of performanceand especially cost advantages more and more installed systems have a shared nothingcluster architecture. Due to the massive parallelism of the hardware programmingparadigms from high performance computing are translated into data processing. Databaseresearch struggles to keep up with this trend. A key feature of traditional database systems isto provide transparent access to the stored data. This introduces data dependencies andincreases system complexity and inter process communication. Therefore; many …,*,2011,*
Introducing Scalileo: a Java based scaling framework,Tilmann Rabl; Christian Dellwo; Harald Kosch,Abstract Scalability is a major concern of internet based applications. Access peaks thatoverload the application are a financial risk. Therefore; systems are built to scale. They areusually configured to be able to process peaks at any give moment. This can be veryinefficient. Yet; there are various ways to improve efficiency. One reasonable approach is toscale applications according to their current workload. This requires the possibility to scale asystem up and down. In this paper we present a scaling framework for Java applications. Itallows not only autonomic scaling; but also migration of distributed applications. We will thenshow how energy efficiency can be increased by scaling applications. To present anexample we have used our framework to autonomically scale a web server cluster.,Proceedings of the 1st International Conference on Energy-Efficient Computing and Networking,2010,*
Das Java Permission Modell und ein konservativer Ansatz zu dessen Analyse,Tilmann Rabl,*,*,2003,*
Ein Entscheidungstheoretischer Ansatz zu Planung; Wahrnehmung und Steuerung,Tilmann Rabl,*,*,2001,*
Benchmarking Distributed Stream Data Processing Systems,Jeyhun Karimov; Tilmann Rabl; Asterios Katsifodimos; Roman Samarev; Henri Heiskanen; Volker Markl,Abstract—The need for scalable and efficient stream analysis has led to the development ofmany open-source streaming data processing systems (SDPSs) with highly divergingcapabilities and performance characteristics. While first initiatives try to compare the systemsfor simple workloads; there is a clear gap of detailed analyses of the systems' performancecharacteristics. In this paper; we propose a framework for benchmarking distributed streamprocessing engines. We use our suite to evaluate the performance of three widely usedSDPSs in detail; namely Apache Storm; Apache Spark; and Apache Flink. Our evaluationfocuses in particular on measuring the throughput and latency of windowed operations;which are the basic type of operations in stream analytics. For this benchmark; we designworkloads based on real-life; industrial use-cases inspired by the online gaming industry …,*,*,*
Scotty: Efficient Window Aggregation for out-of-order Stream Processing,Jonas Traub; Philipp Grulich; Alejandro Rodrıguez Cuéllar; Sebastian Breß; Asterios Katsifodimos; Tilmann Rabl; Volker Markl,Abstract—Computing aggregates over windows is at the core of virtually every streamprocessing job. Typical stream processing applications involve overlapping windows and;therefore; cause redundant computations. Several techniques prevent this redundancy bysharing partial aggregates among windows. However; these techniques do not support out-of-order processing and session windows. Out-of-order processing is a key requirement todeal with delayed tuples in case of source failures such as temporary sensor outages.Session windows are widely used to separate different periods of user activity from eachother. In this paper; we present Scotty; a high throughput operator for window discretizationand aggregation. Scotty splits streams into non-overlapping slices and computes partialaggregates per slice. These partial aggregates are shared among all concurrent queries …,*,*,*
Distributed Machine Learning-but at what COST?,Christoph Boden; Tilmann Rabl; Volker Markl,Abstract Training machine learning models at scale is a popular workload for distributeddata flow systems. However; as these systems were originally built to fulfill quite differentrequirements it remains an open question how effectively they actually perform for MLworkloads. In this paper we argue that benchmarking of large scale ML systems shouldconsider state of the art; single machine libraries as baselines and sketch such a benchmarkfor distributed data flow systems. We present an experimental evaluation of a representativeproblem for XGBoost; LightGBM and Vowpal Wabbit and compare them to Apache SparkMLlib with respect to both: runtime and prediction quality. Our results indicate that whilebeing able to robustly scale with increasing data set size; current generation data flowsystems are surprisingly inefficient at training machine learning models at need …,*,*,*
Apache Flink in Current Research Projects,Tilmann Rabl; Jonas Traub; Volker Markl,Abstract: Recent trends in data collection and the decreasing prices of storage result inconstantly growing amounts of analyzable data. These masses of data cannot easily beprocessed by traditional database systems as these do not allow for a sufficient degree ofscalability. Programs especially designed for parallel data analysis on large scaledistributed systems are required. Developing such programs on clusters of commodityhardware is a complex challenge for even the most experienced system developers.Frameworks such as Apache Hadoop are scalable; but–when compared to SQL–extremelyhard to program. The open-source platform Apache Flink is a link between conventionaldatabase systems and big data analysis frameworks. Flink is based on a fault tolerantruntime for data stream processing; which manages the distribution of data as well as …,*,*,*
Big Data Stream Processing,Tilmann Rabl; Berlin Big Data Center,Page 1. 1 © DIMA 2017 © 2013 Berlin Big Data Center • All Rights Reserved 1 © DIMA 2017Big Data Stream Processing Tilmann Rabl Berlin Big Data Center www.dima.tu-berlin.de |bbdc.berlin | rabl@tu-berlin.de Page 2. 2 © DIMA 2017 2 2 © DIMA 2017 Agenda Introductionto Streams • Use cases • Stream Processing 101 Stream Processing Systems • Ingredients ofa stream processing system • Some examples • More details on Storm; Spark; Flink • Maybe ademo (!) Stream Processing Optimizations (if we have time) • How to optimize With slides fromData Artisans; Volker Markl; Asterios Katsifodimos; Jonas Traub Page 3. 3 © DIMA 2017 3 3 ©DIMA 2017 Big Fast Data • Data is growing and can be evaluated – Tweets; social networks(statuses; check- ins; shared content); blogs; click streams; various logs; … – Facebook: > 845Mactive users; > 8B messages/day – Twitter: > 140M active users; > 340M tweets/day …,*,*,*
PROTEUS: Scalable Online Machine Learning for Predictive Analytics and Real-Time Interactive Visualization,Bonaventura Del; Jeyhun Karimov Monte; Alireza Rezaei Mahdiraji; Tilmann Rabl; Volker Markl,ABSTRACT Big data analytics is a critical and unavoidable process in any business andindustrial environment. Nowadays; companies that do exploit big data's inner value get moreeconomic revenue than the ones which do not. Once companies have determined their bigdata strategy; they face another serious problem: in-house designing and building of ascalable system that runs their business intelligence is difficult. The PROTEUS project aimsto design; develop; and provide an open ready-to-use big data software architecture whichis able to handle extremely large historical data and data streams and supports onlinemachine learning predictive analytics and real-time interactive visualization. The overallevaluation of PROTEUS is carried out using a real industrial scenario.,*,*,*
Big Data streaming processing engines under the umbrella of the Apache Foundation: benchmark and industrial applications,Guido Mazza; Sonia Bergamaschi; Tilmann Rabl,This dissertation is the result of the work jointly conducted by the Databases Groups at theTechnische Universität in Berlin (TUB); precisely at the Datenbanksysteme u.Informationsmanagement Department (DIMA); chaired by Prof. Dr. Volker Markl; and the DBGroup at University of Modena and Reggio Emilia. My personal experience has beencharacterized by five months spent at TUB; from September 2015 to February 2016. Theresearch described have been developed under the supervision of Dr. Tilmann Rabl; seniorresearcher of the Database Systems and Information Management Group at TU Berlin and Itis based on the previous project Big Bench; big data analytics benchmark. Important relatedinformation can be found on the official github repository [1] and further onlinedocumentation ([2];[3]). The workload; data model and data generation have been …,*,*,*
2014 BigData Congress Technical Program Committee,Geoffrey Fox; Sergei Vassilvitskii; Fatma Ozcan; Suren Byna; Lavanya Ramakrishnan; Philip Carns; Andy Twigg; Florin Rusu; Xiaoyong Du; Zhanhuai Li; Weining Qian; Ge Yu; Jianhua Feng; Jian Yin; Kun Yue; Masaru Kitsuregawa; Yoshiharu Ishikawa; Jeffrey Yu; David Cheung; Xuemin Li; Xiaofang Zhou; Ee-Peng Lim; Hesham Hallal; Aziz Bouras; Srividya Kona; Maria Ebling; Gong Zhang; Rafael Accorsi; EBTIC Marcello Leida; UAE Irene Vanderfeesten; Lionel Brunie; Philippe Cudre-Maroux; Piero Fraternali; Gregorio Martinez; Rainer Stotzka; Hoang Tam Vo; Jarek Szlichta; Tilmann Rabl; Shiyong Lu,Du Li; Yahoo; USA Geoffrey Fox; Indiana University; USA Sergei Vassilvitskii; GoogleResearch; USA Poess Meikel; Oracle; USA Maja Vukovic; IBM TJ Research Center; USA YuanChi Chang; IBM TJ Research Center; USA Fatma Ozcan; IBM Almaden Research Center; USACharles (Chang-shing) Perng; IBM TJ Research Center; USA Suren Byna; Lawrence BerkeleyNational Laboratory; USA Lavanya Ramakrishnan; Lawrence Berkeley National Laboratory;USA Philip Carns; Argonne National Laboratory; USA Andy Twigg; Oxford University; UK FlorinRusu; University of California; Merced; USA Xiaoyong Du; Renmin University of China; ChinaZhanhuai Li; Northwestern Polytechnical University; China Weining Qian; East China NormalUniversity; China Ge Yu; Northeastern University; China Guoren Wang; Northeat University;China Jianhua Feng; Tsinghua University; China Jian Yin; Sun Yat-Sen University; China …,*,*,*
SCC 2014 Technical Program Committee,Jean-Paul Jamont; Luis-Felipe Rodriguez; Yasmin A Rios-Solis; Osvaldo Cairo; Marios D Dikaiakos; Mohand-Said Hacid; KTH Šarūnas Girdzijauskas; Sweden Murat Kantarcioglu; Massimo Mecella; Australia Bugra Gedik; Shangguang Wang; Zaiwen Feng; Anand Dersingh; Lalita Narupiyakul; Sherif G Aly; Jungpil Shin; Jinan Fiaidhi; Hoda M Hosny; Wesley Gifford; Dashun Wang; Nan Shao; Sechan Oh; Guangjie Ren; Yu Deng; EE Jan; Sai Zeng; Yixin Diao; Remco Dijkman; Akhilesh Bajaj; Dickson Chiu; Hong-va Leong; Qing Li; Dragan Gasevic; Tilmann Rabl; Vijay Varadharajan; Miguel Vargas Martin; Fabio Casati; Junhua Ding; Eleanna Kafeza; Wei-Tek Tsai; Jie Xu; San-Yih Hwang,Michel Occello; Pierre Mendes France University; France Jean-Paul Jamont; Université deGrenoble; France Luis-Felipe Rodriguez; Instituto Tecnológico de Sonora; Mexico Yasmin A.Rios-Solis; Universidad Autónoma de Nuevo León; Mexico Osvaldo Cairo; Instituto TecnológicoAutónomo de México; Mexico Marios D. Dikaiakos; University of Cyprus; Cyprus Mohand-SaidHacid; Université Claude Bernard Lyon 1; France Šarūnas Girdzijauskas; KTH; Sweden MuratKantarcioglu; University of Texas at Dallas; USA James Joshi; University of Pittsburg; USA MassimoMecella; University of Rome; Italy Athman Bouguettaya; RMIT; Australia Bugra Gedik; BilkentUniversity; Turkey Shangguang Wang; Beijing University of Posts & Telecommunications; ChinaZaiwen Feng; Wuhan University; China Anand Dersingh; Assumption University; Thailand LalitaNarupiyakul; Mahidol University; Thailand Sherif G. Aly; The American University in …,*,*,*
Big Data Challenges in Application Performance Management,Tilmann Rabl; Hans-Arno Jacobsen; Serge Mankovskii,ABSTRACT Many web companies deal with enormous data sizes and request rates beyondthe capabilities of traditional database systems. This has led to the development of modernWeb Data Platforms (WDPs). WDPs handle large amounts of data and activity throughmassively distributed infrastructures. To achieve performance and availability at Internetscale; WDPs restrict querying capability; and provide weaker consistency guarantees thantraditional ACID transactions. The reduced functionality is sufficient for many webapplications. High data and query rates also appear in application performancemanagement (APM). APM has similar requirements like current web based informationsystems such as weaker consistency needs; geographical distribution and asynchronousprocessing. At the same time; APM has some unique features and requirements that …,*,*,*
