Generalized fisher score for feature selection,Quanquan Gu; Zhenhui Li; Jiawei Han,Abstract: Fisher score is one of the most widely used supervised feature selection methods.However; it selects each feature independently according to their scores under the Fishercriterion; which leads to a suboptimal subset of features. In this paper; we present ageneralized Fisher score to jointly select features. It aims at finding an subset of features;which maximize the lower bound of traditional Fisher score. The resulting feature selectionproblem is a mixed integer programming; which can be reformulated as a quadraticallyconstrained linear programming (QCLP). It is solved by cutting plane algorithm; in eachiteration of which a multiple kernel learning problem is solved alternatively by multivariateridge regression and projected gradient descent. Experiments on benchmark data setsindicate that the proposed method outperforms Fisher score as well as many other state …,arXiv preprint arXiv:1202.3725,2012,220
Data classification: algorithms and applications,Charu C Aggarwal,Comprehensive Coverage of the Entire Area of Classification Research on the problem ofclassification tends to be fragmented across such areas as pattern recognition; database;data mining; and machine learning. Addressing the work of these different communities in aunified way; Data Classification: Algorithms and Applications explores the underlyingalgorithms of classification as well as applications of classification in a variety of problemdomains; including text; multimedia; social network; and biological data. Thiscomprehensive book focuses on three primary aspects of data classification: Methods: Thebook first describes common techniques used for classification; including probabilisticmethods; decision trees; rule-based methods; instance-based methods; support vectormachine methods; and neural networks. Domains: The book then examines specific …,*,2014,185
Collaborative filtering: Weighted nonnegative matrix factorization incorporating user and item graphs,Quanquan Gu; Jie Zhou; Chris Ding,Abstract Collaborative filtering is an important topic in data mining and has been widelyused in recommendation system. In this paper; we proposed a unified model forcollaborative filtering based on graph regularized weighted nonnegative matrix factorization.In our model; two graphs are constructed on users and items; which exploit the internalinformation (eg neighborhood information in the user-item rating matrix) and externalinformation (eg content information such as user's occupation and item's genre; or other kindof knowledge such as social trust network). The proposed method not only inherits theadvantages of model-based method; but also owns the merits of memory-based methodwhich considers the neighborhood information. Moreover; it has the ability to make use ofcontent information and any additional information regarding user-user such as social …,*,2010,151
Co-clustering on manifolds,Quanquan Gu; Jie Zhou,Abstract Co-clustering is based on the duality between data points (eg documents) andfeatures (eg words); ie data points can be grouped based on their distribution on features;while features can be grouped based on their distribution on the data points. In the pastdecade; several co-clustering algorithms have been proposed and shown to be superior totraditional one-side clustering. However; existing co-clustering algorithms fail to consider thegeometric structure in the data; which is essential for clustering data on manifold. To addressthis problem; in this paper; we propose a Dual Regularized Co-Clustering (DRCC) methodbased on semi-nonnegative matrix tri-factorization. We deem that not only the data points;but also the features are sampled from some manifolds; namely data manifold and featuremanifold respectively. As a result; we construct two graphs; ie data graph and feature …,Proceedings of the 15th ACM SIGKDD international conference on Knowledge discovery and data mining,2009,145
Personalized entity recommendation: A heterogeneous information network approach,Xiao Yu; Xiang Ren; Yizhou Sun; Quanquan Gu; Bradley Sturt; Urvashi Khandelwal; Brandon Norick; Jiawei Han,Abstract Among different hybrid recommendation techniques; network-based entityrecommendation methods; which utilize user or item relationship information; are beginningto attract increasing attention recently. Most of the previous studies in this category onlyconsider a single relationship type; such as friendships in a social network. In manyscenarios; the entity recommendation problem exists in a heterogeneous informationnetwork environment. Different types of relationships can be potentially used to improve therecommendation quality. In this paper; we study the entity recommendation problem inheterogeneous information networks. Specifically; we propose to combine heterogeneousrelationship information for each user differently and aim to provide high-qualitypersonalized recommendation results using user implicit feedback data and personalized …,Proceedings of the 7th ACM international conference on Web search and data mining,2014,137
Joint feature selection and subspace learning,Quanquan Gu; Zhenhui Li; Jiawei Han,Abstract Dimensionality reduction is a very important topic in machine learning. It can begenerally classified into two categories: feature selection and subspace learning. In the pastdecades; many methods have been proposed for dimensionality reduction. However; mostof these works study feature selection and subspace learning independently. In this paper;we present a framework for joint feature selection and subspace learning. We reformulatethe subspace learning problem and use L2; 1-norm on the projection matrix to achieverowsparsity; which leads to selecting relevant features and learning transformationsimultaneously. We discuss two situations of the proposed framework; and present theiroptimization algorithms. Experiments on benchmark face recognition data sets illustrate thatthe proposed framework outperforms the state of the art methods overwhelmingly.,IJCAI Proceedings-International Joint Conference on Artificial Intelligence,2011,110
Learning the shared subspace for multi-task clustering and transductive transfer classification,Quanquan Gu; Jie Zhou,There are many clustering tasks which are closely related in the real world; eg clustering theweb pages of different universities. However; existing clustering approaches neglect theunderlying relation and treat these clustering tasks either individually or simply together. Inthis paper; we will study a novel clustering paradigm; namely multi-task clustering; whichperforms multiple related clustering tasks together and utilizes the relation of these tasks toenhance the clustering performance. We aim to learn a subspace shared by all the tasks;through which the knowledge of the tasks can be transferred to each other. The objective ofour approach consists of two parts:(1) Within-task clustering: clustering the data of each taskin its input space individually; and (2) Cross-task clustering: simultaneous learning theshared subspace and clustering the data of all the tasks together. We will show that it can …,Data Mining; 2009. ICDM'09. Ninth IEEE International Conference on,2009,88
Citation prediction in heterogeneous bibliographic networks,Xiao Yu; Quanquan Gu; Mianwei Zhou; Jiawei Han,Abstract To reveal information hiding in link space of bibliographical networks; link analysishas been studied from different perspectives in recent years. In this paper; we address anovel problem namely citation prediction; that is: given information about authors; topics;target publication venues as well as time of certain research paper; finding and predictingthe citation relationship between a query paper and a set of previous papers. Consideringthe gigantic size of relevant papers; the loosely connected citation network structure as wellas the highly skewed citation relation distribution; citation prediction is more challengingthan other link prediction problems which have been studied before. By building a meta-pathbased prediction model on a topic discriminative search space; we here propose a two-phase citation probability learning approach; in order to predict citation relationship …,*,2012,75
Clustered support vector machines,Quanquan Gu; Jiawei Han,Abstract In many problems of machine learning; the data are distributed nonlinearly. Oneway to address this kind of data is training a nonlinear classifier such as kernel supportvector machine (kernel SVM). However; the computational burden of kernel SVM limits itsapplication to large scale datasets. In this paper; we propose a Clustered Support VectorMachine (CSVM); which tackles the data in a divide and conquer manner. More specifically;CSVM groups the data into several clusters; followed which it trains a linear support vectormachine in each cluster to separate the data locally. Meanwhile; CSVM has an additionalglobal regularization; which requires the weight vector of each local linear SVM aligning witha global weight vector. The global regularization leverages the information from one clusterto another; and avoids over-fitting in each cluster. We derive a data-dependent …,Artificial Intelligence and Statistics,2013,74
Latent community topic analysis: Integration of community discovery with topic modeling,Zhijun Yin; Liangliang Cao; Quanquan Gu; Jiawei Han,Abstract This article studies the problem of latent community topic analysis in text-associatedgraphs. With the development of social media; a lot of user-generated content is availablewith user networks. Along with rich information in networks; user graphs can be extendedwith text information associated with nodes. Topic modeling is a classic problem in textmining and it is interesting to discover the latent topics in text-associated graphs. Differentfrom traditional topic modeling methods considering links; we incorporate communitydiscovery into topic analysis in text-associated graphs to guarantee the topical coherence inthe communities so that users in the same community are closely linked to each other andshare common latent topics. We handle topic modeling and community discovery in thesame framework. In our model we separate the concepts of community and topic; so one …,ACM Transactions on Intelligent Systems and Technology (TIST),2012,67
Recommendation in heterogeneous information networks with implicit user feedback,Xiao Yu; Xiang Ren; Yizhou Sun; Bradley Sturt; Urvashi Khandelwal; Quanquan Gu; Brandon Norick; Jiawei Han,Abstract Recent studies suggest that by using additional user or item relationshipinformation when building hybrid recommender systems; the recommendation quality canbe largely improved. However; most such studies only consider a single type of relationship;eg; social network. Notice that in many applications; the recommendation problem exists inan attribute-rich heterogeneous information network environment. In this paper; we study theentity recommendation problem in heterogeneous information networks. We propose tocombine various relationship information from the network with user feedback to providehigh quality recommendation results. The major challenge of building recommendersystems in heterogeneous information networks is to systematically define features torepresent the different types of relationships between entities; and learn the importance of …,Proceedings of the 7th ACM conference on Recommender systems,2013,63
Correlated multi-label feature selection,Quanquan Gu; Zhenhui Li; Jiawei Han,Abstract Multi-label learning studies the problem where each instance is associated with aset of labels. There are two challenges in multi-label learning:(1) the labels areinterdependent and correlated; and (2) the data are of high dimensionality. In this paper; weaim to tackle these challenges in one shot. In particular; we propose to learn the labelcorrelation and do feature selection simultaneously. We introduce a matrix-variate Normalprior distribution on the weight vectors of the classifier to model the label correlation. Ourgoal is to find a subset of features; based on which the label correlation regularized loss oflabel ranking is minimized. The resulting multi-label feature selection problem is a mixedinteger programming; which is reformulated as quadratically constrained linearprogramming (QCLP). It can be solved by cutting plane algorithm; in each iteration of …,Proceedings of the 20th ACM international conference on Information and knowledge management,2011,51
Local learning regularized nonnegative matrix factorization,Quanquan Gu Jie Zhou,Abstract Nonnegative Matrix Factorization (NMF) has been widely used in machine learningand data mining. It aims to find two nonnegative matrices whose product can wellapproximate the nonnegative data matrix; which naturally lead to parts-basedrepresentation. In this paper; we present a local learning regularized nonnegative matrixfactorization (LLNMF) for clustering. It imposes an additional constraint on NMF that thecluster label of each point can be predicted by the points in its neighborhood. This constraintencodes both the discriminative information and the geometric structure; and is good atclustering data on manifold. An iterative multiplicative updating algorithm is proposed tooptimize the objective; and its convergence is guaranteed theoretically. Experiments onmany benchmark data sets demonstrate that the proposed method outperforms NMF as …,*,2009,47
A network-assisted co-clustering algorithm to discover cancer subtypes based on gene expression,Yiyi Liu; Quanquan Gu; Jack P Hou; Jiawei Han; Jian Ma,Cancer subtype information is critically important for understanding tumor heterogeneity.Existing methods to identify cancer subtypes have primarily focused on utilizing genericclustering algorithms (such as hierarchical clustering) to identify subtypes based on geneexpression data. The network-level interaction among genes; which is key to understandingthe molecular perturbations in cancer; has been rarely considered during the clusteringprocess. The motivation of our work is to develop a method that effectively incorporatesmolecular interaction networks into the clustering process to improve cancer subtypeidentification. We have developed a new clustering algorithm for cancer subtypeidentification; called “network-assisted co-clustering for the identification of cancersubtypes”(NCIS). NCIS combines gene network information to simultaneously group …,BMC bioinformatics,2014,41
Linear discriminant dimensionality reduction,Quanquan Gu; Zhenhui Li; Jiawei Han,Abstract Fisher criterion has achieved great success in dimensionality reduction. Tworepresentative methods based on Fisher criterion are Fisher Score and Linear DiscriminantAnalysis (LDA). The former is developed for feature selection while the latter is designed forsubspace learning. In the past decade; these two approaches are often studiedindependently. In this paper; based on the observation that Fisher score and LDA arecomplementary; we propose to integrate Fisher score and LDA in a unified framework;namely Linear Discriminant Dimensionality Reduction (LDDR). We aim at finding a subset offeatures; based on which the learnt linear transformation via LDA maximizes the Fishercriterion. LDDR inherits the advantages of Fisher score and LDA and is able to do featureselection and subspace learning simultaneously. Both Fisher score and LDA can be seen …,Joint European Conference on Machine Learning and Knowledge Discovery in Databases,2011,38
Cluscite: Effective citation recommendation by information network-based clustering,Xiang Ren; Jialu Liu; Xiao Yu; Urvashi Khandelwal; Quanquan Gu; Lidan Wang; Jiawei Han,Abstract Citation recommendation is an interesting but challenging research problem. Mostexisting studies assume that all papers adopt the same criterion and follow the samebehavioral pattern in deciding relevance and authority of a paper. However; in reality;papers have distinct citation behavioral patterns when looking for different references;depending on paper content; authors and target venues. In this study; we investigate theproblem in the context of heterogeneous bibliographic networks and propose a novel cluster-based citation recommendation framework; called ClusCite; which explores the principlethat citations tend to be softly clustered into interest groups based on multiple types ofrelationships in the network. Therefore; we predict each query's citations based on relatedinterest groups; each having its own model for paper authority and relevance. Specifically …,Proceedings of the 20th ACM SIGKDD international conference on Knowledge discovery and data mining,2014,36
Trustworthiness analysis of sensor data in cyber-physical systems,Lu-An Tang; Xiao Yu; Sangkyum Kim; Quanquan Gu; Jiawei Han; Alice Leung; Thomas La Porta,Abstract A Cyber-Physical System (CPS) is an integration of sensor networks withinformational devices. CPS can be used for many promising applications; such as trafficobservation; battlefield surveillance; and sensor-network-based monitoring. One key issuein CPS research is trustworthiness analysis of sensor data. Due to technology limitationsand environmental influences; the sensor data collected by CPS are inherently noisy andmay trigger many false alarms. It is highly desirable to sift meaningful information from alarge volume of noisy data. In this study; we propose a method called Tru-Alarm; whichincreases the capability of a CPS to recognize trustworthy alarms. Tru-Alarm estimates thelocations of objects causing alarms; constructs an object-alarm graph and carries outtrustworthiness inference based on the graph links. The study also reveals that the alarm …,Journal of Computer and System Sciences,2013,36
Towards feature selection in network,Quanquan Gu; Jiawei Han,Abstract Traditional feature selection methods assume that the data are independent andidentically distributed (iid). However; in real world; there are tremendous amount of datawhich are distributing in a network. Existing features selection methods are not suited fornetworked data because the iid assumption no longer holds. This motivates us to studyfeature selection in a network. In this paper; we present a supervised feature selectionmethod based on Laplacian Regularized Least Squares (LapRLS) for networked data. Indetail; we use linear regression to utilize the content information; and adopt graphregularization to consider the link information. The proposed feature selection method aimsat selecting a subset of features such that the empirical error of LapRLS is minimized. Theresultant optimization problem is a mixed integer programming; which is difficult to solve …,Proceedings of the 20th ACM international conference on Information and knowledge management,2011,36
Neighborhood Preserving Nonnegative Matrix Factorization.,Quanquan Gu; Jie Zhou,Abstract Nonnegative Matrix Factorization (NMF) has been widely used in computer visionand pattern recognition. It aims to find two nonnegative matrices whose product can wellapproximate the nonnegative data matrix; which naturally leads to parts-based and non-subtractive representation. In this paper; we present a neighborhood preservingnonnegative matrix factorization (NPNMF) for dimensionality reduction. It imposes anadditional constraint on NMF that each data point can be represented as a linearcombination of its neighbors. This constraint preserves the local geometric structure; and isgood at dimensionality reduction on manifold. An iterative multiplicative updating algorithmis proposed to optimize the objective; and its convergence is guaranteed theoretically.Experiments on benchmark face recognition data sets demonstrate that the proposed …,BMVC,2009,35
Learning a Kernel for Multi-Task Clustering.,Quanquan Gu; Zhenhui Li; Jiawei Han,Abstract Multi-task learning has received increasing attention in the past decade. Manysupervised multi-task learning methods have been proposed; while unsupervised multitasklearning is still a rarely studied problem. In this paper; we propose to learn a kernel for multi-task clustering. Our goal is to learn a Reproducing Kernel Hilbert Space; in which thegeometric structure of the data in each task is preserved; while the data distributions of anytwo tasks are as close as possible. This is formulated as a unified kernel learning framework;under which we study two types of kernel learning: nonparametric kernel learning andspectral kernel design. Both types of kernel learning can be solved by linear programming.Experiments on several cross-domain text data sets demonstrate that kernel k-means on thelearned kernel can achieve better clustering results than traditional single-task clustering …,AAAI,2011,34
On trivial solution and scale transfer problems in graph regularized nmf,Quanquan Gu; Chris Ding; Jiawei Han,Abstract Combining graph regularization with nonnegative matrix (tri-) factorization (NMF)has shown great performance improvement compared with traditional nonnegative matrix (tri-) factorization models due to its ability to utilize the geometric structure of the documents andwords. In this paper; we show that these models are not well-defined and suffering fromtrivial solution and scale transfer problems. In order to solve these common problems; wepropose two models for graph regularized nonnegative matrix (tri-) factorization; which canbe applied for document clustering and co-clustering respectively. In the proposed models; aNormalized Cut-like constraint is imposed on the cluster assignment matrix to make theoptimization problem well-defined. We derive a multiplicative updating algorithm for theproposed models; and prove its convergence. Experiments of clustering and coclustering …,IJCAI Proceedings-International Joint Conference on Artificial Intelligence,2011,28
Collaborative filtering with entity similarity regularization in heterogeneous information networks,Xiao Yu; Xiang Ren; Quanquan Gu; Yizhou Sun; Jiawei Han,Abstract Researchers have been studying hybrid recommender systems which combineuser-item rating data with external information in recent years. Some studies suggest that byleveraging additional user and/or item relations; eg; social network; the performance of therecommendation models can be improved. These studies; nevertheless; mostly utilize asingle type of external relationship. Considering the heterogeneity of real-world applications;we propose to position the well-studied recommendation problem in a heterogeneousinformation network context and attempt to incorporate different recommendation factors. Wediscuss how heterogeneous information network can benefit recommender systems andthen propose a matrix factorization based unified recommendation model to take advantageof both rating data and the related information network. Empirical studies show that our …,IJCAI HINA,2013,26
High dimensional expectation-maximization algorithm: Statistical optimization and asymptotic normality,Zhaoran Wang; Quanquan Gu; Yang Ning; Han Liu,Abstract: We provide a general theory of the expectation-maximization (EM) algorithm forinferring high dimensional latent variable models. In particular; we make two contributions:(i)For parameter estimation; we propose a novel high dimensional EM algorithm whichnaturally incorporates sparsity structure into parameter estimation. With an appropriateinitialization; this algorithm converges at a geometric rate and attains an estimator with the(near-) optimal statistical rate of convergence.(ii) Based on the obtained estimator; wepropose new inferential procedures for testing hypotheses and constructing confidenceintervals for low dimensional components of high dimensional parameters. For a broadfamily of statistical models; our framework establishes the first computationally feasibleapproach for optimal estimation and asymptotic inference in high dimensions. Our theory …,arXiv preprint arXiv:1412.8729,2014,24
Low-rank and sparse structure pursuit via alternating minimization,Quanquan Gu; Zhaoran Wang Wang; Han Liu,Abstract In this paper; we present a nonconvex alternating minimization optimizationalgorithm for low-rank and sparse structure pursuit. Compared with convex relaxation basedmethods; the proposed algorithm is computationally more efficient for large scale problems.In our study; we define a notion of bounded difference of gradients; based on which werigorously prove that with suitable initialization; the proposed nonconvex optimizationalgorithm enjoys linear convergence to the global optima and exactly recovers theunderlying low rank and sparse matrices under standard conditions such as incoherenceand sparsity conditions. For a wide range of statistical models such as multi-task learningand robust principal component analysis (RPCA); our algorithm provides a principledapproach to learning the low rank and sparse structures with provable guarantee …,Artificial Intelligence and Statistics,2016,23
Towards active learning on graphs: An error bound minimization approach,Quanquan Gu; Jiawei Han,Active learning on graphs has received increasing interest in the past years. In this paper;we propose a\textit {nonadaptive} active learning approach on graphs; based ongeneralization error bound minimization. In particular; we present a data-dependent errorbound for a graph-based learning method; namely learning with local and globalconsistency (LLGC). We show that the empirical transductive Rademacher complexity of thefunction class for LLGC provides a natural criterion for active learning. The resulting activelearning approach is to select a subset of nodes on a graph such that the empiricaltransductive Rademacher complexity of LLGC is minimized. We propose a simple yeteffective sequential optimization algorithm to solve it. Experiments on benchmark datasetsshow that the proposed method outperforms the state-of-the-art active learning methods …,Data Mining; 2012. ICDM'12. Ninth IEEE International Conference on,2012,22
Batch-mode active learning via error bound minimization,Quanquan Gu; Tong Zhang; Jiawei Han,Abstract Active learning has been proven to be quite effective in reducing the humanlabeling efforts by actively selecting the most informative examples to label. In this paper; wepresent a batch-mode active learning method based on logistic regression. Our keymotivation is an out-of-sample bound on the estimation error of class distribution in logisticregression conditioned on any fixed training sample. It is different from a typical PAC-stylepassive learning error bound; that relies on the iid assumption of example-label pairs. Inaddition; it does not contain the class labels of the training sample. Therefore; it can beimmediately used to design an active learning algorithm by minimizing this bound iteratively.We also discuss the connections between the proposed method and some existing activelearning approaches. Experiments on benchmark UCI datasets and text datasets …,Urbana,2014,18
Wireless sensor network data collection by connected cooperative UAVs,Peng Wei; Quanquan Gu; Dengfeng Sun,Wireless sensor network is a prevailing research topic in recent years. It is adopted in thescenario of monitoring environmental parameters; which is normally expensive or evenimpossible to monitor by human labor or other technologies. At the same time; anotherpopular topic is Unmanned Aerial Vehicle (UAV); which is widely used in military;commercial and civilian activities. In this paper cooperative UAVs form a team to accomplishthe data collection task on wireless sensor network; where the technologies in wirelesssensor network and UAV are integrated together. We study the novel wireless sensornetwork data collection with UAVs by considering the cluster load balancing and theconnectivity of UAVs. We implement an Iterative Balanced Assignment with IntegerProgramming (IBA-IP) algorithm for efficient UAV deployment and sensor assignment …,American Control Conference (ACC); 2013,2013,17
Intrumine: Mining intruders in untrustworthy data of cyber-physical systems,Lu-An Tang; Quanquan Gu; Xiao Yu; Jiawei Han; Thomas La Porta; Alice Leung; Tarek Abdelzaher; Lance Kaplan,Abstract A Cyber-Physical System (CPS) integrates physical (ie; sensor) devices with cyber(ie; informational) components to form a situation-aware system that responds intelligently todynamic changes in real-world. It has wide application to scenarios of traffic control;environment monitoring and battlefield surveillance. This study investigates the specificproblem of intruder mining in CPS: With a large number of sensors deployed in a designatedarea; the task is real time detection of intruders who enter the area; based on untrustworthydata. We propose a method called IntruMine to detect and verify the intruders. IntruMineconstructs monitoring graphs to model the relationships between sensors and possibleintruders; and computes the position and energy of each intruder with the link informationfrom these monitoring graphs. Finally; a confidence rating is calculated for each potential …,*,2012,16
Sparse pca with oracle property,Quanquan Gu; Zhaoran Wang; Han Liu,Abstract In this paper; we study the estimation of the $ k $-dimensional sparse principalsubspace of covariance matrix $\Sigma $ in the high-dimensional setting. We aim to recoverthe oracle principal subspace solution; ie; the principal subspace estimator obtainedassuming the true support is known a priori. To this end; we propose a family of estimatorsbased on the semidefinite relaxation of sparse PCA with novel regularizations. In particular;under a weak assumption on the magnitude of the population projection matrix; oneestimator within this family exactly recovers the true support with high probability; has exactrank-$ k $; and attains a $\sqrt {s/n} $ statistical rate of convergence with $ s $ being thesubspace sparsity level and $ n $ the sample size. Compared to existing support recoveryresults for sparse PCA; our approach does not hinge on the spiked covariance model or …,Advances in neural information processing systems,2014,14
Selective labeling via error bound minimization,Quanquan Gu; Tong Zhang; Jiawei Han; Chris H Ding,Abstract In many practical machine learning problems; the acquisition of labeled data isoften expensive and/or time consuming. This motivates us to study a problem as follows:given a label budget; how to select data points to label such that the learning performance isoptimized. We propose a selective labeling method by analyzing the generalization error ofLaplacian regularized Least Squares (LapRLS). In particular; we derive a deterministicgeneralization error bound for LapRLS trained on subsampled data; and propose to select asubset of data points to label by minimizing this upper bound. Since the minimization is acombinational problem; we relax it into continuous domain and solve it by projected gradientdescent. Experiments on benchmark datasets show that the proposed method outperformsthe state-of-the-art methods.,Advances in neural information processing systems,2012,14
A unified computational and statistical framework for nonconvex low-rank matrix estimation,Lingxiao Wang; Xiao Zhang; Quanquan Gu,Abstract: We propose a unified framework for estimating low-rank matrices throughnonconvex optimization based on gradient descent algorithm. Our framework is quitegeneral and can be applied to both noisy and noiseless observations. In the general casewith noisy observations; we show that our algorithm is guaranteed to linearly converge to theunknown low-rank matrix up to minimax optimal statistical error; provided an appropriateinitial estimator. While in the generic noiseless setting; our algorithm converges to theunknown low-rank matrix at a linear rate and enables exact recovery with optimal samplecomplexity. In addition; we develop a new initialization algorithm to provide a desired initialestimator; which outperforms existing initialization algorithms for nonconvex low-rank matrixestimation. We illustrate the superiority of our framework through three examples: matrix …,arXiv preprint arXiv:1610.05275,2016,13
Active learning: A survey,Charu C Aggarwal; Xiangnan Kong; Quanquan Gu; Jiawei Han; Philip S Yu,CiteSeerX - Document Details (Isaac Councill; Lee Giles; Pradeep Teregowda):,*,2014,13
Robust tensor decomposition with gross corruption,Quanquan Gu; Huan Gui; Jiawei Han,Abstract In this paper; we study the statistical performance of robust tensor decompositionwith gross corruption. The observations are noisy realization of the superposition of a low-rank tensor $\mathcal {W}^* $ and an entrywise sparse corruption tensor $\mathcal {V}^* $.Unlike conventional noise with bounded variance in previous convex tensor decompositionanalysis; the magnitude of the gross corruption can be arbitrary large. We show that undercertain conditions; the true low-rank tensor as well as the sparse corruption tensor can berecovered simultaneously. Our theory yields nonasymptotic Frobenius-norm estimation errorbounds for each tensor separately. We show through numerical experiments that our theorycan precisely predict the scaling behavior in practice.,Advances in Neural Information Processing Systems,2014,13
Selective sampling on graphs for classification,Quanquan Gu; Charu Aggarwal; Jialu Liu; Jiawei Han,Abstract Selective sampling is an active variant of online learning in which the learner isallowed to adaptively query the label of an observed example. The goal of selectivesampling is to achieve a good trade-off between prediction performance and the number ofqueried labels. Existing selective sampling algorithms are designed for vector-based data. Inthis paper; motivated by the ubiquity of graph representations in real-world applications; wepropose to study selective sampling on graphs. We first present an online version of the well-known Learning with Local and Global Consistency method (OLLGC). It is essentially asecond-order online learning algorithm; and can be seen as an online ridge regression inthe Hilbert space of functions defined on graphs. We prove its regret bound in terms of thestructural property (cut size) of a graph. Based on OLLGC; we present a selective …,Proceedings of the 19th ACM SIGKDD international conference on Knowledge discovery and data mining,2013,12
Mining lines in the sand: On trajectory discovery from untrustworthy data in cyber-physical system,Lu-An Tang; Xiao Yu; Quanquan Gu; Jiawei Han; Alice Leung; Thomas La Porta,Abstract A Cyber-Physical System (CPS) integrates physical (ie; sensor) devices with cyber(ie; informational) components to form a context sensitive system that responds intelligentlyto dynamic changes in real-world situations. The CPS has wide applications in scenariossuch as environment monitoring; battlefield surveillance and traffic control. One key researchproblem of CPS is called" mining lines in the sand". With a large number of sensors (sand)deployed in a designated area; the CPS is required to discover all the trajectories (lines) ofpassing intruders in real time. There are two crucial challenges that need to beaddressed:(1) the collected sensor data are not trustworthy;(2) the intruders do not send outany identification information. The system needs to distinguish multiple intruders and tracktheir movements. In this study; we propose a method called LiSM (Line-in-the-Sand Miner …,Proceedings of the 19th ACM SIGKDD international conference on Knowledge discovery and data mining,2013,12
Towards faster rates and oracle property for low-rank matrix estimation,Huan Gui; Quanquan Gu,Abstract: We present a unified framework for low-rank matrix estimation with nonconvexpenalties. We first prove that the proposed estimator attains a faster statistical rate than thetraditional low-rank matrix estimator with nuclear norm penalty. Moreover; we rigorouslyshow that under a certain condition on the magnitude of the nonzero singular values; theproposed estimator enjoys oracle property (ie; exactly recovers the true rank of the matrix);besides attaining a faster rate. As far as we know; this is the first work that establishes thetheory of low-rank matrix estimation with nonconvex penalties; confirming the advantages ofnonconvex penalties for matrix completion. Numerical experiments on both synthetic andreal world datasets corroborate our theory.,arXiv preprint arXiv:1505.04780,2015,11
HTF: A novel feature for general crack detection,Han Hu; Quanquan Gu; Jie Zhou,Recent years; image-based crack detection has attracted more and more attentions for itspotential applications on the inspection; diagnosis; and maintenance of various products; egmetal workpiece; concrete structure; asphalt road and etc. Generally; the applications areinevitably confronted with noises such as non-uniform illuminated conditions; shadings;stains and nature textures. To ease the problem; traditional methods usually focused on aspecial application and are carried out with strictly controlled image acquisitionenvironments or an adhoc preprocessing procedure. In this paper; we propose a generalcrack detection method which can deal with various products as well as the noises in aunified fashion; and even with the same parameters. The method partitions an image intooverlapped small grid cells and determines whether the cells contain cracks using a well …,Image Processing (ICIP); 2010 17th IEEE International Conference on,2010,11
Subspace maximum margin clustering,Quanquan Gu; Jie Zhou,Abstract In text mining; we are often confronted with very high dimensional data. Clusteringwith high dimensional data is a challenging problem due to the curse of dimensionality. Inthis paper; to address this problem; we propose an subspace maximum margin clustering(SMMC) method; which performs dimensionality reduction and maximum margin clusteringsimultaneously within a unified framework. We aim to learn a subspace; in which we try tofind a cluster assignment of the data points; together with a hyperplane classifier; such thatthe resultant margin is maximized among all possible cluster assignments and all possiblesubspaces. The original problem is transformed from learning the subspace to learning apositive semi-definite matrix; in order to avoid tuning the dimensionality of the subspace. Thetransformed problem can be solved efficiently via cutting plane technique and …,Proceedings of the 18th ACM conference on Information and knowledge management,2009,11
A similarity measure under Log-Euclidean metric for stereo matching,Quanquan Gu; Jie Zhou,Stereo matching has been one of the most active areas in computer vision for decades.Many methods; ranging from similarity measures to local or global matching costoptimization algorithms; have been proposed. In this paper; we propose a novel similaritymeasure under Log-Euclidean metric for stereo matching. A generalized structure tensor isapplied to describe a point and the similarity is measured by the distance between theassociated tensors. Since the structure tensor lies in a Riemannian manifold; the Log-Euclidean metric is adopted to calculate the distance between the generalized structuretensors. The proposed similarity measure can provide an effective and efficient way to fusedifferent features and is independent of illumination change and window scaling.Experiments on standard data set prove that the proposed similarity measure outperforms …,Pattern Recognition; 2008. ICPR 2008. 19th International Conference on,2008,11
Identifying gene regulatory network rewiring using latent differential graphical models,Dechao Tian; Quanquan Gu; Jian Ma,Abstract Gene regulatory networks (GRNs) are highly dynamic among different tissue types.Identifying tissue-specific gene regulation is critically important to understand gene functionin a particular cellular context. Graphical models have been used to estimate GRN fromgene expression data to distinguish direct interactions from indirect associations. However;most existing methods estimate GRN for a specific cell/tissue type or in a tissue-naive way;or do not specifically focus on network rewiring between different tissues. Here; we describea new method called Latent Differential Graphical Model (LDGM). The motivation of ourmethod is to estimate the differential network between two tissue types directly withoutinferring the network for individual tissues; which has the advantage of utilizing muchsmaller sample size to achieve reliable differential network estimation. Our simulation …,Nucleic acids research,2016,10
Accelerated Stochastic Block Coordinate Gradient Descent for Sparsity Constrained Nonconvex Optimization.,Jinghui Chen; Quanquan Gu,Abstract We propose an accelerated stochastic block coordinate descent algorithm fornonconvex optimization under sparsity constraint in the high dimensional regime. The coreof our algorithm is leveraging both stochastic partial gradient and full partial gradientrestricted to each coordinate block to accelerate the convergence. We prove that thealgorithm converges to the unknown true parameter at a linear rate; up to the statistical errorof the underlying model. Experiments on both synthetic and real datasets backup our theory.,UAI,2016,10
Local and Global Inference for High Dimensional Gaussian Copula Graphical Models,Quanquan Gu; Yuan Cao; Yang Ning; Han Liu,Abstract In this paper; we propose a unified asymptotic inference framework for Gaussiancopula graphical models; to test the presence of a single edge and construct a uniformconfidence subgraph for the true graph. To avoid the estimation of the unknown marginaltransformation functions; we consider a pseudo likelihood approach. The core of ourframework is a decorrelated pseudo score function for the parameter of interest. Theproposed pseudo score function has the structure of a nonlinear transformation of U-statistics; and a delta method-type analysis is used to prove its asymptotic normality. Ourtheory provides asymptotic guarantees on the type I error as well as the local power of theproposed score test. We also propose a global hypothesis testing procedure based on Waldtest statistic and multiplier bootstrap; to provide a confidence subgraph for the true graph …,arXiv preprint arXiv:1502.02347,2015,10
High dimensional em algorithm: Statistical optimization and asymptotic normality,Zhaoran Wang; Quanquan Gu; Yang Ning; Han Liu,Abstract We provide a general theory of the expectation-maximization (EM) algorithm forinferring high dimensional latent variable models. In particular; we make two contributions:(i)For parameter estimation; we propose a novel high dimensional EM algorithm whichnaturally incorporates sparsity structure into parameter estimation. With an appropriateinitialization; this algorithm converges at a geometric rate and attains an estimator with the(near-) optimal statistical rate of convergence.(ii) Based on the obtained estimator; wepropose a new inferential procedure for testing hypotheses for low dimensional componentsof high dimensional parameters. For a broad family of statistical models; our frameworkestablishes the first computationally feasible approach for optimal estimation and asymptoticinference in high dimensions.,Advances in neural information processing systems,2015,10
Locality preserving feature learning,Quanquan Gu; Marina Danilevsky; Zhenhui Li; Jiawei Han,Abstract Locality Preserving Indexing (LPI) has been quite successful in tackling documentanalysis problems; such as clustering or classification. The approach relies on the LocalityPreserving Criterion; which preserves the locality of the data points. However; LPI takesevery word in a data corpus into account; even though many words may not be useful fordocument clustering. To overcome this problem; we propose an approach called LocalityPreserving Feature Learning (LPFL); which incorporates feature selection into LPI.Specifically; we aim to find a subset of features; and learn a linear transformation to optimizethe Locality Preserving Criterion based on these features. The resulting optimizationproblem is a mixed integer programming problem; which we relax into a constrainedFrobenius norm minimization problem; and solve using a variation of Alternating Direction …,Artificial Intelligence and Statistics,2012,10
Transductive classification via dual regularization,Quanquan Gu; Jie Zhou,Abstract Semi-supervised learning has witnessed increasing interest in the past decade.One common assumption behind semi-supervised learning is that the data labels should besufficiently smooth with respect to the intrinsic data manifold. Recent research has shownthat the features also lie on a manifold. Moreover; there is a duality between data points andfeatures; that is; data points can be classified based on their distribution on features; whilefeatures can be classified based on their distribution on the data points. However; existingsemi-supervised learning methods neglect these points. Based on the above observations;in this paper; we present a dual regularization; which consists of two graph regularizers anda co-clustering type regularizer. In detail; the two graph regularizers consider the geometricstructure of the data points and the features respectively; while the co-clustering type …,Joint European Conference on Machine Learning and Knowledge Discovery in Databases,2009,10
Local relevance weighted maximum margin criterion for text classification,Quanquan Gu; Jie Zhou,Abstract Text classification is a very important task in information retrieval and data mining.In vector space model (VSM); document is represented as a high dimensional vector; and afeature extraction phase is usually needed to reduce the dimensionality of the document. Inthis paper; we propose a feature extraction method; named Local Relevance WeightedMaximum Margin Criterion (LRWMMC). It aims to learn a subspace in which the documentsin the same class are as near as possible while the documents in the different classes are asfar as possible in the local region of each document. Furthermore; the relevance is taken intoaccount as a weight to determine the extent to which the documents will be projected.LRWMMC is able to find the low dimensional manifold embedded in the high dimensionalambient space. In addition; We generalize LRWMMC to Reproducing Kernel Hilbert …,*,2009,10
Classification with active learning and meta-paths in heterogeneous information networks,Chang Wan; Xiang Li; Ben Kao; Xiao Yu; Quanquan Gu; David Cheung; Jiawei Han,Abstract A heterogeneous information network (HIN) is used to model objects of differenttypes and their relationships. Meta-paths are sequences of object types. They are used torepresent complex relationships between objects beyond what links in a homogeneousnetwork capture. We study the problem of classifying objects in an HIN. We propose class-level meta-paths and study how they can be used to (1) build more accurate classifiers and(2) improve active learning in identifying objects for which training labels should beobtained. We show that class-level meta-paths and object classification exhibit interestingsynergy. Our experimental results show that the use of class-level meta-paths results in veryeffective active learning and good classification performance in HINs.,Proceedings of the 24th ACM International on Conference on Information and Knowledge Management,2015,9
Towards a lower sample complexity for robust one-bit compressed sensing,Rongda Zhu; Quanquan Gu,Abstract In this paper; we propose a novel algorithm based on nonconvex sparsity-inducingpenalty for one-bit compressed sensing. We prove that our algorithm has a samplecomplexity of O (s/ε^ 2) for strong signals; and O (s\log d/ε^ 2) for weak signals; where s isthe number of nonzero entries in the signal vector; d is the signal dimension and εis therecovery error. For general signals; the sample complexity of our algorithm lies between O(s/ε^ 2) and O (s\log d/ε^ 2). This is a remarkable improvement over the existing best samplecomplexity O (s\log d/ε^ 2). Furthermore; we show that our algorithm achieves exact supportrecovery with high probability for strong signals. Our theory is verified by extensivenumerical experiments; which clearly illustrate the superiority of our algorithm for bothapproximate signal and support recovery in the noisy setting.,International Conference on Machine Learning,2015,9
Two dimensional maximum margin criterion,Quanquan Gu; Jie Zhou,Maximum Margin Criterion is a well-known method for feature extraction and dimensionalityreduction. In this paper; we propose a novel feature extraction method; namely TwoDimensional Maximum Margin Criterion (2DMMC); specifically for matrix representationdata; eg images. 2DMMC aims to find two orthogonal projection matrices to project theoriginal matrices to a low dimensional matrix subspace; in which a sample is close to thosein the same class but far from those in different classes. Both theoretical analysis andexperiments on benchmark face recognition data sets illustrate that the proposed method isvery effective and efficient.,Acoustics; Speech and Signal Processing; 2009. ICASSP 2009. IEEE International Conference on,2009,9
Contextual bandits in a collaborative environment,Qingyun Wu; Huazheng Wang; Quanquan Gu; Hongning Wang,Abstract Contextual bandit algorithms provide principled online learning solutions to findoptimal trade-offs between exploration and exploitation with companion side-information.They have been extensively used in many important practical scenarios; such as displayadvertising and content recommendation. A common practice estimates the unknown banditparameters pertaining to each user independently. This unfortunately ignores dependencyamong users and thus leads to suboptimal solutions; especially for the applications thathave strong social components. In this paper; we develop a collaborative contextual banditalgorithm; in which the adjacency graph among users is leveraged to share context andpayoffs among neighboring users while online updating. We rigorously prove an improvedupper regret bound of the proposed collaborative bandit algorithm comparing to …,Proceedings of the 39th International ACM SIGIR conference on Research and Development in Information Retrieval,2016,8
Accelerated stochastic block coordinate descent with optimal sampling,Aston Zhang; Quanquan Gu,Abstract We study the composite minimization problem where the objective function is thesum of two convex functions: one is the sum of a finite number of strongly convex andsmooth functions; and the other is a general convex function that is non-differentiable.Specifically; we consider the case where the non-differentiable function is block separableand admits a simple proximal mapping for each block. This type of composite optimization iscommon in many data mining and machine learning problems; and can be solved by blockcoordinate descent algorithms. We propose an accelerated stochastic block coordinatedescent (ASBCD) algorithm; which incorporates the incrementally averaged partialderivative into the stochastic partial derivative and exploits optimal sampling. We prove thatASBCD attains a linear rate of convergence. In contrast to uniform sampling; we reveal …,Proceedings of the 22nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining,2016,7
Optimal statistical and computational rates for one bit matrix completion,Renkun Ni; Quanquan Gu,Abstract We consider one bit matrix completion under rank constraint. We present anestimator based on rank constrained maximum likelihood estimation; and an efficient greedyalgorithm to solve it approximately based on an extension of conditional gradient descent.The output of the proposed algorithm converges at a linear rate to the underlying true low-rank matrix up to the optimal statistical estimation error rate; ie; O (prn log (n)/| Ω|); where n isthe dimension of the underlying matrix and| Ω| is the number of observed entries. Our workestablishes the first computationally efficient approach with provable guarantee for optimalestimation in one bit matrix completion. Our theory is supported by thorough numericalresults.,Artificial Intelligence and Statistics,2016,7
Precision matrix estimation in high dimensional gaussian graphical models with faster rates,Lingxiao Wang; Xiang Ren; Quanquan Gu,Abstract We present a new estimator for precision matrix in high dimensional Gaussiangraphical models. At the core of the proposed estimator is a collection of node-wise linearregression with nonconvex penalty. In contrast to existing estimators for Gaussian graphicalmodels with O (s√ log d/n) estimation error bound in terms of spectral norm; where s is themaximum degree of a graph; the proposed estimator could attain O (s/√ n+√ log d/n)spectral norm based convergence rate in the best case; and it is no worse than exitingestimators in general. In addition; our proposed estimator enjoys the oracle property under amilder condition than existing estimators. We show through extensive experiments on bothsynthetic and real datasets that our estimator outperforms the state-of-the-art estimators.,Artificial Intelligence and Statistics,2016,6
Local and Global Inference for High Dimensional Nonparanormal Graphical Models,Quanquan Gu; Yuan Cao; Yang Ning; Han Liu,Abstract: This paper proposes a unified framework to quantify local and global inferentialuncertainty for high dimensional nonparanormal graphical models. In particular; we considerthe problems of testing the presence of a single edge and constructing a uniform confidencesubgraph. Due to the presence of unknown marginal transformations; we propose a pseudolikelihood based inferential approach. In sharp contrast to the existing high dimensionalscore test method; our method is free of tuning parameters given an initial estimator; andextends the scope of the existing likelihood based inferential framework. Furthermore; wepropose a U-statistic multiplier bootstrap method to construct the confidence subgraph. Weshow that the constructed subgraph is contained in the true graph with probability greaterthan a given nominal level. Compared with existing methods for constructing confidence …,arXiv preprint arXiv:1502.02347,2015,6
Sharp computational-statistical phase transitions via oracle computational model,Zhaoran Wang; Quanquan Gu; Han Liu,Abstract: We study the fundamental tradeoffs between computational tractability andstatistical accuracy for a general family of hypothesis testing problems with combinatorialstructures. Based upon an oracle model of computation; which captures the interactionsbetween algorithms and data; we establish a general lower bound that explicitly connectsthe minimum testing risk under computational budget constraints with the intrinsicprobabilistic and combinatorial structures of statistical problems. This lower bound mirrorsthe classical statistical lower bound by Le Cam (1986) and allows us to quantify the optimalstatistical performance achievable given limited computational budgets in a systematicfashion. Under this unified framework; we sharply characterize the statistical-computationalphase transition for two testing problems; namely; normal mean detection and sparse …,arXiv preprint arXiv:1512.08861,2015,5
Gin: A clustering model for capturing dual heterogeneity in networked data,Jialu Liu; Chi Wang; Jing Gao; Quanquan Gu; Charu Aggarwal; Lance Kaplan; Jiawei Han,Abstract Networked data often consists of interconnected multi-typed nodes and links. Acommon assumption behind such heterogeneity is the shared clustering structure. However;existing network clustering approaches over-simplify the heterogeneity by either treatingnodes or links in a homogeneous fashion; resulting in massive loss of information. Inaddition; these studies are more or less restricted to specific network schemas orapplications; losing generality. In this paper; we introduce a flexible model to explain theprocess of forming heterogeneous links based on shared clustering information ofheterogeneous nodes. Specifically; we categorize the link generation process into binaryand weighted cases and model them respectively. We show these two cases can beseamlessly integrated into a unified model. We propose to maximize a joint log-likelihood …,*,2015,5
Two dimensional nonnegative matrix factorization,Quanquan Gu; Jie Zhou,Nonnegative Matrix Factorization (NMF) has been widely used in computer vision andpattern recognition. It aims to find two nonnegative matrices whose product can wellapproximate the original matrix; which naturally leads to parts-based representation. In thispaper; we propose a Two Dimensional Nonnegative Matrix Factorization (2DNMF);specifically for a sequence of matrices. In contrast to NMF which applies for only a singlematrix; and finds only one base matrix; 2DNMF aims to find two base matrices to representthe input matrices in a low dimensional matrix subspace. It not only inherits the advantagesof NMF; but also owns the properties low computational complexity; as well as highrecognition accuracy. Experiments on benchmark image recognition data sets illustrate thatthe proposed method is very effective and efficient.,Image Processing (ICIP); 2009 16th IEEE International Conference on,2009,5
Belief propagation on Riemannian manifold for stereo matching,Quanquan Gu; Jie Zhou,Stereo matching has been one of the most active research areas in computer vision fordecades. Many methods; ranging from similarity measures to local or global matching costoptimization algorithms; have been proposed. As we known; stereo matching can beformulated under the framework of Markov random field (MRF); and the global optimizationin stereo matching can be approximated by inference procedure. There are many exact orapproximate inference algorithms; among which belief propagation is one of the mosteffective. In this paper; by combining Riemannian metric based similarity measure with thebelief propagation algorithm; we propose a global optimization method for stereo matching;namely belief propagation on Riemannian manifold (BPRM). Experiments on benchmarkdataset demonstrate the encouraging performance of our method.,Image Processing; 2008. ICIP 2008. 15th IEEE International Conference on,2008,5
A novel similarity measure under Riemannian metric for stereo matching,Quanquan Gu; Jie Zhou,Stereo matching has been one of the most active areas in computer vision for decades.Many methods; ranging from similarity measures to local or global matching costoptimization algorithms; have been proposed. In this paper; we propose a novel similaritymeasure under Riemannian metric. A generalized structure tensor is applied to describe apoint and the similarity is measured by the distance between the associated tensors. Sincethe structure tensor lies in a Riemannian manifold; the distance between structure tensors isthe geodesic distance on Riemannian manifold. We will show that our similarity measureprovides an efficient way to fuse different features and it is independent of illuminationchange and window scaling. Experiments on standard dataset prove that our similaritymeasure outperforms many traditional measures such as SSD; SAD and normalized …,Acoustics; Speech and Signal Processing; 2008. ICASSP 2008. IEEE International Conference on,2008,5
A nonconvex free lunch for low-rank plus sparse matrix recovery,Xiao Zhang; Lingxiao Wang; Quanquan Gu,Abstract: We study the problem of low-rank plus sparse matrix recovery. We propose ageneric and efficient nonconvex optimization algorithm based on projected gradient descentand double thresholding operator; with much lower computational complexity. Comparedwith existing convex-relaxation based methods; the proposed algorithm recovers the low-rank plus sparse matrices for free; without incurring any additional statistical cost. It not onlyenables exact recovery of the unknown low-rank and sparse matrices in the noiselesssetting; and achieves minimax optimal statistical error rate in the noisy case; but alsomatches the best-known robustness guarantee (ie; tolerance for sparse corruption). At thecore of our theory is a novel structural Lipschitz gradient condition for low-rank plus sparsematrices; which is essential for proving the linear convergence rate of our algorithm; and …,arXiv preprint arXiv:1702.06525,2017,4
Stochastic variance-reduced gradient descent for low-rank matrix recovery from linear measurements,Xiao Zhang; Lingxiao Wang; Quanquan Gu,Abstract: We study the problem of estimating low-rank matrices from linear measurements(aka; matrix sensing) through nonconvex optimization. We propose an efficient stochasticvariance reduced gradient descent algorithm to solve a nonconvex optimization problem ofmatrix sensing. Our algorithm can be applied to both noisy and noiseless observations. Inthe case with noisy observations; we prove that our algorithm converges to the unknown low-rank matrix at a linear rate up to the minimax optimal statistical error. While in the noiselesssetting; our algorithm is guaranteed to linearly converge to the unknown low-rank matrix andachieves exact recovery with optimal sample complexity. Most notably; the overallcomputational complexity of our proposed algorithm; which is defined as the iterationcomplexity times per iteration time complexity; is lower than the state-of-the-art algorithms …,arXiv preprint arXiv:1701.00481,2017,4
Communication-efficient Distributed Sparse Linear Discriminant Analysis,Lu Tian; Quanquan Gu,Abstract: We propose a communication-efficient distributed estimation method for sparselinear discriminant analysis (LDA) in the high dimensional regime. Our method distributesthe data of size $ N $ into $ m $ machines; and estimates a local sparse LDA estimator oneach machine using the data subset of size $ N/m $. After the distributed estimation; ourmethod aggregates the debiased local estimators from $ m $ machines; and sparsifies theaggregated estimator. We show that the aggregated estimator attains the same statisticalrate as the centralized estimation method; as long as the number of machines $ m $ ischosen appropriately. Moreover; we prove that our method can attain the model selectionconsistency under a milder condition than the centralized method. Experiments on bothsynthetic and real datasets corroborate our theory.,arXiv preprint arXiv:1610.04798,2016,4
A framework of mining trajectories from untrustworthy data in cyber-physical system,Lu-An Tang; Xiao Yu; Quanquan Gu; Jiawei Han; Guofei Jiang; Alice Leung; Thomas La Porta,Abstract A cyber-physical system (CPS) integrates physical (ie; sensor) devices with cyber(ie; informational) components to form a context-sensitive system that responds intelligentlyto dynamic changes in real-world situations. The CPS has wide applications in scenariossuch as environment monitoring; battlefield surveillance; and traffic control. One keyresearch problem of CPS is called mining lines in the sand. With a large number of sensors(sand) deployed in a designated area; the CPS is required to discover all trajectories (lines)of passing intruders in real time. There are two crucial challenges that need to beaddressed:(1) the collected sensor data are not trustworthy; and (2) the intruders do notsend out any identification information. The system needs to distinguish multiple intrudersand track their movements. This study proposes a method called LiSM (Line-in-the-Sand …,ACM Transactions on Knowledge Discovery from Data (TKDD),2015,4
Statistical Limits of Convex Relaxations,Zhaoran Wang; Quanquan Gu; Han Liu,Abstract: Many high dimensional sparse learning problems are formulated as nonconvexoptimization. A popular approach to solve these nonconvex optimization problems isthrough convex relaxations such as linear and semidefinite programming. In this paper; westudy the statistical limits of convex relaxations. Particularly; we consider two problems:Mean estimation for sparse principal submatrix and edge probability estimation forstochastic block model. We exploit the sum-of-squares relaxation hierarchy to sharplycharacterize the limits of a broad class of convex relaxations. Our result shows statisticaloptimality needs to be compromised for achieving computational tractability using convexrelaxations. Compared with existing results on computational lower bounds for statisticalproblems; which consider general polynomial-time algorithms and rely on computational …,arXiv preprint arXiv:1503.01442,2015,4
A Universal Variance Reduction-Based Catalyst for Nonconvex Low-Rank Matrix Recovery,Lingxiao Wang; Xiao Zhang; Quanquan Gu,Abstract: We propose a generic framework based on a new stochastic variance-reducedgradient descent algorithm for accelerating nonconvex low-rank matrix recovery. Startingfrom an appropriate initial estimator; our proposed algorithm performs projected gradientdescent based on a novel semi-stochastic gradient specifically designed for low-rank matrixrecovery. Based upon the mild restricted strong convexity and smoothness conditions; wederive a projected notion of the restricted Lipschitz continuous gradient property; and provethat our algorithm enjoys linear convergence rate to the unknown low-rank matrix with animproved computational complexity. Moreover; our algorithm can be employed to bothnoiseless and noisy observations; where the optimal sample complexity and the minimaxoptimal statistical rate can be attained respectively. We further illustrate the superiority of …,arXiv preprint arXiv:1701.02301,2017,3
Speeding Up Latent Variable Gaussian Graphical Model Estimation via Nonconvex Optimization,Pan Xu; Jian Ma; Quanquan Gu,Abstract We study the estimation of the latent variable Gaussian graphical model (LVGGM);where the precision matrix is the superposition of a sparse matrix and a low-rank matrix. Inorder to speed up the estimation of the sparse plus low-rank components; we propose asparsity constrained maximum likelihood estimator based on matrix factorization and anefficient alternating gradient descent algorithm with hard thresholding to solve it. Ouralgorithm is orders of magnitude faster than the convex relaxation based methods forLVGGM. In addition; we prove that our algorithm is guaranteed to linearly converge to theunknown sparse and low-rank components up to the optimal statistical precision.Experiments on both synthetic and genomic data demonstrate the superiority of ouralgorithm over the state-of-the-art algorithms and corroborate our theory.,Advances in Neural Information Processing Systems,2017,3
Semiparametric differential graph models,Pan Xu; Quanquan Gu,Abstract In many cases of network analysis; it is more attractive to study how a networkvaries under different conditions than an individual static network. We propose a novelgraphical model; namely Latent Differential Graph Model; where the networks under twodifferent conditions are represented by two semiparametric elliptical distributionsrespectively; and the variation of these two networks (ie; differential graph) is characterizedby the difference between their latent precision matrices. We propose an estimator for thedifferential graph based on quasi likelihood maximization with nonconvex regularization. Weshow that our estimator attains a faster statistical rate in parameter estimation than the state-of-the-art methods; and enjoys oracle property under mild conditions. Thorough experimentson both synthetic and real world data support our theory.,Advances in Neural Information Processing Systems,2016,3
Online spectral learning on a graph with bandit feedback,Quanquan Gu; Jiawei Han,Online learning on a graph is appealing due to its efficiency. However; existing onlinelearning algorithms on a graph are limited to binary classification. Moreover; they requireaccessing the full label information; where the label oracle needs to return the true classlabel after the learner makes classification of each node. In many application scenarios; weonly have access to partial label information; where the label oracle will return a single bitindicating whether the prediction is correct or not; instead of the true class label. This is alsoknown as bandit feedback. In this paper; to overcome the above limitations of existing onlinelearning algorithms on a graph; we study online learning on a graph for multi-class nodeclassification; in both the full information setting and the partial information setting. First; wepresent an online multi-class classification algorithm in the full information setting. It is …,Data Mining (ICDM); 2014 IEEE International Conference on,2014,3
Unsupervised link selection in networks,Quanquan Gu; Charu Aggarwal; Jiawei Han,Abstract Real-world networks are often noisy; and the existing linkage structure may not bereliable. For example; a link which connects nodes from different communities may affect thegroup assignment of nodes in a negative way. In this paper; we study a new problem calledlink selection; which can be seen as the network equivalent of the traditional featureselection problem in machine learning. More specifically; we investigate unsupervised linkselection as follows: given a network; it selects a subset of informative links from the originalnetwork which enhance the quality of community structures. To achieve this goal; we useRatio Cut size of a network as the quality measure. The resulting link selection approach canbe formulated as a semi-definite programming problem. In order to solve it efficiently; wepropose a backward elimination algorithm using sequential optimization. Experiments on …,Artificial Intelligence and Statistics,2013,3
Multiframe motion segmentation via penalized map estimation and linear programming,Han Hu; Quanquan Gu; Lei Deng; Jie Zhou,*,The 20th British Machine Vision Conference,2009,3
Accelerated stochastic mirror descent: From continuous-time dynamics to discrete-time algorithms,Pan Xu; Tianhao Wang; Quanquan Gu,Abstract We present a new framework to analyze accelerated stochastic mirror descentthrough the lens of continuous-time stochastic dynamic systems. It enables us to design newalgorithms; and perform a unified and simple analysis of the convergence rates of thesealgorithms. More specifically; under this framework; we provide a Lyapunov function basedanalysis for the continuous-time stochastic dynamics; as well as several new discrete-timealgorithms derived from the continuous-time dynamics. We show that for general convexobjective functions; the derived discrete-time algorithms attain the optimal convergence rate.Empirical experiments corroborate our theory.,Artificial Intelligence and Statistics,2018,2
Saving Gradient and Negative Curvature Computations: Finding Local Minima More Efficiently,Yaodong Yu; Difan Zou; Quanquan Gu,Abstract: We propose a family of nonconvex optimization algorithms that are able to savegradient and negative curvature computations to a large extent; and are guaranteed to findan approximate local minimum with improved runtime complexity. At the core of ouralgorithms is the division of the entire domain of the objective function into small and largegradient regions: our algorithms only perform gradient descent based procedure in the largegradient region; and only perform negative curvature descent in the small gradient region.Our novel analysis shows that the proposed algorithms can escape the small gradientregion in only one negative curvature descent step whenever they enter it; and thus theyonly need to perform at most $ N_ {\epsilon} $ negative curvature direction computations;where $ N_ {\epsilon} $ is the number of times the algorithms enter small gradient regions …,arXiv preprint arXiv:1712.03950,2017,2
Efficient algorithm for sparse tensor-variate gaussian graphical models via gradient descent,Pan Xu; Tingting Zhang; Quanquan Gu,Abstract We study the sparse tensor-variate Gaussian graphical model (STGGM); whereeach way of the tensor follows a multivariate normal distribution whose precision matrix hassparse structures. In order to estimate the precision matrices; we propose a sparsityconstrained maximum likelihood estimator. However; due to the complex structure of thetensor-variate GGMs; the likelihood based estimator is non-convex; which poses greatchallenges for both computation and theoretical analysis. In order to address thesechallenges; we propose an efficient alternating gradient descent algorithm to solve thisestimator; and prove that; under certain conditions on the initial estimator; our algorithm isguaranteed to linearly converge to the unknown precision matrices up to the optimalstatistical error. Experiments on both synthetic data and real world brain imaging data …,Artificial Intelligence and Statistics,2017,2
Forward Backward Greedy Algorithms for Multi-Task Learning with Faster Rates.,Lu Tian; Pan Xu; Quanquan Gu,Abstract A large body of algorithms have been proposed for multi-task learning. However;the effectiveness of many multi-task learning algorithms highly depends on the structuralregularization; which incurs bias in the resulting estimators and leads to slower convergencerate. In this paper; we aim at developing a multi-task learning algorithm with fasterconvergence rate. In particular; we propose a general estimator for multitask learning withrow sparsity constraint on the parameter matrix; ie; the number of nonzero rows in theparameter matrix being small. The proposed estimator is a nonconvex optimization problem.In order to solve it; we develop a forward backward greedy algorithm with provableguarantee. More specifically; we prove that the output of the greedy algorithm attains asharper estimation error bound than many state-of-the-art multi-task learning methods …,UAI,2016,2
Statistical analysis of DMV crash data,Wenting Tong; Paul Cherian; Jianzhe Liu; Haoyu Li; Quanquan Gu,The purpose of this paper is to present statistical methods and models we used to find outfactors that caused fatal car crashes and high damage cost. The benefit of our project is thatthe Virginia DMV can make some adjustments accordingly and reduce the number ofcrashes that are fatal and have high damage cost. The data we used is between 2010 and2014 for both fatality analysis and damage cost analysis. Data of 2015 was used for fatalityanalysis only. In the first part of this paper; we will introduce how we find factors that causedfatal car crashes. Since the data are unbalanced; we first subsampled the non-fatal crashesand applied a higher weight for fatal crashes. When building the model; we used logisticregression model to predict whether an accident is fatal or not. To select features that aremore important; we used factors that are all numeric and with correlation value more than …,Systems and Information Engineering Design Symposium (SIEDS); 2016 IEEE,2016,2
Robust classification of information networks by consistent graph learning,Shi Zhi; Jiawei Han; Quanquan Gu,Abstract Graph regularization-based methods have achieved great success for networkclassification by making the label-link consistency assumption; ie; if two nodes are linkedtogether; they are likely to belong to the same class. However; in a real-world network; thereexist links that connect nodes of different classes. These inconsistent links raise a bigchallenge for graph regularization and deteriorate the classification performancesignificantly. To address this problem; we propose a novel algorithm; namely ConsistentGraph Learning; which is robust to the inconsistent links of a network. In particular; given anetwork and a small number of labeled nodes; we aim at learning a consistent network withmore consistent and fewer inconsistent links than the original network. Since the linkinformation of a network is naturally represented by a set of relation matrices; the learning …,Joint European Conference on Machine Learning and Knowledge Discovery in Databases,2015,2
A practical algorithm for learning scene information from monocular video,Lin Zhu; Jie Zhou; Jingyan Song; Zhenlei Yan; Quanquan Gu,The estimate of the scene information; such as the region of ground/non-ground; the relativedepth of the ground and the unevenness of ground; is important for applications such asvideo surveillance; mapbuilding and etc. Previous research in this field is based on specificassumptions which are difficult to satisfy in practical situations. In this paper a practicalalgorithm is proposed to estimate the scene information in monocular video. With thepedestrian detection results for a period of time; the Pedestrian-Scene Map (PS Map);consisting of the average width of a pedestrian and occurrence probability of a pedestrian ateach position of the scene; is learned by integrating the pedestrian samples with differentsizes at different positions of the scene. Furthermore; the relative depth of ground region; theground/non-ground region and the unevenness of ground can be measured with PS Map …,Optics Express,2008,2
Global Convergence of Langevin Dynamics Based Algorithms for Nonconvex Optimization,Pan Xu; Jinghui Chen; Quanquan Gu,Abstract: We present a unified framework to analyze the global convergence of Langevindynamics based algorithms for nonconvex finite-sum optimization with $ n $ componentfunctions. At the core of our analysis is a new decomposition scheme of the optimizationerror; under which we directly analyze the ergodicity of the numerical approximations ofLangevin dynamics and prove sharp convergence rates. We establish the first globalconvergence guarantee of gradient Langevin dynamics (GLD) with iteration complexity $O\big (1/\epsilon\cdot\log (1/\epsilon)\big) $. In addition; we improve the convergence rate ofstochastic gradient Langevin dynamics (SGLD) to the" almost minimizer"; which does notdepend on the undesirable uniform spectral gap introduced in previous studies.Furthermore; we for the first time prove the global convergence guarantee of variance …,arXiv preprint arXiv:1707.06618,2017,1
Robust gaussian graphical model estimation with arbitrary corruption,Lingxiao Wang; Quanquan Gu,Abstract We study the problem of estimating the high-dimensional Gaussian graphicalmodel where the data are arbitrarily corrupted. We propose a robust estimator for the sparseprecision matrix in the high-dimensional regime. At the core of our method is a robustcovariance matrix estimator; which is based on truncated inner product. We establish thestatistical guarantee of our estimator on both estimation error and model selectionconsistency. In particular; we show that provided that the number of corrupted samples $n_2 $ for each variable satisfies $ n_2\lesssim\sqrt {n}/\sqrt {\log d} $; where $ n $ is thesample size and $ d $ is the number of variables; the proposed robust precision matrixestimator attains the same statistical rate as the standard estimator for Gaussian graphicalmodels. In addition; we propose a hypothesis testing procedure to assess the uncertainty …,International Conference on Machine Learning,2017,1
Robust Wirtinger flow for phase retrieval with arbitrary corruption,Jinghui Chen; Lingxiao Wang; Xiao Zhang; Quanquan Gu,Abstract: We consider the phase retrieval problem of recovering the unknown signal from themagnitude-only measurements; where the measurements can be contaminated by bothsparse arbitrary corruption and bounded random noise. We propose a new nonconvexalgorithm for robust phase retrieval; namely Robust Wirtinger Flow; to jointly estimate theunknown signal and the sparse corruption. We show that our proposed algorithm isguaranteed to converge linearly to the unknown true signal up to a minimax optimalstatistical precision in such a challenging setting. Compared with existing robust phaseretrieval methods; we improved the statistical error rate by a factor of $\sqrt {n/m} $ where $ n$ is the dimension of the signal and $ m $ is the sample size; provided a refinedcharacterization of the corruption fraction requirement; and relaxed the lower bound …,arXiv preprint arXiv:1704.06256,2017,1
Communication-efficient Distributed Estimation and Inference for Transelliptical Graphical Models,Pan Xu; Lu Tian; Quanquan Gu,Abstract: We propose communication-efficient distributed estimation and inference methodsfor the transelliptical graphical model; a semiparametric extension of the elliptical distributionin the high dimensional regime. In detail; the proposed method distributes the $ d $-dimensional data of size $ N $ generated from a transelliptical graphical model into $ m $worker machines; and estimates the latent precision matrix on each worker machine basedon the data of size $ n= N/m $. It then debiases the local estimators on the worker machinesand send them back to the master machine. Finally; on the master machine; it aggregatesthe debiased local estimators by averaging and hard thresholding. We show that theaggregated estimator attains the same statistical rate as the centralized estimator based onall the data; provided that the number of machines satisfies $ m\lesssim\min\{N\log d/d …,arXiv preprint arXiv:1612.09297,2016,1
Aggregating Private Sparse Learning Models Using Multi-Party Computation,Lu Tian; Bargav Jayaraman; Quanquan Gu; David Evans,Abstract We consider the problem of privately learning a sparse model across multiplesensitive datasets; and propose learning individual models locally and privately aggregatingthem using secure multi-party computation. In this paper; we report some preliminaryexperiments on distributed sparse linear discriminant analysis; showing both the feasibilityand effectiveness of our approach on experiments using heart disease data collected acrossfour hospitals.,NIPS Workshop on Private Multi-Party Machine Learning; Barcelona; Spain,2016,1
Online and active learning of big networks: Theory and algorithms,Quanquan Gu,We are living in the Internet Age; in which information entities and objects areinterconnected; thereby forming gigantic information networks. These networks are not onlymassive; but also grow and evolve very quickly. It is critical to quickly process andunderstand these networks in order to enable data-driven applications. On the other hand;the labels of the nodes in big networks are scarce. It is urgent to optimize the process bywhich the labels are collected; because it is unrealistic to get labels of every node. Theobjective of my research is to develop algorithms for big network analytics; which are bothstatistically and computationally efficient; and with provable guarantee on their performance.In particular; I present active learning; online learning; selective sampling (online activelearning); and online learning with bandit feedback algorithms for learning in a network …,*,2014,1
year=2014,Yiyi Liu; Quanquan Gu; Jack P Hou; Jiawei Han; Jian Ma; Yiyi Liu; Quanquan Gu; Jack P Hou; Jiawei Han; Jian Ma,Abstract This Provisional PDF corresponds to the article as it appeared upon acceptance.Fully formatted PDF and full text (HTML) versions will be made available soon. A network-assisted co-clustering algorithm to discover cancer subtypes based on gene expressionBMC Bioinformatics 2014; 15: 37 doi: 10.1186/1471-2105-15-37,*,2014,1
Multiple kernel maximum margin criterion,Quanquan Gu; Jie Zhou,Maximum Margin Criterion (MMC) is an efficient and robust feature extraction method; whichhas been proposed recently. Like other kernel methods; when MMC is extended toReproducing Kernel Hilbert Space via kernel trick; its performance heavily depends on thechoice of kernel. In this paper; we address the problem of learning the optimal kernel over aconvex set of prescribed kernels for Kernel MMC (KMMC). We will give an equivalent graphbased formulation of MMC; based on which we present Multiple Kernel Maximum MarginCriterion (MKMMC). Then we will show that MKMMC can be solved via alternativeoptimization schema. Experiments on benchmark image recognition data sets show that theproposed method outperforms KMMC via cross validation; as well as some state of the artmethods.,Image Processing (ICIP); 2009 16th IEEE International Conference on,2009,1
Regular simplex criterion: A novel feature extraction criterion,Quanquan Gu; Jie Zhou,Feature extraction is an important topic in machine learning. There are two representativecriterions for feature extraction; ie Fisher Criterion and Maximum Margin Criterion. In thispaper; we propose a new criterion; called Regular Simplex Criterion. This criterion requiresthat samples from the same class are projected to the same point; while samples fromdifferent classes have unit distance. Under this criterion; we present a novel dimensionalityreduction method; namely Linear Simplex Analysis (LSA). LSA is solved by multivariatelinear regression with a specific definition of class indicator matrix which has a stronggeometrical interpretation; ie each column of this matrix corresponds to a vertex of a regularsimplex. Several variants of LSA; eg Regularized Simplex Analysis (RSA) and KernelSimplex Analysis (KSA); are also proposed. Encouraging experimental results on UCI …,Acoustics; Speech and Signal Processing; 2009. ICASSP 2009. IEEE International Conference on,2009,1
Fast and Sample Efficient Inductive Matrix Completion via Multi-Phase Procrustes Flow,Xiao Zhang; Simon S Du; Quanquan Gu,Abstract: We revisit the inductive matrix completion problem that aims to recover a rank-$ r $matrix with ambient dimension $ d $ given $ n $ features as the side prior information. Thegoal is to make use of the known $ n $ features to reduce sample and computationalcomplexities. We present and analyze a new gradient-based non-convex optimizationalgorithm that converges to the true underlying matrix at a linear rate with sample complexityonly linearly depending on $ n $ and logarithmically depending on $ d $. To the best of ourknowledge; all previous algorithms either have a quadratic dependency on the number offeatures in sample complexity or a sub-linear computational convergence rate. In addition;we provide experiments on both synthetic and real world data to demonstrate theeffectiveness of our proposed algorithm.,arXiv preprint arXiv:1803.01233,2018,*
Stochastic Variance-Reduced Hamilton Monte Carlo Methods,Difan Zou; Pan Xu; Quanquan Gu,Abstract: We propose a fast stochastic Hamilton Monte Carlo (HMC) method; for samplingfrom a smooth and strongly log-concave distribution. At the core of our proposed method is avariance reduction technique inspired by the recent advance in stochastic optimization. Weshow that; to achieve $\epsilon $ accuracy in 2-Wasserstein distance; our algorithmachieves $\tilde O\big (n+\kappa^{2} d^{1/2}/\epsilon+\kappa^{4/3} d^{1/3}n^{2/3}/\epsilon^{2/3}\big) $ gradient complexity (ie; number of component gradientevaluations); which outperforms the state-of-the-art HMC and stochastic gradient HMCmethods in a wide regime. We also extend our algorithm for sampling from smooth andgeneral log-concave distributions; and prove the corresponding gradient complexity as well.Experiments on both synthetic and real data demonstrate the superior performance of our …,arXiv preprint arXiv:1802.04791,2018,*
Stochastic Variance-Reduced Cubic Regularized Newton Method,Dongruo Zhou; Pan Xu; Quanquan Gu,Abstract: We propose a stochastic variance-reduced cubic regularized Newton method fornon-convex optimization. At the core of our algorithm is a novel semi-stochastic gradientalong with a semi-stochastic Hessian; which are specifically designed for cubicregularization method. We show that our algorithm is guaranteed to converge to an$(\epsilon;\sqrt {\epsilon}) $-approximately local minimum within $\tilde{O}(n^{4/5}/\epsilon^{3/2}) $ second-order oracle calls; which outperforms the state-of-the-artcubic regularization algorithms including subsampled cubic regularization. Our work alsosheds light on the application of variance reduction technique to high-order non-convexoptimization methods. Thorough experiments on various non-convex optimization problemssupport our theory.,arXiv preprint arXiv:1802.04796,2018,*
Third-order Smoothness Helps: Even Faster Stochastic Optimization Algorithms for Finding Local Minima,Yaodong Yu; Pan Xu; Quanquan Gu,Abstract: We propose stochastic optimization algorithms that can find local minima fasterthan existing algorithms for nonconvex optimization problems; by exploiting the third-ordersmoothness to escape non-degenerate saddle points more efficiently. More specifically; theproposed algorithm only needs $\tilde {O}(\epsilon^{-10/3}) $ stochastic gradient evaluationsto converge to an approximate local minimum $\mathbf {x} $; which satisfies $\|\nabla f(\mathbf {x})\| _2\leq\epsilon $ and $\lambda_ {\min}(\nabla^ 2 f (\mathbf {x}))\geq-\sqrt{\epsilon} $ in the general stochastic optimization setting; where $\tilde {O}(\cdot) $ hideslogarithm polynomial terms and constants. This improves upon the $\tilde {O}(\epsilon^{-7/2}) $ gradient complexity achieved by the state-of-the-art stochastic local minima findingalgorithms by a factor of $\tilde {O}(\epsilon^{-1/6}) $. For nonconvex finite-sum …,arXiv preprint arXiv:1712.06585,2017,*
Fast Newton Hard Thresholding Pursuit for Sparsity Constrained Nonconvex Optimization,Jinghui Chen; Quanquan Gu,Abstract We propose a fast Newton hard thresholding pursuit algorithm for sparsityconstrained nonconvex optimization. Our proposed algorithm reduces the per-iteration timecomplexity to linear in the data dimension d compared with cubic time complexity inNewton's method; while preserving faster computational and statistical convergence rates. Inparticular; we prove that the proposed algorithm converges to the unknown sparse modelparameter at a composite rate; namely quadratic at first and linear when it gets close to thetrue parameter; up to the minimax optimal statistical precision of the underlying model.Thorough experiments on both synthetic and real datasets demonstrate that our algorithmoutperforms the state-of-the-art optimization algorithms for sparsity constrained optimization.,Proceedings of the 23rd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining,2017,*
A Unified Variance Reduction-Based Framework for Nonconvex Low-Rank Matrix Recovery,Lingxiao Wang; Xiao Zhang; Quanquan Gu,Abstract We propose a generic framework based on a new stochastic variance-reducedgradient descent algorithm for accelerating nonconvex low-rank matrix recovery. Startingfrom an appropriate initial estimator; our proposed algorithm performs projected gradientdescent based on a novel semi-stochastic gradient specifically designed for low-rank matrixrecovery. Based upon the mild restricted strong convexity and smoothness conditions; wederive a projected notion of the restricted Lipschitz continuous gradient property; and provethat our algorithm enjoys linear convergence rate to the unknown low-rank matrix with animproved computational complexity. Moreover; our algorithm can be employed to bothnoiseless and noisy observations; where the (near) optimal sample complexity andstatistical rate can be attained respectively. We further illustrate the superiority of our …,International Conference on Machine Learning,2017,*
Uncertainty Assessment and False Discovery Rate Control in High-Dimensional Granger Causal Inference,Aditya Chaudhry; Pan Xu; Quanquan Gu,Abstract Causal inference among high-dimensional time series data proves an importantresearch problem in many fields. While in the classical regime one often establishescausality among time series via a concept known as “Granger causality;” existingapproaches for Granger causal inference in high-dimensional data lack the means tocharacterize the uncertainty associated with Granger causality estimates (eg; p-values andconfidence intervals). We make two contributions in this work. First; we introduce a novelasymptotically unbiased Granger causality estimator with corresponding test statistics andconfidence intervals to allow; for the first time; uncertainty characterization in high-dimensional Granger causal inference. Second; we introduce a novel method for falsediscovery rate control that achieves higher power in multiple testing than existing …,International Conference on Machine Learning,2017,*
High-Dimensional Variance-Reduced Stochastic Gradient Expectation-Maximization Algorithm,Rongda Zhu; Lingxiao Wang; Chengxiang Zhai; Quanquan Gu,Abstract We propose a generic stochastic expectation-maximization (EM) algorithm for theestimation of high-dimensional latent variable models. At the core of our algorithm is a novelsemi-stochastic variance-reduced gradient designed for the $ Q $-function in the EMalgorithm. Under a mild condition on the initialization; our algorithm is guaranteed to attain alinear convergence rate to the unknown parameter of the latent variable model; and achievean optimal statistical rate up to a logarithmic factor for parameter estimation. Compared withexisting high-dimensional EM algorithms; our algorithm enjoys a better computationalcomplexity and is therefore more efficient. We apply our generic algorithm to two illustrativelatent variable models: Gaussian mixture model and mixture of linear regression; anddemonstrate the advantages of our algorithm by both theoretical analysis and numerical …,International Conference on Machine Learning,2017,*
Mixed linear modeling techniques for predicting fatalities in vehicle crashes,Lulu Ge; Tyler Hutcherson; Qi Tang; Quanquan Gu,Motor vehicle crashes cause loss of life; property; and finances. It remains a focus of trafficsafety research; uncovering useful information that can be directly applied to reduce theselosses. Traditionally; modeling crash fatalities has been done using machine learningtechniques; considering crash level variables such as roadway characteristics; lightingconditions; weather conditions; and the prevalence of drugs or alcohol. This research movesin a new direction by incorporating heterogeneous data sources; including both police crashreport data and demographic data; potentially leading to a heightened understanding of therelationship between crash location and the likelihood of a fatality. In order to utilize multipledata sources; we propose using a mixed linear modeling technique that enables data fusionin a principled way to build a better predictive model. We integrate these data sources to …,Systems and Information Engineering Design Symposium (SIEDS); 2017,2017,*
Multi-task cox proportional hazard model for predicting risk of unplanned hospital readmission,Megan Grzyb; Amber Zhang; Cristina Good; Khaled Khalil; Bochen Guo; Lu Tian; Jose Valdez; Quanquan Gu,Unplanned hospital readmissions are a tremendous challenge faced by medical providersin the United States: In 2015; 17.8% of Medicare and Medicaid patients returned to thehospital within 30 days of discharge. An unplanned readmission marks a setback in apatient's recovery and burdens hospitals financially-the estimated national cost of caring forreadmitted patients is $15 billion annually. Financial penalties from the Center for Medicare& Medicaid Services intensify these costs; penalizing hospitals with high rates relative to thenational average. At the University of Virginia Medical Center; the Medicare & Medicaid risk-adjusted readmission rate of 16.8% is higher than the national average of 15.2%. Thishigher than average rate leads to penalties; which are estimated at $764;000 for the 2017fiscal year. The UVA Medical Center prioritizes reducing their readmission rate and has …,Systems and Information Engineering Design Symposium (SIEDS); 2017,2017,*
High Dimensional Multivariate Regression and Precision Matrix Estimation via Nonconvex Optimization,Jinghui Chen; Quanquan Gu,Abstract: We propose a nonconvex estimator for joint multivariate regression and precisionmatrix estimation in the high dimensional regime; under sparsity constraints. A gradientdescent algorithm with hard thresholding is developed to solve the nonconvex estimator;and it attains a linear rate of convergence to the true regression coefficients and precisionmatrix simultaneously; up to the statistical error. Compared with existing methods along thisline of research; which have little theoretical guarantee; the proposed algorithm not only iscomputationally much more efficient with provable convergence guarantee; but also attainsthe optimal finite sample statistical rate up to a logarithmic factor. Thorough experiments onboth synthetic and real datasets back up our theory.,arXiv preprint arXiv:1606.00832,2016,*
Introduction to Spectral Clustering,Quanquan Gu,*,*,2011,*
