Jaql: A scripting language for large scale semistructured data analysis,Kevin S Beyer; Vuk Ercegovac; Rainer Gemulla; Andrey Balmin; Mohamed Eltabakh; Carl-Christian Kanne; Fatma Ozcan; Eugene J Shekita,ABSTRACT This paper describes Jaql; a declarative scripting language for analyzing largesemistructured datasets in parallel using Hadoop's MapReduce framework. Jaql is currentlyused in IBM's InfoS-phere BigInsights [5] and Cognos Consumer Insight [9] products. Jaql'sdesign features are:(1) a flexible data model;(2) reusability;(3) varying levels of abstraction;and (4) scalability. Jaql's data model is inspired by JSON and can be used to representdatasets that vary from flat; relational tables to collections of semistructured documents. AJaql script can start without any schema and evolve over time from a partial to a rigidschema. Reusability is provided through the use of higher-order functions and by packagingrelated functions into modules. Most Jaql scripts work at a high level of abstraction forconcise specification of logical operations (eg; join); but Jaql's notion of physical …,Proceedings of VLDB conference,2011,221
CoHadoop: flexible data placement and its exploitation in Hadoop,Mohamed Y Eltabakh; Yuanyuan Tian; Fatma Özcan; Rainer Gemulla; Aljoscha Krettek; John McPherson,Abstract Hadoop has become an attractive platform for large-scale data analytics. In thispaper; we identify a major performance bottleneck of Hadoop: its lack of ability to colocaterelated data on the same set of nodes. To overcome this bottleneck; we introduceCoHadoop; a lightweight extension of Hadoop that allows applications to control where dataare stored. In contrast to previous approaches; CoHadoop retains the flexibility of Hadoop inthat it does not require users to convert their data to a certain format (eg; a relationaldatabase or a specific file format). Instead; applications give hints to CoHadoop that someset of files are related and may be processed jointly; CoHadoop then tries to colocate thesefiles for improved efficiency. Our approach is designed such that the strong fault toleranceproperties of Hadoop are retained. Colocation can be used to improve the efficiency of …,Proceedings of the VLDB Endowment,2011,216
A framework for using materialized XPath views in XML query processing,Andrey Balmin; Fatma Özcan; Kevin S Beyer; Roberta J Cochrane; Hamid Pirahesh,Abstract XML languages; such as XQuery; XSLT and SQL/XML; employ XPath as the searchand extraction language. XPath expressions often define complicated navigation; resultingin expensive query processing; especially when executed over large collections ofdocuments. In this paper; we propose a framework for exploiting materialized XPath views toexpedite processing of XML queries. We explore a class of materialized XPath views; whichmay contain XML fragments; typed data values; full paths; node references or anycombination thereof. We develop an XPath matching algorithm to determine when suchviews can be used to answer a user query containing XPath expressions. We use the matchinformation to identify the portion of an XPath expression in the user query which is notcovered by the XPath view. Finally; we construct; possibly multiple; compensation …,Proceedings of the Thirtieth international conference on Very large data bases-Volume 30,2004,205
System RX: one part relational; one part XML,Kevin Beyer; Roberta J Cochrane; Vanja Josifovski; Jim Kleewein; George Lapis; Guy Lohman; Bob Lyle; Fatma Özcan; Hamid Pirahesh; Normen Seemann; Tuong Truong; Bert Van der Linden; Brian Vickery; Chun Zhang,Abstract This paper describes the overall architecture and design aspects of a hybridrelational and XML database system called System RX. We believe that such a system isfundamental in the evolution of enterprise data management solutions: XML and relationaldata will co-exist and complement each other in enterprise solutions. Furthermore; asuccessful XML repository requires much of the same infrastructure that already exists in arelational database management system. Finally; XML query languages have considerableconceptual and functional overlap with relational dataflow engines. System RX is the firsttruly hybrid system that comingles XML and relational data; giving them equal footing. Thenew support for XML includes native support for storage and indexing as well as querycompilation and evaluation support for the latest industry-standard query languages; SQL …,Proceedings of the 2005 ACM SIGMOD international conference on Management of data,2005,162
IMPACT: A platform for collaborating agents,Khaled A Arisha; Fatma Ozcan; Robert Ross; VS Subrahmanian; Thomas Eiter; Sarit Kraus,The paper discusses the Impact platform (Interactive Maryland Platform) for collaborativeagents. Impact agents consist of software code with an associated wrapper that agentizesthe code. A set of specialized servers facilitate agent interoperability in an application-independent manner.,IEEE Intelligent Systems and Their Applications,1999,143
Cost models do matter: Providing cost information for diverse data sources in a federated system,Mary Tork Roth; Laura M Haas; Fatma Ozcan,Abstract An important issue for federated systems of diverse data sources is how to optimizecross-source queries; without building knowledge of individual sources into the optimizer.Garlic is a federated system with an emphasis on extensibility and diverse sources. Toachieve these goals; data sources are attached to Garlic by means of a wrapper. Wrappersparticipate in query planning; telling Garlic what parts of a query a data source can do andhow much it will cost. This paper describes a framework through which wrappers provide thenecessary cost and cardinality information for optimization; and the facilities Garlic providesto make this task easier. Our framework makes it easy for wrappers to provide costinformation; requires few changes to a conventional bottomup optimizer and is easilyextensible to a broad range of sources. We believe that our framework for costing is the …,*,1999,141
XPath containment for index and materialized view matching,*,A method for using pre-computed information stored in auxiliary structures to speed upprocessing of expensive queries on hierarchical documents such as XML documents beingqueried using XPath. The invention defines a taxonomy of such structures such as indexesand materialized views for storing pre-computed XPath results (PXRs); determines whatportion of the query can be evaluated by the structures; and computes the compensation forthe results generated by the structures. The invention detects all structures applicable to thequery and rewrites the query to use such structures; speeding up the performance of thequeries. The invention identifies the matching structures by detecting containment mappingsbetween XPath expressions in the query and the structure. The invention also includes anew representation for XPath expressions that is rich enough to express all features of …,*,2008,121
Extending XQuery for analytics,Kevin Beyer; Don Chambérlin; Latha S Colby; Fatma Özcan; Hamid Pirahesh; Yu Xu,Abstract XQuery is a query language under development by the W3C XML Query WorkingGroup. The language contains constructs for navigating; searching; and restructuring XMLdata. With XML gaining importance as the standard for representing business data; XQuerymust support the types of queries that are common in business analytics. One such class ofqueries is OLAP-style aggregation queries. Although these queries are expressible inXQuery Version 1; the lack of explicit grouping constructs makes the construction of thesequeries non-intuitive and places a burden on the XQuery engine to recognize and optimizethe implicit grouping constructs. Furthermore; although the flexibility of the XML data modelprovides an opportunity for advanced forms of grouping that are not easily represented inrelational systems; these queries are difficult to express using the current XQuery syntax …,Proceedings of the 2005 ACM SIGMOD international conference on Management of data,2005,103
Sql-on-hadoop: Full circle back to shared-nothing database architectures,Avrilia Floratou; Umar Farooq Minhas; Fatma Özcan,Abstract SQL query processing for analytics over Hadoop data has recently gainedsignificant traction. Among many systems providing some SQL support over Hadoop; Hive isthe first native Hadoop system that uses an underlying framework such as MapReduce orTez to process SQL-like statements. Impala; on the other hand; represents the newemerging class of SQL-on-Hadoop systems that exploit a shared-nothing parallel databasearchitecture over Hadoop. Both systems optimize their data ingestion via columnar storage;and promote different file formats: ORC and Parquet. In this paper; we compare theperformance of these two systems by conducting a set of cluster experiments using a TPC-Hlike benchmark and two TPC-DS inspired workloads. We also closely study the I/O efficiencyof their columnar formats using a set of micro-benchmarks. Our results show that Impala is …,Proceedings of the VLDB Endowment,2014,93
Clash of the titans: Mapreduce vs. spark for large scale data analytics,Juwei Shi; Yunjie Qiu; Umar Farooq Minhas; Limei Jiao; Chen Wang; Berthold Reinwald; Fatma Özcan,Abstract MapReduce and Spark are two very popular open source cluster computingframeworks for large scale data analytics. These frameworks hide the complexity of taskparallelism and fault-tolerance; by exposing a simple programming API to users. In thispaper; we evaluate the major architectural components in MapReduce and Sparkframeworks including: shuffle; execution model; and caching; by using a set of importantanalytic workloads. To conduct a detailed analysis; we developed two profiling tools:(1) Wecorrelate the task execution plan with the resource utilization for both MapReduce andSpark; and visually present this correlation;(2) We provide a break-down of the taskexecution time for in-depth analysis. Through detailed experiments; we quantify theperformance differences between MapReduce and Spark. Furthermore; we attribute …,Proceedings of the VLDB Endowment,2015,77
Multidatabase query optimization,Cem Evrendilek; Asuman Dogac; Sena Nural; Fatma Ozcan,Abstract A multidatabase system (MDBS) allows the users to simultaneously accessheterogeneous; and autonomous databases using an integrated schema and a singleglobal query language. The query optimization problem in MDBSs is quite different from thequery optimization problem in distributed homogeneous databases due to schemaheterogeneity and autonomy of local database systems. In this work; we consider theoptimization of query distribution in case of data replication and the optimization of intersitejoins; that is; the join of the results returned by the local sitesin response to the globalsubqueries. The algorithms presented for the optimization of intersite joins try to maximizethe parallelism in execution and take the federated nature of the problem into account. It hasalso been shown through a comparativeperformance study that the proposed intersite …,Distributed and Parallel Databases,1997,67
METU interoperable database system,Asuman Dogac; Cevdet Dengi; Ebru Kilic; Gokhan Ozhan; Fatma Ozcan; Sena Nural; Cem Evrendilek; Ugur Halici; Budak Arpinar; Pinar Koksal; N Kesim; Sema Mancuhan,Abstract METU INteroperable Database System (MIND) is a multidatabase system that aimsat achieving interoperability among heterogeneous; federated DBMSs. MIND architecture ifbased on OMG distributed object management model. It is implemented on top of a CORBAcompliant ORB; namely; ObjectBroker. MIND provides users a single ODMG-93 compliantcommon data model; and a single global query language based on SQL. This makes itpossible to incorporate both relational and object oriented databases into the system.Currently Oracle 7; Sybase and METU OODBMS (MOOD) have been incorporated intoMIND. The main components of MIND are a global query processor; a global transactionmanager; a schema integrator; interfaces to supported database systems and a usergraphical interface. In MIND all local databases are encapsulated in a generic database …,ACM Sigmod Record,1995,61
IMPACT: The interactive Maryland platform for agents collaborating together,Khaled Arisha; F Ozcan; R Ross; S Kraus; VS Subrahmanian,We describe a platform called IMPACT to support multiagent interactions. The platformprovides a set of servers (yellow pages; thesaurus; registration; type; and interface) thatfacilitate agent interoperability in an application independent manner. In IMPACT agentshave an associated set of service descriptions; specifying the services they provide. Wedevelop an HTML-like language for such service descriptions. When an agent wishes toidentify another agent that provides a service; the requested service must be matched; usinga metric approach; against existing service descriptions. We provide a formal frameworkwithin which this may be done; and develop algorithms to compute the k nearest matches;as well as all matches within a given distance from the requested service. We report onexperiments evaluating our algorithms with large data sets.,Multi Agent Systems; 1998. Proceedings. International Conference on,1998,59
Heterogenous Active Agents,VS Subrahmanian; Piero Bonatti; Jurgen Dix; Thomas Eiter; Sarit Kraus; Fatma Ozcan; Robert Ross,*,*,2000,53
Dynamic query optimization in multidatabases,Fatma Ozcan; Sena Nural; Pinar Koksal; Cem Evrendilek; Asuman Dogac,Abstract In this paper; we describe a dynamic query optimization technique for amultidatabase system; namely MIND; implemented on a DOM environment. A DistributedObject Management (DOM) architecture; when used as the infrastructure of a multidatabasesystem; not only enables easy and flexible interoperation of DBMSs; but also facilitatesinteroperation of the multidatabase system with other repositories that do not have DBMScapabilities. This is an important advantage; since most data still resides on repositories thatdo not have DBMS capabilities. Dynamic query optimization; which schedules intersiteoperations at run-time; fits better to such an environment since it benefits from locationtransparency provided by the DOM framework. In this way; the dynamic changes in theconfiguration of system resources such as a relocated DBMS or a new mirror to an …,IEEE Data Eng. Bull.,1997,52
Method and apparatus for XML query evaluation using early-outs and multiple passes,*,A method and apparatus is disclosed for XML query evaluation using early-outs and multiplepasses to evaluate an XML query. A multi-pass evaluation procedure evaluates the XMLquery one step at a time as needed to complete evaluation. The multi-pass evaluationprocedure evaluates XML queries containing logical expressions such as “AND”expressions;“OR” expressions; and implied “AND” expressions within “FOR” clauses.Queries containing logical expressions are often satisfied before every component isevaluated. Thus; executing the multi-pass evaluation procedure allows the evaluation to exitearly when the veracity of the query is determined; not necessarily when every componenthas been evaluated. The multi-pass evaluation procedure executes as long as adescendant axis of the XML query need not be evaluated past a child node. When …,*,2010,48
DB2 goes hybrid: Integrating native XML and XQuery with relational data and SQL,K Beyer; Roberta Cochrane; M Hvizdos; Vanja Josifovski; Jim Kleewein; George Lapis; G Lohman; Robert Lyle; Matthias Nicola; Fatma Ozcan; Hamid Pirahesh; Normen Seemann; Ashutosh Singh; T Truong; Robbert C Van der Linden; Brian Vickery; Chun Zhang; Guogen Zhang,Comprehensive and efficient support for XML data management is a rapidly increasingrequirement for database systems. To address this requirement; DB2 UniversalDatabase™(UDB) now combines relational data management with native XML support. Thismakes DB2® a truly hybrid database management system with first-class support for bothXML and relational data processing as well as the integration of the two. This paper presentsthe overall architecture and design aspects of native XML support in DB2 UDB and itsintegration with the relational data-flow engine. We describe the new XML components inDB2 UDB and show how XML processing leverages much of the infrastructure which is usedfor relational data.,IBM Systems Journal,2006,46
Context quantifier transformation in XML query rewrite,*,An XML query compilation processor (20) includes an execution compiler (42) thattransforms an XML query into an executable XML query plan (22). A query rewrite processor(34) performs query transformations on the XML query. Said query transformations includetransforming an expression input (60) received by an expression (62) conditional upon a setof items defined by an output (64) of the expression (62) being independent of grouping ofitems in the expression input (60).,*,2007,44
Eagle-eyed elephant: split-oriented indexing in Hadoop,Mohamed Y Eltabakh; Fatma Özcan; Yannis Sismanis; Peter J Haas; Hamid Pirahesh; Jan Vondrak,Abstract An increasingly important analytics scenario for Hadoop involves multiple (often adhoc) grouping and aggregation queries with selection predicates over a slowly changingdataset. These queries are typically expressed via high-level query languages such as Jaql;Pig; and Hive; and are used either directly for business-intelligence applications or toprepare the data for statistical model building and machine learning. In such scenarios it hasbeen increasingly recognized that; as in classical databases; techniques for avoiding accessto irrelevant data can dramatically improve query performance. Prior work on Hadoop;however; has simply ported classical techniques to the MapReduce setting; focusing onrecord-level indexing and key-based partition elimination. Unfortunately; record-levelindexing only slightly improves overall query performance; because it does not minimize …,Proceedings of the 16th International Conference on Extending Database Technology,2013,38
A multidatabase system implementation on CORBA,Asuman Dogaç; Cevdet Dengi; Ebru Kilic; Gökhan Ozhan; Fatma Ozcan; Sena Nural; Cem Evrendilek; Ugur Halici; Budak Arpinar; Pinar Koksal; Sema Mancuhan,METU Interoperable DBMS (MIND) is a multidatabase system based on OMG's distributedobject management architecture. It is implemented on top of a CORBA compliant ORB;namely; DEC's ObjectBroker. In MIND; all local databases are encapsulated in a genericdatabase object. The interface of the generic database object is defined in CORBA IDL andmultiple implementations of this interface; one for each component DBMS; namely Sybase;Adabas D and MOOD are provided. MIND provides its users with a common data model anda single global query language based on SQL. The main components of MIND are a globalquery manager; a global transaction manager; a schema integrator; interfaces to supporteddatabase systems and a graphical user interface. The integration of export schemas iscurrently performed by using an object definition language (ODL) which is based on …,Research Issues in Data Engineering; 1996. Interoperability of Nontraditional Database Systems. Proceedings. Sixth International Workshop on,1996,37
DB2/XML: designing for evolution,Kevin Beyer; Fatma Özcan; Sundar Saiprasad; Bert Van der Linden,Abstract DB2 provides native XML storage; indexing; navigation and query processingthrough both SQL/XML and XQuery using the XML data type introduced by SQL/XML. In thistutorial we focus on DB2's XML support for schema evolution; especially DB2's schemarepository and document-level validation.,Proceedings of the 2005 ACM SIGMOD international conference on Management of data,2005,36
Dynamic query optimization on a distributed object management platform,Fatma Ozcan; Sena Nural; Pinar Koksal; Cem Evrendilek; Asuman Dogac,Abstract A Distributed Object Management(DOM) architecture; when used as theinfrastructure of a multidatabase system; not only enables easy and flexible interoperation ofD13MSS; but also facilitates interoperation of the multidatabase system with otherrepositories that do not have DIBMS capabilities. Thk is an important advantage; since mostof data still resides on repositories that do not have DIBMS capabilities. In thk paper; wedescribe a dynamic query optimization technique for a multidatabaae system; namely MIND;implement ed on a DOM environment. Dynamic query optimization; which schedulesintersite operations at runtime; fits better to such an environment since it benefits fromlocation transparency provided by the DOM framework. In thk way; the dynamic changes inthe configuration of system resources such as a relocated DBMS or a new mirror to an …,Proceedings of the fifth international conference on Information and knowledge management,1996,33
Proceedings of the 2003 ACM SIGMOD International Conference on Management of Data,Zachary G Ives; Yannis Papakonstantinou; Alon Halevy,*,*,2003,25
METU interoperable database system,Asuman Dogac; Ugur Halici; Ebru Kilic; Gokhan Ozhan; Fatma Ozcan; Sena Nural; Cevdet Dengi; Sema Mancuhan; Budak Arpinar; Pinar Koksal; Cem Evrendilek,NIETU INteroperable DBMS(MIiND)(This project is being partially supported by MotorolaInc.; USA and Sevgi Foundation; Turkey) is a multiclatabase system based on OMG's(OMGis a registered tracfemark; and CORBA; ORB; OIMG IDL; Object Request Broker aretrademarks of ONIG) distributed object management architect ure. It is implemented on top ofa CORBA compliant ORB; namely; DEC'S ObjectBroker (objectBroker is a registeredtrademark of DEC Corp.)[DDO! M]. In MIND all local databases are encapsulated in geuericDatabase Object. The interface of the generic Database Object is defined in CORBA IDL andmultiple ilrl [) lelnelltatiolls of this interface; one for each compullent DBMSS; namely;0racle7(Oracle? is a trademark of Oracle Corp.); Sybase(Sybase is a trademark of SybaseCorp.);. klabas D (. 4dabas D is a trademark uf Software AG Corp.) and Iv1OOD[Dog94] …,ACM SIGMOD Record,1996,25
Optimization of extensible markup language path language (XPATH) expressions in a database management system configured to accept extensible markup langu...,*,An apparatus; system; and method are disclosed for optimization of XPath expressions in adatabase management system configured to accept XML queries. Operations of the methodinclude receiving an XQuery representation and partitioning XPath expressions within theXQuery representation into a plurality of XPath expression clusters. The XPath expressionclusters may comprise one or more XPath expressions and those in each cluster mayoperate on a common document. Furthermore; the XPath expressions in each cluster arehierarchically related to each other such that branch nodes of the cluster are executableindependent of nodes in other XPath expression clusters. The method also defines mergingthe one or more XPath expressions into one or more expression trees for each XPathexpression cluster. The method generates one or more query execution plans from the …,*,2011,23
On the effectiveness of flexible querying heuristics for XML data,Zografoula Vagena; Latha Colby; Fatma Özcan; Andrey Balmin; Quanzhong Li,Abstract The ability to perform effective XML data retrieval in the absence of schemaknowledge has recently received considerable attention. The majority of relevant proposalsemploys heuristics that identify groups of meaningfully related nodes using informationextracted from the input data. These heuristics are employed to effectively prune the searchspace of all possible node combinations and their popularity is evident by the large numberof such heuristics and the systems that use them. However; a comprehensive study detailingthe relative merits of these heuristics has not been performed thus far. One of the challengesin performing this study is the fact that these techniques have been proposed within differentand not directly comparable contexts. In this paper; we attempt to fill this gap. In particular;we first abstract the common selection problem that is tackled by the relatedness …,International XML Database Symposium,2007,19
XQery for Analytics: Challenges and Requirements.,Kevin S Beyer; Roberta Cochrane; Latha S Colby; Fatma Ozcan; Hamid Pirahesh,ABSTRACT XML has emerged as the industry standard for representing and exchangingdata and is already predominant in several applications today. Business; analytic; andstructured data will be exchanged as XML between applications and web services. XQueryis a query language that is emerging as the standard for querying XML data. The currentversion of the XQuery standard contains many features for navigating the hierarchical andordered content of XML data. However; as compared to SQL; it lacks some key constructswhich makes it difficult to succinctly express and efficiently execute some simple classes ofanalytic queries. In this paper; we describe some of the limitations of the current XQuerylanguage and argue that extensions to XQuery are necessary to overcome these limitations.,XIME-P,2004,19
Emerging trends in the enterprise data analytics: connecting Hadoop and DB2 warehouse,Fatma Özcan; David Hoa; Kevin S Beyer; Andrey Balmin; Chuan Jie Liu; Yu Li,Abstract Enterprises are dealing with ever increasing volumes of data; reaching into thepetabyte scale. With many of our customer engagements; we are observing an emergingtrend: They are using Hadoop-based solutions in conjunction with their data warehouses.They are using Hadoop to deal with the data volume; as well as the lack of strict structure intheir data to conduct various analyses; including but not limited to Web log analysis;sophisticated data mining; machine learning and model building. This first stage of theanalysis is off-line and suitable for Hadoop. But; once their data is summarized or cleansedenough; and their models are built; they are loading the results into a warehouse forinteractive querying and report generation. At this later stage; they leverage the wealth ofbusiness intelligence tools; which they are accustomed to; that exist for warehouses. In …,Proceedings of the 2011 ACM SIGMOD International Conference on Management of data,2011,18
On the path to efficient XML queries,Andrey Balmin; Kevin S Beyer; Fatma Özcan; Matthias Nicola,Abstract XQuery and SQL/XML are powerful new languages for querying XML data.However; they contain a number of stumbling blocks that users need to be aware of to getthe expected results and performance. For example; certain language features make it hardif not impossible to exploit XML indexes. The major database vendors provide XQuery andSQL/XML support in their current or upcoming product releases. In this paper; we identifycommon pitfalls gleaned from the experiences of early adopters of this functionality. Weillustrate these pitfalls through concrete examples; explain the unexpected query behavior;and show alternative formulations of the queries that behave and perform as anticipated. Asresults we provide guidelines for XQuery and SQL/XML users; feedback on the languagestandards; and food for thought for emerging languages and APIs.,Proceedings of the 32nd international conference on Very large data bases,2006,18
Integration of SQL and XQuery in IBM DB2,Fatma Ozcan; Don Chamberlin; Krishna Kulkarni; J-E Michels,Relational database systems have dominated the database industry for a quarter century.However; the advent of the Web has led to requirements for storage of new kinds ofinformation in which the order of information is important and data structure can vary overtime and from one document to another. These evolving requirements have given rise toExtensible Markup Language (XML) as a widely accepted data format and to XQuery as anemerging standard language for querying XML data sources. A set of extensions to theStructured Query Language (SQL) called SQL/XML enables XML data to be stored inrelational databases; taking advantage of the mature infrastructure of relational systems andcombining the advantages of SQL and XQuery. However; building a bridge between SQLand XQuery is challenging due to the many syntactic and semantic differences between …,IBM Systems Journal,2006,17
Query decomposition and processing in multidatabase systems,Sena Nural; Pinar Koksal; Fatma Ozcan; Asuman Dogac,ABSTRACT A multidatabase system allows its users to simultaneously accessheterogeneous; and autonomous databases using an integrated schema and a singleglobal query language. An important problem in multidatabase systems is processing of theglobal queries. In this paper; we describe a global query processing scheme as it isimplemented in a multidatabase environment; namely MIND. Since multidatabase queryprocessing is very much dependent on the way schema integration is realized; theunderlying MIND schema integration is also described. The details of both querydecomposition process and the necessary post-processing to combine the partial resultscoming from local databases; are provided.,OODBMS Symposium of the European Joint Conference on Engineering Systems Design and Analysis; Montpellier,1996,17
Query optimization in multidatabase systems,C Evrendilek; A Dogac; S Nural; F Ozcan,*,Proc. of the Next Generation Information Technologies and Systems; Israel,1995,17
Grouping and optimization of XPath expressions in DB2® pureXML,Andrey Balmin; Fatma Özcan; Ashutosh Singh; Edison Ting,Abstract Several XML DBMSs support XQuery and/or SQL/XML languages; which are basedon navigational primitives in the form of XPath expressions. Typically; these systems eithermodel each XPath step as a separate query plan operator; or employ holistic approachesthat can evaluate multiple steps of a single XPath expression. There have also beenproposals to execute as many XPath expressions as possible within a single FLWOR blocksimultaneously in a data streaming context. We observe that blindly combining all possibleXPath expressions for concurrent execution can result in significant performancedegradation in a database system. We identify two main problems with this strategy. First;the simple strategy of grouping all XPath expressions on a single document does not alwayswork if the query involves more than one data source or has nested query blocks. Second …,Proceedings of the 2008 ACM SIGMOD international conference on Management of data,2008,15
Are we experiencing a big data bubble?,Fatma Özcan; Nesime Tatbul; Daniel J Abadi; Marcel Kornacker; C Mohan; Karthik Ramasamy; Janet Wiener,Over the last decade; the database field has seen resurgence with the big data wave.Accelerated increase in data volumes; and modern hardware have been two major factorsthat brought in significant investment in new database technologies. Our field has benefitedfrom this increased interest and focus. There is now an abundance of NoSQL; NewSQL; andSQL-on-Hadoop systems. According to nosql-database. org; the list of NoSQL databases [6]has reached 150. Many of these systems claim horizontal scalability; and support for non-relational data. However; this high scalability usually comes at the cost of strong support forACID transactions. Most of them only provide eventual consistency; or even worse; defermanaging transactional semantics to the application layer. Another important aspect of theseNoSQL systems is the lack of declarative query interfaces. Most only support …,Proceedings of the 2014 ACM SIGMOD international conference on Management of data,2014,13
Dynamically optimizing queries over large scale data platforms,Konstantinos Karanasos; Andrey Balmin; Marcel Kutsch; Fatma Ozcan; Vuk Ercegovac; Chunyang Xia; Jesse Jackson,Abstract Enterprises are adapting large-scale data processing platforms; such as Hadoop; togain actionable insights from their" big data". Query optimization is still an open challenge inthis environment due to the volume and heterogeneity of data; comprising both structuredand un/semi-structured datasets. Moreover; it has become common practice to pushbusiness logic close to the data via user-defined functions (UDFs); which are usuallyopaque to the optimizer; further complicating cost-based optimization. As a result; classicalrelational query optimization techniques do not fit well in this setting; while at the same time;suboptimal query plans can be disastrous with large datasets. In this paper; we propose newtechniques that take into account UDFs and correlations between relations for optimizingqueries running on large scale clusters. We introduce" pilot runs"; which execute part of …,Proceedings of the 2014 ACM SIGMOD international conference on Management of data,2014,12
Athena: An ontology-driven system for natural language querying over relational data stores,Diptikalyan Saha; Avrilia Floratou; Karthik Sankaranarayanan; Umar Farooq Minhas; Ashish R Mittal; Fatma Özcan,Abstract In this paper; we present ATHENA; an ontology-driven system for natural languagequerying of complex relational databases. Natural language interfaces to databases enableusers easy access to data; without the need to learn a complex query language; such asSQL. ATHENA uses domain specific ontologies; which describe the semantic entities; andtheir relationships in a domain. We propose a unique two-stage approach; where the inputnatural language query (NLQ) is first translated into an intermediate query language overthe ontology; called OQL; and subsequently translated into SQL. Our two-stage approachallows us to decouple the physical layout of the data in the relational store from thesemantics of the query; providing physical independence. Moreover; ontologies providericher semantic information; such as inheritance and membership relations; that are lost …,Proceedings of the VLDB Endowment,2016,11
A region based query optimizer through cascades query optimizer framework,Fatma Ozcan; Sena Nural; Pinar Koksal; Mehmet Altinel; Asuman Dogac,Abstract The Cascades Query Optimizer Framework is a tool to help the databaseimplementor (DBI) in constructing a query optimizer for a DBMS. It is data modelindependent and allows to code a query optimizer by providing the implementations of thesubclasses of predefined interface classes. When the implementations of the requiredclasses are provided properly; the generated optimizer produces the optimum executionplans for the queries. Although providing the complete set of rules and thus finding theoptimum execution plans are beneficial for most of the queries; the query optimization timeincreases unacceptably for certain types of queries; eg; for star queries. Hence it is importantto be able to limit the number of alternative plans considered by the optimizer for specifictypes of queries by using the proper heuristics for each type. This leads to the concept of …,IEEE Data Eng. Bull.,1995,11
Data for all: A systems approach to accelerate the path from data to insight,Eser Kandogan; Mary Roth; Cheryl Kieliszewski; Fatma Özcan; Bob Schloss; Marc-Thomas Schmidt,Zettabytes of data are available to be harvested for competitive business advantage; soundgovernment policies; and new insights in a broad array of applications. Yet; most of this datais inaccessible for users; since current data analysis tools require an army of technicalpeople to find; transform; analyze; and visualize data in order to make it consumable fordecision making. In this paper; we present work in progress to lower the barriers for data-driven decision making by introducing a systems approach to scale the user experience; notonly in the volume and variety of data; but also in the skills required to harvest that data. Wecall for a new approach for data-intensive applications that engages the user as anintelligent partner in a social and intelligent conversation with data by automating; guiding;and recommending data; transformations; visualizations; analytics; and suggesting …,Big Data (BigData Congress); 2013 IEEE International Congress on,2013,10
Xquery rewrite optimization in ibm db2 purexml,Fatma Ozcan; Normen Seemann; Ling Wang,Abstract In this paper; we describe XQuery compilation and rewrite optimization in DB2pureXML; a hybrid relational and XML database management system. DB2 pureXML hasbeen designed to scale to large collections of XML data. In such a system; effective filteringof XML documents and efficient execution of XML navigation are vital for high throughput.Hence the focus of rewrite optimization is to consolidate navigation constructs as much aspossible and to pushdown comparison predicates and navigation constructs into dataaccess to enable index usage. In this paper; we describe the new rewrite transformations wehave implemented specifically for XQuery and its navigational constructs. We also brieflydiscuss how some of the existing rewrite transformations developed for the SQL engine areextended and adapted for XQuery.,IEEE Data Engineering Bulletin,2008,10
XMLTable,Fred Zemke; Michael Rys; Krishna Kulkarni; J Michels; Berthold Reinwald; F Oczan; Z Hua Liu; Ian Davis; Keith Hare,*,ISO/IEC JTC1/SC32 WG3: SIA-051 ANSI NCITS H,2004,9
Joins for Hybrid Warehouses: Exploiting Massive Parallelism in Hadoop and Enterprise Data Warehouses.,Yuanyuan Tian; Tao Zou; Fatma Ozcan; Romulo Goncalves; Hamid Pirahesh,ABSTRACT HDFS has become an important data repository in the enterprise as the centerfor all business analytics; from SQL queries; machine learning to reporting. At the same time;enterprise data warehouses (EDWs) continue to support critical business analytics. This hascreated the need for a new generation of special federation between Hadoop-like big dataplatforms and EDWs; which we call the hybrid warehouse. There are many applications thatrequire correlating data stored in HDFS with EDW data; such as the analysis that associatesclick logs stored in HDFS with the sales data stored in the database. All existing solutionsreach out to HDFS and read the data into the EDW to perform the joins; assuming that theHadoop side does not have the efficient SQL support. In this paper; we show that it isactually better to do most data processing on the HDFS side; provided that we can …,EDBT,2015,8
Making Oracle7; Sybase and Adabas D Interoperable through CORBA: MIND Project,Gokhan Ozhan; Asuman Dogac; Ebru Kilic; Fatma Ozcan; Sena Nural; Cevdet Dengi; U Halici; B Arpinar; P Koksal; S Mancuhan; C Evrendilek,Summary METU Interoperable DBMS (MIND) is a multidatabase system which aims atachieving interoperability among heterogeneous; federated DBMSs. The architecture ofMIND is based on OMG1 distributed object management model. It is implemented on top ofa CORBA compliant ORB; namely; ObjectBroker2. In MIND all local databases areencapsulated in a generic database object. The interface of the generic database object isdefined in CORBA IDL and multiple implementations of this interface; one for eachcomponent DBMSs; namely; Oracle73; Sybase4; Adabas D5 and MOOD (METU Object-Oriented Database System)(Asuman Dogac; 1994a-b) are provided. MIND provides itsusers a common data model and a single global query language based on SQL. The maincomponents of MIND are a global query manager; a global transaction manager; a …,Proc. of European Oracle User Group Conference,1996,8
Tutorial: SQL-on-Hadoop Systems,Daniel Abadi; Shivnath Babu; Fatma Ozcan; Ippokratis Pandis,*,Proceedings of the VLDB Endowment,2015,6
A platform for eXtreme Analytics,Andrey Balmin; Kevin Beyer; Vuk Ercegovac; John McPherson; Fatma Oezcan; Hamid Pirahesh; Eugene Shekita; Yannis Sismanis; Sandeep Tata; Yuanyuan Tian,With the rapid increase in the volume of data that enterprises are producing; enterprises areadopting large-scale data processing platforms such as Hadoop® to store; manage; and rundeep analytics to gain actionable insights from their “big data.” At IBM Research-Almaden;we have been helping enterprise customers build solutions exploiting data-intensiveanalytics. Our deep experience with actual users has led to an extensive understanding ofthe platform requirements needed to support these solutions; and our goal is to provide apowerful analytics platform; which we call eXtreme Analytics Platform (XAP); that can beused to create solutions for customer problems that have not been economically feasible tosolve until now. XAP provides Jaql [ie; JavaScript® Object Notation (JSON) query language;a scripting language to specify data flows; tools; and techniques to optimize the runtime …,IBM Journal of Research and Development,2013,6
Search driven analysis of heterogenous XML data,Andrey Balmin; Latha Colby; Emiran Curtmola; Quanzhong Li; Fatma Ozcan,Abstract: Analytical processing on XML repositories is usually enabled by designingcomplex data transformations that shred the documents into a common data warehousingschema. This can be very time-consuming and costly; especially if the underlying XML datahas a lot of variety in structure; and only a subset of attributes constitutes meaningfuldimensions and facts. Today; there is no tool to explore an XML data set; discoverinteresting attributes; dimensions and facts; and rapidly prototype an OLAP solution. In thispaper; we propose a system; called SEDA that enables users to start with simple keyword-style querying; and interactively refine the query based on result summaries. SEDA thenmaps query results onto a set of known; or newly created; facts and dimensions; and derivesa star schema and its instantiation to be fed into an off-the-shelf OLAP tool; for further …,arXiv preprint arXiv:0909.1773,2009,6
Split elimination in mapreduce systems,*,Embodiments of the present invention relate to elimination of blocks such as splits indistributed processing systems such as MapReduce systems using the Hadoop DistributedFiling System (HDFS). In one embodiment; a method of and computer program product foroptimizing queries in distributed processing systems are provided. A query is received. Thequery includes at least one predicate. The query refers to data. The data includes a pluralityof records. Each record comprises a plurality of values in a plurality of attributes. Each recordis located in at least one of a plurality of blocks of a distributed file system. Each block has aunique identifier. For each block of the distributed file system; at least one value cluster isdetermined for an attribute of the plurality of attributes. Each value cluster has a range. Thepredicate of the query is compared with the at least one value cluster of each block. The …,*,2015,5
SQL-on-hadoop systems: tutorial,Daniel Abadi; Shivnath Babu; Fatma Özcan; Ippokratis Pandis,Abstract Enterprises are increasingly using Apache Hadoop; more specifically HDFS; as acentral repository for all their data; data coming from various sources; including operationalsystems; social media and the web; sensors and smart devices; as well as their applications.At the same time many enterprise data management tools (eg from SAP ERP and SAS toTableau) rely on SQL and many enterprise users are familiar and comfortable with SQL. Asa result; SQL processing over Hadoop data has gained significant traction over the recentyears; and the number of systems that provide such capability has increased significantly. Inthis tutorial we use the term SQL-on-Hadoop to refer to systems that provide some level ofdeclarative SQL (-like) processing over HDFS and noSQL data sources; using architecturesthat include computational or storage engines compatible with Apache Hadoop.,Proceedings of the VLDB Endowment,2015,5
Benchmarking sql-on-hadoop systems: Tpc or not tpc?,Avrilia Floratou; Fatma Özcan; Berni Schiefer,Abstract Benchmarks are important tools to evaluate systems; as long as their results aretransparent; reproducible and they are conducted with due diligence. Today; many SQL-on-Hadoop vendors use the data generators and the queries of existing TPC benchmarks; butfail to adhere to the rules; producing results that are not transparent. As the SQL-on-Hadoopmovement continues to gain more traction; it is important to bring some order to this “wildwest” of benchmarking. First; new rules and policies should be defined to satisfy thedemands of the new generation SQL systems. The new benchmark evaluation schemesshould be inexpensive; effective and open enough to embrace the variety of SQL-on-Hadoop systems and their corresponding vendors. Second; adhering to the new standardsrequires industry commitment and collaboration. In this paper; we discuss the problems …,Workshop on Big Data Benchmarks,2014,5
Partitioning activities for agents,Fatma Ozcan; VS Subrahmanian,Abstract There are now numerous agent applications that track interests of thousands ofusers in situations where changes occur continuously.[Shim et al.; 1994] suggested thatsuch agents can be made efficient by merging commonalities in their activities. However;past algorithms cannot merge more than 10 or 20 concurrent activities. We developtechniques so that a large number of concurrent activities (typically over 1000) can bepartitioned into components (groups of activities) of small size (eg 10 to 50) so that eachcomponent's activities can be merged using previously developed algorithms (eg [Shim etal.; 1994]). We first formalize the problem and show that finding optimal partitions is NP-hard.We then develop three algorithms-Greedy; A-based and BAB (branch and bound). A-basedand BAB are both guaranteed to compute optimal solutions. Greedy on the other hand …,INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE,2001,5
Adaptive caching in Big SQL using the hdfs cache,Avrilia Floratou; Nimrod Megiddo; Navneet Potti; Fatma Özcan; Uday Kale; Jan Schmitz-Hermes,Abstract The memory and storage hierarchy in database systems is currently undergoing aradical evolution in the context of Big Data systems. SQL-on-Hadoop systems share datawith other applications in the Big Data ecosystem by storing their data in HDFS; using openfile formats. However; they do not provide automatic caching mechanisms for storing data inmemory. In this paper; we describe the architecture of IBM Big SQL and its use of the HDFScache as an alternative to the traditional buffer pool; allowing in-memory data to be sharedwith other Big Data applications. We design novel adaptive caching algorithms for Big SQLtailored to the challenges of such an external cache scenario. Our experimental evaluationshows that only our adaptive algorithms perform well for diverse workload characteristics;and are able to adapt to evolving data access patterns. Finally; we discuss our …,Proceedings of the Seventh ACM Symposium on Cloud Computing,2016,4
Wildfire: Concurrent blazing data ingest and analytics,Ronald Barber; Matt Huras; Guy Lohman; C Mohan; Rene Mueller; Fatma Özcan; Hamid Pirahesh; Vijayshankar Raman; Richard Sidle; Oleg Sidorkin; Adam Storm; Yuanyuan Tian; Pinar Tözun,Abstract We demonstrate Hybrid Transactional and Analytics Processing (HTAP) on theSpark platform by the Wildfire prototype; which can ingest up to~ 6 million inserts per secondper node and simultaneously perform complex SQL analytics queries. Here; a simplifiedmobile application uses Wildfire to recommend advertising to mobile customers based upontheir distance from stores and their interest in products sold by these stores; whilecontinuously graphing analytics results as those customers move and respond to the adswith purchases.,Proceedings of the 2016 International Conference on Management of Data,2016,4
SEDA: a system for search; exploration; discovery; and analysis of XML Data,Andrey Balmin; Latha Colby; Emiran Curtmola; Quanzhong Li; Fatma Özcan; Sharath Srinivas; Zografoula Vagena,Abstract Keyword search in XML repositories is a powerful tool for interactive dataexploration. Much work has recently been done on making XML search aware ofrelationship information embedded in XML document structure; but without a clear winner inall data and query scenarios. Furthermore; due to its imprecise nature; search results cannoteasily be analyzed and summarized to gain more insights into the data. We address theseshortcomings with SEDA: a system for Search; Exploration; Discovery; and Analysis of XMLData. SEDA is based on a paradigm of search and user interaction to help users start withsimple keyword-style querying and perform rich analysis of XML data by leveraging both thecontent and structure of the data. SEDA is an interactive system that allows the user to refineher query iteratively to explore the XML data and discover interesting relationships. SEDA …,Proceedings of the VLDB Endowment,2008,4
Heterogeneous Active Agents,VS Subrahmanian; Thomas Eiter; George Pick,Over the years; many different agent programming languages have been proposed. In thispaper; we propose a concept called Agent Programs using which; the way an agent shouldact in various situations can be declaratively specified by the creator of that agent. AgentPrograms may be built on top of arbitrary pieces of software code and may be used tospecify what an agent is obliged to do; what an agent may do; and what an agent may notdo. In this paper; we define several successively more sophisticated and epistemicallysatisfying declarative semantics for agent programs; and study the computation price to bepaid (in terms of complexity) for such epistemic desiderata. We further show that agentprograms cleanly extend well understood semantics for logic programs; and thus are clearlylinked to existing results on logic programming and nonmonotonic reasoning. Last; but …,*,1998,4
Evolving Databases for New-Gen Big Data Applications.,Ronald Barber; Christian Garcia-Arellano; Ronen Grosman; Rene Mueller; Vijayshankar Raman; Richard Sidle; Matt Spilchen; Adam J Storm; Yuanyuan Tian; Pinar Tözün; Daniel C Zilio; Matt Huras; Guy M Lohman; Chandrasekaran Mohan; Fatma Özcan; Hamid Pirahesh,ABSTRACT The rising popularity of large-scale real-time analytics applications (real-timeinventory/pricing; mobile apps that give you suggestions; fraud detection; risk analysis; etc.)emphasize the need for distributed data management systems that can handle fasttransactions and analytics concurrently. Efficient processing of transactional and analyticalrequests; however; require different optimizations and architectural decisions in a system.This paper presents the Wildfire system; which targets Hybrid Transactional and AnalyticalProcessing (HTAP). Wildfire leverages the Spark ecosystem to enable large-scale dataprocessing with different types of complex analytical requests; and columnar dataprocessing to enable fast transactions and analytics concurrently.,CIDR,2017,3
Building a hybrid warehouse: efficient joins between data stored in HDFS and enterprise warehouse,Yuanyuan Tian; Fatma Özcan; Tao Zou; Romulo Goncalves; Hamid Pirahesh,Abstract The Hadoop Distributed File System (HDFS) has become an important datarepository in the enterprise as the center for all business analytics; from SQL queries andmachine learning to reporting. At the same time; enterprise data warehouses (EDWs)continue to support critical business analytics. This has created the need for a newgeneration of a special federation between Hadoop-like big data platforms and EDWs;which we call the hybrid warehouse. There are many applications that require correlatingdata stored in HDFS with EDW data; such as the analysis that associates click logs stored inHDFS with the sales data stored in the database. All existing solutions reach out to HDFSand read the data into the EDW to perform the joins; assuming that the Hadoop side doesnot have efficient SQL support. In this article; we show that it is actually better to do most …,ACM Transactions on Database Systems (TODS),2016,3
A Generic Solution to Integrate SQL and Analytics for Big Data.,Nick R Katsipoulakis; Yuanyuan Tian; Fatma Ozcan; Hamid Pirahesh; Berthold Reinwald,ABSTRACT There is a need to integrate SQL processing with more advanced machinelearning (ML) analytics to drive actionable insights from large volumes of data. As a first steptowards this integration; we study how to efficiently connect big SQL systems (either MPPdatabases or new-generation SQL-on-Hadoop systems) with distributed big ML systems. Weidentify two important challenges to address in the integrated data analytics pipeline: datatransformation; how to efficiently transform SQL data into a form suitable for ML; and datatransfer; how to efficiently handover SQL data to ML systems. For the data transformationproblem; we propose an In-SQL approach to incorporate common data transformations forML inside SQL systems through extended user-defined functions (UDFs); by exploiting themassive parallelism of the big SQL systems. We propose and study a general method for …,EDBT,2015,3
Secure agent programs,VS Subrahmanian; P Bonatti; J Dix; T Eiter; S Kraus; F Ozcan; R Ross,*,Heterogeneous Agent Systems,2000,3
Join algorithms over full text indexes,*,According to one embodiment of the present invention; a method for processing joinpredicates in full-text indexes is provided. The method includes evaluating local predicatesof an outer full text index to generate a first posting list of documents. For each document inthe first posting list; the value of a join attribute is determined and an inner full text index isprobed to obtain a second posting list of documents containing one of the join attributesdetermined for each document. Local predicates of an inner full text index are evaluated togenerate a third posting list of documents; and the second posting list is merged with thethird posting list to generate a merge list of documents. Documents in the first posting listmay be paired up with documents in the merge list.,*,2014,2
SQL-on-Hadoop without compromise,Scott C Gray; Fatma Ozcan; Herbert Pereyra; Bert van der Linden; Adriana Zubiri,*,*,2014,2
Next generation data analytics at IBM research,Oktie Hassanzadeh; Anastasios Kementsietsidis; Benny Kimelfeld; Rajasekar Krishnamurthy; Fatma Özcan; Ippokratis Pandis,IBM Research has a rich history of innovation in information management with severalrevolutionary breakthroughs; including the invention of relational databases; advanced textanalytics demonstrated by Watson; and the first data mining algorithms to name a few. IBMResearch has been committed to contributing to the community via seminal papers;exemplified by several 10-year awards received by IBM researchers. This short abstract isintended as a quick tour of some of the current information management projects; and notmeant to be an exhaustive list by any means. There has been many disruptive technologicaldevelopments over the last decade. The emergence of cloud computing; and several largescale data processing platforms; advances in on-line social media; the explosion of datavolumes; and the advances in hardware have all forced us to rethink the information …,Proceedings of the VLDB Endowment,2013,2
XQuery processors,Torsten Grust; HV Jagadish; Fatma Özcan; Cong Yu,XML access control refers to the practice of limiting access to (parts of) XML data to onlyauthorized users. Similar to access control over other types of data and resources; XMLaccess control is centered around two key problems:(i) the development of formal models forthe specification of access control policies over XML data; and (ii) techniques for efficientenforcement of access control policies over XML data.,*,2009,2
Improving performance of heterogeneous agents,Fatma Özcan; VS Subrahmanian; Jürgen Dix,Abstract Agents provide services not only to humans users but also to agents in one or moremultiagent systems. When agents are confronted with multiple tasks to perform (or requeststo satisfy); the agent can reduce load on itself by attempting to take advantage ofcommonalities between the tasks that need to be performed. In this paper; we develop alogical theory by which such “heavily loaded” agents can merge commonalities amongstsuch tasks. In our framework; agents can be built on top of legacy codebases. We propose alogical formalism called invariants using which agent developers may specify knowncommonalities between tasks–after this; we propose a sound and complete mechanism toderive all possible derived commonalities. An obvious A*-based algorithm may be used tomerge a set of tasks in a way that minimised expected execution cost. Unfortunately the …,Annals of Mathematics and Artificial Intelligence,2004,2
Multidatabase Query Optimization,Asuman Dogac; Sena Nural; Fatman Ozcan,*,Middle East Technical University (METU). Project Number: EEEAG-Yazilim5; by Motorola (USA) and by evgin Holding (Turkey),*,2
Processing Java UDFs in a C++ environment,Viktor Rosenfeld; Rene Mueller; Pinar Tözün; Fatma Özcan,Abstract Many popular big data analytics systems today make liberal use of user-definedfunctions (UDFs) in their programming interface and are written in languages based on theJava Virtual Machine (JVM). This combination creates a barrier when we want to integrateprocessing engines written in a language that compiles down to machine code with a JVM-based big data analytics ecosystem. In this paper; we investigate efficient ways of executingUDFs written in Java inside a data processing engine written in C++. While it is possible tocall Java code from machine code via the Java Native Interface (JNI); a naiveimplementation that applies the UDF one row at a time incurs a significant overhead; up toan order of magnitude.,Proceedings of the 2017 Symposium on Cloud Computing,2017,1
Hybrid Transactional/Analytical Processing: A Survey,Fatma Özcan; Yuanyuan Tian; Pinar Tözün,Abstract The popularity of large-scale real-time analytics applications (real-timeinventory/pricing; recommendations from mobile apps; fraud detection; risk analysis; IoT;etc.) keeps rising. These applications require distributed data management systems that canhandle fast concurrent transactions (OLTP) and analytics on the recent data. Some of themeven need running analytical queries (OLAP) as part of transactions. Efficient processing ofindividual transactional and analytical requests; however; leads to different optimizationsand architectural decisions while building a data management system. For the kind of dataprocessing that requires both analytics and transactions; Gartner recently coined the termHybrid Transactional/Analytical Processing (HTAP). Many HTAP solutions are emergingboth from the industry as well as academia that target these new applications. While …,Proceedings of the 2017 ACM International Conference on Management of Data,2017,1
Adaptive Caching Algorithms for Big Data Systems,Avrilia Floratou; Nimrod Megiddo; Navneet Potti; Fatma Özcan; Uday Kale; Jan Schmitz-Hermes,Abstract Today's Big Data platforms have enabled the democratization of data by allowingdata sharing among various data processing frameworks and applications that run in thesame platform. This data and resource sharing; combined with the fact that most applicationstend to access a hot set of the data has led to the development of external; in-memory;distributed caching frameworks. In this paper; we develop online; adaptive algorithms forexternal caches. Our caching algorithms take into account the workload access pattern; andthe cost of insertions in the external caching framework when making cache insertion andreplacement decisions. We provide both a detailed simulation study as well as clusterexperiments on IBM Big SQL; and show that only our adaptive algorithms perform well fordifferent workload characteristics; are able to adapt to evolving workload access patterns …,*,2015,1
CDMW 2012-city data management workshop: workshop summary,Veli Bicer; Thanh Tran; Fatma Ozcan; Opher Etzion,Abstract Cities today have become highly dense; dynamic living areas for the majority ofplanet's population and also focal points of innovation; commerce; and growth in a highlymodernized world. Due to its intensifying importance; cities need to transform intosustainable; smarter and credible places to enable a tenantable and comfortable life for theircitizens. City data; which is the source of our digitized knowledge about the cities; is a highlyimportant element to achive this goal as it is the main input to build complex city ecosystemsand to solve particular problems that are encountered in the cities today. In this respect; thisworkshop will provide a major forum to identify the challenges and opportunities in terms ofbetter managing city data and to reveal its discriminating importance in various applicationsin a city ecosystem. As city data becomes more widespread and prevailing; it poses novel …,Proceedings of the 21st ACM international conference on Information and knowledge management,2012,1
Optimal Agent Selection.,Fatma Ozcan; VS Subrahmanian; Leana Golubchik,Abstract. The Internet contains a vast array of sources that provide identical or similarservices. When an agent needs to solve a problem; it may split the problem into“subproblems” and find an agent to solve each of the subproblems. Later; it may combinethe results of these subproblems to solve the original problem. In this case; the agent isfaced with the task of determining to which agents to assign the subproblems. We call thisthe agent selection problem (ASP for short). Solving ASP is complex because it must takeinto account several different parameters. For instance; different agents might take differentamounts of time to process a request. Different agents might provide varying “qualities” ofanswers. Network latencies associated with different agents might vary. In this paper; we firstformalize the agent selection problem and show that it is NP-hard. We then propose a …,KI/ÖGAI,2001,1
Transforming an ontology query to an sql query,*,Abstract A computer-implemented method according to one embodiment includes receivingan ontology language query; receiving a mapping of an ontology to a relational database;and generating a structured query language (SQL) query; utilizing the ontology languagequery and the mapping of the ontology to the relational database.,*,2018,*
Dynamic query optimization with pilot runs,*,Abstract In one embodiment; a computer-implemented method includes selecting one ormore sub-expressions of a query during compile time. One or more pilot runs are performedby one or more computer processors. The one or more pilot runs include a pilot runassociated with each of one or more of the selected sub-expressions; and each pilot runincludes at least partial execution of the associated selected sub-expression. The pilot runsare performed during execution time. Statistics are collected on the one or more pilot runsduring performance of the one or more pilot runs. The query is optimized based at least inpart on the statistics collected during the one or more pilot runs; where the optimizationincludes basing cardinality and cost estimates on the statistics collected during the pilotruns.,*,2017,*
Caching policies for selection and replacement of objects,*,In one embodiment; a computer-implemented method includes inserting a set of accessedobjects into a cache; where the set of accessed objects varies in size. An object includes aset of object components; and responsive to receiving a request to access the object; it isdetermined that the object does not fit into the cache given the set of accessed objects and atotal size of the cache. A heuristic algorithm is applied; by a computer processor; to identifyin the set of object components one or more object components for insertion into the cache.The heuristic algorithm considers at least a priority of the object compared to priorities of oneor more objects in the set of accessed objects. The one or more object components areinserted into the cache.,*,2017,*
Parallel data streaming between cloud-based applications and massively parallel systems,*,Embodiments relate to parallel data streaming between a first computer system and asecond computer system. Aspects include transmitting a request to establish anauthenticated connection between a processing job on the first computer system and aprocess on the second computer system and transmitting a query to the process on thesecond computer system over the authenticated connection. Aspects further include creatingone or more tasks on the first computer system configured to receive data from the secondcomputer system in parallel and reading data received by the one or more tasks by theprocessing job on the first computer system.,*,2017,*
No data left behind: real-time insights from a complex data ecosystem,Manos Karpathiotakis; Avrilia Floratou; Fatma Özcan; Anastasia Ailamaki,Abstract The typical enterprise data architecture consists of several actively updated datasources (eg; NoSQL systems; data warehouses); and a central data lake such as HDFS; inwhich all the data is periodically loaded through ETL processes. To simplify queryprocessing; state-of-the-art data analysis approaches solely operate on top of the local;historical data in the data lake; and ignore the fresh tail end of data that resides in theoriginal remote sources. However; as many business operations depend on real-timeanalytics; this approach is no longer viable. The alternative is hand-crafting the analysis taskto explicitly consider the characteristics of the various data sources and identify optimizationopportunities; rendering the overall analysis non-declarative and convoluted. Based on ourexperiences operating in data lake environments; we design System-PV; a real-time …,Proceedings of the 2017 Symposium on Cloud Computing,2017,*
Joining data across a parallel database and a distributed processing system,*,Embodiments relate to joining data across a parallel database and a distributed processingsystem. Aspects include receiving a query on data stored in parallel database T and datastored in distributed processing system L; applying local query predicates and projection todata T to create T′; and applying local query predicates and projection to L to create L′.Based on determining that a size of L′ is less than a size of T′ and that the size of L′ isless than a first threshold; transmitting L′ to the parallel database and executing a joinbetween T′ and L′. Based on determining that a number of the nodes distributedprocessing system n multiplied by the size of T′ is less than the size of L′ and that the sizeof T′ is less than a second threshold; transmitting T′ to the distributed processing systemand executing a join between T′ and L′.,*,2017,*
Creation and interaction with large-scale domain-specific knowledge bases,S Bharadwaj; L Chiticariu; M Danilevsky; S Dhingra; S Divekar; A Carreno-Fuentes; H Gupta; N Gupta; S-D Han; M Hernández; H Ho; P Jain; S Joshi; H Karanam; S Krishnan; R Krishnamurthy; Y Li; S Manivannan; A Mittal; F Özcan; A Quamar; P Raman; D Saha; K Sankaranarayanan; J Sen; P Sen; S Vaithyanathan; M Vasa; H Wang; H Zhu,Abstract The ability to create and interact with large-scale domain-specific knowledge basesfrom unstructured/semi-structured data is the foundation for many industry-focused cognitivesystems. We will demonstrate the Content Services system that provides cloud services forcreating and querying high-quality domain-specific knowledge bases by analyzing andintegrating multiple (un/semi) structured content sources. We will showcase an instantiationof the system for a financial domain. We will also demonstrate both cross-lingual naturallanguage queries and programmatic API calls for interacting with this knowledge base.,Proceedings of the VLDB Endowment,2017,*
Assignment of Data Within File Systems,*,The embodiments relate to assigning data to processors of a file system. Metadataassociated with respective blocks of data; and an initial batch of the blocks is assigned tonodes of a file system based on the metadata. Unassigned blocks are selectively assignedto one or more of the nodes. The selective assignment includes constructing a linearregression model based on node data; and determining a value for each node based on thelinear regression model. Each value is associated with a predicted load corresponding to anew assignment of one or more unassigned blocks.,*,2017,*
Adaptive fragment assignment for processing file data in a database,*,Scheduling mechanisms for assigning data in a distributed file system to database workersare provided. In one embodiment; a method of and computer program product forassignment of data blocks to database workers are provided. A request for table data isreceived. Metadata for a plurality of blocks in a file system is retrieved from a metadata store.Each of the plurality of blocks contains a subset of the table data. A request for work isreceived from a requestor. An assignment of one or more of the plurality of blocks isprovided to the requestor.,*,2017,*
Encyclopedia of Database Systems: A Springer Live Reference,Simonas Šaltenis; Ugur Cetintemel; Fatma Özcan; M Tamer Özsu; Peter Øhrstrøm; Ali Ünlü; Daniel Abadi; Alberto Abello; Serge Abiteboul; Ioannis Aekaterinidis,*,*,2011,*
Grouping and Optimization of XPath Expressions in System RX,Andrey Balmin; Fatma Ozcan; Ashutosh Singh; Edison Ting,Several XML DBMS support XQuery and/or SQL/XML languages; which are based onnavigational primitives in the form of XPath expressions. Typically; these systems eithermodel each XPath step as a separate query plan operator; or employ holistic approachesthat can evaluate multiple steps of a single XPath expression. There have also beenproposals to execute as many XPath expressions as possible within a single FLWOR blocksimultaneously in a data streaming context. We observe in our System-RX prototype thatblindly combining all possible XPath expressions for concurrent execution can result insignificant performance degradation. We identify two main problems. First; the simplestrategy of grouping all XPath expressions on a single document does not always work if thequery involves more than one data source or has nested query blocks. Second; merging …,Data Engineering; 2008. ICDE 2008. IEEE 24th International Conference on,2008,*
Number One (G321-0160) On demand platform for online games 7 A. Shaikh; S. Sahu; M.-C. Rosu; M. Shea; and D. Saha Running Quake II on a grid 21,G Deen; M Hammer; J Bethencourt; I Eiron; J Thomas; JH Kaufman; M Ye; L Cheng; AE Eichenberger; JK O’Brien; KM O’Brien; P Wu; T Chen; PH Oden; DA Prener; JC Shepherd; B So; Z Sura; A Wang; T Zhang; P Zhao; MK Gschwind; R Archambault; Y Gao; R Koo; M Ohara; H Inoue; Y Sohda; H Komatsu; T Nakatani; B D’Amora; K Magerlein; A Binstock; A Nanda; B Yee; G Myles; S Nusser; L Luo; J Liu; L Shao; W Lu; CE Sharp; M Rowe; R Hirschheim; A Schwarz; P Todd; E Perkins; M Matsa; MG Kostoulas; A Heifets; N Mendelsohn; F Ozcan; D Chamberlin; K Kulkarni; JE Michels; K Beyer; R Cochrane; M Hvizdos; V Josifovski; J Kleewein; G Lapis; G Lohman; R Lyle; M Nicola; H Pirahesh; N Seemann; A Singh; T Truong; RC Van der Linden; B Vickery; C Zhang; G Zhang; A Balmin; T Eliaz; J Hornibrook; L Lim; GM Lohman; D Simmen; M Wang; CC Kanne; G Moerkotte; S Amer-Yahia; C Botev; J Dörre; J Shanmugasundaram; XML Enhancing; P Case; A Shabo; S Rabinovici-Cohen; P Vortman; S Hinkelman; D Buddenbaum; LJ Zhang,Page 1. Contents of Volume 45; 2006 & Number One (G321-0160) On demand platform foronline games 7 A. Shaikh; S. Sahu; M.-C. Rosu; M. Shea; and D. Saha Running Quake II ona grid 21 G. Deen; M. Hammer; J. Bethencourt; I. Eiron; J. Thomas; and JH KaufmanSystem-performance modeling for massively multiplayer online role-playing games 45 M. Yeand L. Cheng Using advanced compiler technology to exploit the performance of the CellBroadband Enginee architecture 59 AE Eichenberger; JK O'Brien; KM O'Brien; P. Wu; T. Chen;PH Oden; DA Prener; JC Shepherd; B. So; Z. Sura; A. Wang; T. Zhang; P. Zhao; MK Gschwind;R. Archambault; Y. Gao; and R. Koo MPI microtask for programming the Cell Broadband Engineeprocessor 85 M. Ohara; H. Inoue; Y. Sohda; H. Komatsu; and T. Nakatani High-performanceserver systems and the next generation of online games 103 …,IBM Systems Journal,2006,*
Improving Performance of Agents by Activity Partitioning,Fatma Ozcan; VS Subrahmanian,There is growing interest in software agents that provide a variety of services to humans;other agents; and third party software applications. Some of these agents are engaged inhundreds of activities at any given time point. In such cases; agents may try to examine a setA of activities and leverage commonalities between them in order to reduce their load. Wecall this activity merging. Unfortunately; in most application domains; activity merging turnsout to be NP-complete. Thus; for each application domain; there is an integer k (which variesfrom domain to domain) such that activity merging can merge up to k activities whilesatisfying the application's performance expectations. In this paper; we consider the problemof what to do when the set of activities exceeds k. Our approach partitions A into disjoint setsA1 union A2 union... union An such that each Ai contains at most k activities in it (thus the …,*,2002,*
Probabilistic Temporal Databases; II: Calculus and Query Processing,Alex Dekhtyar; Fatma Ozcan; Robert Ross; VS Subrahmanian,There is a vast class of applications in which we know that a certain event occurred; but donot know exactly when it occurred. However; as studied by Dyreson and Snodgrass\cite{ds98}; there are many natural scenarios where probability distributions exist and quantifythis uncertainty. Dekhtyar et. al. extended Dyreson and Snodgrass's work and defined anextension of the relational algebra to handle such data. The first contribution of this paper isa declarative temporal probabilistic (TP for short) calculus which we show is equivalent inexpressive power to the temporal probabilistic algebra of Dekhtyar et. al. Our second majorcontribution is a set of equivalence and containment results for the TP-algebra. Our thirdcontribution is the development of cost models that may be used to estimate the cost of TP-algebra operations. Our fourth contribution is an experimental evaluation of the accuracy …,*,2001,*
Optimal Agent Section,Fatma Özcan; VS Subrahmanian; Leana Golubchik,Abstract The Internet contains a vast array of sources that provide identical or similarservices. When an agent needs to solve a problem; it may split the problem into“subproblems” and find an agent to solve each of the subproblems. Later; it may combinethe results of these subproblems to solve the original problem. In this case; the agent isfaced with the task of determining to which agents to assign the subproblems. We call thisthe agent selection problem (ASP for short). Solving ASP is complex because it must takeinto account several different parameters. For instance; different agents might take differentamounts of time to process a request. Different agents might provide varying “qualities” ofanswers. Network latencies associated with different agents might vary. In this paper; we firstformalize the agent selection problem and show that it is NP-hard. We then propose a …,Annual Conference on Artificial Intelligence,2001,*
Improving the performance of heterogeneous databases and agents,Fatma Ozcan,Abstract Today's applications require the ability to access and query multiple heterogeneousdata sources. Heterogeneous databases (HDB) and heterogeneous agent systems providethe necessary means to attain this goal. A common characteristics of such HDB and agentsystems is that they simultaneously process large numbers of queries/requests. The ability toefficiently handle large volumes of simultaneous queries is critical in many suchapplications. In this thesis; we present various query optimization techniques to improve theperformance of such heavily loaded HDB and agent systems. Since cost models play a keyrole in query optimization; we first propose a framework through which a heterogeneoussystem can obtain cost and cardinality information required for optimization. Our approach isthe first to adapt a traditional System-R style optimizer to perform costing in a …,*,2001,*
Improving Performance of heavily loaded agents,Fatma Ozcan; VS Subrahmanian; Juergen Dix,Abstract: With the increase in agent-based applications; there are now agent systems thatsupport\emph {concurrent} client accesses. The ability to process large volumes ofsimultaneous requests is critical in many such applications. In such a setting; the traditionalapproach of serving these requests one at a time via queues (eg\textsf {FIFO} queues;priority queues) is insufficient. Alternative models are essential to improve the performanceof such\emph {heavily loaded} agents. In this paper; we propose a set of\emph {cost-basedalgorithms} to\emph {optimize} and\emph {merge} multiple requests submitted to an agent.In order to merge a set of requests; one first needs to identify commonalities among suchrequests. First; we provide an\emph {application independent framework} within which anagent developer may specify relationships (called\emph {invariants}) between requests …,arXiv preprint cs/0012004,2000,*
An Interoperability Infrastructure for Developing Multidatabase Systems,Asuman Doğac; Gökhan Özhan; Ebru Kılıç; Fatma Özcan; Sena Nural; Sema Mancuhan; Cevdet Dengi; Pınar Köksal; Uğur Halıcı; Budak Arpınar; Cem Evrendilek; Vahid Sadjadi,Abstract: A multidatabase system (MDBS) allows the users to simultaneously accessautonomous; heterogeneous databases using a single data model and a query language.This provides for achieving interoperability among heterogeneous; federated DBMSs. In thispaper; we describe the interoperability infrastructure of a multidatabase system; namelyMETU Interoperable DBMS (MIND). The architecture of MIND is based on OMG distributedobject management model. It is implemented on top of a CORBA compliant ORB; namely;ObjectBroker. The interface of the generic database object is defined in CORBA IDL andmultiple implementations of this interface; one for each component DBMSs; namely; Oracle7; Sybase; Adabas D and MOOD (METU Object-Oriented Database System) are provided.The main components of MIND which are built on this infrastructure are a global query …,TURKISH JOURNAL OF ELECTRICAL ENGINEERING & COMPUTER SCIENCES,1998,*
Multidatabase Query Optimization,CEM EVRENDILEK ASUMAN DOGAC SENA NURAL; FATMA OZCAN,Abstract. A multidatabase system (MDBS) allows the users to simultaneously accessheterogeneous; and autonomous databases using an integrated schema and a singleglobal query language. The query optimization problem in MDBSs is quite di erent from thequery optimization problem in distributed homogeneous databases due to schemaheterogeneity and autonomy of local database systems. In this work; we consider theoptimization of query distribution in case of data replication and the optimization of intersitejoins; that is; the join of the results returned by the local sites in response to the globalsubqueries. The algorithms presented for the optimization of intersite joins try to maximizethe parallelism in execution and take the federated nature of the problem into account. It hasalso been shown through a comparative performance study that the proposed intersite …,Distributed and Parallel Databases,1997,*
Data Engineering,Fatma Ozcan; Sena Nural; Pinar Koksal; Mehmet Altinel; Asuman Dogac,The optimization problem of Select-Project-Join queries has been studied extensively.However; a problem that has until recently received relatively less attention is that ofoptimizing queries with aggregates. For example; for single block SQL; traditional queryprocessing systems directly implement SQL semantics and defer execution of grouping untilall joins in the FROM and WHERE clauses have been executed. Furthermore; for queriesthat reference views with aggregates; traditional optimizers do not consider flattening suchviews. In this paper; we will show that there is a rich set of execution alternatives that cansignificantly enhance the quality of the plans produced. We also discuss how one canchoose among the alternatives. First; let us consider single-block SQL queries. For thesequeries; the reason to consider alternatives where a group-by operation precedes a join …,Urbana,1995,*
2014 BigData Congress Technical Program Committee,Geoffrey Fox; Sergei Vassilvitskii; Fatma Ozcan; Suren Byna; Lavanya Ramakrishnan; Philip Carns; Andy Twigg; Florin Rusu; Xiaoyong Du; Zhanhuai Li; Weining Qian; Ge Yu; Jianhua Feng; Jian Yin; Kun Yue; Masaru Kitsuregawa; Yoshiharu Ishikawa; Jeffrey Yu; David Cheung; Xuemin Li; Xiaofang Zhou; Ee-Peng Lim; Hesham Hallal; Aziz Bouras; Srividya Kona; Maria Ebling; Gong Zhang; Rafael Accorsi; EBTIC Marcello Leida; UAE Irene Vanderfeesten; Lionel Brunie; Philippe Cudre-Maroux; Piero Fraternali; Gregorio Martinez; Rainer Stotzka; Hoang Tam Vo; Jarek Szlichta; Tilmann Rabl; Shiyong Lu,Du Li; Yahoo; USA Geoffrey Fox; Indiana University; USA Sergei Vassilvitskii; GoogleResearch; USA Poess Meikel; Oracle; USA Maja Vukovic; IBM TJ Research Center; USA YuanChi Chang; IBM TJ Research Center; USA Fatma Ozcan; IBM Almaden Research Center; USACharles (Chang-shing) Perng; IBM TJ Research Center; USA Suren Byna; Lawrence BerkeleyNational Laboratory; USA Lavanya Ramakrishnan; Lawrence Berkeley National Laboratory;USA Philip Carns; Argonne National Laboratory; USA Andy Twigg; Oxford University; UK FlorinRusu; University of California; Merced; USA Xiaoyong Du; Renmin University of China; ChinaZhanhuai Li; Northwestern Polytechnical University; China Weining Qian; East China NormalUniversity; China Ge Yu; Northeastern University; China Guoren Wang; Northeat University;China Jianhua Feng; Tsinghua University; China Jian Yin; Sun Yat-Sen University; China …,*,*,*
Program Committees,Sihem Amer Yahia; Kevin Beyer; CWI Peter Boncz; Netherlands Angela Bonifati; Arbee Chen; Jan Chomicki; Bobbie Cochrane; Latha Colby; Ada Fu; Sumit Ganguly; Torsten Grust; Raghav Kaushik; Arnd Christian Konig; Sailesh Krishnamurthy; Amalgamated Insight; David Lomet; Christopher Olston; Fatma Ozcan; Neoklis Polyzotis; Raghu Ramakrishnan; Krithi Ramamritham; Vijayshankar Raman; Rajeev Rastogi; Mary Roth; Jerome Simeon; Ioana Stanoi; Andrew Tomkins; AUEB Vasilis Vassalos; Greece Victor Vianu; Min Wang; Aidong Zhang,Foto Afrati; NTUA; Greece Natassa Ailamaki; CMU; USA Sihem Amer Yahia; YahooResearch; USA Paolo Atzeni; Univ. di Roma Tre; Italy Shivnath Babu; Duke Univ.; USA JamesA. Bailey; Univ. of Melbourne; Australia Magdalena Balazinska; Univ. of Washington; USA KevinBeyer; IBM Research; USA Michael Boehlen; Univ. of Bolzano; Italy Peter Boncz; CWI; NetherlandsAngela Bonifati; CNR; Italy Arbee Chen; National Tsing Hua Univ.; Taiwan Mitch Cherniack;Brandeis Univ.; USA Jan Chomicki; SUNY Buffalo; USA Stavros Christodoulakis; Tech Univ.of Crete; Greece Bobbie Cochrane; IBM Research; USA Edith Cohen; AT&T Labs; USA LathaColby; IBM Research; USA Graham Cormode; AT&T Labs; USA Abhinandan Das; GoogleLabs; USA Amol Deshpande; Univ. of Maryland; USA Alin Dobra; Univ. of Florida; USA ElenaFerrari; Univ. of Insubria; Italy J. Christoph Freytag; Humboldt Univ.; Germany Ada Fu …,*,*,*
ICDE 2009,Adam Silberstein; Akrivi Vlachou; Alexander G Connor; Alfredo Goñi; Ali Inan; Amar Phanishayee; Amruta Joshi; Anastasios Kementsietsidis; Ander de Keijzer; Anduo Wang; Anish Das Sarma; Arjun Dasgupta; Arthur H Lee; Arvind Arasu; Arvind Thiagarajan; Badrish Chandramouli; Barzan Mozafari; Bee-Chung Chen; Bhargav Kanagal; Bing-Rong Lin; Bingsheng He; Biswanath Panda; Bo Xu; Bogdan Alexe; Bolin Ding; Brandon Unger; Brian Ruttenberg; Bruce Lindsa; Caetano Traina Jr; Cao Yu; Carina F Dorneles; Changbin Liu; Changbin Song; Changliang Wang; Charalambos Charalambous; Chengkai Li; Choudur K Lakshminarayan; Chris Mayfield; Chris Re; Christian Beecks; Christoph Lofi; Christophe Bobineau; Christos Doulkeridis; Chuan Xiao; Congxing Cai; Conny Franke; Craig Freedman; Cyrus Shahabi; Daniela Leal Musa; David Detlefs; David Novak; Davide Mazza; Debojyoti Dutta; Derek Hao Hu; Dimitrios Tsoumakos; Dimitris Sacharidis; Dimitris Tsoumakos; Djoerd Hiemstra; Dominic Mueller; Duygu Ucar; Eduardo Mena; Eirinaios Michelakis; Emmanuel Müller; Eunseok Yang; Evan Welbourne; Evangelos Dellis; Fan Yang; Fatma Ozcan; Florin Rusu; Gabriel Ghinita; Gagan Agrawal; Gaoping Zhu; George Beskales; George Pallis; Grigoris Karvounarakis; Guadalupe Canahuate; Haibo Hu,Adam Silberstein Akrivi Vlachou Alexander G. Connor Alfredo Goñi Ali Inan Amar PhanishayeeAmruta Joshi Anastasios Kementsietsidis Ander de Keijzer Anduo Wang Anish Das Sarma ArjunDasgupta Arthur H. Lee Arvind Arasu Arvind Thiagarajan Badrish Chandramouli Barzan MozafariBee-Chung Chen Bhargav Kanagal Bing-Rong Lin Bingsheng He Biswanath Panda Bo Xu BogdanAlexe Bolin Ding Brandon Unger Brandon Unger Brian Ruttenberg Bruce Lindsa Caetano TrainaJr Cao Yu Carina F. Dorneles Changbin Liu Changbin Song Changliang Wang CharalambosCharalambous Chengkai Li Choudur K. Lakshminarayan Chris Mayfield … Chris Re ChristianBeecks Christoph Lofi Christophe Bobineau Christos Doulkeridis Chuan Xiao Congxing CaiConny Franke Craig Freedman Cyrus Shahabi Daniela Leal Musa David Detlefs David NovakDavide Mazza Debojyoti Dutta Derek Hao Hu Dimitrios Tsoumakos Dimitris Sacharidis …,*,*,*
Multiple Query Optimization in Mediator Systems,Fatma Ozcan; VS Subrahmanian,Abstract With the increase in mediated applications; there are now mediated applicationservers that support concurrent client accesses. Multiple query optimization (MQO) isessential for efficient processing of concurrent read only queries. The MQO problem inmediated environments differs from that of ordinary relational MQO systems in two ways:first; in mediated environments; the MQO system must be capable of interacting with the“local” query optimizers of the various sources being accessed. Second; in mediatedenvironments; the notion of what constitutes a “common” subexpression varies dramaticallyfrom one source to another; and the MQO system must be capable of working with thesediverse notions of “common” subexpression. In this paper; we extend classical relationalDBMS MQO techniques to the case of mediated applications. Our architecture has a …,*,*,*
Peter Chen; Louisiana State University & Carnegie-Mellon University; USA Du Li; Ericsson; USA Stratis Viglas; University of Edinburgh; UK Poess Meikel; Oracle; USA,Zhe Shang; Maja Vukovic; Yuan Chi Chang; Wesley M Gifford; Fatma Ozcan; Yannis Sismanis; Charles Perng; Suren Byna; Lavanya Ramakrishnan; Philip Carns; Andy Wilson; Andy Twigg; Florin Rusu; Xiaoyong Du; Zhanhuai Li; Weining Qian; Ge Yu; Guoren Wang; Jianhua Feng; Jian Yin; Kun Yue; Masaru Kitsuregawa; Yokota Haruo; Yoshiharu Ishikawa; Jeffrey Yu; David Cheung; Xuemin Lin; Xiaofang Zhou; Ee-peng Lim; Shailesh Kumar; Hesham Hallal; Jacob Slonim; Vasant Honavar; Bhuvan Bamba; Pankaj Mehra; Gong Zhang; Rafael Accorsi; Paolo Ceravolo; Etienne Riviere; Ioana Ciuciu; Maurice Van Keulen; Gabriele Ruffatti; Hong-Linh Truong,Peter Chen; Louisiana State University & Carnegie-Mellon University; USA Du Li; Ericsson; USAStratis Viglas; University of Edinburgh; UK Poess Meikel; Oracle; USA Zhe Shang; ManhattanCollege; USA Maja Vukovic; IBM TJ Research Center; USA Yuan Chi Chang; IBM TJ ResearchCenter; USA Wesley M. Gifford; IBM TJ Research Center; USA Fatma Ozcan; IBM Almaden ResearchCenter; USA Yannis Sismanis; IBM Almaden Research Center; USA Charles Perng; IBM TJ ResearchCenter; USA Suren Byna; Lawrence Berkeley National Laboratory; USA LavanyaRamakrishnan; Lawrence Berkeley National Laboratory; USA Philip Carns; Argonne NationalLaboratory; USA Andy Wilson; Sandia National Labs; USA Andy Twigg; Oxford University; UKFlorin Rusu; University of California; Merced; USA Xiaoyong Du; Renmin University ofChina; China Zhanhuai Li; Northwestern Polytechnical University; China Weining Qian …,*,*,*
B. Arpinar; P. Koksal; N. Kesimy; S. Mancuhan Software Research and Development Center of TUBITAK Middle East Technical University (METU); Turkiye email: as...,A Dogac; C Dengi; E Kilic; G Ozhan; F Ozcan; S Nural; C Evrendilek; U Halici,Abstract METU INteroperable DBMS (MIND) is a multidatabase system based on OMG'sdistributed object management architecture. It is implemented on top of a CORBA compliantORB; namely; DEC's ObjectBroker. In MIND all local databases are encapsulated in ageneric database object. The interface of the generic database object is de ned in CORBAIDL and multiple implementations of this interface; one for each component DBMSs; namely;Oracle7; Sybase; Adabas D and MOOD are provided. MIND provides its users a commondata model and a single global query language based on SQL. The main components ofMIND are a global query manager; a global transaction manager; a schema integrator;interfaces to supported database systems and a graphical user interface. The integration ofexport schemas is currently performed by using an object de nition language (ODL) which …,*,*,*
Massive-Scale Analytics,A Soffer; P Malik; AN Ghoting; JA Gunnels; P Kambadur; EP Pednault; MS Squillante; HP Hofstee; GC Chen; FH Gebara; K Hall; J Herring; D Jamsek; J Li; Y Li; JW Shi; PWY Wong; A Balmin; K Beyer; V Ercegovac; J McPherson; F Ozcan; H Pirahesh; E Shekita; Y Sismanis; S Tata; Y Tian; R Jain; P Sarkar; D Subhraveti; LL Fong; Y Gao; XR Guerin; YG Liu; T Salo; SR Seelam; W Tan,BBig Data [refers to large data sets that are beyond the capability of traditional software toolsto quickly manage; process; and analyze. The development of techniques for gaining insightfrom such information provides potential benefits in such arenas as business; science; andpublic policy. This special issue of the IBM Journal emphasizes applications; analytics;software; and hardware technologies that form the foundational building blocks for massive-scale analytics and the processing of Big Data.,*,*,*
Bulletin of the Technical Committee on,Fatma Ozcan; Sena Nural; Pinar Koksal; Mehmet Altinel; Asuman Dogac,*,Urbana,*,*
METU Interoperable Database System,Asuman Dogac Ugur Halici Ebru Kilic; Gokhan Ozhan; Fatma Ozcan; Sena Nural Cevdet Dengi Sema Mancuhan; Budak Arpinar Pinar Koksal; Cem Evrendilek,*,*,*,*
