Structured databases on the web: Observations and implications,Kevin Chen-Chuan Chang; Bin He; Chengkai Li; Mitesh Patel; Zhen Zhang,Abstract The Web has been rapidly" deepened" by the prevalence of databases online. Withthe potentially unlimited information hidden behind their query interfaces; this" deep Web" ofsearchable databses is clearly an important frontier for data access. This paper surveys thisrelatively unexplored frontier; measuring characteristics pertinent to both exploring andintegrating structured Web sources. On one hand; our" macro" study surveys the deep Webat large; in April 2004; adopting the random IP-sampling approach; with one millionsamples.(How large is the deep Web? How is it covered by current directory services?) Onthe other hand; our" micro" study surveys source-specific characteristics over 441 sources ineight representative domains; in December 2002.(How" hidden" are deep-Web sources?How do search engines cover their data? How complex and expressive are query forms?) …,ACM sigmod record,2004,563
Top-k query processing in uncertain databases,Mohamed A Soliman; Ihab F Ilyas; Kevin Chen-Chuan Chang,Top-k processing in uncertain databases is semantically and computationally different fromtraditional top-k processing. The interplay between score and uncertainty makes traditionaltechniques inapplicable. We introduce new probabilistic formulations for top-k queries. Ourformulations are based on" marriage" of traditional top-k semantics and possible worldssemantics. In the light of these formulations; we construct a framework that encapsulates astate space model and efficient query processing techniques to tackle the challenges ofuncertain data settings. We prove that our techniques are optimal in terms of the number ofaccessed tuples and materialized search states. Our experiments show the efficiency of ourtechniques under different data distributions with orders of magnitude improvement overnaive materialization of possible worlds.,Data Engineering; 2007. ICDE 2007. IEEE 23rd International Conference on,2007,484
Accessing the deep web,Bin He; Mitesh Patel; Zhen Zhang; Kevin Chen-Chuan Chang,Page 1. ACCESSIN DEEP WEB Attem that 94 May 2007/Vol. 50; No. 5 COMMUNICATIONS OFTHE ACM Page 2. COMMUNICATIONS OF THE ACM May 2007/Vol. 50; No. 5 95 The Web hasbeen rapidly “deepened” by massive databases online and current search engines do not reachmost of the data on the Internet [4]. While the surface Web has linked billions of static HTML pages;a far more significant amount of information is believed to be “hidden” in the deep Web; behindthe query forms of searchable databases; as Figure 1(a) conceptually illustrates. Such informationmay not be accessible through static URL links because they are assembled into Web pagesas responses to queries submitted through the query interface of an underlying database. Becausecurrent search engines cannot effectively crawl databases; such data remains …,Communications of the ACM,2007,443
Statistical schema matching across web query interfaces,Bin He; Kevin Chen-Chuan Chang,Abstract Schema matching is a critical problem for integrating heterogeneous informationsources. Traditionally; the problem of matching multiple schemas has essentially relied onfinding pairwise-attribute correspondence. This paper proposes a different approach;motivated by integrating large numbers of data sources on the Internet. On this" deep Web;"we observe two distinguishing characteristics that offer a new view for considering schemamatching: First; as the Web scales; there are ample sources that provide structuredinformation in the same domains (eg; books and automobiles). Second; while sourcesproliferate; their aggregate schema vocabulary tends to converge at a relatively small size.Motivated by these observations; we propose a new paradigm; statistical schema matching:Unlike traditional approaches using pairwise-attribute correspondence; we take a holistic …,Proceedings of the 2003 ACM SIGMOD international conference on Management of data,2003,412
The Stanford digital library metadata architecture,Michelle Baldonado; Chen-Chuan K Chang; Luis Gravano; Andreas Paepcke,Abstract. The overall goal of the Stanford Digital Library project is to provide an infrastructurethat affords interoperability among heterogeneous; autonomous digital library services.These services include both search services and remotely usable information processingfacilities. In this paper; we survey and categorize the metadata required for a diverse set ofStanford Digital Library services that we have built. We then propose an extensible metadataarchitecture that meets these requirements. Our metadata architecture fits into ourestablished infrastructure and promotes interoperability among existing and de-factometadata standards. Several pieces of this architecture are implemented; others are underconstruction. The architecture includes attribute model proxies; attribute model translationservices; metadata information facilities for search services; and local metadata …,International Journal on Digital Libraries,1997,376
STARTS: Stanford proposal for Internet meta-searching,Luis Gravano; Chen-Chuan K Chang; Héctor García-Molina; Andreas Paepcke,Abstract Document sources are available everywhere; both within the internal networks oforganizations and on the Internet. Even individual organizations use search engines fromdifferent vendors to index their internal document collections. These search engines aretypically incompatible in that they support different query models and interfaces; they do notreturn enough information with the query results for adequate merging of the results; andfinally; in that they do not export metadata about the collections that they index (eg; to assistin resource discovery). This paper describes STARTS; an emerging protocol for Internetretrieval and search that facilitates the task of querying multiple document sources. STARTShas been developed in a unique way. It is not a standard; but a group effort coordinated byStanford's Digital Library project; and involving over 11 companies and organizations …,ACM SIGMOD Record,1997,360
Minimal probing: supporting expensive predicates for top-k queries,Kevin Chen-Chuan Chang; Seung-won Hwang,Abstract This paper addresses the problem of evaluating ranked top-k queries withexpensive predicates. As major DBMSs now all support expensive user-defined predicatesfor Boolean queries; we believe such support for ranked queries will be even moreimportant: First ranked queries often need to model user-specific concepts of preference;relevance; or similarity; which call for dynamic user-defined functions. Second; middlewaresystems must incorporate external predicates for integrating autonomous sources typicallyaccessible only by per-object queries. Third; fuzzy joins are inherently expensive; as theyare essentially user-defined operations that dynamically associate multiple relations. Thesepredicates; being dynamically defined or externally accessed; cannot rely on indexmechanisms to provide zero-time sorted output; and must instead require per-object …,Proceedings of the 2002 ACM SIGMOD international conference on Management of data,2002,342
RankSQL: query algebra and optimization for relational top-k queries,Chengkai Li; Kevin Chen-Chuan Chang; Ihab F Ilyas; Sumin Song,Abstract This paper introduces RankSQL; a system that provides a systematic and principledframework to support efficient evaluations of ranking (top-k) queries in relational databasesystems (RDBMS); by extending relational algebra and query optimization. Previously; top-kquery processing is studied in the middleware scenario or in RDBMS in a" piecemeal"fashion; ie; focusing on specific operator or sitting outside the core of query engines. Incontrast; we aim to support ranking as a first-class database construct. As a key insight; thenew ranking relationship can be viewed as another logical property of data; parallel to the"membership" property of relational data model. While membership is essentially supportedin RDBMS; the same support for ranking is clearly lacking. We address the fundamentalintegration of ranking in RDBMS in a way similar to how membership; ie; Boolean filtering …,Proceedings of the 2005 ACM SIGMOD international conference on Management of data,2005,308
Tedas: A twitter-based event detection and analysis system,Rui Li; Kin Hou Lei; Ravi Khadiwala; Kevin Chen-Chuan Chang,Witnessing the emergence of Twitter; we propose a Twitter-based Event Detection andAnalysis System (TEDAS); which helps to (1) detect new events; to (2) analyze the spatialand temporal pattern of an event; and to (3) identify importance of events. In thisdemonstration; we show the overall system architecture; explain in detail the implementationof the components that crawl; classify; and rank tweets and extract location from tweets; andpresent some interesting results of our system.,Data engineering (icde); 2012 ieee 28th international conference on,2012,306
PEBL: positive example based learning for web page classification using SVM,Hwanjo Yu; Jiawei Han; Kevin Chen-Chuan Chang,Abstract Web page classification is one of the essential techniques for Web mining.Specifically; classifying Web pages of a user-interesting class is the first step of mininginteresting information from the Web. However; constructing a classifier for an interestingclass requires laborious pre-processing such as collecting positive and negative trainingexamples. For instance; in order to construct a" homepage" classifier; one needs to collect asample of homepages (positive examples) and a sample of non-homepages (negativeexamples). In particular; collecting negative training examples requires arduous work andspecial caution to avoid biasing them. We introduce in this paper the Positive ExampleBased Learning (PEBL) framework for Web page classification which eliminates the need formanually collecting negative training examples in pre-processing. We present an …,Proceedings of the eighth ACM SIGKDD international conference on Knowledge discovery and data mining,2002,285
Optimal multimodal fusion for multimedia data analysis,John R Smith Yi Wu; Edward Y Chang; Kevin Chen-Chuan Chang,Abstract Considerable research has been devoted to utilizing multimodal features for betterunderstanding multimedia data. However; two core research issues have not yet beenadequately addressed. First; given a set of features extracted from multiple media sources(eg; extracted from the visual; audio; and caption track of videos); how do we determine thebest modalities? Second; once a set of modalities has been identified; how do we best fusethem to map to semantics? In this paper; we propose a two-step approach. The first stepfinds< i> statistically independent modalities</i> from raw features. In the second step; weuse< i> super-kernel fusion</i> to determine the optimal combination of individualmodalities. We carefully analyze the tradeoffs between three design factors that affect fusionperformance:< i> modality independence</i>;< i> curse of dimensionality</i>; and< i> …,Proceedings of the 12th annual ACM international conference on Multimedia,2004,267
Understanding web query interfaces: Best-effort parsing with hidden syntax,Zhen Zhang; Bin He; Kevin Chen-Chuan Chang,Abstract Recently; the Web has been rapidly" deepened" by many searchable databasesonline; where data are hidden behind query forms. For modelling and integrating Webdatabases; the very first challenge is to understand what a query interface says-or whatquery capabilities a source supports. Such automatic extraction of interface semantics ischallenging; as query forms are created autonomously. Our approach builds on theobservation that; across myriad sources; query forms seem to reveal some" concertedstructure;" by sharing common building blocks. Toward this insight; we hypothesize theexistence of a hidden syntax that guides the creation of query interfaces; albeit from differentsources. This hypothesis effectively transforms query interfaces into a visual language with anon-prescribed grammar-and; thus; their semantic understanding a parsing problem …,Proceedings of the 2004 ACM SIGMOD international conference on Management of data,2004,265
Toward Large Scale Integration: Building a MetaQuerier over Databases on the Web.,Kevin Chen-Chuan Chang; Bin He; Zhen Zhang,Abstract The Web has been rapidly “deepened” by myriad searchable databases online;where data are hidden behind query interfaces. Toward large scale integration over this“deep Web;” we have been building the MetaQuerier system–for both exploring (to find) andintegrating (to query) databases on the Web. As an interim report; first; this paper proposesour goal of the MetaQuerier for Web-scale integration–With its dynamic and ad-hoc nature;such large scale integration mandates both dynamic source discovery and on-thefly querytranslation. Second; we present the system architecture and underlying technology of keysubsystems in our ongoing implementation. Third; we discuss “lessons” learned to date;focusing on our efforts in system integration; for putting individual subsystems to functiontogether. On one hand; we observe that; across subsystems; the system integration of an …,CIDR,2005,260
PEBL: Web page classification without negative examples,Hwanjo Yu; Jiawei Han; KC-C Chang,Web page classification is one of the essential techniques for Web mining becauseclassifying Web pages of an interesting class is often the first step of mining the Web.However; constructing a classifier for an interesting class requires laborious preprocessingsuch as collecting positive and negative training examples. For instance; in order toconstruct a" homepage" classifier; one needs to collect a sample of homepages (positiveexamples) and a sample of nonhomepages (negative examples). In particular; collectingnegative training examples requires arduous work and caution to avoid bias. The paperpresents a framework; called positive example based learning (PEBL); for Web pageclassification which eliminates the need for manually collecting negative training examplesin preprocessing. The PEBL framework applies an algorithm; called mapping …,IEEE Transactions on Knowledge and Data Engineering,2004,260
Towards social user profiling: unified and discriminative influence model for inferring home locations,Rui Li; Shengjie Wang; Hongbo Deng; Rui Wang; Kevin Chen-Chuan Chang,Abstract Users' locations are important to many applications such as targeted advertisementand news recommendation. In this paper; we focus on the problem of profiling users' homelocations in the context of social network (Twitter). The problem is nontrivial; becausesignals; which may help to identify a user's location; are scarce and noisy. We propose aunified discriminative influence model; named as UDI; to solve the problem. To overcomethe challenge of scarce signals; UDI integrates signals observed from both social network(friends) and user-centric data (tweets) in a unified probabilistic framework. To overcome thechallenge of noisy signals; UDI captures how likely a user connects to a signal with respectto 1) the distance between the user and the signal; and 2) the influence scope of the signal.Based on the model; we develop local and global location prediction methods. The …,Proceedings of the 18th ACM SIGKDD international conference on Knowledge discovery and data mining,2012,243
Interoperability for digital libraries worldwide,Andreas Paepcke; Chen-Chuan K Chang; Terry Winograd; Héctor García-Molina,nteroperability has been a critical problem in the 1990s and will be for the foreseeablefuture; as the number of computer systems; information repositories; applications; and usersmultiplies at an explosive rate. It gets worse as system design and software productionbecome global activities in which; for example; the politics of local regions may dictate whichservices a component may provide or what data can be exchanged. Interoperability is also;by nature; an extremely complex and evolving problem. Although researchers have beenstruggling with interoperability for more than 20 years; it is often not clear what principleshave been established or key results have been obtained. Here we present a broadintroduction to the issues of interoperability; suggesting factors that may be used inevaluating related solutions and providing an overview of solution classes …,Communications of the ACM,1998,224
Interoperability for digital libraries worldwide,Héctor García-Molina Andreas Paepcke; Chen-Chuan K Chang; Terry Winograd,*,Communications of the ACM,1998,224
Data mining for web intelligence,Jiawei Han; KC-C Chang,Searching; comprehending; and using the semistructured HTML; XML; and database-service-engine information stored on the Web poses a significant challenge. This data ismore sophisticated and dynamic than the information commercial database systems store.To supplement keyword-based indexing; researchers have applied data mining to Web-page ranking. In this context; data mining helps Web search engines find high-quality Webpages and enhances Web click stream analysis. For the Web to reach its full potential;however; we must improve its services; make it more comprehensible; and increase itsusability. As researchers continue to develop data mining techniques; the authors believethis technology will play an increasingly important role in meeting the challenges ofdeveloping the intelligent Web. Ultimately; data mining for Web intelligence will make the …,Computer,2002,219
Discovering complex matchings across web query interfaces: a correlation mining approach,Bin He; Kevin Chen-Chuan Chang; Jiawei Han,Abstract To enable information integration; schema matching is a critical step for discoveringsemantic correspondences of attributes across heterogeneous sources. While complexmatchings are common; because of their far more complex search space; most existingtechniques focus on simple 1: 1 matchings. To tackle this challenge; this paper takes aconceptually novel approach by viewing schema matching as correlation mining; for our taskof matching Web query interfaces to integrate the myriad databases on the Internet. On this"deep Web;" query interfaces generally form complex matchings between attribute groups(eg;[author] corresponds to [first name; last name] in the Books domain). We observe that theco-occurrences patterns across query interfaces often reveal such complex semanticrelationships: grouping attributes (eg;[first name; last name]) tend to be co-present in …,Proceedings of the tenth ACM SIGKDD international conference on Knowledge discovery and data mining,2004,212
EntityRank: searching entities directly and holistically,Tao Cheng; Xifeng Yan; Kevin Chen-Chuan Chang,Abstract As the Web has evolved into a data-rich repository; with the standard" page view;"current search engines are becoming increasingly inadequate for a wide range of querytasks. While we often search for various data" entities"(eg; phone number; paper PDF; date);today's engines only take us indirectly to pages. While entities appear in many pages;current engines only find each page individually. Toward searching directly and holisticallyfor finding information of finer granularity; we study the problem of entity search; a significantdeparture from traditional document retrieval. We focus on the core challenge of rankingentities; by distilling its underlying conceptual model Impression Model and developing aprobabilistic ranking framework; EntityRank; that is able to seamlessly integrate both localand global information in ranking. We evaluate our online prototype over a 2TB Web …,Proceedings of the 33rd international conference on Very large data bases,2007,190
PowerBookmarks: a system for personalizable Web information organization; sharing; and management,Wen-Syan Li; Quoc Vu; Divakant Agrawal; Yoshinori Hara; Hajime Takano,Abstract We extend the notion of bookmark management by introducing the functionalities ofhypermedia databases. PowerBookmarks is a Web information organization; sharing; andmanagement tool; which parses metadata from bookmarked URLs and uses it to index andclassify the URLs. PowerBookmarks supports advanced query; classification; and navigationfunctionalities on collections of bookmarks. PowerBookmarks monitors and utilizes users'access patterns to provide many useful personalized services; such as automated URLbookmarking; document refreshing; and bookmark expiration. It also allows users to specifytheir preference in bookmark management; such as ranking schemes and classification treestructures. Subscription services for new or updated documents of users' interests are alsosupported.,Computer Networks,1999,185
Automatic complex schema matching across web query interfaces: A correlation mining approach,Bin He; Kevin Chen-Chuan Chang,Abstract To enable information integration; schema matching is a critical step for discoveringsemantic correspondences of attributes across heterogeneous sources. While complexmatchings are common; because of their far more complex search space; most existingtechniques focus on simple 1: 1 matchings. To tackle this challenge; this article takes aconceptually novel approach by viewing schema matching as correlation mining; for our taskof matching Web query interfaces to integrate the myriad databases on the Internet. On this“deep Web” query interfaces generally form complex matchings between attribute groups(eg;{author} corresponds to {first name; last name} in the Books domain). We observe thatthe co-occurrences patterns across query interfaces often reveal such complex semanticrelationships: grouping attributes (eg;{first name; last name}) tend to be co-present in …,ACM Transactions on Database Systems (TODS),2006,150
Special issue on web content mining,Bing Liu; Kevin Chen-Chuan-Chang,Abstract With the phenomenal growth of the Web; there is an everincreasing volume of dataand information published in numerous Web pages. The research in Web mining aims todevelop new techniques to effectively extract and mine useful knowledge or information fromthese Web pages [8]. Due to the heterogeneity and lack of structure of Web data; automateddiscovery of targeted or unexpected knowledge/information is a challenging task. It calls fornovel methods that draw from a wide range of fields spanning data mining; machinelearning; natural language processing; statistics; databases; and information retrieval. In thepast few years; there was a rapid expansion of activities in the Web mining field; whichconsists of Web usage mining; Web structure mining; and Web content mining. Web usagemining refers to the discovery of user access patterns from Web usage logs. Web …,Acm Sigkdd explorations newsletter,2004,140
Boolean query mapping across heterogeneous information sources,K Chen-Chuan Chang; Hector Garcia-Molina; Andreas Paepcke,Searching over heterogeneous information sources is difficult because of the nonuniformquery languages. Our approach is to allow a user to compose Boolean queries in one richfront end language. For each user query and target source; we transform the user query intoa subsuming query that can be supported by the source but that may return extradocuments. The results are then processed by a filter query to yield the correct final result.We introduce the architecture and associated algorithms for generating the supportedsubsuming queries and filters. We show that generated subsuming queries return a minimalnumber of documents; we also discuss how minimal cost filters can be obtained. We haveimplemented prototype versions of these algorithms and demonstrated them onheterogeneous Boolean systems.,IEEE Transactions on Knowledge and Data Engineering,1996,130
Efficient algorithms for layer assignment problem,KC Chang; DH-C Du,The layer assignment problem for interconnect is the problem of determining which layersshould be used for wiring the signal nets. The objective of the layer assignment problem ingeneral is to minimize the number of vias required. Thus; it is also referred to as the viaminimization problem. In a via minimization problem; if the topology of the given layout isfixed; the problem is referred to as a constrained via minimization (CVM) problem. On theother hand; if both the topology of the layout and the layer assignment are to be decided; it isreferred to as an unconstrained via minimization (UVM) problem. In this paper; both the CVMand UVM problems are studied. For the CVM problems; efficient algorithms which can beeasily modified to take extra constraints into consideration are proposed. Experimentalresults show that the proposed algorithms for the CVM problem are time efficient …,IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems,1987,121
Mind your vocabulary: Query mapping across heterogeneous information sources,Chen-Chuan K Chang; Hector Garcia-Molina,Abstract In this paper we present a mechanism for translating constraint queries; ie; Booleanexpressions of constraints; across heterogeneous information sources. Integrating suchsystems is difficult in part because they use a wide range of constraints as the vocabulary forformulating queries. We describe algorithms that apply user-provided mapping rules totranslate query constraints into ones that are understood and supported in another context;eg; that use the proper operators and value formats. We show that the translated queriesminimally subsume the original ones. Furthermore; the translated queries are also the mostcompact possible. Unlike other query mapping work; we effectively consider inter-dependencies among constraints; ie; we handle constraints that cannot be translatedindependently. Furthermore; when constraints are not fully supported; our framework …,ACM SIGMOD Record,1999,118
Organizing structured web sources by query schemas: a clustering approach,Bin He; Tao Tao; Kevin Chen-Chuan Chang,Abstract In the recent years; the Web has been rapidly" deepened" with the prevalence ofdatabases online. On this deep Web; many sources are< i> structured</i> by providingstructured query interfaces and results. Organizing such structured sources into a domainhierarchy is one of the critical steps toward the integration of heterogeneous Web sources.We observe that; for structured Web sources; query schemas< i> ie</i>; attributes in queryinterfaces) are discriminative representatives of the sources and thus can be exploited forsource characterization. In particular; by viewing query schemas as a type of categoricaldata; we abstract the problem of source organization into the clustering of categorical data.Our approach hypothesizes that" homogeneous sources" are characterized by the samehidden generative models for their schemas. To find clusters governed by such statistical …,Proceedings of the thirteenth ACM international conference on Information and knowledge management,2004,110
Entity Search Engine: Towards Agile Best-Effort Information Integration over the Web.,Tao Cheng; Kevin Chen-Chuan Chang,The immense scale and wide spread has rendered the Web as an ultimate informationrepository–as not only the sources where we find but also the destinations where we publishinformation. The dual forces have enriched the Web with all kinds of data; much beyond theconventional page view of the Web as a corpus of HTML pages; or “documents.” The Webhas thus become a rich collection of data-rich pages; on the “surface Web” of static URLs(eg; personal or company homepages) as well as the “deep Web” of database-backedcontents (eg; flights from aa. com); as Figure 1 (a) shows. The richness of data; while apromising opportunity; has challenged us to effectively find data we need; from one ormultiple sources. In particular; we are motivated by; when building the Meta-Querier atUIUC; the need of large scale on-the-fly integration for online structured data. The …,*,2007,100
Probabilistic top-k and ranking-aggregate queries,Mohamed A Soliman; Ihab F Ilyas; Kevin Chen--Chuan Chang,Abstract Ranking and aggregation queries are widely used in data exploration; dataanalysis; and decision-making scenarios. While most of the currently proposed ranking andaggregation techniques focus on deterministic data; several emerging applications involvedata that is unclean or uncertain. Ranking and aggregating uncertain (probabilistic) dataraises new challenges in query semantics and processing; making conventional methodsinapplicable. Furthermore; uncertainty imposes probability as a new ranking dimension thatdoes not exist in the traditional settings. In this article we introduce new probabilisticformulations for top-k and ranking-aggregate queries in probabilistic databases. Ourformulations are based on marriage of traditional top-k semantics with possible worldssemantics. In the light of these formulations; we construct a generic processing framework …,ACM Transactions on Database Systems (TODS),2008,83
Supporting ad-hoc ranking aggregates,Chengkai Li; Kevin Chen-Chuan Chang; Ihab F Ilyas,Abstract This paper presents a principled framework for efficient processing of ad-hoc top-k(ranking) aggregate queries; which provide the k groups with the highest aggregates asresults. Essential support of such queries is lacking in current systems; which process thequeries in a naïve materialize-group-sort scheme that can be prohibitively inefficient. Ourframework is based on three fundamental principles. The Upper-Bound Principle dictatesthe requirements of early pruning; and the Group-Ranking and Tuple-Ranking Principlesdictate group-ordering and tuple-ordering requirements. They together guide the queryprocessor toward a provably optimal tuple schedule for aggregate query processing. Wepropose a new execution framework to apply the principles and requirements. We addressthe challenges in realizing the framework and implementing new query operators …,Proceedings of the 2006 ACM SIGMOD international conference on Management of data,2006,82
Progressive and selective merge: computing top-k with ad-hoc ranking functions,Dong Xin; Jiawei Han; Kevin C Chang,Abstract The family of threshold algorithm (ie; TA) has been widely studied for efficientlycomputing top-k queries. TA uses a sort-merge framework that assumes data lists are pre-sorted; and the ranking functions are monotone. However; in many database applications;attribute values are indexed by tree-structured indices (eg; B-tree; R-tree); and the rankingfunctions are not necessarily monotone. To answer top-k queries with ad-hoc rankingfunctions; this paper studies anindex-merge paradigm that performs progressive search overthe space of joint states composed by multiple index nodes. We address two challenges forefficient query processing. First; to minimize the search complexity; we present a double-heap algorithm which supports not only progressive state search but also progressive stategeneration. Second; to avoid unnecessary disk access; we characterize a type of" empty …,Proceedings of the 2007 ACM SIGMOD international conference on Management of data,2007,81
Light-weight domain-based form assistant: querying web databases on the fly,Zhen Zhang; Bin He; Kevin Chen-Chuan Chang,Abstract The Web has been rapidly" deepened" by myriad searchable databases online;where data are hidden behind query forms. Helping users query alternative" deep Web"sources in the same domain (eg; Books; Airfares) is an important task with broadapplications. As a core component of those applications; dynamic query translation (ie;translating a user's query across dynamically selected sources) has not been extensivelyexplored. While existing works focus on isolated subproblems (eg; schema matching; queryrewriting) to study; we target at building a complete query translator and thus face newchallenges: 1) To complete the translator; we need to solve the predicate mapping problem(ie; map a source predicate to target predicates); which is largely unexplored by existingworks; 2) To satisfy our application requirements; we need to design a customizable …,Proceedings of the 31st international conference on Very large data bases,2005,75
Predicate rewriting for translating Boolean queries in a heterogeneous information system,Chen-Chuan K Chang; Hector Garcia-Molina; Andreas Paepcke,Abstract Searching over heterogeneous information sources is difficult in part because of thenonuniform query languages. Our approach is to allow users to compose Boolean queries inone rich front-end language. For each user query and target source; we transform the userquery into a subsuming query that can be supported by the source but that may return extradocuments. The results are then processed by a filter query to yield the correct final results.In this article we introduce the architecture and associated mechanism for query translation.In particular; we discuss techniques for rewriting predicates in Boolean queries into nativesubsuming forms; which is a basis of translating complex queries. In addition; we presentexperimental results for evaluating the cost of postfiltering. We also discuss the drawbacks ofthis approach and cases when it may not be effective. We have implemented prototype …,ACM Transactions on Information Systems (TOIS),1999,73
Using distributed objects to build the stanford digital library infobus,Andreas Paepcke; Michelle Q. Wang  Baldonado; C-CK Chang; Steve Cousins; Hector Garcia-Molina,For digital libraries to thrive; the providers of information processing services must be able toevolve their systems autonomously. However; as the complexity of their offerings increases;software tools more sophisticated than existing Web facilities are needed. Distributed objecttechnology may be the answer. The availability of high-volume; increasingly sophisticatedinformation is making the need for metadata facilities more urgent. Traditional; library-basedapproaches break down when used in an advanced digital library. More modularmechanisms are needed; and the CORBA system is one approach. Digital libraries areaffected at a deep technical level by the widely differing user traditions of Web users andlibrary patrons. The challenge and opportunity of digital libraries will be the synthesis ofthese traditions. The authors set out to create a technical infrastructure to support the …,Computer,1999,68
Metadata for digital libraries: Architecture and design rationale,Michelle Baldonado; Chen-Chuan K Chang; Luis Gravano; Andreas Paepcke,Abstract In a distributed; heterogeneous; proxy-based digital library; autonomous servicesand collections are accessed indirectly via proxies. To facilitate metadata compatibiity andinteroperabiity in such a digital library; we have designed a metadata architecture thatincludes four basic component classes: attribute model proxies; attribute model translators;metadata facilities for search proxies; and metadata repositories. Attribute model proxieselevate both attribute sets and the attributes they define to first-class objects. They also allowrelationships among attributes to be captured. Attribute model translators map attributes andattribute values from one attribute model to another (where possible). Metadata facilities forsearch proxies provide structured descriptions both of the collections to which the searchproxies provide access and of the search capabilities of the proxies. Finally; metadata …,Proceedings of the second ACM international conference on Digital libraries,1997,66
Making holistic schema matching robust: an ensemble approach,Bin He; Kevin Chen-Chuan Chang,Abstract The Web has been rapidly" deepened" by myriad searchable databases online;where data are hidden behind query interfaces. As an essential task toward integratingthese massive" deep Web" sources; large scale schema matching (ie; discovering semanticcorrespondences of attributes across many query interfaces) has been actively studiedrecently. In particular; many works have emerged to address this problem by" holistically"matching many schemas at the same time and thus pursuing" mining" approaches in nature.However; while holistic schema matching has built its promise upon the large quantity ofinput schemas; it also suffers the robustness problem caused by noisy data quality. Suchnoises often inevitably arise in the automatic extraction of schema data; which is mandatoryin large scale integration. For holistic matching to be viable; it is thus essential to make it …,Proceedings of the eleventh ACM SIGKDD international conference on Knowledge discovery in data mining,2005,59
Multiple location profiling for users and relationships from social network and content,Rui Li; Shengjie Wang; Kevin Chen-Chuan Chang,Abstract Users' locations are important for many applications such as personalized searchand localized content delivery. In this paper; we study the problem of profiling Twitter users'locations with their following network and tweets. We propose a multiple location profilingmodel (MLP); which has three key features: 1) it formally models how likely a user followsanother user given their locations and how likely a user tweets a venue given his location; 2)it fundamentally captures that a user has multiple locations and his following relationshipsand tweeted venues can be related to any of his locations; and some of them are even noisy;and 3) it novelly utilizes the home locations of some users as partial supervision. As a result;MLP not only discovers users' locations accurately and completely; but also" explains" eachfollowing relationship by revealing users' true locations in the relationship. Experiments …,Proceedings of the VLDB Endowment,2012,58
Boolean+ ranking: querying a database by k-constrained optimization,Zhen Zhang; Seung-won Hwang; Kevin Chen-Chuan Chang; Min Wang; Christian A Lang; Yuan-chi Chang,Abstract The wide spread of databases for managing structured data; compounded with theexpanded reach of the Internet; has brought forward interesting data retrieval and analysisscenarios to RDBMS. In such settings; queries often take the form of k-constrainedoptimization; with a Boolean constraint and a numeric optimization expression as the goalfunction; retrieving only the top-k tuples. This paper proposes the concept of supporting suchqueries; as their nature implies; by a functional optimization machinery over the searchspace of multiple indices. To realize this concept; we combine the dual perspectives ofdiscrete state search (from the view of indices) and continuous function optimization (fromthe view of goal functions). We present; as the marriage of the two perspectives; the OPT*framework; which encodes k-constrained optimization as an A* search over the …,Proceedings of the 2006 ACM SIGMOD international conference on Management of data,2006,54
User profiling in an ego network: co-profiling attributes and relationships,Rui Li; Chi Wang; Kevin Chen-Chuan Chang,Abstract User attributes; such as occupation; education; and location; are important for manyapplications. In this paper; we study the problem of profiling user attributes in social network.To capture the correlation between attributes and social connections; we present a newinsight that social connections are discriminatively correlated with attributes via a hiddenfactor--relationship type. For example; a user's colleagues are more likely to share the sameemployer with him than other friends. Based on the insight; we propose to co-profile users'attributes and relationship types of their connections. To achieve co-profiling; we develop anefficient algorithm based on an optimization framework. Our algorithm captures our insighteffectively. It iteratively profiles attributes by propagation via certain types of connections;and profiles types of connections based on attributes and the network structure. We …,Proceedings of the 23rd international conference on World wide web,2014,52
Towards rich query interpretation: walking back and forth for mining query templates,Ganesh Agarwal; Govind Kabra; Kevin Chen-Chuan Chang,Abstract We propose to mine structured query templates from search logs; for enabling richquery interpretation that recognizes both query intents and associated attributes. Weformalize the notion of template as a sequence of keywords and domain attributes; and ourobjective is to discover templates with high precision and recall for matching queries in adomain of interest. Our solution bootstraps from small seed input knowledge to discoverrelevant query templates; by harnessing the wealth of information available in search logs.We model this information in a tri-partite QueST network of queries; sites; and templates. Wepropose a probabilistic inferencing framework based on the dual metrics of precision andrecall-and we show that the dual inferencing correspond respectively to the random walks inbackward and forward directions. We deployed and tested our algorithm over a real-world …,Proceedings of the 19th international conference on World wide web,2010,50
Context-aware wrapping: synchronized data extraction,Shui-Lung Chuang; Kevin Chen-Chuan Chang; ChengXiang Zhai,Abstract The deep Web presents a pressing need for integrating large numbers ofdynamically evolving data sources. To be more automatic yet accurate in building anintegration system; we observe two problems: First; across sequential tasks in integration;how can a wrapper (as an extraction task) consider the peer sources to facilitate thesubsequent matching task? Second; across parallel sources; how can a wrapper leveragethe peer wrappers or domain rules to enhance extraction accuracy? These issues; whileseemingly unrelated; both boil down to the lack of" context awareness": Current automaticwrapper induction approaches generate a wrapper for one source at a time; in isolation; andthus inherently lack the awareness of the peer sources or domain knowledge in the contextof integration. We propose the concept of context-aware wrappers that are amenable to …,Proceedings of the 33rd international conference on Very large data bases,2007,49
The UIUC web integration repository,Kevin Chen-Chuan Chang; Bin He; Chengkai Li; Zhen Zhang,*,Computer Science Department; University of Illinois at Urbana-Champaign. http://metaquerier. cs. uiuc. edu/repository,2003,49
Supporting ranking and clustering as generalized order-by and group-by,Chengkai Li; Min Wang; Lipyeow Lim; Haixun Wang; Kevin Chen-Chuan Chang,Abstract The Boolean semantics of SQL queries cannot adequately capture the" fuzzy"preferences and" soft" criteria required in non-traditional data retrieval applications. One wayto solve this problem is to add a flavor of" information retrieval" into database queries byallowing fuzzy query conditions and flexibly supporting grouping and ranking of the queryresults within the DBMS engine. While ranking is already supported by all major commercialDBMSs natively; support of flexibly grouping is still very limited (ie; group-by). In this paper;we propose to generalize group-by to enable flexible grouping (clustering specifically) of thequery results. Different from clustering in data mining applications; our focus is on supportingefficient clustering of Boolean results generated at query time. Moreover; we propose tointegrate ranking and clustering with Boolean conditions; forming a new type of …,Proceedings of the 2007 ACM SIGMOD international conference on Management of data,2007,47
Clustering structured web sources: A schema-based; model-differentiation approach,Bin He; Tao Tao; Kevin Chen-Chuan Chang,Abstract The Web has been rapidly “deepened” with the prevalence of databases online. Onthis “deep Web;” numerous sources are structured; providing schema-rich data. Theirschemas define the object domain and its query capabilities. This paper proposes clusteringsources by their query schemas; which is critical for enabling both source selection andquery mediation; by organizing sources of with similar query capabilities. In abstraction; thisproblem is essentially clustering categorical data (by viewing each query schema as atransaction). Our approach hypothesizes that “homogeneous sources” are characterized bythe same hidden generative models for their schemas. To find clusters governed by suchstatistical distributions; we propose a novel objective function; model-differentiation; whichemploys principled hypothesis testing to maximize statistical heterogeneity among …,International Conference on Extending Database Technology,2004,47
Accessing the web: from search to integration,Kevin Chen-Chuan Chang; Junghoo Cho,Abstract We have witnessed the rapid growth of the Web--It has not only" broadened" butalso" deepened": While the" surface Web" has expanded from the 1999 estimate of 800million to the recent 19.2 billion pages reported by Yahoo index; an equally or even moresignificant amount of information is hidden on the" deep Web;" behind query forms; recentlyestimated at over 1.2 million; of online databases. Accessing the information on the Webthus requires not only search to locate pages of interests; from the surface Web; but alsointegration to aggregate data from alternative or complementary sources; from the deepWeb. Although the opportunities are unprecedented; the challenges are also immense: Onthe one hand; for the surface Web; while search seems to have evolved into a standardtechnology; its maturity and pervasiveness have also invited the attack of spam and the …,Proceedings of the 2006 ACM SIGMOD international conference on Management of data,2006,43
Metaquerier: querying structured web sources on-the-fly,Bin He; Zhen Zhang; Kevin Chen-Chuan Chang,Abstract Recently; we witness the rapid growth and thus the prevalence of databases on theWeb. Our recent survey [2] in April 2004 estimated 450;000 online databases. On this deepWeb; myriad online databases provide dynamic query-based data access through theirquery interfaces; instead of static URL links. As the door to the deep Web; it is essential tointegrate these query interfaces for integrating the deep Web.,Proceedings of the 2005 ACM SIGMOD international conference on Management of data,2005,43
A holistic paradigm for large scale schema matching,Bin He; Kevin Chen-Chuan Chang,Abstract Schema matching is a critical problem for integrating heterogeneous informationsources. Traditionally; the problem of matching multiple schemas has essentially relied onfinding pairwise-attribute correspondences in isolation. In contrast; we propose a newmatching paradigm; holistic schema matching; to match many schemas at the same timeand find all matchings at once. By handling a set of schemas together; we can explore theircontext information that reflects the semantic correspondences among attributes. Suchinformation is not available when schemas are matched only in pairs. As the realizations ofholistic schema matching; we develop two alternative approaches: global evaluation andlocal evaluation. Global evaluation exhaustively assesses all possible" models;" where amodel expresses all attribute matchings. In particular; we propose the MGS framework for …,ACM SIGMOD Record,2004,42
Knocking the door to the deep web: Integrating web query interfaces,Bin He; Zhen Zhang; Kevin Chen-Chuan Chang,Recently; we witness the rapid growth and thus the prevalence of databases on the Web.Our recent survey [2] in December 2002 estimated between 127;000 to 330;000 deep Websources. On this deep Web; myriad online databases provide dynamic query-based dataaccess through their query interfaces; instead of static URL links. As the “door” to the deepWeb; it is essential to integrate these query interfaces for integrating the deep Web. Theoverall goal of the MetaQuerier project (http://metaquerier.-cs. uiuc. edu) aims at opening upthe deep Web to users; by building a system to help users exploring and integrating deepWeb sources. In particular; to start with; we focus on the integration of deep Web sources inthe same domain (eg; Books; Airfares); which is itself an important integration task. Thetypical scenarios include purchasing a book with lowest price among book sources and a …,Proceedings of the 2004 ACM SIGMOD international conference on Management of Data,2004,42
Supporting entity search: a large-scale prototype search engine,Tao Cheng; Xifeng Yan; Kevin Chen-Chuan Chang,Abstract As the Web has evolved into a data-rich repository; with the standard page view;"current search engines are increasingly inadequate. While we often search for various data"entities"(eg phone number; paper PDF; date); today's engines only take us indirectly topages. Therefore; we propose the concept of entity search; a significant departure fromtraditional document retrieval. Towards our goal of supporting entity search; in the WISDMproject at UIUC we build and evaluate our prototype search engine over a 2TB Web corpus.Our demonstration shows the feasibility and promise of a large-scale system architecture tosupport entity search.,Proceedings of the 2007 ACM SIGMOD international conference on Management of data,2007,38
Optimizing top-k queries for middleware access: A unified cost-based approach,Seung-won Hwang; Kevin Chen-chuan Chang,Abstract This article studies optimizing top-k queries in middlewares. While many assortedalgorithms have been proposed; none is generally applicable to a wide range of possiblescenarios. Existing algorithms lack both the “generality” to support a wide range of accessscenarios and the systematic “adaptivity” to account for runtime specifics. To fulfill this criticallacking; we aim at taking a cost-based optimization approach: By runtime search over aspace of algorithms; cost-based optimization is general across a wide range of accessscenarios; yet adaptive to the specific access costs at runtime. While such optimization hasbeen taken for granted for relational queries from early on; it has been clearly lacking forranked queries. In this article; we thus identify and address the barriers of realizing such aunified framework. As the first barrier; we need to define a “comprehensive” space …,ACM Transactions on Database Systems (TODS),2007,38
Searching patterns for relation extraction over the web: rediscovering the pattern-relation duality,Yuan Fang; Kevin Chen-Chuan Chang,Abstract While tuple extraction for a given relation has been an active research area; its dualproblem of pattern search--to find and rank patterns in a principled way--has not beenstudied explicitly. In this paper; we propose and address the problem of pattern search; inaddition to tuple extraction. As our objectives; we stress reusability for pattern search andscalability of tuple extraction; such that our approach can be applied to very large corporalike the Web. As the key foundation; we propose a conceptual model PRDualRank tocapture the notion of precision and recall for both tuples and patterns in a principled way;leading to the" rediscovery" of the Pattern-Relation Duality--the formal quantification of thereinforcement between patterns and tuples with the metrics of precision and recall. We alsodevelop a concrete framework for PRDualRank; guided by the principles of a perfect …,Proceedings of the fourth ACM international conference on Web search and data mining,2011,36
Approximate query mapping: Accounting for translation closeness,Kevin Chen-Chuan Chang; Héctor García-Molina,Abstract In this paper we present a mechanism for approximately translating Boolean queryconstraints across heterogeneous information sources. Achieving the best translation ischallenging because sources support different constraints for formulating queries; and oftenthese constraints cannot be precisely translated. For instance; a query [score> 8] might be“perfectly” translated as [rating> 0.8] at some site; but can only be approximated as [grade=A] at another. Unlike other work; our general framework adopts a customizable “closeness”metric for the translation that combines both precision and recall. Our results show that forquery translation we need to handle interdependencies among both query conjuncts as wellas disjuncts. As the basis; we identify the essential requirements of a rule system for users toencode the mappings for atomic semantic units. Our algorithm then translates complex …,The VLDB Journal—The International Journal on Very Large Data Bases,2001,35
Conjunctive constraint mapping for data translation,Chen-Chuan K Chang; Hector Garcia-Molina,ABSTRACT In this paper we present a mechanism for translating information inheterogeneous digital library environments. We model information as a set of con; junctiveconstraints that arc satisfied by real-world objects (eg; documents; their metadata). Throughapplication of semantic rules and value transformation functions; constraints arc mappedinto ones undcrstood and supported in another context. Our machinery can also deal withhierarchically structured information.,Proceedings of the third ACM conference on Digital libraries,1998,35
Towards social data platform: Automatic topic-focused monitor for twitter stream,Rui Li; Shengjie Wang; Kevin Chen-Chuan Chang,Abstract Many novel applications have been built based on analyzing tweets about specifictopics. While these applications provide different kinds of analysis; they share a commontask of monitoring" target" tweets from the Twitter stream for a topic. The current solution forthis task tracks a set of manually selected keywords with Twitter APIs. Obviously; this manualapproach has many limitations. In this paper; we propose a data platform to automaticallymonitor target tweets from the Twitter stream for any given topic. To monitor target tweets inan optimal and continuous way; we design Automatic Topic-focused Monitor (ATM); whichiteratively 1) samples tweets from the stream and 2) selects keywords to track based on thesamples. To realize ATM; we develop a tweet sampling algorithm to sample sufficientunbiased tweets with available Twitter APIs; and a keyword selection algorithm to …,Proceedings of the VLDB Endowment,2013,34
Query routing: Finding ways in the maze of the DeepWeb,Govind Kabra; Chengkai Li; Kevin Chen-Chuan Chang,This paper presents a source selection system based on attribute co-occurrence frameworkfor ranking and selecting Deep Web sources that provide information relevant to usersrequirement. Given the huge number of heterogeneous Deep Web data sources; the endusers may not know the sources that can satisfy their information needs. Selecting andranking sources in relevance to the user requirements is challenging. Our system findsappropriate sources for such users by allowing them to input just an imprecise initial query.As a key insight; we observe that the semantics and relationships between deep Websources are self-revealing through their query interfaces; and in essence; through the co-occurrences between attributes. Based on this insight; we design a co-occurrence basedattribute graph for capturing the relevances of attributes; and using them in ranking of …,Web Information Retrieval and Integration; 2005. WIRI'05. Proceedings. International Workshop on Challenges in,2005,34
Approximate query translation across heterogeneous information sources,Chen-Chuan K Chang; Hector Garcia-Molina,Abstract In this paper we present a mechanism for approximately translating Boolean queryconstraints across heterogeneous information sources. Achieving the best translation ischallenging because sources support different constraints for formulating queries; and oftenthese constraints cannot be precisely translated. For instance; a query [score 8] might be“perfectly” translated as [rating 0.8] at some site; but can only be approximated as [grade= A]at another. Unlike other work; our general framework adopts a customizable “closeness”metric for the translation that combines both precision and recall. Our results show that forquery translation we need to handle interdependencies among both query conjuncts as wellas disjuncts. As the basis; we identify the essential requirements of a rule system for users toencode the mappings for atomic semantic units. Our algorithm then translates complex …,architecture,1999,34
Metaquerier over the deep web: Shallow integration across holistic sources,Kevin Chen-Chuan Chang; Bin He; Zhen Zhang,Abstract The Web has been rapidly “deepened” by myriad searchable databases online. Toenable effective access to the “deep Web;” we are building the MetaQuerier–for exploringand integrating databases on the Web. Such metaquerying must tackle integration at a largescale (as sources are proliferating online) and of a dynamic nature (as each query willaccess different sources). Toward such integration; our approach hinges on the insight thatthe challenge of large scale is itself an opportunity: We observe that the desired “semantics”often connects to surface presentation characteristics; through some hidden regularities overmany sources. Generalizing our recent works; this paper thus proposes our approach ofshallow integration across holistic sources–to discover desired semantics by exploiting thehidden regularities of shallow clues across many sources holistically. As evidences; we …,In Proceedings of the VLDB Workshop on Information Integration on the Web,2004,33
Method and System for Extracting Web Query Interfaces,*,A computer program product being embodied on a computer readable medium for extractingsemantic information about a plurality of documents being accessible via a computernetwork; the computer program product including computer-executable instructions for:generating a plurality of tokens from at least one of the documents; each token beingindicative of a displayed item and a corresponding position; and; constructing at least oneparse tree indicative of a semantic structure of the at least one document from the tokensdependently upon a grammar being indicative of presentation conventions.,*,2010,31
The Stanford InfoBus and its service layers: Augmenting the Internet with higher-level information management protocols,Martin Röscheisen; Michelle Baldonado; Kevin Chang; Luis Gravano; Steven Ketchpel; Andreas Paepcke,Abstract The Stanford InfoBus is a prototype infrastructure developed as part of the StanfordDigital Libraries Project to extend the current Internet protocols with a suite of higher-levelinformation management protocols. This paper surveys the five service layers provided bythe Stanford InfoBus: protocols for managing items and collections (DLIOP); metadata(SMA); search (STARTS); payment (UPAI); and rights and obligations (FIRM).,*,1998,31
Method and apparatus for organizing data sources,*,A method for organizing deep Web services is provided. In one aspect; the method obtains acollection of sources and their associated attributes and/or input modes; for instance; using acrawling algorithm. The method uses this information to organize the sources intocommunities. A mining algorithm such as the hyperclique mining algorithm is used to obtaincliques of highly correlated attributes. A clustering algorithm such as the hierarchicalagglomerative clustering algorithm is used to further cluster the cliques of attributes intolarger cliques; which in the present disclosure is referred to as signatures. The sources thatare associated with each signature form a community and a graph representation of thecommunities is constructed; where the vertices are communities and the edges are theshared attributes.,*,2009,28
Enabling soft queries for data retrieval,Hwanjo Yu; Seung-won Hwang; Kevin Chen-Chuan Chang,Abstract Data retrieval finding relevant data from large databases—has become a seriousproblem as myriad databases have been brought online in the Web. For instance; queryingthe for-sale houses in Chicago from realtor. com returns thousands of matching houses.Similarly; querying “digital camera” in froogle. com returns hundreds of thousand of results.This data retrieval is essentially an online ranking problem; ie; ranking data resultsaccording to the user's preference effectively and efficiently. This paper proposes a new rankquery framework; for effectively incorporating “user-friendly” rank-query formulation into“data base (DB)-friendly” rank-query processing; in order to enable “soft” queries ondatabases. Our framework assumes; as the “back-end;” the score-based ranking model forexpressive and efficient query processing. On top of the score-based model; as the “front …,Information Systems,2007,27
RankSQL: supporting ranking queries in relational database management systems,Chengkai Li; Mohamed A Soliman; Kevin Chen-Chuan Chang; Ihab F Ilyas,Abstract Ranking queries (or top-k queries) are dominant in many emerging applications;eg; similarity queries in multimedia databases; searching Web databases; middleware; anddata mining. The increasing importance of top-k queries warrants an efficient support ofranking in the relational database management system (RDBMS) and has recently gainedthe attention of the research community. Top-k queries aim at providing only the top k queryresults; according to a user-specified ranking function; which in many cases is an aggregateof multiple criteria. The following is an example top-k query.,Proceedings of the 31st international conference on Very large data bases,2005,27
Probe minimization by schedule optimization: Supporting top-k queries with expensive predicates,Seung-won Hwang; Kevin Chen-Chuan Chang,This paper addresses the problem of evaluating ranked top-k queries with expensivepredicates. As major DBMSs now all support expensive user-defined predicates for Booleanqueries; we believe such support for ranked queries can be even more important: first;ranked queries often need to model user-specific concepts of preference; relevance; orsimilarity; which call for dynamic user-defined functions. Second; middleware systems mustincorporate external predicates for integrating autonomous sources typically accessible onlyby per-object queries. Third; ranked queries often accompany Boolean ranking conditions;which may turn predicates into expensive ones; as the index structure on the predicate builton the base table may be no longer effective in retrieving the filtered objects in order. Fourth;fuzzy joins are inherently expensive; as they are essentially user-defined operations that …,IEEE Transactions on Knowledge and Data Engineering,2007,26
Optimizing access cost for top-k queries over Web sources: A unified cost-based approach,Seung-won Hwang; KC-C Chang,We study the problem of supporting ranked queries in middleware environments; wherequeries are evaluated over multiple sources. In particular; we study Web middlewarescenarios; querying over various Web sources. To motivate; consider a Web" travel agent"scenario for finding restaurants and hotels.(We use this real scenario as" benchmark"queries for experiments as well). In particular; how to access sources with differentcapabilities and costs; to answer queries efficiently? As our Web middleware coordinatesvarious sources; each source access incurs network communication and servercomputation. This paper aims at optimizing such access; costs-which dominate the overallquery processing (like I/O in relational DBMS).,Data Engineering; 2005. ICDE 2005. Proceedings. 21st International Conference on,2005,26
URank: formulation and efficient evaluation of top-k queries in uncertain databases,Mohamed A Soliman; Ihab F Ilyas; Kevin Chen-Chuan Chang,Abstract Top-k processing in uncertain databases is semantically and computationallydifferent from traditional top-k processing. The interplay between query scores and datauncertainty makes traditional techniques inapplicable. We introduce URank; a system thatprocesses new probabilistic formulations of top-k queries inuncertain databases. The newformulations are based on marriage of traditional top-k semantics with possible worldssemantics. URank encapsulates a new processing framework that leverages existing queryprocessing capabilities; and implements efficient search strategies that integrate ranking onscores with ranking on probabilities; to obtain meaningful answers for top-k queries.,Proceedings of the 2007 ACM SIGMOD international conference on Management of data,2007,24
Rankfp: A framework for supporting rank formulation and processing,Hwanjo Yu; Seung-won Hwang; KC-C Chang,To enable ad-hoc ranking for data retrieval; we observe two major barriers: first; usability: ad-hoc ranking should be" user friendly"; for ordinary users to easily specify their rankingcriteria. Second; efficiency: ad-hoc ranking should be" database friendly"; to be amenable toefficient processing. This paper proposes a new framework such that: 1) to achieve usability;it allows users to qualitatively and intuitively express their preferences by partial orders onselected examples; from which it effectively learns a quantitative global ranking function; and(2) to achieve efficiency; it integrates the front-end machine learner with a back-end top-kquery processor to evaluate the learned functions. First; to support efficient queryprocessing; our framework assumes the score-based ranking model. Such a model is bothexpressive and amenable to efficient query processing.,Data Engineering; 2005. ICDE 2005. Proceedings. 21st International Conference on,2005,24
System for entity search and a method for entity scoring in a linked document database,*,A system has a processor coupled to access a document database that indexes keywordsand instances of entities having entity types in a plurality of documents. The processor isprogrammed to receive an input query including one or more keywords and one or moreentity types; and search the database for documents having the keywords and entities withthe entity types of the input query. The processor is programmed for aggregating arespective score for each of a plurality of entity tuples across the plurality of documents. Theaggregated scores are normalized. Each respective normalized score provides a ranking ofa respective entity tuple; relative to other entity tuples; as an answer to the input query. Theprocessor has an interface to a storage or display device or network for outputting a listincluding a subset of the entity tuples having the highest normalized scores among the …,*,2012,23
Mining semantics for large scale integration on the web: evidences; insights; and challenges,Kevin Chen-Chuan Chang; Bin He; Zhen Zhang,Abstract The Web has been rapidly" deepened"--with myriad searchable databases online;where data are hidden behind query interfaces. Toward large scale integration over this"deep Web;" we are facing a new challenge-With its dynamic and ad-hoc nature; such largescale integration mandates dynamic semantics discovery. That is; we must on-the-fly copewith" semantics" of dynamically discovered sources without pre-configured source-specificknowledge. To tackle this challenge; our initial works hinge on the insight that the largescale is itself also a unique opportunity: We observe that the desired" semantics" oftenconnects to surface presentation characteristics; through some hidden regularities overmany sources. Such regularities can be essentially leveraged in enabling semanticsdiscovery. In particular; we report our evidences in three initial tasks for integrating the …,ACM SIGKDD Explorations Newsletter,2004,23
Incremental and accuracy-aware personalized pagerank through scheduled approximation,Fanwei Zhu; Yuan Fang; Kevin Chen-Chuan Chang; Jing Ying,Abstract As Personalized PageRank has been widely leveraged for ranking on a graph; theefficient computation of Personalized PageRank Vector (PPV) becomes a prominent issue.In this paper; we propose FastPPV; an approximate PPV computation algorithm that isincremental and accuracy-aware. Our approach hinges on a novel paradigm of scheduledapproximation: the computation is partitioned and scheduled for processing in an"organized" way; such that we can gradually improve our PPV estimation in an incrementalmanner; and quantify the accuracy of our approximation at query time. Guided by thisprinciple; we develop an efficient hub based realization; where we adopt the metric of hub-length to partition and schedule random walk tours so that the approximation error reducesexponentially over iterations. Furthermore; as tours are segmented by hubs; the shared …,Proceedings of the VLDB Endowment,2013,21
Heterogeneous learner for Web page classification,Hwanjo Yu; KC-C Chang; Jiawei Han,Classification of an interesting class of Web pages has been an interesting problem. Typicalmachine learning algorithms for this problem require two classes of data for training: positiveand negative training examples. However in application to Web page classification;gathering an unbiased sample of negative examples appears to be difficult. We propose aheterogeneous learning framework for classifying Web pages; which (1) eliminates the needfor negative training data; and (2) increases classification accuracy by using twoheterogeneous learners. Our framework uses two heterogeneous learners-a decision listand a linear separator which complement each other-to eliminate the need for negativetraining data in the training phase and to increase the accuracy in the testing phase. Ourresults show that our heterogeneous framework achieves high accuracy without requiring …,Data Mining; 2002. ICDM 2003. Proceedings. 2002 IEEE International Conference on,2002,21
System; method and graphical user interface for managing contacts and calendars within an online card system,*,A system; method and graphical user interface (GUI) are described for managing a contactsand calendar database within an online stationery/card service. For example; a systemimplemented by an online stationery/card service allowing a user to personalize and sendnon-electronic stationery/cards is described; the system comprising: a graphical userinterface for personalizing and sending non-electronic stationery/cards comprising: areminder list comprised a plurality of reminder entries; each of the reminder entriesidentifying an upcoming event including events generated based on a specified relationshipbetween the user and one or more contacts stored in a contacts database of the user; arecommendation region comprising a plurality of stationery/card design recommendations;the recommendation region populated with stationery/card designs associated with a …,*,2012,20
Beyond pages: supporting efficient; scalable entity search with dual-inversion index,Tao Cheng; Kevin Chen-Chuan Chang,Abstract Entity search; a significant departure from page-based retrieval; finds data; ie;entities; embedded in documents directly and holistically across the whole collection. Thispaper aims at distilling and abstracting the essential computation requirements of entitysearch. From the dual views of reasoning--entity as input and entity as output; we propose adual-inversion framework; with two indexing and partition schemes; towards efficient andscalable query processing. We systematically evaluate our framework using a prototypeover a 3TB real Web corpus with 150M pages and over 20 entity types extracted. Ourexperiments in two concrete application settings show our techniques of on average; 2 to 4orders of magnitude speed-up; over the keyword-based baseline; with reasonable spaceoverhead.,Proceedings of the 13th International Conference on Extending Database Technology,2010,20
Method and system for extracting web query interfaces,*,A computer program product being embodied on a computer readable medium for extractingsemantic information about a plurality of documents being accessible via a computernetwork; the computer program product including computer-executable instructions for:generating a plurality of tokens from at least one of the documents; each token beingindicative of a displayed item and a corresponding position; and; constructing at least oneparse tree indicative of a semantic structure of the at least one document from the tokensdependently upon a grammar being indicative of presentation conventions.,*,2009,19
Semantic proximity search on graphs with metagraph-based learning,Yuan Fang; Wenqing Lin; Vincent W Zheng; Min Wu; Kevin Chen-Chuan Chang; Xiao-Li Li,Given ubiquitous graph data such as the Web and social networks; proximity search ongraphs has been an active research topic. The task boils down to measuring the proximitybetween two nodes on a graph. Although most earlier studies deal with homogeneous orbipartite graphs only; many real-world graphs are heterogeneous with objects of varioustypes; giving rise to different semantic classes of proximity. For instance; on a social networktwo users can be close for different reasons; such as being classmates or family members;which represent two distinct classes of proximity. Thus; it becomes inadequate to onlymeasure a “generic” form of proximity as previous works have focused on. In this paper; weidentify metagraphs as a novel and effective means to characterize the common structuresfor a desired class of proximity. Subsequently; we propose a family of metagraph-based …,Data Engineering (ICDE); 2016 IEEE 32nd International Conference on,2016,18
Mining complex matchings across web query interfaces,Bin He; Kevin Chen-Chuan Chang; Jiawei Han,Abstract To enable information integration; schema matching is a critical step for discoveringsemantic correspondences of attributes across heterogeneous sourcess. As a new attempt;this paper studies such matching as a data mining problem. Specifically; while complexmatchings are common; because of their far more complex search space; most existingtechniques focus on simple 1: 1 matchings. To tackle this challenge; this paper takes aconceptually novel approach by viewing schema matching as correlation mining; for our taskof matching Web query interfaces to integrate the myriad databases on the Internet. On this"deep Web;" query interfaces generally form complex matchings between attribute groups(eg;{author} corresponds to {first name; last name} in the Books domain). We observe thatthe co-occurrences patterns across query interfaces often reveal such complex semantic …,Proceedings of the 9th ACM SIGMOD workshop on Research issues in data mining and knowledge discovery,2004,17
On-the-fly constraint mapping across web query interfaces,Zhen Zhang; Bin He; Kevin Chen-Chuan Chang,Recently; the Web has been rapidly``deepened" with the prevalence of databases onlineand becomes an important frontier for data integration. On this deep Web; a significantamount of information can only be accessed as response to dynamically issued queries tothe\emph {query interface} of a back-end database; instead of by traversing static URL links.Such a query interface expresses a set of\emph {constraint templates}; where eachconstraint template states how an attribute can be queried. To enable automatic querymediation among heterogenous deep Web sources; it is critical to automatically translatethose constraints; which we name as\emph {constraint mapping}. In particular; this paperaims at enabling\emph {on-the-fly} constraint mapping; toward on-the-fly integration of Webdatabases; due to the the large scale and dynamic nature of the deep Web. Such on-the …,*,2004,17
Statistical schema integration across the deep web,Bin He; Kevin C Chang,Abstract Schema integration is a central problem for integrating heterogeneous informationsources. Traditionally; the problem has been defined and addressed as finding schemamapping between pairs of sources. This paper proposes a fundamentally different approachfor schema integration; motivated by integrating large numbers of data sources on theInternet. On this``deep Web;" we observe two distinguishing characteristics that offer a freshview for rethinking schema integration: First; as the Web scales; there are ample sourcesthat provide structured information in the same domains (eg; books and automobiles).Second; while sources proliferate; their aggregate schema vocabulary tends to converge ata relatively small size. Motivated by these observations; we propose a novel paradigm;"statistical schema integration": Unlike traditional pairwise mapping; we take a holistic …,*,2002,17
NBDL: a CIS framework for NSDL,Joe Futrelle; Su-Shing Chen; Kevin C Chang,Joe Futrelle NCSA; University of Illinois Urbana-Champaign; Illinois Futrelle@ncsa.uiuc.edu… Su-Shing Chen University of Missouri Columbia; Missouri ChenS@missouri.edu … KevinC. Chang University of Illinois Urbana-Champaign; Illinois Kcchang@cs.uiuc.edu … ABSTRACTIn this paper; we describe the NBDL (National Biology Digital Library) project; one of the six CIS(Core Integration System) projects of the NSF NSDL (National SMETE Digital Library)Program … Categories and Subject Descriptors H.3.7 [Information Storage and Retrieval]: DigitalLibraries – standards; user issues; dissemination … Keywords Digital library; SMETeducation; Federated search … 1. INTRODUCTION This NSDL project; NBDL; consists of participatinginstitutions: University of Missouri-Columbia (MU); NCSA; University of Illinois-Urbana/Champaign(UIUC); and Missouri Botanical Garden (MOBOT) [6]. The project focuses on building an …,Proceedings of the 1st ACM/IEEE-CS joint conference on Digital libraries,2001,17
Towards building a metaquerier: Extracting and matching web query interfaces,Bin He; Zhen Zhang; KC-C Chang,We witness the rapid growth and thus the prevalence of databases on the Web. Our recentstudy in April 2004 estimated 450;000 online databases. On this deep Web; myriaddatabases provide dynamic query-based data access through their query interfaces; insteadof static URL links. It is thus essential to integrate these query interfaces for integrating thedeep Web. The overall goal of the MetaQuerier project aims at opening up the deep Web tousers; by building a system to help users exploring and integrating deep Web sources. Inparticular; to start with; we focus on the integration of deep Web sources in the samedomain; which is itself an important integration task. To automate this integration scenario;we need to solve two critical problems: extracting query interfaces and matching queryinterfaces. To solve the interface extraction problem; we introduce a parsing paradigm by …,Data Engineering; 2005. ICDE 2005. Proceedings. 21st International Conference on,2005,16
Entity-centric document filtering: boosting feature mapping through meta-features,Mianwei Zhou; Kevin Chen-Chuan Chang,Abstract This paper studies the entity-centric document filtering task--given an entityrepresented by its identification page (eg; an Wikpedia page); how to correctly identify itsrelevant documents. In particular; we are interested in learning an entity-centric documentfilter based on a small number of training entities; and the filter can predict documentrelevance for a large set of unseen entities at query time. Towards characterizing therelevance of a document; the problem boils down to learning keyword importance for thequery entities. Since the same keyword will have very different importance for differententities; we abstract the entity-centric document filtering problem as a transfer learningproblem; and the challenge becomes how to appropriately transfer the keyword importancelearned from training entities to query entities. Based on the insight that keywords sharing …,Proceedings of the 22nd ACM international conference on Information & Knowledge Management,2013,15
Data-oriented content query system: searching for data into text on the web,Mianwei Zhou; Tao Cheng; Kevin Chen-Chuan Chang,Abstract As the Web provides rich data embedded in the immense contents inside pages;we witness many ad-hoc efforts for exploiting fine granularity information across Web text;such as Web information extraction; typed-entity search; and question answering. To unifyand generalize these efforts; this paper proposes a general search system--Data-orientedContent Query System (DoCQS)--to search directly into document contents for findingrelevant values of desired data types. Motivated by the current limitations; we start bydistilling the essential capabilities needed by such content querying. The capabilities call fora conceptually relational model; upon which we design a powerful Content Query Language(CQL). For efficient processing; we design novel index structures and query processingalgorithms. We evaluate our proposal over two concrete domains of realistic Web corpora …,Proceedings of the third ACM international conference on Web search and data mining,2010,15
Building the infobus: A review of technical choices in the stanford digital library project,Andreas Paepcke; Michelle Baldonado; Chen-Chuan K Chang; Steve Cousins; Hector Garcia-Molina,We review selected technical challenges addressed in our digital library project. OurInfoBus; a CORBA-based distributed object infrastructure; unifies access to heterogeneousdocument collections and information processing services. We organize search accessusing a protocol (DLIOP) that is tailored for use with distributed objects. A metadataarchitecture supports novel user interfaces and query translation facilities. We briefly explainthese components and then describe how technology choices such as distributed objects;commercial cataloguing schemes and Java; helped and hindered our progress. We alsodescribe the evolution of our design tradeoffs.,*,2000,15
Privacy Risk in Anonymized Heterogeneous Information Networks.,Aston Zhang; Xing Xie; Kevin Chen-Chuan Chang; Carl A Gunter; Jiawei Han; XiaoFeng Wang,ABSTRACT Anonymized user datasets are often released for research or industryapplications. As an example; t. qq. com released its anonymized users' profile; socialinteraction; and recommendation log data in KDD Cup 2012 to call for recommendationalgorithms. Since the entities (users and so on) and edges (links among entities) are ofmultiple types; the released social network is a heterogeneous information network. Priorwork has shown how privacy can be compromised in homogeneous information networks bythe use of specific types of graph patterns. We show how the extra information derived fromheterogeneity can be used to relax these assumptions. To characterize and demonstrate thisadded threat; we formally define privacy risk in an anonymized heterogeneous informationnetwork to identify the vulnerability in the possible way such data are released; and …,EDBT,2014,14
RoundTripRank: Graph-based proximity with importance and specificity?,Yuan Fang; Kevin Chen-Chuan Chang; Hady W Lauw,Graph-based proximity has many applications with different ranking needs. However; mostprevious works only stress the sense of importance by finding “popular” results for a query.Often times important results are overly general without being well-tailored to the query;lacking a sense of specificity-which only emerges recently. Even then; the two senses aretreated independently; and only combined empirically. In this paper; we generalize the well-studied importance-based random walk into a round trip and develop RoundTripRank;seamlessly integrating specificity and importance in one coherent process. We alsorecognize the need for a flexible trade-off between the two senses; and further developRoundTripRank+ based on a scheme of hybrid random surfers. For efficient computation; westart with a basic model that decomposes RoundTripRank into smaller units. For each unit …,Data Engineering (ICDE); 2013 IEEE 29th International Conference on,2013,14
Collaborative wrapping: A turbo framework for web data extraction,Shui-Lung Chuang; Kevin Chen-Chuan Chang; ChengXiang Zhai,To access data sources on the Web; a crucial step is wrapping; which translates queryresponses; rendered in textual HTML; back into their relational form. Traditionally; thisproblem has been addressed with syntax-based approaches for a single source. However;as online databases multiply; we often need to wrap multiple sources; in particular fordomain-based integration. Observing that sources in the same domain usually sharecommon fields; we propose a novel wrapping concept-collaborative wrapping-wheremultiple sources are extracted concurrently with content-based synchronization to produceconsentaneous extractions. Toward this concept; recognizing wrapping as a communicationprocess; we develop the turbo wrapper; upon the insight of turbo codes-a multi-codedecoding scheme in information theory. Our experiment shows that the turbo wrapper …,Data Engineering; 2007. ICDE 2007. IEEE 23rd International Conference on,2007,14
Evaluating the cost of Boolean query mapping,Chen-Chuan K Chang; Hector Garcia-Molina,Abstract Non-uniform query languages make searching over heterogeneous informationsources difficult. Our approach is to allow a user to compose Boolean queries in one richfront-end language. For each user query and target source; we transform the user query intoa subsuming query that can be supported by the source but that may return extradocuments. The results are then processed by a filter query to yield the correct final results.This post-filtering approach may involve significant cost because the documents that theusers will not see may have to be retrieved and filtered. There are generally two ways toimplement post-filtering: batch post-filtering and incremental post-filtering. In this paper weevaluate the costs of both methods for different search features such as proximity operators.The experimental results show that in many cases incremental post-filtering cost may be …,Proceedings of the second ACM international conference on Digital libraries,1997,13
From node embedding to community embedding,Vincent W Zheng; Sandro Cavallari; Hongyun Cai; Kevin Chen-Chuan Chang; Erik Cambria,Abstract: Most of the existing graph embedding methods focus on nodes; which aim tooutput a vector representation for each node in the graph such that two nodes being" close"on the graph are close too in the low-dimensional space. Despite the success of embeddingindividual nodes for graph analytics; we notice that an important concept of embeddingcommunities (ie; groups of nodes) is missing. Embedding communities is useful; not only forsupporting various community-level applications; but also to help preserve communitystructure in graph embedding. In fact; we see community embedding as providing a higher-order proximity to define the node closeness; whereas most of the popular graph embeddingmethods focus on first-order and/or second-order proximities. To learn the communityembedding; we hinge upon the insight that community embedding and node embedding …,arXiv preprint arXiv:1610.09950,2016,11
Graph-based semi-supervised learning: Realizing pointwise smoothness probabilistically,Yuan Fang; Kevin Chen-Chuan Chang; Hady W Lauw,Abstract As the central notion in semi-supervised learning; smoothness is often realized on agraph representation of the data. In this paper; we study two complementary dimensions ofsmoothness: its pointwise nature and probabilistic modeling. While no existing graph-basedwork exploits them in conjunction; we encompass both in a novel framework of ProbabilisticGraph-based Pointwise Smoothness (PGP); building upon two foundational models of datacloseness and label coupling. This new form of smoothness axiomatizes a set of probabilityconstraints; which ultimately enables class prediction. Theoretically; we provide an error androbustness analysis of PGP. Empirically; we conduct extensive experiments to show theadvantages of PGP.,*,2014,11
Integrating web query results: holistic schema matching,Shui-Lung Chuang; Kevin Chen-Chuan Chang,Abstract The emergence of numerous data sources online has presented a pressing needfor more automatic yet accurate data integration techniques. For the data returned fromquerying such sources; most works focus on how to extract the embedded structured datamore accurately. However; to eventually provide an integrated access to these query results;a last but not least step is to combine the extracted data coming from different sources. Acritical task is finding the correspondence of the data fields between the sources-a problemwell known as schema matching. Query results are a small and biased sample set ofinstances obtained from sources; the obtained schema information is thus very implicit andincomplete; which often prevents existing schema matching approaches from performingeffectively. In this paper; we develop a novel framework for understanding and effectively …,Proceedings of the 17th ACM conference on Information and knowledge management,2008,11
Trustworthy keyword search for compliance storage,Soumyadeb Mitra; Marianne Winslett; Windsor W Hsu; Kevin Chen-Chuan Chang,Abstract Intense regulatory focus on secure retention of electronic records has led to a needto ensure that records are trustworthy; ie; able to provide irrefutable proof and accuratedetails of past events. In this paper; we analyze the requirements for a trustworthy index tosupport keyword-based search queries. We argue that trustworthy index entries must bedurable--the index must be updated when new documents arrive; and not periodicallydeleted and rebuilt. To this end; we propose a scheme for efficiently updating an invertedindex; based on judicious merging of the posting lists of terms. Through extensivesimulations and experiments with two real world data sets and workloads; we demonstratethat the scheme achieves online update speed while maintaining good query performance.We also present and evaluate jump indexes; a novel trustworthy and efficient index for …,The VLDB Journal—The International Journal on Very Large Data Bases,2008,11
Dewex: an exploration facility for enabling the Deep Web integration,Govind Kabra; Zhen Zhang; Kevin Chen-Chuan Chang,In this demo; we present Dewex; an exploration facility for answering questions like T1-TA;running on repository of over 30;000 real sources. The main technical contributions of thisdemo are: as our system; we present a novel facility for exploring the deep Web; as oursolution; we propose a schematic metadata based source modeling; and a generalizedsearch mechanism to compute associativity in metadata graph; and in our realization; toenable online exploration; we propose to speed up computation using matrix optimization.,Data Engineering; 2007. ICDE 2007. IEEE 23rd International Conference on,2007,11
A structure-driven yield-aware web form crawler: building a database of online databases,Bin He; Chengkai Li; David Killian; Mitesh Patel; Yuping Tseng; Kevin Chen-Chuan Chang,The Web has been rapidly``deepened" by massive databases online: Recent surveys showthat while the surface Web has linked billions of static HTML pages; a far more significantamount of information is``hidden" in the deep Web; behind the query forms of searchabledatabases. With its myriad databases and hidden content; this deep Web is an importantfrontier for information search. In this paper; we develop a novel Web Form Crawler to collectthe``doors" of Web databases; ie; query forms; to build a database for online databases inboth efficient and comprehensive manners. Being object-focused; topic-neutral andcoverage-comprehensive; such a crawler; while critical to searching and integrating onlinedatabases; has not been extensively studied. In particular; query forms; while many; whencompared with the size of the Web; are sparsely scattered among pages; which brings …,*,2006,11
Information integration research: Summary of nsf idm workshop breakout session,Alon Halevy; Chen Li; Contributions From Philip Bernstein; Kevin Chang; Jayavel Shanmugasundaram; Mike Uschold,Abstract Information integration systems provide users a uniform interface to a multitude ofheterogeneous; independently developed data sources. They free the user from having tolocate the data sources; interact with each one in isolation and manually combine data frommultiple sources. The applications of information integration systems range frommanagement of data in large enterprises; data sharing amongst government agencies andlarge scientific projects (eg; biological research and astronomy); and integration of datasources on the World-Wide Web. In the past few years we have seen significant progress onmany aspects of data integration; including languages for mediation between data sources;query processing techniques for data integration; and the construction of wrappers to datasources. In addition; recent commercial activities have produced tools that efficiently …,*,2004,11
Learning community embedding with community detection and node embedding on graphs,Sandro Cavallari; Vincent W Zheng; Hongyun Cai; Kevin Chen-Chuan Chang; Erik Cambria,Abstract In this paper; we study an important yet largely under-explored setting of graphembedding; ie; embedding communities instead of each individual nodes. We find thatcommunity embedding is not only useful for community-level applications such as graphvisualization; but also beneficial to both community detection and node classification. Tolearn such embedding; our insight hinges upon a closed loop among communityembedding; community detection and node embedding. On the one hand; node embeddingcan help improve community detection; which outputs good communities for fitting bettercommunity embedding. On the other hand; community embedding can be used to optimizethe node embedding by introducing a community-aware high-order proximity. Guided by thisinsight; we propose a novel community embedding framework that jointly solves the three …,Proceedings of the 2017 ACM on Conference on Information and Knowledge Management,2017,10
The Stanford InfoBus and its service layers,Martin Röscheisen; Michelle Baldonado; Kevin Chang; Luis Gravano; Steven Ketchpel; Andreas Paepcke,The Stanford InfoBus is a prototype infrastructure developed as part of the Stanford DigitalLibraries Project to extend the current Internet protocols with a suite of higherlevelinformation management protocols. This paper surveys the five service layers provided bythe Stanford InfoBus: protocols for managing items and collections (DLIOP); metadata(SMA); search (STARTS); payment (UPAI); and rights and obligations (FIRM).,Augmenting the Internet with Higher-Level Information Management Protocols http://www-diglib. stanford. edu/cgi-bin/WP/get/SIDL-WP-1997-0065 [eingesehen: 26.05. 98],1997,10
Unifying learning to rank and domain adaptation: Enabling cross-task document scoring,Mianwei Zhou; Kevin C Chang,Abstract For document scoring; although learning to rank and domain adaptation are treatedas two different problems in previous works; we discover that they actually share the samechallenge of adapting keyword contribution across different queries or domains. In thispaper; we propose to study the cross-task document scoring problem; where a task refers toa query to rank or a domain to adapt to; as the first attempt to unify these two problems.Existing solutions for learning to rank and domain adaptation either leave the heavy burdenof adapting keyword contribution to feature designers; or are difficult to be generalized. Toresolve such limitations; we abstract the keyword scoring principle; pointing out that thecontribution of a keyword essentially depends on; first; its importance to a task and; second;its importance to the document. For determining these two aspects of keyword importance …,Proceedings of the 20th ACM SIGKDD international conference on Knowledge discovery and data mining,2014,9
Query and data mapping across heterogeneous information sources,Kevin Chen Chuan Chang,Abstract The Internet has brought together information sources worldwide. Integrating suchheterogeneous and autonomous sources is challenging because of their non-uniform querylanguages and data representations. To help users uniformly query over different sources;we have developed an integration system or a mediator for optimally mapping queries anddata across disparate contexts. Such a translation technique is essential for many importantapplications that require querying sources and analyzing data on the web; such as meta-searching; e-commerce; and web mining. This thesis presents our solutions...,*,2001,9
Interoperability for digital libraries: problems and directions,Andreas Paepcke; Chen-Chuan K Chang; Hector Garcia-Molina; Terry Winograd,Interoperability is a central concern whenever digital libraries are constructed as collectionsof independently developed components that rely on each other to accomplish a larger task.The ultimate goal for such a system is to have components evolve independently; yet toallow all components to call on each other efficiently and conveniently. For digital libraries toscale to an international level; they need to be constructed from such interoperable pieces.This is the case not only for technical reasons; but also because information repositories andinformation processing services for digital libraries often need to be operated byindependent organizations. Frequently; the terms “heterogeneous” or “federated” systemsare used to describe cooperating systems where individual components are designed oroperated autonomously. This is in contrast to the more general term “distributed systems” …,Retrieved September,1998,9
DataSpread: Unifying databases and spreadsheets,Mangesh Bendre; Bofan Sun; Ding Zhang; Xinyan Zhou; Kevin Chen-Chuan Chang; Aditya Parameswaran,Abstract Spreadsheet software is often the tool of choice for ad-hoc tabular datamanagement; processing; and visualization; especially on tiny data sets. On the other hand;relational database systems offer significant power; expressivity; and efficiency overspreadsheet software for data management; while lacking in the ease of use and ad-hocanalysis capabilities. We demonstrate D ata S pread; a data exploration tool that holisticallyunifies databases and spreadsheets. It continues to offer a Microsoft Excel-basedspreadsheet front-end; while in parallel managing all the data in a back-end database;specifically; PostgreSQL. D ata S pread retains all the advantages of spreadsheets;including ease of use; ad-hoc analysis and visualization capabilities; and a schema-freenature; while also adding the advantages of traditional relational databases; such as …,Proceedings of the VLDB Endowment,2015,8
Towards a social media analytics platform: event detection and user profiling for twitter,Manish Gupta; Rui Li; Kevin Chen-Chuan Chang,Abstract Microblog data differs significantly from the traditional text data with respect to avariety of dimensions. Microblog data contains short documents; SMS kind of language; andis full of code mixing. Though a lot of it is mere social babble; it also contains fresh newscoming from human sensors at a humungous rate. Given such interesting characteristics; theworld wide web community has witnessed a large number of research tasks formicroblogging platforms recently. Event detection on Twitter is one of the most popular suchtasks with a large number of applications. The proposed tutorial on social analytics forTwitter will contain three parts. In the first part; we will discuss research efforts towardsdetection of events from Twitter using both the tweet content as well as other externalsources. We will also discuss various applications for which event detection mechanisms …,Proceedings of the 23rd International Conference on World Wide Web,2014,7
DoCQS: a prototype system for supporting data-oriented content query,Mianwei Zhou; Tao Cheng; Kevin Chen-Chuan Chang,Abstract Witnessing the richness of data in document content and many ad-hoc efforts forfinding such data; we propose a Data-oriented Content Query System (DoCQS); which isoriented towards fine granularity data of all types by searching directly into documentcontent. DoCQS uses the relational model as the underlying data model; and offers apowerful and flexible Content Query Language (CQL) to adapt to diverse query demands. Inthis demonstration; we show how to model various search tasks by CQL statements; andhow the system architecture efficiently supports the CQL execution. Our online demo of thesystem is available at http://wisdm. cs. uiuc. edu/demos/docqs/.,Proceedings of the 2010 ACM SIGMOD International Conference on Management of data,2010,7
Semantic Proximity Search on Heterogeneous Graph by Proximity Embedding.,Zemin Liu; Vincent W Zheng; Zhou Zhao; Fanwei Zhu; Kevin Chen-Chuan Chang; Minghui Wu; Jing Ying,Abstract Many real-world networks have a rich collection of objects. The semantics of theseobjects allows us to capture different classes of proximities; thus enabling an important taskof semantic proximity search. As the core of semantic proximity search; we have to measurethe proximity on a heterogeneous graph; whose nodes are various types of objects. Most ofthe existing methods rely on engineering features about the graph structure between twonodes to measure their proximity. With recent development on graph embedding; we see agood chance to avoid feature engineering for semantic proximity search. There is very littlework on using graph embedding for semantic proximity search. We also observe that graphembedding methods typically focus on embedding nodes; which is an “indirect” approach tolearn the proximity. Thus; we introduce a new concept of proximity embedding; which …,AAAI,2017,6
A Comprehensive Survey of Graph Embedding: Problems; Techniques and Applications,Hongyun Cai; Vincent W Zheng; Kevin Chen-Chuan Chang,Abstract: Graph is an important data representation which appears in a wide diversity of real-world scenarios. Effective graph analytics provides users a deeper understanding of what isbehind the data; and thus can benefit a lot of useful applications such as node classification;node recommendation; link prediction; etc. However; most graph analytics methods sufferthe high computation and space cost. Graph embedding is an effective yet efficient way tosolve the graph analytics problem. It converts the graph data into a low dimensional space inwhich the graph structural information and graph properties are maximally preserved. In thissurvey; we conduct a comprehensive review of the literature in graph embedding. We firstintroduce the formal definition of graph embedding as well as the related concepts. Afterthat; we propose two taxonomies of graph embedding which correspond to what …,arXiv preprint arXiv:1709.07604,2017,5
Cold-Start Heterogeneous-Device Wireless Localization.,Vincent W Zheng; Hong Cao; Shenghua Gao; Aditi Adhikari; Miao Lin; Kevin Chen-Chuan Chang,Abstract In this paper; we study a cold-start heterogeneous-device localization problem. Thisproblem is challenging; because it results in an extreme inductive transfer learning setting;where there is only source domain data but no target domain data. This problem is alsounderexplored. As there is no target domain data for calibration; we aim to learn a robustfeature representation only from the source domain. There is little previous work on such arobust feature learning task; besides; the existing robust feature representation proposalsare both heuristic and inexpressive. As our contribution; we for the first time provide aprincipled and expressive robust feature representation to solve the challenging cold-startheterogeneous-device localization problem. We evaluate our model on two public real-world data sets; and show that it significantly outperforms the best baseline by 23.1 …,AAAI,2016,5
Learning to rank from distant supervision: Exploiting noisy redundancy for relational entity search,Mianwei Zhou; Hongning Wang; Kevin Chen-Chuan Change,In this paper; we study the task of relational entity search which aims at automaticallylearning an entity ranking function for a desired relation. To rank entities; we exploit theredundancy abound in their snippets; however; such redundancy is noisy as not all thesnippets represent information relevant to the desired relation. To explore useful informationfrom such noisy redundancy; we abstract the task as a distantly supervised ranking problem-based on coarse entity-level annotations; deriving a relation-specific ranking function for thepurpose of online searching. As the key challenge; without detailed snippet-levelannotations; we have to learn an entity ranking function that can effectively filter noise;furthermore; the ranking function should also be online executable. We develop Pattern-based Filter Network (PFNet); a novel probabilistic graphical model; as our solution. To …,Data Engineering (ICDE); 2013 IEEE 29th International Conference on,2013,5
Confidence-aware graph regularization with heterogeneous pairwise features,Yuan Fang; Bo-June Paul Hsu; Kevin Chen-Chuan Chang,Abstract Conventional classification methods tend to focus on features of individual objects;while missing out on potentially valuable pairwise features that capture the relationshipsbetween objects. Although recent developments on graph regularization exploit this aspect;existing works generally assume only a single kind of pairwise feature; which is ofteninsufficient. We observe that multiple; heterogeneous pairwise features can oftencomplement each other and are generally more robust in modeling the relationshipsbetween objects. Furthermore; as some objects are easier to classify than others; objectswith higher initial classification confidence should be weighed more towards classifyingrelated but more ambiguous objects; an observation missing from previous graphregularization techniques. In this paper; we propose a Dirichlet-based regularization …,Proceedings of the 35th international ACM SIGIR conference on Research and development in information retrieval,2012,5
Method for searching deep web services,*,A method for searching deep web services is provided. The method in one aspect allowsorganizing communities; sources and schema attributes in a multi-tier containmentrelationship; searching representative schema attributes in one or more communities;searching representative services in one or more communities; searching for relatedschema attributes; and searching for related communities.,*,2009,5
Method and apparatus for organizing data sources,*,A method and apparatus for organizing deep Web services are provided. In one aspect; themethod and apparatus obtains a collection of sources and their associated attributes and/orinput modes; for instance; using a crawling algorithm. The method and apparatus uses thisinformation to organize the sources into communities. A mining algorithm such as thehyperclique mining algorithm is used to obtain cliques of highly correlated attributes. Aclustering algorithm such as the hierarchical agglomerative clustering algorithm is used tofurther cluster the cliques of attributes into larger cliques; which in the present disclosure isreferred to as signatures. The sources that are associated with each signature form acommunity and a graph representation of the communities is constructed; where the verticesare communities and the edges are the shared attributes.,*,2008,5
Enabling Ad-hoc Ranking for Data Retrieval.,Hwanjo Yu; Seung-won Hwang; Kevin Chen-Chuan Chang,*,ICDE,2005,5
Boolean query mapping across heterogeneous information sources (extended version),C Chang; Hector Garcia-Molina; Andreas Paepcke,Searching over heterogeneous information sources is diffcult because of the non-uniformquery languages. Our approach is to allow a user to compose Boolean queries in one richfront-end language. For each user query and target source; we transform the user query intoa subsuming query that can be supported by the source but that may return extradocuments. The results are then processed by a filter query to yield the correct final result. Inthis paper we introduce the architecture and associated algorithms for generating thesupported subsuming queries and filters. We show that generated subsuming queries returna minimal number of documents; we also discuss how minimal cost filters can be obtained.We have implemented prototype versions of these algorithms and demonstrated them onheterogeneous Boolean systems. Index Terms Boolean queries; query translation …,*,1996,5
Mobility Profiling for User Verification with Anonymized Location Data.,Miao Lin; Hong Cao; Vincent W Zheng; Kevin Chen-Chuan Chang; Shonali Krishnaswamy,Abstract Mobile user verification is to authenticate whether a given user is the legitimate userof a smartphone device. Unlike the current methods that commonly require users activecooperation; such as entering a short pin or a one-stroke draw pattern; we propose a newpassive verification method that requires minimal imposition of users through modellingusers subtle mobility patterns. Specifically; our method computes the statistical ambiencefeatures on WiFi and cell tower data from location anonymized data sets and then wecustomize Hidden Markov Model (HMM) to capture the spatialtemporal patterns of eachuser's mobility behaviors. Our learned model is subsequently validated and applied to verifya test user in a time-evolving manner through sequential likelihood test. Experimentally; ourmethod achieves 72% verification accuracy with less than a day's data and a detection …,IJCAI,2015,4
System and method for online and mobile memories and greeting service,*,A system; a method; and a user interface are described for personalizing and sendingstationery/cards. A reminder list on the user interface includes a list of reminder entries eachidentifying an upcoming event including events generated based on a specified relationshipbetween the user and one or more contacts of the user. A recommendation region ispopulated one or more recommended stationery/card designs associated with one of theentries in the reminder list. A stationery/card personalization engine provides the user with aset of personalization options related to the selected stationery/card design; and generatespersonalized stationery based on the selected stationery/card design and the user input.,*,2015,4
Object search: supporting structured queries in web search engines,Kim Cuong Pham; Nicholas Rizzolo; Kevin Small; Kevin Chen-Chuan Chang; Dan Roth,Abstract As the web evolves; increasing quantities of structured information is embedded inweb pages in disparate formats. For example; a digital camera's description may include itsprice and megapixels whereas a professor's description may include her name; university;and research interests. Both types of pages may include additional ambiguous information.General search engines (GSEs) do not support queries over these types of data becausethey ignore the web document semantics. Conversely; describing requisite semanticsthrough structured queries into databases populated by information extraction (IE)techniques are expensive and not easily adaptable to new domains. This paper describes amethodology for rapidly developing search engines capable of answering structured queriesover unstructured corpora by utilizing machine learning to avoid explicit IE. We …,Proceedings of the NAACL HLT 2010 Workshop on Semantic Search,2010,4
Efficient processing of ad-hoc top-k aggregate queries in OLAP,Chengkai Li; Kevin Chen-Chuan Chang; Ihab F Ilyas,In this paper; we develop a principled framework for efficient processing of ad-hoc top-k(ranking) aggregate queries in OLAP. Such queries provide the k groups with the highestaggregates to decision makers. Essential support of top-k aggregate queries is lacking incurrent RDBMSs; which process such queries in a naive and overkill materialize-group-sortscheme; therefore can be prohibitively inefficient. Our new framework is based on twofundamental properties; the Group-Ranking and Tuple-Ranking Principles. The principlesdictate group-ordering and tuple-ordering requirement that together guide the queryprocessor toward the optimal aggregate query processing. To realize the requirements; wepropose a new execution model and address the challenges of implementing new queryoperators; enabling efficient top-k aggregate query plans that are both group-aware and …,*,2005,4
Mind your vocabulary: Query mapping across heterogeneous information sources (extended version),Chen-Chuan K Chang; Hector Garcia-Molina,In this paper we present a mechanism for translating constraint queries; ie; Booleanexpressions of constraints; across heterogeneous information sources. Integrating suchsystems is difficult in part because they use a wide range of constraints as the vocabulary forformulating queries. We describe algorithms that apply user-provided mapping rules totranslate query constraints into ones that are understood and supported in another context;eg; that use the proper operators and value formats. We show that the translated queriesminimally subsume the original ones. Furthermore; the translated queries are also the mostcompact possible. Unlike other query mapping work; we effectively consider inter-dependencies among constraints; ie; we handle constraints that cannot be translatedindependently. Furthermore; when constraints are not fully supported; our framework …,*,1999,4
Predicate Rewriting for Translating Boolean Queries in a Heterogeneous Information System,Chen Chang; Hector Garcia-Molina; Andreas Paepcke,Abstract Searching over heterogeneous information sources is difficult in part because of thenon-uniform query languages. Our approach is to allow users to compose Boolean queriesin one rich front-end language. For each user query and target source; we transform the userquery into a subsuming query that can be supported by the source but that may return extradocuments. The results are then processed by a filter query to yield the correct final results.In this paper we introduce the architecture and associated mechanism for query translation.In particular; we discuss techniques for rewriting predicates in Boolean queries into nativesubsuming forms; which is a basis of translating complex queries. In addition; we presentexperimental results for evaluating the cost of post-filtering. We also discuss the drawbacksof this approach and cases when it may not be effective. We have implemented prototype …,*,1998,4
Boolean Query Mapping Across Heterogeneous Information Sources (Extended Version),Kevin C Chang; Hector Garcia-Molina; Andreas Paepcke,Abstract Searching over heterogeneous information sources is difficult because of the non-uniform query languages. Our approach is to allow a user to compose Boolean queries inone rich front-end language. For each user query and target source; we transform the userquery into a subsuming query that can be supported by the source but that may return extradocuments. The results are then processed by a filter query to yield the correct final result. Inthis paper we introduce the architecture and associated algorithms for generating thesupported subsuming queries and filters. We show that generated subsuming queries returna minimal number of documents; we also discuss how minimal cost filters can be obtained.We have implemented prototype versions of these algorithms and demonstrated them onheterogeneous Boolean systems.,*,1997,4
From community detection to community profiling,Hongyun Cai; Vincent W Zheng; Fanwei Zhu; Kevin Chen-Chuan Chang; Zi Huang,Abstract Most existing community-related studies focus on detection; which aim to find thecommunity membership for each user from user friendship links. However; membershipalone; without a complete profile of what a community is and how it interacts with othercommunities; has limited applications. This motivates us to consider systematically profilingthe communities and thereby developing useful community-level applications. In this paper;we for the first time formalize the concept of community profiling. With rich user informationon the network; such as user published content and user diffusion links; we characterize acommunity in terms of both its internal content profile and external diffusion profile. Thedifficulty of community profiling is often underestimated. We novelly identify three uniquechallenges and propose a joint Community Profiling and Detection (CPD) model to …,Proceedings of the VLDB Endowment,2017,3
LiPo battery energy studies for improved flight performance of unmanned aerial systems,K Chang; P Rammos; SA Wilkerson; M Bundy; S Andrew Gadsden,Energy storage is one of the most important determinants of how long and far a small electricpowered unmanned aerial system (UAS) can fly. For years; most hobby andexperimentalists used heavy fuels to power small drone-like systems. Electric motors andbattery storage prior to the turn of the century were either too heavy or too inefficient for flighttimes of any usable duration. However; with the availability of brushless electric motors andlithium-based batteries everything has changed. Systems like the Dragon Eye; Pointer; andRaven are in service performing reconnaissance; intelligence; surveillance; and targetacquisition (RISTA) for more than an hour at a time. More recently; multi-rotor vehicles haveexpanded small UAS capabilities to include activities with hovering and persistentsurveillance. Moreover; these systems coupled with the surge of small; low-cost …,Unmanned Systems Technology XVIII,2016,3
Approximate Query Translation (Extended version),C Chang; H Garcia-Molina,In this paper we present a mechanism for approximately translating Boolean queryconstraints across heterogeneous information sources. Achieving the best translation ischallenging because sources support different constraints for formulating queries; and oftenthese constraints cannot be precisely translated. For instance; a query [score> 8] mightbe``perfectly''translated as [rating][>][0.8] at some site; but can only be approximated as[grade][=][A] at another. Unlike other work; our general framework adopts a customizable``closeness''metric for the translation that combines both precision and recall. Our resultsshow that for query translation we need to handle interdependencies among both queryconjuncts as well as disjuncts. As the basis; we identify the essential requirements of a rulesystem for users to encode the mappings for atomic semantic units. Our algorithm then …,*,1999,3
Editorial issue:” Special Issue on Web Content Mining”,Bing Liu; Kevin Chen-Chuan Chang,*,SIGKDD Explorations,*,3
Towards Context-aware Social Recommendation via Individual Trust,Jun Li; Chaochao Chen; Huiling Chen; Changfei Tong,Abstract Incorporating social network information and contexts to improve recommendationperformance has been drawing considerable attention recently. However; a majority ofexisting social recommendation approaches suffer from the following problems:(1) They onlyemploy individual trust among users to optimize prediction solutions in user latent featurespace or in user-item rating space; thus; they exhibit low recommendation accuracy.(2) Theyuse decision trees to perform context-based user-item subgrouping; thus; they can onlyhandle categorical contexts.(3) They have difficulty coping with the data sparsity problem. Tosolve these problems; and accurately and realistically model recommender systems; wepropose a social matrix factorization method to optimize the prediction solution in both userlatent feature space and user-item rating space using the individual trust among users. To …,Knowledge-Based Systems,2017,2
Aerial swarms as asymmetric threats,Stephen Wilkerson; Christopher Korpela; Kevin Chang; Andrew Lee; Andrew Gadsden,Despite being unmatched on the battlefield or at home; low-cost; asymmetric threats haveproven dangerous for US military forces and homeland security. The proliferation ofimprovised explosive devices of all types in the Iraqi and Afghan theaters has demonstratedthat inexpensive; commercial off-the-shelf technology and some electronics knowledge canbe combined to significantly impact high-tech operations. Autonomous GPS-guided andsemi-autonomous unmanned aerial vehicles will change the paradigm in their employmentin the very near future. While a single attack might be insignificant; a swarm of roboticdevices could prove a credible threat. In this paper we discuss the impact and limitations ofcommercially off-the-shelf drones and what measures might be used to counter thesedevices. We back up our findings with flight tests and observations on systems commonly …,Unmanned Aircraft Systems (ICUAS); 2016 International Conference on,2016,2
Learning to query: Focused web page harvesting for entity aspects,Yuan Fang; Vincent W Zheng; Kevin Chen-Chuan Chang,As the Web hosts rich information about real-world entities; our information quests becomeincreasingly entity centric. In this paper; we study the problem of focused harvesting of Webpages for entity aspects; to support downstream applications such as business analytics andbuilding a vertical portal. Given that search engines are the de facto gateways to assessinformation on the Web; we recognize the essence of our problem as Learning to Query(L2Q)-to intelligently select queries so that we can harvest pages; via a search engine;focused on an entity aspect of interest. Thus; it is crucial to quantify the utilities of thecandidate queries wrt some entity aspect. In order to better estimate the utilities; we identifytwo opportunities and address their challenges. First; a target entity in a given domain hasmany peers. We leverage these peer entities to become domain aware. Second; a …,Data Engineering (ICDE); 2016 IEEE 32nd International Conference on,2016,2
Scheduled approximation for Personalized PageRank with Utility-based Hub Selection,Fanwei Zhu; Yuan Fang; Kevin Chen-Chuan Chang; Jing Ying,Abstract As Personalized PageRank has been widely leveraged for ranking on a graph; theefficient computation of Personalized PageRank Vector (PPV) becomes a prominent issue.In this paper; we propose FastPPV; an approximate PPV computation algorithm that isincremental and accuracy-aware. Our approach hinges on a novel paradigm of scheduledapproximation: the computation is partitioned and scheduled for processing in an“organized” way; such that we can gradually improve our PPV estimation in an incrementalmanner and quantify the accuracy of our approximation at query time. Guided by thisprinciple; we develop an efficient hub-based realization; where we adopt the metric of hublength to partition and schedule random walk tours so that the approximation error reducesexponentially over iterations. In addition; as tours are segmented by hubs; the shared …,The VLDB Journal,2015,2
Probe card stiffener with decoupling,*,A stiffener for a probe card assembly can include decoupling mechanisms disposed withinradial arms of the stiffener. The decoupling mechanisms can be compliant in a directionalong a radial direction of said radial arm and rigid in a direction perpendicular to said radialarm. The decoupling mechanisms can decouple the stiffener from thermally induceddifferential radial contraction and expansion of the stiffener relative to the cardholder towhich the stiffener is mounted. This can reduce thermally-induced vertical translation of theprobe card assembly.,*,2014,2
Egonet-uiuc: A dataset for ego network research,Rui Li; Kevin Chen-Chuan Chang,Abstract: In this report; we introduce the version one of EgoNet-UIUC; which is a dataset forego network research. The dataset contains about 230 ego networks in Linkedin; whichhave about 33K users (with their attributes) and 283K relationships (with their relationshiptypes) in total. We name this dataset as EgoNet-UIUC; which stands for Ego NetworkDataset from University of Illinois at Urbana-Champaign.,arXiv preprint arXiv:1309.4157,2013,2
User profiling in ego network: An attribute and relationship type co-profiling approach,R Li; C Wang; K Chang,*,Proc. of the 23rd Intl. Conf. on World Wide Web (WWW),2011,2
Towards rich query interpretation: Back and forth on mining query templates,Ganesh Agarwal; Govind Kabra; Kevin C Chang,ABSTRACT In this paper; we propose to mine templates from search engine query logs; withthe goal of rich structured query interpretation. To begin with; we formalize the notion of templatesas a sequence of keywords and domain attributes; instantiating many queries based on the instancesof these domain attributes. We identify the key challenge in template discovery as the limitedseed knowledge. Our solution bootstraps from small seed input to discover relevant querytemplates; by harnessing the wealth of information available in search logs. We model this informationin a tri-partite infer- ence network of queries; sites and templates—together forming the“QueST” network. We propose iterative probabilistic inferencing framework based on dual metricsof precision and recall. We have deployed and tested our algorithm over a real-world large-scalesearch log of 15 Million queries from the MSN search engine. We find the accuracy of our …,Proceedings of the 19th International Conference on World Wide Web (WWW 2010); Raleigh; North Carolina; USA,2010,2
Deep-web search,Kevin C Chang,realized using such logical structures. For example; in tree based data acquisition protocols;a collection tree is built that is rooted at the data collection center such as the sink node [8].The dissemination of the data requests from the participating nodes and collection of datafrom the sensor nodes are accomplished using this tree. A cluster based data acquisitionmechanism has been proposed in [3]. As shown in Fig. 1; nodes are organized into a fixednumber of clusters; and nodes within each cluster dynamically elect a cluster head. The dataacquisition is carried out in two phases. In the first phase; cluster heads collect data fromtheir cluster nodes. In the second phase; cluster heads send collected data to the nodes thathave subscribed to the data. The cluster heads are re-elected to balance energyconsumption among the nodes in the cluster. Zhang et al.[13] have proposed an adaptive …,*,2009,2
Object matching for information integration: a profiler-based approach,B He; KC Chang,*,ACM Trans. Database Syst,2006,2
Making holistic schema matching robust: An ensemble framework with sampling and voting,Bin He; Kevin Chen-Chuan Chang,With the prevalence of databases on the Web;\emph {large scale} integration has become apressing problem. As an essential task;\emph {holistic schema matching}(ie; discoveringattribute correspondences among many schemas) has been actively studied recently. Asa``data mining" approach in nature; holistic schema matching; on one hand; benefits fromthe large scale of input schema data; while on the other hand; also suffers the problem ofnoises. Such noises often inevitably arise in the automatic extraction of schema data; whichis mandatory in large scale integration. For holistic matching to be viable; it is thus essentialto make it robust against noisy schemas. Toward this goal; we propose a novel``ensemble"framework; which aggregates a multitude of base holistic matchers to achieve robustness;by exploiting statistical sampling and majority voting: To begin with; we observe that Web …,*,2004,2
A holistic paradigm for schema matching,Bin He; Kevin Chen-Chuan Chang,Abstract Schema matching is a critical problem for integrating heterogeneous informationsources. Traditionally; the problem of matching multiple schemas has essentially relied onfinding pairwise-attribute correspondence. In contrast; we propose a new matchingparadigm; holistic schema matching; to holistically match many schemas at the same timeand find all the matchings at once. By handling a set of schemas together; we can exploretheir context information that reflects the semantic correspondences among attributes; whichis not available when schemas are matched only in pairs. As the realizations of the holisticparadigm; we developed two alternative approaches recently. This article takes an initialstep to unify those two approaches and further contrasts their strength and weakness.Specifically; we develop two alternative methods for realizing holistic schema matching …,SIGMOD Record,2004,2
Topological recurrent neural network for diffusion prediction,Jia Wang; Vincent W Zheng; Zemin Liu; Kevin Chen-Chuan Chang,Abstract: In this paper; we study the problem of using representation learning to assistinformation diffusion prediction on graphs. In particular; we aim at estimating the probabilityof an inactive node to be activated next in a cascade. Despite the success of recent deeplearning methods for diffusion; we find that they often underexplore the cascade structure.We consider a cascade as not merely a sequence of nodes ordered by their activation timestamps; instead; it has a richer structure indicating the diffusion process over the data graph.As a result; we introduce a new data model; namely diffusion topologies; to fully describe thecascade structure. We find it challenging to model diffusion topologies; which are dynamicdirected acyclic graphs (DAGs); with the existing neural networks. Therefore; we propose anovel topological recurrent neural network; namely Topo-LSTM; for modeling dynamic …,arXiv preprint arXiv:1711.10162,2017,1
Motif-based Convolutional Neural Network on Graphs,Aravind Sankar; Xinyang Zhang; Kevin Chen-Chuan Chang,Abstract: This paper introduces a generalization of Convolutional Neural Networks (CNNs)from regular grid-structured data such as images to graphs with irregular linkage structures;especially expressive heterogeneous graphs with typed nodes and schemas. We propose anovel spatial convolution operation to model the key aspects of a CNN: local connectivityand translation invariance; using higher-order structures. We use the concept of motif; whichprovides us flexibility to describe spatial locality in Heterogeneous graphs with respect to itsschema; or any graph with respect to desired higher-order connection patterns. We developa novel neural network architecture Motif-CNN that captures higher-order structural andfeature information by combining the information extracted from multiple patterns throughdeeper layers. Our experiments on semi-supervised learning tasks on social networks …,arXiv preprint arXiv:1711.05697,2017,1
Towards a Holistic Integration of Spreadsheets with Databases: A Scalable Storage Engine for Presentational Data Management,Mangesh Bendre; Vipul Venkataraman; Xinyan Zhou; Kevin Chen-Chuan Chang; Aditya Parameswaran,Abstract: Spreadsheet software is the tool of choice for interactive ad-hoc data management;with adoption by billions of users. However; spreadsheets are not scalable; unlike databasesystems. On the other hand; database systems; while highly scalable; do not supportinteractivity as a first-class primitive. We are developing DataSpread; to holistically integratespreadsheets as a front-end interface with databases as a back-end datastore; providingscalability to spreadsheets; and interactivity to databases; an integration we termpresentational data management (PDM). In this paper; we make a first step towards thisvision: developing a storage engine for PDM; studying how to flexibly represent spreadsheetdata within a database and how to support and maintain access by position. We first conductan extensive survey of spreadsheet use to motivate our functional requirements for a …,arXiv preprint arXiv:1708.06712,2017,1
Sociallens: Searching and browsing communities by content and interaction,Hongyun Cai; Vincent W Zheng; Penghe Chen; Fanwei Zhu; Kevin Chen-Chuan Chang; Zi Huang,Community analysis is an important task in graph mining. Most of the existing communitystudies are community detection; which aim to find the community membership for each userbased on the user friendship links. However; membership alone; without a complete profileof what a community is and how it interacts with other communities; has limited applications.This motivates us to consider systematically profiling the communities and therebydeveloping useful community-level applications. In this paper; we introduce a novel conceptof community profiling; upon which we build a SocialLens system1 to enable searching andbrowsing communities by content and interaction. We deploy SocialLens on two socialgraphs: Twitter and DBLP. We demonstrate two useful applications of SocialLens; includinginteractive community visualization and profile-aware community ranking.,Data Engineering (ICDE); 2017 IEEE 33rd International Conference on,2017,1
When do-gooders do harm: Accountability of the United Nations toward third parties in peace operations,Kevin C Chang,The United Nations' mandate in a peace operation can be multi-dimensional; ranging fromceasefire monitoring to investigating human rights abuses to post-conflict stabilisation andrecovery. The exercise of wide-ranging powers comes with risks of failure and unintendedconsequences. Like any organisation; the UN is subject to flaws in decision-making that mayresult in harmful impact to the local population. Until recent times; international lawyers havepaid scant attention to the UN's potential to inflict harm in the pursuit of its noble aims. Theexpansion of the UN's role over the decades has given rise to greater awareness of itsaccountability gap under international and municipal laws. The organisation's response torecent claims from third parties illustrates the challenges that lie before victims in attainingaccountability in a manner consistent with international human rights standards. This …,Journal of International Peacekeeping,2016,1
Regularizing structured classifier with conditional probabilistic constraints for semi-supervised learning,Vincent W Zheng; Kevin Chen-Chuan Chang,Abstract Constraints have been shown as an effective way to incorporate unlabeled data forsemi-supervised structured classification. We recognize that; constraints are oftenconditional and probabilistic; moreover; a constraint can have its condition depend on eitherjust observations (which we call x-type constraint) or even hidden variables (which we call y-type constraint). We wish to design a constraint formulation that can flexibly model theconstraint probability for both x-type and y-type constraints; and later use it to regularizegeneral structured classifiers for semi-supervision. Surprisingly; none of the existing modelshave such a constraint formulation. Thus in this paper; we propose a new conditionalprobabilistic formulation for modeling both x-type and y-type constraints. We also recognizethe inference complication for y-type constraint; and propose a systematic selective …,Proceedings of the 25th ACM International on Conference on Information and Knowledge Management,2016,1
Ushio: Analyzing News Media and Public Trends in Twitter,Fangzhou Yao; Kevin Chen-Chuan Chang; Roy H Campbell,In this information age; Social Networking Services contribute a significant amount ofcontents in creating a knowledge based society. Nowadays; there are more than 500 milliontweets sent per day in Twitter. Such drastic growth of contents brings new opportunities forhuman beings to discover their surroundings more effectively in a timely manner. Moreover;these types of services evolve not only in a perspective of scalability; but also in the view ofindicating more meaningful information regarding what happens in the world. Numerousnews agencies are broadcasting breaking news via Twitter and people would like to leavecomments with their own opinions as well. However; there are differences between eventsthat news media are more willing to cover and news stories that people are more interestedin. Furthermore; as people are becoming the largest sensor network; trending topics are …,Utility and Cloud Computing (UCC); 2015 IEEE/ACM 8th International Conference on,2015,1
An Efficient Mutual Authentication with Key Agreement Protocol for Mobile Devices,Jen-Ho Yang; Chin-Chen Chang; Shih-Yi Lin,Authentication with key agreement protocol (AKA) can provide mutual authentication andcreate a session key between two communication parties. In 2005; Chen and Yeh proposedan AKA protocol based on one-way hash function and exclusive-or (XOR) operations.Having the feature of fast processing; their protocol is more efficient than previously relatedworks. However; we discover that Chen and Yeh's protocol cannot withstand denial ofservice (DoS) attack. Moreover; their protocol has redundant communication rounds suchthat it is not efficient for mobile devices. Therefore; we propose an efficient AKA protocol formobile devices in this paper; which has lower computation and communication loads.Moreover; our protocol can prevent DoS attack and does not require a verification table inthe server. In a word; our AKA protocol is efficient and practical for mobile devices.,Intelligent Information Hiding and Multimedia Signal Processing (IIH-MSP); 2011 Seventh International Conference on,2011,1
Prevention of an alarm activation and supporting methods and apparatus,*,A method and apparatus for preventing false alarm activation is provided. According to oneembodiment of the invention; a determination (410) is made as to whether an instructionfrom a controller is a commanded reset; and control of a Subscriber Line Interface Circuit istaken (416) from a voice processor circuit when the instruction is a commanded reset.,*,2010,1
AIDE: ad-hoc intents detection engine over query logs,Yunliang Jiang; Hui-Ting Yang; Kevin Chen-Chuan Chang; Yi-Shin Chen,Abstract While keyword queries have become the" standard" query language of web searchand many other database applications; their brevity and unstructuredness make it difficult todetect what users really want. In this demonstration; we aim to detect such hidden queryintents; which we define as the frequent phrases that users co-ask with the query term; byexploring query logs. Toward building an online search system AIDE; we offer users thefunction to detect general and unique intents using arbitrary ad-hoc queries at run time. Wewill also demonstrate the effectiveness of the system which achieves indexing andsearching over 14M MSN query log records.,Proceedings of the 2009 ACM SIGMOD International Conference on Management of data,2009,1
Three Improved Codebook Searching Algorithms for Image Compression Using Vector Quantizer,-CC Chang; C-L Kuo; C-C Chen,Abstract In this paper; we propose three improved codebook searching algorithms for vectorquantization (VQ). Our improved schemes are based on three fast searching methodsproposed by Huang et al.; IEEE Transactions on Image Processing; 1 (3); 1992; 413–416and the double test (DT) method proposed by Torres and Huguet; IEEE Transactions onCommunications; 42 (2| 3| 4); 1994; 208–210. Compared with three codebook searchingschemes proposed by Huang et al.[9]; we find our proposed algorithms have betterperformance in terms of encoding time and distortion computations according to theexperimental results.,International Journal of Computers and Applications,2009,1
Exploring the deep web: Associativity search over schematic metadata,Govind Kabra; Zhen Zhang; Kevin Chen-Chuan Chang; Lipyeow Lim; Min Wang; Yuan-chi Chang,The Web has been rapidly deepened with the prevalence of databases online. As sourcesproliferate; while there are often useful; alternative; and related sources for our needs; weare lacking an effective facility to explore this" deep Web." For``ad-hoc users" and``systemintegrators" alike; to enable access and integration to the multitude of sources; we often mustanswer semantic association questions--How sources relate to each other? What"vocabularies" do they speak? Such semantic associativity is often revealed holisticallythrough cooccurrence analysis of``schematic metadata;''which describes the nature of dataat sources. We observe two interesting phenomena through the syntactic associativity ofsources and their schematic metadata: The first phenomenon; occurrence localities;suggests syntactic associativity as a useful notion for discovering semantic associativity …,*,2006,1
Discovering Attribute Locality across the Deep Web: an Ordering-Based Approach,Chengkai Li; Kevin Chen-Chuan Chang,Abstract The large number of structured database sources on the Web presents pressingneed for information integration at a large scale. How can we enable systematic access tothis “deep Web”? We observe that; while autonomous sources are seemingly independent;their query schemas often reveal certain correlations; such that sources in the samestructured domain (eg; books; cars) tend to share a “locality” of query attributes. This paperthus develops the notion of attribute localities; which is key for many schema-basedintegration tasks–such as source clustering and query mediation. Such attribute localities;while very useful; are computational expensive to discover. However; our observation furtherindicates that the localities are often self-revealing; when attributes are linearly ordered in acertain way; reflecting their connectivities. We thus further propose a novel ordering …,*,2003,1
System; method and graphical user interface for managing contacts and calendars within an online card system,*,Abstract A system; a method; and a user interface are described for personalizing andsending stationery/cards. A reminder list on the user interface includes a list of reminderentries each identifying an upcoming event including events generated based on a specifiedrelationship between the user and one or more contacts of the user. A recommendationregion is populated one or more recommended stationery/card designs associated with oneof the entries in the reminder list. A stationery/card personalization engine provides the userwith a set of personalization options related to the selected stationery/card design; andgenerates personalized stationery based on the selected stationery/card design and theuser input.,*,2018,*
Characterizing Scalability Issues in Spreadsheet Software using Online Forums,Kelly Mack; John Lee; Kevin Chang; Karrie Karahalios; Aditya Parameswaran,Abstract: In traditional usability studies; researchers talk to users of tools to understand theirneeds and challenges. Insights gained via such interviews offer context; detail; andbackground. Due to costs in time and money; we are beginning to see a new form of toolinterrogation that prioritizes scale; cost; and breadth by utilizing existing data from onlineforums. In this case study; we set out to apply this method of using online forum data to aspecific issue---challenges that users face with Excel spreadsheets. Spreadsheets are aversatile and powerful processing tool if used properly. However; with versatility and powercome errors; from both users and the software; which make using spreadsheets lesseffective. By scraping posts from the website Reddit; we collected a dataset of questions andcomplaints about Excel. Specifically; we explored and characterized the issues users …,arXiv preprint arXiv:1801.03829,2018,*
Distance-aware dag embedding for proximity search on heterogeneous graphs,Zemin Liu; Vincent W Zheng; Zhou Zhao; Fanwei Zhu; Kevin Chen-Chuan Chang; Minghui Wu; Jing Ying,Abstract Proximity search on heterogeneous graphs aims to measure the proximity betweentwo nodes on a graph wrt some semantic relation for ranking. Pioneer work often tries tomeasure such proximity by paths connecting the two nodes. However; paths as linearsequences have limited expressiveness for the complex network connections. In this paper;we explore a more expressive DAG (directed acyclic graph) data structure for modeling theconnections between two nodes. Particularly; we are interested in learning a representationfor the DAGs to encode the proximity between two nodes. We face two challenges to useDAGs; including how to efficiently generate DAGs and how to effectively learn DAGembedding for proximity search. We find distance-awareness as important for proximitysearch and the key to solve the above challenges. Thus we develop a novel Distance …,*,2018,*
Statistical Link Label Modeling for Sign Prediction: Smoothing Sparsity by Joining Local and Global Information,Amin Javari; HongXiang Qiu; Elham Barzegaran; Mahdi Jalili; Kevin Chen-Chuan Chang,One of the major issues in signed networks is to use network structure to predict the missingsign of an edge. In this paper; we introduce a novel probabilistic approach for the signprediction problem. The main characteristic of the proposed models is their ability to adapt tothe sparsity level of an input network. Building a model that has an ability to adapt to thesparsity of the data has not yet been considered in the previous related works. We suggestthat there exists a dilemma between local and global structures and attempt to build sparsityadaptive models by resolving this dilemma. To this end; we propose probabilistic predictionmodels based on local and global structures and integrate them based on the concept ofsmoothing. The model relies more on the global structures when the sparsity increases;whereas it gives more weights to the information obtained from local structures for low …,Data Mining (ICDM); 2017 IEEE International Conference on,2017,*
Relationship Profiling over Social Networks: Reverse Smoothness from Similarity to Closeness,Carl Yang; Kevin Chen-Chuan Chang,Abstract: On social networks; while nodes bear rich attributes; we often lack thesemantics' ofwhy each link is formed--and thus we are missing theroad signs' to navigate and organizethe complex social universe. How to identify relationship semantics without labels? Foundedon the prevalent homophily principle; we propose the novel problem of Attribute-basedRelationship Profiling (ARP); to profile the closeness wrt the underlying relationships (eg;schoolmate) between users based on their similarity in the corresponding attributes (eg;education) and; as output; learn a set of social affinity graphs; where each link is weightedby its probabilities of carrying the relationships. As requirements; ARP should be systematicand complete to profile every link for every relationship--our challenges lie in effectivelymodeling homophily. We propose a novel reverse smoothness principle by observing that …,arXiv preprint arXiv:1710.01363,2017,*
CONE: Community Oriented Network Embedding,Carl Yang; Hanqing Lu; Kevin Chen-Chuan Chang,Abstract: Detecting communities has long been popular in the research on networks. It isusually modeled as an unsupervised clustering problem on graphs; based on heuristicassumptions about community characteristics; such as edge density and node homogeneity.In this work; we doubt the universality of these widely adopted assumptions and comparehuman labeled communities with machine predicted ones obtained via various mainstreamalgorithms. Based on supportive results; we argue that communities are defined by varioussocial patterns and unsupervised learning based on heuristics is incapable of capturing allof them. Therefore; we propose to inject supervision into community detection throughCommunity Oriented Network Embedding (CONE); which leverages limited ground-truthcommunities as examples to learn an embedding model aware of the social patterns …,arXiv preprint arXiv:1709.01554,2017,*
Dynamic Model and Motion Control of a Robotic Manipulator,Jinho Kim; Kevin Chang; Brian Schwarz; Andrew S Lee; S Andrew Gadsden; Mohammad Al-Shabi,*,JOURNAL OF ROBOTICS NETWORKING AND ARTIFICIAL LIFE,2017,*
Active Learning for Graph Embedding,Hongyun Cai; Vincent W Zheng; Kevin Chen-Chuan Chang,Abstract: Graph embedding provides an efficient solution for graph analysis by convertingthe graph into a low-dimensional space which preserves the structure information. Incontrast to the graph structure data; the iid node embedding can be processed efficiently interms of both time and space. Current semi-supervised graph embedding algorithmsassume the labelled nodes are given; which may not be always true in the real world. Whilemanually label all training data is inapplicable; how to select the subset of training data tolabel so as to maximize the graph analysis task performance is of great importance. Thismotivates our proposed active graph embedding (AGE) framework; in which we design ageneral active learning query strategy for any semi-supervised graph embedding algorithm.AGE selects the most informative nodes as the training labelled nodes based on the …,arXiv preprint arXiv:1705.05085,2017,*
Dynamic Modeling and Motion Control of a Three-Link Robotic Manipulator,Jinho Kim; Andrew S Lee; Kevin Chang; Brian Schwarz; S Andrew Gadsden; Mohammad Al-Shabi,Abstract This paper presents the dynamic modeling and motion control of a three-link roboticmanipulator; also known as the RRR robot. The Kinect motion capture system by Microsoft isused in conjunction with the manipulator. A camera is used to capture the motion of a user'sarm and tracks certain angles made by parts of the arm. We consider a pinhole cameramodel to generate reference angles as per a pinhole camera model in our simulations.These desired angles are fed into the controller and are used by the RRR robot in an effortto copy the movement of the user. A proportionalderivative (PD) controller is developed andapplied to the manipulator for improved trajectory tracking. The RRR robot manipulator isdynamically modeled and the results of the proposed control strategy demonstrate goodtrajectory following.,*,2017,*
Analyte-testing device,*,A device adapted to determine an analyte concentration of a fluid sample using a testsensor. The device comprises a display adapted to display information to a user. The devicefurther comprises at least one user-interface mechanism adapted to allow the user to interactwith the device. The device further comprises a body portion including at least one openingformed therein; the at least one opening being of sufficient size to receive the test sensor.The device further comprises a memory adapted to store a plurality of stored analyteconcentrations. The device further comprises a processing feature adapted to inhibit thestored analyte concentrations from being displayed on the display.,*,2016,*
Network Cartography: Seeing the Forest and the Trees,Jia Wang; Kevin Chen-Chuan Chang; Hari Sundaram,Abstract: Real-world networks are often complex and large with millions of nodes; posing agreat challenge for analysts to quickly see the big picture for more productive subsequentanalysis. We aim at facilitating exploration of node-attributed networks by creatingrepresentations with conciseness; expressiveness; interpretability; and multi-resolutionviews. We develop such a representation as a {\it map}---among the first to exploreprincipled network cartography for general networks. In parallel with common maps; ourshas landmarks; which aggregate nodes homogeneous in their traits and interactions withnodes elsewhere; and roads; which represent the interactions between the landmarks. Wecapture such homogeneity by the similar roles the nodes played. Next; to concretely modelthe landmarks; we propose a probabilistic generative model of networks with roles as …,arXiv preprint arXiv:1512.06021,2015,*
IntelligShop: Enabling Intelligent Shopping in Malls through Location-based Augmented Reality,Aditi Adhikari; Vincent W Zheng; Hong Cao; Miao Lin; Yuan Fang; Kevin Chen-Chuan Chang,Shopping experience is important for both citizens and tourists. We present IntelligShop; anovel location-based augmented reality application that supports intelligent shoppingexperience in malls. As the key functionality; IntelligShop provides an augmented realityinterface--people can simply use ubiquitous smartphones to face mall retailers; thenIntelligShop will automatically recognize the retailers and fetch their online reviews fromvarious sources (including blogs; forums and publicly accessible social media) to display onthe phones. Technically; IntelligShop addresses two challenging data mining problems;including robust feature learning to support heterogeneous smartphones in localization andlearning to query for automatically gathering the retailer content from the Web for augmentedreality. We demonstrate the system effectiveness via a test bed established in a real mall …,Data Mining Workshop (ICDMW); 2015 IEEE International Conference on,2015,*
Towards a Social Media Analytics Platform: Event Detection and User Profiling for Microblogs,Manish Gupta; Kevin Chang; Rui Li,– `2m'; `2ma'; `2mar'; `2mara'; `2maro'; `2marrow'; `2mor'; `2mora'; `2moro'; `2morow'; `2morr';`2morro'; `2morrow'; `2moz'; `2mr'; `2mro'; `2mrrw'; `2mrw'; `2mw'; `tmmrw' … `tmo'; `tmoro';`tmorrow'; `tmoz'; `tmr'; `tmro'; `tmrow'; `tmrrow'; `tmrrw'; `tmrw' … `tmrww'; `tmw'; `tomaro';`tomarow'; `tomarro'; `tomarrow'; `tomm'; `tommarow' … `tommarrow'; `tommoro';`tommorow'; `tommorrow'; `tommorw'; `tommrow'; `tomo' … `tomolo'; `tomoro'; `tomorow';`tomorro'; `tomorrw'; `tomoz'; `tomrw'; `tomz' … – “The Hobbit has FINALLY started filming! I cannotwait!” … – Read each sentence from today's New York times … – Finding Best Phrase to Summarizean Event … – Finding Best Phrase to Summarize an Event … – Tweet waves travel faster thanearthquake waves … • Showing 10 relevant tweets is not a great idea; since … • Will look atapplications of event detection … • Twitter partnered with the third-party website,*,2014,*
Walking forward and backward: Towards graph-based searching and mining,Yuan Fang,Abstract Graphs are powerful vehicles to represent data objects that are interconnecting orinteracting with each other. We explore random walks on various kinds of graph to addressdifferent searching and mining scenarios. This dissertation focuses on two symmetric formsof random walk called the forward walk and backward walk; which can be applied to enrichthree key tasks in searching and mining; namely; extraction; ranking and classification; innovel ways. More specifically; we enhance extraction with the metrics of probabilisticprecision and recall; ranking with the senses of importance and specificity; and classificationwith heterogeneous contexts in terms of relationship type and confidence level. We furtherstudy the underpinning principle of random walks on a graph; which is often known as thesmoothness assumption. We argue that smoothness is a pointwise property and requires …,*,2014,*
2013 Index IEEE Transactions on Reliability Vol. 62,AM Abouammoh; F Aguirre; IA Ahmad; H Aliee; S Anastasiadis; JE Angus; DL Antzoulakos; C Argyrides; R Arnold; M Asadi; N Balakrishnan; P Baraldi; I Bayramoglu; H Ben-Haim; CAV Cavalcante; JH Cha; CC Chang; PC Chang; E Chen; IR Chen; M Chen; TY Chen,This index covers all technical items-papers; correspondence; reviews; etc.-that appeared inthis periodical during the year; and items from previous years that were commented upon orcorrected in this year. Departments and other items may also be covered if they have beenjudged to have archival value. The Author Index contains the primary entry for each item;listed under the first author's name. The primary entry includes the co-authors' names; thetitle of the paper or other item; and its location; specified by the publication abbreviation;year; month; and inclusive pagination. The Subject Index contains entries describing theitem under all appropriate subject headings; plus the first author's name; the publicationabbreviation; month; and year; and inclusive pages. Note that the item title is found onlyunder the primary entry in the Author Index.,IEEE Transactions on Reliability,2013,*
Service Culture Construction of Libraries Based on Humanist Harmony,Ya-juan WANG; Pei-ying ZHAO; Chen CHANG; Jie-hui WANG,It is stated the ideas; methods and ways of service culture construction from the meaningsand requirements of the service culture in the library. And these can play certain referenceroles for constructing the colleges' libraries.,Journal of Tianjin Agricultural University,2012,*
Web-Scale Search-Based Data Extraction and Integration,Kevin C Chang; Truman Shuck; Govind Kabra,Abstract: In the current age of abundant; digitized geographic data; the classic; manualapproach to geospatial feature discovery and gazetteer creation is cost-prohibitive. Whilegeographic data has become increasingly prevalent on the open Web; it remains largelyunstructured and difficult to study. This; the GeoEngine project; has developed generalizablemethods for automatic gazetteer generation based on the ample; but unstructured data onthe open Web. GeoEngine solves this problem with a three tiered architecture: automaticdata discovery and extraction; machine-based semantic aggregation and human validation.GeoEngine has produced specific; but generalizable solutions in the following areas: sub-city feature discovery in domestic and foreign locales; neighborhood boundary discoveryand refinement; physical feature gazetteer generation and attribute addition; Wikipedia …,*,2011,*
Toward large scale data-aware search: Ranking; indexing; resolution and beyond,Tao Cheng; Kevin Chen-Chuan Chang,As the Web has evolved into a data-rich repository; with the standard “page view;” currentsearch engines are becoming increasingly inadequate. To realize data-aware search;toward searching for data entities on the Web; we have been developing the various aspectsof an entity search system; including: entity ranking; entity indexing and parallelization; entityresolution; as well as generalization and customization. Preliminary results show thepromise of our proposals; achieving high accuracy; efficiency and scalability. We will alsosummarize our contributions and point out interesting future directions along the line ofenabling data-aware search on the Web.,Data Engineering Workshops (ICDEW); 2010 IEEE 26th International Conference on,2010,*
DoCQS: A System for Supporting Data-oriented Querying over Web Content,Mianwei Zhou; Tao Cheng; Kevin Chen-Chuan Chang,ABSTRACT Witnessing the richness of data in document content and many ad-hoc efforts forfinding such data; we propose a Data-oriented Content Query System (DoCQS); which isoriented towards fine granularity data of all types by searching directly into documentcontent. DoCQS uses the relational model as the underlying data model; and offers apowerful and flexible Content Query Language (CQL) to adapt to diverse query demands. Inthis demonstration; we show how to model various search tasks by CQL statements; andhow the system architecture efficiently supports the CQL execution. Our online demo of thesystem is available at http://wisdm. cs. uiuc. edu/demos/docqs/.,*,2010,*
Integration at Web-Scale: Scalable Agent Technology for Enabling Structured Vertical Search,Govind Kabra; Kevin Chang,The Web today has``everything'': Every object of interest in real world is starting to find itspresence in the online World. As such; the search needs of users are getting increasinglysophisticated. How do you search for apartments? How do you find products to buy?Traditional paradigm of Web search; starting from keyword input; and ending in Web pagesas output; stifles users---requiring intensive manual post-processing of search results. As thesolution; we present a platform for enabling vertical search. At the core is our novel agenttechnology for structured crawling. We showcase the promise of our platform using twoconcrete products that clearly demonstrate the possibility of Integration at Web-Scale. Thetalk will show demos of two concrete products (apartment search; shopping search) and keyunderlying technologies. The slides are attached in pdf format. The power-point version …,*,2009,*
An Efficient Key-Lock-Pair Mechanism Based on Division Algorithm,Hui-Feng Huang; Chin-Chen Chang,In the access control of a file system; the Chinese remainder theorem (CRT) is a methodused to establish the key-lock-pair mechanism; However; the key computed using CRTtakes much more time to add up a new file. In order to improve upon this; we show that thekey-lock-pair mechanism based on the division algorithm can be extended very efficientlywhen a file is added to the file system. Also; it can be applied to delete a file or to update theaccess rights of a file in the file system. Therefore; the proposed method is very useful for thedynamic file system.,Multimedia and Ubiquitous Engineering; 2007. MUE'07. International Conference on,2007,*
Contextual Indexing and Joining: Supporting Efficient; Scalable Entity Search,Tao Cheng; Kevin Chen-Chuan Chang,As the Web has evolved into an entity abundant repository; with the standard``page view'';current search engines are becoming increasingly inadequate for a wide range of querytasks. Entity search; a significant departure from document retrieval; finds fine granularityinformation; ie; entities; embedded in documents directly and holistically across the wholecollection. Essentially; entity search is to find matching entities by context patterns from eachdocument and to aggregate them across documents for ranking. This text-based patternmatching suggests that standard inverted lists-based query processing can be applied.However; this baseline is limited in both efficiency; due to long entity lists; and scalability;due to cross-document aggregation. To enhance efficiency; we propose``contextual index'';an index that materializes pre-joins; to eliminate unnecessary index reading and reduce …,*,2007,*
Content-Based Retrieval Concept,Yung-Kuan Chan; Chin-Chen Chang,Abstract Because of the demand for efficient management in images; much attention hasbeen paid to image retrieval over the past few years. The text-based image retrieval systemis commonly used in traditional search engines (Ratha et al.; 1996); where a query isrepresented by keywords that are usually identified and classified by human beings. Sincepeople have different understandings on a particular image; the consistency is difficult tomaintain. When the database is larger; it is arduous to describe and classify the imagesbecause most images are complicated and have many different objects. There has been atrend towards developing the content-based retrieval system; which tries to retrieve imagesdirectly and automatically based on their visual contents.,*,2005,*
A framework for one-round mobile agent transaction,Chi-Chao Chang; Narn-Yih Lee; Tzonelih Hwang,Mobile agent systems are essential in the next generation of electronic commercialapplications. However; existing solutions for mobile agents to sign documents without userintervention are problematic because there is no restriction on who can generate thesignatures. In this paper; we present a modified version of undetachable signature schemewith which the power to generate digital signatures can be designated to a neutral party. Wealso give a transaction model to support the scheme. Discussions regarding the security ofthe signature scheme as well as some attacks on its application in our model are presentedtoo.,IEICE transactions on communications,2004,*
Weaving Entities into Relations: From Page Retrieval to Relation Mining on the Web,Joseph M Kelley; Kevin Chen-Chuan Chang; Tao Cheng; Shui-Lung Chuang; William Davis,With its sheer amount of information; the Web is clearly an important frontier for data mining.While Web mining must start with content on the Web; there is no effective``search-based''mechanism to help sifting through the information on the Web. Our goal is to providea such online search-based facility for supporting query primitives; upon which Web miningapplications can be built. As a first step; this paper aims at entity-relation discovery; or ERdiscovery; as a useful function--to weave scattered entities on the Web into coherentrelations. To begin with; as our proposal; we formalize the concept of ER discovery. Further;to realize ER discovery; as our main thesis; we abstract tuple ranking--the essentialchallenge of ER discovery--as pattern-based cooccurrence analysis. Finally; as our keyinsight; we observe that such relation mining shares the same core functions as …,*,2004,*
Light-weight Domain-based Form Assistant: Querying Databases on the Web,Zhen Zhang; Bin He; Kevin Chen-Chuan Chang,The Web has been rapidly``deepened" by myriad searchable databases online; where dataare hidden behind query forms. Helping users query alternative``deep Web" sources in thesame domain (\eg; Books; Airfares) is an important task with broad applications. As a corecomponent of those applications; dynamic query translation (\ie; translating a user's queryacross dynamically selected sources) has not been extensively explored. While existingworks focus on isolated subproblems (\eg; schema matching; query rewriting) to study; wetarget at building a complete query translator and thus face new challenges: 1) To completethe translator; we need to solve the\emph {predicate mapping} problem (\ie; map a sourcepredicate to target predicates); which is largely unexplored by existing works; 2) To satisfyour application requirements; we need to design a customizable system architecture to …,*,2004,*
Database research at the University of Illinois at Urbana-Champaign,Marianne Winslett; K Chang; A Doan; Jiawei Han; ChengXiang Zhai; Yuanyuan Zhou,The Department of Computer Science at the University of Illinois at Urbana-Champaign(UIUC) has identified the area of information systems; broadly construed; as one of threecore areas for the department's future directions. In tandem with a mandate from the UIUCCollege of Engineering for the department to double its number of tenure-track faculty; thisfocus on information systems has resulted in a significant expansion of the number of facultyin the department in the database area over the past few years. Our roster currently includesMarianne Winslett; who joined the department in 1987; Kevin Chang and Jiawei Han; whojoined us in 2000 and 2001; respectively; and AnHai Doan; Chengxiang Zhai; andYuanyuan Zhou; who joined the department in 2002. In the near future; we plan to round outthe information systems group with additional hires of senior faculty.,ACM SIGMOD Record,2002,*
Network System Challenges in Selective Sharing and Verification for Personal; Social; and Urban,Mani B Srivastava; Jeffrey A Burke; Mark Hansen; Andrew Parker; Sasank Reddy; Thomas Schmid; Kevin Chang; Saurabh Ganeriwal; Mark Allman; Vern Paxson; D Estrin,*,Info:,*,*
PEBL: Web Page Classification without Negative Examples,Jiawei Han; Kevin Chen-Chuan Chang,*,*,*,*
Motion Capture Control of a Nano Quadrotor,Kevin Chang; Jin H Kim; Stephen A Wilkerson; S Andrew Gadsden,Abstract–Motion capture control of quadrotors is a relatively well known and establishedmethod of researching quadrotor flight dynamics. However; these capture systems areusually very expensive because they require many cameras; a large space; and relativelylarge quadrotors. In this project; we explore the viability of using a minimally sized motioncapture camera setup to serve as a framework for autonomous flight of a quadrotor. Thesystem that we utilize consists of four Optitrack Motion capture cameras; a Crazyflie 2.0Nano-quadrotor; and a Pixhawk flight controller. The Optitrack cameras capture the preciseposition of the quadrotor within a predefined capture volume. The positional information issent to a ground station computer via Ethernet. The positional data is then processed andsent wirelessly to the quadrotor. This system will serve as a proof of concept that smaller …,*,*,*
Using Distributed Objects to Build the Stanford Digital Library Infobus,Q Michelle; K Chang; Steve Cousins,*,*,*,*
Scaling up to Billions of Cells with DATASPREAD: Supporting Large Spreadsheets with Databases,Mangesh Bendre; Vipul Venkataraman; Xinyan Zhou; Kevin Chen-Chuan Chang; Aditya Parameswaran,ABSTRACT Spreadsheet software is the tool of choice for ad-hoc tabular data management;manipulation; querying; and visualization with adoption by billions of users. However;spreadsheets are not scalable; unlike database systems. We develop DATASPREAD; asystem that holistically unifies databases and spreadsheets with a goal to work with massivespreadsheets: DATASPREAD retains all of the advantages of spreadsheets; including easeof use; ad-hoc analysis and visualization capabilities; and a schema-free nature; while alsoadding the scalability and collaboration abilities of traditional relational databases. Wedesign DATASPREAD with a spreadsheet front-end and a regular relational database back-end. To integrate spreadsheets and databases; in this paper; we develop a storage andindexing engine for spreadsheet data. We first formalize and study the problem of …,*,*,*
ARISE-PIE: A People Information Integration Engine over the Web,Vincent W Zheng; Tao Hoang; Penghe Chen; Yuan Fang; Xiaoyan Yang; Kevin Chen-Chuan Chang,ABSTRACT Searching for people information on the Web is a common practice in life.However; it is time consuming to search for such information manually. In this paper; we aimto develop an automatic people information search system; named ARISE-PIE. To buildsuch a system; we tackle two major technical challenges: data harvesting and dataintegration. For data harvesting; we study how to leverage search engine to help crawl therelevant Web pages for a target entity; then we propose a novel learning to query model thatcan automatically select a set of “best” queries to maximize collective utility (eg; precision orrecall). For data integration; we study how to leverage flexible forms of constraints as weaksupervision to achieve collective information extraction from a target entity's Web pagecorpus; then we propose a novel conditional probabilistic formulation to model constraints …,*,*,*
Computer Science Department Stanford University,Luis Gravano; Chen-Chuan K Chang,*,*,*,*
STARTS: Stanford Proposal for Internet Meta-Searching,Andreas Paepcke,Abstract Document sources are available everywhere; both within the internal networks oforganizations and on the Internet. Even individual organizations use search engines from dierent vendors to index their internal document collections. These search engines aretypically incompatible in that they support di erent query models and interfaces; they do notreturn enough information with the query results for adequate merging of the results; andnally; in that they do not export metadata about the collections that they index (eg; to assist inresource discovery). This paper describes STARTS; an emerging protocol for Internetretrieval and search that facilitates the task of querying multiple document sources. STARTShas been developed in a unique way. It is not a standard; but a group e ort coordinated byStanford's Digital Library project; and involving over 11 companies and organizations …,*,*,*
Large Scale Integration over the Deep Web: Frontier; State of the Art; and Research Directions,Kevin C Chang; Bin He,*,*,*,*
Integration at Web-scale: Cazoodle’s Agent Technology for Enabling Vertical Search,Kevin Chen-Chuan Chang; Govind Kabra; Quoc Le; Yuping Tseng,ABSTRACT The Web today has “everything”: Every object of interest in real world is startingto find its presence in the online World. As such; the search needs of users are gettingincreasingly sophisticated. How do you search for apartments? How do you find products tobuy? Traditional paradigm of Web search; starting from keyword input; and ending in Webpages as output; stifles users—requiring intensive manual post-processing of search results.As solution; Cazoodle has developed technology for enabling Web-scale vertical search. Atthe core is our agent technology for accurately crawling and indexing of structured data onthe Web; with low cost of maintenance. We demonstrate the possibilities of integration atWeb-scale using vertical search applications in two domains—Apartment Search(http://apartments. cazoodle. com) for finding rental apartments anywhere in US; and …,Programme Chairs,*,*
Graph-based Semi-supervised Learning: Realizing Pointwise Smoothness Probabilistically.(2014). Research Collection School Of Information Systems,Yuan Fang; Kevin Chen-Chuan Chang; Hady Wirawan Lauw,Abstract As the central notion in semi-supervised learning; smoothness is often realized on agraph representation of the data. In this paper; we study two complementary dimensions ofsmoothness: its pointwise nature and probabilistic modeling. While no existing graph-basedwork exploits them in conjunction; we encompass both in a novel framework of ProbabilisticGraph-based Pointwise Smoothness (PGP); building upon two foundational models of datacloseness and label coupling. This new form of smoothness axiomatizes a set of probabilityconstraints; which ultimately enables class prediction. Theoretically; we provide an error androbustness analysis of PGP. Empirically; we conduct extensive experiments to show theadvantages of PGP.,*,*,*
Message from The Second International Workshop on Challenges in Web Information Retrieval and Integration (WIRI 2006) Co-Chairs,Jun Adachi; Kevin C Chang; Wang Shan; Athena Vakali,This volume includes selected papers from the International Workshop on Challenges inWeb Information Retrieval and Integration (WIRI 2006); which was held in conjunction withthe 22nd International Conference on Data Engineering (ICDE 2006); held in Atlanta;Georgia; USA; April 3-7; 2006. Web information retrieval has become a critical and emergingresearch area due to the exponential increase in the information availability anddissemination over the Web. Many challenging problems must be solved toward utilizingand exploiting the vast Web information sources which are highly heterogeneous anddynamic. Therefore; new research ideas or practices in this area are of crucial importancedue to the difficulties raised by the diversity of the Web data structure and representation; theinformation distribution; and the communication and accessing costs. This workshop …,*,*,*
Graph-based Semi-supervised Learning: Realizing Pointwise Smoothness Probabilistically (Supplementary Material),Yuan Fang; Kevin Chen-Chuan Chang; Hady W Lauw,The full proofs for all propositions can be found in this section. The propositions themselvesand necessary equations are reproduced here for convenience. All equations are re-numbered in this document; which may have different numbering from the main paper.Unless explicitly stated; all equation references are self-contained in this document. In ournotation; all unquantified indices such as i; j; k range from 1 to| X|; unless stated explicitly.,*,*,*
What Shape Research?,Kevin C Chang,● 1988: Laguna Beach meeting–sponsored by ICSI at Berkeley (Stonebraker)–primarily inthe system area (no theory representatives)● 1990: Lagunita I report–organized by NSF DBand Expert Systems Program director–aimed at a broader representation of the DBcommunity● 1995: Lagunita II report● 1996: ACM Workshop–strategic directions incomputing research–as a part of its 50th anniversary celebration,*,*,*
