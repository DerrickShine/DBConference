SPIRIT: Sequential pattern mining with regular expression constraints,Minos N Garofalakis; Rajeev Rastogi; Kyuseok Shim,Abstract Discovering sequential patterns is an important problem in data mining with a hostof application domains including medicine; telecommunications; and the World Wide Web.Conventional mining systems provide users with only a very restricted mechanism (basedon minimum support) for specifying patterns of interest. In this paper; we propose the use ofRegular Expressions (REs) as a flexible constraint specification tool that enables user-controlled focus to be incorporated into the pattern mining process. We develop a family ofnovel algorithms (termed SPIRIT–Sequential Pattern mIning with Regular expressIonconsTraints) for mining frequent sequential patterns that also satisfy user-specified REconstraints. The main distinguishing factor among the proposed schemes is the degree towhich the RE constraints are enforced to prune the search space of patterns during …,VLDB,1999,646
Approximate query processing using wavelets,Kaushik Chakrabarti; Minos Garofalakis; Rajeev Rastogi; Kyuseok Shim,Abstract Approximate query processing has emerged as a cost-effective approach fordealing with the huge data volumes and stringent response-time requirements of today'sdecision support systems (DSS). Most work in this area; however; has so far been limited inits query processing scope; typically focusing on specific forms of aggregate queries.Furthermore; conventional approaches based on sampling or histograms appear to beinherently limited when it comes to approximating the results of complex queries over high-dimensional DSS data sets. In this paper; we propose the use of multi-dimensional waveletsas an effective tool for general-purpose approximate query processing in modern; high-dimensional applications. Our approach is based on building wavelet-coefficient synopsesof the data and using these synopses to provide approximate answers to queries. We …,The VLDB Journal—The International Journal on Very Large Data Bases,2001,576
Efficient filtering of XML documents with XPath expressions,C-Y Chan; Pascal Felber; Minos Garofalakis; Rajeev Rastogi,Abstract The publish/subscribe paradigm is a popular model for allowing publishers (ie; datagenerators) to selectively disseminate data to a large number of widely dispersedsubscribers (ie; data consumers) who have registered their interest in specific informationitems. Early publish/subscribe systems have typically relied on simple subscriptionmechanisms; such as keyword or” bag of words” matching; or simple comparison predicateson attribute values. The emergence of XML as a standard for information exchange on theInternet has led to an increased interest in using more expressive subscription mechanisms(eg; based on XPath expressions) that exploit both the structure and the content of publishedXML documents. Given the increased complexity of these new data-filtering mechanisms;the problem of effectively identifying the subscription profiles that match an incoming XML …,The VLDB Journal—The International Journal on Very Large Data Bases,2002,565
Adaptive cleaning for RFID data streams,Shawn R Jeffery; Minos Garofalakis; Michael J Franklin,Abstract To compensate for the inherent unreliability of RFID data streams; most RFIDmiddleware systems employ a" smoothing filter"; a sliding-window aggregate thatinterpolates for lost readings. In this paper; we propose SMURF; the first declarative;adaptive smoothing filter for RFID data cleaning. SMURF models the unreliability of RFIDreadings by viewing RFID streams as a statistical sample of tags in the physical world; andexploits techniques grounded in sampling theory to drive its cleaning processes. Throughthe use of tools such as binomial sampling and π-estimators; SMURF continuously adaptsthe smoothing window size in a principled manner to provide accurate RFID data toapplications.,Proceedings of the 32nd international conference on Very large data bases,2006,529
Processing complex aggregate queries over data streams,Alin Dobra; Minos Garofalakis; Johannes Gehrke; Rajeev Rastogi,Abstract Recent years have witnessed an increasing interest in designing algorithms forquerying and analyzing streaming data (ie; data that is seen only once in a fixed order) withonly limited memory. Providing (perhaps approximate) answers to queries over suchcontinuous data streams is a crucial requirement for many application environments;examples include large telecom and IP network installations where performance data fromdifferent parts of the network needs to be continuously collected and analyzed. In this paper;we consider the problem of approximately answering general aggregate SQL queries overcontinuous data streams with limited memory. Our method relies on randomizing techniquesthat compute small" sketch" summaries of the streams that can then be used to provideapproximate answers to aggregate queries with provable guarantees on the …,Proceedings of the 2002 ACM SIGMOD international conference on Management of data,2002,396
Secure XML querying with security views,Wenfei Fan; Chee-Yong Chan; Minos Garofalakis,Abstract The prevalent use of XML highlights the need for a generic; flexible access-controlmechanism for XML documents that supports efficient and secure query access; withoutrevealing sensitive information unauthorized users. This paper introduces a novel paradigmfor specifying XML security constraints and investigates the enforcement of such constraintsduring XML query evaluation. Our approach is based on the novel concept of security views;which provide for each user group (a) an XML view consisting of all and only the informationthat the users are authorized to access; and (b) a view DTD that the XML view conforms to.Security views effectively protect sensitive data from access and potential inferences byunauthorized user; and provide authorized users with necessary schema information tofacilitate effective query formulation and optimization. We propose an efficient algorithm …,Proceedings of the 2004 ACM SIGMOD international conference on Management of data,2004,344
Querying and mining data streams: you only get one look a tutorial,Minos Garofalakis; Johannes Gehrke; Rajeev Rastogi,Traditional Database Management Systems (DBMS) software is built on the concept ofpersistent data sets; that are stored reliably in stable storage and queried/updated severaltimes throughout their lifetime. For several emerging application domains; however; dataarrives and needs to be processed on a continuous (24 x 7) basis; without the benefit ofseveral passes over a static; persistent data image. Such continuous data streams arisenaturally; for example; in the network installations of large Telecom and Internet serviceproviders where detailed usage information (Call-Detail-Records (CDRs); SNMP/RMONpacket-flow data; etc.) from different parts of the underlying network needs to becontinuously collected and analyzed for interesting trends. Other applications that generaterapid; continuous and large volumes of stream data include transactions in retail chains …,Proceedings of the 2002 ACM SIGMOD international conference on Management of data,2002,322
XTRACT: a system for extracting document type descriptors from XML documents,Minos Garofalakis; Aristides Gionis; Rajeev Rastogi; Sridhar Seshadri; Kyuseok Shim,Abstract XML is rapidly emerging as the new standard for data representation and exchangeon the Web. An XML document can be accompanied by a Document Type Descriptor (DTD)which plays the role of a schema for an XML data collection. DTDs contain valuableinformation on the structure of documents and thus have a crucial role in the efficient storageof XML data; as well as the effective formulation and optimization of XML queries. In thispaper; we propose XTRACT; a novel system for inferring a DTD schema for a database ofXML documents. Since the DTD syntax incorporates the full expressive power of regularexpressions; naive approaches typically fail to produce concise and intuitive DTDs. Instead;the XTRACT inference algorithms employ a sequence of sophisticated steps that involve:(1)finding patterns in the input sequences and replacing them with regular expressions to …,ACM SIGMOD Record,2000,321
Topology discovery in heterogeneous IP networks,Yuri Breitbart; Minos Garofalakis; Cliff Martin; Rajeev Rastogi; S Seshadri; Avi Silberschatz,Knowledge of the up-to-date physical topology of an IP network is crucial to a number ofcritical network management tasks; including reactive and proactive resource management;event correlation; and root-cause analysis. Given the dynamic nature of today's IP networks;keeping track of topology information manually is a daunting (if not impossible) task. Thus;effective algorithms for automatically discovering physical network topology are necessary.Earlier work has typically concentrated on either:(a) discovering logical (ie; layer-3)topology; which implies that the connectivity of all layer-2 elements (eg; switches andbridges) is ignored; or (b) proprietary solutions targeting specific product families. In thispaper; we present novel algorithms for discovering physical topology in heterogeneous (ie;multi-vendor) IP networks. Our algorithms rely on standard SNMP MIB information that is …,INFOCOM 2000. Nineteenth Annual Joint Conference of the IEEE Computer and Communications Societies. Proceedings. IEEE,2000,304
Declarative networking: language; execution and optimization,Boon Thau Loo; Tyson Condie; Minos Garofalakis; David E Gay; Joseph M Hellerstein; Petros Maniatis; Raghu Ramakrishnan; Timothy Roscoe; Ion Stoica,Abstract The networking and distributed systems communities have recently explored avariety of new network architectures; both for application-level overlay networks; and asprototypes for a next-generation Internet architecture. In this context; we have investigateddeclarative networking: the use of a distributed recursive query engine as a powerful vehiclefor accelerating innovation in network architectures [23; 24; 33]. Declarative networkingrepresents a significant new application area for database research on recursive queryprocessing. In this paper; we address fundamental database issues in this domain. First; wemotivate and formally define the Network Datalog (NDlog) language for declarative networkspecifications. Second; we introduce and prove correct relaxed versions of the traditionalsemi-naïve query evaluation technique; to overcome fundamental problems of the …,Proceedings of the 2006 ACM SIGMOD international conference on Management of data,2006,280
Topology discovery in heterogeneous IP networks: the NetInventory system,Yuri Breitbart; Minos Garofalakis; Ben Jai; Cliff Martin; Rajeev Rastogi; Avi Silberschatz,Abstract Knowledge of the up-to-date physical topology of an IP network is crucial to anumber of critical network management tasks; including reactive and proactive resourcemanagement; event correlation; and root-cause analysis. Given the dynamic nature oftoday's IP networks; keeping track of topology information manually is a daunting (if notimpossible) task. Thus; effective algorithms for automatically discovering physical networktopology are necessary. Earlier work has typically concentrated on either 1) discoveringlogical (ie; layer-3) topology; which implies that the connectivity of all layer-2 elements (eg;switches and bridges) is ignored; or 2) proprietary solutions targeting specific productfamilies. In this paper; we present novel algorithms for discovering physical topology inheterogeneous (ie; multi-vendor) IP networks. Our algorithms rely on standard SNMP MIB …,IEEE/ACM Transactions on Networking (TON),2004,255
Holistic aggregates in a networked world: Distributed tracking of approximate quantiles,Graham Cormode; Minos Garofalakis; S Muthukrishnan; Rajeev Rastogi,Abstract While traditional database systems optimize for performance on one-shot queries;emerging large-scale monitoring applications require continuous tracking of complexaggregates and data-distribution summaries over collections of physically-distributedstreams. Thus; effective solutions have to be simultaneously space efficient (at each remotesite); communication efficient (across the underlying communication network); and providecontinuous; guaranteed-quality estimates. In this paper; we propose novel algorithmicsolutions for the problem of continuously tracking complex holistic aggregates in such adistributed-streams setting---our primary focus is on approximate quantile summaries; butour approach is more broadly applicable and can handle other holistic-aggregate functions(eg;" heavy-hitters" queries). We present the first known distributed-tracking schemes for …,Proceedings of the 2005 ACM SIGMOD international conference on Management of data,2005,216
System and method for filtering XML documents with XPath expressions,*,A system for; and method of; filtering an XML document with XPath expressions and aselective data dissemination system incorporating the system or the method. In oneembodiment; the filtering system includes:(1) a tree builder that builds a document data treefor the XML document and an XPath expression tree based on substrings in the XPathexpressions and (2) a tree prober; associated with the tree builder; that employs the XPathexpression tree to probe the document data tree and obtain matches with the substrings.,*,2004,207
Distributed sparse random projections for refinable approximation,Wei Wang; Minos Garofalakis; Kannan Ramchandran,Abstract Consider a large-scale wireless sensor network measuring compressible data;where n distributed data values can be well-approximated using only k «n coefficients ofsome known transform. We address the problem of recovering an approximation of the ndata values by querying any L sensors; so that the reconstruction error is comparable to theoptimal k-term approximation. To solve this problem; we present a novel distributedalgorithm based on sparse random projections; which requires no global coordination orknowledge. The key idea is that the sparsity of the random projections greatly reduces thecommunication cost of pre-processing the data. Our algorithm allows the collector to choosethe number of sensors to query according to the desired approximation error. Thereconstruction quality depends only on the number of sensors queried; enabling robust …,Proceedings of the 6th international conference on Information processing in sensor networks,2007,205
Wavelet synopses with error guarantees,Minos Garofalakis; Phillip B Gibbons,Abstract Recent work has demonstrated the effectiveness of the wavelet decomposition inreducing large amounts of data to compact sets of wavelet coefficients (termed" waveletsynopses") that can be used to provide fast and reasonably accurate approximate answersto queries. A major criticism of such techniques is that unlike; for example; random sampling;conventional wavelet synopses do not provide informative error guarantees on the accuracyof individual approximate answers. In fact; as this paper demonstrates; errors can varywidely (without bound) and unpredictably; even for identical queries on nearly-identicalvalues in distinct parts of the data. This lack of error guarantees severely limits thepracticality of traditional wavelets as an approximate query-processing tool; because usershave no idea of the quality of any particular approximate answer. In this paper; we …,Proceedings of the 2002 ACM SIGMOD international conference on Management of data,2002,200
MashMaker: mashups for the masses,Robert J Ennals; Minos N Garofalakis,MashMaker is an interactive tool for editing; querying; manipulating; and visualizing “live”semi-structured data. MashMaker borrows ideas from word processors; web browsers; andspreadsheets. Like a word processor; MashMaker allows ad-hoc; unstructured editing ofdata. Like a web browser; MashMaker encourages users to find information by exploring;rather than by writing queries. Like a spreadsheet; MashMaker allows users to mixcomputed values with their data; including editing “live”(ie; continuously-updated) dataassembled through the web and/or user queries. MashMaker represents a novel paradigmfor the ad-hoc exploration and management of diverse; heterogeneous collections of livedata; that draws on the design principles of more “natural” software tools (like web browsersand spreadsheets) and simple scripting languages; rather than formal database models …,Proceedings of the 2007 ACM SIGMOD international conference on Management of data,2007,198
Sketching streams through the net: Distributed approximate query tracking,Graham Cormode; Minos Garofalakis,Abstract Emerging large-scale monitoring applications require continuous tracking ofcomplex data-analysis queries over collections of physically-distributed streams. Effectivesolutions have to be simultaneously space/time efficient (at each remote monitor site);communication efficient (across the underlying communication network); and providecontinuous; guaranteed-quality approximate query answers. In this paper; we propose novelalgorithmic solutions for the problem of continuously tracking a broad class of complexaggregate queries in such a distributed-streams setting. Our tracking schemes maintainapproximate query answers with provable error guarantees; while simultaneously optimizingthe storage space and processing time at each remote site; and the communication costacross the network. They rely on tracking general-purpose randomized sketch summaries …,Proceedings of the 31st international conference on Very large data bases,2005,198
Synopses for massive data: Samples; histograms; wavelets; sketches,Graham Cormode; Minos Garofalakis; Peter J Haas; Chris Jermaine,Abstract Methods for Approximate Query Processing (AQP) are essential for dealing withmassive data. They are often the only means of providing interactive response times whenexploring massive datasets; and are also needed to handle high speed data streams. Thesemethods proceed by computing a lossy; compact synopsis of the data; and then executingthe query of interest against the synopsis rather than the entire dataset. We describe basicprinciples and recent developments in AQP. We focus on four key synopses: randomsamples; histograms; wavelets; and sketches. We consider issues such as accuracy; spaceand time efficiency; optimality; practicality; range of applicability; error bounds on queryanswers; and incremental maintenance. We also discuss the trade-offs between the differentsynopsis types.,Foundations and Trends in Databases,2012,195
Sketching probabilistic data streams,Graham Cormode; Minos Garofalakis,Abstract The management of uncertain; probabilistic data has recently emerged as a usefulparadigm for dealing with the inherent unreliabilities of several real-world applicationdomains; including data cleaning; information integration; and pervasive; multi-sensorcomputing. Unlike conventional data sets; a set of probabilistic tuples defines a probabilitydistribution over an exponential number of possible worlds (ie;" grounded"; deterministicdatabases). This" possibleworlds" interpretation allows for clean query semantics but alsoraises hard computational problems for probabilistic database query processors. To furthercomplicate matters; in many scenarios (eg; large-scale process and environmentalmonitoring using multiple sensor modalities); probabilistic data tuples arrive and need to beprocessed in a streaming fashion; that is; using limited memory and CPU resources and …,Proceedings of the 2007 ACM SIGMOD international conference on Management of data,2007,187
Statistical synopses for graph-structured XML databases,Neoklis Polyzotis; Minos Garofalakis,Abstract Effective support for XML query languages is becoming increasingly important withthe emergence of new applications that access large volumes of XML data. All existingproposals for querying XML (eg; XQuery) rely on a pattern-specification language thatallows path navigation and branching through the XML data graph in order to reach thedesired data elements. Optimizing such queries depends crucially on the existence ofconcise synopsis structures that enable accurate compile-time selectivity estimates forcomplex path expressions over graph-structured XML data. In this paper; We introduce anovel approach to building and using statistical summaries of large XML data graphs foreffective path-expression selectivity estimation. Our proposed graph-synopsis model(termed XS KETCH) exploits localized graph stability to accurately approximate (in limited …,Proceedings of the 2002 ACM SIGMOD international conference on Management of data,2002,176
Approximate XML query answers,Neoklis Polyzotis; Minos Garofalakis; Yannis Ioannidis,Abstract The rapid adoption of XML as the standard for data representation and exchangeforeshadows a massive increase in the amounts of XML data collected; maintained; andqueried over the Internet or in large corporate data-stores. Inevitably; this will result in thedevelopment of on-line decision support systems; where users and analysts interactivelyexplore large XML data sets through a declarative query interface (eg; XQuery or XSLT).Given the importance of remaining interactive; such on-line systems can employapproximate query answers as an effective mechanism for reducing response time andproviding users with early feedback. This approach has been successfully used in relationalsystems and it becomes even more compelling in the XML world; where the evaluation ofcomplex queries over massive tree-structured data is inherently more expensive. In this …,Proceedings of the 2004 ACM SIGMOD international conference on Management of data,2004,172
Declarative networking,Boon Thau Loo; Tyson Condie; Minos Garofalakis; David E Gay; Joseph M Hellerstein; Petros Maniatis; Raghu Ramakrishnan; Timothy Roscoe; Ion Stoica,Abstract Declarative Networking is a programming methodology that enables developers toconcisely specify network protocols and services; which are directly compiled to a dataflowframework that executes the specifications. This paper provides an introduction to basicissues in declarative networking; including language design; optimization; and dataflowexecution. We present the intuition behind declarative programming of networks; includingroots in Datalog; extensions for networked environments; and the semantics of long-runningqueries over network state. We focus on a sublanguage we call Network Datalog (NDlog);including execution strategies that provide crisp eventual consistency semantics withsignificant flexibility in execution. We also describe a more general language called Overlog;which makes some compromises between expressive richness and semantic guarantees …,Communications of the ACM,2009,170
Approximate Query Processing: Taming the TeraBytes.,Minos N Garofalakis; Phillip B Gibbons,+ Seeing entire data is very helpful (provably & in practice)(But must construct synopses fora family of queries)+ Often faster: better access patterns; small synopses can reside inmemory or cache+ Middleware: Can use with any DBMS; no special index striding+ Alsoeffective for remote or streaming data,VLDB,2001,168
Mining sequential patterns with regular expression constraints,Minos Garofalakis; Rajeev Rastogi; Kyuseok Shim,Discovering sequential patterns is an important problem in data mining with a host ofapplication domains including medicine; telecommunications; and the World Wide Web.Conventional sequential pattern mining systems provide users with only a very restrictedmechanism (based on minimum support) for specifying patterns of interest. As aconsequence; the pattern mining process is typically characterized by lack of focus andusers often end up paying inordinate computational costs just to be inundated with anoverwhelming number of useless results. We propose the use of Regular Expressions (REs)as a flexible constraint specification tool that enables user-controlled focus to beincorporated into the pattern mining process. We develop a family of novel algorithms(termed SPIRIT-Sequential Pattern mining with Regular expression consTraints) for …,IEEE Transactions on knowledge and data engineering,2002,164
Physical topology discovery for large multisubnet networks,Yigal Bejerano; Yuri Breitbart; Minos Garofalakis; Rajeev Rastogi,Knowledge of the up-to-date physical (ie; layer-2) topology of an Ethernet network is crucialto a number of critical network management tasks; including reactive and proactive resourcemanagement; event correlation; and root-cause analysis. Given the dynamic nature oftoday's IP networks; keeping track of topology information manually is a daunting (if notimpossible) task. Thus; effective algorithms for automatically discovering physical networktopology are necessary. In this paper; we propose the first complete algorithmic solution fordiscovering the physical topology of a large; heterogeneous Ethernet network comprisingmultiple subnets as well as (possibly) dumb or uncooperative network elements. Ouralgorithms rely on standard SNMP MIB information that is widely supported in modern IPnetworks and require no modifications to the operating system software running on …,INFOCOM 2003. Twenty-Second Annual Joint Conference of the IEEE Computer and Communications. IEEE Societies,2003,163
BayesStore: managing large; uncertain data repositories with probabilistic graphical models,Daisy Zhe Wang; Eirinaios Michelakis; Minos Garofalakis; Joseph M Hellerstein,Abstract Several real-world applications need to effectively manage and reason about largeamounts of data that are inherently uncertain. For instance; pervasive computingapplications must constantly reason about volumes of noisy sensory readings for a variety ofreasons; including motion prediction and human behavior modeling. Such probabilistic dataanalyses require sophisticated machine-learning tools that can effectively model thecomplex spatio/temporal correlation patterns present in uncertain sensory data.Unfortunately; to date; most existing approaches to probabilistic database systems haverelied on somewhat simplistic models of uncertainty that can be easily mapped onto existingrelational architectures: Probabilistic information is typically associated with individual datatuples; with only limited or no support for effectively capturing and reasoning about …,Proceedings of the VLDB Endowment,2008,159
Independence is good: Dependency-based histogram synopses for high-dimensional data,Amol Deshpande; Minos Garofalakis; Rajeev Rastogi,Abstract Approximating the joint data distribution of a multi-dimensional data set through acompact and accurate histogram synopsis is a fundamental problem arising in numerouspractical scenarios; including query optimization and approximate query answering. Existingsolutions either rely on simplistic independence assumptions or try to directly approximatethe full joint data distribution over the complete set of attributes. Unfortunately; bothapproaches are doomed to fail for high-dimensional data sets with complex correlationpatterns between attributes. In this paper; we propose a novel approach to histogram-basedsynopses that employs the solid foundation of statistical interaction models to explicitlyidentify and exploit the statistical characteristics of the data. Abstractly; our key idea is tobreak the synopsis into (1) a statistical interaction model that accurately captures …,ACM SIGMOD Record,2001,155
Data mining and the Web: past; present and future,Minos N Garofalakis; Rajeev Rastogi; S Seshadri; Kyuseok Shim,The World Wide Web is rapidly emerging as an important medium for transacting commerceas well as for the dissemination of information related to a wide range of topics (eg;business; government; recreation). According to most predictions; the majority of humaninformation will be available on the Web in ten years. These huge amounts of data raise agrand challenge; namely; how to turn the Web into a more useful information utility.Crawlers; search engines and Web directories like Yahoo! constitute the state-of-the-arttools for information retrieval on the Web today. Crawlers for the major search enginesretrieve Web pages on which full-text indexes are constructed. A user query is simply a list ofkeywords (with some additional operators); and the query response is a list of pages rankedbased on their similarity to the query. Today's search tools; however; are plagued by the …,Proceedings of the 2nd international workshop on Web information and data management,1999,149
In-network PCA and anomaly detection,Ling Huang; XuanLong Nguyen; Minos Garofalakis; Michael I Jordan; Anthony Joseph; Nina Taft,Abstract We consider the problem of network anomaly detection in large distributed systems.In this setting; Principal Component Analysis (PCA) has been proposed as a method fordiscovering anomalies by continuously tracking the projection of the data onto a residualsubspace. This method was shown to work well empirically in highly aggregated networks;that is; those with a limited number of large nodes and at coarse time scales. This approach;however; has scalability limitations. To overcome these limitations; we develop a PCA-based anomaly detector in which adaptive local data filters send to a coordinator justenough data to enable accurate global detection. Our method is based on a stochasticmatrix perturbation analysis that characterizes the tradeoff between the accuracy of anomalydetection and the amount of data communicated over the network.,Advances in Neural Information Processing Systems,2007,143
Structure and value synopses for XML data graphs,Neoklis Polyzotis; Minos Garofalakis,This chapter proposes a novel XSKETCH graph synopsis model for eXtensible MarkupLanguage (XML) data graphs with raw data values. All existing proposals for querying XMLrely on a pattern-specification language that allows path navigation and branching throughthe label structure of the XML data graph; and predicates on the values of specificpath/branch nodes in order to reach the desired data elements. Optimizing such queriesdepends crucially on the existence of concise synopsis structures that enable accuratecompile time selectivity estimates for complex path expressions over graph-structured XMLdata. XML is rapidly emerging as the new standard for data representation and exchange onthe Internet. The simple; self-describing nature of the XML standard promises to enable abroad suite of next-generation Internet applications; ranging from intelligent Web …,*,2002,142
Efficiently monitoring bandwidth and latency in IP networks,Yuri Breitbart; Chee-Yong Chan; Minos Garofalakis; Rajeev Rastogi; Abraham Silberschatz,Effective monitoring of network utilization and performance indicators is a key enablingtechnology for proactive and reactive resource management; flexible accounting; andintelligent planning in next-generation IP networks. In this paper; we address thechallenging problem of efficiently monitoring bandwidth utilization and path latencies in anIP data network. Unlike earlier approaches; our measurement architecture assumes a singlepoint-of-control in the network (corresponding to the network operations center) that isresponsible for gathering bandwidth and latency information using widely-deployedmanagement tools; like SNMP; RMON/NetFlow; and explicitly-routed IP probe packets. Ourgoal is to identify effective techniques for monitoring (a) bandwidth usage for a given set oflinks or packet flows; and (b) path latencies for a given set of paths; while minimizing the …,INFOCOM 2001. Twentieth Annual Joint Conference of the IEEE Computer and Communications Societies. Proceedings. IEEE,2001,139
Communication-efficient online detection of network-wide anomalies,Ling Huang; XuanLong Nguyen; Minos Garofalakis; Joseph M Hellerstein; Michael I Jordan; Anthony D Joseph; Nina Taft,There has been growing interest in building large-scale distributed monitoring systems forsensor; enterprise; and ISP networks. Recent work has proposed using principal componentanalysis (PCA) over global traffic matrix statistics to effectively isolate network-wideanomalies. To allow such a PCA-based anomaly detection scheme to scale; we propose anovel approximation scheme that dramatically reduces the burden on the productionnetwork. Our scheme avoids the expensive step of centralizing all the data by performingintelligent filtering at the distributed monitors. This filtering reduces monitoring bandwidthoverheads; but can result in the anomaly detector making incorrect decisions based on aperturbed view of the global data set. We employ stochastic matrix perturbation theory tobound such errors. Our algorithm selects the filtering parameters at local monitors such …,INFOCOM 2007. 26th IEEE International Conference on Computer Communications. IEEE,2007,132
Proof sketches: Verifiable in-network aggregation,Minos Garofalakis; Joseph M Hellerstein; Petros Maniatis,A work on distributed; in-network aggregation assumes a benign population of participants.Unfortunately; modern distributed systems are plagued by malicious participants. In thispaper we present a first step towards verifiable yet efficient distributed; in-networkaggregation in adversarial settings. We describe a general framework and threat model forthe problem and then present proof sketches; a compact verification mechanism thatcombines cryptographic signatures and Flajolet-Martin sketches to guarantee acceptableaggregation error bounds with high probability. We derive proof sketches for countaggregates and extend them for random sampling; which can be used to provide verifiableapproximations for a broad class of data-analysis queries; eg; quantiles and heavy hitters.Finally; we evaluate the practical use of proof sketches; and observe that adversaries can …,Data Engineering; 2007. ICDE 2007. IEEE 23rd International Conference on,2007,116
An adaptive RFID middleware for supporting metaphysical data independence,Shawn R Jeffery; Michael J Franklin; Minos Garofalakis,Abstract Sensor devices produce data that are unreliable; low-level; and seldom able to beused directly by applications. In this paper; we propose metaphysical data independence(MDI); a layer of independence that shields applications from the challenges that arise wheninteracting directly with sensor devices. The key philosophy behind MDI is that applicationsdo not deal with any aspect of physical device data; but rather interface with a high-levelreconstruction of the physical world created by a sensor infrastructure. As a concreteinstantiation of MDI in such a sensor infrastructure; we detail MDI-SMURF; a RadioFrequency Identification (RFID) middleware system that alleviates issues associated withusing RFID data through adaptive techniques based on a novel statistical framework.,The VLDB Journal—The International Journal on Very Large Data Bases,2008,107
Selectivity estimation for XML twigs,Neoklis Polyzotis; Minos Garofalakis; Yannis Ioannidis,Twig queries represent the building blocks of declarative query languages over XML data. Atwig query describes a complex traversal of the document graph and generates a set ofelement tuples based on the intertwined evaluation (ie; join) of multiple path expressions.Estimating the result cardinality of twig queries or; equivalently; the number of tuples in sucha structural (path-based) join; is a fundamental problem that arises in the optimization ofdeclarative queries over XML. It is crucial; therefore; to develop concise synopsis structuresthat summarize the document graph and enable such selectivity estimates within the timeand space constraints of the optimizer. We propose novel summarization and estimationtechniques for estimating the selectivity of twig queries with complex XPath expressions overtree-structured data. Our approach is based on the XSKETCH model; augmented with …,Data Engineering; 2004. Proceedings. 20th International Conference on,2004,105
Processing set expressions over continuous update streams,Sumit Ganguly; Minos Garofalakis; Rajeev Rastogi,Abstract There is growing interest in algorithms for processing and querying continuous datastreams (ie; data that is seen only once in a fixed order) with limited memory resources. In itsmost general form; a data stream is actually an update stream; ie; comprising data-itemdeletions as well as insertions. Such massive update streams arise naturally in severalapplication domains (eg; monitoring of large IP network installations; or processing of retail-chain transactions). Estimating the cardinality of set expressions defined over several(perhaps; distributed) update streams is perhaps one of the most fundamental query classesof interest; as an example; such a query may ask" what is the number of distinct IP sourceaddresses seen in passing packets from both router R 1 and R 2 but not router R 3?". Earlierwork has only addressed very restricted forms of this problem; focusing solely on the …,Proceedings of the 2003 ACM SIGMOD international conference on Management of data,2003,105
Deterministic wavelet thresholding for maximum-error metrics,Minos Garofalakis; Amit Kumar,Abstract Several studies have demonstrated the effectiveness of the wavelet; decompositionas a tool for reducing large amounts of data down to compact; wavelet synopses that can beused to obtain fast; accurate approximate answers to user queries. While conventionalwavelet synopses are based on greedily minimizing the overall root-mean-squared (ie; L 2-norm) error in the data approximation; recent work has demonstrated that such synopsescan suffer from important problems; including severe bias and wide variance in the quality ofthe data reconstruction; and lack of non-trivial guarantees for individual approximateanswers. As a result; probabilistic thresholding schemes have been recently proposed as ameans of building wavelet synopses that try to probabilistically control other approximation-error metrics; such as the maximum relative error in data-value reconstruction; which is …,Proceedings of the twenty-third ACM SIGMOD-SIGACT-SIGART symposium on Principles of database systems,2004,104
Parallel query scheduling and optimization with time-and space-shared resources,Minos N Garofalakis; Yannis E Ioannidis,Abstract Scheduling query execution plans is a particularly complex problem in hierarchicalparallel systems; where each site consists of a collection of local time-shared (eg; CPU (s) ordisk (s)) and space-shared (eg; memory) resources and communicates with remote sites bymessagepassing. We develop a general approach to the problem; capturing the fullcomplexity of scheduling distributed multi-dimensional resource units for all kinds ofparallelism within and across queries and operators. We present heuristic algorithms forvarious forms of the problem; some of which are provably near-optimal. Preliminaryexperimental results confirm the effectiveness of our approach.,SORT,1997,101
Intel Mash Maker: join the web,Rob Ennals; Eric Brewer; Minos Garofalakis; Michael Shadle; Prashant Gandhi,Abstract Intel® Mash Maker is an interactive tool that tracks what the user is doing and triesto infer what information and visualizations they might find useful for their current task. MashMaker uses structured data from existing web sites to create new" mashed up" interfacescombining information from many sources. The Intel® Mash Maker client is currentlyimplemented as an extension to the FireFox web browser. Mash Maker adds a toolbar to thebrowser that shows buttons representing enhancements that Mash Maker believes the usermight want to apply to the current page. An enhancement might combine the data on thepage with data from another source; or visualize data in a new way. Mash Maker is intendedto be an integral part of the way the user browses information; rather than being a specialtool that a user uses when they want to create mashups.,ACM SIGMOD Record,2007,94
Multi-dimensional resource scheduling for parallel queries,Minos N Garofalakis; Yannis E Ioannidis,Abstract Scheduling query execution plans is an important component of query optimizationin parallel database systems. The problem is particularly complex in a shared-nothingexecution environment; where each system node represents a collection of time-shareableresources (eg; CPU (s); disk (s); etc.) and communicates with other nodes only by message-passing. Significant research effort has concentrated on only a subset of the various forms ofintra-query parallelism so that scheduling and synchronization is simplified. In addition; mostprevious work has focused its attention on one-dimensional models of parallel queryscheduling; effectively ignoring the potential benefits of resource sharing. In this paper; wedevelop an approach that is more general in both directions; capturing all forms of intra-query parallelism and exploiting sharing of multi-dimensional resource nodes among …,ACM SIGMOD Record,1996,94
Large-scale collective entity matching,Vibhor Rastogi; Nilesh Dalvi; Minos Garofalakis,Abstract There have been several recent advancements in Machine Learning community onthe Entity Matching (EM) problem. However; their lack of scalability has prevented them frombeing applied in practical settings on large real-life datasets. Towards this end; we proposea principled framework to scale any generic EM algorithm. Our technique consists of runningmultiple instances of the EM algorithm on small neighborhoods of the data and passingmessages across neighborhoods to construct a global solution. We prove formal propertiesof our framework and experimentally demonstrate the effectiveness of our approach inscaling EM algorithms.,Proceedings of the VLDB Endowment,2011,92
Tree pattern aggregation for scalable XML data dissemination,Chee-Yong Chan; Wenfei Fan; Pascal Felber; Minos Garofalakis; Rajeev Rastogi,Summary With the rapid growth of XML-document traffic on the Internet; scalable content-based dissemination of XML documents to a large; dynamic group of consumers hasbecome an important research challenge. To indicate the type of content that they areinterested in; data consumers typically specify their subscriptions using some XML patternspecification language (eg; XPath). Given the large volume of subscribers; system scalabilityand efficiency mandate the ability to aggregate the set of consumer subscriptions to asmaller set of content specifications; so as to both reduce their storage-space requirementsas well as speed up the document-subscription matching process. In this paper; we providethe first systematic study of subscription aggregation where subscriptions are specified withtree patterns (an important subclass of XPath expressions). The main challenge is to …,*,2002,92
Spartan: A model-based semantic compression system for massive data tables,Shivnath Babu; Minos Garofalakis; Rajeev Rastogi,Abstract While a variety of lossy compression schemes have been developed for certainforms of digital data (eg; images; audio; video); the area of lossy compression techniques forarbitrary data tables has been left relatively unexplored. Nevertheless; such techniques areclearly motivated by the ever-increasing data collection rates of modern enterprises and theneed for effective; guaranteed-quality approximate answers to queries over massiverelational data sets. In this paper; we propose SPARTAN; a system that takes advantage ofattribute semantics and data-mining models to perform lossy compression of massive datatables. SPARTAN is based on the novel idea of exploiting predictive data correlations andprescribed error tolerances for individual attributes to construct concise and accurateClassification and Regression Tree (CaRT) models for entire columns of a table. More …,ACM SIGMOD Record,2001,89
Re-tree: an efficient index structure for regular expressions,Chee-Yong Chan; Minos Garofalakis; Rajeev Rastogi,Abstract. Due to their expressive power; regular expressions (REs) are quickly becoming anintegral part of language specifications for several important application scenarios. Many ofthese applications have to manage huge databases of RE specifications and need toprovide an effective matching mechanism that; given an input string; quickly identifies theREs in the database that match it. In this paper; we propose the RE-tree; a novel indexstructure for large databases of RE specifications. Given an input query string; the RE-treespeeds up the retrieval of matching REs by focusing the search and comparing the inputstring with only a small fraction of REs in the database. Even though the RE-tree is similar inspirit to other tree-based structures that have been proposed for indexing multidimensionaldata; RE indexing is significantly more challenging since REs typically represent infinite …,The VLDB Journal—The International Journal on Very Large Data Bases,2003,87
Determination of physical topology of a communication network,*,Physical connectivity is determined between elements such as switches and routers in amultiple subnet communication network. Each element has one or more interfaces each ofwhich is physically linked with an interface of another network element. Address sets aregenerated for each interface of the network elements; wherein members of a given addressset correspond to network elements that can be reached from the corresponding interface forwhich the given address set was generated. The members of first address sets generated forcorresponding interfaces of a given network element; are compared with the members ofsecond address sets generated for corresponding interfaces of network elements other thanthe given element. A set of candidate connections between an interface of the given networkelement and one or more interfaces of other network elements; are determined. If more …,*,2004,84
Data Stream Management: Processing High-Speed Data Streams,Minos Garofalakis; Johannes Gehrke; Rajeev Rastogi,This volume focuses on the theory and practice of data stream management; and the novelchallenges this emerging domain poses for data-management algorithms; systems; andapplications. The collection of chapters; contributed by authorities in the field; offers acomprehensive introduction to both the algorithmic/theoretical foundations of data streams;as well as the streaming systems and applications built in different domains. A shortintroductory chapter provides a brief summary of some basic data streaming concepts andmodels; and discusses the key elements of a generic stream query processing architecture.Subsequently; Part I focuses on basic streaming algorithms for some key analytics functions(eg; quantiles; norms; join aggregates; heavy hitters) over streaming data. Part II thenexamines important techniques for basic stream mining tasks (eg; clustering …,*,2016,83
Probabilistic wavelet synopses,Minos Garofalakis; Phillip B Gibbons,Abstract Recent work has demonstrated the effectiveness of the wavelet decomposition inreducing large amounts of data to compact sets of wavelet coefficients (termed" waveletsynopses") that can be used to provide fast and reasonably accurate approximate queryanswers. A major shortcoming of these existing wavelet techniques is that the quality of theapproximate answers they provide varies widely; even for identical queries on nearlyidentical values in distinct parts of the data. As a result; users have no way of knowingwhether a particular approximate answer is highly-accurate or off by many orders ofmagnitude. In this article; we introduce Probabilistic Wavelet Synopses; the first wavelet-based data reduction technique optimized for guaranteed accuracy of individualapproximate answers. Whereas previous approaches rely on deterministic thresholding …,ACM Transactions on Database Systems (TODS),2004,83
XSKETCH synopses for XML data graphs,Neoklis Polyzotis; Minos Garofalakis,Abstract Effective support for XML query languages is becoming increasingly important withthe emergence of new applications that access large volumes of XML data. All existingproposals for querying XML (eg; XQuery) rely on a pattern-specification language thatallows (1) path navigation and branching through the label structure of the XML data graph;and (2) predicates on the values of specific path/branch nodes; in order to reach the desireddata elements. Clearly; optimizing such queries requires approximating the result cardinalityof the referenced paths and hence hinges on the existence of concise synopsis structuresthat enable accurate compile-time selectivity estimates for complex path expressions overthe base XML data. In this article; we introduce a novel approach to building and usingstatistical summaries of large XML data graphs for effective path-expression selectivity …,ACM Transactions on Database Systems (TODS),2006,81
XTRACT: Learning document type descriptors from XML document collections,Minos Garofalakis; Aristides Gionis; Rajeev Rastogi; Sridhar Seshadri; Kyuseok Shim,Abstract XML is rapidly emerging as the new standard for data representation and exchangeon the Web. Unlike HTML; tags in XML documents describe the semantics of the data andnot how it is to be displayed. In addition; an XML document can be accompanied by aDocument Type Descriptor (DTD) which plays the role of a schema for an XML datacollection. DTDs contain valuable information on the structure of documents and thus have acrucial role in the efficient storage of XML data; as well as the effective formulation andoptimization of XML queries. Despite their importance; however; DTDs are not mandatory;and it is frequently possible that documents in XML databases will not have accompanyingDTDs. In this paper; we propose XTRACT; a novel system for inferring a DTD schema for adatabase of XML documents. Since the DTD syntax incorporates the full expressive …,Data mining and knowledge discovery,2003,78
Efficient Stepwise Selection in Decomposable Models,Amol Deshpande; Minos Garofalakis; Michael I Jordan,Abstract In this paper; we present an e cient algorithm for performing stepwise selection inthe class of decomposable models. We focus on the forward selection procedure; but wealso discuss how backward selection and the combination of the two can be performed eciently. The main contributions of this paper are (1) a simple characterization for the edgesthat can be added to a decomposable model while retaining its decomposability and (2) ane cient algorithm for enumerating all such edges for a given decomposable model in O (n2)time; where n is the number of variables in the model. We also analyze the complexity of theoverall stepwise selection procedure (which includes the complexity of enumerating eligibleedges as well as the complexity of deciding how to\progress"). We use the KL divergence ofthe model from the saturated model as our metric; but the results we present here extend …,*,*,76
Sketch-based querying of distributed sliding-window data streams,Odysseas Papapetrou; Minos Garofalakis; Antonios Deligiannakis,Abstract While traditional data-management systems focus on evaluating single; ad-hocqueries over static data sets in a centralized setting; several emerging applications require(possibly; continuous) answers to queries on dynamic data that is widely distributed andconstantly updated. Furthermore; such query answers often need to discount data that is"stale"; and operate solely on a sliding window of recent data arrivals (eg; data updatesoccurring over the last 24 hours). Such distributed data streaming applications mandatenovel algorithmic solutions that are both time-and space-efficient (to manage high-speeddata streams); and also communication-efficient (to deal with physical data distribution). Inthis paper; we consider the problem of complex query answering over distributed; high-dimensional data streams in the sliding-window model. We introduce a novel sketching …,Proceedings of the VLDB Endowment,2012,72
Wavelet synopses for general error metrics,Minos Garofalakis; Amit Kumar,Abstract Several studies have demonstrated the effectiveness of the wavelet decompositionas a tool for reducing large amounts of data down to compact wavelet synopses that can beused to obtain fast; accurate approximate query answers. Conventional wavelet synopsesthat greedily minimize the overall root-mean-squared (ie; L 2-norm) error in the dataapproximation can suffer from important problems; including severe bias and wide variancein the quality of the data reconstruction; and lack of nontrivial guarantees for individualapproximate answers. Thus; probabilistic thresholding schemes have been recentlyproposed as a means of building wavelet synopses that try to probabilistically controlmaximum approximation-error metrics (eg; maximum relative error). A key open problem iswhether it is possible to design efficient deterministic wavelet-thresholding algorithms for …,ACM Transactions on Database Systems (TODS),2005,70
Distributed set-expression cardinality estimation,Abhinandan Das; Sumit Ganguly; Minos Garofalakis; Rajeev Rastogi,Abstract We consider the problem of estimating set-expression cardinality in a distributedstreaming environment where rapid update streams originating at remote sites arecontinually transmitted to a central processing system. At the core of our algorithmicsolutions for answering set-expression cardinality queries are two novel techniques forlowering data communication costs without sacrificing answer precision. Our first techniqueexploits global knowledge of the distribution of certain frequently occurring stream elementsto significantly reduce the transmission of element state information to the central site. Oursecond technical contribution involves a novel way of capturing the semantics of the inputset expression in a boolean logic formula; and using models (of the formula) to determinewhether an element state change at a remote site can affect the set expression result …,Proceedings of the Thirtieth international conference on Very large data bases-Volume 30,2004,69
Sketch-based multi-query processing over data streams,Alin Dobra; Minos Garofalakis; Johannes Gehrke; Rajeev Rastogi,Abstract Recent years have witnessed an increasing interest in designing algorithms forquerying and analyzing streaming data (ie; data that is seen only once in a fixed order) withonly limited memory. Providing (perhaps approximate) answers to queries over suchcontinuous data streams is a crucial requirement for many application environments;examples include large telecom and IP network installations where performance data fromdifferent parts of the network needs to be continuously collected and analyzed. Randomizedtechniques; based on computing small “sketch” synopses for each stream; have recentlybeen shown to be a very effective tool for approximating the result of a single SQL queryover streaming data tuples. In this paper; we investigate the problems arising when data-stream sketches are used to process multiple such queries concurrently. We demonstrate …,International Conference on Extending Database Technology,2004,65
Optimal configuration of OSPF aggregates,Rajeev Rastogi; Yuri Breitbart; Minos Garofalakis; Amit Kumar,Abstract Open Shortest Path First (OSPF) is a popular protocol for routing within anautonomous system (AS) domain. In order to scale for large networks containing hundredsand thousands of subnets; OSPF supports a two-level hierarchical routing scheme throughthe use of OSPF areas. Subnet addresses within an area are aggregated; and thisaggregation is a crucial requirement for scaling OSPF to large AS domains; as it results insignificant reductions in routing table sizes; smaller link-state databases; and less networktraffic to synchronize the router link-state databases. On the other hand; addressaggregation also implies loss of information about the length of the shortest path to eachsubnet; which in turn; can lead to suboptimal routing. In this paper; we address the importantpractical problem of configuring OSPF aggregates to minimize the error in OSPF shortest …,IEEE/ACM Transactions on Networking (TON),2003,65
Scalable ranked publish/subscribe,Ashwin Machanavajjhala; Erik Vee; Minos Garofalakis; Jayavel Shanmugasundaram,Abstract Publish/subscribe (pub/sub) systems are designed to efficiently match incomingevents (eg; stock quotes) against a set of subscriptions (eg; trader profiles specifying quotesof interest). However; current pub/sub systems only support a simple binary notion ofmatching: an event either matches a subscription or it does not; for instance; a stock quotewill either match or not match a trader profile. In this paper; we argue that this simple notionof matching is inadequate for many applications where only the" best" matchingsubscriptions are of interest. For instance; in targeted Web advertising; an incoming user ("event") may match several different advertiser-specified user profiles (" subscriptions"); butgiven the limited advertising real-estate; we want to quickly discover the best (eg; mostrelevant) ads to display. To address this need; we initiate a study of ranked pub/sub …,Proceedings of the VLDB Endowment,2008,63
Admission control system and method for media-on-demand servers,*,In a server system having a predetermined total bandwidth providing data files to a pluralityof clients in response to requests received from the clients; a method for providing admissioncontrol comprises the steps of allocating a plurality of channel partitions to a plurality ofchannel groups such that each channel group includes one or more of the channelpartitions. The system then obtains a channel group number based on the length of the datafile requested by one of the clients and transmits the requested data file when a channelgroup corresponding to the obtained channel group number contains a vacant channelpartition.,*,2001,63
Histograms and wavelets on probabilistic data,Graham Cormode; Minos Garofalakis,There is a growing realization that uncertain information is a first-class citizen in moderndatabase management. As such; we need techniques to correctly and efficiently processuncertain data in database systems. In particular; data reduction techniques that canproduce concise; accurate synopses of large probabilistic relations are crucial. Similar totheir deterministic relation counterparts; such compact probabilistic data synopses can formthe foundation for human understanding and interactive data exploration; probabilistic queryplanning and optimization; and fast approximate query processing in probabilistic databasesystems. In this paper; we introduce definitions and algorithms for building histogram-andHaar wavelet-based synopses on probabilistic data. The core problem is to choose a set ofhistogram bucket boundaries or wavelet coefficients to optimize the accuracy of the …,IEEE Transactions on Knowledge and Data Engineering,2010,61
Approximate continuous querying over distributed streams,Graham Cormode; Minos Garofalakis,Abstract While traditional database systems optimize for performance on one-shot queryprocessing; emerging large-scale monitoring applications require continuous tracking ofcomplex data-analysis queries over collections of physically distributed streams. Thus;effective solutions have to be simultaneously space/time efficient (at each remote monitorsite); communication efficient (across the underlying communication network); and providecontinuous; guaranteed-quality approximate query answers. In this paper; we propose novelalgorithmic solutions for the problem of continuously tracking a broad class of complexaggregate queries in such a distributed-streams setting. Our tracking schemes maintainapproximate query answers with provable error guarantees; while simultaneously optimizingthe storage space and processing time at each remote site; and the communication cost …,ACM Transactions on Database Systems (TODS),2008,61
XCluster synopses for structured XML content,Neoklis Polyzotis; Minos Garofalakis,We tackle the difficult problem of summarizing the path/branching structure and valuecontent of an XML database that comprises both numeric and textual values. We introduce anovel XML-summarization model; termed XCLUSTERs; that enables accurate selectivityestimates for the class of twig queries with numeric-range; substring; and textual IRpredicates over the content of XML elements. In a nutshell; an XCLUSTER synopsisrepresents an effective clustering of XML elements based on both their structural and value-based characteristics. By leveraging techniques for summarizing XML-document structureas well as numeric and textual data distributions; our XCLUSTER model provides the firstknown unified framework for handling path/branching structure and different types ofelement values. We detail the XCLUSTER model; and develop a systematic framework …,Data Engineering; 2006. ICDE'06. Proceedings of the 22nd International Conference on,2006,61
System and method for constraint based sequential pattern mining,*,The present invention provides a method and system for sequential pattern mining with agiven constraint. A Regular Expression (RE) is used for identifying the family of interestingfrequent patterns. A family of methods that enforce the RE constraint to different degreeswithin the generating and pruning of candidate patterns during the mining process isutilized. This is accomplished by employing different relaxations of the RE constraint in themining loop. Those sequences which satisfy the given constraint are thus identified mostexpeditiously.,*,2002,59
Scheduling resources for continuous media databases,*,Various systems and methods of scheduling media segments of varying display rate; lengthand/or periodicity on at least one clustered; vertically-striped or horizontally-stripedcontinuous media database volume. With respect to the at least one horizontally-stripeddatabase volume; one method includes the steps of:(1) associating a display value witheach of the media segments;(2) sorting the media segments in a non-increasing order ofvalue density to obtain an ordered list thereof and (3) building a scheduling tree of the mediasegments; the scheduling tree having a structure that increases a total display value of themedia segments.,*,1998,59
Sharing aggregate computation for distributed queries,Ryan Huebsch; Minos Garofalakis; Joseph M Hellerstein; Ion Stoica,Abstract An emerging challenge in modern distributed querying is to efficiently processmultiple continuous aggregation queries simultaneously. Processing each queryindependently may be infeasible; so multi-query optimizations are critical for sharing workacross queries. The challenge is to identify overlapping computations that may not beobvious in the queries themselves. In this paper; we reveal new opportunities for sharingwork in the context of distributed aggregation queries that vary in their selection predicates.We identify settings in which a large set of q such queries can be answered by executingk<< q different queries. The k queries are revealed by analyzing a boolean matrix capturingthe connection between data and the queries that they satisfy; in a manner akin to familiartechniques like Gaussian elimination. Indeed; we identify a class of linear aggregate …,Proceedings of the 2007 ACM SIGMOD international conference on Management of data,2007,57
System and method for compressing a data table using models,*,A system for; and method of compressing a data table using models and a databasemanagement system incorporating the system or the method. In one embodiment; thesystem includes:(1) a table modeller that discovers data mining models with guaranteederror bounds of at least one attribute in the data table in terms of other attributes in the datatable and (2) a model selector; associated with the table modeller; that selects a subset ofthe at least one model to form a basis upon which to compress the data table.,*,2006,57
Prediction-based geometric monitoring over distributed data streams,Nikos Giatrakos; Antonios Deligiannakis; Minos Garofalakis; Izchak Sharfman; Assaf Schuster,Abstract Many modern streaming applications; such as online analysis of financial; network;sensor and other forms of data are inherently distributed in nature. An important query typethat is the focal point in such application scenarios regards actuation queries; where properaction is dictated based on a trigger condition placed upon the current value that amonitored function receives. Recent work studies the problem of (non-linear) sophisticatedfunction tracking in a distributed manner. The main concept behind the geometric monitoringapproach proposed there; is for each distributed site to perform the function monitoring overan appropriate subset of the input domain. In the current work; we examine whether thedistributed monitoring mechanism can become more efficient; in terms of the number ofcommunicated messages; by extending the geometric monitoring framework to utilize …,Proceedings of the 2012 ACM SIGMOD International Conference on Management of Data,2012,56
Method for distinct count estimation over joins of continuous update stream,*,The invention provides methods and systems for summarizing multiple continuous updatestreams such that an approximate answer to a query over one or more of the continuousupdate streams (such as a Query requiring a join operation followed by a duplicateelimination step) may be rapidly provided. The systems and methods use multiple (parallel)Join Distinct (JD) Sketch data structures corresponding to hash buckets of at least one initialattribute.,*,2010,56
XML stream processing using tree-edit distance embeddings,Minos Garofalakis; Amit Kumar,Abstract We propose the first known solution to the problem of correlating; in small space;continuous streams of XML data through approximate (structure and content) matching; asdefined by a general tree-edit distance metric. The key element of our solution is a novelalgorithm for obliviously embedding tree-edit distance metrics into an L 1 vector space whileguaranteeing a (worst-case) upper bound of O (log 2 n log* n) on the distance distortionbetween any data trees with at most n nodes. We demonstrate how our embeddingalgorithm can be applied in conjunction with known random sketching techniques to (1)build a compact synopsis of a massive; streaming XML data tree that can be used as aconcise surrogate for the full tree in approximate tree-edit distance computations; and (2)approximate the result of tree-edit-distance similarity joins over continuous XML …,ACM Transactions on Database Systems (TODS),2005,56
Building decision trees with constraints,Minos Garofalakis; Dongjoon Hyun; Rajeev Rastogi; Kyuseok Shim,Abstract Classification is an important problem in data mining. Given a database of records;each with a class label; a classifier generates a concise and meaningful description for eachclass that can be used to classify subsequent records. A number of popular classifiersconstruct decision trees to generate class models. Frequently; however; the constructedtrees are complex with hundreds of nodes and thus difficult to comprehend; a fact that callsinto question an often-cited benefit that decision trees are easy to interpret. In this paper; weaddress the problem of constructing “simple” decision trees with few nodes that are easy forhumans to interpret. By permitting users to specify constraints on tree size or accuracy; andthen building the “best” tree that satisfies the constraints; we ensure that the final tree is botheasy to understand and has good accuracy. We develop novel branch-and-bound …,Data Mining and Knowledge Discovery,2003,56
Processing data-stream join aggregates using skimmed sketches,Sumit Ganguly; Minos Garofalakis; Rajeev Rastogi,Abstract There is a growing interest in on-line algorithms for analyzing and querying datastreams; that examine each stream element only once and have at their disposal; only alimited amount of memory. Providing (perhaps approximate) answers to aggregate queriesover such streams is a crucial requirement for many application environments; examplesinclude large IP network installations where performance data from different parts of thenetwork needs to be continuously collected and analyzed. In this paper; we present theskimmed-sketch algorithm for estimating the join size of two streams.(Our techniques alsoreadily extend to other join-aggregate queries.) To the best of our knowledge; our skimmed-sketch technique is the first comprehensive join-size estimation algorithm to provide tighterror guarantees while:(1) achieving the lower bound on the space required by any join …,International Conference on Extending Database Technology,2004,52
Fast approximate wavelet tracking on streams,Graham Cormode; Minos Garofalakis; Dimitris Sacharidis,Abstract Recent years have seen growing interest in effective algorithms for summarizingand querying massive; high-speed data streams. Randomized sketch synopses provideaccurate approximations for general-purpose summaries of the streaming data distribution(eg; wavelets). The focus of existing work has typically been on minimizing spacerequirements of the maintained synopsis—however; to effectively support high-speed data-stream analysis; a crucial practical requirement is to also optimize:(1) the update time forincorporating a streaming data element in the sketch; and (2) the query time for producingan approximate summary (eg; the top wavelet coefficients) from the sketch. Such time costsmust be small enough to cope with rapid stream-arrival rates and the real-time queryingrequirements of typical streaming applications (eg; ISP network monitoring). With cheap …,International Conference on Extending Database Technology,2006,51
Probabilistic Data Management for Pervasive Computing: The Data Furnace Project.,Minos N Garofalakis; Kurt P Brown; Michael J Franklin; Joseph M Hellerstein; Daisy Zhe Wang; Eirinaios Michelakis; Liviu Tancau; Eugene Wu; Shawn R Jeffery; Ryan Aipperspach,Abstract The wide deployment of wireless sensor and RFID (Radio Frequency IDentification)devices is one of the key enablers for next-generation pervasive computing applications;including large-scale environmental monitoring and control; context-aware computing; and“smart digital homes”. Sensory readings are inherently unreliable and typically exhibit strongtemporal and spatial correlations (within and across different sensing devices); effectivereasoning over such unreliable streams introduces a host of new data managementchallenges. The Data Furnace project at Intel Research and UC-Berkeley aims to build aprobabilistic data management infrastructure for pervasive computing environments thathandles the uncertain nature of such data as a first-class citizen through a principledframework grounded in probabilistic models and inference techniques.,IEEE Data Eng. Bull.,2006,50
Streaming in a connected world: querying and tracking distributed data streams,Graham Cormode; Minos Garofalakis,Today; a majority of data is fundamentally distributed in nature. Data for almost any task iscollected over a broad area; and streams in at a much greater rate than ever before. Inparticular; advances in sensor technology and miniaturization have led to the concept of thesensor network: a (typically wireless) collection of sensing devices collecting detailed dataabout their surroundings. A fundamental question arises: how to query and monitor this richnew source of data? A similar scenario emerges within more traditional; wired networks: ifdata is collected over remote sites; either about observed external conditions or about thenetwork itself (eg in IP network monitoring); how to process this data in order to answercertain queries? Additionally; other emerging models of distributed computation; such aspeer-to-peer (P2P) networks and grid-based computing face the same problems of …,Proceedings of the 2007 ACM SIGMOD international conference on Management of data,2007,47
Correlating XML data streams using tree-edit distance embeddings,Minos Garofalakis; Amit Kumar,Abstract We propose the first known solution to the problem of correlating; in small space;continuous streams of XML data through approximate (structure and content) matching; asdefined by a general tree-edit distance metric. The key element of our solution is a novelalgorithm for obliviously embedding tree-edit distance metrics into an L 1 vector space whileguaranteeing an upper bound of O (log 2 n log* n) on the distance distortion between anydata trees with at most n nodes. We demonstrate how our embedding algorithm can beapplied in conjunction with known random sketching techniques to:(1) build a compactsynopsis of a massive; streaming XML data tree that can be used as a concise surrogate forthe full tree in approximate tree-edit distance computations; and;(2) approximate the result oftree-edit distance similarity joins over continuous XML document streams. To the best of …,Proceedings of the twenty-second ACM SIGMOD-SIGACT-SIGART symposium on Principles of database systems,2003,46
Communication-efficient tracking of distributed cumulative triggers,Ling Huang; Minos Garofalakis; Anthony D Joseph; Nina Taft,In recent work; we proposed D-Trigger; a framework for tracking a global condition over alarge network that allows us to detect anomalies while only collecting a very limited amountof data from distributed monitors. In this paper; we expand our previous work by designing anew class of queries (conditions) that can be tracked for anomaly violations. We show howsecurity violations can be detected over a time window of any size. This is importantbecause security operators do not know in advance the window of time in whichmeasurements should be made to detect anomalies. We also present an algorithm thatdetermines how each machine should filter its time series measurements before back-hauling them to a central operations center. Our filters are computed analytically such thatupper bounds on false positive and missed detection rates are guaranteed. In our …,Distributed Computing Systems; 2007. ICDCS'07. 27th International Conference on,2007,44
Streaming algorithms for robust; real-time detection of ddos attacks,Sumit Ganguly; Minos Garofalakis; Rajeev Rastogi; Krishan Sabnani,Effective mechanisms for detecting and thwarting distributed denial-of-service (DDoS)attacks are becoming increasingly important to the success of today's Internet as a viablecommercial and business tool. In this paper; we propose novel data-streaming algorithms forthe robust; real-time detection of DDoS activity in large ISP networks. The key element of oursolution is a new; hash-based synopsis data structure for network-data streams that allowsus to efficiently track; in guaranteed small space and time; destination IP addresses in theunderlying network that are" large" with respect to the number of distinct source IPaddresses that have established potentially-malicious (eg;" half-open") connections to them.Our work is the first to address the problem of efficiently tracking the top distinct-sourcefrequencies over a general stream of updates (insertions and deletions) to the set of …,Distributed Computing Systems; 2007. ICDCS'07. 27th International Conference on,2007,43
Scalable filtering of XML data for Web services,Pascal Felber; Chee-Yong Chan; Minos Garofalakis; Rajeev Rastogi,As the Web gains prevalence as an application-to-application communication medium;organizations are deploying more Web service applications to provide standardized;programmatic application functionality over the Internet. The paper considers how scalablecontent-based routing architectures for Web applications can handle the growing number ofXML messages associated with Web services.,IEEE Internet Computing,2003,42
Toward sophisticated detection with distributed triggers,Ling Huang; Minos Garofalakis; Joseph Hellerstein; Anthony Joseph; Nina Taft,Abstract Recent research has proposed efficient protocols for distributed triggers; which canbe used in monitoring infrastructures to maintain system-wide invariants and detectabnormal events with minimal communication overhead. To date; however; this work hasbeen limited to simple thresholds on distributed aggregate functions like sums and counts. Inthis paper; we present our initial results that show how to use these simple threshold triggersto enable sophisticated anomaly detection in near-real time; with modest communicationoverheads. We design a distributed protocol to detect" unusual traffic patterns" buried in anOrigin-Destination network flow matrix that: a) uses a Principal Components Analysisdecomposition technique to detect anomalies via a threshold function on residual signals[10]; and b) efficiently tracks this threshold function in near-real time using a simple …,Proceedings of the 2006 SIGCOMM workshop on Mining network data,2006,41
Compact histograms for hierarchical identifiers,Frederick Reiss; Minos Garofalakis; Joseph M Hellerstein,Abstract Distributed monitoring applications often involve streams of unique identifiers(UIDs) such as IP addresses or RFID tag IDs. An important class of query for suchapplications involves partitioning the UIDs into groups using a large lookup table; the querythen performs aggregation over the groups. We propose using histograms to reducebandwidth utilization in such settings; using a histogram partitioning function as a compactrepresentation of the lookup table. We investigate methods for constructing histogrampartitioning functions for lookup tables over unique identifiers that form a hierarchy ofcontiguous groups; as is the case with network addresses and several other types of UID.Each bucket in our histograms corresponds to a subtree of the hierarchy. We develop threenovel classes of partitioning functions for this domain; which vary in their structure …,Proceedings of the 32nd international conference on Very large data bases,2006,40
Tracking set-expression cardinalities over continuous update streams,Sumit Ganguly; Minos Garofalakis; Rajeev Rastogi,Abstract. There is growing interest in algorithms for processing and querying continuousdata streams (ie; data seen only once in a fixed order) with limited memory resources. In itsmost general form; a data stream is actually an update stream; ie; comprising data-itemdeletions as well as insertions. Such massive update streams arise naturally in severalapplication domains (eg; monitoring of large IP network installations or processing of retail-chain transactions). Estimating the cardinality of set expressions defined over several(possibly distributed) update streams is perhaps one of the most fundamental query classesof interest; as an example; such a query may ask “what is the number of distinct IP sourceaddresses seen in passing packets from both router R 1 and R 2 but not router R 3?”. Earlierwork only addressed very restricted forms of this problem; focusing solely on the special …,The VLDB Journal,2004,40
Efficient Algorithms for Constructing Decision Trees with Constraints,Minos Garofalakis; Dongjoon Hyun; Rajeev Rastogi; Kyuseok Shim,*,*,*,40
Techniques for information dissemination using tree pattern subscriptions and aggregation thereof,*,A set of subscriptions are provided; where one or more subscriptions each comprises a treepattern; and a tree pattern comprises one or more interconnected nodes having a hierarchyand adapted to specify content and structure of information. The set of subscriptions is usedto select information for dissemination to users. Generally; the one or more subscriptionshaving the tree pattern describe information the users are interested in receiving.Techniques are presented for determining an aggregation from the subscriptions; where theaggregation comprises a set of aggregate patterns. The set of subscriptions may comprise anumber of tree patterns; and the aggregate patterns generally also comprise tree patternscomprising one or more interconnected nodes having a hierarchy and adapted to specifycontent and structure of information. The set of aggregation patterns is smaller than the …,*,2004,39
Sketch-based geometric monitoring of distributed stream queries,Minos Garofalakis; Daniel Keren; Vasilis Samoladas,Abstract Emerging large-scale monitoring applications rely on continuous tracking ofcomplex data-analysis queries over collections of massive; physically-distributed datastreams. Thus; in addition to the space-and time-efficiency requirements of conventionalstream processing (at each remote monitor site); effective solutions also need to guaranteecommunication efficiency (over the underlying communication network). The complexity ofthe monitored query adds to the difficulty of the problem--this is especially true for nonlinearqueries (eg; joins); where no obvious solutions exist for distributing the monitor conditionacross sites. The recently proposed geometric method offers a generic methodology forsplitting an arbitrary (non-linear) global threshold-monitoring task into a collection of localsite constraints; still; the approach relies on maintaining the complete stream (s) at each …,Proceedings of the VLDB Endowment,2013,37
Hybrid in-database inference for declarative information extraction,Daisy Zhe Wang; Michael J Franklin; Minos Garofalakis; Joseph M Hellerstein; Michael L Wick,Abstract In the database community; work on information extraction (IE) has centered on twothemes: how to effectively manage IE tasks; and how to manage the uncertainties that arisein the IE process in a scalable manner. Recent work has proposed a probabilistic database(PDB) based declarative IE system that supports a leading statistical IE model; and anassociated inference algorithm to answer top-k-style queries over the probabilistic IEoutcome. Still; the broader problem of effectively supporting general probabilistic inferenceinside a PDB-based declarative IE system remains open. In this paper; we explore the in-database implementations of a wide variety of inference algorithms suited to IE; includingtwo Markov chain Monte Carlo algorithms; the Viterbi and the sum-product algorithms. Wedescribe the rules for choosing appropriate inference algorithms based on the model; the …,Proceedings of the 2011 ACM SIGMOD International Conference on Management of data,2011,36
Querying probabilistic information extraction,Daisy Zhe Wang; Michael J Franklin; Minos Garofalakis; Joseph M Hellerstein,Abstract Recently; there has been increasing interest in extending relational queryprocessing to include data obtained from unstructured sources. A common approach is touse stand-alone Information Extraction (IE) techniques to identify and label entities withinblocks of text; the resulting entities are then imported into a standard database andprocessed using relational queries. This two-part approach; however; suffers from two maindrawbacks. First; IE is inherently probabilistic; but traditional query processing does notproperly handle probabilistic data; resulting in reduced answer quality. Second;performance inefficiencies arise due to the separation of IE from query processing. In thispaper; we address these two problems by building on an in-database implementation of aleading IE model---Conditional Random Fields using the Viterbi inference algorithm. We …,Proceedings of the VLDB Endowment,2010,32
Extended wavelets for multiple measures,Antonios Deligiannakis; Minos Garofalakis; Nick Roussopoulos,Abstract Several studies have demonstrated the effectiveness of the Haar waveletdecomposition as a tool for reducing large amounts of data down to compact waveletsynopses that can be used to obtain fast; accurate approximate answers to user queries.Although originally designed for minimizing the overall mean-squared (ie; L 2-norm) error inthe data approximation; recently proposed methods also enable the use of Haar wavelets inminimizing other error metrics; such as the relative error in data value reconstruction; whichis arguably the most important for approximate query answers. Relatively little attention;however; has been paid to the problem of using wavelet synopses as an approximate queryanswering tool over complex tabular datasets containing multiple measures; such as thosetypically found in real-life OLAP applications. Existing decomposition approaches will …,ACM Transactions on Database Systems (TODS),2007,30
Monitoring distributed streams using convex decompositions,Arnon Lazerson; Izchak Sharfman; Daniel Keren; Assaf Schuster; Minos Garofalakis; Vasilis Samoladas,Abstract Emerging large-scale monitoring applications rely on continuous tracking ofcomplex data-analysis queries over collections of massive; physically-distributed datastreams. Thus; in addition to the space-and time-efficiency requirements of conventionalstream processing (at each remote monitor site); effective solutions also need to guaranteecommunication efficiency (over the underlying communication network). The complexity ofthe monitored query adds to the difficulty of the problem---this is especially true for non-linear queries (eg; joins); where no obvious solutions exist for distributing the monitoredcondition across sites. The recently proposed geometric method; based on the notion ofcovering spheres; offers a generic methodology for splitting an arbitrary (non-linear) globalcondition into a collection of local site constraints; and has been applied to massive …,Proceedings of the VLDB Endowment,2015,28
Lightweight authentication of linear algebraic queries on data streams,Stavros Papadopoulos; Graham Cormode; Antonios Deligiannakis; Minos Garofalakis,Abstract We consider a stream outsourcing setting; where a data owner delegates themanagement of a set of disjoint data streams to an untrusted server. The ownerauthenticates his streams via signatures. The server processes continuous queries on theunion of the streams for clients trusted by the owner. Along with the results; the server sendsproofs of result correctness derived from the owner's signatures; which are easily verifiableby the clients. We design novel constructions for a collection of fundamental problems overstreams represented as linear algebraic queries. In particular; our basic schemesauthenticate dynamic vector sums and dot products; as well as dynamic matrix products.These techniques can be adapted for authenticating a wide range of important operations instreaming environments; including group by queries; joins; in-network aggregation …,Proceedings of the 2013 ACM SIGMOD International Conference on Management of Data,2013,26
Sketch techniques for approximate query processing,Graham Cormode,*,Foundations and Trends in Databases. NOW publishers,2011,26
Resource scheduling for composite multimedia objects,Minos N Garofalakis; Yannis E Ioannidis; Banu Özden,Abstract Scheduling algorithms for composite multimedia presentations need to ensure thatthe user-defined synchronization constraints for the various presentation components aremet. This requirement gives rise to task models that are significantly more complex than themodels employed in scheduling theory and practice. In this paper; we formulate the resourcescheduling problems for composite multimedia ob-jects and develop novel efficientscheduling algorithms drawing on a number of techniques from pattern matching andmultiprocessor scheduling. Our formulation is based on a novel sequence packing problem;where the goal is to superimpose numeric sequences (representing the objects' resourceneeds as a function of time) within a fixed capacity bin (representing the server's resourcecapacity). Given the intractability of the problem; we propose heuristic solutions using a …,VLDB,1998,26
System and method for optimizing open shortest path first aggregates and autonomous network domain incorporating the same,*,Systems and method for selecting open shortest path first (OSPF) aggregates and aggregateweights for a particular area. In one embodiment; an aggregate selecting systemincludes:(1) a database for containing data pertaining to candidate OSPF aggregates andcorresponding weights and (2) an aggregate selector; associated with the database; thatselects at least a subset of the OSPF aggregates such that the shortest path length betweenthe particular source and destination subnets resulting from advertisement of a set ofweighted aggregates approaches the shortest path length between the particular sourceand destination subnets irrespective of the advertisement. In one embodiment; a weightselection system includes:(1) a database for containing data pertaining to candidate OSPFaggregates and (2) a weight assigner; associated with the database; that assigns; for the …,*,2006,25
Composable XML integration grammars,Wenfei Fan; Minos Garofalakis; Ming Xiong; Xibei Jia,Abstract The proliferation of XML as a standard for data representation and exchange indiverse; next-generation Web applications has created an emphatic need for effective XMLdata-integration tools. For several real-life scenarios; such XML data integration needs tobe< i> DTD-directed</i>--in other words; the target; integrated XML database must conformto a prespecified; user-or application-defined DTD. In this paper; we propose a novelformalism;< i> XML Integration Grammars (XIGs)</i>; for specifying DTD-directed integrationof XML data. Abstractly; an XIG maps data from multiple XML sources to a target XMLdocument that conforms to a predefined DTD. An XIG extracts source XML data via queriesexpressed in a fragment of XQuery; and controls target document generation with tree-valued attributes and the target DTD. The novelty of XIGs consists in not only their …,Proceedings of the thirteenth ACM international conference on Information and knowledge management,2004,25
Data Mining Meets Network Management: The NEMESIS Project.,Minos N Garofalakis; Rajeev Rastogi,ABSTRACT Modern communication networks generate large amounts of operational data;including traffic and utilization statistics and alarm/fault data at various levels of detail. Thesemassive collections of network-management data can grow in the order of several Terabytesper year; and typically hide “knowledge” that is crucial to some of the key tasks involved ineffectively managing a communication network (eg; capacity planning and trafficengineering). In this short paper; we provide an overview of some of our recent and ongoingwork in the context of the NEMESIS project at Bell Laboratories that aims to develop noveldata warehousing and mining technology for the effective storage; exploration; and analysisof massive network-management data sets. We first give some highlights of our work onModel-Based Semantic Compression (MBSC); a novel data-compression framework that …,DMKD,2001,25
Resource scheduling in enhanced pay-per-view continuous media databases,Minos N Garofalakis; Banu Özden; Abraham Silberschatz,Abstract The enhanced pay-per-view (EPPV) model for providing continuous-media-on-demand (CMOD) services associates with each continuous media clip a display frequencythat depends on the clip's popularity. The aim is to increase the number of clients that can beserviced concurrently beyond the capacity limitations of available resources; whileguaranteeing a constraint on the response time. This is achieved by sharing periodiccontinuous media streams among multiple clients. In this paper; we provide acomprehensive study of the resource scheduling problems associated with supporting EPPVfor continuous media clips with (possibly) different display rates; frequencies; and lengths.Our main objective is to maximize the amount of disk bandwidth that is effectively scheduledunder the given data layout and storage constraints. This formulation gives rise to NP …,VLDB,1997,25
Scalable data mining with model constraints,Minos Garofalakis; Rajeev Rastogi,ABSTRACT Data mining can be abstractly defined as the process of extracting concise andinteresting models (or; patterns) from large amounts of data. Unfortunately; conventionalmining systems provide users with only very restricted mechanisms for specifying models ofinterest. As a consequence; the mining process is typically characterized by lack of focusand users often end up paying computational costs that are inordinately high compared tothe specific models] patterns of interest. Exploiting user-defined model constraints during themining process can help alleviate this problem and ensure system performance that iscommensurate with the level of user focus. Attaining such performance goals; however; isnot straightforward and; typically; requires the design of novel data mining algorithms thatmake effective use of the model constraints. In this paper; we provide an overview of our …,ACM SIGKDD Explorations Newsletter,2000,24
Probabilistic declarative information extraction,Daisy Zhe Wang; Eirinaios Michelakis; Michael J Franklin; Minos Garofalakis; Joseph M Hellerstein,Unstructured text represents a large fraction of the world's data. It often contains snippets ofstructured information (eg; people's names and zip codes). Information Extraction (IE)techniques identify such structured information in text. In recent years; database researchhas pursued IE on two fronts: declarative languages and systems for managing IE tasks; andprobabilistic databases for querying the output of IE. In this paper; we make the first step tomerge these two directions; without loss of statistical robustness; by implementing a state-of-the-art statistical IE model-Conditional Random Fields (CRF)-in the setting of a ProbabilisticDatabase that treats statistical models as first-class data objects. We show that the Viterbialgorithm for CRF inference can be specified declaratively in recursive SQL. We also showthe performance benefits relative to a standalone open-source Viterbi implementation …,Data Engineering (ICDE); 2010 IEEE 26th International Conference on,2010,23
Join-distinct aggregate estimation over update streams,Sumit Ganguly; Minos Garofalakis; Amit Kumar; Rajeev Rastogi,Abstract There is growing interest in algorithms for processing and querying continuous datastreams (ie; data that is seen only once in a fixed order) with limited memory resources.Providing (perhaps approximate) answers to queries over such streams is a crucialrequirement for many application environments; examples include large IP networkinstallations where performance data from different parts of the network needs to becontinuously collected and analyzed. The ability to estimate the number of distinct (sub)tuples in the result of a join operation correlating two data streams (ie; the cardinality of aprojection with duplicate elimination over a join) is an important requirement for several data-analysis scenarios. For instance; to enable real-time traffic analysis and load balancing; anetwork-monitoring application may need to estimate the number of distinct (< i> source< …,Proceedings of the twenty-fourth ACM SIGMOD-SIGACT-SIGART symposium on Principles of database systems,2005,23
Distributed PCA and network anomaly detection,Ling Huang; Xuanlong Nguyen; Minos Garofalakis; Michael Jordan; A Joseph; Nina Taft,Abstract We consider the problem of network anomaly detection given the data collectedand processed over large distributed systems. Our algorithmic framework can be seen as anapproximate; distributed version of the well-known Principal Component Analysis (PCA)method; which is concerned with continuously tracking the behavior of the data projectedonto the residual subspace of the principal components within error bound guarantees. Ourapproach consists of a protocol for local processing at individual monitoring devices; andglobal decision-making and monitoring feedback at a coordinator. A key ingredient of ourframework is an analytical method based on stochastic matrix perturbation theory forbalancing the tradeoff between the accuracy of our approximate network anomaly detection;and the amount of data communication over the network.,In Proceedings of NIPS,2006,22
Method for distributed tracking of approximate join size and related summaries,*,A method of distributed approximate query tracking relies on tracking general-purposerandomized sketch summaries of local streams at remote sites along with concise predictionmodels of local site behavior in order to produce highly communication-efficient andspace/time-efficient solutions. A powerful approximate query tracking framework readilyincorporates several complex analysis queries; including distributed join and multi-joinaggregates and approximate wavelet representations; thus giving the first known low-overhead tracking solution for such queries in the distributed-streams model.,*,2010,21
Probabilistic histograms for probabilistic data,Graham Cormode; Antonios Deligiannakis; Minos Garofalakis; Andrew McGregor,Abstract There is a growing realization that modern database management systems(DBMSs) must be able to manage data that contains uncertainties that are represented inthe form of probabilistic relations. Consequently; the design of each core DBMS componentmust be revisited in the presence of uncertain and probabilistic information. In this paper; westudy how to build histogram synopses for probabilistic relations; for the purposes ofenabling both DBMS-internal decisions (such as indexing and query planning); and(possibly; user-facing) approximate query processing tools. In contrast to initial work in thisarea; our probabilistic histograms retain the key possible-worlds semantics of probabilisticdata; allowing for more accurate; yet concise; representation of the uncertaintycharacteristics of data and query results. We present a variety of techniques for building …,Proceedings of the VLDB Endowment,2009,21
Methods and apparatus for representing probabilistic data using a probabilistic histogram,*,Methods and apparatus for representing probabilistic data using a probabilistic histogramare disclosed. An example method comprises partitioning a plurality of ordered data itemsinto a plurality of buckets; each of the data items capable of having a data value from aplurality of possible data values with a probability characterized by a respective individualprobability distribution function (PDF); each bucket associated with a respective subset ofthe ordered data items bounded by a respective beginning data item and a respectiveending data item; and determining a first representative PDF for a first bucket associatedwith a first subset of the ordered data items by partitioning the plurality of possible datavalues into a first plurality of representative data ranges and respective representativeprobabilities based on an error between the first representative PDF and a first plurality of …,*,2012,20
Method for performing information-preserving DTD schema embeddings,*,Method for performing information-preserving DTD schema embeddings between a sourceschema when matching a source schema and a target schema. The preservation is realizedby a matching process between the two schemas that finds a first string marking of the targetschema; evaluates a legality of the first string marking; determines an estimated minimal costof the first string marking and subsequently adjusts the estimated minimal cost based uponone to one mapping of source schema and target schema subcomponents.,*,2009,20
Document descriptor extraction method,*,The present invention discloses a document descriptor extraction method and system. Thedocument descriptor extraction method and system creates a document descriptor bygeneralizing input sequences within a document; factoring the input sequences andgeneralized input sequences; and selecting a document descriptor from the inputsequences; generalized sequences; and factored sequences; preferably using minimumdescriptor length (MDL) principles. Novel algorithms are employed to perform thegeneralizing; factoring; and selecting.,*,2006,20
Distributed geometric query monitoring using prediction models,Nikos Giatrakos; Antonios Deligiannakis; Minos Garofalakis; Izchak Sharfman; Assaf Schuster,Abstract Many modern streaming applications; such as online analysis of financial; network;sensor; and other forms of data; are inherently distributed in nature. An important query typethat is the focal point in such application scenarios regards actuation queries; where properaction is dictated based on a trigger condition placed upon the current value that amonitored function receives. Recent work [Sharfman et al. 2006; 2007b; 2008] studies theproblem of (nonlinear) sophisticated function tracking in a distributive manner. The mainconcept behind the geometric monitoring approach proposed there is for each distributedsite to perform the function monitoring over an appropriate subset of the input domain. In thecurrent work; we examine whether the distributed monitoring mechanism can become moreefficient; in terms of the number of communicated messages; by extending the geometric …,ACM Transactions on Database Systems (TODS),2014,19
On periodic resource scheduling for continuous-media databases,Minos N Garofalakis; Banu Özden; Avi Silberschatz,Abstract. The Enhanced Pay-Per-View (EPPV) model for providing continuous-mediaservices associates with each continuous-media clip a display frequency that depends onthe clip's popularity. The aim is to increase the number of clients that can be servicedconcurrently beyond the capacity limitations of available resources; while guaranteeing aconstraint on the response time. This is achieved by sharing periodic continuous-mediastreams among multiple clients. The EPPV model offers a number of advantages over otherdata-sharing schemes (eg; batching); which make it more attractive to large-scale serviceproviders. In this paper; we provide a comprehensive study of the resource-schedulingproblems associated with supporting EPPV for continuous-media clips with (possibly)different display rates; frequencies; and lengths. Our main objective is to maximize the …,The VLDB Journal,1998,19
Practical private range search revisited,Ioannis Demertzis; Stavros Papadopoulos; Odysseas Papapetrou; Antonios Deligiannakis; Minos Garofalakis,Abstract We consider a data owner that outsources its dataset to an untrusted server. Theowner wishes to enable the server to answer range queries on a single attribute; withoutcompromising the privacy of the data and the queries. There are several schemes on"practical" private range search (mainly in Databases venues) that attempt to strike a trade-offbetween efficiency and security. Nevertheless; these methods either lack provable securityguarantees; or permit unacceptable privacy leakages. In this paper; we take aninterdisciplinary approach; which combines the rigor of Security formulations and proofs withefficient Data Management techniques. We construct a wide set of novel schemes withrealistic security/performance trade-offs; adopting the notion of Searchable SymmetricEncryption (SSE) primarily proposed for keyword search. We reduce range search to …,Proceedings of the 2016 International Conference on Management of Data,2016,18
Continuous fragmented skylines over distributed streams,Odysseas Papapetrou; Minos Garofalakis,Distributed skyline computation is important for a wide range of application domains; fromdistributed and web-based systems to ISP-network monitoring and distributed databases.The problem is particularly challenging in dynamic distributed settings; where the goal is toefficiently monitor a continuous skyline query over a collection of distributed streams. Allexisting work relies on the assumption of a single point of reference for objectattributes/dimensions; ie; objects may be vertically or horizontally partitioned; but theaccurate value of each dimension for each object is always maintained by a single site. Thisassumption is unrealistic for several distributed monitoring applications; where objectinformation is fragmented over a set of distributed streams (each monitored by a differentsite) and needs to be aggregated (eg; averaged) across several sites. Furthermore; it is …,Data Engineering (ICDE); 2014 IEEE 30th International Conference on,2014,17
Method and system for resource scheduling composite multimedia objects,*,A system for the effective resource scheduling of composite multimedia objects involves asequence packing formulation of the composite object scheduling problem and associatedefficient algorithms using techniques from pattern matching and multiprocessor scheduling.An associated method of scheduling the provision of composite multimedia objects; eachcomprising one or more continuous media streams of audio data; video data and other data;where the continuous media streams are of varying bandwidth requirement and durationcomprise the steps of; generating composite multimedia objects from the continuous mediastreams and determining a run-length compressed form for each of the generated compositemultimedia objects.,*,2003,16
Automated document classifier tuning including training set adaptive to user browsing behavior,*,Subject matter disclosed herein relates to document classification and/or automateddocument classifier tuning. In an example embodiment; a document received from a usercomputing platform in an online database stored in a memory of a server computing platformmay be classified based; at least in part; on a training set. Also for an example embodiment;the training set may be modified based; at least in part; on statistics gathered from userbrowsing behavior.,*,2010,15
Method and apparatus for secure processing of XML-based documents,*,Method for providing controlled access to an XML document includes defining at least oneaccess control policy for a user of the XML document; deriving a security view of the XMLdocument for the user based upon said access control policy and schema level processingof the XML document and translating a user query based on the security view of the XMLdocument to an equivalent query based on the XML document. An apparatus for sameincludes means for defining an access control policy for a user of the XML document andmeans for deriving a security view of the XML document for the user based on said accesscontrol policy and schema level processing of the XML document. Also included are meansfor translating a user query based on the security view of the XML document to an equivalentquery based on the XML document.,*,2008,15
Scheduling issues in multimedia query optimization,Minos N Garofalakis; Yannis E Ioannidis,This paper examines the scheduling of concurrent requests on multimedia storage serversconsisting of multiple resources; which is a central issue in processing and optimization ofcomplex queries in multimedia database systems [Chaudhuri 1994]. It introduces a formalmodel for the demands imposed by multimedia requests on the server resources; describeda heuristic algorithm for scheduling the requests that is based on the formal model; andpresents a formal result that bounds the performance of the schedule produced by thealgorithm compared to the optimal schedule. Scheduling requests that involve continuousmedia data types; for example; audio and video objects; is a challenging problem due to thefollowing distinguishing characteristics of multimedia environments:,ACM Computing Surveys (CSUR),1995,14
Method and apparatus for globally approximating quantiles in a distributed monitoring environment,*,The invention comprises a method and apparatus for determining a rank of a query value.Specifically; the method comprises receiving a rank query request; determining; for each ofthe at least one remote monitor; a predicted lower-bound rank value and upper-bound rankvalue; wherein the predicted lower-bound rank value and upper-bound rank value aredetermined according to at least one respective prediction model used by each of the atleast one remote monitor to compute the at least one local quantile summary; computing apredicted average rank value for each of the at least one remote monitor using the at leastone predicted lower-bound rank value and the at least one predicted upper-bound rankvalue associated with the respective at least one remote monitor; and computing the rank ofthe query value using the at least one predicted average rank value associated with the …,*,2010,13
Filtering; punctuation; windows and synopses,David Maier; Peter A Tucker; Minos Garofalakis,Abstract This chapter addresses some of the problems raised by the high-volume;nonterminating nature of many data streams. We begin by outlining challenges for queryprocessing over such streams; such as outstripping CPU or memory resources; operatorsthat wait for the end of input and unbounded query state. We then consider varioustechniques for meeting those challenges. Filtering attempts to reduce stream volume inorder to save on system resources. Punctuations incorporate semantics on the structure of astream into the stream itself; and can help unblock query operators and reduce the state theymust retain. Windowing modifies a query so that processing takes place on finite subsets offull streams. Synopses are compact; efficiently maintained summaries of data that canprovide approximate answers to particular queries.,*,2005,13
Fractional XSKETCH synopses for XML databases,Natasha Drukh; Neoklis Polyzotis; Minos Garofalakis; Yossi Matias,Abstract A key step in the optimization of declarative queries over XML data is estimating theselectivity of path expressions; ie; the number of elements reached by a specific navigationpattern through the XML data graph. Recent studies have introduced XSketch structuralgraph synopses as an effective; space-efficient tool for the compile-time estimation ofcomplex path-expression selectivities over graph-structured; schema-less XML data. Briefly;XSketch es exploit localized graph stability and well-founded statistical assumptions toaccurately approximate the path and branching distribution in the underlying XML datagraph. Empirical results have demonstrated the effectiveness of XSketch summaries overreal-life and synthetic data sets; and for a variety of path-expression workloads. In this paper;we introduce fractional XSketch es (f XSketches) a simple; yet intuitive and very effective …,International XML Database Symposium,2004,13
Dtd inference from xml documents: The xtract approach,Minos Garofalakis; Aristides Gionis; Rajeev Rastogi; S Seshadri; Kyuseok Shim,Abstract XML is rapidly emerging as the new standard for data representation and exchangeon the Web. Document Type Descriptors (DTDs) contain valuable information on thestructure of XML documents and thus have a crucial role in the efficient storage andquerying of XML data. Despite their importance; however; DTDs are not mandatory; and it isquite possible for documents in XML databases to not have accompanying DTDs. In thispaper; we present an overview of XTRACT; a novel system for inferring a DTD schema for adatabase of XML documents. Since the DTD syntax incorporates the full expressive power ofregular expressions; naive approaches typically fail to produce concise and intuitive DTDs.Instead; the XTRACT inference algorithms employ a sequence of sophisticated steps thatinvolve:(1) finding patterns in the input sequences and replacing them with regular …,IEEE Data Engineering Bulletin,2003,13
Fast approximate wavelet tracking on streams,*,The first fast solution to the problem of tracking wavelet representations of one-dimensionaland multi-dimensional data streams based on a stream synopsis; the Group-Count Sketch(GCS) is provided. By imposing a hierarchical structure of groups over the data and applyingthe GCS; our algorithms can quickly recover the most important wavelet coefficients withguaranteed accuracy. A tradeoff between query time and update time is established; byvarying the hierarchical structure of groups; allowing the right balance to be found forspecific data streams. Experimental analysis confirmed this tradeoff; and showed that all themethods significantly outperformed previously known methods in terms of both update timeand query time; while maintaining a high level of accuracy.,*,2011,12
Reviewer profiling using sparse matrix regression,Evangelos E Papalexakis; Nicholas D Sidiropoulos; Minos N Garofalakis,Thousands of scientific conferences happen every year; and each involves a laboriousscientific peer review process conducted by one or more busy scientists serving asTechnical/Scientific Program Committee (TPC) chair (s). The chair (s) must match submittedpapers to their reviewer pool in such a way that i) each paper is reviewed by experts in itssubject matter; and ii) no reviewer is overloaded with reviews or under-utilized. Towards thisend; seasoned TPC chairs know the value of reviewer and paper profiling: summarizing theexpertise/interests of each reviewer and the subject matter of each paper using judiciouslychosen domain-specific keywords. An automated profiling algorithm is proposed for thispurpose; which starts from generic/noisy reviewer profiles extracted using Google Scholarand derives custom conference-centric reviewer and paper profiles. Each reviewer is …,Data Mining Workshops (ICDMW); 2010 IEEE International Conference on,2010,12
Issues in complex event processing: Status and prospects in the big data era,Ioannis Flouris; Nikos Giatrakos; Antonios Deligiannakis; Minos Garofalakis; Michael Kamp; Michael Mock,Abstract Many Big Data technologies were built to enable the processing of humangenerated data; setting aside the enormous amount of data generated from Machine-to-Machine (M2M) interactions and Internet-of-Things (IoT) platforms. Such interactions createreal-time data streams that are much more structured; often in the form of series of eventoccurrences. In this paper; we provide an overview on the main research issues confrontedby existing Complex Event Processing (CEP) techniques; with an emphasis on queryoptimization aspects. Our study expands on both deterministic and probabilistic eventmodels and spans from centralized to distributed network settings. In that; we cover a widerange of approaches in the CEP domain and review the current status of techniques thattackle efficient query processing. These techniques serve as a starting point for …,Journal of Systems and Software,2017,11
Public Health for the Internet φ Towards A New Grand Challenge for Information Management,Joseph M Hellerstein; Tyson Condie; Minos Garofalakis; Boon Thau Loo; Petros Maniatis; Timothy Roscoe; Nina A Taft,Abstract Business incentives have brought us within a small factor of achieving the databasecommunity's Grand Challenge set out in the Asilomar Report of 1998. This paper makes thecase for a new; focused Grand Challenge: Public Health for the Internet. The goal of PHI (orφ) is to enable collectives of hosts on the Internet to jointly monitor and promote networkhealth by sharing information on network conditions in a peer-to-peer fashion. We argue thatthis will be a positive effort for the research community for a variety of reasons; both in termsof its technical reach and its societal impact.,*,2007,11
A Fast Approximation Scheme for Probabilistic Wavelet Synopses.,Antonios Deligiannakis; Minos N Garofalakis; Nick Roussopoulos,Abstract Several studies have demonstrated the effectiveness of Haar wavelets in reducinglarge amounts of data down to compact wavelet synopses that can be used to obtain fast;accurate approximate query answers. While Haar wavelets were originally designed forminimizing the overall root-mean-squared (ie; L2-norm) error in the data approximation; therecently-proposed idea of probabilistic wavelet synopses also enables their use inminimizing other error metrics; such as the relative error in individual datavaluereconstruction; which is arguably the most important for approximate query processing.Known construction algorithms for probabilistic wavelet synopses employ probabilisticschemes for coefficient thresholding that are based on optimal Dynamic-Programming (DP)formulations over the error-tree structure for Haar coefficients. Unfortunately; these (exact) …,SSDBM,2005,11
Efficient Strategies for Continuous Distributed Tracking Tasks.,Graham Cormode; Minos N Garofalakis,Abstract While traditional databases have focused on single query evaluation in acentralized setting; emerging applications require continuous tracking of queries on datathat is widely distributed and constantly updated. We describe such scenarios; and describethe challenges involved in designing communication-efficient protocols for the tracking taskswe define. We outline some solutions to these problems; by abstracting a model of thecommunication system; defining the tracking tasks of interest; and building query-trackingschemes based on three guiding principles of minimizing global information; usingsummaries to capture whole data streams; and seeking stability of the protocols.,IEEE Data Eng. Bull.,2005,11
Methods and apparatus to construct histogram and wavelet synopses for probabilistic data,*,Example methods and apparatus to construct histogram and wavelet synopses forprobabilistic data are disclosed. A disclosed example method involves receivingprobabilistic data associated with probability measures and generating a plurality ofhistograms based on the probabilistic data. Each histogram is generated based on itemsrepresented by the probabilistic data. In addition; each histogram is generated using adifferent quantity of buckets containing different ones of the items. An error measureassociated with each of the plurality of histograms is determined and one of the plurality ofhistograms is selected based on its associated error measure. The method also involvesdisplaying parameter information associated with the one of the plurality of histograms torepresent the data.,*,2013,10
Display advertising inventory estimation,*,With networks such as the Internet gaining tremendous popularity and with the vast multitudeof pages and/or other documents and/or other media content becoming available to users viathe World Wide Web (web); for example; Web-based display advertising has increased in importanceand prominence as industry seeks to take better advantage of the opportunities potentially affordedby these networks; including the Internet. In Web-based advertising systems; advertisementsmay be embedded in web pages that may be accessed by users via web browser applicationsexecuted on any of a number of electronic device types. In such systems; it may be advantageousto present particular advertisements to particular users or types of users … FIG. 5 is a blockdiagram illustrating an example system comprising a plurality of computing devices coupledvia a network in accordance with one or more embodiments … Reference is made in …,*,2010,10
Tree-pattern similarity estimation for scalable content-based routing,Raphaël Chand; Pascal Felber; Minos Garofalakis,With the advent of XML as the de facto language for data publishing and exchange; scalabledistribution of XML data to large; dynamic populations of consumers remains an importantchallenge. Content-based publish/subscribe systems offer a convenient design paradigm;as most of the complexity related to addressing and routing is encapsulated within thenetwork infrastructure. To indicate the type of content that they are interested in; dataconsumers typically specify their subscriptions using a tree-pattern specification language(an important subset of XPath); while producers publish XML content without priorknowledge of any potential recipients. Discovering semantic communities of consumers withsimilar interests is an important requirement for scalable content-based systems: such"semantic clusters" of consumers play a critical role in the design of effective content …,Data Engineering; 2007. ICDE 2007. IEEE 23rd International Conference on,2007,10
Exploratory DSP-wavelet-based approximation techniques in database systems,Minos Garofalakis,Several recent studies have demonstrated the effectiveness of the wavelet transform as atool for approximate query processing over massive relational tables and continuous datastreams. The idea is to apply wavelet transform to the input relation to obtain a compact datasynopsis that comprises a select small collection of wavelet coefficients. The excellentenergy compaction and decorrelation properties of the wavelet transform allow for conciseand effective approximate representations that exploit the structure of the data. Furthermore;wavelet transforms can generally be computed in linear time; thus allowing for very efficientalgorithms. This paper provides a brief overview of recent work and results on wavelet-based approximation techniques for relational database systems,IEEE Signal processing magazine,2006,10
Competitive on-line scheduling of continuous-media streams,Minos Garofalakis; Yannis Ioannidis; Banu Özden; Avi Silberschatz,Abstract Multimedia applications require a guaranteed level of service for accessingcontinuous-media data. To obtain such guarantees; the database server where the data areresiding must employ an admission control scheme to limit the number of clients that can beserved concurrently. We investigate the problem of on-line admission control; where thedecision of whether to accept or reject a request must be made without any knowledgeabout future requests. Employing competitive analysis techniques; we address the problemin its most general form with the following key contributions:(1) We prove a tight upper boundon the competitive ratio of the conventional Work-Conserving (WC) policy; showing that it iswithin a factor 1+ Δ 1− ρ of the optimal clairvoyant strategy; where Δ is the ratio of themaximum to minimum request length (ie; time duration); and ρ is the maximum fraction of …,Journal of Computer and System Sciences,2002,10
Of crawlers; portals; mice; and men: is there more to mining the Web?,Minos N Garofalakis; Sridhar Ramaswamy; Rajeev Rastogi; Kyuseok Shim,Abstract The World Wide Web is rapidly emerging as an important medium for transactingcommerce as well as for the dissemination of information related to a wide range of topics(eg; business; government; recreation). According to most predictions; the majority of humaninformation will be available on the Web in ten years. These huge amounts of data raise agrand challenge for the database community; namely; how to turn the Web into a moreuseful information utility. This is exactly the subject that will be addressed by this panel.,ACM SIGMOD Record,1999,10
Declarative networking with distributed recursive query processing,Boon Thau Loo; Tyson Condie; Minos Garofalakis; DE Gay; Joseph M Hellerstein; Petros Maniatis; Raghu Ramakrishnan; Timothy Roscoe; Ion Stoica,ABSTRACT There have been recent proposals in the networking and distributed systemsliterature on declarative networking; where network protocols are declaratively specifiedusing a recursive query language. This represents a significant new application area forrecursive query processing technologies from databases. In this paper; we extend uponthese recent proposals in the following ways. First; we motivate and formally define theNDlog language for declarative network specifications. We introduce the concept of link-restricted rules; which can be syntactically guaranteed to be executable via single-nodederivations and message passing on an underlying network graph. Second; we introduceand prove correct relaxed versions of the traditional semi-naive execution technique thatovercome fundamental problems of traditional semi-naıve evaluation in an asynchronous …,ACM SIGMOD International Conference on Management of Data,2006,8
Optimal configuration of OSPF aggregates,Yuri Breitbart; Minos Garofalakis; Amit Kumar; Rajeev Rastogi,Abstract Open Shortest Path First (OSPF) is a popular protocol for routing within anAutonomous System (AS) domain. In order to scale for large networks containing hundredsand thousands of subnets; OSPF supports a twolevel hierarchical routing scheme throughthe use of OSPF areas. Each area consists of a set of interconnected subnets and trafficacross areas is handled by routers attached to two or more areas; known as Area BorderRouters (ABRs). OSPF ABRs are typically configured to aggregate the subnet addresses intheir areas and to advertise these aggregates in the remainder of the network instead ofindividual subnet addresses. Address aggregation within areas is a crucial requirement forscaling OSPF to large AS domains; as it results in significant reductions in routing tablesizes; smaller link-state databases; and less network traffic to synchronize the router link …,Proc. of IEEE INFOCOM02; New York; USA,2002,8
Sketching distributed sliding-window data streams,Odysseas Papapetrou; Minos Garofalakis; Antonios Deligiannakis,Abstract While traditional data management systems focus on evaluating single; ad hocqueries over static data sets in a centralized setting; several emerging applications require(possibly; continuous) answers to queries on dynamic data that is widely distributed andconstantly updated. Furthermore; such query answers often need to discount data that is“stale” and operate solely on a sliding window of recent data arrivals (eg; data updatesoccurring over the last 24 h). Such distributed data streaming applications mandate novelalgorithmic solutions that are both time and space efficient (to manage high-speed datastreams) and also communication efficient (to deal with physical data distribution). In thispaper; we consider the problem of complex query answering over distributed; high-dimensional data streams in the sliding-window model. We introduce a novel sketching …,The VLDB Journal,2015,7
Multi-query optimization for sketch-based estimation,Alin Dobra; Minos Garofalakis; Johannes Gehrke; Rajeev Rastogi,Abstract Randomized techniques; based on computing small “sketch” synopses for eachstream; have recently been shown to be a very effective tool for approximating the result of asingle SQL query over streaming data tuples. In this paper; we investigate the problemsarising when data-stream sketches are used to process multiple such queries concurrently.We demonstrate that; in the presence of multiple query expressions; intelligently sharingsketches among concurrent query evaluations can result in substantial improvements in theutilization of the available sketching space and the quality of the resulting approximationerror guarantees. We provide necessary and sufficient conditions for multi-query sketchsharing that guarantee the correctness of the result-estimation process. We also investigatethe difficult optimization problem of determining sketch-sharing configurations that are …,Information Systems,2009,7
Distributed data streams,Minos Garofalakis,realized using such logical structures. For example; in tree based data acquisition protocols;a collection tree is built that is rooted at the data collection center such as the sink node [8].The dissemination of the data requests from the participating nodes and collection of datafrom the sensor nodes are accomplished using this tree. A cluster based data acquisitionmechanism has been proposed in [3]. As shown in Fig. 1; nodes are organized into a fixednumber of clusters; and nodes within each cluster dynamically elect a cluster head. The dataacquisition is carried out in two phases. In the first phase; cluster heads collect data fromtheir cluster nodes. In the second phase; cluster heads send collected data to the nodes thathave subscribed to the data. The cluster heads are re-elected to balance energyconsumption among the nodes in the cluster. Zhang et al.[13] have proposed an adaptive …,*,2009,7
SPARTAN: using constrained models for guaranteed-error semantic compression,Shivnath Babu; Minos Garofalakis; Rajeev Rastogi,Abstract While a variety of lossy compression schemes have been developed for certainforms of digital data (eg; images; audio; video); the area of lossy compression techniques forarbitrary data tables has been left relatively unexplored. Nevertheless; such techniques areclearly motivated by the ever-increasing data collection rates of modern enterprises and theneed for effective; guaranteed-quality approximate answers to queries over massiverelational data sets. In this paper; we propose SPARTAN; a system that takes advantage ofattribute semantics and data-mining models to perform lossy compression of massive datatables. SPARTAN is based on the novel idea of exploiting predictive data correlations andprescribed error-tolerance constraints for individual attributes to construct concise andaccurate Classification and Regression Tree (CaRT) models for entire columns of a table …,ACM SIGKDD Explorations Newsletter,2002,7
Guest Editors' Introduction: Special Section on Mining Large Uncertain and Probabilistic Databases,Reynold Cheng; Michael Chau; Minos Garofalakis; Jeffrey Xu Yu,RECENT years have witnessed the emergence of novel database applications in various nontraditionaldo- mains; including location-based services; sensor networks; RFID systems; and biologicaland biometric databases. Traditionally; data mining has been widely used to reveal interestingpatterns in the vast amounts of data generated by such applications. However; for most of theseemerging domains; data is often riddled with uncertainty; arising; for instance; from inherent measurementinaccuracies; sampling and curation errors; and network latencies; or even from intentional blurringof the data (to preserve anonymity). Such forms of data uncertainty have to be handledcarefully; or else the results of long and tedious data analyses could be inaccurate or evenincorrect. In particular; it is important to collect and distill the knowledge from experts in developingmining and data processing methods that are uncertainty- aware. Recently; there has …,IEEE Transactions on Knowledge and Data Engineering,2010,6
Probabilistic wavelet synopses for multiple measures,*,A technique for building probabilistic wavelet synopses for multi-measure data sets isprovided. In the presence of multiple measures; it is demonstrated that the problem of exactprobabilistic coefficient thresholding becomes significantly more complex. An algorithmicformulation for probabilistic multi-measure wavelet thresholding based on the idea of partial-order dynamic programming (PODP) is provided. A fast; greedy approximation algorithm forprobabilistic multi-measure thresholding based on the idea of marginal error gains isprovided. An empirical study with both synthetic and real-life data sets validated theapproach; demonstrating that the algorithms outperform naive approaches based onoptimizing individual measures independently and the greedy thresholding schemeprovides near-optimal and; at the same time; fast and scalable solutions to the …,*,2007,6
Throughput-competitive admission control for continuous media databases,Minos N Garofalakis; Yannis E Ioannidis; Banu Özden; Avi Silberschatz,Multimedia applications require a guaranteed level of service for accessing ContinuousMedia (CM) data; such as video and audio. To obtain such guarantees; the database serverwhom the data is residing must employ an admission control schomo to limit the number ofclients that can be served concurrently; We investigate the problem of on-line admissioncontrol where the decision on whether to accept or reject a request must bc made withoutany knowledge about future rcqucsts. Employing competitive analysis techniques; weaddress the problem in its most general form with the following key contributions:(1) weprove a tight upper bound on the competitive ratio of the conventional Work-Conserving(WC) policy; showing that it is within a factor e of the optimal clairvoyant strategy that knowsthe entire request scquoncc in advance; where A is the ratio of the maximum to minimum …,Proceedings of the seventeenth ACM SIGACT-SIGMOD-SIGART symposium on Principles of database systems,1998,6
Issues in complex event processing systems,Ioannis Flouris; Nikos Giatrakos; Minos Garofalakis; Antonios Deligiannakis,Many Big Data technologies were built to enable the processing of human generated data;setting aside the enormous amount of data generated from Machine-to-Machine (M2M)interactions. M2M interactions create real-time data streams that are much more structured;often in the form of series of event occurrences. In this paper; we provide an overview on themain research issues confronted by existing Complex Event Processing (CEP) techniques;as a starting point for Big Data applications that enable the monitoring of complex eventoccurrences in M2M interactions.,Trustcom/BigDataSE/ISPA; 2015 IEEE,2015,5
Biological interaction networks based on sparse temporal expansion of graphical models,KD Kalantzaki; Ekaterini S Bei; M Garofalakis; M Zervakis,Biological networks are often described as probabilistic graphs in the context of gene andprotein sequence analysis in molecular biology. Microarrays and proteomics technologyallow the monitoring of expression levels over thousands of biological units over time. Inexperimental efforts we are interested in unveiling pairwise interactions. Many graphicalmodels have been introduced in order to discover associations from the expression dataanalysis. However; the small size of samples compared to the number of observedgenes/proteins makes the inference of the network structure quite challenging. In this studywe generate gene-protein networks from sparse experimental data using two methods;partial correlations and Kernel Density Estimation; in order to capture genetic interactions.Dynamic Gaussian analysis is used to match special characteristics to genes and …,Bioinformatics & Bioengineering (BIBE); 2012 IEEE 12th International Conference on,2012,5
Declarative information extraction in a probabilistic database system,D Wang; Eirinaios Michelakis; M Garofalakis; MJ Franklin; Joseph M Hellerstein,ABSTRACT Full-text documents represent a large fraction of the world's data. Although notstructured per se; they often contain snippets of structured information within them: eg;names; addresses; and document titles. Information Extraction (IE) techniques identify suchstructured information in text. In recent years; database research has pursued IE on twofronts: declarative languages and systems for managing IE tasks; and IE as an uncertaindata source for Probabilistic Databases. It is natural to consider merging these twodirections; but efforts to do so have had to compromise on the statistical robustness of IEalgorithms in order to fit with early Probabilistic Database models. In this paper; we bridgethe gap between these ideas by implementing a state-of-the-art statistical IE approach–Conditional Random Fields (CRFs)–in the setting of Probabilistic Databases that treat …,Proc. of the 26th ICDE Conf,2010,5
Communication-efficient tracking of distributed triggers,Ling Huang; Minos Garofalakis; Anthony D Joseph; Nina Taft,Abstract There has been growing interest in large-scale distributed monitoring systems; suchas Dynamic Denial of Service attack detectors and sensornet-based environmentalmonitors. Recent work has posited that these infrastructures lack a critical component;namely a distributed-triggering mechanism that fires when an aggregate of remote-sitebehavior exceeds some threshold. For several scenarios; the trigger conditions of interestare naturally cumulative; they continuously monitor the accumulation of threshold infractions(eg; resource overuse) over time. In this paper; we develop a novel framework andcommunicationefficient protocols to support distributed cumulative triggers. In sharp contrastto earlier work focusing on instantaneous violations; we introduce a general model ofthreshold conditions that enables us to track distributed cumulative violations over time …,*,2006,5
Ferari: A prototype for complex event processing over streaming multi-cloud platforms,Ioannis Flouris; Vasiliki Manikaki; Nikos Giatrakos; Antonios Deligiannakis; Minos Garofalakis; Michael Mock; Sebastian Bothe; Inna Skarbovsky; Fabiana Fournier; Marko Stajcer; Tomislav Krizan; Jonathan Yom-Tov; Taji Curin,Abstract In this demo; we present FERARI; a prototype that enables real-time Complex EventProcessing (CEP) for large volume event data streams over distributed topologies. Ourprototype constitutes; to our knowledge; the first complete; multi-cloud based end-to-endCEP solution incorporating: a) a user-friendly; web-based query authoring tool;(b) apowerful CEP engine implemented on top of a streaming cloud platform;(c) a CEP optimizerthat chooses the best query execution plan with respect to low latency and/or reduced inter-cloud communication burden; and (d) a query analytics dashboard encompassing graphand map visualization tools to provide a holistic picture with respect to the detected complexevents to final stakeholders. As a proof-of-concept; we apply FERARI to enable mobile frauddetection over real; properly anonymized; telecommunication data from T-Hrvatski …,Proceedings of the 2016 International Conference on Management of Data,2016,4
Allocation of internet advertising inventory,*,A method and system for allocating inventory in an Internet environment is provided. Amethod employed by the system may include generating an inventory pool that represents anumber of impressions deliverable to all users; then determining; from multiple past ordersfor booking impressions; a hierarchy of parameters utilized to target users and a number ofimpressions deliverable to users characterized by the parameters. The inventory pool maythen be partitioned into multiple inventory pools according to the hierarchy; where eachinventory pool represents a number of impressions deliverable to users characterized byparameters associated with the inventory pool. The hierarchy of pools may then be stored toa database.,*,2010,4
System and methods for generating diversified vertical search listings,*,A method of generating a diversified vertical search results listing; including listing attributevalues related to search criteria and their frequency of occurrence to create a plurality oflistings; creating a plurality of interval bands based on the plurality of listings; generating arandom diversity score for each listing over a substantially uniform distribution within each ofthe plurality of bands; and sorting a set of search results for diversified listing in response toa user searching for the search criteria according to the diversity score of each listing.,*,2009,4
Scalable approximate query tracking over highly distributed data streams,Nikos Giatrakos; Antonios Deligiannakis; Minos Garofalakis,Abstract The recently-proposed Geometric Monitoring (GM) method has provided a generaltool for the distributed monitoring of arbitrary non-linear queries over streaming dataobserved by a collection of remote sites; with numerous practical applications. Unfortunately;GM-based techniques can suffer from serious scalability issues with increasing numbers ofremote sites. In this paper; we propose novel techniques that effectively tackle theaforementioned scalability problems by exploiting a carefully designed sample of the remotesites for efficient approximate query tracking. Our novel sampling-based scheme utilizes asample of cardinality proportional to√ N (compared to N for the original GM); where $ N $ isthe number of sites in the network; to perform the monitoring process. Our experimentalevaluation over a variety of real-life data streams demonstrates that our sampling-based …,Proceedings of the 2016 International Conference on Management of Data,2016,3
Leveraging Reconfigurable Computing in Distributed Real-time Computation Systems.,Apostolos Nydriotis; Pavlos Malakonakis; Nikos Pavlakis; Grigorios Chrysos; Ekaterini Ioannou; Euripides Sotiriades; Minos N Garofalakis; Apostolos Dollas,ABSTRACT The community of Big Data processing typically performs realtime computationson data streams with distributed systems such as the Apache Storm. Such systems offersubstantial parallelism; however; the communication overhead among nodes for thedistribution of the workload places an upper limit to the exploitable parallelism. Thecontribution of the present work is the integration of a reconfigurable platform with theApache Storm; which is the main platform of the Big Data streaming processing community.By exploiting the internal bandwidth of FPGAs we show that the computational limits forstream processing are significantly increased vs. conventional distributed processingwithout compromising on the platform of choice or its seamless operation in a dynamicpipeline. The integration of a Maxeler MPC-C Series platform with the Apache Storm; as …,EDBT/ICDT Workshops,2016,3
Grammar and method for integrating XML data from multiple sources,*,A grammar for mapping a first grouping of XML data into a second grouping of XML data anda method for accomplishing same to incorporate the first grouping into the second grouping.The grammar includes a first rule for computing a first child element attribute and a secondrule for computing a second parent element attribute. The first rule and second rule varyaccording to a production of an element type of the first grouping. The element types includePCDATA; disjunctive; conjunctive and Kleene star; each having a unique rule set fordefining inherited and synthesized attributes of the parent and child elements. The methodincludes the step of executing a mapping of a first grouping having at least one parentelement and a set of corresponding child elements into a second grouping in accordancewith the grammar rules based on the production of the element type.,*,2015,3
Nonparametric network design and analysis of disease genes in oral cancer progression,K Kalantzaki; Ekaterini S Bei; Konstantinos P Exarchos; M Zervakis; M Garofalakis; Dimitrios I Fotiadis,Biological networks in living organisms can be seen as the ultimate means of understandingthe underlying mechanisms in complex diseases; such as oral cancer. During the lastdecade; many algorithms based on high-throughput genomic data have been developed tounravel the complexity of gene network construction and their progression in time. However;the small size of samples compared to the number of observed genes makes the inferenceof the network structure quite challenging. In this study; we propose a framework forconstructing and analyzing gene networks from sparse experimental temporal data andinvestigate its potential in oral cancer. We use two network models based on partialcorrelations and kernel density estimation; in order to capture the genetic interactions. Usingthis network construction framework on real clinical data of the tissue and blood at …,IEEE journal of biomedical and health informatics,2014,3
Biological interaction networks based on non-parametric estimation,Kalliopi D Kalantzaki; Ekaterini S Bei; Minos Garofalakis; Michalis Zervakis,Biological networks are often described as probabilistic graphs in the context of gene andprotein sequence analysis in molecular biology. Microarrays and proteomics technologiesfacilitate the monitoring of expression levels over thousands of biological units over time.Several experimental efforts have appeared aiming to unveiling pairwise interactions; withmany graphical models being introduced in order to discover associations from expression-data analysis. However; the small size of samples compared to the number of observedgenes/proteins makes the inference of the network structure quite challenging. In this study;we generate gene–protein networks from sparse experimental temporal data using twomethods; partial correlations and Kernel Density Estimation (KDE); in an attempt to capturegenetic interactions. Applying KDE method we model the genetic associations as …,International Journal of Biomedical Engineering and Technology 5,2013,3
System and/or method for processing events,*,The publish/subscribe (“pub/sub”) paradigm in which a large population of users expresseslong-term interests (“subscriptions”) over streams of “published events” has gained immensepopularity in recent years; at least in part due to the availability of increasing volumes of dynamicinformation available over the worldwide web such as; or example; stock quotes and newsreports. A pub/sub engine typically matches an incoming event to a subset of standingsubscriptions. For example; streams of event messages originating at one or more“publishers” may be matched with the interests of one or more pre-registered “subscribers …Non-limiting and non-exhaustive embodiments will be described with reference to the followingfigures; wherein like reference numerals refer to like parts throughout the various figures unlessotherwise specified … FIG. 1 is a schematic diagram of a tree comprising nodes …,*,2011,3
Processing data-stream join aggregates using skimmed sketches,*,A method of estimating an aggregate of a join over data-streams in real-time using skimmedsketches; that only examines each data element once and has a worst case spacerequirement of O (n2/J); where J is the size of the join and n is the number of data elements.The skimmed sketch is an atomic sketch; formed as the inner product of the data-streamfrequency vector and a random binary variable; from which the frequency values that exceeda predetermined threshold have been skimmed off and placed in a dense frequency vector.The join size is estimated as the sum of the sub-joins of skimmed sketches and densefrequency vectors. The atomic sketches may be arranged in a hash structure so thatprocessing a data element only requires updating a single sketch per hash table. This keepsthe per-element overhead logarithmic in the domain and stream sizes.,*,2009,3
Wavelets on streams,Minos Garofalakis,W3C was founded in 1994 by the inventor of the World Wide Web Tim Berners-Lee as avendor-neutral forum for building consensus around Web technologies. The consortiumconsists of member organization and dedicated staff of technical experts. Membership isopen to any organization or individual whose application is reviewed and approved by theW3C. Usually W3C members invest significant resources into the Web technologies. W3Cfulfils its mission by creation of recommendations enjoying status of international standards.In the first 10 years of existence; it produced over eighty W3C recommendations. W3C isresponsible for such technologies as HTML; XHTML; XML; XML Schema; CSS; SOAP;WSDL and others. W3C members play a leading role in the development of therecommendations. W3C initiatives involve international; national; and regional …,*,2009,3
Discrete Wavelet Transform and Wavelet Synopses,Minos Garofalakis,realized using such logical structures. For example; in tree based data acquisition protocols;a collection tree is built that is rooted at the data collection center such as the sink node [8].The dissemination of the data requests from the participating nodes and collection of datafrom the sensor nodes are accomplished using this tree. A cluster based data acquisitionmechanism has been proposed in [3]. As shown in Fig. 1; nodes are organized into a fixednumber of clusters; and nodes within each cluster dynamically elect a cluster head. The dataacquisition is carried out in two phases. In the first phase; cluster heads collect data fromtheir cluster nodes. In the second phase; cluster heads send collected data to the nodes thathave subscribed to the data. The cluster heads are re-elected to balance energyconsumption among the nodes in the cluster. Zhang et al.[13] have proposed an adaptive …,*,2009,3
Very Large Databases,Minos Garofalakis; Neoklis Polyzotis,A growing number of database applications require online; interactive access to very large volumesof data to perform a variety of data analysis tasks. As an example; large tele- communicationand Internet service providers typically col- lect and store Gigabytes or Terabytes of detailedusage information (Call Detail Records; SNMP/RMON packet flow data; etc.) from the underlyingnetwork to satisfy the requirements of various network management tasks; includ- ing billing;fraud/anomaly detection; and strategic planning. Such large datasets are typically representedeither as mas- sive alphanumeric data tables (in the relational data model) or as massive labeleddata graphs (in richer; semistructured data models; such as extensible markup language(XML)). In order to deal with the huge data volumes; high query com- plexities; and interactiveresponse time requirements char- acterizing these modern data analysis applications …,Wiley Encyclopedia of Computer Science and Engineering,2008,3
Granularity conscious modeling for probabilistic databases,Eirinaios Michelakis; Daisy Zhe Wang; Minos Garofalakis; Joseph M Hellerstein,The convergence of embedded sensor systems and stream query processing suggests animportant role for database techniques; in managing data that only partially and of-teninaccurately capture the state of the world. Reasoning about uncertainty as a first classcitizen; inside a database system; becomes an increasingly important operation forprocessing non deterministic data. An essential step for such an approach lies in the choiceof the appropriate un-certainty model; that captures the probabilistic information in the data;both accurately and at the right semantic de-tail level. This paper introduces HierarchicalFirst-Order Graphical Models (HFGMs); an intuitive and economical representation of thedata correlations stored in a Proba-bilistic Data Management system; in a hierarchicalsetting. HFGM semantics allow for an efficient summarization of the probabilistic model …,Data Mining Workshops; 2007. ICDM Workshops 2007. Seventh IEEE International Conference on,2007,3
On Configuring BGP route reflectors,Yuri Breitbart; Minos Garofalakis; Anupam Gupta; Amit Kumar; Rajeev Rastogi,The Border Gateway Protocol (BGP) is the standard protocol for exchanging routinginformation between border routers of Autonomous Systems (ASes) in today's Internet.Within an AS; border routers exchange externally-learned BGP route advertisements viaInternal-BGP (I-BGP) peerings. Naive solutions for these I-BGP peering sessions (eg; basedon full-mesh topologies) simply cannot scale to the sizes of modern AS networks. Carefullydesigned route-reflector configurations can drastically reduce the total number andconnection cost of the required I-BGP sessions. Nevertheless; no principled algorithmicapproaches exist for designing such configurations; and current practice relies on manualreflector selection using simple; ad-hoc rules. In this paper; we address the novel andchallenging optimization problems involved in designing effective BGP route-reflector …,Communication Systems Software and Middleware; 2007. COMSWARE 2007. 2nd International Conference on,2007,3
Streaming in a Connected World.,Graham Cormode; Minos N Garofalakis,*,VLDB,2006,3
Physical and service topology discovery in heterogeneous networks: the NetInventory system,PPS Narayan; Y Brietbart; M Garofalakis; SK Iyer; C Martin; G Prabhakar; R Rastogi; A Silberschatz,Knowledge of both; the up-to-date physical topology of an IP network and provisionedservices in a core data or optical network; is crucial to a number of critical networkmanagement tasks; including reactive and proactive resource management; eventcorrelation; and root-cause analysis. Given the dynamic nature of today's networks; keepingtrack of physical and service topology information manually is a daunting (if not impossible)task. Thus; effective algorithms for automatically discovering network topology arenecessary. We present novel algorithms for (a) discovering physical topology inheterogeneous (ie; multivendor) IP networks; and (b) discovering service topology in coredata or optical networks. Our algorithms for physical topology of IP networks rely on standardSNMP MIB information that is widely supported by modern IP network elements. We have …,Telecommunications Network Strategy and Planning Symposium. NETWORKS 2004; 11th International,2004,3
What’s Next in XML and Databases?,Minos Garofalakis; Ioana Manolescu; Marco Mesiti; George Mihaila; Ralf Schenkel; Bhavani Thuraisingham; Vasilis Vassalos,Abstract Since the time XML became a W3C standard for document representation andexchange over the Web; many efforts have been devoted to the development of standards;methodologies; and tools for handling; storing; retrieving; and protecting XML documents.The purpose of this panel; held during the international EDBT'2004 workshop on “databasetechnologies for handling XML information on the Web”[3]; is to discuss the current status ofthe research in XML data management and to foresee new trends towards the XML-izationof database research.,International Conference on Extending Database Technology,2004,3
Network Data Mining and Analysis: The NEMESIS Project,Minos Garofalakis; Rajeev Rastogi,*,Advances in Knowledge Discovery and Data Mining,2002,3
Model-based semantic compression for network-data tables,Shivnath Babu; Minos Garofalakis; Rajeev Rastogi; Avi Silberschatz,ABSTRACT While a variety of lossy compression schemes have been developed for certainforms of digital data (eg; images; audio; video); the area of lossy compression techniques forarbitrary data tables has been left relatively unexplored. Nevertheless; such techniques areclearly motivated by the ever-increasing data collection rates of modern enterprises and theneed for effective; guaranteedquality approximate answers to queries over massiverelational data sets. In this paper; we propose Model-Based Semantic Compression(MBSC); a novel datacompression framework that takes advantage of attribute semanticsand datamining models to perform lossy compression of massive data tables. We describethe architecture and some of the key algorithms underlying¢¤£¦¥ § ©¥; a model-basedsemantic compression system that exploits predictive data correlations and prescribed …,Proc. of NRDM,2001,3
Data Stream Management: A Brave New World,Minos Garofalakis; Johannes Gehrke; Rajeev Rastogi,Abstract Traditional data-management systems software is built on the concept of persistentdata sets that are stored reliably in stable storage and queried/updated several timesthroughout their lifetime. For several emerging application domains; however; data arrivesand needs to be processed on a continuous basis; without the benefit of several passes overa static; persistent data image. Such continuous data streams arise naturally; for instancetelecom and IP network monitoring. This volume focuses on the theory and practice of datastream management; and the difficult; novel challenges this emerging domain introduces fordata-management systems. The collection of chapters (contributed by authorities in the field)offers a comprehensive introduction to both the algorithmic/theoretical foundations of datastreams and the streaming systems/applications built in different domains. In the …,*,2016,2
Query analytics over probabilistic databases with unmerged duplicates,Ekaterini Ioannou; Minos Garofalakis,Recent entity resolution approaches exhibit benefits when addressing the problem throughunmerged duplicates: instances describing real-world objects are not merged based onapriori thresholds or human intervention; instead relevant resolution information is employedfor evaluating resolution decisions during query processing using “possible worlds”semantics. In this paper; we present the first known approach for efficiently handlingcomplex analytical queries over probabilistic databases with unmerged duplicates. Wepropose the ENTITY-JOIN operator that allows expressing complex aggregation andiceberg/top-k queries over joins between tables with unmerged duplicates and otherdatabase tables. Our technical content includes a novel indexing structure for efficientaccess to the entity resolution information and novel techniques for the efficient …,IEEE Transactions on Knowledge and Data Engineering,2015,2
Deterministic wavelet thresholding for general-error metrics,*,Novel; computationally efficient schemes for deterministic wavelet thresholding with theobjective of optimizing maximum-error metrics are provided. An optimal low polynomial-timealgorithm for one-dimensional wavelet thresholding based on a new dynamic-programming(DP) formulation is provided that can be employed to minimize the maximum relative orabsolute error in the data reconstruction. Directly extending a one-dimensional DP algorithmto multi-dimensional wavelets results in a super-exponential increase in time complexity withthe data dimensionality. Thus; novel; polynomial-time approximation schemes (with tunableapproximation guarantees for the target maximum-error metric) for deterministic waveletthresholding in multiple dimensions are also provided.,*,2010,2
Approximate decision making in large-scale distributed systems,Ling Huang; Minos Garofalakis; Anthony D Joseph; Nina Taft,As the Internet has evolved into a valuable and critical service platform for business anddaily life; the research community has enthusiastically applied data mining methods toimprove application performance by analyzing and optimizing the behaviors of theunderlying systems (eg; datacenter design; network resource provisioning; network security;etc.) These data mining procedures often use large-scale widelydistributed monitoringsystems; which continuously generate numerous distributed data streams; and backhaul allof the data to a central location (eg; a Network Operation Center or NOC) for data analysisand decision making. This application scenario presents both new opportunities andchallenges in efficient data analysis and online decision making; where a decision functiondepends on aggregating and analyzing continuous data streams from distributed …,NIPS Workshop: Statistical Learning Techniques for Solving Systems Problems,2007,2
Proof sketches: Verifiable multi-party aggregation,Minos Garofalakis; Joseph M Hellerstein; Petros Maniatis,ABSTRACT Recent work on distributed aggregation has assumed a benign population ofparticipants. In modern distributed systems; it is now necessary to account for adversarialbehavior. In this paper we consider the problem of ensuring verifiable yet efficient results totypical aggregation queries in a distributed; multi-party setting. We describe a generalframework for the problem; including the threat model for adversaries that we consider. Wethen present a mechanism called a proof sketch; which uses a compact combination ofcryptographic signatures and Flajolet-Martin sketches to verify that a query answer is withinacceptable error bounds with high probability. When verification fails; we provide efficientmechanisms to identify any participants responsible for the perturbed result. We derive proofsketches for count aggregates; and extend them to proof sketches for verifiable random …,*,2006,2
Analyzing massive data streams: past; present; and future,Minos Garofalakis,Abstract Continuous data streams arise naturally; for example; in the installations of largetelecom and Internet service providers where detailed usage information (Call-Detail-Records; SNMP-/RMON packet-flow data; etc.) from different parts of the underlying networkneeds to be continuously collected and analyzed for interesting trends. Such environmentsraise a critical need for effective stream-processing algorithms that can provide (typically;approximate) answers to data-analysis queries while utilizing only small space (to maintainconcise stream synopses) and small processing time per stream item. In this talk; I willdiscuss the basic pseudo-random sketching mechanism for building stream synopses andour ongoing work that exploits sketch synopses to build an approximate SQL (multi) queryprocessor. I will also describe our recent results on extending sketching to handle more …,Proceedings of the 8th ACM SIGMOD workshop on Research issues in data mining and knowledge discovery,2003,2
XSketch synopses for XML,Neoklis Polyzotis; Minos N Garofalakis,Abstract All existing proposals for querying XML (eg; XQuery) rely on a pattern-specificationlanguage that allows path navigation and branching through the XML data graph in order toreach the desired data elements. Optimizing such queries depends crucially on theexistence of concise synopsis structures that enable accurate compile-time selectivityestimates for complex path expressions over graph-structured XML data. In this paper; wesummarize our main results from our recent work on XS-KETCHes; a novel approach tobuilding and using statistical summaries of large XML data graphs for effective path-expression selectivity estimation. Our proposed graph-synopsis model exploits localizedgraph stability to accurately approximate (in limited space) the path and branchingdistribution in the data graph. To estimate the selectivities of complex path expressions …,Proceedings of the 1st Hellenic Data Management Symposium; HDMS’02,2002,2
Query scheduling and optimization in parallel and multimedia databases,Minos N Garofalakis,Abstract E ective resource management support for parallelism and multimedia data is animportant mandate for next-generation information systems. In this thesis; we address anumber of resource scheduling issues that arise in the context of query processing andoptimization in parallel and multimedia databases. Our contributions to the area of paralleldatabases include the development of a multi-dimensional framework and provably near-optimal algorithms for scheduling both Time-Shared and Space-Shared resources inhierarchical and shared-nothing architectures. We also present results from theimplementation of our algorithms on top of a detailed simulation model that verify their eectiveness in a realistic setting. Based on our scheduling results; we identify a novel costmodel for parallel query optimization that manages to capture all the important execution …,*,1998,2
Complex event recognition in the big data era,Nikos Giatrakos; Alexander Artikis; Antonios Deligiannakis; Minos Garofalakis,Abstract The concept of event processing is established as a generic computationalparadigm in various application fields; ranging from data processing in Web environments;over maritime and transport; to finance and medicine. Events report on state changes of asystem and its environment. Complex Event Recognition (CER) in turn; refers to theidentification of complex/composite events of interest; which are collections of simple eventsthat satisfy some pattern; thereby providing the opportunity for reactive and proactivemeasures. Examples include the recognition of attacks in computer network nodes; humanactivities on video content; emerging stories and trends on the Social Web; traffic andtransport incidents in smart cities; fraud in electronic marketplaces; cardiac arrhythmias; andepidemic spread. In each scenario; CER allows to make sense of Big event Data streams …,Proceedings of the VLDB Endowment,2017,1
Distributed Query Monitoring through Convex Analysis: Towards Composable Safe Zones,Minos Garofalakis; Vasilis Samoladas,Abstract Continuous tracking of complex data analytics queries over high-speed distributedstreams is becoming increasingly important. Query tracking can be reduced to continuousmonitoring of a condition over the global stream. Communication-efficient monitoring relieson locally processing stream data at the sites where it is generated; by deriving site-localconditions which collectively guarantee the global condition. Recently proposed geometrictechniques offer a generic approach for splitting an arbitrary global condition into localgeometric monitoring constraints (known as" Safe Zones"); still; their application to variousproblem domains has so far been based on heuristics and lacking a principled;compositional methodology. In this paper; we present the first known formal results on thedifficult problem of effective Safe Zone (SZ) design for complex query monitoring over …,LIPIcs-Leibniz International Proceedings in Informatics,2017,1
Sketch-Based Multi-Query Processing over Data Streams,Alin Dobra; Minos Garofalakis; Johannes Gehrke; Rajeev Rastogi,Abstract We consider the problem of approximately answering multiple general aggregateSQL queries over continuous data streams with limited memory. Our method extends therandomizing techniques of Alon et al. that compute small “sketch” summaries of the streamsthat can then be used to provide approximate answers to aggregate queries with provableguarantees on the approximation error. By intelligently sharing the sketches among multiplequeries; the memory required can be reduced. We provide necessary and sufficientconditions for the sketch sharing to result in correct estimation and address optimizationproblems that arise. We also demonstrate how existing statistical information on the basedata (eg; histograms) can be used in the proposed framework to improve the quality of theapproximation provided by our algorithms. The key idea is to intelligently partition the …,*,2016,1
Lightweight query authentication on streams,Stavros Papadopoulos; Graham Cormode; Antonios Deligiannakis; Minos Garofalakis,Abstract We consider a stream outsourcing setting; where a data owner delegates themanagement of a set of disjoint data streams to an untrusted server. The ownerauthenticates his streams via signatures. The server processes continuous queries on theunion of the streams for clients trusted by the owner. Along with the results; the server sendsproofs of result correctness derived from the owner's signatures; which are verifiable by theclients. We design novel constructions for a collection of fundamental problems over streamsrepresented as linear algebraic queries. In particular; our basic schemes authenticatedynamic vector sums; matrix products; and dot products. These techniques can be adaptedfor authenticating a wide range of important operations in streaming environments; includinggroup-by queries; joins; in-network aggregation; similarity matching; and event …,ACM Transactions on Database Systems (TODS),2014,1
Querying Big; Dynamic; Distributed Data,Minos Garofalakis,Abstract Effective Big Data analytics pose several difficult challenges for modern datamanagement architectures. One key such challenge arises from the naturally streamingnature of big data; which mandates efficient algorithms for querying and analyzing massive;continuous data streams (that is; data that is seen only once and in a fixed order) with limitedmemory and CPU-time resources. Such streams arise naturally in emerging large-scaleevent monitoring applications; for instance; network-operations monitoring in large ISPs;where usage information from numerous sites needs to be continuously collected andanalyzed for interesting trends. In addition to memory-and time-efficiency concerns; theinherently distributed nature of such applications also raises important communication-efficiency issues; making it critical to carefully optimize the use of the underlying network …,Proceedings of the 17th International Workshop on Data Warehousing and OLAP,2014,1
Analytics over probabilistic unmerged duplicates,Ekaterini Ioannou; Minos Garofalakis,Abstract This paper introduces probabilistic databases with unmerged duplicates (DB ud);ie; databases containing probabilistic information about instances found to describe thesame real-world objects. We discuss the need for efficiently querying such databases andfor supporting practical query scenarios that require analytical or summarized information.We also sketch possible methodologies and techniques that would allow performing efficientprocessing of queries over such probabilistic databases; and especially without the need tomaterialize the (potentially; huge) collection of all possible deduplication worlds.,International Conference on Scalable Uncertainty Management,2014,1
Querying distributed data streams,Minos Garofalakis,Abstract Effective Big Data analytics pose several difficult challenges for modern datamanagement architectures. One key such challenge arises from the naturally streamingnature of big data; which mandates efficient algorithms for querying and analyzing massive;continuous data streams (that is; data that is seen only once and in a fixed order) with limitedmemory and CPU-time resources. Such streams arise naturally in emerging large-scaleevent monitoring applications; for instance; network-operations monitoring in large ISPs;where usage information from numerous sites needs to be continuously collected andanalyzed for interesting trends. In addition to memory-and time-efficiency concerns; theinherently distributed nature of such applications also raises important communication-efficiency issues; making it critical to carefully optimize the use of the underlying network …,East European Conference on Advances in Databases and Information Systems,2014,1
Data management research at the technical university of crete,Stavros Christodoulakis; Minos Garofalakis; Euripides GM Petrakis; Antonios Deligiannakis; Vasilis Samoladas; Ekaterini Ioannou; Odysseas Papapetrou; Stelios Sotiriadis,The Technical University of Crete (TUC; www. tuc. gr) founded in 1977 in Chania; Crete isthe youngest of the two technical universities in Greece (the other being the NationalTechnical University of Athens). The purpose of this state institution is to provide high-qualityundergraduate as well as graduate studies in modern engineering fields demanded by theGreek and international job market; to conduct research in cutting edge technologies as wellas to develop links with the Greek and European industry. Today; the Technical University ofCrete comprises five Engineering Schools (Electronic and Computer Engineering;Production Engineering and Management; Mineral Resources Engineering; EnvironmentalEngineering; and Architecture). The School of Electronic and Computer Engineering (ECE)at TUC (www. ece. tuc. gr) has achieved an excellent reputation for its research and …,ACM SIGMOD Record,2014,1
Distributed set-expression cardinality estimation,*,A method and system for answering set-expression cardinality queries while lowering datacommunication costs by utilizing a coordinator site to provide global knowledge of thedistribution of certain frequently occurring stream elements to significantly reduce thetransmission of element state information to the central site and; optionally; capturing thesemantics of the input set expression in a Boolean logic formula and using models of theformula to determine whether an element state change at a remote site can affect the setexpression result.,*,2011,1
Tracking set-expression cardinalities over continuous update streams,*,A method of estimating set-expression cardinalities over data streams with guaranteed smallmaintenance time per data-element update. The method only examines each data elementonce and uses a limited amount of memory. The time-efficient stream synopsis extends 2-level hash-sketches by randomly; but uniformly; pre-hashing data-elements prior tologarithmically hashing them to a first-level hash-table. This generates a set of independent2-level hash-sketches. The set-union cardinality can be estimated by determining thesmallest hash-bucket index j at which only a predetermined fraction of the b hash-bucketshas a non-empty union| A∪ B|. Once a set-union cardinality is estimated; general set-expression cardinalities may be estimated by counting witness elements for the set-expression; ie; those first-level hash-buckets that are both a singleton for the set …,*,2009,1
Indexed Regular Expression Matching,Chee Yong Chan; Minos Garofalakis; Rajeev Rastogi,Regular expressions (REs) provide an expressive and powerful formalism for capturing the structureof messages; events; and documents. Consequently; they have been used extensively in thespecification of a number of languages for important application domains; including the XPathpattern language for XML documents [6] and the policy language of the Border Gateway Protocol(BGP) for propagating routing information between autonomous systems in the Internet [12].Many of these applications have to manage large databases of RE specifications and need toprovide an effective matching mechanism that; given an input string; quickly identifies all theREs in the database that match it. This RE retrieval problem is therefore important for a varietyof software components in the middleware and networking infrastructure of the Internet. The REretrieval problem can be stated as follows: Given a large set S of REs over an alphabet † …,*,2008,1
Regular Expression Indexing,Chee-Yong Chan; Minos Garofalakis; Rajeev Rastogi,OBJECTIVE: Let j (V) j=. Then is the number of colors that'actually uses (it is usually calledorder of G under'). The number= maxv2V (v) minu2V (u)+ 1 is usually called the span of Gunder'. The function'satisfies one of the following objectives: minimum span: is the minimumpossible over all possible functions' of G; minimum order: is the minimum possible over allpossible functions' of G;,*,2008,1
Spartan: A model-based semantic compression system for massive data tables,Babu Shivnath; Minos Garofalakis; Rajeev Rastogi,While a variety of lossy compression schemes have been developed for certain forms ofdigital data (eg; images; audio; video); the area of lossy compression techniques for arbitrarydata tables has been left relatively unexplored. Nevertheless; such techniques are clearlymotivated by the ever-increasing data collection rates of modern enterprises and the needfor effective; guaranteed-quality approximate answers to queries over massive relationaldata sets. In this paper; we propose SPARTAN; a system that takes advantage of attributesemantics and data-mining models to perform lossy compression of massive data tables.SPARTAN is based on the novel idea of exploiting predictive data correlations andprescribed error tolerances for individual attributes to construct concise and accurateClassification and Regression Tree models for entire columns of a table. More precisely …,2001 ACM SIGMOD International Conference on Management of Data,2001,1
Processing massive data streams,Minos Garofalakis,Page 1. 1 Processing Massive Data Streams Minos Garofalakis Yahoo! Research & UC Berkeleyminos@acm.org 1;1 f s;1 f 1;k f s;k f sf 1f local update streams local update streams Site 1 Sitek State−Update Coordinator Global Streams Approximate Answer User Query Q(fi; fj; ...) forQ(fi; fj; ...) Messages (Thanks to: Graham Cormode; Johannes Gehrke; Rajeev Rastogi) ProcessingMassive Data Streams – VLDB School'2008; Cairo; Egypt 2 Streams – A Brave New World ∎Traditional DBMS: data stored in finite; persistent data sets ∎ Data Streams: distributed; continuous;unbounded; rapid; time varying; noisy; . . . ∎ Data-Stream Management: variety of modernapplications – Network monitoring and traffic engineering – Sensor networks – Telecom call-detailrecords – Network security – Financial applications – Manufacturing processes – Web logs andclickstreams – Other massive data sets… Page 2. 2 …,VLDB Database School; Cairo University,*,1
Holistic query evaluation over information extraction pipelines,Ekaterini Ioannou; Minos Garofalakis,Abstract We introduce holistic in-database query processing over information extractionpipelines. This requires considering the joint conditional distribution over genericConditional Random Fields that uses factor graphs to encode extraction tasks. Our approachintroduces Canopy Factor Graphs; a novel probabilistic model for effectively capturing thejoint conditional distribution given a canopy clustering of the data; and special queryoperators for retrieving resolution information. Since inference on such models is intractable;we introduce an approximate technique for query processing and optimizations that cutacross the integrated tasks for reducing the required processing time. Effectiveness andscalability are verified through an extensive experimental evaluation using real andsynthetic data.,Proceedings of the VLDB Endowment,2017,*
Streaming analytics,Minos Garofalakis,Abstract Effective Big Data analytics need to rely on algorithms for querying and analyzingmassive; continuous data streams (that is; data that is seen only once and in a fixed order)with limited memory and CPU-time resources. Such streams arise naturally in emerginglarge-scale event monitoring applications; for instance; network-operations monitoring inlarge ISPs; where usage information from numerous network devices needs to becontinuously collected and analyzed for interesting trends and real-time reaction to differentscenarios (eg; hotspots or DDoS attacks). In addition to memory-and time-efficiencyconcerns; the inherently distributed nature of such applications also raises importantcommunication-efficiency issues; making it critical to carefully optimize the use of theunderlying communication infrastructure. This course will provide an overview of some …,1st Europe Summer School: Data Science,2017,*
Complex event processing over streaming multi-cloud platforms: the FERARI approach,Ioannis Flouris; Vasiliki Manikaki; Nikos Giatrakos; Antonios Deligiannakis; Minos Garofalakis; Michael Mock; Sebastian Bothe; Inna Skarbovsky; Fabiana Fournier; Marko Štajcer; Tomislav Križan; Jonathan Yom-Tov; Marijo Volarević,Abstract We present FERARI; a prototype for processing voluminous event streams overmulti-cloud platforms. At its core; FERARI both exploits the potential for in-situ (intra-cloud)processing and orchestrates inter-cloud complex event detection in a communication-efficient way. At the application level; it includes a user-friendly query authoring tool and ananalytics dashboard providing granular reports about detected events. In that; FERARIconstitutes; to our knowledge; the first complete end-to-end solution of its kind. In this demo;we apply the FERARI approach on a real scenario from the telecommunication domain.,Proceedings of the 10th ACM International Conference on Distributed and Event-based Systems,2016,*
Distributed Data Streams and the Power of Geometry.,Minos N Garofalakis,ABSTRACT Sequences arise in many online and offline settings: urls to visit; songs to listento; videos to watch; restaurants to dine at; and so on. User-generated sequences are tightlyrelated to mechanisms of choice; where a user must select one from a finite set ofalternatives. In this talk; we will discuss a class of problems arising from studying suchsequences and the role discrete choice theory plays in these problems. We will presentmodeling and algorithmic approaches to some of these problems and illustrate them in thecontext of large-scale data analysis.,COMAD,2016,*
Conclusions and Looking Forward,Minos Garofalakis; Johannes Gehrke; Rajeev Rastogi,Abstract Today; data streaming is a part of the mainstream and several data steamingproducts are now publicly available. Data streaming algorithms are powering complex eventprocessing; predictive analytics; and big data applications in the cloud. In this final chapter;we provide an overview of current data streaming products; and applications of datastreaming to cloud computing; anomaly detection and predictive modeling. We also identifyfuture research directions for mining and doing predictive analytics on data streams;especially in a distributed environment.,*,2016,*
Tracking Queries over Distributed Streams,Minos Garofalakis,Abstract Effective Big Data analytics pose several difficult challenges for modern datamanagement architectures. One key such challenge arises from the naturally streamingnature of big data; which mandates efficient algorithms for querying and analyzing massive;continuous data streams (that is; data that is seen only once and in a fixed order) with limitedmemory and CPU-time resources. Such streams arise naturally in emerging large-scaleevent monitoring applications; for instance; network-operations monitoring in large ISPs;where usage information from numerous sites needs to be continuously collected andanalyzed for interesting trends. In addition to memory-and time-efficiency concerns; theinherently distributed nature of such applications also raises important communication-efficiency issues; making it critical to carefully optimize the use of the underlying network …,*,2016,*
Join Sizes; Frequency Moments; and Applications,Graham Cormode; Minos Garofalakis,Abstract We focus on a set of problems chiefly inspired by the problem of estimating the sizeof the (equi-) join between two relational data streams. This problem is at the heart of a widevariety of other problems; both in databases/data streams and beyond; includingapproximating range-query aggregates; quantiles; and heavy-hitter elements; and buildingapproximate histograms and wavelet representations. Our discussion focuses on efficient;sketch-based streaming algorithms for join-size and self-join-size estimation problems;based on the influential papers of Alon; Matias; Gibbons; and Szegedy.,*,2016,*
Approximate Geometric Query Tracking over Distributed Streams.,Minos N Garofalakis,Abstract Effective Big Data analytics pose several difficult challenges for modern datamanagement architectures. One key such challenge arises from the naturally streamingnature of big data; which mandates efficient algorithms for querying and analyzing massive;continuous data streams (that is; data that is seen only once and in a fixed order) with limitedmemory and CPU-time resources. Such streams arise naturally in emerging large-scaleevent monitoring applications; for instance; network-operations monitoring in large ISPs;where usage information from numerous sites needs to be continuously collected andanalyzed for interesting trends. In addition to memory-and time-efficiency concerns; theinherently distributed nature of such applications also raises important communication-efficiency issues; making it critical to carefully optimize the use of the underlying network …,IEEE Data Eng. Bull.,2015,*
Program committee chairs' welcome,Minos Garofalakis; Ian Soboroff; Torsten Suel; Min Wang,Garofalakis; M.; Soboroff; I.; Suel; T.; & Wang; M. (2014). Program committee chairs'welcome. Unknown Journal; iv … Program committee chairs' welcome. / Garofalakis;Minos; Soboroff; Ian; Suel; Torsten; Wang; Min … Garofalakis; M; Soboroff; I; Suel; T &Wang; M 2014; 'Program committee chairs' welcome' Unknown Journal; pp. iv … GarofalakisM; Soboroff I; Suel T; Wang M. Program committee chairs' welcome. Unknown Journal. 2014Nov 3;iv … Powered by Pure; Scopus & Elsevier Fingerprint Engine™ © 2017 Elsevier BV.,Unknown Journal,2014,*
Multi-Resource Parallel Query Scheduling and Optimization,Minos Garofalakis; Yannis Ioannidis,Abstract: Scheduling query execution plans is a particularly complex problem in shared-nothing parallel systems; where each site consists of a collection of local time-shared (eg;CPU (s) or disk (s)) and space-shared (eg; memory) resources and communicates withremote sites by message-passing. Earlier work on parallel query scheduling employs either(a) one-dimensional models of parallel task scheduling; effectively ignoring the potentialbenefits of resource sharing; or (b) models of globally accessible resource units; which areappropriate only for shared-memory architectures; since they cannot capture the affinity ofsystem resources to sites. In this paper; we develop a general approach capturing the fullcomplexity of scheduling distributed; multi-dimensional resource units for all forms ofparallelism within and across queries and operators. We present a level-based list …,arXiv preprint arXiv:1403.7729,2014,*
Indentification of altered MET network in oral cancer progression based on nonparametric network design,K Kalantzaki; ES Bei; KP Exarchos; M Zervakis; DI Fotiadis; M Garofalakis,Oral cancer is characterized by multiple genetic events such as alterations of a number ofoncogenes and tumour suppressor genes. The aim of this study is to identify genes and theirfunctional interactions that may play a crucial role on a specific disease-state; especiallyduring oral cancer progression. We examine gene interaction networks on blood genomicdata; obtained from twenty three oral cancer patients at four different time stages. Wegenerate the gene-gene networks from sparse experimental temporal data using twomethods; Partial Correlations and Kernel Density Estimation; in order to capture geneticinteractions. The network study reveals an altered MET (hepatocyte growth factor receptor)network during oral cancer progression; which is further analyzed in relation to other studies.,Engineering in Medicine and Biology Society (EMBC); 2013 35th Annual International Conference of the IEEE,2013,*
Method For Generating Score-Optimal R-Trees,*,A method of constructing a score-optimal R-tree to support top-k stabbing queries over a setof scored intervals generates a constraint graph from the set; and determines over eachnode in the constraint graph that has no other nodes pointing to it the node with the smallestleft endpoint; for each of these nodes; the associated interval is added to the tree and thenode is removed from the constraint graph.,*,2010,*
DATABASES SPECIAL SECTION ON MINING LARGE UNCERTAIN AND PROBABILISTIC Guest Editors' Introduction: Special Section on Mining Large Uncertain an...,R Cheng; M Chau; M Garofalakis; JX Yu,*,IEEE Transactions on Knowledge and Data Engineering,2010,*
System and method for determining the physical topology of a network having multiple subnets,*,A system for; and method of; determining a physical topology of a network having multiplesubnets. In one embodiment; the system includes:(1) a skeleton path initializer that usesaddressing information from elements in the network to develop a collection of skeletonpaths of direct physical connections between labeled ones of the elements; the skeletonpaths traversing multiple of the subnets and (2) a skeleton path refiner; coupled to theskeleton path initializer; that refines the collection by inferring; from the direct physicalconnections and path constraints derived therefrom; other physical connections in theskeleton paths involving unlabeled ones of the elements.,*,2009,*
Special issue: best papers of VLDB 2007,Minos Garofalakis; Johannes Gehrke; Divesh Srivastava,This special issue of the VLDB Journal is dedicated to the best papers from the 33rdInternational Conference on Very Large Data Bases; which took place on 23–28 September2007 at the University of Vienna in Austria. The conference received 668 submissionsoverall. The Core Database Technology Track received 263 submissions out of which 46(17.5%) were accepted; the Infrastructure for Information Systems Track received 275submissions out of which 45 (16.4%) were accepted; the Industrial; Applications; andExperience Track received 56 submissions out of which 17 (30.4%) were accepted; and theDemonstrations Track received 74 submissions out of which 29 (39.2%) were accepted.,The VLDB Journal,2009,*
Practical Private Range Search In Depth,IOANNIS DEMERTZIS; STAVROS PAPADOPOULOS; ODYSSEAS PAPAPETROU; ANTONIOS DELIGIANNAKIS; MINOS GAROFALAKIS; CHARALAMPOS PAPAMANTHOU,We focus on a setting with two parties; a data owner and a server. The owner outsources itsdataset to the server; and gives the latter the authority to answer range queries on a singleattribute. The server is untrusted; and the goal is to protect the privacy of the dataset and thequeries. The owner encrypts its data prior to sending them to the server. The challenge liesin enabling the server to process the owner's queries directly on the encrypted data; whileachieving performance and costs close to the non-private case. The benefits of dataoutsourcing and the importance of privacy have been stressed in numerous earlier works(eg;[18; 59; 62; 66]). Prior work. Privacy-preserving range queries can be solved with optimalsecurity via powerful theoretical cryptographic tools; such as Oblivious Random AccessMachine (ORAM)[32; 56] and Fully Homomorphic Encryption (FHE)[27; 28]. Nevertheless …,*,2009,*
Continuous Distributed Stream Querying using Sketches,Graham Cormode; Minos Garofalakis,While traditional database systems optimize for performance on one-shot query processing;emerging largescale monitoring applications require continuous tracking of complex data-analysis queries over collections of physically-distributed streams. Thus; effective solutionshave to be simultaneously space/time efficient (at each remote monitor site); communicationefficient (across the underlying communication network); and provide continuous;guaranteed-quality approximate query answers. In this paper; we propose novel algorithmicsolutions for the problem of continuously tracking a broad class of complex aggregatequeries in such a distributed-streams setting. Our tracking schemes maintain approximatequery answers with provable error guarantees; while simultaneously optimizing the storagespace and processing time at each remote site; and the communication cost across the …,*,2008,*
33rd International Conference on,Christoph Koch; Johannes Gehrke; Minos Garofalakis; Divesh Srivastava; Anand Deshpande; Dana Florescu; Chee-Yong Chan; Venkatesh Ganti; Carl-Christian Kanne; Wolfgang Klas; Erich J Neuhold,Editors: Christoph Koch; Saarland University; Germany Johannes Gehrke; CornellUniversity; USA Minos Garofalakis; Yahoo! Research and UC Berkeley; USA DiveshSrivastava; AT&T Labs Research; USA Karl Aberer; EPFL; Switzerland Anand Deshpande; PersistentSystems; India Dana Florescu; Oracle; USA Chee-Yong Chan; National University ofSingapore; Singapore Venkatesh Ganti; Microsoft Research; USA Carl-Christian Kanne; Universityof Mannheim; Germany Wolfgang Klas; University of Vienna; Austria Erich J. Neuhold; ResearchStudio Digital Memory Engineering; Austria,*,2007,*
Proceedings of the 33rd International Conference on Very Large Data Bases (VLDB); University of Vienna; Austria; September 23-27; 2007,Christoph Koch; Johannes Gehrke; Minos N Garofalakis; Divesh Srivastava; Karl Aberer; Anand Deshpande; Chee Yong Chan; Venkatesh Ganti; Carl-Christian Kanne; Wolfgang Klas; Erich J Neuhold,*,*,2007,*
Experimental Results,Tong Zhang; C-C Jay Kuo,Abstract We have built a generic audio database to be used as the testbed of the proposedalgorithms; which consists of the following contents: 1000 clips of environmental audioincluding the sounds of applause; animal; footstep; raining; explosion; knocking; vehiclesand so on; 100 pieces of classical music played with 10 kinds of instruments; 100 othermusic pieces of different styles (classic; jazz; blues; light music; Chinese and Indian folkmusic; etc.); 50 clips of songs sung by male; female; or children; with or without musicalinstrument accompaniment; 200 speech pieces in different languages (English; German;French; Spanish; Japanese; Chinese; etc.) and with different levels of noise; 50 clips ofspeech with the music background; 40 clips of environmental sound with the musicbackground; and 20 samples of silence segment with different types of low-volume noise …,*,2001,*
for Massive Data Tables,Shivnath Babu; Minos Garofalakis; Rajeev Rastogi,*,*,2001,*
Model-Based Semantic Compression for Network-Data Tables,Babu Shivnath; Minos Garofalakis; Rajeev Rastogi; Avi Silberschatz,While a variety of lossy compression schemes have been developed for certain forms ofdigital data (eg; images; audio; video); the area of lossy compression techniques for arbitrarydata tables has been left relatively unexplored. Nevertheless; such techniques are clearlymotivated by the ever-increasing data collection rates of modern enterprises and the needfor effective; guaranteed-quality approximate answers to queries over massive relationaldata sets. In this paper; we propose Model-Based Semantic Compression (MBSC); a noveldata compression framework that takes advantage of attribute semantics and data-miningmodels to perform lossy compression of massive data tables. We describe the architectureand algorithms underlying SPARTAN; a model-based semantic compression system thatexploits predictive data correlations and prescribed error tolerances for individual …,Proceedings of Workshop on Network-Related Data Management (NRDM 2001),2001,*
XTRACT: A System for Extracting Document Type Descriptors,Minos Garofalakis; Aristides Gionis; Rajeev Rastogi; S Seshadri,*,*,*,*
Online Appendix to: Extended Wavelets for Multiple Measures,ANTONIOS DELIGIANNAKIS; MINOS GAROFALAKIS; NICK ROUSSOPOULOS,PROOF OF THEOREM 1. Our proof bears similarities to the corresponding proof for the 0-1Knapsack problem. A significant observation is that whenever we select a set PickedSet ofcoefficient values from a combined coefficient Coeff for storage; any candidate set subOpt ofCoeff that will later be inserted into the max-heap for consideration cannot have a larger per-space benefit than that of PickedSet. We will prove this by contradiction. Assume that subOpthas a larger per-space benefit than PickedSet. By the way the candidate sets are formed; thefollowing observations hold:,ACM Transactions on Database Systems,*,*
Invited Talk Analyzing Massive Data Streams: Past; Present; and Future,Minos Garofalakis,ABSTRACT Continuous data streams arise naturally; for example; in the installations oflarge telecom and Internet service providers where detailed usage information (Call-Detail-Records; SNMP-/RMON packet-flow data; etc.) from different parts of the underlying networkneeds to be continuously collected and analyzed for interesting trends. Such environmentsraise a critical need for effective stream-processing algorithms that can provide (typically;approximate) answers to data-analysis queries while utilizing only small space (to maintainconcise stream synopses) and small processing time per stream item. In this talk; I willdiscuss the basic pseudo-random sketching mechanism for building stream synopses andour ongoing work that exploits sketch synopses to build an approximate SQL (multi) queryprocessor. I will also describe our recent results on extending sketching to handle more …,*,*,*
2007 7th IEEE International Conference on Data Mining Workshops,Alan Ratner; Ron Loui,In this paper we propose an approach for incremental learning of semi-supervised SVM. Theproposed approach makes use of the locality of radial basis function kernels to do local andincremental training of semi-supervised support vector machines. The algorithm introducesa se-quential minimal optimization based implementation of the branch and boundtechnique for training semi-supervised SVM problems...,*,*,*
Lightweight Query Authentication on Streams,Graham Cormode; ANTONIOS DELIGIANNAKIS; MINOS GAROFALAKIS,We consider a stream outsourcing setting; where a data owner delegates the managementof a set of disjoint data streams to an untrusted server. The owner authenticates his streamsvia signatures. The server processes continuous queries on the union of the streams forclients trusted by the owner. Along with the results; the server sends proofs of resultcorrectness derived from the owner's signatures; which are verifiable by the clients. Wedesign novel constructions for a collection of fundamental problems over streamsrepresented as linear algebraic queries. In particular; our basic schemes authenticatedynamic vector sums; matrix products; and dot products. These techniques can be adaptedfor authenticating a wide range of important operations in streaming environments; includinggroup-by queries; joins; in-network aggregation; similarity matching; and event …,*,*,*
ICT; STREP FERARI ICT-FP7-619491,Antonios Deligiannakis; Ioannis Flouris; Minos Garofalakis; Nikos Giatrakos; Michael Kamp; Fabiana Fournier,Page 1. ICT; STREP FERARI ICT-FP7-619491 Flexible Event pRocessing for big dAtaaRchItectures Collaborative Project D 5.1 Requirements and State of the Art Overview onRobust Stream Monitoring 01.04.2014 – 31.01.2015(preparation period) Contractual Dateof Delivery: 31.01.2015 Actual Date of Delivery: xx.xx.xxxx Author(s): Antonios Deligiannakis;Ioannis Flouris; Minos Garofalakis; Nikos Giatrakos; Michael Kamp; Fabiana Fournier Institution:Technical University of Crete Workpackage: WP5 Security: PU Nature: R Total number ofpages: 80 Page 2. Project funded by the European Community under the Information andCommunication Technologies Programme Contract ICT-FP7-619491 Project coordinatorname: Michael Mock Project coordinator organisation name: Fraunhofer Institute for IntelligentAnalysis and Information Systems (IAIS) Revision: 1 …,*,*,*
General and Program Chairs,NCGIA Silvia Nittel; Dimitrios Gunopulos; Peter Buneman; Carol Bult; Susan Davidson; Alex Delis; Carlotta Domeniconi; Johann-Christoph Freytag; Minos Garofalakis; Johannes Gehrke; Jiawei Han; Joe Hellerstein; Yannis Ioannidis; Christian Jensen; Manolis Koubarakis; Stefano Lonardi; HIIT Heikki Mannila; Finland Richard Muntz; Torsten Suel; HIIT Hannu Toivonen; Finland Vassilis Tsotras; Michalis Vazirgiannis; Oikonomiko Panepistimio; Marianne Winslett; Mohammed Zaki; George Kollios; Theodoros Folias,This year's conference focused on the priority themes of Bioinformatics (Genomics; Biodiversityinformatics including Biological Databases); and Geospatial and Sensor Databases. The callfor papers attracted 48 full paper submissions; 5 short papers and 7 demo submissions. For theconference; 20 full papers were accepted by the program committee; as well as 12 poster anddemo papers. Most of these papers present preliminary reports of continuing research; they havebeen read by the Program Committee but not formally refereed. It is anticipated that most of themwill appear in a more polished form in scientific journals … The proceedings also include theabstracts of the three plenary talks given in the conference by Prof. H.- J. Lenz (FreeUniversity; Berlin); Dr. Divesh Srivastava (AT&T Research) and Prof. Ian Foster (Argonne NationalLab; and University of Chicago). Although not covered in these proceedings; the …,*,*,*
Ulrik Brandes; University of Konstanz; Germany Piotr Br6dka; Wroc1aw University of Technology; Poland Yi Cai; South China University of Technology; China,James Bailey; Bettina Berendt; Longbing Cao; Australia Nitesh Chawla; Xueqi Chen; Jana Diesner; Wei Ding; Minos Garofalakis; Greece Uwe Glaesser; Jiawei Han; George Karypis; Tao Li; Ee-Peng Lim; Huan Liu; Jian Pei; Jie Tang; Vincent S Tseng; Meng Wang; China Hui Xiong; Philip Yu; Daniel Zeng; Aoying Zhou; Xingquan Hill Zhu; Mohsen Afsharchi; Kemal Akkaya; Toshiyuki Amagasa; Aijun An; Soumya Banerjee; Guido Barbian; Vladimir Batagelj; Maria Bielikova; Petko Bogdanov,Nitin Agarwal; Professor; University of Arkansas at Little Rock; United States James Bailey; TheUniversity of Melbourne; Australia Bettina Berendt; KU Leuven; Belgium Longbing Cao; Universityof Technology Sydney; Australia; Australia Nitesh Chawla; University of Notre Dame; UnitedStates Xueqi Chen; Institute of Computing Technology; Chinese Academy of Sciences; ChinaJana Diesner; University of Illinois at Urbana-Champaign; United States Wei Ding; Universityof Massachusetts Boston; USA; United States Minos Garofalakis; Technical University ofCrete; Greece; Greece Uwe Glaesser; Simon Fraser University; Canada Jiawei Han; Universityof Illinois at Urbana-Champaign; United States George Karypis; University of Minnesota; UnitedStates Przemyslaw Kazienko; Wroc1aw University of Technology; Poland Tao Li; Florida InternationalUniversity; USA; United States Ee-Peng Lim; Singapore Management University …,*,*,*
Monitoring Distributed Streams using Convex Decompositions (Extended Version),Arnon Lazerson; Izchak Sharfman; Daniel Keren; Assaf Schuster; Minos Garofalakis; Vasilis Samoladas,ABSTRACT Emerging large-scale monitoring applications rely on continuous tracking ofcomplex data-analysis queries over collections of massive; physically-distributed datastreams. Thus; in addition to the space-and time-efficiency requirements of conventionalstream processing (at each remote monitor site); effective solutions also need to guaranteecommunication efficiency (over the underlying communication network). The complexity ofthe monitored query adds to the difficulty of the problem—this is especially true for nonlinearqueries (eg; joins); where no obvious solutions exist for distributing the monitored conditionacross sites. The recently proposed geometric method; based on the notion of coveringspheres; offers a generic methodology for splitting an arbitrary (non-linear) global conditioninto a collection of local site constraints; and has been applied to massive distributed …,*,*,*
Graphical Models in Genomic Networks,Kalliopi Kalantzaki; M Zervakis; M Garofalakis; E Petrakis,2. ABSTRACT During the past few years there has been an increasing interest in studyingthe underlying genetic/proteomic mechanisms behind the discovery of genetic interactionsbetween molecules. This kind of knowledge is of great importance in many scientific areassuch as clinical prognosis; diagnosis and treatment. In this context; various methodologicalapproaches have been suggested for the analysis of genetic interactions in terms ofpredicting the genetic/proteomic associations and for modeling the dependencies amongthe studied molecules. This work explores two distinct aspects. In the first approach weestimate the genetic interactions between sets of genes/proteins of interest in which we usetwo methodologies; the first is a standard technique that relies on partial correlations (PC)while the second is a proposed algorithm based on kernel density estimation (KDE). We …,*,*,*
LIFT ICT-FP7-255957,Assaf Schuster; Daniel Keren; Minos Garofalakis,Abstract: This document is the LIFT deliverable of WP1 for the first review period (01.10.2010–30.09. 2011). The document contains an overview on algorithms for safe zoneconstruction and then presents the work achieved during the last reporting period of the LIFTproject.,Algorithms,*,*
c¿ Kluwer Academic Ñublishers 2002,Minos Garofalakis; Dongjoon Hyun; Rajeev Rastogi; Kyuseok Shim,*,*,*,*
A Quick Introduction to Data Stream Algorithmics,Minos Garofalakis,Page 1. A Quick Introduction to Data Stream Algorithmics Minos Garofalakis Yahoo! Research& UC Berkeley minos@acm.org Page 2. A Quick Intro to Data Stream Algorithmics – CS262 2Streams – A Brave New World  Traditional DBMS: data stored in finite; persistent data sets Data Streams: distributed; continuous; unbounded; rapid; time varying; noisy; . . .  Data-StreamManagement: variety of modern applications – Network monitoring and traffic engineering –Sensor networks – Telecom call-detail records – Network security – Financial applications –Manufacturing processes – Web logs and clickstreams – Other massive data sets… Page 3. AQuick Intro to Data Stream Algorithmics – CS262 3  Data is continuously growing faster thanour ability to store or index it  There are 3 Billion Telephone Calls in US each day; 30 Billionemails daily; 1 Billion SMS; IMs  Scientific data: NASA's observation satellites …,*,*,*
Q uerying and Tracking D istributed D ata Streams,Minos Garofalakis; Graham Cormode,Page 1. 1 Streaming in a Connected World: Q uerying and Tracking D istributed D ata Streams MinosGarofalakis Yahoo! Research & UC Berkeley minos@acm.org 1;1 f s;1 f 1;k f s;k f sf 1f local updatestreams local update streams Site 1 Site k State−Update Coordinator Global Streams ApproximateAnswer User Query Q(fi; fj; ...) for Q(fi; fj; ...) Messages Graham Cormode AT&T Labs - Researchgraham@research.att.com Streaming in a Connected World — Cormode & Garofalakis 2 Streams –A Brave N ew World ∎ Traditional DBMS: data stored in finite; persistent data sets ∎ Data Streams:distributed; continuous; unbounded; rapid; time varying; noisy; . . . ∎ Data-Stream Management:variety of modern applications – Network monitoring …,*,*,*
Efficiently Monitoring Bandwidth and Latency,Yuri Breitbart; Chee-Yong Chan; Minos Garofalakis; Rajeev Rastogi; Avi Silberschatz,*,*,*,*
Approximate Answers for XML Queries with Range Predicates,Neoklis Polyzotis; Minos Garofalakis,ABSTRACT In this paper; we tackle the difficult problem of summarizing the path/branchingstructure and numerical value content of an XML database. We introduce a novel; powerfulXML-summarization model; termed VTreeSketches; that enables accurate approximateanswers for the class of twig queries with numerical-range predicates. In a nutshell; aVTreeSketch synopsis represents an effective clustering of XML elements based on boththeir structural and value-based characteristics. By leveraging techniques for summarizingXML-document structure as well as numerical data distributions; our VTreeSketch modelprovides the first known framework for approximate query answering that handlespath/branching structure and predicates on numerical element values. We detail theVTreeSketch model and its design rationale; and develop a systematic framework for the …,*,*,*
Network Data Mining and Analysis: The,Minos Garofalakis; Rajeev Rastogi,Abstract. Modern communication networks generate large amounts of operational data;including traffic and utilization statistics and alarm/fault data at various levels of detail. Thesemassive collections of network-management data can grow in the order of several Terabytesper year; and typically hide “knowledge” that is crucial to some of the key tasks involved ineffectively managing a communication network (eg; capacity planning and trafficengineering). In this short paper; we provide an overview of some of our recent and ongoingwork in the context of the project at Bell Laboratories that aims to develop novel datawarehousing and mining technology for the effective storage; exploration; and analysis ofmassive network-management data sets. We first give some highlights of our work on Model-Based Semantic Compression (MBSC); a novel data-compression framework that takes …,NEtwork,*,*
Resource Scheduling in Enhanced Pay-Per-View,Minos N Garofalakis; Avi Silberschatz,*,*,*,*
