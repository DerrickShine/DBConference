Profiling relational data: a survey,Ziawasch Abedjan; Lukasz Golab; Felix Naumann,Abstract Profiling data to determine metadata about a given dataset is an important andfrequent activity of any IT professional and researcher and is necessary for various use-cases. It encompasses a vast array of methods to examine datasets and produce metadata.Among the simpler results are statistics; such as the number of null values and distinctvalues in a column; its data type; or the most frequent patterns of its data values. Metadatathat are more difficult to compute involve multiple columns; namely correlations; uniquecolumn combinations; functional dependencies; and inclusion dependencies. Furthertechniques detect conditional properties of the dataset at hand. This survey provides aclassification of data profiling tasks and comprehensively reviews the state of the art for eachclass. In addition; we review data profiling tools and systems from research and industry …,The VLDB Journal,2015,55
Profiling linked open data with ProLOD,Christoph Böhm; Felix Naumann; Ziawasch Abedjan; Dandy Fenz; Toni Grütze; Daniel Hefenbrock; Matthias Pohl; David Sonnabend,Linked open data (LOD); as provided by a quickly growing number of sources constitutes awealth of easily accessible information. However; this data is not easy to understand. It isusually provided as a set of (RDF) triples; often enough in the form of enormous filescovering many domains. What is more; the data usually has a loose structure when it isderived from end-user generated sources; such as Wikipedia. Finally; the quality of theactual data is also worrisome; because it may be incomplete; poorly formatted; inconsistent;etc. To understand and profile such linked open data; traditional data profiling methods donot suffice. With ProLOD; we propose a suite of methods ranging from the domain level(clustering; labeling); via the schema level (matching; disambiguation); to the data level(data type detection; pattern detection; value distribution). Packaged into an interactive …,Data Engineering Workshops (ICDEW); 2010 IEEE 26th International Conference on,2010,53
Profiling and mining RDF data with ProLOD++,Ziawasch Abedjan; Toni Gruetze; Anja Jentzsch; Felix Naumann,Before reaping the benefits of open data to add value to an organizations internal data; suchnew; external datasets must be analyzed and understood already at the basic level of datatypes; constraints; value patterns etc. Such data profiling; already difficult for large relationaldata sources; is even more challenging for RDF datasets; the preferred data model for linkedopen data. We present ProLod++; a novel tool for various profiling and mining tasks tounderstand and ultimately improve open RDF data. ProLod++ comprises various traditionaldata profiling tasks; adapted to the RDF data model. In addition; it features many specificprofiling results for open data; such as schema discovery for user-generated attributes;association rule discovery to uncover synonymous predicates; and uniqueness discoveryalong ontology hierarchies. ProLod++ is highly efficient; allowing interactive profiling for …,Data Engineering (ICDE); 2014 IEEE 30th International Conference on,2014,48
Scalable discovery of unique column combinations,Arvid Heise; Jorge-Arnulfo Quiané-Ruiz; Ziawasch Abedjan; Anja Jentzsch; Felix Naumann,Abstract The discovery of all unique (and non-unique) column combinations in a givendataset is at the core of any data profiling effort. The results are useful for a large number ofareas of data management; such as anomaly detection; data integration; data modeling;duplicate detection; indexing; and query optimization. However; discovering all unique andnon-unique column combinations is an NP-hard problem; which in principle requires toverify an exponential number of column combinations for uniqueness on all data values.Thus; achieving efficiency and scalability in this context is a tremendous challenge by itself.In this paper; we devise Ducc; a scalable and efficient approach to the problem of finding allunique and non-unique column combinations in big datasets. We first model the problem asa graph coloring problem and analyze the pruning effect of individual combinations. We …,Proceedings of the VLDB Endowment,2013,46
Improving rdf data through association rule mining,Ziawasch Abedjan; Felix Naumann,Abstract Linked Open Data comprises very many and often large public data sets; which aremostly presented in the Rdf triple structure of subject; predicate; and object. However; theheterogeneity of available open data requires significant integration steps before it can beused in applications. A promising and novel technique to explore such data is the use ofassociation rule mining. We introduce “mining configurations”; which allow us to mine Rdfdata sets in various ways. Different configurations enable us to identify schema and valuedependencies that in combination result in interesting use cases. We present rule-basedapproaches for predicate suggestion; data enrichment; ontology improvement; and queryrelaxation. On the one hand we prevent inconsistencies in the data through predicatesuggestion; enrichment with missing facts; and alignment of the corresponding ontology …,Datenbank-Spektrum,2013,31
Advancing the discovery of unique column combinations,Ziawasch Abedjan; Felix Naumann,Abstract Unique column combinations of a relational database table are sets of columns thatcontain only unique values. Discovering such combinations is a fundamental researchproblem and has many different data management and knowledge discovery applications.Existing discovery algorithms are either brute force or have a high memory load and canthus be applied only to small datasets or samples. In this paper; the well-known Gordianalgorithm [9] and" Apriori-based" algorithms [4] are compared and analyzed for furtheroptimization. We greatly improve the Apriori algorithms through efficient candidategeneration and statistics-based pruning methods. A hybrid solution HCA-Gordian combinesthe advantages of Gordian and our new algorithm HCA; and it outperforms all previous workin many situations.,Proceedings of the 20th ACM international conference on Information and knowledge management,2011,26
Context and target configurations for mining RDF data,Ziawasch Abedjan; Felix Naumann,Abstract Association rule mining has been widely studied in the context of basket analysisand sale recommendations [1]. In fact; the concept can be applied to any domain with manyitems or events in which interesting relationships can be inferred from co-occurrence ofthose items or events in existing subsets (transactions). The increasing amount of LinkedOpen Data (LOD) in the World Wide Web raises new opportunities and challenges for thedata mining community [5]. LOD is often represented in the Resource DescriptionFramework (RDF) data model. In RDF; data is represented by a triple structure consisting ofsubject; predicate; and object (SPO). Each triple represents a statement/fact. We propose anapproach that applies association rule mining at statement level by introducing the conceptof mining configurations.,Proceedings of the 1st international workshop on Search and mining entity-relationship data,2011,24
DFD: Efficient functional dependency discovery,Ziawasch Abedjan; Patrick Schulze; Felix Naumann,Abstract The discovery of unknown functional dependencies in a dataset is of greatimportance for database redesign; anomaly detection and data cleansing applications.However; as the nature of the problem is exponential in the number of attributes none of theexisting approaches can be applied on large datasets. We present a new algorithm DFD fordiscovering all functional dependencies in a dataset following a depth-first traversal strategyof the attribute lattice that combines aggressive pruning and efficient result verification. Ourapproach is able to scale far beyond existing algorithms for up to 7.5 million tuples; and is upto three orders of magnitude faster than existing approaches on smaller datasets.,Proceedings of the 23rd ACM International Conference on Conference on Information and Knowledge Management,2014,23
Detecting Data Errors: Where are we and what needs to be done?,Ziawasch Abedjan; Xu Chu; Dong Deng; Raul Castro Fernandez; Ihab F Ilyas; Mourad Ouzzani; Paolo Papotti; Michael Stonebraker; Nan Tang,Abstract Data cleaning has played a critical role in ensuring data quality for enterpriseapplications. Naturally; there has been extensive research in this area; and many datacleaning algorithms have been translated into tools to detect and to possibly repair certainclasses of errors such as outliers; duplicates; missing values; and violations of integrityconstraints. Since different types of errors may coexist in the same data set; we often need torun more than one kind of tool. In this paper; we investigate two pragmatic questions:(1) arethese tools robust enough to capture most errors in real-world data sets? and (2) what is thebest strategy to holistically run multiple tools to optimize the detection effort? To answerthese two questions; we obtained multiple data cleaning tools that utilize a variety of errordetection techniques. We also collected five real-world data sets; for which we could …,Proceedings of the VLDB Endowment,2016,22
Discovering conditional inclusion dependencies,Jana Bauckmann; Ziawasch Abedjan; Ulf Leser; Heiko Müller; Felix Naumann,Abstract Data dependencies are used to improve the quality of a database schema; tooptimize queries; and to ensure consistency in a database. Conditional dependencies havebeen introduced to analyze and improve data quality. A conditional dependency is adependency with a limited scope defined by conditions over one or more attributes. Only thematching part of the instance must adhere to the dependency. In this paper we focus onconditional inclusion dependencies (CINDs). We generalize the definition of CINDs;distinguishing covering and completeness conditions. We present a new use case for suchCINDs showing their value for solving complex data quality tasks. Further; we proposeefficient algorithms that identify covering and completeness conditions conforming to givenquality thresholds. Our algorithms choose not only the condition values but also the …,Proceedings of the 21st ACM international conference on Information and knowledge management,2012,21
Synonym analysis for predicate expansion,Ziawasch Abedjan; Felix Naumann,Abstract Despite unified data models; such as the Resource Description Framework (Rdf) onstructural level and the corresponding query language Sparql; the integration and usage ofLinked Open Data faces major heterogeneity challenges on the semantic level. Incorrect useof ontology concepts and class properties impede the goal of machine readability andknowledge discovery. For example; users searching for movies with a certain artist cannotrely on a single given property artist; because some movies may be connected to that artistby the predicate starring. In addition; the information need of a data consumer may notalways be clear and her interpretation of given schemata may differ from the intentions of theontology engineer or data publisher. It is thus necessary to either support users during queryformulation or to incorporate implicitly related facts through predicate expansion. To this …,Extended Semantic Web Conference,2013,19
Reconciling ontologies and the web of data,Ziawasch Abedjan; Johannes Lorey; Felix Naumann,Abstract To integrate Linked Open Data; which originates from various and heterogeneoussources; the use of well-defined ontologies is essential. However; oftentimes the utilizationof these ontologies by data publishers differs from the intended application envisioned byontology engineers. This may lead to unspecified properties being used ad-hoc aspredicates in RDF triples or it may result in infrequent usage of specified properties. Thesemismatches impede the goals and propagation of the Web of Data as data consumers facedifficulties when trying to discover and integrate domain-specific information. In this work; weidentify and classify common misusage patterns by employing frequency analysis and rulemining. Based on this analysis; we introduce an algorithm to propose suggestions for a data-driven ontology re-engineering workflow; which we evaluate on two large-scale RDF …,Proceedings of the 21st ACM international conference on Information and knowledge management,2012,19
Temporal rules discovery for web data cleaning,Ziawasch Abedjan; Cuneyt G Akcora; Mourad Ouzzani; Paolo Papotti; Michael Stonebraker,Abstract Declarative rules; such as functional dependencies; are widely used for cleaningdata. Several systems take them as input for detecting errors and computing a" clean"version of the data. To support domain experts; in specifying these rules; several tools havebeen proposed to profile the data and mine rules. However; existing discovery techniqueshave traditionally ignored the time dimension. Recurrent events; such as persons reported inlocations; have a duration in which they are valid; and this duration should be part of therules or the cleaning process would simply fail. In this work; we study the rule discoveryproblem for temporal web data. Such a discovery process is challenging because of thenature of web data; extracted facts are (i) sparse over time;(ii) reported with delays; and (iii)often reported with errors over the values because of inaccurate sources or non robust …,Proceedings of the VLDB Endowment,2015,16
Dataxformer: An interactive data transformation tool,John Morcos; Ziawasch Abedjan; Ihab Francis Ilyas; Mourad Ouzzani; Paolo Papotti; Michael Stonebraker,Abstract While syntactic transformations require the application of a formula on the inputvalues; such as unit conversion or date format conversions; semantic transformations; suchas" zip code to city"; require a look-up in some reference data. We recently presentedDataXFormer; a system that leverages Web tables; Web forms; and expert sourcing to covera wide range of transformations. In this demonstration; we present the user-interaction withDataXFormer and show scenarios on how it can be used to transform data and explore theeffectiveness and efficiency of several approaches for transformation discovery; leveragingabout 112 million tables and online sources.,Proceedings of the 2015 ACM SIGMOD International Conference on Management of Data,2015,14
DataXFormer: Leveraging the Web for Semantic Transformations,Ziawasch Abedjan; John Morcos; Michael Gubanov; Ihab F Ilyas; Michael Stonebraker; Paolo Papotti; Mourad Ouzzani,ABSTRACT Data transformation is a crucial step in data integration. While sometransformations; such as liters to gallons; can be easily performed by applying a formula or aprogram on the input values; others; such as zip code to city; require sifting through arepository containing explicit value mappings. There are already powerful systems thatprovide formulae and algorithms for transformations. However; the automated identificationof reference datasets to support value mapping remains largely unresolved. The Web ishome to millions of tables with many containing explicit value mappings. This is in additionto value mappings hidden behind Web forms. In this paper; we present DataXFormer; atransformation engine that leverages Web tables and Web forms to perform transformationtasks. In particular; we describe an inductive; filter-refine approach for identifying explicit …,*,2015,13
The Data Civilizer System.,Dong Deng; Raul Castro Fernandez; Ziawasch Abedjan; Sibo Wang; Michael Stonebraker; Ahmed K Elmagarmid; Ihab F Ilyas; Samuel Madden; Mourad Ouzzani; Nan Tang,ABSTRACT In many organizations; it is often challenging for users to find relevant data forspecific tasks; since the data is usually scattered across the enterprise and ofteninconsistent. In fact; data scientists routinely report that the majority of their effort is spentfinding; cleaning; integrating; and accessing data of interest to a task at hand. In order todecrease the “grunt work” needed to facilitate the analysis of data “in the wild”; we presentDATA CIVILIZER; an end-to-end big data management system. DATA CIVILIZER has alinkage graph computation module to build a linkage graph for the data and a data discoverymodule which utilizes the linkage graph to help identify data that is relevant to user tasks. Italso uses the linkage graph to discover possible join paths that can then be used in a query.For the actual query execution; we use a polystore DBMS; which federates query …,CIDR,2017,12
Rdf ontology (re-) engineering through large-scale data mining,Johannes Lorey; Ziawasch Abedjan; Felix Naumann; Christoph Böhm,Abstract. As Linked Open Data originates from various sources; leveraging well-definedontologies aids integration. However; oftentimes the utilization of RDF vocabularies by datapublishers differs from the intended application envisioned by ontology engineers.Especially in largescale datasets as presented in the Billion Triple Challenge a significantdivergence between vocabulary specification and usage patterns can be observed. Thismay impede the goals of the Web of Data in terms of discovering domain-specificinformation in the Semantic Web. In this work; we identify common misusage patterns byemploying frequency analysis and rule mining and propose reengineering suggestions.,Semantic Web Challenge,2011,10
DataXFormer: A robust transformation discovery system,Ziawasch Abedjan; John Morcos; Ihab F Ilyas; Mourad Ouzzani; Paolo Papotti; Michael Stonebraker,In data integration; data curation; and other data analysis tasks; users spend a considerableamount of time converting data from one representation to another. For example US dates toEuropean dates or airport codes to city names. In a previous vision paper; we presented theinitial design of DataXFormer; a system that uses web resources to assist in transformationdiscovery. Specifically; DataXFormer discovers possible transformations from web tablesand web forms and involves human feedback where appropriate. In this paper; we presentthe full fledged system along with several extensions. In particular; we present algorithms tofind (i) transformations that entail multiple columns of input data;(ii) indirect transformationsthat are compositions of other transformations;(iii) transformations that are not functions butrather relationships; and (iv) transformations from a knowledge base of public data. We …,Data Engineering (ICDE); 2016 IEEE 32nd International Conference on,2016,7
Detecting unique column combinations on dynamic data,Ziawasch Abedjan; Jorge-Arnulfo Quiané-Ruiz; Felix Naumann,The discovery of all unique (and non-unique) column combinations in an unknown datasetis at the core of any data profiling effort. Unique column combinations resemble candidatekeys of a relational dataset. Several research approaches have focused on their efficientdiscovery in a given; static dataset. However; none of these approaches are suitable forapplications on dynamic datasets; such as transactional databases; social networks; andscientific applications. In these cases; data profiling techniques should be able to efficientlydiscover new uniques and non-uniques (and validate old ones) after tuple inserts or deletes;without re-profiling the entire dataset. We present the first approach to efficiently discoverunique and non-unique constraints on dynamic datasets that is independent of the initialdataset size. In particular; Swan makes use of intelligently chosen indices to minimize …,Data Engineering (ICDE); 2014 IEEE 30th International Conference on,2014,6
Data profiling: A tutorial,Ziawasch Abedjan; Lukasz Golab; Felix Naumann,Abstract is to understand the dataset at hand and its metadata. The process of metadatadiscovery is known as data profiling. Profiling activities range from ad-hoc approaches; suchas eye-balling random subsets of the data or formulating aggregation queries; to systematicinference of structural information and statistics of a dataset using dedicated profiling tools.In this tutorial; we highlight the importance of data profiling as part of any data-related use-case; and we discuss the area of data profiling by classifying data profiling tasks andreviewing the state-of-the-art data profiling systems and techniques. In particular; we discusshard problems in data profiling; such as algorithms for dependency discovery and profilingalgorithms for dynamic data and streams. We also pay special attention to visualizing andinterpreting the results of data profiling. We conclude with directions for future research in …,Proceedings of the 2017 ACM International Conference on Management of Data,2017,5
Amending RDF entities with new facts,Ziawasch Abedjan; Felix Naumann,Abstract Linked and other Open Data poses new challenges and opportunities for the datamining community. Unfortunately; the large volume and great heterogeneity of availableopen data requires significant integration steps before it can be used in applications. Apromising technique to explore such data is the use of association rule mining. We introducetwo algorithms for enriching Rdf data. The first application is a suggestion engine that isbased on mining Rdf predicates and supports manual statement creation by suggesting newpredicates for a given entity. The second application is knowledge creation: Based onmining both predicates and objects; we are able to generate entirely new statements for agiven data set without any external resources.,European Semantic Web Conference,2014,5
Towards large-scale data discovery: position paper,Raul Castro Fernandez; Ziawasch Abedjan; Samuel Madden; Michael Stonebraker,Abstract With thousands of data sources spread across multiple databases and data lakes;modern organizations face a data discovery challenge. Analysts spend more time findingrelevant data to answer the questions at hand than analyzing it. In this paper we introduce adata discovery system that facilitates locating relevant data among thousands of datasources. We represent data sources succinctly through signatures; and then create searchpaths that permit quick execution of a set of data discovery primitives used for findingrelevant data. We have built a prototype that is being used to solve data discoverychallenges of two big organizations.,Proceedings of the Third International Workshop on Exploratory Search in Databases and the Web,2016,3
Assigning global relevance scores to DBpedia facts,Philipp Langer; Patrick Schulze; Stefan George; Matthias Kohnen; Tobias Metzke; Ziawasch Abedjan; Gjergji Kasneci,Knowledge bases have become ubiquitous assets in today's Web. They provide access tobillions of statements about real-world entities derived from governmental; institutional;product-oriented; bibliographic; bio-chemical; and many other domain-oriented and general-purpose datasets. The sheer amount of statements that can be retrieved for a given entitycalls for ranking techniques that return the most salient; ie; globally relevant; statements astop results. In this paper we analyze and compare various strategies for assigning globalrelevance scores to DBpedia facts with the goal to derive the best one among thesestrategies. Some of these strategies build on complementary aspects such as frequency andinverse document frequency; yet others combine structural information about the underlyingknowledge graph with Web-based co-occurrence statistics for entity pairs. A user …,Data Engineering Workshops (ICDEW); 2014 IEEE 30th International Conference on,2014,3
Sprint: ranking search results by paths,Christoph Böhm; Eyk Kny; Benjamin Emde; Ziawasch Abedjan; Felix Naumann,Abstract Graph-structured data abounds and has become the subject of much attention inthe past years; for instance when searching and analyzing social network structures.Measures such as the shortest path or the number of paths between two nodes are used asproxies for similarity or relevance [1]. These approaches benefit from the fact that themeasures are determined from some context node; eg;" me" in a social network. With Sprint;we apply these notions to a new domain; namely ranking web search results using the link-path-structure among pages. Sprint demonstrates the feasibility and effectiveness of< u>S</u> earching by< u> P</u> ath< u> R</u> anks on the< u> INT</u> ernet with two usecases: First; we re-rank intranet search results based on the position of the user's homepageon the graph. Second; as a live proof-of-concept we dynamically re-rank Wikipedia …,Proceedings of the 14th International Conference on Extending Database Technology,2011,3
Mining Association Rules on RDF Data,Ziawasch Abedjan,Linked Open Data brings new challenges and opportunities for the data mining community.Its underlying data model RDF is heterogeneous and contains machine readable semanticrelations. The amount of available open data requires profiling and integration for desiredapplications. One of the promising underlying techniques is association rule mining. Thisreport presents an overview of elaborated solutions to improve RDF data. In particular; werevisit the concept of mining configurations. Based on the mining configuration methodology;we describe several use cases: ontology engineering; auto-completion; data imputation andsynonym discovery.,Technische Berichte des Hasso-Plattner-Instituts für Softwaresystemtechnik an der Universität Potsdam,2014,1
Covering or complete? discovering conditional inclusion dependencies,Jana Bauckmann; Ziawasch Abedjan; Ulf Leser; Heiko Müller; Felix Naumann,Data dependencies; or integrity constraints; are used to improve the quality of a databaseschema; to optimize queries; and to ensure consistency in a database. In the last yearsconditional dependencies have been introduced to analyze and improve data quality. Inshort; a conditional dependency is a dependency with a limited scope defined by conditionsover one or more attributes. Only the matching part of the instance must adhere to thedependency. In this paper we focus on conditional inclusion dependencies (CINDs). Wegeneralize the definition of CINDs; distinguishing covering and completeness conditions.We present a new use case for such CINDs showing their value for solving complex dataquality tasks. Further; we define quality measures for conditions inspired by precision andrecall. We propose efficient algorithms that identify covering and completeness conditions …,*,2012,1
Entity Consolidation: The Golden Record Problem,Dong Deng; Wenbo Tao; Ziawasch Abedjan; Ahmed Elmagarmid; Ihab F Ilyas; Samuel Madden; Mourad Ouzzani; Michael Stonebraker; Nan Tang,Abstract: Four key subprocesses in data integration are: data preparation (ie; transformingand cleaning data); schema integration (ie; lining up like attributes); entity resolution (ie;finding clusters of records that represent the same entity) and entity consolidation (ie;merging each cluster into a" golden record" which contains the canonical values for eachattribute). In real scenarios; the output of entity resolution typically contains multiple dataformats and different abbreviations for cell values; in addition to the omnipresent problem ofmissing data. These issues make entity consolidation challenging. In this paper; we studythe entity consolidation problem. Truth discovery systems can be used to solve this problem.They usually employ simplistic heuristics such as majority consensus (MC) or sourceauthority to determine the golden record. However; these techniques are not capable of …,arXiv preprint arXiv:1709.10436,2017,*
A Demo of the Data Civilizer System,Raul Castro Fernandez; Dong Deng; Essam Mansour; Abdulhakim A Qahtan; Wenbo Tao; Ziawasch Abedjan; Ahmed Elmagarmid; Ihab F Ilyas; Samuel Madden; Mourad Ouzzani; Michael Stonebraker; Nan Tang,Abstract Finding relevant data for a specific task from the numerous data sources availablein any organization is a daunting task. This is not only because of the number of possibledata sources where the data of interest resides; but also due to the data being scattered allover the enterprise and being typically dirty and inconsistent. In practice; data scientists areroutinely reporting that the majority (more than 80%) of their effort is spent finding; cleaning;integrating; and accessing data of interest to a task at hand. We propose to demonstrateDATA CIVILIZER to ease the pain faced in analyzing data" in the wild". DATA CIVILIZER isan end-to-end big data management system with components for data discovery; dataintegration and stitching; data cleaning; and querying data from a large variety of storageengines; running in large enterprises.,Proceedings of the 2017 ACM International Conference on Management of Data,2017,*
CYBER SECURITY PART 2 AUTO-IMMUNITY,A Elmagarmid; P Cochrane; M Ouzzani; WJ Al Marri; Q Malluhi; M Tang; WG Aref; Z Abedjan; X Chu; D Deng; RC Fernandez; IF Ilyas; P Papotti; M Stonebraker; N Tang; Z Khayyat; W Lucia; J Quiane-Ruiz; T Nan; Y Yu; QM Malluhi; TK Saha; HM Hammady; AK Elmagarmid; H Hammady; Z Fedorowicz; M Yakout; H Elmeleegy; Y Qi,*,US Patent App,2016,*
Datasets profiling tools; methods; and systems,*,A dataset profiling tool configured to identify unique and non-unique column combinations ina dataset which comprises a plurality of tuples; the tool including: an inserts handler moduleconfigured to: receive one or more new tuples for insertion into the dataset; receive one ormore minimal uniques and one or more maximal non-uniques for the dataset; identify andgroup; for each minimal unique; any tuples of the dataset and any of the one or more newtuples which contain duplicate values in the column combinations of the minimal unique; toform grouped tuples which are grouped according to the minimal unique to which the tuplesrelate; validate the grouped tuples to identify supersets of the minimal uniques for whichduplicate values were identified; to generate a new set of one or more minimal uniques andone or more maximal non-uniques; and output the new set of one or more updated …,*,2016,*
Improving RDF data with data mining,Ziawasch Abedjan,Abstract Linked Open Data (Lod) comprises very many and often large public data sets andknowledge bases. Those datasets are mostly presented in the Rdf triple structure of subject;predicate; and object; where each triple represents a statement or fact. Unfortunately; theheterogeneity of available open data requires significant integration steps before it can beused in applications. Meta information; such as ontological definitions and exact rangedefinitions of predicates; are desirable and ideally provided by an ontology. However in thecontext of Lod; ontologies are often incomplete or simply not available. Thus; it is useful toautomatically generate meta information; such as ontological dependencies; rangedefinitions; and topical classifications. Association rule mining; which was originally appliedfor sales analysis on transactional databases; is a promising and novel technique to …,*,2014,*
Synonym Discovery in RDF Data,Ziawasch Abedjan,Linked Open Data brings new challenges and opportunities for the data mining community.Its underlying data model RDF is heterogeneous and contains machine readable semanticrelations. The amount of available open data requires profiling and integration for desiredapplications. One of the promising underlying techniques is association rule mining.However there has been only limited application of association rules on semantic web data.We introduce the concept of mining configurations that allows us to mine RDF data onstatement level. We described elaborated use cases such as ontology engineering; dataimputation that are based on configurations in the context of RDF subjects. A novelapplication that is based on mining configurations is synonym discovery. Synonym discoveryis useful for discovering globally valid synonyms for a thesauros as well supporting the …,Proceedings of the 6th Ph. D. Retreat of the HPI Research School on Service-oriented Systems Engineering,2013,*
Discovering Data Transformations in Web Resources,Ziawasch Abedjan; John Morcos; Ihab F Ilyas; Mourad Ouzzani; Paolo Papotti; Michael Stonebraker,Abstract. In data integration; data curation; and other data analysis tasks; users spend aconsiderable amount of time converting data from one representation to another. Forexample US dates to European dates or airport codes to city names. In practice; datascientists have to code most of the transformation tasks manually; search for the appropriatedictionaries; and involve domain experts. In a previous vision paper; we presented the initialdesign of DataXFormer; a system that uses web resources to assist in transformationdiscovery [1]. Specifically; DataXFormer discovers possible transformations from web tablesand web forms and involves human feedback where appropriate. We demonstrated thesystem at SIGMOD 2015 and deployed an open version of the system; which helped us toincrease our initial workload from 50 to 120 transformations [3]. At the same time we …,*,*,*
Abdelhamid; Ahmed S.,Ziawasch Abedjan; Ashraf Aboulnaga; Charu Aggarwal; Anastasia Ailamaki; Tatsuya Akutsu; Daley Alex,Page 1. ICDE 2016 Conference Detailed Author Index [Page 1 / 89] A Abdelhamid; Ahmed S. 1406Cruncher: Distributed In-Memory Processing for Location-Based Services Abedjan; Ziawasch 1134DataXFormer: A Robust Transformation Discovery System 1432 Data Profiling Aboulnaga; Ashraf181 NoSE: Schema Design for NoSQL Applications 1322 ALEX: Automatic Link Exploration in LinkedData Aggarwal; Charu 385 An Embedding Approach to Anomaly Detection 481 Efficient Handlingof Concept Drift and Concept Evolution Over Stream Data 553 Link Prediction in Graph Streams1038 Edge Classification in Networks Ailamaki; Anastasia 673 TRANSFORMERS: Robust SpatialJoins on Non-Uniform Data Distributions Akutsu; Tatsuya …,*,*,*
