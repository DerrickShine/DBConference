Timber: A native xml database,Hosagrahar V Jagadish; Shurug Al-Khalifa; Adriane Chapman; Laks VS Lakshmanan; Andrew Nierman; Stelios Paparizos; Jignesh M Patel; Divesh Srivastava; Nuwee Wiwatwattana; Yuqing Wu; Cong Yu,Abstract This paper describes the overall design and architecture of the Timber XMLdatabase system currently being implemented at the University of Michigan. The system isbased upon a bulk algebra for manipulating trees; and natively stores XML. New accessmethods have been developed to evaluate queries in the XML context; and new costestimation and query optimization techniques have also been developed. We presentperformance numbers to support some of our design decisions. We believe that the keyintellectual contribution of this system is a comprehensive set-at-a-time query processingability in a native XML store; with all the standard components of relational queryprocessing; including algebraic rewriting and a cost-based optimizer.,The VLDB Journal—The International Journal on Very Large Data Bases,2002,568
Provenance management in curated databases,Peter Buneman; Adriane Chapman; James Cheney,Abstract Curated databases in bioinformatics and other disciplines are the result of a greatdeal of manual annotation; correction and transfer of data from other sources. Provenanceinformation concerning the creation; attribution; or version history of such data is crucial forassessing its integrity and scientific value. General purpose database systems provide littlesupport for tracking provenance; especially when data moves among databases. This paperinvestigates general-purpose techniques for recording provenance for data that is copiedamong databases. We describe an approach in which we track the user's actions whilebrowsing source databases and copying data into a curated database; in order to record theuser's actions in a convenient; queryable form. We present an implementation of thistechnique and use it to evaluate the feasibility of database support for provenance …,Proceedings of the 2006 ACM SIGMOD international conference on Management of data,2006,362
Making database systems usable,HV Jagadish; Adriane Chapman; Aaron Elkiss; Magesh Jayapandian; Yunyao Li; Arnab Nandi; Cong Yu,Abstract Database researchers have striven to improve the capability of a database in termsof both performance and functionality. We assert that the usability of a database is asimportant as its capability. In this paper; we study why database systems today are sodifficult to use. We identify a set of five pain points and propose a research agenda toaddress these. In particular; we introduce a presentation data model and recommend directdata manipulation with a schema later approach. We also stress the importance ofprovenance and of consistency across presentation models.,Proceedings of the 2007 ACM SIGMOD international conference on Management of data,2007,225
Efficient provenance storage,Adriane P Chapman; Hosagrahar V Jagadish; Prakash Ramanan,Abstract As the world is increasingly networked and digitized; the data we store has moreand more frequently been chopped; baked; diced and stewed. In consequence; there is anincreasing need to store and manage provenance for each data item stored in a database;describing exactly where it came from; and what manipulations have been applied to it.Storage of the complete provenance of each data item can become prohibitively expensive.In this paper; we identify important properties of provenance that can be used toconsiderably reduce the amount of storage required. We identify three different techniques:a family of factorization processes and two methods based on inheritance; to decrease theamount of storage required for provenance. We have used the techniques described in thiswork to significantly reduce the provenance storage costs associated with constructing …,Proceedings of the 2008 ACM SIGMOD international conference on Management of data,2008,197
Why not?,Adriane Chapman; HV Jagadish,Abstract As humans; we have expectations for the results of any action; eg we expect at leastone student to be returned when we query a university database for student records. Whenthese expectations are not met; traditional database users often explore datasets via aseries of slightly altered SQL queries. Yet most database access is via limited interfaces thatdeprive end users of the ability to alter their query in any way to garner better understandingof the dataset and result set. Users are unable to question why a particular data item is Notin the result set of a given query. In this work; we develop a model for answers to WHY NOT?queries. We show through a user study the usefulness of our answers; and describe twoalgorithms for finding the manipulation that discarded the data item of interest. Moreover; wework through two different methods for tracing the discarded data item that can be used …,Proceedings of the 2009 ACM SIGMOD International Conference on Management of data,2009,155
Michigan Molecular Interactions (MiMI): putting the jigsaw puzzle together,Magesh Jayapandian; Adriane Chapman; V Glenn Tarcea; Cong Yu; Aaron Elkiss; Angela Ianni; Bin Liu; Arnab Nandi; Carlos Santos; Philip Andrews; Brian Athey; David States; HV Jagadish,Abstract Protein interaction data exists in a number of repositories. Each repository has itsown data format; molecule identifier and supplementary information. Michigan MolecularInteractions (MiMI) assists scientists searching through this overwhelming amount of proteininteraction data. MiMI gathers data from well-known protein interaction databases and deep-merges the information. Utilizing an identity function; molecules that may have differentidentifiers but represent the same real-world object are merged. Thus; MiMI allows the usersto retrieve information from many different databases at once; highlighting complementaryand contradictory information. To help scientists judge the usefulness of a piece of data;MiMI tracks the provenance of all data. Finally; a simple yet powerful user interface aidsusers in their queries; and frees them from the onerous task of knowing the data format or …,Nucleic acids research,2006,130
Michigan molecular interactions r2: from interacting proteins to pathways,V Glenn Tarcea; Terry Weymouth; Alex Ade; Aaron Bookvich; Jing Gao; Vasudeva Mahavisno; Zach Wright; Adriane Chapman; Magesh Jayapandian; Arzucan Özgür; Yuanyuan Tian; Jim Cavalcoli; Barbara Mirel; Jignesh Patel; Dragomir Radev; Brian Athey; David States; HV Jagadish,Abstract Molecular interaction data exists in a number of repositories; each with its own dataformat; molecule identifier and information coverage. Michigan molecular interactions (MiMI)assists scientists searching through this profusion of molecular interaction data. The originalrelease of MiMI gathered data from well-known protein interaction databases; and deepmerged this information while keeping track of provenance. Based on the feedback receivedfrom users; MiMI has been completely redesigned. This article describes the resulting MiMIRelease 2 (MiMIr2). New functionality includes extension from proteins to genes and topathways; identification of highlighted sentences in source publications; seamless two-waylinkage with Cytoscape; query facilities based on MeSH/GO terms and other concepts;approximate graph matching to find relevant pathways; support for querying in bulk; and a …,Nucleic acids research,2008,99
A provenance model for manually curated data,Peter Buneman; Adriane Chapman; James Cheney; Stijn Vansummeren,Abstract Many curated databases are constructed by scientists integrating various existingdata sources “by hand”; that is; by manually entering or copying data from other sources.Capturing provenance in such an environment is a challenging problem; requiring a goodmodel of the process of curation. Existing models of provenance focus on queries/views indatabases or computations on the Grid; not updates of databases or Web sites. In this paperwe motivate and present a simple model of provenance for manually curated databases anddiscuss ongoing and future work.,International Provenance and Annotation Workshop,2006,53
TIMBER: A native system for querying XML,Stelios Paparizos; Shurug Al-Khalifa; Adriane Chapman; HV Jagadish; Laks VS Lakshmanan; Andrew Nierman; Jignesh M Patel; Divesh Srivastava; Nuwee Wiwatwattana; Yuqing Wu; Cong Yu,Abstract XML has become ubiquitous; and XML data has to be managed in databases. Thecurrent industry standard is to map XML data into relational tables and store this informationin a relational database. Such mappings create both expressive power problems andperformance problems. In the T IMBER [7] project we are exploring the issues involved instoring XML in native format. We believe that the key intellectual contribution of this system isa comprehensive set-at-a-time query processing ability in a native XML store; with all thestandard components of relational query processing; including algebraic rewriting and acost-based optimizer.,Proceedings of the 2003 ACM SIGMOD international conference on Management of data,2003,43
Do you know where your data’s been?–tamper-evident database provenance,Jing Zhang; Adriane Chapman; Kristen Lefevre,Abstract Database provenance chronicles the history of updates and modifications to data;and has received much attention due to its central role in scientific data management.However; the use of provenance information still requires a leap of faith. Without additionalprotections; provenance records are vulnerable to accidental corruption; and even maliciousforgery; a problem that is most pronounced in the loosely-coupled multi-user environmentsoften found in scientific research. This paper investigates the problem of providing integrityand tamper-detection for database provenance. We propose a checksum-based approach;which is well-suited to the unique characteristics of database provenance; including non-linear provenance objects and provenance associated with multiple fine granularities ofdata. We demonstrate that the proposed solution satisfies a set of desirable security …,Workshop on Secure Data Management,2009,30
Issues in Building Practical Provenance Systems.,Adriane Chapman; HV Jagadish,Abstract The importance of maintaining provenance has been widely recognized;particularly with respect to highly-manipulated data. However; there are few deployeddatabases that provide provenance information with their data. We have constructed adatabase of protein interactions (MiMI); which is heavily used by biomedical scientists; bymanipulating and integrating data from several popular biological sources. The provenancestored provides key information for assisting researchers in understanding and trusting thedata. In this paper; we describe several desiderata for a practical provenance system; basedon our experience from this system. We discuss the challenges that these requirementspresent; and outline solutions to several of these challenges that we have implemented. Ourlist of a dozen or so desiderata includes: efficiently capturing provenance from external …,IEEE Data Eng. Bull.,2007,30
Scalable Access Controls for Lineage.,Arnon Rosenthal; Len Seligman; Adriane Chapman; Barbara T Blaustein,Abstract Lineage stores often contain sensitive information that needs protection fromunauthorized access. We build on prior work for security and privacy of lineage information;focusing on complex conditions and scalable administration. We use Attribute-Based AccessControl (ABAC) to express conditions based on many attributes; instead of roles. We thenmake administration and management more scalable; instead of managing large; monolithicaccess predicates for each object. To do so; we first support modular traceability andmaintainability for separate concerns (eg security; legally mandated privacy;organizationally mandated privacy). We then provide constructs to manage authority whenmultiple administrators must collaborate. We show that these security techniques areneeded for easy lineage security administration.,Workshop on the Theory and Practice of Provenance,2009,26
Plus: A provenance manager for integrated information,Adriane Chapman; Barbara T Blaustein; Len Seligman; M David Allen,It can be difficult to fully understand the result of integrating information from diverse sources.When all the information comes from a single organization; there is a collective knowledgeabout where it came from and whether it can be trusted. Unfortunately; once information frommultiple organizations is integrated; there is no longer a shared knowledge of the data andits quality. It is often impossible to view and judge the information from a differentorganization; when errors occur; notification does not always reach all users of the data. Wedescribe how a multi-organizational provenance store that collects provenance fromheterogeneous systems addresses these problems. Unlike most provenance systems; wecope with an open world; where the data usage is not determined in advance and can takeplace across many systems and organizations.,Information Reuse and Integration (IRI); 2011 IEEE International Conference on,2011,21
Surrogate parenthood: protected and informative graphs,Barbara Blaustein; Adriane Chapman; Len Seligman; M David Allen; Arnon Rosenthal,Abstract Many applications; including provenance and some analyses of social networks;require path-based queries over graphstructured data. When these graphs contain sensitiveinformation; paths may be broken; resulting in uninformative query results. This paperpresents innovative techniques that give users more informative graph query results; thetechniques leverage a common industry practice of providing what we call surrogates:alternate; less sensitive versions of nodes and edges releasable to a broader community.We describe techniques for interposing surrogate nodes and edges to protect sensitivegraph components; while maximizing graph connectivity and giving users as muchinformation as possible. In this work; we formalize the problem of creating a protectedaccount G'of a graph G. We provide a utility measure to compare the informativeness of …,Proceedings of the VLDB Endowment,2011,21
Provenance-based belief,Adriane Chapman; Barbara Blaustein; Chris Elsaesser,Page 1. © 2010 The MITRE Corporation. All rights reserved. Approved for Public Release;Distribution Unlimited - 09-5315 Adriane Chapman; Barbara Blaustein and Chris ElsaesserProvenance-based Belief Confession #1 Provenance and Causality Confession #2 CausalityArguments Page 2. © 2010 The MITRE Corporation. All rights reserved. Approved for PublicRelease; Distribution Unlimited - 09-5315 2 Motivation “Provenance can be used to determinehow much to trust the data” Provenance metadata is essential for data consumers to assess theauthoritativeness and trustworthiness of the data asset – IA Metadata COI Adventure Hiking Blog:Stomach Flu US State Dept. Travel Advisory: Dengue Hemorrhagic Fever Page 3. © 2010 TheMITRE Corporation. All rights reserved. Approved for Public Release; Distribution Unlimited -09-5315 3 So add Provenance Report of suspected Dengue Hemorrhagic Fever …,3rd USENIX Workshop on the Theory and Practice of Provenance,2010,16
Anomaly detection for database systems,*,Methods; systems and computer program products for detecting anomalies for a databasesystem are provided. A method may include extracting workload features from a queryoptimizer based on a query workload and generating feature models for the extractedworkload features. The method may also include extracting instance features from the queryoptimizer based on a query instance. Instance feature values may be obtained. The methodmay further include applying a query instance to the workload feature models to produce aprediction value for each workload feature. Anomalies may be reported based on acomparison of each instance feature value with a corresponding prediction value. A systemfor detecting anomalies for a database system may include a query optimizer; a featuremodeler and an anomaly detector.,*,2013,15
Provenance for collaboration: Detecting suspicious behaviors and assessing trust in information,M David Allen; Adriane Chapman; Len Seligman; Barbara Blaustein,Data collaborations allow users to draw upon diverse resources to solve complex problems.While collaborations enable a greater ability to manipulate data and services; they alsocreate new security vulnerabilities. Collaboration participants need methods to detectsuspicious behaviors (potentially caused by malicious insiders) and assess trust ininformation when it passes through many hands. In this work; we describe these challengesand introduce provenance as a way to solve them. We describe a provenance system;PLUS; and show how it can be used to assist in assessing trust and detecting suspiciousbehaviors. A preliminary study shows this to be a promising direction for future research.,Collaborative Computing: Networking; Applications and Worksharing (CollaborateCom); 2011 7th International Conference on,2011,12
Capturing provenance in the wild,M David Allen; Adriane Chapman; Barbara Blaustein; Len Seligman,Abstract All current provenance systems are “closed world” systems; provenance is collectedwithin the confines of a well understood; pre-planned system. However; when userscompose services from heterogeneous systems and organizations to form a newapplication; it is impossible to track the provenance in the new system using currentlyavailable work. In this work; we describe the ability to compose multiple provenance-unaware services in an “open world” system and still collect provenance information abouttheir execution. Our approach is implemented using the PLUS provenance system and theopen source MULE Enterprise Service Bus. Our evaluations show that this approach isscalable and has minimal overhead.,International Provenance and Annotation Workshop,2010,12
Getting It Together: Enabling Multi-organization Provenance Exchange.,M David Allen; Adriane Chapman; Barbara T Blaustein; Len Seligman,Abstract We present an architecture that supports provenance queries in large; dynamic;multi-organizational environments. The Provenance Challenges have explored exchangeacross disparate provenance systems; yet this is only a first step. We describe requirementsfor multi-organizational provenance; evaluate candidate architectures; describe theapproach implemented in the PLUS prototype provenance manager; and presentperformance results that indicate the approach is scalable.,TaPP,2011,11
Understanding provenance black boxes,Adriane Chapman; HV Jagadish,Abstract Current provenance stores associated with workflow management systems(WfMSs) capture enough coarse-grained information to describe which datasets were usedand which processes were run. While this information is enough to rebuild a workflow run; itis not enough to facilitate user understanding. Because the data is manipulated via a seriesof black boxes; it is often impossible for a human to understand what happened to the data.In this work; we highlight the missing information that can assist user understanding.Unfortunately; provenance information is already very complex and difficult for a user tocomprehend; which can be exacerbated by adding the extra information needed for deeperblackbox understanding. In order to alleviate this; we develop a model of provenanceanswers that follow a “roll up”;“drill down” strategy. We evaluate these techniques to …,Distributed and Parallel Databases,2010,11
Towards Query Interoperability: PASSing PLUS.,Uri Braun; Margo I Seltzer; Adriane Chapman; Barbara T Blaustein; M David Allen; Len Seligman,Abstract We describe our experiences importing PASS [16] provenance into PLUS [7].Although both systems import and export provenance that conforms to the Open ProvenanceModel (OPM)[14]; the two systems vary greatly with respect to the granularity of provenancecaptured; how much semantic knowledge the system contributes; and the completeness ofprovenance capture. We encountered several problems reconciling provenance betweenthe two systems and use that experience to specify a Common Provenance Framework; thatprovides a higher degree of interoperability between provenance systems. In each case; theproblems stem from the fact that OPM interoperability is a weaker requirement than queryinteroperability. Our goal in presenting this work is to generate discussion about differingdegrees of interoperability and the requirements thereof.,TaPP,2010,11
TIMBER: A native XML database,Stelios Paparizos; Shurug Al-Khalifa; Y Wu; N Wiwatwattana; HV Jagadish; Andrew Nierman; C Yu; LVS Lakshmanan; D Srivastava; A Chapman; Jignesh M Patel,This paper describes the overall design and architecture of the Timber XML databasesystem currently being implemented at the University of Michigan. The system is based upona bulk algebra for manipulating trees; and natively stores XML. New access methods havebeen developed to evaluate queries in the XML context; and new cost estimation and queryoptimization techniques have also been developed. We present performance numbers tosupport some of our design decisions. We believe that the key intellectual contribution of thissystem is a comprehensive set-at-a-time query processing ability in a native XML store; withall the standard components of relational query processing; including algebraic rewritingand a cost-based optimizer.,*,2002,10
It's About the Data: Provenance as a Tool for Assessing Data Fitness.,Adriane Chapman; M David Allen; Barbara T Blaustein,Abstract The end goal of provenance is to assist users in understanding their data: How wasit created? When? By whom? How was it manipulated? In other words; provenance is apowerful tool to help users answer the question;“Is this data fit for use?” However; there is noone set of criteria that make data “fit for use”. The criteria depend on the user; the task athand; and the current situation. In this work we describe Fitness Widgets; predefined queriesover provenance graphs that users can customize to determine data fitness. We haveimplemented Fitness Widgets in our provenance system; PLUS.,TaPP,2012,8
Provenance and the Price of Identity,Adriane Chapman; HV Jagadish,Abstract As developers acknowledge that provenance is essential; more and more datasetsare attempting to keep provenance records describing how they were created. Some ofthese datasets are constructed using workflows; others cobble together processes andapplications to manipulate the data. While the provenance needs are the same; the inputsand set of processes used must be kept; the identity needs are very different. We outlineseveral identification strategies that can be used for data manipulation outside of workflows.We evaluate these strategies in terms of time to create and store identity; and the spaceneeded to keep this information. Additionally; we discuss the strengths and weaknesses ofeach strategy.,International Provenance and Annotation Workshop,2008,7
PLUS: Provenance for life; the universe and stuff,Adriane Chapman; M David Allen; Barbara Blaustein; Len Seligman; Chris Wolf; Michael Morse; Arnon Rosenthal,ABSTRACT In this demonstration; we exhibit a new type of provenance system; one that isnot tied to any particular domain; closed-world system or use. The PLUS provenance systemwas inspired by government requirements to enable provenance capture; storage and useacross multi-organizational systems. PLUS is general enough to interact across open-worlddistributed systems; often without administrative access to those underlying distributedsystems. It captures and stores provenance; permits user annotations; and provides tools foranalyzing the provenance on the basis of those annotations. Due to the need to shareprovenance across many organizations; much attention has been paid to provenanceaccess and security. We highlight all of these features via a demonstration using anEmergency Preparedness and Response (EP&R) scenario.,VLDB'10; VLDB Endowment,2010,5
What do we do now? Workflows for an unpredictable world,M David Allen; Adriane Chapman; Barbara Blaustein; Lisa Mak,Abstract Workflow systems permit organization of many individual subtasks into a cohesivewhole; in order to accomplish a specific mission. For many government and businessmissions; these systems are used to manage repetitive processes; such as large data-processing and exploitation pipelines. Government missions with strong interactions with thereal world are extremely dynamic; as are all missions dealing with error-prone or changingdata streams. We contribute a vision for discovery of new steps in adaptive workflowsystems; suitability functions that can discover candidate alternatives; and a way forward forsourcing options for decision-makers; without the strong assumptions required by previouswork. As data-processing workflows are shared; the sharing entities may find that certainparts of the workflow must be adapted to the new environment of mission. Extremely …,Future Generation Computer Systems,2015,4
Provenance Capture Disparities Highlighted through Datasets.,G Blake Coe; R Christopher Doty; M David Allen; Adriane Chapman,Abstract Provenance information is inherently affected by the method of its capture. Differentcapture mechanisms create very different provenance graphs. In this work; we describe anacademic use case that has corollaries in offices everywhere. We also describe two distinctpossibilities for provenance capture methods within this domain. We generate three datasetsusing these two capture methods: the capture methods run individually and a trace of whatan omniscient capture agent would see. We describe how the different capture methodslead to such very different graphs and release the graphs for others to use via theProvBench effort.,TAPP,2014,4
Effective integration of protein data through better data modeling,Adriane Chapman; Cong Yu; HV Jagadish,Protein data; from sequence and structure to interaction; is being generated through manydiverse methodologies; it is stored and reported in numerous forms and multiple places. Themagnitude of the data limits researchers abilities to utilize all information generated.Effective integration of protein data can be accomplished through better data modeling. Wedemonstrate this through the MIPD project.,OMICS A Journal of Integrative Biology,2003,4
Fit for purpose: engineering principles for selecting an appropriate type of data exchange standard,Arnon Rosenthal; Len Seligman; M David Allen; Adriane Chapman; Hongwei Zhu,Abstract Data standards are a powerful; real-world tool for enterprise interoperability; yetthere exists no well-grounded methodology for selecting among alternative standardsapproaches. We focus on a specific sub-problem within a community's data sharingchallenge and identify four major standards-based approaches to that task. We presentcharacteristics of a data sharing community that one should consider in selecting astandards approach—such as relative power; motivation level; and technical sophisticationof different participants—and illustrate with real-world examples. These characteristics andother factors are then analyzed to develop decision rules for selecting among the fourapproaches. Independent of the data exchange problem; we suggest two general practicesin choosing a standards approach:(1) vertical decomposition of interoperability issues; in …,Information Systems and e-Business Management,2014,2
Engineering Choices for Open World Provenance,M David Allen; Adriane Chapman; Barbara Blaustein,Abstract This work outlines engineering decisions required to support a provenance systemin an open world where systems are not under any common control and use many differenttechnologies. Real US government applications have shown us the need for specializedidentity techniques; flexible storage; scalability testing; protection of sensitive information;and customizable provenance queries. We analyze tradeoffs for approaches to each area;focusing more on maintaining graph connectivity and breadth of capture; rather than on fine-grained/detailed capture as in other works. We implement each technique in the PLUSsystem; test its real-time efficiency; and describe the results.,International Provenance and Annotation Workshop,2014,2
Fit for purpose: toward an engineering basis for data exchange standards,Arnon Rosenthal; Len Seligman; M David Allen; Adriane Chapman,Abstract Data standards are a powerful; real-world tool for enterprise interoperability; yetthere exists no rigorous methodology for selecting among alternative standards approaches.This paper is a first step toward creating a detailed engineering basis for choosing amongstandards approaches. We define a specific sub-problem within a community's data sharingchallenge; and focus on it in depth. We describe the major choices (kinds of standards)applied to that task; examining tradeoffs. We present characteristics of a data sharingcommunity that one should consider in selecting a standards approach—such as relativepower; motivation level; and technical sophistication of different participants—and illustratewith real-world examples. We then show that one can state simple decision rules (based onengineering experience) that system engineers without decades of data experience can …,International IFIP Working Conference on Enterprise Interoperability,2013,2
Capturing Provenance Data Within Heterogeneous Distributed Communications Systems,*,A system and method is provided for capturing provenance from heterogeneous distributedcommunication systems. A point of coordination is monitored for messages that are input toand output from applications. Each message is identified and linked and each message islinked to the application that such message is input to or output from. Numerous sequencesof such interactions can be linked together to form a provenance graph.,*,2012,2
Provenance Capture and Use: A Practical Guide,M David Allen; Len Seligman; Barbara Blaustein; Adriane Chapman,ABSTRACT. There is a widespread recognition across MITRE's sponsors of the importanceof capturing the provenance of information (sometimes called lineage or pedigree).However; the technology for supporting capture and usage of provenance is relativelyimmature. While there has been much research; few commercial capabilities exist. Inaddition; there is neither a commonly understood concept of operations nor established bestpractices for how to capture and use provenance information in a consistent and principledway. This document captures lessons learned from the IM-PLUS project; which isprototyping a provenance capability that synthesizes prior research; the project is alsoapplying the prototype to government application scenarios spanning defense; homelandsecurity; and bio-surveillance. We describe desirable features of a provenance capability …,The MITRE Corporation,2010,2
Incorporating provenance in database systems,Adriane P Chapman,Abstract The importance of maintaining provenance has been widely recognized;particularly with respect to highly-manipulated data. Currently there are two approaches:provenance generated within workflow frameworks; and provenance within a containedrelational database. The workflow provenance allows workflow re-execution; and can offersome explanation of results. Within relational databases; knowledge of SQL queries andrelational operators is used to express what happened to a tuple.,*,2008,2
Guest editorial: The provenance of online data,Adriane Chapman; James Cheney; Simon Miles,Across many domains; there is a need to trace how data has been created; manipulated;and disseminated. This has led to strong recent interest in technology for modelling andreasoning about provenance. Provenance is information about the entities; activities; andpeople involved in producing a piece of data or thing; which can be used to formassessments about its quality; reliability; or trustworthiness. It is itself data; commonlyrepresented as a directed acyclic graph linking these elements (entities; activities; andagents) to the earlier elements that influenced them. Provenance is becoming a key Internettechnology; and the World Wide Web Consortium has standardised PROV as arepresentation for exchanging provenance on the (Semantic) Web. It is also important in anumber of other settings to address the problems that arise in a distributed …,ACM Transactions on Internet Technology (TOIT),2017,1
Modelling Provenance Collection Points and Their Impact on Provenance Graphs,David Gammack; Steve Scott; Adriane P Chapman,Abstract As many domains employ ever more complex systems-of-systems; capturingprovenance among component systems is increasingly important. Applications such asintrusion detection; load balancing; traffic routing; and insider threat detection all involvemonitoring and analyzing the data provenance. Implicit in these applications is theassumption that “good” provenance is captured (eg complete provenance graphs; or one fullpath). When attempting to provide “good” provenance for a complex system of systems; it isnecessary to know “how hard” the provenance-enabling will be and the likely quality of theprovenance to be produced. In this work; we provide analytical results and simulation toolsto assist in the scoping of the provenance enabling process. We provide use cases ofcomplex systems-of-systems within which users wish to capture provenance. We describe …,International Provenance and Annotation Workshop,2016,1
Provenance tipping point,David Gammack; Adriane Chapman,Abstract Capture is a known; difficult problem for provenance. Obtaining from the systemsand programs exactly what happened has been a continuing struggle outside of databaseand workflow systems. The provenance research community has created libraries to logprovenance; and has also embedded instances of capture agents within operating systems;specific programs; etc. However; it is impossible to know if we are inserting capture agents atboth the optimal location and frequency in a given system for a high quality provenancegraph. In this work; we develop an initial agent based model to simulate Activity and Entityinteractions in a complex system of software. Using this model; we can attempt to definesome generalized principles about type; frequency and distribution of provenance captureagents given a new system.,*,2015,1
Data Provenance and Financial Systemic Risk,Len Seligman; Shaun Brady; Barbara Blaustein; Paula Mutchler; Adriane Chapman; Charles Worrell,Abstract: We describe the needs for data provenance in a large-scale analytic environmentto support financial systemic risk analysis. Government financial regulators need to makesense of the outputs of thousands to tens of thousands of simulation runs invoked by a largeanalytic staff; automatic capture of data provenance (dataset sources and processing steps)supports analysts without adding to their workloads. We present an architecture forautomated provenance capture from both simulations and data transformation tools. Finally;we describe a prototype implementation and next steps.,*,2013,1
Provenance: Information for Shared Understanding,M David Allen; Adriane Chapman; Barbara Blaustein,Abstract–Agile command and control (C2) systems allow users to draw upon diverseresources to solve complex problems. This paper describes data provenance technologybeing developed to support shared understanding of information and to better equip users toassess the suitability of shared information. We describe a provenance system; PLUS; andshow how it can be used to assist in assessing trust and system quality. In addition; wedescribe novel and minimally invasive approaches to capture provenance automaticallywithin distributed; heterogeneous C2 systems; and we compare the engineering costs andbenefits of these approaches.,*,2012,1
MiMI: Michigan molecular interactions,Adriane Chapman; Magesh Jayapandian; Cong Yu; HV Jagadish,ABSTRACT There is a proliferation of data sources in biology. A complete understanding ofa biological problem often requires the integration of multiple data sources; each providinginsights on certain aspects of the problem. Furthermore; different sources often representdata in different ways; even when they cover the same information. Researchers interestedin a particular biological problem are forced to search for and understand multiple; oftenconflicting sources; and piece the jigsaw puzzle of information together for themselves. TheMichigan Molecular Interactions Database (MiMI) attempts to relieve scientists of this burden(MiMI; 2005). By integrating popular; well-known datasets; MiMI combines all the power ofeach individual dataset; like BIND (Bader et al.; 2003); and multiplies their benefits toindividual researchers by merging them with other known facts from diverse datasets. By …,*,2005,1
prFood:: ontology principles for provenance and risk in the food domain,Belfrit Batlajery; Mark Weal; Adriane Chapman; Luc Moreau,An ontology; a formal representation of domain knowledge; is an integral building block ofthe semantic web and is important in building an application within interdisciplinarydomains. In the food domain; regulations require Food Business Operators (FBOs) to complywith traceability and track-ability measures when handling food in order to assess risk. In thispaper; we identify several requirements to model food; food history; and risk ofcontamination in order to support the safety regulations of food. Using those requirements;we also identify and apply several design principles for building an ontology called prFoodthat encompasses Interdisciplinary domains; food and risk. In order to apply safe handling offood in the food supply chain; we integrate and incorporate the pre-existing food ontologieswith prFood by implementing a mapping procedure. Finally; we validate our approach by …,*,2018,*
2017 TERMIS-Americas Conference & Exhibition Charlotte; NC December 3–6; 2017,CP Jackman; S Heo; N Bursac; BW Walker; CH Yu; E Shirzaei Sani; W Kimball; N Annabi; S Sapru; D Naskar; B Kundu; AK Ghosh; M Mandal; RL Reis; SC Kundu; JM Oliveira Sr; RL Reis; X Jing; H Mi; L Turng; FR Maia; DS Musson; D Naot; LP da Silva; AR Bastos; JB Costa; JM Oliveira; VM Correlo; RL Reis; J Cornish; A Orza; N Iyer; M Estevez; A Sreeram; S Cuskey; N Fedorchak; R Ashton; S Chew; U Milbreta; C Pinese; J Park; I Wetzel; H Cho; LA Poole-Warren; U Aregueta Robles; A Gilmour; J Goding; NH Lovell; PJ Martens; RA Green; L Zirretta; D Stapp; S Grundeen; A Doyle; JM Grasman; DL Kaplan; NV Maximova; ME Krasheninnikov; ID Klabukov; IA Pomytkin; AV Lyundup; EP Sproul; S Nandi; CA Roosa; AC Brown; A Kharge; A Gandhi; P Attar; S Korn; K Lam; S Saini; D Nichols; S Hyoju; O Zaborina; J Alverdy; F Teymour; G Papavasiliou; R Narayan; S Wadsworth; S Beyer; K Walus; K Thain; S Pan; T Mohamed; G De Riccardis; PG Alexander; MT Raimondi; RS Tuan; R Gottardi; J Lembong; MJ Lerman; TJ Kingsbury; CI Civin; JP Fisher; M Felder; C Williams; V Sikavitsas; M Komura; K Suzuki; H Komura; JK Williams; SK Lankford; K Andersson; AF Pellegata; AM Tedeschi; A Gjinovci; S Russo; C Camilli; G Cossu; S Mantero; P De Coppi; MC Cramer; SF Badylak; E Zakhem; J Bohl; R Tamburrini; P Dadhich; K Bitar; P Dadhich; EM Petran; E Zakhem; KN Bitar; M Juhas; NO Abutaleb; JT Wang; N Bursac; C Di Bella; C O'Connell; R Blanchard; S Duchi; S Ryan; Z Yue; C Onofrillo; G Wallace; P Choong; l wang; A Meppelink; D Remer; X Hu; SS Blemker; GJ Christ; L Cornell; J McDaniel; B Lund; D Zamora; V Delplace; N Mitrousis; J Parker; M Pakulska; MS Shoichet,Cardiomyocytes (CM) in the adult mammalian heart have limited capacity to proliferatefollowing injury. Thus; therapies to induce endogenous regeneration of the heart wouldsignificantly improve cardiac function in the setting of heart disease. We have previouslyengineered 3-dimensional cylindrical tissues (''cardiobundles'') made from neonatal rat CMembedded in fibrin-based hydrogel (* 16 cardiobundles derived from 1 neonatal heart);which accurately mimic the dense and anisotropic cellular structure of native myocardiumwhile also displaying tissue-level functional properties comparable to the adult oradolescent heart [1]. Here; we show that CM in cardiobundles stop proliferating (< 1%turnover per day) after 2 weeks in standard culture conditions; representing a high-fidelity invitro model to test potential therapies for re-activation of the cell cycle in post-mitotic …,Tissue Engineering Part A,2017,*
Making data useful and usable,Adriane Chapman,Data is ubiquitous; everyone has it and deals with it. However; just because everyone dealswith it; doesn't mean that we naturally handle it well or efficiently. In this talk; AdrianeChapman will introduce herself to the WAIS group and describe her interest in making datauseful and usable. She will describe her past work in provenance; and her current work inannotations; provenance and data modelling.,*,2017,*
How we learned to stop worrying and embrace the chaos,Peter Mork; Adriane Chapman; Arnon Rosenthal,The University of Southampton …,*,2017,*
Provenance Storage,Thomas Heinis; Adriane Chapman,Heinis; Thomas and Chapman; Adriane (2017) Provenance Storage In; Liu; Ling and Ozsu;M. Tamer (eds.) Encyclopedia of Database Systems. Springer New York (doi:10.1007/978-1-4899-7993-3_80746-1) … Downloads from ePrints over the past year. Other digital versions mayalso be available to download eg from the publisher's website … This repository has been builtusing EPrints software; developed at the University of Southampton; but available to everyoneto use … We use cookies to ensure that we give you the best experience on our website. If youcontinue without changing your settings; we will assume that you are happy to receive cookieson the University of Southampton website.,*,2017,*
The Challenge of “Quick and Dirty” Information Quality,Adriane P Chapman; Arnon Rosenthal; Len Seligman,Traditionally; information quality (IQ) techniques provide CIOs and other senior IT managerswith an in-depth quality assessment of data assets under the control of the enterprise. Thegoal is to clean dirty data to improve current operational effectiveness and to identify ways inwhich the organization's data production processes can be improved so as to producehigher-quality data in the future. This process typically takes place over months and years;and it consumes substantial human and computer resources [Redman 1998; Shilakes andJulieTylman 1998; Gorla; Somers et al. 2010]. Prior work that studies data quality within alimited time frame; such as Long et al.[2004]; assumes that the data owner is undertaking acuration task. This article argues for a new direction in IQ research; to enable the creation ofrapidly deployed functionality; where the timescale is hours or days rather than months. In …,Journal of Data and Information Quality (JDIQ),2016,*
connect with us,Paolo Missier; Jun Zhao; Vanessa Braganholo; Adriane Chapman; Sarah Cohen-Boulakia; Vasa Curcin; Tom De Nies; Lois Delcambre; Saumen Dey; Alan Fekete; Irini Fundulaki; Floris Geerts; Ashish Gehani; Boris Glavic; Paul Groth; Melanie Herschel; Bertram Ludaescher; Simon Miles; Luc Moreau; Paolo Papotti; Sudeepa Roy; Perdita Stevens; James Cheney,Abstract: The cost of deriving actionable knowledge from large datasets has beendecreasing thanks to a convergence of positive factors: low cost data generation;inexpensively scalable storage and processing infrastructure (cloud); software frameworksand tools for massively distributed data processing; and parallelisable data analyticsalgorithms. One observation that is often overlooked; however; is that each of theseelements is not immutable; rather they all evolve over time. As those datasets change overtime; the value of their derivative knowledge may decay; unless it is preserved by reacting tothose changes. Our broad research goal is to develop models; methods; and tools forselectively reacting to changes by balancing costs and benefits; ie through complete orpartial re-computation of some of the underlying processes. In this paper we present an …,*,2016,*
Extending the FHIR standard to handle provenance,John Moehrke; Arnon Rosenthal; Adriane Chapman,Downloads from ePrints over the past year. Other digital versions may also be available to downloadeg from the publisher's website … This repository has been built using EPrints software; developedat the University of Southampton; but available to everyone to use … We use cookies to ensurethat we give you the best experience on our website. If you continue without changing yoursettings; we will assume that you are happy to receive cookies on the University of Southamptonwebsite.,*,2016,*
Provenance Needs Incentives for Everyone,Adriane Chapman; Arnon Rosenthal,Abstract Despite fervent early adopters; a rich research community and top-down mandatesrequiring its use; digital provenance has not become a pervasive and mainstreamtechnology. While technological barriers still exist; the provenance community also mustaddress thorny nontechnical issues. In particular; for critical stakeholders; the cost (time;expenses) of using and maintaining a provenance system is; from their viewpoint; often notworth the investment. In this work; we describe a real military use case and identify thevarious stakeholders. We then introduce the concept of incentives; to increase the return oninvestment for provenance usage; illustrating incentives with our use case.,*,2014,*
Time Constrained Information Quality,Arnon Rosenthal; Len Seligman; Adriane Chapman,Abstract. Prior information quality metrics and techniques help CIOs and other senior ITmanagers assess and improve the quality of enterprise data over months and years. Wepropose a new direction for research: time constrained information quality (TCIQ). Wedescribe motivating applications in which mashup developers must quickly choose amongpotential data sources and provide “good enough” information in a hurry. We briefly describeresearch in progress tackling the time constrained information quality challenge. We presenta notional architecture for a TCIQ Advisor tool and describe open research challenges.,ACM Journal of Data and Information Quality,2012,*
Provenance Capture and Use: A Practical Guide,Adriane Chapman; Barbara Blaustein; Leonard Seligman; M David Allen,Downloads from ePrints over the past year. Other digital versions may also be available to downloadeg from the publisher's website … This repository has been built using EPrints software; developedat the University of Southampton; but available to everyone to use … We use cookies to ensurethat we give you the best experience on our website. If you continue without changing yoursettings; we will assume that you are happy to receive cookies on the University of Southamptonwebsite.,*,2010,*
Provenance in Manually Curated Databases,Peter Buneman; Adriane Chapman; James Cheney; Stijn Vansummeren,Abstract. Many curated databases are constructed by scientists integrating various existingdata sources. Most current approaches to provenance in databases are based on views andfail to take account of the added value of the work done by scientists in manually creatingand modifying data. Capturing provenance in such an environment is a challengingproblem; requiring changes in practice; changes to existing software; and crucially; a goodmodel of the process of curation.,*,*,*
Novelty Discovery with Heterogeneous Features,Ken Samuel; Peter Mork; Adriane Chapman; David Moore; Irina Vayndiner; Erik Sax,Abstract This paper presents experiments with a unique machine learning method calledCross-Feature Analysis; which is a novelty discovery method that can easily accommodateheterogeneous features. The domain of our work is database security; with the goal ofdetecting attacks that are similar to those seen in the past as well as completely novelattacks that have not yet been seen. The training data consists of database logs that have noattacks; so supervised machine learning methods cannot apply; and unsupervised machinelearning methods are unsatisfactory; because we have a variety of feature types; includingnumerical features; categorical features; and set-valued features. However; Cross-FeatureAnalysis transforms our novelty discovery problem into multiple supervised machinelearning problems; building one submodel for each feature by treating that feature as the …,*,*,*
