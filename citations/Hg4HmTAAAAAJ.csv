On the computation of multidimensional aggregates,Sameet Agarwal; Rakesh Agrawal; Prasad M Deshpande; Ashish Gupta; Jeffrey F Naughton; Raghu Ramakrishnan; Sunita Sarawagi,Abstract At the heart of OLAP or multidimensional data analysis applications is the ability tosimultaneously aggregate across many sets of dimensions. Computing multidimensionalaggregates is a performance bottleneck for these applications. We explore various schemesfor implementing multidimensional aggregation; in particular; the CUBE operator [1]proposed by Gray et al. This operator computes aggregates over all subsets of dimensionsspecified in the CUBE operation; and is equivalent to the union of a number of standardgroup-by operations. We show how the structure of CUBE computation can be viewed interms of a hierarchy of group-by operations; and present a class of sorting-based algorithmsthat overlap the computation of different group-by operations using the least possiblememory for each computation. Our algorithms seek to minimize the number of sorting …,VLDB,1996,849
Modeling multidimensional databases,Rakesh Agrawal; Ashish Gupta; Sunita Sarawagi,The authors propose a data model and a few algebraic operations that provide semanticfoundation to multidimensional databases. The distinguishing feature of the proposed modelis the symmetric treatment not only of all dimensions but also measures. The model providessupport for multiple hierarchies along each dimension and support for ad hoc aggregates.The proposed operators are composable; reorderable; and closed in application. Theseoperators are also minimal in the sense that none can be expressed in terms of others norcan any one be dropped without sacrificing functionality. They make possible the declarativespecification and optimization of multidimensional database queries that are currentlyspecified operationally. The operators have been designed to be translated to SQL and canbe implemented either on top of a relational database system or within a special purpose …,Data Engineering; 1997. Proceedings. 13th International Conference on,1997,802
Information extraction,Sunita Sarawagi,Abstract The automatic extraction of information from unstructured sources has opened upnew avenues for querying; organizing; and analyzing data by drawing upon the cleansemantics of structured databases and the abundance of unstructured data. The field ofinformation extraction has its genesis in the natural language processing community wherethe primary impetus came from competitions centered around the recognition of namedentities like people names and organization from news articles. As society became moredata oriented with easy online access to both structured and unstructured data; newapplications of structure extraction came around. Now; there is interest in converting ourpersonal desktops to structured databases; the knowledge in scientific publications tostructured records; and harnessing the Internet for structured fact finding queries …,Foundations and Trends® in Databases,2008,714
Interactive deduplication using active learning,Sunita Sarawagi; Anuradha Bhamidipaty,Abstract Deduplication is a key operation in integrating data from multiple sources. The mainchallenge in this task is designing a function that can resolve when a pair of records refer tothe same entity in spite of various data inconsistencies. Most existing systems use hand-coded functions. One way to overcome the tedium of hand-coding is to train a classifier todistinguish between duplicates and non-duplicates. The success of this method criticallyhinges on being able to provide a covering and challenging set of training pairs that bringout the subtlety of deduplication function. This is non-trivial because it requires manuallysearching for various data inconsistencies between any two records spread apart in largelists. We present our design of a learning-based deduplication system that uses a novelmethod of interactively discovering challenging training pairs using active learning. Our …,Proceedings of the eighth ACM SIGKDD international conference on Knowledge discovery and data mining,2002,685
Semi-markov conditional random fields for information extraction,Sunita Sarawagi; William W Cohen,Abstract We describe semi-Markov conditional random fields (semi-CRFs); a conditionallytrained version of semi-Markov chains. Intuitively; a semi-CRF on an input sequence xoutputs a “segmentation” of x; in which labels are assigned to segments (ie; subsequences)of x rather than to individual elements xi of x. Importantly; features for semi-CRFs canmeasure properties of segments; and transitions within a segment can be non-Markovian. Inspite of this additional power; exact learning and inference algorithms for semi-CRFs arepolynomial-time—often only a small constant factor slower than conventional CRFs. Inexperiments on five named entity recognition problems; semi-CRFs generally outperformconventional CRFs.,Advances in neural information processing systems,2005,617
Integrating association rule mining with relational database systems: Alternatives and implications,Sunita Sarawagi; Shiby Thomas; Rakesh Agrawal,Abstract Data mining on large data warehouses is becoming increasingly important. Insupport of this trend; we consider a spectrum of architectural alternatives for coupling miningwith database systems. These alternatives include: loose-coupling through a SQL cursorinterface; encapsulation of a mining algorithm in a stored procedure; caching the data to afile system on-the-fly and mining; tight-coupling using primarily user-defined functions; andSQL implementations for processing in the DBMS. We comprehensively study the option ofexpressing the mining algorithm in the form of SQL queries using Association rule mining asa case in point. We consider four options in SQL-92 and six options in SQL enhanced withobject-relational extensions (SQL-OR). Our evaluation of the different architecturalalternatives shows that from a performance perspective; the Cache-Mine option is …,Acm Sigmod Record,1998,550
Discriminative methods for multi-labeled classification,Shantanu Godbole; Sunita Sarawagi,Abstract In this paper we present methods of enhancing existing discriminative classifiers formulti-labeled predictions. Discriminative methods like support vector machines perform verywell for uni-labeled text classification tasks. Multi-labeled classification is a harder tasksubject to relatively less attention. In the multi-labeled setting; classes are often related toeach other or part of a is-a hierarchy. We present a new technique for combining textfeatures and features indicating relationships between classes; which can be used with anydiscriminative algorithm. We also present two enhancements to the margin of SVMs forbuilding better models in the presence of overlapping classes. We present results ofexperiments on real world text benchmark datasets. Our new methods beat accuracy ofexisting methods with statistically significant improvements.,Pacific-Asia conference on knowledge discovery and data mining,2004,536
Discovery-driven exploration of OLAP data cubes,Sunita Sarawagi; Rakesh Agrawal; Nimrod Megiddo,Abstract Analysts predominantly use OLAP data cubes to identify regions of anomalies thatmay represent problem areas or new opportunities. The current OLAP systems supporthypothesis-driven exploration of data cubes through operations such as drill-down; roll-up;and selection. Using these operations; an analyst navigates unaided through a huge searchspace looking at large number of values to spot exceptions. We propose a new discovery-driven exploration paradigm that mines the data for such exceptions and summarizes theexceptions at appropriate levels in advance. It then uses these exceptions to lead theanalyst to interesting regions of the cube during navigation. We present the statisticalfoundation underlying our approach. We then discuss the computational issue of findingexceptions in data and making the process efficient on large multidimensional data bases.,International Conference on Extending Database Technology,1998,423
Efficient set joins on similarity predicates,Sunita Sarawagi; Alok Kirpal,Abstract In this paper we present an efficient; scalable and general algorithm for performingset joins on predicates involving various similarity measures like intersect size; Jaccard-coefficient; cosine similarity; and edit-distance. This expands the existing suite of algorithmsfor set joins on simpler predicates such as; set containment; equality and non-zero overlap.We start with a basic inverted index based probing method and add a sequence ofoptimizations that result in one to two orders of magnitude improvement in running time. Thealgorithm folds in a data partitioning strategy that can work efficiently with an indexcompressed to fit in any available amount of main memory. The optimizations used in ouralgorithm generalize to several weighted and unweighted measures of partial word overlapbetween sets.,Proceedings of the 2004 ACM SIGMOD international conference on Management of data,2004,380
Efficient organization of large multidimensional arrays,Sunita Sarawagi; Michael Stonebraker,Large multidimensional arrays are widely used in scientific and engineering databaseapplications. The authors present methods of organizing arrays to make their access onsecondary and tertiary memory devices fast and efficient. They have developed fourtechniques for doing this:(1) storing the array in multidimensional" chunks" to minimize thenumber of blocks fetched;(2) reordering the chunked array to minimize seek distancebetween accessed blocks;(3) maintaining redundant copies of the array; each organized fora different chunk size and ordering and (4) partitioning the array onto platters of a tertiarymemory device so as to minimize the number of platter switches. The measurements on realdata obtained from global change scientists show that accesses on arrays organized usingthese techniques are often an order of magnitude faster than on the unoptimized data.,Data Engineering; 1994. Proceedings. 10th International Conference,1994,344
Automatic segmentation of text into structured records,Vinayak Borkar; Kaustubh Deshmukh; Sunita Sarawagi,Abstract In this paper we present a method for automatically segmenting unformatted textrecords into structured elements. Several useful data sources today are human-generatedas continuous text whereas convenient usage requires the data to be organized asstructured records. A prime motivation is the warehouse address cleaning problem oftransforming dirty addresses stored in large corporate databases as a single text field intosubfields like “City” and “Street”. Existing tools rely on hand-tuned; domain-specific rule-based systems. We describe a tool DATAMOLD that learns to automatically extract structurewhen seeded with a small number of training examples. The tool enhances on HiddenMarkov Models (HMM) to build a powerful probabilistic model that corroborates multiplesources of information including; the sequence of elements; their length distribution …,ACM SIGMOD Record,2001,337
Record linkage: similarity measures and algorithms,Nick Koudas; Sunita Sarawagi; Divesh Srivastava,Abstract This tutorial provides a comprehensive and cohesive overview of the key researchresults in the area of record linkage methodologies and algorithms for identifyingapproximate duplicate records; and available tools for this purpose. It encompassestechniques introduced in several communities including databases; information retrieval;statistics and machine learning. It aims to identify similarities and differences across thetechniques as well as their merits and limitations.,Proceedings of the 2006 ACM SIGMOD international conference on Management of data,2006,286
Exploiting dictionaries in named entity extraction: combining semi-markov extraction processes and data integration methods,William W Cohen; Sunita Sarawagi,Abstract We consider the problem of improving named entity recognition (NER) systems byusing external dictionaries---more specifically; the problem of extending state-of-the-art NERsystems by incorporating information about the similarity of extracted entities to entities in anexternal dictionary. This is difficult because most high-performance named entity recognitionsystems operate by sequentially classifying words as to whether or not they participate in anentity name; however; the most useful similarity measures score entire candidate names. Tocorrect this mismatch we formalize a semi-Markov extraction process; which is based onsequentially classifying segments of several adjacent words; rather than single words. Inaddition to allowing a natural way of coupling high-performance NER methods and high-performance similarity functions; this formalism also allows the direct use of other useful …,Proceedings of the tenth ACM SIGKDD international conference on Knowledge discovery and data mining,2004,283
Annotating and searching web tables using entities; types and relationships,Girija Limaye; Sunita Sarawagi; Soumen Chakrabarti,Abstract Tables are a universal idiom to present relational data. Billions of tables on Webpages express entity references; attributes and relationships. This representation ofrelational world knowledge is usually considerably better than completely unstructured; free-format text. At the same time; unlike manually-created knowledge bases; relationalinformation mined from" organic" Web tables need not be constrained by availability ofprecious editorial time. Unfortunately; in the absence of any formal; uniform schemaimposed on Web tables; Web search cannot take advantage of these high-quality sources ofrelational information. In this paper we propose new machine learning techniques toannotate table cells with entities that they likely mention; table columns with types fromwhich entities are drawn for cells in the column; and relations that pairs of table columns …,Proceedings of the VLDB Endowment,2010,239
Mining surprising patterns using temporal description length,Soumen Chakrabarti; Sunita Sarawagi; Byron Dom,Abstract We propose a new notion of surprising temporal patterns in market basket data; andalgorithms to nd such patterns. This is distinct from nding frequent patterns as addressed inthe common mining literature. We argue that once the analyst is already familiar withprevalent patterns in the data; the greatest incremental bene t is likely to be from changes inthe relationship between item frequencies over time. A simple measure of surprise is theextent of departure from a model; estimated using standard multivariate time series analysis.Unfortunately; such estimation involves models; smoothing windows and parameters whoseoptimal choices can vary dramatically from one application to another. In contrast; wepropose a precise characterization of surprise based on the number of bits in which a basketsequence can be encoded under a carefully chosen coding scheme. In this scheme it is …,VLDB,1998,172
The Claremont report on database research,Rakesh Agrawal; Anastasia Ailamaki; Philip A Bernstein; Eric A Brewer; Michael J Carey; Surajit Chaudhuri; AnHai Doan; Daniela Florescu; Michael J Franklin; Hector Garcia-Molina; Johannes Gehrke; Le Gruenwald; Laura M Haas; Alon Y Halevy; Joseph M Hellerstein; Yannis E Ioannidis; Hank F Korth; Donald Kossmann; Samuel Madden; Roger Magoulas; Beng Chin Ooi; Tim O'Reilly; Raghu Ramakrishnan; Sunita Sarawagi; Michael Stonebraker; Alexander S Szalay; Gerhard Weikum,Abstract In late May; 2008; a group of database researchers; architects; users and punditsmet at the Claremont Resort in Berkeley; California to discuss the state of the research fieldand its impacts on practice. This was the seventh meeting of this sort in twenty years; andwas distinguished by a broad consensus that we are at a turning point in the history of thefield; due both to an explosion of data and usage scenarios; and to major shifts in computinghardware and platforms. Given these forces; we are at a time of opportunity for researchimpact; with an unusually large potential for influential results across computing; thesciences and society. This report details that discussion; and highlights the group'sconsensus view of new focus areas; including new database engine architectures;declarative programming languages; the interplay of structured and unstructured data …,ACM Sigmod Record,2008,163
Creating probabilistic databases from information extraction models,Rahul Gupta; Sunita Sarawagi,ABSTRACT w ny re lElife ppli tions depend on dt ses utom tiE lly ur ted from unstru turedsour es through imperfe t stru ture extr tion toolsF uhdt ses re est tre ted s impre ise representtions of multiple extr tion possi iliE tiesF t teEofEtheE rt st tisti l models of extr tion providesound pro ility distri ution over extr tions ut re not e sy to represent nd query in rel tion l frmeworkF sn this p per we ddress the h llenge of pproxim ting su h distri utions s impre ise dtmodelsF sn p rti ul rD we inE vestig te model th t ptures oth rowElevel nd olumnE level un ertinty nd show th t this represent tion provides signi ntly etter pproxim tion omp red to modelsth t use only row or only olumn level un ert intyF e present efE ient lgorithms for nding the estpproxim ting pr mE eters for su h modelY our lgorithm exploits the stru ture of the model tovoid enumer ting the exponenti l num er of extr tion possi ilitiesF,VLDB,2006,156
Indexing OLAP data,Sunita Sarawagi,Abstract In this paper we discuss indexing methods for On-Line Analytical Processing(OLAP) databases. We start with a survey of existing indexing methods and discuss theiradvantages and shortcomings. We then propose extensions to conventionalmultidimensional indexing methods to make them more suitable for indexing OLAP data. Wecompare and contrast R-trees with bit-mapped indices which is the most popular choice forindexing OLAP data today.,IEEE Data Eng. Bull.,1997,155
Explaining differences in multidimensional aggregates,Sunita Sarawagi,Abstract Our goal is to enhance multidimensional database systems with advanced miningprimitives. Current Online Analytical Processing (OLAP) products provide a minimal set ofbasic aggregate operators like sum and average and a set of basic navigational operatorslike drill-downs and roll-ups. These operators have to be driven entirely by the analyst'sintuition. Such ad hoc exploration gets tedious and error-prone as data dimensionality andsize increases. In earlier work we presented one such advanced primitive where wepremined OLAP data for exceptions; summarized the exceptions at appropriate levels; andused them to lead the analyst to the interesting regions. In this paper we present a secondenhancement: a single operator that lets the analyst get summarized reasons for drops orincreases observed at an aggregated level. This eliminates the need to manually drill …,VLDB,1999,143
Discovery-driven exploration of OLAP data cubes,*,A method for locating data anomalies in ak dimensional data cube that includes the steps ofassociating a surprise value with each cell of a data cube; and indicating a data anomalywhen the surprise value associated with a cell exceeds a predetermined exceptionthreshold. According to one aspect of the invention; the surprise value associated with eachcell is a composite value that is based on at least one of a Self-Exp value for the cell; an In-Exp value for the cell and a Path-Exp value for the cell. Preferably; the step of associatingthe surprise value with each cell includes the steps of determining a Self-Exp value for thecell; determining an In-Exp value for the cell; determining a Path-Exp value for the cell; andthen generating the surprise value for the cell based on the Self-Exp value; the In-Exp valueand the Path-value.,*,2000,141
On computing the data cube,Sunita Sarawagi,国立情報学研究所による学協会向け論文電子化・公開サービス (NII-ELS) の終了にともない;利用者のみなさまにご不便をおかけしておりますことをお詫び申し上げます.本件について;学協会ならびに契約機関等に向けては周知に努めて参りましたが; 利用者のみなさまに対する事前のご案内が行き届かず; ご心配をおかけしていることについても重ねてお詫び申し上げます.,Research Report RH10026,1996,137
Functional sites in protein families uncovered via an objective and automated graph theoretic approach,Pramod P Wangikar; Ashish V Tendulkar; S Ramya; Deepali N Mali; Sunita Sarawagi,Abstract We report a method for detection of recurring side-chain patterns (DRESPAT) usingan unbiased and automated graph theoretic approach. We first list all structural patterns assub-graphs where the protein is represented as a graph. The patterns from proteins arecompared pair-wise to detect patterns common to a protein pair based on content andgeometry criteria. The recurring pattern is then detected using an automated searchalgorithm from the all-against-all pair-wise comparison data of proteins. Intra-protein patterncomparison data are used to enable detection of patterns recurring within a protein. Amethod has been proposed for empirical calculation of statistical significance of recurringpattern. The method was tested on 17 protein sets of varying size; composed of non-redundant representatives from SCOP superfamilies. Recurring patterns in serine …,Journal of molecular biology,2003,129
Integrating unstructured data into relational databases,Imran R Mansuri; Sunita Sarawagi,In this paper we present a system for automatically integrating unstructured text into a multi-relational database using state-of-the-art statistical models for structure extraction andmatching. We show how to extend current highperforming models; Conditional RandomFields and their semi-markov counterparts; to effectively exploit a variety of recognition cluesavailable in a database of entities; thereby significantly reducing the dependence onmanually labeled training data. Our system is designed to load unstructured records intocolumns spread across multiple tables in the database while resolving the relationship of theextracted text with existing column values; and preserving the cardinality and link constraintsof the database. We show how to combine the inference algorithms of statistical models withthe database imposed constraints for optimal data integration.,Data Engineering; 2006. ICDE'06. Proceedings of the 22nd International Conference on,2006,128
User-adaptive exploration of multidimensional data,Sunita Sarawagi,Abstract In this paper we present a tool for enhanced exploration of OLAP data that isadaptive to a user's prior knowledge of the data. The tool continuously keeps track of theparts of the cube that a user has visited. The information in these scattered visited parts ofthe cube is pieced together to form a model of the user's expected values in the unvisitedparts. The mathematical foundation for this modeling is provided by the classical MaximumEntropy principle. At any time; the user can query for the most surprising unvisited parts ofthe cube. The most surprising values are defined as those which if known to the user wouldbring the new expected values closest to the actual values. This process of updating theuser's context based on visited parts and querying for regions to explore further continues ina loop until the user's mental model perfectly matches the actual cube. We believe and …,VLDB,2000,126
Database system and method employing data cube operator for group-by operations,*,Disclosed is a system and method for performing database queries including GROUP-BYoperations; in which aggregate values for attributes are desired for distinct; partitionedsubsets of tuples satisfying a query. A special case of the aggregation problem is addressed;employing a structure; called the data cube operator; which provides information useful forexpediting execution of GROUP-BY operations in queries. Algorithms are provided forconstructing the data cube by efficiently computing a collection of GROUP-BYs on theattributes of the relation. Decision support systems often require computation of multipleGROUP-BY operations on a given set of attributes; the GROUP-BYs being related in thesense that their attributes are subsets or supersets of each other. The invention extendshash-based and sort-based grouping methods with optimizations; including combining …,*,1998,123
Answering table augmentation queries from unstructured lists on the web,Rahul Gupta; Sunita Sarawagi,Abstract We present the design of a system for assembling a table from a few example rowsby harnessing the huge corpus of information-rich but unstructured lists on the web. Wedeveloped a totally unsupervised end to end approach which given the sample query rows---(a) retrieves HTML lists relevant to the query from a pre-indexed crawl of web lists;(b)segments the list records and maps the segments to the query schema using a statisticalmodel;(c) consolidates the results from multiple lists into a unified merged table;(d) andpresents to the user the consolidated records ranked by their estimated membership in thetarget relation. The key challenges in this task include construction of new rows from veryfew examples; and an abundance of noisy and irrelevant lists that swamp the consolidationand ranking of rows. We propose modifications to statistical record segmentation models …,Proceedings of the VLDB Endowment,2009,113
Integrating association rule mining with relational database systems: Alternatives and implications,Sunita Sarawagi; Shiby Thomas; Rakesh Agrawal,Abstract Data mining on large data warehouses is becoming increasingly important. Insupport of this trend; we consider a spectrum of architectural alternatives for coupling miningwith database systems. These alternatives include: loose-coupling through a SQL cursorinterface; encapsulation of a mining algorithm in a stored procedure; caching the data to afile system on-the-fly and mining; tight-coupling using primarily user-defined functions; andSQL implementations for processing in the DBMS. We comprehensively study the option ofexpressing the mining algorithm in the form of SQL queries using Association rule mining asa case in point. We consider four options in SQL-92 and six options in SQL enhanced withobject-relational extensions (SQL-OR). Our evaluation of the different architecturalalternatives shows that from a performance perspective; the Cache option is superior …,Data mining and knowledge discovery,2000,113
Intelligent rollups in multidimensional OLAP data,Gayatri Sathe; Sunita Sarawagi,Abstract In this paper we propose a new operator for advanced exploration of largemultidimensional databases. The proposed operator can automatically generalize from aspecific problem case in detailed data and return the broadest context in which the problemoccurs. Such a functionality would be useful to an analyst who after observing a problemcase; say a drop in sales for a product in a store; would like to find the exact scope of theproblem. With existing tools he would have to manually search around the problem tupletrying to draw a pattern. This process is both tedious and imprecise. Our proposed operatorcan automate these manual steps and return in a single step a compact and easy-to-interpret summary of all possible maximal generalizations along various roll-up pathsaround the case. We present a flexible cost-based framework that can generalize various …,VLDB,2001,111
System and method for organizing repositories of semi-structured documents such as email,*,A user can easily organize computerized document folders by associating a few sampledocuments in the document database with each folder. The present invention learns folderprofiles based on the sample documents and moves the remaining documents into thefolders accordingly. In this way; the user can construct new folders; or rearrange existingfolders; or cause the computer to automatically rearrange and maintain the folders. This isparticularly useful for managing a database of perhaps thousands of emails.,*,2003,110
The Claremont report on database research,Rakesh Agrawal; Anastasia Ailamaki; Philip A Bernstein; Eric A Brewer; Michael J Carey; Surajit Chaudhuri; Anhai Doan; Daniela Florescu; Michael J Franklin; Hector Garcia-Molina; Johannes Gehrke; Le Gruenwald; Laura M Haas; Alon Y Halevy; Joseph M Hellerstein; Yannis E Ioannidis; Hank F Korth; Donald Kossmann; Samuel Madden; Roger Magoulas; Beng Chin Ooi; Tim O'Reilly; Raghu Ramakrishnan; Sunita Sarawagi; Michael Stonebraker; Alexander S Szalay; Gerhard Weikum,Here; we explore the conclusions of this self-assessment. It is by definition somewhatinward-focused but may be of interest to the broader computing community as both a windowinto upcoming directions in database research and a description of some of the community issuesand initiatives that surfaced. We describe the group's consensus view of new focus areas forresearch; including database engine architectures; declarative programming languages; interplayof structured data and free text; cloud data services; and mobile and virtual worlds. We also reporton discussions of the database community's growth and processes that may be of interest toother research areas facing similar challenges … Over the past 20 years; small groups of databaseresearchers have periodically gathered to assess the state of the field and propose directionsfor future research. 1;3;4;5;6;7 Reports of the meetings served to foster debate within the …,Communications of the ACM,2009,100
Domain adaptation of conditional probability models via feature subsetting,Sandeepkumar Satpal; Sunita Sarawagi,Abstract The goal in domain adaptation is to train a model using labeled data sampled froma domain different from the target domain on which the model will be deployed. We exploitunlabeled data from the target domain to train a model that maximizes likelihood over thetraining sample while minimizing the distance between the training and target distribution.Our focus is conditional probability models used for predicting a label structure y given inputx based on features defined jointly over x and y. We propose practical measures ofdivergence between the two domains based on which we penalize features with largedivergence; while improving the effectiveness of other less deviant correlated features.Empirical evaluation on several real-life information extraction tasks using ConditionalRandom Fields (CRFs) show that our method of domain adaptation leads to significant …,European Conference on Principles of Data Mining and Knowledge Discovery,2007,98
Mining Generalized Association Rules and Sequential Patterns Using SQL Queries.,Shiby Thomas; Sunita Sarawagi,Abstract Database integration of mining is becoming increasingly important with tileinstallation of larger and larger data warehouses built around relational databasetechnology. Most of the commercially available mining systems integrate loosely (typically;through an ODBC or SQL cursor interface) with data stored in DBMSs. In cases where themining algorithm makes nmltiple passes over the data; it is also possible to cache the data infiat files rather than retrieve multiple times from the DBMS; to achieve better performance.Recent studies have found that for association rule mining; with carefully tuned SQLforinulations it is possible to achieve performance comparable to systems that cache thedata in files outside the DBMS. The SQL implementation has potential for offering otherqualitaUve advantages like automatic parallehzation; development ease; portability and …,KDD,1998,97
Integrated database and data-mining system,*,A method and apparatus for mining data relationships from an integrated database and data-mining system are disclosed. A set of frequent 1-itemsets is generated using a group-byquery on data transactions. From these frequent 1-itemsets and the transactions; frequent 2-itemsets are determined. A candidate set of (n+ 2)-itemsets are generated from the frequent2-itemsets; where n= 1. Frequent (n+ 2)-itemsets are determined from candidate set and thetransaction table using a query operation. The candidate set and frequent (n+ 2)-itemset aregenerated for (n+ 1) until the candidate set is empty. Rules are then extracted from the unionof the determined frequent itemsets.,*,2001,93
System and method for mining surprising temporal patterns,*,A system and method for data mining is provided in which temporal patterns of itemsets intransactions having unexpected support values are identified. A surprising temporal patternis an itemset whose support changes over time. The method may use a minimum descriptionlength formulation to discover these surprising temporal patterns.,*,2001,85
Efficient batch top-k search for dictionary-based entity recognition,Amit Chandel; PC Nagesh; Sunita Sarawagi,We consider the problem of speeding up Entity Recognition systems that exploit existinglarge databases of structured entities to improve extraction accuracy. These systems requirethe computation of the maximum similarity scores of several overlapping segments of theinput text with the entity database. We formulate a Batch-Top-K problem with the goal ofsharing computations across overlapping segments. Our proposed algorithm performs afactor of three faster than independent Top-K queries and only a factor of two slower than anunachievable lower bound on total cost. We then propose a novel modification of thepopular Viterbi algorithm for recognizing entities so as to work with easily computablebounds on match scores; thereby reducing the total inference time by a factor of eightcompared to stateof-the-art methods.,Data Engineering; 2006. ICDE'06. Proceedings of the 22nd International Conference on,2006,84
Query processing in tertiary memory databases,Sunita Sarawagi,Abstract Wit; 11 rapid increase in the number of applications thal; require access to largeamounts of da; ta.; it is becoming increasingly important for tla. ta. l~ aac syst; ems t; o ha.ndle tert; ia. ry storage dcviccs. The cha. ra. ctcristics of tertia. ry memory devices a. re verydiffer& from secondary storag; c devices that; conventional database sysletr~ a. re designedfor. This requires new approa. ches to ma. naging data; loca. tion and movcmcnt; togetherwith query execution in a unilied framework. In this paper WC present methods ofscheduling queries; caching and controlling the order of da. ta; rct; rieva. l for eff~-c&1.operation in a tertia. ry rncniory cnvironnienl. Wc show how careful interspersing of queriesand informed cache management can achieve rema. rkable reductions in access timecompared 1x1 conventional methods. Our algoril (hms use a few model pa. rameters for …,VLDB,1995,78
Scaling multi-class support vector machines using inter-class confusion,Shantanu Godbole; Sunita Sarawagi; Soumen Chakrabarti,Abstract Support vector machines (SVMs) excel at two-class discriminative learningproblems. They often outperform generative classifiers; especially those that use inaccurategenerative models; such as the naïve Bayes (NB) classifier. On the other hand; generativeclassifiers have no trouble in handling an arbitrary number of classes efficiently; and NBclassifiers train much faster than SVMs owing to their extreme simplicity. In contrast; SVMshandle multi-class problems by learning redundant yes/no (one-vs-others) classifiers foreach class; further worsening the performance gap. We propose a new technique for multi-way classification which exploits the accuracy of SVMs and the speed of NB classifiers. Wefirst use a NB classifier to quickly compute a confusion matrix; which is used to reduce thenumber and complexity of the two-class SVMs that are built in the second stage. During …,Proceedings of the eighth ACM SIGKDD international conference on Knowledge discovery and data mining,2002,65
Cross-training: learning probabilistic mappings between topics,Sunita Sarawagi; Soumen Chakrabarti; Shantanu Godbole,Abstract Classification is a well-established operation in text mining. Given a set of labels Aand a set DA of training documents tagged with these labels; a classifier learns to assignlabels to unlabeled test documents. Suppose we also had available a different set of labelsB; together with a set of documents DB marked with labels from B. If A and B have somesemantic overlap; can the availability of DB help us build a better classifier for A; and viceversa? We answer this question in the affirmative by proposing cross-training: a newapproach to semi-supervised learning in presence of multiple label sets. We givedistributional and discriminative algorithms for cross-training and show; through extensiveexperiments; that cross-training can discover and exploit probabilistic relations between twotaxonomies for more accurate classification.,Proceedings of the ninth ACM SIGKDD international conference on Knowledge discovery and data mining,2003,58
Efficient inference with cardinality-based clique potentials,Rahul Gupta; Ajit A Diwan; Sunita Sarawagi,Abstract Many collective labeling tasks require inference on graphical models where theclique potentials depend only on the number of nodes that get a particular label. We designefficient inference algorithms for various families of such potentials. Our algorithms are exactfor arbitrary cardinality-based clique potentials on binary labels and for max-like andmajority-like clique potentials on multiple labels. Moving towards more complex potentials;we show that inference becomes NP-hard even on cliques with homogeneous Pottspotentials. We present a 13/15-approximation algorithm with runtime sub-quadratic in theclique size. In contrast; the best known previous guarantee for graphs with Potts potentials isonly 0.5. We perform empirical comparisons on real and synthetic data; and show that ourproposed methods are an order of magnitude faster than the well-known Tree-based re …,Proceedings of the 24th international conference on Machine learning,2007,57
Document classification through interactive supervision of document and term labels,Shantanu Godbole; Abhay Harpale; Sunita Sarawagi; Soumen Chakrabarti,Abstract Effective incorporation of human expertise; while exerting a low cognitive load; is acritical aspect of real-life text classification applications that is not adequately addressed bybatch-supervised high-accuracy learners. Standard text classifiers are supervised in onlyone way: assigning labels to whole documents. They are thus deprived of the enormouswisdom that humans carry about the significance of words and phrases in context. Wepresent HIClass; an interactive and exploratory labeling package that actively collects useropinion on feature representations and choices; as well as whole-document labels; whileminimizing redundancy in the input sought. Preliminary experience suggests that; startingwith essentially an unlabeled corpus; very little cognitive labor suffices to set up a labeledcollection on which standard classifiers perform well.,European Conference on Principles of Data Mining and Knowledge Discovery,2004,57
Answering table queries on the web using column keywords,Rakesh Pimplikar; Sunita Sarawagi,Abstract We present the design of a structured search engine which returns a multi-columntable in response to a query consisting of keywords describing each of its columns. Weanswer such queries by exploiting the millions of tables on the Web because these aremuch richer sources of structured knowledge than free-format text. However; a corpus oftables harvested from arbitrary HTML web pages presents huge challenges of diversity andredundancy not seen in centrally edited knowledge bases. We concentrate on one concretetask in this paper. Given a set of Web tables T 1;...; T n; and a query Q with q sets ofkeywords Q 1;...; Q q; decide for each T i if it is relevant to Q and if so; identify the mappingbetween the columns of T i and query columns. We represent this task as a graphical modelthat jointly maps all tables by incorporating diverse sources of clues spanning matches in …,Proceedings of the VLDB Endowment,2012,54
Automation in information extraction and integration,Sunita Sarawagi,Page 1. Automation in Information Extraction and Integration Sunita Sarawagi IIT Bombaysunita@it.iitb.ac.in Page 2. ¡¢£¤¥ Data integration The process of integrating data from multiple;heterogeneous; loosely structured information sources into a single well-defined structureddatabase A tedious exercise involving schema mapping; structure/information extraction;duplicate elimination; missing value substitution; error detection standardization Page 3. ¡¢£¤¥Application scenarios Large enterprises: Phenomenal amount of time and resources spenton data cleaning Example: Segmenting and merging name-address lists during datawarehousing Web: Creating structured databases from distributed unstructured web-pagesCitation databases: Citeseer and Cora Other scientific applications Bio-informatics Extractinggene relations from medical text (KDD cup 2002) Page 4. ¡¢£¤¥ …,Tutorial of The 28th International Conference on Very Large Data Bases (VLDB),2002,50
Automatically extracting structure from free text addresses,Vinayak R.  Borkar; Kaustubh Deshmukh; Sunita Sarawagi,Abstract In this paper we present a novel way to automatically elementize postal addressesseen as a plain text string into atomic structured elements like” City” and” Street name”. Thisis an essential step in all warehouse data cleaning activities. In spite of the practicalimportance of the problem and the technical challenges it offers; research effort on the topichas been limited. Existing commercial approaches are based on hand-tuned; rule-basedapproaches that are brittle and require extensive manual effort when moved to a differentpostal system. We present a Hidden Markov Model based approach that can work with justabout any address domain when seeded with a small training data set. Experiments on real-life datasets yield accuracy of 89% on a heterogeneous nationwide database of Indianpostal addresses and 99.6% on US addresses that tend to be more templatized.,IEEE Data Eng. Bull.,2000,47
Data mining models as services on the internet,Sunita Sarawagi; Sree Hari Nagaralu,ABSTRACT The goal of this article is to raise a debate on the usefulness of providing datamining models as services on the internet. These services can be provided by anyone withadequate data and expertise and made available on the internet for anyone to use. Forinstance; Yahoo or Altavista; given their huge categorized document collection; can train adocument classifier and provide the model as a service on the internet. This way data miningcan be made accessible to a wider audience instead of being limited to people with the dataand the expertise. A host of practical problems need to be solved before this idea can bemade to work. We identify them and close with an invitation for further debate andinvestigation.,ACM SIGKDD Explorations Newsletter,2000,44
Reordering query execution in tertiary memory databases,Sunita Sarawagi; Michael Stonebraker,Abstract In the relational model the order of fetching data does not a ect query correctness.This exibility is exploited in query optimization by statically reordering data accesses.However; once a query is optimized; it is executed in a xed order in most systems; with theresult that data requests are made in a xed order. Only limited forms of runtime reorderingcan be provided by low-level device managers. More aggressive reordering strategies areessential in scenarios where the latency of access to data objects varies widely anddynamically; as in tertiary devices. This paper presents such a strategy. Our key innovationis to exploit dynamic reordering to match execution order to the optimal data fetch order; inall parts of the plan-tree. To demonstrate the practicality of our approach and the impact ofour optimizations; we report on a prototype implementation based on Postgres. Using our …,VLDB,1996,44
Accurate max-margin training for structured output spaces,Sunita Sarawagi; Rahul Gupta,Abstract Tsochantaridis et al.(2005) proposed two formulations for maximum margin trainingof structured spaces: margin scaling and slack scaling. While margin scaling has beenextensively used since it requires the same kind of MAP inference as normal structuredprediction; slack scaling is believed to be more accurate and better-behaved. We present anefficient variational approximation to the slack scaling method that solves its inferencebottleneck while retaining its accuracy advantage over margin scaling. We further argue thatexisting scaling approaches do not separate the true labeling comprehensively whilegenerating violating constraints. We propose a new max-margin trainer PosLearn thatgenerates violators to ensure separation at each position of a decomposable loss function.Empirical results on real datasets illustrate that PosLearn can reduce test error by up to …,Proceedings of the 25th international conference on Machine learning,2008,38
i3: intelligent; interactive investigation of OLAP data cubes,Sunita Sarawagi; Gayatri Sathe,Abstract The goal of the i 3 (eye cube) project is to enhance multidimensional databaseproducts with a suite of advanced operators to automate data analysis tasks that arecurrently handled through manual exploration. Most OLAP products are rather simplistic andrely heavily on the user's intuition to manually drive the discovery process. Such ad hoc user-driven exploration gets tedious and error-prone as data dimensionality and size increases.We first investigated how and why analysts currently explore the data cube and thenautomated them using advanced operators that can be invoked interactively like existingsimple operators.,ACM SIGMOD Record,2000,38
Efficient evaluation of queries with mining predicates,Surajit Chaudhuri; Vivek Narasayya; Sunita Sarawagi,Modern relational database systems are beginning to support ad-hoc queries on datamining models. In this paper; we explore novel techniques for optimizing queries that applymining models to relational data. For such queries; we use the internal structure of themining model to automatically derive traditional database predicates. We present algorithmsfor deriving such predicates for some popular discrete mining models: decision trees; naiveBayes; and clustering. Our experiments on a Microsoft SQL Server 2000 demonstrate thatthese derived predicates can significantly reduce the cost of evaluating such queries.,Data Engineering; 2002. Proceedings. 18th International Conference on,2002,36
Database systems for efficient access to tertiary memory,Sunita Sarawagi,Tertiary storage devices have long been in use for storing massive amounts of data in file-oriented mass storage systems. However; their use in database systems is relatively new.Database systems associate more structure to the data than just raw sequence of bytes.Hence; if they are allowed control of the tertiary memory devices; they can greatly reduceaccess cost by performing informed caching; query optimization; and query scheduling.However; most conventional database systems are designed for data stored on magneticdisks. Accesses to tertiary storage devices are slow and nonuniform compared to secondarystorage devices. Therefore; inclusion of tertiary memory as an active part of the storagehierarchy requires a rethinking of conventional query processing techniques. In this project;our aim is to design a database system that can use its knowledge of the data layout on …,Mass Storage Systems; 1995.'Storage-At the Forefront of Information Infrastructures'; Proceedings of the Fourteenth IEEE Symposium on,1995,35
idiff: Informative summarization of differences in multidimensional aggregates,Sunita Sarawagi,Abstract Multidimensional OLAP products provide an excellent opportunity for integratingmining functionality because of their widespread acceptance as a decision support tool andtheir existing heavy reliance on manual; user-driven analysis. Most OLAP products arerather simplistic and rely heavily on the user's intuition to manually drive the discoveryprocess. Such ad hoc user-driven exploration gets tedious and error-prone as datadimensionality and size increases. Our goal is to automate these manual discoveryprocesses. In this paper we present an example of such automation through a iDiff operatorthat in a single step returns summarized reasons for drops or increases observed at anaggregated level. We formulate this as a problem of summarizing the difference betweentwo multidimensional arrays of real numbers. We develop a general framework for such …,Data Mining and Knowledge Discovery,2001,29
Domain adaptation of information extraction models,Rahul Gupta; Sunita Sarawagi,Abstract Domain adaptation refers to the process of adapting an extraction model trained inone domain to another related domain with only unlabeled data. We present a brief surveyof existing methods of retraining models to best exploit labeled data from a related domain.These approaches that involve expensive model retraining are not practical when a largenumber of new domains have to be handled in an operational setting. We describe ourapproach for adapting record extraction models that exploits the regularity within a domainto jointly label records without retraining any model.,ACM SIGMOD Record,2009,26
Joint training for open-domain extraction on the web: exploiting overlap when supervision is limited,Rahul Gupta; Sunita Sarawagi,Abstract We consider the problem of jointly training structured models for extraction frommultiple web sources whose records enjoy partial content overlap. This has importantapplications in open-domain extraction; eg a user materializing a table of interest frommultiple relevant unstructured sources; or a site like Freebase augmenting an incompleterelation by extracting more rows from web sources. Such applications require extraction overarbitrary domains; so one cannot use a pre-trained extractor or demand a huge labeleddataset. We propose to overcome this lack of supervision by using content overlap acrossthe related web sources. Existing methods of exploiting overlap have been developed undersettings that do not generalize easily to the scale and diversity of overlap seen on Websources. We present an agreement-based learning framework that jointly trains the …,Proceedings of the fourth ACM international conference on Web search and data mining,2011,23
Enhancing Search with Structure.,Soumen Chakrabarti; Sunita Sarawagi; S Sudarshan,Keyword search has traditionally focussed on retrieving documents in ranked order; given simplekey- word queries. Similarly; work on keyword queries on structured data has focussed on retrievingclosely connected pieces of data that together contain given query keywords. In recentyears; there has been a good deal of work that attempts to go beyond the above paradigms;to improve search experience on unstructured textual data as well as on structured or semi-structureddata. In this paper; we survey recent work on adding structure to keyword search; which canbe categorized on three axes: (a) adding structure to unstructured data; (b) adding structure toanswers; and (c) adding structure to queries al- lowing more power than simple keywordqueries; but while avoiding the complexity of elaborate query languages that demand extensiveschema knowledge … Web search and information retrieval (IR) have traditionally …,IEEE Data Eng. Bull.,2010,22
Efficient inference on sequence segmentation models,Sunita Sarawagi,Abstract Sequence segmentation is a flexible and highly accurate mechanism for modelingseveral applications. Inference on segmentation models involves dynamic programmingcomputations that in the worst case can be cubic in the length of a sequence. In contrast;typical sequence labeling models require linear time. We remove this limitation ofsegmentation models vis-a-vis sequential models by designing a succinct representation ofpotentials common across overlapping segments. We exploit such potentials to designefficient inference algorithms that are both analytically shown to have a lower complexityand empirically found to be comparable to sequential models for typical extraction tasks.,Proceedings of the 23rd international conference on Machine learning,2006,21
Open-domain quantity queries on web tables: annotation; response; and consensus models,Sunita Sarawagi; Soumen Chakrabarti,Abstract Over 40% of columns in hundreds of millions of Web tables contain numericquantities. Tables are a richer source of structured knowledge than free text. We harnessWeb tables to answer queries whose target is a quantity with natural variation; such as networth of zuckerburg; battery life of ipad; half life of plutonium; and calories in pizza. Our goalis to respond to such queries with a ranked list of quantity distributions; suitably represented.Apart from the challenges of informal schema and noisy extractions; which have beenknown since tables were used for non-quantity information extraction; we face additionalproblems of noisy number formats; as well as unit specifications that are often contextualand ambiguous. Early" hardening" of extraction decisions at a table level leads to pooraccuracy. Instead; we use a probabilistic context free grammar (PCFG) based unit …,Proceedings of the 20th ACM SIGKDD international conference on Knowledge discovery and data mining,2014,20
Maximum mean discrepancy for class ratio estimation: Convergence bounds and kernel selection,Arun Iyer; Saketha Nath; Sunita Sarawagi,Abstract In recent times; many real world applications have emerged that require estimatesof class ratios in an unlabeled instance collection as opposed to labels of individualinstances in the collection. In this paper we investigate the use of maximum meandiscrepancy (MMD) in a reproducing kernel Hilbert space (RKHS) for estimating such ratios.First; we theoretically analyze the MMD-based estimates. Our analysis establishes that;under some mild conditions; the estimate is statistically consistent. More importantly; itprovides an upper bound on the error in the estimate in terms of intuitive geometricquantities like class separation and data spread. Next; we use the insights obtained from thetheoretical analysis; to propose a novel convex formulation that automatically learns thekernel to be employed in the MMD-based estimation. We design an efficient cutting plane …,International Conference on Machine Learning,2014,20
Proceedings of the ACM SIGKDD International Conference on Knowledge Discovery and Data Mining,Bing Liu; Sunita Sarawagi; Ying Li,Liu; B.; Sarawagi; S.; & Li; Y. (2008). Proceedings of the ACM SIGKDD International Conferenceon Knowledge Discovery and Data Mining: Foreword. Unknown Journal … Proceedings ofthe ACM SIGKDD International Conference on Knowledge Discovery and Data Mining :Foreword. / Liu; Bing; Sarawagi; Sunita; Li; Ying … Liu; B; Sarawagi; S & Li; Y 2008; 'Proceedingsof the ACM SIGKDD International Conference on Knowledge Discovery and Data Mining:Foreword' Unknown Journal … Liu B; Sarawagi S; Li Y. Proceedings of the ACM SIGKDD InternationalConference on Knowledge Discovery and Data Mining: Foreword. Unknown Journal. 2008 …Liu; Bing; Sarawagi; Sunita; Li; Ying / Proceedings of the ACM SIGKDD International Conferenceon Knowledge Discovery and Data Mining : Foreword … Powered by Pure; Scopus & ElsevierFingerprint Engine™ © 2017 Elsevier BV.,Unknown Journal,2008,20
Single query optimization for tertiary memory,Sunita Sarawagi; Michael Stonebraker,Abstract We present query execution strategies that are optimized for the characteristics oftertiary memory devices. Traditional query execution methods are oriented to magnetic diskor main memory and perform poorly on tertiary memory. Our methods use ordering andbatching techniques on the I/O requests to reduce the media switch cost and seek cost onthese devices. Some of our methods are provably optimal and others are shown to besuperior by simulation and cost formula analysis.,University of California at Berkeley; Berkeley; CA,1993,19
Efficient evaluation of queries with mining predicates,*,A method for evaluating a user query on a database having a mining model that classifiesrecords contained in the database into classes when the query comprises at least onemining predicate that refers to a class of database records. An upper envelope is derived forthe class referred to by the mining predicate corresponding to a query that returns a set ofdatabase records that includes all of the database records belonging to the class. The upperenvelope is included in the user query for query evaluation. The method may be practicedduring a preprocessing phase by evaluating the mining model to extract a set of classes ofthe database records and deriving an upper envelope for each class. These upperenvelopes are stored for access during user query evaluation.,*,2008,18
User-cognizant multidimensional analysis,Sunita Sarawagi,Abstract. Our goal is to enhance multidimensional database systems with a suite ofadvanced operators to automate data analysis tasks that are currently handled throughmanual exploration. In this paper; we present a key component of our system thatcharacterizes the information content of a cell based on a user's prior familiarity with thecube and provides a context-sensitive exploration of the cube. There are three mainmodules of this component. A Tracker; that continuously tracks the parts of the cube that auser has visited. A Modeler; that pieces together the information in the visited parts to modelthe user's expected values in the unvisited parts. An Informer; that processes user's queriesabout the most informative unvisited parts of the cube. The mathematical basis for theexpected value modeling is provided by the classical maximum entropy principle …,The VLDB Journal,2001,18
Probabilistic graphical models and their role in databases,Amol Deshpande; Sunita Sarawagi,Abstract Probabilistic graphical models provide a framework for compact representation andefficient reasoning about the joint probability distribution of several interdependentvariables. This is a classical topic with roots in statistical physics. In recent years; spurred byseveral applications in unstructured data integration; sensor networks; image processing;bio-informatics; and code design; the topic has received renewed interest in the machinelearning; data mining; and database communities. Techniques from graphical models havealso been applied to many topics directly of interest to the database community includinginformation extraction; sensor data analysis; imprecise data representation and querying;selectivity estimation for query optimization; and data privacy. As database researchcontinues to expand beyond the confines of traditional enterprise domains; we expect …,Proceedings of the 33rd international conference on very large data bases,2007,16
Numerical Relation Extraction with Minimal Supervision.,Aman Madaan; Ashish Mittal; G Ramakrishnan Mausam; Ganesh Ramakrishnan; Sunita Sarawagi,Abstract We study a novel task of numerical relation extraction with the goal of extractingrelations where one of the arguments is a number or a quantity (eg; atomic number(Aluminium; 13); inflation rate (India; 10.9%)). This task presents peculiar challenges notfound in standard Information Extraction (IE); such as the difficulty of matching numbers indistant supervision and the importance of units. We design two extraction systems thatrequire minimal human supervision per relation:(1) NumberRule; a rule based extractor; and(2) NumberTron; a probabilistic graphical model. We find that both systems dramaticallyoutperform MultiR; a state-of-the-art non-numerical IE model; obtaining up to 25 points F-score improvement.,AAAI,2016,14
Learning to extract information from large websites using sequential models.,VG Vinod Vydiswaran; Sunita Sarawagi,ABSTRACT We propose a new method of information extraction from large websites bylearning the sequence of links that lead to a specific goal page on the website. Sampleapplications include finding computer science publications starting from university rootpages and fetching addresses of companies on a web database. We model the website as agraph on a set of important states chosen via domain knowledge and train a ConditionalRandom Field (CRF) over it. The conditional exponential models of CRFs enable us toexploit a variety of features including keywords and patterns extracted from and aroundhyperlinks and HTML pages and any sequential orderings amongst states. Our techniqueprovides two times better harvest rates than techniques used in generic focused crawlers.,COMAD,2005,14
A few good predictions: selective node labeling in a social network,Gaurish Chaudhari; Vashist Avadhanula; Sunita Sarawagi,Abstract Many social network applications face the following problem: given a network G=(V;E) with labels on a small subset O\subset V of nodes and an optional set of features onnodes and edges; predict the labels of the remaining nodes. Much research has gone intodesigning learning models and inference algorithms for accurate predictions in this setting.However; a core hurdle to any prediction effort is that for many nodes there is insufficientevidence for inferring a label. We propose that instead of focusing on the impossible task ofproviding high accuracy over all nodes; we should focus on selectively making the few nodepredictions which will be correct with high probability. Any selective prediction strategy willrequire that the scores attached to node predictions be well-calibrated. Our evaluationsshow that existing prediction algorithms are poorly calibrated. We propose a new method …,Proceedings of the 7th ACM international conference on Web search and data mining,2014,12
Higher-order graphical models for classification in social and affiliation networks,Elena Zheleva; Lise Getoor; Sunita Sarawagi,Abstract In this work we explore the application of higher-order Markov Random Fields(MRF) to classification in social and affiliation networks. We consider both friendship linksand group membership for inferring hidden attributes in a collective inference framework.We explore different ways of using the social groups as either node features or to constructthe graphical model structure. The bottleneck in applying higher-order MRFs to a domainwith many overlapping large cliques is the complexity of inference which is exponential inthe size of the largest clique. To circumvent the slow inference problem; we borrow recentadvancements in the computer vision community to achieve fast approximate inferenceresults. We provide preliminary results using a dataset from facebook which suggest that ourhigher-order MRF models are capturing the structural dependencies in the networks and …,NIPS Workshop on Networks Across Disciplines: Theory and Applications,2010,12
Resolving citations in a paper repository,Sunita Sarawagi; VG Vydiswaran; Sumana Srinivasan; Kapil Bhudhia,ABSTRACT In this paper; we describe our process of creating a citation graph from a givenrepository of physics publications in LATEX format. The task involved a series of informationextraction; data cleaning; matching and ranking steps. This paper describes the challengeswe faced along the way and the issues involved in resolving them.,ACM SIGKDD Explorations Newsletter,2003,12
Factorizing complex predicates in queries to exploit indexes,Surajit Chaudhuri; Prasanna Ganesan; Sunita Sarawagi,Abstract Decision-support applications generate queries with complex predicates. We showhow the factorization of complex query expressions exposes significant opportunities forexploiting available indexes. We also present a novel idea of relaxing predicates in acomplex condition to create possibilities for factoring. Our algorithms are designed for easyintegration with existing query optimizers and support multiple optimization levels; providingdifferent trade-offs between plan complexity and optimization time.,Proceedings of the 2003 ACM SIGMOD international conference on Management of data,2003,11
Alias: An active learning led interactive deduplication system,Sunita Sarawagi; Anuradha Bhamidipaty; Alok Kirpal; Chandra Mouli,De-duplication is a key operation in integrating data from multiple sources. The goal of theActive Learning Led Interactive Alias Suppression (ALIAS) de-duplication system is toautomate the manual; time consuming process of removing duplicates in large semi-structured lists. The main challenge in this task is defining a robust de-duplication functionthat can capture when two records refer to the same entity in spite of the variousinconsistencies and errors in data. ALIAS automates this task by learning the function fromexamples of duplicates and non-duplicates. Early experience on real-life datasets showedthat the quality of the learnt de-duplication function critically hinges on being able to providea large covering and challenging set of examples that bring out the subtlety of the de-duplication function. Finding such examples is not easy because real-life data often has …,*,2002,11
Discovering structure in the universe of attribute names,Alon Halevy; Natalya Noy; Sunita Sarawagi; Steven Euijong Whang; Xiao Yu,Abstract Recently; search engines have invested significant effort to answering entity--attribute queries from structured data; but have focused mostly on queries for frequentattributes. In parallel; several research efforts have demonstrated that there is a long tail ofattributes; often thousands per class of entities; that are of interest to users. Researchers arebeginning to leverage these new collections of attributes to expand the ontologies thatpower search engines and to recognize entity--attribute queries. Because of the sheernumber of potential attributes; such tasks require us to impose some structure on this longand heavy tail of attributes. This paper introduces the problem of organizing the attributes byexpressing the compositional structure of their names as a rule-based grammar. These rulesoffer a compact and rich semantic interpretation of multi-word attributes; while …,Proceedings of the 25th International Conference on World Wide Web,2016,10
Active evaluation of classifiers on large datasets,Namit Katariya; Arun Iyer; Sunita Sarawagi,The goal of this work is to estimate the accuracy of a classifier on a large unlabeled datasetbased on a small labeled set and a human labeler. We seek to estimate accuracy and selectinstances for labeling in a loop via a continuously refined stratified sampling strategy. Forstratifying data we develop a novel strategy of learning r bit hash functions to preservesimilarity in accuracy values. We show that our algorithm provides better accuracy estimatesthan existing methods for learning distance preserving hash functions. Experiments on awide spectrum of real datasets show that our estimates achieve between 15% and 62%relative reduction in error compared to existing approaches. We show how to performstratified sampling on unlabeled data that is so large that in an interactive setting even asingle sequential scan is impractical. We present an optimal algorithm for performing …,Data Mining (ICDM); 2012 IEEE 12th International Conference on,2012,10
Sequence data mining,Sunita Sarawagi,Summary Many interesting real-life mining applications rely on modeling data as sequencesof discrete multi-attribute records. Existing literature on sequence mining is partitioned onapplication-specific boundaries. In this article we distill the basic operations and techniquesthat are common to these applications. These include conventional mining operations; suchas classification and clustering; and sequence specific operations; such as tagging andsegmentation. We review state-of-the-art techniques for sequential labeling and show howthese apply in two real-life applications arising in address cleaning and informationextraction from websites.,*,2005,10
Models and indices for integrating unstructured data with a relational database,Sunita Sarawagi,Abstract Database systems are islands of structure in a sea of unstructured data sources.Several real-world applications now need to create bridges for smooth integration of semi-structured sources with existing structured databases for seamless querying. This integrationrequires extracting structured column values from the unstructured source and mappingthem to known database entities. Existing methods of data integration do not effectivelyexploit the wealth of information available in multi-relational entities. We present statisticalmodels for co-reference resolution and information extraction in a database setting. We thengo over the performance challenges of training and applying these models efficiently oververy large databases. This requires us to break open a black box statistical model andextract predicates over indexable attributes of the database. We show how to extract such …,International Workshop on Knowledge Discovery in Inductive Databases,2004,10
Mining subjective properties on the web,Immanuel Trummer; Alon Halevy; Hongrae Lee; Sunita Sarawagi; Rahul Gupta,Abstract Even with the recent developments in Web search of answering queries fromstructured data; search engines are still limited to queries with an objective answer; such asEUROPEAN CAPITALS or WOODY ALLEN MOVIES. However; many queries are subjective;such as SAFE CITIES; or CUTE ANIMALS. The underlying knowledge bases of searchengines do not contain answers to these queries because they do not have a ground truth.We describe the Surveyor system that mines the dominant opinion held by authors of Webcontent about whether a subjective property applies to a given entity. The evidence on whichSURVEYOR relies is statements extracted from Web text that either support the property orclaim its negation. The key challenge that SURVEYOR faces is that simply counting thenumber of positive and negative statements does not suffice; because there are multiple …,Proceedings of the 2015 ACM SIGMOD International Conference on Management of Data,2015,9
Efficient top-k count queries over imprecise duplicates,Sunita Sarawagi; Vinay S Deshpande; Sourabh Kasliwal,Abstract We propose efficient techniques for processing various Top-K count queries ondata with noisy duplicates. Our method differs from existing work on duplicate elimination intwo significant ways: First; we dedup on the fly only the part of the data needed for theanswer---a requirement in massive and evolving sources where batch deduplication isexpensive. The non-local nature of the problem of partitioning data into duplicate groups;makes it challenging to filter only those tuples forming the K largest groups. We propose anovel method of successively collapsing and pruning records which yield an order ofmagnitude reduction in running time compared to deduplicating the entire data first. Second;we return multiple high scoring answers to handle situations where it is impossible toresolve if two records are indeed duplicates of each other. Since finding even the highest …,Proceedings of the 12th International Conference on Extending Database Technology: Advances in Database Technology,2009,7
System and method for explaining exceptions in data,*,A system and method for explaining why an exceptional element in a multidimensionaldatabase is exceptional by presenting the element using at least two of the dimensionsresponsible for the exception. Maximal terms are identified in the monolithic equation that isused to identify exceptions; and based on the maximal terms the dimensions that are to bedisplayed are selected as a visual indication of why a displayed element is exceptional.,*,2004,7
Execution reordering for tertiary memory access,Sunita Sarawagi,Abstract In this article we investigate methods of dynamically reordering execution of a queryplan. In existing systems; once a query is optimized; it is executed in a fixed order; with theresult that data requests are made in a fixed order. Only limited forms of runtime reorderingcan be provided by low-level device managers. More aggressive reordering strategies areessential in scenarios where the latency of access to data objects varies widely anddynamically; as in tertiary devices; wide area distributed systems and broadcast disks inmobile computing. In this article we focus on methods of dynamically reordering differentparts of a plan tree to match execution order to the optimal data fetch order. Thesetechniques were developed in the context of a tertiary memory database system but areapplicable to other cases as well. Our prototype implementation based on Postgres yields …,IEEE Data Eng. Bull.,1997,7
Collective inference for extraction mrfs coupled with symmetric clique potentials,Rahul Gupta; Sunita Sarawagi; Ajit A Diwan,Abstract Many structured information extraction tasks employ collective graphical modelsthat capture inter-instance associativity by coupling them with various clique potentials. Wepropose tractable families of such potentials that are invariant under permutations of theirarguments; and call them symmetric clique potentials. We present three families ofsymmetric potentials− MAX; SUM; and MAJORITY.,Journal of Machine Learning Research,2010,6
Extracting predicates from mining models for efficient query evaluation,Surajit Chaudhuri; Vivek Narasayya; Sunita Sarawagi,Abstract Modern relational database systems are beginning to support ad hoc queries onmining models. In this article; we explore novel techniques for optimizing queries thatcontain predicates on the results of application of mining models to relational data. For suchqueries; we use the internal structure of the mining model to automatically derive traditionaldatabase predicates. We present algorithms for deriving such predicates for a large class ofpopular discrete mining models: decision trees; naive Bayes; clustering and linear supportvector machines. Our experiments on Microsoft SQL Server demonstrate that these derivedpredicates can significantly reduce the cost of evaluating such queries.,ACM Transactions on Database Systems (TODS),2004,6
Scaling up the alias duplicate elimination system: a demonstration,Sunita Sarawagi; Alok Kirpal,Abstract Duplicate elimination is an important stage in integrating data from multiplesources. The challenges involved are finding a robust deduplication function that canidentify when two records are duplicates and efficiently applying the function on very largelists of records. In ALIAS the task of designing a deduplication function is eased by learningthe function from examples of duplicates and nonduplicates and by using active learning tospot such examples effectively [1]. Here we investigate the issues involved in efficientlyapplying the learnt deduplication system on large lists of records. We demonstrate theworking of the ALIAS evaluation engine and highlight the optimizations it uses tosignificantly cut down the number of record pairs that need to be explicitly materialized.,PROCEEDINGS OF THE INTERNATIONAL CONFERENCE ON DATA ENGINEERING,2003,6
Efficient organization of large multidimensional,Sunita Sarawagi; Michael Stonebraker,Abstract Large multidimensional arrays are widely used in scientific and engineeringdatabase applications. In this paper; we present methods of organizing arrays to make theiraccess on secondary and tertiary memory devices fast and efficient. We have developedfour techniques for doing this:(1) storing the array in multidimensional" chunks" to minimizethe number of blocks fetched;(2) reordering the chunked array to minimize seek distancebetween accessed blocks;(3) maintaining redundant copies of the array; each organized fora different chunk size and ordering and (4) partitioning the array onto platters of a tertiarymemory device so as to minimize the number of platter switches. Our measurements on realdata sets obtained from global change scientists demonstrate that accesses on arraysorganized using the above techniques are often an order of magnitude faster than on the …,*,1993,6
Answering web questions using structured data: dream or reality?,Fernando Pereira; Anand Rajaraman; Sunita Sarawagi; William Tunstall-Pedoe; Gerhard Weikum; Alon Halevy,Abstract The question of which role structured data can play in Web search has been raisedfrom the early days of the Web. On the one hand; structured data can be used to answerfactual queries. On the other; large amounts of structured data can be used to betterorganize web-content and therefore to improve search on a wide range of queries.,Proceedings of the VLDB Endowment,2009,5
I3: Intelligent; interactive inspection of cubes,Sunita Sarawagi; Gayatri Sathe; Aameek Singh,Multidimensional OLAP products provide an excellent opportunity for integrating miningfunctionality because of their widespread acceptance as a decision support tool and theirexisting heavy reliance on manual; user-driven analysis. Most OLAP products are rathersimplistic and rely heavily on the user's intuition to manually drive the discovery process.Mining technology can play a fitting role in improving the state of these products. Wepropose a suite of extensions in the form of a toolkit attached with a OLAP product that willenable richer; faster answering of queries that are currently handled through manualexploration.,*,2009,4
Text classification with evolving label-sets,Shantanu Godbole; Ganesh Ramakrishnan; Sunita Sarawagi,We introduce the evolving label-set problem encountered in building real-world textclassification systems. This problem arises when a text classification system trained on alabel-set encounters documents of unseen classes at deployment time. We design a class-detector module that monitors unlabeled data; detects new classes; and suggests them tothe administrator for inclusion in the label-set. We propose abstractions that group togethertokens under human understandable concepts and provide a mechanism of assigningimportance to unseen terms. We present generative algorithms leveraging the notion ofsupport of documents in a model for (1) selecting documents of proposed new classes; and(2) automatically triggering detection of new classes. Experiments on three real worldtaxonomies show that our methods select new class documents with high precision; and …,Data Mining; Fifth IEEE International Conference on,2005,4
Cleaning methods in data warehousing,Sunita Sarawagi; TV Raisinghani,*,Online im Internet unter: http://www. it. iitb. ac. in/rvijay/seminar/dwhclean. ps. gz (Stand: 28.07. 2007),1999,4
Length bias in encoder decoder models and a case for global conditioning,Pavel Sountsov; Sunita Sarawagi,Abstract: Encoder-decoder networks are popular for modeling sequences probabilistically inmany applications. These models use the power of the Long Short-Term Memory (LSTM)architecture to capture the full dependence among variables; unlike earlier models likeCRFs that typically assumed conditional independence among non-adjacent variables.However in practice encoder-decoder models exhibit a bias towards short sequences thatsurprisingly gets worse with increasing beam size. In this paper we show that suchphenomenon is due to a discrepancy between the full sequence margin and the per-element margin enforced by the locally conditioned training objective of a encoder-decodermodel. The discrepancy more adversely impacts long sequences; explaining the biastowards predicting short sequences.,arXiv preprint arXiv:1606.03402,2016,3
Learning to extract information from large domain-specific websites using sequential models,Sunita Sarawagi; VG Vydiswaran,Abstract In this article we describe a novel information extraction task on the web and showhow it can be solved effectively using the emerging conditional exponential models. Thetask involves learning to find specific goal pages on large domain-specific websites. Anexample of such a task is to find computer science publications starting from university rootpages. We encode this as a sequential labeling problem solved using Conditional RandomFields (CRFs). These models enable us to exploit a wide variety of features includingkeywords and patterns extracted from and around hyperlinks and HTML pages; dependencyamong labels of adjacent pages; and existing databases of named entities in a unifiedprobabilistic framework. This is an important advantage over previous rule-based orgenerative models for tackling the challenges of diversity on web data.,ACM SIGKDD Explorations Newsletter,2004,3
Sequence data mining techniques and applications,Sunita Sarawagi,Abstract Many interesting real-life mining applications rely on modeling data as sequencesof discrete multi-attribute records. Mining models for network intrusion detection view data assequences of TCP/IP packets. Text information extraction systems model the input text as asequence of words and delimiters. Customer data mining applications profile buying habitsof customers as a sequence of items purchased. In computational biology; DNA; RNA andprotein data are all best modeled as sequences. Classifying; clustering and characterizingsuch sequence data presents interesting issues in feature engineering; discretization andpattern discovery. In this seminar we will review techniques ranging from item set counting;MDL-based discretization and Markov modeling to perform various supervised andunsupervised pattern discovery tasks on sequences. We will present case studies from …,Data Engineering; 2003. Proceedings. 19th International Conference on,2003,3
MAP estimation in Binary MRFs via Bipartite Multi-cuts,Sashank J Reddi; Sunita Sarawagi; Sundar Vishwanathan,Abstract We propose a new LP relaxation for obtaining the MAP assignment of a binary MRFwith pairwise potentials. Our relaxation is derived from reducing the MAP assignmentproblem to an instance of a recently proposed Bipartite Multi-cut problem where the LPrelaxation is guaranteed to provide an O (log k) approximation where k is the number ofvertices adjacent to non-submodular edges in the MRF. We then propose a combinatorialalgorithm to efficiently solve the LP and also provide a lower bound by concurrently solvingits dual to within an ϵ approximation. The algorithm is up to an order of magnitude faster andprovides better MAP scores and bounds than the state of the art message passing algorithmof [1] that tightens the local marginal polytope with third-order marginal constraints.,Advances in Neural Information Processing Systems,2010,2
Queries over Unstructured Data: Probabilistic Methods to the Rescue,Sunita Sarawagi,Abstract Unstructured data like emails; addresses; invoices; call transcripts; reviews; andpress releases are now an integral part of any large enterprise. A challenge of modernbusiness intelligence applications is analyzing and querying data seamlessly acrossstructured and unstructured sources. This requires the development of automatedtechniques for extracting structured records from text sources and resolving entity mentionsin data from various sources. The success of any automated method for extraction andintegration depends on how effectively it unifies diverse clues in the unstructured source andin existing structured databases. We argue that statistical learning techniques likeConditional Random Fields (CRFs) provide a accurate; elegant and principled framework fortackling these tasks. Given the inherent noise in real-world sources; it is important to …,International Workshop on Business Intelligence for the Real-Time Enterprise,2009,2
Generalized collective inference with symmetric clique potentials,Rahul Gupta; Sunita Sarawagi; Ajit A Diwan,Abstract: Collective graphical models exploit inter-instance associative dependence tooutput more accurate labelings. However existing models support very limited kind ofassociativity which restricts accuracy gains. This paper makes two major contributions. First;we propose a general collective inference framework that biases data instances to agree ona set of {\em properties} of their labelings. Agreement is encouraged through symmetricclique potentials. We show that rich properties leads to bigger gains; and present asystematic inference procedure for a large class of such properties. The procedure performsmessage passing on the cluster graph; where property-aware messages are computed withcluster specific algorithms. This provides an inference-only solution for domain adaptation.Our experiments on bibliographic information extraction illustrate significant test error …,arXiv preprint arXiv:0907.0589,2009,2
Knowledge Discovery in Databases: PKDD 2007,JN Kok; J Koronacki; RL de Mántaras; S Matwin; D Mladenic; A Skowron,*,11th European Conference on Principles and Practice of Knowledge Discovery in Databases; Warsaw; Poland,2007,2
MAP estimation in MRFs via rank aggregation,Rahul Gupta; Sunita Sarawagi,Abstract Efficient estimation of the maximum a priori (MAP) assignment in large statisticalrelational networks still remains an open issue in spite of the extensive research in this area.We propose a novel method of exploiting top-K MAP estimates from simpler subgraphs tofind an assignment that is either MAP optimal; or has an associated bound on how far it isfrom the optimal. Our method extends the well-known tree reweighted max-productalgorithm (TRW) and is guaranteed to always provide tighter upper bounds. Experiments onsynthetic and real data show that we are able to the find the optimal in many more casesthan TRW; at significantly fewer iterations and our bounds are much tighter than thoseprovided by TRW.,Proceeding of the ICML Workshop on Learning in Structured Output Spaces,2006,2
Privacy-preserving class ratio estimation,Arun Shankar Iyer; J Saketha Nath; Sunita Sarawagi,Abstract In this paper we present learning models for the class ratio estimation problem;which takes as input an unlabeled set of instances and predicts the proportions of instancesin the set belonging to the different classes. This problem has applications in social andcommercial data analysis. Existing models for class-ratio estimation however requireinstance-level supervision. Whereas in domains like politics; and demography; set-levelsupervision is more common. We present a new method for directly estimating class-ratiosusing set-level supervision. Another serious limitation in applying these techniques tosensitive domains like health is data privacy. We propose a novel label privacy-preservingmechanism that is well-suited for supervised class ratio estimation and has guarantees forachieving efficient differential privacy; provided the per-class counts are large enough …,Proceedings of the 22nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining,2016,1
Data-based research at IIT Bombay,Soumen Chakrabarti; Ganesh Ramakrishnan; Krithi Ramamritham; Sunita Sarawagi; S Sudarshan,The Indian Institute of Technology (IIT) Bombay has a history of research and developmentin the area of databases; dating back to the early 1980s. DB Phatak and NL Sarda wereamong the first faculty members at IIT Bombay to work in the area of database systems. Thiswas a period when the financial sector of India; headquartered primarily in Bombay (nowrenamed Mumbai) saw a spurt in computerization; and IIT Bombay faculty played a leadingrole as consultants for database implementations in these companies. Research in the areaof databases began in the early 1980s; but increased greatly from the early 1990s; with thehiring of several faculty including S. Seshadri; S. Sudarshan; and later Krithi Ramamritham;who moved to IIT Bombay from U. Mass. Amherst in the early to mid 1990s. With the hiring ofSunita Sarawagi and Soumen Chakrabarti in the late 1990s; there was a significant …,ACM SIGMOD Record,2013,1
Label Organized Memory Augmented Neural Network,Shiv Shankar; Sunita Sarawagi,Abstract: We propose a design of memory augmented neural networks (MANNs) calledLabeled Memory Networks (LMNs) suited for tasks requiring online adaptation inclassification models. LMNs organize the memory with classes as the primary key. Thememory acts as a second boosted stage following a regular neural network thereby allowingthe memory and the primary network to play complementary roles. Unlike existing MANNsthat write to memory for every instance and use LRU based memory replacement; LMNswrite only for instances with non-zero loss and use label-based memory replacement. Wedemonstrate significant accuracy gains on various tasks including word-modelling and few-shot learning. Subjects: Learning (cs. LG); Machine Learning (stat. ML) Cite as: arXiv:1707.01461 [cs. LG](or arXiv: 1707.01461 v1 [cs. LG] for this version) Submission history …,arXiv preprint arXiv:1707.01461,2017,*
Occurrence Statistics of Entities; Relations and Types on the Web,Aman Madaan; Sunita Sarawagi,Abstract: The problem of collecting reliable estimates of occurrence of entities on the openweb forms the premise for this report. The models learned for tagging entities cannot beexpected to perform well when deployed on the web. This is owing to the severe mismatchin the distributions of such entities on the web and in the relatively diminutive training data.In this report; we build up the case for maximum mean discrepancy for estimation ofoccurrence statistics of entities on the web; taking a review of named entity disambiguationtechniques and related concepts along the way. Subjects: Computation and Language (cs.CL) Cite as: arXiv: 1605.04359 [cs. CL](or arXiv: 1605.04359 v1 [cs. CL] for this version)Submission history From: Aman Madaan [view email][v1] Sat; 14 May 2016 01: 13: 48 GMT(288kb; D),arXiv preprint arXiv:1605.04359,2016,*
Special issue on best papers of VLDB 2011,Wolfgang Lehner; Sunita Sarawagi,The selection covers a wide spectrum of database systemrelated topics; ranging from queryoptimization to information retrieval and model management. Also; the papers come fromresearch groups all over the world: Redmond; Waterloo; Oxford; Berlin; and Bombay; a trulyinternational mix! All contributions are significantly extended and improved with respect tothe original conference version. We hope you enjoy these “Best of VLDB 2011” papers—may the papers spark novel research ideas!!! The first paper “Efficiently Adapting GraphicalModels for Selectivity Estimation” of this special issue focuses on a classical problem withindatabase query optimization: how to increase the accuracy of a cost model? Sincetraditional query optimization techniques are based on the independence assumption ofindividual columns; even small correlations in the database may results in significant …,The VLDB Journal,2013,*
Supporting database schema evolution represents a long-standing challenge of practical and theoretical importance for modern information systems. In this paper; w...,Wolfgang Lehner; Sunita Sarawagi; Carlo Curino; Hyun Jin Moon; Alin Deutsch; Carlo Zaniolo,In this paper; we present a technique for building a high-availability (HA) databasemanagement system (DBMS). The proposed technique can be applied to any DBMS withlittle or no customization; and with reasonable performance overhead. Our approach isbased on Remus; a commodity HA solution implemented in the virtualization layer; that usesasynchronous virtual machine state replication to provide...,The VLDB Journal,2013,*
Joint Structured Models for Extraction from Overlapping Sources,Rahul Gupta; Sunita Sarawagi,Abstract: We consider the problem of jointly training structured models for extraction fromsources whose instances enjoy partial overlap. This has important applications like user-driven ad-hoc information extraction on the web. Such applications present new challengesin terms of the number of sources and their arbitrary pattern of overlap not seen by earliercollective training schemes applied on two sources. We present an agreement-basedlearning framework and alternatives within it to trade-off tractability; robustness to noise; andextent of agreement. We provide a principled scheme to discover low-noise agreement setsin unlabeled data across the sources. Through extensive experiments over 58 real datasets;we establish that our method of additively rewarding agreement over maximal segments oftext provides the best trade-offs; and also scores over alternatives such as collective …,arXiv preprint arXiv:1005.0104,2010,*
Column Segmentation,Sunita Sarawagi,Query processing algorithms are designed to efficiently exploit the available cache units inthe memory hierarchy. Cache-conscious algorithms typically employ knowledge ofarchitectural parameters such as cache size and latency. This knowledge can be used toensure that the algorithms have good temporal and/or spatial locality on the target platform.,*,2009,*
Querying for relations from the semi-structured Web.,Sunita Sarawagi,Abstract We present a class of web queries whose result is a multi-column relation instead ofa collection of unstructured documents as in standard web search. The user specifies thequery either via a few example records; or a text description of columns of the relation.Starting from this seed; we show how to compile the result from several; possiblyoverlapping; tables and lists on the web. Many challenges arise in the process. First; weneed to be able to extract structured records from HTML pages with little user supervision.We present algorithms for jointly aligning arbitrary record sets on the web with the querytable. We adapt state of the art extraction models like Conditional Random Fields to exploitinter and intra source regularity in a unified framework. Second; we need to be able toconsolidate the results from several sources in the face of missing columns; noisy …,COMAD,2009,*
Foundations and Trends® in Databases,Sunita Sarawagi,*,Foundations and Trends® in Databases,2008,*
Seminar Report Dimensionality Reduction and its Application to Semi-supervised Learning,Nandan Marathe; IIT KReSIT,Abstract The problem of finding a low dimensional structure amongst inputs that have beensampled from high dimensional manifold is known as dimensionality reduction. Whenviewed from a machine learning perspective; it can be directly compared with featureselection. Another way of looking at dimensionality reduction is as a preprocessingmechanism wherein; the data of high dimensionality can be processed; so as to improve theresults that can be attained after applying the standard classification techniques. Eventhough classical methods exist for dimensionality reduction; they fail when presented withsome nonlinear data. Powerful geometric methods have evolved recently to handle suchnon-linear input samples. The report provides an overview of the various methods fordimensionality reduction and looks at the advantages and disadvantages of using them …,*,2006,*
Automatic Extraction of Structured Records From Free Text,Creena Veda; Sunita Sarawagi,*,*,2001,*
ACM SIGKDD Explorations Newsletter Volume 2 Issue 2,Usama Fayyad; Kyuseok Shim; PS Bradley; S Sarawagi,*,*,2000,*
Semistructured Data and XML,Gayatri Sathe; Sunita Sarawagi,*,*,1999,*
Wrappers: Extracting Information from the Web M. Tech. Seminar Report Abhijit Karmarkar Roll No. 99329004,Sunita Sarawagi,*,*,1999,*
Indexing OLAP data,Sunita Sarawagi Ibm; Sunita Sarawagi,Abstract In this paper we discuss indexing methods for On-Line Analytical Processing(OLAP) databases. We start with a survey of existing indexing methods and discuss theiradvantages and shortcomings. We then propose extensions to conventionalmultidimensional indexing methods to make them more suitable for indexing OLAP data. Wecompare and contrast R-trees with bit-mapped indices which is the most popular choice forindexing OLAP data today. 1,Data Engineering Bulletin,1997,*
Query processing in tertiary memory databases,Sunita Sarawagi,The ongoing information explosion calls for an overhaul of conventional database systemsto support the increasing storage demands of many applications. Applications like EOSDIS[DR91a; Sto91b] are estimated to collect around a petabyte of data per year. This amount ofdata cannot be stored cost-e ectively on magnetic disks [SD91; SSU95]. In view ofapplications like EOSDIS and other applications like data warehouses [Ome92]; image[RFJ+93; OS95] and video storage systems [FR94]; there is increasing consensus amongdatabase researchers [SSU95; Sto91a; CHL93; Sel93; Moh93] for supporting tertiarymemory devices [Ran91]. Not only are all these applications huge; they also require e cientquerying and data management facilities; making it necessary to deploy database systemsinstead of relying on conventional le oriented mass storage systems [N+87; C+82]. A …,*,1996,*
Practical methods of Active Learning,Sunita Sarawagi,Abstract In many machine learning applications; labeled data is scarce but unlabeled dataplentiful. However; labeling them requires tedious human supervision. The goal of activelearning [2; 6; 12; 3; 1; 5] is to seek out from the unlabeled pool those instances which whenlabeled will help strengthen the classifier at the fastest possible rate. An active learner startswith a limited labeled and a large unlabeled pool of instances. The labeled set forms thetraining data for an initial preliminary classifier. The active learner then carefully selects afew examples from the unlabeled set and seeks its labels from a user. The newly labeled setis added to the training set and the classifier retrained. The new knowledge is used to selectanother set of unlabeled instance and this continues in a loop until the user is happy with thelearnt classifier. The number of examples required to be manually labeled can reduced …,*,1993,*
Dynamic Model Selection without Prior Meta-learning,Sunita Sarawagi; Shantanu Godbole,Abstract We present a new framework for impromptu selection of the best amongstspecialized classifiers without any synchronized metalearning phase. Such a need wouldarise when classifiers start being shared widely and freely like information on the internet.An ad hoc user will then need to select the best model without any knowledge of the trainingprocess. Typically a one-time user will have just the instance to be classified and noseparate validation dataset. We show how none of the existing model combinationalgorithms meet the demands of impromptu model selection. We propose a novel approachthat relies only on model-neutral information collected dynamically at the time of classifyinga instance. Analytical and experimental evaluation of the method show its superiority toexisting voting schemes on a wide range of settings.,*,*,*
Data Cube: A Relational Aggregation Operator Generalizing Group-By; Cross-Tab; and Sub-Totals,S Sarawagi; S Thomas,Abstract Abstract Data mining on large data warehouses is becoming increasingly important.In support of this trend; we consider a spectrum of architectural alternatives for couplingmining with database systems. These alternatives include: loose-coupling through a SQLcursor interface; encapsulation of a mining algorithm in a stored procedure; caching the datato a _le system on-the-y and mining; tight-coupling using primarily user-defined functions;and SQL implementations for processing in the DBMS. We comprehensively study theoption of expressing the mining algorithm in the form of SQL queries using Association rulemining as a case in point. We consider four options in SQL-92 and six options in SQLenhanced with object-relational extensions (SQL-OR). Our evaluation of the di_erentarchitectural alternatives shows that from a performance perspective; the Cache-Mine …,*,*,*
The Capability Maturity Model [4] is an orderly way for organizations to determine the capabilities of their current processes for developing software and to establish...,Surajit Chaudhuri; Donald Kossmann; Jan Chomicki; Heikki Mannila; Luis Gravano; Arnie Rosenthal; MITRE Ralf Hartmut Güting; Betty Salzberg; Richard Hull; Sunita Sarawagi; Christian S Jensen; Dan Suciu; Hank Korth; Jennifer Widom,*,*,*,*
MAP estimation in Binary MRFs via Bipartite Multi-cuts (Supplementary Material),Sashank J Reddi; Sunita Sarawagi; Sundar Vishwanathan,Figure 1:(a) The graph construction for submodular edges.(b) The graph construction fornonsubmodular edges. Here θij= θij (0; 1)+ θij (1; 0)− θij (0; 0)− θij (1; 1). If the edge issubmodular; θij is non-negative. We have also assumed Θ≥ 0. Hence all the edges in thispart of the graph have non-negative edge weights.,*,*,*
External Referees,Ladjel Bellatreche; Albert Belussi; Chao-Chun Chen; Meng Chen; Yong Chung Chen; Tsong-Min Chen; Wu-Hong Chen; YC Chen; Kajal Claypool; Cheng Hian Goh; Vivekanand Gopalkrishnan; Giovanna Guerrini; Takahiro Hara; Alien JL Hsu; Spot YS Hua; Kamal Karlapalem; Chih-Horng Ke; Joseph Lee; Mong Li Lee; Weifa Liang; Edgar Chia-Han Lin; Yu-lung Lo; M Nakano; Jang Ho Park; Prabhu Ram; P Krishna Reddy; W Retschitzegger; Shazia Sadiq; Wasim Sadiq; Sunita Sarawagi; J Schiefer; Bressan Stephane; Hiroki Takakura; Takayuki Tamura; Arthur ter Hofstede; CY Tsai; Pauray Tsai; Quang Le Viet; Chih-Ping Wei; Yiwen Yin; Haruo Yokota; Jeffrey Xu Yu,*,*,*,*
Program Vice-Chairs,Jeff Naughton; Sunita Sarawagi; Hank Korth; Arnie Rosenthal; Jeff Ullman; Hans Schek; Phil Bernstein; Donald Kossmann; Stavros Christodoulakis; Theo Haerder; Beng Chin Ooi; HV Jagadish; Gerhard Weikum,Page 1. xix Program Vice-Chairs Jeff Naughton; University of Wisconsin; USA Sunita Sarawagi;IBM Almaden; USA Hank Korth; Lucent - Bell Labs; USA Arnie Rosenthal; Mitre; USA Jeff Ullman;Stanford University; USA Hans Schek; ETH Zurich; Switzerland Phil Bernstein; Microsoft; USADonald Kossmann; University of Passau; Germany Stavros Christodoulakis; University of Crete;Greece Theo Haerder; University of Kaiserslautern; Germany Beng Chin Ooi; National Universityof Singapore; Singapore HV Jagadish; University of Illinois at Urbana-Champaign; USA AwardCommittee Members Hank Korth Donald Kossmann Arnie Rosenthal Gerhard Weikum,*,*,*
Semi-Markov Models for Named Entity Recognition,Sunita Sarawagi; William W Cohen; Zhenzhen Kou,Abstract We described semi-Markov models which relaxes usual Markov assumptions madein hidden Markov models. Semi-Markov models classify segments of adjacent words; ratherthan single words. We proposed two training strategies; a discriminative training and agenerative training for semi-Markov models. Importantly; features for semi-Markov modelscan measure properties of segments; and transitions within a segment can be non-Markovian. This formalism can incorporate information about the similarity of extractedentities to entities in an external dictionary. This is difficult because most high-performancenamed entity recognition systems operate by sequentially classifying words as to whether ornot they participate in an entity name; however; the most useful similarity measures scoreentire candidate names. In addition to allowing a natural way of coupling high …,*,*,*
Efficient graphical models for sequence segmentation,Sunita Sarawagi,Abstract Segmentation of sequences is an important modeling primitive with severalapplications. Training and inference of segmentation models involves dynamicprogramming computations that in the worst case can be cubic in the length of a sequence.In contrast; typical sequence labeling models require linear time. We propose an alternativegraphical model for efficient sharing of potentials across overlapping segments. We thendesign message passing algorithms that are significantly faster than the original cubicalgorithms. When segmentation models are posed as large margin structured classificationtasks; our algorithm directly impact the computation of marginals for exponentiated gradienttraining algorithms [1] and modes for cutting plane algorithms [7].,*,*,*
The Challenge is Growing,PS Bradley; Usama Fayyad; S Sarawagi; K Shim,According to recent studies on the tremendous increase in the amount of data recorded andstored on digital media; it is clear that the gap between this digitally stored data and ourability to process it is widening. The primary driver for this phenomenon is the moreaggressive relative of the familiar “Moore's Law”. Moore's Law is the observation thatcomputational power doubles approximately every 18 months. The corresponding law in theworld of digital storage is even more amazing. Storage capacity; for a fixed price; appears tobe doubling approximately every 9 months![1]. In a world governed by these two empiricallaws; the importance of the fields of databases and Data Mining and Knowledge Discoveryare growing. From a strategic perspective; our need to navigate the rapidly growing universeof digital data will rely heavily on our ability to come up with the right systems that can …,*,*,*
Bulletin of the IEEE Computer Society Technical Committee on Data Engineering,Sunita Sarawagi,Abstract In this paper we discuss indexing methods for On-Line Analytical Processing(OLAP) databases. We start with a survey of existing indexing methods and discuss theiradvantages and shortcomings. We then propose extensions to conventionalmultidimensional indexing methods to make them more suitable for indexing OLAP data. Wecompare and contrast R-trees with bit-mapped indices which is the most popular choice forindexing OLAP data today.,*,*,*
Rakesh Agrawal Nimrod Megiddo IBM Research Division Almaden Research Center,Sunita Sarawagi,*,*,*,*
Program Committee Vice Chairs,Daniel Barbara; Tamraparni Dasu; Inderjit Dhillon; Venkatesh Ganti; Bart Goethals; Dimitrios Gunopulos; Hillol Kargupta; George Karypis; S Muthu Muthukrishnan; Dino Pedreschi; Jian Pei; Sunita Sarawagi; Arno Siebes; Jeffrey Xu Yu; Dimitris Achlioptas; Gediminas Adomavicius; Gagan Agarwal; Charu Aggarwal; Eugene Agichtein; Hiroki Arimura; Arindam Banerjee; Francesco Bonchi; Jean-Francois Boulicaut; Paul Bradley; Erick Cantu-Paz; Philip Chan; Kevin Chang; Sanjay Chawla; Hsinchun Chen; Ming-Syan Chen; David Wai-lok Cheung; Chris Clifton; Frans Coenen; Diane Cook; Rob Cooley; Graham Cormode; Honghua Dai; Gautam Das; Chris Ding; Alin Dobra; Carlotta Domeniconi,Program Committee Vice Chairs Daniel Barbara; George Mason University; USA TamraparniDasu; AT&T Research Labs; USA Inderjit Dhillon; University of Texas at Austin; USA VenkateshGanti; Microsoft Research; USA Bart Goethals; University of Antwerp; Belgium DimitriosGunopulos; University of California; Riverside; USA Hillol Kargupta; University of Maryland; BaltimoreCounty & Agnik; LLC; USA George Karypis; University of Minnesota; USA S. MuthuMuthukrishnan; Rutgers University; USA Dino Pedreschi; Univ. of Pisa; Italy Jian Pei; State Universityof New York at Buffalo; USA Sunita Sarawagi; Indian Institute of Technology; Bombay; India ArnoSiebes; Utrecht University; Netherlands Jeffrey Xu Yu; Chinese University of Hong Kong; PRChina … Program Committee Members Dimitris Achlioptas; Microsoft Research; USA GediminasAdomavicius; University of Minnesota; USA Gagan Agarwal; Ohio State University; USA …,*,*,*
Alok Kirpal Guided By: Dr. Sunita Sarawagi,Sunita Sarawagi,*,*,*,*
Mining surprising patterns using temporal,Soumen Chakrabarti; Sunita Sarawagi,Abstract We propose a new notion of surprising temporal patterns in market. basket data;and algorithms to find such pat; terns. This is distinct; from finding frequent pat-terns asaddressed in the common mining literature. We argue that. once the analyst. is alreadyfamiliar with prevalent patterns in t; he data; the greatest; increment; al benefit. is likely t; o befrom changes in the relationship between item frequencies over time.,*,*,*
The POSTGRES User Manual,Jolly Chen Caetta; Ron Choi; Jeffrey Goh; Joey Hellerstein; Wei Hong; Anant Jhingran; Greg Kemnitz; Case Larsen; Jeff Meredith; Michael Olson; Lay-Peng Ong; Spyros Potamianos; Sunita Sarawagi; Cimarron Taylor; Chandra Ghosh Mosher; Jim Frew,Traditional relational DBMSs support a data model consisting of a collection of namedrelations; each attribute of which has a specific type. In current commercial systems; possibletypes are floating point numbers; integers; character strings; money; and dates. It iscommonly recognized that this model is inadequate for future data processing applications.,*,*,*
Efficient feature representation for semi-Markov models with unbounded segment length,Sunita Sarawagi,Abstract Semi-Markov conditional random fields (Semi-CRFs) are a recently proposedformalism for Named Entity Recognition (NER) that support entity-level features; and thusmodel NER problems more naturally than word-level sequence models like CRFs. Empiricalresults on real-life NER tasks show that they yield higher accuracy than CRFs but at 3–10times the computation cost. We propose a faster variant of a Semi-CRF that is based on asuccinct representation of features common across overlapping segments. We exploit this todesign an efficient training algorithm that can sum over all possible input segmentation intime that is sub-quadratic in the input length; even while imposing no bound on themaximum segment length. Consequently; the running time becomes comparable to CRFseven with the addition of useful entity-level features on large input segments.,*,*,*
Optimizing the evaluation of complex similarity predicates,Alok Kirpal; Sunita Sarawagi,*,*,*,*
On the Computation of Multidimensional Aggregates,Jeffrey F Naughton; Raghu Ramakrishnan; Sunita Sarawagi,Abstract At the heart of all OLAP or multidimensional data analysis applications is the abilityto simultaneously aggregate across many sets of dimensions. Computing multidimensionalaggregates is a performance bottleneck for these applications. This paper presents fastalgorithms for computing a collection of group bys. We focus on a special case of theaggregation problem-computation of the CUBE operator. The CUBE operator requirescomputing group-bys on all possible combinations of a list of attributes; and is equivalent tothe union of a number of standard group-by operations. We show how the structure of CUBEcomputation can be viewed in terms of a hierarchy of group-by operations. Our algorithmsextend sort-based and hashbased grouping methods with several. optimizations; likecombining common operations across multiple groupbys; caching; and using pre …,*,*,*
Building Classifiers With Unrepresentative Training Instances: Experiences From The KDD Cup 2001 Competition,Anuradha Bhamidipaty; Anand Janakiraman; Sunita Sarawagi; Jayant Haritsa,Abstract In this paper we discuss our experiences in participating in the KDD Cup 2001competition. The task involved classifying organic molecules as either active or inactive intheir binding to a receptor. The classification task presented three challenges: highly skewedclass distribution; large number of features exceeding training set size by two orders ofmagnitude; and non-representative training instances. Of these; we found the thirdchallenge the most interesting and novel. We present our process of experimenting with anumber of classification methods before finally converging on an ensemble of decision treesconstructed using a novel attribute partitioning method. Decision trees provided partialshield from the differences in data distribution and the ensemble provided stability byexploiting the redundancy in the large set of features. Finally; we employed …,*,*,*
