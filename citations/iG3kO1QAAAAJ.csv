Implementing reproducible research,Victoria Stodden; Friedrich Leisch; Roger D Peng,In computational science; reproducibility requires that researchers make code and dataavailable to others so that the data can be analyzed in a similar manner as in the originalpublication. Code must be available to be distributed; data must be accessible in a readableformat; and a platform must be available for widely distributing the data and code. Inaddition; both data and code need to be licensed permissively enough so that others canreproduce the work without a substantial legal burden. Implementing ReproducibleResearch covers many of the elements necessary for conducting and distributingreproducible research. It explains how to accurately reproduce a scientific result. Dividedinto three parts; the book discusses the tools; practices; and dissemination platforms forensuring reproducibility in computational science. It describes: Computational tools; such …,*,2014,123
ReproZip: Using Provenance to Support Computational Reproducibility.,Fernando Seabra Chirigati; Dennis E Shasha; Juliana Freire,Abstract We describe ReproZip; a tool that makes it easier for authors to publishreproducible results and for reviewers to validate these results. By tracking operating systemcalls; ReproZip systematically captures detailed provenance of existing experiments;including data dependencies; libraries used; and configuration parameters. This informationis combined into a package that can be installed and run on a different environment. Animportant goal that we have for ReproZip is usability. Besides simplifying the creation ofreproducible results; the system also helps reviewers. Because the package isselfcontained; reviewers need not install any additional software to run the experiments. Inaddition; ReproZip generates a workflow specification for the experiment. This not onlyenables reviewers to execute this specification within a workflow system to explore the …,TaPP,2013,65
Chiron: a parallel engine for algebraic scientific workflows,Eduardo Ogasawara; Jonas Dias; Vitor Silva; Fernando Chirigati; Daniel Oliveira; Fabio Porto; Patrick Valduriez; Marta Mattoso,SUMMARY Large-scale scientific experiments based on computer simulations are typicallymodeled as scientific workflows; which eases the chaining of different programs. Thesescientific workflows are defined; executed; and monitored by scientific workflowmanagement systems (SWfMS). As these experiments manage large amounts of data; itbecomes critical to execute them in high-performance computing environments; such asclusters; grids; and clouds. However; few SWfMS provide parallel support. The ones that doso are usually labor-intensive for workflow developers and have limited primitives tooptimize workflow execution. To address these issues; we developed workflow algebra tospecify and enable the optimization of parallel execution of scientific workflows. In thispaper; we show how the workflow algebra is efficiently implemented in Chiron; an …,Concurrency and Computation: Practice and Experience,2013,62
noWorkflow: Capturing and Analyzing Provenance of Scripts,Leonardo Murta; Vanessa Braganholo; Fernando Chirigati; David Koop; Juliana Freire,Abstract We propose noWorkflow; a tool that transparently captures provenance of scriptsand enables reproducibility. Unlike existing approaches; noWorkflow is non-intrusive anddoes not require users to change the way they work–users need not wrap their experimentsin scientific workflow systems; install version control systems; or instrument their scripts. Thetool leverages Software Engineering techniques; such as abstract syntax tree analysis;reflection; and profiling; to collect different types of provenance; including detailedinformation about the underlying libraries. We describe how noWorkflow captures multiplekinds of provenance and the different classes of analyses it supports: graph-basedvisualization; differencing over provenance trails; and inference queries.,Provenance and Annotation of Data and Processes: 5th International Provenance and Annotation Workshop; IPAW 2014; Cologne; Germany; June 9-13; 2014. Revised Selected Papers,2015,61
Exploring many task computing in scientific workflows,Eduardo Ogasawara; Daniel de Oliveira; Fernando Chirigati; Carlos Eduardo Barbosa; Renato Elias; Vanessa Braganholo; Alvaro Coutinho; Marta Mattoso,Abstract One of the main advantages of using a scientific workflow management system(SWfMS) to orchestrate data flows among scientific activities is to control and register thewhole workflow execution. The execution of activities within a workflow with highperformance computing (HPC) presents challenges in SWfMS execution control. Currentsolutions leave the scheduling to the HPC queue system. Since the workflow executionengine does not run on remote clusters; SWfMS are not aware of the parallel strategy of theworkflow execution. Consequently; remote execution control and provenance registry of theparallel activities is very limited from the SWfMS side. This work presents a set ofcomponents to be included on the workflow specification of any SWMfS to controlparallelization of activities as MTC. In addition; these components can gather provenance …,Proceedings of the 2nd Workshop on Many-Task Computing on Grids and Supercomputers,2009,55
YesWorkflow: a user-oriented; language-independent tool for recovering workflow information from scripts,Timothy McPhillips; Tianhong Song; Tyler Kolisnik; Steve Aulenbach; Khalid Belhajjame; Kyle Bocinsky; Yang Cao; Fernando Chirigati; Saumen Dey; Juliana Freire; Deborah Huntzinger; Christopher Jones; David Koop; Paolo Missier; Mark Schildhauer; Christopher Schwalm; Yaxing Wei; James Cheney; Mark Bieda; Bertram Ludaescher,Abstract: Scientific workflow management systems offer features for composing complexcomputational pipelines from modular building blocks; for executing the resulting automatedworkflows; and for recording the provenance of data products resulting from workflow runs.Despite the advantages such features provide; many automated workflows continue to beimplemented and executed outside of scientific workflow systems due to the convenienceand familiarity of scripting languages (such as Perl; Python; R; and MATLAB); and to thehigh productivity many scientists experience when using these languages. YesWorkflow is aset of software tools that aim to provide such users of scripting languages with many of thebenefits of scientific workflow systems. YesWorkflow requires neither the use of a workflowengine nor the overhead of adapting code to run effectively in such a system. Instead …,arXiv preprint arXiv:1502.02403,2015,45
The more the merrier: Efficient multi-source graph traversal,Manuel Then; Moritz Kaufmann; Fernando Chirigati; Tuan-Anh Hoang-Vu; Kien Pham; Alfons Kemper; Thomas Neumann; Huy T Vo,Abstract Graph analytics on social networks; Web data; and communication networks hasbeen widely used in a plethora of applications. Many graph analytics algorithms are basedon breadth-first search (BFS) graph traversal; which is not only time-consuming for largedatasets but also involves much redundant computation when executed multiple times fromdifferent start vertices. In this paper; we propose Multi-Source BFS (MS-BFS); an algorithmthat is designed to run multiple concurrent BFSs over the same graph on a single CPU corewhile scaling up as the number of cores increases. MS-BFS leverages the properties ofsmall-world networks; which apply to many real-world graphs; and enables efficient graphtraversal that:(i) shares common computation across concurrent BFSs;(ii) greatly reduces thenumber of random memory accesses; and (iii) does not incur synchronization costs. We …,Proceedings of the VLDB Endowment,2014,32
Reproducibility Using VisTrails,J Freire; D Koop; FS Chirigati; C Silva,Science has long placed an emphasis on revisiting and reusing past results: reproducibilityis a core component of the scientific process. Testing and extending published results arestandard activities that lead to practical progress: science moves forward using past workand allowing scientists to “stand on the shoulders of giants.” In natural science; long traditionrequires experiments to be described in enough detail so that they can be reproduced,*,2014,30
The PBase scientific workflow provenance repository,Víctor Cuevas-Vicenttín; Parisa Kianmajd; Bertram Ludäscher; Paolo Missier; Fernando Chirigati; Yaxing Wei; David Koop; Saumen Dey,Scientific workflows and their supporting systems are becoming increasingly popular forcompute-intensive and data-intensive scientific experiments. The advantages scientificworkflows offer include rapid and easy workflow design; software and data reuse; scalableexecution; sharing and collaboration; and other advantages that altogether facilitate“reproducible science”. In this context; provenance–information about the origin; context;derivation; ownership; or history of some artifact–plays a key role; since scientists areinterested in examining and auditing the results of scientific experiments. However; in orderto perform such analyses on scientific results as part of extended research collaborations; anadequate environment and tools are required. Concretely; the need arises for a repositorythat will facilitate the sharing of scientific workflows and their associated execution traces …,International Journal of Digital Curation,2014,26
Similarity-based workflow clustering,Vıtor Silva; Fernando Chirigati; Kely Maia; Eduardo Ogasawara; D Oliveira; Vanessa Braganholo; Leonardo Murta; Marta Mattoso,ABSTRACT Scientists have been using scientific workflow management systems (SWfMS) tosupport scientific experiments. However; SWfMS expect a modeled workflow to berepresented on its workflow language to be executed. The scientist does not have anassistance or guidance to obtain a modeled workflow. Experiment lines; which are a novelapproach to deal with these limitations; allow for the abstract representation and systematiccomposition of experiments. Since there are many scientific workflows already modeled andsuccessfully executed; they can be used to leverage the construction of new abstractrepresentations. These previous experiments can be helpful by identifying scientificworkflow clusters that are generated according to similarity criteria. This paper proposesSimiFlow; which is an architecture for similarity-based comparison and clustering to build …,JCIS,2011,21
GExpLine: a tool for supporting experiment composition,Daniel de Oliveira; Eduardo Ogasawara; Fernando Seabra; Vítor Silva; Leonardo Murta; Marta Mattoso,Abstract Scientific experiments present several advantages when modeled at highabstraction levels; independent from Scientific Workflow Management System (SWfMS)specification languages. For example; the scientist can define the scientific hypothesis interms of algorithms and methods. Then; this high level experiment can be mapped intodifferent scientific workflow instances. These instances can be executed by a SWfMS andtake advantage of its provenance records. However; each workflow execution is oftentreated by the SWfMS as independent instances. There are no tools that allow modeling theconceptual experiment and linking it to the diverse workflow execution instances. This workpresents GExpLine; a tool for supporting experiment composition through provenance. In ananalogy to software development; it can be seen as a CASE tool while a SWfMS can be …,Provenance and Annotation of Data and Processes,2010,17
Data polygamy: the many-many relationships among urban spatio-temporal data sets,Fernando Chirigati; Harish Doraiswamy; Theodoros Damoulas; Juliana Freire,Abstract The increasing ability to collect data from urban environments; coupled with a pushtowards openness by governments; has resulted in the availability of numerous spatio-temporal data sets covering diverse aspects of a city. Discovering relationships betweenthese data sets can produce new insights by enabling domain experts to not only test butalso generate hypotheses. However; discovering these relationships is difficult. First; arelationship between two data sets may occur only at certain locations and/or time periods.Second; the sheer number and size of the data sets; coupled with the diverse spatial andtemporal scales at which the data is available; presents computational challenges on allfronts; from indexing and querying to analyzing them. Finally; it is non-trivial to differentiatebetween meaningful and spurious relationships. To address these challenges; we …,Proceedings of the 2016 International Conference on Management of Data,2016,16
ReproZip: Computational Reproducibility with Ease,Fernando Chirigati; Rémi Rampin; Dennis Shasha; Juliana Freire,*,Proceedings of the SIGMOD,*,15
Towards Integrating Workflow and Database Provenance: A Practical Approach,Fernando Chirigati; Juliana Freire,*,*,*,15
Evaluating parameter sweep workflows in high performance computing,Fernando Chirigati; Vítor Silva; Eduardo Ogasawara; Daniel De Oliveira; Jonas Dias; Fábio Porto; Patrick Valduriez; Marta Mattoso,Abstract Scientific experiments based on computer simulations can be defined; executedand monitored using Scientific Workflow Management Systems (SWfMS). Several SWfMSare available; each with a different goal and a different engine. Due to the exploratoryanalysis; scientists need to run parameter sweep (PS) workflows; which are workflows thatare invoked repeatedly using different input data. These workflows generate a large amountof tasks that are submitted to High Performance Computing (HPC) environments. Differentexecution models for a workflow may have significant differences in performance in HPC.However; selecting the best execution model for a given workflow is difficult due to theexistence of many characteristics of the workflow that may affect the parallel execution. Wedeveloped a study to show performance impacts of using different execution models in …,Proceedings of the 1st ACM SIGMOD Workshop on Scalable Workflow Execution Engines and Technologies,2012,14
Using explicit control processes in distributed workflows to gather provenance,Sérgio Manuel Serra da Cruz; Fernando Seabra Chirigati; Rafael Dahis; Maria Luiza M Campos; Marta Mattoso,Abstract Distributing workflow tasks among high performance environments involves localprocessing and remote execution on clusters and grids. This dis-tribution often needsinteroperation between heterogeneous workflow definition languages and theircorresponding execution machines. A centralized Workflow Management System (WfMS)can be locally controlling the execution of a workflow that needs a grid WfMS to execute asub-workflow that requires high performance. Workflow specification languages oftenprovide different control-flow execution structures. Moving from one environment to anotherrequires mappings between these languages. Due to heterogeneity; control-flow structures;available in one system; may not be supported in another. In these heterogeneousdistributed environments; provenance gathering becomes also heterogeneous. This work …,International Provenance and Annotation Workshop,2008,14
Packing experiments for sharing and publication,Fernando Chirigati; Dennis Shasha; Juliana Freire,Abstract Reproducibility is a core component of the scientific process. Revisiting and reusingpast results allow science to move forward-" standing on the shoulders of giants"; as Newtononce said. An impediment to the adoption of computational reproducibility is that authors findit difficult to generate a compendium that encompasses all the required components tocorrectly reproduce their experiments. Even when a compendium is available; reviewersand readers may have difficulties in verifying the results on platforms different from the oneswhere the experiments were originally run. As a step towards simplifying the process ofcreating reproducible experiments; we have developed ReproZip; a tool that automaticallycaptures the provenance of experiments and packs all the necessary files; librarydependencies and variables to reproduce the results. Reviewers can then unpack and …,Proceedings of the 2013 ACM SIGMOD International Conference on Management of Data,2013,12
Computação em nuvem,Fernando Seabra Chirigati,*,Rio de Janeiro; RJ,2009,11
A conception process for abstract workflows: an example on deep water oil exploitation domain,W Martinho; E Ogasawara; D Oliveira; F Chirigati; I Santos; GHT Travassos; M Mattoso,*,5th IEEE International Conference on e-Science,2009,11
Provone: A prov extension data model for scientific workflow provenance,Víctor Cuevas-Vicenttín; B Ludäscher; P Missier; K Belhajjame; F Chirigati; Y Wei; B Leinfelder,*,*,2015,10
Scientific workflow management system applied to uncertainty quantification in large eddy simulation,Gabriel Guerra; Fernando Rochinha; Renato Elias; Alvaro Coutinho; Vanessa Braganholo; D de Oliveira; Eduardo Ogasawara; Fernando Chirigati; Marta Mattoso,Abstract. Currently Large Eddy Simulation (LES) requires intensive computation and a lot ofdata management. Today this management is often carried out in a case by case basis andrequires great effort to track it. This is due to the large amount of data involved; thus makingthis process prone to errors. Moreover; there is a need to explore parameter variability (eg;eddy viscosities) for the same set of data. In this context; techniques and methodologies ofscientific workflows can improve the management of simulations. This variability can be putin the general context of Uncertainty Quantification (UQ); which provides a rationalperspective for analysts and decision makers. The objective of this work is to provide asystematic approach in:(i) modeling of LES numerical experiments;(ii) managing the UQanalysis (iii) running each variation in parallel under the control of the Scientific Workflow …,Congresso Ibero Americano de Métodos Computacionais em Engenharia,2009,10
Reproducible experiments on dynamic resource allocation in cloud data centers,Andreas Wolke; Martin Bichler; Fernando Chirigati; Victoria Steeves,Abstract In Wolke et al.[1] we compare the efficiency of different resource allocationstrategies experimentally. We focused on dynamic environments where virtual machinesneed to be allocated and deallocated to servers over time. In this companion paper; wedescribe the simulation framework and how to run simulations to replicate experiments orrun new experiments within the framework.,Information Systems,2016,9
SimiFlow: Uma Arquitetura para Agrupamento de Workflows por Similaridade,Vítor Silva; Fernando Chirigati; Kely Maia; Eduardo Ogasawara; D Oliveira; Vanessa Braganholo; Leonardo Murta; Marta Mattoso,Abstract. Scientists have been using scientific workflows to support scientific experiments.However; the Scientific Workflow Management Systems present some limitation on workflowcomposition. Experiment Lines; which are a novel approach to deal with these limitations;allow the representation and systematic composition of the experiment. Nevertheless; thereare many scientific workflows already modeled that can leverage the construction ofexperiment lines via the identification of scientific workflows clusters that are createdaccording to similarity. This paper proposes SimiFlow; an architecture for similarity-basedcomparison and clustering to build experiment lines following a bottom-up approach.Resumo. Workflows científicos vêm sendo utilizados no apoio aos experimentos científicos.Workflows em um mesmo experimento normalmente apresentam pequenas variações …,IV e-Science,2010,7
A model project for reproducible papers: critical temperature for the Ising model on a square lattice,Michele Dolfi; Jan Gukelberger; Andreas Hehn; J Imriška; K Pakrouski; TF Rønnow; Matthias Troyer; I Zintchenko; F Chirigati; Juliana Freire; D Shasha,Abstract: In this paper we present a simple; yet typical simulation in statistical physics;consisting of large scale Monte Carlo simulations followed by an involved statistical analysisof the results. The purpose is to provide an example publication to explore tools for writingreproducible papers. The simulation estimates the critical temperature where the Isingmodel on the square lattice becomes magnetic to be Tc/J= 2.26934 (6) using a finite sizescaling analysis of the crossing points of Binder cumulants. We provide a virtual machinewhich can be used to reproduce all figures and results.,arXiv preprint arXiv:1401.2000,2014,6
A Computational Reproducibility Benchmark.,Fernando Seabra Chirigati; Matthias Troyer; Dennis E Shasha; Juliana Freire,Abstract Creating and testing reproducible computational experiments is hard. Researchersmust derive a compendium that encapsulates all the components needed to reproduce aresult. Reviewers must unpack the encapsulated components; run them in an environmentthat could be different from the source environment; and verify the results. Although manytools support some aspect of reproducibility; there is no common benchmark against whichsingle or multiple tools can be tested. This paper describes a benchmark that can be used tocategorize and better understand existing systems. The benchmark will also serve as thebasis for a competition whereby tool builders will demonstrate if and how their systemssupport end-to-end reproducibility.,IEEE Data Eng. Bull.,2013,6
Exploring What not to Clean in Urban Data: A Study Using New York City Taxi Trips,Juliana Freire; Aline Bessa; Fernando Chirigati; Huy Vo; Kai Zhao,*,IEEE Data Engineering Bulletin,2016,5
ProvONE: A PROV Extension Data Model for Scientific Workflow Provenance (2015),V Cuevas-Vicenttín; B Ludäscher; P Missier; K Belhajjame; F Chirigati; Y Wei; S Dey; P Kianmajd; D Koop; S Bowers; I Altintas,*,*,*,5
Knowledge exploration using tables on the web,Fernando Chirigati; Jialu Liu; Flip Korn; You Will Wu; Cong Yu; Hao Zhang,Abstract The increasing popularity of mobile device usage has ushered in many features inmodern search engines that help users with various information needs. One of those needsis Knowledge Exploration; where related documents are returned in response to a userquery; either directly through right-hand side knowledge panels or indirectly throughnavigable sections underneath individual search results. Existing knowledge explorationfeatures have relied on a combination of Knowledge Bases and query logs. In this paper; wepropose Knowledge Carousels of two modalities; namely sideways and downwards; thatfacilitate exploration of IS-A and HAS-A relationships; respectively; with regard to an entity-seeking query; based on leveraging the large corpus of tables on the Web. This brings manytechnical challenges; including associating correct carousels with the search entity …,Proceedings of the VLDB Endowment,2016,4
VisTrails provenance traces for benchmarking,Fernando Chirigati; Juliana Freire; David Koop; Cláudio Silva,Abstract The benchmark provenance traces that we have collected come from the VisTrailssystem for exploratory data analysis and visualization and from the VisTrails; Inc.provenance plugin for Autodesk Maya [1]. They contain diþerent kinds of provenanceinformation; including prospective and retrospective provenance as well as provenance ofthe evolution of work ows and models [4]. Our traces are stored using a change-basedrepresentation to compactly save all directions a user explored when developing a result.,Proceedings of the Joint EDBT/ICDT 2013 Workshops,2013,4
A collaborative approach to computational reproducibility,Fernando Chirigati; Rebecca Capone; Dennis Shasha; Remi Rampin; Juliana Freire,Abstract: Although a standard in natural science; reproducibility has been only episodicallyapplied in experimental computer science. Scientific papers often present a large number oftables; plots and pictures that summarize the obtained results; but then loosely describe thesteps taken to derive them. Not only can the methods and the implementation be complex;but also their configuration may require setting many parameters and/or depend onparticular system configurations. While many researchers recognize the importance ofreproducibility; the challenge of making it happen often outweigh the benefits. Fortunately; aplethora of reproducibility solutions have been recently designed and implemented by thecommunity. In particular; packaging tools (eg; ReproZip) and virtualization tools (eg; Docker)are promising solutions towards facilitating reproducibility for both authors and reviewers …,arXiv preprint arXiv:1709.01154,2017,3
HESML: A scalable ontology-based semantic similarity measures library with a set of reproducible experiments and a replication dataset,Juan J Lastra-Díaz; Ana García-Serrano; Montserrat Batet; Miriam Fernández; Fernando Chirigati,Abstract This work is a detailed companion reproducibility paper of the methods andexperiments proposed by Lastra-Díaz and García-Serrano in (2015; 2016)[56–58]; whichintroduces the following contributions:(1) a new and efficient representation model fortaxonomies; called PosetHERep; which is an adaptation of the half-edge data structurecommonly used to represent discrete manifolds and planar graphs;(2) a new Java softwarelibrary called the Half-Edge Semantic Measures Library (HESML) based on PosetHERep;which implements most ontology-based semantic similarity measures and InformationContent (IC) models reported in the literature;(3) a set of reproducible experiments on wordsimilarity based on HESML and ReproZip with the aim of exactly reproducing theexperimental surveys in the three aforementioned works;(4) a replication framework and …,Information Systems,2017,3
Provenance storage; querying; and visualization in PBase,Paolo Missier; Fernando Chirigati; Yaxing Wei; David Koop; Saumen Dey,Abstract. We present PBase; a repository for scientific workflows and their correspondingprovenance information that facilitates the sharing of experiments among the scientificcommunity. PBase is interoperable since it uses ProvONE; a standard provenance model forscientific workflows. Workflows and traces are stored in RDF; and with the support ofSPARQL and the tree cover encoding; the repository provides a scalable infrastructure forquerying the provenance data. Furthermore; through its user interface; it is possible to:visualize workflows and execution traces; visualize reachability relations within these traces;issue SPARQL queries; and visualize query results.,International Provenance and Annotation Workshop (IPAW),2015,3
Uma avaliação da Distribuição de Atividades Estática e Dinâmica em Ambientes Paralelos usando o Hydra,Vítor Silva; Fernando Chirigati; Eduardo Ogasawara; Jonas Dias; D Oliveira; Fábio Porto; Patrick Valduriez; Marta Mattoso,Abstract. Scientific Workflows are used as a basic tool to design and execute scientificexperiments on different computational environments. These workflows can becomputational and data intensive; requiring high performance computing. The way in whichworkflow activities are parallelized and distributed over these environments affects theoverall performance of the workflow. This work evaluates two different strategies for activitydistribution (static and dynamic) using Hydra middleware integrated with VisTrails. Ourexperiments show that using the right strategy decreases elapsed time for activitydistribution in 30%. Resumo. Workflows Científicos são usados como uma abstração básicapara estruturação e execução de experimentos científicos em diferentes ambientescomputacionais. Estes workflows podem ser intensivos tanto computacionalmente …,V e-Science,2011,3
Uma Abordagem Semântica para Linhas de Experimentos Científicos Usando Ontologias,Daniel de Oliveira; Eduardo Ogasawara; Fernando Chirigati; Vítor Sousa; Leonardo Murta; Cláudia Werner; Marta Mattoso,Abstract. Scientific workflows have been used as an abstraction to compose scientificexperiments. However; the composition of these workflows is a complex task. Currently thereis no guidance or process to follow to reach a workflow specification. As workflows becomemore complex; composition needs abstraction and semantic support. Experiment lines arean innovative and promising solution to model and reuse scientific workflows in differentlevels of abstraction. This paper proposes an ontology coupled to experiment lines toprovide semantics and flexibility. Resumo. Workflows científicos vêm sendo usados comouma abstração para compor experimentos científicos. Entretanto; a composição destesworkflows é uma tarefa complexa. Atualmente não há um guia ou processo a ser seguidopara alcançar uma especificação de um workflow. Conforme os workflows se tornam …,*,2009,3
Virtual lightweight snapshots for consistent analytics in NoSQL stores,Fernando Chirigati; Jérôme Siméon; Martin Hirzel; Juliana Freire,Increasingly; applications that deal with big data need to run analytics concurrently withupdates. But bridging the gap between big and fast data is challenging: most of theseapplications require analytics' results that are fresh and consistent; but without impactingsystem latency and throughput. We propose virtual lightweight snapshots (VLS); amechanism that enables consistent analytics without blocking incoming updates in NoSQLstores. VLS requires neither native support for database versioning nor a transactionmanager. Besides; it is storage-efficient; keeping additional versions of records only whenneeded to guarantee consistency; and sharing versions across multiple concurrentsnapshots. We describe an implementation of VLS in MongoDB and present a detailedexperimental evaluation which shows that it supports consistency for analytics with small …,Data Engineering (ICDE); 2016 IEEE 32nd International Conference on,2016,2
Provenance storage; querying; and visualization in PBase,Víctor Cuevas-Vicenttín; Parisa Kianmajd; Bertram Ludäscher; Paolo Missier; Fernando Chirigati; Yaxing Wei; David Koop; Saumen Dey,Abstract We present PBase; a repository for scientific workflows and their correspondingprovenance information that facilitates the sharing of experiments among the scientificcommunity. PBase is interoperable since it uses ProvONE; a standard provenance model forscientific workflows. Workflows and traces are stored in RDF; and with the support ofSPARQL and the tree cover encoding; the repository provides a scalable infrastructure forquerying the provenance data. Furthermore; through its user interface; it is possible to:visualize workflows and execution traces; visualize reachability relations within these traces;issue SPARQL queries; and visualize query results.,International Provenance and Annotation Workshop,2014,2
ReproZip: The Reproducibility Packer,Rémi Rampin; Fernando Chirigati; Dennis Shasha; Juliana Freire; Vicky Steeves,*,The Journal of Open Source Software,2016,1
Provenance Storage; Querying; and Visualization in PBase,Parisa Kianmajd; Bertram Ludascher; Paolo Missier; Fernando Chirigati; Yaxing Wei; David Koop; Saumen Dey,*,*,2015,1
Scientific Workflows+ Provenance= Better (Meta-) Data Management,B Ludaescher; V Cuevas-Vicenttín; P Missier; S Dey; P Kianmajd; Y Wei; D Koop; F Chirigati; I Altintas; K Belhajjame; S Bowers,Abstract The origin and processing history of an artifact is known as its provenance. Dataprovenance is an important form of metadata that explains how a particular data productcame about; eg; how and when it was derived in a computational process; which parametersettings and input data were used; etc. Provenance information provides transparency andhelps to explain and interpret data products. Other common uses and applications ofprovenance include quality control; data curation; result debugging; and more generally;'reproducible science'. Scientific workflow systems (eg Kepler; Taverna; VisTrails; andothers) provide controlled environments for developing computational pipelines with built-inprovenance support. Workflow results can then be explained in terms of workflow steps;parameter settings; input data; etc. using provenance that is automatically captured by the …,AGU Fall Meeting Abstracts,2013,1
A conception process for abstract workflows: an example on deep water oil exploitation domain,Wallace Pereira; Eduardo Ogasawara; Daniel de Oliveira; Fernando Chirigati; Fabrício Correa; Breno Jacob; Ismael Santos; Guilherme H Travassos; Marta Mattoso,Abstract: Experimentation is one of the ways used to support theories based on a scientificmethod. In-silico experiments are highly dependent of massive use of computationalresources to execute their simulations. One way to use in-silico experiments is through theuse of scientific work-flows. It is a model that represents the flow of programs; services anddata usually orchestrated to support a simulation. Scientific workflows are executed inengines called Scientific Workflow Management Systems (SWfMS); which are responsiblefor enacting; controlling and monitoring the workflow. Each one of the scientific workflowswithin an experiment follows specific phases regarding composition; execution and analysis.Usually; when conducting a scientific experiment; the first phase to be considered is calledComposition. One important sub-phase is the Conception; which is responsible for setting …,*,2009,1
Using Reprozip for Reproducibility and Library Services,Vicky Steeves; Remi Rampin; Fernando Chirigati,Abstract This is a pre-print of a manuscript pending publication. Achieving researchreproducibility is challenging in many ways: there are social and cultural obstacles as wellas a constantly changing technical landscape that makes replicating and reproducingresearch difficult. Users face challenges in reproducing research across different operatingsystems; in using different versions of software across long projects and amongcollaborations; and in using publicly available work. The dependencies required toreproduce the computational environments in which research happens can be exceptionallyhard to track–in many cases; these dependencies are hidden or nested too deeply todiscover; and thus impossible to install on a new machine; which means adoption remainslow. In this paper; we present ReproZip; an open source tool to help overcome the …,*,2017,*
Querying and Exploring Polygamous Relationships in Urban Spatio-Temporal Data Sets,Yeuk-Yin Chan; Fernando Chirigati; Harish Doraiswamy; Cláudio T Silva; Juliana Freire,Abstract The Data Polygamy framework allows users to uncover interesting patterns andinteractions in the data exhaust from different components of an urban environment. Butanalyzing the plethora of relationships derived by the framework is challenging. In thisdemo; we show how visualization can help in the discovery of relationships that arepotentially interesting by allowing users to query and explore the relationship set in anintuitive way. We will demonstrate the effectiveness of the visual interface through casestudies; and demo visitors will also interact with the polygamous relationships.,Proceedings of the 2017 ACM International Conference on Management of Data,2017,*
Provenance and Reproducibility,Fernando Chirigati; Juliana Freire,A computational experiment composed by a sequence of steps S created at time T; onenvironment (hardware and operating system) E; using data D is reproducible if it can beexecuted with a sequence of steps S0 (modified from or equal to S) at time T 0> T; onenvironment E0 (potentially different than E); using data D0 that is similar to (or the same as)D with consistent results [5]. Replication is a special case of reproducibility where S0 DS andD0 D D. While there is substantial disagreement on how to define reproducibility [1]; inparticular across different domains; in this entry; we focus on computational reproducibility;ie; reproducibility for computational experiments or processes. The information needed toreproduce an experiment can be obtained from its provenance: the details of how theexperiment was carried out and the results it derived. For computational experiments …,*,2017,*
A model project for reproducible papers,Michele Dolfi; Jan Gukelberger; Andreas Hehn; Jakub Imriska; Kiryl Pakrouski; Troels Rønnow; Matthias Troyer; Ilia Zintchenko; F Chirigati; J Freire; D Shasha,In this paper we present a simple; yet typical simulation in statistical physics; consisting oflarge scale Monte Carlo simulations followed by an involved statistical analysis of theresults. The purpose is to provide an example publication to explore tools for writingreproducible papers. The simulation estimates the critical temperature where the Isingmodel on the square lattice becomes magnetic to be Tc/J= 2.26934 (6) using a finite sizescaling analysis of the crossing points of Binder cumulants. We provide a virtual machinewhich can be used to reproduce all figures and results.,*,2014,*
Facilitating Scientific Research through Workflows and Provenance on the DataONE Cyberinfrastructure,B Ludaescher; V Cuevas-Vicenttín; P Missier; S Dey; P Kianmajd; Y Wei; D Koop; F Chirigati; I Altintas; K Belhajjame; S Bowers,Abstract Provenance data has numerous applications in science. Two key ones are 1)replication: facilitate the repeatable derivation of results and 2) discovery: enable thelocation of data based on processing history and derivation relationships. The followingscenario illustrates a typical use of provenance data. Alice; a climate scientist; hasdeveloped a VisTrails workflow to prepare Gross Primary Productivity (GPP) data. Afterverifying that the workflow generates data in the desired form; she uses the ReproZip tool tocreate a reproducible package that will enable other scientists to re-run the workflow withouthaving to install and configure the particular libraries she is using. In addition; she exportsthe provenance information of the workflow execution and customizes it through a tool suchas the ProvExplorer; in order to eliminate the information she regards as superfluous. She …,AGU Fall Meeting Abstracts,2013,*
ReproZip: Packing experiments for sharing and publications,Fernando Chirigati; Dennis Shasha; Juliana Freire,Skip to main content …,*,2013,*
ReproZip,Fernando Chirigati; Dennis Shasha; Juliana Freire,Page 1. REPROZIP Using Provenance to Support Computational Reproducibility FernandoChirigati NYU-Poly Dennis Shasha NYU Juliana Freire NYU-Poly & NYU TaPP'13 Page 2.Reproducibility Good science requires reproducibility Computational experiments requirereproducibility A program P running on computational environment E at time T is said to bereproducible if it yields the same answer on environment E' at time T' > T “If I have seen further;it is by standing on the shoulders of giants.” Isaac Newton Page 3. Computational ReproducibilityFew computational experiments are reproducible Why? We need provenance How toencapsulate my experiment? What should be included? Too many dependencies… Too manyfiles to keep track… Sigh. Author Description of the data Specification of the experimentDescription of the environment Page 4. Computational Reproducibility …,*,*,*
IDCC14| Practice Paper,Víctor Cuevas-Vicenttín; Parisa Kianmajd; Bertram Ludäscher; Paolo Missier; Fernando Chirigati; Yaxing Wei; David Koop; Saumen Dey,Abstract Scientific workflows and their supporting systems are becoming increasinglypopular for compute-intensive and data-intensive scientific experiments. The advantagesscientific workflows offer include rapid and easy workflow design; software and data reuse;scalable execution; sharing and collaboration; and other advantages that altogetherfacilitate “reproducible science”. In this context; provenance; information about the origin;context; derivation; ownership; or history of some artifact plays a key role; since scientists areinterested in examining and auditing the results of scientific experiments. However; in orderto perform such analyses on scientific results as part of extended research collaborations; anadequate environment and tools are required. Concretely; the need arises for a repositorythat will facilitate sharing scientific workflows and their associated execution traces in an …,*,*,*
Data Engineering,Thomas Heinis; Farhan Tauheed; Mirjana Pavlovic; Anastasia Ailamaki; Jacob Vanderplas; Emad Soroush; Simon Krughoff; Magdalena Balazinska; Michael Stonebraker; Jennie Duggan; Leilani Battle; Olga Papaemmanouil; Colin Talbert; Marian Talbert; Jeff Morisette; David Koop; Fernando Chirigati; Matthias Troyer; Dennis Shasha; Juliana Freire,Abstract Researchers in several scientific disciplines are struggling to cope with the massesof data resulting from either increasingly precise instruments or from simulation runs on evermore powerful supercomputers. Efficiently managing this deluge of data has become key tounderstand the phenomena they are studying. Scientists in the simulation sciences; forexample; build increasingly big and detailed models; as detailed as the hardware allows;but they lack the efficient technology to update and analyze them. In this paper we discusshow innovative data management techniques we have developed; enable scientists to buildand analyze bigger and more detailed spatial models and how these techniques ultimatelyaccelerate discovery in the simulation sciences. These include spatial join methods (inmemory and on disk); techniques for the efficient navigation in detailed meshes; an index …,*,*,*
Controles de Fluxo Explícitos em Workflows Científicos,Sérgio Manuel Serra da Cruz; Fernando Seabra Chirigati; Rafael Dahis; Maria Luiza M Campos; Marta Mattoso,Abstract. Scientific experiments often involve cooperation between large scale computingand data resources. Workflow management systems (WfMS) are emerging as a key elementto help scientists to prototype and execute experiments to accelerate the scientificdiscoveries. However; even though scientific workflows have been widely labeled as data-centered; they do require some control-flow to design the steps of the experiment–but; thesemodules are not available in the majority of WfMS. When available they are veryheterogeneous. We propose a package of generic control-flow modules independent of theWfMS execution-machine language. Our goal is to provide a meta-workflow specificationwhere control can be designed and executed or mapped to different workflow engines. Wepresent the incorporation of control-flow modules based on workflow patterns to the …,*,*,*
