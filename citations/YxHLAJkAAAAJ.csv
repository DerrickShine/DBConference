Using noun phrase heads to extract document keyphrases,Ken Barker; Nadia Cornacchia,Abstract Automatically extracting keyphrases from documents is a task with manyapplications in information retrieval and natural language processing. Document retrievalcan be biased towards documents containing relevant keyphrases; documents can beclassified or categorized based on their keyphrases; automatic text summarization mayextract sentences with high keyphrase scores. This paper describes a simple system forchoosing noun phrases from a document as keyphrases. A noun phrase is chosen based onits length; its frequency and the frequency of its head noun. Noun phrases are extracted froma text using a base noun phrase skimmer and an off-the-shelf online dictionary. Experimentsinvolving human judges reveal several interesting results: the simple noun phrase-basedsystem performs roughly as well as a state-of-the-art; corpus-trained keyphrase extractor; …,Conference of the Canadian Society for Computational Studies of Intelligence,2000,242
A library of generic concepts for composing knowledge bases,Ken Barker; Bruce Porter; Peter Clark,Abstract Building a knowledge base for a given domain traditionally involves a subjectmatter expert and a knowledge engineer. One of the goals of our research is to eliminate theknowledge engineer. There are at least two ways to achieve this goal: train domain expertsto write axioms (ie; turn them into knowledge engineers) or create tools that allow users tobuild knowledge bases without having to write axioms. Our strategy is to create tools thatallow users to build knowledge bases through instantiation and assembly of genericknowledge components from a small library. In many ways; creating such a library is likedesigning an ontology: What are the most general kinds of events and entities? How arethese things related hierarchically? What is their meaning and how is it represented? Thepressures of making the library usable by domain experts; however; leads to departures …,Proceedings of the 1st international conference on Knowledge capture,2001,139
Semi-automatic recognition of noun modifier relationships,Ken Barker; Stan Szpakowicz,Abstract Semantic relationships among words and phrases are often marked by explicitsyntactic or lexical clues that help recognize such relationships in texts. Within complexnominals; however; few overt clues are available. Systems that analyze such nominals mustcompensate for the lack of surface clues with other information. One way is to load thesystem with lexical semantics for nouns or adjectives. This merely shifts the problemelsewhere: how do we define the lexical semantics and build large semantic lexicons?Another way is to find constructions similar to a given complex nominal; for which therelationships are already known. This is the way we chose; but it too has drawbacks.Similarity is not easily assessed; similar analyzed constructions may not exist; and if they doexist; their analysis may not be appropriate for the current nominal. We present a semi …,Proceedings of the 17th international conference on Computational linguistics-Volume 1,1998,122
Project halo: Towards a digital aristotle,Noah S Friedland; Paul G Allen; Gavin Matthews; Michael Witbrock; David Baxter; Jon Curtis; Blake Shepard; Pierluigi Miraglia; Jurgen Angele; Steffen Staab; Eddie Moench; Henrik Oppermann; Dirk Wenke; David Israel; Vinay Chaudhri; Bruce Porter; Ken Barker; James Fan; Shaw Yi Chaw; Peter Yeh; Dan Tecuci; Peter Clark,Abstract Project Halo is a multistaged effort; sponsored by Vulcan Inc; aimed at creatingDigital Aristotle; an application that will encompass much of the world's scientific knowledgeand be capable of applying sophisticated problem solving to answer novel questions.Vulcan envisions two primary roles for Digital Aristotle: as a tutor to instruct students in thesciences and as an interdisciplinary research assistant to help scientists in their work. As afirst step towards this goal; we have just completed a six-month pilot phase designed toassess the state of the art in applied knowledge representation and reasoning (KR&/R).Vulcan selected three teams; each of which was to formally represent 70 pages from theadvanced placement (AP) chemistry syllabus and deliver knowledge-based systemscapable of answering questions on that syllabus. The evaluation quantified each system's …,AI magazine,2004,100
Knowledge entry as the graphical assembly of components,Peter Clark; John Thompson; Ken Barker; Bruce Porter; Vinay Chaudhri; Andres Rodriguez; Jerome Thomere; Sunil Mishra; Yolanda Gil; Pat Hayes; Thomas Reichherzer,Abstract Despite some successes; the lack of tools to allow subject matter experts to directlyenter; query; and debug formal domain knowledge in a knowledge-base still remains amajor obstacle to their deployment. Our goal is to create such tools; so that a trainedknowledge engineer is no longer required to mediate the interaction. This paper presentsour work on the knowledge entry part of this overall knowledge capture task; which is basedon several claims: that users can construct representations by connecting pre-fabricated;representational components; rather than writing low-level axioms; that these componentscan be presented to users as graphs; and the user can then perform composition throughgraph manipulation operations. To operationalize this; we have developed a noveltechnique of graphical dialog using examples of the component concepts; followed by an …,Proceedings of the 1st international conference on Knowledge capture,2001,98
Project Halo Update—Progress Toward Digital Aristotle,David Gunning; Vinay K Chaudhri; Peter E Clark; Ken Barker; Shaw-Yi Chaw; Mark Greaves; Benjamin Grosof; Alice Leung; David D McDonald; Sunil Mishra; John Pacheco; Bruce Porter; Aaron Spaulding; Dan Tecuci; Jing Tien,*,AI Magazine,2010,83
Learning by reading: A prototype system; performance baseline and lessons learned,Ken Barker; Bhalchandra Agashe; Shaw Yi Chaw; James Fan; Noah Friedland; Michael Glass; Jerry Hobbs; Eduard Hovy; David Israel; Doo Soon Kim; Rutu Mulkar-Mehta; Sourabh Patwardhan; Bruce W Porter; Dan Tecuci; Peter Z Yeh,Abstract A traditional goal of Artificial Intelligence research has been a system that can readunrestricted natural language texts on a given topic; build a model of that topic and reasonover the model. Natural Language Processing advances in syntax and semantics havemade it possible to extract a limited form of meaning from sentences. KnowledgeRepresentation research has shown that it is possible to model and reason over topics ininteresting areas of human knowledge. It is useful for these two communities to reuniteperiodically to see where we stand with respect to the common goal of text understanding. Inthis paper; we describe a coordinated effort among researchers from the Natural Languageand Knowledge Representation and Reasoning communities. We routed the output ofexisting NL software into existing KR software to extract knowledge from texts for …,AAAI,2007,59
Representing roles and purpose,James Fan; Ken Barker; Bruce Porter; Peter Clark,Abstract Ontology designers often distinguish Entities (things that are) from Events (thingsthat happen). It is not obvious how this division admits Roles (things that are; but only in thecontext of things that happen). For example; Person might be considered an Entity; whileEmployee is a Role. A Person remains a Person independent of the Events in which heparticipates. Someone is an Employee only by virtue of participating in an EmploymentEvent. The problem of how to represent Roles is not new; but there is little consensus on asolution. In this paper; we present an ontology that finds a place for Roles as well as arepresentation that allows Roles to be related to Entities and Events to express theteleological notion of purpose.,Proceedings of the 1st international conference on Knowledge capture,2001,53
Towards the open advancement of question answering systems,David Ferrucci; Eric Nyberg; James Allan; Ken Barker; Eric Brown; Jennifer Chu-Carroll; Arthur Ciccolo; Pablo Duboue; James Fan; David Gondek; Eduard Hovy; Boris Katz; Adam Lally; Michael McCord; Paul Morarescu; Bill Murdock; Bruce Porter; John Prager; Tomek Strzalkowski; Chris Welty; Wlodek Zadrozny,1 Summary On February 27-28; 2008; a group of researchers from industry and academiamet to discuss the state of the Question Answering (QA) field. The discussion focused onrecent experiences from funded research programs (eg AQUAINT; HALO) and openevaluations (eg TREC; NTCIR). The group acknowledged that funded research programsand evaluations have been instrumental in establishing fundamental QA research. However;major advances in the field of QA are yet to be realized. Advances that can openlyaccelerate progress and greatly generalize QA technologies to produce scalable; moreadaptable methodologies and business applications are within our reach. Although thereare deep technical challenges; we believe these challenges can be effectively addressed byopen collaboration in the open-source development of integrated QA technologies aimed …,IBM; Armonk; NY; IBM Res. Rep,2009,52
A Question-Answering System for AP Chemistry: Assessing KR&R Technologies.,Ken Barker; Vinay K Chaudhri; Shaw Yi Chaw; Peter Clark; James Fan; David J Israel; Sunil Mishra; Bruce W Porter; Pedro Romero; Dan Tecuci; Peter Z Yeh,Abstract Basic research in knowledge representation and reasoning (KR&R) has steadilyadvanced over the years; but it has been difficult to assess the capability of fielded systemsderived from this research. In this paper; we present a knowledge-based question-answering system that we developed as part of a broader effort by Vulcan Inc. to assessKR&R technologies; and the result of its assessment. The challenge problem presentedsignificant new challenges for knowledge representation; compared with earlier suchassessments; due to the wide variability of question types that the system was expected toanswer. Our solution integrated several modern KR&R technologies; in particularsemantically well-defined frame systems; automatic classification methods; reusableontologies; a methodology for knowledge base construction; and a novel extension of …,KR,2004,49
A Knowledge Acquisition Tool for Course of Action Analysis.,Kim Barker; Jim Blythe; Gary C Borchardt; Vinay K Chaudhri; Peter Clark; Paul R Cohen; Julie Fitzgerald; Kenneth D Forbus; Yolanda Gil; Boris Katz; Jihie Kim; Gary W King; Sunil Mishra; Clayton T Morrison; Kenneth S Murray; Charley Otstott; Bruce W Porter; Robert Schrag; Tomás E Uribe; Jeffrey M Usher; Peter Z Yeh,Abstract We present the novel application of a general-purpose knowledge-based system;SHAKEN; to the specific task of acquiring knowledge for military Course of Action (COA)analysis. We show how SHAKEN can capture and reuse expert knowledge for COAcritiquing; which can then be used to produce high-level COA assessments throughdeclarative inference and simulation. The system has been tested and evaluated by domainexperts; and we report on the results. The generality of the approach makes it applicable totask analysis and knowledge capture in other domains. The primary objective of this work isto demonstrate the application of the knowledge acquisition technology to the task of COAanalysis. Developing a system deployable in an operational environment is the subject offuture work.,IAAI,2003,48
Interactive semantic analysis of technical texts,Sylvain Delisle; Ken Barker; Terry Copek; Stan Szpakowicz,Abstract Sentence syntax is the basis for organizing semantic relations in TANKA; a projectthat aims to acquire knowledge from technical text. Other hallmarks include an absence ofprecoded domain-specific knowledge; significant use of public-domain generic linguisticinformation sources; involvement of the user as a judge and source of expertise; andlearning from the meaning representations produced during processing. These elementsshape the realization of the TANKA project: implementing a trainable text processing systemto propose correct semantic interpretations to the user. A three-level model of sentencesemantics; including a comprehensive Case system; provides the framework for TANKA'srepresentations. Text is first processed by the DIPETT parser; which can handle a widevariety of unedited sentences. The semantic analysis module HAIKU then semi …,Computational Intelligence,1996,48
Using transformations to improve semantic matching,Peter Z Yeh; Bruce Porter; Ken Barker,Abstract Many AI tasks require determining whether two knowledge representations encodethe same knowledge. Solving this matching problem is hard because representations mayencode the same content but differ substantially in form. Previous approaches to thisproblem have used either syntactic measures; such as graph edit distance; or semanticknowledge to determine the" distance" between two representations. Although semanticapproaches outperform syntactic ones; previous research has focused primarily on the useof taxonomic knowledge. We show that this is not enough because mismatches betweenrepresentations go largely unaddressed. In this paper; we describe how transformations canaugment existing semantic approaches to further improve matching. We also describe theapplication of our approach to the task of critiquing military Courses of Action and …,Proceedings of the 2nd international conference on Knowledge capture,2003,41
Capturing and answering questions posed to a knowledge-based system,Peter Clark; Shaw-Yi Chaw; Ken Barker; Vinay Chaudhri; Philip Harrison; James Fan; Bonnie John; Bruce Porter; Aaron Spaulding; John Thompson; Peter Yeh,Abstract As part of the ongoing project; Project Halo; our goal is to build a system capable ofanswering questions posed by novice users to a formal knowledge base. In our currentcontext; the knowledge base covers selected topics in physics; chemistry; and biology; andour question set consists of AP (advanced high-school) level examination questions. Thetask is challenging because the questions are linguistically complex and are oftenincomplete (assume unstated knowledge); and because the users do not have priorknowledge of the system's contents. Our solution involves two parts: a controlled languageinterface; in which users reformulate the original natural language questions in a simplifiedversion of English; and a novel problem solver that can elaborate initially inadequate logicalinterpretations of a question by selecting relevant pieces of knowledge in the knowledge …,Proceedings of the 4th international conference on Knowledge capture,2007,39
Towards a Quantitative; Platform-Independent Analysis of Knowledge Systems.,Noah S Friedland; Paul G Allen; Michael J Witbrock; Gavin Matthews; Nancy Salay; Pierluigi Miraglia; Jürgen Angele; Steffen Staab; David J Israel; Vinay K Chaudhri; Bruce W Porter; Ken Barker; Peter Clark,*,KR,2004,39
Systematic construction of a versatile case system,Ken Barker; Terry Copeck; Stan Szpakowicz; Sylvain Delisle,Abstract Case systems abound in natural language processing. Almost any attempt torecognize and uniformly represent relationships within a clause–a unit at the centre of anylinguistic system that goes beyond word level statistics–must be based on semantic rolesdrawn from a small; closed set. The set of roles describing relationships between a verb andits arguments within a clause is a case system. What is required of such a case system?How does a natural language practitioner build a system that is complete and detailed yetpractical and natural? This paper chronicles the construction of a case system from its originin English marker words to its successful application in the analysis of English text.,Natural Language Engineering,1997,37
A trainable bracketer for noun modifiers,Ken Barker,Abstract Noun phrases carry much of the information in a text. Systems that attempt toacquire knowledge from text must first decompose complex noun phrases to get access tothat information. In the case of noun compounds; this decomposition usually meansbracketing the modifiers into nested modifier-head pairs. It is then possible to determine thesemantic relationships among individual components of the noun phrase. This paperdescribes a semi-automatic system for bracketing an unlimited number of adjectival ornominal premodifiers. Since the system is intended to start processing with no priorknowledge; it gets trained as it brackets. That is; it starts from scratch and accumulatesbracketing evidence while processing a text under user supervision. Experiments show thatgeneralizations of the structure of complex modifier sequences allow the system to …,Conference of the Canadian Society for Computational Studies of Intelligence,1998,31
Interactive semantic analysis of clause-level relationships,Ken Barker; Stan Szpakowicz,Abstract Natural Language Processing (NLP) systems usually require large amounts of pre-coded domain knowledge to perform semantic analysis automatically. Until repositories ofsuch background knowledge are widely available; these systems may not scale up to non-trivial applications of NLP. This paper describes the design and implementation of a systemthat uses surface-syntactic information to interpret interactively semantic relationshipsbetween clauses. English technical texts are analyzed by a domain-independent parser thatproduces detailed parse trees of the input. The system then examines clausal connectivesand syntactic verb phrase features to determine what kinds of semantic relationships existbetween clauses. The results of this activity are used in a large Knowledge Acquisitionsystem that; by design; requires little a priori semantic knowledge. We present a set of …,Proceedings of the Second Conference of the Pacific Association for Computational Linguistics (PACLING {95); pages 22 {30; Brisbane; Australia,1995,31
The knowledge required to interpret noun compounds,James Fan; Ken Barker; Bruce W Porter,Abstract Noun compound interpretation is the task of determining the semantic relationsamong the constituents of a noun compound. For example;“concrete floor” means a floormade of concrete; while “gymnasium floor” is the floor region of a gymnasium. We would liketo enable knowledge acquisition systems to interpret noun compounds; as part of theiroverall task of translating imprecise and incomplete information into formal representationsthat support automated reasoning. However; if interpreting noun compounds requiresdetailed knowledge of the constituent nouns; then it may not be worth doing: the cost ofacquiring this knowledge may outweigh the potential benefit. This paper describes anempirical investigation of the knowledge required to interpret noun compounds. It concludesthat the axioms and ontological distinctions important for this task are derived from the top …,IJCAI,2003,27
Semiautomatic recognition of semantic relationships in english technical texts,Ken Barker,Abstract When people read a text; they rely on a priori knowledge of language; commonsense knowledge and knowledge of the domain. Many natural language processingsystems implement this human model of language understanding; and therefore are heavilyknowledge-dependent. Such systems assume the availability of large amounts ofbackground knowledge coded in advance in a specialized formalism. The problem withsuch an assumption is that building a knowledge base with sufficient and relevant content islabour-intensive and very costly. And often; the resulting knowledge is either too specific tobe used for more than one very narrow domain or too general to allow subtle analyses oftexts. In order to avoid the problems of manually encoding background knowledge; manyresearchers have abandoned symbolic language analysis in favour of statistical methods …,*,1998,27
Indirect anaphora resolution as semantic path search,James Fan; Ken Barker; Bruce Porter,Abstract Anaphora occur commonly in natural language text; and resolving them is essentialfor capturing the knowledge encoded in text. Indirect anaphora are especially challenging toresolve because the referring expression and the antecedent are related by unstatedbackground knowledge. Such anaphora need to be resolved properly in order toautomatically capture the knowledge expressed in natural language. Resolving indirectanaphora has been treated as a unique problem that requires special-purpose methods;and these methods have had limited success in precision and recall. In this study; we used ageneric tool for finding semantic paths between two concepts to resolve these anaphora;and it achieved approximately twice the recall of the best previous system without loss ofprecision. A series of ablation study showed that the biggest increase in recall came from …,Proceedings of the 3rd international conference on Knowledge capture,2005,25
A web-based ontology browsing and editing system,Jérôme Thoméré; Ken Barker; Vinay Chaudhri; Peter Clark; Michael Eriksen; Sunil Mishra; Bruce Porter; Andres Rodriguez,Abstract Making logic-based AI representations accessible to ordinary users has been anongoing challenge for the successful deployment of knowledge bases. Past work to meetthis objective has resulted in a variety of ontology editing tools and task-specific knowledge-acquisition methods. In this paper; we describe a Web-based ontology browsing and editingsystem with the following features:(a) well-organized English-like presentation of conceptdescriptions and (b) use of graphs to enter concept relationships; add/delete lists; andanalogical correspondences. No existing tool supports these features. The system is Web-based and its user interface uses a mixture of HTML and Java. It has undergone significanttesting and evaluation in the context of a real application.,AAAI/IAAI,2002,25
Test-driving TANKA: Evaluating a semi-automatic system of text analysis for knowledge acquisition,Ken Barker; Sylvain Delisle; Stan Szpakowicz,Abstract The evaluation of a large implemented natural language processing systeminvolves more than its application to a common performance task. Such tasks have beenused in the message understanding conferences (MUCs); text retrieval conferences(TRECs) as well as in speech technology and machine translation workshops. It is useful tocompare the performance of different systems in a predefined application; but a detailedevaluation must take into account the specificity of the system. We have carried out asystematic performance evaluation of our text analysis system tanka. Since it is a semi-automatic; trainable system; we had to measure the user's participation (with a view todecreasing it gradually) and the rate at which the system learns from preceding analyses.This paper discusses the premises; the design and the execution of an evaluation of …,Conference of the Canadian Society for Computational Studies of Intelligence,1998,24
Object-oriented analysis: Getting help from robust computational linguistic tools,Sylvain Delisle; Ken Barker; Ismaïl Biskri,Abstract In object-oriented (OO) software engineering; objects; attributes and processes areoften specified in natural language descriptions. Following a precise methodology; we herelook at the analysis phase of OO software engineering and show that robust computationallinguistic tools initially developed for knowledge extraction from text can provide usefulsupport during this initial but crucial phase of any OO software development project.,*,1999,18
A unified knowledge based approach for sense disambiguation and semantic role labeling,Peter Z Yeh; Bruce Porter; Ken Barker,Abstract In this paper; we present a unified knowledge based approach for sensedisambiguation and semantic role labeling. Our approach performs both tasks through asingle algorithm that matches candidate semantic interpretations to background knowledgeto select the best matching candidate. We evaluate our approach on a corpus of sentencescollected from various domains and show how our approach performs well on both sensedisambiguation and semantic role labeling.,AAAI,2006,16
Matching utterances to rich knowledge structures to acquire a model of the speaker's goal,Peter Z Yeh; Bruce Porter; Ken Barker,Abstract An ultimate goal of AI is to build end-to-end systems that interpret natural language;reason over the resulting logical forms; and perform actions based on that reasoning. Thisrequires systems from separate fields be brought together; but often this exposesrepresentational gaps between them. The logical forms from a language interpreter maymirror the surface forms of utterances too closely to be usable as-is; given a reasoner'srequirements for knowledge representations. What is needed is a system that can matchlogical forms to background knowledge flexibly to acquire a rich semantic model of thespeaker's goal. In this paper; we present such a" matcher" that uses semantictransformations to overcome structural differences between the two representations. Weevaluate this matcher in a MUC-like template-filling task and compare its performance to …,Proceedings of the 3rd international conference on Knowledge capture,2005,15
Enabling domain experts to convey questions to a machine: a modified; template-based approach,Peter Clark; Vinay Chaudhri; Sunil Mishra; Jérôme Thoméré; Ken Barker; Bruce Porter,Abstract In order for a knowledge capture system to be effective; it needs to not only acquiregeneral domain knowledge from experts; but also capture the specific problem-solvingscenarios and questions which those experts are interested in solving using that knowledge.For some tasks; this latter aspect of knowledge capture is straightforward. In other cases; inparticular for systems aimed at a wide variety of tasks; the question-posing aspect ofknowledge capture can be a challenge in its own right. In this paper; we present theapproach we have developed to address this challenge; based on the creation of a catalogof domain-independent question types and the extension of question template methods withgraphical tools. Our goal was that domain experts could directly convey complex questionsto a machine; in a form which it could then reason with. We evaluated the resulting system …,Proceedings of the 2nd international conference on Knowledge Capture,2003,15
What is technical text?,Terry Copeck; Ken Barker; Sylvain Delisle; Stan Szpakowicz; Jean-François Delannoy,Abstract Beyond labeling it easier to process than other types; few researchers who usetechnical text in their work try to define what it is. This paper describes a study thatinvestigates the character of texts typically considered technical. We identify 42 features of atext considered likely to correlate with its degree of technicality. These include bothobjectively verifiable measures like marked presence of interrogative or imperativesentences which are akin to the criteria used by Biber in Variation Across Speech andWriting; and subjective measures such as presence of hierarchical organization. All are lessambiguous than technicality; so our inventory may be suited to use in a procedure thatclassifies text as technical or non-technical. An inventory organizing and describing theselexical; syntactic; semantic and discourse features was used to rate nine varied sample …,Language Sciences,1997,15
Improving the quality of text understanding by delaying ambiguity resolution,Doo Soon Kim; Ken Barker; Bruce Porter,Abstract Text Understanding systems often commit to a single best interpretation of asentence before analyzing subsequent text. This interpretation is chosen by resolvingambiguous alternatives to the one with the highest confidence; given the context available atthe time of commitment. Subsequent text; however; may contain information that changesthe confidence of alternatives. This may especially be the case with multiple redundant textson the same topic. Ideally; systems would delay choosing among ambiguous alternativesuntil more text has been read. One solution is to maintain multiple candidate interpretationsof each sentence until the system acquires disambiguating evidence. Unfortunately; thenumber of alternatives explodes quickly. In this paper; we propose a packed graphical (PG)representation that can efficiently represent a large number of alternative interpretations …,Proceedings of the 23rd International Conference on Computational Linguistics,2010,13
Pattern matching for case analysis: A computational definition of closeness,Sylvain Delisle; Terry Copeck; Stan Szpakowicz; Ken Barker,Proposes a conceptually and technically neat method to identify known semantic patternsclose to a novel pattern. This occurs in the context of a system to acquire knowledgeincrementally from systematically processed expository technical text. This semi-automaticsystem requires the user to respond to specific multiple-choice questions about the currentsentence. The questions are prepared from linguistic elements previously encountered inthe text similar to elements in the new sentence. We present a metric to characterize thesimilarity between semantic case patterns. The computation is based on syntactic indicatorsof semantic relations and is defined in terms of symbolic pattern matching.,Computing and Information; 1993. Proceedings ICCI'93.; Fifth International Conference on,1993,12
Mining transformation rules for semantic matching,Peter Yeh; Bruce Porter; Ken Barker,Abstract. Semantic matching is finding a mapping between two knowledge representationsencoded using the same ontology. Solving this matching problem is hard because thesyntactic form of two knowledge representations rarely matches exactly. Previous researchhas shown transformation rules can be used to improve matching; but acquiringtransformations is difficult. In this paper; we present an algorithm for mining transformationrules for semantic matching. This algorithm was evaluated in two domains–battle spaceplanning and chemistry. In both cases; the resulting transformations helped to improvematching significantly compared to using only taxonomic knowledge.,ECML/PKDD 2nd International Workshop on Mining Graphs; Trees; and Sequences,2004,10
Automating the measurement of linguistic features to help classify texts as technical,Terry Copeck; Kim Barker; Sylvain Delisle; Stan Szpakowicz,Abstract Text classification plays a central role in software systems which perform automaticinformation classification and retrieval. Occurrences of linguistic feature values must becounted by any mechanism that classifies or characterizes natural language text by topic;style; genre or; in our case; by the degree to which a text is technical. We discuss themethodology and key details of the feature value extraction process; paying attention to fastand reliable implementation. Our results are mixed but support continued investigation—while a significant level of automation has been achieved; the successfully extracted featurecounts do not always correlate with technicality as strongly as anticipated.,Proceedings of the Seventh Conference on Automatic NLP (TALN-2000),2000,10
From text to Horn clauses: Combining linguistic analysis and machine learning,Sylvain Delisle; Ken Barker; Jean-François Delannoy; Stan Matwin; Stan Szpakowicz,Abstract The paper describes a system that extracts knowledge from technical English texts.Our basic assumption is that in technical texts syntax is a reliable indication of meaning.Consequently; semantic interpretation of the text starts from surface syntax. The linguisticcomponent of the system uses a broad-coverage; domainindependent parser of English; aswell as a user-assisted semantic interpreter that memorizes its experience. The resultingsemantic structures are translated into Horn clauses; a representation suitable forExplanation-based Learning (EBL). An EBL engine performs symbollevel learning onrepresentations of both the domain theory and the example provided by the linguistic part ofthe system. Our approach has been applied to the Canadian Individual Income Tax Guideand examples from it are used in the presentation.,PROCEEDINGS OF THE BIENNIAL CONFERENCE-CANADIAN SOCIETY FOR COMPUTATIONAL STUDIES OF INTELLIGENCE,1994,10
Query Driven Hypothesis Generation for Answering Queries over NLP Graphs,Chris Welty; Ken Barker; Lora Aroyo; Shilpa Arora,Abstract It has become common to use RDF to store the results of Natural LanguageProcessing (NLP) as a graph of the entities mentioned in the text with the relationshipsmentioned in the text as links between them. These NLP graphs can be measured withPrecision and Recall against a ground truth graph representing what the documents actuallysay. When asking conjunctive queries on NLP graphs; the Recall of the query is expected tobe roughly the product of the Recall of the relations in each conjunct. Since Recall istypically less than one; conjunctive query Recall on NLP graphs degrades geometricallywith the number of conjuncts. We present an approach to address this Recall problem byhypothesizing links in the graph that would improve query Recall; and then attempting to findmore evidence to support them. Using this approach; we confirm that in the context of …,The Semantic Web–ISWC 2012,2012,9
Transformation rules for knowledge-based pattern matching,Peter Yeh; Bruce Porter; Ken Barker,BIB-VERSION:: CS-TR-v2.0. ID:: UTEXAS.CS//AI03-299. ENTRY:: December 12; 2003.ORGANIZATION:: The University of Texas at Austin;. Department of Computer Sciences. TYPE::Technical Report. TITLE:: Transformation Rules for Knowledge-Based Pattern Matching. AUTHOR::Yeh; Peter. CONTACT:: Department of Computer Sciences. The University of Texas at Austin.Austin; TX 78712. AUTHOR:: Porter; Bruce. CONTACT:: Department of Computer Sciences. TheUniversity of Texas at Austin. Austin; TX 78712. AUTHOR:: Barker; Ken. CONTACT:: Departmentof Computer Sciences. The University of Texas at Austin. Austin; TX 78712. DATE:: December2003. PAGES:: 32. KEY WORDS: RETRIEVAL:: Available via anonymous FTP from.ftp://ftp.cs.utexas.edu/pub/AI-Lab/tech-reports/UT-AI-TR-03-299.ps.gz. ABSTRACT:: END::UTEXAS.CS//AI03-299. BIB-VERSION:: CS-TR-v2.0. ID:: UTEXAS.CS//AI03-302 …,The University of Texas at Austin; Computer Sciences Technical Report UT-AI-TR-03-299,2003,9
Noun modifier relationship analysis in the TANKA system,Ken Barker,Abstract This paper describes work in progress on part of HAIKU (Delisle et al. 1996); asystem to extract semantic information from English technical text. Semantic processing inHAIKU consists of three parts: clause level relationship analysis; case analysis and nounmodifier relationship analysis. This paper reports on early work on noun modifierrelationship analysis. Research to date includes the construction of a set of semantic labelsfor the relationships between nouns and their modifiers; the design of algorithms to semi-automatically assign these labels to pairs of elements in noun phrases; as well as animplemented semi-automatic learning bracketer for sequences of multiple premodifiers ofhead nouns.,Ottawa: University of Ottawa,1997,9
Clause-level relationship analysis in the TANKA system,Ken Barker,Abstract Knowledge acquisition from text is often attempted in the presence of large amountsof pre-coded domain knowledge. Seeding a system with such knowledge is often a hugeknowledge acquisition effort in itself. Breaking this circle requires a text processing systemthat relies on little a priori semantic information. In the absence of such knowledge;processing must rely on available information; such as surface syntax. Semantic analysiswill consist of determining the semantic relationships between the various surface-syntacticconstituents in the sentence. This report describes the design and implementation of asystem that interactively interprets semantic relationships between clauses. The Clause-Level Relationship Analyzer inspects the parse trees produced by a domainindependentparser for syntactic features that can be used to determine what kinds of semantic …,Department of Computer Science; University of Ottawa; TR-94-07,1994,9
Knowledge integration across multiple texts,Doo Soon Kim; Ken Barker; Bruce Porter,Abstract One of the grand challenges of AI is to build systems that learn by reading. Theideal system would construct a rich knowledge base capable of automated reasoning. Wehave built a Learning-by-Reading system and this paper focuses on one aspect of it: the taskof integrating together snippets of knowledge drawn from multiple texts to build a singlecoherent knowledge base. Our evaluation shows that our approach to the knowledgeintegration is both feasible and promising.,Proceedings of the fifth international conference on Knowledge capture,2009,7
Experimental validation of a semi-automatic text analyzer,Ken Barker; Sylvain Delisle,Abstract The aim of the TANKA project is to acquire knowledge from actual uneditedtechnical text using a minimum of pre-coded semantic information. To make up for this lackof “seed knowledge”; the HAIKU semantic analyzer initially draws on detailed syntacticinformation provided by the DIPETT parser and on the help of a cooperative user. As moresentences from a text are analyzed; HAIKU builds pattern dictionaries which it uses to makeincreasingly informed suggestions for semantic analysis. The process is described in detailin Delisle et al.(1996). This document reports on an experiment to process a completeEnglish technical text using the major components of the DIPETT/HAIKU system. The resultsof the test are also used to forecast the toll on the user over the period required to process areal; complete technical text.,*,1996,7
The assessment of semantic cases using English positional; prepositional and adverbial case markers,Ken Barker,ABSTRACT Semantic analysis of text is often based on semantic roles drawn from a small;closed set. The set of roles describing relationships between a verb and its arguments withina clause are cases. This report assesses the cases used in the TANKA project (TextANalysis for Knowledge Acquisition) according to the distribution of the words and syntacticconstituents that mark them. The definitions of TANKA's cases; the number of instances ofeach case in a test text and numerous English example sentences and counterexamples arealso used in the assessment. Results show that TANKA's cases are supported by the markerdata.,*,1996,6
Report on the Fourth International Conference on Knowledge Capture (K-CAP 2007),Derek Sleeman; Ken Barker; David Corsar,Abstract The Fourth International Conference on Knowledge Capture was held October 28-31; 2007 in Whistler; British Columbia. K-CAP 2007 included two invited talks; technicalpapers; posters; and demonstrations. Topics included knowledge engineering and modelingmethodologies; knowledge engineering and the semantic web; mixed-initiative planningand decision-support tools; acquisition of problem-solving knowledge; knowledge-basedmarkup techniques; knowledge extraction systems; knowledge acquisition tools; and advicetaking systems.,AI Magazine,2009,4
More alike than not-an analysis of word frequencies in four general-purpose text corpora,Terry Copeck; Ken Barker; Sylvain Delisle; Stan Szpakowicz,Abstract INTRODUCTION This work arose from our need for a word frequency list. Wedecided to create one by averaging the rankings in public domain frequency lists based onseveral large; widely known corpora representative of current written English language use.Four such lists can be found on the Internet: the British National Corpus (BNC); the StandardCorpus of Present-Day Edited American English (Brown); the Lancaster/Oslo-BergenCorpus (LOB); and various collections of Wall Street Journal articles (WSJ). The four differsignificantly in formulation; so each was first brought to a common format as far as practical.Words innormalized'lists were then classified into four categories of our own devising.Common words appear in our project's dictionary of English words; proper words begin witha capital letter or have been tagged as such. Special words include numbers or …,*,1999,4
The design of a configurable text summarization system,Ken Barker; Yllias Chali; Terry Copeck; Stan Matwin; Stan Szpakowicz,Abstract This report presents the design of a exible summarization system consisting ofseveral independent linguistic processing tools that can be rapidly con gured andextensively parameterized. Summarization will begin with segmentation of the text at placeswhere there is a probable topic change. Next; segments will be classi ed and segmentswhich strongly evidence of the topic suggested by a user's query will be identi ed. Finally;summary sentences will be extracted from the most relevant segments rather than the wholetext.,Univ. Ottawa; School of Information Technology and Engineering,1998,4
Flexible Summarization,Jean-François Delannoy; Ken Barker; Terry Copeck; Martin Laplante; Stan Matwin; Stan Szpakowicz,Abstract Our project; initiated in 1997; approaches text summarization as a knowledge-scanttask of passage selection. Several features make this task more discriminating. Thesefeatures include" smart" key phrase selection that uses machine learning techniques andsimple linguistic criteria; dynamic passage selection; adaptation to the type of text; andchoice among several styles of summary. This paper presents the guiding principles of theproject; describes the current state of the prototype; and discusses short-term and long-termfuture research.,AAAI Spring Symposium Workshop on Intelligent Text Summarization,1998,4
Medical Concept Resolution,Nitish Aggarwal; Ken Barker; Chris Welty,Abstract. In this paper; we present a problem that we refer to as Medical Concept Resolutionfor finding concept identifiers in a large knowledge base; given medical terms mentioned ina text. We define the problem with its unique features and novel algorithms to address it. Wecompare performance to MetaMap and find distinct and complementary behavior.,ISWC 2015 -- the 14th International Semantic Web Conference,2015,3
Bootstrapping relation extraction using parallel news articles,Michael Glass; Ken Barker,Abstract Relation extraction is the task of finding entities in text connected by semanticrelations. Bootstrapping approaches to relation extraction have gained considerableattention in recent years. These approaches are built with an underlying assumption; thatwhen a pair of words is known to be related in a specific way; sentences containing thosewords are likely to express that relationship. Therefore; sentences containing the pair ofwords may be used as training data for the relation extractor. We test this assumption forvarious relations drawn from two domains; using parallel and non-parallel corpora of newsarticles. We find that the assumption holds with substantially greater probability for parallelcorpora.,Proceedings of the IJCAI Workshop on Learning by Reading and its Applications in Intelligent Question-answering; Barcelona,2011,2
Automatic interpretation of loosely encoded input,James Fan; Ken Barker; Bruce Porter,Abstract Knowledge-based systems are often brittle when given unanticipated input; ieassertions or queries that misalign with the ontology of the knowledge base. We call suchmisalignments “loose speak”. We found that loose speak occurs frequently in interactionswith knowledge-based systems; but with such regularity that it often can be interpreted andcorrected algorithmically. We also found that the common types of loose speak; such asmetonymy and noun-noun compounds; have a common root cause. We created a Loose-Speak Interpreter and evaluated it with a variety of empirical studies in different domains andtasks. We found that a single; parsimonious algorithm successfully interpreted numerousmanifestations of loose speak with an average precision of 98% and an average recall of90%.,Artificial intelligence,2009,2
Preliminary validation of a text summarization algorithm,Stan Szpakowicz; Ken Barker; Terry Copeck; JF Delannoy; Stan Matwin,Abstract We describe an experiment whose purpose has been a manual simulation of analgorithm at the heart of a text summarization project proposed in 1996 to NSERC. Wepresent the algorithm; based on shallow linguistic clues and on a simple machine learningmethod of keyphrase identification. We discuss the various heuristics applied by theexperimenters; and the summaries they constructed. The experiment has shown anoteworthy overlap of summaries produced from different heuristics. This lends credence toour claim that automated summarization based on keyphrases can give usable results evenwithout advanced natural language processing techniques.,*,1997,2
A Case System for Interactive Knowledge Acquisition from Text,Ken Barker; Terry Copeck; Sylvain Delisle; Stan Szpakowicz,*,Journal of Natural Language Engineering,1996,2
Relational Path Mining in Structured Knowledge,Mihaela Bornea; Ken Barker,Abstract Large sources of structured knowledge are available in many domains; enablingthe construction of applications requiring relational knowledge. But in spite of the apparentavailability of relational content; the semantics and granularity of these sources don't alwaysmatch the requirements of specific tasks. Yet even when the coverage of explicit relationalknowledge in a source seems inadequate; there may be implicit knowledge in the completespace of relation instances. In this paper; we show that explicit relation instances in theUnified Medical Language System (UMLS) are insufficient for our task of detecting relationsbetween concepts in Electronic Medical Records. But by mining UMLS for relational pathsbetween pairs of concepts in a training set; then using generalizations of those paths asfeatures in a classifier; we achieve better results on the relation detection task than using …,K-CAP 2015,2015,1
Focused Grounding for Markov Logic Networks,Michael Glass; Ken Barker,Abstract Markov logic networks have been successfully applied to many problems in AI.However; the computational complexity of the inference procedures has limited theirapplication. Previous work in lifted inference; lazy inference and cutting plane inference hasidentified cases where the entire ground network need not be constructed. Theseapproaches are specific to particular inference procedures; and apply well only to certainclasses of problems. We introduce a method of focused grounding that can use eithergeneral purpose or domain specific heuristics to produce only the most relevant groundformulas. Though a solution to the focused grounding is not; in general; a solution to thecomplete grounding; we show empirically that the smaller search space of a focusedgrounding makes it easier to locate a good solution. We evaluate focused grounding on …,Twenty-Fifth International FLAIRS Conference,2012,1
Combining Structured and Unstructured Knowledge Sources for Question Answering in Watson,Ken Barker,Abstract One of the classical challenges of Artificial Intelligence research has been to buildautomatic; open-domain question answering (QA) systems. The goal is not merely to retrievedocuments containing answers to questions; or to query databases known to contain theanswers. Rather; open-domain question answering systems must accept any question onany topic; find relevant information from possibly disparate sources; synthesize an answer;explain the evidence supporting the answer and provide an indication of the systemsconfidence that the answer is correct.,Data Integration in the Life Sciences,2012,1
Building an end-to-end text reading system based on a packed representation,Doo Soon Kim; Ken Barker; Bruce Porter,Abstract We previously proposed a packed graphical representation to succinctly representa huge number of alternative semantic representations of a given sentence. We alsoshowed that this representation could improve text interpretation accuracy considerablybecause the system could postpone resolving ambiguity until more evidence accumulates.This paper discusses our plan to build an end-to-end text reading system based on ourpacked representation.,Proceedings of the NAACL HLT 2010 First International Workshop on Formalisms and Methodology for Learning by Reading,2010,1
A Scalable Problem-Solver for Large Knowledge-Bases,Shaw-Yi Chaw; Ken Barker; Bruce Porter; Dan Tecuci; Peter Z Yeh,We describe a problem solver built to answer questions like those on Advanced Placementexams using knowledge bases authored by domain experts. The problem solver is designedto work independently of any particular knowledge base or domain. Given a question; theproblem solver identifies those portions of the knowledge base that are relevant to thequestion. We found that simple heuristics for judging relevance significantly improvedperformance; with no drop in coverage.,Tools with Artificial Intelligence; 2009. ICTAI'09. 21st International Conference on,2009,1
Constructing a semantic interpreter using distributional analysis,Michael Glass; Ken Barker; Rekha Kumar; Guhan Ravi; Bruce Porter,Abstract Extracting a formal representation from text that can be used to reason and answerquestions has long been a goal of Artificial Intelligence research. We demonstrate a methodfor knowledge engineers to construct a semantic interpeter that requires little naturallanguage processing expertise. The resulting semantic interpreter is also able to extend itscoverage using semi-supervised learning. We compare the performance of an existingsemantic interpretation system to our resulting semantic interpreter. Our semantic interpretershows considerably superior performance on the two of the three test documents.,Proceedings of the 8th Conference of the Pacific Association for Computational Linguistics; Sapporo,2009,1
AURA: enabling subject matter experts to construct declarative knowledge bases from science textbooks,Ken Barker; Vinay K Chaudhri; Shaw Yi Chaw; Peter E Clark; Daniel Hansch; Bonnie E John; Sunil Mishra; John Pacheco; Bruce Porter; Aaron Spaulding; Moritz Weiten,*,PROCEEDINGS OF THE NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE,2007,1
Towards an Ontology-Independent Problem Solver,Shaw-Yi Chaw; Ken Barker; Bruce Porter; Peter Z Yeh,Abstract Questions posed to knowledge based systems typically omit information that isessential for answering them. Problem solvers; therefore; take on the responsibility ofelaborating them before they can be answered. Automating this process is especiallychallenging when the problem solver is meant to work with a variety of knowledge bases.We have studied this problem in the context of a system used to answer questions posed bynaive users who are unfamiliar with the content and organization (ie the ontology) of theknowledge bases. This separation between the builders and the users of the knowledgebases requires the problem solving system to elaborate the questions automatically withinformation drawn from the knowledge base being queried. Our approach is shown to workwell on different knowledge bases and it answers a broad range of unanticipated …,*,2007,1
Flexible Semantic Matching for Link Analysis: A Proposal,Peter Z Yeh; Bruce Porter; Ken Barker,Abstract Intelligence professionals need to determine quickly and accurately the “big picture”that connects disparate data points–ie link analysis. These connections can be found bymatching the data points with a knowledge base of models encoding activities of interest. Inthis paper; we propose using a flexible semantic matcher to satisfy this matchingrequirement.,*,2006,1
HALO Pilot Project,Ken Barker; Vinay K Chaudhri; David J Israel; Bruce Porter; Pedro Romer; Noah Friedland,*,*,2003,1
A Modified Template-Based Approach to Question-Answering from Knowledge Bases,Peter Clark; Ken Barker; Bruce Porter; Art Souther; Vinay Chaudhri; Sunil Mishra; Jerome Thomere; Jim Blythe; Jihie Kim; Pat Hayes; Ken Forbus; Shawn Nicholson,Abstract As part of a larger project; one of our goals is to enable users; not trained in AI; to beable to pose questions to an inference-capable knowledge base (KB); and receiveacceptable answers. In particular; we wish the system to support answering a wide variety ofquestions; including longer questions which may include scenario descriptions; withoutrequiring users to formulate their queries in predicate logic directly. In this paper; we presentthe approach we have developed to deal with this problem; based on the creation of acatalog of domain-independent question types and the extension of question templatemethods with graphical tools. We also report on the results of an extensive evaluation of thiswork conducted in Summer 2001.,Florida Keys National Marine Sanctuary Advisory Council,2002,1
Stacking with Auxiliary Features for Entity Linking in the Medical Domain,Nazneen Fatema Rajani; Mihaela Bornea; Ken Barker,Abstract Linking spans of natural language text to concepts in a structured source is animportant task for many problems. It allows intelligent systems to leverage rich knowledgeavailable in those sources (such as concept properties and relations) to enhance thesemantics of the mentions of these concepts in text. In the medical domain; it is common tolink text spans to medical concepts in large; curated knowledge repositories such as theUnified Medical Language System. Different approaches have different strengths: some areprecision-oriented; some recalloriented; some better at considering context but more proneto hallucination. The variety of techniques suggests that ensembling could outperformcomponent technologies at this task. In this paper; we describe our process for building aStacking ensemble using additional; auxiliary features for Entity Linking in the medical …,BioNLP 2017,2017,*
Information sources for resolving the ambiguities captured in a packed representation,Doo Soon Kim; Ken Barker; Bruce Porter,*,NLU 21,2011,*
Improving Recall on Conjunctive Queries against Text Documents using Query-Driven Hypothesis Generation,Ken Barker; James Fan; Chris Welty,*,NLU 21,2011,*
Bootstrapping Relation Extraction Using a Parallel Corpus,Michael Glass; Ken Barker,*,NLU 21,2011,*
ISI; USC,Peter Clark; Ken Barker; Bruce Porter; Art Souther; Vinay Chaudhri; Sunil Mishra; Jerome Thomere; Jim Blythe; Jihie Kim; Pat Hayes; Ken Forbus; Shawn Nicholson,Abstract As part of a larger project; one of our goals is to enable users; not trained in AI; to beable to pose questions to an inference-capable knowledge base (KB); and receiveacceptable answers. In particular; we wish the system to support answering a wide variety ofquestions; including longer questions which may include scenario descriptions; withoutrequiring users to formulate their queries in predicate logic directly. In this paper; we presentthe approach we have developed to deal with this problem; based on the creation of acatalog of domain-independent question types and the extension of question templatemethods with graphical tools. We also report on the results of an extensive evaluation of thiswork conducted in Summer 2001.,*,2002,*
More Thoughts On Views Working Note 22,Peter Clark; John Thompson; Ken Barker; James Fan,Page 1. More Thoughts On Views Working Note 22 Peter Clark; John Thompson Ken Barker; JamesFan; Knowledge Systems Bruce Porter; Dan Tecuci; Peter Yeh Mathematics and ComputingTechnology Computer Science Dept. Boeing University of Texas MS 7L66; PO Box 3707; Seattle;WA 98124 Austin; TX 78712 January 2001 Abstract This working note provides some morediscussion on the notion of representing “views” in a knowledge-base. 1 Introduction This workingnote explores some thoughts about the notion of “views” (including the “modeled-as” relationship);which we have been discussing recently. It revisits – again – one of the constants in our research;namely the desire that a knowledge-base to be able to be selective …,*,2001,*
Using Views in a Knowledge-Base Working Note 19,Peter Clark; John Thompson; Ken Barker; James Fan,Abstract In this working note; we sketch out some current thoughts on the use of “views” in aknowledge-base. A view is an explicit representation of how a general concept can beapplied to a domain-specific concept. By making views explicit; we can control which; andhow; more general concepts can be used to represent a domain-specific concept. We alsodiscuss the use of views to select alternative theories describing (“implementing”) thegeneral concept; in the spirit of compositional modeling.,*,2000,*
SHAKEN: A Knowledge Base Authoring Environment for Subject Matter Experts,Vinay Chaudhri; Tom Garvey; Srinivas Narayanan; Mark Stickel; Jerome Thomere; Mabry Tyson; Bruce Porter; Ken Barker; Art Souther; James Junmin Fan; Peter Zei-Chan Yeh; Dan Tecuci; Charlie Benton; Peter Clark; John Thompson; Yolanda Gil; Jihie Kim; Jim Blythe; Pat Hayes; Thomas Reichherzer; Ken Forbus; Ron Ferguson; Jeff Usher; Shawn Nicholson; Cara Meverden; John McCarthy; Eyal Amir; Aarati Parmar; Boris Katz; Gary Borchardt; Paul Cohen; Steve McKay; Jill Jermano; Richard Fikes; Deborah L McGuinness; Mala Mehrotra,Knowledge bases (KBs) are expensive to develop and difficult to deploy. Enabling subjectmatter experts (SMEs) to directly enter their knowledge is central to both improving theknowledge acquisition rates and making it practical to put KBs into operational use.In thisdocument; we describe the design of an end-to-end system; called SHAKEN; to enableSMEs; unassisted by AI technologists; to assemble models of mechanisms and processes.These models are both declarative and executable; so that questions about the mechanismsand processes can be answered by conventional inference methods (eg; theorem provingand taxonomic inference) and by various task-specific methods (eg; simulation; analogicalreasoning; and problem solving). One scientific innovation; and the principal extension toCyc and the “HPKB standard” of KBs; is the idea of declarative and executable models …,*,2000,*
Natural Language Processing for Prolog Programmers Michael A. Covington,Ken Barker; Stan Szpakowicz,The title says it all: it is truly a textbook for Prolog programmers; for better and for worse. Itpresents simple NLP for experienced Prolog programmers. The book is written in a casual(occasionally quite casual) style and is eminently readable if you are reasonablycomfortable with Prolog. The presentation has a satisfying flow. The book feels well planned;and is certainly well executed; considering its goals stated in the preface. Editing isadmirably meticulous; formatting nearly flawless. The many examples in Prolog are clearand work well. Prolog code for examples is available by ftp. References are abundant anduseful. The book has nine chapters and two appendices:,*,1996,*
Du texte aux clauses de Horn par la combinaison de l'analyse linguistique et de l'apprentissage automatique,SYLVAIN DELISLE; KEN BARKER; JEAN-FRANÇOIS DELANNOY; STAN MATWIN; STAN SZPAKOWICZ,RÉSUMÉ Cet article décrit un système d'extraction de connaissances à partir de textestechniques en anglais. Notre hypothèse de départ est que dans les textes techniques lasyntaxe est un indicateur fiable de la signification. L'interprétation sémantique part donc dela syntaxe. Le sous-système linguistique utilise un analyseur général de l'anglais;indépendant du domaine; et un interpréteur sémantique interactif qui accumule et utilise sonexpérience. Les structures sémantiques résultantes sont traduites en clauses de Horn; unereprésentation appropriée pour l'apprentissage à partir d'explications (EBL). Le systèmeapprend au niveau symbolique des représentations de la théorie du domaine et desexemples; tous deux fournis par le sous-système linguistique. Cette approche a étéappliquée à une partie du Guide d'Impôt Canadien.,Actes des Cinquiemes Journees Acquisition des Connaissances,1994,*
EXTRACTION OF INFERENCE RULES FROM HETEROGENEOUS GRAPHS,*,*,*,*,*
Report on the Fourth International Conference on Knowledge Capture,Derek Sleeman; Ken Barker; David Corsar,The Knowledge Capture 2007 (K-CAP 2007) Conference was held in Whistler (Canada) onOctober 28-31 2007. This was the fourth in a series of meetings; the first was held in Victoria;British Columbia in 2001; the second was co-located with the ISWC meeting and was heldon Sanibel Island; Florida in October 2003; and the third meeting was held in Banff; Albertain October 2005. The conference was held at The Fairmont Chateau in Whistler. Whistler is aspectacular setting; and is one of the principal sites of the 2010 Winter Olympic Games.Views from the Conference hotel were breathtaking and many of the participants tookadvantage of the venue to participate in various forms of outdoor sports.,*,*,*
Ahmed MK 153,K Barker; B Bosch; D Cameron; T Copcck; T Crowley; DR Davis; H Davis; V de Klerk; JF Delannoy; S Delisle; FJ Dicamilla; H Fraser; R Hasada; D Hill; C Hutton; JP Lantolf; N Love; M Onishi; B Peeters; D Schalkwyk; JW Sew; AM Simon-Vandenbergen; A St-Hilaire; R Stanwood; J Stonham; S Szpakowicz; TJ Taylor; M Tong; M Toolan; T Weber; G Wolf; M Yell,*,*,*,*
MORE ALIKE THAN NOT—,TERRY COPECK; KEN BARKER; SYLVAIN DELISLE; STAN SZPAKOWICZ,We compare word frequency lists derived from four general-purpose written English corpora:BNC; Brown; LOB and WSJ. Statistically significant correlation exists among the ranks ofcommon vocabulary words appearing in more than one list; despite marked differencesbetween the underlying corpora. The correlation may be sufficient to postulate acorpusindependent list for common words. Proper names and specific tokens such asnumbers show much less correlation and should be separated from common words if theirsimilarity is to remain unobscured. Our result has a bearing on word-sense disambiguation;text categorization and text summarization.,*,*,*
