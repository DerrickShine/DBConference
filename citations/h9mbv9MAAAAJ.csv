Trajectory clustering: a partition-and-group framework,Jae-Gil Lee; Jiawei Han; Kyu-Young Whang,Abstract Existing trajectory clustering algorithms group similar trajectories as a whole; thusdiscovering common trajectories. Our key observation is that clustering trajectories as awhole could miss common sub-trajectories. Discovering common sub-trajectories is veryuseful in many applications; especially if we have regions of special interest for analysis. Inthis paper; we propose a new partition-and-group framework for clustering trajectories;which partitions a trajectory into a set of line segments; and then; groups similar linesegments together into a cluster. The primary advantage of this framework is to discovercommon sub-trajectories from a trajectory database. Based on this partition-and-groupframework; we develop a trajectory clustering algorithm TRACLUS. Our algorithm consists oftwo phases: partitioning and grouping. For the first phase; we present a formal trajectory …,Proceedings of the 2007 ACM SIGMOD international conference on Management of data,2007,1088
Trajectory outlier detection: A partition-and-detect framework,Jae-Gil Lee; Jiawei Han; Xiaolei Li,Outlier detection has been a popular data mining task. However; there is a lack of seriousstudy on outlier detection for trajectory data. Even worse; an existing trajectory outlierdetection algorithm has limited capability to detect outlying sub-trajectories. In this paper; wepropose a novel partition-and-detect framework for trajectory outlier detection; whichpartitions a trajectory into a set of line segments; and then; detects outlying line segments fortrajectory outliers. The primary advantage of this framework is to detect outlying sub-trajectories from a trajectory database. Based on this partition-and-detect framework; wedevelop a trajectory outlier detection algorithm TRAOD. Our algorithm consists of twophases: partitioning and detection. For the first phase; we propose a two-level trajectorypartitioning strategy that ensures both high quality and high efficiency. For the second …,Data Engineering; 2008. ICDE 2008. IEEE 24th International Conference on,2008,313
TraClass: trajectory classification using hierarchical region-based and trajectory-based clustering,Jae-Gil Lee; Jiawei Han; Xiaolei Li; Hector Gonzalez,Abstract Trajectory classification; ie; model construction for predicting the class labels ofmoving objects based on their trajectories and other features; has many important; real-world applications. A number of methods have been reported in the literature; but due tousing the shapes of whole trajectories for classification; they have limited classificationcapability when discriminative features appear at parts of trajectories or are not relevant tothe shapes of trajectories. These situations are often observed in long trajectories spreadingover large geographic areas. Since an essential task for effective classification is generatingdiscriminative features; a feature generation framework TraClass for trajectory data isproposed in this paper; which generates a hierarchy of features by partitioning trajectoriesand exploring two types of clustering:(1) region-based and (2) trajectory-based. The …,Proceedings of the VLDB Endowment,2008,264
Traffic density-based discovery of hot routes in road networks,Xiaolei Li; Jiawei Han; Jae-Gil Lee; Hector Gonzalez,Abstract Finding hot routes (traffic flow patterns) in a road network is an important problem.They are beneficial to city planners; police departments; real estate developers; and manyothers. Knowing the hot routes allows the city to better direct traffic or analyze congestioncauses. In the past; this problem has largely been addressed with domain knowledge of city.But in recent years; detailed information about vehicles in the road network have becomeavailable. With the development and adoption of RFID and other location sensors; anenormous amount of moving object trajectories are being collected and can be usedtowards finding hot routes. This is a challenging problem due to the complex nature of thedata. If objects traveled in organized clusters; it would be straightforward to use a clusteringalgorithm to find the hot routes. But; in the real world; objects move in unpredictable ways …,International Symposium on Spatial and Temporal Databases,2007,212
n-gram/2l: A space and time efficient two-level n-gram inverted index structure,Min-Soo Kim; Kyu-Young Whang; Jae-Gil Lee; Min-Jae Lee,Abstract The n-gram inverted index has two major advantages: language-neutral and error-tolerant. Due to these advantages; it has been widely used in information retrieval or insimilar sequence matching for DNA and protein databases. Nevertheless; the n-graminverted index also has drawbacks: the size tends to be very large; and the performance ofqueries tends to be bad. In this paper; we propose the two-level n-gram inverted index(simply; the n-gram/2L index) that significantly reduces the size and improves the queryperformance while preserving the advantages of the n-gram inverted index. The proposedindex eliminates the redundancy of the position information that exists in the n-gram invertedindex. The proposed index is constructed in two steps: 1) extracting subsequences of lengthm from documents and 2) extracting n-grams from those subsequences. We formally …,Proceedings of the 31st international conference on Very large data bases,2005,111
Incremental clustering for trajectories,Zhenhui Li; Jae-Gil Lee; Xiaolei Li; Jiawei Han,Abstract Trajectory clustering has played a crucial role in data analysis since it revealsunderlying trends of moving objects. Due to their sequential nature; trajectory data are oftenreceived incrementally; eg; continuous new points reported by GPS system. However; sinceexisting trajectory clustering algorithms are developed for static datasets; they are notsuitable for incremental clustering with the following two requirements. First; clusteringshould be processed efficiently since it can be frequently requested. Second; huge amountsof trajectory data must be accommodated; as they will accumulate constantly. Anincremental clustering framework for trajectories is proposed in this paper. It contains twoparts: online micro-cluster maintenance and offline macro-cluster creation. For online part;when a new bunch of trajectories arrives; each trajectory is simplified into a set of directed …,International Conference on Database Systems for Advanced Applications,2010,110
MoveMine: mining moving object databases,Zhenhui Li; Ming Ji; Jae-Gil Lee; Lu-An Tang; Yintao Yu; Jiawei Han; Roland Kays,Abstract With the maturity of GPS; wireless; and Web technologies; increasing amounts ofmovement data collected from various moving objects; such as animals; vehicles; mobiledevices; and climate radars; have become widely available. Analyzing such data has broadapplications; eg; in ecological study; vehicle control; mobile communication management;and climatological forecast. However; few data mining tools are available for flexible andscalable analysis of massive-scale moving object data. Our system; MoveMine; is designedfor sophisticated moving object data mining by integrating several attractive functionsincluding moving object pattern mining and trajectory mining. We explore the state-of-the-artand novel techniques at implementation of the selected functions. A user-friendly interface isprovided to facilitate interactive exploration of mining results and flexible tuning of the …,Proceedings of the 2010 ACM SIGMOD International Conference on Management of data,2010,107
Temporal outlier detection in vehicle traffic data,Xiaolei Li; Zhenhui Li; Jiawei Han; Jae-Gil Lee,Outlier detection in vehicle traffic data is a practical problem that has gained traction latelydue to an increasing capability to track moving vehicles in city roads. In contrast to otherapplications; this particular domain includes a very dynamic dimension: time. Many existingalgorithms have studied the problem of outlier detection at a single instant in time. This studyproposes a method for detecting temporal outliers with an emphasis on historical similaritytrends between data points. Outliers are calculated from drastic changes in the trends.Experiments with real world traffic data show that this approach is effective and efficient.,Data Engineering; 2009. ICDE'09. IEEE 25th International Conference on,2009,102
Movemine: Mining moving object data for discovery of animal movement patterns,Zhenhui Li; Jiawei Han; Ming Ji; Lu-An Tang; Yintao Yu; Bolin Ding; Jae-Gil Lee; Roland Kays,Abstract With the maturity and wide availability of GPS; wireless; telecommunication; andWeb technologies; massive amounts of object movement data have been collected fromvarious moving object targets; such as animals; mobile devices; vehicles; and climateradars. Analyzing such data has deep implications in many applications; such as; ecologicalstudy; traffic control; mobile communication management; and climatological forecast. In thisarticle; we focus our study on animal movement data analysis and examine advanced datamining methods for discovery of various animal movement patterns. In particular; weintroduce a moving object data mining system; MoveMine; which integrates multiple datamining functions; including sophisticated pattern mining and trajectory analysis. In thissystem; two interesting moving object pattern mining functions are newly developed:(1) …,ACM Transactions on Intelligent Systems and Technology (TIST),2011,84
Mining discriminative patterns for classifying trajectories on road networks,Jae-Gil Lee; Jiawei Han; Xiaolei Li; Hong Cheng,Classification has been used for modeling many kinds of data sets; including sets of items;text documents; graphs; and networks. However; there is a lack of study on a new kind ofdata; trajectories on road networks. Modeling such data is useful with the emerging GPS andRFID technologies and is important for effective transportation and traffic planning. In thiswork; we study methods for classifying trajectories on road networks. By analyzing thebehavior of trajectories on road networks; we observe that; in addition to the locations wherevehicles have visited; the order of these visited locations is crucial for improvingclassification accuracy. Based on our analysis; we contend that (frequent) sequentialpatterns are good feature candidates since they preserve this order information.Furthermore; when mining sequential patterns; we propose to confine the length of …,IEEE Transactions on Knowledge and Data Engineering,2011,82
Geospatial big data: challenges and opportunities,Jae-Gil Lee; Minseo Kang,Abstract Geospatial big data refers to spatial data sets exceeding capacity of currentcomputing systems. A significant portion of big data is actually geospatial data; and the sizeof such data is growing rapidly at least by 20% every year. In this paper; we explore thechallenges and opportunities which geospatial big data brought us. Several case studiesare introduced to show the importance and benefits of the analytics of geospatial big data;including fuel and time saving; revenue increase; urban planning; and health care. Then; weintroduce new emerging platforms for sharing the collected geospatial big data and fortracking human mobility via mobile devices. The researchers in academia and industry havespent a lot of efforts to improve the value of geospatial big data as well as take advantage ofits value. Along the same line; we present our current research activities toward the …,Big Data Research,2015,80
Continuous query processing in data streams using duality of data and queries,Hyo-Sang Lim; Jae-Gil Lee; Min-Jae Lee; Kyu-Young Whang; Il-Yeol Song,Abstract Recent data stream systems such as TelegraphCQ have employed the well-knownproperty of duality between data and queries. In these systems; query processing methodsare classified into two dual categories--data-initiative and query-initiative--depending onwhether query processing is initiated by selecting a data element or a query. Although theduality property has been widely recognized; previous data stream systems do not fully takeadvantages of this property since they use the two dual methods independently: data-initiative methods only for continuous queries and query-initiative methods only for ad-hocqueries. We contend that continuous query processing can be better optimized by adoptingan approach that integrates the two dual methods. Our primary contribution is based on theobservation that spatial join is a powerful tool for achieving this objective. In this paper …,Proceedings of the 2006 ACM SIGMOD international conference on Management of data,2006,64
Spatial join processing using corner transformation,Ju-Won Song; Kyu-Young Whang; Young-Koo Lee; Min-Jae Lee,Spatial join finds pairs of spatial objects having a specific spatial relationship in spatialdatabase systems. Since spatial join is a fairly expensive operation; we need an efficientalgorithm taking advantage of the characteristics of available spatial access methods. In thispaper; we propose a spatial join algorithm using corner transformation and show itsexcellence through experiments. To the extent of authors' knowledge; the spatial joinprocessing using corner transformation is new. In corner transformation; two regions in onefile joined with two adjacent regions in the other file share a large common area. Theproposed algorithm utilizes this property in order to reduce the number of disk accesses forspatial join. Experimental results show that the performance of the algorithm is generallybetter than that of the R*-tree based algorithm proposed by Brinkhoff et al.(1993. 1994) …,IEEE Transactions on Knowledge and Data Engineering,1999,44
LinkSCAN*: Overlapping community detection using the link-space transformation,Sungsu Lim; Seungwoo Ryu; Sejeong Kwon; Kyomin Jung; Jae-Gil Lee,In this paper; for overlapping community detection; we propose a novel framework of the link-space transformation that transforms a given original graph into a link-space graph. Itsunique idea is to consider topological structure and link similarity separately using twodistinct types of graphs: the line graph and the original graph. For topological structure; eachlink of the original graph is mapped to a node of the link-space graph; which enables us todiscover overlapping communities using non-overlapping community detection algorithmsas in the line graph. For link similarity; it is calculated on the original graph and carried overinto the link-space graph; which enables us to keep the original structure on the transformedgraph. Thus; our transformation; by combining these two advantages; facilitates overlappingcommunity detection as well as improves the resulting quality. Based on this framework …,Data Engineering (ICDE); 2014 IEEE 30th International Conference on,2014,43
Odysseus: a high-performance ORDBMS tightly-coupled with IR features,Kyu-Young Whang; Min-Jae Lee; Jae-Gil Lee; Min-Soo Kim; Wook-Shin Han,We propose the notion of tight-coupling [K. Whang et al.;(1999)] to add new data types intothe DBMS engine. In this paper; we introduce the Odysseus ORDBMS and present its tightly-coupled IR features (US patented). We demonstrate a Web search engine capable ofmanaging 20 million Web pages in a non-parallel configuration using Odysseus.,Data Engineering; 2005. ICDE 2005. Proceedings. 21st International Conference on,2005,41
Mining massive rfid; trajectory; and traffic data sets,Jiawei Han; Jae-Gil Lee; Hector Gonzalez; Xiaolei Li,*,Proceedings of the 14th ACM SIGKDD international conference on Knowledge discovery and data mining,2008,40
An overview of clustering methods in geographic data analysis,Jiawei Han; Jae-Gil Lee; Micheline Kamber,Clustering is the process of grouping a set of physical or abstract objects into classes ofsimilar objects. A cluster is a collection of data objects that are similar to one another withinthe same cluster and are dissimilar to the objects in other clusters. Although classification isan effective means for distinguishing groups or classes of objects; it often requires costlycollection and labeling of a large set of training tuples or patterns; which the classifier usesto model each group. In contrast; clustering does not require such labeling at all. Clusteranalysis has been widely used in numerous applications; including market research; patternrecognition; data analysis; and image processing. In business; clustering can help marketersdiscover distinct groups in their customer bases and characterize customer groups based onpurchasing patterns. In biology; it can be used to derive plant and animal taxonomies …,Geographic data mining and knowledge discovery,2009,35
Sampling cube: a framework for statistical olap over sampling data,Xiaolei Li; Jiawei Han; Zhijun Yin; Jae-Gil Lee; Yizhou Sun,Abstract Sampling is a popular method of data collection when it is impossible or too costlyto reach the entire population. For example; television show ratings in the United States aregathered from a sample of roughly 5;000 households. To use the results effectively; thesamples are further partitioned in a multidimensional space based on multiple attributevalues. This naturally leads to the desirability of OLAP (Online Analytical Processing) oversampling data. However; unlike traditional data; sampling data is inherently uncertain; ie; notrepresenting the full data in the population. Thus; it is desirable to return not only queryresults but also the confidence intervals indicating the reliability of the results. Moreover; acertain segment in a multidimensional space may contain none or too few samples. Thisrequires some additional analysis to return trustable results. In this paper we propose a …,Proceedings of the 2008 ACM SIGMOD international conference on Management of data,2008,35
Community detection in multi-layer graphs: A survey,Jungeun Kim; Jae-Gil Lee,Abstract Community detection; also known as graph clustering; has been extensivelystudied in the literature. The goal of community detection is to partition vertices in a complexgraph into densely-connected components socalled communities. In recent applications;however; an entity is associated with multiple aspects of relationships; which brings newchallenges in community detection. The multiple aspects of interactions can be modeled asa multi-layer graph comprised of multiple interdependent graphs; where each graphrepresents an aspect of the interactions. Great efforts have therefore been made to tackle theproblem of community detection in multi-layer graphs. In this survey; we provide readers witha comprehensive understanding of community detection in multi-layer graphs and comparethe state-of-the-art algorithms with respect to their underlying properties.,ACM SIGMOD Record,2015,33
Business Analytics in (a) Blink.,Ronald Barber; Peter Bendel; Marco Czech; Oliver Draese; Frederick Ho; Namik Hrle; Stratos Idreos; Min-Soo Kim; Oliver Koeth; Jae-Gil Lee; Tianchao Tim Li; Guy M Lohman; Konstantinos Morfonios; René Müller; Keshava Murthy; Ippokratis Pandis; Lin Qiao; Vijayshankar Raman; Richard Sidle; Knut Stolze; Sandor Szabo,Abstract The Blink project's ambitious goal is to answer all Business Intelligence (BI) queriesin mere seconds; regardless of the database size; with an extremely low total cost ofownership. Blink is a new DBMS aimed primarily at read-mostly BI query processing thatexploits scale-out of commodity multi-core processors and cheap DRAM to retain a (copy ofa) data mart completely in main memory. Additionally; it exploits proprietary compressiontechnology and cache-conscious algorithms that reduce memory bandwidth consumptionand allow most SQL query processing to be performed on the compressed data. Blinkalways scans (portions of) the data mart in parallel on all nodes; without using any indexesor materialized views; and without any query optimizer to choose among them. The Blinktechnology has thus far been incorporated into two IBM accelerator products generally …,IEEE Data Eng. Bull.,2012,30
Secure query processing against encrypted XML data using Query-Aware Decryption,Jae-Gil Lee; Kyu-Young Whang,Abstract Dissemination of XML data on the internet could breach the privacy of dataproviders unless access to the disseminated XML data is carefully controlled. Recently; themethods using encryption have been proposed for such access control. However; in thesemethods; the performance of processing queries has not been addressed. A queryprocessor cannot identify the contents of encrypted XML data unless the data are decrypted.This limitation incurs overhead of decrypting the parts of the XML data that would notcontribute to the query result. In this paper; we propose the notion of Query-AwareDecryption for efficient processing of queries against encrypted XML data. Query-AwareDecryption allows us to decrypt only those parts that would contribute to the query result. Forthis purpose; we disseminate an encrypted XML index along with the encrypted XML data …,Information sciences,2006,30
Scalable community detection from networks by computing edge betweenness on mapreduce,Seunghyeon Moon; Jae-Gil Lee; Minseo Kang,Community detection from social network data gains much attention from academia andindustry since it has many real-world applications. The Girvan-Newman (GN) algorithm is adivisive hierarchical clustering algorithm for community detection; which is regarded as oneof the most popular algorithms. It exploits the concept of edge betweenness to divide anetwork into multiple communities. Though it is being widely used; it has limitations insupporting large-scale networks since it needs to calculate the shortest path between everypair of nodes in a network. In this paper; we develop a parallel version of the GN algorithm tosupport large-scale networks. To this end; we propose a new algorithm; which we callShortest Path Betweenness MapReduce Algorithm (SPB-MRA); that utilizes the MapReducemodel. This algorithm consists of four major stages; and all operations are executed in …,Big Data and Smart Computing (BIGCOMP); 2014 International Conference on,2014,26
The dynamic predicate: integrating access control with query processing in XML databases,Jae-Gil Lee; Kyu-Young Whang; Wook-Shin Han; Il-Yeol Song,Abstract Recently; access control on XML data has become an important research topic.Previous research on access control mechanisms for XML data has focused on increasingthe efficiency of access control itself; but has not addressed the issue of integrating accesscontrol with query processing. In this paper; we propose an efficient access controlmechanism tightly integrated with query processing for XML databases. We present thenovel concept of the dynamic predicate (DP); which represents a dynamically constructedcondition during query execution. A DP is derived from instance-level authorizations andconstrains accessibility of the elements. The DP allows us to effectively integrateauthorization checking into the query plan so that unauthorized elements are excluded inthe process of query execution. Experimental results show that the proposed access …,The VLDB Journal,2007,25
Booming Up the Long Tails: Discovering Potentially Contributive Users in Community-Based Question Answering Services.,Juyup Sung; Jae-Gil Lee; Uichin Lee,Abstract Community-based question answering (CQA) services such as Yahoo! Answershave been widely used by Internet users to get the answers for their inquiries. The CQAservices totally rely on the contributions by the users. However; it is known that newcomersare prone to lose their interests and leave the communities. Thus; finding expert users in anearly phase when they are still active is essential to improve the chances of motivating themto contribute to the communities further. In this paper; we propose a novel approach todiscovering “potentially” contributive users from recently-joined users in CQA services. Thelikelihood of becoming a contributive user is defined by the user's expertise as well asavailability; which we call the answer affordance. The main technical difficulty lies in the factthat such recently-joined users do not have abundant information accumulated for many …,ICWSM,2013,21
Structural optimization of a full-text n-gram index using relational normalization,Min-Soo Kim; Kyu-Young Whang; Jae-Gil Lee; Min-Jae Lee,Abstract As the amount of text data grows explosively; an efficient index structure for largetext databases becomes ever important. The n-gram inverted index (simply; the n-gramindex) has been widely used in information retrieval or in approximate string matching dueto its two major advantages: language-neutral and error-tolerant. Nevertheless; the n-gramindex also has drawbacks: the size tends to be very large; and the performance of queriestends to be bad. In this paper; we propose the two-level n-gram inverted index (simply; the n-gram/2L index) that significantly reduces the size and improves the query performance byusing the relational normalization theory. We first identify that; in the (full-text) n-gram index;there exists redundancy in the position information caused by a non-trivial multivalueddependency. The proposed index eliminates such redundancy by constructing the index …,The VLDB Journal—The International Journal on Very Large Data Bases,2008,17
n-Gram/2L-approximation: a two-level n-gram inverted index structure for approximate string matching,M Kim; K Whang; J Lee,Approximate string matching is to find all the occurrences of a query string in a text databaseallowing a specified number of errors. Approximate string matching based on the n-graminverted index (simply; n-gram Matching) has been widely used. A major reason is that it isscalable for large databases since it is not a main memory algorithm. Nevertheless; n-gramMatching also has drawbacks: the query performance tends to be bad; and many falsepositives occur if a large number of errors are allowed. In this paper; we propose an invertedindex structure; which we call the n-gram/2L-Approximation index; that improves thesedrawbacks and an approximate string matching algorithm based on it. The n-gram/2L-Approximation is an adaptation of the n-gram/2L index [4]; which the authors have proposedearlier for exact matching. Inheriting the advantages of the n-gram/2L index; the n-gram …,Computer Systems Science and Engineering,2007,16
A unifying framework of mining trajectory patterns of various temporal tightness,Jae-Gil Lee; Jiawei Han; Xiaolei Li,Discovering trajectory patterns is shown to be very useful in learning interactions betweenmoving objects. Many types of trajectory patterns have been proposed in the literature; butprevious methods were developed for only a specific type of trajectory patterns. Thislimitation could make pattern discovery tedious and inefficient since users typically do notknow which types of trajectory patterns are hidden in their data sets. Our main observation isthat many trajectory patterns can be arranged according to the strength of temporalconstraints. In this paper; we propose a unifying framework of mining trajectory patterns ofvarious temporal tightness; which we call unifying trajectory patterns (UT-patterns). Thisframework consists of two phases: initial pattern discovery and granularity adjustment. A setof initial patterns are discovered in the first phase; and their granularities (ie; levels of …,IEEE Transactions on Knowledge and Data Engineering,2015,15
Two-level n-gram index structure and methods of index building; query processing and index derivation,*,Disclosed relates to a structure of two-level n-gram inverted index and methods of buildingthe same; processing queries and deriving the index that reduce the size of n-gram invertedindex and improves the query performance by eliminating the redundancy of the positioninformation that exists in the n-gram inverted index. The inverted index of the presentinvention comprises a back-end inverted index using subsequences extracted fromdocuments as a term and a front-end inverted index using n-grams extracted from thesubsequences as a term. The back-end inverted index uses the subsequences of a specificlength extracted from the documents to be overlapped with each other by n− 1 (n: the lengthof n-gram) as a term and stores position information of the subsequences occurring in thedocuments in a posting list for the respective subsequences. The front-end inverted index …,*,2010,13
Blink: Not Your Father’s Database!,Ronald Barber; Peter Bendel; Marco Czech; Oliver Draese; Frederick Ho; Namik Hrle; Stratos Idreos; Min-Soo Kim; Oliver Koeth; Jae-Gil Lee; Tianchao Tim Li; Guy Lohman; Konstantinos Morfonios; Rene Mueller; Keshava Murthy; Ippokratis Pandis; Lin Qiao; Vijayshankar Raman; Sandor Szabo; Richard Sidle; Knut Stolze,Abstract The Blink project's ambitious goals are to answer all Business Intelligence (BI)queries in mere seconds; regardless of the database size; with an extremely low total cost ofownership. It takes a very innovative and counter-intuitive approach to processing BIqueries; one that exploits several disruptive hardware and software technology trends.Specifically; it is a new; workload-optimized DBMS aimed primarily at BI query processing;and exploits scale-out of commodity multi-core processors and cheap DRAM to retain a(copy of a) data mart completely in main memory. Additionally; it exploits proprietarycompression technology and cache-conscious algorithms that reduce memory bandwidthconsumption and allow most SQL query processing to be performed on the compresseddata. Ignoring the general wisdom of the last three decades that the only way to scalably …,International Workshop on Business Intelligence for the Real-Time Enterprise,2011,11
Parallel community detection on large graphs with MapReduce and GraphChi,Seunghyeon Moon; Jae-Gil Lee; Minseo Kang; Minsoo Choy; Jin-woo Lee,Abstract Community detection from social network data gains much attention from academiaand industry since it has many real-world applications. The Girvan–Newman (GN) algorithmis a divisive hierarchical clustering algorithm for community detection; which is regarded asone of the most popular algorithms. It exploits the concept of edge betweenness to divide anetwork into multiple communities. Though it is being widely used; it has limitations insupporting large-scale networks since it needs to calculate the shortest path between everypair of vertices in a network. In this paper; we develop two parallel versions of the GNalgorithm to support large-scale networks. First; we propose a new algorithm; which we callShortest Path Betweenness MapReduce Algorithm (SPB-MRA); that utilizes the MapReducemodel. Second; we propose another new algorithm; which we call Shortest Path …,Data & Knowledge Engineering,2016,10
Tightly-coupled spatial database features in the Odysseus/OpenGIS DBMS for high-performance,Kyu-Young Whang; Jae-Gil Lee; Min-Soo Kim; Min-Jae Lee; Ki-Hoon Lee; Wook-Shin Han; Jun-Sung Kim,Abstract Conventional object-relational database management system (ORDBMS) vendorsprovide extension mechanisms for adding user-defined types and functions to their ownDBMSs. Here; the extension mechanisms are implemented using a high-level (typically;SQL-level) interface. We call this mechanism loose-coupling. The advantage of loose-coupling is that it is easy to implement. However; it is not preferable for implementing newdata types and operations in large databases when high performance is required. We haveearlier proposed the tight-coupling architecture (Whang et al. 2002; 2005) to satisfy thisrequirement. In tight-coupling; new data types and operations are integrated into the core ofthe DBMS engine in the extensible type layer. Thus; they are supported in a consistentmanner with high performance. This tight-coupling architecture is being used to …,GeoInformatica,2010,10
Joins on encoded and partitioned data,Jae-Gil Lee; Gopi Attaluri; Ronald Barber; Naresh Chainani; Oliver Draese; Frederick Ho; Stratos Idreos; Min-Soo Kim; Sam Lightstone; Guy Lohman; Konstantinos Morfonios; Keshava Murthy; Ippokratis Pandis; Lin Qiao; Vijayshankar Raman; Vincent Kulandai Samy; Richard Sidle; Knut Stolze; Liping Zhang,Abstract Compression has historically been used to reduce the cost of storage; I/Os from thatstorage; and buffer pool utilization; at the expense of the CPU required to decompress dataevery time it is queried. However; significant additional CPU efficiencies can be achieved bydeferring decompression as late in query processing as possible and performing queryprocessing operations directly on the still-compressed data. In this paper; we investigate thebenefits and challenges of performing joins on compressed (or encoded) data. Wedemonstrate the benefit of independently optimizing the compression scheme of each joincolumn; even though join predicates relating values from multiple columns may requiretranslation of the encoding of one join column into the encoding of the other. We also showthe benefit of compressing" payload" data other than the join columns" on the fly;" to …,Proceedings of the VLDB Endowment,2014,9
Hippocratic XML databases: a model and an access control mechanism,Jae-Gil Lee; Kyu-Young Whang; W Han; I Song,Abstract The Hippocratic database model recently proposed by Agrawal et al. incorporatesprivacy protection capabilities into relational databases. Since the Hippocratic database isbased on the relational database; it needs extensions to be adapted for XML databases. Inthis paper; we propose the Hippocratic XML database model; an extension of theHippocratic database model for XML databases and present an efficient access controlmechanism under this model. In contrast to relational data; XML data have tree-likehierarchies. Thus; in order to manage these hierarchies of XML data; we extend and formallydefine concepts presented in the Hippocratic database model. Next; we present a newmechanism; which we call the authorization index; that is used in the access controlmechanism. This authorization index; which is implemented using a multi-dimensional …,COMPUTER SYSTEMS SCIENCE AND ENGINEERING,2006,9
Looking back on the current day: interruptibility prediction using daily behavioral features,Minsoo Choy; Daehoon Kim; Jae-Gil Lee; Heeyoung Kim; Hiroshi Motoda,Abstract When a person seeks another person's attention; it is of prime importance to assesshow interruptible the other person is. Since smartphones are ubiquitously used ascommunication media these days; interruptibility prediction on smartphones has started toattract great interest from both academia and industry. Previous studies; in general;attempted to model interruptibility using the behaviors at the current moment and in theimmediate past (eg; 5 minutes before). However; a person's interruptibility at a certainmoment is indeed affected by his/her preceding behaviors for several reasons. Motivated bythis long-term effect; in this paper we propose a novel methodology of extracting featuresbased on past behaviors from smartphone sensor data. The primary difference fromprevious studies is that we systematically consider a longer history of up to a day in …,Proceedings of the 2016 ACM international joint conference on pervasive and ubiquitous computing,2016,7
Glaucus: Exploiting the Wisdom of Crowds for Location-Based Queries in Mobile Environments.,Minsoo Choy; Jae-Gil Lee; Gahgene Gweon; Daehoon Kim,Abstract In this paper; we build a social search engine named Glaucus for location-basedqueries. They compose a significant portion of mobile searches; thus becoming morepopular with the prevalence of mobile devices. However; most of existing social searchengines are not designed for location-based queries and thus often produce poor-qualityresults for such queries. Glaucus is inherently designed to support locationbased queries. Itcollects the check-in information; which pinpoints the places where each user visited; fromlocation-based social networking services such as Foursquare. Then; it calculates theexpertise of each user for a query by using our new probabilistic model called the locationaspect model. We conducted two types of evaluation to prove the effectiveness of ourengine. The results showed that Glaucus selected the users supported by stronger …,ICWSM,2014,7
The influence in twitter: Are they really influenced?,Juyup Sung; Seunghyeon Moon; Jae-Gil Lee,Abstract Twitter is a popular social network service which is continuously growing. BecauseTwitter has become an efficient platform for advertising companies as a new vast medium; itis obvious that finding influential Twitter users and measuring their influence are important.Intuitively; users who have more followers are likely to be more influential. However; thenumber of followers does not necessarily mean the confidence of influence. In order to findinfluential users in Twitter more precisely; in this paper; we present an improvement ofPageRank; which we call InterRank (Inter action Rank). It considers not only the followerrelationship of the network but also topical similarity between users from tweet context. Byusing retweet information; we verify that topical similarity indeed affects the influence of auser. Then; we compare InterRank to PageRank with an assumption that influential users …,*,2013,7
A practitioner’s approach to normalizing XQuery expressions,Ki-Hoon Lee; Seo-Young Kim; Euijong Whang; Jae-Gil Lee,Abstract XQuery becomes a standard of the XML query language. Just like in SQL; XQueryallows nested expressions. To optimize XQuery processing; a lot of research has been doneon normalization; ie; transforming nested expressions to equivalent unnested ones.Previous normalization rules are classified into two categories–source-level and algebra-level–depending on whether a construct is specified by using a query language or analgebraic expression. In implementation point of view; we contend that the source-level ruleis preferable to the algebra-level rule because algebras used for normalization are hard tobe directly exploited in a typical DBMS. However; a complete set of source-level rules is yetto be developed. In this paper; we propose source-level rules for normalizing XQueryexpressions and present an implementation mechanism. We show that our rules are …,International Conference on Database Systems for Advanced Applications,2006,6
Adaptive row major order: a new space filling curve for efficient spatial join processing in the transform space,Min-Jae Lee; Kyu-Young Whang; Wook-Shin Han; Il-Yeol Song,Abstract A transform-space index indexes spatial objects represented as points in thetransform space. An advantage of a transform-space index is that optimization of spatial joinalgorithms using these indexes can be more formal. The authors earlier proposed theTransform-Based Spatial Join algorithm that joins two transform-space indexes. It rendersglobal optimization easy with little overhead by utilizing the characteristics of the transformspace. In particular; it allows us to globally determine the order of accessing disk pages;which makes a significant impact on the performance of joins. For this purpose; we usevarious space filling curves. In this paper; we propose a new space filling curve called theadaptive row major order (ARM order). The ARM order adaptively controls the order ofaccessing pages and significantly reduces the one-pass buffer size (the minimum buffer …,Journal of Systems and Software,2005,6
DB-IR integration using tight-coupling in the Odysseus DBMS,Kyu-Young Whang; Jae-Gil Lee; Min-Jae Lee; Wook-Shin Han; Min-Soo Kim; Jun-Sung Kim,Abstract As many recent applications require integration of structured data and text data;unifying database (DB) and information retrieval (IR) technologies has become one of majorchallenges in our field. There have been active discussions on the system architecture forDB-IR integration; but a clear agreement has not been reached yet. Along this direction; wehave advocated the use of the tight-coupling architecture and developed a novel structure ofthe IR index as well as tightly-coupled query processing algorithms. In tight-coupling; the textdata type is supported from the storage system just like a built-in data type so that the queryprocessor can efficiently handle queries involving both structured data and text data. In thispaper; for archival purposes; we consolidate our achievements reported at non-regularpublications over the last ten years or so; extending them by adding greater details on the …,World Wide Web,2015,5
On finding fine-granularity user communities by profile decomposition,Seulki Lee; Minsam Ko; Keejun Han; Jae-Gil Lee,The social network represents various relationships between users; and communitydiscovery is one of the most popular tasks analyzing these relationships. The relationshipsare either explicit (eg; friends) or implicit; and we focus on community discovery with implicitrelationships. Here; the key issue is how to extract the relationships between users. A user istypically represented by his/her profile; and the similarity between user profiles is measured.In most algorithms; a user has a single profile aggregating all the information about the user.For example; a profile for a researcher is a list of papers he/she wrote. This setting; however;oversimplifies the multiple characteristics of a man since individual characteristics are mixedup. In this paper; we propose the notion and method of profile decomposition; which dividesa profile into a set of sub-profiles so that they represent individual characteristics precisely …,Advances in Social Networks Analysis and Mining (ASONAM); 2012 IEEE/ACM International Conference on,2012,5
Quality-based automatic classification for presentation slides,Seongchan Kim; Wonchul Jung; Keejun Han; Jae-Gil Lee; Y Yi Mun,Abstract Computerized presentation slides have become essential for effective businessmeetings; classroom discussions; and even general events and occasions. With theexploding number of online resources and materials; locating the slides of high quality is adaunting challenge. In this study; we present a new; comprehensive framework ofinformation quality developed specifically for computerized presentation slides on the basisof a user study involving 60 university students from two universities and extensive codinganalysis; and explore the possibility of automatically detecting the information quality ofslides. Using the classifications made by human annotators as the golden standard; wecompare and evaluate the performance of alternative information quality features anddimensions. The experimental results support the validity of the proposed approach in …,European Conference on Information Retrieval,2014,4
Odysseus: a high-performance ORDBMS tightly-coupled with spatial database features,Kyu-Young Whang; Jae-Gil Lee; Min-Soo Kim; Min-Jae Lee; Ki-Hoon Lee,We have earlier proposed the tight-coupling architecture for adding new data types into theDBMS engine. In this paper; we introduce the Odysseus ORDBMS and present its tightly-coupled spatial database features. We demonstrate a geographical information system (GIS)implemented using Odysseus.,Data Engineering; 2007. ICDE 2007. IEEE 23rd International Conference on,2007,4
Transformation-based spatial join,Ju-Won Song; Kyu-Young Whang; Young-Koo Lee; Min-Jae Lee; Sang-Wook Kim,Abstract Spatial join finds pairs of spatial objects having a specific spatial relationship inspatial database systems. A number of spatial join algorithms have recently been proposedin the literature. Most of them; however; perform the join in the original space. Joining in theoriginal space has a drawback of dealing with sizes of objects and thus has difficulty indeveloping a formal algorithm that does not rely on heuristics. In this paper; we propose aspatial join algorithm based on the transformation technique. An object having a size in thetwo-dimensional original space is transformed into a point in the four-dimensional transformspace; and the join is performed on these point objects. This can be easily extended to n-dimensional cases. We show the excellence of the proposed approach through analysis andextensive experiments. The results show that the proposed algorithm has a performance …,Proceedings of the eighth international conference on Information and knowledge management,1999,4
Apam: Adaptive eager-lazy hybrid evaluation of event patterns for low latency,Ilyeop Yi; Jae-Gil Lee; Kyu-Young Whang,Abstract Event pattern detection refers to identifying combinations of events matched to auser-specified query event pattern from a real-time event stream. Latency is an importantmeasure of the performance of an event pattern detection system. Existing methods can beclassified into the eager evaluation method and the lazy evaluation method depending onwhen each event arrival is evaluated. These methods have advantages and disadvantagesin terms of latency depending on the event arrival rate. In this paper; we propose a hybrideager-lazy evaluation method that combines the advantages of both methods. For eachevent type; the hybrid method; which we call APAM (Adaptive Partitioning-And-Merging);determines which method to use: eager or lazy. We also propose a formal cost model toestimate the latency and propose a method of finding the optimal partition based on the …,Proceedings of the 25th ACM International on Conference on Information and Knowledge Management,2016,3
BlackHole: Robust community detection inspired by graph drawing,Sungsu Lim; Junghoon Kim; Jae-Gil Lee,With regard to social network analysis; we concentrate on two widely-accepted buildingblocks: community detection and graph drawing. Although community detection and graphdrawing have been studied separately; they have a great commonality; which means that itis possible to advance one field using the techniques of the other. In this paper; we proposea novel community detection algorithm for undirected graphs; called BlackHole; by importinga geometric embedding technique from graph drawing. Our proposed algorithm transformsthe vertices of a graph to a set of points on a low-dimensional space whose coordinates aredetermined by a variant of graph drawing algorithms; following the overall procedure ofspectral clustering. The set of points are then clustered using a conventional clusteringalgorithm to form communities. Our primary contribution is to prove that a common idea in …,Data Engineering (ICDE); 2016 IEEE 32nd International Conference on,2016,3
Multithreaded data merging for multi-core processing unit,*,Described herein are methods; systems; apparatuses and products for multithreaded datamerging for multi-core central and graphical processing units. An aspect provides forexecuting a plurality of threads on at least one central processing unit comprising a pluralityof cores; each thread comprising an input data set (IDS) and being executed on one of theplurality of cores; initializing at least one local data set (LDS) comprising a size and athreshold; inserting IDS data elements into the at least one LDS such that each inserted IDSdata element increases the size of the at least one LDS; and merging the at least one LDSinto a global data set (GDS) responsive to the size of the at least one LDS being greater thanthe threshold. Other aspects are disclosed herein.,*,2013,3
Topical influence modeling via topic-level interests and interactions on social curation services,Daehoon Kim; Jae-Gil Lee; Byung Suk Lee,Social curation services are emerging social media platforms that enable users to curatetheir contents according to the topic and express their interests at the topic level by followingcurated collections of other users' contents rather than the users themselves. The topic-levelinformation revealed through this new feature far exceeds what existing methods solicit fromthe traditional social networking services; to greatly enhance the quality of topic-sensitiveinfluence modeling. In this paper; we propose a novel model called the topical influence withsocial curation (TISC) to find influential users from social curation services. This model;formulated by the continuous conditional random field; fully takes advantage of the explicitlyavailable topic-level information reflected in both contents and interactions. In order tovalidate its merits; we comprehensively compare TISC with state-of-the-art models using …,Data Engineering (ICDE); 2016 IEEE 32nd International Conference on,2016,1
Method and apparatus for providing location-based social search service,*,Provided is a method of providing a location-based social search service. The methodincludes collecting; from a social network system; one or more pieces of visit historyinformation including at least one of visit information of social search service users inassociation with at least a place and review data associated with the place; and storing thecollected information; selecting a topic for each topic category from the visit historyinformation; when a location-based query is received from at least one of the users;extracting a topic for each topic category from the location-based query; analyzing; for eachtopic category; a relationship between the topic extracted from the location-based query andthe topic selected from the visit history information; and selecting at least one of the users asan expert.,*,2016,1
SocialKeyboard: Proofreading Everyday Writings in Mobile Phones,Jin-woo Lee; Joohyun Kim; Uichin Lee; Jae-Gil Lee,Abstract The flood tide of professional proofreading services has exceeded the marketdemand; but many pioneering competitors seem to be torn between quality and cost.Furthermore; proofreading of everyday writings has received little attention thus far; which isimportant for non-native speakers. In this paper; we propose SocialKeyboard that usesmobile crowd workers that can be contacted in a mobile environment. By embeddingproofreading features into existing mobile keyboards; SocialKeyboard also achieves easyaccess anytime and everywhere in mobile environments. Moreover; it aims to induce fasterresponses by implementing 1) Push based task assignment to mobile crowd workers; 2)Real-time track changes; and 3) Synchronous task chaining of proofreading and verification.We present a first working prototype of SocialKeyboard and describe the interplay …,Proceedings of the 33rd Annual ACM Conference Extended Abstracts on Human Factors in Computing Systems,2015,1
On Exploiting Tag Information for Community Detection on Flickr,Minsoo Choy; Woochul Sung; Jae-Gil Lee; Mun Yong Yi; Young-Ho Park,Abstract The social network service (SNS) has been gaining increasing attention. Among theextant SNSs; our study focuses on Flickr; which is one of the most popular photo hosting andsharing websites. Users can upload and explore many photos on various subjects. Inaddition; users sharing common interests can become friends; and they can join the groupsthat match their interests in particular subjects. Facebook's friend recommendation has beenproven to help users find potential friends easily; but Flickr is yet to offer friend or grouprecommendation services. For this reason; we propose a way of recommendingphotographically similar users and creating implicit user communities based on collectiveintelligence manifested through tag information. With a massive amount of tag data in Flickr;we represent users as feature vectors after carrying out tag preprocessing and selecting …,International Information Institute (Tokyo). Information,2014,1
An experimental analysis of limitations of MapReduce for iterative algorithms on Spark,Minseo Kang; Jae-Gil Lee,Abstract MapReduce is the most popular framework for distributed processing. Recently; thescalability of data mining and machine learning algorithms has significantly improved withhelp from MapReduce. However; MapReduce does not handle iterative algorithms veryefficiently. The problem is that many data mining and machine learning algorithms areiterative by nature. In order to overcome the limitations of MapReduce; many advanceddistributed systems have been developed; including HaLoop; iMapReduce; Twister; andSpark. In this paper; we identify and categorize the limitations of MapReduce in handlingiterative algorithms; and then; experimentally investigate the consequences of theselimitations by using the most flexible and stable distributed system; Spark. According to ourexperiment results; the network I/O overhead was the primary factor that affected system …,Cluster Computing,2017,*
PAMAE: Parallel k-Medoids Clustering with High Accuracy and Efficiency,Hwanjun Song; Jae-Gil Lee; Wook-Shin Han,Abstract The k-medoids algorithm is one of the best-known clustering algorithms. Despitethis; however; it is not as widely used for big data analytics as the k-means algorithm; mainlybecause of its high computational complexity. Many studies have attempted to solve theefficiency problem of the k-medoids algorithm; but all such studies have improved efficiencyat the expense of accuracy. In this paper; we propose a novel parallel k-medoids algorithm;which we call PAMAE; that achieves both high accuracy and high efficiency. We identify twofactors---" global search" and" entire data"---that are essential to achieving high accuracy;but are also very time-consuming if considered simultaneously. Thus; our key idea is toapply them individually through two phases: parallel seeding and parallel refinement;neither of which is costly. The first phase performs global search over sampled data; and …,Proceedings of the 23rd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining,2017,*
Boundary image matching supporting partial denoising using time-series matching techniques,Bum-Soo Kim; Yang-Sae Moon; Jae-Gil Lee,Abstract In this paper; we deal with the problem of boundary image matching which findssimilar boundary images regardless of partial noise exploiting time-series matchingtechniques. Time-seris matching techniques make it easier to compute distances forsimilarity identification; and therefore it is feasible to perform boundary image matching evenon a large image database. To solve this problem; we first convert all boundary images intotimes-series and derive partial denoising time-series. The partial denoising time-series isgenerated from an original time-series by removing partial noise; that is; it is obtained bychanging a position of partial denoising from original time-series. We then introduce thepartial denoising distance; which is the minimum distance from a query time-series to allpossible partial denoising time-series generated from a data time-series; and propose …,Multimedia Tools and Applications,2017,*
Efficient fall detection based on event pattern matching in image streams,Hyun-Gook Kang; Minseo Kang; Jae-Gil Lee,This work proposes sliding window fall detection match (SW-FDM); a rule-based falldetection method based on event pattern matching from human body posture event streams.Fall and post-fall (long lie) rules are expressed as patterns; and complex event processing(CEP) systems are adopted to quickly find these patterns. They can be detected with eventselection strategies such as Skip Till Next Match and Skip Till Any Match. However; existingstrategies generate either duplicate or missing alarms; even worse; their processing cost isvery high when the size of event streams is large. Since SW-FDM uses a concept of slidingwindow; it is able to detect correct matches constantly and reduce the processing costwithout duplicate computation. The experiments demonstrate that SW-FDM results in bothhigher accuracy and efficiency. Also; it is shown that the improvement of efficiency …,Big Data and Smart Computing (BigComp); 2017 IEEE International Conference on,2017,*
Multiplication-based method for stitching results of predicate evaluation in column stores,*,A system joins predicate evaluated column bitmaps having varying lengths. The systemincludes a column unifier for querying column values with a predicate and generating anindicator bit for each of the column values that is then joined with the respective columnvalue. The system also includes a bitmap generator for creating a column-major linearbitmap from the column values and indicator bits. The column unifier also determines anoffset between adjacent indicator bits. The system also includes a converter for multiplyingthe column-major linear bitmap with a multiplier to shift the indicator bits into consecutivepositions in the linear bitmap.,*,2015,*
Triangle counting in networks using a multi-level branching technique,Jungeun Kim; Minseo Kang; Sungsu Lim; Jae-Gil Lee,Counting triangles in networks is a fundamental problem in network science. In addition;because we are forced to manage very large real-world networks; current triangle countingalgorithms naturally require a distributed computing system. In this paper; we propose adistributed triangle counting algorithm based on both the vertex-centric and node-iteratormodels and using the multi-level branching technique. Multi-level branching is a method thatconstructs an ordered graph structure based on levels. This method not only facilitates anefficient triangle counting process; but also guarantees the computational integrity of eachsplit in the distributed triangle counting process. First; we describe a level-based trianglecounting algorithm based on both the vertex-centric model and the node-iterator algorithm.Then; we develop a distributed implementation of the proposed algorithm using GraphChi …,Big Data and Smart Computing (BigComp); 2015 International Conference on,2015,*
Method of detecting overlapping community in network,*,A method of detecting an overlapping community in a network including nodes and linksbetween the nodes; includes calculating a similarity between the links; and generating a linegraph of the network. The method further includes detecting one or more cores in the linegraph; and growing a cluster for each of the one or more cores. The method further includesconverting the cluster into a cluster of nodes of a node graph.,*,2014,*
Understanding the Difficulty Factors for Learning Materials: A Qualitative Study,Keejun Han; Y Yi Mun; Gahgene Gweon; Jae-Gil Lee,Abstract Difficult materials overwhelm learners whereas easy materials deter advancedknowledge acquisition. Toward the goal of automatic assessment of learning materials; weconducted a laboratory experiment involving 50 college students recruited from twouniversities in Korea using 115 PowerPoint files. On the basis of the qualitative analysisresults; we propose a model of learning difficulty; distinguishing measurable factors fromnon-measurable factors. The most influential factors for the easiest and the hardest learningmaterials are also identified and compared. The study findings have implications foreducational service providers who need to automatically classify learning materials basedon their innate difficulties.,International Conference on Artificial Intelligence in Education,2013,*
Transformation-based temporal aggregation using order-based buffer replacement strategy,Joon-Ho Woo; Byung Suk Lee; Min-Jae Lee; Jae-Gil Lee; Kyu-Young Whang,We present a new method for computing temporal aggregation based on dimensiontransformation. The novelty of our method lies in transforming the start time and end time ofone-dimensional temporal tuples to two-dimensional data points and storing the points in atwo-dimensional index. It then calculates temporal aggregates through a temporal joinbetween the data in the index and the base intervals (defined as the intervals delimited bythe start time or end time of the tuples). To enhance the performance; this method calculatesthe aggregates by incrementally modifying the aggregates from that of the previous baseinterval without re-reading all tuples for the current base interval. We further improve theefficiency with a new buffer page replacement technique that predicts the page access orderwithin the index. We demonstrate the efficacy of our method through experiments.,Comput. Syst. Sci. Eng.,2004,*
