CrowdDB: Answering queries with crowdsourcing,Michael Franklin; Donald Kossmann; Tim Kraska; Sukriti Ramesh; Reynold Xin,Abstract Some queries cannot be answered by machines only. Processing such queriesrequires human input for providing information that is missing from the database; forperforming computationally difficult functions; and for matching; ranking; or aggregatingresults based on fuzzy criteria. CrowdDB uses human input via crowdsourcing to processqueries that neither database systems nor search engines can adequately answer. It usesSQL both as a language for posing complex queries and as a way to model data. WhileCrowdDB leverages many aspects of traditional database systems; there are also importantdifferences. Conceptually; a major change is that the traditional closed-world assumption forquery processing does not hold for human input. From an implementation perspective;human-oriented query operators are needed to solicit; integrate and cleanse …,SIGMOD 2011,2011,567
MLlib: Machine Learning in Apache Spark,Xiangrui Meng; Joseph Bradley; Burak Yavuz; Evan Sparks; Shivaram Venkataraman; Davies Liu; Jeremy Freeman; DB Tsai; Manish Amde; Sean Owen; Doris Xin; Reynold Xin; Michael J Franklin; Reza Zadeh; Matei Zaharia; Ameet Talwalkar,Abstract Apache Spark is a popular open-source platform for large-scale data processingthat is well-suited for iterative machine learning tasks. In this paper we present MLlib;Spark's open-source distributed machine learning library. MLlib provides efficientfunctionality for a wide range of learning settings and includes several underlying statistical;optimization; and linear algebra primitives. Shipped with Spark; MLlib supports severallanguages and provides a high-level API that leverages Spark's rich ecosystem to simplifythe development of end-to-end machine learning pipelines. MLlib has experienced a rapidgrowth due to its vibrant open-source community of over 140 contributors; and includesextensive documentation to support further growth and to let users quickly get up to speed.,The Journal of Machine Learning Research,2016,511
GraphX: Graph Processing in a Distributed Dataflow Framework,Joseph E Gonzalez; Reynold S Xin; Ankur Dave; Daniel Crankshaw; Michael J Franklin; Ion Stoica,Abstract In pursuit of graph processing performance; the systems community has largelyabandoned general-purpose distributed dataflow frameworks in favor of specialized graphprocessing systems that provide tailored programming abstractions and accelerate theexecution of iterative graph algorithms. In this paper we argue that many of the advantagesof specialized graph processing systems can be recovered in a modern general-purposedistributed dataflow system. We introduce GraphX; an embedded graph processingframework built on top of Apache Spark; a widely used distributed dataflow system. GraphXpresents a familiar composable graph abstraction that is sufficient to express existing graphAPIs; yet can be implemented using only a few basic dataflow operators (eg; join; map;group-by). To achieve performance parity with specialized graph systems; GraphX …,OSDI 2014,2014,471
Spark SQL: Relational Data Processing in Spark,Michael Armbrust; Reynold S Xin; Cheng Lian; Yin Huai; Davies Liu; Joseph K Bradley; Xiangrui Meng; Tomer Kaftan; Michael J Franklin; Ali Ghodsi; Matei Zaharia,Abstract Spark SQL is a new module in Apache Spark that integrates relational processingwith Spark's functional programming API. Built on our experience with Shark; Spark SQL letsSpark programmers leverage the benefits of relational processing (eg declarative queriesand optimized storage); and lets SQL users call complex analytics libraries in Spark (egmachine learning). Compared to previous systems; Spark SQL makes two main additions.First; it offers much tighter integration between relational and procedural processing; througha declarative DataFrame API that integrates with procedural Spark code. Second; it includesa highly extensible optimizer; Catalyst; built using features of the Scala programminglanguage; that makes it easy to add composable rules; control code generation; and defineextension points. Using Catalyst; we have built a variety of features (eg schema inference …,SIGMOD 2015,2015,466
GraphX: A Resilient Distributed Graph System on Spark,Reynold S Xin; Joseph E Gonzalez; Michael J Franklin; Ion Stoica; EECS AMPLab,Abstract From social networks to targeted advertising; big graphs capture the structure indata and are central to recent advances in machine learning and data mining. Unfortunately;directly applying existing data-parallel tools to graph computation tasks can be cumbersomeand inefficient. The need for intuitive; scalable tools for graph computation has lead to thedevelopment of new graph-parallel systems (eg.; Pregel; PowerGraph) which are designedto efficiently execute graph algorithms. Unfortunately; these new graph-parallel systems donot address the challenges of graph construction and transformation which are often just asproblematic as the subsequent computation. Furthermore; existing graph-parallel systemsprovide limited fault-tolerance and support for interactive data mining. We introduce GraphX;which combines the advantages of both data-parallel and graph-parallel systems by …,GRADES (SIGMOD workshop),2013,415
Shark: SQL and Rich Analytics at Scale,Reynold Xin; Josh Rosen; Matei Zaharia; Michael J Franklin; Scott Shenker; Ion Stoica,Abstract Shark is a new data analysis system that marries query processing with complexanalytics on large clusters. It leverages a novel distributed memory abstraction to provide aunified engine that can run SQL queries and sophisticated analytics functions (eg iterativemachine learning) at scale; and efficiently recovers from failures mid-query. This allowsShark to run SQL queries up to 100X faster than Apache Hive; and machine learningprograms more than 100X faster than Hadoop. Unlike previous systems; Shark shows that itis possible to achieve these speedups while retaining a MapReduce-like execution engine;and the fine-grained fault tolerance properties that such engine provides. It extends such anengine in several ways; including column-oriented in-memory storage and dynamic mid-query replanning; to effectively execute SQL. The result is a system that matches the …,SIGMOD 2013,2013,411
Apache Spark: a unified engine for big data processing,Matei Zaharia; Reynold S Xin; Patrick Wendell; Tathagata Das; Michael Armbrust; Ankur Dave; Xiangrui Meng; Josh Rosen; Shivaram Venkataraman; Michael J Franklin; Ali Ghodsi; Joseph Gonzalez; Scott Shenker; Ion Stoica,The growth of data volumes in industry and research poses tremendous opportunities; as wellas tremendous computational challenges. As data sizes have outpaced the capabilities of singlemachines; users have needed new systems to scale out computations to multiple nodes. As aresult; there has been an explosion of new cluster programming models targeting diverse computingworkloads. 1;4;7;10 At first; these models were relatively specialized; with new models developedfor new workloads; for example; MapReduce 4 supported batch processing; but Google alsodeveloped Dremel 13 for interactive SQL queries and Pregel 11 for iterative graphalgorithms. In the open source Apache Hadoop stack; systems like Storm 1 and Impala 9 arealso specialized. Even in the relational database world; the trend has been to move away from"one-size-fits-all" systems. 18 Unfortunately; most big data applications need to combine …,Communications of the ACM,2016,138
Shark: fast data analysis using coarse-grained distributed memory,Cliff Engle; Antonio Lupher; Reynold Xin; Matei Zaharia; Michael J Franklin; Scott Shenker; Ion Stoica,Abstract Shark is a research data analysis system built on a novel coarse-grained distributedshared-memory abstraction. Shark marries query processing with deep data analysis;providing a unified system for easy data manipulation using SQL and pushing sophisticatedanalysis closer to data. It scales to thousands of nodes in a fault-tolerant manner. Shark cananswer queries 40X faster than Apache Hive and run machine learning programs 25X fasterthan MapReduce programs in Apache Hadoop on large datasets.,SIGMOD 2012,2012,121
Finding related tables,Anish Das Sarma; Lujun Fang; Nitin Gupta; Alon Halevy; Hongrae Lee; Fei Wu; Reynold Xin; Cong Yu,Abstract We consider the problem of finding related tables in a large corpus of heterogenoustables. Detecting related tables provides users a powerful tool for enhancing their tables withadditional data and enables effective reuse of available public data. Our first contribution is aframework that captures several types of relatedness; including tables that are candidatesfor joins and tables that are candidates for union. Our second contribution is a set ofalgorithms for detecting related tables that can be either unioned or joined. We describe aset of experiments that demonstrate that our algorithms produce highly related tables. Wealso show that we can often improve the results of table search by pulling up tables that areranked much lower based on their relatedness to top-ranked tables. Finally; we describehow to scale up our algorithms and show the results of running it on a corpus of over a …,SIGMOD 2012,2012,89
Graphx: Unifying data-parallel and graph-parallel analytics,Reynold S Xin; Daniel Crankshaw; Ankur Dave; Joseph E Gonzalez; Michael J Franklin; Ion Stoica,Abstract: From social networks to language modeling; the growing scale and importance ofgraph data has driven the development of numerous new graph-parallel systems (eg;Pregel; GraphLab). By restricting the computation that can be expressed and introducingnew techniques to partition and distribute the graph; these systems can efficiently executeiterative graph algorithms orders of magnitude faster than more general data-parallelsystems. However; the same restrictions that enable the performance gains also make itdifficult to express many of the important stages in a typical graph-analytics pipeline:constructing the graph; modifying its structure; or expressing computation that spans multiplegraphs. As a consequence; existing graph analytics pipelines compose graph-parallel anddata-parallel systems using external storage systems; leading to extensive data …,arXiv preprint arXiv:1402.2394,2014,56
The case for tiny tasks in compute clusters,Kay Ousterhout; Aurojit Panda; Joshua Rosen; Shivaram Venkataraman; Reynold Xin; Sylvia Ratnasamy; Scott Shenker; Ion Stoica,Abstract We argue for breaking data-parallel jobs in compute clusters into tiny tasks thateach complete in hundreds of milliseconds. Tiny tasks avoid the need for complex skewmitigation techniques: by breaking a large job into millions of tiny tasks; work will be evenlyspread over available resources by the scheduler. Furthermore; tiny tasks alleviate long waittimes seen in today's clusters for interactive jobs: even large batch jobs can be split intosmall tasks that finish quickly. We demonstrate a 5.2 x improvement in response times due tothe use of smaller tasks. In current data-parallel computing frameworks; high task launchoverheads and scalability limitations prevent users from running short tasks. Recentresearch has addressed many of these bottlenecks; we discuss remaining challenges andpropose a task execution framework that can efficiently support tiny tasks.,HotOS,2013,50
CrowdDB: Query Processing with the VLDB Crowd,Amber Feng; Michael Franklin; Donald Kossmann; Tim Kraska; Samuel Madden; Sukriti Ramesh; Andrew Wang; Reynold Xin,Databases often give incorrect answers when data are missing or semantic understandingof the data is required. Processing such queries requires human input for providing themissing information; for performing computationally difficult functions; and for matching;ranking; or aggregating results based on fuzzy criteria. In this demo we present CrowdDB; ahybrid database system that automatically uses crowdsourcing to integrate human input forprocessing queries that a normal database system cannot answer. CrowdDB uses SQL bothas a language to ask complex queries and as a way to model data stored electronically andprovided by human input. Furthermore; queries are automatically compiled and optimized.Special operators provide user interfaces in order to integrate and cleanse human input.Currently CrowdDB supports two crowdsourcing platforms: Amazon Mechanical Turk and …,VLDB,2011,48
Scaling Spark in the real world: performance and usability,Michael Armbrust; Tathagata Das; Aaron Davidson; Ali Ghodsi; Andrew Or; Josh Rosen; Ion Stoica; Patrick Wendell; Reynold Xin; Matei Zaharia,Abstract Apache Spark is one of the most widely used open source processing engines forbig data; with rich language-integrated APIs and a wide range of libraries. Over the past twoyears; our group has worked to deploy Spark to a wide range of organizations throughconsulting relationships as well as our hosted service; Databricks. We describe the mainchallenges and requirements that appeared in taking Spark to a wide set of users; andusability and performance improvements we have made to the engine in response.,Proceedings of the VLDB Endowment,2015,45
Fine-grained Partitioning for Aggressive Data Skipping,Liwen Sun; Michael J Franklin; Sanjay Krishnan; Reynold S Xin,Abstract Modern query engines are increasingly being required to process enormousdatasets in near real-time. While much can be done to speed up the data access; apromising technique is to reduce the need to access data through data skipping. Bymaintaining some metadata for each block of tuples; a query may skip a data block if themetadata indicates that the block does not contain relevant data. The effectiveness of dataskipping; however; depends on how well the blocking scheme matches the query filters. Inthis paper; we propose a fine-grained blocking technique that reorganizes the data tuplesinto blocks with a goal of enabling queries to skip blocks aggressively. We first extractrepresentative filters in a workload as features using frequent itemset mining. Based onthese features; each data tuple can be represented as a feature vector. We then formulate …,SIGMOD 2014,2014,31
Linkage query writer,Oktie Hassanzadeh; Reynold Xin; Renée J Miller; Anastasios Kementsietsidis; Lipyeow Lim; Min Wang,Abstract We present Linkage Query Writer (LinQuer); a system for generating SQL queriesfor semantic link discovery over relational data. The LinQuer framework consists of (a)LinQL; a language for specification of linkage requirements;(b) a web interface and an APIfor translating LinQL queries to standard SQL queries;(c) an interface that assists users inwriting LinQL queries. We discuss the challenges involved in the design and implementationof a declarative and easy to use framework for discovering links between different data itemsin a single data source or across different data sources. We demonstrate different steps ofthe linkage requirements specification and discovery process in several real world scenariosand show how the LinQuer system can be used to create high-quality linked data sources.,PVLDB,2009,26
SparkR: Scaling R Programs with Spark,Shivaram Venkataraman; Zongheng Yang; Eric Liang Davies Liu; Hossein Falaki; Xiangrui Meng; Reynold Xin; Ali Ghodsi; Michael Franklin; Ion Stoica; Matei Zaharia,Abstract R is a popular statistical programming language with a number of extensions thatsupport data processing and machine learning tasks. However; interactive data analysis inR is usually limited as the R runtime is single threaded and can only process data sets that fitin a single machine's memory. We present SparkR; an R package that provides a frontend toApache Spark and uses Spark's distributed computation engine to enable large scale dataanalysis from the R shell. We describe the main design goals of SparkR; discuss how thehigh-level DataFrame API enables scalable computation and present some of the keydetails of our implementation.,SIGMOD,2016,19
GraySort on Apache Spark by Databricks,Reynold Xin; Parviz Deyhim; Ali Ghodsi; Xiangrui Meng; Matei Zaharia,Apache Spark [1] is a general cluster compute engine for scalable data processing. It wasoriginally developed by researchers at UC Berkeley AMPLab [2]. The engine is faulttolerantand is designed to run on commodity hardware. It generalizes two stage Map/Reduce tosupport arbitrary DAGs of tasks and fast data sharing between operations.,*,2014,19
GraphFrames: an integrated api for mixing graph and relational queries,Ankur Dave; Alekh Jindal; Li Erran Li; Reynold Xin; Joseph Gonzalez; Matei Zaharia,Abstract Graph data is prevalent in many domains; but it has usually required specializedengines to analyze. This design is onerous for users and precludes optimization acrosscomplete workflows. We present GraphFrames; an integrated system that lets users combinegraph algorithms; pattern matching and relational queries; and optimizes work across them.GraphFrames generalize the ideas in previous graph-on-RDBMS systems; such as GraphXand Vertexica; by letting the system materialize multiple views of the graph (not just thespecific triplet views in these systems) and executing both iterative algorithms and patternmatching using joins. To make applications easy to write; GraphFrames provide a concise;declarative API based on the" data frame" concept in R that can be used for both interactivequeries and standalone programs. Under this API; GraphFrames use a graph-aware join …,Proceedings of the Fourth International Workshop on Graph Data Management Experiences and Systems,2016,17
Publishing Bibliographic Data on the Semantic Web using BibBase,Reynold S Xin; Oktie Hassanzadeh; Christian Fritz; Shirin Sohrabi; Yang Yang; Minghua Zhao; Renée J Miller,Abstract We present BibBase; a system for publishing and managing bibliographic dataavailable in BiBTeX files. BibBase uses a powerful yet light-weight approach to transformBiBTeX files into rich Linked Data as well as custom HTML code and RSS feed that canreadily be integrated within a user's website while the data can instantly be queried onlineon the system's SPARQL endpoint. In this paper; we present an overview of several featuresof our system. We outline several challenges involved in on-the-fly transformation of highlyheterogeneous BiBTeX files into high-quality Linked Data; and present our solution to thesechallenges.,Semantic Web,2013,14
A Partitioning Framework for Aggressive Data Skipping,Liwen Sun; Sanjay Krishnan; Reynold S Xin; Michael J Franklin,Abstract We propose to demonstrate a fine-grained partitioning framework that reorganizesthe data tuples into small blocks at data loading time. The goal is to enable queries tomaximally skip scanning data blocks. The partition framework consists of four steps:(1)workload analysis; which extracts features from a query workload;(2) augmentation; whichaugments each data tuple with a feature vector;(3) reduce; which succinctly represents a setof data tuples using a set of feature vectors; and (4) partitioning; which performs a clusteringalgorithm to partition the feature vectors and uses the clustering result to guide the actualdata partitioning. Our experiments show that our techniques result in a 3-7x query responsetime improvement over traditional range partitioning due to more effective data skipping.,VLDB 2014,2014,7
Introduction to spark 2.0 for database researchers,Michael Armbrust; Doug Bateman; Reynold Xin; Matei Zaharia,Abstract Originally started as an academic research project at UC Berkeley; Apache Spark isone of the most popular open source projects for big data analytics. Over 1000 volunteershave contributed code to the project; it is supported by virtually every commercial vendor;many universities are now offering courses on Spark. Spark has evolved significantly sincethe 2010 research paper: its foundational APIs are becoming more relational and structuralwith the introduction of the Catalyst relational optimizer; and its execution engine isdeveloping quickly to adopt the latest research advances in database systems such aswhole-stage code generation. This tutorial is designed for database researchers (graduatestudents; faculty members; and industrial researchers) interested in a brief hands-onoverview of Spark. This tutorial covers the core APIs for using Spark 2.0; including …,Proceedings of the 2016 International Conference on Management of Data,2016,5
MEET DB2: automated database migration evaluation,Reynold S Xin; William McLaren; Patrick Dantressangle; Steve Schormann; Sam Lightstone; Maria Schwenger,Abstract Commercial databases compete for market share; which is composed of not onlynet-new sales to those purchasing a database for the first time; but also competitive" win-backs" and migrations. Database migration; or the act of moving both application code andits underlying database platform from one database to another; presents a seriousadministrative and application development challenge fraught with large manual costs.Migration is typically a high cost effort due to incompatibilities between database platforms.Incompatibilities are caused most often by product specific extensions to language support;procedural logic; DDL; and administrative interfaces. The migration evaluation is the firststep in any competitive database migration process. Historically this has been a manualprocess; with the high costs and subjective results. This has led us to reexamine …,VLDB,2010,3
The magazine archive includes every article published in Communications of the ACM for over the past 50 years.,Domenico Talia; Paolo Trunfio,Supercomputing is evolving toward hybrid and accelerator-based architectures with millionsof cores. The Hardware/Hybrid Accelerated Cosmology Code (HACC) framework exploitsthis diverse landscape at the largest scales of problem size; obtaining high scalability andsustained performance. Developed to satisfy the science requirements of cosmologicalsurveys; HACC melds particle and grid methods using a novel algorithmic structure thatflexibly maps across architectures; including CPU/GPU; multi/many-core; and Blue Genesystems. In this Research Highlight; we demonstrate the success of HACC on two verydifferent machines; the CPU/GPU system Titan and the BG/Q systems Sequoia and Mira;attaining very high levels of scalable performance. We demonstrate strong and weak scalingon Titan; obtaining up to 99.2% parallel efficiency; evolving 1.1 trillion particles. On …,Communications of the ACM,*,2
Spark Satellite Clusters to Hadoop Data Stores,*,An advertising and data analysis platform may need to mine through vast amounts of data tocome up with insights into advertising effectiveness; and measure and improve theeffectiveness of advertising reach. Distributed network data analytics may be applied to admatching/targeting; such that an in-memory cluster computing environment may be usedwith advertising data. For example; HADOOP may be utilized for distributed processing ofthe vast amounts of data and the HADOOP distributed file system (HDFS) is used fororganizing communications and storage of that data. Satellite clusters or nodes may begenerated that also utilize HDFS. For example; a SPARK or SHARK satellite cluster may bearranged to further utilize the HDFS of the HADOOP clusters.,*,2014,1
Beating State-of-the-art By-10000%.,Reynold Xin; UC AMPLab; Joseph Gonzalez; Josh Rosen; Matei Zaharia; Michael Franklin; Scott Shenker; Ion Stoica,Page 1. Beating State-of-the-art By -10000% Reynold Xin; AMPLab; UC Berkeley with help fromJoseph Gonzalez; Josh Rosen; Matei Zaharia; Michael Franklin; Scott Shenker; Ion Stoica Page2. Beating State-of-the-art By -10000% NOT A TYPO Reynold Xin; AMPLab; UC Berkeley withhelp from Joseph Gonzalez; Josh Rosen; Matei Zaharia; Michael Franklin; Scott Shenker; Ion StoicaPage 3. MapReduce deterministic; idempotent tasks fault-tolerance elasticity resource sharingPage 4. “The bar for open source software is at historical low.” Page 5. “The bar for open sourcesoftware is at historical low.” ie “This is the right time to do grad school.” Page 6. iterative machinelearning OLAP strong temporal locality Page 7. Does in-memory computation help inpetabyte-scale warehouses? Page 8. Does in-memory computation help in petabyte-scalewarehouses? YES Page 9. Spark How to do in-memory computation …,CIDR 2013,2013,1
Detecting Spam on Social Networking Sites: Related Work,Antonio Lupher; Cliff Engle; Reynold Xin,The rise of social media has made Social Networking Services (SNSs) more attractivetargets for spam and fraud; leading to increasingly sophisticated attacks. This trend isreflected in recent research; as papers have focused on identifying and classifying thevarious types of social media spam. Many of these studies employ techniques previouslyused to combat conventional email and web spam. SNSs also provide opportunities to takeadvantage of user reputation and other social graph-dependent features to improveclassification. Nevertheless; most research has been carried out on publicly-available datafrom SNSs; making it difficult up until now to measure the effect of private user data onalgorithms for detecting site misuse.,University of California Berkeley,2012,1
The End of an Architectural Era for Analytical Databases,Reynold S Xin,Abstract Traditional enterprise warehouse solutions center around an analytical databasesystem that is monolithic and inflexible: data needs to be extracted; transformed; and loadedinto the rigid relational form before analysis. It takes years of sophisticated planning toprovision and deploy a warehouse; adding new hardware resources to an existingwarehouse is an equally lengthy and daunting task. Additionally; modern data analysisemploys statistical methods that go well beyond the typical roll-up and drill-down capabilitiesprovided by warehouse systems. Although it is possible to implement such methods using acombination of SQL and UDFs; query engines in relational databases are ill-suited for these.The Hadoop ecosystem introduces a suite of tools for data analytics that overcome some ofthe problems of traditional solutions. These systems; however; forgo years of warehouse …,TinyToCs 2012,2012,*
Improving Data Management Applications Using Microtask Platforms,Jiannan Wang; Reynold S Xin,ABSTRACT Many data management problems are inherently vague and hard for algorithmsto process. Take for example entity resolution; also known as record linkage; the process toresolve records for the same entity from heterogeneous sources. Properly resolving suchrecords require not only the syntactic structure of the data; but also contextual semantics thatare hard for machines to understand. To properly perform such data management tasksrequires human inputs for providing information that is missing from the structured data thatmachines can read; for performing computationally difficult functions; and for matching;ranking; or aggregating results based on fuzzy criteria. The rise of microtask crowdsourcingplatforms; eg Amazon's Mechanical Turk; provides a unique opportunity to integrate humaninputs into the algorithmic data flow. There are two recent work; CrowdDB [1] and …,TinyToCs 2012,2012,*
BibBase triplified,Oktie Hassanzadeh; Reynold S Xin; Christian Fritz; Yang Yang; Jiang Du; Minghua Zhao; Renée J Miller,Abstract We present BibBase; a system for publishing and managing bibliographic dataavailable in BibTeX files. BibBase uses a powerful yet light-weight approach to transformBibTeX files into rich triplified data as well as custom HTML and RSS code that can readilybe integrated within a user's website while the data can instantly be queried online on thesystem's SPARQL endpoint. In this short report; we present a brief overview of the features ofour system and outline a few research challenges in building such a system.,Proceedings of the 6th International Conference on Semantic Systems,2010,*
The magazine archive includes every article published in Communications of the ACM for over the past 50 years.,Akhilesh Chandra; Thomas Calderon,Information systems (IS) are quickly emerging as critical resources to be leveraged fororganizational productivity in many business; social; and economic enterprises. Theexplosive growth in information technology (IT) can be broadly attributed to the emergingnovel linkages of IS/IT with several base disciplines; extending the reach of IS/IT toapplication domains never previously considered.In this article; we focus on certainimportant and promising IS/IT frontiers identified from the perspectives of academia; industry;and federal research funding agencies. Our objective is to focus the collective awareness ofthe IS community and those in related disciplines on some of the frontier developments inIS/IT with a vision of the road ahead and point to challenges and opportunities [1].,Communications of the ACM,2000,*
1Nanjing University; 2Databricks Inc.; 3Alibaba Group Inc.,Qian Wang; Rong Gu; Yihua Huang; Reynold Xin; Wei Wu; Jun Song; Junluan Xia,Abstract In this paper; we present NADSort; a sorting system on top of the distributedcomputing platform Apache Spark [1]. We report performance results of NADSort for DaytonaCloudSort and Indy CloudSort benchmarks. NADSort is able to complete the 100TB DaytonaCloudSort in 2983.33 seconds on random non-skewed datasets at an average cost of$144.22 and 3057.67 seconds on skewed datasets at an average cost of $147.82; andcomplete Indy CloudSort in 2983.33 seconds at an average cost of $144.22.,*,*,*
Interfaces3,Reynold Xin,Page 1. Interfaces3 Reynold Xin Aug 22; 2014 @ Databricks Retreat Repurposed Jan 27; 2015for Spark community Page 2. Spark's two improvements over Hadoop MR • Performance: “100X”faster than Hadoop MR • Programming model: easier to use Page 3. public static classWordCountMapClass extends MapReduceBase implements Mapper<LongWritable; Text; Text;IntWritable> { private final static IntWritable one = new IntWritable(1); private Text word = newText(); public void map(LongWritable key; Text value; OutputCollector<Text; IntWritable> output;Reporter reporter) throws IOException { String line = value.toString(); StringTokenizer itr = newStringTokenizer(line); while (itr.hasMoreTokens()) { word.set(itr.nextToken()); output.collect(word; one); } } } public static class WorkdCountReduce extends MapReduceBase implementsReducer<Text; IntWritable; Text; IntWritable> …,*,*,*
CrowdDB: Answering Queries using Crowdsourcing,Michael J Franklin; Donald Kossmann; Tim Kraska; Sukriti Ramesh; Reynold Xin,Workers develop relationship with requesters and skills for certain types of HITs. Notuncommon to find workers doing only image classification. Hesitant to do tasks fromrequesters who don't provide well-defined tasks/pay appropriately. CrowdDB design to takelonger-term view on task and worker community development.,*,*,*
