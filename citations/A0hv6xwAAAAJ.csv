l-diversity: Privacy beyond k-anonymity,Ashwin Machanavajjhala; Johannes Gehrke; Daniel Kifer; Muthuramakrishnan Venkitasubramaniam,Publishing data about individuals without revealing sensitive information about them is animportant problem. In recent years; a new definition of privacy called\kappa-anonymity hasgained popularity. In a\kappa-anonymized dataset; each record is indistinguishable from atleast k—1 other records with respect to certain" identifying" attributes. In this paper we showwith two simple attacks that a\kappa-anonymized dataset has some subtle; but severeprivacy problems. First; we show that an attacker can discover the values of sensitiveattributes when there is little diversity in those sensitive attributes. Second; attackers oftenhave background knowledge; and we show that\kappa-anonymity does not guaranteeprivacy against attackers using background knowledge. We give a detailed analysis of thesetwo attacks and we propose a novel and powerful privacy definition called\ell-diversity. In …,Data Engineering; 2006. ICDE'06. Proceedings of the 22nd International Conference on,2006,3768
Privacy: Theory meets practice on the map,Ashwin Machanavajjhala; Daniel Kifer; John Abowd; Johannes Gehrke; Lars Vilhuber,Abstract In this paper; we propose the first formal privacy analysis of a data anonymizationprocess known as the synthetic data generation; a technique becoming popular in thestatistics community. The target application for this work is a mapping program that showsthe commuting patterns of the population of the United States. The source data for thisapplication were collected by the US Census Bureau; but due to privacy constraints; theycannot be used directly by the mapping program. Instead; we generate synthetic data thatstatistically mimic the original data while providing privacy guarantees. We use thesesynthetic data as a surrogate for the original data. We find that while some existingdefinitions of privacy are inapplicable to our target application; others are too conservativeand render the synthetic data useless since they guard against privacy breaches that are …,Proceedings of the 2008 IEEE 24th International Conference on Data Engineering,2008,363
Worst-case background knowledge for privacy-preserving data publishing,David J Martin; Daniel Kifer; Ashwin Machanavajjhala; Johannes Gehrke; Joseph Y Halpern,Recent work has shown the necessity of considering an attacker's background knowledgewhen reasoning about privacy in data publishing. However; in practice; the data publisherdoes not know what background knowledge the attacker possesses. Thus; it is important toconsider the worst-case. In this paper; we initiate a formal study of worst-case backgroundknowledge. We propose a language that can express any background knowledge about thedata. We provide a polynomial time algorithm to measure the amount of disclosure ofsensitive information in the worst case; given that the attacker has at most k pieces ofinformation in this language. We also provide a method to efficiently sanitize the data so thatthe amount of disclosure in the worst case is less than a specified threshold.,2007 IEEE 23rd International Conference on Data Engineering,2007,319
No free lunch in data privacy,Daniel Kifer; Ashwin Machanavajjhala,Abstract Differential privacy is a powerful tool for providing privacy-preserving noisy queryanswers over statistical databases. It guarantees that the distribution of noisy query answerschanges very little with the addition or deletion of any tuple. It is frequently accompanied bypopularized claims that it provides privacy without any assumptions about the data and thatit protects against attackers who know all but one record. In this paper we critically analyzethe privacy protections offered by differential privacy. First; we use a no-free-lunch theorem;which defines non-privacy as a game; to argue that it is not possible to provide privacy andutility without making assumptions about how the data are generated. Then we explainwhere assumptions are needed. We argue that privacy of an individual is preserved when itis possible to limit the inference of an attacker about the participation of the individual in …,Proceedings of the 2011 ACM SIGMOD International Conference on Management of data,2011,308
Entity resolution: theory; practice & open challenges,Lise Getoor; Ashwin Machanavajjhala,Abstract This tutorial brings together perspectives on ER from a variety of fields; includingdatabases; machine learning; natural language processing and information retrieval; toprovide; in one setting; a survey of a large body of work. We discuss both the practicalaspects and theoretical underpinnings of ER. We describe existing solutions; currentchallenges; and open research problems.,Proceedings of the VLDB Endowment,2012,158
Personalized social recommendations: accurate or private,Ashwin Machanavajjhala; Aleksandra Korolova; Atish Das Sarma,Abstract With the recent surge of social networks such as Facebook; new forms ofrecommendations have become possible--recommendations that rely on one's socialconnections in order to make personalized recommendations of ads; content; products; andpeople. Since recommendations may use sensitive information; it is speculated that theserecommendations are associated with privacy risks. The main contribution of this work is informalizing trade-offs between accuracy and privacy of personalized socialrecommendations. We study whether" social recommendations"; or recommendations thatare solely based on a user's social network; can be made without disclosing sensitive linksin the social graph. More precisely; we quantify the loss in utility when existingrecommendation algorithms are modified to satisfy a strong notion of privacy; called …,Proceedings of the VLDB Endowment,2011,137
P-ring: an efficient and robust P2P range index structure,Adina Crainiceanu; Prakash Linga; Ashwin Machanavajjhala; Johannes Gehrke; Jayavel Shanmugasundaram,Abstract Peer-to-peer systems have emerged as a robust; scalable and decentralized way toshare and publish data. In this paper; we propose P-Ring; a new P2P index structure thatsupports both equality and range queries. P-Ring is fault-tolerant; provides logarithmicsearch performance even for highly skewed data distributions and efficiently supports largesets of data items per peer. We experimentally evaluate P-Ring using both simulations and areal distributed deployment on PlanetLab; and we compare its performance with SkipGraphs; Online Balancing and Chord.,Proceedings of the 2007 ACM SIGMOD international conference on Management of data,2007,99
Publishing Search Logs—A Comparative Study of Privacy Guarantees,Michaela Götz; Ashwin Machanavajjhala; Guozhang Wang; Xiaokui Xiao; Johannes Gehrke,Search engine companies collect the “database of intentions;” the histories of their users'search queries. These search logs are a gold mine for researchers. Search enginecompanies; however; are wary of publishing search logs in order not to disclose sensitiveinformation. In this paper; we analyze algorithms for publishing frequent keywords; queries;and clicks of a search log. We first show how methods that achieve variants of k-anonymityare vulnerable to active attacks. We then demonstrate that the stronger guarantee ensuredby ε-differential privacy unfortunately does not provide any utility for this problem. We thenpropose an algorithm ZEALOUS and show how to set its parameters to achieve (ε; δ)-probabilistic privacy. We also contrast our analysis of ZEALOUS with an analysis byKorolova et al.[17] that achieves (ε'; δ')-indistinguishability. Our paper concludes with a …,IEEE Transactions on Knowledge and Data Engineering,2012,97
On perfectly secure communication over arbitrary networks,MVN Kumar; Pranava R Goundan; K Srinathan; C Pandu Rangan,Abstract We study the interplay of network connectivity and perfectly secure messagetransmission under the corrupting influence of generalized Byzantine adversaries. It isknown that in the threshold adversary model; where the Byzantine adversary can corruptupto any t among the n players (nodes); perfectly secure communication among any pair ofplayers is possible if and only if the underlying synchronous network is (2t+ 1)-connected.Strictly generalizing these results to the non-threshold setting; we show that perfectly securecommunication among any pair of players is possible if and only if the union of no two sets inthe adversary structure is a vertex cutset of the synchronous network. The computation andcommunication complexities of the transmission protocol are polynomial in the size of thenetwork and the maximal basis of the adversary structure.,Proceedings of the twenty-first annual symposium on Principles of distributed computing,2002,89
A rigorous and customizable framework for privacy,Daniel Kifer; Ashwin Machanavajjhala,Abstract In this paper we introduce a new and general privacy framework called Pufferfish.The Pufferfish framework can be used to create new privacy definitions that are customizedto the needs of a given application. The goal of Pufferfish is to allow experts in an applicationdomain; who frequently do not have expertise in privacy; to develop rigorous privacydefinitions for their data sharing needs. In addition to this; the Pufferfish framework can alsobe used to study existing privacy definitions. We illustrate the benefits with severalapplications of this privacy framework: we use it to formalize and prove the statement thatdifferential privacy assumes independence between records; we use it to define and studythe notion of composition in a broader context than before; we show how to apply it to protectunbounded continuous attributes and aggregate information; and we show how to use it …,Proceedings of the 31st ACM SIGMOD-SIGACT-SIGAI symposium on Principles of Database Systems,2012,88
Big privacy: protecting confidentiality in big data,Ashwin Machanavajjhala; Jerome P Reiter,A tremendous amount of data about individuals—demographic information; Internet activity; energyusage; communication patterns; and social interactions; to mention a few—are being collectedby national statistical agencies; survey organizations; medical centers; and Web and social networkingcompanies. Wide dissemination of such microdata (data at the granularity of individuals) facilitatesadvances in science and public policy; helps citizens to learn about their societies; and enablesstudents to develop data analysis skills. Often; however; data producers cannot release microdataas collected; because doing so could reveal data subjects' identities or values of sensitiveattributes. Failing to protect confidentiality (when promised) is unethical and can cause harmto data subjects and the data provider. Failure to protect individuals' privacy may even beillegal; especially in government and research settings. For example; if one reveals …,XRDS: Crossroads; The ACM Magazine for Students,2012,70
Pufferfish: A framework for mathematical privacy definitions,Daniel Kifer; Ashwin Machanavajjhala,Abstract In this article; we introduce a new and general privacy framework called Pufferfish.The Pufferfish framework can be used to create new privacy definitions that are customizedto the needs of a given application. The goal of Pufferfish is to allow experts in an applicationdomain; who frequently do not have expertise in privacy; to develop rigorous privacydefinitions for their data sharing needs. In addition to this; the Pufferfish framework can alsobe used to study existing privacy definitions. We illustrate the benefits with severalapplications of this privacy framework: we use it to analyze differential privacy and formalizea connection to attackers who believe that the data records are independent; we use it tocreate a privacy definition called hedging privacy; which can be used to rule out attackerswhose prior beliefs are inconsistent with the data; we use the framework to define and …,ACM Transactions on Database Systems (TODS),2014,68
Finding connected components in map-reduce in logarithmic rounds,Vibhor Rastogi; Ashwin Machanavajjhala; Laukik Chitnis; Anish Das Sarma,Given a large graph G=(V; E) with millions of nodes and edges; how do we compute itsconnected components efficiently? Recent work addresses this problem in map-reduce;where a fundamental trade-off exists between the number of map-reduce rounds and thecommunication of each round. Denoting d the diameter of the graph; and n the number ofnodes in the largest component; all prior techniques for map-reduce either require a linear;Θ (d); number of rounds; or a quadratic; Θ (n| V|+| E|); communication per round. Wepropose here two efficient map-reduce algorithms:(i) Hash-Greater-to-Min; which is arandomized algorithm based on PRAM techniques; requiring O (log n) rounds and O (| V|+|E|) communication per round; and (ii) Hash-to-Min; which is a novel algorithm; provablyfinishing in O (log n) iterations for path graphs. The proof technique used for Hash-to-Min …,Data Engineering (ICDE); 2013 IEEE 29th International Conference on,2013,67
On the efficiency of checking perfect privacy,Ashwin Machanavajjhala; Johannes Gehrke,Abstract Privacy-preserving query-answering systems answer queries while provablyguaranteeing that sensitive information is kept secret. One very attractive notion of privacy isperfect privacy—a secret is expressed through a query QS; and a query QV is answeredonly if it discloses no information about the secret query Q S. However; if QS and QV arearbitrary conjunctive queries; the problem of checking whether QV discloses any informationabout QS is known to be Π p 2-complete. In this paper; we show that for large interestingsubclasses of conjunctive queries enforcing perfect privacy is tractable. Instead of givingdifferent arguments for query classes of varying complexity; we make a connection betweenperfect privacy and the problem of checking query containment. We then use this connectionto relate the complexity of enforcing perfect privacy to the complexity of query containment.,Proceedings of the twenty-fifth ACM SIGMOD-SIGACT-SIGART symposium on Principles of database systems,2006,67
Scalable ranked publish/subscribe,Ashwin Machanavajjhala; Erik Vee; Minos Garofalakis; Jayavel Shanmugasundaram,Abstract Publish/subscribe (pub/sub) systems are designed to efficiently match incomingevents (eg; stock quotes) against a set of subscriptions (eg; trader profiles specifying quotesof interest). However; current pub/sub systems only support a simple binary notion ofmatching: an event either matches a subscription or it does not; for instance; a stock quotewill either match or not match a trader profile. In this paper; we argue that this simple notionof matching is inadequate for many applications where only the" best" matchingsubscriptions are of interest. For instance; in targeted Web advertising; an incoming user ("event") may match several different advertiser-specified user profiles (" subscriptions"); butgiven the limited advertising real-estate; we want to quickly discover the best (eg; mostrelevant) ads to display. To address this need; we initiate a study of ranked pub/sub …,Proceedings of the VLDB Endowment,2008,63
Load balancing and range queries in P2P systems using P-Ring,Adina Crainiceanu; Prakash Linga; Ashwin Machanavajjhala; Johannes Gehrke; Jayavel Shanmugasundaram,Abstract In peer-to-peer (P2P) systems; computers from around the globe share data andcan participate in distributed computation. P2P became famous; and infamous; due to file-sharing systems like Napster. However; the scalability and robustness of these systemsmake them appealing to a wide range of applications. This article introduces P-Ring; a newpeer-to-peer index structure. P-Ring is fully distributed; fault tolerant; and provides loadbalancing and logarithmic search performance while supporting both equality and rangequeries. Our theoretical analysis as well as experimental results; obtained both in asimulated environment and on PlanetLab; show the performance of our system.,ACM Transactions on Internet Technology (TOIT),2011,58
Blowfish privacy: Tuning privacy-utility trade-offs using policies,Xi He; Ashwin Machanavajjhala; Bolin Ding,Abstract Privacy definitions provide ways for trading-off the privacy of individuals in astatistical database for the utility of downstream analysis of the data. In this paper; wepresent Blowfish; a class of privacy definitions inspired by the Pufferfish framework; thatprovides a rich interface for this trade-off. In particular; we allow data publishers to extenddifferential privacy using a policy; which specifies (a) secrets; or information that must bekept secret; and (b) constraints that may be known about the data. While the secretspecification allows increased utility by lessening protection for certain individual properties;the constraint specification provides added protection against an adversary who knowscorrelations in the data (arising from constraints). We formalize policies and present novelalgorithms that can handle general specifications of sensitive information and certain …,Proceedings of the 2014 ACM SIGMOD international conference on Management of data,2014,57
Entity resolution for big data,Lise Getoor; Ashwin Machanavajjhala,Abstract Entity resolution (ER); the problem of extracting; matching and resolving entitymentions in structured and unstructured data; is a long-standing challenge in databasemanagement; information retrieval; machine learning; natural language processing andstatistics. Accurate and fast entity resolution has huge practical implications in a wide varietyof commercial; scientific and security domains. Despite the long history of work on entityresolution; there is still a surprising diversity of approaches; and lack of guiding theory.Meanwhile; in the age of big data; the need for high quality entity resolution is growing; aswe are inundated with more and more data; all of which needs to be integrated; aligned andmatched; before further utility can be extracted. In this tutorial; we bring togetherperspectives on entity resolution from a variety of fields; including databases; information …,Proceedings of the 19th ACM SIGKDD international conference on Knowledge discovery and data mining,2013,57
Data publishing against realistic adversaries,Ashwin Machanavajjhala; Johannes Gehrke; Michaela Götz,Abstract Privacy in data publishing has received much attention recently. The key to definingprivacy is to model knowledge of the attacker--if the attacker is assumed to know too little;the published data can be easily attacked; if the attacker is assumed to know too much; thepublished data has little utility. Previous work considered either quite ignorant adversaries ornearly omniscient adversaries. In this paper; we introduce a new class of adversaries thatwe call realistic adversaries who live in the unexplored space in between. Realisticadversaries have knowledge from external sources with an associated stubbornnessindicating the strength of their knowledge. We then introduce a novel privacy frameworkcalled epsilon-privacy that allows us to guard against realistic adversaries. We also showthat prior privacy definitions are instantiations of our framework. In a thorough …,Proceedings of the VLDB Endowment,2009,54
Highly efficient algorithms for structural clustering of large websites,Lorenzo Blanco; Nilesh Dalvi; Ashwin Machanavajjhala,Abstract In this paper; we present a highly scalable algorithm for structurally clusteringwebpages for extraction. We show that; using only the URLs of the webpages and simplecontent features; it is possible to cluster webpages effectively and efficiently. At the heart ofour techniques is a principled framework; based on the principles of information theory; thatallows us to effectively leverage the URLs; and combine them with content and structuralproperties. Using an extensive evaluation over several large full websites; we demonstratethe effectiveness of our techniques; at a scale unattainable by previous techniques.,Proceedings of the 20th international conference on World wide web,2011,45
An analysis of structured data on the web,Nilesh Dalvi; Ashwin Machanavajjhala; Bo Pang,Abstract In this paper; we analyze the nature and distribution of structured data on the Web.Web-scale information extraction; or the problem of creating structured tables usingextraction from the entire web; is gathering lots of research interest. We perform a study tounderstand and quantify the value of Web-scale extraction; and how structured informationis distributed amongst top aggregator websites and tail sites for various interesting domains.We believe this is the first study of its kind; and gives us new insights for informationextraction over the Web.,Proceedings of the VLDB Endowment,2012,41
An automatic blocking mechanism for large-scale de-duplication tasks,Anish Das Sarma; Ankur Jain; Ashwin Machanavajjhala; Philip Bohannon,Abstract De-duplication-identification of distinct records referring to the same real-worldentity-is a well-known challenge in data integration. Since very large datasets prohibit thecomparison of every pair of records; blocking has been identified as a technique of dividingthe dataset for pairwise comparisons; thereby trading off recall of identified duplicates forefficiency. Traditional de-duplication tasks; while challenging; typically involved a fixedschema such as Census data or medical records. However; with the presence of large;diverse sets of structured data on the web and the need to organize it effectively on contentportals; de-duplication systems need to scale in a new dimension to handle a large numberof schemas; tasks and data sets; while handling ever larger problem sizes. In addition; whenworking in a map-reduce framework it is important that canopy formation be implemented …,Proceedings of the 21st ACM international conference on Information and knowledge management,2012,39
Principled evaluation of differentially private algorithms using DPBench,Michael Hay; Ashwin Machanavajjhala; Gerome Miklau; Yan Chen; Dan Zhang,Abstract Differential privacy has become the dominant standard in the research communityfor strong privacy protection. There has been a flood of research into query answeringalgorithms that meet this standard. Algorithms are becoming increasingly complex; and inparticular; the performance of many emerging algorithms is data dependent; meaning thedistribution of the noise added to query answers may change depending on the input data.Theoretical analysis typically only considers the worst case; making empirical study ofaverage case performance increasingly important. In this paper we propose a set ofevaluation principles which we argue are essential for sound evaluation. Based on theseprinciples we propose DPBench; a novel evaluation framework for standardized evaluationof privacy algorithms. We then apply our benchmark to evaluate algorithms for answering …,Proceedings of the 2016 International Conference on Management of Data,2016,37
Privacy preserving interactive record linkage (PPIRL),Hye-Chung Kum; Ashok Krishnamurthy; Ashwin Machanavajjhala; Michael K Reiter; Stanley Ahalt,Abstract Objective Record linkage to integrate uncoordinated databases is critical inbiomedical research using Big Data. Balancing privacy protection against the need for highquality record linkage requires a human–machine hybrid system to safely manageuncertainty in the ever changing streams of chaotic Big Data. Methods In the computerscience literature; private record linkage is the most published area. It investigates how toapply a known linkage function safely when linking two tables. However; in practice; thelinkage function is rarely known. Thus; there are many data linkage centers whose main roleis to be the trusted third party to determine the linkage function manually and link data forresearch via a master population list for a designated region. Recently; a more flexiblecomputerized third-party linkage platform; Secure Decoupled Linkage (SDLink); has been …,Journal of the American Medical Informatics Association,2014,33
Information integration over time in unreliable and uncertain environments,Aditya Pal; Vibhor Rastogi; Ashwin Machanavajjhala; Philip Bohannon,Abstract Often an interesting true value such as a stock price; sports score; or currenttemperature is only available via the observations of noisy and potentially conflictingsources. Several techniques have been proposed to reconcile these conflicts by computinga weighted consensus based on source reliabilities; but these techniques focus on staticvalues. When the real-world entity evolves over time; the noisy sources can delay; or evenmiss; reporting some of the real-world updates. This temporal aspect introduces two keychallenges for consensus-based approaches:(i) due to delays; the mapping between asource's noisy observation and the real-world update it observes is unknown; and (ii) missedupdates may translate to missing values for the consensus problem; even if the mapping isknown. To overcome these challenges; we propose a formal approach that models the …,Proceedings of the 21st international conference on World Wide Web,2012,33
DPT: differentially private trajectory synthesis using hierarchical reference systems,Xi He; Graham Cormode; Ashwin Machanavajjhala; Cecilia M Procopiuc; Divesh Srivastava,Abstract GPS-enabled devices are now ubiquitous; from airplanes and cars to smartphonesand wearable technology. This has resulted in a wealth of data about the movements ofindividuals and populations; which can be analyzed for useful information to aid in city andtraffic planning; disaster preparedness and so on. However; the places that people go candisclose extremely sensitive information about them; and thus their use needs to be filteredthrough privacy preserving mechanisms. This turns out to be a highly challenging task: rawtrajectories are highly detailed; and typically no pair is alike. Previous attempts fail either toprovide adequate privacy protection; or to remain sufficiently faithful to the original behavior.This paper presents DPT; a system to synthesize mobility data based on raw GPStrajectories of individuals while ensuring strong privacy protection in the form of ε …,Proceedings of the VLDB Endowment,2015,30
Markit: Privacy markers for protecting visual secrets,Nisarg Raval; Animesh Srivastava; Kiron Lebeck; Landon Cox; Ashwin Machanavajjhala,Abstract The increasing popularity of wearable devices that continuously capture video; andthe prevalence of third-party applications that utilize these feeds have resulted in a newthreat to privacy. In many situations; sensitive objects/regions are maliciously (oraccidentally) captured in a video frame by third-party applications. However; currentsolutions do not allow users to specify and enforce fine grained access control over videofeeds. In this paper; we describe MarkIt; a computer vision based privacy marker framework;that allows users to specify and enforce fine grained access control over video feeds. Wepresent two example privacy marker systems--PrivateEye and WaveOff. We conclude with adiscussion of the computer vision; privacy and systems challenges in building acomprehensive system for fine grained access control over video feeds.,Proceedings of the 2014 ACM International Joint Conference on Pervasive and Ubiquitous Computing: Adjunct Publication,2014,30
Social genome: Putting big data to work for population informatics,Hye-Chung Kum; Ashok Krishnamurthy; Ashwin Machanavajjhala; Stanley C Ahalt,Data-intensive research using distributed; federated; person-level datasets in near real timehas the potential to transform social; behavioral; economic; and health sciences--but issuesaround privacy; confidentiality; access; and data integration have slowed progress in thisarea. When technology is properly used to manage both privacy concerns and uncertainty;big data will help move the growing field of population informatics forward.,Computer,2014,29
Feed following: the big data challenge in social applications,Adam Silberstein; Ashwin Machanavajjhala; Raghu Ramakrishnan,Abstract Internet users spend billions of minutes per month on sites like Facebook andTwitter. These sites support feed following; where users" follow" activity streams associatedwith other users and entities. Followers get personalized feeds that blend streams producedby those followed. The emphasis on recency and relevance; and the highly variable fan-outof the follows graph; make this feature difficult to implement at the scale seen in major socialnetworks. In this paper; we place feed following in the context of existing research areas andhighlight the novel data management challenges that it poses; with the goal of stimulatingresearch in this new direction. We discuss solutions based on pub/sub; caching; andmaterialized views; and argue that none of these existing approaches fully exploit theunique characteristics of feed following. The number of distinct queries and the query rate …,Databases and Social Networks,2011,23
Collective extraction from heterogeneous web lists,Ashwin Machanavajjhala; Arun Shankar Iyer; Philip Bohannon; Srujana Merugu,Abstract Automatic extraction of structured records from inconsistently formatted lists on theweb is challenging: different lists present disparate sets of attributes with variations in theordering of attributes; many lists contain additional attributes and noise that can confuse theextraction process; and formatting within a list may be inconsistent due to missing attributesor manual formatting on some sites. We present a novel solution to this extraction problemthat is based on i) collective extraction from multiple lists simultaneously and ii) carefulexploitation of a small database of seed entities. Our approach addresses the layouthomogeneity within the individual lists; content redundancy across some snippets fromdifferent sources; and the noisy attribute rendering process. We experimentally evaluatevariants of this algorithm on real world data sets and show that our approach is a …,Proceedings of the fourth ACM international conference on Web search and data mining,2011,18
Demo: What You Mark is What Apps See,Nisarg Raval; Animesh Srivastava; Ali Razeen; Kiron Lebeck; Ashwin Machanavajjhala; Landon P Cox,*,Proceedings of the 14th Annual International Conference on Mobile Systems; Applications; and Services Companion,2016,16
What you mark is what apps see,Nisarg Raval; Animesh Srivastava; Ali Razeen; Kiron Lebeck; Ashwin Machanavajjhala; Lanodn P Cox,Abstract Users are increasingly vulnerable to inadvertently leaking sensitive informationthrough cameras. In this paper; we investigate an approach to mitigating the risk of suchinadvertent leaks called privacy markers. Privacy markers give users fine-grained control ofwhat visual information an app can access through a device's camera. We present twoexamples of this approach: PrivateEye; which allows a user to mark regions of a two-dimensional surface as safe to release to an app; and WaveOff; which does the same forthree-dimensional objects. We have integrated both systems with Android's camerasubsystem. Experiments with our prototype show that a Nexus 5 smartphone can delivernear realtime frame rates while protecting secret information; and a 26-person user studyelicited positive feedback on our prototype's speed and ease-of-use.,Proceedings of the 14th Annual International Conference on Mobile Systems; Applications; and Services,2016,16
Large scale entity-specific resource classification,*,A system and method is described for large scale entity-specific classification of each entity-specific set of candidates in a collection of candidates for each specific entity in a collectionof entities. The collection of entities may comprise a specific category or domain of entities(eg schools; restaurants; manufacturers; products; events; people). Candidates maycomprise webpages or other resources with resource identifiers. Entity specific sets ofcandidates may be found by leveraging search engine query results and user interactiontherewith for queries based on entity-specific attributes. The relationship (s) or class (es) forwhich candidate resources are being classified relative to a specific entity may comprise anauthoritative; official home page (OHP); or other class (eg fan page; review; aggregator)relative to a specific entity. A feature generator generates entity-specific features for …,*,2016,16
Designing statistical privacy for your data,Ashwin Machanavajjhala; Daniel Kifer,There is a long history of proposed privacy definitions; new vulnerabilities discovered; andamended privacy definitions developed only to be broken once again. As privacy concernsspread; parallel copies of this process are spawned in many research areas. Fortunately;current research has identified many best practices for engineering robust privacyprotections for sensitive data. Although they can be formalized in a mathematically rigorousway; we present them at a more intuitive level; leveraging the following privacy definitions assources of examples.,Communications of the ACM,2015,15
Differentially Private Algorithms for Empirical Machine Learning,Ben Stoddard; Yan Chen; Ashwin Machanavajjhala,Abstract: An important use of private data is to build machine learning classifiers. While thereis a burgeoning literature on differentially private classification algorithms; we find that theyare not practical in real applications due to two reasons. First; existing differentially privateclassifiers provide poor accuracy on real world datasets. Second; there is no knowndifferentially private algorithm for empirically evaluating the private classifier on a private testdataset. In this paper; we develop differentially private algorithms that mirror real worldempirical machine learning workflows. We consider the private classifier training algorithmas a blackbox. We present private algorithms for selecting features that are input to theclassifier. Though adding a preprocessing step takes away some of the privacy budget fromthe actual classification process (thus potentially making it noisier and less accurate); we …,arXiv preprint arXiv:1411.5428,2014,15
SPARSI: partitioning sensitive data amongst multiple adversaries,Theodoros Rekatsinas; Amol Deshpande; Ashwin Machanavajjhala,Abstract We present SPARSI; a novel theoretical framework for partitioning sensitive dataacross multiple non-colluding adversaries. Most work in privacy-aware data sharing hasconsidered disclosing summaries where the aggregate information about the data ispreserved; but sensitive user information is protected. Nonetheless; there are applications;including online advertising; cloud computing and crowdsourcing markets; where detailedand fine-grained user data must be disclosed. We consider a new data sharing paradigmand introduce the problem of privacy-aware data partitioning; where a sensitive dataset mustbe partitioned among k untrusted parties (adversaries). The goal is to maximize the utilityderived by partitioning and distributing the dataset; while minimizing the total amount ofsensitive information disclosed. The data should be distributed so that an adversary …,Proceedings of the VLDB Endowment,2013,14
Opinion aggregation system,*,A system is disclosed for obtaining and aggregating opinions generated by multiple sourceswith respect to one or more objects. The disclosed system uses observed variablesassociated with an opinion and a probabilistic model to estimate latent properties of thatopinion. With those latent properties; the disclosed system may enable publishers to reliablyand comprehensively present object information to interested users.,*,2015,10
On the Privacy Properties of Variants on the Sparse Vector Technique,Yan Chen; Ashwin Machanavajjhala,Abstract: The sparse vector technique is a powerful differentially private primitive that allowsan analyst to check whether queries in a stream are greater or lesser than a threshold. Thistechnique has a unique property--the algorithm works by adding noise with a finite varianceto the queries and the threshold; and guarantees privacy that only degrades with (a) themaximum sensitivity of any one query in stream; and (b) the number of positive answersoutput by the algorithm. Recent work has developed variants of this algorithm; which we call{\em generalized private threshold testing}; and are claimed to have privacy guarantees thatdo not depend on the number of positive or negative answers output by the algorithm. Thesealgorithms result in a significant improvement in utility over the sparse vector technique for agiven privacy budget; and have found applications in frequent itemset mining; feature …,arXiv preprint arXiv:1508.07306,2015,10
User behavior-driven background cache refreshing,*,Methods and system for providing social feeds from a plurality of third party sites to a user ata host site includes retrieving one or more access logs capturing online behavior of the user.The access logs are analyzed to determine the user's interactive behavioral pattern relatedto social feeds from each of the plurality of third party sites. A refresh schedule for the user iscomputed to refresh cache entries of social feeds at the host site based on the analysis ofthe user's online behavior at the social feeds. Cache entries of social feeds for the user arerefreshed at the host site from the one or more of the plurality of third party sites at an allottedtime specified by the refresh schedule.,*,2014,10
System for opinion reconciliation,*,A system is disclosed for reconciling opinions generated by agents with respect to one ormore predicates. The disclosed system may use observed variables and a probabilisticmodel including latent parameters to estimate a truth score associated with each of thepredicates. The truth score; as well as one or more of the latent parameters of theprobabilistic model; may be estimated based on the observed variables. The truth scoregenerated by the disclosed system may enable publishers to reliably represent the truth of apredicate to interested users.,*,2011,10
Privacy in data publishing.,Johannes Gehrke; Daniel Kifer; Ashwin Machanavajjhala,No. 4417749 conducted hundreds of searches over a threemonth period on topics rangingfrom “numb fingers” to “60 single men” to “dog that urinates on everything.” And search bysearch; click by click; the identity of AOL user No. 4417749 became easier to discern. Thereare queries for q “landscapers in Lilburn; Ga;” several people with the last name Arnold and“homes sold in shadow lake subdivision gwinnett county georgia.” It did not take muchinvestigating to follow that data trail to Thelma Arnold; a 62-year-old widow who lives inLilburn; Ga.; frequently researches her friends' medical ailments and loves her threedogs.“Those are my searches;” she said; after a reporter read part of the list to her.,ICDE,2010,10
Asynchronous secure communication tolerating mixed adversaries,K Srinathan; MVN Ashwin Kumar; C Pandu Rangan,Abstract We study the problem of secure communication tolerating generalized mixedadversaries across an underlying completely asynchronous incomplete network. We explorethe interplay between the minimal network connectivity required and the degree of securityattainable; and completely characterize the network requirements for attaining perfect andunconditional (with negligible error) security. We also consider networks with additionalbroadcast capabilities and prove that unconditionally secure communication can beachieved with much lesser connectivity if the network assures the broadcast primitive.,International Conference on the Theory and Application of Cryptology and Information Security,2002,10
curso: protect yourself from curse of attribute inference: a social network privacy-analyzer,Eunsu Ryu; Yao Rong; Jie Li; Ashwin Machanavajjhala,Abstract While social networking platforms allow users to control how their privateinformation is shared; recent research has shown that a user's sensitive attribute can beinferred based on friendship links and group memberships; even when the attribute value isnot shared with anyone else. Thus; existing access control mechanisms are unable toprotect against such privacy breaches. Our research goal is to develop tools that help a userAlice be aware of privacy breaches via attribute inference. In this paper; we specifically focuson two problems:(a) whether Alice's sensitive attribute can be inferred based on publicinformation in Alice's neighborhood; and (b) whether making Alice's sensitive attribute publicleads to the disclosure of sensitive information of another user Bob in Alice's neighborhood.We propose three algorithms to detect the aforementioned privacy breaches. We limit our …,Proceedings of the ACM SIGMOD Workshop on Databases and Social Networks,2013,9
Pythia: Data dependent differentially private algorithm selection,Ios Kotsogiannis; Ashwin Machanavajjhala; Michael Hay; Gerome Miklau,Abstract Differential privacy has emerged as a preferred standard for ensuring privacy inanalysis tasks on sensitive datasets. Recent algorithms have allowed for significantly lowererror by adapting to properties of the input data. These so-called data-dependent algorithmshave different error rates for different inputs. There is now a complex and growing landscapeof algorithms without a clear winner that can offer low error over all datasets. As a result; thebest possible error rates are not attainable in practice; because the data curator cannotknow which algorithm to select prior to actually running the algorithm. We address thischallenge by proposing a novel meta-algorithm designed to relieve the data curator of theburden of algorithm selection. It works by learning (from non-sensitive data) the associationbetween dataset properties and the best-performing algorithm. The meta-algorithm is …,Proceedings of the 2017 ACM International Conference on Management of Data,2017,8
Sampling hidden objects using nearest-neighbor oracles,Nilesh Dalvi; Ravi Kumar; Ashwin Machanavajjhala; Vibhor Rastogi,Abstract Given an unknown set of objects embedded in the Euclidean plane and a nearest-neighbor oracle; how to estimate the set size and other properties of the objects? In thispaper we address this problem. We propose an efficient method that uses the Voronoipartitioning of the space by the objects and a nearest-neighbor oracle. Our method can beused in the hidden web/databases context where the goal is to estimate the number ofcertain objects of interest. Here; we assume that each object has a geographic location andthe nearest-neighbor oracle can be realized by applications such as maps; local; or store-locator APIs. We illustrate the performance of our method on several real-world datasets.,Proceedings of the 17th ACM SIGKDD international conference on Knowledge discovery and data mining,2011,8
Design of policy-aware differentially private algorithms,Samuel Haney; Ashwin Machanavajjhala; Bolin Ding,Abstract The problem of designing error optimal differentially private algorithms is wellstudied. Recent work applying differential privacy to real world settings have used variants ofdifferential privacy that appropriately modify the notion of neighboring databases. Theproblem of designing error optimal algorithms for such variants of differential privacy is open.In this paper; we show a novel transformational equivalence result that can turn the problemof query answering under differential privacy with a modified notion of neighbors to one ofquery answering under standard differential privacy; for a large class of neighbor definitions.We utilize the Blowfish privacy framework that generalizes differential privacy. Blowfish usesa policy graph to instantiate different notions of neighboring databases. We show that theerror incurred when answering a workload W on a database x under a Blowfish policy …,Proceedings of the VLDB Endowment,2015,6
Theory of Equal-Flows in networks,K Srinathan; Pranava R Goundan; MVN Ashwin Kumar; R Nandakumar; C Pandu Rangan,Abstract The Maximum-Flow problem is a classical problem in combinatorial optimizationand has many practical applications. We introduce a new variant of this well knownMaximum-Flow problem; viz.; the Maximum-Equal-Flow problem; wherein; for each vertex(other than the source) in the network; the actual flows along the arcs emanating from thatvertex are constrained to be equal and integral. Surprisingly; unlike the Maximum-Flowproblem that is known to admit a polynomial time solution; we prove that the Maximum-Equal-Flow problem is NP-Hard. Nevertheless; we provide an approximation algorithm forthe Maximum-Equal-Flow problem. We develop a new (analogous) theory for Equal-Flowsin networks and also illustrate the Maximum-Equal-Flow equivalents of the fundamentalresults in flow theory.,Lecture notes in computer science,2002,6
Protecting Visual Secrets using Adversarial Nets,Nisarg Raval; Ashwin Machanavajjhala; Landon P Cox,Abstract Protecting visual secrets is an important problem due to the prevalence of camerasthat continuously monitor our surroundings. Any viable solution to this problem should alsominimize the impact on the utility of applications that use images. In this work; we build onthe existing work of adversarial learning to design a perturbation mechanism that jointlyoptimizes privacy and utility objectives. We provide a feasibility study of the proposedmechanism and present ideas on developing a privacy framework based on the adversarialperturbation mechanism.,Computer Vision and Pattern Recognition Workshops (CVPRW); 2017 IEEE Conference on,2017,4
Utility Cost of Formal Privacy for Releasing National Employer-Employee Statistics,Samuel Haney; Ashwin Machanavajjhala; John M Abowd; Matthew Graham; Mark Kutzbach; Lars Vilhuber,Abstract National statistical agencies around the world publish tabular summaries based oncombined employer-employee (ER-EE) data. The privacy of both individuals and businessestablishments that feature in these data are protected by law in most countries. These dataare currently released using a variety of statistical disclosure limitation (SDL) techniques thatdo not reveal the exact characteristics of particular employers and employees; but lackprovable privacy guarantees limiting inferential disclosures. In this work; we present novelalgorithms for releasing tabular summaries of linked ER-EE data with formal; provableguarantees of privacy. We show that state-of-the-art differentially private algorithms add toomuch noise for the output to be useful. Instead; we identify the privacy requirementsmandated by current interpretations of the relevant laws; and formalize them using the …,Proceedings of the 2017 ACM International Conference on Management of Data,2017,4
A Framework for Sharing Confidential Research Data; Applied to Investigating Differential Pay by Race in the US Government,Andrés F Barrientos; Alexander Bolton; Tom Balmat; Jerome P Reiter; John M de Figueiredo; Ashwin Machanavajjhala; Yan Chen; Charley Kneifel; Mark DeLong,ABSTRACT Data stewards seeking to provide access to large-scale social science data facea difficult challenge. They have to share data in ways that protect privacy and confidentiality;are informative for many analyses and purposes; and are relatively straightforward to use bydata analysts. We present a framework for addressing this challenge. The framework usesan integrated system that includes fully synthetic data intended for wide access; coupledwith means for approved users to access the confidential data via secure remote accesssolutions; glued together by verification servers that allow users to assess the quality of theiranalyses with the synthetic data. We apply this framework to data on the careers ofemployees of the US federal government; studying differentials in pay by race. Theintegrated system performs as intended; allowing users to explore the synthetic data for …,arXiv preprint arXiv:1705.07872,2017,3
System and/or method for processing events,*,The publish/subscribe (“pub/sub”) paradigm in which a large population of users expresseslong-term interests (“subscriptions”) over streams of “published events” has gained immensepopularity in recent years; at least in part due to the availability of increasing volumes of dynamicinformation available over the worldwide web such as; or example; stock quotes and newsreports. A pub/sub engine typically matches an incoming event to a subset of standingsubscriptions. For example; streams of event messages originating at one or more“publishers” may be matched with the interests of one or more pre-registered “subscribers …Non-limiting and non-exhaustive embodiments will be described with reference to the followingfigures; wherein like reference numerals refer to like parts throughout the various figures unlessotherwise specified … FIG. 1 is a schematic diagram of a tree comprising nodes …,*,2011,3
Trusted cvs,Muthuramakrishnan Venkitasubramaniam; Ashwin Machanavajjhala; David Martin; Johannes Gehrk,The CVS (Concurrent Versions System) software is a popular method for recordingmodifications to data objects; in addition to concurrent access to data in a multi-userenvironment. In current implementations; all users have to trust that the CVS server performsall user operations as instructed. In this paper; we develop protocols that allow users toverify that the server has been compromised; and that it has performed exactly the users'operations on the data. We first show that communication between users is necessary toguarantee that users can detect that the server has been compromised. We then proposeefficient protocols that fast enable detection of server integrity under CVS workloads. Ourtechniques also have applications in the outsourcing model where multiple users own acommon database maintained by an untrusted third-party vendor.,22nd International Conference on Data Engineering Workshops (ICDEW'06),2006,3
Differentially Private Regression Diagnostics,Yan Chen; Ashwin Machanavajjhala; Jerome P Reiter; Andrés F Barrientos,Linear and logistic regression are popular statistical techniques for analyzing multi-variatedata. Typically; analysts do not simply posit a particular form of the regression model;estimate its parameters; and use the results for inference orprediction. Instead; they first usea variety of diagnostic techniques to assess how well the model fits the relationships in thedata and how well it can be expected to predict outcomes for out-of-sample records; revisingthe model as necessary to improve fit and predictive power. In this article; we develop ε-differentially private diagnostics for regression; beginning to fill a gap in privacy-preservingdata analysis. Specifically; we create differentially private versions of residual plots for linearregression and of receiver operating characteristic (ROC) curves for logistic regression. Theformer helps determine whether or not the data satisfy the assumptions underlying the …,Data Mining (ICDM); 2016 IEEE 16th International Conference on,2016,2
Differential privacy in the wild: a tutorial on current practices & open challenges,Ashwin Machanavajjhala; Xi He; Michael Hay,Abstract Differential privacy has emerged as an important standard for privacy preservingcomputation over databases containing sensitive information about individuals. Researchon differential privacy spanning a number of research areas; including theory; security;database; networks; machine learning; and statistics; over the last decade has resulted in avariety of privacy preserving algorithms for a number of analysis tasks. Despite maturingresearch efforts; the adoption of differential privacy by practitioners in industry; academia; orgovernment agencies has so far been rare. Hence; in this tutorial; we will first describe thefoundations of differentially private algorithm design that cover the state of the art in privatecomputation on tabular data. In the second half of the tutorial we will highlight real worldapplications on complex data types; and identify research challenges in applying …,Proceedings of the VLDB Endowment,2016,2
Scalable Social Coordination using Enmeshed Queries,Jianjun Chen; Ashwin Machanavajjhala; George Varghese,Abstract: Social coordination allows users to move beyond awareness of their friends toefficiently coordinating physical activities with others. While specific forms of socialcoordination can be seen in tools such as Evite; Meetup and Groupon; we introduce a moregeneral model using what we call enmeshed queries. An enmeshed query allows users todeclaratively specify an intent to coordinate by specifying social attributes such as thedesired group size and who/what/when; and the database returns matching queries.Enmeshed queries are continuous; but new queries (and not data) answer older queries; thevariable group size also makes enmeshed queries different from entangled queries; publish-subscribe systems; and dating services. We show that even offline group coordination usingenmeshed queries is NP-hard. We then introduce efficient heuristics that use selective …,Arxiv preprint arXiv:1205.0435,2012,2
ℓ-Diversity,Johannes Gehrke; Daniel Kifer; Ashwin Machanavajjhala,Background Many organizations are increasingly publishing microdata–tables that containinformation about individuals that is not aggregated in any way. Examples include medical;voter registration; census; and customer data. Microdata is a valuable source of informationfor subsequent data analysis–medical research; the allocation of public funds; or trendanalysis; just to name a few. However; if individuals can be uniquely identified in themicrodata; then their private information is disclosed; and this is unacceptable.,*,2011,2
An indexing framework for structured p2p systems,Adina Crainiceanu; Prakash Linga; Ashwin Machanavajjhala; Johannes Gehrke; Carl Lagoze; Jayavel Shanmugasundaram,Abstract Different collaborative applications in a peer-topeer (P2P) environment imposedifferent requirements on the underlying P2P system. In this paper; we present amodularized indexing framework that cleanly separates the functional components of astructured P2P index; thereby allowing an application to tailor an index to its needs; whilereusing components developed in previous systems. Our main contribution is a systematicway of handling query correctness; concurrency; and failures in the context of our indexingframework. Our techniques provide provable correctness and availability guarantees in adynamic P2P system. In a simulation study; we use our indexing framework to compare theperformance of three different P2P indices proposed in the literature. 1,*,2004,2
Differentially private significance tests for regression coefficients,Andrés F Barrientos; Jerome P Reiter; Ashwin Machanavajjhala; Yan Chen,Abstract: Many data producers seek to provide users access to confidential data withoutunduly compromising data subjects' privacy and confidentiality. When intense redaction isneeded to do so; one general strategy is to require users to do analyses without seeing theconfidential data; for example; by releasing fully synthetic data or by allowing users to queryremote systems for disclosure-protected outputs of statistical models. With fully syntheticdata or redacted outputs; the analyst never really knows how much to trust the resultingfindings. In particular; if the user did the same analysis on the confidential data; wouldregression coefficients of interest be statistically significant or not? We present algorithms forassessing this question that satisfy differential privacy. We describe conditions under whichthe algorithms should give accurate answers about statistical significance. We illustrate …,arXiv preprint arXiv:1705.09561,2017,1
Directed Edge Recommender System,Ios Kotsogiannis; Elena Zheleva; Ashwin Machanavajjhala,Abstract Recommender systems have become ubiquitous in online applications wherecompanies personalize the user experience based on explicit or inferred user preferences.Most modern recommender systems concentrate on finding relevant items for eachindividual user. In this paper; we describe the problem of directed edge recommendationswhere the system recommends the best item that a user can gift; share or recommend toanother user that he/she is connected to. We propose algorithms that utilize the preferencesof both the sender and the recipient by integrating individual user preference models (eg;based on items each user purchased for themselves) with models of sharing preferences(eg; gift purchases for others) into the recommendation process. We compare our work togroup recommender systems and social network edge labeling; showing that …,Proceedings of the Tenth ACM International Conference on Web Search and Data Mining,2017,1
Privacy-Preserving Data Analysis for the Federal Statistical Agencies,John Abowd; Lorenzo Alvisi; Cynthia Dwork; Sampath Kannan; Ashwin Machanavajjhala; Jerome Reiter,Abstract: Government statistical agencies collect enormously valuable data on the nation'spopulation and business activities. Wide access to these data enables evidence-basedpolicy making; supports new research that improves society; facilitates training for studentsin data science; and provides resources for the public to better understand and participate intheir society. These data also affect the private sector. For example; the EmploymentSituation in the United States; published by the Bureau of Labor Statistics; moves markets.Nonetheless; government agencies are under increasing pressure to limit access to databecause of a growing understanding of the threats to data privacy and confidentiality.,arXiv preprint arXiv:1701.00752,2017,1
ePrivateEye: To the Edge and Beyond!,Christopher Streiffer; Animesh Srivastava; Victor Orlikowski; Yesenia Velasco; Vincentius Martin; Nisarg Raval; Ashwin Machanavajjhala; Landon P Cox,Abstract Edge computing offers resource-constrained devices low-latency access to high-performance computing infrastructure. In this paper; we present ePrivateEye; animplementation of PrivateEye that offloads computationally expensive computer-visionprocessing to an edge server. The original PrivateEye locally processed video frames on amobile device and delivered approximately 20 fps; whereas ePrivateEye transfers frames toa remote server for processing. We present experimental results that utilize our campusSoftware-Defined Networking infrastructure to characterize how network-path latency;packet loss; and geographic distance impact offloading to the edge in ePrivateEye. We showthat offloading video-frame analysis to an edge server at a metro-scale distance allowsePrivateEye to analyze more frames than PrivateEye's local processing over the same …,*,2017,1
A demonstration of VisDPT: visual exploration of differentially private trajectories,Xi He; Nisarg Raval; Ashwin Machanavajjhala,Abstract The release of detailed taxi trips has motivated numerous useful studies; but hasalso triggered multiple privacy attacks on individuals' trips. Despite these attacks; no toolsare available for systematically analyzing the privacy risk of released trajectory data. While;recent studies have proposed mechanisms to publish synthetic mobility data with provableprivacy guarantees; the questions on--1) how to explain the theoretical privacy guarantee tonon-privacy experts; and 2) how well private data preserves the properties of ground truth;remain unclear. To address these issues; we propose a system---VisDPT that provides richvisualization of sensitive information in trajectory databases and helps data curatorsunderstand the impact on utility due to privacy preserving mechanisms. We believe VisDPTwill enable data curators to take informed decisions while publishing sanitized data.,Proceedings of the VLDB Endowment,2016,1
Exploring Privacy-Accuracy Tradeoffs using DPComp,Michael Hay; Ashwin Machanavajjhala; Gerome Miklau; Yan Chen; Dan Zhang; George Bissias,Abstract The emergence of differential privacy as a primary standard for privacy protectionhas led to the development; by the research community; of hundreds of algorithms forvarious data analysis tasks. Yet deployment of these techniques has been slowed by thecomplexity of algorithms and an incomplete understanding of the cost to accuracy implied bythe adoption of differential privacy. In this demonstration we present DPComp; a publicly-accessible web-based system; designed to support a broad community of users; includingdata analysts; privacy researchers; and data owners. Users can use DPComp to assess theaccuracy of state-of-the-art privacy algorithms and interactively explore algorithm output inorder to understand; both quantitatively and qualitatively; the error introduced by thealgorithms. In addition; users can contribute new algorithms and new (non-sensitive) …,Proceedings of the 2016 International Conference on Management of Data,2016,1
Releasing True Data with Formal Privacy Guarantees,Stylianos Doudalis; Sharad Mehrotra; Samuel Haney; Ashwin Machanavajjhala,User activity logs on search engines; e-commerce sites and social networks contain awealth of information that has revolutionized search and advertising. These data are alsovaluable for furthering scientific and medical research (eg Google Flu 1). However; since therelease of AOL search logs and the Netflix challenge dataset in 2006; both of which led towidely publicized breaches of individual privacy; internet companies have become waryabout releasing user activity data for research. Fast forward a decade and the field ofanonymization and privacy preserving computation has modernized with a mathematicalnotion called ϵ-differential privacy [1] becoming the de facto standard for provably privatedata releases. An algorithm operating on a private database of records satisfies differentialprivacy if its outputs are insensitive to the presence or absence of any single record in the …,Privacy-Preserving IR Workshop at SIGIR,2016,1
Scalable Social Coordination with Group Constraints using Enmeshed Queries.,Jianjun Chen; Ashwin Machanavajjhala; George Varghese,ABSTRACT While specific forms of social coordination appear in tools such as Meetup andin game platforms such as XBox LIVE; we introduce a more general model using what wecall enmeshed queries. An enmeshed query allows users to declaratively specify an intent tocoordinate with other users (who they may not know a priori) by specifying constraints onwho/what/when as well as on the composition of the group; such as the desired group size.The database returns a group of users who have registered queries with matching intents.Enmeshed queries are continuous; but new queries (and not data) answer older queries; thegroup constraints and the ability to coordinate with unknown partners make enmeshedqueries differ from entangled queries; publish-subscribe systems; dating services andnested transactions. While even offline group coordination using enmeshed queries is NP …,CIDR,2013,1
Defining and enforcing privacy in data sharing,Ashwin Kumar VenkataNaga Machanavajjhala,Recent advances in processing and storing information has led to an explosion of datacollection. Many organizations like the Census; hospitals and even search enginecompanies collect; analyze and distribute personal information in return for useful services.However; the collected data track entire public and private lives of individuals; thus resultingin an immense privacy risk of unauthorized disclosure. This dissertation presents novelconceptual and practical tools to ensure privacy of individuals while enabling thedissemination of valuable data about humans to improve their lives. Our contributionsinclude novel formal definitions of the privacy risk arising from unauthorized disclosure; andpractical algorithms for enforcing these definitions of privacy. We consider two distinctsettings of data dissemination that require different notions of privacy. In the first part of …,*,2008,1
Asynchronous perfectly secure computation tolerating generalized adversaries,MVN Ashwin Kumar; K Srinathan; C Pandu Rangan,Abstract We initiate the study of perfectly secure multiparty computation over asynchronousnetworks tolerating generalized adversaries. The classical results in information-theoretically secure asynchronous multiparty computation among n players state that lessthan n 4 active adversaries can be tolerated in the perfect setting 4. Strictly generalizingthese results to the non-threshold setting; we show that perfectly secure asynchronousmultiparty computation among n players tolerating the adversary structure A is possible ifand only if the union of no four sets in the adversary structure cover the full set of players.The computation and communication complexities of the presented protocols are polynomialin the size of the maximal basis of the adversary structure. Our results generalize the resultsof 16; 10 to the asynchronous setting. Furthermore; when restricted to the threshold …,Lecture notes in computer science,2002,1
DIAS: Differentially Private Interactive Algorithm Selection using Pythia,Ios Kotsogiannis; Michael Hay; Ashwin Machanavajjhala; Gerome Miklau; Margaret Orr,Abstract Differential privacy has emerged as the dominant privacy standard for dataanalysis. Its wide acceptance has led to significant development of algorithms that meet thisrigorous standard. For some tasks; such as the task of answering low dimensional countingqueries; dozens of algorithms have been proposed. However; no single algorithm hasemerged as the dominant performer; and in fact; algorithm performance varies drasticallyacross inputs. Thus; it's not clear how to select an algorithm for a particular task; andchoosing the wrong algorithm might lead to significant degradation in terms of analysisaccuracy. We believe that the difficulty of algorithm selection is one factor limiting theadoption of differential privacy in real systems. In this demonstration we present DIAS(Differentially-private Interactive Algorithm Selection); an educational privacy game …,Proceedings of the 2017 ACM International Conference on Management of Data,2017,*
Scaling Private Record Linkage using Output Constrained Differential Privacy,Xi He; Ashwin Machanavajjhala; Cheryl Flynn; Divesh Srivastava,Abstract: Many scenarios require computing the join of databases held by two or moreparties that do not trust one another. Private record linkage is a cryptographic tool that allowssuch a join to be computed without leaking any information about records that do notparticipate in the join output. However; such strong security comes with a cost: except forexact equi-joins; these techniques have a high computational cost. While blocking has beenused to successfully scale non-private record linkage trading off efficiency with outputaccuracy; we show that prior techniques that use blocking; even based on differentiallyprivate algorithms; result in leakage of non-matching records. In this paper; we seekmethods for speeding up private record linkage with strong provable privacy guarantees. Wepropose a novel privacy model; called output constrained differential privacy; that shares …,arXiv preprint arXiv:1702.00535,2017,*
Composing Differential Privacy and Secure Computation: A case study on scaling private record linkage,Xi He; Ashwin Machanavajjhala; Cheryl Flynn; Divesh Srivastava,Abstract Private record linkage (PRL) is the problem of identifying pairs of records that aresimilar as per an input matching rule from databases held by two parties that do not trust oneanother. We identify three key desiderata that a PRL solution must ensure:(1) perfectprecision and high recall of matching pairs;(2) a proof of end-to-end privacy; and (3)communication and computational costs that scale subquadratically in the number of inputrecords. We show that all of the existing solutions for PRL? including secure 2-partycomputation (S2PC); and their variants that use non-private or differentially private (DP)blocking to ensure subquadratic cost--violate at least one of the three desiderata. Inparticular; S2PC techniques guarantee end-to-end privacy but have either low recall orquadratic cost. In contrast; no end-to-end privacy guarantee has been formalized for …,*,2017,*
PeGaSus: Data-Adaptive Differentially Private Stream Processing,Yan Chen; Ashwin Machanavajjhala; Michael Hay; Gerome Miklau,Abstract Individuals are continually observed by an ever-increasing number of sensors thatmake up the Internet of Things. The resulting streams of data; which are analyzed in realtime; can reveal sensitive personal information about individuals. Hence; there is an urgentneed for stream processing solutions that can analyze these data in real time with provableguarantees of privacy and low error. We present PeGaSus; a new algorithm for differentiallyprivate stream processing. Unlike prior work that has focused on answering individualqueries over streams; our algorithm is the first that can simultaneously support a variety ofstream processing tasks--counts; sliding windows; event monitoring--over multipleresolutions of the stream. PeGaSus uses a Perturber to release noisy counts; a data-adaptive Perturber to identify stable uniform regions in the stream; and a query specific …,*,2017,*
Ayumu: Efficient lifelogging with focused tasks,Ben Stoddard; Kate O’Hanlon; Brian Lin; Ashwin Machanavajjhala; Landon P Cox,ABSTRACT Today's lifelogging devices capture images periodically without consideringwhat data is important to users. Due to their small form factors and limited battery capacities;these lifeloggers are bound to miss important data either because they record at a slow rateto conserve power; or because they record at such a high rate that they must frequentlyrecharge. In this paper; we present a new approach to lifelogging that better utilizes adevice's battery by integrating knowledge of the specific information that a user wantscaptured. We have developed the first instance of such a focused-task lifelogging systemcalled Ayumu; which aims to capture the reading material that a user interacts with over thecourse of a day. Instead of capturing images periodically; Ayumu uses a suite of inexpensivesensors to record only when reading material is present. By recognizing when it would be …,Proceedings of the 8th EAI International Conference on Mobile Computing; Applications and Services,2016,*
Presentation: NCRN Fall 2015: Formal Privacy Protection for Data Products Combining Individual and Employer Frames,John M Abowd; Samuel Haney; Ashwin Machanavajjhala; Mark Kutzbach; Matthew Graham; Lars Vilhuber,Published tabular summaries of linked employer-employee data usually use a job frame(statutory employer linked to a specific employee) but include characteristics of both theindividual (employee) and workplace (employer establishment). Formal privacy protection ofthese characteristics requires defining the sensitivity of the published statistic to variation ina single individual or a single workplace (establishment). We propose a model thatsimultaneously protects individuals and establishments using parameters that control theconventional differential privacy for individuals and a generalization that provides a similarprivacy guarantee for the employment magnitudes associated with an employerestablishment. We implement our model using three alternative noise distributions. Wepresent results for cross-sectional employment summaries for combinations of employer …,*,2015,*
Curso,Eunsu Ryu; Yao Rong; Jie Li; Ashwinkumar Venkatanaga Machanavajjhala,*,3rd ACM SIGMOD Workshop on Databases and Social Networks; DBSocial 2013,2013,*
Sparsi,Theodoros Rekatsinas; Amol Deshpande; Ashwinkumar Venkatanaga Machanavajjhala,*,*,2013,*
Challenges in enabling social application at scale: cloudDB'12 invited-keynote talk abstract,Ashwin Machanavajjhala,Abstract Internet users spend billions of minutes per month on social networking sites likeFacebook; LinkedIn and Twitter. Not only do they create tons of data everyday in the form ofposts; tweets and photos; the connections between users have given rise to newapplications for social discovery and engagement. In this talk I will highlight the novel datamanagement and privacy challenges in three such applications:(i) Feed Following; or theproblem of delivering highly personalized feeds based on content generated by one'sfriends;(ii) Social Coordination; or the problem of jointly planning and coordinating on a task;and (iii) Social Recommendations; or recommending objects and people based on one'ssocial connections.,Proceedings of the fourth international workshop on Cloud data management,2012,*
E-Privacy,Johannes Gehrke; Ashwin Machanavajjhala,Background E uses a secret key of at most bits; and an initialization vector IV ofbits. IV is composed of a-bit Bluetooth address; and a-bit master counter. Bluetoothprotocol processes frames of at most bits; each frame being encrypted with a differentIV; while the secret key K remains the same for the whole session. As usual for streamciphers; encryption/decryption relies on two important steps: the setup of the initial state andthe keystream generation. The system is derived from the⊳ summation generator; with fourinputs⊳ LFSRs and four memory bits. The four LFSRs have lengths;;; and;respectively; their feedback polynomials are all primitive; with five nonzero,Encyclopedia of Cryptography and Security,2011,*
Article 16 (30 pages)-Load Balancing and Range Queries in P2P Systems Using P-Ring,A Crainiceanu; P Linga; A Machanavajjhala; J Gehrke; J Shanmugasundaram,*,ACM Transactions on Internet Technology,2010,*
Randomization Methods to Ensure Data Privacy,Ashwin Machanavajjhala; Johannes Gehrke,Many organizations; eg; government statistical offices and search engine companies; collectpotentially sensitive information regarding individuals either to publish this data for research;or in return for useful services. While some data collection organizations; like the census; arelegally required not to breach the privacy of the individuals; other data collectionorganizations may not be trusted to uphold privacy. Hence; if U denotes the original datacontaining sensitive information about a set of individuals; then an untrusted data collectoror researcher should only have access to an anonymized version of the data; U*; that doesnot disclose the sensitive information about the individuals. A randomized anonymizationalgorithm R is said to be a privacy preserving randomization method if for every table T; andfor every output T*= R (T); the privacy of all the sensitive information of each individual in …,*,2009,*
Privacy preserving data publishing,Bee-Chung Chen; Daniel Kifer; Kristen LeFevre; Ashwin Machanavajjhala,*,Foundations and Trends in Databases,2009,*
Method For Generating Score-Optimal R-Trees,*,A method of constructing a score-optimal R-tree to support top-k stabbing queries over a setof scored intervals generates a constraint graph from the set; and determines over eachnode in the constraint graph that has no other nodes pointing to it the node with the smallestleft endpoint; for each of these nodes; the associated interval is added to the tree and thenode is removed from the constraint graph.,*,2008,*
On perfectly secure communication over arbitrary networks,C Pandu Rangan M V N Ashwin Kumar; P R Goundan; K. Srinathan,*,Principled of Distributed Computing,2002,*
Is my model any good: differentially private regression diagnostics,Yan Chen; Andrés F Barrientos; Ashwin Machanavajjhala; Jerome P Reiter,Abstract Linear and logistic regression are popular statistical techniques for analyzing multi-variate data. Typically; analysts do not simply posit a particular form of the regression model;estimate its parameters; and use the results for inference or prediction. Instead; they first usea variety of diagnostic techniques to assess how well the model fits the relationships in thedata and how well it can be expected to predict outcomes for out-of-sample records; revisingthe model as necessary to improve fit and predictive power. In this article; we develop ϵ ϵ-differentially private diagnostics tools for regression; beginning to fill a gap in privacy-preserving data analysis. Specifically; we create differentially private versions of residualplots for linear regression and of receiver operating characteristic (ROC) curves as well asbinned residual plot for logistic regression. The residual plot and binned residual plot …,Knowledge and Information Systems,*,*
Entity Resolution: Tutorial,Ashwin Machanavajjhala,*,*,*,*
Demo Program Committee,Sihem Amer-Yahia; Arvind Arasu; Sunil Arvindam; Magdalena Balazinska; Fabio Casati; Malu Castellanos; Mariano Cilia; Brian F Cooper; Adina Crainiceanu; Abhinandan Das; Alin Dobra; Pablo Guerrero; Christian Konig; Georgia Koutrika; Wolfgang Lehner; Feifei Li; Ashwin Machanavajjhala; Thomas Neumann; Dan Olteanu; Carlos Ordonez; Peter Pietzuch; Adam Silberstein; Alkis Simitsis,Sihem Amer-Yahia; Qatar Computing Research Institute Arvind Arasu; Microsoft Research SunilArvindam; SAP Research; India Magdalena Balazinska; University of Washington FabioCasati; University of Trento; Italy Malu Castellanos; HP Labs; USA Mariano Cilia; IntelCorporation; Argentina Brian F Cooper; Google Adina Crainiceanu; US Naval Academy AbhinandanDas; Google Alin Dobra; University of Florida Javier Garcia-Garcia; UNAM University; MexicoPablo Guerrero; TU Darmstadt; Germany Melanie Herschel; Tubingen University ChristianKonig; Microsoft Research Georgia Koutrika; IBM Almaden Research Center WolfgangLehner; TU Dresden; Germany Feifei Li; Florida State University Ashwin Machanavajjhala; YahooResearch Thomas Neumann; TU Munchen Dan Olteanu; University of Oxford CarlosOrdonez; University of Houston Peter Pietzuch; Imperial College London Lin Qiao; IBM …,*,*,*
Composition for Statistical Databases,Ashwin Machanavajjhala,*,*,*,*
Principled Evaluation of Differentially Private Algorithms,Michael Hay; Ashwin Machanavajjhala; Gerome Miklau; Yan Chen; Dan Zhang,Abstract The emergence of differential privacy as a primary standard for privacy protectionhas led to the development of hundreds of algorithms for various data analysis tasks. Thesealgorithms are becoming increasingly complex; and in particular; the performance of manyemerging algorithms is data dependent; meaning the distribution of the noise added toquery answers may change depending on the input data. Theoretical analysis typically onlyconsiders the worst case; making empirical study of average case performance increasinglyimportant. We propose a set of evaluation principles which we argue are essential for soundevaluation. Based on these principles we propose DPBENCH; a novel evaluation frameworkfor standardized evaluation of privacy algorithms. We then apply our benchmark to evaluatealgorithms for answering 1-and 2-dimensional range queries. The result is a thorough …,*,*,*
ε-Privacy: Data Publishing against Realistic Adversaries,Michaela Götz; Ashwin Machanavajjhala; Johannes Gehrke,Page 1. ε-Privacy: Data Publishing against Realistic Adversaries Speaker: Michaela Götz Jointwork with: Ashwin Machanavajjhala and Johannes Gehrke Cornell University Page 2. Name AgeZip Disease Bob 17 13005 Heart Disease Jim 19 13000 Viral Infection Cathy 20 14850 CancerAnne 24 14850 Heart Disease Joe 29 14850 Viral Infection Marie 34 13005 Cancer Dana 39 13005Cancer Bill 45 13010 Cancer Data Curator Individuals table T Setting Published table T' Bob 1713005 Heart Disease Bill 45 13010 Cancer Users ε-Privacy VLDB 2009 Age Zip Disease < 201300* Heart Disease < 20 1300* Viral Infection 2* 14850 Cancer 24 14850 Heart Disease 29 14850Viral Infection 34 130** Cancer 39 130** Cancer 45 130** Cancer Page 3. • What is sensitiveinformation? ▫ “Bob has ulcer” ▫ “Bob has some stomach disease” • What is privacy? ▫ Adversarydoes not learn much about Bob's sensitive information …,*,*,*
The Cost of Provable Privacy: A Case Study on Linked Employer-Employee Data,Samuel Haney; Ashwin Machanavajjhala; John M Abowd; Matthew Graham; Mark Kutzbach; Lars Vilhuber,*,*,*,*
Muthuramakrishnan Venkitasubramaniam Cornell University,Ashwin Machanavajjhala; Johannes Gehrke; Daniel Kifer,*,*,*,*
