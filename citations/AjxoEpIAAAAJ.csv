Supervised Hashing with Kernels,W Liu; J Wang; R Ji; YG Jiang; SF Chang,Recent years have witnessed the growing popularity of hashing in large-scale visionproblems. It has been shown that the hashing quality could be boosted by leveragingsupervised information into hash function learning. However; the existing supervisedmethods either lack adequate performance or often incur cumbersome model training. In thispaper; we propose a novel kernel-based supervised hashing model which requires a limitedamount of supervised information; ie; similar and dissimilar data pairs; and a feasibletraining cost in achieving high quality hashing. The idea is to map the data to compact binarycodes whose Hamming distances are minimized on similar pairs and simultaneouslymaximized on dissimilar pairs. Our approach is distinct from prior works by utilizing theequivalence between optimizing the code inner products and the Hamming distances …,Proceedings of IEEE Conference on Computer Vision and Pattern Recognition (CVPR),2012,707
Hashing with Graphs,W. Liu; J. Wang; S. Kumar; S. Chang,Abstract Hashing is becoming increasingly popular for efficient nearest neighbor search inmassive databases. However; learning short codes that yield good search performance isstill a challenge. Moreover; in many cases realworld data lives on a low-dimensionalmanifold; which should be taken into account to capture meaningful nearest neighbors. Inthis paper; we propose a novel graph-based hashing method which automatically discoversthe neighborhood structure inherent in the data to learn appropriate compact codes. Tomake such an approach computationally feasible; we utilize Anchor Graphs to obtaintractable low-rank adjacency matrices. Our formulation allows constant time hashing of anew data point by extrapolating graph Laplacian eigenvectors to eigenfunctions. Finally; wedescribe a hierarchical threshold learning procedure in which each eigenfunction yields …,Proceedings of International Conference on Machine Learning (ICML),2011,600
Large graph construction for scalable semi-supervised learning,Wei Liu; Junfeng He; Shih-Fu Chang,*,Proceedings of International Conference on Machine Learning (ICML),2010,316
Learning distance metrics with contextual constraints for image retrieval,Steven CH Hoi; Wei Liu; Michael R Lyu; Wei-Ying Ma,Relevant Component Analysis (RCA) has been proposed for learning distance metrics withcontextual constraints for image retrieval. However; RCA has two important disadvantages.One is the lack of exploiting negative constraints which can also be informative; and theother is its incapability of capturing complex nonlinear relationships between data instanceswith the contextual information. In this paper; we propose two algorithms to overcome thesetwo disadvantages; ie; Discriminative Component Analysis (DCA) and Kernel DCA.Compared with other complicated methods for distance metric learning; our algorithms arerather simple to understand and very easy to solve. We evaluate the performance of ouralgorithms on image retrieval in which experimental results show that our algorithms areeffective and promising in learning good quality distance metrics for image retrieval.,Proceedings of IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR),2006,288
Supervised Discrete Hashing,Fumin Shen; Chunhua Shen; Wei Liu; Heng Tao Shen,Recently; learning based hashing techniques have attracted broad research interests due tothe resulting efficient storage and retrieval of images; videos; documents; etc. However; amajor difficulty of learning to hash lies in handling the discrete constraints imposed on theneeded hash codes. In general; the discrete constraints imposed on the binary codes thatthe target hash functions generate lead to mixed-integer optimization problems—which isgenerally NP hard. To simplify the optimization involved in a binary code learningprocedure; most of the aforementioned methods choose to first solve a relaxed problemthrough directly discarding the discrete constraints; and then threshold the continuousoutputs to be binary. This greatly simplifies the optimization but; unfortunately; theapproximated solution is typically of low quality and often makes the final hash functions …,Proceedings of IEEE Conference on Computer Vision and Pattern Recognition (CVPR),2015,275
Semi-supervised distance metric learning for collaborative image retrieval,Steven CH Hoi; Wei Liu; Shih-Fu Chang,*,Proceedings of IEEE Conference on Computer Vision and Pattern Recognition (CVPR),2008,226
Trajectory-Based Modeling of Human Actions with Motion Reference Points,Yu-Gang Jiang; Qi Dai; Xiangyang Xue; Wei Liu; Chong-Wah Ngo,Abstract Human action recognition in videos is a challenging problem with wideapplications. State-of-the-art approaches often adopt the popular bag-of-featuresrepresentation based on isolated local patches or temporal patch trajectories; where motionpatterns like object relationships are mostly discarded. This paper proposes a simplerepresentation specifically aimed at the modeling of such motion relationships. We adoptglobal and local reference points to characterize motion information; so that the finalrepresentation can be robust to camera movement. Our approach operates on top of visualcodewords derived from local patch trajectories; and therefore does not require accurateforeground-background separation; which is typically a necessary step to model objectrelationships. Through an extensive experimental evaluation; we show that the proposed …,The 12th European Conference on Computer Vision (ECCV),2012,188
Discrete Graph Hashing,Wei Liu; Cun Mu; Sanjiv Kumar; Shih-Fu Chang,Abstract Hashing has emerged as a popular technique for fast nearest neighbor search ingigantic databases. In particular; learning based hashing has received considerableattention due to its appealing storage and search efficiency. However; the performance ofmost unsupervised learning based hashing methods deteriorates rapidly as the hash codelength increases. We argue that the degraded performance is due to inferior optimizationprocedures used to achieve discrete binary codes. This paper presents a graph-basedunsupervised hashing model to preserve the neighborhood structure of massive data in adiscrete code space. We cast the graph hashing problem into a discrete optimizationframework which directly learns the binary codes. A tractable alternating maximizationalgorithm is then proposed to explicitly deal with the discrete constraints; yielding high …,Advances in Neural Information Processing Systems (NIPS),2014,158
Learning to hash for indexing big data—a survey,Jun Wang; Wei Liu; Sanjiv Kumar; Shih-Fu Chang,The explosive growth in Big Data has attracted much attention in designing efficient indexingand search methods recently. In many critical applications such as large-scale search andpattern matching; finding the nearest neighbors to a query is a fundamental researchproblem. However; the straightforward solution using exhaustive comparison is infeasibledue to the prohibitive computational complexity and memory requirement. In response;approximate nearest neighbor (ANN) search based on hashing techniques has becomepopular due to its promising performance in both efficiency and accuracy. Prior randomizedhashing methods; eg; locality-sensitive hashing (LSH); explore data-independent hashfunctions with random projections or permutations. Although having elegant theoreticguarantees on the search quality in certain metric spaces; performance of randomized …,Proceedings of the IEEE,2016,140
Scalable similarity search with optimized kernel hashing,Junfeng He; Wei Liu; Shih-Fu Chang,Abstract Scalable similarity search is the core of many large scale learning or data miningapplications. Recently; many research results demonstrate that one promising approach iscreating compact and efficient hash codes that preserve data similarity. By efficient; we referto the low correlation (and thus low redundancy) among generated codes. However; mostexisting hash methods are designed only for vector data. In this paper; we develop a newhashing algorithm to create efficient codes for large scale data of general formats with anykernel function; including kernels on vectors; graphs; sequences; sets and so on. Startingwith the idea analogous to spectral hashing; novel formulations and solutions are proposedsuch that a kernel based hash function can be explicitly represented and optimized; anddirectly applied to compute compact hash codes for new samples of general formats …,Proceedings of the 16th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining (KDD),2010,111
Towards Large-Scale Histopathological Image Analysis: Hashing-Based Image Retrieval,Xiaofan Zhang; Wei Liu; Murat Dundar; Sunil Badve; Shaoting Zhang,Automatic analysis of histopathological images has been widely utilized leveragingcomputational image-processing methods and modern machine learning techniques. Bothcomputer-aided diagnosis (CAD) and content-based image-retrieval (CBIR) systems havebeen successfully developed for diagnosis; disease detection; and decision support in thisarea. Recently; with the ever-increasing amount of annotated medical data; large-scale anddata-driven methods have emerged to offer a promise of bridging the semantic gap betweenimages and diagnostic information. In this paper; we focus on developing scalable image-retrieval techniques to cope intelligently with massive histopathological images. Specifically;we present a supervised kernel hashing technique which leverages a small amount ofsupervised information in learning to compress a 10\thinspace000-dimensional image …,IEEE Transactions on Medical Imaging,2015,110
Robust and Scalable Graph-Based Semisupervised Learning,Wei Liu; Jun Wang; S-F Chang,Graph-based semisupervised learning (GSSL) provides a promising paradigm for modelingthe manifold structures that may exist in massive data sources in high-dimensional spaces. Ithas been shown effective in propagating a limited amount of initial labels to a large amountof unlabeled data; matching the needs of many emerging applications such as imageannotation and information retrieval. In this paper; we provide reviews of several classicalGSSL methods and a few promising methods in handling challenging issues oftenencountered in web-scale applications. First; to successfully incorporate the contaminatednoisy labels associated with web data; label diagnosis and tuning techniques applied toGSSL are surveyed. Second; to support scalability to the gigantic scale (millions or billions ofsamples); recent solutions based on anchor graphs are reviewed. To help researchers …,Proceedings of the IEEE,2012,110
Efficient manifold ranking for image retrieval,Bin Xu; Jiajun Bu; Chun Chen; Deng Cai; Xiaofei He; Wei Liu; Jiebo Luo,Abstract Manifold Ranking (MR); a graph-based ranking algorithm; has been widely appliedin information retrieval and shown to have excellent performance and feasibility on a varietyof data types. Particularly; it has been successfully applied to content-based image retrieval;because of its outstanding ability to discover underlying geometrical structure of the givenimage database. However; manifold ranking is computationally very expensive; both ingraph construction and ranking computation stages; which significantly limits its applicabilityto very large data sets. In this paper; we extend the original manifold ranking algorithm andpropose a new framework named Efficient Manifold Ranking (EMR). We aim to address theshortcomings of MR from two perspectives: scalable graph construction and efficientcomputation. Specifically; we build an anchor graph on the data set instead of the …,Proceedings of the 34th International ACM SIGIR Conference on Research and Development in Information Retrieval (SIGIR),2011,102
Robust multi-class transductive learning with graphs,Wei Liu; Shih-Fu Chang,Graph-based methods form a main category of semi-supervised learning; offering flexibilityand easy implementation in many applications. However; the performance of these methodsis often sensitive to the construction of a neighborhood graph; which is non-trivial for manyreal-world problems. In this paper; we propose a novel framework that builds on learning thegraph given labeled and unlabeled data. The paper has two major contributions. Firstly; weuse a nonparametric algorithm to learn the entire adjacency matrix of a symmetry-favored k-NN graph; assuming that the matrix is doubly stochastic. The nonparametric algorithmmakes the constructed graph highly robust to noisy samples and capable of approximatingunderlying submanifolds or clusters. Secondly; to address multi-class semi-supervisedclassification; we formulate a constrained label propagation problem on the learned …,Proceedings of IEEE Conference on Computer Vision and Pattern Recognition (CVPR),2009,102
Task-Dependent Visual Codebook Compression,Rongrong Ji; Hongxun Yao; W Liu; X Sun; Q Tian,A visual codebook serves as a fundamental component in many state-of-the-art computervision systems. Most existing codebooks are built based on quantizing local featuredescriptors extracted from training images. Subsequently; each image is represented as ahigh-dimensional bag-of-words histogram. Such highly redundant image description lacksefficiency in both storage and retrieval; in which only a few bins are nonzero and distributedsparsely. Furthermore; most existing codebooks are built based solely on the visual statisticsof local descriptors; without considering the supervise labels coming from the subsequentrecognition or classification tasks. In this paper; we propose a task-dependent codebookcompression framework to handle the above two problems. First; we propose to learn acompression function to map an originally high-dimensional codebook into a compact …,IEEE Transactions on Image Processing (TIP),2012,101
Hallucinating faces: Tensorpatch super-resolution and coupled residue compensation,Wei Liu; Dahua Lin; Xiaoou Tang,In this paper; we propose a new face hallucination framework based on image patches;which integrates two novel statistical super-resolution models. Considering that imagepatches reflect the combined effect of personal characteristics and patch-location; we firstformulate a TensorPatch model based on multilinear analysis to explicitly model theinteraction between multiple constituent factors. Motivated by locally linear embedding; wedevelop an enhanced multilinear patch hallucination algorithm; which efficiently exploits thelocal distribution structure in the sample space. To better preserve face subtle details; wederive the coupled PCA algorithm to learn the relation between high-resolution residue andlow-resolution residue; which is utilized for compensate the error residue in hallucinatedimages. Experiments demonstrate that our framework on one hand well maintains the …,Proceedings of IEEE Conference on Computer Vision and Pattern Recognition (CVPR),2005,98
A face annotation framework with partial clustering and interactive labeling,Yuandong Tian; Wei Liu; Rong Xiao; Fang Wen; Xiaoou Tang,Face annotation technology is important for a photo management system. In this paper; wepropose a novel interactive face annotation framework combining unsupervised andinteractive learning. There are two main contributions in our framework. In the unsupervisedstage; a partial clustering algorithm is proposed to find the most evident clusters instead ofgrouping all instances into clusters; which leads to a good initial labeling for later userinteraction. In the interactive stage; an efficient labeling procedure based on minimization ofboth global system uncertainty and estimated number of user operations is proposed toreduce user interaction as much as possible. Experimental results show that the proposedannotation framework can significantly reduce the face annotation workload and is superiorto existing solutions in the literature.,Proceedings of IEEE Conference on Computer Vision and Pattern Recognition (CVPR),2007,87
Null space approach of fisher discriminant analysis for face recognition,Wei Liu; Yunhong Wang; Stan Li; Tieniu Tan,Abstract The null space of the within-class scatter matrix is found to express mostdiscriminative information for the small sample size problem (SSSP). The null space-basedLDA takes full advantage of the null space while the other methods remove the null space. Itproves to be optimal in performance. From the theoretical analysis; we present the NLDAalgorithm and the most suitable situation for NLDA. Our method is simpler than all other nullspace approaches; it saves the computational cost and maintains the performancesimultaneously. Furthermore; kernel technique is incorporated into discriminant analysis inthe null space. Firstly; all samples are mapped to the kernel space through a better kernelfunction; called Cosine kernel; which is proposed to increase the discriminating capability ofthe original polynomial kernel function. Secondly; a truncated NLDA is employed. The …,Biometric Authentication,2004,78
Learning Hash Codes with Listwise Supervision,Jun Wang; Wei Liu; Andy Sun; Yu-Gang Jiang,Abstract Hashing techniques have been intensively investigated in the design of highlyefficient search engines for largescale computer vision applications. Compared with priorapproximate nearest neighbor search approaches like treebased indexing; hashing-basedsearch schemes have prominent advantages in terms of both storage and computationalefficiencies. Moreover; the procedure of devising hash functions can be easily incorporatedinto sophisticated machine learning tools; leading to data-dependent and task-specificcompact hash codes. Therefore; a number of learning paradigms; ranging fromunsupervised to supervised; have been applied to compose appropriate hash functions.However; most of the existing hash function learning methods either treat hash functiondesign as a classification problem or generate binary codes to satisfy pairwise …,Proceedings of IEEE International Conference on Computer Vision (ICCV),2013,71
Null space-based kernel fisher discriminant analysis for face recognition,Wei Liu; Yunhong Wang; Stan Z Li; Tieniu Tan,The null space-based LDA takes full advantage of the null space while the other methodsremove the null space. It proves to be optimal in performance. From the theoretical analysis;we present the NLDA algorithm and the most suitable situation for NLDA. Our method issimpler than all other null space approaches; it saves the computational cost and maintainsthe performance simultaneously. Furthermore; kernel technique is incorporated into our nullspace method. Firstly; all samples are mapped to the kernel space through an efficientkernel function; called cosine kernel; which have been demonstrated to increase thediscriminating capability of the original polynomial kernel function. Secondly; a truncatedNLDA is employed. The novel approachh only requires one eigenvalu analysis and is alsoapplicable to the large sample size problem. Experiments are carried out on different face …,Automatic Face and Gesture Recognition; 2004. Proceedings. Sixth IEEE International Conference on,2004,67
Nonnegative Local Coordinate Factorization for Image Representation,Y. Chen; J. Zhang; D. Cai; W. Liu; X. He,Recently; nonnegative matrix factorization (NMF) has become increasingly popular forfeature extraction in computer vision and pattern recognition. NMF seeks two nonnegativematrices whose product can best approximate the original matrix. The nonnegativityconstraints lead to sparse parts-based representations that can be more robust thannonsparse global features. To obtain more accurate control over the sparseness; in thispaper; we propose a novel method called nonnegative local coordinate factorization (NLCF)for feature extraction. NLCF adds a local coordinate constraint into the standard NMFobjective function. Specifically; we require that the learned basis vectors be as close to theoriginal data points as possible. In this way; each data point can be represented by a linearcombination of only a few nearby basis vectors; which naturally leads to sparse …,IEEE Transactions on Image Processing (TIP),2013,65
Learning Binary Codes for Maximum Inner Product Search,Fumin Shen; Wei Liu; Shaoting Zhang; Yang Yang; Heng Tao Shen,Abstract Binary coding or hashing techniques are recognized to accomplish efficient nearneighbor search; and have thus attracted broad interests in the recent vision and learningstudies. However; such studies have rarely been dedicated to Maximum Inner ProductSearch (MIPS); which plays a critical role in various vision applications. In this paper; weinvestigate learning binary codes to exclusively handle the MIPS problem. Inspired by thelatest advance in asymmetric hashing schemes; we propose an asymmetric binary codelearning framework based on inner product fitting. Specifically; two sets of coding functionsare learned such that the inner products between their generated binary codes can revealthe inner products between original data vectors. We also propose an alternative simplerobjective which maximizes the correlations between the inner products of the produced …,Proceedings of IEEE International Conference on Computer Vision (ICCV),2015,64
Discrete Collaborative Filtering,Hanwang Zhang; Fumin Shen; Wei Liu; Xiangnan He; Huanbo Luan; Tat-Seng Chua,Abstract We address the efficiency problem of Collaborative Filtering (CF) by hashing usersand items as latent vectors in the form of binary codes; so that user-item affinity can beefficiently calculated in a Hamming space. However; existing hashing methods for CFemploy binary code learning procedures that most suffer from the challenging discreteconstraints. Hence; those methods generally adopt a two-stage learning scheme composedof relaxed optimization via discarding the discrete constraints; followed by binaryquantization. We argue that such a scheme will result in a large quantization loss; whichespecially compromises the performance of large-scale CF that resorts to longer binarycodes. In this paper; we propose a principled CF hashing framework called DiscreteCollaborative Filtering (DCF); which directly tackles the challenging discrete optimization …,Proceedings of the 39th International ACM SIGIR Conference on Research and Development in Information Retrieval (SIGIR),2016,57
Compact Hyperplane Hashing with Bilinear Functions,Wei Liu; Jun Wang; Yadong Mu; Sanjiv Kumar; Shih-Fu Chang,Abstract: Hyperplane hashing aims at rapidly searching nearest points to a hyperplane; andhas shown practical impact in scaling up active learning with SVMs. Unfortunately; theexisting randomized methods need long hash codes to achieve reasonable search accuracyand thus suffer from reduced search speed and large memory overhead. To this end; thispaper proposes a novel hyperplane hashing technique which yields compact hash codes.The key idea is the bilinear form of the proposed hash functions; which leads to highercollision probability than the existing hyperplane hash functions when using randomprojections. To further increase the performance; we propose a learning based framework inwhich the bilinear functions are directly learned from the data. This results in short yetdiscriminative codes; and also boosts the search performance over the random projection …,Proceedings of International Conference on Machine Learning (ICML),2012,56
Noise resistant graph ranking for improved web image search,Wei Liu; Yu-Gang Jiang; Jiebo Luo; Shih-Fu Chang,In this paper; we exploit a novel ranking mechanism that processes query samples withnoisy labels; motivated by the practical application of web image search re-ranking wherethe originally highest ranked images are usually posed as pseudo queries for subsequent re-ranking. Availing ourselves of the low-frequency spectrum of a neighborhood graph built onthe samples; we propose a graph-theoretical framework amenable to noise resistantranking. The proposed framework consists of two components: spectral filtering and graph-based ranking. The former leverages sparse bases; progressively selected from a pool ofsmooth eigenvectors of the graph Laplacian; to reconstruct the noisy label vector associatedwith the query sample set and accordingly filter out the query samples with less authenticpositive labels. The latter applies a canonical graph ranking algorithm with respect to the …,Proceedings of IEEE Conference on Computer Vision and Pattern Recognition (CVPR),2011,55
Transductive component analysis,Wei Liu; Dacheng Tao; Jianzhuang Liu,In this paper; we study semi-supervised linear dimensionality reduction. Beyondconventional supervised methods which merely consider labeled instances; the semi-supervised scheme allows to leverage abundant and ample unlabeled instances intolearning so as to achieve better generalization performance. Under semi-supervisedsettings; our objective is to learn a smooth as well as discriminative subspace and lineardimensionality reduction is thus achieved by mapping all samples into the subspace.Specifically; we present the Transductive Component Analysis (TCA) algorithm to generatesuch a subspace founded on a graph-theoretic framework. Considering TCA is non-orthogonal; we further present the Orthogonal Transductive Component Analysis (OTCA)algorithm to iteratively produce a series of orthogonal basis vectors. OTCA has better …,Proceedings of the Eighth IEEE International Conference on Data Mining (ICDM),2008,54
Saliency Propagation from Simple to Difficult,Chen Gong; Dacheng Tao; Wei Liu; Stephen J. Maybank; Meng Fang; Keren Fu; Jie Yang,Abstract Saliency propagation has been widely adopted for identifying the most attractiveobject in an image. The propagation sequence generated by existing saliency detectionmethods is governed by the spatial relationships of image regions; ie; the saliency value istransmitted between two adjacent regions. However; for the inhomogeneous difficultadjacent regions; such a sequence may incur wrong propagations. In this paper; we attemptto manipulate the propagation sequence for optimizing the propagation quality. Intuitively;we postpone the propagations to difficult regions and meanwhile advance the propagationsto less ambiguous simple regions. Inspired by the theoretical results in educationalpsychology; a novel propagation algorithm employing the teaching-to-learn and learning-to-teach strategies is proposed to explicitly improve the propagation quality. In the teaching …,IEEE Conference on Computer Vision and Pattern Recognition (CVPR),2015,53
Semi-supervised sparse metric learning using alternating linearization optimization,Wei Liu; Shiqian Ma; Dacheng Tao; Jianzhuang Liu; Peng Liu,Abstract In plenty of scenarios; data can be represented as vectors and then mathematicallyabstracted as points in a Euclidean space. Because a great number of machine learningand data mining applications need proximity measures over data; a simple and universaldistance metric is desirable; and metric learning methods have been explored to producesensible distance measures consistent with data relationship. However; most existingmethods suffer from limited labeled data and expensive training. In this paper; we addressthese two issues through employing abundant unlabeled data and pursuing sparsity ofmetrics; resulting in a novel metric learning approach called semi-supervised sparse metriclearning. Two important contributions of our approach are: 1) it propagates scarce prioraffinities between data to the global scope and incorporates the full affinities into the …,Proceedings of the 16th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining (KDD),2010,53
Visual Reranking through Weakly Supervised Multi-Graph Learning,Cheng Deng; Rongrong Ji; Wei Liu; Dacheng Tao; Xinbo Gao,Abstract Visual reranking has been widely deployed to refine the quality of conventionalcontent-based image retrieval engines. The current trend lies in employing a crowd ofretrieved results stemming from multiple feature modalities to boost the overall performanceof visual reranking. However; a major challenge pertaining to current reranking methods ishow to take full advantage of the complementary property of distinct feature modalities.Given a query image and one feature modality; a regular visual reranking framework treatsthe top-ranked images as pseudo positive instances which are inevitably noisy; difficult toreveal this complementary property; and thus lead to inferior ranking performance. Thispaper proposes a novel image reranking approach by introducing a Co-Regularized Multi-Graph Learning (Co-RMGL) framework; in which the intra-graph and inter-graph …,Proceedings of International Conference on Computer Vision (ICCV),2013,49
Nonparametric subspace analysis for face recognition,Zhifeng Li; Wei Liu; Dahua Lin; Xiaoou Tang,Linear discriminant analysis (LDA) is a popular face recognition technique. However; aninherent problem with this technique stems from the parametric nature of the scatter matrix;in which the sample distribution in each class is assumed to be normal distribution. So ittends to suffer in the case of non-normal distribution. In this paper a nonparametric scattermatrix is defined to replace the traditional parametric scatter matrix in order to overcome thisproblem. Two kinds of nonparametric subspace analysis (NSA): PNSA and NNSA areproposed for face recognition. The former is based on the principal space of intra-personalscatter matrix; while the latter is based on the null space. In addition; based on thecomplementary nature of PNSA and NNSA; we further develop a dual NSA-based classifierframework using Gabor images to further improve the recognition performance …,Proceedings of IEEE Conference on Computer Vision and Pattern Recognition (CVPR),2005,45
Tensor Robust Principal Component Analysis: Exact Recovery of Corrupted Low-Rank Tensors via Convex Optimization,Canyi Lu; Jiashi Feng; Yudong Chen; Wei Liu; Zhouchen Lin; Shuicheng Yan,Abstract This paper studies the Tensor Robust Principal Component (TRPCA) problemwhich extends the known Robust PCA [4] to the tensor case. Our model is based on a newtensor Singular Value Decomposition (t-SVD)[14] and its induced tensor tubal rank andtensor nuclear norm. Consider that we have a 3-way tensor 기∈ Rn1× n2× n3 such that 기=L0+ s0; where L0 has low tubal rank and s0 is sparse. Is that possible to recover bothcomponents? In this work; we prove that under certain suitable assumptions; we can recoverboth the low-rank and the sparse components exactly by simply solving a convex programwhose objective is a weighted combination of the tensor nuclear norm and the ℓ1-norm; ie;min,Proceedings of IEEE Conference on Computer Vision and Pattern Recognition (CVPR),2016,40
Neighbor combination and transformation for hallucinating faces,Wei Liu; Dahua Lin; Xiaoou Tang,In this paper; we propose a novel face hallucination framework based on image patches;which exploits local geometry structures of overlapping patches to hallucinate differentcomponents associated with one facial image. To achieve local fidelity while preservingsmoothness in the target high-resolution image; we develop a neighbor combination super-resolution model for high-resolution patch synthesis. For further enhancing the detailedinformation; we propose another model; which effectively learns neighbor transformationsbetween low-and high-resolution image patch residuals to compensate modeling errorscaused by the first model. Experiments demonstrate that our approach can hallucinate highquality super-resolution faces.,Multimedia and Expo; 2005. ICME 2005. IEEE International Conference on,2005,39
Unsupervised One-Class Learning for Automatic Outlier Removal,Wei Liu; Gang Hua; John R. Smith,Abstract Outliers are pervasive in many computer vision and pattern recognition problems.Automatically eliminating outliers scattering among practical data collections becomesincreasingly important; especially for Internet inspired vision applications. In this paper; wepropose a novel oneclass learning approach which is robust to contamination of inputtraining data and able to discover the outliers that corrupt one class of data source. Ourapproach works under a fully unsupervised manner; differing from traditional one-classlearning supervised by known positive labels. By design; our approach optimizes a kernel-based max-margin objective which jointly learns a large margin one-class classifier and asoft label assignment for inliers and outliers. An alternating optimization algorithm is thendesigned to iteratively refine the classifier and the labeling; achieving a provably …,IEEE Conference on Computer Vision and Pattern Recognition (CVPR),2014,38
Bayesian tensor inference for sketch-based facial photo hallucination,Wei Liu; Xiaoou Tang; Jianzhuang Liu,Abstract This paper develops a statistical inference approach; Bayesian Tensor Inference;for style transformation between photo images and sketch images of human faces. Motivatedby the rationale that image appearance is determined by two cooperative factors: imagecontent and image style; we first model the interaction between these factors throughlearning a patch-based tensor model. Second; by introducing a common variation space; wecapture the inherent connection between photo patch space and sketch patch space; thusbuilding bidirectional mapping/inferring between the two spaces. Subsequently; weformulate a Bayesian approach accounting for the statistical inference from sketches to theircorresponding photos in terms of the learned tensor model. Comparative experiments areconducted to contrast the proposed method with state-of-the-art algorithms for facial …,Proceedings of the 20th International Joint Conference on Artificial Intelligence (IJCAI),2007,35
Image Fusion with Local Spectral Consistency and Dynamic Gradient Sparsity,Chen Chen; Yeqing Li; Wei Liu; Junzhou Huang,Abstract In this paper; we propose a novel method for image fusion from a high resolutionpanchromatic image and a low resolution multispectral image at the same geographicallocation. Different from previous methods; we do not make any assumption about theupsampled multispectral image; but only assume that the fused image after downsamplingshould be close to the original multispectral image. This is a severely ill-posed problem anda dynamic gradient sparsity penalty is thus proposed for regularization. Incorporating theintra-correlations of different bands; this penalty can effectively exploit the prior information(eg sharp boundaries) from the panchromatic image. A new convex optimization algorithm isproposed to efficiently solve this problem. Extensive experiments on four multispectraldatasets demonstrate that the proposed method significantly outperforms the state-of-the …,IEEE Conference on Computer Vision and Pattern Recognition (CVPR),2014,34
Graduated Consistency-Regularized Optimization for Multi-graph Matching,Junchi Yan; Yin Li; Wei Liu; Hongyuan Zha; Xiaokang Yang; Stephen M. Chu,Abstract Graph matching has a wide spectrum of computer vision applications such asfinding feature point correspondences across images. The problem of graph matching isgenerally NP-hard; so most existing work pursues suboptimal solutions between two graphs.This paper investigates a more general problem of matching N attributed graphs to eachother; ie labeling their common node correspondences such that a certaincompatibility/affinity objective is optimized. This multi-graph matching problem involves twokey ingredients affecting the overall accuracy: a) the pairwise affinity matching scorebetween two local graphs; and b) global matching consistency that measures theuniqueness and consistency of the pairwise matching results by different sequentialmatching orders. Previous work typically either enforces the matching consistency …,The European Conference on Computer Vision (ECCV),2014,32
Multi-Modal Curriculum Learning for Semi-Supervised Image Classification,Chen Gong; Dacheng Tao; Stephen J. Maybank; Wei Liu; Guoliang Kang; Jie Yang,Semi-supervised image classification aims to classify a large quantity of unlabeled imagesby typically harnessing scarce labeled images. Existing semi-supervised methods oftensuffer from inadequate classification accuracy when encountering difficult yet critical images;such as outliers; because they treat all unlabeled images equally and conduct classificationsin an imperfectly ordered sequence. In this paper; we employ the curriculum learningmethodology by investigating the difficulty of classifying every unlabeled image. Thereliability and the discriminability of these unlabeled images are particularly investigated forevaluating their difficulty. As a result; an optimized image sequence is generated during theiterative propagations; and the unlabeled images are logically classified from simple todifficult. Furthermore; since images are usually characterized by multiple visual feature …,IEEE Transactions on Image Processing (TIP),2016,29
Discrete Hyper-graph Matching,Junchi Yan; Chao Zhang; Hongyuan Zha; Wei Liu; Xiaokang Yang; Stephen M. Chu,Graph matching has become a popular tool in a variety of areas in computer science;ranging from computer vió sion to machine learning to computational geometry. Graph turesets; with a wide spectrum of applications that reó quire feature matching; as diverse asimage recognition [36]; shape matching [1] and object tracking [28]; among 9; 12] onlyconsider the nodeówise unary compatibility between two point sets; which can be reducedto a linear assignó ment problem and solved in polynomial time by standard techniquessuch as the Hungarian algorithm [12]. One step further; in secondóorder graph matching;each feature set is formulated as a graph with nodes representing features and edgeweights measuring the similarity between nodes; where the correspondence is establishedthrough preserving the structure similarity across two graphs. When involving both node …,IEEE Conference on Computer Vision and Pattern Recognition (CVPR),2015,29
Exploring Representativeness and Informativeness for Active Learning,Bo Du; Zengmao Wang; Lefei Zhang; Liangpei Zhang; Wei Liu; Jialie Shen; Dacheng Tao,How can we find a general way to choose the most suitable samples for training a classifier?Even with very limited prior information? Active learning; which can be regarded as aniterative optimization procedure; plays a key role to construct a refined training set toimprove the classification performance in a variety of applications; such as text analysis;image recognition; social network modeling; etc. Although combining representativenessand informativeness of samples has been proven promising for active sampling; state-of-the-art methods perform well under certain data structures. Then can we find a way to fuse thetwo active sampling criteria without any assumption on data? This paper proposes a generalactive learning framework that effectively fuses the two criteria. Inspired by a two-samplediscrepancy problem; triple measures are elaborately designed to guarantee that the …,IEEE Transactions on Cybernetics,2017,28
When Location Meets Social Multimedia: A Survey on Vision-Based Recognition and Mining for Geo-Social Multimedia Analytics,Rongrong Ji; Yue Gao; Wei Liu; Xing Xie; Qi Tian; Xuelong Li,Abstract Coming with the popularity of multimedia sharing platforms such as Facebook andFlickr; recent years have witnessed an explosive growth of geographical tags on socialmultimedia content. This trend enables a wide variety of emerging applications; for example;mobile location search; landmark recognition; scene reconstruction; and touristicrecommendation; which range from purely research prototype to commercial systems. In thisarticle; we give a comprehensive survey on these applications; covering recent advances inrecognition and mining of geographical-aware social multimedia. We review related work inthe past decade regarding to location recognition; scene summarization; tourism suggestion;3D building modeling; mobile visual search and city navigation. At the end; we furtherdiscuss potential challenges; future topics; as well as open issues related to geo-social …,ACM Transactions on Intelligent Systems and Technology,2015,28
Spatio-temporal embedding for statistical face recognition from video,Wei Liu; Zhifeng Li; Xiaoou Tang,Abstract This paper addresses the problem of how to learn an appropriate featurerepresentation from video to benefit video-based face recognition. By simultaneouslyexploiting the spatial and temporal information; the problem is posed as learning Spatio-Temporal Embedding (STE) from raw video. STE of a video sequence is defined as itscondensed version capturing the essence of space-time characteristics of the video. Relyingon the co-occurrence statistics and supervised signatures provided by training videos; STEpreserves the intrinsic temporal structures hidden in video volume; meanwhile encodes thediscriminative cues into the spatial domain. To conduct STE; we propose two noveltechniques; Bayesian keyframe learning and nonparametric discriminant embedding (NDE);for temporal and spatial learning; respectively. In terms of learned STEs; we derive a …,The 9th European Conference on Computer Vision,2006,27
Combining space-based Gabor features for face recognition,Wei Fan; Yunhong Wang; Wei Liu; Tieniu Tan,We propose a face recognition strategy combining various discriminating Gabor features inmulti-scales and multi-orientations. A bank of well-chosen Gabor filters is applied on theimage to construct a group of feature vectors; and then the Null Space-based LDA (NLDA) isperformed simultaneously on each orientation channel and the original image to give 5component classifier outputs; which are then combined to increase the final recognition rate.Experimental results on the FERET database demonstrate the effectiveness and flexibility ofour proposed method.,Pattern Recognition; 2004. ICPR 2004. Proceedings of the 17th International Conference on,2004,27
Top Rank Supervised Binary Coding for Visual Search,Dongjin Song; Wei Liu; Rongrong Ji; David A. Meyer; John R. Smith,Abstract In recent years; binary coding techniques are becoming increasingly popularbecause of their high efficiency in handling large-scale computer vision applications. It hasbeen demonstrated that supervised binary coding techniques that leverage supervisedinformation can significantly enhance the coding quality; and hence greatly benefit visualsearch tasks. Typically; a modern binary coding method seeks to learn a group of codingfunctions which compress data samples into binary codes. However; few methods pursuedthe coding functions such that the precision at the top of a ranking list according to Hammingdistances of the generated binary codes is optimized. In this paper; we propose a novelsupervised binary coding approach; namely Top Rank Supervised Binary Coding (Top-RSBC); which explicitly focuses on optimizing the precision of top positions in a Hamming …,Proceedings of IEEE International Conference on Computer Vision (ICCV),2015,24
Stochastic Quasi-Newton Methods for Nonconvex Stochastic Optimization,Xiao Wang; Shiqian Ma; Donald Goldfarb; Wei Liu,In this paper we study stochastic quasi-Newton methods for nonconvex stochasticoptimization; where we assume that noisy information about the gradients of the objectivefunction is available via a stochastic first-order oracle (SFO). We propose a generalframework for such methods; for which we prove almost sure convergence to stationarypoints and analyze its worst-case iteration complexity. When a randomly chosen iterate isreturned as the output of such an algorithm; we prove that in the worst case; the SFO-callscomplexity is O(ϵ^-2) to ensure that the expectation of the squared norm of the gradient issmaller than the given accuracy tolerance ϵ. We also propose a specific algorithm; namely;a stochastic damped limited-memory BFGS (SdLBFGS) method; that falls under theproposed framework. Moreover; we incorporate the stochastic variance reduced gradient …,SIAM Journal on Optimization,2017,23
Mining Histopathological Images via Composite Hashing and Online Learning,Xiaofan Zhang; Lin Yang; Wei Liu; Hai Su; Shaoting Zhang,Abstract With a continuous growing amount of annotated histopathological images; large-scale and data-driven methods potentially provide the promise of bridging the semantic gapbetween these images and their diagnoses. The purpose of this paper is to increase thescale at which automated systems can entail scalable analysis of histopathological imagesin massive databases. Specifically; we propose a principled framework to unify hashing-based image retrieval and supervised learning. Concretely; composite hashing is designedto simultaneously fuse and compress multiple high-dimensional image features into tens ofbinary hash bits; enabling scalable image retrieval with a very low computational cost. Upona local data subset that retains the retrieved images; supervised learning methods areapplied on-the-fly to model image structures for accurate classification. Our framework is …,Annual International Conference on Medical Image Computing and Computer Assisted Intervention (MICCAI),2014,23
Spectral kernel learning for semi-supervised classification,Wei Liu; Buyue Qian; Jingyu Cui; Jianzhuang Liu,Abstract Typical graph-theoretic approaches for semisupervised classification infer labels ofunlabeled instances with the help of graph Laplacians. Founded on the spectraldecomposition of the graph Laplacian; this paper learns a kernel matrix via minimizing theleave-one-out classification error on the labeled instances. To this end; an efficient algorithmis presented based on linear programming; resulting in a transductive spectral kernel. Theidea of our algorithm stems from regularization methodology and also has a niceinterpretation in terms of spectral clustering. A simple classifier can be readily built upon thelearned kernel; which suffices to give prediction for any data point aside from those in theavailable dataset. Besides this usage; the spectral kernel can be effectively used in tandemwith conventional kernel machines such as SVMs. We demonstrate the efficacy of the …,Proceedings of the 21st International Joint Conference on Artificial Intelligence (IJCAI),2009,23
Weakly Supervised Visual Dictionary Learning by Harnessing Image Attributes,Yue Gao; Rongrong Ji; Wei Liu; Qionghai Dai; Gang Hua,Bag-of-features (BoFs) representation has been extensively applied to deal with variouscomputer vision applications. To extract discriminative and descriptive BoF; one importantstep is to learn a good dictionary to minimize the quantization loss between local featuresand codewords. While most existing visual dictionary learning approaches are engaged withunsupervised feature quantization; the latest trend has turned to supervised learning byharnessing the semantic labels of images or regions. However; such labels are typically tooexpensive to acquire; which restricts the scalability of supervised dictionary learningapproaches. In this paper; we propose to leverage image attributes to weakly supervise thedictionary learning procedure without requiring any actual labels. As a key contribution; ourapproach establishes a generative hidden Markov random field (HMRF); which models …,IEEE Transactions on Image Processing (TIP),2014,22
Label Propagation via Teaching-to-Learn and Learning-to-Teach,Chen Gong; Dacheng Tao; Wei Liu; Liu Liu; Jie Yang,How to propagate label information from labeled examples to unlabeled examples over agraph has been intensively studied for a long time. Existing graph-based propagationalgorithms usually treat unlabeled examples equally; and transmit seed labels to theunlabeled examples that are connected to the labeled examples in a neighborhood graph.However; such a popular propagation scheme is very likely to yield inaccurate propagation;because it falls short of tackling ambiguous but critical data points (eg; outliers). To this end;this paper treats the unlabeled examples in different levels of difficulties by assessing theirreliability and discriminability; and explicitly optimizes the propagation quality bymanipulating the propagation sequence to move from simple to difficult examples. Inparticular; we propose a novel iterative label propagation algorithm in which each …,IEEE Transactions on Neural Networks and Learning Systems,2017,21
Low-Rank Similarity Metric Learning in High Dimensions,Wei Liu; Cun Mu; Rongrong Ji; Shiqian Ma; John R. Smith; Shih-Fu Chang,Abstract Metric learning has become a widespreadly used tool in machine learning. Toreduce expensive costs brought in by increasing dimensionality; low-rank metric learningarises as it can be more economical in storage and computation. However; existing low-rankmetric learning algorithms usually adopt nonconvex objectives; and are hence sensitive tothe choice of a heuristic low-rank basis. In this paper; we propose a novel low-rank metriclearning algorithm to yield bilinear similarity functions. This algorithm scales linearly withinput dimensionality in both space and time; therefore applicable to high-dimensional datadomains. A convex objective free of heuristics is formulated by leveraging trace normregularization to promote low-rankness. Crucially; we prove that all globally optimal metricsolutions must retain a certain low-rank structure; which enables our algorithm to …,Proceedings of The Twenty-Ninth AAAI Conference on Artificial Intelligence (AAAI),2015,21
SCA-CNN: Spatial and Channel-wise Attention in Convolutional Networks for Image Captioning,Long Chen; Hanwang Zhang; Jun Xiao; Liqiang Nie; Jian Shao; Wei Liu; Tat-Seng Chua,Visual attention has been successfully applied in structural prediction tasks such as visualcaptioning and question answering. Existing visual attention models are generally spatial;ie; the attention is modeled as spatial probabilities that re-weight the last conv-layer featuremap of a CNN encoding an input image. However; we argue that such spatial attention doesnot necessarily conform to the attention mechanism-a dynamic feature extractor thatcombines contextual fixations over time; as CNN features are naturally spatial; channel-wiseand multi-layer. In this paper; we introduce a novel convolutional neural network dubbedSCA-CNN that incorporates Spatial and Channel-wise Attentions in a CNN. In the task ofimage captioning; SCA-CNN dynamically modulates the sentence generation context inmulti-layer feature maps; encoding where (ie; attentive spatial locations at multiple layers) …,Proceedings of IEEE Conference on Computer Vision and Pattern Recognition (CVPR),2017,20
Discriminative Multi-instance Multitask Learning for 3D Action Recognition,Yanhua Yang; Cheng Deng; Shangqian Gao; Wei Liu; Dapeng Tao; Xinbo Gao,As the prosperity of low-cost and easy-operating depth cameras; skeleton-based humanaction recognition has been extensively studied recently. However; most of the existingmethods partially consider that all 3D joints of a human skeleton are identical. Actually;these 3D joints exhibit diverse responses to different action classes; and some jointconfigurations are more discriminative to distinguish a certain action. In this paper; wepropose a discriminative multi-instance multitask learning (MIMTL) framework to discoverthe intrinsic relationship between joint configurations and action classes. First; a set ofdiscriminative and informative joint configurations for the corresponding action class iscaptured in multi-instance learning model by regarding the action and the jointconfigurations as a bag and its instances; respectively. Then; a multitask learning model …,IEEE Transactions on Multimedia,2017,20
Video De-fencing,Yadong Mu; Wei Liu; Shuicheng Yan,This paper describes and provides an initial solution to a novel video editing task; ie; videode-fencing. It targets automatic restoration of the video clips that are corrupted by fence-likeocclusions during capture. Our key observation lies in the visual parallax between fencesand background scenes; which is caused by the fact that the former are typically closer to thecamera. Unlike in traditional image inpainting; fence-occluded pixels in the videos tend toappear later in the temporal dimension and are therefore recoverable via optimized pixelselection from relevant frames. To eventually produce fence-free videos; major challengesinclude cross-frame subpixel image alignment under diverse scene depth; and correct pixelselection that is robust to dominating fence pixels. Several novel tools are developed in thispaper; including soft fence detection; weighted truncated optical flow method; and robust …,IEEE Transactions on Circuits and Systems for Video Technology,2014,20
Constrained metric learning via distance gap maximization,Wei Liu; Xinmei Tian; Dacheng Tao; Jianzhuang Liu,Abstract Vectored data frequently occur in a variety of fields; which are easy to handle sincethey can be mathematically abstracted as points residing in a Euclidean space. Anappropriate distance metric in the data space is quite demanding for a great number ofapplications. In this paper; we pose robust and tractable metric learning under pairwiseconstraints that are expressed as similarity judgements between data pairs. The majorfeatures of our approach include: 1) it maximizes the gap between the average squareddistance among dissimilar pairs and the average squared distance among similar pairs; 2) itis capable of propagating similar constraints to all data pairs; and 3) it is easy to implementin contrast to the existing approaches using expensive optimization such as semidefiniteprogramming. Our constrained metric learning approach has widespread applicability …,Proceedings of The Twenty-Fourth AAAI Conference on Artificial Intelligence (AAAI),2010,20
Discriminative Dictionary Learning With Common Label Alignment for Cross-Modal Retrieval,Cheng Deng; Xu Tang; Junchi Yan; Wei Liu; Xinbo Gao,Cross-modal retrieval has attracted much attention in recent years due to its widespreadapplications. In this area; how to capture and correlate heterogeneous features originatingfrom different modalities remains a challenge. However; most existing methods dealing withcross-modal learning only focus on learning relevant features shared by two distinct featurespaces; therefore overlooking discriminative feature information of them. To remedy thisissue and explicitly capture discriminative feature information; we propose a novel cross-modal retrieval approach based on discriminative dictionary learning that is augmented withcommon label alignment. Concretely; a discriminative dictionary is first learned to accountfor each modality; which boosts not only the discriminating capability of intra-modality datafrom different classes but also the relevance of inter-modality data in the same class …,IEEE Transactions on Multimedia,2016,19
Human Action Recognition in Unconstrained Videos by Explicit Motion Modeling,Yu-Gang Jiang; Qi Dai; Wei Liu; Xiangyang Xue; Chong-Wah Ngo,Human action recognition in unconstrained videos is a challenging problem with manyapplications. Most state-of-the-art approaches adopted the well-known bag-of-featuresrepresentations; generated based on isolated local patches or patch trajectories; wheremotion patterns; such as object-object and object-background relationships are mostlydiscarded. In this paper; we propose a simple representation aiming at modeling thesemotion relationships. We adopt global and local reference points to explicitly characterizemotion information; so that the final representation is more robust to camera movements;which widely exist in unconstrained videos. Our approach operates on the top of visualcodewords generated on dense local patch trajectories; and therefore; does not requireforeground-background separation; which is normally a critical and difficult step in …,IEEE Transactions on Image Processing (TIP),2015,19
Scalable Mammogram Retrieval Using Anchor Graph Hashing,Jingjing Liu Liu; Shaoting Zhang; Wei Liu; Xiaofan Zhang; Dimitris Metaxas,Mammogram analysis is known to provide early-stage diagnosis of breast cancer inreducing its morbidity and mortality. In this paper; we propose a scalable content-basedimage retrieval (CBIR) framework for digital mammograms. CBIR is of great significance forbreast cancer diagnosis as it can provide doctors image-guided avenues to access relevantcases. Clinical decisions based on such cases offer a reliable and consistent supplement fordoctors. In our framework; we employ an unsupervised algorithm; Anchor Graph Hashing(AGH); to compress the mammogram features into compact binary codes; and then performsearching in the Hamming space. In addition; we also propose to fuse different features inAGH to improve its search accuracy. Experiments on the Digital Database for ScreeningMammography (DDSM) demonstrate that our system is capable of providing content …,IEEE International Symposium on Biomedical Imaging,2014,19
Learning an image-word embedding for image auto-annotation on the nonlinear latent space,Wei Liu; Xiaoou Tang,Abstract Latent Semantic Analysis (LSA) has shown encouraging performance for theproblem of unsupervised image automatic annotation. LSA conducts annotation bykeywords propagation on a linear Latent Space; which accounts for the underlying semanticstructure of word and image features. In this paper; we formulate a more general nonlinearmodel; called Nonlinear Latent Space model; to reveal the latent variables of word andvisual features more precisely. Instead of the basic propagation strategy; we present a novelinference strategy for image annotation via Image-Word Embedding (IWE). IWEsimultaneously embeds images and words and captures the dependencies between themfrom a probabilistic viewpoint. Experiments show that IWE-based annotation on thenonlinear latent space outperforms previous unsupervised annotation methods.,Proceedings of the 13th annual ACM international conference on Multimedia,2005,19
SIRF: Simultaneous Satellite Image Registration and Fusion in A Unified Framework,Chen Chen; Yeqing Li; Wei Liu; Junzhou Huang,In this paper; we propose a novel method for image fusion with a high-resolutionpanchromatic image and a low-resolution multispectral (Ms) image at the samegeographical location. The fusion is formulated as a convex optimization problem whichminimizes a linear combination of a least-squares fitting term and a dynamic gradientsparsity regularizer. The former is to preserve accurate spectral information of the Ms image;while the latter is to keep sharp edges of the high-resolution panchromatic image. We furtherpropose to simultaneously register the two images during the fusing process; which isnaturally achieved by virtue of the dynamic gradient sparsity property. An efficient algorithmis then devised to solve the optimization problem; accomplishing a linear computationalcomplexity in the size of the output image in each iteration. We compare our method …,IEEE Transactions on Image Processing (TIP),2015,17
Can Visual Recognition Benefit from Auxiliary Information in Training?‏,Qilin Zhang; Gang Hua; Wei Liu; Zicheng Liu; Zhengyou Zhang,Abstract We examine an under-explored visual recognition problem; where we have a mainview along with an auxiliary view of visual information present in the training data; butmerely the main view is available in the test data. To effectively leverage the auxiliary view totrain a stronger classifier; we propose a collaborative auxiliary learning framework based ona new discriminative canonical correlation analysis. This framework reveals a commonsemantic space shared across both views through enforcing a series of nonlinearprojections. Such projections automatically embed the discriminative cues hidden in bothviews into the common space; and better visual recognition is thus achieved on the test datathat stems from only the main view. The efficacy of our proposed auxiliary learning approachis demonstrated through three challenging visual recognition tasks with different kinds of …,Asian Conference on Computer Vision (ACCV),2014,16
Semi-Supervised Learning with Manifold Fitted Graphs,Tongtao Zhang; Rongrong Ji; Wei Liu; Dacheng Tao; Gang Hua,Abstract In this paper; we propose a locality-constrained and sparsity-encouraged manifoldfitting approach; aiming at capturing the locally sparse manifold structure into neighborhoodgraph construction by exploiting a principled optimization model. The proposed modelformulates neighborhood graph construction as a sparse coding problem with the localityconstraint; therefore achieving simultaneous neighbor selection and edge weightoptimization. The core idea underlying our model is to perform a sparse manifold fitting taskfor each data point so that close-by points lying on the same local manifold are automaticallychosen to connect and meanwhile the connection weights are acquired by simple geometricreconstruction. We term the novel neighborhood graph generated by our proposedoptimization model M-Fitted Graph since such a graph stems from sparse manifold fitting …,Proceedings of the 23rd International Joint Conference on Artificial Intelligence (IJCAI),2013,16
Asymmetric Binary Coding for Image Search,Fumin Shen; Yang Yang; Li Liu; Wei Liu; Dacheng Tao; Heng Tao Shen,Learning to hash has attracted broad research interests in recent computer vision andmachine learning studies; due to its ability to accomplish efficient approximate nearestneighbor search. However; the closely related task; maximum inner product search (MIPS);has rarely been studied in this literature. To facilitate the MIPS study; in this paper; weintroduce a general binary coding framework based on asymmetric hash functions; namedasymmetric inner-product binary coding (AIBC). In particular; AIBC learns two different hashfunctions; which can reveal the inner products between original data vectors by thegenerated binary vectors. Although conceptually simple; the associated optimization is verychallenging due to the highly nonsmooth nature of the objective that involves sign functions.We tackle the nonsmooth optimization in an alternating manner; by which each single …,IEEE Transactions on Multimedia,2017,15
Latent Max-Margin Multitask Learning With Skelets for 3-D Action Recognition,Yanhua Yang; Cheng Deng; Dapeng Tao; Shaoting Zhang; Wei Liu; Xinbo Gao,Recent emergence of low-cost and easy-operating depth cameras has reinvigorated theresearch in skeleton-based human action recognition. However; most existing approachesoverlook the intrinsic interdependencies between skeleton joints and action classes; thussuffering from unsatisfactory recognition performance. In this paper; a novel latent max-margin multitask learning model is proposed for 3-D action recognition. Specifically; weexploit skelets as the mid-level granularity of joints to describe actions. We then apply thelearning model to capture the correlations between the latent skelets and action classeseach of which accounts for a task. By leveraging structured sparsity inducing regularization;the common information belonging to the same class can be discovered from the latentskelets; while the private information across different classes can also be preserved. The …,IEEE Transactions on Cybernetics,2017,15
Supervised matrix factorization for cross-modality hashing,Hong Liu; Rongrong Ji; Yongjian Wu; Gang Hua,Abstract: Matrix factorization has been recently utilized for the task of multi-modal hashing forcross-modality visual search; where basis functions are learned to map data from differentmodalities to the same Hamming embedding. In this paper; we propose a novel cross-modality hashing algorithm termed Supervised Matrix Factorization Hashing (SMFH) whichtackles the multi-modal hashing problem with a collective non-matrix factorization across thedifferent modalities. In particular; SMFH employs a well-designed binary code learningalgorithm to preserve the similarities among multi-modal original features through a graphregularization. At the same time; semantic labels; when available; are incorporated into thelearning procedure. We conjecture that all these would facilitate to preserve the mostrelevant information during the binary quantization process; and hence improve the …,arXiv preprint arXiv:1603.05572,2016,15
Dictionary Pair Learning on Grassmann Manifolds for Image Denoising,Xianhua Zeng; Wei Bian; Wei Liu; Jialie Shen; Dacheng Tao,Image denoising is a fundamental problem in computer vision and image processing thatholds considerable practical importance for real-world applications. The traditional patch-based and sparse coding-driven image denoising methods convert 2D image patches into1D vectors for further processing. Thus; these methods inevitably break down the inherent2D geometric structure of natural images. To overcome this limitation pertaining to theprevious image denoising methods; we propose a 2D image denoising model; namely; thedictionary pair learning (DPL) model; and we design a corresponding algorithm called theDPL on the Grassmann-manifold (DPLG) algorithm. The DPLG algorithm first learns aninitial dictionary pair (ie; the left and right dictionaries) by employing a subspace partitiontechnique on the Grassmann manifold; wherein the refined dictionary pair is obtained …,IEEE Transactions on Image Processing (TIP),2015,15
Layered local prediction network with dynamic learning for face super-resolution,Dahua Lin; Wei Liu; Xiaoou Tang,In this paper; we propose a novel framework for face super-resolution based on a layeredpredictor network. In the first layer; multiple predictors are trained online with a dynamic-constructed training set; which is adaptively selected in order to make the trained modeltailored to the testing face. When the dynamic training set is obtained; the optimum predictorcan be learned based on the resampling-maximum likelihood-model. To further enhance therobustness of prediction and the smoothness of the hallucinated image; additional layers aredesigned to fuse multiple predictors with the fusion rule learned from the training set.Experiments fully demonstrate the effectiveness of the framework.,Image Processing; 2005. ICIP 2005. IEEE International Conference on,2005,15
Nearest intra-class space classifier for face recognition,Wei Liu; Yunhong Wang; Stan Z Li; Tieniu Tan,We propose a novel classification method; called nearest intra-class space (NICS); for facerecognition. In our method; the distribution of face patterns of each person is represented bythe intra-class space to capture all intra-class variations. Then; a regular principal subspaceis derived from each intra-class space using principal component analysis. The classificationis based on the nearest weighted distance; combining distance-from-subspace and distance-in-subspace; between the query face and each intra-class subspace. Experimental resultsshow that the NICS classifier outperforms other classifiers in terms of recognitionperformance.,Pattern Recognition; 2004. ICPR 2004. Proceedings of the 17th International Conference on,2004,15
Attentive Collaborative Filtering: Multimedia Recommendation with Item- and Component-Level Attention,Jingyuan Chen; Hanwang Zhang; Xiangnan He; Liqiang Nie; Wei Liu; Tat-Seng Chua,Abstract Multimedia content is dominating today's Web information. The nature of multimediauser-item interactions is 1/0 binary implicit feedback (eg; photo likes; video views; songdownloads; etc.); which can be collected at a larger scale with a much lower cost thanexplicit feedback (eg; product ratings). However; the majority of existing collaborativefiltering (CF) systems are not well-designed for multimedia recommendation; since theyignore the implicitness in users' interactions with multimedia content. We argue that; inmultimedia recommendation; there exists item-and component-level implicitness which blursthe underlying users' preferences. The item-level implicitness means that users' preferenceson items (eg photos; videos; songs; etc.) are unknown; while the component-levelimplicitness means that inside each item users' preferences on different components (eg …,ACM SIGIR Conference on Research and Development in Information Retrieval (SIGIR),2017,14
Mining Histopathological Images via Hashing-Based Scalable Image Retrieval,Xiaofan Zhang; Wei Liu; Shaoting Zhang,Automatic analysis of histopathological images has been widely investigated usingcomputational image processing and machine learning techniques. Computer-aideddiagnosis (CAD) systems and content-based image retrieval (CBIR) systems have beensuccessfully developed for diagnosis; disease detection; and decision support in this area.In this paper; we focus on a scalable image retrieval method with high-dimensional featuresfor the analysis of histopathology images. Specifically; we present a kernelized andsupervised hashing method. With a small amount of supervised information; our method cancompress a 10;000-dimensional image feature vector into only tens of binary bits withinformative signatures preserved; and these binary codes are then indexed into a hash tablethat enables real-time retrieval. We validate the hashing-based image retrieval framework …,IEEE International Symposium on Biomedical Imaging,2014,13
Relevance aggregation projections for image retrieval,Wei Liu; Wei Jiang; Shih-Fu Chang,Abstract To narrow the semantic gap in content-based image retrieval (CBIR); relevancefeedback is utilized to explore knowledge about the user's intention in finding a target imageor a image category. Users provide feedback by marking images returned in response to aquery image as relevant or irrelevant. Existing research explores such feedback to refinequerying process; select features; or learn a image classifier. However; the vast amount ofunlabeled images is ignored and often substantially limited examples are engaged intolearning. In this paper; we address the two issues and propose a novel effective methodcalled Relevance Aggregation Projections (RAP) for learning potent subspace projections ina semi-supervised way. Given relevances and irrelevances specified in the feedback; RAPproduces a subspace within which the relevant examples are aggregated into a single …,Proceedings of the 2008 international conference on Content-based image and video retrieval,2008,13
Mqsearch: image search by multi-class query,Yiwen Luo; Wei Liu; Jianzhuang Liu; Xiaoou Tang,Abstract Image search is becoming prevalent in web search as the number of digital photosgrows exponentially on the internet. For a successful image search system; removingoutliers in the top ranked results is a challenging task. Typical content based image searchengines take an input image from one class as a query and compute relevance between thequery and images in a database. The results often contain a large number of outliers; sincethese outliers may be similar to the query image in some way. In this paper we present anovel search scheme using query images from multiple classes. Instead of conducting querysearch for one image class at a time; we conduct multi-class query search jointly. By usingseveral query classes that are similar to each other for multi-class query; we can utilizeinformation across similar classes to fine tune the similarity measure to remove outliers …,Proceeding of the twenty-sixth annual SIGCHI conference on Human factors in computing systems (CHI),2008,13
Deep Self-Taught Learning for Weakly Supervised Object Localization,Zequn Jie; Yunchao Wei; Xiaojie Jin; Jiashi Feng; Wei Liu,Abstract Most existing weakly supervised localization (WSL) approaches learn detectors byfinding positive bounding boxes based on features learned with image-level supervision.However; those features do not contain spatial location related information and usuallyprovide poor-quality positive samples for training a detector. To overcome this issue; wepropose a deep self-taught learning approach; which makes the detector learn the object-level features reliable for acquiring tight positive samples and afterwards re-train itself basedon them. Consequently; the detector progressively improves its detection ability andlocalizes more informative positive samples. To implement such self-taught learning; wepropose a seed sample acquisition method via image-to-object transferring and densesubgraph discovery to find reliable positive samples for initializing the detector. An online …,Proceedings of IEEE Conference on Computer Vision and Pattern Recognition (CVPR),2017,12
Towards 3D Object Detection With Bimodal Deep Boltzmann Machines Over RGBD Imagery,Wei Liu; Rongrong Ji; Shaozi Li,Coming with the popularities of depth sensors like Kinect; nowadays have witnessed anexplosive growth of RGB-Depth (RGBD) data to be processed and analyzed; with extensiveapplications in robotic navigation; pilotless automobile; gaming and entertainments etc. Inthe core of such applications lies the problem of RGBD scene parsing; ie; inferring labels ofindividual verxels to parse their semantic structure. In this paper; we focus on objectdetection in RGBD point clouds; which retains as an open problem in the state-of-the-artsemantic parsing algorithms of 3D point clouds. 3D object detection in RGBD scenes is avery challenging task due to the deficiency of training data. To the best of our knowledge; theexisting labels available for RGBD images are mostly hundreds to thousands; for instance;NYU [5]; RMRC [6]; and SUN3D [9]; which is of scales less comparing to endeavors on …,Proceedings of IEEE Conference on Computer Vision and Pattern Recognition (CVPR),2015,12
Design; synthesis and evaluation of novel dual monoamine-cholinesterase inhibitors as potential treatment for Alzheimer’s disease,Wei Liu; Ming Lang; Moussa BH Youdim; Tamar Amit; Yewei Sun; Zaijun Zhang; Yuqiang Wang; Orly Weinreb,Abstract Current novel therapeutic approach suggests that multifunctional compounds withdiverse biological properties and a single bioavailability and pharmacokinetic metabolism;will produce higher significant advantages in treatment of neurodegenerative diseases; suchas Alzheimer's disease (AD). Based on this rational; a new class of cholinesterase (ChE)-monoamine oxidase (MAO) inhibitors were designed and synthesized by amalgamating thepropargyl moiety of the irreversible selective MAO-B inhibitor; neuroprotective/neurorestorative anti-Parkinsonian drug; rasagiline; into the “N-methyl” position of the ChEinhibitor; anti-AD drug rivastigmine. Initially; we examined the MAO and ChE inhibitory effectof these novel compounds; MT series in vitro and in vivo. Among MT series; MT-031exhibited higher potency as a dual MAO-A and ChE inhibitor compared to other …,Neuropharmacology,2016,11
Towards Optimal Binary Code Learning via Ordinal Embedding,Hong Liu; Rongrong Ji; Yongjian Wu; Wei Liu,Abstract Binary code learning; aka; hashing; has been recently popular due to its highefficiency in large-scale similarity search and recognition. It typically maps high-dimensionaldata points to binary codes; where data similarity can be efficiently computed via rapidHamming distance. Most existing unsupervised hashing schemes pursue binary codes byreducing the quantization error from an original real-valued data space to a resultingHamming space. On the other hand; most existing supervised hashing schemes constrainbinary code learning to correlate with pairwise similarity labels. However; few methodsconsider ordinal relations in the binary code learning process; which serve as a verysignificant cue to learn the optimal binary codes for similarity search. In this paper; wepropose a novel hashing scheme; dubbed Ordinal Embedding Hashing (OEH); which …,Proceedings of the Thirtieth AAAI Conference on Artificial Intelligence (AAAI),2016,11
Rank Preserving Hashing for Rapid Image Search,Dongjin Song; Wei Liu; David A. Meyer; Dacheng Tao; Rongrong Ji,In recent years; hashing techniques are becoming overwhelmingly popular for their highefficiency in handling large-scale computer vision applications. It has been shown thathashing techniques which leverage supervised information can significantly enhanceperformance; and thus greatly benefit visual search tasks. Typically; a modern hashingmethod uses a set of hash functions to compress data samples into compact binary codes.However; few methods have developed hash functions to optimize the precision at the top ofa ranking list based upon Hamming distances. In this paper; we propose a novel supervisedhashing approach; namely Rank Preserving Hashing (RPH); to explicitly optimize theprecision of Hamming distance ranking towards preserving the supervised rank information.The core idea is to train disciplined hash functions in which the mistakes at the top of a …,IEEE Data Compression Conference (DCC),2015,11
Mining Spatiotemporal Video Patterns towards Robust Action Retrieval,Liujuan Cao; Rongrong Ji; Yue Gao; Wei Liu; Qi Tian,Abstract In this paper; we present a spatiotemporal co-location video pattern miningapproach with application to robust action retrieval in YouTube videos. First; we introduce anattention shift scheme to detect and partition the focused human actions from YouTubevideos; which is based upon the visual saliency [13] modeling together with both the face[35] and body [32] detectors. From the segmented spatiotemporal human action regions; weextract 3D-SIFT [17] detector. Then; we quantize all detected interest points from thereference YouTube videos into a vocabulary; based on which assign each individual interestpoint with a word identity. An APrior based frequent itemset mining scheme is then deployedover the spatiotemporal co-located words to discover co-location video patterns. Finally; wefuse both visual words and patterns and leverage a boosting based feature selection to …,Neurocomputing,2013,11
Pairwise Relationship Guided Deep Hashing for Cross-Modal Retrieval,Erkun Yang; Cheng Deng; Wei Liu; Dacheng Tao; Xinbo Gao,Abstract With benefits of low storage cost and fast query speed; crossmodal hashing hasreceived considerable attention recently. However; almost all existing methods on cross-modal hashing cannot obtain powerful hash codes due to directly utilizing hand-craftedfeatures or ignoring heterogeneous correlations across different modalities; which willgreatly degrade the retrieval performance. In this paper; we propose a novel deep cross-modal hashing method to generate compact hash codes through an end-to-end deeplearning architecture; which can effectively capture the intrinsic relationships betweenvarious modalities. Our architecture integrates different types of pairwise constraints toencourage the similarities of the hash codes from an intra-modal view and an inter-modalview; respectively. Moreover; additional decorrelation constraints are introduced to this …,Proceedings of The Thirty-First AAAI Conference on Artificial Intelligence (AAAI),2017,10
Face Recognition via Archetype Hull Ranking,Yuanjun Xiong; Wei Liu; Deli Zhao; Xiaoou Tang,Abstract The archetype hull model is playing an important role in large-scale data analyticsand mining; but rarely applied to vision problems. In this paper; we migrate such a geometricmodel to address face recognition and verification together through proposing a unifiedarchetype hull ranking framework. Upon a scalable graph characterized by a compact set ofarchetype exemplars whose convex hull encompasses most of the training images; theproposed framework explicitly captures the relevance between any query and the storedarchetypes; yielding a rank vector over the archetype hull. The archetype hull ranking is thenexecuted on every block of face images to generate a blockwise similarity measure that isachieved by comparing two different rank vectors with respect to the same archetype hull.After integrating blockwise similarity measurements with learned importance weights; we …,Proceedings of IEEE International Conference on Computer Vision (ICCV),2013,10
Distribution Calibration in Riemannian Symmetric Space,Si Si; Wei Liu; Dacheng Tao; K-P Chan,Distribution calibration plays an important role in cross-domain learning. However; existingdistribution distance metrics are not geodesic; therefore; they cannot measure the intrinsicdistance between two distributions. In this paper; we calibrate two distributions by using thegeodesic distance in Riemannian symmetric space. Our method learns a latent subspace inthe reproducing kernel Hilbert space; where the geodesic distance between the distributionof the source and the target domains is minimized. The corresponding geodesic distance isthus equivalent to the geodesic distance between two symmetric positive definite (SPD)matrices defined in the Riemannian symmetric space. These two SPD matricesparameterize the marginal distributions of the source and target domains in the latentsubspace. We carefully design an evolutionary algorithm to find a local optimal solution …,Systems; Man; and Cybernetics; Part B: Cybernetics; IEEE Transactions on,2011,10
Output regularized metric learning with side information,Wei Liu; Steven Hoi; Jianzhuang Liu,Abstract Distance metric learning has been widely investigated in machine learning andinformation retrieval. In this paper; we study a particular content-based image retrievalapplication of learning distance metrics from historical relevance feedback log data; whichleads to a novel scenario called collaborative image retrieval. The log data provide the sideinformation expressed as relevance judgements between image pairs. Exploiting the sideinformation as well as inherent neighborhood structures among examples; we design aconvex regularizer upon which a novel distance metric learning approach; named outputregularized metric learning; is presented to tackle collaborative image retrieval. Differentfrom previous distance metric methods; the proposed technique integrates synergisticinformation from both log data and unlabeled data through a regularization framework …,The 10th European Conference on Computer Vision (ECCV),2008,10
Face hallucination through dual associative learning,Wei Liu; Dahua Lin; Xiaoou Tang,In this paper; we propose a novel patch-based face hallucination framework; which employsa dual model to hallucinate different components associated with one facial image. Ourmodel is based on a statistical learning approach: associative learning. It suffices to learnthe dependencies between low-resolution image patches and their high-resolution oneswith a new concept hidden parameter space as a bridge to connect those patches withdifferent resolutions. To compensate higher frequency information of images; we present adual associative learning algorithm for orderly inferring main components and highfrequency components of faces. The patches can be finally integrated to form a whole high-resolution image. Experiments demonstrate that our approach does render high qualitysuperresolution faces.,Image Processing; 2005. ICIP 2005. IEEE International Conference on,2005,10
Classification by Retrieval: Binarizing Data and Classifiers,Fumin Shen; Yadong Mu; Yang Yang; Wei Liu; Li Liu; Jingkuan Song; Heng Tao Shen,Abstract This paper proposes a generic formulation that significantly expedites the trainingand deployment of image classification models; particularly under the scenarios of manyimage categories and high feature dimensions. As the core idea; our method representsboth the images and learned classifiers using binary hash codes; which are simultaneouslylearned from the training data. Classifying an image thereby reduces to retrieving its nearestclass codes in the Hamming space. Specifically; we formulate multiclass image classificationas an optimization problem over binary variables. The optimization alternatingly proceedsover the binary classifiers and image hash codes. Profiting from the special property ofbinary codes; we show that the sub-problems can be efficiently solved through either abinary quadratic program (BQP) or a linear program. In particular; for attacking the BQP …,ACM SIGIR Conference on Research and Development in Information Retrieval (SIGIR),2017,9
Sub-Selective Quantization for Large-Scale Image Search,Yeqing Li; Chen Chen; Wei Liu; Junzhou Huang,Abstract Recently with the explosive growth of visual content on the Internet; large-scaleimage search has attracted intensive attention. It has been shown that mappinghighdimensional image descriptors to compact binary codes can lead to considerableefficiency gains in both storage and similarity computation of images. However; mostexisting methods still suffer from expensive training devoted to large-scale binary codelearning. To address this issue; we propose a sub-selection based matrix manipulationalgorithm which can significantly reduce the computational cost of code learning. As casestudies; we apply the sub-selection algorithm to two popular quantization techniques PCAQuantization (PCAQ) and Iterative Quantization (ITQ). Crucially; we can justify the resultingsub-selective quantization by proving its theoretic properties. Extensive experiments are …,Proceedings of The Twenty-Eighth AAAI Conference on Artificial Intelligence (AAAI),2014,9
Two-Stage Hashing for Fast Document Retrieval,Hao Li; Wei Liu; Heng Ji,Abstract This work fulfills sublinear time Nearest Neighbor Search (NNS) in massivescaledocument collections. The primary contribution is to propose a two-stage unsupervisedhashing framework which harmoniously integrates two state-of-theart hashing algorithmsLocality Sensitive Hashing (LSH) and Iterative Quantization (ITQ). LSH accounts forneighbor candidate pruning; while ITQ provides an efficient and effective reranking over theneighbor pool captured by LSH. Furthermore; the proposed hashing framework capitalizeson both term and topic similarity among documents; leading to precise document retrieval.The experimental results convincingly show that our hashing based document retrievalapproach well approximates the conventional Information Retrieval (IR) method in terms ofretrieving semantically similar documents; and meanwhile achieves a speedup of over …,Proceedings of The 52nd Annual Meeting of the Association for Computational Linguistics (ACL),2014,9
When location meets social multimedia: A comprehensive survey on location-aware social multimedia,Rongrong Ji; Yue Gao; Wei Liu; Xing Xie; Qi Tian; Xuelong Li,*,ACM Transactions on Intelligent System and Technology,2014,9
Joint Intermodal and Intramodal Label Transfers for Extremely Rare or Unseen Classes,Guo-Jun Qi; Wei Liu; Charu Aggarwal; Thomas Huang,In this paper; we present a label transfer model from texts to images for image classificationtasks. The problem of image classification is often much more challenging than textclassification. On one hand; labeled text data is more widely available than the labeledimages for classification tasks. On the other hand; text data tends to have natural semanticinterpretability; and they are often more directly related to class labels. On the contrary; theimage features are not directly related to concepts inherent in class labels. One of our goalsin this paper is to develop a model for revealing the functional relationships between textand image features as to directly transfer intermodal and intramodal labels to annotate theimages. This is implemented by learning a transfer function as a bridge to propagate thelabels between two multimodal spaces. However; the intermodal label transfers could be …,IEEE Transactions on Pattern Analysis and Machine Intelligence (TPAMI),2017,8
Spectral–spatial co-clustering of hyperspectral image data based on bipartite graph,Wei Liu; Shaozi Li; Xianming Lin; YunDong Wu; Rongrong Ji,Abstract The high dimensionality of hyperspectral images are usually coupled with limiteddata available; which degenerates the performances of clustering techniques based only onpixel spectral. To improve the performances of clustering; incorporation of spectral andspatial is needed. As an attempt in this direction; in this paper; we propose an unsupervisedco-clustering framework to address both the pixel spectral and spatial constraints; in whichthe relationship among pixels is formulated using an undirected bipartite graph. The optimalpartitions are obtained by spectral clustering on the bipartite graph. Experiments on fourhyperspectral data sets are performed to evaluate the effectiveness of the proposedframework. Results also show our method achieves similar or better performance whencompared to the other clustering methods.,Multimedia Systems,2016,8
Fast Structural Binary Coding,Dongjin Song; Wei Liu; David A Meyer,Abstract Binary coding techniques; which compress originally high-dimensional datasamples into short binary codes; are becoming increasingly popular due to their efficiencyfor information retrieval. Leveraging supervised information can dramatically enhance thecoding quality; and hence improve search performance. There are few methods; however;that efficiently learn coding functions that optimize the precision at the top of the Hammingdistance ranking list while approximately preserving the geometric relationships betweendatabase examples. In this paper; we propose a novel supervised binary coding approach;namely Fast Structural Binary Coding (FSBC); to optimize the precision at the top of aHamming distance ranking list and ensure that similar images can be returned as a whole.The key idea is to train disciplined coding functions by optimizing a lower bound of the …,Proceedings of the Twenty-Fifth International Joint Conference on Artificial Intelligence (IJCAI),2016,8
Teaching-to-Learn and Learning-to-Teach For Multi-label Propagation,Chen Gong; Dacheng Tao; Jie Yang; Wei Liu,Abstract Multi-label propagation aims to transmit the multi-label information from labeledexamples to unlabeled examples based on a weighted graph. Existing methods ignore thespecific propagation difficulty of different unlabeled examples and conduct the propagationin an imperfect sequence; leading to the error-prone classification of some difficult exampleswith uncertain labels. To address this problem; this paper associates each possible labelwith a “teacher”; and proposes a “Multi-Label Teaching-to-Learn and Learning-to-Teach”(ML-TLLT) algorithm; so that the entire propagation process is guided by the teachers andmanipulated from simple examples to more difficult ones. In the teaching-to-learn step; theteachers select the simplest examples for the current propagation by investigating both thedefinitiveness of each possible label of the unlabeled examples; and the dependencies …,Proceedings of the Thirtieth AAAI Conference on Artificial Intelligence (AAAI),2016,8
Multi-View Matrix Decomposition: A New Scheme for Exploring Discriminative Information,Cheng Deng; Zongting Lv; Wei Liu; Junzhou Huang; Dacheng Tao; Xinbo Gao,Abstract Recent studies have demonstrated the advantages of fusing information frommultiple views for various machine learning applications. However; most existingapproaches assumed the shared component common to all views and ignored the privatecomponents of individual views; which thereby restricts the learning performance. In thispaper; we propose a new multi-view; low-rank; and sparse matrix decomposition scheme toseamlessly integrate diverse yet complementary information stemming from multiple views.Unlike previous approaches; our approach decomposes an input data matrix concatenatedfrom multiple views as the sum of lowrank; sparse; and noisy parts. Then a unifiedoptimization framework is established; where the lowrankness and group-structured sparsityconstraints are imposed to simultaneously capture the shared and private components in …,Proceedings of the 24th International Joint Conference on Artificial Intelligence (IJCAI),2015,8
Optimal Semi-Supervised Metric Learning for Image Retrieval,Kun Zhao; Wei Liu; Jianzhuang Liu,Abstract In a typical content-based image retrieval (CBIR) system; images are representedas vectors and similarities between images are measured by a specified distance metric.However; the traditional Euclidean distance cannot always deliver satisfactory performance;so an effective metric sensible to the input data is desired. Tremendous recent works onmetric learning have exhibited promising performance; but most of them suffer from limitedlabel information and expensive training costs. In this paper; we propose two novel metriclearning approaches; Optimal Semi-Supervised Metric Learning and its kernelized version.In the proposed approaches; we incorporate information from both labeled and unlabeleddata to design a convex and computationally tractable learning framework which results in aglobally optimal solution to the target metric of much lower rank than the original data …,ACM International Conference on Multimedia,2012,8
Real-Time Neural Style Transfer for Videos,Haozhi Huang; Hao Wang; Wenhan Luo; Lin Ma; Wenhao Jiang; Xiaolong Zhu; Zhifeng Li; Wei Liu,Abstract Recent research endeavors have shown the potential of using feed-forwardconvolutional neural networks to accomplish fast style transfer for images. In this work; wetake one step further to explore the possibility of exploiting a feed-forward network to performstyle transfer for videos and simultaneously maintain temporal consistency among stylizedvideo frames. Our feed-forward network is trained by enforcing the outputs of consecutiveframes to be both well stylized and temporally consistent. More specifically; a hybrid loss isproposed to capitalize on the content information of input frames; the style information of agiven style image; and the temporal information of consecutive frames. To calculate thetemporal loss during the training stage; a novel two-frame synergic training mechanism isproposed. Compared with directly applying an existing image style transfer method to …,Proceedings of IEEE Conference on Computer Vision and Pattern Recognition (CVPR),2017,7
Efficient Robust Conditional Random Fields,Dongjin Song; Wei Liu; Tianyi Zhou; Dacheng Tao; David A. Meyer,Conditional random fields (CRFs) are a flexible yet powerful probabilistic approach andhave shown advantages for popular applications in various areas; including text analysis;bioinformatics; and computer vision. Traditional CRF models; however; are incapable ofselecting relevant features as well as suppressing noise from noisy original features.Moreover; conventional optimization methods often converge slowly in solving the trainingprocedure of CRFs; and will degrade significantly for tasks with a large number of samplesand features. In this paper; we propose robust CRFs (RCRFs) to simultaneously selectrelevant features. An optimal gradient method (OGM) is further designed to train RCRFsefficiently. Specifically; the proposed RCRFs employ the $\ell _ {1} $ norm of the modelparameters to regularize the objective used by traditional CRFs; therefore enabling …,IEEE Transactions on Image Processing (TIP),2015,7
Large-scale machine learning for classification and search,Wei Liu,Abstract With the rapid development of the Internet; nowadays tremendous amounts of dataincluding images and videos; up to millions or billions; can be collected for training machinelearning models. Inspired by this trend; this thesis is dedicated to developing large-scalemachine learning techniques for the purpose of making classification and nearest neighborsearch practical on gigantic databases.,*,2012,7
Scalable Mammogram Retrieval Using Composite Anchor Graph Hashing With Iterative Quantization,Jingjing Liu Liu; Shaoting Zhang; Wei Liu; Cheng Deng; Yuanjie Zheng; Dimitris N. Metaxas,Content-based image retrieval (CBIR) shows great significance in clinical decision-making;which explores the visual content of medical images rather than keywords; tags; ordescriptions. It provides doctors an image-guided approach to explore relevant cases thatcould offer doctors instructive reference. Mammogram screening has been known to bewidely used in the early stage diagnosis of breast cancer and could reduce its morbidity andmortality. In this paper; we aim to develop a scalable CBIR method for a large repository ofmammogram. To this end; we extend the original Anchor Graph Hashing (AGH) andpropose a new unsupervised hashing algorithm; named as composite AGH with iterativequantization (C-AGH-ITQ); which compresses mammographic regions of interest (ROIs) intocompact binary codes and enables real-time searching in Hamming space. Multimodal …,IEEE Transactions on Circuits and Systems for Video Technology,2017,6
Stochastic Gradient Made Stable: A Manifold Propagation Approach for Large-Scale Optimization,Yadong Mu; Wei Liu; Xiaobai Liu; Wei Fan,Stochastic gradient descent (SGD) holds as a classical method to build large scale machinelearning models over big data. A stochastic gradient is typically calculated from a limitednumber of samples (known as mini-batch); which potentially incurs a high variance andcauses the estimated parameters to bounce around the optimal solution. To improve thestability of stochastic gradient; recent years have witnessed the proposal of several semi-stochastic gradient descent algorithms; which distinguish themselves from standard SGD byincorporating global information into gradient computation. In this paper; we contribute anovel stratified semi-stochastic gradient descent (S3GD) algorithm to this nascent researcharea; accelerating the optimization of a large family of composite convex functions. Thoughtheoretically converging faster; prior semi-stochastic algorithms are found to suffer from …,IEEE Transactions on Knowledge and Data Engineering (TKDE),2017,6
Deep Learning Driven Visual Path Prediction from a Single Image,Siyu Huang; Xi Li; Zhongfei Zhang; Zhouzhou He; Fei Wu; Wei Liu; Jinhui Tang; Yueting Zhuang,Capabilities of inference and prediction are the significant components of visual systems.Visual path prediction is an important and challenging task among them; with the goal toinfer the future path of a visual object in a static scene. This task is complicated as it needshigh-level semantic understandings of both the scenes and underlying motion patterns invideo sequences. In practice; cluttered situations have also raised higher demands on theeffectiveness and robustness of models. Motivated by these observations; we propose adeep learning framework; which simultaneously performs deep feature learning for visualrepresentation in conjunction with spatiotemporal context modeling. After that; a unified path-planning scheme is proposed to make accurate path prediction based on the analytic resultsreturned by the deep context models. The highly effective visual representation and deep …,IEEE Transactions on Image Processing (TIP),2016,6
Scalable Histopathological Image Analysis via Active Learning,Yan Zhu; Shaoting Zhang; Wei Liu; Dimitris N. Metaxas,Abstract Training an effective and scalable system for medical image analysis usuallyrequires a large amount of labeled data; which incurs a tremendous annotation burden forpathologists. Recent progress in active learning can alleviate this issue; leading to a greatreduction on the labeling cost without sacrificing the predicting accuracy too much. However;most existing active learning methods disregard the “structured information” that may exist inmedical images (eg; data from individual patients); and make a simplifying assumption thatunlabeled data is independently and identically distributed. Both may not be suitable for real-world medical images. In this paper; we propose a novel batch-mode active learning methodwhich explores and leverages such structured information in annotations of medical imagesto enforce diversity among the selected data; therefore maximizing the information gain …,Annual International Conference on Medical Image Computing and Computer Assisted Intervention (MICCAI),2014,6
Fast Tweet Retrieval with Compact Binary Codes,Weiwei Guo; Wei Liu; Mona Diab,Abstract The most widely used similarity measure in the field of natural language processingmay be cosine similarity. However; in the context of Twitter; the large scale of massive tweetdata inevitably makes it expensive to perform cosine similarity computations amongtremendous data samples. In this paper; we exploit binary coding to tackle the scalabilityissue; which compresses each data sample into a compact binary code and hence enableshighly efficient similarity computations via Hamming distances between the generatedcodes. In order to yield semantics sensitive binary codes for tweet data; we design abinarized matrix factorization model and further improve it in two aspects. First; we force theprojection directions employed by the model nearly orthogonal to reduce the redundantinformation in their resulting binary bits. Second; we leverage the tweets' neighborhood …,Proceedings of The 25th International Conference on Computational Linguistics (COLING),2014,6
Anti-inflammatory and protective effects of MT-031; a novel multitarget MAO-A and AChE/BuChE inhibitor in scopolamine mouse model and inflammatory cells,Wei Liu; Alon Rabinovich; Yuval Nash; Dan Frenkel; Yuqiang Wang; Moussa BH Youdim; Orly Weinreb,Abstract Previous study demonstrated that the novel multitarget compound; MT-031preserved in one molecule entity the beneficial properties of its parent drugs; rasagiline andrivastigmine; and exerted high dual potencies of monoamine oxidase-A (MAO-A) andcholinesterase (ChE) inhibition in acute-treated mice and neuroprotective effects against H 2O 2-induced neurotoxicity in human neuroblastoma SH-SY5Y cells. The present studyaimed to further investigate the anti-inflammatory and protective effects of MT-031 inscopolamine mouse model and inflammatory cell cultures. Our findings demonstrated thatonce daily chronic administration of MT-031 (5–10 mg/kg) to mice antagonized scopolamine-induced memory and cognitive impairments; displayed brain selective MAO-A andAChE/BuChE inhibition; increased the levels of striatal dopamine (DA); serotonin (5-HT) …,Neuropharmacology,2017,5
Video Classification via Weakly Supervised Sequence Modeling,Jingjing Liu; Chao Chen; Yan Zhu; Wei Liu; Dimitris N Metaxas,Abstract Traditional approaches for video classification treat the entire video clip as one datainstance. They extract visual features from video frames which are then quantized (eg; K-means) and pooled (eg; average pooling) to produce a single feature vector. Such holisticrepresentations of videos are further used as inputs of a classifier. Despite of efficiency;global and aggregate feature representation unavoidably brings in redundant and noisyinformation from background and unrelated video frames that sometimes overwhelmstargeted visual patterns. Besides; temporal correlations between consecutive video framesare also ignored in both training and testing; which may be the key indicator of an action orevent. To this end; we propose Weakly Supervised Sequence Modeling (WSSM); a novelframework that combines multiple-instance learning (MIL) and Conditional Random Field …,Computer Vision and Image Understanding,2016,5
Scalable Sequential Spectral Clustering,Yeqing Li; Junzhou Huang; Wei Liu,Abstract In the past decades; Spectral Clustering (SC) has become one of the most effectiveclustering approaches. Although it has been widely used; one significant drawback of SC isits expensive computation cost. Many efforts have been devoted to accelerating SCalgorithms and promising results have been achieved. However; most of the existingalgorithms rely on the assumption that data can be stored in the computer memory. Whendata cannot fit in the memory; these algorithms will suffer severe performance degradations.In order to overcome this issue; we propose a novel sequential SC algorithm for tacklinglarge-scale clustering with limited computational resources; eg; memory. We begin withinvestigating an effective way of approximating the graph affinity matrix via leveraging abipartite graph. Then we choose a smart graph construction and optimization strategy to …,Proceedings of the Thirtieth AAAI Conference on Artificial Intelligence (AAAI),2016,5
On Stochastic Primal-Dual Hybrid Gradient Approach for Compositely Regularized Minimization,Linbo Qiao; Tianyi Lin; Yu-Gang Jiang; Fan Yang; Wei Liu; Xicheng Lu,Abstract. We consider a wide spectrum of regularized stochastic minimization problems;where the regularization term is composite with a linear function. Examples of thisformulation include graphguided regularized minimization; generalized Lasso and a class ofl1 regularized problems. The computational challenge is that the closed-form solution of theproximal mapping associated with the regularization term is not available due to theimposed linear composition. Fortunately; the structure of the regularization term allows us toreformulate it as a new convex-concave saddle point problem which can be solved using thePrimal-Dual Hybrid Gradient (PDHG) approach. However; this approach may be inefficientin realistic applications as computing the full gradient of the expected objective functioncould be very expensive when the number of input data samples is considerably large. To …,The Twenty-second European Conference on Artificial Intelligence (ECAI),2016,4
Auxiliary Training Information Assisted Visual Recognition,Qilin Zhang; Gang Hua; Wei Liu; Zicheng Liu; Zhengyou Zhang,Abstract: In the realm of multi-modal visual recognition; the reliability of the data acquisitionsystem is often a concern due to the increased complexity of the sensors. One of the majorissues is the accidental loss of one or more sensing channels; which poses a majorchallenge to current learning systems. In this paper; we examine one of these specificmissing data problems; where we have a main modality/view along with an auxiliarymodality/view present in the training data; but merely the main modality/view in the test data.To effectively leverage the auxiliary information to train a stronger classifier; we propose acollaborative auxiliary learning framework based on a new discriminative canonicalcorrelation analysis. This framework reveals a common semantic space shared across bothmodalities/views through enforcing a series of nonlinear projections. Such projections …,IPSJ Transactions on Computer Vision and Applications,2015,4
Understanding Image Structure via Hierarchical Shape Parsing,Xianming Liu; Rongrong Ji; Changhu Wang; Wei Liu; Bineng Zhong; Thomas S. Huang,Abstract Exploring image structure is a long-standing yet important research subject in thecomputer vision community. In this paper; we focus on understanding image structureinspired by the “simple-to-complex” biological evidence. A hierarchical shape parsingstrategy is proposed to partition and organize image components into a hierarchicalstructure in the scale space. To improve the robustness and flexibility of imagerepresentation; we further bundle the image appearances into hierarchical parsing trees.Image descriptions are subsequently constructed by performing a structural pooling;facilitating efficient matching between the parsing trees. We leverage the proposedhierarchical shape parsing to study two exemplar applications including edge scalerefinement and unsupervised “objectness” detection. We show competitive parsing …,Proceedings of IEEE Conference on Computer Vision and Pattern Recognition (CVPR),2015,4
Localizing Web Videos Using Social Images,Liujuan Cao; Xianming Liu; Wei Liu; Rongrong Ji; Thomas S. Huang,Abstract While inferring the geo-locations of web images has been widely studied; there islimited work engaging in geo-location inference of web videos due to inadequate labeledsamples available for training. However; such a geographical localization functionality is ofgreat importance to help existing video sharing websites provide location-aware services;such as location-based video browsing; video geo-tag recommendation; and locationsensitive video search on mobile devices. In this paper; we address the problem oflocalizing web videos through transferring large-scale web images with geographic tags toweb videos; where near-duplicate detection between images and video frames is conductedto link the visually relevant web images and videos. To perform our approach; we choosethe trustworthy web images by evaluating the consistency between the visual features …,Information Sciences,2015,4
Image-based tree pruning,Wei Liu; George Kantor; Fernando De la Torre; Nanning Zheng,There is an increasing awareness and development of agricultural robots to take the toil offarming by automating growing plants and trees. Pruning is an expensive and laborintensive step in growing trees; that greatly affects its productivity. Moreover; pruningrequires knowledge about what; where and how to cut. To partially solve the limitations ofmanual pruning methods; this paper presents an automatic image-based pruning system.Our system uses a high-resolution and a Kinect camera mounted on a mobile robot tocapture the 3D structure of trees in the field. The robot goes around a tree andsynchronously captures high-resolution and depth images. The visual and depth informationacross images is fused to estimate a 3D “stick” representation of the tree. The output of oursystem suggests the operator which branches to cut based on pre-existing rules. Several …,Robotics and Biomimetics (ROBIO); 2012 IEEE International Conference on,2012,4
Geometric Descent Method for Convex Composite Minimization,Shixiang Chen; Shiqian Ma; Wei Liu,Abstract In this paper; we extend the geometric descent method recently proposed byBubeck; Lee and Singh to tackle nonsmooth and strongly convex composite problems. Weprove that our proposed algorithm; dubbed geometric proximal gradient method (GeoPG);converges with a linear rate $(1-1/\sqrt {\kappa}) $ and thus achieves the optimal rate amongfirst-order methods; where $\kappa $ is the condition number of the problem. Numericalresults on linear regression and logistic regression with elastic net regularization show thatGeoPG compares favorably with Nesterov's accelerated proximal gradient method;especially when the problem is ill-conditioned.,Advances in Neural Information Processing Systems (NIPS),2017,3
Hierarchical Visualization of Video Search Results for Topic-based Browsing,Yu-Gang Jiang; Jiajun Wang; Qiang Wang; Wei Liu; Chong-Wah Ngo,Existing video search engines return a ranked list of videos for each user query; which is notconvenient for browsing the results of query topics that have multiple facets; such as the“early life;”“personal life;” and “presidency” of a query “Barack Obama.” Organizing videosearch results into semantically structured hierarchies with nodes covering different topicfacets can significantly improve the browsing efficiency for such queries. In this paper; weintroduce a hierarchical visualization approach for video search result browsing; which canhelp users quickly understand the multiple facets of a query topic in a very well-organizedmanner. Given a query; our approach starts from the hierarchy of its textual descriptionsnormally available on Wikipedia and then adjusts the hierarchical structure by analyzing thevideo information to reflect the topic structure of the search result. After that; a simple …,IEEE Transactions on Multimedia,2016,3
Visual Tracking with Reliable Memories.,Shu Wang; Shaoting Zhang; Wei Liu; Dimitris N Metaxas,Abstract In this paper; we propose a novel visual tracking framework that intelligentlydiscovers reliable patterns from a wide range of video to resist drift error for long-termtracking tasks. First; we design a Discrete Fourier Transform (DFT) based tracker which isable to exploit a large number of tracked samples while still ensures real-time performance.Second; we propose a clustering method with temporal constraints to explore and memorizeconsistent patterns from previous frames; named as “reliable memories”. By virtue of thismethod; our tracker can utilize uncontaminated information to alleviate drifting issues.Experimental results show that our tracker performs favorably against other stateof-the-artmethods on benchmark datasets. Furthermore; it is significantly competent in handling driftsand able to robustly track challenging long videos over 4000 frames; while most of others …,IJCAI,2016,3
Efficient Multi-Class Selective Sampling on Graphs,Peng Yang; Peilin Zhao; Zhen Hai; Wei Liu; Steven C.H. Hoi; Xiao-Li Li,Abstract A graph-based multi-class classification problem is typically converted into acollection of binary classification tasks via the one-vs.-all strategy; and then tackled byapplying proper binary classification algorithms. Unlike the one-vs.-all strategy; we suggesta unified framework which operates directly on the multi-class problem without reducing it toa collection of binary tasks. Moreover; this framework makes active learning practicallyfeasible for multi-class problems; while the one-vs.-all strategy cannot. Specifically; weemploy a novel randomized query technique to prioritize the informative instances. Thisquery technique based on the hybrid criterion of" margin" and" uncertainty" can achieve acomparable mistake bound with its fully supervised counterpart. To take full advantage ofcorrectly predicted labels discarded in traditional conservative algorithms; we propose an …,The Conference on Uncertainty in Artificial Intelligence (UAI),2016,3
An Efficient Semi-Supervised Clustering Algorithm with Sequential Constraints,Jinfeng Yi; Lijun Zhang; Tianbao Yang; Wei Liu,Abstract Semi-supervised clustering leverages side information such as pairwise constraintsto guide clustering procedures. Despite promising progress; existing semi-supervisedclustering approaches overlook the condition of side information being generatedsequentially; which is a natural setting arising in numerous real-world applications such associal network and e-commerce system analysis. Given emerged new constraints; classicalsemi-supervised clustering algorithms need to re-optimize their objectives over all datasamples and constraints in availability; which prevents them from efficiently updating theobtained data partitions. To address this challenge; we propose an efficient dynamic semi-supervised clustering framework that casts the clustering problem into a search problemover a feasible convex set; ie; a convex hull with its extreme points being an ensemble of …,Proceedings of the 21th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining (KDD),2015,3
Sparse Subspace Clustering for Incomplete Images,Xiao Wen; Linbo Qiao; Shiqian Ma; Wei Liu; Hong Cheng,Abstract In this paper; we propose a novel approach to cluster incomplete imagesleveraging sparse subspace structure and total variation regularization. Sparse subspaceclustering obtains a sparse representation coefficient matrix for input data points by solvingan ℓ1 minimization problem; and then uses the coefficient matrix to construct a sparsesimilarity graph over which spectral clustering is performed. However; conventional sparsesubspace clustering methods are not exclusively designed to deal with incomplete images.To this end; our goal in this paper is to simultaneously recover incomplete images andcluster them into appropriate clusters. A new nonconvex optimization framework isestablished to achieve this goal; and an efficient first-order algorithm is developed to tacklethe nonconvex optimization. Extensive experiments carried out on three public datasets …,Proceedings of IEEE International Conference on Computer Vision (ICCV) Workshops,2015,3
Wei Liu,Wei Liu,729 Arapeen Drive; Salt Lake City; UT; 84108 Phone: 801-386-7629 Email: weiliu atcs.utah.edu http://www.cs.utah.edu/~weiliu … Machine learning; data mining; imaging and computervision. I'm especially interested RESEARCH INTERESTS in applying statistical learning algorithmto multivariate data in imaging and vision … EDUCATION School of Computing; University ofUtah • Resting-State Functional Magnetic Resonance Imaging Analysis By Graphical Model(Advisor: Tom Fletcher) … Jilin University; Changchun; Jilin; China • Feature Extraction UsingSubspace Decomposing and Kernel Space Mapping (Advisor: HexinChen) … EMPLOYMENTUtah Center for Advanced Imaging Research; University of Utah • Working with Dr. Brian Chapmanon statistical shape analysis with human lung CT imaging … Scientific Computing and ImagingInstitute; University of Utah • Worked with Dr. Tom Fletcher on human brain functional …,J. Mater. Chem. C,2014,3
Weakly Supervised Codebook Learning by Iterative Label Propagation with Graph Quantization,Liujuan Cao; Rongrong Ji; Wei Liu; Hongxun Yao; Qi Tian,Abstract Visual codebook serves as a fundamental component in many state-of-the-artvisual search and object recognition systems. While most existing codebooks are builtbased solely on unsupervised patch quantization; there are few works exploited imagelabels to supervise its construction. The key challenge lies in the following: image labels areglobal; but patch supervision should be local. Such imbalanced supervision is beyond thescope of most existing supervised codebooks [9; 10; 12–15; 29]. In this paper; we propose aweakly supervised codebook learning framework; which integrates image labels tosupervise codebook building with two steps: the Label Propagation step propagates imagelabels into local patches by multiple instance learning and instance selection [20; 21]. TheGraph Quantization step integrates patch labels to build codebook using Mean Shift. Both …,Signal Processing,2013,3
Local manifold matching for face recognition,Wei Liu; Wei Fan; Yunhong Wang; Tieniu Tan,In this paper; we propose a novel classification method; called local manifold matching(LMM); for face recognition. LMM has great representational capacity of available prototypesand is based on the local linearity assumption that each data point and its k nearestneighbors from the same class lie on a linear manifold locally embedded in the imagespace. We present a supervised local manifold learning algorithm for learning all locallylinear manifold structures. Then we propose the nearest manifold criterion for theclassification in which the query feature point is assigned to the most matching facemanifold. Experimental results show that kernel PCA incorporated with the LMM classifierachieves the best face recognition performance.,Image Processing; 2005. ICIP 2005. IEEE International Conference on,2005,3
Classification of DNA Sequences,Yi-ping HAN; Hang YU; Wei LIU,This paper proposes several methods for the classification of DNA sequences. We noticedthat different sequences have differentalkali radicals and therefore set up models usingEuclidean distance; Mahalanobis distance and Fisher principle. We also noticed thatdifferent sequences have different permutations of alkali radicals and an algorithm usingrelativity analysis is proposed. Further we discussed a relativity analysis algorithm with feed-back mechanism. As to the natural and artificial data given our algorithms work well and fineresults are given. At last several other common algorithms are compared; especially on theirstabilities,Mathematics In Practice and Theory,2001,3
Learning for 3D Understanding,Yue Gao; Rongrong Ji; Wei Liu; Qionghai Dai,*,Neurocomputing,2015,2
Zeta Hull Pursuits: Learning Nonconvex Data Hulls,Yuanjun Xiong; Wei Liu; Deli Zhao; Xiaoou Tang,Abstract Selecting a small informative subset from a given dataset; also called columnsampling; has drawn much attention in machine learning. For incorporating structured datainformation into column sampling; research efforts were devoted to the cases where datapoints are fitted with clusters; simplices; or general convex hulls. This paper aims to studynonconvex hull learning which has rarely been investigated in the literature. In order to learndata-adaptive nonconvex hulls; a novel approach is proposed based on a graph-theoreticmeasure that leverages graph cycles to characterize the structural complexities of input datapoints. Employing this measure; we present a greedy algorithmic framework; dubbed ZetaHulls; to perform structured column sampling. The process of pursuing a Zeta hull involvesthe computation of matrix inverse. To accelerate the matrix inversion computation and …,Advances in Neural Information Processing Systems (NIPS),2014,2
Learning to rank binary codes,Jie Feng; Wei Liu; Yan Wang,Abstract: Binary codes have been widely used in vision problems as a compact featurerepresentation to achieve both space and time advantages. Various methods have beenproposed to learn data-dependent hash functions which map a feature vector to a binarycode. However; considerable data information is inevitably lost during the binarization stepwhich also causes ambiguity in measuring sample similarity using Hamming distance.Besides; the learned hash functions cannot be changed after training; which makes themincapable of adapting to new data outside the training data set. To address both issues; inthis paper we propose a flexible bitwise weight learning framework based on the binarycodes obtained by state-of-the-art hashing methods; and incorporate the learned weightsinto the weighted Hamming distance computation. We then formulate the proposed …,arXiv preprint arXiv:1410.5524,2014,2
Method for searching a database using query images and an image anchor graph-based ranking algorithm,*,A method for searching in a large-scale database of images for images that are visuallysimilar to query images is provided using a processor to perform the following steps:computing visual features for the database images; constructing an Image Anchor Graphthat contains a plurality of anchors corresponding to a subset of images in the database;according to the computed visual features; computing visual features for the query images;and retrieving database images similar to one or more user query images using a rankingalgorithm that uses the anchors in the Image Anchor Graph according to the computedvisual features of both the query images and the database images on the Image AnchorGraph.,*,2014,2
Bidirectional Label Propagation over Graphs,Wei Liu; Tongtao Zhang,Abstract Graph-Based label propagation algorithms are popular in the state-of-the-art semi-supervised learning research. The key idea underlying this algorithmic family is to enforcelabeling consistency between any two examples with a positive similarity. However;negative similarities or dissimilarities are equivalently valuable in practice. To this end; wesimultaneously leverage similarities and dissimilarities in our proposed semi-supervisedlearning algorithm which we term Bidirectional Label Propagation (BLP). Different fromprevious label propagation mechanisms that proceed along a single direction of graphedges; the BLP algorithm can propagate labels along not only positive but also negativeedge directions. By using an initial neighborhood graph and class assignment constraintsinherent among the labeled examples; a set of class-specific graphs are learned; which …,International Journal of Software and Informatics,2013,2
Learning to Generate Time-Lapse Videos Using Multi-Stage Dynamic Generative Adversarial Networks,Wei Xiong; Wenhan Luo; Lin Ma; Wei Liu; Jiebo Luo,Abstract: Taking a photo outside; can we predict the immediate future; like how the cloudwould move in the sky? We answer this question by presenting a generative adversarialnetwork (GAN) based two-stage approach to generating realistic time-lapse videos of highresolution. Given the first frame; our model learns to generate long-term future frames. Thefirst stage aims to generate videos of similar content as that in the input frame and ofplausible motion dynamics. The second stage refines the generated video from the firststage by enforcing it to be closer to real videos with regard to dynamics. To furtherencourage realistic motion in the final generated video; Gram matrix is employed to modelthe motion more precisely. We build a large scale time-lapse dataset; and test our approachon this new dataset. Using our model; we are able to generate up to $128\times 128 …,IEEE Conference on Computer Vision and Pattern Recognition (CVPR),2018,1
Scaling Up Sparse Support Vector Machines by Simultaneous Feature and Sample Reduction,Weizhong Zhang; Bin Hong; Wei Liu; Jieping Ye; Deng Cai; Xiaofei He; Jie Wang,Abstract: Sparse support vector machine (SVM) is a popular classification technique that cansimultaneously learn a small set of the most interpretable features. It has achieved greatsuccess in many real-world applications. However; for large-scale problems involving ahuge number of samples and extremely high-dimensional features; solving sparse SVMremains challenging. By noting that sparse SVM induces sparsities in both feature andsample spaces; we propose a novel approach---that is based on accurate estimations of theprimal and dual optimums of sparse SVM---to simultaneously identify the features andsamples that are guaranteed to be irrelevant to the outputs. Thus; we can remove theidentified samples and features from the training phase; which may lead to substantialsavings in both memory usage and computational cost without sacrificing accuracy. To …,International Conference on Machine Learning (ICML),2017,1
Mobile social multimedia analytics in the big data era: An introduction to the special issue,Rongrong Ji; Wei Liu; Xing Xie; Yiqiang Chen; Jiebo Luo,The proliferation of mobile devices has led to a bright new stage in which multimedia searchand analysis are increasingly moving from the desktop to the cloud. Nowadays; it hasbecome convenient to capture images and videos on the mobile end and associate themwith social and contextual metadata such as comments and Global Positioning System(GPS) tags. Such a hybrid data structure can benefit a wide variety of potential multimediaapplications on the mobile end; such as location recognition; landmark search; augmentedreality; and commercial recommendations. One intrinsic potential is to explore large-scalesocial multimedia to assist and facilitate location-related applications; which is furtherpromoted by the evolution of mobile devices. With the combination of social and mobilecues; several problems that previously had been difficult to tackle in multimedia content …,ACM Transactions on Intelligent Systems and Technology (TIST),2017,1
Adaptive Proximal Average Approximation for Composite Convex Minimization,Li Shen; Wei Liu; Junzhou Huang; Yugang Jiang; Shiqian Ma,Abstract We propose a fast first-order method to solve multi-term nonsmooth compositeconvex minimization problems by employing a recent proximal average approximationtechnique and a novel adaptive parameter tuning technique. Thanks to this powerfulparameter tuning technique; the proximal gradient step can be performed with a much largerstepsize in the algorithm implementation compared with the prior PAAPG method (Yu 2013);which is the core to enable significant improvements in practical performance. Moreover; bychoosing the approximation parameter adaptively; the proposed method is shown to enjoythe O (1 k) iteration complexity theoretically without needing any extra computational cost;while the PA-APG method incurs much more iterations for convergence. The preliminaryexperimental results on overlapping group Lasso and graph-guided fused Lasso …,Proceedings of The Thirty-First AAAI Conference on Artificial Intelligence (AAAI),2017,1
Advanced learning for large-scale heterogeneous computing,Quan Zou; Wei Liu; Michele Merler; Rongrong Ji,*,Neurocomputing,2016,1
Multimedia hashing and networking,Wei Liu; Tongtao Zhang,This department discusses multimedia hashing and networking. The authors summarizeshallow-learning-based hashing and deep-learning-based hashing. By exploitingsuccessful shallow-learning algorithms; state-of-the-art hashing techniques have beenwidely used in high-efficiency multimedia storage; indexing; and retrieval; especially inmultimedia search applications on smartphone devices. The authors also introduceMultimedia Information Networks (MINets) and present one paradigm of leveraging MINetsto incorporate both visual and textual information to reach a sensible event coreferenceresolution. The goal is to make deep learning practical in realistic multimedia applications.,IEEE MultiMedia,2016,1
Learning with l0-Graph: l0-Induced Sparse Subspace Clustering,Yingzhen Yang; Jiashi Feng; Jianchao Yang; Wei Liu; Thomas S Huang,Abstract Sparse subspace clustering methods; such as Sparse Subspace Clustering(SSC)[8] and ℓ1-graph [26; 4]; are effective in partitioning the data that lie in a union ofsubspaces. Most of those methods use ℓ1-norm or ℓ2-norm with thresholding to impose thesparsity of the constructed sparse similarity graph; and certain assumptions; egindependence or disjointness; on the subspaces are required to obtain the subspace-sparserepresentation; which is the key to their success. Such assumptions are not guaranteed tohold in practice and they limit the application of sparse subspace clustering on subspaceswith general location. In this paper; we propose a new sparse subspace clustering methodnamed ℓ0-graph. In contrast to the required assumptions on subspaces for most existingsparse subspace clustering methods; it is proved that subspace-sparse representation …,*,2016,1
Coordinate Discrete Optimization for Efficient Cross-View Image Retrieval,Yadong Mu; Wei Liu; Cheng Deng; Zongting Lv; Xinbo Gao,Abstract Learning compact hash codes has been a vibrant research topic for large-scalesimilarity search owing to the low storage cost and expedited search operation. A recentresearch thrust aims to learn compact codes jointly from multiple sources; referred to ascross-view (or cross-modal) hashing in the literature. The main theme of this paper is todevelop a novel formulation and optimization scheme for cross-view hashing. As a keydifferentiator; our proposed method directly conducts optimization on discrete binary hashcodes; rather than relaxed continuous variables as in existing cross-view hashing methods.This way relaxation-induced search accuracy loss can be avoided. We attack the crossviewhashing problem by simultaneously capturing semantic neighboring relations andmaximizing the generative probability of the learned hash codes in each view …,Proceedings of the Twenty-Fifth International Joint Conference on Artificial Intelligence (IJCAI),2016,1
Query-Dependent Visual Dictionary Adaptation for Image Reranking,Jialong Wang; Cheng Deng; Wei Liu; Rongrong Ji; Xiangyu Chen; Xinbo Gao,Abstract Although text-based image search engines are popular for ranking images of user'sinterest; the state-of-the-art ranking performance is still far from satisfactory. One major issuecomes from the visual similarity metric used in the ranking operation; which depends solelyon visual features. To tackle this issue; one feasible method is to incorporate semanticconcepts; also known as image attributes; into image ranking. However; the optimalcombination of visual features and image attributes remains unknown. In this paper; wepropose a query-dependent image reranking approach by leveraging the higher levelattribute detection among the top returned images to adapt the dictionary built over thevisual features to a query-specific fashion. We start from offline learning transpositionprobabilities between visual codewords and attributes; then utilize the probabilities to …,The 21st ACM International Conference on Multimedia,2013,1
August 12; 2012,Wei Liu,Resting-state functional MRI (rs-fMRI) is increasingly used for probing functional connectivityof the human brain. The spontaneous activity identified by rs-fMRI plays a key role inunderstanding the normal brain's functional organization. It also holds valuable diagnosticand prognostic information towards various neurological or psychiatric diseases includingAlzheimer's disease; depression; schizophrenia; etc [1]. The blood oxygenation level-dependent (BOLD) signal of fMRI detects the locations of increased neuro activity bymeasuring the blood oxygen levels at consecutive time points. The higher the temporalcorrelation between two spatially distant regions; the more likely that there is a functionalconnection between those regions. The analysis of rs-fMRI data is a challenging task; due tothe scanner noise; physiological noise; head motion; and subject's random thoughts …,*,2012,1
Rapid image search in a large database,*,A method for searching in a large-scale database of images for images that are visuallysimilar to query images is provided using a processor to perform the following steps:computing visual features for the database images; constructing an Image Anchor Graphthat contains a plurality of anchors corresponding to a subset of images in the database;according to the computed visual features; computing visual features for the query images;and retrieving database images similar to one or more user query images using a rankingalgorithm that uses the anchors in the Image Anchor Graph according to the computedvisual features of both the query images and the database images on the Image AnchorGraph.,*,2012,1
Weakly Supervised Topic Grouping of YouTube Search Results,Liujuan Cao; Rongrong Ji; Wei Liu; Yue Gao; Ling-Yu Duan; Chaoguang Men,Recent years have witnessed an explosive growth of user contributed videos on websiteslike YouTube and Metacafe; which usually provide a query-by-keyword functionality tofacilitate the user browsing. For a given query; the returned videos typically contain multipletopics that are mixed up to duplicate the user browsing. Therefore; their diversification andgrouping are highly demanded to improve the user experiences. However; the tagging andcontent qualities of user contributed videos are uncontrolled against their precise grouping.In this paper; we present a weakly supervised topic grouping paradigm to diversify thereturned videos of a given keyword query. Our grouping is based on the bag-of-words visualsignature quantized over the spatiotemporal STIP descriptor [1] extracted from each returnedvideo. First; we adopt a min-Hashing based visual similarity in combination of the tagging …,IEEE International Conference on Image Processing,2012,1
Channel Assignment Strategies for Cellular Phone Systems,Wei Liu; Yiping Han; Hang Yu,Abstract Nowadays people benefit a lot from mobile communication systems. One of recentmajor breakthroughs in solving the problem of spectral congestion is the cellular concept;which means replacing a large transmitter with many little transmitters; each providingcoverage to a small piece of the service area. Neighboring transmitters are assigneddifferent groups of channels so that the interference between transmitters is minimized. Eachcellular transmitter is assigned a radio channel to be used within a small geographic areacalled a cell. By limiting the coverage area to within the boundaries of a cell; the samechannel may be used to cover different cells that are separated from one another bydistances large enough to keep interference levels within tolerable limits. The designprocess of selecting and allocating channel groups for all of the cellular transmitters in a …,Mathematical Contest in Modeling (MCM),2000,1
CosFace: Large Margin Cosine Loss for Deep Face Recognition,Hao Wang; Yitong Wang; Zheng Zhou; Xing Ji; Dihong Gong; Jingchao Zhou; Zhifeng Li; Wei Liu,Abstract: Face recognition has achieved revolutionary advancement owing to theadvancement of the deep convolutional neural network (CNN). The central task of facerecognition; including face verification and identification; involves face featurediscrimination. However; traditional softmax loss of deep CNN usually lacks the power ofdiscrimination. To address this problem; recently several loss functions such as centralloss\cite {centerloss}; large margin softmax loss\cite {lsoftmax}; and angular softmax loss\cite{sphereface} have been proposed. All these improvement algorithms share the same idea:maximizing inter-class variance and minimizing intra-class variance. In this paper; wedesign a novel loss function; namely large margin cosine loss (LMCL); to realize this ideafrom a different perspective. More specifically; we reformulate the softmax loss as cosine …,IEEE Conference on Computer Vision and Pattern Recognition (CVPR),2018,*
Zero-Shot Visual Recognition using Semantics-Preserving Adversarial Embedding Network,Long Chen; Hanwang Zhang; Jun Xiao; Wei Liu; Shih-Fu Chang,Abstract: We propose a novel framework called Semantics-Preserving AdversarialEmbedding Network (SP-AEN) for zero-shot visual recognition (ZSL); where test images andtheir classes are both unseen during training. SP-AEN aims to tackle the inherent problem---semantic loss---in the prevailing family of embedding-based ZSL; where some semanticswould be discarded during training if they are non-discriminative for training classes; butinformative for test classes. Specifically; SP-AEN prevents the semantic loss by introducingan independent visual-to-semantic space embedder which disentangles the semantic spaceinto two subspaces for the two arguably conflicting objectives: classification andreconstruction. Through adversarial learning of the two subspaces; SP-AEN can transfer thesemantics from the reconstructive subspace to the discriminative one; accomplishing the …,IEEE Conference on Computer Vision and Pattern Recognition (CVPR),2018,*
Fine-grained Video Attractiveness Prediction Using Multimodal Deep Learning on a Large Real-world Dataset,Xinpeng Chen; Jingyuan Chen; Lin Ma; Jian Yao; Wei Liu; Jiebo Luo; Tong Zhang,*,The Web Conference (WWW); The Big Web Track,2018,*
Neural Stereoscopic Image Style Transfer,Xinyu Gong; Haozhi Huang; Lin Ma; Fumin Shen; Wei Liu,Abstract: Neural style transfer is an emerging technique which is able to endow daily-lifeimages with attractive artistic styles. Previous work has succeeded in applying convolutionalneural network (CNN) to style transfer for monocular images or videos. However; styletransfer for stereoscopic images is still a missing piece. Different from processing amonocular image; the two views of a stylized stereoscopic pair are required to be consistentto provide the observer a comfortable visual experience. In this paper; we propose a dualpath network for view-consistent style transfer on stereoscopic images. While each view ofthe stereoscopic pair is processed in an individual path; a novel feature aggregation strategyis proposed to effectively share information between the two paths. Besides a traditionalperceptual loss used for controlling style transfer quality in each view; a multi-layer view …,arXiv preprint arXiv:1802.09985,2018,*
Learning to Guide Decoding for Image Captioning,Wenhao Jiang; Lin Ma; Hanwang Zhang; Xinpeng Chen; Wei Liu,*,AAAI Conference on Artificial Intelligence (AAAI),2018,*
Stochastic Non-convex Ordinal Embedding with Stabilized Barzilai-Borwein Step Size,Ke Ma; Jinshan Zeng; Jiechao Xiong; Qianqian Xu; Xiaochun Cao; Wei Liu; Yuan Yao,Abstract: Learning representation from relative similarity comparisons; often called ordinalembedding; gains rising attention in recent years. Most of the existing methods are batchmethods designed mainly based on the convex optimization; say; the projected gradientdescent method. However; they are generally time-consuming due to that the singular valuedecomposition (SVD) is commonly adopted during the update; especially when the data sizeis very large. To overcome this challenge; we propose a stochastic algorithm called SVRG-SBB; which has the following features:(a) SVD-free via dropping convexity; with goodscalability by the use of stochastic algorithm; ie; stochastic variance reduced gradient(SVRG); and (b) adaptive step size choice via introducing a new stabilized Barzilai-Borwein(SBB) method as the original version for convex problems might fail for the considered …,AAAI Conference on Artificial Intelligence (AAAI),2018,*
NDDR-CNN: Layer-wise Feature Fusing in Multi-Task CNN by Neural Discriminative Dimensionality Reduction,Yuan Gao; Qi She; Jiayi Ma; Mingbo Zhao; Wei Liu; Alan L Yuille,Abstract: State-of-the-art Convolutional Neural Network (CNN) benefits a lot from multi-tasklearning (MTL); which learns multiple related tasks simultaneously to obtain shared ormutually related representations for different tasks. The most widely-used MTL CNNstructure is based on an empirical or heuristic split on a specific layer (eg; the lastconvolutional layer) to minimize different task-specific losses. However; this heuristicsharing/splitting strategy may be harmful to the final performance of one or multiple tasks. Inthis paper; we propose a novel CNN structure for MTL; which enables automatic featurefusing at every layer. Specifically; we first concatenate features from different tasks accordingto their channel dimension; and then formulate the feature fusing problem as discriminativedimensionality reduction. We show that this discriminative dimensionality reduction can …,arXiv preprint arXiv:1801.08297,2018,*
DeepProduct: Mobile Product Search with Portable Deep Features,Yu-Gang Jiang; Minjun Li; Xi Wang; Wei Liu; Xian-Sheng Hua,*,ACM Transactions on Multimedia Computing; Communications; and Applications,2018,*
Shared Predictive Cross-Modal Deep Quantization,Erkun Yang; Cheng Deng; Chao Li; Wei Liu; Jie Li; Dacheng Tao,*,IEEE Transactions on Neural Networks and Learning Systems,2018,*
Mixture-Rank Matrix Approximation for Collaborative Filtering,Dongsheng Li; Chao Chen; Wei Liu; Tun Lu; Ning Gu; Stephen Chu,Abstract Low-rank matrix approximation (LRMA) methods have achieved excellent accuracyamong today's collaborative filtering (CF) methods. In existing LRMA methods; the rank ofuser/item feature matrices is typically fixed; ie; the same rank is adopted to describe allusers/items. However; our studies show that submatrices with different ranks could coexist inthe same user-item rating matrix; so that approximations with fixed ranks cannot perfectlydescribe the internal structures of the rating matrix; therefore leading to inferiorrecommendation accuracy. In this paper; a mixture-rank matrix approximation (MRMA)method is proposed; in which user-item ratings can be characterized by a mixture of LRMAmodels with different ranks. Meanwhile; a learning algorithm capitalizing on iteratedcondition modes is proposed to tackle the non-convex optimization problem pertaining to …,Advances in Neural Information Processing Systems (NIPS),2017,*
Improving Event Extraction via Multimodal Integration,Tongtao Zhang; Spencer Whitehead; Hanwang Zhang; Hongzhi Li; Joseph Ellis; Lifu Huang; Wei Liu; Heng Ji; Shih-Fu Chang,Abstract In this paper; we focus on improving Event Extraction (EE) by incorporating visualknowledge with words and phrases from text documents. We first discover visual patternsfrom large-scale text-image pairs in a weakly-supervised manner and then propose amultimodal event extraction algorithm where the event extractor is jointly trained with textualfeatures and visual patterns. Extensive experimental results on benchmark data setsdemonstrate that the proposed multimodal EE method can achieve significantly betterperformance on event extraction: absolute 7.1% F-score gain on event trigger labeling and8.5% F-score gain on event argument labeling.,ACM International Conference on Multimedia (ACM MM),2017,*
GSOS: Gauss-Seidel Operator Splitting Algorithm for Multi-Term Nonsmooth Convex Composite Optimization,Li Shen; Wei Liu; GanZhao Yuan; Shiqian Ma,Abstract In this paper; we propose a fast Gauss-Seidel Operator Splitting (GSOS) algorithmfor addressing multi-term nonsmooth convex composite optimization; which has wideapplications in machine learning; signal processing and statistics. The proposed GSOSalgorithm inherits the advantage of the Gauss-Seidel technique to accelerate theoptimization procedure; and leverages the operator splitting technique to reduce thecomputational complexity. In addition; we develop a new technique to establish the globalconvergence of the GSOS algorithm. To be specific; we first reformulate the iterations ofGSOS as a two-step iterations algorithm by employing the tool of operator optimizationtheory. Subsequently; we establish the convergence of GSOS based on the two-stepiterations algorithm reformulation. At last; we apply the proposed GSOS algorithm to solve …,International Conference on Machine Learning (ICML),2017,*
Theoretic Analysis and Extremely Easy Algorithms for Domain Adaptive Feature Learning,Wenhao Jiang; Cheng Deng; Wei Liu; Feiping Nie; Fu-lai Chung; Heng Huang,Abstract Domain adaptation problems arise in a variety of applications; where a trainingdataset from the source domain and a test dataset from the target domain typically followdifferent distributions. The primary difficulty in designing effective learning models to solvesuch problems lies in how to bridge the gap between the source and target distributions. Inthis paper; we provide comprehensive analysis of feature learning algorithms used inconjunction with linear classifiers for domain adaptation. Our analysis shows that in order toachieve good adaptation performance; the second moments of the source domaindistribution and target domain distribution should be similar. Based on our new analysis; anovel extremely easy feature learning algorithm for domain adaptation is proposed.Furthermore; our algorithm is extended by leveraging multiple layers; leading to a deep …,International Joint Conference on Artificial Intelligence (IJCAI),2017,*
Diverse Image Annotation,Baoyuan Wu; Fan Jia; Wei Liu; Bernard Ghanem,Abstract In this work; we study a new image annotation task called diverse image annotation(DIA). Its goal is to describe an image using a limited number of tags; whereby the retrievedtags need to cover as much useful information about the image as possible. As compared tothe conventional image annotation task; DIA requires the tags to be not only representativeof the image but also diverse from each other; so as to reduce redundancy. To this end; wetreat DIA as a subset selection problem; based on the conditional determinantal pointprocess (DPP) model; which encodes representation and diversity jointly. We further exploresemantic hierarchy and synonyms among candidate tags to define weighted semantic paths.It is encouraged that two tags with the same semantic path are not retrieved simultaneouslyfor the same image. This restriction is embedded into the algorithm used to sample from …,Proceedings of IEEE Conference on Computer Vision and Pattern Recognition (CVPR),2017,*
End-to-end Active Object Tracking via Reinforcement Learning,Wenhan Luo; Peng Sun; Yadong Mu; Wei Liu,Abstract: In this paper we propose an active object tracking approach; which provides atracking solution simultaneously addressing tracking and camera control. Crucially; thesetwo tasks are tackled in an end-to-end manner via reinforcement learning. Specifically; aConvNet-LSTM function approximator is adopted; which takes as input only visualobservations (ie; frame sequences) and directly outputs camera motions (eg; move forward;turn left; etc.). The tracker; regarded as an agent; is trained with the A3C algorithm; where weharness an environment augmentation technique and a customized rewarding function toencourage robust object tracking. We carry out experiments on the AI research platformViZDoom. The yielded tracker can automatically pay attention to the most likely object in theinitial frame and perform tracking subsequently; not requiring a manual bounding box as …,arXiv preprint arXiv:1705.10561,2017,*
Detecting Faces Using Inside Cascaded Contextual CNN,Kaipeng Zhang; Zhanpeng Zhang; Hao Wang; Zhifeng Li; Yu Qiao; Wei Liu,Abstract Deep Convolutional Neural Networks (CNNs) achieve substantial improvements inface detection in the wild. Classical CNN-based face detection methods simply stacksuccessive layers of filters where an input sample should pass through all layers beforereaching a face/non-face decision. Inspired by the fact that for face detection; filters indeeper layers can discriminate between difficult face/nonface samples while those inshallower layers can efficiently reject simple non-face samples; we propose InsideCascaded Structure that introduces face/non-face classifiers at different layers within thesame CNN. In the training phase; we propose data routing mechanism which enablesdifferent layers to be trained by different types of samples; and thus deeper layers can focuson handling more difficult samples compared with traditional architecture. In addition; we …,Proceedings of the IEEE International Conference on Computer Vision (ICCV),2017,*
Sub-Selective Quantization for Learning Binary Code in Large-Scale Image Search,Yeqing Li; Wei Liu; Junzhou Huang,Recently with the explosive growth of visual content on the Internet; large-scale imagesearch has attracted intensive attention. It has been shown that mapping high-dimensionalimage descriptors to compact binary codes can lead to considerable efficiency gains in bothstorage and in performing similarity computation of images. However; most existing methodsstill suffer from expensive training devoted to large-scale binary code learning. To addressthis issue; we propose a sub-selection based matrix manipulation algorithm; which cansignificantly reduce the computational cost of code learning. As case studies; we apply thesub-selection algorithm to several popular quantization techniques including cases usinglinear and nonlinear mapping. Crucially; we can justify the resulting sub-selectivequantization by proving its theoretic properties. Extensive experiments were carried out …,IEEE Transactions on Pattern Analysis and Machine Intelligence (TPAMI),2017,*
Reversed Spectral Hashing,Qingshan Liu; Guangcan Liu; Lai Li; Xiaotong Yuan; Meng Wang; Wei Liu,Hashing is emerging as a powerful tool for building highly efficient indices in large-scalesearch systems. In this paper; we study spectral hashing (SH); which is a classical method ofunsupervised hashing. In general; SH solves for the hash codes by minimizing an objectivefunction that tries to preserve the similarity structure of the data given. Althoughcomputationally simple; very often SH performs unsatisfactorily and lags distinctly behind thestate-of-the-art methods. We observe that the inferior performance of SH is mainly due to itsimperfect formulation; that is; the optimization of the minimization problem in SH actuallycannot ensure that the similarity structure of the high-dimensional data is really preserved inthe low-dimensional hash code space. In this paper; we; therefore; introduce reversed SH(ReSH); which is SH with its input and output interchanged. Unlike SH; which estimates …,IEEE Transactions on Neural Networks and Learning Systems,2017,*
Supplementary Material of Tensor Robust Principal Component Analysis: Exact Recovery of Corrupted Low-Rank Tensors via Convex Optimization,Canyi Lu; Jiashi Feng; Yudong Chen; Wei Liu; Zhouchen Lin; Shuicheng Yan,This document gives the detailed proof of Theorem 3.1 in the manuscript. Section 2 givessome other notations and properties which will be used in the proofs. Section 3 provides away for the construction of the solution to the TRPCA problem; and Section 4 proves that theconstructed solution is exact to the TRPCA problem. Section 5 gives the proofs of somelemmas which are used in Section 4.,A∗= A,2016,*
Visual Tracking via Reliable Memories,Shu Wang; Shaoting Zhang; Wei Liu; Dimitris N Metaxas,Abstract: In this paper; we propose a novel visual tracking framework that intelligentlydiscovers reliable patterns from a wide range of video to resist drift error for long-termtracking tasks. First; we design a Discrete Fourier Transform (DFT) based tracker which isable to exploit a large number of tracked samples while still ensures real-time performance.Second; we propose a clustering method with temporal constraints to explore and memorizeconsistent patterns from previous frames; named as reliable memories. By virtue of thismethod; our tracker can utilize uncontaminated information to alleviate drifting issues.Experimental results show that our tracker performs favorably against other state of-the-artmethods on benchmark datasets. Furthermore; it is significantly competent in handling driftsand able to robustly track challenging long videos over 4000 frames; while most of others …,Proceedings of the Twenty-Fifth International Joint Conference on Artificial Intelligence (IJCAI),2016,*
Modeling Inter- and Intra-Part Deformations for Object Structure Parsing,Ling Cai; Rongrong Ji; Wei Liu; Gang Hua,Abstract Part deformation has been a longstanding challenge for object parsing; of which theprimary difficulty lies in modeling the highly diverse object structures. To this end; wepropose a novel structure parsing model to capture deformable object structures. Theproposed model consists of two deformable layers: the top layer is an undirected graph thatincorporates inter-part deformations to infer object structures; the base layer is consisted ofvarious independent nodes to characterize local intra-part deformations. To learn this two-layer model; we design a layer-wise learning algorithm; which employs matching pursuitand belief propagation for a low computational complexity inference. Specifically; activebasis sparse coding is leveraged to build the nodes at the base layer; while the edgeweights are estimated by a structural support vector machine. Experimental results on two …,Proceedings of the 24th International Joint Conference on Artificial Intelligence (IJCAI),2015,*
Saliency Propagation from Simple to Difficult (Supplementary Material),Chen Gong; Dacheng Tao; Wei Liu; SJ Maybank; Meng Fang; Keren Fu; Jie Yang,When the iteration proceeds; the size l of labeled set L will grow larger and larger; soinverting the l× l matrix KL; L (KL; L is the sub-matrix of K corresponding to L) at scratchunder each iteration is very inefficient. Here we tackle this computational issue byincrementally updating K− 1 L; L based on the previous inverting result. As our submission;T is used to denote the curriculum set with size q; and KT; L; KL; T; KL; L are sub-matrices ofthe kernel matrix K indexed by the associated subscripts. After one iteration; the kernelmatrix on the labeled set is updated by,*,2015,*
Hashing by Deep Learning,Wei Liu,*,Proceedings of the IEEE,2015,*
Optimizing Bag Features for Multiple-Instance Retrieval,Zhouyu Fu; Feifei Pan; Cheng Deng; Wei Liu,Abstract Multiple-Instance (MI) learning is an important supervised learning technique whichdeals with collections of instances called bags. While existing research in MI learning mainlyfocused on classification; in this paper we propose a new approach for MI retrieval to enableeffective similarity retrieval of bags of instances; where training data is presented in the formof similar and dissimilar bag pairs. An embedded scheme is devised as encoding each baginto a single bag feature vector by exploiting a similarity-based transformation. In this way;the original MI problem is converted into a single-instance version. Furthermore; we developa principled approach for optimizing bag features specific to similarity retrieval throughleveraging pairwise label information at the bag level. The experimental results demonstratethe effectiveness of the proposed approach in comparison with the alternatives for MI …,Proceedings of The Twenty-Ninth AAAI Conference on Artificial Intelligence (AAAI),2015,*
Learning to Rank Binary Codes,Feng Jie; Wei Liu; Yan Wang,*,http://arxiv.org/abs/1410.5524,2014,*
Supplementary Materials: Histopathological Image Analysis via Active Learning,Yan Zhu; Wei Liu; Shaoting Zhang; Dimitris N Metaxas,Lemma 1.(from Lemma 3 in [1]) Let V={1;...; n}; Y be finite sets; f: 2V× Y→ N monotonic andsubmodular; and P (YV) such that (f; P) is adaptive submodular. Let A1; A2;...; Am⊆ V; anddefine for i∈{1;...; m}; Zi=[Yj1;...; jl] where Ai={j1;...; jl}; and l is a constant integer. Let W={1;...;m} and Q (ZW) be the distribution over Z1; Z2;...; Zm induced by P. Let Y= Ji∈ W range (Zi).Define the function γ: 2W× Y→ 2V× Y; γ ({(a1; z1);...;(at; zt)})= t,*,2014,*
Zeta Hull Pursuits: Learning Nonconvex Data Hulls Supplementary Material,Yuanjun Xiong; Wei Liu; Deli Zhao; Xiaoou Tang,† Information Engineering Department; The Chinese University of Hong Kong; Hong Kong ‡IBM TJ Watson Research Center; Yorktown Heights; New York; USA ♯ Advanced AlgorithmResearch Group; HTC; Beijing; China {yjxiong;xtang}@ie.cuhk.edu.hk weiliu@us.ibm.com delizhao@htc.com … Theorem 1. Let I be the identity matrix and ρ(W) be the spectral radius of thematrix W; respec- tively. If 0 <z< 1/ρ(W); then ζz(G)=1/ det(I - zW) … Proof. By definition; νl andW are related as … W is W = QΛQ−1 ; where the diagonal matrix Λ = diag(λ1;...;λn). Then wehave … Theorem 2. Given ϵG and ϵG/xj as in Theorem 1; the point extremeness measure εxjof point xj satisfies εxj = (I - zW) −1 (jj) ; ie; the point extremeness measure of point xj is equalto the j-th diagonal entry of the matrix (I - zW) −1 … Proof. By Theorem 1; the structural complexityof the remaining graph; ϵG/xj ; has the determinant form ϵG/xj = 1/ det(I - zWjj); where …,*,2014,*
Supplemental Material for “Discrete Graph Hashing”,Wei Liu; Cun Mu; Sanjiv Kumar; Shih-Fu Chang,Proof. Since the B-subproblem in Eq. (5) of the main paper is to maximize a continuous functionover a compact (ie; closed and bounded) set; its optimal objective function value f∗ is finite. AsB(j) is feasible for each j; the sequence {f(B(j))} is bounded from above … By definition;ˆfj(B(j)) ≡ f(B(j)). Since B(j+1) … ∈ arg maxB∈{±1}n×r ˆfj(B); we have … ˆfj(B(j+1)) ≥ ˆfj(B(j)).Also; as A is positive semidefinite; f(B) is a convex function. Therefore; f(B) ≥ ˆfj(B) at any B ∈{1; −1}n×r; which implies that f(B(j+1)) ≥ ˆfj(B(j+1)). Putting all the above together; we havef(B(j+1)) ≥ ˆfj(B(j+1)) ≥ ˆfj(B(j)) = f(B(j)); ∀j ∈ Z; j ≥ 0 … Together with the fact that {f(B(j))}is bounded from above; it turns out that the monotonically non-decreasing sequence {f(B(j))}converges … The convergence of {B(j)} is established based on the following three keyfacts … First; if B(j+1) = B(j); then due to the update in Eq. (7) of the main paper; we …,*,2014,*
Supplemental Material for “Can Visual Recognition Benefit from Auxiliary Information in Training?”,Qilin Zhang; Gang Hua; Wei Liu; Zicheng Liu; Zhengyou Zhang,In this section; we present the proof of the Proposition 1 for Paper 498. First; the existence ofthe upper bound is proven in Section 1.1; then the proof that the sequence f (W (s)); s= 1; 2;···is monotonic is presented in Section 1.2. With the Bolzano-Weierstrass theorem and theconclusions of Section 1.1 and Section 1.2; the Proposition 1 is proven.,*,2014,*
Supervised Hashing with Kernels Supervised Hashing with Kernels,Wei Liu Columbia Jun Wang; Wei Liu; Rongrong Ji; Yu-Gang Jiang; Shih Fu Chang; Shih-Fu Chang,Page 1. Supervised Hashing with Kernels Supervised Hashing with Kernels Wei Liu (Columbia)Jun Wang (IBM) Wei Liu (Columbia); Jun Wang (IBM); Rongrong Ji (Columbia); Yu-Gang Jiang(Fudan); and Shih Fu Chang (Columbia) and Shih-Fu Chang (Columbia) June; 2012 Page 2.Outline • Motivations • Motivations • Problem • Our Approach • Experiments • Conclusions CVPR2012 2 Page 3. Fast Nearest Neighbor Search • Exhaustive search ( time) is inefficient. CVPR2012 3 Page 4. Tree Based Indexing Tree-Based Indexing • O(log n) search time O(log n) searchtime. • Impractical for high dimensionality. tree KD-tree CVPR 2012 4 Page 5. Locality SensitiveHashing Locality-Sensitive Hashing [Gionis; Indyk; and Motwani 1999] [Datar et al. 2004] •Sublinear search time for –approximate NN. • Long hash bits (>=1k) and multiple hash tables.0 101 Query 1 Feature Vector 1 hash function 0 1 1 random 1 0 …,*,2012,*
Supplementary Material for “Compact Hyperplane Hashing with Bilinear Functions”,Wei Liu; Jun Wang; Yadong Mu; Sanjiv Kumar; Shih-Fu Chang,Theorem 2 in the main paper introduces the asymptotic complexity of our proposedrandomized bilinear hashing scheme BH-Hash. For self-contained consideration; here weprovide the proof; which is basically following the technique previously used in the proof ofTheorem 1 in (Gionis et al.; 1999). Recall that in Theorem 1 of the main paper; we haveshown that the proposed BH-Hash is (r; r (1+ ǫ); p1; p2)-sensitive. Particularly; we show thatp1= 1,*,2012,*
Video-to-Video Online Face Recognition with Conditional Manifold Density,Wei Liu; Jianzhuang Liu,*,International Journal of Electronics; Computing and Engineering Education,2010,*
Adaptive Face Hallucination through Global Statistical Inference and Local Geometry Transfer,Wei Liu; Yiwen Luo; Jianzhuang Liu,*,International Journal of Electronics; Computing and Engineering Education,2010,*
Clustering Time Series,Wei Liu,*,*,2009,*
What If Another Floyd?-Escaping a Hurricane’s Wrath,Hang Yu; Wei Liu; Yiping Han,Abstract The State of South Carolina is very vulnerable to the attack of hurricanes since it isadjacent with the Atlantic Ocean. In 1999 hurricane Floyd led most people living in thecoastal region into a great panic. Take the city of Charleston as an example; 500;000 peoplerushed to Columbia; a safety heaven more than 200 kilometers away; through Interstate I-26.Since I-26 is the principal route going inland from Charleston to Columbia; there happeneda standstill on the I-26. What is normally an easy two-hour drive took up to 18 hours tocomplete. Many cars simply ran out of gas along the way. Fortunately; Floyd turned northand spared the state this time; but the public outcry is forcing state officials to find ways toavoid a repeat of this traffic nightmare. The principal proposal put forth to deal with thisproblem is the reversal of traffic on I-26; so that both sides; including the coastal-bound …,*,2001,*
SSD ARCHITECTURE,Wei Liu; Dragomir Anguelov; Dumitru Erhan; Christian Szegedy; Scott Reed; Cheng-Yang Fu; Alexander C Berg,Method mAP FPS batchsize# Boxes Input res Faster R-CNN (VGG16) 73.2 7 1∼ 6000∼1000× 600 Fast YOLO 52.7 155 1 98 448× 448 YOLO (VGG16) 66.4 21 1 98 448× 448SSD300 74.3 46 1 8732 300× 300 SSD512 76.8 19 1 24564 512× 512 SSD300 74.3 59 88732 300× 300 SSD512 76.8 22 8 24564 512× 512,image,*,*
2015 IEEE International Conference on Computer Vision (ICCV)(2015),Fumin Shen; Wei Liu; Shaoting Zhang; Yang Yang; Heng Tao Shen,*,*,*,*
Supplementary Material: Diverse Image Annotation,Baoyuan Wu; Fan Jia; Wei Liu; Bernard Ghanem,Here we present the results of different methods; evaluated by conventional metrics;including precision (P); recall (R) and F1 score; on ESP Game and IAPRTC-12; as shown inTable 2. ML-MG shows the best performance in all cases; which has also verified in [1]. Incontrast; DPP-S-sampling gives the worst performance in all cases. The obvious reason isMLMG picks the most representative tags in top-k tags; such that more positive tags could beretrieved. In contrast; the diversity encourages DPP-S-sampling to cover tags from differentsemantic paths; such that some negative labels maybe included. However; as shown in themain manuscript; the conventional metrics are much less consistent with human evaluationthan the semantic metrics. data metric→ 3 tags 5 tags method+ PR F1 PR F1,*,*,*
Clustering Time Series: July,Wei Liu,*,*,*,*
