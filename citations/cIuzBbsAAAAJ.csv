The SAP HANA Database–An Architecture Overview,Franz Färber; Norman May; Wolfgang Lehner; Philipp Große; Ingo Müller; Hannes Rauhe; Jonathan Dees,Abstract Requirements of enterprise applications have become much more demanding.They require the computation of complex reports on transactional data while thousands ofusers may read or update records of the same data. The goal of the SAP HANA database isthe integration of transactional and analytical workload within the same databasemanagement system. To achieve this; a columnar engine exploits modern hardware(multiple CPU cores; large main memory; and caches); compression of database content;maximum parallelization in the database kernel; and database extensions required byenterprise applications; eg; specialized data structures for hierarchies or support for domainspecific languages. In this paper we highlight the architectural concepts employed in theSAP HANA database. We also report on insights gathered with the SAP HANA database …,Data Engineering Bulletin,2012,191
Towards a unified service description language for the internet of services: Requirements and first developments,Jorge Cardoso; Alistair Barros; Norman May; Uwe Kylau,Service-oriented Architectures (SOA) and Web services leverage the technical value ofsolutions in the areas of distributed systems and cross-enterprise integration. Theemergence of Internet marketplaces for business services is driving the need to describeservices; not only from a technical level; but also from a business and operationalperspective. While; SOA and Web services reside in an IT layer; organizations owingInternet marketplaces are requiring advertising and trading business services which residein a business layer. As a result; the gap between business and IT needs to be closed. Thispaper presents USDL (Unified Service Description Language); a specification language todescribe services from a business; operational and technical perspective. USDL plays amajor role in the Internet of Services to describe tradable services which are advertised in …,Services Computing (SCC); 2010 IEEE International Conference on,2010,150
An idea ontology for innovation management,Christoph Riedl; Norman May; Jan Finzen; Stephan Stathel; Viktor Kaufman; Helmut Krcmar,ABSTRACT Exchanging and analyzing ideas across different software tools and repositoriesis needed to implement the concepts of open innovation and holistic innovationmanagement. However; a precise and formal definition for the concept of an idea is hard toobtain. In this paper; the authors introduce an ontology to represent ideas. This ontologyprovides a common language to foster interoperability between tools and to support the idealife cycle. Through the use of an ontology; additional benefits like semantic reasoning andautomatic analysis become available. Our proposed ontology captures both a core ideaconcept that covers the 'heart of the idea'and further concepts to support collaborative ideadevelopment; including rating; discussing; tagging; and grouping ideas. This modularapproach allows the idea ontology to be complemented by additional concepts like …,Semantic Services; Interoperability and Web Applications: Emerging Concepts,2011,73
Timeline index: A unified data structure for processing queries on temporal data in SAP HANA,Martin Kaufmann; Amin Amiri Manjili; Panagiotis Vagenas; Peter Michael Fischer; Donald Kossmann; Franz Färber; Norman May,Abstract Managing temporal data is becoming increasingly important for many applications.Several database systems already support the time dimension; but provide only fewtemporal operators; which also often exhibit poor performance characteristics. On theacademic side; a large number of algorithms and data structures have been proposed; butthey often address a subset of these temporal operators only. In this paper; we develop theTimeline Index as a novel; unified data structure that efficiently supports temporal operatorssuch as temporal aggregation; time travel; and temporal joins. As the Timeline Index isindependent of the physical order of the data; it provides flexibility in physical design; eg; itsupports any kind of compression scheme; which is crucial for main memory column stores.Our experiments show that the Timeline Index has predictable performance and beats …,Proceedings of the 2013 ACM SIGMOD International Conference on Management of Data,2013,56
Nested Queries and Quantifiers in an Ordered Context,Norman May; Sven Helmer; Guido Moerkotte,We present algebraic equivalences that allow to unnest nested algebraic expressions fororder-preserving algebraic operators. We illustrate how these equivalences can be appliedsuccessfully to unnest nested queries given in the XQuery language. Measurementsillustrate the performance gains possible by unnesting.,technical report,2004,54
Strategies for query unnesting in XML databases,Norman May; Sven Helmer; Guido Moerkotte,Abstract Queries formulated in a nested way are very common in XQuery. Unfortunately;their evaluation is usually very inefficient when done in a straightforward fashion. Wepresent a framework for handling nested queries that is based on unnesting the queries afterhaving translated them into an algebra. We not only present a collection of algebraicequivalences; but also supply a strategy on how to use them effectively. The full potential ofthe approach is demonstrated by applying our rewrites to actual queries and showing thatperformance gains of several orders of magnitude are possible.,ACM Transactions on Database Systems (TODS),2006,43
Managing service innovations with an idea ontology,Christoph Riedl; Norman May; Jan Finzen; Stephan Stathel; Torsten Leidig; Viktor Kaufman; Roxana Belecheanu; Helmut Krcmar,As the importance of the service sector increases; so does the importance of systematicapproaches to develop new services. Two key activities in service innovation are generationand evaluation of new service ideas. Exchanging and analysing ideas across differentsoftware tools and repositories is needed to implement the concepts of open innovation andholistic innovation management. In this paper; we introduce an ontology to represent ideasfor service innovations. The Idea Ontology provides a common language to fosterinteroperability between tools and to support the idea life cycle. The paper focuses on howsuch an ontology-based approach can be used to facilitate innovation management in theservice domain where special aspects of services impair innovation. The expected benefitsof a semantic approach such as semantic reasoning and automatic analysis of ideas are …,Proceedings of XIX International RESER Conference,2009,28
High-Performance Transaction Processing in SAP HANA.,Juchang Lee; Michael Muehle; Norman May; Franz Faerber; Vishal Sikka; Hasso Plattner; Jens Krueger; Martin Grund,Abstract Modern enterprise applications are currently undergoing a complete paradigm shiftaway from traditional transactional processing to combined analytical and transactionalprocessing. This challenge of combining two opposing query types in a single databasemanagement system results in additional requirements for transaction management as well.In this paper; we discuss our approach to achieve high throughput for transactional queryprocessing while allowing concurrent analytical queries. We present our approach todistributed snapshot isolation and optimized two-phase commit protocols.,IEEE Data Eng. Bull.,2013,27
Service innovation in business value networks,Stephan Stathel; Jan Finzen; Christoph Riedl; Norman May,Les réseaux business value offrent de nouvelles possibilités pour la coopération liée àl'innovation. Cet article présente un nouveau processus d'innovation ainsi qu'un cadre;développés pour le cas d'utilisation Texo1 du projet Theseus2; qui fournissent uneapproche complète et néanmoins flexible permettant de gérer les projets innovants àacteurs multiples dans les écosystèmes économiques. Un des objectifs principaux du cadreproposé est d'impliquer des communautés dans les projets innovants; comme cela a étésuggéré par l'idée d'«innovation ouverte».,Proceedings of XVIII international RESER conference,2008,24
XQuery processing in natix with an emphasis on join ordering,Norman May; Sven Helmer; Carl-Christian Kanne; Guido Moerkotte,ABSTRACT We give an overview on how XQuery processing works in our native XMLdatabase system Natix. After a brief description of the query compiler we focus on the aspectof join ordering when generating query execution plans. Here we show that better plans canbe found when extending the search space of the plan generator. 1.,In< XIME− P/>,2004,24
Task scheduling for highly concurrent analytical and transactional main-memory workloads,Iraklis Psaroudakis; Tobias Scheuer; Norman May; Anastasia Ailamaki,ABSTRACT Task scheduling typically employs a worker thread per hardware context toprocess a dynamically changing set of tasks. It is an appealing solution to exploit modernmulti-core processors; as it eases parallelization and avoids unnecessary context switchesand their associated costs. Naıvely bundling DBMS operations into tasks; however; canresult in sub-optimal usage of CPU resources: highly contending transactional workloadsinvolve blocking tasks. Moreover; analytical queries assume they can use all availableresources while issuing tasks; resulting in an excessive number of tasks and anunnecessary associated scheduling overhead. In this paper; we show how to overcomethese problems and exploit the performance benefits of task scheduling for main-memoryDBMS. Firstly; we use application knowledge about blocking tasks to dynamically adapt …,Proceedings of the Fourth International Workshop on Accelerating Data Management Systems Using Modern Processor and Storage Architectures (ADMS 2013),2013,21
Scaling up concurrent main-memory column-store scans: towards adaptive NUMA-aware data and task placement,Iraklis Psaroudakis; Tobias Scheuer; Norman May; Abdelkader Sellami; Anastasia Ailamaki,Abstract Main-memory column-stores are called to efficiently use modern non-uniformmemory access (NUMA) architectures to service concurrent clients on big data. The efficientusage of NUMA architectures depends on the data placement and scheduling strategy of thecolumn-store. Most column-stores choose a static strategy that involves partitioning all dataacross the NUMA architecture; and employing a stealing-based task scheduler. In thispaper; we implement different strategies for data placement and task scheduling for the caseof concurrent scans. We compare these strategies with an extensive sensitivity analysis. Ourmost significant findings include that unnecessary partitioning can hurt throughput by up to70%; and that stealing memory-intensive tasks can hurt throughput by up to 58%. Based onour analysis; we envision a design that adapts the data placement and task scheduling …,Proceedings of the VLDB Endowment,2015,20
Unnesting scalar SQL queries in the presence of disjunction,Matthias Brantner; Norman May; Guido Moerkotte,Optimizing nested queries is an intricate problem. It becomes even harder if in a nestedquery the linking predicate or the correlation predicate occurs disjunctively. We present thefirst unnesting strategy that can effectively deal with such queries. The starting point of ourapproach is to translate SQL into the relational algebra extended by bypass operators. Thenwe present for the first time unnesting equivalences which are valid for algebraicexpressions containing bypass operators. Applying these to the translated queries results inour effective unnesting strategy for nested SQL queries with disjunction. With an extensiveexperimental study (including three commercial DBMSs); we demonstrate the possibleperformance gains of our approach.,Data Engineering; 2007. ICDE 2007. IEEE 23rd International Conference on,2007,18
SQLScript: Efficiently Analyzing Big Enterprise Data in SAP HANA,Carsten Binnig; Norman May; Tobias Mindnich,Abstract: Today; not only Internet companies such as Google; Facebook or Twitter do haveBig Data but also Enterprise Information Systems store an ever growing amount of data(called Big Enterprise Data in this paper). In aclassical SAP system landscape acentral datawarehouse (SAP BW) is used to integrate and analyze all enterprise data. In SAP BW mostof the business logic required for complex analytical tasks (eg; acomplexcurrencyconversion) is implemented in the application layer on top of astandardrelational database. While being independent from the underlying database when usingsuch an architecture; this architecture has twomajor drawbacks when analyzing BigEnterprise Data:(1) algorithms in ABAP do not scale with the amount of data and (2) datashipping is required. To this end; we present anovel programming language called …,15. GI-Fachtagung Datenbanksysteme für Business; Technologie und Web,2013,17
Index vs. navigation in XPath evaluation,Norman May; Matthias Brantner; Alexander Böhm; Carl-Christian Kanne; Guido Moerkotte,Abstract A well-known rule of thumb claims; it is better to scan than to use an index whenmore than 10% of the data are accessed. This rule was formulated for relational databases.But is it still valid for XML queries? In this paper we develop similar rules of thumb for XMLqueries by experimentally comparing different execution strategies; eg using navigation orindices. These rules can be used immediately for heuristic optimization of XML queries; andin the long run; they may serve as a foundation for cost-based query optimization in XQuery.,International XML Database Symposium,2006,17
Scaling up mixed workloads: a battle of data freshness; flexibility; and scheduling,Iraklis Psaroudakis; Florian Wolf; Norman May; Thomas Neumann; Alexander Böhm; Anastasia Ailamaki; Kai-Uwe Sattler,Abstract The common “one size does not fit all” paradigm isolates transactional andanalytical workloads into separate; specialized database systems. Operational data isperiodically replicated to a data warehouse for analytics. Competitiveness of enterprisestoday; however; depends on real-time reporting on operational data; necessitating anintegration of transactional and analytical processing in a single database system. Themixed workload should be able to query and modify common data in a shared schema. Thedatabase needs to provide performance guarantees for transactional workloads; and; at thesame time; efficiently evaluate complex analytical queries. In this paper; we share ouranalysis of the performance of two main-memory databases that support mixed workloads;SAP HANA and HyPer; while evaluating the mixed workload CH-benCHmark. By …,Technology Conference on Performance Evaluation and Benchmarking,2014,16
Tpc-bih: A benchmark for bitemporal databases,Martin Kaufmann; Peter M Fischer; Norman May; Andreas Tonder; Donald Kossmann,Abstract An increasing number of applications such as risk evaluation in banking orinventory management require support for temporal data. After more than a decade ofstandstill; the recent adoption of some bitemporal features in SQL: 2011 has reinvigoratedthe support among commercial database vendors; who incorporate an increasing number ofrelevant bitemporal features. Naturally; assessing the performance and scalability oftemporal data storage and operations is of great concern for potential users. The cost ofkeeping and querying history with novel operations (such as time travel; temporal joins ortemporal aggregations) is not adequately reflected in any existing benchmark. In this paper;we present a benchmark proposal which provides comprehensive coverage of thebitemporal data management. It builds on the solid foundations of TPC-H but extends it …,Technology Conference on Performance Evaluation and Benchmarking,2013,16
Composing services for third-party service delivery,Ingo Weber; Alistair Barros; Norman May; Jörg Hoffmann; Tomasz Kaczmarek,This paper proposes a model-based technique for lowering the entrance barrier for serviceproviders to register services with a marketplace broker; such that the service is rapidlyconfigured to utilize the broker's local service delivery management components.Specifically; it uses process modeling for supporting the execution steps of a service andshows how service delivery functions (eg payment points)“local” to a service broker can becorrectly configured into the process model. By formalizing the different operations in aservice delivery function (like payment or settlement) and their allowable executionsequences (full payments must follow partial payments); including cross-functiondependencies; it shows how through tool support; the non-technical user can quicklyconfigure service delivery functions in a consistent and complete way.,Web Services; 2009. ICWS 2009. IEEE International Conference on,2009,12
Exploiting ordered dictionaries to efficiently construct histograms with q-error guarantees in SAP HANA,Guido Moerkotte; David DeHaan; Norman May; Anisoara Nica; Alexander Boehm,Abstract Histograms that guarantee a maximum multiplicative error (q-error) for estimatesmay significantly improve the plan quality of query optimizers. However; the constructiontime for histograms with maximum q-error was too high for practical use cases. In this paperwe extend this concept with a threshold; ie; an estimate or true cardinality θ; below which wedo not care about the q-error because we still expect optimal plans. This allows us todevelop far more efficient construction algorithms for histograms with bounded error. Thetest for θ; q-acceptability developed also exploits the order-preserving dictionary encoding ofSAP HANA. We have integrated this family of histograms into SAP HANA; and we report onthe construction time; histograms size; and estimation errors on real-world data sets. Invirtually all cases the histograms can be constructed in far less than one second …,Proceedings of the 2014 ACM SIGMOD international conference on Management of data,2014,11
Main Memory Implementations for Binary Grouping,Norman May; Guido Moerkotte,Abstract An increasing number of applications depend on efficient storage and analysisfeatures for XML data. Hence; query optimization and efficient evaluation techniques for theemerging XQuery standard become more and more important. Many XQuery queries requirenested expressions. Unnesting them often introduces binary grouping. We introduce severalalgorithms implementing binary grouping and analyze their time and space complexity.Experiments demonstrate their performance.,technical report,2005,11
Three cases for query decorrelation in XQuery,Norman May; Sven Helmer; Guido Moerkotte,Abstract We present algebraic equivalences that allow to unnest nested algebraicexpressions for order-preserving algebraic operators. We illustrate how these equivalencescan be applied successfully to unnest nested queries given in the XQuery language.Measurements illustrate the performance gains possible our approach.,International XML Database Symposium,2003,11
Parallel execution of parsed query based on a concurrency level corresponding to an average number of available worker threads,*,Systems and method for a task scheduler with dynamic adjustment of concurrency levelsand task granularity are disclosed for improved execution of highly concurrent analytical andtransactional systems. The task scheduler can avoid both over commitment andunderutilization of computing resources by monitoring and controlling the number of activeworker threads. The number of active worker threads can be adapted to avoidunderutilization of computing resources by giving the OS control of additional worker threadsprocessing blocked application tasks. The task scheduler can dynamically determine anumber of parallel operations for a particular task based on the number of available threads.The number of available worker threads can be determined based on the averageavailability of worker threads in the recent history of the application. Based on the number …,*,2016,9
Extending database task schedulers for multi-threaded application code,Florian Wolf; Iraklis Psaroudakis; Norman May; Anastasia Ailamaki; Kai-Uwe Sattler,Abstract Modern databases can run application logic defined in stored procedures inside thedatabase server to improve application speed. The SQL standard specifies how to callexternal stored routines implemented in programming languages; such as C; C++; or JAVA;to complement declarative SQL-based application logic. This is beneficial for scientific andanalytical algorithms because they are usually too complex to be implemented entirely inSQL. At the same time; database applications like matrix calculations or data miningalgorithms benefit from multi-threading to parallelize compute-intensive operations. Multi-threaded application code; however; introduces a resource competition between the threadsof applications and the threads of the database task scheduler. In this paper; we show thatmulti-threaded application code can render the database's workload scheduling …,Proceedings of the 27th International Conference on Scientific and Statistical Database Management,2015,9
Bi-temporal timeline index: A data structure for processing queries on bi-temporal data,Martin Kaufmann; Peter M Fischer; Norman May; Chang Ge; Anil K Goel; Donald Kossmann,Following the adoption of basic temporal features in the SQL: 2011 standard; there has beena tremendous interest within the database industry in supporting bi-temporal features; as asignificant number of real-life workloads would greatly benefit from efficient temporaloperations. However; current implementations of bi-temporal storage systems and operatorsare far from optimal. In this paper; we present the Bi-temporal Timeline Index; whichsupports a broad range of temporal operators and exploits the special properties of an in-memory column store database system. Comprehensive performance experiments with theTPC-BiH benchmark show that algorithms based on the Bi-temporal Timeline Indexoutperform significantly both existing commercial database systems and state-of-the-art datastructures from research.,Data Engineering (ICDE); 2015 IEEE 31st International Conference on,2015,9
Benchmarking Bitemporal Database Systems: Ready for the Future or Stuck in the Past?,Martin Kaufmann; Peter M Fischer; Norman May; Donald Kossmann,ABSTRACT After more than a decade of a virtual standstill; the adoption of temporal datamanagement features has recently picked up speed; driven by customer demand and theinclusion of temporal expressions into SQL: 2011. Most of the big commercial DBMS nowinclude support for bitemporal data and operators. In this paper; we perform a thoroughanalysis of these commercial temporal DBMS: We investigate their architecture; determinetheir performance and study the impact of performance tuning. This analysis utilizes ourrecent (TPCTC 2013) benchmark proposal; which includes a comprehensive temporalworkload definition. The results of our analysis show that the support for temporal data is stillin its infancy: All systems store their data in regular; statically partitioned tables and rely onstandard indexes as well as query rewrites for their operations. As shown by our …,EDBT,2014,9
Distributed snapshot isolation: global transactions pay globally; local transactions pay locally,Carsten Binnig; Stefan Hildenbrand; Franz Färber; Donald Kossmann; Juchang Lee; Norman May,Abstract Modern database systems employ Snapshot Isolation to implement concurrencycontrol and isolationbecause it promises superior query performance compared to lock-based alternatives. Furthermore; Snapshot Isolation never blocks readers; which is animportant property for modern information systems; which have mixed workloads of heavyOLAP queries and short update transactions. This paper revisits the problem ofimplementing Snapshot Isolation in a distributed database system and makes threeimportant contributions. First; a complete definition of Distributed Snapshot Isolation is given;thereby extending existing definitions from the literature. Based on this definition; a set ofcriteria is proposed to efficiently implement Snapshot Isolation in a distributed system.Second; the design space of alternative methods to implement Distributed Snapshot …,The VLDB Journal,2014,8
DeltaNI: An efficient labeling scheme for versioned hierarchical data,Jan Finis; Robert Brunel; Alfons Kemper; Thomas Neumann; Franz Färber; Norman May,Abstract Main-memory database systems are emerging as the new backbone of businessapplications. Besides flat relational data representations also hierarchical ones are essentialfor these modern applications; therefore we devise a new indexing and versioning approachfor hierarchies that is deeply integrated into the relational kernel. We propose the DeltaNIindex as a versioned pendant of the nested intervals (NI) labeling scheme. The index isspace-and time-efficient and yields a gapless; fixed-size integer NI labeling for each versionwhile also supporting branching histories. In contrast to a naive NI labeling; it facilitates evencomplex updates of the tree structure. As many query processing techniques that work ontop of the NI labeling have already been proposed; our index can be used as a buildingblock for processing various kinds of queries. We evaluate the performance of the index …,Proceedings of the 2013 ACM SIGMOD International Conference on Management of Data,2013,8
Execution-level process modeling,*,A system includes a semantic process validator that includes a state construction componentthat is configured to collect state information for an instance of a process model; a parallelitychecker that is configured to determine a set of one or more process tasks within theinstance of the process model that may be executed in parallel to a selected task; and avalidation coordinator that is configured to coordinate requests to the state constructioncomponent and to the parallelity checker. The system includes a process modeling tool thatincludes a goal creator that is configured to construct a constraint set for the selected taskusing the set of process tasks; where the selected task has a goal. The system includes atask composer that is configured to find one or more services to fulfill the goal for theselected task using the constraint set.,*,2009,8
System and method of performing snapshot isolation in distributed databases,*,A system and method of performing snapshot isolation in distributed databases. Each nodestores local snapshot information that enforces snapshot isolation for that node. The methodincludes partially processing a distributed transaction by a first node; receiving a globalcommit identifier from a coordinator; and continuing to process the distributed transaction; bythe first node and a second node; in accordance with the global commit identifier.,*,2015,7
SAP HANA–From Relational OLAP Database to Big Data Infrastructure,Norman May; Wolfgang Lehner; Shahul Hameed; Nitesh Maheshwari; Carsten Müller; Sudipto Chowdhuri; Anil Goel,ABSTRACT SAP HANA started as one of the best-performing database engines for OLAPworkloads strictly pursuing a main-memory centric architecture and exploiting hardwaredevelopments like large number of cores and main memories in the TByte range. Within thispaper; we outline the steps from a traditional relational database engine to a Big Datainfrastructure comprising different methods to handle data of different volume; coming in withdifferent velocity; and showing a fairly large degree of variety. In order to make thepresentation of this transformation process more tangible; we discuss two major technicaltopics–HANA native integration points as well as extension points for collaboration withHadoop-based data management infrastructures. The overall of goal of this paper is to (a)review current application patterns and resulting technical challenges as well as to (b) …,EDBT,2015,7
Benchmarking Databases with History Support,Martin Kaufmann; Peter M Fischer; Norman May; Donald Kossmann,An increasing number of applications such as risk evaluation in banking or inventorymanagement require support for temporal data. After more than a decade of standstill; therecent adoption of some bitemporal features in SQL: 2011 has reinvigorated the supportamong commercial database vendors; who incorporate an increasing number of relevantbitemporal features. Naturally; assessing the performance and scalability of temporal datastorage and operations is of great concern for potential users. The cost of keeping andquerying history with novel operations (such as time travel; temporal joins or temporalaggregations) is not adequately reflected in any existing benchmark. In this paper; wepresent a benchmark proposal which provides comprehensive coverage of the bitemporaldata management. It builds on the solid foundations of TPC-H but extends it with a rich set …,*,2013,7
Towards an automated gap analysis for e-Service portfolios,Norman May; Ulrich Scholten; Robin Fischer,Intermediaries for e-services continuously gain momentum; powered by a materializingInternet of Services. However; quality of service still exhibits considerable shortcomings; asno structured process to enhance consumer satisfaction is available yet. To improve thematch of delivered e-service quality and expected service quality on the consumer side; wedevelop a portfolio optimization process that integrates both; the consumer's as well as theintermediary's perspective. First; we introduce a toolkit for an e-service oriented gapanalysis. Thereupon; we identify monitoring points to measure service quality gapsautomatically. A subsequent aggregation of measured data into customized feedbackinformation allows for applying the toolkit to continuously optimize e-service portfolios.Instantiated in the AGORA e-service market; we conclude with a report on our recent …,Services Computing (SCC); 2011 IEEE International Conference on,2011,7
Unified Service Description Language (USDL)—Service Module,Alistair Barros; Christian Baumann; Anis Charfi; Matthias Flügge; Steffen Heinzl; Tom Kiemes; Uwe Kylau; Florian Marienfeld; Norman May; Oliver Müller; Francesco Novelli; Daniel Oberle; Jonas Pattberg; Philip Robinson; Benjamin Schmeling; Wolfgang Theilmann; Heiko Witteborg; Jan Finzen; Andrea Horch; Maximilien Kintz,*,SAP Research; SAP Research,2011,7
Quantifiers in XQuery,Norman May; Sven Helmer; Guido Moerkotte,We present algebraic equivalences that allow to unnest nested algebraic expressionscontaining quantifiers for order-preserving algebraic operators. We illustrate how theseequivalences can be applied successfully to unnest nested queries formulated in XQuery.Measurements illustrate the performance gains possible by unnesting.,WISE,2003,7
Patterns for emerging application integration scenarios: A survey,Daniel Ritter; Norman May; Stefanie Rinderle-Ma,Abstract The discipline of enterprise application integration (EAI) enables the decoupledcommunication between (business) applications; and thus became a cornerstone of today'sIT architectures. In 2004; the book by Hohpe and Woolf on Enterprise Integration Patterns(EIP) provided a fundamental collection of messaging patterns; denoting the building blocksof many EAI system implementations. Since then; multiple new trends and a broad range ofnew application scenarios have emerged; eg; cloud and mobile computing; multimediastreams. These developments ultimately lead to conceptual changes and challenges suchas larger data volumes (ie; message sizes); a growing number of messages (ie; velocity)and communication partners; and even more diverse message formats (ie; variety).However; the research since 2004 focused on isolated EAI solutions; and thus a broader …,*,2017,6
Adaptive NUMA-aware data placement and task scheduling for analytical workloads in main-memory column-stores,Iraklis Psaroudakis; Tobias Scheuer; Norman May; Abdelkader Sellami; Anastasia Ailamaki,Abstract Non-uniform memory access (NUMA) architectures pose numerous performancechallenges for main-memory column-stores in scaling up analytics on modern multi-socketmulti-core servers. A NUMA-aware execution engine needs a strategy for data placementand task scheduling that prefers fast local memory accesses over remote memory accesses;and avoids an imbalance of resource utilization; both CPU and memory bandwidth; acrosssockets. State-of-the-art systems typically use a static strategy that always partitions dataacross sockets; and always allows inter-socket task stealing. In this paper; we show thatadapting data placement and task stealing to the workload can improve throughput by up toa factor of 4 compared to a static approach. We focus on highly concurrent workloadsdominated by operators working on a single table or table group (copartitioned tables) …,Proceedings of the VLDB Endowment,2016,6
Benchmarking integration pattern implementations,Daniel Ritter; Norman May; Kai Sachs; Stefanie Rinderle-Ma,The integration of a growing number of distributed; heterogeneous applications is one of themain challenges of enterprise data management. Through the advent of cloud and mobileapplication integration; higher volumes of messages have to be processed; compared tocommon enterprise computing scenarios; while guaranteeing high throughput. However; noprevious study has analyzed the impact on message throughput for Enterprise IntegrationPatterns (EIPs)(eg; channel creation; routing and transformation). Acknowledging this void;we propose EIPBench; a comprehensive micro-benchmark design for evaluating themessage throughput of frequently implemented EIPs and message delivery semantics inproductive cloud scenarios. For that; these scenarios are collected and described in aprocess-driven; TPC-C-like taxonomy; from which the most relevant patterns; message …,*,2016,6
Supporting Hierarchical Data in SAP HANA,Robert Brunel; Jan Finis; Gerald Franz; Norman May; Alfons Kemper; Thomas Neumann; Franz Faerber,Managing hierarchies is an ever-recurring challenge for relational database systems.Through investigations of customer scenarios at SAP we found that today's RDBMSs stillleave a lot to be desired in order to meet the requirements of typical applications. Ourresearch puts a new twist on handling hierarchies in SQL-based systems. We present anapproach for modeling hierarchical data natively; and we extend the SQL language withexpressive constructs for creating; manipulating; and querying a hierarchy. The constructscan be evaluated efficiently by leveraging existing indexing and query processingtechniques. We demonstrate the feasibility of our concepts with initial measurements on aHANA-based prototype.,PVLDB,2015,6
Information gathering for semantic service discovery and composition in business process modeling,Norman May; Ingo Weber,Abstract When creating an execution-level process model today; two crucial problems arehow to find the right services (service discovery and composition); and how to make surethey are in the right order (semantic process validation). While isolated solutions for bothproblems exist; a unified approach has not yet been available. Our approach resolves thisshortcoming by gathering all existing information in the process; thus making the basis ofsemantic service discovery and task composition both broader and more targeted. Therebywe achieve the following benefits:(i) less modeling overhead for semantic annotations to theprocess;(ii) more information regarding the applicability of services; and (iii) early avoidanceof inconsistencies in the interrelation between all process parts. Consequently; new orchanged business processes can be realized in IT more efficiently and with fewer errors …,*,2008,6
Advanced Analytics with the SAP HANA Database,Philipp Große; Wolfgang Lehner; Norman May,Abstract: MapReduce as a programming paradigm provides a simple-to-use yet verypowerful abstraction encapsulated in two second-order functions: Map and Reduce. Assuch; they allow defining single sequentially processed tasks while at the same time hidingmany of the framework details about how those tasks are parallelized and scaled out. In thispaper we discuss four processing patterns in the context of the distributed SAP HANAdatabase that go beyond the classic MapReduce paradigm. We illustrate them using sometypical Machine Learning algorithms and present experimental results that demonstrate howthe data flows scale out with the number of parallel tasks.,DATA,2013,5
A Generic Database Benchmarking Service,Martin Kaufmann; Peter M Fischer; Donald Kossmann; Norman May,Benchmarks are widely applied for the development and optimization of database systems.Standard benchmarks such as TPC-C and TPC-H provide a way of comparing theperformance of different systems. In addition; micro benchmarks can be exploited to test aspecific behavior of a system. Yet; despite all the benefits that can be derived frombenchmark results; the effort of implementing and executing benchmarks remainsprohibitive: Database systems need to be set up; a large number of artifacts such as datagenerators and queries need to be managed and complex; time-consuming operations haveto be orchestrated. In this demo; we introduce a generic benchmarking service thatcombines a rich meta model; low marginal cost and ease of use; which drastically reducesthe time and cost to define; adapt and run a benchmark.,IEEE 29th International Conference on Data Engienering (ICDE),2013,5
Supply Chain Control building on Emergent Self-Organizing Effects,Ulrich Scholten; Robin Fischer; Dimitar Bojkov; Norman May,Abstract This paper sheds light on control mechanisms to improve and automate servicequality respectively service portfolio management in platform ecosystems. Its focus is placedon e-service value networks as found in platforms such as the Apple App Store; Facebook;Salesforce or SAP ByD. The paper differentiates between direct and indirect controlmechanisms and explains how they can be embedded within feedback controlled systems.Informative and Motivational Control mechanisms act on the macro level; indirectlyinfluencing a whole system or subsystem towards a specific target. Sanctional andRestrictive Control in conjunction with Co-Regulative Control act on the micro level anddirectly influence specific services. Market Regulative Control indirectly influences specificservices. The paper suggests and formalizes possible sequences to implement control …,Supply Management Research,2011,5
Methods and systems for one dimensional heterogeneous histograms,*,A method and system to generate cardinality estimates for at least one query execution planfor a query using a histogram; the cardinality estimation being constrained by a q-error thatis a factor by which the estimate deviates; at most; from a true value of the cardinality and athreshold value which the cardinality does not exceed; use the cardinality estimation todetermine an optimal query plan for executing the query; and produce an output of theoptimal query plan.,*,2015,4
Indexing highly dynamic hierarchical data,Jan Finis; Robert Brunel; Alfons Kemper; Thomas Neumann; Norman May; Franz Faerber,Abstract Maintaining and querying hierarchical data in a relational database system is animportant task in many business applications. This task is especially challenging whenconsidering dynamic use cases with a high rate of complex; possibly skewed structuralupdates. Labeling schemes are widely considered the indexing technique of choice forhierarchical data; and many different schemes have been proposed. However; they cannothandle dynamic use cases well due to various problems which we investigate in this paper.We therefore propose our dynamic Order Indexes; which offer competitive queryperformance; unprecedented update efficiency; and robustness for highly dynamicworkloads.,Proceedings of the VLDB Endowment,2015,4
Efficient XQuery evaluation of grouping conditions with duplicate removals,Norman May; Guido Moerkotte,Abstract Currently; grouping in XQuery must be expressed implicitly with nested FLWORexpressions. With XQuery 1.1; an explicit group by clause will be part of this query language.As users integrate this new construct into their applications; it becomes important to haveefficient evaluation techniques available to process even complex grouping conditions.Among them; the removal of distinct values or distinct nodes in the partitions defined by thegroup by clause is not well-supported yet. The evaluation technique proposed in this paperis able to handle duplicate removal in the partitions efficiently. Experiments show thesuperiority of our solution compared to state-of-the-art query processing.,International XML Database Symposium,2007,4
Managed Query Processing within the SAP HANA Database Platform,Norman May; Alexander Böhm; Meinolf Block; Wolfgang Lehner,Abstract The SAP HANA database extends the scope of traditional database engines as itsupports data models beyond regular tables; eg text; graphs or hierarchies. Moreover; SAPHANA also provides developers with a more fine-grained control to define their databaseapplication logic; eg exposing specific operators which are difficult to express in SQL.Finally; the SAP HANA database implements efficient communication to dedicated clientapplications using more effective communication mechanisms than available with standardinterfaces like JDBC or ODBC. These features of the HANA database are complemented bythe extended scripting engine–an application server for server-side JavaScript applications–that is tightly integrated into the query processing and application lifecycle management. Asa result; the HANA platform offers more concise models and code for working with the …,Datenbank-Spektrum,2015,3
A study of partitioning and parallel UDF execution with the SAP HANA database,Philipp Große; Norman May; Wolfgang Lehner,Abstract Large-scale data analysis relies on custom code both for preparing the data foranalysis as well as for the core analysis algorithms. The map-reduce framework offers asimple model to parallelize custom code; but it does not integrate well with relationaldatabases. Likewise; the literature on optimizing queries in relational databases has largelyignored user-defined functions (UDFs). In this paper; we discuss annotations for user-defined functions that facilitate optimizations that both consider relational operators andUDFs. In this paper we focus on optimizations that enable the parallel execution of relationaloperators and UDFs for a number of typical patterns. A study on real-world data investigatesthe opportunities for parallelization of complex data flows containing both relationaloperators and UDFs.,Proceedings of the 26th International Conference on Scientific and Statistical Database Management,2014,3
Hardware accelerated application integration processing: Industry paper,Daniel Ritter; Jonas Dann; Norman May; Stefanie Rinderle-Ma,Abstract The growing number of (cloud) applications and devices massively increases thecommunication rate and volume pushing integration systems to their (throughput) limits.While the usage of modern hardware like Field Programmable Gate Arrays (FPGAs) led tolow latency when employed for query and event processing; application integration adds yetunexplored processing opportunities. In this industry paper; we explore how to programintegration semantics (eg; message routing and transformation) in form of EnterpriseIntegration Patterns (EIP) on top of an FPGA; thus complementing the existing research onFPGA data processing. We focus on message routing; re-define the EIP for streamprocessing and propose modular hardware implementations as templates that aresynthesized to circuits. For our real-world" connected car" scenario (ie; composed …,Proceedings of the 11th ACM International Conference on Distributed and Event-based Systems,2017,2
Order Indexes: supporting highly dynamic hierarchical data in relational main-memory database systems,Jan Finis; Robert Brunel; Alfons Kemper; Thomas Neumann; Norman May; Franz Faerber,Abstract Maintaining and querying hierarchical data in a relational database system is animportant task in many business applications. This task is especially challenging whenconsidering dynamic use cases with a high rate of complex; possibly skewed structuralupdates. Labeling schemes are widely considered the indexing technique of choice forhierarchical data; and many different schemes have been proposed. However; they cannothandle dynamic use cases well due to various problems; which we investigate in this paper.We therefore propose Order Indexes—a dynamic representation of the nested intervalsencoding—which offer competitive query performance; unprecedented update efficiency;and robustness for highly dynamic workloads.,The VLDB Journal,2017,2
SAP HANA–The Evolution of an In-Memory DBMS from Pure OLAP Processing Towards Mixed Workloads,Norman May; Alexander Böhm; Wolfgang Lehner,The journey of SAP HANA started as an in-memory appliance for complex; analyticalapplications. The success of the system quickly motivated SAP to broaden the scope fromthe OLAP workloads the system was initially architected for to also handle transactionalworkloads; in particular to support its Business Suite flagship product. In this paper; wehighlight some of the core design changes to evolve an in-memory column store systemtowards handling OLTP workloads. We also discuss the challenges of running mixedworkloads with low-latency OLTP queries and complex analytical queries in the context ofthe same database management system and give an outlook on the future databaseinteraction patterns of modern business applications we see emerging currently.,BTW,2017,2
Optimization of parallelization of user-defined functions with flexible partitioning,*,Technologies are disclosed for generating query execution plans optimized for parallelexecution for programs having both core database relational functions and user-definedfunctions. A variety of optimization strategies can be employed to improve performance in aparallel execution scenarios. A flexible range of permitted partition arrangements can bespecified as acceptable to parallelized instances of the user-defined function. The optimizercan leverage such information when constructing an optimized query execution plan.Partitioning arrangements or other properties can be leveraged to avoid additional orunnecessary processing.,*,2016,2
Transactional-consistent cache for database objects,*,A system and method for providing a transactional-consistent cache for database objects isdisclosed. New data is received by a cache manager. The cache manager updates an entryof a cache with the new data received by the cache manager; by registering the updating ofthe entry with the new data with an invalidator. The registering includes a timestamp. Aninvalidation event is then generated by the invalidator. The invalidation event includes anotification about the updating of the entry of the cache with the new data received by thecache manager according to the timestamp.,*,2015,2
Caching views on historical data,*,In a general aspect; a computer-implemented method for executing a query on a table of adatabase; where the table has multiple partitions; can include receiving a query requesting aview on the table. The view on the table can be based on data included in a partition of themultiple partitions of the table. The method can also include determining a cached result tothe query is not available in the database and generating a result to the query from; at least;the data of the partition of the multiple partitions. After the generating; the method caninclude building a cache including the result to the query; associating a transaction identifierfor the query with the result to the query result in the cache; and returning the result to thequery.,*,2016,1
Task Scheduling for Highly Concurrent Analytical and Transaction Workloads,*,Systems and method for a task scheduler with dynamic adjustment of concurrency levelsand task granularity are disclosed for improved execution of highly concurrent analytical andtransactional systems. The task scheduler can avoid both over commitment andunderutilization of computing resources by monitoring and controlling the number of activeworker threads. The number of active worker threads can be adapted to avoidunderutilization of computing resources by giving the OS control of additional worker threadsprocessing blocked application tasks. The task scheduler can dynamically determine anumber of parallel operations for a particular task based on the number of available threads.The number of available worker threads can be determined based on the averageavailability of worker threads in the recent history of the application. Based on the number …,*,2016,1
Annotations for parallelization of user-defined functions with flexible partitioning,*,Annotations can be placed in source code to indicate properties for user-defined functions. Awide variety of properties can be implemented to provide information that can be leveragedwhen constructing a query execution plan for the user-defined function and associated coredatabase relational operations. A flexible range of permitted partition arrangements can bespecified via the annotations. Other supported properties include expected sorting andgrouping arrangements; ensured post-conditions; and behavior of the user-defined function.,*,2015,1
From Static to Agile-Interactive Particle Physics Analysis in the SAP HANA DB,David Kernert; Norman May; Michael Hladik; Klaus Werner; Wolfgang Lehner,Abstract: In order to confirm their theoretical assumptions; physicists employ Monte-Carlogenerators to produce millions of simulated particle collision events and compare them withthe results of the detector experiments. The traditional; static analysis workflow of physicistsinvolves creating and compiling a C++ program for each study; and loading large data filesfor every run of their program. To make this process more interactive and agile; we createdan application that loads the data into the relational in-memory column store DBMS SAPHANA; exposes raw particle data as database views and offers an interactive web interfaceto explore this data. We expressed common particle physics analysis algorithms using SQLqueries to benefit from the inherent scalability and parallelization of the DBMS. In this paperwe compare the two approaches; ie manual analysis with C++ programs and interactive …,Proceedings of 4th International Conference on Data Management Technologies and Applications (DATA),2015,1
Normalization and Translation of XQuery,Norman May; Guido Moerkotte,ABSTRACT Early approaches to XQueryprocessing proposed proprietary techniques tooptimize and evaluate XQuery statements. In this chapter; the authors argue for an algebraicoptimization and evaluation technique for XQuery as it allows us to benefit from experiencegained with relational databases. An algebraic XQuery processing method requires atranslation into an algebra representation. While many publications already exist onalgebraic optimizations and evaluation techniques for XQuery; an assessment of translationtechniques is required. Consequently; they give a comprehensive survey for translatingXQuery into various query representations. The authors relate these approaches to the waynormalization and translation is implemented in Natix and discuss these two steps in detail.In their experience; their translation method is a good basis for further optimizations and …,Advanced Applications and Structures in XML Processing: Label Streams; Semantics Utilization and Data Query Technologies. Hershey: Igi Global Publishing,2010,1
Innovation in the Internet of Services,Jan Finzen; Christoph Riedl; Norman May; Stephan Stathel,Le projet TEXO; un des six scénarios d'application du programme de recherche THESEUS;a pour but de développer une infrastructure pour l'Internet des services en s' appuyant surtrois paradigmes: 1) une architecture orientée services (SOA); 2) le Web sémantique et 3) leWeb 2.0. Nous proposons que les logiciels facilitant l'innovation en matière de servicesutilisent ces trois aspects pour être déployés et utilisés facilement au sein de l'Internet desservices. Dans cet article; nous présentons des caractéristiques clé des servicesélectroniques et leurs implications concernant le processus d'innovation en matière deservices. Nous présentons le cadre d'innovation pour les services (service innovationframework) développé et utilisé dans le projet TEXO et décrivons les logiciels constituant cecadre.,RESER,2010,1
Querying embedded RDF with XML Technology-A Feasibility Study,Norman May; Heiner Stuckenschmidt,*,XML Tage 2007 in Berlin: 24.-26. September 2007 in Berlin;[Tagungsband],2007,1
An Algebraic Approach to XQuery Optimization,Norman May,Abstract: As more data is stored in XML and more applications need to process this data;XML query optimization becomes performance critical. While optimization techniques forrelational databases have been developed over the last thirty years; the optimization of XMLqueries poses new challenges. Query optimizers for XQuery; the standard query languagefor XML data; need to consider both document order and sequence order. Nevertheless;algebraic optimization proved powerful in query optimizers in relational and object orienteddatabases. Thus; this dissertation presents an algebraic approach to XQuery optimization. Inthis thesis; an algebra over sequences is presented that allows for a simple translation ofXQuery into this algebra. The formal definitions of the operators in this algebra allow us toreason formally about algebraic optimizations. This thesis leverages the power of this …,*,2007,1
Hierarchical Window Database Query Execution,*,Abstract Addressed herein is the problem of expressing and evaluating computations onhierarchies represented as database tables. Engine support for such computations is verylimited today; and so they are usually outsourced into stored procedures or client code.Structural grouping is applied to relational algebra to provide concise syntax to express aclass of useful computations. Algorithms are also provided to evaluate such structuralgroupings efficiently by exploiting available indexing schemes. Related apparatus; systems;techniques and articles are also described.,*,2018,*
Hierarchical Data Grouping in Main-Memory Relational Databases,*,Abstract Addressed herein is the problem of expressing and evaluating computations onhierarchies represented as database tables. Engine support for such computations is verylimited today; and so they are usually outsourced into stored procedures or client code.Structural grouping is applied to relational algebra to provide concise syntax to express aclass of useful computations. Algorithms are also provided to evaluate such structuralgroupings efficiently by exploiting available indexing schemes. Related apparatus; systems;techniques and articles are also described.,*,2018,*
Interleaving with coroutines: a practical approach for robust index joins,Georgios Psaropoulos; Thomas Legler; Norman May; Anastasia Ailamaki,ABSTRACT Index join performance is determined by the efficiency of the lookup operationon the involved index. Although database indexes are highly optimized to leverageprocessor caches; main memory accesses inevitably increase lookup runtime when theindex outsizes the last-level cache; hence; index join performance drops. Still; robust indexjoin performance becomes possible with instruction stream interleaving: given a group oflookups; we can hide cache misses in one lookup with instructions from other lookups byswitching among their respective instruction streams upon a cache miss. In this paper; wepropose interleaving with coroutines for any type of index join. We showcase our proposalon SAP HANA by implementing binary search and CSB+-tree traversal for an instance ofindex join related to dictionary compression. Coroutine implementations not only perform …,Proceedings of the VLDB Endowment,2017,*
Timeline index for managing temporal data,*,Embodiments described herein generally relate to creating a timeline index for executingqueries on temporal data. A computer-implemented method is described. The methodincludes creating a first list of tuples that are invalidated in a temporal table and sorting thefirst list of the invalidated tuples. The method can further include creating a second list oftuples that are activated in the temporal table and combining the first list and the second listinto a third list that includes the activated tuples and the invalidated tuples; wherein the thirdlist contains ROW_IDs of both the activated tuples and the invalidated tuples.,*,2017,*
Methods and systems for estimating the number of points in two-dimensional data,*,A method; medium; and system to generate cardinality estimates for at least one queryexecution plan for a query by representing a given set of multidimensional data including aplurality of data points having a value by a hierarchical tree data structure including nodes;each node representing a distribution of a subset of the points in the data set and beingpartitioned into tiles; calculating a bounding rectangle of the data points in each node;entering all non-empty tiles into a queue; processing of the queue can continue until acomputational memory space limit is reached or until a desired estimation resolution is met;and encoding the resulting tree structure.,*,2017,*
Transactional cache invalidation for inter-node caching,*,Disclosed herein are system; method; and computer program product embodiments forefficiently providing transaction-consistent snapshots of data stored in or associated with adatabase stored within a database management system. An embodiment operates byreceiving; at a source database; an update request to update a table at the source databaseand transmitting a message to a cache node to invalidate a copy of a table time stampassociated with the table; where the copy of the table time stamp is stored at the cache node.The embodiment continues by updating the table at the source database based on theupdate request.,*,2017,*
Atomic visibility switch for transactional cache invalidation,*,Disclosed herein are system; method; and computer program product embodiments forefficiently providing transaction-consistent snapshots of data stored in or associated with adatabase stored within a database management system. An embodiment operates byreceiving; at a source database; an update request to update data associated with a tablestored at the source database. The embodiment continues by modifying a value of amodification-in-progress data structure corresponding to the table to indicate that amodification is in progress for the table; and that cached data associated with the table isinvalid while the modification is in progress for the table and performing the table updatebased; at least; on information received in the update request. The embodiment furthercontinues by updating a value of a commit identification counter; and subsequently a …,*,2017,*
Query hints for caching and replication,*,A method may include receiving a query for data to be provided by a database server;wherein the query includes an indication of a maximum lag. The method may further includedetermining whether a hint is available to apply to the query; wherein the hint affects anexecution of the query. When no hint is available; a baseline database server may beselected to be the database server. When the hint is available; a replication server or acache server may be selected to be the database server based on the hint and the maximumlag. The query may be processed at the selected database server.,*,2017,*
Using statistics for database partition pruning on correlated columns,*,A system includes a database having one or more tables having multiple partitions. Thedatabase includes memory modules to store the multiple partitions; a query processor; adata manipulation language (DML) processor configured to process operations tomanipulate data in one or more of the partitions and a statistics module. For each partition;the statistics module maintains a partition profile and stores the partition profile in a statisticscache. The partition profile includes at least a first interval of data range values per columnfor one or more columns. The statistics module updates at least the first interval of a partitionprofile for a partition with new data range values responsive to the DML processorprocessing an operation to manipulate data in the partition. The database includes apartition pruning module that is configured to include partitions responsive to a received …,*,2017,*
Adaptive table placement in numa architectures,*,Techniques and solutions are provided for performing adaptive database table placement ina non-uniform memory access (NUMA) architecture. The adaptive table placement canoccur in response to changing workloads on the NUMA nodes. For example; if a particularNUMA node is saturated; a database table may be moved from the memory of the saturatedNUMA node to the memory of another NUMA node that is underutilized. In some cases; anentire database table is moved; while in other cases the database table is partitioned andonly part of the table is moved.,*,2017,*
JexLog: a sonar for the abyss,Tobias Scheuer; Norman May; Alexander Böhm; Daniel Scheibli,Abstract Today's hardware architectures provide an ever-increasing number of CPU coresthat can be used for running concurrent operations. A big challenge is to ensure that theseoperations are properly synchronized and make efficient use of the available resources.Fellow database researchers have appropriately described this problem as" staring into theabyss" of complexity [12]; where reasoning about the interplay of jobs on a thousand coresbecomes extremely challenging. In this demonstration; we show how a new tool; JexLog;can help to visually analyze concurrent jobs in system software and how it is used tooptimize for modern hardware.,Proceedings of the VLDB Endowment,2016,*
Index-assisted hierarchical computations in main-memory RDBMS,Robert Brunel; Norman May; Alfons Kemper,Abstract We address the problem of expressing and evaluating computations on hierarchiesrepresented as database tables. Engine support for such computations is very limited today;and so they are usually outsourced into stored procedures or client code. Recently; datamodel and SQL language extensions were proposed to conveniently represent and workwith hierarchies. On that basis we introduce a concept of structural grouping to relationalalgebra; provide concise syntax to express a class of useful computations; and discussalgorithms to evaluate them efficiently by exploiting available indexing schemes. Thisextends the versatility of RDBMS towards a great many use cases dealing with hierarchicaldata.,Proceedings of the VLDB Endowment,2016,*
Timeline index for partitioned temporal database tables,*,Partitioning of temporal databases can implement distributed storage of temporal data viatime-based or space-based techniques to improve performance of operators on thedatabase. A variety of operators can be supported for the partitioned tables; includingtemporal aggregation; time travel; and temporal join. The use of checkpoints can greatlyincrease performance in a variety of scenarios. The described partitioning techniques canbe applied in a parallel execution context to great benefit. The partitioning can also reducelocal memory footprint; facilitating in-memory database processing.,*,2016,*
Cached Views,*,Embodiments relate to view caching techniques that cache for a limited time; some of the(intermediate) results of a previous query execution; in order to avoid expensive re-computation of query results. Particular embodiments may utilize a cache manager todetermine whether information relevant to a subsequent user request can be satisfied by anexisting cache instance or view; or whether creation of an additional cache instance isappropriate. At design time; cache defining columns of a view are defined; with user inputparameters automatically being cache defining. Cache instances are created for each tupleof literals for the cache defining columns; and for each explicit or implicit group by clause.Certain embodiments may feature enhanced reuse between cache instances; in order tolimit memory footprint. Over time a cache instances may be evicted from memory based …,*,2015,*
Time slider operator for temporal data aggregation,*,Calculation of aggregated values in a history database table can be optimized using anapproach in which an ordered history table is accessed. The ordered history table caninclude a sequential listing of commit identifiers associated with updates; insertions; and/ordeletions to values in the database table. The ordered history table can be traversed in asingle pass to calculate an aggregation function using an optimized algorithm. Theoptimized algorithm can enable calculation of an aggregated metric of the values based ona selected method for tracking invalidated values to their corresponding commit identifiers.The calculated metric is generated for a current version of the database table; and promoted.,*,2014,*
Method and system for database benchmarking,*,A method and system to define a plurality of benchmark component types; each of thebenchmark component types being a meta model defining the benchmark component type;generate instances of the plurality of benchmark component types; define parametersassociated with the plurality of benchmark component types; and combine one or more ofthe instances of the plurality of benchmark component types and the defined parametersassociated with the benchmark component types being combined.,*,2014,*
Modeling Foundations,Steffen Heinzl; Uwe Kylau; Norman May,Abstract One of the basic purposes of USDL is to provide a “commercial envelope” around aservice for exposition in Web-based service networks (ie; the Internet of Services). Besidesthe description of pricing; licensing; functionality; behavior; service levels; and securityaspects; there remain the following fundamental facets: the interweaving of all the aspects;the modeling of basic concepts such as service; composite service; or bundles; and theinformation about participants in the delivery of the service. These concepts are reflected inthe modules introduced in this chapter: the Service Module and the Participants Module.These two modules are complemented by the Foundation which covers aspects that areused in multiple other modules. This chapter presents the module design taking into accountthe influence of the state of the art and several of the general language requirements as …,*,2012,*
Natix Visual Interfaces,Alexander Böhm; Matthias Brantner; Carl-Christian Kanne; Norman May; Guido Moerkotte,The Natix Project [3] was among the first to realize the idea of a native XML Data Store(XDS); which supports XML process- ing down to the deep levels of storage and query executionengine. Such native XDSs are now also being introduced by major database vendors [1]. NatixVersion 2.0 pro- vides most features of a native; enterprise- class XDS to applicationprogrammers; eg ACID transactions; efficient processing of XPath 1.0; and a rich set of APIs.Fig. 1 shows the modules contained in the Natix C++ library. Applications use Natix' schemamanage- ment facilities to organize their persistent XML data collections. The topmost organizationalunit is the Natix instance. Sys- tem parameters; such as main memory buffer sizes; areinstance-specific. Both trans- action and crash recovery operate at the instance level.Therefore; all operations of a particular transaction must be executed within the context of …,Advances in Database Technology-EDBT 2006,2006,*
