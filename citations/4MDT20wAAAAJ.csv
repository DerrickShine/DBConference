YAGO2: A spatially and temporally enhanced knowledge base from Wikipedia,Johannes Hoffart; Fabian M Suchanek; Klaus Berberich; Gerhard Weikum,Abstract We present YAGO2; an extension of the YAGO knowledge base; in which entities;facts; and events are anchored in both time and space. YAGO2 is built automatically fromWikipedia; GeoNames; and WordNet. It contains 447 million facts about 9.8 million entities.Human evaluation confirmed an accuracy of 95% of the facts in YAGO2. In this paper; wepresent the extraction methodology; the integration of the spatio-temporal dimension; andour knowledge representation SPOTL; an extension of the original SPO-triple model to timeand space.,Artificial Intelligence,2013,744
YAGO2: exploring and querying world knowledge in time; space; context; and many languages,Johannes Hoffart; Fabian M Suchanek; Klaus Berberich; Edwin Lewis-Kelham; Gerard De Melo; Gerhard Weikum,Abstract We present YAGO2; an extension of the YAGO knowledge base with focus ontemporal and spatial knowledge. It is automatically built from Wikipedia; GeoNames; andWordNet; and contains nearly 10 million entities and events; as well as 80 million factsrepresenting general world knowledge. An enhanced data representation introduces timeand location as first-class citizens. The wealth of spatio-temporal information in YAGO canbe explored either graphically or through a special time-and space-aware query language.,Proceedings of the 20th International Conference on World Wide Web (WWW 2011),2011,278
A language modeling approach for temporal information needs,Klaus Berberich; Srikanta Bedathur; Omar Alonso; Gerhard Weikum,Abstract This work addresses information needs that have a temporal dimension conveyedby a temporal expression in the user's query. Temporal expressions such as “in the 1990s”are frequent; easily extractable; but not leveraged by existing retrieval models. Onechallenge when dealing with them is their inherent uncertainty. It is often unclear whichexact time interval a temporal expression refers to. We integrate temporal expressions into alanguage modeling approach; thus making them first-class citizens of the retrieval modeland considering their inherent uncertainty. Experiments on the New York Times AnnotatedCorpus using Amazon Mechanical Turk to collect queries and obtain relevanceassessments demonstrate that our approach yields substantial improvements in retrievaleffectiveness.,*,2010,165
Natural language questions for the Web of data,Mohamed Yahya; Klaus Berberich; Shady Elbassuoni; Maya Ramanath; Volker Tresp; Gerhard Weikum,Abstract The Linked Data initiative comprises structured databases in the Semantic-Webdata model RDF. Exploring this heterogeneous data by structured query languages istedious and error-prone even for skilled users. To ease the task; this paper presents amethodology for translating natural language questions into structured SPARQL queriesover linked-data sources. Our method is based on an integer linear program to solve severaldisambiguation tasks jointly: the segmentation of questions into phrases; the mapping ofphrases to semantic entities; classes; and relations; and the construction of SPARQL triplepatterns. Our solution harnesses the rich type system provided by knowledge bases in theweb of linked data; to constrain our semantic-coherence objective function. We presentexperiments on both the question translation and the resulting query answering.,Proceedings of the 2012 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning (EMNLP 2012),2012,142
A Time Machine for Text Search,Klaus Berberich; Srikanta Bedathur; Thomas Neumann; Gerhard Weikum,Abstract Text search over temporally versioned document collections such as web archiveshas received little attention as a research problem. As a consequence; there is no scalableand principled solution to search such a collection as of a specified time. In this work; weaddress this shortcoming and propose an efficient solution for time-travel text search byextending the inverted file index to make it ready for temporal search. We introduceapproximate temporal coalescing as a tunable method to reduce the index size withoutsignificantly affecting the quality of results. In order to further improve the performance oftime-travel queries; we introduce two principled techniques to trade off index size for itsperformance. These techniques can be formulated as optimization problems that can besolved to near-optimality. Finally; our approach is evaluated in a comprehensive series of …,Proceedings of the 30th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval (SIGIR 2007),2007,113
T-Rank: Time-Aware Authority Ranking,Klaus Berberich; Michalis Vazirgiannis; Gerhard Weikum,Abstract Analyzing the link structure of the web for deriving a page's authority and impliedimportance has deeply affected the way information providers create and link content; theranking in web search engines; and the users' access behavior. Due to the enormousdynamics of the web; with millions of pages created; updated; deleted; and linked to everyday; timeliness of web pages and links is a crucial factor for their evaluation. Users areinterested in important pages (ie; pages with high authority score) but are equally interestedin the recency of information. Time–and thus the freshness of web content and link structure–emanates as a factor that should be taken into account in link analysis when computing theimportance of a page. So far only minor effort has been spent on the integration of temporalaspects into link analysis techniques. In this paper we introduce T-Rank; a link analysis …,Proceedings of the Third International Workshop on Algorithms and Models for the Web-Graph (WAW 2004),2004,60
Time-Aware Authority Ranking,Klaus Berberich; Michalis Vazirgiannis; Gerhard Weikum,The link structure of the web is analyzed to measure the authority of pages; which can betaken into account for ranking query results. Due to the enormous dynamics of the web; withmillions of pages created; updated; deleted; and linked to every day; temporal aspects ofweb pages and links are crucial factors for their evaluation. Users are interested in importantpages (ie; pages with high authority score) but are equally interested in the recency ofinformation. Time—and thus the freshness of web content and link structure—emanates as afactor that should be taken into account in link analysis when computing the importance of apage. So far only minor effort has been spent on the integration of temporal aspects into link-analysis techniques. In this paper we introduce T-Rank Light and T-Rank; two link-analysisapproaches that take into account the temporal aspects freshness (ie; timestamps of most …,Internet Mathematics,2005,55
Robust Question Answering over the Web of Linked Data,Mohamed Yahya; Klaus Berberich; Shady Elbassuoni; Gerhard Weikum,Abstract Knowledge bases and the Web of Linked Data have become important assets forsearch; recommendation; and analytics. Natural-language questions are a user-friendlymode of tapping this wealth of knowledge and data. However; question answeringtechnology does not work robustly in this setting as questions have to be translated intostructured queries and users have to be careful in phrasing their questions. This paperadvocates a new approach that allows questions to be partially translated into relaxedqueries; covering the essential but not necessarily all aspects of the user's input. Tocompensate for the omissions; we exploit textual sources associated with entities andrelational facts. Our system translates user questions into an extended form of structuredSPARQL queries; with text predicates attached to triple patterns. Our solution is based on …,Proceedings of the 22nd ACM International Conference on Information and Knowledge Management (CIKM 2013),2013,54
Mind the Gap: Large-Scale Frequent Sequence Mining,Iris Miliaraki; Klaus Berberich; Rainer Gemulla; Spyros Zoupanos,Abstract Frequent sequence mining is one of the fundamental building blocks in datamining. While the problem has been extensively studied; few of the available techniques aresufficiently scalable to handle datasets with billions of sequences; such large-scale datasetsarise; for instance; in text mining and session analysis. In this paper; we propose MG-FSM; ascalable algorithm for frequent sequence mining on MapReduce. MG-FSM can handle so-called" gap constraints"; which can be used to limit the output to a controlled set of frequentsequences. At its heart; MG-FSM partitions the input database in a way that allows us tomine each partition independently using any existing frequent sequence mining algorithm.We introduce the notion of w-equivalency; which is a generalization of the notion of a"projected database" used by many frequent pattern mining algorithms. We also present a …,Proceedings of the ACM SIGMOD International Conference on Management of Data (SIGMOD 2013),2013,43
Deep answers for naturally asked questions on the web of data,Mohamed Yahya; Klaus Berberich; Shady Elbassuoni; Maya Ramanath; Volker Tresp; Gerhard Weikum,Abstract We present DEANNA; a framework for natural language question answering overstructured knowledge bases. Given a natural language question; DEANNA translatesquestions into a structured SPARQL query that can be evaluated over knowledge basessuch as Yago; Dbpedia; Freebase; or other Linked Data sources. DEANNA analyzesquestions and maps verbal phrases to relations and noun phrases to either individualentities or semantic classes. Importantly; it judiciously generates variables for target entitiesor classes to express joins between multiple triple patterns. We leverage the semantic typesystem for entities and use constraints in jointly mapping the constituents of the question torelations; classes; and entities. We demonstrate the capabilities and interface of DEANNA;which allows advanced users to influence the translation process and to see how the …,Proceedings of the 21st International Conference on World Wide Web (WWW 2012),2012,38
Bridging the terminology gap in web archive search,Klaus Berberich; Srikanta Bedathur; Mauro Sozio; G Weikum,Page 1. Bridging the Terminology Gap in Web Archive Search Klaus Berberich; Srikanta Bedathur;Mauro Sozio; Gerhard Weikum Max-Planck Institute for Informatics; Saarbrücken; Germany Page2. Bridging the Terminology Gap in Web Archives (Klaus Berberich) ∎ http://www.liwa-project.eu ∎ European Union FP7 project that develops next generation web archiving technologiesPage 3. Bridging the Terminology Gap in Web Archives (Klaus Berberich) Web Archives ∎Archived contents increasingly made available on the Web – Web content increasingly archived ∎Web archives play an important role in providing access and preserving our cultural heritagehttp://archives.timesonline.co.uk Issues since 1785 digitized http://archive.org/web 150B webpages archived since 1996 Page 4. Bridging the Terminology Gap in Web Archives (KlausBerberich) What is the Terminology Gap? ∎ Terminology evolves constantly …,Proceedings of the 12th International Workshop on the Web and Databases (WebDB 2009),2009,36
Time will tell: Leveraging temporal expressions in ir,Irem Arikan; S Bedathur; Klaus Berberich,Abstract Temporal expressions; such as between 1992 and 2000; are frequent across manykinds of documents. Text retrieval; though; treats them as common terms; thus ignoring theirinherent semantics. For queries with a strong temporal component; such as US president1997; this leads to a decrease in retrieval effectiveness; since relevant documents (eg; abiography of Bill Clinton containing the aforementioned temporal expression) can not bereliably matched to the query. We propose a novel approach; based on language models; tomake temporal expressions first-class citizens of the retrieval model. In addition; we presentexperiments that show actual improvements in retrieval effectiveness.,Proceedings of the Second International Conference on Web Search and Web Data Mining (WSDM 2009),2009,32
Durable top-k search in document archives,Leong Hou U; Nikos Mamoulis; Klaus Berberich; Srikanta Bedathur,*,Proceedings of the 2010 International Conference on Management of Data (SIGMOD 2010),2010,31
Location-aware click prediction in mobile local search,Dimitrios Lymberopoulos; Peixiang Zhao; Christian Konig; Klaus Berberich; Jie Liu,Abstract Users increasingly rely on their mobile devices to search; locate and discoverplaces and activities around them while on the go. Their decision process is driven by theinformation displayed on their devices and their current context (eg traffic; driving or walkingetc.). Even though recent research efforts have already examined and demonstrated howdifferent context parameters such as weather; time and personal preferences affect the waymobile users click on local businesses; little has been done to study how the location of theuser affects the click behavior. In this paper we follow a data-driven methodology where weanalyze approximately 2 million local search queries submitted by users across the US; tovisualize and quantify how differently mobile users click across locations. Based on the dataanalysis; we propose new location-aware features for improving local search click …,Proceedings of the 20th ACM International Conference on Information and Knowledge Management (CIKM 2011),2011,30
Index Maintenance for Time-Travel Text Search,Avishek Anand; Srikanta Bedathur; Klaus Berberich; Ralf Schenkel,Abstract Time-travel text search enriches standard text search by temporal predicates; sothat users of web archives can easily retrieve document versions that are consideredrelevant to a given keyword query and existed during a given time interval. Different indexstructures have been proposed to efficiently support time-travel text search. None of them;however; can easily be updated as the Web evolves and new document versions are addedto the web archive. In this work; we describe a novel index structure that efficiently supportstime-travel text search and can be maintained incrementally as new document versions areadded to the web archive. Our solution uses a sharded index organization; bounds thenumber of spuriously read index entries per shard; and can be maintained using small in-memory buffers and append-only operations. We present experiments on two large-scale …,Proceedings of the 35th International ACM SIGIR Conference on Research and Development in Information Retrieval (SIGIR 2012),2012,28
Temporal Diversification of Search Results,Klaus Berberich; Srikanta Bedathur,ABSTRACT We investigate the notion of temporal diversity; bringing together two recentlyactive threads of research; namely temporal ranking and diversification of search results. Anovel method is developed to determine search results consisting of documents that arerelevant to the query and were published at diverse times of interest to the query.Preliminary experiments on twenty years' worth of newspaper articles from The New YorkTimes demonstrate characteristics of our method and compare it against two baselines.,Proceedings of Workshop on Time-aware Information Access (TAIA 2013),2013,24
Temporal Index Sharding for Space-Time Efficiency in Archive Search,Avishek Anand; Srikanta Bedathur; Klaus Berberich; Ralf Schenkel,Abstract Time-travel queries that couple temporal constraints with keyword queries areuseful in searching large-scale archives of time-evolving content such as the web archivesor wikis. Typical approaches for efficient evaluation of these queries involve slicing either theentire collection [20] or individual index lists [10] along the time-axis. Both these methods arenot satisfactory since they sacrifice compactness of index for processing efficiency makingthem either too big or; otherwise; too slow. We present a novel index organization schemethat shards each index list with almost zero increase in index size but still minimizes the costof reading index entries during query processing. Based on the optimal sharding thusbtained; we develop a practically efficient sharding that takes into account the different costsof random and sequential accesses. Our algorithm merges shards from the optimal …,Proceedings of the 34th International ACM SIGIR Conference on Research and Development in Information Retrieval (SIGIR 2011),2011,23
Interesting-phrase mining for ad-hoc text analytics,Srikanta Bedathur; Klaus Berberich; Jens Dittrich; Nikos Mamoulis; Gerhard Weikum,Abstract Large text corpora with news; customer mail and reports; or Web 2.0 contributionsoffer a great potential for enhancing business-intelligence applications. We propose aframework for performing text analytics on such data in a versatile; efficient; and scalablemanner. While much of the prior literature has emphasized mining keywords or tags in blogsor social-tagging communities; we emphasize the analysis of interesting phrases. Theseinclude named entities; important quotations; market slogans; and other multi-word phrasesthat are prominent in a dynamically derived ad-hoc subset of the corpus; eg; being frequentin the subset but relatively infrequent in the overall corpus. We develop preprocessing andindexing methods for phrases; paired with new search techniques for the top-k mostinteresting phrases in ad-hoc subsets of the corpus. Our framework is evaluated using a …,Proceedings of the VLDB Endowment,2010,23
Approximate Information Filtering in Peer-to-Peer Networks,Christian Zimmer; Christos Tryfonopoulos; Klaus Berberich; Manolis Koubarakis; Gerhard Weikum,Abstract Most approaches to information filtering taken so far have the underlying hypothesisof potentially delivering notifications from every information producer to subscribers. Thisexact publish/subscribe model creates an efficiency and scalability bottleneck; and might noteven be desirable in certain applications. The work presented here puts forward MAPS; anovel approach to support approximate information filtering in a peer-to-peer environment.In MAPS a user subscribes to and monitors only carefully selected data sources; andreceives notifications about interesting events from these sources only. This way scalabilityis enhanced by trading recall for lower message traffic. We define the protocols of a peer-to-peer architecture especially designed for approximate information filtering; and introducenew node selection strategies based on time series analysis techniques to improve data …,Proceedings of the 9th International Conference on Web Information Systems Engineering (WISE 2008),2008,23
FluxCapacitor: Efficient Time-Travel Text Search,Klaus Berberich; Srikanta Bedathur; Thomas Neumann; Gerhard Weikum,Abstract An increasing number of temporally versioned text collections is available todaywith Web archives being a prime example. Search on such collections; however; is often notsatisfactory and ignores their temporal dimension completely. Time-travel text search solvesthis problem by evaluating a keyword query on the state of the text collection as of a user-specified time point. This work demonstrates our approach to efficient time-travel text searchand its implementation in the FLUXCAPACITOR prototype.,Proceedings of the 33rd International Conference on Very Large Data Bases (VLDB 2007),2007,23
Computing n-Gram Statistics in MapReduce,Klaus Berberich; Srikanta Bedathur,Abstract Statistics about n-grams (ie; sequences of contiguous words or other tokens in textdocuments or other string data) are an important building block in information retrieval andnatural language processing. In this work; we study how n-gram statistics; optionallyrestricted by a maximum n-gram length and minimum collection frequency; can be computedefficiently harnessing MapReduce for distributed data processing. We describe differentalgorithms; ranging from an extension of word counting; via methods based on the Aprioriprinciple; to a novel method Suffix-σ that relies on sorting and aggregating suffixes. Weexamine possible extensions of our method to support the notions of maximality/closednessand to perform aggregations beyond occurrence counting. Assuming Hadoop as a concreteMap-Reduce implementation; we provide insights on an efficient implementation of the …,Proceedings of the 16th International Conference on Extending Database Technology (EDBT 2013),2013,22
Efficient Temporal Keyword Search over Versioned Text,Avishek Anand; Srikanta Bedathur; Klaus Berberich; Ralf Schenkel,Abstract Modern text analytics applications operate on large volumes of temporal text datasuch as Web archives; newspaper archives; blogs; wikis; and micro-blogs. In these settings;searching and mining needs to use constraints on the time dimension in addition to keywordconstraints. A natural approach to address such queries is using an inverted index whoseentries are enriched with valid-time intervals. It has been shown that these indexes have tobe partitioned along time in order to achieve efficiency. However; when the temporalpredicate corresponds to a long time range; requiring the processing of multiple partitions;naive query processing incurs high cost of reading of redundant entries across partitions.We present a framework for efficient approximate processing of keyword queries over atemporally partitioned inverted index which minimizes this overhead; thus speeding up …,Proceedings of the 19th ACM International Conference on Information and Knowledge Management (CIKM 2010),2010,22
BuzzRank… and the trend is your friend,Klaus Berberich; Srikanta Bedathur; Michalis Vazirgiannis; Gerhard Weikum,Abstract Ranking methods like PageRank assess the importance of Web pages based onthe current state of the rapidly evolving Web graph. The dynamics of the resultingimportance scores; however; have not been considered yet; although they provide the key toan understanding of the Zeitgeist on the Web. This paper proposes the BuzzRank methodthat quantifies trends in time series of importance scores and is based on a relevant growthmodel of importance scores. We experimentally demonstrate the usefulness of BuzzRank ona bibliographic dataset.,Proceedings of the 15th International Conference on World Wide Web (WWW 2006),2006,22
Identifying Time Intervals of Interest to Queries,Dhruv Gupta; Klaus Berberich,Abstract We investigate how time intervals of interest to a query can be identifiedautomatically based on pseudo-relevant documents; taking into account both theirpublication dates and temporal expressions from their contents. Our approach is based on agenerative model and is able to determine time intervals at different temporal granularities(eg; day; month; or year). We evaluate our approach on twenty years' worth of newspaperarticles from The New York Times using two novel testbeds consisting of temporallyunambiguous and temporally ambiguous queries; respectively.,Proceedings of the 23rd ACM International Conference on Information and Knowledge Management (CIKM 2014),2014,21
EntityAuthority: Semantically Enriched Graph-Based Authority Propagation,Julia Stoyanovich; Srikanta Bedathur; Klaus Berberich; Gerhard Weikum,ABSTRACT This paper pursues the recently emerging paradigm of searching for entities thatare embedded in Web pages. We utilize informationextraction techniques to identify entitycandidates in documents; map them onto entries in a richly structured ontology; and derive ageneralized data graph that encompasses Web pages; entities; and ontological conceptsand relationships. We exploit this combination of pages and entities for a novel kind ofsearch-result ranking; coined EntityAuthority; in order to improve the quality of keywordqueries that return either pages or entities. To this end; we utilize the mutual reinforcementbetween authoritative pages and important entities. This resembles the HITS method forWeb-graph link analysis and recently proposed ObjectRank methods; but our approachoperates on a much richer; typed graph structure with different kinds of nodes and also …,Proceedings of the 10th International Workshop on the Web and Databases (WebDB 2007),2007,20
Relationship Queries on Extended Knowledge Graphs,Mohamed Yahya; Denilson Barbosa; Klaus Berberich; Qiuyue Wang; Gerhard Weikum,Abstract Entity search over text corpora is not geared for relationship queries where answersare tuples of related entities and where a query often requires joining cues from multipledocuments. With large knowledge graphs; structured querying on their relational facts is analternative; but often suffers from poor recall because of mismatches between user queriesand the knowledge graph or because of weakly populated relations. This paper presents theTriniT search engine for querying and ranking on extended knowledge graphs that combinerelational facts with textual web contents. Our query language is designed on the paradigmof SPO triple patterns; but is more expressive; supporting textual phrases for each of theSPO arguments. We present a model for automatic query relaxation to compensate formismatches between the data and a user's query. Query answers--tuples of entities--are …,Proceedings of the Ninth ACM International Conference on Web Search and Data Mining,2016,18
Improving Local Search Ranking through External Logs,Klaus Berberich; Arnd Christian König; Dimitrios Lymberopoulos; Peixiang Zhao,Abstract The signals used for ranking in local search are very different from web search: inaddition to (textual) relevance; measures of (geographic) distance between the user and thesearch result; as well as measures of popularity of the result are important for effectiveranking. Depending on the query and search result; different ways to quantify these factorsexist--for example; it is possible to use customer ratings to quantify the popularity ofrestaurants; whereas different measures are more appropriate for other types of businesses.Hence; our approach is to capture the different notions of distance/popularity relevant via anumber of external data sources (eg; logs of customer ratings; driving-direction requests; orsite accesses). In this paper we will describe the relevant signal contained in a number ofsuch data sources in detail and present methods to integrate these external data sources …,Proceedings of the 34th International ACM SIGIR Conference on Research and Development in Information Retrieval (SIGIR 2011),2011,18
EverLast: A Distributed Architecture for Preserving the Web,Avishek Anand; Srikanta Bedathur; Klaus Berberich; Ralf Schenkel; Christos Tryfonopoulos,Abstract The World Wide Web has become a key source of knowledge pertaining to almostevery walk of life. Unfortunately; much of data on the Web is highly ephemeral in nature; withmore than 50-80% of content estimated to be changing within a short time. Continuing thepioneering efforts of many national (digital) libraries; organizations such as the InternationalInternet Preservation Consortium (IIPC); the Internet Archive (IA) and the European Archive(EA) have been tirelessly working towards preserving the ever changing Web. However;while these web archiving efforts have paid significant attention towards long termpreservation of Web data; they have paid little attention to developing an global-scaleinfrastructure for collecting; archiving; and performing historical analyzes on the collecteddata. Based on insights from our recent work on building text analytics for Web Archives …,Proceedings of the 9th ACM/IEEE-CS Joint Conference on Digital Libraries (JCDL 2009),2009,17
Time-Based Exploration of News Archives,Omar Alonso; Klaus Berberich; Srikanta Bedathur; Gerhard Weikum,ABSTRACT In this paper; we present NEAT; a prototype system that provides an explorationinterface to news archive search. Our prototype visualizes search results making use of twokinds of temporal information; namely; news articles' publication dates but also theircontained temporal expressions. The displayed timelines are annotated with major events;harvested using crowdsourcing; to make it easier for users to put the shown search resultsinto context. The prototype has been fully implemented and deployed on the New YorkTimes Annotated Corpus.,Proceedings of the Fourth Workshop on Human-Computer Interaction and Information Retrieval (HCIR 2010),2010,15
Local search using feature backoff,*,A local search system is described herein that provides a framework for the integration ofvarious external sources to improve local search ranking. The framework provided by thelocal search system described herein uses a notion of backoff. The system uses ageneralization of the concept of backoff to improve local search results that incorporate avariety of data features. The system can apply backoff in multiple dimensions at the sametime to generate features for local search ranking. The system integrates various additionaldata sources; such as web access logs; driving direction request logs; reviews; and so forth;to quantify popularity and distance (or distance sensitivity) into a framework for local searchranking. Thus; the system provides search results that are more relevant by incorporating anumber of data sources into the ranking in a manner that handles abnormalities in the …,*,2012,12
Comparing Apples and Oranges: Normalized PageRank for Evolving Graphs,Klaus Berberich; Srikanta Bedathur; Gerhard Weikum; Michalis Vazirgiannis,Abstract PageRank is the best known technique for link-based importance ranking. Thecomputed importance scores; however; are not directly comparable across differentsnapshots of an evolving graph. We present an efficiently computable normalization forPageRank scores that makes them comparable across graphs. Furthermore; we show thatthe normalized PageRank scores are robust to non-local changes in the graph; unlike thestandard PageRank measure.,Proceedings of the 16th International Conference on World Wide Web (WWW 2007),2007,12
Generating Quiz Questions from Knowledge Graphs,Dominic Seyler; Mohamed Yahya; Klaus Berberich,Abstract We propose an approach to generate natural language questions from knowledgegraphs such as DBpedia and YAGO. We stage this in the setting of a quiz game. Ourapproach; though; is general enough to be applicable in other settings. Given a topic ofinterest (eg; Soccer) and a difficulty (eg; hard); our approach selects a query answer;generates a SPARQL query having the answer as its sole result; before verbalizing thequestion.,Proceedings of the 24th International World Wide Web Conference (WWW 2015),2015,11
Linking Wikipedia Events to Past News,Aruna Mishra; Dragan Milchevski; Klaus Berberich,Temporal; Social and Spatially-aware Information Access … TAIA 2014: Linking Wikipedia Eventsto Past News … ''I could hear the words my father had spoken to me when I was a child: 'Oneday you will sing for kings and queens;' ''Aretha Franklin recalls about an early 1980's Londongala attended by the Prince of Wales and the Queen Mother. She has also sung in the WhiteHouse for Presidents Jimmy Carter and Bill Clinton; although she turned down a ball in MonteCarlo for Princes Albert and Rainier and a performance for Queen Beatrix of theNetherlands. The reason? Her fear of flying. Franklin -- who is 57 years old; has won 15 GrammyAwards and in 1987 became the first woman inducted into the Rock and Roll Hall of Fame (thoughher fear of flying also kept her from that ceremony) -- has written a self-congratulatory yet entertainingautobiography. The fourth of five children born to a famous Baptist preacher and a …,Proceedings of Workshop on Time-aware Information Access (TAIA 2014),2014,11
InZeit: Efficiently Identifying Insightful Time Points,Vinay Setty; Srikanta Bedathur; Klaus Berberich; Gerhard Weikum,Abstract Web archives are useful resources to find out about the temporal evolution ofpersons; organizations; products; or other topics. However; even when advanced text searchfunctionality is available; gaining insights into the temporal evolution of a topic can be atedious task and often requires sifting through many documents. The demonstrated systemnamed InZeit (pronounced" insight") assists users by determining insightful time points for agiven query. These are the time points at which the top-k time-travel query result changessubstantially and for which the user should therefore inspect query results. InZeit determinesthe m most insightful time points efficiently using an extended segment tree for in-memorybookkeeping.,Proceedings of the VLDB Endowment,2010,11
NEAT: News Exploration Along Time,Omar Alonso; Klaus Berberich; Srikanta Bedathur; Gerhard Weikum,Abstract There are a number of efforts towards building applications that leverage temporalinformation in documents. The demonstration of our NEAT (News Exploration Along Time)prototype system that we propose here; is an attempt towards building an intuitive andexploratory interface for search results over large news archives using timelines. Thedemonstration uses the New York Times Annotated Corpus as an illustrative example ofsuch a news archive. The NEAT system consists of two parts: the back-end server extractsand stores in an index all the temporal information from documents; and performs importantphrase discovery from sentences that have time-sensitive information. The front-end userinterface; anchors the results of a keyword search along the timeline where the user canexplore and browse results at different points in time. To aid in this exploration; the …,Proceedings of the 32nd European Conference on IR Research (ECIR 2010),2010,11
Temporal Query Classification at Different Granularities,Dhruv Gupta; Klaus Berberich,Abstract In this work; we consider the problem of classifying time-sensitive queries atdifferent temporal granularities (day; month; and year). Our approach involves performingBayesian analysis on time intervals of interest obtained from pseudo-relevant documents.Based on the Bayesian analysis we derive several effective features which are used to traina supervised machine learning algorithm for classification. We evaluate our method on alarge temporal query workload to show that we can determine the temporal class of a querywith high precision.,Proceedings of the 22nd International Symposium on String Processing and Information Retrieval (SPIRE 2015),2015,10
PACRR: A Position-Aware Neural IR Model for Relevance Matching,Kai Hui; Andrew Yates; Klaus Berberich; Gerard de Melo,Abstract In order to adopt deep learning for information retrieval; models are needed thatcan capture all relevant information required to assess the relevance of a document to agiven user query. While previous works have successfully captured unigram term matches;how to fully employ position-dependent information such as proximity and termdependencies has been insufficiently explored. In this work; we propose a novel neural IRmodel named PACRR aiming at better modeling position-dependent interactions between aquery and a document. Extensive experiments on six years' TREC Web Track data confirmthat the proposed model yields better results under multiple benchmarks.,Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing,2017,9
Efficient Time-Travel on Versioned Text Collections,Klaus Berberich; Srikanta Bedathur; Gerhard Weikum,Abstract: The availability of versioned text collections such as the Internet Archive opens upopportunities for time-aware exploration of their contents. In this paper; we propose time-travel retrieval and ranking that extends traditional keyword queries with a temporal contextin which the query should be evaluated. More precisely; the query is evaluated over allstates of the collection that existed during the temporal context. In order to support thesequeries; we make key contributions in (i) defining extensions to well-known relevancemodels that take into account the temporal context of the query and the version history ofdocuments;(ii) designing an immortal index over the full versioned text collection that avoidsa blowup in index size; and (iii) making the popular NRA algorithm for top-k queryprocessing aware of the temporal context. We present preliminary experimental analysis …,Proceedings of GI-Fachtagung für Datenbanksysteme in Business; Technologie und Web (BTW 2007),2007,9
Important Events in the Past; Present; and Future,Abdalghani Abujabal; Klaus Berberich,Abstract We address the problem of identifying important events in the past; present; andfuture from semantically-annotated large-scale document collections. Semantic annotationsthat we consider are named entities (eg; persons; locations; organizations) and temporalexpressions (eg; during the 1990s). More specifically; for a given time period of interest; ourobjective is to identify; rank; and describe important events that happened. Our approachP2F Miner makes use of frequent itemset mining to identify events and group sentencesrelated to them. It uses an information-theoretic measure to rank identified events. For eachof them; it selects a representative sentence as a description. Experiments on ClueWeb09using events listed in Wikipedia year articles as ground truth show that our approach iseffective and outperforms a baseline based on statistical language models.,Proceedings of the 24th International World Wide Web Conference (WWW 2015),2015,8
Node Behavior Prediction for Large-Scale Approximate Information Filtering,Christian Zimmer; Christos Tryfonopoulos; Klaus Berberich; Gerhard Weikum; Manolis Koubarakis,ABSTRACT In this paper we investigate methods that allow us to identify the publishingbehavior of individual nodes in large-scale distributed information filtering systems. Thework presented here is based on our system MAPS (Minerva ApproximatePublish/Subscribe); a novel approach to support approximate information filteringfunctionality in a peer-to-peer environment. In MAPS; a user subscribes to and monitors onlycarefully selected publisher nodes; and receives notifications from these information sourcesonly. In this way; document-granularity dissemination is known from exact informationfiltering approaches is avoided; and the system is able to support very high publication rates.However this scalability benefits come at the cost of lower recall. To improve node selectionand thus recall; in previous work we have proposed a ranking method that predicts nodes' …,Proceedings of the Workshop on Large Scale Distributed Systems for Information Retrieval (LSDS-IR 2007),2007,7
MAPS: Approximate Publish/Subscribe Functionality in Peer-to-Peer Networks,Klaus Berberich; Manolis Koubarakis; Christos Tryfonopoulos; Gerhard Weikum; Christian Zimmer,Abstract Information filtering has been a research issue for years. In an information filteringscenario users information needs are expressed by user subscriptions; and users arenotified about published documents or events that match these interests. The combination ofthe publish/subscribe scenario with the peer-to-peer (P2P) approach of autonomous peersmakes high demands on the scalability and the efficiency of such a given highly distributednetwork. However; in many cases a subscriber is not interested in all the events that matchhis profile; but rather in a small representative set. In this paper; we present our approach ofan approximate publish/subscribe system; that relaxes the assumption for receivingnotifications from every information producer in the network. Our work builds upondistributed hash table technology to create and maintain a distributed global directory that …,Proceedings of the 1st International Workshop on Advanced Data Processing in Ubiquitous Computing (ADPUC 2006),2006,7
Diversifying Search Results Using Time - An Information Retrieval Method for Historians,Dhruv Gupta; Klaus Berberich,*,Proceedings of the 38th European Conference on IR Research (ECIR 2016),2016,6
Closing the Gap: Sequence Mining at Scale,Kaustubh Beedkar; Klaus Berberich; Rainer Gemulla; Iris Miliaraki,Abstract Frequent sequence mining is one of the fundamental building blocks in datamining. While the problem has been extensively studied; few of the available techniques aresufficiently scalable to handle datasets with billions of sequences; such large-scale datasetsarise; for instance; in text mining and session analysis. In this article; we propose MG-FSM; ascalable algorithm for frequent sequence mining on MapReduce. MG-FSM can handle so-called “gap constraints”; which can be used to limit the output to a controlled set of frequentsequences. Both positional and temporal gap constraints; as well as appropriate maximalityand closedness constraints; are supported. At its heart; MG-FSM partitions the inputdatabase in a way that allows us to mine each partition independently using any existingfrequent sequence mining algorithm. We introduce the notion of ω-equivalency; which is …,ACM Transactions on Database Systems (TODS),2015,6
Learning to Select a Time-Aware Retrieval Model,Nattiya Kanhabua; Klaus Berberich; Kjetil Nørvåg,Abstract Time-aware retrieval models exploit one of two time dimensions; namely;(a)publication time or (b) content time (temporal expressions mentioned in documents). Weshow that the effectiveness for a temporal query (eg; illinois earthquake 1968) dependssignificantly on which time dimension is factored into ranking results. Motivated by this; wepropose a machine learning approach to select the most suitable time-aware retrieval modelfor a given temporal query. Our method uses three classes of features obtained fromanalyzing distributions over two time dimensions; a distribution over terms; and retrievalscores within top-k result documents. Experiments on real-world data with crowdsourcedrelevance assessments show the potential of our approach.,Proceedings of the 35th International ACM SIGIR Conference on Research and Development in Information Retrieval (SIGIR 2012),2012,6
Tunable Word-Level Index Compression for Versioned Corpora,Klaus Berberich; Srikanta Bedathur; Gerhard Weikum,Abstract. This paper presents a tunable index compression scheme for supporting time-travel phrase queries over large versioned corpora such as web archives. Support forphrase queries makes maintenance of word positions necessary; thus increasing the indexsize significantly. We propose to fuse the word positions in many neighboring versions of adocument; and thus exploit the typically high level of redundancy and compressibility toshrink the index size. The resulting compression scheme called FUSION; can be tuned totrade off compression for query-processing overheads. Our experiments on the revisionhistory of Wikipedia demonstrate the effectiveness of our method.,Proceedings of the 1st Workshop on Efficiency Issues in Information Retrieval (EIIR 2008),2008,6
Representing and quantifying rank-change for the Web graph,Akrivi Vlachou; Michalis Vazirgiannis; Klaus Berberich,Abstract One of the grand research and industrial challenges in recent years is efficient websearch; inherently involving the issue of page ranking. In this paper we address the issue ofrepresenting and quantifying web ranking trends as a measure of web pages. We study therank position of a web page among different snapshots of the web graph and proposenormalized measures of ranking trends that are comparable among web graph snapshots ofdifferent sizes. We define the ra nk c hang er ate (racer) as a measure quantifying the webgraph evolution. Thereafter; we examine different ways to aggregate the rank change ratesand quantify the trends over a group of web pages. We outline the problem of identifyinghighly dynamic web pages and discuss possible future work. In our experimental evaluationwe study the dynamics of web pages; especially those highly ranked.,*,2006,6
Selective Labeling and Incomplete Label Mitigation for Low-Cost Evaluation,Kai Hui; Klaus Berberich,Abstract Information retrieval evaluation heavily relies on human effort to assess therelevance of result documents. Recent years have seen efforts and good progress to reducethe human effort and thus lower the cost of evaluation. Selective labeling strategies carefullychoose a subset of result documents to label; for instance; based on their aggregate rank inresults; strategies to mitigate incomplete labels seek to make up for missing labels; forinstance; predicting them using machine learning methods. How different strategies interact;though; is unknown. In this work; we study the interaction of several state-of-the-artstrategies for selective labeling and incomplete label mitigation on four years of TREC WebTrack data (2011–2014). Moreover; we propose and evaluate MaxRep as a novel selectivelabeling strategy; which has been designed so as to select effective training data for …,Proceedings of the 22nd International Symposium on String Processing and Information Retrieval (SPIRE 2015),2015,5
EXPOSÉ: EXploring Past news fOr Seminal Events,Arunav Mishra; Klaus Berberich,Abstract Recent increases in digitization and archiving efforts on news data have led tooverwhelming amounts of online information for general users; thus making it difficult forthem to retrospect on past events. One dimension along which past events can be effectivelyorganized is time. Motivated by this idea; we introduce EXPOSÉ; an exploratory searchsystem that explicitly uses temporal information associated with events to link different kindsof information sources for effective exploration of past events. In this demonstration; we useWikipedia and news articles as two orthogonal sources. Wikipedia is viewed as an eventdirectory that systematically lists seminal events in a year; news articles are viewed as asource of detailed information on each of these events. To this end; our demo includesseveral time-aware retrieval approaches that a user can employ for retrieving relevant …,Proceedings of the 24th International World Wide Web Conference (WWW 2015),2015,5
Location-Aware Search Ranking,*,A training system is described for generating at least one ranking module using featuresderived; in part; from region information. The region information encodes characteristicsabout regions which are associated with queries in search log data. A query processingsystem is also described for applying the ranking model generated by the training system toprocess queries in real time. In one implementation; the training system can also generateplural ranking models corresponding to plural respective map areas. The training systemcan also generate a mapping model which correlates each region with a ranking model tobe applied when processing queries that originate from that region. The query processingsystem can process a query by determining a region associated with the query and thenidentifying and applying a ranking model which corresponds to the region.,*,2012,5
Visual Exploration of Collaboration Networks based on Graph Degeneracy,Christos Giatsidis; Klaus Berberich; Dimitrios M Thilikos; Michalis Vazirgiannis,Abstract We demonstrate a system that supports the visual exploration of collaborationnetworks. The system leverages the notion of fractional cores introduced in earlier work torank vertices in a collaboration network and filter vertices' neighborhoods. Fractional coresbuild on the idea of graph degeneracy as captured by the notion of k-cores in graph theoryand extend it to undirected edge-weighted graphs. In a co-authorship network; for instance;the fractional core index of an author intuitively reflects the degree of collaboration withequally or higher-ranked authors. Our system has been deployed on a real-world co-authorship network derived from DBLP; demonstrating that the idea of fractional cores canbe applied even to large-scale networks. The system provides an easy-to-use interface toquery for the fractional core index of an author; to see who the closest equally or higher …,Proceedings of the 18th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining (KDD 2012),2012,5
Rank Synopses for Efficient Time Travel on the Web Graph,Klaus Berberich; Srikanta Bedathur; Gerhard Weikum,The World Wide Web is increasingly becoming the key source of information pertaining notonly to business and entertainment but also to a spectrum of sciences; culture; and politics.However; the Web has an even greater source of information within it–evolutionary history ofits structure and content. It not only captures the evolution of digital content but embodies thenear-term history of our society; economy; and science. Although efforts such as the InternetArchive [1] are archiving a large fraction of the Web; there is a serious lack of tools that aredesigned for the effective search over these Web archives. Time travel queries are aimed atsupporting the evolutionary (temporal) analysis over Web archives extending the power ofWeb search-engines. Specifically; a time travel query Q is defined as a pair〈 Qir; Qtc〉;where Qir is the IR-style keyword query and Qtc is the target temporal context. For …,Proceedings of the 15th ACM International Conference on Information and Knowledge Management (CIKM 2006),2006,5
Knowledge questions from knowledge graphs,Dominic Seyler; Mohamed Yahya; Klaus Berberich,Abstract We address the problem of automatically generating quiz-style knowledgequestions from a knowledge graph such as DBpedia. Questions of this kind have ampleapplications; for instance; to educate users about or to evaluate their knowledge in a specificdomain. To solve the problem; we propose a novel end-to-end approach. The approach firstselects a named entity from the knowledge graph as an answer. It then generates astructured triple-pattern query; which yields the answer as its sole result. If a multiple-choicequestion is desired; the approach selects alternative answer options as distractors. Finally;our approach uses a template-based method to verbalize the structured query and yield anatural language question. A key challenge is estimating how difficult the generatedquestion is to human users. To do this; we make use of historical data from the Jeopardy …,Proceedings of the ACM SIGIR International Conference on Theory of Information Retrieval,2017,4
Position-aware representations for relevance matching in neural information retrieval,Kai Hui; Andrew Yates; Klaus Berberich; Gerard de Melo,Abstract To deploy deep learning models for ad-hoc information retrieval; suitablerepresentations of query-document pairs are needed. Such representations ought to captureall relevant information required to assess the relevance of a document for a given query;including uni-gram term overlap as well as positional information such as proximity and termdependencies. In this work; we investigate the use of similarity matrices that are able toencode such position-specific information. Extensive experiments on TREC Web Track dataconfirm that such representations can yield good results.,Proceedings of the 26th International Conference on World Wide Web Companion,2017,4
Event Digest: A Holistic View on Past Events,Arunav Mishra; Klaus Berberich,Abstract For a general user; easy access to vast amounts of online information available onpast events has made retrospection much harder. We propose a problem of automatic eventdigest generation to aid effective and efficient retrospection. For this; in addition to text; adigest should maximize the reportage of time; geolocations; and entities to present a holisticview on the past event of interest. We propose a novel divergence-based framework thatselects excerpts from an initial set of pseudo-relevant documents; such that the overallrelevance is maximized; while avoiding redundancy in text; time; geolocations; and namedentities; by treating them as independent dimensions of an event. Our method formulates theproblem as an Integer Linear Program (ILP) for global inference to diversify across the eventdimensions. Relevance and redundancy measures are defined based on JS-divergence …,Proceedings of the 39th International ACM SIGIR conference on Research and Development in Information Retrieval,2016,4
Exploratory Querying of Extended Knowledge Graphs,Mohamed Yahya; Klaus Berberich; Maya Ramanath; Gerhard Weikum,Abstract Knowledge graphs (KGs) are important assets for search; analytics; andrecommendations. However; querying a KG to explore entities and discover facts is difficultand tedious; even for users with skills in SPARQL. First; users are not familiar with thestructure and labels of entities; classes and relations. Second; KGs are bound to beincomplete; as they capture only major facts about entities and their relationships and missout on many of the more subtle aspects. We demonstrate TriniT; a system that facilitatesexploratory querying of large KGs; by addressing these issues of" vocabulary" mismatch andKG incompleteness. TriniT supports query relaxation rules that are invoked to allow forrelevant answers which are not found otherwise. The incompleteness issue is addressed byextending a KG with additional text-style token triples obtained by running Open IE on …,Proceedings of the VLDB Endowment,2016,4
User-Defined Redundancy in Web Archives,Bibek Paudel; Avishek Anand; Klaus Berberich,ABSTRACT Web archives are valuable resources. However; they are characterized by ahigh degree of redundancy. Not only does this redundancy waste computing resources; butit also deteriorates users' experience; since they have to sift through and weed outredundant content. Existing methods focus on identifying near-duplicate documents;assuming a universal notion of redundancy; and can thus not adapt to userspecificrequirements such as a preference for more recent or diversely opinionated content. In thiswork; we propose an approach that equips users with fine-grained control over what theyconsider redundant. Users thus specify a binary coverage relation between documents thatcan factor in documents' contents as well as their meta data. Our approach then determinesa minimumcardinality cover set of non-redundant documents. We describe how this can …,Proceedings of the 10th International Workshop on Large-Scale and Distributed Systems for Information Retrieval (LSDS-IR 2013),2013,4
Temporal Search in Web Archives,Klaus Berberich,Webarchive bezeichnen einerseits Archive ursprünglich im Web veröffentlichter Inhalte (z. B.das Internet Archive); andererseits Archive; die vor langer Zeit veröffentlichter Inhalte imWeb zugreifbar machen (z. B. das Archiv von The Times). Ein gewachsenes Bewusstein;dass originär digitale Inhalte bewahrenswert sind; sowie verbesserteDigitalisierungsverfahren haben dazu geführt; dass Anzahl und Umfang von Webarchivenzugenommen haben. Um das volle Potenzial von Webarchiven auszuschöpfen; bedarf esdurchdachter Suchverfahren. Diese Arbeit befasst sich mit drei relevanten Teilproblemenund leistet die folgenden Beiträge:-Vorstellung des Time-Travel Inverted indeX (TTIX) alseine Erweiterung des invertierten Index; um Zeitreise-Textsuche auf Webarchiven effizientzu unterstützen.-Eine neue Methode zur automatischen Umformulierung von …,*,2010,4
Evaluating the potential of explicit phrases for retrieval quality,Andreas Broschart; Klaus Berberich; Ralf Schenkel,Abstract This paper evaluates the potential impact of explicit phrases on retrieval qualitythrough a case study with the TREC Terabyte benchmark. It compares the performance ofuser-and system-identified phrases with a standard score and a proximity-aware score; andshows that an optimal choice of phrases; including term permutations; can significantlyimprove query performance.,*,2010,4
Transitivity; Time Consumption; and Quality of Preference Judgments in Crowdsourcing,Kai Hui; Klaus Berberich,Abstract Preference judgments have been demonstrated as a better alternative to gradedjudgments to assess the relevance of documents relative to queries. Existing work hasverified transitivity among preference judgments when collected from trained judges; whichreduced the number of judgments dramatically. Moreover; strict preference judgments andweak preference judgments; where the latter additionally allow judges to state that twodocuments are equally relevant for a given query; are both widely used in literature.However; whether transitivity still holds when collected from crowdsourcing; ie; whether thetwo kinds of preference judgments behave similarly remains unclear. In this work; we collectjudgments from multiple judges using a crowdsourcing platform and aggregate them tocompare the two kinds of preference judgments in terms of transitivity; time consumption …,Proceedings of the 39th European Conference on Information Retrieval (ECIR 2017),2017,3
Low-Cost Preference Judgment via Ties,Kai Hui; Klaus Berberich,Abstract Preference judgment; as an alternative to graded judgment; leads to more accuratelabels and avoids the need to define relevance levels. However; it also requires a largernumber of judgments. Prior research has successfully reduced that number to O (N_d\; N_d)for N_d documents by assuming transitivity; which is still too expensive in practice. In thiswork; by analytically deriving the number of judgments and by empirically simulating theground-truth ranking of documents from Trec Web Track; we demonstrate that the number ofjudgments can be dramatically reduced when allowing for ties.,Proceedings of the 39th European Conference on Information Retrieval (ECIR 2017),2017,3
A Probabilistic Framework for Time-Sensitive Search,Dhruv Gupta; Klaus Berberich,ABSTRACT This research article presents TimeSearch; a probabilistic framework; thatcompeted in the Temporalia-2 task. The subtasks in Temporalia-2 require an informationretrieval system to be informed of the temporal expressions (eg 1990s) in documents andqueries to identify relevant documents. Analysis of these temporal expressions like naturallanguage understanding is challenging. TimeSearch utilizes an unique time model toaddress these challenges and to understand temporal expressions. Building on this model itidentifies interesting time intervals for a given keyword query. These time intervals are thenused to rank and diversify documents in a time-sensitive manner. In this article we describeTimeSearch and its performance in Temporalia-2.,Proceedings of the 12th NTCIR Conference (NTCIR),2016,3
Leveraging Semantic Annotations to Link Wikipedia and News Archives,Arunav Mishra; Klaus Berberich,Abstract The incomprehensible amount of information available online has made it difficult toretrospect on past events. We propose a novel linking problem to connect excerpts fromWikipedia summarizing events to online news articles elaborating on them. To address thislinking problem; we cast it into an information retrieval task by treating a given excerpt as auser query with the goal to retrieve a ranked list of relevant news articles. We find thatWikipedia excerpts often come with additional semantics; in their textual descriptions;representing the time; geolocations; and named entities involved in the event. Our retrievalmodel leverages text and semantic annotations as different dimensions of an event byestimating independent query models to rank documents. In our experiments on twodatasets; we compare methods that consider different combinations of dimensions and …,Proceedings of the 38th European Conference on IR Research (ECIR 2016),2016,3
MPI-INF at the NTCIR-11 Temporal Query Classification Task,Robin Burghartz; Klaus Berberich,ABSTRACT MPI-INF participated in the Temporal Query Intent Classification Task (TQIC) ofthe Temporalia track at NTCIR-11. This paper describes our approach to address thisspecific task. Our overall strategy has been to rely on established off-the-shelf components(eg; standard classifiers from Weka and natural language processing methods from StanfordCoreNLP) and focus on feature engineering. Devised features include surface (eg; n-grams); linguistic (eg; capturing whether the query is a question); and temporal (eg; statisticsabout publication dates and temporal expressions). We provide details on their precisedefinition and report on their effectiveness.,Proceedings of the 11th NTCIR Conference (NTCIR),2014,3
A Pocket Guide to Web History,Klaus Berberich; Srikanta Bedathur; Gerhard Weikum,Abstract Web archives like the Internet Archive preserve the evolutionary history of largeportions of the Web. Access to them; however; is still via rather limited interfaces–a searchfunctionality is often missing or ignores the time axis. Time-travel search alleviates thisshortcoming by enriching keyword queries with a time-context of interest. In order to beeffective; time-travel queries require historical PageRank scores. In this paper; we addressthis requirement and propose rank synopses as a novel structure to compactly representand reconstruct historical PageRank scores. Rank synopses can reconstruct the PageRankscore of a web page as of any point during its lifetime; even in the absence of a snapshot ofthe Web as of that time. We further devise a normalization scheme for PageRank scores tomake them comparable across different graphs. Through a comprehensive evaluation …,Proceedings of the 14th International Symposium on String Processing and Information Retrieval (SPIRE 2007),2007,3
Time-Aware and Trend-Based Authority Ranking,Klaus Berberich,Abstract This thesis devises time-aware and trend-based ranking techniques. The time-aware techniques exploit temporal information; present in networks like the World WideWeb; to produce rankings reflecting authority with regard to a temporal interest. Thetrendbased techniques produce rankings based on the relative change of authority withregard to a temporal interest. We describe mathematics behind the approaches and reviewefforts having related aims. On this basis; two time-aware and two trend-based methods areproposed. The time-aware methods extend PageRank and are defined incrementally. Thetrend-based methods are defined independently; one extending PageRank and the otherbased on a comparison of precomputed authority rankings. The methods were implementedin a prototype system using Java and extensively evaluated in a series of experiments on …,*,2004,3
Automated Question Generation for Quality Control in Human Computation Tasks,Dominic Seyler; Mohamed Yahya; Klaus Berberich; Omar Alonso,Abstract When running large human computation tasks in the real-world; honeypots play animportant role for assessing the overall quality of the work produced. The generation of suchhoneypots can be a significant burden on the task owner as they require specificcharacteristics in their design and implementation and continuous maintenance whenoperating data pipelines that include a human computation component. In this extendedabstract we outline a novel approach for creating honeypots using automatically generatedquestions from a reference knowledge base with the ability to control such parameters astopic and difficulty.,Proceedings of the 8th ACM Conference on Web Science,2016,2
Cluster Hypothesis in Low-Cost IR Evaluation with Different Document Representations,Kai Hui; Klaus Berberich,Abstract Offline evaluation for information retrieval aims to compare the performance ofretrieval systems based on relevance judgments for a set of test queries. Since manualjudgments are expensive; selective labeling has been developed to semi-automaticallylabel documents; in the wake of the similarity relationship among retrieved documents.Intuitively; the agreement wrt the cluster hypothesis can directly determine the amount ofmanual judgments that can be saved by creating labels with a semi-automatic method.Meanwhile; in representing documents; certain information is lost. We argue that betterdocument representation can lead to better agreement with the cluster hypothesis. To thisend; we investigate different document representations on established benchmarks in thecontext of low-cost evaluation; showing that different document representations vary in …,Proceedings of the 25th International Conference Companion on World Wide Web,2016,2
Instant Espresso: Interactive Analysis of Relationships in Knowledge Graphs,Stephan Seufert; Patrick Ernst; Srikanta J Bedathur; Sarath Kumar Kondreddi; Klaus Berberich; Gerhard Weikum,Abstract We demonstrate InstantEspresso; a system to explain the relationship between twosets of entities in knowledge graphs. Instant-Espresso answers questions of the form. WhichEuropean politicians are related to politicians in the United States; and how? or How canone summarize the relationship between China and countries from the Middle East? Eachquestion is specified by two sets of query entities. These sets (eg European politicians orUnited States politicians) can be determined by an initial graph query over a knowledgegraph capturing relationships between real-world entities. Instant-Espresso analyzes the(indirect) relationships that connect entities from both sets and provides a user-friendlyexplanation of the answer in the form of concise subgraphs. These so-called relatednesscores correspond to important event complexes involving entities from the two sets. Our …,Proceedings of the 25th International Conference Companion on World Wide Web,2016,2
Phrase Query Optimization on Inverted Indexes,Avishek Anand; Ida Mele; Srikanta Bedathur; Klaus Berberich,Abstract Phrase queries are a key functionality of modern search engines. Beyond that; theyincreasingly serve as an important building block for applications such as entity-orientedsearch; text analytics; and plagiarism detection. Processing phrase queries is costly; though;since positional information has to be kept in the index and all words; including stopwords;need to be considered. We consider an augmented inverted index that indexes selectedvariable-length multi-word sequences in addition to single words. We study how arbitraryphrase queries can be processed efficiently on such an augmented inverted index. We showthat the underlying optimization problem is NP-hard in the general case and describe anexact exponential algorithm and an approximation algorithm to its solution. Experiments onClueWeb09 and The New York Times with different real-world query workloads examine …,Proceedings of the 23rd ACM International Conference on Information and Knowledge Management (CIKM 2014),2014,2
On the SPOT: Question Answering over Temporally Enhanced Structured Data,Mohamed Yahya; Klaus Berberich; Maya Ramanath; Gerhard Weikum,ABSTRACT Natural-language question answering is a convenient way for humans todiscover relevant information in structured Web data such as knowledge bases or LinkedOpen Data sources. This paper focuses on data with a temporal dimension; and discussesthe problem of mapping natural-language questions into extended SPARQL queries overRDF-structured data. We specifically address the issue of disambiguating temporal phrasesin the question into temporal entities like dates and named events; and temporal predicates.For the situation where the data has only partial coverage of the time dimension but isaugmented with textual descriptions of entities and facts; we also discuss how to generatequeries that combine structured search with keyword conditions.,Proceedings of Workshop on Time-aware Information Access (TAIA 2013),2013,2
Co-PACRR: A Context-Aware Neural IR Model for Ad-hoc Retrieval,Kai Hui; Andrew Yates; Klaus Berberich; Gerard de Melo,ABSTRACT Neural IR models; such as DRMM and PACRR; have achieved strong results bysuccessfully capturing relevance matching signals. We argue that the context of thesematching signals is also important. Intuitively; when extracting; modeling; and combiningmatching signals; one would like to consider the surrounding text (local context) as well asother signals from the same document that can contribute to the overall relevance score. Inthis work; we highlight three potential shortcomings caused by not considering contextinformation and propose three neural ingredients to address them: a disambiguationcomponent; cascade k-max pooling; and a shuffling combination layer. Incorporating thesecomponents into the PACRR model yields Co-PACRR; a novel context-aware neural IRmodel. Extensive comparisons with established models on Trec Web Track data confirm …,Proceedings of the 11th ACM International Conference on Web Search and Data Mining. WSDM,2018,1
RE-PACRR: A Context and Density-Aware Neural Information Retrieval Model,Kai Hui; Andrew Yates; Klaus Berberich; Gerard de Melo,Abstract: Ad-hoc retrieval models can benefit from considering different patterns in theinteractions between a query and a document; effectively assessing the relevance of adocument for a given user query. Factors to be considered in this interaction include (i) thematching of unigrams and ngrams;(ii) the proximity of the matched query terms;(iii) theirposition in the document; and (iv) how the different relevance signals are combined overdifferent query terms. While previous work has successfully modeled some of these factors;not all aspects have been fully explored. In this work; we close this gap by proposingdifferent neural components and incorporating them into a single architecture; leading to anovel neural IR model called RE-PACRR. Extensive comparisons with established modelson TREC Web Track data confirm that the proposed model yields promising search …,arXiv preprint arXiv:1706.10192,2017,1
Dealing with Incomplete Judgments in Cascade Measures,Kai Hui; Klaus Berberich; Ida Mele,Abstract Cascade measures like alpha-nDCG; ERR-IA; and NRBP take into account noveltyand diversity of query results and are computed using judgments provided by humans;which are costly to collect. These measures expect that all documents in the result list of aquery are judged and cannot make use of judgments beyond the assigned labels. Existingwork has demonstrated that condensing the query results by taking out documents withoutjudgment can address this problem to some extent. However; how highly incompletejudgments can affect cascade measures and how to cope with such incompleteness havenot been addressed yet. In this paper; we propose an approach which mitigates incompletejudgments by leveraging the content of documents relevant to the query's subtopics. Theselanguage models are estimated at each rank taking into account the document and the …,Proceedings of the ACM SIGIR International Conference on Theory of Information Retrieval (ICTIR 2017),2017,1
ESPRESSO: Explaining Relationships between Entity Sets,Stephan Seufert; Klaus Berberich; Srikanta J Bedathur; Sarath Kumar Kondreddi; Patrick Ernst; Gerhard Weikum,Abstract Analyzing and explaining relationships between entities in a knowledge graph is afundamental problem with many applications. Prior work has been limited to extracting themost informative subgraph connecting two entities of interest. This paper extends andgeneralizes the state of the art by considering the relationships between two sets of entitiesgiven at query time. Our method; coined ESPRESSO; explains the connection betweenthese sets in terms of a small number of relatedness cores: dense sub-graphs that havestrong relations with both query sets. The intuition for this model is that the cores correspondto key events in which entities from both sets play a major role. For example; to explain therelationships between US politicians and European politicians; our method identifies eventslike the PRISM scandal and the Syrian Civil War as relatedness cores. Computing cores …,Proceedings of the 25th ACM International on Conference on Information and Knowledge Management,2016,1
EventMiner: Mining Events from Annotated Documents,Dhruv Gupta; Jannik Strötgen; Klaus Berberich,Abstract Events are central in human history and thus also in Web queries; in particular ifthey relate to history or news. However; ambiguity issues arise as queries may refer toambiguous events differing in time; geography; or participating entities. Thus; users wouldgreatly benefit if search results were presented along different events. In this paper; wepresent EventMiner; an algorithm that mines events from top-k pseudo-relevant documentsfor a given query. It is a probabilistic framework that leverages semantic annotations in theform of temporal expressions; geographic locations; and named entities to analyze naturallanguage text and determine important events. Using a large news corpus; we show thatusing semantic annotations; EventMiner detects important events and presents documentscovering the identified events in the order of their importance.,Proceedings of the ACM SIGIR International Conference on Theory of Information Retrieval (ICTIR 2016),2016,1
DIGITALHISTORIAN: Search & Analytics Using Annotations.,Dhruv Gupta; Jannik Strötgen; Klaus Berberich,Abstract Born-digital document collections contain vast amounts of historical facts andknowledge. However; manual assessment of these large text collections is infeasible. In thispaper; we demonstrate a retrieval system; DIG-ITALHISTORIAN; that analyzes thesedocument collections using semantic annotations in the form of temporal expressions andnamed entities linked to a knowledge graph. For queries about entities or eventsDIGITALHISTO-RIAN utilizes state-of-the-art methods to understand and analyze temporalexpressions in the content of documents. It understands uncertainty in temporal expressionsand uses them to mine interesting time intervals for keyword queries. These time intervalsare further used for re-ranking and diversifying documents; so that the ranked list ofdocuments portray a historic overview of the query. Further; to contextualize the …,HistoInformatics@ DH,2016,1
SIGIR 2015 Workshop on Temporal; Social and Spatially-aware Information Access (# TAIA2015),Klaus Berberich; James Caverlee; Miles Efron; Claudia Hauff; Vanessa Murdock; Milad Shokouhi; Bart Thomee,Page 1. SIGIR 2015 Workshop on Temporal; Social and Spatially-aware Information Access(#TAIA2015) Klaus Berberich Max Planck Institute for Informatics Saarbruecken; Germanykberberi@mpi-inf.mpg.de James Caverlee Department of Computer Science and EngineeringTexas A&M University College Station; USA caverlee@cse.tamu.edu Miles Efron GraduateSchool of Library and Information Science University of Illinois Champaign; USAmefron@illinois.edu Claudia Hauff Web Information Systems Delft University of TechnologyDelft; the Netherlands c.hauff@tudelft.nl Vanessa Murdock Microsoft Corporation Redmond;USA vanmur@microsoft.com Milad Shokouhi Microsoft Research Cambridge; UKmilads@microsoft.com Bart Thomee Yahoo! Labs San Francisco; USA bthomee@yahoo-inc.com 1. OVERVIEW Spatial and temporal context are tightly coupled …,Proceedings of the 38th International ACM SIGIR Conference on Research and Development in Information Retrieval,2015,1
Efficient Computation of Relationship-Centrality in Large Entity-Relationship Graphs,Stephan Seufert; Srikanta J Bedathur; Johannes Hoffart; Andrey Gubichev; Klaus Berberich,Abstract. Given two sets of entities–potentially the results of two queries on a knowledge-graph like YAGO or DBpedia–characterizing the relationship between these sets in the formof important people; events and organizations is an analytics task useful in many domains.In this paper; we present an intuitive and efficiently computable vertex centrality measurethat captures the importance of a node with respect to the explanation of the relationshipbetween the pair of query sets. Using a weighted link graph of entities contained in theEnglish Wikipedia; we demonstrate the usefulness of the proposed measure.,Proceedings of the ISWC 2013 Posters & Demonstrations Track (ISWC 2013),2013,1
D-Hive: Data Bees Pollinating RDF; Text; and Time.,Srikanta J Bedathur; Klaus Berberich; Ioannis Patlakas; Peter Triantafillou; Gerhard Weikum,ABSTRACT Although the problem of integrating IR and DB solutions is considered “old”; theincreasing importance of big data analytics and its formidable demands for both enrichedfunctionality and scalable performance creates the need to revisit the problem itself and tosee possible solutions from a new perspective. Our goal is to develop a system that willmake large corpora aware of entities and relationships (ER); addressing the challenges insearching and analyzing ER patterns in web data and social media. We put forward D-Hive;a system facilitating analytics over RDF-style (SPO) triples augmented with text and(validity/transaction) time capable of addressing the functionality and scalabilityrequirements which current solutions cannot meet. We consider various alternatives for thedata modeling; storage; indexing; and query processing engines of D-Hive paying …,Proceedings of the Sixth Biennial Conference on Innovative Data Systems Research (CIDR 2013),2013,1
Estimating Event Focus Time Using Neural Word Embeddings,Supratim Das; Arunav Mishra; Klaus Berberich,Abstract Time associated with news events has been leveraged as a complementarydimension to text in several applications such as temporal information retrieval; news eventlinking; etc. Short textual event descriptions (eg; single sentences) are prevalent in webdocuments (also considered as inputs in the above applications) and often lack explicittemporal expressions for grounding them to a precise time period. For example; the eventdescription;" France swears in Emmanuel Macron as the 25th President"; lacks temporalcues to indicate that the event occurred in the year" 2017". Thus; we address the problem ofestimating event focus time defined as a time interval with maximum association therebyindicating its occurrence period. We propose several estimators that leverage distributionalevent and time representations learned from large external document collections by …,Proceedings of the 26th ACM International Conference on Information and Knowledge Management (CIKM 2017),2017,*
Merge-Tie-Judge: Low-Cost Preference Judgments with Ties,Kai Hui; Klaus Berberich,ABSTRACT Preference judgments have been demonstrated to yield more accurate labelsthan graded judgments and also forego the need to de ne grades upfront. ese bene ts;however; come at the cost of a larger number of judgments that is required. Prior research;by exploiting the transitivity of preferences; successfully reduced the overall number ofpreference judgments required to O (Nd log Nd) for Nd documents; which is still prohibitivein practice. In this work; we reduce the overall number of preference judgments required byallowing for ties and exploiting that ties naturally cluster documents. Our novel judgmentmechanism Merge-Tie-Judge exploits this “clustering e ect” by automatically inferringpreferences between documents from di erent clusters. Experiments on relevancejudgments from the T Web Track show that the proposed mechanism requires fewer …,Proceedings of the ACM SIGIR International Conference on Theory of Information Retrieval (ICTIR 2017),2017,*
How do Order and Proximity Impact the Readability of Event Summaries?,Arunav Mishra; Klaus Berberich,Abstract Organizing the structure of fixed-length text summaries for events is important fortheir coherence and readability. However; typical measures used for evaluation in textsummarization tasks often ignore the structure. In this paper; we conduct an empirical studyon a crowdsourcing platform to get insights into regularities that make a text summarycoherent and readable. For this; we generate four variants of human-written text summarieswith 10 sentences for 100 seminal events; and conduct three experiments. Experiment 1 and2 focus on analyzing the impact of sentence ordering and proximity between originallyoccurring adjacent sentences; respectively. Experiment 3 analyzes the feasibility ofconducting such a study on a crowdsourcing platform. We release our data to facilitate futurework like designing dedicated measures to evaluate summary structures.,Proceedings of the 39th European Conference on Information Retrieval (ECIR 2017),2017,*
Estimating Time Models for News Article Excerpts,Arunav Mishra; Klaus Berberich,Abstract It is often difficult to ground text to precise time intervals due to the inherentuncertainty arising from either missing or multiple expressions at year; month; and day timegranularities. We address the problem of estimating an excerpt-time model capturing thetemporal scope of a given news article excerpt as a probability distribution over chronons.For this; we propose a semi-supervised distribution propagation framework that leveragesredundancy in the data to improve the quality of estimated time models. Our methodgenerates an event graph with excerpts as nodes and models various inter-excerpt relationsas edges. It then propagates empirical excerpt-time models estimated for temporallyannotated excerpts; to those that are strongly related but miss annotations. In ourexperiments; we first generate a test query set by randomly sampling 100 Wikipedia …,Proceedings of the 25th ACM International Conference on Information and Knowledge Management (CIKM 2010),2016,*
X-REC: Cross-Category Entity Recommendation,Dragan Milchevski; Klaus Berberich,Abstract We demonstrate X-Rec; a novel system for entity recommendation. In contrast toother systems; X-Rec can recommend entities from diverse categories including goods (eg;books); other physical entities (eg; actors); but also immaterial entities (eg; ideologies).Further; it does so only based on publicly available data sources; including the revisionhistory of Wikipedia; using an easily extensible approach for recommending entities. Wedescribe X-Rec's architecture; showing how its components interact with each other.Moreover; we outline our demonstration; which foresees different modes for users to interactwith the system.,Proceedings of the 5th Information Interaction in Context Symposium (IIiX 2014),2014,*
Web Archives,Klaus Berberich,Internet use has always been social. Moreover; it is through social ties that users havetended to become increasingly drawn into other cooperative activity; whether personal;professional; or community related. Thus; social theory; encompassing social networks;social participation; resource exchange networks; media uses and gratifications; and socialinfluence; has contributed significantly to our understanding of the use and impact ofcomputing related to social behavior. This chapter offers an examination of the contributionsof social theory to the diffusion of social computing through a case study of the communitycomputer network known as the Blacksburg Electronic Village in Blacksburg; Virginia.,*,2014,*
Phrase Queries with Inverted + Direct Indexes,Kiril Panev; Klaus Berberich,Abstract Phrase queries play an important role in web search and other applications.Traditionally; phrase queries have been processed using a positional inverted index;potentially augmented by selected multi-word sequences (eg; n-grams or frequent nounphrases). In this work; instead of augmenting the inverted index; we take a radically differentapproach and leverage the direct index; which provides efficient access to compactrepresentations of documents. Modern retrieval systems maintain such a direct index; forinstance; to generate snippets or compute proximity features. We present extensions of theestablished term-at-a-time and document-at-a-time query-processing methods that makeeffective combined use of the inverted index and the direct index. Our experiments on tworeal-world document collections using diverse query workloads demonstrate that our …,Proceedings of the 15th International Conference on Web Information Systems Engineering (WISE 2014),2014,*
Unstoppable Stateful PHP Web Services,German Shegalov; Gerhard Weikum; Klaus Berberich,Abstract This paper presents the architecture and implementation of the EOS 2 failure-masking framework for composite Web Services. EOS 2 is based on the recently proposednotion of interaction contracts (IC); and provides exactly-once execution semantics forgeneral; arbitrarily distributed Web Services in the presence of message losses andcomponent crashes without requiring explicit coding effort by the application programmer.The EOS 2 implementation masks failures by adding a recovery layer to popular Webtechnology products:(i) the server-side script language PHP run on Apache Web server; and(ii) Internet browsers like IE to deliver recovery guarantees to the end-user.,Proceedings of the 7th International Conference on Web Information Systems Engineering (WISE 2006),2006,*
