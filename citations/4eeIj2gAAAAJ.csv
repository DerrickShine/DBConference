Probabilistic databases,Dan Suciu; Dan Olteanu; Christopher Ré; Christoph Koch,Abstract Probabilistic databases are databases where the value of some attributes or thepresence of some records are uncertain and known only with some probability. Applicationsin many areas such as information extraction; RFID and scientific data management; datacleaning; data integration; and financial risk assessment produce large volumes of uncertaindata; which are best modeled and processed by a probabilistic database. This bookpresents the state of the art in representation formalisms and query processing techniquesfor probabilistic data. It starts by discussing the basic principles for representing largeprobabilistic databases; by decomposing them into tuple-independent tables; block-independent-disjoint tables; or U-databases. Then it discusses two classes of techniques forquery evaluation on probabilistic databases. In extensional query evaluation; the entire …,Synthesis Lectures on Data Management,2011,339
XPath: looking forward,Dan Olteanu; Holger Meuss; Tim Furche; François Bry,Abstract The location path language XPath is of particular importance for XML applicationssince it is a core component of many XML processing standards such as XSLT or XQuery. Inthis paper; based on axis symmetry of XPath; equivalences of XPath 1.0 location pathsinvolving reverse axes; such as anc and prec; are established. These equivalences areused as rewriting rules in an algorithm for transforming location paths with reverse axes intoequivalent reverse-axis-free ones. Location paths without reverse axes; as generated by thepresented rewriting algorithm; enable efficient SAX-like streamed data processing of XPath.,International Conference on Extending Database Technology,2002,302
Fast and simple relational processing of uncertain data,Lyublena Antova; Thomas Jansen; Christoph Koch; Dan Olteanu,This paper introduces U-relations; a succinct and purely relational representation system foruncertain databases. U-relations support attribute-level uncertainty using verticalpartitioning. If we consider positive relational algebra extended by an operation forcomputing possible answers; a query on the logical level can be translated into; andevaluated as; a single relational algebra query on the U-relational representation. Thetranslation scheme essentially preserves the size of the query in terms of number ofoperations and; in particular; number of joins. Standard techniques employed in off-the-shelfrelational database management systems are effective for optimizing and processingqueries on U-relations. In our experiments we show that query evaluation on U-relationsscales to large amounts of data with high degrees of uncertainty.,Data Engineering; 2008. ICDE 2008. IEEE 24th International Conference on,2008,277
A semi-empirical simulation of the extragalactic radio continuum sky for next generation radio telescopes,RJ Wilman; L Miller; MJ Jarvis; T Mauch; F Levrier; FB Abdalla; S Rawlings; H-R Klöckner; D Obreschkow; D Olteanu; S Young,Abstract We have developed a semi-empirical simulation of the extragalactic radiocontinuum sky suitable for aiding the design of next generation radio interferometers such asthe Square Kilometre Array (SKA). The emphasis is on modelling the large-scalecosmological distribution of radio sources rather than the internal structure of individualgalaxies. Here we provide a description of the simulation to accompany the online release ofa catalogue of≃ 320 million simulated radio sources. The simulation covers a sky area of20× 20 deg2–a plausible upper limit to the instantaneous field of view attainable with future(eg SKA) aperture array technologies–out to a cosmological redshift of z= 20; and down toflux density limits of 10 nJy at 151; 610 MHz; 1.4; 4.86 and 18 GHz. Five distinct source typesare included: radio-quiet active galactic nuclei (AGN); radio-loud AGN of the Fanaroff …,Monthly Notices of the Royal Astronomical Society,2008,255
$ ${10^{(10^{6})}} $ $ worlds and beyond: efficient representation and processing of incomplete information,Lyublena Antova; Christoph Koch; Dan Olteanu,Abstract We present a decomposition-based approach to managing probabilisticinformation. We introduce world-set decompositions (WSDs); a space-efficient and completerepresentation system for finite sets of worlds. We study the problem of efficiently evaluatingrelational algebra queries on world-sets represented by WSDs. We also evaluate ourtechnique experimentally in a large census data scenario and show that it is both scalableand efficient.,The VLDB Journal,2009,186
MayBMS: a probabilistic database management system,Jiewen Huang; Lyublena Antova; Christoph Koch; Dan Olteanu,Abstract MayBMS is a state-of-the-art probabilistic database management system whichleverages the strengths of previous database research for achieving scalability. As a proof ofconcept for its ease of use; we have built on top of MayBMS a Web-based application thatoffers NBA-related information based on what-if analysis of team dynamics using dataavailable at www. nba. com.,Proceedings of the 2009 ACM SIGMOD International Conference on Management of data,2009,149
Conditioning probabilistic databases,Christoph Koch; Dan Olteanu,Abstract Past research on probabilistic databases has studied the problem of answeringqueries on a static database. Application scenarios of probabilistic databases however ofteninvolve the conditioning of a database using additional information in the form of newevidence. The conditioning problem is thus to transform a probabilistic database of priorsinto a posterior probabilistic database which is materialized for subsequent queryprocessing or further refinement. It turns out that the conditioning problem is closely relatedto the problem of computing exact tuple confidence values. It is known that exact confidencecomputation is an NP-hard problem. This has led researchers to consider approximationtechniques for confidence computation. However; neither conditioning nor exact confidencecomputation can be solved using such techniques. In this paper we present efficient …,Proceedings of the VLDB Endowment,2008,133
Agora: Living with XML and relational,Ioana Manolescu; Daniela Florescu; Donald Kossmann; Florian Xhumari; Dan Olteanu,1 Introduction There has been a significant body of research in the last fifteen yearsdedicated to integration of data from various repositories; exhibiting heterogeneous formats;and sometimes access restrictions; for a survey of such systems see; for example;[12]. Themain technical issues to be addressed in a mediation system are: how to semantically unifyheterogeneous data formats and schemas; and how to use query processing capabilities ofparticipant data sites and that of the mediator in order to answer a particular query. Systemslike the Information Manifold; and Garlic from IBM have chosen the relational andrespectively the object-oriented model as the integration model. Given the popularity of XMLas a data description format; more and more DBMS manufacturers have added to theirsystems the capability to export relational or object-oriented data to an XML format; other …,Vldb,2000,126
MayBMS: Managing incomplete information with probabilistic world-set decompositions,Lyublena Antova; Christoph Koch; Dan Olteanu,Managing incomplete information is important in many real world applications. In thisdemonstration we present MayBMS-a system for representing and managing finite sets ofpossible worlds-that successfully combines expressiveness and efficiency. Some features ofMayBMS are: completeness of the representation system for finite world-sets; space-efficientrepresentation of large world-sets; scalable evaluation and support for full relational algebraqueries; and probabilistic extension of the representation system and the query language.MayBMS is implemented on top of PostgreSQL. It models incomplete data using the so-called world-set decompositions (WSDs)(Ruggles et al.; 2004). For this demonstration; weintroduce a probabilistic extension of world-sets and WSDs; where worlds or correlationsbetween worlds have probabilities. The main idea underlying probabilistic WSDs is to use …,Data Engineering; 2007. ICDE 2007. IEEE 23rd International Conference on,2007,104
Sprout: Lazy vs. eager query plans for tuple-independent probabilistic databases,Dan Olteanu; Jiewen Huang; Christoph Koch,A paramount challenge in probabilistic databases is the scalable computation ofconfidences of tuples in query results. This paper introduces an efficient secondary-storageoperator for exact computation of queries on tuple-independent probabilistic databases. Weconsider the conjunctive queries without self-joins that are known to be tractable on anytuple-independent database; and queries that are not tractable in general but becometractable on probabilistic databases restricted by functional dependencies. Our operator issemantically equivalent to a sequence of aggregations and can be naturally integrated intoexisting relational query plans. As a proof of concept; we developed an extension of thePostgreSQL 8.3. 3 query engine called SPROUT. We study optimizations that push or pullour operator or parts thereof past joins. The operator employs static information; such as …,Data Engineering; 2009. ICDE'09. IEEE 25th International Conference on,2009,99
From complete to incomplete information and back,Lyublena Antova; Christoph Koch; Dan Olteanu,Abstract Incomplete information arises naturally in numerous data managementapplications. Recently; several researchers have studied query processing in the context ofincomplete information. Most work has combined the syntax of a traditional query languagelike relational algebra with a nonstandard semantics such as certain or ranked possibleanswers. There are now also languages with special features to deal with uncertainty.However; to the standards of the data management community; to date no languageproposal has been made that can be considered a natural analog to SQL or relationalalgebra for the case of incomplete information. In this paper we propose such a language;World-set Algebra; which satisfies the robustness criteria and analogies to relational algebrathat we expect. The language supports the contemplation on alternatives and can thus …,Proceedings of the 2007 ACM SIGMOD international conference on Management of data,2007,99
Parallel Materialisation of Datalog Programs in Centralised; Main-Memory RDF Systems.,Boris Motik; Yavor Nenov; Robert Piro; Ian Horrocks; Dan Olteanu,Abstract We present a novel approach to parallel materialisation (ie; fixpoint computation) ofdatalog programs in centralised; main-memory; multi-core RDF systems. Our approachcomprises an algorithm that evenly distributes the workload to cores; and an RDF indexingdata structure that supports efficient;'mostly'lock-free parallel updates. Our empiricalevaluation shows that our approach parallelises computation very well: with 16 physicalcores; materialisation can be up to 13.9 times faster than with just one core.,AAAI,2014,87
An evaluation of regular path expressions with qualifiers against XML streams,Dan Olteanu; Tobias Kiesling; François Bry,We present SPEX; a streamed and progressive evaluation of regular path expressions withXPath-like qualifiers against XML streams. SPEX proceeds as follows. An expression istranslated in linear time into a network of transducers; most of them having 1-DPDTequivalents. Every stream message is then processed once by the entire network and resultfragments are output on the fly. In most practical cases SPEX needs a time linear in thestream size and for transducer stacks a memory quadratic in the stream depth. Experimentswith a prototype implementation point to a very good efficiency of the SPEX approach.,Data Engineering; 2003. Proceedings. 19th International Conference on,2003,86
SPEX: Streamed and progressive evaluation of XPath,Dan Olteanu,Streams are preferable over data stored in memory in contexts where data is too large orvolatile; or a standard approach to data processing based on storing is too time or spaceconsuming. Emerging applications such as publish-subscribe systems; data monitoring insensor networks; financial and traffic monitoring; and routing of MPEG-7 call for queryingstreams. In many such applications; XML streams are arguably more appropriate than flatstreams; for they convey (possibly unbounded) unranked ordered trees with labeled nodes.However; the flexibility enabled by XML streams in data modeling makes query evaluationdifferent from traditional settings and challenging. This paper describes SPEX; a streamedand progressive evaluation of XML Path Language (XPath). SPEX compiles queries intonetworks of simple and independent transducers and processes XML streams with …,IEEE Transactions on Knowledge and Data Engineering,2007,81
World-set decompositions: Expressiveness and efficient algorithms,Dan Olteanu; Christoph Koch; Lyublena Antova,Abstract Uncertain information is commonplace in real-world data management scenarios.The ability to represent large sets of possible instances (worlds) while supporting efficientstorage and processing is an important challenge in this context. The recent formalism ofworld-set decompositions (WSDs) provides a space-efficient representation for uncertaindata that also supports scalable processing. WSDs are complete for finite world-sets in thatthey can represent any finite set of possible worlds. For possibly infinite world-sets; we showthat a natural generalization of WSDs precisely captures the expressive power of c-tables.We then show that several important problems are efficiently solvable on WSDs while theyare NP-hard on c-tables. Finally; we give a polynomial-time algorithm for factorizing WSDs;ie an efficient algorithm for minimizing such representations.,Theoretical Computer Science,2008,75
Approximate confidence computation in probabilistic databases,Dan Olteanu; Jiewen Huang; Christoph Koch,This paper introduces a deterministic approximation algorithm with error guarantees forcomputing the probability of propositional formulas over discrete random variables. Thealgorithm is based on an incremental compilation of formulas into decision diagrams usingthree types of decompositions: Shannon expansion; independence partitioning; and productfactorization. With each decomposition step; lower and upper bounds on the probability ofthe partially compiled formula can be quickly computed and checked against the allowederror.,Data Engineering (ICDE); 2010 IEEE 26th International Conference on,2010,73
Using OBDDs for efficient query evaluation on probabilistic databases,Dan Olteanu; Jiewen Huang,Abstract We consider the problem of query evaluation for tuple independent probabilisticdatabases and Boolean conjunctive queries with inequalities but without self-joins. Weapproach this problem as a construction problem for ordered binary decision diagrams(OBDDs): Given a query q and a probabilistic database D; we construct in polynomial timean OBDD such that the probability of q (D) can be computed linearly in the size of thatOBDD. This approach is applicable to a large class of queries; including the hierarchicalqueries; ie; the Boolean conjunctive queries without self-joins that admit PTIME evaluationon any tuple-independent probabilistic database; hierarchical queries extended withinequalities; and non-hierarchical queries on restricted databases.,International Conference on Scalable Uncertainty Management,2008,66
Design and implementation of the LogicBlox system,Molham Aref; Balder ten Cate; Todd J Green; Benny Kimelfeld; Dan Olteanu; Emir Pasalic; Todd L Veldhuizen; Geoffrey Washburn,Abstract The LogicBlox system aims to reduce the complexity of software development formodern applications which enhance and automate decision-making and enable their usersto evolve their capabilities via a``self-service''model. Our perspective in this area is informedby over twenty years of experience building dozens of mission-critical enterpriseapplications that are in use by hundreds of large enterprises across industries such as retail;telecommunications; banking; and government. We designed and built LogicBlox to be thesystem we wished we had when developing those applications. In this paper; we discuss thedesign considerations behind the LogicBlox system and give an overview of itsimplementation; highlighting innovative aspects. These include: LogiQL; a unified anddeclarative language based on Datalog; the use of purely functional data structures; …,Proceedings of the 2015 ACM SIGMOD International Conference on Management of Data,2015,64
The XML stream query processor SPEX,François Bry; Fatih Coskun; Serap Durmaz; Tim Furche; Dan Olteanu; Markus Spannagel,Data streams are an emerging technology for data dissemination in cases where the datathroughput or size makes it unfeasible to rely on the conventional approach based onstoring the data before processing it. SPEX evaluates XPath queries against XML datastreams. SPEX is built upon formal frameworks for (1) rewriting XPath queries intoequivalent XPath queries without reverse axes and (2) correct query evaluation withpolynomial combined complexity using networks of pushdown transducers. Suchtransducers are simple; independent; and can be connected in a flexible manner; thusallowing not only easy extensions but also extensive query optimization. Querying XMLstreams with SPEX consists in four steps: first; the input XPath query is rewritten into anXPath query without reverse axes. Second; the forward XPath query is compiled into a …,Data Engineering; 2005. ICDE 2005. Proceedings. 21st International Conference on,2005,46
An efficient single-pass query evaluator for XML data streams,Dan Olteanu; Tim Furche; François Bry,Abstract Data streams might be preferable to data stored in memory in contexts where thedata is too large or volatile; or a standard approach to data processing based on dataparsing and/or storing is too time or space consuming. Emerging applications such aspublish-subscribe systems; data monitoring in sensor networks [6]; financial and trafficmonitoring; and routing of MPEG-7 [7] call for querying data streams. In many suchapplications; XML streams are arguably more appropriate than flat data streams; for XMLdata is record-like; though not precluding multiple occurrences of fields with the same name.Evaluating selection queries against XML streams is especially challenging because XMLdata is structured (like records) and might have unbounded size. This paper proposes anefficient single-pass evaluator of XPath queries against XML data streams unbounded …,Proceedings of the 2004 ACM symposium on Applied computing,2004,41
Query language support for incomplete information in the MayBMS system,Lyublena Antova; Christoph Koch; Dan Olteanu,Abstract MayBMS [4; 1; 3; 2] is a data management system for incomplete informationdeveloped at Saarland University. Its main features are a simple and compactrepresentation system for incomplete information and a language called I-SQL with explicitoperations for handling uncertainty. MayBMS is currently an extension of PostgreSQL andmanages both complete and incomplete data and evaluates I-SQL queries.,Proceedings of the 33rd international conference on Very large data bases,2007,40
Secondary-storage confidence computation for conjunctive queries with inequalities,Dan Olteanu; Jiewen Huang,Abstract This paper investigates the problem of efficiently computing the confidences ofdistinct tuples in the answers to conjunctive queries with inequalities (<) on tuple-independent probabilistic databases. This problem is fundamental to probabilistic databasesand was recently stated open.,Proceedings of the 2009 ACM SIGMOD International Conference on Management of data,2009,39
Providing support for full relational algebra in probabilistic databases,Robert Fink; Dan Olteanu; Swaroop Rath,Extensive work has recently been done on the evaluation of positive queries on probabilisticdatabases. The case of queries with negation has notoriously been left out; since it raisesserious additional challenges to efficient query evaluation. This paper provides a completeframework for the evaluation of full relational algebra queries in probabilistic databases. Inparticular; it proposes exact and approximate evaluation techniques for relational algebraqueries on representation systems that can accommodate any finite probability space overrelational databases. Key ingredients to these techniques are (1) the manipulation of nestedpropositional expressions used for probability computation without unfolding them intodisjunctive normal form; and (2) efficient computation of lower and upper probability boundsof such expressions by deriving coarser expressions in tractable theories such as one …,Data Engineering (ICDE); 2011 IEEE 27th International Conference on,2011,36
Evaluating complex queries against XML streams with polynomial combined complexity,Dan Olteanu; Tim Furche; François Bry,Abstract Querying XML streams is receiving much attention due to its growing range ofapplications from traffic monitoring to routing of media streams. Existing approaches toquerying XML streams consider restricted query language fragments; in most cases withexponential worst-case complexity in the size of the query. This paper gives correctness andcomplexity results for a query evaluator against XML streams called SPEX [8]. Its combinedcomplexity is shown to be polynomial in the size of the data and the query. Extensiveexperimental evaluation with a prototype confirms the theoretical complexity results.,British National Conference on Databases,2004,36
Aggregation in probabilistic databases via knowledge compilation,Robert Fink; Larisa Han; Dan Olteanu,Abstract This paper presents a query evaluation technique for positive relational algebraqueries with aggregates on a representation system for probabilistic data based on thealgebraic structures of semiring and semimodule. The core of our evaluation technique is aprocedure that compiles semimodule and semiring expressions into so-calleddecomposition trees; for which the computation of the probability distribution can be done intime linear in the product of the sizes of the probability distributions represented by its nodes.We give syntactic characterisations of tractable queries with aggregates by exploiting theconnection between query tractability and polynomial-time decomposition trees.,Proceedings of the VLDB Endowment,2012,35
Learning linear regression models over factorized joins,Maximilian Schleich; Dan Olteanu; Radu Ciucanu,Abstract We investigate the problem of building least squares regression models overtraining datasets defined by arbitrary join queries on database tables. Our key observation isthat joins entail a high degree of redundancy in both computation and data representation;which is not required for the end-to-end solution to learning over joins. We propose a newparadigm for computing batch gradient descent that exploits the factorized computation andrepresentation of the training datasets; a rewriting of the regression objective function thatdecouples the computation of cofactors of model parameters from their convergence; andthe commutativity of cofactor computation with relational union and projection. We introducethree flavors of this approach: F/FDB computes the cofactors in one pass over thematerialized factorized join; Favoids this materialization and intermixes cofactor and join …,Proceedings of the 2016 International Conference on Management of Data,2016,34
Size bounds for factorised representations of query results,Dan Olteanu; Jakub Závodný,Abstract We study two succinct representation systems for relational data based onrelational algebra expressions with unions; Cartesian products; and singleton relations: f-representations; which employ algebraic factorisation using distributivity of product overunion; and d-representations; which are f-representations where further succinctness isbrought by explicit sharing of repeated subexpressions. In particular we study suchrepresentations for results of conjunctive queries. We derive tight asymptotic bounds forrepresentation sizes and present algorithms to compute representations within thesebounds. We compare the succinctness of f-representations and d-representations for resultsof equi-join queries; and relate them to fractional edge covers and fractional hypertreedecompositions of the query hypergraph.,ACM Transactions on Database Systems (TODS),2015,32
On the optimal approximation of queries using tractable propositional languages,Robert Fink; Dan Olteanu,Abstract This paper investigates the problem of approximating conjunctive queries withoutself-joins on probabilistic databases by lower and upper bounds that can be computed moreefficiently. We study this problem via an indirection: Given a propositional formula &phis;;find formulas in a more restricted language that are greatest lower bound and least upperbound; respectively; of &phis;. We study bounds in the languages of read-once formulas;where every variable occurs at most once; and of read-once formulas in disjunctive normalform. We show equivalences of syntactic and model-theoretic characterisations of optimalbounds for unate formulas; and present algorithms that can enumerate them with polynomialdelay. Such bounds can be computed by queries expressed using first-order queriesextended with transitive closure and a special choice construct.,Proceedings of the 14th International Conference on Database Theory,2011,32
Aggregation and ordering in factorised databases,Nurzhan Bakibayev; Tomáš Kočiský; Dan Olteanu; Jakub Závodný,Abstract A common approach to data analysis involves understanding and manipulatingsuccinct representations of data. In earlier work; we put forward a succinct representationsystem for relational data called factorised databases and reported on the main-memoryquery engine FDB for select-project-join queries on such databases. In this paper; weextend FDB to support a larger class of practical queries with aggregates and ordering. Thisrequires novel optimisation and evaluation techniques. We show how factorisation coupledwith partial aggregation can effectively reduce the number of operations needed for queryevaluation. We also show how factorisations of query results can support enumeration oftuples in desired orders as efficiently as listing them from the unfactorised; sorted results.,Proceedings of the VLDB Endowment,2013,30
Symmetry in xpath,Dan Olteanu; Holger Meuss; Tim Furche; François Bry,Abstract The location path language XPath is of particular importance for XML applicationssince it is a core component of many XML processing standards such as XSLT or XQuery. Inthis paper; based on axis symmetry of XPath; equivalences of XPath 1.0 location pathsinvolving “reverse axes”; such as ancestor and preceding; are established. Theseequivalences are used as rewriting rules in an algorithm for transforming location paths withreverse axes into equivalent reverse-axis-free ones. Location paths without reverse axes; asgenerated by the presented rewriting algorithm; enable efficient SAX-like streamed dataprocessing of XPath.,*,2001,29
Probabilistic XML via Markov chains,Michael Benedikt; Evgeny Kharlamov; Dan Olteanu; Pierre Senellart,Abstract We show how Recursive Markov Chains (RMCs) and their restrictions can defineprobabilistic distributions over XML documents; and study tractability of querying over suchmodels. We show that RMCs subsume several existing probabilistic XML models. In contrastto the latter; RMC models (i) capture probabilistic versions of XML schema languages suchas DTDs;(ii) can be exponentially more succinct; and (iii) do not restrict the domain ofprobability distributions to be finite. We investigate RMC models for which tractability can beachieved; and identify several tractable fragments that subsume known tractableprobabilistic XML models. We then look at the space of models between existingprobabilistic XML formalisms and RMCs; giving results on the expressiveness andsuccinctness of RMC subclasses; both with each other and with prior formalisms.,Proceedings of the VLDB Endowment,2010,28
Forward node-selecting queries over trees,Dan Olteanu,Abstract Node-selecting queries over trees lie at the core of several important XMLlanguages for the web; such as the node-selection language XPath; the query languageXQuery; and the transformation language XSLT. The main syntactic constructs of suchqueries are the backward predicates; for example; ancestor and preceding; and the forwardpredicates; for example; descendant and following. Forward predicates are included in thedepth-first; left-to-right preorder relation associated with the input tree; whereas backwardpredicates are included in the inverse of this preorder relation. This work is devoted to anexpressiveness study of node-selecting queries with proven theoretical and practicalapplicability; especially in the field of query evaluation against XML streams. The mainquestion it answers positively is whether; for each input query with forward and backward …,ACM Transactions on Database Systems (TODS),2007,28
Bridging the gap between intensional and extensional query evaluation in probabilistic databases,Abhay Jha; Dan Olteanu; Dan Suciu,Abstract There are two broad approaches to query evaluation over probabilisticdatabases:(1) Intensional Methods proceed by manipulating expressions over symbolicevents associated with uncertain tuples. This approach is very general and can be appliedto any query; but requires an expensive postprocessing phase; which involves somegeneral-purpose probabilistic inference.(2) Extensional Methods; on the other hand;evaluate the query by translating operations over symbolic events to a query plan;extensional methods scale well; but they are restricted to safe queries. In this paper; webridge this gap by proposing an approach that can translate the evaluation of any query intoextensional operators; followed by some post-processing that requires probabilisticinference. Our approach uses characteristics of the data to adapt smoothly between the …,Proceedings of the 13th International Conference on Extending Database Technology,2010,27
FDB: A query engine for factorised relational databases,Nurzhan Bakibayev; Dan Olteanu; Jakub Závodný,Abstract Factorised databases are relational databases that use compact factorisedrepresentations at the physical layer to reduce data redundancy and boost queryperformance. This paper introduces FDB; an in-memory query engine for select-project-joinqueries on factorised databases. Key components of FDB are novel algorithms for queryoptimisation and evaluation that exploit the succinctness brought by data factorisation.Experiments show that for data sets with many-to-many relationships FDB can outperformrelational engines by orders of magnitude.,Proceedings of the VLDB Endowment,2012,26
Repeatability and workability evaluation of SIGMOD 2011,Philippe Bonnet; Stefan Manegold; Matias Bjørling; Wei Cao; Javier Gonzalez; Joel Granados; Nancy Hall; Stratos Idreos; Milena Ivanova; Ryan Johnson; David Koop; Tim Kraska; René Müller; Dan Olteanu; Paolo Papotti; Christine Reilly; Dimitris Tsirogiannis; Cong Yu; Juliana Freire; Dennis Shasha,Abstract SIGMOD has offered; since 2008; to verify the experiments published in the papersaccepted at the conference. This year; we have been in charge of reproducing theexperiments provided by the authors (repeatability); and exploring changes to experimentparameters (workability). In this paper; we assess the SIGMOD repeatability process in termsof participation; review process and results. While the participation is stable in terms ofnumber of submissions; we find this year a sharp contrast between the high participationfrom Asian authors and the low participation from American authors. We also find that mostexperiments are distributed as Linux packages accompanied by instructions on how to setupand run the experiments. We are still far from the vision of executable papers.,ACM SIGMOD Record,2011,25
Factorised representations of query results: Size bounds and readability,Dan Olteanu; Jakub Závodný,ABSTRACT We introduce a representation system for relational data based on algebraic factorisationusing distributivity of prod- uct over union and commutativity of product and union. We give twocharacterisations of conjunctive queries based on factorisations of their results whose nestingstructure is defined by so-called factorisation trees. The first characterisation concerns sizes offactorised rep- resentations. For any query; we derive a size bound that is asymptotically tightwithin our class of factorisations. We also characterise the queries by tight bounds on the readabilityof the provenance of result tuples and define syn- tactically the class of queries with boundedreadability … Categories and Subject Descriptors H.2.4 [Database Management]:Systems—Relational Data- bases; Query Processing … Keywords conjunctive queries; datafactorisation; hierarchical queries; provenance; query evaluation; readability; size bounds,Proceedings of the 15th International Conference on Database Theory,2012,22
On factorisation of provenance polynomials,Dan Olteanu; Jakub Závodný,Tracking and managing provenance information in databases has applications inincomplete information and probabilistic databases; query evaluation under bag semantics;view maintenance and update; debugging and explanation; and annotation propagation [2].A recurring observation is that provenance information tends to grow very large with thenumber of data operations: For instance; many records in the Gene Ontology publicdatabase have each over 10MB of provenance data [12]. Practical and theoretical tools arethus necessary to pave the way to efficient management of such large amounts ofprovenance data. A second observation is that the propagation of provenance informationvia queries in databases follows a rather regular pattern; which can be exploited for query-aware provenance compression. These two observations are at the outset of our recently …,USENIX TaPP Workshop,2011,22
Ranking Query Answers in Probabilistic Databases: Complexity and Efficient Algorithms,Dan Olteanu; Hongkai Wen,In many applications of probabilistic databases; the probabilities are mere degrees ofuncertainty in the data and are not otherwise meaningful to the user. Often; users care onlyabout the ranking of answers in decreasing order of their probabilities or about a few mostlikely answers. In this paper; we investigate the problem of ranking query answers inprobabilistic databases. We give a dichotomy for ranking in case of conjunctive querieswithout repeating relation symbols: it is either in polynomial time or NP-hard. Surprisingly;our syntactic characterisation of tractable queries is not the same as for probabilitycomputation. The key observation is that there are queries for which probability computationis\# P-hard; yet ranking can be computed in polynomial time. This is possible wheneverprobability computation for distinct answers has a common factor that is hard to compute …,ICDE,2012,20
Anytime approximation in probabilistic databases,Robert Fink; Jiewen Huang; Dan Olteanu,Abstract This article describes an approximation algorithm for computing the probability ofpropositional formulas over discrete random variables. It incrementally refines lower andupper bounds on the probability of the formulas until the desired absolute or relative errorguarantee is reached. This algorithm is used by the SPROUT query engine to approximatethe probabilities of results to relational algebra queries on expressive probabilisticdatabases.,The VLDB Journal,2013,17
SPROUT 2: a squared query engine for uncertain web data,Robert Fink; Andrew Hogue; Dan Olteanu; Swaroop Rath,Abstract SPROUT² is a query answering system that allows users to ask structured queriesover tables embedded in Web pages; over Google Fusion tables; and over uncertain tablesthat can be extracted from answers to Google Squared. At the core of this service liesSPROUT; a query engine for probabilistic databases. This demonstration allows users tocompose and ask ad-hoc queries of their choice and also to take a tour through the system'scapabilities along pre-arranged scenarios on; eg; movie actors and directors; biomassfacilities; or leveraging corporate databases.,Proceedings of the 2011 ACM SIGMOD International Conference on Management of data,2011,14
Evaluation of XPath queries against XML streams,Dan Olteanu,Abstract XML is nowadays the de facto standard for electronic data interchange on the Web.Available XML data ranges from small Web pages to ever-growing repositories of; eg;biological and astronomical data; and even to rapidly changing and possibly unboundedstreams; as used in Web data integration and publish-subscribe systems. Animated by theubiquity of XML data; the basic task of XML querying is becoming of great theoretical andpractical importance. The last years witnessed efforts as well from practitioners; as also fromtheoreticians towards defining an appropriate XML query language. At the core of thiscommon effort has been identified a navigational approach for information localization inXML data; comprised in a practical and simple query language called XPath. This workbrings together the two aforementioned``worlds''; ie; the XPath query evaluation and the …,*,2005,13
Semistrukturierte Daten,François Bry; Michael Kraus; Dan Olteanu; Sebastian Schaffert,In einer Anfrage an eine solche Adresskartei sollen nicht nur die Texte; Zahlen odersonstige Daten ermittelt werden; die als Inhalte der innersten Elemente vorkommen;sondern auch die Elementnamen; wie ¹Nameª; ¹Einrichtungª oder ¹Kontaktª. Schema-undObjektdaten sollen also in Anfragen nicht wie in traditionellen Anfragesprachen wie SQLunterschiedlich behandelt werden. Wird in einer solchen Adresskartei nach einer E-Mail-Adresse für eine bestimmte Person gesucht; dann kann der Elementname ¹EMailª (oderirgendein Synonym dieses Elementnamens; welches eine sog. Ontologie liefern könnte) anbeliebiger Tiefe gesucht werden. Eine Anfragesprache muss also über Sprachkonstrukteverfügen; die es ermöglichen; eine unbekannte Struktur oder eine unbestimmte Tiefeauszudrücken.,Informatik-Spektrum,2001,12
A dichotomy for non-repeating queries with negation in probabilistic databases,Robert Fink; Dan Olteanu,Abstract This paper shows that any non-repeating conjunctive relational query with negationhas either polynomial time or# P-hard data complexity on tuple-independent probabilisticdatabases. This result extends a dichotomy by Dalvi and Suciu for non-repeatingconjunctive queries to queries with negation. The tractable queries with negation areprecisely the hierarchical ones and can be recognized efficiently.,Proceedings of the 33rd ACM SIGMOD-SIGACT-SIGART symposium on Principles of database systems,2014,9
F: regression models over factorized views,Dan Olteanu; Maximilian Schleich,Abstract We demonstrate F; a system for building regression models over database views. Atits core lies the observation that the computation and representation of materialized views;and in particular of joins; entail non-trivial redundancy that is not necessary for the efficientcomputation of aggregates used for building regression models. F avoids this redundancyby factorizing data and computation and can outperform the state-of-the-art systems MADlib;R; and Python StatsModels by orders of magnitude on real-world datasets. We illustrate howto incrementally build regression models over factorized views using both an in-memoryimplementation of F and its SQL encoding. We also showcase the effective use of F formodel selection: F decouples the data-dependent computation step from the data-independent convergence of model parameters and only performs once the former to …,Proceedings of the VLDB Endowment,2016,8
Dichotomies for queries with negation in probabilistic databases,Robert Fink; Dan Olteanu,Abstract This article charts the tractability frontier of two classes of relational algebra queriesin tuple-independent probabilistic databases. The first class consists of queries with join;projection; selection; and negation but without repeating relation symbols and union. Thesecond class consists of quantified queries that express the following binary relationshipsamong sets of entities: set division; set inclusion; set equivalence; and set incomparability.Quantified queries are expressible in relational algebra using join; projection; nestednegation; and repeating relation symbols. Each query in the two classes has eitherpolynomial-time or &num; P-hard data complexity and the tractable queries can berecognised efficiently. Our result for the first query class extends a known dichotomy forconjunctive queries without self-joins to such queries with negation. For quantified …,ACM Transactions on Database Systems (TODS),2016,8
ENFrame: A platform for processing probabilistic data,Sebastiaan J Van Schaik; Dan Olteanu; Robert Fink,Abstract: This paper introduces ENFrame; a unified data processing platform for queryingand mining probabilistic data. Using ENFrame; users can write programs in a fragment ofPython with constructs such as bounded-range loops; list comprehension; aggregateoperations on lists; and calls to external database engines. The program is then interpretedprobabilistically by ENFrame. The realisation of ENFrame required novel contributions alongseveral directions. We propose an event language that is expressive enough to succinctlyencode arbitrary correlations; trace the computation of user programs; and allow forcomputation of discrete probability distributions of program variables. We exemplifyENFrame on three clustering algorithms: k-means; k-medoids; and Markov Clustering. Weintroduce sequential and distributed algorithms for computing the probability of …,arXiv preprint arXiv:1309.0373,2013,8
G-Store: a storage manager for graph data,Robin Steinhaus; Dan Olteanu; Tim Furche,ABSTRACT Graph data is ubiquitous: Social networks; Semantic Web; pointer analysis insoftware engineering; and biological and chemical networks all rely on a graphrepresentation of data. This paper makes the case for a native storage layer for graph data;rather than relying on relational or columnar stores. We propose a lightweight storagemanager for graph data called G-Store. It exploits the structure of the graph for placement ofdata in pages that is optimized for a wide range of access patterns found in graph queries.Our placement approach partitions the data into pages using a multilevel partitioningalgorithm and arranges the pages on disk to minimize the distance on disk betweenadjacent vertices. Initial experiments show that G-Store can outperform existing graphdatabase solutions by orders of magnitude. We believe that these results justify a …,*,2010,8
Datenströme,François Bry; Tim Furche; Dan Olteanu,In der Forschung über Datenströme werden derzeit drei komplementäre Arten vonDatensätzen betrachtet: Ein Datenstrom wird als eine sehr lange oder ununterbrocheneFolge entweder von Punkten (also skalaren Werten wie Zahlen oder Zeichen) oder vonTupeln oder von XML-Dokumenten (oder so genannten,Informatik-Spektrum,2004,8
Grouping Constructs for Semistructured Data,Francois Bry; Dan Olteanu; Sebastian Schaffert,Abstract Markup languages for semistructured data like XML are of growing importance asmeans for data exchange and storage. In this paper we propose an enhancement for thesemistructured data model that allows to express more semantics. A data model is proposedand the implications on pattern matching are investigated.,*,2001,8
Declarative probabilistic programming with datalog,Vince Bárány; Balder Ten Cate; Benny Kimelfeld; Dan Olteanu; Zografoula Vagena,Abstract Probabilistic programming languages are used for developing statistical models.They typically consist of two components: a specification of a stochastic process (the prior)and a specification of observations that restrict the probability space to a conditionalsubspace (the posterior). Use cases of such formalisms include the development ofalgorithms in machine learning and artificial intelligence. In this article; we establish aprobabilistic-programming extension of Datalog that; on the one hand; allows for defining arich family of statistical models; and on the other hand retains the fundamental properties ofdeclarativity. Our proposed extension provides mechanisms to include common numericalprobability functions; in particular; conclusions of rules may contain values drawn from suchfunctions. The semantics of a program is a probability distribution over the possible …,ACM Transactions on Database Systems (TODS),2017,7
Dagger: clustering correlated uncertain data (to predict asset failure in energy networks),Dan Olteanu; Sebastiaan J van Schaik,DAGger is a clustering algorithm for uncertain data. In con- trast to prior work; DAGger can workon arbitrarily corre- lated data and can compute both exact and approximate clusterings witherror guarantees. We demonstrate DAGger using a real-world scenario in which partial dischargedata from UK Power Networks is clustered to predict asset failure in the energy network … Categoriesand Subject Descriptors H.2.8 [Database Management]: Database Applications— Data mining… Keywords Clustering; classification; uncertain data; probabilistic data; correlations; partialdischarge; dagger … 1. CLUSTERING UNCERTAIN DATA Recent years have witnessed asurge in the amount of digitally-born data. In many scenarios; this data is inher- ently uncertainor probabilistic; such as in automatic data extraction; image and voice detection (eg; processinghand- writing; controlling mobile phones by voice); location detec- tion; sensor networks …,Proceedings of the 18th ACM SIGKDD international conference on Knowledge discovery and data mining,2012,6
Factorized databases,Dan Olteanu; Maximilian Schleich,Abstract This paper overviews factorized databases and their application to machinelearning. The key observation underlying this work is that state-of-the-art relational queryprocessing entails a high degree of redundancy in the computation and representation ofquery results. This redundancy can be avoided and is not necessary for subsequentanalytics such as learning regression models.,ACM SIGMOD Record,2016,5
Parallel OWL 2 RL Materialisation in Centralised; Main-Memory RDF Systems.,Boris Motik; Yavor Nenov; Robert Piro; Ian Horrocks; Dan Olteanu,Abstract. We present a novel approach to parallel materialisation (ie; fixpoint computation) ofOWL RL Knowledge Bases in centralised; main-memory; multicore RDF systems. Ourapproach comprises a datalog reasoning algorithm that evenly distributes the workload tocores; and an RDF indexing data structure that supports efficient;'mostly'lock-free parallelupdates. Our empirical evaluation shows that our approach parallelises computation verywell so; with 16 physical cores; materialisation can be up to 13.9 times faster than with justone core.,Description Logics,2014,5
Live programming in the LogicBlox system: a MetaLogiQL approach,Todd J Green; Dan Olteanu; Geoffrey Washburn,Abstract The emerging category of self-service enterprise applications motivates support for"live programming" in the database; where the user's iterative data exploration triggerschanges to installed application code and its output in real time. This paper discusses thetechnical challenges in supporting live programming in the database and presents thesolution implemented in the LogicBlox commercial system. The workhorse architecturalcomponent is a" meta-engine" that incrementally maintains metadata representingapplication code; guides its compilation into an internal representation in the databasekernel; and orchestrates maintenance of materialized views based on those changes. Ourapproach mirrors LogicBlox's declarative programming model and describes themaintenance of application code using declarative meta-rules; the meta-engine is …,Proceedings of the VLDB Endowment,2015,4
Declarative statistical modeling with Datalog,Vince Barany; Balder ten Cate; Benny Kimelfeld; Dan Olteanu; Zografoula Vagena,Abstract: Formalisms for specifying statistical models; such as probabilistic-programminglanguages; typically consist of two components: a specification of a stochastic process (theprior); and a specification of observations that restrict the probability space to a conditionalsubspace (the posterior). Use cases of such formalisms include the development ofalgorithms in machine learning and artificial intelligence. We propose and investigate adeclarative framework for specifying statistical models on top of a database; through anappropriate extension of Datalog. By virtue of extending Datalog; our framework offers anatural integration with the database; and has a robust declarative semantics. Our Datalogextension provides convenient mechanisms to include numerical probability functions; inparticular; conclusions of rules may contain values drawn from such functions. The …,arXiv preprint arXiv:1412.2221,2014,4
Πgora: An integration system for probabilistic data,Dan Olteanu; Lampros Papageorgiou; Sebastiaan J Van Schaik,Πgora is an integration system for probabilistic data modelled using different formalismssuch as pc-tables; Bayesian networks; and stochastic automata. User queries are expressedover a global relational layer and are evaluated by Πgora using a range of strategies;including data conversion into one probabilistic formalism followed by evaluation using aformalism-specific engine; and hybrid plans; where subqueries are evaluated using enginesfor different formalisms. This demonstration allows users to experience Πgora on real-worldheterogeneous data sources from the medical domain.,Data Engineering (ICDE); 2013 IEEE 29th International Conference on,2013,4
Factorised representations of query results,Dan Olteanu; Jakub Zavodny,Abstract: Query tractability has been traditionally defined as a function of input database andquery sizes; or of both input and output sizes; where the query result is represented as a bagof tuples. In this report; we introduce a framework that allows to investigate tractabilitybeyond this setting. The key insight is that; although the cardinality of a query result can beexponential; its structure can be very regular and thus factorisable into a nestedrepresentation whose size is only polynomial in the size of both the input database andquery. For a given query result; there may be several equivalent representations; and wequantify the regularity of the result by its readability; which is the minimum over all itsrepresentations of the maximum number of occurrences of any tuple in that representation.We give a characterisation of select-project-join queries based on the bounds on …,arXiv preprint arXiv:1104.0867,2011,3
„Big Data “,Georg Gottlob; Giovanni Gr Asso; Dan Olte Anu; Christian Schallhart,This volume contains the papers presented at BNCOD 2013: 29th British NationalConference on Databases held during July 7–9; 2013; in Oxford. The BNCOD Conference isa venue for the presentation and discussion of research papers on a broad range of topicsrelated to data-centric computation. For some years; every edition of BNCOD has centeredaround a main theme; acting as a focal point for keynote addresses; tutorials; and researchpapers. The theme of BNCOD 2013 is Big Data. It encompases a growing need to managedata that is too big; too fast; or too hard for the existing technology. This year; BNCODattracted 42 complete submissions from 14 different African; European; South and NorthAmerican countries. Each submission was reviewed by three Program Committee members.The committee decided to accept 20 papers on such topics as query and update …,*,2013,2
Demonstration of the FDB query engine for factorised databases,Nurzhan Bakibayev; Dan Olteanu; Jakub Závodný,1. FACTORISED DATABASES The thesis underlying factorised databases is that rela- tionaldatabases can admit compact representations by alge- braic factorisation using distributivityof product over union. This is similar in spirit to the relationship between logic functions in disjunctivenormal form and their equivalent nested forms obtained by algebraic factorisation. In earlier work[7] we give a complete characterisation of the com- pactness of factorised results forselect-project-join queries on relational databases and show that the gap between the sizesof query results and of their factorised representations can be exponential. In particular; thereare arbitrarily large queries for which the query results have sizes exponential in the query sizeyet their factorised representations only have sizes bounded by the input database size. A similarexpo- nential gap holds between the times needed to compute from the input relational …,Proceedings of the VLDB Endowment,2012,2
In-database factorized learning,Hung Q Ngo; XuanLong Nguyen; Dan Olteanu; Maximilian Schleich,In this paper; we overview recent contributions on in-database analytics for a class ofoptimization problems that are important for LogicBlox retail-planning and forecastingapplications [4; 5; 7]. The class includes ridge linear regression; polynomial regression;factorization machines; principal component analysis and classification models. Suchproblems are typically computed over input data defined by a feature extraction join queryon data sources residing inside a database. The query result can have a large number ofattributes and records; which leads to large compute times or failure to process the entiredataset for conventional analytics engines. Pushing analytical computation inside thedatabase engine saves non-trivial time usually spent on data import/export at the interfacebetween database systems and statistical packages. In addition; a large part of the …,*,2017,1
In-database learning with sparse tensors,Hung Q Ngo; XuanLong Nguyen; Dan Olteanu; Maximilian Schleich,Abstract: We introduce a unified framework for a class of optimization based statisticallearning problems used by LogicBlox retail-planning and forecasting applications; where theinput data is given by queries over relational databases. This class includes ridge linearregression; polynomial regression; factorization machines; and principal componentanalysis. The main challenge posed by computing these problems is the large number ofrecords and of categorical features in the input data; which leads to very large computetimes or failure to process the entire data. We address this challenge with two orthogonalcontributions. First; we introduce a sparse tensor representation and computation frameworkthat allows for space and time complexity reduction when dealing with feature extractionqueries that have categorical variables. Second; we exploit functional dependencies …,arXiv preprint arXiv:1703.04780,2017,1
ENFrame: a framework for processing probabilistic data,Dan Olteanu; Sebastiaan J Van Schaik,Abstract This article introduces ENFrame; a framework for processing probabilistic data.Using ENFrame; users can write programs in a fragment of Python with constructs such asloops; list comprehension; aggregate operations on lists; and calls to external databaseengines. Programs are then interpreted probabilistically by ENFrame. We exemplifyENFrame on three clustering algorithms (k-means; k-medoids; and Markov clustering) andone classification algorithm (k-nearest-neighbour). A key component of ENFrame is an eventlanguage to succinctly encode correlations; trace the computation of user programs; andallow for computation of discrete probability distributions for program variables. We proposea family of sequential and concurrent; exact; and approximate algorithms for computing theprobability of interconnected events. Experiments with k-medoids clustering and k …,ACM Transactions on Database Systems (TODS),2016,1
Factorized Databases: A Knowledge Compilation Perspective.,Dan Olteanu,Abstract This paper overviews recent work on compilation of relational queries into losslessfactorized representations. The primary motivation for this compilation is to avoidredundancy in the representation of query results and speed up their computation andsubsequent analytics.,AAAI Workshop: Beyond NP,2016,1
SOMM: industry oriented ontology management tool,Evgeny Kharlamov; Bernardo Cuenca Grau; Ernesto Jimenez-Ruiz; Steffen Lamparter; Gulnar Mehdi; Martin Ringsquandl; Yavor Nenov; Stephan Grimm; Mikhail Roshchin; Ian Horrocks; Evgeny Kharlamov; Bernardo Cuenca Grau; Ernesto Jimenez-Ruiz; Steffen Lamparter; Gulnar Mehdi; Martin Ringsquandl; Yavor Nenov; Stephan Grimm; Mikhail Roshchin; Ian Horrocks; Yujiao Zhou; Bernardo Cuenca Grau; Yavor Nenov; Mark Kaminski; Ian Horrocks; Yavor Nenov; Robert Piro; Boris Motik; Ian Horrocks; Zhe Wu; Jay Banerjee; Yujiao Zhou; Yavor Nenov; Bernardo Cuenca Grau; Ian Horrocks; Boris Motik; Yavor Nenov; Robert Piro; Ian Horrocks; Yujiao Zhou; Bernardo Cuenca Grau; Yavor Nenov; Ian Horrocks; Boris Motik; Yavor Nenov; Robert Edgar Felix Piro; Ian Horrocks; Boris Motik; Yavor Nenov; Robert Edgar Felix Piro; Ian Horrocks; Yujiao Zhou; Yavor Nenov; Bernardo Cuenca Grau; Ian Horrocks; Yujiao Zhou; Yavor Nenov; Bernardo Cuenca Grau; Ian Horrocks; Mark Kaminski; Yavor Nenov; Bernardo Cuenca Grau; Mark Kaminski; Yavor Nenov; Bernardo Cuenca Grau; Mark Kaminski; Yavor Nenov; Bernardo Cuenca Grau; Boris Motik; Yavor Nenov; Robert Piro; Ian Horrocks; Dan Olteanu; Boris Motik; Yavor Nenov; Robert Piro; Ian Horrocks; Dan Olteanu; Yujiao Zhou; Yavor Nenov; Bernardo Cuenca Grau; Ian Horrocks; Yavor Nenov,Publications; by bibtex; Department of Computer Science; Oxford; Yavor Nenov.,Proc. of International Semantic Web Conference (ISWC); Posters and Demonstrations Track,2015,1
PPDL: probabilistic programming with Datalog,Balder ten Cate; Benny Kimelfeld; Dan Olteanu,There has been a substantial recent focus on the concept of probabilistic programming [6]towards its positioning as a prominent paradigm for advancing and facilitating thedevelopment of machine-learning applications. 4 A probabilisticprogramming languagetypically consists of two components: a specification of a stochastic process (the prior); and aspecification of observations that restrict the probability space to a conditional subspace (theposterior). This paper gives a brief overview of Probabilistic Programming DataLog (PPDL);a recently proposed declarative framework for specifying statistical models on top of adatabase; through an appropriate extension of Datalog [1]. By virtue of extending Datalog;PPDL offers a natural integration with the database; and has a robust declarative semantics;that is; semantic independence from the algorithmic evaluation of rules; and semantic …,Alberto Mendelzon International Workshop on Foundations of Data Management,2015,1
Probabilistic Data Programming with ENFrame.,Dan Olteanu; Sebastiaan J van Schaik,Abstract This paper overviews ENFrame; a programming framework for probabilistic data. Inaddition to relational query processing supported via an existing probabilistic databasemanagement system; ENFrame allows programming with loops; assignments; conditionals;list comprehension; and aggregates to encode complex tasks such as clustering andclassification of probabilistic data. We explain the design choices behind ENFrame; somedistilled from the wealth of work on probabilistic databases and some new. We also highlighta few challenges lying ahead.,IEEE Data Eng. Bull.,2014,1
Report on the first Workshop on Innovative Querying of Streams,Michael Benedikt; Dan Olteanu,INnovative QUErying of STreams (INQUEST) was held on September 25-27; 2012 in theDepartment of Computer Science of the University of Oxford (UK). It was sponsored by theUK's Engineering and Physical Sciences Research Council (EPSRC); as part of the project“Enforcement of Constraints on XML Streams”. Stream processing represents a thriving areaof research across the algorithms; databases; networking; programming languages; andsystems research communities. Within the database community; a “classical” problem isquery processing on streams of discrete tuple-oriented data. One goal of the workshopconsiders the way recent developments add complexity to this problem:• how does thesetting change when data to be considered by queries is not relational; but has nestedstructure; such as XML or JSON?• conversely; how does the setting change when data to …,ACM SIGMOD Record,2013,1
Incremental view maintenance with triple lock factorisation benefits,M Nikolic; DA Olteanu,Abstract: We introduce F-IVM; a unified incremental view maintenance (IVM) approach for avariety of tasks; including gradient computation for learning linear regression models overjoins; matrix chain multiplication; and factorized evaluation of conjunctive queries. F-IVM is ahigher-order IVM algorithm that reduces the maintenance of the given task to themaintenance of a hierarchy of increasingly simpler views. The views are functions mappingkeys; which are tuples of input data values; to payloads; which are elements from a task-specific ring. Whereas the computation over the keys is the same for all tasks; thecomputation over the payloads depends on the task. F-IVM achieves efficiency by factorizingthe computation of the keys; payloads; and updates. We implemented F-IVM as an extensionof DBToaster. We show in a range of scenarios that it can outperform classical first-order …,*,2018,*
Boolean Tensor Decomposition for Conjunctive Queries with Negation,Mahmoud Abo Khamis; Hung Q Ngo; Dan Olteanu; Dan Suciu,Abstract: We propose an algorithm for answering conjunctive queries with negation; wherethe negated relations are sparse. Its data complexity matches that of the best knownalgorithms for the positive subquery of the input query and is expressed in terms of thefractional hypertree width and the submodular width. The query complexity depends on thestructure of the negated subquery; in general it is exponential in the number of join variablesoccurring in negated relations yet it becomes polynomial for several classes of queries. Thisalgorithm relies on several contributions. We show how to rewrite queries with negation onsparse relations into equivalent conjunctive queries with not-all-equal (NAE) predicates;which are a multi-dimensional analog of disequality. We then generalize the known color-coding technique to conjunctions of NAE predicates and explain it via a Boolean tensor …,arXiv preprint arXiv:1712.07445,2017,*
Special issue on in-database analytics,Dan Olteanu; Florin Rusu,Recent years have witnessed a sustained effort towards big data analytics; such asregression; classification; and recommendation; on massive datasets of varied types andformats. Although most of the methods to perform these tasks have been studied before inmachine learning and data mining; scalability and generality have risen as primarychallenges not addressed before. As a result; many libraries; frameworks; and platformshave been recently developed to provide scalable support for distributed and parallelstatistical analytics. While mostly scalable; several of the newly proposed approaches fallshort on generality. In-database solutions seek to reuse and extend the query language andprocessing infrastructure of a database system with generic constructs and operatorsrequired to perform these considerably more complicated tasks. They are generic; but not …,Distributed and Parallel Databases,2017,*
Covers of Query Results,Ahmet Kara; Dan Olteanu,Abstract: We introduce succinct lossless representations of query results called covers thatare subsets of these results; yet allow for constant-delay enumeration of all result tuples. Wefirst study covers whose structures are given by hypertree decompositions of join queries.For any join query; we give asymptotically tight size bounds for the covers of the queryresults and show that such covers can be computed in worst-case optimal time (up to alogarithmic factor in the database size). For acyclic join queries; we can compute coverscompositionally from covers for subqueries using plans with a new operator called cover-join.,arXiv preprint arXiv:1709.01600,2017,*
Technical perspective: Juggling functions inside a database,Dan Olteanu,The paper entitled” Juggling Functions Inside a Database” gives a brief overview of FAQ; aframework for computational problems expressed as Functional Aggregate Queries. Thiswork falls into my bucket of select database research contributions that go significantlybeyond the state of the art along several dimensions. First; it provides an elegant anddeclarative formalism for a host of ubiquituous computational problems across ComputerScience and at the right level of abstraction that exposes structural properties of the probleminstances and allows for fine-grained complexity analysis. Second; it is technically deep;proposing an algorithmic solution that achieves lower than or the same complexity asspecialized approaches in their respective domain. Third; it is implemented in a commercialdatabase system with scores of real-world applications. Fourth; it is currently under …,*,2017,*
Incremental Maintenance of Regression Models over Joins,Milos Nikolic; Dan Olteanu,Abstract: This paper introduces a principled incremental view maintenance (IVM)mechanism for in-database computation described by rings. We exemplify our approach byintroducing the covariance matrix ring that we use for learning linear regression models overarbitrary equi-join queries. Our approach is a higher-order IVM algorithm that exploits thefactorized structure of joins and aggregates to avoid redundant computation and improveperformance. We implemented it in DBToaster; which uses program synthesis to generatehigh-performance maintenance code. We experimentally show that it can outperform first-order and fully recursive higher-order IVM as well as recomputation by orders of magnitudewhile using less memory.,arXiv preprint arXiv:1703.07484,2017,*
In-Database Learning with Sparse Tensors,Mahmoud Abo Khamis; Hung Ngo; XuanLong Nguyen; Dan Olteanu; Maximilian Schleich,ABSTRACT In-database analytics is of great practical importance as it avoids the costlyrepeated loop data scientists have to deal with on a daily basis: select features; export thedata; convert data format; train models using an external tool; reimport the parameters. It isalso a fertile ground of theoretically fundamental and challenging problems at theintersection of relational and statistical data models. This paper introduces a unifiedframework for training and evaluating a class of statistical learning models inside a relationaldatabase. This class includes ridge linear regression; polynomial regression; factorizationmachines; and principal component analysis. We show that; by synergizing key tools fromrelational database theory such as schema information; query structure; recent advances inquery evaluation algorithms; and from linear algebra such as various tensor and matrix …,arXiv preprint arXiv:1703.04780,2017,*
Factorized Databases: Past and Future Past.,Dan Olteanu,Abstract. In this talk I will overview the FDB project at Oxford on succinct; losslessrepresentations of relational data that I call factorized databases. I will first present acharacterization of the succinctness of results to conjunctive queries and how factorizationscan speed up query processing. I will then comment on how this succinctnesscharacterization relates to seemingly disparate results on: readability of provenancepolynomials; representation systems for incomplete information; one-pass query evaluationusing finite cursor machines; tractability in probabilistic databases; and parallel queryevaluation with one synchronization step. I will conclude with two near-future projects thatbrought me back to factorized data representations: scalable machine learning overrelational data and distributed database systems with low communication cost.,AMW,2015,*
Evaluation of relational algebra queries on probabilistic databases: tractability and approximation,Dan Olteanu,Abstract: Query processing is a core task in probabilistic databases: Given a query and adatabase that encodes uncertainty in data by means of probability distributions; the problemis to compute possible query answers together with their respective probabilities of beingcorrect. This thesis advances the state of the art in two aspects of query processing inprobabilistic databases: complexity analysis and query evaluation techniques. A dichotomyis established for non-repeating; con-junctive relational algebra queries with negation thatseparates# P-hard queries from those with PTIME data complexity. A framework forcomputing proba-bilities of relational algebra queries is presented; the probabilitycomputation algorithm is based on decomposition methods and provides exact answers inthe case of exhaustive decompositions; or anytime approximate answers with absolute or …,*,2014,*
A framework for processing correlated probabilistic data,Dan Olteanu,Abstract: The amount of digitally-born data has surged in recent years. In many scenarios;this data is inherently uncertain (or: probabilistic); such as data originating from sensornetworks; image and voice recognition; location detection; and automated web dataextraction. Probabilistic data requires novel and different approaches to data mining andanalysis; which explicitly account for the uncertainty and the correlations therein.,*,2014,*
Factorisation in relational databases,Dan Olteanu,Abstract: We study representation systems for relational data based on relational algebraexpressions with unions; products; and singleton relations. Algebraic factorisation using thedistributivity of product over union allows succinct representation of many-to-manyrelationships; further succinctness is brought by sharing repeated subexpressions. We showthat these techniques are especially applicable to results of conjunctive queries.,*,2014,*
1. IMPORTANT DATES,Carmen Tang,It is widely understood that China shelters one of the richest mycofloras in the world. Thevariety of ecological zones; topological relief; and geographical extent supports this fact. Theoldest and largest mycological collection in the country is that maintained at the Institute ofMicrobiology; Academia Sinica; in Beijing. The Beijing herbarium (acronym: HMAS) wasestablished in 1953 and now houses over 75;000 specimens of fungi. The rapiddevelopment of mycology in China during the last two decades has not been brought tointernational attention (but see Bartholomew; Brittonia 3 1: 1-25; 1979; Ma; Taxon 38: 617-620; 1989). It is a pleasure; therefore; to introduce the mycological herbarium at Kunming;Yunnan; and to welcome foreign visitors and loan requests.,*,2013,*
Updates in Factorised Databases,Laura Draghici; Dan Olteanu,Abstract Factorised databases are relational databases that use compact factorisedrepresentations at the physical layer to reduce data redundancy and boost queryperformance. Succinctness is achieved by algebraic factorisation using distributivity ofproduct over union and commutativity of product and union. Factorised databases use the so-called factorisation trees to define the structure of their representations. This thesis studiesthe problem of updates (insertion/value modification/deletion) in the context of suchdatabases. We study two types of insertions. We first discuss an algorithm that inserts a tupleinto a factorised representation. We also propose and experimentally compare threealgorithms for bulk insertion which; in the context of factorised databases; is defined as theconstruction of a factorised representation for the relation consisting of the tuples to be …,*,2013,*
Big Data: 29th British National Conference on Databases; BNCOD 2013; Oxford; UK; July 8-10; 2013. Proceedings,Dan Olteanu; Georg Gottlob; Christian Schallhart,This book constitutes the thoroughly refereed post-conference proceedings of the 29thBritish National Conference on Databases; BNCOD 2013; held in Oxford; UK; in July 2013.The 20 revised full papers; presented together with three keynote talks; two tutorials; andone panel session; were carefully reviewed and selected from 42 submissions. Specialfocus of the conference has been" Big Data" and so the papers cover a wide range of topicssuch as query and update processing; relational storage; benchmarking; XML queryprocessing; big data; spatial data and indexing; data extraction and social networks.,*,2013,*
VLDB Endowment,Michael Böhlen; Christoph Koch; Ashraf Aboulnaga; Sihem Amer‐Yahia; Chee Yong Chan; Yanlei Diao; Ada Waichee Fu; Johannes Gehrke; Alon Halevy; Jayant Haritsa; Nikos Mamoulis; Thomas Neumann; Dan Olteanu; Divesh Srivastava; Jens Teubner; Stefan Manegold; Peer Kröger; Stratis D Viglas,39th International Conference on Very Large Data Bases; Riva del Garda; Trento; Italy … Proceedingsof the 39th International Conference on … Very Large Data Bases; Riva del Garda; Trento; Italy… Ashraf Aboulnaga; Sihem Amer‐Yahia; Chee Yong Chan; Yanlei Diao; Ada Waichee Fu;Johannes Gehrke; Alon Halevy; Jayant Haritsa; Nikos Mamoulis; Thomas Neumann; DanOlteanu; Divesh Srivastava; Jens Teubner … The 39th International Conference on Very LargeData Bases; Riva del Garda; Trento; Italy … Permission to make digital or hard copies of portionsof this work for personal or classroom use is granted without fee provided that copies are notmade or distributed for profit or commercial advantage and that copies bear this notice and thefull citation on the first page. Copyright for components of this work owned by others than VLDBEndowment must be honored. Abstracting with credit is permitted. To copy otherwise; to …,*,2013,*
DAGger: Clustering Correlated Uncertain Data,Dan Olteanu; Sebastiaan J van Schaik,ABSTRACT DAGger is a clustering algorithm for uncertain data. In contrast to prior work;DAGger can work on arbitrarily correlated data and can compute both exact andapproximate clusterings with error guarantees. We demonstrate DAGger using a real-worldscenario in which partial discharge data from UK Power Networks is clustered to predictasset failure in the energy network.,Proceedings of the 18th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining ‚KDD'12 ‚Beijing ‚China ‚August 12− 16 ‚2012,2012,*
Working Group: Classification; Representation and Modeling.,S Das; C Koch; B König-Ries; Ander de Keijzer; V Markl; A Deshpande; M van Keulen; PJ Haas; IF Ilyas; T Neumann; D Olteanu; M Theobald; V Vassalos,KNAW Narcis. Back to search results. Publication Working Group: Classification;Representation and Modeling. (2009). Pagina-navigatie: Main …,*,2009,*
Report of the Probabilistic Databases Benchmarking: 08421 Working Group,C Koch; C Re; D Olteanu; H-J Lenz; PJ Haas; JZ Pan; B König-Ries; V Markl,*,*,2009,*
08421 Working Group: Report of the Probabilistic Databases Benchmarking,Christoph Koch; C Re; D Olteanu; HJ Lenz; PJ Haas; JZ Pan,Koch; C.; Re; C.; Olteanu; D.; Lenz; HJ; Haas; PJ; & Pan; JZ (2009). 08421 Working Group: Reportof the Probabilistic Databases Benchmarking. In C. Koch; B. König-Ries; V. Markl; & M. van Keulen(Eds.); Proceedings of Dagstuhl Seminar 08421 on Uncertainty Management in Information Systems(pp. -). (Dagstuhl Seminar Proceedings; No. 08421). Dagstuhl; Germany: Schloss Dagstuhl -Leibniz-Zentrum fuer Informatik … Koch; C.; Re; C.; Olteanu; D.; Lenz; HJ; Haas; PJ; Pan; JZ/ 08421 Working Group: Report of the Probabilistic Databases Benchmarking … Proceedingsof Dagstuhl Seminar 08421 on Uncertainty Management in Information Systems. ed. / C.Koch; B. König-Ries; V. Markl; Maurice van Keulen. Dagstuhl; Germany : Schloss Dagstuhl -Leibniz-Zentrum fuer Informatik; 2009. p. - (Dagstuhl Seminar Proceedings; No. 08421) …Koch; C; Re; C; Olteanu; D; Lenz; HJ; Haas; PJ & Pan; JZ 2009; 08421 Working Group …,Uncertainty Management in Information Systems: Dagstuhl Seminar 08421,2009,*
A Toolbox of Query Evaluation Techniques for Probabilistic Databases,Dan Olteanu,We study the problem of query evaluation in probabilistic databases and survey some of themost promising existing techniques recently proposed by the database community. Althoughthis problem is subsumed by general probabilistic inference; we argue that two fundamentalaspects of databases; that is;(i) the separation of (very large) data and (small and fixed)query; and (ii) the use of mature relational query engines; can lead to more scalabletechniques. We survey both exact and approximate query evaluation techniques. In case ofexact evaluation; we discuss syntactical restrictions of the language of conjunctive querieswith inequalities; under which the queries become tractable [2; 6](in general; the problem is#P-hard [1]). For these queries; we also show how relational query plans extended withefficient aggregation operators can be successfully used to evaluate them [1; 7]. At their …,Logic in Databases (LID 2009),2009,*
08421 Working Group: Classification; Representation and Modeling,Anish Das Sarma; Ander de Keijzer; Amol Deshpande; Peter J Haas; Ihab F Ilyas; Christoph Koch; Thomas Neumann; Dan Olteanu; Martin Theobald; Vasilis Vassalos,Abstract This report briefly summarizes the discussions carried out in the working group onclassification; representation and modeling of uncertain data. The discussion was dividedinto two subgroups: the first subgroup studied how different representation and modelingalternatives currently proposed can fit in a bigger picture of theory and technologyinteraction; while the second subgroup focused on contrasting current systemimplementations and the reasons behind such diverse class of available prototypes. Wesummarize the findings of these two groups and the future steps suggested by groupmembers.,Dagstuhl Seminar Proceedings,2009,*
08421 Working Group: Classification; Representation and Modeling.,Anish Das Sarma; Ander de Keijzer; Amol Deshpande; Peter J Haas; Ihab F Ilyas; Christoph Koch; Thomas Neumann; Dan Olteanu; Martin Theobald; Vasilis Vassalos,*,Uncertainty Management in Information Systems,2008,*
MayBMS: A Possible Worlds Base Management System,Lyublena Antova; Christoph Koch; Dan Olteanu,Incomplete information is frequent in real-world applications. This is often the case in dataintegration scenarios; in scientific data collections; or whenever the information is acquiredusing human interaction and is erroneous or imperfect. The different interpretations ofincomplete information yield different possible worlds. A system for managing incompletedata faces the challenge of being able to represent large sets of possible worlds compactly;while at the same time supporting efficient processing of the data. Nevertheless; there hasbeen little research so far into expressive yet scalable systems for managing incompleteinformation. Most current representation models have at least one of two flaws; some of them(such as or-set relations and v-tables) are not strong enough to represent query answerswithin the same formalism; and other (such as the c-tables) are strong enough but …,*,2006,*
Accelerating XPath Evaluation against XML Streams,Dan Olteanu,XML has emerged as the de facto standard for data interchange. One reason for itspopularity is that it defines a standard mechanism for structuring data as ordered; labeledtrees. The utility of XML as an application integration mechanism is enhanced wheninteracting applications agree on the structure and vocabulary of labels of the XML datainterchanged. This requirement has led to the development of the XML Schemastandard—an XML Schema specifies a set of XML documents whose vocabulary and structure satisfyconstraints in the XML Schema. Despite the increased importance of XML; the availablefacilities for processing XML in current programming languages are primitive. Programmersoften use runtime APIs such as DOM [6]; which builds an inmemory tree from an XMLdocument; or SAX [5]; where an XML document parser raises events that are handled by …,PLAN-X 2006 Informal Proceedings,2006,*
Building a Native XML-DBMS as a Term Project in a Database Systems Course,Christoph Koch; Dan Olteanu; Stefanie Scherzinger,This is to report on a database systems course the first author held in the summer semesterof 2005 at Saarland University; Saarbrücken; Germany. This course was an experiment inseveral respects. For one; we wanted to teach a systems course with a practical part inwhich students apply the material taught to build the core of a database managementsystem. Such a systems building effort seems to be quite common in top-tier US universities;but it is rare in Europe. One main reason for this is that European curricula often requirestudents to take many small courses per term. Students then cannot be required to invest thetime necessary for such a systems-building effort into an individual course. In Saarbrücken;this fortunately does not apply and students are expected to take only about two maincourses per term.(The database systems course in Saarbrücken is worth 9 points in the …,*,2006,*
Markup Sprachen und semi-strukturierte Daten,Dan Olteanu,Node type Built-in template rule root call< xsl: apply-templates> to process its children.element call< xsl: apply-templates> to process its children. attribute copy the attribute valueto the result tree. text copy the text to the result tree. commment do nothing. pi do nothing.namespace do nothing.,*,*,*
MayBMS: A Probabilistic DBMS,Jiewen Huang; Lyublena Antova; Christoph Koch; Dan Olteanu,Page 1. MayBMS: A Probabilistic DBMS Jiewen Huang ∗;∗∗ ; Lyublena Antova ∗ ; ChristophKoch ∗ ; and Dan Olteanu ∗∗ ∗ Cornell University ∗∗ Oxford University Example: random graphsGoal: Compute the probability that a random graph contains a triangle. T uv bit p 1 2 1 .5 1 2 0.5 1 3 1 .5 1 3 0 .5 2 3 1 .5 2 3 0 .5 create table E as select Qu; Qv from (repair key (u;v) in T weightby p) Q where Q.bit = 1; 8 possible worlds; one has a triangle. E not given as symmetric relation;but as subset of total order. select conf() as triangle_prob from E e1; E e2; E e3 where e1.v =e2.u and e2.v = e3.v and e1.u = e3.u and e1.u < e2.u and e2.u < e3.v; triangle_prob 0.125 Example:hypothetical queries Suppose I buy a company and exactly one em- ployee leaves. Which skillsdo I gain for certain? CE CID EID Google Bob Google Joe Yahoo Dan Yahoo Bill Yahoo FredES EID Skill Bob Web Joe Web Dan Java Dan Web …,*,*,*
Demo Program Committee,Sihem Amer-Yahia; Arvind Arasu; Sunil Arvindam; Magdalena Balazinska; Fabio Casati; Malu Castellanos; Mariano Cilia; Brian F Cooper; Adina Crainiceanu; Abhinandan Das; Alin Dobra; Pablo Guerrero; Christian Konig; Georgia Koutrika; Wolfgang Lehner; Feifei Li; Ashwin Machanavajjhala; Thomas Neumann; Dan Olteanu; Carlos Ordonez; Peter Pietzuch; Adam Silberstein; Alkis Simitsis,Sihem Amer-Yahia; Qatar Computing Research Institute Arvind Arasu; Microsoft Research SunilArvindam; SAP Research; India Magdalena Balazinska; University of Washington FabioCasati; University of Trento; Italy Malu Castellanos; HP Labs; USA Mariano Cilia; IntelCorporation; Argentina Brian F Cooper; Google Adina Crainiceanu; US Naval Academy AbhinandanDas; Google Alin Dobra; University of Florida Javier Garcia-Garcia; UNAM University; MexicoPablo Guerrero; TU Darmstadt; Germany Melanie Herschel; Tubingen University ChristianKonig; Microsoft Research Georgia Koutrika; IBM Almaden Research Center WolfgangLehner; TU Dresden; Germany Feifei Li; Florida State University Ashwin Machanavajjhala; YahooResearch Thomas Neumann; TU Munchen Dan Olteanu; University of Oxford CarlosOrdonez; University of Houston Peter Pietzuch; Imperial College London Lin Qiao; IBM …,*,*,*
On Efficiently Evaluating Inequality Queries on Probabilistic Databases and Counting Vertex Covers,Rasmus Wissmann; Dan Olteanu,ABSTRACT The problem of efficient evaluation of queries on probabilistic databases hasreceived a great attention in recent years. In this paper; we introduce a class of queries withinequalities (<;≤) and self-joins that admit tractable evaluation; in the context where queryevaluation is# P-hard in general. This class strictly contains the class of inequality queriesrecently introduced by Olteanu and Huang. We also show that particular tractable instancesof our problem capture previously-open problems of counting vertex covers in chain andconvex bipartite graphs; for which we can now easily derive efficient algorithms. Ourapproach to both query evaluation and counting vertex covers is based on a novelsyntactical characterization of k-DNF formulas that capture the lineage of our tractablequeries and that can be compiled in at most quadratic time into binary decision diagrams …,*,*,*
