MapReduce online,Tyson Condie; Neil Conway; Peter Alvaro; Joseph M Hellerstein; Khaled Elmeleegy; Russell Sears,Abstract MapReduce is a popular framework for data-intensive distributed computing ofbatch jobs. To simplify fault tolerance; many implementations of MapReduce materialize theentire output of each map and reduce task before it can be consumed. In this paper; wepropose a modified MapReduce architecture that allows data to be pipelined betweenoperators. This extends the MapReduce programming model beyond batch processing; andcan reduce completion times and improve system utilization for batch jobs as well. Wepresent a modified version of the Hadoop MapReduce framework that supports onlineaggregation; which allows users to see “early returns” from a job as it is being computed.Our Hadoop Online Prototype (HOP) also supports continuous queries; which enableMapReduce programs to be written for applications such as event monitoring and stream …,Proceedings of the 7th USENIX conference on Networked systems design and implementation,2010,899
Online aggregation and continuous query support in mapreduce,Tyson Condie; Neil Conway; Peter Alvaro; Joseph M Hellerstein; John Gerth; Justin Talbot; Khaled Elmeleegy; Russell Sears,Abstract MapReduce is a popular framework for data-intensive distributed computing ofbatch jobs. To simplify fault tolerance; the output of each MapReduce task and job ismaterialized to disk before it is consumed. In this demonstration; we describe a modifiedMapReduce architecture that allows data to be pipelined between operators. This extendsthe MapReduce programming model beyond batch processing; and can reduce completiontimes and improve system utilization for batch jobs as well. We demonstrate a modifiedversion of the Hadoop MapReduce framework that supports online aggregation; whichallows users to see" early returns" from a job as it is being computed. Our Hadoop OnlinePrototype (HOP) also supports continuous queries; which enable MapReduce programs tobe written for applications such as event monitoring and stream processing. HOP retains …,Proceedings of the 2010 ACM SIGMOD International Conference on Management of data,2010,164
Consistency Analysis in Bloom: a CALM and Collected Approach.,Peter Alvaro; Neil Conway; Joseph M Hellerstein; William R Marczak,ABSTRACT Distributed programming has become a topic of widespread interest; and manyprogrammers now wrestle with tradeoffs between data consistency; availability and latency.Distributed transactions are often rejected as an undesirable tradeoff today; but in theabsence of transactions there are few concrete principles or tools to help programmersdesign and verify the correctness of their applications. We address this situation with theCALM principle; which connects the idea of distributed consistency to program tests forlogical monotonicity. We then introduce Bloom; a distributed programming language that isamenable to high-level consistency analysis and encourages order-insensitiveprogramming. We present a prototype implementation of Bloom as a domain-specificlanguage in Ruby. We also propose a program analysis technique that identifies points of …,CIDR,2011,148
Boom analytics: exploring data-centric; declarative programming for the cloud,Peter Alvaro; Tyson Condie; Neil Conway; Khaled Elmeleegy; Joseph M Hellerstein; Russell Sears,Abstract Building and debugging distributed software remains extremely difficult. Weconjecture that by adopting a data-centric approach to system design and by employingdeclarative programming languages; a broad range of distributed software can be recastnaturally in a data-parallel programming model. Our hope is that this model can significantlyraise the level of abstraction for programmers; improving code simplicity; speed ofdevelopment; ease of software evolution; and program correctness. This paper presents ourexperience with an initial large-scale experiment in this direction. First; we used the Overloglanguage to implement a" Big Data" analytics stack that is API-compatible with Hadoop andHDFS and provides comparable performance. Second; we extended the system withcomplex distributed features not yet available in Hadoop; including high availability …,Proceedings of the 5th European conference on Computer systems,2010,128
Dedalus: Datalog in time and space,Peter Alvaro; William R Marczak; Neil Conway; Joseph M Hellerstein; David Maier; Russell Sears,Abstract Recent research has explored using Datalog-based languages to express adistributed system as a set of logical invariants. Two properties of distributed systems proveddifficult to model in Datalog. First; the state of any such system evolves with its execution.Second; deductions in these systems may be arbitrarily delayed; dropped; or reordered bythe unreliable network links they must traverse. Previous efforts addressed the former byextending Datalog to include updates; key constraints; persistence and events; and the latterby assuming ordered and reliable delivery while ignoring delay. These details have asemantics outside Datalog; which increases the complexity of the language and itsinterpretation; and forces programmers to think operationally. We argue that the missingcomponent from these previous languages is a notion of time. In this paper we present …,*,2011,112
Logic and lattices for distributed programming,Neil Conway; William R Marczak; Peter Alvaro; Joseph M Hellerstein; David Maier,Abstract In recent years there has been interest in achieving application-level consistencycriteria without the latency and availability costs of strongly consistent storage infrastructure.A standard technique is to adopt a vocabulary of commutative operations; this avoids the riskof inconsistency due to message reordering. Another approach was recently captured by theCALM theorem; which proves that logically monotonic programs are guaranteed to beeventually consistent. In logic languages such as Bloom; CALM analysis can automaticallyverify that programs achieve consistency without coordination. In this paper we presentBloom L; an extension to Bloom that takes inspiration from both of these traditions. Bloom Lgeneralizes Bloom to support lattices and extends the power of CALM analysis to wholeprograms containing arbitrary lattices. We show how the Bloom interpreter can be …,Proceedings of the Third ACM Symposium on Cloud Computing,2012,88
FATE and DESTINI: A framework for cloud recovery testing,Haryadi S Gunawi; Thanh Do; Pallavi Joshi; Peter Alvaro; Joseph M Hellerstein; Andrea C Arpaci-Dusseau; Remzi H Arpaci-Dusseau; Koushik Sen; Dhruba Borthakur,Abstract As the cloud era begins and failures become commonplace; failure recoverybecomes a critical factor in the availability; reliability and performance of cloud services.Unfortunately; recovery problems still take place; causing downtimes; data loss; and manyother problems. We propose a new testing framework for cloud recovery: FATE (FailureTesting Service) and DESTINI (Declarative Testing Specifications). With FATE; recovery issystematically tested in the face of multiple failures. With DESTINI; correct recovery isspecified clearly; concisely; and precisely. We have integrated our framework to severalcloud systems (eg; HDFS [33]); explored over 40;000 failure scenarios; wrote 74specifications; found 16 new bugs; and reproduced 51 old bugs.,Proceedings of NSDI’11: 8th USENIX Symposium on Networked Systems Design and Implementation,2011,65
I do declare: consensus in a logic language,Peter Alvaro; Tyson Condie; Neil Conway; Joseph M Hellerstein; Russell Sears,Abstract The Paxos consensus protocol can be specified concisely; but is notoriously difficultto implement in practice. We recount our experience building Paxos in Overlog; a distributeddeclarative programming language. We found that the Paxos algorithm is easily translated todeclarative logic; in large part because the primitives used in consensus protocolspecifications map directly to simple Overlog constructs such as aggregation and selection.We discuss the programming idioms that appear frequently in our implementation; and theapplicability of declarative programming to related application domains.,ACM SIGOPS Operating Systems Review,2010,34
Blazes: Coordination analysis for distributed programs,Peter Alvaro; Neil Conway; Joseph M Hellerstein; David Maier,Distributed consistency is perhaps the most discussed topic in distributed systems today.Coordination protocols can ensure consistency; but in practice they cause undesirableperformance unless used judiciously. Scalable distributed architectures avoid coordinationwhenever possible; but undercoordinated systems can exhibit behavioral anomalies underfault; which are often extremely difficult to debug. This raises significant challenges fordistributed system architects and developers. In this paper we present BLAZES; a cross-platform program analysis framework that (a) identifies program locations that requirecoordination to ensure consistent executions; and (b) automatically synthesizes application-specific coordination code that can significantly outperform general-purpose techniques. Wepresent two case studies; one using annotated programs in the Twitter Storm system; and …,Data Engineering (ICDE); 2014 IEEE 30th International Conference on,2014,32
Consistency without borders,Peter Alvaro; Peter Bailis; Neil Conway; Joseph M Hellerstein,Abstract Distributed consistency is a perennial research topic; in recent years it has becomean urgent practical matter as well. The research literature has focused on enforcing variousflavors of consistency at the I/O layer; such as linearizability of read/write registers. Forpractitioners; strong I/O consistency is often impractical at scale; while looser forms of I/Oconsistency are difficult to map to application-level concerns. Instead; it is common fordevelopers to take matters of distributed consistency into their own hands; leading toapplication-specific solutions that are tricky to write; test and maintain. In this paper; weagitate for the technical community to shift its attention to approaches that lie between theextremes of I/O-level and application-level consistency. We ground our discussion in earlywork in the area; including our own experiences building programmer tools and …,Proceedings of the 4th annual Symposium on Cloud Computing,2013,28
BOOM: Data-centric programming in the datacenter,Peter Alvaro; Tyson Condie; Neil Conway; Khaled Elmeleegy; Joseph M Hellerstein; Russell C Sears,ABSTRACT Cloud computing makes datacenter clusters a commodity; potentially enabling awide range of programmers to develop new scalable services. However; current cloudplatforms do little to simplify truly distributed systems development. In this paper; we explorethe use of a declarative; data-centric programming model to achieve this simplicity. Wedescribe our experience using Overlog and Java to implement a “Big Data” analytics stackthat is API-compatible with Hadoop and HDFS; with equivalent performance. We extendedthe system with complex features not yet available in Hadoop; including availability;scalability; and unique monitoring and debugging facilities. We present our experience tovalidate the enhanced programmer productivity afforded by declarative programming; andinform the design of new development environments for distributed programming.,EECS Department; University of California; Berkeley; Tech. Rep. UCB/EECS-2009-113,2009,24
Lineage-driven fault injection,Peter Alvaro; Joshua Rosen; Joseph M Hellerstein,Abstract In large-scale data management systems; failure is practically a certainty. Fault-tolerant protocols and components are notoriously difficult to implement and debug. Worsestill; choosing existing fault-tolerance mechanisms and integrating them correctly intocomplex systems remains an art form; and programmers have few tools to assist them. Wepropose a novel approach for discovering bugs in fault-tolerant data management systems:lineage-driven fault injection. A lineage-driven fault injector reasons backwards from correctsystem outcomes to determine whether failures in the execution could have prevented theoutcome. We present MOLLY; a prototype of lineage-driven fault injection that exploits anovel combination of data lineage techniques from the database literature and state-of-the-art satisfiability testing. If fault-tolerance bugs exist for a particular configuration; MOLLY …,Proceedings of the 2015 ACM SIGMOD International Conference on Management of Data,2015,20
Confluence analysis for distributed programs: A model-theoretic approach,William R Marczak; Peter Alvaro; Neil Conway; Joseph M Hellerstein; David Maier,Abstract Building on recent interest in distributed logic programming; we take a model-theoretic approach to analyzing confluence of asynchronous distributed programs. We beginwith a model-theoretic semantics for Dedalus and introduce the ultimate model; whichcaptures non-deterministic eventual outcomes of distributed programs. After showing thequestion of confluence undecidable for Dedalus; we identify restricted sub-languages thatguarantee confluence while providing adequate expressivity. We observe that thesemipositive restriction Dedalus+ guarantees confluence while capturing PTIME; but showthat its restriction of negation makes certain simple and practical programs difficult to write.To remedy this; we introduce Dedalus S; a restriction of Dedalus that allows a kind ofstratified negation; but retains the confluence of Dedalus+ and similarly captures PTIME.,*,2012,18
BloomUnit: Declarative testing for distributed programs,Peter Alvaro; Andrew Hutchinson; Neil Conway; William R Marczak; Joseph M Hellerstein,Abstract We present BloomUnit; a testing framework for distributed programs written in theBloom language. BloomUnit allows developers to write declarative test specifications thatdescribe the input/output behavior of a software module. Test specifications are expressedas Bloom queries over (distributed) execution traces of the program under test. To allowexecution traces to be produced automatically; BloomUnit synthesizes program inputs thatsatisfy user-provided constraints. For a given input; BloomUnit systematically explores thespace of possible network message reorderings. BloomUnit searches this space efficientlyby exploiting program semantics to ignore" uninteresting" message schedules.,Proceedings of the Fifth International Workshop on Testing Database Systems,2012,15
A declarative semantics for Dedalus,Peter Alvaro; Tom J Ameloot; Joseph M Hellerstein; William R Marczak; Jan Van den Bussche,The language Dedalus is a Datalog-like language in which distributed computations andnetworking protocols can be programmed; in the spirit of the Declarative Networkingparadigm. Whereas recently formal operational semantics for Dedalus-like languages havebeen developed; a purely declarative semantics has been lacking so far. The challenge is tocapture precisely the amount of nondeterminism that is inherent to distributed computationsdue to concurrency; networking delays; and asynchronous communication. This papershows how a declarative semantics can be obtained by simply using the well-known stablemodel semantics for Datalog with negation. This semantics is applied to the Dedalus rulesafter they are modified to account for nondeterministic arrival times of messages; andaugmented with control rules which model causality. The main result then is that; as far as …,*,2013,10
Edelweiss: Automatic storage reclamation for distributed programming,Neil Conway; Peter Alvaro; Emily Andrews; Joseph M Hellerstein,Abstract Event Log Exchange (ELE) is a common programming pattern based on immutablestate and messaging. ELE sidesteps traditional challenges in distributed consistency; at theexpense of introducing new challenges in designing space reclamation protocols to avoidconsuming unbounded storage. We introduce Edelweiss; a sublanguage of Bloom thatprovides an ELE programming model; yet automatically reclaims space without programmerassistance. We describe techniques to analyze Edelweiss programs and automaticallygenerate application-specific distributed space reclamation logic. We show how Edelweisscan be used to elegantly implement a variety of communication and distributed storageprotocols; the storage reclamation code generated by Edelweiss effectively garbage-collectsstate and often matches hand-written protocols from the literature.,Proceedings of the VLDB Endowment,2014,9
Knuckles: bringing the database to the data,Peter Alvaro; Dmitriy V Ryaboy; Divyakant Agrawal,Click-stream data warehousing has emerged as a monumental information managementand processing challenge for commercial enterprises. Traditional solutions based oncommercial DBMS technology often suffer from poor scalability and large processinglatencies. Although click-stream data tends to be collected in a distributed manner to supportscaling the servers that host the websites; in general these partitioned click-stream logs arecollated and pushed upstream to a centralised database storage repository; creating storagebottlenecks. In this paper; we propose a design of an ad-hoc retrieval system suitable forclick-stream data warehouses; in which the data remains distributed and database queriesare rewritten to be executed against the distributed data. The query rewrite does not involveany centralised control and is therefore highly scalable. The elimination of centralised …,International Journal of Computational Science and Engineering,2010,6
Automating failure testing research at Internet scale,Peter Alvaro; Kolton Andrus; Chris Sanden; Casey Rosenthal; Ali Basiri; Lorin Hochstein,Abstract Large-scale distributed systems must be built to anticipate and mitigate a variety ofhardware and software failures. In order to build confidence that fault-tolerant systems arecorrectly implemented; Netflix (and similar enterprises) regularly run failure drills in whichfaults are deliberately injected in their production system. The combinatorial space of failurescenarios is too large to explore exhaustively. Existing failure testing approaches eitherrandomly explore the space of potential failures randomly or exploit the" hunches" of domainexperts to guide the search. Random strategies waste resources testing" uninteresting"faults; while programmer-guided approaches are only as good as human intuition and onlyscale with human effort. In this paper; we describe how we adapted and implemented aresearch prototype called lineage-driven fault injection (LDFI) to automate failure testing …,Proceedings of the Seventh ACM Symposium on Cloud Computing,2016,4
Malacology: A programmable storage system,Michael A Sevilla; Noah Watkins; Ivo Jimenez; Peter Alvaro; Shel Finkelstein; Jeff LeFevre; Carlos Maltzahn,Abstract Storage systems need to support high-performance for special-purpose dataprocessing applications that run on an evolving storage device technology landscape. Thisputs tremendous pressure on storage systems to support rapid change both in terms of theirinterfaces and their performance. But adapting storage systems can be difficult becauseunprincipled changes might jeopardize years of code-hardening and performanceoptimization efforts that were necessary for users to entrust their data to the storage system.We introduce the programmable storage approach; which exposes internal services andabstractions of the storage stack as building blocks for higher-level services. We also build aprototype to explore how existing abstractions of common storage system services can beleveraged to adapt to the needs of new data processing systems and the increasing …,Proceedings of the Twelfth European Conference on Computer Systems,2017,2
Growing a protocol,Kamala Ramasubramanian; Kathryn Dahlgren; Asha Karim; Sanjana Maiya; Sarah Borland; P Alvaro,Abstract Verification is often regarded as a one-time procedure undertaken after a protocol isspecified but before it is implemented. However; in practice; protocols continually evolvewith the addition of new capabilities and performance optimizations. Existing verificationtools are illsuited to “tracking” protocol evolution and programmers are too busy (or toolazy?) to simultaneously co-evolve specifications manually. This means that the correctnessguarantees determined at verification time can erode as protocols evolve. Existing softwarequality techniques such as regression testing and root cause analysis; which naturallysupport system evolution; are poorly suited to reasoning about fault tolerance properties of adistributed system because these properties require a search of the execution schedulerather than merely replaying inputs. This paper advocates that our community should …,9th Usenix Workshop on Hot Topics in Cloud Computing,2017,1
Putting logic-based distributed systems on stable grounds,Tom J Ameloot; Jan Van den Bussche; William R Marczak; Peter Alvaro; Joseph M Hellerstein,Abstract In the Declarative Networking paradigm; Datalog-like languages are used toexpress distributed computations. Whereas recently formal operational semantics for theselanguages have been developed; a corresponding declarative semantics has been lackingso far. The challenge is to capture precisely the amount of nondeterminism that is inherent todistributed computations due to concurrency; networking delays; and asynchronouscommunication. This paper shows how a declarative; model-based semantics can beobtained by simply using the well-known stable model semantics for Datalog with negation.We show that the model-based semantics matches previously proposed formal operationalsemantics.,Theory and Practice of Logic Programming,2016,1
Brados: Declarative; programmable object storage,Noah Watkins; Michael Sevilla; Ivo Jimenez; Neha Ojha; Peter Alvaro; Carlos Maltzahn,Abstract To meet the needs of a diverse and growing set of cloud-based applications;modern distributed storage frameworks expose a variety of composable subsystems asbuilding blocks. This approach gives infrastructure programmers significant flexibility inimplementing application-specific semantics while reusing trusted components.Unfortunately; in current storage systems the composition of subsystems is a low-level taskthat couples (and hence obscures) a variety of orthogonal concerns; including functionalcorrectness and performance. Building an application by wiring together a collection ofcomponents typically requires thousands of lines of carefullywritten C++ code; an effort thatmust be repeated whenever device or subsystem characteristics change. In this paper; wepropose a declarative approach to subservice composition that allows programmers to …,*,2016,1
Multi-query optimization for parallel dataflow systems,Peter Alvaro; Neil Conway; Andrew Krioukov,Abstract Existing parallel dataflow systems are strictly reactive in their optimizations. At best;such approaches approximate the optimal strategy; missing opportunities to optimize acrossmultiple queries and reschedule queries to improve locality. We propose three techniquesthat improve query execution performance by utilizing high-level knowledge of the workload.The first technique predictively replicates data to improve aggregate read bandwidth andincrease locality. The second technique reorders similar queries to improve cacheperformance. The third technique schedules multiple queries in parallel to improve resourceutilization. We evaluate these techniques using Apache Hive on Amazon EC2 and showperformance improvements of 5% to 50%.,URL: http://neilconway. org/docs/286_mqo. pdf,2009,1
Fail-Slow at Scale: Evidence of Hardware Performance Faults in Large Production Systems,Haryadi S Gunawi; Riza O Suminto; Russell Sears; Casey Golliher; Swaminathan Sundararaman; Xing Lin; Tim Emami; Weiguang Sheng; Nematollah Bidokhti; Caitie McCaffrey; Gary Grider; Parks M Fields; Kevin Harms; Robert B Ross; Andree Jacobson; Robert Ricci; Kirk Webb; Peter Alvaro; H Birali Runesha; Mingzhe Hao; Huaicheng Li,*,*,2018,*
Blazes: Coordination Analysis and Placement for Distributed Programs,Peter Alvaro; Neil Conway; Joseph M Hellerstein; David Maier,Abstract Distributed consistency is perhaps the most-discussed topic in distributed systemstoday. Coordination protocols can ensure consistency; but in practice they causeundesirable performance unless used judiciously. Scalable distributed architectures avoidcoordination whenever possible; but under-coordinated systems can exhibit behavioralanomalies under fault; which are often extremely difficult to debug. This raises significantchallenges for distributed system architects and developers. In this article; we present Blazes; a cross-platform program analysis framework that (a) identifies program locations thatrequire coordination to ensure consistent executions; and (b) automatically synthesizesapplication-specific coordination code that can significantly outperform general-purposetechniques. We present two case studies; one using annotated programs in the Twitter …,ACM Transactions on Database Systems (TODS),2017,*
Abstracting the geniuses away from failure testing,Peter Alvaro; Severine Tymon,These superusers; known as Chaos Engineers and Jepsen experts; must study the systemsunder test; observe system executions; and then formulate hypotheses about which faultsare most likely to expose real system-design flaws. This approach is fundamentallyunscalable and unprincipled. It relies on the superuser's ability to interpret how a distributedsystem employs redundancy to mask or ameliorate faults and; moreover; the ability torecognize the insufficiencies in those redundancies—in other words; human genius. Thisarticle presents a call to arms for the distributed systems research community to improve thestate of the art in fault tolerance testing. Ordinary users need tools that automate theselection of custom-tailored faults to inject. We conjecture that the process by whichsuperusers select experiments—observing executions; constructing models of system …,Queue,2017,*
DeclStore: Layering is for the Faint of Heart,Noah Watkins; Michael A Sevilla; Ivo Jimenez; Kathryn Dahlgren; Peter Alvaro; Shel Finkelstein; Carlos Maltzahn,Popular storage systems support diverse storage abstractions by providing importantdisaggregation benefits. Instead of maintaining a separate system for each abstraction;unified storage systems; in particular; support standard file; block; and object abstractions sothe same hardware can be used for a wider range and a more flexible mix of applications.As large-scale unified storage systems continue to evolve to meet the requirements of anincreasingly diverse set of applications and next-generation hardware; de jure approachesof the past—based on standardized interfaces—are giving way to domain-specific interfacesand optimizations. While promising; the ad-hoc strategies characteristic of currentapproaches to co-design are untenable. The standardization of the POSIX I/O interface hasbeen a major success. General adoption has allowed application developers to avoid …,9th {USENIX} Workshop on Hot Topics in Storage and File Systems (HotStorage 17),2017,*
Research for practice: tracing and debugging distributed systems; programming by examples,Peter Bailis; Peter Alvaro; Sumit Gulwani,JULY 2017| VOL. 60| NO. 7| COMMUNICATIONS OF THE ACM 47 ing it easier to derivehigh-level explanations of end-to-end interactions spanning many nodes in distributedcomputations. But there is no free lunch. Broadly speaking; large-scale tracing systemsimpose on adopters both an instrumentation burden (the effort that goes into tweakingexisting code to add instrumentation points or to propagate metadata; or both) and anoverhead burden (the runtime cost of trace capture and propagation). The collection ofpapers chosen here illustrates some strategies for ameliorating these burdens; as well assome creative applications for high-level explanations.,Communications of the ACM,2017,*
Research for Practice: Tracing and Debugging Distributed Systems; Programming by Examples,Peter Alvaro; Sumit Galwani; Peter Bailis,BY PETER ALVARO Large-scale distributed systems can be a nightmare to debug.Individuallys unlikely events (eg; a server crashing or a process taking too long to respond toa request) are commonplace at the massive scale at which many Internet enterprisesoperate. State-of-the-art monitoring systems can help measure the frequency of theseanomalies but do little to identify their root causes. Pervasive logging may record events ofinterest at appropriate granularity; but correlating events across the logs of large numbers ofmachines is prohibitively difficult. Distributed tracing systems overcome many of theselimitations; making it easier to derive high-level explanations of end-to-end interactionsspanning many nodes in distributed computations. But there is no free lunch. Broadlyspeaking; large-scale tracing systems impose on adopters both an instrumentation …,Queue,2017,*
GeneralStore: Declarative Programmable Storage.,Peter Alvaro,ABSTRACT Despite the broad and growing diversity of storage-intensive applications;storage interfaces have evolved little over time. Fears of vendor lock-in and loss orinaccessibility of legacy data have discouraged the evolution of the POSIX API to bettersupport existing and emerging workloads. This has long been a source of consternation forapplications developers; who are often required to duplicate significant functionality to avoidinefficiencies [3]. Recently; the development of programmable storage systems (PSS)[5] haspromised to upend this tradition; exposing a variety of composable subsystems as buildingblocks rather than a narrow storage interface. Such systems provide infrastructureprogrammers with great flexibility in implementing application-specific semantics whilereusing trusted components. Unfortunately; the composition of subsystems is a low-level …,CIDR,2017,*
Data-centric Programming for Distributed Systems,Peter Alexander Alvaro,Abstract Distributed systems are difficult to reason about and program because offundamental uncertainty in their executions; arising from sources of nondeterminism such asasynchrony and partial failure. Until relatively recently; responsibility for managing thesecomplexities was relegated to a small group of experts; who hid them behind infrastructure-backed abstractions such as distributed transactions. As a consequence of technologytrends including the rise of cloud computing; the proliferation of open-source storage andprocessing technologies; and the ubiquity of personal mobile devices; today nearly all non-trivial applications are physically distributed and combine a variety of heterogeneoustechnologies; including" NoSQL" stores; message queues and caches. Applicationdevelopers and analysts must now (alongside infrastructure engineers) take on the …,*,2015,*
Inner CALM: Concurrency control protocols through the looking glass.,Peter Alvaro,ABSTRACT The CALM theorem—which states that monotonic programs produce consistentdistributed outcomes without coordination [2; 4]—originated with the (mirror image)observation that mechanisms for ensuring consistency (eg; concurrency control and othercoordination protocols) cannot be implemented with purely monotonic logic [5]. Since thattime; CALM has been a useful guiding principle for deciding whether costly protocols arenecessary to ensure correct program outcomes [1; 3; 10]. Recalling CALM's roots in protocolimplementation; we might be tempted to ask if we can apply a finer-grained monotonicityanalysis to study the implementations of coordination mechanisms themselves. Forexample; do certain concurrency control protocols fundamentally require more coordinationor synchronization than others? In 2011 and again in 2012; Joe Hellerstein and I taught a …,CIDR,2015,*
Distributed programming and consistency: principles and practice,Peter Alvaro; Neil Conway; Joseph M Hellerstein,Abstract In recent years; distributed programming has become a topic of widespread interestamong developers. However; writing reliable distributed programs remains stubbornlydifficult. In addition to the inherent challenges of distribution---asynchrony; concurrency; andpartial failure---many modern distributed systems operate at massive scale. Scalabilityconcerns have in turn encouraged many developers to eschew strongly consistentdistributed storage in favor of application-level consistency criteria [5; 10; 18]; which hasraised the degree of difficulty still further.,Proceedings of the Third ACM Symposium on Cloud Computing,2012,*
Doughface: A logic language for specifying secure distributed systems,Peter Alvaro,Distributed systems are difficult to build; verify and extend. Part of the problem is the gapbetween specification and implementation: systems that may be specified very conciselyoften require implementations that are several orders of magnitude larger than thespecification text in LOC (lines of code). Hence the burden of manually comparing thespecification to the program text is too large to be carried out with confidence. Worse still; theimperative languages that are often used for implementations are not amenable to automaticverification; due to general issues like the state explosion problem and specific semanticissues like pointer aliasing. These issues are worrisome enough for any distributed system;but particularly for secure systems. In general; we can partition the correctness properties ofa distributed system into two principal classes: safety properties and liveness properties …,*,2009,*
BoomFS: A Declarative Approach To Building Distributed File Systems,Peter Alvaro; Neil Conway,Abstract While architectures for distributed computing are changing rapidly; techniques forbuilding distributed systems have remained stagnant. As distributed computation becomesthe common case; traditional techniques for building such systems will become increasinglyburdensome; because they force programmers to deal with the mundane details ofconstructing reliable distributed systems rather than concentrating on the desiredcomputation. This yields programs that are difficult to construct; understand; modify; andadapt to new environments. We propose BOOM; an ongoing project to develop concisedeclarative specifications for a broad class of scalable distributed systems. In this paper; wedescribe the first application in the BOOM stack: BoomFS; a distributed file system that isimplemented using a combination of Java and declarative logic. We show that BoomFS is …,*,2008,*
Declarative Semantics for Declarative Networking,Jan Van den Bussche; Peter Alvaro; Joe Hellerstein; Bill Marczak,Page 1. Declarative Semantics for Declarative Networking Jan Van den Bussche HasseltUniversity; Belgium joint work with Tom Ameloot (Hasselt); Peter Alvaro; Joe Hellerstein; BillMarczak (Berkeley) 1 Page 2. Declarative Networking UC Berkeley SIGMOD 2006: NetworkDatalog [Loo; Hellerstein; et al.] • use Datalog to program network protocols; eg: – routing (shortestpath) – peer-to-peer PODS 2010: Dedalus [Hellerstein et al.] • use Datalog to program clusters: –querying distributed databases – data-oriented cloud computing 2 Page 3. 3 Page 4. Distributedcomputing Hard to program Two extremes: • Message-Passing Interface (in C or Fortran) •SQL-like formalisms (MapReduce; Hive; Pig) Dedalus offers something in between Practicallanguage: BLOOM WebDamLog [Abiteboul et al.] 4 Page 5. Distributed transitive closure inDedalus Input: binary relation R; distributed among the nodes …,*,*,*
