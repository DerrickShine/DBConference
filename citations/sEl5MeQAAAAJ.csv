A Distributed Graph Engine for Web Scale RDF Data,Kai Zeng; Jiacheng Yang; Haixun Wang; Bin Shao; Zhongyuan Wang,Abstract Much work has been devoted to supporting RDF data. But state-of-the-art systemsand methods still cannot handle web scale RDF data effectively. Furthermore; many usefuland general purpose graph-based operations (eg; random walk; reachability; communitydiscovery) on RDF data are not supported; as most existing systems store and index data inparticular ways (eg; as relational tables or as a bitmap matrix) to maximize one particularoperation on RDF data: SPARQL query processing. In this paper; we introduce Trinity. RDF;a distributed; memory-based graph engine for web scale RDF data. Instead of managing theRDF data in triple stores or as bitmap matrices; we store RDF data in its native graph form. Itachieves much better (sometimes orders of magnitude better) performance for SPARQLqueries than the state-of-the-art approaches. Furthermore; since the data is stored in its …,Proceedings of the VLDB Endowment,2013,205
Early accurate results for advanced analytics on mapreduce,Nikolay Laptev; Kai Zeng; Carlo Zaniolo,Abstract Approximate results based on samples often provide the only way in whichadvanced analytical applications on very massive data sets can satisfy their time andresource constraints. Unfortunately; methods and tools for the computation of accurate earlyresults are currently not supported in MapReduce-oriented systems although these areintended for'big data'. Therefore; we proposed and implemented a non-parametric extensionof Hadoop which allows the incremental computation of early results for arbitrary work-flows;along with reliable on-line estimates of the degree of accuracy achieved so far in thecomputation. These estimates are based on a technique called bootstrapping that has beenwidely employed in statistics and can be applied to arbitrary functions and data distributions.In this paper; we describe our Early Accurate Result Library (EARL) for Hadoop that was …,Proceedings of the VLDB Endowment,2012,105
High-performance complex event processing over XML streams,Barzan Mozafari; Kai Zeng; Carlo Zaniolo,Abstract Much research attention has been given to delivering high-performance systemsthat are capable of complex event processing (CEP) in a wide range of applications.However; many current CEP systems focus on processing efficiently data having a simplestructure; and are otherwise limited in their ability to support efficiently complex continuousqueries on structured or semi-structured information. However; XML streams represent avery popular form of data exchange; comprising large portions of social network and RSSfeeds; financial records; configuration files; and similar applications requiring advanced CEPqueries. In this paper; we present the XSeq language and system that support CEP on XMLstreams; via an extension of XPath that is both powerful and amenable to an efficientimplementation. Specifically; the XSeq language extends XPath with natural operators to …,Proceedings of the 2012 ACM SIGMOD International Conference on Management of Data,2012,54
The analytical bootstrap: a new method for fast error estimation in approximate query processing,Kai Zeng; Shi Gao; Barzan Mozafari; Carlo Zaniolo,Abstract Sampling is one of the most commonly used techniques in Approximate QueryProcessing (AQP)-an area of research that is now made more critical by the need for timelyand cost-effective analytics over" Big Data". Assessing the quality (ie; estimating the error) ofapproximate answers is essential for meaningful AQP; and the two main approaches used inthe past to address this problem are based on either (i) analytic error quantification or (ii) thebootstrap method. The first approach is extremely efficient but lacks generality; whereas thesecond is quite general but suffers from its high computational overhead. In this paper; weintroduce a probabilistic relational model for the bootstrap process; along with rigoroussemantics and a unified error model; which bridges the gap between these two traditionalapproaches. Based on our probabilistic framework; we develop efficient algorithms to …,Proceedings of the 2014 ACM SIGMOD international conference on Management of data,2014,51
Very fast estimation for result and accuracy of big data analytics: The EARL system,Nikolay Laptev; Kai Zeng; Carlo Zaniolo,Approximate results based on samples often provide the only way in which advancedanalytical applications on very massive data sets (akabig data') can satisfy their time andresource constraints. Unfortunately; methods and tools for the computation of accurate earlyresults are currently not supported in big data systems (eg; Hadoop). Therefore; we proposea nonparametric accuracy estimation method and system to speedup big data analytics. Ourframework is called EARL (Early Accurate Result Library) and it works by predicting thelearning curve and choosing the appropriate sample size for achieving the desired errorbound specified by the user. The error estimates are based on a technique calledbootstrapping that has been widely used and validated by statisticians; and can be appliedto arbitrary functions and data distributions. Therefore; this demo will elucidate (a) the …,Data Engineering (ICDE); 2013 IEEE 29th International Conference on,2013,29
G-ola: Generalized on-line aggregation for interactive analysis on big data,Kai Zeng; Sameer Agarwal; Ankur Dave; Michael Armbrust; Ion Stoica,Abstract Nearly 15 years ago; Hellerstein; Haas and Wang proposed online aggregation(OLA); a technique that allows users to (1) observe the progress of a query by showingiteratively refined approximate answers; and (2) stop the query execution once its resultachieves the desired accuracy. In this demonstration; we present G-OLA; a novel mini-batchexecution model that generalizes OLA to support general OLAP queries with arbitrarilynested aggregates using efficient delta maintenance techniques. We have implemented G-OLA in FluoDB; a parallel online query execution framework that is built on top of the Sparkcluster computing framework that can scale to massive data sets. We will demonstrateFluoDB on a cluster of 100 machines processing roughly 10TB of real-world session logsfrom a video-sharing website. Using an ad optimization and an A/B testing based …,Proceedings of the 2015 ACM SIGMOD International Conference on Management of Data,2015,27
Making sense of trajectory data: A partition-and-summarization approach,Han Su; Kai Zheng; Kai Zeng; Jiamin Huang; Shazia Sadiq; Nicholas Jing Yuan; Xiaofang Zhou,Due to the prevalence of GPS-enabled devices and wireless communication technology;spatial trajectories that describe the movement history of moving objects are beinggenerated and accumulated at an unprecedented pace. However; a raw trajectory in theform of sequence of timestamped locations does not make much sense for humans withoutsemantic representation. In this work we aim to facilitate human's understanding of a rawtrajectory by automatically generating a short text to describe it. By formulating this task asthe problem of adaptive trajectory segmentation and feature selection; we propose apartition-and-summarization framework. In the partition phase; we first define a set offeatures for each trajectory segment and then derive an optimal partition with the aim tomake the segments within each partition as homogeneous as possible in terms of their …,Data Engineering (ICDE); 2015 IEEE 31st International Conference on,2015,26
ABS: a system for scalable approximate queries with accuracy guarantees,Kai Zeng; Shi Gao; Jiaqi Gu; Barzan Mozafari; Carlo Zaniolo,Abstract Approximate Query Processing (AQP) based on sampling is critical for supportingtimely and cost-effective analytics over big data. To be applied successfully; AQP must beaccompanied by reliable estimates on the quality of sample-produced approximate answers;the two main techniques used in the past for this purpose are (i) closed-form analytic errorestimation; and (ii) the bootstrap method. Approach (i) is extremely efficient but lacksgenerality; whereas (ii) is general but suffers from high computational overhead. Ourrecently introduced Analytical Bootstrap method combines the strengths of both approachesand provides the basis for our ABS system; which will be demonstrated at the conference.The ABS system models bootstrap by a probabilistic relational model; and extends relationalalgebra with operations on probabilistic relations to predict the distributions of the AQP …,Proceedings of the 2014 ACM SIGMOD international conference on Management of data,2014,22
Graph queries in a next-generation datalog system,Alexander Shkapsky; Kai Zeng; Carlo Zaniolo,Abstract Recent theoretical advances have enabled the use of special monotonicaggregates in recursion. These special aggregates make possible the concise expressionand efficient implementation of a rich new set of advanced applications. Among theseapplications; graph queries are particularly important because of their pervasiveness in dataintensive application areas. In this demonstration; we present our Deductive ApplicationLanguage (DeAL) System; the first of a new generation of Deductive Database Systems thatsupport applications that could not be expressed using regular stratification; or could beexpressed using XY-stratification (also supported in DeAL) but suffer from inefficientexecution. Using example queries; we will (i) show how complex graph queries can beconcisely expressed using DeAL and (ii) illustrate the formal semantics and efficient …,Proceedings of the VLDB Endowment,2013,22
High-performance complex event processing over hierarchical data,Barzan Mozafari; Kai Zeng; Loris D'antoni; Carlo Zaniolo,Abstract While Complex Event Processing (CEP) constitutes a considerable portion of the so-called Big Data analytics; current CEP systems can only process data having a simplestructure; and are otherwise limited in their ability to efficiently support complex continuousqueries on structured or semistructured information. However; XML-like streams represent avery popular form of data exchange; comprising large portions of social network and RSSfeeds; financial feeds; configuration files; and similar applications requiring advanced CEPqueries. In this article; we present the XSeq language and system that support CEP on XMLstreams; via an extension of XPath that is both powerful and amenable to an efficientimplementation. Specifically; the XSeq language extends XPath with natural operators toexpress sequential and Kleene-* patterns over XML streams; while remaining highly …,ACM Transactions on Database Systems (TODS),2013,20
STMaker: a system to make sense of trajectory data,Han Su; Kai Zheng; Kai Zeng; Jiamin Huang; Xiaofang Zhou,Abstract Widely adoption of GPS-enabled devices generates large amounts of trajectoriesevery day. The raw trajectory data describes the movement history of moving objects by asequence of< longitude; latitude; time-stamp> triples; which are nonintuitive for human toperceive the prominent features of the trajectory; such as where and how the moving objecttravels. In this demo; we present the STMaker system to help users make sense of individualtrajectories. Given a trajectory; STMaker can automatically extract the significant semanticbehavior of the trajectory; and summarize the behavior by a short human-readable text. Inthis paper; we first introduce the phrases of generating trajectory summarizations; and thenshow several real trajectory summarization cases.,Proceedings of the VLDB Endowment,2014,17
From regular expressions to nested words: Unifying languages and query execution for relational and xml sequences,Barzan Mozafari; Kai Zeng; Carlo Zaniolo,Abstract There is growing interest in query language extensions for pattern matching overevent streams and stored database sequences; due to the many important applications thatsuch extensions make possible. The push for such extensions has led DBMS vendors andDSMS venture companies to propose Kleene-closure extensions of SQL standards; buildingon seminal research that demonstrated the effectiveness and amenability to efficientimplementation of such constructs. These extensions; however powerful; suffer fromlimitations that severely impair their effectiveness in many real-world applications. Toovercome these problems; we have designed the K* SQL language and system; based onour investigation of the nested words; which are recent models that generalize both wordsand trees. K* SQL extends the existing relational sequence languages; and also enables …,Proceedings of the VLDB Endowment,2010,17
K* sql: A unifying engine for sequence patterns and xml,Barzan Mozafari; Kai Zeng; Carlo Zaniolo,Abstract A strong interest is emerging in SQL extensions for sequence patterns using Kleene-closure expressions. This burst of interest from both the research community and thecommercial world is due to the many database and data stream applications made possibleby these extensions; including financial services; RFID-based inventory management; andelectronic health systems. In this demo we will present the K* SQL system that represents amajor step forward in this area. K* SQL supports a more expressive language that allows forgeneralized Kleene-closure queries and also achieves the expressive power of the nestedword model; which greatly expands the application domain to include XML queries; softwaretrace analysis; and genomics. In this demo; we first introduce the core features of ourlanguage in expressing complex pattern queries over both relational and XML data. We …,Proceedings of the 2010 ACM SIGMOD International Conference on Management of data,2010,11
IOLAP: Managing uncertainty for efficient incremental OLAP,Kai Zeng; Sameer Agarwal; Ion Stoica,Abstract The size of data and the complexity of analytics continue to grow along with theneed for timely and cost-effective analysis. However; the growth of computation powercannot keep up with the growth of data. This calls for a paradigm shift from traditional batchOLAP processing model to an incremental OLAP processing model. In this paper; wepropose iOLAP; an incremental OLAP query engine that provides a smooth trade-offbetween query accuracy and latency; and fulfills a full spectrum of user requirements fromapproximate but timely query execution to a more traditional accurate query execution.iOLAP enables interactive incremental query processing using a novel mini-batch executionmodel---given an OLAP query; iOLAP first randomly partitions the input dataset into smallersets (mini-batches) and then incrementally processes through these mini-batches by …,Proceedings of the 2016 International Conference on Management of Data,2016,6
PerNav: A route summarization framework for personalized navigation,Yaguang Li; Han Su; Ugur Demiryurek; Bolong Zheng; Kai Zeng; Cyrus Shahabi,Abstract In this paper; we study a route summarization framework for PersonalizedNavigation dubbed PerNav-with which the goal is to generate more intuitive and customizedturn-by-turn directions based on user generated content. The turn-by-turn directionsprovided in the existing navigation applications are exclusively derived from underlying roadnetwork topology information ie; the connectivity of nodes to each other. Therefore; the turn-by-turn directions are simplified as metric translation of physical world (eg distance/time toturn) to spoken language. Such translation-that ignores human cognition about thegeographic space-is often verbose and redundant for the drivers who have knowledgeabout the geographical areas. PerNav utilizes wealth of user generated historical trajectorydata to extract namely" landmarks"(eg; point of interests or intersections) and frequently …,Proceedings of the 2016 International Conference on Management of Data,2016,2
Complex pattern matching in complex structures: the xseq approach,Kai Zeng; Mohan Yang; Barzan Mozafari; Carlo Zaniolo,There is much current interest in applications of complex event processing over datastreams and of complex pattern matching over stored sequences. While some applicationsuse streams of flat records; XML and various semi-structured information formats arepreferred by many others-in particular; applications that deal with domain science; socialnetworks; RSS feeds; and finance. XSeq and its system improve complex pattern matchingtechnology significantly; both in terms of expressive power and efficient implementation.XSeq achieves higher expressiveness through an extension of XPath based on Kleene-*pattern constructs; and achieves very efficient execution; on both stored and streaming data;using Visibly Pushdown Automata (VPA). In our demo; we will (i) show examples of XSeq indifferent application domains;(ii) explain its compilation/query optimization techniques …,Data Engineering (ICDE); 2013 IEEE 29th International Conference on,2013,2
Extending relational query languages for data streams,Nikolay Laptev; Barzan Mozafari; Hamid Mousavi; Hetal Thakkar; Haixun Wang; Kai Zeng; Carlo Zaniolo,Abstract The design of continuous query languages for data streams and the extent to whichthese should rely on database query languages represent pivotal issues for data streammanagement systems (DSMSs). The Expressive Stream Language (ESL) of our Stream Millsystem is designed to maximize the spectrum of applications a DSMS can support efficiently;while retaining compatibility with the SQL: 2003 standards. This approach offers significantadvantages; particularly for the many applications that span both data streams anddatabases. Therefore; ESL supports minimal extensions required to overcome SQL'sexpressive power limitations—a critical enhancement since said limitations are quite severeon database applications and are further exacerbated on data stream applications; where;eg; only nonblocking query operators can be used. Thus; ESL builds on user-defined …,*,2016,1
Groupwise analytics via adaptive MapReduce,Liping Peng; Vuk Ercegovac; Kai Zeng; Peter J Haas; Andrey Balmin; Yannis Sismanis,Shared-nothing systems such as Hadoop vastly simplify parallel programming whenprocessing disk-resident data whose size exceeds aggregate cluster memory. Such systemsincur a significant performance penalty; however; on the important class of “groupwise set-valued analytics”(GSVA) queries in which the data is dynamically partitioned into groupsand then a set-valued synopsis is computed for some or all of the groups. Key examples ofsynopses include top-k sets; bottom-k sets; and uniform random samples. Applications ofGSVA queries include micro-marketing; root-cause analysis for problem diagnosis; andfraud detection. A naive approach to executing GSVA queries first reshuffles all of the dataso that all records in a group are at the same node and then computes the synopsis for thegroup. This approach can be extremely inefficient when; as is typical; only a very small …,Data Engineering (ICDE); 2015 IEEE 31st International Conference on,2015,1
Approximation and Search Optimization on Massive Data Bases and Data Streams,Kai Zeng,A fast response is critical in many data-intensive applications; including knowledgediscovery analytics on big data; and queries searching for complex patterns in sequences;data streams and graphs. Moreover; the volume of data and the complexity of the analyticaltasks they must support are now growing at such a torrid rate that the vigorous progress inperformance and scalability of computer systems cannot keep up with it. This situation callsfor (i) effective optimization techniques to reduce the cost of complex pattern queries; and (ii)approximation techniques to produce results of predictable accuracy using a small subset ofthe data. In this dissertation we (i) introduce new query languages and optimizationtechniques for pattern matching in sequences; data streams and graphs; and (ii) formulate ageneral approximation model for analytics queries. Thus; in this dissertation we have …,*,2014,*
