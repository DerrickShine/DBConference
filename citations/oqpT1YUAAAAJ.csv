Ontology-based integration of information-a survey of existing approaches,Holger Wache; Thomas Voegele; Ubbo Visser; Heiner Stuckenschmidt; Gerhard Schuster; Holger Neumann; Sebastian Hübner,Abstract We review the use on ontologies for the integration of heterogeneous informationsources. Based on an in-depth evaluation of existing approaches to this problem we discusshow ontologies are used to support the integration task. We evaluate and compare thelanguages used to represent the ontologies and the use of mappings between ontologies aswell as to connect ontologies with information sources. We also ask for ontology engineeringmethods and tools used to develop ontologies for information integration. Based on theresults of our analysis we summarize the state of the art in ontology-based informationintegration and name areas of further research activities.,IJCAI-01 workshop: ontologies and information sharing,2001,1707
C-owl: Contextualizing ontologies,Paolo Bouquet; Fausto Giunchiglia; Frank Van Harmelen; Luciano Serafini; Heiner Stuckenschmidt,Abstract Ontologies are shared models of a domain that encode a view which is common toa set of different parties. Contexts are local models that encode a party's subjective view of adomain. In this paper we show how ontologies can be contextualized; thus acquiring certainuseful properties that a pure shared approach cannot provide. We say that an ontology iscontextualized or; also; that it is a contextual ontology; when its contents are kept local; andtherefore not shared with other ontologies; and mapped with the contents of other ontologiesvia explicit (context) mappings. The result is Context OWL (C-OWL); a language whosesyntax and semantics have been obtained by extending the OWL syntax and semantics toallow for the representation of contextual ontologies.,International Semantic Web Conference,2003,477
Results of the ontology alignment evaluation initiative 2007,Jérôme Euzenat; Antoine Isaac; Christian Meilicke; Pavel Shvaiko; Heiner Stuckenschmidt; Ondrej Svab; Vojtech Svatek; Willem Robert Van Hage; Mikalai Yatskevich,We present the Ontology Alignment Evaluation Initiative 2007 campaign as well as itsresults. The OAEI campaign aims at comparing ontology matching systems on preciselydefined test sets. OAEI-2007 builds over previous campaigns by having 4 tracks with 7 testsets followed by 17 participants. This is a major increase in the number of participantscompared to the previous years. Also; the evaluation results demonstrate that moreparticipants are at the forefront. The final and official results of the campaign are thosepublished on the OAEI web site.,Proc. 2nd ISWC 2007 international workshop on ontology matching (OM),2007,388
Structure-based partitioning of large concept hierarchies,Heiner Stuckenschmidt; Michel Klein,Abstract The increasing awareness of the benefits of ontologies for information processinghas lead to the creation of a number of large ontologies about real-world domains. The sizeof these ontologies and their monolithic character cause serious problems in handling them.In other areas; eg software engineering; these problems are tackled by partitioningmonolithic entities into sets of meaningful and mostly self-contained modules. In this paper;we suggest a similar approach for ontologies. We propose a method for automaticallypartitioning large ontologies into smaller modules based on the structure of the classhierarchy. We show that the structure-based method performs surprisingly well on real-worldontologies. We support this claim by experiments carried out on real-world ontologiesincluding SUMO and the NCI cancer ontology. The results of these experiments are …,International semantic web conference,2004,277
A framework for handling inconsistency in changing ontologies,Peter Haase; Frank Van Harmelen; Zhisheng Huang; Heiner Stuckenschmidt; York Sure,Abstract One of the major problems of large scale; distributed and evolving ontologies is thepotential introduction of inconsistencies. In this paper we survey four different approaches tohandling inconsistency in DL-based ontologies: consistent ontology evolution; repairinginconsistencies; reasoning in the presence of inconsistencies and multi-version reasoning.We present a common formal basis for all of them; and use this common basis to comparethese approaches. We discuss the different requirements for each of these methods; theconditions under which each of them is applicable; the knowledge requirements of thevarious methods; and the different usage scenarios to which they would apply.,International semantic web conference,2005,265
Information sharing on the semantic web,Heiner Stuckenschmidt; Frank Van Harmelen,The large-scale and almost ubiquitous availability of information has become as much of acurse as it is a blessing. The more information is available; the harder it is to locate anyparticular piece of it. And even when it has been successfully found; it is even harder still tousefully combine it with other information we may already possess. This problem occurs atmany different levels; ranging from the overcrowded disks of our own PCs to the mass ofunstructured information on the World Wide Web. It is commonly understood that thisproblem of information sharing can only be solved by giving computers better access to thesemantics of the information. While it has been recognized that ontologies play a crucial rolein solving the open problems; most approaches rely on the existence of well-establisheddata structures. To overcome these shortcomings; Stuckenschmidt and van Harmelen …,*,2005,260
Contextualizing ontologies,Paolo Bouquet; Fausto Giunchiglia; Frank Van Harmelen; Luciano Serafini; Heiner Stuckenschmidt,Abstract Ontologies are shared models of a domain that encode a view which is common toa set of different parties. Contexts are local models that encode a party's subjective view of adomain. In this paper; we show how ontologies can be contextualized; thus acquiring certainuseful properties that a pure shared approach cannot provide. We say that an ontology iscontextualized or; also; that it is a contextual ontology; when its contents are kept local; andtherefore not shared with other ontologies; and mapped with the contents of other ontologiesvia explicit (context) mappings. The result is Context OWL (C-OWL); a language whosesyntax and semantics have been obtained by extending the OWL syntax and semantics toallow for the representation of contextual ontologies.,Web Semantics: Science; Services and Agents on the World Wide Web,2004,249
State of the art on ontology alignment,Jerome Euzenat; Thanh Le Bach; J Barrasa; P Bouquet; J De Bo; R Dieng; M Ehrig; M Hauswirth; Mustafa Jarrar; R Lara; D Maynard; A Napoli; G Stamou; H Stuckenschmidt; P Shvaiko; S Tessaris; S Van Acker; Ilya Zaihrayeu,*,Knowledge Web Deliverable D,2004,247
Ontology alignment evaluation initiative: six years of experience,Jérôme Euzenat; Christian Meilicke; Heiner Stuckenschmidt; Pavel Shvaiko; Cássia Trojahn,Abstract In the area of semantic technologies; benchmarking and systematic evaluation isnot yet as established as in other areas of computer science; eg; information retrieval. Inspite of successful attempts; more effort and experience are required in order to achievesuch a level of maturity. In this paper; we report results and lessons learned from theOntology Alignment Evaluation Initiative (OAEI); a benchmarking initiative for ontologymatching. The goal of this work is twofold: on the one hand; we document the state of the artin evaluating ontology matching methods and provide potential participants of the initiativewith a better understanding of the design and the underlying principles of the OAEIcampaigns. On the other hand; we report experiences gained in this particular area ofsemantic technologies to potential developers of benchmarking for other kinds of systems …,*,2011,222
Ontologies for geographic information processing,Ubbo Visser; Heiner Stuckenschmidt; Gerhard Schuster; Thomas Vögele,Abstract The development of geographical information systems (GIS) and the interoperabilitybetween these systems demands new requirements for the description of the underlyingdata. The exchange of data between GIS systems is problematic and often fails due toconfusion in the meaning of concepts. The term semantic translator; a translator betweenGIS systems and/or catalogue systems which gives the user the option to map data betweenthe systems is a topic of current research. This paper provides an overview of formalontologies and how they can be used for geographical information processing. A descriptionof an intelligent broker architecture for semantic-based information retrieval is introduced;and shows how this approach can be used for general purposes. In conclusion we attemptto provide a roadmap for the use of ontologies for geographic information processing.,Computers & Geosciences,2002,182
Modular ontologies: concepts; theories and techniques for knowledge modularization,Heiner Stuckenschmidt; Christine Parent; Stefano Spaccapietra,Volume Editors Heiner Stuckenschmidt Universität Mannheim; Institut für Informatik B6; 26; 68159Mannheim; Germany E-mail: heiner@ informatik. uni-mannheim. de Christine Parent Universitéde Lausanne; HEC ISI 1015 Lausanne; Switzerland E-mail: christine. parent@ epfll. ch StefanoSpaccapietra École Polytechnique Fédérale de Lausanne; EPFL-IC; Database Laboratory 1015Lausanne; Switzerland E-mail: stefano. spaccapietra@ epfl. ch Library of Congress ControlNumber: Applied for CR Subject Classification (1998): D. 1; D. 2; D. 3; F. 3.2; F. 4.1 LNCSSublibrary: SL 1–Theoretical Computer Science and General Issues ISSN 0302-9743 ISBN-103-642-01906-4 Springer Berlin Heidelberg New York ISBN-13 978-3-642-01906-7 SpringerBerlin Heidelberg New York This work is subject to copyright. All rights are reserved; whetherthe whole or part of the material is concerned; specifically the rights of translation …,*,2009,165
Repairing ontology mappings,Christian Meilicke; Heiner Stuckenschmidt; Andrei Tamilin,Abstract Automatically discovering semantic relations between ontologies is an importanttask with respect to overcoming semantic heterogeneity on the semantic web. Existingontology matching systems; however; often produce erroneous mappings. In this paper; weaddress the problem of errors in mappings by proposing a completely automatic debuggingmethod for ontology mappings. The method uses logical reasoning to discover and repairlogical inconsistencies caused by erroneous mappings. We describe the debugging methodand report experiments on mappings submitted to the ontology alignment evaluationchallenge that show that the proposed method actually improves mappings created bydifferent matching systems without any human intervention.,AAAI,2007,138
Index structures and algorithms for querying distributed RDF repositories,Heiner Stuckenschmidt; Richard Vdovjak; Geert-Jan Houben; Jeen Broekstra,Abstract A technical infrastructure for storing; querying and managing RDFdata is a keyelement in the current semantic web development. Systems like Jena; Sesame or the ICS-FORTH RDF Suite are widelyused for building semantic web applications. Currently; noneofthese systems supports the integrated querying of distributed RDF repositories. Weconsider this a major shortcoming since the semanticweb is distributed by nature. In thispaper we present an architecture for querying distributed RDF repositories by extending theexisting Sesame system. We discuss the implications of our architectureand propose anindex structure as well as algorithms forquery processing and optimization in such adistributed context.,Proceedings of the 13th international conference on World Wide Web,2004,131
Integrity and change in modular ontologies,Heiner Stuckenschmidt; Michel Klein,Abstract The benefits of modular representations are well known from many areas ofcomputer science. In this paper; we concentrate on the benefits of modular ontologies withrespect to local containment of terminological reasoning. We define an architecture formodular ontologies that supports local reasoning by compiling implied subsumptionrelations. We further address the problem of guaranteeing the integrity of a modular ontologyin the presence of local changes. We propose a strategy for analyzing changes and guidingthe process of updating compiled information.,IJCAI,2003,128
Uml for the semantic web: Transformation-based approaches,H Stuckenschmidt; K Falkovych; M Sabou,Abstract The perspective role of UML as a conceptual modelling language for the SemanticWeb has become an important research topic. We argue that UML could be a keytechnology for overcoming the ontology development bottleneck thanks to its wideacceptance and sophisticated tool support. Transformational approaches are a promisingway of establishing a connection between UML and web-based ontology languages. Wecompare some proposals for defining transformations between UML and web ontologylanguages and discuss the different ways they handle the conceptual differences betweenthese languages. We identify commonalities and differences of the approaches and pointout open questions that have not or not satisfyingly been addressed by existing approaches.,Knowl. Transformation Semant. Web,2003,123
Results of the ontology alignment evaluation initiative 2008,Caterina Caraciolo; Jérôme Euzenat; Laura Hollink; Ryutaro Ichise; Antoine Isaac; Véronique Malaisé; Christian Meilicke; Juan Pane; Pavel Shvaiko; Heiner Stuckenschmidt; Ondrej Svab; Vojtech Svátek,Ontology matching consists of finding correspondences between ontology entities. OAEIcampaigns aim at comparing ontology matching systems on precisely defined test sets. Testsets can use ontologies of different nature (from expressive OWL ontologies to simpledirectories) and use different modalities; eg; blind evaluation; open evaluation; consensus.OAEI-2008 builds over previous campaigns by having 4 tracks with 8 test sets followed by13 participants. Following the trend of previous years; more participants reach the forefront.The official results of the campaign are those published on the OAEI web site.,Proc. 3rd ISWC workshop on ontology matching (OM),2008,122
Enabling technologies for interoperability,Ubbo Visser; Heiner Stuckenschmidt; Holger Wache; Thomas Vögele,Abstract We present a new approach; which proposes to minimize the numerous problemsexisting in order to have fully interoperable GIS. We discuss the existence of theseheterogeneity problems and the fact that they must be solved to achieve interoperability.These problems are addressed on three levels: the syntactic; structural and semantic level.In addition; we identify the needs for an approach performing semantic translation forinteroperability and introduce a uniform description of contexts. Furthermore; we discuss aconceptual architecture Buster (Bremen University Semantic Translation for EnhancedRetrieval) which can provide intelligent information integration based on a reclassification ofinformation entities in a new context. Lastly; we demonstrate our theories by sketching a reallife scenario.,Workshop on the 14th International Symposium of Computer Science for Environmental Protection,2000,120
Final results of the ontology alignment evaluation initiative 2011,Jérôme Euzenat; Alfio Ferrara; Willem Robert Van Hague; Laura Hollink; Christian Meilicke; Andriy Nikolov; François Scharffe; Pavel Shvaiko; Heiner Stuckenschmidt; Ondrej Sváb-Zamazal; Cássia Trojahn dos Santos,Ontology matching consists of finding correspondences between entities of two ontologies.OAEI campaigns aim at comparing ontology matching systems on precisely defined testcases. Test cases can use ontologies of different nature (from simple directories toexpressive OWL ontologies) and use different modalities; eg; blind evaluation; openevaluation; consensus. OAEI-2011 builds over previous campaigns by having 4 tracks with 6test cases followed by 18 participants. Since 2010; the campaign introduces a newevaluation modality in association with the SEALS project. A subset of OAEI test cases isincluded in this new modality which provides more automation to the evaluation and moredirect feedback to the participants. This paper is an overall presentation of the OAEI 2011campaign.,Proc. 6th ISWC workshop on ontology matching (OM),2011,118
Semantic Web and Peer-to-peer: decentralized management and exchange of knowledge and information,Steffen Staab; Heiner Stuckenschmidt,The Semantic Web and Peer-to-Peer are two technologies that address a common need atdifferent levels:• The Semantic Web addresses the requirement that one may model;manipulate and query knowledge and information at the conceptual level rather than at thelevel of some technical implementation. Moreover; it pursues this objective in a way thatallows people from all over the world to relate their own view to this conceptual layer. Thus;the Semantic Web brings new degrees of freedom for changing and exchanging theconceptual layer of applications.• Peer-to-Peer technologies aim at abandoning centralizedcontrol in favor of decentralized organization principles. In this objective they bring newdegrees of freedom for changing information architectures and exchanging informationbetween different nodes in a network.,*,2006,118
Learning domain ontologies for semantic web service descriptions,Marta Sabou; Chris Wroe; Carole Goble; Heiner Stuckenschmidt,Abstract High quality domain ontologies are essential for successful employment ofsemantic Web services. However; their acquisition is difficult and costly; thus hampering thedevelopment of this field. In this paper we report on the first stage of research that aims todevelop (semi-) automatic ontology learning tools in the context of Web services that cansupport domain experts in the ontology building task. The goal of this first stage was to get abetter understanding of the problem at hand and to determine which techniques might befeasible to use. To this end; we developed a framework for (semi-) automatic ontologylearning from textual sources attached to Web services. The framework exploits the fact thatthese sources are expressed in a specific sublanguage; making them amenable toautomatic analysis. We implement two methods in this framework; which differ in the …,Web Semantics: Science; Services and Agents on the World Wide Web,2005,111
Fine-grained sentiment analysis with structural features,Cäcilia Zirn; Mathias Niepert; Heiner Stuckenschmidt; Michael Strube,Abstract Sentiment analysis is the problem of determining the polarity of a text with respect toa particular topic. For most applications; however; it is not only necessary to derive thepolarity of a text as a whole but also to extract negative and positive utterances on a morefinegrained level. Sentiment analysis systems working on the (sub-) sentence level;however; are difficult to develop since shorter textual segments rarely carry enoughinformation to determine their polarity out of context. In this paper; therefore; we present afully automatic framework for fine-grained sentiment analysis on the subsentence levelcombining multiple sentiment lexicons and neighborhood as well as discourse relations toovercome this problem. We use Markov logic to integrate polarity scores from differentsentiment lexicons with information about relations between neighboring segments; and …,Proceedings of 5th International Joint Conference on Natural Language Processing,2011,99
A metadata model for semantics-based peer-to-peer systems,Jeen Broekstra13; Marc Ehrig; Peter Haase; Frank Van Harmelen; Arjohn Kampman; Marta Sabou; Ronny Siebes; Steffen Staab; Heiner Stuckenschmidt; Christoph Tempich,Abstract. Peer-to-Peer systems are a new paradigm for information sharing and somesystems have successfully been deployed. It has been argued that current Peer-to-Peersystems suffer from the lack of semantics. The SWAP project (Semantic Web and Peer-to-Peer) aims at overcoming this problem by combining the Peer-to-Peer paradigm withSemantic Web technologies. In the course of our investigations it turned out that the natureof Peer-to-Peer systems requires some compromises with respect to the use of semanticknowledge models. In particular; the notion of ontology does not really apply as we often donot find a shared understanding of the domain. In this paper; we propose a data model forencoding semantic information that combines features of ontology (concept hierarchies;relational structures) with a flexible description and rating model that allows us to handle …,SemPGRID’03,2003,97
Ontologien: Konzepte; Technologien und Anwendungen,Heiner Stuckenschmidt,Ontologien haben durch die aktuellen Entwicklungen des Semantic Web große Beachtungerfahren; da jetzt Technologien bereitgestellt werden; die eine Verwendung von Ontologienin Informationssystemen ermöglichen. Beginnend mit den grundlegenden Konzepten undIdeen von Ontologien; die der Philosophie und Linguistik entstammen; stellt das Buch denaktuellen Stand der Technik im Bereich unterstützender Technologien aus der SemanticWeb Forschung dar und zeigt vielversprechende Anwendungsbiete auf. Das Buch richtetsich an alle Leser; die ein grundlegendes Interesse an Ontologien als Teil modernerInformationstechnologien haben und sich einen Überblick und schnellen Einstieg in dasGebiet verschaffen wollen.,*,2009,88
Reasoning with multi-version ontologies: A temporal logic approach,Zhisheng Huang; Heiner Stuckenschmidt,Abstract In this paper we propose a framework for reasoning with multi-version ontology; inwhich a temporal logic is developed to serve as its semantic foundation. We show that thetemporal logic approach can provide a solid semantic foundation which can support variousrequirements on multi-version ontology reasoning. We have implemented the prototype ofMORE (Multi-version Ontology REasoner); which is based on the proposed framework. Wehave tested MORE with several realistic ontologies. In this paper; we also discuss theimplementation issues and report the experiments with MORE.,International Semantic Web Conference,2005,87
Reasoning support for mapping revision,Christian Meilicke; Heiner Stuckenschmidt; Andrei Tamilin,Abstract Finding correct semantic correspondences between heterogeneous ontologies isone of the most challenging problems in the area of semantic web technologies. Asmanually constructing such mappings is not feasible in realistic scenarios; a number ofautomatic matching tools have been developed that propose mappings based on generalheuristics. As these heuristics often produce incorrect results; a manual revision is inevitablein order to guarantee the quality of generated mappings. Experiences with benchmarkingmatching systems revealed that the manual revision of mappings is still a very difficultproblem because it has to take the semantics of the ontologies as well as interactionsbetween mappings into account. In this article; we propose methods for supporting humanexperts in the task of revising automatically created mappings. In particular; we present …,Journal of logic and computation,2008,86
Exploring large document repositories with RDF technology: the DOPE project,Heiner Stuckenschmidt; Frank Van Harmelen; Anita De Waard; Tony Scerri; Ravinder Bhogal; Jan Van Buel; Ian Crowlesmith; Christiaan Fluit; Arjohn Kampman; Jeen Broekstra; Erik Van Mulligen,This thesaurus-based search system uses automatic indexing; RDF-based querying; andconcept-based visualization of results to support exploration of large online documentrepositories. Innovative research institutes rely on the availability of complete and accurateinformation about new research and development. Information providers such as Elseviermake it their business to provide the required information in a cost-effective way. Thesemantic Web will likely contribute significantly to this effort because it facilitates access toan unprecedented quantity of data. The DOPE project (Drug Ontology Project for Elsevier)explores ways to provide access to multiple life-science information sources through asingle interface.,IEEE Intelligent Systems,2004,85
Swap: Ontology-based knowledge management with peer-to-peer technology,Marc Ehrig; Christoph Tempich; Steffen Staab; J Broekstra; FV Harmelen; Marta Sabou; Ronny Siebes; Heiner Stuckenschmidt,Abstract The combination of Semantic Web and Peer-to-Peer is highly innovative withprospective benefits to the the individualization of work views as well as to the facilitation ofknowledge sharing. SWAP will tackle the challenges brought up by this novel combinationsuch that knowledge finding and sharing is effectively possible.,*,2003,84
RockIt: Exploiting Parallelism and Symmetry for MAP Inference in Statistical Relational Models.,Jan Noessner; Mathias Niepert; Heiner Stuckenschmidt,Abstract ROCKIT is a maximum a-posteriori (MAP) query engine for statistical relationalmodels. MAP inference in graphical models is an optimization problem which can becompiled to integer linear programs (ILPs). We describe several advances in translatingMAP queries to ILP instances and present the novel meta-algorithm cutting planeaggregation (CPA). CPA exploits local context-specific symmetries and bundles up sets oflinear constraints. The resulting counting constraints lead to more compact ILPs and makethe symmetry of the ground model more explicit to state-of-the-art ILP solvers. Moreover;ROCKIT parallelizes most parts of the MAP inference pipeline taking advantage ofubiquitous shared-memory multi-core architectures. We report on extensive experimentswith Markov logic network (MLN) benchmarks showing that ROCKIT outperforms the state …,AAAI Workshop: Statistical Relational Artificial Intelligence,2013,83
A pattern-based ontology matching approach for detecting complex correspondences,Dominique Ritze; Christian Meilicke; O Sváb-Zamazal; Heiner Stuckenschmidt,Abstract. State of the art ontology matching techniques are limited to detect simplecorrespondences between atomic concepts and properties. Nevertheless; for manyconcepts and properties atomic counterparts will not exist; while it is possible to constructequivalent complex concept and property descriptions. We define a correspondence whereat least one of the linked entities is non-atomic as complex correspondence. Further; weintroduce several patterns describing complex correspondences. In particular; we focus onmethods for automatically detecting complex correspondences. These methods are basedon a combination of basic matching techniques. We conduct experiments with differentdatasets and discuss the results.,ISWC Workshop on Ontology Matching; Chantilly (VA US),2009,81
Ontology modularization for knowledge selection: Experiments and evaluations,Mathieu d’Aquin; Anne Schlicht; Heiner Stuckenschmidt; Marta Sabou,Abstract Problems with large monolithical ontologies in terms of reusability; scalability andmaintenance have led to an increasing interest in modularization techniques for ontologies.Currently; existing work suffers from the fact that the notion of modularization is not as wellunderstood in the context of ontologies as it is in software engineering. In this paper; weexperiment on applying state-of-the-art tools for ontology modularization in the context of aconcrete application: the automatic selection of knowledge components to be used for Webpage annotation and semantic browsing. We conclude that; in a broader context; anevaluation framework is required to guide the choice of a modularization tool; in accordancewith the requirements of the considered application.,International Conference on Database and Expert Systems Applications,2007,81
Leveraging terminological structure for object reconciliation,Jan Noessner; Mathias Niepert; Christian Meilicke; Heiner Stuckenschmidt,Abstract It has been argued that linked open data is the major benefit of semantictechnologies for the web as it provides a huge amount of structured data that can beaccessed in a more effective way than web pages. While linked open data avoids manyproblems connected with the use of expressive ontologies such as the knowledgeacquisition bottleneck; data heterogeneity remains a challenging problem. In particular;identical objects may be referred to by different URIs in different data sets. Identifying suchrepresentations of the same object is called object reconciliation. In this paper; we propose anovel approach to object reconciliation that is based on an existing semantic similaritymeasure for linked data. We adapt the measure to the object reconciliation problem; presentexact and approximate algorithms that efficiently implement the methods; and provide a …,Extended Semantic Web Conference,2010,79
A Probabilistic-Logical Framework for Ontology Matching.,Mathias Niepert; Christian Meilicke; Heiner Stuckenschmidt,Abstract Ontology matching is the problem of determining correspondences betweenconcepts; properties; and individuals of different heterogeneous ontologies. With this paperwe present a novel probabilistic-logical framework for ontology matching based on Markovlogic. We define the syntax and semantics and provide a formalization of the ontologymatching problem within the framework. The approach has several advantages over existingmethods such as ease of experimentation; incoherence mitigation during the alignmentprocess; and the incorporation of a-priori confidence values. We show empirically that theapproach is efficient and more accurate than existing matchers on an established ontologyalignment benchmark dataset.,AAAI,2010,77
Introduction to the ontology alignment evaluation 2005,Jérôme Euzenat; Heiner Stuckenschmidt; Mikalai Yatskevich,The increasing number of methods available for schema matching/ontology integrationsuggests the need to establish a consensus for evaluation of these methods. The OntologyAlignment Evaluation Initiative1 is now a coordinated international initiative that has beenset up for organising evaluation of ontology matching algorithms. After the two eventsorganized in 2004 (namely; the Information Interpretation and Integration Conference(I3CON) and the EON Ontology Alignment Contest [4]); this year one unique evaluationcampaign is organised. Its outcome is presented at the Workshop on Integrating Ontologiesheld in conjunction with K-CAP 2005 at Banff (Canada) on October 2; 2005. Since last year;we have set up a web site; improved the software on which the tests can be evaluated andset up some precise guidelines for running these tests. We have taken into account last …,Proc. K-Cap 2005 workshop on Integrating ontology,2005,75
Recognizing interleaved and concurrent activities: A statistical-relational approach,Rim Helaoui; Mathias Niepert; Heiner Stuckenschmidt,A majority of the approaches to activity recognition in sensor environments are either basedon manually constructed rules for recognizing activities or lack the ability to incorporatecomplex temporal dependencies. Furthermore; in many cases; the rather unrealisticassumption is made that the subject carries out only one activity at a time. In this paper; wedescribe the use of Markov logic as a declarative framework for recognizing interleaved andconcurrent activities incorporating both input from pervasive light-weight sensor technologyand common-sense background knowledge. In particular; we assess its ability to learnstatistical-temporal models from training data and to combine these models with backgroundknowledge to improve the overall recognition accuracy. To this end; we propose two Markovlogic formulations for inferring the foreground activity as well as each activities' start and …,Pervasive Computing and Communications (PerCom); 2011 IEEE International Conference on,2011,71
Interoperability in GIS-enabling technologies,Ubbo Visser; Heiner Stuckenschmidt; Christoph Schlieder,Abstract: We present a new approach; which proposes to minimize the numerous problemsexisting in order to have fully interoperable GIS. We discuss the existence of theseheterogeneity problems and the fact that they must be solved to achieve interoperability.These problems are addressed on three levels: the syntactic; structural and semantic level.In addition; we identify the needs for an approach performing semantic translation forinteroperability and introduce a uniform description of contexts. Furthermore; we discuss aconceptual architecture BUSTER (Bremen University Semantic Translation for EnhancedRetrieval); which can provide intelligent information integration; based on a reclassificationof information entities in a new context. Also; we demonstrate our theories with theimplemented prototype of our approach sketching a real life scenario. Lastly; we will …,Proceedings of the 5th AGILE Conference on Geographic Information Science,2002,71
A personalized music system for motivation in sport performance,Gertjan Wijnalda; Steffen Pauws; Fabio Vignoli; Heiner Stuckenschmidt,We developed a personalized music system called IM4Sports (interactive music for sports)for individual exercising; although running is the prime target. Research prototype of thesystem consists of a personal computer; a portable music flash player; a heart sensor strap;and a pedometer.,IEEE pervasive computing,2005,70
The SWAP data and metadata model for semantics-based peer-to-peer systems,Marc Ehrig; Peter Haase; Ronny Siebes; Steffen Staab; Heiner Stuckenschmidt; Rudi Studer; Christoph Tempich,Abstract Peer-to-Peer systems are a new paradigm for information sharing and somesystems have successfully been deployed. It has been argued that current Peer-to-Peersystems suffer from the lack of semantics. The SWAP project (Semantic Web and Peer-to-Peer) aims at overcoming this problem by combining the Peer-to-Peer paradigm withSemantic Web technologies. In this paper; we propose a data model for encoding semanticinformation that combines features of ontologies (concept hierarchies; relational structures)with a flexible description and rating model that allows us to handle heterogeneous andeven contradictory views on the domain of interest. We discuss the role of this model in theSWAP environment and describe the model as well as its application.,German Conference on Multiagent System Technologies,2003,68
A probabilistic ontological framework for the recognition of multilevel human activities,Rim Helaoui; Daniele Riboni; Heiner Stuckenschmidt,Abstract A major challenge of ubiquitous computing resides in the acquisition and modellingof rich and heterogeneous context data; among which; ongoing human activities at differentdegrees of granularity. In a previous work; we advocated the use of probabilistic descriptionlogics (DLs) in a multilevel activity recognition framework. In this paper; we present an in-depth study of activity modeling and reasoning within that framework; as well as anexperimental evaluation with a large real-world dataset. Our solution allows us to cope withthe uncertain nature of ontological descriptions of activities; while exploiting the expressivepower and inference tools of the OWL 2 language. Targeting a large dataset of real humanactivities; we developed a probabilistic ontology modeling nearly 150 activities and actionsof daily living. Experiments with a prototype implementation of our framework confirm the …,Proceedings of the 2013 ACM international joint conference on Pervasive and ubiquitous computing,2013,67
Criteria and evaluation for ontology modularization techniques,Mathieu d’Aquin; Anne Schlicht; Heiner Stuckenschmidt; Marta Sabou,Summary While many authors have argued for the benefits of applying principles ofmodularization to ontologies; there is not yet a common understanding of how modules aredefined and what properties they should have. In the previous section; this question wasaddressed from a purely logical point of view. In this chapter; we take a broader view onpossible criteria that can be used to determine the quality of a modules. Such criteria includelogic-based; but also structural and application-dependent criteria; sometimes borrowingfrom related fields such as software engineering. We give an overview of possible criteriaand identify a lack of application-dependent quality measures. We further report somemodularization experiments and discuss the role of quality criteria and evaluation in thecontext of these experiments.,*,2009,66
Probabilistic optimization of semantic process model matching,Henrik Leopold; Mathias Niepert; Matthias Weidlich; Jan Mendling; Remco Dijkman; Heiner Stuckenschmidt,Abstract Business process models are increasingly used by companies; often yieldingrepositories of several thousand models. These models are of great value for businessanalysis such as service identification or process standardization. A problem is though thatmany of these analyses require the pairwise comparison of process models; which is hardlyfeasible to do manually given an extensive number of models. While the computation ofsimilarity between a pair of process models has been intensively studied in recent years;there is a notable gap on automatically matching activities of two process models. In thispaper; we develop an approach based on semantic techniques and probabilisticoptimization. We evaluate our approach using a sample of admission processes fromdifferent universities.,International Conference on Business Process Management,2012,65
Ontology-based information sharing in weakly structured environments,Heiner Stuckenschmidt,The so-called information society demands for complete access to available information;which is often heterogeneous and distributed. Most information systems use specific datamodels and databases for this purpose. This implies that making new data available to asystem requires; that the data is either transferred into the system's specific data format or iseven acquired again. This process is very time consuming and tedious. Data acquisition;automatically or semi-automatically; often makes large-scale investment in technicalinfrastructure and/or manpower inevitable. The idea of information sharing is to overcomethese problems by providing common access to existing information sources Theadvantages of successful information sharing are obvious for many reasons:,*,2003,65
Context Modeling and Transformation for Semantic Interoperability.,Heiner Stuckenschmidt; Holger Wache,Abstract Mediators are middleware components that provide a flexible integration of severalheterogeneous information systems. But current approaches ignore that each informationhas to be considered in its context. Besides the integration the information has to be alsoconverted from its source context into the context of the integrated view in order to achieveinteroperability at the semantic level. Two different methods for context transformation arediscussed: a rule-based and a classification-based context transformation. We argue that therule-based context transformation approach does only provide solutions for rather simpletransformation tasks. We present an alternative approach that is based on sophisticatedcontext modeling using ontologies based on description logics. We show that this approachsupports context transformation based on subsumption reasoning offering reasonable …,KRDB,2000,64
Improving ontology matching using meta-level learning,Kai Eckert; Christian Meilicke; Heiner Stuckenschmidt,Abstract Despite serious research efforts; automatic ontology matching still suffers fromsevere problems with respect to the quality of matching results. Existing matching systemstrade-off precision and recall and have their specific strengths and weaknesses. This leadsto problems when the right matcher for a given task has to be selected. In this paper; wepresent a method for improving matching results by not choosing a specific matcher butapplying machine learning techniques on an ensemble of matchers. Hereby we learn rulesfor the correctness of a correspondence based on the output of different matchers andadditional information about the nature of the elements to be matched; thus leveraging theweaknesses of an individual matcher. We show that our method always performssignificantly better than the median of the matchers used and in most cases outperforms …,European Semantic Web Conference,2009,63
Log-linear description logics,Mathias Niepert; Jan Noessner; Heiner Stuckenschmidt,Abstract Log-linear description logics are a family of probabilistic logics integrating variousconcepts and methods from the areas of knowledge representation and reasoning andstatistical relational AI. We define the syntax and semantics of log-linear description logics;describe a convenient representation as sets of first-order formulas; and discusscomputational and algorithmic aspects of probabilistic queries in the language. The paperconcludes with an experimental evaluation of an implementation of a log-linear DLreasoner.,IJCAI,2011,59
Towards distributed processing of RDF path queries,Heiner Stuckenschmidt; Richard Vdovjak; Jeen Broekstra; Geert-Jan Houben,A technical infrastructure for storing; querying and managing RDF data is a key element inthe current semantic web development. Systems like Jena; Sesame or the ICS-FORTH RDFSuite are widely used for building semantic web applications. Currently; none of thesesystems support the integrated querying of distributed RDF repositories. We consider this amajor shortcoming since the semantic web is distributed by nature. In this paper we presentan architecture for querying distributed RDF repositories by extending the existing Sesamesystem. We discuss the implications of our architecture and propose an index structure aswell as algorithms for query processing and optimisation in such a distributed context.,International Journal of Web Engineering and Technology,2005,59
Semantic translation based on approximate re-classification,Heiner Stuckenschmidt; Ubbo Visser,Abstract We present a knowledge-based approach to intelligent information integrationbased on a re-classi cation of information entities in a new context. We identify the needs ofapproaches performing semantic translation; we introduce a uniform description of contextsand discuss a naive classi cation approach. We argue that this approach makes unrealisticassumptions about the absence of uncertainty. To overcome this problem we discussseveral approximate classi cation approaches and their use for information integration.Thereby we address symbolic as well as numeric approaches for uncertainty handling. Wesumarize with a description of an actual application area and a discussion of open researchtopics.,Proceedings of the’Semantic Approximation; Granularity and Vagueness’ Workshop,2000,59
Learning disjointness for debugging mappings between lightweight ontologies,Christian Meilicke; Johanna Völker; Heiner Stuckenschmidt,Abstract Dealing with heterogeneous ontologies by means of semantic mappings hasbecome an important area of research and a number of systems for discovering mappingsbetween ontologies have been developed. Most of these systems rely on general heuristicsfor finding mappings; hence are bound to fail in many situations. Consequently;automatically generated mappings often contain logical inconsistencies that hinder asensible use of these mappings. In previous work; we presented an approach for debuggingmappings between expressive ontologies that eliminates inconsistencies by means ofdiagnostic reasoning. A shortcoming of this method was its need for expressive classdefinitions. More specifically; the applicability of this method critically relies on the existenceof a high-quality disjointness axiomatization. This paper deals with the application of the …,International Conference on Knowledge Engineering and Knowledge Management,2008,56
Analyzing mapping extraction approaches,Christian Meilicke; Heiner Stuckenschmidt,Abstract. While lots of research in ontology matching is related to the issue of computing andrefining similarity measures; only little attention has been paid to question how to extract thefinal alignment from a matrix of similarity values. In this paper we present a theoreticalframework for describing extraction methods and argue that the quality of the final matchingresult is highly affected by the extraction method. Therefore; we discuss several extractionmethods and apply them to some of the results submitted to the OAEI 2006. The results ofour experimental study show that the proposed strategies differ with respect to precision andrecall. In particular; theoretical considerations as well as emprirical results indicate thatmethods that additionally make use of information encoded in the ontologies result in betterextractions compared to state of the art approaches.,Proceedings of the 2nd International Conference on Ontology Matching-Volume 304,2007,56
Incoherence as a basis for measuring the quality of ontology mappings,Christian Meilicke; Heiner Stuckenschmidt,Abstract Traditionally; the quality of ontology matching is measured using precision andrecall with respect to a reference mapping. These measures have at least two majordrawbacks. First; a mapping with acceptable precision and recall might nevertheless sufferfrom internal logical problems that hinder a sensible use of the mapping. Second; inpractical situations reference mappings are not available. To avoid these drawbacks weintroduce quality measures that are based on the notion of mapping incoherence that can beused without a reference mapping. We argue that these measures are a reasonablecomplement to the well-known measures already used for mapping evaluation. In particular;we show that one of these measures provides a strict upper bound for the precision of amapping.,Proceedings of the 3rd International Conference on Ontology Matching-Volume 431,2008,55
A formal investigation of mapping language for terminological knowledge,Luciano Serafini; Heiner Stuckenschmidt; Holger Wache,Abstract The need to represent mappings between different ontologies has been recognizedas a result of the fact that different ontologies may partially overlap; or even represent thesame domain from different points of view. Unlike ontology languages; work on languages torepresent ontology mappings has not yet reached a state where a common understanding ofthe basic principles exists. In this paper we propose a formal comparison of existingmapping languages by translating them into distributed first order logic. This allows us toanalyze underlying assumptions and differences in the interpretation of ontology mappings.,IJCAI,2005,55
Ontology-based metadata generation from semi-structured information,Heiner Stuckenschmidt; Frank Van Harmelen,Abstract Content-related metadata plays an important role in intelligent information systems.Especially on the world-wide web meaningful metadata describing the contents of a web-site is the key to intelligent retrieval and access of information. Metadata descriptionstandards like RDF and RDF schema have been developed and work in progressaddresses the use of ontologies to provide a logical foundation for metadata. However; theacquisition of appropriate metadata is still a problem. The main part of the paper isconcerned with the specification of ontologies and metadata models. We describe theSpectacle approach; a knowledge-based approach for metadata validation and generationas well as tools related to the ontology language OIL. We conclude that the specification ofontologies and the generation of metadata models are processes that supplement each …,Proceedings of the 1st international conference on Knowledge capture,2001,55
Cássia Trojahn; Ontology alignment evaluation initiative: six years of experience,Jérôme Euzenat; Christian Meilicke; Heiner Stuckenschmidt; Pavel Shvaiko,*,Journal on data semantics XV; Springer-Verlag; Berlin; Heidelberg,2011,53
Approximating terminological queries,Heiner Stuckenschmidt; Frank Van Harmelen,Abstract Current proposals for languages to encode terminological knowledge in intelligentsystems support logical reasoning for answering user queries about objects and classes. Anapplication ofthese languages on the World Wide Web; however; is hampered by thelimitations of logical reasoning in terms of efficiency and flexibility. In this paper we describe;how techniques from approximate reasoning can be used to overcome these problems. Wediscuss terminological knowledge and approximate reasoning in general and show thebenefits ofappro ximate reasoning using the example ofbuilding and maintaining semanticcatalogues that can be used to query resource locations based on object classes.,International Conference on Flexible Query Answering Systems,2002,53
MultiFarm: A benchmark for multilingual ontology matching,Christian Meilicke; RaúL GarcíA-Castro; Fred Freitas; Willem Robert Van Hage; Elena Montiel-Ponsoda; Ryan Ribeiro De Azevedo; Heiner Stuckenschmidt; OndřEj ŠVáB-Zamazal; Vojtěch Svátek; Andrei Tamilin; Cássia Trojahn; Shenghui Wang,Abstract In this paper we present the MultiFarm dataset; which has been designed as abenchmark for multilingual ontology matching. The MultiFarm dataset is composed of a setof ontologies translated in different languages and the corresponding alignments betweenthese ontologies. It is based on the OntoFarm dataset; which has been used successfully forseveral years in the Ontology Alignment Evaluation Initiative (OAEI). By translating theontologies of the OntoFarm dataset into eight different languages–Chinese; Czech; Dutch;French; German; Portuguese; Russian; and Spanish–we created a comprehensive set ofrealistic test cases. Based on these test cases; it is possible to evaluate and compare theperformance of matching approaches with a special focus on multilingualism.,Web Semantics: Science; Services and Agents on the World Wide Web,2012,52
Structure-based partitioning of large ontologies,Heiner Stuckenschmidt; Anne Schlicht,Summary In this chapter we describe a method for structure-based ontology partitioning andits implementation that is practically applicable to very large ontologies. We show that amodularization based on structural properties of the ontology only already results inmodules that intuitively make sense. The method was used for creating an overview graphfor ontologies and for extracting key topics from an ontology that correspond to topicsselected by human experts. Because the optimal modularization of an ontology greatlydepends on the application it is used for; we implemented the partitioning algorithm in a waythat allows for adaption to different requirements. Furthermore this adaption can beperformed automatically by specifying requirements of the application.,*,2009,52
Using environmental information efficiently: Sharing data and knowledge from heterogeneous sources,Ubbo Visser; Heiner Stuckenschmidt; Holger Wache; Thomas Vögele,Environmental information systems have gained more importance both in the publicadministration and industry since the beginning of 1990. For example; in publicadministration; every state in the Federal Republic of Germany has developed a type ofenvironmental information system. National and European legislation demanding farreaching transparency in the state of the environment encouraged this development. Inindustry on the other hand; environmental information systems are used for cost-and product-specific recording of waste flows. These are used to point out weak points within thecompanies' processes. Both application areas share the need to store and process largeamounts of diverse data; which is often geographically distributed. Most environmentalinformation systems use specific data models and databases for this purpose. This …,Environmental information systems in industry and public administration,2001,52
RDF storage and retrieval systems,Alice Hertel; Jeen Broekstra; Heiner Stuckenschmidt,Summary Ontologies are often used to improve data access. For this purpose; existing datahas to be linked to an ontology and appropriate access mechanisms have to be provided. Inthis chapter; we review RDF storage and retrieval technologies as a common approach foraccessing ontology-based data. We discuss different storage models; typical functionalitiesof RDF middleware such as data model support and reasoning capabilities and RDF querylanguages with a special focus on SPARQL as an emerging standard. We also discusssome trends such as support for expressive ontology and rule languages.,*,2009,48
Debugging OWL Ontologies-A Reality Check.,Heiner Stuckenschmidt,Abstract. One of the arguments for choosing description logics as the basis for the WebOntology Language is the ability to support the development of complex ontologies throughlogical reasoning. Recently; significant work has been done on developing advancedmethods for debugging erroneous ontologies that go beyond the pure identification ofinconsistencies. While the theory of these methods has been studied extensively littleattention has been paid to the application of these Methods in practice. In this paper; weevaluate existing implementations of advanced methods for debugging description logicontologies. We show that most existing systems suffer from serious problems with respect toscalability but surprisingly enough also with respect to the correctness of the results oncertain test sets. We conclude that there is a need for further improvements of existing …,EON,2008,48
Crowdsourcing the assembly of concept hierarchies,Kai Eckert; Mathias Niepert; Christof Niemann; Cameron Buckner; Colin Allen; Heiner Stuckenschmidt,Abstract The" wisdom of crowds" is accomplishing tasks that are cumbersome for individualsyet cannot be fully automated by means of specialized computer algorithms. One such taskis the construction of thesauri and other types of concept hierarchies. Human expertfeedback on the relatedness and relative generality of terms; however; can be aggregated todynamically construct evolving concept hierarchies. The InPhO (Indiana PhilosophyOntology) project bootstraps feedback from volunteer users unskilled in ontology design intoa precise representation of a specific domain. The approach combines statistical textprocessing methods with expert feedback and logic programming to create a dynamicsemantic representation of the discipline of philosophy. In this paper; we show that results ofcomparable quality can be achieved by leveraging the workforce of crowdsourcing …,Proceedings of the 10th annual joint conference on Digital libraries,2010,47
An efficient method for computing alignment diagnoses,Christian Meilicke; Heiner Stuckenschmidt,Abstract Formal; logic-based semantics have long been neglected in ontology matching. Asa result; almost all matching systems produce incoherent alignments of ontologies. In thispaper we propose a new method for repairing such incoherent alignments that extendsprevious work on this subject. We describe our approach within the theory of diagnosis andintroduce the notion of a local optimal diagnosis. We argue that computing a local optimaldiagnosis is a reasonable choice for resolving alignment incoherence and suggest anefficient algorithm. This algorithm partially exploits incomplete reasoning techniques toincrease runtime performance. Nevertheless; the completeness and optimality of thesolution is still preserved. Finally; we test our approach in an experimental study and discussresults with respect to runtime and diagnostic quality.,International Conference on Web Reasoning and Rule Systems,2009,47
An efficient method for computing alignment diagnoses,Christian Meilicke; Heiner Stuckenschmidt,Abstract Formal; logic-based semantics have long been neglected in ontology matching. Asa result; almost all matching systems produce incoherent alignments of ontologies. In thispaper we propose a new method for repairing such incoherent alignments that extendsprevious work on this subject. We describe our approach within the theory of diagnosis andintroduce the notion of a local optimal diagnosis. We argue that computing a local optimaldiagnosis is a reasonable choice for resolving alignment incoherence and suggest anefficient algorithm. This algorithm partially exploits incomplete reasoning techniques toincrease runtime performance. Nevertheless; the completeness and optimality of thesolution is still preserved. Finally; we test our approach in an experimental study and discussresults with respect to runtime and diagnostic quality.,International Conference on Web Reasoning and Rule Systems,2009,47
Approximating description logic classification for semantic web reasoning,Perry Groot; Heiner Stuckenschmidt; Holger Wache,Abstract In many application scenarios; the use of the Web ontology language OWL ishampered by the complexity of the underlying logic that makes reasoning in OWL intractablein the worst case. In this paper; we address the question whether approximation techniquesknown from the knowledge representation literature can help to simplify OWL reasoning. Inparticular; we carry out experiments with approximate deduction techniques on the problemof classifying new concept expressions into an existing OWL ontology using existingOntologies on the web. Our experiments show that a direct application of approximatededuction techniques as proposed in the literature in most cases does not lead to animprovement and that these methods also suffer from some fundamental problems.,European Semantic Web Conference,2005,47
Reasoning about ontology mappings,Heiner Stuckenschmidt; Luciano Serafini; Holger Wache,Abstract: The use of logic-based representations in distributed environments such as thesemantic web has lead to work on the representation of and reasoning with mappingsbetween distributed ontologies. Up to now the investigation of reasoning methods in thisarea was restricted to the use of mapping for query answering or subsumption reasoning. Inthis paper; we investigate the task of reasoning about the mappings themselves. We identifya number of properties such as consistency and entailment of mappings that are importantfor validating and comparing mappings. We provide formal definitions for these propertiesand show how the properties can be checked using existing reasoning methods by reducingthem to local and global satisfiability testing in distributed description logics.,Technical reports,2005,47
Reasoning and change management in modular ontologies,Heiner Stuckenschmidt; Michel Klein,Abstract The benefits of modular representations are well known from many areas ofcomputer science. While in software engineering modularization is mainly a vehicle forsupporting distributed development and re-use; in knowledge representation; the main goalof modularization is efficiency of reasoning. In this paper; we concentrate on the benefits ofmodularization in the context of ontologies; explicit representations of the terminology usedin a domain. We define a formal representation for modular ontologies based on the notionof Distributed Description Logics and introduce an architecture that supports local reasoningby compiling implied axioms. We further address the problem of guaranteeing thecorrectness and completeness of compiled knowledge in the presence of changes indifferent modules. We propose a heuristic for analyzing changes and their impact on …,Data & Knowledge Engineering,2007,46
Ontology alignment: An annotated bibliography,Natasha Noy; Heiner Stuckenschmidt,Abstract Ontology mapping; alignment; and translation has been an active researchcomponent of the general research on semantic integration and interoperability. In our talk;we gave our own classification of different topics in this research. We talked about types ofheterogeneity between ontologies; various mapping representations; classified methods fordiscovering methods both between ontology concepts and data; and talked about varioustasks where mappings are used. In this extended abstract of our talk; we provide anannotated bibliography for this area of research; giving readers brief pointers onrepresentative papers in each of the topics mentioned above. We did not attempt to compilea comprehensive bibliography and hence the list in this abstract is necessarily incomplete.Rather; we tried to sketch a map of the field; with some specific reference to help …,Dagstuhl Seminar Proceedings,2005,45
Towards structural criteria for ontology modularization,Anne Schlicht; Heiner Stuckenschmidt,Abstract. Recently; the benefits of modular representations of ontologies has beenrecognized by the semantic web community. Existing methods for splitting up models intomodules either optimize for completeness of local or for the efficiency of distributedreasoning. In our work on semantics-based P2P systems; we are also concerned with theadditional criteria of robustness or reasoning in cases where peers are unavailable and withease of maintenance. We define a number of structural criteria for modularized ontologiesand argue why these criteria are suitable for estimating efficiency; robustness andmaintainability. We apply the criteria to a number of modularization approaches and discussthe trade-offs made. Based on the discussion we propose a general quality measure formodular representations in the context of our use case.,Proceedings of the 1st International Conference on Modular Ontologies-Volume 232,2006,42
Adapting communication vocabularies using shared ontologies,Heiner Stuckenschmidt; Ingo J Timm,ABSTRACT In has been argued that ontologies play a key role in multiagent communicationbecause they provide and define a shared vocabulary to be used in the course ofcommunication. In real-life scenarios; however; the situation where two agents completelyshare a vocabulary is rather an exception. More often; each agent uses its own vocabularyspecified in a private ontology that is not known by other agents. In this paper we propose asolution to this problem for the situation; where agents share at least parts of theirvocabulary. We argue that the assumption of a partially shared vocabulary is valid andsketch an approach for re-formulating terms from the private part of an agent's ontology intoa shared part thus enabling other agents to understand them. We further describe how theapproach can be implemented using existing technology and proof the correctness of the …,Proceedings of the Second International Workshop on Ontologies in Agent Systems; Workshop at 1st International Conference on Autonomous Agents and Multi-Agent Systems,2002,42
Towards expressive stream reasoning,Heiner Stuckenschmidt; Stefano Ceri; Emanuele Della Valle; Frank Van Harmelen,Abstract Stream Data processing has become a popular topic in database researchaddressing the challenge of efficiently answering queries over continuous data streams.Meanwhile data streams have become more and more important as a basis for higher leveldecision processes that require complex reasoning over data streams and rich backgroundknowledge. In previous work the foundation for complex reasoning over streams andbackground knowledge was laid by introducing technologies for wrapping and queryingstreams in the RDF data format and by supporting simple forms of reasoning in terms ofincremental view maintenance. In this paper; we discuss how this existing technologiesshould be extended toward richer forms of reasoning using Sensor Networks as a motivatingexample.,Dagstuhl Seminar proceedings,2010,41
Using C-OWL for the alignment and merging of medical ontologies,Heiner Stuckenschmidt; Frank Van Harmelen; Luciano Serafini; Paolo Bouquet; Fausto Giunchiglia,A number of sophisticated medical ontologies have been created over the past years. Withtheir development the need for supporting the alignment of different ontologies is gainingimportance. We proposed C-OWL; an extension of the Web Ontology Language OWL thatsupports alignment mappings between different; possibly incompatible ontologies on asemantic level. In this paper we report experiences from using C-OWL for the alignment ofmedical ontologies. We briefly review key concepts of the C-OWL semantics; explain thesetting of the case study including some examples from the alignment and discuss thepossibility of reasoning about the mapping based on the C-OWL semantics. We conclude byarguing that C-OWL provides an adequate framework for aligning complex ontologies in themedical domain.,*,2004,41
Relaxing RDF queries based on user and domain preferences,Peter Dolog; Heiner Stuckenschmidt; Holger Wache; Jörg Diederich,Abstract Research in cooperative query answering is triggered by the observation that usersare often not able to correctly formulate queries to databases such that they return theintended result. Due to lacking knowledge about the contents and the structure of adatabase; users will often only be able to provide very broad queries. Existing methods forautomatically refining such queries based on user profiles often overshoot the targetresulting in queries that do not return any answer. In this article; we investigate methods forautomatically relaxing such over-constrained queries based on domain knowledge and userpreferences. We describe a framework for information access that combines queryrefinement and relaxation in order to provide robust; personalized access to heterogeneousresource description framework data as well as an implementation in terms of rewriting …,Journal of Intelligent Information Systems,2009,40
Scalable instance retrieval for the semantic web by approximation,Holger Wache; Perry Groot; Heiner Stuckenschmidt,Abstract Approximation has been identified as a potential way of reducing the complexity oflogical reasoning. Here we explore approximation for speeding up instance retrieval in aSemantic Web context. For OWL ontologies; ie; Description Logic (DL) Knowledge Bases; itis known that reasoning is a hard problem. Especially in instance retrieval when the numberof instances that need to be retrieved becomes very large. We discuss two approximationmethods for retrieving instances to conjunctive queries over DL T-Boxes and the results ofexperiments carried out with a modified version of the Instance Store System.,International Conference on Web Information Systems Engineering,2005,40
Probabilistic models for the semantic web: A survey,Livia Predoiu; Heiner Stuckenschmidt,AbstrAct Recently; there has been an increasing interest in formalisms for representinguncertain information on the Semantic Web. This interest is triggered by the observation thatknowledge on the web is not always crisp and we have to be able to deal with incomplete;inconsistent and vague information. The treatment of this kind of information requires newapproaches for knowledge representation and reasoning on the web as existing SemanticWeb languages are based on classical logic which is known to be inadequate forrepresenting uncertainty in many cases. While different general approaches for extendingSemantic Web languages with the ability to represent uncertainty are explored; we focus ourattention on probabilistic approaches. We survey existing proposals for extending semanticweb languages or formalisms underlying Semantic Web languages in terms of their …,The Semantic Web for Knowledge and Data Management: Technologies and Practices. Information Science Reference; Hershey; PA; USA,2008,39
Improving automatically created mappings using logical reasoning,Christian Meilicke; Heiner Stuckenschmidt; Andrei Tamilin,Abstract A lot of attention has been devoted to heuristic methods for discovering semanticmappings between ontologies. Despite impressive improvements; the mappings created bythese automatic matching tools are still far from being perfect. In particular; they often containwrong and redundant mapping rules. In this paper we present an approach for improvingsuch mappings using logical reasoning in the context of Distributed Description Logics(DDL). Our method is orthogonal to the matching algorithm used and can therefore be usedin combination with any matching tool. We explain the general idea of our approachinformally using a small example and present the results of experiments conducted on theOntoFarm Benchmark which is part of the Ontology Alignment Evaluation challenge.,Proceedings of the 1st International Conference on Ontology Matching-Volume 225,2006,39
Guest editor's introduction: Ontology issues and applications,Fred Freitas; Heiner Stuckenschmidt; Natalya F Noy,After being studied by philosophers for twenty three centuries;" ontologies" have recentlybecome a new buzzword in computer science. The topic is currently receiving specialattention not only from an active community of researchers from many areas of informatics;but also from the industry; which is providing increasing budgets and investments to developthis technology and to enhance its applicability in business settings.In computer scienceterms; an ontology comprises a set of definitions of concepts; properties; relations;constraints; axioms; processes and events that describe a certain domain or universe ofdiscourse. By providing this body of definitions about a domain; an ontology enablesapplications and software agents to use the precise; clear; formal semantics to process theinformation described by the ontology and to use this information in intelligent …,Journal of the Brazilian Computer Society,2005,38
Constructing a legal core ontology: LRI-Core,JAPJ Breuker; F Freitas; H Stuckenschmidt; R Volz,KNAW Narcis. Back to search results. Publication Constructing a legalcore ontology: LRI-Core (2004). Pagina-navigatie: Main …,*,2004,38
Practical context transformation for information system interoperability,Holger Wache; Heiner Stuckenschmidt,Abstract This paper discusses the use of contextual reasoning; ie context transformation forachieving semantic interoperability in heterogeneous information systems. We introduceterminological contexts and their explication in terms of formal ontologies. Using a real-worldexample; we compare two practical approaches for context transformation one based ontransformation rule; the other on re-classification of information entities in a differentterminological context. We argue that both approaches supplement each other and developa unifying theory of context transformation. A sound and complete context transformationcalculus is presented.,International and Interdisciplinary Conference on Modeling and Using Context,2001,36
A study in empirical and ‘casuistic’analysis of ontology mapping results,Ondřej Šváb; Vojtěch Svátek; Heiner Stuckenschmidt,Abstract Many ontology mapping systems nowadays exist. In order to evaluate theirstrengths and weaknesses; benchmark datasets (ontology collections) have been created;several of which have been used in the most recent edition of the Ontology AlignmentEvaluation Initiative (OAEI). While most OAEI tracks rely on straightforward comparison ofthe results achieved by the mapping systems with some kind of reference mapping created apriori; the'conference'track (based on the OntoFarm collection of heterogeneous' conferenceorganisation'ontologies) instead encompassed multiway manual as well as automatedanalysis of mapping results themselves; with 'correct'and 'incorrect'cases determined aposteriori. The manual analysis consisted in simple labelling of discovered mappings plusdiscussion of selected cases ('casuistics') within a face-to-face consensus building …,European Semantic Web Conference,2007,35
Mining RDF data for property axioms,Daniel Fleischhacker; Johanna Völker; Heiner Stuckenschmidt,Abstract The Linked Data cloud grows rapidly as more and more knowledge bases becomeavailable as Linked Data. Knowledge-based applications have to rely on efficientimplementations of query languages like SPARQL; in order to access the information whichis contained in large datasets such as DBpedia; Freebase or one of the many domain-specific RDF repositories. However; the retrieval of specific facts from an RDF dataset isoften hindered by the lack of schema knowledge; that would allow for query-time inferenceor the materialization of implicit facts. For example; if an RDF graph contains informationabout films and actors; but only Titanic starring Leonardo_DiCaprio is stated explicitly; aquery for all movies Leonardo DiCaprio acted in might not yield the expected answer. Only ifthe two properties starring and actedIn are declared inverse by a suitable schema; the …,OTM Confederated International Conferences" On the Move to Meaningful Internet Systems",2012,34
A flexible partitioning tool for large ontologies,Anne Schlicht; Heiner Stuckenschmidt,The benefits of modular ontologies in terms of easier creation and maintenance as well asbetter computational properties have been recognized by different researchers. As most realworld ontologies; however; are still designed in a monolithic way; there is a need formethods that partition an existing ontology into a set of modules. Currently; existing worksuffers from the fact that the notion of modularization is not as well understood in the contextof ontologies as it is in software engineering. In this paper we present a flexible partitioningtool for large ontologies that can be adapted to the needs of different applications based oncriteria that the resulting modular ontology should satisfy.,Web Intelligence and Intelligent Agent Technology; 2008. WI-IAT'08. IEEE/WIC/ACM International Conference on,2008,34
Applying logical constraints to ontology matching,Christian Meilicke; Heiner Stuckenschmidt,Abstract Automatically discovering semantic relations between ontologies is an importanttask with respect to overcoming semantic heterogeneity on the semantic web. Ontologymatching systems; however; often produce erroneous mappings. In this paper we propose amethod for optimizing precision and recall of existing matching systems. The principle of thismethod is based on the idea that it is possible to infer logical constraints by comparingsubsumption relations between concepts of the ontologies to be matched. In order to verifythis principle we implemented a system that uses our method as basis for optimizingmappings. We generated a set of synthetic ontologies and corresponding defectivemappings and studied the behavior of our method with respect to the properties of thematching problem. The results show that our strategy actually improves the quality of the …,Annual Conference on Artificial Intelligence,2007,34
Time–space trade-offs in scaling up RDF schema reasoning,Heiner Stuckenschmidt; Jeen Broekstra,Abstract A common way of reducing run time complexity of RDF Schema reasoning is tocompute (parts of) the deductive closure of a model offline. This reduces the complexity atrun time; but increases the space requirements and model maintenance because derivablefacts have to be stored explicitly and checked for validity when the model is updated. In thispaper we experimentally identify certain kinds of statements as the major sources for theincrease. Based on this observation; we develop a new approach for RDF reasoning thatonly computes a small part of the implied statements offline thereby reducing spacerequirements; upload time and maintenance overhead. The computed fragment is chosen insuch a way that the problem of inferring implied statements at run time can be reduced to asimple form of query re-writing. This new methods has two benefits: it reduces the amount …,International Conference on Web Information Systems Engineering,2005,33
Benchmarking matching applications on the semantic web,Alfio Ferrara; Stefano Montanelli; Jan Noessner; Heiner Stuckenschmidt,Abstract The evaluation of matching applications is becoming a major issue in the semanticweb and it requires a suitable methodological approach as well as appropriate benchmarks.In particular; in order to evaluate a matching application under different experimentalconditions; it is crucial to provide a test dataset characterized by a controlled variety ofdifferent heterogeneities among data that rarely occurs in real data repositories. In thispaper; we propose SWING (Semantic Web INstance Generation); a disciplined approach tothe semi-automatic generation of benchmarks to be used for the evaluation of matchingapplications.,Extended Semantic Web Conference,2011,31
Distributed resolution for expressive ontology networks,Anne Schlicht; Heiner Stuckenschmidt,Abstract The Semantic Web is commonly perceived as a web of partially interlinked machinereadable data. This data is inherently distributed and resembles the structure of the web interms of resources being provided by different parties at different physical locations. Anumber of infrastructures for storing and querying distributed semantic web data; primarilyencoded in RDF have been developed but almost all the work on description logicreasoning as a basis for implementing inference in the Web Ontology Language OWL stillassumes a centralized approach where the complete terminology has to be present on asingle system and all inference steps are carried out on this system. We propose adistributed reasoning method that preserves soundness and completeness of reasoningunder the original OWL import semantics. The method is based on resolution methods for …,International Conference on Web Reasoning and Rule Systems,2009,31
The'family of languages' approach to semantic interoperability,Jerome Euzenat1 Heiner Stuckenschmidt,Abstract Different Semantic Web applications can use different knowledge representationlanguages. Exchanging knowledge thus requires techniques for ensuring semanticinteroperability across languages. We present the'family of languages' approach based on aset of knowledge representation languages whose partial ordering depends on thetransformability from one language to another by preserving a particular formal propertysuch as logical consequence. For the same set of languages; there can be several suchstructures based on the property selected for structuring the family. Properties of differentstrength allow performing practicable but well founded transformations. The approach offersthe choice of the language in which a representation will be imported and the composition ofavailable transformations between the members of the family.,Knowledge transformation for the semantic web,2003,31
Using OIL for intelligent information integration,Heiner Stuckenschmidt,Abstract. Recently; the OIL language has been proposed as a new standard language forspecifying and exchanging ontologies. The build-in reasoning support that relies on theclose relationship between OIL and description logics was claimed to be advantageous inmany application areas and should be considered one of the main advantages over existinglanguages. In this paper; we address the validity of the claims made by the developers ofOIL focusing on the reasoning support provided. In order to test this support; we use anapplication from the field of intelligent information integration. We introduce the'BremenUniversity Semantic Translation Project'http: www. semantic-translation. de and review thesemantic integration problem. Based on this description we address the question of how OILcan be used to model information sources and shared terminologies required by the …,Proceedings of the Workshop on Applications of Ontologies and Problem-solving Methods; 14th European Conference on Artificial Intelligence ECAI,2000,31
Partial matchmaking using approximate subsumption,Heiner Stuckenschmidt,Abstract Description Logics; and in particular the web ontology language OWL has beenproposed as an appropriate basis for computing matches between structured objects for thesake of information integration and service discovery. A drawback of the direct use ofsubsumption as a matching criterion is the inability to compute partial matches and qualifythe degree of mismatch. In this paper; we describe a method for overcoming these problemsthat is based on approximate logical reasoning. In particular; we approximate thesubsumption relation by defining the notion of subsumption with respect to a certain subsetof the concept and relation names. We present the formal semantics of this relation; describea sound and complete algorithm for computing approximate subsumption and discuss itsapplication to matching tasks.,AAAI,2007,29
Toward multi-viewpoint reasoning with OWL ontologies,Heiner Stuckenschmidt,Abstract Despite of their advertisement as task independent representations; the reuse ofontologies in different contexts is difficult. An explanation for this is that when developing anontology; a choice is made with respect to what aspects of the world are relevant. In thispaper we deal with the problem of reusing ontologies in a context where only parts of theoriginally encoded aspects are relevant. We propose the notion of a viewpoint on anontology in terms of a subset of the complete representation vocabulary that is relevant in acertain context. We present an approach of implementing different viewpoints in terms of anapproximate subsumption operator that only cares about a subset of the vocabulary. Wediscuss the formal properties of subsumption with respect to a subset of the vocabulary andshow how these properties can be used to efficiently compute different viewpoints on the …,European Semantic Web Conference,2006,29
The process model matching contest 2015,Goncalo Antunes; Marzieh Bakhshandeh; Jose Borbinha; Joao Cardoso; Sharam Dadashnia; Chiara Di Francescomarino; Mauro Dragoni; Peter Fettke; Avigdor Gal; Chiara Ghidini; Philip Hake; Abderrahmane Khiat; Christopher Klinkmüller; Elena Kuss; Henrik Leopold; Peter Loos; Christian Meilicke; Tim Niesen; Catia Pesquita; Timo Péus; Andreas Schoknecht; Eitam Sheetrit; Andreas Sonntag; Heiner Stuckenschmidt; Tom Thaler; Ingo Weber; Matthias Weidlich,Process model matching refers to the automatic identification of correspondences betweenthe activities of process models. Application scenarios of process model matching reachfrom model validation over harmonization of process variants to effective management ofprocess model collections. Recognizing this; several process model matching techniqueshave been developed in recent years. However; to learn about specific strengths andweaknesses of these techniques; a common evaluation basis is indispensable. The secondedition of the Process Model Matching Contest in 2015 hence addresses the need foreffective evaluation by defining process model matching problems over published data sets.This paper summarizes the setup and the results of the contest. Next to a description of thecontest matching problems; the paper provides short descriptions of all matching …,Enterprise modelling and information systems architectures,2015,28
Supporting Manual Mapping Revision using Logical Reasoning.,Christian Meilicke; Heiner Stuckenschmidt; Andrei Tamilin,Abstract Finding correct semantic correspondences between ontologies is one of the mostchallenging problems in the area of semantic web technologies. Experiences withbenchmarking matching systems revealed that even the manual revision of automaticallygenerated mappings is a very difficult problem because it has to take the semantics of theontologies as well as interactions between correspondences into account. In this paper; wepropose methods for supporting human experts in the task of revising automatically createdmappings. In particular; we present non-standard reasoning methods for detecting andpropagating implications of expert decisions on the correctness of a mapping. We show thatthe use of these reasoning methods significantly reduces the effort of mapping revision interms of the number of decisions that have to be made by the expert.,AAAI,2008,28
Tightly integrated probabilistic description logic programs for representing ontology mappings,Andrea Calì; Thomas Lukasiewicz; Livia Predoiu; Heiner Stuckenschmidt,Abstract Creating mappings between ontologies is a common way of approaching thesemantic heterogeneity problem on the Semantic Web. To fit into the landscape of semanticweb languages; a suitable; logic-based representation formalism for mappings is needed.We argue that such a formalism has to be able to deal with uncertainty and inconsistenciesin automatically created mappings. We analyze the requirements for such a formalism; andwe propose a novel approach to probabilistic description logic programs as such aformalism; which tightly combines disjunctive logic programs under the answer setsemantics with both description logics and Bayesian probabilities. We define the language;and we show that it can be used to resolve inconsistencies and merge mappings fromdifferent matchers based on the level of confidence assigned to different rules …,International Symposium on Foundations of Information and Knowledge Systems,2008,28
Peer-to-peer reasoning for interlinked ontologies,Anne Schlicht; Heiner Stuckenschmidt,The Semantic Web is commonly perceived as a web of partially-interlinked machinereadable data. This data is inherently distributed and resembles the structure of the web interms of resources being provided by different parties at different physical locations. Anumber of infrastructures for storing and querying distributed semantic web data; primarilyencoded in RDF have been developed. While there are first attempts for integrating RDFSchema reasoning into distributed query processing; almost all the work on description logicreasoning as a basis for implementing inference in the Web Ontology Language OWL stillassumes a centralized approach where the complete terminology has to be present on asingle system and all inference steps are carried out on this system. We have designed andimplemented a distributed reasoning method that preserves soundness and …,International Journal of Semantic Computing,2010,27
The Semantic Web: Research and Applications: 6th European Semantic Web Conference; ESWC 2009 Heraklion; Crete; Greece; May 31–June 4; 2009 Proceedings,Lora Aroyo; Paolo Traverso; Fabio Ciravegna; Philipp Cimiano; Tom Heath; Eero Hyvönen; Riichiro Mizoguchi; Eyal Oren; Marta Sabou; Elena Simperl,This volume contains papers from the technical program of the 6th European Semantic WebConference (ESWC 2009); held from May 31 to June 4; 2009; in Heraklion; Greece. ESWC2009 presented the latest results in research and applications of Semantic Webtechnologies. In addition to the technical research track; ESWC 2009 featured a tutorialprogram; a PhD symposium; a system demo track; a poster track; a number of collocatedworkshops; and for the? rst time in the series a Semantic Web in-use track exploring thebene? ts of applying Semantic Web technology in real-life applications and contexts.Thetechnical researchpaper trackreceivedover250submissions. The review process wasorganized using a two-tiered system; where each submission was reviewed by at least threemembers of the Program Committee. Vice Program …,*,2009,27
Distributed Resolution for ALC.,Anne Schlicht; Heiner Stuckenschmidt,Abstract. The use of Description Logic as the basis for Semantic Web Languages has led tonew requirements with respect to scalable and nonstandard reasoning. In this paper; weaddress the problem of scalable reasoning by proposing a distributed; complete andterminating algorithm that decides satisfiability of terminologies in ALC. The algorithm isbased on recent results on applying resolution to description logics. We show that theresolution procedure proposed by Tammet can be distributed amongst multiple resolutionsolvers by assigning unique sets of literals to individual solvers. This results provides thebasis for a highly scalable reasoning infrastructure for Description logics.,Description logics,2008,26
Terminology integration for the management of distributed information resources,Ubbo Visser; Heiner Stuckenschmidt; Christoph Schlieder; Holger Wache; Ingo J.  Timm,Efficient information management and the processes therein become more and moreimportant within enterprises or when enterprises are merging together. Most informationsystems use specific data models and databases for this purpose. This implies that makingnew data available to the system requires; that the data be transferred; into the system'sspecific data format. This is a process; which is very time consuming and tedious. Dataacquisition; automatically or semi-automatically; often makes large-scale investment intechnical infrastructure and/or manpower inevitable. These obstacles are some of thereasons behind the concept of information integration.,KI,2002,26
Results of the ontology alignment evaluation initiative 2016,Manel Achichi; Michelle Cheatham; Zlatan Dragisic; Jérôme Euzenat; Daniel Faria; Alfio Ferrara; Giorgos Flouris; Irini Fundulaki; Ian Harrow; Valentina Ivanova; Ernesto Jiménez-Ruiz; Elena Kuss; Patrick Lambrix; Henrik Leopold; Huanyu Li; Christian Meilicke; Stefano Montanelli; Catia Pesquita; Tzanina Saveta; Pavel Shvaiko; Andrea Splendiani; Heiner Stuckenschmidt; Konstantin Todorov; Cássia Trojahn dos Santos; Ondrej Zamazal,Ontology matching consists of finding correspondences between semantically relatedentities of two ontologies. OAEI campaigns aim at comparing ontology matching systems onprecisely defined test cases. These test cases can use ontologies of different nature (fromsimple thesauri to expressive OWL ontologies) and use different modalities; eg; blindevaluation; open evaluation; or consensus. OAEI 2016 offered 9 tracks with 22 test cases;and was attended by 21 participants. This paper is an overall presentation of the OAEI 2016campaign.,OM: Ontology Matching,2016,25
MapResolve,Anne Schlicht; Heiner Stuckenschmidt,Abstract We propose an approach to scalable reasoning on description logic ontologies thatis based on MapReduce. Our work is inspired by previous work that provided fastmaterialization of RDFS ontologies and proposed MapReduce for more expressive logics.We explain challenges imposed by higher expressivity that were not addressed before anddescribe how they can be solved.,International Conference on Web Reasoning and Rule Systems,2011,25
Implementation and evaluation of a distributed rdf storage and retrieval system,Gergely Adamku; Heiner Stuckenschmidt,Abstract It is widely agreed that the Semantic Web will be build on RDF. Therefore thesuccess of the Semantic Web also depends on the availability of a scalable and reliableinfrastructure for storing and accessing RDF data. A number of storage and retrieval systemshave been developed recently; but despite the inherently distributed nature of the SemanticWeb most of these systems do not support distributed storage and retrieval of data. In thispaper we report our experiences with implementing a distributed storage and queryinfrastructure on top of an existing RDF infrastructure. We present the system architectureand discuss performance issues based on a set of experiments with the infrastructure. Weconclude with an identification of remaining performance bottlenecks and point to furtherimprovements.,Proceedings of the 2005 IEEE/WIC/ACM International Conference on Web Intelligence,2005,25
Similarity-based query caching,Heiner Stuckenschmidt,Abstract With the success of the semantic web infrastructures for storing and querying RDFdata are gaining importance. A couple of systems are available now that provide basicdatabase functionality for RDF data. Compared to modern database systems; RDF storagetechnology still lacks sophisticated optimization methods for query processing. Current workin this direction is mainly focussed on index structures for speeding up the access at triplelevel or for special queries. In this paper; we discuss semantic query caching as a high leveloptimization technique for RDF querying to supplement existing work on lower leveltechniques. Our approach for semantic caching is based on the notion of similarity of RDFqueries determined by the costs of modifying the results of a previous query into the resultfor the actual one. We discuss the problem of subsumption for RDF queries; present a …,International Conference on Flexible Query Answering Systems,2004,25
Approximate information filtering with multiple classification hierarchies,Heiner Stuckenschmidt,Web page categorization is an approach for improving precision and efficiency ofinformation retrieval on the web by filtering out irrelevant pages. Current approaches toinformation filtering based on categorization assume the existence of a single classificationhierarchy used for filtering. In this paper; we address the problem of filtering informationcategorized according to different classification hierarchies. We describe a method forapproximating Boolean queries over class names across different class hierarchies.,International Journal of Computational Intelligence and Applications,2002,25
Intelligent brokering of environmental information with the buster system,Holger Neumann; Gerhard Schuster; Heiner Stuckenschmidt; Ubbo Visser; Thomas Vögele; H Wache,Abstract In this paper we discuss the general problems which arise when informationsources have to be found and integrated into a system and present a solution by introducingthe BUSTER 2 system. We give an overview of our ontology-based approach with logicalreasoning on metadata for retrieving information sources and semantic translation into thedesired format.,international symposium informatics for environmental protection,2001,24
Generating and managing metadata for web-based information systems,Heiner Stuckenschmidt; Frank Van Harmelen,Abstract As metadata become of increasing importance to the Web; we will need to startmanaging such metadata. We argue that there is a strong need for metadata management.We introduce the Spectacle Workbench for verifying semi-structured information and showhow it can be used to validate; aggregate and visualize the metadata of an existinginformation system. We conclude that the possibility to verify and aggregate metadata is anadded value with respect to contents-based access to information and that it is possible togenerate it on the basis of Web contents.,Knowledge-Based Systems,2004,23
Representation of semantic mappings,Heiner Stuckenschmidt; Michael Uschold,Abstract The aim of this breakout session was to chart the landscape of existing approachesfor representing mappings between heterogeneous models; identify common ideas andformulate research questions to be addressed in the future. In the session; the discussionmainly concerned three aspects: The nature of mappings; existing proposals for mappingsand open research questions.,Dagstuhl Seminar Proceedings,2005,22
Enriching structured knowledge with open information,Arnab Dutta; Christian Meilicke; Heiner Stuckenschmidt,Abstract We propose an approach for semantifying web extracted facts. In particular; we mapsubject and object terms of these facts to instances; and relational phrases to objectproperties defined in a target knowledge base. By doing this we resolve the ambiguityinherent in the web extracted facts; while simultaneously enriching the target knowledgebase with a significant number of new assertions. In this paper; we focus on the mapping ofthe relational phrases in the context of the overall work ow. Furthermore; in an openextraction setting identical semantic relationships can be represented by different surfaceforms; making it necessary to group these surface forms together. To solve this problem wepropose the use of markov clustering. In this work we present a complete; ontologyindependent; generalized workflow which we evaluate on facts extracted by Nell and …,Proceedings of the 24th international conference on world wide web,2015,21
Criteria-based partitioning of large ontologies,Anne Schlicht; Heiner Stuckenschmidt,With the increasing use of ontologies in many branches of science and industry not only thenumber of available ontologies has increased considerably but also many widely usedontologies have reached a size that overburdens development and quality controlprocedures. It has been argued that the maintenance of large ontologies would be greatlyfacilitated by decomposing large ontologies into smaller modules that cover certainsubtopics of the ontology. Another argument in favor of ontology modularization is the factthat very large ontologies sometimes cannot adequately be handled by the availableontology tools; some cannot even be loaded into an standard editor. In our work; we focuson the task of splitting up an existing ontology into a set of modules according to somecriteria that define the notion of a good modularization. Intuitively; we can say that a …,Proceedings of the 4th international conference on Knowledge Capture,2007,21
Query processing in ontology-based peer-to-peer systems,Heiner Stuckenschmidt; Frank Van Harmelen; Fausto Giunchiglia,Abstract The unstructured; heterogeneous and dynamic nature of the Web poses a newchallenge to query-answering over multiple data sources. The so-called Semantic Web aimsat providing more and semantically richer structures in terms of ontologies and meta-data. Aproblem that remains is the combined use of heterogeneous sources. In a dynamicenvironment; it is no longer realistic to assume that the involved data sources act as if theywere a single (virtual) source; modelled as a global schema; as is done in classical dataintegration approaches. In this paper; we propose an alternative approach where wereplace the role of a single virtual data source schema with a peer-to-peer approach relyingon limited shared (or: overlapping) vocabularies between peers. Since overlaps betweenvocabularies of peers will be limited and the dynamic nature of the system prohibits the …,*,2005,21
Ontologies for geographic information integration,Heiner Stuckenschmidt; Ubbo Visser; Gerhard Schuster; Thomas Vögele,Abstract The opening of geographical information systems (GIS) and the interoperabilitybetween these systems demands new requirements for the description of the underlyingdata. The exchange of data between GIS systems is problematic and often fails due toconfusion in the meaning of concepts. The term semantic translator; a translator betweenGIS systems and/or catalogue systems which gives the user the option to map data betweenthe s stems is a current research topic. This paper proposes an overview of formalontologies and how they can be used for geographical information integration. A descriptionof an intelligent architecture for semantic-based information retrieval is introduced andshows how this approach can be used for general purposes. In conclusion we attempt toprovide a roadmap for the use of ontologies for geographic information processing.,Proceedings of the workshop intelligent methods for handling enviromental information: Special aspects of processing space and time.; Magdeburg; Germany,1999,21
A semantic similarity measure for ontology-based information,Heiner Stuckenschmidt,Abstract Computing the similarity between data elements is a basic functionality in flexiblequery answering systems. In the case of complex data definitions; for instance in terms of anontology; computing the similarity between data elements becomes a non-trivial problem. Inthis paper; we propose a similarity measure for data described in terms of the DL-liteontology language. In this measure; we take implicit information contained in the definition ofclasses and relations into account. In contrast to many other proposals for similaritymeasures; our proposal does not rely on structural criteria of the definitions involved but issolely based on the logical consequences that can be drawn.,International Conference on Flexible Query Answering Systems,2009,20
Robust query processing for personalized information access on the semantic web,Peter Dolog; Heiner Stuckenschmidt; Holger Wache,Abstract Research in Cooperative Query answering is triggered by the observation thatusers are often not able to correctly formulate queries to databases that return the intendedresult. Due to a lack of knowledge of the contents and the structure of a database; users willoften only be able to provide very broad queries. Existing methods for automatically refiningsuch queries based on user profiles often overshoot the target resulting in queries that donot return any answer. In this paper; we investigate methods for automatically relaxing suchover-constraint queries based on domain knowledge and user preferences. We describe aframework for information access that combines query refinement and relaxation in order toprovide robust; personalized access to heterogeneous RDF data as well as animplementation in terms of rewriting rules and explain its application in the context of e …,International Conference on Flexible Query Answering Systems,2006,20
Catalogue integration-a case study in ontology-based semantic translation,Heiner Stuckenschmidt; Frank Van Harmelen; Dieter Fensel; Michel Klein; Ian Horrocks,Abstract this report is to bring together two current research activities; carried out at the VrijeUniversiteit Amsterdam and at the Center for Computing Technologies at the University ofBremen. The context of the research at the Free University is the European project" On-To-Knowledge"(www. ontoknowledge. com) whose goal it is to provide support for efficient andeffective knowledge management. The scope of the project are weakly structuredinformation sources in the internet. The approach of the project is to use ontologies toprovide explicitly available semantic information about information sources in order tosupport the acquisition; maintenance and access to these information sources. Backgroundof the research at the Center for Computing Technologies is the Project INTEREC-IICProject" DataShare"[Voegele; 2000]. The goal of this project is to provide intelligent …,*,2000,20
On-body localization of wearable devices: An investigation of position-aware activity recognition,Timo Sztyler; Heiner Stuckenschmidt,Human activity recognition using mobile device sensors is an active area of research inpervasive computing. In our work; we aim at implementing activity recognition approachesthat are suitable for real life situations. This paper focuses on the problem of recognizing theon-body position of the mobile device which in a real world setting is not known a priori. Wepresent a new real world data set that has been collected from 15 participants for 8 commonactivities were they carried 7 wearable devices in different positions. Further; we introduce adevice localization method that uses random forest classifiers to predict the device positionbased on acceleration data. We perform the most complete experiment in on-body devicelocation that includes all relevant device positions for the recognition of a variety of differentactivities. We show that the method outperforms other approaches achieving an F …,Pervasive Computing and Communications (PerCom); 2016 IEEE International Conference on,2016,19
Recognizing interleaved and concurrent activities using qualitative and quantitative temporal relationships,Rim Helaoui; Mathias Niepert; Heiner Stuckenschmidt,Abstract The majority of approaches to activity recognition in sensor environments are eitherbased on manually constructed rules for recognizing activities or lack the ability toincorporate complex temporal dependencies. Furthermore; in many cases; the ratherunrealistic assumption is made that the subject carries out only one activity at a time. In thispaper; we describe the use of Markov logic as a declarative framework for recognizinginterleaved and concurrent activities incorporating both input from pervasive lightweightsensor technology and common-sense background knowledge. In particular; we assess itsability to learn statistical-temporal models from training data and to combine these modelswith background knowledge to improve the overall recognition accuracy. We also show theviability and the benefit of exploiting both qualitative and quantitative temporal …,Pervasive and Mobile Computing,2011,19
A reasoning-based support tool for ontology mapping evaluation,Christian Meilicke; Heiner Stuckenschmidt; Ondřej Šváb-Zamazal,Abstract In this paper we describe a web-based tool that supports the human in revisingontology alignments. Our tool uses logical reasoning as a basis for detecting conflicts inmappings and exploits these conflicts to propagate user decision. The proposed approachreduces the effort of the human expert and points to logical problems that are hard to findwithout support.,European Semantic Web Conference,2009,19
Tightly coupled probabilistic description logic programs for the Semantic Web,Andrea Calì; Thomas Lukasiewicz; Livia Predoiu; Heiner Stuckenschmidt,Abstract We present a novel approach to probabilistic description logic programs for theSemantic Web in which disjunctive logic programs under the answer set semantics aretightly coupled with description logics and Bayesian probabilities. The approach has severalnice features. In particular; it is a logic-based representation formalism that naturally fits intothe landscape of Semantic Web languages. Tightly coupled probabilistic description logicprograms can especially be used for representing mappings between ontologies; which area common way of approaching the semantic heterogeneity problem on the Semantic Web. Inthis application; they allow in particular for resolving inconsistencies and for mergingmappings from different matchers based on the level of confidence assigned to differentrules. Furthermore; tightly coupled probabilistic description logic programs also provide a …,*,2009,19
Towards distributed ontology reasoning for the web,Anne Schlicht; Heiner Stuckenschmidt,Abstract The use of description logics as one of the primary logical languages for knowledgerepresentation on the Web has created new challenges with respect to reasoning in theselogics. In order to support the vision of a semantic web of interrelated ontologies; reasoningprocedures have to be highly scalable and able to deal with physically distributedknowledge models. A natural way of addressing these problems is to rely on distributedinference procedures that can distribute the load between different solvers; thus reducingpotential bottlenecks both in terms of memory and computation time. In this paper; wepropose a distributed resolution approach that solves the problem by local resolution andpropagation of derived axioms between different reasoners. The method is complete for firstorder logic; terminates for ALC ontologies and avoids duplication of axioms and …,Proceedings of the 2008 IEEE/WIC/ACM International Conference on Web Intelligence and Intelligent Agent Technology-Volume 01,2008,19
The Semantic Web-ISWC 2005,Yolanda Gil; Enrico Motta; V Richard Benjamins; Mark A Musen,*,4th International Semantic Web Conference; ISWC,2005,19
Approximate information filtering on the semantic web,Heiner Stuckenschmidt,Abstract Facing the increasing amount of information available on the World Wide Web;intelligent techniques for content-based information filtering gain more and moreimportance. Conventional approaches using keyword-or text-based retrieval methods havebeen developed that perform reasonably well. However; these approaches have problemswith ambiguous and imprecise information. The semantic web that aims at supplementinginformation sources with a formal specification of its meaning using ontologies canpotentially help to overcome this problem. At the moment; however; the semantic web stillsuffers from its own problems in terms of heterogeneous ontologies and the need to relatethem to each other. In this paper; we argue that we can overcome this problem by usingshared vocabularies; a standardized language for encoding ontology that supports basic …,Annual Conference on Artificial Intelligence,2002,19
The ontology and modelling of real estate transactions,Erik Stubkjaer,Due to differences in the legal systems and business environments; it is difficult to comparethe process of buying and selling land in different European countries. Illustrated by a rangeof European case studies; this book identifies and discusses the problems of this and similarcomparisons. It then examines how ontological modelling can be applied to real estatetransactions and advocates this as a basis for comparing the various processes used acrossEurope. The book consists of four parts: the economic; legal and ontological aspects of realproperty transactions; a discussion of the current situation in different countries; thusshowing the heterogeneity and complexity of processes that have to be captured; whilst thethird and fourth parts describe ontological modelling and its benefits for the purpose ofunderstanding the nature of real property transactions together with examples of …,*,2017,18
Multidimensional topic analysis in political texts,Cäcilia Zirn; Heiner Stuckenschmidt,Abstract Automatic content analysis is more and more becoming an accepted researchmethod in social science. In political science researchers are using party manifestos andtranscripts of political speeches to analyze the positions of different actors. Existingapproaches are limited to a single dimension; in particular; they cannot distinguish betweenthe positions with respect to a specific topic. In this paper; we propose a method foranalyzing and comparing documents according to a set of predefined topics that is based onan extension of Latent Dirichlet Allocation (LDA) for inducing knowledge about relevanttopics. We validate the method by showing that it can guess which member of a coalitionwas assigned a certain ministry based on a comparison of the parties' election manifestoswith the coalition contract. We apply the method to German National Elections since 1990 …,Data & Knowledge Engineering,2014,18
Formal and conceptual comparison of ontology mapping languages,Saartje Brockmans; Peter Haase; Luciano Serafini; Heiner Stuckenschmidt,Summary The compositional approach where several existing ontologies are connected toform a large modular ontology relies on the representation of mappings between elementsin the different participating ontologies. A number of languages have been proposed for thispurpose that extend existing logical languages for ontologies in a non-standard way. In thischapter; we compare different proposals for such extensions on a formal level and show thatthese approaches exhibit fundamental differences with respect to the assumptionsunderlying their semantics. In order to support application developers to select the rightmapping language for a given situation; we propose a mapping metamodel that allows us toencode the formal differences on the conceptual level and facilitates the selection of anappropriate formalism on the basis of a formalism-independent specification of semantic …,*,2009,18
Building shared ontologies for terminology integration,Gerhard Schuster; Heiner Stuckenschmidt,Abstract. We present an approach for developing shared ontologies which can be used todefine terms from different vocabularies and to automatically translate them from onevocabulary into another. We first motivate the use of shared ontologies as a means foridentifying semantic correspondences between terms and underline the need for a sharedontology. Then; the general steps of a specialized methodology for building such sharedontologies are described. We further illustrate the application of the methodology using areal-life example from the domain of geo-informatics.,KI-01 Workshop on Ontologies; Vienna; Austria,2001,18
Towards the automated annotation of process models,Henrik Leopold; Christian Meilicke; Michael Fellmann; Fabian Pittke; Heiner Stuckenschmidt; Jan Mendling,Abstract Many techniques for the advanced analysis of process models build on theannotation of process models with elements from predefined vocabularies such astaxonomies. However; the manual annotation of process models is cumbersome andsometimes even hardly manageable taking the size of taxonomies into account. In thispaper; we present the first approach for automatically annotating process models with theconcepts of a taxonomy. Our approach builds on the corpus-based method of second-ordersimilarity; different similarity functions; and a Markov Logic formalization. An evaluation witha set of 12 process models consisting of 148 activities and the PCF taxonomy consisting of1;131 concepts demonstrates that our approach produces satisfying results.,International Conference on Advanced Information Systems Engineering,2015,17
Query-based access control for ontologies,Martin Knechtel; Heiner Stuckenschmidt,Abstract Role-based access control is a standard mechanism in information systems. Basedon the role a user has; certain information is kept from the user even if requested. Forontologies representing knowledge; deciding what can be told to a user without revealingsecrets is more difficult as the user might be able to infer secret knowledge using logicalreasoning. In this paper; we present two approaches to solving this problem: query rewritingvs. axiom filtering; and show that while both approaches prevent the unveiling of secretknowledge; axiom filtering is more complete in the sense that it does not suppressknowledge the user is allowed to see while this happens frequently in query rewriting. Axiomfiltering requires that each axiom carries a label representing its access level. We presentmethods to find an optimal axiom labeling to enforce query-based access restrictions and …,International Conference on Web Reasoning and Rule Systems,2010,17
A statistical-relational activity recognition framework for ambient assisted living systems,Rim Helaoui; Mathias Niepert; Heiner Stuckenschmidt,Abstract Smart environments with ubiquitous sensing technologies are a promisingperspective for reliable and continuous healthcare systems with reduced costs. A primarychallenge for such assisted living systems is the automated recognition of everyday activitiescarried out by humans in their own home. In this work; we investigate the use of MarkovLogic Networks as a framework for activity recognition within intelligent home-likeenvironments equippedwith pervasive light-weight sensor technologies. In particular; weexplore the ability of MLNs to capture temporal relations and background knowledge forimproving the recognition performance.,*,2010,17
Testing the impact of pattern-based ontology refactoring on ontology matching results,Ondrej Šváb-Zamazal; Vojtech Svátek; Christian Meilicke; Heiner Stuckenschmidt,Abstract. We observe the impact of ontology refactoring; based on detection of namepatterns in the ontology structure; on the results of ontology matching. Results of ourexperiment are evaluated using novel logic-based measures accompanied by an analysis oftypical effects. Although the pattern detection method only covers a fraction of ontologicalerrors; there seems to be a measurable effect on the quality of the resulting matching.,The 7th International Semantic Web Conference,2008,17
A topic-based browser for large online resources,Heiner Stuckenschmidt; Anita De Waard; Ravinder Bhogal; Christiaan Fluit; Arjohn Kampman; Jan van Buel; Erik van Mulligen; Jeen Broekstra; Ian Crowlesmith; Frank van Harmelen; Tony Scerri,Abstract The exploration of large information spaces is a difficult task; especially if the user isnot familiar with the terminology used to describe information. Conceptual models of adomain in terms of thesauri or ontologies can leverage this problem to some extend. In orderto be useful; there is a need for interactive tools for exploring large information sets based onconceptual knowledge. We present a thesaurus based browser that supports a mixed-initiative exploration of large online resources that provides support for thesaurus-basedsearch and topic-based exploration of query results. We motivate the chosen explorationstrategy the browser functionality; present the results of user studies and discuss futureimprovements of the browser.,International Conference on Knowledge Engineering and Knowledge Management,2004,17
Unsupervised recognition of interleaved activities of daily living through ontological and probabilistic reasoning,Daniele Riboni; Timo Sztyler; Gabriele Civitarese; Heiner Stuckenschmidt,Abstract Recognition of activities of daily living (ADLs) is an enabling technology for severalubiquitous computing applications. In this field; most activity recognition systems rely onsupervised learning methods to extract activity models from labeled datasets. An inherentproblem of that approach consists in the acquisition of comprehensive activity datasets;which is expensive and may violate individuals' privacy. The problem is particularlychallenging when focusing on complex ADLs; which are characterized by large intra-andinter-personal variability of execution. In this paper; we propose an unsupervised method torecognize complex ADLs exploiting the semantics of activities; context data; and sensingdevices. Through ontological reasoning; we derive semantic correlations among activitiesand sensor events. By matching observed sensor events with semantic correlations; a …,Proceedings of the 2016 ACM International Joint Conference on Pervasive and Ubiquitous Computing,2016,16
Towards activity recognition using probabilistic description logics,Rim Helaoui; Daniele Riboni; Mathias Niepert; Claudio Bettini; Heiner Stuckenschmidt,Abstract A major challenge of pervasive context-aware computing and intelligentenvironments resides in the acquisition and modelling of rich and heterogeneous contextdata. Decisive aspects of this information are the ongoing human activities at differentdegrees of granularity. We conjecture that ontology-based activity models are key to supportinteroperable multilevel activity representation and recognition. In this paper; we report onan initial investigation about the application of probabilistic description logics (DLs) to aframework for the recognition of multilevel activities in intelligent environments. In particular;being based on Log-linear DLs; our approach leverages the potential of highly expressivedescription logics with probabilistic reasoning in one unified framework. While we believethat this approach is very promising; our preliminary investigation suggests that …,Activity Context Representation: Techniques and Languages; AAAI Technical Report WS-12-05,2012,16
Learning Structural Classification Rules for Web-Page Categorization.,Heiner Stuckenschmidt; Jens Hartmann; Frank Van Harmelen,*,FLAIRS conference,2002,16
Modelling uncertainty in expertise,KC Ranze; H Stuckenschmidt,Abstract Almost all approaches of model-based development of knowledge-based systemsare lacking an explicit handling of uncertain knowledge. Based on a KADS-oriented modelof expertise our paper presents a general framework that enables the representation ofuncertainty in a structure of causality. Based on an existing model of expertise we introducea separate model of uncertainty; whose elements are represented independent of specificnumerical processing methods. With this approach we got the foundations of a model-basedframework integrating different kinds of uncertain information.,Proceedings of IT&KNOWS Conference; 15th IFIP World Computer Congress' 98,1998,16
Learning complex ontology alignments a challenge for ILP research,Heiner Stuckenschmidt; Livia Predoiu; Christian Meilicke,Abstract. In this paper; we propose the task of learning complex logical mappings betweenontologies as a challenging task for ILP research. We motivate the need for complexontology mappings using an example; formally define the task of learning complexmappings and identify a number of challenges for research on this issue in terms oftractability and uncertainty handling.,Proceedings of the 18th International Conference on Inductive Logic Programming,2008,15
Rule-based approaches for representing probabilistic ontology mappings,Andrea Calì; Thomas Lukasiewicz; Livia Predoiu; Heiner Stuckenschmidt,Abstract Using mappings between ontologies is a common way of approaching the semanticheterogeneity problem on the Semantic Web. To fit into the landscape of Semantic Weblanguages; a suitable logic-based representation formalism for mappings is needed; whichallows to reason with ontologies and mappings in an integrated manner; and to deal withuncertainty and inconsistencies in automatically created mappings. We analyze therequirements for such a formalism; and propose to use frameworks that integrate descriptionlogic ontologies with probabilistic rules. We compare two such frameworks and show theadvantages of using the probabilistic extensions of their deterministic counterparts. The twoframeworks that we compare are tightly coupled probabilistic dl-programs; which tightlycombine the description logics behind OWL DL resp. OWL Lite; disjunctive logic …,*,2008,15
A framework for representing ontology mappings under probabilities and inconsistency,Andrea Calì; Thomas Lukasiewicz; Livia Predoiu; Heiner Stuckenschmidt,Abstract Creating mappings between ontologies is a common way of approaching thesemantic heterogeneity problem on the SemanticWeb. To fit into the landscape of semanticweb languages; a suitable; logic-based representation formalism for mappings is needed.We argue that such a formalism has to be able to deal with uncertainty and inconsistenciesin automatically created mappings. We analyze the requirements for such a mappinglanguage and present a formalism that combines tightly integrated description logicprograms with independent choice logic for representing probabilistic information. We definethe language; show that it can be used to resolve inconsistencies and merge mappings fromdifferent matchers based on the level of confidence assigned to different rules. We alsoanalyze the computational aspects of consistency checking and query processing in …,Proceedings of the Third International Conference on Uncertainty Reasoning for the Semantic Web-Volume 327,2007,15
Exploiting partially shared ontologies for multi-agent communication,Heiner Stuckenschmidt,Abstract In has been argued that ontologies play a key role in multiagent communicationbecause they provide and define a shared vocabulary to be used in the course ofcommunication. In real-life scenarios; however; the situation where two agents completelyshare a vocabulary is rather an exception. More often; each agent uses its own vocabularyspecified in a private ontology that is not known by other agents. In this paper we propose asolution to this problem for the situation; where agents share at least parts of theirvocabulary. We argue that the assumption of a partially shared vocabulary is valid andsketch an approach for re-formulating terms from the private part of an agent's ontology intoa shared part thus enabling other agents to understand them. We further describe how theapproach can be implemented using existing technology and proof the correctness of the …,International Workshop on Cooperative Information Agents,2002,15
Modularization of Ontologies--WonderWeb: Ontology Infrastructure for the Semantic Web,Heiner Stuckenschmidt; Michel Klein,Documents; Authors; Tables. Log in; Sign up; MetaCart; Donate. CiteSeerX logo. Documents:Advanced Search Include Citations. Authors: Advanced Search Include Citations | Disambiguate.Tables: Modularization of Ontologies -- WonderWeb: Ontology Infrastructure for the SemanticWeb (2001). Cached. Download as a PDF. Download Links. [www.cs.vu.nl]. Save to List; Addto Collection; Correct Errors; Monitor Changes. by Heiner Stuckenschmidt ; Michel Klein. Citations:9 - 0 self. Summary; Citations; Active Bibliography; Co-citation; Clustered Documents; VersionHistory. BibTeX. @MISC{Stuckenschmidt01modularizationof; author = {Heiner Stuckenschmidtand Michel Klein}; title = {Modularization of Ontologies -- WonderWeb: Ontology Infrastructurefor the Semantic Web}; year = {2001} }. Share. Facebook; Twitter; Reddit; Bibsonomy. OpenURL.Abstract. Keyphrases. ontology wonderweb semantic web ontology infrastructure …,*,2001,15
Interactive thesaurus assessment for automatic document annotation,Kai Eckert; Heiner Stuckenschmidt; Magnus Pfeffer,Abstract The use of thesaurus-based indexing is a common approach for increasing theperformance of document retrieval. With the growing amount of documents available;manual indexing is not a feasible option. Statistical methods for automated documentindexing are an attractive alternative. We argue that the quality of the thesaurus used as abasis for indexing in regard to its ability to adequately cover the contents to be indexed is ofcrucial importance inautomatic indexing because there is no human in the loop that can spotand avoid indexing errors. We propose a method for thesaurus evaluation that is based on acombination of statistical measures and appropriate visualization techniques that supportsthe detection of potential problems in a thesaurus. We describe this method and show itsapplication in the context of two automatic indexing tasks. The examples show that the …,Proceedings of the 4th international conference on Knowledge capture,2007,14
The legal concepts and the layman’s terms,Ronny van Laarschot; Wouter van Steenbergen; Heiner Stuckenschmidt; Arno R Lodder; Frank van Harmelen,Abstract. The aim of the BEST-project is to support laymen in judging their legal positionthrough intelligent disclosure of case-law in the area of Dutch tort law. A problem we have toface in this context is the discrepancy between the terminology laymen use to describe theircase and the terminology found in legal documents. We address this problem by supportingusers to describe their case in common sense terms taken from an ontology. We use logicalreasoning to automatically determine law articles that are relevant for determining liability ofparties in a case based on this description; thus bridging the gap between the laymen'sdescription and the terminology relevant for certain articles that can be found in legaldocuments. We introduce the BEST-project and describe the ontology built for supportingcase descriptions focussing on its use for automatically determining relevant articles of …,Proceedings of the 18th annual conference on legal knowledge and information systems,2005,14
Evolution management for interconnected ontologies,Michel Klein; Heiner Stuckenschmidt,Abstract Mappings between ontologies are easily harmed by changes in the ontologies. Inthis paper we explain a mechanism to define modular ontologies and mappings in a waythat allows for local containment of terminological reasoning. We have also developed achange detection and analysis method that predicts the effect of changes on the concepthierarchy. This method determines whether the changes in one ontology affect thereasoning inside other ontologies or not. Together; these mechanisms allow ontologies toevolve without unpredictable effects on other ontologies. In this paper; we also apply thesemethods in a case study that is undertaken in a EU IST project.,ICSW-Workshop on Semantic Integration,2003,14
Query processing on the semantic web,Heiner Stuckenschmidt,Methods for query processing are an essential part of database and information systems(see eg [Garcia-Molina et. al. 2002]). Named queries; also called views; are not only used toaccess information; but also for (re-) structuring and integrating information [Halevy 2001].On the World Wide Web; effective query processing used to be impossible due to the lack ofdata structures and scheme information. The ability to efficiently access information in aquery-like fashion had been sacrificed for the ease of authoring and publishing information.When we talk about the Semantic Web today; then we mainly refer to an effort of bringingback structure to the Information that is available on the World Wide Web. This time;structures do not come in the shape of well-defined database schemas but in terms ofsemantic annotations that conform to a specific; often loosely defined schema or even to …,KI,2003,14
Modeling land transactions: legal ontologies in context,Heiner Stuckenschmidt; Erik Stubkjær; Christoph Schlieder,Abstract We present the new European COST Action „Modeling Real Property Transactions“and discuss the role of legal ontologies in this context. Ontologies play a key role in theaction as means of developing a better understanding in the domain of cadastral systems;providing interoperability between systems and supporting teaching and research. Weargue that legal ontologies play an important role in the cadastral domain; but they need tobe put into context. We exemplify this claim by discussing the interaction of legal ontologieswith ontologies of space and time as well as domain-specific classifications.,Proceedings of the Second International Workshop on Legal Ontologies,2001,14
Discovery of personal processes from labeled sensor data: An application of process mining to personalized health care,Timo Sztyler; Johanna Völker; Josep Carmona Vargas; Oliver Meier; Heiner Stuckenschmidt,Abstract Currently; there is a trend to promote personalized health care in order to preventdiseases or to have a healthier life. Using current devices such as smart-phones and smart-watches; an individual can easily record detailed data from her daily life. Yet; this data hasbeen mainly used for self-tracking in order to enable personalized health care. In this paper;we provide ideas on how process mining can be used as a fine-grained evolution oftraditional self-tracking. We have applied the ideas of the paper on recorded data from a setof individuals; and present interesting conclusions and challenges.,Proceedings of the International Workshop on Algorithms & Theories for the Analysis of Event Data: Brussels; Belgium; June 22-23; 2015,2015,13
A practical implementation of semantic precision and recall,Daniel Fleischhacker; Heiner Stuckenschmidt,The systematic evaluation of ontology alignments still faces a number of problems. One isthe argued inadequacy of traditional quality measures adopted from the field of informationretrieval. In previous work; Euzenat and others have proposed notions of semantic precisionand recall that are supposed to better reflect the true quality of an alignment by consideringits deductive closure rather than the explicitly stated correspondences. So far; thesemeasures have only been investigated in theory. In this paper; we present the firstimplementation of a restricted version of semantic precision and recall as well asexperiments in using it; we conducted on the results of the 2008 OAEI campaign.,Complex; Intelligent and Software Intensive Systems (CISIS); 2010 International Conference on,2010,13
A Model-driven Approach to enable Access Control for Ontologies.,Willy Chen; Heiner Stuckenschmidt,Abstract Industrial applications of semantic technologies-in particular ontologies-include theintegration of heterogeneous information sources and the management of informationresources and services. Currently; the adoption of these technologies in large-scaledapplications within enterprises is slowed down by their failure to meet some basicrequirements of commercial applications. One of those is the support of sophisticatedsecurity policies for protecting the knowledge contained in ontologies and their instancesfrom unauthorized use. In this paper; we propose a model-driven approach to enable accesscontrol for lightweight ontologies based on a role-based security model and well-knownstandard technologies.,Wirtschaftsinformatik (1),2009,13
Formalism-Independent specification of ontology mappings–a metamodeling approach,Saartje Brockmans; Peter Haase; Heiner Stuckenschmidt,Abstract Recently; the advantages of metamodeling for the graphical specification ofontologies have been recognized by the semantic web community. This has lead to anumber of activities concerned with the development of graphical modeling approaches forthe Web Ontology Language based on the Meta Object Facility (MOF) and the UnifiedModeling Language (UML). An aspect that has not been addressed so far is the need tospecify mappings between heterogenous ontologies. With an increasing number ofontologies being available; the problem of specifying mappings is becoming more importantand the rationales for providing model based graphical modeling support for mappings isthe same as for the ontologies themselves. In this paper; we therefore propose a MOF-basedmetamodel for mappings between OWL DL ontologies.,OTM Confederated International Conferences" On the Move to Meaningful Internet Systems",2006,13
Peer-to-peer and Semantic Web,Heiner Stuckenschmidt; Frank Van Harmelen; Wolf Siberski; Steffen Staab,Summary Just as the industrial society of the last century depended on natural resources;today's society depends on information. A lack of resources in the industrial society hindereddevelopment just as a lack of information hinders development in the information society.Consequently; the exchange of information becomes essential for more and more areas ofsociety: Companies announce their products in online marketplaces and exchangeelectronic orders with their suppliers; in the medical area patient information is exchangedbetween general practitioners; hospitals and health insurances; public administrationreceive tax information from employers and offer online services to their citizens. As a replyto this increasing importance of information exchange; new technologies supporting a fastand accurate information exchange are being developed. Prominent examples of such …,*,2006,13
Integrated view and comparison of alignment semantics,Pascal Hitzler; Jérôme Euzenat; Markus Krötzsch; Luciano Serafini; Heiner Stuckenschmidt; Holger Wache; Antoine Zimmermann,We take a general perspective on alignment in order to develop common theoreticalfoundations for the subject. The deliverable comprises a comparative study of differentmapping languages by means of distributed first-order logic; and a study on category-theoretical modelling of alignment and merging by means of pushout-combinations.,*,2005,13
Probabilistic-logical web data integration,Mathias Niepert; Jan Noessner; Christian Meilicke; Heiner Stuckenschmidt,Abstract The integration of both distributed schemas and data repositories is a majorchallenge in data and knowledge management applications. Instances of this problemrange from mapping database schemas to object reconciliation in the linked open datacloud. We present a novel approach to several important data integration problems thatcombines logical and probabilistic reasoning. We first provide a brief overview of some ofthe basic formalisms such as description logics and Markov logic that are used in theframework. We then describe the representation of the different integration problems in theprobabilistic-logical framework and discuss efficient inference algorithms. For each of theapplications; we conducted extensive experiments on standard data integration andmatching benchmarks to evaluate the efficiency and performance of the approach. The …,*,2011,12
A probabilistic framework for information integration and retrieval on the Semantic Web,Livia Predoiu; Heiner Stuckenschmidt,ABSTRACT We present a framework for probabilistic Information Processing on theSemantic Web that is capable of representing ontologies; deductive databases; uncertainmappings between them; results of statistical instance classification and ontology learning.Our framework is built on a knowledge representation formalism called BayesianDescription Logic Programs because it is a probabilistic extension of Description LogicProgramms and a fragment of Bayesian Logic Programs. We show in this paper how toperform information integration and retrieval within our framework by means of integratedreasoning.,Proc. InterDB-2007 Workshop on Database Interoperability,2007,12
Tackling the ontology acquisition bottleneck: An experiment in ontology re-engineering,Sean Bechhofer; Aldo Gangemi; Nicola Guarino; Frank van Harmelen; Ian Horrocks; Michel Klein; Claudio Masolo; Daniel Oberle; Steffen Staab; Heiner Stuckenschmidt; Raphael Volz,Abstract Ontologies form the backbone of the Semantics Web. They provide explicitdescriptions of the conceptualization underlying available information. The e# ort involved increating and maintaining ontologies is one of the most severe obstacles to a wide adoptionof semantic web technology. In this paper; we address the problem of creating ontologies forthe semantic and describe experiences with an approach that combines automatedextraction of conceptual models from existing information sources with state-of-the-artmethodologies and tools for ontological engineering. We further discuss tool interoperationbased on semantic web technology as an enabler for successful ontology maintenance.,*,2003,12
Intelligent; location-dependent acquisition and retrieval of environmental information,Ubbo Visser; Heiner Stuckenschmidt,ABSTRACT We are proposing the integration of an existing environmental informationsystem with techniques for intelligent processing of geographical information and mobilecomputing; to support location-dependent on-site acquisition and analysis of environmentalimpacts. The state of Bremen environmental information system BUISY organizesenvironmental information in several strands. One of the most important of these strands isthe geographical position of the object. To enable intelligent access to information containedin the BUISY system different dimensions will be given a formal semantic in terms of“dimension ontologies”. These ontologies will define possible concepts and relations; whichwill allow the information to be organized in a certain dimension. We will outline an ontologyexample. Two main points will illustrate our proposal: A descriptive ontology that can …,Proceedings of the 21st Urban Data Management Symposium (UDMS'99); Italy,1999,12
Automatic acquisition of class disjointness,Johanna Völker; Daniel Fleischhacker; Heiner Stuckenschmidt,Abstract Although it is widely acknowledged that adding class disjointness to ontologiesenables a wide range of interesting applications; this type of axiom is rarely used on today'sSemantic Web. This is due to the enormous skill and effort required to make the necessarymodeling decisions. Automatically generating disjointness axioms could lower the barrier ofentry and lead to a wider spread adoption. Different methods have been proposed for thisautomatic generation. These include supervised; top-down approaches which base theirresults on heterogeneous types of evidence and unsupervised; bottom-up approacheswhich rely solely on the instance data available for the ontology. However; current literatureis missing a thorough comparison of these approaches. In this article; we provide thiscomparison by presenting two fundamentally different state-of-the-art approaches and …,Web semantics: science; services and agents on the World Wide Web,2015,11
Intelligent brokering of environmental information with the BUSTER system,Heiner Stuckenschmidt; Thomas Vögele; Ubbo Visser; Ryco Meyer,Abstract Many application areas of information systems share the need to store and processlarge amounts of diverse data; which is often geographically distributed. This implies that inorder to make new data available to the system these data has to be transferred into thesystem's specific data format. This is a very time consuming and tedious process. Dataacquisition; automatically or semi-automatically; often requires large-scale investment intechnical infrastructure and/or manpower. These obstacles are some of the reasons behindthe concept of information sharing. Information sharing is attractive because in order tosupplement an existing data basis remote information can be accessed by systems. Theadvantages of successful information sharing is thus obvious for many reasons: Qualityimprovement of data due to the availability of large and complete data. Quality …,*,2001,11
Data semantics on the web,Heiner Stuckenschmidt,Abstract Data Semantics is a wide area that continuously faces new challenges arising fromthe invention of new information formats and novel applications. An area that is particularlychallenging with respect to identifying; representing and using data semantics is the Web.This paper attempts to characterize the nature and challenges of Data Semantics on theWeb as an interesting research area to be covered by the Journal on Data Semantics.,*,2012,10
Thesaurus extension using web search engines,Robert Meusel; Mathias Niepert; Kai Eckert; Heiner Stuckenschmidt,Abstract Maintaining and extending large thesauri is an important challenge facing digitallibraries and IT businesses alike. In this paper we describe a method building on andextending existing methods from the areas of thesaurus maintenance; natural languageprocessing; and machine learning to (a) extract a set of novel candidate concepts from textcorpora and (b) to generate a small ranked list of suggestions for the position of theseconcept in an existing thesaurus. Based on a modification of the standard tf-idf termweighting we extract relevant concept candidates from a document corpus. We then apply apattern-based machine learning approach on content extracted from web search enginesnippets to determine the type of relation between the candidate terms and existingthesaurus concepts. The approach is evaluated with a large-scale experiment using the …,International Conference on Asian Digital Libraries,2010,10
Network analysis as a basis for partitioning class hierarchies,Heiner Stuckenschmidt,Abstract. We discuss the use of network analysis methods to support the automaticpartitioning of large concept hierarchies. Different from other work in the area; we directlyapply these methods on the structure of the hierarchy. We show that this way of usingnetwork analysis techniques can provide significant results with respect to identifying keyconcepts and using them to determine subsets of class hierarchies that are related content-wise. We discuss the methods used and evaluate the result on the ACM classification ofcomputer science topis.,W8: Semantic Network Analysis,2005,10
Semantic Grid-Convergence of Technologies,York Sure; Carole Goble; Carl Kesselman,Abstract s other than the originators. Often these schemas are fixed; which makes themrather inflexible. Much of the metadata is hard-coded and buried in code libraries; typesystems; or grid applications. This makes it hard to adapt and configure. Finally;understanding and know-how is frequently tacit; embedded in best practice and experiencerather than explicitly recorded. This makes sharing and adaptation extremely difficult. Thus;existing Grid Services deal with knowledge in the form of metadata and its associatedsemantics in an implicit fashion; providing poor mechanisms for sharing this knowledge withother Grid components. The Semantic Grid is an initiative to systematically exposesemantically rich information associated with resources to build more intelligent Gridservices. It is an extension of the current Grid in which information and services are given …,*,2005,10
Automating oaei campaigns (first report),Cássia Trojahn; Christian Meilicke; Jérôme Euzenat; Heiner Stuckenschmidt,Abstract. This paper reports the first effort into integrating OAEI and SEALS evaluationcampaigns. OAEI is an annual evaluation campaign for ontology matching systems. The2010 campaign includes a new modality in coordination with the SEALS project. This projectaims at providing standardized resources (software components and data sets) forautomatically executing evaluations of typical semantic web tools; including ontologymatching tools. A first version of the software infrastructure is based on a web serviceinterface wrapping the functionality of the matching tool to be evaluated. In this setting; theevaluation results can be visualized and manipulated immediately in a direct feedbackcycle. We describe how parts of the OAEI 2010 evaluation campaign have been integratedinto the SEALS software infrastructure. In particular; we discuss technical and …,CEUR workshop proceedings,2010,9
A unified approach for representing metametadata,Kai Eckert; Magnus Pfeffer; Heiner Stuckenschmidt,Abstract Using metametadata like provenance on the statement level has been proposed asa possible solution to some--if not most--problems that occur in a metadata aggregationcontext. Examples for these problems are the information loss that occurs during metadataformat conversion or the alignment of disparate metadata quality. Until now; no feasible wayto store and manage meta information has been proposed. In this paper; we suggest the useof RDF reification as an elegant way to fill this gap that in addition adheres to all standardsand recommendations. We demonstrate this approach by the means of two scenarios: First;an enhancement for metadata crosswalks that supports the maintenance of the convertedmetadata; and second the use of metametadata for the efficient integration of subjectannotations from different sources.,International Conference on Dublin Core and Metadata Applications,2009,9
RDF and Traditional Query Architectures,Richard Vdovjak; Geert-Jan Houben; Heiner Stuckenschmidt; Ad Aerts,Summary The Resource Description Framework (RDF) is a step towards the support forintegrated and uniform access to information sources. It is designed to standardize thedefinition and use of metadata descriptions of Web-based resources. It is complementedwith RDF Schema (RDFS) that lets developers define an extensible; object-oriented typesystem for RDF data models. While RDF is targeted towards representing metadata; it canrepresent the underlying data as well. Together; RDF and RDFS provide a sound basis forthe capture of domain knowledge in a form that lends itself for automatic processing. Sincethe Web is inherently distributed; RDF querying systems should also be able to handle thedistribution of multiple; autonomous RDF repositories. A sound approach is needed forquerying distributed RDF sources to disclose the information they contain. In this chapter …,*,2006,9
Tightly integrated probabilistic description logic programs for representing ontology mappings,Thomas Lukasiewicz; Livia Predoiu; Heiner Stuckenschmidt,Abstract Creating mappings between ontologies is a common way of approaching thesemantic heterogeneity problem on the Semantic Web. To fit into the landscape of SemanticWeb languages; a suitable; logic-based representation formalism for mappings is needed.We argue that such a formalism has to be able to deal with uncertainty and inconsistenciesin automatically created mappings. We analyze the requirements for such a formalism; andwe propose a novel approach to probabilistic description logic programs as such aformalism; which tightly combines normal logic programs under the well-founded semanticswith both tractable ontology languages and Bayesian probabilities. We define the language;and we show that it can be used to resolve inconsistencies and merge mappings fromdifferent matchers based on the level of confidence assigned to different rules …,Annals of Mathematics and Artificial Intelligence,2011,8
An alternative interpretation of the seven-pointed star on CBS 1766,CAH Waerzeggers; RM Siebes,KNAW Narcis. Back to search results. Publication An Alternative Interpretation of theSeven-Pointed Star on CBS 1766 (2007). Pagina-navigatie: Main …,Nouvelles Assyriologiques Br ่ ves et Utilitaires,2007,8
MusiDB: A personalized search engine for music,Ruud Stegers; Peter Fekkes; Heiner Stuckenschmidt,Abstract The increasing use of structured information on the web demands new ways ofsearching and integrating data from different sources. In this paper; we focus on the use ofunique representations of data objects in terms of public repositories (in this caseMusicBrainz) and the use of recommendation mechanisms as a basis for supportinginformation access. We have implemented a prototypical system with the correspondingfunctionality in the area of digital music. We discuss the challenges of providing integratedaccess to structured web resources and the solutions adopted in the MusiDB system.,Web Semantics: Science; Services and Agents on the World Wide Web,2006,8
Reasoning with multi-version ontologies,Zhisheng Huang; Heiner Stuckenschmidt,Abstract. EU-IST Integrated Project (IP) IST-2003-506826 SEKT Deliverable D3. 5.1 (WP3.5) In this document; we propose a framework for reasoning with multi-version ontology; inwhich a temporal logic is developed to serve as its semantic foundation. We show that thetemporal logic approach can provide a solid semantic foundation which can support variousrequirements on multi-version ontology reasoning. We have implemented the prototype ofMORE (Multi-version Ontology REasoner); which is based on the proposed framework. Inthis document; we present the design of the interfaces for MORE; and discuss itsimplementation.,EU-IST Integrated Project (IP) IST-2003-506826 SEKT; Deliverable D,2005,8
The Legal Concepts and the Layman's TermsBridging the Gap through Ontology-Based Reasoning about Liability,Ronny van Laarschot; Wouter Van Steenbergen; Heiner Stuckenschmidt; Arno R Lodder; Frank van Harmelen,Abstract The aim of the BEST-project is to support laymen in judging their legal positionthrough intelligent disclosure of case-law in the area of Dutch tort law. A problem we have toface in this context is the discrepancy between the terminology laymen use to describe theircase and the terminology found in legal documents. We address this problem by supportingusers to describe their case in common sense terms taken from an ontology. We use logicalreasoning to automatically determine law articles that are relevant for determining liability ofparties in a case based on this description; thus bridging the gap between the laymen'sdescription and the terminology relevant for certain articles that can be found in legaldocuments. We introduce the BEST-project and describe the ontology built for supportingcase descriptions focussing on its use for automatically determining relevant articles of …,Proceedings of the 2005 conference on Legal Knowledge and Information Systems: JURIX 2005: The Eighteenth Annual Conference,2005,8
Ontology-Based Information Integration: A Survey,H Wache; T Vogele; U Visser; H Stuckenschmidt; G Schuster; H Neumann; S Hubner,Abstract In the past a lot of approaches concerning the integration of heterogeneousinformation sources are developed. In the last years the semantics; which play an importantrole during the integration task; come into the focus leading to the so called ontology-basedintegration approaches. This paper provides a survey of most prominent ontologybasedintegration approaches. The approaches are evaluated according four criterions; ie the roleand the representation of the ontologies; the mapping relating sources and ontologies; andtheir support for ontology engineering. The evaluation gives an impression; how whichproblems are solved; and shows the need for further research.,International Journal on Artificial Intelligence,2001,8
Probabilistic evaluation of process model matching techniques,Elena Kuss; Henrik Leopold; Han Van der Aa; Heiner Stuckenschmidt; Hajo A Reijers,Abstract Process model matching refers to the automatic identification of correspondingactivities between two process models. It represents the basis for many advanced processmodel analysis techniques such as the identification of similar process parts or processmodel search. A central problem is how to evaluate the performance of process modelmatching techniques. Often; not even humans can agree on a set of correctcorrespondences. Current evaluation methods; however; require a binary gold standard;which clearly defines which correspondences are correct. The disadvantage of thisevaluation method is that it does not take the true complexity of the matching problem intoaccount and does not fairly assess the capabilities of a matching technique. In this paper; wepropose a novel evaluation method for process model matching techniques. In particular …,International Conference on Conceptual Modeling,2016,7
Classifying topics and detecting topic shifts in political manifestos,Cäcilia Zirn; Goran Glavaš; Federico Nanni; Jason Eichorts; Heiner Stuckenschmidt,Abstract: General political topics; like social security and foreign affairs; recur in electoralmanifestos across countries. The Comparative Manifesto Project collects and manuallycodes manifestos of political parties from all around the world; detecting political topics atsentence level. Since manual coding is time-consuming and allows for annotationinconsistencies; in this work we present an automated approach to topical coding of politicalmanifestos. We first train three independent sentence-level classifiers–one for detecting thetopic and two for detecting topic shifts–and then globally optimize their predictions using aMarkov Logic network. Experimental results show that the proposed global model achieveshigh classification performance and significantly outperforms the local sentence-level topicclassifier.,*,2016,7
Applying markov logic for debugging probabilistic temporal knowledge bases,Jakob Huber; Christian Meilicke; Heiner Stuckenschmidt,Abstract A probabilistic temporal knowledge base contains facts that are annotated with atime interval and a confidence score. The interval defines the time span for which it can beassumed that the fact is true with a probability that is expressed by the confidence score.Given a probabilistic temporal knowledge base; we propose the use of Markov Logic incombination with Allen's interval calculus to select the most probable consistent subset offacts by computing the MAP state. We apply our approach on a specific domain of DBpedia;namely the domain of academics. We simulate a scenario of extending a knowledge baseautomatically in an open setting by adding erroneous facts to the facts stated in DBpedia.Our results indicate that we can eliminate a large fraction of these errors without removingtoo many correctly stated facts.,Proceedings of the 4th Workshop on Automated Knowledge Base Construction (AKBC),2014,7
Semantifying Triples from Open Information Extraction Systems.,Arnab Dutta; Christian Meilicke; Heiner Stuckenschmidt,Abstract. The last few years have witnessed some remarkable success of the stateof-the artunsupervised knowledge extraction systems like NELL and REVERB. These systems aregifted with typically web-scale coverage but are often plagued with ambiguity due to lack ofproper schema or unique identifiers for the instances. This classifies them apart fromextraction systems like DBPEDIA; YAGO or FREEBASE which have precise informationcontent but have smaller coverage. In this work we bring together the former to enrich thelater with high precision novel facts and present a statistical approach to discover newknowledge. In particular; we semantify NELL triples using DBPEDIA.,STAIRS,2014,7
D1. 2.2. 1.3 Benchmarking of annotation tools,Diana Maynard; S Dasiopolou; S Costache; K Eckert; H Stuckenschmidt; M Dzbor; S Handschuh,Abstract. EU-IST Network of Excellence (NoE) IST-2004-507482 KWEB Deliverable D1. 2.2.1 (WP1. 2/2.1) This deliverable investigates methods and results for benchmarkingannotation tools. We define first some criteria for benchmarking; including both performanceand usability issues; and examine those factors which are particularly important for a user inan industrial setting to be able to determine which is the most suitable tool for their use. Wealso look particularly at two issues: scalability of the tool; which is most important if the toolsare to be used in a real industrial setting rather than just as research prototypes; and thebest way to evaluate performance. We then perform a series of experiments on theannotation tools; and discuss the results; finally drawing some conclusions about the futureof annotation tools.,Knowledge Web Project; University of Sheffield; Technical Report,2007,7
Combining ontologies and peer-to-peer technologies for inter-organizational knowledge management,Heiner Stuckenschmidt; Wolf Siberski; Wolfgang Nejdl,Purpose–The purpose of the paper is to review the characteristics of systems that combineP2P technology with explicit ontologies and assess the benefits of these technologies forinter-organizational knowledge management. Design/methodology/approach–Wecharacterize existing technologies with respect to a number of aspects that are relevant toknowledge management on a technical level. We further provide an example of an existingsystem and categorize it according to the aspects. Findings–We conclude that ontology-based P2P systems are in general beneficial for distributed knowledge managementsystems and that the design of such systems can be guided using the aspects wedistinguish. Originality/value–The paper presents the first attempt to rigorously identify anddiscuss the design space of ontology-based P2P systems.,The Learning Organization,2005,7
The drug ontology project for Elsevier,J Broekstra; C Fluit; A Kampman; F van Harmelen; H Stuckenschmidt; R Bhogal; A Scerri; A de Waard; E van Mulligen,*,Proceedings of the WWW'04 workshop on Application Design; Development and Implementation Issues in the Semantic Web; New York,2004,7
Ontology language integration: A constructive approach,Heiner Stuckenschmidt; Jérôme Euzenat,The problem of integrating different ontology languages has become of special interestrecently; especially in the context of semantic web applications. In the paper; we present anapproach that is based on the configuration of a joint language all other languages can betranslated into. We use description logics as a basis for constructing this common languagetaking advantage of the modular character and the availability of profound theoretical resultsin this area. We give the central definitions and exemplify the approach using exampleontologies available on the Web.,Proc. KI 2001 workshop on Applications of Description Logics,2001,7
Knowledge-based validation; aggregation; and visualization of meta-data: Analyzing a web-based information system,Heiner Stuckenschmidt; Frank Van Harmelen,Abstract As meta-data become of increasing importance to the Web; we will need to startmanaging such meta-data. We argue that there is a strong need for meta-data validation andaggregation. We introduce the Spectacle Workbench for verifying semi-structuredinformation and show how it can be used to validate; aggregate and visualize the metadataof an existing Information System. We conclude that the possibility to verify and aggregatemeta-data is an added value with respect to contents-based access to information.,*,2001,7
Buisy-using brokered data objects for environmental information systems,Thomas Vögele; Heiner Stuckenschmidt; Ubbo Visser,Abstract Internet-based information systems can be applied to manage and efficiently usedistributed data-sources in large companies and government organizations. However; dueto the heterogeneity of data-sources and user requirements;“traditional” information systemarchitectures have serious shortcomings. In this paper; we introduce the concept ofinformation sites based on brokered data-objects; and present an implementation of such asite; the Bremer Umweltinformationssystem (BUISY). We also show that; through the use ofknowledge-based methods; the approach can be extended to provide intelligent dataretrieval and site navigation.,Hypermedia im Umweltschutz; Marburg,2000,7
Interactive data integration with mappingassistant,Jan Noessner; Faraz Fallahi; E Kiss; Heiner Stuckenschmidt,Abstract. Due to the heterogeneity of distributed systems data integration is a main successfactor in real-life business. Applying semantic web technologies for matching data is onesuccessful approach for data integration. Ontoprise uses ontologies as target schema forintegrating different sources like databases; text-files and ontologies. However; the createdtarget ontology and the corresponding mapping-rules might be error-prone. Hence; wedeveloped the conflict resolution framework MappingAssistant which detects wrong rules orfacts on the instance level in an interactive way. In this demo we present theMappingAssistant framework and an evaluation which emphasizes that users are used toinvestigate data on the instance level.,Demo Paper at the 10th International Semantic Web Conference ISWC,2011,6
Implementing semantic precision and recall,Daniel Fleischhacker; Heiner Stuckenschmidt,*,Proceedings of the 4th International Conference on Ontology Matching-Volume 551,2009,6
Semtinel: interactive supervision of automatic indexing,Kai Eckert; Heiner Stuckenschmidt; Magnus Pfeffer,The use of thesaurus-based indexing is a common approach for improving the result ofdocument retrieval. With the growing amount of documents available; manual indexing is nolonger a feasible option and statistical methods for automated document indexing arebecoming an attractive alternative. But especially in areas where manual indexing could becomplemented or replaced by automatic systems; the correctness and completeness of theresulting annotations is very important. We argue that the quality of automatic indexing notonly depends on the involved indexing system; but also on the quality of the thesaurus inregard to its ability to adequately cover the contents to be indexed. A manual verification ofall automatically assigned annotations is obviously not a solution and it is questionable; ifthe verification of random samples would be sufficient to ensure an overall annotation …,Proceedings of the 8th ACM/IEEE-CS joint conference on Digital libraries,2008,6
Assessing thesaurus-based annotations for semantic search applications,Kai Eckert; Magnus Pfeffer; Heiner Stuckenschmidt,Statistical methods for automated document indexing are becoming an alternative to themanual assignment of keywords. We argue that the quality of the thesaurus used as a basisfor indexing in regard to its ability to adequately cover the contents to be indexed and as abasis for the specific indexing method used is of crucial importance in automatic indexing.We present an interactive tool for thesaurus evaluation that is based on a combination ofstatistical measures and appropriate visualisation techniques that supports the detection ofpotential problems in a thesaurus. We describe the methods used and show that the toolsupports the detection and correction of errors; leading to a better indexing result.,International Journal of Metadata; Semantics and Ontologies,2008,6
KnowledgeWeb Deliverable 2.2. 9: Description of alignment evaluation and benchmarking results,Pavel Shvaiko; Jérôme Euzenat; Heiner Stuckenschmidt; Malgorzata Mochol; Fausto Giunchiglia; Mikalai Yatskevich; Paolo Avesani; Willem Robert van Hage; Ondrej Šváb; Vojtech Svátek,*,*,2007,6
Implementing modular ontologies with distributed description logics,Heiner Stuckenschmidt,Abstract. In an earlier paper; we presented a logical framework for representing andreasoning with modular ontologies with a special focus on supporting localized reasoningand integrity in the face of changes. This framework while being based on a formalsemantics; was not specific to a particular logic used to specify ontologies and links betweenmodules. As a result; no system was provided that implemented the ideas presented in thatpaper. In this work; we close this gap by explaining; how the general framework for modularontologies can be mapped onto distributed description logics and implemented using theDRAGO reasoning system. In particular; we refine the notion of modular ontologies to thecase where local ontologies are represented in SHIQ. We define a sound and completeinference rule for modular ontologies based distributed decsription logic and analyze the …,Proceedings of the 1st International Conference on Modular Ontologies-Volume 232,2006,6
Integrating Ontologies’ 05,Benhamin Ashpole; Marc Ehrig; Jérôme Euzenat; Heiner Stuckenschmidt; Hans Akkermans; Andrew Choi; Marek Hatala; Hung-Ju Chu; Randy YC Chow; Su-Shing Chen; Raja RA Issa; Ivan Mutis; Wei Hu; Ningsheng Jian; Yuzhong Qu; Yanbing Wang; Carlos Lamsfus; María Teresa Linaza; Tim Smithers; Nuno Silva; Paulo Maio; João Rocha; Mikalai Yatskevich; York Sure; Yannis Kalfoglou; Bo Hu; Gong Cheng; Umberto Straccia; Raphael Troncy; Philippe Guégan; Petko Valtchev,CEUR Workshop Proceedings IntOnt '05.,Proc. of the K-Cap Workshop on Integrating Ontologies; Banff (Canada),2005,6
Ontology-based information in dynamic environments,Heiner Stuckenschmidt,A number of ontology based systems have been developed that support typical knowledgemanagement tasks. At the moment almost all of these systems; however; rely on a number ofassumptions about the nature of environment they are used in. In such an environment; anumber of problems occur when trying to use ontology-based information and these are thefollowing (1) changing information is the change in the set of information that should beaccessible using an ontology;(2) changing ontologies are changes in the ontologies used toaccess information; and (3) changing sources or change of information sources making itimpossible to establish a centralized ontology infrastructure that supports informationsharing.,Enabling Technologies: Infrastructure for Collaborative Enterprises; 2003. WET ICE 2003. Proceedings. Twelfth IEEE International Workshops on,2003,6
Spatial Reasoning for Information Brokering.,Heiner Stuckenschmidt; Christoph Schlieder; Ubbo Visser; Thomas J Vögele; Holger Neumann,Abstract The World Wide Web provides new opportunities for collecting information fromdistributed; multiple; and heterogeneous data sources. Information brokering can be used toprovide coordinated access to these sources if they are structured or semi-structured. TheBUSTER (Bremen University Semantic Translator for Enhanced Retrieval) approachprovides enabling technologies for information search and integration and can be seen asan information broker. However; it is not possible to represent and reason about spatialobjects. In this paper; we motivate the need for the integration of spatial representation andreasoning. We start with information brokering in general and proceed with a brief overviewof BUSTER. In the following; use cases are defined that demand certain representations andreasoning methods and give examples for these cases. We discuss gazetteers as an …,FLAIRS Conference,2001,6
Ontologies for Semantic Information Integration: Opportunities and Open Problems,Heiner Stuckenschmidt,Abstract We present a knowledge-based approach to intelligent information integration topreserve the intended meaning of information entities in a different context. We propose tointerpret this semanticspreserving context transformation as a classification task: translatingan information item from one context to another then becomes the task of taking theproperties of information item from its source context; and use these properties to re-classifythe item in its target context; resulting in a re-interpretation of the information item in the newcontext. We investigate the role of ontologies for providing a shared terminology and supportfor the integration process. After addressing these questions in principle we summarize theresults of a case study were we used the Ontology Interchange Language OIL in order tosupport the integration of different catalogue systems. We assess useful features of the …,*,2000,6
Intelligenter Zugang zu Umweltinformationen durch Ontologie-basiertes Information-Retrieval,Heiner Stuckenschmidt; K Christoph Ranze,Zusammenfassung Der Zugriff auf Umweltinformationen über das Internet wirft zahlreicheProbleme auf die vor allem durch die Komplexität der unterschiedlichen Informationensowie deren Heterogenität und Verteilt entstehen. Das Problem wird noch durch dieTeilweise sehr unterschiedlichen Anforderungen verschärft; die für unterschiedlicheBenutzer von Umweltinformationssystemen zu berücksichtigen sind. In diesem Papier wirddas Konzept eines intelligenten Zugriffs auf Umweltinformationen vorgestellt; welches dievorhandenen Probleme teilweise lösen könnte. Das Konzept basiert auf zweigrundlegenden Prinzipien.(1) Verwendung unterschiedlicher Bezüge vonUmweltinformationen zur Reflektion der unterschiedlichen Sichten von Benutzern auf dievorhandenen Informationen.(2) Verwendung wissensbasierter Methoden; insbesondere …,GI-Workshop Hypermedia im Umweltschutz; Metropolis-Verlag Marburg,1999,6
Position-aware activity recognition with wearable devices,Timo Sztyler; Heiner Stuckenschmidt; Wolfgang Petrich,Abstract Reliable human activity recognition with wearable devices enables thedevelopment of human-centric pervasive applications. We aim to develop a robust wearable-based activity recognition system for real life situations where the device position is up to theuser or where a user is unable to collect initial training data. Consequently; in this work wefocus on the problem of recognizing the on-body position of the wearable device ensued bycomprehensive experiments concerning subject-specific and cross-subjects activityrecognition approaches that rely on acceleration data. We introduce a device localizationmethod that predicts the on-body position with an F-measure of 89% and a cross-subjectsactivity recognition approach that considers common physical characteristics. In this context;we present a real world data set that has been collected from 15 participants for 8 …,Pervasive and mobile computing,2017,5
Cluster-based hierarchical demand forecasting for perishable goods,Jakob Huber; Alexander Gossmann; Heiner Stuckenschmidt,Abstract Demand forecasting is of particular importance for retailers in the context of supplychains of perishable goods and fresh food. Such goods are daily produced and delivered asthey need to be provided as fresh as possible and quickly deteriorate. Demandunderestimation and overestimation negatively affect the revenues of the retailer. Stock-outshave an undesired impact on consumers while unsold items need to be discarded at the endof the day. We propose a DSS that supports day-to-operations by providing hierarchicalforecasts at different organizational levels based on most recent point-of-sales data. Itidentifies article clusters that are used to extend the hierarchy based on intra-day salespattern. We apply multivariate ARIMA models to forecast the daily demand to supportoperational decisions. We evaluate the approach with point-of-sales data of an …,Expert systems with applications,2017,5
Fast approximate a-box consistency checking using machine learning,Heiko Paulheim; Heiner Stuckenschmidt,Abstract Ontology reasoning is typically a computationally intensive operation. Whilesoundness and completeness of results is required in some use cases; for many others; asensible trade-off between computation efforts and correctness of results makes moresense. In this paper; we show that it is possible to approximate a central task in reasoning;ie; A-box consistency checking; by training a machine learning model which approximatesthe behavior of that reasoner for a specific ontology. On four different datasets; we show thatsuch learned models constantly achieve an accuracy above 95% at less than 2% of theruntime of a reasoner; using a decision tree with no more than 20 inner nodes. For example;this allows for validating 293M Microdata documents against the schema. org ontology inless than 90 min; compared to 18 days required by a state of the art ontology reasoner.,International Semantic Web Conference,2016,5
Constructs replacing and complexity downgrading via a generic OWL ontology transformation framework,Ondřej Šváb-Zamazal; Anne Schlicht; Heiner Stuckenschmidt; Vojtěch Svátek,Abstract Many of the tools supporting the OWL ontological language face complexityproblems when handling certain constructs of the language. This leads to the requirement ofautomatically changing the ontology; either by removing a specific type of construct or byadhering (downgrading) the ontology to a predefined OWL2 profile such as OWL2 EL. Wepresent an approach to construct replacing and complexity downgrading that relies ontransformation patterns processed by a generic ontology transformation framework.Transformation patterns allow to declaratively formulate and transparently execute axiomreplacement operations. This potentially preserves derivations that would otherwise be lostdue to simple removal of problematic axioms.,International Conference on Current Trends in Theory and Practice of Computer Science,2013,5
Multi-dimensional analysis of political documents,Heiner Stuckenschmidt; Cäcilia Zirn,Abstract Automatic content analysis is more and more becoming an accepted researchmethod in social science. In political science researchers are using party manifestos andtranscripts of political speeches to analyze the positions of different actors. Existingapproaches are limited to a single dimension; in particular; they cannot distinguish betweenthe positions with respect to a specific topic. In this paper; we propose a method foranalyzing and comparing documents according to a set of predefined topics that is based onan extension of Latent Dirichlet Allocation for inducing knowledge about relevant topics. Wevalidate the method by showing that it can reliably guess which member of a coalition wasassigned a certain ministry based on a comparison of the parties' election manifestos withthe coalition contract.,International Conference on Application of Natural Language to Information Systems,2012,5
Towards distributed mcmc inference in probabilistic knowledge bases,Mathias Niepert; Christian Meilicke; Heiner Stuckenschmidt,Abstract Probabilistic knowledge bases are commonly used in areas such as large-scaleinformation extraction; data integration; and knowledge capture; to name but a few.Inference in probabilistic knowledge bases is a computationally challenging problem. Withthis contribution; we present our vision of a distributed inference algorithm based on conflictgraph construction and hypergraph sampling. Early empirical results show that the approachefficiently and accurately computes a-posteriori probabilities of a knowledge base derivedfrom a well-known information extraction system.,Proceedings of the Joint Workshop on Automatic Knowledge Base Construction and Web-scale Knowledge Extraction,2012,5
Automating OAEI campaigns (first report),Cássia Trojahn dos Santos; Christian Meilicke; Jérôme Euzenat; Heiner Stuckenschmidt,This paper reports the first effort into integrating OAEI and SEALS evaluation campaigns.The SEALS project aims at providing standardized resources (software components; datasets; etc.) for automatically executing evaluations of typical semantic web tools; includingontology matching tools. A first version of the software infrastructure is based on the use of aweb service interface wrapping the functionality of a matching tool to be evaluated. In thissetting; the evaluation results can visualized and manipulated immediately in a directfeedback cycle. We describe how parts of the OAEI 2010 evaluation campaign have beenintegrated into this software infrastructure. In particular; we discuss technical andorganizational aspects related to the use of the new technology for both participants andorganizers of the OAEI.,Proc. 1st ISWC international workshop on evaluation of semantic technologies (iWEST),2010,5
Services for the automatic evaluation of matching tools,Christian Meilicke; Cássia Trojahn dos Santos; Jérôme Euzenat,In this deliverable we describe a SEALS evaluation service for ontology matching that isbased on the use of a web service interface to be implemented by the tool vendor. Followingthis approach we can offer an evaluation service before many components of the SEALSplatform have been finished. We describe both the system architecture of the evaluationservice from a general point of view as well as the specific components and their relation tothe modules of the SEALS platform.,*,2010,5
Ontology matching OM-2010,Pavel Shvaiko; Jérôme Euzenat; Fausto Giunchiglia; Heiner Stuckenschmidt; Ming Mao; Isabel Cruz,Shvaiko; P.; Euzenat; J.; Giunchiglia; F.; Stuckenschmidt; H.; Mao; M.; & Cruz; I. (2010). Ontologymatching OM-2010. Unknown Journal; 689 … Ontology matching OM-2010. / Shvaiko;Pavel; Euzenat; Jérôme; Giunchiglia; Fausto; Stuckenschmidt; Heiner; Mao; Ming; Cruz;Isabel … Shvaiko; P; Euzenat; J; Giunchiglia; F; Stuckenschmidt; H; Mao; M & Cruz; I 2010;'Ontology matching OM-2010' Unknown Journal; vol 689 … Shvaiko P; Euzenat J; GiunchigliaF; Stuckenschmidt H; Mao M; Cruz I. Ontology matching OM-2010. Unknown Journal.2010;689 … Shvaiko; Pavel; Euzenat; Jérôme; Giunchiglia; Fausto; Stuckenschmidt;Heiner; Mao; Ming; Cruz; Isabel / Ontology matching OM-2010 … Powered by Pure; Scopus& Elsevier Fingerprint Engine™ © 2018 Elsevier BV.,Unknown Journal,2010,5
Ontology-based product catalogues: an example implementation,Philipp Nowakowski; Heiner Stuckenschmidt,One of the basic problems connected to an efficient use of electronic marketplaces is theproblem of matchmaking between offers for products or services and requests by potentialcustomers (Veit 2003). Determining which offers are‟ good enough‟ often does not onlydepend on offer and request itself; but also on the preferences of the customer and theintended use of the product or service. This means that matching has to understand thenature of a product to be able to decide if it is similar to what the customer wants and it has tobe customizable towards the specific needs of a customer. Another challenge for successfulmatchmaking in electronic marketplaces is the need to integrate heterogeneous product andservice descriptions from different product catalogues to enable the customer to choose fromdifferent providers; as the representations used by different participants for their internal …,Multikonferenz Wirtschaftsinformatik 2010,2010,5
Distributed resolution for ALC-first results,Anne Schlicht; Heiner Stuckenschmidt,Abstract. The use of description logic as the basis for semantic web languages has led tonew requirements with respect to scalable and non-standard reasoning. Description logic isa decidable fragment of FOL but still; the standard reasoning tasks are of exponentialcomplexity; satisfiability and subsumption tests are often intractable on large ontologies.Existing large ontologies have a modular structure like networks of linked ontologies;caused by the development process. However; current reasoning approaches do scarcelytake advantage of this structure. The available reasoners do not exploit parallel computationand scalability improvements enabled by distributed reasoning. In this paper; we lay thefoundation for developing distributed reasoning methods by showing that the descriptionlogic fragment ALC can be distributed. We propose a distributed; complete and …,ESWC Workshop on Advancing Reasoning on the Web,2008,5
Partial Matchmaking for complex Product and Service Descriptions.,Heiner Stuckenschmidt; Martin Kolb,It has been argued that matchmaking in electronic markets can benefit from the use ofsemantic web technologies. In particular; OWL has been proposed as a suitable languagefor representing product classifications [Hep06] and to use logical reasoning in OWL forcomputing matches between offers and requests [GCTB01; LH04]. This approach has anumber of advantages. In particular; the ability to capture complex descriptions in ameaningful way and the ability to make use of background knowledge about the domain ofdiscourse in terms of product and services ontologies support more informed choices. Onthe other hand; the use of logical reasoning also has some problems. In particular; there arevery limited ways of determining particular matches. The abilities boil down to decidingwhether an offer is equivalent; more specific; more general or consistent with an offer …,Multikonferenz Wirtschaftsinformatik,2008,5
A metadata model for semantics-based peer-to-peer systems,Marc Ehrig; Ch Tempich; Jeen Broekstra; Frank van Harmelen; Marta Sabou; Ronny Siebes; Steffen Staab; Heiner Stuckenschmidt,Peer-to-Peer systems are a new paradigm for information sharing and some systems havesuccessfully been deployed. It has been argued that current Peer-to-Peer systems sufferfrom the lack of semantics. The SWAP project (Semantic Web and Peer-to-Peer) aims atovercoming this problem by combining the Peer-to-Peer paradigm with Semantic Webtechnologies. In the course of our investigations it turned out that the nature of Peer-to-Peersystems requires some compromises with respect to the use of semantic knowledge models.In particular; the notion of ontology does not really apply as we often do not find a sharedunderstanding of the domain. In this paper; we propose a data model for encoding semanticinformation that combines features of ontology (concept hierarchies; relational structures)with a flexible description and rating model that allows us to handle heterogeneous and …,Proceedings of the second Konferenz Professionelles Wissensmanagement,2003,5
Ontologies and semantic interoperability,Jérôme Euzenat; A Gomez-Perez; Nicola Guarino; Heiner Stuckenschmidt,The ECAI-02 Workshop on Ontologies and Semantic Interoperbability is a follow up of aseries of successful Workshops on Ontologies and related topics that have been held atmajor AI and Computer Science Conferences over the last years. With the increasinginterest in the Semantic Web Ontologies have become a major topic in many conferencesand workshops. On the one hand; this leads to a wider acceptance and use of ontologies; onthe other hand the field is in danger of of loosing focus. This workshop is meant to provide aforum for reserachers interested in Ontologies as a core technology for intrelligentinformation processing; thereby trying to shape the area and its specific topics. At the IJCAI-01 Workshop on Ontologies an Information Sharing; there has been an agreement thatinteroperability will be a main issue in reserach over the next years. Consequently; this …,Proceedings of the European Conference on Artificial Intelligence ECAI'02 Workshops; Université de Lyon,2002,5
Automatic metadata analysis for environmental information systems,Jens Hartmann; Heiner Stuckenschmidt,Abstract Metadata plays an important role in web-based environmental information systems(EIS). It structures existing information and provides background information about technicalissues as well as the context in which information has been generated or should beinterpreted. Further; many systems such as the BUISY (Bremer Umweltinformationssystem)use metadata in order to provide content-based search facilities. Such methods; however;depend on the correctness and completeness of the metadata. In this paper; we discuss anapproach for automatically analyzing the metadata of web-based information systems that isbased on machine learning techniques and its application to different environmentalsystems. We analyze three web-based EIS and discuss our results.,Proceedings of the International Symposium on Environmental Informatics,2002,5
Markov Logic Networks with Numerical Constraints.,Melisachew Wudage Chekol; Jakob Huber; Christian Meilicke; Heiner Stuckenschmidt,Abstract. Markov logic networks (MLNs) have proven to be useful tools for reasoning aboutuncertainty in complex knowledge bases. In this paper; we extend MLNs with numericalconstraints and present an efficient implementation in terms of a cutting plane method. Thisextension is useful for reasoning over uncertain temporal data. To show the applicability ofthis extension; we enrich log-linear description logics (DLs) with concrete domains(datatypes). Thereby; allowing to reason over weighted DLs with datatypes. Moreover; weuse the resulting formalism to reason about temporal assertions in DB-pedia; thus illustratingits practical use.,ECAI,2016,4
Self-tracking reloaded: applying process mining to personalized health care from labeled sensor data,Timo Sztyler; Josep Carmona; Johanna Völker; Heiner Stuckenschmidt,Abstract Currently; there is a trend to promote personalized health care in order to preventdiseases or to have a healthier life. Using current devices such as smart-phones and smart-watches; an individual can easily record detailed data from her daily life. Yet; this data hasbeen mainly used for self-tracking in order to enable personalized health care. In this paper;we provide ideas on how process mining can be used as a fine-grained evolution oftraditional self-tracking. We have applied the ideas of the paper on recorded data from a setof individuals; and present conclusions and challenges.,*,2016,4
Towards decision making via expressive probabilistic ontologies,Erman Acar; Camilo Thorne; Heiner Stuckenschmidt,Abstract We propose a framework for automated multi-attribute decision making; employingthe probabilistic non-monotonic description logics proposed by Lukasiewicz in 2008. Usingthis framework; we can model artificial agents in decision-making situation; whereinbackground knowledge; available alternatives and weighted attributes are represented viaprobabilistic ontologies. It turns out that extending traditional utility theory with suchdescription logics; enables us to model decision-making problems where probabilisticignorance and default reasoning plays an important role. We provide several decisionfunctions using the notions of expected utility and probability intervals; and study theirproperties.,International Conference on Algorithmic DecisionTheory,2015,4
Towards Joint Inference for Complex Ontology Matching.,Christian Meilicke; Jan Noessner; Heiner Stuckenschmidt,Abstract In this paper; we show how to model the matching problem as a problem of jointinference. In opposite to existing approaches; we distinguish between the layer of labels andthe layer of concepts and properties. Entities from both layers appear as first class citizens inour model. We present an example and explain the benefits of our approach. Moreover; weargue that our approach can be extended to generate correspondences involving complexconcept descriptions.,AAAI (Late-Breaking Developments),2013,4
A Study in User-centric Data Integration.,Heiner Stuckenschmidt; Jan Noessner; Faraz Fallahi,Abstract: Data integration is a central problem in information systems. While the problem ofdata integration has been studied intensively from a technical point of view; less attentionhas been paid to user aspects of data integration. In this work; we present a user-centricapproach to data integration that supports the user in finding and validating mapping rulesbetween heterogeneous data sources. The results of our report underline that the user-centric approach leads to better integration results and is perceived as being more intuitive;especially for users with little or no technical knowledge.,ICEIS (3),2012,4
BRAMBLE: A web-based framework for interactive rdf-graph visualisation,Nikolas Schmitt; Mathias Niepert; Heiner Stuckenschmidt,Abstract. Most graph visualisation tools for RDF data are desktop applications focused onloading complete ontologies and metadata from a file and allowing users to filter outinformation if needed. Recently both scientific and commercial frameworks have started toshift their focus to the web; however they still rely on plugins such as Java and rarely handlelarger collections of RDF statements efficiently. In this abstract we present a frameworkwhich visualises RDF graphs in a native browser environment; leveraging both the SVGstandard and JavaScript technology to provide a responsive user interface. Graphs can bedirectly expanded; modified and explored. Users select nodes and edges from a central datarepository containing millions of statements. The resulting graph can be shared with otherusers retaining full interactivity for collaborative work or presentation purposes.,CEUR workshop proceedings,2010,4
Results of the Ontology Alignment Evaluation Initiative 2016,Giorgos Flouris Ferrara; Irini Fundulaki; Ian Harrow; Valentina Ivanova; Ernesto Jiménez-Ruiz; Elena Kuss; Patrick Lambrix; Henrik Leopold; Huanyu Li; Christian Meilicke; Stefano Montanelli; Catia Pesquita; Tzanina Saveta; Pavel Shvaiko; Andrea Splendiani; Heiner Stuckenschmidt; Konstantin Todorov; Cássia Trojahn dos Santos; Ondrej Zamazal,Ontology matching consists of finding correspondences between semantically relatedentities of two ontologies. OAEI campaigns aim at comparing ontology matching systems onprecisely defined test cases. These test cases can use ontologies of different nature (fromsimple thesauri to expressive OWL ontologies) and use different modalities; eg; blindevaluation; open evaluation; or consensus. OAEI 2016 offered 9 tracks with 22 test cases;and was attended by 21 participants. This paper is an overall presentation of the OAEI 2016campaign.[aguirre2012a] José Luis Aguirre; Bernardo Cuenca Grau; Kai Eckert; JérômeEuzenat; Alfio Ferrara; Willem Robert van Hage; Laura Hollink; Ernesto Jiménez-Ruiz;Christian Meilicke; Andriy Nikolov; Dominique Ritze; François Scharffe; Pavel Shvaiko;Ondrej Sváb-Zamazal; Cássia Trojahn dos Santos; Benjamin Zapilko;,ISWC workshop on Ontology Matching,2010,4
Cartographic aspects of geoportals,Lars Harrie; Sebastién Mustiere; Heiner Stuckenschmidt; Hanna Stigmar,Abstract. Following the Inspire directive; several countries are now setting up geoportals.This paper focuses on the cartographic issues raised by view services in these geoportals.The problem with view services; from a cartographic perspective; is the absence of thetraditional cartographer who optimizes the presentation of the cartographic data. In order toenhance the readability of the maps automatic methods should be used. The paper presentsfour types of methods for improving the readability: semantic; conflation generalization andsymbolization methods; as well as some ideas of how the technical implementation of thesemethods could be performed.,Presenting Spatial Information: Granularity; Relevance; and Integration,2009,4
Reasoning about Mappings in Distributed Description Logics,Christian Meilicke; Heiner Stuckenschmidt,An essential element of the semantic web is the use of ontologies to describe the domain ofan information source. As argued by Baader; Horrock; and Sattler in [2]; description logicsare well-suited as ontology languages. Describing an information source by defining anontology of the domain; results in the problem of semantic integration. If the same domain isdescribed by different terminologies; there are also different corresponding domainrepresentations that have to be integrated (compare [4]). In distributed description logicssemantic mappings are used to bridge the gap between different ontologies.Stuckenschmidt; Serafini; and Wache distinguish two lines of work related to the problem ofsemantic integration (see [9]). On the one hand research focuses on the use of semanticmappings for reasoning and query answering. On the other hand tools for the (semi-) …,Bachelor Thesis; University of Mannheim,2006,4
Visualizing RDF Data for P2P Information Sharing,Arthur Ouwerkerk; Heiner Stuckenschmidt,Abstract We discuss the problem of assisting the users of RDF-based Peer-to-peer systemsfor information sharing with visual information about available information and conceptualstructures. We focus on the problem of exploring the knowledge available in the P2Pnetwork and of formulating queries at the conceptual level. After defining requirements forthese tasks; we briefly introduce existing visualization tools that work on RDF-based dataand discuss their suitability with respect to the identified requirements. We conclude with adiscussion of visualization needs that are not supported by available tools and proposesome directions for future research.,Procs of the workshop on Visualizing Information in Knowledge Engineering; VIKE’03,2003,4
Methodologies for ontology-based semantic translation,H Stuckenschmidt; H Wache; U Visser; G Schuster,Use established technologies Ontologies for the explication of the contents of an informationsource (mainly by describing the meaning of table and datafield names) Each informationsource has ontology (resembles and extends structure of DB) Integration with eithercommon ontology or fixed mappings between ontologies Ontology language based on DL,ECIMF,2001,4
Ontological engineering for the cadastral domain,Erik Stubkjær; Heiner Stuckenschmidt,ABSTRACT The term'ontology'has been used in many ways and across differentcommunities. In th following we will introduce ontologies as an explication of some sharedvocabulary or conceptualization of a specific subject matter. The main problem with the useof a shared vocabulary according to a specific conceptualization of the world is that muchinformation remains implicit. Ontologies have set out to overcome the problem of implicit andhidden knowledge by making the conceptualization of a domain (eg mathematics) explicit.Ontological engineering is thus an approach to achieve a conceptual rigor that characterizesestablished academic disciplines; like geodesy. Many university courses address moreapplication oriented fields; like cadastral law; and spatial planning; and they may benefitfrom the ontological engineering approach. The paper provides an introduction to the …,Urban and Regional Data Management Symposium (UDMS 2000); Delft,2000,4
Towards intelligent brokering of geo-information,Thomas Vögele; Heiner Stuckenschmidt; Ubbo Visser,ABSTRACT Using the example of geospatial data; we present an approach for intelligentinformation sharing and data integration. The approach is based on the idea of an intelligentbroker that is able to query formalized semantic descriptions of data sources and softwarecomponents that are available over intranets or the Internet. We discuss the use ofontologies to implement the semantic descriptions of data sources; and define requirementsfor the semantic description of software components. We focus on the first step of dataintegration; ie selecting suitable data sources together with matching software components.We illustrate the approach with a comprehensible application scenario.,Proceedings of the Urban Data Management Symposium; Delft,2000,4
Capturing uncertainty in models of expertise,Heiner Stuckenschmidt; K Christoph Ranze,Abstract Almost all approaches of model-based development of knowledge-based systemsare lacking an explicit handling of uncertain knowledge. Based on a KADS-oriented modelof expertise our paper presents a general framework that enables the representation ofuncertainty in a structure of causality. Based on an existing model of expertise we introducea separate model of uncertainty; whose elements are represented independent of speci cnumerical processing methods. With this approach we got the foundations of a model-basedframework integrating di erent kinds of uncertain information. The corresponding elements ofboth models are explicitly connected. Based on a modi ed part of the Sisyphus I domain; theadvances of handling uncertainties in a causal model preserving the structure of the modelof expertise are shown.,Proceedings of the KEML98 workshop; Karlsruhe; Germany,1998,4
Bridging gaps in models of expertise,K Christoph Ranze; Heiner Stuckenschmidt,Abstract. This paper presents an approach to the explicit integration of uncertain reasoningmechanisms into conventional KADS-based models of expertise. We assume thatuncertainty is present in the model of expertise in the sense that terminological knowledge isavailable but some assertions cannot be determined due to uncertainty. These gaps can bebridged in a three-step inference scheme using a general model of uncertainty in whichknowledge is represented as sets of hypotheses. Our work is based on Shenoy's valuation-based systems and on Pearl's structural equation model of causality. Combining these twoapproaches we obtain a model of uncertainty including a scheme for uncertain inferences.The resulting structure can be used to integrate the specification of uncertainty intoconventional models of expertise. The inference scheme presented in this paper can be …,J" urgen Dix and Steffen H" olldobler; editors; Inference Mechanisms in Knowledge-Based Systems: Theory and Applications,1998,4
Marrying Uncertainty and Time in Knowledge Graphs.,Melisachew Wudage Chekol; Giuseppe Pirrò; Joerg Schoenfisch; Heiner Stuckenschmidt,Abstract The management of uncertainty is crucial when harvesting structured content fromunstructured and noisy sources. Knowledge Graphs (KGs) are a prominent example. KGsmaintain both numerical and non-numerical facts; with the support of an underlying schema.These facts are usually accompanied by a confidence score that witnesses how likely is forthem to hold. Despite their popularity; most of existing KGs focus on static data thusimpeding the availability of timewise knowledge. What is missing is a comprehensivesolution for the management of uncertain and temporal data in KGs. The goal of this paper isto fill this gap. We rely on two main ingredients. The first is a numerical extension of MarkovLogic Networks (MLNs) that provide the necessary underpinning to formalize the syntax andsemantics of uncertain temporal KGs. The second is a set of Datalog constraints with …,AAAI,2017,3
Cross-Evaluation of entity linking and disambiguation systems for clinical text annotation,Camilo Thorne; Stefano Faralli; Heiner Stuckenschmidt,Abstract In this paper we study whether state-of-the-art techniques for multi-domain andmultilingual entity linking can be ported to the clinical domain. To do so; we compare twoknown entity linking systems; BabelFly and TagMe; that leverage on Wikipedia andDBpedia; with the standard clinical semantic annotation and disambiguation system;MetaMap; over the SemRep clinical word sense disambiguation gold standard. We showthat BabelFly and especially TagMe; while achieving decent precision on clinical annotation;outmatch MetaMap's F1-score.,Proceedings of the 12th International Conference on Semantic Systems,2016,3
Schema-Based Debugging of Federated Data Sources.,Andreas Nolle; Christian Meilicke; Melisachew Wudage Chekol; German Nemirovski; Heiner Stuckenschmidt,Abstract. Information explosion leads to continuous growth of data distributed over differentdata sources. However; the increasing number of data sources increases the risk ofinconsistency. In such a federative setting; description logics can be applied to define acentral schema that serves as a conceptual view comprising and extending the semantics ofeach data source. Consequently; each data source is treated as a single knowledge basethat is integrated in a federated knowledge base. Following this idea; we propose anapproach for automated debugging of federated knowledge bases that targets theidentification and repair of inconsistency. We report on experiments with a large distributeddataset from the domain of library science.,ECAI,2016,3
Using abduction in markov logic networks for root cause analysis,Joerg Schoenfisch; Jens Ortmann; Christian Meilicke; Heiner Stuckenschmidt,Abstract: IT infrastructure is a crucial part in most of today's business operations. Highavailability and reliability; and short response times to outages are essential. Thus a highamount of tool support and automation in risk management is desirable to decreaseoutages. We propose a new approach for calculating the root cause for an observed failurein an IT infrastructure. Our approach is based on Abduction in Markov Logic Networks.Abduction aims to find an explanation for a given observation in the light of somebackground knowledge. In failure diagnosis; the explanation corresponds to the root cause;the observation to the failure of a component; and the background knowledge to thedependency graph extended by potential risks. We apply a method to extend a MarkovLogic Network in order to conduct abductive reasoning; which is not naturally supported …,arXiv preprint arXiv:1511.05719,2015,3
Towards large-scale probabilistic OBDA,Joerg Schoenfisch; Heiner Stuckenschmidt,Abstract Ontology-based Data Access has intensively been studied as a very relevantproblem in connection with semantic web data. Often it is assumed; that the accessed databehaves like a classical database; ie it is known which facts hold for certain. Many Webapplications; especially those involving information extraction from text; have to deal withuncertainty about the truth of information. In this paper; we introduce an implementation anda benchmark of such a system on top of relational databases. Furthermore; we propose anovel benchmark for systems handling large probabilistic ontologies. We describe thebenchmark design and show its characteristics based on the evaluation of ourimplementation.,International Conference on Scalable Uncertainty Management,2015,3
Completeness and optimality in ontology alignment debugging.,Jan Noessner; Heiner Stuckenschmidt; Christian Meilicke; Mathias Niepert,Abstract. The benefit of light-weight reasoning in ontology matching has been recognized bya number of researchers resulting in alignment repair systems such as Alcomo and LogMap.While the general benefit of logical reasoning has been shown in principle; there is nosystematic empirical evaluation analyzing (i) the impact of completeness of the reasoningmethods and (ii) whether approximate or optimal solutions to the conflict resolution problemhave to be preferred. Using standard benchmark data sets; we show that increasing theexpressive power does improve the matching results and that optimal resolution methodsslightly outperform approximate ones.,OM,2014,3
Efficient federated debugging of lightweight ontologies,Andreas Nolle; Christian Meilicke; Heiner Stuckenschmidt; German Nemirovski,Abstract In the last years ontologies have been applied increasingly as a conceptual viewfacilitating the federation of numerous data sources using different access methods and dataschemes. Approaches such as ontology-based data integration (OBDI) are aimed at thispurpose. According to these approaches; queries formulated in an ontology describing theknowledge domain as a whole are translated into queries formulated in vocabularies ofintegrated data sources. In such integrative environments the increasing number ofheterogeneous data sources increases the risk of inconsistencies. These inconsistenciesbecome a serious obstacle for leveraging the full potential of approaches like OBDI sinceinconsistencies can be hardly identified by existing reasoning algorithms; which mostly havebeen developed for processing of locally available knowledge bases. In this paper we …,International Conference on Web Reasoning and Rule Systems,2014,3
Erstellen von Ontologien,Heiner Stuckenschmidt,Zusammenfassung In diesem Buch haben wir uns bisher hauptsächlich mit der Fragebeschäftigt; welche Art von Definitionen Teil einer Ontologie sind und wie wir diese sodarstellen können; dass eine automatische Verarbeitung möglich ist. Die Existenzentsprechender Sprachstandards wie OWL bietet zwar ein formales Gerüst; an dem sichEntwickler von Ontologien orientieren können; es gibt jedoch keine Antwort auf die Frage;wie man eine gute Ontologie erstellt. In der Tat stellt die Formulierung exakter und korrekterOntologien noch immer eine der größten Herausforderungen dar; und der hiermitverbundene Aufwand ist eines der Hauptprobleme; die der Verwendung von Ontologien invielen praktischen Bereichen entgegenstehen. Dies hat mehrere Gründe. Zunächst müssenwir feststellen; dass bei der Erstellung zwei Ebenen eine Rolle spielen. Die konzeptuelle …,*,2011,3
Mappingassistant: Interactive conflict-resolution for data integration,Faraz Fallahi; Jan Noessner; E Kiss; Heiner Stuckenschmidt,Abstract. Enterprise applications often face the problem of integrating heterogeneous datadue to the growing number of distributed systems. Leveraging semantic web technologieswith ontologies as target schema for matching data is a successful approach for dataintegration. We developed a new interactive approach for identifying errors withinalignments in the scope of the MappingAssistant project. It is based on a diagnostic methodcombined with human-understandable explanations on the instance level. This supports theusers in finding erroneous rules or facts in a time-saving manner. Introduction. Alignmentsproduced by automated ontology matching algorithms are error-prone. Consequently; theirresults need to be supervised by a human domain expert. As they are usually represented inways only technical experts can deal with; the evaluation task is complicated and time …,Poster at the 8th Extended Semantic Web Conference; ESWC,2011,3
The Semantic Web: Research and Applications,Grigoris Antoniou; Eero Hyvönen; Annette ten Teije; Heiner Stuckenschmidt; Liliana Cabral; Tania Tudorache,*,*,2010,3
A purely logic-based approach to approximate matching of Semantic Web Services,Jörg Schönfisch; Willy Chen; Heiner Stuckenschmidt,Abstract: Most current approaches to matchmaking of semantic Web services utilize hybridstrategies consisting of logic-and non-logic-based similarity measures (or even no logic-based similarity at all). This is mainly due to pure logic-based matchers achieving a goodprecision; but very low recall values. We present a purely logic-based matcherimplementation based on approximate subsumption and extend this approach to takeadditional information about the taxonomy of the background ontology into account. Our aimis to provide a purely logic-based matchmaker implementation; which also achievesreasonable recall levels without large impact on precision.,CEUR workshop proceedings,2010,3
Introduction to Part III,Heiner Stuckenschmidt; Christine Parent; Stefano Spaccapietra,Abstract Another valid view on modularity is ontologies that differs from the one taken in partII of the book is the idea that modules are not created by splitting up a large ontology intosmaller parts but by composing a number of small ontologies that have been createdindependently of each other into a larger model. In this scenario that was investigated inmore detail in chapter 4 the original ontologies become modules in a large modularontology. The advantage of this scenario is not easier maintenance and analysis of theoverall system-in fact integrating different ontologies normally makes both more complicatedcompared to the individual models. The rationale for this approach is the benefit of beingable to reuse knowledge that has been created by other people as well as the Data thatmight be associated with the ontologies to be integrated. This scenario is much closer to …,*,2009,3
Visual Analysis of Classification Systems and Library Collections,Magnus Pfeffer; Kai Eckert; Heiner Stuckenschmidt,Abstract In this demonstration we present a visual analysis approach that addresses bothdevelopers and users of hierarchical classification systems. The approach supports anintuitive understanding of the structure and current use in relation to a specific collection. Wewill also demonstrate its application for the development and management of librarycollections.,International Conference on Theory and Practice of Digital Libraries,2008,3
ISWC’04 Tutorial: Theory and Practice of RDF Query Processing,Heiner Stuckenschmidt; Ad Aerts; Jeen Broekstra; GJ Houben; J Broekstra,• Background/Theory – A short Introduction to RDF and RDF Schema – Graphs; Entailment andQuery Answers – RDF Algebra • Practice – RDF Query Languages and APIs – Storing RDF inRelational Databases – Distributed RDF Querying • Applications – DOPE: Thesaurus-BasedDocument Retrieval – HERA … (What it's like to be a machine?) … <ItemDetail><Description> Armada M700 PIII 12 GB </Description> <UnitPrice> <Money currency="USD"> 998;00 </Money> </UnitPrice> <Classification domain= "UNSPSC"> C43171801</Classification> <Manufacturer> Florsheim </Manufacturer> </ItemDetail> … • Gives structureto data in documents • Gives hints on meaning and relation of data: – possibly meaningful namesfor tags – nesting of tags (tags inside tags) … XML makes no commitment on: ➊ Domain specificontological vocabulary ➋ Ontological modelling primitives … ⇨ requires pre-arranged …,The Third International Semantic Web Conference (ISWC04),2004,3
Enhancing Gezeteers with Qualitative Spatial Concepts,T Vögele; Heiner Stuckenschmidt,Abstract Gazetteers are important tools when it comes to the management and retrieval ofgeospatial and environmental data. Analogous to thematic thesauri; they provide acontrolled and geo-referenced vocabulary of geographic features. However; currentimplementations of gazetteers have a number of limitations with respect to the formulation ofspatial queries. We propose to use qualitative spatial modeling and reasoning to enhancestate-of-the-art gazetteers; and to overcome some of these shortcomings.,Proceedings of the Workshop on Hypermedia in Environmental Protection; Ulm,2001,3
Knowledge-based meta-data validation: Analyzing a web-based information system,Frank Van Harmelen; Arjohn Kampman; Heiner Stuckenschmidt; T Vogele; K Greve,Abstract Web-based information systems play an important role in today's practice of data-analysis and reporting in the field of environmental protection. While these systems solvedsome technical problems concerning the integration and visualization of information theyshow some problems even harder to handle. These problems are concerned with contentand organization of the information within the information system and arise as a result of de-centralized authoring and provision of information. We present an AI approach for analyzingand structuring web-based information systems in order to check validity and consistency ofinformation and to provide a content driven navigation structure. We show the usefulness ofthe approach by applying it to an existing environment information system that we analyzeand structure according to different thematic categories. We also discuss further potentials …,Fourtheenth International Symposium Informatics for Environmental Protection. German Computer Society,2000,3
e Semantic Web: Research and Applications (Part I). th Extended Semantic Web Conference (ESWC)(Hersonissos; Crete; Greece; May–June;),Lora Aroyo; Grigoris Antoniou; Eero Hyvönen; Annette ten Teije; Heiner Stuckenschmidt; Liliana Cabral; Tania Tudorache,*,Lecture Notes in Computer Science. Springer Verlag;(cit. on pp.;),*,3
Overcoming individual process model matcher weaknesses using ensemble matching,Christian Meilicke; Henrik Leopold; Elena Kuss; Heiner Stuckenschmidt; Hajo A Reijers,Abstract In recent years; a considerable number of process model matching techniqueshave been proposed. The goal of these techniques is to identify correspondences betweenthe activities of two process models. However; the results from the Process Model MatchingContest 2015 reveal that there is still no universally applicable matching technique and thateach technique has particular strengths and weaknesses. It is hard or even impossible tochoose the best technique for a given matching problem. We propose to cope with thisproblem by running an ensemble of matching techniques and automatically selecting asubset of the generated correspondences. To this end; we propose a Markov Logic basedoptimization approach that automatically selects the best correspondences. The approachbuilds on an adaption of a voting technique from the domain of schema matching and …,Decision Support Systems,2017,2
Online personalization of cross-subjects based activity recognition models on wearable devices,Timo Sztyler; Heiner Stuckenschmidt,Human activity recognition using wearable devices is an active area of research inpervasive computing. In our work; we address the problem of reducing the effort for trainingand adapting activity recognition approaches to a specific person. We focus on the problemof cross-subjects based recognition models and introduce an approach that considersphysical characteristics. Further; to adapt such a model to the behavior of a new user; wepresent a personalization approach that relies on online and active machine learning. In thiscontext; we use online random forest as a classifier to continuously adapt the model withoutkeeping the already seen data available and an active learning approach that uses user-feedback for adapting the model while minimizing the effort for the new user. We test ourapproaches on a real world data set that covers 15 participants; 8 common activities; and …,Pervasive Computing and Communications (PerCom); 2017 IEEE International Conference on,2017,2
Multi-attribute decision making with weighted description logics,Erman Acar; Manuel Fink; Christian Meilicke; Camilo Thorne; Heiner Stuckenschmidt,Abstract: We introduce a decision-theoretic framework based on Description Logics (DLs);which can be used to encode and solve single stage multi-attribute decision problems. Inparticular; we consider the background knowledge as a DL knowledge base where eachattribute is represented by a concept; weighted by a utility value which is asserted by theuser. This yields a compact representation of preferences over attributes. Moreover; werepresent choices as knowledge base individuals; and induce a ranking via the aggregationof attributes that they satisfy. We discuss the benefits of the approach from a decision theorypoint of view. Furthermore; we introduce an implementation of the framework as a Protégéplugin called uDecide. The plugin takes as input an ontology as background knowledge;and returns the choices consistent with the user's (the knowledge base) preferences. We …,IFCoLog journal of logics and its applications,2017,2
Exploring a multi-sensor picking process in the future warehouse,Alexander Diete; Lydia Weiland; Timo Sztyler; Heiner Stuckenschmidt,Abstract Recognizing; validating; and optimizing activities of workers in logistics isincreasingly aided by smart devices like glasses; gloves; and sensor enhanced wristbands.We present a system that augments picking processes with smart glasses and wristband thatincorporates different types of sensors including ultrasonic; pressure; and inertial. We focuson low barriers for the adoption as well as the combination of video and inertial sensors. Forthat purpose; we create a new semi-supervised dataset to evaluate the feasibility of ourapproach. The system recognizes and monitors activities like grabbing and releasing ofobjects that are essential for order picking tasks.,Proceedings of the 2016 ACM International Joint Conference on Pervasive and Ubiquitous Computing: Adjunct,2016,2
Group decision making via probabilistic belief merging,Nico Potyka; Erman Acar; Matthias Thimm; Heiner Stuckenschmidt,Abstract: We propose a probabilistic-logical framework for group decision-making. Its maincharacteristic is that we derive group preferences from agents' beliefs and utilities ratherthan from their individual preferences as done in social choice approaches. This can bemore appropriate when the individual preferences hide too much of the individuals' opinionsthat determined their preferences. We introduce three preference relations and investigatethe relationships between the group preferences and in-dividual and subgroup preferences.,*,2016,2
New paradigm for alignment extraction.,Christian Meilicke; Heiner Stuckenschmidt,Abstract. Ontology matching techniques that are based on the analysis of names usuallycreate first a set of matching hypotheses annotated with similarity weights followed by theextraction or selection of a set of correspondences. We propose to model this last step as anoptimization problem. Our proposal differs fundamentally from other approaches since bothlogical and linguistic entities appear as first class citizens in the optimization problem. Theextraction step will not only result in a set of correspondences but will also entailassumptions related to the meaning of the tokens that appeared in the involved labels. Wediscuss examples that illustrate the benefits of our approach and present a Markov Logicformalization. We conduct an experimental evaluation and present first results.,OM,2015,2
Exploring structural features for position analysis in political discussions,Cäcilia Zirn; Michael Schäfer; Michael Strube; Simone Paolo Ponzetto; Heiner Stuckenschmidt,Abstract In the context of the NLP Unshared Task in PoliInformatics 2014; we analyze thestructure of FOMC discussions as potential features for position analysis. We access thelength of discussion statements and show that the distinction between long opinionatedstatements and short spontaneous discussion elements improves the analysis of similarityamong speakers. Furthermore; we explore the structure within dialogs by dividing them intosubdialogs and representing the subsequence of speakers as graphs. In our web demo; wepresent visualizations of our analysis including the subgraphs and the similarity amongspeakers.,Paper entry to the,2014,2
On the status of experimental research on the semantic web,Heiner Stuckenschmidt; Michael Schuhmacher; Johannes Knopp; Christian Meilicke; Ansgar Scherp,Abstract Experimentation is an important way to validate results of Semantic Web andComputer Science research in general. In this paper; we investigate the development andthe current status of experimental work on the Semantic Web. Based on a corpus of 500papers collected from the International Semantic Web Conferences (ISWC) over the pastdecade; we analyse the importance and the quality of experimental research conducted andcompare it to general Computer Science. We observe that the amount and quality ofexperiments are steadily increasing over time. Unlike hypothesised; we cannot confirm astatistically significant correlation between a paper's citations and the amount ofexperimental work reported. Our analysis; however; shows that papers comparingthemselves to other systems are more often cited than other papers.,International Semantic Web Conference,2013,2
Debugging weighted ontologies.,Heiner Stuckenschmidt,Abstract. We present our work on debugging weighted ontologies. We define this problemas computing a consistent subontology with a maximal sum of axiom weights. We present areformulation of the problem as finding the most probable consistent ontology according to alog-linear model and show how existing methods from probabilistic reasoning can beadapted to our problem. We close with a discussion of the possible application of weightedontology debugging to web scale information extraction.,WoDOOM,2013,2
Evaluating ontology matching systems on large; multilingual and real-world test cases,Christian Meilicke; Ondrej Sváb-Zamazal; Cássia Trojahn; Ernesto Jiménez-Ruiz; José-Luis Aguirre; Heiner Stuckenschmidt; Bernardo Cuenca Grau,Abstract: In the field of ontology matching; the most systematic evaluation of matchingsystems is established by the Ontology Alignment Evaluation Initiative (OAEI); which is anannual campaign for evaluating ontology matching systems organized by different groups ofresearchers. In this paper; we report on the results of an intermediary OAEI campaign calledOAEI 2011.5. The evaluations of this campaign are divided in five tracks. Three of thesetracks are new or have been improved compared to previous OAEI campaigns. Overall; weevaluated 18 matching systems. We discuss lessons learned; in terms of scalability;multilingual issues and the ability do deal with real world cases from different domains.,arXiv preprint arXiv:1208.3148,2012,2
Web-scale semantic information processing,Jeff Heflin; Heiner Stuckenschmidt,*,*,2012,2
Coherent top-k ontology alignment for owl el,Jan Noessner; Mathias Niepert; Heiner Stuckenschmidt,Abstract The integration of distributed information sources is a key challenge in data andknowledge management applications. Instances of this problem range from mappingschemas of heterogeneous databases to object reconciliation in linked open datarepositories. In this paper; we approach the problem of aligning description logic ontologies.We focus particularly on the problem of computing coherent alignments; that is; alignmentsthat do not lead to unsatisfiable classes in the resulting merged ontologies. We believe thatconsidering coherence during the alignment process is important as it is this logical conceptthat distinguishes ontology alignment from other data integration problems. Depending onthe heterogeneity of the ontologies it is often more reasonable to generate alignments withat most k correspondences because not every entity has a matchable counterpart. We …,International Conference on Scalable Uncertainty Management,2011,2
Towards checking laws' consistency through ontology design: the case of Brazilian vehicles' laws,Fred Freitas; Zacharias Candeias Jr; Heiner Stuckenschmidt,Abstract Official documents; and particularly legal ones like law codes; often containambiguities and/or inconsistencies; due to linguistic problems like polysemy; as well asontological problems like underspecification; disagreements and/or false agreements. Suchproblems can be identified by formalizing the terminology of a domain in terms of anontology. We show this phenomenon in a particular domain; the definition of differentclasses of vehicles. Defining accurately these different vehicle types shed light on some ofthese semantic deficiencies present in two Brazilian legal codes responsible for definingvehicles' categories in an unambiguous manner for many purposes; eg tax calculations;and; more importantly; to make e-government systems interoperate while taking laws intoaccount in a Semantic Web scenario. In this work; we define a framework linking the …,Journal of theoretical and applied electronic commerce research,2011,2
User-centered Maintenance of Concept Hierarchies,Kai Eckert; Robert Meusel; Heiner Stuckenschmidt,Abstract Taxonomies are hierarchical concept representations that have numerousimportant applications from improved indexing of document collections to faceted browsingand semantic search applications. The maintenance of taxonomies includes the dynamicextension; analysis; and visualization of these representations. Instead of focusing on theconstruction of taxonomies from scratch; however; the authors describe several successfulapproaches to the semi-automatic maintenance of taxonomies. These approaches have incommon that they incorporate the human expert as a central part of the system.,*,2011,2
A new usage for semantic technologies for e-government: checking official documents’ consistency,Fred Freitas; Zacharias Candeias; Heiner Stuckenschmidt,Abstract. Semantic technologies; and particularly the ones related to the Semantic Web andits ontologies; have proven useful for many government related applications and prototypes;such as service configuration; automatic service connection among many others. This ispossible because the Semantic Web is based on ontologies; which; in practical words;stands for a detailed conceptualization of a domain and its concepts; relations; constraintsand axioms; defined in an unambiguous manner using formal logic. On the other hand;official documents; and particularly legal ones like law codes; often contain semanticdeficiencies that are not realized by their authors. The most common among them areambiguities; inconsistencies and underspecifications. These deficiencies are certainly asource of systems' and databases' integration problems and confusion during their usage …,ECEG2010-Proceedings of the 10th European Conference on E-Government: National Center for Taxation Studies University of Limerick; Ireland 17-18 June 2010,2010,2
Towards Industrial Strength Knowledge Bases for Product Lifecycle Management.,Willy Chen; Heiner Stuckenschmidt,Abstract The benefits of using semantic technologies for industrial applications arebecoming more and more apparent. While their general usefulness is widely acknowledged;the uptake of technologies originally developed for the semantic web is complicated by themismatch between industrial requirements and design principles of standards such as OWL.In this paper; we argue for the need of a flexible; metamodel-driven approach to addressnon-functional requirements for the use of knowledge bases in industrial settings andpresent a lightweight metamodel for ontologies and rules.,ECIS,2008,2
D1. 2.2. 1.4 Benchmarking of Processing Inconsistent Ontologies,Zhisheng Huang; J Volker; Q Ji; H Stuckenschmidt; C Meilicke; S Schlobach; F van Harmelen; J Lam,Abstract. EU-IST Network of Excellence (NoE) IST-2004-507482 KWEB Deliverable D2. 1.6.3/D1. 2.2. 1.4 (WP2. 1+ WP1. 2) This deliverable investigates methods and results forbenchmarking of processing inconsistent ontologies. In this document; we propose a goldstandard specification language for evaluation of processing inconsistent ontologies. Wehave implemented a benchmarking suite for processing inconsistent ontologies; whichconsists of benchmarking tools; data sets; and gold standards. We have performed a seriesof experiments of benchmarking with realistic inconsistent ontologies. In this document; wereport a comprehensive evaluation of various approaches of processsing inconsistentontologies.,*,2007,2
Towards automatic partitioning of class hierarchies,Heiner Stuckenschmidt; Michel Klein,Abstract—The increasing awareness of the benefits of ontologies for information processinghas lead to the creation of a number of large ontologies about real world domains. The sizeof these ontologies and their monolithic character cause serious problems in handling them.In other areas; eg software engineering; these problems are tackled by partitioningmonolithic entities into sets of meaningful and mostly self-contained modules. In this paper;we suggest a similar approach for ontologies. We propose propose an approach forautomatically partitioning large ontologies into smaller modules based on the structure of theclass hierarchy. The method is demonstrated on a part of the UMLS semantic network.Experiments with larger ontologies are available online at http://swserver. cs. vu.nl/partitioning/,Proc. of the 1st International Conf. on Knowledge Management and Decision Support (ICKMDS’04).–Porto (Portugal).–2004,2004,2
The drug ontology project for elsevier-an rdf architecture enabling thesaurus-driven data integration,Jeen Broekstra; Christiaan Fluit; Arjohn Kampman; Frank Van Harmelen; Heiner Stuckenschmidt; Ravinder Bhogal; A Scerri; Anita de Waard; E van Mulligen,Abstract The DOPE project (Drug Ontology Project for Elsevier) is driven by the need toaccess multiple information sources through a single interface. In this paper; we describehow DOPE allows thesaurus-driven access to heterogeneous and distributed data; basedon the RDF data model. The architecture allows for the easy addition of thesauri and datasources; and can facilitate explorations in ontology mapping and data integration.,*,2004,2
Ontologies and Distributed Systems,Fausto Giunchiglia; Asuncion Gomez-Perez; Adam Pease; Heiner Stuckenschmidt; York Sure; Steven Willmott,From the early 1990s; there has been a fruitful series of over a dozen workshops; symposiaand conferences on the emerging field concerned with the development and application ofontologies. Early workshops were focused in large part on identifying what ontologies were;and how they might be used. As the field developed and matured; we have obtained areasonable understanding and consensus about the nature of ontologies. The core idea isto explicitly encode a shared understanding of some domain that can be agreed amongdifferent parties (be they people or computers). This shared understanding is the ontology-itis an explicit representation comprising a vocabulary of terms; each with a definitionspecifying its meaning. All parties commit to using these terms in accordance to theirdefinitions. Meanwhile; the benefits of using ontologies have been recognized in many …,Proceedings of the IJCAI-03 Workshop; CEUR Workshop Proceedings,2003,2
Semantic web,Heiner Stuckenschmidt,Page 1. 1 Heiner Stuckenschmidt; 2003 The Semantic Web From Vision to Technology HeinerStuckenschmidt Knowledge Representation and Reasoning Group Vrije Universiteit Amsterdamheiner@cs.vu.nl http://www.cs.vu.nl/~heiner/ euroSDR Workshop; Paris 15.4.2004 Page 2. 2 HeinerStuckenschmidt; 2003 The current Web • WWW is an impressive success: • amount of availableinformation (3.3 Giga-page) • number of web-servers (30 million) • number human users (500 million)Page 3. 3 Heiner Stuckenschmidt; 2003 Semantic Web: the vision • However; we've only seentwo generations: ➊ handwritten HTML ➋ database generated pages The real power will come withthe 3rd generation: ➌ machine accessible semantics human readers Page 4. 4 HeinerStuckenschmidt; 2003 machine accessible meaning (What it's like to be a machine) CV nameeducation work private Page 5. 5 Heiner Stuckenschmidt; 2003 …,KI,2002,2
Ontology Language Version 1,D Fensel; I Horrocks; F van Harmelen; J Broekstra; M Crubezy; S Decker; Y Ding; M Erdmann; C Goble; M Klein; B Omelayenko; S Staab; H Stuckenschmidt; R Studer,Ontologies are a popular research topic in various communities such as knowledgeengineering; natural language processing; cooperative information systems; intelligentinformation integration; knowledge management. They provide a shared and commonunderstanding of a domain that can be communicated across people and applicationsystems. They have been developed in Artificial Intelligence to facilitate knowledge sharingand reuse. Recent articles covering various aspects of ontologies can be found in [Uschold& Grüninger; 1996];[van Heijst et al.; 1997];[Studer et al.; 1998];[Benjamins et al.; 1999(a)];[Gomez Perez & Benjamins; 1999];[Fensel; 2000]. An ontology provides an explicitconceptualization (ie; meta information) that describe the semantics of the data. They have asimilar function as a database schema. The differences are1:,On-To-Knowledge deliverable D-1; Vrije Universiteit Amsterdam,2000,2
Das System cosap Optimierung von umweltrelevanten Wirkungen auf der Basis einer ökologischen Schwachstellenanalyse,G Jäschke; KC Ranze; I Timm; H Stuckenschmidt; O Herzog,*,Betriebliche Umweltinformationssysteme in Produktion und Logistik; Metropolis-Verlag Marburg,1998,2
Elwira-wissensbasierte Methoden für den produktionsintegrierten Umweltschutz,Heiner Stuckenschmidt; Ingo Timm; Jörg Schröder; Dietrich Hartmann,*,Proceedings der UI,1997,2
Elwira: Elemente eines wissensbasierten Systems zur Reduzierung umweltrelevanter Auswirkungen,H Stuckenschmidt; I Timm; J Schröder; D Hartmann,*,Wissensbasierte Systeme in Umweltanwendungen. Proceedings des gleichnamigen Workshops auf der XPS,1997,2
Analyzing real-world SPARQL queries and ontology-based data access in the context of probabilistic data,Joerg Schoenfisch; Heiner Stuckenschmidt,Abstract Handling uncertain knowledge is crucial for modeling many real world domains.Ontologies and ontology-based data access (OBDA) have proven to be versatile methods tocapture this knowledge. Multiple systems for OBDA have been developed and there istheoretical work towards probabilistic OBDA; namely identifying efficiently processablequeries. These queries are called safe queries. However; there is no analysis on thesafeness of probabilistic queries in real-world applications; and there exists no tool supportfor applying the existing formalisms to the standard query language of SPARQL. In thispaper we investigate queries collected from several public SPARQL endpoints anddetermine the distribution of safe and unsafe queries. This analysis shows that many queriesin practice are safe; making probabilistic OBDA feasible and practical to fulfill real-world …,International journal of approximate reasoning,2017,1
Fast ABox consistency checking using incomplete reasoning and caching,Christian Meilicke; Daniel Ruffinelli; Andreas Nolle; Heiko Paulheim; Heiner Stuckenschmidt,Abstract Reasoning with complex ontologies can be a resource-intensive task; which can bean obstacle; eg; for real-time applications. Hence; weakening the constraints of soundnessand/or completeness is often an approach to practical solutions. In this paper; we proposean extension of incomplete reasoning methods for checking the consistency of a largenumber of ABoxes against a given TBox. In particular; we use and extend the clash queriesproposed by Lembo et al. 9 for DL-Lite to compute inconsistent patterns of ABox assertions.By caching instantiations of these patterns; we are able to reduce the amount of reasoningrequired to determine the inconsistency of an ABox with every previously processed ABox.We present experimental results of our approach in terms of runtime and accuracy andcompare it against complete reasoning techniques; the reasoning approach for DL-Lite …,International Joint Conference on Rules and Reasoning,2017,1
A smart data annotation tool for multi-sensor activity recognition,Alexander Diete; Timo Sztyler; Heiner Stuckenschmidt,Annotation of multimodal data sets is often a time consuming and a challenging task asmany approaches require an accurate labeling. This includes in particular video recordingsas often labeling exact to a frame is required. For that purpose; we created an annotationtool that enables to annotate data sets of video and inertial sensor data. However; in contrastto the most existing approaches; we focus on semi-supervised labeling support to inferlabels for the whole dataset. More precisely; after labeling a small set of instances oursystem is able to provide labeling recommendations and in turn it makes learning of imagefeatures more feasible by speeding up the labeling time for single frames. We aim to rely onthe inertial sensors of our wristband to support the labeling of video recordings. For thatpurpose; we apply template matching in context of dynamic time warping to identify time …,Pervasive Computing and Communications Workshops (PerCom Workshops); 2017 IEEE International Conference on,2017,1
Domain adaptation for automatic detection of speculative sentences,Sanja Štajner; Goran Glavaš; Simone Paolo Ponzetto; Heiner Stuckenschmidt,The use of speculative; uncertain or vague sentences is common in both spoken and writtenlanguage. Automatic detection of such sentences plays significant role in natural languageprocessing and social sciences as it could enhance information extraction systems and leadto faster and more reliable analyses in social sciences. However; this problem has onlybeen addressed in biomedical and encyclopedic domains. In this paper; we addressautomatic speculation detection (as a binary sentence classification task) in monetary policydomain; and for the first time; on the transcripts of spoken language. We build two newspeculation detection datasets and a dictionary of speculation triggers using expertannotations; and benchmark the performance of automatic speculation detection systems inthis new domain.,Semantic Computing (ICSC); 2017 IEEE 11th International Conference on,2017,1
Automatic classification to matching patterns for process model matching evaluation,Elena Kuss; Heiner Stuckenschmidt,Abstract. Business process model matching is concerned with the detection of similarities inbusiness process models. To support the progress of process model matching techniques;efficient evaluation strategies are required. State-of-the-art evaluation techniques provide agrading of the evaluated matching techniques. However; they only offer limited informationabout strength and weaknesses of the individual matching technique. To efficiently evaluatematching systems; it is required to automatically analyze the attributes of the matcher output.In this paper; we propose an evaluation by automatic classification of the alignments tomatching patterns. On the one hand; to understand strength and weaknesses of a matchingtechnique. On the other hand; to identify potential for further improvement. Consequently;optimal matching scenarios of a specific matcher can be derived. This further enables …,CEUR workshop proceedings,2017,1
Root cause analysis through abduction in Markov logic networks,Joerg Schoenfisch; Janno von Stulpnagel; Jens Ortmann; Christian Meilicke; Heiner Stuckenschmidt,IT infrastructure is a crucial part in most of today''s business operations. High availability andreliability; and short response times to outages are essential. Thus a high amount of toolsupport and automation in risk management is desirable to decrease outages. We proposea new approach for calculating the root cause for an observed failure in an IT infrastructure.Our approach is based on Abduction in Markov Logic Networks. Abduction aims to find anexplanation for a given observation in the light of some background knowledge. In failurediagnosis; the explanation corresponds to the root cause; the observation to the failure of acomponent; and the background knowledge to the dependency graph extended by potentialrisks. We apply a method to extend a Markov Logic Network in order to conduct abductivereasoning; which is not naturally supported in this formalism. Our approach exhibits a …,Enterprise Distributed Object Computing Conference (EDOC); 2016 IEEE 20th International,2016,1
15 years of semantic web: An incomplete survey,Birte Glimm; Heiner Stuckenschmidt,Abstract It has been 15 years since the first publications proposed the use of ontologies as abasis for defining information semantics on the Web starting what today is known as theSemantic Web Research Community. This work undoubtedly had a significant influence onAI as a field and in particular the knowledge representation and Reasoning Community thatquickly identified new challenges and opportunities in using Description Logics in a practicalsetting. In this survey article; we will try to give an overview of the developments the field hasgone through in these 15 years. We will look at three different aspects: the evolution ofSemantic Web Language Standards; the evolution of central topics in the Semantic WebCommunity and the evolution of the research methodology.,KI-Künstliche Intelligenz,2016,1
Analyzing Real-World SPARQL Queries in the Light of Probabilistic Data.,Joerg Schoenfisch; Heiner Stuckenschmidt,Abstract. Handling uncertain knowledge–like information extracted from unstructured text;with some probability of being correct–is crucial for modeling many real world domains.Ontologies and ontology-based data access (OBDA) have proven to be versatile methods tocapture this knowledge. Multiple systems for OBDA have been developed and there istheoretical work towards probabilistic OBDA; namely identifying efficiently processable(safe) queries. However; there is no analysis on the safeness of probabilistic queries in real-world applications; or in other words the feasibility of fulfilling users' information needs overprobabilistic data. In this paper we investigate queries collected from several publicSPARQL endpoints and determine the distribution of safe and unsafe queries. This analysisshows that many queries in practice are safe; making probabilistic OBDA feasible and …,URSW@ ISWC,2016,1
E-Commerce and Web Technologies: 16th International Conference on Electronic Commerce and Web Technologies; EC-Web 2015; Valencia; Spain; September 2...,Heiner Stuckenschmidt; Dietmar Jannach,This book constitutes the revised proceedings of the 16th International Conference onElectronic Commerce and Web Technologies (EC-Web) held in Valencia; Spain; inSeptember 2015. The 10 full papers included in this volume were carefully reviewed andselected from 28 submissions. The papers are organized in topical sections onrecommender systems; multimedia recommendation; social and semantic web; and processmanagement.,*,2015,1
uDecide: A protégé plugin for multiattribute decision making,Erman Acar; Manuel Fink; Christian Meilicke; Heiner Stuckenschmidt,Abstract This paper introduces the Protégé plugin uDecide. With the help of uDecide it ispossible to solve multi-attribute decision making problems encoded in a straight forwardextension of standard Description Logics. The formalism allows to specify backgroundknowledge in terms of an ontology; while each attribute is represented as a weighted classexpression. On top of such an approach one can compute the best choice (or the best k-choices) taking background knowledge into account in the appropriate way. We show howto implement the approach on top of existing semantic web technologies and demonstrateits benefits with the help of an interesting use case that illustrates how to convert an existingweb resource into an expert system with the help of uDecide.,Proceedings of the 8th International Conference on Knowledge Capture,2015,1
On the use of different modalities in political communication: evidence from German election manifestos,Marc Debus; Heiner Stuckenschmidt; Hartmut Wessler,Political communication is largely multimodal in character. The media that citi-Zens use mostwidely to inform themselves about political matters–television; media-owned websites; evenprint newspapers–use a combination of text and images or of text; moving images; spokenlanguage; and sound. The same applies to social media platforms such as Facebook andTwitter which feature some political information often in the form of (short) written texts plusimages or links to (multimodal) websites. Similarly; the communication that emanates frompolitical actors directly combines different modalities–think about party or candidatewebsites and social media feeds; printed materials such as leaflets and posters or televisedpublic appearances and speeches; particularly on the campaign trail. In this contribution; wefocus on one such material; namely election manifestos that political parties produce to …,Sprache-Medien-Innovationen,2015,1
Lost in discussion? Tracking opinion groups in complex political discussions by the example of the fomc meeting transcriptions,Cäcilia Zirn; Robert Meusel; Heiner Stuckenschmidt,Abstract The Federal Open Market Committee (FOMC) is a committee within the centralbanking system of the US and decides on the target rate. Analyzing the positions of itsmembers is a challenge even for experts with a deep knowledge of the financial domain. Inour work; we aim at automatically determining opinion groups in transcriptions of the FOMCdiscussions. We face two main challenges: first; the positions of the members are morecomplex as in common opinion mining tasks because they have more dimensions than proor contra. Second; they cannot be learned as there is no labeled data available. We addressthe challenge using graph clustering methods to group the members; including the similarityof their speeches as well as agreement and disagreement they show towards each other indiscussions. We show that our approach produces stable opinion clusters throughout …,Proceedings of the International Conference Recent Advances in Natural Language Processing,2015,1
Cluster It! Semiautomatic Splitting and Naming of Classification Concepts,Dominik Stork; Kai Eckert; Heiner Stuckenschmidt,Abstract In this paper; we present a semiautomatic approach to split overpopulatedclassification concepts (ie classes) into subconcepts and propose suitable names for thenew concepts. Our approach consists of three steps: In a first step; meaningful term clustersare created and presented to the user for further curation and selection of possible newsubconcepts. A graph representation and simple tf-idf weighting is used to create the clustersuggestions. The term clusters are used as seeds for the subsequent content-basedclustering of the documents using k-Means. At last; the resulting clusters are evaluatedbased on their correlation with the preselected term clusters and proper terms for the namingof the clusters are proposed. We show that this approach efficiently supports the maintainerwhile avoiding the usual quality problems of fully automatic clustering approaches …,*,2013,1
Knowledge Engineering and Knowledge Management: 18th International Conference; EKAW 2012; Galway City; Ireland; October 8-12; 2012; Proceedings,Annette ten Teije; Johanna Völker; Siegfried Handschuh; Heiner Stuckenschmidt; Mathieu d'Acquin; Andriy Nikolov; Nathalie Aussenac-Gilles; Nathalie Hernandez,This book constitutes the refereed proceedings of the 18th International Conference onKnowledge Engineering and Knowledge Management; EKAW 2012; held in Galway City;Ireland; in October 2012. The 44 revised full papers were carefully reviewed and selectedfrom 107 submissions. The papers are organized in topical sections on knowledgeextraction and enrichment; natural language processing; linked data; ontology engineeringand evaluation; social and cognitive aspects of knowledge representation; application ofknowledge engineering; and demonstrations.,*,2012,1
User-centric data integration with the mappingassistant,Heiner Stuckenschmidt; Jan Noessner; Faraz Fallahi,Abstract Data integration is the problem of transferring complex data from one into anotherrepresentation in order to support exchange between different systems. From a technicalpoint of view data integration has intensively been studied. However; less attention hasbeen paid to user-centric aspects of data integration. In this work; we present theMappingAssistant which supports the user in finding and validating mapping rules betweenheterogeneous data sources. Compared to existing approaches we focus on an user-centricapproach where the user inspects the consequences of the data integration rules on theinstance level rather than being confronted with complex data integration rules. Weperformed a study which shows that the user-centric approach leads to better integrationresults; especially for users with little or no technical knowledge and is perceived as …,International Conference on Enterprise Information Systems,2012,1
Mining Unstructured Financial News to Forecast Intraday Stock Price Movements,Simon Bacher,Abstract: In this thesis; we develop a system that analyzes unstructured financial news usingtext classification in order to forecast stock price trends. We review similar systems to buildon successful ideas and combine them with novel approaches. We discuss the differenttypes of news that are potentially relevant to the stock prices and choose news sources forthe system accordingly. To eliminate irrelevant news; we present suitable filteringapproaches such as the implementation of a rule-based thesaurus. We develop anautomatic labeling approach and compare it to a manual labeling approach. We evaluatethe influence of different automatic labeling approaches on the prediction performance. In adata training phase; we introduce a set of features novel with respect to the price forecastingtask. We compare different text mining techniques such as the feature vector …,*,2012,1
Beispiele,Heiner Stuckenschmidt,Zusammenfassung In den vorangegangenen Kapiteln haben wir uns mit grundlegendenKonzepten und Ansätzen zur Repräsentation von ontologischem Wissen beschäftigt. Bevorwir im folgenden Teil dieses Buches auf konkrete Technologien eingehen; welche dieErstellung und Nutzung von Ontologien unterstützen; wollen wir uns zunächst einigenBeispielen bestehender Ontologien zuwenden. Diese Beispiele stellen die Verbindungzwischen den beschriebenen Prinzipien sowie den konkreten Anwendungen vonOntologien her; die im letzten Teil dieses Buches beschrieben werden. Die Beispielewichtiger Ontologien zeigen; dass sowohl das Prinzip der semantischen Netze; als auch dieLogik-basierte Darstellung von ontologischem Wissen in der Realität Anwendung findet.,*,2011,1
A web-based evaluation service for ontology matching,Jérôme Euzenat; Christian Meilicke; Heiner Stuckenschmidt; Cássia Trojahn dos Santos,Evaluation of semantic web technologies at large scale; including ontology matching; is animportant topic of semantic web research. This paper presents a web-based evaluationservice for automatically executing the evaluation of ontology matching systems. Thisservice is based on the use of a web service interface wrapping the functionality of amatching tool to be evaluated and allows developers to launch evaluations of their tool atany time on their own. Furthermore; the service can be used to visualise and manipulate theevaluation results. The approach allows the execution of the tool on the machine of the tooldeveloper without the need for a runtime environment.,Proc. 9th demonstration track on international semantic web conference (ISWC),2010,1
Text-Mining for Semi-Automatic Thesaurus Enhancement,Robert Meusel; Heiner Stuckenschmidt,The ongoing dispersion of the internet and digital stored media press the research in thearea of information retrieval ahead. Media indexing and retrieval; as it is provided by thepopular web search engine companies Google and Yahoo has become also in companiesmore and more popular for internal use. These organisations try to support the knowledgemanagement of their employees. This includes the creation and storing of meta data and inaddition the providing of a retrieval system. Caused by the enormous costs of suchprocesses; more and more automatism has been included; already in the past. A structurewhich supports the automatic indexing and retrieval is a thesaurus. A thesaurus is astructured dictionary; which is focused on the representation of a limited set of semanticrelations between different concepts. In the process of automatic document indexing the …,*,2009,1
Generating Complex Ontology Alignments,Dominique Ritze; Heiner Stuckenschmidt,Nowadays a huge amount of information is available via the World Wide Web. Everyone candistribute data and a lot of companies sell their goods online. This leads to several problemsespecially to find information a user is looking for. The reason behind is that computers;unlike humans; cannot really gather the facts and particularly not understand them. Also thedecentralized organization of the Internet does not help to solve this problem; in contrast; itsupports the heterogeneity of information. Due to the facts mentioned above it is not possibleto get all information and to represent them in a consistent way. The Semantic Web;introduced by Tim Berners-Lee 2001 [2]; tries to find a solution by constituting all informationin a machine-readable way. Discovering and integrating information and additionally infernew data out of given data are the main Semantic Web challenges. To achieve the ideas …,University Mannheim (Bachelor thesis),2009,1
Modularity in databases,Christine Parent; Stefano Spaccapietra; Esteban Zimányi,Summary Modularization can be sought for as a technique to provide context-dependentperspectives over a given shared information repository. This chapter presents an approachto database modularization where the modules represent application-specific perspectivesover the shared database. The approach is meant to support the creation/definition of themodules as part of the conceptual schema definition process; that is to say the modules andthe database they are a subset of are simultaneously defined. This is similar to Cyc'sapproach to ontological microtheories definition. The chapter develops both intuitive andformal definition of the proposed approach. It also shows the basics of how the modules areused by user transactions and of how the overall multiperception database can beimplemented on a commercial database management system.,*,2009,1
Debugging Description Logic Ontologies-A Reality Check,Heiner Stuckenschmidt,*,CEUR workshop proceedings,2008,1
Approximate Subsumption in ALCΟ,Heiner Stuckenschmidt,Abstract. We present a non-standard interpretation for concept expressions in ALCQ thatdefines approximate notions of subsumption based on approximating a subset of theconcept and role names. We present the non-standard semantics; and the correspondingnotion of approximate subsumption; discuss its formal properties and show that is can becomputed by syntactic manipulations of concept expressions.,International Workshop on Description Logics (DL 2007),2007,1
Thesaurus Analysis and Visualization in Semantic Search Applications,Kai Eckert; Heiner Stuckenschmidt,In this chapter; we give an overview of the context of our work. Next; we briefly outline thebasics of thesaurus-based information retrieval and describe the Collexis Engine that wasused for our experiments. In Chapter 3; we describe two experiments in automaticallyindexing documents in the areas of medicine and economics with corresponding thesauriand compare the results to available manual annotations. Chapter 4 describes methods forassessing thesauri and visualizing the result in terms of a treemap. We depict examples ofinteresting observations supported by the method and show that we actually find criticalproblems. We conclude with a discussion of open questions and future research in Chapter5.,*,2007,1
Querying embedded RDF with XML Technology-A Feasibility Study,Norman May; Heiner Stuckenschmidt,*,*,2007,1
The Integrating Ontologies Workshop at K-CAP 2005,Benjamin Ashpole; Marc Ehrig; Jérôme Euzenat; Heiner Stuckenschmidt,The Integrating Ontologies Workshop is a forum for researchers and application developersfrom the area of ontology interoperability to exchange knowledge; ideas; approaches; andchallenges for handling multiple competing ontologies. The workshop will facilitatemethodological and technical discussions. For many knowledge domains; a variety ofostensibly “standard” ontologies have been engineered; learned; and extended. Each is aninterface for a similar purpose yet uses different nomenclatures. To enable collaborationwithin and across application domains; software agents require transparency between thevarious formalisms. This requires both semantic alignment and syntactical translation. Purelymanual approaches are error-prone; onerous; and insufficient to support dynamic systemsinteroperability. However; recent research in ontology alignment exploits “meaning” that …,Integrating Ontologies Workshop Proceedings,2005,1
D2. 1.2 Methods for Approximate Reasoning,Perry Groot; Pascal Hitzler; Ian Horrocks; Boris Motik; Jeff Z Pan; Heiner Stuckenschmidt; Daniele Turi; Holger Wache,Abstract. EU-IST Network of Excellence (NoE) IST-2004-507482 KWEB Deliverable D2.1.2(WP2.1) This deliverable shows examples about approximating symbolic inference enginesin a Semantic Web environment. Approaches of language weakening; knowledgecompilation; and approxi- mated deduction are presented. The last one is evaluated in practicalapplications with mixed results. Keyword list: state-of-the-art; scalability; approximation;modularisation; distribution; symbolic reasoning … Document Identifier KWEB/2004/D2.1.2/v1.2 Project KWEB EU-IST-2004-507482 Version v1.2 Date January 30th; 2005 State final Distributionpublic … This document is part of a research project funded by the IST Programme of the Commissionof the European Com- munities as project number IST-2004-507482 … University of Innsbruck(UIBK) - Coordinator Institute of Computer Science Technikerstrasse 13 A-6020 …,Knowledge Web Project Deliverable. http://knowledgeweb,2005,1
Methods for approximate reasoning,Perry Groot; Pascal Hitzler; Ian Horrocks; Boris Motik; Jeff Z Pan; Heiner Stuckenschmidt; Daniele Turi; Holger Wache,Abstract This deliverable shows examples about approximating symbolic inference enginesin a Semantic Web environment. Approaches of language weakening; knowledgecompilation; and approximated deduction are presented. The last one is evaluated inpractical applications with mixed results.,*,2005,1
Ontology-based information sharing,Heiner Stuckenschmidt; Frank van Harmelen,Summary. In the last chapter we introduced the general problem of information sharing inthe presence of heterogeneous data. In this chapter; we introduce ontologies as a means ofdealing with semantic heterogeneity. We discuss the nature and applications of ontologiesand review existing approaches that use ontologies for dealing with heterogeneous data.We also identify the state of the art in ontology-based information integration and identifyopen problems that will be addressed in the remainder of the book.,Information Sharing on the Semantic Web,2005,1
Ontology languages for the Semantic Web,Heiner Stuckenschmidt; Frank van Harmelen,We first give a general and abstract model of ontologies and the logical infer- ences that theysupport (in section 3.1). We then describe a stack of ever more expressive Web-based ontologylanguages: RDF Schema; OWL Lite; OWL DL and OWL Full (sections 3.2.1–3.2.4). We concludethis chapter with a brief comparison with other ontology languages (section 3.3) … In orderto get a general notion of ontological knowledge; we define the general structure of a terminologicalknowledge base (ontology) and its instantiation independent of a concrete language … Definition3.1 (terminological knowledge base). A terminological knowledge base T is a triple … Terminologicalknowledge usually groups objects of the World that have cer- tain properties in common (egcities or countries). A description of the shared properties is called a class definition. Conceptscan be arranged into a subclass–superclass relation in order to be able to further …,Information Sharing on the Semantic Web,2005,1
Sharing statistical information,Heiner Stuckenschmidt; Frank van Harmelen,Summary. In the last chapter; we introduced a number of basic techniques for retrieving andintegrating heterogeneous information sources. In this chapter; we report an application ofsome of these techniques in a project on the integration of European fishery statistics. Weidentify the special characteristics of statistical information and focus on the use of the WebOntology Language for representing statistical information and for retrieving informationbased on a semantic description.,Information Sharing on the Semantic Web,2005,1
Towards Mapping-Based Document Retrieval in Heterogeneous Digital Libraries,Heiner Stuckenschmidt; Wolf Siberski; Erik van Mulligen,Abstract In many scientific domains; researchers depend on a timely and efficient access toavailable publications in their particular area. The increasing availability of publications inelectronic form via digital libraries is a reaction to this need. A remaining problem is the factthat the pool of all available publications is distributed between different libraries. In order toincrease the availability of information; these different libraries should be linked in such away; that all the information is available via any one of them. Peer-to-peer technologiesprovide sophisticated solutions for this kind of loose integration of information sources. In ourwork; we consider digital libraries that organize documents according to a dedicatedclassification hierarchy or provide access to information on the basis of a thesaurus. Thesekinds of access mechanisms have proven to increase the retrieval result and are …,Dagstuhl Seminar Proceedings,2005,1
3.6 Refined Methods,Marc Ehrig; Peter Haase; Björn Schnizler; Steffen Staab; Christoph Tempich; Ronny Siebes; Heiner Stuckenschmidt,SWAP: Semantic Web and Peer-to-Peer … Marc Ehrig; Peter Haase; Björn Schnizler; SteffenStaab … Christoph Tempich (University of Karlsruhe); Ronny Siebes … ExecutiveSummary. SWAP EU IST-2001-34103 Project Deliverable D3.6 This paper describes the methodsdeveloped throughout the project. The deliverable focuses on updates and refinements of theprevious deliverables … Copyright c 2004 Institute AIFB; University of Karlsruhe …SWAP/2003/D3/v1.0 SWAP EU IST-2001-34103 July 15; 2004 public … This document is partof a research project partially funded by the IST Programme of the Commission of the EuropeanCommunities as project number IST-2001-34103. The partners in this project are: Institute AIFB/ University of Karlsruhe (coordinator; Germany); Vrije Universiteit Amsterdam VUA(Netherlands); Meta4 (Spain); empolis UK ltd. (UK); empolis Polska (Poland); and IBIT …,Semantic Web and Peer-to-Peer (SWAP) Consortium,2004,1
Survey of scalability techniques for reasoning with ontologies,J Euzenat; T Bach; J Barrasa; P Bouquet; J Bo; R Dieng; M Ehrig; M Hauswirth; M Jarrar; R Lara; D Maynard; A Napoli; G Stamou; H Stuckenschmidt; P Shvaiko; S Tessaris; S Acker; I Zaihrayeu,*,*,2004,1
Foreword: ontologies for distributed systems,Heiner Stuckenschmidt,Abstract The benefits of using ontologies have been recognised in many areas such asknowledge and content management; electronic commerce and recently the emerging fieldof the Semantic Web. These new applications can be seen as a great success of research inontologies. On the other hand; moving into real application comes with new challenges thatneed to be addressed on a principled level rather than for specific applications. This specialissue will be devoted to less well-explored topics that have come into focus recently as aresponse to the new problems we face when trying to use ontologies in heterogeneousdistributed environments. These environments include the use of ontologies in peer-to-peerand pervasive computing systems.,The Knowledge Engineering Review,2003,1
Kick-Off Meeting of the COST Action G9" Modeling Real-property Transactions",Christoph Schlieder; Erik Stubkjaer; Heiner Stuckenschmidt,*,*,2001,1
Statement of Interest: Towards Ontology Language Customization,Heiner Stuckenschmidt,Systems Engineering: The use of ontologies for the description of information and systemshas many benefits. The ontology can be used to identify requirements as well asinconsistencies in a chosen design. It can help to acquire or search for available information.Once a systems component has been implemented its specification can be used formaintenance and extension purposes. Information Integration: An important application areaof ontologies is the integration of existing systems. The ability to exchange information at runtime; also known as interoperability; is an important topic. In order to enable machines tounderstand each other we also have to explicate the vocabulary of each system in terms ofan ontology.,Ontologies and Information Sharing,2001,1
A flexible framework for uncertain expertise,Heiner Stuckenschmidt; K Christoph Ranze,Abstract In this paper we argue that the development of knowledge-based Systems built towork in partially uncertain domains benefit from The use of different conceptualizations forcertain and uncertain parts Of the knowledge. We present conceptualizations that haveproven to be Useful; namely the KADS model of expertise and a causal model of uncertaintyThat reflects well known approaches to uncertain reasoning like Bayesian belief nets. After abrief introduction to theses conceptualizations We propose a translation approach that aimsat an integration of These conceptualizations in a common knowledge model that can beused In a knowledge engineering process.,International Conference on Knowledge Engineering and Knowledge Management,1999,1
A specification language for uncertain knowledge models,Heiner Stuckenschmidt; K Christoph Ranze,Abstract. We extend the language ML 2; which was designed to describe models ofexpertise in a formal way with an explicit model of uncertainty. Doing this we follow aframework for modeling uncertain expertise which has been presented elsewhere. Wereview the language ML 2and the framework for uncertain expertise. Finally we present thelanguage FLUE Formal Language for Uncertain Expertise which is the result of extendingthe syntax of ML 2with concepts to describe uncertain parts of a model of expertise. We endwith a brief discussion of benefits and open problems.,Language,*,1
Semantic Translation of Land-Use classifications: A case study,Heiner Stuckenschmidt,Over the laSt few yearS much work haS been conducted in regardS to the reSearch topicfully interoperable GIS (VckovSki; 1998). GIS'S Share the need to Store and proceSS largeamountS of diverSe data; which iS often geographically diStributed. MoSt GIS'S uSe Specificdata modelS and databaSeS for thiS purpoSe. ThiS implieS; that making new data availableto the SyStem requireS the data to be tranSferred into the SyStem'S Specific data format.ThiS problem iS addreSSed by the Bremen UniverSity Semantic TranSlation Project1. Themain deliverable of the project iS a knowledge-baSed SyStem for the integration of(geographic) data. The SyStem diStinguiSheS three levelS on integration: Syntactic;Structural; and Semantic integration. In thiS paper we focuS on the Semantic aSpectS ofintelligent information integration that trieS to preServe the intended meaning of …,Geographical Domain and Geo-graphical Information Systems,*,1
Introduction to the 1st International Workshop on Business Process Innovation with Artificial Intelligence (BPAI 2017),Riccardo De Masellis; Chiara Di Francescomarino; Jana Koehler; Fabrizio Maria Maggi; Marco Montali; Arik Senderovich; Biplav Srivastava; Heiner Stuckenschmidt,Abstract. Artificial Intelligence (AI) is receiving high interest from academics; businessprofessionals; and media. It is considered as the next disruptive technology that willsignificantly impact the workplace and change; innovate; and automate a manifold ofbusiness activities. The goal of the workshop was to foster the exchange between AI andBusiness Process Management (BPM) by taking a closer look at how BPM inspires novelapplication domains for AI; as well as at how BPM and related fields can benefit from AIsolutions. Six full and four short papers were accepted for presentation at the workshop.They stimulated an interesting discussion on potential future synergies between the twodisciplines.,Business Process Management Workshops: BPM 2017 International Workshops; Barcelona; Spain; September 10-11; 2017; Revised Papers,2018,*
NECTAR: Knowledge-based collaborative active learning for activity recognition,Gabriele Civitarese; Claudio Bettini; Timo Sztyler; Daniele Riboni; Heiner Stuckenschmidt,Abstract: Due to the emerging popularity of pervasive healthcare applications; tools formonitoring activities in smart homes are gaining momentum. Existing methods mainly relyon supervised learning algorithms for recognizing activities based on sensor data. A keyissue with those approaches is the acquisition of comprehensive training sets of activities.Indeed; that task incurs relevant costs in terms of manual labeling effort; moreover; labelingby external observers violates the individual's privacy. For these reasons; there is anincreasing interest in unsupervised activity recognition methods. A popular approach relieson knowledge-based models expressed by ontologies of activities; environment andsensors. Unfortunately; those models require significant knowledge engineering efforts; andare often limited to a specific application. Our intuition is that a generic knowledge-based …,*,2018,*
Improving motion-based activity recognition with ego-centric vision,Alexander Diete; Timo Sztyler; Lydia Weiland; Heiner Stuckenschmidt,Abstract: Human activity recognition using wearable computers is an active area of researchin pervasive computing. Existing works mainly focus on the recognition of physical activitiesor so called activities of daily living by relying on inertial or interaction sensors. A main issueof those studies is that they often focus on critical applications like health care but withoutany evidence that the monitored activities really took place. In our work; we aim to overcomethis limitation and present a multi-modal egocentric-based activity recognition approachwhich is able to recognize the critical objects. As it is unfeasible to expect always a highquality camera view; we enrich the vision features with inertial sensor data that representsthe users' arm movement. This enables us to compensate the weaknesses of the respectivesensors. We present first results of our ongoing work on this topic.,*,2018,*
Towards Systematic Benchmarking of Activity Recognition Algorithms,Timo Sztyler; Christian Meilicke; Heiner Stuckenschmidt,Abstract: In this paper we propose a benchmarking framework for evaluating activityrecognition methods. We use an ontology for describing activity recognition datasets on themeta-level and propose a fine-grained annotation scheme for activity recognition datasets.Given a method that implements a defined interface; an evaluation client can be used toautomatically run experiments on annotated datasets. Our framework helps to find relevantdatasets and makes results reproducible by fixing concrete experimental settings. We showhow to use the framework and report about a preliminary evaluation experiment.,*,2018,*
Modeling and reasoning with ProbLog: an application in recognizing complex activities,Timo Sztyler; Gabriele Civitarese; Heiner Stuckenschmidt,Abstract: Smart-home activity recognition is an enabling tool for a wide range of ambientassisted living applications. The recognition of ADLs usually relies on supervised learning orknowledge-based reasoning techniques. In order to overcome the well-known limitations ofthose two approaches and; at the same time; to combine their strengths to improve therecognition rate; many researchers investigated Markov Logic Networks (MLNs). However;MLNs require a non-trivial effort by experts to properly model probabilities in terms ofweights. In this paper; we propose a novel method based on ProbLog. ProbLog is aprobabilistic extension of Prolog; which allows to explicitly define probabilistic facts andrules. With respect to MLN; the inference mode of ProbLog is based on the closed-worldassumption and it has faster response times. We propose a simple and flexible ProbLog …,*,2018,*
Hips do lie! A position-aware mobile fall detection system,Christian Krupitzer; Timo Sztyler; Janick Edinger; Martin Breitbach; Heiner Stuckenschmidt; Christian Becker,Abstract: Ambient Assisted Living using mobile device sensors is an active area of researchin pervasive computing. Multiple approaches have shown that wearable sensors performvery well and distinguish falls reliably from Activities of Daily Living. However; these systemsare tested in a controlled environment and are optimized for a given set of sensor types;sensor positions; and subjects. In this work; we propose a self-adaptive pervasive falldetection approach that is robust to the heterogeneity of real life situations. Therefore; wecombine sensor data of four publicly available datasets; covering about 100 subjects; 5devices; and 3 sensor placements. In a comprehensive evaluation; we show that our systemis not only robust regarding the different dimensions of heterogeneity; but also adaptsautonomously to spontaneous changes in the sensor's position at runtime.,*,2018,*
Rule based temporal inference,Melisachew Wudage Chekol; Heiner Stuckenschmidt,Abstract Time-wise knowledge is relevant in knowledge graphs as the majority facts are truein some time period; for instance;(Barack Obama; president of; USA; 2009; 2017).Consequently; temporal information extraction and temporal scoping of facts in knowledgegraphs have been a focus of recent research. Due to this; a number of temporal knowledgegraphs have become available such as YAGO and Wikidata. In addition; since the temporalfacts are obtained from open text; they can be weighted; ie; the extraction tools assign eachfact with a confidence score indicating how likely that fact is to be true. Temporal factscoupled with confidence scores result in a probabilistic temporal knowledge graph. In such agraph; probabilistic query evaluation (marginal inference) and computing most probableexplanations (MPE inference) are fundamental problems. In addition; in these problems …,OASIcs-OpenAccess Series in Informatics,2018,*
A data-driven newsvendor problem: From data to decision,Jakob Huber; Sebastian Müller; Moritz Fleischmann; Heiner Stuckenschmidt,Abstract Retailers that order perishable items are required to make ordering decisions forhundreds of products on a daily basis. This task is non-trivial because the risk of ordering toomuch or too little is associated with overstocking costs and unsatisfied customers.Traditionally; this problem is solved in a two-step procedure. First; the parameters of a givendemand distribution are estimated; and second; an optimization problem based on thisdistribution is solved to obtain the order quantity. However; in reality; the true demanddistribution is almost never known to the decision maker. Therefore; we present a novelsolution method based on Artificial Neural Networks and Quantile Regression that does notrequire the assumption of a specifc demand distribution. We provide an empirical evaluationof our method with point-of-sales data for a large German bakery chain. We find that our …,*,2017,*
Root cause analysis in IT infrastructures using ontologies and abduction in Markov Logic Networks,Joerg Schoenfisch; Christian Meilicke; Janno von Stülpnagel; Jens Ortmann; Heiner Stuckenschmidt,Abstract Information systems play a crucial role in most of today's business operations. Highavailability and reliability of services and hardware; and; in the case of outages; shortresponse times are essential. Thus; a high amount of tool support and automation in riskmanagement is desirable to decrease downtime. We propose a new approach forcalculating the root cause for an observed failure in an IT infrastructure. Our approach isbased on abduction in Markov Logic Networks. Abduction aims to find an explanation for agiven observation in the light of some background knowledge. In failure diagnosis; theexplanation corresponds to the root cause; the observation to the failure of a component;and the background knowledge to the dependency graph extended by potential risks. Weapply a method to extend a Markov Logic Network in order to conduct abductive …,Information Systems,2017,*
Automated Fine-grained Trust Assessment in Federated Knowledge Bases,Andreas Nolle; Melisachew Wudage Chekol; Christian Meilicke; German Nemirovski; Heiner Stuckenschmidt,Abstract The federation of different data sources gained increasing attention due to thecontinuously growing amount of data. But the more data are available from heterogeneoussources; the higher the risk is of inconsistency. To tackle this challenge in federatedknowledge bases we propose a fully automated approach for computing trust values atdifferent levels of granularity. Gathering both the conflict graph and statistical evidencegenerated by inconsistency detection and resolution; we create a Markov network tofacilitate the application of Gibbs sampling to compute a probability for each conflictingassertion. Based on which; trust values for each integrated data source and its respectivesignature elements are computed. We evaluate our approach on a large distributed datasetfrom the domain of library science.,International Semantic Web Conference,2017,*
Ranking-based evaluation of process model matching,Elena Kuss; Henrik Leopold; Christian Meilicke; Heiner Stuckenschmidt,Abstract Process model matching refers to the automatic detection of semanticallyequivalent or similar activities between two process models. The output of process modelmatchers is the basis for many advanced process model analysis techniques and; therefore;must be as accurate as possible. Measuring the performance of process model matchers;however; is a difficult task. On the one hand; it is hard to define which correspondences areactually correct. On the other hand; it is challenging to appropriately take the output ofmatchers into account; because they often produce confidence values between zero andone. In this paper; we propose the first evaluation procedure for process model matchersthat addresses both of these challenges. The core idea is to rank both the computed and thedesired correspondences based on their confidence values and compare them using the …,OTM Confederated International Conferences" On the Move to Meaningful Internet Systems",2017,*
Automatic assessment of absolute sentence complexity,Sanja Štajner; Simone Paolo Ponzetto; Heiner Stuckenschmidt,Abstract Lexically and syntactically simpler sentences result in shorter reading time andbetter understanding in many people. However; no reliable systems for automaticassessment of sentence complexity have been proposed so far. Instead; the assessment isusually done manually; requiring expert human annotators. To address this problem; we firstdefine the sentence complexity assessment as a five-level classification task; and build a'gold standard'dataset. Next; we propose robust systems for sentence complexityassessment; using a novel set of features based on leveraging lexical properties of freelyavailable corpora; and investigate the impact of the feature type and corpus size on theclassification performance.,Proceedings of the 26th International Joint Conference on Artificial Intelligence,2017,*
T e C o R e: temporal conflict resolution in knowledge graphs,Melisachew W Chekol; Giuseppe Pirro; Joerg Schoenfisch; Heiner Stuckenschmidt,Abstract The management of uncertainty is crucial when harvesting structured content fromunstructured and noisy sources. Knowledge Graphs (kg s); maintaining both numerical andnon-numerical facts supported by an underlying schema; are a prominent example.Knowledge Graph management is challenging because:(i) most of existing kg s focus onstatic data; thus impeding the availability of timewise knowledge;(ii) facts in kg s are usuallyaccompanied by a confidence score; which witnesses how likely it is for them to hold. Wedemonstrate T e C o R e; a system for temporal inference and conflict resolution in uncertaintemporal knowledge graphs (utkg s). At the heart of T e C o R e are two state-of-the-artprobabilistic reasoners that are able to deal with temporal constraints efficiently. While one isscalable; the other can cope with more expressive constraints. The demonstration will …,Proceedings of the VLDB Endowment,2017,*
'Wikiganda': detecting bias in multimodal Wikipedia entries,Hartmut Wessler; Christoph Kilian Theil; Heiner Stuckenschmidt; Angelika Storrer; Marc Debus,Allegations of bias or the lack of neutrality are frequent in political and media realms; butalso in everyday communication. The media portrayal of a particular politician is oftenlabeled unfair or biased when that person or his or her supporters feel that importantinformation has been omitted or the available information has been presented inunfavorable terms or with pejorative connotations. However; such allegations are hard toevaluate in an absolute sense: What is the universe of information that could and shouldhave been included? And what would a perfectly neutral presentation of such informationlook like? For both the selection problem and the presentation problem; explicit standardsare needed; which facilitate a valid judgment on the degree of bias or neutrality found inparticular media offerings. This need is even more pressing when the analysis deals; as it …,New Studies in Multimodality: Conceptual and Methodological Elaborations,2017,*
The Web Data Commons Structured Data Extraction,Anna Primpeli; Robert Meusel; Christian Bizer; Heiner Stuckenschmidt,More and more websites annotate their content using different markup formats. Theseannotations involve a large number of topics such as persons; events; products; hotels;organizations and cities. The purpose of embedding structured data in HTML pages is tomake the content of those pages understandable to web applications. In this way; theretrieval and integration of data deriving from different web pages is greatly facilitated. Thepresented poster gives an overview of the Web Data Commons-structured data project forthe year 2016. The Web Data Commons project extracts structured data from the web corpusprovided by Common Crawl; the largest public web corpus; and offers the extracted data forpublic download. In order to process these huge amounts of data; Web Data Commonsbuilds upon its Extraction Framework and the Amazon Web Services.,*,2017,*
Pervasive and Mobile Computing,Timo Sztyler; Heiner Stuckenschmidt; Wolfgang Petrich,Reliable human activity recognition with wearable devices enables the development ofhuman-centric pervasive applications. We aim to develop a robust wearable-based activityrecognition system for real life situations where the device position is up to the user or wherea user is unable to collect initial training data. Consequently; in this work we focus on theproblem of recognizing the on-body position of the wearable device ensued bycomprehensive experiments concerning subject-specific and cross-subjects activityrecognition approaches that rely on acceleration data. We introduce a device localizationmethod that predicts the on-body position with an F-measure of 89% and a cross-subjectsactivity recognition approach that considers common physical characteristics. In this context;we present a real world data set that has been collected from 15 participants for 8 …,*,2017,*
Sentence alignment methods for improving text simplification systems,Sanja Štajner; Marc Franco-Salvador; Simone Paolo Ponzetto; Paolo Rosso; Heiner Stuckenschmidt,Abstract We provide several methods for sentencealignment of texts with different complexitylevels. Using the best of them; we sentence-align the Newsela corpora; thus providing largetraining materials for automatic text simplification (ATS) systems. We show that using thisdataset; even the standard phrase-based statistical machine translation models for ATS canoutperform the state-of-the-art ATS systems.,Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers),2017,*
Automatic detection of uncertain statements in the financial domain,Christoph Kilian Theil; Sanja Štajner; Heiner Stuckenschmidt; Simone Paolo Ponzetto,*,Lecture notes in computer science,2017,*
Fast ABox Consistency Checking Using Incomplete Reasoning and Caching,Heiner Stuckenschmidt,Abstract. Reasoning with complex ontologies can be a resourceintensive task; which can bean obstacle; eg; for real-time applications. Hence; weakening the constraints of soundnessand/or completeness is often an approach to practical solutions. In this paper; we proposean extension of incomplete reasoning methods for checking the consistency of a largenumber of ABoxes against a given TBox. In particular; we use and extend the clash queriesproposed by Lembo et al.[9] for DL-Lite to compute inconsistent patterns of ABox assertions.By caching instantiations of these patterns; we are able to reduce the amount of reasoningrequired to determine the inconsistency of an ABox with every previously processed ABox.We present experimental results of our approach in terms of runtime and accuracy andcompare it against complete reasoning techniques; the reasoning approach for DL-Lite A …,Rules and Reasoning: International Joint Conference; RuleML+ RR 2017; London; UK; July 12-15; 2017; Proceedings,2017,*
Recognizing grabbing actions from inertial and video sensor data in a warehouse scenario,Alexander Diete; Timo Sztyler; Lydia Weiland; Heiner Stuckenschmidt,Abstract Modern industries are increasingly adapting to smart devices for aiding andimproving their productivity and work flow. This includes logistics in warehouses wherevalidation of correct items per order can be enhanced with mobile devices. Since handlingincorrect orders is a big part of the costs of warehouse maintenance; reducing errors likemissed or wrong items should be avoided. Thus; early identification of picking proceduresand items picked is beneficial for reducing these errors. By using data glasses and asmartwatch we aim to reduce these errors while also enabling the picker to work hands-free.In this paper; we present an analysis of feature sets for classification of grabbing actions inthe order picking process. For this purpose; we created a dataset containing inertial dataand egocentric video from four participants performing picking tasks; modeled closely to a …,Procedia computer science,2017,*
An infrastructure for probabilistic reasoning with web ontologies,Jakob Huber; Mathias Niepert; Jan Noessner; Joerg Schoenfisch; Christian Meilicke; Heiner Stuckenschmidt,Abstract We present an infrastructure for probabilistic reasoning with ontologies based onour Markov logic engine RockIt. Markov logic is a template language that combines first-order logic with log-linear graphical models. We show how to translate OWL-EL as well asRDF schema to Markov logic and how to use RockIt for applying MAP inference on the givenset of formulas. The resulting system is an infrastructure for log linear logics that can be usedfor probabilistic reasoning with both extended OWL-EL and RDF schema. We describe oursystem and illustrate its benefits by presenting experimental results for two types ofapplications. These are ontology matching and knowledge base verification; with a specialfocus on temporal reasoning. Moreover; we illustrate two further use cases which are ActivityRecognition and Root Cause Analysis. Our infrastructure has been applied to these use …,Semantic web,2017,*
Detecting meaningful compounds in complex class labels,Heiner Stuckenschmidt; Simone Paolo Ponzetto; Christian Meilicke,Abstract Real-world ontologies such as; for instance; those for the medical domain oftenrepresent highly specific; fine-grained concepts using complex labels that consist of asequence of sublabels. In this paper; we investigate the problem of automatically detectingmeaningful compounds in such complex class labels to support methods that require anautomatic understanding of their meaning such as; for example; ontology matching; ontologylearning and semantic search. We formulate compound identification as a supervisedlearning task and investigate a variety of heterogeneous features; including statistical (ie;knowledge-lean) as well as knowledge-based; for the task at hand. Our classifiers aretrained and evaluated using a manually annotated dataset consisting of about 300 complexlabels taken from real-world ontologies; which we designed to provide a benchmarking …,European Knowledge Acquisition Workshop,2016,*
Group Decision Making via Probabilistic Belief Merging,Heiner Stuckenschmidt,Group decision making [4; 5; 8; 9; 11; 14] addresses the problem of finding a reasonabledecision when multiple decision makers have different preferences. In this extendedabstract; we give a high-level description of the key ideas from [20]. We explain howprobabilistic belief merging can be applied to solve Group decision problems when thepreferences can be derived from agents' individual utilities and beliefs. Subsequently; wediscuss some guarantees that our approach can give regarding the relationship between theindividual preferences and the derived group preferences. Some group decisionapproaches consider dynamic aspects like communication between agents [16; 23]. Ourgroup-decision approach is static; similar to social-choice approaches that take individualpreferences for granted and apply voting rules to make a group decision from the …,KI 2016: Advances in Artificial Intelligence: 39th Annual German Conference on AI; Klagenfurt; Austria; September 26-30; 2016; Proceedings,2016,*
Interview with Prof. Dr. Rudi Studer; Professor at the Institute of Applied Informatics and Formal Description Methods (AIFB) at KIT,Heiner Stuckenschmidt,*,*,2016,*
Interview mit Prof. Dr. Rudi Studer; Professor am Institut für Angewandte Informatik und Formale Beschreibungsverfahren (AIFB) des KIT,Heiner Stuckenschmidt,KI: Hallo Rudi; vielen Dank; dass Du dir die Zeit genommen hast; uns ein Interview für die KIZeitung zu geben. Uns war es wichtig; Kollegen zu Wort kommen zu lassen; die von Anfangan die Entwicklung des Semantic Webs aktiv begleitet haben. Eine der ersten Dinge; die ichmit dem Thema verbinde sind eure Arbeiten über den Ontobroker. Das ist jetzt schon mehrals 15 Jahre her. Wie kam es eigentlich dazu; dass ihr euch mit dem Thema beschfätigthabt?,KI-Künstliche Intelligenz,2016,*
Special Issue on Semantic Web,Birte Glimm; Heiner Stuckenschmidt,Fifteen years ago Tim Berners-Lee; James Hendler; and Ora Lassila formulated the idea of aSemantic Web that extends the standard Web by giving information well-defined andcomputer-processable meaning with the goal of enabling computers and people to work incooperation. Since then; this idea led to many developments. For example; thecrowedsourced community effort DBpedia makes a large part of the free encyclopediaWikipedia available in a structured and machine processable format. The English version ofDBpedia alone describes 4.58 million things (1;445;000 persons; 735;000 places; 411;000creative works; 241;000 organizations; 251;000 species; and 6;000 diseases) and 125localized versions are further available. The developments are; however; not limited to thearea of the (Semantic) Web itself. For example; the Systematized Nomenclature of …,*,2016,*
Semantic Web,Birte Glimm; Heiner Stuckenschmidt,*,*,2016,*
Automatic detection of speculation in policy statements,Sanja Štajner; Nicole Baerg; Simone Paolo Ponzetto; Heiner Stuckenschmidt,ABSTRACT In this paper; we present the first study of automatic detection of speculativesentences in official monetary policy statements. We build two expert-annotated datasets.The first contains the transcripts of monetary policy meetings on the US central bank'smonetary policy committee (Debates). The second contains the official monetary policystatements (Decisions). We use the first part of the Debates dataset to build dictionaries withlexical triggers for speculative and non-speculative sentences. We then test theirperformance on an in-domain test set (the second part of the same dataset) and on an out-of-domain test set (the Decisions dataset) using several rule-based and machine learningclassifiers. Our best classifiers achieve an accuracy of 82.5%(0.70 F-score on thespeculative class); comparable with automatic detection of speculative sentences in …,*,2016,*
Uncertain Temporal Knowledge Graphs.,Melisachew Wudage Chekol; Heiner Stuckenschmidt,Abstract. Temporal data can be found in various sources from patient histories; purchasehistories; employee histories; to web logs. Recent advances in open information extractionhave paved the way for automatic construction of knowledge graphs (kgs) from suchsources. Often the extraction tools used to construct kgs produce facts and rules along withtheir confidence scores; leading to the notion of uncertain temporal kgs. The facts and rulescontained in these graphs tend to be noisy and erroneous due to either the accuracy of theextraction tools or uncertainty in the source data. In this work; we use a numerical extensionof Markov logic networks to provide formal syntax and semantics for uncertain temporal kgs.Moreover; we propose a set of datalog constraints with inequalities; that extend theunderlying schema of the kgs and help in resolving conflicting facts. Finally; we …,URSW@ ISWC,2016,*
Probabilistic EL with Nominals and Concrete Domains,Melisachew Wudage Chekol; Jakob Huber; Christian Meilicke; Heiner Stuckenschmidt,Abstract We present MEL++(M denotes Markov logic networks) an extension of the log-linear description logics EL++-LL with concrete domains; nominals; and instances. We useMarkov logic networks (MLNs) in order to find the most probable; classified and coherentEL++ ontology from an MEL++ knowledge base. In particular; we develop a novel way todeal with concrete domains by extending MLN's cutting plane inference (CPI) algorithm.,WL4AI-2015,2015,*
Towards log-linear logics with concrete domains,Melisachew Wudage Chekol; Jakob Huber; Heiner Stuckenschmidt,Abstract: We present $\mathcal {MEL}^{++} $(M denotes Markov logic networks) anextension of the log-linear description logics $\mathcal {EL}^{++} $-LL with concretedomains; nominals; and instances. We use Markov logic networks (MLNs) in order to find themost probable; classified and coherent $\mathcal {EL}^{++} $ ontology from an $\mathcal{MEL}^{++} $ knowledge base. In particular; we develop a novel way to deal with concretedomains (also known as datatypes) by extending MLN's cutting plane inference (CPI)algorithm.,arXiv preprint arXiv:1507.02456,2015,*
Probabilistic EL++ with nominals and concrete domains,Melisachew Wudage Chekol; Jakob Huber; Christian Meilicke; Heiner Stuckenschmidt,Page 1. Probabilistic EL++ with Nominals and Concrete Domains Melisachew W. Chekol Dataand Web Science Group Universit ¨at Mannheim (joint work with Jakob Huber; Christian Meilickeand Heiner Stuckenschmidt ) WL4AI 2015 Page 2. Introduction Description Logics are decidablefragments of FOL used in knowledge representation and reasoning. EL++ ◦ maximum tractablefragment of OWL ◦ classification/reasoning in PTime Concrete domain is a construct that canbe used to define new classes with values from a fixed domain such as integers. For instance;Teenager ⊑ ≥13(age) 2 / 19 Page 3. Related Work Probabilistic description logics fall into 3categories based on the inference technique: Markov logic networks (MLN) ◦ EL++ withprobabilistic uncertainty based on the annotation of axioms [Lukasiewicz et al.; 2012] ◦ log-linearEL++ [Niepert et al.; 2011] ←− this work Bayesian networks …,*,2015,*
Automatic classification of iconic images based on a multimodal model: an interdisciplinary project,Simone Paolo Ponzetto; Hartmut Wessler; Lydia Weiland; Stephan Kopf; Wolfgang Effelsberg; Heiner Stuckenschmidt,The term “iconic image” refers here to images produced to create privileged associationsbetween a particular visual representation and a referent. They are highly recognizable formedia users and typically induce negative or positive emotions that have an impact onviewers' attitudes and actions. In our work we focus on iconic images in the topical area ofclimate change. Previous research (see; for example; ONeill & Nocholson-Cole; 2009) hasidentified recurring iconic representations such as the polar bear on a drifting ice floe (for theproblem) or wind turbines in an untouched landscape surrounded by a clear sky (forpossible solutions). In this paper we present first results of an interdisciplinary endeavorinvolving media and communication researchers and computer scientists specializing in textand image analysis. We aim at producing a model that computationally captures the …,Sprache-Medien-Innovationen,2015,*
A fast Markov Logic solver,Jan Noessner; Heiner Stuckenschmidt,*,*,2014,*
A Gold Standard of Meaningful Compounds in Complex Class Labels,Heiner Stuckenschmidt; Simone Paolo Ponzetto; Christian Meilicke,The dataset comprises the Gold Standard created for evaluating the experiments conductedfor the Paper" Detecting Meaningful Compounds in Complex Class Labels"; which has beensubmitted to ESWC 2014. Addditional experimental results and further information areavailable here: https://madata. bib. uni-mannheim. de/67/.,*,2014,*
Temporal Reasoning for RDF (S): A Markov Logic based Approach,Jakob Huber,Abstract: In this work; we propose a formalism that is suitable to carry out temporal reasoningfor probabilistic knowledge bases. In particular; we focus on detecting erroneous statementsby exploiting temporal relations of facts. Therefore; we rely on RDF (S) and its associatingentailment rules which provide a data representation model as well as a basic logicalexpressiveness. Moreover; we use Allen 19s interval algebra to express the relations of factsbased on their associated temporal information. We carry out reasoning by transforming thestatements and constraints to Markov Logic and compute the most probable consistent state(MAP inference) with respect to the defined constraints. Moreover; we evaluate the proposedapproach in order to demonstrate its practicality and flexibility.,*,2014,*
Estimating Central Bank Preferences,Nicole Rae Berg; Will Lowe; Simone Paolo Ponzetto; Heiner Stuckenschmidt; Cäcilia Zirn,Abstract Scholars often use Federal Open Market Committee (FOMC) votes to estimate thepreferences of central bankers. However; rarely do people cast dissenting votes. As a result;voting records are not a random sample and using votes to measure preferences may causemisleading measures and wrong substantive conclusions. Instead of using voting records;this article demonstrates the usefulness of using what central bankers say in FOMCmeetings as a way to better measure central bank preferences. Putting together automatedtext analysis tools and scaling methods; we estimate a new measure of central bankpreferences on the FOMC leading up to the financial crisis. The financial crisis has drawnincreasing attention to the power of central bankers. More than ever before; the things thatcentral bankers do and the things that central bankers say have a profound and …,*,2014,*
On a steady path to semantic technology evaluation,Raúl Garcia-Castro; Stuart N Wrigley; Jeff Heflin; Heiner Stuckenschmidt,Keywords data integration description logic description logics editorial information retrievalknowledge representation linked data machine learning ontologies ontology ontologyalignment ontology learning ontology mapping owl provenance rdf semantic search sparqlweb 2.0 web of data web services,Web Semantics: Science; Services and Agents on the World Wide Web,2013,*
Iterative implementation of services for the automatic evaluation of matching tools (v2),José Luis Aguirre; Christian Meilicke; Jérôme Euzenat,This deliverable reports on the current status of the service implementa-tion for the automaticevaluation of matching tools; and on the final sta-tus of those services. These services havebeen used in the third SEALS evaluation of matching systems; held in Spring 2012 incoordination with the OAEI 2011.5 campaign. We worked mainly on the tasks of modifyingthe WP12 BPEL work-flow to introduce new features introduced in the RES 1.2 version;testing the modified work-flows on a local installation and on the SEALS Platform; writingtransformations of result data to be compliant with the new SEALS ontologies specifications;and finally; extending the SEALS client for ontology matching evaluation for bettersupporting the automation of WP12 evaluation campaigns and to ad-vance in the integrationwith SEALS repositories. We report the results obtained while accomplishing these tasks.,*,2012,*
Proceedings 18th International Conference Knowledge Engineering and Knowledge Management;; EKAW 2012,ACM ten Teije; J Volker; S Handschuh; H Stuckenschmidt; M d'Acquin; A Nikolov; N Aussenac-Gilles; N Hernandez,KNAW Narcis. Back to search results. Publication Proceedings 18th International ConferenceKnowledge Engineering and... (2012). Pagina-navigatie: Main …,LNAI,2012,*
Linked Data is becoming the core part of modern Web applications and thus efficient access to structured information expressed in RDF gains paramount importanc...,Jeff Heflin; Heiner Stuckenschmidt; Renaud Delbru; Stephane Campinas; Giovanni Tummarello,More and more (semi) structured information is becoming available on the web in the form ofdocuments embedding metadata (eg; RDF; RDFa; Microformats and others). There arealready hundreds of millions of such documents accessible and their number is growingrapidly. This calls for large scale systems providing effective means of searching andretrieving this semi-structured information with the...,Web Semantics: Science; Services and Agents on the World Wide Web,2012,*
Proc. 7th ISWC workshop on ontology matching (OM),Pavel Shvaiko; Jérôme Euzenat; Anastasios Kementsietsidis; Ming Mao; Natalya Noy; Heiner Stuckenschmidt,No abstract available.,*,2012,*
Special Issue" Scalability",Jeff Heflin; Heiner Stuckenschmidt,From the earliest days of semantic web research; the problem of semantically processinginformation at very large scale has cast a shadow over its many successes. Having the Webas a primary use case has been both a blessing and a curse. While targeting the Web hasattracted a lot of attention and has significantly improved the awareness for the benefits ofsemantic data models and automatic reasoning; the field still has to prove that semantics willwork on web scale. During the first years; semantic web research was dominated by on theconsideration of rich semantic representations in the tradition of symbolic AI. Significantprogress was achieved with respect to integrating knowledge representation and reasoningwith mainstream web infrastructure leading to key standards such as OWL; RDF andSPARQL; however; processing enormous quantities of the corresponding data is still one …,Web Semantics: Science; Services and Agents on the World Wide Web,2012,*
A Little Logic Goes a Long Way–Logical Reasoning in Web Data Integration and Ontology Learning,Heiner Stuckenschmidt,There is an ongoing dispute in the Semantic Web Community about the usefulness of(Description) Logic as a basis for describing data on the web. While researchers in logicargue with the benefits of logic in terms of a clean semantics and richness of the language;criticism against the use of logic normally focusses on two points: its computationalcomplexity and its inability to represent soft constraints. In this talk; we will address thesecriticisms and argue that if used in the right way description logics are a valuable tool fortypical tasks on the semantic web. We use problem of semantic matchmaking as an exampleto show that the use of rather inexpressive logics with good computational propertiesalready provide significant benefits by eliminating incoherent matches. In the second part ofthe talk we address the problem of dealing with soft constraints and show two solutions to …,24th International Workshop on Description Logics,2011,*
Evaluation design and collection of test data for matching tools (v2),Christian Meilicke; Cássia Trojahn dos Santos; Heiner Stuckenschmidt; Maria Rosoiu,Based on the results of the first evaluation campaign (T12. 3); and taking into account thetechnical progress of the SEALS platform; we deliver an updated and extended evaluationand test data design for our second evaluation campaign. This campaign is planned to takeplace in the context of the OAEI at the ISWC 2011.,*,2011,*
Iterative implementation of services for the automatic evaluation of matching tools,Cássia Trojahn dos Santos; Christian Meilicke; Jérôme Euzenat,The implementation of the automatic services for evaluating matching tools follows aniterative model. The aim is to provide a way for continuously analysing and improving theseservices. In this deliverable; we report the first iteration of this process; ie; currentimplementation status of the services. In this first iteration; we have extended our previousimplementation in order to migrate our own services to the SEALS components; which havebeen finished since the end of the first evaluation campaign.,*,2011,*
Results of the Ontology Alignment Evaluation Initiative 2011 (Final),Jérôme Euzenat; Alfio Ferrara; Willem Robert van Hage; Laura Hollink; Christian Meilicke; Andriy Nikolov; Francois Scharffe; Pavel Shvaiko; Heiner Stuckenschmidt; Ondrej Svab-Zamazal; Cássia Trojahn,Abstract. Ontology matching consists of finding correspondences between semanticallyrelated entities of two ontologies. OAEI campaigns aim at comparing ontology matchingsystems on precisely defined test cases. These test cases can use ontologies of differentnature (from simple directories to expressive OWL ontologies) and use different modalities;eg; blind evaluation; open evaluation; consensus. OAEI-2011 builds over previouscampaigns by having 4 tracks with 6 test cases followed by 18 participants. Since 2010; thecampaign has been using a new evaluation modality which provides more automation to theevaluation. In particular; this year it allowed to compare run time across systems. This paperis an overall presentation of the OAEI 2011 campaign.,CEUR workshop proceedings,2011,*
A Little Logic Goes A Long Way,Heiner Stuckenschmidt,*,CEUR workshop proceedings,2011,*
Repräsentation von Bedeutung,Heiner Stuckenschmidt,Zusammenfassung Die im vorangegangenen Kapitel vorgestellten Methoden aus derPhilosophie und der Linguistik zur Erfassung von Semantik zielten primär darauf ab;Prinzipien zu verstehen. Ihr Ansatz war demnach eher analytisch. In derInformationsverarbeitung ist das Ziel ein anderes. Hier geht es nicht in erster Linie um dasVerstehen von Prinzipien; sondern vielmehr um deren Anwendung; um ein gegebenesProblem zu lösen. Dieser eher konstruktive Ansatz bedingt eine formalere Erfassung vonBedeutung als bisher. Insbesondere ist es notwendig; die im letzten Abschnitt diskutiertenPrinzipien derart formal abzubilden; dass eine zumindest teilweise Automatisierung dersemantischen Analyse möglich wird. Die Entwicklung solcher Formalismen ist Inhalt desTeilgebietes der Künstlichen Intelligenz; welches als Wissensrepräsentation bezeichnet …,*,2011,*
Symbole; Objekte und Konzepte,Heiner Stuckenschmidt,Zusammenfassung Um die potenzielle Bedeutung von Ontologien in derInformationsverarbeitung zu verstehen; muss man sich klarmachen; was die grundlegendenAufgaben und Probleme der Informationsverarbeitung sind: nämlich bestimmte Ausschnitteder realen Welt in eine geeignete Darstellungsform zu überführen; die mit Hilfe desComputers manipuliert werden kann; um mit dieser Veränderungen in der realen Weltabzubilden. Dies können wir am Beispiel des Electronic Banking genauer betrachten. EinSystem in diesem Bereich muss bestimmte Objekte der Welt–Personen; Organisationen;Konten; Aktien; Geldbeträge usw.–abbilden. Diese Objekte können physikalische Objektesein; wie etwa Personen; oder aber abstrakte Objekte; wie Konten. Häufig ist hierbei derÜbergang zwischen konkreten und abstrakten Objekten fließend. Eine Aktie zum Beispiel …,*,2011,*
Approximate Matching of Semantic Web Services,Jörg Schönfisch; Heiner Stuckenschmidt,*,*,2010,*
Web-based RDF Graph Visualisation using SVG,Nikolas Schmitt; Heiner Stuckenschmidt,*,*,2010,*
D12. 2 Services for the automatic evaluation of matching tools v1,Heiner Stuckenschmidt,Executive Summary In this deliverable; we describe a SEALS evaluation service that isbased on the use of a web service interface wrapping the functionality of a tool to beevaluated. This interface allows to evaluate the tool without the need for a runtimeenvironment. Contrary to this; the tool will be executed on the machine of the tool developer;while the evaluation takes place within the SEALS infrastructure. We refer to the proposedapproach as a lightweight evaluation service; because the approach neither requires aRuntime Evaluation Service nor the powerful hardware infrastructure underlying this service.We firstly discuss pros and cons of offering a lightweight evaluation service (§ 1). At themoment of writing this deliverable many required components for setting up a first prototypeof an evaluation service are-due to the underlying complexity-still under development. For …,*,2010,*
The Semantic Web: Research and Applications 7th Extended Semantic Web Conference; ESWC 2010 Proceedings,LM Aroyo; G Antoniou; E Hyvonen; ACM ten Teije; H Stuckenschmidt,KNAW Narcis. Back to search results. Publication The Semantic Web: Research andApplications 7th Extended Semantic Web... (2010). Pagina-navigatie: Main …,Lecture Notes in Computer Science,2010,*
Evaluation design and collection of test data for matching tools,Cássia Trojahn dos Santos; Jérôme Euzenat; Christian Meilicke; Heiner Stuckenschmidt,This deliverable presents a systematic procedure for evaluating ontology matching systemsand algorithms; in the context of SEALS project. It describes the criteria and metrics on whichthe evaluations will be carried out and the characteristics of the test data to be used; as wellas the evaluation target; which includes the systems generating the alignments forevaluation.,*,2009,*
Domain (Internet),Heiner Stuckenschmidt,*,*,2009,*
Modular Ontologies,Stefano Spaccapietra; Christine Parent; Heiner Stuckenschmidt,*,*,2009,*
Informationssuche,Heiner Stuckenschmidt,Neben strukturierten Daten; zum Beispiel aus Datenbanken wie sie im Kapitel überDatenintegration behandelt wurden; gewinnen unstrukturierte Dokumente zunehmend anBedeutung als Informationsquelle. Dies hat vor allem zwei Ursachen. Zum einen stehen inForm des World Wide Webs inzwischen riesige Mengen an Dokumenten zu fast jedemdenkbaren Thema zur Verfügung; zum anderen stehen Angebote klassischer Bibliothekenzunehmend auch in elektronischer Form zur Verfügung und sind so für eine breite Massepotenzieller Nutzer zugänglich; die nun aus dem Angebot vieler verschiedener Bibliothekenwählen können.,*,2009,*
Datenintegration,Heiner Stuckenschmidt,Eine der wichtigsten Anwendungen von Ontologien in der modernenInformationsverarbeitung ist die semantische Datenintegration. Die Integration von Datenaus heterogenen Quellen zum Zweck einer gemeinsamen Nutzung ist eines der zentralenProbleme der Informationsverarbeitung und tritt in der Praxis in unterschiedlichsten Formenund zusammenhängen auf. Hierbei treten in der Regel Probleme auf unterschiedlichenEbenen auf; welche die Nutzung beeinträchtigen. In der Regel unterschiedet man zwischenden folgenden Arten von Problemen; die bei der Integration auftreten können:,*,2009,*
Ontologiesprachen,Heiner Stuckenschmidt,Die wahrscheinlich bedeutendste Entwicklung in Bezug auf Ontologien und derenPopularität ist weniger ein grundlegender Technologischer oder theoretischer Fortschritt imBereich der Formalisierung von Wissen; sondern eher eine organisatorische Veränderung.Ontologien; wie die im ersten Teil dieses Buches gezeigten in der Tradition derphilosophischen Ontologie; wurden in der Regel als normative Modelle einer bestimmtenDomäne gesehen. Die Tatsache; dass es unterschiedliche Ontologien gibt-im Bereichallgemeiner Ontologien sind dies neben SUMO-Ontologien wie DOLCE oder Cyc-wurdeeher als Unfall betrachtet und es wurden hitzige Diskussionen darüber geführt; welcheOntologie die Realität am korrektesten widerspiegelt.,*,2009,*
Zusammenfassung und Literatur,Heiner Stuckenschmidt,In diesem Buch haben wir uns mit Konzepten; Technologien und Anwendungen vonOntologien in der Informationsverarbeitung beschäftigt. Ziel war es hierbei nicht; den Standder Technik in diesem Bereich umfassend darzustellen; sondern einen Einstieg in diesesspannende und komplexe Thema zu bieten. Wir haben uns hierzu dem Thema Ontologienaus drei unterschiedlichen Richtungen genähert. Im ersten Teil des Buches haben wir unsaus der Sicht des Wissenschaftlers mit den grundlegenden Konzepten und Ideen derVerwendung von Ontologien in der modernen Informationsverarbeitung beschäftigt.,*,2009,*
Towards a Logic− based Assessment of the compatibility of UMLS sources,Ernesto Jimenez Ruiz; Bernardo Cuenca Grau; Ian Horrocks; Rafael Berlanga,*,Proceedings of the International Workshop on Semantic Web Applications and Tools for Life Sciences (SWAT4LS 2009),2009,*
Spatial Reasoning for the Semantic Web-Use Cases and Technological Challenges,Heiner Stuckenschmidt,Abstract The goal of semantic web research is to turn the World-Wide Web into a Web ofData that can be processed automatically to a much larger extend than possible withtraditional web technology. Important features of the solution currently being developed isthe ability to link data from from different sources and to provide formal definitions of theintended meaning of the terminology used in different sources as a basis for deriving implicitinformation and for conflict detection. Both requires the ability to reason about the definitionof terms. With the development of OWL as the standard language for representingterminological knowledge; reasoning in description logics has been determined as themajor technique for performing this reasoning cite {OWLreasoning}. More recently; rulelanguages have gained more importance as well as they have been shown to be more …,Dagstuhl Seminar Proceedings,2009,*
Cartographic and semantic aspects on web services,Lars Harrie; Heiner Stuckenschmidt,Abstract Several countries are currently working on setting up geoportals as part of theirnational spatial data infrastructure (SDI)(and this is also a requirement of the Inspireinitiative). A key ability of these geoportals is that the user should be able to view (anddownload) data from several sources from one access point. This will certainly make theaccess to geospatial data easier. However; there are also cartographic and semanticchallenges that have to be solved. In this discussion group we discussed some topicsconcerning both download services and view services and some possible solutions.,Dagstuhl Seminar Proceedings,2009,*
Proc. 3rd ISWC international workshop on ontology matching (OM),Pavel Shvaiko; Jérôme Euzenat; Fausto Giunchiglia; Heiner Stuckenschmidt,No abstract available.,*,2008,*
The 7th International Semantic Web Conference,Pavel Shvaiko; Jérôme Euzenat; Fausto Giunchiglia; Heiner Stuckenschmidt,Ontology matching is a key interoperability enabler for the semantic web; since it takes theontologies as input and determines as output an alignment; that is; a set of correspondencesbetween the semantically related entities of those ontologies. These correspondences canbe used for various tasks; such as ontology merging; query answering; data translation; orfor navigation on the semantic web. Thus; matching ontologies allows the knowledge anddata expressed in the matched ontologies to interoperate.,*,2008,*
Representing ontology mappings with probabilistic description logics programs,Andrea Calì; Thomas Lukasiewicz; Livia Predoiu; Heiner Stuckenschmidt,The problem of aligning heterogeneous ontologies via semantic mappings has beenidentified as one of the major challenges of semantic web technologies. In order to addressthis problem; a number of languages for representing semantic relations between elementsin different ontologies as a basis for reasoning and query answering across multipleontologies have been proposed [28]. In the presence of real world ontologies; it is unrealisticto assume that mappings between ontologies are created manually by domain experts; dueto the large size of existing ontologies. Recently; a number of heuristic methods; relying onlinguistic and structural criteria; for matching elements from different ontologies have beenproposed that support the creation of mappings between different languages by suggestingcandidate mappings (eg;[11]). Such methods often trade off precision and recall; as …,Proceedings of the 16th Italian Symposium on Advanced Database Systems ‚SEBD 2008 ‚Mondello ‚Italy ‚June 22− 25 ‚2008,2008,*
D2. 3.9 Theoretical Aspects for Ontology Lifecycle,Zhisheng Huang; Alessandro Artale; Norman Foo; Enrico Franconi; Tommie Meyer10; Mathieu d’Aquin11; Jean Lieber; Amedeo Napoli; Giorgos Flouris; Jeff Z Pan; Dimitris Plexousakis; Holger Wache; Heiner Stuckenschmidt; Siegfried Handschuh,Abstract. Deliverable D2. 3.9 (WP2. 3) presents a study on theoretical aspects of ontologylifecycle and dynamic maintenance. Several crucial topics are analysed; ranging fromlogical groundwork of ontology dynamics based on belief-change theory; through semanticsof ontology diffs; to multiversion reasoning. Building on the theoretical studies; basicpractical guidelines and combined approach to multi-version ontology reasoning arediscussed in the report; too. This is meant to provide a tangible binding between the theoryand interests of practitioners.,*,2007,*
Report on Realizing Practical Approximate and Distributed Reasoning for Ontologies,Pascal Hitzler; Peter Dolog; Perry Groot; Michel Klein; Malgorzata Mochol; Lyndon Nixon; Linda Peelen; Sebastian Rudolph; Stefan Schlobach; Heiner Stuckenschmidt; Denny Vrandecic; Holger Wache,Abstract We report on the progress we have made in KnowledgeWeb on the topic ofscalable ontology reasoning. This deliverable contains contributions which advance thestate of the art on a broad front; covering query approximation; ABox reasoning and TBoxreasoning. It also covers approximation for uncertainty handling and for multi-perspectivereasoning.,*,2007,*
Ontologies and their Applications J. UCS Special Issue,Heiner Stuckenschmidt; Andréia Malucelli; H Sofia Pinto,After pursuing a long tradition of study in Philosophy; the term “ontology” has become thenew buzzword in computer science. It is receiving special attention not only from an activecommunity of researchers pertaining to many areas of informatics but also from the industry;which is providing increasing budgets and investments to develop this technology and makeit available in business as soon as possible. There is at least one main reason for thisrecognition: ontologies constitute the backbone of the Semantic Web; as they areresponsible for providing context to pages; thus promising to make a relevant part of theWeb contents understandable and processable by the software. However; there are somechallenging obstacles that should be tackled to make ontologies wide-spread reputationshift from a promise to a daily used technology. For instance; heterogeneity and …,Journal of Universal Computer Science,2007,*
Proc. 1st ISWC 2006 international workshop on ontology matching (OM),Pavel Shvaiko; Jérôme Euzenat; Natalya Noy; Heiner Stuckenschmidt; Richard Benjamins; Michael Uschold,No abstract available.,*,2006,*
D2. 1.2. 2. v1 Report on realizing practical approximate and distributed reasoning for ontologies,Stefania Ghita-Costache; Peter Dolog; Pascal Hitzler; Luciano Serafini; Wolf Siberski; Heiner Stuckenschmidt; Andrei Tamilin; Denny Vrandecic; Holger Wache,Abstract. EU-IST Network of Excellence (NoE) IST-2004-507482 KWEB Deliverable D2. 1.2.2. v1 (WP2. 1) This document reports on practical applications of approximate reasoning;mainly based on A-Box techniques or cooperative query processing. It also shows examplesand implementations of distributed reasoning systems for ontologies; as distributed instanceretrieval or a mix of ontology querying and information retrieval methods.,*,2006,*
WONTO'2006: Proceedings of the Workshop on 2nd Workshop on Ontologies and their Applications co-located with the International Joint Conference IBERAMIA-S...,Fred Freitas; Heiner Stuckenschmidt; Sophia Pinto; Andrea Malucelli,*,*,2006,*
Proceedings of the 1st International Workshop on Ontology Matching (OM-2006) Collocated with the 5th International Semantic Web Conference (ISWC-2006); Athe...,Pavel Svaiko; Jérôme Euzenat; Natalya F Noy; Heiner Stuckenschmidt; V Richard Benjamins; Mike Uschold,*,CEUR workshop proceedings,2006,*
Proceedings of the 2nd Workshop on Ontologies and Applications,Fred Freitas; Heiner Stuckenschmidt; Sophia Pinto; Andrea Malucelli,*,CEUR Workshop Proceedings; 199,2006,*
Semantic-Web-Technologien zur Unterstützung des Zugriffs auf medizinischen Informationen,Heiner Stuckenschmidt; Christian Herzog,Abstract Viele Bereiche der Medizin; insbesondere die Medizinische Forschung undMedikamentenentwicklung benoetigen effektiven Zugriff auf eine Vielzahl von Informationenin Form von Artikeln; Patenten und chemischen Zusammenhängen. Traditionelle Schlagwort-basierte Suchmaschinen stossen hier schnell an Ihre Grenzen. Eine Alternative bietenOntologie-basierte Verfahren zur automatischen Indizierung sowie zur Suche undNavigation in grossen Informationsbeständen. Im Vortrag werden Erfahrungen mit derEntwicklung eines Ontologie-basierten Recherchesystems fuer medizinische Informationengeschildert und weiterführende Möglichkeiten der Technologie diskutiert.,*,2006,*
Generating Reference Mappings for Evaluating Ontology Matching Tools,M Yatskevich; P Avesani; H Stuckenschmidt; E Van Mulligen,Ontology Alignment is one of the biggest challenges of semantic web research. Recentlythere has been some attention on automatic alignment methods and number of matchingtools have been developed. One of the open problem of automatic matching currently is theevaluation of the quality of automatically generated mappings. Normally; referencemappings are used to compute the precision and recall of automatically created mappings.Often; however; such reference mappings do not exist and creating them by hand is notfeasible for large ontologies. In this paper; we extend previous work on overcoming thisproblem by proposing a method for automatically generating highly correct referencemappings. In particular; we consider the case where we do not have shared instances forthe ontologies to be aligned and report the results of an experiment in which we used …,*,2006,*
Das Semantische Web-Fakten und Fiktionen,Heiner Stuckenschmidt,*,Log in,2006,*
Ontologies; Databases and Applications of Semantics (ODBASE) 2006 International Conference-Ontology Mappings-Formalism-Independent Specification of Ontolo...,Saartje Haase; Peter Brockmans; Heiner Stuckenschmidt,*,Lecture Notes in Computer Science,2006,*
Description of alignment implementation and benchmarking results,Heiner Stuckenschmidt; Marc Ehrig; Jérôme Euzenat; Andreas Hess; Willem Robert Van Hage; Wei Hu; Ningsheng Jian; Gong Chen; Yuzhong Qu; George Stoilos; Giorgos Stamou; Umberto Straccia; Vojtech Svátek; Raphaël Troncy; Petko Valtchev; Mikalai Yatskevich,HAL is a multi-disciplinary open access archive for the deposit and dissemination of sci- entificresearch documents; whether they are pub- lished or not. The documents may come from teachingand research institutions in France or abroad; or from public or private research centers …L'archive ouverte pluridisciplinaire HAL; est destinée au dépôt et `a la diffusion de documentsscientifiques de niveau recherche; publiés ou non; émanant des établissements d'enseignementet de recherche français ou étrangers; des laboratoires publics ou privés … Coordinator: HeinerStuckenschmidt (University of Mannheim) Marc Ehrig (Universität Karlruhe); Jérôme Euzenat(INRIA Rhône-Alpes) Andreas Hess; Willem Robert van Hage (Vrije Universiteit Amsterdam)Wei Hu; Ningsheng Jian; Gong Cheng and Yuzhong Qu (Southeast University China) GeorgeStoilos; George Stamou (ITI-Certh) Umberto Straccia (ISTI-CNR) Vojtech Svatek …,*,2005,*
Overview: Data Storage and Access,Heiner Stuckenschmidt,As discussed in the introduction; technologies for storing and accessing data is the basicaspect of semantics-based P2P systems. While data access is often limited to key-based orkeyword based queries in traditional P2P solutions; a distinguishing feature of the kind ofsystems discussed in this book is that they provide more sophisticated ways of storing andaccessing data. These are based on the use of Semantic Web technologies in terms oflanguages for representing and querying semistructured data. The focus of this book is onthe use of RDF for data storage and access. It is quite obvious that there are two sides to theuse of RDF: the RDF model itself and its use for representing and storing complexinformation content; and the provision of a language for querying and transforming RDFdata. The RDF model itself has been standardized by the W3C and is now a commonly …,Semantic Web and Peer-to-Peer,2005,*
Overview: Semantic Integration,Heiner Stuckenschmidt,The problem of heterogeneity is well known in the area of databases and informationsystems. Different systems tend to represent the same information in different ways usingdifferent syntactic and conceptual structures and often also using different terminologies ordifferent interpretations of the same terminology. This problem; of course; also appears inP2P systems where a potentially large number of independent peers provide and requestinformation about a certain domain. Dealing with heterogeneity in a P2P setting is muchharder than in more centralized systems. The lack of a central control element leads to theproblem that a peer will often not even know if other peers in the system use the same or adifferent way of modelling information because only the direct system neighborhood isknown to him. This means that semantic mismatches will often only be discovered during …,Semantic Web and Peer-to-Peer,2005,*
Integrating Ontologies K-Cap 2005,Benjamin Ashpole; Marc Ehrig; Jérôme Euzenat; Heiner Stuckenschmidt,Page 1. Integrating Ontologies K-Cap 2005 October 2; 2005 Banff; Canada Benjamin Ashpole;Marc Ehrig; Jérôme Euzenat; Heiner Stuckenschmidt Page 2. ∎ Research Presentations ∎Ontology Alignment Evaluation Initiative Page 3. Topics ∎ ontology/schema alignment andmatching ∎ ontology/schema mapping and transformation ∎ ontology/schema merging andintegration ∎ ontology/schema mediation and reconciliation ∎ reuse of knowledge fromdisparate sources (text; user input; etc.) for ontology alignment ∎ automatic and semi-automaticapproaches ∎ mapping languages ∎ applications for and tools based on alignment ∎ integrationwithin larger applications ∎ evaluation approaches ∎ translation of information betweenheterogeneous sources Page 4. Agenda I Session 2: Research Presentations Gasevic; Hatala:Searching Web Resources Using Ontology Mappings …,*,2005,*
Proceedings K-Cap 2005 integrating ontology workshop,Ben Ashpole; Marc Ehrig; Jérôme Euzenat; Heiner Stuckenschmidt,No abstract available.,*,2005,*
Curriculum Vitae: Dr. Heiner Stuckenschmidt,Heiner Stuckenschmidt,4.1 InternationalJournals . . . . . . . . . . . . . . . . . . . . . . . . . . 11 4.2 Selected Conference Papers . .. . . . . . . . . . . . . . . . . . . . . 11 4.3 BooksandMonographes . . . . . . . . . . . . . . . . . . . . . . . . 13 4.4 BookChapters. . . . . . . . . . . . . . . . . . . . . . . . . . . . . 13 4.5 Magazines and National Journals . . . . . . . . . . . . . . . . .. . . 14 4.6 Workshops . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 14 … Dr. Heiner Stuckenschmidt Dateof Birth: 29.04.1974 in Bremen Nationality: German … Contact: Vrije Universiteit AmsterdamDe Boelelaan 1081a; 1081HV Amsterdam; Niederlande Tel.: +31 20 5987752 Fax: +31 20 5987653E-mail: heiner@cs.vu.nl URL: http://www.cs.vu.nl/∼heiner … January 2003 PhD; Faculty ofScience; Vrije Universiteit Amsterdam Topic: Ontology- Based Information Sharing in WeaklyStructured Environments supervisors: Prof. Frank van Harmelen (Vrije Universiteit Amsterda)and Prof. Otthein Herzog (University of Bremen) … 1998 Masters in Computer Science …,*,2005,*
Modularization,Heiner Stuckenschmidt; Frank van Harmelen,Summary. In Chap. 3 we introduced the Web Ontology Language as a suitable way ofdescribing information on the Semantic Web. We described the use of the language forintegrating different information sources. In this context; we always considered ontologies asmonolithic entities. In particular; we assumed that reasoning is performed on the completeset of consistent definitions from all relevant ontologies. On the Web it is much more likely;however; that the ontologies themselves are distributed and describe the same domain indifferent; potentially mutually inconsistent ways. In this chapter; we propose an extension ofOWL that deals with distributed ontologies and show its benefits compared to direct use ofOWL.,Information Sharing on the Semantic Web,2005,*
Integration and retrieval systems,Heiner Stuckenschmidt; Frank van Harmelen,Summary. The goal of this chapter is to give evidence for the practical applicability of themodels and methods presented. After having proposed a logical framework and anarchitecture for representing information semantics as well as the possibility to generatemetadata based on this framework and methods to reason about information contents; wenow present existing systems that implement some of the methods discussed. We focus onthese methods and explain the specific implementation using a common example.,Information Sharing on the Semantic Web,2005,*
Evolution management,Heiner Stuckenschmidt; Frank van Harmelen,Summary. In the last chapter we introduced modular ontologies as a natural way ofrepresenting terminological information on the Semantic Web. We proposed to usecompilation techniques for improving the efficiency of reasoning. In this section we addressthe problem of maintaining modular ontologies. In particular; we present an update strategythat guarantees the integrity of compiled knowledge in a modular ontology.,Information Sharing on the Semantic Web,2005,*
Metadata generation,Heiner Stuckenschmidt; Frank van Harmelen,Summary. In the previous chapter; we defined a general architecture for describinginformation semantics in terms of ontologies that are derived from shared terminologies of adomain and encoded using terminological languages in order to give them a clean; model-theoretic semantics. We also presented a strategy for building these ontologies. What is stillmissing at the moment is a strategy of how to actually relate information to its semanticsencoded in source ontologies. In this chapter; we will discuss how weakly structuredinformation can be linked to the ontology infrastructure described in the previous chaptersusing metadata.,Information Sharing on the Semantic Web,2005,*
Spatially-related information,Heiner Stuckenschmidt; Frank van Harmelen,Summary. In the last chapters we described techniques for retrieving information based on asemantic description of the content. As the application described in the last chapterillustrates; the relevance of information often not only depends on their content but also ontheir spatial context. In this chapter; we discuss the problem of representing the spatialcontext of information and of using it to determine relevance with respect to a certainrequest.,Information Sharing on the Semantic Web,2005,*
Ontology creation,Heiner Stuckenschmidt; Frank van Harmelen,Summary. In the last chapter we discussed languages for explicating information semanticsand argued for the need of an integration at the language level. We now draw attention tothe nature and the content of ontologies needed to support information sharing. The goal isto define an architecture combining the advantages of global and local ontologies and toshow how this infrastructure can be derived from an information-sharing task.,Information Sharing on the Semantic Web,2005,*
Retrieval and Integration,Heiner Stuckenschmidt; Frank van Harmelen,Summary. In the last part; we discussed how information sources can be semi-automaticallyenriched by semantic information. In this chapter; we show how information can be retrievedand transformed between different systems based on their semantic descriptions. We showthat translations between different ontologies can be approximated using a minimal sharedterminology. We further describe how this transformation can be exploited for content-basedinformation filtering across different systems.,Information Sharing on the Semantic Web,2005,*
Reasoning about Ontology Mappings,Luciano Serafini,*,*,2005,*
Workshop on Scalable Semantic Web Knowledge Base Systems-Session 3-Query Handling and Optimization Techniques-Scalable Instance Retrieval for the Sema...,Holger Wache; Perry Groot; Heiner Stuckenschmidt,*,Lecture Notes in Computer Science,2005,*
Query Processing for RDF Data,Heiner Stuckenschmidt,Abstract The World Wide Web today is a huge network of information resources which wasbuilt in order to broadcast information for human users. Consequently; most of theinformation on the Web is designed to be suitable for human consumption: the structuringprinciples are weak; many different kinds of information co-exist; and most of the informationis represented as free text.,*,2005,*
Workshop on Scalable Semantic Web Knowledge Base Systems-Session 1-Scalable Repository and Reasoning Services-Time--Space Trade-Offs in Scaling up RD...,Heiner Stuckenschmidt; Jeen Broekstra,*,Lecture Notes in Computer Science,2005,*
38050 Povo (Trento); Italy Tel.:+ 39 0461 314312 Fax:+ 39 0461 302040 e− mail: prdoc@ itc. it− url: http://www. itc. it,H Stuckenschmidt; van F Harmelen; L Serafini; P Bouquet; F Giunchiglia,Abstract A number of sophisticated medical ontologies have been created over the pastyears. With their development the need for supporting the alignment of different ontologies isgaining importance. We proposed C-OWL; an extension of the Web Ontology LanguageOWL that supports alignment mappings between different; possibly incompatible ontologieson a semantic level. In this paper we report experiences from using C-OWL for the alignmentof medical ontologies. We briefly review key concepts of the C-OWL semantics; explain thesetting of the case study including some examples from the alignment and discuss thepossibility of reasoning about the mapping based on the C-OWL semantics We conclude byarguing that C-OWL provides an adequate framework for aligning complex ontologies in themedical domain.,*,2004,*
Towards distributed RDF querying,Richard Vdovjak; Geert-Jan Houben; Heiner Stuckenschmidt,General rights Copyright and moral rights for the publications made accessible in the public portalare retained by the authors and/or other copyright owners and it is a condition of accessing publicationsthat users recognise and abide by the legal requirements associated with these rights. • Usersmay download and print one copy of any publication from the public portal for the purpose ofprivate study or research. • You may not further distribute the material or use it for any profit-makingactivity or commercial gain • You may freely distribute the URL identifying the publication in thepublic portal ? Take down policy If you believe that this document breaches copyright pleasecontact us providing details; and we will remove access to the work immediately and investigateyour claim … Richard Vdovjak (TU Eindhoven) Geert-Jan Houben (TU Eindhoven) Heiner Stuckenschmidt(VU Amsterdam) … Query 1 Query 2 Query 3 User … Sem. Web / RDF(S) to the …,*,2004,*
Intelligent Information Integration for the Semantic Web,Heiner Stuckenschmidt; Erik Stubkjaer; Christoph Schlieder,*,*,2004,*
C-OWL: Contextualizing Ontologies,Luciano Serafini; Reiner Stuckenschmidt,*,The Semantic Web; ISWC 2003: Second International Semantic Web Conference; Sanibel Island; FL; USA; October 20-23; 2003: Proceedings,2003,*
D4. 2 Basic Ontology Services,Jeen Broekstra; Arjohn Kampmann; Heiner Stuckenschmidt,*,*,2003,*
Proceedings of the IJCAI-03 workshop on ontologies and distributed systems (ODS 2003),F Giunchiglia; A Gomez-perez; A Pease; H Stuckenschmidt; Y Sure; S Willmott,E' presente una richiesta di inserimento in ANCE di una nuova rivista; utilizza la funzione "Registracodice ANCE" per registrare il codice ricevuto dal servizio LoginMIUR o inviare una nuova richiestadi inserimento oppure cercare nuovamente la rivista. E' presente una richiesta di inserimentoin ANCE di una nuova serie; utilizza la funzione "Registra codice ANCE" per registrare il codicericevuto dal servizio LoginMIUR o inviare una nuova richiesta di inserimento oppure cercarenuovamente la serie … Segnalazioni con codici 20501/20503/20504: Alcuni dati obbligatoriper il sito CINECA non sono presenti o invalidi; oppure il sito CINECA non è riuscito ad individuareuna rivista con i dati forniti; è necessario controllare la correttezza dell'ISSN e/o EISSN doveapplicabili e il titolo della rivista … Segnalazioni con codici 20201/20202:La pubblicazionenon è stata trasferita SOLO per i docenti segnalati nel messaggio a causa di problemi …,*,2003,*
From Corporate Memories to Supply Web Memory,Ingo J Timm; Heiner Stuckenschmidt,Abstract Modern production has discovered knowledge as an additional factor of productionand a new trend of research; development and implementation of corporate memorysystems is arising. The global economy leads to tighter corporation relations betweenenterprises. Therefore the knowledge of one product does not exist in a single company butwithin participating companies respective the supply chain. A modern product centeredknowledge management has to face the difficult task of the integration of distributedknowledge sources. This contribution states our interest in research on the integration ofcorporate memory. In a first step we are focusing on single products leading to supply chainmemories. Further research and development will lead to supply web memory.,*,2001,*
Towards Intelligent Brokering of Geo-Information,Heiner Stuckenschmidt; Ubbo Visser; Thomas J Voegele,ABSTRACT We present an approach for intelligent sharing of geographic information. Theapproach is based on the idea of an intelligent broker that is able to query semanticdescriptions of data sources and software components available ever the World Wide Web(WWW). In the paper we discuss the use of ontologies for the semantic description ofinformation sources; and define requirements for the semantic description of softwarecomponents. We illustrate the approach with a comprehensible application scenario.,In Proceedings of the Urban Data Management Symposium,2000,*
Agent-Based Services for the Semantic Web,H Stuckenschmidt; I Timm; C Schlieder,The semantic web has become an important research area devoted to the development oftechniques and methods that enable intelligent applications to work on information contentsavailable on the World Wide Web. In a recent article; Berners-Lee Hendler and Lassiladescribe the benefits of the semantic web as follows:” The real power of the Semantic Webwill be realized when people create many programs that collect Web content from diversesources; process the information and exchange the results with other programs. Theeffectiveness of such software agents will increase exponentially as more machine-readableWeb content and automated services (including other agents) become available. TheSemantic Web promotes this synergy: even agents that were not expressly designed to worktogether can transfer data among themselves when the data come with semantics.”[27],*,2000,*
A Framework for the Design of Uncertain Reasoning systems,Heiner Stuckenschmidt,Abstract We describe a general framework for the design of uncertain reasoning systemsbased on reusable components. We take the emerging UPML standard for component-based design of intelligent systems as a starting point for our discussion. We modify theUPML component model for the needs of uncertain reasoning and show how the model canbe used to design a specific reasoning approach in terms of component-wiseaxiomatization. We argue that this approach offers an optimal trade-off betweendevelopment from scratch and the use of standard development tools in terms of flexibilitydevelopment costs. We show how our framework applies to the design of a semantictranslator for the integration of heterogeneous information sources on the basis ofprobabilistic classification.,*,2000,*
Spezifikation von unsicherem Wissen in einem erweiterten Expertisemodell,K Christoph Ranze; Heiner Stuckenschmidt,Zusammenfassung Formale Modelle der Expertise gewinnen immer größere Bedeutung imBereich des Knowledge Engineering. Der Aufbau dieser Modelle ist geprägt durch dieUnterscheidung zwischen Domäne; Inferenz; und Kontroll-oder auch Aufgabenwissen.Diese Arbeit stellt einen Ansatz vor; der es ermöglicht; mit Hilfe eines am KADS-Ansatzorientierten Modell der Expertise explizit Unsicherheiten im modellierten Wissendarzustellen. Es entsteht ein paralleles Unsicherheitsmodell; das durch expliziteReferenzierung mit den Elementen des Expertisemodells verbunden ist. Die Verarbeitungdes unsicheren Wissens wird in die Inferenzebene des Expertisemodells integriert; in dementsprechenden Ergebnisse; die durch spezielle Inferenzen im Unsicherheitsmodellberechnet werden; durch eine Interpretation in Axiome übersetzt werden. Ein …,*,1999,*
Problem-solving methods for efficient reasoning under uncertainty,Heiner Stuckenschmidt,Abstract Parallel to the research effort spend on the investigation of reusable components forbuilding knowledge based systems amongst which problem-solving methods play a centralrole; researchers from the uncertain reasoning community have made significant progress inthe development of powerful and efficient algorithms for uncertain reasoning based uponnumerical representations of uncertainty. We argue that this important class of algorithmshas been totally neglected in the research on problem-solving methods carried out duringthe last years. Almost all existing approaches are dominated by the examination of methodsbased on the paradigm of search. In this paper we try to close this gap by a systematicanalysis of numerical methods for uncertain reasoning. We base our investigation on wellknown notions used to describe reusable problem-solving methods and show that there …,Proceedings of KAW,1999,*
cosap - Bilanz eines studentischen KI-Projektes,Heiner Stuckenschmidt; Ingo J.  Timm; Joerg Schroeder,*,KI,1997,*
E-Commerce and Web Technologies,Heiner Stuckenschmidt; Dietmar Jannach,EC-Web is an international scientific conference series devoted to technology-relatedaspects of e-commerce and e-business. The 16th edition of the conference; EC-Web 2015;took place in Valencia; Spain; in September 2015 and served as a forum to bring togetherresearchers and practitioners to present and discuss recent advances in their fields. Theconference series historically covers the following areas:–Search; comparison andrecommender systems–Preference representation and reasoning–Semantic-based systems;ontologies and linked data–Agent-based systems; negotiation and auctions–Social Weband social media in e-commerce–Computational advertising–E-commerce infrastructuresand cloud-based services–Service modelling and engineering–Business processes; Webservices and service-oriented architectures–E-business architectures,*,*,*
15 Years of Semantic Web,Birte Glimm; Heiner Stuckenschmidt,Abstract It has been 15 years since the first publications proposed the use of ontologies as abasis for defining information semantics on the Web starting what today is known as theSemantic Web Research Community. This work undoubtedly had a significant influence onAI as a field and in particular the Knowledge Representation and Reasoning Communitythat quickly identified new challenges and opportunities in using Description Logics in apractical setting. In this survey article; we will try to give an overview of the developments thefield has gone through in these 15 years. We will look at three different aspects: theevolution of Semantic Web Language Standards; the evolution of central topics in theSemantic Web Community and the evolution of the research methodology.,*,*,*
Automatische Vergabe von RVK-Notationen anhand von bibliografischen Daten mittels fallbasiertem Schließen.,Stephan Büttner; Heiner Stuckenschmidt,Zusammenfassung Klassifikation von bibliografischen Einheiten ist für einen systematischenZugang zu den Beständen einer Bibliothek und deren Aufstellung unumgänglich. Bislangwurde diese Aufgabe von Fachexperten manuell erledigt; sei es individuell nach einerselbst entwickelten Systematik oder kooperativ nach einer gemeinsamen Systematik. Indieser Arbeit wird ein Verfahren zur Automatisierung des Klassifikationsvorgangsvorgestellt. Dabei kommt das Verfahren des fallbasierten Schließens zum Einsatz; das imKontext der Forschung zur künstlichen Intelligenz entwickelt wurde. Das Verfahren liefert fürjedes Werk; für das bibliografische Daten vorliegen; eine oder mehrere möglicheKlassifikationen. In Experimenten werden die Ergebnisse der automatischen Klassifikationmit der durch Fachexperten verglichen. Diese Experimente belegen die hohe Qualität der …,*,*,*
Artificial Intelligence on the Web (AIW),Sebastian Rudolph; Heiner Stuckenschmidt; Matthias Thimm; Chris Biemann; Claudia D’Amato; Gerd Gröner; Barbara Hammer; Andreas Hotho; Yevgeny Kazakov; Pavel Klinov; Kristian Kersting; Mathias Niepert; Rafael Penaloza Nyssen; Ansgar Scherp; Michael Strube; Ingo J Timm; Stefan Woltran,The World Wide Web has become a unique source of knowledge on virtually anyimaginable topic. It is continuously fed by companies; academia; and common people with avariety of information in numerous formats. By today; the Web has become an invaluableasset for research; learning; commerce; socializing; communication; and entertainment. Still;making full use of the knowledge contained on the Web is an ongoing challenge due to thespecial properties of the Web as an information source:,*,*,*
Universität Mannheim; Germany {heiner; anne}@ informatik. uni-mannheim. de,Heiner Stuckenschmidt; Anne Schlicht,Summary. In this chapter we describe a method for structure-based ontology partitioning andits implementation that is practically applicable to very large ontologies. We show that amodularization based on structural properties of the ontology only already results inmodules that intuitively make sense. The method was used for creating an overview graphfor ontologies and for extracting key topics from an ontology that correspond to topicsselected by human experts. Because the optimal modularization of an ontology greatlydepends on the application it is used for; we implemented the partitioning algorithm in a waythat allows for adaption to different requirements. Furthermore this adaption can beperformed automatically by specifying requirements of the application.,*,*,*
ORGANIZING COMMrITEE,SK Chan,*,*,*,*
A Formal Investigation of Mapping Language for Terminological Knowledge,Via Sommarive ITC-IRST; Heiner Stuckenschmidt; Holger Wache,Abstract The need for being able to talk about mappings between different ontologies hasbeen recognized as a result of the fact that different ontologies may partially overlap or evenrepresent the same domain from different points of view. Unlike for the case of ontologylanguages; work on mapping languages has not yet reached a state where a commonunderstanding of the basic principles exists. In this paper we propose a formal comparisonof existing mapping language by translating them into distributed£ rst order logic. Weanalyze underlying assumptions and differences in the interpretation of mappings.,*,*,*
A Connection Method for Reasoning with the Description Logic ALC,Fred Freitas; Anne Schlicht; Heiner Stuckenschmidt,*,*,*,*
ONTOLOGIES FOR SEMANTIC TRANSLATION: A CASE STUDY,Heiner Stuckenschmidt; Ubbo Visser; Christoph Schlieder,*,*,*,*
Semantic Web Challenge,Michel Klein; Ubbo Visser; Heiner Stuckenschmidt; Frank van Harmelen; Anita de Waard; Tony Scerri; Ravinder Bhogal; Jan van Buel; Ian Crowlesmith; Christiaan Fluit; Arjohn Kampman; Jeen Broekstra; Erik van Mulligen; Daniel Bloomfield Ramagem; Bruno Margerin; Jackie Kendall; Jens Hartmann; York Sure; Andreas Harth; Martin Michalowski; José Luis Ambite; Craig A Knoblock; Steve Minton; Snehal Thakkar; Rattapoom Tuchinda; Sebastian Hübner; Rainer Spittel; Thomas J Vögele; John Atkinson-Abutridy; Chris Mellish; Stuart Aitken,Circulation: IEEE Intelligent Systems (ISSN 1094-7167) is published bimonthly by the IEEE ComputerSociety. IEEE Headquarters; Three Park Ave.; 17th Floor; New York; NY 10016-5997; IEEE ComputerSociety Publications Office; 10662 Los Vaqueros Circle; PO Box 3014; Los Alamitos; CA90720-1314; phone +1 714 821 8380; IEEE Computer Society Headquarters; 1730 MassachusettsAve. NW; Washington; DC 20036-1903. Subscription rates: IEEE Computer Society membersget the lowest rates and choice of media option – US$37/30/48 print/electronic/combination.Go to www.computer.org/subscribe to order and for more information on other subscriptionprices. Nonmember rate: available on request. Back issues: $20 for members and $108 fornonmembers … Cover illustration: Jud Guitteau; Cover design: Toni Van Buskirk … Editor inChief Nigel Shadbolt University of Southhampton nrs@ecs.soton.ac.uk Associate Editors …,*,*,*
Alexander V. Smirnov; Russian,Heiner Stuckenschmidt; Aixin Sun; York Sure; Domenico Talia; Christopher A Welty; Raymond Wong; Zhaohui Wu; Baowen Xu; Guangwen Yang; Yun Yang; Wlodek Zadrozny,Witold Abramowicz; Poznan University of Economics; Poland Boanerges Aleman-Meza; Universityof Georgia; USA Mark A. Baker; University of Portsmouth; UK Jim Blythe; University of SouthernCalifornia; USA Peter Brezany; University of Vienna Marian Bubak; AGH University of Scienceand Technology; Poland Mario Cannataro; University Magna Graecia of Catanzaro; Italy GuihaiChen; Nanjing University; China Jinjun Chen; Swinburne University of Technology; AustraliaLiming Chen; University of Southampton; UK Yin Chen; Hong Kong Univ. of Science and Tech& China Southern Normal University; China William Kwok-Wai Cheung; Hong Kong BaptistUniversity; China Ying Ding; University of Innsbruck; Austria John Domingue; The OpenUniversity; UK Lukasz Dutka; Academic Computer Centre Cyfronet AGH; Poland Kevin F.Franklin; University of California; USA Naoki Fukuta; Shizuoka University; Japan Yuxi Fu …,*,*,*
Ontologies and Information Sharing,A Gómez Pérez; M Gruninger; H Stuckenschmidt; M Uschold,From the early 1990s; there has been a fruitful series of over a dozen workshops;symposiums and conferences on the emerging field concerned with the development andapplication of ontologies. Early workshops were focused in large part on identifying whatontologies were; and how they might be used. As the field developed and matured; we haveobtained a reasonable understanding and consensus about the nature of ontologies. Thecore idea is to explicitly encode a shared understanding of some domain that can be agreedamong different parties (be they people or computers). This shared understanding is theontology–it is an explicit representation comprising a vocabulary of terms; each with adefinition specifying its meaning. All parties commit to using these terms in accordance totheir definitions. Although there was a consensus on what an ontology was; how exactly …,*,*,*
Compiling Complex Terminologies for Query Processing,Heiner Stuckenschmidt,Abstract It is widely accepted that the Semantic Web will be based on machine-readablemetadata describing the content of resources. These descriptions are designed to enableintelligent agents to locate and filter relevant information with a higher level of accuracy. TheResource Description Framework (RDF) has been developed as universal language forencoding content-related metadata and recently a number of query languages have beenproposed to extract information from metadata models. Current applications of RDF andRDF query languages only use very simple metadata like simple concept hierarchies (TheOpen Directory) or pre-defined attribute value pairs (Dublin Core). In this paper we addressthe problem of encoding and querying complex metada using RDF models and queries. Inour approach we consider ontologies with complex concept definitions in the spirit of …,*,*,*
Compiling Complex Terminologies for Efficient Query Answering on the Semantic Web,Heiner Stuckenschmidt,ABSTRACT It is widely accepted that the Semantic Web will be based on machine-readablemetadata describing the content of resources. These descriptions are designed to enableintelligent agents to locate and filter relevant information with a higher level of accuracy. TheResource Description Framework (RDF) has been developed as universal language forencoding content-related metadata and recently a number of query languages have beenproposed to extract information from metadata models. Current applications of RDF andRDF query languages only use very simple metadata like simple concept hierarchies (TheOpen Directory) or pre-defined attribute value pairs (Dublin Core). In this paper we addressthe problem of encoding and querying complex metada using RDF models and queries. Inour approach we consider ontologies with complex concept definitions in the spirit of …,*,*,*
Querying Embedded RDF Data with XML Technology: A Feasibility Study,Norman May; Heiner Stuckenschmidt,Abstract: XML has become the de facto standard for representing and accessing data on theWeb. At the same time RDF is becoming more and more popular for representing metadata.While RDF also has an XML-based syntax; storage and query technologies for the twoformats are not compatible due to differences in the data model. This is a potential problemwhen trying to query data that combine XML data with RDF-based metadata annotations. Inthis paper; we investigate the feasibility of querying such embedded RDF models with XMLtechnologies. We motivate the problem using the vision of intelligent content objects;describe an approach for querying RDF data with XQuery and identify problems andopportunities based on experiments with real world data.,*,*,*
