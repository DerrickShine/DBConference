Challenges and opportunities with big data,Alexandros Labrinidis; Hosagrahar V Jagadish,Abstract The promise of data-driven decision-making is now being recognized broadly; andthere is growing enthusiasm for the notion of" Big Data;" including the recent announcementfrom the White House about new funding initiatives across different agencies; that targetresearch for Big Data. While the promise of Big Data is real--for example; it is estimated thatGoogle alone contributed 54 billion dollars to the US economy in 2009--there is no clearconsensus on what is Big Data. In fact; there have been many controversial statementsabout Big Data; such as" Size is the only thing that matters." In this panel we will try toexplore the controversies and debunk the myths surrounding Big Data.,Proceedings of the VLDB Endowment,2012,606
Big data and its technical challenges,HV Jagadish; Johannes Gehrke; Alexandros Labrinidis; Yannis Papakonstantinou; Jignesh M Patel; Raghu Ramakrishnan; Cyrus Shahabi,The growth rate of the output of current NGS methods in terms of the raw sequence data producedby a single NGS machine is shown in Figure 1; along with the performance increase for the SPECintCPU benchmark. Clearly; the NGS sequence data growth far outstrips the performance gainsoffered by Moore's Law for single-threaded applications (here; SPECint). Note the sequencedata size in Figure 1 is the output of analyzing the raw images that are actually produced by theNGS instruments. The size of these raw image datasets themselves is so large (many TBs perlab per day) that it is impractical today to even consider storing them. Rather; these images areanalyzed on the fly to produce sequence data; which is then retained … Big Data has the potentialto revolutionize much more than just research. Google's work on Google File System andMapReduce; and subsequent open source work on systems like Hadoop; have led to …,Communications of the ACM,2014,411
Balancing energy efficiency and quality of aggregate data in sensor networks,Mohamed A Sharaf; Jonathan Beaver; Alexandros Labrinidis; Panos K Chrysanthis,Abstract. In-network aggregation has been proposed as one method for reducing energyconsumption in sensor networks. In this paper; we explore two ideas related to furtherreducing energy consumption in the context of in-network aggregation. The first is byinfluencing the construction of the routing trees for sensor networks with the goal of reducingthe size of transmitted data. To this end; we propose a group-aware network configurationmethod that “clusters” along the same path sensor nodes that belong to the same group. Thesecond idea involves imposing a hierarchy of output filters on the sensor network with thegoal of both reducing the size of transmitted data and minimizing the number of transmittedmessages. More specifically; we propose a framework to use temporal coherency tolerancesin conjunction with in-network aggregation to save energy at the sensor nodes while …,The VLDB journal,2004,319
TiNA: a scheme for temporal coherency-aware in-network aggregation,Mohamed A Sharaf; Jonathan Beaver; Alexandros Labrinidis; Panos K Chrysanthis,Abstract This paper presents TiNA; a scheme for minimizing energy consumption in sensornetworks by exploiting end-user tolerance to temporal coherency. TiNA utilizes temporalcoherency tolerances to both reduce the amount of information transmitted by individualnodes (communication cost dominates power usage in sensor networks); and to improvequality of data when not all sensor readings can be propagated up the network within agiven time constraint. TiNA was evaluated against a traditional in-network aggregationscheme with respect to power savings as well as the quality of data for aggregate queries.Preliminary results show that TiNA can reduce power consumption by up to 50% without anyloss in the quality of data.,Proceedings of the 3rd ACM international workshop on Data engineering for wireless and mobile access,2003,312
WebView materialization,Alexandros Labrinidis; Nick Roussopoulos,Abstract A WebView is a web page automatically created from base data typically stored in aDBMS. Given the multi-tiered architecture behind database-backed web servers; we havethe option of materializing a WebView inside the DBMS; at the web server; or not at all;always computing it on the fly (virtual). Since WebViews must be up to date; materializedWebViews are immediately refreshed with every update on the base data. In this paper wecompare the three materialization policies (materialized inside the DBMS; materialized atthe web server and virtual) analytically; through a detailed cost model; and quantitatively;through extensive experiments on an implemented system. Our results indicate thatmaterializing at the web server is a more scalable solution and can facilitate an order ofmagnitude more users than the virtual and materialized inside the DBMS policies; even …,ACM SIGMOD Record,2000,143
Challenges and Opportunities with big data 2011-1,Divyakant Agrawal; Philip Bernstein; Elisa Bertino; Susan Davidson; Umeshwas Dayal; Michael Franklin; Johannes Gehrke; Laura Haas; Alon Halevy; Jiawei Han; HV Jagadish; Alexandros Labrinidis; Sam Madden; Yannis Papakonstantinou; Jignesh Patel; Raghu Ramakrishnan; Kenneth Ross; Cyrus Shahabi; Dan Suciu; Shiv Vaithyanathan; Jennifer Widom,Abstract The promise of data-driven decision-making is now being recognized broadly; andthere is growing enthusiasm for the notion of``Big Data.''While the promise of Big Data is real--for example; it is estimated that Google alone contributed 54 billion dollars to the USeconomy in 2009--there is currently a wide gap between its potential and its realization.,*,2011,127
Update propagation strategies for improving the quality of data on the web,Alexandros Labrinidis; Nick Roussopoulos,Dynamically generated web pages are ubiquitous today but their high demand for resourcescreates a huge scalability problem at the servers. Traditional web caching is not able tosolve this problem since it cannot provide any guarantees as to the freshness of the cacheddata. A robust solution to the problem is web materialization; where pages are cached at theweb server and constantly updated in the background; resulting in fresh data accesses oncache hits. In this work; we define Quality of Data metrics to evaluate how fresh the dataserved to the users is. We then focus on the update scheduling problem: given a set of viewsthat are materialized; find the best order to refresh them; in the presence of continuousupdates; so that the overall Quality of Data (QoD) is maximized. We present a QoD-awareUpdate Scheduling algorithm that is adaptive and tolerant to surges in the incoming …,*,2001,106
Ratio rules: A new paradigm for fast; quantifiable data mining,Flip Korn; Alexandros Labrinidis; Yannis Kotidis; Christos Faloutsos,Abstract Association Rule Mining algorithms operate on a data matrix (eg; customersproducts) to derive association rules 2; 23]. We propose a new paradigm; namely; RatioRules; which are quanti able in that we can measure the\goodness" of a set of discoveredrules. We propose to use the\guessing error" as a measure of the\goodness"; that is; therootmean-square error of the reconstructed values of the cells of the given matrix; when wepretend that they are unknown. Another contribution is a novel method to guessmissing/hidden values from the Ratio Rules that our method derives. For example; ifsomebody bought $10 of milk and $3 of bread; our rules can\guess" the amount spent on;say; butter. Thus; we can perform a variety of important tasks such as forecasting;answering\what-if" scenarios; detecting outliers; and visualizing the data. Moreover; we …,*,1998,83
Preference-aware query and update scheduling in web-databases,Huiming Qu; Alexandros Labrinidis,Typical Web-database systems receive read-only queries; that generate dynamic Webpages as a response; and write-only updates; that keep information up-to-date. Users expectshort response times and low staleness. However; it may be extremely hard to apply allupdates on time; ie; keep zero staleness; and also get fast response times; especially inperiods of bursty traffic. In this paper; we present the concept of quality contracts (QCs)which combines the two incomparable performance metrics: response time or quality ofservice (QoS); and staleness or quality of data (QoD). QCs allows individual users toexpress their preferences for the expected QoS and QoD of their queries by assigning"profit" values. To maximize the total profit from submitted QCs; we propose an adaptivealgorithm; called QUTS. QUTS addresses the problem of prioritizing the scheduling of …,Data Engineering; 2007. ICDE 2007. IEEE 23rd International Conference on,2007,75
Report from the first workshop on geo sensor networks,Silvia Nittel; Anthony Stefanidis; I Cruz; M Egenhofer; D Goldin; A Howard; Alexandros Labrinidis; Samuel Madden; Agnès Voisard; M Worboys,Advances in sensor technology and deployment strategies are revolutionizing the way thatgeospatial information is collected and analyzed. For example; cameras and GPS sensorson-board static or mobile platforms have the ability to provide continuous streams ofgeospatiallyrich information. Furthermore; with the advent of nanotechnology it becomesfeasible and economically viable to develop and deploy low-cost; low-power devices thatare general-purpose computing platforms with multi-purpose on-board sensing and wirelesscommunications capabilities. Today; research efforts are taking place developinginfrastructure for systems consisting of large numbers of small unattended; untethered andcollaborative sensor nodes that have non-renewable power supply and communicate viashort range radio frequency with neighboring nodes. These types of sensors may also act …,ACM SIGMOD Record,2004,73
Exploring the tradeoff between performance and data freshness in database-driven web servers,Alexandros Labrinidis; Nick Roussopoulos,Abstract Personalization; advertising; and the sheer volume of online data generate astaggering amount of dynamic Web content. In addition to Web caching; view materializationhas been shown to accelerate the generation of dynamic Web content. View materializationis an attractive solution as it decouples the serving of access requests from the handling ofupdates. In the context of the Web; selecting which views to materialize must be decidedonline and needs to consider both performance and data freshness; which we refer to as theonline view selection problem. In this paper; we define data freshness metrics; provide anadaptive algorithm for the online view selection problem that is based on user-specified datafreshness requirements; and present experimental results. Furthermore; we examinealternative metrics for data freshness and extend our proposed algorithm to handle …,The VLDB Journal—The International Journal on Very Large Data Bases,2004,68
Algorithms and metrics for processing multiple heterogeneous continuous queries,Mohamed A Sharaf; Panos K Chrysanthis; Alexandros Labrinidis; Kirk Pruhs,Abstract The emergence of monitoring applications has precipitated the need for DataStream Management Systems (DSMSs); which constantly monitor incoming data feeds(through registered continuous queries); in order to detect events of interest. In this article;we examine the problem of how to schedule multiple Continuous Queries (CQs) in a DSMSto optimize different Quality of Service (QoS) metrics. We show that; unlike traditional onlinesystems; scheduling policies in DSMSs that optimize for average response time will bedifferent from policies that optimize for average slowdown; which is a more appropriatemetric to use in the presence of a heterogeneous workload. Towards this; we proposepolicies to optimize for the average-case performance for both metrics. Additionally; wepropose a hybrid scheduling policy that strikes a fine balance between performance and …,ACM Transactions on Database Systems (TODS),2008,66
Location-aware routing for data aggregation in sensor networks,Jonathan Beaver; M Sharaf; Alexandros Labrinidis; P Chrysanthis,ABSTRACT In-network aggregation has been proposed as one method for reducing energyconsumption in networked sensors. In this paper; we explore the idea of influencing theconstruction of the routing trees for sensor networks with the goal of reducing the size oftransmitted data for networks with in-network aggregation involving Group By queries.Toward this; we propose a group-aware network configuration method and present twoalgorithms; that “cluster” along the same path sensor nodes which belong to the samegroup. We evaluate our proposed scheme experimentally; in the context of existing in-network aggregation schemes; with respect to energy consumption and quality of data.Overall; our routing tree construction scheme provides energy savings over existing networkconfiguration schemes and improves quality of data in systems with imperfect quality of …,Geosensor Networks,2004,62
Quantifiable data mining using ratio rules,Flip Korn; Alexandros Labrinidis; Yannis Kotidis; Christos Faloutsos,Abstract Association Rule Mining algorithms operate on a data matrix (eg; customers $\times$ products) to derive association rules [AIS93b; SA96]. We propose a new paradigm;namely; Ratio Rules; which are quantifiable in that we can measure the “goodness” of a setof discovered rules. We also propose the “guessing error” as a measure of the “goodness”;that is; the root-mean-square error of the reconstructed values of the cells of the given matrix;when we pretend that they are unknown. Another contribution is a novel method to guessmissing/hidden values from the Ratio Rules that our method derives. For example; ifsomebody bought $10 of milk and $3 of bread; our rules can “guess” the amount spent onbutter. Thus; unlike association rules; Ratio Rules can perform a variety of important taskssuch as forecasting; answering “what-if” scenarios; detecting outliers; and visualizing the …,The VLDB Journal—The International Journal on Very Large Data Bases,2000,59
-Balancing Performance and Data Freshness in Web Database Servers,Alexandros Labrinidis; Nick Roussopoulos,This chapter defines data-freshness metrics; provides an adaptive algorithm for the onlineview selection problem; and presents experimental results. Personalization; advertising; andthe sheer volume of online data generate a staggering amount of dynamic web content. Inaddition to web caching; View Materialization has been shown to accelerate the generationof dynamic web content. View materialization is an attractive solution as it decouples theserving of access requests from the handling of updates. In the context of the Web; selectingwhich views to materialize must be decided online and needs to consider both performanceand data freshness; which one refer to as the online view selection problem.BalancingPerformance and Data Freshness in Web Database Servers Alexandros LabrinidisDepartment of Computer Science University of Pittsburgh labrinid 9 pitt. edu Nick …,*,2003,55
On the materialization of webviews,Alexandros Labrinidis; Nick Roussopoulosxa,Abstract: A WebView is a web page that is automatically created from base data; which areusually drawn from a DBMS. A WebView can be either materialized as an html page at theweb server; or virtual; always being computed on-the-fly. For the materialized case; updatesto base data lead to immediate recomputation of the WebView; whereas in the virtual case;recomputation is done on demand with each request. We introduce the materialize on-demand approach which combines the two strategies; and generates WebViews ondemand; but also stores the results and re-uses them in the future if possible. Deciding onone of the three materialization policies for each WebView is clearly a performance issue. Inthis paper; we give the framework for the problem and provide a cost model; which we testwith experiments on a real web server. Descriptors:* DATA BASES;* INTERNET …,*,1999,54
GeoSensor networks,Silvia Nittel,Gaussian processes (GPs) are local approximation techniques that model spatial data byplacing (and updating) priors on the covariance structures underlying the data. Originallydeveloped for geo-spatial contexts; they are also applicable in general contexts that involvecomputing and modeling with multi-level spatial aggregates; eg; modeling a configurationspace for crystallographic design; casting folding energies as a function of a protein'scontact map; and formulation of vaccination policies taking into account social dynamics ofindividuals. Typically; we assume a parametrized covariance structure underlying the data tobe modeled. We estimate the covariance parameters conditional on the locations for whichwe have observed data; and use the inferred structure to make predictions at new locations.GPs have a probabilistic basis that allow us to estimate variances at unsampled locations …,Encyclopedia of GIS,2008,48
Power-aware in-network query processing for sensor data,Jonathan Beaver; Mohamed A Sharaf; Alexandros Labrinidis; Panos K Chrysanthis,Abstract Minimizing energy consumption has been a major objective at all levels in sensornetworks. In this paper; we present TiNA; an in-network aggregation scheme that maintainsthe user-specified quality of data requirement while significantly reducing the overall energyconsumption. Specifically; since communication dominates power usage in sensornetworks; TiNA exploits end-user temporal coherency tolerances to reduce the amount ofinformation transmitted by individual nodes. Further; we show that TiNa; by using temporalcoherency tolerances; can allow for better quality of data when the time given to performreadings is too short for all data to be propagated up through the network. We compare ourproposed scheme against an existing in-network aggregation scheme with a local sensorcache. We present experimental results measuring both power savings and also the …,Proc. of the 2nd Hellenic Data Management Symposium,2003,46
Global transcriptional response to spermine; a component of the intramacrophage environment; reveals regulation of Francisella gene expression through insertion...,Paul E Carlson; Joseph Horzempa; Dawn M O'Dee; Cory M Robinson; Panayiotis Neophytou; Alexandros Labrinidis; Gerard J Nau,ABSTRACT Tularemia is caused by the category A biodefense agent Francisella tularensis.This bacterium is associated with diverse environments and a plethora of arthropod andmammalian hosts. How F. tularensis adapts to these different conditions; particularly theeukaryotic intracellular environment in which it replicates; is poorly understood. Here; wedemonstrate that the polyamines spermine and spermidine are environmental signals thatalter bacterial stimulation of host cells. Genomewide analysis showed that F. tularensis LVSundergoes considerable changes in gene expression in response to spermine.Unexpectedly; analysis of gene expression showed that multiple members of two classes ofFrancisella insertion sequence (IS) elements; ISFtu1 and ISFtu2; and the genes adjacent tothese elements were induced by spermine. Spermine was sufficient to activate …,Journal of bacteriology,2009,44
Efficient scheduling of heterogeneous continuous queries,Mohamed A Sharaf; Panos K Chrysanthis; Alexandros Labrinidis; Kirk Pruhs,Abstract Data Stream Management Systems (DSMS) typically host multiple ContinuousQueries (CQ) that process streams of data. In this paper; we examine the problem of how toschedule CQs in a DSMS to optimize for average QoS. We show that unlike standard on-linesystems; scheduling policies in DSMSs that optimize for average response time will bedifferent than policies that optimize for average slowdown which is more appropriate metricto use in the presence of a heterogeneous workload. We also propose a hybrid schedulingpolicy based on slowdown that strikes a fine balance between performance and fairness.We further discuss how our policies can be efficiently implemented and extended to exploitsharing in optimized multi-query plans and multi-stream CQs. Finally; we experimentallyshow using real data that our policies outperform currently used ones.,Proceedings of the 32nd international conference on Very large data bases,2006,39
Generating dynamic content at database-backed web servers: cgi-bin vs. mod_perl,Alexandros Labrinidis; Nick Roussopoulos,Abstract Web servers are increasingly being used to deliver dynamic content rather thanstatic HTML pages. In order to generate web pages dynamically; servers need to execute ascript; which typically connects to a DBMS. Although CGI was the first approach at serverside scripting; it has significant performance shortcomings. Currently; there are manyalternative server side scripting architectures which offer better performance than CGI. In thispaper; we report our experiences using mod_perl; an Apache Server module; which canimprove the performance of CGI scripts by at least an order of magnitude. Except forpresenting results from our experiments; we also briefly describe the implementation of anindustrial strength database-backed web site that we recently built and give a quickoverview of the various server-side scripting mechanisms.,ACM SIGMOD Record,2000,37
Unit: User-centric transaction management in web-database systems,Huiming Qu; Alexandros Labrinidis; Daniel Mosse,Web-database systems are nowadays an integral part of everybody's life; with applicationsranging from monitoring/trading stock portfolios; to personalized blog aggregation and newsservices; to personalized weather tracking services. For most of these services to besuccessful (and their users to be kept satisfied); two criteria need to be met: user requestsmust be answered in a timely fashion and using fresh data. This paper presents a frameworkto balance both requirements from the users' perspective. Toward this; we propose a usersatisfaction metric to measure the overall effectiveness of the Web-database system. Wealso provide a set of algorithms to dynamically optimize this metric; through query admissioncontrol and update frequency modulation. Finally; we present extensive experimental resultswhich compare our proposed algorithms to the current state of the art and show that we …,Data Engineering; 2006. ICDE'06. Proceedings of the 22nd International Conference on,2006,35
Adaptive scheduling of web transactions,Shenoda Guirguis; Mohamed A Sharaf; Panos K Chrysanthis; Alexandros Labrinidis; Kirk Pruhs,In highly interactive dynamic web database systems; user satisfaction determines theirsuccess. In such systems; user requested web pages are dynamically created by executinga number of database queries or web transactions. In this paper; we model the interrelatedtransactions generating a web page as workflows and quantify the user satisfaction byassociating dynamic web pages with soft-deadlines. Further; we model the importance oftransactions in generating a page by associating different weights to transactions. Using thisframework; system success is measured in terms of minimizing the deviation from thedeadline (ie; tardiness) and also minimizing the weighted such deviation (ie; weightedtardiness). In order to efficiently support the materialization of dynamic web pages; wepropose ASETS∗; which is a parameter-free adaptive scheduling algorithm that …,Data Engineering; 2009. ICDE'09. IEEE 25th International Conference on,2009,32
Preemptive rate-based operator scheduling in a data stream management system,Mohamed A Sharaf; Panos K Chrysanthis; Alexandros Labrinidis,Summary form only given. Data stream management systems are being developed toprocess continuous queries over multiple data streams. These continuous queries aretypically used for monitoring purposes where the detection of an event might trigger asequence of actions or the execution of a set of specified tasks. Such events are identified bytuples produced by a query and hence; it is important to produce the available portions of aquery result as early as possible. A core element for improving the interactive performanceof a continuous query is the operator scheduler. An operator scheduler is particularlyimportant when the processing requirements and the productivity of different streams arehighly skewed. The need for an operator scheduler becomes even more crucial when tuplesfrom different streams arrive asynchronously. To meet these needs; we are proposing a …,Computer Systems and Applications; 2005. The 3rd ACS/IEEE International Conference on,2005,32
Adaptive webview materialization,Alexandros Labrinidis; Nick Roussopoulos,Abstract: Dynamic content generation poses huge resource demands on web servers;creating a scalability problem. WebView Materialization; where web pages are cached andconstantly refreshed in the background; has been shown to ameliorate the scalabilityproblem without sacrificing data freshness. In this work we present an adaptive onlinealgorithm to select which WebViews to materialize; that realizes the trade-off betweenQuality of Service and Quality of Data. Our algorithm performs very close to the static; off-lineoptimal algorithm; and; under rapid workload changes; it outperforms the optimal.Descriptors:* ADAPTIVE SYSTEMS;* INTERNET; ALGORITHMS; OPTIMIZATION; OFFLINESYSTEMS; ONLINE SYSTEMS; DYNAMICS. Subject Categories: OPERATIONSRESEARCH COMPUTER PROGRAMMING AND SOFTWARE Distribution Statement …,*,2001,32
Caching and materialization for web databases,Alexandros Labrinidis; Qiong Luo; Jie Xu; Wenwei Xue,Abstract Database systems have been driving dynamic websites since the early 1990s;nowadays; even seemingly static websites employ a database back-end for personalizationand advertising purposes. In order to keep up with the high demand fuelled by the rapidgrowth of the Internet; a number of caching and materialization techniques have beenproposed for web databases over the years. The main goal of these techniques is to improveperformance; scalability; and manageability of database-driven dynamic websites; in a waythat the quality of data is not compromised. Although caching and materialization are well-understood concepts in the traditional database and networking/operating systemsliterature; the Web and web databases bring forth unique characteristics that warrant newtechniques and approaches. In this monograph; we adopt a data management point of …,Foundations and Trends in Databases,2010,27
Freshness-Aware Scheduling of Continuous Queries in the Dynamic Web.,Mohamed A Sharaf; Alexandros Labrinidis; Panos K Chrysanthis; Kirk Pruhs,ABSTRACT The dynamics of the Web and the demand for new; active services are imposingnew requirements on Web servers. One such new service is the processing of continuousqueries whose output data stream can be used to support the personalization of individualuser's web pages. In this paper; we are proposing a new scheduling policy for continuousqueries with the objective of maximizing the freshness of the output data stream and hencethe QoD of such new services. The proposed Freshness-Aware Scheduling of MultipleContinuous Queries (FAS-MCQ) policy decides the execution order of continuous queriesbased on each query's properties (ie; cost and selectivity) as well the properties of the inputupdate streams (ie; variability of updates). Our experimental results have shown that FAS-MCQ can increase freshness by up to 50% compared to existing scheduling policies used …,WebDB,2005,27
Quality contracts for real-time enterprises,Alexandros Labrinidis; Huiming Qu; Jie Xu,Abstract Real-time enterprises rely on user queries being answered in a timely fashion andusing fresh data. This is relatively easy when systems are lightly loaded and both queriesand updates can be finished quickly. However; this goal becomes fundamentally hard toachieve due to the high volume of queries and updates in real systems; especially in periodsof flash crowds. In such cases; systems typically try to optimize for the average case; treatingall users; queries; and data equally. In this paper; we argue that it is more beneficial for real-time enterprises to have the users specify how to balance such a tradeoff between Quality ofService (QoS) and Quality of Data (QoD); in other words;“instructing” the system on how tobest allocate resources to maximize the overall user satisfaction. Specifically; we proposeQuality Contracts (QC) which is a framework based on the micro-economic paradigm and …,International Workshop on Business Intelligence for the Real-Time Enterprise,2006,26
Quantifiable data mining using principal component analysis,Christos Faloutsos; Flip Korn; Alexandros Labrinidis; Yannis Kotidis; Alex Kaplunovich; Dejan Perkovic,Association Rule Mining algorithms operate on a data matrix (eg; customers x products) toderive rules. We propose a single-pass algorithm for mining linear rules in such a matrixbased on Principal Component Analysis. PCA detects correlated columns of the matrix;which correspond to; eg; products that sell together. The first contribution of this work is thatwe propose to quantify the``goodness''of a set of discovered rules. We define the``guessingerror'': the root-mean-square error of the reconstructed values of the cells of the given matrix;when we pretend that they are unknown. The second contribution is a novel method toguess missing/hidden values from the linear rules that our method derives. For example; ifsomebody bought $10 of milk and $3 of bread; our rules can``guess''the amount spent on;say; butter. Thus; we can perform a variety of important tasks such as forecasting;what-if' …,*,1997,25
Optimized processing of multiple aggregate continuous queries,Shenoda Guirguis; Mohamed A Sharaf; Panos K Chrysanthis; Alexandros Labrinidis,Abstract Data Streams Management Systems are designed to support monitoringapplications; which require the processing of hundreds of Aggregate Continuous Queries(ACQs). These ACQs typically have different time granularities; with possibly differentselection predicates and group-by attributes. In order to achieve scalability in the presenceof heavy workloads; in this paper; we introduce the concept of'Weaveability'as an indicator ofthe potential gains of sharing the processing of ACQs. We then propose Weave Share; acost-based optimizer that exploits weaveability to optimize the shared processing of ACQs.Our experimental analysis shows that Weave Share outperforms the alternative sharingschemes generating up to four orders of magnitude better quality plans. Finally; we describea practical implementation of the Weave Share optimizer.,Proceedings of the 20th ACM international conference on Information and knowledge management,2011,24
Divide et impera: Partitioning unstructured peer-to-peer systems to improve resource location,Harris Papadakis; Paraskevi Fragopoulou; Evangelos P Markatos; Marios Dikaiakos; Alexandros Labrinidis,Abstract Unstructured P2P systems exhibit a great deal of robustness and self-healing at thecost of reduced scalability. Resource location is performed using a broadcast-like processcalled flooding. The work presented in this paper comprises an effort to reduce theoverwhelming volume of traffic generated by flooding; thus increasing the scalability ofunstructured P2P systems. Using a simple hash-based content categorization method theUltrapeer overlay network is partitioned into a relatively small number of distinctsubnetworks. By employing a novel index splitting technique each leaf peer is effectivelyconnected to each different subnetwork. The search space of each individual flooding isrestricted to a single partition; and is thus considerably limited. This reduces significantly thevolume of traffic produced by flooding without affecting at all the accuracy of the search …,*,2008,22
Similarity-aware query processing in sensor networks,Ping Xia; Panos K Chrysanthis; Alexandros Labrinidis,We assume a sensor network with data-centric storage; where sensor data is stored withinthe sensor network and ad hoc queries are disseminated and processed inside the network.In such an environment; there are often similarities among submitted queries. Using currentsolutions; similar queries may have to go through the same expensive query processingsteps thus wasting energy. In this paper; we propose a similarity-aware query processingscheme (SAQP) that materializes previous query results within the sensor network andutilizes these materialized results to answer future similar queries. Through simulation; wedemonstrate that our SAQP scheme reduces energy consumption on queries with negligibleincrease in response time; and without compromising the quality of data,Parallel and Distributed Processing Symposium; 2006. IPDPS 2006. 20th International,2006,21
Tuning query performance in mobile sensor databases,Vladimir Zadorozhny; Divyasheel Sharma; Prashant Krishnmurthy; Alexandros Labrinidis,Abstract In this paper we propose a query-driven approach for tuning the time/energy trade-off in sensor networks with mobile sensors. The tuning factors include re-positioning ofmobile sensors and changing their transmission ranges. We propose an algebraic queryoptimization framework that explores these factors while utilizing collision-free concurrentdata transmissions with different degrees of data filtering and aggregation.,Proceedings of the 6th international conference on Mobile data management,2005,21
Three-level processing of multiple aggregate continuous queries,Shenoda Guirguis; Mohamed A Sharaf; Panos K Chrysanthis; Alexandros Labrinidis,Aggregate Continuous Queries (ACQs) are both a very popular class of Continuous Queries(CQs) and also have a potentially high execution cost. As such; optimizing the processing ofACQs is imperative for Data Stream Management Systems (DSMSs) to reach their fullpotential in supporting (critical) monitoring applications. For multiple ACQs that vary inwindow specifications and pre-aggregation filters; existing multiple ACQs optimizationschemes assume a processing model where each ACQ is computed as a final-aggregationof a sub-aggregation. In this paper; we propose a novel processing model for ACQs; calledTri Ops; with the goal of minimizing the repetition of operator execution at the sub-aggregation level. We also propose Tri Weave; a Tri Ops-aware multi-query optimizer. Weanalytically and experimentally demonstrate the performance gains of our proposed …,Data Engineering (ICDE); 2012 IEEE 28th International Conference on,2012,20
Multi-criteria routing in wireless sensor-based pervasive environments,Qinglan Li; Jonathan Beaver; Ahmed Amer; Panos K Chrysanthis; Alexandros Labrinidis; Ganesh Santhanakrishnan,Wireless sensor networks are expected to be an integral part of any pervasive computingenvironment. This implies an ever-increasing need for efficient energy and resourcemanagement of both the sensor nodes; as well as the overall sensor network; in order tomeet the expected quality of data and service requirements. There have been numerousstudies that have looked at the routing of data in sensor networks with the sole intention ofreducing communication power consumption. However; there has been comparatively littleprior art in the area of multi-criteria based routing that exploit both the semantics of queriesand the state of sensor nodes to improve network service longevity. In this paper; we look atrouting in sensor networks from this perspective and propose an adaptive multi-criteriarouting protocol. Our algorithm offers automated reconfiguration of the routing tree as …,International Journal of Pervasive Computing and Communications,2005,20
Algebraic optimization of data delivery patterns in mobile sensor networks,Vladimir Zadorozhny; Panos K Chrysanthis; Alexandros Labrinidis,Database-like query processing over a network of sensors has become an attractiveparadigm for building sensor applications. A sensor query is characterized by data streamsamong participating sensor nodes with possible in-node data filtering or aggregation; andcan be described as a tree-like data delivery pattern. The data delivery pattern can also beconsidered as a query execution plan; or query routing tree. We propose an algebraicoptimization of the query routing tree construction and reconfiguration. In particular; we aimat generating query trees that maximize collision-free concurrent data transmissions hencereducing energy and time wastes due to retransmissions. Towards this; we introduce a datatransmission algebra (DTA) and apply it for efficient generation of such query trees.,Database and Expert Systems Applications; 2004. Proceedings. 15th International Workshop on,2004,20
A performance evaluation of online warehouse update algorithms,Alexandros Labrinidis; Nick Roussopoulos,Data warehouse maintenance algorithms usually work off-line; making the warehouseunavailable tousers. However; since most organizations require continuous operation; weneed to be able to performthe updates online; concurrently with user queries. To guaranteethat user queries access a consistentview of the warehouse; online update algorithmsintroduce redundancy in order to store multipleversions of the data objects that are beingchanged. In this paper; we present an online warehouseupdate algorithm that storesmultiple versions of data as separate rows (vertical redundancy). Wecompare our algorithmto another online algorithm that stores multiple versions within each tuple byextending thetable schema (horizontal redundancy). We have implemented both algorithms on top ofanInformix Dynamic Server and measured their performance under varying workloads …,*,1998,20
A feedback-based approach to reduce duplicate messages in unstructured peer-to-peer networks,Charis Papadakis; Paraskevi Fragopoulou; Evangelos P Markatos; Elias Athanasopoulos; Marios Dikaiakos; Alexandras Labrinidis,Abstract Resource location in unstructured P2P systems is mainly performed by having eachnode forward each incoming query message to all of its neighbors; a process calledflooding. Although this algorithm has excellent response time and is very simple toimplement; it creates a large volume of unnecessary traffic in today's Internet because eachnode may receive the same query several times through different paths. We propose aninnovative technique; the feedback-based approach that aims to improve the scalability offlooding. The main idea behind our algorithm is to monitor the ratio of duplicate messagestransmitted over each network connection; and not forward query messages overconnections whose ratio exceeds some threshold. Through extensive simulation we showthat this algorithm exhibits significant reduction of traffic in random and small-world …,*,2007,18
Astroshelf: understanding the universe through scalable navigation of a galaxy of annotations,Panayiotis Neophytou; Roxana Gheorghiu; Rebecca Hachey; Timothy Luciani; Di Bao; Alexandros Labrinidis; Elisabeta G Marai; Panos K Chrysanthis,Abstract This demo presents AstroShelf; our on-going effort to enable astrophysicists tocollaboratively investigate celestial objects using data originating from multiple sky surveys;hosted at different sites. The AstroShelf platform combines database and data stream;workflow and visualization technologies to provide a means for querying and displayingtelescope images (in a Google Sky manner); visualizations of spectrum data; and formanaging annotations. In addition to the user interface; AstroShelf supports a programmaticinterface (available as a web service); which allows astrophysicists to incorporatefunctionality from AstroShelf in their own programs. A key feature is Live Annotations whichis the detection and delivery of events or annotations to users in real-time; based on theirprofiles. We demonstrate the capabilities of AstroShelf through real end-user exploration …,Proceedings of the 2012 ACM SIGMOD International Conference on Management of Data,2012,16
Admission control mechanisms for continuous queries in the cloud,Lory Al Moakar; Panos K Chrysanthis; Christine Chung; Shenoda Guirguis; Alexandros Labrinidis; Panayiotis Neophytou; Kirk Pruhs,Amazon; Google; and IBM now sell cloud computing services. We consider the setting of afor-profit business selling data stream monitoring/management services and we investigateauction-based mechanisms for admission control of continuous queries. When submitting aquery; each user also submits a bid of how much she is willing to pay for that query to run.The admission control auction mechanism then determines which queries to admit; and howmuch to charge each user in a way that maximizes system revenue while beingstrategyproof and sybil immune; incentivizing users to use the system honestly. Specifically;we require that each user maximizes her payoff by bidding her true value of having herquery run. We design several payment mechanisms and experimentally evaluate them. Wedescribe the provable game theoretic characteristics of each mechanism alongside its …,Data Engineering (ICDE); 2010 IEEE 26th International Conference on,2010,16
Quality aware query scheduling in wireless sensor networks,Hejun Wu; Qiong Luo; Jianjun Li; Alexandros Labrinidis,Abstract We study query scheduling in Wireless Sensor Networks (WSNs) with a focus ontwo important metrics: Quality of Service (QoS) and Quality of Data (QoD). The motivationcomes from our observation that most WSN scheduling techniques ignore the qualityrequirements of queries. As a result; they are inefficient or inapplicable to quite a fewapplications that have different quality requirements. In this paper; we propose a distributedQuality Aware Scheduling (QAS) framework to address this problem. QAS works on top ofexisting quality-unaware query scheduling protocols and allows individual users to specifytheir QoS and QoD requirements on their queries. Given these quality requirements; QASdetermines the target qualities to be provided in scheduling and the execution order of thesequeries so as to maximize the total system profit. Our preliminary results show that QAS …,Proceedings of the Sixth International Workshop on Data Management for Sensor Networks,2009,16
Self-managing load shedding for data stream management systems,Thao N Pham; Panos K Chrysanthis; Alexandros Labrinidis,Load shedding is an integral component in many Data Stream Management Systems;aiming at preventing the response time from exceeding a user-specified delay target underoverload situations. The currently best performing load shedder determines the correctamount of load to shed by utilizing a feedback loop for correcting the statistics-basedestimations. Although this load shedder outperforms previous works in controlling responsetime as well as minimizing data loss; it requires a manually-tuned parameter and cannotwork with complex query networks containing joins; aggregations or shared operators. Inthis paper; we propose SEaMLeSS-SElf Managing Load Shedding for data Streammanagement systems; which extends and rectifies these limitations of the state-of-the-artload shedder while making it applicable for multi-tenant servers. We implement and …,Data Engineering Workshops (ICDEW); 2013 IEEE 29th International Conference on,2013,14
Optimizing i/o-intensive transactions in highly interactive applications,Mohamed A Sharaf; Panos K Chrysanthis; Alexandros Labrinidis; Cristiana Amza,Abstract The performance provided by an interactive online database system is typicallymeasured in terms of meeting certain pre-specified Service Level Agreements (SLAs); withexpected transaction latency being the most commonly used type of SLA. This form of SLAacts as a soft deadline for each transaction; and user satisfaction can be measured in termsof minimizing tardiness; that is; the deviation from SLA. This objective is further complicatedfor I/O-intensive transactions; where the storage system becomes the performancebottleneck. Moreover; common I/O scheduling policies employed by the Operating Systemwith a goal of improving I/O throughput or average latency may run counter to optimizing per-transaction performance since the Operating System is typically oblivious to the applicationhigh-level SLA specifications. In this paper; we propose a new SLA-aware policy for …,Proceedings of the 2009 ACM SIGMOD International Conference on Management of data,2009,14
Efficient Dissemination of Aggregate Data over the Wireless Web.,Mohamed A Sharaf; Yannis Sismanis; Alexandros Labrinidis; Panos K Chrysanthis; Nick Roussopoulos,ABSTRACT The proliferation of wireless technologies along with the large volume of dataavailable online are forcing us to rethink existing data dissemination techniques for dataover the Web; and in particular for aggregate data. In addition to scalability and responsetime; data delivery to mobile clients with wireless Web connectivity must also considerenergy consumption. In this work; we present a hybrid scheduling algorithm (DV-ES) forbroadcast-based data delivery of aggregate data over the wireless Web. Our algorithmefficiently" packs" aggregate data for broadcast delivery and utilizes view subsumption at themobile client; which allow for faster response times and lower energy consumption.,WebDB,2003,13
The impact of workload clustering on transaction routing,Christos Nikolaou; Alexandros Labrinidis; Volker Bohn; Donald Ferguson; Michalis Artavanis; Christos Kloukinas; Manolis Marazakis,Abstract The qualitative and quantitative description of the workload of a system is veryimportant for capacity planning and performance management. In large-scale transactionprocessing systems; dynamic workload control algorithms are applied to optimize systemperformance. Such algorithms can benefit from the results of workload clustering algorithmsthat partition the workload into classes consisting of units of work exhibiting similarcharacteristics. This paper presents CLUE; a clustering environment for OLTP workloadcharacterization. CLUE provides a library of clustering algorithms that classify transactionsinto classes; according to their database reference patterns. This paper introduces HALC; anew batch-mode heuristic clustering algorithm; designed to cope with the large volume ofinput data that is typical for real-life applications. Next; an on the fly clustering algorithm …,FORTH; Institute of Computer Science; Technical Report,1998,13
Dilos: A dynamic integrated load manager and scheduler for continuous queries,Thao N Pham; Lory Al Moakar; Panos K Chrysanthis; Alexandros Labrinidis,In a Data Stream Management System (DSMS); continuous queries (CQs) registered bydifferent applications inherently have different levels of importance (ie; quality of service(QoS) and quality of data (QoD) requirements). Moreover; the shift to cloud services and thegrowing need for monitoring applications will inevitably lead to the establishment of datastream management cloud services. In such a multi-tenant environment; it is expected thatthe different applications/users will demand different QoS and QoD requirements for theirCQs. In this work; we are proposing an approach that exploits the synergy betweenscheduling and load shedding to effectively handle different ranks of CQ classes; eachassociated with different QoS and QoD requirements. The proposed approach wasimplemented and evaluated within AQSIOS; our DSMS prototype.,Data Engineering Workshops (ICDEW); 2011 IEEE 27th International Conference on,2011,12
Class-based continuous query scheduling for data streams,Lory Al Moakar; Thao N Pham; Panayiotis Neophytou; Panos K Chrysanthis; Alexandros Labrinidis; Mohamed Sharaf,Abstract Wireless sensor networks link the physical and digital worlds enabling bothsurveillance as well as scientific exploration. In both cases; on-line detection of interestingevents can be accomplished with continuous queries (CQs) in a Data Stream ManagementSystem (DSMS). However; the quality-of-service requirements of detecting these events aredifferent for different monitoring applications. The CQs for detecting anomalous events (eg;fire; flood) have stricter response time requirements over CQs which are for logging andkeeping statistical information of physical phenomena. In this work; we are proposing theContinuous Query Class (CQC) scheduler; a new scheduling policy which employs two-level scheduling that is able to handle different ranks of CQ classes. It provides the lowestresponse times for classes of critical CQs; while at the same time keeping reasonable …,Proceedings of the Sixth International Workshop on Data Management for Sensor Networks,2009,12
Towards continuous workflow enactment systems,Panayiotis Neophytou; Panos K Chrysanthis; Alexandros Labrinidis,Abstract Traditional workflow enactment systems and workflow design processes view theworkflow as a one-time interaction with the various data sources; executing a series of stepsonce; whenever the workflow results are requested. The fundamental underlyingassumption has been that data sources are passive and all interactions are structured alongthe request/reply (query) model. Hence; traditional Workflow Management Systems cannoteffectively support business or scientific monitoring applications that require the processingof data streams. In this paper; we propose a paradigm shift from the traditional step-wiseworkflow execution model to a continuous execution model; in order to handle data streamspublished and delivered asynchronously from multiple sources.,International Conference on Collaborative Computing: Networking; Applications and Worksharing,2008,12
Automated service integration for crisis management,Alan Berfield; Panos K Chrysanthis; Alexandros Labrinidis,Abstract The integration and coordination of different emergency service personnel is crucialto Crisis Management. Crisis centers create plans of action to deal with the varioussituations that arise during an event. These plans require different personnel with differentexpertise to execute them within a given set of constraints. In this paper; we show that suchplans can be represented as workflows; and that the discovery and integration of personnelcan use a scheme we previously developed for the establishment of virtual enterprises. Animportant extension to our previous work is the introduction of Intelligent PersonalAssistants; or iPAs. iPAs aid in the discovery of appropriate personnel and provide thecoordination between them and the crisis centers. iPAs also assist their users during planexecution by interfacing with different information sources; such as sensor networks; and …,First International Workshop on Databases in Virtual Organizations (DIVO 2004),2004,12
Ce-storm: Confidential elastic processing of data streams,Nick R Katsipoulakis; Cory Thoma; Eric A Gratta; Alexandros Labrinidis; Adam J Lee; Panos K Chrysanthis,Abstract Data Stream Management Systems (DSMS) are crucial for modern high-volume/high-velocity data-driven applications; necessitating a distributed approach toprocessing them. In addition; data providers often require certain levels of confidentiality fortheir data; especially in cases of user-generated data; such as those coming out of physicalactivity/health tracking devices (ie; our motivating application). This demonstration willshowcase Synefo; an infrastructure that enables elastic scaling of DSMS operators; andCryptStream; a framework that provides confidentiality and access controls for data streamswhile allowing computation on untrusted servers; fused as CE-Storm. We will demonstrateboth systems working in tandem and also visualize their behavior over time under differentscenarios.,Proceedings of the 2015 ACM SIGMOD International Conference on Management of Data,2015,10
Adaptive class-based scheduling of continuous queries,Lory Al Moakar; Alexandros Labrinidis; Panos K Chrysanthis,The emergence of Data Stream Management Systems (DSMS) facilitates implementingmany types of monitoring applications via continuous queries (CQs). However; theseapplications usually have different quality-of-service requirements for different CQs. In thiswork; we are proposing the Adaptive Broadcast Disks (ABD) scheduler; a new schedulingpolicy which employs two-level scheduling that can handle different ranks of CQ classes.The ABD scheduler optimizes the weighted average response time of the CQ classes whilestill preserving the relative importance of each class. We demonstrate that ABD outperformsstate-of-the-art schedulers and adapts to changes in the workload without manualintervention.,Data Engineering Workshops (ICDEW); 2012 IEEE 28th International Conference on,2012,10
Demonstrating an evacuation algorithm with mobile devices using an e-scavenger hunt game,Jesse Szwedko; Callen Shaw; Alexander G Connor; Alexandros Labrinidis; Panos K Chrysanthis,Abstract Casualties in emergency situations are often caused by panic and in cases wherebuilding evacuation is required; they are often caused by a disorganized evacuation. Thishas motivated us to design a two-layer indoor evacuation system that takes advantage oftwo technologies all people carry on them; namely; cellular phones with cameras and RFIDcards. The proposed system integrates QR-Code and RFID-based positioning with a routingsystem with mounted terminals and displays for guiding people with RFID tags out of abuilding. People with mobile devices with cameras use an application that resolves QR-Codes into web addresses that point to dynamically generated evacuation instructions. As aproof-of-concept; we have implemented this system with commercially available tools andcomponents as an e-scavenger hunt game which uses SCAVY; our novel evacuation …,Proceedings of the Eighth ACM International Workshop on Data Engineering for Wireless and Mobile Access,2009,10
Panel on mobility in sensor networks,Alexandros Labrinidis; Anthony Stefanidis,Abstract Sensor networks are promising unprecedented levels of access to informationabout the physical world; in real time. Many areas of human activity are starting to see thebenefits of utilizing sensor networks; in almost all such cases; sensor networks are staticallydeployed. The next evolutionary step for sensor networks is to handle mobility in all its forms.This panel aims to identify the benefits from such a step and recognize the resultingresearch challenges.,Proceedings of the 6th international conference on Mobile data management,2005,10
Multiple Query Routing Trees in Sensor Networks.,Andreea Munteanu; Jonathan Beaver; Alexandros Labrinidis; Panos K Chrysanthis,MULTIPLE QUERY ROUTING TREES IN SENSOR NETWORKS Andreea Munteanu; JonathanBeaver; Alexandros Labrinidis; Panos K. Chrysanthis Advanced Data Management TechnologiesLaboratory Department of Computer Science; University of Pittsburgh Pittsburgh; PA 15260;USA {andreea; beaver; labrinid; panos}@cs.pitt.edu ABSTRACT Advances in sensor technologyprovide the opportunity for a wide range of applications not examined before. These advancescome with the realization of many limitations; like energy constraints; communicationlimitations; or sen- sor node failures. To combat these limitations; several so- lutions have beenproposed; most of which organize the sensor nodes into a tree-like configuration that enablesin- network aggregation. These solutions can lead to a heavy energy burden being put on nodeshigher up in the tree; causing node failure and "stranded" nodes; unable to com …,Databases and Applications,2005,10
Reduction of materialized view staleness using online updates,Alexandros Labrinidis; Nick Roussopoulos,Updating the materialized views stored in data warehouses usually implies making thewarehouse unavailable to users. We propose MAUVE; a new algorithm for onlineincremental view updates that uses timestamps and allows consistent read-only access tothe warehouse while it being updated. The algorithm propagates the updates to the viewsmore often than the typical once a day in order to reduce view staleness. We haveimplemented MAUVE top of the Informix Universal Server and used a synthetic workloadgenerator to experiment with various update workloads and different view updatefrequencies. Our results show that; all kinds of update streams benefit from more frequentview updates; instead of just once a day. However; there is a clear maximum for the viewupdate frequency; for which view staleness is minimal.(Also cross-referenced as UMIACS …,*,1998,10
Scheduling continuous queries in data stream management systems,Mohamed A Sharaf; Alexandros Labrinidis; Panos K Chrysanthis,Abstract Recently; several policies have been proposed for scheduling multiple ContinuousQueries (CQs) in a Data Stream Management System (DSMS). The decision on which policyto use plays an important role in shaping the percieved online performance provided by theDSMS. In this tutorial; we provide an overview of different policies employed by current CQschedulers and the performance goals optimized by these policies. Further; we discuss thesalient properties of CQs conisdered by current policies as well as the efficentimplementation of such policies into CQ schedulers. Finally; we present future researchdirections and open problems in CQ scheduling.,Proceedings of the VLDB Endowment,2008,9
ViP: a user-centric view-based annotation framework for scientific data,Qinglan Li; Alexandros Labrinidis; Panos K Chrysanthis,Abstract Annotations play an increasingly crucial role in scientific exploration and discovery;as the amount of data and the level of collaboration among scientists increase. In this paper;we introduce ViP; a user-centric; view-based annotation framework that promotesannotations as first-class citizens. ViP introduces novel ways of propagating annotations;empowering users to express their preferences over the time and network semantics ofannotations. To efficiently support such novel functionality; ViP utilizes database views andintroduces new caching techniques. Through an extensive experimental study on a realsystem; we show that ViP can seamlessly introduce new annotation propagation semanticswhile significantly improving the performance over the current state of the art.,International Conference on Scientific and Statistical Database Management,2008,9
Poster session: ASETS: A self-managing transaction scheduler,Mohamed A Sharaf; Shenoda Guirguis; Alexandros Labrinidis; Kirk Pruhs; Panos K Chrysanthis,User satisfaction determines the success of web-database applications. User satisfactioncan be expressed in terms of expected response time or expected delay. Given the burstyand unpredictable behavior of web user populations; we model user requests astransactions with soft-deadlines. For such a model of user requests with soft-deadlines; thehit ratio is not the most expressive metric. Instead; the average tardiness is a better measurein such cases. In this paper; we propose and evaluate an adaptive self-managing algorithmcalled ASETS; which optimizes for the average tardiness. ASETS prioritize resources asneeded in order to keep users satisfied under varying workloads. Our performanceevaluation shows ASETS to outperform both EDF and SRPT which are known to be optimalfor the under and over utilization system conditions respectively.,Data Engineering Workshop; 2008. ICDEW 2008. IEEE 24th International Conference on,2008,9
Confluence: Implementation and application design,Panayiotis Neophytou; Panos K Chrysanthis; Alexandros Labrinidis,Data streams have become pervasive and data production rates are increasingexponentially; driven by advances in technology; for example the proliferation of sensors;smart phones; and their applications. This fact effectuates an unprecedented opportunity tobuild real-time monitoring and analytics applications; which when used collaboratively andinteractively; will provide insights to every aspect of our environment; both in the businessand scientific domains. In our previous work; we have identified the need for workflowmanagement systems which are capable of orchestrating the processing of multipleheterogeneous data streams; while enabling their users to interact collaboratively with theworkflows in real time. In this paper; we describe CONFLuEnCE (CONtinuous workFLowExeCution Engine); which is an implementation of our continuous workflow model …,Collaborative Computing: Networking; Applications and Worksharing (CollaborateCom); 2011 7th International Conference on,2011,8
Towards a Content-Provider-Friendly Web Page Crawler.,Jie Xu; Qinglan Li; Huiming Qu; Alexandros Labrinidis,ABSTRACT Search engine quality is impacted by two factors: the quality of theranking/matching algorithm used and the freshness of the search engine's index; whichmaintains a “snapshot” of the Web. Web crawlers capture web pages and refresh the index;but this is always a never-ending quest; as web pages get updated frequently (and thushave to be re-crawled). Knowing when to re-crawl a web page is fundamentally linked to thefreshness of the index; given the size of the Web today and the inherent resourceconstraints: re-crawling too frequently leads to wasted bandwidth; recrawling tooinfrequently brings down the quality of the search engine. In this work; we address thescheduling problem for web crawlers; with the objective of optimizing the quality of the index(ie; maximize the freshness probability of the local repository as well as of the index) …,WebDB,2007,8
Architecture-aware graph repartitioning for data-intensive scientific computing,Angen Zheng; Alexandros Labrinidis; Panos K Chrysanthis,Graph partitioning and repartitioning have been widely used by scientists to parallelizecompute-and dataintensive simulations. However; existing graph (re) partitioning algorithmsusually assume homogeneous communication costs among partitions; which contradicts theincreasing heterogeneity in inter-core communication in modern parallel architectures and isfurther exacerbated by increasing dataset sizes (ie; Big Data). To resolve this; we proposean architecture-aware graph repartitioner; called AragonLB. AragonLB considers theheterogeneity in both inter-and intra-node communication while rebalancing the load. Ourexperimental study with a turbulent combustion simulation dataset shows that AragonLB canresult in up to 60% improvement against existing architecture-agnostic graph repartitioners(which assume uniform communication costs among partitions); and the improvement …,Big Data (Big Data); 2014 IEEE International Conference on,2014,7
Quality is in the eye of the beholder: towards user-centric web-databases,Huiming Qu; Jie Xu; Alexandros Labrinidis,Abstract The proliferation of database-driven web sites (or web-databases) has broughtupon a plethora of applications where both Quality of Service (QoS) and Quality of Data(QoD) are of paramount importance to the end users. In our previous work; we haveproposed Quality Contracts; a comprehensive framework for specifying multiple dimensionsof QoS/QoD; we have also developed user-centric admission control and schedulingalgorithms in web databases; whose goal is to maximize overall system performance. In thiswork; we turn our attention to the user side of the equation. Specifically; we propose todemonstrate how the adaptation of Quality Contracts (QCs) by the users can lead to vastlydifferent performance results; both from the user point of view (ie; user satisfaction) and alsofrom the system point of view. Towards this; we propose to structure our demo in the form …,Proceedings of the 2007 ACM SIGMOD international conference on Management of data,2007,7
Description of the adaptive resource management problem; cost functions and performance objectives,G Georgiannakis; C Houstis; S Kapidakis; M Karavassili; A Labrinidis; M Marazakis; E Markatos; M Mavronicolas; C Nikolaou-FORTH; S Chabridon; E Gelenbe-EHEI; E Born-SNI; L Richter; LYDIA Id,! 2 ? one observable path of the system N(t; !; k; i) number of units of work of class i; waiting orunder processing at node k at time t within path (observation) ! D(t; !) decision matrix for unitsof work to be distributed. Value D(t; !; k; i) in row k and column i gives the probability that a unitof work of class i will be distributed to node k; if it appears at time t at the distribution module.B(t; !) preemption matrix for unit of work re-distribution; defining the internal dynamics of thesystem. Value B(t; !; k; i) gives the number of units of work of class i; preempted and reroutedto the distribution algorithm from node k at time t in path !. (t; !) stochastic intensity vector. Value(t; !; i) gives the intensity of preempting units of work of class i from any node … A(t; !; k; i)defines stochastic process A = (A(t))t2R+ counting units of work of class i; arrived at node k upto time t. Ae(t; !; i) defines stochastic process Ae = (A(t))t2R+ counting units of work of …,ESPRIT,1994,7
Automated operator placement in distributed data stream management systems subject to user constraints,Cory Thoma; Alexandros Labrinidis; Adam J Lee,Traditional distributed Data Stream Management Systems assign query operators to sites byoptimizing for some criterion such as query throughput; or network delay. The workpresented in this paper begins to augment this traditional operator placement technique byallowing the user issuing a continuous query to specify a variety of constraints-includingcollocation; upstream/downstream; and tag-or attribute-based constraints-controllingoperator placement within the query network. Given a set of constraints; operators; and sites;four strategies are presented for optimizing the operator placement. An optimal brute forcealgorithm is presented first for smaller cases; followed by linear programming; constraintsatisfaction; and local search strategies. The four methods are compared for speed;accuracy; and efficiency; with constraint satisfaction performing the best; and allowing …,Data Engineering Workshops (ICDEW); 2014 IEEE 30th International Conference on,2014,6
Confluence: Continuous workflow execution engine,Panayiotis Neophytou; Panos K Chrysanthis; Alexandros Labrinidis,Abstract Traditional workflow enactment systems view a workflow as a one-time interactionwith various data sources; executing a series of steps once; whenever the workflow resultsare requested. The fundamental underlying assumption has been that data sources arepassive and all interactions are structured along the request/reply (query) model. Hence;traditional Workflow Management Systems cannot effectively support business or scientificreactive applications that require the processing of continuous data streams. In this demo;we will present our prototype which transforms workflow execution from the traditional step-wise workflow execution model to a continuous execution model; in order to handle datastreams published and delivered asynchronously from multiple sources. We willdemonstrate a supply chain management scenario which takes advantage of our …,Proceedings of the 2011 ACM SIGMOD International Conference on Management of data,2011,6
Online view selection for the web,Alexandros Labrinidis; Nick Roussopoulos,View materialization has been shown to ameliorate the scalability problem of data-intensiveweb servers. However; unlike data warehouses which are off-line during updates; most webservers maintain their back-end databases online and perform updates concurrently withuser accesses. In such environments; the selection of views to materialize must beperformed online; both performance and data freshness should be considered. In this paper;we discuss the Online View Selection problem: select which views to materialize in order tomaximize performance while maintaining freshness at acceptable levels. We define Qualityof Service and Quality of Data metrics and present OVIS (theta); an adaptive algorithm forthe Online View Selection problem. OVIS (theta) evolves the materialization decisions tomatch the constantly changing access/update patterns on the Web. The algorithm is also …,*,2002,6
Focused crawling for the hidden web,Panagiotis Liakos; Alexandros Ntoulas; Alexandros Labrinidis; Alex Delis,Abstract A constantly growing amount of high-quality information resides in databases and isguarded behind forms that users fill out and submit. The Hidden Web comprises all theseinformation sources that conventional web crawlers are incapable of discovering. In order toexcavate and make available meaningful data from the Hidden Web; previous work hasfocused on developing query generation techniques that aim at downloading all the contentof a given Hidden Web site with the minimum cost. However; there are circumstances whereonly a specific part of such a site might be of interest. For example; a politics portal shouldnot have to waste bandwidth or processing power to retrieve sports articles just becausethey are residing in databases also containing documents relevant to politics. In cases likethis one; we need to make the best use of our resources in downloading only the portion …,World Wide Web,2016,5
Planar: Parallel lightweight architecture-aware adaptive graph repartitioning,Angen Zheng; Alexandros Labrinidis; Panos K Chrysanthis,Graph partitioning is an essential preprocessing step in distributed graph computation andscientific simulations. Existing well-studied graph partitioners are designed for static graphs;but real-world graphs; such as social networks and Web networks; keep changingdynamically. In fact; the communication and computation patterns of some graph algorithmsmay vary significantly; even across their different computation phases. This means that theoptimal partitioning changes over time; requiring the graph to be repartitioned periodically tomaintain good performance. However; the state-of-the-art graph (re) partitioners are knownfor their poor scalability against massive graphs. Furthermore; they usually assume ahomogeneous and contention-free computing environment; which is no longer true inmodern high performance computing infrastructures. In this paper; we introduce Planar; a …,Data Engineering (ICDE); 2016 IEEE 32nd International Conference on,2016,5
PARAGON: Parallel Architecture-Aware Graph Partition Refinement Algorithm.,Angen Zheng; Alexandros Labrinidis; Patrick H Pisciuneri; Panos K Chrysanthis; Peyman Givi,ABSTRACT With the explosion of large; dynamic graph datasets from various fields; graphpartitioning and repartitioning are becoming more and more critical to the performance ofmany graph-based Big Data applications; such as social analysis; web search; andrecommender systems. However; well-studied graph (re) partitioners usually assume ahomogeneous and contention-free computing environment; which contradicts the increasingcommunication heterogeneity and shared resource contention in modern; multicore highperformance computing clusters. To bridge this gap; we introduce PARAGON; a parallelarchitecture-aware graph partition refinement algorithm; which mitigates the mismatch bymodifying a given decomposition according to the nonuniform network communication costsand the contentiousness of the underlying hardware topology. To further reduce the …,EDBT,2016,5
Unifying qualitative and quantitative database preferences to enhance query personalization,Roxana Gheorghiu; Alexandros Labrinidis; Panos K Chrysanthis,Abstract Query personalization can be an effective technique in dealing with the datascalability challenge; primarily from the human point of view; ie; making big data easier touse. In order to customize their query results; users need to express their preferences in asimple and user-friendly manner. In this paper; we present a graph-based theoreticalframework and a prototype system that unify qualitative and quantitative preferences; whileeliminating their disadvantages. Our integrated system allows for (1) the specification ofdatabase preferences and the creation of user preference profiles in a user-friendlymanner;(2) the manipulation of preferences of individuals or groups of users and (3) totalordering of the tuples in the database; matching both qualitative and quantitativepreferences; hence significantly increasing the number of tuples covered by the user …,Proceedings of the Second International Workshop on Exploratory Search in Databases and the Web,2015,5
Preferential diversity,Xiaoyu Ge; Panos K Chrysanthis; Alexandros Labrinidis,Abstract The ever increasing supply of data is bringing a renewed attention to querypersonalization. Query personalization is a technique that utilizes user preferences with thegoal of providing relevant results to the users. Along with preferences; diversity is anotherimportant aspect of query personalization especially useful during data exploration. Thegoal of result diversification is to reduce the amount of redundant information included in theresults. Most previous approaches of result diversification focus solely on generating themost diverse results; which do not take user preferences into account. In this paper; wepropose a novel framework called Preferential Diversity (PrefDiv) that aims to support bothrelevancy and diversity of user query results. PrefDiv utilizes user preference models thatreturn ranked results and reduces the redundancy of results in an efficient and flexible …,Proceedings of the Second International Workshop on Exploratory Search in Databases and the Web,2015,5
The Big Data-Same Humans Problem.,Alexandros Labrinidis,Big data is transforming all aspects of the human experience; be it everyday life; scientificexploration and discovery; medicine; business; law; journalism; and decision-making at alllevels of government. On the one hand; big data is primarily driven by computing technology(ie; computing power; data storage capacity; network capacity; etc.) becoming better andcheaper. This trend is captured by Moore's law1 (ie; the observation that; over the history ofcomputing hardware; the number of transistors in a integrated circuit doubles approximatelyevery two years) and by Bezos' law2 (ie; the observation that; over the history of the cloud; aunit of computing power price is reduced by 50% approximately every three years).,CIDR,2015,5
Qmd: exploiting flash for energy efficient disk arrays,Sean M Snyder; Shimin Chen; Panos K Chrysanthis; Alexandros Labrinidis,Abstract Energy consumption for computing devices in general and for data centers inparticular is receiving increasingly high attention; both because of the increasing ubiquity ofcomputing and also because of increasing energy prices. In this work; we propose QMD(Quasi Mirrored Disks) that exploit flash as a write buffer to complement RAID systemsconsisting of hard disks. QMD along with partial on-line mirrors; are a first step towardsenergy proportionality which is seen as the" holy grail" of energy-efficient system design.QMD exhibits significant energy savings of up 31%; as per our evaluation study using realworkloads.,Proceedings of the seventh international workshop on data management on new hardware,2011,5
Power-aware operator placement and broadcasting of continuous query results,Panayiotis Neophytou; Mohamed A Sharaf; Panos K Chrysanthis; Alexandros Labrinidis,Abstract Complex event detection over data streams has become ubiquitous through thewidespread use of sensors; wireless connectivity and the wide variety of end-user mobiledevices. Typically; such event detection is carried out by a data stream management serverexecuting continuous queries; previously submitted by the users. In this paper; we considerthe situation where the end-users submit queries from hand-held devices and the results ofthe continuous queries; which are in the form of individual data streams; are disseminated tothe users over a shared broadcast medium. Specifically; we propose three power-awarequery operator placement algorithms that determine which part of a continuous query plan isexecuted at the data stream management server and which part is executed at the users'wireless device. The algorithms' effectiveness with respect to energy consumption is …,Proceedings of the Ninth ACM International Workshop on Data Engineering for Wireless and Mobile Access,2010,5
A Greek (privacy) tragedy: the introduction of social security numbers in Greece,Eleni Gessiou; Alexandros Labrinidis; Sotiris Ioannidis,Abstract We highlight the privacy issues that have arisen from the introduction of the GreekSocial Security Number (AMKA); in connection with the availability of personally identifiableinformation on Greek web sites. In particular; we identify privacy problems with the currentAMKA setup and present data from a web study we conducted in May 2009; exposing theseproblems. Given the anticipated ubiquity of AMKA in Greece in the future; along the lines ofthe Social Security Number in the US.,Proceedings of the 8th ACM workshop on Privacy in the electronic society,2009,5
User-centric annotation management for biological data,Qinglan Li; Alexandros Labrinidis; Panos K Chrysanthis,Abstract Annotations play an increasingly crucial role in scientific exploration and discovery;as the amount of data and the level of collaboration among scientists increases. Although allsuch systems are implemented to take user input (ie; the annotations themselves); very fewsystems are user-centric; taking into account user preferences on how annotations shouldpropagate and be applied over data. In this paper; we propose to treat annotations as first-class citizens for biological data management by presenting a user− centric; view− basedannotation framework; called ViP. Under the ViP framework we consider user preferencesover the time semantics of annotations (by supporting future annotations) and over thenetwork semantics of annotations (by supporting both implicitly-defined and explicitly-defined annotation propagation paths). In addition to novel functionality; we describe a …,International Provenance and Annotation Workshop,2008,5
Replication-aware query processing in large-scale distributed information systems,Jie Xu; Alexandros Labrinidis,ABSTRACT In this work; we address the problem of replica selection in distributed queryprocessing over the Web; in the presence of user preferences for Quality of Service andQuality of Data. In particular; we propose RAQP; which stands for Replication-Aware QueryProcessing. RAQP uses an initial statically-optimized logical plan; and then selects theexecution site for each operator and also selects which replica to use; thus converting thelogical plan to an executable plan. Unlike prior work; we do not perform an exhaustivesearch for the second phase; which allows RAQP to scale significantly better. Extensiveexperiments show that our scheme can provide improvements in both query response timeand overall quality of QoS and QoD as compared to random site allocation with iterativeimprovement.,International Workshop on Web and Databases,2006,5
Secure-citi critical information-technology infrastructure,Daniel Mossé; Louise Comfort; Ahmed Amer; José C Brustoloni; Panos K Chrysanthis; Milos Hauskrecht; Alexandros Labrinidis; Rami Melhem; Kirk Pruhs,Abstract The Secure and robust Critical Information-Technology Infrastructure (S-CITI forshort) project aims at providing support to Emergency Managers (EMs) that are faced withmanagement of resources and with decisions before; during; and after emergencies ordisasters. Our approach consists of using new and existing sensors to gather data from thefield; processing this data to detect and predict emergency/disaster situations; anddisseminating this data among the appropriate organizational units. The data flow will bedone in a reliable and secure manner and EMs will coordinate actions in a VirtualCoordination Center (VCC); which need not be in a fixed (and thus vulnerable) physicallocation. The EMs are responsible for indicating what type of data is more valuable; so that S-CITI can display that information appropriately.,Proceedings of the 2006 international conference on Digital government research,2006,5
Argo: Architecture-aware graph partitioning,Angen Zheng; Alexandros Labrinidis; Panos K Chrysanthis; Jack Lange,The increasing popularity and ubiquity of various large graph datasets has caused renewedinterest for graph partitioning. Existing graph partitioners either scale poorly against largegraphs or disregard the impact of the underlying hardware topology. A few solutions haveshown that the nonuniform network communication costs may affect the performance greatly.However; none of them considers the impact of resource contention on the memorysubsystems (eg; LLC and Memory Controller) of modern multicore clusters. They all neglectthe fact that the bandwidth of modern high-speed networks (eg; Infiniband) has becomecomparable to that of the memory subsystems. In this paper; we provide an in-depthanalysis; both theoretically and experimentally; on the contention issue for distributedworkloads. We found that the slowdown caused by the contention can be as high as 11x …,Big Data (Big Data); 2016 IEEE International Conference on,2016,4
Processing of aggregate continuous queries in a distributed environment,Anatoli U Shein; Panos K Chrysanthis; Alexandros Labrinidis,Abstract. Data Stream Management Systems (DSMSs) performing online analytics rely onthe efficient execution of large numbers of Aggregate Continuous Queries (ACQs). In thispaper; we study the problem of generating high quality execution plans of ACQs in DSMSsdeployed on multi-node (multi-core and multi-processor) distributed environments. Towardsthis goal; we classify optimizers based on how they partition the workload among computingnodes and on their usage of the concept of Weavability; which is utilized by the state-ofthe-art WeaveShare optimizer to selectively combine ACQs and produce low cost executionplans for single-node environments. For each category; we propose an optimizer; whicheither adopts an existing strategy or develops a new one for assigning and grouping ACQsto computing nodes. We implement and experimentally compare all of our proposed …,*,2015,4
Large-Scale Overlays and Trends: Visually Mining; Panning and Zoomingthe Observable Universe,Timothy Basil Luciani; Brian Cherinka; Daniel Oliphant; Sean Myers; W Michael Wood-Vasey; Alexandros Labrinidis; G Elisabeta Marai,We introduce a web-based computing infrastructure to assist the visual integration; miningand interactive navigation of large-scale astronomy observations. Following an analysis ofthe application domain; we design a client-server architecture to fetch distributed image dataand to partition local data into a spatial index structure that allows prefix-matching of spatialobjects. In conjunction with hardware-accelerated pixel-based overlays and an online cross-registration pipeline; this approach allows the fetching; displaying; panning and zooming ofgigabit panoramas of the sky in real time. To further facilitate the integration and mining ofspatial and non-spatial data; we introduce interactive trend images-compact visualrepresentations for identifying outlier objects and for studying trends within large collectionsof spatial objects of a given class. In a demonstration; images from three sky surveys …,IEEE transactions on visualization and computer graphics,2014,4
Optimizing the energy consumption of continuous query processing with mobile clients,Panayiotis Neophytou; Jesse Szwedko; Mohamed A Sharaf; Panos K Chrysanthis; Alexandros Labrinidis,Complex event detection over data streams has become ubiquitous through the widespreaduse of sensors; wireless connectivity and the wide variety of end-user mobile devices.Typically; such event detection is carried out by a data stream management systemexecuting continuous queries (CQs); registered by the users. In this paper; we consider thesituation where the results of the CQs; which are in the form of individual data streams; aredisseminated to the users' hand-held; battery-operated devices over a shared broadcastmedium. In order to reduce the overall energy consumption of the mobile devices; wepropose Bose*; a power-aware query operator placement algorithm that determines whichpart of a CQ plan should be executed at the data stream management system and whichpart should be executed at the mobile device. Bose*'s effectiveness in reducing energy …,Mobile Data Management (MDM); 2011 12th IEEE International Conference on,2011,4
Tuning qod in stream processing engines,Mohamed A Sharaf; Panos K Chrysanthis; Alexandros Labrinidis,Abstract Quality of Service (QoS) and Quality of Data (QoD) are the two major dimensions forevaluating any query processing system. In the context of data stream management systems(DSMSs); multi-query scheduling has been exploited to improve QoS. In this paper; we areproposing to exploit query scheduling to improve QoD in DSMSs. Specifically; we arepresenting a new policy for scheduling multiple continuous queries with the objective ofmaximizing the freshness of the output data streams and hence the QoD of such outputs.The proposed Freshness-Aware Scheduling of Multiple Continuous Queries (FAS-MCQ)policy decides the execution order of continuous queries based on each query's properties(ie; cost and selectivity) as well the properties of the input update streams (ie; variability ofupdates). Our experimental results have shown that FAS-MCQ can improve QoD by up to …,Proceedings of the Twenty-First Australasian Conference on Database Technologies-Volume 104,2010,4
Polystream: Cryptographically enforced access controls for outsourced data stream processing,Cory Thoma; Adam J Lee; Alexandros Labrinidis,Abstract With data becoming available in larger quantities and at higher rates; new dataprocessing paradigms have been proposed to handle high-volume; fast-moving data. DataStream Processing is one such paradigm wherein transient data streams flow through setsof continuous queries; only returning results when data is of interest to the querier. To avoidthe large costs associated with maintaining the infrastructure required for processing thesedata streams; many companies will outsource their computation to third-party cloud services.This outsourcing; however; can lead to private data being accessed by parties that a dataprovider may not trust. The literature offers solutions to this confidentiality and access controlproblem but they have fallen short of providing a complete solution to these problems; due toeither immense overheads or trust requirements placed on these third-party services. To …,Proceedings of the 21st ACM on Symposium on Access Control Models and Technologies,2016,3
Avoiding class warfare: managing continuous queries with differentiated classes of service,Thao N Pham; Panos K Chrysanthis; Alexandros Labrinidis,Abstract Data stream management systems (DSMSs) offer the most effective solution forprocessing data streams by efficiently executing continuous queries (CQs) over theincoming data. CQs inherently have different levels of criticality and hence different levels ofexpected quality of service (QoS) and quality of data (QoD). Adhering to such expectedQoS/QoD metrics is even more important in cases of multi-tenant data stream managementservices. In this work; we propose DILoS; a framework that; through priority-basedscheduling and load shedding; supports differentiated QoS and QoD for multiple classes ofCQs. Unlike existing works that consider scheduling and load shedding separately; DILoS isa novel unified framework that exploits the synergy between scheduling and load shedding.We also propose ALoMa; a general; adaptive load manager that DILoS is built upon. By …,The VLDB Journal,2016,3
A user-friendly framework for database preferences,Roxana Gheorghiu; Alexandros Labrinidis; Panos K Chrysanthis,Data drives all aspects of our society; from everyday life; to business; to medicine; andscience. It is well known that query personalization can be an effective technique in dealingwith the data scalability challenge; primarily from the human point of view. In order tocustomize their query results; users need to express their preferences in a simple and user-friendly manner. There are two types of preferences: qualitative and quantitative. Eachpreference type has advantages and disadvantages with respect to expressiveness. In thispaper; we present a graph-based theoretical framework and a prototype system that unifyqualitative and quantitative preferences; while eliminating their disadvantages. Ourintegrated system allows for (1) the specification of database preferences and creation ofuser preference profiles in a user-friendly manner and (2) the manipulation of preferences …,Collaborative Computing: Networking; Applications and Worksharing (CollaborateCom); 2014 International Conference on,2014,3
Database preferences-a unified model,Roxana Gheorghiu; Alexandros Labrinidis; Panos K Chrysanthis,ABSTRACT In this work we present a new model that combines two different types ofpreferences; qualitative and quantitative. We show how our model can support differenttypes of preferences at different granularity levels and how can an application use thesepreferences to retrieve a list of tuples. The new model takes advantage of graphrepresentation of preferences where nodes in the graph are SQL predicates; edges betweentwo nodes describe a qualitative preference and edges from a node to the same nodecapture quantitative preferences. Each edge is labeled with a numeric value; between-1 and1; to express the intensity of each preference. Using this graph representation we furthershow how two different preferences can be combined and applied to the existing queryresult set to filter the result and identify the most relevant tuples first.,PersDB,2012,3
Scheduling update and query transactions under quality contracts in web-databases,Huiming Qu; Alexandros Labrinidis,ABSTRACT In modern web-database systems; users typically perform readonly queries;whereas all data updates are performed in the background; concurrently with queries. In thispaper; we present the concept of Quality Contracts which allows individual users to expresstheir preferences by assigning “profit” values to their expected Quality of Service (QoS) andQuality of Data (QoD). We propose an adaptive algorithm; called QUTS; to maximize thetotal profit from submitted Quality Contracts; which essentially optimizes the overall usersatisfaction. QUTS address the problem of prioritizing the scheduling of updates (crucial toQoD) over queries (crucial to both QoS and QoD) using a two-level scheduling scheme thatdynamically allocates CPU resources to updates and queries. We present the results of anextensive experimental study using real data (taken from a stock information web site) …,Proceedings of the 5th Hellenic Data Management Symposium (HDMS’06),2006,3
Multi-criteria routing in pervasive environment with sensors,Ganesh Santhanakrishnan; Qinglan Li; Jonathan Beaver; Panos K Chrysanthis; Ahmed Amer; Alexandros Labrinidis,Interconnected computing nodes in pervasive systems demand efficient management toensure longevity and effectiveness. This is particularly true when we consider wirelesssensor networks; for which we propose a new scheme for adaptive route management.There have been numerous studies that have looked at the routing of data in sensornetworks with the sole intention of reducing communication power. However there has beencomparatively less prior art in the area of semantic and multi-criteria based routing. We lookat routing in sensor networks from these perspectives and propose an adaptive multi-criteriarouting protocol in the context of wireless sensor networks. Our experimental results showthat our approach consistently outperforms the leading multi-criteria algorithm in its classthat considers query semantics; in terms of network lifetime; network coverage and the …,Pervasive Services; 2005. ICPS'05. Proceedings. International Conference on,2005,3
F1: Accelerating the Optimization of Aggregate Continuous Queries,Anatoli U Shein; Panos K Chrysanthis; Alexandros Labrinidis,Abstract Data Stream Management Systems performing on-line analytics rely on the efficientexecution of large numbers of Aggregate Continuous Queries (ACQs). The state-of-the-artWeaveShare optimizer uses the Weavability concept in order to selectively combine ACQsfor partial aggregation and produce high quality execution plans. However; WeaveSharedoes not scale well with the number of ACQs. In this paper we propose a novel closedformula; F1; that accelerates Weavability calculations; and thus allows WeaveShare toachieve exceptional scalability in systems with heavy workloads. In general; F1 can reducethe computation time of any technique that combines partial aggregations within compositeslides of multiple ACQs. We theoretically analyze the Bit Set approach currently used byWeaveShare and show that F1 is superior in both time and space complexities. We show …,Proceedings of the 24th ACM International on Conference on Information and Knowledge Management,2015,2
A continuous workflow scheduling framework,Panayiotis Neophytou; Panos K Chrysanthis; Alexandros Labrinidis,Abstract Traditional workflow management or enactment systems (WfMS) and workflowdesign processes view the workflow as a one-time interaction with the various data sources;ie; when a workflow is invoked; its steps are executed once and in-order. The fundamentalunderlying assumption has been that data sources are passive and all interactions arestructured along the request/reply (query) model. Hence; traditional WfMS cannot effectivelysupport business or scientific monitoring applications that require the processing of datastreams such as those generated nowadays by sensing devices as well as mobile and webapplications. Our hypothesis is that WfMS; both in the scientific and business domains; canbe extended to support data stream semantics to enable monitoring applications. Thisincludes the ability to apply flexible bounds on unbounded data streams and the ability to …,Proceedings of the 2nd ACM SIGMOD Workshop on Scalable Workflow Execution Engines and Technologies,2013,2
Panning and zooming the observable universe with prefix-matching indices and pixel-based overlays,Timothy Luciani; Boyu Sun; Brian Cherinka; W Michael Wood-Vasey; G Elisabeta Marai; Sean Myers; Alexandros Labrinidis,We introduce a web-based; client-server computing infrastructure to assist the interactivenavigation of large-scale astronomy observations. Large image datasets are partitioned intoa spatial index structure that allows prefix-matching of spatial objects. In conjunction withpixel-based overlays; this approach allows fetching; displaying; panning and zooming ofgigabit panoramas of the sky in real time. Images from three sky surveys (SDSS; FIRST andsimulated LSST results) are cross-registered and integrated as overlays; allowing cross-spectrum analysis of astronomy observations. The front-end of the infrastructure uses theweb technologies We-bGL and HTML5 to enable cross-platform; web-based functionality.Our approach attains interactive rendering framerates; its power and flexibility enables us toserve the needs of the astronomy community. Evaluation on a galaxy case study; as well …,Large Data Analysis and Visualization (LDAV); 2012 IEEE Symposium on,2012,2
Key-key-value stores for efficiently processing graph data in the cloud,Alexander G Connor; Panos K Chrysanthis; Alexandros Labrinidis,Modern cloud data storage services have powerful capabilities for data-sets that can beindexed by a single key-key-value stores-and for data-sets that are characterized by multipleattributes (such as Google's BigTable). These data stores have non-ideal overheads;however; when graph data needs to be maintained; overheads are incurred because related(by graph edges) keys are managed in physically different host machines. We propose anew distributed data-storage paradigm; the key-key-value store; which will extend the key-value model and significantly reduce these overheads by storing related keys in the sameplace. We provide a high-level description of our proposed system for storing large-scale;highly interconnected graph data-such as social networks-as well as an analysis of our key-key-value system in relation to existing work. In this paper; we show how our novel data …,Data Engineering Workshops (ICDEW); 2011 IEEE 27th International Conference on,2011,2
Guiding personal choices in a quality contracts driven query economy,Huiming Qu; Jie Xu; Alexandros Labrinidis,ABSTRACT The emergence of Web 2.0 has brought upon a plethora of databasedriven webapplications and services where both Quality of Service (QoS) and Quality of Data (QoD) areof paramount importance to end users. In our previous work; we have proposed QualityContracts; a comprehensive framework for specifying multiple dimensions of QoS/QoD; wehave also developed algorithms to maximize overall system performance under QualityContracts. In this work; we turn our attention to the user side of the equation; on how tochoose and adapt Quality Contracts to better serve users' needs in the presence of otherusers; who are competing for the same resources; in a virtual “economy” of Quality Contractsat the server. Towards this; we propose the Adaptive Quality Contract (AQC) scheme tomaximize the success ratio of user queries. AQC switches between its Overbid …,PersDB Workshop; SIGMOD Conference,2009,2
Efficient handling of sensor failures,Andreea Berfield; Panos K Chrysanthis; Alexandros Labrinidis,Abstract Sensors provide unprecedented access to a wealth of information from the physicalenvironment in real-time. However; they suffer from a variety of resource limitations; mostimportantly power consumption and communication bandwidth. Additionally; environmentalconditions can contribute to sensor failures; disrupting the flow of query results. In this paper;we propose new techniques to deal with sensor failures based on the principles of partitionand single path redundancy. Our experimental results confirm the efficiency of ourtechniques with respect to different performance metrics in general; and; in particular; highquality of data.,Proceedings of the 3rd workshop on Data management for sensor networks: in conjunction with VLDB 2006,2006,2
Data Transmission Algebra for Collision-Aware Scheduling in Sensor Networks,V Zadorozhny; Divyasheel Sharma; P Chrysanthis; Alexandros Labrinidis,Sensor databases extend database technology to query and monitor the physical world as ahighly distributed database. In this paper we consider a Data Transmission Algebra (DTA)that allows a query optimizer to utilize lower layer communication protocols in schedulingsensor database queries. By being able to determine the order in which data are processedat sensor nodes and transmitted between sensor nodes in a query routing tree; a queryoptimizer can both improve the response time and reduce the energy consumption perquery. We use a logical framework to specify DTA semantics and to prove its soundness andcompleteness. Further; we prove that DTA query execution schedules have the key propertyof being collision-free.,Formal Methods in Compositional infrastructures of Heterogeneous Distributed Information Systems; Russian Academy of Science Publ,2005,2
Secure-CITI: A Secure Critical Information Technology Infrastructure for Disaster Management,Ahmed Amer; J Brustoloni; PK Chrysanthis; Milos Hauskrecht; Alexandros Labrinidis; Rami Melhem; Daniel Mossé; Kirk Pruhs; Louise Comfort,Real-Time operation: temporal requirements; monitoring in real-time; responses cannot bedelayed too much; information cannot be stale Reliability and Self-Healing: system shouldbe robust to failures and other unexpected events (nature of disasters!) Efficiency andScalability: size is predicted to be astronomical (millions of sensors; lots of data traffic) cliche:need the right data at the right time for the right people,Hazard Reduction and Response in Metropolitan Regions: An Interdisciplinary Model; Workshop and Interactive Videoconference among Metropolitan Regions,2003,2
View materialization for the web,Alexandros Labrinidis,Abstract The frustration of broken links from the early Web has been replaced today by thefrustration of web servers stalling or crashing under the heavy load of dynamically generatedcontent. Even seemingly static web pages are usually generated dynamically in order toinclude personalization and advertising features. Such dynamic content has high resourcedemands and poses a scalability problem for both web and database servers.,*,2002,2
Uninterruptible migration of continuous queries without operator state migration,Thao N Pham; Nikos R Katsipoulakis; Panos K Chrysanthis; Alexandros Labrinidis,ABSTRACT The elasticity brought by cloud infrastructure provides a promising solution for adata stream management system to handle its incoming workload; which can be highlyvariable: the system can scale out when heavily loaded; and scale in otherwise. In such asolution; the efficiency of the mechanism used to migrate a query from one node to anotheris very important. Generally; a stream application requires real-time outputs for itscontinuous queries; and downtime is not acceptable. Moreover; the migration should notadd considerable processing cost to a node that could have been already overloaded. Inthis paper; we present our migration protocol; named UniMiCo; which satisfies thoserequirements. We implemented UniMiCo in a DSMS prototype and experimentally show thatthe protocol preserves correctness; while introducing no noticeable changes in the …,ACM SIGMOD Record,2017,1
A holistic view of stream partitioning costs,Nikos R Katsipoulakis; Alexandros Labrinidis; Panos K Chrysanthis,Abstract Stream processing has become the dominant processing model for monitoring andreal-time analytics. Modern Parallel Stream Processing Engines (pSPEs) have made itfeasible to increase the performance in both monitoring and analytical queries byparallelizing a query's execution and distributing the load on multiple workers. A determiningfactor for the performance of a pSPE is the partitioning algorithm used to disseminate tuplesto workers. Until now; partitioning methods in pSPEs have been similar to the ones used inparallel databases and only recently load-aware algorithms have been employed to improvethe effectiveness of parallel execution. We identify and demonstrate the need to incorporateaggregation costs in the partitioning model when executing stateful operations in parallel; inorder to minimize the overall latency and/or through-put. Towards this; we propose new …,Proceedings of the VLDB Endowment,2017,1
Flatfit: Accelerated incremental sliding-window aggregation for real-time analytics,Anatoli U Shein; Panos K Chrysanthis; Alexandros Labrinidis,Abstract Data stream processing is becoming essential in most current advanced scientificor business applications as data production rates are increasing. Different companiescompete to efficiently ingest high velocity data and apply some form of computation in orderto make better business decisions. In order to successfully compete in this environment;companies are focusing on the most recent data within a count or time-based window bycontinuously executing aggregate queries on it. Incremental sliding-window computation iscommonly used to avoid the performance implications of re-evaluating the aggregate valueof the window from scratch on every update. The state-of-the-art FlatFAT technique executesACQs with high efficiency but it does not scale well with the increasing workloads. In thispaper we propose a novel algorithm; FlatFIT; that accelerates such calculations by …,Proceedings of the 29th International Conference on Scientific and Statistical Database Management,2017,1
Interactive Exploration of Correlated Time Series,Daniel Petrov; Rakan Alseghayer; Mohamed Sharaf; Panos K Chrysanthis; Alexandros Labrinidis,Abstract The rapid growth of monitoring applications has led to unprecedented amounts ofgenerated time series data. Data analysts typically explore such large volumes of time seriesdata looking for valuable insights. One such insight is finding pairs of time series; in whichsubsequences of values exhibit certain levels of correlation. However; since exploratoryqueries tend to be initially vague and imprecise; an analyst will typically use the results ofone query as a springboard to formulating a new one; in which the correlation specificationsare further refined. As such; it is essential to provide analysts with quick initial results to theirexploratory queries; which allows for speeding up the refinement process. This goal ischallenging when exploring the correlation in a large search space that consists of a bignumber of long time series. In this work we propose search algorithms that address …,Proceedings of the ExploreDB'17,2017,1
Repartitioning Strategies for Massively Parallel Simulation of Reacting Flow,Patrick Pisciuneri; Angen Zheng; Peyman Givi; Alexandros Labrinidis; Panos Chrysanthis,Abstract The majority of parallel CFD simulators partition the domain into equal regions andassign the calculations for a particular region to a unique processor. This type of domaindecomposition is vital to the efficiency of the solver. However; as the simulation develops;the workload among the partitions often become uneven (eg by adaptive mesh refinement;or chemically reacting regions) and a new partition should be considered. The process ofrepartitioning adjusts the current partition to evenly distribute the load again. We comparetwo repartitioning tools: Zoltan; an architecture-agnostic graph repartitioner developed at theSandia National Laboratories; and Paragon; an architecture-aware graph repartitionerdeveloped at the University of Pittsburgh. The comparative assessment is conducted viasimulation of the Taylor-Green vortex flow with chemical reaction.,APS Division of Fluid Dynamics Meeting Abstracts,2015,1
Stream query processing on emerging memory architectures,Chelsea Mafrica; John Johnson; Santiago Bock; Thao N Pham; Bruce R Childers; Panos K Chrysanthis; Alexandros Labrinidis,Stream query processing is becoming increasingly important as more time-oriented data isproduced and analyzed online. Stream processing is typically memory-resident for thefastest processing of ephemeral data. With workload consolidation; processing separatedata streams on the same processor may lead to harmful contention between queryworkloads. This contention may become particularly problematic as new main memorytechnologies are adopted; such as phase-change memory; that have asymmetric read andwrite latency. This work presents a preliminary study of performance implications ofconsolidation and emerging memory on stream query processing. We show that contentionin the memory subsystem worsens with a phase-change main memory; suggesting that newstream optimization and hardware approaches will be required to achieve quality of …,Non-Volatile Memory System and Applications Symposium (NVMSA); 2015 IEEE,2015,1
Web views,Alexandros Labrinidis,W3C was founded in 1994 by the inventor of the World Wide Web Tim Berners-Lee as avendor-neutral forum for building consensus around Web technologies. The consortiumconsists of member organization and dedicated staff of technical experts. Membership isopen to any organization or individual whose application is reviewed and approved by theW3C. Usually W3C members invest significant resources into the Web technologies. W3Cfulfils its mission by creation of recommendations enjoying status of international standards.In the first 10 years of existence; it produced over eighty W3C recommendations. W3C isresponsible for such technologies as HTML; XHTML; XML; XML Schema; CSS; SOAP;WSDL and others. W3C members play a leading role in the development of therecommendations. W3C initiatives involve international; national; and regional …,*,2009,1
QuickStack: A Fast Algorithm for XML Query Matching,Iyad Batal; Alexandros Labrinidis,Abstract With the increasing popularity of XML for data representation and exchange; muchresearch has been done for providing an efficient way to evaluate twig patterns in an XMLdatabase. As a result; many holistic join algorithms have been developed; most of which arederivatives of the well-known TwigStack algorithm. However; these algorithms still apply atwo phase processing scheme: first identify all root-toleaf path solutions and then join theseintermediate solutions to form the twig results. In this paper; we first propose a novelalgorithm; QuickStack; for matching single path queries. The proposed algorithm extensivelyoptimizes the PathStack algorithm by effectively skipping the ancestor and descendantelements that do not participate in the results. Secondly; we generalize QuickStack toanswer twig pattern queries. Unlike the previous algorithms; QuickStack joins the …,Department of Computer Science University of Pittsburgh,2008,1
Journal of Metals,CM Brown; RW Fountain,*,*,1958,1
Detection of Highly Correlated Live Data Streams,Rakan Alseghayer; Daniel Petrov; Panos K Chrysanthis; Mohamed Sharaf; Alexandros Labrinidis,Abstract More and more organizations (commercial; health; government and security)currently base their decisions on real-time analysis of fast arriving; large volumes of datastreams. For such analysis to lead to actionable information in real-time and at the right time;the most recent data needs to be processed within a specified delay target. Effectivesolutions for analysis of such data streams rely on two techniques;(1) incremental sliding-window computation of aggregates; to avoid unnecessary recomputations and (2) intelligentscheduling of computational steps and operations. In this paper; we propose a solution thatcombines both of these techniques to find highly correlated data streams in real-time; usingthe Pearson Correlation Coefficient as a correlation metric for two windows of data streams.Specifically; we propose to partition a set of data streams into micro-batches that capture …,Proceedings of the International Workshop on Real-Time Business Intelligence and Analytics,2017,*
Skew-Resistant Graph Partitioning,Angen Zheng; Alexandros Labrinidis; Christos Faloutsos,Large graph datasets have caused renewed interest for graph partitioning. However;existing well-studied graph partitioners often assume that vertices of the graph are alwaysactive during the computation; which may lead to time-varying skewness for traversal-stylegraph workloads; like Breadth First Search; since they only explore part of the graph in eachsuperstep. Additionally; existing solutions do not consider what vertices each partition willhave; as a result; high-degree vertices may be concentrated into a few partitions; causingimbalance. Towards this; we introduce the idea of skew-resistant graph partitioning; wherethe objective is to create an initial partitioning that will" hold well" over time without sufferingfrom skewness. Skewresistant graph partitioning tries to mitigate skewness by taking thecharacteristics of both the target workload and the graph structure into consideration.,Data Engineering (ICDE); 2017 IEEE 33rd International Conference on,2017,*
Technical Sessions of NVMSA,Edwin Sha; Xianzhang Chen; Qingfeng Zhuge; Liang Shi; Weiwen Jiang; Bruce Childers; Chelsea Mafrica; John Johnson; Santiago Bock; Thao Pham; Panos Chrysanthis; Alexandros Labrinidis; Xianlu Luo; Duo Liu; Liang Liang; Yang Li; Kan Zhong; Linbo Long; Byunghei Jun; Dongkun Shin; Xiao Zhu; Xiaojun Cai; Lei Ju; Xin Li; Zhiyong Zhang; Zhiping Jia; Yi Ran; Wang Kang; Youguang Zhang; Jacques-Olivier Klein; Weisheng Zhao; Huizhang Luo; Mengying Zhao; Chun Xue; Rami Melhem; Daniel Mosse,Page 1. Program At A Glance August 19; 2015 08:30‐09:30 Registration 09:30‐10:30 JointKeynote 1: Fast Data Accesses in Memory and Storage; Prof. Xiaodong Zhang 10:30‐11:00 CoffeeBreak 11:00‐12:30 Session1: NVM-Aware File Systems and Data Processing (Room: AAB204)12:30‐14:30 Lunch 14:30‐16:00 Session 2: I/O Scheduling and Wear Leveling (Room: AAB204)16:00‐16:30 Coffee Break 16:30‐18:00 Session 3: Architectural/Circuit Exploitation andOptimization (Room: AAB204) 18:30‐20:00 Reception August 20; 2015 08:30‐09:30 Registration09:30‐10:30 Joint Keynote 2：When Bits meet Joules: A view from data center operations'perspective; Prof. Xue (Steve) Liu 10:30‐11:00 Coffee Break 11:00‐12:30 Invited Session 1:Emerging NVM and Nonvolatile Processors (Room: AAB204) 12:30‐14:30 Lunch 14:30‐16:30Poster Session (Room: AAB205) 16:30‐18:00 Local Tour 18:30‐20:00 Banquet …,*,2015,*
CryptStream: Cryptographic Access Controls for Streaming Data,Cory Thoma; Adam J Lee; Alexandros Labrinidis,Abstract With data becoming available in larger quantities and at higher rates; new dataprocessing paradigms have been proposed to handle large and fast data. Data StreamProcessing is one such paradigm wherein transient data flows as streams through sets ofcontinuous queries; only returning results when data is of interest to the querier; allowinguninteresting data to be ignored. To process these data streams; users are employing thirdparty computational platforms or large private platforms to reduce the individual cost forquerying and computing over data streams. Utilizing third parties for outsourcingcomputation means data being processed is available to the third party as well; which couldviolate the data provider's privacy. There has been research done into access control forstreaming data; and these works provide a good first step; but fall short of a complete …,Proceedings of the 5th ACM Conference on Data and Application Security and Privacy,2015,*
Towards automated personalized data storage,John Lange; Alexandros Labrinidis; Panos K Chrysanthis,User data is growing at an ever greater pace that threatens to overwhelm our ability toeffectively manage it. As the types of data increase; and the storage environments becomeever more heterogeneous; even reasoning about basic data management decisionsbecomes increasingly difficult. This expansion in complexity requires new methodologies formanaging data that alleviate as much of the burden as possible from the individual user.Instead of requiring users to understand their full collection of data and the underlyingstorage architectures; future storage systems need to be able to decide on their own how tomanage individual files both in terms of the appropriate storage medium as well as thenecessary file operation semantics. In this paper we present a vision for future storagesystems that address the dramatic increase in complexity and volume by providing …,Data Engineering Workshops (ICDEW); 2014 IEEE 30th International Conference on,2014,*
Education and career paths for data scientists,Magdalena Balazinska; Susan B Davidson; Bill Howe; Alexandros Labrinidis,Abstract MOTIVATION: As industry and science are increasingly data-driven; the need forskilled data scientists is exceeding what our universities are producing. According to aMckinsey report:" By 2018; the United States alone could face a shortage of 140;000 to190;000 people with deep analytical skills". Similarly; the ability to extract knowledge fromscientific data is accelerating discovery and we need the next generation of domainscientists to be experts not only in their domain but also in data management. At the sametime; however; researchers in academia who focus on building instruments or datamanagement tools are often less recognized for their contributions than researchersfocusing purely on the actual science. OVERVIEW: The goal of this panel will be to discussall these challenges. We will discuss various aspects of how we should be educating both …,Proceedings of the 25th International Conference on Scientific and Statistical Database Management,2013,*
Auction-based Admission Control for Continuous Queries in a Multi-Tenant DSMS,Lory Al Moakar; Panos K Chrysanthis; Christine Chung; Shenoda Guirguis; Alexandros Labrinidis; Panayiotis Neophytou; Kirk Pruhs,Abstract The growing popularity of monitoring applications and “Big Data” analytics used bya variety of users will leadto a multi-tenant data stream management system. This paperdeals with the problem of admission control ofcontinuous queries; where the streamprocessing resources are sold to the end users. We employ variable pricingby means ofauction-based mechanisms. The admission control auction mechanism determines whichqueries toadmit; and how much to charge the user for each query in a way that maximizessystem revenue. The admissionmechanism is required to be strategyproof and sybil-immune; incentivizing users to use the system honestly. Specifically; we require that eachuser maximizes her payoff by bidding her true value of having a query run. Wefurtherconsider the requirement that the mechanism be sybil-immune: that is; no user can …,International Journal of Next-Generation Computing,2012,*
Visualization of Energy Consumption of Continuous Query Processing with Mobile Clients,Jesse Szwedko; Panayiotis Neophytou; Panos K Chrysanthis; Alexandros Labrinidis; Mohamed A Sharaf,Complex event detection over data streams has become ubiquitous through the widespreaduse of sensors; wireless connectivity and the wide variety of end-user mobile devices.Typically; event detection is carried out by a central server executing continuous queries. Inthis demonstration; we focus on the case where users with mobile devices submitcontinuous queries (for event detection) to a data stream management server whichdisseminates the results to the users over a shared broadcast medium. In order to minimizethe overall energy consumption of the mobile devices (clients); we have proposed operatorplacement algorithms that split the processing of each continuous query between thecentralized server and the requesting mobile clients; thus trading off energy consumption forcommunication energy consumption for computation. Specifically; in this demonstration …,Mobile Data Management (MDM); 2011 12th IEEE International Conference on,2011,*
Foundations and Trends® in Databases,Alexandros Labrinidis; Qiong Luo; Jie Xu; Wenwei Xue,*,Foundations and Trends® in Databases,2010,*
Admission Control Mechanisms for Continuous Queries in the Cloud,Christine Chung; Lory Al Moakar; Panos Chrysanthis; Shenoda Guirguis; Alexandros Labrinidis; Panayiotis Panickos Neophytou; Kirk Pruhs,Abstract—Amazon; Google; and IBM now sell cloud comput-ing services. We consider thesetting of a for-profit business selling data stream monitoring/management services and weinvestigate auction-based mechanisms for admission control of continuous queries. Whensubmitting a query; each user also submits a bid of how much she will commit to paying forthat query to run. The admission control auction mechanism then determines which queriesto admit; and how much to charge each user in a way that maximizes system revenue whileincentivizing users to use the system honestly. Specifically; we require that each usermaximizes her payoff by bidding her true value of having her query run. We further considerthe requirement that the mechanism be sybil-immune; that is; that no user can increase herpayoff by submitting queries that she does not value. The main combinatorial challenges …,*,2010,*
Open Forum-Call for Opinions,Alexandros Labrinidis,The Open Forum Column was introduced with the March 2008 issue as a forum for membersof the broader data management community to present (meta-) ideas about non-technicalissues and challenges of interest to the entire community. With this issue; we are taking thenext (evolutionary) step for the column; namely opening the floor to comments and opinionsfrom the entire community on a specific topic. The goal is simple: allow more members of thecommunity to express their opinion about a particular topic and hopefully identify aconsensus; whenever possible. The first topic will be the “Role of Workshops in theDissemination of Research Results”. In the past; it used to be that workshops were a venuefor immediate feedback on new; not fully-developed ideas (and typically did not have officialproceedings). Works presented in workshops typically materialized subsequently into …,SIGMOD Record,2009,*
Hash-based Overlay Partitioning in Unstructured Peer-to-Peer Systems,Harris Papadakis; Paraskevi Fragopoulou; Evangelos P Markatos; Marios D Dikaiakos; Alexandros Labrinidis,Unstructured peer-to-peer (P2P) networks suffer from the increased volume of trafficproduced by flooding. Methods such as random walks or dynamic querying managed to limitthe traffic at the cost of reduced network coverage. In this paper; we propose a partitioningmethod of the unstructured overlay network into a relative small number of distinctsubnetworks. The partitioning is driven by the categorization of keywords based on auniform hash function. The method proposed in this paper is easy to implement and resultsin significant benefit for the blind flood method. Each search is restricted to a certain partitionof the initial overlay network and as a result it is much more targeted. Last but not least; thesearch accuracy is not sacrificed to the least since all related content is searched. Thebenefit of the proposed method is demonstrated with extensive simulation results; which …,Parallel Processing Letters,2009,*
Demonstrating An Evacuation Algorithm with Mobile Devices using an e-Scavenger Hunt Game (Demo Paper),Jesse Szwedko; Callen Shaw; Alexander G Connor; Alexandros Labrinidis; Panos K Chrysanthis,1. INTRODUCTION йж в й а в к й и гвИ ж и ж бйзи и в иг ж бгк з б вн д гда жгб и й а в з з анз дгзз а К йжж вианИ абгзи аа й а в з к а и м и з вз в к й и гв б дз и зд Ќ аг и гвз Д и ви жз Йи гвз гж в ж ггжзЕИ йи и з ж йв а иг джгк ж аЙ и б в гжб и гв зй з л и ж и м и з в зз а гж гк жжгл л в а иг згж в о в дги ви аан в жгйз к й и гвзК ии ж б и иг згб Й гл ж и и к й з и жгй аг игвЙ л ж знзи бК С аанИ и з знзи б лгйа б йз г аг а дгз и гв в знзи б Д ШЫЕ иг ад йз жз игви н и ж аг и гв в гл иг джг иг в ж н м изК Ргл к жИ в в ггж в кЙ и гв знзи б ввги йжж виан жан гв ШЫ в гжб и гв йз и в гжб и гв з г и в в гбда и гж в зз а в в ггж з в ж гз з л аа з в иж и гваан гван илг б вз гв а л з г а ииа йз в бйаи Йггж й а в зК Свзи И л к з в знзи б л нв б аан йз йз жз иг з м из в аг а в б вв жИ л и Й гйи ж ей ж в зд а о бгв игж в ей дб виК Ь знзЙ и б лз з в иг и к ви г илг и вгаг з Сви жв иЙ д а бг а д гв зИ л ж жан дгдйа жИ в ж гЙ ж ей в н …,*,2009,*
View Maintenance,Alexandros Labrinidis; Yannis Sismanis,The valid time of a fact is the time when the fact is true in the modeled reality. Any subset ofthe time domain may be associated with a fact. Thus; valid timestamps may be sets of timeinstants and time intervals; with single instants and intervals being important special cases.Valid times are usually supplied by the user.,*,2009,*
Scheduling Strategies for Data Stream Processing,Mohamed Sharaf; Alexandros Labrinidis,The values in the relations of a relational database are elements of one or more underlyingsets called domains. In practical applications; a domain may be infinite; eg; the set of naturalnumbers. In this case; the value of a relational calculus query when applied to such adatabase may be infinite; eg;{njn! 10}. A query Q is called finite if the value of Q whenapplied to any database is finite. Even when the database domains are finite; all that isnormally known about them is that they are some finite superset of the values that occur inthe database. In this case; the value of a relational calculus query may depend on such anunknown domain; eg;{xj 8yR (x; y)}. A query Q is called domain independent if the value of Qwhen applied to any database is the same for any two domains containing the databasevalues or; equivalently; if the value of Q when applied to a database contains only values …,*,2009,*
Welcome to the December 2008 issue of SIGMOD Record. We begin the issue with a welcome message from Yannis Ioannidis to SIGMOD members in general and...,Alexandros Labrinidis,The Distinguished Profiles in Data Management Column (edited by Marianne Winslett)features an interview of Surajit Chaudhuri; who is a research area manager at MicrosoftResearch; an ACM Fellow; and has received the SIGMOD Contributions Award in 2004.Read Surajit's interview to find out (among many other things) how data mining led him toself-tuning databases and about life as a research manager.,SIGMOD Record,2008,*
GeoSensor Networks: Second International Conference; GSN 2006; Boston; MA; USA; October 1-3; 2006; Revised Selected and Invited Papers,David Hutchison; Takeo Kanade; Josef Kittler; Jon M Kleinberg; Alexandros Labrinidis; Friedemann Mattern; John C Mitchell; Moni Naor; Oscar Nierstrasz; Silvia Nittel; C Pandu Rangan; Anthony Stefanidis; Bernhard Steffen; Madhu Sudan; Demetri Terzopoulos; Doug Tygar; Moshe Y Vardi; Gerhard Weikum,*,*,2008,*
GeoSensor Networks-Second International Conference; GSN 2006. Boston; MA; USA; October 2006. Revised Selected and Invited Papers,Silvia Nittel; Alexandros Labrinidis; Anthony Stefanidis,*,Lecture Notes in Computer Science,2008,*
Report on the Fourth International Workshop on Data Management for Sensor Networks (DMSN 2007),Magdalena Balazinska; Amol Deshpande; Alexandros Labrinidis; Qiong Luo; Samuel Madden; Jun Yang,Abstract Sensor networks enable an unprecedented level of access to the physical world;and hold tremendous potential to revolutionize many application domains. Research onsensor networks spans many areas of computer science; and there are now majorconferences; eg; IPSN and SenSys; devoted to sensor networks. However; there is nofocused forum for discussion of early and innovative work on data management in sensornetworks. The International Workshop on Data Management for Sensor Networks (DMSN);inaugurated in 2004; aims to fill this significant gap in the database and sensor networkcommunities.,ACM SIGMOD Record,2007,*
WhiteBoard P2P: A Peer-to-Peer Reliable Data Dissemination Infrastructure for Collaborative Applications,Panayiotis Neophytou; Alexandros Labrinidis; Panos K Chrysanthis,Abstract In this paper we present a new Peer-to-Peer approach for enabling datadissemination; using filtering techniques; that provides support for many types ofcollaborative applications. Our architecture; called WhiteBoard P2P; is designed to act as aninnovative distributed data stream processing system which is vendor-independent andtechnologyindependent. Our infrastructure can support the interconnection of existing legacysystems as well as new systems; and allows dynamic joining and leaving of collaborativeparticipants on a need-to basis. Furthermore; our system is designed to support mobile andad-hoc networks that are unstable; by allowing disconnected operations while enablingdynamic restructuring of the network as required. We are currently testing our system in thecontext of disaster management; as part of the Secure-CITI project.,Proc. of the Int’l Conference on Intelligent Systems and Computing: Theory and Applications,2006,*
Report on MobiDE 2003: The 3rd International ACM Workshop on Data Engineering for Wireless and Mobile Access,Sujata Banerjee; Mitch Cherniack; Panos K Chrysanthis; Vijay Kumar; Alexandros Labrinidis,Abstract The 3rd International ACM Workshop on Data Engineering for Wireless and MobileAccess (MobiDE 2003 for short) took place on September 19; 2003 at the Westin HortonPlaza Hotel in San Diego; California in conjunction with MobiCom 2003. The MobiDEworkshops serve as a bridge between the data management and network researchcommunities; and have a tradition of presenting innovations on mobile as well as wirelessdata engineering issues (such as those found in sensor networks). This workshop was thethird in the MobiDE series; MobiDE 1999 having taken place in Seattle in conjunction withMobiCom 1999; and MobiDE 2001 having taken place in Santa Barbara in conjunction withSIGMOD 2001.,ACM SIGMOD Record,2005,*
Foreword: MobiDE 2005: Proceedings of the 4th ACM International Workshop on Data Engineering for Wireless and Mobile Access,V Kumar; Ugar Cetintemel; Arkady Zaslavsky; A Labrinidis,diva-portal.org. Please wait …,MobiDE 2005: 12/06/2005-12/06/2005,2005,*
MobiDE 2005: Proceedings of the Fourth ACM International Workshop on Data Engineering for Wireless and Mobile Access: June 12; 2005; Baltimore; Maryland; USA,Uğur Çetintemel; Alexandros Labrinidis,*,*,2005,*
1st International Workshop on,Alexandros Labrinidis; Samuel Madden,The past few years have seen substantial amounts of computer science research on sensornetworks. Other subfields have had a number of workshops on the topic (eg; the Workshopon Wireless Sensor Networks and Applications (WSNA) in 2002 and 2003 and the SensorNetworks Protocols and Applications (SNPA) Workshop in 2002 and 2003; both of which aresystems/networking focused). Furthermore; there are now at least two major conferences–the Conference on Information Processing in Sensor Networks (IPSN); started in 2002; andthe ACM Conference on Sensor Systems (SenSys); started in 2003. These conferenceshave published a small number of database papers; but there is no forum for discussion onearly and innovative work on data management in sensor networks. We believe that theWorkshop on Data Management for Sensor Networks (DMSN'04) fills a significant gap in …,*,2004,*
Editorial message: special track on internet data management,Marios Dikaiakos; Alexandros Labrinidis; Qiong Luo,The Internet is gradually turning into a public “utility” in people's daily life; and the Web hasserved as a catalyst in this process. With an increasing number of emerging applicationsand architectures on the Internet; such as sensor data acquisition; peer-to-peer data sharing;and grid computing; it is essential to revitalize and enrich the Internet data managementarena. For this reason; ACM SAC included a special Track on Internet Data Managementthis year for the first time. This Track aims to examine the state of the art in Internet datamanagement; focusing on emerging applications in addition to traditional web datamanagement. The underlying theme of the Track is in building systems that are easy to useand are scalable. These usability/scalability issues will be considered in many dimensions:manageability; heterogeneity; performance; reliability; device capabilities; user behaviors …,Proceedings of the 2004 ACM symposium on Applied computing,2004,*
Internet data management(IDM),Marios Dikaiakos; Alexandros Labrinidis; Qiong Luo,*,Symposium on Applied Computing: Proceedings of the 2004 ACM symposium on Applied computing,2004,*
S-CITI: A Secure Critical Information Technology Infrastructure for Disaster Management,Ahmed Amer; Jose Carlos Brustoloni; Panos Chrysanthis; Louise K Comfort; Milos Hauskrecht; Alexandros Labrinidis; Rami Melhem; Daniel Mossé; Kirk Pruhs,*,*,2003,*
Proceedings of the Third ACM International Workshop on Data Engineering for Wireless and Mobile Access,Sujata Banerjee; Mitch Cherniack; Alexandros Labrinidis,*,*,2003,*
The Opsis project: materialized views for data warehouses and the web,Nick Roussopoulos; Yannis Kotidis; Alexandros Labrinidis; Yannis Sismanis,Abstract The real world we live in is mostly perceived through an incredibly large collectionof views generated by humans; machines; and other systems. This is the view reality. TheOpsis project concentrates its efforts on dealing with the multifaceted form and complexity ofdata views including data projection views; aggregate views; summary views (synopses)and finally web views. In particular; Opsis deals with the generation; the storageorganization (Cubetrees); the efficient run-time management (Dynamat) of materializedviews for Data Warehouse systems and for web servers with dynamic content (WebViews).,Panhellenic Conference on Informatics,2001,*
Introduction to the Career Forum Column,Alexandros Labrinidis,Welcome to the second installment of the Career Forum column. The column; which debutedin the September 2001 issue; aims to provide career advice and practical information tograduating students and database professionals. In addition to the standard; 6-page articlesthat cover broad topics; we plan to solicit shorter articles (1-2 pages). Shorter articles willpresent multiple (and probably different) views on specific questions. Taking this a stepfurther; we will also experiment with online surveys; in order to provide hard-to-findquantitative data on a variety of career-related topics (a salary survey is one such example).Survey data will be collected over the web and tabulated into short articles for the printedition. Finally; we are organizing the resources mentioned in the Career Forum articlestogether with other helpful web pointers into a separate section of SIGMOD Online …,SIGMOD Record,2001,*
Career-enhancing services at SIGMOD online,Alexandros Labrinidis; Alberto O Mendelzon,Abstract This article serves three purposes. First of all; to introduce dbjobs; the database ofdatabase jobs; and also describe its functionality and architecture. Secondly; to presentstatistics for the dbgrads system; after 18 months of continuous operation. Finally; todescribe exciting future projects for SIGMOD Online.,ACM SIGMOD Record,2001,*
WebView Materialization Ѓ,Alexandros Labrinidis; Nick Roussopoulos,*,*,2000,*
The magazine archive includes every article published in Communications of the ACM for over the past 50 years.,Akhilesh Chandra; Thomas Calderon,Information systems (IS) are quickly emerging as critical resources to be leveraged fororganizational productivity in many business; social; and economic enterprises. Theexplosive growth in information technology (IT) can be broadly attributed to the emergingnovel linkages of IS/IT with several base disciplines; extending the reach of IS/IT toapplication domains never previously considered.In this article; we focus on certainimportant and promising IS/IT frontiers identified from the perspectives of academia; industry;and federal research funding agencies. Our objective is to focus the collective awareness ofthe IS community and those in related disciplines on some of the frontier developments inIS/IT with a vision of the road ahead and point to challenges and opportunities [1].,Communications of the ACM,2000,*
Using Materialized Views in an Environment with Continous & Asynchronous Update Flow,Alexandros Labrinidis,*,*,1997,*
Scalable Processing of Aggregate Continuous Queries in a Distributed Environment,Anatoli U Shein; Panos K Chrysanthis; Alexandros Labrinidis,Page 1. Scalable Processing of Aggregate Continuous Queries in a Distributed EnvironmentAnatoli U. Shein; Panos K. Chrysanthis; Alexandros Labrinidis SELECT AVG(price) FROMStock_Stream Range = 100 msec AND Slide = 5 msec SELECT MAX(heart_rate) FROMPatient_Stream Range = 30 min AND Slide = 10 min SELECT MIN(humidity) FROMForest_Stream Range = 1 day msec AND Slide = 2 hrs SELECT MEDIAN(luminance) FROMStar_Stream Range = 10 min msec AND Slide = 30 sec Online Analytics & Data StreamManagement Systems Optimizers Non Cost-based Cost-based Random Round Robin To LowestTo Nodes Inserted Categories Group only GRAND GRR GTL - - Weave only WRAND WRR -WTN WI Weave + Group WGRAND WGRR - WGTN WGI Taxonomy of Optimizers Related WorkO S. Guirguis; MA Sharaf; PK Chrysanthis; and A. Labrinidis. Optimized …,*,*,*
Preference-Aware Query and Update Scheduling in Web-databases,Alexandros Labrinidis,Abstract Typical web-database systems receive read-only queries; that generate dynamicweb pages as a response; and writeonly updates; that keep information up-to-date. Usersexpect short response times and low staleness. However; it may be extremely hard to applyall updates on time; ie; keep zero staleness; and also get fast response times; especially inperiods of bursty traffic. In this paper; we present the concept of Quality Contracts (QCs)which combines the two incomparable performance metrics: response time or Quality ofService (QoS); and staleness or Quality of Data (QoD). QCs allows individual users toexpress their preferences for the expected QoS and QoD of their queries by assigning“profit” values. To maximize the total profit from submitted QCs; we propose an adaptivealgorithm; called QUTS. QUTS addresses the problem of prioritizing the scheduling of …,*,*,*
NSF III-2010 PI Workshop Report on “Future Directions for III”,Peggy Agouris; Vassilis Athitsos; Ramazan Aygun; Vineet Bafna; Arindam Banerjee; Chaitan Baru; Juan Bello; Tanya Berger-Wolf; Catherine Blake; Jamie Callan; Yi Chen; Evangelos Christidis; Fernand Cohen; David Cooper; Susan Davidson; Brian Davison; Lois Delcambre; Yanlei Diao; UC Amr El Abbadi; Michael Genesereth; Venu Govindaraju; Jiawei Han; UIUC Brent Heeringa; Bill Howe; Yan Huang; Richard Hull; Watson Christopher Jermaine; Patrick Juola; Richard Karp; Jay Kesan; Alexandros Labrinidis; Kristina Lerman; Chen Li; Boon Thau Loo; Bill Manaris; BS Manjunath,● Spatiotemporal modeling; especially as it relates to fuzzy and abstract information●Support for seamless navigation through space and time datasets o Continuous updates ofdatabases o Fully 3-D spaces o Space/time prediction (eg for event monitoring; resourceallocation; alert issues) o Legacy and historical data integration o Now and then in GoogleEarth: continuously updating its content; accessing legacy and timely data and information;predicting emerging situations● Event-driven approaches: o Event modeling o Automatedattribute recognition o Event similarity assessment o Spatiotemporal event mining oReasoning o Risk assessment; etc. o Integration in a spatiotemporal algebra● Globalmonitoring: cross temporal-and spatial-scale analysis● Mobility; flow; and evolution: fromsingle to composite objects (eg cars; pollution front; groups of people; disease risk) …,*,*,*
NSF III-2010 Workshop: PI Reports,Peggy Agouris; Vassilis Athitsos; Ramazan Aygun; Vineet Bafna; Arindam Banerjee; Chaitan Baru; Juan Bello; Tanya Berger-Wolf; Catherine Blake; Jamie Callan; Yi Chen; Evangelos Christidis; Fernand Cohen; David Cooper; Susan Davidson; Brian Davison; Lois Delcambre; Yanlei Diao; UC Amr El Abbadi; Michael Genesereth; Venu Govindaraju; Jiawei Han; UIUC Brent Heeringa; Bill Howe; Yan Huang; Richard Hull; Watson Christopher Jermaine; Patrick Juola; Richard Karp; Jay Kesan; Alexandros Labrinidis; Kristina Lerman; Chen Li; Boon Thau Loo; Bill Manaris; BS Manjunath,The workshop brought together the most active researchers in spatiotemporal informaticsfrom the fields of computer science; geoinformation science; engineering and geography.Because participants included representatives from industry; government; and K-12educators; the presented views represented all facets of the field; and thus contributedtowards a well-rounded exchange of ideas as to future trends and needs. More specifically;workshop participants gave presentations which addressed the following questions aboutthe field of geospatial and geotemporal informatics: 1. What is solved? Include expected andsurprise successes. 2. What is almost solved? Include on-going hot areas. 3. What hasfailed? Include surprise failures. 4. What is missing? Discuss areas not currently on theradar. 5. What is next? Include both high risk and needed topics.,*,*,*
Message from the Organizing Committee,Alexandros Labrinidis; Samuel R Madden; Amol Deshpande; Qiong Luo,The past few years have seen substantial amounts of computer science research on sensornetworks as they have the potential to bring an unprecedented level of access to thephysical world. Other subfields of Computer Science have had a number of workshops onthe topic. Also; there are now at least two major conferences–the Conference on InformationProcessing in Sensor Networks (IPSN); started in 2002 (the 2006 IPSN was held in April);and the ACM Conference on Sensor Systems (SenSys); started in 2003 (the 2006 SenSyswill be held in November). These conferences have published a small number of databasepapers; but there is no exclusive forum for discussion on early and innovative work on datamanagement in sensor networks. We believe that the DMSN 2006 workshop; building on thesuccesses of the DMSN 2004 and DMSN 2005 workshops; fills a significant gap in the …,*,*,*
MobiDE 2006(proceedings of the Fifth ACM International Workshop on Data Engineering for Wireless and Mobile Access),Panos K Chrysanthis; Christian S Jensen; Vijay Kumar; Alexandros Labrinidis,*,*,*,*
Extending the Synergy between MAC Layer and Query Optimization in Wireless Sensornets,Vladimir I Zadorozhny; Panos K Chrysanthis; Prashant Krishnamurthy; Alexandros Labrinidis; Divyasheel Sharma,*,*,*,*
Scheduling Multiple Continuous Queries to Improve QoD,Mohamed A Sharaf; Alexandros Labrinidis; Panos K Chrysanthis; Kirk Pruhs,ABSTRACT Quality of Service (QoS) and Quality of Data (QoD) are the two majordimensions for evaluating any query processing system. In the context of the new datastream management stystems (DSMSs); multi-query scheduling has been exploited toimprove QoS. In this paper; we are proposing to exploit scheduling to improve QoD.Specifically; we are presenting a new policy for scheduling multiple continuous queries withthe objective of maximizing the freshness of the output data streams and hence the QoD ofsuch outputs. The proposed Freshness-Aware Scheduling of Multiple Continuous Queries(FAS-MCQ) policy decides the execution order of continuous queries based on each query'sproperties (ie; cost and selectivity) as well the properties of the input update streams (ie;variability of updates). Our experimental results have shown that FAS-MCQ can increase …,*,*,*
CLUE: A clustering environment for OLTP workloads.,Alexandros Labrinidis; Christos Nikolaou; Maria Karavassili; Volker Bohny; Thomas Delicay; Donald Fergusonz,CLUE: A clustering environment for OLTP workloads. Alexandros Labrinidis; ChristosNikolaou; Maria Karavassili; Volker Bohny; Thomas Delicay and Donald Fergusonz Departmentof Computer Science; University of Crete; and Institute of Computer Science (ICS); Foundationfor Research & Technology-Hellas (FORTH) Heraklion; Crete; Greece Email: labrinid@ ics.forth. gr; nikolau@ ics. forth. gr; karma@ ics. forth. gr ySIEMENS NIXDORF InformationssystemeAG; Germany Email: Volker. Bohn@ mch. sni. de; Thomas. Delica@ mch. sni. de zWatson ResearchCenter; PO Box 704; Yorktown Heights NY 10598; USA Email: d erg@ watson. ibm. com 1 IntroductionKnowledge of the workload intrinsic characteristics is essential for dynamic goal orientedwork- load control algorithms used to optimize the system's performance behavior; for examplethrough the use of transaction routing algorithms (FNGD93]). Intrinsic characteristics; are …,Session 1: Distributed Systems: A Case Study,*,*
Exploiting Flash for Energy Efficient Disk Arrays,Shimin Chen; Panos K Chrysanthis; Alexandros Labrinidis,A growing concern; energy consumption in data centers has been the focus of numerouswhite papers; research studies; and news reports [1; 11; 4; 3]. According to a report to UScongress [11]; the total energy consumption by servers and data centers in US was about 61billion kWh in 2006; and is projected to nearly double by 2011 [11]. Among the componentsin data centers; it has been shown that storage experienced the fastest annual growth (20%between 2000 and 2006) in energy consumption [11]. A key goal in energy efficient systemdesign is to achieve energy proportionality [2]; ie; energy consumption being proportional tothe system utilization. However; hard disk drives (HDDs); the dominant technology for datastorage today; contain moving components; making it difficult to achieve this goal. Forexample; an enterprise class Seagate Cheetah 15K. 4 HDD consumes about 15W under …,*,*,*
