VL2: a scalable and flexible data center network,Albert Greenberg; James R Hamilton; Navendu Jain; Srikanth Kandula; Changhoon Kim; Parantap Lahiri; David A Maltz; Parveen Patel; Sudipta Sengupta,Abstract To be agile and cost effective; data centers should allow dynamic resourceallocation across large server pools. In particular; the data center network should enable anyserver to be assigned to any service. To meet these goals; we present VL2; a practicalnetwork architecture that scales to support huge data centers with uniform high capacitybetween servers; performance isolation between services; and Ethernet layer-2 semantics.VL2 uses (1) flat addressing to allow service instances to be placed anywhere in thenetwork;(2) Valiant Load Balancing to spread traffic uniformly across network paths; and (3)end-system based address resolution to scale to large server pools; without introducingcomplexity to the network control plane. VL2's design is driven by detailed measurements oftraffic and fault data from a large operational cloud service provider. VL2's implementation …,ACM SIGCOMM computer communication review,2009,2144
CloudCmp: comparing public cloud providers,Ang Li; Xiaowei Yang; Srikanth Kandula; Ming Zhang,Abstract While many public cloud providers offer pay-as-you-go computing; their varyingapproaches to infrastructure; virtualization; and software services lead to a problem ofplenty. To help customers pick a cloud that fits their needs; we develop CloudCmp; asystematic comparator of the performance and cost of cloud providers. CloudCmp measuresthe elastic computing; persistent storage; and networking services offered by a cloud alongmetrics that directly reflect their impact on the performance of customer applications.CloudCmp strives to ensure fairness; representativeness; and compliance of thesemeasurements while limiting measurement cost. Applying CloudCmp to four cloud providersthat together account for most of the cloud customers today; we find that their offeredservices vary widely in performance and costs; underscoring the need for thoughtful …,Proceedings of the 10th ACM SIGCOMM conference on Internet measurement,2010,848
Diversity in smartphone usage,Hossein Falaki; Ratul Mahajan; Srikanth Kandula; Dimitrios Lymberopoulos; Ramesh Govindan; Deborah Estrin,Abstract Using detailed traces from 255 users; we conduct a comprehensive study ofsmartphone use. We characterize intentional user activities--interactions with the device andthe applications used--and the impact of those activities on network and energy usage. Wefind immense diversity among users. Along all aspects that we study; users differ by one ormore orders of magnitude. For instance; the average number of interactions per day variesfrom 10 to 200; and the average amount of data received per day varies from 1 to 1000 MB.This level of diversity suggests that mechanisms to improve user experience or energyconsumption will be more effective if they learn and adapt to user behavior. We find thatqualitative similarities exist among users that facilitate the task of learning user behavior. Forinstance; the relative application popularity for can be modeled using an exponential …,Proceedings of the 8th international conference on Mobile systems; applications; and services,2010,808
The nature of data center traffic: measurements & analysis,Srikanth Kandula; Sudipta Sengupta; Albert Greenberg; Parveen Patel; Ronnie Chaiken,Abstract We explore the nature of traffic in data centers; designed to support the mining ofmassive data sets. We instrument the servers to collect socket-level logs; with negligibleperformance impact. In a 1500 server operational cluster; we thus amass roughly a petabyteof measurements over two months; from which we obtain and report detailed views of trafficand congestion conditions and patterns. We further consider whether traffic matrices in thecluster might be obtained instead via tomographic inference from coarser-grained counterdata.,Proceedings of the 9th ACM SIGCOMM conference on Internet measurement,2009,807
Reining in the Outliers in Map-Reduce Clusters using Mantri.,Ganesh Ananthanarayanan; Srikanth Kandula; Albert G Greenberg; Ion Stoica; Yi Lu; Bikas Saha; Edward Harris,Abstract–Experience from an operational Map-Reduce cluster reveals that outlierssignificantly prolong job completion. e causes for outliers include run-time contention forprocessor; memory and other resources; disk failures; varying bandwidth and congestionalong network paths and; imbalance in task workload. We present Mantri; a system thatmonitors tasks and culls outliers using cause-and resource-aware techniques. Mantri'sstrategies include restarting outliers; network-aware placement of tasks and protectingoutputs of valuable tasks. Using real-time progress reports; Mantri detects and acts onoutliers early in their lifetime. Early action frees up resources that can be used bysubsequent tasks and expedites the job overall. Acting based on the causes and theresource and opportunity cost of actions lets Mantri improve over prior work that only …,OSDI,2010,582
Achieving high utilization with software-driven WAN,Chi-Yao Hong; Srikanth Kandula; Ratul Mahajan; Ming Zhang; Vijay Gill; Mohan Nanduri; Roger Wattenhofer,Abstract We present SWAN; a system that boosts the utilization of inter-datacenter networksby centrally controlling when and how much traffic each service sends and frequently re-configuring the network's data plane to match current traffic demand. But done simplistically;these re-configurations can also cause severe; transient congestion because differentswitches may apply updates at different times. We develop a novel technique that leveragesa small amount of scratch capacity on links to apply updates in a provably congestion-freemanner; without making any assumptions about the order and timing of updates at individualswitches. Further; to scale to large networks in the face of limited forwarding table capacity;SWAN greedily selects a small set of entries that can best satisfy current demand. It updatesthis set without disrupting traffic by leveraging a small amount of scratch capacity in …,ACM SIGCOMM Computer Communication Review,2013,507
Botz-4-sale: Surviving organized DDoS attacks that mimic flash crowds,Srikanth Kandula; Dina Katabi; Matthias Jacob; Arthur Berger,Abstract Recent denial of service attacks are mounted by professionals using Botnets of tensof thousands of compromised machines. To circumvent detection; attackers are increasinglymoving away from bandwidth floods to attacks that mimic the Web browsing behavior of alarge number of clients; and target expensive higher-layer resources such as CPU;database and disk bandwidth. The resulting attacks are hard to defend against usingstandard techniques; as the malicious requests differ from the legitimate ones in intent butnot in content. We present the design and implementation of Kill-Bots; a kernel extension toprotect Web servers against DDoS attacks that masquerade as flash crowds. Kill-Botsprovides authentication using graphical tests but is different from other systems that usegraphical tests. First; Kill-Bots uses an intermediate stage to identify the IP addresses that …,Proceedings of the 2nd conference on Symposium on Networked Systems Design & Implementation-Volume 2,2005,447
A first look at traffic on smartphones,Hossein Falaki; Dimitrios Lymberopoulos; Ratul Mahajan; Srikanth Kandula; Deborah Estrin,Abstract Using data from 43 users across two platforms; we present a detailed look atsmartphone traffic. We find that browsing contributes over half of the traffic; while each ofemail; media; and maps contribute roughly 10%. We also find that the overhead of lowerlayer protocols is high because of small transfer sizes. For half of the transfers that usetransport-level security; header bytes correspond to 40% of the total. We show that whilepacket loss is the main factor that limits the throughput of smartphone traffic; larger sendbuffers at Internet servers can improve the throughput of a quarter of the transfers. Finally; bystudying the interaction between smartphone traffic and the radio power managementpolicy; we find that the power consumption of the radio can be reduced by 35% with minimalimpact on the performance of packet exchanges.,Proceedings of the 10th ACM SIGCOMM conference on Internet measurement,2010,436
Walking the tightrope: Responsive yet stable traffic engineering,Srikanth Kandula; Dina Katabi; Bruce Davie; Anna Charny,Abstract Current intra-domain Traffic Engineering (TE) relies on offline methods; which uselong term average traffic demands. It cannot react to realtime traffic changes caused by BGPreroutes; diurnal traffic variations; attacks; or flash crowds. Further; current TE deals withnetwork failures by pre-computing alternative routings for a limited set of failures. It may failto prevent congestion when unanticipated or combination failures occur; even though thenetwork has enough capacity to handle the failure. This paper presents TeXCP; an onlinedistributed TE protocol that balances load in realtime; responding to actual traffic demandsand failures. TeXCP uses multiple paths to deliver demands from an ingress to an egressrouter; adaptively moving traffic from over-utilized to under-utilized paths. These adaptationsare carefully designed such that; though done independently by each edge router based …,ACM SIGCOMM Computer Communication Review,2005,435
Towards highly reliable enterprise network services via inference of multi-level dependencies,Paramvir Bahl; Ranveer Chandra; Albert Greenberg; Srikanth Kandula; David A Maltz; Ming Zhang,Abstract Localizing the sources of performance problems in large enterprise networks isextremely challenging. Dependencies are numerous; complex and inherently multi-level;spanning hardware and software components across the network and the computinginfrastructure. To exploit these dependencies for fast; accurate problem localization; weintroduce an Inference Graph model; which is well-adapted to user-perceptible problemsrooted in conditions giving rise to both partial service degradation and hard faults. Further;we introduce the Sherlock system to discover Inference Graphs in the operational enterprise;infer critical attributes; and then leverage the result to automatically detect and localizeproblems. To illuminate strengths and limitations of the approach; we provide results from aprototype deployment in a large enterprise network; as well as from testbed emulations …,ACM SIGCOMM Computer Communication Review,2007,393
Sharing the Data Center Network.,Alan Shieh; Srikanth Kandula; Albert G Greenberg; Changhoon Kim; Bikas Saha,Abstract–While today's data centers are multiplexed across many non-cooperatingapplications; they lack effective means to share their network. Relying on TCP's congestioncontrol; as we show from experiments in production data centers; opens up the network todenial of service attacks and performance interference. We present Seawall; a networkbandwidth allocation scheme that divides network capacity based on an administrator-specified policy. Seawall computes and enforces allocations by tunneling traffic throughcongestion controlled; point to multipoint; edge to edge tunnels. The resulting allocationsremain stable regardless of the number of flows; protocols; or destinations in theapplication's traffic mix. Unlike alternate proposals; Seawall easily supports dynamic policychanges and scales to the number of applications and churn of today's data centers …,NSDI,2011,361
Flashback: A lightweight extension for rollback and deterministic replay for software debugging,Sudarshan M Srinivasan; Srikanth Kandula; Christopher R Andrews; Yuanyuan Zhou,Abstract: Software robustness has significant impact on system availability. Unfortunately;finding software bugs is a very challenging task because many bugs are hard to reproduce.While debugging a program; it would be very useful to rollback a crashed program to aprevious execution point and deterministically re-execute the``buggy''code region. However;most previous work on rollback and replay support was designed to survive hardware oroperating system failures; and is therefore too heavy-weight for the fine-grained rollback andreplay needed for software debugging.,USENIX Annual Technical Conference; General Track,2004,327
Dynamic load balancing without packet reordering,Srikanth Kandula; Dina Katabi; Shantanu Sinha; Arthur Berger,Abstract Dynamic load balancing is a popular recent technique that protects ISP networksfrom sudden congestion caused by load spikes or link failures. Dynamic load balancingprotocols; however; require schemes for splitting traffic across multiple paths at a finegranularity. Current splitting schemes present a tussle between slicing granularity andpacket reordering. Splitting traffic at the granularity of packets quickly and accurately assignsthe desired traffic share to each path; but can reorder packets within a TCP flow; confusingTCP congestion control. Splitting traffic at the granularity of a flow avoids packet reorderingbut may overshoot the desired shares by up to 60% in dynamic environments; resulting inlow end-to-end network goodput Contrary to popular belief; we show that one cansystematically split a single flow across multiple paths without causing packet reordering …,ACM SIGCOMM Computer Communication Review,2007,283
Augmenting data center networks with multi-gigabit wireless links,Daniel Halperin; Srikanth Kandula; Jitendra Padhye; Paramvir Bahl; David Wetherall,Abstract The 60 GHz wireless technology that is now emerging has the potential to providedense and extremely fast connectivity at low cost. In this paper; we explore its use to relievehotspots in oversubscribed data center (DC) networks. By experimenting with prototypeequipment; we show that the DC environment is well suited to a deployment of 60GHz linkscontrary to concerns about interference and link reliability. Using directional antennas; manywireless links can run concurrently at multi-Gbps rates on top-of-rack (ToR) switches. Thewired DC network can be used to sidestep several common wireless problems. By analyzingproduction traces of DC traffic for four real applications; we show that adding a small amountof network capacity in the form of wireless flyways to the wired DC network can improveperformance. However; to be of significant value; we find that one hop indirect routing is …,ACM SIGCOMM Computer Communication Review,2011,253
Scarlett: coping with skewed content popularity in mapreduce clusters,Ganesh Ananthanarayanan; Sameer Agarwal; Srikanth Kandula; Albert Greenberg; Ion Stoica; Duke Harlan; Ed Harris,Abstract To improve data availability and resilience MapReduce frameworks use filesystems that replicate data uniformly. However; analysis of job logs from a large productioncluster shows wide disparity in data popularity. Machines and racks storing popular contentbecome bottlenecks; thereby increasing the completion times of jobs accessing this dataeven when there are machines with spare cycles in the cluster. To address this problem; wepresent Scarlett; a system that replicates blocks based on their popularity. By accuratelypredicting file popularity and working within hard bounds on additional storage; Scarlettcauses minimal interference to running jobs. Trace driven simulations and experiments intwo popular MapReduce frameworks (Hadoop; Dryad) show that Scarlett effectivelyalleviates hotspots and can speed up jobs by 20.2%.,Proceedings of the sixth conference on Computer systems,2011,238
PACMan: Coordinated memory caching for parallel jobs,Ganesh Ananthanarayanan; Ali Ghodsi; Andrew Wang; Dhruba Borthakur; Srikanth Kandula; Scott Shenker; Ion Stoica,Abstract Data-intensive analytics on large clusters is important for modern Internet services.As machines in these clusters have large memories; in-memory caching of inputs is aneffective way to speed up these analytics jobs. The key challenge; however; is that thesejobs run multiple tasks in parallel and a job is sped up only when inputs of all such paralleltasks are cached. Indeed; a single task whose input is not cached can slow down the entirejob. To meet this" all-or-nothing" property; we have built PACMan; a caching service thatcoordinates access to the distributed caches. This coordination is essential to improve jobcompletion times and cluster efficiency. To this end; we have implemented two cachereplacement policies on top of PACMan's coordinated infrastructure fb-LIFE that minimizesaverage completion time by evicting large incomplete inputs; and LFU-F that maximizes …,Proceedings of the 9th USENIX conference on Networked Systems Design and Implementation,2012,232
Shrink: A tool for failure diagnosis in IP networks,Srikanth Kandula; Dina Katabi; Jean-Philippe Vasseur,Abstract Faults in an IP network have various causes such as the failure of one or morerouters at the IP layer; fiber-cuts; failure of physical elements at the optical layer; orextraneous causes like power outages. These faults are usually detected as failures of a setof dependent logical entities--the IP links affected by the failed components. We presentShrink; a tool for root cause analysis of network faults which; given a set of failed IP links;identifies the underlying cause of the faulty state. Shrink models the diagnosis problem as aBayesian network. It has two main contributions. First; it effectively accounts for noisymeasurement and inaccurate mapping between the IP and optical layers. Second; it has anefficient inference algorithm that finds the most likely failure causes in polynomial time andwith bounded errors. We compare Shrink with two prior approaches and show that it …,Proceedings of the 2005 ACM SIGCOMM workshop on Mining network data,2005,214
R-BGP: Staying connected in a connected world,Nate Kushman; Srikanth Kandula; Dina Katabi; Bruce M Maggs,ABSTRACT Many studies show that; when Internet links go up or down; the dynamics ofBGP may cause several minutes of packet loss. The loss occurs even when multiple pathsbetween the sender and receiver domains exist; and is unwarranted given the highconnectivity of the Internet. Our objective is to ensure that Internet domains stay connectedas long as the underlying network is connected. Our solution; R-BGP works by pre-computing a few strategically chosen failover paths. R-BGP provably guarantees that adomain will not become disconnected from any destination as long as it will have a policy-compliant path to that destination after convergence. Surprisingly; this can be done using afew simple and practical modifications to BGP; and; like BGP; requires announcing only onepath per neighbor. Simulations on the AS-level graph of the current Internet show that R …,*,2007,197
Detailed diagnosis in enterprise networks,Srikanth Kandula; Ratul Mahajan; Patrick Verkaik; Sharad Agarwal; Jitendra Padhye; Paramvir Bahl,Abstract By studying trouble tickets from small enterprise networks; we conclude that theiroperators need detailed fault diagnosis. That is; the diagnostic system should be able todiagnose not only generic faults (eg; performance-related) but also application specific faults(eg; error codes). It should also identify culprits at a fine granularity such as a process orfirewall configuration. We build a system; called NetMedic; that enables detailed diagnosisby harnessing the rich information exposed by modern operating systems and applications.It formulates detailed diagnosis as an inference problem that more faithfully captures thebehaviors and interactions of fine-grained network components such as processes. Theprimary challenge in solving this problem is inferring when a component might be impactinganother. Our solution is based on an intuitive technique that uses the joint behavior of two …,ACM SIGCOMM Computer Communication Review,2009,196
Dynamic scheduling of network updates,Xin Jin; Hongqiang Harry Liu; Rohan Gandhi; Srikanth Kandula; Ratul Mahajan; Ming Zhang; Jennifer Rexford; Roger Wattenhofer,Abstract We present Dionysus; a system for fast; consistent network updates in software-defined networks. Dionysus encodes as a graph the consistency-related dependenciesamong updates at individual switches; and it then dynamically schedules these updatesbased on runtime differences in the update speeds of different switches. This dynamicscheduling is the key to its speed; prior update methods are slow because they pre-determine a schedule; which does not adapt to runtime conditions. Testbed experiments anddata-driven simulations show that Dionysus improves the median update speed by 53--88%in both wide area and data center networks compared to prior methods.,ACM SIGCOMM Computer Communication Review,2014,186
FatVAP: Aggregating AP Backhaul Capacity to Maximize Throughput.,Srikanth Kandula; Kate Ching-Ju Lin; Tural Badirkhanli; Dina Katabi,Abstract-It is increasingly common that computers in residential and hotspot scenarios seemultiple access points (APs). These APs often provide high speed wireless connectivity butaccess the Internet via independent; relatively low-speed DSL or cable modem links. Ideally;a client would simultaneously use all accessible APs and obtain the sum of their backhaulbandwidth. Past work can connect to multiple APs; but can neither aggregate AP backhaulbandwidth nor can it maintain concurrent TCPs across them. This paper introduces FatVAP;an 802.11 driver that aggregates the bandwidth available at accessible APs and alsobalances their loads. FatVAP has three key features. First; it chooses the APs that are worthconnecting to and connects with each AP just long enough to collect its available bandwidth.Second; it ensures fast switching between APs without losing queued packets; and hence …,NSDI,2008,181
Flyways to de-congest data center networks,Srikanth Kandula; Jitendra Padhye; Paramvir Bahl,Abstract–Astudyofapplicationdemandsfromaproducti…; application demandscanbegenerally metbyanetwork that isslightly oversubscribed. Eliminating over-subscription ishence a needless overkill. In a significant departure from recent proposals that do so; weadvocate a hybrid architecture. The base network is provisioned for the average case; isoversubscribed; and canbebuiltwith any ofthe existing networkdesigns.Totacklethehotspotsthatremain; weaddextra links on an on-demand basis. Theselinks calledflywaysprovideadditional capacity whereandwhenneeded. Ourresultsshowthatevenafewadditional flywayssubstantially improve performance (by over 50%); aslong as they are added at the right place in the network. We consider two design alternativesforadding flywaysatnegligibleadditional cost: onethat useswirelesslinks (60GHzor802 …,*,2009,179
Jockey: guaranteed job latency in data parallel clusters,Andrew D Ferguson; Peter Bodik; Srikanth Kandula; Eric Boutin; Rodrigo Fonseca,Abstract Data processing frameworks such as MapReduce [8] and Dryad [11] are used todayin business environments where customers expect guaranteed performance. To date;however; these systems are not capable of providing guarantees on job latency becausescheduling policies are based on fair-sharing; and operators seek high cluster use throughstatistical multiplexing and over-subscription. With Jockey; we provide latency SLOs for dataparallel jobs written in SCOPE. Jockey precomputes statistics using a simulator that capturesthe job's complex internal dependencies; accurately and efficiently predicting the remainingrun time at different resource allocations and in different stages of the job. Our control policymonitors a job's performance; and dynamically adjusts resource allocation in the sharedcluster in order to maximize the job's economic utility while minimizing its impact on the …,Proceedings of the 7th ACM european conference on Computer Systems,2012,173
Multi-resource packing for cluster schedulers,Robert Grandl; Ganesh Ananthanarayanan; Srikanth Kandula; Sriram Rao; Aditya Akella,Abstract Tasks in modern data parallel clusters have highly diverse resource requirements;along CPU; memory; disk and network. Any of these resources may become bottlenecks andhence; the likelihood of wasting resources due to fragmentation is now larger. Today'sschedulers do not explicitly reduce fragmentation. Worse; since they only allocate cores andmemory; the resources that they ignore (disk and network) can be over-allocated leading tointerference; failures and hogging of cores or memory that could have been used by othertasks. We present Tetris; a cluster scheduler that packs; ie; matches multi-resource taskrequirements with resource availabilities of machines so as to increase cluster efficiency(makespan). Further; Tetris uses an analog of shortest-running-time-first to trade-off clusterefficiency for speeding up individual jobs. Tetris' packing heuristics seamlessly work …,ACM SIGCOMM Computer Communication Review,2015,142
Re-optimizing data-parallel computing,Sameer Agarwal; Srikanth Kandula; Nicolas Bruno; Ming-Chuan Wu; Ion Stoica; Jingren Zhou,Abstract Performant execution of data-parallel jobs needs good execution plans. Certainproperties of the code; the data; and the interaction between them are crucial to generatethese plans. Yet; these properties are difficult to estimate due to the highly distributed natureof these frameworks; the freedom that allows users to specify arbitrary code as operations onthe data; and since jobs in modern clusters have evolved beyond single map and reducephases to logical graphs of operations. Using fixed apriori estimates of these properties tochoose execution plans; as modern systems do; leads to poor performance in severalinstances. We present RoPE; a first step towards re-optimizing data-parallel jobs. RoPEcollects certain code and data properties by piggybacking on job execution. It adaptsexecution plans by feeding these properties to a query optimizer. We show how this …,Proceedings of the 9th USENIX conference on Networked Systems Design and Implementation,2012,135
Seawall: Performance Isolation for Cloud Datacenter Networks.,Alan Shieh; Srikanth Kandula; Albert G Greenberg; Changhoon Kim,Abstract–While today's virtual datacenters have hypervisor based mechanisms to partitioncompute resources between the tenants co-located on an end host; they provide little controlover how tenants share the network. is opens cloud applications to interference from othertenants; resulting in unpredictable performance and exposure to denial of service attacks. ispaper explores the design space for achieving performance isolation between tenants. Wefind that existing schemes for enterprise datacenters suffer from at least one of theseproblems: they cannot keep up with the numbers of tenants and the VM churn observed incloud datacenters; they impose static bandwidth limits to obtain isolation at the cost ofnetwork utilization; they require switch and/or NIC modifications; they cannot toleratemalicious tenants and compromised hypervisors. We propose Seawall; an edge-based …,HotCloud,2010,134
Can you hear me now?!: it must be BGP,Nate Kushman; Srikanth Kandula; Dina Katabi,ABSTRACT Industry observers expect VoIP to eventually replace most of the existing land-line telephone connections. Currently however; quality and reliability concerns largely limitVoIP usage to either personal calls on cross-domain services such as Skype and Vonage; orto single-domain services such as trunking; where a core ISP carries long-distance voice asVoIP only within its backbone; to save cost with a unified voice/data infrastructure. Thispaper investigates the factors that prevent cross-domain VoIP deployments from achievingthe quality and reliability of existing land-line telephony (PSTN). We ran over 50;000 VoIPphone calls between 24 locations in US and Europe for a three-week period. Our resultsindicate that VoIP usability is hindered as much by BGP's slow convergence as networkcongestion. In fact; about half of the unintelligible VoIP samples in our data occur within …,ACM SIGCOMM Computer Communication Review,2007,107
Profiling Network Performance for Multi-tier Data Center Applications.,Minlan Yu; Albert G Greenberg; David A Maltz; Jennifer Rexford; Lihua Yuan; Srikanth Kandula; Changhoon Kim,Abstract Network performance problems are notoriously tricky to diagnose; and this ismagnified when applications are often split into multiple tiers of application componentsspread across thousands of servers in a data center. Problems often arise in thecommunication between the tiers; where either the application or the network (or both!)could be to blame. In this paper; we present SNAP; a scalable network-application profilerthat guides developers in identifying and fixing performance problems. SNAP passivelycollects TCP statistics and socket-call logs with low computation and storage overhead; andcorrelates across shared resources (eg; host; link; switch) and connections to pinpoint thelocation of the problem (eg; send buffer mismanagement; TCP/application conflicts;application-generated microbursts; or network congestion). Our one-week deployment of …,NSDI,2011,98
What's going on?: learning communication rules in edge networks,Srikanth Kandula; Ranveer Chandra; Dina Katabi,Abstract Existing traffic analysis tools focus on traffic volume. They identify the heavy-hitters-flows that exchange high volumes of data; yet fail to identify the structure implicit in networktraffic-do certain flows happen before; after or along with each other repeatedly over time?Since most traffic is generated by applications (web browsing; email; p2p); network traffictends to be governed by a set of underlying rules. Malicious traffic such as network-widescans for vulnerable hosts (mySQLbot) also presents distinct patterns. We present eXpose; atechnique to learn the underlying rules that govern communication over a network. Frompacket timing information; eXpose learns rules for network communication that may bespread across multiple hosts; protocols or applications. Our key contribution is a novelstatistical rule mining technique to extract significant communication patterns in a packet …,ACM SIGCOMM Computer Communication Review,2008,97
CloudCmp: Shopping for a Cloud Made Easy.,Ang Li; Xiaowei Yang; Ming Zhang; S Kandula,Abstract–Cloud computing has gained much popularity recently; and many companies nowoffer a variety of public cloud computing services; such as Google AppEngine; AmazonAWS; and Microsoft Azure. These services differ in service models and pricing schemes;making it challenging for customers to choose the best suited cloud provider for theirapplications. This paper proposes a framework called CloudCmp to help a customer select acloud provider. We outline the design of CloudCmp and highlight the main technicalchallenges. CloudCmp includes a set of benchmarking tools that compare the commonservices offered by cloud providers; and uses the benchmarking results to predict theperformance and costs of a customer's application when deployed on a cloud provider. Wepresent preliminary benchmarking results on three representative cloud providers. These …,HotCloud,2010,95
Low latency geo-distributed data analytics,Qifan Pu; Ganesh Ananthanarayanan; Peter Bodik; Srikanth Kandula; Aditya Akella; Paramvir Bahl; Ion Stoica,Abstract Low latency analytics on geographically distributed datasets (across datacenters;edge clusters) is an upcoming and increasingly important challenge. The dominantapproach of aggregating all the data to a single datacenter significantly inflates thetimeliness of analytics. At the same time; running queries over geo-distributed inputs usingthe current intra-DC analytics frameworks also leads to high query response times becausethese frameworks cannot cope with the relatively low and variable capacity of WAN links. Wepresent Iridium; a system for low latency geo-distributed analytics. Iridium achieves lowquery response times by optimizing placement of both data and tasks of the queries. Thejoint data and task placement optimization; however; is intractable. Therefore; Iridium usesan online heuristic to redistribute datasets among the sites prior to queries' arrivals; and …,ACM SIGCOMM Computer Communication Review,2015,83
Leveraging endpoint flexibility in data-intensive clusters,Mosharaf Chowdhury; Srikanth Kandula; Ion Stoica,Abstract Many applications do not constrain the destinations of their network transfers. Newopportunities emerge when such transfers contribute a large amount of network bytes. Bychoosing the endpoints to avoid congested links; completion times of these transfers as wellas that of others without similar flexibility can be improved. In this paper; we focus onleveraging the flexibility in replica placement during writes to cluster file systems (CFSes);which account for almost half of all cross-rack traffic in data-intensive clusters. The replicasof a CFS write can be placed in any subset of machines as long as they are in multiple faultdomains and ensure a balanced use of storage throughout the cluster. We study CFSinteractions with the cluster network; analyze optimizations for replica placement; andpropose Sinbad--a system that identifies imbalance and adapts replica destinations to …,ACM SIGCOMM Computer Communication Review,2013,80
Harnessing TCP’s burstiness with flowlet switching,Shan Sinha; Srikanth Kandula; Dina Katabi,*,Proc. 3rd ACM Workshop on Hot Topics in Networks (Hotnets-III),2004,79
Cloudprophet: towards application performance prediction in cloud,Ang Li; Xuanran Zong; Srikanth Kandula; Xiaowei Yang; Ming Zhang,Abstract Choosing the best-performing cloud for one's application is a critical problem forpotential cloud customers. We propose CloudProphet; a trace-and-replay tool to predict alegacy application's performance if migrated to a cloud infrastructure. CloudProphet tracesthe workload of the application when running locally; and replays the same workload in thecloud for prediction. We discuss two key technical challenges in designing CloudProphet;and some preliminary results using a prototype implementation.,ACM SIGCOMM Computer Communication Review,2011,72
Speeding up distributed request-response workflows,Virajith Jalaparti; Peter Bodik; Srikanth Kandula; Ishai Menache; Mikhail Rybalkin; Chenyu Yan,Abstract We found that interactive services at Bing have highly variable datacenter-sideprocessing latencies because their processing consists of many sequential stages;parallelization across 10s-1000s of servers and aggregation of responses across thenetwork. To improve the tail latency of such services; we use a few building blocks: reissuinglaggards elsewhere in the cluster; new policies to return incomplete results and speeding uplaggards by giving them more resources. Combining these building blocks to reduce theoverall latency is non-trivial because for the same amount of resource (eg; number ofreissues); different stages improve their latency by different amounts. We present Kwiken; aframework that takes an end-to-end view of latency improvements and costs. It decomposesthe problem of minimizing latency over a general processing DAG into a manageable …,ACM SIGCOMM Computer Communication Review,2013,70
Traffic engineering with forward fault correction,Hongqiang Harry Liu; Srikanth Kandula; Ratul Mahajan; Ming Zhang; David Gelernter,Abstract Faults such as link failures and high switch configuration delays can cause heavycongestion and packet loss. Because it takes time to detect and react to faults; theseconditions can last long---even tens of seconds. We propose forward fault correction (FFC);a proactive approach to handling faults. FFC spreads network traffic such that freedom fromcongestion is guaranteed under arbitrary combinations of up to k faults. We show how FFCcan be practically realized by compactly encoding the constraints that arise from this largenumber of possible faults and solving them efficiently using sorting networks. Experimentswith data from real networks show that; with negligible loss in overall network throughput;FFC can reduce data loss by a factor of 7--130 in well-provisioned networks; and reduce theloss of high-priority traffic to almost zero in well-utilized networks.,ACM SIGCOMM Computer Communication Review,2014,57
Discovering dependencies for network management,Victor Bahl; Paul Barham; Richard Black; Ranveer Chandra; Moises Goldszmidt; Rebecca Isaacs; Srikanth Kandula; Lun Li; John MacCormick; Dave Maltz; Richard Mortier; Mike Wawrzoniak; Ming Zhang,Abstract This paper presents the Leslie Graph; a simple yet powerful abstraction describingthe complex dependencies between network; host and application components in modernnetworked systems. It discusses challenges in the discovery of Leslie Graphs; their uses;and describes two alternate approaches to their discovery; supported by some initialfeasibility results.,*,2006,46
Calendaring for wide area networks,Srikanth Kandula; Ishai Menache; Roy Schwartz; Spandana Raj Babbula,Abstract Datacenter WAN traffic consists of high priority transfers that have to be carried assoon as they arrive alongside large transfers with pre-assigned deadlines on theircompletion (ranging from minutes to hours). The ability to offer guarantees to large transfersis crucial for business needs and impacts overall cost-of-business. State-of-the-art trafficengineering solutions only consider the current time epoch and hence cannot provide pre-facto promises for long-lived transfers. We present Tempus; an online traffic engineeringscheme that exploits information on transfer size and deadlines to appropriately pack long-running transfers across network paths and time; thereby leaving enough capacity slack forfuture high-priority requests. Tempus builds on a tailored approximate solution to a mixedpacking-covering linear program; which is parallelizable and scales well in both running …,ACM SIGCOMM computer communication review,2014,43
SideCar: building programmable datacenter networks without programmable switches,Alan Shieh; Srikanth Kandula; Emin Gun Sirer,Abstract This paper examines an extreme point in the design space of programmableswitches and network policy enforcement. Rather than relying on extensive changes toswitches to provide more programmability; SideCar distributes custom processing codebetween shims running on every end host and general purpose sidecar processors; such asserver blades; connected to each switch via commonly available redirection mechanisms.This provides applications with pervasive network instrumentation and programmability onthe forwarding plane. While not a perfect replacement for programmable switches; thissolves several pressing problems while requiring little or no change to existing switches. Inparticular; in the context of public cloud data centers with 1000s of tenants; we present novelsolutions for multicast; controllable network bandwidth allocation (eg; use-what-you-pay …,Proceedings of the 9th ACM SIGCOMM Workshop on Hot Topics in Networks,2010,40
Performance isolation for clouds,*,Traffic in a cloud is controlled by the nodes participating in the cloud. Tenants of the cloudeach have a ratio. On any given node; a current transmission rate of the node is allocatedamong the tenants of the node; or more specifically; their execution units (eg; virtualmachines) on the node. Thus each tenant receives a predefined portion of the transmissioncapacity of the node. The transmission capacity can vary as conditions on the networkchange. For example; if congestion occurs; the transmission capacity may be decreased.Nonetheless; each tenant receives; according to its ratio; a same relative portion of theoverall transmission capacity.,*,2016,39
Constructing an inference graph for a network,*,Constructing an inference graph relates to the creation of a graph that reflects dependencieswithin a network. In an example embodiment; a method includes determining dependenciesamong components of a network and constructing an inference graph for the networkresponsive to the dependencies. The components of the network include services andhardware components; and the inference graph reflects cross-layer components includingthe services and the hardware components. In another example embodiment; a systemincludes a service dependency analyzer and an inference graph constructor. The servicedependency analyzer is to determine dependencies among components of a network; thecomponents including services and hardware components. The inference graph constructoris to construct an inference graph for the network responsive to the dependencies; the …,*,2013,37
Daytona: A user-level tcp stack,Prashant Pradhan; Srikanth Kandula; Wen Xu; Anees Shaikh; Erich Nahum,*,URL http://nms. csail. mit. edu/% 7Ekandula/data/daytona. pdf,2002,31
Resource management with deep reinforcement learning,Hongzi Mao; Mohammad Alizadeh; Ishai Menache; Srikanth Kandula,Abstract Resource management problems in systems and networking often manifest asdifficult online decision making tasks where appropriate solutions depend on understandingthe workload and environment. Inspired by recent advances in deep reinforcement learningfor AI problems; we consider building systems that learn to manage resources directly fromexperience. We present DeepRM; an example solution that translates the problem ofpacking tasks with multiple resource demands into a learning problem. Our initial resultsshow that DeepRM performs comparably to state-of-the-art heuristics; adapts to differentconditions; converges quickly; and learns strategies that are sensible in hindsight.,Proceedings of the 15th ACM Workshop on Hot Topics in Networks,2016,30
Efficient queue management for cluster scheduling,Jeff Rasley; Konstantinos Karanasos; Srikanth Kandula; Rodrigo Fonseca; Milan Vojnovic; Sriram Rao,Abstract Job scheduling in Big Data clusters is crucial both for cluster operators' return oninvestment and for overall user experience. In this context; we observe several anomalies inhow modern cluster schedulers manage queues; and argue that maintaining queues oftasks at worker nodes has significant benefits. On one hand; centralized approaches do notuse worker-side queues. Given the inherent feedback delays that these systems incur; theyachieve suboptimal cluster utilization; particularly for workloads dominated by short tasks.On the other hand; distributed schedulers typically do employ worker-side queuing; andachieve higher cluster utilization. However; they fail to place tasks at the best possiblemachine; since they lack cluster-wide information; leading to worse job completion time;especially for heterogeneous workloads. To the best of our knowledge; this is the first …,Proceedings of the Eleventh European Conference on Computer Systems,2016,27
System and method for proactive task scheduling of a copy of outlier task in a computing environment,*,The described implementations relate to distributed computing. One implementationprovides a system that can include an outlier detection component that is configured toidentify an outlier task from a plurality of tasks based on runtimes of the plurality of tasks. Thesystem can also include a cause evaluation component that is configured to evaluate acause of the outlier task. For example; the cause of the outlier task can be an amount of dataprocessed by the outlier task; contention for resources used to execute the outlier task; or acommunication link with congested bandwidth that is used by the outlier task to input oroutput data. The system can also include one or more processing devices configured toexecute one or more of the components.,*,2016,25
Parallel computing execution plan optimization,*,The use of statistics collected during the parallel distributed execution of the tasks of a jobmay be used to optimize the performance of the task or similar recurring tasks. An executionplan for a job is initially generated; in which the execution plan includes tasks. Statisticsregarding operations performed in the tasks are collected while the tasks are executed viaparallel distributed execution. Another execution plan is then generated for anotherrecurring job; in which the additional execution plan has at least one task in common withthe execution plan for the job. The additional execution plan is subsequently optimizedbased at least on the statistics to produce an optimized execution plan.,*,2016,25
Argus: A Distributed Network Intrusion Detection System,Srikanth Kandula; Sankalp Singh; Dheeraj Sanghi,СК Свижг й и гв ХЧ ЪЦ гбдйи ж Ц илгж з ж гбда м ви и з и и джгк л Йк ж ин г з жЙ к зК Ьдгдйа ж ин г и Сви жв иИ а ижгв гбб ж И гждгж и в илгж з в зиж йи гбдйи в з йз джга ж и гв ги вЙ гжб и гв иж взб ии и жгй и з в илгж зИ и гвз ей в г л И з ж дж б йб гв в илгж з йж инК Ьк а а ин г к айЙ а в гжб и гв гв бг жв гбдйи ж в илгж з з а иг джгдгжи гв и в ж з в и гбЙ да мин в к ж ин г в илгж вижйз гвзК а зЙ з а з йж ин б в збз а Ќж л аазИ в ЙигЙ в в жнди гв в йиви и гв к и ж глв зйз ди а и зК ж л ааз ж йв а иг агг и и и гви ви г д из д зз в и жгй и б л и гйизйЋ ж в з в Ќ ви жгд в и и жгй дйиК Ь н ж азг миж б ан кйав ж Й а иг в а г з жк ии з з л аа зиЙ и з и и гб жгб вз и Ќж л ааК в Й игЙ в в жнди гв гж йи ви и гв а гж и бз ж з к ж ан в ж н иа г дй а н в ж зижй ийж гк ж и Сви жв иК Ц илгж Й иж Ц зйжк аа в в вижйз гвЙ и и гв знзЙ ибз ДС ЫЕ к жй а жга иг да н в и иЙ в зй в илгж вижйз гвз в ж аЙи б К з з джгк в зйЦ ви в …,*,2002,25
Ensuring predictable and quantifiable networking performance,*,The ensuring of predictable and quantifiable networking performance. Embodiments of theinvention combine a congestion free network core with a hypervisor based (ie; edge-based)throttling design to help insure quantitative and invariable subscription bandwidth rates. Alightweight shim layer in a hypervisor can adaptively throttle the rate of VM-to-VM traffic flow.A receiving hypervisor can detect congestion and communicate back to sending hypervisorsthat rates are to be regulated. In response; sending hypervisors can reduce transmissionrate to mitigate congestion at the receiving hypervisor. In some embodiments; the principlesare extended to any message processors communicating over a congestion free network.,*,2017,23
Quickr: Lazily approximating complex adhoc queries in bigdata clusters,Srikanth Kandula; Anil Shanbhag; Aleksandar Vitorovic; Matthaios Olma; Robert Grandl; Surajit Chaudhuri; Bolin Ding,Abstract We present a system that approximates the answer to complex ad-hoc queries inbig-data clusters by injecting samplers on-the-fly and without requiring pre-existing samples.Improvements can be substantial when big-data queries take multiple passes over data andwhen samplers execute early in the query plan. We present a new; universe; sampler whichis able to sample multiple join inputs. By incorporating samplers natively into a cost-basedquery optimizer; we automatically generate plans with appropriate samplers at appropriatelocations. We devise an accuracy analysis method using which we ensure that query planswith samplers will not miss groups and that aggregate values are within a small ratio of theirtrue value. An implementation on a cluster with tens of thousands of machines shows thatqueries in the TPC-DS benchmark use a median of 2X fewer resources. In contrast …,Proceedings of the 2016 International Conference on Management of Data,2016,23
Netclinic: Interactive visualization to enhance automated fault diagnosis in enterprise networks,Zhicheng Liu; Bongshin Lee; Srikanth Kandula; Ratul Mahajan,Diagnosing faults in an operational computer network is a frustrating; time-consumingexercise. Despite advances; automatic diagnostic tools are far from perfect: theyoccasionally miss the true culprit and are mostly only good at narrowing down the search toa few potential culprits. This uncertainty and the inability to extract useful sense from tooloutput renders most tools not usable to administrators. To bridge this gap; we presentNetClinic; a visual analytics system that couples interactive visualization with an automateddiagnostic tool for enterprise networks. It enables administrators to verify the output of theautomatic analysis at different levels of detail and to move seamlessly across levels whileretaining appropriate context. A qualitative user study shows that NetClinic users canaccurately identify the culprit; even when it is not present in the suggestions made by the …,Visual Analytics Science and Technology (VAST); 2010 IEEE Symposium on,2010,23
Push-Button Verification of File Systems via Crash Refinement.,Helgi Sigurbjarnarson; James Bornholt; Emina Torlak; Xi Wang,Abstract The file system is an essential operating system component for persisting data onstorage devices. Writing bug-free file systems is non-trivial; as they must correctly implementand maintain complex on-disk data structures even in the presence of system crashes andreorderings of disk operations. This paper presents Yggdrasil; a toolkit for writing filesystems with push-button verification: Yggdrasil requires no manual annotations or proofsabout the implementation code; and it produces a counterexample if there is a bug.Yggdrasil achieves this automation through a novel definition of file system correctnesscalled crash refinement; which requires the set of possible disk states produced by animplementation (including states produced by crashes) to be a subset of those allowed bythe specification. Crash refinement is amenable to fully automated satisfiability modulo …,OSDI,2016,22
Inferring candidates that are potentially responsible for user-perceptible network problems,*,Candidates that are potentially responsible for user-perceptible network problems may beinferred. In an example embodiment; a system includes an inference engine to produce a listof candidates that are potentially responsible for user-perceptible network problems; with thecandidates being network components that may include both services and networkelements. A response to a service request may be a non response; an incorrect response;an untimely correct response; or a timely correct response. The user-perceptible networkproblems may include the untimely correct response as well as the non response and theincorrect response. In another example embodiment; a method includes monitoring anetwork and producing a list of candidates that are potentially responsible for user-perceptible network problems. The candidates of the list may include both services and …,*,2011,22
Diagnosing abnormalities without application-specific knowledge,*,Methods; articles; and systems for determining a probable cause of a component's abnormalbehavior are described. To determine the probable cause; a computing device computes; forone or more pairs of components having dependency relationships; a likelihood thatbehavior of one component of a pair is impacting behavior of the other component of thepair. This computing is based on joint historical behavior of the pair of components. Thecomputing device then determines that one of a plurality of components is a probable causeof the abnormal behavior based on the computed likelihoods.,*,2013,21
Recurring job optimization in scope,Nicolas Bruno; Sameer Agarwal; Srikanth Kandula; Bing Shi; Ming-Chuan Wu; Jingren Zhou,An increasing number of applications require distributed data storage and processinginfrastructure over large clusters of commodity hardware for critical business decisions. TheMapReduce programming model [2] helps programmers write distributed applications onlarge clusters; but requires dealing with complex implementation details (eg; reasoning withdata distribution and overall system configuration). Recent proposals; such as SCoPE [1];raise the level of abstraction by providing a declarative language that not only increasesprogramming productivity but is also amenable to sophisticated optimization. Like intraditional database systems; such optimization relies on detailed data statistics to choosethe best execution plan in a cost-based fashion. However; in contrast to database systems; itis very difficult to obtain and maintain good quality statistics in a highly distributed …,Proceedings of the 2012 ACM SIGMOD International Conference on Management of Data,2012,19
Discovering communication rules in a network trace,*,The claimed subject matter provides a system and/or a method that facilitates managing anetwork by mining a communication rule. An analysis engine can employ a packet tracewithin a network in order to provide timing information; wherein the network includes at leastone of a host; a protocol; or an application. A traffic evaluator can extract a communicationrule for the network based upon an activity matrix generated from the timing information inwhich the activity matrix includes at least one of a row of a time window for the packet traceand a column for a flow in the packet trace.,*,2011,18
Sampling biases in network path measurements and what to do about it,Srikanth Kandula; Ratul Mahajan,Abstract We show that currently prevalent practices for network path measurements canproduce inaccurate inferences because of sampling biases. The inferred mean path latencycan be more than a factor of two off the true mean. We present the Broom toolkit that hasthree methods to correct for this bias. Broom places no burden on the measurement processitself and can be applied post hoc to any measured data set. Our evaluation finds that two ofthe methods are particularly effective. One of them estimates missing path samples byembedding the nodes in a low-dimensional coordinate space. For realistic sampling rates;the quality of its estimates for path latency approximates ideal; unbiased sampling. The othermethod is based on a view of network paths as being composed of source-specific;destination-specific; and shared components. It reduces bias for a wide range of path …,Proceedings of the 9th ACM SIGCOMM conference on Internet measurement,2009,16
G: Packing and Dependency-aware Scheduling for Data-Parallel Clusters,Robert Grandl; Srikanth Kandula; Sriram Rao; Aditya Akella; Janardhan Kulkarni,Abstract–Wepresent anewclusterscheduler; G; aimed at jobs that haveacomplexdependency structure and heterogeneous resource demands. Relaxing either of thesechallenges; ie; scheduling a DAG of homogeneous tasks or an independent set ofheterogeneous tasks; leads to NP-hard problems. Reasonable heuristics exist for thesesimpler problems; but they perform poorly when scheduling heterogeneous DAGs. Our keyinsights are:() focus on the long-running tasks and those with toughto-pack resourcedemands;() compute a DAG schedule; oine; by rst scheduling such troublesome tasks andthen scheduling the remaining tasks without violating dependencies. ese oine schedulesare distilled to a simple precedence order and are enforced by an online component thatscales to many jobs. e online component also uses heuristics to compactly pack tasks …,Proceedings of OSDI’16: 12th USENIX Symposium on Operating Systems Design and Implementation,2016,15
Dynamic pricing and traffic engineering for timely inter-datacenter transfers,Virajith Jalaparti; Ivan Bliznets; Srikanth Kandula; Brendan Lucier; Ishai Menache,Abstract Neither traffic engineering nor fixed prices (eg;\$/GB) alone fully address thechallenges of highly utilized inter-datacenter WANs. The former offers more service to userswho overstate their demands and poor service overall. The latter offers no serviceguarantees to customers; and providers have no lever to steer customer demand to lightlyloaded paths/times. To address these issues; we design and evaluate Pretium--a frameworkthat combines dynamic pricing with traffic engineering for inter-datacenter bandwidth. InPretium; users specify their required rates or transfer sizes with deadlines; and a pricemodule generates a price quote for different guarantees (promises) on these requests. Theprice quote is generated using internal prices (which can vary over time and links) which aremaintained and periodically updated by Pretium based on history. A supplementary …,Proceedings of the 2016 ACM SIGCOMM Conference,2016,13
Flashback: A light-weight rollback and deterministic replay extension for software debugging,Sudarshan Srinivasan; Srikanth Kandula; Christopher Andrews; Yuanyuan Zhou,*,*,2004,13
LARK: A light-weight; resilient application-level multicast protocol,Srikanth Kandula; Jong-Kwon Lee; Jennifer C Hou,Application-level multicasting (ALM) has attracted a significant amount of attention; as it is aconvincing alternative over traditional IP multicasting. We present a simple; light-weight; yetscalable; ALM protocol; called. LARK; that allows the formation and maintenance of overlaytopologies in a completely distributed fashion while maintaining only O (1) state at eachnode and ensuring robustness in the presence of a large number of node failures.Conceptually; members self-organize into cliques; where a clique is a cluster of end-hosts inwhich each end-host is aware of; and exchanges state with; every other end-host in thecluster. No control message is exchanged for clique maintenance beyond the necessarystate update among members belonging to the same clique. In addition; members areallowed to peer with randomly selected members belonging to other distinct cliques. This …,Computer Communications; 2003. CCW 2003. Proceedings. 2003 IEEE 18th Annual Workshop on,2003,13
CloudBuild: Microsoft's distributed and caching build service,Hamed Esfahani; Jonas Fietz; Qi Ke; Alexei Kolomiets; Erica Lan; Erik Mavrinac; Wolfram Schulte; Newton Sanches; Srikanth Kandula,Abstract Thousands of Microsoft engineers build and test hundreds of software productsseveral times a day. It is essential that this continuous integration scales; guarantees shortfeedback cycles; and functions reliably with minimal human intervention. This paperdescribes C loud B uild; the build service infrastructure developed within Microsoft over thelast few years. C loud B uild is responsible for all aspects of a continuous integrationworkflow; including builds; test and code analysis; as well as drops; package and symbolcreation and storage. C loud B uild supports multiple build languages as long as they fulfill acoarse grained; file IO based contract. C loud B uild uses content based caching to run build-related tasks only when needed. Lastly; it builds on many machines in parallel. C loud B uildoffers a reliable build service in the presence of unreliable components. It aims to rapidly …,Proceedings of the 38th International Conference on Software Engineering Companion,2016,12
Delivery controller between cloud and enterprise,*,A delivery controller for use in an enterprise environment that communicates with a cloudcomputing environment that is providing a service for the enterprise. As the cloud serviceprocessing progresses; some cloud service data is transferred from the cloud computingenvironment to the enterprise environment; and vice versa. The cloud service data may beexchanged over any one of a number of different types of communication channels. Thedelivery controller selects which communication channel to use to transfer specific data;depending on enterprise policy. Such policy might consider any business goals of theenterprise; and may be applied at the application level.,*,2013,10
Virtualizing Traffic Shapers for Practical Resource Allocation.,Gautam Kumar; Srikanth Kandula; Peter Bodik; Ishai Menache,Many network resource allocation scenarios would benefit from the use of traffic shapers;such as weighted fair queues (WFQs)[2]; priority queues [10] and rate limiters [11]. However;the number of such shapers implemented in hardware in switches; routers; and networkinterface cards (NICs) is very low; typically less than ten (see Table 1). Instead of simple useof hardware traffic shapers; network operators thus have to resort to more complex solutions.For example; public clouds such as Amazon Web Services and Windows Azure want to limitthe network bandwidth that is allocated to each VM along each path through their network.However; NICs only support a small number of rate limiters in hardware [11]. So; the cloudproviders implement rate limits in software; forcing all server traffic to go through thehypervisor. This results in both worse latency and lower throughput because it requires …,HotCloud,2013,10
Dccast: Efficient point to multipoint transfers across datacenters,Mohammad Noormohammadpour; Cauligi S Raghavendra; Sriram Rao; Srikanth Kandula,Abstract Using multiple datacenters allows for higher availability; load balancing andreduced latency to customers of cloud services. To distribute multiple copies of data; cloudproviders depend on inter-datacenter WANs that ought to be used efficiently consideringtheir limited capacity and the ever-increasing data demands. In this paper; we focus onapplications that transfer objects from one datacenter to several datacenters over dedicatedinter-datacenter networks. We present DCCast; a centralized Point to Multi-Point (P2MP)algorithm that uses forwarding trees to efficiently deliver an object from a source datacenterto required destination datacenters. With low computational overhead; DCCast selectsforwarding trees that minimize bandwidth usage and balance load across all links. Withsimulation experiments on Google's GScale network; we show that DCCast can reduce …,arXiv preprint arXiv:1707.02096,2017,8
Approximate query processing: no silver bullet,Surajit Chaudhuri; Bolin Ding; Srikanth Kandula,Abstract In this paper; we reflect on the state of the art of Approximate Query Processing.Although much technical progress has been made in this area of research; we are yet to seeits impact on products and services. We discuss two promising avenues to pursue towardsintegrating Approximate Query Processing into data platforms.,Proceedings of the 2017 ACM International Conference on Management of Data,2017,8
CloudProphet: predicting web application performance in the cloud,Ang Li; Xuanran Zong; Ming Zhang; Srikanth Kandula; Xiaowei Yang,Abstract–As public cloud computing services are gaining popularity; many are consideringmigrating their applications from on-premise to cloud. However; due to diverse cloudperformance; choosing the cloud platform that is the best suited to migrate is a difficultunsolved problem. In this work; we present CloudProphet; a low cost tool to accuratelypredict the end-to-end response time of an on-premise web application if migrated to acloud. CloudProphet collects a resource usage trace of the application running on-premise;and then replays it in cloud to predict performance. This approach does not require actualmigration; and is agnostic to both the application and the cloud platform. We address twokey design challenges in CloudProphet; including how to trace with both high fidelity andlow overhead; and how to extract and enforce application dependency. Our evaluation …,ACM SIGCOMM Poster,2011,7
Enriching driving experience with cloud assistance,*,Described is a technology by which driver safety technology such as collision detection isimplemented via mobile device (eg; smartphone) sensors and a cloud service thatprocesses data received from vehicles associated with the devices. Trajectory-related datais received at the cloud service and used to predict collisions between vehicles and/or lanedepartures of vehicles. To operate the service in real-time with low latency; also described isdividing driving areas into grids; eg; based upon traffic density; having parallel grid serverseach responsible for only vehicles in or approaching its own grid; and otherparallel/distributed mechanisms of the cloud service.,*,2015,6
Flyway Generation in Data Centers,*,The subject disclosure is directed towards configuring and controlling wireless flyways (eg;communication links between server racks provisioned on demand in a data center) tooperate efficiently and without interfering with one another. Control and flyway selection maybe based upon steered antenna directionality; channel; location in the data center; transmitpower; and measured and/or predicted (estimated) network traffic. Flyways also may beused to route indirect traffic to reduce traffic on a bottleneck (eg; wired) link. A payload maybe sent over a over a wireless flyway with acknowledgment via a wired backchannel so thatwireless communication is in one direction. The lack of interference and communication inone direction facilitates flyway operation without a backoff function and/or without clearchannel assessment.,*,2012,6
A case for resource heterogeneity in large sensor networks,Srikanth Kandula; Jennifer Hou; Lui Sha,Sensor networks have traditionally consisted of nodes with the same amount of resourcessuch as battery life and computational power. While such homogeneity has distinctadvantages in terms of ease-of-fabrication; it has also been shown that in multi-hop ad-hocscenarios homogeneity leads to large duty cycles; small end-to-end data throughput andpoor deployment lifetimes. In this paper; we investigate sensor networks that have a singledegree of heterogeneity; a random subset of the sensors; called accumulators; have morepower and computational capability. To this end; we develop a decentralized; hierarchicalclustering algorithm; called hierarchical clustering and routing (HCR) algorithm. HCRexploits heterogeneity among sensor nodes to form a cluster hierarchy; with the objective ofachieving better information throughput and improving network lifetime. A unique feature …,Military Communications Conference; 2004. MILCOM 2004. 2004 IEEE,2004,6
Interactive visualization to enhance automated fault diagnosis in networks,*,Described is a visual analytics system for network diagnostics. The visual analytics systemobtains network diagnostic-related information from a diagnostic system. The visualanalytics system includes an interactive user interface that displays the representations ofnetwork components; including network machines and; zero or more links between thosecomponents;(eg; as appropriate based upon selection or dynamic conditions). The userinterface includes a main network view that displays representations of networkcomponents; a diagnostics view that displays suggested diagnosis results obtained from thediagnostic system; and a performance counter view that displays performance counter data.User interaction with one of the views correspondingly changes the displays in the otherviews. The system allows effective exploration of multiple levels of detail; eg; variable …,*,2015,5
Low latency analytics of geo-distributed data in the wide area,Qifan Pu; Ganesh Ananthanarayanan; Peter Bodik; Srikanth Kandula; Aditya Akella; V Bahl; Ion Stoica,*,Proc. of ACM SIGCOMM,2015,5
Do the hard stuff first: Scheduling dependent computations in data-analytics clusters,Robert Grandl; Srikanth Kandula; Sriram Rao; Aditya Akella; Janardhan Kulkarni,Abstract: We present a scheduler that improves cluster utilization and job completion timesby packing tasks having multi-resource requirements and inter-dependencies. While theproblem is algorithmically very hard; we achieve near-optimality on the job DAGs thatappear in production clusters at a large enterprise and in benchmarks such as TPC-DS. Akey insight is that carefully handling the long-running tasks and those with tough-to-packresource needs will produce good-enough schedules. However; which subset of tasks totreat carefully is not clear (and intractable to discover). Hence; we offer a search procedurethat evaluates various possibilities and outputs a preferred schedule order over tasks. Anonline component enforces the schedule orders desired by the various jobs running on thecluster. In addition; it packs tasks; overbooks the fungible resources and guarantees …,arXiv preprint arXiv:1604.07371,2016,4
Ensuring predictable and quantifiable networking performance,*,The ensuring of predictable and quantifiable networking performance. Embodiments of theinvention combine a congestion free network core with a hypervisor based (ie; edge-based)throttling design to help insure quantitative and invariable subscription bandwidth rates. Alightweight shim layer in a hypervisor can adaptively throttle the rate of VM-to-VM traffic flow.A receiving hypervisor can detect congestion and communicate back to sending hypervisorsthat rates are to be regulated. In response; sending hypervisors can reduce transmissionrate to mitigate congestion at the receiving hypervisor. In some embodiments; the principlesare extended to any message processors communicating over a congestion free network.,*,2016,4
Application enhancement using edge data center,*,A management service that receives requests for the cloud computing environment to hostapplications; and improves performance of the application using an edge server. Inresponse to the original request; the management service allocates the application to run onan origin data center; evaluates the application by evaluating at least one of the applicationproperties designated by an application code author or provider; or the applicationperformance; and uses an edge server to improve performance of the application inresponse to evaluating the application. For instance; a portion of application code may beoffloaded to run on the edge data center; a portion of application data may be cached at theedge data center; or the edge server may add functionality to the application.,*,2013,4
Backing creativity,Neil Savage,Hacker spaces are spreading around the world; though some government funding is raisingquestions. bots to go-karts. DARPA plans to provide $10 million to 1;000 schools over threeyears to promote science; technology; engineering; and mathematics (STEM) education.O'Reilly's involvement led some hackers to boycott the Maker Faire. One of the chief critics isMitch Altman; co-founder of the San Francisco hacker space Noisebridge; who worries thatDARPA will steer work in spaces it funds toward military applications; uses he does not wanthis efforts supporting.“I see the military as going out and bombing and killing; not fordefending our country but for other purposes;” he says. Even though the US DefenseDepartment says the DARPA funding comes with no strings; Altman does not believethat.“When a politician accepts gifts from individuals and corporations; it's very likely …,Communications of the ACM,2013,4
Visflow: a relational platform for efficient large-scale video analytics,Yao Lu; Aakanksha Chowdhery; Srikanth Kandula,Abstract–We describe VisFlow; a system that efficiently analyzes the feeds from manycameras. Ubiquitous camera deployments are widely used for security; traffic monitoring;and customer analytics. However; existing methods to analyze the video feeds in real-timeor postfacto do not scale and are error-prone. Our key contributions are two-fold.Surveillance video is hard to analyze because it has low-resolution; many objects per frame;varying light; etc. By leveraging the fixed perspective of surveillance cameras; we show thattypical vision tasks can be performed with high accuracy. Next; to efficiently process manyfeeds; we use a relational dataflow system. We observe that (i) even vision queries thatseem different have common parts (eg; background subtraction and feature extraction);(ii)often neither camera-level or frame-level parallelism lead to good executions; and (iii) the …,ACM Symposium on Cloud Computing (SoCC),2016,3
Computing long-term schedules for data transfers over a wide area network,*,Various technologies pertaining to scheduling network traffic in a network are described. Arequest to transfer data from a first computing device to a second computing device includesdata that identifies a volume of the data to be transferred and a deadline; where the data isto be transferred prior to the deadline. A long-term schedule is computed based upon therequest; wherein the long-term schedule defines flow of traffic through the network over arelatively long time horizon. A short-term schedule is computed based upon the long-termschedule; where devices in the network are configured based upon the short-term schedule.,*,2015,3
Dynamic scheduling of network updates,*,Abstract The techniques and/or systems described herein are configured to determine a setof update operations to transition a network from an observed network state to a targetnetwork state and to generate an update dependency graph used to dynamically schedulethe set of update operations based on constraint (s) defined to ensure reliability of thenetwork during the transition. The techniques and/or systems dynamically schedule the setof update operations based on feedback. For example; the feedback may include anindication that a previously scheduled update operation has been delayed; has failed; orhas been successfully completed.,*,2018,2
Optasia: A relational platform for efficient large-scale video analytics,Yao Lu; Aakanksha Chowdhery; Srikanth Kandula,Abstract Camera deployments are ubiquitous; but existing methods to analyze video feedsdo not scale and are error-prone. We describe Optasia; a dataflow system that employsrelational query optimization to efficiently process queries on video feeds from manycameras. Key gains of Optasia result from modularizing vision pipelines in such a mannerthat relational query optimization can be applied. Specifically; Optasia can (i) de-duplicatethe work of common modules;(ii) auto-parallelize the query plans based on the video inputsize; number of cameras and operation complexity;(iii) offers chunk-level parallelism thatallows multiple tasks to process the feed of a single camera. Evaluation on traffic videos froma large city on complex vision queries shows high accuracy with many fold improvements inquery completion time and resource usage relative to existing systems.,Proceedings of the Seventh ACM Symposium on Cloud Computing,2016,2
SWAN: achieving high utilization in networks,*,Greater network utilization is implemented through dynamic network reconfiguration andallocation of network services and resources based on the data to be transferred and theconsumer transferring it. A hierarchical system is utilized whereby requests from lower layersare aggregated before being provided to upper layers; and allocations received from upperlayers are distributed to lower layers. To maximize network utilization; paths through thenetwork are reconfigured by identifying specific types of packets that are to be flagged in aspecific manner; and then by further identifying specific routing rules to be applied in thetransmission of such packets. Network reconfiguration is performed on an incremental basisto avoid overloading a path; and capacity can be reserved along one or more paths toprevent such overloading. Background data is agnostic as to specific transmission times …,*,2015,2
Act for affordable data care,Saikat Guha; Srikanth Kandula,Abstract Data breaches; eg. malware; network intrusions; or physical theft; that lead to thecompromise of users' personal data; happen often. The impacted companies lose reputationand have to spend millions of dollars providing affected users with identity and creditmonitoring services. Users can suffer from fraudulent transactions and identity theft. Atpresent; there are no mechanisms that both cover the risk from accidental data breachesand incentivise best practices that would prevent such breaches. This paper proposes adata breach insurance mechanism and the associated risk assessment technology to meetthese goals. In so doing; we break from (failed) past approaches that seek to solve theproblem solely through technology.,Proceedings of the 11th ACM Workshop on Hot Topics in Networks,2012,2
Integrated Network Performance Diagnostics,Srikanth Kandula; Anees Shaikh; Erich Nahum,One of the most challenging parts of running a networkbased service is monitoring andmanaging performance. End-to-end performance may be influenced by numerous factors;and problems are not easily attributable to their correct source [1]. When a performanceproblem arises; the service provider or customer has available a number of tools to aid indiagnosing performance issues; each of which test different aspects of the network service.Client-perceived performance; for example; requires the use of application-layer tests tomeasure the application response time. Such tests can be conducted for Webbasedapplications using tools like PageDetailer [2] or services provided by companies such asKeynote Systems [3]. Low-level network properties such as connectivity and latency may betested using tools like traceroute or ping. Network protocol behavior can be examined in …,Urbana,2002,2
QuickCast: Fast and Efficient Inter-Datacenter Transfers using Forwarding Tree Cohorts,Mohammad Noormohammadpour; Cauligi S Raghavendra; Srikanth Kandula; Sriram Rao,Abstract: Large inter-datacenter transfers are crucial for cloud service efficiency and areincreasingly used by organizations that have dedicated wide area networks betweendatacenters. A recent work uses multicast forwarding trees to reduce the bandwidth needsand improve completion times of point-to-multipoint transfers. Using a single forwarding treeper transfer; however; leads to poor performance because the slowest receiver dictates thecompletion time for all receivers. Using multiple forwarding trees per transfer alleviates thisconcern--the average receiver could finish early; however; if done naively; bandwidth usagewould also increase and it is apriori unclear how best to partition receivers; how to constructthe multiple trees and how to determine the rate and schedule of flows on these trees. Thispaper presents QuickCast; a first solution to these problems. Using simulations on real …,arXiv preprint arXiv:1801.00837,2018,1
Errata and proofs for “quickr”,Srikanth Kandula,• The transitivity theorem; in Proposition 1 of Quickr; has a revision in item iii. The revisedversion is Proposition 5 in this document.• Definition 1 in Appendix B. 2; which definesdominance; has a revision in the condition for c-dominance. The revised version is Definition1 in this document. We also offer new definitions of equivalence and weak equivalence.•The dominance pushdown rules in Appendix B. 3 have; in general; been revised andsubstantially expanded. In particular; Proposition 7 in Quickr; which relates to projectionsthat drop columns is simple but incomplete; Propositions 8 and 9 in this document considerthe case of projections that rename columns and create new columns respectively.Proposition 8 in Quickr; which relates to pushing samplers past selections; is replaced withProposition 10 in this document. Finally; we separate the Proposition 9 in Quickr; which …,*,2017,1
Estimating and predicting fuel usage with smartphone,*,Examples are disclosed herein that relate to estimating and predicting vehicular fuel use.One example estimates fuel usage by a vehicle during a trip by obtaining sensormeasurements from one or more sensors of a mobile computing device during the trip;determining a plurality of trip features from the sensor measurements; each trip featurerepresenting an aspect of one or more of energy produced and energy consumed during thetrip; obtaining vehicle-specific parameters of the vehicle; and determining an estimated fuelusage from the vehicle-specific parameters and the plurality of trip features for output by thecomputing device.,*,2016,1
Packing and Dependency-Aware Scheduling for Data-Parallel Clusters,Robert Grandl; Srikanth Kandula; Sriram Rao; Aditya Akella; Janardhan Kulkarni,*,12th USENIX Symposium on Operating Systems Design and Implementation (OSDI 16),2016,1
Network services provided in cloud computing environment,*,A cloud computing environment providing a network service for a client computing entity.The network service is not an application level service; but rather a service that operates ator below the network layer in the protocol stack. For instance; the network service might be anetwork endpoint service such as a network address service (such as DNS) or a dynamicnetwork service (such as DHCP); or a network traffic service such as a firewall service or asecure tunneling service (such as VPN). The service might also provide a pipeline ofnetwork services for network level traffic to and from the client computing entity. The cloudenvironment uses policy to determine which of a plurality of communication channels to usewhen exchanging cloud service data for the network service.,*,2014,1
Surviving DDoS Attacks,Srikanth Kandula,Información del artículo Surviving DDoS attacks.,; login:: the magazine of USENIX & SAGE,2005,1
Controlling approximations of queries,*,One or more approximations of query output in a data analytics platform are controlled. Theone or more approximations are controlled by generating values of error metrics associatedwith placements of samplers in one or more query execution plans associated with thequery; and injecting a plurality of samplers into the query execution plans; using thedetermined values of the error metrics; in lieu of storing samples of input to the query prior toexecution of the query.,*,2017,*
Harnessing path diversity for laser control in data center optical networks,Y Demir; N Terzenidis; H Han; D Syrivelis; GT Kanellos; N Hardavellas; N Pleros; S Kandula; F Bustamante,Optical interconnects are already the dominant technology in large-scale datacenternetworks. Unfortunately; the high optical loss of many optical components; coupled with thelow efficiency of laser sources; result in high aggregate power requirements for thethousands of optical transceivers that such networks employ. As optical interconnects stayalways on; even during periods of system inactivity; most of this power is wasted. Ideally wewould like to turn off the transceivers when a network link is idle (ie;“power gate” the lasers);and turn them back on right before the next transmission. The danger with this approach isthat it may expose the laser turn-on delay and lead to higher network latency. However; datacenter networks typically employ network topologies with path diversity and facilitate multiplepaths for each source-destination pair. Based on this observation; we propose an optical …,Photonics Society Summer Topical Meeting Series (SUM); 2017 IEEE,2017,*
Latency reduction with pre-moving of distributed data and adaptive allocating of compute operations,*,Latency in responding to queries directed to geographically distributed data can be reducedby allocating individual steps; of a multi-step compute operation requested by the query;among the geographically distributed computing devices so as to reduce the duration ofshuffling of intermediate data among such devices; and; additionally; by pre-moving; prior tothe receipt of the query; portions of the distributed data that are input to a first step of themultistep compute operation; to; again; reduce the duration of the exchange of intermediatedata. The pre-moving of input data occurring; and the adaptive allocation of intermediatesteps; are prioritized for high-value data sets. Additionally; a threshold increase in a quantityof data exchanged across network communications can be established to avoid incurringnetwork communication usage without an attendant gain in latency reduction.,*,2017,*
Ensuring predictable and quantifiable networking performance,*,The ensuring of predictable and quantifiable networking performance includes adaptivelythrottling the rate of VM-to-VM traffic flow. A receiving hypervisor can detect congestion andcommunicate messages for throttling traffic flow to reduce congestion at the receivinghypervisor.,*,2017,*
Proactive handling of network faults,*,The techniques and/or systems described herein implement a fault handling service that isable to ensure that at least part of a network can avoid congestion (eg; a link exceedingcapacity) as long as a predetermined maximum number of faults is not exceeded. The faulthandling service models different combinations of possible faults based on network topologyand then computes an amount of traffic to be communicated via individual paths such thatcongestion is avoided as long as a number of actual faults that occur is less than or equal tothe predetermined maximum number of faults.,*,2017,*
Automated controlling of host over network,*,The provisioning of a host computing system by a controller located over a wide areanetwork. The host computing system has power-on code that automatically executes uponpowering up; and causes the host to notify the controller of the host address. In a first level ofbootstrapping; the controller instructs the host to download a maintenance operating system.The host responds by downloading and installing a maintenance operating system;enabling further bootstrapping. The persistent memory may further have security data; suchas a public key; that allows the host computing system to securely identify the source of thedownload instructions (and subsequent instructions) as originating from the controller. Asecond level of bootstrapping may accomplish the configuring of the host with a hypervisorand a host agent. A third level of bootstrapping may accomplish the provisioning of virtual …,*,2016,*
Computing cluster with latency control,*,A computing cluster operated according to a resource allocation policy based on apredictive model of completion time. The predictive model may be applied in a resourcecontrol loop that iteratively updates resources assigned to an executing job. At eachiteration; the amount of resources allocated to the job may be updated based on of thepredictive model so that the job will be scheduled to complete execution at a targetcompletion time. The target completion time may be derived from a utility functiondetermined for the job. The utility function; in turn; may be derived from a service levelagreement with service guarantees and penalties for late completion of a job. Allocatingresources in this way may maximize utility for an operator of the computing cluster whileminimizing disruption to other jobs that may be concurrently executing.,*,2016,*
VisFlow: A Declarative Platform for Parallelizing Large-Scale Vision Programs,Yao Lu; Aakanksha Chowdhery; Srikanth Kandula,Large-scale image and video datasets are becoming increasingly important in bothacademic and production systems. Existing big-data platforms; such as Map-Reduce orSpark; are sub-optimal in processing these datasets due to the following reasons.(1)Performance. Multiple factors; such as resource allocation or parallel scheduling; affect thecompletion time of executing a program on the cluster. However; current systems do notautomatically apply an optimal strategy to minimize the completion time; manually optimizingthe program based on the available infrastructure can be tedious and time-consuming.(2)Usability. Existing platforms require special programming expertise (languages; APIs; etc.);while popular libraries such as OpenCV and Caffe are not naturally deployed on clusters.We present VisFlow that addresses the above issues. Vis-Flow borrows the ideas from …,The 4th International Workshop on Large Scale Visual Recognition and Retrieval (CVPR Workshop); Las Vegas; USA,2016,*
Enriching driving experience with cloud assistance,*,Described is a technology by which driver safety technology such as collision detection isimplemented via mobile device (eg; smartphone) sensors and a cloud service thatprocesses data received from vehicles associated with the devices. Trajectory-related datais received at the cloud service and used to predict collisions between vehicles and/or lanedepartures of vehicles. To operate the service in real-time with low latency; also described isdividing driving areas into grids; eg; based upon traffic density; having parallel grid serverseach responsible for only vehicles in or approaching its own grid; and otherparallel/distributed mechanisms of the cloud service.,*,2015,*
Offloading virtual machine flows to physical queues,*,The present invention extends to methods; systems; and computer program products foroffloading virtual machine flows to physical queues. A computer system executes one ormore virtual machines; and programs a physical network device with one or more rules thatmanage network traffic for the virtual machines. The computer system also programs thenetwork device to manage network traffic using the rules. In particular; the network device isprogrammed to determine availability of one or more physical queues at the network devicethat are usable for processing network flows for the virtual machines. The network device isalso programmed to identify network flows for the virtual machines; including identifyingcharacteristics of each network flow. The network device is also programmed to; based onthe characteristics of the network flows and based on the rules; assign one or more of the …,*,2015,*
Flyways in data centers,*,Described is a technology by which additional network communications capacity is providedto an oversubscribed base network where needed; through the use of dynamicallyprovisioned communications links referred to as flyways. A controller detects a need foradditional network communications capacity between two network machines; eg; betweentwo racks of servers with top-of-rack switches. The controller configures flyway mechanisms(eg; one per rack) to carry at least some of the network traffic between the machines of theracks and thereby provide the additional network communications capacity. The flywaymechanisms may be based on any wireless or wired technologies; including 60 GHztechnology; optical links; 802.11 n or wired commodity switches.,*,2015,*
Modeling non-convex costs in an LP (for traffic engineering on WANs),Srikanth Kandula; Brendan Lucier; Ishai Menache; Mohit Singh,Formulation. A byte request; indexed by i; has a quantity of data di to be routed; and a valueper byte vi. The request indicates the source Si and target Ti; data must be transmitted alonga path from Si to Ti. Write Ri for the set of admissible paths (or routes) for request i. Let Xirtdenote the number of bytes from request i transmitted along route r∈ Ri at time t. Thequantities X=(Xirt) fully describe a schedule of transfers. The objective of TE is to maximizewelfare (values minus costs). Formally; the objective is maximize− C (X)+∑ i,*,2015,*
usenix conference policies,Rodrigo Fonseca; Dave Maltz; Hitesh Balani; Byung-Gon Chun; Ali Ghodsi; Sharon Goldberg; Jeff Hammerbacher; Joe Hellerstein; Bill Howe; Srikanth Kandula; Dejan Kostić; Michael A Kozuch; Hui Lei; Michael Locasto; David Oppenheimer; KyoungSoo Park; George Porter; Thomas Ristenpart; Xiaowei Yang; Lihua Yuan; John Arrasjid; Erich Nahum; Sambit Sahu; Margo Seltzer; Ion Stoica; John Wilkes; Dongyan Xu,Abstract: Kernel concurrency bugs are notoriously difficult to find during testing since theyare only triggered under certain instruction interleavings. Unfortunately; no tools forsystematically subjecting kernel code to concurrency tests have been proposed to date. Thisgap in tool support may be explained by the challenge of controlling precisely which kernelinterleavings are executed without modifying the kernel under test itself. Furthermore; to bepractical; prohibitive runtime overheads must be avoided and tools must remain portable asthe kernel evolves.,*,2014,*
Virtualizing Trafﬁc Shapers for Practical Resource Allocation,Gautam Kumar; Srikanth Kandula; Peter Bodik; Ishai Menache,Skip to main content …,Presented as part of the 5th {USENIX} Workshop on Hot Topics in Cloud Computing,2013,*
Increasing the robustness of networked systems,Srikanth Kandula,Abstract What popular news do you recall about networked systems? You've probably heardabout the several hour failure at Amazon's computing utility that knocked down manystartups for several hours; or the attacks that forced the Estonian government web-sites to beinaccessible for several days; or you may have observed inexplicably slow responses orerrors from your favorite web site. Needless to say; keeping networked systems robust toattacks and failures is an increasingly significant problem. Why is it hard to keep networkedsystems robust? We believe that uncontrollable inputs and complex dependencies are thetwo main reasons. e owner of a web-site has little control on when users arrive; the operatorof an ISP has little say in when a fiber gets cut; and the administrator of a campus network isunlikely to know exactly which switches or file-servers may be causing a user's sluggish …,*,2009,*
Hossein Falaki,Hossein Falaki; Ratul Mahajan; Srikanth Kandula; Dimitrios Lymberopoulos; Ramesh Govindan; Deborah Estrin,Page 1. Hossein Falaki Center for Embedded Networked Sensing UCLA 3563 Boelter Hall LosAngeles; CA 90095-1596 Email: falaki@cs.ucla.edu Phone: 401-281-9390 Fax: 310-206-3053Research Interests I am interested in Computer Networks; Operating Systems; and Wirelessand Mobile Systems. Education Ph.D. Computer Science University of California; Los Angeles;USA Present GPA: 4.0 MMath. Computer Science University of Waterloo; Canada 2008 GPA:4.0 BS. Computer Engineering Sharif University of Technology; Iran 2006 GPA: 3.53 Diploma;Mathematics and Physics National Organization for Exceptional Talents; Iran 2002 GPA: 4.0Research Experience Research Assistant Center for Embedded Networked Sensing Universityof California; Los Angeles; USA 2008-present I am a research assistant of Prof. Deborah Estrinon the Participatory Sensing project. Research Intern …,Conference on Information Technologies and Development,2007,*
A note to predict the thickness of the resin coating with time-a moving boundary problem,V Dharma Rao; GS Murty; PK Sarma,CONCLUSIONS (1) In the presence of more than 0 20% w/w actkvated carbon and m therange of the speed of aatation and the concentration of sodium sulfide used m the presentstudy; which are representative of con&Ions employed m mdustrlal practice; the reaction 1scontrolled by the drffusron of oxygen mto the liquid phase,Chemical Engineering Science,1977,*
Sinbad,Mosharaf Chowdhury; Srikanth Kandula; Ion Stoica,Page 1. Sinbad Leveraging Endpoint Flexibility in Data-Intensive Clusters Mosharaf Chowdhury;Srikanth Kandula; Ion Stoica UC Berkeley Page 2. Communication is Crucial for Analytics at ScalePerformance Facebook analytics jobs spend 33% of their runtime in communication1 As in-memorysystems proliferate; the network is likely to become the primary bottleneck 1. Managing DataTransfers in Computer Clusters with Orchestra; SIGCOMM'2011 Page 3. Network Usage isImbalanced1 Facebook 0 0.25 0.5 0.75 1 0 1 2 3 4 5 6 Fraction of Time Coeff. of Var.2 of LoadAcross Core-Rack Links Bing 0 0.25 0.5 0.75 1 0 1 2 3 4 Fraction of Time Coeff. of Var. of LoadAcross Core-Rack Links More than 50% of the time; links have high imbalance (C v > 1). 1.Imbalance considering all cross-rack bytes. Calculated in 10s bins. 2. Coefficient of variation; Cv =(stdev/mean). Imbalance (Coeff. of Var.2 of Link Utilization) …,*,*,*
Resource Management with Deep Reinforcement Learning,Yashovardhan Sharma; Hongzi Mao; Mohammad Alizadeh; Ishai Menache; Srikanth Kandula,Page 1. Resource Management with Deep Reinforcement Learning 1 Yashovardhan SharmaHongzi Mao; Mohammad Alizadeh; Ishai Menache; Srikanth Kandula Page 2. Problem Page 3.Problem… • Resource management problems in systems • Current solutions are complicated andtake painstaking effort to implement • Can systems learn to manage resources on their own? Page4. Solution Page 5. What do they suggest? • Use Machine Learning (obviously!) • But do we needML for this problem? • They argue : 1. Underlying systems are complex; hard to model accurately2. Have to make online decisions with noisy inputs; should work well under diverse conditions3. Some performance metrics are hard to optimise in a principled manner Page 6. Key Idea •Reinforcement Learning • Agent learns directly from experience; by interacting with the environment •They believe that this approach is particularly well …,*,*,*
Optasia: A Relational Platform for E cient Large-Scale Video Analytics,Yao Lu; Aakanksha Chowdhery; Srikanth Kandula,Abstract Camera deployments are ubiquitous; but existing methods to analyze video feedsdo not scale and are error-prone. We describe Optasia; a dataflow system that employsrelational query optimization to e ciently process queries on video feeds from manycameras. Key gains of Optasia result from modularizing vision pipelines in such a mannerthat relational query optimization can be applied. Speci cally; Optasia can (i) de-duplicatethe work of common modules;(ii) auto-parallelize the query plans based on the video inputsize; number of cameras and operation complexity;(iii) offers chunk-level parallelism thatallows multiple tasks to process the feed of a single camera. Evaluation on tra c videos froma large city on complex vision queries shows high accuracy with many fold improvements inquery completion time and resource usage relative to existing systems.,*,*,*
Enhancing Datacenter Network Security and Scalability with Trusted End Host Monitors,Alan Shieh; Srikanth Kandula; Albert Greenberg,Although datacenters dedicated for cloud computing services are becoming increasinglyprevalent; the current datacenter network security architecture is poorly suited for thisapplication. Policy enforcement is smeared between the network and end hosts; increasingcost and complexity while reducing flexibility and security. Enforcement is typically done atnetwork chokepoints; which inherently see high traffic levels from aggregate traffic; packetfilters and deep packet inspection engines that can operate at these data rates requireexpensive; custom hardware. Elasticity to tenant demand and hosting untrusted tenantapplications are central features of cloud computing that present further challenges. Astenant VMs and applications are spun up or migrated; the common infrastructure needs tobe reconfigured; reducing performance and pulling the network devices into the trusted …,*,*,*
Inside the Social Network’s (Datacenter) Network–Public,Srikanth Kandula,This paper presents a first look into the traffic characteristics of the workloads in datacentersoperated by Facebook. In doing so; the paper extends the publicly available knowledge-base on production workloads. As well; it offers some novel and interesting measurements.First; the Hadoop clusters operated at Facebook exhibit substantially smaller amounts ofrack locality than previously reported. That is; more than 80% of the traffic crosses racks.Second; in spite of the above lack of locality; the overall network link utilization is quite small–an average of less than 10% on all potential bottlenecks. Links that support Hadoop trafficare much more likely to have a higher load relative to other links in the datacenter. And;diurnal changes in request load from users accounts for only a modest variation in networktraffic (about 2×). Third; the other dominant application at Facebook is memcached-style …,*,*,*
JOSEPH L. HELLERSTEIN,SRIKANTH KANDULA,The Industrial Partners Program (IPP) provides a formal mechanism for interactions betweenindustry and the Brown Department of Computer Science. Member companies benefit from superiorvisibility in the Department; exclusive access to event/interview space in the CIT and assistancewith the recruiting process; students benefit from specific information about opportunities for summerinternships and full-time employment. Opportunities are also available for partners to form researchcollaborations with our faculty. The Department wishes to thank our industrial partners … AffiliatesApple Facebook Google GTECH Microsoft NetApp Oracle VMware … Individuals PaulEdelman; Edelman & Associates Robert Khoury; Worldwide Financial Industry Recruiting Services… To learn more about the Industrial Partners Program; contact: Amy Tarbox; Program ManagerTelephone: 401- 863-7610 abt@cs.brown.edu … 8:30-8:50 Breakfast & Registration …,*,*,*
Instrumentation and Debugging Session Chair: Val Henson; Sun Making the" Box" Transparent: System Call Performance as a First-Class Result Yaoping Ruan and...,Bryan M Cantrill; Michael W Shapiro; Adam H Leventhal; Sudarshan M Srinivasan; Christopher R Andrews; Srikanth Kandula; Yuanyuan Zhou; Autonomic Computing,Trade magazines are buzzing about reducing the size of system administration staff by usingcomputers that administer themselves; tune themselves; and generally behave" as theyshould." Two sessions will present opposite points of view on attacking these problems; onewith centralized administration and one using techniques that feel more like peer-to-peer.,*,*,*
DDoS attacks,SRIKANTH KANDULA,Alyssa Hacker subverts tens of thousands of machines by using a worm and then uses thesezombies to mount a distributed denial of service attack on a Web server. Alyssa's zombiesdo not launch a SYN flood or issue dummy packets that will only congest the Web server'saccess link. Instead; the zombies fetch files or query search engine databases at the Webserver. From the Web server's perspective; these zombie requests look exactly likelegitimate requests; so the server ends up spending a lot of its time serving the zombies;causing legitimate users to be denied service. Such an attack; which we call CyberSlam; isdisconcertingly real. In a recent FBI case; a Massachusetts businessman hired professionalsto DDoS his competitor's Web site [1]. Like any other online business; the competitor had asearch engine back end. So the professionals used a large botnet to flood the …,*,*,*
