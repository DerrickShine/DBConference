A prime number labeling scheme for dynamic ordered XML trees,Xiaodong Wu; Mong Li Lee; Wynne Hsu,Efficient evaluation of XML queries requires the determination of whether a relationshipexists between two elements. A number of labeling schemes have been designed to labelthe element nodes such that the relationships between nodes can be easily determined bycomparing their labels. With the increased popularity of XML on the Web; finding a labelingscheme that is able to support order-sensitive queries in the presence of dynamic updatesbecomes urgent. We propose a new labeling scheme that take advantage of the uniqueproperty of prime numbers to meet this need. The global order of the nodes can be capturedby generating simultaneous congruence values from the prime number node labels.Theoretical analysis of the label size requirements for the various labeling schemes is given.Experiment results indicate that the prime number labeling scheme is compact compared …,Data Engineering; 2004. Proceedings. 20th International Conference on,2004,301
XClust: clustering XML schemas for effective integration,Mong Li Lee; Liang Huai Yang; Wynne Hsu; Xia Yang,Abstract It is increasingly important to develop scalable integration techniques for thegrowing number of XML data sources. A practical starting point for the integration of largenumbers of Document Type Definitions (DTDs) of XML sources would be to first find clustersof DTDs that are similar in structure and semantics. Reconciling similar DTDs within such acluster will be an easier task than reconciling DTDs that are different in structure andsemantics as the latter would involve more restructuring. We introduce XClust; a novelintegration strategy that involves the clustering of DTDs. A matching algorithm based on thesemantics; immediate descendents and leaf-context similarity of DTD elements isdeveloped. Our experiments to integrate real world DTDs demonstrate the effectiveness ofthe XClust approach.,Proceedings of the eleventh international conference on Information and knowledge management,2002,297
Supporting frequent updates in r-trees: A bottom-up approach,Mong Li Lee; Wynne Hsu; Christian S Jensen; Bin Cui; Keng Lik Teo,This paper proposes a generalized bottom-up update strategy for R-trees. This strategy ismotivated by the class of monitoring applications; which are characterized by large volumesof updates; and the increasingly important role of indexing. This update strategy can easilybe applied to the members of the family of R-tree-based indexing techniques; as it preservesthe index structure and takes into account concurrency control. The strategy improves therobustness of R-trees by supporting different levels of index reorganization—ranging fromlocal to global—during updates; thus using expensive top-down updates only whennecessary. This chapter presents a compact main-memory summary structure along withefficient bottom-up algorithms that reduce the numbers of disk accesses and CPU resourcesused for update and querying. Empirical studies indicate that the new strategy …,Proceedings of the 29th international conference on Very large data bases-Volume 29,2003,237
An effective approach to detect lesions in color retinal images,Huan Wang; Wynne Hsu; Kheng Guan Goh; Mong Li Lee,Diabetic-related eye diseases are the most common cause of blindness in the world. So farthe most effective treatment for these eye diseases is early detection through regularscreening. To lower the cost of such screenings; we employ state-of-the-art imageprocessing techniques to automatically detect the presence of abnormalities in the retinalimages obtained during the screenings. The authors focus on one of the abnormal signs: thepresence of exudates/lesions in the retinal images. We propose a novel approach thatcombines brightness adjustment procedure with statistical classification method and local-window-based verification strategy. Experimental results indicate that we are able to achieve100% accuracy in terms of identifying all the retinal images with exudates while maintaininga 70% accuracy in correctly classifying the truly normal retinal images as normal. This …,Computer Vision and Pattern Recognition; 2000. Proceedings. IEEE Conference on,2000,206
IntelliClean: a knowledge-based intelligent data cleaner,Mong Li Lee; Tok Wang Ling; Wai Lup Low,ABSTRACT Existing data cleaning methods work on the basis of computing the degree ofsimilarity between nearby records in a sorted database. High recall is achieved by acceptingrecords with low degrees of similarity as duplicates; at the cost of lower precision. Highprecision is achieved analogously at the cost of lower recall. This is the rec all-precisiondilemma. In this paper; we propose a generic knowledge-based framework for e ective datacleaning that implements existing cleaning strategies and more. We develop a new methodto compute transitive closure under uncertaint ywhich handles the merging of groups ofinexact duplicate records. Experimental results show that this framework can identifyduplicates and anomalies with high recall and precision.,Proceedings of the sixth ACM SIGKDD international conference on Knowledge discovery and data mining,2000,200
Cleansing data for mining and warehousing,Mong-Li Lee; Hongjun Lu; Tok Wang Ling; Yee Teng Ko,Abstract Given the rapid growth of data; it is important to extract; mine and discover usefulinformation from databases and data warehouses. The process of data cleansing is crucialbecause of the “garbage in; garbage out” principle.“Dirty” data files are prevalent because ofincorrect or missing data values; inconsistent value naming conventions; and incompleteinformation. Hence; we may have multiple records refering to the same real world entity. Inthis paper; we examine the problem of detecting and removing duplicating records. Wepresent several efficient techniques to pre-process the records before sorting them so thatpotentially matching records will be brought to a close neighbourhood. Based on thesetechniques; we implement a data cleansing system which can detect and remove moreduplicate records than existing methods.,DEXA,1999,196
Image mining: Trends and developments,Wynne Hsu; Mong Li Lee; Ji Zhang,Abstract Advances in image acquisition and storage technology have led to tremendousgrowth in very large and detailed image databases. These images; if analyzed; can revealuseful information to the human users. Image mining deals with the extraction of implicitknowledge; image data relationship; or other patterns not explicitly stored in the images.Image mining is more than just an extension of data mining to image domain. It is aninterdisciplinary endeavor that draws upon expertise in computer vision; image processing;image retrieval; data mining; machine learning; database; and artificial intelligence. In thispaper; we will examine the research issues in image mining; current developments in imagemining; particularly; image mining frameworks; state-of-the-art techniques and systems. Wewill also identify some future research directions for image mining.,Journal of Intelligent Information Systems,2002,184
Designing functional dependencies for XML,Mong Li Lee; Tok Wang Ling; Wai Lup Low,Abstract Functional dependencies are an integral part of database theory and they form thebasis for normalizing relational tables up to BCNF. With the increasing relevance of the data-centric aspects of XML; it is pertinent to study functional dependencies in the context of XML;which will form the basis for further studies into XML keys and normalization. In this work; weinvestigate the design of functional dependencies in XML databases. We propose FD XML;a notation and DTD for representing functional dependencies in XML. We observe that manydatabases are hierarchical in nature and the corresponding nested XML data 1 mayinevitably contain redundancy. We develop a model based on FD XML to estimate theamount of data replication in XML data. We show how functional dependencies in XML canbe verified with a single pass through the XML data; and present supporting experimental …,International Conference on Extending Database Technology,2002,180
Efficient mining of XML query patterns for caching,Liang Huai Yang; Mong Li Lee; Wynne Hsu,This chapter discusses the efficient mining of XML query patterns for caching. As XMLbecomes ubiquitous; the efficient retrieval of XML data becomes critical. Research toimprove query response time has been largely concentrated on indexing paths andoptimizing XML queries. An orthogonal approach is to discover frequent XML query patternsand cache their results to improve the performance of XML management systems. Thischapter presents an efficient algorithm called Fast X-Miner; to discover frequent XML querypatterns. This chapter develops theorems to prove that only a small subset of the generatedcandidate patterns needs to undergo expensive tree containment tests. In addition; itdemonstrates how the frequent query patterns can be used to improve caching performance.Experiment results show that Fast X-Miner is efficient and scalable; and caching the …,Proceedings of the 29th international conference on Very large data bases-Volume 29,2003,139
Icicles: Self-tuning samples for approximate query answering,Venkatesh Ganti; Mong-Li Lee; Raghu Ramakrishnan,Abstract Approximate query answering systems provide very fast alternatives to OLAPsystems when applications are tolerant to small errors in query answers. Current sampling-based approaches to approximately answer aggregate queries over foreign key joins sufferfrom the following drawback. All tuples in relations are deemed equally important foranswering queries even though; in reality; OLAP queries exhibit locality in their data access.Consequently; they may waste precious real estate by sampling tuples that are not requiredat all or required very rarely. In this paper; we introduce icicles; a new class of samples thattune themselves to a dynamic workload. Intuitively; the probability of a tuple being present inan icicle is proportional to its importance for answering queries in the workload. Therefore;an icicle consists of more tuples from a subset of the relation that is required to answer …,VLDB,2000,138
Image mining: Issues; frameworks and techniques,Ji Zhang; Wynne Hsu; Mong Li Lee,Abstract Advances in image acquisition and storage technology have led to tremendousgrowth in significantly large and detailed image databases. These images; if analyzed; canreveal useful information to the human users. Image mining deals with the extraction ofimplicit knowledge; image data relationship; or other patterns not explicitly stored in theimages. Image mining is more than just an extension of data mining to image domain. It is aninterdisciplinary endeavor that draws upon expertise in computer vision; image processing;image retrieval; data mining; machine learning; database; and artificial intelligence. Despitethe development of many applications and algorithms in the individual research fields citedabove; research in image mining is still in its infancy. In this paper; we will examine theresearch issues in image mining; current developments in image mining; particularly …,Proceedings of the 2nd ACM SIGKDD International Workshop on Multimedia Data Mining (MDM/KDD'01),2001,137
Quantitative assessment of early diabetic retinopathy using fractal analysis,Ning Cheung; Kim C Donaghue; Gerald Liew; Sophie L Rogers; Jie Jin Wang; Shueh-Wen Lim; Alicia J Jenkins; Wynne Hsu; Mong Li Lee; Tien Y Wong,OBJECTIVE—Fractal analysis can quantify the geometric complexity of the retinal vascularbranching pattern and may therefore offer a new method to quantify early diabeticmicrovascular damage. In this study; we examined the relationship between retinal fractaldimension and retinopathy in young individuals with type 1 diabetes. RESEARCH DESIGNAND METHODS—We conducted a cross-sectional study of 729 patients with type 1 diabetes(aged 12–20 years) who had seven-field stereoscopic retinal photographs taken of botheyes. From these photographs; retinopathy was graded according to the modified AirlieHouse classification; and fractal dimension was quantified using a computer-based programfollowing a standardized protocol. RESULTS—In this study; 137 patients (18.8%) haddiabetic retinopathy signs; of these; 105 had mild retinopathy. Median (interquartile range …,Diabetes care,2009,133
A knowledge-based approach for duplicate elimination in data cleaning,Wai Lup Low; Mong Li Lee; Tok Wang Ling,Abstract Existing duplicate elimination methods for data cleaning work on the basis ofcomputing the degree of similarity between nearby records in a sorted database. High recallcan be achieved by accepting records with low degrees of similarity as duplicates; at thecost of lower precision. High precision can be achieved analogously at the cost of lowerrecall. This is the recall–precision dilemma. We develop a generic knowledge-basedframework for effective data cleaning that can implement any existing data cleaningstrategies and more. We propose a new method for computing transitive closure underuncertainty for dealing with the merging of groups of inexact duplicate records and explainwhy small changes to window sizes has little effect on the results of the sorted neighborhoodmethod. Experimental study with two real-world datasets show that this approach can …,Information Systems,2001,129
The role of domain knowledge in the detection of retinal hard exudates,Wynne Hsu; PMDS Pallawala; Mong Li Lee; Kah-Guan Au Eong,Diabetic retinopathy is a major cause of blindness in the world. Regular screening andtimely intervention can halt or reverse the progression of this disease. Digital retinal imagingtechnologies have become an integral part of eye screening programs worldwide due totheir greater accuracy and repeatability in staging diabetic retinopathy. These screeningprograms produce an enormous number of retinal images since diabetic patients typicallyhave both their eyes examined at least once a year. Automated detection of retinal lesionscan reduce the workload and increase the efficiency of doctors and other eye-carepersonnel reading the retinal images and facilitate the follow-up management of diabeticpatients. Existing techniques to detect retinal lesions are neither adaptable nor sufficientlysensitive and specific for real-life screening application. In this paper; we demonstrate the …,Computer Vision and Pattern Recognition; 2001. CVPR 2001. Proceedings of the 2001 IEEE Computer Society Conference on,2001,118
Quantitative and qualitative retinal microvascular characteristics and blood pressure,Carol Y Cheung; Wan T Tay; Paul Mitchell; Jie J Wang; Wynne Hsu; Mong L Lee; Qiangfeng P Lau; Ai L Zhu; Ronald Klein; Seang M Saw; Tien Y Wong,Objective: The present study examined the effects of blood pressure on a spectrum ofquantitative and qualitative retinal microvascular signs. Methods: Retinal photographs fromthe Singapore Malay Eye Study; a population-based cross-sectional study of 3280 (78.7%response) persons aged 40–80 years; were analyzed. Quantitative changes in the retinalvasculature (branching angle; vascular tortuosity; fractal dimension; and vascular caliber)were measured using a semi-automated computer-based program. Qualitative signs;including focal arteriolar narrowing (FAN); arteriovenous nicking (AVN); opacification of thearteriolar wall (OAW); and retinopathy (eg; microaneurysms; retinal hemorrhages); wereassessed from photographs by trained technicians. After excluding persons with diabetesand ungradable photographs; 1913 persons provided data for this analysis. Results: In …,Journal of hypertension,2011,117
Mining relationships among interval-based events for classification,Dhaval Patel; Wynne Hsu; Mong Li Lee,Abstract Existing temporal pattern mining assumes that events do not have any duration.However; events in many real world applications have durations; and the relationshipsamong these events are often complex. These relationships are modeled using ahierarchical representation that extends Allen's interval algebra. However; thisrepresentation is lossy as the exact relationships among the events cannot be fullyrecovered. In this paper; we augment the hierarchical representation with additionalinformation to achieve a lossless representation. An efficient algorithm called IEMiner isdesigned to discover frequent temporal patterns from interval-based events. The algorithmemploys two optimization techniques to reduce the search space and remove non-promisingcandidates. From the discovered temporal patterns; we build an interval-based classifier …,Proceedings of the 2008 ACM SIGMOD international conference on Management of data,2008,117
The retinal vasculature as a fractal: methodology; reliability; and relationship to blood pressure,Gerald Liew; Jie Jin Wang; Ning Cheung; Yong Ping Zhang; Wynne Hsu; Mong Li Lee; Paul Mitchell; Gabriella Tikellis; Bronwen Taylor; Tien Yin Wong,Objective Fractals represent a type of derived geometric pattern that permits thecharacterization of the branching pattern of retinal vessels. We examined a newsemiautomated method to measure retinal vessel fractals. Design Methodology study.Participants Three hundred randomly selected participants from the population-based BlueMountains Eye Study. Methods We developed a semiautomated computer program tomeasure the fractal dimension (D f) of the retinal vessels from digitized images of disk-centered retinal photographs. Two trained graders masked to participant characteristicsmeasured D f of right eye images of participants. Reliability was determined by repeatgrading of the images from 60 participants; and association with systolic and diastolic bloodpressure was examined in all 300 participants. Main Outcome Measure D f of the retinal …,Ophthalmology,2008,113
BORDER: efficient computation of boundary points,Chenyi Xia; Wynne Hsu; Mong-Li Lee; Beng Chin Ooi,This work addresses the problem of finding boundary points in multidimensional data sets.Boundary points are data points that are located at the margin of densely distributed datasuch as a cluster. We describe a novel approach called BORDER (a BOundaRy pointsDEtectoR) to detect such points. BORDER employs the state-of-the-art database technique-the Gorder kNN join and makes use of the special property of the reverse k nearest neighbor(RkNN). Experimental studies on data sets with varying characteristics indicate thatBORDER is able to detect the boundary points effectively and efficiently.,IEEE Transactions on Knowledge and Data Engineering,2006,107
Retinal vascular tortuosity; blood pressure; and cardiovascular risk factors,Carol Yim-lui Cheung; Yingfeng Zheng; Wynne Hsu; Mong Li Lee; Qiangfeng Peter Lau; Paul Mitchell; Jie Jin Wang; Ronald Klein; Tien Yin Wong,Objective To examine the relationship of retinal vascular tortuosity to age; blood pressure;and other cardiovascular risk factors. Design Population-based; cross-sectional study.Participants A total of 3280 participants aged 40 to 80 years from the Singapore Malay EyeStudy (78.7% response rate). Methods Retinal arteriolar and venular (vascular) tortuositywere quantitatively measured from fundus images using a computer-assisted program.Retinal vascular tortuosity was defined as the integral of the curvature square along the pathof the vessel; normalized by the total path length. Data on blood pressure and majorcardiovascular disease (CVD) risk factors were collected from all participants. MeanOutcome Measures Retinal arteriolar and venular tortuosity. Results A total of 2915participants contributed data to this study. The mean (standard deviation) and median …,Ophthalmology,2011,106
Automatic grading of retinal vessel caliber,Huiqi Li; Wynne Hsu; Mong Li Lee; Tien Yin Wong,New clinical studies suggest that narrowing of the retinal blood vessels may be an earlyindicator of cardiovascular diseases. One measure to quantify the severity of retinalarteriolar narrowing is the arteriolar-to-venular diameter ratio (AVR). The manualcomputation of AVR is a tedious process involving repeated measurements of the diametersof all arterioles and venules in the retinal images by human graders. Consistency andreproducibility are concerns. To facilitate large-scale clinical use in the general population; itis essential to have a precise; efficient and automatic system to compute this AVR. Thispaper describes a new approach to obtain AVR. The starting points of vessels are detectedusing a matched Gaussian filter. The detected vessels are traced with the help of acombined Kalman filter and Gaussian filter. A modified Gaussian model that takes into …,IEEE Transactions on Biomedical Engineering,2005,105
Designing valid XML views,Ya Bing Chen; Tok Wang Ling; Mong Li Lee,Abstract Existing systems for XML views only support selection operation applied in theviews and cannot validate views. In this paper; we propose a systematic approach to designvalid XML views. First; we transform the semistructured XML source documents into asemantically rich O bject-R elationship-A ttribute model designed for SemLStructured data(ORA-SS). Second; we enrich the ORA-SS diagram with semantics such as participationconstraints of object classes and distinguishing between attributes of object classes andrelationship types; which cannot be expressed in the XML document. Third; we use theadditional semantics to develop a set of rules to guide the design of valid XML views. Weidentify four transformation operations for creating XML views; namely; selection; projection;join and swap operation. Finally; we develop a comprehensive algorithm that checks for …,International Conference on Conceptual Modeling,2002,101
Alterations in retinal microvascular geometry in young type 1 diabetes,Muhammad Bayu Sasongko; Jie Jin Wang; Kim C Donaghue; Ning Cheung; Paul Benitez-Aguirre; Alicia Jenkins; Wynne Hsu; Mong-Li Lee; Tien Y Wong,OBJECTIVE To describe retinal microvascular geometric parameters in young patients withtype 1 diabetes. RESEARCH DESIGN AND METHODS Patients with type 1 diabetes (aged12–20 years) had clinical assessments and retinal photography following standardizedprotocol at a tertiary-care hospital in Sydney. Retinal microvascular geometry; includingarteriolar and venular tortuosity; branching angles; optimality deviation; and length-to-diameter ratio (LDR); were measured from digitized photographs. Associations of thesegeometric characteristics with diabetes duration; A1C level; systolic blood pressure (SBP);and other risk factors were assessed. RESULTS Of 1;159 patients enrolled; 944 (81.4%) hadgradable photographs and 170 (14.7%) had retinopathy. Older age was associated withdecreased arteriolar (P= 0.024) and venular (P= 0.002) tortuosity; and female subjects …,Diabetes care,2010,100
NeMoFinder: Dissecting genome-wide protein-protein interactions with meso-scale network motifs,Jin Chen; Wynne Hsu; Mong Li Lee; See-Kiong Ng,Abstract Recent works in network analysis have revealed the existence of network motifs inbiological networks such as the protein-protein interaction (PPI) networks. However; existingmotif mining algorithms are not sufficiently scalable to find meso-scale network motifs. Also;there has been little or no work to systematically exploit the extracted network motifs fordissecting the vast interactomes. We describe an efficient network motif discovery algorithm;NeMoFinder; that can mine meso-scale network motifs that are repeated and unique in largePPI networks. Using NeMoFinder; we successfully discovered; for the first time; up to size-12network motifs in a large whole-genome S. cerevisiae (Yeast) PPI network. We also showthat such network motifs can be systematically exploited for indexing the reliability of PPIdata that were generated via highly erroneous high-throughput experimental methods.,Proceedings of the 12th ACM SIGKDD international conference on Knowledge discovery and data mining,2006,99
A piecewise Gaussian model for profiling and differentiating retinal vessels,Huiqi Li; Wynne Hsu; Mong-Li Lee; Hongyu Wang,Accurate measurement and identification of blood vessels could provide useful informationto clinical diagnosis. A piecewise Gaussian model is proposed to describe the intensitydistribution of vessel profile in this paper. The characteristic of central reflex is speciallyconsidered in the proposed model. The comparison with the single Gaussian model isperformed; which shows that the piecewise Gaussian model is a more appropriate model forvessel profile. The obtained model parameters could be utilized in the identification of vesseltype. The minimum Mahalanobis distance classifier is employed in the classification. 505segments of vessels were tested. The success rate is 82.46% and 89.03% for the arteriesand veins respectively.,Image Processing; 2003. ICIP 2003. Proceedings. 2003 International Conference on,2003,96
Increasing confidence of protein interactomes using network topological metrics,Jin Chen; Wynne Hsu; Mong Li Lee; See-Kiong Ng,Abstract Motivation: Experimental limitations in high-throughput protein–protein interactiondetection methods have resulted in low quality interaction datasets that contained sizablefractions of false positives and false negatives. Small-scale; focused experiments are thenneeded to complement the high-throughput methods to extract true protein interactions.However; the naturally vast interactomes would require much more scalable approaches.Results: We describe a novel method called IRAP* as a computational complement forrepurification of the highly erroneous experimentally derived protein interactomes. Ourmethod involves an iterative process of removing interactions that are confidently identifiedas false positives and adding interactions detected as false negatives into the interactomes.Identification of both false positives and false negatives are performed in IRAP* using …,Bioinformatics,2006,94
An information-driven framework for image mining,Ji Zhang; Wynne Hsu; Mong Li Lee,Abstract Image mining systems that can automatically extract semantically meaningfulinformation (knowledge) from image data are increasingly in demand. The fundamentalchallenge in image mining is to determine how lowlevel; pixel representation contained in araw image or image sequence can be processed to identify high-level spatial objects andrelationships. To meet this challenge; we propose an efficient information-driven frameworkfor image mining. We distinguish four levels of information: the Pixel Level; the Object Level;the Semantic Concept Level; and the Pattern and Knowledge Level. High-dimensionalindexing schemes and retrieval techniques are also included in the framework to support theflow of information among the levels. We believe this framework represents the first steptowards capturing the different levels of information present in image data and addressing …,Database and expert systems applications,2001,92
ORA-SS: An Object-Relationship-Attribute Model for Semi-Structured Data,Gillian Dobbie; Xiaoying Wu; Tok Wang Ling; Mong Li Lee,Semi-structured data is becoming increasingly important with the introduction of XML andrelated languages and technologies. The recent shift from DTDs (document type definitions)to XML-Schema for XML data highlights the importance of a schema definition for semi-structured data applications. At the same time; there is a move to extend semi-structureddata models to express richer semantics. In this paper we propose a semantically rich datamodel for semi-structured data; ORA-SS (Object-Relationship-Attribute model for Semi-Structured data). ORA-SS not only reflects the nested structure of semi-structured data; but italso distinguishes between objects; relationships and attributes. It is possible to specify thedegree of n-ary relationships and indicate if an attribute is an attribute of a relationship or anattribute of an object. Such information is lacking in existing semi-structured data models …,TR21/00; Department of Computer Science; National University of Singapore,2000,91
Efficient remote homology detection using local structure,Yuna Hou; Wynne Hsu; Mong Li Lee; Christopher Bystroff,Abstract Motivation: The function of an unknown biological sequence can often beaccurately inferred if we are able to map this unknown sequence to its correspondinghomologous family. At present; discriminative methods such as SVM-Fisher and SVM-pairwise; which combine support vector machine (SVM) and sequence similarity; arerecognized as the most accurate methods; with SVM-pairwise being the most accurate.However; these methods typically encode sequence information into their feature vectorsand ignore the structure information. They are also computationally inefficient. Based onthese observations; we present an alternative method for SVM-based protein classification.Our proposed method; SVM-I-sites; utilizes structure similarity for remote homologydetection. Result: We run experiments on the Structural Classification of Proteins 1.53 …,Bioinformatics,2003,89
Snnb: A selective neighborhood based naive Bayes for lazy learning,Zhipeng Xie; Wynne Hsu; Zongtian Liu; Mong Li Lee,Abstract Naïve Bayes is a probability-based classification method which is based on theassumption that attributes are conditionally mutually independent given the class label.Much research has been focused on improving the accuracy of Naïve Bayes via eagerlearning. In this paper; we propose a novel lazy learning algorithm; SelectiveNeighbourhood based Naïve Bayes (SNNB). SNNB computes different distanceneighborhoods of the input new object; lazily learns multiple Naïve Bayes classifiers; anduses the classifier with the highest estimated accuracy to make decision. The results of ourexperiments on 26 datasets show that our proposed SNNB algorithm is efficient and itoutperforms Naïve Bayes; and state-of-the-art classification methods NBTree; CBA; and C4.5 in terms of accuracy.,Pacific-Asia Conference on Knowledge Discovery and Data Mining,2002,89
XOO7: Applying OO7 Benchmark to XML Query Processing Tools,Stéphane Bressan; Gillian Dobbie; Zoé Lacroix; Mong Li Lee; Y Guang Li; Ullas Nambiar; Bimlesh Wadhwa,If XML is to play the critical role of the lingua franca for Internet data interchange that manypredict; it is necessary to start designing and adopting benchmarks allowing the comparativeperformance analysis of the tools being developed and proposed. The effectiveness ofexisting XML query languages has been studied by many who focused on the comparison oflinguistic features; implicitly reflecting the fact that most XML tools exist only on paper. In thispaper; with a focus on efficiency and concreteness; we propose a pragmatic first step towardthe systematic benchmarking of XML query processing platforms with an initial focus on thedata (versus document) point of view. We propose XOO7; an XML version of the OO7benchmark. We discuss the applicability of XOO7; its strengths; limitations and theextensions we are considering. We illustrate its use by presenting and discussing the …,Proceedings of the ACM International Conference on Information and Knowledge Management (CIKM),2001,89
ADRIS: an automatic diabetic retinal image screening system,Kheng Guan Goh; Wynne Hsu; M Li Lee; Huan Wang,*,STUDIES IN FUZZINESS AND SOFT COMPUTING,2001,88
Towards self-tuning data placement in parallel database systems,Mong Li Lee; Masaru Kitsuregawa; Beng Chin Ooi; Kian-Lee Tan; Anirban Mondal,Abstract Parallel database systems are increasingly being deployed to support theperformance demands of end-users. While declustering data across multiple nodesfacilitates parallelism; initial data placement may not be optimal due to skewed workloadsand changing access patterns. To prevent performance degradation; the placement of datamust be reorganized; and this must be done on-line to minimize disruption to the system. Inthis paper; we consider a dynamic self-tuning approach to reorganization in a sharednothing system. We introduce a new index-based method that faciliates fast and efficientmigration of data. Our solution incorporates a globally height-balanced structure and loadtracking at different levels of granularity. We conducted an extensive performance study; andimplemented the methods on the Fujitsu AP3000 machine. Both the simulation and …,ACM SIGMOD Record,2000,84
Mining frequent query patterns from XML queries,Liang Huai Yang; Mong Li Lee; H Wynne; Sumit Acharya,As XML prevails over the Internet; the efficient retrieval of XML data becomes important.Research to improve query response times has been largely concentrate on indexing XMLdocuments and processing regular path expressions. Another approach is to discoverfrequent query patterns since the answers to these queries can be stored and indexed.Mining frequent query patterns requires more than simple tree matching since the XMLqueries involves special characters such as"*" or"//". In addition; the matching process canbe expensive since the search space is exponential to the size of XML schema. In thispaper; we present two mining algorithms; XQPMiner and XQPMinerTID; to discover frequentquery pattern frees from a large collection of XML queries efficiently. Both algorithms exploitschema information to guide the enumeration of candidate subtrees; thus eliminating …,Database Systems for Advanced Applications; 2003.(DASFAA 2003). Proceedings. Eighth International Conference on,2003,69
Remote homolog detection using local sequence–structure correlations,Yuna Hou; Wynne Hsu; Mong Li Lee; Christopher Bystroff,Abstract Remote homology detection refers to the detection of structural homology inproteins when there is little or no sequence similarity. In this article; we present a remotehomolog detection method called SVM-HMMSTR that overcomes the reliance on detectablesequence similarity by transforming the sequences into strings of hidden Markov states thatrepresent local folding motif patterns. These state strings are transformed into fixed-dimension feature vectors for input to a support vector machine. Two sets of features aredefined: an order-independent feature set that captures the amino acid and local structurecomposition; and an order-dependent feature set that captures the sequential ordering of thelocal structures. Tests using the Structural Classification of Proteins (SCOP) 1.53 data setshow that the SVM-HMMSTR gives a significant improvement over several current …,PROTEINS: Structure; Function; and Bioinformatics,2004,66
Fractal analysis of retinal microvasculature and coronary heart disease mortality,Gerald Liew; Paul Mitchell; Elena Rochtchina; Tien Yin Wong; Wynne Hsu; Mong Li Lee; Alan Wainwright; Jie Jin Wang,Abstract Aim Fractal analysis provides a global assessment of vascular network architecture.We examined the relationship of retinal vascular fractal dimension (D f) with coronary heartdisease (CHD) mortality. Methods and results We examined the relationship of D f with 14-year CHD mortality in a prospective; population-based cohort of 3303 participants aged 49years or older. D f was measured from digitized fundus photographs using computer-automated methods; CHD mortality was documented from Australian National Death Indexrecords. Mean D f in this population was 1.441 (standard deviation; 0.024). Over 14 years;there were 468 (14.2%) CHD deaths. Participants with suboptimal D f (lowest and highestquartiles) had 50% higher 14-year CHD mortality than those with optimal D f (middlequartiles); after adjusting for age; blood pressure; and other risk factors. Among …,European heart journal,2011,60
The XOO7 benchmark,Stéphane Bressan; Mong Li Lee; Ying Guang Li; Zoé Lacroix; Ullas Nambiar,Abstract As XML becomes the standard for electronic data interchange; benchmarks areneeded to provide a comparative performance analysis of XML Management Systems(XMLMS). Typically a benchmark should adhere to four criteria: relevance; portability;scalability and simplicity [1]. The data structure of a benchmark for XML must be complexenough to capture the characteristics of XML data representation. Data sets should be invarious sizes. Benchmark queries should only be defined with the primitives of thelanguage.,*,2003,59
Resolving structural conflicts in the integration of XML schemas: A semantic approach,Xia Yang; Mong Li Lee; Tok Wang Ling,Abstract While the Internet has facilitated access to information sources; the task of scalableintegration of these heterogeneous data sources remains a challenge. The adoption of theeXtensible Markup Language (XML) as the standard for data representation and exchangehas led to an increasing number of XML data sources; both native and non-native. Recentintegration work has mainly focused on developing matching techniques to find equivalentelements and attributes among the different XML sources. In this paper; we introduce asemantic approach to resolve structural conflicts in the integration of XML schemas. Weemploy a data model called the ORA-SS (Object-Relationship-Attribute Model for Semi-Structured Data) to capture the implicit semantics in an XML schema. We present acomprehensive algorithm to integrate XML schemas. Compared to existing methods; our …,International Conference on Conceptual Modeling,2003,58
Exploration mining in diabetic patients databases: findings and conclusions,Wynne Hsu; Mong Li Lee; Bing Liu; Tok Wang Ling,ABSTRACT Real-life data mining applications are interesting because they often present adifferent set of problems for data miners. One such real-life application that we have done ison the diabetic patients databases. Valuable lessons are learnt from this application. Inparticular; we discover that the often neglected pre-processing and post-processing steps inknowledge discovery are the most critical elements in determining the success of a real-lifedata mining application. In this paper; we shall discuss how we carry out knowledgediscovery on this diabetic patient database; the interesting issues that have surfaced; as wellas the lessons we have learnt from this application. We will describe a semi-automaticmeans for cleaning the diabetic patient database; and present a step-by-step approach tohelp the health doctors explore their data and to understand the discovered rules better.,Proceedings of the sixth ACM SIGKDD international conference on Knowledge discovery and data mining,2000,57
Cleaning the spurious links in data,Mong Li Lee; Wynne Hsu; Vijay Kothari,Data quality problems can arise from abbreviations; data entry mistakes; duplicate records;missing fields; and many other sources. These problems proliferate when you integratemultiple data sources in data warehousing; federated databases; and global informationsystems. A newly discovered class of erroneous data is spurious links; where a real-worldentity has multiple links that might not be properly associated with it. The existence of suchspurious links often leads to confusion and misrepresentation in the data recordsrepresenting the entity. Although the data set is well known for its high-quality bibliographicinformation; collecting and maintaining the data from diverse sources requires enormouseffort. Errors; including spurious links; are inevitable. To solve this problem; we use contextinformation to identify spurious links. First; we identify data records that contain potential …,IEEE Intelligent Systems,2004,54
Designing semistructured databases using ORA-SS model,Xiaoying Wu; Tok Wang Ling; Mong Li Lee; Gillian Dobbie,Semistructured data has become prevalent with the growth of the Internet. The developmentof new web applications that require efficient design and maintenance of large amounts ofdata makes it increasingly important to design" good" semistructured databases to preventdata redundancy and updating anomalies. However; it is not easy; even impossible; forcurrent semistructured data models to capture the semantics traditionally needed fordesigning databases. In this paper; we show how an object-relationship-attribute model forsemistructured data (ORA-SS) can facilitate the design of" good" semistructured databases.This is accomplished via the normalization of ORA-SS. An XML DTD or Schema generatedfrom a normal form ORA-SS schema diagram has no undesirable redundancy; and thus noupdating anomalies for the complying semistructured databases. The general design …,Web Information Systems Engineering; 2001. Proceedings of the Second International Conference on,2001,54
Semistructured database design,Tok Wang Ling; Gillian Dobbie,Semistructured Database Design provides an essential reference for anyone interested inthe effective management of semsistructured data. Since many new and advanced webapplications consume a huge amount of such data; there is a growing need to properlydesign efficient databases. This volume responds to that need by describing a semanticallyrich data model for semistructured data; called Object-Relationship-Attribute model forSemistructured data (ORA-SS). Focusing on this new model; the book discuss problems andpresent solutions for a number of topics; including schema extraction; the design of non-redundant storage organizations for semistructured data; and physical semsitructureddatabase design; among others. Semistructured Database Design; presents researchersand professionals with the most complete and up-to-date research in this fast-growing …,*,2004,53
Mining dense periodic patterns in time series data,Chang Sheng; Wynne Hsu; Mong Li Lee,Existing techniques to mine periodic patterns in time series data are focused on discoveringfull-cycle periodic patterns from an entire time series. However; many useful partial periodicpatterns are hidden in long and complex time series data. In this paper; we aim to discoverthe partial periodicity in local segments of the time series data. We introduce the notion ofcharacter density to partition the time series into variable-length fragments and to determinethe lower bound of each character's period. We propose a novel algorithm; called DPMiner;to find the dense periodic patterns in time series data. Experimental results on both syntheticand real-life datasets demonstrate that the proposed algorithm is effective and efficient toreveal interesting dense periodic patterns.,22nd International Conference on Data Engineering (ICDE'06),2006,51
On the accurate counting of tumor cells,Bin Fang; Wynne Hsu; Mong Li Lee,Quantitative analysis of tumor cells is fundamental to pathological studies. Current practicesare mostly manual; time-consuming; and tedious; yielding subjective and imprecise results.To understand the behavior of tumor cells; it is critical to have an objective way to countthese cells. In addition; these counts must be reproducible and independent of the personperforming the count. In this work; we propose a two-stage tumor cell identification strategy.In the first stage; potential tumor cells are segmented automatically using local adaptivethresholding and dynamic water immersion techniques. Unfortunately; due to histologicalnoise in the images; a large number of false identifications are obtained. To improve theaccuracy of the identified tumor cells; a second stage of feature rules mining is initiated.Experiment results show that image processing techniques alone are unable to give …,IEEE Transactions on nanobioscience,2003,51
Making recommendations from multiple domains,Wei Chen; Wynne Hsu; Mong Li Lee,Abstract Given the vast amount of information on the World Wide Web; recommendersystems are increasingly being used to help filter irrelevant data and suggest informationthat would interest users. Traditional systems make recommendations based on a singledomain eg; movie or book domain. Recent work has examined the correlations in differentdomains and designed models that exploit user preferences on a source domain to predictuser preferences on a target domain. However; these methods are based on matrixfactorization and can only be applied to two-dimensional data. Transferring highdimensional data from one domain to another requires decomposing the high dimensionaldata to binary relations which results in information loss. Furthermore; this decompositioncreates a large number of matrices that need to be transferred and combining them in the …,Proceedings of the 19th ACM SIGKDD international conference on Knowledge discovery and data mining,2013,49
Temporal and spatio-temporal data mining,Wynne Hsu,The recent surge of interest in spatio-temporal databases has resulted in numerousadvances; such as: modeling; indexing; and querying of moving objects and spatio-temporaldata. Aside from this; rule mining in spatial databases and temporal databases has beenstudied extensively in data mining research. Temporal and Spatio-Temporal Data Mining:Association Patterns and Applications examines the problem of mining topological patternsin spatio-temporal databases by imposing the temporal constraints into the process ofmining spatial collocation patterns. Temporal and Spatio-Temporal Data Mining: AssociationPatterns and Applications presents probable solutions when discovering the spatialsequence patterns by incorporating the spatial information into the sequence of patterns;and introduces two new classes of spatial sequence patterns: flow patterns and …,*,2007,48
Reconstruction of vascular structures in retinal images,Bin Fang; Wynne Hsu; Mong Li Lee,Vessels in retinal fundus images are useful in revealing the severity of eye-related diseases.In addition; they can act as landmarks for localizing lesions and the central vision area; andguide laser treatment of neovascularization. In this paper; we propose a two-stage method toidentify and extract vascular structure. First; the vessels are enhanced by mathematicalmorphology with respect to their spatial properties. These vessels are differentiated frombackground patterns through the use of curvature evaluation and linear filtering. However;this may result in missing out some important features of bifurcation and intersection points.To overcome this; a reconstruction process is performed using dynamic local region growingto recover the complete vascular structure. Experiment results indicate that the proposedmethod is able to detect the vascular structure in 97% of 35 retinal images with …,Image Processing; 2003. ICIP 2003. Proceedings. 2003 International Conference on,2003,48
Current approaches to XML management,Ullas Nambiar; Zoé Lacroix; Stéphane Bressan; Mong Li Lee; Yingguang Li,The Extensible Markup Language has become the standard for information interchange onthe Web. We study the data-and document-centric uses of XML management systems(XMLMS). We want to provide XML data users with a guideline for choosing the datamanagement system that best meets their needs. Because the systems we test are first-generation approaches; we suggest a hypothetical design for a useful XML database thatcould use all the expressive power of XML and XML query languages.,IEEE Internet Computing,2002,48
An evaluation of XML indexes for structural join,Hanyu Li; Mong Li Lee; Wynne Hsu; Chao Chen,Abstract XML queries differ from relational queries in that the former are expressed as pathexpressions. The efficient handling of structural relationships has become a key factor inXML query processing. Many index-based solutions have been proposed for efficientstructural join in XML queries. This work explores the state-of-the-art indexes; namely;< i>B</i>< sup>+</sup>-tree; XB-tree and XR-tree; and analyzes how well they support XMLstructural joins. Experiment results indicate that all three indexes yield comparableperformances for non-recursive XML data; while the XB-tree outperforms the rest for highlyrecursive XML data.,ACM SIGMOD Record,2004,45
Automated optic disc localization and contour detection using ellipse fitting and wavelet transform,PMDS Pallawala; Wynne Hsu; Mong Lee; Kah-Guan Eong,Abstract Optic disc detection is important in the computer-aided analysis of retinal images. Itis crucial for the precise identification of the macula to enable successful grading of macularpathology such as diabetic maculopathy. However; the extreme variation of intensityfeatures within the optic disc and intensity variations close to the optic disc boundarypresents a major obstacle in automated optic disc detection. The presence of blood vessels;crescents and peripapillary chorioretinal atrophy seen in myopic patients also increase thecomplexity of detection. Existing techniques have not addressed these difficult cases; andare neither adaptable nor sufficiently sensitive and specific for real-life application. This workpresents a novel algorithm to detect the optic disc based on wavelet processing and ellipsefitting. We first employ Daubechies wavelet transform to approximate the optic disc region …,Computer Vision-ECCV 2004,2004,45
Simultaneously Identifying All True Vessels from Segmented Retinal Images,Qiangfeng Peter Lau; Mong Li Lee; Wynne Hsu; Tien Yin Wong,Measurements of retinal blood vessel morphology have been shown to be related to the riskof cardiovascular diseases. The wrong identification of vessels may result in a largevariation of these measurements; leading to a wrong clinical diagnosis. In this paper; weaddress the problem of automatically identifying true vessels as a postprocessing step tovascular structure segmentation. We model the segmented vascular structure as a vesselsegment graph and formulate the problem of identifying vessels as one of finding the optimalforest in the graph given a set of constraints. We design a method to solve this optimizationproblem and evaluate it on a large real-world dataset of 2446 retinal images. Experimentresults are analyzed with respect to actual measurements of vessel morphology. The resultsshow that the proposed approach is able to achieve 98.9% pixel precision and 98.7 …,*,2013,44
Discovering reliable protein interactions from high-throughput experimental data using network topology,Jin Chen; Wynne Hsu; Mong Li Lee; See-Kiong Ng,Summary Objective: Current protein–protein interaction (PPI) detection via high-throughputexperimental methods; such as yeast-two-hybrid has been reported to be highly erroneous;leading to potentially costly spurious discoveries. This work introduces a novel measurecalled IRAP; ie “interaction reliability by alternative path”; for assessing the reliability ofprotein interactions based on the underlying topology of the PPI network. Methods andmaterials: A candidate PPI is considered to be reliable if it is involved in a closed loop inwhich the alternative path of interactions between the two interacting proteins is strong. Wedevise an algorithm called AlternativePathFinder to compute the IRAP value for eachinteraction in a complex PPI network. Validation of the IRAP as a measure for assessing thereliability of PPIs is performed with extensive experiments on yeast PPI data. All the data …,Artificial Intelligence in Medicine,2005,44
Maxfirst for maxbrknn,Zenan Zhou; Wei Wu; Xiaohui Li; Mong Li Lee; Wynne Hsu,The MaxBRNN problem finds a region such that setting up a new service site within thisregion would guarantee the maximum number of customers by proximity. This problemassumes that each customer only uses the service provided by his/her nearest service site.However; in reality; a customer tends to go to his/her k nearest service sites. To handle this;MaxBRNN can be extended to the MaxBRkNN problem which finds an optimal region suchthat setting up a service site in this region guarantees the maximum number of customerswho would consider the site as one of their k nearest service locations. We furthergeneralize the MaxBRkNN problem to reflect the real world scenario where customers mayhave different preferences for different service sites; and at the same time; service sites mayhave preferred targeted customers. In this paper; we present an efficient solution called …,2011 IEEE 27th International Conference on Data Engineering,2011,43
A framework for mining topological patterns in spatio-temporal databases,Junmei Wang; Wynne Hsu; Mong Li Lee,Abstract Mining topological patterns in spatial databases has received a lot of attention.However; existing work typically ignores the temporal aspect and suffers from certainefficiency problems. They are not scalable for mining topological patterns in spatio-temporaldatabases. In this paper; we study the problem for mining topological patterns byincorporating the temporal aspect in the mining process. We introduce a summary-structurethat records the instances' count information of a feature in a region within a time window.Using this structure; we design an algorithm; TopologyMiner; to find interesting topologicalpatterns without the need to generate candidates. Experimental results show thatTopologyMiner is effective and scalable in finding topological patterns and outperformsApriori-like algorithm by a few orders of magnitudes.,Proceedings of the 14th ACM international conference on Information and knowledge management,2005,43
Image mining in IRIS: integrated retinal information system,Wynne Hsu; Mong Li Lee; Kheng Guan Goh,Abstract There is an increasing demand for systems that can automatically analyze imagesand extract semantically meaningful information. IRIS; an Integrated Retinal Informationsystem; has been developed to provide medical professionals easy and unified access tothe screening; trend and progression of diabetic-related eye diseases in a diabetic patientdatabase. This paper shows how mining techniques can be used to accurately extractfeatures in the retinal images. In particular; we apply a classification approach to determinethe conditions for tortuousity in retinal blood vessels.,ACM SIGMOD Record,2000,43
XOO7: applying OO7 benchmark to XML query processing tool,Ying Guang Li; Stéphane Bressan; Gillian Dobbie; Zoé Lacroix; Mong Li Lee; Ullas Nambiar; Bimlesh Wadhwa,Abstract If XML is to play the critical role of the lingua franca for Internet data interchange thatmany predict; it is necessary to start designing and adopting benchmarks allowing thecomparative performance analysis of the tools being developed and proposed. Theeffectiveness of existing XML query languages has been studied by many; with a focus onthe comparison of linguistic features; implicitly reflecting the fact that most XML tools existonly on paper. In this paper; with a focus on efficiency and concreteness; we propose apragmatic first step toward the systematic benchmarking of XML query processing platformswith an initial focus on the data (versus document) point of view. We propose XOO7; an XMLversion of the OO7 benchmark. We discuss the applicability of XOO7; its strengths;limitations and the extensions we are considering. We illustrate its use by presenting and …,Proceedings of the tenth international conference on Information and knowledge management,2001,42
OrientStore: a schema based native XML storage system,Xiaofeng Meng; Daofeng Luo; Mong Li Lee; Jing An,This chapter discusses a schema based native XML storage system. The increasing numberof XML repositories has provided the impetus to design and develop systems that can storeand query XML data efficiently. Research to improve system performance has been largelyconcentrated on indexing paths and optimizing XML queries. The storage configuration ofXML data on disk also has an impact on the efficiency of an XML data management system.Existing XML storage strategies can be classified into two categories: native XML storageand non-native XML storage. The main distinction between them is their data model. Theformer is based on the XML Data Models such as document object model (DOM); and objectexchange model (OEM); while the latter is based on the traditional relational data model; orobject-oriented data model. An evaluation of the alternative non-native storage strategies …,Proceedings of the 29th international conference on Very large data bases-Volume 29,2003,41
Increasing temporal diversity with purchase intervals,Gang Zhao; Mong Li Lee; Wynne Hsu; Wei Chen,Abstract The development of Web 2.0 technology has led to huge economic benefits andchallenges for both e-commerce websites and online shoppers. One core technology toincrease sales and consumers' satisfaction is the use of recommender systems. Existingproduct recommender systems consider the order of items purchased by users to obtain alist of recommended items. However; they do not consider the time interval between theproducts purchased. For example; there is often an interval of 2-3 months between thepurchase of printer ink cartridges or refills. Thus; recommending appropriate ink cartridgesone week before the user needs to replace the depleted ink cartridges would increase thelikelihood of a purchase decision. In this paper; we propose to utilize the purchase intervalinformation to improve the performance of the recommender systems for e-commerce. We …,Proceedings of the 35th international ACM SIGIR conference on Research and development in information retrieval,2012,40
Labeling network motifs in protein interactomes for protein function prediction,Jin Chen; Wynne Hsu; Mong Li Lee; See-Kiong Ng,Biological networks such as the protein-protein interaction (PPI) network have been found tocontain small recurring subnetworks in significantly higher frequencies than in randomnetworks. Such network motifs are useful for uncovering structural design principles ofcomplex biological networks. However; current network motif finding algorithms models thePPI network as a uni-labeled graph; discovering only unlabeled and thus relativelyuninforma-tive network motifs as a result. Our objective is to exploit the currently availablebiological information that are associated with the vertices (the proteins) to capture not onlythe topological shapes of the motifs; but also the biological context in which they occurred inthe PPI networks for network motif applications. We present a method called LaMoFinder tolabel network motifs with gene ontology terms in a PPI network. We also show how the …,Data Engineering; 2007. ICDE 2007. IEEE 23rd International Conference on,2007,40
Duplicate detection in biological data using association rule mining,Judice LY Koh; Mong Li Lee; Asif M Khan; Paul TJ Tan; Vladimir Brusic,ABSTRACT Recent advancement in biotechnology has produced a massive amount of rawbiological data which are accumulating at an exponential rate. Errors; redundancy anddiscrepancies are prevalent in the raw data; and there is a serious need for systematicapproaches towards biological data cleaning. This work examines the extent of redundancyin biological data and proposes a method for detecting duplicates in biological data.Duplicate relations in a real-world biological dataset are modeled into forms of associationrules so that these duplicate relations or rules can be induced from data with knownduplicates using association rule mining. Our approach of using association rule induction tofind duplicate relations is new. Evaluation of our method on a real-world dataset shows thatour duplicate association rules can accurately identify up to 96.8% of the duplicates in the …,Locus,2004,36
Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics): Preface,ML Lee; JX Yu; Z Bellahsène; R Unland,*,*,2010,35
Detection of retinal blood vessels based on nonlinear projections,Yongping Zhang; Wynne Hsu; Mong Li Lee,Abstract An automated method for blood vessel segmentation is presented in this paper. Theapproach uses the nonlinear orthogonal projection to capture the features of vesselnetworks; and derives a novel local adaptive thresholding algorithm for vessel detection. Byembedding in a kind of image decomposition model; the selection of system parameterwhich reflects the size of concerned convex set is examined. This approach differs frompreviously known methods in that it uses matched filtering; vessel tracking or supervisedmethods. The algorithm was tested on two publicly available databases: the DRIVE and theSTARE. By comparison with hand-labeled ground truth; an average accuracy of 96.1% isachieved on the former database; and an average accuracy of 90.8% is achieved on thelater database.,Journal of Signal Processing Systems,2009,34
Resolving constraint conflicts in the integration of entity-relationship schemas,Mong LEE; Tok Ling,Abstract In this work; we address the problem of constraint conflicts while integrating theconceptual schemas of multiple autonomous databases modeled using the EntityRelationship (ER) approach. This paper presents a detailed framework to resolve threetypes of constraint conflicts; domain constraint conflicts; attribute constraint conflicts andrelationship constraint conflicts. There are two types of domain constraint conflict; convertibleand inconvertible. We distinguish two types of convertible domain constraints conflict;reversible and irreversible; and present an algorithm to resolve domain constraint conflicts.We identify six factors that can contribute to conflict in attribute constraints: impreciseconstraint design; domain mismatch; incomplete information; imprecise semantics; valueinconsistency and set relation between object types. In relationship constraint conflict …,Conceptual Modeling—ER'97,1997,34
NF-SS: A normal form for semistructured schema,Xiaoying Wu; Tok Wang Ling; Lee Sin Yeung; Mong Li Lee; Gillian Dobbie,Abstract Semistructured data is becoming increasingly important for web applications withthe development of XML and related technologies. Designing a “good” semistructureddatabase is crucial to prevent data redundancy; inconsistency and undesirable updatinganomalies. However; unlike relational databases; there is no normalization theory tofacilitate the design of good semistructured databases. In this paper; we introduce the notionof a semistructured schema and identify the various anomalies that may occur in such aschema. A Normal Form for Semistructured Schemata; NF-SS; is proposed. A semistructuredschema in NF-SS guarantees minimal redundancy and hence no undesirable updatinganomalies for the associated semistructured databases. Furthermore; a semistructuredschema in NF-SS gives a more reasonable representation of real world semantics. We …,*,2002,33
Community-based user recommendation in uni-directional social networks,Gang Zhao; Mong Li Lee; Wynne Hsu; Wei Chen; Haoji Hu,Abstract Advances in Web 2.0 technology has led to the rising popularity of many socialnetwork services. For example; there are over 500 million active users in Twitter. Given thehuge number of users; user recommendation has gained importance where the goal is tofind a set of users whom a target user is likely to follow. Content-based approaches that relyon tweet content for user recommendation have low precision as tweet contents are typicallyshort and noisy; while collaborative filtering approaches that utilize follower-followeerelationships lead to higher precision but data sparsity remains a challenge. In this work; wepropose a community-based approach to user recommendation in Twitter-style socialnetworks. Forming communities enables us to reduce data sparsity as the focus is ondiscover the latent characteristics of communities instead of individuals. We employ an …,Proceedings of the 22nd ACM international conference on Conference on information & knowledge management,2013,32
XML structures for relational data,Wenyue Du; Mong Li Lee; Tok Wang Ling,XML is increasingly being adopted for information publishing on the World Wide Web.However; the underlying data is often stored in the relational databases. Some mechanismis needed to convert the relational data into XML data. In this work we employ a semanticallyrich semistructured data model; the object-relationship-attribute model for semistructureddata; as a middleware to support the schema conversion from semantically enrichedrelational schema to XML schema. This approach allows us to handle the translation of a setof related relations and to distinguish attributes of relationship types from attributes of objectclasses; multivalued attributes; and different types of relationships such as binary; n-ary;recursive and ISA. The resulting XML structures are able to reflect the inherent semanticsand implicit structure in the underlying relational database. We also show that the …,Web Information Systems Engineering; 2001. Proceedings of the Second International Conference on,2001,31
Clustering in dynamic spatial databases,Ji Zhang; Wynne Hsu; Mong Li Lee,Abstract Efficient clustering in dynamic spatial databases is currently an open problem withmany potential applications. Most traditional spatial clustering algorithms are inadequatebecause they do not have an efficient support for incremental clustering. In this paper; wepropose DClust; a novel clustering technique for dynamic spatial databases. DClust is ableto provide multi-resolution view of the clusters; generate arbitrary shapes clusters in thepresence of noise; generate clusters that are insensitive to ordering of input data andsupport incremental clustering efficiently. DClust utilizes the density criterion that capturesarbitrary cluster shapes and sizes to select a number of representative points; and builds theMinimum Spanning Tree (MST) of these representative points; called R-MST. After the initialclustering; a summary of the cluster structure is built. This summary enables quick …,Journal of intelligent information systems,2005,30
Finding hot query patterns over an XQuery stream,Huai Yang; Li Lee; Wynne Hsu,Abstract. Caching query results is one efficient approach to improving the performance ofXML management systems. This entails the discovery of frequent XML queries issued byusers. In this paper; we model user queries as a stream of XML query pattern trees and minethe frequent query patterns over the query stream. To facilitate the one-pass mining process;we devise a novel data structure called DTS to summarize the pattern trees seen so far. Bygrouping the incoming pattern trees into batches; we can dynamically mark the activeportion of the current batch in DTS and limit the enumeration of candidate trees to only thecurrently active pattern trees. We also design another summary data structure called ECTreethat provides for the incremental computation of the frequent tree patterns over the querystream. Based on the above two constructs; we present two mining algorithms called …,The VLDB Journal—The International Journal on Very Large Data Bases,2004,30
Mining viewpoint patterns in image databases,Wynne Hsu; Jing Dai; Mong Li Lee,Abstract The increasing number of image repositories has made image mining an importanttask because of its potential in discovering useful image patterns from a large set of images.In this paper; we introduce the notion of viewpoint patterns for image databases. Viewpointpatterns refer to patterns that capture the invariant relationships of one object from the pointof view of another object. These patterns are unique and significant in images because theabsolute positional information of objects for most images is not important; but rather; it is therelative distance and orientation of the objects from each other that is meaningful. We designa scalable and efficient algorithm to discover such viewpoint patterns. Experiments resultson various image sets demonstrate that viewpoint patterns are meaningful and interesting tohuman users.,Proceedings of the ninth ACM SIGKDD international conference on Knowledge discovery and data mining,2003,30
A methodology for structural conflict resolution in the integration of entity-relationship schemas,MongLi Lee; TokWang Ling,Abstract. The integration ofinf ormation systems is becoming increasingly important. Acommon requirement in distributed data-intensive applications; such as data warehousingand data mining; is that the various databases involved be joined in a process calledschema integration. The entity-relationship (ER) model or a variant of the ER model is oftenused as the common data model. To aid the schema conforming; merging and restructuringphases of the integration process; various transformations have been defined to mapbetween various equivalent ER representations. In this paper; we describe a differentapproach to integrate ER schemas. We focus on the resolution of structural conflicts; that is;when related real-world concepts are modeled using different constructs in differentschemas. Unlike previous work; our approach proposes to resolve the structural conflict …,Knowledge and Information Systems,2003,30
Retinal vascular fractal dimension and its relationship with cardiovascular and ocular risk factors,Carol Y Cheung; George N Thomas; Wanting Tay; M Kamran Ikram; Wynne Hsu; Mong Li Lee; Qiangfeng Peter Lau; Tien Yin Wong,Purpose To examine the influence of a range of cardiovascular risk factors and ocularconditions on retinal vascular fractal dimension in the Singapore Malay Eye Study. DesignPopulation-based cross-sectional study. Methods Fractal analysis of the retinal vessels is amethod to quantify the global geometric complexity of the retinal vasculature. Retinalvascular fractal dimension (D f) and caliber were measured from retinal photographs using acomputer-assisted program. D f and arteriolar caliber were combined to form a retinalvascular optimality score (ranging from 0 to 3). Data on cardiovascular and ocular factorswere collected from all participants based on a standardized protocol. Results Two thousandnine hundred thirteen (88.8% of 3280 participants) persons had retinal photographs ofsufficient quality for the measurement. The mean D f was 1.405 (standard deviation; 0.046 …,American journal of ophthalmology,2012,29
Efficient XML data management: an analysis,Ullas Nambiar; Zoé Lacroix; Stéphane Bressan; Mong Li Lee; Ying Guang Li,Abstract With XML rapidly gaining popularity as the standard for data exchange on the WorldWide Web; a variety of XML management systems (XMLMS) are becoming available. Thechoice of an XMLMS is made difficult by the significant difference in the expressive power ofthe queries and the performance shown by these XMLMS. Most XMLMS are legacy systems(mostly relational) extended to load; query; and publish data in XML format. A few are nativeXMLMS and capture all the characteristics of XML data representation. This paper looks atexpressive power and efficiency of various XMLMS. The performance analysis relies on thetestbed provided by XOO7; a benchmark derived from OO7 to capture both data anddocument characteristics of XML. We present efficiency results for two native XMLMS; anXML-enabled semi-structured data management system and an XML-enabled RDBMS …,*,2002,29
Resolving structural conflicts in the integration of entity-relationship schemas,Mong Li Lee; Tok Wang Ling,Abstract Schema integration is essential to define a global schema that describes all thedata in existing databases participating in a distributed or federated database managementsystem. This paper describes a different approach to integrate two Entity-Relationship (ER)schemas. We focus on the resolution of structural conflicts; that is; when related real worldconcepts are modelled using different constructs in different schemas. Unlike previousworks; our approach only needs to resolve the structural conflict between an entity type inone schema and an attribute in another schema and the other structural conflicts areautomatically resolved. We have an algorithm to transform an attribute in one schema intoan equivalent entity type in another schema without any loss of semantics or functionaldependencies which previous approaches have not considered.,*,1995,29
Designing good semi-structured databases,Sin Yeung Lee; Mong Li Lee; Tok Wang Ling; Leonid A Kalinichenko,Abstract Semi-structured data has become prevalent with the growth of the Internet andother on-line information repositories. Many organizational databases are presented on theweb as semi-structured data. Designing a “good” semi-structured database is increasinglycrucial to prevent data redundancy; inconsistency and updating anomalies. In this paper; wedefine a semi-structured schema graph and identify the various anomalies that may occur inthe graph. A normal form for semi-structured schema graph; S3-NF; is proposed. We presenttwo approaches to design S3-NF database; namely; restructuring by decomposition and theER approach. The first approach consists of a set of rules to decompose a semi-structuredschema graph into S3-NF. The second approach uses the ER model to remove anomalies atthe semantic level.,*,1999,28
Modeling user's receptiveness over time for recommendation,Wei Chen; Wynne Hsu; Mong Li Lee,Abstract Existing recommender systems model user interests and the social influencesindependently. In reality; user interests may change over time; and as the interests change;new friends may be added while old friends grow apart and the new friendships formed maycause further interests change. This complex interaction requires the joint modeling of userinterest and social relationships over time. In this paper; we propose a probabilisticgenerative model; called Receptiveness over Time Model (RTM); to capture this interaction.We design a Gibbs sampling algorithm to learn the receptiveness and interest distributionsamong users over time. The results of experiments on a real world dataset demonstrate thatRTM-based recommendation outperforms the state-of-the-art recommendation methods.Case studies also show that RTM is able to discover the user interest shift and …,Proceedings of the 36th international ACM SIGIR conference on Research and development in information retrieval,2013,27
Increasing confidence of protein-protein interactomes,Jin Chen; Hon Nian Chua; Wynne Hsu; Mong-Li Lee; See-Kiong Ng; Rintaro Saito; Wing-Kin Sung; Limsoon Wong,抄録 High-throughput experimental methods; such as yeast-two-hybrid and phage display;have fairly high levels of false positives (and false negatives). Thus the list of protein-proteininteractions detected by such experiments would need additional wet laboratory validation. Itwould be useful if the list could be prioritized in some way. Advances in computationaltechniques for assessing the reliability of protein-protein interactions detected by such high-throughput methods are reviewed in this paper; with a focus on techniques that rely only ontopological information of the protein interaction network derived from such high-throughputexperiments. In particular; we discuss indices that are abstract mathematicalcharacterizations of networks of reliable protein-protein interactions-eg;“interactiongenerality”(IG);“interaction reliability by alternatve pathways”(IRAP); and “functional …,GENOME INFORMATICS SERIES,2006,27
Topological methods on the theory of covering generalized rough sets,J Li,*,Pattern recognition and artificial intelligence,2004,27
Correlation-based detection of attribute outliers,Judice LY Koh; Mong Li Lee; Wynne Hsu; Kai Tak Lam,Abstract An outlier is an object that does not conform to the normal behavior of the data set.In data cleaning; outliers are identified for data noise reduction. In applications such as frauddetection; and stock market analysis; outliers suggest abnormal behavior requiring furtherinvestigation. Existing outlier detection methods have focused on class outliers and researchon attribute outliers is limited; despite the equal role attribute outliers play in depreciatingdata quality and reducing data mining accuracy. In this paper; we propose a novel method todetect attribute outliers from the deviating correlation behavior of attributes. We formulatethree metrics to evaluate outlier-ness of attributes; and introduce an adaptive factor todistinguish outliers from non-outliers. Experiments with both synthetic and real-world datasets indicate that the proposed method is effective in detecting attribute outliers.,*,2007,26
An estimation system for XPath expressions,Hanyu Li; Mong Li Lee; Wynne Hsu; Gao Cong,Estimating the result sizes of XML queries is important in query optimization and is useful inproviding a quick feedback about the queries. Existing works have focused on the selectivityestimation of XML queries without order-based axes. In this work; we develop a frameworkto estimate the result sizes of XPath expressions with order-based axes. We describe howthe path and order information of XML elements can be captured and summarized incompact data structures. We also describe methods to estimate the selectivity of XPathqueries. The results of extensive experiments on both synthetic and real-world datasetsdemonstrate the effectiveness and accuracy of the proposed approach.,Data Engineering; 2006. ICDE'06. Proceedings of the 22nd International Conference on,2006,26
Erknn: efficient reverse k-nearest neighbors retrieval with local knn-distance estimation,Chenyi Xia; Wynne Hsu; Mong Li Lee,Abstract The Reverse k-Nearest Neighbors (RkNN) queries are important in profile-basedmarketing; information retrieval; decision support and data mining systems. However; theyare very expensive and existing algorithms are not scalable to queries in high dimensionalspaces or of large values of k. This paper describes an efficient estimation-based RkNNsearch algorithm (ERkNN) which answers RkNN queries based on local kNN-distanceestimation methods. The proposed approach utilizes estimation-based filtering strategy tolower the computation cost of RkNN queries. The results of extensive experiments on bothsynthetic and real life datasets demonstrate that ERkNN algorithm retrieves RkNN efficientlyand is scalable with respect to data dimensionality; k; and data size.,Proceedings of the 14th ACM international conference on Information and knowledge management,2005,26
Flowminer: Finding flow patterns in spatio-temporal databases,Junmei Wang; Wynne Hsu; Mong-Li Lee,The widespread use of spatio-temporal databases and applications has fuelled an urgentneed to discover interesting time and space patterns in such databases. While much workhas been done in discovering time/sequence patterns or spatial patterns; discovering ofpatterns involving both time and space dimensions is still in its infancy; We introduce theconcept of flow patterns. Flow patterns are intended to describe the change of events overspace and time. These flow patterns are useful to the understanding of many real-lifeapplications. We present a disk-based algorithm; FlowMiner; which utilizes temporalrelationships and spatial relationships amid events to generate flow patterns. Ourperformance study shows that FlowMiner is both scalable and efficient. Experiments on real-life datasets also reveal interesting flow patterns.,Tools with Artificial Intelligence; 2004. ICTAI 2004. 16th IEEE International Conference on,2004,26
Access control of XML documents in relational database systems,Kian-Lee Tan; Mong Li Lee; Yue Wang,Abstract In this paper; we present the design and implementation of an access controlsystem for XML documents. Our system stores XML documents as relational tables in arelational database management system; and operates in three phases. In phase 1; theauthorization rules are preprocessed to determine the information that should be protected.In phase 2; only the necessary information are retrieved from the database; ie; the protectedinformation are not accessed. Finally; in phase 3; the retrieved data are verified against the(remaining) authorization rules to filter away those that cannot be disclosed.,IN INTERNATIONAL CONFERENCE ON INTERNET COMPUTING,2001,26
Concept lattice based composite classifiers for high predictability,Zhipeng Xie; Wynne Hsu; Zongtian Liu; Mong Li Lee,Concept lattice model; the core structure in formal concept analysis; has been successfullyapplied in software engineering and knowledge discovery. This paper integrates the simplebase classifier (Naïve Bayes or Nearest Neighbour) into each node of the concept lattice toform a new composite classifier. Two new classification systems are developed; CLNB andCLNN; which employ efficient constraints to search for interesting patterns and votingstrategy to classify a new object. CLNB integrates the Naïïve Bayes base classifier intoconcept nodes while CLNN incorporates the Nearest Neighbour base classifier into conceptnodes. Experimental results indicate that these two composite classifiers greatly improve theaccuracy of their corresponding base classifier. In addition; CLNB even outperforms threeother state-of-the-art classification methods; NBTree; CBA and C4. 5 Rules.,Journal of Experimental & Theoretical Artificial Intelligence,2002,25
A unified framework for recommendations based on quaternary semantic analysis,Chen Wei; Wynne Hsu; Mong Li Lee,Abstract Social network systems such as FaceBook and YouTube have played a significantrole in capturing both explicit and implicit user preferences for different items in the form ofratings and tags. This forms a quaternary relationship among users; items; tags and ratings.Existing systems have utilized only ternary relationships such as users-items-ratings; orusers-items-tags to derive their recommendations. In this paper; we show that ternaryrelationships are insufficient to provide accurate recommendations. Instead; we model thequaternary relationship among users; items; tags and ratings as a 4-order tensor and castthe recommendation problem as a multi-way latent semantic analysis problem. A unifiedframework for user recommendation; item recommendation; tag recommendation and itemrating prediction is proposed. The results of extensive experiments performed on a real …,Proceedings of the 34th international ACM SIGIR conference on Research and development in Information Retrieval,2011,23
A partition-based approach to graph mining,Junmei Wang; Wynne Hsu; Mong Li Lee; Chang Sheng,Existing graph mining algorithms typically assume that databases are relatively static andcan fit into the main memory. Mining of subgraphs in a dynamic environment is currentlybeyond the scope of these algorithms. To bridge this gap; we first introduce a partition-basedapproach called PartMiner for mining graphs. The PartMiner algorithm finds the frequentsubgraphs by dividing the database into smaller and more manageable units; miningfrequent subgraphs on these smaller units and finally combining the results of these units tolosslessly recover the complete set of subgraphs in the database. Next; we extend PartMinerto handle updates in the dynamic environment. Experimental results indicate that PartMineris effective and scalable in finding frequent subgraphs; and outperforms existing algorithmsin the presence of updates.,Data Engineering; 2006. ICDE'06. Proceedings of the 22nd International Conference on,2006,23
Exploring essential attributes for detecting microRNA precursors from background sequences,Yun Zheng; Wynne Hsu; Mong Lee; Limsoon Wong,Abstract MicroRNAs (miRNAs) have been shown to play important roles in post-transcriptional gene regulation. The hairpin structure is a key characteristic of themicroRNAs precursors (pre-miRNAs). How to encode their hairpin structures is a critical stepto correctly detect the pre-miRNAs from background sequences; ie; pseudo miRNAprecursors. In this paper; we have proposed to encode the hairpin structures of the pre-miRNA with a set of features; which captures both the global and local structurecharacteristics of the pre-miRNAs. Furthermore; we find that four essential attributes arediscriminatory for classifying human pre-miRNAs and background sequences with aninformation theory approach. The experimental results show that the number of conservedessential attributes decreases when the phylogenetic distance between the species …,Data Mining and Bioinformatics,2006,21
The XOO7 XML Management System Benchmark,Stéphane Bressan; Mong Li Lee; Ying Guang Li; Zoé Lacroix; Ullas Nambiar,As XML becomes the standard for electronic data interchange; it is necessary to design benchmarksto provide for the comparative performance analysis of XML management systems(XMLMS). In this work; we propose XOO7; a benchmark for XMLMS. The XOO7 benchmark isan XML version of the OO7 benchmark [11] enriched with relational; document and navigationalqueries that are specific and critical for XML databases. We show that the benchmark meetsthe four criteria; namely; relevance; portability; scalability and simplicity. We implement XOO7and illustrate its applicability by using it to evaluate the performance of four XML managementsystems … XOO7; Performance Analysis; XML Benchmark; Query Processing … Introducedas a schema-less; self-describing data representation language; XML … Language) to solvethe problems faced by the document community. XML … Languages and tools designed …,National University of Singapore CS Department Technical Report TR21/00,2001,21
A Semantic Approach to Keyword Search over Relational Databases,Zhong Zeng; Zhifeng Bao; Mong Li Lee; Tok Wang Ling,Abstract Research in relational keyword search has been focused on the efficientcomputation of results as well as strategies to rank and output the most relevant ones.However; the challenge to retrieve the intended results remains. Existing relational keywordsearch techniques suffer from the problem of returning overwhelming number of results;many of which may not be useful. In this work; we adopt a semantic approach to relationalkeyword search via an Object-Relationship-Mixed data graph. This graph is constructedbased on database schema constraints to capture the semantics of objects and relationshipsin the data. Each node in the ORM data graph represents either an object; or a relationship;or both. We design an algorithm that utilizes the ORM data graph to process keywordqueries. Experiment results show our approach returns more informative results …,*,2013,20
Automated microaneurysm segmentation and detection using generalized eigenvectors,PMD Pallawala; Wynne Hsu; Mong Li Lee; Say Song Goh,Diabetic retinopathy is a major cause of blindness and microaneurysms are the first clinicallyobservable manifestations of diabetic retinopathy. Regular screening and timely interventioncan halt or reverse the progression of this disease. This paper describes an approach that isbased on the generalized eigenvectors of affinity matrix to extract microaneurysms fromdigital retinal images. Microaneurysms are in the low intensity regions and detection iscomplicated by their small sizes; the presence of retinal vessels; and their similarity toanother type of retinal abnormality-haemorrhages. In order to accurately detectmicroaneurysms; the affinity matrix is defined to suppress larger structures such as bloodvessels; haemorrhages; etc and to create uniform affinity distribution for pixels belonging tomicroaneurysms. The generalized eigenvector solution seeks to find the optimal …,Application of Computer Vision; 2005. WACV/MOTIONS'05 Volume 1. Seventh IEEE Workshops on,2005,20
Mining generalized spatio-temporal patterns,Junmei Wang; Wynne Hsu; Mong Li Lee,Abstract Spatio-temporal databases offer a rich repository and opportunities to developtechniques for discovering new types of spatio-temporal patterns. In this paper; we introducea new class of spatio-temporal patterns; called the generalized spatio-temporal patterns; todescribe the repeated sequences of events that occur within small neighbourhoods. Suchpatterns are crucial to the understanding of habitual patterns. To discover this class ofpatterns; we develop an algorithm GenSTMiner based on the idea of pattern growthapproach; and introduce some optimization techniques that are used to reduce the numberof candidates generated and minimize the size of the projected databases. Our performancestudy indicates that GenSTMiner is highly efficient and outperforms PrefixSpan.,Database Systems for Advanced Applications,2005,20
Automatic generation of XQuery view definitions from ORA-SS views,Ya Chen; Tok Ling; Mong Lee,Abstract Many Internet-based applications have adopted XML as the standard dataexchange format. These XML data are typically stored in its native form; thus creating theneed to present XML views over the underlying data files; and to allow users to query theseviews. Using a conceptual model for the design and querying of XML views provides a fastand user-friendly approach to retrieve XML data. The Object-Relationship-Attribute model forSemiStructured data (ORA-SS) is a semantically rich model that facilitates the design of validXML views. It preserves semantic information in the source data. In this paper; we develop amethod that automatically generates view definitions in XQuery from views that have beendesigned using the ORA-SS model. This technique can be used to materialize the views andmap queries issued on XML views into the equivalent queries in XQuery syntax on the …,Conceptual Modeling-ER 2003,2003,20
Retinal Vascular Fractal Dimension Measurement and Its Influence from Imaging Variation: Results of Two Segmentation Methods,Victoria Fay Cosatto; Gerald Liew; Elena Rochtchina; Alan Wainwright; YongPing Zhang; Wynne Hsu; Mong Li Lee; Qiangfeng Peter Lau; Haslina H Hamzah; Paul Mitchell; Tien Yin Wong; Jie Jin Wang,Aim: To assess the influences of imaging variation (different photographic angle) on themeasurement of retinal vascular fractal dimension (D f); using two segmentation methods.Materials and methods: Nonlinear orthogonal projection segmentation (International RetinalImaging Software-Fractal; termed IRIS-Fractal) and curvature-based segmentation(Singapore Institute Vessel Assessment-Fractal; termed SIVA-Fractal) methods were used tomeasure D f and were assessed for their reproducibility in detecting retinal vessels of 30stereoscopic pairs of optic disc color images. Each pair was taken from the same eye withslightly different angles of incidence. Each photograph of the pairs had subtle variations inbrightness between areas temporal and nasal to the optic disc. Results: Intragraderreproducibility of D f measurement was similar (intraclass correlation 0.81 and 0.96 …,Current Eye Research,2010,19
Efficient mining of frequent XML query patterns with repeating-siblings,Liang Huai Yang; Mong Li Lee; Wynne Hsu; Decai Huang; Limsoon Wong,Abstract A recent approach to improve the performance of XML query evaluation is to cachethe query results of frequent query patterns. Unfortunately; discovering these frequent querypatterns is an expensive operation. In this paper; we develop a two-pass mining algorithm2PXMiner that guarantees the discovery of frequent query patterns by scanning thedatabase at most twice. By exploiting a transaction summary data structure; and anenumeration tree; we are able to determine the upper bounds of the frequencies of thecandidate patterns; and to quickly prune away the infrequent patterns. We also design anindex to trace the repeating candidate subtrees generated by sibling repetition; thusavoiding redundant computations. Experiments results indicate that 2PXMiner is bothefficient and scalable.,Information and Software Technology,2008,19
Designing semistructured databases: a conceptual approach,Mong Li Lee; Sin Yeung Lee; Tok Wang Ling; Gillian Dobbie; Leonid A Kalinichenko,Abstract Semistructured data has become prevalent with the growth of the Internet. The datais usually stored in a database system or in a specialized repository. Many informationproviders have presented their databases on the web as semistructured data; while othersare developing repositories for new applications. Designing a “good” semistructureddatabase is important to prevent data redundancy and updating anomalies. In this paper; wepropose a conceptual approach to design semistructured databases. A conceptual layerbased on the Entity-Relationship model is used to remove redundancies at the semanticlevel. An algorithm to map an ER diagram involving composite attributes weak entity types;recursive; n-ary and ISA relationship sets; and aggregations to a semistructured schemagraph (S3-Graph) is also given.,*,2001,19
Linking Temporal Records for Profiling Entities,Furong Li; Mong Li Lee; Wynne Hsu; Wang-Chiew Tan,Abstract To harness the rich amount of information available on the Web today; manyorganizations start to aggregate public (and private) data to derive new knowledge bases. Afundamental challenge in constructing an accurate integrated knowledge repository fromdifferent data sources is to understand how facts across different sources are related to oneanother over time. This challenge; referred to as the temporal record linkage problem; goesfar beyond the traditional record linkage problem as it requires a fine-grained analysis ofhow two facts are temporally related if they both refer to the same entity. In this paper; wepresent a new solution for understanding how two facts may be temporally related andexploit the knowledge to profile how entities evolve over time. Our solution makes use of anovel transition model which captures sophisticated patterns of value transitions …,Proceedings of the 2015 ACM SIGMOD International Conference on Management of Data,2015,17
Answering Top-k Similar Region Queries,Chang Sheng; Yu Zheng; Wynne Hsu; Mong Lee; Xing Xie,Abstract Advances in web technology have given rise to new information retrievalapplications. In this paper; we present a model for geographical region search and call thisclass of query similar region query. Given a spatial map and a query region; a similar regionsearch aims to find the top-k most similar regions to the query region on the spatial map. Wedesign a quadtree based algorithm to access the spatial map at different resolution levels.The proposed search technique utilizes a filter-and-refine manner to prune regions that arenot likely to be part of the top-k results; and refine the remaining regions. Experimental studybased on a real world dataset verifies the effectiveness of the proposed region similaritymeasure and the efficiency of the algorithm.,Database Systems for Advanced Applications,2010,17
Discovering spatial interaction patterns,Chang Sheng; Wynne Hsu; Mong Lee; Anthony Tung,Abstract Advances in sensing and satellite technologies and the growth of Internet haveresulted in the easy accessibility of vast amount of spatial data. Extracting useful knowledgefrom these data is an important and challenging task; in particular; finding interaction amongspatial features. Existing works typically adopt a grid-like approach to transform thecontinuous spatial space to a discrete space. In this paper; we propose to model the spatialfeatures in a continuous space through the use of influence functions. For each feature type;we build an influence map that captures the distribution of the feature instances.Superimposing the influence maps allows the interaction of the feature types to be quicklydetermined. Experiments on both synthetic and real world datasets indicate that theproposed approach is scalable and is able to discover patterns that have been missed by …,Database Systems for Advanced Applications,2008,17
Path-augmented keyword search for XML documents,Wynne Hsu; Mong Li Lee; Xiaodong Wu,Keyword search is easy to use since it does not require the prior knowledge of querylanguages or the structure of the underlying data. However; keyword search does not utilizethe rich information encoded in the structures of XML to aid in the retrieval of documents. InThis work; we devise a context-aware approach for searching XML to improve theeffectiveness of keyword search on XML via query expansion. We find a set of XML pathexpressions that capture the contextual meaning of a keyword query. Paths in the contexts ofthe query are used to expand the original query to improve the effectiveness of keywordsearch on XML. Empirical results indicate that the proposed path-augmented keywordsearch of XML documents outperforms current keyword expansion and keyword proximitysearch techniques.,Tools with Artificial Intelligence; 2004. ICTAI 2004. 16th IEEE International Conference on,2004,17
Xml benchmarks put to the test,Ullas Nambiar; Zoé Lacroix; Stéphane Bressan; Mong Li Lee; YG Li,Abstract The effectiveness of existing XML query languages has been studied by many whofocused on the comparison of linguistic features; implicitly reflecting the fact that most XMLtools exist only on paper. In this paper; with a focus on efficiency and concreteness; wepropose a pragmatic first step toward the systematic benchmarking of XML query processingplatforms. We begin by identifying the necessary functionalities an XML data managementsystem should support. We review existing approaches for managing XML data and thequery processing capabilities of these approaches. We then compare three XML querybenchmarks XMach-1; XMark and XOO7 and discuss the applicability; strengths andlimitations of these benchmarks. We highlight the bias of these benchmarks towards the datacentric view of XML and motivate our selection of XOO7 to extend with document centric …,Proceedings of the Third International Conference on Information Integration and Web-based Applications and Services; Linz; Austria,2001,17
Applications of ORA-SS: an object-relationship-attribute data model for semistructured data,T Ling; M Lee; Gillian Dobbie,*,IIWAS’01: Proceedings of 3rd International Conference on Information Integration and Web-based Applications and Serives,2001,17
Effective detection of retinal exudates in fundus images,Wang Huan; Wynne Hsu; Lee Mong Li,Diabetic-related eye diseases are the most common cause of blindness in the world. Earlydetection through regular screenings is the most effective treatment for these eye diseases.To improve the efficiency of such screenings; it is very important that effectively finding thepresence of abnormalities in the retinal images captured during the screenings. In thispaper; it is focused on automatically detecting one of the abnormal signs: the presenceof'exudates/lesions in the retinal images. A novel approach that combines median filteringand dynamic clustering analysis is proposed. Experimental results indicate that the newalgorithm is easier; faster and more effective for lesion detection from retinal images ofvarious qualities.,Biomedical Engineering and Informatics; 2009. BMEI'09. 2nd International Conference on,2009,15
Consistent top-k queries over time,Mong Lee; Wynne Hsu; Ling Li; Wee Tok,Abstract Top-k queries have been well-studied in snapshot databases and data streams. Weobserve that decision-makers are often interested in a set of objects that exhibit a certaindegree of consistent behavior over time. We introduce a new class of queries calledconsistent top-k to retrieve k objects that are always amongst the top at every time point overa specified time interval. Applying top-k methods at each time point leads to largeintermediate results and wasted computations. We design two methods; rank-based andbitmap; to address these shortcomings. Experiment results indicate that the proposedmethods are efficient and scalable; and consistent top-k queries are practical in real worldapplications.,Database Systems for Advanced Applications,2009,15
Systematic assessment of high-throughput experimental data for reliable protein interactions using network topology,Jin Chen; Wynne Hsu; Mong Li Lee; See-Kiong Ng,Current protein interaction detection via high-throughput experimental methods such asyeast-two-hybrid has been reported to be highly erroneous. This work introduces a novelmeasure called IRAP for assessing the reliability of protein interaction based on theunderlying topology of the protein interaction network. A candidate protein interaction isconsidered to be reliable if it is involved in a closed loop in which the alternative path ofinteractions between the two interacting proteins is strong. We design an algorithm tocompute the IRAP value for each interaction in a protein interaction network. Validation ofIRAP as a measure for assessing the reliability of protein-protein interactions fromconventional high-throughput experiments is performed. We devise a heuristic algorithm tocompute IRAP that is able to achieve a 40% speedup in runtime while maintaining a 95 …,Tools with Artificial Intelligence; 2004. ICTAI 2004. 16th IEEE International Conference on,2004,15
2PXMiner: an efficient two pass mining of frequent XML query patterns,Liang Huai Yang; Mong Li Lee; Wynne Hsu; Xinyu Guo,Abstract Caching the results of frequent query patterns can improve the performance ofquery evaluation. This paper describes a 2-pass mining algorithm called 2PXMiner todiscover frequent XML query patterns. We design 3 data structures to expedite the miningprocess. Experiments results indicate that 2PXMiner is both efficient and scalable.,Proceedings of the tenth ACM SIGKDD international conference on Knowledge discovery and data mining,2004,15
Transformed Representations for Convolutional Neural Networks in Diabetic Retinopathy Screening,Gilbert Lim; Mong Li Lee; Wynne Hsu; Tien Yin Wong,Abstract Convolutional neural networks (CNNs) are flexible; biologically-inspired variants ofmulti-layer perceptrons that have proven themselves to be exceptionally suited todiscriminative vision tasks. However; relatively little is known on whether they can be madeboth more efficient and more accurate; by introducing suitable transformations that exploitgeneral knowledge of the target classes. We demonstrate this functionality through pre-segmentation of input images with a fast and robust but loose segmentation step; to obtain aset of candidate objects. These objects then undergo a spatial transformation into a reducedspace; retaining but a compact high-level representation of their appearance. Additionalattributes may be abstracted as raw features that are incorporated after the convolutionalphase of the network. Finally; we compare its performance against existing approaches …,Workshops at the Twenty-Eighth AAAI Conference on Artificial Intelligence,2014,14
Measurement of the Macular Vascular Fractal Dimension Using a Computer-Assisted Program,George N Thomas; Shin-Yeu Ong; Yih Chung Tham; Wynne Hsu; Mong-Li Lee; Qiangfeng Peter Lau; Wan Ting Tay; Jessica Alessi-Calandro; Lauren AB Hodgson; Ryo Kawasaki; Tien Yin Wong; Carol Yim-lui Cheung,Purpose.: Macular diseases may be associated with an altered retinal vasculature. Wedescribe and test new software for the measurement of retinal vascular fractal dimension toquantify the complexity of retinal vasculature at the macula (D mac) and to compare this withfractal dimension measured around the optic disc (D disc). Methods.: A total of 342 macular-centered and optic disc-centered digital retinal photographs from 171 subjects was selectedrandomly from a population-based study. Retinal vascular fractional dimension (D f) wasmeasured by two trained graders using a computer-assisted program (SIVA-FA; softwareversion 1.0; National University of Singapore) on macula-centered (D mac) and optic disc-centered (D disc) photographs; to assess intergrader reliability. Measurements wererepeated after two weeks to determine intragrader reliability. A separate 50 pairs of …,Investigative ophthalmology & visual science,2014,14
Incorporating duration information for trajectory classification,Dhaval Patel; Chang Sheng; Wynne Hsu; Mong Li Lee,Trajectory classification has many useful applications. Existing works on trajectoryclassification do not consider the duration information of trajectory. In this paper; we extractduration-aware features from trajectories to build a classifier. Our method utilizes informationtheory to obtain regions where the trajectories have similar speeds and directions. Further;trajectories are summarized into a network based on the MDL principle that takes intoaccount the duration difference among trajectories of different classes. A graph traversal isperformed on this trajectory network to obtain the top-k covering path rules for eachtrajectory. Based on the discovered regions and top-k path rules; we build a classifier topredict the class labels of new trajectories. Experiment results on real-world datasets showthat the proposed duration-aware classifier can obtain higher classification accuracy than …,Data Engineering (ICDE); 2012 IEEE 28th International Conference on,2012,14
RRPJ: Result-rate based progressive relational join,Wee Tok; Stephane Bressan; Mong-Li Lee,Abstract Progressive join algorithms are join algorithms that produce results incrementallyas input data is available. Because they are non-blocking; they are particularly suitable foronline processing of data streams. Reference algorithms of this family are the symmetrichash join; the X-join and more recently; the rate-based progressive join (RPJ). While thesymmetric hash join introduces the idea of a symmetric processing of the input streams butassumes sufficient main memory; the X-Join suggests that the processing can scale to verylarge amounts of data if main memory is regularly flushed to disk; and a reactive/cleanupphase is triggered for disk-resident data. The X-join flushing strategy is based on a simplelargest-first strategy; where the largest partition is flushed to disk. The recently proposed RPJpredicts the main memory tuples or partitions that should be flushed to disk in order to …,Advances in Databases: Concepts; Systems and Applications,2007,14
A path-based labeling scheme for efficient structural join,Hanyu Li; Mong Li Lee; Wynne Hsu,Abstract The structural join has become a core operation in XML query processing. Thiswork examines how path information in XML can be utilized to speed up the structural joinoperation. We introduce a novel approach to pre-filter path expressions and identify aminimal set of candidate elements for the structural join. The proposed solution comprises ofa path-based node labeling scheme and a path join algorithm. The former associates everynode in an XML document with its path type; while the latter greatly reduces the cost ofsubsequent element node join by filtering out elements with irrelevant path types.Comparative experiments with the state-of-the-art holistic join algorithm clearly demonstratethat the proposed approach is efficient and scalable for queries ranging from simple paths tocomplex branch queries.,*,2005,14
Xstorm: A scalable storage mapping scheme for xml data,Wen Qiang Wang; Mong Li Lee; Beng Chin Ooi; Kian–Lee Tan,Abstract With the increasing ubiquity of XML; an eXtensible Markup Language; the industryis racing to provide XML infrastructure for e–commerce; information interchange; effectivequery of diverse sources and yet more integration of diverse data. It is anticipated that largevolumes of XML data will be created manually from HTML documents or generated usingsome WWW tools and electronic data interchange (EDI). In this paper; we examine howlarge amounts of XML data can be stored in a relational database. Our scheme considersthe unique irregular features of XML; including missing elements or multiple occurrences ofthe same element; and elements which may have atomic values in some data items andstructured values in others. A detailed experimental study demonstrates good queryperformance; effective space utilization and scalability.,World Wide Web,2001,14
Entity Profiling with Varying Source Reliabilities,Furong Li; Mong Li Lee; Wynne Hsu,Abstract The rapid growth of information sources on the Web has intensified the problem ofdata quality. In particular; the same real world entity may be described by different sources invarious ways with overlapping information; and possibly conflicting or even erroneousvalues. In order to obtain a more complete and accurate picture for a real world entity; weneed to collate the data records that refer to the entity; as well as correct any erroneousvalues. We observe that these two tasks are often tightly coupled: rectifying erroneousvalues will facilitate data collation; while linking similar records provides us with a clearerview of the data and additional evidence for error correction. In this paper; we present aframework called Comet that interleaves record linkage with error correction; taking intoconsideration the source reliabilities on various attributes. The proposed framework first …,*,2014,13
Efficient Mining of Dense Periodic Patterns in Time Series,Chang SHENG; Wynne HSU; Mong Li LEE,Existing techniques to mine periodic patterns in time series data are focused on discoveringfull-cycle periodic patterns from an entire time series. However; many useful partial periodicpatterns are hidden in long and complex time series data. In this paper; we aim to discoverthe partial periodicity in local segments of the time series data. We introduce the notion ofcharacter density to partition the time series into variable-length fragments and to determinethe lower bound of each character's period. We propose a novel algorithm; called DPMiner;to. nd the dense periodic patterns in time series data. The algorithm makes use of an Apriori-like property to prune the search space. Experimental results on both synthetic and real-lifedatasets demonstrate that the proposed algorithm is effective and ef. cient to revealinteresting dense periodic patterns.,*,2005,13
Correlation-based attribute outlier detection in XML,Judice LY Koh; Mong Li Lee; Wynne Hsu; Wee Tiong Ang,Compared to relational data models; the hierarchical structure of semi-structured data suchas XML provides semantically meaningful neighbourhoods advancing data cleaningproblems such as outlier detection. In this paper; we introduce the concept of correlatedsubspace that leverages on the hierarchical relationships between XML attributes to providecontextually informative neighbourhoods for attribute outlier detection. We also design twocorrelation-based attribute outlier metrics for XML; namely the xO-Measure and xQ-Measure.The effectiveness of our XML outlier detection approach is supported with experimentalresults.,Data Engineering; 2008. ICDE 2008. IEEE 24th International Conference on,2008,12
BioWare: A framework for bioinformatics data retrieval,JLY Koh; SPT Krishnan; SH Seah; PTJ Tan; AM Khan; ML Lee; V Brusic,*,*,2004,12
Tumor cell identification using features rules,Bin Fang; Wynne Hsu; Mong Li Lee,Abstract Advances in imaging techniques have led to large repositories of images. There isan increasing demand for automated systems that can analyze complex medical imagesand extract meaningful information for mining patterns. Here; we describe a real-life imagemining application to the problem of tumour cell counting. The quantitative analysis oftumour cells is fundamental to characterizing the activity of tumour cells. Existingapproaches are mostly manual; time-consuming and subjective. Efforts to automate theprocess of cell counting have largely focused on using image processing techniques only.Our studies indicate that image processing alone is unable to give accurate results. In thispaper; we examine the use of extracted features rules to aid in the process of tumor cellcounting. We propose a robust local adaptive thresholding and dynamic water immersion …,Proceedings of the eighth ACM SIGKDD international conference on Knowledge discovery and data mining,2002,12
Integration of disparate information sources: A short survey,M Lee; Stephane Bressan; Cheng Hian Goh; Raghu Ramakrishnan,Abstract In this paper; we try and give a brief introduction to the Gestalt approach to theintegration of disparate information sources and to the Context Interchange approach to theautomatic identification and resolution of semantic conflicts. We also attempt present asurvey of the modern solutions to the problems of query processing in Internet networkeddata sources; which both Gestalt and Context Interchange leverage and attempt to adaptand improve.,ACM Multimedia,1999,12
ExpressQ: Identifying Keyword Context and Search Target in Relational Keyword Queries,Zhong Zeng; Zhifeng Bao; Thuy Ngoc Le; Mong Li Lee; Wang Tok Ling,Abstract Keyword search in relational databases has gained popularity due to its ease ofuse. However; the challenge to return query answers that satisfy users' information needremains. Traditional keyword queries have limited expressive capability and are ambiguous.In this work; we extend keyword queries to enhance their expressive power and describe ansemantic approach to process these queries. Our approach considers keywords that matchmeta-data such as the names of relations and attributes; and utilizes them to provide thecontext of subsequent keywords in the query. Based on the ORM schema graph whichcaptures the semantics of objects and relationships in the database; we determine theobjects and relationships referred to by the keywords in order to infer the search target of thequery. Then; we construct a set of minimal connected graphs called query patterns; to …,Proceedings of the 23rd ACM International Conference on Conference on Information and Knowledge Management,2014,11
View update in entity-relationship approach,Tok Wang Ling; Mong Li Lee,Abstract The traditional problem of updating relational databases through views is animportant practical problem that has attracted much interest. In this paper; we examine theproblem of view update in Entity-Relationship based database management systems [1]where the conceptual schema is represented by a normal form ER diagram [2] and viewsmay be modelled by ER diagrams. We develop a theory within the framework of the ERapproach that characterizes the conditions under which there exist mappings from viewupdates into updates on the conceptual schema. Concepts such as virtual updates andthree types of insertability are introduced. We also present two algorithms; the ViewUpdatability Algorithm and the View Update Translation Algorithm.,Data & knowledge engineering,1996,11
Relational to entity-relationship schema translation using semantic and inclusion dependencies,Tok Wang Ling; Mong Li Lee,Abstract When a database is to be interoperated with others; its schema must first beconverted to the canonical model of the federated system. This implies a knowledgeacquisition process to upgrade the semantics of the local schema. This article addresses theproblem of translating relational schemas to a semantically rich entity–relationship (ER)model. We introduce a concept called semantic dependency; which we define formally inboth the ER and relational models. We use this concept to semantically enrich a relationalschema before translating it to the corresponding ER schema. We show that using theconcept of semantic dependency in addition to inclusion dependency; functionaldependency; and multivalued dependency will result in a more accurate relational to ERschema translation.,Integrated Computer-Aided Engineering,1995,11
Integrated Optic Disc and Cup Segmentation with Deep Learning,Gilbert Lim; Yuan Cheng; Wynne Hsu; Mong Li Lee,Glaucoma is a widespread ocular disorder leading to irreversible loss of vision. Therefore;there is a pressing need for cost-effective screening; such that preventive measures can betaken. This can be achieved with an accurate segmentation of the optic disc and cup fromretinal images to obtain the cup-to-disc ratio. We describe a comprehensive solution basedon applying convolutional neural networks to feature exaggerated inputs emphasizing discpallor without blood vessel obstruction; as well as the degree of vessel kinking. Theproduced raw probability maps then undergo a robust refinement procedure that takes intoaccount prior knowledge about retinal structures. Analysis of these probability maps furtherallows us to obtain a confidence estimate on the correctness of the segmentation; which canbe used to direct the most challenging cases for manual inspection. Tests on two large …,Tools with Artificial Intelligence (ICTAI); 2015 IEEE 27th International Conference on,2015,10
iSearch: an interpretation based framework for keyword search in relational databases,Zhong Zeng; Zhifeng Bao; Tok Wang Ling; Mong Li Lee,Abstract Keyword search has become an effective information retrieval method for structureddata. Existing works in relational database keyword search have addressed the problems offinding and evaluating candidate results. However; given that keyword queries areinherently ambiguous; it is often the case that candidate results do not match users' searchintention. In this paper; we analyze the limitations of current keyword search techniques andintroduce the problem of generating and ranking keyword query interpretations. We proposea novel 3-phase keyword search paradigm which consists of:(1) the ability to predict queryinterpretations;(2) incorporate user feedback to to remove keyword ambiguities;(3) a rankingmodel to evaluate a query interpretation.,Proceedings of the Third International Workshop on Keyword Search on Structured Data,2012,10
Integrating frequent pattern mining from multiple data domains for classification,Dhaval Patel; Wynne Hsu; Mong Li Lee,Many frequent pattern mining algorithms have been developed for categorical; numerical;time series; or interval data. However; little attention has been given to integrate thesealgorithms so as to mine frequent patterns from multiple domain datasets for classification. Inthis paper; we introduce the notion of a heterogenous pattern to capture the associationsamong different kinds of data. We propose a unified framework for mining multiple domaindatasets and design an iterative algorithm called HTMiner. HTMiner discovers essentialheterogenous patterns for classification and performs instance elimination. This instanceelimination step reduces the problem size progressively by removing training instanceswhich are correctly covered by the discovered essential heterogenous pattern. Experimentson two real world datasets show that the HTMiner is efficient and can significantly improve …,Data Engineering (ICDE); 2012 IEEE 28th International Conference on,2012,10
Lag patterns in time series databases,Dhaval Patel; Wynne Hsu; Mong Li Lee; Srinivasan Parthasarathy,Abstract Time series motif discovery is important as the discovered motifs generally form theprimitives for many data mining tasks. In this work; we examine the problem of discoveringgroups of motifs from different time series that exhibit some lag relationships. We define anew class of pattern called lagPatterns that captures the invariant ordering among motifs.lagPatterns characterize localized associative pattern involving motifs derived from eachentity and explicitly accounts for lag across multiple entities. We present an exact algorithmthat makes use of the order line concept and the subsequence matching property of thenormalized time series to find all motifs of various lengths. We also describe a method calledLPMiner to discover lagPatterns efficiently. LPMiner utilizes inverted index and motifalignment technique to reduce the search space and improve the efficiency. A detailed …,*,2010,10
Discovering geographical-specific interests from web click data,Chang Sheng; Wynne Hsu; Mong Li Lee,Abstract As the Internet continues to play an important role in many business applications; itbecomes vital to increase the competitive edge by offering geographically tailored contentsthat reflect the common interests of the geographical region of the web visitors. In this paper;we define the problem of mining geographical-specific interests patterns. We utilize thequadtree to model the influence distributions of different features; and design an algorithmcalled Flex-iPROBER to mine geographical-specific interests patterns that are significant ina local region. We further examine how these patterns can change over time and develop analgorithm called MineGIC to efficiently discover pattern changes. Experiment resultsdemonstrate that the proposed algorithms are scalable and efficient. Patterns discoveredfrom real world web click datasets reveal interesting patterns and show the evolution of …,Proceedings of the first international workshop on Location and the web,2008,10
A classification of biological data artifacts,Judice LY Koh; Mong Li Lee; Vladimir Brusic,ABSTRACT Advancements in sequencing techniques continue to generate large volumes ofbiological data which accumulate rapidly in the public molecular databases. Publicbiological data are commonly used for data mining and analyses; although ironically; thedatabases contain a significant extent of data artifacts (errors; redundancies; anddiscrepancies). Automatic cross-referencing and crossupdating between multiple moleculardatabases result in propagation of the data artifacts; further reducing the quality of thesedatabases. Reduced data quality; in turn; affects the accuracy of data mining results.,ICDT Workshop on Database Issues in Biological Databases (DBiBD),2005,10
Efficient evaluation of multiple queries on streaming XML data,Mong Li Lee; Boon Chin Chua; Wynne Hsu; Kian-Lee Tan,Abstract Traditionally; XML documents are processed at where they are stored. This allowsthe query processor to exploit pre-computed data structures (eg; index) to retrieve thedesired data efficiently. However; this mode of processing is not suitable for manyapplications where the documents are frequently updated. In such situations; efficientevaluation of multiple queries over streaming XML documents becomes important. Thispaper introduces a new operator; mqX-scan; which efficiently evaluates multiple querieswith a single pass on streaming XML data. To facilitate matching; mqX-scan utilizestemplates containing paths that have been traversed to match regular path expressionpatterns in a pool of queries. Results of the experiments demonstrate the efficiency andscalability of the mqX-scan operator.,Proceedings of the eleventh international conference on Information and knowledge management,2002,10
Extending classical functional dependencies for physical database design,Tok Wang Ling; Cheng Hian Goh; Mong Li Lee,Abstract Traditionally; database design activities are partitioned into distinct phases in whicha logical design phase precedes physical database design. The objective of the logicaldesign step is to eliminate redundancies and updating anomalies using the notion of datadependencies; while leaving the physical design step to consider how the database schemamay be restructured to provide more efficient access. We argue in this paper that theseparation of these two steps often results in physical database design not being able tobenefit from knowledge of the semantics of data captured in the earlier phases of thedatabase design life cycle. As a step towards overcoming this problem; we demonstrate howclassical functional dependencies can be extended to capture data semantics relevant to thedesign of database schemas which are more desirable from the efficiency point of view …,Information and Software Technology,1996,10
Tagcloud-based explanation with feedback for recommender systems,Wei Chen; Wynne Hsu; Mong Li Lee,Abstract Personalized recommender systems aim to push only the relevant items andinformation directly to the users without requiring them to browse through millions of webresources. The challenge of these systems is to achieve a high user acceptance rate on theirrecommendations. In this paper; we aim to increase the user acceptance ofrecommendations by providing more intuitive tag-based explanations of why the items arerecommended. Tags are used as intermediary entities that not only relate target users to therecommended items but also understand users' intents. Our system also allows tag-basedonline relevance feedback. Experiment results on the Movielens dataset show that theproposed approach is able to increase the acceptance rate of recommendations andimprove user satisfaction.,Proceedings of the 36th international ACM SIGIR conference on Research and development in information retrieval,2013,9
Segmentation of Retinal Vessels Using Nonlinear Projections,Yongping Zhang; Wynne Hsu; Mong Li Lee,An automated method for blood vessel segmentation is presented in this paper. Theapproach uses the nonlinear orthogonal projection to capture the features of vesselnetworks; and derives a novel local adaptive thresholding algorithm for vessel detection. Byembedding in a kind of image decomposition model; the selection of system parameterwhich reflects the size of concerned convex set is examined. This approach differs frompreviously known methods in that it uses matched filtering; vessel tracking or supervisedmethods. The algorithm was tested on two publicly available databases: the DRIVE and theSTARE. By comparison with hand-labeled ground truth; good average accuracies areachieved for the both databases.,Image Processing; 2007. ICIP 2007. IEEE International Conference on,2007,9
Data cleaning and XML: The DBLP experience,Wai Lup Low; Wee Hyong Tok; Mong Li Lee; Tok Wang Ling,With the increasing popularity of data-centric XML; data warehousing and miningapplications are being developed for rapidly burgeoning XML data repositories. Data qualitywill no doubt be a critical factor for the success of such applications. Data cleaning; whichrefers to the processes used to improve data quality; has been well researched in thecontext of traditional databases. In earlier work we developed a knowledge-basedframework for data cleaning relational databases. In this work; we present a novel attempt toapply this framework to XML databases. Our experimental dataset is the DBLP database; apopular online XML bibliography database used by many researchers.,Data Engineering; 2002. Proceedings. 18th International Conference on,2002,9
Issues in an Entity-Relationship Based Federated Database System.,Tok Wang Ling; Mong-Li Lee,*,CODAS,1996,9
Node Immunization over Infectious Period,Chonggang Song; Wynne Hsu; Mong Li Lee,Abstract Locating nodes to immunize in computer/social networks to control the spread ofvirus or rumors has become an important problem. In real world contagions; nodes may getinfected by external sources when the propagation is underway. While most studiesformalize the problem in a setting where contagion starts at one time point; we model a morerealistic situation where there are likely to be many breakouts of contagions over a timewindow. We call this the node immunization over infectious period (NIIP) problem. We showthat the NIIP problem is NP-hard and remains so even in directed acyclic graphs. Wepropose a NIIP algorithm to select $ k $ nodes to immunize over a time period. Simulation isperformed to estimate a good distribution of $ k $ over the time period. For each time point;the NIIP algorithm will make decisions which nodes to immunize given the estimated …,Proceedings of the 24th ACM International on Conference on Information and Knowledge Management,2015,8
Utilizing purchase intervals in latent clusters for product recommendation,Gang Zhao; Mong LI Lee; Hsu Wynne,Abstract Collaborative filtering have become increasingly important with the development ofWeb 2.0. Online shopping service providers aim to provide users with quality list ofrecommended items that will enhance user satisfaction and loyalty. Matrix factorizationapproaches have become the dominant method as they can reduce the dimension of thedata set and alleviate the sparsity problem. However; matrix factorization approaches arelimited because they depict each user as one preference vector. In practice; we observe thatusers may have different preferences when purchasing different subsets of items; and theperiods between purchases also vary from one user to another. In this work; we propose aprobabilistic approach to learn latent clusters in the large user-item matrix; and incorporatetemporal information into the recommendation process. Experimental results on a real …,Proceedings of the 8th Workshop on Social Network Mining and Analysis,2014,8
Coordination guided reinforcement learning,Qiangfeng Peter Lau; Mong Li Lee; Wynne Hsu,Abstract In this paper; we propose to guide reinforcement learning (RL) with expertcoordination knowledge for multi-agent problems managed by a central controller. The aimis to learn to use expert coordination knowledge to restrict the joint action space and to directexploration towards more promising states; thereby improving the overall learning rate. Wemodel such coordination knowledge as constraints and propose a two-level RL system thatutilizes these constraints for online applications. Our declarative approach towardsspecifying coordination in multi-agent learning allows knowledge sharing betweenconstraints and features (basis functions) for function approximation. Results on a soccergame and a tactical real-time strategy game show that coordination constraints improve thelearning rate compared to using only unary constraints. The two-level RL system also …,Proceedings of the 11th International Conference on Autonomous Agents and Multiagent Systems-Volume 1,2012,8
RETINAL IMAGE ANALYSIS SYSTEMS AND METHODS,*,*,*,2010,8
RETINAL IMAGE ANALYSIS SYSTEMS AND METHODS,*,*,*,2009,8
A stratified approach to progressive approximate joins,Wee Hyong Tok; Stéphane Bressan; Mong-Li Lee,Abstract Users often do not require a complete answer to their query but rather only asample. They expect the sample to be either the largest possible or the most representative(or both) given the resources available. We call the query processing techniques that deliversuch results' approximate'. Processing of queries to streams of data is said tobe'progressive'when it can continuously produce results as data arrives. In this paper; weare interested in the progressive and approximate processing of queries to data streamswhen processing is limited to main memory. In particular; we study one of the main buildingblocks of such processing: the progressive approximate join. We devise and present severalnovel progressive approximate join algorithms. We empirically evaluate the performance ofour algorithms and compare them with algorithms based on existing techniques. In …,Proceedings of the 11th international conference on Extending database technology: Advances in database technology,2008,8
A path-based approach for efficient structural join with not-predicates,Hanyu Li; Mong Li Lee; Wynne Hsu; Ling Li,Abstract There has been much research on XML query processing. However; there hasbeen little work on the evaluation of XML queries involving not-predicates. Such queries areuseful and common in many real-life applications. In this paper; we present a model calledXQuery tree to model queries involving not-predicates and describe a path-based method toevaluate such queries efficiently. A comprehensive set of experiments is carried out todemonstrate the effectiveness and efficiency of the proposed solution.,*,2007,8
Progressive spatial join,Wee Hyong Tok; Stéphane Bressan; Mong Li Lee,In spatial data exploration and analysis; the system would present a user with initialpromising results and empower the user to modify runtime query parameters. The highdegree of interactivity would significantly reduce users' waiting time for results that are notuseful; and then having to re-issue a new query. To support this level of interaction duringquery processing; it necessitates the study of adaptive and progressive spatial queryprocessing techniques that can deliver initial results quickly and adapt to run-timefluctuations during the delivery of remote data. Our goal is to design a generic framework foradaptive and progressive spatial query processing. In this paper; we present our ongoingwork on designing progressive spatial join algorithm as an initial step,Scientific and Statistical Database Management; 2006. 18th International Conference on,2006,8
Database Systems for Advanced Applications,Mong-Li Lee; Kian-Lee Tan; Vilas Wuwongse,*,11th International Conference; DASFAA,2006,8
Efficient pattern discovery for semistructured data,Zhou Feng; Wynne Hsu; Mong Li Lee,The process of discovering frequent patterns from large semistructured data repositories isone of the hardest categories of tree mining problems; since it involves the discovery ofunordered embedded tree patterns. Existing work has focused primarily on the discovery ofordered; induced trees. This work proposes a divide-and-conquer algorithm called WTIMinerto discover the complete set of frequent unordered embedded subtrees. The algorithmsuccessfully reduces the complexity of pattern matching and counting problem that a regulartree mining algorithm faces. Experimental results demonstrate the efficiency and scalabilityof WTIMiner in terms of both time and space,Tools with Artificial Intelligence; 2005. ICTAI 05. 17th IEEE International Conference on,2005,8
Techniques for temporal registration of retinal images,Bin Fang; Wynne Hsu; Mong Li Lee,Temporal registration of retinal images is helpful to provide physicians important informationin tracking the evolution of eye-related diseases. The vascular structure of the retina is themost appropriate feature representation for registration. This paper describes a fast chamfermatching applied to the vascular structure to align pairs of fundus images. While the fastchamfer matching is able to achieve successful alignment consistently; it fails to find correctmodel parameters in a few cases. To alleviate this problem; we propose a nonparametricelastic matching method. The two matching algorithms are tested on 98 pairs of temporalfundus images. We found that elastic matching gives better performance than the fastchamfer matching method where there are 3 failure cases were reported.,Image Processing; 2004. ICIP'04. 2004 International Conference on,2004,8
A Case Tool for Designing XML Views,Ya Bing Chen; Tok Wang Ling; Mong Li Lee,Abstract XML views are essential for managing XML data on the Web. Like views intraditional databases; XML views allow users to see data from different perspectives.Moreover; XML views are able to offer a structured interface over semistructured data andmake it possible to integrate heterogeneous data source. In this paper; we describe agraphical case tool for designing XML views with the following novel features. First; itsupports validation of views by checking if a view conforms to the semantics in theunderlying source schemas. The feature is critical for XML views design because it avoidproducing meaningless views. Second; the case tool provides a scheme to store XML datainto an object-relational database that reduces redundancies and facilitates efficientprocessing of queries over XML views.,DIWeb,2002,8
Benchmarking xml management systems: The xoo7 way,Ullas Nambiar; Zoé Lacroix; Stéphane Bressan; Mong Li Lee; Yingguang Li,Abstract The effectiveness of existing XML query languages has been studied by many whofocused on the comparison of linguistic features; implicitly reflecting the fact that most XMLtools exist only on paper. In this paper; with a focus on efficiency and concreteness; wepropose a pragmatic first step toward the systematic benchmarking of XML query processingplatforms. We begin by identifying the necessary functionalities an XML data managementsystem should support. We review existing approaches for managing XML data and thequery processing capabilities of these approaches. We then compare three XML querybenchmarks XMach-1; XMark and XOO7 and discuss the applicability; strengths andlimitations of these benchmarks. We highlight the bias of these benchmarks towards the datacentric view of XML and motivate our selection of XOO7 to extend with document centric …,Proceedings of IIWAS; Linz; Austria,2001,8
Twig’n join: Progressive query processing of multiple xml streams,Wee Hyong Tok; Stéphane Bressan; Mong-Li Lee,Abstract We propose a practical approach to the progressive processing of (FWR) XQueryqueries on multiple XML streams; called Twig'n Join (or TnJ). The query is decomposed intoa query plan combining several twig queries on the individual streams; followed by a multi-way join and a final twig query. The processing is itself accordingly decomposed into threepipelined stages progressively producing streams of XML fragments. Twig'n Join combinesthe advantages of the recently proposed TwigM algorithm and our previous work onrelational result-rate based progressive joins. In addition; we introduce a novel dynamicprobing technique; called Result-Oriented Probing (ROP); which determines an optimalprobing sequence for the multi-way join. This significantly reduces the amount of redundantprobing for results. We comparatively evaluate the performance of Twig'n Join using both …,*,2008,7
A statistical approach for XML query size estimation,Mong Li Lee; Hanyu Li; Wynne Hsu; Beng Chin Ooi,Abstract The increasing number of XML repositories has intensified research activities in theoptimization of XML queries. The success of any optimization approach hinges on anaccurate query size estimation. This paper presents a statistical method for estimating theresult size of XML queries. Our estimation system extracts two summarized information;namely; node ratio and node factor; from every distinct parent-child path in the XML files.Experiment results indicate that our approach requires small memory footprint; and yetproves to be sufficient in estimating the result size of queries under the data-independentassumption.,*,2005,7
XML management system benchmarks,Stéphane Bressan; Mong Li Lee; Ying Guang Li; Zoé Lacroix; U Nambiar,*,XML Data Management: Native XML and XML-Enabled Database Systems; Addison Wesley; Reading; MA,2003,7
A Prolog implementation of an entity-relationship based database management system,Tok Wang Ling; Mong Li Lee,A three level schema architecture Entity-Relationship based database management systemwas proposed in [Ling871. In this paper; we describe the use of logic as a tool forimpbmenting the various ER database concepts. We describe and illustrate the approachthat we adopt to represent an ER database internally in Prolog. Our approach is based onnested relations. In particular; we consider the storage of multivalued attributes; weak entitytypes and relationship sets. Set operations are defined and conceptual-to-internal mappingrules to retrieve and update the database are automatically generated. We also present analgorithm to construct the external-to-conceptual mapping in Prolog rules given a user view.,*,1991,7
Prediction of Cerebral Aneurysm Rupture,Qiangfeng Peter Lau; Wynne Hsu; Mong Li Lee; Ying Mao; Liang Chen,Cerebral aneurysms are weak or thin spots on blood vessels in the brain that balloon out.While the majority of aneurysms do not burst; those that do would lead to seriouscomplications including hemorrhagic stroke; permanent nerve damage; or death. Yet;surgical options for treating cerebral aneurysms carry high risk to the patient. It is vital for thedoctors to accurately diagnose aneurysms that have high probabilities of rupturing. In thisapplication; the patient dataset has many attributes; ranging from patient profile to resultsfrom diagnostic test and features extracted from brain images. Many of the attributes arediscrete and have missing values. The dataset is also highly biased; with 15% unrupturecases and 85% rupture cases. Building a classifier that unerringly predicts the unrupture(rare) class is a challenge. In this paper; we describe a systematic approach to build such …,Tools with Artificial Intelligence; 2007. ICTAI 2007. 19th IEEE International Conference on,2007,6
SVM-based identification of microRNA precursors,LIANG HUAI Yang; Wynne Hsu; Mong Li Lee; LIMSOON Wong,*,Proceedings of 4th Asia-Pacific Bioinformatics Conference,2006,6
Enhancing SNNB with local accuracy estimation and ensemble techniques,Zhipeng Xie; Qing Zhang; Wynne Hsu; Mong Li Lee,Abstract Naïve Bayes; the simplest Bayesian classifier; has shown excellent performancegiven its unrealistic independence assumption. This paper studies the selectiveneighborhood-based naïve Bayes (SNNB) for lazy classification; and develops three variantalgorithms; SNNB-G; SNNB-L; and SNNB-LV; all with linear computational complexity. TheSNNB algorithms use local learning strategy for alleviating the independence assumption.The underlying idea is; for a test example; first to construct multiple classifiers on its multipleneighborhoods with different radius; and then to select out the classifier with the highestestimated accuracy to make decision. Empirical results show that both SNNB-L and SNNB-LV generate more accurate classifiers than naïve Bayes and several other state-of-the-artclassification algorithms including C4. 5; Naïve Bayes Tree; and Lazy Bayesian Rule. The …,Database Systems for Advanced Applications,2005,6
A semantic approach to query rewriting for integrated XML data,Xia Yang; Mong Lee; Tok Ling; Gillian Dobbie,Abstract Query rewriting is a fundamental task in query optimization and data integration.With the advent of the web; there has been renewed interest in data integration; where datais dispersed among many sources and an integrated view over these sources is provided.Queries on the integrated view are rewritten to query the underlying source repositories. Inthis paper; we develop a novel algorithm for rewriting queries that considers the XMLhierarchy structure and the semantic relationship between the source schemas and theintegrated schema. Our approach is based on the semantically rich Object-Relationship-Attribute model for SemiStructured data (ORA-SS); and guarantees that the rewritten queriesgive the expected results; even where the integrated view is complex.,Conceptual Modeling–ER 2005,2005,6
Scaling SDI systems via query clustering and aggregation,Xi Zhang; Liang Huai Yang; Mong Li Lee; Wynne Hsu,Abstract XML-based Selective Dissemination of Information (SDI) systems aims to quicklydeliver useful information to the users based on their profiles or user subscriptions. Thesesubscriptions are specified in the form of XML queries. This paper investigates howclustering and aggregation of user queries can help scale SDI systems by reducing thenumber of document-subscription matchings required. We design a new distance function tomeasure the similarity of query patterns; and develop a filtering technique called YFilter* thatis based on YFilter. Experiment results show that the proposed approach is able to achievehigh precision; high recall; while reducing runtime requirement.,*,2004,6
Mining Frequent Query Patterns in XML. 8th Int,LH Yang; ML Lee; W Hsu,*,Conference on Database Systems for Advanced Applications (DASFAA),2003,6
Advanced database technologies in a diabetic healthcare system,Wynne Hsu; Mong Li Lee; Beng Chin Ooi; Pranab Kumar Mohanty; Keng Lik Teo; Chenyi Xia,This chapter shows a practical system that employs advanced database technologies toachieve seamless integration; from capturing and indexing of the patient medical history andretina images; to the automatic computer analysis on the retinal fundus images of eachpatient; to determining the risk profile and subpopulation targeting of the patient database;thereby providing total care to all diabetic patients. With the increased emphasis on healthcare worldwide; the issue of being able to efficiently and effectively manage large amount ofpatient information in diverse media becomes critical. This system represents the future ofhealth care systems; where the aim is not just to manage patient data; but also to integrateand analyze the data so that it can deliver total care to the patients. With the increasedemphasis on health care worldwide; the issue of being able to efficiently and effectively …,Proceedings of the 28th international conference on Very Large Data Bases,2002,6
A knowledge-based framework for duplicates elimination,WL Low; ML Lee; TW Ling,*,Information Systems: Special Issue on Data Extraction; Cleaning and Reconciliation,2001,6
ERL: Logic for entity-relationship databases,John Grant; Tok Wang Ling; Mong Lee,Abstract We develop a logic for entity-relationship databases; ERL; that is a generalization ofdatabase logic. ERL provides advantages to the ER model much as FOL (first-order logic)does to the relational model: a uniform language for expressing database schema; integrityconstraints; and database manipulation; clearly defined semantics; the capability to expressdatabase transformations; and deductive capabilities. We propose three query languagesfor ER databases called ERRC; ERSQL; and ERQBE; which are generalizations of therelational calculus; SQL; and QBE; respectively. We use example queries and updates todemonstrate the capabilities of these languages. We apply database transformations tointroduce the notion of views and to show that both ERRC and ERSQL are relationallycomplete.,Journal of Intelligent Information Systems,1993,6
Towards An Interactive Keyword Search over Relational Databases,Zhong Zeng; Zhifeng Bao; Mong Li Lee; Tok Wang Ling,Abstract Keyword search over relational databases has been widely studied for theexploration of structured data in a user-friendly way. However; users typically have limiteddomain knowledge or are unable to precisely specify their search intention. Existingmethods find the minimal units that contain all the query keywords; and largely ignore theinterpretation of possible users' search intentions. As a result; users are often overwhelmedwith a lot of irrelevant answers. Moreover; without a visually pleasing way to present theanswers; users often have difficulty understanding the answers because of their complexstructures. Therefore; we design an interactive yet visually pleasing search paradigm calledExpressQ. ExpressQ extends the keyword query language to include keywords that matchmeta-data; eg; names of relations and attributes. These keywords are utilized to infer …,Proceedings of the 24th International Conference on World Wide Web Companion,2015,5
The Singapore Eye Vessel Assessment System,Qiangfeng Peter Lau; Mong Li Lee; Wynne Hsu; Tien Yin Wong,Images of the retina provide one of the few avenues to observe human microcirculation in anoninvasive manner. A variety of measurements have been proposed over the years1 toquantify multiple aspects of retinal vascular morphology. Many of these measures havebeen found through population studies to have good diagnostic capabilities for diseases ascardiovascular risk factors; 2–9 while other measures are actively being investigated in large-scale population studies. These population studies make use of computer-assistedsemiautomated systems to take measurements from retinal images. Such real-worldapplications use image-processing techniques to reduce the time taken for manual editing(grading) and limit human error; producing reliable results for large studies. After thediagnostic capabilities of particular measurements have been verified; the systems can …,Image Analysis and Modeling in Ophthalmology,2014,5
Twig’n join: Progressive query processing of multiple xml streams,Wee Hyong Tok; Stéphane Bressan; Mong-Li Lee,Abstract We propose a practical approach to the progressive processing of (FWR) XQueryqueries on multiple XML streams; called Twig'n Join (or TnJ). The query is decomposed intoa query plan combining several twig queries on the individual streams; followed by a multi-way join and a final twig query. The processing is itself accordingly decomposed into threepipelined stages progressively producing streams of XML fragments. Twig'n Join combinesthe advantages of the recently proposed TwigM algorithm and our previous work onrelational result-rate based progressive joins. In addition; we introduce a novel dynamicprobing technique; called Result-Oriented Probing (ROP); which determines an optimalprobing sequence for the multi-way join. This significantly reduces the amount of redundantprobing for results. We comparatively evaluate the performance of Twig'n Join using both …,*,2008,5
Mining progressive confident rules,Minghua Zhang; Wynne Hsu; Mong Li Lee,Abstract Many real world objects have states that change over time. By tracking the statesequences of these objects; we can study their behavior and take preventive measuresbefore they reach some undesirable states. In this paper; we propose a new kind of patterncalled progressive confident rules to describe sequences of states with an increasingconfidence that lead to a particular end state. We give a formal definition of progressiveconfident rules and their concise set. We devise pruning strategies to reduce the enormoussearch space. Experiment result shows that the proposed algorithm is efficient and scalable.We also demonstrate the application of progressive confident rules in classification.,Proceedings of the 12th ACM SIGKDD international conference on Knowledge discovery and data mining,2006,5
Improving data quality: eliminating dupes & ID-ing those spurious links,Mong Li Lee; Wynne Hsu,Dirty data arise as a result of abbreviations; data entry mistakes; duplicate records; missingfields and so forth. This problem is aggravated when multiple data sources need to beintegrated. Data cleaning refers to a series of processes employed to deal with detectingand removing errors and inconsistencies from data. Given the" garbage in; garbage out"principle; clean data is crucial for database integration; data warehousing and data mining.Data cleaning is a necessary step prior to the knowledge discovery process. We havereviewed a knowledge-based framework that provides for the definition of duplicateidentification rules. We have described a context-based approach to identify these spuriouslinks in the data.,Potentials; IEEE,2005,5
A histogram-based selectivity estimator for skewed XML data,Hanyu Li; Mong Lee; Wynne Hsu,Abstract The optimization of XML queries requires an accurate and compact structure tocapture the characteristics of the underlying data. A compact structure works well when thedata is uniformly distributed and has many common paths. However; more detailedinformation needs to be maintained when the data is skewed. This work presents ahistogram-based structure to capture the distribution of skewed XML data. It builds upon astatistical method to estimate the result size of XML queries. Experiment results indicate thatthe proposed method leads to a more accurate estimation.,Database and Expert Systems Applications,2005,5
Using Interval Association Rules to Identify Dubious Data Values,Ren Lu; Mong Li Lee; Wynne Hsu,Abstract A hard-to-catch erroneous data is one whose value looks perfectly legitimate. Yet; ifwe examine this value in conjunction with other attribute values; the value appearquestionable. Detecting such dubious values is a major problem in data cleaning. Thispaper presents a framework to automatically detect dubious data values in the datasets.Data is first pre-processed by data smoothing and mapping. Next; interval association rulesare generated which involved data partitioning via clustering before the rules are generatedusing an Apriori algorithm. Finally; these rules are used to identify data values that falloutside the expected intervals. Experiment results show that the proposed framework is ableto accurately and efficiently dubious values in large datasets.,Advances inWeb-Age Information Management,2004,5
Efficient mining of frequent query patterns for caching,LH Yang; ML Lee; W Hsu,*,Proc. Of 29th VLDB Conference,2003,5
A Knowledge-Based Framework for Intelligent Data Cleaning,Mong Li Lee; Tok Wang Ling; Wai Lup Low,*,Information Systems Journal-Special Issue on Data Extraction and Cleaning,2001,5
A theory for entity-relationship view updates,Tok Ling; Mong Lee,Abstract The traditional problem of updating relational databases through views is animportant practical problem that has attracted much interest. In this paper; we examine theproblem of view update in Entity-Relationship based database management systems [17]where the conceptual schema is represented by a normal form ER diagram [16] and viewsmay be modelled by ER diagrams. We develop a theory within the framework of the ERapproach that characterizes the conditions under which there exist mappings from viewupdates into conceptual schema updates. Concepts such as virtual updates and three typesof insertability are introduced.,Entity-Relationship Approach—ER'92,1992,5
Targeted Influence Maximization in Social Networks,Chonggang Song; Wynne Hsu; Mong Li Lee,*,*,*,5
Temporal Influence Blocking: Minimizing the Effect of Misinformation in Social Networks,Chonggang Song; Wynne Hsu; Mong Li Lee,The diffusion of rumors is a major concern for web users. Limiting the spread of rumor onsocial networks has become an important task. One approach is to identify nodes to start atruth campaign such that when users are aware of the truth; they would not believe orpropagate the rumor. However; existing works do not take into account the delays ofinformation diffusion or the time point beyond which propagation of misinformation is nolonger critical. In this paper; we consider a more realistic situation where information ispropagated with delays and the goal is to reduce the number of rumor-infected users beforea deadline. We call this the Temporal Influence Blocking (TIB) problem. We propose a two-phase solution called TIB-Solver to select k nodes to start a truth campaign such that thenumber of users reached by a rumor is minimized. Experiments show that the proposed …,Data Engineering (ICDE); 2017 IEEE 33rd International Conference on,2017,4
Answering keyword queries involving aggregates and groupby on relational databases,Zhong Zeng; Mong Li Lee; Tok Wang Ling,Keyword search over relational databases has gained popularity as it provides a user-friendly way to explore structured data. Current research has focused on the computation ofminimal units that contain all the query keywords; and largely ignores queries to retrievestatistical information from the database. The latter involves aggregate functions and group-bys; and are called aggregate queries. In this work; we propose a semantic approach toanswer keyword queries containing aggregates and group-bys. Our approach utilizes theORM schema graph to capture the semantics of objects and relationships in the database;and determines the various interpretations of a query. Based on each interpretation; wegenerate an SQL statement to apply aggregates and group-bys. Further; we detectduplications of objects and relationships arising from denormalized relations so that the …,*,2016,4
Similar subsequence search in time series databases,Shrikant Kashyap; Mong Li Lee; Wynne Hsu,Abstract Finding matching subsequences in time series data is an important problem. Theclassical approach to search for matching subsequences has been on the principle ofexhaustive search; where all possible candidates are generated and evaluated or all theterms of the time series in a data base are examined. As a result most of the subsequencesearch algorithms are cubic in nature with few algorithms of quadratic nature. Someapproximate algorithms have been proposed; as a result; to speed up the search formatching subsequences. In this work; we propose a fast and efficient exact subsequencesearch algorithm which is sub-quadratic in nature. We introduce the notion of eHaar(envelope Haar) to prune parts of the time series data which will not contain subsequencesthat can match the query subsequence. This pruning phase dramatically reduces the …,*,2011,4
Mining mutation chains in biological sequences,Chang Sheng; Wynne Hsu; Mong Li Lee; Joo Chuan Tong; See-Kiong Ng,The increasing infectious disease outbreaks has led to a need for new research to betterunderstand the disease's origins; epidemiological features and pathogenicity caused by fast-mutating; fast-spreading viruses. Traditional sequence analysis methods do not take intoaccount the spatio-temporal dynamics of rapidly evolving and spreading viral species. Theyare also focused on identifying single-point mutations. In this paper; we propose a novelapproach that incorporates space-time relationships for studying changes in proteinsequences from fast mutating viruses. We aim to detect both single-point mutations as wellas k-mutations in the viral sequences. We define the problem of mutation chain patternmining and design algorithms to discover valid mutation chains. Compact data structures tofacilitate the mining process as well as pruning strategies to increase the scalability of the …,Data Engineering (ICDE); 2010 IEEE 26th International Conference on,2010,4
Farm: Feature-assisted aggregate route mining in trajectory data,Shrikant Kashyap; Sujoy Roy; Mong Li Lee; Wynne Hsu,An aggregate route of a set of trajectories is the representative movement direction of theset. Existing solutions address the problem of finding representative routes by findingclusters in the data with minimum intra-cluster deviation and then deriving a simplifiedtrajectory to represent each cluster. However; existing similarity measures for trajectories arenot discriminative and are sensitive to noise. This paper presents FARM; a framework forextracting aggregate routes from trajectory data. FARM first transforms the trajectories into afeature space. Next; it applies spectral clustering to find clusters in the feature space. Finally;we find a representative route for each cluster obtained. Experimental studies demonstratethe effectiveness of the proposed method.,Data Mining Workshops; 2009. ICDMW'09. IEEE International Conference on,2009,4
Deepdetect: An extensible system for detecting attribute outliers & duplicates in XML,Qiangfeng Peter Lau; Wynne Hsu; Judice LY Koh; Mong Li Lee,Abstract XML; the eXtensible Markup Language; is fast evolving into the new standard fordata representation and exchange on the WWW. This has resulted in a growing number ofdata cleaning techniques to locate" dirty" data (artifacts). In this paper; we presentDEEPDETECT–an extensible system that detects attribute outliers and duplicates in XMLdocuments. Attribute outlier detection finds objects that contain deviating values with respectto a relevant group of objects. This entails utilizing the correlation among element values ina given XML document. Duplicate detection in XML requires the identification of subtreesthat correspond to real world objects. Our system architecture enables sharing of commonoperations that prepare XML data for the various artifact detection techniques.DEEPDETECT also provides an intuitive visual interface for the user to specify various …,Data Quality and High-Dimensional Data Analysis: Proceedings of the DASFAA 2008 Workshops,2008,4
Finding Orientation-Sensitive Patterns in Snapshot Databases,Minghua Zhang; Wynne Hsu; Mong Li Lee,Snapshot data have become ubiquitous; eg; maps; images and videos. By extractinginteresting features from snapshot data and analyzing their relative orientations andproximities; we can discover important structure configuration information among groups offeatures in a snapshot database. In this paper; we introduce a class of pattern calledorientation-sensitive patterns; which occur in many applications ranging from weather study;sport game analysis to medical image processing. We examine three approaches todiscover orientation-sensitive patterns. We show that the first apriori-based approach isexpensive while the second enumeration-based approach is memory intensive. The thirdapproach decomposes an orientation-sensitive pattern into an H-list and a V-list; whichgreatly simplifies the mining process. Extensive experiment studies show that the third …,Tools with Artificial Intelligence; 2007. ICTAI 2007. 19th IEEE International Conference on,2007,4
Progressive High-Dimensional Similarity Join,Wee Tok; Stéphane Bressan; Mong-Li Lee,Abstract The Rate-Based Progressive Join (RPJ) is a non-blocking relational equijoinalgorithm. It is an equijoin that can deliver results progressively. In this paper; we firstpresent a naive extension; called neRPJ; to the progressive computation of the similarity joinof high-dimensional data. We argue that this naive extension is not suitable. We thereforepropose an adequate solution in the form of a Result-Rate Progressive Join (RRPJ) for high-dimensional distance similarity joins. Using both synthetic and real-life datasets; weempirically show that RRPJ is effective and efficient; and outperforms the naive extension.,Database and Expert Systems Applications,2007,4
Mining wafer fabrication: framework and challenges,Jemmy Soenjaya; Wynne Hsu; Mong Li Lee; Tachyang Lee,The increasing market expansion of electronic devices such as handphones; computers;and television sets has provided the impetus for development of high-tech industry. Waferfabrication; or the process of producing an integrated circuit on semiconductor materials;plays an important role in manufacturing the fundamental components of electronic devices.Manufacturing is typically a controlled process; where the process flow is carefully andsystematically designed. However; random events and subtle changes in environment mightcause failures. As with many other manufacturing processes; wafer fabrication often facesfluctuation in products' quality. In order to detect possible failures; various sensors monitorthe process history and record intermediate quality measurements of the productionprocess. The data collected aim to provide insight of the production process; to improve …,Next Generation of Data-Mining Application; John Wiley & Sons; New York,2005,4
On the Detection of Retinal Vessels in Fundus Images,Bin Fang; Wynne Hsu; Mong Li Lee,Ocular fundus image can provide information on pathological changes caused by localocular diseases and early signs of certain systemic diseases. Automated analysis andinterpretation of fundus images has become a necessary and important diagnosticprocedure in ophthalmology. Among the features in ocular fundus image are the optic disc;fovea (central vision area); lesions; and retinal vessels. These features are useful inrevealing the states of diseases in the form of measurable abnormalities such as length ofdiameter; change in color; and degree of tortuosity in the vessels. In addition; retinal vesselscan also serve as landmarks for image-guided laser treatment of choroidalneovascularization. Thus; reliable methods for blood vessel detection that preserve variousvessel measurements are needed. In this paper; we will examine the pathological issues …,*,2003,4
Development and validation of a deep learning system for diabetic retinopathy and related eye diseases using retinal images from multiethnic populations with diab...,Daniel Shu Wei Ting; Carol Yim-Lui Cheung; Gilbert Lim; Gavin Siew Wei Tan; Nguyen D Quang; Alfred Gan; Haslina Hamzah; Renata Garcia-Franco; Ian Yew San Yeo; Shu Yen Lee; Edmund Yick Mun Wong; Charumathi Sabanayagam; Mani Baskaran; Farah Ibrahim; Ngiap Chuan Tan; Eric A Finkelstein; Ecosse L Lamoureux; Ian Y Wong; Neil M Bressler; Sobha Sivaprasad; Rohit Varma; Jost B Jonas; Ming Guang He; Ching-Yu Cheng; Gemmy Chui Ming Cheung; Tin Aung; Wynne Hsu; Mong Li Lee; Tien Yin Wong,Importance A deep learning system (DLS) is a machine learning technology with potentialfor screening diabetic retinopathy and related eye diseases. Objective To evaluate theperformance of a DLS in detecting referable diabetic retinopathy; vision-threatening diabeticretinopathy; possible glaucoma; and age-related macular degeneration (AMD) in communityand clinic-based multiethnic populations with diabetes. Design; Setting; and ParticipantsDiagnostic performance of a DLS for diabetic retinopathy and related eye diseases wasevaluated using 494 661 retinal images. A DLS was trained for detecting diabeticretinopathy (using 76 370 images); possible glaucoma (125 189 images); and AMD (72 610images); and performance of DLS was evaluated for detecting diabetic retinopathy (using112 648 images); possible glaucoma (71 896 images); and AMD (35 948 images) …,Jama,2017,3
An Incremental Feature Extraction Framework for Referable Diabetic Retinopathy Detection,Jay Nandy; Wynne Hsu; Mong Li Lee,Diabetic retinopathy (DR) might be characterized by the occurrence of lesions in the retinalimage. Existing approaches require a large set of retinal images where lesions in the imageare individually annotated to learn a model that will classify an image as referable or non-referable DR. However; annotating individual lesions is a tedious task and the accuracy ofthe learnt model is limited by the availability of these annotated images. In this paper; we firstlearn a universal Gaussian mixture model (GMM) from a small set of annotated images. Thisuniversal GMM is then applied as the prior belief to learn an adaptive GMM for individualimages. The proposed approach aims to capture the characteristics of referable versus non-referable images by examining the difference between the universal GMM and the adaptiveGMM. An image-level classifier is then built based on these differences as features …,Tools with Artificial Intelligence (ICTAI); 2016 IEEE 28th International Conference on,2016,3
ORA-semantics based keyword search in XML and relational databases,Tok Wang Ling; Zhong Zeng; Thuy Ngoc Le; Mong Li Lee,Keyword search in XML and relational databases (RDB) has gained popularity as it providesa user-friendly way to explore structured data. Existing works on XML and RDB keywordsearch only rely on the structures of XML/RDB data and/or schemas; and this causes seriousproblems of returning incomplete answers; meaningless answers and overwhelminganswers. In this paper; we identify the problems of existing keyword search methods andpoint out that the main reason of these problems is due to the unawareness of the Object-Relationship-Attribute (ORA) semantics in XML/RDB. We exploit the ORA semantics in XMLand RDB; and capture these semantics by constructing the Object tree for XML; and theObject-Relationship-Mixed (ORM) data graph for RDB; respectively. Based on the Objecttree and the ORM data graph; we propose an ORA-Semantics based keyword search in …,2016 IEEE 32nd International Conference on Data Engineering Workshops (ICDEW),2016,3
Mining Brokers in Dynamic Social Networks,Chonggang Song; Wynne Hsu; Mong Li Lee,Abstract The theory of brokerage in sociology suggests if contacts between two parties areenabled through a third party; the latter occupies a strategic position of controllinginformation flows. Such individuals are called brokers and they play a key role indisseminating information. However; there is no systematic approach to identify brokers inonline social networks. In this paper; we formally define the problem of detecting top-$ k $brokers given a social network and show that it is NP-hard. We develop a heuristic algorithmto find these brokers based on the weak tie theory. In order to handle the dynamic nature ofonline social networks; we design incremental algorithms: WeakTie-Local for unidirectionalnetworks and WeakTie-Bi for bidirectional networks. We use two real world datasets; DBLPand Twitter; to evaluate the proposed methods. We also demonstrate how the detected …,Proceedings of the 24th ACM International on Conference on Information and Knowledge Management,2015,3
Distributed relational temporal difference learning,Qiangfeng Peter Lau; Mong Li Lee; Wynne Hsu,Abstract Relational representations have great potential for rapidly generalizing learnedknowledge in large Markov decision processes such as multi-agent problems. In this work;we introduce relational temporal difference learning for the distributed case where thecommunication links among agents are dynamic. Thus no critical components of the systemshould reside in any one agent. Relational generalization among agents' learning isachieved through the use of partially bound relational features and a message passingscheme. We further describe how the proposed concepts can be applied to distributedreinforcement learning methods that use value functions. Experiments were conducted onsoccer and real-time strategy game domains with dynamic communication. Results showthat our methods improve goal achievement in online learning with a greatly decreased …,Proceedings of the 2013 international conference on Autonomous agents and multi-agent systems,2013,3
Utilizing users' tipping points in E-commerce Recommender systems,Kailun Hu; Wynne Hsu; Mong Li Lee,Existing recommendation algorithms assume that users make their purchase decisionssolely based on individual preferences; without regard to the type of users nor the products'maturity stages. Yet; extensive studies have shown that there are two types of users:innovators and imitators. Innovators tend to make purchase decisions based solely on theirown preferences; whereas imitators' purchase decisions are often influenced by a product'sstage of maturity. In this paper; we propose a framework that seamlessly incorporates thetype of user and product maturity into existing recommendation algorithms. We apply Bassmodel to classify each user as either an innovator or imitator according to his/her previouspurchase behavior. In addition; we introduce the concept of tipping point of a user. Thistipping point refers to the point on the product maturity curve beyond which the user is …,Data Engineering (ICDE); 2013 IEEE 29th International Conference on,2013,3
Constrained-MSER detection of retinal pathology,Gilbert Lim Yong San; Mong Li Lee; Wynne Hsu,With the increase in age and diabetes-related eye diseases; there is a rising demand forsystems which can efficiently screen and locate abnormalities in retinal images. In thispaper; we propose a framework that utilizes a variant of the Maximally Stable ExtremalRegion method; termed C-MSER; to systematically detect various retinopathy pathologiessuch as microaneurysms; haemorrhages; hard exudates and soft exudates. Experiments onthree real-world datasets show that C-MSER is effective for online screening of diabeticretinopathy.,Pattern Recognition (ICPR); 2012 21st International Conference on,2012,3
Analyzing Abnormal Events from Spatio-Temporal Trajectories,Dhaval Patel; Chidansh Bhatt; Wynne Hsu; Mong Li Lee; Mohan Kankanhalli,Advances in RFID based sensor technologies has been used in applications which requiresthe tracking of assets; products and individuals. The recording of such movements iscaptured in a trajectory database and can be analyzed for the monitoring of abnormalevents. In this paper; we describe a system called InViTA for analyzing abnormal eventsfrom spatio-temporal trajectories captured during an office evacuation after an explosion.InViTA utilizes a trajectory representation scheme and extract the features to derive a set ofrules that label each person's trajectory as belonging to a suspect; witness; or victim; etc. Werun the system on the office evacuation data provided in VAST 2008 challenge and obtaincomparable results with that obtained from visualization and human analysis. The systemincludes a user-friendly graphical interface for parameter tuning and intuitive result …,Data Mining Workshops; 2009. ICDMW'09. IEEE International Conference on,2009,3
Mining in Spatiotemporal Databases.,Junmei Wang; Wynne Hsu; Mong-Li Lee,Abstract Recent interest in spatio-temporal applications has been fueled by the need todiscover and predict complex patterns that occur when we observe the behavior of objects inthe three-dimensional space of time and spatial coordinates. Although the complex andintrinsic relationships among the spatio-temporal data limit the usefulness of conventionaldata mining techniques to discover the patterns in the spatio-temporal databases; they alsolead to opportunities for mining new classes of patterns in spatiotemporal databases. Thischapter provides a survey of the work done for mining patterns in spatial databases andtemporal databases; and the preliminary work for mining patterns in spatio-temporaldatabases. We highlight the unique challenges of mining interesting patterns inspatiotemporal databases. We also describe two special types of spatio-temporal patterns …,*,2005,3
Approximate counting of frequent query patterns over XQuery stream,Liang Huai Yang; Mong Li Lee; Wynne Hsu,Abstract One efficient approach to improve the performance of XML management systems isto cache the frequently retrieved results. This entails the discovery of frequent query patternsthat are issued by users. In this paper; we model user queries as a stream of XML querypattern trees and mine for frequent query patterns in a batch-wise manner. We design anovel data structure called D-GQPT to merge the pattern trees of the batches seen so far;and to dynamically mark the active portion of the current batch. With the D-GQPT; we areable to limit the enumeration of candidate trees to only the currently active pattern trees. Wealso design a summary data structure called ECTree to incrementally compute the frequenttree patterns over the query stream. Based on the above two constructs; we present thefrequent query pattern mining algorithm called AppXQSMiner over the XML query stream …,*,2004,3
Automatic generation of SQLX view definitions from ORA-SS views,Ya Chen; Tok Ling; Mong Lee,Abstract Although XML is the dominant standard for publishing and exchanging data forInternet-based business applications; data is typically stored in relational or object-relationaldatabases. Thus; it is necessary to define XML views over these traditional databases.Unfortunately; it is not easy for users to manually write SQLX queries to define the XMLviews. This paper describes a method to automatically generate SQLX view definitions fromobject-relational databases. We utilize the semantically rich ORA-SS data model to capturethe schematic structure and semantics of the underlying data. Valid ORA-SS views are firstdesigned on the ORA-SS schema; before they are mapped to XML views. The generatedview definitions are SQL queries with XML extension (SQLX) that can be directly evaluatedon object-relational databases to materialize the views. This approach removes the need …,Database Systems for Advanced Applications,2004,3
Profiling Entities over Time in the Presence of Unreliable Sources,Furong Li; Mong Li Lee; Wynne Hsu,To harness the rich amount of information available on the web today; many organizationsaggregate public (and private) data to derive knowledge repositories for real-world entities.This paper aims to build historical profiles of real-world entities by integrating temporalrecords collected from different sources. This problem is challenging not only becauseentities may change their attribute values over time; but also because information providedby the sources could be unreliable. In this paper; we present a new solution for profilingentities over time. To understand the evolution of entities; we describe a novel transitionmodel which gives the probability that an entity will change to a particular attribute valueafter some time period. Next; a set of quality metrics are defined for the data sources tocapture the exactness and timeliness of their provided values. The transition model and …,IEEE Transactions on Knowledge and Data Engineering,2017,2
k-Consistent Influencers in Network Data,Enliang Xu; Wynne Hsu; Mong Li Lee; Dhaval Patel,Abstract With the prevalence of online social media such as Facebook; Twitter andYouTube; social influence analysis has attracted considerable research interests recently.Existing works on top-k influential nodes discovery find influential users at single time pointonly and do not capture whether the users are consistently influential over a period of time.Finding top-k consistent influencers has many interesting applications; such as targetedmarketing; recommendation; experts finding; and stock market. Identifying top-k consistentinfluencers is a challenging task. First; we need to dynamically compute the total influence ofeach user at each time point from an action log. However; to find the consistent top-scorers;we need to sort and rank them at each time point. This is computationally expensive and notscalable. In this paper; we define the consistency of a node based on its influence and …,*,2015,2
Incremental Mining of Top-k Maximal Influential Paths in Network Data,Enliang Xu; Wynne Hsu; Mong Li Lee; Dhaval Patel,Abstract Information diffusion refers to the spread of abstract ideas and concepts; technicalinformation; and actual practices within a social system; where the spread denotes flow ormovement from a source to an adopter; typically via communication and influence.Discovering influence relations among users has important applications in viral marketing;personalized recommendations and feed ranking in social networks. Existing works oninformation diffusion analysis have focused on discovering “influential users” and “whoinfluences whom” relationships using data obtained from social networks. However; they donot consider the continuity of influence among users. In this paper; we develop a method forinferring top-k maximal influential paths which can capture the continuity of influence. Wedefine a generative influence propagation model based on the Independent Cascade …,*,2013,2
Detecting Aggregate Incongruities in XML,Wynne Hsu; Qiangfeng Lau; Mong Lee,Abstract The problem of identifying deviating patterns in XML repositories has importantapplications in data cleaning; fraud detection; and stock market analysis. Current methodsdetermine data discrepancies by assessing whether the data conforms to the expecteddistribution of its immediate neighborhood. This approach may miss interesting deviationsinvolving aggregated information. For example; the average number of transactions of aparticular bank account may be exceptionally high as compared to other accounts withsimilar profiles. Such incongruity could only be revealed through aggregating appropriatedata and analyzing the aggregated results in the associated neighborhood. Thisneighborhood is implicitly encapsulated in the XML structure. In addition; the hierarchicalnature of the XML structure reflects the different levels of abstractions in the real world …,Database Systems for Advanced Applications,2009,2
Mining prevalence-based ratio patterns,Minghua Zhang; Wynne Hsu; Mong Li Lee,Association rule mining aims to discover sets of features that occur together. A variation ofassociation rule mining is ratio rule mining. A ratio rule is an eigenvector of the database thatdescribes ratios of features. However; ratio rules are sensitive to outliers. In this work; wedesign a prevalence-based model for mining ratio patterns from a database. Our model ismore robust to noises; and ratio patterns in our model have clear statistic meanings. Wedevelop an algorithm to quickly determine the sets of features and their ratios that satisfy theprevalence requirement. Data structures; such as hash table and hash tree are utilized tofurther improve the efficiency of the algorithm. Experiments on synthetic data indicates theefficiency and scalability of the proposed algorithm. We also present a case study on UScensus data.,Tools with Artificial Intelligence; 2007. ICTAI 2007. 19th IEEE International Conference on,2007,2
Rewriting Queries for XML Integration Systems,Ling Li; Mong Lee; Wynne Hsu,Abstract A data integration system typically creates a target XML schema to represent anapplication domain and source schemas are mapped to the target schema. A user poses aquery over the target schema; and the system rewrites the query into a set of queries overthe data sources. Existing algorithms generate a set of static rules based on the targetschema and mappings; and rewrite the target query using these rules. We design a flexibleand dynamic approach that rewrites XML queries directly based on the mappings betweenthe target and source schemas. Theoretical analysis and experiments on both synthetic andreal-world datasets indicate that the proposed approach is efficient and scalable.,Database and Expert Systems Applications,2006,2
Generalization of classification rules,Zhipeng Xie; Wynne Hsu; Mong Li Lee,Traditional classification rules are in the form of production rules. Recent works in hybridclassification algorithms have proposed the generation of contextual rules; whereby the right-hand side of the production rule is replaced by a classifier; to achieve higher accuracy. Inthis work; we present a framework to further generalize classification rules such that the left-hand side of a production rule is expressed as a conjunction of classifiers; called spacesplitters. An intelligent divide-and-conquer approach is designed to construct suchgeneralized classification rules. The construction algorithm; GCTree; is elegant; efficient andscalable. The resulting classifier is able to achieve high predictive accuracy that outperformsnaive Bayes and C4. 5. Experiments demonstrate that GCTree is compact and stable.,Tools with Artificial Intelligence; 2003. Proceedings. 15th IEEE International Conference on,2003,2
PowerQ: An Interactive Keyword Search Engine for Aggregate Queries on Relational Databases,Zhong Zeng; Mong Li Lee; Tok Wang Ling,*,*,*,2
Semantic path ranking scheme for relational keyword queries,Zhong Zeng; Zhifeng Bao; Gillian Dobbie; Mong Li Lee; Tok Wang Ling,*,25th International Conference on Database and Expert Systems,*,2
Quantifying Aspect Bias in Ordinal Ratings using a Bayesian Approach,Lahari Poddar; Wynne Hsu; Mong Li Lee,Abstract: Opinion of users expressed in the form of observed ratings can influence anindividual's view of an item. However; the true quality of an item is often obfuscated by userbiases; and it is not obvious from the observed ratings the importance users place ondifferent aspects of an item. In this paper; we propose a probabilistic modeling of theobserved aspect ratings to infer (i) each user's aspect bias and (ii) latent intrinsic quality ofan item. We model multi-aspect ratings as ordered discrete data and encode thedependency between different aspects by using a latent Gaussian structure. We handle theGaussian-Categorical non-conjugacy using a stick-breaking formulation coupled withrecently developed Polya-Gamma auxiliary variable augmentation for a simple; fullyBayesian inference. On two real world datasets; we demonstrate the predictive ability of …,arXiv preprint arXiv:1705.05098,2017,1
Author-aware Aspect Topic Sentiment Model to Retrieve Supporting Opinions from Reviews,Lahari Poddar; Wynne Hsu; Mong Li Lee,Abstract User generated content about products and services in the form of reviews are oftendiverse and even contradictory. This makes it difficult for users to know if an opinion in areview is prevalent or biased. We study the problem of searching for supporting opinions inthe context of reviews. We propose a framework called SURF; that first identifies opinionsexpressed in a review; and then finds similar opinions from other reviews. We design anovel probabilistic graphical model that captures opinions as a combination of aspect; topicand sentiment dimensions; takes into account the preferences of individual authors; as wellas the quality of the entity under review; and encodes the flow of thoughts in a review byconstraining the aspect distribution dynamically among successive review segments. Wederive a similarity measure that considers both lexical and semantic similarity to find …,Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing,2017,1
Comparison of Common Retinal Vessel Caliber Measurement Software and a Conversion Algorithm,WanFen Yip; Yih Chung Tham; Wynne Hsu; Mong Li Lee; Ronald Klein; Barbara Klein; Mohammad Kamran Ikram; Tien Yin Wong; Carol Yim-lui Cheung,Purpose: To compare three commonly used retinal vessel caliber measurement softwaresystems; and propose an algorithm for conversion between measurement systems.Methods: We used 120 retinal photographs to evaluate the agreement between threecommonly used software (Retinal Analysis [RA]; Integrative Vessel Analysis [IVAN]; andSingapore I Vessel Assessment [SIVA]). Bland-Altman plots were used to evaluateagreement of retinal arteriolar (central retinal artery equivalent; CRAE) and venular (centralretinal vein equivalent; CRVE) calibers. Pearson's correlation was used to assess theassociations between systemic factors and retinal vessel calibers; and Z-test was used tocompare the strength of the correlation coefficients across the three software systems. Analgorithm was created to convert measurements; with paired t-test performed to evaluate …,Translational Vision Science & Technology,2016,1
ClaimFinder: A Framework for Identifying Claims in Microblogs,Wee Yong Lim; Mong Li Lee; Wynne Hsu,ABSTRACT Twitter is a microblogging platform that allows users to post public shortmessages. Posts shared by users pertaining to real-world events or themes can provide arich “on-theground” live update of the events for the benefit of everyone. Unfortunately; theposted information may not be all credible and rumours can spread over this platform.Existing credibility assessment work have focused on identifying features for discriminatingthe credibility of messages at the tweet level. However; they do not handle tweets thatcontain multiple pieces of information; each of which may have different level of credibility. Inthis work; we introduce the notion of a claim based on subject and predicate terms; andpropose a framework to identify claims from a corpus of tweets related to some major eventor theme. Specifically; we draw upon work done in open information extraction to extract …,*,2016,1
Cloud-based Imaging Program for Diabetic Retinopathy Screening and Monitoring,Pok Chien Tan; Carol YL Cheung; Ecosse Lamoureux; Wynne Hsu; Mong Li Lee; Tien Yin Wong,Purpose We tested the performance of a cloud-based automated imaging program fordiabetic retinopathy (DR) screening and monitoring as used in a Singapore screeningprogram; with the aim to reduce the workload of the trained graders for DR screening inreading centre. Methods The Singapore Integrated Diabetic Retinopathy ScreeningProgramme (SiDRP) is a tele-medicine screening program for DR based on assessment ofretinal images of patients with diabetes seen at the primary care setting. Currently; theassessment is based on a standardized assessment of DR presence and severity by trainednon-ophthalmologists assessors (graders). To improve the efficiency of the SiDRPscreening; we developed and machine-trained a prototype imaging software (SELENA);which is a cloud-based tele-medicine platform that processes digital retinal images based …,Investigative Ophthalmology & Visual Science,2015,1
LinkNet: capturing temporal dependencies among spatial regions,Dhaval Patel; Wynne Hsu; Mong Li Lee,Abstract Many applications require understanding how event occurrences at onegeographical region affect or influence event occurrences at another region; eg spread ofdisease and forest fires. Existing works typically impose a grid to partition the spatial spaceand utilize spatial autocorrelation property to model the spatial dependency among the gridcells. However; they are often highly sensitive to the granularity of the grid size and they donot incorporate the temporal dynamics of the event occurrences among regions. This paperutilizes the notion of a spatial network with temporal dependency to capture the dynamics ofevent occurrences among regions. This network is modeled as a directed graph where eachnode is a group of spatially nearby events and each directed edge represents the influenceof events from a source node to a destination node. We design an algorithm called …,Distributed and Parallel Databases,2014,1
Are Computer-assisted programs for measuring Retinal Vascular Caliber Interchangeable?,WanFen Yip; Carol Yim-lui Cheung; Haslina Hamzah; Claire Han; Wynne Hsu; Mong Li Lee; Tien Yin Wong,Purpose:: Changes in retinal vascular caliber reflect early microvascular pathology and maypredict ocular and systemic vascular diseases. We compared retinal vascular calibermeasurements between two commonly used software: the Singapore I Vessel Assessment(SIVA) and Interactive Vessel Analysis (IVAN). Methods:: Retinal photographs from theSingapore Chinese Eye Study (SCES); a population-based survey of persons aged 40 to 80years; were used for this study. A subset of 200 retinal photographs was randomly selected.Retinal arteriolar caliber and venular caliber; summarized as central retinal arteriolarequivalent (CRAE) and central retinal venular equivalent (CRVE); were measured within astandard zone (from 0.5 to 1.0 disc diameter) by trained graders using both the SIVA(National University of Singapore; version 3.0) and IVAN (University of Wisconsin …,Investigative Ophtalmology and Visual Science,2012,1
Top-k Maximal Influential Paths in Network Data,Enliang Xu; Wynne Hsu; Mong Li Lee; Dhaval Patel,Abstract Information diffusion is a fundamental process taking place in networks. It is oftenpossible to observe when nodes get influenced; but it is hard to directly observe theunderlying network. Furthermore; in many applications; the underlying networks are implicitor even unknown. Existing works on network inference can only infer influential edgesbetween two nodes. In this paper; we develop a method for inferring top-k maximalinfluential paths which can capture the dynamics of information diffusion better compared toinfluential edges. We define a generative influence propagation model based on theIndependent Cascade Model and Linear Threshold Model; which mathematically model thespread of certain information through a network. We formalize the top-k maximal influentialpath inference problem and develop an efficient algorithm; called TIP; to infer the top-k …,*,2012,1
Correlation Between Right and Left Eyes in the Measurement of Retinal Vascular Fractal Dimension in an Older Population,V Cosatto; A Wainwright; E Rochtchina; YP Zhang; G Liew; W Hsu; ML Lee; P Mitchell; TY Wong; JJ Wang,Purpose:: Retinal vessel fractal dimension (D f) is a global measure of density in the retinalvasculature. Recent research suggests that this measurement may indicate subtle retinalmicrovascular changes associated with different ocular and systemic conditions. Weassessed the correlation between D f measurements of the left and right eyes of the sameperson; using Blue Mountains Eye Study (BMES) data. Methods:: A random subsample of300 participants (600 eyes) was selected from the baseline BMES survey (1992-4). IRIS-Fractal (version 1.4) was used to measure D f; by outlining a skeletonised line tracing of theretinal vascular network from the original digitised image. Intraclass correlation coefficients(ICC) were used to assess intergrader reproducibility between graders on 300 right eyeimages. The mean D f of right and left eyes was compared using Student's paired t-test …,Investigative Ophthalmology & Visual Science,2009,1
A Prüfer Based Approach to Process Top-k Queries in XML,Ling Li; Mong Lee; Wynne Hsu; Han Zhen,Abstract Top-k queries in XML involves retrieving approximate matching XML documents.Existing techniques process top-k queries in XML by applying one or more relaxations onthe twig query. In this work; we investigate how Prüfer sequence can be utilized to processtop-k queries in XML. We design a method called XPRAM that incorporates the relaxationsinto the sequence matching process. Experiment results indicate that the proposedapproach is efficient and scalable.,Database and Expert Systems Applications,2009,1
Discovering Trends and Relationships among Rules,Chaohai Chen; Wynne Hsu; Mong Lee,Abstract Data repositories are constantly evolving and techniques are needed to reveal thedynamic behaviors in the data that might be useful to the user. Existing temporal associationrules mining algorithms consider time as another dimension and do not describe thebehavior of rules over time. In this work; we introduce the notion of trend fragment to facilitatethe analysis of relationships among rules. Two algorithms are proposed to find therelationships among rules. Experiment results on both synthetic and real-world datasetsindicate that our approach is scalable and effective.,Database and Expert Systems Applications,2009,1
Entity‐Relationship Model,Tok Wang Ling; Mong Li Lee,Abstract Data modeling is an important phase in the development of a database system. TheEntity-Relationship (ER) model was introduced by Peter Chen in 1977. This model has beenwidely used for conceptual data modeling and has become a tool for communicationbetween database designers and end users at the analysis phase of databasedevelopment. This article presents the main constructs of the ER model; namely; entities andrelationships and their associated attributes; as well as some of its extensions. We alsodiscuss how conceptual database design can be carried out using the ER model; the normalform ER diagram and the translation of ER diagrams to the relational model.,Wiley Encyclopedia of Computer Science and Engineering,2008,1
Database Systems for Advanced Applications: 11th International Conference; DASFAA 2006; Singapore; April 12-15; 2006; Proceedings,Mong Li Lee; Kian Lee Tan; Vilas Wuwongse,This book constitutes the refereed proceedings of the 11th International Conference onDatabase Systems for Advanced Applications; DASFAA 2006; held in Singapore in April2006. 46 revised full papers and 16 revised short papers presented were carefully reviewedand selected from 188 submissions. Topics include sensor networks; subsequencematching and repeating patterns; spatial-temporal databases; data mining; XMLcompression and indexing; xpath query evaluation; uncertainty and streams; peer-to-peerand distributed networks and more.,*,2006,1
Normalization,Tok Wang Ling; Mong Li Lee; Gillian Dobbie,Example 5.1 Consider the XML document in Figure 5.1 that contains information aboutcourses in a department and the students who take the courses. In this document; there aretwo courses (with code CS1102 and CS2104) and two students (with stuNo stu123 andstu125). The details of the students; such as stuName; address and hobby; are repeated foreach course the student takes. This duplication of information causes a number of problems.For example; if a student changes their address; it must be updated everywhere the addressis stored; that is it must be updated in every course the student takes. If a new course isinserted and student stu125 enrolls in that course then the details of,Semistructured Database Design,2005,1
BioWare: A framework for bioinformatics data retrieval; annotation and publishing,Judice LY Koh; SPT Krishnan; SH Seah; PT Tan; A Khan; ML Lee; V Brusic,ABSTRACT In-depth analysis about a specific subject in molecular biology; specificallythose associated with the structural and functional properties of a particular group ofsequences typically requires access to an extensive knowledge base. The knowledge basemay take the form of a specialist database or subject-specific data warehouse (SSDW) tofacilitate the organisation of specialized data and the extraction of new knowledge. TheseSSDWs are particularly useful for data mining or knowledge discovery processes whichrequire the relevant information from multiple data sources. The construction of a specialistdatabase is a multistep process which typically involves enrichment of annotations (bydomain experts); development and integration of analytical tools (by computerprogrammers); and construction of the system (by database experts). The SSDWs contain …,Search and Discovery in Bioinformatics,2004,1
Discovering geographical features for location-based services,Junmei Wang; Wynne Hsu; Mong Li Lee,Abstract In applications such as location-based services; development planning and areamarketing; the knowledge of frequent service requests that are always issued together isuseful for decision and policy making. However; knowing merely the frequently co-locatedservice requests may not suffice. We observe that often times; these co-located servicerequests are influenced by surrounding geographical features. By incorporatinggeographical features with the co-located service requests; we discover a new class ofpatterns called geographical-based NRS (N eighbouring service R equest S ets); which isfound to reveal more information compared to co-located service requests. We design twoalgorithms; namely TwoPhaseGSS and AprioriGSS; to discover this new class of patterns.Experiment results demonstrate the efficiency and the scalability of these algorithms.,*,2004,1
IDB: Toward the Scalable Integration of Queryable Internet Data Sources,Jaewoo Kang; Mong Li Lee; Jeffrey F Naughton,Abstract As the number of databases accessible on the Web grows; the ability to executequeries spanning multiple heterogeneous queryable sources is becoming increasinglyimportant. To date; research in this area has focused on providing semantic completeness;and has generated solutions that work well when querying over a relatively small number ofdatabases that have static and well-defined schemas. Unfortunately; these solutions do notextend to the scale of the present Internet; let alone the Internet of the future. In this paper;we present an approach that makes the opposite tradeoff: it provides a scalable; unified viewover large numbers of queryable information sources by sacrificing some expressive powerin the set of queries supported. We have developed a prototype system; IDB; whichimplements this approach. The IDB system provides scalability through three main …,*,2000,1
Efficient join processing using partial precomputation,Kian-Lee Tan; Cheng Hian Goh; Mong Li Lee; Beng Chin Ooi,Abstract In this paper; we generalize conventional join indexes to a cluster-based join index;in which objects are grouped into clusters based on proximity. Each record of our join indexrepresents a pair of clusters in which the join condition is satisfied by some members of thecluster. This strategy is especially useful for spatial and high-dimensional databasesbecause of their typically large data volume and complex operations. Our approachleverages on the structure of R-trees by exploiting the internal nodes of an R-tree ineffectively determining the precomputed clusters which can be used in our join index. Byvarying the size of the cluster; we are able to fine-tune the join index to achieve a balancebetween update cost and retrieval cost to suit individual applications. Differentimplementations of the join index are examined to determine how the join index can be …,Knowledge and Information Systems,1999,1
A Methodology for Structural Conflict Resolution in the Integration of Entity-Relationship Schemas,Mong Li Lee; Tok Wang Ling,*,*,1995,1
Overview of an Entity-Relationship Based Database Management System.,Tok Wang Ling; Mong-Li Lee,Abstract Ling proposes an Entity-Relationship (ER) based DBMS which has a three levelschema architecture. 19 The conceptual schema is represented by a normal form ERdiagam. 18 The internal schema is represented by a set of normal form not-necessarilynormalized relations (or nested relations). 20 The external schema is represented by Entity-Relationship diagrams; not necessarily in normal form. This paper describes the work doneon such a truly ER based DBMS. In particular; we consider the automatic generation ofconceptual-to-internal and external-to-conceptual mappings. We also examine the problemof view update in ER based DBMS. Here; we introduce three types of insertability forexternal relationship sets in views and give a systematic approach to view update.,Future Databases,1992,1
MAROON+: A System for Profiling Entities Over Time,Furong Li; Mong Li Lee; Wynne Hsu,*,*,*,1
Mining Generalized Flow Patterns,Wynne Hsu; Mong Li Lee; Junmei Wang,*,*,*,1
Early Works in Spatio-Temporal Mining,Wynne Hsu; Mong Li Lee; Junmei Wang,*,*,*,1
Mining Flow Patterns in Spatio-Temporal Data,Wynne Hsu; Mong Li Lee; Junmei Wang,*,*,*,1
iFACT: An Interactive Framework to Assess Claims from Tweets,Wee Yong Lim; Mong Li Lee; Wynne Hsu,Abstract Posts by users on microblogs such as Twitter provide diverse real-time updates tomajor events. Unfortunately; not all the information are credible. Previous works that assessthe credibility of information in Twitter have focused on extracting features from the Tweets.In this work; we present an interactive framework called iFACT for assessing the credibility ofclaims from tweets. The proposed framework collects independent evidence from websearch results (WSR) and identify the dependencies between claims. It utilizes features fromthe search results to determine the probabilities that a claim is credible; not credible orinconclusive. Finally; the dependencies between claims are used to adjust the likelihoodestimates of a claim being credible; not credible or inconclusive. iFACT allows users to beengaged in the credibility assessment process by providing feedback as to whether the …,Proceedings of the 2017 ACM on Conference on Information and Knowledge Management,2017,*
Deep Learning System for Screening of Diabetic Retinopathy; Glaucoma and Age-related Macular Degeneration Using Retinal Photographs: The DEEP EYE Study,Gilbert Lim; Daniel Shu Wei Ting; Carol Yim-lui Cheung; Gavin S Tan; Rina Rudyanto; Alfred Tau Liang Gan; Ching-Yu Cheng; Wynne Hsu; Mong Li Lee; Tien Yin Wong,*,Investigative Ophthalmology & Visual Science,2017,*
Special issue on conceptual modeling–34th International Conference on Conceptual Modeling (ER 2015),Paul Johannesson; Mong Li Lee; Stephen Liddle; Andreas L Opdahl; Oscar Pastor,*,*,2017,*
Target-Oriented Keyword Search over Temporal Databases,Xianyan Jia; Wynne Hsu; Mong Li Lee,Abstract Keyword search in relational databases has gained popularity due to its ease ofuse. However; existing methods do not handle keyword search in temporal databases. Inthis paper; we extend keyword queries to allow temporal information to be associated withkeywords; as well as support temporal relationships between two keywords. We design atarget-oriented search over an augmented data graph to efficiently evaluate such temporalkeyword queries. Experiments on 3 datasets demonstrate the efficiency of the proposedapproach to answer complex temporal keyword queries.,International Conference on Database and Expert Systems Applications,2016,*
Improving the Correctness of Some Database Research Using ORA-Semantics,Tok Wang Ling; Zhong Zeng; Mong Li Lee; Thuy Ngoc Le,Abstract We refer to the concepts of object class; relationship type; and attribute of objectclass and relationship type in the ER model as ORA-semantics. Common database modelssuch as the relational model and the XML data model do not capture these ORA-semanticswhich leads to many serious problems in relational and XML database design; data andschema integration; and keyword query processing in these databases. In this paper; wehighlight the limitations and problems of current database research in these areas; anddiscuss how ORA-semantics can be utilized to resolve these problems.,Conceptual Modeling: 35th International Conference; ER 2016; Gifu; Japan; November 14-17; 2016; Proceedings,2016,*
Conceptual Modeling: 34th International Conference; ER 2015; Stockholm; Sweden; October 19-22; 2015; Proceedings,Paul Johannesson; Mong Li Lee; Stephen W Liddle; Andreas L Opdahl; Óscar Pastor López,This book constitutes the refereed proceedings of the 34th International Conference onConceptual Modeling; ER 2015; held in Stockholm; Sweden; in October 2015. The 26 fulland 19 short papers presented were carefully reviewed and selected from 131 submissions.The papers are organized in topical sections on business process and goal models;ontology-based models and ontology patterns; constraints; normalization; interoperabilityand integration; collaborative modeling; variability and uncertainty modeling; modeling andvisualization of user generated content; schema discovery and evolution; process and textmining; domain-based modeling; data models and semantics; and applications ofconceptual modeling.,*,2015,*
Database Systems for Advanced Applications,Wook-Shin Han; Mong Li Lee; Agus Muliantara; Ngurah Agus Sanjaya; Bernhard Thalheim; Shuigeng Zhou,This book constitutes the workshop proceedings of the 19th International Conference onDatabase Systems for Advanced Applications; DASFAA 2014; held in Bali; Indonesia; inApril 2014. The volume contains papers from 4 workshops; each focusing on hot topicsrelated to database systems and applications: the Second International Workshop on BigData Management and Analytics; BDMA 2014; the Third International Workshop on DataManagement for Emerging Network Infrastructure; DaMEN 2014; the Third InternationalWorkshop on Spatial Information Modeling; Management and Mining; SIM3 2014; and theDASFAA Workshop on Uncertain and Crowdsourced Data; UnCrowd 2014.,*,2014,*
Inferring Topic-Level Influence from Network Data,Enliang Xu; Wynne Hsu; Mong Li Lee; Dhaval Patel,Abstract Existing influence analysis research has largely focused on studying themaximization of influence spread in the whole network; or inferring the “hidden” networkfrom a list of observations. There is little work on topic-level specific influence analysis.Although some works try to address this problem; their methods depend on known socialnetwork structure; and do not consider temporal factor which plays an important role indetermining the degree of influence. In this paper; we take into account the temporal factor toinfer the influential strength between users at topic-level. Our approach does not require theunderlying network structure to be known. We propose a guided hierarchical LDA approachto automatically identify topics without using any structural information. We then construct thetopic-level influence network incorporating the temporal factor to infer the influential …,*,2014,*
Database Systems for Advanced Applications: 19th International Conference; DASFAA 2014; Bali; Indonesia; April 21-24; 2014. Proceedings,Sourav S Bhowmick; Curtis E Dyreson; Christian S Jensen; Mong Li Lee; Agus Muliantara; Bernhard Thalheim,These two volumes set LNCS 8421 and LNCS 8422 constitutes the refereed proceedings ofthe 19th International Conference on Database Systems for Advanced Applications;DASFAA 2014; held in Bali; Indonesia; in April 2014. The 62 revised full papers presentedtogether with 1 extended abstract paper; 4 industrial papers; 6 demo presentations; 3tutorials and 1 panel paper were carefully reviewed and selected from a total of 257submissions. The papers cover the following topics: big data management; indexing andquery processing; graph data management; spatio-temporal data management; databasefor emerging hardware; data mining; probabilistic and uncertain data management; web andsocial data management; security; privacy and trust; keyword search; data streammanagement and data quality.,*,2014,*
Matching and Clustering XML Schemas for Scalable Integration and Warehousing,Liang Huai Yang; Xin Gui He; Mong Li Lee; Wynne Hsu; Bingsheng He; Lijun Chen; Weihua Gong; Yi Zhuang,*,IJEC,2013,*
Database research at the National University of Singapore,Stephane Bressan; Chee Yong Chan; Wynne Hsu; Mong-Li Lee; Tok-Wang Ling; Beng Chin Ooi; Kian-Lee Tan; Anthony KH Tung,At the National University of Singapore (NUS); the database group has worked on a widerange of research; ranging from traditional database technology (eg; database design; queryprocessing and optimization) to more advanced database technology (eg; cloud and bigdata management) to novel database utilities (eg; database usability; visualization; securityand privacy). In this article; we describe some recent and on-going interdisciplinary projectsfor which we have received significant amount of funding.,ACM SIGMOD Record,2013,*
Efficient Mining of Lag Patterns in Evolving Time Series,Dhaval Patel; Wynne Hsu; Mong Li Lee,Abstract Time series motifs are sets of similar subsequences. Lag patterns; or the invariantordering among time series motifs; depict localized repeated associative relationshipsacross multiple real valued time series. Lag patterns are of special interest in many realworld applications; such as constructing stock portfolio in financial domain; extractingregulator-target relationship in bioinformatics domain; etc. However; mining lag patterns iscomputationally intensive; particularly in evolving time series data. In this paper; we presentan efficient algorithm called LPMiner* that iteratively discovers motifs and generates lagpatterns of increasing length. We also design an incremental algorithm called incLPMiner tomine lag patterns in the presence of frequent database updates. Experimental analysis onreal world time series datasets demonstrate the efficiency and scalability of our proposed …,*,2013,*
A Novel PIM System and its Effective Storage Compression Scheme,Liang Huai Yang; Jian Zhou; Jiacheng Wang; Mong Li Lee,Abstract—The increasingly large amount of personal information poses a critical problem tousers. Traditional file organization in hierarchical directories is not suited to the effectivemanagement of personal information. In order to overcome the shortcomings of the currenthierarchical file system and efficiently organize and maintain personal information; somenew tools are expected to be invented. In this paper; we propose a novel scheme calledconcept space-a network of concepts and their associations–and use topic map as theunderlying data model. We present a materialized view scheme to provide users with aflexible view of the file system according to their own cognition. We also reduce the storagerequirement to save space usage of this system by borrowing some ideas from XML datamanagement and contriving a novel and efficient data compression scheme. To …,Journal of Software,2012,*
Advances in Conceptual Modeling: ER 2012 Workshops CMS; ECDM-NoCoDA; MoDIC; MORE-BI; RIGiM; SeCoGIS; WISM; Florence; Italy; October 15-18; 2012. Pr...,Silvana Castano; Panos Vassiliadis; Laks V Lakshmanan; Mong Li Lee,This book constitutes the refereed proceedings of workshops; held at the 31st InternationalConference on Conceptual Modeling; ER 2012; in Florence; Italy in October 2012. The 32revised papers presented together with 6 demonstrations were carefully reviewed andselected from 84 submissions. The papers are organized in sections on the workshops CMS2012; EDCM-NoCoDa; MODIC; MORE-BI; RIGIM; SeCoGIS and WISM. The workshopscover different conceptual modeling topics; from requirements; goal and service modeling; toevolution and change management; to non-conventional data access; and they span a widerange of domains including Web information systems; geographical information systems;business intelligence; data-intensive computing.,*,2012,*
Discriminative Mutation Chains in Virus Sequences,Dhaval Patel; Wynne Hsu; Mong Li Lee,Influenza viruses mutate frequently and new mutations may emerge while old mutationsdisappear over a period of time. In addition; some mutations may be dominant in one sub-population but not in the other. Discovering such mutations can help to customize vaccinesto increase the effectiveness for targeted group of people. In this paper; we study theproblem of mining discriminative mutation chains from two influenza A virus protein datasets;D1 and D2; such that the mutations are frequent and significant in one dataset but infrequentand insignificant in the other dataset. We present an efficient algorithm called DMMiner todiscover discriminative mutation chains. Experiments results on the real world influenza Avirus protein datasets reveal that DMMiner is able to find interesting discriminative mutationchains involving the H1N1 2009 influenza A virus as well as region-specific mutations …,Tools with Artificial Intelligence (ICTAI); 2011 23rd IEEE International Conference on,2011,*
The Methodology And Reliability Of Retinal Fractal Dimension Measurement Using A Novel Computer-assisted Method In An Indian Population,George N Thomas; Tien Yin Wong; Shin-Yeu Ong; Wynne Hsu; Mong-Li Lee; Qiangfeng P Lau; Jessica Alessi-Calandro; Lauren Hodgson; Ryo Kawasaki; Carol Y Cheung,Purpose:: Fractal analysis is a method to quantify the geometric branching complexity anddensity of the retinal vessels. This study describes the methodology of fractal analysis andevaluates the reliability of retinal fractal dimension (Df) measurement with a novel computer-assisted method. Methods:: We developed a new computer-assisted program to measurethe Fractal Dimension (Df) of the retinal vessels from digital retinal photographs for disc-centred (OD Df) and macula-centred (Mac Df) views. Retinal photographs from theSingapore Indian Eye Study (SINDI); a population-based survey of 3;400 (75.6% response)persons aged 40 to 80 years; were used for this study. A subset of 171 retinal photographs(5% of SINDI participants) were randomly selected and measured by two trained gradersindependently to determine the inter-grader reliability. The graders repeated the …,Investigative Ophthalmology & Visual Science,2011,*
Database and XML Technologies XSym'10: 7th International XML Database Symposium,Mong-Li Lee; Jeffrey Xu Yu; Zohra Bellahsene,N/A.,XSym'10: 7th International XML Database Symposium-Database and XML Technologies,2010,*
Proceedings of the 7th international XML database conference on Database and XML technologies,Mong Li Lee; Jeffrey Xu Yu; Zohra Bellahsène; Rainer Unland,*,*,2010,*
Database and XML Technologies: 7th International XML Database Symposium; XSym 2010; Singapore; September 17; 2010; Proceedings,Mong Li Lee; Jeffrey Xu Yu; Zohra Bellahsène; Rainer Unland,Since its first edition in 2003; the XML Database Symposium series (XSym) has been aforum for academics; practitioners; users and vendors; allowing all to discuss the use of andsynergy between database management systems and XML. The symposia have providedmany opportunities for timely discussions on a broad range of topics pertaining to the theoryand practice of XML data management and its applications. XSym 2010 continued thisXSym tradition with a program consisting of 11 papers and a keynote shared with the 36thInternational Conference on Very Large Data Bases (VLDB 2010). We received 20 papersubmissions; out of which 8 papers were accepted as full papers; and 3 as short papers.Each submitted paper underwent a rigorous and careful review by four referees. Thecontributions in these proceedings are a fine sample of the current research in XML query …,*,2010,*
Correlation and Reproducibility of Semi-Automated Retinal Vascular Geometric Measurements Within Paired Stereoscopic Images,LA Hodgson; MB Sasongko; R Kawasaki; JJ Wang; W Hsu; ML Lee; QP Lau; TY Wong,Purpose:: Retinal vasculature geometry may be a marker of pre-clinical microvasculardisease. We aimed to assess the robustness and reproducibility of a new computer imagingprogram in measuring retinal vascular geometry using retinal images of the same eye takenwith different photographic angle of incidence. Methods:: We used 30 stereoscopic pairs ofcolour optic disc centred photographs of the Blue Mountain Eye Study to assess thefollowing geometric parameters of retinal arterioles and venules; using a new semi-automated software (SIVA) following standardized protocol: 1) retinal arteriolar/venularcaliber (CRAE/CRVE); 2) arteriole-to-venule ratio (AVR); 3) branching angle; and 4)tortuosity. We used Pearson correlation (r) and Intra-class Correlation Coefficient (ICC) toassess within-pair correlation and agreement for each parameter measure. Results …,Investigative Ophthalmology & Visual Science,2010,*
Lens Opacity and Refractive Influences on Retinal Vascular Fractal Dimension Measurement,H Li; P Mitchell; G Liew; E Rochtchina; TY Wong; W Hsu; ML Lee; YP Zhang; J Wang,Purpose:: To examine the influence of lens opacity and refraction on retinal vascular fractaldimension (Df) measurement. Methods:: Right eye optic disc photographs of 3654participants (aged 49-97 years) of the Blue Mountains Eye Study (1992-94) were digitized.Df of retinal vasculature was quantified using a computer-based program. Lens opacityscores were the sum of severity scores of nuclear; cortical and posterior subcapsularcataract; assessed from lens photographs. Refractive errors were measured using anautorefractor followed by subjective refraction. Spherical equivalent refraction (SER) wascalculated as the sum of spherical plus 0.5 cylinder power. Axial length was measured at the10-year follow-up examination using an IOL master. Results:: Complete data were availablein 2859 subjects. Mean Df of retinal vasculature was 1.444±0.023. Increasing lens opacity …,Investigative Ophthalmology & Visual Science,2010,*
Database and XML Technologies,Mong Li Lee; Jeffrey Xu Yu; Zohra Bellahsène; Rainer Unland,*,Lecture Notes in Computer Science,2010,*
Inter-and Intra-Grader Reliability of Computer-Assisted Measurement of Retinal Vascular Geometry,AK McAuley; N Cheung; H Hamzah; W Hsu; QP Lau; ML Lee; R Kawasaki; JJ Wang; TY Wong,Purpose:: Changes in the retinal vasculature are markers of systemic and ocular vasculardiseases. We developed a semi-automated retinal vascular imaging program thatquantitatively measures retinal vascular geometric parameters; and reported inter-and intra-grader reproducibility of the measures. Methods:: This computer-based program quantifiesfrom retinal images a range of retinal vascular parameters (retinal arteriolar and venularcaliber; branch angles; and simple and curvature tortuosity). Two trained gradersindependently graded twice for 23 right eye images of participants from the Singapore MalayEye Study according to a standardized protocol. Inter-and intra-grader intraclass correlationcoefficients (ICC) were estimated. The Bland-Altman plots were used to depict limits ofagreement by showing mean difference with 95% confidence interval. Results:: Means (±; …,Investigative Ophthalmology & Visual Science,2009,*
Effect of Image Brightness; Focus and Contrast on Measurement of Multifractal Dimension of Retinal Vasculature,AC Wainwright; G Liew; B Taylor; ZY Ping; W Hsu; ML Lee; TY Wong; P Mitchell; JJ Wang,Purpose:: Multifractal dimension (D ref) of the retinal microvasculature is a new globalmeasure of vascular branching architecture and can be measured from retinal photographs.D ref may be useful for assessing overall health of retinal circulation. In this report weinvestigate whether image quality (image brightness; focus and contrast) affects measures ofD ref. Methods:: From the Blue Mountains Eye Study population we selected 30 right-eye;disc-centered; greyscale images of participants free from hypertension or diabetes whichwere judged to have good image clarity. We cropped each image with a circular mask with adiameter of 3.5 x optic disc diameter to provide a consistent image field. We altered thecropped images with Adobe Photoshop CS2 (Adobe Systems) to give image sets whichvaried in parameters including brightness (-40;-30;-20;-10;+ 20;+ 30;+ 40); focus …,Investigative Ophthalmology & Visual Science,2008,*
Does the Photographic Angle of Incidence Alter the Measured Fractal Dimension of the Retinal Vasculature?,V Cosatto; B Taylor; G Liew; YP Zhang; W Hsu; ML Lee; P Mitchell; TY Wong; JJ Wang,Purpose:: Fractal dimension of the retinal vasculature is a new global measure of itsarchitecture and may reflect systemic vascular health. To validate new software for fractaldimension measurement from retinal photographs; we examined whether subtle differencesin the photographic angle of incidence affected fractal dimension measures. Methods:: Arandom sample of 30 pairs of stereoscopic photographs of the right optic disc was selectedfrom Blue Mountains Eye Study participants. These photographs were taken at slightlydifferent angles of incidence to obtain stereoscopic views. The IRIS-Fractal program wasused to measure fractal dimension. This program traces the vessel network to produce askeletal image and then quantifies fractal dimension by a box-counting method. A graderrefines the tracings by removing background noise (peripapillary atrophy; choroidal …,Investigative Ophthalmology & Visual Science,2008,*
Non-blocking Spatial Join,Wee Hyong Tok; Stephane BRESSAN; Mong Li Lee,We propose and study sequential non-blocking algorithms for the processing of spatial joinson continuous data streams with unpredictable arrival rates or on large collections of spatialdata that are not indexed. Given two sets of spatial data represented by their boundingboxes; the algorithms immediately and continuously compute and output the pairs of datafrom each set whose bounding boxes intersect. The different algorithms we propose takeadvantage of different possible characteristics of the data such as clustering of the input tobuild indexes or synopses to accelerate the production of results. We comparatively analyzethe performance of the proposed algorithms using several synthetic and realistic data sets.,*,2007,*
Correlation-based Attribute Outlier Detection in XML,LY Judice; Mong Li LEE; HSU Wynne; Wee Tiong ANG,*,*,2007,*
Database systems for advanced applications;(Lecture notes in computer science; Vol. 3882),Mong Li LEE,*,*,2006,*
Improving data quality,M Li Lee; W Hsu,*,IEEE POTENTIALS,2005,*
Views,Tok Wang Ling; Mong Li Lee; Gillian Dobbie,Summary In this paper; we have proposed a systematic approach for valid XML view design.The approach is composed of three steps. The first step transforms an XML document intoan ORA-SS schema diagram. The second step enriches the ORA-SS schema diagram withnecessary semantics for valid XML views design. The final step uses the proposed a set ofrules to guide the design of valid XML views. We have also presented rules to validateviews.,Semistructured Database Design,2005,*
Schema Extraction,Tok Wang Ling; Mong Li Lee; Gillian Dobbie,Unlike data stored in traditional relational or object-oriented databases; semistructured datadoes not have a fixed schema that is known in advance and that can be stored separatelyfrom the data. In fact; the structure of semistructured data is irregular; unknown; and changesoften [Suciu; 1998]. The lack of external schema information renders the storage; indexing;and querying of semistructured data inefficient; or even impossible. This leads to thedevelopment of methods such as DataGuide [Goldman and Widom; 1997] to extract theschema from semistructured data. The focus of these techniques is to extract the hierarchystructure of semistructured data. In contrast; ORASS is able to capture important semanticinformation such as objects classes; relationship types; attributes; degree of relationshiptypes; participation constraints of the object classes in the relationship types. Further …,Semistructured Database Design,2005,*
Data Models for Semistructured Data,Tok Wang Ling; Mong Li Lee; Gillian Dobbie,Traditionally; real world semantics are captured in a data model; and mapped to thedatabase schema. The real world semantics are modeled as constraints and used to ensureconsistency of the data in the resulting database. Similarly; in semistructured databases theconsistency of the data can be enforced through the use of constraints. There are twoapproaches to designing a schema for a semistructured database. The first follows thetraditional approach and captures the real world constraints in a data model. The secondapproach is used in the case where a semistructured document exists without a schema.Following this approach the constraints are extracted from the document and modeled usinga data model. A data model that is used in the design of schemas for semistructured datahas different requirements than those used in the design of schemas for relational …,Semistructured Database Design,2005,*
Physical Database Design,Tok Wang Ling; Mong Li Lee; Gillian Dobbie,Summary While the process of transforming an ORA-SS schema diagram to an NF ORA-SSschema diagram can lead to databases that have no replicated data which in turn leads to areduction in anomalies; the addition of references may adversely degrade the performanceof queries on the database. In this chapter; we have addressed how replication can beadded back into a schema in a controlled manner in order to improve the performance ofqueries that are frequently asked. We have reviewed how attributes that seldom change aredealt with in relational databases; and how pairings are maintained automatically inhierarchical IMS databases for answering symmetric queries efficiently. We have describedthe kinds of replication that can arise in semistructured databases; and how the replication ofrelatively stable attributes and relationship types can be added; and how pairings …,Semistructured Database Design,2005,*
ORA-SS,Tok Wang Ling; Mong Li Lee; Gillian Dobbie,The ORA-SS data model has three basic concepts: object classes; relationship types andattributes. Object classes model sets of real world entities. An object class is related to otherobject classes through relationship types. Attributes are properties; and may belong to anobject class or a relationship type. The ORA-SS data model consists of four diagrams: ORA-SS instance diagram; ORA-SS schema diagram; functional dependency diagram and ORA-SS inheritance diagram. The instance diagram provides a way to visualize an instance of thedata; the schema diagram represents the structure and constraints on an instance;additional functional dependencies can be represented in the functional dependencydiagram and specialization/generalization relationships among the object classes arerepresented in the inheritance diagram.,Semistructured Database Design,2005,*
Finding Patterns in Image Databases,Wynne Hsu; Mong Li Lee; Jing Dai,Abstract Image is one of the most widely used media in the world. Many real-life applicationshave been designed to process and analyze large number of images. For example; in theterrain matching applications; we have thousands of images that are returned by the satellitewhich need to be processed and mapped; in the archaeology domain; all ancient artifactsare photographed and stored for subsequent efficient retrieval; in the medical domain;images such as mammograms; ultrasound images; X-ray images; MRI-images are already astandard part of health care industry. Finding meaningful patterns from large sets of imagesis necessary for automatic indexing; categorizing; retrieving; and analyzing these images.,Intelligent Knowledge-Based Systems,2005,*
Semistructured database design;(Web information systems engineering & Internet technologies series; Vol. 1),Tok W LING; Mong L LEE; Gillian DOBBIE,*,*,2005,*
Maintaining semantics in the design of valid and reversible semistructured views,Ya Bing Chen; Tok Wang Ling; Mong Li Lee,Abstract Existing systems that support semistructured views do not maintain semanticsduring the process of designing views. Thus; there is no guarantee that the views obtainedare valid and reversible views. In this paper; we propose an approach to designing valid andreversible semistructured views. We employ four types of view operators; namely; select;drop; join and swap operators; and develop a set of rules to maintain the semantics of theviews when the swap operator is applied. We also examine the reversible view problem anddevelop rules to guarantee the designed views are reversible. Finally; we examine thepossible changes to the participation constraints of relationship types and propose rules tokeep the participation constraints correct.,Database Systems for Advanced Applications,2005,*
Cleaning the Spurious Links in Data,Vijay Kothari; Wynne Hsu; Mong Li Lee,*,*,2004,*
Database Technologies for Handling-XML-Information on the Web (DataX)-Querying XMEL Documents and Schema Evolution-A Statistical Approach for XML Query...,Mong Li Lee; Hanyu Li; Wynne Hsu; Beng Chin Ooi,*,Lecture Notes in Computer Science,2004,*
Semantic Data Models for Semistructured Data,Tok Wang Ling; Mong Li Lee; Gillian Dobbie,[摘要]: 正Semistructured data has become more prevalent on the Web; and XML hasbecome the de facto standard for semistructured data; with much of the data stored in flatfiles. There is a growing concern for the effective management and efficient storage andretrieval of semistructured data. This paper provides an overview of the data models thathave been developed for capturing the semantics that are crucial for the effectivemanagement of semistructured data. These data models include DTD; DOM; OEM;DataGuide; and ORA-SS. The semantics include the representation of objects; relationships;attributes of objects; key attributes; functional dependencies; degrees of relationships;participation constraints in relationships; attributes of relationships; etc. We will alsodemonstrate the usefulness of these semantics in minimizing redundancy in the storage …,第二十一届中国数据库学术会议论文集 (技术报告篇),2004,*
Order-sensitive clustering for remote homologous protein detection,Jin Chen; Wynne Hsu; Mong Li Lee,Traditional sequence alignment methods are effective in identifying homologous proteinsthat are highly similar. However; these approaches do not perform well for remotehomologous proteins; that is; proteins whose 3D structures are similar but their sequencesare not. Recent biological research reveals that protein sequences contain residues thatdetermine the 3D structure of proteins. In this work; we investigate incorporating thisinformation to aid in the clustering of protein databases. We capture protein residues in theform of patterns with fixed order among them. First; the significant patterns are extracted fromthe protein sequences. Based on the extracted patterns; we perform sequence mining togenerate the order among them. Finally; we adopt a partition-based method to clusterprotein sequences using the patterns and order features. Experiments on COG and …,Tools with Artificial Intelligence; 2003. Proceedings. 15th IEEE International Conference on,2003,*
Towards Cleaning XML Databases: Experience and Performance Evaluation,Wai Lup Low; Wee Hyong Tok; Mong Li Lee; Tok Wang Ling,*,*,2003,*
Proceedings of the VLDB 2002 Workshop EEXTT and CAiSE 2002 Workshop DTWeb on Efficiency and Effectiveness of XML Tools and Techniques and Data Integr...,Stéphane Bressan; Akmal B Chaudhri; Mong-Li Lee; Jeffrey Xu Yu; Zoé Lacroix,*,*,2003,*
Informal Proceedings of The First VLDB Workshop on Efficiency and Effectiveness of XML Tools; and Techniques (EEXTT2002),Mong Li Lee; Stephane Bressan; Akmal Chaudhri,With XML potentially becoming the standard for data exchange on the Internet; a variety ofXML management systems (XMLMS) differing widely in terms of expressive power andperformance are becoming available. The majority of the XML management systems arelegacy systems (mostly relational database systems) extended to load; query; and publishdata in XML format. A few are native XMLMS and capture almost all the characteristics ofXML data representation. Yet a large number of new techniques are being tuned or devisedfor the management of XML data. In this workshop we propose to focus on the evaluation ofthe performance; effectiveness and efficiency; of XMLMS systems; tools and techniques. Thefirst VLDB workshop on efficiency and effectiveness of XML tools and techniques hostspapers on various aspect of the management of XML data and of the XML data …,*,2002,*
Updatability in federated database systems,Mong Li Lee; Sin Yeung Lee; Tok Wang Ling,Abstract It is important to support updates in federated database systems. However; not allupdates on the federated schema are possible because some may violate certainconstraints in the local databases which are involved in the federation. In this paper; we givea formal framework which characterizes the conditions under which a federated schemaobject type is updatable. We study the steps involved to systematically map an updaterequest on an external view of a federated schema into the equivalent update (s) on thelocal databases. We also consider the situation where semantically equivalent object typesmay not model exactly the same set of objects in the real world. We ensure that the setconstraints (EQUAL; SUBSET; DISJOINT) between the instance sets of equivalent objecttypes are not violated after an update.,*,2001,*
Conceptual Modeling - Er '98,Sudha Ram; W Ling; S RAM; ML Lee,I would like to welcome you to Singapore and the 17th International Conference onConceptual Modeling (ER'98). This conference provides an international forum for technicaldiscussion on conceptual modeling of information systems among researchers; developersand users. This is the first time that this conference is held in Asia; and Singapore is a veryexciting place to host ER'98. We hope that you will find the technical program andworkshops useful and stimulating. The technical program of the conference was selected bythe distinguished program committee consisting of two co-chairs and 83 members. Credit forthe excellent final program is due to Tok Wang Ling and Sudha Ram. Special thanks toFrederick H. Lochovsky for selecting interesting panels; and Alain Pirotte for preparation ofattractive tutorials. I would also like to thank Yong Meng Teo (Publicity Chair); and the …,*,1999,*
Conceptual Modeling-ER'98: Proceedings of the 17th International Conference on...; Singapore; November 16-19; 1998,Mong Li Lee; Sudha Ram; Tok Wang Ling,*,*,1998,*
View Update in Entity-Relationship Based Database Management Systems,Tok Wang Ling; Mong Li Lee,*,*,1992,*
An Elastic Matching-Based Registration Algorithm for Retinal Images Using Vascular Structure,Bin Fang; Wynne Hsu; Mong Li Lee,ABSTRACT Temporal registration of retinal images is fundamental in tracking evolution ofeye-related diseases and providing important information for physicians to decide furthertreatments. In this paper; we propose an elastic matching-based registration algorithm forfundus images using vascular structure features. A two-stage process is first presented toidentify and extract vascular structure. Vessels are enhanced by mathematical morphologytransformation with respect to their spatial properties and are differentiated from backgroundpatterns by curvature evaluation and linear filtering. Morphology reconstruction is performedusing dynamic local region growing to recover the complete vascular structure. With therecovered vascular structure; we perform the registration using an elastic matchingalgorithm. Prior to registration; the extracted vessels are thinned and approximated using …,*,*,*
Efficiency and Effectiveness of XML Tools and Techniques and Data Integration over the Web,Stéphane. Bressan; Mong Li Lee; Akmal B Chaudhri,*,*,*,*
Source Title: Temporal and Spatio-Temporal Data Mining,Wynne Hsu; Mong Lee; Junmei Wang,*,*,*,*
A Unified Framework for Mining Multiple Kinds of Data,Dhaval Patel; Wynne Hsu; Mong Li Lee,*,*,*,*
ER'98: conceptual modeling(Singapore; 16-19 November 1998),Tok Wank Ling; Sudha Ram; Mong Li Lee,*,Lecture notes in computer science,*,*
Mining Topological Patterns in Spatio-Temporal Databases,Wynne Hsu; Mong Li Lee; Junmei Wang,*,*,*,*
Mining Progressive Confident Rules in Sequence Databases,Wynne Hsu; Mong Li Lee; Junmei Wang,*,*,*,*
Mining Sequence Patterns in Evolving Databases,Wynne Hsu; Mong Li Lee; Junmei Wang,*,*,*,*
EEXTT: efficiency and effectiveness of XML tools and techniques and data integration over the web(London[?]; 2002; revised papers),Stéphane Bressan; Akmal B Chaudhri; Mong Li Lee; Jeffrey Xu Yu; Zoé Lacroix,*,Lecture notes in computer science,*,*
Efficient Remote Homology Detection with Secondary Structure,Yuna Hou; Wynne Hsu; Mong Li Lee,ABSTRACT Motivation: The function of an unknown biological sequence can often beaccurately inferred if we are able to map this unknown sequence to its correspondinghomologous family. Currently; discriminative approach which combines support vectormachine and sequence similarity is recognized as the most accurate approach. SVM-Fisherand SVM-pairwise methods are two representatives of this approach; and SVM-pairwise isthe most accurate method. However; these methods only encode sequence information intotheir feature vectors and ignore the structure information. In addition; one of their majordrawbacks is their computation inefficiency. Based on this observation; we present analternative method for SVM-based protein classification. Our method; SVM-I-sites; usesstructure similarity instead of sequence similarity for remote homology detection. Our …,*,*,*
Topband Queries in Time Series Data,Ling Li; Mong Li Lee; Wynne Hsu,Abstract Top-k queries have been extensively studied in various snapshot databases anddata streams for applications where the state of an object is static with respect to time. Weobserve that decision-makers are often interested in a set of objects that exhibit a certaindegree of consistent performance over time. In this paper; we introduce a new class ofqueries called⌈ k⌉-topband that is able to retrieve objects that are within top k at every timepoint over a specified time interval. Topband queries can be processed using standard SQLand existing top-k methods. However; the SQL method requires the nested loops to computethe top-k result; while the top-k approach leads to large intermediate results and wastedcomputations. We design a rank-based approach to address these shortcomings.Experiment results on both synthetic and real world datasets indicate that the proposed …,*,*,*
Time Series Mining: Background and Related Work,Wynne Hsu; Mong Li Lee; Junmei Wang,*,*,*,*
Mining Spatio-Temporal Trees,Wynne Hsu; Mong Li Lee; Junmei Wang,*,*,*,*
Mining Spatio-Temporal Graph Patterns,Wynne Hsu; Mong Li Lee; Junmei Wang,*,*,*,*
Mining Dense Periodic Patterns in Time Series Databases,Wynne Hsu; Mong Li Lee; Junmei Wang,*,*,*,*
Query based Personalized Search in Tag Social Systems,Gang Zhao; Mong Li Lee; Wynne Hsu; Jiawei Zhang,ABSTRACT Online social networks (OSNs) like Delicious; Facebook and Flicker arebecoming more and more popular with both users of Web 2.0 and academic researchers fornew opportunities. Users of such web sites can use tags to annotate various resources andshare them with their friends. With this new way of sharing and managing resources in thesocial systems; the challenge is to incorporate this additional information to retrieve relevantresources for the querying users. In this paper; we focus on the problem of improving searchin tag social systems. We first show the weakness of the existing user-centric friendship-based solutions where the strength of a friendship is determined by the degree ofoverlapping tags or resources among users. Such solutions may not be able to retrieverelevant results as they do not consider whether these friends are qualified to answer the …,*,*,*
Data Integration: An Alternative Perspective,Tok Wang Ling; Mong Li Lee,Abstract Given the rapid growth of the Internet and other on-line information repositories; it isincreasing important to integrate a wider variety of data formats and data found on the Web.In this paper; we o er an alternative perspective on the integration of data from multiplesources such as traditional databases and semi-structured data sources on the Web. Weobserve that a lot of work on the integration of heterogenous data sources assume that thedata is correct and complete. However;" dirty" data les are prevalent as a result of incorrector missing data values due to data entry errors or typographical errors; inconsistent valuenaming conventions due to di erent eld entry format and use of abbreviations; data valuecon icts due to domain mismatch and incomplete information due to unavailability of data.Hence; we may have multiple records refering to the same real world entity. This not only …,*,*,*
Classifying Mobile-Phone Users With An Information Theory Approach,Yun Zheng; Wynne Hsu; Mong Li Lee; Limsoon Wong,Abstract In this paper; we use a learning method based on information theory to classifymobilephone users as 2G and 3G customers. In our method; we aim at looking forinformative and discriminatory feature subset. Then; we build classification models withthese feature subsets. We find some general properties of promising 3G users; ie; the falsepositive predictions. These properties should be useful for easily differentiating the 3Gmobile phone users.,*,*,*
