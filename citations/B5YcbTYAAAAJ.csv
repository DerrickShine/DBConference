On the computation of multidimensional aggregates,Sameet Agarwal; Rakesh Agrawal; Prasad M Deshpande; Ashish Gupta; Jeffrey F Naughton; Raghu Ramakrishnan; Sunita Sarawagi,Abstract At the heart of OLAP or multidimensional data analysis applications is the ability tosimultaneously aggregate across many sets of dimensions. Computing multidimensionalaggregates is a performance bottleneck for these applications. We explore various schemesfor implementing multidimensional aggregation; in particular; the CUBE operator [1]proposed by Gray et al. This operator computes aggregates over all subsets of dimensionsspecified in the CUBE operation; and is equivalent to the union of a number of standardgroup-by operations. We show how the structure of CUBE computation can be viewed interms of a hierarchy of group-by operations; and present a class of sorting-based algorithmsthat overlap the computation of different group-by operations using the least possiblememory for each computation. Our algorithms seek to minimize the number of sorting …,VLDB,1996,849
An array-based algorithm for simultaneous multidimensional aggregates,Yihong Zhao; Prasad M Deshpande; Jeffrey F Naughton,Abstract Computing multiple related group-bys and aggregates is one of the core operationsof On-Line Analytical Processing (OLAP) applications. Recently; Gray et al.[GBLP95]proposed the “Cube” operator; which computes group-by aggregations over all possiblesubsets of the specified dimensions. The rapid acceptance of the importance of this operatorhas led to a variant of the Cube being proposed for the SQL standard. Several efficientalgorithms for Relational OLAP (ROLAP) have been developed to compute the Cube.However; to our knowledge there is nothing in the literature on how to compute the Cube forMultidimensional OLAP (MOLAP) systems; which store their data in sparse arrays ratherthan in tables. In this paper; we present a MOLAP algorithm to compute the Cube; andcompare it to a leading ROLAP algorithm. The comparison between the two is interesting …,ACM SIGMOD Record,1997,589
Materialized view selection for multidimensional datasets,Amit Shukla; Prasad Deshpande; Jeffrey F Naughton,Abstract To fulfill the requirement of fast interactive multidimensional data analysis; databasesystems precompute aggregate views on some subsets of dimensions and theircorresponding hierarchies. However; the problem of what to precompute is difficult andintriguing. The leading existing algorithm; BPUS; has a running time that is polynomial in thenumber of views and is guaranteed to be within (0.63-f) of optimal; where f is the fraction ofavailable space consumed by the largest aggregate. Unfortunately; BPUS can beimpractically slow; and in some instances may miss good solutions due to the coarsegranularity at which it makes its decisions of what to precompute. In view of this; we study thestructure of the precomputation problem and show that under certain broad conditions onthe multidimensional data; an even simpler and faster algorithm; PBS; achieves the same …,VLDB,1998,365
Caching multidimensional queries using chunks,Prasad M Deshpande; Karthikeyan Ramasamy; Amit Shukla; Jeffrey F Naughton,Abstract Caching has been proposed (and implemented) by OLAP systems in order toreduce response times for multidimensional queries. Previous work on such caching hasconsidered table level caching and query level caching. Table level caching is more suitablefor static schemes. On the other hand; query level caching can be used in dynamic schemes;but is too coarse for “large” query results. Query level caching has the further drawback forsmall query results in that it is only effective when a new query is subsumed by a previouslycached query. In this paper; we propose caching small regions of the multidimensionalspace called “chunks”. Chunk-based caching allows fine granularity caching; and allowsqueries to partially reuse the results of previous queries with which they overlap. To facilitatethe computation of chunks required by a query but missing from the cache; we propose a …,ACM SIGMOD Record,1998,265
Storage estimation for multidimensional aggregates in the presence of hierarchies,Amit Shukla; Prasad Deshpande; Jeffrey F Naughton; Karthikeyan Ramasamy,*,VLDB,1996,260
OLAP over uncertain and imprecise data,Doug Burdick; Prasad M Deshpande; TS Jayram; Raghu Ramakrishnan; Shivakumar Vaithyanathan,Abstract We extend the OLAP data model to represent data ambiguity; specificallyimprecision and uncertainty; and introduce an allocation-based approach to the semanticsof aggregation queries over such data. We identify three natural query properties and usethem to shed light on alternative query semantics. While there is much work on representingand querying ambiguous data; to our knowledge this is the first paper to handle bothimprecision and uncertainty in an OLAP setting.,Proceedings of the 31st international conference on Very large data bases,2005,136
OLAP over uncertain and imprecise data,Doug Burdick; Prasad M Deshpande; TS Jayram; Raghu Ramakrishnan; Shivakumar Vaithyanathan,Abstract We extend the OLAP data model to represent data ambiguity; specificallyimprecision and uncertainty; and introduce an allocation-based approach to the semanticsof aggregation queries over such data. We identify three natural query properties and usethem to shed light on alternative query semantics. While there is much work on representingand querying ambiguous data; to our knowledge this is the first paper to handle bothimprecision and uncertainty in an OLAP setting.,The VLDB Journal—The International Journal on Very Large Data Bases,2007,99
Simultaneous optimization and evaluation of multiple dimensional queries,Yihong Zhao; Prasad M Deshpande; Jeffrey F Naughton; Amit Shukla,Abstract Database researchers have made significant progress on several research issuesrelated to multidimensional data analysis; including the development of fast cubingalgorithms; efficient schemes for creating and maintaining precomputed group-bys; and thedesign of efficient storage structures for multidimensional data. However; to date there hasbeen little or no work on multidimensional query optimization. Recently; Microsoft hasproposed “OLE DB for OLAP” as a standard multidimensional interface for databases. OLEDB for OLAP defines Multi-Dimensional Expressions (MDX); which have the interesting andchallenging feature of allowing clients to ask several related dimensional queries in a singleMDX expression. In this paper; we present three algorithms to optimize multiple relateddimensional queries. Two of the algorithms focus on how to generate a global plan from …,ACM Sigmod Record,1998,97
Automatically processing dynamic business rules in a content management system,*,A business rule processing system automatically processes dynamic business rules in acontent management system; allowing frequent updates to the business rules. The updatescan be automatically adapted by the system without restarting the content managementsystem. The system utilizes a stand-alone rule engine. Business logic is encoded asbusiness rule definition files using a platform-independent language; the business ruledefinition files are stored in a central business rule repository. The business rules aremanaged and executed by the rules engine; the rules engine provides business ruleprocessing services to other parts of the content management system. The system reducesdevelopment and maintenance cost; accelerates the business rule update cycle; andsimplifies administration efforts.,*,2012,92
Using a knowledge cache for interactive discovery of association rules,Biswadeep Nag; Prasad M Deshpande; David J DeWitt,Abstract Association rule mining is a valuable decision support technique that can be usedto analyze customer preferences; buying patterns; and product correlations. Current systemsare however handicapped by the long processing times required by mining algorithms thatmake them unsuitable for interactive use. In this paper; we propose the use of a knowledgecache that can reduce the response time by several orders of magnitude. Most of theperformance gain comes from the idea of guaranteed support that allows us to completelyeliminate database accesses in a large number of cases. Using this cache; the time taken toanswer a query is proportional to just the size of the result; rather than to the size of thedatabase. Cache replacement is best done by a benefit-metric based strategy that can easilyadapt to changing query patterns. We show that our caching scheme is quite robust …,Proceedings of the fifth ACM SIGKDD international conference on Knowledge discovery and data mining,1999,86
Active caching for multi-dimensional data sets in relational database management system,*,An “active cache”; for use by On-Line Analytic Processing (OLAP) systems; that can not onlyanswer queries that match data stored in the cache; but can also answer queries that requireaggregation or other computation of the data stored in the cache … This invention relates ingeneral to database management systems performed by computers; and in particular; to an activecache approach to caching multi-dimensional data sets for an on-line analytical processing(OLAP) system that uses a relational database management system (RDBMS) … (Note: Thisapplication references a number of different publications as indicated throughout the specificationby reference numbers enclosed in brackets; eg; [x]. A list of these different publications orderedaccording to these reference numbers can be found in the “Detailed Description of the PreferredEmbodiment” in Section 9 entitled “References.” Each of these publications is …,*,2003,72
Grammar-based task analysis of web logs,*,A method of detecting tasks performed by users wherein a single task is a sequence of webURLs invocation. Task patterns are detected in web logs to identify tasks performed by usersand analyze task trends over time; across corporate divisions and geographies. A grammar-based framework is used to model and detect tasks from web log patterns. The frameworkhas two components: a declarative unit—to generate a task grammar; and a processing unit—to detect tasks from access logs by generating a state machine for applying the taskgrammar to the tokens associated with the access records. By analyzing user tasks; ratherthan just URLs; useful business information can be extracted.,*,2010,54
Materialized view selection for multi-cube data models,Amit Shukla; Prasad M Deshpande; Jeffrey F Naughton,Abstract OLAP applications use precomputation of aggregate data to improve queryresponse time. While this problem has been well-studied in the recent database literature; toour knowledge all previous work has focussed on the special case in which all aggregatesare computed from a single cube (in a star schema; this corresponds to there being a singlefact table). This is unfortunate; because many real world applications require aggregatesover multiple fact tables. In this paper; we attempt to fill this lack of discussion about theissues arising in multi-cube data models by analyzing these issues. Then we examineperformance issues by studying the precomputation problem for multi-cube systems. Weshow that this problem is significantly more complex than the single cube precomputationproblem; and that algorithms and cost models developed for single cube precomputation …,International Conference on Extending Database Technology,2000,51
Computation of multidimensional aggregates,Prasad M Deshpande; Sameet Agarwal; Jeffrey F Naughton; Raghu Ramakrishnan,*,*,1996,45
Aggregate aware caching for multi-dimensional queries,Prasad M Deshpande; Jeffrey F Naughton,Abstract To date; work on caching for OLAP workloads has focussed on using cachedresults from a previous query as the answer to another query. This strategy is effective whenthe query stream exhibits a high degree of locality. It unfortunately misses the dramaticperformance improvements obtainable when the answer to a query; while not immediatelyavailable in the cache; can be computed from data in the cache. In this paper; we considerthe common subcase of answering queries by aggregating data in the cache. In order to useaggregation in the cache; one must solve two subproblems:(1) determining when it ispossible to answer a query by aggregating data in the cache; and (2) determining the fastestpath for this aggregation; since there can be many. We present two strategies—a naive oneand a Virtual Count based strategy. The virtual count based method finds if a query is …,International Conference on Extending Database Technology,2000,42
Efficient allocation algorithms for OLAP over imprecise data,Doug Burdick; Prasad M Deshpande; TS Jayram; Raghu Ramakrishnan; Shivakumar Vaithyanathan,Abstract Recent work proposed extending the OLAP data model to support data ambiguity;specifically imprecision and uncertainty. A process called allocation was proposed totransform a given imprecise fact table into a form; called the Extended Database; that can bereadily used to answer OLAP aggregation queries. In this work; we present scalable;efficient algorithms for creating the Extended Database (ie; performing allocation) for a givenimprecise fact table. Many allocation policies require multiple iterations over the imprecisefact table; and the straightforward evaluation approaches introduced earlier can be highlyinefficient. Optimizing iterative allocation policies for large datasets presents novelchallenges; and has not been considered previously to the best of our knowledge. Inaddition to developing scalable allocation algorithms; we present a performance …,Proceedings of the 32nd international conference on Very large data bases,2006,39
Method for determining the computability of data for an active multi-dimensional cache in a relational database management system,*,An “active cache”; for use by On-Line Anaytic Processing (OLAP) systems; that can not only answerqueries that match data stored in the cache; but can also answer queries that require aggregationor other computation of the data stored in the cache … This invention relates in general to databasemanagement systems performed by computers; and in particular; to an active cache approachto caching multi-dimensional data sets for an on-line analytical processing (OLAP) system thatuses a relational database management system (RDBMS) … (Note: This application referencesa number of different publications as indicated throughout the specification by reference numbersenclosed in brackets; eg; [x]. A list of these different publications ordered according to these referencenumbers can be found in the “Detailed Description of the Preferred Embodiment” in Section 9entitled “References.” Each of these publications is incorporated by reference herein.),*,2004,34
Efficient reverse skyline retrieval with arbitrary non-metric similarity measures,Prasad M Deshpande; P Deepak,Abstract A Reverse Skyline query returns all objects whose skyline contains the queryobject. In this paper; we consider Reverse Skyline query processing where the distancebetween attribute values are not necessarily metric. We outline real world cases thatmotivate Reverse Skyline processing in such scenarios. We consider various optimizationsto develop efficient algorithms for Reverse Skyline processing. Firstly; we consider block-based processing of objects to optimize on IO costs. We then explore pre-processing to re-arrange objects on disk to speed-up computational and IO costs. We then present our maincontribution; which is a method of using group-level reasoning and early pruning to micro-optimize processing by reducing attribute level comparisons. An extensive empiricalevaluation with real-world datasets and synthetic data of varying characteristics shows …,Proceedings of the 14th International Conference on Extending Database Technology,2011,32
Shared computation of user-defined metrics in an on-line analytic processing system,*,An On-Line Analytic Processing (OLAP) system computes complex expressions andaggregations in queries by re-using and sharing subparts of the expressions andaggregations. A dependency generation phase performed by the OLAP system identifiesdependencies among metrics based on the expressions; aggregations; and other metricsused by the metrics. An access plan generation phase performed by the OLAP systemgenerates an access plan based on the identified dependencies; wherein the access planensures that expressions; aggregations; and metrics are computed before they are needed;and that required values and intermediate results are passed up a tree structure of theaccess plan until they are used or consumed by some operator. An operator assignmentphase performed by the OLAP system generates operators based on the access plan …,*,2003,30
Efficient online top-k retrieval with arbitrary similarity measures,Prasad M Deshpande; Krishna Kummamuru,Abstract The top-k retrieval problem requires finding k objects most similar to a given queryobject. Similarities between objects are most often computed as aggregated similarities oftheir attribute values. We consider the case where the similarities between attribute valuesare arbitrary (non-metric); due to which standard space partitioning indexes cannot be used.Among the most popular techniques that can handle arbitrary similarity measures is thefamily of threshold algorithms. These were designed as middleware algorithms that assumethat similarity lists for each attribute are available and focus on efficiently merging these liststo arrive at the results. In this paper; we explore multi-dimensional indexing of non-metricspaces that can lead to efficient pruning of the search space utilizing inter-attributerelationships; during top-k computation. We propose an indexing structure; the AL-Tree …,Proceedings of the 11th international conference on Extending database technology: Advances in database technology,2008,27
Rule based synonyms for entity extraction from noisy text,Rema Ananthanarayanan; Vijil Chenthamarakshan; Prasad M Deshpande; Raghuram Krishnapuram,Abstract Identification of named entities such as person; organization and product namesfrom text is an important task in information extraction. In many domains; the same entitycould be referred to in multiple ways due to variations introduced by different user groups;variations of spellings across regions or cultures; usage of abbreviations; typographicalerrors and other reasons associated with conventional usage. Identifying a piece of text as amention of an entity in such noisy data is difficult; even if we have a dictionary of possibleentities. Previous approaches treat the synonym problem as part entity disambiguation anduse learning-based methods that use the context of the words to identify synonyms. In thispaper; we show that existing domain knowledge; encoded as rules; can be used effectivelyto address the synonym problem to a considerable extent. This makes the disambiguation …,Proceedings of the second workshop on Analytics for noisy unstructured text data,2008,26
Simultaneous computation of multiple moving aggregates in a relational database management system,*,An On-Line Analytic Processing (OLAP) system identifies a plurality of simultaneouslycomputable moving aggregate functions in a query. The identified moving aggregatefunctions are then partitioned into sets that can be computed simultaneously based onequivalent sort expressions. Finally; the OLAP system generates an access plan thatexecutes the partitioned sets simultaneously.,*,2003,26
Cubing algorithms; storage estimation; and storage and processing alternatives for OLAP,Prasad M Deshpande,CiNii 国立情報学研究所 学術情報ナビゲータ[サイニィ]. メニュー 検索 …,IEEE Data Engineering Bulletin,1997,24
Pregnancy differentially impacts performance of latent tuberculosis diagnostics in a high-burden setting,Jyoti S Mathad; Ramesh Bhosale; Vikrant Sangar; Vidya Mave; Nikhil Gupte; Savita Kanade; Ashwini Nangude; Kavita Chopade; Nishi Suryavanshi; Prasad Deshpande; Vandana Kulkarni; Marshall J Glesby; Daniel Fitzgerald; Renu Bharadwaj; Pradeep Sambarey; Amita Gupta,Background Targeted screening for latent TB infection (LTBI) in vulnerable populations is arecommended TB control strategy. Pregnant women are at high risk for developing TB andlikely to access healthcare; making pregnancy an important screening opportunity indeveloping countries. The sensitivity of the widely-used tuberculin skin test (TST); however;may be reduced during pregnancy. Methods We performed a cross-sectional studycomparing the TST with the QuantiFERON Gold In-tube (QGIT) in 401 HIV-negative womenpresenting antepartum (n= 154); at delivery (n= 148); or postpartum (n= 99) to a governmenthospital in Pune; India. A subset of 60 women enrolled during pregnancy was followedlongitudinally and received both tests at all three stages of pregnancy. Results The QGITreturned significantly more positive results than the TST. Of the 401 women in the cross …,PloS one,2014,22
Efficient exception handling during access plan execution in an on-line analytic processing system,*,An On-Line Analytic Processing (OLAP) system converts queries into an operator treecomprised of a plurality of operators; wherein each of the operators is independentlyexecuted. When an exception is detected in one or more of the independently executedoperators; the exception is propagated to the remaining operators of the operator tree byrecycling empty data pages; piggybacking the detected exceptions on the recycled datapages; and sending the recycled data pages both upstream and downstream in the operatortree to the remaining operators of the operator tree. The propagated exceptions aredelivered to the remaining operators; without interrupting the operators; at one or morepoints at which the operator normally reads or writes data from its input stream. Finally; theoperators are terminated using a depth-first traversal of the operator tree.,*,2004,22
Online analytic processing in the presence of uncertainties,*,Disclosed are embodiments of a method for online analytic processing of queries and; andmore particularly; of a method that extends the on-line analytic processing (OLAP) datamodel to represent data ambiguity; such as imprecision and uncertainty; in data values.Specifically; the embodiments of the method incorporate a statistical model that allows foruncertain measures to be modeled as conditional probabilities. Additionally; an embodimentof the method further identifies natural query properties (eg; consistency and faithfulness)and uses them to shed light on alternative query semantics. Lastly; an embodiment of themethod further introduces an allocation-based approach to the semantics of aggregationqueries over such data.,*,2007,21
A service delivery platform for server management services,Jon Lenchner; Daniela Rosu; Nicole F Velasquez; Shang Guo; Ken Christiance; Don DeFelice; Prasad M Deshpande; Krishna Kummamuru; Naama Kraus; Laura Z Luan; Debapriyo Majumdar; Martin McLaughlin; Shila Ofek-Koifman; P Deepak; C-S Perng; Haggai Roitman; Christopher Ward; James Young,Computer server management is an important component of the global IT (informationtechnology) services business. The providers of server management services faceunrelenting efficiency challenges in order to remain competitive with other providers. Serversystem administrators (SAs) represent the majority of the workers in this industry; and theirprimary task is server management. Since system administration is a highly skilled position;the costs of employing such individuals are high; and thus; the challenge is to increase theirefficiency so that a given SA can manage larger numbers of servers. In this paper; wedescribe a widely deployed Service Delivery Portal (SDP) in use throughout the ServerSystems Operations business of IBM that provides a set of well-integrated technologies tohelp SAs perform their tasks more efficiently. The SDP is based on three simple design …,IBM Journal of Research and Development,2009,17
Indexing and matching trajectories under inconsistent sampling rates,Sayan Ranu; P Deepak; Aditya D Telang; Prasad Deshpande; Sriram Raghavan,Quantifying the similarity between two trajectories is a fundamental operation in analysis ofspatio-temporal databases. While a number of distance functions exist; the recent shift in thedynamics of the trajectory generation procedure violates one of their core assumptions; aconsistent and uniform sampling rate. In this paper; we formulate a robust distance functioncalled Edit Distance with Projections (EDwP) to match trajectories under inconsistent andvariable sampling rates through dynamic interpolation. This is achieved by deploying theidea of projections that goes beyond matching only the sampled points while aligningtrajectories. To enable efficient trajectory retrievals using EDwP; we design an indexstructure called TrajTree. TrajTree derives its pruning power by employing the uniquecombination of bounding boxes with Lipschitz embedding. Extensive experiments on real …,Data Engineering (ICDE); 2015 IEEE 31st International Conference on,2015,15
Determining Essential Statistics for Cost Based Optimization of an ETL Workflow.,Ramanujam Halasipuram; Prasad M Deshpande; Sriram Padmanabhan,ABSTRACT Many of the ETL products in the market today provide tools for design of ETLworkflows; with very little or no support for optimization of such workflows. Optimization ofETL workflows pose several new challenges compared to traditional query optimization indatabase systems. There have been many attempts both in the industry and the researchcommunity to support cost-based optimization techniques for ETL Workflows; but with limitedsuccess. Non-availability of source statistics in ETL is one of the major challenges thatprecludes the use of a cost based optimization strategy. However; the basic philosophy ofETL workflows of design once and execute repeatedly allows interesting possibilities fordetermining the statistics of the input. In this paper; we propose a framework to determinevarious sets of statistics to collect for a given workflow; using which the optimizer can …,EDBT,2014,13
Exploiting evidence from unstructured data to enhance master data management,Karin Murthy; Prasad M Deshpande; Atreyee Dey; Ramanujam Halasipuram; Mukesh Mohania; P Deepak; Jennifer Reed; Scott Schumacher,Abstract Master data management (MDM) integrates data from multiple structured datasources and builds a consolidated 360-degree view of business entities such as customersand products. Today's MDM systems are not prepared to integrate information fromunstructured data sources; such as news reports; emails; call-center transcripts; and chatlogs. However; those unstructured data sources may contain valuable information about thesame entities known to MDM from the structured data sources. Integrating information fromunstructured data into MDM is challenging as textual references to existing MDM entities areoften incomplete and imprecise and the additional entity information extracted from textshould not impact the trustworthiness of MDM data. In this paper; we present an architecturefor making MDM text-aware and showcase its implementation as IBM Info-Sphere MDM …,Proceedings of the VLDB Endowment,2012,13
Towards smarter documents,Vikas Krishna; Prasad M Deshpande; Savitha Srinivasan,Abstract Document analysis research typically focuses on document image understandingor classic problems in text classification; clustering; summarization and discovery. While thatis an important aspect of document management; in practice; documents lifecycles are oftendetermined by the context of the business process that they are relevant to. It thereforebecomes necessary for the document analysis techniques to recognize and leverage thecontextual information provided by a supporting schema and business process. This paperpresents an intelligent document management framework with relevant document analysis;metadata extraction; and business process association algorithms and methodology. Thearchitecture supporting this framework seamlessly integrates a runtime environment with anauthoring environment by combining relational data modeling tools with document …,Proceedings of the thirteenth ACM international conference on Information and knowledge management,2004,13
Configurable and Extensible Multi-flows for Providing Analytics as a Service on the Cloud,P Deepak; Prasad M Deshpande; Karin Murthy,Compared to traditional analytics deployment models; cloud-based solutions for businessanalytics provide numerous advantages such as reduction of a large upfront infrastructuralcost and the efforts to setup an in-house analytics team. Such advantages of cloud-basedservice delivery make it particularly attractive for small and medium businesses. In spite ofthese advantages; analytics penetration has been low particularly in developing regionssuch as India and China due to many other factors. In this paper; we propose pre-packagedconfigurable workflows for analytics as a means of endearing cloud-based analytics tocustomers; with a special focus on small and medium businesses in developing regions. Weintroduce the concept of configurable multi-flows that make it easy for non-technicalpersonnel to use and customize without being aware of the technical details of the …,SRII Global Conference (SRII); 2012 Annual,2012,11
Systems and methods for dynamic product and service bundling,*,Systems and methods for dynamic product bundling are described herein. For example;embodiments dynamically generate product bundle for customer within a particular segmentin view of that customer's interest in a particular product. Embodiments determine customeraffinity; customer commonality; and product complementarity and use this information todynamically generate and optimize product bundles for customers interested in one or moreproducts.,*,2012,10
Reverse Auction Based Pull Model Framework for Workload Allocation Problems in IT Service Delivery Industry,*,A call center system for allocating problem tickets for technical services by using a pullmodel auction to select an agent to work on the problem ticket. When the call center receivesan order for a technical service; it develops a complexity estimate for the tasks specified inthe problem ticket; and calculates deadlines for completing the problem ticket and forconducting the auction. Invitations to bid on the problem ticket are sent to potential agents ona bidder's list. The winning bid is selected from among the bids received back from thepotential agents; and; after evaluating the bids; the problem ticket is transferred to thewinning agent.,*,2009,10
Improving recall of regular expressions for information extraction,Karin Murthy; P Deepak; Prasad M Deshpande,Abstract Learning or writing regular expressions to identify instances of a specific conceptwithin text documents with a high precision and recall is challenging. It is relatively easy toimprove the precision of an initial regular expression by identifying false positives coveredand tweaking the expression to avoid the false positives. However; modifying the expressionto improve recall is difficult since false negatives can only be identified by manuallyanalyzing all documents; in the absence of any tools to identify the missing instances. Wefocus on partially automating the discovery of missing instances by soliciting minimal userfeedback. We present a technique to identify good generalizations of a regular expressionthat have improved recall while retaining high precision. We empirically demonstrate theeffectiveness of the proposed technique as compared to existing methods and show …,International Conference on Web Information Systems Engineering,2012,9
Analysis of OLAP data to determine user-relevant information,*,The analysis of OLAP data to determine user-relevant information firstly generates a set ofqueries based on said preferences. Each query is evaluated sequentially against the OLAPdata to give a query result. For each evaluated query in turn; it is determined whether saidresult is relevant to the user on the basis of conditions derived from the user preferences. Anoutput results set is formed consisting of the relevant results. Further; if a previous queryresult containing a common measure was determined not to be relevant; then a subsequentquery can be omitted from evaluation.,*,2010,9
Caching for multi-dimensional data mining queries,Biswadeep Nag; P Deshpande; David J DeWitt,Abstract Multi-dimensional data analysis and online analytical processing are standardquerying techniques applied on today's data warehouses. Data mining algorithms; on theother hand; are still mostly run in stand-alone; batch mode on flat files extracted fromrelational databases. In this paper we propose a general querying model combining thepower of relational databases; SQL; multidimensional querying and data mining. Using thismodel allows data mining to leverage much of the extensive infrastructure that has alreadybeen built for data warehouses including many of the highly successful query processingstrategies designed for OLAP. We present one such integrated; chunk-based cachingscheme that is central to the design of an interactive; multi-dimensional data mining systemand conclude with an experimental evaluation of three different cache replacement …,Proc. of SCI,2001,9
Operators for similarity search: Semantics; techniques and usage scenarios,P Deepak; Prasad M Deshpande,With the growing variety of entities that have their presence on the web; retrieving relevantentities for various user requirements becomes an important problem. The area of SimilaritySearch that addresses this problem has received a lot of attention in the last fifteen years.Increasingly sophisticated data representations; query specifications; indexing mechanismsand algorithms to retrieve relevant entities to a query are being devised. Of these;developing indexes tailored to new kinds of data and devising algorithms to use suchindexes to reduce the turnaround time for similarity search has attracted attention from thedatabase community; resulting in several focused surveys and a few books that educate theaudience about the field. Though relatively less discussed; another dimension in retrievalthat has recorded tremendous progress over the years has been the development of …,*,2015,8
Detecting localized homogeneous anomalies over spatio-temporal data,Aditya Telang; P Deepak; Salil Joshi; Prasad Deshpande; Ranjana Rajendran,Abstract The last decade has witnessed an unprecedented growth in availability of datahaving spatio-temporal characteristics. Given the scale and richness of such data; findingspatio-temporal patterns that demonstrate significantly different behavior from theirneighbors could be of interest for various application scenarios such as—weather modeling;analyzing spread of disease outbreaks; monitoring traffic congestions; and so on. In thispaper; we propose an automated approach of exploring and discovering such anomalouspatterns irrespective of the underlying domain from which the data is recovered. Ourapproach differs significantly from traditional methods of spatial outlier detection; andemploys two phases—(i) discovering homogeneous regions; and (ii) evaluating theseregions as anomalies based on their statistical difference from a generalized …,Data Mining and Knowledge Discovery,2014,8
Auction based models for ticket allocation problem in IT service delivery industry,Prasad M Deshpande; Dinesh Garg; N Rama Suri,In this paper; we study the service request (ticket) allocation problem which arises in every ITservice delivery organization. We refer to this problem as Ticket Allocation Problem (TAP).We first show that TAP is an instance of the online scheduling problem on unrelatedmachines; which is known to be a hard problem. Next; we describe a baseline model;namely push model; that deals with the TAP. The push model is an industry wide standardand can be used with any known online scheduling algorithm for unrelated machines. Toelaborate this further; we discuss a well known Generalized List Scheduling algorithm whichcan be used by the push model. We prove a bound for this algorithm's competitive ratiowhich beats all the known bounds. We show that push model suffers from an inherentinefficiency due to scheduler having incomplete and imprecise information regarding …,Services Computing; 2008. SCC'08. IEEE International Conference on,2008,8
Information extraction combining spatial and textual layout cues,*,Techniques for extracting information from a formatted document are provided. Thetechniques include combining one or more visual layout rules; one or more mark-up rulesand one or more text-based rules in connection with a formatted document; and specifyingone or more rules from the one or more visual layout rules; one or more mark-up rules andone or more text based rules to extract information from the formatted document.,*,2012,7
Auto-grouping emails for faster e-discovery,Sachindra Joshi; Danish Contractor; Kenney Ng; Prasad M Deshpande; Thomas Hampp,*,Proceedings of the VLDB Endowment,2011,7
Quantitative IFN-γ and IL-2 response associated with latent tuberculosis test discordance in HIV-infected pregnant women,Jyoti S Mathad; Ramesh Bhosale; Usha Balasubramanian; Savita Kanade; Vidya Mave; Nishi Suryavanshi; Nikhil Gupte; Samir Joshi; Ajay Chandanwale; Kathryn M Dupnik; Vandana Kulkarni; Prasad Deshpande; Daniel W Fitzgerald; Amita Gupta,Rationale: Pregnant women with latent tuberculosis infection (LTBI) are at high risk fordevelopment of TB; especially if infected with HIV. Objectives: To assess the performance ofLTBI tests in pregnant and postpartum women infected with HIV; investigate the immunologybehind discordance in pregnancy; and explore the implications for the development ofpostpartum TB. Methods: We screened pregnant women in their second/third trimester andat delivery for LTBI using the tuberculin skin test (TST) and IFN-γ release assay(IGRA)(QuantiFERON Gold). A subset of antepartum women had longitudinal testing; withrepeat testing at delivery and postpartum and additional cytokines measured from the IGRAsupernatant. The kappa statistic and Wilcoxon rank sum test were used to determineagreement and comparison of cytokine concentrations; respectively. Measurements and …,American journal of respiratory and critical care medicine,2016,6
Systems and methods for dynamically reconfiguring predictive analytics within workflows using selective user feedback,*,Workflow management in geographically contained or distributed organizations typically seeksto efficiently assign tasks to resources (or individuals positioned to or capable of accommodatingone or more tasks). Predictive analytics capabilities are often used in workflow managementto choose a branch or path to which a workflow can next be directed. For instance; such analyticscan make use of historical information to permit automated decision making on choosing a branchor path; or at least can provide information; insight or data that would assist in manual decisionmaking. However; conventional efforts have proven to be insufficient in continually providingreasonably efficient workflow management over longer periods of time … In summary; one aspectof the invention provides a method comprising: accepting a work item; routing the work item froma first node to a second node based on a predictive analytics model; validating the …,*,2013,6
Efficient rknn retrieval with arbitrary non-metric similarity measures,P Deepak; Prasad M Deshpande,Abstract AR kNN query returns all objects whose nearest k neighbors contain the queryobject. In this paper; we consider RkNN query processing in the case where the distancesbetween attribute values are not necessarily metric. Dissimilarities between objects couldthen be a monotonic aggregate of dissimilarities between their values; such aggregationfunctions being specified at query time. We outline real world cases that motivate RkNNprocessing in such scenarios. We consider the AL-Tree index and its applicability in RkNNquery processing. We develop an approach that exploits the group level reasoning enabledby the AL-Tree in RkNN processing. We evaluate our approach against a Naive approachthat performs sequential scans on contiguous data and an improved block-based approachthat we provide. We use real-world datasets and synthetic data with varying …,Proceedings of the VLDB Endowment,2010,6
Grammar-based task analysis of Web logs,Savitha Srinivasan; Arnon Amir; Prasad Deshpande; Vladimir Zbarsky,Abstract The daily use of Internet-based services is involved with hundreds of different tasksbeing performed by multiple users. A single task is typically involved with a sequence ofWeb URLs invocation. We study the problem of pattern detection in Web logs to identifytasks performed by users; and analyze task trends over time using a grammar-basedframework. Our results are demonstrated on a corporate Intranet portal application with 7000users over a 6 week period and demonstrate compelling business value from this high-leveltask analysis.,Proceedings of the thirteenth ACM international conference on information and knowledge management,2004,6
Populating service requests,*,A method; apparatus; architecture and computer program product for populating a servicerequest is disclosed. A service request is modeled to determine the steps involved. The datais missing from a service request for each step of the request is assessed. The data sourcesfor the modeled request are identified. The relevant data is extracted from the identified datasources. The service request is populated with the extracted data. A service request isexecuted by executing at least one process step acting on the populated service request.,*,2011,5
Fast Rule Mining Over Multi-Dimensional Windows,Mahashweta Das; P Deepak; Prasad M Deshpande; Ramakrishnan Kannan,Abstract Association rule mining is an indispensable tool for discovering insights from largedatabases and data warehouses. The data in a warehouse being multi-dimensional; it isoften useful to mine rules over subsets of data defined by selections over the dimensions.Such interactive rule mining over multi-dimensional query windows is difficult since rulemining is computationally expensive. Current methods using pre-computation of frequentitemsets require counting of some itemsets by revisiting the transaction database at querytime; which is very expensive. We develop a method (RMW) that identifies the minimal set ofitemsets to compute and store for each cell; so that rule mining over any query window maybe performed without going back to the transaction database. We give formal proofs that theset of itemsets chosen by RMW is sufficient to answer any query and also prove that it is …,SDM,2011,5
CRM Analytics Framework.,Joseph P Bigus; Upendra Chitnis; Prasad M Deshpande; Ramakrishnan Kannan; Mukesh K Mohania; Sumit Negi; Deepak Padmanabhan; Edwin PD Pednault; Soujanya Soni; Bipen K Telkar; Brian F White,Abstract Implementing a CRM Analytics solution for a business involves many stepsincluding data extraction; populating the extracted data into a warehouse; and running anappropriate mining algorithm. We propose a CRM Analytics Framework that provides an end-to-end framework for developing and deploying pre-packaged predictive modeling businesssolutions; intended to help in reducing the time and effort required for building theapplication. Standardization and metadata-driven development are used in the solution; thismakes the framework accessible to nonexperts. We describe our framework that makes useof industry standard software products and present a case study of its application in thefinancial domain.,COMAD,2009,5
Model Driven Development of Content Management Applications.,Prasad M Deshpande; Brendan McNichols; Michael Richmond; Savitha Srinivasan; Vladimir Zbarsky,ABSTRACT Building applications on databases or content management systems involvesvarious stages such as schema design; business logic design and UI design. We explore amodel driven design approach; in which the application building process is initiated bybuilding a model. The model includes various aspects such as the data model and businessrules definitions. Once the model is defined; other components can be generatedautomatically from it. These components are then used to build the rest of the application.We have developed an integrated; extensible platform for supporting the different roles inthis process: Data Architect; Application Developer & Web Interface Designer. The dataarchitect role is supported by tooling that supports visual repository schema design and datamodeling in a disconnected mode. The application developer and UI designer role is …,COMAD,2005,5
Method for deriving intelligence from activity logs,*,Techniques for segregating one or more logs of at least one multitasking user to derive atleast one behavioral pattern of the at least one multitasking user are provided. Thetechniques include obtaining at least one of at least one action log; configurationinformation; domain knowledge; at least one task history and open task repositoryinformation; correlating the at least one of at least one action log; configuration information;domain knowledge; at least one task history and open task repository information todetermine a task associated with each of one or more actions and segregate the one ormore logs based on the one or more actions; and using the one or more logs that have beensegregated to derive at least one behavioral pattern of the at least one multitasking user.Techniques are also provided for deriving intelligence from at least one activity log of at …,*,2016,4
Discovery; analysis; and visualization of dependencies,*,Product data pertaining to a plurality of products is gathered from a plurality of sources.Dependency information for the plurality of products is extracted from the product data. Thedependency information is analyzed to determine dependencies for each product of theplurality of products. The dependencies for each product of the plurality of products aredisplayed to a user.,*,2014,4
IceCube: efficient targeted mining in data cubes,Shrutendra K Harsola; Prasad M Deshpande; Jayant R Haritsa,We address the problem of mining targeted association rules over multidimensional market-basket data. Here; each transaction has; in addition to the set of purchased items; ancillarydimension attributes associated with it. Based on these dimensions; transactions can bevisualized as distributed over cells of an n-dimensional cube. In this framework; a targetedassociation rule is of the form {X→ Y} R; where R is a convex region in the cube and X→ Y isa traditional association rule within region R. We first describe the TOARM algorithm; basedon classical techniques; for identifying targeted association rules. Then; we discuss theconcepts of bottom-up aggregation and cubing; leading to the Cell Union technique. Thisapproach is further extended; using notions of cube-count interleaving and credit-basedpruning; to derive the Ice Cube algorithm. Our experiments demonstrate that Ice Cube …,Data Mining (ICDM); 2012 IEEE 12th International Conference on,2012,4
Improving the efficiency of legal e-discovery services using text mining techniques,Sachindra Joshi; Prasad M Deshpande; Thomas Hampp,E-Discovery Review is a type of legal service that aims at finding relevant electronicallystored information (ESI) in a legal case. This requires manual reviewing of large number ofdocuments by legal analysts; thus involving huge costs. In this paper; we investigate the useof IT; specifically text mining techniques; for improving the efficiency and quality of theediscovery review service. We employ near duplicate detection and automatic classificationtechniques that can be used to create coherent groups of documents. Since a groupcharacterizes a syntactic or a semantic theme all the documents in a group can be reviewedtogether. This leads to a faster and more consistent review of documents. Our experimentalresults on the publicly available Enron email corpus show that we can achieve highprecision and recall in identifying the syntactic and semantic groups. We also conduct a …,SRII Global Conference (SRII); 2011 Annual,2011,4
Efficient skyline retrieval with arbitrary similarity measures,Prasad M Deshpande; Debapriyo Majumdar; Raghu Krishnapuram,Abstract A skyline query returns a set of objects that are not dominated by other objects. Anobject is said to dominate another if it is closer to the query than the latter on all factors underconsideration. In this paper; we consider the case where the similarity measures may bearbitrary and do not necessarily come from a metric space. We first explore middlewarealgorithms; analyze how skyline retrieval for non-metric spaces can be done on themiddleware backend; and lay down a necessary and sufficient stopping condition formiddleware-based skyline algorithms. We develop the Balanced Access Algorithm; which isprovably more IO-friendly than the state-of-the-art algorithm for skyline query processing onmiddleware and show that BAA outperforms the latter by orders of magnitude. We also showthat without prior knowledge about data distributions; it is unlikely to have a middleware …,Proceedings of the 12th international conference on extending database technology: advances in database technology,2009,4
Influence of oxygen contamination on magnetic properties of amorphous and nanocrystallized FeCuSiNbB thin films,Johan Moulin; Bhaskar Kaviraj; El Houcine Oubensaïd; Francisco Alves; Uday P Deshpande; Ajay Gupta; Elisabeth Dufour-Gergam,Abstract: Article Preview Article Preview Thin films of amorphous FeCuSiNbB alloy havebeen deposited by RF sputtering with various deposition rates. The bulk oxygen content hasbeen characterized using EDS and XPS. Its dependence on deposition rate shows thatwater vapour in the sputtering chamber is at the origin of the contamination. It allows alsoestimating the adsorption coefficient of the oxygen on the sample to be around 15% at 350K. The magnetic hardness and the resistivity increase with the contamination in oxygen. Indevitrified films; this increase is also related to an enrichment of the residual amorphousmatrix in oxygen.,Solid State Phenomena,2009,4
System and method for implementing multi-temporal database functionality,*,A computer-implemented method; computer program product; and computing system forimplementing multi-temporal tables in a database is described. One or more databases areutilized; wherein the one or more databases implement a first temporal table that includes afirst and a second time domain. The one or more databases are enabled to implement asecond temporal table that includes at least a third time domain; wherein the secondtemporal table is associated with the first temporal table.,*,2016,3
Discovery of related entities in a master data management system,*,Methods and arrangements for discovering entity types for a set of records. A set of recordsis input; with each record comprising attributes with associated attribute values. The recordsare grouped into candidate entity types in view of at least one of: the attribute values of therecords; at least one domain ontology and at least one dimension hierarchy. Aninterestingness measure of each candidate entity type is calculated; via estimatinginterestingness based on at least one factor selected from the group consisting of: acorrelation between attribute values of records; a number of attributes; a log of queriesissued to a server; and an average group size for candidate entity types. At least onecandidate entity type is validated based on the calculated interestingness measures. Othervariants and embodiments are broadly contemplated herein.,*,2015,3
Classification of an electronic document,*,A computer receives an electronic document that includes a group of terms. The computersends the electronic document to an information extraction program that extracts specificterms from the group of terms. Each of the specific terms that match to a certain extent withone of the attribute values in an electronic dictionary is identified. A value associated withthe electronic document is generated based on the specific terms that match; and on an end-user that is attempting to access the electronic document.,*,2014,3
Impact of maternal hepatitis B virus coinfection on mother‐to‐child transmission of HIV,Vidya Mave; Dileep Kadam; Aarti Kinikar; Nikhil Gupte; Debika Bhattacharya; Renu Bharadwaj; Katherine McIntire; Vandana Kulkarni; Usha Balasubramanian; Nishi Suryavanshi; Chloe Thio; Prasad Deshpande; Jayagowri Sastry; Robert Bollinger; Amita Gupta; Ramesh Bhosale,Objectives Despite high hepatitis B virus (HBV) endemicity in various resource-limitedsettings (RLSs); the impact of maternal HIV/HBV coinfection on infant health outcomes hasnot been defined. We aimed to assess the prevalence of HBV coinfection among HIV-infected pregnant women and its impact on HIV transmission and infant mortality. Methods Inthis study; the seroprevalence of HBV coinfection was determined among HIV-infectedpregnant women enrolled in the Six-Week Extended-Dose Nevirapine (SWEN) India trial.The impact of maternal HIV/HBV coinfection on mother-to-child transmission (MTCT) of HIVand infant mortality was assessed using univariate and multivariate logistic regressionanalysis. Results Among 689 HIV-infected pregnant Indian women; 32 (4.6%) had HBVcoinfection [95% confidence interval (CI) 3.4%; 5.3%]. HBV DNA was detectable in 18 (64 …,HIV medicine,2014,3
Dynamically reconfiguring predictive analytics within workflows using selective user feedback,*,Workflow management in geographically contained or distributed organizations typically seeksto efficiently assign tasks to resources (or individuals positioned to or capable of accommodatingone or more tasks). Predictive analytics capabilities are often used in workflow managementto choose a branch or path to which a workflow can next be directed. For instance; such analyticscan make use of historical information to permit automated decision making on choosing a branchor path; or at least can provide information; insight or data that would assist in manual decisionmaking. However; conventional efforts have proven to be insufficient in continually providingreasonably efficient workflow management over longer periods of time … In summary; one aspectof the invention provides a method comprising: accepting a work item; routing the work item froma first node to a second node based on a predictive analytics model; validating the …,*,2014,3
Transactions on Large-Scale Data-and Knowledge-Centered Systems VIII: Special Issue on Advances in Data Warehousing and Knowledge Discovery,Abdelkader Hameurlain; Josef Küng; Roland Wagner; Alfredo Cuzzocrea; Umeshwar Dayal,Data warehousing and knowledge discovery is an extremely active research area where anumber of methodologies and paradigms converge; with coverage of both theoretical issuesand practical solutions. The area of data warehousing and knowledge discovery has beenwidely accepted as a key technology for enterprises and organizations; as it allows them toimprove their abilities in data analysis; decision support; and the automatic extraction ofknowledge from data. With the exponentially growing amount of information to be includedin the decision-making process; the data to be considered are becoming more and morecomplex in both structure and semantics. As a consequence; novel developments; both atthe methodological level; eg; complex analytics over data; and at the infrastructural level; eg;cloud computing architectures; are necessary. Orthogonal to the latter aspects; the …,*,2013,3
Dynamic product and service bundling,*,Systems and methods for dynamic product bundling are described herein. For example;embodiments dynamically generate product bundle for customer within a particular segmentin view of that customer's interest in a particular product. Embodiments determine customeraffinity; customer commonality; and product complementarity and use this information todynamically generate and optimize product bundles for customers interested in one or moreproducts.,*,2012,3
Screening for latent tuberculosis in pregnant women: a comparison of an interferon-γ release assay with tuberculin skin testing in Pune; India,JS Mathad; Pradeep Sambarey; Renu Bharadwaj; Savita Kanade; Prasad Deshpande; Vikrant Sangar; Vandana Kulkarni; Nishi Suryavanshi; Vidya Mave; Nikhil Gupte; Marshall Glesby; Amita Gupta,Jyoti Mathad1; MD; Pradeep Sambarey2; MD; PhD; Renu Bharadwaj2; MD; SavitaKanade3; MSc; Prasad Deshpande3; MSc; Vikrant Sangar3; MSc; Vandana Kulkarni3; MSc;… Nishi Suryavanshi3; PhD; Vidya Mave3;4; MD; MPH; Nikhil Gupte3;4; PhD; MarshallGlesby1; MD; PhD; Amita Gupta3;4; MD; MHS … 1Weill Cornell Medical College; New YorkPresbyterian Hospital; New York; NY; 2Byramjee Jeejeebhoy Medical Center-SassoonHospital; Pune; India … 3Byramjee Jeejeebhoy Medical Center-Johns Hopkins Clinical TrialsUnit; Pune; India; 4Johns Hopkins University Medical School; Baltimore; MD … • HIV-negativepregnant women seeking prenatal care during their third trimester … • Antenatal clinic at anurban; public government hospital in Pune; India … • Medical and obstetric history questionnaireadministered by trained nurses … • Active TB symptom screen by trained nurses,Programs and abstracts of the 49th Infectious Diseases Society of America; Boston; MA,2011,3
Dependency analysis framework for software service delivery,Rema Ananthanarayanan; Vijil Chenthamarakshan; Heng Chu; Prasad M Deshpande; Raghu Krishnapuram; Shajeer K Mohammed,Various phases in the delivery of software services such as solution design; applicationdeployment; and maintenance require analysis of the dependencies of software productsthat form the solution. As software systems become more complex and involve a largenumber of software products from multiple vendors; availability of correct and up-to-datesystem requirement information becomes critical to ensure proper functioning of managedand maintained software solutions. System requirement information; is mostly madeavailable in unstructured formats from sources such as websites or product documents andare not amenable to programmatic analysis. In this paper; we motivate the benefits ofcapturing this information in a structured format for software service delivery; and present adependency analysis system that collects and integrates software dependency …,Services Computing; 2009. SCC'09. IEEE International Conference on,2009,3
AVATAR: Using text analytics to bridge the structured–unstructured divide,Huaiyu Zhu; Sriram Raghavan; Shivakumar Vaithyanathan; Jayram S Thathachar; Rajasekar Krishnamurthy; Prasad Deshpande; Rahul Gupta; Krishna P Chitrapura,Abstract There is a growing need in enterprise applications to query and analyze seamlesslyacross structured and unstructured data. We propose an information system in which textanalytics bridges the structured–unstructured divide. Annotations extracted by text analyticengines; with associated uncertainty; is automatically ingested into a structured data store.We propose an interface that is capable of supporting rich queries over this hybrid data.Uncertainty associated with the extracted information is addressed by building statisticalmodels. We show that different classes of statistical models can be built to address issuessuch as ranking and OLAP style reporting. We are currently building a prototype systemcalled AVATAR that utilizes an existing commercial relational DBMS system as theunderlying storage engine. We present the architecture of AVATAR and identify several …,Almaden. ibm.[Online]. Available: http://www. almaden. ibm. com/cs/projects/avatar/techrep04. pdf,2005,3
A study and analysis of function inlining,Prasad Deshpande; Amit Somani,Abstract Function inlining is a widely known technique which has been used to improveprogram performance. Inlining replaces a function call by the body of the function. In thisreport; we study the e ects of inline function expansion by observing the empirical behaviorof a set of C and C++ programs. Our results indicate that for the average C programimprovements in timings due to inlining are not much (2-3%). However; C++ programs benet much more (up to 46%) from inlining due to smaller average function size and a larger callstack depth.,*,*,3
Computing a similarity measure over moving object trajectories,*,Methods and arrangements for measuring similarity with respect to moving objecttrajectories. First and second moving object trajectories are input; each trajectory beingdefined by at least two spatial dimensions and a temporal dimension. At least one segmentis defined with respect to each trajectory; each segment being defined between two definingpoints. At least one segment from the first trajectory is matched with at least one segmentfrom the second trajectory. A spatial distance and temporal distance are each computedbetween the at least one segment from the first trajectory and the at least one segment fromthe second trajectory. The spatial distance and temporal distance are combined to provide ameasure of a spatio-temporal distance between the at least one segment from the firsttrajectory and the at least one segment from the second trajectory. Other variants and …,*,2017,2
The Mask of ZoRRo: preventing information leakage from documents,Prasad M Deshpande; Salil Joshi; Prateek Dewan; Karin Murthy; Mukesh Mohania; Sheshnarayan Agrawal,Abstract In today's enterprise world; information about business entities such as a customer'sor patient's name; address; and social security number is often present in both relationaldatabases as well as content repositories. Information about such business entities isgenerally well protected in databases by well-defined and fine-grained access control.However; current document retrieval systems do not provide user-specific; fine-grainedredaction of documents to prevent leakage of information about business entities fromdocuments. Leaving companies with only two choices: either providing complete access to adocument; risking potential information leakage; or prohibiting access to the documentaltogether; accepting potentially negative impact on business processes. In this paper; wepresent ZoRRo; an add-on for document retrieval systems to dynamically redact sensitive …,Knowledge and Information Systems,2015,2
Effect of HIV on latent TB screening of pregnant women in Pune; India,JS Mathad; R Bhosale; S Kanade; P Deshpande; V Kulkarni; N Nevrekar; V Mave; N Suryavanshi; N Gupte; A Gupta,• Figure 1: Compared to HIV-uninfected women; HIV-infected women had lower TSTpositivity (p= 0.2) and lower QGIT positivity (p= 0.63).• Figure 2: HIV-infected women withTST-/QGIT+ discordance produced significantly less IFN-γ than those with TST+/QGIT+results (1.8 vs 6.4 IU/mL; p= 0.02). There was trend towards this in the HIV-uninfectedwomen (2.2 vs 4.0 IU/mL; p= 0.12)• In multivariate analysis; a positive QGIT was associatedwith having a known TB contact (aOR 2.9; 95% CI: 1-8.9; p= 0.05)• A positive TST was notassociated with a known TB contact (aOR 1.0; 95% CI 0.20-5.4; p= 0.93),Conference on Retroviruses and Opportunistic Infections (CROI),2014,2
Targeted association rule mining in data cubes,S Harsola; P Deshpande; J Haritsa,Abstract Data mining techniques are usually applied over entire datasets. But the localizedbehavior of subset of data can be very different from that of aggregate behavior of dataset.Our goal is to mine patterns in these localized subsets of data. We looked at the problem ofmining association rules in this framework. In this project; we deal with multidimensionalmarket basket data ie in addition to set of customer purchase items; each transaction alsohas dimension attributes associated with it. Based on these dimension attributes;transactions can be visualized as distributed over cells of an n-dimensional cube. Our goalis to mine targeted association rules in this cube space. A targeted association rule is of theform {X→ Y} R; where R is a region in cube and X→ Y is traditional association rule in regionR. Firstly we explain two basic algorithms: RelaxedSup and TOARM developed on the …,Tech. Rep. TR-2012-03; Database Systems Lab,2012,2
Automated Concept Extraction to aid Legal eDiscovery Review.,Prasad M Deshpande; Thomas Hampp; Manjula Hosurmath; Sachindra Joshi; Seema Meena,Abstract E-Discovery is the process of discovering electronically stored information such asemail that is relevant to a legal case. A typical ediscovery process incurs huge costs due tothe large volume of information and the requirement of highly specialized and expensivehuman resources (legal professionals). In this paper; we examine how informationmanagement technologies can be used to reduce the high cost. We propose a set ofconcepts that are helpful in identifying relevant and not-relevant documents. We thendevelop a set of rule based annotators that automatically identify documents with theseconcepts and compare their performance with standard off-the-shelf classifiers for buildingthe concept annotators. The rule based annotators have been integrated into the IBMproduct for ediscovery review called IBM InfoSphere eDiscovery Analyzer.,COMAD,2009,2
Set Valued Attributes,Karthikeyan Ramasamy; Prasad M Deshpande,Abstract About three decades ago; when Codd (1970) invented the relational databasemodel; it took the database world by storm. The enterprises that adapted it early won a largecompetitive edge. The past two decades have witnessed tremendous growth of relationaldatabase systems; and today the relational model is by far the dominant data model and isthe foundation for leading DBMS products; including IBM DB2; Informix; Oracle; Sybase; andMicrosoft SQL server. Relational databases have become a multibillion-dollar industry.,*,2005,2
Opportunistic FTP,BR Badrinath; Tomasz Imeilinsky; Shirish Phatak; Pradeep Sudame; Prasad Deshpande,Abstract Portable hand-held devices face changing network conditions due to mobility.Existing applications are unaware of the changing networks and do not perform well underall the circumstances. In this paper; we propose a mechanism to expose network conditionsto the application layer. We also show how applications can adapt to changing neworkconditions by demonstrating the opportunistic File Transfer Protocol that can schedule itsnetwork access at the most opportune moments while the portable device is undergoingvertical handoffs.,*,1999,2
Product recommendations over multiple stores,*,Abstract Embodiments of the present invention disclose a method; computer programproduct; and system for identifying matching products relative to a reference product. Areference product is identified from a received product query and a query is generatedbased on the reference product. A generated query comprises of an ontology; at least oneword appearing in a title of the reference product; and a set of key words appearing in socialmedia data associated with the reference product. A database is searched using thegenerated query to find matching product sets and the results are returned and filtered.Results are filtered by calculating a relationship score between the reference product andone or more matching products in the set of matching products; and/or by filtering a subset ofthe set of matching products based on a customer profile. The filtered subset of results are …,*,2018,1
Identifying root causes of failures in a deployed distributed application using historical fine grained machine state data,*,Methods and arrangements for identifying root causes of system failures in a distributedsystem said method including: utilizing at least one processor to execute computer code thatperforms the steps of: recording; in a storage device; collected machine state data; whereinthe collected machine state data are added to historical machine state data; creating; basedon the historical machine state data; a healthy map model; detecting at least one failedmachine state in the distributed system; comparing the failed machine state against thehealthy map model; identifying; based on the comparison; at least one root cause of thefailed machine state; and displaying; on a display device; a ranked list comprising the atleast one root cause. Other variants and embodiments are broadly contemplated herein.,*,2017,1
Identifying entity mappings across data assets,*,Entity mappings that produce matching entities for a first data asset having attributes and asecond data asset having attributes are generated by: generating entity mappings thatproduce matching entities for a first data asset having attributes with attribute values and asecond data asset having attributes with attribute values by: matching the attribute values ofthe attributes of the first data asset with the attribute values of the attributes of the seconddata asset; using the matching attribute values to generate matching attribute pairs; andusing the matching attribute pairs to identify entity mappings; computing an entity mappingscore for each of the entity mappings based on a combination of factors; ranking the entitymappings based on each entity mapping score; and using some of the ranked entitymappings to determine whether a same real-world entity is described by the first data …,*,2017,1
Mining dependencies from disk images,*,Methods and arrangements for automatically finding the dependency of a software producton other software products or components. From an install image or directory; a signature isfound by deriving the same from a directory structure of the software. Further; a directory treestructure is built and an approximate sub-tree matching algorithm is applied to findcommonalties across software products.,*,2017,1
Determining statistics for cost-based optimization of a workflow,*,Techniques; systems; and articles of manufacture for determining statistics for cost-basedoptimization of a workflow. A method includes generating individual sets of statistics for eachintermediate relation of a workflow; wherein said intermediate relations comprise results ofstages of any plan of the workflow; and wherein each individual set of statistics computescardinality of the corresponding intermediate relation; determining a global set of statisticsfor the workflow; wherein said global set of statistics comprises at least one of the individualsets of statistics for each of the intermediate relations; instrumenting a given plan of theworkflow to collect the global set of statistics during execution; executing the given plan tocollect the global set of statistics; and determining a plan of the workflow with the lowest costby comparing the cost of multiple plans; wherein the cost of each plan is derived from the …,*,2016,1
User-specific search over protected contextual data,*,Methods and arrangements for facilitating a display of search results. A search query isreceived from a user having a predetermined access level. A search is executed based onthe search query and; based on the executed search; initial search results are produced.Sensitive information is redacted from the initial search results; based on the predeterminedaccess level. The redacted search results are filtered and re-ordered to forestall an inferenceof the redacted sensitive information. The filtered and re-ordered search results aredisplayed to a user. Other variants and embodiments are broadly contemplated herein.,*,2016,1
Retrieval of relevant objects in a similarity,*,Techniques for retrieval of one or more relevant multi-attribute structured objects withrespect to a query are provided. The techniques include receiving a query; grouping one ormore attributes of one or more objects in a database into one or more groups according tohow each bears a relation to the query; and using the one or more attribute groups toproduce an output of one or more relevant multi-attribute structured objects in response tothe query.,*,2016,1
Spatio-temporal indexing: current scenario; challenges and approaches,Aditya Telang; Deepak Padmanabhan; Prasad Deshpande,Abstract With rapid advancements in computing hardware; tracking devices such as GPSreceivers and sensors have become pervasive; generating a large amount of spatio-temporal data; such as measurements of temperature; pressure; air quality; traffic; etc. usingsensors; GPS data from mobile phones and data from radars that capture locationinformation about people and other moving objects such as cars and aeroplanes. This hasenabled a wide variety of spatio-temporal applications; resulting in a renewed interest intechniques for handling spatio-temporal data. Over the past two decades or so; a largenumber of indexes for supporting spatial; temporal and spatio-temporal data have beenindependently proposed in the database and data mining communities. However; thereexists no clear-cut guidelines or a prescriptive formula for pointing out which index should …,Proceedings of the 18th International Conference on Management of Data,2012,1
WYSIWYE: An Algebra for Expressing Spatial and Textual Rules for Information Extraction,Vijil Chenthamarakshan; Ramakrishna Varadarajan; Prasad M Deshpande; Raghuram Krishnapuram; Knut Stolze,Abstract The visual layout of a webpage can provide valuable clues for certain types ofInformation Extraction (IE) tasks. In traditional rule based IE frameworks; these layout cuesare mapped to rules that operate on the HTML source of the webpages. In contrast; we havedeveloped a framework in which the rules can be specified directly at the layout level. Thishas many advantages; since the higher level of abstraction leads to simpler extraction rulesthat are largely independent of the source code of the page; and; therefore; more robust. Itcan also enable specification of new types of rules that are not otherwise possible. To thebest of our knowledge; there is no general framework that allows declarative specification ofinformation extraction rules based on spatial layout. Our framework is complementary totraditional text based rules framework and allows a seamless combination of spatial …,International Conference on Web-Age Information Management,2012,1
English-language translation of exact interpretations of keyword queries,*,The present invention relates to a methodology to translate exact interpretations of keywordqueries into meaningful and grammatically correct plain-language queries in order toconvey the meaning of these interpretations to the initiator of the search. The methodincludes the steps of generating at least one grammatically valid plain-language sentenceinterpretation for a keyword query from a generated sentence plain-language sentenceclauses; wherein the grammatically valid plain-language sentence is based upon differingmatching elements; and presenting at least one grammatically valid plain-languagesentence interpretation for the keyword query to a keyword query system user for the user'sreview.,*,2011,1
Content-Aware Master Data Management.,Karin Murthy; Deepak Padmanabhan; Prasad M Deshpande; Sreekanth L Kakaraparthy; T Vedula; Surya Sandeep; Vijaya K Shyamsundar; Sanjay K Singh,Abstract Master data management (MDM) provides a means to link data from variousstructured data sources and to generate a consolidated master record for entities such ascustomers or products. However; a large amount of valuable information about entities existsas unstructured content in documents. In this paper; we show how MDM can be made awareof information from unstructured content by automatically extracting valuable informationfrom documents. We demonstrate for an example application that it is possible to make MDMcontent-aware without compromising MDM's premise to be the one trusted source for allentity-related information.,COMAD,2010,1
Data Warehousing and OLAP,Jose Hernandez-Orallo,Information systems provide organizations with the necessary information to achieve theirgoals. Relevant information is gathered and stored to allow decision makers to obtainquickandelaborated reports from the data. A data warehouse is an especially designeddatabase that allows large amounts of historical and contextual information to be stored andaccessed through complex; analytical; highly aggregated; but efficient queries. Thesequeries capture strategic information; possibly presented in the form of reports and supportmanagement decision making. As we will see; datawarehouses differ from general;transactional databases in many ways.,Data Warehousing and Mining: Concepts; Methodologies; Tools; and Applications: Concepts; Methodologies; Tools; and Applications,2008,1
A computational study of fuel impingement in the intake of a spark ignition engine,Jason Ronald Guldan,*,*,2007,1
On business activity modeling using grammars,Savitha Srinivasan; Arnon Amir; Prasad Deshpande; Vladimir Zbarsky,Abstract Web based applications offer a mainstream channel for businesses to manage theiractivities. We model such business activity in a grammar-based framework. The BackusNaur form notation is used to represent the syntax of a regular grammar corresponding toWeb log patterns of interest. Then; a deterministic finite state machine is used to parse Weblogs against the grammar. Detected tasks are associated with metadata such as time takento perform the activity; and aggregated along relevant corporate dimensions.,Special interest tracks and posters of the 14th international conference on World Wide Web,2005,1
Efficient database support for olap queries (on-line analytical processing),Prasad Manikarao Deshpande,Abstract Computing multidimensional aggregates is a performance bottleneck for OLAP andmulti-dimensional data analysis applications. This thesis addresses various problems thatarise while speeding up multi-dimensional queries. The first problem we consider deals withcomputing the CUBE operator proposed by Gray et al. We show how the structure of CUBEcomputation can be viewed in terms of a hierarchy of group-by operations; and present aclass of sorting-based algorithms that overlap the computation of different group-byoperations using the least possible memory for each computation. Experiments show thatthe method dramatically outperforms the straightforward implementation of CUBE as asequence of SQL group-by operations. The second and third part of the thesis deal withcaching for multi-dimensional queries. We developed a novel scheme where we cache …,*,2000,1
Materialized view selection for multidimensional datasets,Amit Shukla,Abstract This dissertation describes techniques for speeding up Online AnalyticalProcessing or OLAP queries. OLAP systems allow users to quickly obtain the answers tocomplex business queries. Quickly answering these queries which aggregate large amountsof data; calls for various specialized techniques. One technique used by OLAP systems tospeed up multidimensional data analysis is to precompute aggregates on some subsets ofdimensions and their corresponding hierarchies. We first address the problem of efficientlyestimating aggregate sizes. Precomputation of aggregate data improves query responsetime. However; the decision of what and how much to precompute is a difficult one. It isfurther complicated by the fact that precomputation in the presence of hierarchies can resultin an unintuitively large increase in the amount of storage required by the database …,*,1999,1
Computation of Multidimensional Aggregates,Raghu Ramakrishnan,Abstract At the heart of OLAP or multidimensional data analysis applications is the ability tosimultaneously aggre-gate across many sets of dimensions. Computing multidimensionalaggregates is a performance bottleneck for these applications. We explore various schemesfor implementing multidimensional aggregation; in particular; the CUBE operator [1]proposed by Gray et al. This operator computes aggregates over all subsets of di-mensionsspecified in the CUBE operation; and is equivalent to the union of a number of standardgroup-by operations. We show how the structure of CUBE computation can be viewed interms of a hierarchy of group-by operations; and present a class of sorting-based algorithmsthat overlap the computation of different group-by operations using the least possiblememory for each computation. Our algorithms seek to minimize the number of sorting …,*,1997,1
Supplementing structured information about entities with information from unstructured data sources,*,A method for supplementing structured information within a data system for entities based onunstructured data analyzes a document with unstructured data and extracts attribute valuesfrom the unstructured data for one or more entities of the data system. Entity records withstructured information are retrieved from the data system based on the extracted attributevalues. Entity references for corresponding entities of the data system are constructed basedon a comparison of the retrieved entity records and the extracted attribute values. The entityreferences are linked to the corresponding entities within the data system; with the entityreferences including extracted attributes from the unstructured data for corresponding linkedentities.,*,2017,*
Securely Processing Range Predicates on Cloud Databases,*,Methods; systems; and computer program products for securely processing rangepredicates on cloud databases are provided herein. A computer-implemented methodincludes separately encrypting a set of plain text data using two or more encryptionfunctions; thereby producing an encrypted domain comprising at least two distinct groups ofencrypted data items; converting a range query over plain text data items into a query over atleast one of the distinct groups of encrypted data items; and combining results from thequery over the distinct groups of encrypted data items; thereby generating a final encryptedresult to the range query.,*,2017,*
Collusion-Resistant Processing of Range Predicates,Manish Kesarwani; Akshar Kaul; Gagandeep Singh; Prasad M Deshpande; Jayant R Haritsa,Abstract A basic challenge in outsourcing enterprise relational databases to the Cloud isproviding secure query processing. Tackling this problem is contingent on organic supportfor range predicates; the core building blocks of decision-support queries. Prior solutions forsecurely handling range predicates typically resort to either order-preserving encryption(OPE) or prefixpreserving encryption (PPE). However; these schemes have been analyzedsolely for passive attacks in the “Honest-but-Curious (HBC)” adversarial model; where theserver is only permitted to observe the encrypted query processing. In this paper; weconsider a HBC variant; wherein the server can launch an “active” attack by clandestinelyissuing specific range queries via collusion with a few compromised clients. In this scenario;which we refer to as the “Honest-but-Intrusive (HBI)” adversarial model; a practical …,*,2017,*
Distributed iceberg cubing over ordered dimensions,*,Methods; systems; and computer program products for distributed iceberg cubing overordered dimensions are provided herein. A method includes calculating; from input dataderived from a search query; a set of multiple cube measures for one or more combinationsof multiple non-ordered dimensions; pruning the set of multiple cube measures based onone or more iceberg conditions to generate a sub-set of the cube measures; anddetermining a range for a set of ordered dimensions over a distributed processing platformbased on (i) the sub-set of the cube measures and (ii) the one or more iceberg conditions.,*,2017,*
Contextualization of entity relationships,*,Methods and arrangements for identifying related data in different data sets to assist insearching the data sets. A first data asset and a second data asset are accessed. Commonentities are identified between the first and second data assets. A score is determined for therelationship between the first and second data assets; based on the identified commonentities. One or more relationship contexts are determined for the relationship between thefirst and second data assets; and the relationship score and one or more relationshipcontexts are used to join at least a portion of each of the first and second data assets as abasis for subsequent searching. Other variants and embodiments are broadly contemplatedherein.,*,2017,*
Categorizing Log Records at Run-Time,*,Methods; systems; and computer program products for categorizing log records at run-timeare provided herein. A computer-implemented method includes generating one or moretemplate signatures to be associated with each of multiple templates; wherein each of themultiple templates comprises a concatenation of one or more words; processing each ofmultiple log records derived from a data stream to determine a composition of each of themultiple log records; matching one or more of the generated template signatures to each ofthe multiple log records based on the determined composition of each of the multiple logrecords; and outputting an identification of (i) each of the multiple log records and (ii) the oneor more generated template signatures matched thereto.,*,2017,*
Organizing On-Disk Layout of Index Structures to Support Historical Keyword Search Queries Over Temporally Evolving Data,*,Methods; systems; and computer program products for organizing on-disk layout of indexstructures are provided herein. A method includes organizing an on-disk corpus of dataindex structures; partitioning each data index structure into an active and/or latest state datapartition and an archived data partition; sub-partitioning each of the archived data partitionsinto sub-partitions based on exact lifespan of each data item; executing a search query thatincludes temporal predicates and keyword predicates across the corpus by: pruning acollection of identified items of data from the corpus that contain the keyword predicatesusing range metadata associated with the temporal predicates to generate a pruned list ofdata items; and performing a list intersection operation on the data index structures togenerate a list of common data items from the pruned list; retrieving the common data …,*,2017,*
Delivering personalized recommendations that relate to transactions on display,*,Provided are techniques for providing personalized recommendations. One or moretransactions are received from one or more customer interaction channels. The received oneor more transactions are stored in an incremental data store. One or more predictive rulesare generated based on the received one or more transactions and based on one or moretransactions previously stored in the incremental data store. In real-time; one or morepersonalized recommendations specific to a user and to the received one or moretransactions are generated using the one or more generated predictive rules.,*,2016,*
System and computer program product for deriving intelligence from activity logs,*,Techniques for segregating one or more logs of at least one multitasking user to derive atleast one behavioral pattern of the at least one multitasking user are provided. Thetechniques include obtaining at least one of at least one action log; configurationinformation; domain knowledge; at least one task history and open task repositoryinformation; correlating the at least one of at least one action log; configuration information;domain knowledge; at least one task history and open task repository information todetermine a task associated with each of one or more actions and segregate the one ormore logs based on the one or more actions; and using the one or more logs that have beensegregated to derive at least one behavioral pattern of the at least one multitasking user.Techniques are also provided for deriving intelligence from at least one activity log of at …,*,2016,*
Lifespan-based Partitioning of Index Structures for Time-travel Text Search,Animesh Nandi; Suriya Subramanian; Sriram Lakshminarasimhan; Prasad M Deshpande; Sriram Raghavan,Abstract Time-travel text search over a temporally evolving document collection is useful invarious applications. Supporting a wide range of query classes demanded by theseapplications require different index layouts optimized for their respective query accesspatterns. The problem we tackle is how to efficiently handle different query classes using thesame index layout. Our approach is to use list intersections on single-attribute indexes ofkeywords and temporal attributes. Although joint predicate evaluation on single-attributeindexes is inefficient in general; we show that partitioning the index based on versionlifespans coupled with exploiting the transaction-time ordering of record-identifiers; cansignificantly reduce the cost of list intersections.,Proceedings of the 24th ACM International on Conference on Information and Knowledge Management,2015,*
Fundamentals of Similarity Search,P Deepak; Prasad M Deshpande,Abstract This chapter presents various fundamental building blocks of a similarity searchsystem from the ground up. We start by introducing the attribute-based object representationthat is widely used for representing real-world entities on the web as well as in similaritysearch systems. We then describe the various attribute types as well as measures used toquantify similarity and dissimilarity for specific attribute types. We also touch upon theinterchangeability between the notions of similarity and dissimilarity; and illustrate thevarious transformations that could be applied to transform a similarity measure to a measureof dissimilarity.,*,2015,*
The Road Ahead,P Deepak; Prasad M Deshpande,Abstract As we have seen through this book; there has been a lot of recent work in enablingnewer forms of similarity search by defining novel operators. Arguably; the search for novelsimilarity search operators are as much an active area of research as indexing andefficiency considerations in similarity search systems.,*,2015,*
Categorizing Operators,P Deepak; Prasad M Deshpande,Abstract We consider categorization of similarity operators to aid easy positioning andassimilation of the semantics of different operators. The first classification puts operators inone of two classes based on whether it produces ordered or unordered result sets; whereasthe second considers the usage of attributes in the operator-specific similarityrepresentations for an object. We consider the implications of each of these choices andgive examples of operators that fall into each of these four classes. We then look at features;a set of tools that are available for the designer of any search system to add to operators totune the system to specific search needs. We outline the semantics of the result settransformation under each of these features; illustrate motivating scenarios for the usage ofsuch features; and list operators from literature that have made use of them. Through such …,*,2015,*
Indexing for Similarity Search Operators,P Deepak; Prasad M Deshpande,Abstract This chapter deviates from the semantics-oriented discussion in this book andconsiders the motivation for indexes and efficient algorithms for evaluating similarity queries.We start with the computationally simplest case of processing similarity queries over dataobjects in a Euclidean space where we illustrate the utility of the kd Tree to enable efficientsearch. We then relax the constraints and move to general metric spaces; where the triangleinequality becomes the most important property. We describe a commonly used index calledthe VP Tree for such a case. Finally; we consider the most general scenario where thedistance measure can be arbitrary. The only property assumed is the monotonicity of thedistance function. Here we consider two approaches—the family of Threshold algorithmsand the AL Tree based indexing method and show how they can be used for Top-k …,*,2015,*
Advanced Operators for Similarity Search,P Deepak; Prasad M Deshpande,Abstract This chapter targets to provide a reasonably comprehensive overview of the varioussimilarity search operators that have been proposed over the last one-and-a-half decades.We consider various advanced operators for similarity search under three heads;(a) thosethat build upon the weighted sum operation;(b) operators that enhance the basic skylineoperator and (c) other modes of similarity search not already covered under the first twoheads. We outline each similarity operator by describing the semantics of the operator;followed by a schematic example to illustrate the result set determination under the operator;and end by outlining real-world scenarios that motivate the usage of the operator. We covermore than thirty similarity operators in fair amount of detail in this chapter; forming anextensive overview of the state-of-the-art in similarity operators.,*,2015,*
Common Similarity Search Operators,P Deepak; Prasad M Deshpande,Abstract We present a simple framework for similarity search systems that enablesexpression of different similarity operators as a combination of aggregation and filterfunctions. We then describe the common aggregation functions such as weighted sum andN-Match followed by an overview of common filter functions including the threshold; top-kand skyline filters. We then illustrate how combinations of aggregation and filter functionsform some of the commonly used similarity search operators.,*,2015,*
Collaborative analytics with edge devices,*,Techniques; systems; and articles of manufacture for collaborative analytics with edgedevices. A method includes identifying multiple items of data pertaining to a user from one ormore user actions implemented across multiple user devices; identifying one or more rulesassociated with one or more user preferences; exchanging the multiple items of data acrossthe multiple user devices; and applying the one or more rules to the multiple items of dataacross the multiple user devices to generate an output via at least one of the multiple userdevices.,*,2015,*
Classification of an electronic document,*,A computer receives an electronic document that includes a group of terms. The computersends the electronic document to an information extraction program that extracts specificterms from the group of terms. Each of the specific terms that match to a certain extent withone of the attribute values in an electronic dictionary is identified. A value associated withthe electronic document is generated based on the specific terms that match; and on an end-user that is attempting to access the electronic document.,*,2014,*
Simultaneously improving CSAT and profit in a retail banking organization,Sameep Mehta; Ullas Nambiar; Vishal Batra; Sumit Negi; Prasad Deshpande; Gyana Praija,Abstract Customer satisfaction (CSAT) is the key driver for retention and growth in retailbanking and several techniques have been applied by banks to achieve this. For instance;banks in emerging markets with high footfall in branches have gone beyond the traditionalapproach of segmenting customers and services to optimizing the wait time for customersvisiting the bank's branch. While this approach has significantly improved service quality; ithas also added a new dimension in the service quality metric: pro-actively identify andaddress customer needs for (i) efficient banking experience and (ii) enhancing profit byselling additional services to existing customer. In this paper we present a system thataddresses the challenge involved in providing better service to retail banking customerwhile ensuring that a larger share of customer's wallet comes to the branch. We do this by …,Proceedings of the 20th ACM international conference on Information and knowledge management,2011,*
English-language translation of exact interpretations of keyword queries,*,The present invention relates to a methodology to translate exact interpretations of keywordqueries into meaningful and grammatically correct plain-language queries in order toconvey the meaning of these interpretations to the initiator of the search. The methodincludes the steps of generating at least one grammatically valid plain-language sentenceinterpretation for a keyword query form a generated sentence is based upon differingmatching elements; and presenting at least one grammatically valid plain-languagesentence interpretation for the keyword query to a keyword query system user for the user'sreview.,*,2008,*
Interactive Analytics,Yihong Zhao; Prasad M Deshpande; Jeffrey F Naughton An Array-Based,For decades; most database workloads have been partitioned into two categories:(1) manysmall “transaction processing” queries that do lookups and updates on a small number ofitems in a large database; and (2) fewer big “analytic” queries that summarize large volumesof data for analysis. This section is concerned with ideas for accelerating the secondcategory of queriesparticularly to answer them at interactive speeds; and allow forsummarization; exploration and visualization of data. Over the years there has been a greatdeal of buzzword bingo in industry to capture some or all of this latter workload; from“Decision Support Systems”(DSS) to “Online Analytic Processing”(OLAP) to “BusinessIntelligence”(BI) to “Dashboards” and more generally just “Analytics”. Billions of dollars ofrevenue have been associated with these labels over time; so marketers and industry …,*,*,*
RPC Package for Java,Prasad Deshpande; Avinash Sodani,Abstract Java is an object-oriented and interpreted language. Java object code is machineindependent and can be run by an interpreter running on any machine. Applets written inJava language can thus be downloaded and executed on any machine. We have providedan RPC package for Java so that Java applications can make remote calls to RPC servers.We have also provided functions so that both RPC clients and servers can be programmedin Java. We have used the underlying Sun RPC to implement RPC in Java.,*,*,*
pmd@ cs. wisc. edu,Prasad Deshpande,*,*,*,*
Model-Driven Development and Assembly of Content Management Applications,Michael Richmond; Prasad Deshpande; Brendan McNichols; Savitha Srinivasan; Vladimir Zbarsky,ABSTRACT The use of service-oriented development architectures can speed up businessapplication development allowing market changes to quickly be reflected in enterprisesoftware. We have developed a novel service-oriented development architecture andassociated tooling to support on model-driven development of content management basedapplications. This architecture supports the set of roles necessary for content management:Data Architect and Component Integrator. The data architect role is concerned withcapturing domain knowledge using tooling that supports visual repository schema designand data modeling in a disconnected mode. The Component Integrator role assemblesbusiness and process logic at a high level of abstraction; potentially without the need forspecialized coding skills. The challenge addressed by this approach is to bridge the gaps …,*,*,*
Bulletin of the Technical Committee on,PM Deshpande; JF Naughton; K Ramasamy; A Shukla; K Tufte; Y Zhao,*,*,*,*
Efficient Algorithms for Allocation Policies,Doug Burdick; Prasad M Deshpande; TS Jayram; Raghu Ramakrishnan; Shivakumar Vaithyanathan,ABSTRACT Recent work proposed extending the OLAP data model to support dataambiguity; specifically imprecision and uncertainty. A process called allocation wasproposed to transform a given imprecise fact table into a form; called the ExtendedDatabase; that can be readily used to answer OLAP aggregation queries. In this work; wepresent scalable; efficient algorithms for creating the Extended Data Model (ie; performingallocation) for a given imprecise fact table. Many allocation policies require multipleiterations over the imprecise fact table; and the straightforward evaluation approachesintroduced earlier can be highly inefficient. Optimizing iterative allocation policies for largedatasets presents novel challenges; and has not been considered previously to the best ofour knowledge. In addition to developing scalable allocation algorithms; we present a …,*,*,*
Set-Valued Attributes in O/R DBMS: Implementation Options and Performance Implications,Karthikeyan Ramasamy; Prasad M Deshpande; Jeffrey F Naughton; David Maier,ABSTRACT Although adding set-valued attributes to relational database managementsystems is certainly not a new idea; it is only recently that set-valued attributes have made itto the main-stream of the O/R DBMS world. All the major O/R DBMS vendors either currentlysupport or will support set-valued attributes in their universal servers; furthermore; set-valued attributes are a significant new component of the SQL3 standard. While sets havereceived a good deal of attention in the database modeling and language design literature;to date there has been very little written on implementation options for sets and how theseoptions impact performance. As a first step toward filling this gap we have implemented andanalyzed two broad categories of storage representations for set-valued attributes---Inlinedand External---in an object-relational DBMS. Our experiments show that external …,*,*,*
Data Engineering,PM Deshpande; JF Naughton; K Ramasamy; A Shukla; K Tufte; Y Zhao,Abstract “OLAP” or multi-dimensional analysis workloads present a number of interestingchallenges and opportunities for database developers and researchers. While the OLAPgoal of extremely fast response times is hard to meet in general; the structure of theunderlying multidimensional model (whether implemented by arrays or by tables) provides aframework that can be used to approach this performance goal for this class of queries. Inthis note we give an overview of our research into these problems.,*,*,*
