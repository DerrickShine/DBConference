Resisting structural re-identification in anonymized social networks,Michael Hay; Gerome Miklau; David Jensen; Don Towsley; Philipp Weis,Abstract We identify privacy risks associated with releasing network data sets and providean algorithm that mitigates those risks. A network consists of entities connected by linksrepresenting relations such as friendship; communication; or shared activity. Maintainingprivacy when publishing networked data is uniquely challenging because an individual'snetwork context can be used to identify them even if other identifying information is removed.In this paper; we quantify the privacy risks associated with three classes of attacks on theprivacy of individuals in networks; based on the knowledge used by the adversary. We showthat the risks of these attacks vary greatly based on network structure and size. We proposea novel approach to anonymizing network data that models aggregate network structure andthen allows samples to be drawn from that model. The approach guarantees anonymity …,Proceedings of the VLDB Endowment,2008,518
Anonymizing social networks,Michael Hay; Gerome Miklau; David Jensen; Philipp Weis; Siddharth Srivastava,Abstract Advances in technology have made it possible to collect data about individuals andthe connections between them; such as email correspondence and friendships. Agenciesand researchers who have collected such social network data often have a compellinginterest in allowing others to analyze the data. However; in many cases the data describesrelationships that are private (eg; email correspondence) and sharing the data in full canresult in unacceptable disclosures. In this paper; we present a framework for assessing theprivacy risk of sharing anonymized network data. This includes a model of adversaryknowledge; for which we consider several variants and make connections to known graphtheoretical results. On several real-world social networks; we show that simpleanonymization techniques are inadequate; resulting in substantial breaches of privacy for …,Computer Science Department Faculty Publication Series,2007,377
Boosting the accuracy of differentially private histograms through consistency,Michael Hay; Vibhor Rastogi; Gerome Miklau; Dan Suciu,Abstract We show that it is possible to significantly improve the accuracy of a general classof histogram queries while satisfying differential privacy. Our approach carefully chooses aset of queries to evaluate; and then exploits consistency constraints that should hold overthe noisy output. In a post-processing phase; we compute the consistent input most likely tohave produced the noisy output. The final output is differentially-private and consistent; butin addition; it is often much more accurate. We show; both theoretically and experimentally;that these techniques can be used for estimating the degree sequence of a graph veryprecisely; and for computing a histogram that can support arbitrary range queries accurately.,Proceedings of the VLDB Endowment,2010,348
Learning relational probability trees,Jennifer Neville; David Jensen; Lisa Friedland; Michael Hay,Abstract Classification trees are widely used in the machine learning and data miningcommunities for modeling propositional data. Recent work has extended this basicparadigm to probability estimation trees. Traditional tree learning algorithms assume thatinstances in the training data are homogenous and independently distributed. Relationalprobability trees (RPTs) extend standard probability estimation trees to a relational setting inwhich data instances are heterogeneous and interdependent. Our algorithm for learning thestructure and parameters of an RPT searches over a space of relational features that useaggregation functions (eg A VERAGE; M ODE; C OUNT) to dynamically propositionalizerelational data and create binary splits within the RPT. Previous work has identified anumber of statistical biases due to characteristics of relational data such as …,Proceedings of the ninth ACM SIGKDD international conference on Knowledge discovery and data mining,2003,259
Optimizing linear counting queries under differential privacy,Chao Li; Michael Hay; Vibhor Rastogi; Gerome Miklau; Andrew McGregor,Abstract Differential privacy is a robust privacy standard that has been successfully appliedto a range of data analysis tasks. But despite much recent work; optimal strategies foranswering a collection of related queries are not known. We propose the matrix mechanism;a new algorithm for answering a workload of predicate counting queries. Given a workload;the mechanism requests answers to a different set of queries; called a query strategy; whichare answered using the standard Laplace mechanism. Noisy answers to the workloadqueries are then derived from the noisy answers to the strategy queries. This two stageprocess can result in a more complex correlated noise distribution that preserves differentialprivacy but increases accuracy.,Proceedings of the twenty-ninth ACM SIGMOD-SIGACT-SIGART symposium on Principles of database systems,2010,244
Accurate estimation of the degree distribution of private networks,Michael Hay; Chao Li; Gerome Miklau; David Jensen,We describe an efficient algorithm for releasing a provably private estimate of the degreedistribution of a network. The algorithm satisfies a rigorous property of differential privacy;and is also extremely efficient; running on networks of 100 million nodes in a few seconds.Theoretical analysis shows that the error scales linearly with the number of unique degrees;whereas the error of conventional techniques scales linearly with the number of nodes. Wecomplement the theoretical analysis with a thorough empirical analysis on real and syntheticgraphs; showing that the algorithm's variance and bias is low; that the error diminishes asthe size of the input graph increases; and that common analyses like fitting a power-law canbe carried out very accurately.,Data Mining; 2009. ICDM'09. Ninth IEEE International Conference on,2009,179
An integrated; conditional model of information extraction and coreference with application to citation matching,Ben Wellner; Andrew McCallum; Fuchun Peng; Michael Hay,Abstract Although information extraction and coreference resolution appear together inmany applications; most current systems perform them as independent steps. This paperdescribes an approach to integrated inference for extraction and coreference based onconditionally-trained undirected graphical models. We discuss the advantages of conditionalprobability training; and of a coreference model structure based on graph partitioning. On adata set of research paper citations; we show significant reduction in error by usingextraction uncertainty to improve coreference citation matching accuracy; and usingcoreference to improve the accuracy of the extracted fields.,Proceedings of the 20th conference on Uncertainty in artificial intelligence,2004,164
Relationship privacy: output perturbation for queries with joins,Vibhor Rastogi; Michael Hay; Gerome Miklau; Dan Suciu,Abstract We study privacy-preserving query answering over data containing relationships. Asocial network is a prime example of such data; where the nodes represent individuals andedges represent relationships. Nearly all interesting queries over social networks involvejoins; and for such queries; existing output perturbation algorithms severely distort queryanswers. We propose an algorithm that significantly improves utility over competingtechniques; typically reducing the error bound from polynomial in the number of nodes topolylogarithmic. The algorithm is; to the best of our knowledge; the first to answer suchqueries with acceptable accuracy; even for worst-case inputs. The improved utility isachieved by relaxing the privacy condition. Instead of ensuring strict differential privacy; weguarantee a weaker (but still quite practical) condition based on adversarial privacy. To …,Proceedings of the twenty-eighth ACM SIGMOD-SIGACT-SIGART symposium on Principles of database systems,2009,110
iReduct: Differential privacy with reduced relative errors,Xiaokui Xiao; Gabriel Bender; Michael Hay; Johannes Gehrke,Abstract Prior work in differential privacy has produced techniques for answering aggregatequeries over sensitive data in a privacy-preserving way. These techniques achieve privacyby adding noise to the query answers. Their objective is typically to minimize absolute errorswhile satisfying differential privacy. Thus; query answers are injected with noise whose scaleis independent of whether the answers are large or small. The noisy results for querieswhose true answers are small therefore tend to be dominated by noise; which leads toinferior data utility. This paper introduces iReduct; a differentially private algorithm forcomputing answers with reduced relative error. The basic idea of iReduct is to inject differentamounts of noise to different query results; so that smaller (larger) values are more likely tobe injected with less (more) noise. The algorithm is based on a novel resampling …,Proceedings of the 2011 ACM SIGMOD International Conference on Management of data,2011,105
Resisting structural re-identification in anonymized social networks,Michael Hay; Gerome Miklau; David Jensen; Don Towsley; Chao Li,Abstract We identify privacy risks associated with releasing network datasets and provide analgorithm that mitigates those risks. A network dataset is a graph representing entitiesconnected by edges representing relations such as friendship; communication or sharedactivity. Maintaining privacy when publishing a network dataset is uniquely challengingbecause an individual's network context can be used to identify them even if other identifyinginformation is removed. In this paper; we introduce a parameterized model of structuralknowledge available to the adversary and quantify the success of attacks on individuals inanonymized networks. We show that the risks of these attacks vary based on networkstructure and size and provide theoretical results that explain the anonymity risk in randomnetworks. We then propose a novel approach to anonymizing network data that models …,The VLDB Journal—The International Journal on Very Large Data Bases,2010,80
Crowd-blending privacy,Johannes Gehrke; Michael Hay; Edward Lui; Rafael Pass,Abstract We introduce a new definition of privacy called crowd-blending privacy that strictlyrelaxes the notion of differential privacy. Roughly speaking; k-crowd blending privatesanitization of a database requires that each individual i in the database “blends” with kother individuals j in the database; in the sense that the output of the sanitizer is“indistinguishable” if i's data is replaced by j's. We demonstrate crowd-blending privatemechanisms for histograms and for releasing synthetic data points; achieving strictly betterutility than what is possible using differentially private mechanisms. Additionally; wedemonstrate that if a crowd-blending private mechanism is combined with a “pre-sampling”step; where the individuals in the database are randomly drawn from some underlyingpopulation (as is often the case during data collection); then the combined mechanism …,*,2012,63
Exploiting relational structure to understand publication patterns in high-energy physics,Amy McGovern; Lisa Friedland; Michael Hay; Brian Gallagher; Andrew Fast; Jennifer Neville; David Jensen,Abstract We analyze publication patterns in theoretical high-energy physics using arelational learning approach. We focus on four related areas: understanding and identifyingpatterns of citations; examining publication patterns at the author level; predicting whether apaper will be accepted by specific journals; and identifying research communities from thecitation patterns and paper text. Each of these analyses contributes to an overallunderstanding of theoretical high-energy physics.,ACM SIGKDD Explorations Newsletter,2003,61
A data-and workload-aware algorithm for range queries under differential privacy,Chao Li; Michael Hay; Gerome Miklau; Yue Wang,Abstract We describe a new algorithm for answering a given set of range queries under ε-differential privacy which often achieves substantially lower error than competing methods.Our algorithm satisfies differential privacy by adding noise that is adapted to the input dataand to the given query set. We first privately learn a partitioning of the domain into bucketsthat suit the input data well. Then we privately estimate counts for each bucket; doing so in amanner well-suited for the given query set. Since the performance of the algorithm dependson the input database; we evaluate it on a wide range of real datasets; showing that we canachieve the benefits of data-dependence on both" easy" and" hard" databases.,Proceedings of the VLDB Endowment,2014,55
Avoiding bias when aggregating relational data with degree disparity,David Jensen; Jennifer Neville; Michael Hay,*,Proceedings of the 20th International Conference on Machine Learning (ICML-03),2003,44
Principled evaluation of differentially private algorithms using dpbench,Michael Hay; Ashwin Machanavajjhala; Gerome Miklau; Yan Chen; Dan Zhang,Abstract Differential privacy has become the dominant standard in the research communityfor strong privacy protection. There has been a flood of research into query answeringalgorithms that meet this standard. Algorithms are becoming increasingly complex; and inparticular; the performance of many emerging algorithms is data dependent; meaning thedistribution of the noise added to query answers may change depending on the input data.Theoretical analysis typically only considers the worst case; making empirical study ofaverage case performance increasingly important. In this paper we propose a set ofevaluation principles which we argue are essential for sound evaluation. Based on theseprinciples we propose DPBench; a novel evaluation framework for standardized evaluationof privacy algorithms. We then apply our benchmark to evaluate algorithms for answering …,Proceedings of the 2016 International Conference on Management of Data,2016,38
Privacy-aware data management in information networks,Michael Hay; Kun Liu; Gerome Miklau; Jian Pei; Evimaria Terzi,Abstract The proliferation of information networks; as a means of sharing information; hasraised privacy concerns for enterprises who manage such networks and for individual usersthat participate in such networks. For enterprises; the main challenge is to satisfy twocompeting goals: releasing network data for useful data analysis and also preserving theidentities or sensitive relationships of the individuals participating in the network. Individualusers; on the other hand; require personalized methods that increase their awareness of thevisibility of their private information.,Proceedings of the 2011 ACM SIGMOD International Conference on Management of data,2011,21
The matrix mechanism: optimizing linear counting queries under differential privacy,Chao Li; Gerome Miklau; Michael Hay; Andrew McGregor; Vibhor Rastogi,Abstract Differential privacy is a robust privacy standard that has been successfully appliedto a range of data analysis tasks. We describe the matrix mechanism; an algorithm foranswering a workload of linear counting queries that adapts the noise distribution toproperties of the provided queries. Given a workload; the mechanism uses a different set ofqueries; called a query strategy; which are answered using a standard Laplace or Gaussianmechanism. Noisy answers to the workload queries are then derived from the noisy answersto the strategy queries. This two-stage process can result in a more complex; correlatednoise distribution that preserves differential privacy but increases accuracy. We provide aformal analysis of the error of query answers produced by the mechanism and investigatethe problem of computing the optimal query strategy in support of a given workload. We …,The VLDB journal,2015,20
Enabling accurate analysis of private network data,Michael G Hay,Abstract This dissertation addresses the challenge of enabling accurate analysis of networkdata while ensuring the protection of network participants' privacy. This is an importantproblem: massive amounts of data are being collected (facebook activity; emailcorrespondence; cell phone records); there is huge interest in analyzing the data; but thedata is not being shared due to concerns about privacy. Despite much research in privacy-preserving data analysis; existing technologies fail to provide a solution because they weredesigned for tables; not networks; and cannot be easily adapted to handle the complexitiesof network data.,*,2010,13
Pythia: Data dependent differentially private algorithm selection,Ios Kotsogiannis; Ashwin Machanavajjhala; Michael Hay; Gerome Miklau,Abstract Differential privacy has emerged as a preferred standard for ensuring privacy inanalysis tasks on sensitive datasets. Recent algorithms have allowed for significantly lowererror by adapting to properties of the input data. These so-called data-dependent algorithmshave different error rates for different inputs. There is now a complex and growing landscapeof algorithms without a clear winner that can offer low error over all datasets. As a result; thebest possible error rates are not attainable in practice; because the data curator cannotknow which algorithm to select prior to actually running the algorithm. We address thischallenge by proposing a novel meta-algorithm designed to relieve the data curator of theburden of algorithm selection. It works by learning (from non-sensitive data) the associationbetween dataset properties and the best-performing algorithm. The meta-algorithm is …,Proceedings of the 2017 ACM International Conference on Management of Data,2017,8
Analyzing private network data,Michael Hay; Gerome Miklau; David Jensen,Many phenomena can be modeled as networks in which entities (represented by nodes)participate in binary relationships (represented by edges). In a social network; nodes areindividuals and edges are personal contacts or relationships. In a communication network;nodes are individuals and edges are flows of information such as phone calls or emailmessages. In a technological network; nodes are machines; such as computers or powerstations; and edges are some means of transmission. Research into the structure andfunction of networks has wide-ranging applications. Network analysis is being used bybusinesses to market products [31]; by epidemiologists to combat the spread of diseases[32]; and by financial regulatory agencies to detect fraud among securities dealers [20].Network analysis has also been applied to national security; industrial engineering; and …,Privacy-Aware Knowledge Discovery: Novel Applications and New Techniques,2010,4
Understanding the effects of search constraints on structure learning,Michael Hay; Andrew Fast; David Jensen,Abstract Recently; Tsamardinos et al.[2006] presented an algorithm for Bayesian networkstructure learning that outperforms many state-of-the-art algorithms in terms of efficiency;structure similarity and likelihood. The Max-Min Hill Climbing algorithm is a hybrid ofconstraint-based and search-and-score techniques; using greedy hill climbing to search aconstrained space of possible network structures. The constraints correspond to assertionsof conditional independence that must hold in the network from which the data weresampled. One would expect that constraining the space would make search both faster andmore accurate; focusing search on the “right” part of the space. The published resultsindicate; however; that the resulting structures are less accurate when search is constrained.We reproduce these results and explain why they occur. At small samples; the statistical …,U Mass. Amherst CS; Tech. Rep,2007,4
Improving accuracy of constraint-based structure learning,Andrew Fast; Michael Hay; David Jensen,Abstract Hybrid algorithms for learning the structure of Bayesian networks combinetechniques from both the constraintbased and search-and-score paradigms of structurelearning. One class of hybrid approaches uses a constraintbased algorithm to learn anundirected skeleton identifying edges that should appear in the final network. This skeletonis used to constrain the model space considered by a search-and-score algorithm to orientthe edges and produce a final model structure. At small sample sizes; the performance ofmodels learned using this hybrid approach do not achieve likelihood as high as modelslearned by unconstrained search. Low performance is a result of errors made by theskeleton identification algorithm; particularly false negative errors; which lead to an over-constrained search space. These errors are often attributed to “noisy” hypothesis tests …,*,2008,3
Differential privacy in the wild: A tutorial on current practices & open challenges,Ashwin Machanavajjhala; Xi He; Michael Hay,Abstract Differential privacy has emerged as an important standard for privacy preservingcomputation over databases containing sensitive information about individuals. Researchon differential privacy spanning a number of research areas; including theory; security;database; networks; machine learning; and statistics; over the last decade has resulted in avariety of privacy preserving algorithms for a number of analysis tasks. Despite maturingresearch efforts; the adoption of differential privacy by practitioners in industry; academia; orgovernment agencies has so far been rare. Hence; in this tutorial; we will first describe thefoundations of differentially private algorithm design that cover the state of the art in privatecomputation on tabular data. In the second half of the tutorial we will highlight real worldapplications on complex data types; and identify research challenges in applying …,Proceedings of the VLDB Endowment,2016,2
Exploring Privacy-Accuracy Tradeoffs using DPComp,Michael Hay; Ashwin Machanavajjhala; Gerome Miklau; Yan Chen; Dan Zhang; George Bissias,Abstract The emergence of differential privacy as a primary standard for privacy protectionhas led to the development; by the research community; of hundreds of algorithms forvarious data analysis tasks. Yet deployment of these techniques has been slowed by thecomplexity of algorithms and an incomplete understanding of the cost to accuracy implied bythe adoption of differential privacy. In this demonstration we present DPComp; a publicly-accessible web-based system; designed to support a broad community of users; includingdata analysts; privacy researchers; and data owners. Users can use DPComp to assess theaccuracy of state-of-the-art privacy algorithms and interactively explore algorithm output inorder to understand; both quantitatively and qualitatively; the error introduced by thealgorithms. In addition; users can contribute new algorithms and new (non-sensitive) …,Proceedings of the 2016 International Conference on Management of Data,2016,1
Optimizing histogram queries under differential privacy,Chao Li; Michael Hay; Vibhor Rastogi; Gerome Miklau; Andrew McGregor,ABSTRACT Differential privacy is a robust privacy standard that has been successfullyapplied to a range of data analysis tasks. Despite much recent work; optimal strategies foranswering a collection of correlated queries are not known. We study the problem ofdevising a set of strategy queries; to be submitted and answered privately; that will supportthe answers to a given workload of queries. We propose a general framework in whichquery strategies are formed from linear combinations of counting queries; and we describean optimal method for deriving new query answers from the answers to the strategy queries.Using this framework we characterize the error of strategies geometrically; and we proposesolutions to the problem of finding optimal strategies.,*,*,1
PeGaSus: Data-Adaptive Differentially Private Stream Processing,Yan Chen; Ashwin Machanavajjhala; Michael Hay; Gerome Miklau,Abstract Individuals are continually observed by an ever-increasing number of sensors thatmake up the Internet of Things. The resulting streams of data; which are analyzed in realtime; can reveal sensitive personal information about individuals. Hence; there is an urgentneed for stream processing solutions that can analyze these data in real time with provableguarantees of privacy and low error. We present PeGaSus; a new algorithm for differentiallyprivate stream processing. Unlike prior work that has focused on answering individualqueries over streams; our algorithm is the first that can simultaneously support a variety ofstream processing tasks--counts; sliding windows; event monitoring--over multipleresolutions of the stream. PeGaSus uses a Perturber to release noisy counts; a data-adaptive Perturber to identify stable uniform regions in the stream; and a query specific …,Proceedings of the 2017 ACM SIGSAC Conference on Computer and Communications Security,2017,*
Differentially Private Rank Aggregation,Michael Hay; Liudmila Elagina; Gerome Miklau,Abstract Given a collection of rankings of a set of items; rank aggregation seeks to computea ranking that can serve as a single best representative of the collection. Rank aggregationis a well-studied problem and a number of effective algorithmic solutions have beenproposed in the literature. However; when individuals are asked to contribute a ranking; theymay be concerned that their personal preferences will be disclosed inappropriately toothers. This acts as a disincentive to individuals to respond honestly in expressing theirpreferences and impedes data collection and data sharing. We address this problem byinvestigating rank aggregation under differential privacy; which requires that a releasedoutput (here; the aggregate ranking computed from individuals' rankings) remain almost thesame if any one individual's ranking is removed from the input. We propose a number of …,*,2017,*
Differentially Private Learning of Undirected Graphical Models Using Collective Graphical Models,Garrett Bernstein; Ryan McKenna; Tao Sun; Daniel Sheldon; Michael Hay; Gerome Miklau,Abstract: We investigate the problem of learning discrete; undirected graphical models in adifferentially private way. We show that the approach of releasing noisy sufficient statisticsusing the Laplace mechanism achieves a good trade-off between privacy; utility; andpracticality. A naive learning algorithm that uses the noisy sufficient statistics" as is"outperforms general-purpose differentially private learning algorithms. However; it has threelimitations: it ignores knowledge about the data generating process; rests on uncertaintheoretical foundations; and exhibits certain pathologies. We develop a more principledapproach that applies the formalism of collective graphical models to perform inference overthe true sufficient statistics within an expectation-maximization framework. We show that thislearns better models than competing approaches on both synthetic data and on real …,arXiv preprint arXiv:1706.04646,2017,*
DIAS: Differentially Private Interactive Algorithm Selection using Pythia,Ios Kotsogiannis; Michael Hay; Ashwin Machanavajjhala; Gerome Miklau; Margaret Orr,Abstract Differential privacy has emerged as the dominant privacy standard for dataanalysis. Its wide acceptance has led to significant development of algorithms that meet thisrigorous standard. For some tasks; such as the task of answering low dimensional countingqueries; dozens of algorithms have been proposed. However; no single algorithm hasemerged as the dominant performer; and in fact; algorithm performance varies drasticallyacross inputs. Thus; it's not clear how to select an algorithm for a particular task; andchoosing the wrong algorithm might lead to significant degradation in terms of analysisaccuracy. We believe that the difficulty of algorithm selection is one factor limiting theadoption of differential privacy in real systems. In this demonstration we present DIAS(Differentially-private Interactive Algorithm Selection); an educational privacy game …,Proceedings of the 2017 ACM International Conference on Management of Data,2017,*
How PhD students at research universities can prepare for a career at a liberal arts college,Ann Irvine; Darakhshan Mir; Michael Hay,Abstract We will discuss how to better organize as graduate students and postdoctoralresearchers seeking a career in liberal arts colleges (LACs). The BoF will bring togetherthose who are interested in a career path to a LAC but do not have reliable advice andmentorship in their home departments and often turn out to be the only person in theirdepartment with such a career choice. Additionally; several people who have recently madea successful transition from graduate school to new faculty positions will attend the BoF.,Proceeding of the 44th ACM technical symposium on Computer science education,2013,*
Identifying Independence in Relational Models,Marc Maier; David Jensen,Abstract The rules of d-separation provide a framework for deriving conditionalindependence facts from model structure. However; this theory only applies to simpledirected graphical models. We introduce relational d-separation; a theory for derivingconditional independence in relational models. We provide a sound; complete; andcomputationally efficient method for relational d-separation; and we present empirical resultsthat demonstrate effectiveness.,arXiv preprint arXiv:1206.3536,2012,*
Principled Evaluation of Differentially Private Algorithms,Michael Hay; Ashwin Machanavajjhala; Gerome Miklau; Yan Chen; Dan Zhang,Abstract The emergence of differential privacy as a primary standard for privacy protectionhas led to the development of hundreds of algorithms for various data analysis tasks. Thesealgorithms are becoming increasingly complex; and in particular; the performance of manyemerging algorithms is data dependent; meaning the distribution of the noise added toquery answers may change depending on the input data. Theoretical analysis typically onlyconsiders the worst case; making empirical study of average case performance increasinglyimportant. We propose a set of evaluation principles which we argue are essential for soundevaluation. Based on these principles we propose DPBENCH; a novel evaluation frameworkfor standardized evaluation of privacy algorithms. We then apply our benchmark to evaluatealgorithms for answering 1-and 2-dimensional range queries. The result is a thorough …,*,*,*
Challenges of Visualizing Differentially Private Data,Dan Zhang; Michael Hay; Gerome Miklau; Brendan O’Connor,ABSTRACT Differential privacy has become a primary standard for protecting individual datawhile supporting flexible data analysis. Despite the adaptation of differential privacy to awide variety of applications and tasks; visualizing the output of differentially privatealgorithms has rarely been considered. Visualization is one of the primary means by whichhumans understand and explore an unknown dataset and therefore supporting visualizationis an important goal to advance the practical adoption of differential privacy. In this initialwork on private data visualization we explore key challenges and propose solutionapproaches. We use two-dimensional location data as an example domain; and considerthe challenges of plotting noisy output; the impact of visual artifacts caused by noise; and theproper way to present known uncertainty about private output.,*,*,*
