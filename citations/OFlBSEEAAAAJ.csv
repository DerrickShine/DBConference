Frontiers; challenges; and opportunities for information retrieval: Report from SWIRL 2012 the second strategic workshop on information retrieval in Lorne,James Allan; Bruce Croft; Alistair Moffat; Mark Sanderson,Abstract During a three-day workshop in February 2012; 45 Information Retrievalresearchers met to discuss long-range challenges and opportunities within the field. Theresult of the workshop is a diverse set of research directions; project ideas; and challengeareas. This report describes the workshop format; provides summaries of broad themes thatemerged; includes brief descriptions of all the ideas; and provides detailed discussion of sixproposals that were voted" most interesting" by the participants. Key themes include theneed to: move beyond ranked lists of documents to support richer dialog and presentation;represent the context of search and searchers; provide richer support for informationseeking; enable retrieval of a wide range of structured and unstructured content; anddevelop new evaluation methodologies.,ACM SIGIR Forum,2012,113
Efficient syntheses of the marine alkaloids makaluvamine D and discorhabdin C: the 4; 6; 7-trimethoxyindole approach,Eyyani V Sadanandan; Sasi K Pillai; MV Lakshmikantham; Adil D Billimoria; J Shane Culpepper; Michael P Cava,A new and efficient synthesis of the tricyclic quinonimine 20 as its trifluoroacetate 23 hasbeen developed starting from the commercially available 2; 4; 5-trimethoxybenzaldehydeand proceeding via the hitherto unknown 4; 6; 7-trimethoxyindole (7). Quinonimine 23 is thelate stage key intermediate in several previously reported syntheses of the biologicallyactive pyrrolo [4; 3; 2-delquinoline marine alkaloids discorhabdin C (1) and makaluvamine D(3). In recent years; much attention has been focused upon the isolation and structuredetermination of biologically active materials from marine sources. One of the mostinteresting classes of compounds is the structurally varied group of alkaloids containing thepyrrolo [4; 3; 2-delquinoline nucleus. These include the discorhabdins;'prianosins; 2 damir~nes;~ bat~ ellins;~ is~ batzellins;~ makaluvamines; 6 and~ akayin.~ Many of these …,The Journal of Organic Chemistry,1995,80
Efficient set intersection for inverted indexing,J Shane Culpepper; Alistair Moffat,Abstract Conjunctive Boolean queries are a key component of modern information retrievalsystems; especially when Web-scale repositories are being searched. A conjunctive query qis equivalent to a &verbar; q&verbar;-way intersection over ordered sets of integers; whereeach set represents the documents containing one of the terms; and each integer in each setis an ordinal document identifier. As is the case with many computing applications; there istension between the way in which the data is represented; and the ways in which it is to bemanipulated. In particular; the sets representing index data for typical document collectionsare highly compressible; but are processed using random access techniques; meaning thatmethods for carrying out set intersections must be alert to issues to do with access patternsand data representation. Our purpose in this article is to explore these trade-offs; by …,ACM Transactions on Information Systems (TOIS),2010,79
Top-k ranked document search in general text databases,J Shane Culpepper; Gonzalo Navarro; Simon J Puglisi; Andrew Turpin,Abstract Text search engines return a set of k documents ranked by similarity to a query.Typically; documents and queries are drawn from natural language text; which can readilybe partitioned into words; allowing optimizations of data structures and algorithms forranking. However; in many new search domains (DNA; multimedia; OCR texts; Far Eastlanguages) there is often no obvious definition of words and traditional indexing approachesare not so easily adapted; or break down entirely. We present two new algorithms forranking documents against a query without making any assumptions on the structure of theunderlying text. We build on existing theoretical techniques; which we have implementedand compared empirically with new approaches introduced in this paper. Our best approachis significantly faster than existing methods in RAM; and is even three times faster than a …,European Symposium on Algorithms,2010,71
Including summaries in system evaluation,Andrew Turpin; Falk Scholer; Kalvero Jarvelin; Mingfang Wu; J Shane Culpepper,Abstract In batch evaluation of retrieval systems; performance is calculated based onpredetermined relevance judgements applied to a list of documents returned by the systemfor a query. This evaluation paradigm; however; ignores the current standard operation ofsearch systems which require the user to view summaries of documents prior to reading thedocuments themselves. In this paper we modify the popular IR metrics MAP and P@ 10 toincorporate the summary reading step of the search process; and study the effects on systemrankings using TREC data. Based on a user study; we establish likely disagreementsbetween relevance judgements of summaries and of documents; and use these values toseed simulations of summary relevance in the TREC data. Re-evaluating the runs submittedto the TREC Web Track; we find the average correlation between system rankings and …,Proceedings of the 32nd international ACM SIGIR conference on Research and development in information retrieval,2009,59
Enhanced byte codes with restricted prefix properties,J Shane Culpepper; Alistair Moffat,Abstract Byte codes have a number of properties that make them attractive for practicalcompression systems: they are relatively easy to construct; they decode quickly; and theycan be searched using standard byte-aligned string matching techniques. In this paper wedescribe a new type of byte code in which the first byte of each codeword completelyspecifies the number of bytes that comprise the suffix of the codeword. Our mechanism givesmore flexible coding than previous constrained byte codes; and hence better compression.The structure of the code also suggests a heuristic approximation that allows savings to bemade in the prelude that describes the code. We present experimental results that compareour new method with previous approaches to byte coding; in terms of both compressioneffectiveness and decoding throughput speeds.,International Symposium on String Processing and Information Retrieval,2005,46
Compact set representation for information retrieval,J Shane Culpepper; Alistair Moffat,Abstract Conjunctive Boolean queries are a fundamental operation in web search engines.These queries can be reduced to the problem of intersecting ordered sets of integers; whereeach set represents the documents containing one of the query terms. But there is tensionbetween the desire to store the lists effectively; in a compressed form; and the desire to carryout intersection operations efficiently; using non-sequential processing modes. In this paperwe evaluate intersection algorithms on compressed sets; comparing them to the best non-sequential array-based intersection algorithms. By adding a simple; low-cost; auxiliaryindex; we show that compressed storage need not hinder efficient and high-speedintersection operations.,International Symposium on String Processing and Information Retrieval,2007,39
Efficient in-memory top-k document retrieval,J Shane Culpepper; Matthias Petri; Falk Scholer,Abstract For over forty years the dominant data structure for ranked document retrieval hasbeen the inverted index. Inverted indexes are effective for a variety of document retrievaltasks; and particularly efficient for large data collection scenarios that require disk accessand storage. However; many efficiency-bound search tasks can now easily be supportedentirely in memory as a result of recent hardware advances. In this paper we present ahybrid algorithmic framework for in-memory bag of-words ranked document retrieval using aself-index derived from the FM-Index; wavelet tree; and the compressed suffix tree datastructures; and evaluate the various algorithmic trade-offs for performing efficient queriesentirely in-memory. We compare our approach with two classic approaches to bag-of-wordsqueries using inverted indexes; term-at-a-time (TAAT) and document-at-a-time (DAAT) …,Proceedings of the 35th international ACM SIGIR conference on Research and development in information retrieval,2012,31
Exploring the magic of WAND,Matthias Petri; J Shane Culpepper; Alistair Moffat,Abstract Web search services process thousands of queries per second; and filter theiranswers from collections containing very large amounts of data. Fast response to queries isa critical service expectation. The well-known WAND processing strategy is one way ofreducing the amount of computation necessary when executing such a query. The value ofWAND has now been validated in a wide range of studies; and has become one of the keybaselines against which all new top-k processing algorithms are benchmarked. However;most previous implementations of WAND-based retrieval approaches have been in thecontext of the BM25 Okapi similarity scoring regime. Here we measure the performance ofWAND in the context of the alternative Language Model similarity score computation; andfind that the dramatic efficiency gains reported in previous studies are no longer …,Proceedings of the 18th Australasian Document Computing Symposium,2013,19
The effect of pooling and evaluation depth on IR metrics,Xiaolu Lu; Alistair Moffat; J Shane Culpepper,Abstract Batch IR evaluations are usually performed in a framework that consists of adocument collection; a set of queries; a set of relevance judgments; and one or moreeffectiveness metrics. A large number of evaluation metrics have been proposed; with twoprimary families having emerged: recall-based metrics; and utility-based metrics. In bothfamilies; the pragmatics of forming judgments mean that it is usual to evaluate the metric tosome chosen depth such as k= 20 k= 20 or k= 100 k= 100; without necessarily fullyconsidering the ramifications associated with that choice. Our aim is this paper is to explorethe relative risks arising with fixed-depth evaluation in the two families; and document thecomplex interplay between metric evaluation depth and judgment pooling depth. Using arange of TREC resources including NewsWire data and the ClueWeb collection; we:(1) …,Information Retrieval Journal,2016,18
Large-scale pattern search using reduced-space on-disk suffix arrays,Simon Gog; Alistair Moffat; J Shane Culpepper; Andrew Turpin; Anthony Wirth,The suffix array is an efficient data structure for in-memory pattern search. Suffix arrays canalso be used for external-memory pattern search; via two-level structures that use an internalindex to identify the correct block of suffix pointers. In this paper; we describe a new two-level suffix array-based index structure that requires significantly less disk space thanprevious approaches. Key to the saving is the use of disk blocks that are based on prefixesrather than the more usual uniform-sampling approach; allowing reductions between blocksand subparts of other blocks. We also describe a new in-memory structure-the condensedBWT-and show that it allows common patterns to be resolved without access to the text.Experiments using 64 GB of English web text on a computer with 4 GB of main memorydemonstrate the speed and versatility of the new approach. For this data; the index is …,IEEE Transactions on Knowledge and Data Engineering,2014,18
Open source information retrieval: a report on the SIGIR 2012 workshop,Andrew Trotman; Charles LA Clarke; Iadh Ounis; J. Shane Culpepper; Marc-Allen Cartright; Shlomo Geva,Abstract On August 16; 2012 the SIGIR 2012 Workshop on Open Source InformationRetrieval was held as part of the SIGIR 2012 conference in Portland; Oregon; USA. Therewere 2 invited talks; one from industry and one from academia. There were 6 full papers and6 short papers presented as well as demonstrations of 4 open source tools. Finally therewas a lively discussion on future directions for the open source Information Retrievalcommunity. This contribution discusses the events of the workshop and outlines futuredirections for the community.,ACM SIGIR Forum,2012,18
Efficient and effective realtime prediction of drive-by download attacks,Gaya K Jayasinghe; J Shane Culpepper; Peter Bertok,Abstract Drive-by download attacks are common attack vector for compromising personalcomputers. While several alternatives to mitigate the threat have been proposed;approaches to realtime detection of drive-by download attacks has been predominantlylimited to static and semi-dynamic analysis techniques. These techniques examine theoriginal or deobfuscated JavaScript source code to assess the potential maliciousness of awebpage. However; static and semi-dynamic analysis techniques are vulnerable tocommonly employed evasion techniques. Dynamic anomaly detection approaches are lesssusceptible to targeted evasion; but are used less often as a realtime solution on theindividual systems because these techniques are typically resource intensive. This paperpresents a novel approach to detect drive-by downloads in web browser environments …,Journal of Network and Computer Applications,2014,17
Assessing efficiency–effectiveness tradeoffs in multi-stage retrieval systems without using relevance judgments,Charles LA Clarke; J Shane Culpepper; Alistair Moffat,Abstract Large-scale retrieval systems are often implemented as a cascading sequence ofphases—a first filtering step; in which a large set of candidate documents are extractedusing a simple technique such as Boolean matching and/or static document scores; andthen one or more ranking steps; in which the pool of documents retrieved by the filter isscored more precisely using dozens or perhaps hundreds of different features. Thedocuments returned to the user are then taken from the head of the final ranked list. Here weexamine methods for measuring the quality of filtering and preliminary ranking stages; andshow how to use these measurements to tune the overall performance of the system.Standard top-weighted metrics used for overall system evaluation are not appropriate forassessing filtering stages; since the output is a set of documents; rather than an ordered …,Information Retrieval Journal,2016,15
Dynamic cutoff prediction in multi-stage retrieval systems,J Shane Culpepper; Charles LA Clarke; Jimmy Lin,Abstract Modern multi-stage retrieval systems are comprised of a candidate generationstage followed by one or more reranking stages. In such an architecture; the quality of thefinal ranked list may not be sensitive to the quality of the initial candidate pool; especially interms of early precision. This provides several opportunities to increase retrieval efficiencywithout significantly sacrificing effectiveness. In this paper; we explore a new approach todynamically predicting the size of an initial result set in the candidate generation stage;which can directly affect the overall efficiency and effectiveness of the entire system.Previous work exploring this tradeoff has focused on global parameter settings that apply toall queries; even though optimal settings vary across queries. In contrast; we propose atechnique that makes a parameter prediction to maximize efficiency within an …,Proceedings of the 21st Australasian Document Computing Symposium,2016,13
Hybrid bitvector index compression,Alistair Moffat; J Shane Culpepper,Abstract Bitvector index representations provide fast resolution of conjunctive Booleanqueries; but require a great deal of storage space. On the other hand; compressed indexrepresentations are space-efficient; but query evaluation tends to be slower than bitvectorevaluation; because of the need for sequential or pseudo-random access into thecompressed index lists. Here we investigate a simple hybrid mechanism that stores only asmall fraction of the inverted lists as bitvectors and has no or negligible effect oncompressed index size compared to the use of byte codes; but improves query processingthroughput compared to both byte coded representations and entirely-bitvectorarrangements.,proceedings of the 12th Australasian Document Computing Symposium (Melbourne; Australia December 2007),2007,13
A comparison of Document-at-a-Time and Score-at-a-Time query evaluation,Matt Crane; J Shane Culpepper; Jimmy Lin; Joel Mackenzie; Andrew Trotman,Abstract We present an empirical comparison between document-at-a-time (DaaT) andscore-at-a-time (SaaT) document ranking strategies within a common framework. Althoughboth strategies have been extensively explored; the literature lacks a fair; direct comparison:such a study has been difficult due to vastly different query evaluation mechanics and indexorganizations. Our work controls for score quantization; document processing; compression;implementation language; implementation effort; and a number of details; arriving at anempirical evaluation that fairly characterizes the performance of three specific techniques:WAND (DaaT); BMW (DaaT); and JASS (SaaT). Experiments reveal a number of interestingfindings. The performance gap between WAND and BMW is not as clear as the literaturesuggests; and both methods are susceptible to tail queries that may take orders of …,Proceedings of the Tenth ACM International Conference on Web Search and Data Mining,2017,12
Personalized influential topic search via social network summarization,Jianxin Li; Chengfei Liu; Jeffrey Xu Yu; Yi Chen; Timos Sellis; J Shane Culpepper,Social networks are a vital mechanism to disseminate information to friends and colleagues.In this work; we investigate an important problem-the personalized influential topic search;or PIT-Search in a social network: Given a keyword query q issued by a user u in a socialnetwork; a PIT-Search is to find the top-k q-related topics that are most influential for thequery user u. The influence of a topic to a query user depends on the social connectionbetween the query user and the social users containing the topic in the social network. Tomeasure the topics' influence at the similar granularity scale; we need to extract the socialsummarization of the social network regarding topics. To make effective topic-aware socialsummarization; we propose two random-walk based approaches: random clustering and anL-length random walk. Based on the proposed approaches; we can find a small set of …,IEEE Transactions on Knowledge and Data Engineering,2016,12
Maximizing bichromatic reverse spatial and textual k nearest neighbor queries,Farhana M Choudhury; J Shane Culpepper; Timos Sellis; Xin Cao,Abstract The problem of maximizing bichromatic reverse k nearest neighbor queries(BRkNN) has been extensively studied in spatial databases. In this work; we present arelated query for spatial-textual databases that finds an optimal location; and a set ofkeywords that maximizes the size of bichromatic reverse spatial textual k nearest neighbors(MaxBRSTkNN). Such a query has many practical applications including social mediaadvertisements where a limited number of relevant advertisements are displayed to eachuser. The problem is to find the location and the text contents to include in an advertisementso that it will be displayed to the maximum number of users. The increasing availability ofspatial-textual collections allows us to answer these queries for both spatial proximity andtextual similarity. This paper is the first to consider the MaxBRSTkNN query. We show that …,Proceedings of the VLDB Endowment,2016,11
Score-safe term-dependency processing with hybrid indexes,Matthias Petri; Alistair Moffat; J Shane Culpepper,Abstract Score-safe index processing has received a great deal of attention over the last twodecades. By pre-calculating maximum term impacts during indexing; the number of scoringoperations can be minimized; and the top-k documents for a query can be located efficiently.However; these methods often ignore the importance of the effectiveness gains possiblewhen using sequential dependency models. We present a hybrid approach which leveragesscore-safe processing and suffix-based self-indexing structures in order to provide efficientand effective top-k document retrieval.,Proceedings of the 37th international ACM SIGIR conference on Research & development in information retrieval,2014,11
Indexing word sequences for ranked retrieval,Samuel Huston; J Shane Culpepper; W Bruce Croft,Abstract Formulating and processing phrases and other term dependencies to improvequery effectiveness is an important problem in information retrieval. However; accessingword-sequence statistics using inverted indexes requires unreasonable processing time orsubstantial space overhead. Establishing a balance between these competing space andtime trade-offs can dramatically improve system performance. In this article; we present andanalyze a new index structure designed to improve query efficiency in dependency retrievalmodels. By adapting a class of (ε; δ)-approximation algorithms originally proposed for sketchsummarization in networking applications; we show how to accurately estimate statisticsimportant in term-dependency models with low; probabilistically bounded error rates. Thespace requirements for the vocabulary of the index is only logarithmically linked to the …,ACM Transactions on Information Systems (TOIS),2014,11
Language independent ranked retrieval with NeWT,J Shane Culpepper; Michiko Yasukawa; Falk Scholer,Abstract In this paper; we present a novel approach to language independent; rankeddocument retrieval using our new self-index search engine; Newt. To our knowledge; this isthe first experimental study of ranked self-indexing for multilingual Information Retrievaltasks. We evaluate the query effectiveness of our indexes using Japanese and English. Weexplore the impact that linguistic processing; stemming and stopping have on our character-aligned indexes; and present advantages and challenges discovered during our initialevaluation.,Proc. Aust. Doc. Comp. Symp,2011,11
Improving test collection pools with machine learning,Gaya K Jayasinghe; William Webber; Mark Sanderson; J Shane Culpepper,Abstract IR experiments typically use test collections for evaluation. Such test collections areformed by judging a pool of documents retrieved by a combination of automatic and manualruns for each topic. The proportion of relevant documents found for each topic depends onthe diversity across each of the runs submitted and the depth to which runs are assessed(pool depth). Manual runs are commonly believed to reduce bias in test collections whenevaluating new IR systems. In this work; we explore alternative approaches to improving testcollection reliability. Using fully automated approaches; we are able to recognise a largeportion of relevant documents that would normally only be found through manual runs. Ourapproach combines simple fusion methods with machine learning. The approachdemonstrates the potential to find many more relevant documents than are found using …,Proceedings of the 2014 Australasian Document Computing Symposium,2014,10
Entropy of the retina template,Arathi Arakala; J Shane Culpepper; Jason Jeffers; Andrew Turpin; S Boztaş; Kathy J Horadam; AM McKendrick,Abstract We compare two vessel extraction methods for creation of a retina template; using adatabase of 20 images of normal retinas. Each vessel in a well defined region isrepresented by a three dimensional feature; from which a retina template is built. Based onthe sample distributions; we propose a preliminary theoretical model to predict the entropy ofa retina template. We analyse by experimental and theoretical means the entropy present;and infer that entropy from our retina template compares sufficiently favourably with that of aminutia-based fingerprint template to warrant further study.,International Conference on Biometrics,2009,9
Efficient location-aware web search,Joel Mackenzie; Farhana M Choudhury; J Shane Culpepper,Abstract Mobile search is quickly becoming the most common mode of search on theinternet. This shift is driving changes in user behaviour; and search engine behaviour. Justover half of all search queries from mobile devices have local intent; making location-awaresearch an increasingly important problem. In this work; we compare the efficiency andeffectiveness of two general types of geographical search queries; range queries and knearest neighbor queries; for common web search tasks. We test state-of-the-art spatial-textual indexing and search algorithms for both query types on two large datasets. Finally;we present a rank-safe dynamic pruning algorithm that is simple to implement and use withcurrent inverted indexing techniques. Our algorithm is more efficient than the tightly coupledbest-in-breed hybrid indexing algorithms that are commonly used for top-k spatial textual …,Proceedings of the 20th Australasian Document Computing Symposium,2015,8
RMIT at the TREC 2015 LiveQA Track,Ruey-Cheng Chen; J Shane Culpepper; Tadele T Damessie; Timothy Jones; Ahmed Mourad; Kevin Ong; Falk Scholer; Evi Yulianti,Abstract: This paper describes the four systems RMIT fielded for the TREC 2015 LiveQA taskand the associated experiments. The challenge results show that the base runRMIT-0 hasachieved an above-average performance; but other attempted improvements have allresulted in decreased retrieval effectiveness.,*,2015,8
Phrase-based pattern matching in compressed text,J Shane Culpepper; Alistair Moffat,Abstract Byte codes are a practical alternative to the traditional bit-oriented compressionapproaches when large alphabets are being used; and trade away a small amount ofcompression effectiveness for a relatively large gain in decoding efficiency. Byte codes alsohave the advantage of being searchable using standard string matching techniques. Herewe describe methods for searching in byte-coded compressed text and investigate theimpact of large alphabets on traditional string matching techniques. We also describetechniques for phrase-based searching in a restricted type of byte code; and presentexperimental results that compare our adapted methods with previous approaches.,International Symposium on String Processing and Information Retrieval,2006,8
Efficient cost-aware cascade ranking in multi-stage retrieval,Ruey-Cheng Chen; Luke Gallagher; Roi Blanco; J Shane Culpepper,Abstract Complex machine learning models are now an integral part of modern; large-scaleretrieval systems. However; collection size growth continues to outpace advances inefficiency improvements in the learning models which achieve the highest effectiveness. Inthis paper; we re-examine the importance of tightly integrating feature costs into multi-stagelearning-to-rank (LTR) IR systems. We present a novel approach to optimizing cascadedranking models which can directly leverage a variety of different state-of-the-art LTR rankerssuch as LambdaMART and Gradient Boosted Decision Trees. Using our cascade model; weconclusively show that feature costs and the number of documents being re-ranked in eachstage of the cascade can be balanced to maximize both efficiency and effectiveness. Finally;we also demonstrate that our cascade model can easily be deployed on commonly used …,Proceedings of the 40th International ACM SIGIR Conference on Research and Development in Information Retrieval,2017,7
Load-balancing in distributed selective search,Yubin Kim; Jamie Callan; J Shane Culpepper; Alistair Moffat,Abstract Simulation and analysis have shown that selective search can reduce the cost oflarge-scale distributed information retrieval. By partitioning the collection into small topicalshards; and then using a resource ranking algorithm to choose a subset of shards to searchfor each query; fewer postings are evaluated. Here we extend the study of selective searchusing a fine-grained simulation investigating: selective search efficiency in a parallel queryprocessing environment; the difference in efficiency when term-based and sample-basedresource selection algorithms are used; and the effect of two policies for assigning indexshards to machines. Results obtained for two large datasets and four large query logsconfirm that selective search is significantly more efficient than conventional distributedsearch. In particular; we show that selective search is capable of both higher throughput …,Proceedings of the 39th international ACM SIGIR conference on research and development in information retrieval,2016,6
TREC: topic engineering exercise,J Shane Culpepper; Stefano Mizzaro; Mark Sanderson; Falk Scholer,Abstract In this work; we investigate approaches to engineer better topic sets in informationretrieval test collections. By recasting the TREC evaluation exercise from one of buildingmore effective systems to an exercise in building better topics; we present two possibleapproaches to quantify topic" goodness": topic ease and topic set predictivity. A novelinterpretation of a well known result and a twofold analysis of data from several TRECeditions lead to a result that has been neglected so far: both topic ease and topic setpredictivity have changed significantly across the years; sometimes in a perhapsundesirable way.,Proceedings of the 37th international ACM SIGIR conference on Research & development in information retrieval,2014,6
Efficient distributed selective search,Yubin Kim; Jamie Callan; J Shane Culpepper; Alistair Moffat,Abstract Simulation and analysis have shown that selective search can reduce the cost oflarge-scale distributed information retrieval. By partitioning the collection into small topicalshards; and then using a resource ranking algorithm to choose a subset of shards to searchfor each query; fewer postings are evaluated. In this paper we extend the study of selectivesearch into new areas using a fine-grained simulation; examining the difference in efficiencywhen term-based and sample-based resource selection algorithms are used; measuring theeffect of two policies for assigning index shards to machines; and exploring the benefits ofindex-spreading and mirroring as the number of deployed machines is varied. Resultsobtained for two large datasets and four large query logs confirm that selective search issignificantly more efficient than conventional distributed search architectures and can …,Information Retrieval Journal,2017,5
How effective are proximity scores in term dependency models?,Xiaolu Lu; Alistair Moffat; J Shane Culpepper,Abstract The dominant retrieval models in information retrieval systems today are variants ofTF× IDF; and typically use bag-of-words processing in order to balance recall and precision.However; the size of collections continues to increase; and the number of results producedby these models exceeds the number of documents that can be reasonably assessed. Toaddress this need; researchers and commercial providers are now looking at moreexpensive computational models to improve the quality of the results returned. One suchmethod is to incorporate term proximity into the ranking model. We explore the effectivenessgains achievable when term proximity is a factor used in ranking algorithms; and explore therelative effectiveness of several variants of the term dependency model. Our goal is tounderstand how these proximity-based models improve effectiveness.,Proceedings of the 2014 Australasian Document Computing Symposium,2014,5
Phonetic matching in Japanese,Michiko Yasukawa; J Shane Culpepper; Falk Scholer,ABSTRACT This paper introduces a set of Japanese phonetic matching functions for theopen source relational database PostgreSQL. Phonetic matching allows a search system tolocate approximate strings according to the sound of a term. This sort of approximate stringmatching is often referred to as fuzzy string matching in the open source community. Thisapproach to string matching has been well studied in English and other Europeanlanguages; and open source packages for these languages are readily available. To ourknowledge; there is no such module for the Japanese language. In this paper; we present aset of string matching functions based on the phonetic similarity for modern Japanese. Wehave prototyped the proposed functions as an open source tool in PostgreSQL; andevaluated these functions using the test collection from the NTCIR-9 INTENT task. We …,SIGIR 2012 Workshop on Open Source Information Retrieval,2012,5
Revisiting bounded context block-sorting transformations,J S Culpepper; M Petri; S Puglisi,SUMMARY The Burrows–Wheeler Transform (BWT) produces a permutation of a string X;denoted X∗; by sorting the n cyclic rotations of X into full lexicographical order and takingthe last column of the resulting n× n matrix to be X∗. The transformation is reversible in mathformula,Software-Practice & Experience (2011),2011,5
Does selective search benefit from WAND optimization?,Yubin Kim; Jamie Callan; J Shane Culpepper; Alistair Moffat,Abstract Selective search is a distributed retrieval technique that reduces the computationalcost of large-scale information retrieval. By partitioning the collection into topical shards; andusing a resource selection algorithm to identify a subset of shards to search; selectivesearch allows retrieval effectiveness to be maintained while evaluating fewer postings; oftenresulting in 90+% reductions in querying cost. However; there has been only limitedattention given to the interaction between dynamic pruning algorithms and topical indexshards. We demonstrate that the WAND dynamic pruning algorithm is more effective ontopical index shards than it is on randomly-organized index shards; and that the savingsgenerated by selective search and WAND are additive. We also compare two methods forapplying WAND to topical shards: searching each shard with a separate top-k heap and …,European Conference on Information Retrieval,2016,4
On the cost of extracting proximity features for term-dependency models,Xiaolu Lu; Alistair Moffat; J Shane Culpepper,Abstract Sophisticated ranking mechanisms make use of term dependency features in orderto compute similarity scores for documents. These features often include exact phraseoccurrences; and term proximity estimates. Both cases build on the intuition that if multiplequery terms appear near each other; the document is more likely to be relevant to the query.In this paper we examine the processes used to compute these statistics. Two distinct inputstructures can be used--inverted files and direct files. Inverted files must store the positionoffsets of the terms; while" direct" files represent each document as a sequence ofpreprocessed term identifiers. Based on these two input modalities; a number of algorithmscan be used to compute proximity statistics. Until now; these algorithms have beendescribed in terms of a single set of query terms. But similarity computations such as the …,Proceedings of the 24th ACM International on Conference on Information and Knowledge Management,2015,4
Statistical comparisons of non-deterministic IR systems using two dimensional variance,Gaya K Jayasinghe; William Webber; Mark Sanderson; Lasitha S Dharmasena; J Shane Culpepper,Abstract Retrieval systems with non-deterministic output are widely used in informationretrieval. Common examples include sampling; approximation algorithms; or interactive userinput. The effectiveness of such systems differs not just for different topics; but also fordifferent instances of the system. The inherent variance presents a dilemma–What is thebest way to measure the effectiveness of a non-deterministic IR system? Existingapproaches to IR evaluation do not consider this problem; or the potential impact onstatistical significance. In this paper; we explore how such variance can affect systemcomparisons; and propose an evaluation framework and methodologies capable of doingthis comparison. Using the context of distributed information retrieval as a case study for ourinvestigation; we show that the approaches provide a consistent and reliable …,Information Processing & Management,2015,4
Extending test collection pools without manual runs,Gaya K Jayasinghe; William Webber; Mark Sanderson; J Shane Culpepper,Abstract Information retrieval test collections traditionally use a combination of automatic andmanual runs to create a pool of documents to be judged. The quality of the final judgmentsproduced for a collection is a product of the variety across each of the runs submitted andthe pool depth. In this work; we explore fully automated approaches to generating a pool. Bycombining a simple voting approach with machine learning from documents retrieved byautomatic runs; we are able to identify a large portion of relevant documents that wouldnormally only be found through manual runs. Our initial results are promising and can beextended in future studies to help test collection curators ensure proper judgment coverageis maintained across complete document collections.,Proceedings of the 37th international ACM SIGIR conference on Research & development in information retrieval,2014,4
Efficient indexing algorithms for approximate pattern matching in text,Matthias Petri; J Shane Culpepper,Abstract Approximate pattern matching is an important computational problem with a widevariety of applications in Information Retrieval. Efficient solutions to approximate patternmatching can be applied to natural language keyword queries with spelling mistakes; OCRscanned text incorporated into indexes; language model ranking algorithms based on termproximity; or DNA databases containing sequencing errors. In this paper; we present a novelapproach to constructing text indexes capable of efficiently supporting approximate searchqueries. Our approach relies on a new variant of the Context Bound Burrows-WheelerTransform (k-bwt); referred to as the Variable Depth Burrows-Wheeler Transform (v-bwt).First; we describe our new algorithm; and show that it is reversible. Next; we show how touse the transform to support efficient text indexing and approximate pattern matching …,Proceedings of the Seventeenth Australasian Document Computing Symposium,2012,4
RMIT at the TREC 2016 LiveQA Track.,Joel Mackenzie; Ruey-Cheng Chen; J Shane Culpepper,Abstract—This paper describes the four systems RMIT fielded for the TREC 2016 LiveQAtask and the associated experiments. Similar to last year; the results show that simplesolutions tend to work best; and that our improved baseline systems achieved an above-average performance. We use a commercial search engine as a first stage retrievalmechanism and compare it with our internal system which uses a carefully curateddocument collection. Somewhat surprisingly; we found that on average the small curatedcollection performed better within our current framework; warranting further studies on whenand when not to use an external resource; such as a publicly available search engine API.Finally; we show that small improvements to performance can substantially reduce failurerates.,TREC,2016,3
Batch processing of Top-k Spatial-textual Queries,Farhana M Choudhury; J Shane Culpepper; Timos Sellis,Abstract Top-k spatial-textual queries have received significant attention in the researchcommunity. Several techniques to efficiently process this class of queries are now widelyused in a variety of applications. However; the problem of how best to process multiplequeries efficiently is not well understood. Applications relying on processing continuousstreams of queries; and offline pre-processing of other queries could benefit from solutionsto this problem. In this work; we study practical solutions to efficiently process a set of top-kspatial-textual queries. We propose an efficient best-first algorithm for the batch processingof top-k spatial-textual queries that promotes shared processing and reduced I/O in eachquery batch. By grouping similar queries and processing them simultaneously; we are ableto demonstrate significant performance gains using publicly available datasets.,Second International ACM Workshop on Managing and Mining Enriched Geo-Spatial Data,2015,3
Evaluating non-deterministic retrieval systems,Gaya K Jayasinghe; William Webber; Mark Sanderson; Lasitha S Dharmasena; J Shane Culpepper,Abstract The use of sampling; randomized algorithms; or training based on theunpredictable inputs of users in Information Retrieval often leads to non-deterministicoutputs. Evaluating the effectiveness of systems incorporating these methods can bechallenging since each run may produce different effectiveness scores. Current IRevaluation techniques do not address this problem. Using the context of distributedinformation retrieval as a case study for our investigation; we propose a solution based onmultivariate linear modeling. We show that the approach provides a consistent and reliablemethod to compare the effectiveness of non-deterministic IR algorithms; and explain howstatistics can safely be used to show that two IR algorithms have equivalent effectiveness.,Proceedings of the 37th international ACM SIGIR conference on Research & development in information retrieval,2014,3
Efficient data representations for information retrieval,J Shane Culpepper,Abstract The key role compression plays in efficient information retrieval systems has beenrecognized for some time. However; applying a traditional compression algorithm to thecontents of an information retrieval system is often not the best solution. For example; it isinefficient to perform search operations in maximally compressed data or to find theintersection of maximally compressed sets. In order to perform these operations; the datarepresentation must be fully decompressed. This thesis explores practical space versus timetrade-offs which balance storage space against the competing requirement that operationsbe performed quickly. In particular; we are interested in variable length coding methodswhich are both practical and allow codeword boundaries to be found directly in thecompressed representation. The latter property allows considerable flexibility in …,*,2007,3
Can Deep Effectiveness Metrics Be Evaluated Using Shallow Judgment Pools?,Xiaolu Lu; Alistair Moffat; J Shane Culpepper,Abstract Increasing test collection sizes and limited judgment budgets create measurementchallenges for IR batch evaluations; challenges that are greater when using deepeffectiveness metrics than when using shallow metrics; because of the increased likelihoodthat unjudged documents will be encountered. Here we study the problem of metric scoreadjustment; with the goal of accurately estimating system performance when using deepmetrics and limited judgment sets; assuming that dynamic score adjustment is required pertopic due to the variability in the number of relevant documents. We seek to induce systemorderings that are as close as is possible to the orderings that would arise if full judgmentswere available. Starting with depth-based pooling; and no prior knowledge of samplingprobabilities; the first phase of our two-stage process computes a background gain for …,Proceedings of the 40th International ACM SIGIR Conference on Research and Development in Information Retrieval,2017,2
Answering top-k exemplar trajectory queries,Sheng Wang; Zhifeng Bao; J Shane Culpepper; Timos Sellis; Mark Sanderson; Xiaolin Qin,We study a new type of spatial-textual trajectory search: the Exemplar Trajectory Query(ETQ); which specifies one or more places to visit; and descriptions of activities at eachplace. Our goal is to efficiently find the top-k trajectories by computing spatial and textualsimilarity at each point. The computational cost for pointwise matching is significantly higherthan previous approaches. Therefore; we introduce an incremental pruning baseline andexplore how to adaptively tune our approach; introducing a gap-based optimization and anovel twolevel threshold algorithm to improve efficiency. Our proposed methods supportorder-sensitive ETQ with a minor extension. Experiments on two datasets verify theefficiency and scalability of our proposed solution.,Data Engineering (ICDE); 2017 IEEE 33rd International Conference on,2017,2
RMIT at the NTCIR-13 We Want Web Task,Luke Gallagher; Joel Mackenzie; Rodger Benham; Ruey-Cheng Chen; Falk Scholer; J Shane Culpepper,ABSTRACT Furthering the state-of-the-art in adhoc web search is one of the underlyinggoals for the NTCIR-13 We Want Web (WWW) task. Adhoc search can be viewed as abridge connecting many of the specialized sub-fields that are a result of the way peopleconnect to and use information access systems. Since this is the first year of the WWW task;and no training data was provided for the English subtask; we focused on classic techniquesfor improving effectiveness in lieu of modern techniques based on supervised learning. Inparticular; we explored the use of Markov Random Field Models (MRFs); static documentfeatures; fieldbased weighting; and query expansion. This round we made extensive use ofthe Indri search system and the flexible query language it provides to produce effectiveresults.,Proc. NTCIR-13,2017,2
The influence of topic difficulty; relevance level; and document ordering on relevance judging,Tadele T Damessie; Falk Scholer; J Shane Culpepper,Abstract Judging the relevance of documents for an information need is an activity thatunderpins the most widely-used approach in the evaluation of information retrieval systems.In this study we investigate the relationship between how long it takes an assessor to judgedocument relevance; and three key factors that may influence the judging scenario: thedifficulty of the search topic for which relevance is being assessed; the degree to which thedocuments are relevant to the search topic; and; the order in which the documents arepresented for judging. Two potential confounding influences on judgment speed aredifferences in individual reading ability; and the length of documents that are beingassessed. We therefore propose two measures to investigate the above factors: normalizedprocessing speed (NPS); which adjusts the number of words that were processed per …,Proceedings of the 21st Australasian Document Computing Symposium,2016,2
Interactive trip planning using activity trajectories,Sheng Wang; Zhifeng Bao; J Shane Culpepper; Timos Sellis; Mark Sanderson; Munkh-Erdene Yadamjav,Abstract We present an interactive trip planning system called@ FINDER which uses anexemplar trajectory query to find the most related top-k spatial-textual trajectories.@ FINDERis implemented to support various degrees of user information needs for trip planning. Forusers with zero knowledge about places to travel;@ FINDER provides a heatmap of popularpoints of interest (POIs) as well as popular activities from a trajectory database. The systemhelps users quickly explore the places; and helps formulate an exemplar trajectory query;which specifies preferred places to go and activities of interest. Then@ FINDER providesefficient query processing of the top-k related spatial-textual trajectories using a newapproach to spatial-textual trajectory indexing recently developed at RMIT University. Foreach of the top-k results found in the form of a set of POIs and activities;@ FINDER further …,Proceedings of the 21st Australasian Document Computing Symposium,2016,2
Efficient and Effective Higher Order Proximity Modeling,Xiaolu Lu; Alistair Moffat; J Shane Culpepper,Abstract Bag-of-words retrieval models are widely used; and provide a robust trade-offbetween efficiency and effectiveness. These models often make simplifying assumptionsabout relations between query terms; and treat term statistics independently. However;query terms are rarely independent; and previous work has repeatedly shown that termdependencies can be critical to improving the effectiveness of ranked retrieval results.Among all term-dependency models; the Markov Random Field (MRF)[Metzler and Croft;SIGIR; 2005] model has received the most attention in recent years. Despite cleareffectiveness improvements; these models are not deployed in performance-criticalapplications because of the potentially high computational costs. As a result; bigram modelsare generally considered to be the best compromise between full term dependence; and …,Proceedings of the 2016 ACM International Conference on the Theory of Information Retrieval,2016,2
The effect of document order and topic difficulty on assessor agreement,Tadele T Damessie; Falk Scholer; Kalvero Järvelin; J Shane Culpepper,Abstract Human relevance judgments are a key component for measuring the effectivenessof information retrieval systems using test collections. Since relevance is not an absoluteconcept; human assessors can disagree on particular topic-document pairs for a variety ofreasons. In this work we investigate the effect that document presentation order has on inter-rater agreement; comparing two presentation ordering approaches similar to those used inIR evaluation campaigns: decreasing relevance order and document identifier order. Wemake a further distinction between" easy" topics and" hard" topics in order to explore systemeffects on inter-rater agreement. The results of our pilot user study indicate that assessoragreement is higher when documents are judged in document identifier order. In addition;there is higher overall agreement on easy topics than on hard topics.,Proceedings of the 2016 ACM International Conference on the Theory of Information Retrieval,2016,2
Observed volatility in effectiveness metrics,Xiaolu Lu; Alistair Moffat; J Shane Culpepper,ABSTRACT Information retrieval research and commercial search system evaluation bothrely heavily on the use of batch evaluation and numerical system comparisons usingeffectiveness metrics. Batch evaluation provides a relatively low-cost alternative to userstudies; and permits repeatable and incrementally varying experimentation in researchsituations in which access to high-volume query/click streams is not possible. As a result; theIR community has invested considerable effort into formulating; justifying; comparing; andcontrasting a large number of alternative metrics. In this paper we consider a very simplequestion: to what extent can the various metrics be said to give rise to stable scores; that is;evaluations in which the process of adding further relevance information creates refinedscore estimates rather than different score estimates. Underlying this question is a …,*,2015,2
Sketch-based indexing of n-words,Samuel Huston; J Shane Culpepper; W Bruce Croft,Abstract Formulating and processing phrases and other term dependencies to improvequery effectiveness is an important problem in information retrieval. However; accessingthese types of statistics using standard inverted indexes requires unreasonable processingtime or incurs a substantial space overhead. Establishing a balance between thesecompeting space and time trade-offs can dramatically improve system performance. In thispaper; we present and analyze a new index structure designed to improve query efficiencyin term dependency retrieval models; with bounded space requirements. By adapting aclass of (ε; δ)-approximation algorithms originally proposed for sketch summarization innetworking applications; we show how to accurately estimate various statistics important interm dependency models with low; probabilistically bounded error rates. The space …,Proceedings of the 21st ACM international conference on Information and knowledge management,2012,2
Monitoring the top-m rank aggregation of spatial objects in streaming queries,Farhana M Choudhury; Zhifeng Bao; J Shane Culpepper; Timos Sellis,In this paper; we propose and study the problem of top-m rank aggregation of spatial objectsin streaming queries; where; given a set of objects O; a stream of spatial queries (kNN orrange); the goal is to report the m objects with the highest aggregate rank. The rank of anobject with respect to an individual query is computed based on its distance from the querylocation; and the aggregate rank is computed from all of the individual rank orderings. Inorder to solve this problem; we show how to upper and lower bound the rank of an object forany unseen query. Then we propose an approximation solution to continuously monitor thetop-m objects efficiently; for which we design an Inverted Rank File (IRF) index to guaranteethe error bound of the solution. In particular; we propose the notion of safe ranking todetermine whether the current result is still valid or not when new queries arrive; and …,Data Engineering (ICDE); 2017 IEEE 33rd International Conference on,2017,1
Modeling relevance as a function of retrieval rank,Xiaolu Lu; Alistair Moffat; J Shane Culpepper,Abstract Batched evaluations in IR experiments are commonly built using relevancejudgments formed over a sampled pool of documents. However; judgment coverage tends tobe incomplete relative to the metrics being used to compute effectiveness; since collectionsize often makes it financially impractical to judge every document. As a result; aconsiderable body of work has arisen exploring the question of how to fairly comparesystems in the face of unjudged documents. Here we consider the same problem fromanother perspective; and investigate the relationship between relevance likelihood andretrieval rank; seeking to identify plausible methods for estimating document relevance andhence computing an inferred gain. A range of models are fitted against two typical TRECdatasets; and evaluated both in terms of their goodness of fit relative to the full set of …,Asia Information Retrieval Symposium,2016,1
Monitoring the top-m aggregation in a sliding window of spatial queries,Farhana M Choudhury; Zhifeng Bao; J Shane Culpepper; Timos Sellis,Abstract: In this paper; we propose and study the problem of top-m rank aggregation ofspatial objects in streaming queries; where; given a set of objects O; a stream of spatialqueries (kNN or range); the goal is to report m objects with the highest aggregate rank. Therank of an object wrt an individual query is computed based on its distance from the querylocation; and the aggregate rank is computed from all of the individual rank orderings.Solutions to this fundamental problem can be used to monitor the popularity of spatialobjects; which in turn can provide new analytical tools for spatial data. Our work drawsinspiration from three different domains: rank aggregation; continuous queries and spatialdatabases. To the best of our knowledge; there is no prior work that considers all threeproblem domains in a single context. Our problem is different from the classical rank …,arXiv preprint arXiv:1610.03579,2016,1
Dynamic Trade-Off Prediction in Multi-Stage Retrieval Systems,J Shane Culpepper; Charles LA Clarke; Jimmy Lin,Abstract: Modern multi-stage retrieval systems are comprised of a candidate generationstage followed by one or more reranking stages. In such an architecture; the quality of thefinal ranked list may not be sensitive to the quality of initial candidate pool; especially interms of early precision. This provides several opportunities to increase retrieval efficiencywithout significantly sacrificing effectiveness. In this paper; we explore a new approach todynamically predicting two different parameters in the candidate generation stage which candirectly affect the overall efficiency and effectiveness of the entire system. Previous workexploring this tradeoff has focused on global parameter settings that apply to all queries;even though optimal settings vary across queries. In contrast; we propose a technique whichmakes a parameter prediction that maximizes efficiency within a effectiveness envelope …,arXiv preprint arXiv:1610.02502,2016,1
Backwards search in context bound text transformations,Matthias Petri; Gonzalo Navarro; J Shane Culpepper; Simon J Puglisi,The Burrows-Wheeler Transform (BWT) is the basis for many of the most effectivecompression and self-indexing methods used today. A key to the versatility of the BWT is theability to search for patterns directly in the transformed text. A backwards search for a patternP can be performed on a transformed text by iteratively determining the range of suffixes thatmatch P. The search can be further enhanced by constructing a wavelet tree over the outputof the BWT in order to emulate a suffix array. In this paper; we investigate new algorithms forsearch derived from a variation of the BWT whereby rotations are only sorted to a depth k;commonly referred to as a context bound transform. Interestingly; this BWT variant can beused to mimic a k-gram index; which are used in a variety of applications that need toefficiently return occurrences in text position order. In this paper; we present the first …,Data Compression; Communications and Processing (CCP); 2011 First International Conference on,2011,1
RMIT at TREC 2011 Microblog Track,Matthias Petri; J Shane Culpepper; Falk Scholer,Abstract—This paper describes our submission to the TREC 2011 microblog task. For theexperiments; we use our new self-index search engine; NeWT; to support ranked search inthe Twitter document corpus. We use a combination of phrase queries and degradingconjunctive Boolean intersection to improve retrieval effectiveness.,*,2011,1
RMIT and Gunma University at NTCIR-9 Intent task,Michiko Yasukawa; J Shane Culpepper; Falk Scholer; Matthias Petri,ABSTRACT AM i? Bb2TQi-r2/2b+B# 2 Qm2tT2BK2Mi H2bmHib 7Qi? 2 Lh* A_@ N BMi2Mi ibFX 6QQm2tT2BK2Mib-r2 mb2 Qm2tT2BK2Mi H b2+? 2M; BM2-L2riX L2ri BbMF2/b2H7@BM/2t+ T# H2 Q7 bmTTQiBM; KmHiBTH2 HM; m; 2b# v/272``BM; HBM; mBbiB+/2+ BbBQMbmMiBH [m2v iBK2X hQ QmFMQrH2/; 2-i? Bb Bb i? 2 fibi AM7QK iBQM _2iB2p H i bF QM i?2* Hm2q2# yN@ C+ QHH2+ iBQM T27QK2/2MiB2Hv rBi?MF2/b2H7@ BM/2t2bX,Proceedings of the NTCIR-9 Workshop Meeting,2011,1
Comparing a Hidden Markov Model and a Stochastic Context Free Grammar,J Culpepper,*,*,2007,1
Query Driven Algorithm Selection in Early Stage Retrieval,Joel Mackenzie; J Shane Culpepper; Roi Blanco; Matt Crane; Charles LA Clarke; Jimmy Lin,ABSTRACT Large scale retrieval systems often employ cascaded ranking architectures; inwhich an initial set of candidate documents is iteratively refined and re-ranked byincreasingly sophisticated and expensive ranking models. In this paper; we propose aunified framework for predicting a range of performance-sensitive parameters based onminimizing end-to-end effectiveness loss. The framework does not require relevancejudgments for training; is amenable to predicting a wide range of parameters; allows for finetuned efficiencyeffectiveness trade-offs; and can be easily deployed in large scale searchsystems with minimal overhead. As a proof of concept; we show that the framework canaccurately predict a number of performance parameters on a query-by-query basis; allowingefficient and effective retrieval; while simultaneously minimizing the tail latency of an early …,*,2018,*
On the Cost of Negation for Dynamic Pruning,Joel Mackenzie; Craig Macdonald; Falk Scholer; J Shane Culpepper,Abstract. Negated query terms allow documents containing such terms to be filtered out of asearch results list; supporting disambiguation. In this work; the effect of negation on theefficiency of disjunctive; top-k retrieval is examined. First; we show how negation can beintegrated efficiently into two popular dynamic pruning algorithms. Then; we explore theefficiency of our approach; and show that while often efficient; negation can negativelyimpact the dynamic pruning effectiveness for certain queries.,*,2017,*
Risk-Reward Trade-offs in Rank Fusion,Rodger Benham; J Shane Culpepper,Abstract Rank fusion is a powerful technique that merges multiple system runs to produce asingle top-k list that often has much higher effectiveness than any single system canproduce. Recently; there has been renewed interest in rank fusion in the IR community asthese techniques can also be combined with query variations to produce highly effectiveruns. In this work; we comprehensively evaluate several state-of-the-art fusion algorithms inthe context of risk. Like many re-ranking algorithms; there is a risk-reward trade-off in rankfusion; where improving the retrieval effectiveness for most queries often comes at theexpense of others. Since system performance is usually compared using only aggregatescores for an evaluation metric; the risk is potentially obscured. In this work; we explore theuse of the risk-based evaluation metrics over deep and shallow evaluation goals; and …,Proceedings of the 22nd Australasian Document Computing Symposium,2017,*
Early Termination Heuristics for Score-at-a-Time Index Traversal,Joel Mackenzie; Falk Scholer; J Shane Culpepper,Abstract Score-at-a-Time index traversal is a query processing approach which supportsearly termination in order to balance efficiency and effectiveness trade-offs. In this work; weexplore new techniques which extend a modern Score-at-a-Time traversal algorithm to allowfor parallel postings traversal. We show that careful integration of parallel traversal canimprove both efficiency and effectiveness when compared with current single threaded earlytermination approaches. In addition; we explore the various trade-offs for differing earlytermination heuristics; and propose hybrid systems which parallelize long running queries;while processing short running queries with only a single thread.,Proceedings of the 22nd Australasian Document Computing Symposium,2017,*
Reverse k Nearest Neighbor Search over Trajectories,Sheng Wang; Zhifeng Bao; Shane Culpepper; Timos Sellis; Gao Cong,GPS enables mobile devices to continuously provide new opportunities to improve our dailylives. For example; the data collected in applications created by Uber or Public TransportAuthorities can be used to plan transportation routes; estimate capacities; and proactivelyidentify low coverage areas. In this paper; we study a new kind of query Reverse k NearestNeighbor Search over Trajectories (RkNNT); which can be used for route planning andcapacity estimation. Given a set of existing routes DR; a set of passenger transitions DT; anda query route Q; an RkNNT query returns all transitions that take Q as one of its k nearesttravel routes. To solve the problem; we first develop an index to handle dynamic trajectoryupdates; so that the most up-to-date transition data are available for answering an RkNNTquery. Then we introduce a filter refinement framework for processing RkNNT queries …,IEEE Transactions on Knowledge and Data Engineering,2017,*
Gauging the Quality of Relevance Assessments using Inter-Rater Agreement,Tadele T Damessie; Thao P Nghiem; Falk Scholer; J Shane Culpepper,Abstract In recent years; gathering relevance judgments through non-topic originators hasbecome an increasingly important problem in Information Retrieval. Relevance judgmentscan be used to measure the effectiveness of a system; and are often needed to buildsupervised learning models in learning-to-rank retrieval systems. The two most popularapproaches to gathering bronze level judgments-where the judge is not the originator of theinformation need for which relevance is being assessed; and is not a topic expert-is througha controlled user study; or through crowdsourcing. However; judging comes at a cost (intime; and usually money) and the quality of the judgments can vary widely. In this work; wedirectly compare the reliability of judgments using three different types of bronze assessorgroups. Our first group is a controlled Lab group; the second and third are two different …,Proceedings of the 40th International ACM SIGIR Conference on Research and Development in Information Retrieval,2017,*
Geo-social influence spanning maximization,Jianxin Li; Timos Sellis; J Shane Culpepper; Zhenying He; Chengfei Liu; Junhu Wang,Influence maximization is a recent but well-studied problem which helps identify a small setof users that are most likely to “influence” the maximum number of users in a social network.The problem has attracted a lot of attention as it provides a way to improve marketing;branding; and product adoption. However; existing studies rarely consider the physicallocations of the users; but location is an important factor in targeted marketing. In this paper;we propose and investigate the problem of influence maximization in location-aware socialnetworks; or; more generally; Geo-social Influence Spanning Maximization. Given a query $q $ composed of a region $ R $; a regional acceptance rate $\rho $; and an integer $ k $ asa seed selection budget; our aim is to find the maximum geographic spanning regions(MGSR). We refer to this as the MGSR problem. Our approach differs from previous work …,IEEE Transactions on Knowledge and Data Engineering,2017,*
Efficient and Effective Tail Latency Minimization in Multi-Stage Retrieval Systems,Joel Mackenzie; J Shane Culpepper; Roi Blanco; Matt Crane; Charles LA Clarke; Jimmy Lin,Abstract: Scalable web search systems typically employ multi-stage retrieval architectures;where an initial stage generates a set of candidate documents that are then pruned and re-ranked. Since subsequent stages typically exploit a multitude of features of varying costsusing machine-learned models; reducing the number of documents that are considered ateach stage improves latency. In this work; we propose and validate a unified framework thatcan be used to predict a wide range of performance-sensitive parameters which minimizeeffectiveness loss; while simultaneously minimizing query latency; across all stages of amulti-stage search architecture. Furthermore; our framework can be easily applied in large-scale IR systems; can be trained without explicitly requiring relevance judgments; and cantarget a variety of different efficiency-effectiveness trade-offs; making it well suited to a …,arXiv preprint arXiv:1704.03970,2017,*
Risk-Reward Trade-o s in Rank Fusion,Rodger Benham; J Shane Culpepper,ABSTRACT Rank fusion is a powerful technique that merges multiple system runs toproduce a single top-k list that o en has much higher e ectiveness than any single systemcan produce. Recently; there has been renewed interest in rank fusion in the IR communityas these techniques can also be combined with query variations to produce highly e ectiveruns. In this work; we comprehensively evaluate several state-of-the-art fusion algorithms inthe context of risk. Like many re-ranking algorithms; there is a risk-reward trade-o in rankfusion; where improving the retrieval e ectiveness for most queries o en comes at theexpense of others. Since system performance is usually compared using only aggregatescores for an evaluation metric; the risk is potentially obscured. In this work; we explore theuse of the risk-based evaluation metrics over deep and shallow evaluation goals; and …,*,2017,*
Spatial textual Top-k search in mobile peer-to-peer networks,Thao P Nghiem; Cong Ma; J Shane Culpepper; Timos Sellis,Abstract Mobile hardware and software is quickly becoming the dominant computing modelfor technologically savvy people around the world. Nowadays; mobile devices arecommonly equipped with GPS and wireless connections. Users have also developed thehabit of regularly checking into a location; and adding comments or ratings for restaurants orany place of interest visited. This work explores new approaches to make data availablefrom a local network; and to build a collaborative search application that can suggestlocations of interest based on distance; user reviews and ratings. The proposed systemincludes light-weight indexing to support distributed search over spatio-textual data onmobile devices; and a ranking function to score objects of interest with relevant user reviewcontent. From our experimental study using a Yelp dataset; we found that our proposed …,Australasian Database Conference,2016,*
Data fusion for Japanese term and character N-gram search,Michiko Yasukawa; J Shane Culpepper; Falk Scholer,Abstract Term segmentation plays a vital role in building effective information retrievalsystems. In particular; languages such as Japanese and Chinese require a morphologicalanalyzer or a word segmenter to identify potential terms. The alternative approach toindexing a segmented collection is n-gram search; where every n-length sequence ofsymbols is indexed. Both approaches have strengths and weaknesses when applied to non-English collections. In this study; we explore data fusion techniques to answer the followingquestion: if there are multiple ranked lists of documents from both word and n-gram indexes;can we improve overall effectiveness by combining them? We consider three empiricalmethods for combining search results using eight different search indexes and twenty-onedifferent search models with and without automatic query expansion. Our approach is …,Proceedings of the 20th Australasian Document Computing Symposium,2015,*
Efficient Location-aware Web Search,J Shane Culpepper,Page 1. Efficient Location-aware Web Search J. Shane Culpepper Department of ComputerScience and Information Technology; RMIT University; Australia. November 9th; 2015 ShaneCulpepper (RMIT) Efficient Location-aware Web Search November 9th; 2015 1 / 32 Page 2.Research Agenda Efficient; Scalable Algorithm Design 1 Create new algorithms and datarepresentations to support efficient query processing (verbose queries). 2 Extend and refinein-memory indexing algorithms to support parallel; distributed; and dynamic indexing of massivedata sets more efficiently. 3 Explore efficiency and effectiveness trade-offs in large scale searchalgorithms. 4 Investigate new approaches to combining structured and unstructured search. 5Develop and understand IR evaluation best practices. Shane Culpepper (RMIT) EfficientLocation-aware Web Search November 9th; 2015 2 / 32 Page 3. Interesting Facts …,*,2015,*
Open Source Information Retrieval,Andrew Trotman; Charles LA Clarke; Iadh Ounis; J Shane Culpepper; Marc-Allen Cartright; Shlomo Geva,These proceedings contain the papers of the SIGIR 2012 Workshop on Open SourceInformation Retrieval held in held in Portland; Oregon; USA; on the 16 th of August 2012. Sixfull papers and six short papers were selected by the program committee from thirteensubmissions (92% acceptance rate). Each paper was reviewed by three members of theinternational program committee. In addition to these selected papers; invited talks weregiven by Grant Ingersoll “OpenSearchLab and the Lucene Ecosystem” and Jamie Callan“The Lemur Project and its ClueWeb12 Dataset”. We thank them for their specialcontributions. When reading this volume it is necessary to keep in mind that these papersrepresent the opinions of the authors (who are trying to stimulate debate). It is thecombination of these papers and the debate that will make the workshop a success. We …,*,2012,*
Rmit and Gunma University at NTCIR-9 GeoTime task,Michiko Yasukawa; J Shane Culpepper; Falk Scholer; Matthias Petri,*,Proceedings of the NTCIR-9 Workshop Meeting,2011,*
RMIT at the 2017 TREC CORE Track,Rodger Benham; Luke Gallagher; Joel Mackenzie; Tadele T Damessie; Ruey-Cheng Chen; Falk Scholer; J Shane Culpepper,1 INTRODUCTION e TREC 2017 CORE Track 1 is a re-run of the classic TREC ad hocsearch evaluation campaign; with the vision of establishing new methodologies for creatingIR test collections. e previous TREC newswire ad hoc task was the 2004 Robust Track;where the emphasis was on improving the e ectiveness of poorly performing topics inprevious tracks [16]. e TREC CORE 2017 track reuses the Robust 2004 topic set; for thedevelopment of relevance judgments over a new New York Times corpus; composed ofnewswire articles published between 1987 and 2007. In this track; our interest is driven bytwo related lines of research: e cient multi-stage retrieval [3–7; 9; 14]; where it is believedthat improving recall in early stage retrieval can improve end-to-ende ectiveness; and morereliable deep evaluation when using shallow judgments [8; 10–13]. By participating in …,*,*,*
RMIT at the TREC CORE Track,Rodger Benham; Luke Gallagher; Joel Mackenzie; Tadele T Damessie; Ruey-Cheng Chen; Falk Scholer; J Shane Culpepper,1 INTRODUCTION e TREC 2017 CORE Track 1 is a re-run of the classic TREC ad hocsearch evaluation campaign; with the vision of establishing new methodologies for creatingIR test collections. e previous TREC newswire ad hoc task was the 2004 Robust Track;where the emphasis was on improving the e ectiveness of poorly performing topics inprevious tracks [16]. e TREC CORE 2017 track reuses the Robust 2004 topic set; for thedevelopment of relevance judgments over a new New York Times corpus; composed ofnewswire articles published between 1987 and 2007. In this track; our interest is driven bytwo related lines of research: e cient multi-stage retrieval [3–7; 9; 14]; where it is believedthat improving recall in early stage retrieval can improve end-to-ende ectiveness; and morereliable deep evaluation when using shallow judgments [8; 10–13]. By participating in …,*,*,*
6 Working groups 6.1 PRIMAD–Information gained by different types of reproducibility,Andreas Rauber; Vanessa Braganholo; Jens Dittrich; Nicola Ferro; Juliana Freire; Norbert Fuhr; Daniel Garijo; Carole Goble; Kalervo Järvelin; Bertram Ludäscher; Benno Stein; Rainer Stotzka,What is “reproducibility” anyways? And how is it different from “repeatability”;“replicability”; orany of the other r-words? There are already a number of attempts at defining and sorting outthese different notions. De Roure [1] lists 21 different r-words grouped into 6 categories;stating that reproducibility means reusing a research object with a change to somecircumstances; inputs; resources or components in order to see if the same results areachieved independent of those changes. Often these notions are context-sensitive (eg;validation vs verification have rather precise and very different meanings in differentcommunities. As an alternative approach to sort out terminological confusions; we attemptedto look at a different perspective. When trying to reproduce a study; what are the things thatare kept the same (eg; the overall method or algorithm) and what is changed (eg; the …,Reproducibility of Data-Oriented Experiments in e-Science,*,*
Applying Data Fusion to IR4QA in Japanese using Word Search and Character-based N-gram Search,Michiko Yasukawa; J Shane Culpepper; Falk Scholer,Abstract This paper presents discussion of data fusion methods using word search andcharacter-based n-gram search in Japanese. We show how to improve search effectivenessusing data fusion on the NTCIR IR4QA task. For the experimental evaluation; we use fiveimportant Japanese linguistic tools and 21 state-of-the-art search models. Experimentalresults demonstrate that the combination of the two different approaches can reliablyimprove search effectiveness.,*,*,*
