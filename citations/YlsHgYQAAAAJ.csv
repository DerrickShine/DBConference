Aurora: a new model and architecture for data stream management,Daniel J Abadi; Don Carney; Ugur Çetintemel; Mitch Cherniack; Christian Convey; Sangdon Lee; Michael Stonebraker; Nesime Tatbul; Stan Zdonik,Abstract. This paper describes the basic processing model and architecture of Aurora; a newsystem to manage data streams for monitoring applications. Monitoring applications differsubstantially from conventional business data processing. The fact that a software systemmust process and react to continual inputs from many sources (eg; sensors) rather than fromhuman operators requires one to rethink the fundamental architecture of a DBMS for thisapplication area. In this paper; we present Aurora; a new DBMS currently under constructionat Brandeis University; Brown University; and MIT We first provide an overview of the basicAurora model and architecture and then describe in detail a stream-oriented set ofoperators.,the VLDB Journal,2003,1722
The design of the borealis stream processing engine,Daniel J Abadi; Yanif Ahmad; Magdalena Balazinska; Ugur Cetintemel; Mitch Cherniack; Jeong-Hyon Hwang; Wolfgang Lindner; Anurag S Maskey; Alexander Rasin; Esther Ryvkina; Nesime Tatbul; Ying Xing; Stan Zdonik,Abstract Borealis is a second-generation distributed stream processing engine that is beingdeveloped at Brandeis University; Brown University; and MIT. Borealis inherits core streamprocessing functionality from Aurora [14] and distribution functionality from Medusa [51].Borealis modifies and extends both systems in non-trivial and critical ways to provideadvanced capabilities that are commonly required by newly-emerging stream processingapplications. In this paper; we outline the basic design and functionality of Borealis. Throughsample real-world applications; we motivate the need for dynamically revising query resultsand modifying query specifications. We then describe how Borealis addresses thesechallenges through an innovative set of features; including revision records; time travel; andcontrol lines. Finally; we present a highly flexible and scalable QoS-based optimization …,Second Biennial Conference on Innovative Data Systems Research (CIDR 2005); Asilomar; CA,2005,1517
Monitoring streams—a new class of data management applications,Don Carney; Uğur Çetintemel; Mitch Cherniack; Christian Convey; Sangdon Lee; Greg Seidman; Nesime Tatbul; Stan Zdonik; Michael Stonebraker,Monitoring applications are those where streams of information; triggers; real-timerequirements; and imprecise data are prevalent. Traditional DBMSs are based on the HADPmodel; and thus cannot provide adequate support for such applications. Traditional DBMSshave been oriented toward business data processing; and consequently are designed toaddress the needs of these applications. First; they have assumed that the DBMS is apassive repository storing a large collection of data elements; and that humans initiatequeries and transactions on this repository. Second; they have assumed that the currentstate of the data is the only thing that is important. Hence; current values of data elementsare easy to obtain; while previous values can only be found torturously by decoding theDBMS log. The third assumption is that triggers and alerters are second-class citizens …,*,2002,1148
Load shedding in a data stream manager,Nesime Tatbul; Uğur Çetintemel; Stan Zdonik; Mitch Cherniack; Michael Stonebraker,This chapter discusses load shedding in a data stream manager. A Data Stream Manageraccepts push-based inputs from a set of data sources; processes these inputs with respect toa set of standing queries; and produces outputs based on Quality-of-Service (QoS)specifications. When input rates exceed system capacity; the system will becomeoverloaded and latency will deteriorate. Under these conditions; the system will shed load;thus degrading the answer; to improve the observed latency of the results. The chapterexamines a technique for dynamically inserting and removing drop operators into queryplans as required by the current load. It examines two types of drops: the first drops a fractionof the tuples in a randomized fashion; and the second drops tuples based on the importanceof their content. The chapter addresses the problems of determining when load shedding …,Proceedings of the 29th international conference on Very large data bases-Volume 29,2003,693
Aurora: a data stream management system,Daniel Abadi; Donald Carney; Ugur Cetintemel; Mitch Cherniack; Christian Convey; C Erwin; Eduardo Galvez; M Hatoun; Anurag Maskey; Alex Rasin; A Singer; Michael Stonebraker; Nesime Tatbul; Ying Xing; Rongguo Yan; S Zdonik,Streams are continuous data feeds generated by such sources as sensors; satellites; andstock feeds. Monitoring applications track data from numerous streams; filtering them forsigns of abnormal activity; and processing them for purposes of filtering; aggregation;reduction; and correlation. Aurora [1; 2; 3] is a general-purpose data stream manager that isbeing designed and implemented (at Brandeis University; Brown University; and MIT) toefficiently support a variety of real-time monitoring applications.,Proceedings of the 2003 ACM SIGMOD international conference on Management of data,2003,222
Retrospective on aurora,Hari Balakrishnan; Magdalena Balazinska; Don Carney; Uğur Çetintemel; Mitch Cherniack; Christian Convey; Eddie Galvez; Jon Salz; Michael Stonebraker; Nesime Tatbul; Richard Tibbetts; Stan Zdonik,Abstract. This experience paper summarizes the key lessons we learned throughout thedesign and implementation of the Aurora stream-processing engine. For the past 2 years;we have built five stream-based applications using Aurora. We first describe in detail theseapplications and their implementation in Aurora. We then reflect on the design of Aurorabased on this experience. Finally; we discuss our initial ideas on a follow-on project; calledBorealis; whose goal is to eliminate the limitations of Aurora as well as to address new keychallenges and applications in the stream-processing domain.,The VLDB Journal,2004,192
Window-aware load shedding for aggregation queries over data streams,Nesime Tatbul; Stan Zdonik,Abstract Data stream management systems may be subject to higher input rates than theirresources can handle. When overloaded; the system must shed load in order to maintainlow-latency query results. In this paper; we describe a load shedding technique for queriesconsisting of one or more aggregate operators with sliding windows. We introduce a newtype of drop operator; called a" Window Drop". This operator is aware of the windowproperties (ie; window size and window slide) of its downstream aggregate operators in thequery plan. Accordingly; it logically divides the input stream into windows andprobabilistically decides which windows to drop. This decision is further encoded into tuplesby marking the ones that are disallowed from starting new windows. Unlike earlierapproaches; our approach preserves integrity of windows throughout a query plan; and …,Proceedings of the 32nd international conference on Very large data bases,2006,150
Plan-based complex event detection across distributed sources,Mert Akdere; Uǧur Çetintemel; Nesime Tatbul,Abstract Complex Event Detection (CED) is emerging as a key capability for manymonitoring applications such as intrusion detection; sensor-based activity & phenomenatracking; and network monitoring. Existing CED solutions commonly assume centralizedavailability and processing of all relevant events; and thus incur significant overhead indistributed settings. In this paper; we present and evaluate communication efficienttechniques that can efficiently perform CED across distributed event sources. Ourtechniques are plan-based: we generate multi-step event acquisition and processing plansthat leverage temporal relationships among events and event occurrence statistics tominimize event transmission costs; while meeting application-specific latency expectations.We present an optimal but exponential-time dynamic programming algorithm and two …,Proceedings of the VLDB Endowment,2008,147
Staying fit: Efficient load shedding techniques for distributed stream processing,Nesime Tatbul; Uǧur Çetintemel; Stan Zdonik,Abstract In distributed stream processing environments; large numbers of continuousqueries are distributed onto multiple servers. When one or more of these servers becomeoverloaded due to bursty data arrival; excessive load needs to be shed in order to preservelow latency for the query results. Because of the load dependencies among the servers; loadshedding decisions on these servers must be well-coordinated to achieve end-to-endcontrol on the output quality. In this paper; we model the distributed load shedding problemas a linear optimization problem; for which we propose two alternative solution approaches:a solver-based centralized approach; and a distributed approach based on metadataaggregation and propagation; whose centralized implementation is also available. Both ofour solutions are based on generating a series of load shedding plans in advance; to be …,Proceedings of the 33rd international conference on Very large data bases,2007,142
SECRET: a model for analysis of the execution semantics of stream processing systems,Irina Botan; Roozbeh Derakhshan; Nihal Dindar; Laura Haas; Renée J Miller; Nesime Tatbul,Abstract There are many academic and commercial stream processing engines (SPEs)today; each of them with its own execution semantics. This variation may lead to seeminglyinexplicable differences in query results. In this paper; we present SECRET; a model of thebehavior of SPEs. SECRET is a descriptive model that allows users to analyze the behaviorof systems and understand the results of window-based queries for a broad range ofheterogeneous SPEs. The model is the result of extensive analysis and experimentationwith several commercial and academic engines. In the paper; we describe the types ofheterogeneity found in existing engines; and show with experiments on real systems that ourmodel can explain the key differences in windowing behavior.,Proceedings of the VLDB Endowment,2010,104
Distributed operation in the borealis stream processing engine,Yanif Ahmad; Bradley Berg; Uǧur Cetintemel; Mark Humphrey; Jeong-Hyon Hwang; Anjali Jhingran; Anurag Maskey; Olga Papaemmanouil; Alexander Rasin; Nesime Tatbul; Wenjuan Xing; Ying Xing; Stan Zdonik,Abstract Borealis is a distributed stream processing engine that is being developed atBrandeis University; Brown University; and MIT. Borealis inherits core stream processingfunctionality from Aurora and inter-node communication functionality from Medusa. Wepropose to demonstrate some of the key aspects of distributed operation in Borealis; using amulti-player network game as the underlying application. The demonstration will illustratethe dynamic resource management; query optimization and high availability mechanismsemployed by Borealis; using visual performance-monitoring tools as well as the gamingexperience.,Proceedings of the 2005 ACM SIGMOD international conference on Management of data,2005,90
Dejavu: declarative pattern matching over live and archived streams of events,Nihal Dindar; Baris Güç; Patrick Lau; Asli Ozal; Merve Soner; Nesime Tatbul,Abstract DejaVu is an event processing system that integrates declarative pattern matchingover live and archived streams of events on top of a novel system architecture. We proposeto demonstrate the key aspects of the DejaVu query language and architecture using twodifferent application scenarios; namely a smart RFID library system and a financial marketdata analysis application. The demonstration will illustrate how DejaVu can uniformly handleone-time; continuous; and hybrid pattern matching queries over live and archived streamstores; using highly interactive visual monitoring tools including one that is based on theSecond Life virtual world.,Proceedings of the 2009 ACM SIGMOD International Conference on Management of data,2009,66
A demonstration of the bigdawg polystore system,Aaron Elmore; Jennie Duggan; Mike Stonebraker; Magdalena Balazinska; Ugur Cetintemel; Vijay Gadepally; Jeffrey Heer; Bill Howe; Jeremy Kepner; Tim Kraska; Samuel Madden; David Maier; Timothy Mattson; Stavros Papadopoulos; Jeff Parkhurst; Nesime Tatbul; Manasi Vartak; Stan Zdonik,Abstract This paper presents BigDAWG; a reference implementation of a new architecturefor" Big Data" applications. Such applications not only call for large-scale analytics; but alsofor real-time streaming support; smaller analytics at interactive speeds; data visualization;and cross-storage-system queries. Guided by the principle that" one size does not fit all"; webuild on top of a variety of storage engines; each designed for a specialized use case. Toillustrate the promise of this approach; we demonstrate its effectiveness on a hospitalapplication using data from an intensive care unit (ICU). This complex application serves theneeds of doctors and researchers and provides real-time support for streams of patient data.It showcases novel approaches for querying across multiple storage engines; datavisualization; and scalable real-time analytics.,Proceedings of the VLDB Endowment,2015,55
Streaming data integration: Challenges and opportunities,Nesime Tatbul,In this position paper; we motivate the need for streaming data integration in three mainforms including across multiple streaming data sources; over multiple stream processingengine instances; and between stream processing engines and traditional databasesystems. We argue that this need presents a broad range of challenges and opportunities fornew research. We provide an overview of the young state of the art in this area and furtherdiscuss a selected set of concrete research topics that are currently under investigationwithin the scope of our MaxStream federated stream processing project at ETH Zurich.,Data Engineering Workshops (ICDEW); 2010 IEEE 26th International Conference on,2010,50
S-Store: a streaming NewSQL system for big velocity applications,Ugur Cetintemel; Jiang Du; Tim Kraska; Samuel Madden; David Maier; John Meehan; Andrew Pavlo; Michael Stonebraker; Erik Sutherland; Nesime Tatbul; Kristin Tufte; Hao Wang; Stanley Zdonik,Abstract First-generation streaming systems did not pay much attention to state managementvia ACID transactions (eg;[3; 4]). S-Store is a data management system that combines OLTPtransactions with stream processing. To create S-Store; we begin with H-Store; a main-memory transaction processing engine; and add primitives to support streaming. Thisincludes triggers and transaction workflows to implement push-based processing; windowsto provide a way to bound the computation; and tables with hidden state to implementscoping for proper isolation. This demo explores the benefits of this approach by showinghow a naïve implementation of our benchmarks using only H-Store can yield incorrectresults. We also show that by exploiting push-based semantics and our implementation oftriggers; we can achieve significant improvement in transaction throughput. We demo two …,Proceedings of the VLDB Endowment,2014,44
Efficiently correlating complex events over live and archived data streams,Nihal Dindar; Peter M Fischer; Merve Soner; Nesime Tatbul,Abstract Correlating complex events over live and archived data streams; which we callPattern Correlation Queries (PCQs); provides many benefits for domains which need realtime forecasting of events or identification of causal dependencies; while handling data athigh rates and in massive amounts; like in financial or medical settings. Existing work hasfocused either on complex event processing over a single type of stream source (ie; eitherlive or archived); or on simple stream correlation queries (eg; live events trigerring adatabase lookup). In this paper; we specifically focus on recency-based PCQs and provideclear; useful; and optimizable semantics for them. PCQs raise a number of challenges inoptimizing data management and query processing; which we address in the setting of theDejaVu complex event processing system. More specifically; we propose three …,Proceedings of the 5th ACM international conference on Distributed event-based system,2011,44
Design and implementation of a distributed workflow management system: Metuflow,Asuman Dogac; Esin Gokkoca; Sena Arpinar; Pinar Koksal; Ibrahim Cingil; Budak Arpinar; Nesime Tatbul; Pinar Karagoz; Ugur Halici; Mehmet Altinel,Abstract Workflows are activities involving the coordinated execution of multiple tasksperformed by different processing entities; mostly in distributed heterogeneousenvironments which are very common in enterprises of even moderate complexity.Centralized workflow systems fall short to meet the demands of such environments. Thispaper describes the design and implementation of a distributed workflow managementsystem; namely; METUFIow. The main contribution of this prototype is to provide a trulydistributed execution environment; where the scheduler; the history manager and theworklist manager of the system are fully distributed giving rise to failure resiliency andincreased performance.,*,1998,43
Confidence-based data management for personal area sensor networks,Nesime Tatbul; Mark Buller; Reed Hoyt; Steve Mullen; Stan Zdonik,Abstract The military is working on embedding sensors in a" smart uniform" that will monitorkey biological parameters to determine the physiological status of a soldier. The soldier'sstatus can only be determined accurately by combining the readings from several sensorsusing sophisticated physiological models. Unfortunately; the physical environment and thelow-bandwidth; push-based personal-area network (PAN) introduce uncertainty in the inputsto the models. Thus the model must produce a confidence level as well as a physiologicalstatus value. This paper explores how confidence levels can be used to influence datamanagement decisions. In particular; we look at power-efficient ways to keep the confidenceabove a given threshold. We also contrast push-based broadcast schedules with otherschedules that are made possible by two-way communication.,Proceeedings of the 1st international workshop on Data management for sensor networks: in conjunction with VLDB 2004,2004,41
Flexible and scalable storage management for data-intensive stream processing,Irina Botan; Gustavo Alonso; Peter M Fischer; Donald Kossmann; Nesime Tatbul,Abstract Data Stream Management Systems (DSMS) operate under strict performancerequirements. Key to meeting such requirements is to efficiently handle time-critical taskssuch as managing internal states of continuous query operators; traffic on the queuesbetween operators; as well as providing storage support for shared computation andarchived data. In this paper; we introduce a general purpose storage managementframework for DSMSs that performs these tasks based on a clean; loosely-coupled; andflexible system design that also facilitates performance optimization. An importantcontribution of the framework is that; in analogy to buffer management techniques inrelational database systems; it uses information about the access patterns of streamingapplications to tune and customize the performance of the storage manager. In the paper …,Proceedings of the 12th International Conference on Extending Database Technology: Advances in Database Technology,2009,39
S-Store: streaming meets transaction processing,John Meehan; Nesime Tatbul; Stan Zdonik; Cansu Aslantas; Ugur Cetintemel; Jiang Du; Tim Kraska; Samuel Madden; David Maier; Andrew Pavlo; Michael Stonebraker; Kristin Tufte; Hao Wang,Abstract Stream processing addresses the needs of real-time applications. Transactionprocessing addresses the coordination and safety of short atomic computations. Heretofore;these two modes of operation existed in separate; stove-piped systems. In this work; weattempt to fuse the two computational paradigms in a single system called S-Store. In thisway; S-Store can simultaneously accommodate OLTP and streaming applications. Wepresent a simple transaction model for streams that integrates seamlessly with a traditionalOLTP system; and provides both ACID and stream-oriented guarantees. We chose to build S-Store as an extension of H-Store-an open-source; in-memory; distributed OLTP databasesystem. By implementing S-Store in this way; we can make use of the transaction processingfacilities that H-Store already provides; and we can concentrate on the additional features …,Proceedings of the VLDB Endowment,2015,38
Rip: Run-based intra-query parallelism for scalable complex event processing,Cagri Balkesen; Nihal Dindar; Matthias Wetter; Nesime Tatbul,Abstract Recognition of patterns in event streams has become important in many applicationareas of Complex Event Processing (CEP) including financial markets; electronic health-care systems; and security monitoring systems. In most applications; patterns have to bedetected continuously and in real-time over streams that are generated at very high rates;imposing high-performance requirements on the underlying CEP system. For scaling CEPsystems to increasing workloads; parallel pattern matching techniques that can exploit multi-core processing opportunities are needed. In this paper; we propose RIP-a Run-based Intra-query Parallelism technique for scalable pattern matching over event streams. RIPdistributes input events that belong to individual run instances of a pattern's Finite StateMachine (FSM) to different processing units; thereby providing fine-grained partitioned …,Proceedings of the 7th ACM international conference on Distributed event-based systems,2013,37
Dealing with overload in distributed stream processing systems,Nesime Tatbul; Stan Zdonik,Overload management has been an important problem for large-scale dynamic systems. Inthis paper; we study this problem in the context of our Borealis distributed stream processingsystem. We show that server nodes must coordinate in their load shedding decisions toachieve global control on output quality. We describe a distributed load shedding approachwhich provides this coordination by upstream metadata aggregation and propagation.Metadata enables an upstream node to make fast local load shedding decisions which willinfluence its descendant nodes in the best possible way.,Data Engineering Workshops; 2006. Proceedings. 22nd International Conference on,2006,34
Load shedding on data streams,Nesime Tatbul; Ugur Çetintemel; Stan Zdonik; Mitch Cherniack; Michael Stonebraker,Page 1. Load Shedding on Data Streams Nesime Tatbul; Uğur Çetintemel; Stan Zdonik @ BrownUniversity Mitch Cherniack @ Brandeis University Michael Stonebraker @ MIT Page 2. HandlingOverload with Load Shedding ∎ real-time data pushed from financial data feeds; sensors; andalike ∎ high and unpredictable data rates ∎ resource overload => growing queues and late results ∎solution: “load shedding” ∎ eliminate excess load by dropping data Page 3. Drop k % RandomDrop Filter P(value) Semantic Drop Load Shedding by Inserting Drops QoS QoS ☠ ☠ σ π U σ πσ two types of drops: Page 4. Quality of Service ∎ Value-based QoS ∎ Loss-tolerance QoS utility %delivery 100 50 0 1.0 0.7 utility values 0 80 120 200 1.0 0.4 ▪ Latency-based QoS is handled byscheduler. Page 5. Problem Statement ∎ N: query network ∎ I : set of input streams ∎ C: processingcapacity when Load(N(I)) > C; transform N to N' …,Proceedings of the Workshop on Management and Processing of Data Streams (MPDS 03); San Diego; CA; USA,2003,34
An open electronic marketplace through agent-based workflows: MOPPET,Sena Arpinar; Asuman Dogac; Nesime Tatbul,Abstract. We propose an electronic marketplace architecture; called MOPPET; where thecommerce processes in the marketplace are modeled as adaptable agent-based workflows.The higher level of abstraction provided by the workflow technology makes thecustomization of electronic commerce processes for different users possible. Agent-basedimplementation; on the other hand; provides for a highly reusable component-basedworkflow architecture as well as negotiation ability and the capability to adapt to dynamicchanges in the environment. Agent communication is handled through Knowledge Queryand Manipulation Language (KQML). A workflow-based architecture also makes it possiblefor complete modeling of electronic commerce processes by allowing involved parties to beable to invoke already existing applications or to define new tasks and to re-structure the …,International Journal on Digital Libraries,2000,33
Stream as you go: The case for incremental data access and processing in the cloud,Romeo Kienzler; Remy Bruggmann; Anand Ranganathan; Nesime Tatbul,Cloud infrastructures promise to provide high-performance and cost-effective solutions tolarge-scale data processing problems. In this paper; we identify a common class of data-intensive applications for which data transfer latency for uploading data into the cloud inadvance of its processing may hinder the linear scalability advantage of the cloud. For suchapplications; we propose a" stream-as-you-go" approach for incrementally accessing andprocessing data based on a stream data management architecture. We describe ourapproach in the context of a DNA sequence analysis use case and compare it against thestate of the art in MapReduce-based DNA sequence analysis and incremental MapReduceframeworks. We provide experimental results over an implementation of our approachbased on the IBM InfoSphere Streams computing platform deployed on Amazon EC2 …,Data Engineering Workshops (ICDEW); 2012 IEEE 28th International Conference on,2012,31
Modeling the execution semantics of stream processing engines with SECRET,Nihal Dindar; Nesime Tatbul; Renée J Miller; Laura M Haas; Irina Botan,Abstract There are many academic and commercial stream processing engines (SPEs)today; each of them with its own execution semantics. This variation may lead to seeminglyinexplicable differences in query results. In this paper; we present SECRET; a model of thebehavior of SPEs. SECRET is a descriptive model that allows users to analyze the behaviorof systems and understand the results of window-based queries (with time-and tuple-basedwindows) for a broad range of heterogeneous SPEs. The model is the result of extensiveanalysis and experimentation with several commercial and academic engines. In the paper;we describe the types of heterogeneity found in existing engines and show with experimentson real systems that our model can explain the key differences in windowing behavior.,The VLDB Journal,2013,30
Adaptive input admission and management for parallel stream processing,Cagri Balkesen; Nesime Tatbul; M Tamer Özsu,Abstract In this paper; we propose a framework for adaptive admission control andmanagement of a large number of dynamic input streams in parallel stream processingengines. The framework takes as input any available information about input streambehaviors and the requirements of the query processing layer; and adaptively decides howto adjust the entry points of streams to the system. As the optimization decisions propagateearly from input management layer to the query processing layer; the size of the cluster isminimized; the load balance is maintained; and latency bounds of queries are met in a moreeffective and timely manner. Declarative integration of external meta-data about datasources makes the system more robust and resource-efficient. Additionally; exploitingknowledge about queries moves data partitioning to the input management layer; where …,Proceedings of the 7th ACM international conference on Distributed event-based systems,2013,29
Design and implementation of the MaxStream federated stream processing architecture,Irina Botan; Younggoo Cho; Roozbeh Derakhshan; Nihal Dindar; Laura M Haas; Kihong Kim; Chulwon Lee; Girish Mundada; Ming-Chien Shan; Nesime Tatbul; Ying Yan; Beomjin Yun; Jin Zhang,Despite the availability of several commercial data stream processing engines (SPEs); itremains hard to develop and maintain streaming applications. A major difficulty is the lack ofstandards; and the wide (and changing) variety of application requirements. Consequently;existing SPEs vary widely in data and query models; APIs; functionality; and optimizationcapabilities. This has led to some organizations using multiple SPEs; based on theirapplication needs. Furthermore; management of stored data and streaming data are stillmostly separate concerns; although applications increasingly require integrated access toboth. In the MaxStream project; our goal is to design and build a federated streamprocessing architecture that seamlessly integrates multiple autonomous and heterogeneousSPEs with traditional databases; and hence facilitates the incorporation of new …,Technical report/ETH; Department of Computer Science,2009,29
Federated stream processing support for real-time business intelligence applications,Irina Botan; Younggoo Cho; Roozbeh Derakhshan; Nihal Dindar; Laura Haas; Kihong Kim; Nesime Tatbul,Abstract In this paper; we describe the MaxStream federated stream processing architectureto support real-time business intelligence applications. MaxStream builds on and extendsthe SAP MaxDB relational database system in order to provide a federator over multipleunderlying stream processing engines and databases. We show preliminary results onusefulness and performance of the MaxStream architecture on the SAP Sales andDistribution Benchmark.,International Workshop on Business Intelligence for the Real-Time Enterprise,2009,28
Qos-driven load shedding on data streams,Nesime Tatbul,Abstract In this thesis; we are working on the optimized execution of very large number ofcontinuous queries defined on data streams. Our scope includes both classical queryoptimization issues adapted to the stream data environment as well as analysis andresolution of overload situations by intelligently discarding data based on applicationdependent quality of service (QoS) information. This paper serves as a prelude to our viewof the problem and a promising approach to solve it.,International Conference on Extending Database Technology,2002,26
A workflow-based electronic marketplace on the Web,Asuman Dogac; Ilker Durusoy; Sena Arpinar; Nesime Tatbul; Pinar Koksal; Ibrahim Cingil; Nazife Dimililer,Abstract In this paper; we describe an architecture for an open marketplace exploiting theworkflow technology and the currently emerging data exchange and metadatarepresentation standards on the Web. In this market architecture electronic commerce isrealized through the adaptable workflow templates provided by the marketplace to its users.Having workflow templates for electronic commerce processes results in a component-based architecture where components can be agents (both buying and selling) as well asexisting applications invoked by the workflows. Other advantages provided by the workflowtechnology are forward recovery; detailed logging of the processes through workflow historymanager and being able to specify data and control flow among the workflow components.In the architecture proposed; the resources expose their metadata using Resource …,ACM SIGMOD Record,1998,24
Transactional stream processing,Irina Botan; Peter M Fischer; Donald Kossmann; Nesime Tatbul,Abstract Many stream processing applications require access to a multitude of streaming aswell as stored data sources. Yet there is no clear semantics for correct continuous queryexecution over these data sources in the face of concurrent access and failures. Instead;today's Stream Processing Systems (SPSs) hard-code transactional concepts in theirexecution models; making them both hard to understand and inflexible to use. In this paper;we show that we can successfully reuse the traditional transactional theory (with someminimal extensions) in order to cleanly define the correct interaction of a set of continuousand one-time queries concurrently accessing both streaming and stored data sources. Theresult is a unified transactional model (UTM) for query processing over streams as well astraditional databases. We present a transaction manager that implements this model on …,Proceedings of the 15th International Conference on Extending Database Technology,2012,23
Event processing support for cross-reality environments,Nihal Dindar; Çagri Balkesen; Katina Kromwijk; Nesime Tatbul,Complex event processing (CEP) is an essential functionality for cross-reality environments.Through CEP; we can turn raw sensor data generated in the real world into more meaningfulinformation that has some significance for the virtual world. In this article; the authors presentDejaVu; a general-purpose event processing system built at ETH Zurich. SmartRFLib; across-reality application; builds on DejaVu and enables real-time event detection over RFIDdata streams feeding a virtual library on second life.,IEEE Pervasive Computing,2009,20
Scalable data partitioning techniques for parallel sliding window processing over data streams,Cagri Balkesen; Nesime Tatbul,ABSTRACT This paper proposes new techniques for efficiently parallelizing sliding windowprocessing over data streams on a shared-nothing cluster of commodity hardware. Datastreams are first partitioned on the fly via a continuous split stage that takes the querysemantics into account in a way that respects the natural chunking (windowing) of thestream by the query. The split does not scale well enough when there is high degree ofoverlap across the windows. To remedy this problem; we propose two alternativepartitioning strategies based on batching and pane-based processing; respectively. Lastly;we provide a continuous merge stage at the end that combines the results on the fly whilemeeting QoS requirements on ordered delivery. We implemented these techniques as partof the Borealis distributed stream processing system; and conducted experiments that …,International Workshop on Data Management for Sensor Networks (DMSN),2011,18
Load management and high availability in the borealis distributed stream processing engine,Nesime Tatbul; Yanif Ahmad; Uğur Çetintemel; Jeong-Hyon Hwang; Ying Xing; Stan Zdonik,Abstract Borealis is a distributed stream processing engine that has been developed atBrandeis University; Brown University; and MIT. It extends the first generation of data streamprocessing systems with advanced capabilities such as distributed operation; scalability withtime-varying load; high availability against failures; and dynamic data and querymodifications. In this paper; we focus on aspects that are related to load management andhigh availability in Borealis. We describe our algorithms for balanced and resilient loaddistribution; scalable distributed load shedding; and cooperative and self-configuring highavailability. We also present experimental results from our prototype implementationshowing the effectiveness of these algorithms.,*,2008,18
Ariadne: Managing fine-grained provenance on data streams,Boris Glavic; Kyumars Sheykh Esmaili; Peter Michael Fischer; Nesime Tatbul,Abstract Managing fine-grained provenance is a critical requirement for data streammanagement systems (DSMS); not only to address complex applications that requirediagnostic capabilities and assurance; but also for providing advanced functionality such asrevision processing or query debugging. This paper introduces a novel approach that usesoperator instrumentation; ie; modifying the behavior of operators; to generate and propagatefine-grained provenance through several operators of a query network. In addition toapplying this technique to compute provenance eagerly during query execution; we alsostudy how to decouple provenance computation from query processing to reduce run-timeoverhead and avoid unnecessary provenance retrieval. This includes computing a concisesuperset of the provenance to allow lazily replaying a query network and reconstruct its …,Proceedings of the 7th ACM international conference on Distributed event-based systems,2013,17
Changing flights in mid-air: a model for safely modifying continuous queries,Kyumars Sheykh Esmaili; Tahmineh Sanamrad; Peter M Fischer; Nesime Tatbul,Abstract Continuous queries can run for unpredictably long periods of time. During theirlifetime; these queries may need to be adapted either due to changes in applicationsemantics (eg; the implementation of a new alert detection policy); or due to changes in thesystem's behavior (eg; adapting performance to a changing load). While in previous worksquery modification has been implicitly utilized to serve specific purposes (eg; loadmanagement); to date no research has been done that defines a general-purpose; reliable;and efficiently implementable model for modifying continuous queries at run-time. In thispaper; we introduce a punctuation-based framework that can formally express arbitrarylifecycle operations on the basis of input-output mappings and basic control elements suchas start or stop of queries. On top of this foundation; we derive all possible query change …,Proceedings of the 2011 ACM SIGMOD International Conference on Management of data,2011,17
A workflow system through cooperating agents for control and document flow over the internet,Asuman Dogac; Yusuf Tambag; Arif Tumer; M Ezbiderli; Nesime Tatbul; N Hamali; C Icdem; Catriel Beeri,Abstract In this paper we describe an architecture that provides for automating andmonitoring the flow of control and document over the Internet among different organizations;thereby creating a platform necessary to describe higher order processes involving severalorganizations and companies. The higher order process is designed through a graphicaluser interface and is executed through cooperating agents that are automatically initializedat each site that the process executes. Agents handle the activities at their site; provide forcoordination with other agents in the system by routing the documents in electronic formaccording to the process description. The system is capable of activating externalapplications (which may be inside the company firewall) when necessary; keeping track ofprocess information; and providing for the security and authentication of documents as …,International Conference on Cooperative Information Systems,2000,17
Large-scale DNA sequence analysis in the cloud: a stream-based approach,Romeo Kienzler; Rémy Bruggmann; Anand Ranganathan; Nesime Tatbul,Abstract Cloud computing technologies have made it possible to analyze big data sets inscalable and cost-effective ways. DNA sequence analysis; where very large data sets arenow generated at reduced cost using the Next-Generation Sequencing (NGS) methods; isan area which can greatly benefit from cloud-based infrastructures. Although existingsolutions show nearly linear scalability; they pose significant limitations in terms of datatransfer latencies and cloud storage costs. In this paper; we propose to tackle theperformance problems that arise from having to transfer large amounts of data betweenclients and the cloud based on a streaming data management architecture. Our approachprovides an incremental data processing model which can hide data transfer latencies whilemaintaining linear scalability. We present an initial implementation and evaluation of this …,European Conference on Parallel Processing,2011,16
The Case for Fine-Grained Stream Provenance.,Boris Glavic; Kyumars Sheykh Esmaili; Peter M Fischer; Nesime Tatbul,Abstract: The current state of the art for provenance in data stream management systems(DSMS) is to provide provenance at a high level of abstraction (such as; from which sensorsin a sensor network an aggregated value is derived from). This limitation was imposed byhigh-throughput requirements and an anticipated lack of application demand for moredetailed provenance information. In this work; we first demonstrate by means of well-chosenuse cases that this is a misconception; ie; coarse-grained provenance is in fact insufficientfor many application domains. We then analyze the requirements and challenges involvedin integrating support for fine-grained provenance into a streaming system and outline ascalable solution for supporting tuple-level provenance in DSMS.,BTW Workshops,2011,15
A demonstration of the MaxStream federated stream processing system,Irina Botan; Younggoo Cho; Roozbeh Derakhshan; Nihal Dindar; Ankush Gupta; Laura Haas; Kihong Kim; Chulwon Lee; Girish Mundada; Ming-Chien Shan; Nesime Tatbul; Ying Yan; Beomjin Yun; Jin Zhang,MaxStream is a federated stream processing system that seamlessly integrates multipleautonomous and heterogeneous Stream Processing Engines (SPEs) and databases. In thispaper; we propose to demonstrate the key features of MaxStream using two applicationscenarios; namely the Sales Map & Spikes business monitoring scenario and the LinearRoad Benchmark; each with a different set of requirements. More specifically; we will showhow the MaxStream Federator can translate and forward the application queries to twodifferent commercial SPEs (Coral8 and StreamBase); as well as how it does so undervarious persistency requirements.,Data Engineering (ICDE); 2010 IEEE 26th International Conference on,2010,15
An adaptable workflow system architecture on the Internet for electronic commerce applications,R Cingil; Asuman Dogac; Nesime Tatbul; Sena Arpinar,An electronic commerce (EC) process is a business process and defining it as a workflowprovides all the advantages that come with this technology. Yet electronic commerceprocesses place certain demands on the workflow technology like the distribution of the loadof the workflow engine to multiple servers; dynamic modification of workflows foradaptability; openness and availability. We propose a workflow system architecture toaddress these issues. The componentwise architecture of the system makes it possible toincorporate the functionality and thus the complexity only when it is actually needed. Theinfrastructure of the system is based on CORBA 2.0 where methods are invoked throughXML. The clients of the system are coded as network transportable applets written in Java sothat the end user can activate workflow components through the workflow domain …,Distributed Objects and Applications; 1999. Proceedings of the International Symposium on,1999,14
The Aurora and Borealis Stream Processing Engines,Uğur Çetintemel; Daniel Abadi; Yanif Ahmad; Hari Balakrishnan; Magdalena Balazinska; Mitch Cherniack; Jeong-Hyon Hwang; Samuel Madden; Anurag Maskey; Alexander Rasin; Esther Ryvkina; Mike Stonebraker; Nesime Tatbul; Ying Xing; Stan Zdonik,Abstract Over the last several years; a great deal of progress has been made in the area ofstream-processing engines (SPEs). Three basic tenets distinguish SPEs from current dataprocessing engines. First; they must support primitives for streaming applications. UnlikeOnline Transaction Processing (OLTP); which processes messages in isolation; streamingapplications entail time series operations on streams of messages. Second; streamingapplications entail a real-time component. If one is content to see an answer later; then onecan store incoming messages in a data warehouse and run a historical query on thewarehouse to find information of interest. This tactic does not work if the answer must beconstructed in real time. The need for real-time answers also dictates a fundamentallydifferent storage architecture. DBMSs universally store and index data records before …,*,2016,13
Are we experiencing a big data bubble?,Fatma Özcan; Nesime Tatbul; Daniel J Abadi; Marcel Kornacker; C Mohan; Karthik Ramasamy; Janet Wiener,Over the last decade; the database field has seen resurgence with the big data wave.Accelerated increase in data volumes; and modern hardware have been two major factorsthat brought in significant investment in new database technologies. Our field has benefitedfrom this increased interest and focus. There is now an abundance of NoSQL; NewSQL; andSQL-on-Hadoop systems. According to nosql-database. org; the list of NoSQL databases [6]has reached 150. Many of these systems claim horizontal scalability; and support for non-relational data. However; this high scalability usually comes at the cost of strong support forACID transactions. Most of them only provide eventual consistency; or even worse; defermanaging transactional semantics to the application layer. Another important aspect of theseNoSQL systems is the lack of declarative query interfaces. Most only support …,Proceedings of the 2014 ACM SIGMOD international conference on Management of data,2014,13
Virtualizing stream processing,Michael Duller; Jan S Rellermeyer; Gustavo Alonso; Nesime Tatbul,Abstract Stream processing systems have evolved into established solutions as standaloneengines but they still lack flexibility in terms of large-scale deployment; integration;extensibility; and interoperability. In the last years; a substantial ecosystem of newapplications has emerged that can potentially benefit from stream processing but introducesdifferent requirements on how stream processing solutions can be integrated; deployed;extended; and federated. To address these needs; we present an exoengine architectureand the associated ExoP platform. Together; they provide the means for encapsulatingcomponents of stream processing systems as well as automating the data exchangebetween components and their distributed deployment. The proposed solution can be used;eg; to connect heterogeneous streaming engines; replace operators at runtime; and …,ACM/IFIP/USENIX International Conference on Distributed Systems Platforms and Open Distributed Processing,2011,12
Data integration services,Christian Convey; O Karpenko; Nesime Tatbul; Jue Yan,Data integration systems harmonize data from multiple sources into a single coherentrepresentation. The goal is to provide an integrated view over all the data sources of interestand to provide a uniform interface to access all of these data. The access to the integrateddata is usually in the form of querying rather than updating the data. The data sources to beintegrated may belong to the same enterprise or may be arbitrary sources on the web. Mostof the time; each of the sources is independently designed for autonomous operation. Also;the sources are not necessarily databases; they may be legacy systems (old andobsolescent systems that are difficult to migrate to a modern technology) or structured/unstructured files with different interfaces. Data integration requires that the differences inmodeling; semantics and capabilities of the sources together with the possible …,Brown University; New York,2001,12
UpStream: storage-centric load management for streaming applications with update semantics,Alexandru Moga; Irina Botan; Nesime Tatbul,Abstract This paper addresses the problem of minimizing the staleness of query results forstreaming applications with update semantics under overload conditions. Staleness is ameasure of how out-of-date the results are compared with the latest data arriving on theinput. Real-time streaming applications are subject to overload due to unpredictablyincreasing data rates; while in many of them; we observe that data streams and queries infact exhibit" update semantics"(ie; the latest input data are all that really matters whenproducing a query result). Under such semantics; overload will cause staleness to build up.The key to avoid this is to exploit the update semantics of applications as early as possible inthe processing pipeline. In this paper; we propose UpStream; a storage-centric frameworkfor load management over streaming applications with update semantics. We first …,The VLDB Journal—The International Journal on Very Large Data Bases,2011,9
CherniackM,Camey D AbadiD; U Cetintemel,*,Convey C; Lee S; Stonebraker M; Tatbul N; Zdonik S. Aurora Anewmodeland architecturefordatastreammanagement. TheVLDBJoumal,2003,9
Efficient stream provenance via operator instrumentation,Boris Glavic; Kyumars Sheykh Esmaili; Peter M Fischer; Nesime Tatbul,Abstract Managing fine-grained provenance is a critical requirement for data streammanagement systems (DSMS); not only for addressing complex applications that requirediagnostic capabilities and assurance; but also for providing advanced functionality; such asrevision processing or query debugging. This article introduces a novel approach that usesoperator instrumentation; that is; modifying the behavior of operators; to generate andpropagate fine-grained provenance through several operators of a query network. Inaddition to applying this technique to compute provenance eagerly during query execution;we also study how to decouple provenance computation from query processing to reduceruntime overhead and avoid unnecessary provenance retrieval. Our proposals includecomputing a concise superset of the provenance (to allow lazily replaying a query and …,ACM Transactions on Internet Technology (TOIT),2014,8
DejaVu: a complex event processing system for pattern matching over live and historical data streams,Nihal Dindar; Peter M Fischer; Nesime Tatbul,ABSTRACT This short paper provides an overview of the DejaVu complex event processing(CEP) system; with an emphasis on its novel archi- tecture and query optimization techniquesfor correlating patterns across live and historical data streams … Categories and Subject DescriptorsH.2.4 [Database Management]: Systems - Query Processing … 1. INTRODUCTION CEP hasproven to be an important technology for analyzing complex relationships over high volumesof data in many applica- tion domains. High-performance pattern matching over live event streamshas been a central focus in CEP research to date. Though a less explored researchdirection; archiving streams and integrating them into the live stream processing pipeline offersmany new key capabilities for CEP systems. In particular; longer-term data anal- ysis; such asmaking predictions about future event occurrences or identifying causal relationships …,Proceedings of the 5th ACM international conference on Distributed event-based system,2011,8
Data Ingestion for the Connected World.,John Meehan; Cansu Aslantas; Stan Zdonik; Nesime Tatbul; Jiang Du,ABSTRACT In this paper; we argue that in many “Big Data” applications; getting data into thesystem correctly and at scale via traditional ETL (Extract; Transform; and Load) processes isa fundamental roadblock to being able to perform timely analytics or make real-timedecisions. The best way to address this problem is to build a new architecture for ETL whichtakes advantage of the push-based nature of a stream processing system. We discuss therequirements for a streaming ETL engine and describe a generic architecture which satisfiesthose requirements. We also describe our implementation of streaming ETL using a scalablemessaging system (Apache Kafka); a transactional stream processing system (S-Store); anda distributed polystore (Intel's BigDAWG); as well as propose a new time-series databaseoptimized to handle ingestion internally.,CIDR,2017,7
Integrating real-time and batch processing in a polystore,John Meehan; Stan Zdonik; Shaobo Tian; Yulong Tian; Nesime Tatbul; Adam Dziedzic; Aaron Elmore,This paper describes a stream processing engine called S-Store and its role in theBigDAWG polystore. Fundamentally; S-Store acts as a frontend processor that accepts inputfrom multiple sources; and massages it into a form that has eliminated errors (data cleaning)and translates that input into a form that can be efficiently ingested into BigDAWG. S-Storealso acts as an intelligent router that sends input tuples to the appropriate components ofBigDAWG. All updates to S-Store's shared memory are done in a transactionally consistent(ACID) way; thereby eliminating new errors caused by non-synchronized reads and writes.The ability to migrate data from component to component of BigDAWG is crucial. We havedescribed a migrator from S-Store to Postgres that we have implemented as a first proof ofconcept. We report some interesting results using this migrator that impact the evaluation …,High Performance Extreme Computing Conference (HPEC); 2016 IEEE,2016,7
Task Handling in Workflow Management Systems.,Pinar Karagoz; Sena Nural Arpinar; Pinar Koksal; Nesime Tatbul; Esin Gokkoca; Asuman Dogac,ABSTRACT Work ow management systems aim to automate the execution of businessprocesses. One of the objectives of the work ow systems is to include the already existingapplications such as legacy applications as well as new applications; which are termed astasks; into the system and provide synchronized execution among them. To achieve this; amechanism is necessary to support the communication between the tasks and the system.The communication mechanism should handle the transfer of data necessary for theexecution of the tasks and for the scheduling of the tasks. Another point to be noted is thenecessity of the handling user tasks that have to be performed by the users of the work owsystem. Since the trend is toward distributed execution to avoid the bottlenecks due to thenature of central systems; we considered these issues in a distributed execution …,IADT,1998,7
DEBS11 Grand Challenge: Streams; Rules; or a Custom Solution?,Lynn Aders; Rene Buffat; Zaheer Chothia; Matthias Wetter; Cagri Balkesen; Peter M Fischer; Nesime Tatbul,abstract: This paper describes how we modeled and solved the DEBS11 Grand Challengeof implementing a social network game using event processing technology. We first presentan automaton-based model that we used to capture the game semantics. Then wesummarize three different approaches we investigated to implement this automaton togetherwith their evaluations. Finally; we provide a discussion of our observations and lessonslearned as a result of this study.,month,2011,6
Enabling Real-Time Business Intelligence,Malu Castellanos; Dayal Umeshwar; Renee Miller,In today's competitive and highly dynamic environment; analyzing data to understand howthe business is performing; and to predict outcomes and trends have become critical. Thetraditional approach to reporting is no longer adequate. Instead users now demand easy-to-use intelligent platforms and applications capable of analyzing realtime data to provideinsight and actionable information at the right time. The end goal is to support better andtimelier decision making; enabled by the availability of up-todate; high-quality information.Although there has been progress in this direction and many companies are introducingproducts toward meeting this goal; there is still a long way to go. In particular; the wholelifecycle of business intelligence requires innovative techniques and methodologies capableof dealing with the requirements imposed by these new generation BI applications. From …,*,2010,6
Metu-emar: An agent-based electronic marketplace on the web,Asuman Dogac; Ilker Durusoy; Sena Arpinar; Esin Gokkoca; Nesime Tatbul; Pinar Koksal,Abstract In this paper; we describe a scenario for a distributed marketplace on the Webwhere resource discovery agents find out about resources that may want to join themarketplace and electronic commerce is realized through buying agents representing thecustomers and the selling agents representing the resources like electronic catalogs. Wepropose a possible architecture which is based on the emerging technologies andstandards. In this architecture; the resources expose their metadata using ResourceDescription Framework (RDF) to be accessed by the resource discovery agents and theircontent through Extensible Markup Language (XML) to be accessed by the selling agents byusing Document Object Model (DOM). The marketplace contains Document Type Definitions(DTDs) and a dictionary of synonyms to be used by the buying agents to help the …,International Conference on Theory and Practice of Digital Libraries,1998,6
A workflow specification language and its scheduler,Nesime Tatbul; Sena Arpinar; Pinar Karagoz; Ibrahim Cingil; Esin Gokkoca; Mehmet Altinel; Pinar Koksal; Asuman Dogac; Tamer Ozsu,Abstract This paper describes a workflow specification language; namely MFDL; and theimplementation of its scheduler in a distributed environment. Distributed nature of thescheduling provides failure resilience and increased performance. Since workflowscheduling and management is highly affected from the way the workflow is specified; aworkflow specification language should be efficient to prevent the problems of complexity inworkflow specification and difficulties in debugging/testing the further steps of the workflowmanagement system development. MFDL; being a block-structured procedural workflowspecification language; is capable of defining a workflow in an easy; comprehensible andclear way so that implementation of the scheduler is simplified. The paper also presents taskhandling in the system through a CORBA compliant ORB.,In Proc. of 11th Intl. Symposium on Computer and Information Systems,1997,6
Incremental DNA sequence analysis in the cloud,Romeo Kienzler; Rémy Bruggmann; Anand Ranganathan; Nesime Tatbul,Abstract In this paper; we propose to demonstrate a “stream-as-you-go” approach thatminimizes the data transfer time of data-and compute-intensive scientific applicationsdeployed in the cloud; by making them incrementally processable. We describe a systemthat implements this approach based on the IBM InfoSphere Streams computing platformdeployed over Amazon EC2. The functionality; performance; and usability of the system willbe demonstrated through two DNA sequence analysis applications.,International Conference on Scientific and Statistical Database Management,2012,5
U. etintemel; M,D Abadi; D Carney,*,Cherniack; C. Convey; S. Lee; M. Stonebraker; N. Tatbul; and S. Zdonik,*,5
Handling Shared; Mutable State in Stream Processing with Correctness Guarantees.,Nesime Tatbul; Stan Zdonik; John Meehan; Cansu Aslantas; Michael Stonebraker; Kristin Tufte; Chris Giossi; Hong Quach,Abstract S-Store is a next-generation stream processing system that is being developed atBrown; Intel; MIT; and Portland State University. It is designed to achieve very highthroughput; while maintaining a number of correctness guarantees required to handleshared; mutable state in streaming applications. This paper explores these correctnesscriteria and describes how S-Store achieves them; including a new model of streamprocessing that provides support for ACID transactions.,IEEE Data Eng. Bull.,2015,4
Load shedding,Nesime Tatbul,A language model assigns a probability to a piece of unseen text; based on some trainingdata. For example; a language model based on a big English newspaper archive isexpected to assign a higher probability to ''a bit of text''than to ''aw pit tov tags;''because thewords in the former phrase (or word pairs or word triples if so-called N-Gram Models areused) occur more frequently in the data than the words in the latter phrase. For informationretrieval; typical usage is to build a language model for each document. At search time; thetop ranked document is the one whose language model assigns the highest probability tothe query.,*,2009,4
MARIFlow: A Workflow Management System for Maritime Industry,Asuman Dogac; Catriel Beeri; Arif Tumer; Murat Ezbiderli; Nesime Tatbul; Guray Erus; Orhan Cetinkaya; Necip Hamali,Abstract The aim of MARIFlow Project is to provide a prototype of an architecture forautomating and monitoring the flow of control and data over the Internet among differentorganisations. This &quot; electronic medium&quot;; capable of delivering value-addedservices to the participants; encompasses many different technological areas: fromcommunication to security; databases; transaction support and agents. The project will makeuse of these technologies to produce a workflow management system. In particular; the goalof the project is to develop an adaptable workflow engine through which the activities of thedifferent participants in the maritime industry can be harmonised; combined; and expandedthrough better tracking of functional dependencies and documents; improved data accessand handling; and lower administrative overheads. The MARIFlow system is based on …,MAREXPO Book,2001,4
A Workflow System through Cooperating Agents for Document Flow over the Internet,A Dogac; M Ezbiderli; N Tatbul; A Tumer; C Icdem; G Erus; O Cetinkaya; C Beeri,*,Middle East Technical University; Ankara; Turkey; Hebrew University; Jerusalem; Israel,2001,3
Query processing in sensor networks,Erik Buchmann; Nesime Tatbul; Mario Nascimento,Wireless Sensor Networks (WSNs) provide a new technology that is being more and moreapplied in research; business and industry. Typical use cases are monitoring andsurveillance of areas and processes. WSNs can effectively collect detailed data bycoordinating fine-grained sensor readings from a large number of independent nodes.However; querying data collected and stored within a WSN is a challenging problem. Inparticular; sensor nodes have very limited resources; eg; energy or wireless networkbandwidth. Thus; it is not feasible to apply simple query processing strategies such ascontinuously streaming all sensor values directly to a powerful base-station for furtherprocessing. This special issue of the Distributed and Parallel Databases Journal has itsfocus on efficient query processing in sensor networks. Although this challenge has …,Distributed and parallel databases,2011,2
Cutting the Knot: Explaining the Execution Semantics of Sliding Window Queries over Data Streams,Irina Botan; Roozbeh Derakhshan; Nihal Dindar; Laura Haas; Renee Miller; Nesime Tatbul,Abstract—Despite the availability of several data stream processing engines (SPEs) today; itremains hard to develop and maintain streaming applications. Existing SPEs vary widely intheir data and query models and capabilities. A lack of standards; and the wide (andchanging) variety of application requirements; restrict portability. Users find it difficult to knowwhich system to use; and even to understand the behavior of the system they choose. Ourgoal in this paper is to propose a formalism that can be used to explain a major subset ofthese different behaviors. We first provide an in-depth analysis of the heterogeneity problemacross three well-known and commonly used stream processing systems (two commercialand one academic); focusing on the execution semantics of sliding window queries. We thenpropose a simple yet powerful formal model that captures and explains the core …,ETH Zurich; Computer Science; Tech. Rep.; June,2009,2
Ariadne,Boris Glavic; Kyumars Sheykh Esmaili; Peter M Fischer; Nesime Tatbul,Abstract Managing fine-grained provenance is a critical requirement for data streammanagement systems (DSMS) to be able to address complex applications that requirediagnostic capabilities and assurance as well as serving as a supporting technology forother tasks such as revision processing. In this paper; based on an example use case; wemotivate the need for fine-grained provenance in stream processing and analyze itsrequirements. Inspired by these requirements; we investigate different techniques togenerate and retrieve stream provenance; and propose a new technique that is based onoperator instrumentation. Ariadne; our provenance-aware DSMS implements this techniqueon top of the Borealis system. We propose new optimization techniques to reduce thecomputational overhead of provenance generation and retrieval. Our experiments confirm …,Technical report/Systems Group; Department of Computer Science; ETH Zurich,2012,1
Tools and Techniques for Exploring Execution Model Relationships across Heterogeneous Stream Processing Engines,Burak Kalay,Abstract Today; there is a diverse range of stream processing engines available for use.However; due to lack of standardization; they differ greatly in semantics; syntax andexecution model which may lead differences in query results. SECRET model [1] isproposed to explain such behavioral differences. Yet; exploring relationships betweenheterogenous stream processing engines remains as an important task. This thesisinvestigates how SECRET can be used to explore execution model relationships betweenheterogenous Stream Processing Engines. We define a methodology and propose atechnique to predict relationships between any given engine configurations with highefficieny. We further show the validity of our technique through extensive experiments. Wepresent design and architecture of a simulation and analysis software to serve as a …,*,2011,1
An electronic marketplace architecture,Asuman Dogac; Ilker Durusoy; Sena Arpinar; Nesime Tatbul; Pinar Koksal,We propose a possible architecture to support this scenario which is based on the emergingtechnologies and standards. In this architecture; the resources expose their metadata usingResource Description Framework (RDF) to be accessed by the resource discovery agentsand their content through Extensible Markup Language (XML) to be accessed by the sellingagents by using Document Object Model (DOM). The IDS contains the template workflowsfor buying and selling agents; a trader mechanism. Resource Discovery Agents; DocumentType Definitions (DTDs) and a dictionary of synonyms to be used by the buying agents tohelp the customer to specify the item s/he wishes to purchase. The agents and IDScommunicate through KQML messages. The modifications necessary to the proposedarchitecture considering only the available technology are also discussed.,Current Trends in Data Management Technology,1999,1
Precision and Recall for Range-Based Anomaly Detection,Tae Jun Lee; Justin Gottschlich; Nesime Tatbul; Eric Metcalf; Stan Zdonik,Abstract: Classical anomaly detection is principally concerned with point-based anomalies;anomalies that occur at a single data point. In this paper; we present a new mathematicalmodel to express range-based anomalies; anomalies that occur over a range (or period) oftime. Subjects: Artificial Intelligence (cs. AI) Cite as: arXiv: 1801.03175 [cs. AI](or arXiv:1801.03175 v1 [cs. AI] for this version) Submission history From: Justin Gottschlich [viewemail][v1] Tue; 9 Jan 2018 23: 01: 07 GMT (52kb),arXiv preprint arXiv:1801.03175,2018,*
Greenhouse: A Zero-Positive Machine Learning System for Time-Series Anomaly Detection,Tae Jun Lee; Justin Gottschlich; Nesime Tatbul; Eric Metcalf; Stan Zdonik,Abstract: This short paper describes our ongoing research on Greenhouse-a zero-positivemachine learning system for time-series anomaly detection. Subjects: Artificial Intelligence(cs. AI) Cite as: arXiv: 1801.03168 [cs. AI](or arXiv: 1801.03168 v1 [cs. AI] for this version)Submission history From: Justin Gottschlich [view email][v1] Tue; 9 Jan 2018 22: 44: 21 GMT(255kb; D),arXiv preprint arXiv:1801.03168,2018,*
Towards Dynamic Data Placement for Polystore Ingestion,Jiang Du; John Meehan; Nesime Tatbul; Stan Zdonik,Abstract Integrating low-latency data streaming into data warehouse architectures hasbecome an important enhancement to support modern data warehousing applications. Inthese architectures; heterogeneous workloads with data ingestion and analytical queriesmust be executed with strict performance guarantees. Furthermore; the data warehouse mayconsists of multiple different types of storage engines (aka; polystores or multi-stores). Aparamount problem is data placement; different workload scenarios call for different dataplacement designs. Moreover; workload conditions change frequently. In this paper; weprovide evidence that a dynamic; workload-driven approach is needed for data placement inpolystores with low-latency data ingestion support. We study the problem based on thecharacteristics of the TPC-DI benchmark in the context of an abbreviated polystore that …,Proceedings of the International Workshop on Real-Time Business Intelligence and Analytics,2017,*
ACM SIGMOD Record Volume 45 Issue 3,Yanlei Diao; Vanessa Braganholo; Marco Brambilla; Chee Yong Chan; Rada Chirkova; Zackary Ives; Anastasios Kementsietsidis; Jeffrey Naughton; Frank Neven; Olga Papaemmanoui; Aditya Parameswaran; Anish Das Sarma; Alkis Simitsis; Wang-Chiew Tan; Nesime Tatbul; Marianne Winslett; Jun Yang,Google; Inc. (search). SIGN IN SIGN UP. ACM SIGMOD Record. Volume 45 Issue 3; September2016 table of contents. Editors: Yanlei Diao; University of Massachusetts Amherst. VanessaBraganholo; Universidade Federal Fluminense. Marco Brambilla; Politecnico di Milano.,*,2016,*
Report on the 8th International Workshop on Business Intelligence for the Real-Time Enterprise (BIRTE'14),Malu Castellanos; Umeshwar Dayal; Nesime Tatbul; Damianos Chatziantoniou; Qiming Chen,The 8th International Workshop on Business Intelligence for the Real-Time Enterprise(BIRTE) was held on September 1; 2014 in conjunction with the VLDB 2014 Conference inHangzhou; China. Like in previous years; the workshop was well attended by an engagedaudience from both academia and industry; breaking an attendance record in the history ofthe BIRTE workshop series with more than 80 participants during the keynote session. Inaddition to the keynote speech; the workshop included two invited industrial talks; and fourpresentations of peer-reviewed papers covering a wide range of real-time BI topics with anoverarching emphasis on big data analytics. The workshop developed as follows: After theofficial opening of the workshop; two papers were presented-one on BI analytics on graph-structured data and another on contextual analysis in temporal databases. The invited …,ACM SIGMOD Record,2015,*
ACM SIGMOD Record Volume 43 Issue 1,Ioana Manolescu; Denilson Barbosa; Pablo Barceló; Vanessa Braganholo; Marco Brambilla; Chee Yong Chan; Rada Chirkova; Anish Das Sarma; Glenn Paulley; Alkis Simitsis; Nesime Tatbul; Marianne Winslett,Google; Inc. (search). SIGN IN SIGN UP. ACM SIGMOD Record. Volume 43 Issue 1; March 2014table of contents. Editors: Ioana Manolescu; INRIA Saclay. Denilson Barbosa; University of Alberta.Pablo Barceló; Universidad de Chile. Vanessa Braganholo; Universidade Federal Fluminense.,*,2014,*
Technical Report Nr. 722,Kyumars Sheykh Esmaili; Tahmineh Sanamrad; Peter M Fischer; Nesime Tatbul,Abstract Continuous queries can run for unpredictably long periods of time. During theirlifetime; these queries may need to be adapted either due to changes in applicationsemantics (eg; the implementation of a new alert detection policy); or due to changes in thesystem's behavior (eg; adapting performance to a changing load). While in previous worksquery modification has been implicitly utilized to serve specific purposes (eg; loadmanagement); to date no research has been done that defines a general-purpose; reliable;and efficiently implementable model for modifying continuous queries at run-time. In thisreport; we introduce a punctuation-based framework that can formally express arbitrarylifecycle operations on the basis of input-output mappings and basic control elements suchas start or stop of queries. On top of this foundation; we derive all possible query change …,*,2011,*
DEBS'11 Grand Challenge,Lynn Aders; René Buffat; Zaheer Chothia; Matthias Wetter; Cagri Balkesen; Peter M Fischer; Nesime Tatbul,This paper describes how we modeled and solved the DEBS'11 Grand Challenge ofimplementing a social network game using event processing technology. We first present anautomaton-based model that we used to capture the game semantics. Then we summarizethree different approaches we investigated to implement this automaton together with theirevaluations. Finally; we provide a discussion of our observations and lessons learned as aresult of this study.,Technical reports,2011,*
Changing flights in mid-air,Kyumars Sheykh Esmaili; Tahmineh Sanamrad; Peter Michael Fischer; Nesime Tatbul,Continuous queries can run for unpredictably long periods of time. During their lifetime;these queries may need to be adapted either due to changes in application semantics (eg;the implementation of a new alert detection policy); or due to changes in the system'sbehavior (eg; adapting performance to a changing load). While in previous works querymodification has been implicitly utilized to serve specific purposes (eg; load management);to date no research has been done that defines a general-purpose; reliable; and efficientlyimplementable model for modifying continuous queries at run-time. In this report; weintroduce a punctuation-based framework that can formally express arbitrary lifecycleoperations on the basis of input-output mappings and basic control elements such as start orstop of queries. On top of this foundation; we derive all possible query change methods …,Technical report,2011,*
Changing Flights in Mid-air: A Model for Safely Modifying Continuous Queries,Tahmineh Sanamrad; Kyumars Sheykh Esmaili; Peter M Fischer; Nesime Tatbul,*,*,2011,*
Connecting the Real World with the Virtual World: The SmartRFLib RFID-Supported Library System on Second Life,Katinka Kromwijk; Çagri Balkesen; Gautier Boder; Nihal Dindar; Florian Keusch; Ali Sengül; Nesime Tatbul,Abstract With recent developments in Web technologies enabling interaction in virtualenvironments; as well as the ones in sensor network technologies enabling interaction withthe real world; we see an emerging trend towards bringing these two worlds together. In thischapter; we share our experiences in building an RFID-supported library system on SecondLife called SmartRFLib; which successfully achieves this integration. Although SmartRFLibfocuses on a library system as an application scenario; it has been designed as a general-purpose RFID data management and complex event detection system; and can also beused as a basis to build other RFID-based event monitoring applications.,*,2010,*
Maximize: An Optimizer for Federated Stream Processing Systems,Nesime Tatbul; Donald Kossmann; Roozbeh Derakhshan,*,*,2009,*
The ETH Zurich systems group and enterprise computing center,Gustavo Alonso; Donald Kossmann; Timothy Roscoe; Nesime Tatbul; Andrew Baumann; Carsten Binnig; Peter Fischer; Oriana Riva; Jens Teubner,Computer science is facing a fundamental paradigm shift. Multicore architectures;application virtualization; and cloud computing each present on their own radical departuresin the way software is built; deployed; and operated. Taken together; these trends frame ascenario that makes sense from many points of view (usability; scalability; flexibility;development cost) but is also radically different from what we know today. It is fair to say thata coherent answer to the challenges raised by the combination of these trends has yet toemerge from either academia or industry. From an academic perspective; these challengesare particularly difficult because they imply a considerable departure from establishedprocedures. To start with; multicore computers; the virtualization of computing platforms; andthe replacement of the one-computer-one-local-copy-ofa-program approach by cloud …,ACM SIGMOD Record,2009,*
Storage-centric load management for data streams with update semantics,Alexandru Moga; Irina Botan; Nesime Tatbul,Most data stream processing systems model their inputs as append-only sequences dfg ofdata elements. In this model; the application expects to receive a query answer on thecomplete input stream. However; there are many situations in which each data element (or awindow of data elements) in the stream is in fact an update to a previous one; and therefore;the most recent arrival is all that really matters to the application. UpStream defines astorage-centric approach to efficiently processing continuous queries under such an update-based stream data model. The goal is to provide the most up-to-date answers to theapplication with the lowest staleness possible. To achieve this; we developed a lossy tuplestorage model (called an “update queue”); which under high load; will choose to sacrificeold tuples in favor of newer ones using a number of different update key scheduling …,Technical report,2009,*
Donald Patrick Carney,M Cherniack; C Convey; E Galvez; J Salz; M Stonebraker; N Tatbul; R Tibbetts,Senior Programmer/Analyst• Perform and manage international projects; bringing atelecommunications system through its entire life-cycle (system consisting of 1;000;000+lines of C and SQL and deployed in 20 countries servicing over 25;000;000 telephonelines)• Work with sales force and potential clients; perform pre-sales consulting; includingdemonstrations; requirements and design specifications analysis; and cost analysis•Responsible for software coding; installation and testing; including such projectmanagement tasks as scheduling; goal setting and allocating work to client personnel•Provide training and technical support to clients• On-site development; installation; trainingand support requiring prolonged stays in Chile; Czech Republic; Germany; Mexico;Indonesia and Hong Kong,International Conference on Data Engineering (ICDE),2003,*
The MARIFlow Workflow Management System,Asuman Dogac; M Ezbiderli; Yusuf Tambag; C Icdem; Arif Tumer; Nesime Tatbul; N Hamali; Catriel Beeri,Abstract MARIFlow System [1] provides for automating and monitoring the flow of control anddata over the Internet among different organizations; thereby creating a platform necessaryto describe higher order processes involving several organizations and companies. Thearchitecture is general enough to be applied to any business practice where data flowamong different industries and cooperations and the invocation of activities follow a patternthat can be described through a process definition. The example application provided withinthe scope of this project is on maritime industry A MARIFlow process is executed throughcooperating agents; called MARCAs (MARIFlow Cooperating Agents) that are automaticallyinitialized at each site that the process executes. MARCAs handle the activities at their site;provide for coordination with other MARCAs in the system by routing the documents in …,*,2001,*
GUARD GENERATION FOR A DISTRIBUTED WORKFLOW ENACTMENT SERVICE,NES_IME TATBUL,A workflow can be defined as a collection of processing steps also termed as tasks oractivities organized to accomplish some business process. A task can be performed by oneor more software systems; or; by a person or a team; or a combination of these. In addition tothe collection of tasks; a workflow defines the order of task invocation or condition s underwhich tasks must be invoked; ie control flow; and data flow between these tasks. Workflowmanagement is the automated coordination; control and communication of work as isrequired to satisfy workflow processes. Workflow Management System WFMS is a systemthat completely defines; manages and executes workflows through the execution of softwarewhose order of execution is driven by a computer representation of the workflow logic 19.Workflow management systems aim at automating business processes to provide …,*,1998,*
Introduction to Big Data—the four V's,Donald Kossmann; Nesime Tatbul,Page 1. DATABASE SYSTEMS GROUP Chapter 1: Introduction to Big Data — the four V's BigData Management and Analytics 15 This chapter is mainly based on the Big Data script byDonald Kossmann and Nesime Tatbul (ETH Zürich) Page 2. DATABASE SYSTEMS GROUPGoal of Today • What is Big Data? • introduce all major buzz words • What is not Big Data? •get a feeling for opportunities & limitations Big Data Management and Analytics 16 Page 3.DATABASE SYSTEMS GROUP Goal of Today • What is Big Data? • introduce all major buzzwords • What is not Big Data? • get a feeling for opportunities & limitations Big Data Managementand Analytics 17 Page 4. DATABASE SYSTEMS GROUP Answering Tough Questions • Problem:• sales for lollipops are going down • Data: • all sales data by customer; region; time; … •Information: • lollipops bought by people older than 25 …,*,*,*
Systems Group; Department of Computer Science; ETH Zurich,Aslı Özal; Nesime Tatbul; Anand Ranganathan,Abstract Today; many cities in the world are facing serious transportation challenges. Withcontinuous increase of car usage in urban areas; traffic congestion has become animportant problem in daily life. Intelligent Transportation Systems (ITS) aim to easeenvironmental; social; and economic implications of traffic congestion through theapplication of modern information technology and communications. In this thesis; we aim tohandle the problem of route planning in the presence of traffic congestion. We present asystem architecture that applies stream data management technology on traffic informationdata for real-time route planning. We explain the techniques to gather traffic data fromvarious data sources; to calculate traffic and speed estimations; and to execute continuousroute queries with real-time traffic data.,*,*,*
Recommended Reading,NESIME TATBUL,Definition Data stream management systems may be subject to higher input rates than theycan immediately process with their available system resources (eg; CPU; memory). Wheninput rates exceed the resource capacity; the system becomes overloaded and the queryanswers are delayed. Load shedding is a technique to remove excess load from the systemin order to keep query processing up with the input arrival rates. As a result of loadshedding; the system delivers approximate query answers with reduced latency. HistoricalBackground Load shedding is a term that originally comes from electric power management;where it refers to the process of intentionally cutting off the electric current on certain lineswhen the demand for electricity exceeds the available supply; in order to save the electricgrid from collapsing. The same term has also been used in computer networking to refer …,*,*,*
Auxiliary Reviewiers,Sena Arpinar; Naveen Ashish; Luc Bouganim; Ralph Busse; Dunren Che; Chia-Mei Chen; Andrzej Cichocki; Ibrahim Cingil; Robert Colomb; Yi Deng; Peter Fankhauser; Armin Fessler; Jerry Fowler; Esin Gokkoca; Lorena Gomez; Claus Hagen; Christian Heinlein; Sumi Helal; Gerald Huck; Nadeem Jamali; Jonghyun Kahng; Pinar Karagoz; Kamal Karlapalem; Justus Klingemann; Pinar Koksal; Tony CT Kuo; Juan Lavageiga; Mong Li Lee; HV Leong; Wen-Hsiang Kevin Liao; Francois Llirbat; Kuhanandha Mahalingam; Ion Muslea; Hubert Naacke; Vincent Ng; Moira C Norri; Manfred Reichert; Michael Rys; J Samos; Heiko Schuldt; Antonio Si; Rakesh K Sinha; Geoffrey Smith; Hiroki Takakura; Nesime Tatbul; Thomas Tesch; Heiko Thimm; David Truffet; Wen-Guey Tzeng; Amy Unruh; Marc Volz; Juergen Waesch; James Waldby; Chih-Ping Wei; Yi-Hung Wu,*,*,*,*
Systems Group; Department of Computer Science; ETH Zurich,Romeo Kienzler; Nesime Tatbul; Anand Ranganathan; Remy Bruggmann,*,*,*,*
