Fedx: Optimization techniques for federated query processing on linked data,Andreas Schwarte; Peter Haase; Katja Hose; Ralf Schenkel; Michael Schmidt,Abstract Motivated by the ongoing success of Linked Data and the growing amount ofsemantic data sources available on the Web; new challenges to query processing areemerging. Especially in distributed settings that require joining data provided by multiplesources; sophisticated optimization techniques are necessary for efficient query processing.We propose novel join processing and grouping techniques to minimize the number ofremote requests; and develop an effective solution for source selection in the absence ofpreprocessed metadata. We present FedX; a practical framework that enables efficientSPARQL query processing on heterogeneous; virtually integrated Linked Data sources. Inexperiments; we demonstrate the practicability and efficiency of our framework on a set ofreal-world queries and data sources from the Linked Open Data cloud. With FedX we …,International Semantic Web Conference,2011,239
Data summaries for on-demand queries over linked data,Andreas Harth; Katja Hose; Marcel Karnstedt; Axel Polleres; Kai-Uwe Sattler; Jürgen Umbrich,Abstract Typical approaches for querying structured Web Data collect (crawl) and pre-process (index) large amounts of data in a central data repository before allowing for queryanswering. However; this time-consuming pre-processing phase however leverages thebenefits of Linked Data--where structured data is accessible live and up-to-date atdistributed Web resources that may change constantly--only to a limited degree; as queryresults can never be current. An ideal query answering system for Linked Data should returncurrent answers in a reasonable amount of time; even on corpora as large as the Web.Query processors evaluating queries directly on the live sources require knowledge of thecontents of data sources. In this paper; we develop and evaluate an approximate indexstructure summarising graph-structured content of sources adhering to Linked Data …,Proceedings of the 19th international conference on World wide web,2010,203
AMIE: association rule mining under incomplete evidence in ontological knowledge bases,Luis Antonio Galárraga; Christina Teflioudi; Katja Hose; Fabian Suchanek,Abstract Recent advances in information extraction have led to huge knowledge bases(KBs); which capture knowledge in a machine-readable format. Inductive LogicProgramming (ILP) can be used to mine logical rules from the KB. These rules can helpdeduce and add missing knowledge to the KB. While ILP is a mature field; mining logicalrules from KBs is different in two aspects: First; current rule mining systems are easilyoverwhelmed by the amount of data (state-of-the art systems cannot even run on today'sKBs). Second; ILP usually requires counterexamples. KBs; however; implement the openworld assumption (OWA); meaning that absent data cannot be used as counterexamples. Inthis paper; we develop a rule mining model that is explicitly tailored to support the OWAscenario. It is inspired by association rule mining and introduces a novel measure for …,Proceedings of the 22nd international conference on World Wide Web,2013,169
A survey of skyline processing in highly distributed environments,Katja Hose; Akrivi Vlachou,Abstract During the last decades; data management and storage have become increasinglydistributed. Advanced query operators; such as skyline queries; are necessary in order tohelp users to handle the huge amount of available data by identifying a set of interestingdata objects. Skyline query processing in highly distributed environments poses inherentchallenges and demands and requires non-traditional techniques due to the distribution ofcontent and the lack of global knowledge. This paper surveys this interesting and stillevolving research area; so that readers can easily obtain an overview of the state-of-the-art.We outline the objectives and the main principles that any distributed skyline approach hasto fulfill; leading to useful guidelines for developing algorithms for distributed skylineprocessing. We review in detail existing approaches that are applicable for highly …,The VLDB Journal—The International Journal on Very Large Data Bases,2012,101
FedX: a federation layer for distributed query processing on linked open data,Andreas Schwarte; Peter Haase; Katja Hose; Ralf Schenkel; Michael Schmidt,Abstract Driven by the success of the Linked Open Data initiative today's Semantic Web isbest characterized as a Web of interlinked datasets. Hand in hand with this structure newchallenges to query processing are arising. Especially queries for which more than one datasource can contribute results require advanced optimization and evaluation approaches; themajor challenge lying in the nature of distribution: Heterogenous data sources have to beintegrated into a federation to globally appear as a single repository. On the query level;though; techniques have to be developed to meet the requirements of efficient querycomputation in the distributed setting. We present FedX; a project which extends theSesame Framework with a federation layer that enables efficient query processing ondistributed Linked Open Data sources. We discuss key insights to its architecture and …,Extended Semantic Web Conference,2011,70
Processing relaxed skylines in PDMS using distributed data summaries,Katja Hose; Christian Lemke; Kai-Uwe Sattler,Abstract Peer Data Management Systems (PDMS) are a natural extension of heterogeneousdatabase systems. One of the main tasks in such systems is efficient query processing.Insisting on complete answers; however; leads to asking almost every peer in the network.Relaxing these completeness requirements by applying approximate query answeringtechniques can significantly reduce costs. Since most users are not interested in the exactanswers to their queries; rank-aware query operators like top-k or skyline play an importantrole in query processing. In this paper; we present the novel concept of relaxed skylines thatcombines the advantages of both rank-aware query operators and approximate queryprocessing techniques. Furthermore; we propose a strategy for processing relaxed skylinesin distributed environments that allows for giving guarantees for the completeness of the …,Proceedings of the 15th ACM international conference on Information and knowledge management,2006,69
Comparing data summaries for processing live queries over linked data,Jürgen Umbrich; Katja Hose; Marcel Karnstedt; Andreas Harth; Axel Polleres,Abstract A growing amount of Linked Data—graph-structured data accessible at sourcesdistributed across the Web—enables advanced data integration and decision-makingapplications. Typical systems operating on Linked Data collect (crawl) and pre-process(index) large amounts of data; and evaluate queries against a centralised repository. Giventhat crawling and indexing are time-consuming operations; the data in the centralised indexmay be out of date at query execution time. An ideal query answering system for queryingLinked Data live should return current answers in a reasonable amount of time; even oncorpora as large as the Web. In such a live query system source selection—determiningwhich sources contribute answers to a query—is a crucial step. In this article we propose touse lightweight data summaries for determining relevant sources during query evaluation …,World Wide Web,2011,62
Fast rule mining in ontological knowledge bases with AMIE $ $+ $ $+,Luis Galárraga; Christina Teflioudi; Katja Hose; Fabian M Suchanek,Abstract Recent advances in information extraction have led to huge knowledge bases(KBs); which capture knowledge in a machine-readable format. Inductive logic programming(ILP) can be used to mine logical rules from these KBs; such as “If two persons are married;then they (usually) live in the same city.” While ILP is a mature field; mining logical rules fromKBs is difficult; because KBs make an open-world assumption. This means that absentinformation cannot be taken as counterexamples. Our approach AMIE (Galárraga et al. inWWW; 2013) has shown how rules can be mined effectively from KBs even in the absenceof counterexamples. In this paper; we show how this approach can be optimized to mineeven larger KBs with more than 12M statements. Extensive experiments show how our newapproach; AMIE++; extends to areas of mining that were previously beyond reach.,The VLDB Journal,2015,55
Partout: a distributed engine for efficient RDF processing,Luis Galárraga; Katja Hose; Ralf Schenkel,Abstract The increasing interest in Semantic Web technologies has led not only to a rapidgrowth of semantic data on the Web but also to an increasing number of backendapplications relying on efficient query processing. Confronted with such a trend; existingcentralized state-of-the-art systems for storing RDF and processing SPARQL queries are nolonger sufficient. In this paper; we introduce Partout; a distributed engine for fast RDFprocessing in a cluster of machines. We propose an effective approach for fragmenting RDFdata sets based on a query log and allocating the fragments to hosts in a cluster ofmachines. Furthermore; Partout's query optimizer produces efficient query execution plansfor ad-hoc SPARQL queries.,Proceedings of the 23rd International Conference on World Wide Web,2014,48
WARP: Workload-aware replication and partitioning for RDF,Katja Hose; Ralf Schenkel,With the increasing popularity of the Semantic Web; more and more data becomes availablein RDF with SPARQL as a query language. Data sets; however; can become too big to bemanaged and queried on a single server in a scalable way. Existing distributed RDF storesapproach this problem using data partitioning; aiming at limiting the communication betweenservers and exploiting parallelism. This paper proposes a distributed SPARQL engine thatcombines a graph partitioning technique with workload-aware replication of triples acrosspartitions; enabling efficient query execution even for complex queries from the workload.Furthermore; it discusses query optimization techniques for producing efficient executionplans for ad-hoc queries not contained in the workload.,Data Engineering Workshops (ICDEW); 2013 IEEE 29th International Conference on,2013,47
Database foundations for scalable RDF processing,Katja Hose; Ralf Schenkel; Martin Theobald; Gerhard Weikum,Abstract As more and more data is provided in RDF format; storing huge amounts of RDFdata and efficiently processing queries on such data is becoming increasingly important.The first part of the lecture will introduce state-of-the-art techniques for scalably storing andquerying RDF with relational systems; including alternatives for storing RDF; efficient indexstructures; and query optimization techniques. As centralized RDF repositories havelimitations in scalability and failure tolerance; decentralized architectures have beenproposed. The second part of the lecture will highlight system architectures and strategiesfor distributed RDF processing. We cover search engines as well as federated queryprocessing; highlight differences to classic federated database systems; and discussefficient techniques for distributed query processing in general and for RDF data in …,Proceedings of the 7th international conference on Reasoning web: semantic technologies for the web of data,2011,33
Framebase: Representing n-ary relations using semantic frames,Jacobo Rouces; Gerard de Melo; Katja Hose,Abstract Large-scale knowledge graphs such as those in the Linked Data cloud are typicallyrepresented as subject-predicate-object triples. However; many facts about the world involvemore than two entities. While n-ary relations can be converted to triples in a number of ways;unfortunately; the structurally different choices made in different knowledge sourcessignificantly impede our ability to connect them. They also make it impossible to query thedata concisely and without prior knowledge of each individual source. We presentFrameBase; a wide-coverage knowledge-base schema that uses linguistic frames toseamlessly represent and query n-ary relations from other knowledge bases; at differentlevels of granularity connected by logical entailment. It also opens possibilities to draw onnatural language processing techniques for querying and data mining.,European Semantic Web Conference,2015,31
Aggregating and disaggregating flexibility objects,Laurynas Šikšnys; Emmanouil Valsomatzis; Katja Hose; Torben Bach Pedersen,In many scientific and commercial domains; we encounter flexibility objects; ie; objects withexplicit flexibilities in a time and an amount dimension (eg; energy or product amount).Applications of flexibility objects require novel and efficient techniques capable of handlinglarge amounts of such objects while preserving flexibility. Hence; this paper formally definesthe concept of flexibility objects (flex-objects) and provides a novel and efficient solution foraggregating and disaggregating flex-objects. Out of the broad range of possibleapplications; this paper will focus on smart grid energy data management and discussstrategies for aggregation and disaggregation of flex-objects while retaining flexibility. Thispaperfurther extends these approaches beyond flex-objects originating from energyconsumption by additionally considering flex-objects originating from energy production …,IEEE Transactions on Knowledge and Data Engineering,2015,30
A research agenda for query processing in large-scale peer data management systems,Katja Hose; Armin Roth; André Zeitz; Kai-Uwe Sattler; Felix Naumann,Abstract Peer Data Management Systems (P dms) are a novel; useful; but challengingparadigm for distributed data management and query processing. Conventional integratedinformation systems have a hierarchical structure with an integration component thatmanages a global schema and distributes queries against this schema to the underlyingdata sources. P dms are a natural extension to this architecture by allowing eachparticipating system (peer) to act both as a data source and as an integrator. Peers areinterconnected by schema mappings; which guide the rewriting of queries between theheterogeneous schemas; and thus form a P2P (peer-to-peer)-like network. Despite severalyears of research; the development of efficient P dms still holds many challenges. In thisarticle we first survey the state of the art on peer data management: We classify P dms by …,Information Systems,2008,25
Stream engines meet wireless sensor networks: cost-based planning and processing of complex queries in AnduIN,Daniel Klan; Marcel Karnstedt; Katja Hose; Liz Ribe-Baumann; Kai-Uwe Sattler,Abstract Wireless sensor networks are powerful; distributed; self-organizing systems usedfor event and environmental monitoring. In-network query processors like TinyDB offer auser friendly SQL-like application development. Due to the sensor nodes' resourcelimitations; monolithic approaches often support only a restricted number of operators. Forthis reason; complex processing is typically outsourced to the base station. Nevertheless;previous work has shown that complete or partial in-network processing can be moreefficient than the base station approach. In this paper; we introduce AnduIN; a system fordeveloping; deploying; and running complex in-network processing tasks. In particular; wepresent the query planning and execution strategies used in AnduIN; a system combiningsensor-local in-network processing and a data stream engine. Query planning employs a …,Distributed and Parallel Databases,2011,24
Towards benefit-based RDF source selection for SPARQL queries,Katja Hose; Ralf Schenkel,Abstract The Linked Data cloud consists of a great variety of data provided by an increasingnumber of sources. Selecting relevant sources is therefore a core ingredient of efficientquery processing. So far; this is either done with additional indexes or by iterativelyperforming lookups for relevant URIs. None of the existing methods takes additional aspectsinto account such as the degree of overlap between the sources; resulting in unnecessaryrequests. In this paper; we propose a sketch-based query routing strategy that takes sourceoverlap into account. The proposed strategy uses sketches and can be tuned towards eitherretrieving as many results as possible for a given budget or minimizing the number ofrequests necessary to retrieve all or a certain fraction of the results. Our experiments showsignificant improvements over state-of-the-art but overlap-ignorant methods for source …,Proceedings of the 4th International Workshop on Semantic Web Information Management,2012,23
Processing Top-N Queries in P2P-based Web Integration Systems with Probabilistic Guarantees.,Katja Hose; Marcel Karnstedt; Kai-Uwe Sattler; Daniel Zinn,ABSTRACT Efficient query processing in P2P-based Web integration systems poses avariety of challenges resulting from the strict decentralization and limited knowledge. As aspecial problem in this context we consider the evaluation of top-N queries on structureddata. Due to the characteristics of large-scaled P2P systems it is nearly impossible toguarantee complete and exact query answers without exhaustive search; which usuallyends in flooding the network. In this paper; we address this problem by presenting anapproach relying on histogram-based routing filters. These allow for reducing the number ofqueried peers as well as for giving probabilistic guarantees concerning the goodness of theanswer.,WebDB,2005,22
Towards exploratory OLAP over linked open data–a case study,Dilshod Ibragimov; Katja Hose; Torben Bach Pedersen; Esteban Zimányi,Abstract Business Intelligence (BI) tools provide fundamental support for analyzing largevolumes of information. Data Warehouses (DW) and Online Analytical Processing (OLAP)tools are used to store and analyze data. Nowadays more and more information is availableon the Web in the form of Resource Description Framework (RDF); and BI tools have a hugepotential of achieving better results by integrating real-time data from web sources into theanalysis process. In this paper; we describe a framework for so-called exploratory OLAPover RDF sources. We propose a system that uses a multidimensional schema of the OLAPcube expressed in RDF vocabularies. Based on this information the system is able to querydata sources; extract and aggregate data; and build a cube. We also propose a computer-aided process for discovering previously unknown data sources and building a …,*,2015,19
Query routing and processing in schema-based P2P systems,Marcel Karnstedt; Katja Hose; K-U Sattler,Recently; the peer-to-peer (P2P) paradigm has emerged; mainly by file sharing systemssuch as Napster and Gnutella and in terms of scalable distributed data structures. Due to thedecentralization; P2P systems promise an improved robustness and scalability andtherefore open also a new view on data integration solutions. However; several design andtechnical challenges arise in building scalable P2P-based integration systems. We addressone of them: the problem of distributed query processing. We discuss strategies of querydecomposition and routing based on different kinds of routing indexes and present results ofan experimental evaluation.,Database and Expert Systems Applications; 2004. Proceedings. 15th International Workshop on,2004,19
Processing skyline queries in P2P systems,Katja Hose,Abstract Efficient query processing in P2P systems poses a variety of challenges mainlyresulting from the strict decentralization and limited knowledge. Particularly with regard toqueries involving ranking; top-N or skylines; existing approaches for centralized systemscannot be applied easily to P2P environments. In this paper; we focus on the problem ofefficiently processing skyline queries in large-scale P2P systems; where it is nearlyimpossible to guarantee complete and exact query answers without exhaustive search; ie;flooding the network. Thus; applying approximate query answering techniques; that are alsotypical for processing top-N queries in centralized database environments; seems to be thenatural choice. We address this problem by presenting an approach that allows for reducingthe number of queried peers as well as for giving probabilistic guarantees for the …,VLDB 2005 PhD Workshop,2005,18
Distributed data summaries for approximate query processing in PDMS,Katja Hose; Daniel Klan; Kai-Uwe Sattler,Evolving from heterogeneous database systems one of the main problems in peer datamanagement systems (PDMS) is distributed query processing. With the absence of globalknowledge such strategies have to focus on routing the query efficiently to only those peersthat are most likely to contribute to the final result. Using routing indexes is one possibility toachieve this. Since data may change over time these structures have to be updated andmaintained which can be very expensive. In this paper; we present a novel kind of routingindexes that enables efficient query routing. Furthermore; we propose a threshold basedupdate strategy that can help to reduce maintenance costs by far. We exemplify the benefitof these indexes using a distributed skyline strategy as an example. Finally; we show howrelaxing exactness requirements; that are usually posed on results; can compensate the …,Database Engineering and Applications Symposium; 2006. IDEAS'06. 10th International,2006,17
Linked data management,Andreas Harth; Katja Hose; Ralf Schenkel,Linked Data Management presents techniques for querying and managing Linked Data thatis available on today's Web. The book shows how the abundance of Linked Data can serveas fertile ground for research and commercial applications. The text focuses on aspects ofmanaging large-scale collections of Linked Data. It offers a detailed introduction to LinkedData and related standards; including the main principles distinguishing Linked Data fromstandard database technology. Chapters also describe how to generate links betweendatasets and explain the overall architecture of data integration systems based on LinkedData. A large part of the text is devoted to query processing in different setups. Afterpresenting methods to publish relational data as Linked Data and efficient centralizedprocessing; the book explores lookup-based; distributed; and parallel solutions. It then …,*,2016,16
Processing rank-aware queries in P2P systems,Katja Hose; Marcel Karnstedt; Anke Koch; Kai-Uwe Sattler; Daniel Zinn,Abstract Efficient query processing in P2P systems poses a variety of challenges. As aspecial problem in this context we consider the evaluation of rank-aware queries; namelytop-N and skyline; on structured data. The optimization of query processing in a distributedmanner at each peer requires locally available statistics. In this paper; we address thisproblem by presenting approaches relying on the R-tree and histogram-based indexstructures. We show how this allows for optimizing rank-aware queries even over multipleattributes and thus significantly enhances the efficiency of query processing.,*,2007,16
ROXXI: Reviving witness dOcuments to eXplore eXtracted Information,Shady Elbassuoni; Katja Hose; Steffen Metzger; Ralf Schenkel,Abstract In recent years; there has been considerable research on information extractionand constructing RDF knowledge bases. In general; the goal is to extract all relevantinformation from a corpus of documents; store it into an ontology; and answer future queriesbased only on the created knowledge base. Thus; the original documents becomedispensable. On the one hand; an ontology is a convenient and non-redundant structuredsource of information; based on which specific queries can be answered efficiently. On theother hand; many users doubt the correctness of facts and ontology subgraphs presented tothem as query results without proof. Instead; users often wish to verify the obtained facts orsubgraphs by reading about them in context; ie; in a document relating the facts andproviding background information. In this demo; we present ROXXI; a system operating …,Proceedings of the VLDB Endowment,2010,12
Online tuning of aggregation tables for olap,Katja Hose; Daniel Klan; Kai-Uwe Sattler,Materializing results from complex aggregation queries helps to significantly improveresponse times in OLAP servers. This problem is known as the view selection problem:choosing the optimal set of aggregation tables (called configuration) for a given workload. Inthis paper we present an online approach for adjusting the configuration dynamically to thecurrent workload. This approach is implemented as part of an open source OLAP server andacts on the level of multidimensional MDX queries. The work presents the details of costestimation and optimization of the system demonstrated in [10] and extends it by an onlinetuning strategy.,Data Engineering; 2009. ICDE'09. IEEE 25th International Conference on,2009,12
Towards a programmable semantic extract-transform-load framework for semantic data warehouses,Rudra Pratap Deb Nath; Katja Hose; Torben Bach Pedersen,Abstract In order to create better decisions for business analytics; organizations increasinglyuse external data; structured; semi-structured and unstructured; in addition to the (mostlystructured) internal data. Current Extract-Transform-Load (ETL) tools are not suitable for this"open world scenario" because they do not consider semantic issues in the integrationprocess. Also; current ETL tools neither support processing semantic-aware data nor createa Semantic Data Warehouse (DW) as a semantic repository of semantically integrated data.This paper describes SETL: a (Python-based) programmable Semantic ETL framework.SETL builds on Semantic Web (SW) standards and tools and supports developers byoffering a number of powerful modules; classes and methods for (dimensional andsemantic) DW constructs and tasks. Thus it supports semantic-aware data sources …,Proceedings of the ACM Eighteenth International Workshop on Data Warehousing and OLAP,2015,11
Optimizing RDF Data Cubes for Efficient Processing of Analytical Queries.,Kim Ahlstrøm Jakobsen; Alex B Andersen; Katja Hose; Torben Bach Pedersen,Abstract. In today's data-driven world; analytical querying; typically based on the data cubeconcept; is the cornerstone of answering important business questions and making data-driven decisions. Traditionally; the underlying analytical data was mostly internal to theorganization and stored in relational data warehouses and data cubes. Today; external datasources are essential for analytics and; as the Semantic Web gains popularity; more andmore external sources are available in native RDF. With the recent SPARQL 1.1 standard;performing analytical queries over RDF data sources has finally become feasible. However;unlike their relational counterparts; RDF data cubes stores lack optimizations that enablefast querying. In this paper; we present an approach to optimizing RDF data cubes that isbased on three novel cube patterns that optimize RDF data cubes; as well as associated …,COLD,2015,11
Processing aggregate queries in a federation of SPARQL endpoints,Dilshod Ibragimov; Katja Hose; Torben Bach Pedersen; Esteban Zimányi,Abstract More and more RDF data is exposed on the Web via SPARQL endpoints. With therecent SPARQL 1.1 standard; these datasets can be queried in novel and more powerfulways; eg; complex analysis tasks involving grouping and aggregation; and even data frommultiple SPARQL endpoints; can now be formulated in a single query. This enablesBusiness Intelligence applications that access data from federated web sources and cancombine it with local data. However; as both aggregate and federated queries have becomeavailable only recently; state-of-the-art systems lack sophisticated optimization techniquesthat facilitate efficient execution of such queries over large datasets. To overcome theseshortcomings; we propose a set of query processing strategies and the associated Cost-based Optimizer for Distributed Aggregate queries (CoDA) for executing aggregate …,European Semantic Web Conference,2015,11
Distributed Query Processing in P2P Systems with Incomplete Schema Information.,Marcel Karnstedt; Katja Hose; Kai-Uwe Sattler,Abstract. The peer-to-peer (P2P) paradigm has emerged recently; mainly by file sharingsystems like Napster or Gnutella and in terms of scalable distributed data structures.Because of the decentralization P2P systems promise an improved scalability androbustness; and they open a new view on data integration approaches; too. By exploitingalready available mappings between pairs of peers a new peer joining the systems canimmediately participate and access all the available data after establishing acorrespondence mapping to at least one other peer. One of the technical challenges inbuilding scalable P2P based integration systems is the efficient processing of queries whichis complicated by the locally restricted knowledge about data placement and schemainformation. In this paper; we address this problem by investigating query processing …,DIWeb,2004,11
Using read/write Linked Data for Application Integration-Towards a Linked Data Basic Profile.,Arnaud Le Hors; Martin Nally; Steve Speicher,ABSTRACT Linked Data; as defined by Tim Berners-Lee's 4 rules [1]; has enjoyedconsiderable well-publicized success as a technology for publishing data in the World WideWeb [2]. The Rational group in IBM has for several years been employing a read/write usageof Linked Data as an architectural style for integrating a suite of applications; and we haveshipped commercial products using this technology. We have found that this read/writeusage of Linked Data has helped us solve several perennial problems that we had beenunable to successfully solve with other application integration architectural styles that wehave explored in the past. The applications we have integrated in IBM are primarily in thedomains of Application Lifecycle Management (ALM) and Integration System Management(ISM); but we believe that our experiences using read/write Linked Data to solve …,LDOW,2012,10
S3K: seeking statement-supporting top-K witnesses,Steffen Metzger; Shady Elbassuoni; Katja Hose; Ralf Schenkel,Abstract Traditional information retrieval techniques based on keyword search help toidentify a ranked set of relevant documents; which often contains many documents in the topranks that do not meet the user's intention. By considering the semantics of the keywordsand their relationships; both precision and recall can be improved. Using an ontology andmapping keywords to entities/concepts and identifying the relationship between them thatthe user is interested in; allows for retrieving documents that actually meet the user'sintention. In this paper; we present a framework that enables semantic-aware documentretrieval. User queries are mapped to semantic statements based on entities and theirrelationships. The framework searches for documents expressing these statements indifferent variations; eg; synonymous names for entities or different textual expressions for …,Proceedings of the 20th ACM international conference on Information and knowledge management,2011,10
An extensible; distributed simulation environment for peer data management systems,Katja Hose; Andreas Job; Marcel Karnstedt; Kai-Uwe Sattler,Abstract Peer Data Management Systems (PDMS) have recently attracted attention by thedatabase community. One of the main challenges of this paradigm is the development andevaluation of indexing and query processing strategies for large-scale networks. So far;research groups working in this area build their own testing environment which first causes ahuge effort and second makes it difficult to compare different strategies. In this demonstrationpaper; we present a simulation environment that aims to be an extensible platform forexperimenting with query processing techniques in PDMS and allows for running largesimulation experiments in distributed environments such as workstation clusters or evenPlanetLab. In the demonstration we plan to show the evaluation of processing strategies forqueries with specialized operators like top-k and skyline computation on structured data.,International Conference on Extending Database Technology,2006,10
Power-aware data analysis in sensor networks,Daniel Klan; Katja Hose; Marcel Karnstedt; Kai-Uwe Sattler,Sensor networks have evolved to a powerful infrastructure component for event monitoringin many application scenarios. In addition to simple filter and aggregation operations; animportant task in processing sensor data is data mining-the identification of relevantinformation and patterns. Limited capabilities of sensor nodes in terms of storage andprocessing capacity; battery lifetime; and communication demand a power-efficient;preferably sensor-local processing. In this paper; we present AnduIN; a system fordeveloping; deploying; and running in-network data mining tasks. The system consists of adata stream processing engine; a library of operators for sensor-local processing; a box-and-arrow editor for specifying data mining tasks and deployment; a GUI providing the user withcurrent information about the network and running queries; and an alerter notifying the …,Data Engineering (ICDE); 2010 IEEE 26th International Conference on,2010,9
Developing and deploying sensor network applications with AnduIN,Daniel Klan; Katja Hose; Kai-Uwe Sattler,Abstract Wireless sensor networks have become important architectures for manyapplication scenarios; eg; traffic monitoring or environmental monitoring in general. As thesesensors are battery-powered; query processing strategies aim at minimizing energyconsumption. Because sending all sensor readings to a central stream data managementsystem consumes too much energy; parts of the query can already be processed within thenetwork (in-network query processing). An important optimization criterion in this context iswhere to process which intermediate results and how to route them efficiently. To overcomethese problems; we propose AnduIN; a system addressing these problems and offering anoptimizer that decides which parts of the query should be processed within the sensornetwork. It also considers optimization with respect to complex data analysis tasks; such …,Proceedings of the Sixth International Workshop on Data Management for Sensor Networks,2009,9
Adaptive routing filters for robust query processing in schema-based P2P systems,Katja Hose; Marcel Karnstedt; K-U Sattler; E-A Stehr,Peer data management systems (PDMS) currently gain attention at an emerging scale inorder to cope with the needs of growing organizational integration. Efficient queryprocessing; as one of the main requirements in these systems; provides three majorchallenges: achieving robustness; scalability and self organization. In this paper we dealwith the physical aspects of these requirements. We introduce an adaptive maintenancetechnique based on query feedback for keeping routing filters; used to optimize routing; up-to-date. These filters are applied in conjunction with an iterative query processing strategyand we show that this can improve robustness and scalability of query processing indistributed data management systems.,Database Engineering and Application Symposium; 2005. IDEAS 2005. 9th International,2005,9
Publishing danish agricultural government data as semantic web data,Alex B Andersen; Nurefşan Gür; Katja Hose; Kim A Jakobsen; Torben Bach Pedersen,Abstract Recent advances in Semantic Web technologies have led to a growing popularity ofthe Linked Open Data movement. Only recently; the Danish government has joined themovement and published several datasets as Open Data. These raw datasets are difficult toprocess automatically and combine with other data sources on the Web. Hence; our goal isto convert such data into RDF and make it available to a broader range of users andapplications as Linked Open Data. In this paper; we discuss our experiences based on theparticularly interesting use case of agricultural data as agriculture is one of the mostimportant industries in Denmark. We describe the process of converting the data anddiscuss the particular problems that we encountered with respect to the considered datasets.We additionally evaluate our result based on several queries that could not be answered …,Joint International Semantic Technology Conference,2014,8
Database techniques for linked data management,Andreas Harth; Katja Hose; Ralf Schenkel,Abstract Linked Data refers to data published in accordance with a number of principlesrooted in web standards. In the past few years we have witnessed a tremendous growth inLinked Data publishing on the web; leading to tens of billions of data items published online.Querying the data is a key functionality required to make use of the wealth of rich interlinkeddata. The goal of the tutorial is to introduce; motivate; and detail techniques for queryingheterogeneous structured data from across the web. Our tutorial aims to introduce databaseresearchers and practitioners to the new publishing paradigm on the web; and show howthe abundance of data published as Linked Data can serve as fertile ground for databaseresearch and experimentation. As such; the tutorial focuses on applying databasetechniques to processing Linked Data; such as optimized indexing and query processing …,Proceedings of the 2012 ACM SIGMOD International Conference on Management of Data,2012,8
A relaxed but not necessarily constrained way from the top to the sky,Katja Hose; Christian Lemke; Kai-Uwe Sattler; Daniel Zinn,Abstract As P2P systems are a very popular approach to connect a possibly large number ofpeers; efficient query processing plays an important role. Appropriate strategies have to takethe characteristics of these systems into account. Due to the possibly large number of peers;extensive flooding is not possible. The application of routing indexes is a commonly usedtechnique to avoid flooding. Promising techniques to further reduce execution costs arequery operators such as top-N and skyline; constraints; and the relaxation of exactnessand/or completeness. In this paper; we propose strategies that take all these aspects intoaccount. The choice is left to the user if and to what extent he is willing to relax exactness orapply constraints. We provide a thorough evaluation that uses two types of distributed datasummaries as examples for routing indexes.,OTM Confederated International Conferences" On the Move to Meaningful Internet Systems",2007,8
Complex Schema Mapping and Linking Data: Beyond Binary Predicates.,Jacobo Rouces; Gerard de Melo; Katja Hose,ABSTRACT Currently; datasets in the Linked Open Data (LOD) cloud are mostly connectedby properties such as owl: sameAs; rdfs: subClassOf; or owl: equivalentProperty. Theseproperties either link pairs of entities that are equivalent or express some other binaryrelationship such as subsumption. In many cases; however; this is not sufficient to link alltypes of equivalent knowledge. Often; a relationship exists between an entity in one datasetand what is represented by a complex pattern in another; or between two complex patterns.In this paper; we present a method for linking datasets that is expressive enough to supportthese cases. It consists of integration rules between arbitrary datasets and a mediatedschema. We also present and evaluate a method to create these integration rulesautomatically.,LDOW@ WWW,2016,7
Representing Specialized Events with FrameBase.,Jacobo Rouces; Gerard De Melo; Katja Hose,Abstract. Events of various sorts make up an important subset of the entities relevant not onlyin knowledge representation but also in natural language processing and numerous otherfields and tasks. How to represent these in a homogeneous yet expressive; extensive; andextensible way remains a challenge. In this paper; we propose an approach based onFrameBase; a broad RDFS-based schema consisting of frames and roles. The concept of aframe; which is a very general one; can be considered as subsuming existing definitions ofevents. This ensures a broad coverage and a uniform representation of various kinds ofevents; thus bearing the potential to serve as a unified event model. We show howFrameBase can represent events from several different sources and domains. These includeevents from a specific taxonomy related to organized crime; events captured using …,DeRiVE@ ESWC,2015,7
Sparqling pig-processing linked data with pig latin,Stefan Hagedorn; Katja Hose; Kai-Uwe Sattler,In recent years; dataflow languages such as Pig Latin have emerged as flexible andpowerful tools for handling complex analysis tasks on big data. These languages supportschema flexibility as well as common programming patterns such as iteration. They offerextensibility through user-defined functions while running on top of scalable distributedplatforms. In doing so; these languages enable analytical tasks while avoiding the limitationsof classical query languages such as SQL and SPARQL. However; the tuple-oriented viewof general-purpose languages like Pig does not match very well the specifics of moderndatasets available on the Web; which often use the RDF data model. Graph patterns; forinstance; are one of the core concepts of SPARQL but have to be formulated as explicitjoins; which burdens the user with the details of efficient query processing strategies. In …,Datenbanksysteme für Business; Technologie und Web (BTW 2015),2015,7
The Bigdata® RDF Graph Database.,Bryan B Thompson; Mike Personick; Martyn Cutcher,*,*,2014,7
Learning from the history of distributed query processing: A heretic view on Linked Data management,Heiko Betz; Francis Gropengießer; Katja Hose; Kai-Uwe Sattler,Abstract. The vision of the Semantic Web has triggered the development of various newapplications and opened up new directions in research. Recently; much effort has been putinto the development of techniques for query processing over Linked Data. Being basedupon techniques originally developed for distributed and federated databases; some of theminherit the same or similar problems. Thus; the goal of this paper is to point out pitfalls thatthe previous generation of researchers has already encountered and to introduce the LinkedData as a Service as an idea that has the potential to solve the problem in some scenarios.Hence; this paper discusses nine theses about Linked Data processing and sketches aresearch agenda for future endeavors in the area of Linked Data processing.,Proceedings of the Third International Conference on Consuming Linked Data-Volume 905,2012,7
Maintenance strategies for routing indexes,Katja Hose; Christian Lemke; Kai-Uwe Sattler,Abstract Query processing in large-scale unstructured P2P networks is a crucial part ofoperating such systems. In order to avoid expensive flooding of the network during queryprocessing so-called routing indexes are used. Each peer maintains such an index for itsneighbors. It provides a compact representation (data summary) of data accessible via eachneighboring peer. An important problem in this context is to keep these data summaries up-to-date without paying high maintenance costs. In this paper; we investigate the problem ofmaintaining distributed data summaries in P2P-based environments without globalknowledge and central instances. Based on a classification of update propagationstrategies; we discuss several approaches to reduce maintenance costs and present resultsfrom an experimental evaluation.,Distributed and Parallel Databases,2009,7
Optimizing aggregate SPARQL queries using materialized RDF views,Dilshod Ibragimov; Katja Hose; Torben Bach Pedersen; Esteban Zimányi,Abstract During recent years; more and more data has been published as native RDFdatasets. In this setup; both the size of the datasets and the need to process aggregatequeries represent challenges for standard SPARQL query processing techniques. Toovercome these limitations; materialized views can be created and used as a source ofprecomputed partial results during query processing. However; materialized viewtechniques as proposed for relational databases do not support RDF specifics; such asincompleteness and the need to support implicit (derived) information. To overcome thesechallenges; this paper proposes MARVEL (MAterialized Rdf Views with Entailment andincompLetness). The approach consists of a view selection algorithm based on anassociated RDF-specific cost model; a view definition syntax; and an algorithm for …,International Semantic Web Conference,2016,6
Searching the web of data,Gerard de Melo; Katja Hose,Abstract Search is currently undergoing a major paradigm shift away from the traditionaldocument-centric “10 blue links” towards more explicit and actionable information. Recentadvances in this area are Google's Knowledge Graph; Virtual Personal Assistants such asSiri and Google Now; as well as the now ubiquitous entity-oriented vertical search results forplaces; products; etc. Apart from novel query understanding methods; these developmentsare largely driven by structured data that is blended into the Web Search experience. Wediscuss efficient indexing and query processing techniques to work with large amounts ofstructured data. Finally; we present query interpretation and understanding methods to mapuser queries to these structured data sources.,European Conference on Information Retrieval,2013,6
An experience report of large scale federations,Andreas Schwarte; Peter Haase; Michael Schmidt; Katja Hose; Ralf Schenkel,Abstract: We present an experimental study of large-scale RDF federations on top of theBio2RDF data sources; involving 29 data sets with more than four billion RDF triplesdeployed in a local federation. Our federation is driven by FedX; a highly optimizedfederation mediator for Linked Data. We discuss design decisions; technical aspects; andexperiences made in setting up and optimizing the Bio2RDF federation; and present anexhaustive experimental evaluation of the federation scenario. In addition to a controlledsetting with local federation members; we study implications arising in a hybrid setting;where local federation members interact with remote federation members exhibiting highernetwork latency. The outcome demonstrates the feasibility of federated semantic datamanagement in general and indicates remaining bottlenecks and research opportunities …,arXiv preprint arXiv:1210.5403,2012,6
An extended transaction model for cooperative authoring of XML data,Francis Gropengießer; Katja Hose; Kai-Uwe Sattler,Abstract In many application scenarios; for example in design or media productionprocesses; several authors have to work cooperatively on the same project andconsequently on the same data. In this context; a frequently used data format is XML. Toenable cooperative authoring of shared XML graph structures; several requirements have tobe fulfilled; eg; early visibility of updates; multi-directional information flow; and processingdata in parallel. Most transaction models proposed in the literature are hardly applicable inthis context. In this paper; we propose a novel transaction model based on multi-leveltransactions and dynamic actions that meets these requirements. We describe thetransaction model as well as its formal properties and discuss issues such assynchronization and logging.,Computer Science-Research and Development,2009,6
Processing rank aware queries in schema based P2P systems.,Katja Hose,*,*,2009,6
When is it time to rethink the aggregate configuration of your OLAP server?,Katja Hose; Daniel Klan; Matthias Marx; Kai-Uwe Sattler,Abstract OLAP servers based on relational backends typically exploit materializedaggregate tables to improve response times of complex analytical queries. One of the keyproblems in this context is the view selection problem: choosing the optimal set ofaggregation tables (called configuration) for a given workload. In this paper; we present asystem that continuously monitors the workload and raises a quantified alert; when a betterconfiguration is available. We address the tasks of query monitoring and view selection atthe OLAP level instead of the SQL level; which simplifies the containment checks as well asrewriting and in this way helps to reduce the complexity of the backend system. At the demowe plan to show how our system works; ie; how the system reacts upon arbitrary (interactive)workloads and how the user is alerted that a better configuration is available.,Proceedings of the VLDB Endowment,2008,6
SmurfPDMS: A Platform for Query Processing in Large-Scale PDMS.,Katja Hose; Christian Lemke; Jana Quasebarth; Kai-Uwe Sattler,Abstract: As Peer Data Management Systems (PDMS) are a focus of current research; thereare lots of approaches like query processing or routing issues that have to be evaluated.Since there is no common platform approaches are evaluated in separate. This isdisadvantageous for research groups in two ways. First; it means a huge effort to build asimulation environment from scratch. Second; this makes a direct comparison of approachesmore difficult. In this paper; we present SmurfPDMS an extensible system that means toprovide a common platform for all researchers in that they can easily integrate theirapproaches and that allows for running large simulation experiments in distributedenvironments such as workstation clusters or even PlanetLab.,BTW,2007,6
Measuring and Comparing Energy Flexibilities.,Emmanouil Valsomatzis; Katja Hose; Torben Bach Pedersen; Laurynas Siksnys,ABSTRACT Flexibility in energy supply and demand becomes more and more importantwith increasing Renewable Energy Sources (RES) production and the emergence of theSmart Grid. Socalled prosumers; ie; entities that produce and/or consume energy; can offertheir inherent flexibilities through so-called demand response and thus help stabilize theenergy markets. Thus; prosumer flexibility becomes valuable and the ongoing Danishproject TotalFlex [1] explores the use of prosumer flexibility in the energy market using theconcept of a flex-offer [2]; which captures energy flexibilities in time and/or amount explicitly.However; in order to manage and price the flexibilities of flex-offers effectively; we must firstbe able to measure these flexibilities and compare them to each other. In this paper; wepropose a number of possible flexibility definitions for flex-offers. We consider flexibility …,EDBT/ICDT Workshops,2015,5
Resource Planning for SPARQL Query Execution on Data Sharing Platforms.,Stefan Hagedorn; Katja Hose; Kai-Uwe Sattler; Jürgen Umbrich,Abstract. To increase performance; data sharing platforms often make use of clusters ofnodes where certain tasks can be executed in parallel. Resource planning and especiallydeciding how many processors should be chosen to exploit parallel processing is complexin such a setup as increasing the number of processors does not always improve runtimedue to communication overhead. Instead; there is usually an optimum number of processorsfor which using more or fewer processors leads to less efficient runtimes. In this paper; wepresent a cost model based on widely used statistics (VoiD) and show how to compute theoptimum number of processors that should be used to evaluate a particular SPARQL queryover a particular configuration and RDF dataset. Our first experiments show the generalapplicability of our approach but also how shortcomings in the used statistics limit the …,COLD,2014,5
Incremental Reasoning on RDF Streams.,Daniele Dell'Aglio; Emanuele Della Valle,*,*,2014,5
Distributed skyline processing: a trend in database research still going strong,Katja Hose; Akrivi Vlachou,Abstract During the last decade; data management and storage have become increasinglydistributed. In consideration of the huge amount of data available in such systems; advancedquery operators; such as skyline queries; are necessary to help users process the data. Forexample; a user who is interested in buying a car wants to find a good trade-off betweenminimum age and minimum price. It is not obvious how much cheaper a car should be; if it isone year older than another car. Thus; the skyline query will retrieve a set of data items thatare the best trade-offs for the user's preferences. The skyline operator has been proposedabout a decade ago; but research on skyline queries; especially in distributed scenarios; isstill an ongoing process. Query processing in distributed environments poses inherentchallenges and requires non-traditional techniques due to the distribution of content and …,Proceedings of the 15th International Conference on Extending Database Technology,2012,5
Decentralized managing of replication objects in massively distributed systems,Daniel Klan; Kai-Uwe Sattler; Katja Hose; Marcel Karnstedt,Abstract Data replication is a central technique to increase availability and performance ofdistributed systems. While offering many advantages it also requires more effort for ensuringdata consistency in case of updates. In the research literature various approaches forreplication management in distributed databases have been presented; but they are mostlylimited either in scalability or in the consistency guarantees they provide. On the other hand;P2P systems usually provide replication support but ignore the update problem. In this paperwe present a new approach for managing replicated data in wide area distributed networks.Our solution is orthogonal to the underlying infrastructure and managed in a decentralizedmanner. It guarantees single-master consistency and allows updates at any node of thesystem by combining traditional replication techniques with ideas known from P2P …,Proceedings of the 2008 international workshop on Data management in peer-to-peer systems,2008,5
Aggregating energy flexibilities under constraints,Emmanouil Valsomatzis; Torben Bach Pedersen; Alberto Abelló; Katja Hose,The flexibility of individual energy prosumers (producers and/or consumers) has drawn a lotof attention in recent years. Aggregation of such flexibilities provides prosumers with theopportunity to directly participate in the energy market and at the same time reduces thecomplexity of scheduling the energy units. However; aggregated flexibility should supportnormal grid operation. In this paper; we build on the flex-offer (FO) concept to model theinherent flexibility of a prosumer (eg; a single flexible consumption device such as a clotheswasher). An FO captures flexibility in both time and amount dimensions. We define theproblem of aggregating FOs taking into account grid power constraints. We also propose twoconstraint-based aggregation techniques that efficiently aggregate FOs while retainingflexibility. We show through a comprehensive evaluation that our techniques; in contrast …,Smart Grid Communications (SmartGridComm); 2016 IEEE International Conference on,2016,4
Heuristics for connecting heterogeneous knowledge via FrameBase,Jacobo Rouces; Gerard de Melo; Katja Hose,Abstract With recent advances in information extraction techniques; various large-scaleknowledge bases covering a broad range of knowledge have become publicly available. Asno single knowledge base covers all information; many applications require access tointegrated knowledge from multiple knowledge bases. Achieving this; however; ischallenging due to differences in knowledge representation. To address this problem; thispaper proposes to use linguistic frames as a common representation and mapsheterogeneous knowledge bases to the FrameBase schema; which is formed by a largeinventory of these frames. We develop several methods to create complex mappings fromexternal knowledge bases to this schema; using text similarity measures; machine learning;and different heuristics. We test them with different widely used large-scale knowledge …,International Semantic Web Conference,2016,4
Balancing energy flexibilities through aggregation,Emmanouil Valsomatzis; Katja Hose; Torben Bach Pedersen,Abstract One of the main goals of recent developments in the Smart Grid area is to increasethe use of renewable energy sources. These sources are characterized by energyfluctuations that might lead to energy imbalances and congestions in the electricity grid.Exploiting inherent flexibilities; which exist in both energy production and consumption; isthe key to solving these problems. Flexibilities can be expressed as flex-offers; which due totheir high number need to be aggregated to reduce the complexity of energy scheduling. Inthis paper; we discuss balance aggregation techniques that already during aggregation aimat balancing flexibilities in production and consumption to reduce the probability ofcongestions and reduce the complexity of scheduling. We present results of our extensiveexperiments.,International Workshop on Data Analytics for Renewable Energy Integration,2014,4
SETL: A programmable semantic extract-transform-load framework for semantic data warehouses,Rudra Pratap Deb Nath; Katja Hose; Torben Bach Pedersen; Oscar Romero,Abstract In order to create better decisions for business analytics; organizations increasinglyuse external structured; semi-structured; and unstructured data in addition to the (mostlystructured) internal data. Current Extract-Transform-Load (ETL) tools are not suitable for this“open world scenario” because they do not consider semantic issues in the integrationprocessing. Current ETL tools neither support processing semantic data nor create asemantic Data Warehouse (DW); a repository of semantically integrated data. This paperdescribes our programmable Semantic ETL (SETL) framework. SETL builds on SemanticWeb (SW) standards and tools and supports developers by offering a number of powerfulmodules; classes; and methods for (dimensional and semantic) DW constructs and tasks.Thus it supports semantic data sources in addition to traditional data sources; semantic …,Information Systems,2017,3
Towards constraint-based aggregation of energy flexibilities,Emmanouil Valsomatzis; Torben Bach Pedersen; Alberto Abelló; Katja Hose; Laurynas Šikšnys,Abstract The aggregation of energy flexibilities enables individual producers and/orconsumers with small loads to directly participate in the emerging energy markets. On theother hand; aggregation of such flexibilities might also create problems to the operation ofthe electrical grid. In this paper; we present the problem of aggregating energy flexibilitiestaking into account grid capacity limitations and introduce a heuristic aggregation technique.We show through an experimental setup that our proposed technique; compared to abaseline approach; not only leads to a valid unit commitment result that respects the gridconstraint; but it also improves the quality of the result.,Proceedings of the Seventh International Conference on Future Energy Systems Poster Sessions,2016,3
A foundation for spatial data warehouses on the semantic web,Nurefşan Gür; Torben Bach Pedersen; Esteban Zimányi; Katja Hose,Abstract Large volumes of geospatial data are being published on the Semantic Web (SW);yielding a need for advanced analysis of such data. However; existing SW technologies onlysupport advanced analytical concepts such as multidimensional (MD) data warehouses andOnline Analytical Processing (OLAP) over non-spatial SW data. To remedy this need; thispaper presents the QB4SOLAP vocabulary; which supports spatially enhanced MD datacubes over RDF data. The paper also defines a number of Spatial OLAP (SOLAP) operatorsover QB4SOLAP cubes and provides algorithms for generating spatially extended SPARQLqueries from the SOLAP operators. The proposals are validated by applying them to arealistic use case.,Semantic Web,2016,3
Modeling and querying spatial data warehouses on the semantic web,Nurefşan Gür; Katja Hose; Torben Bach Pedersen; Esteban Zimányi,Abstract The Semantic Web (SW) has drawn the attention of data enthusiasts; and alsoinspired the exploitation and design of multidimensional data warehouses; in anunconventional way. Traditional data warehouses (DW) operate over static data. Howevermultidimensional (MD) data modeling approach can be dynamically extended by definingboth the schema and instances of MD data as RDF graphs. The importance and applicabilityof MD data warehouses over RDF is widely studied yet none of the works support a spatiallyenhanced MD model on the SW. Spatial support in DWs is a desirable feature for enhancedanalysis; since adding encoded spatial information of the data allows to query with spatialfunctions. In this paper we propose to empower the spatial dimension of data warehousesby adding spatial data types and topological relationships to the existing QB4OLAP …,Joint International Semantic Technology Conference,2015,3
Colledge: a vision of collaborative knowledge networks,Steffen Metzger; Katja Hose; Ralf Schenkel,Abstract More and more semantic information has become available as RDF data recently;with the linked open data cloud as a prominent example. However; participating in theSemantic Web is cumbersome. Typically several steps are involved in using semanticknowledge. Information is first acquired; eg by information extraction; crowd sourcing orhuman experts. Then ontologies are published and distributed. Users may apply reasoningand otherwise modify their local ontology instances. However; currently these steps aretreated separately and although each involves human effort; nearly no synergy effect is usedand it is also mostly a one way process; eg user feedback hardly flows back into the mainontology version. Similarly; user cooperation is low. While there are approaches alleviatingsome of these limitations; eg extracting information at query time; personalizing queries …,Proceedings of the 2nd International Workshop on Semantic Search over the Web,2012,3
Advances Towards Semantic Plagiarism Detection.,Hassan Issa; Katja Hose; Steffen Metzger; Ralf Schenkel,Abstract Recent events have again shown that plagiarism detection is an important problemin today's society. The flood of documents; however; makes detection more and more difficultso that the application of computer-based methods is a natural consequence. Theapplication of text comparison techniques; however; eventually leads to'intelligent'plagiarism; where sentences are slightly rephrased or synonyms are used. Tohelp detecting such plagiarism; we propose to use semantic similarity between documentsbased on information extracting techniques. This notion is also useful for other applicationssuch as finding similar news articles and research papers.,LWA,2011,3
On lightweight data summaries for optimised query processing over linked data,Andreas Harth; Katja Hose; Marcel Karnstedt; Axel Polleres; Kai-Uwe Sattler; Jürgen Umbrich,Abstract. Typical approaches for querying structured Web Data collect (crawl) and pre-process (index) large amounts of data in a central data repository before allowing for queryanswering. This time-consuming pre-processing phase however leverages the benefits ofLinked Data–where structured data is accessible live and up-to-date at distributed Webresources that may change constantly–only to a limited degree; as query results can neverbe up-to-date. An ideal query answering system for Linked Data should return currentanswers in a reasonable amount of time; even on corpora as large as the Web. Queryprocessors evaluating queries directly on the live sources require knowledge of the contentsof data sources. In this paper; we develop and evaluate an approximate index structuresummarising graph-structured content of sources adhering to Linked Data principles …,DERI; NUI Galway; Tech. Rep,2009,3
Cooperative data management for XML data,Katja Hose; Kai-Uwe Sattler,Abstract Emerging non-standard applications like the production of high-quality spatialsound pose new challenges to data management. Beside the need for a flexibletransactional management of complex hierarchical scene descriptions a main requirement isthe support of cooperative processes allowing a group of authors to edit a scene together ina distributed environment. Based on previous work on cooperative and non-standardtransactions we present in this paper a transaction model and protocol for XML databasesaddressing this issues.,International Conference on Database and Expert Systems Applications,2007,3
Interoperability in peer data management systems,Katja Hose; Jana Quasebarth; Kai-Uwe Sattler,ABSTRACT Interoperability plays an important role for a variety of applications. One of themare Peer Data Management Systems; where autonomous data sources (peers) interact witheach other based on semantic mappings between their schemas. The building blocks thatenable interoperability and thus the main challenges in such systems are mappingrepresentation; query rewriting; and efficient query processing. While most approachesregard these aspects in separate this paper presents a comprehensive study of theinteractions between these blocks. Our considerations try to provide a holistic view onsemantic interoperability in distributed environments such as PDMS. We discuss techniquesfor distributed query processing and rewriting that consider high-level query operators suchas top-N and skyline. Furthermore; we discuss how to increase efficiency by applying …,SDSI,2007,3
The Odyssey approach for optimizing federated SPARQL queries,Gabriela Montoya; Hala Skaf-Molli; Katja Hose,Abstract Answering queries over a federation of SPARQL endpoints requires combiningdata from more than one data source. Optimizing queries in such scenarios is particularlychallenging not only because of (i) the large variety of possible query execution plans thatcorrectly answer the query but also because (ii) there is only limited access to statisticsabout schema and instance data of remote sources. To overcome these challenges; mostfederated query engines rely on heuristics to reduce the space of possible query executionplans or on dynamic programming strategies to produce optimal plans. Nevertheless; theseplans may still exhibit a high number of intermediate results or high execution times becauseof heuristics and inaccurate cost estimations. In this paper; we present Odyssey; anapproach that uses statistics that allow for a more accurate cost estimation for federated …,International Semantic Web Conference,2017,2
Enabling Completeness-aware Querying in SPARQL,Luis Galárraga; Katja Hose; Simon Razniewski,Abstract Current RDF knowledge bases (KBs) are highly incomplete. This incompleteness isa serious problem both for data users and producers. Users do not have guarantees thatqueries that are run on a KB deliver complete results. Data producers; on the other hand; areblind about the parts of the KB that are incomplete. Yet; completeness informationmanagement is poorly supported in the Semantic Web. No RDF storage engine supportsreasoning with completeness statements. Moreover; SPARQL cannot express completenessconstraints for queries. Motivated by these observations; this paper offers a vision oncompleteness-aware RDF querying. Our vision includes (1) the sketch of a method to reasonabout completeness in RDF knowledge bases;(2) two approaches to representcompleteness information for SPARQL queries; and (3) an extension for the SPARQL …,Proceedings of the 20th International Workshop on the Web and Databases,2017,2
Enabling spatial OLAP over environmental and farming data with QB4SOLAP,Nurefşan Gür; Katja Hose; Torben Bach Pedersen; Esteban Zimányi,Abstract Governmental organizations and agencies have been making large amounts ofspatial data available on the Semantic Web (SW). However; we still lack efficient techniquesfor analyzing such large amounts of data as we know them from relational databasesystems; eg; multidimensional (MD) data warehouses and On-line Analytical Processing(OLAP). A basic prerequisite to enable such advanced analytics is a well-defined schema;which can be defined using the QB4SOLAP vocabulary that provides sufficient context forspatial OLAP (SOLAP). In this paper; we address the challenging problem of MD queryingwith SOLAP operations on the SW by applying QB4SOLAP to a non-trivial spatial use casebased on real-world open governmental data sets across various spatial domains. Wedescribe the process of combining; interpreting; and publishing disparate spatial data …,Joint International Semantic Technology Conference,2016,2
Klint: Assisting Integration of Heterogeneous Knowledge.,Jacobo Rouces; Gerard De Melo; Katja Hose,Abstract An increasing number of structured knowledge bases have become available onthe Web; enabling many new forms of analyses and applications. However; the fact that thedata is being published by different parties with different vocabularies and ontologies meansthat there is a high level of heterogeneity and no common schema. This paper presentsKlint; a web-based system that automatically creates mappings to transform knowledge asprovided by the sources into data that conforms to a large unified schema. The user canreview and edit the mappings with a streamlined interface. In this way; Klint allows forhuman-level accuracy with minimum human effort.,IJCAI,2016,2
LUKe and MIKe: learning from user knowledge and managing interactive knowledge extraction,Steffen Metzger; Michael Stoll; Katja Hose; Ralf Schenkel,Abstract Semantic recognition and annotation of unqiue enities and their relations is a key inunderstanding the essence contained in large text corpora. It typically requires acombination of efficient automatic methods and manual verification. Usually; both parts areseen as consecutive steps. In this demo we present MIKE; a user interface enabling theintegration of user feedback into an iterative extraction process. We show how an extractionsystem can directly learn from such integrated user supervision. In general; this setup allowsfor stepwise training of the extraction system to a particular domain; while using userfeedback early in the iterative extraction process improves extraction quality and reduces theoverall human effort needed.,Proceedings of the 21st ACM international conference on Information and knowledge management,2012,2
Semantic Aware Document Similarity Search,Hassan Issa; Ralf Schenkel; Katja Hose,Autor: Issa; Hassan et al.; Genre: Hochschulschrift; Im Druck veröffentlicht:2012; Titel: Semantic Aware Document Similarity Search.,*,2012,2
Informationsextraktion in deutschen Texten,Sergej Isak-Geidel; Katja Hose; Ralf Schenkel,Autor: Isak-Geidel; Sergej et al.; Genre: Hochschulschrift; Im Druck veröffentlicht:2012; Titel: Informationsextraktion in deutschen Texten.,*,2012,2
Ein kooperativer XMLEditor für Workgroups.,Francis Gropengießer; Katja Hose; Kai-Uwe Sattler,Abstract: In vielen Anwendungsgebieten; zB im Design oder inMedienproduktionsprozessen; hat sich XML als Format für den Datenaustausch etabliert.Zur Verarbeitung von XML-Daten in Mehrbenutzerumgebungen sind spezielle Werkzeugenötig. Allerdings berücksichtigen die derzeit auf dem Markt verfügbaren Editoren nurunzureichend die Anforderungen kooperativer Arbeitsumgebungen. In dieser Arbeit wirddaher ein transaktionsbasierter XML-Editor vorgestellt; der diese Anforderungen erfüllt. Er istfür den Einsatz in eng gekoppelten Systemumgebungen; auch Workgroups genannt;konzipiert. Der Editor erlaubt ein intuitives Bearbeiten von XML-Daten und machtAnderungen eines Nutzers an den Daten anderen Nutzern sehr früh zugänglich. Weiterhinermöglicht er durch dein Einsatz eines intelligenten Sperrprotokolls einen hochgradig …,BTW,2009,2
GeoSemOLAP: Geospatial OLAP on the Semantic Web Made Easy,Nurefsan Gür; Jacob Nielsen; Katja Hose; Torben Bach Pedersen,Abstract The proliferation of spatial data and the publication of multidimensional (MD) dataon the Semantic Web (SW) has led to new opportunities for On-Line Analytical Processing(SOLAP) over spatial data using SPARQL. However; formulating such queries results inverbose statements and can easily become very difficult for inexperienced users. Hence; wehave developed GeoSemOLAP to enable users without detailed knowledge of RDF andSPARQL to query the SW with SOLAP. GeoSemOLAP generates SPARQL queries based onhigh-level SOLAP operators and allows the user to interactively formulate queries using agraphical interface with interactive maps.,Proceedings of the 26th International Conference on World Wide Web Companion,2017,1
QBOAirbase: The European Air Quality Database as an RDF Cube,Luis Galárraga; Kim Ahlstrøm; Katja Hose,Abstract. AirBase is the European air quality dataset maintained by the EEA (EnvironmentalEuropean Agency). The dataset is publicly available on the Web; and contains air qualitymonitoring data for 40 European countries. The multidimensional nature of the data makes ita good fit for OLAP (Online Analytical Processing) systems. These systems are optimized forcomplex queries with grouping on multidimensional data; which are common in dataanalysis. Moreover; by linking the data to existing knowledge bases in the Semantic Web;we can magnify its value; allowing for more sophisticated data analytics. In this paper weintroduce and describe QBAirbase; a multidimensional provenanceaugmented version ofthe Airbase dataset. QBOAirbase represents air pollution information as an RDF data cube;which has been linked to the YAGO and DBpedia knowledge bases.,ISWC; Posters & Demonstrations,2017,1
FrameBase: Enabling integration of heterogeneous knowledge,Jacobo Rouces; Gerard de Melo; Katja Hose,Abstract Large-scale knowledge graphs such as those in the Linked Open Data cloud aretypically stored as subject-predicate-object triples. However; many facts about the worldinvolve more than two entities. While n-ary relations can be converted to triples in a numberof ways; unfortunately; the structurally different choices made in different knowledge sourcessignificantly impede our ability to connect them. They also increase semantic heterogeneity;making it impossible to query the data concisely and without prior knowledge of eachindividual source. This article presents FrameBase; a wide-coverage knowledge baseschema that uses linguistic frames to represent and query n-ary relations from otherknowledge bases; providing multiple levels of granularity connected via logical entailment.Overall; this provides a means for semantic integration from heterogeneous sources …,Semantic Web,2017,1
Towards Answering Provenance-Enabled SPARQL Queries Over RDF Data Cubes,Kim Ahlstrøm; Katja Hose; Torben Bach Pedersen,Abstract The SPARQL 1.1 standard has made it possible to formulate analytical queries inSPARQL. While some approaches have become available for processing analytical querieson RDF data cubes; little attention has been paid to answering provenance-enabled queriesover such data. Yet; considering provenance is a prerequisite to being able to validate if aquery result is trustworthy. The main challenge for existing triple stores is the wayprovenance can be encoded in standard triple stores based on context values (namedgraphs). Hence; in this paper we analyze the suitability of existing triple stores for answeringprovenance-enabled queries on RDF data cubes; identify their shortcomings; and proposean index to handle the high number of context values that provenance encoding typicallyentails. Our experimental results using the Star Schema Benchmark show the feasibility …,Joint International Semantic Technology Conference,2016,1
Distributed database systems,Elvis C Foster; Shripad Godbole,As wonderful as database systems are; they would not be delivering on their true potential ifthey could not be networked in a distributed environment. This chapter discusses distributeddatabase systems under the following subheadings … Each site is a database system in itsown right … The sites work together (if necessary) so that a user at any given site can accessdata at any other site as if the data resides on the host (user's) site … From the definition; theuser is given the notion of virtual database systems consisting of data that may reside anywherein the network … The sites may be distributed over a wide geographical area; or in a localarea/building. A distributed database system can therefore be a LAN (local area network); a MAN(metropolitan area network); or a WAN (wide area network) … Distributed database systemsare not to be confused with remote access systems; sometimes called distributive …,*,2016,1
Interactive Information Extraction based on Distributed Data Management for German Grid Projects,René Jäkel; Steffen Metzger; Jason Milad Daivandy; Katja Hose; Denis Hünich; Ralf Schenkel; Bernd Schuller,In the past years; grid computing [1] has evolved for many different disciplines to solve notonly computationally intense tasks; but also to provide resources for data management orthe provision of services to steer applications; manage users; or create complex workflows.A strong advantage of grid computing is the ability to maintain distributed andheterogeneous resources using a middleware layer to distribute computational jobs ordelegate user access to data storage space. This provides a unique way to handle datatransparently to the user community not knowing the technical details of the underlyinginfrastructure. This approach works well for a rather uniform and straightforward usercommunity with similar needs and requirements. The picture changes for scientificapproaches where collaborative work among partners from different domains is desired …,EGI Community Forum 2012/EMI Second Technical Conference,2012,1
Incremental Mining for Facility Management,Katja Hose; Marcel Karnstedt; Daniel Klan Kai-uwe,Abstract Modern buildings are equipped with high-tech systems that take care of severalfundamental aspects; eg; air-conditioning; heating and water supply. The requirementsposed on facility management by such buildings are challenging. Modern techniquesimplement adaptive control systems to achieve this; in which decisions are preferably basedon the results of (multiple correlated) mining tasks on recently gathered sensor data. In thiswork; we discuss the general relationship between such control systems and the underlyingmining tasks. We exemplary choose change detection in the context of pattern analysis as arepresentative; because this mining task involves general requirements known from streamprocessing like the need for incremental algorithms; but also poses specific challenges likein-time detection. We present three concrete approaches for this and an according …,*,2007,1
The Semantic Web: ESWC 2017 Satellite Events: ESWC 2017 Satellite Events; Portorož; Slovenia; May 28–June 1; 2017; Revised Selected Papers,Eva Blomqvist; Katja Hose; Heiko Paulheim; Agnieszka Ławrynowicz; Fabio Ciravegna; Olaf Hartig,This book constitutes the thoroughly refereed post-conference proceedings of the SatelliteEvents of the 14th European Conference on the Semantic Web; ESWC 2017; held inPortoroz; Slovenia; in May/June2017. The volume contains 8 poster and 24 demonstrationpapers; selected from 105 submissions. Additionally; this book includes a selection of 13best workshop papers. The papers cover various aspects of the semantic web. Thechapter'Scholia; Scientometrics and Wikidata'is available open access under a CC BY 4.0license via link. springer. com.,*,2017,*
Special issue on DOLAP 2015: Evolving data warehousing and OLAP cubes to big data analytics,Carlos Ordonez; Carlos Garcia-Alvarado; Il-Yeol Song; Francesco Cafagna; Michael H Böhlen; Annelies Bracher; Rudra Pratap Deb Nath; Katja Hose; Torben Bach Pedersen; Oscar Romero; Amine Roukh; Ladjel Bellatreche; Selma Bouarar; Ahcene Boukorca,We welcome the reader to the special issue containing best papers from the ACMInternational Workshop on Data Warehousing and OLAP (DOLAP) 2015. We haverevamped DOLAP to be a research venue for big data analytics; expanding its scope; butmaintaining its high quality and applied focus.,*,2017,*
QBOAirbase: The European Air Quality Database as an RDF Cube,Luis Antonio Galarraga Del Prado; Kim Ahlstrøm Meyn Mathiassen; Katja Hose,{"controller"=>"catalog"; "action"=>"show"; "locale"=>"en"; "id"=>"2394244771 …,International Semantic Web Conference,2017,*
Enabling Completeness-aware Querying in SPARQL,Luis Antonio Galarraga Del Prado; Katja Hose; Simon Razniewski,{"controller"=>"catalog"; "action"=>"show"; "locale"=>"en"; "id"=>"2394244769 …,International Workshop on the Web and Databases,2017,*
A Frame-Based Approach for Connecting Heterogeneous Knowledge,Jacobo Rouces; Gerard de Melo; Katja Hose,*,Semantic Web–Interoperability; Usability; Applicability,2017,*
Skyline Queries,Katja Hose,Abstract Many applications face the problem that users are overwhelmed by the largeamount of available data. In some cases an objective ranking function can be used to orderdata items by their relevance–similar to the top 10 results displayed by a Web searchengine. Other applications; however; aim at considering more diverse preferences andmultiple criteria to help users find good results. Such applications can benefit from skylinequeries. The best known example use case for a skyline query is a hotel booking scenariowhere users are looking for hotels. Assume many hotels are available and the user wants tofind one based on two criteria: distance to the beach and price per night. Further assumethat the user is unable to say which of these criteria is more important. So; we need to lookfor hotels representing a good combination of both criteria. The skyline consists of all …,Datenbank-Spektrum,2016,*
Complex Schema Mapping and Linking Data: Beyond Binary Predicates,Jacobo Rouces Gonzalez; Gerard de Melo; Katja Hose,{"controller"=>"catalog"; "action"=>"show"; "locale"=>"en"; "id"=>"2350130818 …,International Workshop on Linked Data on the Web (LDOW2016),2016,*
Rule mining with AMIE+ Fouille de règles avec AMIE,Luis Galárraga; Christina Teflioudi; Katja Hose; Fabian M Suchanek,Résumé Aujourd'hui; le progres dans le domaine de l'extraction d'informations a conduita lamise en place de grandes bases de connaissances (BdC). Ces dernieres contiennent desfaits du monde réel dans un format qui peut être compris par l'ordinateur. Les techniques dela programmation logique inductive (PLI) peuvent être utilisées pour trouver des réglesd'association dans ces BdC; comme par exemple la regle suivante:“Si deux personnes sontmariées; elles vivent (généralement) dans la même ville”. En dépit de la maturité de PLI; ladécouverte de regles dans les BdC reste difficile car elles sont construites sur la base de la“Open World Assumption”. En d'autres termes; toute information qui est absente de la BdCne peut pas être utilisée comme contre-exemple. Avec notre approche AMIE [16]; nousavons montré comment des régles peuvent être découvertes de maniére efficace dans …,*,2015,*
Rule mining with AMIE+,Luis Galárraga; Christina Teflioudi; Katja Hose; Fabian M Suchanek,{"controller"=>"catalog"; "action"=>"show"; "locale"=>"en"; "id"=>"2281346502 …,*,2015,*
Linked Data Management,Ralf Schenkel; Katja Hose; Andreas Harth,*,*,2014,*
Index-Based Source Selection and Optimization.,Jürgen Umbrich; Marcel Karnstedt; Axel Polleres; Kai-Uwe Sattler,*,*,2014,*
P2P-Based Query Processing over Linked Data.,Marcel Karnstedt; Kai-Uwe Sattler; Manfred Hauswirth,*,*,2014,*
Mapping Relational Databases to Linked Data.,Juan F Sequeda; Daniel P Miranker,*,*,2014,*
Federated Query Processing over Linked Data.,Peter Haase; Katja Hose; Ralf Schenkel; Michael Schmidt; Andreas Schwarte,*,*,2014,*
AMIE,Luis Galárraga; Christina Teflioudi; Katja Hose; Fabian M Suchanek,*,Proceedings of the 22nd International World Wide Web Conference; Www'13,2013,*
Partout: A Distributed Approach Towards Scalable RDF Processing,Luis Galárraga; Katja Hose; Ralf Schenkel,Autor: Galárraga; Luis et al.; Genre: Hochschulschrift; Im Druck veröffentlicht: 2012; Titel:Partout: A Distributed Approach Towards Scalable RDF Processing.,*,2012,*
MIKE-Managing Interactive Knowlegde Extraction,Michael Stoll; Ralf Schenkel; Katja Hose,Autor: Stoll; Michael et al.; Genre: Hochschulschrift; Im Druck veröffentlicht: 2012;Titel: MIKE - Managing Interactive Knowlegde Extraction.,*,2012,*
Design and Implementation of a Transparent Cache Layer for RDF Database Systems,Adrian Villwock; Katja Hose; Ralf Schenkel,Autor: Villwock; Adrian et al.; Genre: Hochschulschrift; Im Druck veröffentlicht: 2012; Titel: Designand Implementation of a Transparent Cache Layer for RDF Database Systems.,*,2012,*
Faceted Known-Item Search in RDF Data,Ajaz Basha Shaik; Ralf Schenkel; Katja Hose,Autor: Shaik; Ajaz Basha et al.; Genre: Hochschulschrift; Im Druck veröffentlicht:2012; Titel: Faceted Known-Item Search in RDF Data.,*,2012,*
Bericht zur Herbstschule Information Retrieval 2010,Steffen Metzger; Katja Hose; Andreas Broschart,So bot sich bereits der Anreisetag; Sonntag; der 26.09.; der mit einem gemeinsamenAbendessen begann; zum gegenseitigen Kennenlernen an. Neben der gemeinsamenExkursion in die historische Altstadt Triers bot Schloss Dagstuhl ausreichend Möglichkeitenzur geselligen Abendgestaltung und für weitere Aktivitäten. Die Lage lud zudem dazu ein;gelegentlich frische Luft zu schnappen; so ergab es sich zum Beispiel; dass einigeGeocaches in der Nähe gesucht und gefunden wurden. Bis zum Abreisetag; dem 01.10.;konnte sich so eine familiäre Atmosphäre entwickeln.,Datenbank-Spektrum,2011,*
of Proceedings: The Semanic Web: Research and Applications: 8th Extended Semantic Web Conference; ESWC 2011,Andreas Schwarte; Peter Haase; Katja Hose; Ralf Schenkel; Michael Schmidt,Abstract/Description: Driven by the success of the Linked Open Data initiative today'sSemantic Web is best characterized as a Web of interlinked datasets. Hand in hand with thisstructure new challenges to query processing are arising. Especially queries for which morethan one data source can contribute results require advanced optimization and evaluationapproaches; the major challenge lying in the nature of distribution: Heterogenous datasources have to be integrated into a federation to globally appear as a single repository. Onthe query level; though; techniques have to be developed to meet the requirements ofefficient query computation in the distributed setting. We present FedX; a project whichextends the Sesame Framework with a federation layer that enables ef-ficient queryprocessing on distributed Linked Open Data sources. We discuss key insights to its …,*,2011,*
of Proceedings: LWA 2011: Technical Report; Report of the symposium" Lernen; Wissen; Adaptivität 2011" of the GI special interest groups KDML; IR and WM,Hassan Issa; Katja Hose; Steffen Metzger; Ralf Schenkel,Document title: Advances Towards Semantic Plagiarism Detection Authors: Issa; Hassan; Hose;Katja; Metzger; Steffen; Schenkel; Ralf Document type: Conference-Paper Language: EnglishAudience: Experts Only External Publication Status: published Title of Proceedings: LWA 2011 :Technical Report ; Report of the symposium "Lernen; Wissen; Adaptivität 2011" of the GI specialinterest groups KDML; IR and WM Place of Conference/Meeting: Magdeburg; Germany FullName(s) of Editor(s) of Proceedings: Spiliopoulou; Myra; Nürnberger; Andreas; Schult; RenePlace of Publication: Magdeburg Last Change of the Resource (YYYY-MM-DD): 2012-03-13(Start) Date of Conference/Meeting (YYYY-MM-DD): 2011-09-28 Date of Publication(YYYY-MM-DD): 2011 End Date of Conference/Meeting (YYYY-MM-DD): 2011-09-30 IntendedEducational Use: No Publisher: Otto von Guericke Universität …,*,2011,*
Sharing Knowledge between Independent Grid Communities,Katja Hose; Steffen Metzger; Ralf Schenkel,Abstract: In recent years; grid-based approaches for processing scientific data becamepopular in various fields of research. A multitude of communities has emerged that all benefitfrom the processing and storage power the grid offers to them. So far there has not yet beenmuch collaboration between these independent communities. But applying semantictechnologies to create knowledge bases; sharing this knowledge; and providing access todata maintained by a community; allows to exploit a synergy effect that all communities canbenefit from. In this paper; we propose a framework that applies information extraction togenerate abstract knowledge from source documents to be shared among participatingcommunities. The framework also enables users to search for documents based onkeywords or metadata as well as to search for extracted knowledge. This search is not …,6th International Workshop on Applications of Semantic Technologies,2011,*
Interaktive Wissensextraktion und Wissenssuche.,Michael Stoll; Katja Hose; Steffen Metzger; Ralf Schenkel,Abstract Die hochwertige Annotation von Entitäten und ihren Beziehungen ist ein Schlüsselzur Erschließung großer Textmengen; erfordert aber eine Kombination von effizientenmaschinellen Verfahren und manueller Überprüfung. Darüber hinaus ist auch eineausdrucksstarke Suche; die über eine reine Schlüsselwortsuche hinausgeht; vonentscheidender Bedeutung. Dieser Artikel stellt die Knowledge Workbench vor; dieautomatische Techniken zur Entitätenerkennung und Informationsextraktion zur Verfügungstellt. Durch Interaktion mit dem Benutzer werden die Verfahren dabei inkrementell für dasjeweilige Anwendungsgebiet optimiert. Darüber hinaus erlaubt sie eine strukturierte Suchevon Texten auf Basis extrahierter Informationen.,LWA,2011,*
Processing Approximate Queries in PDMS,Kai-Uwe Sattler; Katja Hose,*,*,2006,*
Top-N Anfrageverarbeitung in PDMS: Anforderungen und Lösungswege.,Katja Hose,Zusammenfassung Da P2P-Netzwerke gewöhnlich aus einer großen Anzahl von Peersbestehen und somit große Datenmengen verfügbar sind; ist es oft unnötig wenn nicht sogarunmöglich; dem Nutzer ein vollständiges Ergebnis seiner Anfrage durch Einbeziehung allerteilnehmenden Peers zu präsentieren. Vielmehr muss in P2P-Systemen begründet durchderen Charakteristik zumeist auf best-effort Lösungen zurückgegriffen werden. Ein Beispieldafür stellen Top-N-Anfragen dar. Als Ergebnis wird ein gemäß der Ähnlichkeit zurgestellten Anfrage sortiertes Ergebnis erwartet; das die „besten “zum gegebenen Zeitpunktim Netzwerk vorhandenen Datenwerte widerspiegelt; ohne dabei eine kostenintensiveBerechnung vorauszusetzen. Die dabei gestellten Anforderungen an dieAnfrageverarbeitung umfassen zumeist eine möglichst geringe Bearbeitungsdauer sowie …,Grundlagen von Datenbanken,2005,*
Katja. Hose@ stud. tu-ilmenau. de Dezember 2003 Prof. Dr.-Ing. habil. Kai-Uwe Sattler,Katja Hose,*,*,2003,*
Answering Provenance-Aware Queries on RDF Data Cubes under Memory Budgets,Luis Galárraga; Kim Ahlstrøm; Katja Hose; Torben Bach Pedersen,Abstract. The steadily-growing popularity of semantic data on the Web and the support foraggregation queries in SPARQL 1.1 have propelled the interest in Online AnalyticalProcessing (OLAP) and multidimensional data (cubes) in RDF. Query processing in suchsettings is challenging because SPARQL OLAP queries usually contain many triple patternswith grouping and aggregation. Moreover; one important factor of query answering on Webdata is its provenance; ie; metadata about its origin. Some applications in data analytics andaccess control require to augment the data with provenance metadata and run queries thatimpose constraints on this provenance. This task is called provenance-aware queryanswering. In this paper; we investigate the benefit of caching some parts of an RDF cubeaugmented with provenance information when answering provenanceaware SPARQL …,*,*,*
3.14 Linked Open Data; Federations; and beyond,Katja Hose,In the past couple of years numerous approaches and techniques for query processing infederations of SPARQL endpoints and over Linked Open Data have been proposed by theresearch community. These techniques cover various subproblems; such as indexing; joinprocessing; reasoning; query optimization; knowledge extraction; quality and completenessof knowledge bases as well as data integration; semantic data warehouses; and many more.As discussed in this talk; we are still far from having reached a point where we can concludethat we have found sufficiently good solutions for query processing in this setup. Apart fromfinding an overall solution that combines solutions to all these subproblems [1; 2]; we areeven still missing solutions for seemingly small problems; such as encoding metadata.,Federated Semantic Data Management,*,*
Addressing structural and linguistic heterogeneity in the Web,Jacobo Rouces; Gerard de Melo; Katja Hose,Abstract An increasing number of structured knowledge bases have become available onthe Web; enabling many new forms of analyses and applications. However; the fact that thedata is being published by different parties with different vocabularies and ontologies meansthat there is a high degree of heterogeneity and no common schema. At the same time; theabundance of different human languages across unstructured data presents a similarproblem; because most text mining tools only cater to the English language. This paperpresents solutions for these two kinds of heterogeneity. It introduces Klint; a Web-basedsystem that automatically creates mappings to transform knowledge from heterogeneoussources into FrameBase; which is a broad linked data schema that enables therepresentation of a wide range of knowledge. With Klint; a user can review and edit the …,AI Communications,*,*
Linked Data Management: Principles and Techniques,Andreas Harth; Katja Hose; Ralf Schenkel,1.1 Observations modeled as streaming timestamped tuples.... 6 1.2 Composite events:precedence; causality and aggregation... 7 1.3 Complex event generation model................. 71.4 Windows w1 and w2 over a data stream............. 9 1.5 Ontology-based sensor queryrewriting architecture [20].... 19 1.6 Mapping from the wan7 sensor to a SSNObservationValue.. 20 1.7 Mapping from the wan7 sensor to a SSN Observation..... 22 1.8Algebra expression after query rewriting............. 22,*,*,*
Umschreiben und Bearbeiten von Anfragen in PDMS,Katja Hose; Jana Quasebarth,*,*,*,*
An Extended Transaction Model for Cooperative Authoring of XML Documents,Francis Gropengießer; Katja Hose; Kai-Uwe Sattler,Abstract In many application scenarios; for example in design or media productionprocesses; several authors have to work cooperatively on the same project andconsequently on the same data. A frequently used data format in this context is XML. Toenable cooperative authoring of shared XML graph structures; several requirements have tobe fulfilled; eg; early visibility of updates; multi-directional information flow; and processingdata in parallel. Most transaction models proposed in the literature are hardly applicable inthis context. In this paper; we propose a novel transaction model based on multi-leveltransactions and dynamic actions that meets these requirements. We describe thetransaction model as well as its formal properties and discuss issues such assynchronization and logging.,*,*,*
Eine inkrementelle Anfragestrategie zur dynamischen und robusten Anfrageverarbeitung in schemabasierten P2P-Systemen,Katja Hose,*,*,*,*
