Objectrank: Authority-based keyword search in databases,Andrey Balmin; Vagelis Hristidis; Yannis Papakonstantinou,Abstract The ObjectRank system applies authority-based ranking to keyword search indatabases modeled as labeled graphs. Conceptually; authority originates at the nodes(objects) containing the keywords and flows to objects according to their semanticconnections. Each node is ranked according to its authority with respect to the particularkeywords. One can adjust the weight of global importance; the weight of each keyword of thequery; the importance of a result actually containing the keywords versus being referencedby nodes containing them; and the volume of authority flow via each type of semanticconnection. Novel performance challenges and opportunities are addressed. First; schemasimpose constraints on the graph; which are exploited for performance purposes. Second; inorder to address the issue of authority ranking with respect to the given keywords (as …,Proceedings of the Thirtieth international conference on Very large data bases-Volume 30,2004,607
Keyword proximity search on XML graphs,Vagelis Hristidis; Yannis Papakonstantinou; Andrey Balmin,XKeyword provides efficient keyword proximity queries on large XML graph databases. Aquery is simply a list of keywords and does not require any schema or query languageknowledge for its formulation. XKeyword is built on a relational database and; hence; canaccommodate very large graphs. Query evaluation is optimized by using the graph'sschema. In particular; XKeyword consists of two stages. In the preprocessing stage a set ofkeyword indices are built along with indexed path relations that describe particular patternsof paths in the graph. In the query processing stage plans are developed that use a nearoptimal set of path relations to efficiently locate the keyword query results. The results arepresented graphically using the novel idea of interactive result graphs; which are populatedon-demand according to the user's navigation and allow efficient information discovery …,Data Engineering; 2003. Proceedings. 19th International Conference on,2003,354
Jaql: A scripting language for large scale semistructured data analysis,Kevin S Beyer; Vuk Ercegovac; Rainer Gemulla; Andrey Balmin; Mohamed Eltabakh; Carl-Christian Kanne; Fatma Ozcan; Eugene J Shekita,ABSTRACT This paper describes Jaql; a declarative scripting language for analyzing largesemistructured datasets in parallel using Hadoop's MapReduce framework. Jaql is currentlyused in IBM's InfoS-phere BigInsights [5] and Cognos Consumer Insight [9] products. Jaql'sdesign features are:(1) a flexible data model;(2) reusability;(3) varying levels of abstraction;and (4) scalability. Jaql's data model is inspired by JSON and can be used to representdatasets that vary from flat; relational tables to collections of semistructured documents. AJaql script can start without any schema and evolve over time from a partial to a rigidschema. Reusability is provided through the use of higher-order functions and by packagingrelated functions into modules. Most Jaql scripts work at a high level of abstraction forconcise specification of logical operations (eg; join); but Jaql's notion of physical …,Proceedings of VLDB conference,2011,221
A framework for using materialized XPath views in XML query processing,Andrey Balmin; Fatma Özcan; Kevin S Beyer; Roberta J Cochrane; Hamid Pirahesh,Abstract XML languages; such as XQuery; XSLT and SQL/XML; employ XPath as the searchand extraction language. XPath expressions often define complicated navigation; resultingin expensive query processing; especially when executed over large collections ofdocuments. In this paper; we propose a framework for exploiting materialized XPath views toexpedite processing of XML queries. We explore a class of materialized XPath views; whichmay contain XML fragments; typed data values; full paths; node references or anycombination thereof. We develop an XPath matching algorithm to determine when suchviews can be used to answer a user query containing XPath expressions. We use the matchinformation to identify the portion of an XPath expression in the user query which is notcovered by the XPath view. Finally; we construct; possibly multiple; compensation …,Proceedings of the Thirtieth international conference on Very large data bases-Volume 30,2004,205
From think like a vertex to think like a graph,Yuanyuan Tian; Andrey Balmin; Severin Andreas Corsten; Shirish Tatikonda; John McPherson,Abstract To meet the challenge of processing rapidly growing graph and network datacreated by modern applications; a number of distributed graph processing systems haveemerged; such as Pregel and GraphLab. All these systems divide input graphs intopartitions; and employ a" think like a vertex" programming model to support iterative graphcomputation. This vertex-centric model is easy to program and has been proved useful formany graph algorithms. However; this model hides the partitioning information from theusers; thus prevents many algorithm-specific optimizations. This often results in longerexecution time due to excessive network messages (eg in Pregel) or heavy schedulingoverhead to ensure data consistency (eg in GraphLab). To address this limitation; wepropose a new" think like a graph" programming paradigm. Under this graph-centric …,Proceedings of the VLDB Endowment,2013,193
Flex: A slot allocation scheduling optimizer for mapreduce workloads,Joel Wolf; Deepak Rajan; Kirsten Hildrum; Rohit Khandekar; Vibhore Kumar; Sujay Parekh; Kun-Lung Wu,Abstract Originally; MapReduce implementations such as Hadoop employed First In FirstOut (fifo) scheduling; but such simple schemes cause job starvation. The Hadoop FairScheduler (hfs) is a slot-based MapReduce scheme designed to ensure a degree of fairnessamong the jobs; by guaranteeing each job at least some minimum number of allocated slots.Our prime contribution in this paper is a different; flexible scheduling allocation scheme;known as flex. Our goal is to optimize any of a variety of standard scheduling theory metrics(response time; stretch; makespan and Service Level Agreements (slas); among others)while ensuring the same minimum job slot guarantees as in hfs; and maximum job slotguarantees as well. The flex allocation scheduler can be regarded as an add-on module thatworks synergistically with hfs. We describe the mathematical basis for flex; and compare it …,Proceedings of the ACM/IFIP/USENIX 11th International Conference on Middleware,2010,161
XPath containment for index and materialized view matching,*,A method for using pre-computed information stored in auxiliary structures to speed upprocessing of expensive queries on hierarchical documents such as XML documents beingqueried using XPath. The invention defines a taxonomy of such structures such as indexesand materialized views for storing pre-computed XPath results (PXRs); determines whatportion of the query can be evaluated by the structures; and computes the compensation forthe results generated by the structures. The invention detects all structures applicable to thequery and rewrites the query to use such structures; speeding up the performance of thequeries. The invention identifies the matching structures by detecting containment mappingsbetween XPath expressions in the query and the structure. The invention also includes anew representation for XPath expressions that is rich enough to express all features of …,*,2008,121
Incremental validation of XML documents,Andrey Balmin; Yannis Papakonstantinou; Victor Vianu,Abstract We investigate the incremental validation of XML documents with respect to DTDs;specialized DTDs; and XML Schemas; under updates consisting of element tag renamings;insertions; and deletions. DTDs are modeled as extended context-free grammars."Specialized DTDs" allow the decoupling of element types from element tags. XML Schemasare abstracted as specialized DTDs with limitations on the type assignment. For DTDs andXML Schemas; we exhibit an O (m log n) incremental validation algorithm using an auxiliarystructure of size O (n); where n is the size of the document and m the number of updates.The algorithm does not handle the incremental validation of XML Schema wrt renaming ofinternal nodes; which is handled by the specialized DTDs incremental validation algorithm.For specialized DTDs; we provide an O (m log 2 n) incremental algorithm; again using an …,ACM Transactions on Database Systems (TODS),2004,107
Hypothetical queries in an olap environment,Andrey Balmin; Thanos Papadimitriou; Yannis Papakonstantinou,Abstract Analysts and decision makers use what if analysis to assess the effects of hypothetical scenarios. What if analysis is currently supported by spreadsheets and ad hoc OLAPtools. Unfortunately; the former lack seam less integration with the data and the lat ter lackflexibility and performance appropri ate for OLAP applications. To tackle these problems wedeveloped the Sesame system; which models an hypothetical scenario as a list ofhypothetical modifications on the ware house views and fact data. We provide formalscenario syntax and semantics; which extend view update semantics for accomodating thespecial requirements of OLAP. We focus on query algebra operators suitable for perform ingspreadsheet style computations. Then we present SesameVs optimizer and its corner stonesubstitution and rewriting mechanisms. Substitution enables lazy evaluation of the hy …,VLDB,2000,82
Storing and querying XML data using denormalized relational databases,Andrey Balmin; Yannis Papakonstantinou,Abstract. XML database systems emerge as a result of the acceptance of the XML datamodel. Recent works have followed the promising approach of building XML databasemanagement systems on underlying RDBMS's. Achieving query processing performancereduces to two questions:(i) How should the XML data be decomposed into data that arestored in the RDBMS?(ii) How should the XML query be translated into an efficient plan thatsends one or more SQL queries to the underlying RDBMS and combines the data into theXML result? We provide a formal framework for XML Schema-driven decompositions; whichencompasses the decompositions proposed in prior work and extends them withdecompositions that employ denormalized tables and binary-coded XML fragments. Weprovide corresponding query processing algorithms that translate the XML query …,The VLDB Journal,2005,65
Adaptive MapReduce using situation-aware mappers,Rares Vernica; Andrey Balmin; Kevin S Beyer; Vuk Ercegovac,Abstract We propose new adaptive runtime techniques for MapReduce that improveperformance and simplify job tuning. We implement these techniques by breaking a keyassumption of MapReduce that mappers run in isolation. Instead; our mappers communicatethrough a distributed meta-data store and are aware of the global state of the job. However;we still preserve the fault-tolerance; scalability; and programming API of MapReduce. Weutilize these" situation-aware mappers" to develop a set of techniques that makeMapReduce more dynamic:(a) Adaptive Mappers dynamically take multiple data partitions(splits) to amortize mapper start-up costs;(b) Adaptive Combiners improve local aggregationby maintaining a cache of partial aggregates for the frequent keys;(c) Adaptive Samplingand Partitioning sample the mapper outputs and use the obtained statistics to produce …,Proceedings of the 15th International Conference on Extending Database Technology,2012,63
Searching digital information and databases,*,This application describes methods for searching digital information such as digitaldocuments (eg; web pages) and computer databases; and specific search techniques suchas authority ranking and information retrieval (IR) relevance ranking in keyword searches. Insome implementations; the technique includes analyzing digital information viewed as alabeled graph; including nodes and edges; based on a flow of authority among the nodesalong the edges; the flow of authority being derived at least in part from different authoritytransfer rates assigned to the edges based on edge type schema information. In someimplementations; the system includes an object rank module configured to generate multipleinitial rankings corresponding to multiple query keywords; each of the multiple initialrankings indicating authority of nodes in a graph with respect to each respective query …,*,2010,63
Scalable topic-specific influence analysis on microblogs,Bin Bi; Yuanyuan Tian; Yannis Sismanis; Andrey Balmin; Junghoo Cho,Abstract Social influence analysis on microblog networks; such as Twitter; has been playinga crucial role in online advertising and brand management. While most previous influenceanalysis schemes rely only on the links between users to find key influencers; they omit theimportant text content created by the users. As a result; there is no way to differentiate thesocial influence in different aspects of life (topics). Although a few prior works do supporttopic-specific influence analysis; they either separate the analysis of content from theanalysis of network structure; or assume that content is the only cause of links; which isclearly an inappropriate assumption for microblog networks. To address the limitations of theprevious approaches; we propose a novel Followship-LDA (FLDA) model; which integratesboth content topic discovery and social influence analysis in the same generative process …,Proceedings of the 7th ACM international conference on Web search and data mining,2014,56
Graph search system and method for querying loosely integrated data,*,A system; method and computer program product for executing a query on linked datasources. Embodiments of the invention generate an instance graph expressing relationshipsbetween objects in the linked data sources and receive a query including at least first andsecond search terms. The first search term is then executed on the instance graph and asummary graph is generated using the results of the executing step. A second search term isthen executed on the summary graph.,*,2012,48
Cost-based optimization in DB2 XML,Andrey Balmin; Tom Eliaz; John Hornibrook; Lipyeow Lim; Guy M Lohman; David Simmen; Min Wang; Chun Zhang,DB2 XML is a hybrid database system that combines the relational capabilities of DB2Universal Database™(UDB) with comprehensive native XML support. DB2 XML augmentsDB2® UDB with a native XML store; XML indexes; and query processing capabilities forboth XQuery and SQL/XML that are integrated with those of SQL. This paper presents theextensions made to the DB2 UDB compiler; and especially its cost-based query optimizer; tosupport XQuery and SQL/XML queries; using much of the same infrastructure developed forrelational data queried by SQL. It describes the challenges to the relational infrastructurethat supporting XQuery and SQL/XML poses and provides the rationale for the extensionsthat were made to the three main parts of the optimizer: the plan operators; the cardinalityand cost model; and statistics collection.,IBM Systems Journal,2006,45
-A System for Keyword Proximity Search on XML Databases,Andrey Balmin; Yannis Papakonstantinou; Vagelis Hristidis; Tianqiu Wang; Divesh Srivastava; Nick Koudas,This chapter discusses keyword proximity search on XML database. Keyword proximitysearch is a user-friendly information discovery technique that has been extensively studiedfor text documents. In extending this technique to structured databases; recent works providekeyword proximity search on labeled graphs. A keyword proximity search does not requirethe user to know the structure of the graph; the role of the objects containing the keywords;or the type of the connections between the objects. The user simply submits a list ofkeywords and the system returns the sub-graphs that connect the objects containing thekeywords. XML and its labeled graph/tree abstractions are becoming the data model ofchoice for representing semistructured; self-describing data; and keyword proximity searchis well-suited to XML documents as well.A System for Keyword Proximity Search on XML …,*,2003,45
Adaptive parallel data processing,*,Described herein are methods; systems; apparatuses and products for adaptive paralleldata processing. An aspect provides providing a map phase in which at least one mapfunction is applied in parallel on different partitions of input data at different mappers in aparallel data processing system; providing a communication channel between mappersusing a distributed meta-data store; wherein said map phase comprises mapper dataprocessing adapted responsive to communication with said distributed meta-data store; andproviding data accessible by at least one reduce phase node in which at least one reducefunction is applied. Other embodiments are disclosed.,*,2015,40
Authority-based keyword queries in databases using ObjectRank,Andrey Balmin; Vagelis Hristidis; Yannis Papakonstantinou,*,VLDB; Toronto,2004,40
System for querying markup language data stored in a relational database according to markup language schema,*,A data processing system receives data in a first format utilizing a markup language such aseXtensible Markup Language (XML); and stores the data in a different; relational databaseformat involving multiple tables and columns; etc. The system translates subsequent queryinput expressed in the first format to prepare representative query instructions in SQL oranother query language compatible with relational data; and thereafter executes theprepared instructions upon data in the relational database. The system outputs results of thequery in format dictated by the query input.,*,2006,36
Same queries; different data: Can we predict runtime performance?,Adrian Daniel Popescu; Vuk Ercegovac; Andrey Balmin; Miguel Branco; Anastasia Ailamaki,We consider MapReduce workloads that are produced by analytics applications. In contrastto ad hoc query workloads; analytics applications are comprised of fixed data flows that arerun over newly arriving data sets or on different portions of an existing data set. Examples ofsuch workloads include document analysis/indexing; social media analytics; and ETL(Extract Transform Load). Motivated by these workloads; we propose a technique thatpredicts the runtime performance for a fixed set of queries running over varying input datasets. Our prediction technique splits each query into several segments where eachsegment's performance is estimated using machine learning models. These per-segmentestimates are plugged into a global analytical model to predict the overall query runtime. Ourapproach uses minimal statistics about the input data sets (eg; tuple size; cardinality) …,Data Engineering Workshops (ICDEW); 2012 IEEE 28th International Conference on,2012,30
System and Method for Optimizing Query Access to a Database Comprising Hierarchically-Organized Data,*,An cost based optimizer optimizes access to at least a portion of hierarchically-organizeddocuments; such as those formatted using eXtensible Markup Language (XML); byestimating a number of results produced by the access of the hierarchically-organizeddocuments. Estimating the number of results comprises computing the cardinality of eachoperator executing query language expressions and further computing a sequence size ofsequences of hierarchically-organized nodes produced by the query language expressions.Access to the hierarchically-organized documents is optimized using the structure of thequery expression and/or path statistics involving the hierarchically-organized data. Thecardinality and the sequence size are used to calculate a cost estimation for execution ofalternate query execution plans. Based on the cost estimation; an optimal query …,*,2008,30
Between matching,*,A query of at least one mark-up language document has a path expression comprising aconjunction; a first filter and a second filter. The first filter has a first probe. The second filterhas a second probe. The first and second filters form a between filter having start and stopvalues specified by the first and second probes. A plan to process the query is generatedbased on; at least in part; a range defined by the start and stop values. An index of mark-uplanguage documents is defined by another path expression; the index comprises values ofmark-up language documents that satisfy the other path expression; the values are keyvalues of the index. The plan is to perform a single scan of the key values from the startvalue to the stop value to identify at least one key value that satisfies the between filter.,*,2011,28
PREDIcT: towards predicting the runtime of large scale iterative analytics,Adrian Daniel Popescu; Andrey Balmin; Vuk Ercegovac; Anastasia Ailamaki,Abstract Machine learning algorithms are widely used today for analytical tasks such as datacleaning; data categorization; or data filtering. At the same time; the rise of social mediamotivates recent uptake in large scale graph processing. Both categories of algorithms aredominated by iterative subtasks; ie; processing steps which are executed repetitively until aconvergence condition is met. Optimizing cluster resource allocations among multipleworkloads of iterative algorithms motivates the need for estimating their runtime; which inturn requires: i) predicting the number of iterations; and ii) predicting the processing time ofeach iteration. As both parameters depend on the characteristics of the dataset and on theconvergence function; estimating their values before execution is difficult. This paperproposes PREDIcT; an experimental methodology for predicting the runtime of iterative …,Proceedings of the VLDB Endowment,2013,23
Optimization of extensible markup language path language (XPATH) expressions in a database management system configured to accept extensible markup langu...,*,An apparatus; system; and method are disclosed for optimization of XPath expressions in adatabase management system configured to accept XML queries. Operations of the methodinclude receiving an XQuery representation and partitioning XPath expressions within theXQuery representation into a plurality of XPath expression clusters. The XPath expressionclusters may comprise one or more XPath expressions and those in each cluster mayoperate on a common document. Furthermore; the XPath expressions in each cluster arehierarchically related to each other such that branch nodes of the cluster are executableindependent of nodes in other XPath expression clusters. The method also defines mergingthe one or more XPath expressions into one or more expression trees for each XPathexpression cluster. The method generates one or more query execution plans from the …,*,2011,23
Binrank: Scaling dynamic authority-based search using materialized subgraphs,Heasoo Hwang; Andrey Balmin; Berthold Reinwald; Erik Nijkamp,Dynamic authority-based keyword search algorithms; such as ObjectRank and personalizedPageRank; leverage semantic link information to provide high quality; high recall search indatabases; and the Web. Conceptually; these algorithms require a query-time PageRank-style iterative computation over the full graph. This computation is too expensive for largegraphs; and not feasible at query time. Alternatively; building an index of precomputedresults for some or all keywords involves very expensive preprocessing. We introduceBinRank; a system that approximates ObjectRank results by utilizing a hybrid approachinspired by materialized views in traditional query processing. We materialize a number ofrelatively small subsets of the data graph in such a way that any keyword query can beanswered by running ObjectRank on only one of the subgraphs. BinRank generates the …,IEEE Transactions on Knowledge and Data Engineering,2010,19
On the effectiveness of flexible querying heuristics for XML data,Zografoula Vagena; Latha Colby; Fatma Özcan; Andrey Balmin; Quanzhong Li,Abstract The ability to perform effective XML data retrieval in the absence of schemaknowledge has recently received considerable attention. The majority of relevant proposalsemploys heuristics that identify groups of meaningfully related nodes using informationextracted from the input data. These heuristics are employed to effectively prune the searchspace of all possible node combinations and their popularity is evident by the large numberof such heuristics and the systems that use them. However; a comprehensive study detailingthe relative merits of these heuristics has not been performed thus far. One of the challengesin performing this study is the fact that these techniques have been proposed within differentand not directly comparable contexts. In this paper; we attempt to fill this gap. In particular;we first abstract the common selection problem that is tackled by the relatedness …,International XML Database Symposium,2007,19
Flowflex: Malleable scheduling for flows of mapreduce jobs,Viswanath Nagarajan; Joel Wolf; Andrey Balmin; Kirsten Hildrum,Abstract We introduce FlowFlex; a highly generic and effective scheduler for flows ofMapReduce jobs connected by precedence constraints. Such a flow can result; for example;from a single user-level Pig; Hive or Jaql query. Each flow is associated with an arbitraryfunction describing the cost incurred in completing the flow at a particular time. The overallobjective is to minimize either the total cost (minisum) or the maximum cost (minimax) of theflows. Our contributions are both theoretical and practical. Theoretically; we advance thestate of the art in malleable parallel scheduling with precedence constraints. We employresource augmentation analysis to provide bicriteria approximation algorithms for bothminisum and minimax objective functions. As corollaries; we obtain approximationalgorithms for total weighted completion time (and thus average completion time and …,ACM/IFIP/USENIX International Conference on Distributed Systems Platforms and Open Distributed Processing,2013,18
Emerging trends in the enterprise data analytics: connecting Hadoop and DB2 warehouse,Fatma Özcan; David Hoa; Kevin S Beyer; Andrey Balmin; Chuan Jie Liu; Yu Li,Abstract Enterprises are dealing with ever increasing volumes of data; reaching into thepetabyte scale. With many of our customer engagements; we are observing an emergingtrend: They are using Hadoop-based solutions in conjunction with their data warehouses.They are using Hadoop to deal with the data volume; as well as the lack of strict structure intheir data to conduct various analyses; including but not limited to Web log analysis;sophisticated data mining; machine learning and model building. This first stage of theanalysis is off-line and suitable for Hadoop. But; once their data is summarized or cleansedenough; and their models are built; they are loading the results into a warehouse forinteractive querying and report generation. At this later stage; they leverage the wealth ofbusiness intelligence tools; which they are accustomed to; that exist for warehouses. In …,Proceedings of the 2011 ACM SIGMOD International Conference on Management of data,2011,18
On the path to efficient XML queries,Andrey Balmin; Kevin S Beyer; Fatma Özcan; Matthias Nicola,Abstract XQuery and SQL/XML are powerful new languages for querying XML data.However; they contain a number of stumbling blocks that users need to be aware of to getthe expected results and performance. For example; certain language features make it hardif not impossible to exploit XML indexes. The major database vendors provide XQuery andSQL/XML support in their current or upcoming product releases. In this paper; we identifycommon pitfalls gleaned from the experiences of early adopters of this functionality. Weillustrate these pitfalls through concrete examples; explain the unexpected query behavior;and show alternative formulations of the queries that behave and perform as anticipated. Asresults we provide guidelines for XQuery and SQL/XML users; feedback on the languagestandards; and food for thought for emerging languages and APIs.,Proceedings of the 32nd international conference on Very large data bases,2006,18
Clydesdale: structured data processing on hadoop,Andrey Balmin; Tim Kaldewey; Sandeep Tata,Abstract There have been several recent proposals modifying Hadoop; radically changingthe storage organization or query processing techniques to obtain good performance forstructured data processing. We will showcase Clydesdale; a research prototype forstructured data processing on Hadoop that can achieve dramatic performanceimprovements over existing solutions; without any changes to the underlying MapReduceimplementation. Clydesdale achieves this through a novel synthesis of several techniquesfrom the database literature and carefully adapting them to the Hadoop environment. On thestar schema benchmark; we show that Clydesdale is on average 38x faster than Hive; thedominant approach for structured data processing on Hadoop today. To the best of ourknowledge; Clydesdale is the fastest solution for processing workloads on structured data …,Proceedings of the 2012 ACM SIGMOD International Conference on Management of Data,2012,17
Circumflex: a scheduling optimizer for mapreduce workloads with shared scans,Joel Wolf; Andrey Balmin; Deepak Rajan; Kirsten Hildrum; Rohit Khandekar; Sujay Parekh; Kun-Lung Wu; Rares Vernica,Abstract We consider MapReduce clusters designed to support multiple concurrent jobs;concentrating on environments in which the number of distinct datasets is modest relative tothe number of jobs. Many datasets in such scenarios wind up being scanned by multipleconcurrent Map phase jobs. As has been noticed previously; this scenario provides anopportunity for Map phase jobs to cooperate; sharing the scans of these datasets; and thusreducing the costs of such scans. Our paper has two main contributions. First; we present anovel and highly general method for sharing scans and thus amortizing their costs. Thisconcept; which we call cyclic piggybacking; has a number of advantages over the moretraditional batching scheme described in the literature. Second; we describe a significant butnatural generalization of the recently introduced flex scheduler; for optimizing schedules …,ACM SIGOPS Operating Systems Review,2012,17
Index exploitation,*,Various embodiments of a computer-implemented method; computer program product; anddata processing system are provided that generate an index plan that produces a supersetof data comprising the query result. In some embodiments; a computer-implementedmethod; computer program product; and data processing system produce a maximal-index-satisfiable query tree.,*,2011,16
On the optimization of schedules for MapReduce workloads in the presence of shared scans,Joel Wolf; Andrey Balmin; Deepak Rajan; Kirsten Hildrum; Rohit Khandekar; Sujay Parekh; Kun-Lung Wu; Rares Vernica,Abstract We consider MapReduce clusters designed to support multiple concurrent jobs;concentrating on environments in which the number of distinct datasets is modest relative tothe number of jobs. In such scenarios; many individual datasets are likely to be scannedconcurrently by multiple Map phase jobs. As has been noticed previously; this scenarioprovides an opportunity for Map phase jobs to cooperate; sharing the scans of thesedatasets; and thus reducing the costs of such scans. Our paper has three main contributionsover previous work. First; we present a novel and highly general method for sharing scansand thus amortizing their costs. This concept; which we call cyclic piggybacking; has anumber of advantages over the more traditional batching scheme described in the literature.Second; we notice that the various subjobs generated in this manner can be assumed in …,The VLDB Journal—The International Journal on Very Large Data Bases,2012,15
Grouping and optimization of XPath expressions in DB2® pureXML,Andrey Balmin; Fatma Özcan; Ashutosh Singh; Edison Ting,Abstract Several XML DBMSs support XQuery and/or SQL/XML languages; which are basedon navigational primitives in the form of XPath expressions. Typically; these systems eithermodel each XPath step as a separate query plan operator; or employ holistic approachesthat can evaluate multiple steps of a single XPath expression. There have also beenproposals to execute as many XPath expressions as possible within a single FLWOR blocksimultaneously in a data streaming context. We observe that blindly combining all possibleXPath expressions for concurrent execution can result in significant performancedegradation in a database system. We identify two main problems with this strategy. First;the simple strategy of grouping all XPath expressions on a single document does not alwayswork if the query involves more than one data source or has nested query blocks. Second …,Proceedings of the 2008 ACM SIGMOD international conference on Management of data,2008,15
Scaling dynamic authority-based search using materialized subgraphs,*,According to one embodiment of the present invention; a method for processing a query isprovided. The method includes generating a set of pre-computed materialized sub-graphsfrom a dataset and receiving a search query having one or more search query terms. Aparticular one of the pre-computed materialized sub-graphs is accessed and a dynamicauthority-based keyword search is executed on the particular one of the pre-computedmaterialized sub-graphs. Nodes in the dataset are then retrieved based on the executing;and a response to the search query is provided which includes the retrieved nodes.,*,2015,13
Searching digital information and databases,*,This application describes methods for searching digital information such as digitaldocuments (eg; web pages) and computer databases; and specific search techniques suchas authority ranking and information retrieval (IR) relevance ranking in keyword searches. Insome implementations; the technique includes analyzing digital information viewed as alabeled graph; including nodes and edges; based on a flow of authority among the nodesalong the edges; the flow of authority being derived at least in part from different authoritytransfer rates assigned to the edges based on edge type schema information. In someimplementations; the system includes an object rank module configured to generate multipleinitial rankings corresponding to multiple query keywords; each of the multiple initialrankings indicating authority of nodes in a graph with respect to each respective query …,*,2014,12
Dynamically optimizing queries over large scale data platforms,Konstantinos Karanasos; Andrey Balmin; Marcel Kutsch; Fatma Ozcan; Vuk Ercegovac; Chunyang Xia; Jesse Jackson,Abstract Enterprises are adapting large-scale data processing platforms; such as Hadoop; togain actionable insights from their" big data". Query optimization is still an open challenge inthis environment due to the volume and heterogeneity of data; comprising both structuredand un/semi-structured datasets. Moreover; it has become common practice to pushbusiness logic close to the data via user-defined functions (UDFs); which are usuallyopaque to the optimizer; further complicating cost-based optimization. As a result; classicalrelational query optimization techniques do not fit well in this setting; while at the same time;suboptimal query plans can be disastrous with large datasets. In this paper; we propose newtechniques that take into account UDFs and correlations between relations for optimizingqueries running on large scale clusters. We introduce" pilot runs"; which execute part of …,Proceedings of the 2014 ACM SIGMOD international conference on Management of data,2014,12
An XML index advisor for DB2,Iman Elghandour; Ashraf Aboulnaga; Daniel C Zilio; Fei Chiang; Andrey Balmin; Kevin Beyer; Calisto Zuzarte,Abstract XML database systems are expected to handle increasingly complex queries overincreasingly large and highly structured XML databases. An important problem that needs tobe solved for these systems is how to choose the best set of indexes for a given workload.We have developed an XML Index Advisor that solves this XML index recommendationproblem and is tightly coupled with the query optimizer of the database system. We haveimplemented our XML Index Advisor for DB2. In this demonstration we showcase the newquery optimizer modes that we added to DB2; the index recommendation process; and theeffectiveness of the recommended indexes.,Proceedings of the 2008 ACM SIGMOD international conference on Management of data,2008,11
DBPubs: multidimensional exploration of database publications,Akanksha Baid; Andrey Balmin; Heasoo Hwang; Erik Nijkamp; Jun Rao; Berthold Reinwald; Alkis Simitsis; Yannis Sismanis; Frank van Ham,Abstract DBPubs is a system for effectively analyzing and exploring the content of databasepublications by combining keyword search with OLAP-style aggregations; navigation; andreporting. DBPubs starts with keyword search over the content of publications. Thepublications' metadata such as title; authors; venues; year; and so on; provide traditionalOLAP static dimensions; which are combined with dynamic dimensions discovered from thecontent of the publications in the search result; such as frequent phrases; relevant phrases;and topics. We compute publication ranks based on the link structure between documents;ie; citations; and aggregate them to find seminal papers; discover trends; and rank authors.We deploy an OLAP tool for multidimensional content exploration through traditional OLAProllup-drilldown operations on the static and dynamic dimensions; solutions for multi-cube …,Proceedings of the VLDB Endowment,2008,10
Dynamic interaction graphs with probabilistic edge decay,Wenlei Xie; Yuanyuan Tian; Yannis Sismanis; Andrey Balmin; Peter J Haas,A large scale network of social interactions; such as mentions in Twitter; can often bemodeled as a “dynamic interaction graph” in which new interactions (edges) are continuallyadded over time. Existing systems for extracting timely insights from such graphs are basedon either a cumulative “snapshot” model or a “sliding window” model. The former modeldoes not sufficiently emphasize recent interactions. The latter model abruptly forgets pastinteractions; leading to discontinuities in which; eg; the graph analysis completely ignoreshistorically important influencers who have temporarily gone dormant. We introduce TIDE; adistributed system for analyzing dynamic graphs that employs a new “probabilistic edgedecay”(PED) model. In this model; the graph analysis algorithm of interest is applied at eachtime step to one or more graphs obtained as samples from the current “snapshot” graph …,Data Engineering (ICDE); 2015 IEEE 31st International Conference on,2015,8
Visualizing jobs with shared resources in distributed environments,Wim De Pauw; Joel Wolf; Andrey Balmin,In this paper we describe a visualization system that shows the behavior of jobs in large;distributed computing clusters. The system has been in use for two years; and is sufficientlygeneric to be applied in two quite different domains: a Hadoop MapReduce environmentand the Watson DeepQA DUCC cluster. Scalable and flexible data processing systemstypically run hundreds or more of simultaneous jobs. The creation; termination; expansionand contraction of these jobs can be very dynamic and transient; and it is difficult tounderstand this behavior without showing its evolution over time. While traditionalmonitoring tools typically show either snapshots of the current load balancing or aggregatetrends over time; our new visualization technique shows the behavior of each of the jobsover time in the context of the cluster; and in either a real-time or post-mortem view. Its …,Software Visualization (VISSOFT); 2013 First IEEE Working Conference on,2013,8
Information discovery in loosely integrated data,Heasoo Hwang; Andrey Balmin; Hamid Pirahesh; Berthold Reinwald,Abstract We model heterogeneous data sources with cross references; such as thosecrawled on the (enterprise) web; as a labeled graph with data objects as typed nodes andreferences or links as edges. Given the labeled data graph; we introduce flexible andefficient querying capabilities that go beyond existing capabilities by additionally discoveringmeaningful relationships between objects that satisfy keyword and/or structured query filters.We introduce the relationship search operator that exploits the link structure between dataobjects to rank objects related to the result of a filter. We implement the search operatorusing the ObjectRank [1] algorithm that uses the random surfer model. We study severalalternatives for constructing summary graphs for query results that consist of individual andaggregate nodes that are somehow linked to qualifying result nodes. Some of the …,Proceedings of the 2007 ACM SIGMOD international conference on Management of data,2007,8
Optimization of hypothetical queries in an OLAP environment,Andrey Balmin; Yannis Papakonstantinou; Thanos Papadimitriou,Analysts and decision-makers use what-if analysis to assess the effects of hypotheticalscenarios on historical data. For example an analyst working for a financial company mayconstruct a scenario for a strategy that would involve 10% higher positions in stocks of largehigh-tech companies for the last 3 years. The hypothetical world created by this scenario willbe queried to calculate the returns and volatility of customer portfolios under this scenario.Current On-Line Analytical Processing (OLAP) systems support what-if analysis only byphysically replicating the data warehouse and modifying it according to the scenario. Thisprocess may take many hours; hence limiting the applicability of OLAP. To eliminate thisinefficiency; we built an OLAP toolkit; called Sesame; that exploits the following twoopportunities. First; typically a small part of the modified data is needed to answer the …,Data Engineering; 2000. Proceedings. 16th International Conference on,2000,7
A platform for eXtreme Analytics,Andrey Balmin; Kevin Beyer; Vuk Ercegovac; John McPherson; Fatma Oezcan; Hamid Pirahesh; Eugene Shekita; Yannis Sismanis; Sandeep Tata; Yuanyuan Tian,With the rapid increase in the volume of data that enterprises are producing; enterprises areadopting large-scale data processing platforms such as Hadoop® to store; manage; and rundeep analytics to gain actionable insights from their “big data.” At IBM Research-Almaden;we have been helping enterprise customers build solutions exploiting data-intensiveanalytics. Our deep experience with actual users has led to an extensive understanding ofthe platform requirements needed to support these solutions; and our goal is to provide apowerful analytics platform; which we call eXtreme Analytics Platform (XAP); that can beused to create solutions for customer problems that have not been economically feasible tosolve until now. XAP provides Jaql [ie; JavaScript® Object Notation (JSON) query language;a scripting language to specify data flows; tools; and techniques to optimize the runtime …,IBM Journal of Research and Development,2013,6
Search driven analysis of heterogenous XML data,Andrey Balmin; Latha Colby; Emiran Curtmola; Quanzhong Li; Fatma Ozcan,Abstract: Analytical processing on XML repositories is usually enabled by designingcomplex data transformations that shred the documents into a common data warehousingschema. This can be very time-consuming and costly; especially if the underlying XML datahas a lot of variety in structure; and only a subset of attributes constitutes meaningfuldimensions and facts. Today; there is no tool to explore an XML data set; discoverinteresting attributes; dimensions and facts; and rapidly prototype an OLAP solution. In thispaper; we propose a system; called SEDA that enables users to start with simple keyword-style querying; and interactively refine the query based on result summaries. SEDA thenmaps query results onto a set of known; or newly created; facts and dimensions; and derivesa star schema and its instantiation to be fed into an off-the-shelf OLAP tool; for further …,arXiv preprint arXiv:0909.1773,2009,6
XML index recommendation with tight optimizer coupling,Iman Elghandour; Ashraf Aboulnaga; Daniel C Zilio; Fei Chiang; Andrey Balmin; Kevin Beyer; Calisto Zuzarte,XML database systems are expected to handle increasingly complex queries overincreasingly large and highly structured XML databases. An important problem that needs tobe solved for these systems is how to choose the best set of indexes for a given workload. Inthis paper; we present an XML Index Advisor that solves this XML index recommendationproblem and has the key characteristic of being tightly coupled with the query optimizer. Werely on the optimizer to enumerate index candidates and to estimate the benefit gained frompotential index configurations. We expand the set of candidate indexes obtained from thequery optimizer to include more general indexes that can be useful for queries other thanthose in the training workload. To recommend an index configuration; we introduce two newsearch algorithms. The first algorithm finds the best set of indexes for the specific training …,Data Engineering; 2008. ICDE 2008. IEEE 24th International Conference on,2008,6
Towards predicting the runtime of iterative analytics with predict,Adrian Daniel Popescu; Andrey Balmin; Vuk Ercegovac; Anastasia Ailamaki,ABSTRACT Machine learning algorithms are widely used today for analytical tasks such asdata cleaning; data categorization; or data filtering. At the same time; the rise of social mediamotivates recent uptake in large scale graph processing. Both categories of algorithms aredominated by iterative subtasks; ie; processing steps which are executed repetitively until aconvergence condition is met. Optimizing cluster resource allocations among multipleworkloads of iterative algorithms motivates the need for estimating their runtime; which inturn requires: i) predicting the number of iterations; and ii) predicting the processing time ofeach iteration. As both parameters depend on the characteristics of the dataset and on theconvergence function; estimating their values before execution is difficult. This paperproposes PREDIcT; an experimental methodology for predicting the runtime of iterative …,*,2013,4
Malleable scheduling for flows of mapreduce jobs,Andrey Balmin; Kirsten Hildrum; Viswanath Nagarajan; Joel Wolf,Abstract We consider the problem of scheduling MapReduce workloads. A workloadconsists of multiple independent flows; and each flow is itself a set of MapReduce jobs withprecedence constraints. We model this as a parallel scheduling problem [5; 9]; morespecifically as precedence constrained malleable scheduling with linear speedup andprocessor maxima. Each flow is associated with an arbitrary cost function that describes thecost incurred for completing the flow at a particular time. The overall objective is to minimizeeither the total cost (minisum) or the maximum cost (minimax) of the flows. We use resourceaugmentation analysis to provide a (2; 3) bicriteria approximation algorithm for generalminisum objectives; and a (1; 2) bicriteria approximation algorithm for minimax objectives.We note that (unless P= NP) no finite approximation ratio is possible without resource …,*,2013,4
Wikianalytics: Ad-hoc querying of highly heterogeneous structured data,Andrey Balmin; Emiran Curtmola,Searching and extracting meaningful information out of highly heterogeneous datasets is ahot topic that received a lot of attention. However; the existing solutions are based on eitherrigid complex query languages (eg; SQL; XQuery/XPath) which are hard to use without fullschema knowledge; without an expert user; and which require up-front data integration. Atthe other extreme; existing solutions employ keyword search queries over relationaldatabases [3];[1];[10];[9];[2];[11] as well as over semistructured data [6];[12];[17];[15] whichare too imprecise to specify exactly the user's intent [16].,Data Engineering (ICDE); 2010 IEEE 26th International Conference on,2010,4
SEDA: a system for search; exploration; discovery; and analysis of XML Data,Andrey Balmin; Latha Colby; Emiran Curtmola; Quanzhong Li; Fatma Özcan; Sharath Srinivas; Zografoula Vagena,Abstract Keyword search in XML repositories is a powerful tool for interactive dataexploration. Much work has recently been done on making XML search aware ofrelationship information embedded in XML document structure; but without a clear winner inall data and query scenarios. Furthermore; due to its imprecise nature; search results cannoteasily be analyzed and summarized to gain more insights into the data. We address theseshortcomings with SEDA: a system for Search; Exploration; Discovery; and Analysis of XMLData. SEDA is based on a paradigm of search and user interaction to help users start withsimple keyword-style querying and perform rich analysis of XML data by leveraging both thecontent and structure of the data. SEDA is an interactive system that allows the user to refineher query iteratively to explore the XML data and discover interesting relationships. SEDA …,Proceedings of the VLDB Endowment,2008,4
Index selection for XML database systems,*,A method; computer-implemented system; and computer program product for creatingindexes over XML data managed by a database system are provided. The method;computer-implemented system; and computer program product provide for receiving aworkload for the XML data; the workload including one or more database statements;utilizing an optimizer of the database system to enumerate a set of one or more pathexpressions by creating a virtual universal index based on the workload received andmatching a path expression to the virtual universal index; and recommending one or morepath expressions from the set of one or more candidate path expressions to create theindexes over the XML data.,*,2017,2
Scheduling flows in a multi-platform cluster environment,*,Techniques for scheduling multiple flows in a multi-platform cluster environment areprovided. The techniques include partitioning a cluster into one or more platform containersassociated with one or more platforms in the cluster; scheduling one or more flows in each ofthe one or more platform containers; wherein the one or more flows are created as one ormore flow containers; scheduling one or more individual jobs into the one or more flowcontainers to create a moldable schedule of one or more jobs; flows and platforms; andautomatically converting the moldable schedule into a malleable schedule.,*,2014,2
Adaptive Processing of User-Defined Aggregates in Jaql.,Andrey Balmin; Vuk Ercegovac; Rares Vernica; Kevin S Beyer,Abstract Adaptive techniques can dramatically improve performance and simplify tuning forMapReduce jobs. However; their implementation often requires global coordinationbetween map tasks; which breaks a key assumption of MapReduce that mappers run inisolation. We show that it is possible to preserve faulttolerance; scalability; and ease of useof MapReduce by allowing map tasks to utilize a limited set of highlevel coordinationprimitives. We have implemented these primitives on top of an open source distributedcoordination service. We expose adaptive features in a high-level declarative querylanguage; Jaql; by utilizing unique features of the language; such as higher-order functionsand physical transparency. For instance; we observe that maintaining a small amount ofglobal state could help improve performance for a class of aggregate functions that are …,IEEE Data Eng. Bull.,2011,2
Circumflex: A scheduling optimizer for mapreduce workloads involving shared scans,Joel Wolf; Andrey Balmin; Deepak Rajan; Kirsten Hildrum; Rohit Khandekar; Sujay Parekh; Kun-Lung Wu; Rares Vernica,ABSTRACT We consider MapReduce clusters designed to support multiple concurrent jobs;concentrating on environments in which the number of distinct datasets is modest relative tothe number of jobs. Many datasets in such scenarios will wind up being scanned by multipleconcurrent Map phase jobs. As has been noticed previously; this scenario provides anopportunity for Map phase jobs to cooperate; sharing the scans of these datasets; and thusreducing the costs of such scans. Our paper has two main contributions. First; we present anew; novel and highly general method for sharing scans and thus amortizing their costs.This concept; which we will call cyclic piggybacking; is an alternative to the more traditionalbatching scheme described in the literature; and seems to have a number of advantagesover that scheme. Second; we describe a method for optimizing schedules within the …,*,2011,2
WIKIANALYTICS: Disambiguation of keyword search results on highly heterogeneous structured data,Andrey Balmin; Emiran Curtmola,Abstract Wikipedia infoboxes is an example of a seemingly structured; yet extraordinarilyheterogenous dataset; where any given record has only a tiny fraction of all possible fields.Such data cannot be queried using traditional means without a massive a priori integrationeffort; since even for a simple request the result values span many record types and fields.On the other hand; the solutions based on keyword search are too imprecise to captureuser's intent. To address these limitations; we propose a system; referred to herein asWikiAnalytics; that utilizes a novel search paradigm in order to derive tables of precise andcomplete results from Wikipedia infobox records. The user starts with a keyword searchquery that finds a superset of the result records; and then browses clusters of recordsdeciding which are and are not relevant. WikiAnalytics uses three categories of clustering …,Procceedings of the 13th International Workshop on the Web and Databases,2010,2
Stratified sampling using adaptive parallel data processing,*,A computer-implemented method includes partitioning a plurality of records into a plurality ofsplits. Each split includes at least a portion of the plurality of records. The method furtherincludes providing at least one split of the plurality of splits to a mapper. The mapper scansthe input data set; transforms each input record using a map function; and extracts agrouping key in parallel. The method further includes assigning at least a portion the recordsof the at least one split to a group. Each assignment to the group is based on a strata of theassigned record; and filtering the records of the group. Each filtering is based on acomparison of a weight of a record to a local threshold of the mapper. The method furtherincludes shuffling the group to a reducer and providing a stratified sampling of the plurality ofrecords based on the group.,*,2017,1
Identifying influencers for topics in social media,*,A computer determines social media influencers in a specific topic. The computer receives adataset of information on a website; the information including a list of users of the websiteand a list of content that each user posts; wherein each user is associated with one or moreother users. The computer identifies a plurality of variables associated with the dataset;wherein the plurality of variables represent the information of the dataset on the website. Thecomputer executes a topic specific search based on the plurality of variables; the topicsearch providing at least another list of users representing influencers in a specific topic.,*,2016,1
Automated scheduling management of MapReduce flow-graph applications,*,Techniques; systems; and articles of manufacture for automated scheduling management ofMapReduce flow-graph applications. A method includes determining a job schedule ofMapReduce jobs within each of multiple MapReduce flows in a cluster environment;wherein said job schedule does not violate a precedence relationship within thecorresponding MapReduce flow and reduces makespan of the corresponding MapReduceflow; determining a flow schedule for the multiple MapReduce flows based on considerationof a given metric; wherein said flow schedule comprises a number of slots allotted to each ofthe multiple MapReduce flows; and wherein said number of slots is less than or equal to anumber of the one or more MapReduce jobs within each corresponding MapReduce flow;and transforming each job schedule into the flow schedule to allocate resources for the …,*,2016,1
Groupwise analytics via adaptive MapReduce,Liping Peng; Vuk Ercegovac; Kai Zeng; Peter J Haas; Andrey Balmin; Yannis Sismanis,Shared-nothing systems such as Hadoop vastly simplify parallel programming whenprocessing disk-resident data whose size exceeds aggregate cluster memory. Such systemsincur a significant performance penalty; however; on the important class of “groupwise set-valued analytics”(GSVA) queries in which the data is dynamically partitioned into groupsand then a set-valued synopsis is computed for some or all of the groups. Key examples ofsynopses include top-k sets; bottom-k sets; and uniform random samples. Applications ofGSVA queries include micro-marketing; root-cause analysis for problem diagnosis; andfraud detection. A naive approach to executing GSVA queries first reshuffles all of the dataso that all records in a group are at the same node and then computes the synopsis for thegroup. This approach can be extremely inefficient when; as is typical; only a very small …,Data Engineering (ICDE); 2015 IEEE 31st International Conference on,2015,1
Identifying influencers for topics in social media,*,Abstract A computer determines social media influencers in a specific topic by receiving adataset of information associated with a website; the information including a first list of usersof the website and a list of content that each user posts on the website; wherein each user isassociated with other users from the first list of users. The computer determines initial valuesrepresenting variables of the dataset of information on the website; wherein the variablesinclude one or more topics for the list of content that each user from the first list of users postson the website. The computer performs an iteration of Gibbs Sampling utilizing the initialvalues. The computer determines the one or more new values representing variables of thedataset represent a distribution of the one or more topics for the list of content that each userfrom the first list of users posts.,*,2018,*
Dynamic query optimization with pilot runs,*,Abstract In one embodiment; a computer-implemented method includes selecting one ormore sub-expressions of a query during compile time. One or more pilot runs are performedby one or more computer processors. The one or more pilot runs include a pilot runassociated with each of one or more of the selected sub-expressions; and each pilot runincludes at least partial execution of the associated selected sub-expression. The pilot runsare performed during execution time. Statistics are collected on the one or more pilot runsduring performance of the one or more pilot runs. The query is optimized based at least inpart on the statistics collected during the one or more pilot runs; where the optimizationincludes basing cardinality and cost estimates on the statistics collected during the pilotruns.,*,2017,*
Dynamic interaction graphs with probabilistic edge decay,*,In one general embodiment; a computer-implemented method is provided for analyzing adynamic graph. The computer-implemented method includes generating two or moresample graphs by sampling edges of a current snapshot of a dynamic graph. Additionally;the computer-implemented method includes generating two or more partial results byexecuting an algorithm on the sample graphs. Still yet; the computer-implemented methodincludes combining the partial results; from executing the algorithm on the sample graphs;into a final result.,*,2017,*
Adaptive fragment assignment for processing file data in a database,*,Scheduling mechanisms for assigning data in a distributed file system to database workersare provided. In one embodiment; a method of and computer program product forassignment of data blocks to database workers are provided. A request for table data isreceived. Metadata for a plurality of blocks in a file system is retrieved from a metadata store.Each of the plurality of blocks contains a subset of the table data. A request for work isreceived from a requestor. An assignment of one or more of the plurality of blocks isprovided to the requestor.,*,2017,*
Subgraph-based distributed graph processing,*,Embodiments relate to subgraph-based distributed graph processing. An aspect includesreceiving an input graph comprising a plurality of vertices. Another aspect includespartitioning the input graph into a plurality of subgraphs; each subgraph comprising internalvertices and boundary vertices. Another aspect includes assigning one or more respectivesubgraphs to each of a plurality of workers. Another aspect includes initiating processing ofthe plurality of subgraphs by performing a series of processing steps comprising: processingthe internal vertices and boundary vertices internally within each of the subgraphs; detectingthat a change was made to a boundary vertex of a first subgraph during the internalprocessing; and sending a message from a first worker to which the first subgraph isassigned to a second worker to which a second subgraph is assigned in response to …,*,2016,*
Scaling dynamic authority-based search using materialized subgraphs,*,A method that includes generating; in a query pre-processor; a set of pre-computedmaterialized sub-graphs by executing a pre-processing dynamic random-walk based searchfor a bin of terms. The method also includes receiving; in a query processor; a search queryhaving at least one search query term. In response to receiving the search query; themethod includes accessing the set of pre-computed materialized sub-graphs. The accessingincludes accessing a text index based on the search query term to retrieve a correspondingterm group identifier and accessing the corresponding pre-computed materialized sub-graph based on the term group identifier. The method also includes executing a dynamicrandom-walk based search on only the corresponding pre-computed materialized sub-graph and based on the executing; retrieving nodes in the dataset and transmitting the …,*,2016,*
2014 Reviewers List,Ahmed Abbasi; Osman Abul; Evrim Acar; Palakorn Achananuparp; Sibel Adali; Nitin Agarwal; Rodrigo Agerri; Ankit Agrawal; Divyakant Agrawal; Manoj Agrawal; Chowdhury Ahmed; Mueen Ahmed; Luca Aiello; Mohammad Akbari; Reza Akbarinia; Oguz Akbilgic; Leman Akoglu; Zaher Al Aghbari; Luai Al-Shalabi; Barron-Cedeno Alberto; Nanopoulos Alexandros; Neda Alipanah; Mohammed Altaf; Toshiyuki Amagasa; Giuseppe Amato; Yuan An; Aris Anagnostopoulos; David Anastasiu; Kai Ang; François Anton; Kemafor Anyanwu; Arvind Arasu; Marcelo Arenas; Nikos Armenatzoglou; Ismailcem Arpinar; Anastasios Arvanitis; Mahdi Asadpour; Ira Assent; Juan Carlos Augusto; G Ausiello; Hakan Aydin,We thank the following reviewers for the time and energy they have given to TKDE … AhmedAbbasi Osman Abul Evrim Acar Palakorn Achananuparp Sibel Adali Nitin Agarwal Rodrigo AgerriAnkit Agrawal Divyakant Agrawal Manoj Agrawal Chowdhury Ahmed Mueen Ahmed Luca AielloMohammad Akbari Reza Akbarinia Oguz Akbilgic Leman Akoglu Zaher Al Aghbari Luai Al-ShalabiBarron-Cede˜no Alberto Nanopoulos Alexandros Neda Alipanah Mohammed Altaf ToshiyukiAmagasa Giuseppe Amato Yuan An Aris Anagnostopoulos David Anastasiu Kai Ang FrançoisAnton Kemafor Anyanwu Arvind Arasu Marcelo Arenas Nikos Armenatzoglou Ismailcem ArpinarAnastasios Arvanitis Mahdi Asadpour Ira Assent Juan Carlos Augusto G. Ausiello Hakan AydinB … Prabhakaran B. Sumeet Bajaj Petko Bakalov Spiridon Bakiras José Balcázar Tim BaldwinForrest Bao … Jie Bao Zhifeng Bao Nathalie Baracaldo Elena Baralis Nicola Barbieri …,IEEE Transactions on Knowledge and Data Engineering,2015,*
Scheduling MapReduce jobs in the presence of priority classes,*,Techniques for scheduling one or more MapReduce jobs in a presence of one or morepriority classes are provided. The techniques include obtaining a preferred ordering for oneor more MapReduce jobs; wherein the preferred ordering comprises one or more priorityclasses; prioritizing the one or more priority classes subject to one or more dynamicminimum slot guarantees for each priority class; and iteratively employing a MapReducescheduler; once per priority class; in priority class order; to optimize performance of the oneor more MapReduce jobs.,*,2014,*
Scheduling flows in a multi-platform cluster environment,*,Techniques for scheduling multiple flows in a multi-platform cluster environment areprovided. The techniques include partitioning a cluster into one or more platform containersassociated with one or more platforms in the cluster; scheduling one or more flows in each ofthe one or more platform containers; wherein the one or more flows are created as one ormore flow containers; scheduling one or more individual jobs into the one or more flowcontainers to create a moldable schedule of one or more jobs; flows and platforms; andautomatically converting the moldable schedule into a malleable schedule.,*,2014,*
2010 Index IEEE Transactions on Knowledge and Data Engineering Vol. 22,Osman Abul; Grigoris Antoniou; Kiyoshi Asai; Andrey Balmin; Robert M Balzer; Zhifeng Bao; Andrzej Bargiela; Payam Barnaghi; Nick Bassiliades; Dizza Beimel; David Bell; Thomas Bernecker; James Bezdek; Zeungnam Bien; Antonis Bikakis; Roland Billen; Harold Boley; PA Bonatti; Francesco Bonchi; Peter Boncz; Mihaela A Bornea; Athman Bouguettaya; Ramadhana Bramandia; Nicholas J Bryan; Di Cai; K Selcuk Candan; Bin Cao; Longbing Cao; Yong Cao; Chia-Hui Chang; Michael Chau; Muhammad Aamir Cheema; Bo Chen; Degang Chen; Honghui Chen; Hsinchun Chen; Huanhuan Chen; Jie Chen; Jinlin Chen; Lei Chen; Ming-Syan Chen; Xue-wen Chen; Yanhua Chen; Haibin Cheng; Hong Cheng; Reynold Cheng; David W-l Cheung; Byron Choi; Chung-Hua Chu; Yi-Hong Chu; Kun-Ta Chuang; Yon Dohn Chung; Eliseo Clementini; Christopher Clifton; Sergio Consoli,This index covers all technical items-papers; correspondence; reviews; etc.-that appeared inthis periodical during the year; and items from previous years that were commented upon orcorrected in this year. Departments and other items may also be covered if they have beenjudged to have archival value. The Author Index contains the primary entry for each item;listed under the first author's name. The primary entry includes the coauthors' names; the titleof the paper or other item; and its location; specified by the publication abbreviation; year;month; and inclusive pagination. The Subject Index contains entries describing the itemunder all appropriate subject headings; plus the first author's name; the publicationabbreviation; month; and year; and inclusive pages. Note that the item title is found onlyunder the primary entry in the Author Index.,IEEE Transactions on Knowledge and Data Engineering,2010,*
Grouping and Optimization of XPath Expressions in System RX,Andrey Balmin; Fatma Ozcan; Ashutosh Singh; Edison Ting,Several XML DBMS support XQuery and/or SQL/XML languages; which are based onnavigational primitives in the form of XPath expressions. Typically; these systems eithermodel each XPath step as a separate query plan operator; or employ holistic approachesthat can evaluate multiple steps of a single XPath expression. There have also beenproposals to execute as many XPath expressions as possible within a single FLWOR blocksimultaneously in a data streaming context. We observe in our System-RX prototype thatblindly combining all possible XPath expressions for concurrent execution can result insignificant performance degradation. We identify two main problems. First; the simplestrategy of grouping all XPath expressions on a single document does not always work if thequery involves more than one data source or has nested query blocks. Second; merging …,Data Engineering; 2008. ICDE 2008. IEEE 24th International Conference on,2008,*
Structured; unstructured; and semistructured search in semistructured databases,Andrey Balmin,A single framework for storing and querying XML data; using denormalized schemadecompositions; can support both structured queries and unstructured searches; as well asserve as a foundation for combining the two forms of information access. XML data formatbecomes increasingly popular in applications that mix structured data and unstructured text.These applications require integration of structured query and text search mechanisms toaccess XML data. First; we introduce a framework for storing and querying XML data usingdenormalized schema decompositions. This framework was initially implemented in theXCacheDB XML database system; which uses XML schemas to shred XML data intorelational storage. The XCacheDB supports a subset of XQuery language and emphasizesquery optimization to reduce latency and output first results quickly. The XCacheDB relies …,*,2006,*
ICDE 2017 Reviewers,Yannis Papakonstantinou; Lei Chen; Reynold Cheng; Wolfgang Gatterbauer; Bingsheng He; Stratos Idreos; Christopher Jermaine; Chen Li; Gerome Miklau; Tamer Özsu; Olga Papaemmanouil; Evimaria Terzi; Eugene Wu; Ashraf Aboulnaga; Alex Alves; Amazon Gabriel Antoniu; INRIA Arvind Arasu; Andrey Balmin; Workday Zhifeng Bao; Sumita Barahmand; Srikanta Bedathur; Carsten Binnig; Spyros Blanas; Marco Brambilla; Stephane Bressan; K Selcuk Candan; Zhao Cao; James Cheng; Fei Chiang; Panos K Chrysanthis; Philippe Cudre-Mauroux,ICDE 2017 Program Committee Chairs Yannis Papakonstantinou; University of California; SanDiego Yanlei Diao; Ecole Polytechnique; France; and University of Massachusetts; Amherst …ICDE 2017 Area Chairs Lei Chen; Hong Kong University of Science and Technology ReynoldCheng; University of Hong Kong Wolfgang Gatterbauer; Carnegie Mellon University BingshengHe; National University of Singapore Stratos Idreos; Harvard University ChristopherJermaine; Rice University Chen Li; University of California Irvine Gerome Miklau; University ofMassachusetts Tamer Özsu; University of Waterloo Olga Papaemmanouil; Brandeis UniversityEvimaria Terzi; Boston University Eugene Wu; Columbia University … ICDE 2017 Program CommitteeAshraf Aboulnaga; Qatar Computing Research Institute Alex Alves; Amazon Gabriel Antoniu;INRIA Arvind Arasu; Microsoft Research Andrey Balmin; Workday Zhifeng Bao; RMIT …,*,*,*
Massive-Scale Analytics,A Soffer; P Malik; AN Ghoting; JA Gunnels; P Kambadur; EP Pednault; MS Squillante; HP Hofstee; GC Chen; FH Gebara; K Hall; J Herring; D Jamsek; J Li; Y Li; JW Shi; PWY Wong; A Balmin; K Beyer; V Ercegovac; J McPherson; F Ozcan; H Pirahesh; E Shekita; Y Sismanis; S Tata; Y Tian; R Jain; P Sarkar; D Subhraveti; LL Fong; Y Gao; XR Guerin; YG Liu; T Salo; SR Seelam; W Tan,BBig Data [refers to large data sets that are beyond the capability of traditional software toolsto quickly manage; process; and analyze. The development of techniques for gaining insightfrom such information provides potential benefits in such arenas as business; science; andpublic policy. This special issue of the IBM Journal emphasizes applications; analytics;software; and hardware technologies that form the foundational building blocks for massive-scale analytics and the processing of Big Data.,*,*,*
