Linked open drug data for pharmaceutical research and development,Matthias Samwald; Anja Jentzsch; Christopher Bouton; Claus Stie Kallesøe; Egon Willighagen; Janos Hajagos; M Scott Marshall; Eric Prud'hommeaux; Oktie Hassanzadeh; Elgar Pichler; Susie Stephens,Abstract There is an abundance of information about drugs available on the Web. Datasources range from medicinal chemistry results; over the impact of drugs on geneexpression; to the outcomes of drugs in clinical trials. These data are typically not connectedtogether; which reduces the ease with which insights can be gained. Linking Open DrugData (LODD) is a task force within the World Wide Web Consortium's (W3C) Health Careand Life Sciences Interest Group (HCLS IG). LODD has surveyed publicly available dataabout drugs; created Linked Data representations of the data sets; and identified interestingscientific and business questions that can be answered once the data sets are connected.The task force provides recommendations for the best practices of exposing data in a LinkedData representation. In this paper; we present past and ongoing work of LODD and …,Journal of cheminformatics,2011,165
Framework for evaluating clustering algorithms in duplicate detection,Oktie Hassanzadeh; Fei Chiang; Hyun Chul Lee; Renée J Miller,Abstract The presence of duplicate records is a major data quality concern in largedatabases. To detect duplicates; entity resolution also known as duplication detection orrecord linkage is used as a part of the data cleaning process to identify records thatpotentially refer to the same real-world entity. We present the Stringer system that providesan evaluation framework for understanding what barriers remain towards the goal of trulyscalable and general purpose duplication detection algorithms. In this paper; we useStringer to evaluate the quality of the clusters (groups of potential duplicates) obtained fromseveral unconstrained clustering algorithms used in concert with approximate jointechniques. Our work is motivated by the recent significant advancements that have madeapproximate join algorithms highly scalable. Our extensive evaluation reveals that some …,Proceedings of the VLDB Endowment,2009,148
Creating probabilistic databases from duplicated data,Oktie Hassanzadeh; Renée J Miller,Abstract A major source of uncertainty in databases is the presence of duplicate items; ie;records that refer to the same real-world entity. However; accurate deduplication is a difficulttask and imperfect data cleaning may result in loss of valuable information. A reasonablealternative approach is to keep duplicates when the correct cleaning strategy is not certain;and utilize an efficient probabilistic query-answering technique to return query results alongwith probabilities of each answer being correct. In this paper; we present a flexible modularframework for scalably creating a probabilistic database out of a dirty relation of duplicateddata and overview the challenges raised in utilizing this framework for large relations ofstring data. We study the problem of associating probabilities with duplicates that aredetected using state-of-the-art scalable approximate join methods. We argue that …,The VLDB Journal—The International Journal on Very Large Data Bases,2009,77
A framework for semantic link discovery over relational data,Oktie Hassanzadeh; Anastasios Kementsietsidis; Lipyeow Lim; Renée J Miller; Min Wang,Abstract Discovering links between different data items in a single data source or acrossdifferent data sources is a challenging problem faced by many information systems today. Inparticular; the recent Linking Open Data (LOD) community project has highlighted theparamount importance of establishing semantic links among web data sources. Currently;LOD sources provide billions of RDF triples; but only millions of links between data sources.Many of these data sources are published using tools that operate over relational datastored in a standard RDBMS. In this paper; we present a framework for discovery ofsemantic links from relational data. Our framework is based on declarative specification oflinkage requirements by a user. We illustrate the use of our framework using several linkdiscovery algorithms on a real world scenario. Our framework allows data publishers to …,Proceedings of the 18th ACM conference on Information and knowledge management,2009,73
Linking open drug data.,Anja Jentzsch; Jun Zhao; Oktie Hassanzadeh; Kei-Hoi Cheung; Matthias Samwald; Bosse Andersson,Abstract: The development of new therapies for diseases requires the integration of largeamounts of biomedical data from many different sources. The goal of the Linking Open DrugData (LODD) 1 project is to facilitate this integration by bringing these data sources onto theWeb of Linked Data. We describe the different datasets published by this project; which arestrongly interlinked with other Linked Data sources and contain 8.4 million RDF triples. Ause case is provided that demonstrates the benefit of this work to patients and medicalresearchers.,I-SEMANTICS,2009,69
Enabling tailored therapeutics with linked data,Anja Jentzsch; Oktie Hassanzadeh; Christian Bizer; Bo Andersson; Susie Stephens,ABSTRACT Advances in the biological sciences are allowing pharmaceutical companies tomeet the health care crisis with drugs that are more suitable for preventive and tailoredtreatment; thereby holding the promise of enabling more cost effective care with greaterefficacy and reduced side effects. However; this shift in business model increases the needfor companies to integrate data across drug discovery; drug development; and clinicalpractice. This is a fundamental shift from the approach of limiting integration activities tofunctional areas. The Linked Data approach holds much potential for enabling suchconnectivity between data silos; thereby enabling pharmaceutical companies to meet theurgent needs in society for more tailored health care. This paper examines the applicabilityand potential benefits of using Linked Data to connect drug and clinical trials related data …,Proceedings of the 2nd Workshop on Linked Data on the Web (LDOW2009),2009,60
Linkedct: A linked data space for clinical trials,Oktie Hassanzadeh; Anastasios Kementsietsidis; Lipyeow Lim; Renée J Miller; Min Wang,Abstract: The Linked Clinical Trials (LinkedCT) project aims at publishing the first opensemantic web data source for clinical trials data. The database exposed by LinkedCT isgenerated by (1) transforming existing data sources of clinical trials into RDF; and (2)discovering semantic links between the records in the trials data and several other datasources. In this paper; we discuss several challenges involved in these two steps andpresent the methodology used in LinkedCT to overcome these challenges. Our approach forsemantic link discovery involves using state-of-the-art approximate string matchingtechniques combined with ontology-based semantic matching of the records; all performedin a declarative and easy-to-use framework. We present an evaluation of the performance ofour proposed techniques in several link discovery scenarios in LinkedCT.,arXiv preprint arXiv:0908.0567,2009,58
Benchmarking declarative approximate selection predicates,Amit Chandel; Oktie Hassanzadeh; Nick Koudas; Mohammad Sadoghi; Divesh Srivastava,Abstract Declarative data quality has been an active research topic. The fundamentalprinciple behind a declarative approach to data quality is the use of declarative statementsto realize data quality primitives on top of any relational data source. A primary advantage ofsuch an approach is the ease of use and integration with existing applications. Over the lastfew years several similarity predicates have been proposed for common quality primitives(approximate selections; joins; etc) and have been fully expressed using declarative SQLstatements. In this paper we propose new similarity predicates along with their declarativerealization; based on notions of probabilistic information retrieval. In particular we show howlanguage models and hidden Markov models can be utilized as similarity predicates for dataquality and present their full declarative instantiation. We also show how other scoring …,Proceedings of the 2007 ACM SIGMOD international conference on Management of data,2007,57
A declarative framework for semantic link discovery over relational data,Oktie Hassanzadeh; Lipyeow Lim; Anastasios Kementsietsidis; Min Wang,Abstract In this paper; we present a framework for online discovery of semantic links fromrelational data. Our framework is based on declarative specification of the linkagerequirements by the user; that allows matching data items in many real-world scenarios.These requirements are translated to queries that can run over the relational data source;potentially using the semantic knowledge to enhance the accuracy of link discovery. Ourframework lets data publishers to easily find and publish high-quality links to other datasources; and therefore could significantly enhance the value of the data in the nextgeneration of web.,Proceedings of the 18th international conference on World wide web,2009,46
Toward a complete dataset of drug–drug interaction information from publicly available sources,Serkan Ayvaz; John Horn; Oktie Hassanzadeh; Qian Zhu; Johann Stan; Nicholas P Tatonetti; Santiago Vilar; Mathias Brochhausen; Matthias Samwald; Majid Rastegar-Mojarad; Michel Dumontier; Richard D Boyce,Abstract Although potential drug–drug interactions (PDDIs) are a significant source ofpreventable drug-related harm; there is currently no single complete source of PDDIinformation. In the current study; all publically available sources of PDDI information thatcould be identified using a comprehensive and broad search were combined into a singledataset. The combined dataset merged fourteen different sources including 5 clinically-oriented information sources; 4 Natural Language Processing (NLP) Corpora; and 5Bioinformatics/Pharmacovigilance information sources. As a comprehensive PDDI source;the merged dataset might benefit the pharmacovigilance text mining community by making itpossible to compare the representativeness of NLP corpora for PDDI text extraction tasks;and specifying elements that can be useful for future PDDI extraction purposes. An …,Journal of biomedical informatics,2015,43
Instance-based matching of large ontologies using locality-sensitive hashing,Songyun Duan; Achille Fokoue; Oktie Hassanzadeh; Anastasios Kementsietsidis; Kavitha Srinivas; Michael J Ward,Abstract In this paper; we describe a mechanism for ontology alignment using instancebased matching of types (or classes). Instance-based matching is known to be a usefultechnique for matching ontologies that have different names and different structures. A keyproblem in instance matching of types; however; is scaling the matching algorithm to (a)handle types with a large number of instances; and (b) efficiently match a large number oftype pairs. We propose the use of state-of-the art locality-sensitive hashing (LSH) techniquesto vastly improve the scalability of instance matching across multiple types. We show thefeasibility of our approach with DBpedia and Freebase; two different type systems withhundreds and thousands of types; respectively. We describe how these techniques can beused to estimate containment or equivalence relations between two type systems; and we …,International Semantic Web Conference,2012,42
Aggregating search results based on associating data instances with knowledge base entities,*,Methods and systems for aggregating search query results include receiving search queryresults and schema information for the query results from multiple heterogeneous sources;determining types for elements of the query results based on the schema information;determining potential aggregations for the query results based on the types; which arebased on accumulated information from the plurality of heterogeneous resources; andaggregating the query results according to one or more of the potential aggregations.,*,2012,39
Linking Semistructured Data on the Web,Soheil Hassas Yeganeh; Oktie Hassanzadeh; Renée J Miller,ABSTRACT Many Web data sources and APIs make their data available in XML; JSON; or adomain-specific semi-structured format; with the goal of making the data easily accessibleand usable by Web application developers. Although such data formats are more machine-processable than pure text documents; managing and analyzing such data in large scale isoften nontrivial. This is mainly due to the lack of a well-defined (or understood) structure andclear semantics in such data formats; which could result in poor data quality. In the xCuratorproject; we add structure to such data with the goal of publishing it on the Web as LinkedData. We enhance the quality of such data by: extracting entities; their types; and theirrelationships to other entities; performing entity (and entity type) identification; mergingduplicate entities (and entity types); linking related entities (internally and to external …,14th International Workshop on the Web and Databases (WebDB 2011),2011,29
Discovering linkage points over web data,Oktie Hassanzadeh; Ken Q Pu; Soheil Hassas Yeganeh; Renée J Miller; Lucian Popa; Mauricio A Hernández; Howard Ho,Abstract A basic step in integration is the identification of linkage points; ie; finding attributesthat are shared (or related) between data sources; and that can be used to match records orentities across sources. This is usually performed using a match operator; that associatesattributes of one database to another. However; the massive growth in the amount andvariety of unstructured and semi-structured data on the Web has created new challenges forthis task. Such data sources often do not have a fixed pre-defined schema and contain largenumbers of diverse attributes. Furthermore; the end goal is not schema alignment as theseschemas may be too heterogeneous (and dynamic) to meaningfully align. Rather; the goal isto align any overlapping data shared by these sources. We will show that even attributeswith different meanings (that would not qualify as schema matches) can sometimes be …,Proceedings of the VLDB Endowment,2013,27
Linkage query writer,Oktie Hassanzadeh; Reynold Xin; Renée J Miller; Anastasios Kementsietsidis; Lipyeow Lim; Min Wang,Abstract We present Linkage Query Writer (LinQuer); a system for generating SQL queriesfor semantic link discovery over relational data. The LinQuer framework consists of (a)LinQL; a language for specification of linkage requirements;(b) a web interface and an APIfor translating LinQL queries to standard SQL queries;(c) an interface that assists users inwriting LinQL queries. We discuss the challenges involved in the design and implementationof a declarative and easy to use framework for discovering links between different data itemsin a single data source or across different data sources. We demonstrate different steps ofthe linkage requirements specification and discovery process in several real world scenariosand show how the LinQuer system can be used to create high-quality linked data sources.,Proceedings of the VLDB Endowment,2009,26
Accuracy of Approximate String Joins Using Grams.,Oktie Hassanzadeh; Mohammad Sadoghi; Renée J Miller,ABSTRACT Approximate join is an important part of many data cleaning and integrationmethodologies. Various similarity measures have been proposed for accurate and efficientmatching of string attributes. The accuracy of the similarity measures highly depends on thecharacteristics of the data such as amount and type of the errors and length of the strings.Recently; there has been an increasing interest in using methods based on q-grams(substrings of length q) made out of the strings; mainly due to their high efficiency. In thiswork; we evaluate the accuracy of the similarity measures used in these methodologies. Wepresent an overview of several similarity measures based on q-grams. We then thoroughlycompare their accuracy on several datasets with different characteristics. Since the efficiencyof approximate joins depend on the similarity threshold they use; we study how the value …,QDB,2007,25
Semantic-aware record matching,*,A method of semantic-aware record matching includes receiving source and target stringrecord specifications associated with a source string record and a target string record;receiving semantic knowledge referring to tokens of the source string record and targetstring record; creating a first set of tokens for the source string record and a second set oftokens for the target string record based on the semantic knowledge; assigning a similarityscore to the source string record and the target string record based on a semanticrelationship between the first set of tokens and the second set of tokens; and matching thesource string record and the target string record based on the similarity score.,*,2013,24
Schema management for document stores,Lanjun Wang; Shuo Zhang; Juwei Shi; Limei Jiao; Oktie Hassanzadeh; Jia Zou; Chen Wangz,Abstract Document stores that provide the efficiency of a schema-less interface are widelyused by developers in mobile and cloud applications. However; the simplicity developersachieved controversially leads to complexity for data management due to lack of a schema.In this paper; we present a schema management framework for document stores. Thisframework discovers and persists schemas of JSON records in a repository; and alsosupports queries and schema summarization. The major technical challenge comes fromvaried structures of records caused by the schema-less data model and schema evolution.In the discovery phase; we apply a canonical form based method and propose an algorithmbased on equivalent sub-trees to group equivalent schemas efficiently. Together with thealgorithm; we propose a new data structure; eSiBu-Tree; to store schemas and support …,Proceedings of the VLDB Endowment,2015,21
Data management issues on the semantic web,Oktie Hassanzadeh; Anastasios Kementsietsidis; Yannis Velegrakis,We provide an overview of the current data management research issues in the context ofthe Semantic Web. The objective is to introduce the audience into the area of the SemanticWeb; and to highlight the fact that the area provides many interesting research opportunitiesfor the data management community. A new model; the Resource Description Framework(RDF); coupled with a new query language; called SPARQL; lead us to revisit someclassical data management problems; including efficient storage; query optimization; anddata integration. These are problems that the Semantic Web community has only recentlystarted to explore; and therefore the experience and long tradition of the databasecommunity can prove valuable. We target both experienced and novice researchers that arelooking for a thorough presentation of the area and its key research topics.,Data Engineering (ICDE); 2012 IEEE 28th International Conference on,2012,19
Helix: Online enterprise data analytics,Oktie Hassanzadeh; Songyun Duan; Achille Fokoue; Anastasios Kementsietsidis; Kavitha Srinivas; Michael J Ward,Abstract The size; heterogeneity and dynamicity of data within an enterprise makesindexing; integration and analysis of the data increasingly difficult tasks. On the other hand;there has been a massive increase in the amount of high-quality open data available on theWeb that could provide invaluable insights to data analysts and business intelligencespecialists within the enterprise. The goal of Helix project is to provide users within theenterprise with a platform that allows them to perform online analysis of almost any type andamount of internal data using the power of external knowledge bases available on the Web.Such a platform requires a novel; data-format agnostic indexing mechanism; and light-weight data linking techniques that could link semantically related records across internaland external data sources of various characteristics. We present the initial architecture of …,Proceedings of the 20th international conference companion on World wide web,2011,19
Dynamic enhancement of drug product labels to support drug safety; efficacy; and effectiveness,Richard D Boyce; John R Horn; Oktie Hassanzadeh; Anita De Waard; Jodi Schneider; Joanne S Luciano; Majid Rastegar-Mojarad; Maria Liakata,Out-of-date or incomplete drug product labeling information may increase the risk ofotherwise preventable adverse drug events. In recognition of these concerns; the UnitedStates Federal Drug Administration (FDA) requires drug product labels to include specificinformation. Unfortunately; several studies have found that drug product labeling fails tokeep current with the scientific literature. We present a novel approach to addressing thisissue. The primary goal of this novel approach is to better meet the information needs ofpersons who consult the drug product label for information on a drug's efficacy;effectiveness; and safety. Using FDA product label regulations as a guide; the approachlinks drug claims present in drug information sources available on the Semantic Web withspecific product label sections. Here we report on pilot work that establishes the baseline …,Journal of biomedical semantics,2013,18
Dynamic enhancement of drug product labels to support drug safety; efficacy; and effectiveness,Richard D Boyce; John R Horn; Oktie Hassanzadeh; Anita De Waard; Jodi Schneider; Joanne S Luciano; Majid Rastegar-Mojarad; Maria Liakata,Out-of-date or incomplete drug product labeling information may increase the risk ofotherwise preventable adverse drug events. In recognition of these concerns; the UnitedStates Federal Drug Administration (FDA) requires drug product labels to include specificinformation. Unfortunately; several studies have found that drug product labeling fails tokeep current with the scientific literature. We present a novel approach to addressing thisissue. The primary goal of this novel approach is to better meet the information needs ofpersons who consult the drug product label for information on a drug's efficacy;effectiveness; and safety. Using FDA product label regulations as a guide; the approachlinks drug claims present in drug information sources available on the Semantic Web withspecific product label sections. Here we report on pilot work that establishes the baseline …,Journal of biomedical semantics,2013,18
Publishing bibliographic data on the Semantic Web using BibBase,Reynold S Xin; Oktie Hassanzadeh; Christian Fritz; Shirin Sohrabi; Renée J Miller,Abstract We present BibBase; a system for publishing and managing bibliographic dataavailable in BiBTeX files. BibBase uses a powerful yet light-weight approach to transformBiBTeX files into rich Linked Data as well as custom HTML code and RSS feed that canreadily be integrated within a user's website while the data can instantly be queried onlineon the system's SPARQL endpoint. In this paper; we present an overview of several featuresof our system. We outline several challenges involved in on-the-fly transformation of highlyheterogeneous BiBTeX files into high-quality Linked Data; and present our solution to thesechallenges.,Semantic Web,2013,14
Online annotation of text streams with structured entities,Ken Q Pu; Oktie Hassanzadeh; Richard Drake; Renée J Miller,Abstract We propose a framework and algorithm for annotating unbounded text streams withentities of a structured database. The algorithm allows one to correlate unstructured anddirty text streams from sources such as emails; chats and blogs; to entities stored instructured databases. In contrast to previous work on entity extraction; our emphasis is onperforming entity annotation in a completely online fashion. The algorithm continuouslyextracts important phrases and assigns to them top-k relevant entities. Our algorithm does sowith a guarantee of constant time and space complexity for each additional word in the textstream; thus infinite text streams can be annotated. Our framework allows the onlineannotation algorithm to adapt to changing stream rate by self-adjusting multiple run-timeparameters to reduce or improve the quality of annotation for fast or slow streams …,Proceedings of the 19th ACM international conference on Information and knowledge management,2010,14
Benchmarking declarative approximate selection predicates,Oktie Hassanzadeh,Abstract: Declarative data quality has been an active research topic. The fundamentalprinciple behind a declarative approach to data quality is the use of declarative statementsto realize data quality primitives on top of any relational data source. A primary advantage ofsuch an approach is the ease of use and integration with existing applications. Severalsimilarity predicates have been proposed in the past for common quality primitives(approximate selections; joins; etc.) and have been fully expressed using declarative SQLstatements. In this thesis; new similarity predicates are proposed along with their declarativerealization; based on notions of probabilistic information retrieval. Then; full declarativespecifications of previously proposed similarity predicates in the literature are presented;grouped into classes according to their primary characteristics. Finally; a thorough …,arXiv preprint arXiv:0907.2471,2009,14
Predicting drug-drug interactions through large-scale similarity-based link prediction,Achille Fokoue; Mohammad Sadoghi; Oktie Hassanzadeh; Ping Zhang,Abstract Drug-Drug Interactions (DDIs) are a major cause of preventable adverse drugreactions (ADRs); causing a significant burden on the patients' health and the healthcaresystem. It is widely known that clinical studies cannot sufficiently and accurately identify DDIsfor new drugs before they are made available on the market. In addition; existing public andproprietary sources of DDI information are known to be incomplete and/or inaccurate and sonot reliable. As a result; there is an emerging body of research on in-silico prediction of drug-drug interactions. We present Tiresias; a framework that takes in various sources of drug-related data and knowledge as inputs; and provides DDI predictions as outputs. The processstarts with semantic integration of the input data that results in a knowledge graph describingdrug attributes and relationships with various related entities such as enzymes; chemical …,International Semantic Web Conference,2016,11
Understanding a Large Corpus of Web Tables Through Matching with Knowledge Bases–An Empirical Study,Oktie Hassanzadeh; Michael J Ward; Mariano Rodriguez-Muro; Kavitha Srinivas,Abstract. Extracting and analyzing the vast amount of structured tabular data available onthe Web is a challenging task and has received a significant attention in the past few years.In this paper; we present the results of our analysis of the contents of a large corpus of over90 million Web Tables through matching table contents with instances from a public cross-domain ontology such as DBpedia. The goal of this study is twofold. First; we examine how alarge-scale matching of all table contents with a knowledge base can help us gain a betterunderstanding of the corpus beyond what we gain from simple statistical measures such asdistribution of table sizes and values. Second; we show how the results of our analysis areaffected by the choice of the ontology and knowledge base. The ontologies studied includeDBpedia Ontology; Schema. org; YAGO; Wikidata; and Freebase. Our results can provide …,*,2015,11
Extending the “Web of Drug Identity” with Knowledge Extracted from United States Product Labels,Oktie Hassanzadeh; Qian Zhu; Robert Freimuth; Richard Boyce,Abstract Structured Product Labels (SPLs) contain information about drugs that can bevaluable to clinical and translational research; especially if it can be linked to other sourcesthat provide data about drug targets; chemical properties; interactions; and biologicalpathways. Unfortunately; SPLs currently provide coarsely-structured drug information andlack the detailed annotation that is required to support computational use cases. To helpaddress this issue we created LinkedSPLs; a Linked Data resource that extends the “web ofdrug identity” using information extracted from SPLs. In this paper we describe the mappingthat LinkedSPLs provides between SPL active ingredients and DrugBank chemical entities.These mappings were created using three approaches: InChI chemical structure descriptorscomparison; exact string matching based on the chemical name; and automatic …,AMIA Summit on Translational Bioinformatics,2013,10
Linked movie data base,Oktie Hassanzadeh; Mariano Consens,ABSTRACT The Linked Movie Database (LinkedMDB) project provides a demonstration ofthe first open linked dataset connecting several major existing (and highly popular) movieweb resources. The database exposed by LinkedMDB contains millions of RDF triples withhundreds of thousands of RDF links to existing web data sources that are part of the growingLinking Open Data cloud; as well as to popular movierelated web pages such as IMDb.LinkedMDB uses a novel way of creating and maintaining large quantities of high qualitylinks by employing state-of-the-art approximate join techniques for finding links; andproviding additional RDF metadata about the quality of the links and the techniques used forderiving them.,Proceedings of the 2nd Workshop on Linked Data on the Web (LDOW2009),2009,9
Methods and systems for discovery of linkage points between data sources,*,Data records are linked across a plurality of datasets. Each dataset contains at least onedata record; and each data record is associated with an entity and includes one or moreattributes of that entity and a value for each attribute. Values associated with attributes arecompared across datasets; and matching attributes having values that satisfy apredetermined similarity threshold are identified. In addition; linkage points between pairs ofdatasets are identified. Each linkage point links one or more pairs of data records. Each datarecord in the pair of data records is contained in one of a given pair of datasets; and eachpair of data records is associated with a common entity having matching attributes in thegiven pair of datasets. Data records associated with the common entities are linked acrossdatasets using the identified linkage points.,*,2017,8
Predicting Drug-Drug Interactions Through Similarity-Based Link Prediction Over Web Data,Achille Fokoue; Oktie Hassanzadeh; Mohammad Sadoghi; Ping Zhang,Abstract Drug-Drug Interactions (DDIs) are a major cause of preventable adverse drugreactions and a huge burden on public health and the healthcare system. On the other hand;there is a large amount of drug-related (open) data published on the Web; describingvarious properties of drugs and their relationships to other drugs; genes; diseases; andrelated concepts and entities. In this demonstration; we describe an end-to-end system wehave designed to take in various Web data sources as input and provide as output aprediction of DDIs along with an explanation of why two drugs may interact. The system firstcreates a knowledge graph out of input data sources through large-scale semanticintegration; and then performs link prediction among drug entities in the graph through large-scale similarity analysis and machine learning. The link prediction is performed using a …,WWW,2016,8
Introduction to Semantic Web Technologies & Linked Data,Oktie Hassanzadeh,Page 1. Introduction to Semantic Web Technologies & Linked Data Oktie Hassanzadeh Universityof Toronto March 2011 CS 443: Database Management Systems - Winter 2011 Page 2. 2 Outline □Introduction □ Semantic Web Technologies □ Resource Description Framework (RDF) □Querying RDF data (SPARQL) □ Linked Data □ Linked Data Principles □ Linking Open DataCommunity Project □ Example Data Sources □ Example Applications Page 3. 3 IntroductionWeb of Documents vs. Web of Data Page 4. 4 Web of Documents Primary objects: documentsLinks between documents (or parts of them) Degree of structure in data: fairly low Implicitsemantics of contents Designed for: human consumption HTML HTML HTML API/ XML UntypedLinks Untyped Links Untyped Links A B C D Based on presentations by Chris Bizer; RichardCyganiak; Tom Heath; available at http://linkeddata.org/guides-and-tutorials …,University of Toronto,2011,8
Finding Diverse High-Quality Plans for Hypothesis Generation.,Shirin Sohrabi; Anton V Riabov; Octavian Udrea; Oktie Hassanzadeh,Abstract. New applications that use AI planning to generate explanations and hypotheseshave given rise to a new class of planning problems; requiring finding multiple alternativeplans while minimizing the cost of those plans. Hypotheses or explanations about a system;such as a monitored network host that could be infected by malware; are generated ascandidate plans given a planning problem definition describing the sequence ofobservations and a domain model capturing the possible state transitions for the modeledsystem; as well as the many-to-many correspondence between the states and theobservations. The plans must minimize both the penalties for unexplained observations andthe cost of state transitions. Additionally; among those candidate plans; a small number ofthe most diverse plans must be selected as representatives for further analysis. To this …,ECAI,2016,7
Data virtualization across heterogeneous formats,*,Various embodiments virtualize data across heterogeneous formats. In one embodiment; aplurality of heterogeneous data sources is received as input. A local schema graph includinga set of attribute nodes and a set of type nodes is generated for each of the plurality ofheterogeneous data sources. A global schema graph is generated based on each localschema graph that has been generated. The global schema graph comprises each of thelocal schema graphs and at least one edge between at least one of two or more attributesnodes and two or more type nodes from different local schema graphs. The edge indicates arelationship between the data sources represented by the different local schema graphscomprising the two or more attributes nodes based on a computed similarity between atleast one value associated with each of the two or more attributes nodes.,*,2016,5
Joint learning of local and global features for entity linking via neural networks,Thien Huu Nguyen; Nicolas Fauceglia; Mariano Rodriguez Muro; Oktie Hassanzadeh; Alfio Massimiliano Gliozzo; Mohammad Sadoghi,Abstract Previous studies have highlighted the necessity for entity linking systems to capturethe local entity-mention similarities and the global topical coherence. We introduce a novelframework based on convolutional neural networks and recurrent neural networks tosimultaneously model the local and global features for entity linking. The proposed modelbenefits from the capacity of convolutional neural networks to induce the underlyingrepresentations for local contexts and the advantage of recurrent neural networks toadaptively compress variable length sequences of predictions for global constraints. Ourevaluation on multiple datasets demonstrates the effectiveness of the model and yields thestate-of-the-art performance on such datasets. In addition; we examine the entity linkingsystems on the domain adaptation setting that further demonstrates the cross-domain …,Proceedings of COLING 2016; the 26th International Conference on Computational Linguistics: Technical Papers,2016,5
Automatic Curation of Clinical Trials Data in LinkedCT,Oktie Hassanzadeh; Renée J Miller,Abstract The Linked Clinical Trials (LinkedCT) project started back in 2008 with the goal ofproviding a Linked Data source of clinical trials. The source of the data is from the XML datapublished on ClinicalTrials. gov; which is an international registry of clinical studies. Sincethe initial release; the LinkedCT project has gone through some major changes to bothimprove the quality of the data and its freshness. The result is a high-quality Linked Datasource of clinical studies that is updated daily; currently containing over 195;000 trials; 4.6million entities; and 42 million triples. In this paper; we present a detailed description of thesystem along with a brief outline of technical challenges involved in curating the raw XMLdata into high-quality Linked Data. We also present usage statistics and a number ofinteresting use cases developed by external parties. We share the lessons learned in the …,International Semantic Web Conference,2015,5
Exploring big data with helix: Finding needles in a big haystack,Jason Ellis; Achille Fokoue; Oktie Hassanzadeh; Anastasios Kementsietsidis; Kavitha Srinivas; Michael J Ward,Abstract While much work has focused on efficient processing of Big Data; little workconsiders how to understand them. In this paper; we describe Helix; a system for guidedexploration of Big Data. Helix provides a unified view of sources; ranging from spreadsheetsand XML files with no schema; all the way to RDF graphs and relational data with well-defined schemas. Helix users explore these heterogeneous data sources through acombination of keyword searches and navigation of linked web pages that includeinformation about the schemas; as well as data and semantic links within and acrosssources. At a technical level; the paper describes the research challenges involved indeveloping Helix; along with a set of real-world usage scenarios and the lessons learned.,ACM SIGMOD Record,2015,5
Collective ontology alignment.,Jason B Ellis; Oktie Hassanzadeh; Kavitha Srinivas; Michael J Ward,Enterprises are captivated by the promise of using big data to develop new products andservices that provide new insights into their customers and businesses. However; there aresignificant challenges leveraging data across heterogeneous data stores; including makingthose data accessible and usable by non-experts. We designed a novel system called Helixwhich employs a combination of userdriven and automated techniques to bootstrap thebuilding of a unified semantic model over virtualized data. Such a uniform semantic modelallows users to query across data stores transparently; without needing to navigate a mazeof data silos; data formats; and query languages. In this poster; we discuss a specific aspectof Helix: the method by which it facilitates ontology alignment. Such alignments are verynoisy and manually fixing the issues is a laborious process; especially when all the work …,OM,2013,5
An evaluation of clustering algorithms in duplicate detection,Bilal Hussain; Oktie Hassanzadeh; Fei Chiang; Hyun Chul Lee; Renée J Miller,HC Lee Content Understanding & Personalization; LinkedIn E-mail: culee@ linkedin. comgration and cleaning of large databases. In this paper; we focus on a class of duplicatedetection algorithms that rely on clustering a similarity graph. Each node in the similaritygraph represents a record and the weight of an edge connecting two nodes reflects theamount of similarity between the corresponding records. The similarity graph can beefficiently constructed using state-of-the-art similarity join techniques. For duplicatedetection; a clustering algorithm over the similarity graph is used to produce sets of recordsthat are likely to represent the same entity. In this paper; we present a framework forevaluating the effectiveness of clustering algorithms for duplicate detection. We present theresults of our extensive evaluation of a wide range of clustering algorithms. Our …,Technical Report CSRG-620; University of Toronto; Department of Computer Science,2013,5
Semantic Link Discovery,*,A method of semantic link discovery through translation of basic declarative languageincludes receiving a set of linkage specifications; receiving a set of data sources related tothe linkage specifications; the set of data sources and the set of linkage requirementsforming a basic declarative language query; translating the basic declarative languagequery into a standard language query; executing the standard language query; andreturning results of the standard language query in response to the executing.,*,2011,4
Efficient high quality plan exploration for network security,Anton Riabov; Shirin Sohrabi; Octavian Udrea; Oktie Hassanzadeh,Abstract We consider the application of planning in network security. In this application;plans represent possible attacks on the network; and network administrators need tools thatwould allow them to explore the plan space quickly and efficiently. Multiple aspects of thisproblem require generating and inspecting more than one plan; primarily due to limitedinformation about the possible actions of the attacker; and a variety of possible attacks. Thisproblem can be modeled as diverse planning; with the caveat that high quality (or;equivalently; low cost) plans must be prioritized; since those plans typically represent themost efficient attacks that are of highest importance to the administrators. Hence; there is aneed for a systematic approach to finding such plans. We propose a new technique basedon a top-k planner that finds k optimal or near-optimal plans; followed by plan …,International Scheduling and Planning Applications woRKshop (SPARK),2016,3
Self-Curating Databases.,Mohammad Sadoghi; Kavitha Srinivas; Oktie Hassanzadeh; Yuan-Chi Chang; Mustafa Canim; Achille Fokoue; Yishai A Feldman,ABSTRACT The success of relational databases is due in part to the simplicity of the tabularrepresentation of data; the clear separation of the physical and logical view of data; and thesimple representation of the logical view (meta-data) as a flat schema. But we are nowwitnessing a paradigm shift owing to the explosion of data volume; variety and veracity; andas a result; there is a real need to knit together data that is naturally heterogeneous; butdeeply interconnected. To be useful in this world; we argue that today's tabular data modelmust evolve into a holistic data model that views meta-data as a new semantically richsource of data and unifies data and meta-data such that the data becomes descriptive.Furthermore; given the dynamicity of data; we argue that fundamental changes are neededin how data is consolidated continuously under uncertainty to make the data model …,EDBT,2016,3
Annotating schema elements based on associating data instances with knowledge base entities,*,Methods and systems for determining schema element types are shown that include poolingpotential annotations for an element of an unlabeled schema from a plurality ofheterogeneous sources; scoring the pool of potential annotations according to relevancyusing information using instance information from the plurality of heterogeneous sources toproduce a relevancy score; and annotating the element of the unlabeled schema using themost relevant potential annotations.,*,2012,3
Producing clustered top-k plans,*,A mechanism is provided for identifying a set of top-in clusters from a set of top-k plans. Aplanning problem and an integer value k indicating a number of top plans to be identifiedare received. A set of top-k plans are generated with at most size k; where the set of top-kplans is with respect to a given measure of plan quality. Each plan in the set of top-k plans isclustered based on a similarity between plans such that each cluster contains similar plansand each plan is grouped only into one cluster thereby forming the set of top-m clusters. Arepresentative plan from each top-m cluster is presented to the user.,*,2017,2
Interactive Planning-Based Hypothesis Generation with LTS++.,Shirin Sohrabi; Octavian Udrea; Anton V Riabov; Oktie Hassanzadeh,1 Introduction and Motivation The set of planning-based tools; collectively called LTS++; presentedin this paper address the hypothesis generation problem that arises in applications that requiremultiple hy- potheses to be generated in order to reason about possibly in- complete or inconsistentsequences of observations received from external sources. For example; when analyzingobser- vations derived from sensor data in intensive care; the goal can be to generate plausiblehypotheses about the condition of the patient. The resulting hypotheses can then be further refinedand analyzed to create a recovery plan for the pa- tient. In another application; decisions aimedto prevent mal- ware spread in computer networks can be based on hypothe- ses about changein behavior of individual hosts generated by reasoning about observations of network traffic overtime. The core idea of the approach to planning-based hypothesis generation we …,IJCAI,2016,2
Annotating web tables through ontology matching.,Vasilis Efthymiou; Oktie Hassanzadeh; Mohammad Sadoghi; Mariano Rodriguez-Muro,Web tables have been proven to constitute valuable sources of information for applications;ranging from Web search; to data discovery in spreadsheet software and KB augmentation[1]. A requirement for those applications is to understand the semantics of Web tables andpotentially match their contents with existing URIs in the Web of Data; a process known asWeb table annotation [4]. Recent works on Web table annotation follow an iterativeapproach between instance-and schema-level refinements; until convergence [6; 7]. In thiswork; we annotate Web tables using ontology matching. As this field has solid tools andbenchmarks3; we design a framework that provides the required input to any ontologymatching tool; resulting in Web table annotations. Moreover; our blocking enables even theless scalable ontology matching tools provide annotations to large-scale KBs; such as …,OM@ ISWC,2016,2
Vizcurator: A visual tool for curating open data,Bahar Ghadiri Bashardoost; Christina Christodoulakis; Soheil Hassas Yeganeh; Renée J Miller; Kelly Lyons; Oktie Hassanzadeh,Abstract Vizcurator permits the exploration; understanding and curation of open RDF data;its schema; and how it has been linked to other sources. We provide visualizations thatenable one to seamlessly navigate through RDFS and RDF layers and quickly understandthe open data; how it has been mapped or linked; how it has been structured (and could berestructured); and how deeply it has been related to other open data sources. Moreimportantly; Vizcurator provides a rich set of tools for data curation. It suggests possibleimprovements to the structure of the data and enables curators to make informed decisionsabout enhancements to the exploration and exploitation of the data. Moreover; Vizcuratorfacilitates the mining of temporal resources and the definition of temporal constraints throughwhich the curator can identify conflicting facts. Finally; Vizcurator can be used to create …,Proceedings of the 24th International Conference on World Wide Web,2015,2
Next Generation Data Analytics at IBM Research,Oktie Hassanzadeh; Anastasios Kementsietsidis; Benny Kimelfeld; Ippokratis Pandis; Krishnamurthy Rajasekar; Fatma Özcan,IBM Research has a rich history of innovation in information management with severalrevolutionary breakthroughs; including the invention of relational databases; advanced textanalytics demonstrated by Watson; and the first data mining algorithms to name a few. IBMResearch has been committed to contributing to the community via seminal papers;exemplified by several 10-year awards received by IBM researchers. This short abstract isintended as a quick tour of some of the current information management projects; and notmeant to be an exhaustive list by any means. There has been many disruptive technologicaldevelopments over the last decade. The emergence of cloud computing; and several largescale data processing platforms; advances in on-line social media; the explosion of datavolumes; and the advances in hardware have all forced us to rethink the information …,Proceedings of the VLDB Endowment,2013,2
Record linkage for web data,Oktie Hassanzadeh,Record linkage refers to the task of finding and linking records (in a single database or in aset of data sources) that refer to the same entity. Automating the record linkage process is achallenging problem; and has been the topic of extensive research for many years.However; the changing nature of the linkage process and the growing size of data sourcescreate new challenges for this task. This thesis studies the record linkage problem for Webdata sources. Our hypothesis is that a generic and extensible set of linkage algorithmscombined within an easy-to-use framework that integrates and allows tailoring andcombining of these algorithms can be used to effectively link large collections of Web datafrom different domains. To this end; we first present a framework for record linkage overrelational data; motivated by the fact that many Web data sources are powered by …,*,2013,2
A hybrid approach for refreshing web page repositories,Mohammad Ghodsi; Oktie Hassanzadeh; Sh Kamali; M Monemizadeh {ghodsi hassanzadeh kamali monemi}@ ce. sharif. edu,Abstract Web pages change frequently and thus crawlers have to download them often.Various policies have been proposed for refreshing local copies of web pages. In this paper;we introduce a new sampling method that excels over other change detection methods inexperiment. Change Frequency (CF) is a method that predicts the change frequency of thepages and; in the long run; achieves an optimal efficiency in comparison with the samplingmethod. Here; we propose a new hybrid method that is a combination of our new samplingapproach and CF and show how our hybrid method improves the efficiency of changedetection.,Database Systems for Advanced Applications,2005,2
Database query processing using horizontal data record alignment of multi-column range summaries,*,Organizing data within a database is provided. In response to determining that a group ofcoarsified data records within a database table is not an aligned group of data records; avirtually replicated subgroup of coarsified data records that corresponds to the group ofcoarsified data records is generated from different groups of coarsified data records withinthe database table. The virtually replicated subgroup of coarsified data records is alignedwith the corresponding group of coarsified data records.,*,2017,1
Large-scale structural and textual similarity-based mining of knowledge graph to predict drug–drug interactions,Ibrahim Abdelaziz; Achille Fokoue; Oktie Hassanzadeh; Ping Zhang; Mohammad Sadoghi,Abstract Drug–Drug Interactions (DDIs) are a major cause of preventable Adverse DrugReactions (ADRs); causing a significant burden on the patients' health and the healthcaresystem. It is widely known that clinical studies cannot sufficiently and accurately identify DDIsfor new drugs before they are made available on the market. In addition; existing public andproprietary sources of DDI information are known to be incomplete and/or inaccurate and sonot reliable. As a result; there is an emerging body of research on in-silico prediction of drug–druginteractions. In this paper; we present Tiresias; a large-scale similarity-based frameworkthat predicts DDIs through link prediction. Tiresias takes in various sources of drug-relateddata and knowledge as inputs; and provides DDI predictions as outputs. The process startswith semantic integration of the input data that results in a knowledge graph describing …,Web Semantics: Science; Services and Agents on the World Wide Web,2017,1
Matching Web Tables with Knowledge Base Entities: From Entity Lookups to Entity Embeddings,Vasilis Efthymiou; Oktie Hassanzadeh; Mariano Rodriguez-Muro; Vassilis Christophides,Abstract Web tables constitute valuable sources of information for various applications;ranging from Web search to Knowledge Base (KB) augmentation. An underlying commonrequirement is to annotate the rows of Web tables with semantically rich descriptions ofentities published in Web KBs. In this paper; we evaluate three unsupervised annotationmethods:(a) a lookup-based method which relies on the minimal entity context provided inWeb tables to discover correspondences to the KB;(b) a semantic embeddings method thatexploits a vectorial representation of the rich entity context in a KB to identify the mostrelevant subset of entities in the Web table; and (c) an ontology matching method; whichexploits schematic and instance information of entities available both in a KB and a Webtable. Our experimental evaluation is conducted using two existing benchmark data sets …,ISWC,2017,1
Linking Data Elements Based on Similarity Data Values and Semantic Annotations,*,Data elements from data sources and having a data value set are linked by using hashfunctions to determine a dimensionally reduced instance signature for each data elementbased on all data values associated with that data element to yield a plurality ofdimensionally reduced instance signatures of equivalent fixed size such that similaritiesamong the data values in the data value sets across all data elements is maintained amongthe plurality of instance signatures. Candidate pairs of data elements to link are identifiedusing the plurality of instance signatures in locality sensitive hash functions; and a similarityindex is generated for each candidate pair using a pre-determined measure of similarity.Candidate pairs of data elements having a similarity index above a given threshold arelinked.,*,2013,1
Publishing Relational Databases as Linked Data,Oktie Hassanzadeh,□ Part 1: How to Publish Linked Data on the Web … □ Part 2: How to Publish Relational Databasesas … Slides by Tom Heath; available at http://tomheath.com/slides/2009-07-cercedilla-how-to-publish-linked-data.pdf … 3. Choose URIs for Things in your Data … Slides by Tom Heath;available at http://tomheath.com/slides/2009-07-cercedilla-how-to-publish-linked-data.pdf …Slides by Tom Heath; available at http://tomheath.com/slides/2009-07-cercedilla-how-to-publish-linked-data.pdf … □ allows people to look up those names … Slides by Tom Heath; availableat http://tomheath.com/slides/2009-07-cercedilla-how-to-publish-linked-data.pdf … Slides byTom Heath; available at http://tomheath.com/slides/2009-07-cercedilla-how-to-publish-linked-data.pdf … □ What are the key things present in your data … Slides by Tom Heath; availableat http://tomheath.com/slides/2009-07-cercedilla-how-to-publish-linked-data.pdf,*,2011,1
Automated Protein Structure Classification: A Survey,Oktie Hassanzadeh,Abstract: Classification of proteins based on their structure provides a valuable resource forstudying protein structure; function and evolutionary relationships. With the rapidlyincreasing number of known protein structures; manual and semi-automatic classification isbecoming ever more difficult and prohibitively slow. Therefore; there is a growing need forautomated; accurate and efficient classification methods to generate classificationdatabases or increase the speed and accuracy of semi-automatic techniques. Recognizingthis need; several automated classification methods have been developed. In this survey;we overview recent developments in this area. We classify different methods based on theircharacteristics and compare their methodology; accuracy and efficiency. We then present afew open problems and explain future directions.,arXiv preprint arXiv:0907.1990,2009,1
Expressive Temporal Predictions Over Semantically Driven Time Windows,*,Abstract Methods; systems; and computer program products for expressive temporalpredictions over semantically-driven time windows are provided herein. A computer-implemented method includes identifying; within a knowledge graph pertaining to a givenprediction; a subset of the knowledge graph related to one or more predicted trainingexamples; wherein the subset comprises (i) a set of nodes and (ii) one or more relationshipsamong the set of nodes; determining; for the identified subset; one or more snapshots of theknowledge graph relevant to the given prediction; quantifying a validity window for the oneor more predicted training examples; wherein the validity window comprises a temporalbound for prediction validity; and computing a validity window for the given prediction basedon the quantified validity window for the one or more predicted training examples.,*,2018,*
Matching Web Tables with Knowledge Base Entities: From Entity Lookups to Entity Embeddings,Vassilis Christophides; Vasilis Efthymiou; Oktie Hassanzadeh; Mariano Rodriguez-Muro,*,2017 International Semantic Web Conference (ISWC),2017,*
Method and apparatus for identifying semantically related records,*,An apparatus and method of identifying semantically related records; including receivinginput data from an input device; splitting the input data into a plurality of clusters according tosemantic relationship; each of the clusters including a plurality of source terms and aplurality of target terms; transforming each of the plurality of clusters based on thetransformation which includes tokenization of the plurality of clusters; for each of the pluralityof clusters that are transformed; finding relatedness scores of a plurality of semanticrelatedness measures with the plurality of target terms; building a vector of similarity scoresfor each of the plurality of target terms; and for each of the plurality of source terms; selectinga predetermined number of the plurality of target terms according to the similarity scores.,*,2017,*
System; method; and recording medium for knowledge graph augmentation through schema extension,*,A method; system; and recording medium for knowledge graph augmentation using databased on a statistical analysis of attributes in the data; including mapping classes; attributes;and instances of the classes of the data; indexing semantically similar input data elementsbased on the mapped data using at least one of a label-based analysis; a content-basedanalysis; and an attribute-based clustering; and ranking the semantically similar input dataelements to create a ranked list.,*,2017,*
Prediction of adverse drug events,*,Embodiments include method; systems and computer program products for predictingadverse drug events on a computational system. Aspects include receiving known drug datafrom drug databases and one or more of a candidate drug; a drug pair; and a candidate drug-patient pair. Aspects also include calculating an adverse event prediction ratingrepresenting a confidence level of an adverse drug event for the candidate drug; a drug pair;and a candidate drug-patient pair; the rating being based on the known drug data. Aspectsalso include associating adverse event features with the candidate drug; drug pair; or acandidate drug-patient pair; including a nature; cause; mechanism; or severity of theadverse drug event. Aspects also include calculating and outputting an adverse eventprediction rating.,*,2017,*
Prediction of adverse drug events,*,Embodiments include method; systems and computer program products for predictingadverse drug events on a computational system. Aspects include receiving known drug datafrom drug databases and one or more of a candidate drug; a drug pair; and a candidate drug-patient pair. Aspects also include calculating an adverse event prediction ratingrepresenting a confidence level of an adverse drug event for the candidate drug; a drug pair;and a candidate drug-patient pair; the rating being based on the known drug data. Aspectsalso include associating adverse event features with the candidate drug; drug pair; or acandidate drug-patient pair; including a nature; cause; mechanism; or severity of theadverse drug event. Aspects also include calculating and outputting an adverse eventprediction rating.,*,2017,*
Uniform search; navigation and combination of heterogeneous data,*,A unified interface that abstracts the underlying differences among heterogeneous datasources and data formats to produce uniform search results. While the result of an initialsearch may be exactly what the user was seeking; it is likely that the result is in theneighborhood of what was sought. It may aid the end user to provide guided data navigationsuggestions to locate related data during data exploration; by providing analysis to identifydata similarities among disparate data sources; and by providing guided combinationoptions. The guided data navigation suggestions may include suggestions based onschematic; semantic; and social information. Guided data navigation may aid the user inmoving from the initial search landing point in the data to the precise result sought.,*,2017,*
OM-2017: Proceedings of the Twelfth International Workshop on Ontology Matching,Pavel Shvaiko; Jérôme Euzenat; Ernesto Jiménez-Ruiz; Michelle Cheatham; Oktie Hassanzadeh,Ontology matching is a key interoperability enabler for the semantic web; as well as a usefultactic in some classical data integration tasks dealing with the semantic heterogeneityproblem. It takes ontologies as input and determines as output an alignment; that is; a set ofcorrespondences between the semantically related entities of those ontologies. Thesecorrespondences can be used for various tasks; such as ontology merging; data translation;query answering or navigation on the web of data. Thus; matching ontologies enables theknowledge and data expressed with the matched ontologies to interoperate.,*,2017,*
Semantic Concept Discovery Over Event Data,Oktie Hassanzadeh; Shari Trewin; Alfio Gliozzo,*,ISWC,2017,*
Uniform search; navigation and combination of heterogeneous data,*,A method and system for interfacing with an end user to search; navigate; and combinelarge numbers of heterogeneous data sources with varying data characteristics. End userentered search terms are received and the end user is then presented a guided explorationincluding search results and search result details. The end user is also presented with aguided combination including search result combination options and combination details.Both the guided exploration and guided combination render all data from the heterogeneousdata sources in a uniform data format and both can culminate in saving selected results.,*,2016,*
Towards Large-Scale Predictive Drug Safety: A Computational Framework for Inferring Drug Interactions Through Similarity-Based Link Prediction.,Achille Fokoue; Ping Zhang; Oktie Hassanzadeh; Mohammad Sadoghi,Drug-Drug Interactions (DDIs) may happen unexpectedly when more than one drugs are co-prescribed; causing serious side effects. Discovering and predicting DDIs will not onlyprevent life-threatening consequence in clinical practice; but also prompt safe drug co-prescriptions for better treatments. In this study; we propose a computational framework thattakes in various sources of drug-related data and knowledge as input; and provides asoutput a list of potential DDIs along with an explanation for each DDI.,AMIA,2016,*
Tiresias: Knowledge Engineering and Large-Scale Machine Learning for Interpretable Drug-Drug Interaction Prediction.,Achille Fokoue; Oktie Hassanzadeh; Mohammad Sadoghi; Ping Zhang,Abstract Accurate prediction of potential Drug-Drug Interactions (DDIs) is a majorrequirement both in drug development and in patient care. In this demonstration; we presentTiresias; a system that takes in heterogeneous sources of knowledge as input and providesas output an accurate and interpretable prediction of potential drug-drug interactions. Wewill show various components of the system that perform knowledge curation from publicsources of drug data; large-scale similarity analysis across all drugs using several similaritymeasures; and feature selection and efficient learning using a logistic regression model tonot only predict potential DDIs; but also explain the reason behind each prediction. We willshow an evaluation of the system using knowledge derived from an old drug database from2011; verifying the predictions and explanations with recently discovered interactions and …,AMIA,2016,*
LinkedCT Live: Platform for Online Curation of Clinical Trials Data.,Oktie Hassanzadeh; Renée J Miller; Fatemeh Nargesian; Erkang Zhu,Abstract. The goal of the Linked Clinical Trials (LinkedCT) project is to transform the datapublished on ClinicalTrials. gov into a highquality knowledge base published as LinkedData on the Web. In this demonstration; we present the platform we have developed for bothonline curation of clinical trials data into linked data; and for rapid Web applicationdevelopment on top of this linked data. We also show a few sample applications built usingthis platform. We have made the project open-source and invite researchers and healthcareprofessionals to develop applications that will be hosted on LinkedCT. org.,International Semantic Web Conference (Posters & Demos),2015,*
Markov Argumentation Random Fields-based Linchpin Sensitivity Analysis,Yuqing Tang; Katia Sycara; Jeff Z Pan; Achille Fokoue,*,*,2014,*
Linking Data Elements Based on Similarity Data Values and Semantic Annotations,*,Data elements from data sources and having a data value set are linked by using hashfunctions to determine a dimensionally reduced instance signature for each data elementbased on all data values associated with that data element to yield a plurality ofdimensionally reduced instance signatures of equivalent fixed size such that similaritiesamong the data values in the data value sets across all data elements is maintained amongthe plurality of instance signatures. Candidate pairs of data elements to link are identifiedusing the plurality of instance signatures in locality sensitive hash functions; and a similarityindex is generated for each candidate pair using a pre-determined measure of similarity.Candidate pairs of data elements having a similarity index above a given threshold arelinked.,*,2013,*
Proc. 7th ISWC workshop on ontology matching (OM),Pavel Shvaiko; Jérôme Euzenat; Anastasios Kementsietsidis; Ming Mao; Natalya Noy; Heiner Stuckenschmidt,No abstract available.,*,2012,*
BibBase triplified,Oktie Hassanzadeh; Reynold S Xin; Christian Fritz; Yang Yang; Jiang Du; Minghua Zhao; Renée J Miller,Abstract We present BibBase; a system for publishing and managing bibliographic dataavailable in BibTeX files. BibBase uses a powerful yet light-weight approach to transformBibTeX files into rich triplified data as well as custom HTML and RSS code that can readilybe integrated within a user's website while the data can instantly be queried online on thesystem's SPARQL endpoint. In this short report; we present a brief overview of the features ofour system and outline a few research challenges in building such a system.,Proceedings of the 6th International Conference on Semantic Systems,2010,*
ENABLING TAILORED THERAPEUTICS WITH LINKED DATA,Oktie Hassanzadeh; Anja Jentzsch; Bo Andersson; Susie Stephens; Christian Bizer; Linking Open Drug Data LODD Task Froce,Data set Number of links LinkedCT 290;000 links; 50;000 of them inside the LODD cloudDrugBank 23;000 links; 8;500 of them inside the LODD cloud DailyMed 29;600 links; all ofthem inside the LODD cloud Diseasome 23;000 links; 8;400 of them inside the LODD cloudTotal 365;600 links; 8.4 million triples,*,2009,*
Semantic Concept Discovery Over Event Databases,Oktie Hassanzadeh; Shari Trewin; Alfio Gliozzo,Abstract. In this paper; we study the problem of identifying certain types of concept (eg;persons; organizations; topics) for a given analysis question with the goal of assisting ahuman analyst in writing a deep analysis report. We consider a case where we have a largeevent database describing events and their associated news articles along with meta-datadescribing various event attributes such as people and organizations involved and the topicof the event. We describe the use of semantic technologies in question understanding anddeep analysis of the event database; and show a detailed evaluation of our proposedconcept discovery techniques using reports from Human Rights Watch organization andother sources. Our study finds that combining our neural network based semantic termembeddings over structured data with an index-based method can significantly …,*,*,*
Towards Comprehensive Noise Detection in Automatically-Created Knowledge Graphs,Nandana Mihindukulasooriya; Oktie Hassanzadeh; Sarthak Dash; Alfio Gliozzo,Abstract. Knowledge Graphs (KGs) play a key role in many artificial intelligence applications.Large KGs are often constructed through a noisy automatic knowledge extraction process.Noise detection is; therefore; an important task for having high-quality KGs. We argue thatthe current noise detection approaches only focus on a specific type of noise (ie; factchecking) whereas knowledge extraction methods result in more than one type of noise. Tothis end; we propose a classification of noise found in automatically-constructed KGs; andan approach for noise detection focused on specific types of noise.,*,*,*
Tiresias: Predicting Drug-Drug Interactions Through Large-Scale Similarity-Based Link Prediction,Achille Fokoue; Mohammad Sadoghi; Oktie Hassanzadeh; Ping Zhang,Page 1. Tiresias: Predicting Drug- Drug Interactions Through Large-Scale Similarity- Based LinkPrediction Achille Fokoue Mohammad Sadoghi Oktie Hassanzadeh Ping Zhang Page 2. AdverseDrug Reactions pose a serious challenge to the healthcare system Over 2 million $136 billionoften do not reveal rare toxicity of some drugs of in-hospital medication errors caused byunforeseen drug-drug interactions serious adverse drug reactions (ADRs) yearly: 100;000 deathsADR associated cost yearly ( > diabetic & cardiovascular care) Clinical Trials 3–5% Source:Flockhart et al.: Preventable adverse drug reactions: A focus on drug interactions. Centers forEducation & Research on Therapeutics Page 3. Similarity-based Drug-Drug Interaction (DDI)Predictions [Gottlieb et al.; Vilar et al.; Zhang et al.; etc.] • Inspired from content-basedrecommender systems: Predict the existence of an DDI through …,Clinical Trials,*,*
