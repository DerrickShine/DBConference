Diagnosing Performance Changes by Comparing Request Flows.,Raja R Sambasivan; Alice X Zheng; Michael De Rosa; Elie Krevat; Spencer Whitman; Michael Stroucken; William Wang; Lianghong Xu; Gregory R Ganger,Abstract The causes of performance changes in a distributed system often elude even itsdevelopers. This paper develops a new technique for gaining insight into such changes:comparing request flows from two executions (eg; of two system versions or time periods).Building on end-to-end request-flow tracing within and across components; algorithms aredescribed for identifying and ranking changes in the flow and/or timing of requestprocessing. The implementation of these algorithms in a tool called Spectroscope isevaluated. Six case studies are presented of using Spectroscope to diagnose performancechanges in a distributed storage service caused by code changes; configurationmodifications; and component degradations; demonstrating the value and efficacy ofcomparing request flows. Preliminary experiences of using Spectroscope to diagnose …,NSDI,2011,145
Packet classification algorithms: From theory to practice,Yaxuan Qi; Lianghong Xu; Baohua Yang; Yibo Xue; Jun Li,During the past decade; the packet classification problem has been widely studied toaccelerate network applications such as access control; traffic engineering and intrusiondetection. In our research; we found that although a great number of packet classificationalgorithms have been proposed in recent years; unfortunately most of them stagnate inmathematical analysis or software simulation stages and few of them have beenimplemented in commercial products as a generic solution. To fill the gap between theoryand practice; in this paper; we propose a novel packet classification algorithm namedHyperSplit. Compared to the well-known HiCuts and HSM algorithms; HyperSplit achievessuperior performance in terms of classification speed; memory usage and preprocessingtime. The practicability of the proposed algorithm is manifested by two facts in our test …,INFOCOM 2009; IEEE,2009,124
Exertion-based Billing for Cloud Storage Access.,Matthew Wachs; Lianghong Xu; Arkady Kanevsky; Gregory R Ganger,Abstract Charging for cloud storage must account for two costs: the cost of the capacity usedand the cost of access to that capacity. For the cost of access; current systems focus on thework requested; such as data transferred or I/O operations completed; rather than theexertion (ie; effort/resources expended) to complete that work. But; the provider's cost isbased on the exertion; and the exertion for a given amount of work can vary dramaticallybased on characteristics of the workload; making current charging models unfair to tenants;provider; or both. This paper argues for exertion-based metrics; such as disk time; for theaccess cost component of cloud storage billing. It also discusses challenges in supportingfair and predictable exertion accounting; such as significant interworkload interferenceeffects for storage access; and a performance insulation approach to addressing them.,HotCloud,2011,25
SpringFS: bridging agility and performance in elastic distributed storage.,Lianghong Xu; James Cipar; Elie Krevat; Alexey Tumanov; Nitin Gupta; Michael A Kozuch; Gregory R Ganger,Abstract Elastic storage systems can be expanded or contracted to meet current demand;allowing servers to be turned off or used for other tasks. However; the usefulness of anelastic distributed storage system is limited by its agility: how quickly it can increase ordecrease its number of servers. Due to the large amount of data they must migrate duringelastic resizing; state-of-the-art designs usually have to make painful tradeoffs amongperformance; elasticity and agility. This paper describes an elastic storage system; calledSpringFS; that can quickly change its number of active servers; while retaining elasticity andperformance goals. SpringFS uses a novel technique; termed bounded write offloading; thatrestricts the set of servers where writes to overloaded servers are redirected. This technique;combined with the read offloading and passive migration policies used in SpringFS …,FAST,2014,22
Exploiting iterative-ness for parallel ML computations,Henggang Cui; Alexey Tumanov; Jinliang Wei; Lianghong Xu; Wei Dai; Jesse Haber-Kucharsky; Qirong Ho; Gregory R Ganger; Phillip B Gibbons; Garth A Gibson; Eric P Xing,Abstract Many large-scale machine learning (ML) applications use iterative algorithms toconverge on parameter values that make the chosen model fit the input data. Often; thisapproach results in the same sequence of accesses to parameters repeating each iteration.This paper shows that these repeating patterns can and should be exploited to improve theefficiency of the parallel and distributed ML applications that will be a mainstay in cloudcomputing environments. Focusing on the increasingly popular" parameter server" approachto sharing model parameters among worker threads; we describe and demonstrate how therepeating patterns can be exploited. Examples include replacing dynamic cache and serverstructures with static pre-serialized structures; informing prefetch and partitioning decisions;and determining which data should be cached at each thread to avoid both contention …,Proceedings of the ACM Symposium on Cloud Computing,2014,17
Para-snort: A multi-thread snort on multi-core ia platform,Xinming Chen; Yiyao Wu; Lianghong Xu; Yibo Xue; Jun Li,ABSTRACT As security threats and network bandwidth increase in a very fast pace; there isa growing interest in designing highperformance network intrusion detection system (NIDS).This paper presents a parallelization strategy for the popular open-source Snort to build ahigh performance NIDS on multi-core IA platform. A modular design of parallel NIDS basedon Snort is proposed in this paper. Named Para-Snort; it enables flexible and easy moduledesign. This paper also analyzed the performance impact of load balancing and multi-pattern matching. Modified-JSQ and AC-WM algorithms are implemented in order to resolvethe bottlenecks and improve the performance of the system.,Proceedings of Parallel and Distributed Computing and Systems (PDCS),2009,17
SmartScan: Efficient metadata crawl for storage management metadata querying in large file systems,Likun Liu; Lianghong Xu; Yongwei Wu; Guangwen Yang; Gregory R Ganger,Abstract SmartScan is a metadata crawl tool that exploits patterns in metadata changes tosignificantly improve the efficiency of support for file-system-wide metadata querying; whichis an important tool for administrators. In most environments; support for metadata queries isprovided by databases populated and refreshed by calling stat () on every file in the filesystem. For large file systems; where such storage management tools are most needed; itcan take many hours to complete each scan; even if only a small percentage of the fileshave changed. To address this issue; we identify patterns in metadata changes that can beexploited to restrict scanning to the small subsets of directories that have recently hadmodified files or that have high variation in file change times. Experiments with usingSmartScan on production file systems show that exploiting metadata change patterns can …,Parallel Data Laboratory,2010,8
Agility and Performance in Elastic Distributed Storage,Lianghong Xu; James Cipar; Elie Krevat; Alexey Tumanov; Nitin Gupta; Michael A Kozuch; Gregory R Ganger,Abstract Elastic storage systems can be expanded or contracted to meet current demand;allowing servers to be turned off or used for other tasks. However; the usefulness of anelastic distributed storage system is limited by its agility: how quickly it can increase ordecrease its number of servers. Due to the large amount of data they must migrate duringelastic resizing; state of the art designs usually have to make painful trade-offs amongperformance; elasticity; and agility. This article describes the state of the art in elastic storageand a new system; called SpringFS; that can quickly change its number of active servers;while retaining elasticity and performance goals. SpringFS uses a novel technique; termedbounded write offloading; that restricts the set of servers where writes to overloaded serversare redirected. This technique; combined with the read offloading and passive migration …,ACM Transactions on Storage (TOS),2014,6
Diagnosing performance changes by comparing system behaviours,Raja R Sambasivan; Alice X Zheng; Elie Krevat; Spencer Whitman; Michael Stroucken; William Wang; Lianghong Xu; Gregory R Ganger,Abstract: The causes of performance changes in a distributed system often elude even itsdevelopers. This paper develops a new technique for gaining insight into such changes:comparing system behaviours from two executions (eg; of two system versions or timeperiods). Building on end-to-end request flow tracing within and across components;algorithms are described for identifying and ranking changes in the flow and/or timing ofrequest processing. The implementation of these algorithms in a tool called Spectroscope isdescribed and evaluated. Five case studies are presented of using Spectroscope todiagnose performance changes in a distributed storage system caused by code changesand configuration modifications; demonstrating the value and efficacy of comparing systembehaviours. Descriptors:* SYSTEMS ENGINEERING; SPECTROSCOPY; MODIFICATION …,*,2010,6
Reducing replication bandwidth for distributed document databases,Lianghong Xu; Andew Pavlo; Sudipta Sengupa; Jin Li; Gregory R. Ganger,Abstract With the rise of large-scale; Web-based applications; users are increasinglyadopting a new class of document-oriented database management systems (DBMSs) thatallow for rapid prototyping while also achieving scalable performance. Like for otherdistributed storage systems; replication is important for document DBMSs in order toguarantee availability. The network bandwidth required to keep replicas synchronized isexpensive and is often a performance bottleneck. As such; there is a strong need to reducethe replication bandwidth; especially for geo-replication scenarios where wide-area network(WAN) bandwidth is limited. This paper presents a deduplication system called sDedup thatreduces the amount of data transferred over the network for replicated document DBMSs.sDedup uses similarity-based deduplication to remove redundancy in replication data by …,Proceedings of the Sixth ACM Symposium on Cloud Computing (SoCC),2015,5
JackRabbit: Improved agility in elastic distributed storage,James Cipar; Lianghong Xu; Elie Krevat; Alexey Tumanov; Nitin Gupta; Michael A Kozuch; Gregory R Ganger,Distributed storage can and should be elastic; just like other aspects of cloud computing.When storage is provided via single-purpose storage devices or servers; elasticity is usefulfor reducing energy usage. For storage provided via multi-purpose servers; however; suchelasticity is needed to provide the cloud infrastructure with the freedom to use those serversfor other purposes; which may be particularly important for increasingly prevalent data-intensive computing activities (eg; data analytics). Unfortunately; most distributed storage isnot elastic. The Hadoop Distributed File System (HDFS)[1]; for example; uses a psuedo-random data layout mainly for data availability and load balancing. But; such a data layoutprevents elasticity by requiring that almost all nodes be active—no more than one node perrack can be turned off without a high likelihood of making some data unavailable.,*,2012,2
Hadoop performance monitoring tools,Kai Ren; Lianghong Xu; Zongwei Zhou,*,*,*,1
Online Deduplication for Databases,Lianghong Xu; Andrew Pavlo; Sudipta Sengupta; Gregory R Ganger,Abstract dbDedup is a similarity-based deduplication scheme for on-line databasemanagement systems (DBMSs). Beyond block-level compression of individual databasepages or operation log (oplog) messages; as used in today's DBMSs; dbDedup uses byte-level delta encoding of individual records within the database to achieve greater savings.dbDedup's single-pass encoding method can be integrated into the storage and loggingcomponents of a DBMS to provide two benefits:(1) reduced size of data stored on diskbeyond what traditional compression schemes provide; and (2) reduced amount of datatransmitted over the network for replication services. To evaluate our work; we implementeddbDedup in a distributed NoSQL DBMS and analyzed its properties using four real datasets.Our results show that dbDedup achieves up to 37x reduction in the storage size and …,Proceedings of the 2017 ACM International Conference on Management of Data,2017,*
Similarity-based Deduplication for Databases,Lianghong Xu; Andrew Pavlo; Sudipta Sengupta; Gregory R Ganger,The rate of data growth outpaces the decline of hardware costs. Database compression isone solution to this problem. For database storage; in addition to space saving; compressionhelps reduce the number of disk I/Os and improve performance; because queried data fits infewer pages. For distributed databases replicated across geographical regions; there is alsoa strong need to reduce the amount of data transfer used to keep replicas in sync. The mostwidely used approach for data reduction in DBMSs is block-level compression [29; 36; 44;41; 3; 16]. Although this method is simple and effective; it fails to address redundancy acrossblocks and therefore leaves significant room for improvement for many applications (eg; dueto app-level versioning in wikis or partial record copying in message boards). Deduplication(dedup) has become popular in backup systems for eliminating duplicate content across …,*,2016,*
Online Deduplication for Distributed Databases,Lianghong Xu,Abstract The rate of data growth outpaces the decline of hardware costs; and there has beenan ever-increasing demand in reducing the storage and network overhead for onlinedatabase management systems (DBMSs). The most widely used approach for datareduction in DBMSs is block-level compression. Although this method is simple andeffective; it fails to address redundancy across blocks and therefore leaves significant roomfor improvement for many applications.,*,2016,*
