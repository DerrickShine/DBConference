A comparison of join algorithms for log processing in mapreduce,Spyros Blanas; Jignesh M Patel; Vuk Ercegovac; Jun Rao; Eugene J Shekita; Yuanyuan Tian,Abstract The MapReduce framework is increasingly being used to analyze large volumes ofdata. One important type of data analysis done with MapReduce is log processing; in whicha click-stream or an event log is filtered; aggregated; or mined for patterns. As part of thisanalysis; the log often needs to be joined with reference data such as information aboutusers. Although there have been many studies examining join algorithms in parallel anddistributed DBMSs; the MapReduce framework is cumbersome for joins. MapReduceprogrammers often use simple but inefficient algorithms to perform joins. In this paper; wedescribe crucial implementation details of a number of well-known join strategies inMapReduce; and present a comprehensive experimental comparison of these jointechniques on a 100-node Hadoop cluster. Our results provide insights that are unique to …,Proceedings of the 2010 ACM SIGMOD International Conference on Management of data,2010,465
Design and evaluation of main memory hash join algorithms for multi-core CPUs,Spyros Blanas; Yinan Li; Jignesh M Patel,Abstract The focus of this paper is on investigating efficient hash join algorithms for modernmulti-core processors in main memory environments. This paper dissects each internalphase of a typical hash join algorithm and considers different alternatives for implementingeach phase; producing a family of hash join algorithms. Then; we implement these mainmemory algorithms on two radically different modern multi-processor systems; and carefullyexamine the factors that impact the performance of each method. Our analysis reveals someinteresting results--a very simple hash join algorithm is very competitive to the other morecomplex methods. This simple join algorithm builds a shared hash table and does notpartition the input relations. Its simplicity implies that it requires fewer parameter settings;thereby making it far easier for query optimizers and execution engines to use it in …,Proceedings of the 2011 ACM SIGMOD International Conference on Management of data,2011,176
High-performance concurrency control mechanisms for main-memory databases,Per-Åke Larson; Spyros Blanas; Cristian Diaconu; Craig Freedman; Jignesh M Patel; Mike Zwilling,Abstract A database system optimized for in-memory storage can support much highertransaction rates than current systems. However; standard concurrency control methodsused today do not scale to the high transaction rates achievable by such systems. In thispaper we introduce two efficient concurrency control methods specifically designed for main-memory databases. Both use multiversioning to isolate read-only transactions from updatesbut differ in how atomicity is ensured: one is optimistic and one is pessimistic. To avoidexpensive context switching; transactions never block during normal processing but theymay have to wait before commit to ensure correct serialization ordering. We alsoimplemented a main-memory optimized version of single-version locking. Experimentalresults show that while single-version locking works well when transactions are short and …,Proceedings of the VLDB Endowment,2011,159
Orthogonal Security with Cipherbase.,Arvind Arasu; Spyros Blanas; Ken Eguro; Raghav Kaushik; Donald Kossmann; Ravishankar Ramamurthy; Ramarathnam Venkatesan,ABSTRACT This paper describes the design of the Cipherbase system. Cipherbase is a full-fledged SQL database system that achieves high performance and high data confidentialityby storing and processing strongly encrypted data. The Cipherbase system incorporatescustomized trusted hardware; extending Microsoft's SQL Server for efficient execution ofqueries using both secure hardware and commodity servers. This paper presents the designof the Cipherbase secure hardware and its implementation using FPGAs. Furthermore; thispaper shows how we addressed hardware/software co-design in the Cipherbase system.,CIDR,2013,114
Parallel data analysis directly on scientific file formats,Spyros Blanas; Kesheng Wu; Surendra Byna; Bin Dong; Arie Shoshani,Abstract Scientific experiments and large-scale simulations produce massive amounts ofdata. Many of these scientific datasets are arrays; and are stored in file formats such asHDF5 and NetCDF. Although scientific data management systems; such as SciDB; aredesigned to manipulate arrays; there are challenges in integrating these systems intoexisting analysis workflows. Major barriers include the expensive task of preparing andloading data before querying; and converting the final results to a format that is understoodby the existing post-processing and visualization tools. As a consequence; integrating a datamanagement system into an existing scientific data analysis workflow is time-consuming andrequires extensive user involvement. In this paper; we present the design of a new scientificdata analysis system that efficiently processes queries directly over data stored in the …,Proceedings of the 2014 ACM SIGMOD international conference on Management of data,2014,41
Secure database-as-a-service with cipherbase,Arvind Arasu; Spyros Blanas; Ken Eguro; Manas Joglekar; Raghav Kaushik; Donald Kossmann; Ravi Ramamurthy; Prasang Upadhyaya; Ramarathnam Venkatesan,Abstract Data confidentiality is one of the main concerns for users of public cloud services.The key problem is protecting sensitive data from being accessed by cloud administratorswho have root privileges and can remotely inspect the memory and disk contents of thecloud servers. While encryption is the basic mechanism that can leveraged to provide dataconfidentiality; providing an efficient database-as-a-service that can run on encrypted dataraises several interesting challenges. In this demonstration we outline the functionality ofCipherbase---a full fledged SQL database system that supports the full generality of adatabase system while providing high data confidentiality. Cipherbase has a novelarchitecture that tightly integrates custom-designed trusted hardware for performingoperations on encrypted data securely such that an administrator cannot get access to …,Proceedings of the 2013 ACM SIGMOD International Conference on Management of Data,2013,30
Contention-based performance evaluation of multidimensional range search in peer-to-peer networks,Spyros Blanas; Vasilis Samoladas,Abstract Performance evaluation of peer-to-peer search techniques has hitherto been basedon simple performance metrics; such as message hop counts and total network traffic; mostlydisregarding the inherently concurrent nature of peer-to-peer networks; where contentionmay arise. This paper is concerned with quantifying the effects of contention in P2Pnetworks; focusing on networks for multidimensional range search. We evaluate peer-to-peer networks derived from recently proposed works; introducing two novel metrics relatedto concurrency and contention; namely responsiveness and throughput. Our results highlightthe impact of contention on these networks; and demonstrate that some studied networks donot scale in the presence of contention. Also; our results indicate that certain P2P networkproperties believed to be desirable (eg even data distribution or uniform peer access) …,Future Generation Computer Systems,2009,16
Memory footprint matters: efficient equi-join algorithms for main memory data processing,Spyros Blanas; Jignesh M Patel,Abstract High-performance analytical data processing systems often run on servers withlarge amounts of main memory. A common operation in such environments is combiningdata from two or more sources using some" join" algorithm. The focus of this paper is onstudying hash-based and sort-based equi-join algorithms when the data sets being joinedfully reside in main memory. We only consider a single node setting; which is an importantbuilding block for larger high-performance distributed data processing systems. A criticalcontribution of this work is in pointing out that in addition to query response time; one mustalso consider the memory footprint of each join algorithm; as it impacts the number ofconcurrent queries that can be serviced. Memory footprint becomes an importantdeployment consideration when running analytical data processing services on hardware …,Proceedings of the 4th annual Symposium on Cloud Computing,2013,13
On Transactional Memory; Spinlocks; and Database Transactions.,Khai Q Tran; Spyros Blanas; Jeffrey F Naughton,ABSTRACT Currently; hardware trends include a move toward multicore processors; cheapand persistent variants of memory; and even sophisticated hardware support for mutualexclusion in the form of transactional memory. These trends; coupled with a growing desirefor extremely high performance on short database transactions; raise the question ofwhether the hardware primitives developed for mutual exclusion can be exploited to rundatabase transactions. In this paper; we present a preliminary exploration of this question.We conduct a set of experiments on both a hardware prototype and a simulator of a multi-core processor with Transactional Memory (TM.) Our results show that TM is attractive underlow contention workloads; while spinlocks can tolerate high contention workloads well; andthat in some cases these approaches can beat a simple implementation of a traditional …,ADMS@ VLDB,2010,11
Forecasting the cost of processing multi-join queries via hashing for main-memory databases,Feilong Liu; Spyros Blanas,Abstract Database management systems (DBMSs) carefully optimize complex multi-joinqueries to avoid expensive disk I/O. As servers today feature tens or hundreds of gigabytesof RAM; a significant fraction of many analytic databases becomes memory-resident. Evenafter careful tuning for an in-memory environment; a linear disk I/O model such as the oneimplemented in PostgreSQL may make query response time predictions that are up to 2×slower than the optimal multi-join query plan over memory-resident data. This paperintroduces a memory I/O cost model to identify good evaluation strategies for complex queryplans with multiple hash-based equi-joins over memory-resident data. The proposed costmodel is carefully validated for accuracy using three different systems; including an AmazonEC2 instance; to control for hardware-specific differences. Prior work in parallel query …,Proceedings of the Sixth ACM Symposium on Cloud Computing,2015,9
BCC: Reducing false aborts in optimistic concurrency control with low cost for in-memory databases,Yuan Yuan; Kaibo Wang; Rubao Lee; Xiaoning Ding; Jing Xing; Spyros Blanas; Xiaodong Zhang,Abstract The Optimistic Concurrency Control (OCC) method has been commonly used for in-memory databases to ensure transaction serializability---a transaction will be aborted if itsread set has been changed during execution. This simple criterion to abort transactionscauses a large proportion of false positives; leading to excessive transaction aborts.Transactions aborted false-positively (ie false aborts) waste system resources and cansignificantly degrade system throughput (as much as 3.68 x based on our experiments)when data contention is intensive. Modern in-memory databases run on systems withincreasingly parallel hardware and handle workloads with growing concurrency. They mustefficiently deal with data contention in the presence of greater concurrency by minimizingfalse aborts. This paper presents a new concurrency control method named Balanced …,Proceedings of the VLDB Endowment,2016,8
How efficient is our radix join implementation,Spyros Blanas; Jignesh M Patel,We recently published a paper [2] that examines the design choices available to create ahigh-performance main-memory hash join algorithm. We experimentally evaluated four hashjoin variants on two different architectures; and we showed that an algorithm that does notdo any partitioning on the input tables often outperforms the other more complexpartitioningbased join alternatives. Our claim is that in an environment with a singleprocessor and multiple cores; the non-partitioning method has many advantages over themore complex methods that have been proposed before. If the memory access latencybetween different processors is non-uniform; partitioning will be more beneficial; the non-partitioning method could then be used as a building block for an efficient hash joinalgorithm for data that has been partitioned to each processor (NUMA node). A full …,*,2011,6
Engineering security and performance with cipherbase,Arvind Arasu; Spyros Blanas; Ken Eguro; Manas Joglekar; Raghav Kaushik; Donald Kossmann; Ravi Ramamurthy; Prasang Upadhyaya; Ramarathnam Venkatesan,Abstract Cipherbase is a full-fledged relational database system that leverages novelcustomized hardware to store and process encrypted data. This paper outlines the space ofphysical design options for Cipherbase and shows how application developers canimplement their data confidentiality requirements by specifying the encryption method forstatic data storage and the acceptable information leakage for runtime data processing. Thegoal is to achieve a physical database design with the best possible performance that fulfillsthe application's confidentiality requirements. 1,*,2012,4
Design and Evaluation of an RDMA-aware Data Shuffling Operator for Parallel Database Systems,Feilong Liu; Lingyan Yin; Spyros Blanas,Abstract The commoditization of high-performance networking has sparked research interestin the RDMA capability of this hardware. One-sided RDMA primitives; in particular; havegenerated substantial excitement due to the ability to directly access remote memory fromwithin an application without involving the TCP/IP stack or the remote CPU. This paperconsiders how to leverage RDMA to improve the analytical performance of parallel databasesystems. To shuffle data efficiently using RDMA; one needs to consider a complex designspace that includes (1) the number of open connections;(2) the contention for the sharednetwork interface;(3) the RDMA transport function; and (4) how much memory should bereserved to exchange data between nodes during query processing. We contribute sixdesigns that capture salient trade-offs in this design space. We comprehensively evaluate …,Proceedings of the Twelfth European Conference on Computer Systems,2017,2
Towards exascale scientific metadata management,Spyros Blanas; Surendra Byna,Abstract: Advances in technology and computing hardware are enabling scientists from allareas of science to produce massive amounts of data using large-scale simulations orobservational facilities. In this era of data deluge; effective coordination between the dataproduction and the analysis phases hinges on the availability of metadata that describe thescientific datasets. Existing workflow engines have been capturing a limited form ofmetadata to provide provenance information about the identity and lineage of the data.However; much of the data produced by simulations; experiments; and analyses still need tobe annotated manually in an ad hoc manner by domain scientists. Systematic andtransparent acquisition of rich metadata becomes a crucial prerequisite to sustain andaccelerate the pace of scientific innovation. Yet; ubiquitous and domain-agnostic …,arXiv preprint arXiv:1503.08482,2015,1
ArrayBridge: Interweaving declarative array processing with high-performance computing,Haoyuan Xing; Sofoklis Floratos; Spyros Blanas; Suren Byna; Kesheng Wu; Paul Brown,Abstract: Scientists are increasingly turning to datacenter-scale computers to produce andanalyze massive arrays. Despite decades of database research that extols the virtues ofdeclarative query processing; scientists still write; debug and parallelize imperative HPCkernels even for the most mundane queries. This impedance mismatch has been partlyattributed to the cumbersome data loading process; in response; the database communityhas proposed in situ mechanisms to access data in scientific file formats. Scientists;however; desire more than a passive access method that reads arrays from files. This paperdescribes ArrayBridge; a bi-directional array view mechanism for scientific file formats; thataims to make declarative array manipulations interoperable with imperative file-centricanalyses. Our prototype implementation of ArrayBridge uses HDF5 as the underlying …,arXiv preprint arXiv:1702.08327,2017,*
Query processing for datacenter-scale computers.,Spyros Blanas,Quickly exploring massive datasets requires an efficient data processing platform. Paralleldatabase management systems were originally designed to scale to a handful of nodes;where each node keeps recent (“hot”) data in memory and has directly-attached hard diskstorage for infrequently accessed (“cold”) data. To keep up with the growing data volumes;the research focus is shifting towards rack-scale architectures. Rack-scale databasemanagement systems; including Oracle Exadata; the IBM PureData System and theMicrosoft Analytics Platform System; combine powerful nodes with directly-attached storagefor “warm” data with hundreds of terabytes of network-attached storage for “cold” data.Processing even larger datasets quickly will inevitably require datacenter-scale computers.Although details of the hardware configurations of commercial datacenters are scarce …,CIDR,2017,*
gr2ǫλ: A Greeklish-to-Greek converter,Spyros Blanas,Greeklish is a transliteration of the Greek language written using Roman characters. Thisphenomenon started in the 1980's; when the Greek language was unfortunately covered bymultiple ASCII extensions (codepages) which were incompatible. This lead tocommunication problems; with users being forced to guess the correct encoding of everymessage; document and webpage. Making matters worse; public discussions werefrequently in different encodings; requiring the user to switch encodings to read each reply ina threaded conversation. In the present day; despite the success of Unicode standardization;Greeklish still is the de facto standard for electronic communication. It is used almostexclusively for personal e-mails; instant messages and sometimes even for businesscorrespondance or marketing e-mails! The Academy of Athens swiftly criticized the …,*,2009,*
GRaSP: generalized range search in peer-to-peer networks,Michail Argyriou; Vasilis Samoladas; Spyros Blanas,Abstract We present a framework for generalized range search on trie-structured P2Pnetworks; such as P-Grid. Our techniques exploit hitherto unknown properties of randomizedtries. We prove that a P-Grid like network has routing diameter O (log n) with high probability;as well as O (log n) congestion; regardless of the shape of the underlying trie. Based onthese properties; we propose GRaSP; a simple scheme for handling arbitrary range searchproblems; with search and update hop latency O (log n) with high probability. We then applyGRaSP on two range search problems: multidimensional range search over points andrectangles; and three-sided search. Our empirical results show that GRaSP deliversexcellent search performance and exhibits very good scalability under heavy load. Withrespect to three-sided search; our proposed scheme is distinguished in that it attempts to …,Proceedings of the 3rd international conference on Scalable information systems,2008,*
ICDE 2017 Reviewers,Yannis Papakonstantinou; Lei Chen; Reynold Cheng; Wolfgang Gatterbauer; Bingsheng He; Stratos Idreos; Christopher Jermaine; Chen Li; Gerome Miklau; Tamer Özsu; Olga Papaemmanouil; Evimaria Terzi; Eugene Wu; Ashraf Aboulnaga; Alex Alves; Amazon Gabriel Antoniu; INRIA Arvind Arasu; Andrey Balmin; Workday Zhifeng Bao; Sumita Barahmand; Srikanta Bedathur; Carsten Binnig; Spyros Blanas; Marco Brambilla; Stephane Bressan; K Selcuk Candan; Zhao Cao; James Cheng; Fei Chiang; Panos K Chrysanthis; Philippe Cudre-Mauroux,ICDE 2017 Program Committee Chairs Yannis Papakonstantinou; University of California; SanDiego Yanlei Diao; Ecole Polytechnique; France; and University of Massachusetts; Amherst …ICDE 2017 Area Chairs Lei Chen; Hong Kong University of Science and Technology ReynoldCheng; University of Hong Kong Wolfgang Gatterbauer; Carnegie Mellon University BingshengHe; National University of Singapore Stratos Idreos; Harvard University ChristopherJermaine; Rice University Chen Li; University of California Irvine Gerome Miklau; University ofMassachusetts Tamer Özsu; University of Waterloo Olga Papaemmanouil; Brandeis UniversityEvimaria Terzi; Boston University Eugene Wu; Columbia University … ICDE 2017 Program CommitteeAshraf Aboulnaga; Qatar Computing Research Institute Alex Alves; Amazon Gabriel Antoniu;INRIA Arvind Arasu; Microsoft Research Andrey Balmin; Workday Zhifeng Bao; RMIT …,*,*,*
Data Engineering,Yves-Alexandre de Montjoye; Samuel S Wang; Alex Sandy Pentland,The Data Engineering Bulletin The Bulletin of the Technical Committee on Data Engineeringis published quarterly and is distributed to all TC members. Its scope includes the design;implementation; modelling; theory and application of database systems and theirtechnology. Letters; conference information; and news should be sent to the Editor-in-Chief.Papers for each issue are solicited by and should be sent to the Associate Editorresponsible for the issue. Opinions expressed in contributions are those of the authors anddo not necessarily reflect the positions of the TC on Data Engineering; the IEEE ComputerSociety; or the authors' organizations. The Data Engineering Bulletin web site is at http://tab.computer. org/tcde/bull_about. html.,*,*,*
Addendum to “High-Performance Concurrency Control Mechanisms for Main-Memory Databases”,Per-Ake Larson; Spyros Blanas; Cristian Diaconu; Craig Freedman,Abstract 1. Single-version locking scheduler Proving the single-version locking schemecorrect is trivial; as the scheduler is a 2PL scheduler. 2. Multi-version pessimistic (locking)scheduler The multi-version pessimistic (locking) scheme is in fact a MV2PL scheduler.Holding a certify (commit) lock on a data item in MV2PL is exactly like having theNoMoreReadLocks bit set in the latest version of the data item in our implementation (seeSection 4.2. 1). Section 5.5. 2 of [WV02] describes MV2PL in detail and proves it only admits1SR multi-version histories. 3. Multi-version optimistic scheduler Let us now prove that themulti-version optimistic scheduler only admits 1SR multi-version histories. We use thenotation and theorems from Section 5.2 of [BHG87]. The multi-version optimistic schedulerbehaves like a MVTO scheduler; with the changes described below. Let transaction Tx be …,*,*,*
Performance evaluation of hash joins on chip multiprocessors,Spyros Blanas,ABSTRACT The join operation is computationally the most expensive operation therelational model supports. It has therefore received significant research attention andvarious algorithms have been proposed. Joining via hashing was introduced over twodecades ago and has been shown to possess interesting properties which allow it toparallelize efficiently in parallel database systems. With the advent of chip multiprocessors;which feature multiple cores per chip; there has been significant research interest in makingdatabases run faster by exploiting the parallelism in common database operations.Surprisingly; proposals to enhance database performance on modern CPUs have focusedon minimizing instruction and level-2 cache misses; typically via prefetching. The scalabilityof existing algorithms on multiple cores has been largely overlooked. To answer this …,*,*,*
