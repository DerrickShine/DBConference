ESP: Path-sensitive program verification in polynomial time,Manuvir Das; Sorin Lerner; Mark Seigle,Abstract In this paper; we present a new algorithm for partial program verification that runs inpolynomial time and space. We are interested in checking that a program satisfies a giventemporal safety property. Our insight is that by accurately modeling only those branches in aprogram for which the property-related behavior differs along the arms of the branch; we candesign an algorithm that is accurate enough to verify the program with respect to the givenproperty; without paying the potentially exponential cost of full path-sensitive analysis. Wehave implemented this" property simulation" algorithm as part of a partial verification toolcalled ESP. We present the results of applying ESP to the problem of verifying the file I/Obehavior of a version of the GNU C compiler (gcc; 140;000 LOC). We are able to prove thatall of the 646 calls to. fprintf in the source code of gcc are guaranteed to print to valid …,ACM Sigplan Notices,2002,619
Staged information flow for JavaScript,Ravi Chugh; Jeffrey A Meister; Ranjit Jhala; Sorin Lerner,Abstract Modern websites are powered by JavaScript; a flexible dynamic scripting languagethat executes in client browsers. A common paradigm in such websites is to include third-party JavaScript code in the form of libraries or advertisements. If this code were malicious; itcould read sensitive information from the page or write to the location bar; thus redirectingthe user to a malicious page; from which the entire machine could be compromised. Wepresent an information-flow based approach for inferring the effects that a piece ofJavaScript has on the website in order to ensure that key security properties are not violated.To handle dynamically loaded and generated JavaScript; we propose a framework forstaging information flow properties. Our framework propagates information flow through thecurrently known code in order to compute a minimal set of syntactic residual checks that …,ACM Sigplan Notices,2009,267
RELAY: static race detection on millions of lines of code,Jan Wen Voung; Ranjit Jhala; Sorin Lerner,Abstract Data races occur when multiple threads are about to access the same piece ofmemory; and at least one of those accesses is a write. Such races can lead to hard-to-reproduce bugs that are time consuming to debug and fix. We present R ELAY; a static andscalable race detection analysis in which unsoundness is modularized to a few sources. Wedescribe the analysis and results from our experiments using R ELAY to find data races inthe Linux kernel; which includes about 4.5 million lines of code.,Proceedings of the the 6th joint meeting of the European software engineering conference and the ACM SIGSOFT symposium on The foundations of software engineering,2007,255
An empirical study of privacy-violating information flows in JavaScript web applications,Dongseok Jang; Ranjit Jhala; Sorin Lerner; Hovav Shacham,Abstract The dynamic nature of JavaScript web applications has given rise to the possibilityof privacy violating information flows. We present an empirical study of the prevalence ofsuch flows on a large number of popular websites. We have (1) designed an expressive; fine-grained information flow policy language that allows us to specify and detect different kindsof privacy-violating flows in JavaScript code;(2) implemented a new rewriting-basedJavaScript information flow engine within the Chrome browser; and (3) used the enhancedbrowser to conduct a large-scale empirical study over the Alexa global top 50;000 websitesof four privacy-violating flows: cookie stealing; location hijacking; history sniffing; andbehavior tracking. Our survey shows that several popular sites; including Alexa global top-100 sites; use privacy-violating flows to exfiltrate information about users' browsing …,Proceedings of the 17th ACM conference on Computer and communications security,2010,186
Mojo: A dynamic optimization system,Wen-Ke Chen; Sorin Lerner; Ronnie Chaiken; David M Gillies,Abstract Dynamic optimization systems have the flexibility to adapt program execution tochanging scenarios and differing hardware configurations. Previous work has shown thatthis flexibility can be exploited for sizeable performance improvement. Yet; the work to datehas been chiefly targeted towards running the SPEC benchmarks on scientific workstations.We contend that this technology is also important to the desktop computing environmentwhere running large; complex commercial software applications is commonplace. In thispaper; we describe work that has been accomplished over the past several months atMicrosoft Research to design and develop a dynamic software optimization system calledMojo. In particular; we present implementation details for the x86 architecture--Mojo's initialtarget. Additionally; we present our experience in supporting exception handling and …,3rd ACM Workshop on Feedback-Directed and Dynamic Optimization (FDDO-3),2000,163
Automatically proving the correctness of compiler optimizations,Sorin Lerner; Todd Millstein; Craig Chambers,Abstract We describe a technique for automatically proving compiler optimizations sound;meaning that their transformations are always semantics-preserving. We first present adomain-specific language; called Cobalt; for implementing optimizations as guarded rewriterules. Cobalt optimizations operate over a C-like intermediate representation includingunstructured control flow; pointers to local variables and dynamically allocated memory; andrecursive procedures. Then we describe a technique for automatically proving thesoundness of Cobalt optimizations. Our technique requires an automatic theorem prover todischarge a small set of simple; optimization-specific proof obligations for each optimization.We have written a variety of forward and backward intraprocedural dataflow optimizations inCobalt; including constant propagation and folding; branch folding; full and partial …,ACM SIGPLAN Notices,2003,158
Automated soundness proofs for dataflow analyses and transformations via local rules,Sorin Lerner; Todd Millstein; Erika Rice; Craig Chambers,Abstract We present Rhodium; a new language for writing compiler optimizations that can beautomatically proved sound. Unlike our previous work on Cobalt; Rhodium expressesoptimizations using explicit dataflow facts manipulated by local propagation andtransformation rules. This new style allows Rhodium optimizations to be mutually recursivelydefined; to be automatically composed; to be interpreted in both flow-sensitive and-insensitive ways; and to be applied interprocedurally given a separate context-sensitivitystrategy; all while retaining soundness. Rhodium also supports infinite analysis domainswhile guaranteeing termination of analysis. We have implemented a soundness checker forRhodium and have specified and automatically proven the soundness of all of Cobalt'soptimizations plus a variety of optimizations not expressible in Cobalt; including …,ACM SIGPLAN Notices,2005,138
ProtectMyPrivacy: detecting and mitigating privacy leaks on iOS devices using crowdsourcing,Yuvraj Agarwal; Malcolm Hall,Abstract In this paper we present the design and implementation of ProtectMyPrivacy (PMP);a system for iOS devices to detect access to private data and protect users by substitutinganonymized data in its place if users decide. We developed a novel crowdsourcedrecommendation engine driven by users who contribute their protection decisions; whichprovides app specific privacy recommendations. PMP has been in use for over nine monthsby 90;621 real users; and we present a detailed evaluation based on the data we collectedfor 225;685 unique apps. We show that access to the device identifer (48.4% of apps);location (13.2% of apps); address book (6.2% of apps) and music library (1.6% of apps) isindeed widespread in iOS. We show that based on the protection decisions contributed byour users we can recommend protection settings for over 97.1% of the 10;000 most …,Proceeding of the 11th annual international conference on Mobile systems; applications; and services,2013,133
Equality saturation: a new approach to optimization,Ross Tate; Michael Stepp; Zachary Tatlock; Sorin Lerner,Abstract Optimizations in a traditional compiler are applied sequentially; with eachoptimization destructively modifying the program to produce a transformed program that isthen passed to the next optimization. We present a new approach for structuring theoptimization phase of a compiler. In our approach; optimizations take the form of equalityanalyses that add equality information to a common intermediate representation. Theoptimizer works by repeatedly applying these analyses to infer equivalences betweenprogram fragments; thus saturating the intermediate representation with equalities. Oncesaturated; the intermediate representation encodes multiple optimized versions of the inputprogram. At this point; a profitability heuristic picks the final optimized program from thevarious programs represented in the saturated representation. Our proposed way of …,ACM SIGPLAN Notices,2009,112
Composing dataflow analyses and transformations,Sorin Lerner; David Grove; Craig Chambers,Abstract Dataflow analyses can have mutually beneficial interactions. Previous efforts toexploit these interactions have either (1) iteratively performed each individual analysis untilno further improvements are discovered or (2) developed" super-analyses" that manuallycombine conceptually separate analyses. We have devised a new approach that allowsanalyses to be defined independently while still enabling them to be combined automaticallyand profitably. Our approach avoids the loss of precision associated with iterating individualanalyses and the implementation difficulties of manually writing a super-analysis. The key toour approach is a novel method of implicit communication between the individualcomponents of a super-analysis based on graph transformations. In this paper; we preciselydefine our approach; we demonstrate that it is sound and it terminates; finally we give …,ACM SIGPLAN Notices,2002,107
SafeDispatch: Securing C++ Virtual Calls from Memory Corruption Attacks.,Dongseok Jang; Zachary Tatlock; Sorin Lerner,Abstract—Several defenses have increased the cost of traditional; low-level attacks thatcorrupt control data; eg return addresses saved on the stack; to compromise programexecution. In response; creative adversaries have begun circumventing these defenses byexploiting programming errors to manipulate pointers to virtual tables; or vtables; of C++objects. These attacks can hijack program control flow whenever a virtual method of acorrupted object is called; potentially allowing the attacker to gain complete control of theunderlying system. In this paper we present SAFEDISPATCH; a novel defense to preventsuch vtable hijacking by statically analyzing C++ programs and inserting sufficient runtimechecks to ensure that control flow at virtual method call sites cannot be arbitrarily influencedby an attacker. We implemented SAFEDISPATCH as a Clang++/LLVM extension; used …,NDSS,2014,94
Proving optimizations correct using parameterized program equivalence,Sudipta Kundu; Zachary Tatlock; Sorin Lerner,Abstract Translation validation is a technique for checking that; after an optimization has run;the input and output of the optimization are equivalent. Traditionally; translation validationhas been used to prove concrete; fully specified programs equivalent. In this paper wepresent Parameterized Equivalence Checking (PEC); a generalization of translationvalidation that can prove the equivalence of parameterized programs. A parameterizedprogram is a partially specified program that can represent multiple concrete programs. Forexample; a parameterized program may contain a section of code whose only knownproperty is that it does not modify certain variables. By proving parameterized programsequivalent; PEC can prove the correctness of transformation rules that represent complexoptimizations once and for all; before they are ever run. We implemented our PEC …,ACM Sigplan Notices,2009,80
Opium: Optimal package install/uninstall manager,Chris Tucker; David Shuffelton; Ranjit Jhala; Sorin Lerner,Linux distributions often include package management tools such as apt-get in Debian oryum in RedHat. Using information about package dependencies and conflicts; such toolscan determine how to install a new package (and its dependencies) on a system of alreadyinstalled packages. Using off-the-shelf SAT solvers; pseudo-boolean solvers; and IntegerLinear Programming solvers; we have developed a new package-management tool; calledOpium; that improves on current tools in two ways:(1) Opium is complete; in that if there is asolution; Opium is guaranteed to find it; and (2) Opium can optimize a user-providedobjective function; which could for example state that smaller packages should be preferredover larger ones. We performed a comparative study of our tool against Debian's apt-get on600 traces of real-world package installations. We show that Opium runs fast enough to …,Software Engineering; 2007. ICSE 2007. 29th International Conference on,2007,80
Dataflow analysis for concurrent programs using datarace detection,Ravi Chugh; Jan W Voung; Ranjit Jhala; Sorin Lerner,Abstract Dataflow analyses for concurrent programs differ from their single-threadedcounterparts in that they must account for shared memory locations being overwritten byconcurrent threads. Existing dataflow analysis techniques for concurrent programs typicallyfall at either end of a spectrum: at one end; the analysis conservatively kills facts about alldata that might possibly be shared by multiple threads; at the other end; a precise thread-interleaving analysis determines which data may be shared; and thus which dataflow factsmust be invalidated. The former approach can suffer from imprecision; whereas the latterdoes not scale. We present RADAR; a framework that automatically converts a dataflowanalysis for sequential programs into one that is correct for concurrent programs. RADARuses a race detection engine to kill the dataflow facts; generated and propagated by the …,ACM SIGPLAN Notices,2008,59
WitchDoctor: IDE support for real-time auto-completion of refactorings,Stephen R Foster; William G Griswold; Sorin Lerner,Abstract Integrated Development Environments (IDEs) have come to perform a wide varietyof tasks on behalf of the programmer; refactoring being a classic example. These operationshave undeniable benefits; yet their large (and growing) number poses a cognitive scalabilityproblem. Our main contribution is WitchDoctor--a system that can detect; on the fly; when aprogrammer is hand-coding a refactoring. The system can then complete the refactoring inthe background and propose it to the user long before the user can complete it. This impliesa number of technical challenges. The algorithm must be 1) highly efficient; 2) handleunparseable programs; 3) tolerate the variety of ways programmers may perform a givenrefactoring; 4) use the IDE's proven and familiar refactoring engine to perform therefactoring; even though the the refactoring has already begun; and 5) support the wide …,Proceedings of the 34th International Conference on Software Engineering,2012,51
Establishing browser security guarantees through formal shim verification,Dongseok Jang; Zachary Tatlock; Sorin Lerner,Abstract Web browsers mediate access to valuable private data in domains ranging fromhealth care to banking. Despite this critical role; attackers routinely exploit browservulnerabilities to exfiltrate private data and take over the underlying system. We presentQUARK; a browser whose kernel has been implemented and verified in Coq. We give aspecification of our kernel; show that the implementation satisfies the specification; andfinally show that the specification implies several security properties; including tab non-interference; cookie integrity and confidentiality; and address bar integrity.,Proceedings of the 21st USENIX conference on Security symposium,2012,45
Validating high-level synthesis,Sudipta Kundu; Sorin Lerner; Rajesh Gupta,Abstract The growing design-productivity gap has made designers shift toward using high-level languages like C; C++ and Java to do system-level design. High-Level Synthesis(HLS) is the process of generating Register Transfer Level (RTL) design from these initialhigh-level programs. Unfortunately; this translation process itself can be buggy; which cancreate a mismatch between what a designer intends and what is actually implemented in thecircuit. In this paper; we present an approach to validate the result of HLS against the initialhigh-level program using insights from translation validation; automated theorem provingand relational approaches to reasoning about programs. We have implemented ourvalidating technique and have applied it to a highly parallelizing HLS framework calledSPARK. We present the details of our algorithm and experimental results.,International Conference on Computer Aided Verification,2008,45
Verifying GPU kernels by test amplification,Alan Leung; Manish Gupta; Yuvraj Agarwal; Rajesh Gupta; Ranjit Jhala; Sorin Lerner,Abstract We present a novel technique for verifying properties of data parallel GPUprograms via test amplification. The key insight behind our work is that we can use thetechnique of static information flow to amplify the result of a single test execution over the setof all inputs and interleavings that affect the property being verified. We empiricallydemonstrate the effectiveness of test amplification for verifying race-freedom anddeterminism over a large number of standard GPU kernels; by showing that the result ofverifying a single dynamic execution can be amplified over the massive space of possibledata inputs and thread interleavings.,ACM SIGPLAN Notices,2012,44
Equality-based translation validator for LLVM,Michael Stepp; Ross Tate; Sorin Lerner,Abstract We updated our Peggy tool; previously presented in [6]; to perform translationvalidation for the LLVM compiler using a technique called Equality Saturation. We presentthe tool; and illustrate its effectiveness at doing translation validation on SPEC 2006benchmarks.,International Conference on Computer Aided Verification,2011,40
Towards Verifying Android Apps for the Absence of No-Sleep Energy Bugs.,Panagiotis Vekris; Ranjit Jhala; Sorin Lerner; Yuvraj Agarwal,Abstract The Android OS conserves battery life by aggressively turning off components; suchas screen and GPS; while allowing application developers to explicitly prevent part of thisbehavior using the WakeLock API. Unfortunately; the inherent complexity of the Androidprogramming model and developer errors often lead to improper use of Wake-Locks thatmanifests as no-sleep bugs. To mitigate this problem; we have implemented a tool thatverifies the absence of this kind of energy bugs wrt a set of Wake-Lock specific policiesusing a precise; inter-procedural data flow analysis framework to enforce them. We run ouranalysis on 328 Android apps that utilize WakeLocks; verify 145 of them and shed light onthe locking patterns employed and when these can be harmful. Further; we identifychallenges that remain in order to make verification of Android apps even more precise.,HotPower,2012,38
Translation validation of high-level synthesis,Sudipta Kundu; Sorin Lerner; Rajesh K Gupta,Abstract Once the important properties of the high-level components have been verifiedpossibly using techniques presented in Chaps. 5 and 6; the translation from the high-leveldesign to low-level RTL still needs to be proven correct; thereby also guaranteeing that theimportant properties of the components are preserved. In this chapter we will discuss anapproach that proves that the translation from high-level design to a scheduled design iscorrect; for each translation that the HLS tool performs. In the next chapter we will describeanother approach that will allow us to write part of these tools in a provably correct manner.,*,2011,38
On subnormal floating point and abnormal timing,Marc Andrysco; David Kohlbrenner; Keaton Mowery; Ranjit Jhala; Sorin Lerner; Hovav Shacham,We identify a timing channel in the floating point instructions of modern x86 processors: therunning time of floating point addition and multiplication instructions can vary by two ordersof magnitude depending on their operands. We develop a benchmark measuring the timingvariability of floating point operations and report on its results. We use floating point datatiming variability to demonstrate practical attacks on the security of the Fire fox browser(versions 23 through 27) and the Fuzz differentially private database. Finally; we initiate thestudy of mitigations to floating point data timing channels with libfixedtimefixedpoint; a newfixed-point; constant-time math library. Modern floating point standards and implementationsare sophisticated; complex; and subtle; a fact that has not been sufficiently recognized by thesecurity community. More work is needed to assess the implications of the use of floating …,Security and Privacy (SP); 2015 IEEE Symposium on,2015,36
Speeding up dataflow analysis using flow-insensitive pointer analysis,Stephen Adams; Thomas Ball; Manuvir Das; Sorin Lerner; Sriram K Rajamani; Mark Seigle; Westley Weimer,Abstract In recent years; static analysis has increasingly been applied to the problem ofprogram verification. Systems for program verification typically use precise and expensiveinterprocedural dataflow algorithms that are difficult to scale to large programs. An attractiveway to scale these analyses is to use a preprocessing step to reduce the number of dataflowfacts propagated by the analysis and/or the number of statements to be processed; beforethe dataflow analysis is run. This paper describes an approach that achieves this effect. Wefirst run a scalable; control-flow-insensitive pointer analysis to produce a conservativerepresentation of value flow in the program. We query the value flow representation at theprogram points where a dataflow solution is required; in order to obtain a conservative over-approximation of the dataflow facts and the statements that must be processed by the …,International Static Analysis Symposium,2002,33
Protecting C++ Dynamic Dispatch Through VTable Interleaving.,Dimitar Bounov; Rami Gökhan Kici; Sorin Lerner,Abstract—With new defenses against traditional control-flow attacks like stack bufferoverflows; attackers are increasingly using more advanced mechanisms to take control ofexecution. One common such attack is vtable hijacking; in which the attacker exploits bugsin C++ programs to overwrite pointers to the virtual method tables (vtables) of objects. Wepresent a novel defense against this attack. The key insight of our approach is a new way oflaying out vtables in memory through careful ordering and interleaving. Although this layoutis very different from a traditional layout; it is backwards compatible with the traditional wayof performing dynamic dispatch. Most importantly; with this new layout; checking the validityof a vtable at runtime becomes an efficient range check; rather than a set membership test.Compared to prior approaches that provide similar guarantees; our approach does not …,NDSS,2016,32
Bringing extensibility to verified compilers,Zachary Tatlock; Sorin Lerner,Abstract Verified compilers; such as Leroy's CompCert; are accompanied by a fully checkedcorrectness proof. Both the compiler and proof are often constructed with an interactive proofassistant. This technique provides a strong; end-to-end correctness guarantee on top of asmall trusted computing base. Unfortunately; these compilers are also challenging to extendsince each additional transformation must be proven correct in full formal detail. At the otherend of the spectrum; techniques for compiler correctness based on a domain-specificlanguage for writing optimizations; such as Lerner's Rhodium and Cobalt; make the compilereasy to extend: the correctness of additional transformations can be checked completelyautomatically. Unfortunately; these systems provide a weaker guarantee since their end-to-end correctness has not been proven fully formally.,ACM Sigplan Notices,2010,30
Generating compiler optimizations from proofs,Ross Tate; Michael Stepp; Sorin Lerner,Abstract We present an automated technique for generating compiler optimizations fromexamples of concrete programs before and after improvements have been made to them.The key technical insight of our technique is that a proof of equivalence between the originaland transformed concrete programs informs us which aspects of the programs are importantand which can be discarded. Our technique therefore uses these proofs; which can beproduced by translation validation or a proof-carrying compiler; as a guide to generalize theoriginal and transformed programs into broadly applicable optimization rules. We present acategory-theoretic formalization of our proof generalization technique. This abstractionmakes our technique applicable to logics besides our own. In particular; we demonstratehow our technique can also be used to learn query optimizations for relational databases …,ACM Sigplan Notices,2010,28
Beyond refactoring: a framework for modular maintenance of crosscutting design idioms,Macneil Shonle; William G Griswold; Sorin Lerner,Abstract Despite the automated refactoring support provided by today's IDEs many programtransformations that are easy to conceptualize--such as improving the implementation of adesign pattern--are not supported and are hence hard to perform. We propose an extensionto the refactoring paradigm that provides for the modular maintenance of crosscutting designidioms; supporting both substitutability of design idiom implementations and the checking ofessential constraints. We evaluate this new approach through the design and use of Arcum;an IDE-based mechanism for declaring; checking; and evolving crosscutting design idioms.,Proceedings of the the 6th joint meeting of the European software engineering conference and the ACM SIGSOFT symposium on The foundations of software engineering,2007,28
Deep typechecking and refactoring,Zachary Tatlock; Chris Tucker; David Shuffelton; Ranjit Jhala; Sorin Lerner,Abstract Large software systems are typically composed of multiple layers; written in differentlanguages and loosely coupled using a string-based interface. For example; in modern web-applications; a server written in Java communicates with a database back-end by passing inquery strings. This widely prevalent approach is unsafe as the analyses developed for theindividual layers are oblivious to the semantics of the dynamically constructed strings;making it impossible to statically reason about the correctness of the interaction. Further;even simple refactoring in such systems is daunting and error prone as the changes mustalso be applied to isolated string fragments scattered across the code base. We presenttechniques for deep typechecking and refactoring for systems that combine Java code with adatabase back-end using the Java Persistence API [10]. Deep typechecking ensures that …,ACM Sigplan Notices,2008,23
System and method for performing a path-sensitive verification on a program,*,Described is a method and system that performs path-sensitive verification on programshaving any code base size. The method maintains a symbolic store that includes symbolicstates. Each symbolic state includes a concrete state and an abstract state. The abstractstate identifies a state in which the property being tested currently exists. The concrete stateidentifies other properties of the program. The symbolic store is updated at each node in alogic path of the program with changes in the abstract state and the concrete state. Theupdates occur such that the symbolic states associated with a particular edge of any nodewill not have identical abstract states. Rather; in this case; the symbolic states are merged bycombining the concrete states to include content that is similar in both symbolic states. Inaddition; the concrete state determines relevant paths to proceed along in the logic path.,*,2005,22
Interactive parser synthesis by example,Alan Leung; John Sarracino; Sorin Lerner,Abstract Despite decades of research on parsing; the construction of parsers remains apainstaking; manual process prone to subtle bugs and pitfalls. We present a programming-by-example framework called Parsify that is able to synthesize a parser from input/outputexamples. The user does not write a single line of code. To achieve this; Parsify provides:(a)an iterative algorithm for synthesizing and refining a grammar one example at a time;(b) aninterface that provides immediate visual feedback in response to changes in the grammarbeing refined; and (c) a graphical mechanism for specifying example parse trees using onlytextual selections. We empirically demonstrate the viability of our approach by using Parsifyto construct parsers for source code drawn from Verilog; SQL; Apache; and Tiger.,ACM SIGPLAN Notices,2015,21
Automatic inference of optimizer flow functions from semantic meanings,Erika Rice Scherpelz; Sorin Lerner; Craig Chambers,Abstract Previous work presented a language called Rhodium for writing program analysesand transformations; in the form of declarative flow functions that propagate instances ofuser-defined dataflow fact schemas. Each dataflow fact schema specifies a semanticmeaning; which allows the Rhodium system to automatically verify the correctness of theuser's flow functions. In this work; we have reversed the roles of the flow functions andsemantic meanings: rather than checking the correctness of the user-written flow functionsusing the facts' semantic meanings; we automatically infer correct flow functions solely fromthe meanings of the dataflow fact schemas. We have implemented our algorithm for inferringflow functions from fact schemas in the context of the Whirlwind compiler; and have used thisimplementation to infer flow functions for a variety of fact schemas. The automatically …,ACM SIGPLAN Notices,2007,18
Introduction,Sudipta Kundu; Sorin Lerner; Rajesh K Gupta,Abstract The quantitative changes brought about by Moore's law in design of integratedcircuits (ICs) affect not only the scale of the designs; but also the scale of the process todesign and validate such chips. While designer productivity has grown at an impressive rateover the past few decades; the rate of improvement has not kept pace with chip capacitygrowth leading to the well known design-productivity-gap [105]. The problem of reducing thedesign-productivity-gap is crucial in not only handling the complexity of the design; but alsocombating the increased fragility of the composed system consisting of heterogeneouscomponents. Unlike software programs; integrated circuits are not repairable. Thedevelopment costs are so high that multiple design spins are ruled out; a design must becorrect in the one and often the only one design iteration to implementation.,*,2011,17
Codespells: how to design quests to teach java concepts,Sarah Esper; Samantha R Wood; Stephen R Foster; Sorin Lerner; William G Griswold,Abstract Serious games are a good approach to teaching computer science [7]. But there arestill complications that arise; for example; no access to an instructor. This paper presents astudy conducted using CodeSpells; a 3D immersive video game that aims to teach noviceprogrammers basic Java concepts [3]. This paper specifically addresses the design of thequests in CodeSpells that provide scaffolding to support students in learning. The studyanalyzed how 16 students aged 8--12 understood and modified basic Java programs tocomplete quests. Based on game-play from an exploratory study; quests were added toengage students earlier and in more complex code edits. Both student understanding ofprogramming and their comfort with modifying code was studied. This paper presentsfindings and lessons learned in quest design; and shows that quest design should set the …,Journal of Computing Sciences in Colleges,2014,14
Taming wildcards in Java's type system,Ross Tate; Alan Leung; Sorin Lerner,Abstract Wildcards have become an important part of Java's type system since theirintroduction 7 years ago. Yet there are still many open problems with Java's wildcards. Forexample; there are no known sound and complete algorithms for subtyping (andconsequently type checking) Java wildcards; and in fact subtyping is suspected to beundecidable because wildcards are a form of bounded existential types. Furthermore; someJava types with wildcards have no joins; making inference of type arguments for genericmethods particularly difficult. Although there has been progress on these fronts; we haveidentified significant shortcomings of the current state of the art; along with new problemsthat have not been addressed. In this paper; we illustrate how these shortcomings reflect thesubtle complexity of the problem domain; and then present major improvements to the …,ACM SIGPLAN Notices,2011,14
Programming Languages,Sorin Lerner,Page 1. 1 CSE 130 : Winter 2007 Program m ing Languages Sorin Lerner UC San Diego Whystudy PL ? (discussion) Why study PL ? “A different language is a different vision of life” - Fellini -Hypothesis: Program m ing language shapes program m ing thought - Characteristics of alanguage affect how ideas can be expressed in the language Course G oals “Free your m ind”-Morpheus You w ill learn several new - languages and constructs - w ays to describe andorganize com putation Yes; you can do that in Java/Assem bly but … So w hat does studyingPL buy me? Enables you to create softw are that is • Readable • Correct • Extendable • Modifiable •Reusable So w hat does studying PL buy me? Will help you learn new languages …,*,1968,12
Automating formal proofs for reactive systems,Daniel Ricketts; Valentin Robert; Dongseok Jang; Zachary Tatlock; Sorin Lerner,Abstract Implementing systems in proof assistants like Coq and proving their correctness infull formal detail has consistently demonstrated promise for making extremely strongguarantees about critical software; ranging from compilers and operating systems todatabases and web browsers. Unfortunately; these verifications demand such heroicmanual proof effort; even for a single system; that the approach has not been widelyadopted. We demonstrate a technique to eliminate the manual proof burden for verifyingmany properties within an entire class of applications; in our case reactive systems; whileonly expending effort comparable to the manual verification of a single system. A crucialinsight of our approach is simultaneously designing both (1) a domain-specific language(DSL) for expressing reactive systems and their correctness properties and (2) proof …,ACM SIGPLAN Notices,2014,11
Automated refinement checking of concurrent systems,Sudipta Kundu; Sorin Lerner; Rajesh Gupta,Abstract Stepwise refinement is at the core of many approaches to synthesis andoptimization of hardware and software systems. For instance; it can be used to build asynthesis approach for digital circuits from high level specifications. It can also be used forpost-synthesis modification such as in Engineering Change Orders (ECOs). Therefore;checking if a system; modeled as a set of concurrent processes; is a refinement of another isof tremendous value. In this paper; we focus on concurrent systems modeled asCommunicating Sequential Processes (CSP) and show their refinements can be validatedusing insights from translation validation; automated theorem proving and relationalapproaches to reasoning about programs. The novelty of our approach is that it handlesinfinite state spaces in a fully automated manner. We have implemented our refinement …,Proceedings of the 2007 IEEE/ACM international conference on Computer-aided design,2007,11
NSF expedition on variability-aware software: Recent results and contributions,Lucas Wanner; Liangzhen Lai; Abbas Rahimi; Mark Gottscho; Pietro Mercati; Chu-Hsiang Huang; Frederic Sala; Yuvraj Agarwal; Lara Dolecek; Nikil Dutt; Puneet Gupta; Rajesh Gupta; Ranjit Jhala; Rakesh Kumar; Sorin Lerner; Subhasish Mitra; Alexandru Nicolau; Tajana Simunic Rosing; Mani B Srivastava; Steve Swanson; Dennis Sylvester; Yuanyuan Zhou,Abstract In this paper we summarize recent results and contributions from the NSFExpedition on Variability-Aware Software; a five year; multi-university effort to tackle theproblem of hardware variations and its implications and opportunities in software. TheExpedition has made contributions in characterization and online monitoring of variations(particularly in microprocessors and flash memories); proposed new coding techniques forvariability-tolerant storage; provided tools and platforms for the development of variability-aware software; and created new runtime support systems for variability-aware task-scheduling and execution.,it-Information Technology,2015,10
Towards verification of hybrid systems in a foundational proof assistant,Daniel Ricketts; Gregory Malecha; Mario M Alvarez; Vignesh Gowda; Sorin Lerner,Unsafe behavior of hybrid systems can have disastrous consequences; motivating the needfor formal verification of the software running on these systems. Foundational verification in aproof assistant such as Coq is a promising technique that can provide extremely strong;foundational; guarantees about software systems. In this paper; we show how to apply thistechnique to hybrid systems. We define a TLA-inspired formalism in Coq for reasoning abouthybrid systems and use it to verify two quadcopter modules: the first limits the quadcopter'svelocity and the second limits its altitude. We ran both of these modules on an actualquadcopter; and they worked as intended. We also discuss lessons learned from ourexperience foundationally verifying hybrid systems.,Formal Methods and Models for Codesign (MEMOCODE); 2015 ACM/IEEE International Conference on,2015,9
Polymorphic blocks: Formalism-inspired UI for structured connectors,Sorin Lerner; Stephen R Foster; William G Griswold,Abstract We present a novel block-based UI called Polymorphic Blocks; in which aconnector's shape visually represents the structure of the data being passed through theconnector. We use Polymorphic Blocks to add visual type information to block-basedprogramming environments like Blockly or Scratch. We also use Polymorphic Blocks torepresent logical proofs. In this context; if we erase all symbols; our UI becomes a puzzlegame; where solving the puzzle amounts to building a proof. We show through a user studythat our Logical Puzzle Game is faster; more fun; and more engaging than an equivalent pen-and-paper interface.,Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems,2015,9
Formal verification of stability properties of cyber-physical systems,Matthew Chan; Daniel Ricketts; Sorin Lerner; Gregory Malecha,We increasingly rely on computers to interact with the physical world for us. At the large end;software underlies the control systems of commercial aircraft and power plants; and at thesmall end it controls medical devices and hobbyist UAVs. The failure of any of these systemscan have severe consequences which are often measured in the loss of human lives.Formal verification has proven a promising approach to achieving very strong guarantees inmore classic areas of computer science. In this work we present an overview of ourexperiences formalizing stability properties of cyber-physical systems (CPSs) using the Coqproof assistant. In particular; we describe and contrast two approaches for proving thestability of the linear; one-dimensional proportional controller (P-controller) depicted inFigure 1. This system runs in a loop where the controller sets the velocity (v) of the system …,Proc. CoqPL,2016,6
Rewriting-based dynamic information flow for JavaScript,Dongseok Jang; Ranjit Jhala; Sorin Lerner; Hovav Shacham,Abstract JavaScript web applications often dynamically load third-party code; which in somecases can steal or corrupt important client information. In this paper; we present a rewriting-based approach for enforcing confidentiality and integrity policies that respectively specifywhat information can flow into and from untrusted thirdparty code. We have implemented ourapproach in the Chrome browser; and we present experiments that evaluate the efficiencyand precision of our technique on real-world websites.,17th ACM Conference on Computer and Communications Security,2010,6
Cobalt: A language for writing provably-sound compiler optimizations,Sorin Lerner; Todd Millstein; Craig Chambers,Abstract We overview the current status and future directions of the Cobalt project. Cobalt isa domain-specific language for implementing compiler optimizations as guarded rewriterules. Cobalt optimizations operate over a C-like intermediate representation includingunstructured control flow; pointers to local variables and dynamically allocated memory; andrecursive procedures. The design of Cobalt engenders a natural inductive strategy forproving the soundness of optimizations. This strategy is fully automated by requiring anautomatic theorem prover to discharge a small set of simple proof obligations for eachoptimization. We have written a variety of forward and backward intraprocedural dataflowoptimizations in Cobalt; including constant propagation and folding; branch folding; full andpartial redundancy elimination; full and partial dead assignment elimination; and simple …,Electronic Notes in Theoretical Computer Science,2005,6
High-Level Verification,Sudipta Kundu; Sorin Lerner; Rajesh Gupta,The growth in size and heterogeneity of System-on-Chip (SOC) design makes their designprocess from initial specification to IC implementation complex. System-level designmethods seek to combat this complexity by shifting increasing design burden to high-levellanguages such as SystemC and SystemVerilog. Such languages not only make a designeasier to describe using high-level abstractions; but also provide a path for systematicimplementation through refinement and elaboration of such descriptions. In principle; thiscan enable a greater exploration of design alternatives and thus better design optimizationthan possible using lower level design methods. To achieve these goals; however;verification capabilities that seek to validate designs at higher levels as well theirequivalences with lower level implementations are crucially needed. To the extent …,IPSJ Transactions on System LSI Design Methodology,2009,5
Automatically proving the correctness of program analyses and transformations,Sorin Lerner; Craig Chambers,In this dissertation; I describe a technique for automatically proving compiler optimizationssound; meaning that their transformations are always semantics-preserving. I first present adomain-specific language; called Rhodium; for implementing optimizations using localpropagation and transformation rules that manipulate explicit dataflow facts. Then I describea technique for automatically proving the soundness of Rhodium optimizations. Thetechnique requires an automatic theorem prover to discharge a simple proof obligation foreach propagation and transformation rule. I have written a variety of forward and backwardintraprocedural dataflow optimizations in Rhodium; including constant propagation andfolding; branch folding; full and partial redundancy elimination; full and partial deadassignment elimination; an intraprocedural version of Andersen's points-to analysis …,*,2006,5
Towards foundational verification of cyber-physical systems,Gregory Malecha; Daniel Ricketts; Mario M Alvarez; Sorin Lerner,The safety-critical aspects of cyber-physical systems motivate the need for rigorous analysisof these systems. In the literature this work is often done using idealized models of systemswhere the analysis can be carried out using high-level reasoning techniques such asLyapunov functions and model checking. In this paper we present VERIDRONE; afoundational framework for reasoning about cyber-physical systems at all levels from high-level models to C code that implements the system. VERIDRONE is a library within the Coqproof assistant enabling us to build on its foundational implementation; its interactivedevelopment environments; and its wealth of libraries capturing interesting theories rangingfrom real numbers and differential equations to verified compilers and floating pointnumbers. These features make proof assistants in general; and Coq in particular; a …,Cyber-Physical Systems Workshop (SOSCYPS); Science of Security for,2016,4
C-to-verilog translation validation,Alan Leung; Dimitar Bounov; Sorin Lerner,To offset the high engineering cost of digital circuit design; hardware engineers are lookingincreasingly toward high-level languages such as C and C++ to implement their designs. Todo this; they employ High-Level Synthesis (HLS) tools that translate their high-levelspecifications down to a hardware description language such as Verilog. Unfortunately; HLStools themselves employ sophisticated optimization passes that may have bugs that silentlyintroduce errors in realized hardware. The cost of such errors is high; as hardware is costlyor impossible to repair if software patching is not an option. In this work; we present atranslation validation approach for verifying the correctness of the HLS translation process.Given an initial C program and the generated Verilog code; our approach establishes theirequivalence without relying on any intermediate results or representations produced by …,Formal Methods and Models for Codesign (MEMOCODE); 2015 ACM/IEEE International Conference on,2015,4
Addressing common crosscutting problems with arcum,Macneil Shonle; William G Griswold; Sorin Lerner,Abstract Crosscutting is an inherent part of software development and can typically bemanaged through modularization: A module's stable properties are defined in an interfacewhile its likely-to-change properties are encapsulated within the module [19]. Thecrosscutting of the stable properties; such as class and method names; can be mitigated withautomated refactoring tools that allow; for example; the interface's elements to be renamed[9; 18]. However; often the crosscutting from design idioms (such as design patterns andcoding styles) are so specific to the program's domain that their crosscutting would not likelyhave been anticipated by the developers of an automated refactoring system. The Arcumplug-in for Eclipse enables programmers to describe the implementation of a crosscuttingdesign idiom as a set of syntactic patterns and semantic constraints. Arcum can process …,Proceedings of the 8th ACM SIGPLAN-SIGSOFT workshop on Program analysis for software tools and engineering,2008,4
Dead store elimination (still) considered harmful,Zhaomo Yang; Brian Johannesmeyer; A Trier Olesen; Sorin Lerner; Kirill Levchenko,Abstract Dead store elimination is a widely used compiler optimization that reduces codesize and improves performance. However; it can also remove seemingly useless memorywrites that the programmer intended to clear sensitive data after its last use. Security-savvydevelopers have long been aware of this phenomenon and have devised ways to preventthe compiler from eliminating these data scrubbing operations. In this paper; we survey theset of techniques found in the wild that are intended to prevent data-scrubbing operationsfrom being removed during dead store elimination. We evaluated the effectiveness andavailability of each technique and found that some fail to protect data-scrubbing writes. Wealso examined eleven open source security projects to determine whether their specificmemory scrubbing function was effective and whether it was used consistently. We found …,26th USENIX Security Symposium. USENIX Association,2017,3
Translating between PEGs and CFGs,Ross Tate; Michael Stepp; Zachary Lee Tatlock; Sorin Lerner,Abstract. In this technical report; we present the algorithms for translating control flow graphs(CFGs) to program expression graphs (PEGs) and translating PEGs to CFGs. In order toexplain these algorithms; we first define a simple imperative language; SIMPLE; and showthe algorithms for translating between SIMPLE programs and PEGs; followed by thetechniques for extending these algorithms to CFGs. For an introduction to PEGs; please referto the original conference paper [4]. For more detail on PEGs; SIMPLE; and guarantees ofthe algorithms presented here; please refer to the more recent journal paper [5]. The journalpaper already contains the algorithms for SIMPLE programs; but not the algorithms forCFGs.,*,2008,3
When refactoring acts like modularity: Keeping options open with persistent condition checking,Macneil Shonle; William G Griswold; Sorin Lerner,Abstract Oftentimes the changes required to improve the design of code are crosscutting innature and thus easier to perform with the assistance of automated refactoring tools.However; the developers of such refactoring tools cannot anticipate every practicaltransformation; particularly those that are specific to the program's domain. We demonstrateArcum; a declarative language for describing and performing both general and domain-specific transformations. Because Arcum works directly with declarative descriptions ofcrosscutting code it can ensure that code written or modified after the transformation alsosatisfies the design's requirements. As a result; preconditions and postconditions arepersistently checked; making the crosscutting code (such as the use of a design idiom orprogramming style) behave more like a module with respect to checkability and …,Proceedings of the 2nd Workshop on Refactoring Tools,2008,3
Finding root causes of floating point error with herbgrind,Alex Sanchez-Stern; Pavel Panchekha; Sorin Lerner; Zachary Tatlock,Abstract: Floating point plays a central role in science; engineering; and finance by enablingdevelopers to approximately compute with real numbers. To address numerical issues inlarge floating-point applications; developers must identify root causes; which is difficultbecause floating point errors are generally silent; non-local; and non-compositional. Thispaper presents Herbgrind; an approach to help developers identify and address root causesin typical numerical code written in low-level C/C++ and Fortran. Herbgrind tracksdependencies between operations and program outputs to avoid false positives; andabstracts erroneous computations to a simplified program fragment whose improvement canreduce output error. We perform several case studies applying Herbgrind to large; expert-crafted numerical programs and show that it scales to applications spanning hundreds of …,arXiv preprint arXiv:1705.10416,2017,2
A framework for the checking and refactoring of crosscutting concepts,Macneil Shonle; William G Griswold; Sorin Lerner,Abstract Programmers employ crosscutting concepts; such as design patterns and otherprogramming idioms; when their design ideas cannot be efficiently or effectivelymodularized in the underlying programming language. As a result; implementations of thesecrosscutting concepts can be hard to change even when the code is well structured. In thisarticle; we describe Arcum; a system that supports the modular maintenance of crosscuttingconcepts. Arcum can be used to both check essential constraints of crosscutting conceptsand to substitute crosscutting concept implementations with alternative implementations.Arcum is complementary to existing refactoring systems that focus on meaning-preservingprogram transformations at the programming-language-semantics level; because Arcumfocuses on transformations at the conceptual level.,ACM Transactions on Software Engineering and Methodology (TOSEM),2012,2
Latent variable models for predicting file dependencies in large-scale software development,Diane Hu; Laurens Maaten; Youngmin Cho; Sorin Lerner; Lawrence K Saul,Abstract When software developers modify one or more files in a large code base; they mustalso identify and update other related files. Many file dependencies can be detected bymining the development history of the code base: in essence; groups of related files arerevealed by the logs of previous workflows. From data of this form; we show how to detectdependent files by solving a problem in binary matrix completion. We explore different latentvariable models (LVMs) for this problem; including Bernoulli mixture models; exponentialfamily PCA; restricted Boltzmann machines; and fully Bayesian approaches. We evaluatethese models on the development histories of three large; open-source software systems:Mozilla Firefox; Eclipse Subversive; and Gimp. In all of these applications; we find that LVMsimprove the performance of related file prediction over current leading methods.,Advances in Neural Information Processing Systems,2010,2
Modular deductive verification of sampled-data systems,Daniel Ricketts; Gregory Malecha; Sorin Lerner,Abstract Unsafe behavior of cyber-physical systems can have disastrous consequences;motivating the need for formal verification of these kinds of systems. Deductive verification ina proof assistant such as Coq is a promising technique for this verification because it (1)justifies all verification from first principles;(2) is not limited to classes of systems for whichfull automation is possible; and (3) provides a platform for proving powerful; higher-ordermodularity theorems that are crucial for scaling verification to complex systems. In this paper;we demonstrate the practicality; utility; and scalability of this approach by developing in Coqsound and powerful rules for modular construction and verification of sampled-data cyber-physical systems. We evaluate these rules by using them to verify a number of non-trivialcontrollers enforcing safety properties of a quadcopter; eg a geo-fence. We show that our …,Proceedings of the 13th International Conference on Embedded Software,2016,1
Seamless Integration of Coding and Gameplay: Writing Code Without Knowing it.,Stephen R Foster; Sorin Lerner; William G Griswold,ABSTRACT Numerous designers and researchers have called for seamless integration ofeducation and play in educational games. In the domain of games that teach coding;seamless integration has not been achieved. We present a system (The Orb Game) todemonstrate an extreme level of integration: in which the coding is so seamlessly integratedthat players do not realize they are coding. Our evaluation shows that the integration wassuccessful: players felt that they were playing a game and did not realize they wereprogramming. We also present a generalized framework called Programming by Gaming(PbG) to guide the design of other such games.,FDG,2015,1
Detecting History Sniffing via Information Flow,Dongseok Jang; Ranjit Jhala; Sorin Lerner; Hovav Shacham,*,*,2010,1
Automated refinement checking of CSP programs,Sudipta Kundu; Sorin Lerner; Rajesh Kumar Gupta,*,*,2007,1
Automatic inference of dataflow analyses,Erika Rice; Sorin Lerner; Craig Chambers,Abstract Much of the work of defining compiler optimizations is in writing dataflow analysisflow functions. We leverage some properties of the Rhodium optimization language toautomatically infer sound dataflow analyses. Our technique infers 77% of the rules written byhand by an expert and infers many rules that cover cases omitted in the handwritten rules.,*,2006,1
Parsimony: an IDE for example-guided synthesis of lexers and parsers,Alan Leung; Sorin Lerner,Abstract We present Parsimony; a programming-by-example development environment forsynthesizing lexers and parsers by example. Parsimony provides a graphical interface inwhich the user presents examples simply by selecting and labeling sample text in a texteditor. An underlying synthesis engine then constructs syntactic rules to solve the system ofconstraints induced by the supplied examples. Parsimony is more expressive and usablethan prior programming-by-example systems for parsers in several ways: Parsimony can (1)synthesize lexer rules in addition to productions;(2) solve for much larger constraint systemsover multiple examples; rather than handling examples one-at-a-time; and (3) infer muchmore complex sets of productions; such as entire algebraic expression grammars; bydetecting instances of well-known grammar design patterns. The results of a controlled …,Proceedings of the 32nd IEEE/ACM International Conference on Automated Software Engineering,2017,*
User-Guided Synthesis of Interactive Diagrams,John Sarracino; Odaris Barrios-Arciga; Jasmine Zhu; Noah Marcus; Sorin Lerner; Ben Wiedermann,Abstract Interactive diagrams are expensive to build; requiring significant programmingexperience. The cost of building such diagrams often prevents novice programmers or non-programmers from doing so. In this paper; we present user-guided techniques that transforma static diagram into an interactive one without requiring the user to write code. We alsopresent a tool called EDDIE that prototypes these techniques. We evaluate EDDIEthrough:(1) a case study in which we use EDDIE to implement existing real-world diagramsfrom the literature and (2) a usability session with target users in which subjects buildseveral diagrams in EDDIE and provide feedback on EDDIE's user experience. Ourexperiments demonstrate that EDDIE is usable and expressive; and that EDDIE enables real-world diagrams to be implemented without requiring programming expertise.,Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems,2017,*
Printing floating-point numbers: a faster; always correct method,Marc Andrysco; Ranjit Jhala; Sorin Lerner,Abstract Floating-point numbers are an essential part of modern software; recently gainingparticular prominence on the web as the exclusive numeric format of Javascript. To usefloating-point numbers; we require a way to convert binary machine representations intohuman readable decimal outputs. Existing conversion algorithms make trade-offs betweencompleteness and performance. The classic Dragon4 algorithm by Steele and White and itslater refinements achieve completeness---ie produce correct and optimal outputs on allinputs---by using arbitrary precision integer (bignum) arithmetic which leads to a highperformance cost. On the other hand; the recent Grisu3 algorithm by Loitsch shows how torecover performance by using native integer arithmetic but sacrifices optimality for 0.5% ofall inputs. We present Errol; a new complete algorithm that is guaranteed to produce …,ACM SIGPLAN Notices,2016,*
Daniel Ricketts,Daniel Ricketts; Gregory Malecha; Mario M Alvarez; Vignesh Gowda; Sorin Lerner; Valentin Robert; Dongseok Jang; Zachary Tatlock,2011.06–2011.08 Software Engineer Intern; Telefónica Research; Madrid; Spain. Telefónicais a telecommunications provider in Spain and Latin America. Developed an Androidapplication for labeling a user's important locations based on GPS traces. Developedfeatures allowing the users to visualize useful aspects of their mobility data. 2009.09–2010.08 Software Engineer; INRIA; Orsay; France. Supervisor: Leslie Lamport. INRIA is aFrench national research institution focusing on computer science and applied math.Developed the TLA+ Toolbox; an Eclipse-based IDE for developing formal specifications.Worked to incorporate tools for model checking and automated theorem proving into theToolbox.,Conference on; pages,2015,*
Using metaphors from natural discussion to improve the design of arcum,Macneil Shonle; William G Griswold; Sorin Lerner,Abstract In this paper we present an exploratory pair-programming study aimed atinvestigating how programmers use a tool and language designed for performingcrosscutting change tasks. Through a qualitative analysis of the pairs' discussions; weidentify the metaphors that the participants used to think about crosscutting change tasks;which allowed us to infer their expectations. The metaphors of particular interest were thecomparisons participants used to describe their approach in terms of other meta and non-meta programming tasks. From this analysis; we identified challenges the participantsencountered in writing custom checks and refactorings.,Proceedings of the 3rd ACM SIGPLAN workshop on Evaluation and usability of programming languages and tools,2011,*
Equality Saturation: A New Approach to Optimization,Sorin Lerner; Zachary Tatlock; Michael Stepp; Ross Tate,Optimizations in a traditional compiler are applied sequentially; with each optimizationdestructively modifying the program to produce a transformed program that is then passed tothe next optimization. We present a new approach for structuring the optimization phase of acompiler. In our approach; optimizations take the form of equality analyses that add equalityinformation to a common intermediate representation. The optimizer works by repeatedlyapplying these analyses to infer equivalences between program fragments; thus saturatingthe intermediate representation with equalities. Once saturated; the intermediaterepresentation encodes multiple optimized versions of the input program. At this point; aprofitability heuristic picks the final optimized program from the various programsrepresented in the saturated representation. Our proposed way of structuring optimizers …,Logical Methods in Computer Science,2011,*
Verification Using Automated Theorem Provers,Sudipta Kundu; Sorin Lerner; Rajesh K Gupta,Abstract An automated theorem prover is a tool that determines; automatically or semi-automatically; the validity of formulas in a particular logic. Automated theorem provers havebeen put to use in many applications. They have been used to solve open problems inmathematics; such as Robbin's problem in boolean algebra [140]; which was open since the1930s; and various open problems about quasigroups [188]. They have also been used toprove interesting properties about real-world systems; properties that would have been hard;difficult or tedious to prove by hand. For example; automated theorem provers have beenused to verify microprocessors [19; 20; 164]; communication protocols [20]; concurrentalgorithms [20]; and various properties of software systems [9; 58; 100; 130; 132; 164; 168].,*,2011,*
Conclusions and Future Work,Sudipta Kundu; Sorin Lerner; Rajesh K Gupta,Abstract We have addressed the need for high-level verificationmethodologies that allowsus to do functional verification early in the design phase and then iteratively use correctrefinement steps to generate the final RTL design. We believe that by performing verificationon the high-level design; where the design description is smaller in size and the designintent information is easier to extract; and then checking that all refinement steps are correct;the domain of high-level verificationcan provide strong and expressive guarantees thatwould have been difficult to achieve by directly analyzing the low-level RTL code.,*,2011,*
Execution-Based Model Checking for High-Level Designs,Sudipta Kundu; Sorin Lerner; Rajesh K Gupta,Abstract In this chapter; we present an high-level property checking approach. We beginwith a general description of verification of concurrent programs; and then describe it for ahigh-level language called SystemC [78]. In this approach; we start with a design written inSystemC; and then use model checking techniques to verify that the design satisfies a givenproperty such as the absence of deadlocks or assertion violations.,*,2011,*
A flexible semantic framework for effects,Ross Tate; Daan Leijen; Sorin Lerner,Abstract. Effects are a powerful and convenient component of programming. They enableprogrammers to interact with the user; take advantage of efficient stateful memory; throwexceptions; and non-deterministically execute programs in parallel. However; they alsocomplicate every aspect of reasoning about a program or language; and as a result it iscrucially important to have a good understanding of what effects are and how they work. Inthis paper we present a new framework for formalizing the semantics of effects that is moregeneral and thorough than previous techniques while clarifying many of the importantconcepts. By returning to the category-theoretic roots of monads; our framework is richenough to describe the semantics of effects for a large class of languages including commonimperative and functional languages. It is also capable of capturing more expressive …,*,2010,*
High-Level Verification (IPSJ Transactions on System LSI Design Methodology Vol. 2),SUDIPTA KUNDU; SORIN LERNER; RAJESH GUPTA,CiNii 国立情報学研究所 学術情報ナビゲータ[サイニィ]. メニュー 検索 …,情報処理学会論文誌 論文誌トランザクション,2009,*
The Techniques Programmers use to Cope with Crosscutting using Arcum,Macneil Shonle; William G Griswold; Sorin Lerner,ABSTRACT At their most essential; aspect languages; program analysis tools; andrefactoring tools attempt to give programmers mechanisms to make it more cost effective tomanage the crosscutting behavior in their programs. Arcum is a tool to help managecrosscutting that lets programmers define custom program checks and programtransformations; using a declarative language [22]. In this paper we present a study aimed atinvestigating how programmers use Arcum for managing the complexity of crosscutting. Inparticular; we recorded and transcribed three pairs of programmers performing a variety oftasks using Arcum. By informally analyzing the language in the transcript; we identify themetaphors that the participants used to think about crosscutting design idioms; and thedevelopment styles that they used to build solutions. Based on these observations; we …,*,2008,*
Programming Models for Developing Reliable Systems (TOPMoDRS),Cristian Tapus; Jason Hickey; Ranjit Jhala; Joe Kiniry; Sorin Lerner; Nenad Medvidovic; Cristina Nita-Rotaru; Aleksey Nogin; Nicolae Tapus; Yuval Tamir,The 1 st TOPMoDRS workshop is a half-day session held at the International Parallel andDistributed Processing Symposium (IPDPS 2007). The workshop focuses on tools andprogramming models for designing reliable systems with a special focus on distributedapplications. The main goal of the workshop is to bring researchers and practitionerstogether in a setting where they can discuss interesting research topics; like:• novelarchitectures to build reliable distributed systems;• the design and implementation of newtools; techniques; programming languages; and compilers to increase the reliability ofdistributed systems;• bug finding and debugging tools for distributed applications; and• newdevelopments in formal verification of distributed environments. The TOPMoDRS 2007session is composed of five refereed papers selected from fourteen submissions. The …,*,2007,*
The Bershad-Weld Index: Predicting the Economy based on CSE Faculty Leaves,Sorin Lerner; Stefan Saroiu,Abstract Current economic indexes; such the NASDAQ index; are reactive: they reflect thecurrent state of the economy. Unfortunately; such reactive indexes are not useful forpredicting economic growth; and therefore cannot be used to effectively make money in thestock market. In this paper; we present a predictive; rather than reactive; economic index thatis based on CSE faculty leaves. Our new index; which we call the Bershad-Weld Index(BWI); is shown to be accurate; effective; simple to compute; and easy to understand.,*,2002,*
bstract Interpretation,Sorin Lerner,The work surveyed in class so far was not concerned with proving correctness of dataflowanalyses. We saw algorithms for computing properties of a program; but it was not shownthat these properties correctly characterized the program. Although it would be possible toreason about the correctness of dataflow analyses one at a time; a unified framework wouldmake the proofs easier to understand and to develop. Abstract interpretation is exactly sucha framework: it provides a unified theory of fixpoint approximations which (amongst otherthings) can be used to formalize the notion of correctness of a dataflow analysis with respectto the semantics of a program. This is achieved by relating the solution of a dataflow analysiswith the behaviors of a program; and guaranteeing that the dataflow solution over-estimatesthe possible behaviors of the program.,*,2001,*
Type Inference with Run-time Logs (Work in Progress),Ravi Chugh; Ranjit Jhala; Sorin Lerner,Abstract. Gradual type systems offer the possibility of migrating programs in dynamically-typed languages to more statically-typed ones. There is little evidence yet that large; real-world dynamically-typed programs can be migrated with a large degree of automation.Unfortunately; since these systems typically lack principal types; fully automatic typeinference is beyond reach. To combat this challenge; we propose using logs from run-timeexecutions to assist inference. As a first step; in this paper we study how to use run-time logsto improve the efficiency of a type inference algorithm for a small language with first-orderfunctions; records; parametric polymorphism; subtyping; and bounded quantification.Handling more expressive features in order to scale up to gradual type systems for dynamiclanguages is left to future work.,*,*,*
WIR 2011,Florent Bouchez; Sebastian Hack; Eelco Visser; Martin Bravenboer; Albert Cohen; François de Ferrière; Robert Fuhrer; Andrew Kennedy; Sorin Lerner; Nathaniel Nystrom; Simon Peyton Jones; Tijs van der Storm,A not-for-profit organization; IEEE is the world's largest technical professional organization dedicatedto advancing technology for the benefit of humanity. © Copyright 2017 IEEE - All rightsreserved. Use of this web site signifies your agreement to the terms and conditions.,*,*,*
Paul Anderson; Grammatech; USA Giulio Antoniol; Research Centre on Software Technology; Università degli Studi del Sannio; Italy Ira Baxter; Semantic Designs;...,Magiel Bruntink; Liz Burd; Jim Cordy; Sebastian Danicic; Tom Dean; Andrea De Lucia; Massimiliano Di Penta; Keith Gallagher; Michael Godfrey; Tibor Gyimóthy; Mark Harman; Katsuro Inoue; Ákos Kiss; Bogdan Korel; Rainer Koschke; Jens Krinke; Sorin Lerner; Spiros Mancoridis; Matthieu Martel; Ana Milanova; Leon Moonen; Malcolm Munro; Jurgen Rilling; Atanas Rountev; Barbara Ryder; Sibylle Schupp; Paolo Tonella; Tom Tourwé; Michael Van De Vanter; Andrew Walenstein; Jim Whitehead; Baowen Xu,Paul Anderson; Grammatech; USA Giulio Antoniol; Research Centre on SoftwareTechnology; Università degli Studi del Sannio; Italy Ira Baxter; Semantic Designs; USA DaveBinkley; Computer Science Department; Loyola College; Maryland; USA Magiel Bruntink; Centrumvoor Wiskunde en Informatica; Netherlands Liz Burd; Department of Computer Science; Universityof Durham; UK Jim Cordy; School of Computing; Queen's University; Canada SebastianDanicic; Department of Mathematical and Computing Sciences; Goldsmiths College; UK TomDean; Department of Electrical and Computer Engineering; Queen's University; Canada AndreaDe Lucia; Dipartimento di Matematica e Informatica; Università degli Studi di Salerno; Italy MassimilianoDi Penta; Research Centre on Software Technology; Università degli Studi del Sannio; Italy KeithGallagher; Department of Computer Science; University of Durham; UK Michael Godfrey …,*,*,*
Michael Van De Vanter; Sun Microsystems; USA Andrew Walenstein; University of Louisiana at Lafeyette; USA Ji Wang; National University of Defense Technology;...,Paul Anderson; Giuliano Antoniol; Françoise Balmas; Ira Baxter; Dave Binkley; Magiel Bruntink; Liz Burd; Cristina Cifuentes; Sebastian Danicic; Thomas Dean; Andrea De Lucia; Massimiliano Di Penta; John Field; Keith Gallagher; Michael Godfrey; Susan L Graham; Tibor Gyimóthy; Mark Harman; Katsuro Inoue; Stan Jarzabek; Maozhong Jin; Bogdan Korel; Rainer Koschke; Jens Krinke; Ralf Lämmel; Dawn J Lawrie; Sorin Lerner; Xuandong Li; Anirban Majumdar; Matthieu Martel; Ana Milanova; Leon Moonen; Jurgen Rilling; Sibylle Schupp; Tarja Systä; Paolo Tonella,Paul Anderson; GrammaTech; USA Giuliano Antoniol; École Polytechnque de Montréal; CanadaFrançoise Balmas; Université Paris 8; France Ira Baxter; Semantic Designs; USA DaveBinkley; Loyola College in Maryland; USA Magiel Bruntink; Centrum voor Wiskunde enInformatica; Netherlands Liz Burd; University of Durham; UK Cristina Cifuentes; Sun MicrosystemsLabs; Australia Sebastian Danicic; Goldsmiths College; UK Thomas Dean; Queen'sUniversity; Canada Andrea De Lucia; Università degli Studi di Salerno; Italy Massimiliano DiPenta; Università degli Studi del Sannio; Italy John Field; IBM TJ Watson Research Center; USAKeith Gallagher; University of Durham; UK Michael Godfrey; University of Waterloo; CanadaSusan L. Graham; University of California at Berkeley; USA Tibor Gyimóthy; University ofSzeged; Hungary Mark Harman; King's College London; UK Katsuro Inoue; Osaka …,*,*,*
