Evaluating probabilistic queries over imprecise data,Reynold Cheng; Dmitri V Kalashnikov; Sunil Prabhakar,Abstract Many applications employ sensors for monitoring entities such as temperature andwind speed. A centralized database tracks these entities to enable query processing. Due tocontinuous changes in these values and limited resources (eg; network bandwidth andbattery power); it is often infeasible to store the exact values at all times. A similar situationexists for moving object environments that track the constantly changing locations of objects.In this environment; it is possible for database queries to produce incorrect or invalid resultsbased upon old data. However; if the degree of error (or uncertainty) between the actualvalue and the database value is controlled; one can place more confidence in the answersto queries. More generally; query answers can be augmented with probabilistic estimates ofthe validity of the answers. In this paper we study probabilistic query evaluation based …,Proceedings of the 2003 ACM SIGMOD international conference on Management of data,2003,737
Querying imprecise data in moving object environments,Reynold Cheng; Dmitri V Kalashnikov; Sunil Prabhakar,In moving object environments; it is infeasible for the database tracking the movement ofobjects to store the exact locations of objects at all times. Typically; the location of an objectis known with certainty only at the time of the update. The uncertainty in its locationincreases until the next update. In this environment; it is possible for queries to produceincorrect results based upon old data. However; if the degree of uncertainty is controlled;then the error of the answers to queries can be reduced. More generally; query answers canbe augmented with probabilistic estimates of the validity of the answer. We study theexecution of probabilistic range and nearest-neighbor queries. The imprecision in answersto queries is an inherent property of these applications due to uncertainty in data; unlike thetechniques for approximate nearest-neighbor processing that trade accuracy for …,IEEE Transactions on Knowledge and Data Engineering,2004,591
Query indexing and velocity constrained indexing: Scalable techniques for continuous queries on moving objects,Sunil Prabhakar; Yuni Xia; Dmitri V Kalashnikov; Walid G Aref; Susanne E Hambrusch,Moving object environments are characterized by large numbers of moving objects andnumerous concurrent continuous queries over these objects. Efficient evaluation of thesequeries in response to the movement of the objects is critical for supporting acceptableresponse times. In such environments; the traditional approach of building an index on theobjects (data) suffers from the need for frequent updates and thereby results in poorperformance. In fact; a brute force; no-index strategy yields better performance in manycases. Neither the traditional approach nor the brute force strategy achieve reasonablequery processing times. This paper develops novel techniques for the efficient and scalableevaluation of multiple continuous queries on moving objects. Our solution leverages twocomplimentary techniques: Query Indexing and Velocity Constrained Indexing (VCI) …,IEEE Transactions on Computers,2002,419
Domain-independent data cleaning via analysis of entity-relationship graph,Dmitri V Kalashnikov; Sharad Mehrotra,Abstract In this article; we address the problem of reference disambiguation. Specifically; weconsider a situation where entities in the database are referred to using descriptions (eg; aset of instantiated attributes). The objective of reference disambiguation is to identify theunique entity to which each description corresponds. The key difference between theapproach we propose (called RelDC) and the traditional techniques is that RelDC analyzesnot only object features but also inter-object relationships to improve the disambiguationquality. Our extensive experiments over two real data sets and over synthetic datasets showthat analysis of relationships significantly improves quality of the result.,ACM Transactions on Database Systems (TODS),2006,186
Exploiting relationships for domain-independent data cleaning,Dmitri V Kalashnikov; Sharad Mehrotra; Zhaoqi Chen,Abstract In this paper we address the problem of reference disambiguation. Specifically; weconsider a situation where entities in the database are referred to using descriptions (eg; aset of instantiated attributes). The objective of reference disambiguation is to identify theunique entity to which each description corresponds. The key difference between theapproach we propose (called RelDC) and the traditional techniques is that RelDC analyzesnot only object features but also inter-object relationships to improve the disambiguationquality. Our extensive experiments over two real datasets and also over synthetic datasetsshow that analysis of relationships significantly improves quality of the result.,*,2005,156
Efficient evaluation of continuous range queries on moving objects,D Kalashnikov; Sunil Prabhakar; Susanne Hambrusch; Walid Aref,Abstract In this paper we evaluate several in-memory algorithms for efficient and scalableprocessing of continuous range queries over collections of moving objects. Constantupdates to the index are avoided by query indexing. No constraints are imposed on thespeed or path of moving objects. We present a detailed analysis of a grid approach whichshows the best results for both skewed and uniform data. A sorting based optimization isdeveloped for significantly improving the cache hit ratio. Experimental evaluationestablishes that indexing queries using the Grid index yields orders of magnitude betterperformance than other index structures such as R*-trees.,International Conference on Database and Expert Systems Applications,2002,117
Main memory evaluation of monitoring queries over moving objects,Dmitri V Kalashnikov; Sunil Prabhakar; Susanne E Hambrusch,Abstract In this paper we evaluate several in-memory algorithms for efficient and scalableprocessing of continuous range queries over collections of moving objects. Constantupdates to the index are avoided by query indexing. No constraints are imposed on thespeed or path of moving objects or fraction of objects that move at any moment in time. Wepresent a detailed analysis of a grid approach which shows the best results for both skewedand uniform data. A sorting based optimization is developed for significantly improving thecache hit-rate. Experimental evaluation establishes that indexing queries using the gridindex yields orders of magnitude better performance than other index structures such as R*-trees.,Distributed and Parallel Databases,2004,115
Project RESCUE: challenges in responding to the unexpected,Sharad Mehrotra; CT Butts; Dmitri Kalashnikov; Nalini Venkatasubramanian; Ramesh R Rao; Ganz Chockalingam; Ron Eguchi; BJ Adams; Charles Huyck,This paper provides an overview of Project RESCUE; which aims to enhance the mitigationcapabilities of first responders in the event of a crisis by dramatically transforming their abilityto collect; store; analyze; interpret; share and disseminate data. The multidisciplinaryresearch agenda incorporates a variety of information technologies: networks; distributedsystems; databases; image and video processing; and machine learning; together withsubjective information obtained through social science. While the IT challenges focus onsystems and algorithms to get the right information to the right person at the right time; socialscience provides the right context. Besides providing an overview of the nature of RESCUEresearch activities the paper highlights challenges of particular interest to the internetimaging community.,Internet Imaging V,2003,107
Exploiting relationships for object consolidation,Zhaoqi Chen; Dmitri V Kalashnikov; Sharad Mehrotra,Abstract Data mining practitioners frequently have to spend significant portion of their projecttime on data preprocessing before they can apply their algorithms on real-world datasets.Such a preprocessing is required because many real-world datasets are not perfect; butrather they contain missing; erroneous; duplicate data and other data cleaning problems. Itis a well established fact that; in general; if such problems with data are not corrected;applying data mining algorithm can lead to wrong results. The latter is known as the"garbage in; garbage out" principle. Given the significance of the problem; numerous datacleaning techniques have been designed in the past to address the aforementionedproblems with data. In this paper; we address one of the data cleaning challenges; calledobject consolidation. This important challenge arises because objects in datasets are …,Proceedings of the 2nd international workshop on Information quality in information systems,2005,86
Adaptive graphical approach to entity resolution,Zhaoqi Chen; Dmitri V Kalashnikov; Sharad Mehrotra,Abstract Entity resolution is a very common Information Quality (IQ) problem with manydifferent applications. In digital libraries; it is related to problems of citation matching andauthor name disambiguation; in Natural Language Processing; it is related to coreferencematching and object identity; in Web application; it is related to Web page disambiguation.The problem of Entity Resolution arises because objects/entities in real world datasets areoften referred to by descriptions; which might not be unique identifiers of these entities;leading to ambiguity. The goal is to group all the entity descriptions that refer to the samereal world entities. In this paper we present a graphical approach for entity resolution. Itcomplements the traditional methodology with the analysis of the entity-relationship graphconstructed for the dataset being analyzed. The paper demonstrates that a technique that …,Proceedings of the 7th ACM/IEEE-CS joint conference on Digital libraries,2007,79
Web people search via connection analysis,Dmitri V Kalashnikov; Zhaoqi Chen; Sharad Mehrotra; Rabia Nuray-Turan,Nowadays; searches for Webpages of a person with a given name constitute a notablefraction of queries to web search engines. Such a query would normally return Webpagesrelated to several namesakes; who happened to have the queried name; leaving the burdenof disambiguating and collecting pages relevant to a particular person (from among thenamesakes) on the user. In this article we develop a Web People Search approach thatclusters Webpages based on their association to different people. Our method exploits avariety of semantic information extracted from Web pages; such as named entities andhyperlinks; to disambiguate among namesakes referred to on the Web pages. Wedemonstrate the effectiveness of our approach by testing the efficacy of the disambiguationalgorithms and its impact on person search.,IEEE Transactions on Knowledge and Data Engineering,2008,73
Exploiting context analysis for combining multiple entity resolution systems,Zhaoqi Chen; Dmitri V Kalashnikov; Sharad Mehrotra,Abstract Entity Resolution (ER) is an important real world problem that has attractedsignificant research interest over the past few years. It deals with determining which objectdescriptions co-refer in a dataset. Due to its practical significance for data mining and dataanalysis tasks many different ER approaches has been developed to address the ERchallenge. This paper proposes a new ER Ensemble framework. The task of ER Ensembleis to combine the results of multiple base-level ER systems into a single solution with thegoal of increasing the quality of ER. The framework proposed in this paper leverages theobservation that often no single ER method always performs the best; consistentlyoutperforming other ER techniques in terms of quality. Instead; different ER solutionsperform better in different contexts. The framework employs two novel combining …,Proceedings of the 2009 ACM SIGMOD International Conference on Management of data,2009,72
Towards breaking the quality curse.: a web-querying approach to web people search.,Dmitri V Kalashnikov; Rabia Nuray-Turan; Sharad Mehrotra,Abstract Searching for people on the Web is one of the most common query types to the websearch engines today. However; when a person name is queried; the returned webpagesoften contain documents related to several distinct namesakes who have the queried name.The task of disambiguating and finding the webpages related to the specific person ofinterest is left to the user. Many Web People Search (WePS) approaches have beendeveloped recently that attempt to automate this disambiguation process. Nevertheless; thedisambiguation quality of these techniques leaves a major room for improvement. Thispaper presents a new server-side WePS approach. It is based on collecting co-occurrenceinformation from theWeb and thus it uses theWeb as an external data source. A skyline-based classification technique is developed for classifying the collected co-occurrence …,Proceedings of the 31st annual international ACM SIGIR conference on Research and development in information retrieval,2008,44
Disambiguation algorithm for people search on the web,Dmitri V Kalashnikov; Sharad Mehrotra; Zhaoqi Chen; Rabia Nuray-Turan; Naveen Ashish,In this paper we develop a disambiguation algorithm and then study its impact on PeopleSearch. The proposed algorithm first uses extraction techniques to automaticallyextractsignificant'entities such as the names of other persons; organizations; and locationson each Web page. In addition; it extracts and parses HTML and Web related data on eachWeb page; such as hyperlinks and email addresses. The algorithm then views all thisinformation in a unified way: as an entity-relationship graph where entities (eg; people;organizations; locations; Web pages) are interconnected via relationships (eg;Web page-mentions-person'; relationships derived from hyperlinks; etc). The algorithm gains its powerby being able to analyze several types of information: attributes associated with the entities(eg; TF/IDF for Web pages) and; most importantly; direct and indirect interconnections that …,Data Engineering; 2007. ICDE 2007. IEEE 23rd International Conference on,2007,43
Issues and evaluations of caching solutions for web application acceleration,Wen-Syan Li; Wang-Pin Hsiung; Dmitri V Kalashnikov; Radu Sion; Oliver Po; Divyakant Agrawal; K Selçuk Candan,Response time and reliability are two key points of differentiation among e-commerce Websites. In business terms; the brand name of an e-commerce site is correlated to the type ofexperience users receive. The need to account for users' quality perception in designingWeb servers for e-commerce systems has been highlighted in this chapter. Snafus and slow-downs at major Web sites during special events or peak times demonstrate the difficulty ofscaling up e-commerce sites. Slow response times and down times can be devastating for e-commerce sites. In technical terms; ensuring the timely delivery of fresh dynamic content toend-users and engineering highly scalable e-commerce Web sites for special peak accesstimes put heavy demand on IT staff. This is compounded by the ever-changing complexity ofe-commerce applications. For many e-commerce applications; Web pages are created …,*,2002,42
Evaluation of probabilistic queries over imprecise data in constantly-evolving environments,Reynold Cheng; Dmitri V Kalashnikov; Sunil Prabhakar,Abstract Sensors are often employed to monitor continuously changing entities like locationsof moving objects and temperature. The sensor readings are reported to a database system;and are subsequently used to answer queries. Due to continuous changes in these valuesand limited resources (eg; network bandwidth and battery power); the database may not beable to keep track of the actual values of the entities. Queries that use these old values mayproduce incorrect answers. However; if the degree of uncertainty between the actual datavalue and the database value is limited; one can place more confidence in the answers tothe queries. More generally; query answers can be augmented with probabilistic guaranteesof the validity of the answers. In this paper; we study probabilistic query evaluation based onuncertain data. A classification of queries is made based upon the nature of the result set …,Information Systems,2007,41
A unified framework for context assisted face clustering,Liyan Zhang; Dmitri V Kalashnikov; Sharad Mehrotra,Abstract Automatic face clustering; which aims to group faces referring to the same peopletogether; is a key component for face tagging and image management. Standard faceclustering approaches that are based on analyzing facial features can already achieve high-precision results. However; they often suffer from low recall due to the large variation offaces in pose; expression; illumination; occlusion; etc. To improve the clustering recallwithout reducing the high precision; we leverage the heterogeneous context information toiteratively merge the clusters referring to same entities. We first investigate the appropriatemethods to utilize the context information at the cluster level; including using of" commonscene"; people co-occurrence; human attributes; and clothing. We then propose a unifiedframework that employs bootstrapping to automatically learn adaptive rules to integrate …,Proceedings of the 3rd ACM conference on International conference on multimedia retrieval,2013,38
Quasar: quality aware sensing architecture,Iosif Lazaridis; Qi Han; Xingbo Yu; Sharad Mehrotra; Nalini Venkatasubramanian; Dmitri V Kalashnikov; Weiwen Yang,Abstract Sensor devices are promising to revolutionize our interaction with the physicalworld by allowing continuous monitoring and reaction to natural and artificial processes atan unprecedented level of spatial and temporal resolution. As sensors become smaller;cheaper and more configurable; systems incorporating large numbers of them becomefeasible. Besides the technological aspects of sensor design; a critical factor enabling futuresensor-driven applications will be the availability of an integrated infrastructure taking careof the onus of data management. Ideally; accessing sensor data should be no difficult orinconvenient than using simple SQL. In this paper we investigate some of the issues thatsuch an infrastructure must address. Unlike conventional distributed database systems; asensor data architecture must handle extremely high data generation rates from a large …,ACM SIGMOD Record,2004,38
Progressive approach to relational entity resolution,Yasser Altowim; Dmitri V Kalashnikov; Sharad Mehrotra,Abstract This paper proposes a progressive approach to entity resolution (ER) that allowsusers to explore a trade-off between the resolution cost and the achieved quality of theresolved data. In particular; our approach aims to produce the highest quality result given aconstraint on the resolution budget; specified by the user. Our proposed method monitorsand dynamically reassesses the resolution progress to determine which parts of the datashould be resolved next and how they should be resolved. The comprehensive empiricalevaluation of the proposed approach demonstrates its significant advantage in terms ofefficiency over the traditional ER techniques for the given problem settings.,Proceedings of the VLDB Endowment,2014,34
Context-based person identification framework for smart video surveillance,Liyan Zhang; Dmitri V Kalashnikov; Sharad Mehrotra; Ronen Vaisenberg,Abstract Smart video surveillance (SVS) applications enhance situational awareness byallowing domain analysts to focus on the events of higher priority. SVS approaches operateby trying to extract and interpret higher “semantic” level events that occur in video. One of thekey challenges of SVS is that of person identification where the task is for each subject thatoccurs in a video shot to identify the person it corresponds to. The problem of personidentification is especially challenging in resource-constrained environments wheretransmission delay; bandwidth restriction; and packet loss may prevent the capture of high-quality data. Conventional person identification approaches which primarily are based onanalyzing facial features are often not sufficient to deal with poor-quality data. To addressthis challenge; we propose a framework that leverages heterogeneous contextual …,Machine Vision and Applications,2014,31
Query-driven approach to entity resolution,Hotham Altwaijry; Dmitri V Kalashnikov; Sharad Mehrotra,Abstract This paper explores" on-the-fly" data cleaning in the context of a user query. A novelQuery-Driven Approach (QDA) is developed that performs a minimal number of cleaningsteps that are only necessary to answer a given selection query correctly. Thecomprehensive empirical evaluation of the proposed approach demonstrates its significantadvantage in terms of efficiency over traditional techniques for query-driven applications.,Proceedings of the VLDB Endowment,2013,31
Toward managing uncertain spatial information for situational awareness applications,Yiming Ma; Dmitri V Kalashnikov; Sharad Mehrotra,Situational awareness (SA) applications monitor the real world and the entities therein tosupport tasks such as rapid decision-making; reasoning; and analysis. Raw input aboutunfolding events may arrive from variety of sources in the form of sensor data; video streams;human observations; and so on; from which events of interest are extracted. Location is oneof the most important attributes of events; useful for a variety of SA tasks. In this article; weconsider the problem of reaching situation awareness from textual input. We propose anapproach to probabilistically model and represent (potentially uncertain) event locationsdescribed by human reporters in the form of free text. We analyze several types of spatialqueries of interest in SA applications. We design techniques to store and index the models;to support the efficient processing of queries. Our extensive experimental evaluation over …,IEEE Transactions on Knowledge and Data Engineering,2008,28
Modeling and querying uncertain spatial information for situational awareness applications,Dmitri V Kalashnikov; Yiming Ma; Sharad Mehrotra; Ramaswamy Hariharan; Carter Butts,Abstract Situational awareness (SA) applications monitor the real world and the entitiestherein to support tasks such as rapid decision-making; reasoning; and analysis. Raw inputabout unfolding events may arrive from variety of sources in the form of sensor data; videostreams; human observations; and so on; from which events of interest are extracted.Location is one of the most important attributes of events; useful for a variety of SA tasks. Inthis paper; we propose an approach to model and represent (potentially uncertain) eventlocations described by human reporters in the form of free text. We analyze several types ofspatial queries of interest in SA applications. Our experimental evaluation demonstrates theeffectiveness of our approach.,Proceedings of the 14th annual ACM international symposium on Advances in geographic information systems,2006,25
Index for fast retrieval of uncertain spatial point data,Dmitri V Kalashnikov; Yiming Ma; Sharad Mehrotra; Ramaswamy Hariharan,Abstract Location information gathered from a variety of sources in the form of sensor data;video streams; human observations; and so on; is often imprecise and uncertain and needsto be represented approximately. To represent such uncertain location information; the useof a probabilistic model that captures the imprecise location as a probability density function(pdf) has been recently proposed. The pdfs can be arbitrarily complex depending on thetype of application and the source of imprecision. Hence; efficiently representing; storing andquerying pdfs is a very challenging task. While the current state of the art indexingapproaches treat the representation and storage of pdfs as a black box; in this paper; wetake the challenge of representing and storing any complex pdf in an efficient way. Wefurther develop techniques to index such pdfs to support the efficient processing of …,Proceedings of the 14th annual ACM international symposium on Advances in geographic information systems,2006,25
Similarity join for low-and high-dimensional data,Dmitri V Kalashnikov; Sunil Prabhakar,The efficient processing of similarity joins is important for a large class of applications. Thedimensionality of the data for these applications ranges from low to high. Most existingmethods have focussed on the execution of high-dimensional joins over large amounts ofdisk-based data. The increasing sizes of main memory available on current computers; andthe need for efficient processing of spatial joins suggest that spatial joins for a large class ofproblems can be processed in main memory. In this paper we develop two new spatial joinalgorithms; the Grid-join and EGO-join; and study their performance in comparison to thestate of the art algorithm EGO-join and the RSJ algorithm. Through evaluation we explorethe domain of applicability of each algorithm and provide recommendations for the choice ofjoin algorithm depending upon the dimensionality of the data as well as the critical/spl …,Database Systems for Advanced Applications; 2003.(DASFAA 2003). Proceedings. Eighth International Conference on,2003,25
Situational awareness technologies for disaster response,Naveen Ashish; Ronald Eguchi; Rajesh Hegde; Charles Huyck; Dmitri Kalashnikov; Sharad Mehrotra; Padhraic Smyth; Nalini Venkatasubramanian,This chapter highlights some of the key information technology challenges being addressedin the RESCUE project; a National Science Foundation (NSF) funded 5-year effort; with aparticular focus on situational awareness technologies. A key premise of the project is thatthe critical decision making required in disaster situations relies heavily on the availability;accuracy; and timeliness of information that can be made available to the decision makers. Amajor thrust within RESCUE is focusing on developing next generation situationalawareness technologies. Our approach in building situational awareness systems is to buildinformation systems that consider situations and events as fundamental entities; and ourresearch is focused on the key technical challenges in the extraction and synthesis;management; and analysis of such situational information. This chapter focuses on our …,*,2008,24
CAMAS: a citizen awareness system for crisis mitigation,Sharad Mehrotra; Carter Butts; Dmitri V Kalashnikov; Nalini Venkatasubramanian; Kemal Altintas; Ram Hariharan; Haimin Lee; Yiming Ma; Amnon Myers; Jehan Wickramasuriya; Ron Eguchi; Charles Huyck,Responding to natural or man-made disasters in a timely and effective manner can reducedeaths and injuries; contain or prevent secondary disasters; and reduce the resultingeconomic losses and social disruption. During a crisis; responding organizations confrontgrave uncertainties in making critical decisions. They need to gather situational information(eg; state of the civil; transportation and information infrastructures); together with informationabout available resources (eg; medical facilities; rescue and law enforcement units). Clearly;there is a strong correlation between the accuracy; timeliness; and reliability of theinformation available to the decisionmakers; and the quality of their decisions. The'Responding to Crises and Unexpected Events'(RESCUE) Project [2] was recentlyconceived with the objective of radically transforming the ability of organizations to gather …,Proceedings of the 2004 ACM SIGMOD international conference on Management of data,2004,24
A semantics-based approach for speech annotation of images,Dmitri Kalashnikov; Sharad Mehrotra; Jie Xu; Nalini Venkatasubramanian,Associating textual annotations/tags with multimedia content is among the most effectiveapproaches to organize and to support search over digital images and multimediadatabases. Despite advances in multimedia analysis; effective tagging remains largely amanual process wherein users add descriptive tags by hand; usually when uploading orbrowsing the collection; much after the pictures have been taken. This approach; however; isnot convenient in all situations or for many applications; eg; when users would like to publishand share pictures with others in real time. An alternate approach is to instead utilize aspeech interface using which users may specify image tags that can be transcribed intotextual annotations by employing automated speech recognizers. Such a speech-basedapproach has all the benefits of human tagging without the cumbersomeness and …,IEEE Transactions on Knowledge and Data Engineering,2011,22
Exploiting web querying for web people search in weps2,Rabia Nuray-Turan; Zhaoqi Chen; Dmitri V Kalashnikov; Sharad Mehrota,ABSTRACT Searching for people on the Web is one of the most common query types to theweb search engines today. However; when a person name is queried; the returned resultoften contains webpages related to several distinct namesakes who have the queried name.The task of disambiguating and finding the webpages related to the specific person ofinterest is left to the user. Many Web People Search (WePS) approaches have beendeveloped recently that attempt to automate this disambiguation process. Nevertheless; thedisambiguation quality of these techniques leaves a major room for improvement. In thispaper we describe our experience of applying our WePS approaches developed in [20] inthe context of WePS-2 Clustering Task [14]. The approach is based on extracting namedentities from the web pages and then querying the web to collecting co-occurrence …,*,2009,21
Self-tuning in graph-based reference disambiguation,Rabia Nuray-Turan; Dmitri V Kalashnikov; Sharad Mehrotra,Abstract Nowadays many data mining/analysis applications use the graph analysistechniques for decision making. Many of these techniques are based on the importance ofrelationships among the interacting units. A number of models and measures that analyzethe relationship importance (link structure) have been proposed (eg; centrality; importanceand page rank) and they are generally based on intuition; where the analyst intuitivelydecides a reasonable model that fits the underlying data. In this paper; we address theproblem of learning such models directly from training data. Specifically; we study a way tocalibrate a connection strength measure from training data in the context of referencedisambiguation problem. Experimental evaluation demonstrates that the proposed modelsurpasses the best model used for reference disambiguation in the past; leading to better …,International Conference on Database Systems for Advanced Applications,2007,21
Attribute and object selection queries on objects with probabilistic attributes,Rabia Nuray-Turan; Dmitri V Kalashnikov; Sharad Mehrotra; Yaming Yu,Abstract Modern data processing techniques such as entity resolution; data cleaning;information extraction; and automated tagging often produce results consisting of objectswhose attributes may contain uncertainty. This uncertainty is frequently captured in the formof a set of multiple mutually exclusive value choices for each uncertain attribute along with ameasure of probability for alternative values. However; the lay end-user; as well as someend-applications; might not be able to interpret the results if outputted in such a form. Thus;the question is how to present such results to the user in practice; for example; to supportattribute-value selection and object selection queries the user might be interested in.Specifically; in this article we study the problem of maximizing the quality of these selectionqueries on top of such a probabilistic representation. The quality is measured using the …,ACM Transactions on Database Systems (TODS),2012,20
Exploiting web querying for web people search,Rabia Nuray-Turan; Dmitri V Kalashnikov; Sharad Mehrotra,Abstract Searching for people on the Web is one of the most common query types submittedto Web search engines today. However; when a person name is queried; the returnedWebpages often contain documents related to several distinct namesakes who have thequeried name. The task of disambiguating and finding the Webpages related to the specificperson of interest is left to the user. Many Web People Search (WePS) approaches havebeen developed recently that attempt to automate this disambiguation process.Nevertheless; the disambiguation quality of these techniques leaves major room forimprovement. In this article; we present a new WePS approach. It is based on issuingadditional auxiliary queries to the Web to gain additional knowledge about the Webpagesthat need to be disambiguated. Thus; the approach uses the Web as an external data …,ACM Transactions on Database Systems (TODS),2012,20
Adaptive connection strength models for relationship-based entity resolution,Rabia Nuray-Turan; Dmitri V Kalashnikov; Sharad Mehrotra,Abstract Entity Resolution (ER) is a data quality challenge that deals with ambiguousreferences in data and whose task is to identify all references that co-refer. Due to practicalsignificance of the ER problem; many creative ER techniques have been proposed in thepast; including those that analyze relationships that exist among entities in data. Suchapproaches view the database as an entity-relationship graph; where direct and indirectrelationships correspond to paths in the graph. These techniques rely on measuring theconnection strength among various nodes in the graph by using a connection strength (CS)model. While such approaches have demonstrated significant advantage over traditional ERtechniques; currently they also have a significant limitation: the CS models that they use areintuition-based fixed models that tend to behave well in general; but are very generic and …,Journal of Data and Information Quality (JDIQ),2013,18
A probabilistic model for entity disambiguation using relationships,Dmitri V Kalashnikov; Sharad Mehrotra,Abstract Graphs representing relationships among sets of entities are of increasing focus ofinterest in the context of data analysis applications. These graphs are typically constructedfrom existing datasets from which entities and relationships are extracted. For some of theentities; values in certain attributes would refer to other entities–such references determinerelationships. Often; for certain datasets such references are given in the form of (string)descriptions. Each such description alone may not uniquely identify one entity as it issupposed to; but rather can match descriptions of multiple entities. Such cases areespecially common if the datasets are collected not from one but multiple heterogeneoussources. Thus the correct linking of entities via relationships can be a nontrivial challengewhich; if done incorrectly; can in turn impede further graph-based analyses. To overcome …,SIAM International Conference on Data Mining (SDM). Newport Beach; California,2005,18
Efficient summarization framework for multi-attribute uncertain data,Jie Xu; Dmitri V Kalashnikov; Sharad Mehrotra,Abstract This paper studies the problem of automatically selecting a small subset ofrepresentatives from a set of objects; where objects:(a) are multi-attributed with eachattribute corresponding to different aspects of the object and (b) are associated withuncertainty--the problem that has received little attention in the past. Such object set leads tonew challenges in modeling information contained in data; defining appropriate criteria forselecting objects; and in devising efficient algorithms for such a selection. We propose aframework that models objects as a set of the corresponding information units and reducesthe ummarization problem to that of optimizing probabilistic coverage. To solve the resultingNP-hard problem; we develop a highly efficient greedy algorithm; which gains its efficiencyby leveraging object-level and iteration-level optimization. A comprehensive empirical …,Proceedings of the 2014 ACM SIGMOD international conference on Management of data,2014,15
Fast similarity join for multi-dimensional data,Dmitri V Kalashnikov; Sunil Prabhakar,Abstract The efficient processing of multidimensional similarity joins is important for a largeclass of applications. The dimensionality of the data for these applications ranges from lowto high. Most existing methods have focused on the execution of high-dimensional joins overlarge amounts of disk-based data. The increasing sizes of main memory available on currentcomputers; and the need for efficient processing of spatial joins suggest that spatial joins fora large class of problems can be processed in main memory. In this paper; we develop twonew in-memory spatial join algorithms; the Grid-join and EGO*-join; and study theirperformance. Through evaluation; we explore the domain of applicability of each approachand provide recommendations for the choice of a join algorithm depending upon thedimensionality of the data as well as the expected selectivity of the join. We show that the …,Information Systems,2007,14
Super-EGO: fast multi-dimensional similarity join,Dmitri V Kalashnikov,Abstract Efficient processing of high-dimensional similarity joins plays an important role for awide variety of data-driven applications. In this paper; we consider ε-join variant of theproblem. Given two d-dimensional datasets and parameter ε; the task is to find all pairs ofpoints; one from each dataset that are within ε distance from each other. We propose a new ε-join algorithm; called Super-EGO; which belongs the EGO family of join algorithms. The newalgorithm gains its advantage by using novel data-driven dimensionality re-orderingtechnique; developing a new EGO-strategy that more aggressively avoids unnecessarycomputation; as well as by developing a parallel version of the algorithm. We study thenewly proposed Super-EGO algorithm on large real and synthetic datasets. The empiricalstudy demonstrates significant advantage of the proposed solution over the existing state …,The VLDB Journal,2013,12
Video entity resolution: Applying er techniques for smart video surveillance,Liyan Zhang; Ronen Vaisenberg; Sharad Mehrotra; Dmitri V Kalashnikov,Smart Video Surveillance (SVS) applications enhance situational awareness by allowingdomain analysts to focus on the events of higher priority. This in turn leads to improveddecision making; allows for better resource management; and helps to reduce informationoverload. SVS approaches operate by trying to extract and interpret higher “semantic” levelevents that occur in video. On of the key challenges of Smart Video Surveillance is that ofperson identification where the task is for each subject that occur in a video shot to identifythe person it corresponds to. The problem of person identification is very complex in theresource constrained environments where transmission delay; bandwidth restriction; andpacket loss may prevent the capture of high quality data. In this paper we connect theproblem of person identification in video data with the problem of entity resolution that is …,Pervasive Computing and Communications Workshops (PERCOM Workshops); 2011 IEEE International Conference on,2011,10
Queries as Data and Expanding Indexes: Techniques for Continuous Queries on Moving Objects,S Prabhakar; Y Xia; D Kalashnikov; WG Aref; S Hambrusch,*,Purdue University,2000,10
Query: A framework for integrating entity resolution with query processing,Hotham Altwaijry; Sharad Mehrotra; Dmitri V Kalashnikov,Abstract This paper explores an analysis-aware data cleaning architecture for a large classof SPJ SQL queries. In particular; we propose QuERy; a novel framework for integratingentity resolution (ER) with query processing. The aim of QuERy is to correctly and efficientlyanswer complex queries issued on top of dirty data. The comprehensive empiricalevaluation of the proposed solution demonstrates its significant advantage in terms ofefficiency over the traditional techniques for the given problem settings.,Proceedings of the VLDB Endowment,2015,9
Context-assisted face clustering framework with human-in-the-loop,Liyan Zhang; Dmitri V Kalashnikov; Sharad Mehrotra,Abstract Automatic face clustering; which aims to group faces referring to the same peopletogether; is a key component for face tagging and image management. Standard faceclustering approaches that are based on analyzing facial features can already achieve high-precision results. However; they often suffer from low recall due to the large variation offaces in pose; expression; illumination; occlusion; etc. To improve the clustering recallwithout reducing the high precision; we leverage the heterogeneous context information toiteratively merge the clusters referring to same entities. We first investigate the appropriatemethods to utilize the context information at the cluster level; including using of “commonscene”; people co-occurrence; human attributes; and clothing. We then propose a unifiedframework that employs bootstrapping to automatically learn adaptive rules to integrate …,International Journal of Multimedia Information Retrieval,2014,9
SAT: Spatial awareness from textual input,Dmitri V Kalashnikov; Yiming Ma; Sharad Mehrotra; Ramaswamy Hariharan; Nalini Venkatasubramanian; Naveen Ashish,Abstract Recent events (WTC attacks; Southeast Asia Tsunamis; Hurricane Katrina; Londonbombings) have illustrated the need for accurate and timely situational awareness tools inemergency response. Developing effective situational awareness (SA) systems has thepotential to radically improve decision support in crises by improving the accuracy andreliability of the information available to the decision-makers. In an evolving crisis; rawsituational information comes from a variety of sources in the form of situational reports; liveradio transcripts; sensor data; video streams. Much of the data resides (or can be converted)in the form of free text; from which events of interest are extracted. Spatial or locationinformation is one of the fundamental attributes of the events; and is useful for a variety ofsituational awareness (SA) tasks.,International Conference on Extending Database Technology,2006,9
Efficient and scalable multi-geography route planning,Vidhya Balasubramanian; Dmitri V Kalashnikov; Sharad Mehrotra; Nalini Venkatasubramanian,Abstract This paper considers the problem of Multi-Geography Route Planning (MGRP)where the geographical information may be spread over multiple heterogeneousinterconnected maps. We first design a flexible and scalable representation to modelindividual geographies and their interconnections. Given such a representation; we developan algorithm that exploits precomputation and caching of geographical data for pathplanning. A utility-based approach is adopted to decide which paths to precompute andstore. To validate the proposed approach we test the algorithm over the workload of acampus level evacuation simulation that plans evacuation routes over multiple geographies:indoor CAD maps; outdoor maps; pedestrian and transportation networks; etc. The empiricalresults indicate that the MGRP algorithm with the proposed utility based caching strategy …,Proceedings of the 13th International Conference on Extending Database Technology,2010,8
Using semantics for speech annotation of images,Chaitanya Desai; Dmitri V Kalashnikov; Sharad Mehrotra; Nalini Venkatasubramanian,Digital cameras and multimedia capture devices are becoming increasingly popular to takepictures. Annotating these pictures is important to support their browsing and retrieval. Fullyautomatic image annotation techniques typically rely entirely on visual properties of theimage. The state of the art image annotation systems of this kind work well in detectinggeneric object classes: car; horse; motorcycle; airplane; etc. However; certain characteristicsof the image are hard to capture using strictly the visual properties. These include location(Paris; California; San Francisco; etc); event (birthday; wedding; graduation ceremony; etc);people (John; Jane; brother; etc) and abstract qualities referring to objects in the image(beautiful; funny; sweet; etc) among others. The more conventional method of annotationthat relies completely on human input has several limitations as well. Typing tags using …,Data Engineering; 2009. ICDE'09. IEEE 25th International Conference on,2009,7
West: Modern technologies for web people search,Dmitri V Kalashnikov; Zhaoqi Chen; Rabia Nuray-Turan; Sharad Mehrotra; Zheng Zhang,In this paper we describe WEST (Web Entity Search Technologies) system that we havedeveloped to improve people search over the Internet. Recently the problem of Web PeopleSearch (WePS) has attracted significant attention from both the industry and academia. Inthe classic formulation of WePS problem the user issues a query to a web search enginethat consists of a name of a person of interest. For such a query; a traditional search enginesuch as Yahoo or Google would return webpages that are related to any people whohappened to have the queried name. The goal of WePS; instead; is to output a set of clustersof webpages; one cluster per each distinct person; containing all of the webpages related tothat person. The user then can locate the desired cluster and explore the webpages itcontains.,Data Engineering; 2009. ICDE'09. IEEE 25th International Conference on,2009,7
Query aware determinization of uncertain objects,Jie Xu; Dmitri V Kalashnikov; Sharad Mehrotra,This paper considers the problem of determinizing probabilistic data to enable such data tobe stored in legacy systems that accept only deterministic input. Probabilistic data may begenerated by automated data analysis/enrichment techniques such as entity resolution;information extraction; and speech processing. The legacy system may correspond to pre-existing web applications such as Flickr; Picasa; etc. The goal is to generate a deterministicrepresentation of probabilistic data that optimizes the quality of the end-application built ondeterministic data. We explore such a determinization problem in the context of two differentdata processing tasks-triggers and selection queries. We show that approaches such asthresholding or top-1 selection traditionally used for determinization lead to suboptimalperformance for such applications. Instead; we develop a query-aware strategy and show …,IEEE Transactions on knowledge and data engineering,2015,6
Learning importance of relationships for reference disambiguation,Dmitri V Kalashnikov; Sharad Mehrotra,Abstract In this paper we address the problem of reference disambiguation. Specifically; weconsider a situation where entities in the database are referred to using descriptions (eg; aset of instantiated attributes). The objective of reference disambiguation is to identify theunique entity to which each description corresponds. The key difference between ourapproach and the traditional techniques is that it analyzes not only object features but alsointer-object relationships to improve the disambiguation quality. To analyze relationships ourapproach utilizes a model that measures the degree of interconnectivity of two entities toeach other via chains of relationships that exist between them. Such a model is a keycomponent of the proposed technique. In this paper we concentrate on a method forlearning such a model by learning the importance of different relationships from the data …,Submitted for Publication,2004,6
On-demand information portals for disaster situations,Yiming Ma; Dmitri V Kalashnikov; Ram Hariharan; Sharad Mehrotra; Nalini Venkatasubramanian; Naveen Ashish; Jay Lickfett,This paper describes our work on developing technology for rapidly assembling informationportals that provide integrated access to and analysis of information from multiple sources inthe case of any disaster. Many recent disasters (the SE Asian Tsunamis; the London subwaybombings; the Katrina hurricane; to name a few) have demonstrated that a lot of valuableinformation becomes available in the hours and days immediately following the disaster;and such information is indeed valuable to disaster managers or even citizens in theirresponse. In this paper we describe our work on developing information portals for disastersin general; we describe many key information processing capabilities and challenges thatwe consider important in such portals and also describe our approach to developing suchcapabilities.,Intelligence and Security Informatics; 2007 IEEE,2007,4
Speech-Based Situational Awareness for Crisis Response,Dmitri V Kalashnikov; Dilek Hakkani-Tür; Gokhan Tur; Nalini Venkatasubramanian,The goal of our work is to explore research in the framework of an end-to-end speechprocessing system that can automatically process human conversations to create situationalawareness during crisis response. Situational awareness refers to knowledge about theunfolding crisis event; the needs; the resources; and the context. Accurate assessment of thesituation is vital to enable first responders (and the public) to take appropriate actions thatcan have significant impact on life and property. Consider; for instance; a situation of a largestructural fire wherein teams of fire fighters enter into a burning building for search andrescue. Knowledge of the location of fire fighters; their physiological status; the ambientconditions and environment are critical for the success and safety of both the victims and firefighters. Appropriate situational awareness is critical not just at incident level; but at all …,EMWS DHS Workshop,2009,3
RelDC project,DV Kalashnikov; S Mehrotra,*,*,*,3
Context assisted person identification for images and videos,Liyan Zhang; Dmitri V Kalashnikov; Sharad Mehrotra,The goal of person identification is to associate each subject that occurs in the image/videowith the real-world person it corresponds to. Conventional person identification techniquesthat are primarily based on facial features suffer from poor performance when dealing withlow-quality data or faces with large variation in pose; expression; illumination; occlusion; etc.In this chapter; we systematically introduce context assisted person identification frameworkwhich can integrate heterogeneous contextual information to improve the performance ofboth face clustering and recognition. We first present the appropriate approaches toleverage context features such as clothing; activity; human attributes; gait; people co-occurrence; common scene; etc.; for both computing similarities and constraints. Then todeal with the task of face clustering and tagging; we introduce the unified framework …,*,2016,2
Qda: A query-driven approach to entity resolution,Hotham Altwaijry; Dmitri V Kalashnikov; Sharad Mehrotra,This paper addresses the problem of query-aware data cleaning in the context of a userquery. In particular; we develop a novel Query-Driven Approach (QDA) that systematicallyexploits the semantics of the predicates in SQL-like selection queries to reduce the datacleaning overhead. The objective of QDA is to issue the minimum number of cleaning stepsthat are necessary to answer a given SQL-like selection correctly. The comprehensiveempirical evaluation of QDA demonstrates outstanding results-that is QDA is significantlybetter compared to traditional ER techniques; especially when the query is very selective.,IEEE Transactions on Knowledge and Data Engineering,2017,1
Enabling Change Exploration: Vision Paper,Tobias Bleifuß; Theodore Johnson; Dmitri V Kalashnikov; Felix Naumann; Vladislav Shkapenyuk; Divesh Srivastava,Abstract Data and metadata suffer many different kinds of change: values are inserted;deleted or updated; entities appear and disappear; properties are added or re-purposed;etc. Explicitly recognizing; exploring; and evaluating such change can alert to changes indata ingestion procedures; can help assess data quality; and can improve the generalunderstanding of the dataset and its behavior over time. We propose a data model-independent framework to formalize such change. Our change-cube enables explorationand discovery of such changes to reveal dataset behavior over time.,Proceedings of the ExploreDB'17,2017,*
Query-Driven Approach to Face Clustering and Tagging,Liyan Zhang; Xikui Wang; Dmitri V Kalashnikov; Sharad Mehrotra; Deva Ramanan,In the era of big data; a traditional offline setting to processing image data is simply nottenable. We simply do not have the computational power to process every image with everypossible tag; moreover; we will not have the manpower to clean up the potentially noisyresults. In this paper; we introduce a query-driven approach to visual tagging; focusing onthe application of face tagging and clustering. We integrate active learning with query-drivenprobabilistic databases. Rather than asking a user to provide manual labels so as tominimize the uncertainty of labels (face tags) across the entire data set; we ask the user toprovide labels that minimize the uncertainty of his/her query result (eg;“How many times didBob and Jim appear together?”). We use a data-driven Gaussian process model of facialappearance to write the probabilistic estimates of facial identity into a probabilistic …,IEEE Transactions on Image Processing,2016,*
Early detection of patients with elevated risk of developing diabetes mellitus is critical to the improved prevention and overall clinical management of these patients....,Jie Xu; Dmitri V Kalashnikov; Sharad Mehrotra; Anna Cinzia Squicciarini; Dan Lin; Smitha Sundareswaran; Joshua Wede,Graph-based ranking models have been widely applied in information retrieval area. In thispaper; we focus on a well known graph-based model-the Ranking on Data Manifold model;or Manifold Ranking (MR). Particularly; it has been successfully applied to content-basedimage retrieval; because of its outstanding ability to discover underlying geometricalstructure of the given image database. However;...,IEEE Transactions on Knowledge and Data Engineering,2015,*
An Event Based Approach to Situational Representation,Naveen Ashish; Dmitri Kalashnikov; Sharad Mehrotra; Nalini Venkatasubramanian,Abstract: Many application domains require representing interrelated real-world activitiesand/or evolving physical phenomena. In the crisis response domain; for instance; one maybe interested in representing the state of the unfolding crisis (eg; forest fire); the progress ofthe response activities such as evacuation and traffic control; and the state of the crisis site(s). Such a situation representation can then be used to support a multitude of applicationsincluding situation monitoring; analysis; and planning. In this paper; we make a case for anevent based representation of situations where events are defined to be domain-specificsignificant occurrences in space and time. We argue that events offer a unifying andpowerful abstraction to building situational awareness applications. We identify challengesin building an Event Management System (EMS) for which traditional data and …,arXiv preprint arXiv:0906.4096,2009,*
Indexing; Query and Velocity-Constrained,Sunil Prabhakar; Dmitri Kalashnikov; Yuni Xia,The iDistance is an indexing and query processing technique for k nearest neighbor (kNN)queries on point data in multi-dimensional metric spaces. The kNN query is one of thehardest problems on multi-dimensional data. It has been shown analytically andexperimentally that any algorithm using hierarchical index structure based on either space-or data-partitioning is less efficient than the naive method of sequentially checking everydata record (called the sequential scan) in high-dimensional spaces [4]. Some datadistributions including the uniform distribution are particularly hard cases [1]. The iDistanceis designed to process kNN queries in high-dimensional spaces efficiently and it isespecially good for skewed data distributions; which usually occur in real-life data sets. Foruniform data; the iDistance beats the sequential scan up to 30 dimensions as reported in …,*,2008,*
This paper proposes a design methodology for very small databases for the purpose of being hosted by portable devices. Three main differences wrt the traditional d...,Reynold Cheng; Dmitri V Kalashnikov; Sunil Prabhakar,Sensors are often employed to monitor continuously changing entities like locations ofmoving objects and temperature. The sensor readings are reported to a database system;and are subsequently used to answer queries. Due to continuous changes in these valuesand limited resources (eg; network bandwidth and battery power); the database may not beable to keep track of the actual values of the entities...,Information Systems,2007,*
RelDC: domain-independent data cleaning utilizing relationships,Dmitri V Kalashnikov; Zhaoqi Chen; Sharad Mehrotra,*,*,2004,*
Efficient querying of constantly evolving data,Dmitri V Kalashnikov,The thesis research addresses important challenges in the emerging areas of sensor(streaming data) and moving objects databases. It focuses on the important class ofapplications that are characterized by (a) constant change to the data values;(b) longrunningcontinuous queries that have to be repeatedly evaluated as the data changes;(c) need fornear real-time results; and (d) inherent imprecision in the data. The thesis addresses thescalability and performance challenge inherent to such applications: all solutions have toscale to large problem sizes; such as millions of sources of constantly changing data andtens of thousands of continuous queries. The contribution of this thesis is summarizedbelow.,*,2003,*
Scheduling the Stream of Instructions for Conveyor RISC Architectures,DV Kalashnikov; IV Mashechkin; MI Petrovskii,*,Moscow University Computational Mathematics and Cybernetics,1999,*
Situational Awareness Technologies for Disaster,Naveen Ashish; Dmitri Kalashnikov; Sharad Mehrotra; Nalini Venkatasubramanian; Ron Eguchi; Rajesh Hegde; Padhraic Smyth,Responding to natural or man-made disasters; in a timely and effective manner; can reducedeaths and injuries; contain or prevent secondary disasters; and reduce the resultingeconomic losses and social disruption. During a crisis; responding organizations confrontgrave uncertainties in making critical decisions. They need to gather situational information(eg; state of the civil; transportation and information infrastructures); together with informationabout available resources (eg; medical facilities; rescue and law enforcement units). Thereis a strong correlation between the accuracy; timeliness; and reliability of the informationavailable to the decision-makers; and the quality of their decisions. Dramatic improvementsin the speed and accuracy at which information about the crisis flows through the disasterresponse networks has the potential to revolutionize crisis response; saving human lives …,*,*,*
Event Based Approach to Situational Representation,Dmitri V Kalashnikov Dawit Seid Yiming; Ma Naveen Ashish Sharad Mehrotra Nalini; Venkatasubramanian Cal,ABSTRACT Many application domains require representing interrelated real-world activitiesand/or evolving physical phenomena. In the crisis response domain; for instance; one maybe interested in representing the state of the unfolding crisis (eg; forest fire); the progress ofthe response activities such as evacuation and traffic control; and the state of the crisis site(s). Such a situation representation can then be used to support multitude of applicationsincluding situation monitoring; analysis; and planning. In this paper; we make a case for anevent based representation of situations where events are defined to be domain-specificsignificant occurrences in space and time. We argue that events offer a unifying andpowerful abstraction to building situational awareness applications. We identify challengesin building an Event Management System (EMS) for which traditional data and …,*,*,*
Online Appendix to Domain-Independent Data Cleaning via Analysis of Entity-Relationship Graph,DMITRI V KALASHNIKOV; SHARAD MEHROTRA; A PROBABILISTIC MODEL,In the main body of the article we have presented the weight based model (WM) forcomputing connection strength. In this section of the appendix; we study a differentconnection strength model; called the probabilistic model (PM). In the probabilistic model anedge weight is treated not as “weight” but as “probability” that the edge exists.,*,*,*
Event Based Approach to Situational Awareness,Dmitri Kalashnikov; Dawit Seid; Yiming Ma; Naveen Ashish; Sharad Mehrotra; Nalini Venkatasubramanian,*,Calit2 Report; UC Irvine,*,*
Computing connection strength in probabilistic graphs,Dmitri V Kalashnikov; Sharad Mehrotra,Abstract Many data mining algorithms view datasets as attributed relation graphs (ARGs) inwhich nodes correspond to entities and edges to relationships. However; frequently real-world datasets contain uncertainty and can be represented only as probabilistic ARGs(pARGs); ie as ARGs where each edge has associated with it a non-zero probability of thatedge to exist–probabilistic edge. In this paper we first introduce an interesting novel conceptof probabilistic ARGs and then present an algorithm for efficient computation of the importantconnection strength metric directly on probabilistic ARGs. Such a metric is useful foranalyzing social and collaboration networks; to measure 'impact'; and other purposes.,*,*,*
