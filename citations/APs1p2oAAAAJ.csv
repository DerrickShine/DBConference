Extended update functionality in temporal databases,Opher Etzion; Avigdor Gal; Arie Segev,Abstract This paper presents an extended update functionality in temporal databases. Intemporal databases; the information is associated with several time dimensions thatdesignate the validity of the information in the application domain as well as the databasedomain. The complexity of information; coupled with the fact that historical data is being keptin the database; requires the use of an update model that provides the user with high-levelabstractions. In this paper we provide an enhanced schema language and an enhancedcollection of update operation types that help the system designer and the user to cope withthe added complexities of such a model. One of the major issues dealt with in this paper isthe situation of simultaneous values of a single data item; this situation occurs when multiplevalues; valid at the same time; were assigned to a data item at different times over the …,*,1998,218
A framework for modeling and evaluating automatic semantic reconciliation,Avigdor Gal; Ateret Anaby-Tavor; Alberto Trombetta; Danilo Montesi,Abstract The introduction of the Semantic Web vision and the shift toward machineunderstandable Web resources has unearthed the importance of automatic semanticreconciliation. Consequently; new tools for automating the process were proposed. In thiswork we present a formal model of semantic reconciliation and analyze in a systematicmanner the properties of the process outcome; primarily the inherent uncertainty of thematching process and how it reflects on the resulting mappings. An important feature of thisresearch is the identification and analysis of factors that impact the effectiveness ofalgorithms for automatic semantic reconciliation; leading; it is hoped; to the design of betteralgorithms by reducing the uncertainty of existing algorithms. Against this background weempirically study the aptitude of two algorithms to correctly match concepts. This research …,The VLDB Journal—The International Journal on Very Large Data Bases,2005,138
Managing uncertainty in schema matching with top-k schema mappings,Avigdor Gal,Abstract In this paper; we propose to extend current practice in schema matching with thesimultaneous use of top-K schema mappings rather than a single best mapping. This is anatural extension of existing methods (which can be considered to fall into the top-1category); taking into account the imprecision inherent in the schema matching process. Theessence of this method is the simultaneous generation and examination of K best schemamappings to identify useful mappings. The paper discusses efficient methods for generatingtop-K methods and propose a generic methodology for the simultaneous utilization of top-Kmappings. We also propose a concrete heuristic that aims at improving precision at the costof recall. We have tested the heuristic on real as well as synthetic data and anlyze theemricial results. The novelty of this paper lies in the robust extension of existing methods …,*,2006,120
Automatic ontology matching using application semantics,Avigdor Gal; Giovanni Modica; Hasan Jamil; Ami Eyal,*,AI magazine,2005,105
The use of machine-generated ontologies in dynamic information seeking,Giovanni Modica; Avigdor Gal; Hasan M Jamil,Abstract Information seeking is the process in which human beings recourse to informationresources in order to increase their level of knowledge with respect to their goals. In thispaper we offer a methodology for automating the evolution of ontologies and share theresults of our experiments in supporting a user in seeking information using interactivesystems. The main conclusion of our experiments is that if one narrows down the scope ofthe domain; ontologies can be extracted with a very high level of precision (more than 90%in some cases). The paper is a step in providing theoretical; as well as practical; foundationfor automatic ontology generation. It is our belief that such a process would allow thecreation of flexible tools to manage metadata; either as an aid to a designer or as anindependent system (“smart agent”) for time critical missions.,International Conference on Cooperative Information Systems,2001,96
Complex event processing over uncertain data,Segev Wasserkrug; Avigdor Gal; Opher Etzion; Yulia Turchin,Abstract In recent years; there has been a growing need for active systems that can reactautomatically to events. Some events are generated externally and deliver data acrossdistributed systems; while others are materialized by the active system itself. Eventmaterialization is hampered by uncertainty that may be attributed to unreliable data sourcesand networks; or the inability to determine with certainty whether an event has actuallyoccurred. Two main obstacles exist when designing a solution to the problem of eventmaterialization with uncertainty. First; event materialization should be performed efficiently;at times under a heavy load of incoming events from various sources. The second challengeinvolves the generation of a correct probability space; given uncertain events. We present asolution to both problems by introducing an efficient mechanism for event materialization …,Proceedings of the second international conference on Distributed event-based systems,2008,88
Why is schema matching tough and what can we do about it?,Avigdor Gal,Abstract In this paper we analyze the problem of schema matching; explain why it is such a"tough" problem and suggest directions for handling it effectively. In particular; we present themonotonicity principle and see how it leads to the use of top-K mappings rather than a singlemapping.,ACM Sigmod Record,2006,79
Uncertain schema matching,Avigdor Gal,Abstract Schema matching is the task of providing correspondences between conceptsdescribing the meaning of data in various heterogeneous; distributed data sources. Schemamatching is one of the basic operations required by the process of data and schemaintegration; and thus has a great effect on its outcomes; whether these involve targetedcontent delivery; view integration; database integration; query rewriting over heterogeneoussources; duplicate data elimination; or automatic streamlining of workflow activities thatinvolve heterogeneous data sources. Although schema matching research has beenongoing for over 25 years; more recently a realization has emerged that schema matchersare inherently uncertain. Since 2003; work on the uncertainty in schema matching haspicked up; along with research on uncertainty in other areas of data management. This …,Synthesis Lectures on Data Management,2011,76
Heterogeneous Stream Processing and Crowdsourcing for Urban Traffic Management.,Alexander Artikis; Matthias Weidlich; Francois Schnitzler; Ioannis Boutsis; Thomas Liebig; Nico Piatkowski; Christian Bockermann; Katharina Morik; Vana Kalogeraki; Jakub Marecek; Avigdor Gal; Shie Mannor; Dimitrios Gunopulos; Dermot Kinane,ABSTRACT Urban traffic gathers increasing interest as cities become bigger; crowded and“smart”. We present a system for heterogeneous stream processing and crowdsourcingsupporting intelligent urban traffic management. Complex events related to traffic congestion(trends) are detected from heterogeneous sources involving fixed sensors mounted onintersections and mobile sensors mounted on public transport vehicles. To deal with dataveracity; a crowdsourcing component handles and resolves sensor disagreement.Furthermore; to deal with data sparsity; a traffic modelling component offers information inareas with low sensor coverage. We demonstrate the system with a real-world use-casefrom Dublin city; Ireland.,EDBT,2014,71
An authorization model for temporal and derived data: securing information portals,Vijayalakshmi Atluri; Avigdor Gal,Abstract The term information portals refers to Web sites that serve as main providers offocused information; gathered from distributed data sources. Gathering and disseminatinginformation through information portals introduce new security challenges. In particular; theauthorization specifications; as well as the granting process; are temporal by nature. Also;more often than not; the information provided by the portal is in fact derived from more thanone backend data source. Therefore; any authorization model for information portals shouldsupport access control based on temporal characteristics of the data; and also shouldprovide tools to prevent indirect unauthorized access through the use of derived data. In thisarticle we focus our attention on devising such an authorization model. The distinguishingfeatures of this model include:(1) the specification of authorizations based on temporal …,ACM Transactions on Information and System Security (TISSEC),2002,71
A semantic approach to approximate service retrieval,Eran Toch; Avigdor Gal; Iris Reinhartz-Berger; Dov Dori,Abstract Web service discovery is one of the main applications of semantic Web services;which extend standard Web services with semantic annotations. Current discovery solutionswere developed in the context of automatic service composition. Thus; the “client” of thediscovery procedure is an automated computer program rather than a human; with little; ifany; tolerance to inexact results. However; in the real world; services which might besemantically distanced from each other are glued together using manual coding. In thisarticle; we propose a new retrieval model for semantic Web services; with the objective ofsimplifying service discovery for human users. The model relies on simple and extensiblekeyword-based query language and enables efficient retrieval of approximate results;including approximate service compositions. Since representing all possible …,ACM Transactions on Internet Technology (TOIT),2007,63
Ontobuilder: Fully automatic extraction and consolidation of ontologies from web sources,Avigdor Gal; Giovanni Modica; Hasan Jamil,Ontologies; formal specifications of domains; have evolved in recent years as a leading toolin representing and interpreting Web data. The OntoBuilder project supports the extraction ofontologies from Web search interfaces; ranging from simple search engine forms to multiple-pages; complex reservation systems. OntoBuilder enables fully-automatic ontologymatching. The use of ontologies; as opposed to relational schema or XML; as an underlyingdata model allows a flexible representation of metadata; that can be tailored to manydifferent types of applications. OntoBuilder was developed using Java; which makes itportable to various platforms and operating system environments. We demonstrateOntoBuilder using an easy-to-follow example of matching car rental ontologies. The systemcreates ontologies of car rental Web sites on-the-fly; and combine them into a global …,Data Engineering; 2004. Proceedings. 20th International Conference on,2004,60
Managing periodically updated data in relational databases: A stochastic modeling approach,Avigdor Gal; Jonathan Eckstein,Abstract Recent trends in information management involve the periodic transcription of dataonto secondary devices in a networked environment; and the proper scheduling of thesetranscriptions is critical for efficient data management. To assist in the scheduling process;we are interested in modeling data obsolescence; that is; the reduction of consistency overtime between a relation and its replica. The modeling is based on techniques from the fieldof stochastic processes; and provides several stochastic models for content evolution in thebase relations of a database; taking referential integrity constraints into account. Thesemodels are general enough to accommodate most of the common scenarios in databases;including batch insertions and lifespans both with and without memory. As an initial" proof ofconcept" of the applicability of our approach; we validate the insertion portion of our …,Journal of the ACM (JACM),2001,59
Efficient processing of uncertain events in rule-based systems,Segev Wasserkrug; Avigdor Gal; Opher Etzion; Yulia Turchin,There is a growing need for systems that react automatically to events. While some eventsare generated externally and deliver data across distributed systems; others need to bederived by the system itself based on available information. Event derivation is hampered byuncertainty attributed to causes such as unreliable data sources or the inability to determinewith certainty whether an event has actually occurred; given available information. Two mainchallenges exist when designing a solution for event derivation under uncertainty. First;event derivation should scale under heavy loads of incoming events. Second; theassociated probabilities must be correctly captured and represented. We present a solutionto both problems by introducing a novel generic and formal mechanism and framework formanaging event derivation under uncertainty. We also provide empirical evidence …,IEEE Transactions on Knowledge and Data Engineering,2012,58
Rank aggregation for automatic schema matching,Carmel Domshlak; Avigdor Gal; Haggai Roitman,Schema matching is a basic operation of data integration; and several tools for automating ithave been proposed and evaluated in the database community. Research in this areareveals that there is no single schema matcher that is guaranteed to succeed in finding agood mapping for all possible domains and; thus; an ensemble of schema matchers shouldbe considered. In this paper; we introduce schema metamatching; a general framework forcomposing an arbitrary ensemble of schema matchers and generating a list of best rankedschema mappings. Informally; schema metamatching stands for computing a" consensus"ranking of alternative mappings between two schemata; given the" individual" gradedrankings provided by several schema matchers. We introduce several algorithms for thisproblem; varying from adaptations of some standard techniques for general quantitative …,IEEE Transactions on Knowledge and Data Engineering,2007,55
Advances in ontology matching,Avigdor Gal; Pavel Shvaiko,Abstract Matching of concepts describing the meaning of data in heterogeneous distributedinformation sources; such as database schemas and other metadata models; grouped hereunder the heading of an ontology; is one of the basic operations of semantic heterogeneityreconciliation. The aim of this chapter is to motivate the need for ontology matching;introduce the basics of ontology matching; and then discuss several promising themes in thearea as reflected in recent research works. In particular; we focus on such themes asuncertainty in ontology matching; matching ensembles; and matcher self-tuning. Finally; weoutline some important directions for future research.,*,2008,54
An authorization model for temporal data,Avigdor Gal; Vijayalakshmi Atluri,ABSTRACT A i ti Lu| i4TLh@* _@|@@ t MiUL4i _i tThi@ _? hiUi?|) i@ htc|?@ TT* U@| L? ttU@ t _@|@@ hi L tit@? _ tT@| L| i4TLh@* _@|@ M@ tit W?| t T@ Tihc ii| i? _| i M@ t U@|Lh 3@| L? 4L_i* M) u@ U*|@|?}||| i U@ T@ M*|)| L i Thitt@| Lh 3@| L? t M@ ti_ L?| i|i4TLh@*@|| h M| it@ t tLU@| i_| _@|@ ct U@ t| h@? t@ U| L?| 4i@? _@* _| 4i W? T@ h|U*@ hc@ t M iU| U@? tTiU u)@| Lh 3@| L? t M@ ti_ L? _@|@@* _|) Lh _@|@ T_@| i| 4ict?} i| ih@ MtL*| i Lh hi*@| i| 4i hiuihi? Uit 5 U@ tTiU U@| L? t itti?|@*? ThL _?}@ UUitt UL?|hL* uLh Thi_ U| i _@|@ c Lh? UL? t| h@??}@ UUitt| L _@|@ M@ ti_ L? U hhi? U) UL? t_ih@| L? ti ThL _i@? i Thitt i*@?}@} i uLh tTiU u)?} t U@ UUitt UL?| hL*| L| i4TLh@* _@|@ct?}@@ h@| L? Lu| i4TLh@** L} U uLh tTiU u)?} UL4T* i| i4TLh@* UL? t| h@?| ti@* tL?| hL_Ui@? i@ t)| L ti@ UUitt UL?| hL* 4iU@? t4 uLh t| hi@ 4 _@|@,Proceedings of the 7th ACM Conference on Computer and Communications Security,2000,54
A model for reasoning with uncertain rules in event composition systems,Segev Wasserkrug; Avigdor Gal; Opher Etzion,Abstract: In recent years; there has been an increased need for the use of active systems-systems required to act automatically based on events; or changes in the environment. Suchsystems span many areas; from active databases to applications that drive the core businessprocesses of today's enterprises. However; in many cases; the events to which the systemmust respond are not generated by monitoring tools; but must be inferred from other eventsbased on complex temporal predicates. In addition; in many applications; such inference isinherently uncertain. In this paper; we introduce a formal framework for knowledgerepresentation and reasoning enabling such event inference. Based on probability theory;we define the representation of the associated uncertainty. In addition; we formally definethe probability space; and show how the relevant probabilities can be calculated by …,arXiv preprint arXiv:1207.1427,2012,52
A generic integration architecture for cooperative information systems,John Mylopoulos; Avigdor Gal; Kostas Kontogiannis; Martin Stanley,Cooperative information systems consist of existing legacy systems integrated in terms of ageneric architecture which supports data integration and coordination among the integratedcomponents. The paper presents a proposal for a generic integration architecture namedCoopWARE. The architecture is presented in terms of the mechanisms it provides for dataintegration; and coordination. Data integration is supported by an information repository withan extensible schema; while coordination is facilitated by a rule set and an event-driven ruleexecution mechanism. In addition; the paper describes implementation and applicationexperiences for the architecture in the context of a three year software engineering project.,Cooperative Information Systems; 1996. Proceedings.; First IFCIS International Conference on,1996,51
Boosting schema matchers,Anan Marie; Avigdor Gal,Abstract Schema matching is recognized to be one of the basic operations required by theprocess of data and schema integration; and thus has a great impact on its outcome. Wepropose a new approach to combining matchers into ensembles; called Schema MatcherBoosting (SMB). This approach is based on a well-known machine learning technique;called boosting. We present a boosting algorithm for schema matching with a uniqueensembler feature; namely the ability to choose the matchers that participate in anensemble. SMB introduces a new promise for schema matcher designers. Instead of tryingto design a perfect schema matcher that is accurate for all schema pairs; a designer canfocus on finding better than random schema matchers. We provide a thorough comparativeempirical results where we show that SMB outperforms; on average; any individual …,OTM Confederated International Conferences" On the Move to Meaningful Internet Systems",2008,50
Tuning the ensemble selection process of schema matchers,Avigdor Gal; Tomer Sagi,Abstract Schema matching is the task of providing correspondences between conceptsdescribing the meaning of data in various heterogeneous; distributed data sources. It isrecognized to be one of the basic operations required by the process of data and schemaintegration and its outcome serves in many tasks such as targeted content delivery and viewintegration. Schema matching research has been going on for more than 25 years now. Aninteresting research topic; that was largely left untouched involves the automatic selection ofschema matchers to an ensemble; a set of schema matchers. To the best of our knowledge;none of the existing algorithmic solutions offer such a selection feature. In this paper weprovide a thorough investigation of this research topic. We introduce a new heuristic;Schema Matcher Boosting (S MB). We show that S MB has the ability to choose among …,Information Systems,2010,49
Queue mining–predicting delays in service processes,Arik Senderovich; Matthias Weidlich; Avigdor Gal; Avishai Mandelbaum,Abstract Information systems have been widely adopted to support service processes invarious domains; eg; in the telecommunication; finance; and health sectors. Recently; workon process mining showed how management of these processes; and engineering ofsupporting systems; can be guided by models extracted from the event logs that arerecorded during process operation. In this work; we establish a queueing perspective inoperational process mining. We propose to consider queues as first-class citizens and usequeueing theory as a basis for queue mining techniques. To demonstrate the value of queuemining; we revisit the specific operational problem of online delay prediction: using eventdata; we show that queue mining yields accurate online predictions of case delay.,International Conference on Advanced Information Systems Engineering,2014,48
Ontobuilder: Fully automatic extraction and consolidation of ontologies from web sources using sequence semantics,Haggai Roitman; Avigdor Gal,Abstract Ontologies; formal specifications of domains; have evolved in recent years as aleading tool in representing and interpreting Web data. The inherent heterogeneity of Webresources; the vast amount of information on the Web; and its non-specific nature requires asemantically rich tool for extracting the essence of Web source content. The OntoBuilderproject [5] supports the extraction of ontologies from Web interfaces; ranging from simpleSearch Engine forms to multiple-pages; complex reservation systems. Ontologies fromsimilar domains are then matched to identify ontology mappings.,International Conference on Extending Database Technology,2006,44
Adaptive pull-based policies for wide area data delivery,Laura Bright; Avigdor Gal; Louiqa Raschid,Abstract Wide area data delivery requires timely propagation of up-to-date information tothousands of clients over a wide area network. Applications include web caching; RSSsource monitoring; and email access via a mobile network. Data sources vary widely in theirupdate patterns and may experience different update rates at different times or unexpectedchanges to update patterns. Traditional data delivery solutions are either push-based; whichrequires servers to push updates to clients; or pull-based; which require clients to check forupdates at servers. While push-based solutions ensure timely data delivery; they are notalways feasible to implement and may not scale to a large number of clients. In this article;we present adaptive pull-based policies that explicitly aim to reduce the overhead ofcontacting remote servers; compared to existing pull-based policies; while meeting …,ACM Transactions on Database Systems (TODS),2006,40
Tuning complex event processing rules using the prediction-correction paradigm,Yulia Turchin; Avigdor Gal; Segev Wasserkrug,Abstract There is a growing need for the use of active systems; systems that actautomatically based on events. In many cases; providing such active functionality requiresmaterializing (inferring) the occurrence of relevant events. A widespread paradigm forenabling such materialization is Complex Event Processing (CEP); a rule based paradigm;which currently relies on domain experts to fully define the relevant rules. These expertsneed to provide the set of basic events which serves as input to the rule; their inter-relationships; and the parameters of the events for determining a new event materialization.While it is reasonable to expect that domain experts will be able to provide a partial rulesspecification; providing all the required details is a hard task; even for domain experts.Moreover; in many active systems; rules may change over time; due to the dynamic …,Proceedings of the Third ACM International Conference on Distributed Event-Based Systems,2009,35
Aggregate query answering under uncertain schema mappings,Avigdor Gal; Maria Vanina Martinez; Gerardo I Simari; VS Subrahmanian,Recent interest in managing uncertainty in data integration has led to the introduction ofprobabilistic schema mappings and the use of probabilistic methods to answer queriesacross multiple databases using two semantics: by-table and by-tuple. In this paper; wedevelop three possible semantics for aggregate queries: the range; distribution; andexpected value semantics; and show that these three semantics combine with the by-tableand by-tuple semantics in six ways. We present algorithms to process COUNT; AVG; SUM;MIN; and MAX queries under all six semantics and develop results on the complexity ofprocessing such queries under all six semantics. We show that computing COUNT is inPTIME for all six semantics and computing SUM is in PTIME for all but the by-tuple/distribution semantics. Finally; we show that AVG; MIN; and MAX are PTIME …,Data Engineering; 2009. ICDE'09. IEEE 25th International Conference on,2009,35
Enhancing portability with multilingual ontology-based knowledge management,Aviv Segev; Avigdor Gal,Abstract Information systems in multilingual environments; such as the EU; suffer from lowportability and high deployment costs. In this paper we propose an ontology-based modelfor multilingual knowledge management in information systems. Our unique feature is alightweight mechanism; dubbed context; that is associated with ontological concepts andspecified in multiple languages. We use contexts to assist in resolving cross-language andlocal variation ambiguities. Equipped with such a model; we next provide a four-stepprocedure for overcoming the language barrier in deploying a new information system. Wealso show that our proposed solution can overcome differences that stem from localvariations that may accompany multilingual information systems deployment. The proposedmechanism was tested in an actual multilingual eGovernment environment and by using …,Decision Support Systems,2008,35
Queue mining for delay prediction in multi-class service processes,Arik Senderovich; Matthias Weidlich; Avigdor Gal; Avishai Mandelbaum,Abstract Information systems have been widely adopted to support service processes invarious domains; eg; in the telecommunication; finance; and health sectors. Informationrecorded by systems during the operation of these processes provides an angle foroperational process analysis; commonly referred to as process mining. In this work; weestablish a queueing perspective in process mining to address the online delay predictionproblem; which refers to the time that the execution of an activity for a running instance of aservice process is delayed due to queueing effects. We present predictors that treat queuesas first-class citizens and either enhance existing regression-based techniques for processmining or are directly grounded in queueing theory. In particular; our predictors target multi-class service processes; in which requests are classified by a type that influences their …,Information Systems,2015,33
Goal Recognition Design for Non-Optimal Agents.,Sarah Keren; Avigdor Gal; Erez Karpas,Abstract Goal recognition design involves the offline analysis of goal recognition models byformulating measures that assess the ability to perform goal recognition within a model andfinding efficient ways to compute and optimize them. In this work we present goal recognitiondesign for non-optimal agents; which extends previous work by accounting for agents thatbehave non-optimally either intentionally or naıvely. The analysis we present includes a newgeneralized model for goal recognition design and the worst case distinctiveness (wcd)measure. For two special cases of sub-optimal agents we present methods for calculatingthe wcd; part of which are based on novel compilations to classical planning problems. Ourempirical evaluation shows the proposed solutions to be effective in computing andoptimizing the wcd.,AAAI,2015,33
Pay-as-you-go reconciliation in schema matching networks,Quoc Viet Hung Nguyen; Thanh Tam Nguyen; Zoltan Miklos; Karl Aberer; Avigdor Gal; Matthias Weidlich,Schema matching is the process of establishing correspondences between the attributes ofdatabase schemas for data integration purposes. Although several automatic schemamatching tools have been developed; their results are often incomplete or erroneous. Toobtain a correct set of correspondences; a human expert is usually required to validate thegenerated correspondences. We analyze this reconciliation process in a setting where anumber of schemas needs to be matched; in the presence of consistency expectations aboutthe network of attribute correspondences. We develop a probabilistic model that helps toidentify the most uncertain correspondences; thus allowing us to guide the expert's work andcollect his input about the most problematic cases. As the availability of such experts is oftenlimited; we develop techniques that can construct a set of good quality correspondences …,Data Engineering (ICDE); 2014 IEEE 30th International Conference on,2014,31
Putting things in context: A topological approach to mapping contexts to ontologies,Aviv Segev; Avigdor Gal,Abstract Ontologies and contexts are complementary disciplines for modeling views. In thearea of information integration; ontologies may be viewed as the outcome of a manual effortto model a domain; while contexts are system generated models. In this work; we provide aformal mathematical framework that delineates the relationship between contexts andontologies. We then use the model to handle the uncertainty associated with automaticcontext extraction from existing documents by providing a ranking method; which ranksontology concepts according to their suitability to a given context. Throughout this work wemotivate our research using QUALEG; a European IST project that aims providing localgovernments with an effective tool for bi-directional communication with citizens. Weempirically evaluate our model using two real-world data sets; coming from Reuters and …,*,2007,31
The process model matching contest 2015,Goncalo Antunes; Marzieh Bakhshandeh; Jose Borbinha; Joao Cardoso; Sharam Dadashnia; Chiara Di Francescomarino; Mauro Dragoni; Peter Fettke; Avigdor Gal; Chiara Ghidini; Philip Hake; Abderrahmane Khiat; Christopher Klinkmüller; Elena Kuss; Henrik Leopold; Peter Loos; Christian Meilicke; Tim Niesen; Catia Pesquita; Timo Péus; Andreas Schoknecht; Eitam Sheetrit; Andreas Sonntag; Heiner Stuckenschmidt; Tom Thaler; Ingo Weber; Matthias Weidlich,Process model matching refers to the automatic identification of correspondences betweenthe activities of process models. Application scenarios of process model matching reachfrom model validation over harmonization of process variants to effective management ofprocess model collections. Recognizing this; several process model matching techniqueshave been developed in recent years. However; to learn about specific strengths andweaknesses of these techniques; a common evaluation basis is indispensable. The secondedition of the Process Model Matching Contest in 2015 hence addresses the need foreffective evaluation by defining process model matching problems over published data sets.This paper summarizes the setup and the results of the contest. Next to a description of thecontest matching problems; the paper provides short descriptions of all matching …,Enterprise modelling and information systems architectures,2015,28
Goal Recognition Design.,Sarah Keren; Avigdor Gal; Erez Karpas,Abstract We propose a new problem we refer to as goal recognition design (grd); in whichwe take a domain theory and a set of goals and ask the following questions: to what extentdo the actions performed by an agent within the model reveal its objective; and what is thebest way to modify a model so that any agent acting in the model reveals its objective asearly as possible. Our contribution is the introduction of a new measure we call worst casedistinctiveness (wcd) with which we assess a grd model. The wcd represents the maximallength of a prefix of an optimal path an agent may take within a system before it becomesclear at which goal it is aiming. To model and solve the grd problem we choose to use themodels and tools from the closely related field of automated planning. We present twomethods for calculating the wcd of a grd model; one of which is based on a novel …,ICAPS,2014,28
Predicting the quality of process model matching,Matthias Weidlich; Tomer Sagi; Henrik Leopold; Avigdor Gal; Jan Mendling,Abstract Process model matching refers to the task of creating correspondences amongactivities of different process models. This task is crucial whenever comparison andalignment of process models are called for. In recent years; there have been a few attemptsto tackle process model matching. Yet; evaluating the obtained sets of correspondencesreveals high variability in the results. Addressing this issue; we propose a method forpredicting the quality of results derived by process model matchers. As such; predictionserves as a case-by-case decision making tool in estimating the amount of trust one shouldput into automatic matching. This paper proposes a model of prediction for process matchingbased on both process properties and preliminary match results.,*,2013,27
Machine-assisted design of business process models using descriptor space analysis,Maya Lincoln; Mati Golani; Avigdor Gal,Abstract In recent years; researchers have become increasingly interested in developingmethods and tools for automating the design of business process models. This worksuggests a method for machine-assisted design of new process models; based on businesslogic that is extracted from real-life process repositories using a linguistic analysis of therelationships between constructs of process descriptors. The analysis enables theconstruction of a descriptor space in which it is possible to define new process sequences.The suggested method can assist process analysts in designing new business processeswhile making use of knowledge that is encoded in the design of existing processrepositories. To demonstrate the method we developed a software tool (“New ProcessDesign Assistant”-NPDA) that automates the suggested design method. We tested our …,International Conference on Business Process Management,2010,27
Managing uncertainty in schema matcher ensembles,Anan Marie; Avigdor Gal,Abstract Schema matching is the task of matching between concepts describing themeaning of data in various heterogeneous; distributed data sources. With many heuristics tochoose from; several tools have enabled the use of schema matcher ensembles; combiningprinciples by which different schema matchers judge the similarity between concepts. In thiswork; we investigate means of estimating the uncertainty involved in schema matching andharnessing it to improve an ensemble outcome. We propose a model for schema matching;based on simple probabilistic principles. We then propose the use of machine learning indetermining the best mapping and discuss its pros and cons. Finally; we provide a thoroughempirical analysis; using both real-world and synthetic data; to test the proposed technique.We conclude that the proposed heuristic performs well; given an accurate modeling of …,International Conference on Scalable Uncertainty Management,2007,27
System and Method for Performing Complex Event Processing,*,A method for performing complex event processing includes receiving events from at leastone entity at a grid of complex event processing (CEP) units; each of the CEP unitscomprising a modular architecture for receiving events from event suppliers; recursivelyprocessing events; and transmitting events to event consumers. The method further includesgenerating event inferences based on the plurality of events by one or more CEP units of thegrid of CEP units.,*,2010,26
On the stable marriage of maximum weight royal couples,Anan Marie; Avigdor Gal,*,Proceedings of AAAI Workshop on Information Integration on the Web,2007,26
Flexible business process management using forward stepping and alternative paths,Mati Golani; Avigdor Gal,Abstract The abilty to continuously revise business practices is essential to organizationsaiming at reducing their costs and increasing their revenues. Rapid and continuous changesto business processes result in less control over the executed activities. As a result; theability of process designers to produce solid; well-validated workflow models is limited.Workflow management systems (WfMSs); serving as the main vehicle of business processexecution; should recognize these risks and become more dynamic to allow the requiredbusiness flexibility. In this paper; we propose a dynamic mechanism that allows backtrackingand forward stepping at an instance level. This mechanism analyzes the feasibility ofapplying certain modifications to running instances and provides an efficient algorithm thatavoids redundant operation activation. We believe that this mechanism can bolster the …,International Conference on Business Process Management,2005,26
Semantic interoperability in information services: experiencing with CoopWARE,Avigdor Gal,Obtaining high quality information has become in recent years a challenging task as datashould be gathered and filtered from a large; open and frequently changing network ofdistributed data sources; with blurred semantics; and no central control over the datasources' structure and availability. This technical challenge is highlighted by the advent ofthe World Wide Web; its current status and its evolving nature. This state of affair creates aneed for technologies for building information services; capable of providing high qualityinformation obtained from distributed; heterogeneous; and autonomous data sources on anas-needed basis. While the use of information brokers exist for some time now (eg ORB inthe CORBA model [13]; HTTP-Hypertext Transfer Protocol-requests; Java virtual machinesembedded in Web browsers to run applets; or remote procedure call protocols) …,ACM Sigmod record,1999,26
MFIBlocks: An effective blocking algorithm for entity resolution,Batya Kenig; Avigdor Gal,Abstract Entity resolution is the process of discovering groups of tuples that correspond tothe same real-world entity. Blocking algorithms separate tuples into blocks that are likely tocontain matching pairs. Tuning is a major challenge in the blocking process and inparticular; high expertise is needed in contemporary blocking algorithms to construct ablocking key; based on which tuples are assigned to blocks. In this work; we introduce ablocking approach that avoids selecting a blocking key altogether; relieving the user fromthis difficult task. The approach is based on maximal frequent itemsets selection; allowingearly evaluation of block quality based on the overall commonality of its members. A uniquefeature of the proposed algorithm is the use of prior knowledge of the estimated size ofduplicate sets in enhancing the blocking accuracy. We report on a thorough empirical …,Information Systems,2013,25
Supporting distributed autonomous information services using coordination,Avigdor Gal; John Mylopoulos,The large quantity and often questionable quality of available information in the informationage provides a shaky foundation for decision making by individuals and organizations alike.This has created a tremendous demand for information services which can access; filter;process and present information on an as-needed basis. However; two factors complicatethe design of such information services; namely the distributed and the autonomous natureof data sources. This paper reports on the design and implementation of a genericarchitecture for supporting information services; which meets the above challenge. Thearchitecture adopts concepts from conceptual modeling to offer a transparent description ofthe information sources' setting and uses active databases techniques to offer a declarative;event-based language for defining coordination rules for integrating distributed …,International Journal of Cooperative Information Systems,2000,25
Representation of highly-complex knowledge in a database,Avigdor Gal; Opher Etzion; Arie Segev,Abstract This paper presents a unified framework for representing highly-complexknowledge in a database as a new paradigm for handling large and complex information inan easy and efficient manner. The framework provides a database with the capabilities tosupport next generation databases for decision support systems through the use ofderivation rules; temporal information; knowledge from multiple sources with differentmeasures of quality and epistemic knowledge. The model integrates concepts from both thedatabase and the artificial intelligence disciplines.,Journal of Intelligent Information Systems,1994,24
A multiagent update process in a database with temporal data dependencies and schema versioning,Avigdor Gal; Opher Etzion,Temporal data dependencies are high-level linguistic constructs that define relationshipsamong values of data-elements in temporal databases. These constructs enable the supportof schema versioning as well as the definition of consistency requirements for a single time-point and among values in different time-points. In this paper; we present a multiagentupdate process in a database with temporal data dependencies and schema versioning.The update process supports the evolution of dependencies over time and the use oftemporal operators within temporal data dependencies. The temporal dependencylanguage is presented; along with the temporal dependency graph-which serves as theexecutable data structure. A thorough discussion of the feasibility; performance; andconsistency of the presented model is provided.,IEEE Transactions on Knowledge and Data Engineering,1998,23
TALE—A temporal active language and execution model,Avigdor Gal; Opher Etzion; Arie Segev,Abstract Complex applications in domains such as decision support systems and real timesystems require a functionality that is achieved by combining the active and temporaldatabase technologies. In this paper we present TALE; a Temporal Active Language andExecution model. TALE is a temporal active database programming language; combinedwith an execution model that enables a correct and efficient processing of operations. Assuch; TALE is a step in accommodating software engineering challenges in moderninformation systems. TALE primitives are presented using examples and an EBNF. The run-time control mechanism of the model is introduced and TALE properties; namely active andtemporal capabilities; and reflective programming capabilities are discussed.,International Conference on Advanced Information Systems Engineering,1996,22
Traveling time prediction in scheduled transportation with journey segments,Avigdor Gal; Avishai Mandelbaum; François Schnitzler; Arik Senderovich; Matthias Weidlich,Abstract Urban mobility impacts urban life to a great extent. To enhance urban mobility;much research was invested in traveling time prediction: given an origin and destination;provide a passenger with an accurate estimation of how long a journey lasts. In this work; weinvestigate a novel combination of methods from Queueing Theory and Machine Learning inthe prediction process. We propose a prediction engine that; given a scheduled bus journey(route) and a 'source/destination'pair; provides an estimate for the traveling time; whileconsidering both historical data and real-time streams of information that are transmitted bybuses. We propose a model that uses natural segmentation of the data according to busstops and a set of predictors; some use learning while others are learning-free; to computetraveling time. Our empirical evaluation; using bus data that comes from the bus network …,Information Systems,2017,21
Matching business process models using positional passage-based language models,Matthias Weidlich; Eitam Sheetrit; Moisés C Branco; Avigdor Gal,Abstract Business operations are often documented by business process models. Use casessuch as system validation and process harmonization require the identification ofcorrespondences between activities; which is supported by matching techniques that copewith textual heterogeneity and differences in model granularity. In this paper; we present amatching technique that is tailored towards models featuring textual descriptions of activities.We exploit these descriptions using ideas from language modelling. Experiments with real-world process models reveal that our technique increases recall by up to factor five; largelywithout compromising precision; compared to existing approaches.,International Conference on Conceptual Modeling,2013,21
Self-adaptive event recognition for intelligent transport management,Alexander Artikis; Matthias Weidlich; Avigdor Gal; Vana Kalogeraki; Dimitrios Gunopulos,Intelligent transport management involves the use of voluminous amounts of uncertainsensor data to identify and effectively manage issues of congestion and quality of service. Inparticular; urban traffic has been in the eye of the storm for many years now and gathersincreasing interest as cities become bigger; crowded; and “smart”. In this work we tackle theissue of uncertainty in transportation systems stream reporting. The variety of existing datasources opens new opportunities for testing the validity of sensor reports and self-adaptingthe recognition of complex events as a result. We report on the use of a logic-based eventreasoning tool to identify regions of uncertainty within a stream and demonstrate our methodwith a real-world use-case from the city of Dublin. Our empirical analysis shows thefeasibility of the approach when dealing with voluminous and highly uncertain streams.,Big Data; 2013 IEEE International Conference on,2013,21
Maintaining data-driven rules in databases,Avigdor Gal; Opher Etzion,A new model with invariant-based language effectively handles data-driven rules indatabases and uses the rules' inherent semantic properties and supporting mechanisms tomeet high-level language requirements. It is an extension of the basic PARDES modeldeveloped by Opher Etzion in 1990 to support derivations and integrity constraints indatabases. The model's invariant-based language; unlike other programming languages;can follow data-driven rules' semantic properties. Such rules are activated by modificationsof data items in a database; and they play an important role in many applications thatmaintain complex relationships between data items or interdependencies between parts ofthe database. Applications include expert systems; real-time databases; simulations; anddecision-support systems. The authors present requirements for choosing an adequate …,Computer,1995,21
Minimizing human effort in reconciling match networks,Hung Quoc Viet Nguyen; Tri Kurniawan Wijaya; Zoltán Miklós; Karl Aberer; Eliezer Levy; Victor Shafran; Avigdor Gal; Matthias Weidlich,Abstract Schema and ontology matching is a process of establishing correspondencesbetween schema attributes and ontology concepts; for the purpose of data integration.Various commercial and academic tools have been developed to support this task. Thesetools provide impressive results on some datasets. However; as the matching is inherentlyuncertain; the developed heuristic techniques give rise to results that are not completelycorrect. In practice; post-matching human expert effort is needed to obtain a correct set ofcorrespondences. We study this post-matching phase with the goal of reducing the costlyhuman effort. We formally model this human-assisted phase and introduce a process ofmatching reconciliation that incrementally leads to identifying the correct correspondences.We achieve the goal of reducing the involved human effort by exploiting a network of …,International Conference on Conceptual Modeling,2013,20
Automatically grounding semantically-enriched conceptual models to concrete web services,Eran Toch; Avigdor Gal; Dov Dori,Abstract The paper provides a conceptual framework for designing and executing businessprocesses using semantic Web services. We envision a world in which a designer defines a“virtual “Web service as part of a business process; while requiring the system to seek actualWeb services that match the specifications of the designer and can be invoked whenever thevirtual Web service is activated. Taking a conceptual modeling approach; the relationshipsbetween ontology concepts and syntactic Web services are identified. We then propose ageneric algorithm for ranking top-K Web services in a decreasing order of their benefit vis-á-vis the semantic Web service. We conclude with an extention of the framework to handleuncertainty as a result of concept mismatch and the desired properties of a schemamatching algorithm to support Web service identification.,International Conference on Conceptual Modeling,2005,20
Retroactive and proactive database processing,Opher Etzion; Avigdor Gal; Arie Segev,The authors discuss issues and problems related to processing rules in temporal activedatabases. They assume an append-only database where changes can occur to data; meta-data; rules; and constraints. They focus on the effect of retroactive and proactive updates insuch an environment.,Research Issues in Data Engineering; 1994. Active Database Systems. Proceedings Fourth International Workshop on,1994,20
Comparative analysis of approximate blocking techniques for entity resolution,George Papadakis; Jonathan Svirsky; Avigdor Gal; Themis Palpanas,Abstract Entity Resolution is a core task for merging data collections. Due to its quadraticcomplexity; it typically scales to large volumes of data through blocking: similar entities areclustered into blocks and pair-wise comparisons are executed only between co-occurringentities; at the cost of some missed matches. There are numerous blocking methods; and theaim of this work is to offer a comprehensive empirical survey; extending the dimensions ofcomparison beyond what is commonly available in the literature. We consider 17 state-of-the-art blocking methods and use 6 popular real datasets to examine the robustness of theirinternal configurations and their relative balance between effectiveness and time efficiency.We also investigate their scalability over a corpus of 7 established synthetic datasets thatrange from 10;000 to 2 million entities.,Proceedings of the VLDB Endowment,2016,19
Grand challenge: The techniball system,Avigdor Gal; Sarah Keren; Mor Sondak; Matthias Weidlich; Hendrik Blom; Christian Bockermann,Abstract In this work we present the solution to the DEBS'2013 Grand Challenge; as craftedby the joint effort of teams from the Technion and TU Dortmund. The paper describes thearchitecture; details the queries; shows throughput and latency evaluation; and offers ourobservations regarding the appropriate way to trade-off high-level processing with timeconstraints.,Proceedings of the 7th ACM international conference on Distributed event-based systems,2013,19
Pattern rewriting framework for event processing optimization,Ella Rabinovich; Opher Etzion; Avigdor Gal,Abstract A growing segment of event-based applications require both strict performancegoals and support in the processing of complex event patterns. Event processing patternshave multiple complexity dimensions: the semantics of the language constructs (eg;sequence) and the variety of semantic interpretations for each pattern (controlled bypolicies). We introduce in this paper a novel approach for pattern rewriting that aims atefficiently processing patterns which comprise all levels of complexity. We present a formalmodel for pattern rewriting and demonstrate its usage in a comprehensive set of rewritingtechniques for comple pattern types; taking various semantic interpretations into account. Acost model is presented; balancing processing latency and event throughput according touser's preference. Pattern cost is then estimated using simulation-based techniques. This …,Proceedings of the 5th ACM international conference on Distributed event-based system,2011,19
Toward Web-based application management systems,Avigdor Gal; John Mylopoulos,As Web technology spreads; the number; variety; and sophistication of Web basedinformation services is literally exploding. While some effort has been put into managing asingle; centrally controlled Web site; current Web technologies offer little help for managingWeb based applications in-the-large. This is partly due to the distributed; heterogeneous;and open nature of such applications. The paper proposes a generic framework formanaging Web based applications which addresses both semantic and managerial issues.Semantic issues are addressed through the inclusion of a domain model component in theframework which describes the kinds of information that are available. Management issuesare treated through a framework which includes formally defined notions for an informationmodel; information base consistency; transactions; and concurrency control. Thus; the …,IEEE Transactions on Knowledge and Data Engineering,2001,19
Obsolescent materialized views in query processing of enterprise information systems,Avigdor Gal,Abstract In recent years; query processing has become more complex as data sources arefrequently replicated and data are periodically processed and embedded within several datasources simultaneously. These trends have necessitated the optimization of techniques forquery processing in order to exploit these new alternatives. Accordingly; this paperintroduces an improved query optimization technique; which is capable of assessing queryplans that use both current and obsolescent data. In particular; we provide a cost model bywhich the trade-offs of using obsolescent materialized views can be evaluated and we alsodiscuss the method's applicability to contemporary query optimization techniques.,Proceedings of the eighth international conference on Information and knowledge management,1999,19
Inter-enterprise workflow management systems,Avigdor Gal; Danilo Montesi,Electronic commerce is conceived as one of the major channels for performing commerceon a global scale; and the area is rapidly evolving. Currently; transferring and processingelectronic data is handled separately from the enterprise support system; eg; workflows; thusblurring the actual functionality of the supply chain. We propose an extension of a standardworkflow model to enable the description and control of the full life cycle of a supply chain.,Database and Expert Systems Applications; 1999. Proceedings. Tenth International Workshop on,1999,18
Temporal support in active databases,O Etzion; A Gal; A Segev,*,Proceedings of the Second Workshop on Information Technologies and Systems (WITS),1992,18
Optimizing event pattern matching using business process models,Matthias Weidlich; Holger Ziekow; Avigdor Gal; Jan Mendling; Mathias Weske,A growing number of enterprises use complex event processing for monitoring andcontrolling their operations; while business process models are used to document workingprocedures. In this work; we propose a comprehensive method for complex eventprocessing optimization using business process models. Our proposed method is based onthe extraction of behavioral constraints that are used; in turn; to rewrite patterns for eventdetection; and select and transform execution plans. We offer a set of rewriting rules that isshown to be complete with respect to the all; seq; and any patterns. The effectiveness of ourmethod is demonstrated in an experimental evaluation with a large number of processesfrom an insurance company. We illustrate that the proposed optimization leads to significantsavings in query processing. By integrating the optimization in state-of-the-art systems for …,IEEE Transactions on Knowledge and Data Engineering,2014,17
Temporal active databases,Opher Etzion; Avigdor Gal; Arie Segev,*,Proceedings of the International Workshop on an Infrastructure for Temporal Databases,1993,17
Searching business process repositories using operational similarity,Maya Lincoln; Avigdor Gal,Abstract Effective retrieval of relevant know-how segments from business processrepositories can save precious employee time and support non-expert users in locating andreusing process data. We present a methodology for searching repositories and retrievingrelevant process segments; using business logic that is extracted from real-life processmodels. The analysis of a process repository enables the construction of three taxonomieswith which it is possible to process the search intention in operational terms. We tested themethod on the Oracle ERP Business Process Model (OBM); showing the approach to beeffective in enabling the search of business process repositories.,OTM Confederated International Conferences" On the Move to Meaningful Internet Systems",2011,16
Inference of security hazards from event composition based on incomplete or uncertain information,Segev Wasserkrug; Avigdor Gal; Opher Etzion,In many security-related contexts; a quick recognition of security hazards is required. Suchrecognition is challenging; since available information sources are often insufficient to inferthe occurrence of hazards with certainty. This requires that the recognition of security hazardis carried out using inference based on patterns of occurrences distributed over space andtime. The two main existing approaches to the inference of security hazards are a) custom-coded solutions; which are tailored to specific patterns; and cannot respond quickly tochanges in the patterns of occurrences used for inference; and b) approaches based ondirect statistical inferencing techniques; such as regression; which do not enable combiningvarious kinds of evidence regarding the same hazard. In this work; we introduce a moregeneric formal framework which overcomes the aforementioned deficiencies; together …,IEEE transactions on knowledge and data engineering,2008,16
Optimizing exception handling in workflows using process restructuring,Mati Golani; Avigdor Gal,Abstract Exception handling is the process by which a failure in a process is mitigated.Depending on the specifics of an exception; exception handers–specifications of exceptionhandling processes–may range from halting a process; through attempts of activityreactivation; to an identification of an alternative path to successful completion of a process.Designing efficient exception handlers is not a simple task. By their very nature; exceptionsare rare events that may result in poor design of exception handlers in terms of cost andlogic. In this work we aim at improving exception handling performance in workflowmanagement systems (WfMSs); a task which has been recognized as a fundamentalcomponent of WfMSs that is critical to their successful deployment in real-world scenarios.Our approach is based on the observation that when designing a business process as a …,International Conference on Business Process Management,2006,16
Swiss-System Based Cascade Ranking for Gait-Based Person Re-Identification.,Lan Wei; Yonghong Tian; Yaowei Wang; Tiejun Huang,Abstract Human gait has been shown to be an efficient biometric measure for personidentification at a distance. However; it often needs different gait features to handle variouscovariate conditions including viewing angles; walking speed; carrying an object andwearing different types of shoes. In order to improve the robustness of gait-based person re-identification on such multi-covariate conditions; a novel Swiss-system based cascaderanking model is proposed in this paper. Since the ranking model is able to learn asubspace where the potential true match is given the highest ranking; we formulate the gait-based person re-identification as a bipartite ranking problem and utilize it as an effectiveway for multi-feature ensemble learning. Then a Swiss multi-round competition system isdeveloped for the cascade ranking model to optimize its effectiveness and efficiency …,AAAI,2015,15
Scalable stateful stream processing for smart grids,Raul Castro Fernandez; Matthias Weidlich; Peter Pietzuch; Avigdor Gal,Abstract We describe a solution to the ACM DEBS Grand Challenge 2014; which evaluatesevent-based systems for smart grid analytics. Our solution follows the paradigm of statefuldata stream processing and is implemented on top of the SEEP stream processing platform.It achieves high scalability by massive data-parallel processing and the option of performingsemantic load-shedding. In addition; our solution is fault-tolerant; ensuring that the largeprocessing state of stream operators is not lost after failure. Our experimental results showthat our solution processes 1 month worth of data for 40 houses in 4 hours. When we scaleout the system; the time reduces linearly to 30 minutes before the system bottlenecks at thedata source. We then apply semantic load-shedding; maintaining a low median predictionerror and reducing the time further to 17 minutes. The system achieves these results with …,Proceedings of the 8th ACM International Conference on Distributed Event-Based Systems,2014,15
Making sense of top-k matchings: A unified match graph for schema matching,Avigdor Gal; Tomer Sagi; Matthias Weidlich; Eliezer Levy; Victor Shafran; Zoltán Miklós; Nguyen Quoc Viet Hung,Abstract Schema matching in uncertain environments faces several challenges; amongthem the identification of complex correspondences. In this paper; we present a method toaddress this challenge based on top-k matchings; ie; a set of matchings comprising only 1: 1correspondences derived by common matchers. We propose the unified top-k match graphand define a clustering problem for it. The obtained attribute clusters are analysed to derivecomplex correspondences. Our experimental evaluation shows that our approach is able toidentify a significant share of complex correspondences.,Proceedings of the Ninth International Workshop on Information Integration on the Web,2012,15
Schema matching prediction with applications to data source discovery and dynamic ensembling,Tomer Sagi; Avigdor Gal,Abstract Web-scale data integration involves fully automated efforts which lack knowledge ofthe exact match between data descriptions. In this paper; we introduce schema matchingprediction; an assessment mechanism to support schema matchers in the absence of anexact match. Given attribute pair-wise similarity measures; a predictor predicts the successof a matcher in identifying correct correspondences. We present a comprehensiveframework in which predictors can be defined; designed; and evaluated. We formally defineschema matching evaluation and schema matching prediction using similarity spaces anddiscuss a set of four desirable properties of predictors; namely correlation; robustness;tunability; and generalization. We present a method for constructing predictors; supportinggeneralization; and introduce prediction models as means of tuning prediction toward …,The VLDB Journal,2013,14
New models and algorithms for throughput maximization in broadcast scheduling,Chandra Chekuri; Avigdor Gal; Sungjin Im; Samir Khuller; Jian Li; Richard McCutchen; Benjamin Moseley; Louiqa Raschid,Abstract In this paper we consider some basic scheduling questions motivated by queryprocessing that involve accessing resources (such as sensors) to gather data. Clients issuerequests for data from resources and the data may be dynamic or changing which imposestemporal constraints on the delivery of the data. A proxy server has to compute a probingschedule for the resources since it can probe a limited number of resources at each timestep. Due to overlapping client requests; multiple queries can be answered by probing theresource at a certain time. This leads to problems related to some well-studied broadcastscheduling problems. However; the specific requirements of the applications motivate somegeneralizations and variants of previously studied metrics for broadcast scheduling. Weconsider both online and offline versions of these problems and provide new algorithms …,International Workshop on Approximation and Online Algorithms,2010,14
Mining resource scheduling protocols,Arik Senderovich; Matthias Weidlich; Avigdor Gal; Avishai Mandelbaum,Abstract In service processes; as found in the telecommunications; financial; or healthcaresector; customers compete for the scarce capacity of service providers. For such processes;performance analysis is important and it often targets the time that customers are delayedprior to service. However; this wait time cannot be fully explained by the load imposed onservice providers. Indeed; it also depends on resource scheduling protocols; whichdetermine the order of activities that a service provider decides to follow when servingcustomers. This work focuses on automatically learning resource decisions from events. Wehypothesize that queueing information serves as an essential element in mining suchprotocols and hence; we utilize the queueing perspective of customers in the miningprocess. We propose two types of mining techniques: advanced classification methods …,International Conference on Business Process Management,2014,13
Event processing over uncertain data,Avigdor Gal; Segev Wasserkrug; Opher Etzion,Abstract Events are the main input of event-based systems. Some events are generatedexternally and flow across distributed systems; while other events and their content need tobe inferred by the event-based system itself. Such inference has a clear trade-off betweeninferring events with certainty; using full and complete information; and the need to provide aquick notification of newly revealed events. Timely event inference is therefore hampered bythe gap between the actual occurrences of events; to which the system must respond; andthe ability of event-based systems to accurately infer these events. This gap results inuncertainty and may be attributed to unreliable data sources (eg; an inaccurate sensorreading); unreliable networks (eg; packet drop at routers); the use of fuzzy terminology inreports (eg; normal temperature) or the inability to determine with certainty whether a …,*,2011,13
A taxonomy and representation of sources of uncertainty in active systems,Segev Wasserkrug; Avigdor Gal; Opher Etzion,Abstract In recent years; there has been an increased need for the use of active systems–systems that include substantial processing which should be triggered by events. In manycases; however; there is an information gap between the actual occurrences of events towhich such a system must respond; and the data generated by monitoring tools regardingthese events. For example; some events; by their very nature; may not be signaled by anymonitoring tools; or the inaccuracy of monitoring tools may incorrectly reflect the informationassociated with events. The result is that in many cases; there is uncertainty in the activesystem associated with event occurrence. In this paper; we provide a taxonomy of thesources of this uncertainty. Furthermore; we provide a formal way to represent thisuncertainty; which is the first step towards addressing the aforementioned information gap.,International Workshop on Next Generation Information Technologies and Systems,2006,13
Conformance checking and performance improvement in scheduled processes: A queueing-network perspective,Arik Senderovich; Matthias Weidlich; Liron Yedidsion; Avigdor Gal; Avishai Mandelbaum; Sarah Kadish; Craig A Bunnell,Abstract Service processes; for example in transportation; telecommunications or the healthsector; are the backbone of today׳ s economies. Conceptual models of service processesenable operational analysis that supports; eg; resource provisioning or delay prediction. Inthe presence of event logs containing recorded traces of process execution; suchoperational models can be mined automatically. In this work; we target the analysis ofresource-driven; scheduled processes based on event logs. We focus on processes forwhich there exists a pre-defined assignment of activity instances to resources that executeactivities. Specifically; we approach the questions of conformance checking (how to assessthe conformance of the schedule and the actual process execution) and performanceimprovement (how to improve the operational process performance). The first question is …,Information Systems,2016,12
The ROAD from sensor data to process instances via interaction mining,Arik Senderovich; Andreas Rogge-Solti; Avigdor Gal; Jan Mendling; Avishai Mandelbaum,Abstract Process mining is a rapidly developing field that aims at automated modeling ofbusiness processes based on data coming from event logs. In recent years; advances intracking technologies; eg; Real-Time Locating Systems (RTLS); put forward the ability to logbusiness process events as location sensor data. To apply process mining techniques tosuch sensor data; one needs to overcome an abstraction gap; because location datarecordings do not relate to the process directly. In this work; we solve the problem ofmapping sensor data to event logs based on process knowledge. Specifically; we proposeinteractions as an intermediate knowledge layer between the sensor data and the event log.We solve the mapping problem via optimal matching between interactions and processinstances. An empirical evaluation of our approach shows its feasibility and provides …,International Conference on Advanced Information Systems Engineering,2016,12
An integrated matching system: GeRoMeSuite and SMB–Results for OAEI 2010,Christoph Quix; Avigdor Gal; Tomer Sagi; David Kensche,Abstract. We present the results of an integrated matching system which is the result of acooperation project between the Israel Institute of Technology (Technion) and the RWTHAachen University in Germany. We have integrated the GeRoMeSuite system (from RWTHAachen) and SMB (from Technion). Both tools aim at matching schemas; whileGeRoMeSuite offers a variety of matchers; SMB provides the information on how to combinematchers and how to enhance match results. Thus; an integration of the tools is beneficial forboth systems.,Ontology Matching,2010,12
AReNA: adaptive distributed catalog infrastructure based on relevance networks,Vladimir Zadorozhny; Avigdor Gal; Louiqa Raschid; Qiang Ye,Abstract Wide area applications (WAAs) utilize a WAN infrastructure (eg; the Internet) toconnect a federation of hundreds of servers with tens of thousands of clients. Earliergenerations of WAA relied on Web accessible sources and the http protocol for datadelivery. Recent developments such as the PlanetLab [8] testbed is now demonstrating anemerging class of data-and compute-intensive wide area applications.,Proceedings of the 31st international conference on Very large data bases,2005,12
Improving web search with automatic ontology matching,Avigdor Gal; Giovanni Modica; HM Jamil,Abstract Web search can be defined as an information-seeking process; conducted throughan interactive interface that involves searching over heterogeneous Web resources; eitherdirectly or via an information portal. such a search necessitates Web resources comparison;which is hampered by their heterogeneity. In this paper; we propose the use of ontology asan interface conceptualization tool for overcoming the heterogeneity in Web resources andimproving search results. We introduce four ontological structures; namely terms; values;composition; and precedence. Given two ontologies; we suggest a set of algorithms toautomatically match terminologies in two Web resources. The novelty of our approach lies inthe provision of a sophisticated matching technique that takes advantage of severalontological structures. In particular; the use of precedence to capture business rules as …,Submitted for publication. Available upon request from avigal@ ie. technion. ac. il,2003,12
Heterogeneous stream processing and crowdsourcing for traffic monitoring: Highlights,Francois Schnitzler; Alexander Artikis; Matthias Weidlich; Ioannis Boutsis; Thomas Liebig; Nico Piatkowski; Christian Bockermann; Katharina Morik; Vana Kalogeraki; Jakub Marecek; Avigdor Gal; Shie Mannor; Dermot Kinane; Dimitrios Gunopulos,Abstract We give an overview of an intelligent urban traffic management system. Complexevents related to congestions are detected from heterogeneous sources involving fixedsensors mounted on intersections and mobile sensors mounted on public transport vehicles.To deal with data veracity; sensor disagreements are resolved by crowdsourcing. To dealwith data sparsity; a traffic model offers information in areas with low sensor coverage. Weapply the system to a real-world use-case.,Joint European Conference on Machine Learning and Knowledge Discovery in Databases,2014,11
Uncertain entity resolution: re-evaluating entity resolution in the big data era: tutorial,Avigdor Gal,Abstract Entity resolution is a fundamental problem in data integration dealing with thecombination of data from different sources to a unified view of the data. Entity resolution isinherently an uncertain process because the decision to map a set of records to the sameentity cannot be made with certainty unless these are identical in all of their attributes orhave a common key. In the light of recent advancement in data accumulation; management;and analytics landscape (known as big data) the tutorial re-evaluates the entity resolutionprocess and in particular looks at best ways to handle data veracity. The tutorial ties entityresolution with recent advances in probabilistic database research; focusing on sources ofuncertainty in the entity resolution process.,Proceedings of the VLDB Endowment,2014,11
Completeness and ambiguity of schema cover,Avigdor Gal; Michael Katz; Tomer Sagi; Matthias Weidlich; Karl Aberer; Hung Quoc Viet Nguyen; Zoltán Miklós; Eliezer Levy; Victor Shafran,Abstract Given a schema and a set of concepts; representative of entities in the domain ofdiscourse; schema cover defines correspondences between concepts and parts of theschema. Schema cover aims at interpreting the schema in terms of concepts and thus; vastlysimplifying the task of schema integration. In this work we investigate two properties ofschema cover; namely completeness and ambiguity. The former measures the part of aschema that can be covered by a set of concepts and the latter examines the amount ofoverlap between concepts in a cover. To study the tradeoffs between completeness andambiguity we define a cover model to which previous frameworks are special cases. Weanalyze the theoretical complexity of variations of the cover problem; some aim atmaximizing completeness while others aim at minimizing ambiguity. We show that …,OTM Confederated International Conferences" On the Move to Meaningful Internet Systems",2013,11
Net-based analysis of event processing networks–the fast flower delivery case,Matthias Weidlich; Jan Mendling; Avigdor Gal,Abstract Event processing networks emerged as a paradigm to implement applications thatinteract with distributed; loosely coupled components. Such a network consists of eventproducers; event consumers; and event processing agents that implement the applicationlogic. Event processing networks are typically intended to process an extensive amount ofevents. Hence; there is a need for performance and scalability evaluation at design time. Inthis paper; we take up the challenge of modelling event processing networks using colouredPetri nets. We outline how this type of system is modelled and illustrate the formalisation withthe widely used showcase of the Fast Flower Delivery Application (FFDA). Further; we reporton the validation of the obtained coloured Petri net with an implementation of the FFDA inthe ETALIS framework. Finally; we show how the net of the FFDA is employed for analysis …,International Conference on Applications and Theory of Petri Nets and Concurrency,2013,11
Non-binary evaluation for schema matching,Tomer Sagi; Avigdor Gal,Abstract In this work we extend the commonly used binary evaluation of schema matching tosupport evaluation methods for non-binary matching results as well. We motivate our workwith some new applications of schema matching. Non-binary evaluation is formally definedtogether with two new; non-binary evaluation measures using a vector-space representationof schema matching outcome. We provide an empirical evaluation to support the usefulnessof non-binary evaluation and show its superiority to its binary counterpart.,International Conference on Conceptual Modeling,2012,11
On the cardinality of schema matching,Avigdor Gal,Abstract In this paper we discuss aspects of cardinality constraints in schema matching. Anew cardinality classification is proposed; emphasizing the challenges in schema matchingthat evolve from cardinality constraints. We also offer a new research direction forautomating schema matching to manage cardinality constraints.,OTM Confederated International Conferences" On the Move to Meaningful Internet Systems",2005,11
Measuring the relative performance of schema matchers,Shlomo Berkovsky; Yaniv Eytani; Avigdor Gal,Schema matching is a complex process focusing on matching between concepts describingthe data in heterogeneous data sources. There is a shift from manual schema matching;done by human experts; to automatic matching; using various heuristics (schema matchers).In this work; we consider the problem of linearly combining the results of a set of schemamatchers. We propose the use of machine learning algorithms to learn the optimal weightassignments; given a set of schema matchers. We also suggest the use of geneticalgorithms to improve the process efficiency.,Web Intelligence; 2005. Proceedings. The 2005 IEEE/WIC/ACM International Conference on,2005,11
A model for schema integration in heterogeneous databases,Avigdor Gal; Alberto Trombetta; Ateret Anaby-Tavor; Danilo Montesi,Schema integration is the process by which schemata from heterogeneous databases areconceptually integrated into a single cohesive schema. In this work we propose a modelingframework for schema integration; capturing the inherent uncertainty accompanying theintegration process. The model utilizes a fuzzy framework to express a confidence measure;associated with the outcome of a schema integration process. In this paper we provide asystematic analysis of the process properties and establish a criterion for evaluating thequality of matching algorithms; which map attributes among heterogeneous schemata.,Database Engineering and Applications Symposium; 2003. Proceedings. Seventh International,2003,11
A temporal database with data dependencies: a key to computer integrated manufacturing,Dov Dori; Avigdor Gal; Opher Etzion,A temporal database scheme with data dependencies is proposed which supports complextasks; such as version control and configuration management in computer integratedmanufacturing (CIM). This architecture adds functionality to the CIM database; therebyreducing the programming effort required outside the database. The database correctness ismaintained even after introducing engineering changes. A case study shows that theproposed scheme also supports automated decision making for shopfloor control.,International Journal of Computer Integrated Manufacturing,1996,11
Goal Recognition Design with Non-Observable Actions.,Sarah Keren; Avigdor Gal; Erez Karpas,Abstract Goal recognition design involves the offline analysis of goal recognition models byformulating measures that assess the ability to perform goal recognition within a model andfinding efficient ways to compute and optimize them. In this work we relax the fullobservability assumption of earlier work by offering a new generalized model for goalrecognition design with non-observable actions. A model with partial observability isrelevant to goal recognition applications such as assisted cognition and security; whichsuffer from reduced observability due to sensor malfunction or lack of sufficient budget. Inparticular we define a worst case distinctiveness (wcd) measure that represents the maximalnumber of steps an agent can take in a system before the observed portion of his trajectoryreveals his objective. We present a method for calculating wcd based on a novel …,AAAI,2016,10
The generation Y of XML schema matching panel description,Avigdor Gal,Abstract Schema matching is the task of matching between concepts describing themeaning of data in various heterogeneous; distributed data sources (eg XML DTDs andXML Schemata). Schema matching is recognized to be one of the basic operations requiredby the process of data integration [3]; and thus has a great impact on its outcome. Schemamappings (the outcome of the matching process) can serve in tasks of generating globalschemata; query rewriting over heterogeneous sources; duplicate data elimination; andautomatic streamlining of workflow activities that involve heterogeneous data sources. Assuch; schema matching has impact on numerous applications. It impacts business; wherecompany data sources continuously realign due to changing markets. It also impacts lifesciences; where scientific workflows cross system boundaries more often than not.,International XML Database Symposium,2007,10
Optimal information monitoring under a politeness constraint,Jonathan Eckstein; Avigdor Gal; Sarit Reiner,Documents; Authors; Tables. Log in; Sign up; MetaCart; Donate. CiteSeerX logo. Documents:Advanced Search Include Citations. Authors: Advanced Search Include Citations | Disambiguate.Tables: Optimal Information Monitoring under a Politeness Constraint (2005). Cached. Downloadas a PDF; Download as a PS. Download Links. [rutcor.rutgers.edu]. Save to List; Add to Collection;Correct Errors; Monitor Changes. by Jonathan Eckstein ; Avigdor Gal ; Sarit Reiner. Citations:3 - 1 self. Summary; Citations; Active Bibliography; Co-citation; Clustered Documents; VersionHistory. BibTeX. @MISC{Eckstein05optimalinformation; author = {Jonathan Eckstein and AvigdorGal and Sarit Reiner}; title = {Optimal Information Monitoring under a Politeness Constraint}; year ={2005} }. Share. Facebook; Twitter; Reddit; Bibsonomy. OpenURL. Abstract. Keyphrases. optimalinformation monitoring politeness constraint …,*,2005,10
Evaluating Matching Algorithms: the Monotonicity Principle.,Ateret Anaby-Tavor; Avigdor Gal; Alberto Trombetta,Abstract In this paper we present the monotonicity principle; a sufficient condition to ensurethat exact mapping; a mapping as would be performed by a human observer; is rankedclose to the best mapping; as generated automatically by a matching algorithm. Theresearch is motivated by the introduction of the semantic Web vision and the shift towardsmachine understandable Web resources. We support the importance of the monotonicityprinciple by empirical analysis of a matching algorithm; showing that algorithms that obeythis principle rank the exact mapping close to the best mapping.,IIWeb,2003,10
Information Services for the Web: Building and Maintaining Domain Models,Avigdor Gal; Scott Kerr; John Mylopoulos,The World Wide Web serves as a leading vehicle for information dissemination by offeringinformation services; such as product information; group interactions; or sales transactions.Three major factors affect the performance and reliability of information services for the Web;namely the distribution of information which has resulted from the globalization ofinformation systems; the heterogeneity of information sources; and the sources' instabilitycaused by autonomous evolution. This paper focuses on integrating existing informationsources; available via the Web; in the delivery of information services. The primary objectiveof the paper is to provide mechanisms for structuring and maintaining domain models forWeb applications. These mechanisms are based on conceptual modeling techniques;where concepts are being defined and refined within a metadata repository through the …,International Journal of Cooperative Information Systems,1999,10
In log and model we trust? A generalized conformance checking framework,Andreas Rogge-Solti; Arik Senderovich; Matthias Weidlich; Jan Mendling; Avigdor Gal,Abstract While models and event logs are readily available in modern organizations; theirquality can seldom be trusted. Raw event recordings are often noisy; incomplete; andcontain erroneous recordings. The quality of process models; both conceptual and data-driven; heavily depends on the inputs and parameters that shape these models; such asdomain expertise of the modelers and the quality of execution data. The mentioned qualityissues are specifically a challenge for conformance checking. Conformance checking is theprocess mining task that aims at coping with low model or log quality by comparing themodel against the corresponding log; or vice versa. The prevalent assumption in theliterature is that at least one of the two can be fully trusted. In this work; we propose ageneralized conformance checking framework that caters for the common case; when …,International Conference on Business Process Management,2016,9
From diversity-based prediction to better ontology & schema matching,Avigdor Gal; Haggai Roitman; Tomer Sagi,Abstract Ontology & schema matching predictors assess the quality of matchers in theabsence of an exact match. We propose MCD (Match Competitor Deviation); a new diversity-based predictor that compares the strength of a matcher confidence in the correspondenceof a concept pair with respect to other correspondences that involve either concept. We alsopropose to use MCD as a regulator to optimally control a balance between Precision andRecall and use it towards 1: 1 matching by combining it with a similarity measure that isbased on solving a maximum weight bipartite graph matching (MWBM). Optimizing thecombined measure is known to be an NP-Hard problem. Therefore; we propose CEM; anapproximation to an optimal match by efficiently scanning multiple possible matches; usingrare event estimation. Using a thorough empirical study over several benchmark real …,Proceedings of the 25th International Conference on World Wide Web,2016,9
Discovering queues from event logs with varying levels of information,Arik Senderovich; Sander JJ Leemans; Shahar Harel; Avigdor Gal; Avishai Mandelbaum; Wil MP van der Aalst,Abstract Detecting and measuring resource queues is central to business processoptimization. Queue mining techniques allow for the identification of bottlenecks and otherprocess inefficiencies; based on event data. This work focuses on the discovery of resourcequeues. In particular; we investigate the impact of available information in an event log onthe ability to accurately discover queue lengths; ie the number of cases waiting for anactivity. Full queueing information; ie timestamps of enqueueing and exiting the queue;makes queue discovery trivial. However; often we see only the completions of activities.Therefore; we focus our analysis on logs with partial information; such as missingenqueueing times or missing both enqueueing and service start times. The proposeddiscovery algorithms handle concurrency and make use of statistical methods for …,International Conference on Business Process Management,2015,9
A dual framework and algorithms for targeted online data delivery,Haggai Roitman; Avigdor Gal; Louiqa Raschid,A variety of emerging online data delivery applications challenge existing techniques fordata delivery to human users; applications; or middleware that are accessing data frommultiple autonomous servers. In this paper; we develop a framework for formalizing andcomparing pull-based solutions and present dual optimization approaches. The firstapproach; most commonly used nowadays; maximizes user utility under the strict setting ofmeeting a priori constraints on the usage of system resources. We present an alternativeand more flexible approach that maximizes user utility by satisfying all users. It does thiswhile minimizing the usage of system resources. We discuss the benefits of this latterapproach and develop an adaptive monitoring solution Satisfy User Profiles (SUPs).Through formal analysis; we identify sufficient optimality conditions for SUP. Using real …,IEEE Transactions on Knowledge and Data Engineering,2011,9
Enhancing the capabilities of attribute correspondences,Avigdor Gal,Abstract In the process of schema matching; attribute correspondence is the association ofattributes in different schemas. Increased importance of attribute correspondences led tonew research attempts that were devoted to improve attribute correspondences byextending their capabilities. In this chapter; we describe recent advances in the schemamatching literature that attempt to enhance the capabilities of attribute correspondences. Wediscuss contextual schema matching as a method for introducing conditionalcorrespondences; based on context. The use of semantic matching is proposed to extendattribute correspondences to results in an ontological relationship. Finally; probabilisticschema matching generates multiple possible models; modeling uncertainty about whichone is correct by using probability theory.,*,2011,9
Providing Top-K Alternative Schema Matchings with ${\mathcal {O}} nto {\mathcal {M}} atcher$,Haggai Roitman; Avigdor Gal; Carmel Domshlak,Abstract Uncertainty management at the core of data integration was motivated by newapproaches to data management; such as dataspaces [2] and the use of fullyautomaticschema matching takes an increasingly prominent role in this field. Recent works suggestedthe use; in parallel; of several alternative schema matching; as an uncertainty managementtool [3; 1]. We offer in this work OntoMatcher; an extension of the OntoBuilder [4] schemamatching tool to support the management of multiple (top-K) schema matching alternatives.,International Conference on Conceptual Modeling,2008,9
Interpreting similarity measures: Bridging the gap between schema matching and data integration,Avigdor Gal,It has been recognized in the literature that the process of schema matching is uncertain.Such uncertainty at the core of data integration needs to be managed correctly to avoid direconsequences. Traditionally; manual intervention was required to make local decisions atthe schema matching level to reach a deteministic matching before the rest of the dataintegration system can use it. Recently; however; researchers have argued for moving tofully-automatic transition of schema matching results into other data integration activities. Inthis work we discuss what it takes to bridge the gap between automatic schema matchingand data integration. We briefly present the modeling of schema matching as an uncertainprocess; review a sufficient condition for using matcher similarity measure as a measure ofschema matching correctness and provide a case study of data integration in Peer …,Data Engineering Workshop; 2008. ICDEW 2008. IEEE 24th International Conference on,2008,9
Satisfying complex data needs using pull-based online monitoring of volatile data sources,Haggai Roitman; Avigdor Gal; Louiqa Raschid,Emerging applications on the Web require better management of volatile data in pull-basedenvironments. In a pull based setting; data may be periodically removed from the server.Data may also become obsolete; no longer serving client needs. In both cases; we considersuch data to be volatile. To model such constraints on data usability; and support complexuser needs we define profiles to specify which data sources are to be monitored and when.Using a novel abstraction of execution intervals we model complex profiles that accesssimultaneously several servers to gain from the used data. Given some budgetaryconstraints (eg; bandwidth); the paper formalizes the problem of maximizing completeness.,Data Engineering; 2008. ICDE 2008. IEEE 24th International Conference on,2008,9
Monitoring an information source under a politeness constraint,Jonathan Eckstein; Avigdor Gal; Sarit Reiner,We describe scheduling algorithms for monitoring a single information source whosecontents change at times modeled by a nonhomogeneous Poisson process. In a given timeperiod of length T; we enforce a server-side politeness constraint that we may only probe thesource at most n times. This constraint; along with an optional constraint that no two probesmay be spaced less than δ time units apart; is intended to prevent the monitor from beingclassified as a nuisance to be “locked out” of the information source. To develop ouralgorithms; we use a portion of the cost model developed in our earlier work. Our firstalgorithm assumes a discrete set of N> n possible update times; and uses dynamicprogramming to identify a provably optimal subset of n of these times at which to probe theserver. Our second algorithm is a simple direct search for locally improving any …,INFORMS Journal on Computing,2008,9
$\mathcal {OPOSSUM} $: Bridging the Gap Between Web Services and the Semantic Web,Eran Toch; Iris Reinhartz-Berger; Avigdor Gal; Dov Dori,Abstract Web services are distributed software components; which are accessed through theWorld Wide Web. The increasing use of Web services raises the need for efficient andprecise retrieval solutions of Web services. We propose to investigate aspects of Webservice retrieval; facing a gap between user specifications; given in some form of a semanticdescription; and Web service definition; given in a standard interface description such asWeb Service Description Language (WSDL); that conveys the syntax of the service. Bridgingthis gap is becoming more and more urgent as users need to find Web services amongincreasing numbers of Web services within organizations and on the Web. One of the majorchallenges of service-retrieval is to make services accessible without having to do additionalsemantic work of classification.,International Workshop on Next Generation Information Technologies and Systems,2006,9
Data driven and temporal rules in PARDES,Opher Etzion; Avigdor Gal; Arie Segev,Summary Data driven rules is one of the important rule types that are used by databaseapplications. This paper analyzes requirements for a programming paradigm appropriate forthe support of data-driven rules; states the linguistic paradigm; discusses its supportingarchitecture and shows an extension of the model to support temporal functionalities;especially retroactive and proactive processing. The focus in this paper is on the softwareengineering aspects of the proposed model: ease of use through a high-level language andimproving the verifiability of the rule language.,*,1994,9
SMART: A tool for analyzing and reconciling schema matching networks,Quoc Viet Hung Nguyen; Thanh Tam Nguyen; Vinh Tuan Chau; Tri Kurniawan Wijaya; Zoltán Miklós; Karl Aberer; Avigdor Gal; Matthias Weidlich,Schema matching supports data integration by establishing correspondences between theattributes of independently designed database schemas. In recent years; various tools forautomatic pair-wise matching of schemas have been developed. Since the matchingprocess is inherently uncertain; the correspondences generated by such tools are oftenvalidated by a human expert. In this work; we consider scenarios in which attributecorrespondences are identified in a network of schemas and not only in a pairwise setting.Here; correspondences between different schemas are interrelated; so that incomplete anderroneous matching results propagate in the network and the validation of acorrespondence by an expert has ripple effects. To analyse and reconcile such matchings inschema networks; we present the Schema Matching Analyzer and Reconciliation Tool …,Data Engineering (ICDE); 2015 IEEE 31st International Conference on,2015,8
Event recognition challenges and techniques: Guest editors' introduction,Alexander Artikis; Avigdor Gal; Vana Kalogeraki; Matthias Weidlich,The concept of event processing is established as a generic computational paradigm invarious application fields; ranging from data processing in Web environments; over logisticsand networking; to finance and medicine [Cugola and Margara 2012]. Events report on statechanges of a system and its environment. Event recognition (event pattern matching[Luckham 2002]); in turn; refers to the detection of events that are considered relevant forprocessing; thereby providing the opportunity to implement reactive measures. Examplesconsist of the recognition of attacks in computer network nodes [Dousson and Maigat 2007];human activities on video content [Brendel et al. 2011]; emerging stories and trends on theSocial Web1; traffic and transport incidents in smart cities [Artikis et al. 2014b]; fraud inelectronic marketplaces [Schultz-Møller et al. 2009]; cardiac arrhythmias [Callens et al …,ACM Transactions on Internet Technology (TOIT),2014,8
Self organizing semantic topologies in p2p data integration systems,Ami Eyal; Avigdor Gal,A semantic topology is a peer overlay network connected via semantic links; constructedusing schema mappings and used for peer querying. The large-scale and dynamicenvironments of P2P networks dictate the use of automatic schema matching; which wasshown to carry with it a degree of uncertainty. Therefore; peers prefer network topologiesthat improve their ability to answer queries effectively; by reducing uncertainty. We introducea model for a peer database management system that manages the inherent uncertainty ofautomatic schema matching; the amplification of this uncertainty over transitive mappings;and its impact on query processing. We then briefly present the research challengesinvolving a dynamic topology setting where peers can change their neighbor set selection.,Data Engineering; 2009. ICDE'09. IEEE 25th International Conference on,2009,8
Information services for the web: Building and maintaining domain models,Scott Kerr; Avigdor Gal; John Mylopoulos,The World Wide Web is serving as a leading vehicle for information dissemination byoffering information services; such as product information; group interactions; or salestransactions. Three major factors affect the performance and reliability of informationservices for the Web: the distribution of information which has resulted from the globalizationof information systems; the heterogeneity of information sources; and the sources' instabilitycaused by their autonomous evolution. This paper focuses on integrating existinginformation sources; available via the Web; in the delivery of information services. Theprimary objective of the paper is to provide mechanisms for structuring and maintaining adomain model for Web applications. These mechanisms are based on conceptual modelingtechniques; where concepts are being defined and refined within a meta-data repository …,Cooperative Information Systems; 1998. Proceedings. 3rd IFCIS International Conference on,1998,8
Privacy Preserving Plans in Partially Observable Environments.,Sarah Keren; Avigdor Gal; Erez Karpas,Abstract Big brother is watching but his eyesight is not all that great; since he only has partialobservability of the environment. In such a setting agents may be able to preserve theirprivacy by hiding their true goal; following paths that may lead to multiple goals. In this workwe present a framework that supports the offline analysis of goal recognition settings withnon-deterministic system sensor models; in which the observer has partial (and possiblynoisy) observability of the agent's actions; while the agent is assumed to have fullobservability of his environment. In particular; we propose a new variation of worst casedistinctiveness (wcd); a measure that assesses the ability to perform goal recognition withina model. We describe a new efficient way to compute this measure via a novel compilationto classical planning. In addition; we discuss the tools agents have to preserve privacy; by …,IJCAI,2016,7
Data-driven performance analysis of scheduled processes,Arik Senderovich; Andreas Rogge-Solti; Avigdor Gal; Jan Mendling; Avishai Mandelbaum; Sarah Kadish; Craig A Bunnell,Abstract The performance of scheduled business processes is of central importance forservices and manufacturing systems. However; current techniques for performance analysisdo not take both queueing semantics and the process perspective into account. In this work;we address this gap by developing a novel method for utilizing rich process logs to analyzeperformance of scheduled processes. The proposed method combines simulation; queueinganalytics; and statistical methods. At the heart of our approach is the discovery of anindividual-case model from data; based on an extension of the Colored Petri Nets formalism.The resulting model can be simulated to answer performance queries; yet it is computationalinefficient. To reduce the computational cost; the discovered model is projected intoQueueing Networks; a formalism that enables efficient performance analytics. The …,International Conference on Business Process Management,2015,7
Ontology verification using contexts,Aviv Segev; Avigdor Gal,Abstract. Ontologies have become the de-facto modeling tool of choice; used in a variety ofapplications and prominently in the Semantic Web. Their design and maintenance;nevertheless; have been and still are a daunting task. As a result; ontologies quickly becomeunderspecified. Therefore; if ontologies do not evolve; the semantic infrastructure of theinformation system can no longer support the changing needs of the organization. In thiswork we provide a model to semi-automatically support relationship evolution in an ontologyusing contexts. We propose to use (machine-generated) contexts as a mechanism forquantifying relationships among concepts. To do so we compare the contexts that areassociated with the ontology constructs. On a conceptual level; we introduce an ontologyverification model; a quantified model for automatically assessing the validity of …,Contexts and Ontologies: Theory; Practice and Applications,2006,7
Negotiation-based price discrimination for information goods,Gabi Koifman; Onn Shehory; Avigdor Gal,Abstract We present a mechanism for trading database tuples in a multiagent system. Themechanism enables negotiation and evaluation of database-based information goods. Aspart of the work we propose various policies for dynamic pricing of information goods. Wehave developed a testbed that simulates a multi-agent system where agents use the offeredmechanism and evaluated the system performance when sellers use different pricingpolicies in competitive and non-competitive environments. The investigated pricing policiesinclude two novel pricing policies that implement negotiation and price discrimination acrossbuyers. These were compared to two policies known in the art; which implement dynamicposted pricing. We have empirically demonstrated the superiority of the offered policies inmaximizing sellers' gains. We have additionally identified equilibria profiles of these …,Proceedings of the Third International Joint Conference on Autonomous Agents and Multiagent Systems-Volume 2,2004,7
Latency profiles: Performance monitoring for wide area applications,Louiqa Raschid; Hui-Fang Wen; Avigdor Gal; Vladimir Zadorozhny,Recent technological advances have enabled the deployment of wide area applicationsagainst Internet accessible sources. A performance challenge to applications in such asetting is the unpredictable end-to-end latency of accessing these sources. We use passiveinformation gathering mechanisms to learn end-to-end latency distributions and constructlatency profiles (LPs). We hypothesize that a group of clients; within an autonomous system(AS); that are accessing a content server; in another AS; may be represented by (one ormore) LPs. Related networking research on IDMaps; points of congestion; and BGP routessupport such hypothesis. We develop aggregate LPs to provide coverage of groups(clusters) of client-server pairs. Using data gathered from a (limited) experiment wedemonstrate the feasibility of constructing LPs.,Internet Applications. WIAPP 2003. Proceedings. The Third IEEE Workshop on,2003,7
Scheduling of data transcription in periodically connected databases,Avigdor Gal; Jonathan Eckstein; Zachary G Stoumbos,Abstract Contemporary data management in applications such as pervasive systems; Web‐based supply chain management; data warehouses; and Web crawlers involve the periodictranscription of data onto secondary devices in a networked environment. In this paper; wefocus on the scheduling of periodic data transcription in append‐only environments; such ase‐mail inboxes; newsgroups; technical support bulletin boards; or procurement requests. Ifthe client connects to the server too frequently; the client will nearly always have up‐to‐dateinformation; but the usage of network resources may be excessive. Conversely; veryinfrequent connections will conserve network resources; but the client's data may often besignificantly out of date; which may also be costly (in terms of lost opportunities; forexample). Thus; the best transcription policies should make on optimal trade‐off between …,*,2003,7
A language for the support of constraints in temporal active databases,Avigdor Gal; Opher Etzion; Arie Segev,Abstract Complex applications in domains such as decision analysis and real time systemsrequire a database that supports active enforcement of constraints with temporal aspects. Inthis paper we present a temporal active language for the support of constraints in temporalactive databases. The language primitives are presented using examples and an EBNF;followed by a discussion of the language properties.,Proc. Workshop on Constraints; Databases and Logic Programming,1995,7
Blockchains for business process management-challenges and opportunities,Jan Mendling; Ingo Weber; Wil Van Der Aalst; Jan vom Brocke; Cristina Cabanillas; Florian Daniel; Soren Debois; Claudio Di Ciccio; Marlon Dumas; Schahram Dustdar; Avigdor Gal; Luciano Garcia-Banuelos; Guido Governatori; Richard Hull; Marcello La Rosa; Henrik Leopold; Frank Leymann; Jan Recker; Manfred Reichert; Hajo A Reijers; Stefanie Rinderle-Ma; Andreas Rogge-Solti; Michael Rosemann; Stefan Schulte; Munindar P Singh; Tijs Slaats; Mark Staples; Barbara Weber; Matthias Weidlich; Mathias Weske; Xiwei Xu; Liming Zhu,Abstract: Blockchain technology promises a sizable potential for executing inter-organizational business processes without requiring a central party serving as a single pointof trust (and failure). This paper analyzes its impact on business process management(BPM). We structure the discussion using two BPM frameworks; namely the six BPM corecapabilities and the BPM lifecycle. This paper provides research directions for investigatingthe application of blockchain technology to BPM. Subjects: Software Engineering (cs. SE)Cite as: arXiv: 1704.03610 [cs. SE](or arXiv: 1704.03610 v1 [cs. SE] for this version)Submission history From: Ingo Weber [view email][v1] Wed; 12 Apr 2017 03: 44: 18 GMT(46kb; D),arXiv preprint arXiv:1704.03610,2017,6
A new class of lineage expressions over probabilistic databases computable in p-time,Batya Kenig; Avigdor Gal; Ofer Strichman,Abstract We study the problem of query evaluation over tuple-independent probabilisticdatabases. We define a new characterization of lineage expressions called disjoint branchacyclic; and show this class to be computed in P-time. Specifically; this work extends theclass of lineage expressions for which evaluation can be performed in PTIME. We achievethis extension with a novel usage of junction trees to compute the probability of theselineage expressions.,International Conference on Scalable Uncertainty Management,2013,6
Web monitoring 2.0: Crossing streams to satisfy complex data needs,Haggai Roitman; Avigdor Gal; Louiqa Raschid,Web Monitoring 2.0 supports the complex information needs of clients who probe multipleinformation sources and generate mashups by integrating across these volatile streams. Aproxy that aims at satisfying multiple customized client profiles will face a scalabilitychallenge in trying to maximize the number of clients served while at the same time fullysatisfying complex client needs. In this paper; we introduce an abstraction of complexexecution intervals; a combination of time intervals and information streams; to capturecomplex client needs. Given some budgetary constraints (eg; bandwidth); we present offlinealgorithmic solutions for the problem of maximizing completeness of capturing complexprofiles.,Data Engineering; 2009. ICDE'09. IEEE 25th International Conference on,2009,6
Efficient entity resolution with mfiblocks,Batya Kenig; Avigdor Gal,ABSTRACT Entity resolution is the process of discovering groups of tuples that correspondto the same real world entity. In order to avoid the prohibitively expensive comparison of allpairs of tuples; blocking algorithms separate the tuples into blocks which are highly likely tocontain matching pairs.,Proc. of the VLDB Endowment,2009,6
Capturing approximated data delivery tradeoffs,Haggai Roitman; Avigdor Gal; Louiqa Raschid,This paper presents a middleware data delivery setting with a proxy that is required tomaximize the completeness of captured updates; specified in its clients' profiles; whileminimizing at the same time the delay in delivering the updates to clients. The two objectivesmay conflict when the monitoring budget is limited. Therefore; any solution should considerthis tradeoff in satisfying both objectives. We term this problem the" proxy dilemma" andformalize it as a biobjective optimization problem. Such problem occurs in manycontemporary applications; such as mobile and sensor networks; and poses scalabilitychallenges in delivering up-to-date data from remote resources to meet client specifications.We present a Pareto set as a formal solution to the proxy dilemma. We discuss thecomplexity of generating a Pareto set for the proxy dilemma and suggest an …,Data Engineering; 2008. ICDE 2008. IEEE 24th International Conference on,2008,6
Scalable catalog infrastructure for managing access costs and source selection in wide area networks,Vladimir Zadorozhny; Louiqa Raschid; Avigdor Gal,A WAN environment; such as the Internet; connects a federation of hundreds of servers withtens of thousands of clients; which poses a substantial scalability challenge. Clients maychoose among sources that vary in both their content and quality as well as in their accesslatencies. At the same time; Internet accessible data sources exhibit transient behavior; theunpredictable behavior of a dynamic WAN results in a wide variability in access cost (end-to-end latency). This motivates a need for a source selection strategy that requires maintainingaccess cost distributions (latency profiles) for each client/server pair. However; in thepresence of hundreds of servers and thousands of clients; managing latency profiles cannotscale. We present a scalable methodology to manage latency profiles that use non-randomassociations between client/server pairs. Such non-random associations may be …,International Journal of Cooperative Information Systems,2008,6
Bid-Based approach for pricing web service,Inbal Yahav; Avigdor Gal; Nathan Larson,Abstract We consider a problem of Web service resource allocation in an economic setting.We assume that different requestors have different valuations for services and a deadline forexecuting a service; after which it is no longer required. We formally show an optimal offlineallocation that maximizes the total welfare; denoted as the total benefit of the requestors. Wethen propose a bid-based approach to resource allocation and pricing for Web services.Using a detailed simulation; we analyze its behavior and performance compared to otherknown algorithms. We empirically show that flexibility in service price benefits both theprovider in terms of profit and the requestors in terms of welfare. Our problem motivationstems from the expanding use of Service-Oriented Architecture (SOA) for outsourcingenterprize activities. While the most common method for pricing a Web service nowadays …,OTM Confederated International Conferences" On the Move to Meaningful Internet Systems",2006,6
A parallel execution model for updating temporal databases,Avigdor Gal; Opher Etzion,Abstract A parallel execution model for the update process of temporal databases isintroduced in this paper; based on temporal parallelism and temporal independence. Theparallel approach improves the throughput of massive and complex updates of a multi-version schema system. The notion of temporal agents and its e ect on parallelism isdiscussed; as well as di erent transaction modes. Several simulation results that present thebene ts of the parallel execution model are introduced and discussed.,database,1994,6
On the impact of junction-tree topology on weighted model counting,Batya Kenig; Avigdor Gal,Abstract We present and evaluate the power of a new framework for weighted modelcounting and inference in graphical models; based on exploiting the topology of the junctiontree representing the formula. The proposed approach uses the junction tree topology inorder to craft a reduced set of partial assignments that are guaranteed to decompose theformula. We show that taking advantage of the junction tree structure; along with existingoptimization methods borrowed from the CNF-SAT domain; can translate into significant timesavings for weighted model counting algorithms.,International Conference on Scalable Uncertainty Management,2015,5
Discovery and validation of queueing networks in scheduled processes,Arik Senderovich; Matthias Weidlich; Avigdor Gal; Avishai Mandelbaum; Sarah Kadish; Craig A Bunnell,Abstract Service processes; for example in transportation; telecommunications or the healthsector; are the backbone of today's economies. Conceptual models of such serviceprocesses enable operational analysis that supports; eg; resource provisioning or delayprediction. Automatic mining of such operational models becomes feasible in the presenceof event-data traces. In this work; we target the mining of models that assume a resource-driven perspective and focus on queueing effects. We propose a solution for the discoveryand validation problem of scheduled service processes-processes with a predefinedschedule for the execution of activities. Our prime example for such processes are complexoutpatient treatments that follow prior appointments. Given a process schedule and datarecorded during process execution; we show how to discover Fork/Join networks; a …,International Conference on Advanced Information Systems Engineering,2015,5
Content-based validation of business process modifications,Maya Lincoln; Avigdor Gal,Abstract Researchers become increasingly interested in developing tools for evaluating thecorrectness of business process models. We present a methodology for content-basedvalidation of changes to business processes; relying on an automatic extraction of businesslogic from real-life business process repositories. Each process step in a repository isautomatically transformed to a descriptor-containing objects; actions; and related qualifiers.From the collection of descriptors we induce taxonomies of action sequence; object lifecycle;and object and action hierarchies that form the logical foundation of the presented validationprocess. The method utilizes these taxonomies to identify process deficiencies that mayoccur due to process model modification; and suggests alternatives in order to correct andvalidate the models.,International Conference on Conceptual Modeling,2011,5
Semantic methods for service categorization--an empirical study,Avigdor Gal,Abstract In this work we provide an initial analysis of service categorization; the process ofassociating services with ontologies. Service categorization is an important pre-processingstep to tasks such as service composition. The absence of semantic understanding ofservices may yield erroneous compositions and therefore; service categorization can assistin determining the correctness of a composition. We analyze two common methods for textprocessing; TF/IDF and context analysis. We also test two types of service description;textual and WSDL. Our initial results indicate that context analysis is more useful than TF/IDFand that WSDL description provides better categorization than textual description.,SDSI'07,2007,5
P $ $^ 3$ $-Folder: Optimal Model Simplification for Improving Accuracy in Process Performance Prediction,Arik Senderovich; Alexander Shleyfman; Matthias Weidlich; Avigdor Gal; Avishai Mandelbaum,Abstract Operational process models such as generalised stochastic Petri nets (GSPNs) areuseful when answering performance queries on business processes (eg 'how long will ittake for a case to finish?'). Recently; methods for process mining have been developed todiscover and enrich operational models based on a log of recorded executions ofprocesses; which enables evidence-based process analysis. To avoid a bias due toinfrequent execution paths; discovery algorithms strive for a balance between over-fittingand under-fitting regarding the originating log. However; state-of-the-art discoveryalgorithms address this balance solely for the control-flow dimension; neglecting possibleover-fitting in terms of performance annotations. In this work; we thus offer a technique forperformance-driven model reduction of GSPNs; using structural simplification rules. Each …,International Conference on Business Process Management,2016,4
In schema matching; even experts are human: Towards expert sourcing in schema matching,Tomer Sagi; Avigdor Gal,Schema matching problems have been historically defined as a semi-automated task inwhich correspondences are generated by matching algorithms and subsequently validatedby a single human expert. Emerging alternative models are based upon piecemeal humanvalidation of algorithmic results and the usage of crowd based validation. We propose analternative model in which human and algorithmic matchers are given more symmetric roles.Under this model; better insight into the respective strengths and weaknesses of human andalgorithmic matchers is required. We present initial insights from a pilot study conducted andoutline future work in this area.,Data Engineering Workshops (ICDEW); 2014 IEEE 30th International Conference on,2014,4
Business Process Management: 10th International Conference; BPM 2012; Tallinn; Estonia; September 3-6; 2012; Proceedings,Alistair Barros; Avigdor Gal; Ekkart Kindler,This book constitutes the proceedings of the 10th International Conference on BusinessProcess Management; BPM 2012; held in Tallinn; Estonia; in September 2012. The 17regular papers and 7 short papers included in this volume were carefully reviewed andselected from 126 submissions. The book also features two keynote lectures which weregiven at the conference. The papers are organized in topical sections named: processquality; conformance and compliance; BPM applications; process model analysis; BPM andthe cloud; requirements and performance; process mining; and refactoring and optimization.,*,2012,4
Generic Architecture of Complex Event Processing Systems.,Avigdor Gal; Ethan Hadar,ABSTRACT In recent years; there has been a growing need for the use of active systems;systems that are required to respond automatically to events. Examples include applicationssuch as Business Activity Monitoring (BAM) and Business Process Management (BPM).Complex event processing is emerging as a discipline in its own right; with roots in existingresearch disciplines such as Databases and Software Engineering. This chapter aims atintroducing a generic architecture of complex event processing systems that promotesmodularity and flexibility. We start with a brief introduction of the primitive elements ofcomplex event processing systems; namely events and rules. We discuss a grid approach tocomplex event processing systems. We detail the layers of the proposed architecture; aswell as the architecture main components within the context of the major data flow in an …,*,2010,4
A dual framework and algorithms for targeted data delivery,Haggai Roitman; Louiqa Raschid; Avigdor Gal; Laura Bright,A variety of emerging wide area applications challenge existing techniques for data deliveryto users and applications accessing data from multiple autonomous servers. In this paper;we develop a framework for comparing pull based solutions and present dual optimizationapproaches. Informally; the first approach maximizes user utility of profiles while satisfyingconstraints on the usage of system resources. The second approach satisfies the utility ofuser profiles while minimizing the usage of system resources. We present a static optimalsolution (SUP) for the latter approach and formally identify sufficient conditions for SUP to beoptimal for both. A shortcoming of static solutions to pull-based delivery is that they cannotadapt to the dynamic behavior of Web source updates. Therefore; we present an adaptivealgorithm (fbSUP) and show how it can incorporate feedback to improve user utility with …,*,2005,4
Egovernment policy evaluation support using multilingual ontologies,Aviv Segev; Avigdor Gal,Abstract: The paper describes the problem associated with multilingual systems in the localgovernment. The paper highlights the issues that are affected by the multilingual systems.Some possible solutions; such as a single ontology system; which deal with the multilingualproblem are presented as well.,Proc. of 1st Int. Conf. on Interoperability of eGovernment Services (eGovInterop 2005)(February 23-24; 2005),2005,4
Adaptive pull-based data freshness policies for diverse update patterns,Laura Bright; Avigdor Gal; Louiqa Raschid,An important challenge to effective data delivery in wide area environments is maintainingthe data freshness of objects using solutions that can scale to a large number of clientswithout incurring significant server overhead. Policies for maintaining data freshness aretraditionally either push-based or pull-based. Push-based policies involve pushing dataupdates by servers; they may not scale to a large number of clients. Pull-based policiesrequire clients to contact servers to check for updates; their effectiveness is limited by thedifficulty of predicting updates. Models to predict updates generally rely on some knowledgeof past updates. Their accuracy of prediction may vary and determining the most appropriatemodel is non-trivial. In this paper; we present an adaptive pull-based solution to thischallenge. We first present several techniques that use update history to estimate the …,*,2004,4
Data management in ecommerce (tutorial session): the good; the bad; and the ugly,Avigdor Gal,Electronic Commerce (eCommeree) is conceived as one of the major channels forperforming commerce on a global scale; and the area is rapidly evolving. Electroniccommerce is based on electronic transfer of data as a main vehicle of" doing business;"while the usage of conventional methods (paper; telephone; etc.) is dramatically reduced insuch an environment. In particular; electronic exchange of data becomes the most cost-effective channel of performing low-cost transactions. Enabling the transfer of data; in and byitself; is hardly sufficient to support efficient and correct processing of transaction in aneCommeree environment. Especially in B2B; enterprises have evolved independently;creating different data ontologies; and thus giving rise to semantic heterogeneity. Thisproblem; which has been investigated for a few decades now; have received a new …,ACM SIGMOD Record,2000,4
Regulating agent involvement in inter-enterprise electronic commerce,Avigdor Gal; Naftaly H Minsky; Victoria Ungureanu,Current research on electronic commerce focuses mainly on fair and efficient transfer ofmoney and goods between a client and a vendor. Inter-enterprise electronic commerce;though; bestows a more complex setting on the trade by adding a new dimension to theindividual-merchant frame. The parties involved in a purchase are no longer autonomousentities; but are members of an organization whose rules of doing business they have toobey. We propose a flexible approach towards regulating agent involvement in inter-enterprise electronic commerce. The method is based on the concept of law-governedinteraction (LGI) which makes a strict separation between a declarative; formal statement ofa policy and its enforcement.,Electronic Commerce and Web-based Applications/Middleware; 1999. Proceedings. 19th IEEE International Conference on Distributed Computing Systems Workshops on,1999,4
Handling constantly changing metadata,A Gal,*,IEEE Computer Society metadata conference,1997,4
Model matching-processes and beyond,Avigdor Gal; Matthias Weidlich,Abstract. Conceptual models in general; and process models in particular; have beenestablished as a means to design; analyze; and improve information systems [1]. Thecreation; utilization; and evolution of such models is supported by manifold concepts andtechniques that offer; for instance; re-use driven modelling support; harmonization of modelvariants; model-based system validation; and effective management of model repositories.Many of these techniques share reliance on the identification of correspondences betweenthe entities of different models; also termed model matching. The accuracy and thereforeusefulness of techniques supporting the creation; utilization; and evolution of models ishighly dependent on the correctness and completeness of the result of model matching. Thistutorial takes up recent advances in matching process models in particular and provides …,Proceedings of the 27th International Conference on Advanced Information Systems Engineering (CAiSE’15),2015,3
Measuring expected integration effort in service composition,Tomer Sagi; Avigdor Gal; Matthias Weidlich,Evaluating alternative solutions for service compositions is done by various properties; eachrequiring an associated evaluation measure. In this paper; we propose a new measure;namely integration effort; to capture the expected effort a human programmer is expected toinvest in integrating composed services into a functioning process. We present severalintegration effort evaluation measures; which were adapted from the related research areasof schema and ontology matching. These measures are embedded in an extendibleframework; allowing application in different levels of refinement. Our measures areempirically validated to be effective proxies of integration effort.,Services Computing (SCC); 2014 IEEE International Conference on,2014,3
On trade-offs in event delivery systems,Haggai Roitman; Avigdor Gal; Louiqa Raschid,Abstract Architectures and middleware for event delivery face scalability challenges inproviding up-to-date events to meet clients' specifications. The use of proxy middleware is acommon practice for increasing scalability. Proxies can aggregate client specifications;taking advantage of similar needs to reduce communication overhead; workload on eventsources (eg; sensors) and network traffic. However; in a setting with thousands of clients;event sources; and constrained resources; proxies cannot always satisfy all client needs. Aproxy is interested in maximizing completeness by capturing as many events as possible.However; due to constraints on resources; event delivery may not be fully current; resultingin a delay in delivering events. In many cases; these two dimensions cannot be directlyrelated and we propose a flexible design framework that can suit different changing …,Proceedings of the Fourth ACM International Conference on Distributed Event-Based Systems,2010,3
Generating and optimizing graphical user interfaces for semantic service compositions,Eran Toch; Iris Reinhartz-Berger; Avigdor Gal; Dov Dori,Abstract Semantic Web service composition is a discovery process in which a given set ofrequirements are fulfilled by dynamically locating and assembling semantically annotatedservices [5; 6]. Semantic annotation of Web services is a set of models that describe itsproperties (eg; inputs; outputs; process); in a formal language such as OWL-S [2]. Thesemodels provide an unambiguous description of service properties by relating them toconcepts belonging to Web ontologies. While dynamic service composition provides aflexible applications which can change according to service failures and other factors; itraises several questions regarding the way users interact with the generated applications.Specifically; it raises a challenge for usability; which is defined as the effectiveness;efficiency and satisfaction in which users perform tasks using a given system [1].,International Conference on Conceptual Modeling,2008,3
Putting things in context: Dynamic eGovernment re-engineering using ontologies and context,Avigdor Gal; Aviv Segev,ABSTRACT The proliferation of the Internet allows citizens to communicate with publicadministration using various channels. The diversity of tools allows citizens to become moreinvolved in the daily decision making of public administration; especially when it comes tolocal governments. However; these new methods of communication require efficienttechniques for handling an ever growing flow of information to civil servants. This positionpaper promotes a technical solution to allow efficient communication between citizens andcivil servants; allowing a civil servant a flexible mechanism to automatically sort out anyincoming data; analyzing it on-the-fly; directing it to the person who may find it most usable;and using it in evaluating services offered by the government. Such a solution paves the wayfor interoperability; while at the same time supporting re-engineering using local …,Proceedings of the 2006 WWW Workshop on E-Government: Barriers and Opportunities,2006,3
Agent oriented data integration,Avigdor Gal; Aviv Segev; Christos Tatsiopoulos; Kostas Sidiropoulos; Pantelis Georgiades,Abstract Data integration is the process by which data from heterogeneous data sources areconceptually integrated into a single cohesive data set. In recent years agents have beenincreasingly used in information systems to promote performance. In this work we propose amodeling framework for agent oriented data integration to demonstrate how agents cansupport this process. We provide a systematic analysis of the process using real worldscenarios; taken from email messages from citizens in a local government; and demonstratetwo agent oriented data integration tasks; email routing and opinion analysis.,International Conference on Conceptual Modeling,2005,3
Handling Uncertain Rules in Composite Event Systems.,Segev Wasserkrug; Avigdor Gal; Opher Etzion,Abstract In recent years; there has been an increased need for active systems-systems thatare required to act automatically based on events; or changes in the environment. In manycases; the events to which the system should respond to; have to be inferred from otherevents based on complex temporal predicates. However; none of the existing compositeevent systems created to enable such inference can deal with cases in which an eventcannot be inferred with absolute certainty based on the reported events. Therefore; in thispaper; we describe how a deterministic event composition system can be extended tomanage such uncertainty; and specify the principles of a formal framework for suchinference. The contribution of this framework is twofold: It extends the semantics of eventcomposition in a natural manner for probabilistic settings; and it enables the application of …,FLAIRS Conference,2005,3
Wide area performance monitoring using aggregate latency profiles,Vladimir Zadorozhny; Avigdor Gal; Louiqa Raschid; Qiang Ye,Abstract A challenge in supporting Wide Area Applications (WAA) is that of scalableperformance management. Individual Latency Profiles (iLPs) were proposed in the literatureto capture latency distributions experienced by clients when connecting to a server; it is apassive measurement made by client applications and is gathered on a continuous basis. Inthis paper; we propose a scalable technique for managing iLPs by aggregating them intoaggregate Latency Profiles (aLPs). We use measures such as mutual information andcorrelation to compare the similarity of pairs of iLPs.,International Conference on Web Engineering,2004,3
Combining simultaneous values and temporal data dependencies,Avigdor Gal; Dov Dori,In temporal databases there are situations where multiple values of the same data item haveoverlapping validity times. In addition to the common case of multi-valued properties; thereare several possible semantics to multiple values with overlapping validity times of the samedata item. We refer to such data items as having simultaneous values. This paper presents apolynomial algorithm for efficient handling of simultaneous values in a database withtemporal data dependencies-integrity rules that define relationships among values ofdifferent dated items in a temporal database. The algorithm is demonstrated using a casestudy from the game theory area. An implementation of the algorithm is integrated in aprototype of a temporal active database.,Temporal Representation and Reasoning; 1996.(TIME'96); Proceedings.; Third International Workshop on,1996,3
Handling change management using temporal active repositories,Avigdor Gal; Opher Etzion,Abstract Business Re-engineering requires frequent changes in the enterprises' informationsystems; however the current technology of data dictionaries is not effective for the tracing ofrequired changes and their management. In this paper we introduce an architecture ofchange management using active temporal repositories. Flexible change managementallows the support of information about past or future versions of information systems; aswell as the capability to retrieve and update temporal information. The implementation ofchange management in a temporal environment is carried out by the partition of thetemporal universe among temporal agents; each of them handles a single version of anapplication with a required collaboration among them. The change management process;and the inter and intra agent processing are described in this paper.,International Conference on Conceptual Modeling,1995,3
A temporal active database model,Opher Etzion; Avigdor Gal; Arie Segev,*,*,1992,3
Instance-based process matching using event-log information,Han van der Aa; Avigdor Gal; Henrik Leopold; Hajo A Reijers; Tomer Sagi; Roee Shraga,Abstract Process model matching provides the basis for many process analysis techniquessuch as inconsistency detection and process querying. The matching task refers to theautomatic identification of correspondences between activities in two process models.Numerous techniques have been developed for this purpose; all share a focus on process-level information. In this paper we introduce instance-based process matching; whichspecifically focuses on information related to instances of a process. In particular; weintroduce six similarity metrics that each use a different type of instance information stored inthe event logs associated with processes. The proposed metrics can be used as standalonematching techniques or to complement existing process model matching techniques. Aquantitative evaluation on real-world data demonstrates that the use of information from …,International Conference on Advanced Information Systems Engineering,2017,2
Equi-reward utility maximizing design in stochastic environments,Sarah Keren; Luis Pineda; Avigdor Gal; Erez Karpas; Shlomo Zilberstein,Abstract We present the Equi-Reward Utility Maximizing Design (ERUMD) problem forredesigning stochastic environments to maximize agent performance. ER-UMD fits wellcontemporary applications that require offline design of environments where robots andhumans act and cooperate. To find an optimal modification sequence we present two novelsolution techniques: a compilation that embeds design into a planning problem; allowinguse of off-the-shelf solvers to find a solution; and a heuristic search in the modificationsspace; for which we present an admissible heuristic. Evaluation shows the feasibility of theapproach using standard benchmarks from the probabilistic planning competition and abenchmark we created for a vacuum cleaning robot setting.,HSDIP 2017,2017,2
Multi-source uncertain entity resolution at yad vashem: Transforming holocaust victim reports into people,Tomer Sagi; Avigdor Gal; Omer Barkol; Ruth Bergman; Alexander Avram,Abstract In this work we describe an entity resolution project performed at Yad Vashem; thecentral repository of Holocaust-era information. The Yad Vashem dataset is unique withrespect to classic entity resolution; by virtue of being both massively multi-source and byrequiring multi-level entity resolution. With today's abundance of information sources; thisproject sets an example for multi-source resolution on a big-data scale. We discuss a set ofrequirements that led us to choose the MFIBlocks entity resolution algorithm in achieving thegoals of the application. We also provide a machine learning approach; based upondecision trees to transform soft clusters into ranked clustering of records; representingpossible entities. An extensive empirical evaluation demonstrates the unique properties ofthis dataset; highlighting the shortcomings of current methods and proposing avenues for …,Proceedings of the 2016 International Conference on Management of Data,2016,2
A cooperative model for preference-based information sharing in narrow bandwidth networks,Rami Rashkovits; Avigdor Gal,Users of wide area network applications are usually concerned about both response timeand content validity. The common solution of client-side caching that reuses cached contentbased on arbitrary time-to-live may not be applicable in narrow bandwidth environment;where heavy load is imposed on sparse transmission abilities. In such cases; some usersmay wait for a long time for fresh content extracted from the origin server although theywould settle for obsolescent content; while other users may receive the cached copy whichis considered valid; although they would be ready to wait longer for fresher content. In thiswork; a new model for caching is introduced; where clients introduce preferences regardingtheir expectations for the time they are willing to wait; and the level of obsolescence they arewilling to tolerate. The cache manager considers user preferences; and is capable of …,International Journal of Cooperative Information Systems,2013,2
Efficient uncertainty management in complex event systems: saving the witch from Henzel & Gretel,Segev Wasserkrug; Avigdor Gal; Yulia Turchin; Opher Etzion,Abstract There is a growing need for the use of active systems; systems that actautomatically based on events. Applications include business applications; eg; BusinessProcess Management (BPM); engineering applications; eg; forecasting networked resourcesavailability; and scientific applications; eg; utilization of grid resources. Event CompositionSystems (eg;[1; 2; 6]) have been proposed as a tool to analyze data and detect situationsthat require a response. These are general purpose systems intended for inferring (usingrules); in real time; the occurrence of events; based on the occurrence of other events. Thedeclarative nature of rules; combined with an optimized inference mechanism; allows thesesystems to respond quickly to new and evolving situations by changing a set of rules ratherthan by making changes in code.,Proceedings of the second international conference on Distributed event-based systems,2008,2
Puzzling It Out: Supporting Ontology Evolution with Applications to eGovernment,Aviv Segev; Avigdor Gal,Abstract In recent years; the use of ontologies in information systems has dramaticallyincreased. Ontology design and maintenance; nonetheless; have been and still aredaunting tasks. We argue that ontologies need to evolve; or else the semantic infrastructureof the information system will no longer support the organization's changing needs.Therefore; in this work we aim at tackling the problem of ontology evolution. We propose touse (machinegenerated) contexts as a mechanism for quantifying relationships amongconcepts. To do so we compare contexts that are associated with ontology concepts. Ourapproach is unique in two aspects. First; we base it on a combination of ontologies andcontexts; where contexts replace; to a certain extent; the role of the ontology engineer in theprocess. Second; we provide the ontology administrator with an explicit numeric …,Proceedings of IJCAI-Workshop on Workshop on Modeling and Representation in Computational Semantics,2007,2
Using non-random associations for predicting latency in WANs,Vladimir Zadorozhny; Louiqa Raschid; Avigdor Gal; Qiang Ye; Hyma Murthy,Abstract In this paper; we propose a scalable performance management tool for Wide AreaApplications. Our objective is to scalably identify non-random associations between pairs ofindividual Latency Profiles (iLPs)(ie; latency distributions experienced by clients whenconnecting to a server) and exploit them in latency prediction. Our approach utilizesRelevance Networks (RNs) to manage tens of thousands of iLPs. Non-random associationsbetween iLPs can be identified by topology-independent measures such as correlation andmutual information. We demonstrate that these non-random associations do indeed have asignificant impact in improving the error of latency prediction.,International Conference on Web Information Systems Engineering,2005,2
A cooperative model for wide area content delivery applications,Rami Rashkovits; Avigdor Gal,Abstract Content delivery is a major task in wide area environments; such as the Web.Latency; the time elapses since the user sends the request until the server's response isaccepted is a major concern in many applications. Therefore; minimizing latency is anobvious target of wide area environments and one of the more common solutions in practiceis the use of client-side caching. Collaborative caching is used to further enhance contentdelivery; but unfortunately; it often fails to provide significant improvements. In this work; weexplore the limitations of collaborative caching; analyze the existing literature and suggest acooperative model for which cache content sharing show more promise. We propose anovel approach; based on the observation that clients can specify their tolerance towardscontent obsolescence using a simple-to-use method; and servers can supply content …,OTM Confederated International Conferences" On the Move to Meaningful Internet Systems",2005,2
Multi-agent negotiation and price discrimination for information goods,Gabi Koifman; Onn Shehory; Avigdor Gal,We have developed a mechanism that supports trading database tuples in a multi-agentsystem. The mechanism enables negotiation and evaluation of database-based informationgoods. We propose various policies for dynamic pricing of information goods. We havedeveloped a test-bed that simulates a multi-agent system where each agent uses the offeredmechanism and have evaluated the system performance when sellers use different pricingpolicies in two market environments; namely competitive and non-competitive. Theinvestigated pricing policies include two novel pricing policies that implement negotiationand price discrimination across consumers. These are compared to two policies known inthe art; which implement dynamic posted pricing. We have empirically demonstrated thesuperiority of the offered policies in maximizing sellers' gains. We have additionally …,Systems; Man and Cybernetics; 2004 IEEE International Conference on,2004,2
An authorization system for temporal data,Avigdor Gal; Vijayalakshmi Atluri; Gang Xu,We present a system; called the Temporal Data Authorization Model (TDAM); for managingauthorizations for temporal data. TDAM is capable of expressing access control policiesbased on the temporal characteristics of data. TDAM extends existing authorization modelsto allow the specifications of temporal constraints on data; based on data validity; datacapture time; and replication time; using either absolute or relative time references. Theability to specify access control based on such temporal aspects were not supported before.The formulae are evaluated with respect to various temporal assignments to ensure thecorrectness of access control.,Data Engineering; 2002. Proceedings. 18th International Conference on,2002,2
Modeling Cooperation Among Information Systems Using Control Elements.,Avigdor Gal,Abstract Next generation information systems will be cooperative in nature; with datadependencies and interoperability relationships. In this paper we report on the use of activedatabase technology in the design of control elements which are particularly well suited forhandling unreliable network technologies and autonomous decisions of availability ofinformation systems. A control element is combined of a set of rules and an executable datastructure that consists of operations for cooperating among information systems.Manipulating control elements by using local transformations increases the exibility ofinformation systems by allowing multiple paths for receiving data and activating consistencymaintenance operations. We provide the substitute method as an example of manipulatingcontrol elements; aimed at minimizing the interaction of an information system with other …,NGITS,1997,2
CODES| a design tool for computerized systems,Avigdor Gal; Opher Etzion,Abstract In this paper we present a design tool for complex computerized systems; that isbased on the experience gained in the active database research area. CODES; a COntroland Data Engineering of Systems; extends the capabilities of contemporary design tools byenabling a top-down design and reasoning facilities. The model combines the notions ofhierarchy; concurrency and communication; and enables the representation of data ow aswell as control ow. These properties form a highly structured and accurate speci cationlanguage. The model is given using a formal and a graphical presentation.,Proc. NGITS,1995,2
Tapuz: The design of a second generation active database,Opher Etzion; Avigdor Gal,Abstract The rst generation of active database systems attracted interest in both theacademic and the industrial communities. However the paradigm it is based upon su ersfrom some intrinsic problems; such as: non deterministic execution and possible redundantoperations. This paper reports on these problems and on the design of TAPUZ; a secondgeneration active database system that is aimed at reducing these problems; yet maintainsthe same goals and functionalities of the rst generation. The main features of this model are:the use of high-level invariant language; yet enable the use of auxiliary proceduralprogramming when required. A dependency-graph based control model is used to provide adeterministic and well-de ned semantics for the execution process. 1 introduction andmotivation,*,1993,2
The internet-of-things meets business process management: mutual benefits and challenges,Christian Janiesch; Agnes Koschmider; Massimo Mecella; Barbara Weber; Andrea Burattin; Claudio Di Ciccio; Avigdor Gal; Udo Kannengiesser; Felix Mannhardt; Jan Mendling; Andreas Oberweis; Manfred Reichert; Stefanie Rinderle-Ma; WenZhan Song; Jianwen Su; Victoria Torres; Matthias Weidlich; Mathias Weske; Liang Zhang,Abstract: The Internet of Things (IoT) refers to a network of connected devices collecting andexchanging data over the Internet. These things can be artificial or natural; and interact asautonomous agents forming a complex system. In turn; Business Process Management(BPM) was established to analyze; discover; design; implement; execute; monitor andevolve collaborative business processes within and across organizations. While the IoT andBPM have been regarded as separate topics in research and practice; we strongly believethat the management of IoT applications will strongly benefit from BPM concepts; methodsand technologies on the one hand; on the other one; the IoT poses challenges that willrequire enhancements and extensions of the current state-of-the-art in the BPM field. In thispaper; we question to what extent these two paradigms can be combined and we discuss …,arXiv preprint arXiv:1709.03628,2017,1
Multi-source uncertain entity resolution: Transforming holocaust victim reports into people,Tomer Sagi; Avigdor Gal; Omer Barkol; Ruth Bergman; Alexander Avram,Abstract In this work we present a multi-source uncertain entity resolution model and showits implementation in a use case of Yad Vashem; the central repository of Holocaust-erainformation. The Yad Vashem dataset is unique with respect to classic entity resolution; byvirtue of being both massively multi-source and by requiring multi-level entity resolution.With today's abundance of information sources; this project motivates the use of multi-sourceresolution on a big-data scale. We instantiate the proposed model using the MFIBlocks entityresolution algorithm and a machine learning approach; based upon decision trees totransform soft clusters into ranked clustering of records; representing possible entities. Anextensive empirical evaluation demonstrates the unique properties of this dataset that makeit a good candidate for multi-source entity resolution. We conclude with proposing …,Information Systems,2017,1
Redesigning Stochastic Environments for Maximized Utility.,Sarah Keren; Avigdor Gal; Erez Karpas; Luis Enrique Pineda; Shlomo Zilberstein,Abstract We present the Utility Maximizing Design (UMD) model for optimally redesigningstochastic environments to achieve maximized performance. This model suits wellcontemporary applications that involve the design of environments where robots andhumans co-exist an co-operate; eg; vacuum cleaning robot. We discuss two special cases ofthe UMD model. The first is the equi-reward UMD (ER-UMD) in which the agents and thesystem share a utility function; such as for the vacuum cleaning robot. The second is the goalrecognition design (GRD) setting; discussed in the literature; in which system and agentutilities are independent. To find the set of optimal modifications to apply to a UMD model;we present a generic method; based on heuristic search. After specifying the conditions foroptimality in the general case; we present an admissible heuristic for the ER-UMD case …,AAAI,2017,1
Feature learning for accurate time prediction in congested healthcare systems,Arik Senderovich; Matthias Weidlich; Avigdor Gal,ABSTRACT Time prediction in healthcare systems such as outpatient clinics; hospital wards;and emergency departments is an essential component of decision making. Predictions areused for effective and efficient resource allocation; optimised ambulance routing; andaccurate delay announcement. In this work; we focus on time prediction in congestedhealthcare systems; where patients share scarce resources such as nurses; physicians; andMRI machines. To achieve accurate time prediction in this setting; features describing theclinical state of the patient (eg; severity of condition; age; and medical history) need to becombined with features that capture cross-patient information. To include the interplay ofpatients in time prediction; we present a method to learn congestion-related features; suchas the current number of patients in the hospital and recent lengths-of-stay. To this end …,*,2017,1
In log and model we trust?,Andreas Rogge-Solti; Arik Senderovich; Matthias Weidlich; Jan Mendling; Avigdor Gal,Abstract: While models and event logs are readily available in modern organizations; theirquality can seldom be trusted. Raw event recordings are often noisy; incomplete; andcontain erroneous recordings. The quality of process models; both conceptual and data-driven; heavily depends on the inputs and parameters that shape these models; such asdomain expertise of the modelers and the quality of execution data. The mentioned qualityissues are specifically a challenge for conformance checking. Conformance checking is theprocess mining task that aims at coping with low model or log quality by comparing themodel against the corresponding log; or vice versa. The prevalent assumption in theliterature is that at least one of the two can be fully trusted. In this work; we propose ageneralized conformance checking framework that caters for the common case; when …,EMISA,2016,1
On predicting traveling times in scheduled transportation,Avigdor Gal; Avishai Mandelbaum; Francois Schnitzler; Arik Senderovich; Matthias Weidlich,Note: OCR errors may be found in this Reference List extracted from the full text article. ACMhas opted to expose the complete List rather than only correct and linked references …Chien; Steven I-Jy; Ding; Yuqing; and Wei; Chienhung. Dynamic bus arrival time prediction withartificial neural networks. Journal of Transportation Engineering; 128 (5):429-438; 2002 … Thispaper presents an overview of the second International Workshop on Mining Urban Data(MUD2). The MUD2 workshop was held in conjunction with the 32nd International Conferenceon Machine Learning (ICML 2015) in Lille; France; July 11; 2015 … This paper presents anoverview of the second International Workshop on Mining Urban Data (MUD2). The MUD2 workshopwas held in conjunction with the 32nd International Conference on Machine Learning (ICML2015) in Lille; France; July 11; 2015 … There is a significant effort towards moving …,Proceedings of the 2nd International Conference on Mining Urban Data-Volume 1392,2015,1
Measuring expected integration effort in web service composition,Tomer Sagi; Matthias Weidlich; Avigdor Gal,Abstract. Web services support information systems engineering by flexible composition ofready-made software components to enact business processes. A plethora of automatic andsemi-automatic composition methods have been suggested. Due to duplication and overlapbetween services; there exists a search space of possible compositions. Evaluatingalternative composition solutions is done by various properties; each requiring anassociated evaluation measure. In this paper; we propose a new property; namelyintegration effort; which captures the expected effort by a human programmer to integratecomposed services into a functioning process. We present a series of effort evaluationmeasures by adapting the well-known precision and recall functions from related fields ofschema and ontology matching. We present an extendable framework; allowing …,Technion–Israel Institute of Technology; Tech. Rep. IE/IS-2013-05,2013,1
Data-Parallel Computing Meets STRIPS.,Erez Karpas; Tomer Sagi; Carmel Domshlak; Avigdor Gal; Avi Mendelson; Moshe Tennenholtz,Abstract The increased demand for distributed computations on big data has led to solutionssuch as SCOPE; DryadLINQ; Pig; and Hive; which allow the user to specify queries in anSQL-like language; enriched with sets of user-defined operators. The lack of exactsemantics for user-defined operators interferes with the query optimization process; thusputting the burden of suggesting; at least partial; query plans on the user. In an attempt toease this burden; we propose a formal model that allows for data-parallel program synthesis(DPPS) in a semantically well-defined manner. We show that this model generalizes existingframeworks for dataparallel computation; while providing the flexibility of query plangeneration that is currently absent from these frameworks. In particular; we show howexisting; offthe-shelf; AI planning tools can be used for solving DPPS tasks.,AAAI,2013,1
Answering queries with acyclic lineage expressions over probabilistic databases,Batya Kenig; Avigdor Gal; Ofer Strichman,ABSTRACT This work extends the class of lineage expressions of queries over tupleindependent probabilistic databases for which evaluation can be performed in PTIME. Wedefine a new characterization of lineage expressions; called γ-acyclic; and present a methodto compute the probability of such expressions in PTIME. The method is based on thejunction tree message passing algorithm and applies both to conjunctive queries without selfjoins and; under certain constraints; also to union of such queries.,*,2012,1
Content-based validation of business process models,Maya Lincoln; Avigdor Gal,Abstract. In this work we present a methodology for content-based validation of businessprocess models; focusing on existing organizational policies. This methodology goesbeyond structural notation and proposes to automatically extract business logic from processrepositories as a basis for content validation. Each process activity is encoded automaticallyas a descriptor; containing objects; actions; and qualifiers. The collection of all processdescriptors formulates a taxonomy model of action sequence; object lifecycle and object andaction hierarchies that are used to support the validation procedure. We propose a stepwisemethod for context-based validation that includes deficiency identification (using existingdescriptors as a reference); validation score calculation and generation of a ranked list ofcorrections. We illustrate our approach using three types of validation errors that may …,*,2011,1
Panel: Current State and Future of,Annika Hinze; Jean Bacon; Alejandro Buchmann; Sharma Chakravarthy; Mani Chandi; Avigdor Gal; Dieter Gawlick; Richard Tibbetts,This chapter is a panel discussion in writing. The field of event-based systems findsresearchers from a number of different backgrounds: distributed systems; streaming data;databases; middleware; and sensor networks. One of the consequences is that everyonecomes to the field with a slightly different mindset and different expectations and goals. Inthis chapter; we try to capture some of the voices that are influential in our field. Sevenpanellists from academia and industry were invited to answer and discuss questions aboutevent-based systems. The questions were distributed via email; to which each participantreplied their initial set of answers. In a second round every panelist was given theopportunity to expand their statement and discuss the contributions of the other panellists.The questions asked can be grouped into two types. Questions in the first group refer to …,Principles and Applications of Distributed Event-Based Systems,2010,1
The Health Problems of Data Integration,Avigdor Gal,Abstract Data integration is the process of combining data residing at different data sourcesto generate a unified data view of these data. Schema matching generates correspondencesbetween concepts describing the meaning of data in various heterogeneous; distributeddata sources. Therefore; schema matching is recognized to be one of the basic operationsrequired by the process of data integration and thus has a great impact on its outcome andon numerous modern applications.,OTM Confederated International Conferences" On the Move to Meaningful Internet Systems",2008,1
On the challenges in event delivery,Haggai Roitman; Avigdor Gal; Louiqa Raschid,Complex Event Processing systems are dependent upon the collection of events fromdistributed systems. Without a dependent mechanism for event delivery; the inferencing ofcomplex events is hampered and the reliability of the system quickly deteriorates.Determining the right method for collecting events may have a significant impact on systemperformance and resource utilization and therefore the design of event delivery mechanismshould be done with care. As an example; consider the growing use of RSS feeds. A clientcan customize the rate of monitoring RSS feeds. The RSS 2.0 specification ([3]) also allowsservers to specify some server capabilities; such as Time-To-Live (TTL)(specified by the< ttl>XML tag); indicating when an RSS feed is expected to be refreshed by the server. The RSS2.0 specification also allows servers to use XML tags such as< skipHours> that provides …,Fast abstract; Int. Conf. on Distributed Event-Based Systems (DEBS’08),2008,1
Modeling alternatives in exception executions,Mati Golani; Avigdor Gal; Eran Toch,Abstract To date; the ability of a business process designer to produce a solid; well-validatedworkflow models is limited; especially since all necessary scenarios that need to be coveredby the workflow are hard to predict. Workflow management systems (WfMSs); serving as themain vehicle of business process execution; should recognize those limits; and increase itssupport to designers in this task. One aspect of such assistance is in exception handlersgeneration. In this paper we propose a model language enrichment for expressing workflowsemantics; in the context of alternative solutions; within the process model. Thus; enablingthe designer to state which possible alternatives and their applicability to changingexecution paths states. Using this enrichment; an inference algorithm can efficiently find anadequate alternative. The model language is used as a basis for a design tool and an …,International Conference on Business Process Management,2007,1
Second order snapshot-log relations: supporting multi-directional database replication using asynchronous snapshot replication,Yochai Ben-Chaim; Avigdor Gal,Abstract Multi-directional asynchronous replication is a desired mechanism which allowsupdates to be performed locally at any site; and later propagated asynchronously to othersites. This paper proposes using second order snapshot-log relations as a mechanism forextending the use of single-directional asynchronous replication to multi-directional. Theproposed mechanism is fully based on DBMS core tools and existing DBMS snapshotreplication support; thus allowing a natural extension for systems that already supportasynchronous snapshot replication. We have implemented and tested the proposed mecha-nism; showing results and terms of correctness.,International Workshop on Next Generation Information Technologies and Systems,2006,1
Framework and algorithms for web resource monitoring and data delivery,Haggai Roitman; Avigdor Gal; Louiqa Raschid,ABSTRACT Web enabled application servers and the clients for their Web services haveincreased in both the sophistication of server capabilities as well as in the demand for clientcustomization. Therefore; there is a necessity of a specification language for sophisticatedclient needs and a framework for resource monitoring and data delivery that goes beyondexisting standards. In this work we propose ProMo; a framework for Web resourcemonitoring. Using an expressive specification language a client can specify a profile; a set ofdata delivery needs; using notification rules. Such rules are also utilized to specify servercapabilities. ProMo supports an abstract model where the semantics of a notification rulecan be exploited to reason about a timeline of events occurring at the server; and determinean appropriate schedule to both pull data from servers and to push notifications to clients …,*,2006,1
Unspecified Ontologies for eGovernment Web Services Composition and Orchestration,Shlomo Berkovsky; Yaniv Eytani; Avigdor Gal,Abstract Ontologies and Web services are the emerging technologies for serviceinteroperability in eGovernment applications. This work proposes to adapt the notion of“UNSpecified Ontology”(UNSO) to the realm of eGovernment Web services. UNSO allowsdifferent users to specify their own personal ontologies; thus eliminating the need for an all-inclusive shared ontology and enhance the users' privacy. In the context of eGoverment Webservices; it allows users to describe their need in a relatively free form manner and supportssmart semantic matching capabilities which simplify use by inexperienced users. In addition;we propose to use these capabilities for the purpose of composition and orchestration ofeGoverment Web services to enable specific behaviors tailored to user needs.,Proceedings of the International Workshop on Semantics and Orchestration of eGovernment Processes,2005,1
A clinical problem-oriented decision support model based on extended temporal database functionalities,Yaron Denekamp; Avigdor Gal,Abstract Several diagnostic decision support systems have been proposed. Yet; suchsystems are not commonly used partly due to insufficient temporal reasoning. We havedeveloped a clinical problem-oriented diagnostic decision support model that employstemporal reasoning by using extended temporal database functionalities developed at ourlab. In addition; our model supports the workflow of the diagnostic process and employsdetailed clinical data. We developed a prototype system that implements the concepts of themodel.,AMIA Annual Symposium Proceedings,2005,1
Evaluating Matching Algorithms: the Monotonicity Principle,Avigdor Gal,Traditionally; semantic reconciliation was performed by a human observer (a designer or aDBA)[8] due to its complexity [3]. However; manual reconciliation (with or without computer-aided tools) tends to be slow and inefficient in dynamic environments and does not scale forobvious reasons. Therefore; the introduction of the semantic Web vision and the shifttowards machine understandable Web resources has unearthed the importance ofautomatic semantic reconciliation. Consequently; new tools for automating the process; suchas GLUE [4]; and OntoBuilder [11]; were introduced. Generally speaking; the process ofsemantic reconciliation is performed in two steps. First; given two attribute sets A and A(denoted schemata) with n1 and n2 attributes; respectively; 1 a degree of similarity iscomputed automatically for all attribute pairs (one attribute from each schema); 2 using …,Semantic Integration Workshop (SI-2003),2003,1
Inference and Prediction of Uncertain Events in Active Systems: A Language and Execution Model.,Segev Wasserkrug; Opher Etzion; Avigdor Gal,Abstract This paper presents initial research into a framework (specification and executionmodel) for inference; prediction; and decision making with uncertain events in activesystems. This work is motivated by the observation that in many cases; there is a gapbetween the reported events that are used as a direct input to an active system; and theactual events upon which an active system must act. This paper motivates the work; surveysother efforts in this area; and presents preliminary ideas for both specification and executionmodel.,VLDB PhD Workshop,2003,1
New Perspectives in Temporal Databases,Avigdor Gal; Opher Etzion,Abstract The research of temporal databases has focused mainly on query languages thatincorporate time into conventional query languages and on structural aspects of thetemporal representation. Yet; the combination of time and databases has a potential to bemore powerful than the current capabilities it supports. In this paper we show the powergained by three extensions to temporal database modeling: the support of simultaneousvalues; a uni ed approach to past and future and the enrichment of an update model fortemporal databases.,*,1995,1
September 7; 1995,Avigdor Gal; Opher Etzion,*,*,1995,1
From diversity-based prediction to better schema matching,Avigdor Gal; Haggai Roitman; Tomer Sagi,ABSTRACT Schema matching predictors assess the quality of schema matchers in theabsence of an exact match. We propose MCD (Match Competitor Deviation); a new diversity-based predictor that compares the strength of a matcher confidence in an attribute paircorrespondence with respect to other correspondences that involve either attribute. We alsopropose to use MCD as a regulator to optimally control a balance between Precision andRecall and use it towards 1: 1 match (combining it with a similarity measure that is based onsolving a maximum weight bipartite graph matching (MWBM)) and 1: n match (combining itwith a matcher called Max-Delta). While optimizing the latter combination is straightforward;optimizing the former combined measure is known to be an NP-Hard problem. Therefore; wepropose an approximation to an optimal match by efficiently scanning multiple possible …,*,*,1
Semantic Interoperability in Information Services: Experiences with CoopWARE,Avigdor Gal,*,ACM SIGMOD Record,*,1
Non-binary evaluation measures for big data integration,Tomer Sagi; Avigdor Gal,Abstract The evolution of data accumulation; management; analytics; and visualization hasled to the coining of the term big data; which challenges the task of data integration. Thistask; common to any matching problem in computer science involves generating alignmentsbetween structured data in an automated fashion. Historically; set-based measures; basedupon binary similarity matrices (match/non-match); have dominated evaluation practices ofmatching tasks. However; in the presence of big data; such measures no longer suffice. Inthis work; we propose evaluation methods for non-binary matrices as well. Non-binaryevaluation is formally defined together with several new; non-binary measures using avector space representation of matching outcome. We provide empirical analyses of theusefulness of non-binary evaluation and show its superiority over its binary counterparts …,The VLDB Journal,2018,*
Temporal Network Representation of Event Logs for Improved Performance Modelling in Business Processes,Arik Senderovich; Matthias Weidlich; Avigdor Gal,Abstract Analysing performance of business processes is an important vehicle to improvetheir operation. Specifically; an accurate assessment of sojourn times and remaining timesenables bottleneck analysis and resource planning. Recently; methods to create respectiveperformance models from event logs have been proposed. These works are severelylimited; though: They either consider control-flow and performance information separately; orrely on an ad-hoc selection of temporal relations between events. In this paper; we introducethe Temporal Network Representation (TNR) of a log; based on Allen's interval algebra; as acomplete temporal representation of a log; which enables simultaneous discovery of control-flow and performance information. We demonstrate the usefulness of the TNR for detecting(unrecorded) delays and for probabilistic mining of variants when modelling the …,International Conference on Business Process Management,2017,*
FlinkMan: Anomaly Detection in Manufacturing Equipment with Apache Flink: Grand Challenge,Nicolo Rivetti; Yann Busnel; Avigdor Gal,Abstract We present a (soft) real-time event-based anomaly detection application formanufacturing equipment; built on top of the general purpose stream processing frameworkApache Flink. The anomaly detection involves multiple CPUs and/or memory intensivetasks; such as clustering on large time-based window and parsing input data in RDF-format.The main goal is to reduce end-to-end latencies; while handling high input throughput andstill provide exact results. Given a truly distributed setting; this challenge also entails carefultask and/or data parallelization and balancing. We propose FlinkMan; a system that offers ageneric and efficient solution; which maximizes the usage of available cores and balancesthe load among them. We illustrates the accuracy and efficiency of FlinkMan; over a 3-steppipelined data stream analysis; that includes clustering; modeling and querying.,Proceedings of the 11th ACM International Conference on Distributed and Event-based Systems,2017,*
REMI; Reusable Elements for Multi-Level Information Availability,Avigdor Gal; Nicolo Rivetti; Arik Senderovich; Dimitrios Gunopulos; Ioannis Katakis; Nikolaos Panagiotou; Vana Kalogeraki,Abstract Applications targeting Smart Cities tackle common challenges; however solutionsare seldom portable from one city to another due to the heterogeneity of city ecosystems. Amajor obstacle involves the differences in the levels of available information. In thisdemonstration we present REMI; a reusable elements framework to handle varying degreesof information availability by design from two complementary angles; namely gracefuldegradation (GRADE) and data enrichment (DARE). In a nutshell; we develop reusablemachine learning black boxes for mining and aggregating streaming data; either to infermissing data from available data; or to adapt expected accuracy based on data availability.We illustrate the proposed approach using tram data from the city of Warsaw.,Proceedings of the 11th ACM International Conference on Distributed and Event-based Systems,2017,*
Strong Stubborn Sets for Efficient Goal Recognition Design,Sarah Keren; Avigdor Gal; Erez Karpas,Abstract Goal recognition design (GRD) is the task of redesigning environments (eitherphysical or virtual) to allow efficient online goal recognition. In this work we formulate theredesign problem as an optimization problem; aiming at early goal recognition. To this end;we use a measure of worst case distinctiveness (wcd); which represents the maximalnumber of steps an agent may take before his goal is revealed. With the objective ofminimizing wcd; we construct a search space in which each node in the space is a goalrecognition model (one of which is the original model given as input) and one can movefrom one model to another by applying a model modification; chosen from a set of allowedmodifications given as input. Our specific contribution in this work involves the specificationof a class of modifications for which we can prune the search space using strong stubborn …,*,2017,*
Dagstuhl Reports; Vol. 6; Issue 8 ISSN 2192-5283,Martin Bossert; Eimear Byrne; Emina Soljanin; David Eyers; Avigdor Gal; Hans-Arno Jacobsen; Matthias Weidlich; Lejla Batina; Swarup Bhunia; Patrick Schaumont; Gene Myers; Mihai Pop; Knut Reinert; Tandy Warnow,Coding Theory in the Time of Big Data (Dagstuhl Seminar 16321) Martin Bossert; EimearByrne; and Emina Soljanin … Integrating Process-Oriented and Event-BasedSystems (Dagstuhl Seminar 16341) David Eyers; Avigdor Gal; Hans-Arno Jacobsen; and MatthiasWeidlich .......... 21 … Foundations of Secure Scaling (Dagstuhl Seminar 16342) LejlaBatina; Swarup Bhunia; and Patrick Schaumont ........................... 65 … Next Generation Sequencing– Algorithms; and Software For Biomedical Applications (Dagstuhl Seminar 16351) GeneMyers; Mihai Pop; Knut Reinert; and Tandy Warnow ...................... 91 … Published online andopen access by Schloss Dagstuhl – Leibniz-Zentrum für Informatik GmbH; DagstuhlPublishing; Saarbrücken/Wadern; Germany. Online available at http://www.dagstuhl.de/dagpub/2192-5283 … Bibliographic information published by the Deutsche Nationalbibliothek …,*,2017,*
Integrating Process-Oriented and Event-Based Systems (Dagstuhl Seminar 16341),David Eyers; Avigdor Gal; Hans-Arno Jacobsen; Matthias Weidlich,Abstract This report documents the programme and the outcomes of Dagstuhl Seminar16341 on" Integrating Process-Oriented and Event-Based Systems"; which took placeAugust 21--26; 2016; at Schloss Dagstuhl--Leibniz Center for Informatics. The seminarbrought together researchers and practitioners from the communities that have beenestablished for research on process-oriented information systems on the one hand; andevent-based systems on the other hand. By exploring the use of processes in event handling(from the distribution of event processing to the assessment of event data quality); the use ofevents in processes (from rich event semantics in processes to support for flexible BPM);and the role of events in process choreographies; the seminar identified the diverseconnections between the scientific fields. This report summarises the outcomes of the …,Dagstuhl Reports,2017,*
INSIGHT: Dynamic Traffic Management Using Heterogeneous Urban Data,Nikolaos Panagiotou; Nikolas Zygouras; Ioannis Katakis; Dimitrios Gunopulos; Nikos Zacheilas; Ioannis Boutsis; Vana Kalogeraki; Stephen Lynch; Brendan O’Brien; Dermot Kinane; Jakub Mareček; Jia Yuan Yu; Rudi Verago; Elizabeth Daly; Nico Piatkowski; Thomas Liebig; Christian Bockermann; Katharina Morik; Francois Schnitzler; Matthias Weidlich; Avigdor Gal; Shie Mannor; Hendrik Stange; Werner Halft; Gennady Andrienko,In this demo we present a traffic monitoring system that is currently deployed in Dublin and utilizedfor city event detection. The purpose of this demo is to show; that; using novel data mining techniqueswe are able to monitor diverse data coming from city-wide infrastructures and extract useful informationto present to the city operators. We collaborated with Dublin City Council (DCC) and designeda system that is able to process real-time data from diverse input sources such as sensors mountedon top of buses; traffic sensors embedded in street intersections or even citizen's tweets. INSIGHTidentifies events of interest such as traffic congestion; construction works and accidents [1] …Although sensor data are available to smart city authorities; it is very difficult for human operatorsto monitor the vast amount of information. Figureá1 shows the DCC control center; where oneof the screens displays INSIGHT 1 . Our system identifies events and aids operators to …,Joint European Conference on Machine Learning and Knowledge Discovery in Databases,2016,*
P3-Folder: Optimal Model Simplification for Improving Accuracy in Process Performance Prediction,Avigdor Gal; Avishai Mandelbaum,Abstract. Operational process models such as generalised stochastic Petri nets (GSPNs) areuseful when answering performance queries on business processes (eg 'how long will ittake for a case to finish?'). Recently; methods for process mining have been developed todiscover and enrich operational models based on a log of recorded executions ofprocesses; which enables evidence-based process analysis. To avoid a bias due toinfrequent execution paths; discovery algorithms strive for a balance between over-fittingand under-fitting regarding the originating log. However; state-of-the-art discoveryalgorithms address this balance solely for the control-flow dimension; neglecting possibleover-fitting in terms of performance annotations. In this work; we thus offer a technique forperformance-driven model reduction of GSPNs; using structural simplification rules. Each …,Business Process Management: 14th International Conference; BPM 2016; Rio de Janeiro; Brazil; September 18-22; 2016. Proceedings,2016,*
Exploiting the Hidden Structure of Junction Trees for MPE.,Batya Kenig; Avigdor Gal,Abstract The role of decomposition-trees (also known as junction and clique trees) inprobabilistic inference is widely known and has been the basis for many well knowninference algorithms. Recent approaches have demonstrated that such trees have a “hiddenstructure”; which enables the characterization of tractable problem instances as well as leadto insights that enable boosting the performance of inference algorithms. We consider theMPE problem on a Boolean formula in CNF where each literal in the formula is associatedwith a weight. We describe techniques for exploiting the junction-tree structure of theseformulas in the context of a branch-and-bound algorithm for MPE.,AAAI Workshop: Beyond NP,2016,*
SMART: A tool for analyzing and reconciling schema matching networks,Hung Nguyen Quoc Viet; Tam Nguyen Thanh; Vinh Chau; Tri Kurniawan Wijaya; Zoltan Miklos; Karl Aberer; Avigdor Gal; Matthias Weidlich,Abstract—Schema matching supports data integration by establishing correspondencesbetween the attributes of independently designed database schemas. In recent years;various tools for automatic pair-wise matching of schemas have been developed. Since thematching process is inherently uncertain; the correspondences generated by such tools areoften validated by a human expert. In this work; we consider scenarios in which attributecorrespondences are identified in a network of schemas and not only in a pairwise setting.Here; correspondences between different schemas are interrelated; so that incomplete anderroneous matching results propagate in the network and the validation of acorrespondence by an expert has ripple effects. To analyse and reconcile such matchings inschema networks; we present the Schema Matching Analyzer and Reconciliation Tool …,31st International Conference on Data Engineering,2015,*
Special issue,Alistair Barros; Avigdor Gal; Ekkart Kindler,Google; Inc. (search). SIGN IN SIGN UP. Special issue. Authors: Alistair Barros;Queensland University of Technology; Australia. Avigdor Gal; Technion - IsraelInstitute of Technology; Israel. Ekkart Kindler; Technical University of Denmark;Denmark. Published in: · Journal. Information Systems archive.,Information Systems,2015,*
Grand Challenge: Scalable Stateful Stream Processing for Smart Grids,Raul Castro Fernandez; Matthias Weidlich; Peter Pietzuch; Avigdor Gal,ABSTRACT We describe a solution to the ACM DEBS Grand Challenge 2014; whichevaluates event-based systems for smart grid analytics. Our solution follows the paradigm ofstateful data stream processing and is implemented on top of the SEEP stream processingplatform. It achieves high scalability by massive data-parallel processing and the option ofperforming semantic load-shedding. In addition; our solution is fault-tolerant; ensuring thatthe large processing state of stream operators is not lost after failure. Our experimentalresults show that our solution processes 1 month worth of data for 40 houses in 4 hours.When we scale out the system; the time reduces linearly to 30 minutes before the systembottlenecks at the data source. We then apply semantic load-shedding; maintaining a lowmedian prediction error and reducing the time further to 17 minutes. The system achieves …,Proceedings of the 8th International Conference on Distributed Event-Based Systems (DEBS’2014). Mumbai; India,2014,*
November 17; 2013,Avigdor Gal,My main area of research can be broadly categorized as that of Data Semantics. In my earlycareer I have focused on various aspects of data semantics in cooperative informationsystems; including transaction management in a Web environment [6] and schema matching(see below). Since 2008; I have investigated the interface between data; processes (thevehicles of generating and consuming data); and events (indicators of change); with anattempt to create a single theory that encapsulates all three aspects of information systems.For more than 12 years I have researched semantic issues in schema matching. A schemais a representation of data; developed either within a database or as part of an infrmationsystem. A schema represents the basic data elements an application uses. In the currentworld of big data; systems often need to exchange data and the first step in doing so …,*,2013,*
TechniBall: DEBS’2013 Grand Challenge,Avigdor Gal; Sarah Keren; Mor Sondak; Matthias Weidlich; Hendrik Blom; Christian Bockermann,ABSTRACT In this work we present the solution to the DEBS'2013 Grand Challenge; ascrafted by the joint effort of teams from the Technion and TU Dortmund. The paper describesthe architecture; details the queries and offers our observations regarding the appropriateway to trade-off high-level processing with time constraints.,*,2013,*
Data Driven and Temporal Rules in,Opher Etzion; Avigdor Gal; Arie Segev,Abstract Data driven rules is one of the important rule types that are used by databaseapplications. This paper analyzes requirements for a programming paradigm appropriate forthe support of data-driven rules; states the linguistic paradigm; discusses its supportingarchitecture and shows an extension of the model to support temporal functionalities;especially retroactive and proactive processing. The focus in this paper is on the softwareengineering aspects of the proposed model: ease of use through a high-level language andimproving the verifiability of the rule language.,Rules in Database Systems: Proceedings of the 1st International Workshop on Rules in Database Systems; Edinburgh; Scotland; 30 August–1 September 1993,2012,*
D1. 4–Micro-Mapping Model,Eliezer Levy–SAP; Victor Shafran–SAP; Zoltán Miklós; Nguyen Quoc Viet Hung–EPFL; Avigdor Gal; Matthias Weidlich–IIT,*,*,2012,*
Schema Covering: Problem; Modeling; Analysis; and Applications,Avigdor Gal; Michael Katz; Tomer Sagi,*,*,2011,*
10042 Abstracts Collection--Semantic Challenges in Sensor Networks,Karl Aberer; Avigdor Gal; Manfred Hauswirth; Kai-Uwe Sattler; Amit P Sheth,Abstract From 24.01. to 29.01. 2010; the Dagstuhl Seminar 10042``Semantic Challenges inSensor Networks''was held in Schloss Dagstuhl~--~ Leibniz Center for Informatics. Duringthe seminar; several participants presented their current research; and ongoing work andopen problems were discussed. Abstracts of the presentations given during the seminar aswell as abstracts of seminar results and ideas are put together in this paper. The first sectiondescribes the seminar topics and goals in general. Links to extended abstracts or full papersare provided; if available.,Dagstuhl Seminar Proceedings,2010,*
10042 Executive Summary--Semantic Challenges in Sensor Networks,Karl Aberer; Avigdor Gal; Manfred Hauswirth; Kai-Uwe Sattler; Amit P Sheth,Abstract There has been significant progress in the number and capabilities of mobiledevices; wireless sensors; and sensor networks. These developments; combined with theimproved ability to bridge between the physical and cyber world in a more seamless way;have fostered the broad availability of sensor data capturing the state of the physical world.Promising and already successful examples are applications in environmental monitoring;agriculture; surveillance and intrusion detection; public security; and supply chainmanagement. Furthermore; ideas towards a Web of sensors have been proposed; which isto be understood as a (large scale) network of spatially distributed sensors. In particular;terms like" Internet of Things";" Collaborating Objects" and" Ambient Intelligence" emphasizethe trend towards a tighter connection between the cyber space and the physical world.,Dagstuhl Seminar Proceedings,2010,*
ODBASE 2009–PC Co-chairs’ Message,Sharma Chakravarthy; Avigdor Gal; Annika Hinze,Abstract Welcome to the proceedings of the 8th International Conference on Ontologies;Databases; and Applications of Semantics (ODBASE 2009) held in Algarve; Portugal;November 2-4; 2009. The ODBASE conferences provide a forum for the sharing of originalresearch results and practical development experiences in the areas of ontologies;databases; and applications of data semantics. This year we announced a special theme of“Semantics in Complex Event Processing” combining two current and important researchareas. Our keynote speaker; Alejandro P. Buchmann; is one of the leading researchers inthe field of complex event processing and his keynote lecture tied in research andapplications; complex event processing and semantics. In addition; one of the researchsessions this year was devoted to semantics in complex event processing. We received …,OTM Confederated International Conferences" On the Move to Meaningful Internet Systems",2009,*
ODBASE 2009–PC Co-chairs’ Message,Avigdor Gal; Annika Hinze,The ODBASE conferences provide a forum for the sharing of original research results andpractical development experiences in the areas of ontologies; databases; and applicationsof data semantics. This year we announced a special theme of” Semantics in Complex EventProcessing” combining two current and important research areas. Our keynote speaker;Alejandro P. Buchmann; is one of the leading researchers in the field of complex eventprocessing and his keynote lecture tied in research and applications; complex eventprocessing and semantics. In addition; one of the research sessions this year was devotedto semantics in complex event processing. We received 65 submissions out of which weselected 16 full papers; 9 short papers; and 7 posters. Main topics of this year were: ontologymanagement; ontology applications; heterogeneity management; knowledge bases; and …,On the Move to Meaningful Internet Systems: OTM 2009: Confederated International Conferences; CoopIS; DOA; IS; and ODBASE 2009; Vilamoura; Portugal; November 1-6; 2009; Proceedings,2009,*
The (Similarity) Matrix Reloaded,Avigdor Gal,Abstract Schema matching provides correspondences between concepts describing themeaning of data in various heterogeneous; distributed data sources. Schemamatching is abasic operation of data and schema integration and thus has a great impact on its outcome.The outcome of the matching process can serve in tasks of targeted content delivery; viewintegration; database integration; query rewriting over heterogeneous sources; duplicatedata elimination; and automatic streamlining ofworkflowactivities that involve heterogeneousdata sources. As such; schema matching has impact on numerous modern applications fromvarious application areas. It impacts business; where company data sources continuouslyrealign due to changing markets. It also impacts the way business and other informationconsumers seek information over theWeb. Finally; it impacts life sciences; where scientific …,OTM Confederated International Conferences" On the Move to Meaningful Internet Systems",2008,*
Second Line Schema Matchers,Anan Marie; ענאן מרעי,Abstract Schema matching is recognized to be one of the basic operations required by theprocess of data and schema integration. Over the years; a significant body of work wasdevoted to the identification of heuristics for schema matching. However; existing tools donot deliver satisfactory results as of yet. In this work we introduce the notion of second lineschema matchers; matchers that operate on the outcome of other matchers to improve theiroriginal outcome. We demonstrate the differences between first and second line matchersusing examples; demonstrating the benefit of this classification. We then introduce four newsecond line heuristics and show their comparative performance through a thoroughempirical analysis of 230 schemata.,*,2008,*
Self organizing semantic topologies in peer database systems,Ami Eyal; עמי איל,I would like to express my deepest gratitude to my supervisor; Professor Avigdor Gal; for hisdevoted guidance and wise counsel. My sincere thanks to the faculty personnel; for theirhelp in all practical and administrative matters during my studies; special thanks are given toJudith Ish-Lev. Additional thanks to my colleagues; Haggai; Inbal; Victor and others; forhelpful discussions; motivation and support when I most needed it. Last and most important;I am deeply indebted to my dear family and friends; whose endless love and supportenabled the completion of this work.,*,2007,*
Semantic Methods for Service Categorization,Avigdor Gal; Aviv Segev; Eran Toch,ABSTRACT In this work we provide an initial analysis of service categorization; the processof associating services with ontologies. Service categorization is an important pre-processing step to tasks such as service composition. The absence of semanticunderstanding of services may yield erroneous compositions and therefore; servicecategorization can assist in determining the correctness of a composition. We analyze twocommon methods for text processing; TF/IDF and context analysis. We also test two types ofservice description; textual and WSDL. Our initial results indicate that context analysis ismore useful than TF/IDF and that WSDL description provides better categorization thantextual description.,*,2007,*
Communication-Efficient Query Answering with Quality Guarantees in Client-Server Applications.,Michal Shmueli-Scheuer; Amitabh Chaudhary; Avigdor Gal; Chen Li,ABSTRACT We study how to reduce costs in client-server web based applications withdynamic data on the server. Client-side caching can help mitigate costs because the clientcan use the cached data to answer queries. Allowing some tolerance on the data stalenessto answer queries makes it possible to significantly reduce costs. For example; if the usercan tolerate data that was received 2 hours ago; we can use the cached data to provide theanswer and to save some costs. In this paper we present useful algorithms under differentcost models; we provide 2-approximation offline algorithm; as well as (k+ 1) competitiveonline algorithm and family of Heuristics. We validate our methods through extensiveexperiments.,WebDB,2007,*
$\mathcal {P} ro\mathcal {M} o $–A Scalable and Efficient Framework for Online Data Delivery,Haggai Roitman; Avigdor Gal; Louiqa Raschid,Abstract Web enabled application servers have had to increase the sophistication of theirserver capabilities in order to keep up with the increasing demand for client customization.Typical applications include RSS feeds; stock prices and auctions on the commercialInternet; and increasingly; the availability of Grid computational resources. Web datadelivery technology has not kept up with these demands. There still remains a fundamentaltrade-off between the scalability of both performance and ease of implementation on theserver side; with respect to the multitude and diversity of clients; and the requiredcustomization to deliver the right service/data to the client at the desired time. Current datadelivery solutions can be classified as either push or pull solutions; each suffering fromdifferent drawbacks. Push is not scalable; and reaching a large numbers of potentially …,International Workshop on Next Generation Information Technologies and Systems,2006,*
International Conference on Semantics of a Networked World: Semantics of Sequence and Time Dependent Data (ICSNW'06)-OntoBuilder: Fully Automatic Extractio...,Haggai Roitman; Avigdor Gal,*,Lecture Notes in Computer Science,2006,*
Seventh International Bi-conference Workshop on Agent-Oriented Information Systems (AOIS-2005)-Invited Talk-Agent Oriented Data Integration,Avigdor Gal; Aviv Segev,*,Lecture Notes in Computer Science,2005,*
Published online: 8 March 2005 M. Tamer Özsu: Coordinating Editor-in-Chief,Alon Y Halevy; Zachary G Ives; Dan Suciu; Igor Tatarinov; Avigdor Gal; Ateret Anaby-Tavor; Alberto Trombetta; Danilo Montesi; Dengfeng Gao; Christian S Jensen; Richard T Snodgrass; Michael D Soo; Yannis Tzitzikas; Nicolas Spyratos; Panos Constantopoulos,. One of the challenging problems that Web service technology faces is the ability toeffectively discover services based on their capabilities. We present an approach to tacklingthis problem in the context of description logics (DLs). We formalize service discovery as anew instance of the problem of rewriting concepts using terminologies. We call this newinstance the best covering problem. We...,The VLDB Journal,2005,*
CoopIS 2004 International Conference (International Conference on Cooperative Information Systems) PC Co-chairs’ Message,Wil van der Aalst; Christoph Bussler; Avigdor Gal,Abstract We would like to welcome you to the Proceedings of the Twelfth InternationalConference on Cooperative Information Systems (CoopIS 04). As in previous years; CoopISis part of the federated conference On the Move (OTM) to Meaningful Internet Systems andUbiquitous Computing; this year taking place in Agia Napa; Cyprus; together with theInternational Symposium on Distributed Objects and Applications (DOA) and theInternational Conference on Ontologies; Databases and Applications of Semantics for large-scale Information Systems (ODBASE).,OTM Confederated International Conferences" On the Move to Meaningful Internet Systems",2004,*
Schema Meta-Matching,Carmel Domshlak; Avigdor Gal,Schema matching is a basic operation in the data integration process; and several tools forautomating it have been proposed and evaluated in the database community. While in manydomains these tools succeed to find the right matching between concepts; empirical analysisshows that there is no single algorithm that is guaranteed to succeed in all possibledomains. In this paper we introduce schema meta-matching; a novel framework forcomposing an arbitrary ensemble of algorithms for schema matching. Informally; schemameta-matching is about computing a" consensus" ranking of alternative mappings betweentwo sets of concepts; given the" individual" graded rankings provided by several schemamatching algorithms. We introduce several algorithms for this problem; varying fromadaptations of some standard techniques for general quantitative rank aggregation; to …,*,2004,*
Cooperative Information Systems (CoopIS) 2004 International Conference-PC Co-chairs' Message,Wil van der Aalst; Christoph Bussler; Avigdor Gal,*,Lecture Notes in Computer Science,2004,*
Workflow reconfiguration using chains,Avigdor Gal; Eugeny Michailovsky; Mati Golani,Abstract Work. ows have become a common tool for modeling organizational activities.Research and practice of Work. ow Management Systems (WfMS) involve ontologicalaspects (eg; the relevant constructs for modeling inter-organizational work. ows [2; 1]);design aspects (eg; synchronization of concurrent work. ow instances [4]); reverseengineering [3]; and optimization. The latter has seen few advances; especially when itcomes to dynamic work. ow design; where organizations need to continuously revise theirwork. ows. As an illustrative example; consider virtual enterprises; enterprises that areformed in a competitive market to respond to the need to improve cost/performance ratio bycross-organizational cooperation. Cross-organizational operations require a dynamic. exiblemechanism that can handle the data. ow among di. erent partners [5; 6]. Therefore; if one …,OTM Confederated International Conferences" On the Move to Meaningful Internet Systems",2003,*
Next Generation Information Technologies and Systems: 5th International Workshop; NGITS 2002; Caesarea; Israel; June 24-25; 2002. Proceedings,Alon Halevy; Avigdor Gal,NGITS2002 was the? fth workshop of its kind; promoting papers that discuss newtechnologies in information systems. Following the success of the four p-vious workshops(1993; 1995; 1997; and 1999); the? fth NGITS Workshop took place on June 24–25; 2002; inthe ancient city of Caesarea. In response to the Call for Papers; 22 papers were submitted.Each paper was evaluated by three Program Committee members. We accepted 11 papersfrom 3 continents and 5 countries; Israel (5 papers); US (3 papers); Germany; Cyprus; andThe Netherlands (1 paper from each). The workshop program consisted of? ve papersessions; two keynote lectures; and one panel discussion. The topics of the paper sessionsare: Advanced Query Processing; Web Applications; Moving Objects; Advanced InformationModels; and Advanced Software Engineering. We would like to thank all the authors who …,*,2003,*
Next Generation Information Technologies and Systems: 5th International Workshop; NGITS 2002: Proceedings,Alon Halevy; Avigdor Gal,*,*,2002,*
1999 Reviewers list,Brad Adelberg; Jun-ichi Aoe; James Bailey; Elena Baralis; Roberto Bayardo; Elisa Bertino; Claudio Bettini; Athman Bouguettaya; J Breuker; K Selcuk Candan; Doris L Carver; Soumen Chakrabarti; Edward Chang; Ray Chen; Yaw-Huei Chen; Hui-Hsien Chou; Li-Der Chou; Christopher W Clifton; William W Cohen; Peter Dadam; Alan Dearle; Suzanne Dietrich; Khanh PV Doan; Guozhu Dong; Daniel Dvorak; Christoph F Eick; Carlos F Enguix; Henrik Eriksson; Opher Etzion; Charles Forgy; Shashi K Gadia; Avigdor Gal; Venkatesh Ganti; Minos Garofalakis; Stella Gatziu; Johannes Gehrke; Michael Gertz; Ashok K Goel; Angela Goh; Joachim Hammer; Susanne Heipcke; Ian Horrocks; Hui-I Hsiao; Stephen Huang; James K Huggins; Ben Jang; Lars J Kangas; Lina Khatib; Donald H Kraft; Gabriel Kuper; Mark Levene; Chung-Sheng Li; Dekang Lin; Witold Litwin; Jen-Chang Liu; Ling Liu; Xiaohui Liu; Rona Machlin; Bamshad Mobasher; Guido Moerkotte; Yasuhiko Morimoto; Shinichi Morishita; Mark A Najork; Vivek Narasayya; Erich J Neuhold; Thuy-Linh Nguyen; Lance Obermeyer; Dimitris Papadias; Jong Soo Park; Yun Peng; Alun Preece; Ivan Radev; Raghu Ramakrishnan; Paul Roback; Mark A Roth; Marie-Christine Rousset; Neil C Rowe; Ingrid Russell; Pierangela Samarati; Joerg Sander; Maria Luisa Sapino; Archana S Sathaye; Lawrence V Saxton; Edward Sciore; Hadas Shachnai; Fenn-Huei Simon Sheu; Jaideep Srivastava,142 IEEE TRANSACTIONS ON KNOWLEDGE AND DATA ENGINEERING; VOL. 12; NO. 1;JANUARY/FEBRUARY 2000 … —————————— 3 —————————— A Brad AdelbergJun-ichi Aoe B James Bailey Elena Baralis Roberto Bayardo Elisa Bertino Claudio Bettini AthmanBouguettaya J. Breuker C K. Selcuk Candan Doris L. Carver Soumen Chakrabarti Edward ChangIng-Ray Chen Yaw-Huei Chen Hui-Hsien Chou Li-Der Chou Christopher W. Clifton WilliamW. Cohen D Peter Dadam Alan Dearle Suzanne Dietrich Khanh PV Doan Guozhu Dong DanielDvorak E Christoph F. Eick Carlos F. Enguix Henrik Eriksson Opher Etzion F Charles Forgy GShashi K. Gadia Avigdor Gal Venkatesh Ganti Minos Garofalakis Stella Gatziu Johannes GehrkeMichael Gertz Ashok K. Goel Angela Goh … H Joachim Hammer Susanne Heipcke Ian HorrocksHui-I Hsiao Stephen Huang James K. Huggins J Ben Jang K Lars J. Kangas Lina Khatib …,IEEE Transactions on Knowledge and Data Engineering,2000,*
INFORMATION SERVICES: COPING WITH THE INFORMATION CRISIS GUEST EDITORS'INTRODUCTION,Avigdor Gal; John Mylopoulos,Information plays a critical role in the information age due to its importance in fulfilling thegoals of individuals and organizations alike. In order to ensure effective decision making;information should be of high quality; ie relevant; complete; accurate; timely; etc. Thesequalities can be achieved; at least in theory; through suitable preprocessing and filtering ofpossibly vast amount of data. However; the distributed; heterogeneous; and autonomousnature of information sources poses severe technical challenges for any technology thatattempts to provide coherent and compact information. In particular; information needs to begathered and filtered from a large; open and changing network of information sources.Moreover; these sources were developed independently; may be based on a variety ofinformation models; and may contain duplicate or even contradictory information. The …,International Journal of Cooperative Information Systems,1998,*
On transaction management in temporal databases,Avigdor Gal,Abstract A transaction model provides a framework for concurrent processing of retrieval andupdate operations in a database. Considerable research effort has focused on varioustechniques and protocols to ensure the ACID properties of transactions in conventionaldatabases. However; the adoption of these techniques and protocols to temporal databasesis not trivial. In particular; a refined locking mechanism based on temporal characteristicscan provide better concurrency among transactions in temporal databases than aconventional locking mechanism. Accordingly; this paper presents a set of modifications andfine tuning of traditional concepts in transaction management; to enable a betterperformance of temporal databases. We also suggest a scheme for implementing atransaction protocol for temporal databases on top of a relational database. The …,*,1998,*
Faculty of Industrial and Management Engineering Technion-Institute of Technology Haifa; 32000; Israel e-mail,Opher Etzion; Avigdor Gal,*,*,1995,*
High Level Change Management using Temporal Agents,Avigdor Gal; Opher Etzion,Abstract Business Re-engineering requires frequent changes in the enterprises' informationsystems; however the current technology of data dictionaries is not e ective for the tracing ofrequired changes and their management. In this paper we introduce an architecture ofchange management using active temporal repositories. Flexible change managementallows the support of information about past or future versions of information systems; aswell as the capability to retrieve and update temporal information. The implementation ofchange management in a temporal environment is carried out by the partition of thetemporal universe among temporal agents; each of them handles a single version of anapplication with a required collaboration among them. The change management process;and the inter and intra agent processing are described in this paper.,*,1995,*
Interval-based Queries over Multiple Streams with Missing Timestamps,Nimrod Busany; Avigdor Gal; Arik Senderovich; Matthias Weidlich,Abstract—Recognising patterns that correlate multiple events over time becomesincreasingly important in applications from urban transportation to surveillance monitoring.In many realworld scenarios; however; timestamps of events may be erroneously recordedand events may be dropped from a stream due to network failures or load shedding policies.In this work; we present SimpMatch; a novel simplex-based algorithm for probabilisticevaluation of event queries using constraints over event orderings in a stream. Ourapproach avoids learning probability distributions for time-points or occurrence intervals.Instead; we employ the abstraction of segmented intervals and compute the probability of asequence of such segments using the principle of order statistics. The algorithm runs inlinear time to the number of missed timestamps; and shows high accuracy; yielding exact …,*,*,*
Pay-as-you-go Reconciliation in Schema Matching Networks,Nguyen Quoc; Viet Hung; Nguyen Thanh Tam; Karl Aberer; Avigdor Gal; Matthias Weidlich,Abstract—Schema matching is the process of establishing correspondences between theattributes of database schemas for data integration purposes. Although several automaticschema matching tools have been developed; their results are often incom-plete orerroneous. To obtain a correct set of correspondences; a human expert is usually required tovalidate the generated correspondences. We analyze this reconciliation process in a settingwhere a number of schemas needs to be matched; in the presence of consistencyexpectations about the network of attribute correspondences. We develop a probabilisticmodel that helps to identify the most uncertain correspondences; thus allowing us to guidethe expert's work and collect his input about the most problematic cases. As the availabilityof such experts is often limited; we develop techniques that can construct a set of good …,*,*,*
1ST WORKSHOP ON THE ROLE OF REAL-WORLD OBJECTS IN BUSINESS PROCESS MANAGEMENT SYSTEMS (RW-BPMS 2015),Avigdor Gal; Sonja Meyer; Andreas Ruppen; Lorenz Hilty; Francesco Leotta; Massimo Mecella; Jan Mendling; Erwin Filtz; Emanuel Sanchez de La Cerda; Mathias Weber; David Zirkovits; Tsun Yin Wong; Susanne Bülow; Mathias Weske,Big Data brings with it new and exciting challenges to complex event processing. Largevolumes of simple events that stream in high velocity to our processing stations from avariety of sources call for rethinking traditional methods of processing complex events. In thistalk we shall explore the interesting phenomenon of event streams that are produced byprocesses; eg; bus data that is governed by bus routes or real time positioning systemtracking patients in an outpatient clinic. The talk shall answer some of the related interestingquestions: how do we discover the rules that govern event creation? how do we use suchrules to optimize complex event processing? and suggest directions for future research. Thetalk will be accompanied by examples of urban transportation in Dublin (the INSIGHTEuropean project) and patient visits to Dana-Farber Cancer Institute (DFCI); a large …,*,*,*
Learning to Match Schemata using Predictors,Avigdor Gal; Haggai Roitman; Roee Shraga,ABSTRACT We propose a learning algorithm that utilizes an innovative set of features to re-rank a list of top-K matches and improves upon the ranking of the best match. We provide abound on the size of an initial match list; tying the number of matches in a desired level ofconfidence for finding the best match. We also propose the use of schema matchingpredictors as features in the learning task; and tailored nine new predictors for this purpose.A large scale empirical evaluation with real-world benchmark schema sets show theeffectiveness of the proposed algorithmic solution for reranking top-K schema matches.,*,*,*
EDU-ProM: ProM for the Classroom,Yossi Dahari; Avigdor Gal; Arik Senderovich,Abstract. We present EDU-ProM; an extension of the ProM framework; which was designedto serve as a classroom version of ProM for educational purposes. EDU-ProM is designed towork in a non-interactive work mode; allowing the execution of a set of mining tasks againstnumerous event logs without user intervention. It is mostly suitable for process miningresearchers and students who are interested in exploring and extending existing ProMalgorithms. EDU-ProM is a standalone open-source project; which requires simple setup toachieve a rich development environment for executing; creating; and extending miningtechniques. The demo is aimed at academics who teach process mining in class; whileusing ProM as the basis for class and home assignments. In addition; the demo will interestresearchers and practitioners who would like to run batch experiments using ProM …,*,*,*
PED 2017 Workshop Organizers,Avigdor Gal; Hans-Arno Jacobsen; Joao E Ferreira; Alessio Lomuscio; Calton Pu; Fabio Porto; Fernanda Baião; Jianwei Yin; Manfred Reichert; Marlon Dumas; Matthias Weidlich; Schahram Dustdar,A not-for-profit organization; IEEE is the world's largest technical professional organization dedicatedto advancing technology for the benefit of humanity. © Copyright 2017 IEEE - All rightsreserved. Use of this web site signifies your agreement to the terms and conditions.,*,*,*
Wissenschaftliche Berichte,J Mendling; I Weber; W van der Aalst; J vom Brocke; C Cabanillas; F Daniel; S Debois; C Di Ciccio; M Dumas; S Dustdar; A Gal; L Garcia-Banuelos; G Governatori; R Hull; M La Rosa; H Leopold; F Leymann; J Recker; M Reichert; H Reijers; S Rinderle-Ma; A Rogge-Solti; M Rosemann; S Schulte; M Singh; T Slaats; M Staples; B Weber; M Weidlich; M Weske; X Xu; L Zhu,Blockchain technology promises a sizable potential for executing inter-organizationalbusiness processes without requiring a central party serving as a single point of trust (andfailure). This paper analyzes its impact on business process management (BPM). Westructure the discussion using two BPM frameworks; namely the six BPM core capabilitiesand the BPM lifecycle. This paper provides research directions for investigating theapplication of blockchain technology to BPM.,*,*,*
AAAI Publications,Sarah Keren; Luis Pineda; Avigdor Gal; Erez Karpas; Shlomo Zilberstein,AAAI Publications. Open Conference Systems. Conference Help. User Username;Password; Remember me. Conference Content Search. All. Browse …,*,*,*
3.10 Optimisation opportunities,Roman Vitenberg; Avigdor Gal; Alessandro Margara; Vinay Setty; Martin Ugarte; Matthias Weidlich; Lijie Wen; Kaiwen Zhang,The scope of optimisations in EP and BPM is large and diverse. A common use of EP is as abuilding block or component or a guiding paradigm within a BPM architecture. On the onehand; process improvements can be based on event data. On the other hand; applicationfeedback and BPM insights can be exploited to optimise and configure implementation ofthe events processing component.,Integrating Process-Oriented and Event-Based Systems,*,*
RW-BPMS 2016 Program Committee,Claudio Di Ciccio; Rik Eshuis; Marco Aiello; Daniel Beverungen; Antonio Bucchiarone; Cristina Cabanillas; Paolo Ceravolo; Massimiliano de Leoni; Schahram Dustdar; Selim Erol; Dirk Fahland; Fabiana Fournier; Avigdor Gal; Paul Grefen; Bernhard Holtkamp; Christian Janiesch; Francesco Leotta; Fabrizio Maria Maggi; Andrea Marrella; Massimo Mecella; Josiane Xavier Parreira; Andreas Rogge-Solti; Stefan Schulte; Stefan Sobernig; Pnina Soffer; Mark Strembeck; Barbara Weber; Matthias Weidlich,Claudio Di Ciccio; Vienna University of Economics and Business; Austria Anne Baumgrass; SynfiooGmbH; Germany Rik Eshuis; Eindhoven University of Technology; The Netherlands … MarcoAiello; University of Groningen; The Netherlands Daniel Beverungen; University of Münster; GermanyAntonio Bucchiarone; Fondazione Bruno Kessler; Italy Cristina Cabanillas; Vienna Universityof Economics and Business; Austria Paolo Ceravolo; University of Milan; Italy Massimiliano deLeoni; Eindhoven University of Technology; The Netherlands Gero Decker; Signavio GmbH;Germany Schahram Dustdar; Vienna University of Technology; Austria Selim Erol; Vienna Universityof Technology; Austria Dirk Fahland; Technical University of Eindhoven; The Netherlands FabianaFournier; IBM Research; Haifa; Israel Avigdor Gal; Technion; Israel Institute of Technology; IsraelPaul Grefen; Eindhoven University of Technology; The Netherlands Bernhard Holtkamp …,*,*,*
Conformance Checking and Performance Improvement in Scheduled Processes: A Queueing-Network Perspective,Arik Senderovich1 Matthias Weidlich2 Liron Yedidsion; Avigdor Gal,Abstract: Conceptual models of service processes enable operational analysis and may beconstructed automatically from event logs containing recorded traces of process execution.In this work; we target the analysis of resource-driven; scheduled processes based on eventlogs. Specifically; we approach the questions of conformance checking (how to assess theconformance of the schedule and the actual process execution) and performanceimprovement (how to improve the operational process performance). The first question isaddressed based on a comparative analysis of queueing networks for both the scheduleand the actual process execution. These results of this analysis are used to improve theoperational performance of a process: we suggest adaptations of the scheduling policy ofthe service process to decrease the tardiness (non-punctuality) and lower the flow time …,*,*,*
SMART: A tool for analyzing and reconciling schema matching networks,Zoltán Miklós; Karl Aberer; Matthias Weidlich' Avigdor Gal,Abstract—Schema matching supports data integration by establishing correspondencesbetween the attributes of independently designed database schemas. In recent years;various tools for automatic pair-wise matching of schemas have been developed. Since thematching process is inherently uncertain; the correspondences generated by such tools areoften validated by a human expert. In this work; we consider scenarios in which attributecorrespondences are identiﬁed in a network of schemas and not only in a pairwise setting.Here; correspondences between different schemas are interrelated; so that incomplete anderroneous matching results propagate in the network and the validation of acorrespondence by an expert has ripple effects. To analyse and reconcile such matchings inschema networks; we present the Schema Matching Analyzer and Reconciliation Tool …,*,*,*
PLAYGROUND–System Demo of Goal Recognition Design,Sarah Keren; Avigdor Gal; Ran Harari; Erez Karpas,Abstract We describe PLAYGROUND; an interactive game developed for demonstrating theconcepts of goal recognition design (grd). grd is a recently formulated task that involves theoff-line analysis of goal recognition models. As such grd involves formulating measures thatassess the ability to perform goal recognition within a model and finding efficient ways tocompute and optimize them. PLAYGROUND is designed as a walk-through introduction tothe concepts of goal recognition design by engaging the user in a goal recognition taskbefore and after goal recognition design has been applied. This setting allows the user tohave a hands-on experience with improving the design of goal recognition tasks.,*,*,*
Data-Parallel Computing Meets STRIPS: Extended Technical Report,Erez Karpas; Tomer Sagi; Carmel Domshlak; Avigdor Gal; Avi Mendelson; Moshe Tennenholtz,Abstract The increased demand for distributed computations on big data has led to solutionssuch as SCOPE; DryadLINQ; Pig; and Hive; which allow the user to specify queries in anSQL-like language; enriched with sets of user-defined operators. The lack of exactsemantics for user-defined operators interferes with the query optimization process; thusputting the burden of suggesting; at least partial; query plans on the user. In an attempt toease this burden; we propose a formal model that allows for data-parallel program synthesis(DPPS) in a semantically well-defined manner. We show that this model generalizes existingframeworks for dataparallel computation; while providing the flexibility of query plangeneration that is currently absent from these frameworks. In particular; we show howexisting; offthe-shelf; AI planning tools can be used for solving DPPS tasks.,*,*,*
OTMA’10-PC Co-chairs Message,Galia Angelova; Christoph Bussler; Paolo Ceravolo; Ling Feng; Avigdor Gal; Frédéric Le Mouël; Chengfei Liu; Hervé Panetto,The OTMA faculty members; who are well respected researchers and practitioners; criticallyreflect on the students' work in a highly positive and inspiring atmosphere; so that thestudents can improve not only their research capacities but also their presentation andwriting skills. Accordingly; we offer a complete coaching seminar. Crucial for the success ofOTMA is the commitment of international researchers and experts of the permanent OTMAfaculty. We sincerely thank:,On the Move to Meaningful Internet Systems: OTM 2010 Workshops,*,*
SEI Capability Maturity Model’s Impact on Contractors; pp. 16-26,Hossein Saiedian; Richard Kuzara; Avigdor Gal; Opher Etzion,*,*,*,*
Helal; A.,K Aberer; G Alonso; B Arpinar; G Aslan; P Attie; T Berkel; E Bertino; A Bouguettaya; Y Breitbart; M Brodie; A Buchmann; P Buhrmann; R Busse; S Christodoulakis; A Cichocki; U Dayal; V Dayal; C Dengi; A Dogac; M Donahoo; W Du; A Elmagarmid; C Evrendilek; C Faloutsos; P F&&user; A Forst; T Furukawa; M Garcia-Solace; G Gardarin; J Geller; D Georgakopoulos; J Haake; V Kashyap; F Kemper; B Klein; P Koksal; S Laufmann; F Lenzen; WS Li; K Liao; W Litwin; S Mahajan; K Makki; F Manola; G Martin; D McLeod; J Miller; S Milliner; J Mylopoulos; S Navathe; B Novikov; T Ozsu; L Rostek; M Rusinkiewicz; F Saltor; HJ Schek; P Scheuermann; B Schwarzer; M Shan; MP Singh; S Spaccapietra,*,*,*,*
A Generalized Cover problem for Schema Matching,Karl Aberer; Ran Bittmann; Avigdor Gal; Michael Katz; Eliezer Levy; Zoltán Miklós; Nguyen Quoc Viet Hung; Tomer Sagi; Victor Shafran,Given a schema and a set of concepts; representative of entities in the domain of discourse(eg; a vendor in an eCommerce application); schema cover defines correspondencesbetween concepts and parts of the schema. Schema cover aims at “explaining” the schemain terms of concepts and thus; enhance the integration of a schema into an existing body ofknowledge. Schema cover can be considered a service in a dataspace toolbox [7]; enablinga pay-as-you-go approach for the introduction of a new schema. More motivation can beinserted here Schema cover builds upon the research work in schema matching; the task ofproviding correspondences between heterogeneous schema elements (eg attributes indatabase schemata). Schema matching is one of the basic operations required by theprocess of data and schema integration [1];[14];[3]; and thus has great effect on its …,*,*,*
On Leveraging Schema Matching Networks for Explorative Process Analysis,Avigdor Gal; Matthias Weidlich,Abstract. Business networks have a large potential of supporting their members in identifyingsynergies; building up consortia; and joining forces to react to legal changes. Hence;business networks should be equipped with an infrastructure supporting those goals.Bridging data heterogeneity and enabling interoperability of business documents in such asetting was recently addressed by schema matching networks. Matching in such a networkis guided by reusable building blocks; called concepts; that are shared by many networkmembers. We propose to adapt the notion of schema matching networks for an explorationof the business processes of network members. Then; a network consists of abstract processdescriptions and matching is guided by the business objects to which the activities refer.,*,*,*
On the move to meaningful internet systems 2004: CoopIS; DOA; and ODBASE(Agia Napa; 25-29 October 2004),Robert Meersman; Zahir Tari; Wil van der Aalst; Christoph Bussler; Avigdor Gal; Vinny Cahill; Steve Vinoski; Werner Vogels; Tiziana Catarci; Katia Sycara,*,Lecture notes in computer science,*,*
VAav: Process Navigator for the Design of New Business Process Models,Maya Lincoln; Avigdor Gal,Abstract. In this demonstration we introduce a prototype of PNav; a process navigator thatassists designers in designing new process models. To do that; PNav generates activitysuggestions for the newly generated process models. The business logic for suchsuggestions is extracted from process repositories through the analysis of existing businessprocess model activities.,*,*,*
Measuring the Relative Performance of Schema Matchers fExtended Abstract,Shlomo Berkovsky; Yaniv Eytani; Avigdor Gal,*,*,*,*
xviii,Akhilesh Bajaj; Roger S Barga; Claudia M Bauzer Medeiros; Elisa Bertino; Athman Bouguettaya; David Buttler; Fabio Castai; Ugur Cetintemel; Alok Chaturvedi; Jian Chen; Alok Choudhary; Jen-Yao Chung; Brian F Cooper; David De Roure; Asuman Dogac; Phillip Ein-Dor; David Embley; Peter Fankhauser; Germary Dieter Fensel; Avigdor Gal; Wolfgang Gentzsch; Kumar Goswami; Amarnath Gupta; Marc N Haines; Alan R Hevner; Michael N Huhns; Kazuo Iwano; Varghese S Jacob; Mario Jeckle; Vipul Kashyap; Michael Kifer; Hiroyuki Kitagawa; Ee-Peng Lim; Leo Mark,Karl Aberer; EPFL; Switzerland Ali Arsanjani; AIS AD CoC; IBM Global Services; USA AkhileshBajaj; University of Tulsa; USA Roger S. Barga; Microsoft Research; USA Claudia M BauzerMedeiros; UNICAMP; Brazil Elisa Bertino; University of Milano; Italy Krishna Bhagavatula; TataConsultancy Services America; USA Athman Bouguettaya; Virginia Tech; USA David Buttler;Lawrence Livermore National Laboratory; USA Mohammed I. Bu-Hulaiga; Joatha InformaticsConsulting; Saudi Arabia Fabio Castai; Hewlett-Packard; USA Ugur Cetintemel; BrownUniversity; USA Alok Chaturvedi; Purdue University; USA Michael Champion; Software AG &W3C WS; Architecture WG; USA Jian Chen; Tsinghua University; China Dickson KW Chiu; DicksonComputer Systems; Hong Kong David Cheung; HongKong University; Hong Kong AlokChoudhary; Northwestern University; USA Jen-Yao Chung; IBM TJ Watson Research …,*,*,*
Manipulating Control Elements: a Flexible Mechanism for Cooperative Information Systems Proofs of lemmas and theorems,Avigdor Gal,Abstract Cooperative information systems (CISs) are information systems with datadependencies and interoperability relationships. The paradigm for such systems involveslarge numbers of information systems distributed over large; complex computer/communication networks. Due to unreliable network technologies; and the possibleautonomous decisions of availability of each information system; CISs should be exibleenough to maintain a reasonable level of operation. In this paper we introduce controlelements as a tool for modeling the relationships among CISs. A control element combines ade nition of a set of CISs' global behavior with an executable data structure for cooperationamong them. Manipulating control elements using local transformations increases theexibility of these systems by allowing multiple paths for receiving data and activating …,*,*,*
RESEARCH THESIS,AVIGDOR GAL,*,*,*,*
Demo Program Committee,Stefan Berchtold; Brian Cooper; Avigdor Gal; Amarnath Gupta; Wei-Ying Ma; Thomas Seidl; Katsumi Tanaka; Wei Tang; Aoying Zhou,A not-for-profit organization; IEEE is the world's largest technical professional organization dedicatedto advancing technology for the benefit of humanity. © Copyright 2017 IEEE - All rightsreserved. Use of this web site signifies your agreement to the terms and conditions.,*,*,*
Digital Resource Profiling for Wide Area Applications,Avigdor Gal; Louiqa RaschidÂ; Vladimir Zadorozhny,We broadly define a wide area application (WAA pronounced double-U double-A) as onethat involves a federation of hundreds of servers and tens of thousands of clients; based onthe public infrastructure. The Handle protocol; an emerging IETF/IRTF standard from theCorporation for National Research Initiatives (CNRI)[41]; provides a global name service foruse over WANs; and can be used as the infrastructure for developing such a WAA. Eachhandle provides a namespace; a name resolution service; and protocols for digital objectlocation and access. As an example of a WAA developed over handles; the International Digital Object Identifier (D OI) Foundation (www. doi. org) and the community of publishersutilize handles to facilitate the identification and exchange of intellectual property in thedigital environment. It is expected that such applications must scale to tens of millions of …,*,*,*
Using Non-random Associations for Predicting Latency in WANs,Louiqa Raschid; Qiang Ye; Vladimir Zadorozhny; Avigdor Gal; Hyma Murthy,Abstract Wide area applications (WAAs) utilize a WAN infrastructure; eg; the Internet; toconnect a federation of hundreds of servers with tens of thousands of clients and they posesubstantial challenges. The diversity of sources means that clients may choose amongsources that vary both in their content and quality as well as their access latencies. However;Internet accessible data sources exhibit transient behavior; the unpredictable behavior of adynamic WAN results in a wide variability in access latency (end-to-end delay). IndividualLatency Profiles (iLPs) were proposed to capture latency distributions experienced by clientswhen connecting to a server; it is a passive measurement made by client applications and isgathered on a continuous basis. In this paper; we propose a management tool based onRelevance Networks (RNs) to managed tens of thousands of iLPs. Our objective is to …,*,*,*
NGITS 2002: next generation information technologies and systems(Caesarea; 24-25 June 2002),Alon Halevy; Avigdor Gal,*,Lecture notes in computer science,*,*
Coupling E ciency with Coupling Modes in Active Databases Proofs of lemmas and theorems,Avigdor Gal,Abstract The paper presents a general framework for handling coupling modes in activedatabases and discusses the inter-relationships between a set of coupling modes of anapplication and transaction e ciency. While the major role of coupling modes in activedatabases is to reduce ambiguous interpretation of transactions; coupling modes can a ectthe transaction's e ciency as well. Therefore; a default coupling mode is de ned for each rulein a given application; based on e ciency considerations. This mechanism enables adesigner of an application to consider e ciency while determining coupling modes; and basethe coupling modes decision on theoretical grounds. This issue is particularly important inwork ow management; where use of active databases in work ows on the one hand; and thefailure of commercial products to support applications with high-throughput work ows on …,*,*,*
SCW 2006 EDA-PS 2006 Workshop Organization,Opher Etzion; Ling Liu; Asaf Adi; Jose Alferes; Mikael Berndtsson; Antonio Carzaniga; Ugur Cetintemel; Mani Chandy; Sharma Chakravarthy; Norman Cohen; Juergen Dingel; Suzanne W Dietrich; Metin Feridun; Avigdor Gal; Burga Gedik; Torsten Greiner; Annika Hinze; H-Arno Jacobsen; Chung-Sheng Li; Susan Malaika; Shailendra Mishra; Themistoklis Palpanas; IBM Claudi Paniagua Macia; Mike Papazoglu; Cesare Pautasso; Calton Pu; Karsten Schwan; Rob Strom; Goce Trajcevski; Susan Urban; Rainer von Ammon; Agnes Voisard,Opher Etzion; IBM Research Lab in Haifa; Israel Ling Liu; Georgia Institute of Technology; USA… Asaf Adi; IBM Research ; Israel Jose Alferes; Universidade Nova de Lisboa MikaelBerndtsson; University of Skovde; Sweden David Buttler; LLNL; USA Antonio Carzaniga; Universityof Colorado; USA Ugur Cetintemel; Brown University; USA Mani Chandy; Cal Tech; USA SharmaChakravarthy; University of Texas Arlington; USA Norman Cohen; IBM Research; USA JuergenDingel; Queens University; Canada Suzanne W. Dietrich; Arizona State University; USA MetinFeridun; IBM Research; Switzerland Avigdor Gal; Technion; Israel Burga Gedik; GeorgiaTech; USA Torsten Greiner; Norisbank AG; Germany Annika Hinze; University of Waikato; NewZealand H.-Arno Jacobsen; University of Toronto; Canada Chung-Sheng Li; IBM Research; USASusan Malaika; IBM Software Group; USA Shailendra Mishra; Oracle; USA Themistoklis …,*,*,*
Experimenting Systems Analysis Teaching Using a Comparative Approach| A position paper,Avigdor Gal; Opher Etzion,Abstract There are many methods for modeling information systems; none of which has a denite advantage over the others. Thus; it is necessary to develop a decision process forexisting modeling methods to determine the most appropriate set of modeling tools for aspeci c application. This position paper outlines such a decision process; based on theexperience accumulated over the years of teaching courses in analysis and design ofinformation systems in the Technion; Israel Institute of Technology. The decision procedureis carried out by using a set of evaluation criteria; that are applied to a speci c application.,*,*,*
Data Driven and Temporal Rules in PARDES Opher Etzion Technion-Israel Institute of Technology Faculty of Industrial Engineering and Management Haifa; 32000;...,Avigdor Gal; Arie Segev,Abstract Data driven rules is one of the important rule types that are used by databaseapplications. This paper analyzes requirements for a programming paradigm appropriate forthe support of data-driven rules; states the linguistic paradigm; discusses its supportingarchitecture and shows an extension of the model to support temporal functionalities;especially retroactive and proactive processing. The focus in this paper is on the softwareengineering aspects of the proposed model: ease of use through a high-level language andimproving the verifiability of the rule language.,*,*,*
Real-Time Middleware Seminar 2007,Haggai Roitman; Avigdor Gal; Louiqa Raschid; Gidon Gershinsky,Applications that require online data delivery include RSS feeds; stock prices and auctionson the commercial Internet; context aware services in the Mobile arena; and increasingly;the availability of Grid computational resources. Services for clients in such a setting havebecome increasingly sophisticated and customized; in order to meet a diversity of clientsand their profiles. This has challenged the capabilities of both service providers and currentdata delivery middleware. To satisfy client needs; data delivery middlewares use either pushor pull methods and each suffers some drawbacks. Several hybrid push-pull solutions exist(eg;[1]); which rely on servers to predict when a client is about to monitor. This does notaddress the scalability problem.To illustrate the problem; consider a simplified scenario of aphysicist client; interested in executing a CPU and memory intensive simulation on a …,*,*,*
Ullas Nambiar (IBM India Research Lab; New Delhi; India); Cochair Zaiqing Nie (Microsoft Research Asia; Beijing; PR China); Cochair,Alon Halevy; Kevin Chen-Chuan Chang; Subbarao Kambhampati; Avigdor Gal; Andrew McCallum; Biplav Srivastava; Bing Liu; Craig Knoblock; Chen Li; Felix Naumann; Ganesh Ramakrishnan; Gautam Das; Hasan Davulcu; Ji-Rong Wen; Kamal Karlapalem; Louiqa Raschid; Michael Cafarella; Misha Bilenko; Mong Li Lee; Nicholas Kushmerick; Robert Grossman; Steven Minton; Thomas Y Lee; Vanja Josifovski; Weiyi Meng; William Cohen,Alon Halevy (Google Inc. Mountain View; California; USA) Kevin Chen-Chuan Chang (Universityof Illinois at Urbana-Champaign; Illinois; USA) Subbarao Kambhampati (Arizona StateUniversity; Tempe; Arizona; USA) … Avigdor Gal (Technion – Israel Institute of Technology)Andrew McCallum (University of Massachusetts Amherst; USA) Biplav Srivastava (IBM IndiaResearch Lab) Bing Liu (University of Illinois at Chicago; USA) Craig Knoblock (University ofSouthern California; USA) Chen Li (University of California; Irvine; USA) Felix Naumann (HassoPlattner Institut; Postdam; Germany) Ganesh Ramakrishnan (IBM India Research Lab) GautamDas (University of Texas; Arlington; USA) Hasan Davulcu (Arizona State University; USA) Ji-RongWen (Microsoft Research Asia) Kamal Karlapalem (IIIT – Hyderabad; India) Louiqa Raschid(University of Maryland College Park; USA) Michael Cafarella (University of Washington …,*,*,*
Optimizing Exception Handling in Workflows using Activity Restructuring,Mati Golani; Avigdor Gal,Abstract. Exception handling is the process by which a failure in a process is mitigated.Depending on the specifics of an exception; excep" tion handling may range from halting aprocess; through attempts of activity reactivation; to an identification of an alternative path tosuc" cessful completion of a process. Designing effi cient exception handlers is not a simpletask. By their very nature; exceptions are rare events which may result in poor design ofexception handlers in terms of cost and logic. In this work we aim at improving exceptionhandling per" formance in workflow management systems (WfMSs); a task which has beenrecognized as a fundamental component of WfMSs that is critical to their successfuldeployment in real" world scenarios. Our approach is based on the observation that whendesigning a business process as a workflow; a designer has some degree of freedom in …,*,*,*
Abiteboul; S. 41 Aggarwal; CC 261;593 Agrawal; D 93; 274;496;639 Agrawal; S. 5,M Akinde; S AI-Khalifa; G Alonso; M Areal; WG Aref; V Atluri; I Atmosukarto; D Baker; R Barga; K Barker; B Benatallah; G Bhalotia; HE Blok; M Bohlen; A Bonifati; D Braga; S Bressan; N Bruno; F Buccafurri; A Campi; F Casati; AC Catlin; S Ceri; S Chakrabarti; NH Chan; S Chaudhuri; B Chen; CM Chen; J Chen; MS Chen; F Chiu; J Cho; HD Chon; L Cohen; B Cooper; R Cordova; G Cormode; G Das; S Davey; U Daya; S Decker; A Descour; A Deshpande; J Desmarais; DJ DeWitt; A Doan; M Dumas; J Dunn; MG Elfeky; CJ El1mann; AK Elmagarmid; R Elmasri; C Fa1outsos; J Fan; A Faradjian; P Felber; J Feng; S Flesca; I Foudos; J Freire; AW Fu; F Furfaro; A Gal; H Garcia-Molina; M Garofalakis; J Gehrke; D Georgakopoulos; M Gertz; A Goel,333 369 264 331 129 567; 685 ; 673 ; 490 ; 266 ; 271 263 29 393 490 212;276 716 498 492271 498 431 176 490 605 29 141 278;463 265; 663 335 488 262 ; 494 ; 266 ; 166 129 309 309333 494 275 673 309 141;567;605 309 262 453 706 329 … 267 269 176 583 269 617 268; 268 543 269;327 155;331;335 155 697 555 507 279 333 267 583 41;369 490 271 29 117 331685 333 212;498 685 685 ; 245 605 333 270 431 529 345;697 271 ;498 273 583 272 297 ;485685 274 275 333 265;663 327 … Ounopulos; D PUO; J. ..; Gtirel; A. Haas; L. ãas; p .J.Haclgtimti; H. I … ¥alevy; A. ãmmad; M. ¥aritsa; JR ¥ellerstein; J .M … Lee; D. Lee; MLLehner; W Leung; CK-S Ling; T. W ' … Ling; Y. Liu; B Liu; J Lomet; D. Low; WL Lu; H. ; Lu; JXLuo; G. Madden; S. Madhyastha; T. Maier; D. Major; G. Mani; M. Mannila; H Marian; A.,*,*,*
SCW 2006 IEEE Services Computing Workshops,Asaf Adi; Jose Alferes; Mikael Berndtsson; Antonio Carzaniga; Ugur Cetintemel; Mani Chandy; Sharma Chakravarthy; Norman Cohen; Juergen Dingel; Suzanne W Dietrich; Metin Feridun; Avigdor Gal; Burga Gedik; Torsten Greiner; Annika Hinze; H-Arno Jacobsen; Chung-Sheng Li; Susan Malaika; Shailendra Mishra; Themistoklis Palpanas; IBM Claudi Paniagua Macia; Mike Papazoglu; Cesare Pautasso; Calton Pu; Karsten Schwan; Rob Strom; Goce Trajcevski; Susan Urban; Rainer von Ammon,Asaf Adi; IBM Research ; Israel Jose Alferes; Universidade Nova de Lisboa MikaelBerndtsson; University of Skovde; Sweden David Buttler; LLNL; USA Antonio Carzaniga; Universityof Colorado; USA Ugur Cetintemel; Brown University; USA Mani Chandy; Cal Tech; USA SharmaChakravarthy; University of Texas Arlington; USA Norman Cohen; IBM Research; USA JuergenDingel; Queens University; Canada Suzanne W. Dietrich; Arizona State University; USA MetinFeridun; IBM Research; Switzerland Avigdor Gal; Technion; Israel Burga Gedik; GeorgiaTech; USA Torsten Greiner; norisbank AG; Germany Annika Hinze; University of Waikato; NewZealand H.-Arno Jacobsen; University of Toronto; Canada Chung-Sheng Li; IBM Research; USASusan Malaika; IBM Software Group; USA Shailendra Mishra; Oracle; USA ThemistoklisPalpanas; IBM Research; USA Claudi Paniagua Macia; IBM; Spain Mike Papazoglu …,*,*,*
Latency Prediction Using Aggregate Latency Profiles,Qiang Ye; Vladimir Zadorozhny; Avigdor Gal; Louiqa Raschid,ABSTRACT A prominent challenge in the support of Wide Area Applications (WAA) involvestheir unpredictable behavior over a dynamic WAN that results in a considerable variability inaccess latency (end-toend delay). Latency profiles capture the changing latencies thatclients experience when accessing a server and can be utilized as a WAA monitoring andoptimization tool. However; in the presence of hundreds of servers and tens of thousands ofclients; managing millions of latency profiles cannot scale. In this paper we propose amethod for scalable monitoring and performance prediction of,*,*,*
Towards Service Retrieval on the Web,Eran Toch; Iris Reinhartz-Berger; Dov Dori; Avigdor Gal,The vast number of services on the Web raises the need for efficient and precise retrievalsolution; which will allow users to locate and analyze services. A'service'is an operationwhich is carried out on favor of a stakeholder; according to a given input; with certain resultsand qualities. Service qualities may include price; execution time etc. This general definitionis useful for describing a wide variety of resources in various fields; which are equivalent inthe sense that they perform an action. These fields include software engineering (egprogram functions); electronic commerce (eg business offerings on the Web); electronicgovernment (eg municipal and governmental services) and more. Therefore; finding astandard way for users to retrieve services; compare them and access them; is particularlyinteresting. The naïve approach towards service retrieval is to describe them with …,*,*,*
Organizing Committee/iii Preface/vii Ullas Nambiar and Zaiqing Nie Semantic Data Integration Environment for Biomedical Research (Mediator Infrastructure,Vadim Astakhov; Jeffrey S Grethe; Edward Ross; David Little; Brian Sanders; Amarnath Gupta; Kedar Bellare; Andrew McCallum; Jim Blythe; Dipsy Kapoor; Craig A Knoblock; Kristina Lerman; Steven Minton; Kurt Bollacker; Patrick Tufts; Tomi Pierce; Robert Cook; Christopher H Brooks; Yeh Fang; Ketaki Joshi; Papanii Okai; Xia Zhou; Aron Culotta; Pallika Kanani; Robert Hall; Michael Wick; Dave Kolas; Thomas Y Lee; Yiming Lu; Zaiqing Nie; Taoyuan Cheng; Ying Gao; Ji-Rong Wen; Anan Marie; Avigdor Gal,Information Integration for the Masses / 16 Jim Blythe; Dipsy Kapoor; Craig A. Knoblock; KristinaLerman; and Steven Minton … A Platform for Scalable; Collaborative; Structured InformationIntegration / 22 Kurt Bollacker; Patrick Tufts; Tomi Pierce; and Robert Cook … Citepack: An AutonomousAgent for Discovering and Integrating Research Sources / 28 Christopher H. Brooks; YehFang; Ketaki Joshi; Papanii Okai; and Xia Zhou … Author Disambiguation using Error-drivenMachine Learning with a Ranking Loss Function / 32 Aron Culotta; Pallika Kanani; RobertHall; Michael Wick; and Andrew McCallum … Efficient Strategies for Improving Partitioning-BasedAuthor Coreference by Incorporating Web Pages as Graph Nodes / 38 Pallika Kanani and AndrewMcCallum … Query Rewriting for Semantic Web Information Integration / 44 Dave Kolas …Using Regulatory Instructions for Information Extraction / 50 Thomas Y. Lee,*,*,*
Wide Area Performance Monitoring Using Aggregate Latency Profiles,Qiang Ye; Vladimir Zadorozhny; Avigdor Gal; Louiqa Raschid,Abstract. A challenge in supporting Wide Area Applications (WAA) is that of scalableperformance management. In particular; the unpredictable behavior of a dynamic WANresults in a considerable variability of latencies; which calls for models to predict the accesslatency (end-to-end delay) between a client and a server. Networking research has hadsignificant success in developing models to predict latency; based on physical topologiesand grounded in network protocols and behavior. However; such solutions are not designedto scale to the continuous monitoring and maintenance required for end-to-end support ofmillions of clients. Individual Latency Profiles (iLPs) capture latency distributionsexperienced by clients when connecting to a server; it is a passive measurement made byclient applications and is gathered on a continuous basis. In this paper; we propose a …,*,*,*
