Wavelet-based histograms for selectivity estimation,Yossi Matias; Jeffrey Scott Vitter; Min Wang,Abstract Query optimization is an integral part of relational database management systems.One important task in query optimization is selectivity estimation; that is; given a query P; weneed to estimate the fraction of records in the database that satisfy P. Many commercialdatabase systems maintain histograms to approximate the frequency distribution of values inthe attributes of relations. In this paper; we present a technique based upon a multiresolutionwavelet decomposition for building histograms on the underlying data distributions; withapplications to databases; statistics; and simulation. Histograms built on the cumulative datadistributions give very good approximations with limited space usage. We give fastalgorithms for constructing histograms and using them in an on-line fashion for selectivityestimation. Our histograms also provide quick approximate answers to OLAP queries …,ACM SIGMoD Record,1998,501
Approximate computation of multidimensional aggregates of sparse data using wavelets,Jeffrey Scott Vitter; Min Wang,Abstract Computing multidimensional aggregates in high dimensions is a performancebottleneck for many OLAP applications. Obtaining the exact answer to an aggregation querycan be prohibitively expensive in terms of time and/or storage space in a data warehouseenvironment. It is advantageous to have fast; approximate answers to OLAP aggregationqueries. In this paper; we present a novel method that provides approximate answers to high-dimensional OLAP aggregation queries in massive sparse data sets in a time-efficient andspace-efficient manner. We construct a compact data cube; which is an approximate andspace-efficient representation of the underlying multidimensional array; based upon amultiresolution wavelet decomposition. In the on-line phase; each aggregation query cangenerally be answered using the compact data cube in one I/O or a smalll number of I/Os …,ACM SIGMOD Record,1999,436
Data cube approximation and histograms via wavelets,Jeffrey Scott Vitter; Min Wang; Bala Iyer,Abstract There has recently been an explosion of interest in the analysis of data in datawarehouses in the ﬁeld of On-Line Analytical Processing (OLAP). Data warehouses can beextremely large; yet obtaining quick answers to queries is important. In many situations;obtaining the exact answer to an OLAP query is prohibitively expensive in terms of timeand/or storage space. It can be advantageous to have fast; approximate answers to queries.In this paper; we present an I/O-efﬁcient technique based upon a multiresolution waveletdecomposition that yields an approximate and space-efﬁcient representation of the datacube; which is one of the core OLAP operators. We build our compact data cube on thelogarithms of the partial sums of the raw data values of a multidimensional array. We getexcellent approximations for on-line range-sum queries with limited space usage and …,Proceedings of the seventh international conference on Information and knowledge management,1998,283
Dynamic Maintenance of Wavelet-Based Histograms.,Yossi Matias; Jeffrey Scott Vitter; Min Wang,Abstract In this paper; we introduce an e cient method for the dynamic maintenance ofwavelet-based histograms (and other transform-based histograms). Previous work hasshown that wavelet-based histograms provide more accurate selectivity estimation thantraditional histograms; such as equi-depth histograms. But since wavelet-based histogramsare built by a nontrivial mathematical procedure; namely; wavelet transform decomposition;it is hard to maintain the accuracy of the histogram when the underlying data distributionchanges over time. In particular; simple techniques; such as split and merge; which workswell for equi-depth histograms; and updating a xed set of wavelet coe cients; are not suitablehere. We propose a novel approach based upon probabilistic counting and sampling tomaintain waveletbased histograms with very little online time and space costs. The …,VLDB,2000,227
Linden: linking named entities with knowledge base via semantic knowledge,Wei Shen; Jianyong Wang; Ping Luo; Min Wang,Abstract Integrating the extracted facts with an existing knowledge base has raised anurgent need to address the problem of entity linking. Specifically; entity linking is the task tolink the entity mention in text with the corresponding real world entity in the existingknowledge base. However; this task is challenging due to name ambiguity; textualinconsistency; and lack of world knowledge in the knowledge base. Several methods havebeen proposed to tackle this problem; but they are largely based on the co-occurrencestatistics of terms between the text around the entity mention and the document associatedwith the entity. In this paper; we propose LINDEN; a novel framework to link named entitiesin text with a knowledge base unifying Wikipedia and WordNet; by leveraging the richsemantic knowledge embedded in the Wikipedia and the taxonomy of the knowledge …,Proceedings of the 21st international conference on World Wide Web,2012,178
XPathLearner: An on-line self-tuning Markov histogram for XML path selectivity estimation,Lipyeow Lim; Min Wang; Sriram Padmanabhan; Jeffrey Scott Vitter; Ronald Parr,This chapter illustrates XPathLearner; a method for estimating selectivity of the mostcommonly used types of path expressions without looking at the XML data. XPathLearnergathers and refines the statistics using query feedback in an online manner and is especiallysuited to queries in Internet scale applications since the underlying XML repository is eitherinaccessible or too large to be scanned in its entirety. The extensible mark-up language(XML) is gaining widespread use as a format for data exchange and storage on the WorldWide Web. Queries over XML data require accurate selectivity estimation of pathexpressions to optimize query execution plans. Selectivity estimation of XML pathexpression is usually done based on summary statistics about the structure of the underlyingXML repository. All previous methods require an off-line scan of the XML repository to …,Proceedings of the 28th international conference on Very Large Data Bases,2002,110
Efficient multi-way theta-join processing using mapreduce,Xiaofei Zhang; Lei Chen; Min Wang,Abstract Multi-way Theta-join queries are powerful in describing complex relations andtherefore widely employed in real practices. However; existing solutions from traditionaldistributed and parallel databases for multi-way Theta-join queries cannot be easilyextended to fit a shared-nothing distributed computing paradigm; which is proven to be ableto support OLAP applications over immense data volumes. In this work; we study theproblem of efficient processing of multi-way Theta-join queries using MapReduce from acost-effective perspective. Although there have been some works using the (key; value) pair-based programming model to support join operations; efficient processing of multi-wayTheta-join queries has never been fully explored. The substantial challenge lies in; given anumber of processing units (that can run Map or Reduce tasks); mapping a multi-way …,Proceedings of the VLDB Endowment,2012,101
Cryptography and relational database management systems,Jingmin He; Min Wang,Security is becoming one of the most urgent challenges in database research and industry;and the challenge is intensifying due to the enormous popularity of e-business. The authorsstudy database security from a cryptographic point of view. They show how to integratemodern cryptography technology into a relational database management system to solvesome major security problems. Our study shows that cryptographic support is anindispensable ingredient for a modern RDBMS to provide a secure environment for storingand processing a huge amount of business data.,Database Engineering and Applications; 2001 International Symposium on.,2001,95
Linking named entities in tweets with knowledge base via user interest modeling,Wei Shen; Jianyong Wang; Ping Luo; Min Wang,Abstract Twitter has become an increasingly important source of information; with more than400 million tweets posted per day. The task to link the named entity mentions detected fromtweets with the corresponding real world entities in the knowledge base is called tweet entitylinking. This task is of practical importance and can facilitate many different tasks; such aspersonalized recommendation and user interest discovery. The tweet entity linking task ischallenging due to the noisy; short; and informal nature of tweets. Previous methods focuson linking entities in Web documents; and largely rely on the context around the entitymention and the topical coherence between entities in the document. However; thesemethods cannot be effectively applied to the tweet entity linking task due to the insufficientcontext information contained in a tweet. In this paper; we propose KAURI; a graph-based …,Proceedings of the 19th ACM SIGKDD international conference on Knowledge discovery and data mining,2013,91
App recommendation: a contest between satisfaction and temptation,Peifeng Yin; Ping Luo; Wang-Chien Lee; Min Wang,Abstract Due to the huge and still rapidly growing number of mobile applications (apps); itbecomes necessary to provide users an app recommendation service. Different fromconventional item recommendation where the user interest is the primary factor; apprecommendation also needs to consider factors that invoke a user to replace an old app (ifshe already has one) with a new app. In this work we propose an Actual-Tempting modelthat captures such factors in the decision process of mobile app adoption. The modelassumes that each owned app has an actual satisfactory value and a new app underconsideration has a tempting value. The former stands for the real satisfactory value theowned app brings to the user while the latter represents the estimated value the new appmay seemingly have. We argue that the process of app adoption therefore is a contest …,Proceedings of the sixth ACM international conference on Web search and data mining,2013,76
Query optimization through the use of multi-column statistics to avoid the problems of non-indexed column correlation,*,The system; method; and program of this invention collects multi-column statistics; by adatabase management system; to reflect a relationship among multiple columns of a table ina relational database. These statistics are stored in the system catalog; and are used duringquery optimization to obtain an estimate of the number of qualifying rows when a query haspredicates on multiple columns of a table. A multi-column linear quantile statistic is collectedby dividing the data of multiple columns into sub-ranges where each sub-range hasapproximately an even distribution of data; and determining a frequency and cardinality ofeach sub-range. A multi-column polygonal quantile statistic is collected by dividing the dataof multiple columns into sub-spaces where each sub-space contains approximately thesame number of tuples; and determining a frequency and cardinality of each sub-space …,*,2001,70
A framework for semantic link discovery over relational data,Oktie Hassanzadeh; Anastasios Kementsietsidis; Lipyeow Lim; Renée J Miller; Min Wang,Abstract Discovering links between different data items in a single data source or acrossdifferent data sources is a challenging problem faced by many information systems today. Inparticular; the recent Linking Open Data (LOD) community project has highlighted theparamount importance of establishing semantic links among web data sources. Currently;LOD sources provide billions of RDF triples; but only millions of links between data sources.Many of these data sources are published using tools that operate over relational datastored in a standard RDBMS. In this paper; we present a framework for discovery ofsemantic links from relational data. Our framework is based on declarative specification oflinkage requirements by a user. We illustrate the use of our framework using several linkdiscovery algorithms on a real world scenario. Our framework allows data publishers to …,Proceedings of the 18th ACM conference on Information and knowledge management,2009,69
Dynamic maintenance of web indexes using landmarks,Lipyeow Lim; Min Wang; Sriram Padmanabhan; Jeffrey Scott Vitter; Ramesh Agarwal,Abstract Recent work on incremental crawling has enabled the indexed document collectionof a search engine to be more synchronized with the changing World Wide Web. However;this synchronized collection is not immediately searchable; because the keyword index isrebuilt from scratch less frequently than the collection can be refreshed. An inverted index isusually used to index documents crawled from the web. Complete index rebuild at highfrequency is expensive. Previous work on incremental inverted index updates have beenrestricted to adding and removing documents. Updating the inverted index for previouslyindexed documents that have changed has not been addressed. In this paper; we proposean efficient method to update the inverted index for previously indexed documents whosecontents have changed. Our method uses the idea of landmarks together with the diff …,Proceedings of the 12th international conference on World Wide Web,2003,67
Scalable set oriented classifier,*,A method; apparatus; and article of manufacture for a computer implemented scaleable set-oriented classifier. The scalable set-oriented classifier stores set-oriented data as a table ina relational database. The table is comprised of rows having attributes. The scalable set-oriented classifier classifies the rows by building a classification tree. The scalable set-oriented classifier determines a gini index value for each split value of each attribute foreach node that can be partitioned in the classification tree. The scalable set-orientedclassifier selects an attribute and a split value for each node that can be partitioned basedon the determined gini index value corresponding to the split value. Then; the scalable set-oriented classifier grows the classification tree by another level based on the selectedattribute and split value for each node. The scalable set-oriented classifier repeats this …,*,1999,66
Learning-based method for estimating cost and statistics of complex operators in continuous queries,*,A learning-based method for estimating costs or statistics of an operator in a continuousquery includes a cost estimation model learning procedure and a model applyingprocedure. The model learning procedure builds a cost estimation model from training data;and the applying procedure uses the model to estimate the cost associated with a givenquery. The learning procedure uses a feature extractor and a cost estimator. The featureextractor collects relevant training data and obtains feature values. The extracted featurevalues are associated with costs and used to create the cost estimator. When applying thecost estimator to a continuous stream of data; the feature extractor extracts feature valuesfrom the data stream and uses the extracted feature values as inputs into the cost estimatorto obtain the desired cost values.,*,2004,62
Linkedct: A linked data space for clinical trials,Oktie Hassanzadeh; Anastasios Kementsietsidis; Lipyeow Lim; Renée J Miller; Min Wang,Abstract: The Linked Clinical Trials (LinkedCT) project aims at publishing the first opensemantic web data source for clinical trials data. The database exposed by LinkedCT isgenerated by (1) transforming existing data sources of clinical trials into RDF; and (2)discovering semantic links between the records in the trials data and several other datasources. In this paper; we discuss several challenges involved in these two steps andpresent the methodology used in LinkedCT to overcome these challenges. Our approach forsemantic link discovery involves using state-of-the-art approximate string matchingtechniques combined with ontology-based semantic matching of the records; all performedin a declarative and easy-to-use framework. We present an evaluation of the performance ofour proposed techniques in several link discovery scenarios in LinkedCT.,arXiv preprint arXiv:0908.0567,2009,58
Relational database management encryption system,*,*,*,2001,57
Boolean+ ranking: querying a database by k-constrained optimization,Zhen Zhang; Seung-won Hwang; Kevin Chen-Chuan Chang; Min Wang; Christian A Lang; Yuan-chi Chang,Abstract The wide spread of databases for managing structured data; compounded with theexpanded reach of the Internet; has brought forward interesting data retrieval and analysisscenarios to RDBMS. In such settings; queries often take the form of k-constrainedoptimization; with a Boolean constraint and a numeric optimization expression as the goalfunction; retrieving only the top-k tuples. This paper proposes the concept of supporting suchqueries; as their nature implies; by a functional optimization machinery over the searchspace of multiple indices. To realize this concept; we combine the dual perspectives ofdiscrete state search (from the view of indices) and continuous function optimization (fromthe view of goal functions). We present; as the marriage of the two perspectives; the OPT*framework; which encodes k-constrained optimization as an A* search over the …,Proceedings of the 2006 ACM SIGMOD international conference on Management of data,2006,54
Characterizing web document change,Lipyeow Lim; Min Wang; Sriram Padmanabhan; Jeffrey Scott Vitter; Ramesh Agarwal,Abstract The World Wide Web is growing and changing at an astonishing rate. For theinformation in the web to be useful; web information systems such as search engines haveto keep up with the growth and change of the web. In this paper we study how webdocuments change. In particular; we study two important characteristics of web documentchange that are directly related to keeping web information systems up-to-date: the degreeof the change and the clusteredness of the change. We analyze the evolution of webdocuments with respect to these two measures and discuss the implications for webinformation systems update.,*,2001,53
Supporting ranking and clustering as generalized order-by and group-by,Chengkai Li; Min Wang; Lipyeow Lim; Haixun Wang; Kevin Chen-Chuan Chang,Abstract The Boolean semantics of SQL queries cannot adequately capture the" fuzzy"preferences and" soft" criteria required in non-traditional data retrieval applications. One wayto solve this problem is to add a flavor of" information retrieval" into database queries byallowing fuzzy query conditions and flexibly supporting grouping and ranking of the queryresults within the DBMS engine. While ranking is already supported by all major commercialDBMSs natively; support of flexibly grouping is still very limited (ie; group-by). In this paper;we propose to generalize group-by to enable flexible grouping (clustering specifically) of thequery results. Different from clustering in data mining applications; our focus is on supportingefficient clustering of Boolean results generated at query time. Moreover; we propose tointegrate ranking and clustering with Boolean conditions; forming a new type of …,Proceedings of the 2007 ACM SIGMOD international conference on Management of data,2007,47
SASH: A self-adaptive histogram set for dynamically changing workloads,Lipyeow Lim; Min Wang; Jeffrey Scott Vitter,This chapter presents self-adaptive set of histograms (SASH) that addresses the problem ofbuilding and maintaining a set of histograms. SASH is a novel two-phase method that buildsand maintains an optimal set of histograms using only query feedback information from amultidimensional query workload; without scanning the database. SASH has also provideda unified framework that addresses the problem of which attribute sets to build histogramson; the problem of allocating memory to a set of histograms; and the problem of tuning a setof histograms to the query workload. In the online tuning phase; the current set of histogramsis tuned in response to the estimation error of each query in an online manner. In therestructuring phase; a new and more accurate set of histograms replaces the current set ofhistograms. The new set of histograms is found using information from a batch of query …,Proceedings of the 29th international conference on Very large data bases-Volume 29,2003,47
Scalable mining for classification rules in relational databases,Min Wang; Bala Iyer; Jeffrey Scott Vitter,Classification is a key function of many business intelligence toolkits and a fundamentalbuilding block in data mining. Immense data may be needed to train a classifier for goodaccuracy. The state-of-art classifiers need an in-memory data structure of size O (N); whereN is the size of the training data; to achieve efficiency. For large data sets; such a datastructure will not fit in the internal memory. The best previously known classifier does aquadratic number of I/Os for large N. We propose a novel classification algorithm (classifier)called MIND (MINing in Databases). MIND can be phrased in such a way that itsimplementation is very easy using the extended relational calculus SQL; and this in turnallows the classifier to be built into a relational database system directly. MIND is trulyscalable with respect to I/O efficiency; which is important since scalability is a key …,Database Engineering and Applications Symposium; 1998. Proceedings. IDEAS'98. International,1998,47
A declarative framework for semantic link discovery over relational data,Oktie Hassanzadeh; Lipyeow Lim; Anastasios Kementsietsidis; Min Wang,Abstract In this paper; we present a framework for online discovery of semantic links fromrelational data. Our framework is based on declarative specification of the linkagerequirements by the user; that allows matching data items in many real-world scenarios.These requirements are translated to queries that can run over the relational data source;potentially using the semantic knowledge to enhance the accuracy of link discovery. Ourframework lets data publishers to easily find and publish high-quality links to other datasources; and therefore could significantly enhance the value of the data in the nextgeneration of web.,Proceedings of the 18th international conference on World wide web,2009,46
Rewriting queries on SPARQL views,Wangchao Le; Songyun Duan; Anastasios Kementsietsidis; Feifei Li; Min Wang,Abstract The problem of answering SPARQL queries over virtual SPARQL views iscommonly encountered in a number of settings; including while enforcing security policies toaccess RDF data; or when integrating RDF data from disparate sources. We approach thisproblem by rewriting SPARQL queries over the views to equivalent queries over theunderlying RDF data; thus avoiding the costs entailed by view materialization andmaintenance. We show that SPARQL query rewriting combines the most challengingaspects of rewriting for the relational and XML cases: like the relational case; SPARQL queryrewriting requires synthesizing multiple views; like the XML case; the size of the rewrittenquery is exponential to the size of the query and the views. In this paper; we present the firstnative query rewriting algorithm for SPARQL. For an input SPARQL query over a set of …,Proceedings of the 20th international conference on World wide web,2011,45
Cost-based optimization in DB2 XML,Andrey Balmin; Tom Eliaz; John Hornibrook; Lipyeow Lim; Guy M Lohman; David Simmen; Min Wang; Chun Zhang,DB2 XML is a hybrid database system that combines the relational capabilities of DB2Universal Database™(UDB) with comprehensive native XML support. DB2 XML augmentsDB2® UDB with a native XML store; XML indexes; and query processing capabilities forboth XQuery and SQL/XML that are integrated with those of SQL. This paper presents theextensions made to the DB2 UDB compiler; and especially its cost-based query optimizer; tosupport XQuery and SQL/XML queries; using much of the same infrastructure developed forrelational data queried by SQL. It describes the challenges to the relational infrastructurethat supporting XQuery and SQL/XML poses and provides the rationale for the extensionsthat were made to the three main parts of the optimizer: the plan operators; the cardinalityand cost model; and statistics collection.,IBM Systems Journal,2006,45
EAGRE: Towards scalable I/O efficient SPARQL query evaluation on the cloud,Xiaofei Zhang; Lei Chen; Yongxin Tong; Min Wang,To benefit from the Cloud platform's unlimited resources; managing and evaluating hugevolume of RDF data in a scalable manner has attracted intensive research efforts recently.Progresses have been made on evaluating SPARQL queries with either high-leveldeclarative programming languages; like Pig [1]; or a sequence of sophisticated designedMapReduce jobs; both of which tend to answer the query with multiple join operations.However; due to the simplicity of Cloud storage and the coarse organization of RDF data inexisting solutions; multiple join operations easily bring significant I/O and network trafficwhich can severely degrade the system performance. In this work; we first propose EAGRE;an Entity-Aware Graph compREssion technique to form a new representation of RDF dataon Cloud platforms; based on which we propose an I/O efficient strategy to evaluate …,Data Engineering (ICDE); 2013 IEEE 29th International Conference on,2013,42
gsketch: On query estimation in graph streams,Peixiang Zhao; Charu C Aggarwal; Min Wang,Abstract Many dynamic applications are built upon large network infrastructures; such associal networks; communication networks; biological networks and the Web. Suchapplications create data that can be naturally modeled as graph streams; in which edges ofthe underlying graph are received and updated sequentially in a form of a stream. It is oftennecessary and important to summarize the behavior of graph streams in order to enableeffective query processing. However; the sheer size and dynamic nature of graph streamspresent an enormous challenge to existing graph management techniques. In this paper; wepropose a new graph sketch method; gSketch; which combines well studied synopses fortraditional data streams with a sketch partitioning technique; to estimate and optimize theresponses to basic queries on graph streams. We consider two different scenarios for …,Proceedings of the VLDB Endowment,2011,42
Enabling Interoperability Between Participants in a Network,*,*,*,2008,40
Enabling interoperability between participants in a network,*,*,*,2004,40
A straw shows which way the wind blows: ranking potentially popular items from early votes,Peifeng Yin; Ping Luo; Min Wang; Wang-Chien Lee,Abstract Prediction of popular items in online content sharing systems has recently attracteda lot of attention due to the tremendous need of users and its commercial values. Differentfrom previous works that make prediction by fitting a popularity growth model; we tackle thisproblem by exploiting the latent conforming and maverick personalities of those who vote toassess the quality of on-line items. We argue that the former personality prompts a user tocast her vote conforming to the majority of the service community while on the contrary thelater personality makes her vote different from the community. We thus propose a Conformer-Maverick (CM) model to simulate the voting process and use it to rank top-k potentiallypopular items based on the early votes they received. Through an extensive experimentalevaluation; we validate our ideas and find that our proposed CM model achieves better …,Proceedings of the fifth ACM international conference on Web search and data mining,2012,39
Flexible aggregate similarity search,Yang Li; Feifei Li; Ke Yi; Bin Yao; Min Wang,Abstract Aggregate similarity search; aka aggregate nearest neighbor (Ann) query; findsmany useful applications in spatial and multimedia databases. Given a group Q of M queryobjects; it retrieves the most (or top-k) similar object to Q from a database P; where thesimilarity is an aggregation (eg; sum; max) of the distances between the retrieved object pand all the objects in Q. In this paper; we propose an added flexibility to the query definition;where the similarity is an aggregation over the distances between p and any subset of ÆMobjects in Q for some support 0< Æ d 1. We call this new definition flexible aggregatesimilarity (Fann) search; which generalizes the Ann problem. Next; we present algorithms foranswering Fann queries exactly and approximately. Our approximation algorithms areespecially appealing; which are simple; highly efficient; and work well in both low and …,Proceedings of the 2011 ACM SIGMOD International Conference on Management of data,2011,38
LIEGE:: link entities in web lists with knowledge base,Wei Shen; Jianyong Wang; Ping Luo; Min Wang,Abstract A critical step in bridging the knowledge base with the huge corpus of semi-structured Web list data is to link the entity mentions that appear in the Web lists with thecorresponding real world entities in the knowledge base; which we call list linking task. Thistask can facilitate many different tasks such as knowledge base population; entity searchand table annotation. However; the list linking task is challenging because a Web list hasalmost no textual context; and the only input for this task is a list of entity mentions extractedfrom the Web pages. In this paper; we propose LIEGE; the first general framework to Link theentities in web lists with the knowledge base to the best of our knowledge. Our assumption isthat entities mentioned in a Web list can be any collection of entities that have the sameconceptual type that people have in mind. To annotate the list items in a Web list with …,Proceedings of the 18th ACM SIGKDD international conference on Knowledge discovery and data mining,2012,37
Advances and challenges for scalable provenance in stream processing systems,Archan Misra; Marion Blount; Anastasios Kementsietsidis; Daby Sow; Min Wang,Abstract While data provenance is a well-studied topic in both database and workflowsystems; its support within stream processing systems presents a new set of challenges. Partof the challenge is the high stream event rate and the low processing latency requirementsimposed by many streaming applications. For example; emerging streaming applications inhealthcare or finance call for data provenance; as illustrated in the Century streamprocessing infrastructure that we are building for supporting online healthcare analytics. Atanytime; given an output data element (eg; a medical alert) generated by Century; thesystem must be able to retrieve the input and intermediate data elements that led to itsgeneration. In this paper; we describe the requirements behind our initial implementation ofCentury's provenance subsystem. We then analyze its strengths and limitations and …,*,2008,37
Query optimization through the use of multi-column statistics to avoid the problems of column correlation,*,The system; method; and program of this invention collects multi-column statistics; by adatabase management system; to reflect a relationship among multiple columns of a table ina relational database. These statistics are stored in the system catalog; and are used duringquery optimization to obtain an estimate of the number of qualifying rows when a query haspredicates on multiple columns of a table. A multi-column linear quantile statistic is collectedby dividing the data of multiple columns into sub-ranges where each sub-range hasapproximately an even distribution of data; and determining a frequency and cardinality ofeach sub-range. A multi-column polygonal quantile statistic is collected by dividing the dataof multiple columns into sub-spaces where each sub-space contains approximately thesame number of tuples; and determining a frequency and cardinality of each sub-space …,*,1999,35
A time-and-value centric provenance model and architecture for medical event streams,Min Wang; Marion Blount; John Davis; Archan Misra; Daby Sow,Abstract Provenance becomes a critical requirement for healthcare IT infrastructures;especially when pervasive biomedical sensors act as a source of raw medical streams forlarge-scale; automated clinical decision support systems. Medical and legal requirementswill make it obligatory for such systems to answer queries regarding the underlying datasamples from which output alerts are derived; the IDs of the processing components usedand the privileges of the individuals and software components accessing the medical data.Unfortunately; existing models of either annotation or process based provenance aredesigned for transaction-oriented systems and do not satisfy the unique requirements forsystems processing high-volume; continuous medical streams. This paper proposes asimple; but useful; hybrid provenance model called Time-Value Centric (TVC) …,Proceedings of the 1st ACM SIGMOBILE international workshop on Systems and networking support for healthcare and assisted living environments,2007,34
Wavelet-based cost estimation for spatial queries,Min Wang; Jeffrey Scott Vitter; Lipyeow Lim; Sriram Padmanabhan,Abstract Query cost estimation is an important and well-studied problem in relationaldatabase systems. In this paper we study the cost estimation problem in the context ofspatial database systems. We introduce a new method that provides accurate costestimation for spatial selections; or window queries; by building wavelet-based histogramsfor spatial data. Our method is based upon two techniques:(a) A representationtransformation in which geometric objects are represented by points in higher-dimensionalspace and window queries correspond to semi-infinite range-sum queries; and (b)Multiresolution wavelet decomposition that provides a time-efficient and space-efficientapproximation of the underlying distribution of the multidimensional point data; especially forsemi-infinite range-sum queries. We also show for the first time how a wavelet …,*,2001,32
Optimizing statistical information extraction programs over evolving text,Fei Chen; Xixuan Feng; Christopher Re; Min Wang,Statistical information extraction (IE) programs are increasingly used to build real-world IEsystems such as Alibaba; CiteSeer; Kylin; and YAGO. Current statistical IE approachesconsider the text corpora underlying the extraction program to be static. However; many real-world text corpora are dynamic (documents are inserted; modified; and removed). As thecorpus evolves; and IE programs must be applied repeatedly to consecutive corpussnapshots to keep extracted information up to date. Applying IE from scratch to eachsnapshot may be inefficient: a pair of consecutive snapshots may change very little; butunaware of this; the program must run again from scratch. In this paper; we present CRFlex;a system that efficiently executes such repeated statistical IE; by recycling previous IE resultsto enable incremental update. As the first step; CRFlex focuses on statistical IE programs …,Data Engineering (ICDE); 2012 IEEE 28th International Conference on,2012,31
Method and apparatus for organizing data sources,*,A method for organizing deep Web services is provided. In one aspect; the method obtains acollection of sources and their associated attributes and/or input modes; for instance; using acrawling algorithm. The method uses this information to organize the sources intocommunities. A mining algorithm such as the hyperclique mining algorithm is used to obtaincliques of highly correlated attributes. A clustering algorithm such as the hierarchicalagglomerative clustering algorithm is used to further cluster the cliques of attributes intolarger cliques; which in the present disclosure is referred to as signatures. The sources thatare associated with each signature form a community and a graph representation of thecommunities is constructed; where the vertices are communities and the edges are theshared attributes.,*,2009,28
Silence is also evidence: interpreting dwell time for recommendation from psychological perspective,Peifeng Yin; Ping Luo; Wang-Chien Lee; Min Wang,Abstract Social media is a platform for people to share and vote content. From the analysis ofthe social media data we found that users are quite inactive in rating/voting. For example; auser on average only votes 2 out of 100 accessed items. Traditional recommendationmethods are mostly based on users' votes and thus can not cope with this situation. Basedon the observation that the dwell time on an item may reflect the opinion of a user; we aim toenrich the user-vote matrix by converting the dwell time on items into users'``pseudovotes''and then help improve recommendation performance. However; it is challenging tocorrectly interpret the dwell time since many subjective human factors; eg user expectation;sensitivity to various item qualities; reading speed; are involved into the casual behavior ofonline reading. In psychology; it is assumed that people have choice threshold in …,Proceedings of the 19th ACM SIGKDD international conference on Knowledge discovery and data mining,2013,25
Querying data and an associated ontology in a database management system,*,A method; apparatus; and computer program for querying data and an associated ontologyin a database. An ontology is associated with data in database. Responsive to receiving aquery from a requestor; relational data in the database is identified using the query to formidentified relational data. Ontological knowledge in the ontology is identified using theidentified relational data and the ontology. A result is returned to the requestor.,*,2010,25
Semantic-aware record matching,*,A method of semantic-aware record matching includes receiving source and target stringrecord specifications associated with a source string record and a target string record;receiving semantic knowledge referring to tokens of the source string record and targetstring record; creating a first set of tokens for the source string record and a second set oftokens for the target string record based on the semantic knowledge; assigning a similarityscore to the source string record and the target string record based on a semanticrelationship between the first set of tokens and the second set of tokens; and matching thesource string record and the target string record based on the similarity score.,*,2013,24
Towards efficient join processing over large RDF graph using mapreduce,Xiaofei Zhang; Lei Chen; Min Wang,Abstract Existing solutions for answering SPARQL queries in a shared-nothing environmentusing MapReduce failed to fully explore the substantial scalability and parallelism of thecomputing framework. In this paper; we propose a cost model based RDF join processingsolution using MapReduce to minimize the query responding time as much as possible.After transforming a SPARQL query into a sequence of MapReduce jobs; we propose anovel index structure; called All Possible Join tree (APJ-tree); to reduce the searching spacefor the optimal execution plan of a set of MapReduce jobs. To speed up the join processing;we employ hybrid join and bloom filter for performance optimization. Extensive experimentson real data sets proved the effectiveness of our cost model. Our solution has as much as anorder of magnitude time saving compared with the state of art solutions.,*,2012,23
Dynamic maintenance of web indices using landmarks,*,A repository index records the position of document entries relative to landmark entrieswithin the document. Landmark entries are selecting using a landmarking policy and theirposition relative to the document are stored in a landmark directory. During index updates;an edit transcript is generated describing the difference between old and new documentversions; and both the document repository index and the landmark directory are updated asneeded. Thus; the number of update operations preformed as compared with conventionalindexing techniques may be substantially reduced when small; localized changes are madeto the document. This is due to fact that the positions of document entries are recordedrelative to the landmark entries rather than the document itself. By doing so; the documentindex becomes more shift-invariant; requiring fewer update operations when entries are …,*,2007,23
Selectivity estimation in the presence of alphanumeric correlations,Min Wang; Jeffrey Scott Vitter; Bala Iyer,Query optimization is an integral part of relational database management systems. Oneimportant task in query optimization is selectivity estimation; that is; given a query P; oneneeds to estimate the fraction of records in the database that satisfy P. Almost all previouswork dealt with the estimation of numeric selectivity; ie; the query contains only numericvariables. The general problem of estimating alphanumeric selectivity is much more difficultand has attracted attention only very recently; and the focus has been on the special casewhen only one column is involved. The authors consider the more general case when thereare two correlated alphanumeric columns. They develop efficient algorithms to build storagestructures that can fit in a database catalog. Results from extensive experiments to test thealgorithms; on the basis of error analysis and space requirements; are given to guide …,Data Engineering; 1997. Proceedings. 13th International Conference on,1997,23
Method for supporting ontology-related semantic queries in DBMSs with XML support,*,A method for supporting semantic matching queries in a database management system(DBMS) by extracting and storing the transitive/subsumption relationships from a givenontology data in a DBMS with native XML support. These transitive relationships aretransformed into a set of XML documents that are natural mappings of the hierarchicalstructure of the transitive relationships. A table function construct expresses semanticmatching queries in a declarative manner. The semantic matching queried are automaticallyrewritten or translated into standard SQL/XML search operators such as XQuery; XPath andXMLExists; and executed by the SQL/XML DBMS on the given instance data and theextracted transitive relationships data.,*,2010,22
Method and system for combining ranking and clustering in a database management system,*,A system for combining ranking and clustering in a query. Bit vectors are intersected onBoolean attributes resulting in a vector. Two summary grids are constructed by intersectingbit vectors on clustering and ranking attributes. The vector is intersected with each summarygrid to obtain a filtered clustering and ranking grid. An algorithm is applied on the clusteringgrid to obtain clusters. Vectors associated with buckets in the clusters are intersectedresulting in one vector for each cluster. The vector corresponding to each cluster isintersected with the ranking grid to obtain a modified grid. Buckets are pruned according tobounds of each bucket in the modified grid and a predetermined number to obtain candidatebuckets containing the predetermined number of data. The data are retrieved and a rankingscore is calculated. The top predetermined number of data are sorted according to …,*,2007,22
A graph-based approach for ontology population with named entities,Wei Shen; Jianyong Wang; Ping Luo; Min Wang,Abstract Automatically populating ontology with named entities extracted from theunstructured text has become a key issue for Semantic Web and knowledge managementtechniques. This issue naturally consists of two subtasks:(1) for the entity mention whosemapping entity does not exist in the ontology; attach it to the right category in the ontology(ie; fine-grained named entity classification); and (2) for the entity mention whose mappingentity is contained in the ontology; link it with its mapping real world entity in the ontology (ie;entity linking). Previous studies only focus on one of the two subtasks and cannot solve thistask of populating ontology with named entities integrally. This paper proposes APOLLO; agrAph-based aPproach for pOpuLating ontoLOgy with named entities. APOLLO leveragesthe rich semantic knowledge embedded in the Wikipedia to resolve this task via random …,Proceedings of the 21st ACM international conference on Information and knowledge management,2012,19
Epi-spire: a system for environmental and public health activity monitoring,Chung-Sheng Li; Charu Aggrarwal; Murray Campbell; Yuan-Chi Chang; Gregory Glass; Vijay Iyengar; Mahesh Joshi; Ching-Yung Lin; Milind Naphade; John R Smith; Belle Tseng; Min Wang; Kung-Lung Wu; Philip Yu,Health activity monitoring (HAM) has received increasing attention due to the rapidadvances of both hardware and software technologies and strong environmental and publichealth needs. In this paper; we describe the architecture and implementation of the Epi-SPIRE prototype; which is a novel health activity monitoring system that generates alertsfrom environmental; behavioral; and public health data sources. A model-based approach isused to develop disease and behavior models from multi-modal heterogeneous datasources. Furthermore; a model-based indexing technique has been developed to speed upthe data access and retrieval. This system has been successfully applied to various genuineand simulated diseases outbreaks scenarios'.,Multimedia and Expo; 2003. ICME'03. Proceedings. 2003 International Conference on,2003,19
Prominent streak discovery in sequence data,Xiao Jiang; Chengkai Li; Ping Luo; Min Wang; Yong Yu,Abstract This paper studies the problem of prominent streak discovery in sequence data.Given a sequence of values; a prominent streak is a long consecutive subsequenceconsisting of only large (small) values. For finding prominent streaks; we make theobservation that prominent streaks are skyline points in two dimensions-streak intervallength and minimum value in the interval. Our solution thus hinges upon the idea to separatethe two steps in prominent streak discovery'candidate streak generation and skylineoperation over candidate streaks. For candidate generation; we propose the concept of localprominent streak (LPS). We prove that prominent streaks are a subset of LPSs and thenumber of LPSs is less than the length of a data sequence; in comparison with the quadraticnumber of candidates produced by a brute-force baseline method. We develop efficient …,Proceedings of the 17th ACM SIGKDD international conference on Knowledge discovery and data mining,2011,17
Unifying data and domain knowledge using virtual views,Lipyeow Lim; Haixun Wang; Min Wang,Abstract The database community is on a constant quest for better integration of datamanagement and knowledge management. Recently; with the increasing use of ontology invarious applications; the quest has become more concrete and urgent. However;manipulating knowledge along with relational data in DBMSs is not a trivial undertaking. Inthis paper; we introduce a novel; unified framework for managing data and domainknowledge. We provide the user with a virtual view that unifies the data; the domainknowledge and the knowledge inferable from the data using the domain knowledge.Because the virtual view is in the relational format; users can query the data and theknowledge in a seamlessly integrated manner. To facilitate knowledge representation andinferencing within the database engine; our approach leverages XML support in hybrid …,Proceedings of the 33rd international conference on Very large data bases,2007,15
Century: Automated aspects of patient care,Marion Blount; John Davis; Maria Ebling; Ji Hyun Kim; Kyun Hyun Kim; KangYoon Lee; Archan Misra; SeHun Park; Daby Sow; Young Ju Tak; Min Wang; Karen Witting,Remote health monitoring affords the possibility of improving the quality of health care byenabling relatively inexpensive out-patient care. However; remote health monitoring raisesnew a problem: the potential for data explosion in health care systems. To address thisproblem; the remote health monitoring systems must be integrated with analysis tools thatprovide automated trend analysis and event detection in real time. In this paper; we proposean overview of Century; an extensible framework for analysis of large numbers of remotesensor-based medical data streams.,Embedded and Real-Time Computing Systems and Applications; 2007. RTCSA 2007. 13th IEEE International Conference on,2007,15
Efficient evaluation of composite correlations for streaming time series,Min Wang; X Sean Wang,Abstract In applications ranging from stock trading to space mission operations; it isimportant to monitor the correlations among multiple streaming time series efficiently in orderto make timely decisions. The challenge is that both the number of streaming time series andthe number of interested correlations can be large. The straightforward way of performingthe evaluation by computing the correlation value for each relevant stream pair at each timeposition is not efficient enough in many situations. In this paper; we introduce an efficientmethod for the case where we need to monitor composite correlations; ie; conjunctions ofhigh correlations among multiple pairs of streaming time series. We use a simplemechanism to predict the correlation values of relevant stream pairs at the next time positionand rank the stream pairs carefully so that the pairs that are likely to have low correlation …,*,2003,15
E cient roll-up and drill-down analysis in relational database,Min Wang; Bala Iyer,Abstract Large collections of data; eg archives of POS (pointof-sale) in the consumerpackaged goods as well as in prescription drugs; are typically iteratively classi ed by ahierarchy 6] on the members of some attributes. Most of the fortune 500 businesses havefound ways to consolidate the data archive into a relational database manager. One of themost common steps in\investigative data exploration" is the navigation of the hierarchy toglean valuable insights about the state of the business. The exploration answers\what if"questions; eg; whatif the retailing of toys were discontinued in all stores and an investmentmade for building a retail organization for personal computers. To answer such questions;we are required to take the data associated with the lowest level of the hierarchy (eg; sales)of individual items and sum it up to the ancestor at the highest level of the hierarchy; an …,1997 SIGMOD Workshop on Research Issues on Data Mining and Knowledge Discovery,1997,15
Semantic queries in databases: problems and challenges,Lipyeow Lim; Haixun Wang; Min Wang,Abstract Supporting semantic queries in relational databases is essential to many advancedapplications. Recently; with the increasing use of ontology in various applications; the needfor querying relational data together with its related ontology has become more urgent. Inthis paper; we identify and discuss the problem of querying relational data with itsontologies. Two fundamental challenges make the problem interesting. First; it is extremelydifficult to express queries against graph structured ontology in the relational querylanguage SQL; and second; in many cases where data and its related ontology arecomplicated; queries are usually not precise; that is; users often have only a vague notion;rather than a clear understanding and definition; of what they query for. We outline a query-by-example approach that enables us to support semantic queries in relational databases …,Proceedings of the 18th ACM conference on Information and knowledge management,2009,14
Method and Apparatus for Determining and Validating Provenance Data in Data Stream Processing System,*,*,*,2008,14
REACTOR: a framework for semantic relation extraction and tagging over enterprise data,Wei Shen; Jianyong Wang; Ping Luo; Min Wang; Conglei Yao,Abstract Relation extraction from Web data has attracted a lot of attention in recent years.However; little work has been done when it comes to relation extraction from enterprise dataregardless of the urgent needs to such work in real applications (eg; E-discovery). In thispaper; we propose a novel unsupervised hybrid framework; called REACTOR (abbreviatedfor a fRamework for sEmantic relAtion extraCtion and Tagging Over enteRprise data). Weevaluate REACTOR over a real-world enterprise data set and empirical results show theeffectiveness of REACTOR.,Proceedings of the 20th international conference companion on World wide web,2011,13
Method for merging multiple ranked lists with bounded memory,*,Systems and methods for conducting attribute-based queries over a plurality of objects usingbounded memory locations and minimizing costly input and output operations are provided.A plurality of attributes are associated with each object; and a plurality of data groups; oneeach for the identified attributes are created. The objects associated with the attributes areplaced into the appropriate data groups; and the objects contained within each data groupare sorted into blocks such that each block within a given attribute contains that objectshaving the same attribute value. Results to the query are created by loading blocks into aprimary memory location in a middleware system and combining the loaded blocks to createthe desire query results. Block combinations are created based upon the fit of the givenblock combination to the query as expressed in an aggregation function. A second …,*,2005,13
Incorporating occupancy into frequent pattern mining for high quality pattern recommendation,Linpeng Tang; Lei Zhang; Ping Luo; Min Wang,Abstract Mining interesting patterns from transaction databases has attracted a lot ofresearch interest for more than a decade. Most of those studies use frequency; the numberof times a pattern appears in a transaction database; as the key measure for patterninterestingness. In this paper; we introduce a new measure of pattern interestingness;occupancy. The measure of occupancy is motivated by some real-world patternrecommendation applications which require that any interesting pattern X should occupy alarge portion of the transactions it appears in. Namely; for any supporting transaction t ofpattern X; the number of items in X should be close to the total number of items in t. In thesepattern recommendation applications; patterns with higher occupancy may lead to higherrecall while patterns with higher frequency lead to higher precision. With the definition of …,Proceedings of the 21st ACM international conference on Information and knowledge management,2012,12
Ontology-based searching in database systems,*,A method; information processing system; and computer program storage product retrievedata from a database. A search request is received from a user for a set of data in at leastone database. An ontology query over is performed over at least one ontology associatedwith at least one database resulting in an ontological dataset associated with the searchrequest in response to receiving the search request from the user. The ontological datasetincludes at least one of a set of synonyms; a set of hypernyms; and a set of hyponyms;associated with the search request. A data query is performed over data in the at least onedatabase using the ontological dataset in response to performing the ontology query. Theset of data is returned to the user based on the data query that has been performed.,*,2012,12
Efficient update of indexes for dynamically changing web documents,Lipyeow Lim; Min Wang; Sriram Padmanabhan; Jeffrey Scott Vitter; Ramesh Agarwal,Abstract Recent work on incremental crawling has enabled the indexed document collectionof a search engine to be more synchronized with the changing World Wide Web. However;this synchronized collection is not immediately searchable; because the keyword index isrebuilt from scratch less frequently than the collection can be refreshed. An inverted index isusually used to index documents crawled from the web. Complete index rebuild at highfrequency is expensive. Previous work on incremental inverted index updates have beenrestricted to adding and removing documents. Updating the inverted index for previouslyindexed documents that have changed has not been addressed. In this paper; we proposean efficient method to update the inverted index for previously indexed documents whosecontents have changed. Our method uses the idea of landmarks together with the diff …,World Wide Web,2007,12
Expressing and optimizing similarity-based queries in SQL,Like Gao; Min Wang; X Sean Wang; Sriram Padmanabhan,Abstract Searching for similar objects (in terms of near and nearest neighbors) of a givenquery object from a large set is an essential task in many applications. Recent years haveseen great progress towards efficient algorithms for this task. This paper takes a querylanguage perspective; equipping SQL with the near and nearest search capability by addinga user-defined-predicate; called NN-UDP. The predicate indicates; among a set of objects; ifan object is a near or nearest-neighbor of a given query object. The use of the NN-UDPmakes the queries involving similarity searches intuitive to express. Unfortunately; traditionalcost-based optimization methods that deal with traditional UDPs do not work well for suchSQL queries. Better execution plans are possible with the introduction of a new operator;called NN-OP; which finds the near or nearest neighbors from a set of objects for a given …,*,2004,12
Exploiting entity relationship for query expansion in enterprise search,Xitong Liu; Fei Chen; Hui Fang; Min Wang,Abstract Enterprise search is important; and the search quality has a direct impact on theproductivity of an enterprise. Enterprise data contain both structured and unstructuredinformation. Since these two types of information are complementary and the structuredinformation such as relational databases is designed based on ER (entity-relationship)models; there is a rich body of information about entities in enterprise data. As a result; manyinformation needs of enterprise search center around entities. For example; a user mayformulate a query describing a problem that she encounters with an entity; eg; the webbrowser; and want to retrieve relevant documents to solve the problem. Intuitively;information related to the entities mentioned in the query; such as related entities and theirrelations; would be useful to reformulate the query and improve the retrieval performance …,Information Retrieval,*,12
Provenance query evaluation: what's so special about it?,Anastasios Kementsietsidis; Min Wang,Abstract While provenance has been extensively studied in the literature; the efficientevaluation of provenance queries remains an open problem. Traditional query optimizationtechniques; like the use of general-purpose indexes; or the materialization of provenancedata; fail on different fronts to address the problem. Therefore; the need to developprovenance-aware access methods becomes apparent. This paper starts by identifyingsome key requirements that are to a large extent specific to provenance queries and arenecessary for their efficient evaluation. The first such property; called duality; requires that asingle access method is used to evaluate both backward provenance queries (which inputitems of some analysis generate an output item) and forward provenance queries (whichoutputs of some analysis does an input item generate). The second property; called …,Proceedings of the 18th ACM conference on Information and knowledge management,2009,11
Semantic data management: Towards querying data with their meaning,Lipyeow Lim; Haixun Wang; Min Wang,Relational database management systems are constantly being extended and augmentedto accommodate data in different domains. Recently; with the increasing use of ontology invarious applications; the need to support ontology; especially the related inferencingoperation; in DBMS has become more concrete and urgent. However; manipulatingknowledge along with relational data in DBMSs is not a trivial undertaking due to themismatch in data models. In this paper; we introduce a framework for managing relationaldata and hierarchical domain knowledge together. Our framework persists taxonomiescontained in ontologies by leveraging XML support in hybrid relational-XML DBMSs (eg;IBM's DB2 v9) and rewrites ontology-based semantic matching queries using the industry-standard query languages; SQL/XML and XQuery. Compared with previous approaches …,Data Engineering; 2007. ICDE 2007. IEEE 23rd International Conference on,2007,11
Query processing method of name-value pairs in relational databases,*,Electronic marketplaces typically apply catalog schema in the format of name-value pairs tostore product attribute names and values to achieve a very high degree of flexibility. Thisvertical schema approach prevents traditional relational database management systemsfrom accurately estimating constraint selectivity and generating efficient query plans. In thisinvention; methods and systems are disclosed for building and maintaining externalhistograms and a query planner uses these external histograms to assist query planning inrelational databases.,*,2002,11
Optimizing content freshness of relations extracted from the web using keyword search,Mohan Yang; Haixun Wang; Lipyeow Lim; Min Wang,Abstract An increasing number of applications operate on data obtained from the Web.These applications typically maintain local copies of the web data to avoid network latencyin data accesses. As the data on the Web evolves; it is critical that the local copy be kept up-to-date. Data freshness is one of the most important data quality issues; and has beenextensively studied for various applications including web crawling. However; web crawlingis focused on obtaining as many raw web pages as possible. Our applications; on the otherhand; are interested in specific content from specific data sources. Knowing the content orthe semantics of the data enables us to differentiate data items based on their importanceand volatility; which are key factors that impact the design of the data synchronizationstrategy. In this work; we formulate the concept of content freshness; and present a novel …,Proceedings of the 2010 ACM SIGMOD International Conference on Management of data,2010,10
Toward detection of aliases without string similarity,Ning An; Lili Jiang; Jianyong Wang; Ping Luo; Min Wang; Bing Nan Li,Abstract Entity aliases commonly exist. Accurately detecting these aliases plays a vital rolein various applications. In particular; it is critical to detect the aliases that are intentionallyhidden from the real identities; such as those of terrorists and frauds. Most existing workdoes not pay close attention to the aliases that have low/no string similarity to the givenentities. In this paper; we propose a classifier that is based on active learning for detectingthis type of aliasing. To minimize the cost of pair-wise comparison; a subset-based method isdesigned to restrict the selection within entity subsets. An active learning classifier is thenemployed in each entity subset to find the probability of whether a candidate is the alias of agiven entity within the subset. After all of the results from the classifier are integrated; a list ofaliases is returned for each given entity. For evaluation; we implemented four state-of-the …,Information Sciences,2014,9
GRIAS: An Entity-Relation Graph Based Framework for Discovering Entity Aliases,Lili Jiang; Ping Luo; Jianyong Wang; Yuhong Xiong; Bingduan Lin; Min Wang; Ning An,Recognizing the various aliases of an entity is a critical task for many applications; includingWeb search; recommendation system; and e-discovery. The goal of this paper is toaccurately identify entity aliases; especially the long tail ones in the unstructured data. Oursolution GRIAS (abbr. for a Graph-based framework for discovering entity Aliases) ismotivated by the entity relationships collected from both the structured and unstructureddata. These relationships help to build an entity-relation graph; and the graph-basedsimilarity is calculated between an entity and its alias candidates which are first chosen byour proposed candidate selection method. Extensive experimental results on two real-worlddatasets demonstrate both the effectiveness and efficiency of the proposed framework.,Data Mining (ICDM); 2013 IEEE 13th International Conference on,2013,9
Indexing provenance data and evaluating provenance data queries in data processing systems,*,*,*,2009,9
On the efficiency of provenance queries,Anastasios Kementsietsidis; Min Wang,While models for data provenance have been extensively studied in the literature; theefficient evaluation of the resulting provenance queries remains an open problem.Traditional query optimization techniques; like the use of general-purpose indexes; or thematerialization of provenance data; fail on different fronts to address the problem.Provenance-specific optimization techniques; like the use of customized indexes; similarlyprove inadequate since the techniques are bound to specific provenance models. Therefore;the need to develop generic provenance-aware techniques quickly becomes apparent. Inthis paper; we argue for such a generic technique in the form of a provenance indexstructure that can be used to efficiently evaluate provenance queries ina variety of contexts.By highlighting the limitations of existing techniques; we identify the set of key properties …,Data Engineering; 2009. ICDE'09. IEEE 25th International Conference on,2009,9
Supporting ontology-based keyword search over medical databases,Anastasios Kementsietsidis; Lipyeow Lim; Min Wang,Abstract The proliferation of medical terms poses a number of challenges in the sharing ofmedical information among different stakeholders. Ontologies are commonly used toestablish relationships between different terms; yet their role in querying has not beeninvestigated in detail. In this paper; we study the problem of supporting ontology-basedkeyword search queries on a database of electronic medical records. We present severalapproaches to support this type of queries; study the advantages and limitations of eachapproach; and summarize the lessons learned as best practices.,AMIA Annual Symposium Proceedings,2008,9
Wiki3C: exploiting wikipedia for context-aware concept categorization,Peng Jiang; Huiman Hou; Lijiang Chen; Shimin Chen; Conglei Yao; Chengkai Li; Min Wang,Abstract Wikipedia is an important human generated knowledge base containing over 21million articles organized by millions of categories. In this paper; we exploit Wikipedia for anew task of text mining: Context-aware Concept Categorization. In the task; we focus oncategorizing concepts according to their context. We exploit article link feature and categorystructure in Wikipedia; followed by introducing Wiki3C; an unsupervised and domainindependent concept categorization approach based on context. In the approach; weinvestigate two strategies to select and filter Wikipedia articles for the categoryrepresentation. Besides; a probabilistic model is employed to compute the semanticrelatedness between two concepts in Wikipedia. Experimental evaluation using manuallylabeled ground truth shows that our proposed Wiki3C can achieve a noticeable …,Proceedings of the sixth ACM international conference on Web search and data mining,2013,8
Towards alias detection without string similarity: an active learning based approach,Lili Jiang; Jianyong Wang; Ping Luo; Ning An; Min Wang,Abstract Entity aliases commonly exist and accurately detecting these aliases plays a vitalrole in various applications. In this paper; we use an active-learning-based method to detectaliases without string similarity. To minimize the cost on pairwise comparison; a subset-based method restricts the alias selection within a small-scale entity set. Within eachgenerated entity set; an active learning based logistic regression classifier is employed topredict whether a candidate is the alias of a given entity. The experimental results on threedatasets clearly demonstrate that our proposed approach can effectively detect this kind ofentity aliases.,Proceedings of the 35th international ACM SIGIR conference on Research and development in information retrieval,2012,8
Search result diversification for enterprise data,Wei Zheng; Hui Fang; Conglei Yao; Min Wang,Abstract Search result diversification aims to return a list of diversified relevant documents inorder to satisfy different user information needs. Most of the efforts focused on Web Search;and few studies have considered another important search domain; ie; enterprise search.Unlike Web search; enterprise search deals with both unstructured and structured data. Inthis paper; we propose to integrate the structured and unstructured data to discovermeaningful query subtopics in search result diversification. Experimental results show thatintegrating structured and unstructured information allows us to discover high quality query;which are effective in diversifying the retrieval results.,Proceedings of the 20th ACM international conference on Information and knowledge management,2011,8
Supporting efficient parametric search of e-commerce data: a loosely-coupled solution,Min Wang; Yuan-Chi Chang; Sriram Padmanabhan,Abstract Electronic commerce is emerging as a major application area for database systems.A large number of e-commerce sites provide electronic product catalogs that allow users tosearch products of interest. Due to the constant evolution and the high sparsity of e-commerce data; most commercial e-commerce systems use the so-called vertical schemafor data storage. However; query processing for data stored using vertical schema isextremely slow because current RDBMS; especially its costbased query optimizer; isdesigned to deal with traditional horizontal schema efficiently. Most e-commerce systemswould like to offer advanced parametric search capabilities to their users. However; mostsearches are expected to be online which means that the query execution should be veryfast. RDBMSs require new capabilities and enhancements before they can satisfy the …,*,2002,8
Approximation and learning techniques in database systems,Min Wang; Jeffrey S Vitter,Abstract In this thesis; we study two important techniques that are widely used in databasesystems: approximation and learning. Approximation has been an area of great interest andimportance in database community. A classic example of using approximation in databasesystems is selectivity estimation. Another example is using approximation techniques toanswer OLAP On-Line Analytical Processing queries; which is quite new and is initiated byour work.,*,1999,8
From Social User Activities to People Affiliation,Guangxiang Zeng; Ping Luo; Enhong Chen; Min Wang,This study addresses the problem of inferring users' employment affiliation information fromsocial activities. It is motivated by the applications which need to monitoring and analyzingthe social activities of the employees from a given company; especially their social tracksrelated to the work and business. It definitely helps to better understand their needs andopinions towards certain business area; so that the account sales targeting these customersin the given company can adjust the sales strategies accordingly. Specifically; in this task weare given a snapshot of a social network and some labeled social users who are theemployees of a given company. Our goal is to identify more users from the same company.We formulate this problem as a task of classifying nodes over a graph; and develop aSupervised Label Propagation model. It naturally incorporates the rich set of features for …,Data Mining (ICDM); 2013 IEEE 13th International Conference on,2013,7
A learning-based approach to estimate statistics of operators in continuous queries: a case study,Like Gao; Min Wang; X Sean Wang; Sriram Padmanabhan,Abstract Statistic estimation such as output size estimation of operators is a well-studiedsubject in the database research community; mainly for the purpose of query optimization.The assumption; however; is that queries are ad-hoc and therefore the emphasis has beenon capturing the data distribution. When long standing continuous queries on a changingdatabase are concerned; a more direct approach; namely building an estimation model foreach operator; is possible. In this paper; we propose a novel learning-based method. Ourmethod consists of two steps. The first step is to design a dedicated feature extractionalgorithm that can be used incrementally to obtain feature values from the underlying data.The second step is to use a data mining algorithm to generate an estimation model basedon the feature values extracted from the historical data. To illustrate the approach; this …,Proceedings of the 8th ACM SIGMOD workshop on Research issues in data mining and knowledge discovery,2003,7
Harnessing the wisdom of the crowds for accurate web page clipping,Lei Zhang; Linpeng Tang; Ping Luo; Enhong Chen; Limei Jiao; Min Wang; Guiquan Liu,Abstract Clipping Web pages; namely extracting the informative clips (areas) from Webpages; has many applications; such as Web printing and e-reading on small handhelddevices. Although many existing methods attempt to address this task; most of them caneither work only on certain types of Web pages (eg; news-and blog-like web pages); orperform semi-automatically where extra user efforts are required in adjusting the outputs.The problem of clipping any types of Web pages accurately in a totally automatic wayremains pretty much open. To this end in this study we harness the wisdom of the crowds toprovide accurate recommendation of informative clips on any given Web pages. Specifically;we leverage the knowledge on how previous users clip similar Web pages; and thisknowledge repository can be represented as a transaction database where each …,Proceedings of the 18th ACM SIGKDD international conference on Knowledge discovery and data mining,2012,6
AWETO: Efficient incremental update and querying in rdf storage system,Xu Pu; Jianyong Wang; Ping Luo; Min Wang,Abstract With the fast growth of the knowledge bases built over the Internet; storing andquerying millions or billions of RDF triples in a knowledge base have attracted increasingresearch interests. Although the latest RDF storage systems achieve good queryingperformance; few of them pay much attention to the characteristic of dynamic growth of theknowledge base. In this paper; to consider the efficiency of both querying and incrementalupdate in RDF data; we propose a hAsh-based tWo-tiEr rdf sTOrage system (abbr. toAWETO) with new index architecture and query execution engine. The performance of oursystem is systematically measured over two large-scale datesets. Compared with the otherthree state-of-the-art RDF storage systems; our system achieves the best incremental updateefficiency; meanwhile; the query efficiency is competitive.,Proceedings of the 20th ACM international conference on Information and knowledge management,2011,6
Database query optimizations,*,A method of processing a query is provided. The method includes performing on aprocessor: receiving a database query that includes a plurality of predicates that associate asubject with an object; where one or more of the predicates is a variable predicate;generating at least one new query by selectively replacing the at least one variablepredicate in the database query with a non-variable predicate; and performing the at leastone new database query on a database to obtain a query result.,*,2010,6
Scalable Matching of Industry Models-a Case Study.,Brian Byrne; Achille Fokoue; Aditya Kalyanpur; Kavitha Srinivas; Min Wang,Abstract. A recent approach to the problem of ontology matching has been to convert theproblem of ontology matching to information retrieval. We explore the utility of this approachin matching model elements of real UML; ER; EMF and XML-Schema models; where thesemantics of the models are less precisely defined. We validate this approach with domainexperts for industry models drawn from very different domains (healthcare; insurance; andbanking). We also observe that in the field; manually constructed mappings for such largeindustry models are prone to serious errors. We describe a novel tool we developed todetect suspicious mappings to quickly isolate these errors.,OM,2009,6
Managing e-Commerce catalogs in a DBMS with native XML support,Lipyeow Lim; Min Wang,Electronic commerce is emerging as a major application area for database systems. A largenumber of e-commerce stores provide electronic product catalogs that allow customers tosearch products of interest and store owners to manage various product information. Due tothe constant schema evolution and the sparsity of e-commerce data; most commercial e-commerce systems use the so-called vertical schema for data storage. However; queryprocessing for data stored using vertical schema is extremely inefficient because currentRDBMSs; especially its cost-based query optimizer; are specifically designed to deal withtraditional horizontal schemas. In this paper; we show that e-catalog management can benaturally supported in IBM's system RX; the first DBMS that truly supports both XML andrelational data in their native forms. By leveraging on system RX's hybrid nature; we …,e-Business Engineering; 2005. ICEBE 2005. IEEE International Conference on,2005,6
Leveraging integrated information to extract query subtopics for search result diversification,Wei Zheng; Hui Fang; Conglei Yao; Min Wang,Abstract Search result diversification aims to diversify search results to cover different querysubtopics; ie; pieces of relevant information. The state of the art diversification methods oftenexplicitly model the diversity based on query subtopics; and their performance is closelyrelated to the quality of subtopics. Most existing studies extracted query subtopics only fromthe unstructured data such as document collections. However; there exists a huge amount ofinformation from structured data; which complements the information from the unstructureddata. The structured data can provide valuable information about domain knowledge; but iscurrently under-utilized. In this article; we study how to leverage the integrated informationfrom both structured and unstructured data to extract high quality subtopics for search resultdiversification. We first discuss how to extract subtopics from structured data. We then …,Information Retrieval,2014,5
Finding the plateau in an aggregated time series,Min Wang; X Sean Wang,Abstract Given d input time series; an aggregated series can be formed by aggregating the dvalues at each time position. It is often useful to find the time positions whose aggregatedvalues are the greatest. Instead of looking for individual top-k time positions; this paper givestwo algorithms for finding the time interval (called the plateau) in which the aggregatedvalues are close to each other (within a given threshold) and are all no smaller than theaggregated values outside of the interval. The first algorithm is a centralized one assumingthat all data are available at a central location; and the other is a distributed search algorithmthat does not require such a central location. The centralized algorithm has a linear timecomplexity with respect to the length of the time series; and the distributed algorithmemploys the Threshold Algorithm by Fagin et al. and is quite efficient in reducing the …,*,2006,5
LogKV: Exploiting Key-Value Stores for Log Processing.,Zhao Cao; Shimin Chen; Feifei Li; Min Wang; Xiaoyang Sean Wang,ABSTRACT Event log processing and analysis play a key role in applications ranging fromsecurity management; IT trouble shooting; to user behavior analysis. Recent years haveseen a rapid growth in system scales and the corresponding rapid increase in the amount oflog event data. At the same time; as logs are found to be a valuable information source; loganalysis tasks have become more sophisticated demanding both interactive exploratoryquery processing and batch computation. Desirable query types include selection with timeranges and value filtering criteria; join within time windows; join between log data andreference tables; and various aggregation types. In such a situation; parallel solutions arenecessary; but existing parallel and distributed solutions either support limited query typesor perform only batch computations on logs. With a system called LogKV; this paper …,CIDR,2013,4
Semantic Link Discovery over Relational Data,Oktie Hassanzadeh; Anastasios Kementsietsidis; Lipyeow Lim; Renée J Miller; Min Wang,Abstract To make semantic search a reality; we need to be able to efficiently publish largedata sets containing rich semantic structure. We have tools for translating relational andsemi-structured data into RDF; but such translation tools do not have the goal of adding orproviding the kind of semantics necessary to achieve the goals of the Semantic Web andsemantic search over the Web. In this chapter; we present LinQuer; a tool for creatingsemantic links within a data source and between data sources. We focus on link discoveryover structured (relational) data since many Semantic Web sources are the result ofpublishing relational data as RDF and since relational engines provide the scalability andflexibility we need for large scale link discovery. The LinQuer framework is based on thedeclarative specification of linkage requirements by a user. We present algorithms for …,*,2012,4
Finding relevant information of certain types from enterprise data,Xitong Liu; Hui Fang; Cong-Lei Yao; Min Wang,Abstract Search over enterprise data is essential to every aspect of an enterprise because ithelps users fulfill their information needs. Similar to Web search; most queries in enterprisesearch are keyword queries. However; enterprise search is a unique research problembecause; compared with the data in traditional IR applications (eg; text data); enterprise dataincludes information stored in different formats. In particular; enterprise data include bothunstructured and structured information; and all the data center around a particularenterprise. As a result; the relevant information from these two data sources could becomplementary to each other. Intuitively; such integrated data could be exploited to improvethe enterprise search quality. Despite its importance; this problem has received littleattention so far. In this paper; we demonstrate the feasibility of leveraging the integrated …,Proceedings of the 20th ACM international conference on Information and knowledge management,2011,4
Semantic Link Discovery,*,A method of semantic link discovery through translation of basic declarative languageincludes receiving a set of linkage specifications; receiving a set of data sources related tothe linkage specifications; the set of data sources and the set of linkage requirementsforming a basic declarative language query; translating the basic declarative languagequery into a standard language query; executing the standard language query; andreturning results of the standard language query in response to the executing.,*,2009,4
Condition evaluation for speculative systems: a streaming time series case,X Sean Wang; Like Gao; Min Wang,Abstract Application systems often need to react with certain actions whenever some presetconditions are satisfied. In many cases; the evaluation of these conditions takes long time;but some prediction of the results can be obtained rather quickly. In this situation;speculation may be a good idea. That is; the system takes predictions (speculation) toprepare (such as prefetch) for the possible reaction. Obviously; the risk is wasted efforts dueto false alarms. Higher precision prediction results in less waste; but takes longer time andmay reduce/eliminate the opportunity for speculation. A balance needs to be struck. A quality-driven prediction subsystem is thus necessary; so that the “user” of the prediction subsystemcan impose quality (in terms of precision and response-time) requirements. This paperfocuses on such a prediction subsystem with conditions on streaming time series. Two …,Toronto; Canada; August 30; 2004,2004,4
Entity centric query expansion for enterprise search,Xitong Liu; Hui Fang; Fei Chen; Min Wang,Abstract Enterprise search is important; and the search quality has a direct impact on theproductivity of an enterprise. Many information needs of enterprise search center aroundentities. Intuitively; information related to the entities mentioned in the query; such as relatedentities; would be useful to reformulate the query and improve the retrieval performance.However; most existing studies on query expansion are term-centric. In this paper; wepropose a novel entity-centric query expansion framework for enterprise search. Specifically;given a query containing entities; we first utilize both unstructured and structured informationto find entities that are related to the ones in the query. We then discuss how to adaptexisting feedback methods to use the related entities to improve search quality. Experimentresults show that the proposed entity-centric query expansion strategy is more effective to …,Proceedings of the 21st ACM international conference on Information and knowledge management,2012,3
Enforcing query policies over resource description framework data,*,*,*,2010,3
Profile-based retrieval of records in medical databases,Anastasios Kementsietsidis; Lipyeow Lim; Min Wang,Abstract Ontologies establish relationships between different terms; yet their potential inquerying has not yet been fully realized. In this paper; we study the problem of ontology-supported profile-based retrieval of medical records. We present an algorithm that providestwo independent techniques (used in isolation or in unison) to address the shortcomings ofexisting keyword-based retrieval solutions; and provide an implementation and experimentsto illustrate the merits of our approach.,AMIA Annual Symposium Proceedings,2009,3
Quality-driven evaluation of trigger conditions on streaming time series,Like Gao; Min Wang; X Sean Wang,Abstract For many applications; it is important to evaluate trigger conditions on time seriesstreams. In a resource constrained environment; users' needs should ultimately decide howthe evaluation system balances the competing factors such as evaluation speed; resultprecision; and load shedding level. This paper presents a basic framework for evaluationalgorithms that takes user-specified quality requirements into consideration. Threeoptimization algorithms; each under a different set of quality requirements; are developed inthe framework:(1) minimize the response time given accuracy requirements and without loadshedding;(2) minimize the load shedding given a response time limit and accuracyrequirements; and (3) minimize one type of accuracy errors given a response time limit andwithout load shedding. Experiments show that these optimization algorithms effectively …,Proceedings of the 2005 ACM symposium on Applied computing,2005,3
Efficient incremental update and querying in AWETO RDF storage system,Xu Pu; Jianyong Wang; Zhenhua Song; Ping Luo; Min Wang,Abstract With the fast growth of the knowledge bases built over the Internet; storing andquerying millions or billions of RDF triples in a knowledge base have attracted increasingresearch interests. Although the latest RDF storage systems achieve good queryingperformance; few of them pay much attention to the characteristic of dynamic growth of theknowledge base. Since the building of the knowledge base is usually a continuous process;incremental update over the RDF storage system is in great need. In this paper; to considerthe efficiency of both querying and incremental update in RDF data; we propose ah Ash-based tWo-tiEr rdf sTOrage system (abbr. to AWETO) with new index architecture and queryexecution engine. The performance of our system is systematically measured over two large-scale datasets. Compared with the other three state-of-the-art open source RDF storage …,Data & Knowledge Engineering,2013,2
Modeling and querying E-commerce data in hybrid relational-XML DBMSs,Lipyeow Lim; Haixun Wang; Min Wang,Abstract Data in many industrial application systems are often neither completely structurednor unstructured. Consequently semi-structured data models such as XML have becomepopular as a lowest common denominator to manage such data. The problem is thatalthough XML is adequate to represent the flexible portion of the data; it fails to exploit thehighly structured portion of the data. XML normalization theory could be used to factor outthe structured portion of the data at the schema level; however; queries written against theoriginal schema no longer run on the normalized XML data. In this paper; we propose a newapproach called eXtricate that stores XML documents in a space-efficient decomposed waywhile supporting efficient processing on the original queries. Our method exploits the factthat considerable amount of information is shared among similar XML documents; and by …,*,2008,2
Persisting and querying biometric event streams with hybrid relational-XML DBMS,Daby M Sow; Lipyeow Lim; Min Wang; Kyu Hyun Kim,Abstract Remote monitoring of patients' biometric data streams offers the possibility tophysicians to extend and improve their services to chronically ill patients who are away frommedical institutions. This emerging technology is a promising way to address importantaspects of the cost issues that most health care systems are experiencing. In order to fulfill itspotential; several challenges need to be overcome. First; the data collected needs to befiltered and annotated intelligently to help physicians cope with and navigate the largeamount of patient sensor data received as a result of large scale remote health monitoringdeployments. Secondly; efficient stream persistence and query mechanisms for these dataneed to be designed to satisfy health care regulations and help physicians track patienthealth histories accurately and efficiently. In this paper; we concentrate on the second …,Proceedings of the 2007 inaugural international conference on Distributed event-based systems,2007,2
APOLLO: a general framework for populating ontology with named entities via random walks on graphs,Wei Shen; Jianyong Wang; Ping Luo; Min Wang,Abstract Automatically populating ontology with named entities extracted from theunstructured text has become a key issue for Semantic Web. This issue naturally consists oftwo subtasks:(1) for the entity mention whose mapping entity does not exist in the ontology;attach it to the right category in the ontology (ie; fine-grained named entity classification);and (2) for the entity mention whose mapping entity is contained in the ontology; link it withits mapping real world entity in the ontology (ie; entity linking). Previous studies only focuson one of the two subtasks. This paper proposes APOLLO; a general weakly supervisedfrAmework for POpuLating ontoLOgy with named entities. APOLLO leverages the richsemantic knowledge embedded in the Wikipedia to resolve this task via random walks ongraphs. An experimental study has been conducted to show the effectiveness of APOLLO.,Proceedings of the 21st international conference companion on World Wide Web,2012,1
Semantic query by example,Lipyeow Lim; Haixun Wang; Min Wang,ABSTRACT Supporting semantic queries in relational databases is essential to manyadvanced applications. Recently; with the increasing use of ontology in various applications;the need for querying relational data togther with its related ontology has become moreurgent. In this paper; we identify two fundamental challenges in this task. First; it is extremelydifficult to express queries against graph structured ontology in the relational querylanguage SQL; and second; in many cases where data and its related ontology arecomplicated; queries are usually not precise; that is; users often have only a vague notion;rather than a clear understanding and definition; of what they query for. To address the twochallenges; we introduce a novel method that enables us to support semantic queries inrelational databases with ease. Instead of endeavoring to incorporate ontology into …,Proceedings of the ACM 18th Conference on Information and Knowledge Management (CIKM),2008,1
Evaluating Trigger Conditions on Streaming Time Series with User-given Quality Requirements.,Like Gao; Min Wang; Xiaoyang Sean Wang,Abstract: For many applications; it is important to evaluate trigger conditions on streamingtime series. In a resource constrained environment; users' needs should ultimately decidehow the evaluation system balances the competing factors such as evaluation speed; resultprecision; and load shedding level. This paper presents a basic framework for evaluationalgorithms that takes user-specified quality requirements into consideration. Threeoptimization algorithms; each under a different set of userdefined probabilistic qualityrequirements; are provided in the framework:(1) minimize the response time given accuracyrequirements and without load shedding;(2) minimize the load shedding given a responsetime limit and accuracy requirements; and (3) minimize one type of accuracy errors given aresponse time limit and without load shedding. Experiments show that these optimization …,J. UCS,2005,1
Optimizing relational store for e-catalog queries: a data mining approach,Min Wang; X Sean Wang,Abstract A frequent use of database management systems in electronic commerce is toprovide electronic product catalogs (e-catalogs) that allow users to search for products ofinterest via constraints on attributes. An intuitively straightforward representation of e-catalogs is to use one table for the whole e-catalog as it is conceptually easy to maintain andquery. However; for any e-commerce business with a reasonably large number of productsand product types; its e-catalog usually involves a large number of attributes due to the greatvariety of the products; and at the same time; contains a large number of null values due tothe fact that each product only has values under a relatively small number of attributes.Because of these properties; the above intuitive method does not work well in currentrelational database systems. Techniques have been proposed in the literature to deal …,Proceedings of the 2002 ACM symposium on Applied computing,2002,1
iPLUG: Personalized List Recommendation in Twitter,Lijiang Chen; Yibing Zhao; Shimin Chen; Hui Fang; Chengkai Li; Min Wang,Abstract A Twitter user can easily be overwhelmed by flooding tweets from her followees;making it challenging for the user to find interesting and useful information in tweets. Thefeature of Twitter Lists allows users to organize their followees into multiple subsets forselectively digesting tweets. However; this feature has not received wide reception becauseusers are reluctant to invest initial efforts in manually creating lists. To address the challengeof bootstrapping Twitter Lists; we envision a novel tool that automatically createspersonalized Twitter Lists and recommends them to users. Compared with lists created byreal Twitter users; the lists generated by our algorithms achieve 73.6% similarity.,*,2013,*
Modeling autonomous catalog for electronic commerce,Yuan-Chi Chang; Vamsavardhana R Chillakuru; Min Wang,Abstract The catalog function is an essential feature in B2C and B2B e-commerce. Whilecatalog is primarily for end users to navigate and search for interested products; other e-commerce functions such as merchandising; order; inventory and aftermarket constantlyrefer to information stored in the catalog [1]. The billion-dollar mail order business wascreated around catalog long before e-commerce. More opportunities surface after catalogcontent previously created on paper is digitized. While catalog is recognized as a necessityfor a successful web store; its content structure varies greatly across industries and alsowithin each industry. Product categories; attributes; measurements; languages; and currencyall contribute to the wide variations; which create a difficult dilemma for catalog designers.,*,2004,*
MIND: A Scalable Classifier in Relational Databases,Min Wang; Bala Iyer; Jeffrey Scott Vitter,Abstract Classification is a key function of many business intelligence" toolkits and afundamental building block in data mining. The best known results indicate that immensedata may be needed to train a classifier for good accuracy. The state-of-art classifiers 21; 25need an in-memory data structure of size ON; where N is the size of the training data; toachieve efficiency. For large data sets; such a data structure will not fit in the internalmemory. The best previously known classifier does a quadratic number of I Os for large N. Inthis paper; we propose a novel classification algorithm classifier called MIND MINing inDatabases. MIND can be phrased in such a way that its implementation is very easy usingthe extended relational calculus SQL; and this in turn allows the classifier to be built into arelational database system directly. MIND is truly scalable with respect to IO efficiency …,*,1999,*
Efficient Roll-Up and Drill-Down Analysis for Large Data,Min Wang; Bala Iyer,*,*,*,*
IBM Santa Teresa Lab balaiyer@ vnet. ibm. com,Min Wang; Bala Iyer; Jeffrey Scott Vitter,*,*,*,*
