The SAP HANA Database--An Architecture Overview.,Franz Färber; Norman May; Wolfgang Lehner; Philipp Große; Ingo Müller; Hannes Rauhe; Jonathan Dees,Abstract Requirements of enterprise applications have become much more demanding.They require the computation of complex reports on transactional data while thousands ofusers may read or update records of the same data. The goal of the SAP HANA database isthe integration of transactional and analytical workload within the same databasemanagement system. To achieve this; a columnar engine exploits modern hardware(multiple CPU cores; large main memory; and caches); compression of database content;maximum parallelization in the database kernel; and database extensions required byenterprise applications; eg; specialized data structures for hierarchies or support for domainspecific languages. In this paper we highlight the architectural concepts employed in theSAP HANA database. We also report on insights gathered with the SAP HANA database …,IEEE Data Eng. Bull.,2012,191
Vectorizing Database Column Scans with Complex Predicates.,Thomas Willhalm; Ismail Oukid; Ingo Müller; Franz Faerber,ABSTRACT The performance of the full table scan is critical for the overall performance ofcolumn-store database systems such as the SAP HANA database. Compressing theunderlying column data format is both an advantage and a challenge; because it reducesthe data volume involved in a scan on one hand and introduces the need for decompressionduring the scan on the other hand. In previous work [26] we have shown how to acceleratethe column-scan with range predicates using SIMD instructions. In this paper; we present aframework for vectorized scans with more complex predicates. One important building blockis the In-List predicate; where all rows whose values are contained in a given list of valuesare selected. While this seems to exhibit only little data parallelism on first sight; we showthat a performant vectorized implementation is possible using the new Intel AVX2 …,ADMS@ VLDB,2013,41
Cache-efficient aggregation: Hashing is sorting,Ingo Müller; Peter Sanders; Arnaud Lacurie; Wolfgang Lehner; Franz Färber,Abstract For decades researchers have studied the duality of hashing and sorting for theimplementation of the relational operators; especially for efficient aggregation. Dependingon the underlying hardware and software architecture; the specifically implementedalgorithms; and the data sets used in the experiments; different authors came to differentconclusions about which is the better approach. In this paper we argue that in terms of cacheefficiency; the two paradigms are actually the same. We support our claim by showing thatthe complexity of hashing is the same as the complexity of sorting in the external memorymodel. Furthermore we make the similarity of the two approaches obvious by designing analgorithmic framework that allows to switch seamlessly between hashing and sorting duringexecution. The fact that we mix hashing and sorting routines in the same algorithmic …,Proceedings of the 2015 ACM SIGMOD International Conference on Management of Data,2015,23
Communication Efficient Algorithms for Fundamental Big Data Problems,Peter Sanders; Sebastian Schlag; Ingo Müller,Big Data applications often store or obtain their data distributed over many computersconnected by a network. Since the network is usually slower than the local memory of themachines; it is crucial to process the data in such a way that not too much communicationtakes place. Indeed; only communication volume sublinear in the input size may beaffordable. We believe that this direction of research deserves more intensive study. We giveexamples for several fundamental algorithmic problems where nontrivial algorithms withsublinear communication volume are possible. Our main technical contribution are severalrelated results on distributed Bloom filter replacements; duplicate detection; and data basejoin. As an example of a very different family of techniques; we discuss linear programmingin low dimensions.,IEEE BigData Conference,2013,20
Aggregation in parallel computation environments with shared memory,*,According to some embodiments; a data structure may be provided by separating an inputtable into a plurality of partitions; generating; by each of a first plurality of execution threadsoperating concurrently; a local hash table for each of the threads; each local hash tablestoring key—index pairs; and merging the local hash tables; by a second plurality ofexecution threads operating concurrently; to produce a set of disjoint result hash tables. Anoverall result may be obtained from the result set of disjoint result hash tables. The datastructure may used in a parallel computing environment to determine an aggregation.,*,2012,19
Adaptive String Dictionary Compression in In-Memory Column-Store Database Systems,Ingo Müller; Cornelius Ratsch; Franz Faerber,ABSTRACT Domain encoding is a common technique to compress the columns of a columnstore and to accelerate many types of queries at the same time. It is based on theassumption that most columns contain a relatively small set of distinct values; in particularstring columns. In this paper; we argue that domain encoding is not the end of the story. Inreal world systems; we observe that a substantial amount of the columns are of string types.Moreover; most of the memory space is consumed by only a small fraction of these columns.To address this issue; we make three main contributions: First we survey severalapproaches and variants for dictionary compression; ie; data structures that store thedictionary of domain encoding in a compressed way. As expected; there is a trade-offbetween size of the data structure and its access performance. This observation can be …,17th International Conference on Extending Database Technology (EDBT) – 2014,2014,13
Distributed join algorithms on thousands of cores,Claude Barthels; Ingo Müleler; Timo Schneider; Gustavo Alonso; Torsten Hoefler,Abstract Traditional database operators such as joins are relevant not only in the context ofdatabase engines but also as a building block in many computational and machine learningalgorithms. With the advent of big data; there is an increasing demand for efficient joinalgorithms that can scale with the input data size and the available hardware resources. Inthis paper; we explore the implementation of distributed join algorithms in systems withseveral thousand cores connected by a low-latency network as used in high performancecomputing systems or data centers. We compare radix hash join to sort-merge joinalgorithms and discuss their implementation at this scale. In the paper; we explain how touse MPI to implement joins; show the impact and advantages of RDMA; discuss theimportance of network scheduling; and study the relative performance of sorting vs …,Proceedings of the VLDB Endowment,2017,12
Hash table and radix sort based aggregation,*,Aggregation of an in-memory database includes receiving; by at least one processor havinga plurality of threads; input having records stored in random access memory; distributing; bythe at least one processor; the input into portions; one of the plurality of threads having anassigned portion; aggregating; by the at least one processor; the records in the assignedportion based on locality of keys in the records and outputting; by the at least one processor;the aggregated records into a global hash table.,*,2015,11
Communication efficient algorithms for top-k selection problems,Lorenz Hübschle-Schneider; Peter Sanders,We present scalable parallel algorithms with sublinear per-processor communicationvolume and low latency for several fundamental problems related to finding the mostrelevant elements in a set; for various notions of relevance: We begin with the classicalselection problem with unsorted input. We present generalizations with sorted inputs;dynamic content (bulk-parallel priority queues); and multiple criteria. Then we move on tofinding frequent objects and top-k sum aggregation.,Parallel and Distributed Processing Symposium; 2016 IEEE International,2016,6
Adaptive dictionary compression/decompression for column-store databases,*,Innovations for adaptive compression and decompression for dictionaries of a column-storedatabase can reduce the amount of memory used for columns of the database; allowing asystem to keep column data in memory for more columns; while delays for accessoperations remain acceptable. For example; dictionary compression variants use differentcompression techniques and implementation options. Some dictionary compression variantsprovide more aggressive compression (reduced memory consumption) but result in slowerrun-time performance. Other dictionary compression variants provide less aggressivecompression (higher memory consumption) but support faster run-time performance. Asanother example; a compression manager can automatically select a dictionarycompression variant for a given column in a column-store database. For different …,*,2015,5
Engineering Aggregation Operators for Relational In-Memory Database Systems,Ingo Müller,ABSTRACT Relational Aggregation is one of the major means to analyze large data setssince the creation of the first database systems. Available hardware performance continuesto grow at an exponential rate; but increasingly so through specialization; which makes itnon-trivial to leverage in software. At the same time; application demands grow at an evenhigher pace. This puts database systems in a continuous race for hardware-conscioussystem architectures; more efficient algorithms; and better implementations—withAggregation being a fundamental building block. In this thesis we study the design andimplementation of Aggregation operators in the context of modern database systems. Inparticular; we identify and address the following challenges: cache-efficiency; CPU-friendliness; parallelism within and across processors; robust handling of skewed data …,*,2016,3
Retrieval and Perfect Hashing Using Fingerprinting,Ingo Müller; Peter Sanders; Robert Schulze; Wei Zhou,Abstract Recent work has shown that perfect hashing and retrieval of data values associatedwith a key can be done in such a way that there is no need to store the keys and that only afew bits of additional space per element are needed. We present FiRe–a new; very simpleapproach to such data structures. FiRe allows very fast construction and better cacheefficiency. The main idea is to substitute keys by small fingerprints. Collisions betweenfingerprints are resolved by recursively handling those elements in an overflow datastructure. FiRe is dynamizable; easily parallelizable and allows distributed implementationwithout communicating keys. Depending on implementation choices; queries may requireclose to a single access to a cache line or the data structure needs as low as 2.58 bits ofadditional space per element.,International Symposium on Experimental Algorithms,2014,3
Reproducible Floating-Point Aggregation in RDBMSs,Ingo Müller; Andrea Arteaga; Torsten Hoefler; Gustavo Alonso,Abstract: Industry-grade database systems are expected to produce the same result if thesame query is repeatedly run on the same input. However; the numerous sources of non-determinism in modern systems make reproducible results difficult to achieve. This isparticularly true if floating-point numbers are involved; where the order of the operationsaffects the final result. As part of a larger effort to extend database engines with datarepresentations more suitable for machine learning and scientific applications; in this paperwe explore the problem of making relational GroupBy over floating-point formats bit-reproducible; ie; ensuring any execution of the operator produces the same result up toevery single bit. To that aim; we first propose a numeric data type that can be used as drop-in replacement for other number formats and is---unlike standard floating-point formats …,arXiv preprint arXiv:1802.09883,2018,*
Systems Group; Department of Computer Science; ETH Zurich,Sabir Akhadov; Ingo Müller; Gustavo Alonso,Abstract Data analytics has become the driving force for many industries and scientificresearch. More and more decisions are maid based on statistical analysis of large datasetsand machine learning. Big data data processing frameworks; such as Apache Spark;provide an easy-to-use out-of-the-box solution; scalable to large machine clusters. Python isthe most widespread programming language in the data science field due to its simplicityand the abundance of analytical tools developed for it. Many Spark users would prefer itsPython frontend in their daily work. Multiple studies indicate; however; that there is a widegap between Spark's performance and the best handwritten code. With this thesis we bringthe functional data-flow programs' performance closer to the bare-metal speeds and showthat it is possible to write productively high performance code. i,*,2017,*
Memory-Constrained Aggregation Using Intra-Operator Pipelining,*,Disclosed herein are system; method; and computer program product embodiments forconstraining the amount of memory used during data aggregation. An embodiment operatesby separating input data into a plurality of partitions. The embodiment then inserts portions ofthe input data into blocks from a free list at a given level of a pipeline. The embodiment theninserts the blocks into buffers for processing at a subsequent level of the pipeline. Theembodiment processes the inserted blocks at the subsequent level of the pipeline andconcatenates the intermediate results into a final aggregate result.,*,2017,*
Dynamic Hash Table Size Estimation During Database Aggregation Processing,*,Disclosed herein are system; method; and computer program product embodiments fordatabase aggregation optimization. An embodiment operates by receiving data from a mainmemory. Within a cache; a first hash table comprising an aggregate hash of a first portion ofthe data is generated. A second portion of data is partitioned into one or more of partitions.Within the cache; one or more intermediate hash tables are generated. A first hash table isaggregated based on the one or more intermediate hash tables. At least a portion of the dataof the final hash table is provided responsive to a query.,*,2017,*
Aggregating database entries by hashing,*,Aggregating input into hashtables using just-in-time compilation of compilable code inresponse to a database query. Compilable code can be generated that is configured tocause a programmable processor to produce one or more hashmaps based on the inputdatabase. The one or more hashmaps can correspond to each individual thread from theinput. The compilable code can be configured to cause the one or more processors to insertthe hashmaps into a scheduler. Compilable code can be generated that is configured to:aggregate elements from the one or more hashmaps into buckets of elements having thesame partition identity; rehash the buckets of elements having the same partition identity toreduce the number of groups within the bucket; facilitate the merger of all non-emptyelements from each target-partition into a merged-partition.,*,2016,*
