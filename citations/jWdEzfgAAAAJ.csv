Overview of SciDB: large scale array storage; processing and analysis,Paul G Brown,Abstract SciDB [4; 3] is a new open-source data management system intended primarily foruse in application domains that involve very large (petabyte) scale array data; for example;scientific applications such as astronomy; remote sensing and climate modeling; bio-scienceinformation management; risk management systems in financial applications; and theanalysis of web log data. In this talk we will describe our set of motivating examples and usethem to explain the features of SciDB. We then briefly give an overview of the project'inflight'; explaining our novel storage manager; array data model; query language; andextensibility frameworks.,Proceedings of the 2010 ACM SIGMOD International Conference on Management of data,2010,280
A demonstration of SciDB: a science-oriented DBMS,Philippe Cudré-Mauroux; Hideaki Kimura; K-T Lim; Jennie Rogers; Roman Simakov; Emad Soroush; Pavel Velikhov; Daniel L Wang; Magdalena Balazinska; Jacek Becla; D DeWitt; Bobbi Heath; David Maier; Samuel Madden; J Patel; Michael Stonebraker; S Zdonik,Abstract In CIDR 2009; we presented a collection of requirements for SciDB; a DBMS thatwould meet the needs of scientific users. These included a nested-array data model; science-specific operations such as regrid; and support for uncertainty; lineage; and named versions.In this paper; we present an overview of SciDB's key features and outline a demonstration ofthe first version of SciDB on data and operations from one of our lighthouse users; the LargeSynoptic Survey Telescope (LSST).,Proceedings of the VLDB Endowment,2009,153
ArrayStore: a storage manager for complex parallel array processing,Emad Soroush; Magdalena Balazinska; Daniel Wang,Abstract We present the design; implementation; and evaluation of ArrayStore; a newstorage manager for complex; parallel array processing. ArrayStore builds on prior work inthe area of multidimensional data storage; but considers the new problem of supporting aparallel and more varied workload comprising not only range-queries; but also binaryoperations such as joins and complex user-defined functions. This paper makes two keycontributions. First; it examines several existing single-site storage management strategiesand array partitioning strategies to identify which combination is best suited for the array-processing workload above. Second; it develops a new and efficient storage-managementmechanism that enables parallel processing of operations that must access data fromadjacent partitions.,Proceedings of the 2011 ACM SIGMOD International Conference on Management of data,2011,94
Induction of fuzzy classification systems using evolutionary ACO-based algorithms,Mohammad Saniee Abadeh; Jafar Habibi; Emad Soroush,In this paper we have proposed an evolutionary algorithm to induct fuzzy classification rules.The algorithm uses an ant colony optimization based local searcher to improve the quality offinal fuzzy classification system. The proposed algorithm is performed on intrusion detectionas a high-dimensional classification problem. Results show that the implementedevolutionary ACO-Based algorithm is capable of producing a reliable fuzzy rule basedclassifier for intrusion detection,Modelling & Simulation; 2007. AMS'07. First Asia International Conference on,2007,51
Longitudinal study of a building-scale rfid ecosystem,Evan Welbourne; Karl Koscher; Emad Soroush; Magdalena Balazinska; Gaetano Borriello,Abstract Radio Frequency IDentification (RFID) deployments are becoming increasinglypopular in both industrial and consumer-oriented settings. To effectively exploit and operatesuch deployments; important challenges must be addressed; from managing RFID datastreams to handling limitations in reader accuracy and coverage. Furthermore; deploymentsthat support pervasive computing raise additional issues related to user acceptance andsystem utility. To better understand these challenges; we conducted a four-week study of abuilding-scale EPC Class-1 Generation-2 RFID deployment; the" RFID Ecosystem"; with 47readers (160 antennas) installed throughout an 8;000 square meter building. During thestudy; 67 participants having over 300 tags accessed the collected RFID data throughapplications including an object finder and a friend tracker and several tools for managing …,Proceedings of the 7th international conference on Mobile systems; applications; and services,2009,33
Fast and quality-guaranteed data streaming in resource-constrained sensor networks,Emad Soroush; Kui Wu; Jian Pei,Abstract In many emerging applications; data streams are monitored in a networkenvironment. Due to limited communication bandwidth and other resource constraints; acritical and practical demand is to online compress data streams continuously with qualityguarantee. Although many data compression and digital signal processing methods havebeen developed to reduce data volume; their super-linear time and more-than-constantspace complexity prevents them from being applied directly on data streams; particularlyover resource-constrained sensor networks. In this paper; we tackle the problem of onlinequality guaranteed compression of data streams using fast linear approximation (ie; usingline segments to approximate a time series). Technically; we address two versions of theproblem which explore quality guarantees in different forms. We develop online …,Proceedings of the 9th ACM international symposium on Mobile ad hoc networking and computing,2008,26
Time travel in a scientific array database,Emad Soroush; Magdalena Balazinska,In this paper; we present TimeArr; a new storage manager for an array database. TimeArrsupports the creation of a sequence of versions of each stored array and their explorationthrough two types of time travel operations: selection of a specific version of a (sub)-arrayand a more general extraction of a (sub)-array history; in the form of a series of (sub)-arrayversions. TimeArr contributes a combination of array-specific storage techniques toefficiently support these operations. To speed-up array exploration; TimeArr furtherintroduces two additional techniques. The first is the notion of approximate time travel withtwo types of operations: approximate version selection and approximate history. For theseoperations; users can tune the degree of approximation tolerable and thus trade-offaccuracy and performance in a principled manner. The second is to lazily create short …,Data Engineering (ICDE); 2013 IEEE 29th International Conference on,2013,24
Squeezing a Big Orange into Little Boxes: The AscotDB System for Parallel Processing of Data on a Sphere.,Jacob VanderPlas; Emad Soroush; K Simon Krughoff; Magdalena Balazinska; Andrew Connolly,Abstract AscotDB is a new; extensible data analysis system developed at the University ofWashington for the interactive analysis of data from astronomical surveys. AscotDB is alayered system: It builds on SciDB to provide a shared-nothing; parallel array processingand data management engine. AscotDB wraps SciDB with a Python middleware thatenables efficient storage and manipulation of spherical data; such as images fromtelescopes or satellites. The goal is to support the efficient storage of raw pixel-level datawithout any prior preprocessing steps. To enable both exploratory and deep analysis of thedata; AscotDB's front-end design integrates a python interface with a graphical interfacebased on the Astronomy Collaborative Toolkit (ASCOT). AscotDB supports seamlessswitching between these two modes of interaction and captures a precise trace of a user's …,IEEE Data Eng. Bull.,2013,13
Efficient iterative processing in the SciDB parallel array engine,Emad Soroush; Magdalena Balazinska; Simon Krughoff; Andrew Connolly,Abstract Many scientific data-intensive applications perform iterative computations on arraydata. There exist multiple engines specialized for array processing. These engines efficientlysupport various types of operations; but none includes native support for iterativeprocessing. In this paper; we develop a model for iterative array computations and a seriesof optimizations. We evaluate the benefits of an optimized; native support for iterative arrayprocessing on the SciDB engine and real workloads from the astronomy domain.,Proceedings of the 27th International Conference on Scientific and Statistical Database Management,2015,10
A boosting ant-colony optimization algorithm for computer intrusion detection,Emad Soroush; Mohammad Saniee Abadeh; Jafar Habibi,Abstract—This paper proposes a boosting Ant-colony optimization algorithm for intrusiondetection in computer networks. The goal of the algorithm is to extract a set of classificationrules from a network dataset. These rules are capable of detecting normal and abnormalbehaviors. The presented algorithm is evaluated according to some measures like detection;false alarm; and classification rates. Results show that the proposed boosting algorithm iscapable of producing a reliable intrusion detection system.,Proceedings of the 2006 International Symposium on Frontiers in Networking with Applications (FINA 2006),2006,9
A demonstration of iterative parallel array processing in support of telescope image analysis,Matthew Moyers; Emad Soroush; Spencer C Wallace; Simon Krughoff; Jake Vanderplas; Magdalena Balazinska; Andrew Connolly,Abstract In this demonstration; we present AscotDB; a new tool for the analysis of telescopeimage data. AscotDB results from the integration of ASCOT; a Web-based tool for thecollaborative analysis of telescope images and their metadata; and SciDB; a parallel arrayprocessing engine. We demonstrate the novel data exploration supported by this integratedtool on a 1 TB dataset comprising scientifically accurate; simulated telescope images. Wealso demonstrate novel iterative-processing features that we added to SciDB in order tosupport this use-case.,Proceedings of the VLDB Endowment,2013,8
Intrusion detection using a boosting ant colony based data miner,Emad Soroush; Jafar Habibi; M Saniee Abadeh,*,Proceedings of the 11th International CSI Computer Conference,2006,8
Hybrid merge/overlap execution technique for parallel array processing,Emad Soroush; Magdalena Balazinska,Abstract Whether in business or science; multi-dimensional arrays are a commonabstraction in data analytics and many systems exist for efficiently processing arrays. Asdataset grow in size; it is becoming increasingly important to process these arrays inparallel. In this paper; we discuss different types of array operations and review how theycan be processed in parallel using two different existing techniques. The first technique;which we call merge; consists in partitioning an array; processing the partitions in parallel;then merging the results to reconcile computations that span partition boundaries. Thesecond technique; which we call overlap; consists in partitioning an array into subarrays thatoverlap by a given number of cells along each dimension. Thanks to this overlap; the arraypartitions can be processed in parallel without any merge phase. We discuss when each …,Proceedings of the EDBT/ICDT 2011 Workshop on Array Databases,2011,7
Analysis and design of cyber-physical systems: a hybrid control systems approach,Ricardo G Sanfelice,Abstract Cyber-physical systems combine digital and analog devices; interfaces; networks;computer systems; and the like with the natural and man-made physical world. The inherentinterconnected and heterogeneous combination of behaviors in these systems makes theiranalysis and design a challenging task. Safety and reliability specifications imposed in cyber-physical applications; which are typically translated into stringent robustness standards;aggravate the matter. Unfortunately; state-of-the-art tools for system analysis and designcannot cope with the intrinsic complexity in cyber-physical systems. Tools suitable foranalysis and design of cyber-physical systems must allow a combination of physical (orcontinuous dynamics) and the cyber (or computational components); as well as handle avariety of types of perturbations; such as exogenous disturbances; time delays; and …,Cyber-physical systems: From theory to practice; Boca Raton; FL; USA: CRC Press (Taylor & Francis Group),2016,6
BReW: Blackbox resource selection for e-Science workflows,Yogesh Simmhan; Emad Soroush; Catharine Van Ingen; Deb Agarwal; Lavanya Ramakrishnan,Workflows are commonly used to model data intensive scientific analysis. As computationalresource needs increase for eScience; emerging platforms like clouds present additionalresource choices for scientists and policy makers. We introduce BReW; a tool enables usersto make rapid; highlevel platform selection for their workflows using limited workflowknowledge. This helps make informed decisions on whether to port a workflow to a newplatform. Our analysis of synthetic and real eScience workflows shows that using just totalruntime length; maximum task fanout; and total data used and produced by the workflow;BReW can provide platform predictions comparable to whitebox models with detailedworkflow knowledge.,Workflows in Support of Large-Scale Science (WORKS); 2010 5th Workshop on,2010,2
Teaching Senior Citizens How to Use the Internet and Student Engagement,Lior Malka; Warren Shenkenfelder; David Sprague; Jennifer Wong; Emad Soroush; Sabrina Marczak; Alireza Hamidi,Abstract This paper describes how the Computer Science Volunteer Program planned andtaught a free Internet course for senior citizens in Victoria; British Columbia; Canada. This isthe first program in North America where graduate students offer free Internet training tosenior citizens. We found that personal attention and focusing on practice rather than theory;make Internet learning more enjoyable and less overwhelming for seniors. Graduatestudents; who form the majority of the Program; reported that they improved their leadershipskills and felt more engaged in the community.,Proceedings of the 13th Annual Western Canadian Conference on Computing Education (WCCCE) Conference,2008,2
Proceedings of the ACM SIGMOD International Conference on Management of Data: Foreword,Gautam Das; Bing Liu; S Yu Philip,Das; G; Liu; B & Yu; PS 2004; Proceedings of the ACM SIGMOD International Conference onManagement of Data: Foreword. in Proceedings of the ACM SIGMOD International Conferenceon Management of Data. 9th Workshop on Research Issues in Data Mining and KnowledgeDiscovery; DMKD 2004; In Conjunction with ACM SIGMOD International Conference on Managementof Data; SIGMOD-04; Paris; France; 6/13/04 … Das G; Liu B; Yu PS. Proceedings of the ACMSIGMOD International Conference on Management of Data: Foreword. In Proceedings of theACM SIGMOD International Conference on Management of Data. 2004 … Das; Gautam ;Liu; Bing ; Yu; Philip S./ Proceedings of the ACM SIGMOD International Conference on Managementof Data : Foreword. Proceedings of the ACM SIGMOD International Conference on Managementof Data. 2004 … Powered by Pure; Scopus & Elsevier Fingerprint Engine™ © 2017 …,9th Workshop on Research Issues in Data Mining and Knowledge Discovery; DMKD 2004; In Conjunction with ACM SIGMOD International Conference on Management of Data; SIGMOD-04,2004,1
Multi-versioned Data Storage and Iterative Processing in a Parallel Array Database Engine,Emad Soroush,Scientists today are able to generate data at an unprecedented scale and rate. For examplethe Sloan Digital Sky Survey (SDSS) generates 200GB of data containing millions of objectson each night on its routine operation. The large hadron collider is producing even moredata today which is approximately 30PB annually. The Large Synoptic Survey Telescope(LSST) also will be producing approximately 30TB of data per night in a few years. Also; inmany fields of science; multidimensional arrays rather than flat tables are standard datatypes because data values are associated with coordinates in space and time. For example;images in astronomy are 2D arrays of pixel intensities. Climate and ocean models usearrays or meshes to describe 3D regions of the atmosphere and oceans. As a result;scientists need powerful tools to help them manage massive arrays. This thesis focuses …,*,2014,*
Fast data streaming in resource constrained wireless sensor networks,Emad Soroush,In many emerging applications; data streams are monitored in a network environment. Dueto limited communication bandwidth and other resource constraints; a critical and practicaldemand is to online compress data streams continuously with quality guarantee. Althoughmany data compression and digital signal processing methods have been developed toreduce data volume; their super-linear time and more-than-constant space complexityprevents them from being applied directly on data streams; particularly over resource-constrained sensor networks. In this thesis; we tackle the problem of online qualityguaranteed compression of data streams using fast linear approximation (ie; using linesegments to approximate a time series). Technically; we address two versions of theproblem which explore quality guarantees in different forms. We develop online …,*,2008,*
Network Calculus,Emad Soroush,*,*,2007,*
c Copyright 2014,Emad Soroush,Scientists today are able to generate data at an unprecedented scale and rate. For examplethe Sloan Digital Sky Survey (SDSS) generates 200GB of data containing millions of objectson each night on its routine operation. The large hadron collider is producing even moredata today which is approximately 30PB annually. The Large Synoptic Survey Telescope(LSST) also will be producing approximately 30TB of data per night in a few years. Also; inmany fields of science; multidimensional arrays rather than flat tables are standard datatypes because data values are associated with coordinates in space and time. For example;images in astronomy are 2D arrays of pixel intensities. Climate and ocean models usearrays or meshes to describe 3D regions of the atmosphere and oceans. As a result;scientists need powerful tools to help them manage massive arrays. This thesis focuses …,*,*,*
Data Engineering,Thomas Heinis; Farhan Tauheed; Mirjana Pavlovic; Anastasia Ailamaki; Jacob Vanderplas; Emad Soroush; Simon Krughoff; Magdalena Balazinska; Michael Stonebraker; Jennie Duggan; Leilani Battle; Olga Papaemmanouil; Colin Talbert; Marian Talbert; Jeff Morisette; David Koop; Fernando Chirigati; Matthias Troyer; Dennis Shasha; Juliana Freire,Abstract Researchers in several scientific disciplines are struggling to cope with the massesof data resulting from either increasingly precise instruments or from simulation runs on evermore powerful supercomputers. Efficiently managing this deluge of data has become key tounderstand the phenomena they are studying. Scientists in the simulation sciences; forexample; build increasingly big and detailed models; as detailed as the hardware allows;but they lack the efficient technology to update and analyze them. In this paper we discusshow innovative data management techniques we have developed; enable scientists to buildand analyze bigger and more detailed spatial models and how these techniques ultimatelyaccelerate discovery in the simulation sciences. These include spatial join methods (inmemory and on disk); techniques for the efficient navigation in detailed meshes; an index …,*,*,*
A More Informative Heuristic Function for Fast Forward Planning,Emad Soroush; Seyyed Ali Akramifar; G Reza Ghassem-Sani,*,*,*,*
