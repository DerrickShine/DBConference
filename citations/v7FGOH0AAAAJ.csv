A systematic comparison and evaluation of k-anonymization algorithms for practitioners,Vanessa Ayala-Rivera; Patrick McDonagh; Thomas Cerqueus; Liam Murphy,The vast amount of data being collected about individuals has brought new challenges inprotecting their privacy when this data is disseminated. As a result; Privacy-Preserving DataPublishing has become an active research area; in which multiple anonymization algorithmshave been proposed. However; given the large number of algorithms available and limitedinformation regarding their performance; it is difficult to identify and select the mostappropriate algorithm given a particular publishing scenario; especially for practitioners. Inthis paper; we perform a systematic comparison of three well-known k-anonymizationalgorithms to measure their efficiency (in terms of resources usage) and their effectiveness(in terms of data utility). We extend the scope of their original evaluation by employing amore comprehensive set of scenarios: different parameters; metrics and datasets. Using …,*,2014,18
Controvol: A framework for controlled schema evolution in nosql application development,Stefanie Scherzinger; Thomas Cerqueus; Eduardo Cunha de Almeida,Building scalable web applications on top of NoSQL data stores is becoming commonpractice. Many of these data stores can easily be accessed programmatically; and do notenforce a schema. Software engineers can design the data model on the go; a flexibility thatis crucial in agile software development. The typical tasks of database schema managementare now handled within the application code; usually involving object mapper libraries.However; today's Integrated Development Environments (IDEs) lack the proper tool supportwhen it comes to managing the combined evolution of the application code and of theschema. Yet simple refactorings such as renaming an attribute at the source code level cancause irretrievable data loss or runtime errors once the application is serving in production.In this demo; we present ControVol; a framework for controlled schema evolution in …,Data Engineering (ICDE); 2015 IEEE 31st International Conference on,2015,13
Safely managing data variety in big data software development,Thomas Cerqueus; Eduardo Cunha De Almeida; Stefanie Scherzinger,Abstract We consider the task of building Big Data software systems; offered as software-as-a-service. These applications are commonly backed by NoSQL data stores that address theproverbial Vs of Big Data processing: NoSQL data stores can handle large volumes of dataand many systems do not enforce a global schema; to account for structural variety in data.Thus; software engineers can design the data model on the go; a flexibility that is particularlycrucial in agile software development. However; NoSQL data stores commonly do not yetaccount for the veracity of changes when it comes to changes in the structure of persisteddata. Yet this is an inevitable consequence of agile software development. In most NoSQL-based application stacks; schema evolution is completely handled within the applicationcode; usually involving object mapper libraries. Yet simple code refactorings; such as …,Proceedings of the First International Workshop on BIG Data Software Engineering,2015,10
A DSL for Deployment and Testing in the Cloud,Adrien Thiery; Thomas Cerqueus; Christina Thorpe; Gerson Sunyé; John Murphy,Cloud computing is becoming increasingly prevalent; more and more software providers areoffering their applications as Software-as-a-Service solutions rather than traditional on-premises installations. In order to ensure the efficacy of the testing phase; it is critical tocreate a test environment that sufficiently emulates the production environment. Thus; Cloudapplications should be tested in the Cloud. Cloud providers offer command-line tools forinteracting with their platforms. However; writing custom low-level scripts using the provider'stool can become very complex to maintain and manage when variability (in terms ofproviders and platforms) is introduced. The contributions in this paper include: thedevelopment of a high level Domain Specific Language for the abstract definition of theapplication deployment process; and resource requirements; and a generation process …,Software Testing; Verification and Validation Workshops (ICSTW); 2014 IEEE Seventh International Conference on,2014,8
Synthetic Data Generation using Benerator Tool,Vanessa Ayala-Rivera; Patrick McDonagh; Thomas Cerqueus; Liam Murphy,Abstract: Datasets of different characteristics are needed by the research community forexperimental purposes. However; real data may be difficult to obtain due to privacyconcerns. Moreover; real data may not meet specific characteristics which are needed toverify new approaches under certain conditions. Given these limitations; the use of syntheticdata is a viable alternative to complement the real data. In this report; we describe theprocess followed to generate synthetic data using Benerator; a publicly available tool. Theresults show that the synthetic data preserves a high level of accuracy compared to theoriginal data. The generated datasets correspond to microdata containing records withsocial; economic and demographic data which mimics the distribution of aggregatedstatistics from the 2011 Irish Census data.,arXiv preprint arXiv:1311.3312,2013,8
Gossiping correspondences to reduce semantic heterogeneity of unstructured P2P systems,Thomas Cerqueus; Sylvie Cazalens; Philippe Lamarre,Abstract In this paper we consider P2P data sharing systems in which each participant usesan ontology to represent its data. If all the participants do not use the same ontology; thesystem is said to be semantically heterogeneous. This situation of heterogeneity preventsperfect interoperability. Indeed participants could be unable to treat queries for which theydo not understand some concepts. Intuitively; the more heterogeneous a system; the harderto communicate. We first define several measures to characterize the semanticheterogeneity of P2P systems according to different facets. Then; we propose a solution;called CorDis; to reduce the heterogeneity by decreasing the gap between peers. The ideais to gossip correspondences through the system so that peers become less disparate fromeach other. The experiments use the PeerSim simulator and ontologies from OntoFarm …,International Conference on Data Management in Grid and P2P Systems,2011,8
ReX: Extrapolating relational data in a representative way,Teodora Sandra Buda; Thomas Cerqueus; John Murphy; Morten Kristiansen,Abstract Generating synthetic data is useful in multiple application areas (eg; databasetesting; software testing). Nevertheless; existing synthetic data generators generally lack thenecessary mechanism to produce realistic data; unless a complex set of inputs are givenfrom the user; such as the characteristics of the desired data. An automated and efficienttechnique is needed for generating realistic data. In this paper; we propose ReX; a novelextrapolation system targeting relational databases that aims to produce a representativeextrapolated database given an original one and a natural scaling rate. Furthermore; weevaluate our system in comparison with an existing realistic scaling method; UpSizeR; bymeasuring the representativeness of the extrapolated database to the original one; theaccuracy for approximate query answering; the database size; and their performance …,British International Conference on Databases,2015,7
SimAttack: private web search under fire,Albin Petit; Thomas Cerqueus; Antoine Boutet; Sonia Ben Mokhtar; David Coquil; Lionel Brunie; Harald Kosch,Abstract Web Search engines have become an indispensable online service to retrievecontent on the Internet. However; using search engines raises serious privacy issues as thelatter gather large amounts of data about individuals through their search queries. Two maintechniques have been proposed to privately query search engines. A first category ofapproaches; called unlinkability; aims at disassociating the query and the identity of itsrequester. A second category of approaches; called indistinguishability; aims at hiding user'squeries or user's interests by either obfuscating user's queries; or forging new fake queries.This paper presents a study of the level of protection offered by three popular solutions: Tor-based; TrackMeNot; and GooPIR. For this purpose; we present an efficient and scalableattack–SimAttack–leveraging a similarity metric to capture the distance between …,Journal of Internet Services and Applications,2016,6
Peas: Private; efficient and accurate web search,Albin Petit; Thomas Cerqueus; Sonia Ben Mokhtar; Lionel Brunie; Harald Kosch,Accounting for the large number of queries sent by users to search engines on a daily basis;the latter are likely to learn and possibly leak sensitive information about individual users. Todeal with this issue; several solutions have been proposed to query search engines in aprivacy preserving way. A first category of solutions aim to hide users' identities; thusenforcing unlinkability between a query and the identity of its originating user. A secondcategory of approaches aims to obfuscate the content of users' queries; or at generating fakequeries in order to blur user profiles; thus enforcing indistinguishability between them. In thispaper we propose PEAS; a new protocol for private Web search. PEAS combines a newefficient unlinkability protocol with a new accurate indistinguishability protocol. Experimentsconducted using a real dataset of search logs show that compared to state-of-the-art …,Trustcom/BigDataSE/ISPA; 2015 IEEE,2015,6
VFDS: Very fast database sampling system,Teodora Sandra Buda; Thomas Cerqueus; John Murphy; Morten Kristiansen,In a wide range of application areas (eg data mining; approximate query evaluation;histogram construction); database sampling has proved to be a powerful technique. It isgenerally used when the computational cost of processing large amounts of information isextremely high; and a faster response with a lower level of accuracy for the results ispreferred. Previous sampling techniques achieve this balance; however; an evaluation ofthe cost of the database sampling process should be considered. We argue that theperformance of current relational database sampling techniques that maintain the dataintegrity of the sample database is low and a faster strategy needs to be devised. In thispaper we propose a very fast sampling method that maintains the referential integrity of thesample database intact. The sampling method targets the production environment of a …,Information Reuse and Integration (IRI); 2013 IEEE 14th International Conference on,2013,5
Testing a cloud application: IBM SmartCloud inotes: methodologies and tools,Michael Lynch; Thomas Cerqueus; Christina Thorpe,Abstract IBM SmartCloud is a branded collection of Cloud products and solutions from IBM. Itincludes Infrastructure as a Service (IaaS); Software as a Service (SaaS); and Platform as aService (PaaS) offered through public; private and hybrid cloud delivery models. This paperfocuses on the software testing process employed for the SmartCloud iNotes SaaSapplication; providing details of the methodologies and tools developed to streamlinetesting. The new tools have enabled the testing team to meet the pace of the highly agiledevelopment team; enabling a more efficient software development lifecycle. Resultsindicate that the methodologies and tools used have increased the performance of thetesting team: there was a decrease in the number of bugs present in the code (prior torelease); and an overall increase in customer satisfaction.,Proceedings of the 2013 International Workshop on Testing the Cloud,2013,5
An approach to manage semantic heterogeneity in unstructured p2p information retrieval systems,Thomas Cerqueus; Sylvie Cazalens; Philippe Lamarre,In unstructured information retrieval P2P systems; semantic heterogeneity comes from theuse of different ontologies. Semantic interoperability refers to the ability of peers tocommunicate with each others. We take into account these notions separately; as raisingtwo different problems. Hence we propose two independent and complementary solutions.The GoOD-TA protocol aims at reducing heterogeneity through ontology-driven topologyadaptation. DiQuESh is a top-k algorithm for distributed information retrieval that is intendedto ensure interoperability. This distinction enables highlighting their respective benefits onthe IR performances and leads to a modular architecture. For our experiments we obtained aset of actively used real-world ontologies through the NCBO BioPortal. We implementedGoOD-TA and DiQuESH in Java and used the PeerSim simulator. We first show that …,Peer-to-Peer Computing (P2P); 2012 IEEE 12th International Conference on,2012,5
Semantic heterogeneity measures of unstructured P2P systems,Thomas Cerqueus; Sylvie Cazalens; Philippe Lamarre,Abstract We consider P2P data sharing systems in which each participant uses an ontologyto represent information. If all the partipants do not use the same ontology; the system is saidto be semantically heterogeneous. Several methods have been proposed to reach a degreeof interoperability but thorough evaluation of these methods is prevented by a lack of tools todescribe the situations in which they have been tested. In this paper we identify componentsthat impact on the semantic heterogeneneity; and we define several complementarymeasures to capture the different facets of heterogeneity. Proposed measures allow tocharacterize the situation in which a method is evaluated; or to measure the heterogeneityreduction produced by another method.,Proceedings of the 2011 IEEE/WIC/ACM International Conferences on Web Intelligence and Intelligent Agent Technology-Volume 01,2011,5
Mysins: make your semantic information system,Anthony Ventresque; Thomas Cerqueus; Celton Louis-Alexandre; Hervouet Gaëtan; Levin Damien; Philippe Lamarre; Sylvie Cazalens,La sémantique est de plus en plus utilisée dans différents domaines comme la recherched'information (RI) et le Web sémantique. Dans le domaine de la RI; différents participantsinterviennent: des fournisseurs d'informations et des utilisateurs. L'utilisation de lasémantique nécessite la mise en œuvre de mécanismes précis. En RI; il s' agit entre autrede l'utilisation d'ontologies; du calcul de similarité et de l'indexation. L'étude de chacun deces axes nécessite un effort important de synthèse et d'intégration. Pour palier le manqueévident d'une architecture générique distribuée pour la conception de systèmesd'information sémantiques; nous proposons un framework: Mysins.,EGC'2010,2010,5
Ontology-based quality evaluation of value generalization hierarchies for data anonymization,Vanessa Ayala-Rivera; Patrick McDonagh; Thomas Cerqueus; Liam Murphy,Abstract: In privacy-preserving data publishing; approaches using Value GeneralizationHierarchies (VGHs) form an important class of anonymization algorithms. VGHs play a keyrole in the utility of published datasets as they dictate how the anonymization of the dataoccurs. For categorical attributes; it is imperative to preserve the semantics of the originaldata in order to achieve a higher utility. Despite this; semantics have not being formallyconsidered in the specification of VGHs. Moreover; there are no methods that allow theusers to assess the quality of their VGH. In this paper; we propose a measurement scheme;based on ontologies; to quantitatively evaluate the quality of VGHs; in terms of semanticconsistency and taxonomic organization; with the aim of producing higher-qualityanonymizations. We demonstrate; through a case study; how our evaluation scheme can …,arXiv preprint arXiv:1503.01812,2015,4
CoDS: A representative sampling method for relational databases,Teodora Sandra Buda; Thomas Cerqueus; John Murphy; Morten Kristiansen,Abstract Database sampling has become a popular approach to handle large amounts ofdata in a wide range of application areas such as data mining or approximate queryevaluation. Using database samples is a potential solution when using the entire databaseis not cost-effective; and a balance between the accuracy of the results and thecomputational cost of the process applied on the large data set is preferred. Existingsampling approaches are either limited to specific application areas; to single tabledatabases; or to random sampling. In this paper; we propose CoDS: a novel samplingapproach targeting relational databases that ensures that the sample database follows thesame distribution for specific fields as the original database. In particular it aims to maintainthe distribution between tables. We evaluate the performance of our algorithm by …,International Conference on Database and Expert Systems Applications,2013,4
Personalization through query explanation and document adaptation,Anthony Ventresque; Sylvie Cazalens; Thomas Cerqueus; Philippe Lamarre; Gabriella Pasi,We present a new formal approach to retrieval personaliza-tion which emcompasses aquery personalization process at the user's side with a light document adaptation at the in-formation server's side. Our solution relies on the use of a domain ontology: queries anddocuments are in fact indexed by sets of concepts. For each concept of the query; the querypersonalization process allows to express the importance of linked concepts; which mayvary according to the search con-text. Each query concept can be” clarified” by this process;although the proposed method clarifies only central query concepts. The initial query as wellas its defined clarifica-tions are sent to the server. Then; the server reconsiders its documentrepresentations based on both the query and the concepts clarifications it received. Theproposed solution does not require that the information server maintains any user profile …,VLDB 2010 co-located workshop on Personalized Access; Profile Management; and Context Awareness in Databases (PersDB2010),2010,4
Finding and Fixing Type Mismatches in the Evolution of Object-NoSQL Mappings.,Stefanie Scherzinger; Eduardo Cunha de Almeida; Thomas Cerqueus; Leandro Batista de Almeida; Pedro Holanda,ABSTRACT NoSQL data stores are popular backends for managing big data that is evolvingover time: Due to their schema-flexibility; a new release of the application does not require afull migration of data already persisted in production. Instead; using object-NoSQL mappers;developers can specify lazy data migrations that are executed on-the-fly; when a legacyentity is loaded into the application. This paper features ControVol; an IDE plugin that tracksevolutionary changes in object-NoSQL mappings; such as adding; renaming; or removingan attribute; which may conflict with entities already persisted in production. If not resolvedprior to launch of the new application; harmful evolutionary changes can cause runtimeexceptions or data loss. In this demo; we focus on a novel feature of ControVol; detectingchanges to attribute types that are not backwards-compatible with legacy entities. When …,EDBT/ICDT Workshops,2016,3
ControVol: Let yesterday's data catch up with today's application code,Thomas Cerqueus; Eduardo Cunha de Almeida; Stefanie Scherzinger,Abstract In building software-as-a-service applications; a flexible development environmentis key to shipping early and often. Therefore; schema-flexible data stores are becomingmore and more popular. They can store data with heterogeneous structure; allowing for newreleases to be pushed frequently; without having to migrate legacy data first. However; thecurrent application code must continue to work with any legacy data that has already beenpersisted in production. To let legacy data structurally" catch up" with the latest applicationcode; developers commonly employ object mapper libraries with life-cycle annotations. Yetwhen used without caution; they can cause runtime errors and even data loss. We presentControVol; an IDE plugin that detects evolutionary changes to the application code that areincompatible with legacy data. ControVol warns developers already at development time …,Proceedings of the 24th International Conference on World Wide Web,2015,3
Influence de l'hétérogénéité sémantique sur les performances d'un système de RI distribuée,Thomas Cerqueus; Sylvie Cazalens; Philippe Lamarre,Nous considérons des systèmes pair-à-pair pour le partage de documents dans lesquelschaque pair utilise une ontologie pour représenter ses documents. Lorsque tous les pairsn'utilisent pas la même ontologie; le système est sémantiquement hétérogène; ce quiconstitue à priori un frein à l'interopérabilité. Nous proposons un système dont l'organisationgénérique en couches logicielles sépare les algorithmes dédiés à la diminution del'hétérogénéité de ceux utilisés pour la recherche d'information sémantique distribuée. Dansce contexte; nous proposons une méthode de recherche d'information; puis nous focalisonssur l'impact qu'ont des algorithmes dédiés à la diminution de l'hétérogénéité surl'interopérabilité (mesurée en termes de précision/rappel). Nos expérimentationsconsidèrent des ontologies du domaine bio-médical et des documents issus de la base …,COnférence en Recherche d'Information et Applications,2012,3
Reducing the semantic heterogeneity of unstructured p2p systems: a contribution based on a dissemination protocol,Thomas Cerqueus; Sylvie Cazalens; Philippe Lamarre,Abstract In resource sharing P2P systems with autonomous participants; each peer is free touse the ontology with which it annotates its resources. Semantic heterogeneity occurs whenthe peers do not use the same ontology. For example; a contributing peer A (eg a doctor)may annotate its photos; diagrams; data sets with some ontology of its own; while peer B (ega genetician) uses another one. In order to answer a query issued in the system; peers needto know alignments that state correspondences between entities of two ontologies.Assuming that each peer has some partial initial knowledge of some alignments; we focuson correspondences sharing between the peers as a means to learn additionalcorrespondences. We first provide several measures of semantic heterogeneity that enableto draw a semantic picture of the system and to evaluate the efficiency of protocols …,*,2012,3
Testing a Cloud Application: IBM SmartCloud iNotes,T Lynch; Thomas Cerqueus; Christina Thorpe,ABSTRACT IBM SmartCloud is a branded collection of Cloud products and solutions fromIBM. It includes Infrastructure as a Service (IaaS); Software as a Service (SaaS); andPlatform as a Service (PaaS) offered through public; private and hybrid cloud deliverymodels1. This paper focuses on the software testing process employed for the SmartCloudiNotes SaaS application; providing details of the methodologies and tools developed tostreamline testing. The new tools have enabled the testing team to meet the pace of thehighly agile development team; enabling a more efficient software development lifecycle.Results indicate that the methodologies and tools used have increased the performance ofthe testing team: there was a decrease in the number of bugs present in the code (prior torelease); and an overall increase in customer satisfaction.,TTC,2013,2
Reducing Semantic Heterogeneity of Unstructured P2P Systems Through Gossip-Based Ontology-Driven Topology Adaptation,Thomas Cerqueus; Sylvie Cazalens; Philippe Lamarre,We present GoOD-TA; a gossip-based; ontology-driven topology adaptation protocol thatreduces the semantic heterogeneity generated by the use of several ontologies within P2Pinformation sharing systems. Peers regularly exchange other peers' descriptors in order tochoose neighbours that are semantically close in terms of used ontology or ability totranslate queries. In GoOD-TA; the descriptors are expressive enough to define a relevantproximity function between peers. Several mechanisms enable to reduce the volume oftransfered data between peers and to manage the dynamicity of the system. Particularattention has been paid to handle the evolution of peers semantic knowledge; when theychange their ontology or the correspondences they know. We implemented the GoOD-TAprotocol in Java; and we used the PeerSim simulator to evaluate it. We used a set of real …,*,2011,2
Mesures d'hétérogénéité sémantique des systèmes P2P non-structurés,Thomas Cerqueus; Sylvie Cazalens; Philippe Lamarre,L'autonomie des participants dans les systèmes P2P pour le partage de données peutconduire à une situation d'hétérogénéité sémantique dans le cas où les participants utilisentleurs propres ontologies pour représenter leurs données. Dans cet article nouscommençons par déﬁnir des mesures de disparité entre participants en considérant leurscontextes sémantiques. En considérant la topologie du système et les disparités entreparticipants; nous proposons des mesures d'hétérogénéité sémantique d'un système P2Pnon-structuré.,Extraction et gestion des connaissances EGC'2010,2011,2
KSample: Dynamic Sampling Over Unbounded Data Streams,Tiago Rodrigo Kepe; Eduardo Cunha de Almeida; Thomas Cerqueus,*,Journal of Information and Data Management,2015,1
VFDS: An Application to Generate Fast Sample Databases,Teodora Sandra Buda; Thomas Cerqueus; John Murphy; Morten Kristiansen,Abstract Large amounts of data often require expensive and time-consuming analysis.Therefore; highly scalable and efficient techniques are necessary to process; analyze anddiscover useful information. Database sampling has proven to be a powerful method tosurpass these limitations. Using only a sample of the original large database brings thebenefit of obtaining useful information faster; at the potential expense of lower accuracy. Inthis paper; we demonstrate\vfds; a novel fast database sampling system that maintains thereferential integrity of the data. The system is developed over the open-source databasemanagement system; MySQL. We present various scenarios to demonstrate theeffectiveness of VFDS in approximate query answering; sample size; and execution time; onboth real and synthetic databases.,Proceedings of the 23rd ACM International Conference on Conference on Information and Knowledge Management,2014,1
Contributions au problème d'hétérogénéité sémantique dans les systèmes pair-à-pair: application à la recherche d'information,Thomas Cerqueus,Nous considérons des systèmes pair-à-pair (P2P) pour le partage de données danslesquels chaque pair est libre de choisir l'ontologie qui correspond le mieux à ses besoinspour représenter ses données. Nous parlons alors d'hétérogénéité sémantique. Cettesituation est un frein important à l'interopérabilité car les requêtes émises par les pairspeuvent être incomprises par d'autres. Dans un premier temps nous nous focalisons sur lanotion d'hétérogénéité sémantique. Nous définissons un ensemble de mesures permettantde caractériser finement l'hétérogénéité d'un système suivant différentes facettes. Dans undeuxième temps nous définissons deux protocoles. Le premier; appelé CorDis; permet deréduire l'hétérogénéité sémantique liée aux disparités entre pairs. Il dissémine descorrespondances dans le système afin que les pairs apprennent de nouvelles …,*,2012,1
ReX: Representative extrapolating relational databases,Teodora Sandra Buda; Thomas Cerqueus; Cristian Grava; John Murphy,Abstract Generating synthetic data is useful in multiple application areas (eg; databasetesting; software testing). Nevertheless; existing synthetic data generators are either limitedto generating data that only respect the database schema constraints; or they are notaccurate in terms of representativeness; unless a complex set of inputs are given from theuser (such as the data characteristics of the desired generated data). In this paper; wepresent an extension of a prior representative extrapolation technique; namely ReX [20];limited to natural scaling rates. The objective is to produce in an automated and efficient waya representative extrapolated database; given an original database O and a rational scalingrate; s∈ Q. In the extended version; the ReX system can handle rational scaling rates bycombining existing efficient sampling and extrapolation techniques. Furthermore; we …,Information Systems,2017,*
Enhancing the Utility of Anonymized Data by Improving the Quality of Generalization Hierarchies.,Vanessa Ayala-Rivera; Patrick McDonagh; Thomas Cerqueus; Liam Murphy; Christina Thorpe,Abstract. The dissemination of textual personal information has become an important driverof innovation. However; due to the possible content of sensitive information; this data mustbe anonymized. A commonly-used technique to anonymize data is generalization.Nevertheless; its effectiveness can be hampered by the Value Generalization Hierarchies(VGHs) used as poorly-specified VGHs can decrease the usefulness of the resulting data. Totackle this problem; in our previous work we presented the Generalization Semantic Loss(GSL); a metric that captures the quality of categorical VGHs in terms of semanticconsistency and taxonomic organization. We validated the accuracy of GSL using anintrinsic evaluation with respect to a gold standard ontology. In this paper; we extend ourprevious work by conducting an extrinsic evaluation of GSL with respect to the …,Transactions on Data Privacy,2017,*
Improving the Utility of Anonymized Datasets through Dynamic Evaluation of Generalization Hierarchies,Vanessa Ayala-Rivera; Thomas Cerqueus; Liam Murphy; Christina Thorpe,The dissemination of textual personal information has become a key driver for innovationand value creation. However; due to the possible content of sensitive information; this datamust be anonymized; which can reduce its usefulness for secondary uses. One of the mostused techniques to anonymize data is generalization. However; its effectiveness can behampered by the Value Generalization Hierarchies (VGHs) used to dictate theanonymization of data; as poorly-specified VGHs can reduce the usefulness of the resultingdata. To tackle this problem; we propose a metric for evaluating the quality of textual VGHsused in anonymization. Our evaluation approach considers the semantic properties of VGHsand exploits information from the input datasets to predict with higher accuracy (compared toexisting approaches) the potential effectiveness of VGHs for anonymizing data. As a …,Information Reuse and Integration (IRI); 2016 IEEE 17th International Conference on,2016,*
Privacy in Big Data,Benjamin Habegger; Omar Hasan; Thomas Cerqueus; Lionel Brunie; Nadia Bennani; Harald Kosch; Ernesto Damiani,Personalization consists of adapting outputs to a particular context and user. It may rely onuser profile attributes such as the geographical location; academic and professionalbackground; membership in groups; interests; preferences; opinions; and so on.Personalization is used by a variety of Web-based services for different purposes. Acommon form of personalization is the recommendation of items; elements; or generalinformation that a user has not yet considered but may find useful. General-purpose socialnetworks such as Facebook. com use personalization techniques to find potential friendsbased on the existing relationships and group memberships of the user. Professional socialnetworks such as LinkedIn. com exploit the skills and professional background informationavailable in a user profile to recommend potential employees. Search engines such as …,*,2015,*
Dynamic Adaptation of the Traffic Management System CarDemo,Arnaud Cordier; Rémi Domingues; Anthony Labaere; Nicolas Noel; Adrien Thiery; Thomas Cerqueus; Siobhán Clarke; Pawel Idziak; Hui Song; Philip Perry; Anthony Ventresque,This paper demonstrates how we applied a constraint-based dynamic adaptation approachon CarDemo; a traffic management system. The approach allows domain experts todescribe the adaptation goals as declarative constraints; and automatically plan theadaptation decisions to satisfy these constraints. We demonstrate how to utilise thisapproach to realise the dynamic switch of routing services of the traffic management system;according to the change of global system states and user requests.,Self-Adaptive and Self-Organizing Systems (SASO); 2014 IEEE Eighth International Conference on,2014,*
Service placement in the cloud,Anthony Ventresque; Christina Thorpe; Thomas Cerqueus,Motivation: The Cloud is a complex and heterogeneous composition of physical machinesand services. It is heterogeneous because capital allocators in companies do not buy newhardware every year and machines age; and the software on those machines are not alwaysat the same version. It is complex because of the software stack on the machines: variouskinds of operating systems; web/database/application servers; and because a large numberof the services nowadays are multi-tier; ie; are composed of separated services that canreside on different machines. Consider for instance a classical e-service with a web interface(eg; a page in Javascript) residing on the machine of a datacentre d1; while the logic issituated remotely on another datacentre d2 and the database in a PaaS provider (eg;Google Datastore). The problem is now that there are potentially an infinite number of …,*,2013,*
Towards the deployment of cloud applications using a DSL,Christina Thorpe; Thomas Cerqueus; Adrien Thiery; Gerson Sunyé,Cloud infrastructures offer facilities to develop and deploy large-scale applications.Nevertheless; testing Cloud applications is an intricate task because applicationsthemselves are very complex; infrastructures are highly distributed and heterogeneous; theamounts of data are massive; and the interconnections between services/components aresophisticated. From a business point of view; testing is generally not seen as an interestingphase of software development because; unlike the development of new features; it doesnot offer a direct return on investment. We think that providing accurate methodologies andtools to test Cloud applications will allow companies to speed up testing (and thus save timeand money); and produce better software (and thus increase their competitiveness). In thisresearch; we aim to ease the deployment of Cloud applications. This task is painful in the …,*,2013,*
Monitoring the cloud-CloudMon,Christina Thorpe; Thomas Cerqueus; Anthony Ventresque,The Cloud is a complex; heterogeneous environment consisting of many layeredcomponents with complicated interconnections and relationships. Monitoring the Cloud isvital in providing service assurance and upholding SLAs. Failure to do either would result ina negative impact to customer satisfaction; potentially resulting in a loss of revenue. Whilethe Cloud offers many advantages and interesting features (easy deployment ofapplications; resiliency; security; performance; scalability; elasticity; etc.); there are manychallenges involved in monitoring such complex systems (Adinarayan; 2012; Aceto; 2012).Some of the main issues for monitoring the Cloud include: heterogeneity ofhardware/software; scalability; aggregating and analyzing data.,*,2013,*
Recherche d'information sémantique dans les systèmes P2P hétérogènes,Thomas Cerqueus,Nous considérons la recherche d'information sémantique dans les systèmes pair-à-pair.Ces derniers semblent être une solution intéressante pour le partage de données car ilsgarantissent le passage à l'échelle; et gère la dynamicité. Dans ce contexte; il estdifficilement imaginable que tous les participants s' accordent sur l'utilisation d'une mêmereprésentation sémantique (schéma; ontologie; graphe conceptuel). Dans ce cas; lesystème est sémantiquement hétérogène. Cette situation limite l'interopérabilité entreparticipants. Dans cet article nous montrons quels sont les problématiques liées àl'hétérogénéité sémantique et nous présentons les solutions que nous proposons pourgarantir un certain degré d'interopérabilité malgré l'hétérogénéité. L'originalité de ce travailse trouve dans le fait de tenter d'améliorer l'interopérabilité sémantique en s' attaquant …,COnférence en Recherche d'Information et Applications-Journée Jeunes chercheurs,2012,*
Recherche sémantique dans les systèmes P2P pour les communautés en ligne,Thomas CERQUEUS,*,*,2010,*
Mise en place de la méthode ExSI2D dans un système P2P hétérogène,Thomas CERQUEUS,Depuis quelques décénnies; la quantité de données numériques augmente de façonimportante et le phénomene ne fait que s' accentuer avec le développement d'Internet. Levolume d'information est si important; qu'il devient de plus en plus difficile de trouver del'information pertinente: les systemes de recherche d'information (RI) sont indispensables etles difficultés auxquelles ils sont confrontés sont d'autant plus délicates. Les systemes derecherche d'information les plus connus (Google; Yahoo) sont des systemes centralisés: lesdonnées sont stockées sur des serveurs centraux. Ce type d'architecture (client/serveur)présente des limites: pas de tolérance aux pannes et difficultéa passera l'échelle. Lessystemes pair-apair (P2P) ont été proposés pour répondrea ces problématiques; mais ladistribution des données dans de tels systemes fait apparaıtre de nouveaux défis pour les …,*,2009,*
Archive ouverte HAL,Mon IdHAL; CV Mon,En mélant la dimension artistique à la dimension scientifique; l'acoustique musicale a suattirer depuis l'Antiquité les plus grands noms des sciences; comme Pythagore; Helmholtz;Rayleigh et bien d'autres... Nombreux sont ceux qui ont cherché à comprendre comment lesmusiciens peuvent tirer de leurs instruments des sons mélodieux ou; au contraire; dessources de crispations pour l'auditoire. On trouve dans la mythologie grecque les premierséléments de facture instrumentale:«Jadis cette déesse [Minerve] voulut imiter les affreuxgémissements des Gorgones et les sifflements que poussèrent les serpents entrelacés surleurs têtes; alors que Persée; les plongeant dans un deuil éternel; trancha la tête à Méduseleur troisième sœur et avec cet horrible trophée porta la mort dans la maritime Sériphe.[...]Cependant quand Pallas eut délivré de ces travaux périlleux le mortel cher à son cœur …,*,*,*
How to Protect Your Privacy Using Search Engines?,Albin Petit; Thomas Cerqueus; S Ben Mokhtar; Lionel Brunie; Harald Kosch,Abstract Our goal is to design a solution that helps people to protect their privacy while usinga Web search engine. In fact; users; through their millions of queries sent every day tosearch engines; disclose a lot of information (eg; interests; political and religious orientation;health status). This data; stored for each user in a profile; can possibly be used for otherpurposes by the search engine (for instance; commercial purpose) without any agreementfrom the user.,10th European Conference on Computer Systems (EuroSys 2015); poster session,*,*
Response to Emergency Situations in a Traffic Management System,Lotfi ben Othmane; Thomas Cerqueus; Adrien Thiery; Mazeiar Salehie; Nicolas Noel; Anthony Labaere; Rémi Domingues; Arnaud Cordier; Anthony Ventresque; Liliana Pasquale; Philip Perry; Bashar Nuseibeh,Abstract—This paper describes CARDEMO; a Traffic Management System (TMS) designedto assist TMS operators. The CARDEMO prototype applies an emergency response modelto the city of Dublin; Ireland; and suggests a set of security controls for protecting criticalassets (eg; hospitals; schools; banks) from unexpected and harmful events that may occur inthe city. Given an emergency situation; the system collects information about the amenitiesand traffic lights in the area; and uses the response model to recommend a set of securitycontrols to mitigate possible threats.,*,*,*
