Shore-MT: a scalable storage manager for the multicore era,Ryan Johnson; Ippokratis Pandis; Nikos Hardavellas; Anastasia Ailamaki; Babak Falsafi,Abstract Database storage managers have long been able to efficiently handle multipleconcurrent requests. Until recently; however; a computer contained only a few single-coreCPUs; and therefore only a few transactions could simultaneously access the storagemanager's internal structures. This allowed storage managers to use non-scalableapproaches without any penalty. With the arrival of multicore chips; however; this situation israpidly changing. More and more threads can run in parallel; stressing the internalscalability of the storage manager. Systems optimized for high performance at a limitednumber of cores are not assured similarly high performance at a higher core count; becauseunanticipated scalability obstacles arise. We benchmark four popular open-source storagemanagers (Shore; BerkeleyDB; MySQL; and PostgreSQL) on a modern multicore …,Proceedings of the 12th International Conference on Extending Database Technology: Advances in Database Technology,2009,196
Data-oriented transaction execution,Ippokratis Pandis; Ryan Johnson; Nikos Hardavellas; Anastasia Ailamaki,Abstract While hardware technology has undergone major advancements over the pastdecade; transaction processing systems have remained largely unchanged. The number ofcores on a chip grows exponentially; following Moore's Law; allowing for an ever-increasingnumber of transactions to execute in parallel. As the number of concurrently-executingtransactions increases; contended critical sections become scalability burdens. In typicaltransaction processing systems the centralized lock manager is often the first contendedcomponent and scalability bottleneck. In this paper; we identify the conventional thread-to-transaction assignment policy as the primary cause of contention. Then; we design DORA; asystem that decomposes each transaction to smaller actions and assigns actions to threadsbased on which data each action is about to access. DORA's design allows each thread …,Proceedings of the VLDB Endowment,2010,180
Impala: A modern; open-source SQL engine for Hadoop,MKABV Bittorf; Taras Bobrovytsky; Casey Ching Alan Choi Justin Erickson; Martin Grund Daniel Hecht; Matthew Jacobs Ishaan Joshi Lenni Kuff; Dileep Kumar Alex Leblang; Nong Li Ippokratis Pandis Henry Robinson; David Rorke Silvius Rus; John Russell Dimitris Tsirogiannis Skye Wanderman; Milne Michael Yoder,ABSTRACT Cloudera Impala is a modern; open-source MPP SQL engine architected fromthe ground up for the Hadoop data processing environment. Impala provides low latencyand high concurrency for BI/analytic read-mostly queries on Hadoop; not delivered by batchframeworks such as Apache Hive. This paper presents Impala from a user's perspective;gives an overview of its architecture and main components and briefly demonstrates itssuperior performance compared against other popular SQL-on-Hadoop systems.,Proceedings of the 7th Biennial Conference on Innovative Data Systems Research,2015,172
Database servers on chip multiprocessors: Limitations and opportunities,Nikos Hardavellas; Ippokratis Pandis; Ryan Johnson; Naju Mancheril; Anastassia Ailamaki; Babak Falsafi,ABSTRACT Prior research shows that database system performance is dominated by off-chip data stalls; resulting in a concerted effort to bring data into on-chip caches. At the sametime; high levels of integration have enabled the advent of chip multiprocessors andincreasingly large (and slow) on-chip caches. These two trends pose the imminent technicaland research challenge of adapting high-performance data management software to ashifting hardware landscape. In this paper we characterize the performance of a commercialdatabase server running on emerging chip multiprocessor technologies. We find that themajor bottleneck of current software is data cache stalls; with L2 hit stalls rising from oblivionto become the dominant execution time component in some cases. We analyze the sourceof this shift and derive a list of features for future database designs to attain maximum …,*,2007,171
DB2 with BLU acceleration: So much more than just a column store,Vijayshankar Raman; Gopi Attaluri; Ronald Barber; Naresh Chainani; David Kalmuk; Vincent KulandaiSamy; Jens Leenstra; Sam Lightstone; Shaorong Liu; Guy M Lohman; Tim Malkemus; Rene Mueller; Ippokratis Pandis; Berni Schiefer; David Sharpe; Richard Sidle; Adam Storm; Liping Zhang,Abstract DB2 with BLU Acceleration deeply integrates innovative new techniques fordefining and processing column-organized tables that speed read-mostly BusinessIntelligence queries by 10 to 50 times and improve compression by 3 to 10 times; comparedto traditional row-organized tables; without the complexity of defining indexes ormaterialized views on those tables. But DB2 BLU is much more than just a column store.Exploiting frequency-based dictionary compression and main-memory query processingtechnology from the Blink project at IBM Research-Almaden; DB2 BLU performs most SQLoperations-predicate application (even range predicates and IN-lists); joins; and grouping-on the compressed values; which can be packed bit-aligned so densely that multiple valuesfit in a register and can be processed simultaneously via SIMD (single-instruction …,Proceedings of the VLDB Endowment,2013,153
Aether: a scalable approach to logging,Ryan Johnson; Ippokratis Pandis; Radu Stoica; Manos Athanassoulis; Anastasia Ailamaki,Abstract The shift to multi-core hardware brings new challenges to database systems; as thesoftware parallelism determines performance. Even though database systems traditionallyaccommodate simultaneous requests; a multitude of synchronization barriers serializeexecution. Write-ahead logging is a fundamental; omnipresent component in ARIES-styleconcurrency and recovery; and one of the most important yet-to-be addressed potentialbottlenecks; especially in OLTP workloads making frequent small changes to data. In thispaper; we identify four logging-related impediments to database system scalability. Eachissue challenges different level in the software architecture:(a) the high volume of small-sized I/O requests may saturate the disk;(b) transactions hold locks while waiting for the logflush;(c) extensive context switching overwhelms the OS scheduler with threads executing …,Proceedings of the VLDB Endowment,2010,104
Agent based middleware infrastructure for autonomous context-aware ubiquitous computing services,John Soldatos; Ippokratis Pandis; Kostas Stamatis; Lazaros Polymenakos; James L Crowley,Abstract Middleware for ubiquitous and context-aware computing entails several challenges;including the need to balance between transparency and context-awareness and therequirement for a certain degree of autonomy. In this paper we outline most of thesechallenges; and highlight techniques for successfully confronting them. Accordingly; wepresent the design and implementation of a middleware infrastructure for ubiquitouscomputing services; which facilitates development of ubiquitous services; allowing theservice developer to focus on the service logic rather than the middleware implementation.In particular; this infrastructure provides mechanisms for controlling sensors and actuators;dynamically registering and invoking resources and infrastructure elements; as well asmodeling of composite contextual information. A core characteristic of this infrastructure is …,Computer Communications,2007,86
PLP: page latch-free shared-everything OLTP,Ippokratis Pandis; Pinar Tözün; Ryan Johnson; Anastasia Ailamaki,Abstract Scaling the performance of shared-everything transaction processing systems tohighly-parallel multicore hardware remains a challenge for database system designers.Recent proposals alleviate locking and logging bottlenecks in the system; leaving pagelatching as the next potential problem. To tackle the page latching problem; we proposephysiological partitioning (PLP). The PLP design applies logical-only partitioning;maintaining the desired properties of shared-everything designs; and introduces a multi-rooted B+ Tree index structure (MRBTree) which enables the partitioning of the accesses atthe physical page level. Logical partitioning and MRBTrees together ensure that allaccesses to a given index page come from a single thread and; hence; can be entirely latch-free; an extended design makes heap page accesses thread-private as well. Eliminating …,Proceedings of the VLDB Endowment,2011,82
NUMA-aware algorithms: the case of data shuffling.,Yinan Li; Ippokratis Pandis; Rene Mueller; Vijayshankar Raman; Guy M Lohman,ABSTRACT In recent years; a new breed of non-uniform memory access (NUMA) systemshas emerged: multi-socket servers of multicores. This paper makes the case that datamanagement systems need to employ designs that take into consideration thecharacteristics of modern NUMA hardware. To prove our point; we focus on a primitive that isused as the building block of numerous data management operations: data shuffling. Weperform a comparison of different data shuffling algorithms and show that a naıve datashuffling algorithm can be up to 3× slower than the highest performing; NUMA-aware one.To achieve the highest performance; we employ a combination of thread binding; NUMA-aware thread allocation; and relaxed global coordination among threads. The importance ofsuch NUMA-aware algorithm designs will only increase; as future server systems are …,CIDR,2013,77
Improving OLTP scalability using speculative lock inheritance,Ryan Johnson; Ippokratis Pandis; Anastasia Ailamaki,Abstract Transaction processing workloads provide ample request level concurrency whichhighly parallel architectures can exploit. However; the resulting heavy utilization of coredatabase services also causes resource contention within the database engine itself andlimits scalability. Meanwhile; many database workloads consist of short transactions whichaccess only a few database records each; often with stringent response time requirements.Performance of these short transactions is determined largely by the amount of overhead thedatabase engine imposes for services such as logging; locking; and transactionmanagement. This paper highlights the negative scalability impact of database locking; aneffect which is especially severe for short transactions running on highly concurrentmulticore hardware. We propose and evaluate Speculative Lock Inheritance; a technique …,Proceedings of the VLDB Endowment,2009,53
OLTP on hardware islands,Danica Porobic; Ippokratis Pandis; Miguel Branco; Pınar Tözün; Anastasia Ailamaki,Abstract Modern hardware is abundantly parallel and increasingly heterogeneous. Thenumerous processing cores have nonuniform access latencies to the main memory and tothe processor caches; which causes variability in the communication costs. Unfortunately;database systems mostly assume that all processing cores are the same and thatmicroarchitecture differences are not significant enough to appear in critical databaseexecution paths. As we demonstrate in this paper; however; hardware heterogeneity doesappear in the critical path and conventional database architectures achieve suboptimal andeven worse; unpredictable performance. We perform a detailed performance analysis ofOLTP deployments in servers with multiple cores per CPU (multicore) and multiple CPUsper server (multisocket). We compare different database deployment strategies where we …,Proceedings of the VLDB Endowment,2012,51
TPC-E vs. TPC-C: characterizing the new TPC-E benchmark via an I/O comparison study,Shimin Chen; Anastasia Ailamaki; Manos Athanassoulis; Phillip B Gibbons; Ryan Johnson; Ippokratis Pandis; Radu Stoica,Abstract TPC-E is a new OLTP benchmark recently approved by the Transaction ProcessingPerformance Council (TPC). In this paper; we compare TPC-E with the familiar TPCCbenchmark in order to understand the behavior of the new TPC-E benchmark. In particular;we compare the I/O access patterns of the two benchmarks by analyzing two OLTP disktraces. We find that (i) TPC-E is more read intensive with a 9.7: 1 I/O read to write ratio; whileTPC-C sees a 1.9: 1 read-to-write ratio; and (ii) although TPC-E uses pseudo-realistic data;TPC-E's I/O access pattern is as random as TPC-C. The latter suggests that like TPC-C; TPC-E can benefit from SSDs; which have superior random I/O support. To verify this; we replayboth disk traces on an Intel X25-E SSD and see dramatic improvements for both TPC-C andTPC-E.,ACM SIGMOD Record,2011,51
To share or not to share?,Ryan Johnson; Stavros Harizopoulos; Nikos Hardavellas; Kivanc Sabirli; Ippokratis Pandis; Anastasia Ailamaki; Naju G Mancheril; Babak Falsafi,Abstract Intuitively; aggressive work sharing among concurrent queries in a databasesystem should always improve performance by eliminating redundant computation or dataaccesses. We show that; contrary to common intuition; this is not always the case in practice;especially in the highly parallel world of chip multiprocessors. As the number of cores in thesystem increases; a trade-off appears between exploiting work sharing opportunities and theavailable parallelism. To resolve the trade-off; we develop an analytical approach thatpredicts the effect of work sharing in multi-core systems. Database systems can use themodel to determine; statically or at runtime; whether work sharing is beneficial and apply itonly when appropriate. The contributions of this paper are as follows. First; we introduce andanalyze the effects of the trade-off between work sharing and parallelism on database …,Proceedings of the 33rd international conference on Very large data bases,2007,50
Scalability of write-ahead logging on multicore and multisocket hardware,Ryan Johnson; Ippokratis Pandis; Radu Stoica; Manos Athanassoulis; Anastasia Ailamaki,Abstract The shift to multi-core and multi-socket hardware brings new challenges todatabase systems; as the software parallelism determines performance. Even thoughdatabase systems traditionally accommodate simultaneous requests; a multitude ofsynchronization barriers serialize execution. Write-ahead logging is a fundamental;omnipresent component in ARIES-style concurrency and recovery; and one of the mostimportant yet-to-be addressed potential bottlenecks; especially in OLTP workloads makingfrequent small changes to data. In this paper; we identify four logging-related impediments todatabase system scalability. Each issue challenges different level in the softwarearchitecture:(a) the high volume of small-sized I/O requests may saturate the disk;(b)transactions hold locks while waiting for the log flush;(c) extensive context switching …,The VLDB Journal—The International Journal on Very Large Data Bases,2012,43
From A to E: analyzing TPC's OLTP benchmarks: the obsolete; the ubiquitous; the unexplored,Pınar Tözün; Ippokratis Pandis; Cansu Kaynak; Djordje Jevdjic; Anastasia Ailamaki,Abstract Introduced in 2007; TPC-E is the most recently standardized OLTP benchmark byTPC. Even though TPC-E has already been around for six years; it has not gained thepopularity of its predecessor TPC-C: all the published results for TPC-E use a singledatabase vendor's product. TPC-E is significantly different than its predecessors. Some of itsdistinguishing characteristics are the non-uniform input creation; longer-running and morecomplicated transactions; more difficult partitioning etc. These factors slow down theadoption of TPC-E. In turn; there is little knowledge in the community about how TPC-Ebehaves micro-architecturally and within the database engine. To shed light on TPC-E; weimplement it on top of a scalable open-source database engine; Shore-MT; and perform aworkload characterization study; comparing it with the previous; much better known OLTP …,Proceedings of the 16th International Conference on Extending Database Technology,2013,41
Memory-efficient hash joins,Ronald Barber; Guy Lohman; Ippokratis Pandis; Vijayshankar Raman; Richard Sidle; G Attaluri; Naresh Chainani; Sam Lightstone; David Sharpe,Abstract We present new hash tables for joins; and a hash join based on them; thatconsumes far less memory and is usually faster than recently published in-memory joins.Our hash join is not restricted to outer tables that fit wholly in memory. Key to this hash join isa new concise hash table (CHT); a linear probing hash table that has 100% fill factor; anduses a sparse bitmap with embedded population counts to almost entirely avoid collisions.This bitmap also serves as a Bloom filter for use in multi-table joins. We study the randomaccess characteristics of hash joins; and renew the case for non-partitioned hash joins. Weintroduce a variant of partitioned joins in which only the build is partitioned; but the probe isnot; as this is more efficient for large outer tables than traditional partitioned joins. This alsoavoids partitioning costs during the probe; while at the same time allowing parallel build …,Proceedings of the VLDB Endowment,2014,36
An ontology-based framework for dynamic resource management in ubiquitous computing environments,Ippokratis Pandis; John Soldatos; Alexander Paar; Jurgen Reuter; Michael Carras; Lazaros Polymenakos,Ubiquitous computing applications are supported by sophisticated middleware componentsenabling dynamic discovery; invocation and management of resources; as well asreasoning in cases of uncertainty. This paper advocates semantic Web technologies asprimary vehicles to achieve dynamic management of resources in ubiquitous computinginfrastructures and services. We introduce a framework for implementing ubiquitouscomputing services comprising a large number of sensors and perceptive interfaces;emphasizing the role of knowledge bases for dynamic registration and invocation ofresources. We present the use of ontology-based mechanisms for controlling sensors andactuators. Moreover; we describe the implementation of a knowledge base server that canleverage different ontology management systems; while also exposing a host to different …,Embedded Software and Systems; 2005. Second International Conference on,2005,33
Business Analytics in (a) Blink.,Ronald Barber; Peter Bendel; Marco Czech; Oliver Draese; Frederick Ho; Namik Hrle; Stratos Idreos; Min-Soo Kim; Oliver Koeth; Jae-Gil Lee; Tianchao Tim Li; Guy M Lohman; Konstantinos Morfonios; René Müller; Keshava Murthy; Ippokratis Pandis; Lin Qiao; Vijayshankar Raman; Richard Sidle; Knut Stolze; Sandor Szabo,Abstract The Blink project's ambitious goal is to answer all Business Intelligence (BI) queriesin mere seconds; regardless of the database size; with an extremely low total cost ofownership. Blink is a new DBMS aimed primarily at read-mostly BI query processing thatexploits scale-out of commodity multi-core processors and cheap DRAM to retain a (copy ofa) data mart completely in main memory. Additionally; it exploits proprietary compressiontechnology and cache-conscious algorithms that reduce memory bandwidth consumptionand allow most SQL query processing to be performed on the compressed data. Blinkalways scans (portions of) the data mart in parallel on all nodes; without using any indexesor materialized views; and without any query optimizer to choose among them. The Blinktechnology has thus far been incorporated into two IBM accelerator products generally …,IEEE Data Eng. Bull.,2012,30
Critical sections: re-emerging scalability concerns for database storage engines,Ryan Johnson; Ippokratis Pandis; Anastasia Ailamaki,Abstract Critical sections in database storage engines impact performance and scalabilitymore as the number of hardware contexts per chip continues to grow exponentially. Withenough threads in the system; some critical section will eventually become a bottleneck.While algorithmic changes are the only long-term solution; they tend to be complex andcostly to develop. Meanwhile; changes in enforcement of critical sections require much lesseffort. We observe that; in practice; many critical sections are so short that enforcing themcontributes a significant or even dominating fraction of their total cost and tuning themdirectly improves database system performance. The contribution of this paper is two-fold:we (a) make a thorough performance comparison of the various synchronization primitivesin the database system developer's toolbox and highlight the best ones for practical use …,Proceedings of the 4th international workshop on Data management on new hardware,2008,26
Offering open hypermedia services to the WWW: a step-by-step approach for developers,Nikos Karousos; Ippokratis Pandis; Siegfried Reich; Manolis Tzagarakis,Abstract Hypermedia systems and more specifically open hypermedia systems (OHS)provide a rich set of implementations of different hypertext flavors such as navigationalhypertext; spatial hypertext or taxonomic hypertext. Additionally; these systems offercomponent-based modular architectures and address interoperability between hypertextdomains. Despite multiple efforts of integrating Web clients; a widespread adoption of OHStechnology by Web developers has not taken place. In this paper it is argued that WebServices-which offer a component model for Web applications-can be integrated in OHSs.An architectural integration is proposed; a step-by-step process is outlined and an exampleof integration is provided. This very approach is aimed to benefit both worlds: the Webcommunity with new rich hypermedia functionality that extends the current navigational …,Proceedings of the 12th international conference on World Wide Web,2003,25
Eliminating unscalable communication in transaction processing,Ryan Johnson; Ippokratis Pandis; Anastasia Ailamaki,Abstract Multicore hardware demands software parallelism. Transaction processingworkloads typically exhibit high concurrency; and; thus; provide ample opportunities forparallel execution. Unfortunately; because of the characteristics of the application;transaction processing systems must moderate and coordinate communication betweenindependent agents; since it is notoriously difficult to implement high performing transactionprocessing systems that incur no communication whatsoever. As a result; transactionprocessing systems cannot always convert abundant; even embarrassing; request-levelparallelism into execution parallelism due to communication bottlenecks. Transactionprocessing system designers must therefore find ways to achieve scalability while stillallowing communication to occur. To this end; we identify three forms of communication in …,The VLDB Journal,2014,22
Scalable and dynamically balanced shared-everything OLTP with physiological partitioning,Pınar Tözün; Ippokratis Pandis; Ryan Johnson; Anastasia Ailamaki,Abstract Scaling the performance of shared-everything transaction processing systems tohighly parallel multicore hardware remains a challenge for database system designers.Recent proposals alleviate locking and logging bottlenecks in the system; leaving pagelatching as the next potential problem. To tackle the page latching problem; we proposephysiological partitioning (PLP). PLP applies logical-only partitioning; maintaining thedesired properties of sharedeverything designs; and introduces a multi-rooted B+ Tree indexstructure (MRBTree) that enables the partitioning of the accesses at the physical page level.Logical partitioning and MRBTrees together ensure that all accesses to a given index pagecome from a single thread and; hence; can be entirely latch free; an extended design makesheap page accesses thread private as well. Moreover; MRBTrees offer an infrastructure …,The VLDB Journal—The International Journal on Very Large Data Bases,2013,20
Ermia: Fast memory-optimized database system for heterogeneous workloads,Kangnyeon Kim; Tianzheng Wang; Ryan Johnson; Ippokratis Pandis,Abstract Large main memories and massively parallel processors have triggered not only aresurgence of high-performance transaction processing systems optimized for large main-memory and massively parallel processors; but also an increasing demand for processingheterogeneous workloads that include read-mostly transactions. Many modern transactionprocessing systems adopt a lightweight optimistic concurrency control (OCC) scheme toleverage its low overhead in low contention workloads. However; we observe that thelightweight OCC is not suitable for heterogeneous workloads; causing significant starvationof read-mostly transactions and overall performance degradation. In this paper; we presentERMIA; a memory-optimized database system built from scratch to cater the need ofhandling heterogeneous workloads. ERMIA adopts snapshot isolation concurrency …,Proceedings of the 2016 International Conference on Management of Data,2016,19
Semantic web technologies for ubiquitous computing resource management in smart spaces,John Soldatos; Kostas Stamatis; Siamak Azodolmolky; Ippokratis Pandis; Lazaros Polymenakos,Context-aware ubiquitous computing environments tend to be highly distributed andheterogeneous; while also featuring increased dynamism as elements; devices andmiddleware components join; leave and change their status. In such environments;information is derived and fused with numerous sensors and context-aware middlewarecomponents. As a result; directory and naming services; along with reasoning mechanisms;are at the heart of any non-trivial ubiquitous computing application. In this paper; we arguethat semantic web technologies can deal with directory service requirements of ubiquitouscomputing environments; much more efficiently than the wide range of legacy mechanisms.To justify this claim; we introduce a model that could greatly facilitate the development;deployment and management of ubiquitous computing applications. This model relies on …,International Journal of Web Engineering and Technology,2007,19
The bionic DBMS is coming; but what will it look like?,Ryan Johnson; Ippokratis Pandis,ABSTRACT Software has always ruled database engines; and commodity processors ridingMoore's Law doomed database machines of the 1980s from the start. However; today'shardware landscape is very different; and moving in directions that make databasemachines increasingly attractive. Stagnant clock speeds; looming dark silicon; availability ofreconfigurable hardware; and the economic clout of cloud providers all align to make customdatabase hardware economically viable or even necessary. Dataflow workloads (businessintelligence and streaming) already benefit from emerging hardware support. In this paper;we argue that control flow workloads—with their corresponding latencies—are anotherfeasible target for hardware support. To make our point; we outline a transaction processingarchitecture that offloads much of its functionality to reconfigurable hardware. We predict …,Proceedings of the 6th Biennial Conference on Innovative Data Systems Research,2013,12
Simultaneous pipelining in QPipe: Exploiting work sharing opportunities across queries,Kun Gao; Stavros Harizopoulos; Ippokratis Pandis; Vladislav Shkapenyuk; Anastassia Ailamaki,Data warehousing and scientific database applications operate on massive datasets andare characterized by complex queries accessing large portions of the database. Concurrentqueries often exhibit high data and computation overlap; eg; they access the same relationson disk; compute similar aggregates; or share intermediate results. Unfortunately; run-timesharing in modern database engines is limited by the paradigm of invoking an independentset of operator instances per query; potentially missing sharing opportunities if the bufferpool evicts data early.,Data Engineering; 2006. ICDE'06. Proceedings of the 22nd International Conference on,2006,12
Blink: Not Your Father’s Database!,Ronald Barber; Peter Bendel; Marco Czech; Oliver Draese; Frederick Ho; Namik Hrle; Stratos Idreos; Min-Soo Kim; Oliver Koeth; Jae-Gil Lee; Tianchao Tim Li; Guy Lohman; Konstantinos Morfonios; Rene Mueller; Keshava Murthy; Ippokratis Pandis; Lin Qiao; Vijayshankar Raman; Sandor Szabo; Richard Sidle; Knut Stolze,Abstract The Blink project's ambitious goals are to answer all Business Intelligence (BI)queries in mere seconds; regardless of the database size; with an extremely low total cost ofownership. It takes a very innovative and counter-intuitive approach to processing BIqueries; one that exploits several disruptive hardware and software technology trends.Specifically; it is a new; workload-optimized DBMS aimed primarily at BI query processing;and exploits scale-out of commodity multi-core processors and cheap DRAM to retain a(copy of a) data mart completely in main memory. Additionally; it exploits proprietarycompression technology and cache-conscious algorithms that reduce memory bandwidthconsumption and allow most SQL query processing to be performed on the compresseddata. Ignoring the general wisdom of the last three decades that the only way to scalably …,International Workshop on Business Intelligence for the Real-Time Enterprise,2011,11
Joins on encoded and partitioned data,Jae-Gil Lee; Gopi Attaluri; Ronald Barber; Naresh Chainani; Oliver Draese; Frederick Ho; Stratos Idreos; Min-Soo Kim; Sam Lightstone; Guy Lohman; Konstantinos Morfonios; Keshava Murthy; Ippokratis Pandis; Lin Qiao; Vijayshankar Raman; Vincent Kulandai Samy; Richard Sidle; Knut Stolze; Liping Zhang,Abstract Compression has historically been used to reduce the cost of storage; I/Os from thatstorage; and buffer pool utilization; at the expense of the CPU required to decompress dataevery time it is queried. However; significant additional CPU efficiencies can be achieved bydeferring decompression as late in query processing as possible and performing queryprocessing operations directly on the still-compressed data. In this paper; we investigate thebenefits and challenges of performing joins on compressed (or encoded) data. Wedemonstrate the benefit of independently optimizing the compression scheme of each joincolumn; even though join predicates relating values from multiple columns may requiretranslation of the encoding of one join column into the encoding of the other. We also showthe benefit of compressing" payload" data other than the join columns" on the fly;" to …,Proceedings of the VLDB Endowment,2014,9
Developer Support in Open Hypermedia Systems: Towards a Hypermedia Service Discovery Mechanism,Nikos Karousos; Ippokratis Pandis,Abstract This paper argues that the open hypermedia research community should focus onthe developer support issue. An enabling step to this target is the provision of an effectiveand easy-to-use hypermedia service discovery mechanism. The inexistence of such kind ofmechanism; for finding and using hypermedia services; amongst the Open HypermediaSystems (OHSs) is one of the main reasons for their narrow publicity and usage. Aiming tothe improvement of the third party (hypermedia-unaware) developer support; thehypermedia service discovery mechanism will boost the OHS usage by providing a standardplatform and a set of tools in order to enable the enhancement of third party applications withhypermedia functionality.,International Symposium on Metainformatics,2003,9
The serial safety net: Efficient concurrency control on modern hardware,Tianzheng Wang; Ryan Johnson; Alan Fekete; Ippokratis Pandis,Abstract Concurrency control (CC) algorithms must trade off strictness for performance; withserializable schemes generally paying high cost---both in runtime overhead such ascontention on lock tables; and in wasted efforts by aborting transactions---to preventanomalies. We propose the serial safety net (SSN); a serializability-enforcing certifier formodern hardware with substantial core count and large main memory. SSN can be appliedwith minimal overhead on top of various CC schemes that offer higher performance butadmit anomalies; eg; snapshot isolation and read committed.,Proceedings of the 11th International Workshop on Data Management on New Hardware,2015,8
A data-oriented transaction execution engine and supporting tools,Ippokratis Pandis; Pinar Tözün; Miguel Branco; Dimitris Karampinas; Danica Porobic; Ryan Johnson; Anastasia Ailamaki,Abstract Conventional OLTP systems assign each transaction to a worker thread and thatthread accesses data; depending on what the transaction dictates. This thread-to-transactionwork assignment policy leads to unpredictable accesses. The unpredictability forces eachthread to enter a large number of critical sections for the completion of even the simplest ofthe transactions; leading to poor performance and scalability on modern manycorehardware. This demonstration highlights the chaotic access patterns of conventional OLTPdesigns which are the source of scalability problems. Then; it presents a working prototypeof a transaction processing engine that follows a non-conventional architecture; called data-oriented or DORA. DORA is designed around the thread-to-data work assignment policy. Itdistributes the transaction execution to multiple threads and offers predictable accesses …,Proceedings of the 2011 ACM SIGMOD International Conference on Management of data,2011,8
Babylon bookmarks: a taxonomic approach to the management of WWW bookmarks,Nikos Karousos; Ioannis Panaretou; Ippokratis Pandis; Manolis Tzagarakis,Abstract Taxonomic reasoning can be a useful organization paradigm to address issuesdealing with the management of WWW bookmarks. Management of WWW bookmarkscomprise one of the most frequent activities of WWW users. In this paper;“BabylonBookmarks” are presented allowing users to apply taxonomic reasoning on WWWbookmarks.“Babylon Bookmarks” is based on the “Babylon System;” an infrastructure tosupport general taxonomic reasoning tasks. The “Babylon System” allows the developmentof arbitrary taxonomic services based on Open Hypermedia Specifications.,International Symposium on Metainformatics,2002,7
On-the-fly encoding method for efficient grouping and aggregation,*,Embodiments include a system for encoding data while it is being processed. The systemincludes a processor; an encoder and a decoder. The processor is configured to process aquery request by determining a set of values. The encoder is configured for encoding the setof values; such that a subsequent processing operation can be performed on the encodedvalues. The processor performs the subsequent processing operations. The decoder isconfigured for decoding each value back to its value prior to being encoded uponcompletion of the processor completing the requested query.,*,2016,6
Tutorial: SQL-on-Hadoop Systems,Daniel Abadi; Shivnath Babu; Fatma Ozcan; Ippokratis Pandis,*,Proceedings of the VLDB Endowment,2015,6
On-the-fly encoding method for efficient grouping and aggregation,*,Embodiments include a method and computer program product for encoding data while it isbeing processed as part of a query is provided. The method includes receiving a queryrequest and determining a set of values associated with data to be encoded for completingthe query request. The method also includes encoding those values such that anysubsequent processing operations can be performed on the encoded values to complete therequested query. After performing the subsequent processing operations to complete therequested query; each value is decoded back to its original value.,*,2016,5
SQL-on-hadoop systems: tutorial,Daniel Abadi; Shivnath Babu; Fatma Özcan; Ippokratis Pandis,Abstract Enterprises are increasingly using Apache Hadoop; more specifically HDFS; as acentral repository for all their data; data coming from various sources; including operationalsystems; social media and the web; sensors and smart devices; as well as their applications.At the same time many enterprise data management tools (eg from SAP ERP and SAS toTableau) rely on SQL and many enterprise users are familiar and comfortable with SQL. Asa result; SQL processing over Hadoop data has gained significant traction over the recentyears; and the number of systems that provide such capability has increased significantly. Inthis tutorial we use the term SQL-on-Hadoop to refer to systems that provide some level ofdeclarative SQL (-like) processing over HDFS and noSQL data sources; using architecturesthat include computational or storage engines compatible with Apache Hadoop.,Proceedings of the VLDB Endowment,2015,5
Toward scalable transaction processing: evolution of shore-MT,Anastasia Ailamaki; Ryan Johnson; Ippokratis Pandis; Pínar Tözün,Abstract Designing scalable transaction processing systems on modern multicore hardwarehas been a challenge for almost a decade. The typical characteristics of transactionprocessing workloads lead to a high degree of unbounded communication on multicores forconventional system designs. In this tutorial; we initially present a systematic way ofeliminating scalability bottlenecks of a transaction processing system; which is based onminimizing the unbounded communication. Then; we show several techniques that applythe presented methodology to minimize logging; locking; latching etc. related bottlenecks oftransaction processing systems. In parallel; we demonstrate the internals of the Shore-MTstorage manager and how they have evolved over the years in terms of scalability onmulticore hardware through such techniques. We also teach how to use Shore-MT with …,Proceedings of the VLDB Endowment,2013,4
Scalable Transaction Processing through Data-oriented Execution,Ippokratis Pandis,Abstract Data management technology changes the world we live in by providing efficientaccess to huge volumes of constantly changing data and by enabling sophisticated analysisof those data. Recently there has been an unprecedented increase in the demand for datamanagement services. In parallel; we have witnessed a tremendous shift in the underlyinghardware technology toward highly parallel multicore processors. In order to cope with theincreased demand and user expectations; data management systems need to fully exploitabundantly available hardware parallelism.,*,2012,4
Semantically annotated hypermedia services,Ippokratis Pandis; Nikos Karousos; Thanassis Tiropanis,Abstract Hypermedia systems' researchers investigate the various approaches in the waydocuments and resources are linked; navigated and stored in a distributed environment.Unfortunately; those systems fail to provide effortlessly usable discrete services; since it isdifficult both to discover and to invoke any of them. This paper proposes the usage ofemerging technologies that try to augment the Web resources with semantics in order toprovide Hypermedia services that can be easily discovered; and integrated by potential thirdparty developers. In this context; we analyze the benefits for the Hypermedia communityupon the adoption of Semantic Web technologies for the description of Hypermediaservices; and we implement an initial corresponding ontology.,Proceedings of the sixteenth ACM conference on Hypertext and hypermedia,2005,4
Efficiently making (almost) any concurrency control mechanism serializable,Tianzheng Wang; Ryan Johnson; Alan Fekete; Ippokratis Pandis,Abstract Concurrency control (CC) algorithms must trade off strictness for performance. Inparticular; serializable CC schemes generally pay higher cost to prevent anomalies; both inruntime overhead such as the maintenance of lock tables and in efforts wasted by abortingtransactions. We propose the serial safety net (SSN); a serializability-enforcing certifierwhich can be applied on top of various CC schemes that offer higher performance but admitanomalies; such as snapshot isolation and read committed. The underlying CC mechanismretains control of scheduling and transactional accesses; while SSN tracks the resultingdependencies. At commit time; SSN performs a validation test by examining only directdependencies of the committing transaction to determine whether it can commit safely ormust abort to avoid a potential dependency cycle. SSN performs robustly for a variety of …,The VLDB Journal,2017,3
Operational analytics data management systems,Alexander Böhm; Jens Dittrich; Niloy Mukherjee; Ippokratis Pandis; Rajkumar Sen,Abstract Prior to mid-2000s; the space of data analytics was mainly confined within the areaof decision support systems. It was a long era of isolated enterprise data ware housescurating information from live data sources and of business intelligence software used toquery such information. Most data sets were small enough in volume and static enoughinvelocity to be segregated in warehouses for analysis. Data analysis was not ad-hoc; itrequired pre-requisite knowledge of underlying data access patterns for the creation ofspecialized access methods (eg covering indexes; materialized views) in order to efficientlyexecute a set of few focused queries.,Proceedings of the VLDB Endowment,2016,3
Implementation of tpc-h and tpc-c toolkits,Kun Gao; Ippokratis Pandis,*,CS and ECE Departments; Carnegie Mellon University http://www. cs. cmu. edu/~ ipandis/courses/15823/project_final_paper. pdf,*,3
Pooling work across multiple transactions for reducing contention in operational analytics systems,*,A method includes scanning multiple incoming database transaction requests. Eachtransaction includes one or more operations. Operations are clustered into a set ofcombined operations based on type of operation constraints. Log records are prepared andwritten for re-performing operations upon system failures; and for undoing operations uponan operation or a transaction failing to be processed fully. Each set of combined operationsare performed within a thread. Each update operation is marked for a transaction withinwhich the update operation belongs. Recoverable update operations belonging to a pluralityof transactions are performed within a single logical thread of execution.,*,2017,2
Characterization of the Impact of Hardware Islands on OLTP,Danica Porobic; Ippokratis Pandis; Miguel Branco; Pınar Tözün; Anastasia Ailamaki,Abstract Modern hardware is abundantly parallel and increasingly heterogeneous. Thenumerous processing cores have non-uniform access latencies to the main memory andprocessor caches; which causes variability in the communication costs. Unfortunately;database systems mostly assume that all processing cores are the same and thatmicroarchitecture differences are not significant enough to appear in critical databaseexecution paths. As we demonstrate in this paper; however; non-uniform core topology doesappear in the critical path and conventional database architectures achieve suboptimal andeven worse; unpredictable performance. We perform a detailed performance analysis ofOLTP deployments in servers with multiple cores per CPU (multicore) and multiple CPUsper server (multisocket). We compare different database deployment strategies where we …,The VLDB Journal,2016,2
Parallel build of non-partitioned join hash tables and non-enforced n: 1 join hash tables,*,A method for building a hash table over a subset of data in a data set includes mapping keysin the data set to values in the data set using multiple parallel computation threads. Eachthread scans a subset of the keys and values and partitioning the subset of the keys andvalues into multiple partitions. A cumulative count for keys and values in each partition isdetermined. A hash table with space reserved for each partition is formed based on thedetermined cumulative counts. Each thread selects one or more partitions and inserts keysand values belonging to the selected one or more partitions into the hash table in thereserved space for those partitions.,*,2016,2
Efficient join on dynamically compressed inner for improved fit into cache hierarchy,*,A method includes joining data between at least two data sets. Values of one or more joinattributes of each of the data sets is represented in a compressed form; indicated by anencoding scheme. A compression scheme for the one or more join attributes is dynamicallyselected.,*,2016,2
Efficient performance of insert and point query operations in a column store,*,A method includes logically organizing; by an object hierarchy processor; data objects in afirst hierarchy. A portion of the data objects in the first hierarchy logically includes groupingsof other data objects. The object hierarchy processor physically organizes the data objectsacross two or more types of memory in a second hierarchy. Another portion of the dataobjects in the second hierarchy physically includes groupings of other data objects.Groupings of the data objects in the second hierarchy are dynamically moved across the twoor more types of memory. Levels of access of the data objects are tracked using a datastructure that maps groupings of the data objects in the first hierarchy onto metadatainformation including combined access frequencies of the data objects; and current numberof accessors to the data objects; in each grouping of the data objects.,*,2016,2
On-the-fly encoding method for efficient grouping and aggregation,*,Embodiments include a method; system; and computer program product for encoding datawhile it is being processed as part of a query is provided. The method includes receiving aquery request and determining a set of values associated with data to be encoded forcompleting the query request. The method also includes encoding those values such thatany subsequent processing operations can be performed on the encoded values tocomplete the requested query. After performing the subsequent processing operations tocomplete the requested query; each value is decoded back to its original value.,*,2016,2
Data shuffling in a non-uniform memory access device,*,Embodiments relate to the orchestration of data shuffling among memory devices of a non-uniform memory access device. An aspect includes a method of orchestrated shuffling ofdata in a non-uniform memory access device includes running an application on a pluralityof threads executing on a plurality of processing nodes and identifying data to be shuffledamong the plurality of processing nodes. The method includes registering the data to beshuffled and generating a plan for orchestrating the shuffling of the data. The method furtherincludes disabling cache coherency of cache memory associated with the processing nodesand shuffling the data among all of the memory devices upon disabling the cachecoherency; the shuffling performed based on the plan for orchestrating the shuffling. Themethod further includes restoring the cache coherency of the cache memory based on …,*,2016,2
Robust concurrency control in main-memory DBMS: What main memory giveth; the application taketh away.,Ryan Johnson; Kangnyeon Kim; Tianzheng Wang; Ippokratis Pandis,Modern systems with large main memories and massively parallel processors have inspiredmany new high-performance OLTP systems [2–4; 6]; often referred to as main memoryDBMS (MMDBMS). These systems leverage spacious main memory to fit the whole workingset in DRAM with streamlined; memoryfriendly data structures; further; optimizations formulticore and multi-socket hardware allow a much higher level of parallelism compared toconventional database systems. With disk overheads and delays removed; transactionlatencies drop precipitously and worker threads can usually execute transactions tocompletion without in-terruption. The result is a welcome reduction in contention and lesspressure on whatever concurrency control (CC) scheme might be in place. Meanwhile;database workloads are evolving to become increasingly heterogeneous; blending the …,IMDM@ VLDB,2014,2
Next generation data analytics at IBM research,Oktie Hassanzadeh; Anastasios Kementsietsidis; Benny Kimelfeld; Rajasekar Krishnamurthy; Fatma Özcan; Ippokratis Pandis,IBM Research has a rich history of innovation in information management with severalrevolutionary breakthroughs; including the invention of relational databases; advanced textanalytics demonstrated by Watson; and the first data mining algorithms to name a few. IBMResearch has been committed to contributing to the community via seminal papers;exemplified by several 10-year awards received by IBM researchers. This short abstract isintended as a quick tour of some of the current information management projects; and notmeant to be an exhaustive list by any means. There has been many disruptive technologicaldevelopments over the last decade. The emergence of cloud computing; and several largescale data processing platforms; advances in on-line social media; the explosion of datavolumes; and the advances in hardware have all forced us to rethink the information …,Proceedings of the VLDB Endowment,2013,2
Increasing the usage of open hypermedia systems: a developer-side approach,Nikos Karousos; Manolis Tzagarakis; Ippokratis Pandis,Abstract This paper argues that the existence of a developer support framework is a criticalissue to the usage of Open Hypermedia Systems (OHSs). For this reason; the OHSCommunity would benefit by the adoption of both a service discovery mechanism and a setof standards and tools to approach the development of hypermedia clients in a transparentand methodological manner.,Proceedings of the fourteenth ACM conference on Hypertext and hypermedia,2003,2
Query Processor,Anastasia Ailamaki; Ippokratis Pandis,In general; the term Quadtree refers to a class of representations of geometric entities (suchas points; line segments; polygons; regions) in a space of two (or more) dimensions; thatrecursively decompose the space containing these entities into blocks until the data in eachblock satisfy some condition (with respect; for example; to the block size; the number of blockentities; the characteristics of the block entities; etc.). In a more restricted sense; the termQuadtree (Octree) refers to a tree data-structure in which each internal node has four (eight)children and is used for the representation of geometric entities in a two (three) dimensionalspace. The root of the tree represents the whole space/region. Each child of a noderepresents a subregion of the subregion of its parent. The subregions of the siblingsconstitute a partition of the parent's regions. Several variations of quadtrees are possible …,*,2009,1
Shore-MT: A Quest for Scalability in the Many-Core Era,Ryan Johnson; Ippokratis Pandis; Nikolaos Hardavellas; Anastasia Ailamaki,Johnson; R.; Pandis; I.; Hardavellas; N.; & Ailamaki; A. (2008). Shore-MT: A Quest for Scalabilityin the Many-Core Era. Unknown Publisher … Shore-MT: A Quest for Scalability in theMany-Core Era. / Johnson; Ryan; Pandis; Ippokratis; Hardavellas; Nikolaos; Ailamaki;Anastasia … Johnson; R; Pandis; I; Hardavellas; N & Ailamaki; A 2008; Shore-MT: A Questfor Scalability in the Many-Core Era. Unknown Publisher … Johnson R; Pandis I; HardavellasN; Ailamaki A. Shore-MT: A Quest for Scalability in the Many-Core Era. Unknown Publisher;2008 … Johnson; Ryan ; Pandis; Ippokratis ; Hardavellas; Nikolaos ; Ailamaki; Anastasia. /Shore-MT: A Quest for Scalability in the Many-Core Era. Unknown Publisher; 2008 … Poweredby Pure; Scopus & Elsevier Fingerprint Engine™ © 2017 Elsevier BV.,*,2008,1
An analysis of database system performance on chip multiprocessors,Nikos Hardavellas; Ippokratis Pandis; Ryan Johnson; Naju Mancheril; Anastasia Ailamaki; Babak Falsafi,ABSTRACT Prior research shows that database system performance is dominated by off-chip data stalls; resulting in a concerted effort to bring data into on-chip caches. At the sametime; high levels of integration have enabled the advent of chip multiprocessors andincreasingly large (and slow) on-chip caches. These two trends pose the imminent technicaland research challenge of adapting high-performance data management software to ashifting hardware landscape. In this paper we characterize the performance of a commercialdatabase server running on emerging chip multiprocessor technologies. We find that themajor bottleneck of current software is data cache stalls; with L2 hit stalls rising from oblivionto become the dominant execution time component in some cases. We analyze the sourceof this shift and derive a list of features for future database designs to attain maximum …,*,2007,1
Adaptive Payload Management,*,Embodiments relate to payload storage format for storing data in support of an aggregationfunction. As an input is subject to aggregation; the input is evaluated to ascertain a payloadformat for the aggregation. It is understood that there is more than one payload format. Anevaluation of the aggregation key is a factor in the initial payload format. If the key is anaddition to an existing aggregation; the evaluation considers changing the format of thepayload to address processing and/or memory efficiency for the aggregation. The evaluationand the format change takes place dynamically so that the aggregation may continue.,*,2017,*
Adaptive payload management,*,Embodiments of the invention relate to payload storage format for storing data in support ofan aggregation function. As an input is subject to aggregation; the input is evaluated toascertain a payload format for the aggregation. It is understood that there is more than onepayload format. An evaluation of the aggregation key is a factor in the initial payload format.If the key is an addition to an existing aggregation; the evaluation considers changing theformat of the payload to address processing and/or memory efficiency for the aggregation.The evaluation and the format change takes place dynamically so that the aggregation maycontinue.,*,2017,*
Query Fresh: Log Shipping on Steroids,Tianzheng Wang; Ryan Johnson; Ippokratis Pandis,ABSTRACT Hot standby systems often have to trade safety (ie; not losing committed work)and freshness (ie; having access to recent updates) for performance. Guaranteeing safetyrequires synchronous log shipping that blocks the primary until the log records are durablyreplicated in one or multiple backups; maintaining freshness necessitates fast log replay onbackups; but is often defeated by the dual-copy architecture and serial replay: a backupmust generate the “real” data from the log to make recent updates accessible to read-onlyqueries. This paper proposes Query Fresh; a hot standby system that provides both safetyand freshness while maintaining high performance on the primary. The crux is an append-only storage architecture used in conjunction with fast networks (eg; InfiniBand) andbyteaddressable; non-volatile memory (NVRAM). Query Fresh avoids the dual-copy …,Proceedings of the VLDB Endowment,2017,*
Logical data shuffling,*,Embodiments relate to data shuffling by logically rotating processing nodes. The nodes arelogically arranged in a two or three dimensional matrix. Every time two of the nodes inadjacent rows of the matrix are positionally aligned; these adjacent nodes exchange data.The positional alignment is a logical alignment of the nodes. The nodes are logicallyarranged and rotated; and data is exchanged in response to the logical rotation.,*,2016,*
Data shuffling in a non-uniform memory access device,*,A method of orchestrated shuffling of data in a non-uniform memory access device thatincludes a plurality of processing nodes that are connected by interconnects. The methodincludes running an application on a plurality of threads executing on the plurality ofprocessing nodes. Data to be shuffled is identified from source threads running on sourceprocessing nodes among the processing nodes to target threads executing on targetprocessing nodes among the processing nodes. The method further includes generating aplan for orchestrating the shuffling of the data among the all of the memory devicesassociated with the threads and for simultaneously transmitting data over differentinterconnects to a plurality of different target processing nodes from a plurality of differentsource processing nodes. The data is shuffled among all of the memory devices based on …,*,2016,*
Data shuffling in a non-uniform memory access device,*,A method of orchestrated shuffling of data in a non-uniform memory access device thatincludes a plurality of processing nodes includes running an application on a plurality ofthreads executing on the plurality of processing nodes and identifying data to be shuffledfrom source threads running on source processing nodes among the processing nodes totarget threads executing on target processing nodes among the processing nodes. Themethod further includes generating a plan for orchestrating the shuffling of the data amongthe all of the memory devices associated with the threads and shuffling the data among all ofthe memory devices based on the plan.,*,2016,*
Accurate partition sizing for memory efficient reduction operations,*,Embodiments of the invention relate to processing data records; and for a multi-phasepartitioned data reduction. The first phase relates to processing data records and partitioningthe records into a first partition of records having a common characteristic and a secondpartition of records that are not members of the first partition. The data records in eachpartition are subject to intra-partition data reduction responsive to a resource constraint. Thedata records in each partition are also subject to an inter-partition data reduction; alsoreferred to as an aggregation to reduce a footprint for storing the records. Partitions and/orindividual records are logically aggregated and a data reduction operation for the logicalaggregation of records takes place in response to available resources.,*,2016,*
Impala: Eine moderne; quellen-offene SQL Engine für Hadoop,Marcel Kornacker; Alexander Behm; Victor Bittorf; Taras Bobrovytsky; Casey Ching; Alan Choi; Justin Erickson; Martin Grund; Daniel Hecht; Matthew Jacobs; Ishaan Joshi; Lenni Kuff; Dileep Kumar; Alex Leblang; Nong Li; Ippokratis Pandis; Henry Robinson; David Rorke; Silvius Rus; John Russel; Dimitris Tsirogiannis; Skye Wanderman-Milne; Michael Yoder,Zusammenfassung Impala von Cloudera ist ein modernes; massiv parallelesDatenbanksystem; welches von Grund auf für die Bedürfnisse und Anforderungen einer BigData Umgebung wie Hadoop entworfen wurde. Das Ziel von Impala ist es; klassische SQL-Abfragen mit geringer Latenz und Laufzeit auszuführen; so wie man es von typischen BI/DWLösungen gewohnt ist. Gleichzeitig sollen dabei sehr große Quelldaten in Hadoop gelesenwerden; ohne dass ein weiterer Extraktionsprozess in zusätzliche Systemlandschaftennotwendig ist. Dieses Kapitel soll einen Überblick über Impala aus der Benutzerperspektivegeben und detaillierter auf die Hauptkomponenten und deren Entwurfsentscheidungeneingehen. Zusätzlich werden wir einen Geschwindigkeitsvergleich mit anderen bekanntenSQL-auf-Hadoop Lösungen vorstellen; der den besonderen Ansatz von Impala …,*,2016,*
Multi-level aggregation techniques for memory hierarchies,*,Embodiments include method; system; and computer program product for providingaggregation hierarchy that is related memory hierarchies. In one embodiment; the methodincludes determining capacity of a first level memory of a memory hierarchy for processingdata relating to completion of an aggregation process and generating a per thread local look-up table in said first level memory upon determining said capacity. Upon the first levelmemory reaching capacity; a plurality of per thread partitions to store remaining data tocomplete the aggregation process in a second level memory of the memory hierarchy isgenerated such that each of said per-thread partitions includes an identical amount of dataportion on each thread. The method also includes storing the per thread partitions in saidsecond level memory and providing a single global look up table for each of the identical …,*,2015,*
Go; server; go!: parallel computing with moving servers,Ronald Barber; G Lohman; René Mueller; Ippokratis Pandis; Vijayshankar Raman; W Wilcke,Abstract In data centers today; servers are stationary and data flows on a hierarchicalnetwork of switches and routers. But such static server arrangements require very scalablenetworks; and many applications are bottlenecked by network bandwidth. In addition; serverdensity is kept low to enable maintenance and upgrades; as well as to increase air flow. Inthis paper; we propose a design in which servers move physically; and communicate viapoint-to-point connections (instead of switches). We argue that this allows data transferbandwidth to scale linearly with the number of servers; and that moving servers is not asexpensive as it sounds; at least in terms of power consumption. Moreover; while serversmove around; they regularly reach the perimeters of the system; which helps with heatdissipation and with servicing of failed nodes. This design also helps in traditional switch …,Proceedings of the 4th annual Symposium on Cloud Computing,2013,*
Smart Thread Scheduling is the Key for OLTP,Pınar Tözün,Abstract Typical transactions of online transaction processing (OLTP) workloads have largeinstruction footprints; 128KB-1MB; that cannot fit in existing L1-I caches; 32KB [1]. Extensivecapacity misses due to instructions lead to severe under-utilization of modern hardware'smicro-architectural resources [3]. As opposed to the traditional way where a transactionstarts and completes its execution on a single core; some recent OLTP designs employmultiple cores to execute a single transaction [1; 2]; leading to performance improvementsup to 70%. The aggregate size of the caches of several cores creates ample L1-I capacity forthe instructions. In addition; the instructions are localized to caches to exploit instructioncommonality (∼ 90%) among different and within the same transactions. Spreadingtransactions to multiple cores; however; creates the need to share the data among …,*,2013,*
Stop-and-Go Operator: Encyclopedia of Database Systems,N Hardavellas; I Pandis; L Liu; MT Ozsu,Hardavellas; N; Pandis; I; Liu; L (ed.) & Ozsu; MT (ed.) Stop-and-Go Operator: Encyclopediaof Database Systems … Hardavellas N; Pandis I; Liu L; (ed.); Ozsu MT; (ed.). Stop-and-GoOperator: Encyclopedia of Database Systems. 2009 … Hardavellas; N. ; Pandis; I. ; Liu; L.(Editor) ; Ozsu; MT (Editor). / Stop-and-Go Operator : Encyclopedia of Database Systems …Powered by Pure; Scopus & Elsevier Fingerprint Engine™ © 2017 Elsevier BV.,*,2009,*
Inter-Query Parallelism: Encyclopedia of Database Systems,N Hardavellas; I Pandis; L Liu; T Ozsu,Hardavellas; N; Pandis; I; Liu; L (ed.) & Ozsu; T (ed.) Inter-Query Parallelism: Encyclopedia ofDatabase Systems … Hardavellas N; Pandis I; Liu L; (ed.); Ozsu T; (ed.). Inter-QueryParallelism: Encyclopedia of Database Systems. 2009 … Hardavellas; N. ; Pandis; I. ; Liu;L. (Editor) ; Ozsu; T. (Editor). / Inter-Query Parallelism : Encyclopedia of Database Systems …Powered by Pure; Scopus & Elsevier Fingerprint Engine™ © 2017 Elsevier BV.,*,2009,*
Execution Skew: Encyclopedia of Database Systems,N Hardavellas; I Pandis; L Liu; MT Ozsu,Hardavellas; N; Pandis; I; Liu; L (ed.) & Ozsu; MT (ed.) Execution Skew: Encyclopedia of DatabaseSystems … Hardavellas N; Pandis I; Liu L; (ed.); Ozsu MT; (ed.). Execution Skew: Encyclopediaof Database Systems. 2009 … Hardavellas; N. ; Pandis; I. ; Liu; L. (Editor) ; Ozsu; MT(Editor). / Execution Skew : Encyclopedia of Database Systems … Powered by Pure; Scopus& Elsevier Fingerprint Engine™ © 2017 Elsevier BV.,*,2009,*
Operator-Level Parallelism: Encyclopedia of Database Systems,N Hardavellas; I Pandis; L Liu; MT Ozsu,Hardavellas; N; Pandis; I; Liu; L (ed.) & Ozsu; MT (ed.) Operator-Level Parallelism: Encyclopediaof Database Systems … Hardavellas N; Pandis I; Liu L; (ed.); Ozsu MT; (ed.). Operator-LevelParallelism: Encyclopedia of Database Systems. 2009 … Hardavellas; N. ; Pandis; I. ; Liu;L. (Editor) ; Ozsu; MT (Editor). / Operator-Level Parallelism : Encyclopedia of DatabaseSystems … Powered by Pure; Scopus & Elsevier Fingerprint Engine™ © 2017 Elsevier BV.,*,2009,*
Stop-&-go Operator,Nikos Hardavellas; Ippokratis Pandis,The values in the relations of a relational database are elements of one or more underlyingsets called domains. In practical applications; a domain may be infinite; eg; the set of naturalnumbers. In this case; the value of a relational calculus query when applied to such adatabase may be infinite; eg;{njn! 10}. A query Q is called finite if the value of Q whenapplied to any database is finite. Even when the database domains are finite; all that isnormally known about them is that they are some finite superset of the values that occur inthe database. In this case; the value of a relational calculus query may depend on such anunknown domain; eg;{xj 8yR (x; y)}. A query Q is called domain independent if the value of Qwhen applied to any database is the same for any two domains containing the databasevalues or; equivalently; if the value of Q when applied to a database contains only values …,*,2009,*
Intra-Query Parallelism,Nikos Hardavellas; Ippokratis Pandis,An example of index oriented towards human navigation is the web directory. In such anindex; links to sites are organized into hierarchical categories; according to the sites'contents. In web directories; normally the tasks of collecting and categorizing pages arecarried out under supervision of human editors. An example of index not oriented to humansis a hidden list of metadata. Metadata are data about data. As a mean of assisting a searchengine to locate content or an information entity; they can be used to describe that content orentity. While not visible to humans; this information can provide contextual clues to automaticalgorithms used by search engines.,*,2009,*
Operator-Level Parallelism,Nikos Hardavellas; Ippokratis Pandis,OASIS was founded in 1993 under the name ''SGML Open.''The initial goal of theorganization was to develop guidelines for interoperability among products using StandardGeneralized Markup Language (SGML). In 1998 it changed name to OASIS to reflect onchanging scope of its technical work. OASIS consists of an open group of memberorganizations whose representatives work in committees developing standards; promotingstandards adoption; product interoperability and standards conformance. In 2007 OASIShad 5;000 participants representing 600 organizations and individual members in 100countries. OASIS is governed by a member-elected Board in an annual election process.The board membership is based on the personal merits of Board nominees. OASIS processallows participants to influence standards that affect their business; contribute to …,*,2009,*
Execution Skew,Nikos Hardavellas; Ippokratis Pandis,Definition eAccessibility refers to the access of Information and CommunicationTechnologies (ICT) by people with disabilities; with particular emphasis on the World WideWeb. It is the extent to which the use of an application or service is affected by the user'sparticular functional limitations or abilities (permanent or temporary). eAccessibility can beconsidered as a fundamental prerequisite of usability.,*,2009,*
Erratum to: Efficiently making (almost) any concurrency control mechanism serializable,Tianzheng Wang; Ryan Johnson; Alan Fekete; Ippokratis Pandis,The original article uses incorrect versions of Figures 6; 7; 8; 9 that do not match theirdescriptions. The correct figures are given below. The original article has been corrected(Figs. 6; 7; 8; 9) … The online version of the original article can be found underdoi:10.1007/s00778-017-0463-8. B Tianzheng Wang tzwang@cs.toronto.edu Ryan Johnsonryan.johnson@logicblox.com Alan Fekete alan.fekete@sydney.edu.au Ippokratis Pandisippo@amazon.com … 1 Department of Computer Science; University of Toronto; Toronto;ON; Canada 2 LogicBlox; Atlanta; GA; USA 3 School of Information Technologies; Universityof Sydney; Sydney; NSW; Australia 4 Amazon Web Services; Palo Alto; CA; USA … 100 200400 800 1600 3200 6400 12800 … SI RC SI/SER RC/SER SI+SSN RC+SSN SSI … 100 200400 800 1600 3200 6400 12800 Database size … Fig. 6 The effect of contention for …,The VLDB Journal,*,*
BionicDB: A Custom Hardware Approach Towards Fast and Power-Efficient Transaction Processing,Kangnyeon Kim; Ryan Johnson; Ippokratis Pandis,ABSTRACT With the rise of dark silicon; specialization has been considered as a promisingalternative to general-purpose hardware for certain range of applications; ushering inheterogeneous computing paradigm. Meanwhile; several recent trends are converging toeliminate the barriers to custom hardware deployment; allowing it to be both technologicallyand economically feasible. Considering the opportunities and challenges from the recenthardware landscape; we describe the design and implementation of BionicDB; a customhardware for online transaction processing (OLTP) that can be built on field programmablegate array (FPGA). With the majority of transaction components offloaded; BionicDBperforms as fast as state-of-the-art databases running on high-end CPUs with an order ofmagnitude lower power footprint; thanks to its highly OLTP-optimized hardware design. It …,*,*,*
ERMIA: Fast and robust memory-optimized OLTP,Kangnyeon Kim Tianzheng Wang Ryan Johnson; Ippokratis Pandis,*,Ratio,*,*
Simultaneous Query Pipelines in QPipe,Kun Gao; Stavros Harizopoulos; Ippokratis Pandis; Anastassia Ailamaki; Vladislav Shkapenyuk,Data warehousing and scientific database applications operate on massive datasets andare characterized by complex queries accessing large portions of the database. Concurrentqueries often exhibit high data and computation overlap; eg; they access the same relationson disk; compute similar aggregates; or share intermediate results. Unfortunately; run-timesharing in modern database engines is limited by the paradigm of invoking an independentset of operator instances per query; potentially missing sharing opportunities if the bufferpool evicts data early. QPipe is a new; operator-centric; relational query engine that candetect and exploit overlap across concurrent queries; at run time [1]. In QPipe; eachrelational operator is promoted to an independent micro-engine (μEngine) with its ownresource management and runtime support. Incoming queries break up into as many …,*,*,*
Data Engineering,Ronald Barber; Peter Bendel; Marco Czech; Oliver Draese; Frederick Ho; Namik Hrle; Stratos Idreos; Min-Soo Kim; Oliver Koeth; Jae-Gil Lee; Tianchao Tim Li; Guy Lohman; Konstantinos Morfonios; Rene Mueller; Keshava Murthy; Ippokratis Pandis; Lin Qiao; Vijayshankar Raman; Richard Sidle; Knut Stolze; Sandor Szabo,The Data Engineering Bulletin The Bulletin of the Technical Committee on Data Engineeringis published quarterly and is distributed to all TC members. Its scope includes the design;implementation; modelling; theory and application of database systems and theirtechnology. Letters; conference information; and news should be sent to the Editor-in-Chief.Papers for each issue are solicited by and should be sent to the Associate Editorresponsible for the issue. Opinions expressed in contributions are those of the authors anddo not necessarily reflect the positions of the TC on Data Engineering; the IEEE ComputerSociety; or the authors' organizations. The Data Engineering Bulletin web site is at http://tab.computer. org/tcde/bull_about. html.,*,*,*
18-741: Advanced Computer Architecture,Kun Gao; Ippokratis Pandis,The current trends in hardware technologies show a constantly increasing performance gapbetween the speed of CPUs (processors) and main memory [1]. This gap results the need oflarge but fast memory caches. If we had only one very big (L1) cache then we would beforced to have larger clock cycles. Thus; we overcome this problem by adding additionallevels of larger and slower memory caches between the CPU and the main memory; asshown in figure 1.,*,*,*
18-742: Multiprocessor Architecture,Nikos Hardavellas; Ippokratis Pandis,Advances in microprocessor fabrication have allowed feature sizes to shrink; leading to anexponential increase in the number of transistors per chip. The shrinking processgeometries coupled with microarchitectural innovation have enabled the placement ofmultiple cores on a single chip (eg Power5 [1]). The resulting architectures are known aschip multiprocessors (CMPs) and they typically employ a second-level (L2) cache that isshared among all on-chip cores. While feature sizes continue to shrink; the InternationalTechnology Roadmap for Semiconductors (ITRS [2]) predicts that market forces andtechnological limitations restrict the chip size to 280 mm2 for high-volume microprocessors.A constant chip area introduces a trade-off between the number of cores that are placed ona chip and the remaining area used for the shared cache; determining the maximum …,*,*,*
15-823: Hot Topics in Database Systems,Kun Gao; Ippokratis Pandis,*,*,*,*
